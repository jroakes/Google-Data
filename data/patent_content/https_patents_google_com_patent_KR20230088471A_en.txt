KR20230088471A - Mapping Type Instances in Documents - Google Patents
Mapping Type Instances in Documents Download PDFInfo
- Publication number
- KR20230088471A KR20230088471A KR1020237016612A KR20237016612A KR20230088471A KR 20230088471 A KR20230088471 A KR 20230088471A KR 1020237016612 A KR1020237016612 A KR 1020237016612A KR 20237016612 A KR20237016612 A KR 20237016612A KR 20230088471 A KR20230088471 A KR 20230088471A
- Authority
- KR
- South Korea
- Prior art keywords
- computer system
- document
- computer
- user
- hash
- Prior art date
Links
- 238000013507 mapping Methods 0.000 title description 22
- 238000000034 method Methods 0.000 claims abstract description 91
- 230000004044 response Effects 0.000 claims abstract description 36
- 238000004590 computer program Methods 0.000 claims description 18
- 230000003190 augmentative effect Effects 0.000 claims description 5
- 230000008859 change Effects 0.000 claims description 5
- 238000001514 detection method Methods 0.000 claims description 4
- 230000015654 memory Effects 0.000 description 31
- 238000004891 communication Methods 0.000 description 22
- 238000012217 deletion Methods 0.000 description 7
- 230000037430 deletion Effects 0.000 description 7
- 230000006870 function Effects 0.000 description 7
- 238000003780 insertion Methods 0.000 description 7
- 230000037431 insertion Effects 0.000 description 7
- 230000003993 interaction Effects 0.000 description 7
- 230000000007 visual effect Effects 0.000 description 6
- 230000004913 activation Effects 0.000 description 4
- 230000003287 optical effect Effects 0.000 description 4
- 230000008520 organization Effects 0.000 description 4
- 230000009471 action Effects 0.000 description 3
- 238000013459 approach Methods 0.000 description 3
- 238000012790 confirmation Methods 0.000 description 3
- 238000007726 management method Methods 0.000 description 3
- 238000005259 measurement Methods 0.000 description 3
- 230000008569 process Effects 0.000 description 3
- 210000001525 retina Anatomy 0.000 description 3
- 240000007320 Pinus strobus Species 0.000 description 2
- 230000003213 activating effect Effects 0.000 description 2
- 230000001413 cellular effect Effects 0.000 description 2
- 238000005516 engineering process Methods 0.000 description 2
- 239000011521 glass Substances 0.000 description 2
- 210000003128 head Anatomy 0.000 description 2
- 238000012905 input function Methods 0.000 description 2
- 238000012015 optical character recognition Methods 0.000 description 2
- 230000002093 peripheral effect Effects 0.000 description 2
- 238000012545 processing Methods 0.000 description 2
- 238000012546 transfer Methods 0.000 description 2
- 208000010415 Low Vision Diseases 0.000 description 1
- 230000004397 blinking Effects 0.000 description 1
- 238000013500 data storage Methods 0.000 description 1
- 238000011161 development Methods 0.000 description 1
- 230000035620 dolor Effects 0.000 description 1
- 239000004973 liquid crystal related substance Substances 0.000 description 1
- 230000004303 low vision Effects 0.000 description 1
- 239000000203 mixture Substances 0.000 description 1
- 238000012986 modification Methods 0.000 description 1
- 230000004048 modification Effects 0.000 description 1
- 230000006855 networking Effects 0.000 description 1
- 239000000047 product Substances 0.000 description 1
- 238000004064 recycling Methods 0.000 description 1
- 230000001953 sensory effect Effects 0.000 description 1
- 230000021317 sensory perception Effects 0.000 description 1
- 239000007787 solid Substances 0.000 description 1
- 239000013589 supplement Substances 0.000 description 1
- 230000001502 supplementing effect Effects 0.000 description 1
- 230000009897 systematic effect Effects 0.000 description 1
- 238000012876 topography Methods 0.000 description 1
- 230000001960 triggered effect Effects 0.000 description 1
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/60—Protecting data
- G06F21/604—Tools and structures for managing or administering access control systems
-
- G—PHYSICS
- G02—OPTICS
- G02B—OPTICAL ELEMENTS, SYSTEMS OR APPARATUS
- G02B27/00—Optical systems or apparatus not provided for by any of the groups G02B1/00 - G02B26/00, G02B30/00
- G02B27/01—Head-up displays
- G02B27/017—Head mounted
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/10—Protecting distributed programs or content, e.g. vending or licensing of copyrighted material ; Digital rights management [DRM]
- G06F21/12—Protecting executable software
- G06F21/14—Protecting executable software against software analysis or reverse engineering, e.g. by obfuscation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/60—Protecting data
- G06F21/62—Protecting access to data via a platform, e.g. using keys or access control rules
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/017—Gesture based interaction, e.g. based on a set of recognized hand gestures
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L13/00—Speech synthesis; Text to speech systems
- G10L13/08—Text analysis or generation of parameters for speech synthesis out of text, e.g. grapheme to phoneme translation, prosody generation or stress or intonation determination
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L63/00—Network architectures or network communication protocols for network security
- H04L63/10—Network architectures or network communication protocols for network security for controlling access to devices or network resources
Abstract
컴퓨터로 구현되는 방법은, 제1 컴퓨터 시스템에 의해, 제1 문서의 유형 인스턴스의 제1 콘텐츠를 검출하는 단계; 제1 컴퓨터 시스템에 의해, 제1 콘텐츠를 사용하여 제1 해시를 생성하는 단계 - 제1 해시는 제1 난독화 콘텐츠를 포함함 -; 제1 컴퓨터 시스템에 의해, 제2 컴퓨터 시스템에 의한 수신을 위해 제1 해시를 전송하는 단계; 및 제1 컴퓨터 시스템에 의해, 제2 컴퓨터 시스템에 의해 생성된 제1 해시에 대한 응답을 수신하는 단계 - 응답은 제1 콘텐츠와 연관된 제2 문서에 대응하는 정보를 포함함 - 를 포함한다.The computer-implemented method includes detecting, by a first computer system, first content of a tangible instance of a first document; generating, by a first computer system, a first hash using the first content, the first hash including the first obfuscated content; transmitting, by the first computer system, the first hash for reception by the second computer system; and receiving, by the first computer system, a response to the first hash generated by the second computer system, the response including information corresponding to a second document associated with the first content.
Description
본 명세서는 문서의 유형 인스턴스 매핑에 관한 것이다. This specification relates to type instance mapping of documents.
역사적으로 문서는 일반적으로 내구성 있는 매체(예: 종이)로 만들어졌다. 동일한 문서의 사본이 두 개 이상 생성되면 사본이 서로 별도로 배포되는 경우가 많았으며 각 개별 사본에 어떤 일이 발생했는지 추적하는 것이 항상 가능하거나 실용적이지 않았다. 예를 들어, 한 사람이 종이 문서를 작성하면 해당 종이에 대해 배우거나 반응할 수 없는 많은 일이 발생할 수 있다. Historically, documents were usually made on a durable medium (e.g. paper). When more than one copy of the same document was created, the copies were often distributed separately from each other, and it was not always possible or practical to keep track of what happened to each individual copy. For example, when a person writes a paper document, many things can happen that cannot learn or react to that paper.
컴퓨터 기술의 출현과 함께 문서를 전자 형식으로 유지 및 편집할 수 있는 가능성이 생겼고 결과적으로 시간이 지남에 따라 보다 체계적이고 신뢰할 수 있는 방식으로 문서의 개발 및 사용을 모니터링할 수 있게 되었다. 그러나 시간 및 물류 기록 보관에 대한 이러한 향상된 기능은 1과 0의 형태로 표현하여 디지털 방식으로 유지 관리되는 전자 기록 자체에만 적용되었다. 한편, 인간이 문서를 직접 인식하거나 이해하기 위해 필요한 이러한 전자 문서의 물리적 인스턴스화는 역사적으로 종이 문서와 관련된 동일한 문제에 직면하는 경우가 많다. With the advent of computer technology came the possibility of maintaining and editing documents in electronic form, which consequently made it possible to monitor the development and use of documents over time in a more systematic and reliable way. However, these enhancements to time and logistical record keeping have only been applied to the electronic records themselves, which are maintained digitally, expressed in the form of ones and zeroes. On the other hand, the physical instantiation of these electronic documents, which is necessary for humans to directly perceive or understand the document, often faces the same problems historically associated with paper documents.
제1 양태에서, 컴퓨터로 구현되는 방법은, 제1 컴퓨터 시스템에 의해, 제1 문서의 유형 인스턴스(tangible instance)의 제1 콘텐츠를 검출하는 단계; 상기 제1 컴퓨터 시스템에 의해, 상기 제1 콘텐츠를 사용하여 제1 해시를 생성하는 단계 -상기 제1 해시는 제1 난독화 콘텐츠를 포함함-; 상기 제1 컴퓨터 시스템에 의해, 제2 컴퓨터 시스템에 의한 수신을 위해 상기 제1 해시를 전송하는 단계; 그리고 상기 제1 컴퓨터 시스템에 의해, 상기 제2 컴퓨터 시스템에 의해 생성된 상기 제1 해시에 대한 응답을 수신하는 단계를 포함하며, 상기 응답은 상기 제1 콘텐츠와 연관된 제2 문서에 대응하는 정보를 포함한다. In a first aspect, a computer-implemented method includes: detecting, by a first computer system, first content of a tangible instance of a first document; generating, by the first computer system, a first hash using the first content, the first hash including first obfuscated content; transmitting, by the first computer system, the first hash for reception by a second computer system; and receiving, by the first computer system, a response to the first hash generated by the second computer system, the response comprising information corresponding to a second document associated with the first content. include
구현에는 다음 기능 중 일부 또는 전부가 포함될 수 있다. 제2 컴퓨터 시스템은 문서들의 컬렉션을 위한 협업 프로그램을 제어한다. 컴퓨터로 구현되는 방법은 제1 컴퓨터 시스템에 의해 그리고 응답에 기초하여 제2 컴퓨터 시스템에 의한 수신을 위해 제1 콘텐츠를 전송하는 단계를 더 포함한다. 제2 컴퓨터 시스템은 제1 콘텐츠를 이용하여 협업 프로그램을 위한 새로운 문서를 생성한다. 컴퓨터로 구현되는 방법은 제1 컴퓨터 시스템에 의해 그리고 응답에 기초하여 제2 컴퓨터 시스템에 의한 수신을 위해 제1 문서의 마크업된 변경을 전송하는 단계를 더 포함한다. 문서들의 컬렉션에는 제2 문서가 포함된다. 제2 컴퓨터 시스템은 제2 문서의 제2 콘텐츠를 사용하여 제2 해시를 생성하고, 제2 해시는 제2 난독화 콘텐츠를 포함하고, 제2 해시는 응답에 포함된다. 컴퓨터로 구현되는 방법은 제1 컴퓨터 시스템에 의해 제2 해시를 사용하여 제1 문서와 제2 문서 사이의 대응관계를 검증하는 단계를 더 포함한다. 컴퓨터로 구현되는 방법은 제1 컴퓨터 시스템에 의해 제2 컴퓨터 시스템으로부터 제2 문서를 수신하는 단계를 더 포함한다. 제2 컴퓨터 시스템은 제1 해시를 수신하면 제2 콘텐츠에 대한 무단 액세스을 검출한다. 컴퓨터로 구현되는 방법은 제1 컴퓨터 시스템에 의해 제1 컴퓨터 시스템의 사용자에 대한 액세스 이력을 수신하는 단계를 더 포함하고, 상기 이력은 상기 제1 해시를 수신한 제2 컴퓨터 시스템에 기초하여 상기 제2 문서에 액세스하기 위한 엔트리를 포함한다. 제2 문서에 액세스하기 위한 엔트리는 상기 사용자가 상기 제1 문서의 하드카피 또는 상기 제1 문서의 온스크린 프리젠테이션 중 적어도 하나에 근접한 것을 검출하는 것에 기초한다. 상기 제2 컴퓨터 시스템은 상기 사용자가 상기 제2 문서에 대한 액세스 권한을 가지고 있다는 결정에 응답하여 상기 엔트리를 생성한다. 상기 사용자는 상기 제2 문서에 대한 액세스 권한을 가지고 있지 않고, 그리고 상기 제2 문서에 대응하는 정보는 상기 사용자가 상기 제2 문서에 대한 액세스 권한을 요청하기 위한 제어를 포함한다. 상기 사용자는 상기 제2 문서에 대한 액세스 권한을 갖고 있지 않으며, 상기 제2 컴퓨터 시스템은 상기 사용자가 적어도 미리 결정된 시간 동안 상기 제1 문서에 액세스하고 있다는 결정에 응답하여 상기 사용자에게 상기 액세스 권한을 부여한다. 상기 제1 컴퓨터 시스템은 상기 제2 컴퓨터 시스템에 대한 상기 제1 컴퓨터 시스템의 사용자를 식별하고, 상기 문서들의 컬렉션은 상기 문서들의 컬렉션에 대한 액세스 권한을 가진 사용자에 기초하여 정의된다. 컴퓨터로 구현되는 방법은 상기 제1 컴퓨터 시스템에 의해 그리고 사용자로부터, 상기 제1 문서에 대한 TTS(text-to-speech) 서비스에 대한 요청을 수신하는 단계 -상기 제2 문서는 구조 마크업을 포함함-, 그리고 상기 제2 문서를 이용하여 상기 제1 문서의 상기 TTS 서비스를 제공하는 단계를 더 포함한다. 상기 제1 컴퓨터 시스템은 디스플레이 장치 상에 제시되는 상기 제1 문서에 기초하여 상기 제1 콘텐츠를 검출한다. 상기 디스플레이 장치는 상기 제1 컴퓨터 시스템에 의해 제어되고 그리고 데스크톱에 스크린 공유 애플리케이션을 제시하고, 상기 제1 문서는 상기 스크린 공유 애플리케이션을 사용하여 상기 제1 컴퓨터 시스템과 스크린 공유되고 있다. 상기 제1 컴퓨터 시스템은 상기 데스크탑 상에 브라우저를 더 제시하고, 상기 브라우저는 상기 협업 프로그램을 사용하여 상기 데스크톱에서 상기 제2 문서를 오프닝하는 제어를 제공한다. 컴퓨터로 구현되는 방법은 상기 제1 컴퓨터 시스템에 의해, 상기 협업 프로그램을 사용하여 상기 제2 문서의 오프닝을 트리거하기 위해 상기 제1 문서의 표현의 드래깅(dragging)을 용이하게 하는 단계를 더 포함한다. 상기 드래깅은 상기 제2 문서가 상기 제1 컴퓨터 시스템의 데스크탑 상에 제시되게 한다. 상기 드래깅은 상기 제1 컴퓨터 시스템에 의해 검출되는 다른 컴퓨터 시스템에 기초하여 상기 제2 문서가 또 다른 컴퓨터 시스템에 제시되게 한다. 상기 제1 컴퓨터 시스템은 증강 현실(AR) 헤드셋을 포함하고, 상기 제1 컴퓨터 시스템은 AR 헤드셋의 FOV(field of view) 내에 있는 상기 제1 콘텐츠에 기초하여 상기 제1 콘텐츠를 검출한다. 컴퓨터로 구현되는 방법은 상기 제1 컴퓨터 시스템에 의해, 상기 AR 헤드셋의 사용자가 AR FOV(field of view) 내에서 제스처를 수행하는 것을 검출하는 단계, 그리고 이에 응답하여 상기 제스처에 따라 상기 AR FOV 내에서 상기 제1 문서의 표현을 이동시키는 단계를 더 포함한다. 상기 표현을 이동시키는 단계는 상기 협업 프로그램을 사용하여 상기 제1 컴퓨터 시스템에서 상기 제2 문서의 오프닝을 용이하게 한다. 상기 표현을 이동시키는 단계는 상기 제1 컴퓨터 시스템에 의해 검출된 다른 컴퓨터 시스템에서, 상기 협업 프로그램을 사용하여, 상기 제2 문서의 오프닝을 용이하게 한다. 컴퓨터로 구현되는 방법은 상기 제1 컴퓨터 시스템에 의해 그리고 상기 정보를 사용하여, 상기 제2 문서의 제2 콘텐츠를 제시하는 단계를 더 포함한다. 상기 제1 컴퓨터 시스템은 증강 현실(AR) 헤드셋을 포함하고, 상기 제1 컴퓨터 시스템은 상기 AR 헤드셋의 FOV 내에 있는 상기 제1 콘텐츠에 기초하여 상기 제1 콘텐츠를 검출하고, 그리고 상기 제2 콘텐츠를 제시하는 단계는 상기 제1 문서에 제1 가상 애노테이션(virtual annotation)을 적용하는 단계를 포함한다. 컴퓨터로 구현되는 방법은 상기 제1 컴퓨터 시스템에 의해, 상기 제1 문서의 변경에 대응하는 사용자에 의해 생성된 오디오 입력을 수신하는 단계, 상기 AR FOV에 상기 제1 문서에 대한 제2 가상 애노테이션을 제시하는 단계, 상기 변경을 상기 제2 컴퓨터 시스템으로 전송하는 단계를 더 포함한다. 상기 제2 문서는 공개적으로 액세스 가능하고 그리고 상기 응답은 상기 제2 문서를 포함한다. 상기 제1 및 제2 문서는 종이 문서이고, 그리고 상기 제2 컴퓨터 시스템은 상기 제2 문서의 제2 해시 및 제1 해시를 사용하여 상기 제1 문서와 연관되는 상기 제2 문서를 검출한다. 상기 제1 및 제2 해시는 상기 제1 및 제2 컴퓨터 시스템 사이에서 상기 제1 또는 제2 문서에 관한 가상 애노테이션의 공유를 용이하게 한다. Implementations may include some or all of the following features: A second computer system controls a collaboration program for a collection of documents. The computer-implemented method further includes sending the first content for reception by the first computer system and based on the response by the second computer system. The second computer system uses the first content to create a new document for the collaboration program. The computer-implemented method further includes transmitting the marked-up changes to the first document for reception by the first computer system and based on the response by the second computer system. The collection of documents includes a second document. The second computer system generates a second hash using the second content of the second document, the second hash includes the second obfuscated content, and the second hash is included in the response. The computer-implemented method further includes verifying, by the first computer system, a correspondence between the first document and the second document using the second hash. The computer-implemented method further includes receiving, by the first computer system, a second document from a second computer system. Upon receiving the first hash, the second computer system detects unauthorized access to the second content. The computer-implemented method further includes receiving, by a first computer system, an access history for a user of the first computer system, wherein the history is based on the second computer system that received the first hash. 2 Contains entries for accessing documents. Entry to access the second document is based on detecting the user's proximity to at least one of a hardcopy of the first document or an on-screen presentation of the first document. The second computer system creates the entry in response to determining that the user has access to the second document. The user does not have access rights to the second document, and information corresponding to the second document includes a control for the user to request access rights to the second document. The user does not have access rights to the second document, and the second computer system grants the user the access rights in response to determining that the user has been accessing the first document for at least a predetermined amount of time. do. The first computer system identifies a user of the first computer system to the second computer system, and the collection of documents is defined based on the user with access rights to the collection of documents. The computer-implemented method includes receiving, by the first computer system and from a user, a request for a text-to-speech (TTS) service for the first document, wherein the second document includes structural markup. and providing the TTS service of the first document by using the second document. The first computer system detects the first content based on the first document presented on a display device. The display device is controlled by the first computer system and presents a screen sharing application on a desktop, and the first document is being screen shared with the first computer system using the screen sharing application. The first computer system further presents a browser on the desktop, and the browser provides controls for opening the second document on the desktop using the collaboration program. The computer-implemented method further includes facilitating, by the first computer system, dragging of a representation of the first document to trigger opening of the second document using the collaboration program. . The dragging causes the second document to be presented on the desktop of the first computer system. The dragging causes the second document to be presented to another computer system based on the other computer system being detected by the first computer system. The first computer system includes an augmented reality (AR) headset, and the first computer system detects the first content based on the first content within a field of view (FOV) of the AR headset. The computer-implemented method includes detecting, by the first computer system, that a user of the AR headset performs a gesture within an AR field of view (FOV), and in response to the gesture within the AR FOV according to the gesture. and moving the representation of the first document in . Moving the representation facilitates opening of the second document at the first computer system using the collaboration program. Moving the representation facilitates opening of the second document, using the collaboration program, at another computer system detected by the first computer system. The computer-implemented method further includes presenting, by the first computer system and using the information, second content of the second document. The first computer system includes an augmented reality (AR) headset, the first computer system detects the first content based on the first content within a FOV of the AR headset, and detects the second content. The presenting includes applying a first virtual annotation to the first document. The computer-implemented method includes receiving, by the first computer system, an audio input generated by a user corresponding to a change in the first document, and displaying a second virtual annotation for the first document in the AR FOV. presenting, and transmitting the change to the second computer system. The second document is publicly accessible and the response includes the second document. The first and second documents are paper documents, and the second computer system detects the second document associated with the first document using a second hash and a first hash of the second document. The first and second hashes facilitate sharing of virtual annotations relating to the first or second document between the first and second computer systems.
제2 양태에서, 컴퓨터 프로그램 제품은 비일시적 저장 매체에 유형적으로 구현되며, 상기 컴퓨터 프로그램 제품은 하나 이상의 프로세서(들)에 의해 실행될 때 상기 하나 이상의 프로세서(들)로 하여금 동작들을 수행하게 하는 명령어를 포함하며, 상기 동작들은, 제1 컴퓨터 시스템에 의해, 제1 문서의 유형 인스턴스의 제1 콘텐츠를 검출하는 동작; 상기 제1 컴퓨터 시스템에 의해, 상기 제1 콘텐츠를 사용하여 제1 해시를 생성하는 동작 -상기 제1 해시는 제1 난독화 콘텐츠를 포함함-; 상기 제1 컴퓨터 시스템에 의해, 제2 컴퓨터 시스템에 의한 수신을 위해 상기 제1 해시를 전송하는 동작; 그리고 상기 제1 컴퓨터 시스템에 의해, 상기 제2 컴퓨터 시스템에 의해 생성된 상기 제1 해시에 대한 응답을 수신하는 동작을 포함하며, 상기 응답은 상기 제1 콘텐츠와 연관된 제2 문서에 대응하는 정보를 포함한다.In a second aspect, a computer program product is tangibly embodied in a non-transitory storage medium, the computer program product comprising instructions that when executed by one or more processor(s) cause the one or more processor(s) to perform operations. The operations include: detecting, by a first computer system, first content of a tangible instance of a first document; generating, by the first computer system, a first hash using the first content, the first hash including first obfuscated content; transmitting, by the first computer system, the first hash for reception by a second computer system; and receiving, by the first computer system, a response to the first hash generated by the second computer system, the response comprising information corresponding to a second document associated with the first content. include
구현에는 다음과 같은 양태가 포함될 수 있다. 상기 컴퓨터 프로그램 제품은 상기 하나 이상의 프로세서(들)에 의해 실행될 때 상기 하나 이상의 프로세서(들)로 하여금 제1항 내지 제33항 중 어느 한 항의 방법을 수행하게 하는 명령어를 포함한다. Implementations may include the following aspects. The computer program product comprises instructions that when executed by the one or more processor(s) cause the one or more processor(s) to perform the method of any one of claims 1-33.
하나의 양태의 선택적 기능은 임의의 다른 양태와 결합될 수 있다. Optional features of one aspect may be combined with any other aspect.
도 1은 컴퓨터 시스템의 예를 보여준다.
도 2는 도 1의 컴퓨터 시스템의 스토리지의 예를 도시한다.
도 3a-3f는 문서의 유형 인스턴스와 관련된 예를 보여준다.
도 4a-4b는 유형 인스턴스 및 컴퓨터 시스템에 관한 예를 개념적으로 도시한다.
도 5는 스토리지 드라이브에 관한 예를 도시한다.
도 6a는 도 5의 스토리지 드라이브에 관한 예를 도시한다.
도 6b는 사용자가 도 3a 내지 도 3d의 유형 인스턴스 및 AR FOV(field of view)를 보고 있음을 도시한다.
도 7a 내지 도 7b는 AR FOV 및 도 3a 내지 도 3e의 유형 인스턴스에 관한 예를 도시한다.
도 8a 내지 도 8e는 디스플레이 장치 및 도 3a 내지 도 3e의 유형 인스턴스에 관한 예를 도시한다.
도 9a 내지 도 9b는 도 8a 내지 8e의 디스플레이 장치에 관한 예를 도시한다.
도 10은 컴퓨터로 구현되는 방법의 예를 보여준다.
도 11은 여기에 기술된 기술을 구현하기 위해 사용될 수 있는 컴퓨터 장치 및 모바일 컴퓨터 장치의 예를 도시한다.
여러 도면에서 동일한 참조 부호는 동일한 요소를 나타낸다.1 shows an example of a computer system.
FIG. 2 illustrates an example of storage of the computer system of FIG. 1;
3a-3f show examples involving type instances of documents.
4A-4B conceptually illustrate examples of type instances and computer systems.
5 shows an example of a storage drive.
FIG. 6A shows an example of the storage drive of FIG. 5 .
FIG. 6B shows that the user is looking at the type instance and AR field of view (FOV) of FIGS. 3A-3D .
7A-7B show examples of AR FOV and type instances of FIGS. 3A-3E.
8a to 8e show examples of display devices and instances of the types of FIGS. 3a to 3e.
9A to 9B show examples of the display devices of FIGS. 8A to 8E.
10 shows an example of a computer-implemented method.
11 illustrates examples of computer devices and mobile computer devices that can be used to implement the techniques described herein.
Like reference numbers in the various drawings indicate like elements.
본 명세서는 문서의 유형 인스턴스(tangible instance)(예: 종이 사본 또는 온-스크린 프리젠테이션)의 매핑을 수행하는 예를 설명한다. 유형 인스턴스는, 유형 인스턴스가 생성된 전자 문서 또는 동일한 문서의 다른 유형 인스턴스(또한 유형 인스턴스가 공통 전자 원본에서 생성되지 않은 경우)에 매핑될 수 있다. 이러한 매핑은 더 나은 사용자 경험, 개인적이거나 민감한 정보에 대한 향상된 보호, 향상된 기록 보관 및/또는 향상된 정보 보안을 촉진할 수 있다. This specification describes examples of performing mapping of tangible instances of documents (eg, paper copies or on-screen presentations). A type instance may be mapped to the electronic document from which it was created or to another type instance of the same document (also if the type instance was not created from a common electronic source). Such mapping may promote a better user experience, improved protection of personal or sensitive information, improved record keeping, and/or improved information security.
여기의 예는 컴퓨터 시스템을 나타낸다. 본 명세서에서 사용되는 바와 같이, 컴퓨터 시스템은 본 명세서에 기술된 하나 이상의 컴퓨터 기술을 수행하기 위해 하드웨어, 펌웨어 및 소프트웨어로 구성된 하나 이상의 장치의 임의의 적절한 조합을 포함하지만 이에 제한되지 않는다. 여기에서 사용되는 컴퓨터 시스템은 집합적으로 작동하는 단일 컴퓨팅 장치 또는 다중 컴퓨팅 장치일 수 있으며 데이터 저장 및 기능 실행이 다양한 컴퓨팅 장치 사이에 분산되어 있다. The example here represents a computer system. As used herein, a computer system includes, but is not limited to, any suitable combination of one or more devices comprised of hardware, firmware, and software to perform one or more of the computer techniques described herein. A computer system as used herein may be a single computing device or multiple computing devices working collectively, with data storage and function execution distributed among the various computing devices.
여기서의 예는 클라이언트 또는 서버에 의해 수행되는 동작 또는 클라이언트 측 또는 서버 측에서 발생하는 동작을 나타낸다. 여기서 클라이언트 및 서버라는 용어는 설명의 목적으로만 사용되며 특정 유형의 컴퓨터 시스템 또는 장치에만 제한되지 않는다. 본 명세서에서 사용되는 바와 같이, 클라이언트 또는 서버는 달리 나타내지 않는 한 모든 유형의 컴퓨터 시스템을 포함할 수 있다. 예를 들어 서버에는 물리적 서버 및/또는 가상 머신이 포함될 수 있다. 예를 들어 클라이언트는 웨어러블 장치, 태블릿, 디지털 오디오 플레이어, 비디오 게임 콘솔, 데스크톱 컴퓨터, 랩톱 컴퓨터, 프로젝터, 텔레비전, 전자 광고판, 휴대폰, PDA 및/또는 스마트폰을 포함할 수 있다. Examples herein represent operations performed by the client or server or operations occurring on the client side or server side. The terms client and server are used herein for descriptive purposes only and are not limited to any particular type of computer system or device. As used herein, a client or server may include any type of computer system unless indicated otherwise. For example, servers may include physical servers and/or virtual machines. For example, clients may include wearable devices, tablets, digital audio players, video game consoles, desktop computers, laptop computers, projectors, televisions, electronic billboards, cell phones, PDAs, and/or smart phones.
여기서의 예는 증강 현실(AR: augmented reality)을 참조한다. 본 명세서에서 사용되는 바와 같이, AR은 적어도 하나의 가상 에스펙트(virtual aspect) 및 적어도 하나의 현실 에스펙트를 포함하는 컴퓨터 시스템이 감각 지각을 용이하게 하는 사용자 경험을 말한다. AR은 웨어러블 장치를 포함하되 이에 국한되지 않는 여러 유형의 컴퓨터 시스템에서 제공될 수 있다. 여기에서 사용되는 AR 헤드셋은 AR을 용이하게 하는 모든 컴퓨터 시스템을 의미한다. AR 헤드셋에는 AR 안경, 다른 웨어러블 AR 장치, 태블릿 또는 노트북 컴퓨터가 포함될 수 있지만 이에 국한되지는 않는다. 일부 유형의 AR에서는 사용자가 컴퓨터 시스템의 중개 없이 자신의 감각으로 직접 현실의 에스펙트를 인지할 수 있다. 예를 들어, 일부 AR 헤드셋은 사용자의 망막에 이미지(예: 인식할 가상 에스펙트)를 전송하는 동시에 눈이 AR 헤드셋에서 생성되지 않은 다른 빛을 등록할 수 있도록 설계되었다. 다른 예로서, 인렌즈 마이크로폰로 디스플레이는 투시 렌즈에 내장될 수 있거나 투사된 디스플레이가 투시 렌즈에 오버레이될 수 있다. 다른 유형의 AR에서 컴퓨터 시스템은 하나 이상의 방식으로 현실에 대한 사용자의 노출(예: 인식할 실제 에스펙트)을 개선, 보완, 변경 및/또는 가능하게 할 수 있다. 일부 구현에서 AR은 컴퓨터 시스템의 디스플레이 장치 화면에서 인식된다. 예를 들어 일부 AR 헤드셋은 카메라 피드스루(feedthrough)로 설계되어 사용자의 눈 앞에 위치한 디스플레이 장치에 사용자 주변 환경의 카메라 이미지를 표시한다. Examples herein refer to augmented reality (AR). As used herein, AR refers to a user experience in which a computer system comprising at least one virtual aspect and at least one real aspect facilitates sensory perception. AR can be delivered on many types of computer systems, including but not limited to wearable devices. AR headset as used herein refers to any computer system that facilitates AR. AR headsets may include, but are not limited to, AR glasses, other wearable AR devices, tablets or laptop computers. In some types of AR, users can perceive aspects of reality directly with their senses without the mediation of a computer system. For example, some AR headsets are designed to transmit images to the user's retina (e.g., virtual aspects to perceive) while allowing the eye to register other light not generated by the AR headset. As another example, with an in-lens microphone, the display can be built into the see-through lens or the projected display can be overlaid on the see-through lens. In other types of AR, a computer system may enhance, supplement, alter, and/or enable a user's exposure to reality (eg, the actual aspect to be perceived) in one or more ways. In some implementations, AR is recognized on the screen of a computer system's display device. For example, some AR headsets are designed with camera feedthroughs, displaying camera images of the user's surroundings on a display device positioned in front of the user's eyes.
여기의 예는 AR 헤드셋에 의해 검출되는 제스처를 나타낸다. 본 명세서에서 사용되는 바와 같이, 제스처의 검출은 AR 헤드셋이 사용자로부터의 입력을 인식할 수 있는 모든 방법을 포함한다. 제스처에는 시각적으로 검출된 신체 부위(예: 손, 손가락 또는 팔)의 모션; 가속도계 또는 기타 관성 측정 장치에 의해 검출된 신체 부위(예: 머리)의 움직임; 또는 제어기(예: 핸드헬드 제어기)를 사용하여 만들고 AR 헤드셋에서 검출한 입력이 포함될 수 있지만 이에 국한되지는 않는다. Examples here represent gestures detected by an AR headset. As used herein, gesture detection includes any method by which an AR headset may recognize input from a user. Gestures include motion of visually detected body parts (eg, hands, fingers, or arms); movement of a body part (eg head) detected by an accelerometer or other inertial measurement device; or inputs made using a controller (e.g., a handheld controller) and detected by an AR headset.
여기의 예는 문서를 참조한다. 본 명세서에서 사용되는 바와 같이, 문서는 매체 내의 정보이다. 예를 들어, 전자 문서는 디지털 형식(예: 저장 매체에 있는 컴퓨터 판독 가능 파일)의 정보를 의미한다. 다른 예로, 하드카피 문서는 인쇄된 정보(예: 종이에 인쇄된 정보)를 말한다. 또 다른 예로, 온스크린 프리젠테이션은 디스플레이 장치에 표시되는 정보를 말한다. 여기에서 예는 문서의 유형 인스턴스(tangible instance)를 나타낸다. 본 명세서에서 사용되는 바와 같이, 문서의 유형 인스턴스는 인간에 의해 인식될 수 있는(그리고 아마도 이해될 수 있는) 형태의 문서의 임의의 실시예를 포함한다. 본 명세서에서 사용되는 바와 같이, 문서의 유형 인스턴스는 적어도 문서의 하드카피 또는 문서의 온스크린 프리젠테이션을 포함한다. 유형 인스턴스가 본질적으로 문서와 동일한 경우 유형 인스턴스는 문서에 해당할 수 있다. 예를 들어 유형 인스턴스가 문서에서 생성된 경우 유형 인스턴스는 문서에 해당한다. See the documentation for an example here. As used herein, a document is information in a medium. For example, electronic document means information in digital form (eg, a computer-readable file on a storage medium). As another example, a hard copy document refers to printed information (eg, information printed on paper). As another example, on-screen presentation refers to information displayed on a display device. Here, examples represent tangible instances of documents. As used herein, a type instance of a document includes any embodiment of a document in a form perceivable (and possibly comprehensible) by humans. As used herein, a tangible instance of a document includes at least a hard copy of the document or an on-screen presentation of the document. A type instance may correspond to a document if the type instance is essentially the same as a document. For example, if a type instance is created from a document, then the type instance corresponds to the document.
여기에서 예는 문서의 내용(콘텐츠)을 나타낸다. 여기에서 사용된 내용은 문서 정보의 일부 또는 전부를 포함한다. Here, the example represents the contents (contents) of the document. The content used herein includes part or all of document information.
여기서의 예는 문서의 내용을 사용하여 해시를 생성하는 것을 말한다. 본 명세서에서 사용되는 바와 같이, 해시를 생성하거나 문서를 해시하는 것은 식별 목적을 위해 문서의 사실상 고유한 표현을 생성하는 모든 방법을 포함한다. 해시는 검증자에게 개인 정보나 민감한 정보를 전달하지 않고 두 개 이상의 문서가 서로 일치하는지 확인하는 데 사용할 수 있다(예: 문서가 사실상 동일함). 일부 해시 형식에서는 텍스트의 일부를 선택할 수 있다. 일정한 간격의 문자나 단어를 선택하여 문서를 해시할 수 있다. 일부 구현에서 단어의 n-그램(n-grams)을 식별할 수 있으며 (n은 1보다 큰 정수임), n-그램의 모든 m번째 단어를 해시로 선택하여 단어 문자열(word string)을 형성할 수 있다(m은 1보다 크고 n보다 작거나 같은 정수임). 예를 들어, 문서의 텍스트에서 다른 모든 단어를 선택하여 여러 단어 문자열을 각각 생성할 수 있다. 해시에 대해 선택된 단어는 개인 정보 또는 기타 민감한 정보를 구성하는 단어를 선택하지 않도록 적어도 하나의 사전에서 조회할 수 있다. 일부 구현에서는 특정 위치의 텍스트 문자를 해시로 선택할 수 있다. 예를 들어, 모든 텍스트 줄의 제1 문자를 사용할 수 있다. 일부 구현에서는 문서에 대한 디지털 정보를 해시로 변환할 수 있다. 예를 들어, 문서의 광학 문자 인식(OCR)은 디지털 비트로 변환(예: 압축)될 수 있으며 디지털 정보의 하위 부분(sub-portion)이 선택될 수 있다. 일부 구현에서 해시는 문서의 토포그래피(topography)를 기반으로 할 수 있다. 예를 들어 해시는 문서 내용의 모양, 배치, 방향 및/또는 구성을 기반으로 할 수 있다. 일부 구현에서, 해시는 텍스트의 배열 또는 텍스트의 서체와 관련된 하나 이상의 특성에 적어도 부분적으로 기초할 수 있다. 예를 들어, 글꼴 또는 글꼴 패밀리, 글꼴 크기, 문자 간격, 단어 간격 및/또는 줄 높이와 같은 글리프 간격(glyph spacing)을 사용할 수 있다. 일부 구현에서는 나중에 문서에서 수행되는 사소한 변경에 대해 더 로버스트(robust)한 소위 "lazy hash"를 수행할 수 있다. 예를 들어 해시는 문서의 일부 내용에만 선택적으로 적용할 수 있다. 일부 구현에서, 문서의 해시는 문서 내용의 핑거프린트(fingerprint)를 포함할 수 있다. 한 문서에 대해 생성된 해시는 문서 중 하나가 다른 문서의 복사본이 아닌 한 다른 문서에서 생성된 해시와 충돌할 가능성이 거의 없어야 한다. 예를 들어, 두 개의 관련 없는 문서가 충돌하는 해시를 가질 가능성은 약 1조분의 1 수준일 수 있다. The example here is using the contents of a document to create a hash. As used herein, generating a hash or hashing a document includes any method that creates a substantially unique representation of a document for identification purposes. Hashes can be used to verify that two or more documents match each other (i.e. documents are effectively identical) without passing any personal or sensitive information to the verifier. Some hash formats allow you to select parts of text. You can hash a document by selecting evenly spaced characters or words. In some implementations, n -grams of words can be identified (where n is an integer greater than 1), and a word string can be formed by selecting every mth word of the n-grams as a hash. (m is an integer greater than 1 and less than or equal to n). For example, you can create multiple word strings each by selecting every other word in the text of the document. The words selected for the hash can be looked up in at least one dictionary to avoid selecting words that constitute personal or other sensitive information. Some implementations may choose a text character at a specific position as a hash. For example, you can use the first character of every text line. Some implementations may convert digital information about a document into a hash. For example, Optical Character Recognition (OCR) of a document can be converted (eg, compressed) into digital bits and a sub-portion of digital information can be selected. In some implementations, the hash can be based on the document's topography. For example, hashes can be based on the shape, placement, orientation, and/or composition of document content. In some implementations, the hash can be based at least in part on one or more characteristics related to the arrangement of the text or the font of the text. For example, glyph spacing such as font or font family, font size, character spacing, word spacing, and/or line height may be used. Some implementations may perform a so-called "lazy hash" that is more robust to minor changes made to the document later. For example, hashes can be selectively applied to only parts of the content of a document. In some implementations, the hash of the document can include a fingerprint of the document content. A hash generated for one document should be unlikely to collide with a hash generated from another document, unless one of the documents is a copy of another document. For example, the odds of two unrelated documents having colliding hashes may be on the order of 1 in 1 trillion.
여기의 예는 난독화 콘텐츠(obfuscation content)를 나타낸다. 본 명세서에서 사용되는 바와 같이, 난독화 콘텐츠는 문서의 해시와 결합된 문서에서 유래하지 않은 콘텐츠이다. 일부 구현에서 난독화 콘텐츠는 식별할 수 있는 의미가 결여된 콘텐츠(예: 넌센스 텍스트 또는 기타 문자 또는 기호)이다. 난독화 콘텐츠는 해시에 포함되어 누군가에게 해시를 전송하여 개인 정보 또는 민감한 정보를 공개할 가능성을 사실상 제거할 수 있다. 일부 구현에서 해시는 문서에서 단어 문자열을 선택(예: 해당 단어 문자열 길이에 도달할 때까지 다른 모든 단어를 선택함으로써)하는 것과 관련된다. 그런 다음 난독화 콘텐츠에는 문서에서 발생하지 않는 동일한 길이의 단어 문자열이 포함될 수 있다. 예를 들어 난독화 단어 문자열에는 사전에서 임의로 선택한 단어가 포함될 수 있다. 일부 구현에서, 해시는 특정 비율의 난독화 콘텐츠를 포함할 수 있다. 예를 들어, 문서에서 가져온 단어 문자열이 12개 미만인 경우 약 100개 이상의 난독화 콘텐츠 단어 문자열이 해시에 포함될 수 있다.The example here represents obfuscation content. As used herein, obfuscated content is content that does not originate from a document combined with a hash of the document. In some implementations, obfuscated content is content that lacks discernible meaning (eg, nonsense text or other characters or symbols). Obfuscated content can be included in a hash, virtually eliminating the possibility of revealing private or sensitive information by sending the hash to someone. In some implementations, hashes involve selecting a word string from a document (eg, by selecting all other words until that word string length is reached). Obfuscated content can then contain strings of words of the same length that do not occur in the document. For example, a string of obfuscated words may contain words randomly selected from a dictionary. In some implementations, the hash may contain a certain percentage of obfuscated content. For example, if there are fewer than 12 word strings from a document, the hash may contain about 100 or more obfuscated content word strings.
여기에서 예시는 문서들의 컬렉션을 위한 협업 프로그램(collaboration program)을 나타낸다. 본 명세서에서 사용되는 바와 같이, 협업 프로그램은 복수의 컴퓨터 시스템이 문서들의 컬렉션의 동일한 문서(들)에 동시에 액세스할 수 있게 한다. 일부 구현에서 협업 프로그램은 사용자가 실시간으로 파일(들)에 대해 다른 사용자와 협업하면서 온라인에서 하나 이상의 파일을 생성, 보기 및 편집할 수 있도록 한다. 예를 들어 협업 프로그램은 워드 프로세싱, 스프레드시트(spreadsheet) 작업 및/또는 슬라이드 프레젠테이션(slide presentations)용으로 설계할 수 있다. The example here represents a collaboration program for a collection of documents. As used herein, a collaboration program allows multiple computer systems to simultaneously access the same document(s) of a collection of documents. In some implementations, a collaboration program allows a user to create, view, and edit one or more files online while collaborating with other users on the file(s) in real time. For example, collaboration programs can be designed for word processing, spreadsheet work, and/or slide presentations.
여기서의 예는 컴퓨터 시스템의 전자 문서에 대한 액세스 권한을 나타낸다. 본 명세서에서 사용되는 바와 같이, 사용자가 적어도 문서의 유형 인스턴스를 인식할 수 있도록 컴퓨터 시스템에 대한 충분한 자격 증명을 가지고 있는 경우 사용자는 전자 문서에 대한 액세스 권한을 갖는다. The examples here represent access rights to electronic documents in a computer system. As used herein, a user has access to an electronic document if the user has sufficient credentials on the computer system to be able to recognize at least a tangible instance of the document.
여기서의 예는 브라우저를 나타낸다. 본원에 사용된 바와 같이, 브라우저는 정보, 브라우저 확장, 및/또는 이들의 임의의 적합한 조합을 검색하고 표시할 수 있는 소프트웨어 애플리케이션을 말한다. 브라우저는 URL(Uniform Resource Locator)을 사용하여 문서(예: 협업 프로그램의 문서)의 콘텐츠를 검색한 다음 문서의 적어도 일부를 사용자에게 제공할 수 있다. The example here represents a browser. As used herein, a browser refers to a software application capable of retrieving and displaying information, browser extensions, and/or any suitable combination thereof. A browser can use a Uniform Resource Locator (URL) to retrieve the contents of a document (eg, a document in a collaboration program) and then present at least part of the document to the user.
여기의 예는 스크린 공유 애플리케이션을 나타낸다. 본 명세서에서 사용되는 바와 같이, 스크린 공유 애플리케이션은 하나의 컴퓨터 시스템이 실질적으로 실시간으로 다른 컴퓨터 시스템의 스크린에서 자신의 현재 스크린 콘텐츠의 적어도 일부를 제시할 수 있게 해주는 소프트웨어이다. 한 가지 예를 들자면 스크린 공유 애플리케이션이 화상 회의 애플리케이션에 포함될 수 있다. The example here represents a screen sharing application. As used herein, a screen sharing application is software that enables one computer system to present at least a portion of its current screen content on the screen of another computer system in substantially real time. As one example, a screen sharing application could be incorporated into a video conferencing application.
도 1은 컴퓨터 시스템(100)의 예를 도시한다. 컴퓨터 시스템(100)은 본 문서의 다른 곳에서 설명된 하나 이상의 다른 예와 함께 사용될 수 있다. 컴퓨터 시스템(100)은 컴퓨터 판독 가능 매체에 저장된 적어도 하나의 프로세서 실행 명령어를 갖도록 설계될 수 있다. 예를 들어, 컴퓨터 시스템(100)은 도 11을 참조하여 아래에서 설명되는 컴포넌트의 일부 또는 전부를 포함할 수 있다. 1 shows an example of a computer system 100 . Computer system 100 may be used with one or more other examples described elsewhere herein. Computer system 100 may be designed to have at least one processor executable instructions stored on a computer readable medium. For example, computer system 100 may include some or all of the components described below with reference to FIG. 11 .
일부 구현에서, 컴퓨터 시스템(100)은 클라이언트 역할에서 수행하는 것으로 및/또는 클라이언트 측에서 구현되는 것으로 특징지어질 수 있다. 예를 들어, 컴퓨터 시스템(100)은 유형의 문서 인스턴스를 검출하고 이들의 해시를 서버에 제공하는 AR 헤드셋(예를 들어, AR 안경 세트 또는 다른 AR 장치)일 수 있다. 일부 구현에서, 컴퓨터 시스템(100)은 서버 역할에서 수행하는 것으로 및/또는 서버 측에서 구현되는 것으로 특징지어질 수 있다. 예를 들어, 컴퓨터 시스템(100)은 수신된 해시에 기초하여 검색을 수행할 수 있으며; 서버가 일치하는 항목을 찾으면 클라이언트에 추가 정보를 제공할 수 있다. In some implementations, computer system 100 may be characterized as performing in a client role and/or as being implemented on the client side. For example, computer system 100 may be an AR headset (eg, a set of AR glasses or other AR device) that detects tangible document instances and provides hashes of them to a server. In some implementations, computer system 100 may be characterized as performing in a server role and/or being implemented on the server side. For example, computer system 100 may perform a search based on the received hash; When the server finds a match, it can provide additional information to the client.
컴퓨터 시스템(100)은 입력 장치(102)를 포함한다. 일부 구현에서, 입력 장치(102)는 키보드 또는 다른 버튼, 마우스, 터치스크린, 하나 이상의 센서, 핑거프린트 판독기, 스캐너, 카메라 또는 기타 이미지 센서, 광학 장치, 마이크로폰, 시선 추적 컴포넌트, 관성 측정 장치 및/또는 GPS(Global Positioning System) 센서를 포함할 수 있다. 카메라는 문서의 유형 인스턴스의 뷰를 캡처하고 그 내용(콘텐츠)을 검출하는 데 사용할 수 있다. 터치스크린은 사용자가 여기에 설명된 입력을 생성하도록 허용할 수 있다. 마이크로폰를 통해 사용자는 작업을 수행하거나 문서를 변경하는 것과 같은 음성 명령을 입력할 수 있다. 시선 추적 컴포넌트는 AR 헤드셋이 사용자가 현재 보고 있는 곳(예: 문서 참조)을 결정할 수 있게 한다. 관성 측정 유닛은 (예를 들어, 다른 컴퓨터 시스템에 대한 근접성을 검출하기 위해) 컴퓨터 시스템(100)이 이동되고 있는지를 검출할 수 있다. GPS 센서는 (예를 들어, 다른 컴퓨터 시스템의 존재를 결정하기 위해) 컴퓨터 시스템(100)의 위치를 검출할 수 있다. Computer system 100 includes an input device 102 . In some implementations, input device 102 may include a keyboard or other buttons, a mouse, a touch screen, one or more sensors, a fingerprint reader, a scanner, a camera or other image sensor, an optical device, a microphone, an eye tracking component, an inertial measurement device, and/or Alternatively, a Global Positioning System (GPS) sensor may be included. A camera can be used to capture a view of a type instance of a document and detect its contents (content). A touchscreen may allow a user to generate input as described herein. The microphone allows users to input voice commands, such as performing tasks or changing documents. The eye-tracking component allows the AR headset to determine where the user is currently looking (e.g. to see a document). The inertial measurement unit may detect if computer system 100 is moving (eg, to detect proximity to another computer system). A GPS sensor may detect the location of computer system 100 (eg, to determine the presence of other computer systems).
컴퓨터 시스템(100)은 출력 장치(104)를 포함할 수 있다. 출력 장치(104)는 디스플레이 장치, 레티나 프로젝터(retina projector), 촉각 컴포넌트(tactile component) 및/또는 스피커를 포함할 수 있다. 디스플레이 장치 및/또는 레티나 프로젝터는 사용자가 인지할 가상의 모습을 제공할 시각적 출력을 생성하는 역할을 할 수 있다. 예를 들어 하나 이상의 문서, 문서 편집, 제어(컨트롤), 페이지, 윈도우 및/또는 데스크탑이 표시될 수 있다. 스피커는 예를 들어 텍스트 TTS(text-to-speech) 애플리케이션에 의해 생성된 오디오 출력을 제공하는 역할을 할 수 있다. Computer system 100 may include an output device 104 . The output device 104 may include a display device, a retina projector, a tactile component, and/or a speaker. A display device and/or a retina projector may serve to generate visual output to provide a virtual appearance to be perceived by a user. For example, one or more documents, document edits, controls (controls), pages, windows and/or desktops may be displayed. The speaker may serve to provide audio output generated by, for example, a text-to-speech (TTS) application.
컴퓨터 시스템(100)은 적어도 하나의 스토리지(저장소)(106)를 포함할 수 있다. 저장소(106)는 매핑 기능; AR 컴포넌트; 서류; 해시; 적어도 한 명의 사용자에 대한 사용자 식별 기록; 최소 한 명의 사용자에 대한 액세스 권한; 콘텐츠를 해시하는 해시 컴포넌트; 난독화 콘텐츠를 생성하기 위한 난독화 콘텐츠 컴포넌트; 해시에 난독화 콘텐츠를 포함하는 해시 결합기; 둘 이상의 해시를 비교하기 위한 해시 비교기; 문서들의 컬렉션을 위한 협업 프로그램; 문서 편집 프로그램(예: 비협업 문서용); 브라우저; 스크린 공유 프로그램(예: 화상 회의 애플리케이션의 일부); OCR 프로그램; 제스처 인식 프로그램; 및/또는 TTS 서비스 애플리케이션을 포함할 수 있다. Computer system 100 may include at least one storage (repository) 106 . Repository 106 includes a mapping function; AR component; document; hash; user identification records for at least one user; access to at least one user; a hash component that hashes the content; an obfuscated content component for generating obfuscated content; a hash combiner that includes the obfuscated content in the hash; a hash comparator for comparing two or more hashes; collaboration program for collection of documents; Document editing programs (eg for non-collaborative documents); browser; screen sharing programs (eg, part of a video conferencing application); OCR program; gesture recognition program; and/or a TTS service application.
예를 들어, 매핑 기능은 본 명세서에 기술된 바와 같이 일부 또는 모든 동작을 수행하도록 프로그래밍될 수 있다(예: 유형 인스턴스와 전자 문서 간의 링크 제공 및/또는 둘 이상의 유형 인스턴스 간의 링크 제공).For example, a mapping function may be programmed to perform some or all operations as described herein (eg, provide a link between a type instance and an electronic document and/or provide a link between two or more type instances).
다른 예로, AR 컴포넌트는 여기에 설명된 일부 또는 모든 예에 따라 작동하도록 프로그래밍될 수 있다(예: 콘텐츠 캡처 및/또는 매핑을 기반으로 정보를 전송, 수신 또는 표시).As another example, an AR component may be programmed to operate according to some or all of the examples described herein (eg, transmit, receive, or display information based on content capture and/or mapping).
다른 예로서, 문서는 컴퓨터 시스템(100)에 의해 캡처(예를 들어, 스캔)될 수 있고 및/또는 다른 컴퓨터 시스템으로부터 수신될 수 있다. As another example, a document may be captured (eg, scanned) by computer system 100 and/or received from another computer system.
다른 예로서, 해시는 컴퓨터 시스템(100)에 의해 생성될 수 있고 및/또는 다른 컴퓨터 시스템으로부터 수신될 수 있다.As another example, a hash may be generated by computer system 100 and/or received from another computer system.
다른 예로서, 사용자 식별 기록은 사용자가 누구인지 지정하고 및/또는 사용자와 관련된 하나 이상의 다른 컴퓨터 시스템을 식별할 수 있다.As another example, the user identification record may designate who the user is and/or identify one or more other computer systems associated with the user.
다른 예로서, 액세스 권한은 사용자가 컴퓨터 시스템(100) 또는 다른 컴퓨터 시스템에서 전자 문서에 액세스하도록 허용되는지 여부를 지정할 수 있다.As another example, access rights may specify whether a user is allowed to access an electronic document on computer system 100 or another computer system.
또 다른 예로서, 해시 컴포넌트는 개인 정보나 민감한 정보가 노출되는 것을 방지하기 위해 문서의 내용을 해시할 수 있다. As another example, a hash component can hash the contents of a document to prevent exposing private or sensitive information.
또 다른 예로서, 난독화 콘텐츠 컴포넌트는 개인 정보나 민감한 정보가 노출되는 것을 피하기 위해 문서 콘텐츠와 관련 없는 콘텐츠를 생성할 수 있다. As another example, an obfuscated content component can generate content unrelated to document content to avoid exposing personal or sensitive information.
또 다른 예로서, 해시 결합기(hash combiner)는 해시된 콘텐츠를 난독화 콘텐츠와 결합하여 개인 정보나 민감한 정보가 노출되는 것을 방지하는 해시를 생성할 수 있다. As another example, a hash combiner can combine hashed content with obfuscated content to generate a hash that prevents personal or sensitive information from being exposed.
다른 예로, 해시 비교기는 두 개 이상의 해시가 해당 문서와 관련이 있는지 여부를 결정할 수 있다. As another example, a hash comparator can determine whether more than one hash is associated with a given document.
다른 예로, 협업 프로그램은 컴퓨터 시스템(100)의 사용자와 별도의 컴퓨터 시스템의 다른 사용자가 동시에 전자 문서에 접근하여 편집할 수 있도록 할 수 있다. As another example, the collaboration program may allow a user of the computer system 100 and another user of a separate computer system to simultaneously access and edit an electronic document.
다른 예로, 문서 편집 프로그램은 컴퓨터 시스템(100)의 사용자가 협업 프로그램과 별개로 문서를 편집하도록 할 수 있다.As another example, the document editing program may allow the user of the computer system 100 to edit the document separately from the collaboration program.
다른 예로서, 브라우저는 컴퓨터 시스템(100)의 사용자가 문서를 보고 및/또는 컴퓨터 시스템(100)에 로컬이거나 원격 위치에서 프로그램을 실행할 수 있도록 허용할 수 있다. As another example, a browser may allow a user of computer system 100 to view documents and/or run programs from a location local to or remote to computer system 100 .
또 다른 예로서, 스크린 공유 프로그램은 컴퓨터 시스템(100)의 사용자가 다른 컴퓨터 시스템에서 공유된 유형의 문서 인스턴스를 볼 수 있게 하고/하거나 그러한 다른 컴퓨터 시스템과 문서의 유형 인스턴스를 공유하도록 할 수 있다.As another example, a screen sharing program may allow a user of computer system 100 to view instances of a document of a type shared on other computer systems and/or to share instances of a type of document with such other computer systems.
또 다른 예로, OCR 프로그램은 문서의 유형 인스턴스에서 콘텐츠를 캡처할 수 있다. As another example, an OCR program can capture content from a type instance of a document.
다른 예로서, 제스처 인식 프로그램은 AR 헤드셋을 제어하기 위해 컴퓨터 시스템(100)의 사용자 또는 신체의 일부의 위치를 추적할 수 있다.As another example, a gesture recognition program may track the location of a user or body part of computer system 100 to control an AR headset.
다른 예로서, TTS 서비스 애플리케이션은 문서의 내용(예를 들어, 전자 문서 또는 그 유형 인스턴스로부터)에 기초하여 컴퓨터 시스템(100)의 사용자에게 음성 출력을 제공할 수 있다. As another example, a TTS service application may provide audio output to a user of computer system 100 based on the content of a document (eg, from an electronic document or tangible instance thereof).
컴퓨터 시스템(100)은 컴퓨터 시스템(100)과 하나 이상의 다른 시스템 및/또는 장치 사이의 통신을 허용하는 적어도 하나의 네트워크 인터페이스(108)를 포함할 수 있다. 네트워크 인터페이스(108)는 무선 및/또는 유선 통신을 위해 구성될 수 있다. 예를 들어, 네트워크 인터페이스(108)는 대응하는 문서를 검색하기 위한 통신을 용이하게 할 수 있다. 다른 예로서, 네트워크 인터페이스(108)는 컴퓨터 시스템(100)과 연관된(예를 들어, 근처에 있는) 컴퓨터 시스템의 검출을 용이하게 할 수 있다.Computer system 100 may include at least one
도 2는 도 1의 컴퓨터 시스템(100)의 저장소(200)의 예를 도시한다. 저장소(200)는 본 명세서의 다른 곳에서 설명된 하나 이상의 다른 예와 함께 사용될 수 있다. 예를 들어, 저장소(200)는 도 1의 저장소(106)의 일부 또는 모든 컴포넌트를 포함할 수 있다. FIG. 2 illustrates an example of
저장소(200)는 N개의 문서(202)를 포함하고, 여기서 N은 임의의 정수이다. 여기서, 문서(202)는 각각 문서(202-1), 문서(202-2, …) 및 문서(202-N)로서 개략적으로 도시되어 있다. 각각의 문서(202)는 하나 이상의 버전(204)으로 존재할 수 있다. 여기서, 각각의 문서(202)는 각각 버전(204-1), 버전(204-2), 버전(204-3), ... 및 버전(204-M)을 갖는 것으로 개략적으로 도시되며, 여기서 M은 임의의 정수이다. 예를 들어, 문서(202) 중 하나가 변경된 경우, 변경사항은 문서의 기존 버전에 통합되거나 변경사항이 포함된 문서가 이전 문서의 새 버전으로 간주되거나 새 문서가 생성될 수 있다. 버전 관리를 위한 다른 접근 방식을 사용할 수 있다. 일부 구현에서, 협업 프로그램을 제어하는 서버는 사용자가 문서(202)를 사용할 수 있도록 한다.
저장소(200)는 P개의 해시(206)를 포함하며, P는 임의의 정수이다. 여기서, 해시(206)는 각각 해시(206-1), 해시(206-2), 해시(206-3), … 및 해시(206-P)로 개략적으로 도시되어 있다. 일부 구현에서, 하나 이상의 해시(206)는 유형의 문서 인스턴스에 기초하여 생성될 수 있다. 해시는 다른 문서가 해시의 기반이 되는 문서에 해당하는지 여부를 결정하기 위해 다른 컴퓨터 시스템(예: 서버)에 제공될 수 있다. 다른 예로, 컴퓨터 시스템(예: 서버)은 발견된 문서의 해시를 생성하고 해시를 다른 컴퓨터 시스템에 제공하여 다른 컴퓨터 시스템(예: 클라이언트)이 발견된 문서가 다른 컴퓨터 시스템에 있는 유형의 문서 인스턴스에 해당하는지 확인할 수 있도록 한다.
다음 예는 여기에 설명된 대로 문서 매핑을 사용하여 AR 경험 및 기타 문서 공동 작업을 개선하는 것과 관련된다. 도 3a-3f는 문서의 유형 인스턴스와 관련된 예를 보여준다. 유형 인스턴스에 관한 모든 예는 여기의 다른 곳에서 설명된 하나 이상의 다른 예와 함께 사용될 수 있다. 일부 구현에서 유형 인스턴스는 하드카피 또는 온스크린 프리젠테이션일 수 있다. 이 문서에는 텍스트가 포함되어 있으며, 여기서는 단순성을 위해 유형 인스턴스에서 플레이스홀더 라틴어 텍스트(placeholder Latin text)로 표시된다. 문서는 유형 인스턴스에 의해 현재 반영된 것보다 더 길 수 있다(예: 더 많은 콘텐츠 포함). The following examples relate to using document mapping as described here to improve AR experiences and other document collaboration. 3a-3f show examples involving type instances of documents. Any example of a type instance may be used in conjunction with one or more of the other examples described elsewhere herein. In some implementations, type instances may be hardcopy or on-screen presentations. This document contains text, here shown as placeholder Latin text in the type instance for simplicity. A document may be longer than currently reflected by the type instance (eg contain more content).
도 3a에서, 유형 인스턴스(300)는 사용자에 의해 인식된다. AR FOV(302)는 여기서 점선 원을 사용하여 개략적으로 표현된다. 일부 구현에서, 유형 인스턴스(300)에 위치된 사용자는 AR FOV(302)를 정의하는 AR 헤드셋을 착용하고 있다. 여기서, 사용자는 AR FOV(302) 내외 모두에서 유형 인스턴스(300)를 볼 수 있고, AR FOV(302) 내에서 여기서는 제어(컨트롤)(304)인 가상 에스펙트를 인지할 수 있다. 현재 AR FOV(302) 내에 있는 문서의 콘텐츠는 AR 헤드셋의 컴퓨터 시스템에서 볼 수 있고 따라서 처리 가능할 수 있다. 예를 들어, AR 헤드셋은 AR FOV(302) 내에 있는 콘텐츠에 기초하여 유형 인스턴스(300)의 콘텐츠(예를 들어, 텍스트)를 검출할 수 있다. 예를 들어, AR 헤드셋은 디스플레이 장치를 포함한다. AR 헤드셋은 예를 들어 유형 인스턴스를 캡처하기 위한 카메라를 포함할 수 있다. 선택적으로 카메라로 캡처한 이미지를 AR 헤드셋의 디스플레이 장치에 표시할 수 있다. 대안적으로 또는 추가로 가상 콘텐츠가 AR 헤드셋의 디스플레이 장치에 표시될 수 있다. 예를 들어, AR 헤드셋의 디스플레이 장치는 유형 인스턴스에 대해 변위 가능하다. 예를 들어, 사용 중에 AR 헤드셋의 디스플레이 장치는 사용자의 눈 중 하나 또는 둘 다와 AR FOV(302)에 있는 유형 인스턴스 사이에 배열될 수 있다. In FIG. 3A, a
제어(컨트롤)(304)는 AR 헤드셋의 컴퓨터 시스템에 의해 생성된다. 컨트롤(304)은 사용자가 유형 인스턴스(300)의 매핑을 트리거하도록 허용할 수 있다. 예를 들어, 그러한 매핑은 유형 인스턴스(300)에 대응할 수 있는(예를 들어, 출처일 수 있는) 임의의 전자 문서를 검색하기 위해 수행될 수 있다. 또 다른 예로, 동일한 문서의 다른 유형 인스턴스를 검색하기 위해 이러한 매핑을 수행할 수 있다. Control (control) 304 is generated by the AR headset's computer system.
개인 정보나 기타 민감한 정보를 위험에 빠뜨리지 않고 매핑을 수행할 수 있다. 유형 인스턴스(300)와 관련하여 서버에 접촉하기 전에, 유형 인스턴스(300) 콘텐츠의 해시가 생성될 수 있으며, 해시는 난독화 콘텐츠도 포함한다. 사용자는 AR FOV(field of view)(302) 내에서 제스처를 수행함으로써(예를 들어, 손이나 손가락으로) 또는 AR 헤드셋의 전용 입력 기능을 통해 컨트롤(304)을 활성화할 수 있다. 즉, 컨트롤(304)의 사용자 활성화는 AR 헤드셋이 민감한 정보를 포함하지 않는 유형 인스턴스(300)와 관련된 해시(예를 들어, 그 해시 및 난독화 콘텐츠)만을 서버로 전송하게 한다. Mapping can be done without risking personal or other sensitive information. Prior to contacting the server with respect to the
AR 헤드셋이 보낸 유형 인스턴스(300)의 해시를 수신한 서버는 하나 이상의 검색에서 해시를 사용할 수 있다. 일부 구현에서 서버는 협업 프로그램과 관련된 문서들의 컬렉션을 검색한다. 검색에 포함할 문서 컬렉션의 범위는 사용자의 액세스 권한을 기반으로 정의할 수 있다. 예를 들어 사용자에게 액세스 권한이 있는 문서만 검색에 포함된다. 또 다른 예로, 검색에는 공개적으로 액세스할 수 있는 문서(예: 인터넷에서 누구나 사용할 수 있는 문서) 및 사용자와 명시적으로 공유된 문서가 포함된다. 검색은 각각의 검색 히트(search hit)가 유형 인스턴스(300)에 대응하는 문서라는 서버의 신뢰도 레벨에 따라 2개 이상의 검색 히트의 순위를 매기(랭킹화)는 것을 수반할 수 있다. 예를 들어 해시가 문서의 충분히 고유한 표현인 경우, 검색은 해당 문서가 서버에 있는 경우 하나의 히트를 생성하거나 해당 문서가 서버에 존재하지 않는 경우 히트를 생성하지 않을 수 있다. Upon receiving the hash of
서버는 해시 수신에 대한 응답을 생성하고 AR 헤드셋에 응답을 보낼 수 있다. 응답은 해시 기반 검색에서 발견된 적어도 하나의 문서에 대응하는 정보를 포함할 수 있다. 일부 구현에서 서버는 찾은 문서의 자체 해시를 수행할 수 있다. 이러한 해시에는 문서의 해시 생성 및 해시에 난독화 콘텐츠 포함이 포함될 수 있다. 예를 들어, 서버는 AR 헤드셋이 수행한 해시와 동일하거나 다른 종류의 해시(해싱)를 수행할 수 있다. The server may generate a response to receiving the hash and send the response to the AR headset. The response may include information corresponding to at least one document found in the hash-based search. In some implementations, the server may perform its own hash of the document it finds. These hashes can include generating hashes of documents and including obfuscated content in hashes. For example, the server may perform the same or a different kind of hash (hashing) than the hash performed by the AR headset.
위의 예는 컴퓨터로 구현되는 방법이, 제1 컴퓨터 시스템(예를 들어, AR 헤드셋)에 의해, 제1 문서의 유형 인스턴스(예를 들어, 유형 인스턴스(300))의 제1 콘텐츠(예를 들어, AR FOV(302) 내의 콘텐츠)를 검출하는 단계; (예를 들어, 제어(컨트롤)(304)의 활성화에 응답하여) 제1 컴퓨터 시스템에 의해, 제1 콘텐츠를 사용하여 제1 해시를 생성하는 단계 -제1 해시는 제1 난독화 콘텐츠를 포함함-; 제1 컴퓨터 시스템에 의해, 제2 컴퓨터 시스템(예를 들어, 서버)에 의한 수신을 위한 제1 해시를 전송하는 단계; 그리고 제1 컴퓨터 시스템에 의해, 제2 컴퓨터 시스템에 의해 생성된 제1 해시에 대한 응답을 수신하는 단계 -응답은 제1 콘텐츠와 관련된 제2 문서에 대응하는 정보(예를 들어, 서버의 해시)를 포함함-를 포함할 수 있음을 보여준다. In the above example, the first content (eg, type instance 300) of the type instance (eg, type instance 300) of the first document is configured by a first computer system (eg, an AR headset). eg, detecting content within the
서버에 의해 생성된 응답을 수신한 후, AR 헤드셋은 유형 인스턴스(300)와 서버에 의해 발견된 문서 간의 대응관계(예를 들어, 문서가 동일함)를 검증(확인)하기 위해 응답을 사용할 수 있다. 예를 들어 이를 통해 AR 헤드셋은 서버가 해시 기반 검색에서 신뢰할 수 있는 작업을 수행했는지 여부를 측정할 수 있다. AR 헤드셋은 유형 인스턴스(300)에 대해 서버의 해시를 확인할 수 있다. After receiving the response generated by the server, the AR headset may use the response to verify (confirm) the correspondence between the
서버로부터 생성된 응답을 수신한 AR 헤드셋은 유형 인스턴스(300)의 일부 또는 전체 콘텐츠를 서버로 전송할 수 있는 기회를 사용자에게 제공할 수 있다. 도 3b는 AR 헤드셋이 AR FOV(302) 내에서 컨트롤(306)을 제시할 수 있음을 예시한다. 사용자는 AR FOV(302) 내에서 제스처를 수행함으로써(예를 들어, 손 또는 손가락으로) 또는 AR 헤드셋의 전용 입력 기능을 통해 컨트롤(306)을 활성화할 수 있다. 예를 들어, 컨트롤(306)을 활성화하면 AR 헤드셋이 유형 인스턴스(300)의 하나 이상의 캡처된 이미지를 서버로 보낼 수 있다. 다른 예로서, 유형 인스턴스(300)의 텍스트가 전송될 수 있다. 일부 구현에서, 서버는 AR 헤드셋에 의해 제공되는 콘텐츠에 기초하여 새로운 전자 문서 또는 발견된 문서의 새로운 버전을 생성할 수 있다. 일부 구현에서, AR 헤드셋은 유형 인스턴스(300)의 마크업된 변경을 서버로 전송하고, 마크업된 변경은 AR 헤드셋이 유형 인스턴스(300)와 서버에 의해 발견된 문서 사이에서 검출한 차이에 대응한다. Upon receiving the response generated from the server, the AR headset may provide the user with an opportunity to transmit part or all of the contents of the
일부 구현에서 서버는 찾은 문서의 콘텐츠를 AR 헤드셋으로 보낸다. 예를 들어 발견된 문서가 공개적으로 사용 가능한 경우 일반 텍스트로 수행되거나 AR 헤드셋을 대신하여 서버가 확인을 받을 때 수행될 수 있다. 그러한 확인에는 AR 헤드셋의 사용자가 찾은 문서에 대한 액세스 권한이 있다는 확인 및/또는 발견된 문서가 실제로 유형 인스턴스(300)에 대응하고 AR 헤드셋이 발견된 문서에 액세스하기를 원한다는 AR 헤드셋으로부터의 통지가 포함될 수 있다. In some implementations, the server sends the content of the found document to the AR headset. This can be done in plain text, for example, if the found document is publicly available, or when the server receives confirmation on behalf of the AR headset. Such confirmations include confirmation that the user of the AR headset has permission to access the document found and/or notification from the AR headset that the document found actually corresponds to type
도 3c는 AR 헤드셋이 AR FOV(302) 내에서 유형 인스턴스(300)의 가상 애노테이션(virtual annotations)을 제시하는 예를 도시한다. 즉, AR 헤드셋의 사용자에게 제공되는 가상 애노테이션은 현실에 대한 사용자의 뷰(여기서는 유형 인스턴스(300)의 뷰)를 증강시키는 마크업된 변경(marked-up changes)을 포함하는 가상 에스펙트이다. 이 예에서, 가상 애노테이션은 단어의 삭제(308) 및 삭제된 단어 대신 다른 단어의 삽입(310)을 포함한다. 이 예에서, 가상 애노테이션은 또한 유형 인스턴스(300)의 구절의 하이라이트(312) 및 하이라이트된 구절과 관련된 코멘트(314)를 포함한다. 3C shows an example in which an AR headset presents virtual annotations of a
일부 가상 애노테이션은 서버가 유형 인스턴스(300)의 해시를 사용한 검색을 기반으로 찾은 전자 문서에 다른 사용자가 입력한 편집 내용이다. 다른 사용자가 현재 전자 문서의 특정 부분에 초점을 맞추고 있는지 여부를 확인하기 위해 시선 추적을 수행할 수 있다. 여기서, 이러한 다른 사용자의 시선 추적에 기초하여 AR FOV(302)에 시선 표시기(gaze indicator)(316)가 제시될 수 있다. 즉, 이 예에서 서버가 찾은 문서는 협업 프로그램과 연관된 문서들의 컬렉션의 일부였다. 이 예에서 유형 인스턴스(300)는 서버가 나중에 찾을 문서의 라이브 프리젠테이션이 아니라는 점에 유의한다. 오히려, 유형 인스턴스(300)는 단지 두 가지 예를 들자면 그 문서의 하드카피 또는 회의실에서 보여지는 온스크린 프리젠테이션일 수 있다. 대신에, 유형 인스턴스(300)에서 수행된 매핑은 여기서 유형 인스턴스(300)를 인식하고 있던 사용자가 유형 인스턴스(300)에 대응하는 것으로 밝혀진 전자 문서로부터 실시간 가상 업데이트에 액세스할 수 있게 해주었다. Some virtual annotations are edits entered by other users to electronic documents that the server finds based on a search using the hash of the
방금 설명한 시나리오가 아닌 다른 시나리오에서는 서버에서 찾은 문서가 협업 프로그램과 연결된 문서 컬렉션의 일부가 아닐 수 있다. 일부 구현에서, 서버는 AR 헤드셋으로부터 수신된 해시와 다른 컴퓨터 시스템으로부터 수신된 또 다른 해시를 사용하여 검색을 수행하여 문서를 찾았을 수 있다. 예를 들어, 다른 컴퓨터 시스템은 (즉, 유형 인스턴스(300)가 아닌) 다른 유형 인스턴스로부터 콘텐츠를 검출하는 것에 기초하여 해시를 업로드했을 수 있다. 이 두 해시가 서로 대응한다고 서버가 결정하는 것에 기초하여, 서버는 각각의 유형 인스턴스가 서로 대응한다고 간주할 수 있다. 예를 들어, 서버가 유형 인스턴스에 해당하는 전자 문서를 찾지 못한 경우에도 두 유형 인스턴스 간의 매핑이 설정될 수 있다. In scenarios other than those just described, documents found on the server may not be part of the document collection associated with the collaboration program. In some implementations, the server may find the document by performing a search using a hash received from the AR headset and another hash received from another computer system. For example, another computer system may have uploaded a hash based on detecting content from another type instance (ie, other than type instance 300 ). Based on the server's determination that these two hashes correspond to each other, the server may consider each type instance to correspond to the other. For example, a mapping between two type instances may be established even if the server does not find an electronic document corresponding to the type instance.
여기에 설명된 매핑은 버전 관리 및/또는 무단 액세스 검출을 개선할 수 있다. 예를 들어, 유형 인스턴스(300)가 영화 스튜디오에 의해 개발 중인 영화의 미발표 원고라고 가정하자. 유형 인스턴스(300)의 해시는 서버가 영화 원고에 대한 액세스 권한이 없는 사용자가 현재 그것을 보고 있음을 검출할 수 있게 한다. The mappings described herein may improve version control and/or unauthorized access detection. Assume, for example, that
AR 헤드셋을 소지한 사용자는 유형 인스턴스(300)의 편집을 수행할 수 있다. 매핑이 설정되면, 그러한 편집은 예를 들어 이제 설명되는 바와 같이 한 명 이상의 다른 사용자와 공유될 수 있다. 도 3d는 AR 헤드셋을 가지고 있는 사용자가 표현의 삭제(318) 및 삭제된 표현 대신에 다른 표현의 삽입(320)을 표시한 것을 보여준다. AR 헤드셋을 가진 사용자가 입력한 편집은 유형 인스턴스(300)가 하드카피인 경우 펜으로 수행될 수 있고, 유형 인스턴스(300)가 온스크린 프리젠테이션인 경우 전자적으로 수행될 수 있다. AR FOV(302)가 편집이 이루어진 유형 인스턴스(300)의 일부를 포함하는 경우, 편집의 공유가 수행될 수 있다. A user with an AR headset can edit the
편집 내용을 다른 사용자와 공유하는 경우 해당 사용자는 해당 유형 인스턴스와 관련하여 편집 내용을 볼 수 있다. 도 3e-3f는 다른 사용자에 의해 인식되고 있는 유형 인스턴스(300')를 도시한다. 유형 인스턴스(300')는 위의 예에서 해시로 검색하여 서버가 찾은 인스턴스이다. 도 3e에서, 다른 사용자는 현재 유형 인스턴스(300')를 전자 형태로 작업하고 있다. 따라서 다른 사용자는 현재 AR을 인식하지 못할 수 있다. 이 예에서, 다른 사용자가 유형 인스턴스(300')에 대해 만든 애노테이션(주석)에는 삭제(308)(도 3c)에 대응하는 삭제(308'), 삽입(310)(도 3c)에 대응하는 삽입(310'), 하이라이트(312)(도 3c)에 대응하는 하이라이트(312'), 및 코멘트(314)(도 3c)에 대응하는 코멘트(314')가 포함된다. 다른 사용자에 의한 이러한 애노테이션은 유형 인스턴스(300')의 기본이 되는 문서에서 전자적으로 만들어지며 가상 에스펙트이 아니다. 유형 인스턴스(300)를 갖는 사용자에 의해 도 3d에 입력된 하나 이상의 애노테이션은 도 3e의 유형 인스턴스(300')와 관련하여 또한 가시적일 수 있다. 여기서, 그러한 애노테이션은 삭제(318)(도 3d)에 대응하는 삭제(318') 및 삽입(320)(도 3d)에 대응하는 삽입(320')을 포함한다. If you share your edits with other users, those users will be able to see your edits in relation to instances of that type. Figures 3e-3f show a type instance 300' being recognized by another user. The type instance 300' is an instance found by the server by searching with hash in the above example. In Fig. 3e, another user is currently working on the type instance 300' in electronic form. Therefore, other users may not be aware of the current AR. In this example, annotations (annotations) made by other users on type instances 300' include deletions 308' corresponding to deletions 308 (FIG. 3C) and insertions corresponding to insertions 310 (FIG. 3C). 310', highlights 312' corresponding to highlights 312 (FIG. 3C), and comments 314' corresponding to comments 314 (FIG. 3C). These annotations by other users are made electronically in the document underlying the type instance 300' and are not virtual aspects. One or more annotations entered in FIG. 3d by a user having
도 3f에서, 유형 인스턴스(300')는 여기에서 하드카피(예를 들어, 종이 출력물)이다. 유형 인스턴스(300')를 인식하고 있는 다른 사용자는 여기서 유형 인스턴스(300')에 대한 AR FOV(302')를 정의하는 AR 헤드셋을 사용하고 있다. 다른 사용자가 유형 인스턴스(300')에 대해 만든 애노테이션은 삭제(308)(도 3c)에 대응하는 삭제(308''), 삽입(310)(도 3c)에 대응하는 삽입(310''), 하이라이트(312)(도 3c)에 대응하는 하이라이트(312''), 및 코멘트(314)(도 3c)에 대응하는 코멘트(314'')를 포함한다. 다른 사용자에 의한 이러한 애노테이션은 유형 인스턴스(300')인 하드카피에 손으로(예를 들어, 펜 또는 형광펜을 사용하여) 만들어지며 가상 또는 전자적 에스펙트가 아니다.3F, the type instance 300' is here a hard copy (e.g., a paper output). Another user aware of the type instance 300' is using an AR headset here defining an AR FOV 302' for the type instance 300'. Annotations made by other users on type instance 300' include delete 308″ corresponding to delete 308 (FIG. 3C), insert 310″ corresponding to insert 310 (FIG. 3C), highlights 312″ corresponding to highlights 312 (FIG. 3C), and comments 314″ corresponding to comments 314 (FIG. 3C). These annotations by other users are made by hand (eg, using a pen or highlighter) on the hardcopy, type instance 300', and are not virtual or electronic aspects.
도 3d의 애노테이션은 도 3f의 AR FOV(302')에서 제시될 수 있다. 여기서, 그러한 애노테이션은 삭제(318)(도 3d)에 대응하는 삭제(318'') 및 삽입(320)(도 3d)에 대응하는 삽입(320'')을 포함한다. 시선 표시기(322)는 유형 인스턴스(300)(도 3a-3d)를 갖는 사용자의 시선 추적에 기초하여 AR FOV(302')에 제시될 수 있다. The annotations in FIG. 3D may be presented in AR FOV 302' in FIG. 3F. Here, such annotations include
위의 예는 디지털 형식의 문서에 대한 전자적 편집 또는 하드카피에서 수동으로 수행된 편집을 보여준다. 편집, 애노테이션 또는 전자 문서와 관련된 기타 마크업 변경을 입력하는 다른 방법이나 기타 명령을 사용할 수 있다. 일부 구현에서, 오디오 인터페이스는 사용자가 만드는 오디오 입력을 등록하고 전자 문서를 변경하기 위한 음성 명령으로 해석할 수 있다. 도 3e를 참조하여 예를 들어, 삭제 308' 및 삽입 310'을 입력하기 위해 키보드를 사용하는 대신에, 사용자는 "line six, replace dolor with dolore(6행, dolor를 dolore로 대체)"라고 말할 수 있다. The example above shows an electronic edit to a document in digital format or an edit performed manually on a hard copy. You may use other methods or other commands to enter edits, annotations, or other markup changes related to electronic documents. In some implementations, the audio interface can register audio inputs made by the user and interpret them as voice commands to alter the electronic document. Referring to FIG. 3E , for example, instead of using the keyboard to enter delete 308' and insert 310', the user could say "line six, replace dolor with dolore". can
본 명세서에 기술된 바와 같은 매핑은 저시력자를 위한 것과 같은 시각 정보에 대한 접근성을 개선할 수 있다. 예를 들어, 도 3a의 유형 인스턴스(300)를 인식하는 사용자가 콘텐츠에 대한 TTS 서비스를 요청한다고 가정한다. AR 헤드셋이 검출한 유형 인스턴스(300)의 텍스트에 기초하여 TTS 서비스를 수행했다면, TTS 서비스는 음성을 생성할 때 병치된 단락(juxtaposed paragraphs)을 읽는 순서 또는 단락이 끝나고 다음 단락이 시작되는 위치와 같은 문서의 특정 구조적 에스펙트(structural aspects)를 추론해야 할 수 있다. 한편, 유형 인스턴스(300)가 전자 문서에 해당하는 경우, 해당 전자 문서는 TTS 서비스에서 사용할 수 있는 구조 마크업을 포함할 수 있다. 구조 마크업은 하이퍼텍스트 마크업 언어(Hypertext Markup Language)를 포함하지만 이에 제한되지 않는 적절한 마크업 언어에 따른 요소를 포함할 수 있다. TTS 서비스는 유형 인스턴스(300)의 텍스트를 음성으로 더 잘 렌더링하기 위해 전자 문서의 마크업 요소에 의해 반영된 구조적 개념(structural notions)을 참조할 수 있다. Mapping as described herein can improve accessibility to visual information, such as for people with low vision. For example, it is assumed that a user recognizing the
도 4a-4b는 유형 인스턴스(400 및 402) 및 컴퓨터 시스템(404)에 관한 예를 개념적으로 도시한다. 유형 인스턴스(400 및 402) 및 컴퓨터 시스템(404)은 본 문서의 다른 곳에서 설명된 하나 이상의 다른 예와 함께 사용될 수 있다. 4A-4B conceptually illustrate examples of
도 4a에서, 컴퓨터 시스템(404)은 각각의 유형 인스턴스(400 및 402)가 대응하는 전자 문서(406)를 포함한다. 예를 들어, 각각의 유형 인스턴스(400 및 402)는 전자 문서(406)의 하드카피 또는 온스크린 프리젠테이션이다. 컴퓨터 시스템(404)은 유형 인스턴스(400)와 연관된 컴퓨터 시스템으로부터 해시를 수신할 때 전자 문서(406)를 식별했을 수 있으며; 유사하게, 컴퓨터 시스템(404)은 유형 인스턴스(402)와 연관된 컴퓨터 시스템으로부터 해시를 수신할 때 전자 문서(406)를 식별했을 수 있다. 따라서, 각각의 유형 인스턴스(400, 402)는 전자 문서(406)에 매핑되고, 유형 인스턴스(400, 402)는 전자 문서(406)를 통해 서로 간에 링크(408)를 갖는다. 링크(408)는 유형 인스턴스(400, 402) 사이의 어느 한 방향 또는 두 방향으로의 식별 및/또는 정보 전달을 위해 사용될 수 있다. In FIG. 4A ,
도 4b에서, 컴퓨터 시스템(404)은 각각의 유형 인스턴스(400 및 402)가 대응하는 임의의 전자 문서를 반드시 포함하지는 않는다. 여기서, 유형 인스턴스(400)와 연관된 컴퓨터 시스템은 유형 인스턴스(400)의 해시(410)를 컴퓨터 시스템(404)에 제공했다. 유사하게, 유형 인스턴스(402)와 연관된 컴퓨터 시스템은 유형 인스턴스(402)의 해시(412)를 컴퓨터 시스템(404)에 제공했다. 따라서 유형 인스턴스(400)는 해시(410)에 매핑되고, 유형 인스턴스(402)는 해시(412)에 매핑된다. 더욱이, 컴퓨터 시스템(404)은 해시(410 및 412)가 서로 대응한다고 결정할 수 있다(예를 들어, 그것들이 동일하기 때문). 즉, 컴퓨터 시스템(404)은 유형 인스턴스(402)가 해시(410 및 412)를 사용하여 유형 인스턴스(400)와 연관되어 있음을 검출할 수 있다. 따라서 유형 인스턴스(400 및 402)는 해시(410 및 412)를 통해 서로 간의 링크(414)를 갖는다. 링크(414)는 유형 인스턴스(400, 402) 사이의 어느 한 방향 또는 두 방향으로의 식별 및/또는 정보 전달을 위해 사용될 수 있다. 즉, 링크(414)는 유형 인스턴스(400, 402)가 하드카피(예: 종이 문서)인 경우에도 유형 인스턴스(400, 402) 사이에 실시간 동적 연결을 제공한다. 예를 들어, 링크(414)는 각각의 컴퓨터 시스템 사이에서 유형 인스턴스(400 또는 402)에 관한 가상 애노테이션의 공유를 용이하게 할 수 있다. 4B,
여기에 설명된 매핑은 유형 인스턴스의 콘텐츠를 전자적으로 캡처하는 편리한 방법을 제공함으로써 시각적 형태로 정보를 문서화하는 프로세스를 개선할 수 있다. 도 5는 저장소(스토리지) 드라이브(500)에 관한 예를 도시한다. 일부 구현에서, 스토리지 드라이브(500)는 여러 사용자의 파일 및 폴더에 대한 중앙 스토리지 솔루션(예: 파일 백업 서비스)으로 제공될 수 있으며 여러 유형의 장치를 사용하여 파일에 액세스할 수 있다. 예를 들어, 스토리지 드라이브(500)는 클라우드에서 이용 가능하게 될 수 있다. The mappings described herein can improve the process of documenting information in visual form by providing a convenient way to electronically capture the content of type instances. 5 shows an example of a storage (storage)
스토리지 드라이브(500)에서, 사용자는 페인(pane)(504)에서 해당 사용자의 파일 이름을 보기 위해 컨트롤(502)을 활성화할 수 있다. 컨트롤(506)은 스토리지 드라이브(500)가 아닌 다른 드라이브(예를 들어, 사용자에게 속하지 않지만 사용자와 공유된 드라이브)에 액세스하는 데 사용될 수 있다. 컨트롤(508)은 사용자가 최근에 액세스한 문서의 이력을 보기 위해 활성화될 수 있다. On the
스토리지 드라이브(500)를 제어하는 사용자가 보관 또는 재활용 여부를 결정하는 종이 문서를 소유하게 되었다고 가정하자. 예를 들어, 종이 문서는 사용자가 구매한 제품에 대한 사용 설명서가 될 수 있다. 사용 설명서를 재활용하고 앞으로 다시는 필요하지 않기를 바라는 대신 사용자는 AR 헤드셋을 착용하고 종이 문서의 일부 또는 전체 페이지를 넘길 수 있다. 도 3a 내지 도 3b를 참조하여 전술한 예와 유사하게, AR 헤드셋은 여기에서 사용자 설명서의 내용을 캡처하고 그 정보를 서버, 이 예에서는 스토리지 드라이브(500)를 제어하는 서버에 제공할 수 있다. 따라서, 그 후에 사용자가 스토리지 드라이브(500)에 액세스할 때, 페인(pane)(504)은 사용자가 페이지를 통해 페이지를 넘긴 사용자 매뉴얼에 대응하는 아이템(510)을 포함할 수 있고, 따라서 이 정보를 유지하는 편리한 방법을 제공한다.Assume that a user who controls the
여기에 설명된 매핑은 사용자가 본 유형 인스턴스의 기록을 제공하는 것과 같이 사용자가 이전에 본 시각적 정보에 대한 액세스를 개선할 수 있다. 도 6a는 도 5의 스토리지 드라이브(500)에 관한 예를 도시한다. 도 3a를 다시 간략히 참조하면, 그 예는 서버에 유형 인스턴스(300)의 해시를 제공하는 AR 헤드셋을 설명한다. 이는 AR 헤드셋과 연관된 사용자가 유형 인스턴스(300)를 인식했음을 서버에 알린다. 본 예는 서버가 해시를 사용하여 찾은 문서에 대한 액세스 권한이 사용자에게 있다고 서버가 결정하는 상황을 포함한다. 따라서 서버는 유형 인스턴스(300)에 대한 식별자를 해당 사용자의 액세스된 문서 기록의 엔트리로 추가한다. 일부 구현에서, 스토리지 드라이브(500)는 사용자가 최근에 본 문서 목록을 볼 수 있는 컨트롤(508)을 제공한다. 컨트롤(508)의 활성화 시, 페인(504)은 액세스 이력에 대한 각각의 엔트리를 제시할 수 있으며, 여기서는 유형 인스턴스(300)에 대응하는 엔트리(512)을 포함한다. 즉, 사용자가 AR 헤드셋을 착용하고 유형 인스턴스(300)(예를 들어, 인쇄된 문서 또는 온스크린 프리젠테이션)를 관찰하기 때문에, 스토리지 드라이브(500)는 사용자의 액세스 이력에 유형 인스턴스(300)를 반영하도록 업데이트된다. 일부 구현에서, 엔트리(512)는 사용자가 유형 인스턴스(300)에 근접(예를 들어, 보기)한다는 검출에 기초할 수 있다. 예를 들어, 유형 인스턴스(300)는 하드카피 문서 또는 전자 문서의 온스크린 프리젠테이션일 수 있다. The mappings described herein can improve access to visual information previously viewed by a user, such as providing a record of type instances viewed by the user. FIG. 6A shows an example of the
도 3a의 상황에서, 서버가 해시를 이용하여 찾은 전자 문서에 대해 사용자가 접근 권한이 없는 경우 추가적인 인터렉션이 발생할 수 있다. 도 6b는 사용자가 유형 인스턴스(300) 및 AR FOV(302)를 보고 있는 것을 도시한다. 상술한 바와 같이, 서버는 AR 헤드셋이 제공하는 해시로 검색하여 해당 전자 문서를 식별하고 사용자에게 접근 권한이 없는 것으로 결정한다. 서버는 AR 헤드셋이 유형 인스턴스(300)가 대응하는 전자 문서에 대한 액세스 권한이 없음을 사용자에게 알리는 프롬프트(600)를 표시하게 할 수 있다. 프롬프트(600)는 수행될 수 있는 하나 이상의 동작(액션)을 사용자에게 제공할 수 있다. 일부 구현에서, 컨트롤(602)은 사용자가 전자 문서에 액세스하기 위한 허가 요청을 제출할 수 있게 한다. 예를 들어, 서버는 소유자이거나 전자 문서를 제어하는 사람이 고려하도록 이러한 요청을 전달할 수 있다. 사용자에게 접근 권한이 부여되면, 서버는 도 3a 내지 도 3f를 참조하여 전술한 하나 이상의 예에 따라 진행할 수 있다. 일부 구현에서, 컨트롤(604)은 사용자가 서버에서 가질 수 있는 다른 계정으로 사용자가 로그인할 수 있도록 한다. 새 계정이 전자 문서에 대한 액세스 권한을 가지고 있으면 서버는 도 3a 내지 도 3f를 참조하여 전술한 하나 이상의 예에 따라 진행할 수 있다. In the situation of FIG. 3A , additional interactions may occur when the user does not have access to the electronic document found by the server using the hash. FIG. 6B shows a user looking at a
일부 구현에서는 정보 보호를 개선하기 위해 문서 관리에 대한 실용적인 접근 방식을 적용할 수 있다. 가정적으로, 조직에서 전자 문서의 소유자 또는 제어기는 위에서 언급한 것과 같은 수많은 액세스 권한 요청으로 넘쳐날 수 있다. 또한, 조직의 문서보호정책에 반하여, 그 사람이 들어오는 모든 액세스 요청을 시기 적절하게 해결할 수 없기 때문에 그러한 사람이 문서를 보호된 상태에서 자유롭게 액세스할 수 있는 상태로 변경하도록 선택할 수 있다. Some implementations may apply a pragmatic approach to document management to improve information protection. Hypothetically, owners or controllers of electronic documents in an organization may be inundated with numerous access rights requests such as those mentioned above. Also, against an organization's document security policy, such a person may choose to change a document from a protected state to a freely accessible state because that person cannot resolve all incoming access requests in a timely manner.
위에서 언급한 실용적인 접근 방식은 해당 컴퓨터 시스템에 대한 액세스 권한이 (아직) 공식적으로 부여되지 않은 경우에도 문서의 유형적 인스턴스를 인식할 수 있는 사람이 문서에 대한 최소한의 액세스 권한을 이미 획득했음을 인식하는 것을 기반으로 할 수 있다. 도 3a를 다시 간략히 참조하면, AR 헤드셋을 착용한 사용자는 현재 유형 인스턴스(300) 앞에 있고 아마도 그 콘텐츠를 인지할 수 있을 것이다. 사용자가 짧은 시간 동안만 유형 인스턴스(300)에 있는 경우, 그러면 의도하지 않게 유형 인스턴스(300)와 접촉하게 되었고 그 내용을 완전히 또는 깊이 인식할 이유나 기회가 없었을 가능성이 있다. 이 경우 해당 전자문서에 대한 접근권한이 없는 것으로 상태를 변경하는 것은 정당하지 않을 수 있다. 그러나, 사용자가 적어도 미리 정해진 시간 동안 유형 인스턴스(300)의 존재(예를 들어, AR 헤드셋을 사용하여 보기)에 있었던 것으로 밝혀지면, 그렇다면 정식으로 요청하지 않아도 자동으로 해당 전자문서에 대한 접근 권한을 부여하는 것이 더 나은 조치라고 볼 수 있다. 적절한 기간으로 간주되는 기간은 문서 정보의 특성, 문서의 크기 또는 복잡성, 조직 유형 또는 조직 내 사용자의 역할에 따라 정의할 수 있다. 사용자가 미리 정해진 시간 이상 동안 유형 인스턴스(300)에 액세스(예를 들어, 존재)했다고 서버가 결정하면, 서버는 프롬프트(600)를 제시하지 않고 해당 전자 문서에 대한 사용자 액세스를 자동으로 승인할 수 있다. The pragmatic approach mentioned above is to recognize that a person capable of recognizing a tangible instance of a document has already obtained at least minimal access to the document, even if access to that computer system has not been officially granted (yet). can be based on Referring briefly again to FIG. 3A , the user wearing the AR headset is in front of the current instance of
본 명세서에 기술된 바와 같은 매핑은 공동 작업(협업) 문서의 유형 인스턴스를 인식하는 것에 기초하여 공동 작업 문서를 찾고 액세스하는 편리한 방법을 제공함으로써 문서 컬렉션을 위한 협업 프로그램으로의 보다 용이한 액세스를 용이하게 할 수 있다. 도 7a-7b는 AR FOV(302) 및 도 3a 내지 도 3e의 유형 인스턴스(300)에 관한 예를 도시한다. 본 예시를 참조하여 설명된 예는 본 명세서의 다른 곳에서 설명된 하나 이상의 다른 예와 함께 사용될 수 있다. Mappings as described herein facilitate easier access to collaboration programs for document collections by providing a convenient way to find and access collaboration documents based on recognizing type instances of collaboration (collaboration) documents. can do 7A-7B show an example of the
이러한 예는 유형 인스턴스(300)가 협업 프로그램과 관련된 문서들의 컬렉션의 문서에 해당하는 상황을 포함한다. 도 7a에서, AR 헤드셋을 착용한 사용자는 현재 AR FOV(302)에서 유형 인스턴스(300)를 보고 있다. 다시 도 3b의 상황을 간략히 언급한 바와 같이, 서버는 제공된 해시에 기초하여 사용자가 해당 전자 문서에 대한 접근 권한이 있다고 결정하면, 서버는 하나 이상의 추가 기능을 사용자에게 제공할 수 있다. 일부 구현에서, 예를 들어 AR FOV(302)에 시각적으로 포함됨으로써 AR 헤드셋에 의해 컨트롤(700)이 제공될 수 있다. 사용자는 컨트롤(700)을 활성화하여 해당 전자 문서에 접근할 수 있다.Examples of this include situations where
일부 구현에서, 도 7a를 참조하여 설명된 기능은 제스처를 수행하여 트리거할 수 있다. 예를 들어, 사용자는 AR FOV(302) 내에서 제스처를 수행할 수 있다. AR 헤드셋은 이 입력을 AR 헤드셋으로 보고 있는 유형 인스턴스(300)로부터 대응하는 전자 문서를 "드래그(drag)"하라는 요청으로 해석할 수 있다. 드래그는 사용자의 손이나 손가락의 위치와 움직임에 의해 공간적으로 제어될 수 있다. 도 7b는 사용자가 AR FOV(302) 내의 유형 인스턴스(300)의 이미지로부터 먼 형상(shape)(702)을 드래그하기 위해 제스처를 수행하는 것을 도시한다. 즉, 형상(702)은 AR 헤드셋에 의해 렌더링되고; 반면에 유형 인스턴스(300)는 AR FOV(302) 내에서 볼 수 있지만 AR 헤드셋에 의해 렌더링되지는 않는다. 컨트롤(704)은 AR 헤드셋의 컴퓨터 시스템에 해당한다. 예를 들어, 사용자는 컨트롤(704)에서 형상(702)을 "드롭(dropping)"하는 것에 대응하는 제스처를 수행할 수 있다. 이로 인해 AR 헤드셋의 컴퓨터 시스템이 협업 프로그램의 해당 전자 문서에 대한 액세스를 생성할 수 있다. 액세스는 AR 헤드셋을 제어하는 컴퓨터 시스템의 그래픽 사용자 인터페이스에서 전자 문서의 표현(예: 링크 또는 아이콘)의 형태로 생성될 수 있다. 접근 권한이 생성되면 사용자는 협업 프로그램을 사용하여 컴퓨터 시스템에서 해당 전자 문서를 열 수 있다. In some implementations, the functionality described with reference to FIG. 7A can be triggered by performing a gesture. For example, a user may perform a gesture within the
또한 컨트롤(706)은 AR 헤드셋에 의해 검출된 주변 컴퓨터 시스템에 해당한다. 예를 들어, 근거리 통신을 통해 AR 헤드셋은 사용자의 태블릿 또는 랩톱 컴퓨터가 근처에 있는지 확인할 수 있으며, 이로 인해 AR 헤드셋이 태블릿 또는 랩톱을 사용자와 연결된 다른 컴퓨터 시스템으로 식별할 수 있다. 사용자는 컨트롤(706)에서 형상(702)을 "드롭"하는 것에 대응하는 제스처를 수행할 수 있다. 이로 인해 다른 컴퓨터 시스템에서 생성될 협업 프로그램의 해당 전자 문서에 대한 액세스가 발생할 수 있다. 다른 컴퓨터 시스템에서의 액세스는 그래픽 사용자 인터페이스에서 전자 문서의 표시(예: 링크 또는 아이콘) 형태로 생성될 수 있다. 접근 권한이 생성되면 사용자는 협업 프로그램을 이용하여 상대 컴퓨터 시스템에서 해당 전자 문서를 열 수 있다.
본 명세서에 기술된 바와 같은 매핑은 컴퓨터 간 문서 관리를 제공하는 것과 같이 AR 영역 외부에서 문서들의 컬렉션을 위한 협업 프로그램에 대한 더 쉬운 액세스를 또한 또는 대신 용이하게 할 수 있다. 도 8a 내지 도 8e는 디스플레이 장치(800) 및 도 3a 내지 도 3e의 유형 인스턴스(300)에 관한 예를 도시한다. 디스플레이 장치(800)를 참조하여 설명된 예는 본 명세서의 다른 곳에서 설명된 하나 이상의 다른 예와 함께 사용될 수 있다. Mapping as described herein may also or instead facilitate easier access to collaboration programs for collections of documents outside the AR realm, such as providing cross-computer document management. 8A to 8E show an example of a
디스플레이 장치(800)는 현재 스크린 공유 애플리케이션(802)을 제시하고 있는 컴퓨터 시스템에 의해 제어된다. 일부 구현에서, 컴퓨터 시스템의 사용자는 현재 별도의 컴퓨터 시스템을 사용하고 있는 다른 사람과 화상 회의에 참여하고 있으며 그 사람은 스크린 공유 애플리케이션(802)을 사용하여 콘텐츠를 공유하고 있다. 예를 들어, 그 사람은 디스플레이 장치(800)에 유형 인스턴스(804)로 나타나는 별도의 컴퓨터 시스템으로부터 전자 문서를 공유하고 있다. The
디스플레이 장치(800)의 컴퓨터 시스템은 디스플레이 장치(800)에 표시되는 것에 기초하여 유형 인스턴스(804)의 콘텐츠를 검출할 수 있다. 컴퓨터 시스템은 협업 프로그램을 제어하는 서버에 해시를 제공할 수 있다. 제공된 해시를 이용하여 사용자가 해당 전자 문서에 대한 접근 권한이 있다고 서버가 결정하면, 하나 이상의 추가 기능이 사용자에게 제공될 수 있다. 도 8b는 사용자가 스크린 공유 애플리케이션(802)의 유형 인스턴스(804)로부터 대응하는 전자 문서를 나타내는 형상(806)을 드래그하고 디스플레이 장치(800)의 데스크탑에 형상(806)을 배치하는 것을 도시한다. 이는 디스플레이 장치(800)의 컴퓨터 시스템이 협업 프로그램의 해당 전자 문서에 대한 액세스를 생성하게 할 수 있다. 도 8c는 데스크탑 상에 위치한 전자 문서의 표현(808)을 도시한다. 표현(808)은 컴퓨터 시스템에 대응하는 전자 문서를 제시하기 위해 협업 프로그램을 트리거하는 링크 또는 아이콘을 포함할 수 있다. The computer system of
디스플레이 장치(800)의 컴퓨터 프로그램에 의해 실행되는 애플리케이션은 검출되는 유형 인스턴스(804)에 기초하여 협업 프로그램에 대한 액세스를 용이하게 할 수 있다. 도 8d는 디스플레이 장치(800)의 컴퓨터 시스템이 브라우저(810)를 제공하는 것을 도시한다. 브라우저(810)는 유형 인스턴스(804)의 콘텐츠를 검출하고 응답으로 하나 이상의 기능을 사용자에게 제공할 수 있다. 일부 구현에서, 브라우저(810)는 디스플레이 장치(800)의 컴퓨터 시스템에서 협업 프로그램의 대응하는 전자 문서에 대한 액세스를 생성하기 위한 컨트롤(812)을 제시한다. 이는 데스크톱에 표현(808)(도 8c)을 배치할 수 있다. An application executed by a computer program on the
일부 구현에서, 브라우저(810)는 다른 컴퓨터 시스템에서 협업 프로그램의 해당 전자 문서에 대한 액세스를 생성하기 위한 컨트롤(814)을 제공한다. 다른 컴퓨터 시스템은 디스플레이 장치(800)의 컴퓨터 시스템에 의해 검출된 주변 컴퓨터 시스템일 수 있다. 예를 들어, 근거리 통신을 통해 디스플레이 장치(800)의 컴퓨터 시스템은 사용자의 태블릿 또는 랩탑 컴퓨터가 근처에 있음을 결정할 수 있으며, 이는 디스플레이 장치(800)의 컴퓨터 시스템이 사용자와 연관된 다른 컴퓨터 시스템으로서 태블릿 또는 랩탑을 식별하게 할 수 있다. 컨트롤(814)의 활성화는 협업 프로그램의 해당 전자 문서에 대한 액세스가 다른 컴퓨터 시스템에서 생성되도록 할 수 있다. 도 8e는 다른 시스템이 디스플레이 장치(816)를 갖고, 전자 문서의 표현(representation)(818)이 그의 데스크탑에 위치함을 도시한다. 표현(818)은 다른 컴퓨터 시스템에 대응하는 전자 문서를 제공하기 위해 협업 프로그램을 트리거하는 링크 또는 아이콘을 포함할 수 있다. In some implementations,
앞서 언급한 바와 같이, 여기에 설명된 매핑은 컴퓨터 간 문서 관리를 제공하는 것과 같이 문서들의 컬렉션을 위한 협업 프로그램에 대한 보다 쉬운 액세스를 용이하게 할 수 있다. 도 9a 내지 도 9b는 도 8a 내지 도 8e의 디스플레이 장치(800)에 관한 예를 도시한다. 디스플레이 장치(800)는 특정 운영 체제를 실행하는 컴퓨터 시스템에 의해 제어될 수 있고, 다른 디스플레이 장치(900)는 다른 운영 체제를 실행하는 별도의 컴퓨터 시스템에 의해 제어될 수 있다. 운영 체제는 예를 들어 구글(Google)이 설계한 크롬(Chrome) OS 또는 언드로이드(Android), 마이크로소프트(Microsoft)가 설계한 윈도우(Windows), 애들(Apple)이 설계한 macOS 또는 iOS 또는 오픈 소스 운영 체제(예: Linux)일 수 있다. As mentioned previously, the mapping described herein may facilitate easier access to collaboration programs for collections of documents, such as providing document management between computers. 9A to 9B show examples of the
여기서, 유형 인스턴스(300)는 디스플레이 장치(800)에 의해 제시되고 현재 AR FOV(302) 내에 있다. 도 9a는 사용자가 AR FOV(302) 내의 유형 인스턴스(300)의 이미지로부터 멀리 형상(902)을 드래그하는 것을 도시한다. 예를 들어, 사용자는 AR FOV(302) 내에서 제스처를 수행함으로써 형상(902)을 드래그하고, 제스처는 AR 헤드셋에 의해 검출되고 해석된다. 즉, 형상(902)은 AR 헤드셋에 의해 렌더링되고; 반면에 유형 인스턴스(300)는 AR FOV(302) 내에서 볼 수 있지만 디스플레이 장치(800)에 의해 렌더링된다. Here,
AR 헤드셋에 의해 AR FOV(302) 내에 렌더링된 형상(902)으로, 대신 사용자는 도 9b에 나타낸 바와 같이 디스플레이 장치(900)를 응시할 수 있다. 예를 들어, 사용자는 AR FOV(302)가 대신 디스플레이 장치(900)를 향하도록 머리를 돌릴 수 있다.다른 예로서, AR FOV(302)는 디스플레이 장치(800 및 900) 모두를 수용하기에 충분히 클 수 있다. AR 헤드셋은 디스플레이 장치(800, 900)의 각 컴퓨터 시스템에 연결된다. 예를 들어, 근거리 통신 네트워크는 AR 헤드셋과 컴퓨터 시스템을 서로 연결할 수 있다. 사용자는 데스크탑 앞에서 제스처를 수행함으로써 디스플레이 장치(900)에 형상(902)을 "드롭"할 수 있다. 디스플레이 장치(900)에 대한 컴퓨터 시스템의 ID(identity), 위치 및 네트워크 주소를 알고 있는 AR 헤드셋에 기초하여, AR 헤드셋은 전자 문서의 표현(904)이 디스플레이 장치(900)의 데스크탑에 위치하게 할 수 있다. 표현(904)은 디스플레이 장치(900)에 대응하는 전자 문서를 제시하기 위해 협업 프로그램을 트리거하는 링크 또는 아이콘을 포함할 수 있다. With the
도 10은 컴퓨터로 구현되는 방법(1000)의 예를 도시한다. 컴퓨터로 구현되는 방법(1000)은 본 명세서의 다른 곳에서 설명된 하나 이상의 예와 함께 사용될 수 있다. 달리 명시되지 않는 한, 표시된 것보다 더 많거나 적은 동작이 수행될 수 있으며 및/또는 두 개 이상의 동작이 다른 순서로 수행될 수 있다. 10 shows an example of a computer-implemented
컴퓨터로 구현되는 방법(1000)은 제1 컴퓨터 시스템에 의해 제1 문서의 유형 인스턴스의 제1 콘텐츠를 검출하는 동작(1002)을 포함할 수 있다. 예를 들어, 클라이언트 측에서 작동하는 컴퓨터 시스템(100)(도 1)의 인스턴스는 유형 인스턴스(300)(도 3)의 콘텐츠를 검출할 수 있다. The computer-implemented
컴퓨터로 구현되는 방법(1000)은 제1 컴퓨터 시스템에 의해 제1 콘텐츠를 사용하여 제1 해시를 생성하는 동작(1004)을 포함할 수 있으며, 제1 해시는 제1 난독화 콘텐츠를 포함한다. 예를 들어, 클라이언트 측에서 작동하는 컴퓨터 시스템(100)(도 1)의 인스턴스는 유형 인스턴스(300)(도 3) 콘텐츠의 해시를 생성할 수 있다. The computer-implemented
컴퓨터로 구현되는 방법(1000)은 제1 컴퓨터 시스템에 의해 제2 컴퓨터 시스템에 의한 수신을 위해 제1 해시를 전송하는 동작(1006)을 포함할 수 있다. 예를 들어, 클라이언트 측에서 작동하는 컴퓨터 시스템(100)(도 1)의 인스턴스는 서버 측에서 작동하는 컴퓨터 시스템(100)(도 1)의 인스턴스에 의한 수신을 위해 유형 인스턴스(300)(도 3)의 콘텐츠의 해시를 보낼 수 있다.The computer-implemented
컴퓨터로 구현되는 방법(1000)은 제1 컴퓨터 시스템에 의해, 제2 컴퓨터 시스템에 의해 생성된 제1 해시에 대한 응답을 수신하는 동작(1008)을 포함할 수 있으며, 응답은 제1 콘텐츠와 연관된 제2 문서에 대응하는 정보를 포함한다. 예를 들어, 클라이언트측에서 작동하는 컴퓨터 시스템(100)(도 1)의 인스턴스는 서버측에서 작동하는 컴퓨터 시스템(100)(도 1)의 인스턴스에 의해 생성된 응답을 수신할 수 있다. The computer-implemented
컴퓨터로 구현되는 방법(1000)은 제1 컴퓨터 시스템에 의해 그리고 응답에 기초하여 제2 컴퓨터 시스템에 의한 수신을 위해 제1 콘텐츠를 전송하는 동작(1010)을 포함할 수 있다. 예를 들어, 클라이언트 측에서 작동하는 컴퓨터 시스템(100)(도 1)의 인스턴스는 서버 측에서 작동하는 컴퓨터 시스템(100)(도 1)의 인스턴스에 의한 수신을 위해 유형 인스턴스(300)(도 3)의 콘텐츠를 전송한다. The computer-implemented
도 11은 여기에 기술된 기술을 구현하기 위해 사용될 수 있는 컴퓨터 장치 및 모바일 컴퓨터 장치의 예를 도시한다. 도 11은 여기에 설명된 기술과 함께 사용될 수 있는 일반 컴퓨터 장치(1100) 및 일반 모바일 컴퓨터 장치(1150)의 예를 도시한다. 컴퓨팅 장치(1100)는 랩탑, 데스크탑, 태블릿, 워크스테이션, PDA, 텔레비전, 서버, 블레이드 서버, 메인프레임 및 기타 적절한 컴퓨팅 장치와 같은 다양한 형태의 디지털 컴퓨터를 나타내도록 의도된다. 컴퓨팅 장치(1150)는 PDA, 셀룰러 전화, 스마트폰 및 기타 유사한 컴퓨팅 장치와 같은 다양한 형태의 모바일 장치를 나타내기 위한 것이다. 여기에 표시된 컴포넌트, 연결 및 관계, 기능은 예시일 뿐이며 이 문서에서 설명 및/또는 청구된 발명의 구현을 제한하지 않는다. 11 illustrates examples of computer devices and mobile computer devices that can be used to implement the techniques described herein. FIG. 11 illustrates examples of a
컴퓨팅 장치(1100)는 프로세서(1102), 메모리(1104), 저장 장치(1106), 메모리(1104)에 연결되는 고속 인터페이스(1108) 및 고속 확장 포트(1110), 저속 버스(1114) 및 저장 장치(1106)에 연결되는 저속 인터페이스(1112)를 포함한다. 컴포넌트(1102, 1104, 1106, 1108, 1110 및 1112) 각각은 다양한 버스를 사용하여 상호 연결되며, 공통 마더보드 또는 적절한 다른 방식으로 장착될 수 있다. 프로세서(1102)는 메모리(1104) 또는 저장 장치(1106)에 저장된 명령을 포함하여 컴퓨팅 장치(1100) 내에서 실행하기 위한 명령을 처리하여 GUI에 대한 그래픽 정보를 고속 인터페이스(1108)로 연결된 디스플레이(1116)와 같은 외부 입력/출력 장치에 표시할 수 있다. 다른 구현에서, 다중 프로세서 및/또는 다중 버스는 다중 메모리 및 메모리 유형과 함께 적절하게 사용될 수 있다. 또한, 복수의 컴퓨팅 장치(1100)가 연결될 수 있으며, 각각의 장치는 필요한 동작의 일부를 제공한다(예를 들어, 서버 뱅크, 블레이드 서버 그룹 또는 다중 프로세서 시스템).
메모리(1104)는 컴퓨팅 장치(1100) 내에 정보를 저장한다. 일 구현에서, 메모리(1104)는 휘발성 메모리 유닛 또는 유닛들이다. 다른 구현에서, 메모리(1104)는 비휘발성 메모리 유닛 또는 유닛들이다. 메모리(1104)는 또한 자기 또는 광학 디스크와 같은 다른 형태의 컴퓨터 판독 가능 매체일 수 있다.
저장 장치(1106)는 컴퓨팅 장치(1100)에 대용량 저장 장치를 제공할 수 있다. 일 구현에서, 저장 장치(1106)는 플로피 디스크 장치, 하드 디스크 장치, 광학 디스크 장치 또는 테이프 장치, 플래시 메모리 또는 기타 유사한 솔리드 스테이트 메모리 장치 또는 어레이와 같은 컴퓨터 판독 가능 매체이거나 이를 포함할 수 있으며, 이는 SAN(Storage Area Network) 또는 기타 구성에 있는 장치를 포함할 수 있다. 컴퓨터 프로그램 제품은 정보 매체에 가시적으로 구현될 수 있다. 컴퓨터 프로그램 제품은 또한 실행될 때 위에서 설명한 것과 같은 하나 이상의 방법을 수행하는 명령을 포함할 수 있다. 정보 매체는 메모리(1104), 저장 장치(1106) 또는 프로세서(1102)의 메모리와 같은 컴퓨터 또는 기계 판독 가능 매체이다. The
고속 제어기(1108)는 컴퓨팅 장치(1100)에 대한 대역폭 집중 동작을 관리하는 반면, 저속 제어기(1112)는 낮은 대역폭 집중 동작을 관리한다. 이러한 기능 할당은 예시일 뿐이다. 일 구현에서, 고속 제어기(1108)는 메모리(1104), 디스플레이(1116)(예: 그래픽 프로세서 또는 가속기를 통해) 및 다양한 확장 카드(미도시)를 수용할 수 있는 고속 확장 포트(1110)에 결합된다. 구현에서, 저속 제어기(1112)는 저장 장치(1106) 및 저속 확장 포트(1114)에 결합된다. 다양한 통신 포트(예: USB, 블루투스, 이더넷, 무선 이더넷)를 포함할 수 있는 저속 확장 포트는 키보드, 포인팅 장치, 스캐너 또는 스위치나 라우터와 같은 네트워킹 장치와 같은 하나 이상의 입/출력 장치에 (예, 네트워크 어댑터를 통해) 연결될 수 있다.
컴퓨팅 장치(1100)는 도면에 도시된 바와 같이 다양한 형태로 구현될 수 있다. 예를 들어, 표준 서버(1120)로 구현되거나 이러한 서버 그룹에서 여러 번 구현될 수 있다. 랙 서버 시스템(1124)의 일부로 구현될 수도 있다. 또한, 랩탑 컴퓨터(1122)와 같은 개인용 컴퓨터에서 구현될 수 있다. 대안적으로, 컴퓨팅 장치(1100)로부터의 컴포넌트는 장치(1150)와 같은 모바일 장치(미도시)의 다른 컴포넌트와 결합될 수 있다. 이러한 장치 각각은 하나 이상의 컴퓨팅 장치(1100, 1150)를 포함할 수 있고, 전체 시스템은 서로 통신하는 복수의 컴퓨팅 장치(1100, 1150)로 구성될 수 있다.The
컴퓨팅 장치(1150)는 다른 컴포넌트 중에서 프로세서(1152), 메모리(1164), 디스플레이(1154)와 같은 입력/출력 장치, 통신 인터페이스(1166) 및 트랜시버(송수신기)(1168)를 포함한다. 장치(1150)에는 추가 저장 장치를 제공하기 위해 마이크로폰로드라이브 또는 기타 장치와 같은 저장 장치가 제공될 수도 있다. 컴포넌트(1150, 1152, 1164, 1154, 1166 및 1168) 각각은 다양한 버스를 사용하여 상호 연결되며, 일부 컴포넌트는 공통 마더보드 또는 적절한 다른 방식으로 장착될 수 있다.
프로세서(1152)는 메모리(1164)에 저장된 명령어를 포함하여 컴퓨팅 장치(1150) 내의 명령어를 실행할 수 있다. 프로세서는 별도의 다중 아날로그 및 디지털 프로세서를 포함하는 칩 세트로 구현될 수 있다. 프로세서는 예를 들어 사용자 인터페이스의 제어, 장치(1150)에 의해 실행되는 애플리케이션 및 장치(1150)에 의한 무선 통신과 같은 장치(1150)의 다른 컴포넌트의 조정을 제공할 수 있다.
프로세서(1152)는 제어 인터페이스(1158) 및 디스플레이(1154)에 연결된 디스플레이 인터페이스(1156)를 통해 사용자와 통신할 수 있다. 디스플레이(1154)는 예를 들어 TFT LCD(Thin-Film-Transistor Liquid Crystal Display) 또는 OLED(Organic Light Emitting Diode) 디스플레이 또는 다른 적절한 디스플레이 기술일 수 있다. 디스플레이 인터페이스(1156)는 디스플레이(1154)를 구동하여 그래픽 및 기타 정보를 사용자에게 제공하기 위한 적절한 회로를 포함할 수 있다. 제어 인터페이스(1158)는 사용자로부터 명령을 수신하고 프로세서(1152)에 제출하기 위해 명령을 변환할 수 있다. 또한, 프로세서(1152)와 통신하는 외부 인터페이스(1162)가 제공되어 다른 장치와 장치(1150)의 근거리 통신을 가능하게 할 수 있다. 외부 인터페이스(1162)는 예를 들어 일부 구현에서는 유선 통신을 위해, 또는 다른 구현에서는 무선 통신을 위해 제공할 수 있고, 복수의 인터페이스가 또한 사용될 수 있다.
메모리(1164)는 컴퓨팅 장치(1150) 내에 정보를 저장한다. 메모리(1164)는 컴퓨터 판독 가능 매체 또는 미디어, 휘발성 메모리 장치 또는 비휘발성 메모리 장치 또는 장치 중 하나 이상으로 구현될 수 있다. 확장 메모리(1164)는 또한 제공될 수 있고 예를 들어 SIMM(Single In Line Memory Module) 카드 인터페이스를 포함할 수 있는 확장 인터페이스(1172)를 통해 장치(1150)에 연결될 수 있다. 이러한 확장 메모리(1164)는 장치(1150)에 추가 저장 공간을 제공하거나 장치(1150)에 대한 애플리케이션 또는 기타 정보를 저장할 수도 있다. 구볼륨으로, 확장 메모리(1164)는 위에서 설명한 프로세스를 수행하거나 보완하기 위한 명령을 포함할 수 있으며 보안 정보도 포함할 수 있다. 따라서 예를 들어 확장 메모리(1164)는 장치(1150)용 보안 모듈로 제공될 수 있으며 장치(1150)의 안전한 사용을 허용하는 명령으로 프로그래밍될 수 있다. 또한 보안 애플리케이션은 SIMM 카드를 통해 해킹 불가능한 방식으로 SIMM 카드에 식별 정보를 배치하는 것과 같은 추가 정보와 함께 제공될 수 있다.
메모리는 예를 들어 후술하는 바와 같이 플래시 메모리 및/또는 NVRAM 메모리를 포함할 수 있다. 한 구현에서, 컴퓨터 프로그램 제품은 정보 매체에 유형적으로 구현된다. 컴퓨터 프로그램 제품은 실행될 때 위에서 설명한 것과 같은 하나 이상의 방법을 수행하는 명령을 포함한다. 정보 캐리어는 예를 들어 트랜시버(1168) 또는 외부 인터페이스(1162)를 통해 수신될 수 있는 메모리, 확장 메모리(1164) 또는 프로세서(1152)의 메모리와 같은 컴퓨터 또는 기계 판독 가능 매체이다.The memory may include, for example, flash memory and/or NVRAM memory as described below. In one implementation, a computer program product is tangibly embodied in an information medium. The computer program product includes instructions that, when executed, perform one or more methods as described above. The information carrier is a computer or machine readable medium, such as memory,
장치(1150)는 필요한 경우 디지털 신호 프로세싱 회로를 포함할 수 있는 통신 인터페이스(1166)를 통해 무선으로 통신할 수 있다. 통신 인터페이스(1166)는 특히 GSM 음성 통화, SMS, EMS 또는 MMS 메시징, CDMA, TDMA, PDC, WCDMA, CDMA2000 또는 GPRS와 같은 다양한 모드 또는 프로토콜 하에서 통신을 제공할 수 있다. 이러한 통신은 예를 들어 무선 빈도 송수신기(1168)를 통해 발생할 수 있다. 또한, 블루투스, WiFi 또는 기타 트랜시버(미도시)를 사용하는 것과 같은 단거리 통신이 발생할 수 있다. 또한, GPS(Global Positioning System) 수신기 모듈(1170)은 장치(1150)에서 실행되는 애플리케이션에 의해 적절하게 사용될 수 있는 추가적인 내비게이션 및 위치 관련 무선 데이터를 장치(1150)에 제공할 수 있다.
장치(1150)는 또한 오디오 코덱(1160)을 사용하여 청각적으로 통신할 수 있으며, 이는 사용자로부터 음성 정보를 수신하고 이를 사용 가능한 디지털 정보로 변환할 수 있다. 마찬가지로 오디오 코덱(1160)은 예를 들어 장치(1150)의 핸드셋에서와 같이 스피커를 통해 사용자를 위한 가청 사운드를 생성할 수 있다. 그러한 사운드는 음성 전화 통화로부터의 사운드를 포함할 수 있고, 녹음된 사운드(예를 들어, 음성 메시지, 음악 파일 등)를 포함할 수 있고, 또한 장치(1150)에서 작동하는 애플리케이션에 의해 생성된 사운드를 포함할 수 있다.
컴퓨팅 장치(1150)는 도면에 도시된 바와 같이 다양한 형태로 구현될 수 있다. 예를 들어, 셀룰러 전화기(1118)로 구현될 수 있다. 또한 스마트폰(1182), PDA 또는 기타 유사한 모바일 장치의 일부로 구현될 수도 있다. The
여기에 설명된 시스템 및 기술의 다양한 구현은 디지털 전자 회로, 집적 회로, 특별히 설계된 ASIC(application specific integrated circuits), 컴퓨터 하드웨어, 펌웨어, 소프트웨어 및/또는 이들의 조합으로 실현될 수 있다. 이러한 다양한 구현은 적어도 하나의 프로그래밍 가능한 프로세서를 포함하는 프로그래밍 가능한 시스템에서 실행 가능 및/또는 해석 가능한 하나 이상의 컴퓨터 프로그램에서의 구현을 포함할 수 있으며, 이는 스토리지 시스템, 적어도 하나의 입력 장치 및 적어도 하나의 출력 장치로부터 데이터 및 명령을 수신하고 데이터 및 명령을 전송하도록 결합된 특수 또는 범용일 수 있다. Various implementations of the systems and techniques described herein may be realized with digital electronic circuits, integrated circuits, specially designed application specific integrated circuits (ASICs), computer hardware, firmware, software, and/or combinations thereof. These various implementations may include implementation in one or more computer programs executable and/or interpretable in a programmable system comprising at least one programmable processor, which includes a storage system, at least one input device, and at least one It can be special or general purpose coupled to receive data and commands from and transmit data and commands from an output device.
이들 컴퓨터 프로그램(또한 프로그램, 소프트웨어, 소프트웨어 애플리케이션, 또는 코드로 알려짐)은 프로그램 가능 한 프로세서를 위한 머신 명령어를 포함하고, 고-레벨 절차 및/또는 객체 지향 프로그램 언어(object-oriented programming language) 및/또는 어셈블리/머신 언어로 구현될 수 있다. 본 명세서에서 사용되는 용어 "머신 판독가능 매체(machine-readable medium)"와 "컴퓨터 판독가능 매체(computer-readable medium)"는 머신 명령어 및/또는 데이터를 프로그램 가능한 프로세서에 제공하기 위해 이용되는 임의의 컴퓨터 프로그램 제품, 장치, 및/또는 디바이스(예를 들어, 마그네틱 디스크, 광학 디스크, 메모리, PLDs(Programmable Logic Devices))를 가리키며, 머신 판독가능 신호와 같은 머신 명령어를 수신하는 머신 판독가능 매체를 포함한다. 용어 "머신 판독가능 신호(machine-readable signal)"는 머신 명령어 및/또는 데이터를 프로그램 가능한 프로세서에 제공하기 위해 사용되는 임의의 신호를 가리킨다. These computer programs (also known as programs, software, software applications, or code) contain machine instructions for programmable processors and contain high-level procedural and/or object-oriented programming languages and/or Or it can be implemented in assembly/machine language. As used herein, the terms "machine-readable medium" and "computer-readable medium" refer to any medium used to provide machine instructions and/or data to a programmable processor. Refers to computer program products, apparatus, and/or devices (e.g., magnetic disks, optical disks, memory, Programmable Logic Devices (PLDs)), including machine readable media that receive machine instructions, such as machine readable signals do. The term “machine-readable signal” refers to any signal used to provide machine instructions and/or data to a programmable processor.
사용자와의 상호작용을 제공하기 위하여, 본 명세서에 기술된 시스템과 기술들은 정보를 사용자에게 디스플레이하기 위한 디스플레이 장치(예를 들어, CRT(cathode ray tube) 또는 LCD 모니터)와 사용자가 컴퓨터에 입력을 제공할 수 있는 키보드 및 포인팅 디바이스(예를 들어, 마우스 또는 트랙볼)를 구비한 컴퓨터 상에서 구현될 수 있다. 사용자와의 상호작용을 제공하기 위하여 다른 종류의 디바이스가 또한 사용될 수 있다; 예를 들어, 사용자에게 제공되는 피드백(feedback)은 임의의 형태의 감각 피드백(예를 들어, 시각 피드백, 청각 피드백 또는 촉각 피드백)일 수 있고, 사용자로부터의 입력은 음향(acoustic), 음성(speech) 또는 촉각(tactile) 입력을 포함하는 임의의 형태로 수신될 수 있다. To provide interaction with a user, the systems and techniques described herein include a display device (eg, a cathode ray tube (CRT) or LCD monitor) for displaying information to a user and input from the user to a computer. It can be implemented on a computer equipped with a keyboard and pointing device (eg, mouse or trackball) that can provide. Other types of devices may also be used to provide interaction with the user; For example, the feedback provided to the user may be any form of sensory feedback (eg, visual feedback, auditory feedback, or tactile feedback), and the input from the user may be acoustic, speech ) or tactile input.
본 명세서에서 설명한 시스템과 기술은, 백 엔드(back end) 컴포넌트(예를 들어, 데이터 서버와 같은), 또는 미들웨어 컴포넌트(예를 들어, 애플리케이션 서버), 또는 프론트 엔드(front end) 컴포넌트(예를 들어, 본 명세서에서 설명된 시스템 및 기술의 구현와 사용자가 상호작용할 수 있는 그래픽 사용자 인터페이스 또는 웹브라우저를 구비한 클라이언트 컴퓨터), 또는 이러한 백 엔드, 미들웨어, 또는 프론트 엔드 컴포넌트들의 임의의 조합을 포함하는 컴퓨팅 시스템으로 구현될 수 있다. 시스템의 컴포넌트는 디지털 데이터 통신의 임의의 형태 또는 매체(예를 들어, 통신 네트워크)에 의해 상호 연결될 수 있다. 통신 네트워크의 예로서, 근거리 네트워크 ("LAN"), 광역 네트워크("WAN"), 및 인터넷이 있다.The systems and techniques described herein may include a back end component (eg, a data server), or a middleware component (eg, an application server), or a front end component (eg, a data server). For example, a client computer having a web browser or graphical user interface through which a user can interact with implementations of the systems and techniques described herein), or computing that includes any combination of such back-end, middleware, or front-end components. can be implemented as a system. The components of the system may be interconnected by any form or medium of digital data communication (eg, a communication network). Examples of communication networks include local area networks ("LAN"), wide area networks ("WAN"), and the Internet.
컴퓨팅 시스템은 클라이언트와 서버를 포함할 수 있다. 클라이언트와 서버는 보통 서로 떨어져 있으며, 일반적으로는 통신 네트워크를 통하여 상호작용한다. 클라이언트와 서버의 관계는 각각의 컴퓨터 상에서 실행되고 상호 클라이언트-서버 관계를 갖는 컴퓨터 프로그램에 의하여 일어난다.A computing system may include a client and a server. Clients and servers are usually remote from each other and usually interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a mutual client-server relationship.
일부 구현에서, 도 11에 도시된 컴퓨팅 장치는 가상 현실(VR 헤드셋(1190))과 인터페이스하는 센서를 포함할 수 있다. 예를 들어, 컴퓨팅 장치(1150) 또는 도 11에 도시된 다른 컴퓨팅 장치에 포함된 하나 이상의 센서는 VR 헤드셋(1190)에 입력을 제공하거나 일반적으로 VR 공간에 입력을 제공할 수 있다. 센서는 터치스크린, 가속도계, 자이로스코프, 압력 센서, 생체 인식 센서, 온도 센서, 습도 센서 및 주변광 센서를 포함할 수 있지만 이에 제한되지 않는다. 컴퓨팅 장치(1150)는 VR 공간에 대한 입력으로서 사용될 수 있는 VR 공간에서 컴퓨팅 장치의 절대 위치 및/또는 검출된 회전을 결정하기 위해 센서를 사용할 수 있다. 예를 들어, 컴퓨팅 장치(1150)는 제어러, 레이저 포인터, 키보드, 무기 등과 같은 가상 객체로서 VR 공간에 통합될 수 있다. VR 공간에 통합될 때 사용자에 의한 컴퓨팅 장치/가상 객체의 위치 지정은 사용자가 VR 공간에서 특정 방식으로 가상 객체를 보도록 컴퓨팅 장치를 위치시킬 수 있게 한다. 예를 들어 가상 객체가 레이저 포인터를 나타내는 경우 사용자는 실제 레이저 포인터인 것처럼 컴퓨팅 장치를 조작할 수 있다. 사용자는 컴퓨팅 장치를 좌우, 상하, 원 등으로 움직일 수 있으며 레이저 포인터를 사용하는 것과 유사한 방식으로 장치를 사용할 수 있다. In some implementations, the computing device shown in FIG. 11 may include sensors that interface with virtual reality (VR headset 1190). For example, one or more sensors included in
일부 구현에서, 컴퓨팅 장치(1150)에 포함되거나 연결되는 하나 이상의 입력 장치는 VR 공간에 대한 입력으로 사용될 수 있다. 입력 장치는 터치스크린, 키보드, 하나 이상의 버튼, 트랙패드, 터치패드, 포인팅 장치, 마우스, 트랙볼, 조이스틱, 카메라, 마이크로폰, 입력 기능이 있는 이어폰 또는 버드, 게임 제어기 또는 기타 연결 가능한 입력 장치를 포함할 수 있지만 이에 제한되지 않는다. 컴퓨팅 장치가 VR 공간에 통합될 때 컴퓨팅 장치(1150)에 포함된 입력 장치와 상호 작용하는 사용자는 VR 공간에서 특정 동작이 발생하도록 할 수 있다. In some implementations, one or more input devices included in or connected to
일부 구현에서, 컴퓨팅 장치(1150)의 터치스크린은 VR 공간에서 터치패드로 렌더링될 수 있다. 사용자는 컴퓨팅 장치(1150)의 터치스크린과 상호 작용할 수 있다. 상호작용은 예를 들어 VR 헤드셋(1190)에서 VR 공간에서 렌더링된 터치패드의 움직임으로 렌더링된다. 렌더링된 움직임은 VR 공간에서 객체를 제어할 수 있다. In some implementations, the touchscreen of
일부 구현에서, 컴퓨팅 장치(1150)에 포함된 하나 이상의 출력 장치는 VR 공간에서 VR 헤드셋(1190)의 사용자에게 출력 및/또는 피드백을 제공할 수 있다. 출력 및 피드백은 시각적, 전술적 또는 오디오일 수 있다. 출력 및/또는 피드백은 진동, 하나 이상의 조명 또는 섬광등을 켜고 끄기 또는 블린킹(blinking) 및/또는 깜박임(flashing ), 알람 소리, 차임벨 재생, 노래 재생, 오디오 파일 재생을 포함할 수 있지만 이에 제한되지 않는다. 출력 장치는 진동 모터, 진동 코일, 압전 장치, 정전기 장치, 발광 다이오드(LED), 스트로브 및 스피커를 포함할 수 있지만 이에 제한되지 않는다. In some implementations, one or more output devices included in
일부 구현에서, 컴퓨팅 장치(1150)는 컴퓨터 생성 3D 환경에서 또 다른 객체로 나타날 수 있다. 컴퓨팅 장치(1150)와 사용자에 의한 상호 작용(예를 들어, 회전, 흔들기, 터치 스크린 터치, 터치 스크린을 가로지르는 손가락 스와이프)은 VR 공간에서 대상과의 상호 작용으로 해석될 수 있다. VR 공간의 레이저 포인터의 예에서 컴퓨팅 장치(1150)는 컴퓨터 생성 3D 환경에서 가상 레이저 포인터로 나타난다. 사용자가 컴퓨팅 장치(1150)를 조작함에 따라 VR 공간의 사용자는 레이저 포인터의 움직임을 보게 된다. 사용자는 컴퓨팅 장치(1150) 또는 VR 헤드셋(1190) 상의 VR 공간에서 컴퓨팅 장치(1150)와의 상호작용으로부터 피드백을 수신한다. In some implementations,
복수의 실시예가 설명되었다. 그럼에도 불구하고, 본 명세서의 사상 및 범위를 벗어나지 않는 범위 내에서 다양한 수정이 이루어질 수 있음이 이해될 것이다.A number of embodiments have been described. Nevertheless, it will be understood that various modifications may be made without departing from the spirit and scope of the present specification.
또한, 도면에 도시된 논리 흐름은 바람직한 결과를 달성하기 위해 도시된 특정 순서 또는 순차적인 순서를 필요로 하지 않는다. 또한, 설명된 흐름에서 다른 단계들이 제공되거나 제거될 수 있으며, 설명된 시스템에 다른 컴포넌트들이 추가되거나 제거될 수 있다. 따라서, 다른 구현들은 다음 청구항의 범위 내에 있다.Further, the logic flows depicted in the figures do not require the specific order shown or sequential order to achieve desirable results. Also, other steps may be provided or removed from the described flow, and other components may be added or removed from the described system. Accordingly, other implementations are within the scope of the following claims.
Claims (35)
제1 컴퓨터 시스템에 의해, 제1 문서의 유형 인스턴스(tangible instance)의 제1 콘텐츠를 검출하는 단계;
상기 제1 컴퓨터 시스템에 의해, 상기 제1 콘텐츠를 사용하여 제1 해시를 생성하는 단계 -상기 제1 해시는 제1 난독화 콘텐츠를 포함함-;
상기 제1 컴퓨터 시스템에 의해, 제2 컴퓨터 시스템에 의한 수신을 위해 상기 제1 해시를 전송하는 단계; 그리고
상기 제1 컴퓨터 시스템에 의해, 상기 제2 컴퓨터 시스템에 의해 생성된 상기 제1 해시에 대한 응답을 수신하는 단계를 포함하며, 상기 응답은 상기 제1 콘텐츠와 연관된 제2 문서에 대응하는 정보를 포함하는 것을 특징으로 하는 컴퓨터로 구현되는 방법. As a computer-implemented method,
detecting, by a first computer system, first content of a tangible instance of a first document;
generating, by the first computer system, a first hash using the first content, the first hash including first obfuscated content;
transmitting, by the first computer system, the first hash for reception by a second computer system; and
receiving, by the first computer system, a response to the first hash generated by the second computer system, the response including information corresponding to a second document associated with the first content; A method implemented by a computer, characterized in that for doing.
상기 제1 컴퓨터 시스템에 의해, 상기 응답에 기초하여 상기 제2 컴퓨터 시스템에 의한 수신을 위해 상기 제1 콘텐츠를 전송하는 단계를 더 포함하는 것을 특징으로 하는 컴퓨터로 구현되는 방법. The method of claim 2, wherein the method,
Sending, by the first computer system, the first content for reception by the second computer system based on the response.
상기 제1 컴퓨터 시스템에 의해 그리고 상기 응답에 기초하여, 상기 제2 컴퓨터 시스템에 의한 수신을 위해 상기 제1 문서의 마크업 변경을 전송하는 단계를 더 포함하는 것을 특징으로 하는 컴퓨터로 구현되는 방법. The method according to any one of claims 2 to 4, wherein the method,
Sending, by the first computer system and based on the response, the markup changes of the first document for reception by the second computer system.
상기 제1 컴퓨터 시스템에 의해 그리고 상기 제2 해시를 사용하여, 상기 제1 문서와 상기 제2 문서 간의 대응관계를 검증하는 단계를 더 포함하는 것을 특징으로 하는 컴퓨터로 구현되는 방법. The method of claim 7, wherein the method,
and verifying, by the first computer system and using the second hash, a correspondence between the first document and the second document.
상기 제1 컴퓨터 시스템에 의해, 상기 제2 컴퓨터 시스템으로부터 상기 제2 문서를 수신하는 단계를 더 포함하는 것을 특징으로 하는 컴퓨터로 구현되는 방법. The method of claim 8, wherein the method,
and receiving, by the first computer system, the second document from the second computer system.
상기 제1 컴퓨터 시스템에 의해, 상기 제1 컴퓨터 시스템의 사용자에 대한 액세스의 이력을 수신하는 단계를 더 포함하고, 상기 이력은 상기 제1 해시를 수신한 제2 컴퓨터 시스템에 기초하여 상기 제2 문서에 액세스하기 위한 엔트리를 포함하는 것을 특징으로 하는 컴퓨터로 구현되는 방법. The method according to any one of claims 1 to 10, wherein the method,
receiving, by the first computer system, a history of access to a user of the first computer system, the history based on the second computer system that received the first hash, the second document A computer-implemented method comprising an entry for accessing.
상기 제1 컴퓨터 시스템에 의해 그리고 사용자로부터, 상기 제1 문서에 대한 TTS(text-to-speech) 서비스에 대한 요청을 수신하는 단계 -상기 제2 문서는 구조 마크업을 포함함-, 그리고 상기 제2 문서를 이용하여 상기 제1 문서의 상기 TTS 서비스를 제공하는 단계를 더 포함하는 것을 특징으로 하는 컴퓨터로 구현되는 방법. The method according to any one of claims 6 to 9, or claims 10 to 13 or 16 with reference to claim 6, wherein the method comprises:
receiving, by the first computer system and from a user, a request for a text-to-speech (TTS) service for the first document, wherein the second document includes structural markup; and 2. The computer-implemented method further comprising providing the TTS service of the first document by using the document.
상기 제1 컴퓨터 시스템에 의해, 상기 협업 프로그램을 사용하여 상기 제2 문서의 오프닝을 트리거하기 위해 상기 제1 문서의 표현의 드래깅(dragging)을 용이하게 하는 단계를 더 포함하는 것을 특징으로 하는 컴퓨터로 구현되는 방법. The method of claim 19 or 20, wherein the method,
facilitating, by the first computer system, dragging of a representation of the first document to trigger opening of the second document using the collaboration program. how it is implemented.
상기 제1 컴퓨터 시스템에 의해, 상기 AR 헤드셋의 사용자가 AR FOV(field of view) 내에서 제스처를 수행하는 것을 검출하는 단계, 그리고 이에 응답하여 상기 제스처에 따라 상기 AR FOV 내에서 상기 제1 문서의 표현을 이동시키는 단계를 더 포함하는 것을 특징으로 하는 컴퓨터로 구현되는 방법. The method of claim 24, wherein the method,
detecting, by the first computer system, that a user of the AR headset performs a gesture within an AR field of view (FOV); The computer implemented method further comprising moving the representation.
상기 제1 컴퓨터 시스템에 의해 그리고 상기 정보를 사용하여, 상기 제2 문서의 제2 콘텐츠를 제시하는 단계를 더 포함하는 것을 특징으로 하는 컴퓨터로 구현되는 방법. 28. The method according to any one of claims 1 to 27, wherein the method comprises:
and presenting, by the first computer system and using the information, second content of the second document.
상기 제1 컴퓨터 시스템에 의해, 상기 제1 문서의 변경에 대응하는 사용자에 의해 생성된 오디오 입력을 수신하는 단계, 상기 AR FOV에 상기 제1 문서에 대한 제2 가상 애노테이션을 제시하는 단계, 상기 변경을 상기 제2 컴퓨터 시스템으로 전송하는 단계를 더 포함하는 것을 특징으로 하는 컴퓨터로 구현되는 방법. The method of claim 29, wherein the method,
receiving, by the first computer system, audio input generated by a user corresponding to a change in the first document; presenting a second virtual annotation to the first document in the AR FOV; The computer-implemented method of claim 1, further comprising the step of transmitting to the second computer system.
제1 컴퓨터 시스템에 의해, 제1 문서의 유형 인스턴스의 제1 콘텐츠를 검출하는 동작;
상기 제1 컴퓨터 시스템에 의해, 상기 제1 콘텐츠를 사용하여 제1 해시를 생성하는 동작 -상기 제1 해시는 제1 난독화 콘텐츠를 포함함-;
상기 제1 컴퓨터 시스템에 의해, 제2 컴퓨터 시스템에 의한 수신을 위해 상기 제1 해시를 전송하는 동작; 그리고
상기 제1 컴퓨터 시스템에 의해, 상기 제2 컴퓨터 시스템에 의해 생성된 상기 제1 해시에 대한 응답을 수신하는 동작을 포함하며, 상기 응답은 상기 제1 콘텐츠와 연관된 제2 문서에 대응하는 정보를 포함하는 것을 특징으로 하는 컴퓨터 프로그램 제품. A computer program product tangibly embodied in a non-transitory storage medium, the computer program product including instructions that when executed by one or more processor(s) cause the one or more processor(s) to perform operations, the computer program product comprising: heard,
detecting, by a first computer system, a first content of a tangible instance of a first document;
generating, by the first computer system, a first hash using the first content, the first hash including first obfuscated content;
transmitting, by the first computer system, the first hash for reception by a second computer system; and
receiving, by the first computer system, a response to the first hash generated by the second computer system, the response including information corresponding to a second document associated with the first content; A computer program product, characterized in that for doing.
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/US2020/070674 WO2022086578A1 (en) | 2020-10-19 | 2020-10-19 | Mapping a tangible instance of a document |
Publications (1)
Publication Number | Publication Date |
---|---|
KR20230088471A true KR20230088471A (en) | 2023-06-19 |
Family
ID=73544414
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
KR1020237016612A KR20230088471A (en) | 2020-10-19 | 2020-10-19 | Mapping Type Instances in Documents |
Country Status (6)
Country | Link |
---|---|
US (1) | US20230385431A1 (en) |
EP (1) | EP4229533A1 (en) |
JP (1) | JP2023549652A (en) |
KR (1) | KR20230088471A (en) |
CN (1) | CN116324776A (en) |
WO (1) | WO2022086578A1 (en) |
Families Citing this family (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11962600B2 (en) * | 2021-10-14 | 2024-04-16 | Bank Of America Corporation | Apparatus and methods for secure, distributed, augmented-reality (AR) communication systems |
Family Cites Families (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2009211603A (en) * | 2008-03-06 | 2009-09-17 | Fuji Xerox Co Ltd | Document search system |
US10599753B1 (en) * | 2013-11-11 | 2020-03-24 | Amazon Technologies, Inc. | Document version control in collaborative environment |
EP3215956A1 (en) * | 2014-11-07 | 2017-09-13 | PCMS Holdings, Inc. | System and method for augmented reality annotations |
US20210098092A1 (en) * | 2019-09-26 | 2021-04-01 | Koninklijke Philips N.V. | Privacy-preserving medical search system using similarity preserving hashing |
-
2020
- 2020-10-19 EP EP20811938.8A patent/EP4229533A1/en active Pending
- 2020-10-19 WO PCT/US2020/070674 patent/WO2022086578A1/en active Application Filing
- 2020-10-19 CN CN202080106404.2A patent/CN116324776A/en active Pending
- 2020-10-19 US US18/248,983 patent/US20230385431A1/en active Pending
- 2020-10-19 KR KR1020237016612A patent/KR20230088471A/en unknown
- 2020-10-19 JP JP2023523624A patent/JP2023549652A/en active Pending
Also Published As
Publication number | Publication date |
---|---|
US20230385431A1 (en) | 2023-11-30 |
EP4229533A1 (en) | 2023-08-23 |
JP2023549652A (en) | 2023-11-29 |
CN116324776A (en) | 2023-06-23 |
WO2022086578A1 (en) | 2022-04-28 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US10599923B2 (en) | Mobile device utilizing multiple cameras | |
US11030351B2 (en) | Secure data display | |
KR20190076034A (en) | System and method for generating virtual notation surfaces with gestures in augmented and / or virtual reality environments | |
US9535595B2 (en) | Accessed location of user interface | |
KR102606037B1 (en) | Direct input from a remote device | |
US11960447B2 (en) | Operating system-level management of multiple item copy and paste | |
US11733959B2 (en) | Physical companion devices for use with extended reality systems | |
JP2015511360A (en) | Language independent probabilistic content matching | |
US10261602B2 (en) | Hop navigation | |
US10592048B2 (en) | Auto-aligner for virtual reality display | |
KR20230088471A (en) | Mapping Type Instances in Documents | |
CN116431138B (en) | Component template building method and device and form building method and device | |
US20230081605A1 (en) | Digital assistant for moving and copying graphical elements | |
US9524036B1 (en) | Motions for displaying additional content | |
US11308266B1 (en) | Augmented reality assisted physical form completion | |
JP6083158B2 (en) | Information processing system, information processing apparatus, and program |