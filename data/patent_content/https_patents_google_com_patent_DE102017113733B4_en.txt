DE102017113733B4 - Convolutional neural network on programmable two-dimensional image processor - Google Patents
Convolutional neural network on programmable two-dimensional image processor Download PDFInfo
- Publication number
- DE102017113733B4 DE102017113733B4 DE102017113733.5A DE102017113733A DE102017113733B4 DE 102017113733 B4 DE102017113733 B4 DE 102017113733B4 DE 102017113733 A DE102017113733 A DE 102017113733A DE 102017113733 B4 DE102017113733 B4 DE 102017113733B4
- Authority
- DE
- Germany
- Prior art keywords
- image data
- neural network
- convolutional neural
- execution
- dimensional
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
- 238000013527 convolutional neural network Methods 0.000 title claims abstract description 88
- 239000011159 matrix material Substances 0.000 claims abstract description 80
- 238000012545 processing Methods 0.000 claims abstract description 48
- 238000000034 method Methods 0.000 claims abstract description 34
- 230000035508 accumulation Effects 0.000 claims abstract description 7
- 238000009825 accumulation Methods 0.000 claims abstract description 7
- 238000004364 calculation method Methods 0.000 claims description 10
- 230000015654 memory Effects 0.000 description 31
- 230000008569 process Effects 0.000 description 17
- 238000007792 addition Methods 0.000 description 14
- 230000006870 function Effects 0.000 description 13
- 238000013459 approach Methods 0.000 description 12
- 230000003936 working memory Effects 0.000 description 8
- 238000013461 design Methods 0.000 description 6
- 238000006073 displacement reaction Methods 0.000 description 5
- 230000000694 effects Effects 0.000 description 4
- 230000009977 dual effect Effects 0.000 description 3
- 238000007726 management method Methods 0.000 description 3
- 238000004891 communication Methods 0.000 description 2
- 238000005516 engineering process Methods 0.000 description 2
- 238000010801 machine learning Methods 0.000 description 2
- 230000003287 optical effect Effects 0.000 description 2
- 238000009738 saturating Methods 0.000 description 2
- 239000004065 semiconductor Substances 0.000 description 2
- 238000013519 translation Methods 0.000 description 2
- 241001378470 Malaxis monophyllos Species 0.000 description 1
- 230000006399 behavior Effects 0.000 description 1
- 230000008901 benefit Effects 0.000 description 1
- 230000001413 cellular effect Effects 0.000 description 1
- 239000003086 colorant Substances 0.000 description 1
- 239000002131 composite material Substances 0.000 description 1
- 238000004590 computer program Methods 0.000 description 1
- 230000001186 cumulative effect Effects 0.000 description 1
- 238000013500 data storage Methods 0.000 description 1
- 238000007667 floating Methods 0.000 description 1
- 238000004519 manufacturing process Methods 0.000 description 1
- 238000013507 mapping Methods 0.000 description 1
- 238000007620 mathematical function Methods 0.000 description 1
- 238000012986 modification Methods 0.000 description 1
- 230000004048 modification Effects 0.000 description 1
- 230000002093 peripheral effect Effects 0.000 description 1
- 230000000750 progressive effect Effects 0.000 description 1
- 230000000644 propagated effect Effects 0.000 description 1
- 238000009877 rendering Methods 0.000 description 1
- 238000012546 transfer Methods 0.000 description 1
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/30—Arrangements for executing machine instructions, e.g. instruction decode
- G06F9/30003—Arrangements for executing specific machine instructions
- G06F9/30007—Arrangements for executing specific machine instructions to perform operations on data operands
- G06F9/3001—Arithmetic instructions
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T1/00—General purpose image data processing
- G06T1/20—Processor architectures; Processor configuration, e.g. pipelining
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/0464—Convolutional networks [CNN, ConvNet]
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F17/00—Digital computing or data processing equipment or methods, specially adapted for specific functions
- G06F17/10—Complex mathematical operations
- G06F17/15—Correlation function computation including computation of convolution operations
- G06F17/153—Multidimensional correlation or convolution
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/30—Arrangements for executing machine instructions, e.g. instruction decode
- G06F9/30003—Arrangements for executing specific machine instructions
- G06F9/30007—Arrangements for executing specific machine instructions to perform operations on data operands
- G06F9/30032—Movement instructions, e.g. MOVE, SHIFT, ROTATE, SHUFFLE
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/30—Arrangements for executing machine instructions, e.g. instruction decode
- G06F9/30003—Arrangements for executing specific machine instructions
- G06F9/30007—Arrangements for executing specific machine instructions to perform operations on data operands
- G06F9/30036—Instructions to perform operations on packed data, e.g. vector, tile or matrix operations
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/30—Arrangements for executing machine instructions, e.g. instruction decode
- G06F9/38—Concurrent instruction execution, e.g. pipeline, look ahead
- G06F9/3885—Concurrent instruction execution, e.g. pipeline, look ahead using a plurality of independent parallel functional units
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/30—Arrangements for executing machine instructions, e.g. instruction decode
- G06F9/38—Concurrent instruction execution, e.g. pipeline, look ahead
- G06F9/3885—Concurrent instruction execution, e.g. pipeline, look ahead using a plurality of independent parallel functional units
- G06F9/3887—Concurrent instruction execution, e.g. pipeline, look ahead using a plurality of independent parallel functional units controlled by a single instruction for multiple data lanes [SIMD]
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/045—Combinations of networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/06—Physical realisation, i.e. hardware implementation of neural networks, neurons or parts of neurons
- G06N3/063—Physical realisation, i.e. hardware implementation of neural networks, neurons or parts of neurons using electronic means
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T1/00—General purpose image data processing
- G06T1/60—Memory management
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T5/00—Image enhancement or restoration
- G06T5/20—Image enhancement or restoration by the use of local operators
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/20—Image preprocessing
- G06V10/36—Applying a local operator, i.e. means to operate on image points situated in the vicinity of a given point; Non-linear local filtering operations, e.g. median filtering
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/40—Extraction of image or video features
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T2200/00—Indexing scheme for image data processing or generation, in general
- G06T2200/28—Indexing scheme for image data processing or generation, in general involving image processing hardware
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T2207/00—Indexing scheme for image analysis or image enhancement
- G06T2207/20—Special algorithmic details
- G06T2207/20084—Artificial neural networks [ANN]
Abstract
Verfahren, umfassend:Ausführen (1601) einer Schicht eines faltenden neuronalen Netzwerks auf einem Bildprozessor, der eine Matrix von Ausführungsbahnen und ein zweidimensionales Schieberegister aufweist, wobei das zweidimensionale Schieberegister einen jeweiligen lokalen Registerbereich für die Ausführungsbahnen bereitstellt, das Ausführen des faltenden neuronalen Netzwerks umfassend:a) Laden (1602) einer Ebene von Bilddaten eines dreidimensionalen Blocks von Bilddaten in das zweidimensionale Schieberegister;b) Durchführen (1603) einer zweidimensionalen Faltung der Ebene von Bilddaten mit einer Matrix von Koeffizientenwerten durch sequentielles:gleichzeitiges Multiplizieren, innerhalb der Ausführungsbahnen, jeweiliger Bildpunkt- und Koeffizientenwerte zwecks Bildens einer Matrix von Teilprodukten;gleichzeitiges Summieren, innerhalb der Ausführungsbahnen, der Teilprodukte mit jeweiligen Akkumulationen von Teilprodukten, die innerhalb des zweidimensionalen Registers für verschiedene Schablonen innerhalb der Bilddaten vorgehalten werden; undBewirken einer Ausrichtung von Werten für die zweidimensionale Faltung innerhalb der Ausführungsbahnen durch Verschieben von Inhalten innerhalb der zweidimensionalen Schieberegistermatrix; wobei der Bildprozessor konfiguriert ist, die Schicht des faltenden neuronalen Netzwerks und eine zweiten Schicht des faltenden neuronalen Netzwerks mit den Bilddaten zu multiplexen, die zwischen der Verarbeitung der Schicht des faltenden neuronalen Netzwerks und der zweiten Schicht des faltenden neuronalen Netzwerks lokal an den Ausführungsbahnen verbleiben.A method comprising:executing (1601) a layer of a convolutional neural network on an image processor having an array of execution lanes and a two-dimensional shift register, the two-dimensional shift register providing a respective local register range for the execution lanes, executing the convolutional neural network comprising: a) loading (1602) a plane of image data of a three-dimensional block of image data into the two-dimensional shift register; b) performing (1603) a two-dimensional convolution of the plane of image data with a matrix of coefficient values by sequentially:simultaneously multiplying, within execution lanes, respective pixel - and coefficient values to form a matrix of partial products;simultaneously summing, within execution paths, the partial products with respective accumulations of partial products occurring within the two-dimensional register for different sche blondes are kept within the image data; andcausing alignment of values for the two-dimensional convolution within the execution lanes by shifting contents within the two-dimensional shift register array; wherein the image processor is configured to multiplex the convolutional neural network layer and a second convolutional neural network layer with the image data remaining local to the execution lanes between processing of the convolutional neural network layer and the second convolutional neural network layer.
Description
TECHNISCHES GEBIETTECHNICAL AREA
Die Beschreibung bezieht sich auf die Bildverarbeitung und noch spezifischer auf ein faltendes neuronales Netzwerk („Convolutional Neural Network, CNN“) auf einem zweidimensionalen Bildprozessor.The description refers to image processing and more specifically to a convolutional neural network (CNN) on a two-dimensional image processor.
ALLGEMEINER STAND DER TECHNIKBACKGROUND ART
Die Bildverarbeitung beinhaltet in der Regel die Verarbeitung von Bildpunktwerten, die in einer Matrix angeordnet sind. Hierbei erfasst eine räumlich angeordnete zweidimensionale Matrix die zweidimensionale Beschaffenheit der Bilder (zusätzliche Dimensionen können unter anderem Zeit (z. B. eine Sequenz von zweidimensionalen Bildern) und Datentyp (z. B. Farben) einschließen). In einem typischen Szenario werden die angeordneten Bildpunktwerte von einer Kamera bereitgestellt, die ein Standbild oder eine Folge von Frames erzeugt hat, um Bewegungsbilder zu erfassen. Herkömmliche Bildprozessoren fallen in der Regel unter eines von zwei Extremen.Image processing typically involves the processing of pixel values arranged in a matrix. Here, a spatially arranged two-dimensional matrix captures the two-dimensional nature of the images (additional dimensions may include time (e.g., a sequence of two-dimensional images) and data type (e.g., colors) among others). In a typical scenario, the arrayed pixel values are provided by a camera that has generated a still image or a sequence of frames to capture moving images. Traditional image processors typically fall into one of two extremes.
Ein erstes Extrem führt Bildverarbeitungsschritte als Softwareprogramme aus, die auf einem Universalprozessor oder einem universell verwendbaren Prozessor (z. B. einem Universalprozessor mit Vektorbefehlserweiterungen) ausgeführt werden. Obwohl das erste Extrem in der Regel eine vielseitig einsetzbare Anwendungssoftware-Entwicklungsplattform bereitstellt, resultiert dessen Verwendung feinerer Datenstrukturen kombiniert mit den zugehörigen Verwaltungsdaten (z. B. Befehlsabruf und - dekodierung, Handhabung von chipinternen und chipexternen Daten, spekulative Ausführung) letztendlich in einem Verbrauch größerer Energiemengen pro Dateneinheit während der Ausführung des Programmcodes.A first extreme performs image processing steps as software programs running on a general-purpose processor or a general-purpose processor (e.g., a general-purpose processor with vector instruction extensions). Although the first extreme typically provides a versatile application software development platform, its use of finer data structures combined with associated overhead (e.g., instruction fetch and decode, handling of on-chip and off-chip data, speculative execution) ultimately results in greater consumption Amounts of energy per data unit during the execution of the program code.
Ein zweites, entgegengesetztes Extrem wendet stationäre, fest verdrahtete Schaltkreise auf viel größere Datenblöcke an. Die Verwendung von größeren (im Gegensatz zu feineren) Datenblöcken, die direkt auf benutzerdefinierte Schaltkreise angewendet werden, verringert den Energieverbrauch pro Dateneinheit erheblich. Jedoch führt die Verwendung von benutzerdefinierten stationären Funktionsschaltkreisen im Allgemeinen zu einer begrenzten Menge von Arbeitsschritten, die der Prozessor ausführen kann. Dementsprechend fehlt im zweiten Extrem die vielseitige Programmierumgebung (die mit dem ersten Extrem assoziiert ist).A second, opposite extreme applies stationary, hard-wired circuitry to much larger blocks of data. The use of larger (as opposed to finer) blocks of data applied directly to custom circuitry significantly reduces power consumption per unit of data. However, the use of user-defined stationary function circuits generally results in a limited set of operations that the processor can perform. Accordingly, the second extreme lacks the versatile programming environment (associated with the first extreme).
Eine Technologieplattform, die sowohl vielseitige Anwendungssoftware-Entwicklungsmöglichkeiten als auch eine verbesserte Energieeffizienz pro Dateneinheit bietet, bleibt eine wünschenswerte und dennoch fehlende Lösung.A technology platform that offers both versatile application software development capabilities and improved energy efficiency per data unit remains a desirable yet missing solution.
Quadeer, Wajahat et al. offenbaren in „Convolution engine: balancing efficiency & flexibility in specialized computing“ in Proceedings of the 40th Annual International Symposium on Computer Architecture. 2013. Seiten 24-35 eine Faltungsmaschine, die auf in rechnergestüzter Fotografie, Bildverarbeitung und Videoverarbeitung üblichen faltungsähnlichen Datenflüssen spezialisiert ist.Faltende neuronale Netzwerke sind zum Beispiel aus Wikipedia bekannt, insbesondere aus „Convolutional neural network“ in Wikipedia, the free enyclopedia (Bearbeitungsstand: 17.06.2016) URL: https://en.wikipedia.org/w/index.php?title Convolutional neural network&oldid=725801598.
KURZDARSTELLUNGEXECUTIVE SUMMARY
Ein Verfahren wird beschrieben, welches das Ausführen einer Schicht eines faltenden neuronalen Netzwerks auf einem Bildprozessor, der eine Matrix von Ausführungsbahnen und ein zweidimensionales Schieberegister aufweist, beinhaltet. Das zweidimensionale Schieberegister stellt einen jeweiligen lokalen Registerbereich für die Ausführungsbahnen bereit. Das Ausführen des faltenden neuronalen Netzwerks beinhaltet das Laden einer Ebene von Bilddaten eines dreidimensionalen Blocks von Bilddaten in das zweidimensionale Schieberegister. Das Ausführen des faltenden neuronalen Netzwerks beinhaltet ebenfalls das Durchführen einer zweidimensionalen Faltung der Ebene von Bilddaten mit einer Matrix von Koeffizientenwerten durch sequentielles: gleichzeitiges Multiplizieren, innerhalb der Ausführungsbahnen, jeweiliger Bildpunkt- und Koeffizientenwerte zwecks Bildens einer Matrix von Teilprodukten; gleichzeitiges Summieren, innerhalb der Ausführungsbahnen, der Teilprodukte mit jeweiligen Akkumulationen von Teilprodukten, die innerhalb des zweidimensionalen Registers für verschiedene Schablonen innerhalb der Bilddaten vorgehalten werden; und Bewirken einer Ausrichtung von Werten für die zweidimensionale Faltung innerhalb der Ausführungsbahnen durch Verschieben von Inhalt innerhalb der zweidimensionalen Schieberegistermatrix.A method is described which involves executing a layer of a convolutional neural network on an image processor having an array of execution paths and a two-dimensional shift register. The two-dimensional shift register provides a respective local register area for the execution threads. Executing the convolutional neural network involves loading a plane of image data of a three-dimensional block of image data into the two-dimensional shift register. Executing the convolutional neural network also involves performing a two-dimensional convolution of the plane of image data with a matrix of coefficient values by sequentially: simultaneously multiplying, within the execution paths, respective pixel and coefficient values to form a matrix of partial products; simultaneously summing, within the execution paths, the partial products with respective accumulations of partial products held within the two-dimensional register for different templates within the image data; and causing values for the two-dimensional convolution to align within the execution lanes by shifting content within the two-dimensional shift register array.
Eine Vorrichtung wird ebenfalls beschrieben, die über Mittel zum Ausführen einer Schicht eines faltenden neuronalen Netzwerks auf einem Bildprozessor verfügt, der eine Matrix von Ausführungsbahnen und ein zweidimensionales Schieberegister aufweist. Das zweidimensionale Schieberegister stellt einen jeweiligen lokalen Registerbereich für die Ausführungsbahnen bereit. Das Mittel zum Ausführen des faltenden neuronalen Netzwerks beinhaltet Mittel zum Laden einer Ebene von Bilddaten eines dreidimensionalen Blocks von Bilddaten in das zweidimensionale Schieberegister. Das Mittel zum Ausführen des faltenden neuronalen Netzwerks beinhaltet ebenfalls Mittel zum Durchführen einer zweidimensionalen Faltung der Ebene von Bilddaten mit einer Matrix von Koeffizientenwerten durch sequentielles: gleichzeitiges Multiplizieren, innerhalb der Ausführungsbahnen, jeweiliger Bildpunkt- und Koeffizientenwerte zwecks Bildens einer Matrix von Teilprodukten; gleichzeitiges Summieren, innerhalb der Ausführungsbahnen, der Teilprodukte mit jeweiligen Akkumulationen von Teilprodukten, die innerhalb des zweidimensionalen Registers für verschiedene Schablonen innerhalb der Bilddaten vorgehalten werden; und Bewirken einer Ausrichtung von Werten für die zweidimensionale Faltung innerhalb der Ausführungsbahnen durch Verschieben von Inhalt innerhalb der zweidimensionalen Schieberegistermatrix.An apparatus is also described having means for executing a layer of a convolutional neural network on an image processor having an array of execution paths and a two-dimensional shift register. The two-dimensional shift register provides a respective local register area for the execution threads. The means for executing the convolutional neural network includes means for loading a plane of image data of a three-dimensional block of image data into the two-dimensional shift register. The means for executing the convolutional neural network also includes means for performing a two-dimensional convolution of the plane of image data with a matrix of coefficient values by sequentially: simultaneously multiplying, within the execution paths, respective pixel and coefficient values to form a matrix of partial products; simultaneously summing, within the execution paths, the partial products with respective accumulations of partial products held within the two-dimensional register for different templates within the image data; and causing values for the two-dimensional convolution to align within the execution lanes by shifting content within the two-dimensional shift register array.
Figurenlistecharacter list
Die folgende Beschreibung und begleitenden Zeichnungen dienen dazu, verschiedene Ausführungsformen der Erfindung zu veranschaulichen. In den Zeichnungen:
-
1 zeigt eine Ausführungsform einer Bildprozessor-Hardwarearchitektur; -
2a ,2b ,2c ,2d und2e zeigen das Parsen von Bilddaten in eine Zeilengruppe, das Parsen einer Zeilengruppe in ein Blatt und die an einem Blatt mit sich überschneidenden Schablonen durchgeführte Operation; -
3a zeigt eine Ausführungsform eines Schablonenprozessors; -
3b zeigt eine Ausführungsform eines Befehlsformats; -
4 zeigt eine Ausführungsform einer Datenberechnungseinheit innerhalb eines Schablonenprozessors; -
5a ,5b ,5c ,5d ,5e ,5f ,5g ,5h ,5i ,5j und5k zeigen ein Beispiel für die Verwendung einer zweidimensionalen Verschiebungsmatrix und einer Ausführungsbahnmatrix, um ein Paar angrenzender Ausgangsbildpunktwerte mit sich überschneidenden Schablonen zu bestimmen; -
6 zeigt eine Ausführungsform einer Einheitszelle für eine integrierte Ausführungsbahnmatrix und eine zweidimensionale Verschiebungsmatrix; -
7 zeigt eine 3D-Faltung; -
8 zeigt eine CNN-Schicht; -
9a zeigt eine 3D-Faltung mit Bild a Koeffizientenebenen; -
9b zeigt eine 2D-Faltung von zwei 3 x 3-Schablonen mit Bilddaten mit einem entsprechenden Satz von Koeffizienten; -
10a ,10b ,10c ,10d ,10e ,10f ,10g ,10h ,10i und10j zeigen die Ausführung einer CNN-Schicht mit Bildebenen und Koeffizientensätzen, die Ebenen von Koeffizienten aufweisen; -
11a ,11b ,11c ,11d ,11e ,11f ,11g ,11h ,11i ,11j zeigen eine zweidimensionale Faltung für zwei 3 x 3-Schablonen mit einem Bildprozessor, der ein zweidimensionales Schieberegister aufweist; -
12 zeigt eine erste Bildprozessor-CNN-Schicht-Konfiguration; -
13 zeigt eine zweite Bildprozessor-CNN-Schicht-Konfiguration; -
14 zeigt eine dritte Bildprozessor-CNN-Schicht-Konfiguration; -
15 bezieht sich auf das Multiplexen mehrerer CNN-Schichten auf einem Bildprozessor; -
16 zeigt ein Verfahren zum Ausführen einer CNN-Schicht auf einem Bildprozessor; -
17 stellt ein Computersystem dar.
-
1 Figure 12 shows one embodiment of an image processor hardware architecture; -
2a ,2 B ,2c ,2d and2e show the parsing of image data into a rowgroup, the parsing of a rowgroup into a sheet, and the operation performed on a sheet with intersecting templates; -
3a Figure 12 shows an embodiment of a template processor; -
3b Figure 12 shows one embodiment of an instruction format; -
4 Figure 12 shows an embodiment of a data calculation unit within a template processor; -
5a ,5b ,5c ,5d ,5e ,5f ,5g ,5h ,5i ,5y and5k show an example of using a two-dimensional displacement matrix and a execution trajectory matrix to determine a pair of adjacent output pixel values with overlapping templates; -
6 Figure 12 shows an embodiment of a unit cell for an integrated execution trajectory matrix and a two-dimensional displacement matrix; -
7 shows a 3D convolution; -
8th shows a CNN layer; -
9a shows a 3D convolution with image a coefficient planes; -
9b shows a 2D convolution of two 3 x 3 templates with image data with a corresponding set of coefficients; -
10a ,10b ,10c ,10d ,10e ,10f ,10g ,10 a.m ,10i and10y show the implementation of a CNN layer with image planes and coefficient sets comprising planes of coefficients; -
11a ,11b ,11c ,11d ,11e ,11f ,11g ,11 a.m ,11i ,11y show a two-dimensional convolution for two 3 x 3 templates with an image processor having a two-dimensional shift register; -
12 Figure 1 shows a first image processor CNN layer configuration; -
13 shows a second image processor CNN layer configuration; -
14 shows a third image processor CNN layer configuration; -
15 refers to the multiplexing of multiple CNN layers on an image processor; -
16 shows a method for running a CNN layer on an image processor; -
17 represents a computer system.
AUSFÜHRLICHE BESCHREIBUNGDETAILED DESCRIPTION
a. Bildprozessor-Hardware-Architektur und -Betrieba. Image processor hardware architecture and operation
In einer Ausführungsform wird der Programmcode kompiliert und auf einen entsprechenden Schablonenprozessor 102 geladen, um die zuvor von einem Softwareentwickler definierten Bildverarbeitungsvorgänge auszuführen (der Programmcode kann je nach Konzipierung und Implementierung auch auf den zugehörigen Blattgenerator des Schablonenprozessors 103 geladen werden). In zumindest einigen Fällen kann eine Bildverarbeitungspipeline realisiert werden, indem ein erstes Kernprogramm für eine erste Pipelinephase in einen ersten Schablonenprozessor 102_1 geladen, ein zweites Kernprogramm für eine zweite Pipelinephase in einen zweiten Schablonenprozessor 102_2 , geladen wird usw., wobei das erste Kernsystem die Funktionen der ersten Pipelinephase durchführt, das zweite Kernsystem die Funktionen der zweiten Pipelinephase durchführt usw., und zusätzliche Steuerablaufverfahren installiert werden, um Ausgabebilddaten von einer Pipelinephase zur nächsten Pipelinephase zu leiten.In one embodiment, the program code is compiled and loaded onto an
In anderen Konfigurationen kann der Bildprozessor als eine parallele Maschine realisiert sein, die zwei oder mehr Schablonenprozessoren 102_1 , 102_2 aufweist, die auf demselben Kernprogrammcode betrieben werden. Zum Beispiel kann ein hochgradig dichter und hoher Datenratenstrom von Bilddaten verarbeitet werden, indem Frames über mehrere Schablonenprozessoren verteilt werden, von denen jeder dieselbe Funktion ausführt.In other configurations, the image processor may be implemented as a parallel machine having two or more template processors 102_1, 102_2 running on the same core program code. For example, a highly dense and high data rate stream of image data can be processed by distributing frames across multiple template processors, each performing the same function.
In noch anderen Konfigurationen kann im Wesentlichen jeder ausgerichtete, azyklische Graph (DAG) von Kernsystemen auf den Hardwareprozessor geladen werden, indem jeweilige Schablonenprozessoren mit deren eigenen jeweiligen Kernsystemprogrammcodes konfiguriert und geeignete Steuerablauf-Hooks in die Hardware konfiguriert werden, um Ausgabebilder von einem Kernsystem an den Eingang eines nächsten Kernsystems in dem DAG-Design zu leiten.In still other configurations, essentially any aligned acyclic graph (DAG) can be loaded from core systems onto the hardware processor by configuring respective template processors with their own respective core system program codes and configuring appropriate control flow hooks into the hardware to output images from a core system to the to direct input of a next core system in the DAG design.
Bei einem allgemeinen Ablauf werden die Frames der Bilddaten von einer Makro-E/A-Einheit 105 empfangen und zu einer oder mehreren der Zeilenpuffereinheiten 101 auf einer Frame-per-Frame-Basis übermittelt. Eine bestimmte Zeilenpuffereinheit parst ihren Frame aus Bilddaten in einen kleineren Bereich von Bilddaten, der als „Zeilengruppe“ bezeichnet wird, und führt dann die Zeilengruppe durch das Netzwerk 104 zu einem bestimmten Blattgenerator. Eine vollständige oder „volle“ singuläre Zeilengruppe kann sich beispielsweise aus den Daten mehrerer zusammenhängender vollständiger Zeilen oder Spalten eines Frames zusammensetzen (der Kürze halber bezieht sich die vorliegende Beschreibung hauptsächlich auf zusammenhängende Zeilen). Der Blattgenerator parst ferner die Zeilengruppe von Bilddaten in einen kleineren Bereich von Bilddaten, der als „Blatt“ bezeichnet wird, und präsentiert das Blatt seinem entsprechenden Schablonenprozessor.In a general flow, frames of image data are received by a macro I/
Im Falle einer Bildverarbeitungspipeline oder eines DAG-Ablaufs mit einem einzigen Eingang werden im Allgemeinen Eingabeframes an die gleiche Zeilenpuffereinheit 101_1 geleitet, die die Bilddaten in Zeilengruppen parst und die Zeilengruppen zu dem Blattgenerator 103_1 leitet, dessen entsprechender Schablonenprozessor 102_1 den Code des ersten Kernsystems in der Pipeline/dem DAG ausführt. Nach Beendigung der Operationen durch den Schablonenprozessor 102_1 an den von ihm verarbeiteten Zeilengruppen sendet der Blattgenerator 103_1 Ausgabezeilengruppen an eine „nachgelagerten“ Zeilenpuffereinheit 101_2 (in manchen Anwendungsfällen kann die Ausgabezeilengruppe zurück an die gleiche Zeilenpuffereinheit 101_1 gesendet werden, die zuvor die Eingabezeilengruppen gesendet hatte).In the case of a single-input image processing pipeline or DAG flow, input frames are generally passed to the same line buffer unit 101_1, which parses the image data into groups of lines and passes the groups of lines to the sheet generator 103_1, whose corresponding template processor 102_1 contains the code of the first core system in the Runs the pipeline/DAG. Upon completion of operations by the template processor 102_1 on the rowgroups it is processing, the sheet generator 103_1 sends output rowgroups to a "downstream" line buffer unit 101_2 (in some use cases the output rowgroup may be sent back to the same line buffer unit 101_1 that previously sent the input rowgroups).
Ein oder mehrere „Abnehmerkernsysteme“, die die nächste Phase/Operation in der Pipeline/dem DAG darstellen, die auf deren eigenen jeweiligen anderen Blattgenerator und Schablonenprozessor (z. B. Blattgenerator 103_2 und Schablonenprozessor 102_2 ) ausgeführt werden, empfangen anschließend die von dem ersten Schablonenprozessor 102_1 erzeugten Bilddaten von der nachgelagerten Zeilenpuffereinheit 101_2 . Auf diese Weise werden die Ausgabedaten eines „Erzeugerkernsystems“, das auf einem ersten Schablonenprozessor betrieben wird, an ein „Abnehmerkernsystem“ weitergeleitet, das auf einem zweiten Schablonenprozessor betrieben wird, wobei das Abnehmerkernsystem nach dem Erzeugerkernsystem den nächsten Satz von Arbeitsschritten gemäß des Designs der gesamten Pipeline oder des DAGs ausführt.One or more "taker core systems" representing the next phase/operation in the pipeline/DAG executing on their own respective other sheet generator and template processor (e.g., sheet generator 103_2 and template processor 102_2) then receive those from the first Template processor 102_1 generated image data from the downstream line buffer unit 101_2. In this way, the output data of a "producer core system" running on a first template processor is passed to a "taker core system" running on a second template processor, with the consumer core system after the producer core system performing the next set of operations according to the design of the entire Pipeline or DAG runs.
Ein Schablonenprozessor 102 ist dafür ausgelegt, gleichzeitig an mehreren sich überschneidenden Schablonen von Bilddaten zu arbeiten. Die mehreren sich überschneidenden Schablonen und die interne Hardwareverarbeitungskapazität des Schablonenprozessors bestimmen effektiv die Größe eines Blattes. Hier arbeiten innerhalb eines Schablonenprozessors 102 Matrizen von Ausführungsbahnen zusammen, um gleichzeitig den Bilddatenoberflächenbereich zu verarbeiten, der von den mehreren sich überschneidenden Schablonen bedeckt ist.A
Wie nachstehend näher beschrieben, werden in verschiedenen Ausführungsformen, Blätter von Bilddaten in eine zweidimensionale Registermatrixstruktur innerhalb der Schablonenprozessoreinheiten 102 geladen. Es wird davon ausgegangen, dass die Verwendung von Blättern und die zweidimensionale Registermatrixstruktur für effektive Energieverbrauchsverbesserungen sorgen, indem eine große Datenmenge in einen großen Registerbereich bewegt wird, so wird beispielsweise eine einzelne Ladeoperation mit direkt an den Daten ausgeführten Verarbeitungsschritten unmittelbar danach durch eine Ausführungsbahnmatrix durchgeführt. Zudem stellt die Verwendung einer Ausführungsbahnmatrix und einer entsprechenden Registermatrix verschiedene Schablonengrößen bereit, die leicht programmierbar/konfigurierbar sind.As described in more detail below, in various embodiments, sheets of image data are loaded into a two-dimensional register matrix structure within
Aufgrund der sich, wie in
Wenn die Zeilengruppe 203 der Eingabebilddaten durch die Zeilenpuffereinheit definiert und an die Blattgeneratoreinheit übermittelt worden ist, parst die Blattgeneratoreinheit die Zeilengruppe ferner in feinere Blätter, die an die Hardwarebeschränkungen des Schablonenprozessors präziser angepasst sind. Insbesondere wird in einer Ausführungsform, wie nachfolgend näher beschrieben, jeder Schablonenprozessor aus einer zweidimensionalen Schieberegistermatrix gebildet. Die zweidimensionale Schieberegistermatrix verschiebt im Wesentlichen Bilddaten „unterhalb“ einer Matrix von Ausführungsbahnen, wobei das Muster der Verschiebung bewirkt, dass jede Ausführungsbahn innerhalb ihrer eigenen jeweiligen Schablone an Daten arbeitet (d. h. jede Ausführungsbahn ihre eigene Schablone von Informationen verarbeitet, um eine Ausgabe für diese Schablone zu erzeugen). In einer Ausführungsform sind Blätter Oberflächenbereiche von Eingabebilddaten, die die zweidimensionale Schieberegistermatrix „ausfüllen“ oder anderweitig in dieselbe geladen werden.Further, when the row set 203 of the input image data has been defined by the line buffer unit and communicated to the sheet generator unit, the sheet generator unit parses the row set into finer sheets that more precisely conform to the hardware limitations of the template processor. In particular, in one embodiment, as further described below, each template processor is formed from a two-dimensional shift register array. The two-dimensional shift register array essentially shifts image data "beneath" an array of threads, with the pattern of shifting causing each thread to operate on data within its own respective template (i.e., each thread processes its own template of information to produce an output for that template to create). In one embodiment, leaves are surface areas of input image data that "fill in" or are otherwise loaded into the two-dimensional shift register matrix.
Wie nachfolgend näher beschrieben, gibt es in verschiedenen Ausführungsformen tatsächlich mehrere Schichten von zweidimensionalen Registerdaten, die bei jedem Zyklus verschoben werden können. Zur Vereinfachung verwendet ein Großteil der vorliegenden Beschreibung einfach den Begriff „zweidimensionales Schieberegister“ und dergleichen, um auf Strukturen zu verweisen, die eine oder mehrere dieser Schichten zweidimensionaler Registerdaten aufweisen, die verschoben werden können.As described in more detail below, in various embodiments there are actually multiple layers of two-dimensional register data that can be shifted on each cycle. For convenience, much of the present description simply uses the term "two-dimensional shift register" and the like to refer to structures that include one or more of these layers of two-dimensional register data that can be shifted.
Wie in
Wie in
Zu beachten ist, dass zwischen den Daten des ersten Blattes 204 und den Daten des zweiten Blattes 205 aufgrund der Randbereiche der Schablonen, die einen Ausgabebildpunktort umgeben, eine gewisse Überschneidung vorliegt. Die Überschneidung könnte einfach gehandhabt werden, indem der Blattgenerator die sich überschneidenden Daten zweimal überträgt. In alternativen Implementierungen kann, um dem Schablonenprozessor ein nächstes Blatt zuzuführen, der Blattgenerator damit fortfahren, ausschließlich neue Daten an den Schablonenprozessor zu senden, während der Schablonenprozessor die sich überschneidenden Daten aus dem vorhergehenden Blatt verwendet.Note that there is some overlap between the data of the
b. Schablonenprozessordesign und -betriebb. Template processor design and operation
Die E/A-Einheit 304 ist verantwortlich für das Laden von „eingegebenen“ Datenblättern, die von dem Blattgenerator empfangen wurden, in die Datenberechnungseinheit 301 sowie das Speichern der von dem Schablonenprozessor „ausgegebenen“ Blätter im Blattgenerator. In einer Ausführungsform umfasst das Laden von Blattdaten in die Datenberechnungseinheit 301 das Parsen eines empfangenen Blattes in die Zeilen/Spalten der Bilddaten sowie das Laden der Zeilen/Spalten der Bilddaten in die zweidimensionale Schieberegisterstruktur 306 oder in die jeweiligen Arbeitsspeicher 307 der Zeilen/Spalten der Ausführungsbahnmatrix (wie nachfolgend näher beschrieben). Wird das Blatt anfänglich in die Speicher 307 geladen, können die einzelnen Ausführungsbahnen innerhalb der Ausführungsbahnmatrix 305 dann die Blattdaten, sofern geeignet (z. B. als Ladebefehl kurz vor der Operation der Blattdaten), in die zweidimensionale Schieberegisterstruktur 306 der Arbeitsspeicher 307 laden. Nach Beendigung des Ladens eines Datenblattes in die Registerstruktur 306 (ob direkt aus einem Blattgenerator oder aus den Speichern 307) arbeiten die Ausführungsbahnen der Ausführungsbahnmatrix 305 an den Daten und „schreiben“ letztendlich die fertigen Daten als ein Blatt direkt „zurück“ in den Blattgenerator oder in die Arbeitsspeicher 307 . Wenn die Ausführungsbahnen in die Arbeitsspeicher 907 zurückschreiben, ruft die E/A-Einheit 304 die Daten aus den Arbeitsspeichern 307 ab, um ein Ausgabeblatt zu bilden, das dann an den Blattgenerator weitergeleitet wird.The I/
Der Skalarprozessor 302 beinhaltet einen Programmcontroller 309 , der die Befehle des Programmcodes des Schablonenprozessors aus dem Skalarspeicher 303 einliest und die Befehle an die Ausführungsbahnen in der Ausführungsbahnmatrix 305 ausgibt. In einer Ausführungsform wird ein einzelner Befehl auf alle Ausführungsbahnen innerhalb der Matrix 305 übertragen, um ein einzelne Anweisung auf multiple Daten(„Singlelnstruction-Multiple-Data, SIMD“)-ähnliches Verhalten der Datenberechnungseinheit 301 zu bewirken. In einer Ausführungsform, beinhaltet das Befehlsformat der Befehle, die aus dem Skalarspeicher 303 eingelesen und an die Ausführungsbahnen der Ausführungsbahnmatrix 305 ausgegeben werden, ein sehr langes Befehlswortformat (VLIW), welches mehr als einen Operationscode pro Befehl beinhaltet. In einer weiteren Ausführungsform beinhaltet das VLIW-Format sowohl einen ALU-Operationscode, der eine mathematische Funktion anweist, die von der ALU einer Ausführungsbahn ausgeführt wird (wobei, wie nachstehend beschrieben, in einer Ausführungsform mehr als eine herkömmliche ALU-Operation angegeben sein kann), als auch einen Speicheroperationscode (der eine Speicheroperation für eine spezifische Ausführungsbahn oder eine Gruppe von Ausführungsbahnen anweist).The
Der Begriff „Ausführungsbahn“ bezieht sich auf eine Gruppe von einer oder mehreren Ausführungseinheiten, die einen Befehl ausführen können (z. B. eine Logikschaltung, die einen Befehl ausführen kann). Eine Ausführungsbahn kann in verschiedenen Ausführungsformen jedoch prozessorähnlichere Funktionen und nicht nur Ausführungseinheiten beinhalten. Beispielsweise kann eine Ausführungsbahn neben einer oder mehreren Ausführungseinheiten auch Logikschaltungen beinhalten, die einen empfangenen Befehl dekodieren, oder für den Fall multiple Anweisungen auf multiple Daten(„Multiple-Instruction-Multiple-Data, MIMD“)-ähnlicherer Architekturen eine Logikschaltung beinhalten, die einen Befehl abruft und dekodiert. In Bezug auf MIMD-ähnliche Ansätze kann, obwohl ein zentraler Programmsteuerungsansatz hier weitgehend beschrieben wurde, auch ein verteilterer Ansatz in verschiedenen alternativen Ausführungsformen (z. B. unter anderem auch Programmcode und ein Programmcontroller innerhalb jeder Ausführungsbahn der Matrix 305) implementiert werden.The term "execution thread" refers to a group of one or more execution units that can execute an instruction (e.g., a logic circuit that can execute an instruction). However, in various embodiments, an execution thread may include more processor-like functions and not just execution units. For example, in addition to one or more execution units, an execution thread may also include logic circuitry that decodes a received instruction, or in the case of multiple-instruction-multiple-data (MIMD)-like architectures, a logic circuitry that decodes a Command retrieves and decodes. With respect to MIMD-like approaches, although a centralized program control approach has been broadly described herein, a more distributed approach may also be implemented in various alternative embodiments (e.g., including program code and a program controller within each thread of
Die Kombination einer Ausführungsbahnmatrix 305 , eines Programmcontrollers 309 und einer zweidimensionalen Schieberegisterstruktur 306 stellt eine weitgehend anpassbare/konfigurierbare Hardware-Plattform für ein breites Spektrum programmierbarer Funktionen bereit. Beispielsweise können Anwendungssoftwareentwickler in der Lage sein, Kernsysteme mit einem breiten Spektrum unterschiedlicher Funktionsfähigkeiten sowie Abmessungen (z. B. Schablonengrößen) zu programmieren, da die einzelnen Ausführungsbahnen in der Lage sind, eine breite Palette von Funktionen auszuführen und ohne Weiteres auf Eingabebilddaten in der Nähe einer beliebigen Ausgabematrixposition zuzugreifen.The combination of an
Abgesehen davon, dass diese als Datenspeicher für Bilddaten genutzt werden, die durch die Ausführungsbahnmatrix 305 bearbeitet werden, können die Arbeitsspeicher 307 zudem eine oder mehrere Wertetabellen verwalten. In verschiedenen Ausführungsformen können eine oder mehrere skalare Wertetabellen auch innerhalb des skalaren Speichers 303 instanziiert werden.In addition to being used as data storage for image data processed by
Ein skalarer Nachschlagevorgang beinhaltet das Übermitteln desselben Datenwertes aus derselben Wertetabelle von demselben Index an sämtliche Ausführungsbahnen innerhalb der Ausführungsbahnmatrix 305 . In verschiedenen Ausführungsformen wird das oben beschriebene VLIW-Befehlsformat erweitert, um darüber hinaus einen skalaren Operationscode einzuschließen, der eine vom Skalarprozessor ausgeführte Nachschlageoperation in eine skalare Wertetabelle leitet. Der für die Verwendung mit dem Operationscode angegebene Index kann ein unmittelbarer Operand sein oder von einem anderen Datenspeicherort abgerufen werden. Unabhängig davon umfasst in einer Ausführungsform ein Nachschlagevorgang in einer skalaren Wertetabelle innerhalb des skalaren Speichers im Wesentlichen das Senden desselben Datenwertes an alle Ausführungsbahnen innerhalb der Ausführungsbahnmatrix 305 während desselben Taktzyklus. Weitere Details zur Verwendung und Operation von Wertetabellen werden nachfolgend bereitgestellt.A scalar lookup involves sending the same data value from the same lookup table from the same index to all execution lanes within
Ein Feld 354 für einen oder mehrere unmittelbare Operanden ist ebenfalls enthalten. Welche der Befehle 351, 352 , 353 welche unmittelbaren Operandeninformationen verwenden, kann im Befehlsformat festgelegt sein. Jeder der Befehle 351, 352 , 353 beinhaltet zudem seinen eigenen Eingabeoperanden sowie resultierende Informationen (z. B. lokale Register für ALU-Operationen und ein lokales Register sowie eine Speicheradresse für Speicherzugriffsbefehle). In einer Ausführungsform wird der Skalarbefehl 351 durch den Skalarprozessor ausgeführt, bevor die Ausführungsbahnen innerhalb der Ausführungsbahnmatrix einen der zwei anderen Befehle 352 , 353 ausführen. Das heißt, die Ausführung des VLIWWortes beinhaltet einen ersten Zyklus, bei dem der Skalarbefehl 351 ausgeführt wird, gefolgt von einem zweiten Zyklus, bei dem die anderen Befehle 352 , 353 ausgeführt werden können (es ist zu beachten, dass in verschiedenen Ausführungsformen die Befehle 352 und 353 parallel ausgeführt werden können).A
In einer Ausführungsform beinhalten die Skalarbefehle, die von dem Skalarprozessor 302 ausgeführt werden, Befehle, die an den Blattgenerator 103 ausgegeben werden, um Blätter von/in die Speicher oder 2D-Schieberegister 306 der Datenberechnungseinheit 301 zu laden/ zu speichern. Hier kann der Betrieb des Blattgenerators von der Operation der Zeilenpuffereinheit 101 oder von anderen Variablen abhängig sein, die ein Vorlaufzeitverständnis der Anzahl von Zyklen verhindern, die der Blattgenerator 103 ausführen wird, um einen Befehl zu beenden, der von dem Skalarprozessor 302 ausgegeben wird. Dementsprechend beinhaltet in einer Ausführungsform jedes beliebige VLIW-Wort, dessen Skalarbefehl 351 dem Blattgenerator 103 entspricht oder diesen anderweitig veranlasst, einen Befehl auszugeben, auch Nicht-Operations-(NOOP-)Befehle in den anderen zwei Befehlsfeldern 352 , 353 . Der Programmcode gibt dann eine Schleife von NOOP-Befehlen für Befehlsfelder 352 , 353 ein, bis der Blattgenerator seine Ladung von/Speicherung unter der Datenberechnungseinheit beendet. Hier kann bei der Ausgabe eines Befehls an den Blattgenerator der Skalarprozessor ein Bit eines Verriegelungsregisters setzen, das der Blattgenerator nach Beendigung des Befehls zurücksetzt. Während der NOOP-Schleife überwacht der Skalarprozessor das Bit des Verriegelungsbits. Sobald der Skalarprozessor erkennt, dass der Blattgenerator seinen Befehl beendet hat, beginnt die normale Ausführung erneut.In one embodiment, the scalar instructions executed by
Die Ausführungsbahnmatrix 405 und die Schieberegisterstruktur 406 sind in Bezug zueinander fixiert. Die Daten innerhalb der Schieberegistermatrix 406 verschieben sich jedoch in einer strategischen und koordinierten Weise, um zu bewirken, dass jede Ausführungsbahn in der Ausführungsbahnmatrix eine andere Schablone innerhalb der Daten verarbeitet. Demgemäß bestimmt jede Ausführungsbahn den Ausgabebildwert für einen anderen Bildpunkt in dem erzeugten Ausgabeblatt. Aus der Architektur von
Einige zu beachtende architektonische Merkmale der Datenberechnungseinheit 401 beinhalten die Schieberegisterstruktur 406 , die breitere Abmessungen als die Ausführungsbahnmatrix 405 aufweist. Das heißt, es gibt einen „Ring“ von Registern 409 außerhalb der Ausführungsbahnmatrix 405 . Obwohl der Ring 409 auf zwei Seiten der Ausführungsbahnmatrix dargestellt ist, kann der Ring je nach Implementierung auf weniger (einer) oder mehr (drei oder vier) Seiten der Ausführungsbahnmatrix 405 existieren. Der Ring 405 dient dazu, einen „Ausweitungsraum“ für Daten bereitzustellen, die sich außerhalb der Grenzen der Ausführungsbahnmatrix 405 ausweiten, wenn die Daten „unterhalb“ der Ausführungsbahnen 405 verschoben werden. In einem einfachen Fall benötigt eine 5 x 5-Schablone, die am rechten Rand der Ausführungsbahnmatrix 405 zentriert ist, vier Ringregisterorte weiter nach rechts, wenn die linksseitigen Bildpunkte der Schablone verarbeitet werden. Zur Vereinfachung der Zeichnung zeigt
Zusätzlicher Überlaufraum wird durch Direktzugriffsspeicher 407 bereitgestellt, die mit jeder Zeile und/oder jeder Spalte in der Matrix oder Teilen davon gekoppelt sind (z. B. kann ein Direktzugriffsspeicher eines „Bereichs“ der Ausführungsbahnmatrix zugewiesen werden, die reihenweise 4 Ausführungsbahnen und spaltenweise 2 Ausführungsbahnen überspannt. Zur Vereinfachung bezieht sich der Rest der Anwendung hauptsächlich auf zeilen- und/oder spaltenbasierte Zuordnungsschemen). Wenn die Kernsystemoperationen einer Ausführungsbahn es erfordern, Bildpunktwerte außerhalb der zweidimensionalen Schieberegistermatrix 406 zu verarbeiten (was einige Bildverarbeitungsroutinen ggf. erfordern), kann sich Ebene der Bilddaten z. B. vom Ringbereich 409 in den Direktzugriffsspeicher 407 weiter überlaufen. Betrachten wir zum Beispiel eine 6 x 6-Schablone, bei der die Hardware einen Ringbereich von nur vier Speicherelementen rechts von einer Ausführungsbahn am rechten Rand der Ausführungsbahnmatrix beinhaltet. In diesem Fall müssten die Daten vom rechten Rand des Rings 409 weiter nach rechts verschoben werden, um die Schablone vollständig zu verarbeiten. Daten, die außerhalb des Ringbereichs 409 verschoben werden, würden dann in den Direktzugriffsspeicher 407 überlaufen. Andere Anwendungen der Direktzugriffsspeicher 407 und des Schablonenprozessors aus
Jede Ausführungsbahn verfügt zudem in einem lokalen Register R2 über den Inhalt „darunter“ in der zweidimensionalen Verschiebungsmatrix. Somit ist R1 ein physisches Register der Ausführungsbahn, während R2 ein physisches Register der zweidimensionalen Schieberegistermatrix ist. Die Ausführungsbahn beinhaltet eine ALU, die mit Operanden arbeiten kann, die von R1 und/oder R2 bereitgestellt werden. Wie nachfolgend näher beschrieben, wird in einer Ausführungsform das Schieberegister tatsächlich mit mehreren (einer „Tiefe“ von) Speicher-/ Registerelementen pro Matrixposition implementiert, die Verschiebungsaktivität ist jedoch auf eine Ebene von Speicherelementen begrenzt (z. B. kann sich nur eine Ebene von Speicherelementen pro Zyklus verschieben).
Wie in
Wie in
In dem Beispiel aus
In einer Ausführungsform wird die zweidimensionale Schieberegisterstruktur implementiert, indem es während eines einzigen Zyklus erlaubt wird, dass der Inhalt eines beliebigen von (nur) eines der Register R2 bis R4 zu einer seiner angrenzenden Registerdateien durch den Ausgangsmultiplexer 603 „heraus“ verschoben wird, und der Inhalt eines beliebigen von (nur) eines der Register R2 bis R4 durch den Inhalt ersetzt wird, der von einem entsprechenden Nachbarn durch den Eingangsmultiplexer 604 „hinein“ verschoben wird, sodass Verschiebungen zwischen den Nachbarn in gleicher Richtung (z. B. alle Ausführungsbahnen nach links, alle Ausführungsbahnen nach rechts usw.) erfolgen. Obwohl es für ein gleiches Register üblich sein kann, dass dessen Inhalt verschoben und durch den Inhalt ersetzt wird, der in demselben Zyklus verschoben wird, erlaubt die Multiplexeranordnung 603 , 604 unterschiedliche Schiebequellen- und Schiebezielregister innerhalb einer gleichen Registerdatei während eines gleichen Zyklus.In one embodiment, the two-dimensional shift register structure is implemented by allowing, during a single cycle, the contents of any one of (only) one of registers R2 through R4 to be shifted "out" to one of its adjacent register files through
Wie in
Obwohl in einer Ausführungsform der Inhalt von nur einem Register pro Ausführungsbahn pro Zyklus verschoben werden darf, können andere Ausführungsformen zulassen, dass der Inhalt von mehr als einem Register herein-/herausverschoben wird. Beispielsweise kann der Inhalt von zwei Registern während eines gleichen Zyklus heraus-/hereinverschoben werden, wenn eine zweite Instanz der in
Falls weniger als der gesamte Inhalt der Registerdateien einer Ausführungsbahn während einer Verschiebungssequenz verschoben wird, ist zu beachten, dass der Inhalt der nicht verschobenen Register jeder Ausführungsbahn an Ort und Stelle bleibt (nicht verschoben wird). Dementsprechend bleibt jeder nicht verschobene Inhalt, der nicht durch eingeschobenen Inhalt ersetzt wird, durch den Verschiebungszyklus hinweg lokal auf der Ausführungsbahn. Die in jeder Ausführungsbahn beobachtete Speichereinheit („M“) wird verwendet, um Daten von/zu dem Arbeitsspeicher zu laden/zu speichern, der mit der Zeile und/oder Spalte der Ausführungsbahn innerhalb der Ausführungsbahnmatrix verbunden ist. Hier fungiert die M-Einheit als Standard-M-Einheit, indem sie häufig zum Laden/Speichern von Daten verwendet wird, die nicht von/in den eigenen Registerbereich der Ausführungsbahn geladen/gespeichert werden können. In verschiedenen Ausführungsformen besteht die primäre Operation der MEinheit darin, Daten von einem lokalen Register in den Speicher zu schreiben und Daten aus dem Speicher einzulesen und in ein lokales Register zu schreiben.Note that if less than the entire contents of a thread's register files are relocated during a relocation sequence, the contents of the non-relocated registers of each thread remain in place (not being relocated). Accordingly, any non-moved content that is not replaced by pushed-in content remains local to the execution thread throughout the move cycle. The memory unit (“M”) observed in each execution lane is used to load/store data from/to the working memory associated with the row and/or column of the execution lane within the execution lane matrix. Here the M-unit acts as a standard M-unit, often being used to load/store data that cannot be loaded/stored from/to the execution lane's own register space. In various embodiments, the Munit's primary operation is to write data from a local register to memory and data read from memory and write to a local register.
In Bezug auf die von der ALU-Einheit der Hardware-Ausführungsbahn 601 unterstützten ISA-Operationscodes sind in verschiedenen Ausführungsformen die von der Hardware-ALU unterstützten mathematischen Operationscodes integral (d. h. im Wesentlichen gleich) mit den von den unterstützten mathematischen Operationscodes verbunden, die eine virtuelle Ausführungsbahn unterstützen (z. B. ADD, SUB, MOV, MUL, MAD, ABS, DIV, SHL, SHR, MIN/MAX, SEL, AND, OR, XOR, NOT). Wie oben beschrieben, können Speicherzugriffsbefehle von der Ausführungsbahn 601 ausgeführt werden, um Daten von/zu ihrem zugehörigen Arbeitsspeicher abzurufen/zu speichern. Zudem unterstützt die Hardware-Ausführungsbahn 601 Verschiebungsoperationsanweisungen (nach rechts, links, oben, unten), um Daten innerhalb der zweidimensionalen Schieberegisterstruktur zu verschieben. Wie oben beschrieben, werden Programmsteuerbefehle weitgehend durch den Skalarprozessor des Schablonenprozessors ausgeführt.
- c. Implementierung des faltenden neuronalen Netzwerks (CNN) auf Bildprozessor
- c. Implementation of convolutional neural network (CNN) on image processor
In der Praxis werden die Bilddaten 701 und Koeffizientendaten 702 als dreidimensionale Informationsmatrizen implementiert. Das bedeutet, dass die Bilddaten 701 als eine dreidimensionale Matrix von Bildpunktdaten implementiert werden können, und die Koeffizientendaten 702 als eine dreidimensionale Matrix von Koeffizientenwerten implementiert werden können. Zwecks Ausführens einer 3D-Faltung wird ein dreidimensionales Skalarprodukt berechnet, wobei Bildpunkte in einem kleineren dreidimensionalen Teil der Bilddaten 701, die dieselben Dimensionen wie die Koeffizienten aufweisen (beispielsweise der kleinere Teil 705 ), jeweils mit gleich positionierten Koeffizienten in der dreidimensionalen Matrix von Koeffizienten 702 multipliziert werden.In practice, the
Die Teilprodukte sämtlicher einzelner Multiplikationen werden sodann addiert, um einen Einzelwert (einen Skalar) zu bilden, welcher dem Ergebnis des Skalarprodukts entspricht. Der resultierende Skalar befindet sich in der resultierenden Matrix 703 an einer Position, die der Position des kleineren Bereichs innerhalb der Bilddaten 701, die gefaltet wurden, entspricht. Beispielsweise erzeugt die Faltung des kleineren Teils 705 mit den Koeffizienten 702 einen Skalar, der sich an Position 704 auf der resultierenden Oberfläche 703 befindet. In gleicher Weise erzeugt die Faltung des kleineren Teils 707 (von dem aus Gründen der einfacheren zeichnerischen Darstellung nur die Oberseitenfläche sichtbar ist) mit den Koeffizienten 702 einen Skalarwert, der sich an Position 706 innerhalb des resultierenden Bereichs 703 befindet.The partial products of all the individual multiplications are then added together to form a single value (a scalar) which is the result of the scalar product. The resulting scalar is in a position in the resulting
Dementsprechend wird für jeden unterschiedlichen kleineren Teil an Bilddaten, die mit den Koeffizienten 702 multipliziert werden, ein unterschiedlicher Skalarwert erzeugt, wobei jeder der unterschiedlichen Skalare eine jeweilige Position auf dem resultierenden Oberflächenbereich 703 besitzt. Einzelheiten mehrerer verschiedener Ausführungsformen der 3D-Faltungsimplementierung werden nachfolgend näher beschrieben.Accordingly, for each different smaller piece of image data multiplied by the
Eine CNN-Schicht beinhaltet typischerweise mehrere 3D-Faltungen pro Block von Bilddaten. Genauer gesagt, beinhaltet eine CNN-Schicht typischerweise mehrere Blöcke von Koeffizienten, die mit einem einzelnen Block von Bilddaten gefaltet werden.
Ebenfalls kann der Block von Koeffizienten 902_1 (der dem ersten Block von Koeffizienten 802_1 in
Beispielsweise wird eine erste 2D-Faltung von Bilddatenebene 901_1 und Koeffizientenebene 902_1_1 durchgeführt, um eine erste resultierende Zwischenebene P1_1 zu erzeugen, eine zweite 2D-Faltung von Bilddatenebene 901_2 und Koeffizientenebene 902_1_2 wird durchgeführt, um eine zweite resultierende Zwischenebene P1_2 zu erzeugen usw. und eine M-te 2D-Faltung von Bilddatenebene 901_M und Koeffizientenebene 902_1_M wird durchgeführt, um eine M-te resultierende Zwischenebene P1_M zu erzeugen. Die Zwischenebenen P1_1 bis P1_M werden sodann in einer ausgerichteten Weise addiert 910 (Skalarwerte an demselben Ort der Zwischenschichtmatrizen werden addiert), um eine resultierende Matrix 903_1 zu bilden. Die resultierende Matrix 903_1 entspricht der resultierenden Matrix 803_1 in
Es ist zu beachten, dass sowohl Operation 940 als auch Operation 941 als umfangreiche Multiplizier-Addier-Operation charakterisiert werden kann (neun Multiplikationen und acht Additionen werden durchgeführt). Da die Schablonenpositionen 950, 951 aneinander angrenzen, werden die Skalar-Ergebnisse S_P1 und S_P2 innerhalb der resultierenden Zwischenebene aneinander angrenzend angeordnet. Hier „gleitet“ die Schablonenposition über den Oberflächenbereich einer gesamten Ebene von Bilddaten, während die „Multiplizier-Addier“-Operationen die durch jede einzigartige Schablonenposition definiert werden, einen einzigartigen Ergebniswert in der Zwischenebene erzeugen. Die Positionen der Ergebniswerte zueinander innerhalb der Zwischenebene werden durch die jeweiligen Positionen der Schablonen, durch welche dieselben erzeugt wurden, definiert.Note that both
Zurückverweisend auf
Wenn die erste Ebene von Bilddaten 1001_1 und der erste Satz von Koeffizienten 1002_1 in den RAM 407 des Schablonenprozessors geladen werden, ist das System bereit, eine wie zuvor mit Bezug auf
Wenn die erste Bildebene 1001_1 mit der ersten Ebene von Koeffizienten 1002_1 gefaltet worden ist, ist die Maschine bereit, die folgende Operationssequenz zu starten. Hier könnte, falls die in
Wie in
Nach Beendigung der Operationen der
Nachdem die zweite Bildebene 1001_2 erschöpft ist, wird die dritte Bildebene geladen und gemäß der obigen Beschreibung für die ersten und zweiten Bildebenen verarbeitet. Jede Bildebene wird sodann auf gleiche Weise nacheinander verarbeitet.
In einer Ausführungsform führt die Maschine die Additionen von 10j in der Weise durch, bei der eine „fortlaufende ZwischenebenenSumme“ fortlaufend aktualisiert wird, anstatt jede einzelne Zwischenebene separat zu speichern und diese dann zu addieren. Bezugnehmend auf
Unter Bezugnahme auf
Von der Erläuterung aus
Unter Bezugnahme auf
Unter Bezugnahme auf
Unter Bezugnahme auf
Obwohl sich vorstehende Erläuterung auf einen Ansatz bezog, in dem eine gesamte CNN-Schicht auf einem gleichen Schablonenprozessor ausgeführt wurde, können andere Ansätze versuchen, eine parallele Ausführung der CNN-Schicht über mehrere Schablonenprozessoren auszuführen (es ist zu berücksichtigen, dass
In einem anderen parallelisierenden Ansatz, der in
In noch einem anderen in
In noch weiteren anderen Konfigurationen kann mehr als eine CNN-Schicht, jeweils N Koeffizientensätze aufweisend, auf einem einzigen Schablonenprozessor ausgeführt werden. In einer Ausführungsform kann das Ausführen mehrerer CNN-Schichten auf einem einzigen Schablonenprozessor durch Zeitmultiplexbetrieb zwischen den mehreren CNN-Schichten durchgeführt werden.
Nachdem der letzte Koeffizientensatz 1502_N für die erste CNN-Schicht gefaltet worden und seine Zwischenebene in den Akkumulator eingegeben worden ist, wird die nächste CNN-Schicht verarbeitet. Das heißt, die Bilddatenebene 1501_1 wird nicht aus dem aktiven Kontext des Schablonenprozessors herausgeschaltet, sondern wird hingegen weiter mit den geeigneten jeweiligen Schichten des Koeffizientensatzes 1512_1 bis 1512_N für die zweite CNN-Schicht verwendet. Zwischenebenen für die zweite CNN-Schicht werden in einem weiteren separaten Akkumulator, also nicht von dem Akkumulator für die erste CNN-Schicht, akkumuliert. Nachdem die geeigneten jeweiligen Ebenen von dem zweiten Satz von Koeffizienten 1512_1 bis 1512_N verarbeitet worden sind, wird eine nächste Bildebene für die Bilddaten in den Kontext des Schablonenprozessors hineingeschaltet, und das Verfahren wiederholt sich, jedoch mit einer unterschiedlichen jeweiligen Ebene für beide Koeffizientensätze.After the last set of coefficients 1502_N for the first CNN layer has been convolved and its intermediate level has been input into the accumulator, the next CNN layer is processed. That is, the image data plane 1501_1 is not switched out of the template processor's active context, but instead continues to be used with the appropriate respective layers of the coefficient set 1512_1 through 1512_N for the second CNN layer. Intermediate levels for the second CNN layer are accumulated in another separate accumulator, not from the accumulator for the first CNN layer. After the appropriate respective levels of the second set of coefficients 1512_1 through 1512_N have been processed, a next image level for the image data is switched into the context of the template processor and the process repeats, but with a different respective level for both sets of coefficients.
In noch einem weiteren anderen Ansatz wird die Ausgabe für eine erste CNN direkt als Eingabe für eine zweite CNN eingespeist. Zum Beispiel bildet die Addition der Zwischenebenen für Koeffizientensatz 1502 eine Eingabebildebene für eine nächste, folgende CNN, die von dem Schablonenprozessor, welcher Koeffizientensatz 1512 aufweist, auszuführen ist.In yet another different approach, the output for a first CNN is fed directly as input for a second CNN. For example, the addition of the intermediate levels for coefficient set 1502 forms an input image level for a next subsequent CNN to be executed by the template processor having
In noch weiteren anderen Konfigurationen können verschiedene und eigenständige Bilder verschiedenen Schablonenprozessoren zugeordnet werden (sodass durch den Bildprozessor CNNs an verschiedenen Bildern gleichzeitig durchgeführt werden können).In still other configurations, different and distinct images can be assigned to different template processors (so that CNNs can be performed on different images simultaneously by the image processor).
Obwohl 3 x 3-Schablonengrößen in den vorstehenden Erläuterungen hervorgehoben wurden, ist die Maschine dafür konzipiert, zahlreiche 3DSchablonen (z. B. 1 x 1 x M, 3 x 3 x M, 5 x 5 x M und 7 x 7 x M) zu unterstützen (z. B. durch Konfiguration des Registerbereichs des Bildprozessors und/oder kompilierten Programmcode).Although 3 x 3 stencil sizes have been emphasized in the explanations above, the machine is designed to cut numerous 3D stencils (e.g. 1 x 1 x M, 3 x 3 x M, 5 x 5 x M and 7 x 7 x M). (e.g. by configuring the register area of the image processor and/or compiled program code).
Obwohl die oben beschriebenen Multiplikations- und Additionsoperationen in Gleitkommadarstellung berechnet werden können, werden diese in anderen Ausführungsformen ggf. in Festkommazahldarstellung berechnet. Ferner kann die Festkommazahldarstellung geringerer Präzision (z. B. 8 Bits oder weniger (wie beispielsweise 5 Bits)) oder höherer Präzision sein. Festkommazahlen geringerer Präzision werden im Hinblick auf Zeit/Energie als effizienter betrachtet, ohne Verlust von Bildqualität bei vielen Anwendungen.Although the multiplication and addition operations described above may be computed in floating point notation, in other embodiments they may be computed in fixed point display calculated. Furthermore, the fixed-point number representation may be of lower precision (e.g., 8 bits or less (such as 5 bits)) or higher precision. Lower precision fixed point numbers are considered more efficient in terms of time/energy without loss of image quality in many applications.
In verschiedenen Ausführungsformen ist der ausführbare Programmcode strukturiert, 2 (z. B. 8-Bit) Multiplizier-Addier-Operationen (MADs) auf einer einzigen ALU-Bahn auszuführen, um 2 MADs pro Zyklus zu erreichen. In einer Ausführungsform ist die ALU-Bahn-Hardware dafür konzipiert, zwei Multiplikationen 8-Bit mal 8-Bit (d. h. vier 8-Bit Eingabeoperanden) durchzuführen, und dann die zwei 16-Bit-Produkte und einen 32-BitAkkumulator zu addieren, um eine 32-Bit-Summe in einem Zyklus zu bilden. Hier entspricht der Akkumulator einem 32-Bit-Eingabeoperanden der zu dem Ergebnis der Multiplikation hinzu addiert wird, wobei das Ergebnis der Addition in das Ausgabe-„Akkumulator“-Register geschrieben wird. Hier wird davon ausgegangen, dass beide Multiplikationen für den gleichen Bildpunkt in der Ausgabeebene sind und deshalb addiert werden können. Die vier 8-Bit-Eingabeoperanden bestehen aus zwei Eingaben von derselben Eingabebildebene und zwei Koeffizientenwerten.In various embodiments, the executable program code is structured to perform 2 (e.g., 8-bit) multiply-add operations (MADs) on a single ALU lane to achieve 2 MADs per cycle. In one embodiment, the ALU lane hardware is designed to perform two 8-bit by 8-bit multiplies (i.e., four 8-bit input operands) and then add the two 16-bit products and a 32-bit accumulator to add to form a 32-bit sum in one cycle. Here, the accumulator corresponds to a 32-bit input operand that is added to the result of the multiplication, with the result of the addition being written to the output "accumulator" register. Here it is assumed that both multiplications are for the same pixel in the output plane and can therefore be added. The four 8-bit input operands consist of two inputs from the same input image plane and two coefficient values.
In einer alternativen Ausführungsform ist jede ALU-Bahn dafür konzipiert, duale 8-Bit Multiplizier-Addier-Operationen zu unterstützen, um 2 MADs pro Zyklus zu erreichen. Das heißt, die Hardware führt eine erste 8-Bit x 8-Bit-Multiplikation und Ergebnis-Addition mit 16-Bit-Eingabeoperand in resultierenden 16-Bit-Akkumulator und eine zweite, separate 8-Bit x 8-Bit-Multiplikation und Ergebnis-Addition mit separatem 16-Bit Eingabeoperand in einen separaten 16-Bit-Akkumulator durch. Es ist jedoch möglich, dass die 16-Bit-Akkumulatoren in einem einzigen Zyklus saturieren (z. B. mit vollen 8- Bit-Eingabemultiplikanden) und eine Übertragung in einen 32-Bit-Akkumulator in jedem Zyklus erfordern, wodurch die Gesamtrate auf 1 MAD pro Zyklus (gesamt) fallen könnte.In an alternate embodiment, each ALU lane is designed to support dual 8-bit multiply-add operations to achieve 2 MADs per cycle. That is, the hardware performs a first 8-bit x 8-bit multiply and result addition with 16-bit input operand in resulting 16-bit accumulator and a second, separate 8-bit x 8-bit multiply and result -Addition with a separate 16-bit input operand into a separate 16-bit accumulator. However, it is possible for the 16-bit accumulators to saturate in a single cycle (e.g. with full 8-bit input multiplicands) and require a transfer to a 32-bit accumulator every cycle, reducing the overall rate to 1 MAD per cycle (overall) could fall.
Um die Saturation zu vermeiden, können Multiplikanden-Eingabedaten niedrigerer Auflösung verwendet werden. Zum Beispiel kann ein Paar von 6-Bit x 6-Bit-Multiplikationen mit jeweiligen Ergebnissen durchgeführt werden, die in separate, entsprechende 16-Bit-Akkumulatoren mit einem entsprechenden unterschiedlichen 16-Bit-Eingabeoperanden addiert werden. Der Eingabe-Multiplikand niedrigerer Auflösung erfordert mehrere Zyklen vor der 16-Bit-Akkumulator-Saturation und entsprechender Übertragung in einen 32-Bit-Akkumulator. Zum Beispiel kann die Saturation nach jeweils 16 Zyklen auftreten. Falls die Saturation nach jeweils 16 Zyklen auftritt, können die dualen 16-Bit-Akkumulatoren im jeweils 17ten Zyklus addiert werden und im jeweils 18ten Zyklus kann das Ergebnis der unmittelbar vorhergehenden dualen Akkumulatorsumme zu einem fortlaufenden 32-Bit-Akkumulator addiert werden. In einer Ausführungsform kann die Software dafür konzipiert sein, die Akkumulator-Summe und -Addition in einen 32-Bit-Akkumulator in einem einzigen Zyklus durchzuführen. In verschiedenen Ausführungsformen kann dieser Ansatz mit geringerer Präzision fähig sein, 1,8 MultiplizierAddier-Operationen pro Zyklus zu erreichen.To avoid saturation, lower resolution multiplicand input data can be used. For example, a pair of 6-bit x 6-bit multiplications can be performed with respective results summed into separate, corresponding 16-bit accumulators with a corresponding different 16-bit input operand. The lower resolution input multiplicand requires several cycles before saturating the 16-bit accumulator and transferring it to a 32-bit accumulator accordingly. For example, saturation may occur every 16 cycles. If saturation occurs every 16 cycles, the dual 16-bit accumulators can be added every 17th cycle and every 18th cycle the result of the immediately preceding dual accumulator sum can be added to form a continuous 32-bit accumulator. In one embodiment, the software can be designed to perform the accumulator sum and addition into a 32-bit accumulator in a single cycle. In various embodiments, this lower precision approach may be able to achieve 1.8 multiply-add operations per cycle.
Anwendungen mit höherer Präzision (z. B. mit mehr als 8-Bits an Eingabemultiplikanden-Daten) können dafür konzipiert sein, einen 32- Bit-Additions-Operanden und einen Akkumulator-Ergebnis mit ca. 1 MAD pro Zyklus zu verwenden. Dies wird, ähnlich wie der Ansatz geringerer Präzision, eine Saturation des Akkumulators vermeiden, bevor eine bedeutende Anzahl an Zyklen durchgeführt worden sind. Im Fall von 12-BitEingabemultiplikanden-Bilddaten, werden 256 Zyklen einzelner MADs ausgeführt, bevor der 32-Bit-Akkumulator saturiert.Higher precision applications (e.g., with more than 8 bits of input multiplicand data) can be designed to use a 32-bit addition operand and an accumulator result with approximately 1 MAD per cycle. Similar to the lower precision approach, this will avoid saturating the accumulator before a significant number of cycles have been performed. In the case of 12-bit input multiplicand image data, 256 cycles of individual MADs are executed before the 32-bit accumulator saturates.
d. Ausführungsformen zur Implementierungi.e. Implementation Embodiments
Es ist wichtig, darauf hinzuweisen, dass die oben beschriebenen verschiedenen Merkmale der Bildprozessorarchitektur nicht zwangsläufig auf die Bildverarbeitung im herkömmlichen Sinne beschränkt sind und daher auf andere Anwendungen angewendet werden können, die ggf. veranlassen, dass der Bildprozessor neu charakterisiert wird oder auch nicht. Wenn beispielsweise eines der vorstehend beschriebenen verschiedenen Merkmale der Bildprozessorarchitektur bei der Erstellung und/oder Erzeugung und/oder Wiedergabe von Animationen anstatt bei der Verarbeitung von tatsächlichen Kamerabildern verwendet werden soll, kann der Bildprozessor als grafische Verarbeitungseinheit charakterisiert sein. Zudem können die oben beschriebenen Architekturmerkmale des Bildprozessors in anderen technischen Anwendungen, wie z. B. in der Videoverarbeitung, Bildverarbeitung, Bilderkennung und/oder dem maschinellen Lernen, angewendet werden. Auf diese Weise kann der Bildprozessor (z. B. als Koprozessor) in einen allgemeineren Universalprozessor (z. B. als Teil einer CPU des Computersystems) mit integriert werden oder ein eigenständiger Prozessor innerhalb eines Computersystems sein.It is important to note that the various features of the image processor architecture described above are not necessarily limited to image processing in the traditional sense, and therefore to other applications may be applied, which may or may not cause the image processor to be re-characterized. For example, if any of the various features of the image processor architecture described above are to be used in the creation and/or generation and/or rendering of animations rather than in the processing of actual camera images, the image processor may be characterized as a graphical processing unit. In addition, the architectural features of the image processor described above can be used in other technical applications, such as e.g. in video processing, image processing, image recognition and/or machine learning. In this way, the image processor may be integrated (e.g., as a co-processor) into a more general purpose processor (e.g., part of a computer system's CPU), or it may be a standalone processor within a computer system.
Die oben beschriebenen Hardware-Ausführungsformen können in einem Halbleiterchip und/oder als Beschreibung eines Schaltungsdesigns zur letztendlichen Ausrichtung auf einen Halbleiterherstellungsprozess enthalten sein. Im letzteren Fall können diese Schaltungsbeschreibungen die Form einer (z. B. VHDL oder Verilog) Beschreibung einer Registerüberleitungsschaltung (RTL), einer Torschaltung, einer Transistorschaltung oder einer Maske oder verschiedener Kombinationen derselben annehmen. Schaltungsbeschreibungen sind in der Regel auf einem computerlesbaren Speichermedium (wie z. B. einer CD-ROM oder einer anderen Art von Speichertechnologie) enthalten.The hardware embodiments described above may be included in a semiconductor chip and/or as a description of a circuit design for ultimate alignment with a semiconductor manufacturing process. In the latter case, these circuit descriptions may take the form of a (e.g., VHDL or Verilog) description of a register pass circuit (RTL), a gate circuit, a transistor circuit, or a mask, or various combinations thereof. Circuit descriptions are typically contained on a computer-readable storage medium (such as a CD-ROM or other type of storage technology).
Aus den vorangehenden Abschnitten ist zu erkennen, dass ein Bildprozessor, wie oben beschrieben, in der Hardware auf einem Computersystem (z. B. als Teil eines Handgerätsystems on Chip (SOC), das Daten von der Kamera des Handgerätes verarbeitet) enthalten sein kann. In Fällen, in denen der Bildprozessor als Hardware-Schaltung ausgebildet ist, ist zu beachten, dass die Bilddaten, die von dem Bildprozessor verarbeitet werden, direkt von einer Kamera empfangen werden können. Hier kann der Bildprozessor Teil einer diskreten Kamera oder Teil eines Computersystems mit einer integrierten Kamera sein. Im letzteren Fall können die Bilddaten direkt von der Kamera oder aus dem Systemspeicher des Computersystems empfangen werden (z. B. sendet die Kamera ihre Bilddaten anstatt an den Bildprozessor an den Systemspeicher). Zu beachten ist auch, dass viele der in den vorangehenden Abschnitten beschriebenen Merkmale auf eine Bildprozessoreinheit (zur Darstellung von Animationen) anwendbar sind.From the previous sections, it can be seen that an image processor as described above may be embodied in hardware on a computer system (e.g., as part of a handset system on chip (SOC) that processes data from the handset's camera). In cases where the image processor is implemented as a hardware circuit, it should be noted that the image data processed by the image processor can be received directly from a camera. Here the image processor can be part of a discrete camera or part of a computer system with an integrated camera. In the latter case, the image data may be received directly from the camera or from the computer system's system memory (e.g., the camera sends its image data to the system memory instead of to the image processor). It should also be noted that many of the features described in the previous paragraphs are applicable to an image processing unit (to render animations).
Wie in
Ein Anwendungsprozessor oder Multikernprozessor 1750 kann einen oder mehrere Universalprozessorkerne 1715 innerhalb seiner CPUs 1701 , eine oder mehrere grafische Verarbeitungseinheiten 1716 , eine Speicherverwaltungsfunktion 1717 (z. B. einen Speichercontroller), eine E/A-Steuerfunktion 1718 und eine Bildverarbeitungseinheit 1719 beinhalten. Die Universalverarbeitungskerne 1715 führen in der Regel das Betriebssystem und die Anwendungssoftware des Computersystems aus. Die Grafikverarbeitungseinheiten 1716 führen in der Regel grafikintensive Funktionen aus, um z. B. Grafikdaten zu erzeugen, die auf dem Display 1703 dargestellt werden. Die Speichersteuerfunktion 1717 ist mit dem Systemspeicher 1702 verbunden, um Daten in den Systemspeicher 1702 zu schreiben bzw. aus diesem einzulesen. Die Energieverwaltungssteuereinheit 1712 steuert im Allgemeinen den Energieverbrauch des Systems 1700 .An application processor or
Die Bildverarbeitungseinheit 1719 kann gemäß einer der oben in den vorangehenden Abschnitten beschriebenen Ausführungsformen der Bildverarbeitungseinheit implementiert sein. Alternativ dazu oder in Kombination kann die IPU 1719 mit einer oder sowohl dem GPU 1716 als auch der CPU 1701 als Koprozessor derselben gekoppelt sein. Darüber hinaus kann in verschiedenen Ausführungsformen der GPU 1716 mit einem der oben beschriebenen Prozessormerkmale implementiert sein.The
Das Touchscreen-Display 1703 , die Kommunikationsschnittstellen 1704 -1707 , die GPS-Schnittstelle 1708 , die Sensoren 1709 , die Kamera 1710 und der Lautsprecher/Mikrofon-Codec 1713 , 1714 können alle als unterschiedliche Formen der E/A (Eingabe und/oder Ausgabe) in Bezug auf das gesamte Rechensystem betrachtet werden, darunter auch gegebenenfalls ein integriertes Peripheriegerät (z. B. die eine oder mehrere Kameras 1710). Je nach Implementierung können verschiedene dieser E/A-Komponenten auf dem Anwendungsprozessor/Multikernprozessor 1750 integriert sein oder sich außerhalb des Chips oder außerhalb des Pakets des Anwendungsprozessors/Multikernprozessors 1750 befinden.The
In einer Ausführungsform beinhalten eine oder mehrere Kameras 1710 eine Tiefenkamera, die in der Lage ist, die Tiefe zwischen der Kamera und einem Objekt in dessen Sichtfeld zu messen. Anwendungssoftware, Betriebssystemsoftware, Gerätetreibersoftware und/oder Firmware, die auf einem universellen CPU-Kern (oder einem anderen Funktionsblock mit einer Befehlsausführungspipeline zum Ausführen eines Programmcodes) eines Anwendungsprozessors oder eines anderen Prozessors ausgeführt werden, können sämtliche der oben beschriebenen Funktionen ausführen.In one embodiment, one or
Ausführungsformen der Erfindung können, wie oben dargelegt, verschiedene Verfahren beinhalten. Die Prozesse können in maschinenausführbaren Befehlen enthalten sein. Die Befehle können dazu verwendet werden, einen Universalprozessor oder Spezialprozessor dazu zu veranlassen, bestimmte Prozesse auszuführen. Alternativ dazu können diese Prozesse von spezifischen Hardwarekomponenten ausgeführt werden, die eine fest verdrahtete Logik zum Ausführen der Prozesse oder eine beliebige Kombination von programmierten Computerkomponenten und benutzerdefinierten Hardwarekomponenten enthalten.As set forth above, embodiments of the invention may involve various methods. The processes can be contained in machine-executable instructions. The instructions can be used to cause a general purpose or special purpose processor to perform specific processes. Alternatively, these processes may be performed by specific hardware components that contain hard-wired logic to perform the processes, or any combination of programmed computer components and custom hardware components.
Elemente der vorliegenden Erfindung können darüber hinaus als maschinenlesbares Medium zum Speichern der maschinenausführbaren Befehle bereitgestellt sein. Das maschinenlesbare Medium kann unter anderem Disketten, optische Platten, CD-ROMs und magneto-optische Platten, FLASH-Speicher, ROMs, RAMs, EPROMs, EEPROMs, magnetische oder optische Karten, Ausbreitungsmedien oder andere Arten von Medien/maschinenlesbare Medien, die für die Speicherung von elektronischen Befehlen geeignet sind, beinhalten. Beispielsweise können Elemente in Form eines Computerprogramms heruntergeladen werden, das von einem dezentralen Computer (z. B. einem Server) mittels eines in einer Trägerwelle oder in einem anderen Ausbreitungsmedium enthaltenen Datensignals an einen anfordernden Computer (z. B. einen Client) über eine Kommunikationsverbindung (z. B. ein Modem oder eine Netzwerkverbindung) übertragen wird.Elements of the present invention may also be provided as a machine-readable medium for storing the machine-executable instructions. The machine-readable medium may include, but is not limited to, floppy disks, optical disks, CD-ROMs and magneto-optical disks, FLASH memories, ROMs, RAMs, EPROMs, EEPROMs, magnetic or optical cards, propagation media, or other types of media/machine-readable media used for the Storage of electronic commands are suitable include. For example, Items may be downloaded in the form of a computer program transmitted from a remote computer (e.g., a server) to a requesting computer (e.g., a client) via a communications link using a data signal contained in a carrier wave or other propagation medium (e.g. a modem or a network connection).
In der vorstehenden Beschreibung wurden spezifische exemplarische Ausführungsformen beschrieben. Es ist jedoch offensichtlich, dass verschiedene Modifikationen und Änderungen daran vorgenommen werden können, ohne von dem in den beigefügten Ansprüchen dargelegten Erfindungsgedanken und Umfang der Erfindung abzuweichen. Die Beschreibung und die Zeichnungen sind daher in einem veranschaulichenden und nicht in einem einschränkenden Sinne zu betrachten.In the foregoing description, specific exemplary embodiments have been described. It will, however, be evident that various modifications and changes can be made thereto without departing from the spirit and scope of the invention as set forth in the appended claims. The specification and drawings are, therefore, to be regarded in an illustrative rather than a restrictive sense.
Claims (18)
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US15/201,204 | 2016-07-01 | ||
US15/201,204 US10546211B2 (en) | 2016-07-01 | 2016-07-01 | Convolutional neural network on programmable two dimensional image processor |
Publications (2)
Publication Number | Publication Date |
---|---|
DE102017113733A1 DE102017113733A1 (en) | 2018-01-04 |
DE102017113733B4 true DE102017113733B4 (en) | 2022-06-30 |
Family
ID=59363203
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
DE102017113733.5A Active DE102017113733B4 (en) | 2016-07-01 | 2017-06-21 | Convolutional neural network on programmable two-dimensional image processor |
DE202017103694.4U Active DE202017103694U1 (en) | 2016-07-01 | 2017-06-21 | Folding neural network on programmable two-dimensional image processor |
Family Applications After (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
DE202017103694.4U Active DE202017103694U1 (en) | 2016-07-01 | 2017-06-21 | Folding neural network on programmable two-dimensional image processor |
Country Status (9)
Country | Link |
---|---|
US (3) | US10546211B2 (en) |
EP (1) | EP3479302B1 (en) |
JP (1) | JP6764954B2 (en) |
KR (1) | KR102232722B1 (en) |
CN (1) | CN107563952B (en) |
DE (2) | DE102017113733B4 (en) |
GB (3) | GB2574940B (en) |
TW (1) | TWI690858B (en) |
WO (1) | WO2018005030A1 (en) |
Families Citing this family (62)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20180046898A1 (en) * | 2016-08-11 | 2018-02-15 | Vivante Corporation | Zero Coefficient Skipping Convolution Neural Network Engine |
US10360470B2 (en) | 2016-10-10 | 2019-07-23 | Gyrfalcon Technology Inc. | Implementation of MobileNet in a CNN based digital integrated circuit |
US10339445B2 (en) | 2016-10-10 | 2019-07-02 | Gyrfalcon Technology Inc. | Implementation of ResNet in a CNN based digital integrated circuit |
US10366328B2 (en) | 2017-09-19 | 2019-07-30 | Gyrfalcon Technology Inc. | Approximating fully-connected layers with multiple arrays of 3x3 convolutional filter kernels in a CNN based integrated circuit |
US9940534B1 (en) * | 2016-10-10 | 2018-04-10 | Gyrfalcon Technology, Inc. | Digital integrated circuit for extracting features out of an input image based on cellular neural networks |
US10402628B2 (en) | 2016-10-10 | 2019-09-03 | Gyrfalcon Technology Inc. | Image classification systems based on CNN based IC and light-weight classifier |
US10366302B2 (en) | 2016-10-10 | 2019-07-30 | Gyrfalcon Technology Inc. | Hierarchical category classification scheme using multiple sets of fully-connected networks with a CNN based integrated circuit as feature extractor |
US10043095B2 (en) * | 2016-10-10 | 2018-08-07 | Gyrfalcon Technology, Inc. | Data structure for CNN based digital integrated circuit for extracting features out of an input image |
TWI634490B (en) * | 2016-11-14 | 2018-09-01 | 美商耐能股份有限公司 | Convolution operation device and convolution operation method |
US10878310B2 (en) | 2016-11-29 | 2020-12-29 | Mellanox Technologies, Ltd. | Accelerated convolution in convolutional neural networks |
US11562115B2 (en) | 2017-01-04 | 2023-01-24 | Stmicroelectronics S.R.L. | Configurable accelerator framework including a stream switch having a plurality of unidirectional stream links |
US10339443B1 (en) | 2017-02-24 | 2019-07-02 | Gopro, Inc. | Systems and methods for processing convolutional neural network operations using textures |
US11037330B2 (en) * | 2017-04-08 | 2021-06-15 | Intel Corporation | Low rank matrix compression |
US11373266B2 (en) * | 2017-05-05 | 2022-06-28 | Intel Corporation | Data parallelism and halo exchange for distributed machine learning |
US10474464B2 (en) | 2017-07-05 | 2019-11-12 | Deep Vision, Inc. | Deep vision processor |
US10817983B1 (en) * | 2017-09-28 | 2020-10-27 | Apple Inc. | Method and device for combining real and virtual images |
CN109754359B (en) * | 2017-11-01 | 2021-12-07 | 腾讯科技（深圳）有限公司 | Pooling processing method and system applied to convolutional neural network |
US11270201B2 (en) | 2017-12-29 | 2022-03-08 | Intel Corporation | Communication optimizations for distributed machine learning |
CN108182471B (en) * | 2018-01-24 | 2022-02-15 | 上海岳芯电子科技有限公司 | Convolutional neural network reasoning accelerator and method |
US10459876B2 (en) * | 2018-01-31 | 2019-10-29 | Amazon Technologies, Inc. | Performing concurrent operations in a processing element |
GB201801639D0 (en) * | 2018-02-01 | 2018-03-21 | Ruff Brendan Patrick | Low precision efficient multiplication free convolutional filter bank device |
US11468302B2 (en) | 2018-03-13 | 2022-10-11 | Recogni Inc. | Efficient convolutional engine |
CN108520297B (en) * | 2018-04-02 | 2020-09-04 | 周军 | Programmable deep neural network processor |
CN108829610B (en) * | 2018-04-02 | 2020-08-04 | 浙江大华技术股份有限公司 | Memory management method and device in neural network forward computing process |
EP3557485B1 (en) * | 2018-04-19 | 2021-05-26 | Aimotive Kft. | Method for accelerating operations and accelerator apparatus |
KR102126857B1 (en) * | 2018-05-10 | 2020-06-25 | 서울대학교산학협력단 | Neural network processor based on row operation and data processing method using thereof |
CN108921926B (en) * | 2018-07-02 | 2020-10-09 | 云从科技集团股份有限公司 | End-to-end three-dimensional face reconstruction method based on single image |
US10417342B1 (en) | 2018-07-03 | 2019-09-17 | Gyrfalcon Technology Inc. | Deep learning device for local processing classical chinese poetry and verse |
CN108681984B (en) * | 2018-07-26 | 2023-08-15 | 珠海一微半导体股份有限公司 | Acceleration circuit of 3*3 convolution algorithm |
CN109065089B (en) * | 2018-07-26 | 2020-11-06 | 杭州闪亿半导体有限公司 | Storage module and module for convolution operation |
US10311149B1 (en) | 2018-08-08 | 2019-06-04 | Gyrfalcon Technology Inc. | Natural language translation device |
CN109086875A (en) * | 2018-08-16 | 2018-12-25 | 郑州云海信息技术有限公司 | A kind of convolutional network accelerating method and device based on macroinstruction set |
US10983583B2 (en) * | 2018-08-23 | 2021-04-20 | Apple Inc. | Electronic display reduced blanking duration systems and methods |
JP7165018B2 (en) | 2018-10-03 | 2022-11-02 | キヤノン株式会社 | Information processing device, information processing method |
US11501141B2 (en) * | 2018-10-12 | 2022-11-15 | Western Digital Technologies, Inc. | Shifting architecture for data reuse in a neural network |
US10387772B1 (en) | 2018-10-22 | 2019-08-20 | Gyrfalcon Technology Inc. | Ensemble learning based image classification systems |
CN109711538B (en) * | 2018-12-14 | 2021-01-15 | 安徽寒武纪信息科技有限公司 | Operation method, device and related product |
US10552939B1 (en) | 2019-02-12 | 2020-02-04 | Google Llc | Image processor complex transfer functions |
JP7408289B2 (en) * | 2019-03-28 | 2024-01-05 | 株式会社エヌエスアイテクス | convolution arithmetic unit |
CN111767994A (en) * | 2019-04-01 | 2020-10-13 | 中国科学院半导体研究所 | Neuron calculation module |
KR20210004702A (en) * | 2019-07-05 | 2021-01-13 | 삼성전자주식회사 | Artificial intelligence processor and performing neural network operation thereof |
US11475283B2 (en) | 2019-10-24 | 2022-10-18 | Apple Inc. | Multi dimensional convolution in neural network processor |
DE102019130930A1 (en) | 2019-11-15 | 2021-05-20 | Carl Zeiss Microscopy Gmbh | Microscope and method with performing a convolutional neural network |
CN110728367B (en) * | 2019-12-18 | 2020-05-05 | 深圳鲲云信息科技有限公司 | Data storage method and device for neural network |
CN111079904B (en) * | 2019-12-23 | 2023-05-23 | 福建星网视易信息系统有限公司 | Acceleration method of depth separable convolution and storage medium |
US11403727B2 (en) | 2020-01-28 | 2022-08-02 | Nxp Usa, Inc. | System and method for convolving an image |
DE102020201182A1 (en) * | 2020-01-31 | 2021-08-05 | Robert Bosch Gesellschaft mit beschränkter Haftung | Hardware-accelerated calculation of convolutions |
US11593609B2 (en) | 2020-02-18 | 2023-02-28 | Stmicroelectronics S.R.L. | Vector quantization decoding hardware unit for real-time dynamic decompression for parameters of neural networks |
WO2021183567A1 (en) * | 2020-03-10 | 2021-09-16 | Verheyen Henry | Hardware architecture for processing data in neural network |
US11513847B2 (en) | 2020-03-24 | 2022-11-29 | Deep Vision Inc. | System and method for queuing commands in a deep learning processor |
JP7367595B2 (en) | 2020-04-07 | 2023-10-24 | 富士通株式会社 | Information processing device and information processing method |
US11500680B2 (en) * | 2020-04-24 | 2022-11-15 | Alibaba Group Holding Limited | Systolic array-friendly data placement and control based on masked write |
KR102441171B1 (en) * | 2020-05-26 | 2022-09-08 | 한국전자통신연구원 | Apparatus and Method for Monitoring User based on Multi-View Face Image |
CN111767985B (en) * | 2020-06-19 | 2022-07-22 | 深圳市商汤科技有限公司 | Neural network training method, video identification method and device |
US11531873B2 (en) | 2020-06-23 | 2022-12-20 | Stmicroelectronics S.R.L. | Convolution acceleration with embedded vector decompression |
US11586442B2 (en) | 2020-08-06 | 2023-02-21 | Nxp Usa, Inc. | System and method for convolving image with sparse kernels |
GB2599098B (en) * | 2020-09-22 | 2024-04-10 | Imagination Tech Ltd | Hardware implementation of windowed operations in three or more dimensions |
US11734017B1 (en) | 2020-12-07 | 2023-08-22 | Waymo Llc | Methods and systems for processing vehicle sensor data across multiple digital signal processing cores virtually arranged in segments based on a type of sensor |
US20220207332A1 (en) * | 2020-12-31 | 2022-06-30 | Nxp Usa, Inc. | Scalable neural network accelerator architecture |
CN112967211A (en) * | 2021-01-31 | 2021-06-15 | 成都商汤科技有限公司 | Image processing method and device, computer equipment and storage medium |
CN113191935A (en) * | 2021-04-30 | 2021-07-30 | 华中科技大学 | Reconfigurable hardware acceleration method and system for Gaussian pyramid construction |
US20230032323A1 (en) * | 2021-07-28 | 2023-02-02 | Apical Limited | Image processing method and system |
Citations (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20150178246A1 (en) | 2013-12-20 | 2015-06-25 | Enric Herrero Abellanas | Processing device for performing convolution operations |
Family Cites Families (77)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4445177A (en) | 1981-05-22 | 1984-04-24 | Data General Corporation | Digital data processing system utilizing a unique arithmetic logic unit for handling uniquely identifiable addresses for operands and instructions |
DE3851005T2 (en) | 1987-06-01 | 1995-04-20 | Applied Intelligent Syst Inc | Parallel neighboring processing system and method. |
US4770430A (en) | 1987-08-11 | 1988-09-13 | Lange Dennis M | Self-steering axle assembly for vehicles |
US4935894A (en) | 1987-08-31 | 1990-06-19 | Motorola, Inc. | Multi-processor, multi-bus system with bus interface comprising FIFO register stocks for receiving and transmitting data and control information |
US5253308A (en) | 1989-06-21 | 1993-10-12 | Amber Engineering, Inc. | Massively parallel digital image data processor using pixel-mapped input/output and relative indexed addressing |
WO1994009595A1 (en) | 1991-09-20 | 1994-04-28 | Shaw Venson M | Method and apparatus including system architecture for multimedia communications |
JP3482660B2 (en) | 1993-09-08 | 2003-12-22 | ソニー株式会社 | Image data processing apparatus and image data processing method |
US5612693A (en) | 1994-12-14 | 1997-03-18 | International Business Machines Corporation | Sliding window data compression using a toroidal bit shift register |
JP3573755B2 (en) | 1996-01-15 | 2004-10-06 | シーメンス アクチエンゲゼルシヤフト | Image processing processor |
US5892962A (en) | 1996-11-12 | 1999-04-06 | Lucent Technologies Inc. | FPGA-based processor |
US6366289B1 (en) | 1998-07-17 | 2002-04-02 | Microsoft Corporation | Method and system for managing a display image in compressed and uncompressed blocks |
US6587158B1 (en) | 1998-07-23 | 2003-07-01 | Dvdo, Inc. | Method and apparatus for reducing on-chip memory in vertical video processing |
US7010177B1 (en) | 1998-08-27 | 2006-03-07 | Intel Corporation | Portability of digital images |
EP1164544B1 (en) | 1999-03-16 | 2011-11-02 | Hamamatsu Photonics K.K. | High-speed vision sensor |
JP3922859B2 (en) | 1999-12-28 | 2007-05-30 | 株式会社リコー | Image processing apparatus, image processing method, and computer-readable recording medium storing program for causing computer to execute the method |
US6745319B1 (en) | 2000-02-18 | 2004-06-01 | Texas Instruments Incorporated | Microprocessor with instructions for shuffling and dealing data |
US6728862B1 (en) | 2000-05-22 | 2004-04-27 | Gazelle Technology Corporation | Processor array and parallel data processing methods |
US6728722B1 (en) | 2000-08-28 | 2004-04-27 | Sun Microsystems, Inc. | General data structure for describing logical data spaces |
US7286717B2 (en) | 2001-10-31 | 2007-10-23 | Ricoh Company, Ltd. | Image data processing device processing a plurality of series of data items simultaneously in parallel |
JP4146654B2 (en) | 2002-02-28 | 2008-09-10 | 株式会社リコー | Image processing circuit, composite image processing circuit, and image forming apparatus |
US9170812B2 (en) | 2002-03-21 | 2015-10-27 | Pact Xpp Technologies Ag | Data processing system having integrated pipelined array data processor |
WO2003088033A1 (en) | 2002-04-09 | 2003-10-23 | University Of Rochester | Multiplier-based processor-in-memory architectures for image and graphics processing |
AU2003286131A1 (en) | 2002-08-07 | 2004-03-19 | Pact Xpp Technologies Ag | Method and device for processing data |
US20060044576A1 (en) | 2004-07-30 | 2006-03-02 | Kabushiki Kaisha Toshiba | Apparatus for image processing |
US7667764B2 (en) | 2004-06-04 | 2010-02-23 | Konica Minolta Holdings, Inc. | Image sensing apparatus |
JP4219887B2 (en) | 2004-12-28 | 2009-02-04 | 富士通マイクロエレクトロニクス株式会社 | Image processing apparatus and image processing method |
ATE504043T1 (en) | 2005-04-28 | 2011-04-15 | Univ Edinburgh | RECONFIGURABLE INSTRUCTION CELL ARRAY |
US7882339B2 (en) | 2005-06-23 | 2011-02-01 | Intel Corporation | Primitives to enhance thread-level speculation |
JP2007067917A (en) | 2005-08-31 | 2007-03-15 | Matsushita Electric Ind Co Ltd | Image data processing apparatus |
US7602974B2 (en) | 2005-10-21 | 2009-10-13 | Mobilic Technology (Cayman) Corp. | Universal fixed-pixel-size ISP scheme |
FR2895103B1 (en) | 2005-12-19 | 2008-02-22 | Dxo Labs Sa | METHOD AND SYSTEM FOR PROCESSING DIGITAL DATA |
US7802073B1 (en) | 2006-03-29 | 2010-09-21 | Oracle America, Inc. | Virtual core management |
US20080111823A1 (en) | 2006-11-13 | 2008-05-15 | Faraday Technology Corp. | Graphics processing system |
EP1927949A1 (en) | 2006-12-01 | 2008-06-04 | Thomson Licensing | Array of processing elements with local registers |
US8321849B2 (en) | 2007-01-26 | 2012-11-27 | Nvidia Corporation | Virtual architecture and instruction set for parallel thread computing |
US20080244222A1 (en) | 2007-03-30 | 2008-10-02 | Intel Corporation | Many-core processing using virtual processors |
TW200842699A (en) | 2007-04-06 | 2008-11-01 | Technology Properties Ltd | Signal processing |
JP4389976B2 (en) | 2007-06-29 | 2009-12-24 | ブラザー工業株式会社 | Image processing apparatus and image processing program |
JP4844853B2 (en) | 2007-09-05 | 2011-12-28 | 国立大学法人東北大学 | Solid-state imaging device and driving method thereof |
CN102047241B (en) | 2008-05-30 | 2014-03-12 | 先进微装置公司 | Local and global data share |
JP4999791B2 (en) | 2008-06-30 | 2012-08-15 | キヤノン株式会社 | Information processing apparatus, control method thereof, and program |
JP5376920B2 (en) | 2008-12-04 | 2013-12-25 | キヤノン株式会社 | Convolution operation circuit, hierarchical convolution operation circuit, and object recognition device |
US8456480B2 (en) | 2009-01-14 | 2013-06-04 | Calos Fund Limited Liability Company | Method for chaining image-processing functions on a SIMD processor |
KR101572879B1 (en) | 2009-04-29 | 2015-12-01 | 삼성전자주식회사 | Dynamic parallel system and method for parallel application program |
US8442927B2 (en) * | 2009-07-30 | 2013-05-14 | Nec Laboratories America, Inc. | Dynamically configurable, multi-ported co-processor for convolutional neural networks |
US20110055495A1 (en) | 2009-08-28 | 2011-03-03 | Qualcomm Incorporated | Memory Controller Page Management Devices, Systems, and Methods |
US8976195B1 (en) | 2009-10-14 | 2015-03-10 | Nvidia Corporation | Generating clip state for a batch of vertices |
US8436857B2 (en) | 2009-10-20 | 2013-05-07 | Oracle America, Inc. | System and method for applying level of detail schemes |
US8595428B2 (en) | 2009-12-22 | 2013-11-26 | Intel Corporation | Memory controller functionalities to support data swizzling |
US8749667B2 (en) | 2010-08-02 | 2014-06-10 | Texas Instruments Incorporated | System and method for maintaining maximum input rate while up-scaling an image vertically |
US8508612B2 (en) | 2010-09-30 | 2013-08-13 | Apple Inc. | Image signal processor line buffer configuration for processing ram image data |
US8797323B2 (en) | 2011-01-18 | 2014-08-05 | Intel Corporation | Shadowing dynamic volumetric media |
WO2012105174A1 (en) | 2011-01-31 | 2012-08-09 | パナソニック株式会社 | Program generation device, program generation method, processor device, and multiprocessor system |
US9092267B2 (en) | 2011-06-20 | 2015-07-28 | Qualcomm Incorporated | Memory sharing in graphics processing unit |
US20130027416A1 (en) | 2011-07-25 | 2013-01-31 | Karthikeyan Vaithianathan | Gather method and apparatus for media processing accelerators |
JP5742651B2 (en) | 2011-10-15 | 2015-07-01 | コニカミノルタ株式会社 | Image processing apparatus, linkage method, and linkage program |
JP5746100B2 (en) | 2011-12-27 | 2015-07-08 | 京セラドキュメントソリューションズ株式会社 | Image forming apparatus |
US8823736B2 (en) | 2012-01-20 | 2014-09-02 | Intel Corporation | Graphics tiling architecture with bounding volume hierarchies |
US10244246B2 (en) | 2012-02-02 | 2019-03-26 | Texas Instruments Incorporated | Sub-pictures for pixel rate balancing on multi-core platforms |
US9235769B2 (en) | 2012-03-15 | 2016-01-12 | Herta Security, S.L. | Parallel object detection method for heterogeneous multithreaded microarchitectures |
TWI520598B (en) | 2012-05-23 | 2016-02-01 | 晨星半導體股份有限公司 | Image processing apparatus and image processing method |
US9232139B2 (en) | 2012-07-24 | 2016-01-05 | Apple Inc. | Image stabilization using striped output transformation unit |
US10318308B2 (en) * | 2012-10-31 | 2019-06-11 | Mobileye Vision Technologies Ltd. | Arithmetic logic unit |
US9378181B2 (en) | 2012-11-09 | 2016-06-28 | Intel Corporation | Scalable computing array |
US8954992B2 (en) | 2013-03-15 | 2015-02-10 | Lenovo Enterprise Solutions (Singapore) Pte. Ltd. | Distributed and scaled-out network switch and packet processing |
US9477999B2 (en) * | 2013-09-20 | 2016-10-25 | The Board Of Trustees Of The Leland Stanford Junior University | Low power programmable image processor |
US10540587B2 (en) | 2014-04-11 | 2020-01-21 | Google Llc | Parallelizing the training of convolutional neural networks |
EP3035204B1 (en) * | 2014-12-19 | 2018-08-15 | Intel Corporation | Storage device and method for performing convolution operations |
US9749548B2 (en) | 2015-01-22 | 2017-08-29 | Google Inc. | Virtual linebuffers for image signal processors |
US10095479B2 (en) | 2015-04-23 | 2018-10-09 | Google Llc | Virtual image processor instruction set architecture (ISA) and memory model and exemplary target hardware having a two-dimensional shift array structure |
US9965824B2 (en) | 2015-04-23 | 2018-05-08 | Google Llc | Architecture for high performance, power efficient, programmable image processing |
US10291813B2 (en) | 2015-04-23 | 2019-05-14 | Google Llc | Sheet generator for image processor |
US9756268B2 (en) | 2015-04-23 | 2017-09-05 | Google Inc. | Line buffer unit for image processor |
US9785423B2 (en) | 2015-04-23 | 2017-10-10 | Google Inc. | Compiler for translating between a virtual image processor instruction set architecture (ISA) and target hardware having a two-dimensional shift array structure |
US9772852B2 (en) | 2015-04-23 | 2017-09-26 | Google Inc. | Energy efficient processor core architecture for image processor |
US9769356B2 (en) | 2015-04-23 | 2017-09-19 | Google Inc. | Two dimensional shift array for image processor |
US10671564B2 (en) * | 2015-10-08 | 2020-06-02 | Via Alliance Semiconductor Co., Ltd. | Neural network unit that performs convolutions using collective shift register among array of neural processing units |
-
2016
- 2016-07-01 US US15/201,204 patent/US10546211B2/en active Active
-
2017
- 2017-06-07 JP JP2018567935A patent/JP6764954B2/en active Active
- 2017-06-07 KR KR1020197000838A patent/KR102232722B1/en active IP Right Grant
- 2017-06-07 EP EP17740501.6A patent/EP3479302B1/en active Active
- 2017-06-07 WO PCT/US2017/036441 patent/WO2018005030A1/en active Search and Examination
- 2017-06-20 GB GB1907743.7A patent/GB2574940B/en active Active
- 2017-06-20 GB GB1814094.7A patent/GB2564285B/en active Active
- 2017-06-20 GB GB1709785.8A patent/GB2554491B/en active Active
- 2017-06-21 DE DE102017113733.5A patent/DE102017113733B4/en active Active
- 2017-06-21 DE DE202017103694.4U patent/DE202017103694U1/en active Active
- 2017-06-23 US US15/631,906 patent/US10789505B2/en active Active
- 2017-06-29 TW TW106121712A patent/TWI690858B/en active
- 2017-07-03 CN CN201710532146.4A patent/CN107563952B/en active Active
-
2020
- 2020-09-22 US US17/028,097 patent/US20210004633A1/en active Pending
Patent Citations (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20150178246A1 (en) | 2013-12-20 | 2015-06-25 | Enric Herrero Abellanas | Processing device for performing convolution operations |
Non-Patent Citations (2)
Title |
---|
Convolutional neural network. In: Wikipedia, the free encyclopedia.Bearbeitungsstand: 17.06.2016.URL: https://en.wikipedia.org/w/index.php?title= Convolutional_neural_network&oldid=725801598[abgerufen am 22.09.2021] |
QADEER, Wajahat [et al.]: Convolution engine: balancing efficiency & flexibility in specialized computing. In: Proceedings of the 40th Annual International Symposium on Computer Architecture. 2013. S. 24-35. |
Also Published As
Publication number | Publication date |
---|---|
CN107563952B (en) | 2021-04-16 |
DE102017113733A1 (en) | 2018-01-04 |
GB2564285B (en) | 2019-07-17 |
JP2019522291A (en) | 2019-08-08 |
US20210004633A1 (en) | 2021-01-07 |
EP3479302B1 (en) | 2023-11-01 |
GB201814094D0 (en) | 2018-10-17 |
JP6764954B2 (en) | 2020-10-07 |
WO2018005030A1 (en) | 2018-01-04 |
US20180005074A1 (en) | 2018-01-04 |
US20180005075A1 (en) | 2018-01-04 |
CN107563952A (en) | 2018-01-09 |
GB2574940B (en) | 2020-07-22 |
DE202017103694U1 (en) | 2017-10-04 |
GB2574940A (en) | 2019-12-25 |
TW201802727A (en) | 2018-01-16 |
GB2564285A (en) | 2019-01-09 |
US10789505B2 (en) | 2020-09-29 |
US10546211B2 (en) | 2020-01-28 |
GB201907743D0 (en) | 2019-07-17 |
GB201709785D0 (en) | 2017-08-02 |
EP3479302A1 (en) | 2019-05-08 |
KR20190022627A (en) | 2019-03-06 |
KR102232722B1 (en) | 2021-03-29 |
GB2554491B (en) | 2018-10-10 |
GB2554491A (en) | 2018-04-04 |
TWI690858B (en) | 2020-04-11 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
DE102017113733B4 (en) | Convolutional neural network on programmable two-dimensional image processor | |
DE112016001837T5 (en) | ARCHITECTURE FOR PERFORMANCE-EFFICIENT AND PROGRAMMABLE HIGH-PERFORMANCE PICTURE PROCESSING | |
DE102017103764A1 (en) | COMPILER-MANAGED MEMORY FOR IMAGE PROCESSOR | |
DE202017103725U1 (en) | Block operations for an image processor having a two-dimensional execution path matrix and a two-dimensional shift register | |
DE112016001836T5 (en) | Energy-efficient processor core architecture for image processors | |
DE102017113735B4 (en) | Statistical operations on a two-dimensional image processor | |
DE112016001835T5 (en) | Sheet generator for image processor | |
DE112016001844T5 (en) | Two-dimensional shift matrix for image processor | |
DE102017113867A1 (en) | Core processes for block operations on an image processor with a two-dimensional runway matrix and a two-dimensional shift register | |
DE19510879C2 (en) | Refraction method for simultaneous, linear equations and memory-distributed parallel processor to carry out the method | |
DE102019112352A1 (en) | REGISTER FILES IN A MULTITHREAD PROCESSOR | |
DE3049437A1 (en) | MATRIX ARRANGEMENT OF A VARIETY OF PROCESSING ELEMENTS FOR PARALLEL PROCESSORS | |
DE102018125805A1 (en) | SYSTEMS, METHODS, AND DEVICES FOR SCALARPRODUCT OPERATIONS | |
DE102015101543A1 (en) | PROCESSING OF PRIMITIVE BLOCKS IN PARALLEL TILING MACHINE PIPES | |
DE102016125846A1 (en) | Macro I / O unit for graphics processor | |
DE102014119038A1 (en) | Execution of processing operations in a SIMD processing unit | |
DE112016005521T5 (en) | Multifunctional execution track for image processor | |
DE102018115991A1 (en) | DIGITAL CIRCUIT FOR CORRECTING A VIGNETING EFFECT IN VALUES OF PIXELS OF AN IMAGE OF AN ELECTRONIC CAMERA | |
DE102006027181B4 (en) | Processor with internal grid of execution units | |
DE102021111028A1 (en) | System and method for int9 quantization | |
DE102007034684A1 (en) | Method for operating a multiprocessor system, in particular in connection with a medical imaging system | |
DE69836408T2 (en) | Method for performing arithmetic and logical operations in fields of a word operand | |
DE112022000529T5 (en) | METHOD AND APPARATUS FOR GATHER/SCATTER OPERATIONS IN A VECTOR PROCESSOR |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
R012 | Request for examination validly filed | ||
R081 | Change of applicant/patentee |
Owner name: GOOGLE LLC (N.D.GES.D. STAATES DELAWARE), MOUN, USFree format text: FORMER OWNER: GOOGLE INC., MOUNTAIN VIEW, CALIF., US |
|
R082 | Change of representative |
Representative=s name: PROCK, THOMAS, DR., GBRepresentative=s name: MAIKOWSKI & NINNEMANN PATENTANWAELTE PARTNERSC, DE |
|
R082 | Change of representative |
Representative=s name: PROCK, THOMAS, DR., GB |
|
R082 | Change of representative |
Representative=s name: PROCK, THOMAS, DR., GB |
|
R016 | Response to examination communication | ||
R018 | Grant decision by examination section/examining division | ||
R130 | Divisional application to |
Ref document number: 102017012424Country of ref document: DE |
|
R020 | Patent grant now final |