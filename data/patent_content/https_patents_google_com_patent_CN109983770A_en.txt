CN109983770A - Multistage composite prediction - Google Patents
Multistage composite prediction Download PDFInfo
- Publication number
- CN109983770A CN109983770A CN201780071236.6A CN201780071236A CN109983770A CN 109983770 A CN109983770 A CN 109983770A CN 201780071236 A CN201780071236 A CN 201780071236A CN 109983770 A CN109983770 A CN 109983770A
- Authority
- CN
- China
- Prior art keywords
- predictor
- fallout predictor
- compound
- prediction
- block
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/50—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding
- H04N19/503—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding involving temporal prediction
- H04N19/51—Motion estimation or motion compensation
- H04N19/53—Multi-resolution motion estimation; Hierarchical motion estimation
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/103—Selection of coding mode or of prediction mode
- H04N19/105—Selection of the reference unit for prediction within a chosen coding or prediction mode, e.g. adaptive choice of position and number of pixels used for prediction
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/103—Selection of coding mode or of prediction mode
- H04N19/109—Selection of coding mode or of prediction mode among a plurality of temporal predictive coding modes
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/103—Selection of coding mode or of prediction mode
- H04N19/11—Selection of coding mode or of prediction mode among a plurality of spatial predictive coding modes
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/50—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding
- H04N19/503—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding involving temporal prediction
- H04N19/51—Motion estimation or motion compensation
- H04N19/513—Processing of motion vectors
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/50—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding
- H04N19/503—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding involving temporal prediction
- H04N19/51—Motion estimation or motion compensation
- H04N19/573—Motion compensation with multiple frame prediction using two or more reference frames in a given prediction direction
Abstract
Be compiled using multistage composite fallout predictor to current block includes: to generate the first compound fallout predictor by combining at least two predictor blocks for the current block, generate the second fallout predictor for being used for the current block, and the first compound fallout predictor and second fallout predictor are combined, to obtain the prediction block for carrying out encoding or decoding to the current block.Can send indicator from the encoder to the decoder to indicate when block to be encoded using multistage composite prediction.
Description
Background technique
Sequence or the static image of frame can be used to indicate video in digital video frequency flow.Digital video can be used in various
Using, comprising: for example, the video that video conference, high definition video amusement, video ads or shared user generate.Number
Video flowing can contain mass data, and consume computing device for processing a large amount of computing resources or the communication resource,
Send or store video data.It has been proposed including compressing with the various methods of other coding techniques to reduce in video flowing
Data amount.
Base can be executed by being divided into frame or image based on the block of one or more prediction blocks of reference frame prediction
In the coding of motion estimation and compensation.In the bitstream to the difference (that is, residual error) between block and prediction block carry out compression and
Coding.Decoder rebuilds frame or image using these differences and reference frame.
Summary of the invention
Disclosed herein is for using multistage composite prediction come for the use of being coded and decoded to block, feature, element and
Implementation.
Disclosed implementation is a kind of method for being encoded to current block on one side.This method packet
It includes: generating the first compound fallout predictor by combining at least two predictor blocks for current block；It generates for current block
Second fallout predictor；And the first compound fallout predictor and second fallout predictor are combined, to obtain for being encoded to current block
Prediction block.Encoding to current block can include: to carry out encoding or decoding to current block.
Therefore, encoder and decoder complexity will not greatly increased or not will increase computing capability or resource is wanted
In the case where asking, reduced bit rate may be implemented.Alternatively, it can be realized while reducing computational resource requirements similar
Bit rate.
Optionally, the second fallout predictor is the second compound fallout predictor, and generating the second fallout predictor includes: to be used for by combination
The other predictor blocks of at least two of current block generate the second compound fallout predictor.
Optionally, generating the second fallout predictor includes: that the second fallout predictor is generated using inter-prediction.
Optionally, generating the second fallout predictor includes: to carry out inter-prediction to current block using NEAREST_MV.
Optionally, generating the second fallout predictor includes: that the second fallout predictor is generated using intra prediction.
Optionally, at least two predictor blocks include the first predicted composition device and the second predicted composition device, and it is multiple to generate first
Closing fallout predictor includes: the pixel for equalizing the first predicted composition device and the second predicted composition device, and the first compound prediction of combination
Device and the second fallout predictor include: the pixel for equalizing the first compound fallout predictor and the second fallout predictor, to obtain prediction block.
Optionally, whether this method may further include: being compound to the second fallout predictor of identification in coded bit stream
The indicator of fallout predictor is encoded.
Optionally, this method may further include: be generated using inter-prediction every at least two predictor blocks
A predictor block.
It on the other hand is a kind of equipment for being encoded according to a kind of implementation of the disclosure to current block, it should
Equipment includes: memory；And processor.The processor is configured as executing the finger of the following operation stored in memory
It enables: generating the first compound fallout predictor by combining at least two predictor blocks for current block；It generates for current block
Second fallout predictor；And the first compound fallout predictor and the second fallout predictor are combined, it is pre- for being encoded to current block to obtain
Survey block.
Optionally, the instruction for generating the second fallout predictor further comprises the instruction of following operation: being used for by combination
The other predictor blocks of at least two of current block generate the second compound fallout predictor.
Optionally, at least two other predictor blocks include the first predicted composition device generated using intra prediction and use
The second predicted composition device that inter-prediction generates.
Optionally, the instruction for generating the second fallout predictor includes the instruction of following operation: by using NEAREST_MV
Inter-prediction is carried out to current block to generate the second fallout predictor.
Optionally, the second fallout predictor is intra predictor generator.
Optionally, at least two predictor blocks include the first predicted composition device and the second predicted composition device, first composition
Fallout predictor is to use the first consecutive frame as reference frame to generate when carrying out inter-prediction to current block, and second forms
Fallout predictor is to be generated when carrying out inter-prediction to current block using the second consecutive frame, and the first consecutive frame is in the video sequence
Before the present frame for the current block being positioned in, and the second consecutive frame is adjacent immediately in first in the video sequence
Before frame and the second fallout predictor is to use the first consecutive frame as reference frame when carrying out inter-prediction to current block to generate
's.
It on the other hand is a kind of a kind of equipment for being decoded according to implementation to current block, the equipment packet
It includes: memory；And processor.The processor is configured as executing the instruction of the following operation stored in memory: according to
Coded bit stream, to be decoded using multistage composite prediction come the indicator encoded to current block to recognizing；Pass through
Combination generates the first compound fallout predictor at least two predictor blocks of current block；Generate the second prediction for current block
Device；And the first compound fallout predictor and the second fallout predictor are combined, to obtain the prediction block for being decoded to current block.
Optionally, indicator identifies whether the second fallout predictor is compound predictor block.
Optionally, the instruction for combining the first compound fallout predictor and the second fallout predictor includes the first compound prediction of equalization
The co-located pixels of device and the second fallout predictor, to obtain the instruction of prediction block.
Optionally, which recognizes the prediction mode for each predictor block at least two predictor blocks.
Optionally, at least two predictor blocks include the first inter predictor and the second inter predictor, and wherein, refer to
Order includes for using identical frame to each of the first inter predictor, the second inter predictor and second fallout predictor
Between prediction mode instruction.
Optionally, the instruction for generating the first compound fallout predictor includes the same position picture of at least two predictor blocks of equalization
Element, to generate the instruction of the first compound fallout predictor.
It should be noted that above-mentioned any feature can make together with any particular aspects of the invention or embodiment
With.
Disclosed in the detailed description below to embodiment, appended claim and attached drawing the disclosure these and
Other aspects.
Detailed description of the invention
Description herein refers to attached drawing, wherein identical appended drawing reference refers to identical component in several views.
Fig. 1 is the schematic diagram of Video coding and decoding system.
Fig. 2 is that by the exemplary block diagram of the computing device of dispatching station or receiving station.
Fig. 3 is the figure for the video flowing that carry out coding to it and then be decoded to it.
Fig. 4 is the block diagram according to the encoder of the implementation of the disclosure.
Fig. 5 is the block diagram according to the decoder of the implementation of the disclosure.
Fig. 6 is the process encoded using multistage composite prediction to current block according to the implementation of the disclosure
Flow chart.
Fig. 7 is the figure predicted according to the interframe three-dimensional of the implementation of the disclosure.
Fig. 8 is the exemplary figure according to the reference frame buffer of the implementation of the disclosure.
Fig. 9 is the figure that three-dimensional is predicted in interframe-frame according to the implementation of the disclosure.
Figure 10 is the figure predicted according to the interframe four-way of the implementation of the disclosure.
Figure 11 is the figure that four-way is predicted in interframe-frame according to the implementation of the disclosure.
Figure 12 is the figure according to the multistage prediction of the implementation of the disclosure.
Figure 13 is the flow chart according to the process of the implementation of the disclosure being decoded to current block.
Specific implementation
As mentioned above, the compression scheme for being related to encoding video flowing may include: using one or more skills
Art divides the image into block and generates digital video output bit flow (that is, coded bit stream), to be limited in output bit flow
In include information.The bit stream received can be decoded to re-create block and source images by limited information.
It can include: chronotaxis using in video flowing that video flowing, perhaps its part (such as frame or block), which is encoded,
Or spatial simlanty improves code efficiency.For example, can be based between identification previously encoded pixel value or previously
Difference (residual error) those of in the combination and current block of the pixel value of coding between pixel value to carry out the current block of video flowing
Coding.
The coding of use space similitude can be referred to as intra prediction.Intra prediction can be attempted using in the periphery of block
Pixel predicted come the pixel value of the block of the frame to video flowing；That is, using in frame identical with block but in the outer of block
The pixel in portion.The prediction block that intra prediction generates is referred to herein as intra predictor generator.It can be held along the direction of prediction
Row intra prediction, wherein each direction can be corresponding with intra prediction mode.Intra prediction mode can be believed by encoder
Number it is sent to decoder.
Inter-prediction can be referred to as using the coding of chronotaxis.Inter-prediction can be attempted using from the time
One or more blocks of the possible displacement of upper neighbouring one or more frames (that is, reference frame) to carry out the pixel value of block pre-
It surveys.Frame neighbouring in time is that the frame for comparing the block that it is encoded in video flowing in time occurs earlier or later
Frame.Inter predictor is referred to herein as according to the prediction block that inter-prediction generates.
Inter-prediction is executed using motion vector.Motion vector for generating prediction block refers to other than present frame
Frame, that is, reference frame.Before or after reference frame can be located at present frame in the sequence of video flowing.Some codecs
Using up to eight reference frames, which can be stored in frame buffer.Motion vector can be with reference to (that is, make
With) one in reference frame in these frame buffers.
Two predictor blocks can be combined, to form the block for video image or the compound fallout predictor in region.It can lead to
It crosses and two or more determining fallout predictors of for example above-mentioned prediction technique (that is, interframe and/or intra prediction) is applied in combination to create
Build compound fallout predictor.For example, compound fallout predictor can be the combination of the first fallout predictor and the second fallout predictor, the first fallout predictor and
Two fallout predictors can be two intra predictor generators (that is, in frame+frame in), intra predictor generator and inter predictor (that is, in frame+frame
Between) or two inter predictors (that is, interframe+interframe).For example, in the case where interframe+interframe, compound inter-prediction energy
Fallout predictor is enough obtained from the first reference frame using the first motion vector, and can be joined using the second motion vector from second
It examines frame and obtains fallout predictor.Reference frame can all be passing frame, all be following frame or its certain combination.Second movement arrow
Amount can be independently of the first motion vector, or can export the second motion vector from the first motion vector.As another example,
And in frame-frame in the case where, compound prediction can using by intra prediction operate generation the first fallout predictor and by frame
Between predicted operation generate the second fallout predictor.
When forming compound fallout predictor, encoder for example can execute average, weighted array, filtering behaviour based on every pixel
Make or estimate each fallout predictor value importance more complicated form, to use the pixel of two individual fallout predictors
To generate the pixel value for combined fallout predictor.Therefore, combined prediction device can generate compound fallout predictor, for example, this is compound
Fallout predictor can be the weighted average of the importance of the average value of two values or the value of each fallout predictor of estimation.
Motion vector can be selected from the reference motion vector list of candidate reference motion vector.Candidate reference movement arrow
Amount can include the motion vector of any previously encoded (or decoded) block in video flowing, such as, from first
The block of the frame of preceding encoded (or decoded) or block from previously encoded (or decoded) same frame.Energy
It is enough to obtain candidate reference motion vector with position block and the surrounding block in reference frame from (current block).For example, surrounding
Block can include the block of the right in same position block, lower left, lower right or lower section.In non-composite inter-prediction (that is, single frame
Between predict) in the case where, at least some reference frames, the candidate reference motion vector for block can include every reference frame
Single fallout predictor motion vector, the single fallout predictor motion vector of every reference frame can be the optimal movement for the reference frame
Vector.It, can be to reference frame to being assessed with (multiple) of the every reference frame pair of determination most in the case where compound inter-prediction
Good speed dynamic vector.It can include in reference motion vector list by each pair of optimum movement vector.
In either case (that is, in frame, interframe or compound prediction), prediction block is generated, and can will be pre-
Block is surveyed from will be to subtracting in the block that it is encoded, to form the residual block that indicate the difference between these blocks.
The implementation of the disclosure can improve motion prediction via multistage composite prediction.It is predicted using multistage composite,
The compound fallout predictor of new type can be created.Multistage composite is predicted as carrying out the region of block or video coding offer more
Candidate predictor.For example, can better adapt to will be to the block that it is encoded for the motion prediction predicted using multistage composite
Special exercise and content change are improved to realize compression.Reference frame buffering can be used in view of some Video Codecs
Maximum value in two of reference frame in device, multistage composite prediction can be generated attached by using the additional combinations of reference frame
The candidate reference motion vector added, to more effectively identify improved prediction block using reference frame.It can remain reasonable
Compression performance is improved while the encoder and decoder complexity of level.
After first describing the environment that multistage composite prediction disclosed herein wherein may be implemented, retouch herein
Details is stated.
Fig. 1 is the schematic diagram of Video coding and decoding system 100.Dispatching station 102 can be: for example, interior with hardware
The computer (such as, the computer described in Fig. 2) of portion's configuration.However, the other of dispatching station 102 are suitably achieved in that
It is possible.For example, the processing of dispatching station 102 can be distributed between multiple devices.
Dispatching station 102 and the connection of receiving station 106 can be used to code and decode video flowing by network 104.Specifically
Ground can encode video flowing in dispatching station 102, and can flow into receiving station 106 to encoded video
Row decoding.Network 104 can be: for example, internet.Network 104 can also be: in this example by video flowing from dispatching station
102 be transferred to receiving station 106 local area network (LAN), wide area network (WAN), Virtual Private Network (VPN), cellular radio network or appoint
What its device.
In one example, receiving station 106 can be that there is the computer of the inside configuration of hardware (such as, to retouch in Fig. 2
The computer stated).However, receiving station 106 it is other be suitably achieved in that it is possible.For example, the processing energy of receiving station 106
It is enough distributed between multiple devices.
Video coding and decoding system 100 it is other be achieved in that it is possible.For example, implementation can omit network
104.In another implementation, video flowing can be carried out encode and then it is stored, for later when
Between be sent to receiving station 106 or any other device with memory.In one implementation, 106 (example of receiving station
Such as, via network 104, computer bus, and/or a certain communication path) encoded video flowing is received, and store the video
Stream, for being decoded later.In sample implementation, real-time transport protocol (RTP) by network 104 for being sent
The video of coding.In another implementation, the transport protocol other than RTP can be used, for example, being based on Hyper text transfer
The video stream protocol of agreement (HTTP).
For example, working as in video conferencing system in use, dispatching station 102 and/or receiving station 106 may include retouching as following
Ability as stating to be coded and decoded to video flowing.For example, receiving station 106 can be video conference participants, it should
Video conference participants receive encoded video bit stream from videoconference server (for example, dispatching station 102), to decode simultaneously
And check, and further the video bit stream of their own is encoded and send it to videoconference server for
Other participants are decoded and check.
Fig. 2 is that by the exemplary block diagram of the computing device 200 of dispatching station or receiving station.For example, computing device 200
It can be realized one or two of dispatching station 102 shown in Fig. 1 and receiving station 106.Computing device 200 can be include multiple meters
The form of the computing system of device or the form of single computing device are calculated, for example, mobile phone, tablet computer, on knee
Computer, notebook computer, desktop computer etc..
CPU 202 in computing device 200 can be central processing unit.Alternatively, CPU202 can be grasped
The device or multiple devices of any other type for the information developed existing for vertical or processing now or later.Although can
Disclosed implementation is practiced using single processor as shown in the figure (for example, CPU 202), but is able to use more than one
A processor realizes the advantage in speed and efficiency.
In implementation, the memory 204 in computing device 200 can be read-only memory (ROM) device or with
Machine accesses memory (RAM) device.The storage device of any other suitable type can be used as memory 204.The memory
204 can include by the code accessed using bus 212 of CPU 202 and data 206.Memory 204 can further comprise
Operating system 208 and application program 210, the application program 210 include that CPU 202 is allowed to execute method described herein extremely
A few program.For example, application program 210 can include using 1 to N is applied, this further comprises executing to N is applied using 1
The Video coding application of method described herein.Computing device 200 can also include auxiliary storage device 214, for example, this auxiliary is deposited
Storage device 214 can be and be memory card that mobile computing device 200 is used together.Because video communication sessions may wrap
Bulk information is included, so they can be stored in auxilary unit 214 in whole or in part and add as needed
It is downloaded in memory 204 to be handled.
Computing device 200 can also include one or more output devices of such as display 218.In one example,
Display 218 can be by display be touch-sensitive display that the operable tactile sensor to sense touch input combines.
Display 218 can be coupled to CPU 202 via bus 212.Replacing other than display 218 or as display 218
For object, being capable of providing allows user to be programmed computing device 200 or in other ways using the other of computing device 200
Output device.When output device is display or when including display, display can be realized in various ways, including logical
Cross the light emitting diode of liquid crystal display (LCD), cathode-ray tube (CRT) display or such as organic LED (OLED) display
(LED) display.
Computing device 200 can also include image sensering device 220 or communicate with image sensering device 220, for example, taking the photograph
As head or now existing for or later develop, image (such as, the figure of the user of operation calculation device 200 can be sensed
Picture) any other image sensering device 220.Image sensering device 220 can be positioned such that it is directed toward operation and calculates dress
Set 200 user.In this example, the position of image sensering device 220 and optical axis can be configured such that the visual field includes direct
Region that is adjacent with display 218 and can be seen that display 218 from it.
Computing device 200 can also include voice sensing device 222 or communicate with voice sensing device 222, for example, wheat
Gram wind or any other sound that can sense the sound near computing device 200 that is now existing or developing later
Sensing device.Voice sensing device 222 can be positioned such that it is directed toward the user of operation calculation device 200, and can
It is configured as receiving the sound (for example, voice or other language) issued in user's operation computing device 200 by user.
Although the CPU 202 of computing device 200 and memory 204 are portrayed as and are integrated into individual unit by Fig. 2, energy
Enough utilize other configurations.The operation of CPU 202 can be distributed on being capable of direct-coupling or across local area network or other networks
On multiple machines (each machine has one or more processors) of coupling.It can be all across multiple machine distributed storages 204
Such as, the memory in multiple machines of the operation of network-based memory or execution computing device 200.Although herein will meter
The bus 212 for calculating device 200 is described as single bus, but the bus 212 of computing device 200 can be made of multiple bus.
Further, auxiliary storage device 214 can couple directly to other components of computing device 200, or can come via network
Auxiliary storage device 214 is accessed, and auxiliary storage device 214 can include single integrated unit (such as, memory card) or more
A unit (such as, multiple memory cards).Therefore, computing device 200 can be realized with various configurations.
Fig. 3 is the exemplary schematic diagram for the video flowing 300 that carry out coding to it and then be decoded to it.Video
Stream 300 includes video sequence 302.At next stage, video sequence 302 includes several consecutive frames 304.Although three frames are described
For consecutive frame 304, but video sequence 302 can include any number of consecutive frame 304.Then, consecutive frame 304 can by into
One step is subdivided into individual frame, for example, frame 306.At next stage, frame 306 can be divided into a series of sections 308 or flat
Face.For example, section 308 can be the subset for allowing to carry out the frame of parallel processing.Section 308 can also can make video data
It is separated into the subset of the frame of individual color.For example, the frame 306 of color video data can include luminance plane and two colorations
Plane.Section 308 can be sampled at varying resolutions.
No matter whether frame 306 is divided into section 308, and frame 306 can be further divided into block 310, these blocks 310
It can include data corresponding with 16 × 16 pixels in such as frame 306.Block 310 can also be arranged to include from picture
The data of one or more sections 308 of prime number evidence.Block 310 can also be any other suitable size, such as, 4 × 4 pictures
Element, 8 × 8 pixels, 16 × 8 pixels, 8 × 16 pixels, 16 × 16 pixels or bigger.
Fig. 4 is the block diagram according to the encoder 400 of the implementation of the disclosure.As described above, encoder 400 can be such as
It is implemented in dispatching station 102 by providing the computer software programs stored in memory (for example, memory 204).It should
Computer software programs can include machine instruction, these machine instructions make to send out when being executed by processor (such as, CPU 202)
102 are seen off in a manner of described herein to encode to video data.Encoder 400 can also be implemented as example,
The specialized hardware for including in dispatching station 102.Encoder 400 has with the next stage, before (by shown in solid line connecting line)
It is performed various functions into path, to use video flowing 300 as input to generate coding or compression bit stream
420: forecast period 402, conversion stages 404, quantization stage 406 and entropy coding stage 408 within the frame/frames.Encoder 400 is also
It may include (by a dotted line shown in connecting line) the reconstruct path for rebuilding frame to be encoded to following block.
In Fig. 4, encoder 400 has with the next stage to perform various functions in reconstruct path: removing quantization stage 410, inverse transformation
Stage 412, reconstruction stage 414 and loop filtering stage 416.The other structures variation of encoder 400 can be used in video flowing
300 are encoded.
When video flowing 300 is presented to be encoded, frame 306 can be handled in blocks.It is predicting within the frame/frames
At stage 402, be able to use intra prediction (also referred to as intra prediction (intra-prediction)) or inter-prediction (
Referred to as inter-prediction (inter-prediction)) or both combination block is encoded.Under any circumstance, all
It is capable of forming prediction block.It, can be according in present frame, previously encoded and rebuild in the case where intra prediction
Sample form all or part of of prediction block.It, can be according to true using motion vector in the case where inter-prediction
The sample in reference frames that fixed one or more had previously been rebuild forms all or part of of prediction block.
Next, referring still to Fig. 4 prediction block can be subtracted from current block to produce in forecast period 402 within the frame/frames
Raw residual block (also referred to as residual error).Conversion stages 404 using it is block-based transformation come by real transform in such as frequency domain
Transformation coefficient.This block-based transformation includes: for example, discrete cosine transform (DCT) and asymmetric discrete sine transform
(ADST).Other block-based transformation are possible.It is possible to further apply the combination of different transformation to single residual error.?
Using in an example of transformation, it is in the frequency domain based on spatial frequency that residual block is transformed to transform coefficient values by DCT.Lowest frequency
Rate (DC) coefficient is on the upper left side of matrix, and highest frequency coefficient is in the lower right of matrix.It is worth noting that, prediction block
Size and the therefore size of resulting residual block, can be of different sizes with transform block.For example, prediction block can be divided into
It is using lesser piece individually converted.
Transformation coefficient is converted into discrete magnitude subvalue using quantizer values or quantization level by quantization stage 406 (should be from
Scattered quantum value is referred to as quantization transform coefficient).For example, divided by quantizer values and transformation series can be truncated in transformation coefficient
Number.Then, entropy coding is carried out to quantization transform coefficient by the entropy coding stage 408.Any number of technology can be used
Execute entropy coding, including token and binary tree.Then, (other information can with the other information for being decoded to block
To include: for example, the type of the prediction used, alternative types, motion vector and quantizer values) together, by entropy-encoded system
Number is exported to compression bit stream 420.It can be by the Entropy Coding for being used to be decoded block in compression bit stream 420
Block, frame, slice and/or section header.Compression bit stream 420 can also be referred to as encoded video stream or encoded video bit
Stream, and these terms will be used interchangeably herein.
(connecting line is shown by a dotted line) reconstruct path in Fig. 4 can be used to ensure that encoder 400 and decoder 500
(described below) is decoded compression bit stream 420 using identical reference frame and block.Reconstruct path execute with it is following
The intimate function of occurring during decoding process of discussing in more detail, including go at quantization stage 410 to amount
Change transformation coefficient to carry out quantization and go quantization transform coefficient to carry out inverse transformation this at the inverse transformation stage 412, to generate
Derive from residual block (also referred to as derivation residual error).In reconstruction stage 414, can predicted within the frame/frames to residual error addition is derived from
The prediction block predicted at stage 402 is to create reconstructed blocks.Can be applied to reconstructed blocks to reduce distortion the loop filtering stage 416
(such as, blocking artefacts).
Other variations of encoder 400 can be used in being decoded compression bit stream 420.For example, for certain pieces or
For person's frame in the case where not needing conversion stages 404, the encoder 400 based on non-shifting can be directly to the residue signal amount of progress
Change.In another implementation, encoder 400 quantization stage 406 and can will go quantization stage 410 to be combined into the single stage.
Fig. 5 is the block diagram according to the decoder 500 of the implementation of the disclosure.Decoder 500 can for example pass through offer
The computer software programs stored in memory 204 are implemented in receiving station 106.The computer software programs can include
Machine instruction, these machine instructions make receiving station 106 with described herein when being executed by processor (such as, CPU 202)
Mode is decoded video data.Decoder 500, which can also be implemented in, to be included in for example, dispatching station 102 or reception
In the hardware stood in 106.Similar to the reconstruct path of encoder 400 discussed above, in one example, decoder 500 wraps
It includes with the next stage to perform various functions, to generate outputting video streams 516 from compression bit stream 420: the entropy decoding stage 502 goes
Quantization stage 504, forecast period 508, reconstruction stage 510, loop filtering stage 512 and is gone at inverse transformation grade 506 within the frame/frames
Block filtering stage 514.The other structures variation of decoder 500 can be used for being decoded compression bit stream 420.
It, can be by the entropy decoding stage 502 come to compression bit stream when compression bit stream 420 is presented to be decoded
Data element in 420 is decoded, to generate one group of quantization transform coefficient.Go quantization stage 504 (for example, by that will quantify
Transformation coefficient is multiplied by quantizer values) quantization transform coefficient quantify, and the inverse transformation stage 506 uses selected change
Change type come to go quantization transform coefficient carry out inverse transformation to generate derivation residual error, the derivation residual error can with pass through encoder
The derivation residual error that the inverse transformation stage 412 in 400 creates is identical.Using from the decoded header information of compression bit stream 420, decode
Device 500 be able to use within the frame/frames forecast period 508 come create in encoder 400 (for example, predicting rank within the frame/frames
402) the identical prediction block of prediction block that section creates.At reconstruction stage 510, prediction block can be added to create to residual error is derived from
Reconstructed blocks.Can be applied to reconstructed blocks to reduce blocking artefacts the loop filtering stage 512.Other filters can be applied to reconstructed blocks
Wave.In this example, the deblocking filtering stage 514 is applied to reconstructed blocks to reduce block distortion, and it is defeated that the result, which is exported,
Video flowing 516 out.The outputting video streams 516 can also be referred to as decoded video streams, and these terms herein can be mutual
Change use.
Other variations of decoder 500 can be used in being decoded compression bit stream 420.For example, decoder 500 is not
Outputting video streams 516 can be generated in the case where needing the deblocking filtering stage 514.In some implementations of decoder 500,
The deblocking filtering stage 514 is applied before the loop filtering stage 512.Additionally or alternatively, in addition to the loop filtering stage
Except 416, encoder 400 further includes the deblocking filtering stage.
Fig. 6 is the process encoded using multistage composite prediction to current block according to the implementation of the disclosure
600 flow chart.Can in encoder (such as, encoder 400 shown in Fig. 4) realization process 600.
For example, process 600 can be implemented as the software program that can be executed by computing device (such as, dispatching station 102).
The software program can include that can be stored in memory (such as, memory 204 or auxiliary storage device 204) and can
It is executed by processor (such as, CPU 202), so that the machine readable instructions of computing device implementation procedure 600.In at least some realities
In existing mode, can completely or partially it be executed by the forecast period within the frame/frames 402 of the encoder 400 of Fig. 4
Journey 600.
Specialized hardware or firmware are able to use to realize process 600.Some computing devices can have multiple memories,
Multiple processors, or both.It is able to use the step of different processors, memory, or both come distributed process 600 or behaviour
Make.Either " memory " meter with a processor or a memory is included using term " processor " in the singular
Device and the device with multiple processors or multiple memories are calculated, these devices, which can be used in, executes described step
Some or all of steps in rapid.
At 602, the first compound fallout predictor is generated by combining at least two predictor blocks for current block.It is formed
The predictor block of compound fallout predictor can be referred to as predicted composition device or blocking herein.In examples described herein
In, each of the first predicted composition device and the second predicted composition device are using as above in relation in the frame described in encoder 400
Or inter-prediction is generated.At 604, process 600 also generates the second fallout predictor using intra prediction or inter-prediction.?
At 606, process 600 combines the first compound fallout predictor and the second fallout predictor, to obtain prediction block.Extremely with further reference to Fig. 7 and Fig. 9
The non-limiting example of Figure 12 describes process 600.In Fig. 7 and Fig. 9 into Figure 12, (REF_x, MV_x) indicates respectively reference frame
With the motion vector of corresponding inter predictor (that is, the prediction block generated by inter prediction operating).For example, the frame of Fig. 7
Between fallout predictor 706 be indicated as using (or reference) reference frame REF_0 and motion vector MV_0.It describes to refer to below for Fig. 8
Frame.
Fig. 7 is the Figure 70 0 predicted according to the interframe three-dimensional of the implementation of the disclosure.Fig. 7 is illustrated to be generated in advance at 2 grades
Survey the compound prediction of two-stage of block.At 0 grade indicated by line 720, process 600 generates at least two predictor blocks at 602,
In this example, that is, inter predictor 704 and inter predictor 706.Process 600 uses the reference frame of reference frame buffer 702
716 carry out fallout predictor 704 between delta frame, and as by illustrated by line 724 using reference frame 714 come fallout predictor between delta frame
706.Process 600 combines inter predictor 706 and inter predictor 704, to generate the first compound predictor block, that is, 1 grade compound
Fallout predictor 708.
At 1 grade indicated by line 722, process 600 generates inter predictor 710 (that is, the second prediction via 604
Device).In this case, the second fallout predictor is inter predictor (that is, being generated using inter-prediction).However, being able to use
Intra prediction generates the second fallout predictor.Process 600 is come between delta frame in advance using the reference frame 718 in reference frame buffer 702
Survey device 710.At 606, process 600 combines 1 grade of compound fallout predictor 708 (that is, first compound fallout predictor) and inter predictor 710
(that is, second fallout predictor), to obtain 2 grades of compound fallout predictors 712.This 2 grades compound fallout predictors 712 form the prediction block of current block.
In some instances, the compound fallout predictor at 1 grade or 2 grades or both place is generated as two individual fallout predictors
The weighted array of pixel.Two individual fallout predictors can meet the size of current block, so that for co-located pixels pixel-by-pixel
On the basis of execute combination.The weighting of fallout predictor can be determined in various ways.For example, the weight of two fallout predictors can divide
It Wei w0 and (1-w0), wherein w0 is value between zero and one.In some implementations, weight w0 can be 1/2, and
Weight (1-w0) can be 1/2, so that the pixel of each fallout predictor in two fallout predictors of equalization.For weight w0's
Other values are possible.For example, weight w0 can be the number between 0 and 16.It can be identical in weighting not at the same level
Or it is different.
As another example, it is able to use the compound prediction based on wedge-shaped (wedge).In the compound prediction based on wedge shape
In, flexible weight can adapt to the texture and location of pixels in current block.Compound prediction based on wedge shape can be based on
Current block is divided into two or more subregions by straight or inclined (that is, not being straight) one or more cut-off rule.
It is able to use the code book of available cut-off rule (partition lines).Compound prediction based on wedge shape can be based on available segmentation
The code book of line divides current block.Interframe and/or intra prediction are able to use individually to predict each subregion of block
(that is, each subregion of block can have individual predictor block).Individual predictor block can be combined to be formed and be had and root
According to the compound predictor block of the identical size of current block of (a plurality of) cut-off rule prediction.
In the case where a cut-off rule, current block is divided into two subregions.It can be individually to each of current block
Subregion carries out inter prediction or infra-frame prediction, to generate the first predictor block and the second predictor block.Compound fallout predictor can be
The smooth weighting or the combination of precipitous weighting (cliff-weighted) of first predictor block and the second predictor block.
It is that the compound fallout predictor for smoothly weighting compound fallout predictor can have and relatively smooth change across compound prediction block
Weight, or can have constant weight (that is, the weight not changed).In contrast, the precipitous compound predictor block energy of weighting
Enough sharp change weight from the first predictor block to the second predictor block using transition region, compared with the size of current block
Compared with the transition region can be narrow.Code book can include one or more transition regions, and weight is applied to the first prediction
Device block and the second predictor block.
Fig. 8 is the exemplary figure according to the reference frame buffer 800 of the implementation of the disclosure.It is such as pre- above in relation to interframe
Description is surveyed, for generating motion vectors reference (that is, use) reference frame of prediction block.It can be by reference frame storing in reference frame
In buffer, such as, reference frame buffer 800.
It is able to use that reference frame (such as, " the last one frame ") carrys out current block to present frame or frame or region carries out
Coding, which is the consecutive frame in video sequence before present frame.When out-of-order video frame is encoded
When (that is, not with their sequences of appearance in video streaming), it can be by the motion information from passing or following video frame
It is included in candidate reference motion vector.For example, can occur to compile video frame using so-called " alternative reference frame "
Code, these " alternative reference frames " are adjacent with the frame being encoded before or after them in time.Alternative reference frame
It can be synthetic frame, which is not present in input video stream, or in the input video stream for being predicted
A frame duplicated frame.After the decoding, it is not possible to display substitution frame.This frame can be similar in non-adjacent future
Video frame.Another example that out-of-order coding may wherein occur is using so-called " gold frame ", which is can
With or can not be adjacent with present frame and be stored in memory for use as reference frame until (for example, with new gold
Frame) video frame rebuild that is replaced.
Reference frame buffer storage carries out the reference frame of encoding or decoding for the block to the frame in video sequence.With reference to
Frame buffer can include reference frame, such as, those described above reference frame.For example, reference frame buffer 800 can include
The last one frame LAST_FRAME802, gold frame GOLDEN_FRAME 804 and alternative reference frame ALTREF_FRAME806.Ginseng
Examining frame buffer can include more, less or other reference frames.Reference frame buffer 800 is shown as including eight
A reference frame.However, reference frame buffer can include being more or less than eight reference frames.
The last one frame LAST_FRAME 802 can be: for example, adjacent before present frame in video sequence
Frame.Gold frame GOLDEN_FRAME 804 can be: for example, the reference that being used to be used as can or can not be adjacent with present frame
The video frame of frame rebuild.Alternative reference frame ALTREF_FRAME 806 can be: for example, in the view in non-adjacent future
Frequency frame, the video frame be after to reference frame.
The reference frame stored in reference frame buffer 800 can be used in identify motion vector so as to frame will to its into
The block of row encoding or decoding is predicted.Can according to the type for the prediction predicted for the current block to present frame come
Use different reference frames.For example, being able to use multiple frames, (such as, one is used for forward prediction when using compound prediction
(for example, LAST_FRAME 802 or GOLDEN_FRAME 804), and one is used for back forecast (for example, ALTREF_
FRAME 806)) current block predicted.
There may be a limited number of reference frames that can be stored in reference frame buffer 800.Such as it is shown in FIG. 8
, reference frame buffer 800 can store up to eight reference frames.Although in eight spaces in reference frame buffer 800
Three spaces are used by LAST_FRAME802, GOLDEN_FRAME 804 and ALTREF_FRAME 806, but five spaces are protected
It holds and can be used for storing other reference frames.
Specifically, other than LAST_FRAME 802, one or more of reference frame buffer 800 can be used can
Space is used to store penultimate frame LAST2_FRAME and/or third last frame LAST3_FRAME as additional forward direction
Reference frame.Other than ALTREF_FRAME 806, additionally it is possible to frame BWDREF_FRAME 808 as after additional after storage
To prediction reference frame.For example, BWDREF_FRAME can in relative distance than ALTREF_FRAME 806 closer to present frame.
In one example, { LAST_FRAME, BWDREF_FRAME } to can be used in generate for being carried out to current block
The compound fallout predictor of coding.In this example, LAST_FRAME be for forward prediction " nearest " forward reference frame, and
BWDREF_FRAME is for back forecast " nearest " backward reference frame.
Current block is predicted based on prediction mode.It can be from one of a variety of intra prediction modes intra prediction
Prediction mode is selected in mode.In the case where inter-prediction, one or more ginsengs in reference frame buffer 800 can be used
Examining frame (includes: for example, LAST_FRAME 802, GOLDEN_FRAME 804, ALTREF_FRAME 806 or any other ginseng
Examine frame) from one of a variety of inter-frame forecast modes inter-frame mode select prediction mode.It can be (all in coded bit stream
Such as, compression bit stream 420 shown in Fig. 4 to Fig. 5) in, from encoder (such as, encoder 400 shown in Fig. 4) by the pre- of current block
Survey mode is sent to decoder (such as, decoder 500 shown in Fig. 5).In this example, bitstream syntax can support three classes interframe
Prediction mode.These inter-frame forecast modes can include: the position identical with current block wherein used in reference frame
Block as prediction block mode (referred to herein as ZERO_MV mode), wherein send motion vector to indicate in reference frame
Will be used as prediction block block the position relative to current block mode (referred to herein as NEW_MV mode) or its
In do not send motion vector and current block and use the last one used by adjacent previously encoded block or penultimate
Non-zero motion vectors come generate prediction block mode (referred to herein as REF_MV mode, and including NEAR_MV or
NEAREST_MV mode).Previously encoded block can be before current block with scanning sequency (for example, raster scan order
Or other scanning sequencies) be encoded those of block.Frame can be used together with any available reference frame in available reference frame
Between prediction mode.Your good reference of NEAREST_MV and NEAR_MV is used for most probable and the second most probable movement of current block
Vector, the most probable and second most probable motion vector pass through the investigation movement arrow in the context (context) of reference
It measures and obtains.With reference to can be cause and effect neighbours in present frame.With reference to the same position motion vector that can be in former frame.
Fig. 9 is Figure 90 0 that three-dimensional is predicted in the frame according to the implementation of the disclosure.Fig. 9 illustrates the compound prediction of two-stage
Another example.At 0 grade indicated by line 920, process 600 generates at least two predictor blocks at 602, in the example
In, that is, intra predictor generator 904 and inter predictor 906.Process 600 is buffered as seen by line 924 using reference frame
Reference frame 914 in device 902 carrys out fallout predictor 906 between delta frame.Reference frame buffer 902 can be the reference frame buffer of Fig. 8
800.Process 600 combines inter predictor 906 and intra predictor generator 904 to generate the first compound fallout predictor, that is, 1 grade compound pre-
Survey device 908.
At 1 grade indicated by line 922, process 600 generates inter predictor 910 (that is, the second prediction at 604
Device).In this example, in Fig. 7, the second fallout predictor is inter predictor.However, the second fallout predictor can be pre- in frame
Survey device.Process 600 uses reference frame 918 and the optionally reference in reference frame buffer 902 in reference frame buffer 902
Frame 714 come generate (as by a dotted line 926 instruction) inter predictor 910.At 606, process 600 combines 1 grade of compound prediction
Device 908 (that is, first compound fallout predictor) and inter predictor 910 (that is, second fallout predictor), to obtain 2 grades of compound fallout predictors
912.This 2 grades compound fallout predictors 912 form the prediction block of current block.
Process 600 can combine inter predictor 906 and intra predictor generator 904 as Fig. 7 description.It is illustrating
Example in, weight w0_0, w0_1 is respectively used to inter predictor 906 and intra predictor generator 904.Process 600 can be as being directed to
1 grade of compound fallout predictor 908 and inter predictor 910 are combined as Fig. 7 description.In the example shown in the series of figures, weight w1_0, w1_1
It is respectively used to 1 grade of compound fallout predictor 908 and inter predictor 910.Weight w0_0, w0_1 can it is identical as w1_0, w1_1 or
It is different.It is noted that can be used and the skill for the combined prediction device at 1 grade in the embodiment or other embodiments
The different technology of art carrys out the combined prediction device at 0 grade.
Figure 10 is the Figure 100 0 predicted according to the interframe four-way of the implementation of the disclosure.It is compound pre- that Figure 10 illustrates two-stage
Another example surveyed.At 0 grade indicated by line 1016, process 600 generates at least two predictor blocks at 602, that is, frame
Between fallout predictor 1002 and inter predictor 1004.Process 600 is generated using the reference frame 1020 in reference frame buffer 1028
Inter predictor 1002, and carry out fallout predictor 1004 between delta frame using reference frame 1022.Reference frame buffer 1028 can be
Reference frame buffer 800 in Fig. 8.Process 600 (for example, using weight 1/2 and 1/2) combines inter predictor 1002 and interframe
Fallout predictor 1004, to generate the first compound fallout predictor, that is, 1 grade of compound fallout predictor _ 1010.
At 604, process 600 generates the second predictor block.In Figure 10, process 600 by line 1018 in (being indicated) 1
The second compound fallout predictor is generated by combining at least two other predictor blocks for current block at grade.That is, the second prediction
Device is 1 grade of compound fallout predictor -11012, this 1 grade compound fallout predictor -1 1012 (being generated using reference frame 1024) interframe is pre-
Survey (for example, using weight 1/2 and 1/2) group of device 1006 and (generating using reference frame 1026) inter predictor 1008
It closes.Alternatively, one or two of same predictor block can be used.It is identical to combine that different technologies can be used
Predictor block is to generate 1 grade of compound fallout predictor _ 1 1012.
At 606,1 grade of compound fallout predictor _ 0 1010 of process 600 (for example, using weight 1/2 and 1/2) combination (that is, the
One compound fallout predictor) and 1 grade of compound fallout predictor _ 1 1012 (that is, second fallout predictor), to obtain 2 grades of compound fallout predictors 1014.2
The compound fallout predictor 1014 of grade forms the prediction block of current block.
Figure 11 is Figure 110 0 that four-way is predicted in the frame according to the implementation of the disclosure.It is compound pre- that Figure 11 illustrates two-stage
Another example surveyed.At 0 grade indicated by line 1116, process 600 generates at least two predictor blocks at 602, that is, frame
Between fallout predictor 1102 and intra predictor generator 1104.In this example, process 600 uses the reference frame in reference frame buffer 1128
1120 carry out fallout predictor 1102 between delta frame.Reference frame buffer 1128 can be the reference frame buffer 800 of Fig. 8.Process 600
(for example, using weight W0_0 and W0_1) combines inter predictor 1102 and intra predictor generator 1104, compound pre- to generate first
Survey device block, that is, 1 grade of compound fallout predictor _ 0 1110.
At 604, process 600 generates the second predictor block at 1 grade indicated by line 1118.In Figure 11, second
Predictor block is compound fallout predictor；That is, the second fallout predictor is 1 grade of compound fallout predictor -1 1112,1 grade of compound fallout predictor -1
1112 be at least two other predictor blocks, (being generated using reference frame 1124) inter predictor 1106 and intra predictor generator
1108 (for example, using weight W0_2 and W0_3) combination.Alternatively, can be used one in same predictor block or
Two.Different technologies can be used to combine identical predictor block, to generate 1 grade of compound fallout predictor _ 1 1112.Weight
W0_0 and W0_1 and weight W0_2 and W0_3 can be identical or be different.
At 606, process 600 combines 1 grade of compound fallout predictor _ 0 1110 (that is, first compound fallout predictor) and 1 grade compound pre-
It surveys device _ 1 1112 (that is, second fallout predictor), to obtain 2 grades of compound fallout predictors 1114.This 2 grades compound compositions of fallout predictor 1114 are worked as
Preceding piece of prediction block.In this example, using weight W1_0 and W1_1, weight W1_0 and W1_1 can with weight W0_0 and
W0_1 and/or weight W0_2 and W0_3 are same or different.
Figure 12 is Figure 120 0 according to the multistage prediction of the implementation of the disclosure.Figure 12 illustrates multistage composite prediction
Example.In this example, 3 grades of compound fallout predictors 1214 are generated at grade 3.This 3 grades compound fallout predictors 1214 form current block
Prediction block.At 0 grade indicated by line 1216, process 600 generates at least two predictor blocks at 602, that is, intra prediction
It is compound pre- that device 1206 and intra predictor generator 1207, the intra predictor generator 1206 and intra predictor generator 1207 are combined to form first
Survey device, that is, 1 grade of compound fallout predictor _ 3 1212.
As shown in the illustration in fig 12, process 600 can also be created at 1 grade (1 grade indicated as passed through line 1218)
Build (by combination inter predictor 1202 and intra predictor generator 1203) compound fallout predictor _ 1 1210 and (by combining interframe
Fallout predictor 1204 and intra predictor generator 1205) 1 grade of compound fallout predictor _ 2 1211.1 grade of compound fallout predictor 1210 and 1 grade is compound
Fallout predictor -2 is combined to generate compound fallout predictor 1213 at 2 grades indicated by line 1220.
Due to not by 1 grade of compound fallout predictor _ 3 1212 and any other 1 grade of predictor block (compound ground or other shapes
Formula) combination, therefore process 600 can be carried out forward to 2 grades.Alternatively, process 600 can be at 2 grades at 1 grade of substitution
Generate 1 grade of compound fallout predictor _ 31212.
At 604, process 600 can generate any number of second prediction according to several expectation grades of compound prediction
Device.For example, 1 grade of compound fallout predictor _ 1 1210,1 grade of compound fallout predictor _ 21211,1 grade of compound fallout predictor _ 3 1212 and 2 grade are again
Closing fallout predictor 1213 can be the second fallout predictor.
At 606, process 600 obtains 3 grades of compound fallout predictors 1214.It, can be via more as shown in for Figure 120 0
A intergrade completes combination the first compound fallout predictor and the second fallout predictor.
Therefore, process 600 can create the prediction block of current block in multiple grades.At 0 grade, one or more frames are created
Interior prediction device and/or inter predictor.0 grade of fallout predictor can be combined as described above (for example, interframe shown in Fig. 7 is pre-
Survey device 704 and inter predictor 706), to generate one or more 1 grade of compound fallout predictor (for example, 1 grade of compound fallout predictor of Fig. 7
708).Some 1 grades compound fallout predictors in 1 grade of compound fallout predictor can be combined (for example, 1 grade of compound fallout predictor _ 0 of Figure 10
1010 and 1 grades of compound fallout predictor _ 1), to create one or more 2 grades of compound fallout predictors (for example, 2 grades of compound fallout predictors of Figure 10
1014).According to several expectation grades, additional interframe and/or intra predictor generator can be generated at (wherein x is greater than 0) x grade
(for example, the inter predictor 710 of Fig. 7 and inter predictor 910 of Fig. 9).It can will be pre- in these additional interframe and/or frame
It surveys device to combine with x grades of compound fallout predictors, with the compound fallout predictor of generation (x+1) grade (for example, 1 grade of compound fallout predictor 708 of combination and frame
Between fallout predictor 710 to form 2 grades of compound fallout predictors 712 of Fig. 7).
Although specific inter predictor and intra predictor generator are shown at different grades into Figure 12 in Fig. 7 and Fig. 9,
It is that the present disclosure is not limited thereto.Any inter predictor, intra predictor generator or inter predictor and frame can be used at any grade
The combination of interior prediction device.For example, the inter predictor 706 of Fig. 7 can be intra predictor generator, the inter predictor 910 of Fig. 9 can
It is intra predictor generator, the intra predictor generator 1108 of Figure 11 can be inter predictor etc..Although in addition, illustrating combination two in advance
The compound fallout predictor of device is surveyed, but the present disclosure is not limited thereto.It can be by combining any number of intra predictor generator, inter-prediction
Device or compound fallout predictor obtain compound fallout predictor.
The additional method of combined prediction device block can be available.As herein or being otherwise disclosed,
Combined prediction device block is (for example, intra predictor generator block or inter predictor block (such as, inter predictor 704 and inter predictor
706)) the compound fallout predictor to generate compound fallout predictor, with another compound fallout predictor is (for example, 1 grade with Figure 10 compound pre-
1 grade of compound fallout predictor _ 0 1010 of survey device -1 1012, or 1 grade of 1 with Figure 12 grade of compound fallout predictor _ 2 1211 are compound
Fallout predictor _ 1 is 1210), the compound fallout predictor with intra predictor generator or inter predictor is (for example, 1 grade of compound fallout predictor of Fig. 7
708 and inter predictor 710) or any combination thereof various methods can be available.
Referring again to Fig. 7 as illustrated examples, the realization side for determining the fallout predictor for multistage composite prediction is described
Formula.It can be by being assessed the motion vector for reference frame pair (that is, search) until the motion vector of reference frame pair
Optimal set is obtained, to obtain 1 grade of compound fallout predictor 708.Can to it is all or all or fewer than possible reference frame into
Row assessment (that is, search).Form the one or more optimum movement vectors and iptimum speed-distortion value phase of the set of motion vector
It is corresponding.Rate-distortion value is to instigate the amount (that is, loss of video quality) of distortion with the rate for being encoded (that is, bit
Number) balance ratio.In Fig. 7, reference frame corresponding with optimum movement vector MV_0, MV_1 is determined as reference frame
714 and 716.
Above-mentioned search process can also be identified for current block in the reference frame in reference frame buffer 702 extremely
The motion vector of few some NEAREST_MV mode and NEAR_MV mode.For each reference frame searched, can identify
Optimum movement vector.The motion vector for being used for NEAREST_MV and NEAR_MV and single motion vector can be added to and be worked as
Preceding piece of reference motion vector list.
For the grade lower than 0 grade, it is able to carry out new motion search, to determine optimum movement vector and reference frame, thus
Generate the second fallout predictor (for example, inter predictor 710).Alternatively, it is able to use the reference motion vector from current block
The best single motion vector (for example, based on minimum speed limit distortion value) of list is come fallout predictor 710 between delta frame.In Fig. 7, ginseng
Examining frame 714 is best single motion vector, and is able to use the reference frame 714 (such as 726 instructions by a dotted line) and carrys out delta frame
Between fallout predictor 710.In some embodiments, it can establish pre- using NEAREST_MV NEAR_MV interframe for next stage
Survey mode carrys out rule of fallout predictor between delta frame itself, to reduce the bit for being encoded to motion vector information
Number.
Using any alternative solution (that is, using single motion vector or using NEAREST_MV or NEAR_MV), no
It executes new motion search and generates the second fallout predictor, to reduce complexity.Equally, 1 grade of compound fallout predictor 708 is being generated
When, the information of (that is, generation) is able to use and had identified that generate multistage composite fallout predictor.
Process 600 can be in coded bit stream (such as, the compression bit stream 420 in Fig. 4 and Fig. 5) to compound prediction class
(for example, one or more syntactic element) indicator of type is encoded.(such as, decoder 500 shown in Fig. 5) decoder
Can be decoded to indicator for example will be from the number of coded bit stream decoded reference frame and motion frame, to solve with determination
Code device executes multistage composite prediction, and multistage composite prediction can be identical as the motion prediction of encoder.For example, indicator can
Identify that three-dimensional type of prediction or four-way predict compound type of prediction.The indicator of four-way prediction can recognize the second fallout predictor
It is compound fallout predictor.In another example, it is compound fallout predictor that the indicator of three-dimensional prediction, which can recognize the second fallout predictor not,.
In any case, indicator can be encoded into the syntactic element in bit stream with process 600 is passed through, or
Person is after the completion of process 600, the number and fallout predictor of the grade of the indicator instruction decoder multistage composite to be executed prediction
In each fallout predictor prediction mode.For example, and referring to Fig.1 2, encoder can indicate compound pre- via syntactic element
Three grades surveyed, and at 1 grade, three compound fallout predictors will be generated: first is compound fallout predictor in interframe-frame, the
Two are compound fallout predictors in interframe-frame, and third be in frame-frame in compound fallout predictor.Encoder can be to can be by
The additional information that decoder uses is encoded.This information can include the identifier of the intra prediction mode for fallout predictor
And/or the identifier and inter prediction reference frame of motion vector, the fallout predictor are formd for encoding to current block
Prediction block.
Compared with prior art, multistage composite prediction can generate in coded bit stream encodes added bit
To generate prediction block.This can be due to needing to the multiple reference frames of identification, multiple motion vectors, and/or a variety of intra prediction moulds
The syntactic element of formula is encoded and is occurred.Added bit can surpass the compression benefit predicted using multistage composite.Multistage is multiple
The implementation for closing prediction can include reducing bit rate while maintaining the encoder and decoder complexity of reasonable level
The step of expense or technology.
In the example for reducing bit-rate overhead, new movement arrow is executed to inter predictor at (wherein, x > 0) grade x
It measures and the new motion vector is encoded, both encoder and decoder are able to use the REF_MV mode of reference frame to obtain
Obtain inter predictor.Further grammer can specify whether NEAREST_MV or NEAR_MV will be used for inter-prediction.Together
Sample does not need that motion vector is written to coded bit stream to carry out inter-prediction in grade x (wherein, x > 0).
In another example for reducing bit-rate overhead, list is can be used in all inter-predictions in multistage composite prediction
Inter-frame forecast mode.For example, all inter-predictions in instruction multistage composite prediction are (for example, pre- for multistage composite when existing
When the indicator of survey) use the encoder of NEAREST_MV mode signal can be used to send AD HOC.
It can also help to reduce bit-rate overhead by more effectively encoding additional movement vector.To for example
For the third motion vector of multistage composite prediction or the 4th motion vector (for example, with 710 phase of inter predictor in Fig. 7
Corresponding motion vector or motion vector corresponding with inter predictor 1006 and 1008 in Figure 10) time for being encoded
Before, it is known that the motion vector of the first compound fallout predictor is (for example, movement corresponding with the inter predictor 704 and 706 of Fig. 7
Vector or motion vector corresponding with the inter predictor 1002 and 1004 of Figure 10).As above incidentally, can incite somebody to action
The motion vector of first compound fallout predictor is added to the reference motion vector list of candidate reference motion vector.These motion vectors
It can be provided more preferably than NEAREST_MV or NEAR_MV to carry out coding to third motion vector and/or the 4th motion vector
Motion vectors reference.In the case where this motion vector provides better motion vectors reference for coding, can generate pair
Third motion vector and/or the 4th motion vector are more effectively encoded.
By improving used context, more effectively reference frame can be encoded, to reduce bit rate
Expense.In entropy coding (for example, at entropy coding stage 408 or entropy decoding stage 502), can be used context model (
Referred to as probability context model or probabilistic model), which is provided to for the symbol for indicating transformation coefficient
The estimation of the conditional probability encoded.Previously encoded data can be used as context for select to be carried out to current block
The context model of coding.For example, when any one of two reference frames of third reference frame and the first compound fallout predictor ginseng
Examine frame it is identical when, encoder can apply specific context.As another example, encoder can be based on by the first compound prediction
The reference frame and third reference frame corresponding with third motion vector and/or the 4th motion vector and/or the 4th ginseng that device uses
Frame is examined to send AD HOC with signal.For example, when the first compound fallout predictor reference frame to be special pattern (for example,
{ LAST_FRAME, BWDREF_FRAME }) and third reference frame when being LAST_FRAME, encoder can be via grammer member
It is usually sent with signal, and does not need to encode reference identifier.
Figure 13 is the process being decoded using multistage composite prediction to current block according to the implementation of the disclosure
1300 flow chart.It can be by decoder come implementation procedure 1300.For example, the pre- within the frame/frames of decoder 500 can be passed through
The survey stage 508 comes completely or partially implementation procedure 1300.It being capable of (connecting by a dotted line in the encoder 400 in Fig. 4
Shown in line) during reconstruct path wholly or partly implementation procedure 1300.For example, storage can be stored in by that will instruct
It is executed in device (such as, the memory 204 of receiving station 106 or dispatching station 102) with being executed by the processor of such as CPU 202
The implementation of process 1300.
Specialized hardware or firmware are able to use to realize process 1300.Some computing devices can have multiple storages
Device, multiple processors or the two.It is able to use the step that different processors, memory or the two carry out distributed process 1300
Rapid or operation.To simplify the explanation, process 1300 is depicted and described as series of steps or operation.However, according to this public affairs
The introduction opened can occur in various orders and/or simultaneously.In addition, according to the step of the disclosure can with it is not shown and retouch herein
The other step 1 stated, which rise, to be occurred.In addition, and the step of not all diagram or operation may be used to realize according to
Theme method.
At 1302, process 1300 according to coded bit stream come to recognize using multistage composite prediction come to current block into
The indicator of row coding is decoded.The indicator can be that guidance decoder is predicted using multistage composite to generate and be used for currently
One or more syntactic elements of the prediction block of block.For example, can according to frame head, piece header or block header come to indicator into
Row decoding.In some cases, indicator may include that the grammer between header divides.For example, frame level indicator can be used
Multistage composite is predicted to identify at least some of frame block, and block grade indicator identifies the type of multistage composite prediction and is used for
The inter-frame forecast mode and/or intra prediction mode of the predicted composition device block of current block.It can also include motion vector and reference
Frame information.
At 1304, process 1300 is generated by combining at least two predictor blocks for current block for current block
The first compound fallout predictor.For example, indicator can include identification for one of each predictor block in predictor block or
The grammer of multiple reference frames and corresponding motion vector, one or more intra prediction modes or any combination thereof.It is based on
The information, process 1300 can be by firstly generating predicted composition device and by their combinations based on the group used by encoder
Conjunction technology (such as, weight) forms the first compound fallout predictor to generate first compound fallout predictor (such as, 1 grade of compound prediction of Fig. 7
Device 708,1 grade of compound fallout predictor 908 of Fig. 9,1 grade of compound fallout predictor _ 0 1010 of Figure 10, Figure 11 1 grade of compound fallout predictor _ 0
1110 etc.).Combination technique can be a priori determined between encoder and decoder, or can be sent from encoder with signal
Combination technique is to be decoded by decoder and be used.
At 1306, process 1300 generates the second fallout predictor for being used for current block.For example, indicator can be pre- for second
Survey device identification intra prediction mode or inter-frame forecast mode.It is pre- that process 1300 generates second using the prediction mode recognized
Survey device.Indicator can identify that the second fallout predictor is frame by including reference frame and/or motion vector in coded bit stream
Between predict.
In some cases, it is compound fallout predictor that indicator, which recognizes the second fallout predictor,.That is, pre- by combination at least two
Device block is surveyed to generate the second fallout predictor.If it is, then process 1300 can determine at 1306 according to coded bit stream
Inter-frame forecast mode and/or the inter-frame forecast mode used, and predicted composition device block is generated after combining them with shape
At the second fallout predictor.It can be determined by the priori between encoder and decoder, be sent out from encoder to decoder with signal
The information sent executes the combination.
It in some implementations, include that indicator can indicate in one or more grades to every in coded bit stream
The predictor block of a inter-prediction uses NEAREST_MV.Equally, decoder is not directed to these blocks and receives individual motion vector
Coding mode.Additionally or alternatively, priori rules may be implemented, it is pre- for 1 grade which allows decoder to be based on
One or more reference frames of device are surveyed to determine the reference frame for 2 grades of fallout predictors.
At 1308, process 1300 combines the first compound fallout predictor and the second fallout predictor, with obtain for current block into
The decoded prediction block of row.Identical mode carries out the combination in a manner of with the combination at encoder.
The various aspects of coding and decoding described above illustrate some coding and decoding technologies.However, it is to be understood that
It is that coding and decoding (as those of used term in detail in the claims) can compression, decompression, transformation with intention to data
Either any other processing or change.
Carry out intention as example, example or explanation using word " example " or " implementation " herein.Herein
Being described as " example ", either any aspect of " implementation " or design are all not necessarily to be construed as prior to or better than other
Aspect or design.On the contrary, using word " example " or " implementation " being intended to that design is specifically presented.As made in this application
, term "or" is intended to indicate that the "or" of the "or" of inclusiveness rather than repellency.That is, unless otherwise indicated, it is no
Then be clear that by context: " X includes A or B " is intended to indicate that any natural inclusiveness displacement.That is, if X includes A；
X includes B；Or X includes A and B, then under any example in previous examples, all meets " X includes A or B ".In addition, such as existing
The article " one " used in the application and appended claim and "one" should be construed generally for expression " one or
It is multiple ", clearly learn that it refers to singular unless otherwise indicated or from the context.In addition, throughout, to term
The use of " implementation " either " a kind of implementation " is not intended to the identical embodiment of intention or implementation, except being far from it
Description.
The implementation of dispatching station 102 and/or receiving station 106 can be realized in hardware, software or any combination thereof
(and be stored in dispatching station 102 and/or receiving station 106 and/or thus (including by encoder 400 and decoder 500) execute
Algorithm, method, instruction etc.).Hardware can include: for example, computer, intellectual property (IP) core, specific integrated circuit
(ASIC), programmable logic array, optical processor, programmable logic controller (PLC), microcode, microcontroller, server, Wei Chu
Manage device, digital signal processor or any other suitable circuit.In detail in the claims, term " processor " should be by
It is interpreted as including any hardware in aforementioned hardware either alone or in combination.Term " signal " and " data " are used interchangeably.
Further, the part of dispatching station 102 and receiving station 106 must be not necessarily realized in an identical manner.
Further, in an aspect, come in fact for example, being able to use computer or processor with computer program
Existing dispatching station 102 or receiving station 106, the computer program implement when executed correlation method described herein, algorithm and/
Or any correlation method, algorithm and/or instruction in instruction.Additionally or alternatively, for example, dedicated computing can be utilized
Machine/processor, the special purpose computer/processor can be containing for carrying out in approach described herein, algorithm or instruction
Any method, algorithm or other hardware of instruction.
For example, dispatching station 102 and receiving station 106 can be implemented on the computer in video conferencing system.It is alternative
Ground, dispatching station 102 can be implemented on the server, and receiving station 106 can be implemented in the dress separated with server
It sets, such as, hand-hold communication device.In this example, dispatching station 102 is able to use encoder 400 for research content into volume
Code vision signal, and encoded vision signal is sent to communication device.Then, then communication device is able to use decoding
Device 500 is decoded encoded vision signal.Alternatively, communication device can be on the communication device to being locally stored
Content be decoded, for example, not being the content sent by dispatching station 102.106 embodiment party of other dispatching stations 102 and receiving station
Formula is available.For example, receiving station 106 can be the personal computer being usually fixed rather than portable communication appts, and/
Or the device including encoder 400 also may include decoder 500.
Further, can take can for example, by tangible computer for all or part of implementation of the disclosure
With or computer-readable medium access computer program product form.Computer can be used or computer-readable medium energy
Enough be can for example, visibly include, store, transmitting or transfer program for any processor using or so as to it is any
Any device of processor connection.Medium can be: for example, electronic device, magnetic device, optical device, electromagnetic device or half
Conductor device.Other suitable media are also available.
Above-described embodiment, implementation and aspect has been described so that being readily appreciated that the disclosure, but does not limit this
It is open.On the contrary, the disclosure is intended to cover include the various modifications and equivalent arrangements in the range of appended claim, accompanying
The range of claims should be endowed broadest interpretation to include allowed by law all this modifications and equivalent structure.
Claims (21)
1. a kind of method for being compiled to current block, comprising:
The first compound fallout predictor is generated by combining at least two predictor blocks for the current block；
Generate the second fallout predictor for being used for the current block；And
The described first compound fallout predictor and second fallout predictor are combined, it is pre- for being compiled to the current block to obtain
Survey block.
2. according to the method described in claim 1, wherein, second fallout predictor is described in the second compound fallout predictor and generation
Second fallout predictor includes:
The described second compound fallout predictor is generated by combining at least two other predictor blocks for the current block.
3. method according to claim 1 or 2, wherein generating second fallout predictor includes:
Second fallout predictor is generated using inter-prediction.
4. according to the method described in claim 3, wherein, generating second fallout predictor includes:
Inter-prediction is carried out to the current block using NEAREST_MV.
5. according to the method described in claim 1, wherein, generating second fallout predictor includes:
Second fallout predictor is generated using intra prediction.
6. according to method described in any one in preceding claims, wherein at least two predictor block includes the
One predicted composition device and the second predicted composition device, generating the first compound fallout predictor includes: that equalization first composition is pre-
The pixel of device and the second predicted composition device is surveyed, and combines the first compound fallout predictor and the second fallout predictor packet
It includes: the pixel of the equalization first compound fallout predictor and second fallout predictor, to obtain the prediction block.
7. according to method described in any one in preceding claims, further comprising:
To identifying whether second fallout predictor is that the indicator of compound fallout predictor encodes in coded bit stream.
8. according to method described in any one in preceding claims, further comprising:
Each predictor block at least two predictor block is generated using inter-prediction.
9. a kind of equipment for being encoded to current block, the equipment include:
Memory；And
Processor, the processor is configured to execute the instruction that stores in the memory with:
The first compound fallout predictor is generated by combining at least two predictor blocks for the current block；
Generate the second fallout predictor for being used for the current block；And
The described first compound fallout predictor and second fallout predictor are combined, it is pre- for being encoded to the current block to obtain
Survey block.
10. equipment according to claim 9, wherein the described instruction for generating second fallout predictor is further wrapped
It includes for instruction below:
The second compound fallout predictor is generated by combining at least two other predictor blocks for the current block.
11. equipment according to claim 10, wherein at least two other predictor blocks include using intra prediction
The the first predicted composition device generated and the second predicted composition device generated using inter-prediction.
12. according to equipment described in any one in claim 9 to 11, wherein for generating second fallout predictor
Described instruction includes being used for instruction below:
Inter-prediction is carried out to the current block by using NEAREST_MV to generate second fallout predictor.
13. equipment according to claim 9, wherein second fallout predictor is intra predictor generator.
14. according to equipment described in any one in claim 9 to 13, wherein at least two predictor block includes
First predicted composition device and the second predicted composition device, the first predicted composition device are to carry out inter-prediction to the current block
When use the first consecutive frame as reference frame to generate, and the second predicted composition device be to the current block carry out
It is generated when inter-prediction using the second consecutive frame, first consecutive frame is in the video sequence immediately in being located in it
In the current block present frame before, and second consecutive frame in the video sequence immediately in first phase
Before adjacent frame and second fallout predictor is to be made when carrying out inter-prediction to the current block using first consecutive frame
It is generated for reference frame.
15. a kind of equipment for being decoded to current block, the equipment include:
Memory；And
Processor, the processor is configured to execute the instruction that stores in the memory with:
According to coded bit stream, the indicator to be encoded using multistage composite prediction to the current block to identification is carried out
Decoding；
The first compound fallout predictor is generated by combining at least two predictor blocks for the current block；
Generate the second fallout predictor for being used for the current block；And
The described first compound fallout predictor and second fallout predictor are combined, it is pre- for being decoded to the current block to obtain
Survey block.
16. equipment according to claim 15, wherein the indicator identifies whether second fallout predictor is compound pre-
Survey device block.
17. equipment according to claim 15 or 16, wherein for combining the described first compound fallout predictor and described second
The described instruction of fallout predictor includes for instruction below: equalizing the first compound fallout predictor and second fallout predictor
Co-located pixels, to obtain the prediction block.
18. equipment described in any one in 5 to 17 according to claim 1, wherein the indicator identification for it is described extremely
The prediction mode of each predictor block in few two predictor blocks.
19. equipment according to claim 18, wherein at least two predictor block include the first inter predictor and
Second inter predictor, and wherein, described instruction include being used for instruction below: to first inter predictor, described
Each of second inter predictor and second fallout predictor use identical inter-frame forecast mode.
20. equipment described in any one in 5 to 19 according to claim 1, wherein for generating the described first compound prediction
The described instruction of device includes for instruction below: the co-located pixels of equalization at least two predictor block, to generate
State the first compound fallout predictor.
21. a kind of computer program product including instruction, described instruction carries out the computer when being executed by computer
According to claim 1 to method described in any one in 8.
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
CN202010645793.8A CN111757106B (en) | 2017-03-14 | 2017-10-31 | Method and apparatus for coding a current block in a video stream using multi-level compound prediction |
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US15/458,403 | 2017-03-14 | ||
US15/458,403 US10362332B2 (en) | 2017-03-14 | 2017-03-14 | Multi-level compound prediction |
PCT/US2017/059293 WO2018169570A1 (en) | 2017-03-14 | 2017-10-31 | Multi-level compound prediction |
Related Child Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202010645793.8A Division CN111757106B (en) | 2017-03-14 | 2017-10-31 | Method and apparatus for coding a current block in a video stream using multi-level compound prediction |
Publications (2)
Publication Number | Publication Date |
---|---|
CN109983770A true CN109983770A (en) | 2019-07-05 |
CN109983770B CN109983770B (en) | 2020-07-24 |
Family
ID=60321017
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202010645793.8A Active CN111757106B (en) | 2017-03-14 | 2017-10-31 | Method and apparatus for coding a current block in a video stream using multi-level compound prediction |
CN201780071236.6A Active CN109983770B (en) | 2017-03-14 | 2017-10-31 | Multi-level composite prediction |
Family Applications Before (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202010645793.8A Active CN111757106B (en) | 2017-03-14 | 2017-10-31 | Method and apparatus for coding a current block in a video stream using multi-level compound prediction |
Country Status (4)
Country | Link |
---|---|
US (2) | US10362332B2 (en) |
EP (1) | EP3596922A1 (en) |
CN (2) | CN111757106B (en) |
WO (1) | WO2018169570A1 (en) |
Cited By (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN110278434A (en) * | 2019-08-06 | 2019-09-24 | 杭州微帧信息科技有限公司 | A kind of method, apparatus and storage medium of quickly more compound frame Video codings |
CN110545208A (en) * | 2019-09-23 | 2019-12-06 | 电子科技大学 | Network traffic prediction method based on LSTM |
Families Citing this family (11)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11445173B2 (en) * | 2017-11-13 | 2022-09-13 | Mediatek Singapore Pte. Ltd. | Method and apparatus for Intra prediction fusion in image and video coding |
US10602178B1 (en) * | 2017-12-21 | 2020-03-24 | Mozilla Corporation | Systems and methods for frame context selection |
WO2019166508A1 (en) * | 2018-02-28 | 2019-09-06 | Fraunhofer-Gesellschaft zur Förderung der angewandten Forschung e.V. | Composed prediction and restricted merge |
WO2020057504A1 (en) * | 2018-09-17 | 2020-03-26 | Mediatek Inc. | Methods and apparatuses of combining multiple predictors for block prediction in video coding systems |
GB2580036B (en) * | 2018-12-19 | 2023-02-01 | British Broadcasting Corp | Bitstream decoding |
WO2021052490A1 (en) | 2019-09-19 | 2021-03-25 | Beijing Bytedance Network Technology Co., Ltd. | Scaling window in video coding |
CN117615155A (en) | 2019-09-19 | 2024-02-27 | 北京字节跳动网络技术有限公司 | Reference sample point position derivation in video coding |
EP4026336A4 (en) | 2019-10-05 | 2022-12-07 | Beijing Bytedance Network Technology Co., Ltd. | Level-based signaling of video coding tools |
JP7391203B2 (en) | 2019-10-12 | 2023-12-04 | 北京字節跳動網絡技術有限公司 | Use and signaling to refine video coding tools |
MX2022004200A (en) | 2019-10-13 | 2022-05-02 | Beijing Bytedance Network Tech Co Ltd | Interplay between reference picture resampling and video coding tools. |
US11800092B2 (en) * | 2021-11-17 | 2023-10-24 | Tencent America LLC | Joint signaling method for motion vector difference |
Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN1984340A (en) * | 2005-11-02 | 2007-06-20 | 三星电子株式会社 | Method and apparatus for encoding and decoding of video |
CN101491107A (en) * | 2006-07-07 | 2009-07-22 | 艾利森电话股份有限公司 | Video data management |
CN107113425A (en) * | 2014-11-06 | 2017-08-29 | 三星电子株式会社 | Method for video coding and equipment and video encoding/decoding method and equipment |
Family Cites Families (16)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN1843037B (en) * | 2003-08-26 | 2010-09-22 | 汤姆森特许公司 | Method and apparatus for encoding hybrid intra-inter coded blocks |
KR100891663B1 (en) * | 2005-10-05 | 2009-04-02 | 엘지전자 주식회사 | Method for decoding and encoding a video signal |
US20070152908A1 (en) * | 2005-12-30 | 2007-07-05 | Khan Mionul H | Adaptive image block fusion |
CA2655970A1 (en) * | 2006-07-07 | 2008-01-10 | Telefonaktiebolaget L M Ericsson (Publ) | Video data management |
CN101711481B (en) * | 2006-10-18 | 2013-01-09 | 汤姆森特许公司 | Method and apparatus for video coding using prediction data refinement |
KR101450940B1 (en) * | 2007-09-19 | 2014-10-15 | 텔레폰악티에볼라겟엘엠에릭슨(펍) | Joint enhancement of multi-channel audio |
KR20090099720A (en) * | 2008-03-18 | 2009-09-23 | 삼성전자주식회사 | Method and apparatus for video encoding and decoding |
EP2269379B1 (en) * | 2008-04-11 | 2019-02-27 | InterDigital Madison Patent Holdings | Methods and apparatus for template matching prediction (tmp) in video encoding and decoding |
PL2661892T3 (en) * | 2011-01-07 | 2022-08-16 | Nokia Technologies Oy | Motion prediction in video coding |
US10123008B2 (en) * | 2011-06-17 | 2018-11-06 | Hfi Innovation Inc. | Method and apparatus for coding of intra prediction mode |
US9531990B1 (en) * | 2012-01-21 | 2016-12-27 | Google Inc. | Compound prediction using multiple sources or prediction modes |
US8737824B1 (en) * | 2012-03-09 | 2014-05-27 | Google Inc. | Adaptively encoding a media stream with compound prediction |
US9883198B2 (en) * | 2012-11-13 | 2018-01-30 | Intel Corporation | Video codec architecture for next generation video |
WO2014120368A1 (en) * | 2013-01-30 | 2014-08-07 | Intel Corporation | Content adaptive entropy coding for next generation video |
US9609343B1 (en) * | 2013-12-20 | 2017-03-28 | Google Inc. | Video coding using compound prediction |
US9992512B2 (en) * | 2014-10-06 | 2018-06-05 | Mediatek Inc. | Method and apparatus for motion vector predictor derivation |
-
2017
- 2017-03-14 US US15/458,403 patent/US10362332B2/en active Active
- 2017-10-31 CN CN202010645793.8A patent/CN111757106B/en active Active
- 2017-10-31 WO PCT/US2017/059293 patent/WO2018169570A1/en unknown
- 2017-10-31 CN CN201780071236.6A patent/CN109983770B/en active Active
- 2017-10-31 EP EP17797829.3A patent/EP3596922A1/en active Pending
-
2019
- 2019-06-07 US US16/434,339 patent/US10555000B2/en active Active
Patent Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN1984340A (en) * | 2005-11-02 | 2007-06-20 | 三星电子株式会社 | Method and apparatus for encoding and decoding of video |
CN101491107A (en) * | 2006-07-07 | 2009-07-22 | 艾利森电话股份有限公司 | Video data management |
CN107113425A (en) * | 2014-11-06 | 2017-08-29 | 三星电子株式会社 | Method for video coding and equipment and video encoding/decoding method and equipment |
Cited By (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN110278434A (en) * | 2019-08-06 | 2019-09-24 | 杭州微帧信息科技有限公司 | A kind of method, apparatus and storage medium of quickly more compound frame Video codings |
CN110545208A (en) * | 2019-09-23 | 2019-12-06 | 电子科技大学 | Network traffic prediction method based on LSTM |
Also Published As
Publication number | Publication date |
---|---|
US20190289319A1 (en) | 2019-09-19 |
US10555000B2 (en) | 2020-02-04 |
US10362332B2 (en) | 2019-07-23 |
WO2018169570A1 (en) | 2018-09-20 |
US20180270502A1 (en) | 2018-09-20 |
EP3596922A1 (en) | 2020-01-22 |
CN111757106A (en) | 2020-10-09 |
CN109983770B (en) | 2020-07-24 |
CN111757106B (en) | 2024-03-08 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN109983770A (en) | Multistage composite prediction | |
US10986361B2 (en) | Video coding using reference motion vectors | |
US11689726B2 (en) | Hybrid motion-compensated neural network with side-information based video coding | |
US20220353534A1 (en) | Transform Kernel Selection and Entropy Coding | |
JP6163674B2 (en) | Content adaptive bi-directional or functional predictive multi-pass pictures for highly efficient next-generation video coding | |
US10484707B1 (en) | Dynamic reference motion vector coding mode | |
CN107852495A (en) | Low time delay video code twice | |
CN107027032A (en) | Last frame motion vector subregion | |
CN111614956B (en) | DC coefficient sign coding scheme | |
CN110741641B (en) | Method and apparatus for video compression | |
WO2018169571A1 (en) | Segmentation-based parameterized motion models | |
CN107302701B (en) | Decoding interpolation filter types | |
WO2019099084A1 (en) | Motion field-based reference frame rendering for motion compensated prediction in video coding | |
WO2014058796A1 (en) | Method and apparatus for video coding using reference motion vectors | |
CN107465923A (en) | Adaptive overlapping block prediction in the video coding of variable block length | |
CN103167286B (en) | Exhaustive sub-macroblock shape candidate save and restore protocol for motion estimation | |
CN106663310B (en) | Frequency domain denoising | |
CN107465925A (en) | Adaptive overlapping block prediction in the video coding of variable block length | |
CN107079156A (en) | Alternately block constrains decision-making mode code | |
CN110679151A (en) | Video coding using parametric motion models | |
CN110692247B (en) | Prediction for composite motion compensation |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
GR01 | Patent grant | ||
GR01 | Patent grant |