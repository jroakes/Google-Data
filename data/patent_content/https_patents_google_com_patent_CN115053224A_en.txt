CN115053224A - Encrypted search without zero-day leakage - Google Patents
Encrypted search without zero-day leakage Download PDFInfo
- Publication number
- CN115053224A CN115053224A CN202080095861.6A CN202080095861A CN115053224A CN 115053224 A CN115053224 A CN 115053224A CN 202080095861 A CN202080095861 A CN 202080095861A CN 115053224 A CN115053224 A CN 115053224A
- Authority
- CN
- China
- Prior art keywords
- encrypted
- hash
- storage device
- documents
- key
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
- 238000000034 method Methods 0.000 claims abstract description 39
- 230000015654 memory Effects 0.000 claims description 32
- 238000012545 processing Methods 0.000 claims description 28
- 230000006870 function Effects 0.000 claims description 25
- 238000004891 communication Methods 0.000 claims description 5
- 241000282326 Felis catus Species 0.000 description 21
- 238000010586 diagram Methods 0.000 description 14
- 238000004590 computer program Methods 0.000 description 8
- 238000012217 deletion Methods 0.000 description 6
- 230000037430 deletion Effects 0.000 description 6
- 230000008859 change Effects 0.000 description 5
- 230000008569 process Effects 0.000 description 5
- 230000004044 response Effects 0.000 description 5
- 238000013459 approach Methods 0.000 description 4
- 230000003287 optical effect Effects 0.000 description 4
- 238000011156 evaluation Methods 0.000 description 3
- 238000002347 injection Methods 0.000 description 2
- 239000007924 injection Substances 0.000 description 2
- 230000003993 interaction Effects 0.000 description 2
- 230000001174 ascending effect Effects 0.000 description 1
- 239000003795 chemical substances by application Substances 0.000 description 1
- 239000004973 liquid crystal related substance Substances 0.000 description 1
- 238000012423 maintenance Methods 0.000 description 1
- 238000012986 modification Methods 0.000 description 1
- 230000004048 modification Effects 0.000 description 1
- 230000006855 networking Effects 0.000 description 1
- 230000000737 periodic effect Effects 0.000 description 1
- 239000004065 semiconductor Substances 0.000 description 1
- 230000001953 sensory effect Effects 0.000 description 1
- 239000007787 solid Substances 0.000 description 1
- 239000000243 solution Substances 0.000 description 1
- 238000000638 solvent extraction Methods 0.000 description 1
- 230000003068 static effect Effects 0.000 description 1
- 238000012546 transfer Methods 0.000 description 1
- 230000000007 visual effect Effects 0.000 description 1
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L63/00—Network architectures or network communication protocols for network security
- H04L63/04—Network architectures or network communication protocols for network security for providing a confidential data exchange among entities communicating through data packet networks
- H04L63/0428—Network architectures or network communication protocols for network security for providing a confidential data exchange among entities communicating through data packet networks wherein the data content is protected, e.g. by encrypting or encapsulating the payload
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/22—Indexing; Data structures therefor; Storage structures
- G06F16/2228—Indexing structures
- G06F16/2255—Hash tables
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/22—Indexing; Data structures therefor; Storage structures
- G06F16/2228—Indexing structures
- G06F16/2246—Trees, e.g. B+trees
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/24—Querying
- G06F16/242—Query formulation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/24—Querying
- G06F16/245—Query processing
- G06F16/2455—Query execution
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/60—Protecting data
- G06F21/602—Providing cryptographic facilities or services
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/60—Protecting data
- G06F21/62—Protecting access to data via a platform, e.g. using keys or access control rules
- G06F21/6218—Protecting access to data via a platform, e.g. using keys or access control rules to a system of files or objects, e.g. local or distributed file system or database
- G06F21/6227—Protecting access to data via a platform, e.g. using keys or access control rules to a system of files or objects, e.g. local or distributed file system or database where protection concerns the structure of data, e.g. records, types, queries
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/60—Protecting data
- G06F21/62—Protecting access to data via a platform, e.g. using keys or access control rules
- G06F21/6218—Protecting access to data via a platform, e.g. using keys or access control rules to a system of files or objects, e.g. local or distributed file system or database
- G06F21/6245—Protecting personal data, e.g. for financial or medical purposes
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L9/00—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols
- H04L9/006—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols involving public key infrastructure [PKI] trust models
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L9/00—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols
- H04L9/06—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols the encryption apparatus using shift registers or memories for block-wise or stream coding, e.g. DES systems or RC4; Hash functions; Pseudorandom sequence generators
- H04L9/065—Encryption by serially and continuously modifying data stream elements, e.g. stream cipher systems, RC4, SEAL or A5/3
- H04L9/0656—Pseudorandom key sequence combined element-for-element with data sequence, e.g. one-time-pad [OTP] or Vernam's cipher
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L9/00—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols
- H04L9/08—Key distribution or management, e.g. generation, sharing or updating, of cryptographic keys or passwords
- H04L9/0861—Generation of secret information including derivation or calculation of cryptographic keys or passwords
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L9/00—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols
- H04L9/08—Key distribution or management, e.g. generation, sharing or updating, of cryptographic keys or passwords
- H04L9/0894—Escrow, recovery or storing of secret information, e.g. secret key escrow or cryptographic key storage
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L9/00—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols
- H04L9/32—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols including means for verifying the identity or authority of a user of the system or for message authentication, e.g. authorization, entity authentication, data integrity or data verification, non-repudiation, key authentication or verification of credentials
- H04L9/3236—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols including means for verifying the identity or authority of a user of the system or for message authentication, e.g. authorization, entity authentication, data integrity or data verification, non-repudiation, key authentication or verification of credentials using cryptographic hash functions
- H04L9/3239—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols including means for verifying the identity or authority of a user of the system or for message authentication, e.g. authorization, entity authentication, data integrity or data verification, non-repudiation, key authentication or verification of credentials using cryptographic hash functions involving non-keyed hash functions, e.g. modification detection codes [MDCs], MD5, SHA or RIPEMD
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L9/00—Cryptographic mechanisms or cryptographic arrangements for secret or secure communications; Network security protocols
- H04L9/40—Network security protocols
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L2209/00—Additional information or applications relating to cryptographic mechanisms or cryptographic arrangements for secret or secure communication H04L9/00
- H04L2209/46—Secure multiparty computation, e.g. millionaire problem
Abstract
A method (900) for providing encrypted searches comprising: a search query (122) for keywords (32) that appear in one or more encrypted documents (152) stored on an untrusted storage device (150) is received at a user device (10) associated with a user (12), and a count table (210) is accessed to obtain a count (212) of documents that include the keywords. The method also includes generating a trusted pseudo-random function (DPRF) (126) based on the key, the private encryption key (124), and the document count. The method also includes evaluating a first portion (126A) of the DPRF and delegating a second portion (126B) of the DPRF to the untrusted storage device, which causes the untrusted storage device to evaluate the DPRF and access the encrypted search index (160). The untrusted storage device determines one or more encrypted documents associated with the DPRF and returns an identifier for each encrypted document (154).
Description
Technical Field
The present disclosure relates to performing an encrypted search without zero-day leakage.
Background
Searchable encryption (i.e., encrypted searching) is becoming increasingly popular as it becomes more common to store large amounts of data in the cloud. An increasing number of users or clients possess a large number of encrypted documents that are stored on servers that are not controlled by the client (i.e., the servers are not trusted). Using searchable encryption, a client can store its encrypted documents on an untrusted server, but still retain the ability to search for documents, e.g., retrieve identifiers for all documents containing a particular keyword. However, such searchable encryption is often accompanied by security and privacy drawbacks.
Disclosure of Invention
One aspect of the present disclosure provides a method for providing encrypted searches without zero-day leakage. The method includes receiving a search query for a keyword at data processing hardware of a user device associated with a user. The keywords appear in one or more encrypted documents in a corpus of encrypted documents stored on an untrusted storage device. The method also includes accessing, by the data processing hardware, the count table to obtain a count of corpus unique documents of the encrypted documents from the corpus of encrypted documents that includes the key, and generating, by the data processing hardware, a trusted pseudo-random function (DPRF) based on the key, the private encryption key, and the count of unique documents that contain the key. The method also includes evaluating, by the data processing hardware, the first portion of the DPRF and delegating, by the data processing hardware, the remaining second portion of the DPRF to the untrusted storage device. When the untrusted storage device receives the remaining second portion of the DPRF, the untrusted storage device is caused to evaluate the remaining second portion of the DPRF and access an encrypted search index associated with a corpus of encrypted documents stored on the untrusted storage device. The untrusted storage device also determines, based on the encrypted search index, one or more encrypted documents in the corpus of encrypted documents associated with the remaining second portion of the DPRF, and returns to the user device an identifier for each encrypted document, the identifier being at least a portion of one or more encrypted documents associated with the remaining second portion of the DPRF.
Implementations of the disclosure may include one or more of the following optional features. In some implementations, generating the DPRF includes generating a binary tree, where the binary tree includes a set of nodes including a root node and a plurality of other nodes. Each other node includes a non-leaf node or a leaf node. The method may further include wherein the number of leaf nodes of the binary tree is equal to or greater than the count of unique documents that include the keyword.
In some examples, a root node of the binary tree includes a private encryption key and a first hash of a key. The root node may be associated with a first child node that includes a first portion of a second hash of a first hash of the private encryption key and the key, and a second child node that includes a second portion of a second hash of the first hash of the private encryption key and the key. Optionally, the first portion of the second hash concatenated with the second portion of the second hash is equivalent to the second hash of the first hash of the private encryption key and the key.
Each leaf node in the set of nodes of the binary tree may be associated with a value stored in the encrypted search index. Each other node in the set of nodes of the binary tree may include a portion of a hash of a parent node associated with the corresponding other node. In some embodiments, evaluating the first portion of the DPRF includes evaluating a first subset of a set of nodes of the binary tree. The untrusted storage device evaluates a second subset of the set of nodes of the binary tree while the untrusted storage device evaluates the remaining second portion of the DPRF. The second subset includes nodes from the set of binary tree nodes that are different from the first subset.
In some examples, the method further comprises: for each unique key of a new encrypted document uploaded by a user into a corpus of encrypted documents stored on an untrusted storage device, incrementing, by data processing hardware in a count table, a count of unique documents in the corpus of encrypted documents that include the corresponding unique key, and generating, by the data processing hardware, a unique key hash from the corpus of encrypted documents that include the corresponding unique key based on a private encryption key, the corresponding unique key, and the incremented count of unique documents. The method may also include generating, by the data processing hardware, a hash pair comprising a unique key hash and an encrypted document identifier associated with a new encrypted document uploaded by a user, and sending, by the data processing hardware, the hash pair to the untrusted storage device.
When the untrusted storage device returns an identifier for each encrypted document of the at least a portion of the one or more encrypted documents associated with the remaining second portion of the DPRF, the untrusted storage device may return encrypted metadata associated with each returned identifier.
Another aspect of the present disclosure provides a system for providing encrypted searches without zero-day leakage. The system includes data processing hardware of a user device associated with a user and memory hardware in communication with the data processing hardware. The memory hardware stores instructions that, when executed on the data processing hardware, cause the data processing hardware to perform operations. The operations include receiving a search query for a keyword. The keywords appear in one or more encrypted documents in a corpus of encrypted documents stored on an untrusted storage device. The operations also include accessing a count table to obtain a count of unique documents in the corpus of encrypted documents that contain the keyword, and generating a trusted pseudo-random function (DPRF) based on the keyword, the private encryption key, and the count of unique documents that include the keyword. The operations also include evaluating a first portion of the DPRF and delegating a remaining second portion of the DPRF to the untrusted memory device. When the untrusted storage device receives the remaining second portion of the DPRF, the untrusted storage device is caused to evaluate the remaining second portion of the DPRF and access an encrypted search index associated with a corpus of encrypted documents stored on the untrusted storage device. The untrusted storage device also determines, based on the encrypted search index, one or more encrypted documents in the corpus of encrypted documents associated with the remaining second portion of the DPRF, and returns to the user device an identifier for each encrypted document, the identifier being at least a portion of the one or more encrypted documents associated with the remaining second portion of the DPRF.
This aspect may include one or more of the following optional features. In some implementations, generating the DPRF includes generating a binary tree, where the binary tree includes a set of nodes including a root node and a plurality of other nodes. Each other node includes a non-leaf node or a leaf node. The operations may also include a case where the number of leaf nodes of the binary tree is equal to or greater than a count of unique documents that include the keyword.
In some examples, a root node of the binary tree includes a private encryption key and a first hash of a key. The root node may be associated with a first child node that includes a first portion of a second hash of the first hash of the key and the private encryption key, and a second child node that includes a second portion of a second hash of the first hash of the key and the private encryption key. Optionally, the first portion of the second hash concatenated with the second portion of the second hash is equivalent to the second hash of the first hash of the private encryption key and the key.
Each leaf node in the set of nodes of the binary tree may be associated with a value stored in the encrypted search index. Each other node in the set of nodes of the binary tree may include a portion of a hash of the parent node associated with the corresponding other node. In some implementations, evaluating the first portion of the DPRF includes evaluating a first subset of a set of nodes of the binary tree. The untrusted storage device evaluates a second subset of the set of nodes of the binary tree while the untrusted storage device evaluates the remaining second portion of the DPRF. The second subset includes nodes from the set of binary tree nodes that are different from the first subset.
In some examples, the operations further include, for each unique key of a newly encrypted document uploaded by a user into the corpus of encrypted documents stored on the untrusted storage device, increasing a count of unique documents within the corpus of encrypted documents, including the corresponding unique key in the count table, and generating a unique key hash based on the private encryption key, the corresponding unique key, and the incremented count of unique documents in the corpus of encrypted documents, including the corresponding unique key. The operations may also include generating a hash pair comprising a unique key hash and an encrypted document identifier associated with a new encrypted document uploaded by a user, and sending the hash pair to the untrusted storage device.
When the untrusted storage device returns an identifier for each encrypted document of the at least a portion of the one or more encrypted documents associated with the remaining second portion of the DPRF, the untrusted storage device may return encrypted metadata associated with each returned identifier.
The details of one or more embodiments of the invention are set forth in the accompanying drawings and the description below. Other aspects, features, and advantages will be apparent from the description and drawings, and from the claims.
Drawings
FIG. 1 provides a schematic diagram of an exemplary system for encrypted searching without zero-day leakage.
FIG. 2 is a diagram of exemplary components of a searchable encryption manager.
Fig. 3 is a schematic diagram of a binary tree.
FIG. 4 is a schematic diagram of a searchable encryption manager and a high-level query.
FIG. 5 is a schematic diagram of an exemplary system that adds documents to a corpus of encrypted documents.
FIG. 6 is a schematic diagram of an exemplary system for deleting a document from a corpus of encrypted documents.
FIG. 7 is a schematic diagram of an untrusted storage device and a count table sub-bucket.
FIG. 8 is a schematic diagram of a probability map for inserting a key into a count table.
FIG. 9 is a flow chart of an exemplary operational arrangement for a method of providing encrypted searches without zero-day leakage.
FIG. 10 is a schematic diagram of an exemplary computing device that may be used to implement the systems and methods described herein.
Like reference symbols in the various drawings indicate like elements.
Detailed Description
Searchable encryption (search, which may also be referred to as encryption) is becoming increasingly popular. The purpose of searchable encryption is to enable a client to outsource storage of a corpus of encrypted documents to an untrusted server. For example, a client may wish to securely store a large number of documents (or any other items uploaded to a server, such as pictures, emails, etc.) in a cloud-based storage solution. The term document is commonly used and may refer to any type of digital file (e.g., a picture, a song, a database entry, etc.). Often, customers desire to maintain the ability to efficiently search for documents (i.e., search for specific keywords) while maintaining the privacy and security of documents provided by encryption. To maintain this privacy, information related to document content or queries from clients must be hidden from untrusted servers. A common approach to solving this problem is to create a separate encrypted search index that indexes the keywords and associated document identifiers of all documents stored on the untrusted server.
This search index is encrypted using a key that is inaccessible to untrusted servers and then stored with the document. The client may then generate a search query that the server evaluates against the encrypted search index. The evaluation generates an encrypted document identifier associated with the keyword of the search query, which the untrusted server returns to the client. In this manner, the client receives a list of document identifiers for documents that include keywords while minimizing information leakage (e.g., to untrusted servers).
Since an untrusted server evaluates the search index against the user's query, the index will gradually reveal information about the search pattern, and by deploying an attack such as frequency analysis, the server may eventually be able to make educated guesses about historical search terms with a non-negligible probability. This is an inherent problem since searches are repeated on the same index, and thus such leakage cannot be effectively prevented.
However, many searchable encryption schemes present many additional security or privacy issues in addition to the problem of such slow leakage using search indices. In one example, some schemes are vulnerable to zero-day attacks. A zero-day attack is an attack that reveals or reveals information to an adversary (e.g., an untrusted storage server) before the storage server processes any queries. That is, a search query (i.e., searching for keywords in an encrypted document) typically reveals at least some information to the server. However, a successful zero-day attack does not require any search query at all to obtain information about the encrypted document.
For example, some searchable encryption schemes hash each key in a document to one or more small values appended to each encrypted document. To search for keywords, each relevant hash value may be searched. However, this scheme displays to the server a frequency table of the number of documents (and identifiers of the documents) that contain a particular hash value. For example, hash values associated with a large number of documents may be more common than hash values associated with fewer documents. This information is displayed to the server prior to executing any search queries. Studies have shown that frequency tables can reveal a large number of keywords. While these schemes may attempt to mitigate this weakness (e.g., by adding random terms), a significant amount of noise must be added to ensure that the frequency problem is overcome, which can significantly reduce the efficiency of the scheme.
Another common security issue that many searchable encryption schemes are vulnerable to is file injection attacks. A prerequisite for these attacks is that an attacker can send an encrypted document (e.g. an email) to the target. These emails will contain specific keywords. When the target queries for these specific keywords, the attacker can see which injected emails are returned, thereby determining the keywords of the query. In some cases, an attacker may even hide the identity of the injected email by hiding keywords that may be notified to the target through, for example, invisible hypertext markup language (HTML). Such an attack may be more complex if the attacker can save the queries executed by the target (or retrieve the queries executed from the log). The attacker may then apply all of these historical queries to recently injected (i.e., injected after the query is executed) emails to compromise the privacy of the query keywords of the historical queries. Thus, when the scheme uses the same hash for all emails in the past or future, the scheme is vulnerable to an attacker, applying all previous queries to the recently injected files.
To mitigate the zero-day attack and file injection attack of encrypted documents while maintaining search functionality and efficiency, implementations herein are directed to an encrypted search scheme using a commissionable pseudorandom function (DPRF) to completely hide the frequency table execution before any search query is executed.
Referring now to fig. 1, in some implementations, an example system 100 includes a user device 10 associated with a respective user or client 12 and in communication with a remote system 111 via a network 112. The user device 10 may correspond to any computing device, such as a desktop workstation, a laptop workstation, or a mobile device (i.e., a smartphone). The user device 10 includes computing resources 18 (e.g., data processing hardware) and/or storage resources 16 (e.g., memory hardware).
The remote system 111 may be a single computer, multiple computers, or a distributed system (e.g., a cloud environment) with extensible/resilient computing resources 118 (e.g., data processing hardware) and/or storage resources 116 (e.g., memory hardware). The untrusted document data store 150 (i.e., the remote storage device 150) is overlaid on the storage resources 116 to allow for scalable use of the storage resources 116 by one or more of the clients or computing resources 118. Document data store 150 is a corpus configured to store documents 152, 152 a-n. Each document 152 includes a document identifier 154 that uniquely identifies the associated document 152 (e.g., document name). Each document 152 also includes a set of keywords 32. The set of keywords 32 includes all keywords that appear in relevant encrypted documents 152 that the user 12 may search for. As used herein, a document 152 may refer to any item uploaded to the remote system 111 for storage within the document data store 150, such as, but not limited to, an email, a calendar event, a note, a database entry, a picture, an audio file, and so forth. In some examples, untrusted storage device 150 stores email corpus 152, and user 12 accesses an inbox through user device 10 to receive and compose emails. In some embodiments, user device 10 executes Searchable Encryption (SE) manager 120 to manage access to encrypted documents 152 within data store 150.
The SE manager 120 receives a search query 122 from a user 12 for one or more keywords 32, the keywords 32 appearing in one or more encrypted documents 152 stored on the untrusted storage device 150. SE manager 120 accesses count table 210 to obtain a count 212 of unique documents 152 in the corpus of encrypted documents 152 containing keywords 32. That is, the count 212 indicates the number of unique documents 152 in which the keyword 32 appears. For example, when the keyword 32 of the query is "cat" and "cat" appears in 526 different documents 152 stored on the storage device 150 and associated with the user 12, the count 212 would be 526.
Referring now to FIG. 2, diagram 200 shows SE manager 120 receiving a key count 212 for query key 32 from count table 210. The count table 210 includes counts 212 of how many different documents 152 the keyword 32 appears in. In the illustrated example, the keyword "cat" appears in 526 documents 152, the keyword "dog" appears in 128 different documents 152, and the keyword "yak" appears in 12 different documents 152. In some examples, count table 210 may be encrypted and SE manager 120 may decrypt count table 210 and/or counts 212 using the encryption key. As discussed in more detail below with reference to fig. 7. As shown in fig. 7, the count table 210 may be stored locally at the user device 10 or remotely (e.g., at the untrusted storage device 150). To maintain privacy, the count table 210 must be kept private and therefore will typically be encrypted, especially when stored remotely from the user device 10.
Referring back to fig. 1, SE manager 120 also obtains a private encryption key 124. In some examples, SE manager 120 generates private key 124. In other examples, SE manager 120 retrieves or receives private key 124 from user device 10 or from user device 10. A third party (e.g., a third party key management service). The SE manager 120 generates a trusted pseudo-random function 126(DPRF) based on the key 32, the private encryption key 124, and a count 212 of unique documents 152 that include the key 32. When a user 12 queries more than one keyword 32, SE manager 120 may generate a separate DPRF126 for each keyword 32.
As used herein, DPRF is a function that uses an input cryptographic key K and an input x to generate an output F (K, x) that is random to any party that cannot access the key K. In particular, DPRF126 allows for delegation of evaluation of a strict subset of the function domain to agents that cannot evaluate functions outside the strict subset.
For example, assume that a user wishes to retrieve values stored on a server, which are associated with a large number of outputs of the function F. That is, the user wishes the server to retrieve or evaluate and storeF (K, x) on the server 1 )，……，F(K,x m ) The associated value. The user may simply send the function F, the key K, and the value range of x to the server, which may evaluate the value range of x to obtain an output. However, in this case, the server may then evaluate the function F for any value of x, since the server has access to the key K. Another possible approach for the user is to evaluate each value of x by himself and then send each output to the server. While this limits the information that the server receives, it needs to send m outputs, which is very inefficient.
Ideally, users would like to minimize the amount of information that the user must send to the server, while also minimizing the amount of information learned by the server. As described in detail in subsequent FIG. 3, DPRF126 is a function that limits the amount of information that the server can obtain by evaluating x values outside of a specified range. For example, when a user sends x 1 To x m For the server to evaluate, the server will not be able to target less than x 1 And x is greater than x m The function F is evaluated. To establish these bounds, the SE manager 120 evaluates the first portion 126A of the DPRF126 and delegates the remaining second portion 126B of the DPRF to the untrusted storage device 150.
Referring again to fig. 2, in some embodiments, SE manager 120 includes DPRF generator 218 and DPRF evaluator 220. DPRF generator 218 generates DPRF126 for the queried key 32 based on private encryption key 124, key 32, and key count 212 received from count table 210. The DPRF generator 218 passes the DPRF126 to the DPRF evaluator 220. As described in detail in subsequent fig. 3, the DPRF evaluator 220 evaluates at least a portion (e.g., the first portion 126a) of the DPRF126 and, based on the evaluated portion, commits (i.e., sends) the remaining second portion 126B to the untrusted remote storage device 150.
Referring back to fig. 1, the untrusted storage device 150 (i.e., the document data store 150 that stores the encrypted documents 152) in response to receiving the remaining second portion 126B of the DPRF126 delegated by the DPRF evaluator of the SE manager 120, evaluates the remaining second portion 126B of the DPRF and accesses an encrypted search index 160 associated with the corpus 152 of encrypted documents stored on the untrusted storage device 150. The storage device 150 determines that the remaining second portion 126B of the DPRF of one or more encrypted documents 152 within the corpus of encrypted documents is based on the encrypted search index 160.
In some implementations, the encrypted search index 160 includes a list of entries 162, 162a-n, where each entry 162 includes an association between a keyword 32 and at least one encrypted document identifier 154 in which the keyword 32 appears. The evaluation of the remaining second portion 126B provides the one or more encryption keys 32 associated with the one or more encrypted document identifiers 154 to the untrusted storage device 150 without revealing the clear text key or the document identifier to the storage device 150. The storage device 150 returns to the user device 10 an identifier 154 for each encrypted document 152 of the at least a portion of the one or more encrypted documents 152 associated with the remaining second portion 126B of the DPRF. That is, in some implementations, the storage device 150 does not return each identifier 154 associated with the document 152 containing the query keyword 32, but rather returns only a portion (e.g., fifty) of the document identifiers 154. Subsequent queries 122 may return additional results (e.g., the next fifty document identifiers 154) by the user 12. In some examples, for example, when the keywords 32 of the query do not appear in any document 152, the storage device 150 returns an empty set (i.e., does not return the document identifier 154) to the user device 10.
In some implementations, when the untrusted storage device 150 returns at least a portion of the document identifiers 154 associated with the encrypted documents 152 that include the query keywords 32, the untrusted storage device also returns encrypted metadata 156 associated with each returned identifier 154. Metadata 156 may include additional relevant or contextual information for user 12. For example, the metadata 156 may include a date (e.g., the date the document 152 was created or uploaded), an author of the document 152, a size of the document 152, a content keyword 32, and the like.
Referring now to FIG. 3, SE manager 120 generates DPRF126 to solve by generating binary tree 300, as previously describedSolution from F (K, x) 1 )，……，F(K,x m ) A range of values of (c). For example, the character K is associated with a particular keyword 32, and each x value of the DPRF126 represents one of the documents 152 in which the selection keyword 32 appears. For example, if the selection key 32 is "cat," then the value 212 associated with the count "cat" is 526, and the cat appears in 526 unique documents 152. In this example, the maximum size of x is 526 (e.g., 1 to 526), and each x would represent one of the documents 152 in which the keyword 32 occurs. Each value of F (K, x) is then associated with a value stored in the encrypted search index 160 that represents the document identifier 154 in which the selected keyword 32 appears.
Thus, in order for SE manager 120 to retrieve all documents 152 having the keyword "cat," SE manager 120 and/or untrusted storage device 150 may evaluate DPRF126 from F (K,1), … …, F (K, 526). Each of the 526 results is associated with a different value stored in the encrypted search index 160. In another example, SE manager 120 may retrieve only a portion of 526 documents 152 that include the keyword "cat". In this example, the SE manager 120 and/or the untrusted storage device 150 will only evaluate a portion of the DPRF 126. For example, to retrieve fifty documents 152, SE manager 120 and/or untrusted storage device 150 may evaluate F (K,1), … …, F (K, 50). Each of the fifty results is again associated with a different value stored in the encrypted search index 160. Similarly, to retrieve the next fifty documents, the SE manager 120 and/or the untrusted store 150 may evaluate F (K, 51), … …, F (K,100), and so on. In this way, the SE manager 120 and the untrusted storage device 150 may evaluate the DPRF126 to obtain results associated with the values (i.e., the entries 162) within the encrypted search index 160. Untrusted storage device 150 may return all or some of the values associated with the results to SE manager 120.
In some implementations, the SE manager 120, in response to receiving the search query 122, generates the DPRF126 associated with the query's keyword 32 by generating a binary tree 300. In other embodiments, SE manager 120 generates binary tree 300 for each. The keywords 32 in the table 210 are counted prior to receiving the search query 122. A binary tree is a tree data structure having a plurality of nodes, where each node in the structure has at most two child nodes. Binary tree 300 includes a set of nodes 310 that includes a root node 310R and a plurality of other nodes 310. Other nodes 310 are non-leaf nodes 310NL or leaf nodes 310L. Each input value of x uniquely assigns a leaf node 310L in ascending order. The number of leaf nodes 310L of the binary tree 300 may be equal to or greater than the count of unique documents 152 that include the relevant keyword 32. For example, if the key "cat" has a count value 212 of 526, SE manager 120 may generate a binary tree 300 having at least 526 leaf nodes 310L for the key "cat". Each of the 526 instances of a "cat" is associated with a particular leaf node 310L.
Each node 310 is also associated with a value 330, 330A-N, which are generally referred to herein as "tokens". In some implementations, the value 330 of each leaf node 310L is associated with a value within an entry 162 of the encrypted search index 160. That is, each value 330 of each leaf node 310L of the binary tree 300 is associated with a value within the encrypted search index 160. Where the encrypted search index 160 is associated with the corresponding keyword 32. Returning to the example of the keyword 32 "cat," each of the 526 leaf nodes 300L in the binary tree 300 generated for the keyword 32 "cat" may be associated with a value stored in the encrypted search index 160, and each of the values associated with the encrypted search index 160 corresponds to a document identifier 154 of a document 152 that includes the keyword 32 "cat.
In some embodiments, the value 330 of the root node 310R of the binary tree 300 is the first hash 340 of the private encryption key 124 and the value of the key 32 associated with the binary tree 300. Thus, each binary tree 300 will have a unique value 330R for each root node 310R of each binary tree 300 generated for the corresponding key 32. Each root node 310R is associated with a first child node (e.g., node "B" in fig. 3) and a second child node (e.g., node "C" in fig. 3). The first child node includes the private encryption key 124 and a first portion 330B of the second hash 342, 342a of the first hash 340 of the key 32, and the second child node includes the private encryption key 124 and a second portion 330C of the second hash 342 of the first hash 340 of the key 32. That is, in some examples, the value 330A of the root node 310R is the first hash 340 of the key 124 and the key 32. This value (shown as "a" in fig. 3) is then hashed (e.g., using SHA256) and the resulting second hash 342a, divided into a first portion 330B and a second portion 330C. As used herein, the terms "hash" and "hash function" are used to indicate any one-way function (i.e., a function that cannot determine an input from an output), and thus, apply equally to encryption operations (e.g., Advanced Encryption Standard (AES)) in addition to hash operations.
In some examples, the first portion 330B of the second hash 342 concatenated with the second portion 330C of the second hash 342 is equivalent to the first hash 340 of the private encryption key 124 and the second hash 342 of the key 32. As shown in fig. 3, a second hash 342 (e.g., SHA256 hash) is the hash of 330A (i.e., root node 310R value 330A) and is equal to "B" | "C" (i.e., value 330B is merged with value 330C). For example, the output of the SHA256 hash is a 256-bit number. The value 330B may correspond to the first 128 bits of the SHA256 output and the value 330C may correspond to the last 128 bits of the SHA256 output. Thus, the value 330B concatenated with the value 330C is equivalent to the hash 342 of the value 330A.
In some embodiments, each other node 310 of the binary tree 300 includes a portion of the hash 342 of the parent node 310 associated with the corresponding other node 310. That is, for each non-root node 310R (i.e., all non-leaf nodes 310NL and all leaf nodes 310L) of the binary tree 300, the value 330 of the node 310 may be part of the hash 342 of the parent node. With continued reference to FIG. 3, node "B" (like root node 310R node "A") has two child nodes 310, node "D" and node "E". Node "C" also has 2 child nodes 310, node "F" and node "G". Since node "D", node "E", node "F" and node "G" do not have child nodes 310, in this example, each of these four nodes is a leaf node 310L. As previously described, the value 330B of node "B" may be the first portion of the hash 342A of the value 330A of node "A". Similarly, the value 330B of node "B" may be hashed (again using, for example, SHA256) and the resulting hash 342B may be split into a first portion 330D and a second portion 330E, each assigned to one of the following values 330, two child nodes 310 (node "D" and node "E"). Also as previously described, the value 330C of node "C" may be the second portion of the hash 342A of the value 330A of node "a". Likewise, the value 330C of node "C" may be hashed (e.g., using SHA256) and the resulting hash 342C may be split into a first portion 330F and a second portion 330G, each assigned to the value 330 node 310 (node "F" and node "G") of one of the two children. Although in the illustrated example, the binary tree 300 stops at these nodes, the binary tree may continue to run for any number of nodes 310 until there are a sufficient number of leaf nodes 310L to account for the count values 212 of the relevant keys 32.
To retrieve all document identifiers 154 associated with each leaf node 310L (i.e., each document identifier 154 associated with a document 152 that includes the query's keyword 32), the SE manager 120 may simply send a hash of the token for node "A" (e.g., the keyword 124 and the keyword 32) and the count value 212 and allow the untrusted storage device 150 to determine the value of each leaf node 310L. In examples where the SE manager 120 only needs to retrieve a portion of the document identifier 154 associated with the keyword 32, the SE manager 120 may evaluate the first portion 126A and delegate only the second portion 126B to the untrusted storage device 150 to limit, for example, when the document 152 includes an email, the user 12, when querying the keyword 32, may receive the last 50 emails including the query's keyword 32 and only if the user indicates a desire for more results will return additional emails.
In some implementations, the document identifiers 154 are sorted in a chronological order (e.g., the document identifier 154 associated with the first leaf node 310L is the oldest document and the document identifier 154 associated with the last leaf node 310L is the newest document, or vice versa), a series of leaf nodes 310L starting from the lower left or lower right corner of the binary tree may be associated with the newest or oldest document 152 associated with the keyword 32. This allows only a portion of the document identifier 154 associated with the keyword 32 to be returned. The keywords 32 (e.g., the fifty recent documents 152) are queried without looking up each keyword 32 instance in the search index 160. This can greatly reduce the total amount of computation required. Although a chronological order is shown in this example, the document identifiers 154 may of course be sorted based on any other desired criteria.
With continued reference to FIG. 3, in examples where SE manager 120 need only retrieve document identifiers 154 associated with tokens 330D, 330E of node "D" and node "E", it may be desirable to avoid providing the necessary information to the untrusted storage device to determine the values of node "F" and node "G", as these nodes are unnecessary for query 122. In this case, SE manager 120 may evaluate a first subset of nodes 310 of binary tree 300 and untrusted storage device 150 may evaluate a second subset of nodes 310 of binary tree 300 that is different from the subset evaluated by SE manager 120.
For example, when SE manager 120 does not provide value 330A of root node 310R to untrusted storage device 150 but instead provides value 330B of node "B" to untrusted storage device 150, untrusted storage device 150 may evaluate DPRF126 (e.g., binary tree 300) to obtain values 330D, 330E of leaf node 310L, node "D," and node "E" using token 330B of node "B. Because the hash function used to obtain token 330B is a one-way function, untrusted storage device 150 cannot use the value to obtain value 330A of root node 310R, and therefore cannot use the value to obtain tokens 330C, 330F, 330G for node "C", node "F", and node "G". Thus, by determining the minimum number of nodes 310 for which the union of leaf nodes 310L accurately (and only) covers the set of values 330 corresponding to the range of document identifiers 154 to be retrieved, the amount of information provided to the untrusted storage device 150 is minimized while maintaining low bandwidth requirements. To return the additional document identifier 154, the SE manager 120 can track by sending the additional value 330 to the untrusted storage device (e.g., the value 330C of node "C" to obtain the values 330F, 330G of node "F" and node "G").
In some embodiments, each entry 162 of the encryption index 160 is an association between exactly one keyword 32 and one document identifier 154. However, in some embodiments, the search index 160 may be optimized without reducing privacy. Instead of each entry 162 of the encrypted index 160 including an association between one keyword 32 and one document identifier 154, each entry 162 may include an association between one keyword 32 and a plurality of document identifiers 154. That is, each entry 162 is associated with a plurality of document identifiers 154 in which the keyword 32 is added to the keyword 32. Note that if there is no limit to the number of document identifiers 154 that each entry 162 may be associated with a single keyword 32, the search index will risk revealing frequency table information. To mitigate this risk, each entry 162 may be limited to a maximum number of document identifiers. For example, each entry 162 may be limited to fifty or one hundred document identifiers 154. In practice, this ensures that keywords with a high frequency (i.e., appearing in many documents 152) will be divided into many different entries 162 in the search index 160.
In some examples, the maximum number of document identifiers may change dynamically based on the frequency of the keywords 32. As the frequency of keywords 32 increases (i.e., keywords 32 are more common in documents 154), the maximum number of document identifiers may increase. As a result, the untrusted storage device 150 does not have to process as many hashes. The count table 210 may be used to track the maximum number of document identifiers for each keyword 32 and the number of document identifiers 154 currently associated with each entry 162. Alternatively, instead of the count table 210 tracking the number of document identifiers 154 currently associated with each entry 162, each time the SE manager 120 adds a new key 32, the SE manager 120 may create a new entry 162 and add a key 32 to the new entry 162 based on the key probabilities. On average, this results in the addition of the expected number of document identifiers 154 to the entry 1622 before another new entry 162 is created. In this way, the count table 210 need not track the number of document identifiers 154 assigned to each entry 162, thereby reducing the size of the count table 210.
Reference is now made to the schematic diagram 400 of fig. 4. As shown in fig. 4, in some examples, SE manager 120 receives disjunctive, conjunctive, or negative search queries 122D, 122C, 122N. Extracted query 122D includes a query of two or more keywords 32 combined with a logical OR. For example, the extracted query 122D may include a query for "cat" or "dog" and should result in the return of any document identifiers 154 associated with the documents 152, including one or both of the keywords "cat" and "dog". For the extracted query 122D, the SE manager 120 may generate a DPRF126 and corresponding sections 126B, 126Ba-n, respectively, for each keyword 32. Upon receiving the document identifier 154 for each keyword 32 at the user device 10, the SE manager 120 can combine the results and, in some embodiments, rank the results using any metadata 156 returned with the document identifier 154.
The conjunction query 122C includes a query of two or more keywords 32 combined with a logical AND. For example, the conjunction query 122C may include a query for "cat" and "dog" and should result in the return of any document identifiers 154 associated with documents 152 that include both "cat" and "dog". Similar to the disjunct query 122D, for the conjunct query 122C, the SE manager 120 may generate a DPRF126 and a corresponding portion 126B for each keyword 32, respectively. After receiving the document identifier 154 for each keyword 32 at the user device 10, the SE manager 120 may return only the returned document identifier 154 for each keyword 32 to the user 12.
Referring now to fig. 5, in some examples, system 100 displays user 12 adding/uploading a new document 152N to a corpus of encrypted documents 152 stored on untrusted storage device 150. In this case, the encrypted search index 160 is updated with the keyword 32 existing in the newly added document 152. The new document 152N is associated with a new document identifier 154N. In some implementations, for each unique keyword 32 of a new encrypted document 152N uploaded by the user 12 into the corpus of encrypted documents 152 stored on the untrusted storage device 150, the SE manager 120 increments a count 212 of the unique document 152 within the corpus of encrypted documents 152 including the corresponding unique keyword 32 in the count table 210. For example, when the new document 152N includes the keyword "cat" and the current count 212 associated with the keyword "cat" is 526, the count 212 is incremented to 527.
In some examples, the SE manager 120 generates the unique key hash 520 based on the private encryption key 124, the corresponding unique key 32, and the incremented count 212 of the unique document 152 that includes the corresponding unique key 32 within the corpus of encrypted documents. For example, SE manager 120 may use hash function 510 to compute H kw ＝F(K||kw,cnt kw ) In which H kw Represents hash value 520, K represents private encryption key 126, kw represents key 32, and cnt kw Representing an incremented count 212. Any suitable one-way function or algorithm may be used to hash or encrypt the key 32 (e.g., SHA 256).
Draft documents 152 (e.g., emails that are saved without being sent or are being actively composed) are typically saved by the user device 10 often (e.g., every few seconds). SE manager 120 may update search index 160 drafts the same frequency as below or with a different frequency. For example, when the draft is saved every 5 seconds, the SE manager 120 may update the encrypted search index 160 every 5 minutes. In some implementations, SE manager 120 may update encrypted search index 160 at the same rate as the draft is saved, but update count table 210 at a slower frequency. In this case, token 330 may be temporarily reused to update search index 160 until count table 210 is updated at a future time.
When the document 152 stored on the untrusted storage device 150 is an email, the SE manager 120 may automatically add the email received at the user device 10 to the corpus of encrypted emails on the untrusted storage device. In some examples, emails that have been received but not yet opened are not added to the search index 160. That is, in some examples, SE manager 120 automatically adds open emails to search index 160. In this way, a sender may revoke an email without the SE manager 120 and/or the untrusted storage device 150 inferring the contents of the revoked email from the keywords 32.
Referring now to FIG. 6, similar to adding document 152, system 100 displays SE manager 120, in some embodiments, receiving a delete request 630 to delete document 152 from untrusted storage device 150. In this case, the SE manager 120 retrieves each key 32 (e.g., from the untrusted storage device 150) present in the document 152 to be deleted, and for each key 32, decrements the corresponding count 212 in the count table 210. The SE manager then instructs the untrusted storage device to delete the value within the encrypted search index associated with deleted document 152D. For example, SE manager 120 may generate a hash 620 of private encryption key 124, key 32, and appropriate count 212 (or other identifier) using hash function 610 to generate a hash pair 622 with document identifier 154. SE manager 120 may send hash pair 622 to untrusted storage device 150 to indicate to the untrusted storage device which entries within encrypted search index 160 are to be deleted. The untrusted storage device 150 may run a periodic task to periodically update the search index 160. In some implementations, the untrusted storage device 150 maintains a list of all document identifiers 154 for the deleted documents 152 and removes any document identifiers 154 associated with the deleted documents 152 before returning results from the search query 122.
Optionally, the untrusted storage device 150 may periodically compress (e.g., perform garbage collection) the search index 160 after one or more documents 152 have been deleted. After deleting a document, the deleted document may create a "hole" at the count 212 associated with the deleted document 152. When deletion from a document becomes available, the untrusted storage device 150 may move or shift the entry in the search index 160 with the higher count 212 to one of the lower counts. The resulting empty higher count entry may then be deleted from the search index 160.
In some scenarios, user 12 may wish to delete portions of document 152 without deleting the entire document 152. In this case, some keywords 32 are removed from the document 152 and the encrypted search index 160 no longer accurately reflects that the existing keywords 32 are in the modified document 152. In some embodiments, deletion index 660 includes references to keywords 32 deleted from documents 152 within the corpus of encrypted documents stored on data store 150. The deletion index 660 can be generated and maintained similar to when new document keywords are added to the search index 160. Before the untrusted storage device 150 returns the document identifiers 154 associated with the query keyword, the untrusted storage device may reference the deletion index 660 to determine whether the deletion index 660 indicates that any document identifiers 154 include keywords 32 that have been deleted. The untrusted storage device 150 may delete the document identifier 154, where the deletion index indicates that the keywords 32 of the query are removed therefrom.
To prevent zero-day leakage (e.g., frequency table attacks), it is important that the plaintext of count table 210 is not available to anyone other than user 12. However, it is also desirable that users 12 have easy access to count table 210 from various user devices 10 at the same time. There are a number of ways of storing the count table 210 that address these issues to varying degrees. For example, the count table may be stored locally only on the user device 10. However, this implementation has significant disadvantages, as the user is limited to user device 10 storing count table 210, and it is difficult to recover count table 210 if user device 10 loses count table 210 (e.g., user device 10 crashes).
Another way to implement is to store the count table 210 on the untrusted storage device 150 in an encrypted format. The count table 210 may be encrypted with a second private encryption key that is different from the private encryption key 124, or the count table 210 may be encrypted using the same private encryption key 124. The user device 10 may then, when executing the query, first download the encrypted count table 210 from the storage server 150, decrypt it, and execute the query. Whenever a document 152 is added or removed from the corpus of encrypted documents, the user device 10 may send an updated count table 210 to the untrusted storage device 150. This allows synchronization between multiple user devices 10 and ensures that backups are made in the event of a user device crash, however, bandwidth requirements can be large, particularly for some user devices (e.g., mobile phones). At the cost of greatly increased complexity, the untrusted storage device 150 may instead store an incremental backup of the count table 210. For example, backups may be uploaded at regular intervals (e.g., once per day or every few hours). The user device may upload changes to the count table 210 (e.g., add or delete documents 152) and the untrusted storage device 150 may track these changes to the count table 210 until the next backup upload.
Yet another implementation for storing count table 210 involves storing an encrypted count table 210 on untrusted storage device 150 and accessing encrypted entries of count table 210. For example, for each key 32, the untrusted storage device 150 may store an encrypted identifier with an encrypted unique key pointing to the count 212 of the key. When user 12 adds document 152, user 12 requests that the untrusted storage device return an encrypted count 212 associated with the identifier. The user device 10 may then perform a search as described above using the recovered count 212 and then send the encrypted incremented count back to the untrusted storage device 150 for updating by the untrusted storage device 150. This implementation provides protection against crashed user equipment and minimizes the required bandwidth. However, logs accessing encrypted counts may reveal frequency information if not deleted correctly. This frequency information may allow for the generation of a frequency table that may be used in an attack.
In yet another embodiment, the count table 210 is replaced with a single maximum count integer. The max count integer may be set to the max count 212. That is, the maximum count integer may be set to the count 212 of the keyword 32 having the highest count 212 (i.e., appearing in the most documents 152). When searching for a key 32, the SE manager 120 may delegate the DPRF126 to the untrusted storage device 150 for the entire range up to the maximum count integer. The untrusted storage device may perform a search (e.g., a binary search) on the encrypted search index 160 to obtain the actual count 212 of queried keywords 32. For example, the untrusted storage device 150 may determine that the result in the matching maximum count value encrypted search index 160 is the actual count 212 of the keyword. This implementation eliminates the need for a count table 210, but increases the number of lookups that the untrusted storage device 150 must perform on the encrypted search index 160, while also potentially reducing privacy, as search logs may reveal the count frequency of the keywords 32.
In yet another embodiment, the count table 210 is partitioned into a plurality of different access buckets. Here, partitioning may use k-anonymity, where k-anonymity refers to the property of anonymous data in which a particular member of a community cannot be readily identified or distinguished from the data.
Reference is now made to schematic diagram 700 of fig. 7. As shown in fig. 7, in some embodiments, SE manager 120 divides count table 210 into a plurality of buckets 710, 710a-n and stores buckets 710 on untrusted storage device 150. Here, each bucket 710 stores one or more unique counts 212 of documents 152 in the corpus of encrypted documents 152 that include the corresponding keyword 32. That is, each key 32 and associated pair of counts 212 712, 712a-n (e.g., "cats" and 526) is encrypted and assigned to bucket 710 and each bucket is stored on untrusted storage device 150. The untrusted storage device 150 may host any number of buckets 710 and each bucket 710 may store any number of key count pairs 712, but each key count pair 712 is assigned to only one single bucket 710. SE manager 120 may request a particular pair 712 (e.g., count 212 for a particular key) by generating and sending a bucket request 720 to untrusted storage device 150 indicating a particular bucket 710 of the plurality of buckets 710. In response, the untrusted storage device 150 returns each pair 712 stored in a particular bucket 710. As such, the untrusted storage device 150 cannot discern the particular pair 712 from the bucket of pairs that the untrusted storage device 150 returns to the SE manager 120. The SE manager 120 may determine which bucket 710 to assign the pair 712 to by generating the second DPRF 726, the output field of the second DPRF 726 being simply the number of buckets 710.
The bandwidth required for the sub-buckets is balanced with the strength of anonymity provided by the sub-buckets. That is, the larger the number of key and count pairs 712 per bucket 710 (i.e., when the total number of buckets 710 is small), the larger the number of pairs 712 returned for each query 122, the greater the anonymity, and the bandwidth consumed. Conversely, the fewer the number of key and count pairs 712 per bucket 710 (i.e., when the total number of buckets 710 is large), the fewer the number of pairs 712 returned for each query 122, the less anonymity, and bandwidth consumption. This implementation ensures that leakage can be mitigated by k-anonymization techniques even without deleting logs generated by untrusted storage devices. In particular, frequency leakage occurs at the granularity of a bucket (which will typically contain k encryption pairs 712), so frequency leakage only leaks around the frequency of a set of k keys 32.
In some examples, the total number of buckets 710 is fixed. That is, the number of buckets 710 in use does not change, and new key count pairs 712 are continually added to the same buckets 710. Over time, as the number of key count pairs 712 per bucket increases, the overall bandwidth consumption of the bucketization technique likewise increases. In other examples, the number of buckets 710 is not fixed (i.e., dynamic bucketing). In this case, the output domain of the second DPRF 726 is the maximum number of buckets (e.g., 1024) that can be deployed. As with the fixed bucket implementation, a second DPRF 726 is used to assign key count pairs 712 to buckets 710. To reduce the number of buckets 710 from the maximum number allocated for the second DPRF 726 to a desired number, different possible outputs may combine multiple buckets 710 of the second DPRF 726 into a single bucket 710. That is, two or more buckets 710 may be dynamically associated together.
For example, if the maximum number of buckets is 1,024, but the target number of buckets is 64, every 16 buckets 710 may be combined such that when a key count pair 712 from one of the 16 buckets is requested, the untrusted storage device 150 will return all pairs 712 from each of the 16 buckets. Note that each set of buckets 710 need not constitute the same number of buckets 710. For example, one group may be 16 buckets and another group 32 buckets. To increase or decrease the number of buckets 710, SE manager 120 may simply change the number of buckets 710 combined. This allows SE manager 120 to dynamically change the number of buckets 710 in use without physically changing the underlying count table 210. Dynamic binning also ensures that counts 212 placed in the same bucket 710 are logically adjacent for efficiency purposes when count table 210 is stored in sorted order.
Fig. 8 shows a graph 800 depicting the likelihood of inserting a new key 32 into the count table 210 when the probability 810 of entering the key is 0.02. The graph 800 has an x-axis representing a plurality of documents 152 having the same new key 32 and a y-axis representing the probability or likelihood of adding the new key 32 to the count table 210. As can be seen from the graph 800, as the number of documents 152 with new keywords 32 approaches 200, the probability of entering keywords 32 approaches 100%. In some implementations, the count table 210 is reduced in size by adding new keys 32 to the count table 210 based on probabilities. That is, when a new document 152N (fig. 5) is added to the corpus of encrypted documents stored on the untrusted storage device 150, the SE manager 120 may determine whether to add a keyword 32 to the count table 210 based on the probability 810 when the new document 152N contains a keyword 32 that is not already in the count table 210. For example, the probability 810 of adding a new key 32 to the count table 210 may be 1/50 (i.e., 2%). When the SE manager 120 determines that a key 32 is to be added to the count table 210 based on the probability 810 (e.g., 2% of the time), the key 32 is added as described in FIG. 5. When the SE manager 120 determines not to add the key 32 to the count table 210 based on the probability 810, the SE manager 120 may instead randomly assign the key 32 to tokens 330 within the threshold range. In some examples, the threshold range may be a default number (e.g., fifty) of document identifiers 154 retrieved in response to the search query.
For example, when the SE manager 120 determines not to add a new key 32 to the count table 210, the SE manager 120 may use a random count value 212 between 1 and 50 to instead generate a hash pair 522 as described with respect to fig. 5. When used in additional documents, the new keyword 32 will eventually be added to the count table 210 (i.e., eventually, the keyword 32 will be added to the count table 210 based on the probability 810).
While it is likely that some tokens 330 will be used for multiple documents 152, i.e., when a count value 212 between 1 and 50 is randomly selected, due to the nature of the uncommon key 32, the same number is randomly selected more than once and the likelihood that the key 32 will eventually be added to the count table 210 is high, the amount of information leaked by the shared token 330 is minimal. At most, the untrusted storage device 150 may know that each document 152 sharing the same token 300 has a common keyword 32. The untrusted storage device 150 does not know what the keywords 32 are or the total number of documents 152 that include the keywords 32. This technique may greatly reduce the size of the count table 210 because rarely used keys (e.g., symbols, acronyms, names, etc.) will not be included. This reduces the storage cost of storing the count table 210 and the communication cost during operation of the count table (e.g., with respect to fig. 7).
Fig. 9 is a flow diagram of an exemplary operational arrangement for a method 900 of providing encrypted searches without zero-day leakage. The method 900 includes, at step 902, receiving a search query 122 for keywords 32 at data processing hardware 18 of a user device 10 associated with a user 12. The keywords 32 appear in one or more encrypted documents 152 within a corpus of encrypted documents 152 stored on the untrusted storage device 150. The method 900 includes, at step 904, accessing, by the data processing hardware 18, the count table 210 to obtain a count 212 of unique documents 152 in the corpus of encrypted documents 152 including the keyword 32; and at step 906, generating, by the data processing hardware 18, a delegateable pseudorandom function (DPRF)126 based on the key 32, the private encryption key 124, and the count 212 of the unique document 152 including the key 32.
At step 908, the method 900 includes evaluating, by the data processing hardware 18, the first portion of the DPRF 126A, and at step 910, delegating, by the data processing hardware 18, the remaining second portion of the DPRF 126B to the untrusted storage device 150. The remaining second portion of the DPRF, when received by the untrusted storage device 150, causes the untrusted storage device 150 to evaluate the remaining second portion of the DPRF 126B (at step 912), access an encrypted search index 160 associated with the corpus 152 of encrypted documents stored on the untrusted storage device 150, and determine one or more encrypted documents 152 within the corpus 152 of encrypted documents associated with the remaining second portion of the DPRF 126B based on the encrypted search index 160. The storage device 150 also returns to the user device 10 an identifier 154 of each encrypted document 152 and the remaining second portion of the DPRF 126B for at least a portion of the associated one or more encrypted documents 152.
FIG. 10 is a schematic diagram of an example computing device 1000 that may be used to implement the systems and methods described in this document. Computing device 1000 is intended to represent various forms of digital computers, such as laptops, desktops, workstations, personal digital assistants, servers, blade servers, mainframes, and other appropriate computers. The components shown here, their connections and relationships, and their functions, are meant to be exemplary only, and are not meant to limit implementations of the inventions described and/or claimed in this document.
The storage device 1030 is capable of providing mass storage for the computing device 1000. In some implementations, the storage device 1030 is a computer-readable medium. In various different implementations, the storage device 1030 may be a floppy disk device, a hard disk device, an optical disk device, or a tape device, a flash memory or other similar solid state storage device, or an array of devices, including devices in a storage area network or other configurations. In further embodiments, a computer program product is tangibly embodied in an information carrier. The computer program product contains instructions that, when executed, perform one or more methods, such as those described above. The information carrier is a computer-or machine-readable medium, such as the memory 1020, the storage device 1030, or memory on processor 1010.
The high speed controller 1040 manages bandwidth-intensive operations for the computing device 1000, while the low speed controller 1060 manages lower bandwidth-intensive operations. Such allocation of duties is exemplary only. In some implementations, the high-speed controller 1040 is coupled to memory 1020, display 1080 (e.g., through a graphics processor or accelerator), and to high-speed expansion ports 1050, which may accept various expansion cards (not shown). In some implementations, low-speed controller 1060 is coupled to storage device 1030 and low-speed expansion port 1090. The low-speed expansion port 1090 may include various communication ports (e.g., USB, bluetooth, ethernet, wireless ethernet) that may be coupled, e.g., through a network adapter, to one or more input/output devices, such as a keyboard, a pointing device, a scanner, or a network device, such as a switch or router.
As shown, computing device 1000 may be implemented in a number of different forms. For example, it may be implemented as a standard server 1000a or multiple times in a group of such servers 1000a, as a laptop computer 1000b, or as part of a rack server system 1000 c.
Various implementations of the systems and techniques described here can be realized in digital electronic and/or optical circuits, integrated circuits, specially designed ASICs (application specific integrated circuits), computer hardware, firmware, software, and/or combinations thereof. These various implementations can include implementation in one or more computer programs that are executable and/or interpretable on a programmable system including at least one programmable processor, which may be special or general purpose, coupled to receive data and instructions from, and to transmit data and instructions to, a storage system, at least one input device, and at least one output device.
These computer programs (also known as programs, software applications or code) include machine instructions for a programmable processor, and can be implemented in a high-level procedural and/or object-oriented programming language, and/or in assembly/machine. As used herein, the terms "machine-readable medium" and "computer-readable medium" refer to any computer program product, non-transitory computer-readable medium, apparatus and/or device (e.g., magnetic discs, optical disks, memory, Programmable Logic Devices (PLDs)) used to provide machine instructions and/or data to a programmable processor, including a machine-readable medium that receives machine instructions as a machine-readable signal. The term "machine-readable signal" refers to any signal used to provide machine instructions and/or data to a programmable processor.
The processes and logic flows described in this specification can be performed by one or more programmable processors (also known as data processing hardware) executing one or more computer programs to perform functions by operating on input data and generating output. The processes and logic flows can also be performed by, and in particular by, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit). Processors suitable for the execution of a computer program include, by way of example, both general and special purpose microprocessors, and any one or more processors of any kind of digital computer. Generally, a processor will receive instructions and data from a read-only memory or a random access memory or both. The essential elements of a computer are a processor for executing instructions and one or more memory devices for storing instructions and data. Generally, a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks. However, a computer need not have such a device. Computer-readable media suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, such as internal hard disks or removable disks; magneto-optical disks; and CD ROM and DVD-ROM disks. The processor and the memory can be supplemented by, or incorporated in, special purpose logic circuitry.
To provide for interaction with a user, one or more aspects of the present disclosure may be implemented on a computer having a display device, e.g., a CRT (cathode ray tube), LCD (liquid crystal display) monitor or touch screen for displaying information, to provide a user with input and an optional keyboard and pointing device, e.g., a mouse or a trackball, by which the user can provide input to the computer. Other types of devices may also be used to provide for interaction with a user; for example, feedback provided to the user can be any form of sensory feedback, such as visual feedback, auditory feedback, or tactile feedback; input from the user can be received in any form, including acoustic, speech, or tactile input. Further, the computer may interact with the user by sending and receiving documents to and from the device used by the user; for example, by sending a web page to a web browser on the user's client device in response to a request received from the web browser.
Many implementations have been described. Nevertheless, it will be understood that various modifications may be made without departing from the spirit and scope of the disclosure. Accordingly, other implementations are within the scope of the following claims.
Claims (20)
1. A computer-implemented method (900) that, when executed by data processing hardware (18) of a user device (10) associated with a user (12), causes the data processing hardware (18) to perform operations comprising:
receiving a search query (122) for keywords (32), the keywords (32) appearing in one or more of the encrypted documents (152) in a corpus of encrypted documents (152) stored on an untrusted storage device (150);
accessing a count table (210) to obtain a count (212) of unique documents (152) in the corpus of encrypted documents (152) that include the keyword (32);
generating a trusted pseudo-random function (DPRF) (126) based on the key (32), a private encryption key (124), and the count (212) of the unique document (152) that includes the key (32);
evaluating a first portion (126A) of the DPRF; and
delegating a remaining second portion (126B) of the DPRF to the untrusted storage device (150), the remaining second portion (126B) of the DPRF, when received by the untrusted storage device (150), causing the untrusted storage device (150) to:
evaluating a remaining second portion (126B) of the DPRF;
accessing an encrypted search index (160) associated with the corpus of encrypted documents (152) stored on the untrusted storage device (150);
determining one or more of the encrypted documents (152) in the corpus of encrypted documents (152) associated with the remaining second portion (126B) of the DPRF based on the encrypted search index (160); and
returning to the user equipment (10) an identifier (154) of each of the encrypted documents (152) of at least a portion of the one or more encrypted documents (152) associated with the remaining second portion (126B) of the DPRF.
2. The method (900) of claim 1, wherein generating the DPRF (126) comprises:
generating a binary tree (300), said binary tree (300) comprising a set of nodes (310), said set of nodes (310) comprising a root node (310R) and a plurality of other nodes (310), each of said other nodes (310) comprising a non-leaf node (310NL) or a leaf node (310L),
wherein the number of the leaf nodes (310L) of the binary tree (300) is equal to or greater than the count (212) of the unique documents (152) that include the keyword (32).
3. The method (900) of claim 2, wherein:
the root node (310R) of the binary tree (300) comprises a first hash (340) of the private encryption key (124) and the key (32); and
the root node (310R) is associated with a first child node comprising the private encryption key (124) and a first portion (330B) of a second hash (342) of the first hash (340) of the key (32) and a second child node comprising the private encryption key (124) and a second portion (330C) of the second hash (342) of the first hash (340) of the key (32).
4. The method (900) of claim 3, wherein the first portion (330B) of the second hash (342) concatenated with the second portion (330C) of the second hash (342) is equivalent to the second hash (342) of the first hash (340) of the key (32) and the private encryption key (124).
5. The method (900) according to any of claims 2-4, wherein each of the leaf nodes (310L) in the set of nodes (310) of the binary tree (300) is associated with a value stored in the encrypted search index (160).
6. The method (900) of any of claims 2-5, wherein each of the other nodes (310) of the set of nodes (310) of the binary tree (300) includes a portion of a hash (342) of a parent node (310) associated with the corresponding other node (310).
7. The method (900) of any of claims 2-6, wherein evaluating the first portion (126A) of the DPRF includes evaluating a first subset of the set of nodes (310) of the binary tree (300).
8. The method (900) of claim 7, wherein when the untrusted storage device (150) evaluates the remaining second portion (126B) of the DPRF, the untrusted storage device (150) evaluates a second subset of the set of nodes (310) of the binary tree (300), the second subset including nodes (310) from the set of nodes (310) of the binary tree (300) that are different than the first subset.
9. The method (900) of any of claims 1-8, wherein the operations further comprise, for each unique keyword (32) of a new encrypted document (152N) uploaded by the user (12) into the corpus of encrypted documents (152) stored on the untrusted storage device (150):
incrementing a count (212) of the unique document (152) in the corpus of encrypted documents (152) that includes the corresponding unique keyword (32) in the count table (210);
generating a unique key hash (520) based on the private encryption key (124), the corresponding unique key (32), and an incremented count (212) of the unique documents (152) in the corpus of encrypted documents (152) that include the corresponding unique key (32);
generating a hash pair (522) comprising the unique key hash (520) and an encrypted document identifier (154N) associated with the new encrypted document (152N) uploaded by the user (12); and
sending the hash pair (522) to the untrusted storage device (150).
10. The method (900) of any of claims 1-9, wherein when the untrusted storage device (150) returns the identifier (154) for each of the encrypted documents (152) of the at least a portion of one or more of the encrypted documents (152) associated with the remaining second portion (126B) of the DPRF, the untrusted storage device (150) returns encrypted metadata (156) associated with each returned identifier (154).
11. A system (100), comprising:
data processing hardware (18) of a user device (10) associated with a user (12); and
memory hardware (16) in communication with the data processing hardware (18), the memory hardware (16) storing instructions that, when executed on the data processing hardware (18), cause the data processing hardware (18) to perform operations comprising:
receiving a search query (122) for keywords (32), the keywords (32) appearing in one or more of the encrypted documents (152) in a corpus of encrypted documents (152) stored on an untrusted storage device (150);
accessing a count table (210) to obtain a count (212) of unique documents (152) in the corpus of encrypted documents (152) that include the keyword (32);
generating a trusted pseudo-random function (DPRF) (126) based on the key (32), a private encryption key (124), and the count (212) of the unique document (152) that includes the key (32);
evaluating a first portion (126A) of the DPRF; and
delegating a remaining second portion of DPRF (126B) to the untrusted storage device (150), the remaining second portion of DPRF (126B), when received by the untrusted storage device (150), causing the untrusted storage device (150) to:
evaluating a remaining second portion (126B) of the DPRF;
accessing an encrypted search index (160) associated with the corpus of encrypted documents (152) stored on the untrusted storage device (150);
determining one or more of the encrypted documents (152) in the corpus of encrypted documents (152) associated with the remaining second portion (126B) of the DPRF based on the encrypted search index (160); and
returning to the user equipment (10) an identifier (154) of each encrypted document (152) of at least a portion of the one or more encrypted documents (152) associated with the remaining second portion (126B) of the DPRF.
12. The system (100) of claim 11, wherein generating the DPRF (126) comprises:
generating a binary tree (300), the binary tree (300) comprising a set of nodes (310), the set of nodes (310) comprising a root node (310R) and a plurality of other nodes (310), each of the other nodes (310) comprising a non-leaf node (310NL) or a leaf node (310L),
wherein the number of the leaf nodes (310L) of the binary tree (300) is equal to or greater than the count (212) of the unique documents (152) that include the keyword (32).
13. The system (100) of claim 12, wherein:
the root node (310R) of the binary tree (300) comprises a first hash (340) of the private encryption key (124) and the key (32); and
the root node (310R) is associated with a first child node comprising the private encryption key (124) and a first portion (330B) of a second hash (342) of the first hash (340) of the key (32) and a second child node comprising the private encryption key (124) and a second portion (330C) of the second hash (342) of the first hash (340) of the key (32).
14. The system (100) as in claim 13, wherein the first portion (330B) of the second hash (342) concatenated with the second portion (330C) of the second hash (342) is equivalent to the second hash (342) of the private encryption key (124) and the first hash (340) of the key (32).
15. The system (100) according to any one of claims 12-14, wherein each of the leaf nodes (310L) in the set of nodes (310) of the binary tree (300) is associated with a value stored in the encrypted search index (160).
16. The system (100) of any of claims 12-15, wherein each of the other nodes (310) of the set of nodes (310) of the binary tree (300) includes a portion of a hash (342) of a parent node (310) associated with the corresponding other node (310).
17. The system (100) of any of claims 12-16, wherein evaluating the first portion (126A) of the DPRF comprises evaluating a first subset of the set of nodes (310) of the binary tree (300).
18. The system (100) of claim 17, wherein the untrusted storage device (150) evaluates a second subset of the set of nodes (310) of the binary tree (300) that includes nodes (310) from the set of nodes (310) of the binary tree (300) that are different from the first subset when the untrusted storage device (150) evaluates the remaining second portion (126B) of the DPRF.
19. The system (100) of any of claims 11-18, wherein the operations further comprise, for each unique keyword (32) of a new encrypted document (152N) uploaded by the user (12) into the corpus of encrypted documents (152) stored on the untrusted storage device (150):
incrementing a count (212) of the unique document (152) in the corpus of encrypted documents (152) that includes the corresponding unique keyword (32) in the count table (210);
generating a unique key hash (520) based on the private encryption key (124), the corresponding unique key (32), and an incremented count (212) of the unique documents (152) in the corpus of encrypted documents (152) that include the corresponding unique key (32);
generating a hash pair (522) comprising the unique key hash (520) and an encrypted document identifier (154N) associated with the new encrypted document (152N) uploaded by the user (12); and
sending the hash pair (522) to the untrusted storage device (150).
20. The system (100) of any of claims 11-19, wherein when the untrusted storage device (150) returns the identifier (154) for each of the encrypted documents (152) of at least a portion of one or more of the encrypted documents (152) associated with the remaining second portion (126B) of the DPRF, the untrusted storage device (150) returns encrypted metadata (156) associated with each returned identifier (154).
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
CN202310442738.2A CN116467728A (en) | 2019-12-12 | 2020-12-11 | Encryption search without zero day leakage |
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US16/712,151 | 2019-12-12 | ||
US16/712,151 US11216433B2 (en) | 2019-12-12 | 2019-12-12 | Encrypted search with no zero-day leakage |
PCT/US2020/064701 WO2021119547A1 (en) | 2019-12-12 | 2020-12-11 | Encrypted search with no zero-day leakage |
Related Child Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202310442738.2A Division CN116467728A (en) | 2019-12-12 | 2020-12-11 | Encryption search without zero day leakage |
Publications (2)
Publication Number | Publication Date |
---|---|
CN115053224A true CN115053224A (en) | 2022-09-13 |
CN115053224B CN115053224B (en) | 2023-05-12 |
Family
ID=74175944
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202080095861.6A Active CN115053224B (en) | 2019-12-12 | 2020-12-11 | Encryption search without zero day leakage |
CN202310442738.2A Pending CN116467728A (en) | 2019-12-12 | 2020-12-11 | Encryption search without zero day leakage |
Family Applications After (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202310442738.2A Pending CN116467728A (en) | 2019-12-12 | 2020-12-11 | Encryption search without zero day leakage |
Country Status (4)
Country | Link |
---|---|
US (2) | US11216433B2 (en) |
EP (2) | EP4074002B1 (en) |
CN (2) | CN115053224B (en) |
WO (1) | WO2021119547A1 (en) |
Families Citing this family (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11250151B2 (en) * | 2020-05-05 | 2022-02-15 | Google Llc | Encrypted search over encrypted data with reduced volume leakage |
US11620275B2 (en) * | 2021-08-26 | 2023-04-04 | International Business Machines Corporation | Multi-text interconnection |
Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20130173917A1 (en) * | 2011-12-30 | 2013-07-04 | Christopher J. Clifton | Secure search and retrieval |
CN104408177A (en) * | 2014-12-15 | 2015-03-11 | 西安电子科技大学 | Cipher searching method based on cloud document system |
US9712320B1 (en) * | 2013-06-11 | 2017-07-18 | EMC IP Holding Company LLC | Delegatable pseudorandom functions and applications |
CN107820614A (en) * | 2015-06-29 | 2018-03-20 | 微软技术许可有限责任公司 | The personal search index of privacy enhancing |
CN108471405A (en) * | 2018-03-07 | 2018-08-31 | 中山大学 | A kind of positive secrecy dynamic based on cloud disk can search for encrypted Protocol Design Method |
CN109726565A (en) * | 2017-10-27 | 2019-05-07 | 恩智浦有限公司 | Whitepack is used in anti-leakage primitive |
Family Cites Families (11)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
NZ279622A (en) * | 1994-01-13 | 1998-04-27 | Certco Llc | Encrypted secure and verifiable communication: cryptographic keys escrowed |
WO2008118966A1 (en) * | 2007-03-26 | 2008-10-02 | Yunzhou Zhu | System and method for user authentication with exposed and hidden keys |
US8862879B2 (en) * | 2009-10-13 | 2014-10-14 | Sergio Demian LERNER | Method and apparatus for efficient and secure creating, transferring, and revealing of messages over a network |
EP2525339A4 (en) * | 2010-01-13 | 2013-09-11 | Mitsubishi Electric Corp | Secret retrieval system, public parameter generation device, encryption device, user secret key generation device, query issue device, retrieval device, computer program, secret retrieval method, public parameter generation method, encryption method, user secret key generation method, query issue method, and retrieval method |
US8615668B2 (en) * | 2010-01-15 | 2013-12-24 | Mitsubishi Electric Corporation | Confidential search system and cryptographic processing system |
US8594329B2 (en) * | 2010-12-17 | 2013-11-26 | Microsoft Corporation | Non-interactive verifiable, delegated computation |
US9111106B2 (en) * | 2011-01-13 | 2015-08-18 | Mitsubishi Electric Corporation | Data processing apparatus and data storage apparatus |
US9894042B2 (en) * | 2015-07-24 | 2018-02-13 | Skyhigh Networks, Inc. | Searchable encryption enabling encrypted search based on document type |
WO2017094009A1 (en) | 2015-12-03 | 2017-06-08 | Dyadic Security Ltd | Securing sql based databases with cryptographic protocols |
US10572352B2 (en) * | 2017-11-01 | 2020-02-25 | Vmware, Inc. | Byzantine fault tolerance with verifiable secret sharing at constant overhead |
US10769295B2 (en) * | 2018-01-18 | 2020-09-08 | Sap Se | Join operations on encrypted database tables |
-
2019
- 2019-12-12 US US16/712,151 patent/US11216433B2/en active Active
-
2020
- 2020-12-11 EP EP20839178.9A patent/EP4074002B1/en active Active
- 2020-12-11 EP EP23159133.0A patent/EP4210272A1/en active Pending
- 2020-12-11 CN CN202080095861.6A patent/CN115053224B/en active Active
- 2020-12-11 CN CN202310442738.2A patent/CN116467728A/en active Pending
- 2020-12-11 WO PCT/US2020/064701 patent/WO2021119547A1/en unknown
-
2021
- 2021-12-03 US US17/457,533 patent/US11645256B2/en active Active
Patent Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20130173917A1 (en) * | 2011-12-30 | 2013-07-04 | Christopher J. Clifton | Secure search and retrieval |
US9712320B1 (en) * | 2013-06-11 | 2017-07-18 | EMC IP Holding Company LLC | Delegatable pseudorandom functions and applications |
CN104408177A (en) * | 2014-12-15 | 2015-03-11 | 西安电子科技大学 | Cipher searching method based on cloud document system |
CN107820614A (en) * | 2015-06-29 | 2018-03-20 | 微软技术许可有限责任公司 | The personal search index of privacy enhancing |
CN109726565A (en) * | 2017-10-27 | 2019-05-07 | 恩智浦有限公司 | Whitepack is used in anti-leakage primitive |
CN108471405A (en) * | 2018-03-07 | 2018-08-31 | 中山大学 | A kind of positive secrecy dynamic based on cloud disk can search for encrypted Protocol Design Method |
Non-Patent Citations (1)
Title |
---|
SARVAR PATEL 等: "Mitigating Leakage in Secure Cloud-Hosted Data Structures: Volume-Hiding for Multi-Maps via Hashing", 《COMPUTER AND COMMUNICATIONS SECURITY,ACM》 * |
Also Published As
Publication number | Publication date |
---|---|
US11216433B2 (en) | 2022-01-04 |
US20210182261A1 (en) | 2021-06-17 |
CN116467728A (en) | 2023-07-21 |
EP4210272A1 (en) | 2023-07-12 |
WO2021119547A1 (en) | 2021-06-17 |
EP4074002B1 (en) | 2023-03-29 |
EP4074002A1 (en) | 2022-10-19 |
CN115053224B (en) | 2023-05-12 |
US11645256B2 (en) | 2023-05-09 |
US20220092047A1 (en) | 2022-03-24 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US20130046974A1 (en) | Dynamic symmetric searchable encryption | |
US11645256B2 (en) | Encrypted search with no zero-day leakage | |
EP4073673B1 (en) | Encrypted search with a public key | |
US20230274007A1 (en) | Response-Hiding Searchable Encryption | |
WO2020095662A1 (en) | Anonymization system and anonymization method | |
CN115104286B (en) | Encryption searching method and system for encrypting E-mail client | |
US11250151B2 (en) | Encrypted search over encrypted data with reduced volume leakage | |
US11909861B2 (en) | Privately querying a database with private set membership using succinct filters | |
Waage et al. | Searchable encryption in apache cassandra | |
Ahmed et al. | Conjunctive keyword forward secure ranked dynamic searchable encryption over outsourced encrypted data | |
Xu et al. | A multi-client dynamic searchable symmetric encryption system with physical deletion | |
Pinkas et al. | A simple recursive tree oblivious ram | |
Chebrolu et al. | An efficiency and privacy-preserving biometric identification scheme in cloud computing | |
Aman et al. | Framework Design for Secured Local Cloud Data Query Processing Analysis | |
CN115422237A (en) | Data query method and device, computer equipment and storage medium | |
EP4136543A1 (en) | Metadata management for a transactional storage system | |
Ulusoy et al. | Analysis of heuristic based access pattern obfuscation | |
Priya Dharshini et al. | DELAY-OPTIMAL TASK OFFLOADING FOR UAV-ENABLED EDGE-CLOUD COMPUTING SYSTEMS |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
GR01 | Patent grant | ||
GR01 | Patent grant |