CN112639709A - Method and system for positioning animated images within a dynamic keyboard interface - Google Patents
Method and system for positioning animated images within a dynamic keyboard interface Download PDFInfo
- Publication number
- CN112639709A CN112639709A CN201980057190.1A CN201980057190A CN112639709A CN 112639709 A CN112639709 A CN 112639709A CN 201980057190 A CN201980057190 A CN 201980057190A CN 112639709 A CN112639709 A CN 112639709A
- Authority
- CN
- China
- Prior art keywords
- keyboard interface
- dynamic keyboard
- context
- application
- different
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
- 238000000034 method Methods 0.000 title claims abstract description 31
- 230000004044 response Effects 0.000 claims abstract description 19
- 238000009877 rendering Methods 0.000 claims abstract description 16
- 238000004891 communication Methods 0.000 claims description 19
- 230000006870 function Effects 0.000 description 12
- 230000008901 benefit Effects 0.000 description 5
- 230000003993 interaction Effects 0.000 description 5
- 238000004883 computer application Methods 0.000 description 3
- 238000012986 modification Methods 0.000 description 2
- 230000004048 modification Effects 0.000 description 2
- 238000012545 processing Methods 0.000 description 2
- 238000007792 addition Methods 0.000 description 1
- 238000003491 array Methods 0.000 description 1
- 230000000694 effects Effects 0.000 description 1
- 230000008451 emotion Effects 0.000 description 1
- 230000008676 import Effects 0.000 description 1
- 230000003287 optical effect Effects 0.000 description 1
- 230000008569 process Effects 0.000 description 1
- 238000012552 review Methods 0.000 description 1
- 239000007787 solid Substances 0.000 description 1
- 210000003813 thumb Anatomy 0.000 description 1
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0487—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser
- G06F3/0488—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser using a touch-screen or digitiser, e.g. input of commands through traced gestures
- G06F3/04886—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser using a touch-screen or digitiser, e.g. input of commands through traced gestures by partitioning the display area of the touch-screen or the surface of the digitising tablet into independently controllable areas, e.g. virtual keyboards or menus
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0481—Interaction techniques based on graphical user interfaces [GUI] based on specific properties of the displayed interaction object or a metaphor-based environment, e.g. interaction with desktop elements like windows or icons, or assisted by a cursor's changing behaviour or appearance
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0481—Interaction techniques based on graphical user interfaces [GUI] based on specific properties of the displayed interaction object or a metaphor-based environment, e.g. interaction with desktop elements like windows or icons, or assisted by a cursor's changing behaviour or appearance
- G06F3/04817—Interaction techniques based on graphical user interfaces [GUI] based on specific properties of the displayed interaction object or a metaphor-based environment, e.g. interaction with desktop elements like windows or icons, or assisted by a cursor's changing behaviour or appearance using icons
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0484—Interaction techniques based on graphical user interfaces [GUI] for the control of specific functions or operations, e.g. selecting or manipulating an object, an image or a displayed text element, setting a parameter value or selecting a range
- G06F3/04842—Selection of displayed objects or displayed text elements
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0487—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser
- G06F3/0488—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser using a touch-screen or digitiser, e.g. input of commands through traced gestures
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T13/00—Animation
- G06T13/20—3D [Three Dimensional] animation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T13/00—Animation
- G06T13/20—3D [Three Dimensional] animation
- G06T13/40—3D [Three Dimensional] animation of characters, e.g. humans, animals or virtual beings
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T13/00—Animation
- G06T13/80—2D [Two Dimensional] animation, e.g. using sprites
Abstract
The present disclosure relates to positioning animated images within a dynamic keyboard interface. Specifically, the methods and systems of the present disclosure may: receiving data indicating a selection of a particular animated image from a plurality of different animated images presented by a dynamic keyboard interface provided in association with an application; receiving data indicating a context for: a dynamic keyboard interface and/or application based at least in part on which of a plurality of different animated images is selected for presentation by the dynamic keyboard interface; and determining a location within the dynamic keyboard interface for rendering the particular animated image in response to the data indicative of the subsequent context of the dynamic keyboard interface, the application, and/or the different and unique application based at least in part on the data indicative of the selection and the data indicative of the context.
Description
RELATED APPLICATIONS
This application claims priority and benefit of U.S. provisional patent application No. 62/725,641 filed on 31/8/2018, which is hereby incorporated by reference in its entirety into U.S. provisional patent application No. 62/725,641.
Technical Field
The present invention relates generally to animated images. More particularly, the present invention relates to positioning animated images within a dynamic keyboard interface.
Background
Computing devices (e.g., desktop computers, laptop computers, tablet computers, smartphones, wearable computing devices, etc.) are ubiquitous in modern society. They may support communication between users, providing users with information about their environment, current events, the entire world, etc. A myriad of different types of interfaces enable users to interact with these devices. For example, many devices include a touch screen and provide an interface configured to allow a user to input information (e.g., including user selectable options, a keyboard, etc.). Animated images (e.g., Graphics Interchange Format (GIF) images, etc.) may include data indicative of a series of ordered image frames that, when rendered, produce moving images, etc. Animated images may be used to convey, communicate ideas, feelings, concepts, emotions, and the like.
Disclosure of Invention
Aspects and advantages of embodiments of the invention will be set forth in part in the description which follows, or may be learned from the description, or may be learned by practice of the embodiments.
One example aspect of the invention relates to a computer-implemented method. The method may include: data is received by one or more computing devices indicating a selection of a particular animated image from a plurality of different animated images presented by a dynamic keyboard interface provided in association with an application. The method may also include receiving, by the one or more computing devices, data indicating a context for: a dynamic keyboard interface based at least in part on which of the plurality of different animated images is selected for presentation by the dynamic keyboard interface and/or an application based at least in part on which of the plurality of different animated images is selected for presentation by the dynamic keyboard interface. The method may also include determining, by the one or more computing devices and based at least in part on the data indicative of the selection and the data indicative of the context, a location within the dynamic keyboard interface for presenting the particular animated image in response to the data indicative of the subsequent context that is: the dynamic keyboard interface, the application and/or the different and unique application, provide the dynamic keyboard interface in association with the different and unique application.
Another exemplary aspect of the invention relates to a system. The system may include one or more processors and memory storing instructions that, when executed by the processors, cause the system to perform operations. The operations may include: receiving data indicating a context for: a dynamic keyboard interface when a particular animated image is selected from a plurality of different animated images presented by the dynamic keyboard interface in association with an application providing the dynamic keyboard interface, and/or an application providing the dynamic keyboard interface when a particular animated image is selected from a plurality of different animated images presented by the dynamic keyboard interface. The operations may further include determining a location within the dynamic keyboard interface for rendering the particular animated image in response to data indicating a subsequent context that indicates: the dynamic keyboard interface, the application and/or the different and unique application, provide the dynamic keyboard interface in association with the different and unique application.
Another example aspect of the invention relates to one or more non-transitory computer-readable media. The non-transitory computer-readable medium may include instructions that, when executed by one or more computing devices, cause the computing devices to perform operations. The operations may include: data is received indicating a selection of a particular animated image from a plurality of different animated images presented by a dynamic keyboard interface provided in association with an application. The operations may also include receiving data indicating an amount of time to select a particular animated image and: the dynamic keyboard interface presents a plurality of different animated images at a time, or a time at which a particular animated image is initially available for selection by the dynamic keyboard interface from the plurality of different animated images. The operations may further include determining a location within the dynamic keyboard interface for rendering the particular animated image in response to the data indicating the context indicating: the dynamic keyboard interface, the application and/or the different and unique application, provide the dynamic keyboard interface in association with the different and unique application.
Other aspects of the invention relate to various systems, apparatuses, non-transitory computer-readable media, user interfaces, and electronic devices.
These and other features, aspects, and advantages of various embodiments of the present disclosure will become better understood with reference to the following description and appended claims. The accompanying drawings, which are incorporated in and constitute a part of this specification, illustrate exemplary embodiments of the disclosure and together with the description, serve to explain the relevant principles.
Drawings
A detailed discussion of embodiments of those skilled in the art is set forth in the specification, which makes reference to the appended drawings, in which:
FIG. 1 depicts an example computing environment in accordance with example embodiments of the present disclosure;
2A-2E depict an exemplary sequence of events according to an exemplary embodiment of the present disclosure;
3A-3Y depict example Graphical User Interfaces (GUIs) according to example embodiments of the present disclosure; and
fig. 4 depicts an exemplary method according to an exemplary embodiment of the present disclosure.
Detailed Description
Exemplary aspects of the present invention relate to positioning animated images within a dynamic keyboard interface. In particular, the animated image may be identified based at least in part on the context of the dynamic keyboard interface (e.g., one or more search terms entered through the dynamic keyboard interface, data presented by and/or entered into one or more applications associated with providing the dynamic keyboard interface, etc.); locate based at least in part on context, frequency of selection thereof, and the like; and presented by a dynamic keyboard interface associated with the application (e.g., for browsing, selecting, etc.).
The animated image may be presented to the user in the dynamic keyboard interface based on prior interactions with the animated image and/or other contextual information. As one example, for users, often popular animated images (e.g., among many users) may be placed more prominently in a dynamic keyboard interface. As another example, an animated image previously selected by the user may be displayed and/or emphasized in the dynamic keyboard interface. Additionally, animated images similar to such previously selected animated images may be displayed and/or emphasized in the dynamic keyboard interface.
As another example, some animated images may be shared more frequently with multiple recipients (e.g., in a "group chat") rather than a single recipient (e.g., in a one-to-one conversation). When a user is searching for animated images to be sent to multiple recipients, animated images that are more frequently shared with multiple recipients may be displayed or emphasized (e.g., displayed more prominently than other animated images) within the dynamic keyboard interface. Similarly, when a user searches for animated images to be sent to a single recipient, animated images that are more frequently shared with the single recipient may be displayed or emphasized within the dynamic keyboard interface (e.g., displayed more prominently than other animated images).
As yet another example, animated images that are contextually relevant based on a user's previous interactions with the user device may be presented to the user more prominently. The user may select an animated image to be sent to the first contact. For example, in an information exchange with a friend, the user may suggest going to the beach to spend an upcoming weekend. Later, when the user is searching for an animated image to be sent to the second contact, the computing system may select the animated image based on contextual information gathered from the user's interaction with the first contact. For example, in response to a message from the user's boss asking whether the user may work on an upcoming weekend, the computing system may display or emphasize an animated image related to the beach in the dynamic keyboard interface.
As yet another example, animated images may be displayed or emphasized based on sequential shared information indicating previous interactions by the user and/or previous interactions by other users. For example, a particular gif may typically be shared immediately after or in response to other particular animated images. The computing system may track and record these correlations and suggest animated images based on these contextual information. For example, users may share animated images (e.g., animated images that describe someone saying "call me" and gesturing with the phone). Statistically, the particular user and/or other users may typically respond with a particular animated image (e.g., animated images including conveying "raise thumb", "how. Such animated images may be displayed or emphasized based on contextual information including such correlations.
As a further example, animated images may be displayed and/or emphasized based on contextual information including a "shared time" metric. The "share time" metric may indicate a duration between a time when a user begins searching for animated images (e.g., enters a search criteria and/or begins scrolling through the dynamic keyboard interface) and (2) a time when the user selects one of the animated images to share or otherwise manipulate and/or engage. As a result, the computing system and/or dynamic keyboard interface may select an animated image to display and/or emphasize to the user in a manner that shortens the user's search time.
Additionally, in some implementations, animated images may be displayed and/or emphasized based on context data that may be collected across multiple computer applications (e.g., text applications, email applications, etc.). The dynamic keyboard interface may be configured to interface with a plurality of applications. The context data may be obtained when the dynamic keyboard interfaces with a computer application (e.g., a text application). When the dynamic keyboard interface is later used with another distinct computer application (e.g., an email application), such context data can be used to select an animated image to be displayed and/or emphasized.
For example, a dynamic keyboard interface (e.g., for use via a touchscreen, etc.) may be provided (e.g., as part of an Operating System (OS), third-party application, plug-in, etc.) to one or more user devices (e.g., computers, smartphones, tablet computing devices, wearable computing devices, etc.). One or more aspects of the dynamic keyboard interface may be configured to provide access (e.g., via search functions, suggestion functions, browsing functions, etc.) to, for example, a corpus of animated images (e.g., Graphic Interchange Format (GIF) images, etc.) that are uploaded to, stored by, indexed by, managed by, etc., a remotely located computing system (e.g., one or more computing devices, etc.).
A user (e.g., with a user device that provides a dynamic keyboard interface, etc.) may perform one or more actions that provide, for example, a context of the user device, the dynamic keyboard interface, an application (e.g., a messaging application, etc.), etc., in association with which the dynamic keyboard interface is provided. For example, a user may position a user device at a particular geographic location, enter one or more search terms through a dynamic keyboard interface, interact with an application through its interface, and so forth. Data indicative of context may be generated (e.g., by a user device, a dynamic keyboard interface, etc.), communicated to a computing system (e.g., over one or more networks, etc.), and received by the computing system, which may update one or more records regarding a corpus of animated images based at least in part on such data.
Based at least in part on the data indicative of the context, the records regarding the corpus of animated images, etc., the computing system may identify a plurality of different animated images associated with the context for presentation by a dynamic keyboard interface associated with the application (e.g., animated images that are contextually-relevant, responsive to the context, etc.). In some embodiments, one or more of the plurality of different animated images associated with the context may include one or more advertisements (e.g., for one or more products, services, media content items, etc.).
According to various aspects of the invention, for each of one or more animated images included in a plurality of different animated images associated with a context, a computing system may determine a location within a dynamic keyboard interface for rendering the animated image (e.g., based at least in part on data indicative of the context, a record regarding a corpus of animated images, etc.). Data indicative of a plurality of different animated images associated with a context, their respective determined locations, etc. may be generated (e.g., by a computing system, etc.) and communicated (e.g., over a network, etc.) to a dynamic keyboard interface (e.g., a user device, etc.), which may present the plurality of different animated images associated with the context associated with the application based at least in part on their respective determined locations. For example, a plurality of different animated images associated with a context may be presented in an ordered, and/or similar manner (e.g., animated images determined to be more relevant to the context, more responsive to the context, etc. may be presented earlier, more prominent, and/or similarly).
A user may select one or more particular animated images from a plurality of different animated images associated with a context through a dynamic keyboard interface. For example, a user may select one or more particular animated images for communication to an application (e.g., input, paste, etc.) through a dynamic keyboard interface. Additionally or alternatively, the user may select one or more particular animated images for future access within the dynamic keyboard interface (e.g., specify such particular animated images for frequent use, "like" them, etc.).
Data indicative of the selection, the type of selection (e.g., for communication to an application, for future accessibility, etc.), the particular animated image selected, etc. may be generated (e.g., by a user device, dynamic keyboard interface, etc.), communicated to a computing system (e.g., over a network, etc.), and received by the computing system, which may update records regarding a corpus of animated images based at least in part on such data.
A user (e.g., utilizing a user device that provides a dynamic keyboard interface, a different and unique user device that provides a dynamic keyboard interface, etc.) may perform one or more actions that provide subsequent context such as such user device, dynamic keyboard interface, application (e.g., messaging application, etc.) with which the dynamic keyboard interface is provided, a different and unique application (e.g., email application, etc.) with which the dynamic keyboard interface is provided, etc. For example, a user may locate such a user device at a particular geographic location, enter one or more search terms through a dynamic keyboard interface, interact with such applications through their respective interfaces, and so forth. Data indicative of subsequent context may be generated (e.g., by a user device, a different and unique user device, a dynamic keyboard interface, etc.), communicated to a computing system (e.g., over a network, etc.), and received by the computing system, which may update records regarding a corpus of animated images based at least in part on such data.
Based at least in part on data indicating a previous context; data indicating a subsequent context; data indicating a selection, a selection type, a particular animated image selected, etc.; with respect to recordings of a corpus of animated images, etc., a computing system can identify a plurality of different image animated images associated with a subsequent context for dynamic keyboard interface presentation associated with an application and/or a different and unique application (e.g., animated images related to, responsive to, etc. the subsequent context). In some embodiments, one or more of the plurality of different animated images associated with a subsequent context may include one or more advertisements.
According to aspects of the invention, for each of one or more animated images included in a plurality of different animated images associated with a subsequent context, the computing system may determine (e.g., based at least in part on data indicative of a previous context; data indicative of a subsequent context; data indicative of a selection, a type of selection, a particular animated image selected, etc.; a record regarding a corpus of animated images, etc.) a location within the dynamic keyboard interface for rendering the animated image.
Data indicative of a plurality of different animated images associated with a subsequent context, their respective determined locations, etc. may be generated (e.g., by a computing system, etc.) and communicated (e.g., over a network, etc.) to a dynamic keyboard interface (e.g., a user device, a different and unique user device, etc.), which may present the plurality of different animated images associated with the subsequent context in association with the application and/or the different and unique application based at least in part on the respective determined locations. For example, a plurality of different animated images associated with a subsequent context may be presented in an ordered, and/or similar manner (e.g., animated images determined to be more contextually relevant, more responsive, etc. may be presented earlier, more prominently, and/or similarly).
In some embodiments, an animated image included in a plurality of different animated images associated with a subsequent context may include one or more particular animated images previously selected. In some such embodiments, the location within the dynamic keyboard interface for presenting such particular animated images may be determined based at least in part on previously selected animated images, context associated with their selection, and the like. For example, such particular animated images may be earlier, more prominent, and/or similar (e.g., lack their previous selections, etc.) than they could otherwise be presented. In some embodiments, one or more such particular animated images may include one or more advertisements.
In some embodiments, the data indicating the previous context may indicate one or more search terms entered through the dynamic keyboard interface. In some such embodiments, the data indicative of subsequent context may be indicative of at least one of such search terms entered through the dynamic keyboard interface.
In some embodiments, the data indicative of a previous context may be indicative of data presented by and/or entered into an application associated with the previous context, and the data indicative of a subsequent context may be indicative of one or more data presented by or entered into such application, a different and unique application, a dynamic keyboard interface, etc. In some such embodiments, for at least one animated image included in a plurality of different animated images associated with a subsequent context, determining a location within the dynamic keyboard interface for presenting such animated image may include determining that data presented by and/or input to an application associated with a previous context corresponds, at least in part, to one or more data presented by or input to such application, different and unique application, dynamic keyboard interface, etc. for such application, different and unique application, dynamic keyboard interface, etc.
In some embodiments, the data indicating the previous context may indicate an animated image previously selected through the dynamic keyboard interface, a time at which the animated image previously selected through the dynamic keyboard interface was selected, and/or the like. In some such embodiments, the data indicating the subsequent context may include data indicating a selection of an animated image previously selected through the dynamic keyboard interface, a time associated with the selection of the animated image through the dynamic keyboard interface, and/or the like.
In some embodiments, the data indicating the previous context may indicate a human language setting associated with a user device executing an application associated with the previous context; a geographical area to which the user equipment is registered; a network identifier associated with the user equipment; a geographic location of a user device associated with selecting a particular animated image; a time associated with selecting a particular animated image; a time of day associated with selecting a particular animated image; a date associated with selecting a particular animated image; a day of the week associated with selecting a particular animated image; a month associated with selecting a particular animated image; a year associated with selecting a particular animated image; the size of the audience associated with selecting a particular animated image; an entity providing one or more specific animated images or content included in one or more specific animated images, etc. In some such embodiments, the data indicating the subsequent context may include data corresponding at least in part to a human language setting, a geographic area, a network identifier, a geographic location, a time of day, a date, a day of week, a month, a year, a size of an audience, an entity, and/or the like.
In some embodiments, the computing system may receive data (e.g., from a user device executing an application associated with a previous context, over a network, etc.) indicating an amount of time between a time from selecting a particular animated image to the dynamic keyboard interface presenting a plurality of different animated images associated with the previous context and a time at which the selected particular animated image is initially available for selection by the dynamic keyboard interface from the plurality of different animated images associated with the previous context. In some such embodiments, for at least one animated image included in a plurality of different animated images associated with a subsequent context, determining a location within the dynamic keyboard interface for presenting such animated image may include determining such location based at least in part on data indicative of an amount of time.
In some embodiments, determining such a location based at least in part on the data indicative of the amount of time may include normalizing the data indicative of the amount of time based at least in part on a location of the animated image within the dynamic keyboard interface when a plurality of different animated images associated with a previous animated image are presented by the dynamic keyboard interface, a location of the animated image within the dynamic keyboard interface when such animated image is initially available for selection by the dynamic keyboard interface from the plurality of different animated images associated with the previous context.
In some embodiments, for at least one animated image included in a plurality of different animated images associated with a subsequent context, determining a location within the dynamic keyboard interface for presenting such animated image may include determining, based at least in part on data indicative of selection of such animated image, a frequency of selection of such animated image. In some such embodiments, the location of such animated images may be determined based at least in part on the selection frequency of such animated images, one or more selection frequencies of such locations, and/or the like.
The techniques described herein may provide a number of technical effects and benefits. For example, as indicated previously, the techniques illustrated herein may render animated images that are determined to be more relevant, responsive, etc. to a given context earlier, more prominently, thereby reducing the time taken to browse, locate, etc. such animated images, thereby conserving computing resources (e.g., energy, processing cycles, network bandwidth, etc.).
Referring now to the drawings, example embodiments of the disclosure will be discussed in further detail.
FIG. 1 depicts an example computing environment in accordance with example embodiments of the present disclosure.
Referring to fig. 1, environment 100 may include one or more computing devices (e.g., one or more desktop computers, laptop computers, tablet computers, mobile devices, smartphones, wearable devices, servers, etc.). For example, environment 100 may include computing devices 10, 20, 30, 40, and 50, and computing system 112, which may include one or more computing devices. The environment 100 may also include one or more networks 110 (e.g., one or more wired networks, wireless networks, etc.). Network 110 may interface computing devices 10, 20, 30, 40, and/or 50 with each other and/or with computing system 112.
The computing system 112 may include one or more processors 114, one or more communication interfaces 116, and memory 118 (e.g., one or more hardware components for storing executable instructions, data, and the like). Communication interface 116 may enable computing system 112 to communicate with computing devices 10, 20, 30, 40, and/or 50. The memory 118 may include (e.g., store, etc.) instructions 120. When executed by the processor 114, the instructions 120 may cause the computing system 112 to perform one or more operations, functions, etc., indicated herein.
Unless explicitly indicated otherwise, the operations, functions, and the like indicated herein may be performed by computing device 10, 20, 30, 40, and/or 50 and/or computing system 112 (e.g., by computing device 10, 20, 30, 40, or 50, by computing system 112, by one or more of computing devices 10, 20, 30, 40, and/or 50 and/or a combination of computing systems 112, etc.).
Fig. 2A-2E depict example sequences of events according to example embodiments of the present disclosure.
Referring to fig. 2A, at (202), computing device 10 may communicate data indicative of one or more animated images (e.g., Graphics Interchange Format (GIF) images, etc.), advertisements, advertising content, a context in which such animated images, advertisements, advertising content, etc. are presented to computing system 112 capable of receiving and storing such data, one or more records generated based at least in part thereon, etc. (e.g., over network 110 (indicated by boxes of fill patterns on lines extending downward from network 110), etc.). For example, computing system 112 may be remotely located from computing devices 10, 20, 30, 40, and/or 50, and may receive a corpus of animated images, an upload, storage, indexing, management, etc. of one or more recordings or the like regarding such a corpus.
Similarly, at (204), computing device 20 may communicate data indicative of one or more animated images, advertisements, advertising content, a context in which such animated images, advertisements, advertising content, etc. are presented to computing system 112, computing system 112 may receive and store such data, one or more records generated based at least in part thereon, etc.; and, at (206), computing device 30 may communicate data indicative of one or more animated images, advertisements, advertising content, a context in which such animated images, advertisements, advertising content, etc. are presented to computing system 112, computing system 112 may receive and store such data, one or more records generated based at least in part thereon, and/or the like.
Referring to fig. 3B, in some embodiments (e.g., to mitigate potential privacy concerns, etc.), one or more users of computing devices 40 and/or 50 may be provided (e.g., via element 306, etc.) information regarding the collection of particular data, etc., one or more controls (e.g., via elements 308 and/or 310, etc.) for allowing the user to make one or more selections to determine whether and/or when the methods, systems, functions, operations, etc., illustrated herein are capable of enabling the collection of particular data, etc. (e.g., presented by and/or input into an application, the dynamic keyboard interface illustrated herein, etc.). Additionally or alternatively, certain data (e.g., rendered and/or input to an application by an application, a dynamic keyboard interface as shown herein, etc.) may be processed in one or more ways before being stored, utilized, etc. (e.g., such that personal identification information may be removed, etc.). For example, the identity of the user, data associated therewith, etc. may be processed such that personally identifiable information, etc. cannot be determined for the user. Thus, the user may have control over what data they have collected, how the information is used, what information is provided, and so forth.
According to various aspects of the invention, a dynamic keyboard interface (e.g., for use via a touch screen, etc.) may be provided to computing devices 40 and/or 50, provided by computing devices 40 and/or 50, etc. (e.g., as part of an Operating System (OS), third party application, plug-in, etc.). For example, referring to FIG. 3C, portion 314 of the GUI shown may be associated with such a dynamic keyboard interface. One or more aspects of the dynamic keyboard interface may be configured to provide access (e.g., through search functions, suggestion functions, browsing functions, etc.) to a corpus of animated images uploaded to, stored by, indexed by, computing system 112, managed by computing system 112, computing system 112. The dynamic keyboard interface may be provided in association with one or more applications executed by computing devices 40 and/or 50. For example, portion 312 can be associated with an application (e.g., messaging application, etc.) associated with element 302, and as shown, a dynamic keyboard interface can be provided in association with such application.
The elements 320 may be configured to cause the dynamic keyboard interface to switch, flip, rotate, etc., between various different keyboards associated with, for example, different languages, letters, etc. (e.g., the illustrated qwerty keyboard, etc.). According to various aspects of the present invention, such keyboards may include animated image keyboards configured to present (e.g., for browsing, selecting, etc.) a variety of different animated images.
Referring again to fig. 2A, at (208), the user may perform one or more actions that provide one or more different and unique contexts associated with computing device 40. The provided context may be computing device 40, a dynamic keyboard interface, an application associated with portion 312, and so forth. For example, the user may position computing device 40 at a particular geographic location, interact with an application associated with portion 312 through its interface, and so on.
At (210), computing device 40 (e.g., a dynamic keyboard interface, etc.) may generate data indicative of such context, and may communicate such data to computing system 112, which computing system 112 may receive the data and update records regarding the corpus of animated images based at least in part thereon. In some embodiments, the data indicating context may indicate data of a dynamic keyboard interface presented to and/or entered into by a dynamic keyboard interface, an application associated with portion 312, and/or the like (e.g., "We're at the coast."; "Nice | Enjoy the beach.").
At (212), based at least in part on the data indicative of the context, the records regarding the corpus of animated images, etc., computing system 112 can identify a plurality of different animated images associated with the context for presentation by the dynamic keyboard interface in association with an application (e.g., an animated image related to the context, responsive to the context, etc.), the application associated with portion 312.
In some embodiments, one or more of the plurality of different animated images associated with the context may include one or more advertisements (e.g., for one or more products, services, media content items, etc.). For example, such animated images may contain advertising content, data (e.g., links, etc.), be configured to cause an application executed by computing devices 40 and/or 50 (e.g., a web browser, an application associated with the subject matter, source, etc. of the advertisement, etc.) to render, navigate to content associated with the advertisement, advertising content, etc., and/or the like.
According to various aspects of the invention, based at least in part on the data indicative of the context, the records regarding the corpus of animated images, etc., the computing system 112 may determine, for each of one or more animated images included in a plurality of different animated images associated with the context, a location within the dynamic keyboard interface for rendering the animated image.
At (214), computing system 112 may generate data indicative of a plurality of different animated images associated with the context, their respective determined positions, etc., and may communicate such data to computing device 40 (e.g., to a dynamic keyboard interface), which computing device 40 may receive the data.
Referring to fig. 3D, in response to a user invoking element 320 or the like, the dynamic keyboard interface may switch (e.g., from a qwerty keyboard or the like) to the illustrated animated image keyboard or the like, which may present a plurality of different animated images associated with the context based at least in part on their respective determined positions. For example, a plurality of different animated images associated with a context may be presented in an ordered, and/or similar manner (e.g., animated images determined to be more contextually relevant, more responsive, may be presented earlier, more prominently).
As shown, multiple different animated images from the multiple different animated images associated with the context may be displayed simultaneously side-by-side by the dynamic keyboard interface. For example, the dynamic keyboard interface may simultaneously display animated images 324, 326, and 328, as well as other ones of a plurality of different animated images associated with context, etc. It should be appreciated that the plurality of different animated images associated with a context may include additional animated images (not shown) that may be displayed, for example, by interacting with the interface (e.g., sliding left, etc.).
Referring again to fig. 2A, at (216), a user may select one or more particular animated images from a plurality of different animated images associated with a context through a dynamic keyboard interface. In some embodiments, the user may select one or more particular animated images for communication (e.g., input, paste, etc.) with the application associated with portion 312 (fig. 3D) through the dynamic keyboard interface. Additionally or alternatively, the user may select one or more particular animated images for future access within the dynamic keyboard interface (e.g., specify such particular animated images for frequent use, "like" them, etc.). For example, referring to FIG. 3E, the user may select animated image 324 for future accessibility within the dynamic keyboard interface (e.g., as shown by the star overlaid on animated image 324, etc.).
At (218), computing device 40 may generate data indicative of the selection, the type of selection (e.g., for future accessibility, etc.), the particular animated image selected (e.g., animated image 324, etc.), and may communicate such data to computing system 112, computing system 112 may receive the data, and at (220), may update records regarding the corpus of animated images based at least in part thereon.
Referring to fig. 2B, at (222), the user may perform one or more actions that provide one or more different and unique current contexts associated with computing device 40. The provided context may be computing device 40, a dynamic keyboard interface, an application associated with portion 312, and so forth. For example, element 322 may correspond to a search box for entering one or more search terms that are used, at least in part, to identify one or more animated images or the like, and referring to fig. 3F, a user may invoke element 322 and enter one or more search terms (e.g., "shell" or the like) using the illustrated keyboard.
At (224), computing device 40 (e.g., a dynamic keyboard interface, etc.) may generate data indicative of such context, and may communicate such data to computing system 112, which computing system 112 may receive the data and update records regarding the corpus of animated images based at least in part thereon. In some embodiments, the data indicative of context may be indicative of an entered search term or the like.
Based at least in part on the data indicative of the current context, the data indicative of the previous context (e.g., received at (210), etc.), the data indicative of a previous selection, a selection type, a particular animated image selected, etc. (e.g., received at (218), etc.), the records regarding the corpus of animated images, etc., at (226), the computing system 112 may identify a plurality of different animated images associated with the current context for use by an application associated program (e.g., an animated image related to, responsive to, etc. the current context) associated with the portion 312 via a dynamic keyboard interface. In some embodiments, one or more of the plurality of different animated images associated with the current context may include one or more advertisements.
Based at least in part on the data indicative of the current context, the data indicative of the previous context (e.g., received at (210), etc.), the data indicative of a previous selection, a type of selection, a particular animated image selected, etc. (e.g., received at (218), etc.), the computing system 112 may determine, for each of one or more animated images included in a plurality of different animated images associated with the current context, a location within the dynamic keyboard interface for presenting the animated image, etc.
At (228), the computing system 112 may generate data indicative of the plurality of different animated images associated with the current context, their respective determined locations, etc., and may communicate such data to the computing device 40 (e.g., to a dynamic keyboard interface), the computing device 40 may receive the data, and referring to fig. 3G, may switch (e.g., from a qwerty keyboard, etc.) to the illustrated animated image keyboard, etc., may render the plurality of different animated images associated with the current context based at least in part on their respective determined locations. For example, a plurality of different animated images associated with the current context may be presented in an ordered, and/or similar manner (e.g., animated images determined to be more relevant to, responsive to, etc. the current context may be presented earlier, more prominently).
As shown, multiple different animated images from the multiple different animated images associated with the current context may be displayed simultaneously side-by-side by the dynamic keyboard interface. For example, the dynamic keyboard interface may simultaneously display animated images 326, 330, and 332, as well as other ones of a plurality of different animated images associated with the current context, and so forth.
At (230), the user may select one or more particular animated images from a plurality of different animated images associated with the current context through the dynamic keyboard interface. For example, referring to FIG. 3H, the user may select animated images 330 and 332 for communication to an application, associated with portion 312, etc., via the dynamic keyboard interface, and, referring to FIG. 3I, in response to the user invoking element 318, etc., the dynamic keyboard interface may communicate animated images 330 and 332 to the application, associated with portion 312, etc.
At (232), computing device 40 may generate data indicative of the selection, the type of selection (e.g., communication for the application associated with portion 312, etc.), the particular animated image selected (e.g., animated images 330 and 332, etc.), and may communicate such data to computing system 112, which computing system 112 may receive such data, and at (234), may update records regarding the corpus of animated images based at least in part thereon.
At (236), the user may perform one or more actions that provide one or more different and unique current contexts associated with computing device 40. The provided context may be computing device 40, a dynamic keyboard interface, an application associated with portion 312, and so forth. For example, referring to FIG. 3J, a user may interact with an application associated with section 312 through their interface (e.g., switch from a message session with "Joe Friend" to a message session with "Cool Cat," etc.).
At (238), computing device 40 (e.g., a dynamic keyboard interface, etc.) may generate data indicative of such context, and may transmit such data to computing system 112, which computing system 112 may receive the data and update records regarding the corpus of animated images based at least in part thereon. In some embodiments, the data indicative of context may be indicative of data (e.g., "Let's go to the shore," etc.) presented by and/or input to the dynamic keyboard interface, the application associated with portion 312, and/or the like.
Based at least in part on the data indicative of the current context, the data indicative of the previous context (e.g., received at (210), (224), etc.), the data indicative of the previous selection, the type of selection, the particular animated image selected, etc. (e.g., received at (218), (232)), the records regarding the corpus of animated images, at (240), the computing system 112 may identify a plurality of different animated images associated with the current context for presentation in association with an application (e.g., an animated image associated with the current context, responsive to the current context, etc.) via a dynamic keyboard interface, the association of the application with the portion 312. In some embodiments, one or more of the plurality of different animated images associated with the current context may include one or more advertisements.
Based at least in part on the data indicative of the current context, the data indicative of the previous context (e.g., received at (210), (224), the data indicative of a previous selection, a type of selection, a particular animated image selected, etc. (e.g., received at (218), (232)), the computing system 112 may determine, for each of one or more animated images included in a plurality of different animated images associated with the current context, a location within the dynamic keyboard interface for presenting the animated image.
Referring to fig. 2C, at (242), computing system 112 may generate data indicative of a plurality of different animated images associated with the current context, their respective determined positions, etc., and may communicate such data to computing device 40 (e.g., to a dynamic keyboard interface), which computing device 40 may receive.
Referring to fig. 3K, in response to a user invoking element 320 or the like, the dynamic keyboard interface may switch (e.g., from a qwerty keyboard or the like) to the illustrated animated image keyboard or the like, which may present a plurality of different animated images associated with the current context based at least in part on their respective determined positions. For example, a plurality of different animated images associated with the current context may be presented in an ordered, and/or similar manner (e.g., animated images determined to be more relevant to, responsive to, etc. the current context may be presented earlier, more prominently).
As shown, multiple different animated images from the multiple different animated images associated with the current context may be displayed simultaneously side-by-side by the dynamic keyboard interface. For example, the dynamic keyboard interface may simultaneously display animated images 324, 328, 330, and 332, as well as other ones of a plurality of different animated images associated with the current context, and so forth.
In some embodiments, the animated images included in the plurality of different animated images associated with the current context may include one or more particular animated images (e.g., animated images 324, 330, 332, etc.) that were previously selected. In some such embodiments, the location within the dynamic keyboard interface for presenting such particular animated image may be determined based at least in part on a previously selected animated image, a previous context associated with its selection, and/or the like. For example, such particular animated images may be earlier, more prominent, etc. than they could have been presented (e.g., lack their previous selection, etc.). In some embodiments, one or more such particular animated images may include one or more advertisements.
As previously described, in some embodiments, the data indicative of the current context may be indicative of data (e.g., "Let's go to the shore," etc.) presented by and/or input to the dynamic keyboard interface, the application associated with portion 312, and/or the like. In some such embodiments, for one or more animated images (e.g., animated images 324, 330, 332, etc.) of animated images included in a plurality of different animated images associated with a current context, determining a location within the dynamic keyboard interface for presenting such animated images may include determining data presented by and/or input to the dynamic keyboard interface by the dynamic keyboard interface, the one or more applications associated with one or more previous contexts indicated by data indicative of one or more previous contexts (e.g., "We're at the coast."; "Nice | en joy the beach." etc.) corresponding, at least in part, to data presented by and/or input to the dynamic keyboard interface by the dynamic keyboard interface, the applications associated with portion 312 indicated by data indicative of the current context (e.g., "Let's go to the shore.", etc.), and the like.
In some embodiments, the data indicative of one or more previous contexts may be indicative of human language settings associated with a user device executing an application associated with the previous context; a geographical area to which the user equipment is registered; a network identifier associated with the user equipment; a geographic location of a user device associated with selecting a particular animated image; a time associated with selecting a particular animated image; a time of day associated with selecting a particular animated image; a date associated with selecting a particular animated image; a day of the week associated with selecting a particular animated image; a month associated with selecting a particular animated image; a year associated with selecting a particular animated image; the size of the audience associated with selecting a particular animated image; an entity providing one or more specific animated images or content included in one or more specific animated images, etc. In some such embodiments, the data indicating the current context may include data corresponding at least in part to a human language setting, a geographic area, a network identifier, a geographic location, a time of day, a date, a day of week, a month, a year, a size of an audience, an entity, and/or the like.
In some embodiments, the data indicative of one or more previous contexts may be indicative of an animated image previously selected via the dynamic keyboard interface, a time at which the animated image previously selected via the dynamic keyboard interface was selected, or the like. In some such embodiments, the data indicative of the current context may include data indicative of a selection of an animated image previously selected through the dynamic keyboard interface, a time associated with selecting an animated image previously selected through the dynamic keyboard interface, and/or the like.
In some embodiments, data indicating one or more previous contexts; data indicating previous selections, types of selections, particular animated images selected, etc.; a record or the like regarding a corpus of animated images may indicate an amount of time between selection of a particular animated image and presentation of a plurality of different animated images including the particular animated image by a dynamic keyboard interface, a time at which the selected particular animated image is initially available for selection from the plurality of different animated images through the dynamic keyboard interface, or the like. In some such embodiments, for at least one animated image included in a plurality of different animated images associated with the current context, determining a location within the dynamic keyboard interface for presenting such animated image may include determining such location based at least in part on data indicative of an amount of time.
In some embodiments, determining such a location based at least in part on the data indicative of the amount of time may include normalizing the data indicative of the amount of time based at least in part on a location of the animated image within the dynamic keyboard interface when a plurality of different animated images including the particular animated image are presented by the dynamic keyboard interface, a location of the animated image within the dynamic keyboard interface when such particular animated image is initially available for selection by the dynamic keyboard interface from among the plurality of different animated images including the particular animated image, and/or the like.
At (244), the user may select one or more particular animated images from a plurality of different animated images associated with the current context through the dynamic keyboard interface. For example, referring to FIG. 3L, a user may select animated image 324 for communication to an application or the like associated with portion 312 via a dynamic keyboard interface, and referring to FIG. 3M, in response to a user invoking element 318 or the like, the dynamic keyboard interface may communicate animated image 324 to an application or the like associated with portion 312.
At (246), computing device 40 may generate data indicative of the selection, the type of selection (e.g., for communication to an application associated with portion 312, etc.), the particular animated image selected (e.g., animated image 324, etc.), and may communicate such data to computing system 112, computing system 112 may receive the data and, at (248), may update records, etc., regarding the corpus of animated images based at least in part thereon.
At (250), the user may perform one or more actions providing one or more different and unique current contexts associated with computing device 40. For example, referring to fig. 3N, a user may switch from an application associated with element 302 (e.g., a messaging application, etc.) to an application associated with element 304 (e.g., an email application, etc.). Portion 334 may be associated with an application associated with element 304, and as shown, a dynamic keyboard interface may be provided in association with such application. The provided context may be computing device 40, a dynamic keyboard interface, an application associated with portion 334, and the like.
At (252), computing device 40 (e.g., a dynamic keyboard interface, etc.) may generate data indicative of such context, and may communicate such data to computing system 112, which computing system 112 may receive the data and update records regarding the corpus of animated images based at least in part thereon. In some embodiments, the data indicative of context may be indicative of data presented by and/or input to a dynamic keyboard interface, an application associated with portion 334, or the like (e.g., "I'm going to be at the coast.
Based at least in part on the data indicative of the current context, the data indicative of the previous context (e.g., received at (210), (224), (238), etc.), the data indicative of the previous selection, the type of selection, the particular animated image selected, etc. (e.g., received at (218), (232), (246), etc.), the records regarding the corpus of animated images, etc., at (254), the computing system 112 may identify a plurality of different animated images associated with the current context for presentation associated with an application by the dynamic keyboard interface (e.g., animated images related to, responsive to, etc. the current context), the application associated with the portion 334. In some embodiments, one or more of the plurality of different animated images associated with the current context may include one or more advertisements.
Based at least in part on the data indicative of the current context, the data indicative of the previous context (e.g., received at (210), (224), (238), etc.), the data indicative of a previous selection, a type of selection, a particular animated image selected, etc. (e.g., received at (218), (232), (246), etc.), the computing system 112 may determine, for each of one or more animated images included in a plurality of different animated images associated with the current context, a location within the dynamic keyboard interface for presenting the animated image.
At (256), computing system 112 may generate data indicative of the plurality of different animated images associated with the current context, their respective determined locations, etc., and may communicate such data to computing device 40 (e.g., to a dynamic keyboard interface), which computing device 40 may receive the data.
Referring to fig. 3O, in response to a user invoking element 320 or the like, the dynamic keyboard interface may switch (e.g., from a qwerty keyboard or the like) to the illustrated animated image keyboard or the like, which may present a plurality of different animated images associated with the current context based at least in part on their respective determined positions. For example, a plurality of different animated images associated with the current context may be presented in an ordered, and/or similar manner (e.g., animated images determined to be more relevant to, responsive to, etc. the current context may be presented earlier, more prominently).
As shown, multiple different animated images from the multiple different animated images associated with the current context may be displayed simultaneously side-by-side by the dynamic keyboard interface. For example, the dynamic keyboard interface may simultaneously display animated images 324, 328, 330, and 332, as well as other ones of a plurality of different animated images associated with the current context, and so forth.
In some embodiments, the animated images included in the plurality of different animated images associated with the current context may include one or more particular animated images (e.g., animated images 324, 330, 332, etc.) that were previously selected. In some such embodiments, the location within the dynamic keyboard interface for presenting such particular animated image may be determined based at least in part on a previously selected animated image, a previous context associated with its selection, and/or the like. For example, such particular animated images may be earlier, more prominent, etc. than they could have been presented (e.g., lack their previous selection, etc.). In some embodiments, one or more such particular animated images may include one or more advertisements.
As previously noted, in some embodiments, the data indicating the current context may indicate data (e.g., "I'm going to be at the monitor") presented by and/or input to an application associated with portion 334 by the dynamic keyboard interface, an application associated with portion 334, or the like. In some such embodiments, for one or more animated images (e.g., animated images 324, 330, 332, etc.) included in the plurality of different animated images associated with the current context, determining a location within the dynamic keyboard interface for presenting such animated images may include determining data presented by and/or input to the dynamic keyboard interface, the one or more applications or the like associated with the one or more previous contexts indicated by the data indicative of the one or more previous contexts (e.g., "We're at the coast.", "Nice | import the beach.", "Let's go to the shore." etc.) correspond, at least in part, to data presented and/or entered by the dynamic keyboard interface, applications associated with the portion 334 indicated by the data indicative of the current context (e.g., "I'm going to be at the coast." etc.), and the like.
At (258), the user may perform one or more actions providing one or more different and unique current contexts associated with computing device 40. The provided context may be computing device 40, a dynamic keyboard interface, an application associated with portion 334, and the like. For example, referring to FIG. 3P, the user may invoke element 322 and enter one or more search terms (e.g., "shell," etc.) using the illustrated keyboard.
At (260), computing device 40 (e.g., a dynamic keyboard interface, etc.) may generate data indicative of such context, and may communicate such data to computing system 112, which computing system 112 may receive the data and update records regarding the corpus of animated images based at least in part thereon. In some embodiments, the data indicative of context may be indicative of an entered search term or the like.
Referring to fig. 2D, based at least in part on the data indicative of the current context, the data indicative of the previous context (e.g., received at (210), (224), (238), (252), etc.), the data indicative of the previous selection, the type of selection, the particular animated image selected, etc. (e.g., received at (218), (232), (246), etc.), the records regarding the corpus of animated images, etc., at (262), the computing system 112 may identify a plurality of different animated images associated with the current context for presentation by the dynamic keyboard interface in association with an application (e.g., an animated image that is relevant to, responsive to, etc. the current context), the application being associated with portion 334. In some embodiments, one or more of the plurality of different animated images associated with the current context may include one or more advertisements.
Based at least in part on the data indicative of the current context, the data indicative of the previous context (e.g., received at (210), (224), (238), (252), etc.), the data indicative of the previous selection, the type of selection, the particular animated image selected, etc. (e.g., received at (218), (232), (246), etc.), the computing system 112 may determine, for each of one or more animated images included in a plurality of different animated images associated with the current context, a location within the dynamic keyboard interface for presenting the animated image, etc.
At (264), the computing system 112 may generate data indicative of the plurality of different animated images associated with the current context, their respective determined locations, etc., and may communicate such data to the computing device 40 (e.g., to a dynamic keyboard interface), the computing device 40 may receive the data, and, with reference to fig. 3Q, may switch (e.g., from a qwerty keyboard, etc.) to the illustrated animated image keyboard, etc., may render the plurality of different animated images associated with the current context based at least in part on their respective determined locations. For example, a plurality of different animated images associated with the current context may be presented in an ordered, and/or similar manner (e.g., animated images determined to be more relevant to, responsive to, etc. the current context may be presented earlier, more prominently).
As shown, multiple different animated images from the multiple different animated images associated with the current context may be displayed simultaneously side-by-side by the dynamic keyboard interface. For example, the dynamic keyboard interface may simultaneously display animated images 326, 330, and 332, as well as other ones of a plurality of different animated images associated with the current context, and so forth.
In some embodiments, the animated images included in the plurality of different animated images associated with the current context may include one or more particular animated images (e.g., animated images 330, 332, etc.) that were previously selected. In some such embodiments, the location within the dynamic keyboard interface for presenting such particular animated image may be determined based at least in part on a previously selected animated image, a previous context associated with its selection, and/or the like. For example, such particular animated images may be earlier, more prominent, etc. than they could have been presented (e.g., lack their previous selection, etc.). In some embodiments, one or more such particular animated images may include one or more advertisements.
In some embodiments, for at least one animated image included in a plurality of different animated images associated with a current context, determining a location within the dynamic keyboard interface for presenting such animated image may include determining a frequency of selection of such animated image based at least in part on data previously received indicating selection of such animated image. In some such embodiments, the location of such animated images may be determined based at least in part on the selection frequency of such animated images, one or more selection frequencies of such locations, and/or the like.
In some embodiments, computing system 112 may determine one or more selection frequencies for such locations based at least in part on data indicative of one or more selection frequencies for one or more animated images previously presented in such locations within the dynamic keyboard interface. In some embodiments, the animated images previously presented at such locations may include one or more animated images that do not contain advertising content. Additionally or alternatively, the animated images previously presented at such locations may include one or more animated images containing one or more advertisements that are different from the advertisements included in the animated images at the determined locations. In some embodiments, computing system 112 may determine one or more selection frequencies for such locations at which the animated image was previously presented based at least in part on data indicative of one or more previous contexts.
At (266), the user may select one or more particular animated images from a plurality of different animated images associated with the current context through the dynamic keyboard interface. For example, the user may select animated image 326 for communication to an application or the like associated with portion 334 through the dynamic keyboard interface, and referring to FIG. 3R, the dynamic keyboard interface may communicate animated image 326 to an application or the like associated with portion 334.
At (268), computing device 40 may generate data indicative of the selection, the type of selection (e.g., for communication to an application associated with portion 334, etc.), the particular animated image selected (e.g., animated image 326, etc.), and may transmit such data to computing system 112, computing system 112 may receive the data and, at (270), may be based at least in part on its recordation of the corpus of animated images.
At (272), the user may perform one or more actions providing one or more different and unique current contexts associated with computing device 50. The provided context may be computing device 50, a dynamic keyboard interface, an application associated with portion 312, and so forth. For example, referring to FIG. 3S, the user may interact with the application associated with portion 312 through its interface (e.g., switch to a message session with "John S," etc.).
At (274), computing device 50 (e.g., a dynamic keyboard interface, etc.) may generate data indicative of such context, and may communicate such data to computing system 112, which computing system 112 may receive the data and update records regarding the corpus of animated images based at least in part thereon. In some embodiments, the data indicative of context may be indicative of data (e.g., "connected score shore," etc.) presented by and/or input to the dynamic keyboard interface, the application associated with portion 312, and/or the like.
Based at least in part on the data indicative of the current context, the data indicative of the previous context (e.g., received at (210), (224), (238), (252), (260), etc.), the data indicative of the previous selection, the type of selection, the particular animated image selected, etc. (e.g., received at (218), (232), (246), (268), etc.), the records regarding the corpus of dynamic images, at (276), computing system 112 may identify a plurality of different animated images associated with the current context for presentation by the dynamic keyboard interface in association with the application associated with portion 312 (e.g., animated images related to, responsive to, etc. the current context). In some embodiments, one or more of the plurality of different animated images associated with the current context may include one or more advertisements.
Based at least in part on the data indicative of the current context, the data indicative of the previous context (e.g., received at (210), (224), (238), (252), (260), etc.), the data indicative of the previous selection, the type of selection, the particular animated image selected, etc. (e.g., received at (218), (232), (246), (268), etc.), the records regarding the corpus of animated images, etc., computing system 112 may determine a location within the dynamic keyboard interface for displaying the animated image for each of one or more animated images included in a plurality of different animated images associated with the current context.
At (278), computing system 112 may generate data indicative of the plurality of different animated images associated with the current context, their respective determined locations, etc., and may communicate such data to computing device 50 (e.g., to a dynamic keyboard interface), which computing device 50 may receive the data.
Referring to fig. 3T, in response to a user invoking element 320 or the like, the dynamic keyboard interface may switch (e.g., from a qwerty keyboard or the like) to the illustrated animated image keyboard or the like, which may present a plurality of different animated images associated with the current context based at least in part on their respective determined positions. For example, a plurality of different animated images associated with the current context may be presented in an ordered, and/or similar manner (e.g., animated images determined to be more relevant to, responsive to, etc. the current context may be presented earlier, more prominently).
As shown, multiple different animated images from the multiple different animated images associated with the current context may be displayed simultaneously side-by-side by the dynamic keyboard interface. For example, the dynamic keyboard interface may simultaneously display animated images 324, 328, 330, and 332, as well as other ones of a plurality of different animated images associated with the current context, and so forth.
In some embodiments, the animated images included in the plurality of different animated images associated with the current context may include one or more particular animated images (e.g., animated images 324, 330, 332, etc.) that were previously selected. In some such embodiments, the location within the dynamic keyboard interface for presenting such particular animated image may be determined based at least in part on a previously selected animated image, a previous context associated with its selection, and/or the like. For example, such particular animated images may be earlier, more prominent, etc. than they could have been presented (e.g., lack their previous selection, etc.). In some embodiments, one or more such particular animated images may include one or more advertisements.
As previously described, in some embodiments, the data indicating the current context may indicate data of data (e.g., "connected score shore," etc.) presented by and/or input to the dynamic keyboard interface, the application associated with portion 312, and/or the like. In some such embodiments, for one or more animated images (e.g., animated images 324, 330, 332, etc.) of animated images included in a plurality of different animated images associated with a current context, determining a location within the dynamic keyboard interface for rendering such animated images may include determining data rendered by and/or input to the dynamic keyboard interface by the dynamic keyboard interface, the one or more applications associated with one or more previous contexts indicated by data indicative of the one or more previous contexts (e.g., "We're at the game."; Nice e en joy the beacon. "; Let's to the shore." "I'm going to be at the game." etc.) corresponding, at least in part, to data rendered by and/or input to the dynamic keyboard interface by the dynamic keyboard interface, the data indicative of the current context (e.g., "connected score shore," etc.) indicates the application associated with portion 312, etc.
At (280), the user may select one or more particular animated images from a plurality of different animated images associated with the current context through the dynamic keyboard interface. For example, referring to FIG. 3U, the user may select animated image 328 for communication by the dynamic keyboard interface to an application or the like associated with portion 312, and referring to FIG. 3V, in response to the user invoking element 318 or the like, the dynamic keyboard interface may communicate animated image 328 to an application or the like associated with portion 312.
Referring to fig. 2E, at (282), computing device 50 may generate data indicative of the selection, the type of selection (e.g., for communicating to an application associated with portion 312, etc.), the particular animated image selected (e.g., animated image 328, etc.), and may communicate such data to computing system 112, which computing system 112 may receive the data, and at (284), may update a record regarding the corpus of animated images based at least in part thereon.
At (286), the user may perform one or more actions providing one or more different and unique current contexts associated with the computing device 50. For example, referring to fig. 3W, a user may switch from an application associated with element 302 (e.g., a messaging application, etc.) to an application associated with element 304 (e.g., an email application, etc.). The provided context may be computing device 50, a dynamic keyboard interface, an application associated with portion 334, and the like.
At (288), computing device 50 (e.g., dynamic keyboard interface, etc.) may generate data indicative of such context, and may communicate such data to computing system 112, which computing system 112 may receive the data and update records regarding the animated image corpus based at least in part thereon. In some embodiments, the data indicating context may indicate data presented by and/or input to the dynamic keyboard interface, an application associated with portion 334, or the like (e.g., "connected score shore," or the like).
Based at least in part on the data indicative of the current context, the data indicative of the previous context (e.g., received at (210), (224), (238), (252), (260), (274), etc.), the data indicative of the previous selection, the type of selection, the particular animated image selected, etc. (e.g., received at (218), (232), (246), (268), (282), etc.), the records regarding the corpus of animated images, etc., at (290), computing system 112 may identify a plurality of different animated images associated with the current context for presentation in association with the application associated with portion 334 by the dynamic keyboard interface (e.g., animated images related to, responsive to, etc. the current context). In some embodiments, one or more of the plurality of different animated images associated with the current context may include one or more advertisements.
Based at least in part on the data indicative of the current context, the data indicative of the previous context (e.g., received at (210), (224), (238), (252), (260), (274), etc.), the data indicative of a previous selection, a type of selection, a particular animated image selected, etc. (e.g., received at (218), (232), (246), (268), (282), etc.), a record regarding a corpus of animated images, etc., computing system 112 may determine, for each of one or more animated images included in a plurality of different animated images associated with the current context, a location within the dynamic keyboard interface for presenting the animated image.
At (292), computing system 112 may generate data indicative of the plurality of different animated images associated with the current context, their respective determined locations, etc., and may communicate such data to computing device 50 (e.g., to a dynamic keyboard interface), which computing device 50 may receive the data.
Referring to fig. 3X, in response to a user invoking element 320 or the like, the dynamic keyboard interface may switch (e.g., from a qwerty keyboard or the like) to an animated image keyboard or the like as illustrated, which may present a plurality of different animated images associated with the current context based at least in part on their respective determined positions. For example, a plurality of different animated images associated with the current context may be presented in an ordered, and/or similar manner (e.g., animated images determined to be more relevant to, responsive to, etc. the current context may be presented earlier, more prominently).
As shown, multiple different animated images from the multiple different animated images associated with the current context may be displayed simultaneously side-by-side by the dynamic keyboard interface. For example, the dynamic keyboard interface may simultaneously display animated images 324, 328, 330, and 332, as well as other ones of a plurality of different animated images associated with the current context, and so forth.
In some embodiments, the animated images included in the plurality of different animated images associated with the current context may include one or more particular animated images (e.g., animated images 324, 328, 330, 332, etc.) that were previously selected. In some such embodiments, the location within the dynamic keyboard interface for presenting such particular animated image may be determined based at least in part on a previously selected animated image, a previous context associated with its selection, and/or the like. For example, such particular animated images may be earlier, more prominent, etc. than they could have been presented (e.g., lack their previous selection, etc.). In some embodiments, one or more such particular animated images may include one or more advertisements.
As previously described, in some embodiments, the data indicating the current context may indicate data presented by and/or input to the dynamic keyboard interface, an application associated with portion 334, or the like (e.g., "connected score shore," or the like). In some such embodiments, for one or more animated images (e.g., animated images 324, 328, 330, 332, etc.) included in an animated image in a plurality of different animated images associated with a current context, determining a location within a dynamic keyboard interface for rendering such animated images may include determining data rendered by and/or input to the dynamic keyboard interface, the one or more applications associated with the one or more previous contexts, etc., indicated by data indicative of the one or more previous contexts (e.g., "We're at the coast."; Nice Enteroy the beach), "Let's go the shore"; I'm going to be at the coast. "," connected history shore, "etc.) corresponding at least in part to the data rendered by and/or input to the dynamic keyboard interface by the dynamic keyboard interface, an application associated with portion 334, indicated by data indicating the current context (e.g., "connected score" or the like).
At (294), the user may select one or more particular animated images from a plurality of different animated images associated with the current context through the dynamic keyboard interface. For example, the user may select animated image 328 for communication by the dynamic keyboard interface to an application or the like associated with portion 334, and referring to FIG. 3Y, the dynamic keyboard interface may communicate animated image 328 to an application or the like associated with portion 334.
At (296), computing device 50 may generate data indicative of the selection, the type of selection (e.g., for communication to an application associated with portion 334, etc.), the particular animated image selected (e.g., animated image 328, etc.), and may communicate such data to computing system 112, computing system 112 may receive the data and, at (298), may update records regarding the corpus of animated images based at least in part thereon.
Fig. 4 depicts an exemplary method according to an exemplary embodiment of the present disclosure.
Referring to fig. 4, at (402), one or more computing devices may receive data indicating a context of: a dynamic keyboard interface and/or an application provided in association with the application. For example, computing system 112 may receive data from computing device 40 indicating a context for: a dynamic keyboard interface provided in association with an application associated with portion 312 (e.g., a messaging application, etc.) and/or an application associated with portion 312.
At (404), the computing device may identify a plurality of different animated images for presentation in association with an application by the dynamic keyboard interface based at least in part on the data indicative of context. For example, computing system 112 may identify, based at least in part on data received from computing device 40, a plurality of different animated images (e.g., animated images 324, 326, 328, etc.) included in the animated image keyboard illustrated in fig. 3D for presentation by the dynamic keyboard interface in association with the application associated with portion 312.
At (406), the computing device may communicate data indicative of a plurality of different animated images to the user device. For example, computing system 112 may communicate data indicative of a plurality of different animated images (e.g., animated images 324, 326, 328, etc.) included in the animated image keyboard shown in fig. 3D to computing device 40.
At (408), the computing device may receive data from the user device indicating a selection of a particular animated image from a plurality of different animated images. For example, computing system 112 may receive data from computing device 40 indicating selection of animated image 324.
At (410), the computing device may receive data indicating a subsequent context of: a dynamic keyboard interface, an application, and/or a different and unique application, with which the dynamic keyboard interface is provided in association. For example, computing system 112 may receive data from computing device 50 indicating the context of: an application associated with portion 334 (e.g., an email application, etc.) and/or a dynamic keyboard interface provided in association therewith.
At (412), the computing device may identify a plurality of different animated images including a particular animated image based at least in part on the data indicative of the subsequent context. For example, computing system 112 may identify, based at least in part on data received from computing device 50, a plurality of different animated images (e.g., animated images 324, 328, 330, 332, etc.) included in the animated image keyboard shown in fig. 3X for presentation by the dynamic keyboard interface in association with the application associated with portion 334.
At (414), the computing device may determine a location within the dynamic keyboard interface for rendering a particular animated image in response to the data indicative of the subsequent context based at least in part on the data indicative of the selection and the data indicative of the context. For example, the computing system 112 may select the animated image 324 based at least in part on the data indicative for identifying, within the dynamic keyboard interface, the dynamic keyboard interface for the programmatic animated image 324 in response to the data indicative: an application associated with portion 334 (e.g., an email application, etc.) and/or a dynamic keyboard interface provided in association therewith.
The techniques discussed herein make reference to servers, databases, software applications, and/or other computer-based systems, as well as actions taken and information sent to and/or from such systems. The inherent flexibility of computer-based systems allows for a variety of possible configurations, combinations, and/or task divisions and/or functionality between components. For example, the processes discussed herein may be implemented using a single device or component and/or multiple devices or components operating in combination. The database and/or application may be implemented on a single system and/or distributed across multiple systems. The distributed components may operate sequentially and/or in parallel.
Various connections between elements are discussed in the above description. These connections are general and, unless specified otherwise, may be direct and/or indirect wired and/or wireless connections. The description is not intended to be limiting in this respect.
The steps depicted and/or indicated are merely illustrative and may be omitted, combined, and/or performed in an order other than depicted and/or indicated; the numbering of the steps depicted is for ease of reference only and does not imply that any particular order is necessary or preferred.
The functions and/or steps described herein may be embodied in computer-usable data and/or computer-executable instructions for execution by one or more computers and/or other devices to perform one or more of the functions described herein. Generally, such data and/or instructions include routines, programs, objects, components, data structures, etc. that perform particular tasks and/or implement particular data types when executed by one or more processors in a computer and/or other data processing device. Computer executable instructions may be stored on a computer readable medium such as a hard disk, optical disk, removable storage media, solid state memory, Read Only Memory (ROM), Random Access Memory (RAM), etc. As will be appreciated, the functionality of such instructions may be combined and/or distributed as desired. Further, the functionality may be embodied in whole or in part in firmware and/or hardware equivalents such as integrated circuits, Application Specific Integrated Circuits (ASICs), Field Programmable Gate Arrays (FPGAs), etc. Particular data structures may be used to more effectively implement one or more aspects of the present disclosure, and such data structures are contemplated to be within the scope of computer-executable instructions and/or computer-usable data shown herein.
Although not required, one of ordinary skill in the art will appreciate that various aspects described herein can be embodied as methods, systems, apparatuses, and/or one or more computer-readable media storing computer-executable instructions. Accordingly, the various aspects may take the form of an entirely hardware embodiment, an entirely software embodiment, an entirely firmware embodiment, and/or an embodiment combining software, hardware, and/or firmware aspects in any combination.
As shown herein, various methods and acts may operate across one or more computing devices and/or networks. The functionality may be distributed in any manner or may be located in a single computing device (e.g., server, client computer, user device, etc.).
Various aspects of the invention have been indicated in accordance with illustrative embodiments of the invention. Numerous other embodiments, modifications and/or variations within the scope and spirit of the appended claims will occur to persons of ordinary skill in the art from a review of this disclosure. For example, those of ordinary skill in the art will appreciate that the steps depicted and/or indicated may be performed in a different order than presented and/or that one or more of the illustrated steps may be optional and/or combined. Any and all features in the following claims may be combined and/or rearranged in any possible way.
While the subject matter of the invention has been indicated in detail in relation to various specific exemplary embodiments thereof, each of these examples is provided by way of illustration and not by way of limitation of the invention. Those skilled in the art, having the benefit of the foregoing description, may readily modify, adapt and/or equivalents to such embodiments. Thus, the present invention does not preclude inclusion of such modifications, variations and/or additions to the present subject matter as would be readily apparent to one of ordinary skill in the art. For instance, features illustrated and/or indicated as part of one embodiment, can be used with another embodiment to yield a still further embodiment. It is therefore intended that the present invention encompass such changes, variations and/or equivalents.
Claims (20)
1. A computer-implemented method, comprising:
receiving, by one or more computing devices, data indicating a selection of a particular animated image from a plurality of different animated images presented by a dynamic keyboard interface provided in association with an application;
receiving, by one or more computing devices, data indicating a context of one or more of:
the dynamic keyboard interface is based at least in part on which of a plurality of different animated images is selected for presentation by the dynamic keyboard interface, or
The application is based at least in part on which of a plurality of different animated images is selected for presentation by the dynamic keyboard interface; and
determining, by the one or more computing devices, a location within the dynamic keyboard interface for presenting the particular animated image based at least in part on the data indicative of the selection and the data indicative of the context, in response to the data indicative of the subsequent context of one or more of:
a dynamic keyboard interface,
use of, or
Different and unique applications, associated with which a dynamic keyboard interface is provided.
2. The computer-implemented method of claim 1,
receiving the data indicative of the selection comprises receiving the data indicative of the selection from a user device on which the application is executing;
receiving data indicative of a context comprises receiving data indicative of a context from a user device on which an application is executing; and
the subsequent context includes a context of the user device when the user device is providing a dynamic keyboard interface associated with the application.
3. The computer-implemented method of claim 1,
receiving data indicative of the selection comprises receiving data indicative of the selection from a user device on which the application and a different and unique application execute;
receiving data indicative of context comprises receiving data indicative of context from a user device on which an application and a different and unique application execute; and
the subsequent context includes a context of the user device when the user device is providing a dynamic keyboard interface associated with a different and unique application.
4. The computer-implemented method of claim 1,
receiving the data indicative of the selection comprises receiving the data indicative of the selection from the first user equipment;
receiving the data indicative of the context comprises receiving the data indicative of the context from the first user equipment;
the subsequent context comprises a context of the second user device when the second user device is providing a dynamic keyboard interface associated with the application; and
the first user device and the second user device are different from each other and are each unique.
5. The computer-implemented method of claim 1,
receiving the data indicative of the selection comprises receiving the data indicative of the selection from the first user equipment;
receiving the data indicative of the context comprises receiving the data indicative of the context from the first user equipment;
the subsequent context comprises a context of the second user device when the second user device is providing a dynamic keyboard interface associated with a different and unique application; and
the first user device and the second user device are different from each other and are each unique.
6. The computer-implemented method of claim 1, wherein receiving data indicating a selection comprises receiving data indicating that a particular animated image has been selected for communication by the dynamic keyboard interface to the application.
7. The computer-implemented method of claim 1, wherein receiving data indicating a selection comprises receiving data indicating that a particular animated image has been selected for future access within a dynamic keyboard interface.
8. The computer-implemented method of claim 1, wherein determining a location within the dynamic keyboard interface for rendering the particular animated image comprises:
determining a frequency of selection of a particular animated image based at least in part on the data indicative of selection; and
the location is determined based at least in part on the selection frequency and one or more selection frequencies of the location.
9. The computer-implemented method of claim 1,
the data indicative of context is indicative of one or more search terms entered via the dynamic keyboard interface; and
the data indicative of the subsequent context is indicative of at least one of the one or more search terms entered via the dynamic keyboard interface.
10. The computer-implemented method of claim 1,
the data indicative of context is indicative of one or more data presented by or input to the application;
the data indicating the subsequent context indicates one or more data presented by or input into one or more of the dynamic keyboard interface, the application, or the different and unique application; and
determining a location within the dynamic keyboard interface for rendering the particular animated image includes determining that one or more data rendered by or input to the application corresponds, at least in part, to one or more data rendered by or input to one or more of the dynamic keyboard interface, the application, or a different and unique application.
11. The computer-implemented method of claim 1,
the context-indicating data indicates one or more of:
animated images previously selected via a dynamic keyboard interface, or
Selecting a time of an animated image previously selected via the dynamic keyboard interface; and
the data indicating the subsequent context comprises data indicating one or more of:
animated images previously selected via a dynamic keyboard interface, or
A time associated with selecting an animated image previously selected via the dynamic keyboard interface.
12. The computer-implemented method of claim 1,
the context-indicating data indicates one or more of:
a human language setting associated with a user device on which the application is executed,
the geographical area in which the user equipment is registered,
a network identifier associated with the user equipment,
the geographic location of the user device associated with the selection of a particular animated image,
the time associated with the selection of a particular animated image,
the time of day associated with the selection of a particular animated image,
the date associated with the selection of a particular animated image,
the day of the week associated with the selection of a particular animated image,
the month associated with the selection of the particular animated image,
the year associated with the selection of a particular animated image,
size of audience associated with selection of a particular animated image, or
An entity that provides one or more specific animated images or content included in a specific animated image; and
the data indicating the subsequent context includes data corresponding at least in part to one or more of a human language setting, a geographic area, a network identifier, a geographic location, a time of day, a date, a day of week, a month, a year, a size of an audience, or an entity.
13. The computer-implemented method of claim 1,
the method includes receiving, by one or more computing devices, data indicating an amount of time between selecting a particular animated image and one or more of:
time of presentation of a plurality of different animated images by a dynamic keyboard interface, or
A particular animated image is initially available for a time selected by the dynamic keyboard interface from a plurality of different animated images; and
determining a location within the dynamic keyboard interface for rendering the particular animated image includes determining the location based at least in part on the data indicative of the amount of time.
14. The computer-implemented method of claim 13, wherein determining a location based at least in part on the data indicative of the amount of time comprises normalizing the data indicative of the amount of time based at least in part on one or more of:
a position of a particular animated image within the dynamic keyboard interface when a plurality of different animated images are presented by the dynamic keyboard interface; or
A location of the particular animated image within the dynamic keyboard interface when the particular animated image is initially available for selection by the dynamic keyboard interface from a plurality of different animated images.
15. A system, comprising:
one or more processors; and
a memory storing instructions that, when executed by the one or more processors, cause the system to perform operations comprising:
receiving data indicating a context of one or more of:
a dynamic keyboard interface when a particular animated image is selected from a plurality of different animated images presented by the dynamic keyboard interface in association with an application providing the dynamic keyboard interface, or
An application that provides a dynamic keyboard interface when a particular animated image is selected from a plurality of different animated images presented by the dynamic keyboard interface; and
determining a location within the dynamic keyboard interface for rendering the particular animated image in response to data indicative of a subsequent context of one or more of:
a dynamic keyboard interface,
use of, or
Different and unique applications, associated with which a dynamic keyboard interface is provided.
16. The system of claim 15, wherein,
the data indicative of context is indicative of one or more search terms entered via the dynamic keyboard interface; and
the data indicating the subsequent context indicates at least one of the one or more search terms entered via the dynamic keyboard interface.
17. The system of claim 15, wherein,
the data indicative of context is indicative of one or more data presented by or input to the application;
the data indicating the subsequent context indicates one or more data presented by or input into one or more of the dynamic keyboard interface, the application, or the different and unique application; and
determining a location within the dynamic keyboard interface for rendering the particular animated image includes determining that one or more data rendered by or input to the application corresponds, at least in part, to one or more data rendered by or input to one or more of the dynamic keyboard interface, the application, or a different and unique application.
18. One or more non-transitory computer-readable media comprising instructions that, when executed by one or more computing devices, cause the one or more computing devices to perform operations comprising:
receiving data indicating a selection of a particular animated image from a plurality of different animated images presented by a dynamic keyboard interface provided in association with an application;
receiving data indicative of an amount of time between selecting a particular animated image and one or more of:
time of presentation of a plurality of different animated images by a dynamic keyboard interface, or
A particular animated image is initially available for a time selected by the dynamic keyboard interface from a plurality of different animated images; and
determining a location within the dynamic keyboard interface for rendering the particular animated image in response to the data indicating the context of one or more of:
a dynamic keyboard interface,
use of, or
Different and unique applications, associated with which a dynamic keyboard interface is provided.
19. The one or more non-transitory computer-readable media of claim 18, wherein determining a location within the dynamic keyboard interface for presenting the particular animated image includes normalizing data indicative of an amount of time based at least in part on one or more of:
a position of a particular animated image within the dynamic keyboard interface when a plurality of different animated images are presented by the dynamic keyboard interface; or
A location of the particular animated image within the dynamic keyboard interface when the particular animated image is initially available for selection by the dynamic keyboard interface from a plurality of different animated images.
20. The one or more non-transitory computer-readable media of claim 18, wherein determining a location within the dynamic keyboard interface for rendering the particular animated image includes determining the location based at least in part on the data indicative of the context.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201862725641P | 2018-08-31 | 2018-08-31 | |
US62/725,641 | 2018-08-31 | ||
PCT/US2019/047216 WO2020046637A1 (en) | 2018-08-31 | 2019-08-20 | Methods and systems for positioning animated images within a dynamic keyboard interface |
Publications (1)
Publication Number | Publication Date |
---|---|
CN112639709A true CN112639709A (en) | 2021-04-09 |
Family
ID=67841206
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201980057190.1A Pending CN112639709A (en) | 2018-08-31 | 2019-08-20 | Method and system for positioning animated images within a dynamic keyboard interface |
Country Status (6)
Country | Link |
---|---|
US (2) | US11740787B2 (en) |
EP (1) | EP3827331A1 (en) |
JP (2) | JP7206370B2 (en) |
KR (3) | KR102481910B1 (en) |
CN (1) | CN112639709A (en) |
WO (1) | WO2020046637A1 (en) |
Families Citing this family (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
KR102481910B1 (en) | 2018-08-31 | 2022-12-27 | 구글 엘엘씨 | Animation image positioning method and system in dynamic keyboard interface |
US11910196B1 (en) * | 2020-11-12 | 2024-02-20 | Wells Fargo Bank, N.A. | Dynamic keyboard for electronic computing device |
KR102471306B1 (en) * | 2022-07-06 | 2022-11-25 | 김봉근 | Device and method for inputting characters |
Citations (10)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN102906750A (en) * | 2010-06-01 | 2013-01-30 | 微软公司 | Providing content items selected based on context |
US20150100537A1 (en) * | 2013-10-03 | 2015-04-09 | Microsoft Corporation | Emoji for Text Predictions |
US20160027045A1 (en) * | 2013-03-11 | 2016-01-28 | Keypoint Technologies India Pvt. Ltd. | Contextual discovery |
US20170083524A1 (en) * | 2015-09-22 | 2017-03-23 | Riffsy, Inc. | Platform and dynamic interface for expression-based retrieval of expressive media content |
US20170142044A1 (en) * | 2015-11-16 | 2017-05-18 | Facebook, Inc. | Ranking and Filtering Comments Based on Impression Calculations |
JP2017211876A (en) * | 2016-05-26 | 2017-11-30 | 京セラドキュメントソリューションズ株式会社 | Display device and display control program |
US20170371522A1 (en) * | 2016-06-23 | 2017-12-28 | Microsoft Technology Licensing, Llc | Suppression of input images |
US20180047195A1 (en) * | 2016-08-09 | 2018-02-15 | Pegge Vissicaro | Keyboard with in-line user created emojis |
US20180053101A1 (en) * | 2016-08-17 | 2018-02-22 | Microsoft Technology Licensing, Llc | Remote and local predictions |
CN108205376A (en) * | 2016-12-19 | 2018-06-26 | 谷歌有限责任公司 | It is predicted for the legend of dialogue |
Family Cites Families (32)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7028253B1 (en) | 2000-10-10 | 2006-04-11 | Eastman Kodak Company | Agent for integrated annotation and retrieval of images |
US20030119531A1 (en) * | 2001-12-21 | 2003-06-26 | Patton Charles M. | Dynamic selection of avatar policies based on physical device location and derived user control |
US20100265182A1 (en) * | 2009-04-20 | 2010-10-21 | Microsoft Corporation | Context-based state change for an adaptive input device |
US20110153387A1 (en) * | 2009-12-17 | 2011-06-23 | Google Inc. | Customizing surveys |
US9015595B2 (en) * | 2010-01-20 | 2015-04-21 | Yahoo! Inc. | Self-targeting local AD system |
KR20140093957A (en) | 2011-11-24 | 2014-07-29 | 마이크로소프트 코포레이션 | Interactive multi-modal image search |
US20130159919A1 (en) | 2011-12-19 | 2013-06-20 | Gabriel Leydon | Systems and Methods for Identifying and Suggesting Emoticons |
US20140157153A1 (en) * | 2012-12-05 | 2014-06-05 | Jenny Yuen | Select User Avatar on Detected Emotion |
US10228819B2 (en) * | 2013-02-04 | 2019-03-12 | 602531 British Cilumbia Ltd. | Method, system, and apparatus for executing an action related to user selection |
US9665240B2 (en) * | 2014-01-27 | 2017-05-30 | Groupon, Inc. | Learning user interface having dynamic icons with a first and second visual bias |
EP3111305A4 (en) * | 2014-02-27 | 2017-11-08 | Keyless Systems Ltd | Improved data entry systems |
KR20160039523A (en) * | 2014-09-30 | 2016-04-11 | (주)위자드웍스 | Keyboard application server and method for providing advertisement contents using the same |
KR101583181B1 (en) * | 2015-01-19 | 2016-01-06 | 주식회사 엔씨소프트 | Method and computer program of recommending responsive sticker |
KR101634086B1 (en) * | 2015-01-19 | 2016-07-08 | 주식회사 엔씨소프트 | Method and computer system of analyzing communication situation based on emotion information |
US20160306438A1 (en) * | 2015-04-14 | 2016-10-20 | Logitech Europe S.A. | Physical and virtual input device integration |
US9940362B2 (en) | 2015-05-26 | 2018-04-10 | Google Llc | Predicting user needs for a particular context |
CA2949184C (en) * | 2015-11-20 | 2023-01-03 | Staples, Inc. | Transactional, digital image-based asynchronous electronic communication |
KR101651390B1 (en) * | 2016-02-16 | 2016-08-25 | 주식회사최병철아이디어팩토리 | System and method for providing advertisement |
US11494547B2 (en) * | 2016-04-13 | 2022-11-08 | Microsoft Technology Licensing, Llc | Inputting images to electronic devices |
US11320982B2 (en) * | 2016-05-18 | 2022-05-03 | Apple Inc. | Devices, methods, and graphical user interfaces for messaging |
US20170344224A1 (en) * | 2016-05-27 | 2017-11-30 | Nuance Communications, Inc. | Suggesting emojis to users for insertion into text-based messages |
US10348662B2 (en) * | 2016-07-19 | 2019-07-09 | Snap Inc. | Generating customized electronic messaging graphics |
CN117634495A (en) * | 2016-09-20 | 2024-03-01 | 谷歌有限责任公司 | Suggested response based on message decal |
KR20210013323A (en) * | 2016-09-23 | 2021-02-03 | 애플 인크. | Avatar creation and editing |
US20180137660A1 (en) * | 2016-11-11 | 2018-05-17 | Microsoft Technology Licensing, Llc | Responsive customized digital stickers |
US10444987B2 (en) * | 2016-12-19 | 2019-10-15 | Microsoft Technology Licensing, Llc | Facilitating selection of holographic keyboard keys |
KR102079221B1 (en) | 2016-12-30 | 2020-02-19 | 주식회사 카카오 | Messenger searching method based on interaction, and server and application implementing the same method |
US20180300542A1 (en) * | 2017-04-18 | 2018-10-18 | Nuance Communications, Inc. | Drawing emojis for insertion into electronic text-based messages |
US20180329622A1 (en) * | 2017-05-12 | 2018-11-15 | Apple Inc. | Portable Computing Input Devices and Methods |
DK180212B1 (en) * | 2018-05-07 | 2020-08-19 | Apple Inc | USER INTERFACE FOR CREATING AVATAR |
KR102481910B1 (en) | 2018-08-31 | 2022-12-27 | 구글 엘엘씨 | Animation image positioning method and system in dynamic keyboard interface |
JP2022016040A (en) | 2020-07-10 | 2022-01-21 | 株式会社Ｎｔｔドコモ | Communication control device |
-
2019
- 2019-08-20 KR KR1020217007935A patent/KR102481910B1/en active IP Right Grant
- 2019-08-20 CN CN201980057190.1A patent/CN112639709A/en active Pending
- 2019-08-20 US US17/272,541 patent/US11740787B2/en active Active
- 2019-08-20 EP EP19762569.2A patent/EP3827331A1/en active Pending
- 2019-08-20 WO PCT/US2019/047216 patent/WO2020046637A1/en unknown
- 2019-08-20 JP JP2021510668A patent/JP7206370B2/en active Active
- 2019-08-20 KR KR1020227044714A patent/KR102634375B1/en active IP Right Grant
- 2019-08-20 KR KR1020247003706A patent/KR20240017141A/en active Application Filing
-
2022
- 2022-12-27 JP JP2022210461A patent/JP2023052127A/en active Pending
-
2023
- 2023-07-13 US US18/351,890 patent/US20230359353A1/en active Pending
Patent Citations (10)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN102906750A (en) * | 2010-06-01 | 2013-01-30 | 微软公司 | Providing content items selected based on context |
US20160027045A1 (en) * | 2013-03-11 | 2016-01-28 | Keypoint Technologies India Pvt. Ltd. | Contextual discovery |
US20150100537A1 (en) * | 2013-10-03 | 2015-04-09 | Microsoft Corporation | Emoji for Text Predictions |
US20170083524A1 (en) * | 2015-09-22 | 2017-03-23 | Riffsy, Inc. | Platform and dynamic interface for expression-based retrieval of expressive media content |
US20170142044A1 (en) * | 2015-11-16 | 2017-05-18 | Facebook, Inc. | Ranking and Filtering Comments Based on Impression Calculations |
JP2017211876A (en) * | 2016-05-26 | 2017-11-30 | 京セラドキュメントソリューションズ株式会社 | Display device and display control program |
US20170371522A1 (en) * | 2016-06-23 | 2017-12-28 | Microsoft Technology Licensing, Llc | Suppression of input images |
US20180047195A1 (en) * | 2016-08-09 | 2018-02-15 | Pegge Vissicaro | Keyboard with in-line user created emojis |
US20180053101A1 (en) * | 2016-08-17 | 2018-02-22 | Microsoft Technology Licensing, Llc | Remote and local predictions |
CN108205376A (en) * | 2016-12-19 | 2018-06-26 | 谷歌有限责任公司 | It is predicted for the legend of dialogue |
Also Published As
Publication number | Publication date |
---|---|
EP3827331A1 (en) | 2021-06-02 |
KR20230007528A (en) | 2023-01-12 |
US20210326037A1 (en) | 2021-10-21 |
KR20210043669A (en) | 2021-04-21 |
JP7206370B2 (en) | 2023-01-17 |
KR102634375B1 (en) | 2024-02-06 |
JP2021535498A (en) | 2021-12-16 |
KR102481910B1 (en) | 2022-12-27 |
WO2020046637A1 (en) | 2020-03-05 |
KR20240017141A (en) | 2024-02-06 |
US11740787B2 (en) | 2023-08-29 |
JP2023052127A (en) | 2023-04-11 |
US20230359353A1 (en) | 2023-11-09 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
EP2987164B1 (en) | Virtual assistant focused user interfaces | |
US8601381B2 (en) | Rich customizable user online environment | |
US20230359353A1 (en) | Methods and Systems for Positioning Animated Images Within a Dynamic Keyboard Interface | |
WO2017083218A1 (en) | Smart card presentation of tabular data from collaboration database | |
CN116034385A (en) | Animated visual cues indicating availability of associated content | |
US20240143166A1 (en) | Methods and Systems for Positioning Animated Images Within a Dynamic Keyboard Interface | |
US11543962B2 (en) | Methods and systems for generating animated images for presentation by a dynamic keyboard interface | |
CN105183292A (en) | Method and system for displaying picture | |
US20230321538A1 (en) | Interactive puzzle |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |