JP6817431B2 - Neural architecture search - Google Patents
Neural architecture search Download PDFInfo
- Publication number
- JP6817431B2 JP6817431B2 JP2019522868A JP2019522868A JP6817431B2 JP 6817431 B2 JP6817431 B2 JP 6817431B2 JP 2019522868 A JP2019522868 A JP 2019522868A JP 2019522868 A JP2019522868 A JP 2019522868A JP 6817431 B2 JP6817431 B2 JP 6817431B2
- Authority
- JP
- Japan
- Prior art keywords
- neural network
- output
- layer
- controller
- child
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
- 230000001537 neural effect Effects 0.000 title claims description 10
- 238000013528 artificial neural network Methods 0.000 claims description 177
- 238000000034 method Methods 0.000 claims description 57
- 238000012549 training Methods 0.000 claims description 42
- 230000000306 recurrent effect Effects 0.000 claims description 30
- 230000008569 process Effects 0.000 claims description 17
- 230000006870 function Effects 0.000 claims description 16
- 230000015654 memory Effects 0.000 claims description 16
- 230000004913 activation Effects 0.000 claims description 11
- 238000012545 processing Methods 0.000 claims description 10
- 238000013527 convolutional neural network Methods 0.000 claims description 7
- 238000004364 calculation method Methods 0.000 claims description 5
- 230000002787 reinforcement Effects 0.000 claims description 5
- 238000005070 sampling Methods 0.000 claims description 2
- 230000009471 action Effects 0.000 description 16
- 238000004590 computer program Methods 0.000 description 14
- 238000010200 validation analysis Methods 0.000 description 9
- 238000004891 communication Methods 0.000 description 6
- 238000010801 machine learning Methods 0.000 description 6
- 230000010076 replication Effects 0.000 description 4
- 238000010586 diagram Methods 0.000 description 3
- 230000003993 interaction Effects 0.000 description 3
- 238000010606 normalization Methods 0.000 description 3
- 238000012795 verification Methods 0.000 description 3
- 238000002347 injection Methods 0.000 description 2
- 239000007924 injection Substances 0.000 description 2
- 230000003287 optical effect Effects 0.000 description 2
- 230000004044 response Effects 0.000 description 2
- 238000013515 script Methods 0.000 description 2
- 238000000926 separation method Methods 0.000 description 2
- 241000009334 Singa Species 0.000 description 1
- 238000003491 array Methods 0.000 description 1
- 230000006399 behavior Effects 0.000 description 1
- 230000005540 biological transmission Effects 0.000 description 1
- 238000006243 chemical reaction Methods 0.000 description 1
- 230000001149 cognitive effect Effects 0.000 description 1
- 238000011156 evaluation Methods 0.000 description 1
- 239000004973 liquid crystal related substance Substances 0.000 description 1
- 239000000203 mixture Substances 0.000 description 1
- 230000004048 modification Effects 0.000 description 1
- 238000012986 modification Methods 0.000 description 1
- 238000005457 optimization Methods 0.000 description 1
- 238000011176 pooling Methods 0.000 description 1
- 230000001902 propagating effect Effects 0.000 description 1
- 239000004065 semiconductor Substances 0.000 description 1
- 230000001953 sensory effect Effects 0.000 description 1
- 230000006403 short-term memory Effects 0.000 description 1
- 238000012546 transfer Methods 0.000 description 1
- 230000000007 visual effect Effects 0.000 description 1
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/082—Learning methods modifying the architecture, e.g. adding, deleting or silencing nodes or connections
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F18/00—Pattern recognition
- G06F18/20—Analysing
- G06F18/21—Design or setup of recognition systems or techniques; Extraction of features in feature space; Blind source separation
- G06F18/217—Validation; Performance evaluation; Active pattern learning techniques
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/044—Recurrent networks, e.g. Hopfield networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/045—Combinations of networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
Description
本明細書は、ニューラルネットワークアーキテクチャの修正に関する。 This specification relates to a modification of the neural network architecture.
ニューラルネットワークは、非線形ユニットの1つまたは複数の層を使用して、受信された入力の出力を予測する機械学習モデルである。いくつかのニューラルネットワークは、出力層に加えて、1つまたは複数の隠れ層を含む。各隠れ層の出力は、ネットワーク内の次の層、すなわち次の隠れ層または出力層への入力として使用される。ネットワークの各層は、パラメータのそれぞれのセットの現在値に従って受信された入力から出力を生成する。 A neural network is a machine learning model that uses one or more layers of nonlinear units to predict the output of a received input. Some neural networks include one or more hidden layers in addition to the output layer. The output of each hidden layer is used as an input to the next layer in the network, the next hidden layer or output layer. Each layer of the network produces an output from the input received according to the current value of each set of parameters.
いくつかのニューラルネットワークは、リカレントニューラルネットワークである。リカレントニューラルネットワークは、入力シーケンスを受信し、その入力シーケンスから出力シーケンスを生成するニューラルネットワークである。特に、リカレントニューラルネットワークは、現在の時間ステップにおける出力を計算する際に、前の時間ステップからのネットワークの内部状態の一部または全部を使用することができる。リカレントニューラルネットワークの一例は、1つまたは複数のLSTMメモリブロックを含むロングショートターム(LSTM)ニューラルネットワークである。各LSTMメモリブロックは、たとえば現在のアクティブ化を生成する際に使用するために、またはLSTMニューラルネットワークの他の構成要素に提供されるように、セルがセルの以前の状態を記憶することを可能にする入力ゲート、忘却ゲート、および出力ゲートを各々含む1つまたは複数のセルを含むことができる。 Some neural networks are recurrent neural networks. A recurrent neural network is a neural network that receives an input sequence and generates an output sequence from the input sequence. In particular, the recurrent neural network can use some or all of the internal state of the network from the previous time step when calculating the output at the current time step. An example of a recurrent neural network is a long short term (LSTM) neural network that contains one or more LSTM memory blocks. Each LSTM memory block allows a cell to store the previous state of the cell, for example to be used when generating the current activation, or as provided to other components of the LSTM neural network. Can contain one or more cells, each containing an input gate, an oblivion gate, and an output gate.
本明細書は、コントローラニューラルネットワークを使用して、特定のニューラルネットワークタスクを実行するように構成される子ニューラルネットワークのアーキテクチャを、1つまたは複数の場所における1つまたは複数のコンピュータ上のコンピュータプログラムとして実装されるシステムがどのように決定できるかを説明する。 This specification uses a controller neural network to implement the architecture of a child neural network configured to perform a particular neural network task, a computer program on one or more computers in one or more locations. Explain how the system implemented as can be determined.
本明細書に記載される主題の特定の実施形態は、以下の利点のうちの1つまたは複数を実現するように実施することができる。システムは、効果的かつ自動的に、すなわちユーザ介入なしに、特定のタスクについて高性能のニューラルネットワークをもたらすことになるニューラルネットワークアーキテクチャを選択することができる。システムは、特定のタスクに適合する新規のニューラルネットワークアーキテクチャを効果的に決定することができ、結果として得られる子ニューラルネットワークがそのタスクに関して改善された性能を有することを可能にする。システムは、強化学習を介してコントローラニューラルネットワークをトレーニングすることによってアーキテクチャを決定するので、システムは、特定のタスクに適合する子ニューラルネットワークのアーキテクチャを識別するために、大空間の可能なアーキテクチャを効果的に探索することができる。 Certain embodiments of the subject matter described herein can be implemented to achieve one or more of the following advantages: The system can choose a neural network architecture that will result in a high performance neural network for a particular task effectively and automatically, ie without user intervention. The system can effectively determine a new neural network architecture that fits a particular task, allowing the resulting child neural network to have improved performance for that task. Since the system determines the architecture by training the controller neural network through reinforcement learning, the system is effective in large space possible architecture to identify the architecture of the child neural network that fits the particular task. Can be searched for.
本明細書に記載の主題の1つまたは複数の実施形態の詳細は、添付の図面および以下の説明に記載されている。主題の他の特徴、態様、および利点は、説明、図面、および特許請求の範囲から明らかになるであろう。 Details of one or more embodiments of the subject matter described herein are described in the accompanying drawings and the following description. Other features, aspects, and advantages of the subject matter will become apparent from the description, drawings, and claims.
様々な図面における同様の参照番号および名称は、同様の要素を示す。 Similar reference numbers and names in various drawings indicate similar elements.
本明細書は、コントローラニューラルネットワークを使用して、特定のニューラルネットワークタスクを実行するように構成される子ニューラルネットワークのアーキテクチャを決定する、1つまたは複数の場所における1つまたは複数のコンピュータ上のコンピュータプログラムとして実装されるシステムを記載する。 The present specification uses a controller neural network to determine the architecture of a child neural network that is configured to perform a particular neural network task, on one or more computers in one or more locations. Describe the system implemented as a computer program.
子ニューラルネットワークは、任意の種類のデジタルデータ入力を受信し、その入力に基づいて、任意の種類のスコア、分類、または回帰出力を生成するように構成することができる。 The child neural network can be configured to receive any type of digital data input and generate any type of score, classification, or regression output based on that input.
たとえば、子ニューラルネットワークへの入力が、画像、または画像から抽出された特徴である場合、所与の画像について子ニューラルネットワークによって生成された出力は、オブジェクトカテゴリのセットの各々についてのスコアでもよく、各スコアは、画像がカテゴリに属するオブジェクトの画像を含む推定尤度を表す。 For example, if the input to the child neural network is an image, or a feature extracted from the image, the output produced by the child neural network for a given image may be a score for each of the set of object categories. Each score represents an estimated likelihood that the image contains an image of an object that belongs to the category.
別の例として、子ニューラルネットワークへの入力がインターネットリソース(たとえばウェブページ)、ドキュメント、またはドキュメントの一部、あるいはインターネットリソース、ドキュメント、またはドキュメントの一部から抽出された特徴である場合、所与のインターネットリソース、ドキュメント、またはドキュメントの一部について、子ニューラルネットワークによって生成された出力は、トピックのセットの各々についてのスコアでもよく、各スコアは、インターネットリソース、ドキュメント、またはドキュメントの一部がトピックに関するものである推定尤度を表す。 As another example, given if the input to the child neural network is a feature extracted from an internet resource (eg, a web page), a document, or part of a document, or an internet resource, document, or part of a document. For an internet resource, document, or part of a document, the output generated by the child neural network may be a score for each of the set of topics, where each score is a topic for the internet resource, document, or part of the document. Represents the estimated likelihood of being related to.
別の例として、子ニューラルネットワークへの入力が特定の広告についての印象コンテキストの特徴である場合、子ニューラルネットワークによって生成された出力は、その特定の広告がクリックされる推定尤度を表すスコアでもよい。 As another example, if the input to the child neural network is characteristic of the impression context for a particular ad, the output generated by the child neural network will also be a score representing the estimated likelihood that the particular ad will be clicked. Good.
別の例として、子ニューラルネットワークへの入力が、あるユーザのためにパーソナライズされた推奨の特徴、たとえばその推奨のコンテキストを特徴付ける特徴、たとえばユーザによってとられた以前のアクションを特徴付ける特徴である場合、子ニューラルネットワークによって生成された出力は、コンテンツアイテムのセットの各々についてのスコアでもよく、各スコアは、ユーザがコンテンツアイテムを勧められることに好意的に応答する推定尤度を表す。 As another example, if the input to the child neural network is a feature that is personalized for a user, eg, a feature that characterizes the context of that recommendation, eg, a feature that characterizes a previous action taken by the user. The output generated by the child neural network may be a score for each of the set of content items, each score representing an estimated likelihood of the user responding favorably to the content item being recommended.
別の例として、子ニューラルネットワークへの入力が1つの言語のテキストのシーケンスである場合、子ニューラルネットワークによって生成された出力は、別の言語のテキストのセットの各々についてのスコアでもよく、各スコアは、他の言語のテキストが他の言語への入力テキストの適切な変換であるという推定尤度を表す。 As another example, if the input to the child neural network is a sequence of text in one language, the output generated by the child neural network may be a score for each of the sets of text in another language, each score. Represents the estimated likelihood that text in another language is a proper conversion of input text to another language.
別の例として、子ニューラルネットワークへの入力が話し言葉を表すシーケンスである場合、子ニューラルネットワークによって生成された出力は、テキストのセットの各々についてのスコアでもよく、各スコアは、テキストが発話の正確な転写である推定尤度を表す。 As another example, if the input to the child neural network is a sequence that represents spoken language, the output produced by the child neural network may be a score for each of the set of texts, where each score is the exact text spoken. Represents the estimated likelihood of a neural network.
図1は、例示的なニューラルアーキテクチャ検索システム100を示す。ニューラルアーキテクチャ検索システム100は、以下に説明するシステム、構成要素、および技法を実装することができる1つまたは複数の場所における1つまたは複数のコンピュータ上のコンピュータプログラムとして実装されるシステムの一例である。 FIG. 1 shows an exemplary neural architecture search system 100. The Neural Architecture Search System 100 is an example of a system implemented as a computer program on one or more computers in one or more locations where the systems, components, and techniques described below can be implemented. ..
ニューラルアーキテクチャ検索システム100は、特定のタスクを実行するようにニューラルネットワークをトレーニングするためのトレーニングデータ102と、特定のタスクにおけるニューラルネットワークの性能を評価するための検証セット104とを取得し、トレーニングデータ102および検証セット104を使用して、特定のタスクを実行するように構成される子ニューラルネットワークのアーキテクチャを決定するシステムである。アーキテクチャは、子ニューラルネットワーク内の層の数、層の各々によって実行される動作、および子ニューラルネットワーク内の層間の接続、すなわちどの層が子ニューラルネットワーク内の他のどの層から入力を受信するかを定義する。 The neural architecture search system 100 acquires training data 102 for training a neural network to perform a specific task and a verification set 104 for evaluating the performance of the neural network in a specific task, and obtains training data. A system that uses 102 and validation set 104 to determine the architecture of a child neural network that is configured to perform a particular task. The architecture is the number of layers in the child neural network, the actions performed by each layer, and the connections between the layers in the child neural network, that is, which layer receives input from which other layers in the child neural network. To define.
一般に、トレーニングデータ102と検証セット104はいずれも、ニューラルネットワーク入力のセットと、各ネットワーク入力について、特定のタスクを実行するために子ニューラルネットワークによって生成されるべきそれぞれのターゲット出力とを含む。たとえば、トレーニングデータ102および検証セット104を生成するために、トレーニングデータのより大きいセットがランダムに区分されてもよい。 In general, both the training data 102 and the validation set 104 include a set of neural network inputs and, for each network input, their respective target outputs that should be generated by the child neural network to perform a particular task. For example, a larger set of training data may be randomly partitioned to generate training data 102 and validation set 104.
システム100は、様々な方法のうちのいずれかでトレーニングデータ102および検証セット104を受信することができる。たとえば、システム100は、たとえばシステム100によって利用可能にされるアプリケーションプログラミングインターフェース(API)を使用して、データ通信ネットワークを介してシステムの遠隔ユーザからアップロードとしてトレーニングデータを受信し、アップロードされたデータをトレーニングデータ102および検証セット104にランダムに分割することができる。別の例として、システム100は、システム100によってすでに維持されているどのデータを、ニューラルネットワークをトレーニングするために使用すべきかを指定するユーザからの入力を受信し、次いで指定されたデータをトレーニングデータ102および検証セット104に分割することができる。 System 100 can receive training data 102 and validation set 104 in any of a variety of ways. For example, system 100 receives training data as an upload from a remote user of the system over a data communication network, using, for example, the application programming interface (API) made available by system 100, and receives the uploaded data. It can be randomly divided into training data 102 and validation set 104. As another example, system 100 receives input from the user specifying which data already maintained by system 100 should be used to train the neural network, and then trains the specified data. It can be divided into 102 and verification set 104.
ニューラルアーキテクチャ検索システム100は、コントローラニューラルネットワーク110、トレーニングエンジン120、およびコントローラパラメータ更新エンジン130を含む。
The neural architecture search system 100 includes a controller
コントローラニューラルネットワーク110は、本明細書では「コントローラパラメータ」と呼ばれるパラメータを有し、コントローラパラメータに従って出力シーケンスを生成するように構成されるニューラルネットワークである。コントローラニューラルネットワーク110によって生成された各出力シーケンスは、子ニューラルネットワークのそれぞれの可能なアーキテクチャを定義する。
The controller
特に、各出力シーケンスは、複数の時間ステップの各々におけるそれぞれの出力を含み、出力シーケンスにおける各時間ステップは、子ニューラルネットワークのアーキテクチャの異なるハイパーパラメータに対応する。したがって、各出力シーケンスは、各時間ステップにおいて、対応するハイパーパラメータのそれぞれの値を含む。集合的に、所与の出力シーケンスにおけるハイパーパラメータの値は、子ニューラルネットワークのアーキテクチャを定義する。一般に、ハイパーパラメータは、子ニューラルネットワークのトレーニングの開始前に設定され、子ニューラルネットワークによって実行される動作に影響を与える値である。出力シーケンスおよび可能なハイパーパラメータは、図2A〜図2Cを参照して以下でより詳細に説明される。 In particular, each output sequence contains its own output at each of the plurality of time steps, and each time step in the output sequence corresponds to different hyperparameters of the child neural network architecture. Therefore, each output sequence contains the respective values of the corresponding hyperparameters at each time step. Collectively, the values of hyperparameters in a given output sequence define the architecture of the child neural network. In general, hyperparameters are values that are set before the start of training for the child neural network and affect the behavior performed by the child neural network. The output sequences and possible hyperparameters are described in more detail below with reference to FIGS. 2A-2C.
一般に、システム100は、コントローラパラメータの値を調整するようにコントローラニューラルネットワーク110をトレーニングすることによって、子ニューラルネットワークのアーキテクチャを決定する。
In general, the system 100 determines the architecture of the child neural network by training the controller
特に、トレーニング手順の反復中、システム100は、コントローラパラメータの現在値に従って、コントローラニューラルネットワーク110を使用して、シーケンスのバッチ112を生成する。バッチ112内の出力シーケンスごとに、トレーニングエンジン120は、トレーニングデータ102における出力シーケンスによって定義されたアーキテクチャを有する子ニューラルネットワークのインスタンスをトレーニングし、検証セット104におけるトレーニング済みインスタンスの性能を評価する。次いで、コントローラパラメータ更新エンジン130は、タスクにおいてコントローラニューラルネットワーク110によって生成された出力シーケンスによって定義されるアーキテクチャの予想性能を向上させるためにコントローラパラメータの現在値を更新するために、バッチ112内の出力シーケンスの評価の結果を使用する。トレーニング済みインスタンスの性能を評価し、コントローラパラメータの現在値を更新することは、図3を参照して以下でより詳細に説明される。
In particular, during the iteration of the training procedure, the system 100 uses the controller
このようにしてコントローラパラメータの値を繰り返し更新することによって、システム100は、特定のタスクにおいて性能が向上した子ニューラルネットワークをもたらす出力シーケンスを生成するように、すなわちコントローラニューラルネットワーク110によって提案されたアーキテクチャの検証セット104における予想精度を最大にするようにコントローラニューラルネットワーク110をトレーニングすることができる。
By repeatedly updating the values of the controller parameters in this way, the system 100 is to generate an output sequence that results in a child neural network with improved performance in a particular task, i.e. the architecture proposed by the controller
コントローラニューラルネットワーク110がトレーニングされると、システム100は、検証セット104において最良に機能したアーキテクチャを子ニューラルネットワークの最終アーキテクチャとして選択することができ、またはコントローラパラメータのトレーニング済みの値に従って新しい出力シーケンスを生成し、新しい出力シーケンスによって定義されたアーキテクチャを子ニューラルネットワークの最終アーキテクチャとして使用することができる。
When the controller
次いで、ニューラルネットワーク検索システム100は、子ニューラルネットワークのアーキテクチャを指定するアーキテクチャデータ150、すなわち子ニューラルネットワークの一部である層、層間の接続、および層によって実行される動作を指定するデータを出力することができる。たとえば、ニューラルネットワーク検索システム100は、アーキテクチャデータ150をトレーニングデータを提出したユーザに出力することができる。いくつかの場合には、データ150は、アーキテクチャを有していた子ニューラルネットワークのトレーニング済みインスタンスのトレーニングからの子ニューラルネットワークのパラメータのトレーニング済みの値も含む。 The neural network search system 100 then outputs architecture data 150 that specifies the architecture of the child neural network, that is, data that specifies the layers that are part of the child neural network, the connections between the layers, and the actions performed by the layers. be able to. For example, the neural network search system 100 can output the architecture data 150 to the user who submitted the training data. In some cases, the data 150 also includes trained values of the child neural network parameters from the training of the trained instance of the child neural network that had the architecture.
いくつかの実装形態では、アーキテクチャデータ150を出力する代わりに、またはそれに加えて、システム100は、たとえば最初から、またはアーキテクチャを有する子ニューラルネットワークのインスタンスのトレーニングの結果として生成されたパラメータ値を微調整するために、決定されたアーキテクチャを有するニューラルネットワークのインスタンスをトレーニングし、次いでトレーニングされたニューラルネットワークを使用して、たとえばシステムによって提供されるAPIを介して、ユーザによって受信された要求を処理する。すなわち、システム100は、処理されるべき入力を受信し、トレーニングされた子ニューラルネットワークを使用して入力を処理し、受信された入力に応答して、トレーニングされたニューラルネットワークによって生成された出力、または生成された出力から導出されたデータを提供することができる。 In some implementations, instead of or in addition to outputting the architecture data 150, the system 100 subtles the parameter values generated, for example, from the beginning or as a result of training an instance of a child neural network with the architecture. To tune, train an instance of a neural network with a determined architecture, then use the trained neural network to process requests received by the user, for example via an API provided by the system. .. That is, system 100 receives the input to be processed, processes the input using the trained child neural network, and responds to the received input with the output produced by the trained neural network. Alternatively, data derived from the generated output can be provided.
いくつかの実装形態では、システム100は、分散的な方法でコントローラニューラルネットワークをトレーニングする。すなわち、システム100は、コントローラニューラルネットワークの複数の複製を含む。トレーニングが分散されるこれらの実装形態のいくつかにおいて、各複製は、複製によって出力された出力シーケンスのバッチについての性能メトリックを生成する専用トレーニングエンジンと、性能メトリックを使用してコントローラパラメータに対する更新を決定する専用コントローラパラメータ更新エンジンとを有する。コントローラパラメータ更新エンジンがひとたび更新を決定すると、コントローラパラメータ更新エンジンは、その更新をすべてのコントローラパラメータ更新エンジンにアクセス可能な中央パラメータ更新サーバに送信することができる。中央パラメータ更新サーバは、サーバによって維持されるコントローラパラメータの値を更新し、更新された値をコントローラパラメータ更新エンジンに送信することができる。いくつかの場合には、複数の複製の各々、ならびにそれらの対応するトレーニングエンジンおよびパラメータ更新エンジンは、トレーニングエンジンおよびパラメータ更新エンジンの他の各セットとは非同期に動作することができる。 In some implementations, System 100 trains controller neural networks in a decentralized manner. That is, system 100 includes multiple replicas of the controller neural network. In some of these training-distributed implementations, each replica uses a dedicated training engine to generate performance metrics for a batch of output sequences output by the replica, and updates to controller parameters using performance metrics. It has a dedicated controller parameter update engine to determine. Once the controller parameter update engine decides to update, the controller parameter update engine can send the update to a central parameter update server that has access to all controller parameter update engines. The central parameter update server can update the values of the controller parameters maintained by the server and send the updated values to the controller parameter update engine. In some cases, each of the multiple replicas, as well as their corresponding training engine and parameter update engine, can operate asynchronously with each other set of training engine and parameter update engine.
図2Aは、出力シーケンスを生成するコントローラニューラルネットワーク110の一例の図200である。
FIG. 2A is FIG. 200, which is an example of a controller
特に、図200は、出力シーケンスの生成中、7つの例示的な時間ステップ202〜214の間にコントローラニューラルネットワーク110によって実行される処理を示す。以下でより詳細に説明されるように、7つの時間ステップ202〜214の各々は、ニューラルネットワークアーキテクチャの異なるハイパーパラメータに対応する。
In particular, FIG. 200 shows the processing performed by the controller
コントローラニューラルネットワーク110は、各時間ステップについて、所与の出力シーケンスにおいて前の時間ステップに対応するハイパーパラメータの値を入力として受信し、リカレントニューラルネットワークの現在の隠れ状態を更新するように入力を処理するように構成される、1つまたは複数のリカレントニューラルネットワーク層、たとえば層220および230を含むリカレントニューラルネットワークである。たとえば、コントローラニューラルネットワーク110内のリカレント層は、長短期記憶(LSTM)層またはゲート型リカレントユニット(GRU)層とすることができる。図2Aの例では、時間ステップ208において、層220および230は、前の時間ステップ206からハイパーパラメータの値を入力として受信し、時間ステップ206から層220および230の隠れ状態を更新して、更新された隠れ状態232を出力として生成する。
For each time step, the controller
コントローラニューラルネットワーク110はまた、出力シーケンスにおける時間ステップごとのそれぞれの出力層、たとえばそれぞれ時間ステップ202〜214の出力層242〜254を含む。出力層の各々は、時間ステップで更新された隠れ状態を含む出力層入力を受信し、時間ステップにおけるハイパーパラメータの可能な値にわたるスコア分布を定義する時間ステップの出力を生成するように構成される。たとえば、各出力層は、まず出力層入力を対応するハイパーパラメータの可能な値の数に適切な寸法に投影し、次いで投影された出力層入力にソフトマックスを適用して、時間ステップでのハイパーパラメータの複数の可能な値の各々についてそれぞれのスコアを生成することができる。たとえば、時間ステップ208の出力層248は、隠れ状態232を含む入力を受信し、ストライド高さハイパーパラメータの複数の可能な値の各々についてそれぞれのスコアを生成するように構成される。
The controller
したがって、出力シーケンス内の所与の時間ステップについてのハイパーパラメータ値を生成するために、システム100は、出力シーケンス内の前の時間ステップにおけるハイパーパラメータの値をコントローラニューラルネットワークへの入力として提供し、コントローラニューラルネットワークは、時間ステップでのハイパーパラメータの可能な値にわたるスコア分布を定義する時間ステップの出力を生成する。出力シーケンスにおける最初の時間ステップでは、前の時間ステップがないので、システム100は、代わりに所定のプレースホルダー入力を提供することができる。次いで、システム100は、出力シーケンス内の時間ステップにおけるハイパーパラメータの値を決定するために、スコア分布に従って、可能な値からサンプリングする。所与のハイパーパラメータがとり得る可能な値は、トレーニングの前に固定されており、可能な値の数は、異なるハイパーパラメータごとに異なる可能性がある。 Therefore, in order to generate hyperparameter values for a given time step in the output sequence, system 100 provides the hyperparameter values for the previous time step in the output sequence as inputs to the controller neural network. The controller neural network produces the output of the time step that defines the score distribution over the possible values of the hyperparameters in the time step. Since there is no previous time step in the first time step in the output sequence, the system 100 can provide a given placeholder input instead. System 100 then samples from possible values according to the score distribution to determine the values of hyperparameters at the time steps in the output sequence. The possible values that a given hyperparameter can take are fixed prior to training, and the number of possible values can vary for different hyperparameters.
一般に、所与の出力シーケンスによって定義されるアーキテクチャに含まれるべき層の数は、シーケンスを生成する前に固定されている。いくつかの実装形態では、コントローラニューラルネットワークのトレーニング中に生成された出力シーケンスによって定義された各アーキテクチャは同じ数の層を有する。他の実装形態では、システムは、トレーニングが進行するにつれて子ニューラルネットワーク内の層の数を増やすスケジュールを使用する。一例として、システムは、6層から始めて、トレーニング中に、1,600サンプルごとに1つまたは複数の層だけ深さを増すことができる。 In general, the number of layers that should be included in an architecture defined by a given output sequence is fixed before the sequence is generated. In some implementations, each architecture defined by the output sequence generated during training of the controller neural network has the same number of layers. In other implementations, the system uses a schedule that increases the number of layers in the child neural network as training progresses. As an example, the system can start with 6 layers and increase the depth by one or more layers for every 1,600 samples during training.
図2Aの例では、子ニューラルネットワークは、畳み込みニューラルネットワークであり、ハイパーパラメータは、子ニューラルネットワーク内の各畳み込みニューラルネットワーク層のハイパーパラメータを含む。特に、図2Aでは、時間ステップ202は、子ニューラルネットワークの畳み込み層N-1のハイパーパラメータに対応し、時間ステップ204〜212は、畳み込み層Nのハイパーパラメータに対応し、時間ステップ214は、畳み込み層N+1のハイパーパラメータに対応する。たとえば、畳み込み層は、スタック状に配置されてもよく、層Nが層N-1によって生成された出力を入力として受信し、層N+1への入力として提供される出力を生成する。
In the example of FIG. 2A, the child neural network is a convolutional neural network, and the hyperparameters include hyperparameters of each convolutional neural network layer in the child neural network. In particular, in FIG. 2A,
図2Aの例では、畳み込み層の場合、層によって実行される動作を定義するハイパーパラメータは、層のフィルタの数、フィルタごとのフィルタ高さ、フィルタごとのフィルタ幅、各フィルタを適用するためのストライド高さ、およびフィルタごとのストライド幅である。他の例では、これらのうちのいくつかを除去することができ、たとえばこれらのハイパーパラメータのうちのいくつかが固定されていると仮定することができ、他のハイパーパラメータ、たとえばアクティブ化関数のタイプ、畳み込みが拡張またはマスクされるかどうかなどを追加することができ、またはその両方とすることができる。 In the example of Figure 2A, for a convolutional layer, the hyperparameters that define the action performed by the layer are the number of filters in the layer, the filter height per filter, the filter width per filter, and for applying each filter. Stride height and stride width for each filter. In other examples, some of these can be removed, for example it can be assumed that some of these hyperparameters are fixed, for other hyperparameters, for example the activation function. You can add types, whether convolutions are expanded and masked, etc., or both.
例示的な一実装形態では、フィルタ高さの可能な値は[1、3、5、7]、フィルタ幅の可能な値は[1、3、5、7]、フィルタの数の可能な値は[24、36、48、64]、およびストライド高さと幅の可能な値は[1、2、3]である。 In one exemplary implementation, the possible values for filter height are [1, 3, 5, 7], the possible values for filter width are [1, 3, 5, 7], and the possible values for the number of filters. Is [24, 36, 48, 64], and possible values for stride height and width are [1, 2, 3].
図2Aの例では、子ニューラルネットワーク内の層の構成、すなわちどの層が他のどの層から層を受信するかは固定されている。しかしながら、他の例では、ハイパーパラメータは、子ニューラルネットワーク内の層間の接続を定義するハイパーパラメータを含む。 In the example of FIG. 2A, the composition of the layers in the child neural network, that is, which layer receives the layer from which other layer, is fixed. However, in other examples, hyperparameters include hyperparameters that define the connections between layers within the child neural network.
図2Bは、スキップ接続を含むアーキテクチャを定義する出力シーケンスを生成するコントローラニューラルネットワーク110の一例の図250である。
FIG. 2B is FIG. 250, which is an example of a controller
特に、図2Bの例では、子ニューラルネットワーク内の1つまたは複数の層について、ハイパーパラメータは、どの以前の層がその層へのスキップ接続を有するかを定義するスキップ接続ハイパーパラメータを含む。より具体的には、出力シーケンス内の時間ステップは、たとえば層N-1の時間ステップ252および層Nの時間ステップ254などのハイパーパラメータがスキップ接続ハイパーパラメータである1つまたは複数の層の各々についてのそれぞれのアンカーポイント時間ステップを含む。
In particular, in the example of Figure 2B, for one or more layers in the child neural network, the hyperparameters include skip connection hyperparameters that define which previous layer has a skip connection to that layer. More specifically, the time steps in the output sequence are for each of one or more layers where the hyperparameters such as
所与の層についての所与のアンカーポイント時間ステップの出力層は、子ニューラルネットワーク内の現在の層よりも前の各層に対応するそれぞれのノードを含む。ノードの各々は、対応する以前の層が子ニューラルネットワーク内の現在の層に接続される尤度を表すスコアを生成するためのパラメータのセットに従って、(i)アンカーポイントステップについての更新された隠れ状態、および(ii)対応する以前の層、すなわちノードに対応する以前の層のアンカーポイント時間ステップについての更新された隠れ状態を処理するように構成される。たとえば、以前の層jに対応する層iの出力層内のノードは、以下を満たす、対応する以前の層のスコアを生成することができる。
P(層jは層iへの入力)=sigmoid(vTtanh(Wprev*hj+Wcurr*hi))
ここで、vT、Wprev、およびWcurrは、ノードのパラメータであり、hjは対応する以前の層jについてのアンカーポイント時間ステップの更新された隠れ状態であり、hiは層iについてのアンカーポイント時間ステップの更新された隠れ状態である。
The output layer of a given anchor point time step for a given layer contains each node corresponding to each layer prior to the current layer in the child neural network. Each of the nodes follows an updated hiding about (i) anchor point steps according to a set of parameters to generate a score representing the likelihood that the corresponding previous layer will be connected to the current layer in the child neural network. It is configured to handle the state, and (ii) the updated hidden state for the anchor point time step of the corresponding previous layer, i.e. the previous layer corresponding to the node. For example, a node in the output layer of layer i corresponding to previous layer j can generate a score for the corresponding previous layer that satisfies:
P (layer j is the input to layer i) = sigmoid (v T tanh (v prev * h j + W curr * h i ))
Where v T , W prev , and W curr are the parameters of the node, h j is the updated hidden state of the anchor point time step for the corresponding previous layer j, and h i is for layer i. An updated hidden state of the anchor point time step of.
次いで、システム100は、以前の層に対応するノードによって生成されたスコアに従って、yesまたはnoのいずれかをサンプリングすることによって、その層がスキップ接続を有する所与の層に接続されるかどうかを判定する。システムが、複数の層が所与の層に接続されるべきであると決定した場合、すべての複数の層によって生成された出力は、所与の層への入力を生成するために深さ寸法で連結される。ある層が別の層と互換性がない場合、スキップ接続が「コンパイル失敗」を引き起こさないこと、およびネットワークが、いかなる入力または出力も有さないいかなる層も含まないことを確実にするために、(i)層が任意のいかなる入力層にも接続されていない場合、ネットワーク入力がその層への入力として使用され、(ii)最後の層では、システムは、未接続のすべての層出力を取り出し、それらを連結してから、最終的な連結された出力をネットワークの出力層に送信し、(iii)連結されるべき入力が異なるサイズを有する場合、システムは、連結されるべき入力が同じサイズを有するように、小さい層をゼロでパディングする。 System 100 then determines whether that layer is connected to a given layer with skip connections by sampling either yes or no according to the score generated by the node corresponding to the previous layer. judge. If the system determines that multiple layers should be connected to a given layer, the output produced by all the multiple layers is a depth dimension to generate an input to the given layer. It is connected by. To ensure that skip connections do not cause "compile failures" if one layer is incompatible with another, and that the network does not contain any layers that have no inputs or outputs. If (i) the layer is not connected to any input layer, the network input will be used as the input to that layer, and (ii) in the last layer, the system will take out all unconnected layer outputs. , Then concatenate them and then send the final concatenated output to the output layer of the network, (iii) if the inputs to be concatenated have different sizes, the system will have the same size of inputs to be concatenated. Pad the small layer at zero to have.
いくつかの例では、子ニューラルネットワークは、複数の異なる層タイプを含む。たとえば、子ニューラルネットワークは、他の種類のニューラルネットワーク層、たとえば完全に接続された層、プーリング層、深度連結層、局所コントラスト正規化、バッチ正規化、出力層、たとえばソフトマックス層または他の分類子層などをも含む畳み込みニューラルネットワークとすることができる。 In some examples, the child neural network contains several different layer types. For example, child neural networks can be other types of neural network layers, such as fully connected layers, pooling layers, depth convolutional layers, local contrast normalization, batch regularization, output layers, such as softmax layers or other classifications. It can be a convolutional neural network that also includes child layers and the like.
これらの例のいくつかにおいて、これらの他の層の位置およびハイパーパラメータは固定されており、出力シーケンスは、子ニューラルネットワーク内の畳み込みニューラルネットワーク層についてのハイパーパラメータ値のみを含む。たとえば、出力層の位置は、子ニューラルネットワーク内の最後の層として固定されていてもよく、畳み込み層のいくつかまたはすべての後にバッチ正規化層があってもよく、またはその前にバッチ正規化層があってもよい。 In some of these examples, the positions and hyperparameters of these other layers are fixed and the output sequence contains only the hyperparameter values for the convolutional neural network layer within the child neural network. For example, the position of the output layer may be fixed as the last layer in the child neural network, there may be a batch normalization layer after some or all of the convolutional layers, or batch normalization before it. There may be layers.
これらの例のうちの他の例では、出力シーケンスによって定義されるハイパーパラメータは、層ごとに層のタイプに対応する値を含む。異なるタイプの層は異なるハイパーパラメータを有するので、これらの例では、システムは、所与の層について、どのタイプのニューラルネットワーク層が選択されるかに基づいて、出力シーケンスの生成中に、どのハイパーパラメータがどの時間ステップに動的に対応するかを決定する。つまり、システムが所与の時間ステップでの出力層として使用する出力層は、最後にサンプリングされた層タイプのハイパーパラメータの値によって決まる。 In other examples of these examples, the hyperparameters defined by the output sequence contain values corresponding to the layer type for each layer. Since different types of layers have different hyperparameters, in these examples, for a given layer, which hyper is during the generation of the output sequence, based on which type of neural network layer is selected. Determines which time step the parameter dynamically corresponds to. That is, the output layer that the system uses as the output layer at a given time step depends on the value of the hyperparameter of the last sampled layer type.
いくつかの例では、子ニューラルネットワークは、リカレントニューラルネットワークである。これらの場合、出力シーケンスは、リカレントセルのアーキテクチャを定義することができ、リカレントセルは、ニューラルネットワークのアーキテクチャを生成するために、子ニューラルネットワーク内で複数回繰り返されることが可能である。上記で説明したように、いくつかの場合には、反復数は、トレーニングを通じて固定され、他の場合には、システムは、トレーニングが進行するにつれて反復数を増加させる。 In some examples, the child neural network is a recurrent neural network. In these cases, the output sequence can define the architecture of the recurrent cell, and the recurrent cell can be repeated multiple times within the child neural network to generate the architecture of the neural network. As explained above, in some cases the number of iterations is fixed throughout the training and in other cases the system increases the number of iterations as the training progresses.
図2Cは、リカレントセルのアーキテクチャを定義する出力シーケンスを生成するコントローラニューラルネットワーク110の一例の図270である。
FIG. 2C is FIG. 270, which is an example of a controller
特に、図2Cの例では、出力シーケンスは、リカレントセルによって実行される計算を表す計算ステップのツリー内のノードごとのそれぞれの計算ステップを含む。リカレントセルは、2つの入力、前の時間ステップからのセルの出力と現在の時間ステップについての入力、すなわちその時間ステップにおける子ネットワークへの入力、または子ネットワークの別の構成要素によって生成された出力を受信する。リカレントセルは、セル出力を生成するようにこれら2つの入力を処理する。以下で説明するように、いくつかの場合には、リカレントセルはまた、第3の入力であるメモリ状態を受信する。 In particular, in the example of Figure 2C, the output sequence contains each node-by-node calculation step in the tree of calculation steps that represents the calculation performed by the recurrent cell. A recurrent cell is two inputs, the output of the cell from the previous time step and the input of the current time step, that is, the input to the child network at that time step, or the output generated by another component of the child network. To receive. The recurrent cell processes these two inputs to produce a cell output. In some cases, the recurrent cell also receives a third input, the memory state, as described below.
具体的には、図2Cの例では、出力シーケンスは、ツリーの3つのノード、すなわちツリーインデックス0における1つのリーフノード、ツリーインデックス1における別のリーフノード、およびツリーインデックス2における内部ノードの設定を定義する。
Specifically, in the example in Figure 2C, the output sequence sets the settings for three nodes in the tree: one leaf node at
ツリーにおける各ノードは、2つの入力をマージして出力を生成し、ノードごとに、出力シーケンスは、(i)2つの入力を組み合わせるための結合方法を識別するデータ、および(ii)出力を生成するために2つの入力の結合に適用されるべきアクティブ化関数を含む。一般に、セル内のリーフノードは、最初にセルへの2つの入力の各々にそれぞれのパラメータ行列を適用し、一方内部ノードはいかなるパラメータも有さない。上記で説明したように、結合方法は、たとえば[add; element wise multiply]などの可能な結合方法のセットから選択され、アクティブ化関数は、たとえば[identity; tanh; sigmoid; relu]などの可能なアクティブ化関数のセットから選択される。 Each node in the tree merges the two inputs to produce an output, and for each node, the output sequence produces (i) data that identifies the join method for combining the two inputs, and (ii) an output. Contains an activation function that should be applied to the combination of two inputs to do so. In general, leaf nodes in a cell first apply their respective parameter matrices to each of the two inputs to the cell, while internal nodes have no parameters. As described above, the join method is selected from a set of possible join methods, for example [add; element wise multiply], and the activation function is possible, for example [identity; tanh; sigmoid; relu]. Selected from a set of activation functions.
たとえば、ツリーインデックス0におけるリーフノードでは、システムは、結合関数として"add"を選択し、アクティブ化関数として"tanh"を選択したので、セルのツリーインデックス0におけるリーフノードは、以下の動作を実行して出力a0を生成してもよい。
a0=tanh(W1*xt+W2*ht-1)
ここで、W1およびW2はノードのパラメータ行列、xtは、時間ステップでのセルへの入力、およびht-1は前の時間ステップからのセルの出力である。
For example, for a leaf node at
a 0 = tanh (W 1 * x t + W 2 * h t-1 )
Where W 1 and W 2 are the parameter matrices of the node, x t is the input to the cell at the time step, and h t-1 is the output of the cell from the previous time step.
ツリーインデックス2におけるノードでは、セルがメモリ状態を有していないとき、図2Cの例は、ノードへの2つの入力、すなわち2つのリーフノードの出力が要素ごとに乗算され、要素ごとのシグモイド関数が要素ごとの乗算の出力に適用されて、内部ノードの出力、すなわちセルの出力を生成することを指定する。 For a node at tree index 2, when the cell has no memory state, the example in Figure 2C shows that the two inputs to the node, the outputs of the two leaf nodes, are multiplied element by element and the element by element sigmoid function. Is applied to the output of the element-by-element multiplication to produce the output of the internal node, that is, the output of the cell.
オプションで、セルのアーキテクチャは、前のメモリ状態を入力として受信することをも含んでもよい。このような場合、出力シーケンスはまた、セルのメモリ状態がどのようにセルにインジェクトされるか、すなわち前のメモリ状態がどのように更新されるか、およびツリー内の次のノードに渡される前に、前のメモリ状態を使用して変更される出力をどのノードが有するかを定義する値を含む。 Optionally, the cell architecture may also include receiving a previous memory state as input. In such cases, the output sequence is also passed to how the memory state of the cell is injected into the cell, that is, how the previous memory state is updated, and to the next node in the tree. Previously contains a value that defines which node has output that changes using the previous memory state.
特に、出力シーケンスはまた、ノードについての更新された出力を生成するために、前のメモリ状態がツリー内のノードのうちの1つの出力とどのように組み合わされるかを指定する2つのセルインジェクト値、すなわち結合方法、および結合のためのアクティブ化関数、ならびに(i)メモリ状態を使用して出力が更新されるノードと、(ii)(ノードについてのアクティブ化関数の適用前に)出力が更新されたメモリ状態に設定されるべきノードとを指定する2つのセルインデックス値を含む。 In particular, the output sequence is also two cell injections that specify how the previous memory state is combined with the output of one of the nodes in the tree to produce updated output for the node. The values, the join method, the activation function for the join, and (i) the node whose output is updated using the memory state, and (ii) the output (before applying the activation function for the node). Contains two cell index values that specify which node should be set to the updated memory state.
図2Cの例では、第2のセルインデックスのために生成された値が0であり、インジェクションのための結合方法がaddであり、アクティブ化関数がReLUであるので、セルは、前のセル状態、およびツリーインデックス0におけるノードの出力(上記でa0と呼ばれる)を追加し、次いでツリーインデックス0におけるノードの更新された出力を生成するために、その合計にReLUを適用することができる。セルは、次いで更新された出力を、ツリーインデックス2におけるノードへの入力として提供することができる。
In the example in Figure 2C, the cell is in the previous cell state because the value generated for the second cell index is 0, the merge method for injection is add, and the activation function is ReLU. , And the output of the node at tree index 0 (referred to above as a 0 ), and then a ReLU can be applied to the sum to produce the updated output of the node at
最初のセルインデックスのために生成された値は1なので、アクティブ化関数が適用される前に、セルは、更新されたメモリ状態をインデックス1におけるツリーの出力に設定する。
Since the value generated for the first cell index is 1, the cell sets the updated memory state to the output of the tree at
図2Cは、説明を容易にするために、ツリーが2つのリーフノードを含む一例を示すが、実際にはリーフノードの数はもっと大きくてもよく、たとえば4、8、または16であってもよい。 Figure 2C shows an example where the tree contains two leaf nodes for ease of explanation, but in reality the number of leaf nodes may be larger, for example 4, 8, or 16. Good.
図3は、コントローラパラメータの現在値を更新するための例示的なプロセス300のフロー図である。便宜上、プロセス300は、1つまたは複数の場所にある1つまたは複数のコンピュータのシステムによって実行されるものとして説明される。たとえば、適切にプログラムされた、ニューラルアーキテクチャ検索システム、たとえば図1のニューラルアーキテクチャ検索システム100は、プロセス300を実行することができる。
FIG. 3 is a flow diagram of an
システムは、コントローラニューラルネットワークをトレーニングする、すなわちコントローラパラメータの初期値からコントローラパラメータのトレーニング済みの値を決定するために、プロセス300を繰り返し実行することができる。
The system can iterate through
システムは、コントローラニューラルネットワークを使用して、反復時点におけるコントローラパラメータの現在値に従って、出力シーケンスのバッチを生成する(ステップ302)。バッチ内の各出力シーケンスは、子ニューラルネットワークのそれぞれのアーキテクチャを定義する。特に、上記で説明したように、システムは、出力シーケンス内の各ハイパーパラメータ値を生成するとき、スコア分布からサンプリングするので、バッチ内のシーケンスは、たとえそれらが各々同じコントローラパラメータ値に従って生成されたとしても一般に異なる。バッチは一般に、所定数の出力シーケンス、たとえば8、16、32、または64のシーケンスを含む。 The system uses a controller neural network to generate a batch of output sequences according to the current values of the controller parameters at the time of iteration (step 302). Each output sequence in the batch defines its own architecture for the child neural network. In particular, as described above, when the system generates each hyperparameter value in the output sequence, it samples from the score distribution, so the sequences in the batch were generated even if they each generated the same controller parameter values. Is generally different. A batch generally contains a predetermined number of output sequences, such as 8, 16, 32, or 64 sequences.
バッチ内の出力シーケンスごとに、システムは、特定のニューラルネットワークタスクを実行するために、出力シーケンスによって定義されたアーキテクチャを有する子ニューラルネットワークのインスタンスをトレーニングする(ステップ304)。すなわち、バッチ内の出力シーケンスごとに、システムは、出力シーケンスによって定義されたアーキテクチャを有するニューラルネットワークをインスタンス化し、受信されたトレーニングデータにおいてインスタンスをトレーニングして、たとえば逆伝播法または通時的誤差逆伝播法(backpropagation-through-time)による確率的勾配降下法などのタスクに適した従来の機械学習トレーニング技法を使用して、特定のニューラルネットワークタスクを実行する。いくつかの実装形態では、システムは、子ニューラルネットワークのトレーニングを並列化してコントローラニューラルネットワークの全体的なトレーニング時間を短縮する。システムは、指定された時間量または指定された回数のトレーニング反復について、それぞれの子ニューラルネットワークをトレーニングすることができる。 For each output sequence in a batch, the system trains an instance of a child neural network with the architecture defined by the output sequence to perform a particular neural network task (step 304). That is, for each output sequence in the batch, the system instantiates a neural network with the architecture defined by the output sequence and trains the instance in the received training data, eg backpropagation or backpropagation through time. Perform specific neural network tasks using traditional machine learning training techniques suitable for tasks such as backpropagation-through-time stochastic gradient descent. In some implementations, the system parallelizes the training of the child neural network to reduce the overall training time of the controller neural network. The system can train each child neural network for a specified amount of time or a specified number of training iterations.
バッチ内の出力シーケンスごとに、システムは、特定のニューラルネットワークタスクにおける子ニューラルネットワークの対応するトレーニング済みインスタンスの性能を評価して、特定のニューラルネットワークタスクにおけるトレーニング済みインスタンスの性能メトリックを決定する(ステップ306)。たとえば、性能メトリックは、適切な精度基準によって測定された検証セットにおけるトレーニング済みインスタンスの精度とすることができる。たとえば、精度は、出力がシーケンスであるときは当惑基準であり、またはタスクが分類タスクであるときは分類誤り率とすることができる。別の例として、性能メトリックは、インスタンスのトレーニングの最後の2、5、または10のエポックの各々について、インスタンスの精度の平均または最大値とすることができる。 For each output sequence in a batch, the system evaluates the performance of the corresponding trained instance of the child neural network in a particular neural network task to determine the performance metric of the trained instance in a particular neural network task (step). 306). For example, the performance metric can be the accuracy of the trained instance in the validation set measured by the appropriate accuracy criteria. For example, accuracy can be a perplexity criterion when the output is a sequence, or a classification error rate when the task is a classification task. As another example, the performance metric can be the average or maximum of instance accuracy for each of the last 2, 5, or 10 epochs of instance training.
システムは、コントローラパラメータの現在値を調整するために、トレーニング済みインスタンスの性能メトリックを使用する(ステップ308)。 The system uses the performance metrics of the trained instance to adjust the current values of the controller parameters (step 308).
特に、システムは、強化学習技法を使用して性能メトリックが向上した子ニューラルネットワークをもたらす出力シーケンスを生成するように、コントローラニューラルネットワークをトレーニングすることによって現在値を調整する。より具体的には、システムは、コントローラニューラルネットワークを訓練して、トレーニング済みインスタンスの性能メトリックに基づいて決定された受け取られた報酬を最大にする出力シーケンスを生成する。特に、所与の出力シーケンスについての報酬は、トレーニング済みインスタンスの性能メトリックの関数である。たとえば、報酬は、性能メトリック、性能メトリックの2乗、性能メトリックの3乗、性能メトリックの平方根などのうちの1つとすることができる。 In particular, the system adjusts the current value by training the controller neural network to generate an output sequence that results in a child neural network with improved performance metrics using reinforcement learning techniques. More specifically, the system trains the controller neural network to generate an output sequence that maximizes the received rewards determined based on the performance metrics of the trained instance. In particular, the reward for a given output sequence is a function of the performance metric of the trained instance. For example, the reward can be one of a performance metric, a square of a performance metric, a cube of a performance metric, a square root of a performance metric, and so on.
いくつかの場合には、システムは、ポリシー勾配技法を使用して、予想される報酬を最大にするようにコントローラニューラルネットワークをトレーニングする。たとえば、ポリシー勾配技法は、REINFORCE技法または近接ポリシー最適化(PPO: Proximal Policy Optimization)技法とすることができる。たとえば、システムは、
ここで、mはバッチ内のシーケンス数、Tはバッチ内の各シーケンス内の時間ステップ数、atは所与の出力シーケンス内の時間ステップtでの出力、Rkは出力シーケンスkについての報酬、θcはコントローラパラメータ、およびbはベースライン関数、たとえば以前のアーキテクチャ精度の指数移動平均である。
In some cases, the system uses policy gradient techniques to train the controller neural network to maximize the expected reward. For example, the policy gradient technique can be a REINFORCE technique or a Proximal Policy Optimization (PPO) technique. For example, the system
Where m is the number of sequences in the batch, T is the number of time steps in each sequence in the batch, a t is the output at time step t in a given output sequence, and R k is the reward for the output sequence k. , Θ c is the controller parameter, and b is the baseline function, eg the exponential moving average of the previous architectural accuracy.
いくつかの実装形態では、システムは、分散的な方法でコントローラニューラルネットワークをトレーニングする。すなわち、システムは、コントローラニューラルネットワークの複数の複製を維持し、トレーニング中に非同期的に複製のパラメータ値を更新する。すなわち、システムは、複製ごとに非同期にステップ302〜306を実行することができ、複製の各々について決定された勾配を使用してコントローラパラメータを更新することができる。 In some implementations, the system trains the controller neural network in a decentralized way. That is, the system maintains multiple replications of the controller neural network and asynchronously updates the replication parameter values during training. That is, the system can perform steps 302-306 asynchronously with each replication and update the controller parameters with the gradient determined for each replication.
本明細書は、システムおよびコンピュータプログラム構成要素に関して「構成される」という用語を使用する。1つまたは複数のコンピュータのシステムが特定の動作またはアクションを実行するように構成されるとは、システムが、動作中システムに動作またはアクションを実行させるソフトウェア、ファームウェア、ハードウェア、またはそれらの組合せをインストールしていることを意味する。1つまたは複数のコンピュータプログラムが特定の動作またはアクションを実行するように構成されるとは、1つまたは複数のプログラムが、データ処理装置によって実行されると、装置に動作またはアクションを実行させる命令を含むことを意味する。 The present specification uses the term "configured" with respect to system and computer program components. When a system of one or more computers is configured to perform a particular action or action, the system has software, firmware, hardware, or a combination thereof that causes the running system to perform the action or action. It means that you have installed it. When one or more computer programs are configured to perform a particular action or action, an instruction that causes the device to perform the action or action when one or more programs are executed by the data processing device. Means to include.
本明細書に記載された主題および機能的動作の実施形態は、デジタル電子回路、有形に実施されたコンピュータソフトウェアまたはファームウェア、本明細書に開示される構造およびそれらの構造的均等物を含むコンピュータハードウェア、またはそれらの1つもしくは複数の組合せに実装することができる。本明細書に記載される主題の実施形態は、1つまたは複数のコンピュータプログラム、すなわちデータ処理装置による実行のため、またはデータ処理装置の動作を制御するために有形の非一時的記憶媒体上に符号化されたコンピュータプログラム命令の1つまたは複数のモジュールとして実装することができる。コンピュータ記憶媒体は、機械可読記憶デバイス、機械可読記憶基板、ランダムまたはシリアルアクセスメモリデバイス、またはそれらの1つもしくは複数の組合せとすることができる。代替的に、または追加として、プログラム命令は、人工的に生成された伝搬信号、たとえばデータ処理装置による実行に適切な受信機装置への送信のために情報を符号化するために生成された機械生成電気、光学、または電磁信号上で符号化することができる。 Embodiments of the subject matter and functional operation described herein include digital electronic circuits, tangibly implemented computer software or firmware, structures disclosed herein and their structural equivalents. It can be implemented in clothing, or one or more combinations thereof. Embodiments of the subject matter described herein are on a tangible non-temporary storage medium for execution by one or more computer programs, i.e., a data processor, or to control the operation of the data processor. It can be implemented as one or more modules of encoded computer program instructions. The computer storage medium can be a machine-readable storage device, a machine-readable storage board, a random or serial access memory device, or a combination of one or more thereof. Alternatively or additionally, the program instruction is an artificially generated propagating signal, eg, a machine generated to encode information for transmission to a receiver device suitable for execution by a data processor. It can be encoded on generated electrical, optical, or electromagnetic signals.
「データ処理装置」という用語は、データ処理ハードウェアを指し、たとえばプログラム可能プロセッサ、コンピュータ、または複数のプロセッサもしくはコンピュータを含むデータを処理するためのあらゆる種類の装置、デバイス、および機械を包含する。装置は、たとえばFPGA(フィールドプログラマブルゲートアレイ)またはASIC(特定用途向け集積回路)などの専用論理回路でもよく、またはそれをさらに含むことができる。装置は、オプションで、ハードウェアに加えて、コンピュータプログラムの実行環境を生成するコード、たとえばプロセッサファームウェア、プロトコルスタック、データベース管理システム、オペレーティングシステム、またはそれらの1つまたは複数の組合せを構成するコードを含むことができる。 The term "data processor" refers to data processing hardware and includes, for example, programmable processors, computers, or any type of device, device, and machine for processing data, including multiple processors or computers. The device may be, or may further include, dedicated logic circuits such as FPGAs (Field Programmable Gate Arrays) or ASICs (Application Specific Integrated Circuits). The device, in addition to the hardware, optionally contains code that generates the execution environment for computer programs, such as processor firmware, protocol stacks, database management systems, operating systems, or a combination of one or more of them. Can include.
プログラム、ソフトウェア、ソフトウェアアプリケーション、アプリ、モジュール、ソフトウェアモジュール、スクリプト、またはコードとも呼ばれ、またはそのようにも記載される場合があるコンピュータプログラムは、コンパイル型もしくはインタープリタ型言語、または宣言型言語もしくは手続き型言語を含む任意の形式のプログラミング言語で記述することができ、スタンドアロンプログラムとして、またはモジュール、構成要素、サブルーチン、もしくはコンピューティング環境での使用に適した他のユニットとしてを含む、あらゆる形式で展開できる。プログラムは、必ずしも必要ではないが、ファイルシステム内のファイルに対応してもよい。プログラムは、問題のプログラム専用の単一のファイル、またはたとえば、1つまたは複数のモジュール、サブプログラム、もしくはコードの一部を記憶するファイルなどの複数の協調したファイルに、たとえばマークアップ言語ドキュメントに記憶された1つまたは複数のスクリプトなどの他のプログラムまたはデータを保持するファイルの一部に記憶することができる。コンピュータプログラムは、1つのコンピュータ上で、または1つのサイトに位置するか、もしくは複数のサイトに分散され、データ通信ネットワークによって相互接続された複数のコンピュータ上で実行されるように配備することができる。 Computer programs, also referred to as, or may also be described as programs, software, software applications, apps, modules, software modules, scripts, or code, are compiled or interpreted languages, or declarative languages or procedures. Can be written in any form of programming language, including type languages, and deployed in any form, including as a stand-alone program or as a module, component, subroutine, or other unit suitable for use in a computing environment. it can. The program may correspond to files in the file system, although not necessarily required. The program can be in a single file dedicated to the program in question, or in multiple collaborative files, such as a file that stores one or more modules, subprograms, or pieces of code, for example in markup language documents. It can be stored as part of a file that holds other programs or data, such as one or more stored scripts. Computer programs can be deployed on one computer, located at one site, or distributed across multiple sites and run on multiple computers interconnected by a data communication network. ..
本明細書では、「データベース」という用語は、任意のデータの集まりを指すために広く使用されており、データは、任意の特定の方法で構造化する必要はなく、またはまったく構造化する必要はなく、1つまたは複数の場所における記憶デバイスに記憶することができる。したがって、たとえばインデックスデータベースは、複数のデータの集まりを含むことができ、それらの各々は、異なって編成されアクセスされてもよい。 As used herein, the term "database" is widely used to refer to any collection of data, and the data does not need to be structured in any particular way, or it needs to be structured at all. It can be stored in a storage device in one or more locations. Thus, for example, an index database can contain multiple collections of data, each of which may be organized and accessed differently.
同様に、本明細書では、「エンジン」という用語は、1つまたは複数の特定の機能を実行するようにプログラムされるソフトウェアベースのシステム、サブシステム、またはプロセスを指すために広く使用される。一般に、エンジンは、1つまたは複数の場所における1つまたは複数のコンピュータにインストールされた1つまたは複数のソフトウェアモジュールまたは構成要素として実装される。いくつかの場合には、1つまたは複数のコンピュータが特定のエンジンに専用であり、他の場合には、複数のエンジンを同じコンピュータにインストールし、そこで実行することができる。 Similarly, as used herein, the term "engine" is widely used to refer to a software-based system, subsystem, or process that is programmed to perform one or more specific functions. Generally, an engine is implemented as one or more software modules or components installed on one or more computers in one or more locations. In some cases, one or more computers are dedicated to a particular engine, in other cases multiple engines can be installed and run on the same computer.
本明細書に記載されたプロセスおよび論理フローは、入力データ上で動作し、出力を生成することによって機能を実行するために、1つまたは複数のコンピュータプログラムを実行する1つまたは複数のプログラム可能コンピュータによって実行することができる。プロセスおよび論理フローは、たとえばFPGAまたはASICなどの専用論理回路によって、または専用論理回路と1つまたは複数のプログラムされたコンピュータとの組合せによっても実行することができる。 The processes and logical flows described herein can be programmed to run one or more computer programs to run on input data and perform functions by producing output. It can be run by a computer. Processes and logic flows can also be performed by dedicated logic circuits such as FPGAs or ASICs, or by a combination of dedicated logic circuits and one or more programmed computers.
コンピュータプログラムの実行に適したコンピュータは、汎用マイクロプロセッサもしくは専用マイクロプロセッサ、もしくはその両方、または他の種類の中央処理装置に基づくことができる。一般に、中央処理装置は、読取り専用メモリまたはランダムアクセスメモリまたはその両方から命令およびデータを受信する。コンピュータの必須要素は、命令を実施または実行するための中央処理装置、ならびに命令およびデータを記憶するための1つまたは複数のメモリデバイスである。中央処理装置およびメモリは、専用論理回路によって補うまたは組み込むことができる。一般に、コンピュータは、たとえば磁気、光磁気ディスク、または光ディスクなどのデータを記憶するための1つまたは複数の大容量記憶デバイスをも含み、あるいは1つまたは複数の大容量記憶デバイスからデータを受信する、それにデータを転送する、またはその両方のために動作可能に結合される。しかしながら、コンピュータはそのようなデバイスを有する必要はない。さらに、コンピュータは、別のデバイス、たとえばほんのいくつかの例を挙げれば、携帯電話、携帯情報端末(PDA)、モバイルオーディオまたはビデオプレーヤ、ゲームコンソール、全地球測位システム(GPS)受信機、またはポータブルストレージデバイス、たとえばユニバーサルシリアルバス(USB)フラッシュドライブ中に組み込むことができる。 A suitable computer for executing a computer program can be based on a general purpose microprocessor, a dedicated microprocessor, or both, or other types of central processing units. In general, central processing units receive instructions and data from read-only memory and / or random access memory. Essential elements of a computer are a central processing unit for executing or executing instructions, as well as one or more memory devices for storing instructions and data. The central processing unit and memory can be supplemented or incorporated by dedicated logic circuits. In general, a computer also includes one or more mass storage devices for storing data, such as magnetic, magneto-optical disks, or optical disks, or receives data from one or more mass storage devices. , Transfer data to it, or combined operably for both. However, the computer does not have to have such a device. In addition, a computer can be another device, such as a mobile phone, personal digital assistant (PDA), mobile audio or video player, game console, Global Positioning System (GPS) receiver, or portable, to name just a few. It can be embedded in a storage device, such as a universal serial bus (USB) flash drive.
コンピュータプログラム命令およびデータを記憶するのに適したコンピュータ可読媒体は、一例として、たとえばEPROM、EEPROM、およびフラッシュメモリデバイスなどの半導体メモリデバイス、たとえば内部ハードディスクまたはリムーバブルディスクなどの磁気ディスク、光磁気ディスク、およびCD-ROMおよびDVD-ROMディスクを含むすべての形態の不揮発性メモリ、メディアおよびメモリデバイスを含む。 Computer-readable media suitable for storing computer program instructions and data include, for example, semiconductor memory devices such as EPROM, EEPROM, and flash memory devices, such as magnetic disks such as internal hard disks or removable disks, magneto-optical disks, and the like. And includes all forms of non-volatile memory, media and memory devices, including CD-ROM and DVD-ROM disks.
ユーザとの対話を提供するために、本明細書に記載される主題の実施形態は、ユーザに情報を表示するための、たとえばCRT(陰極線管)またはLCD(液晶ディスプレイ)モニタなどのディスプレイデバイス、ならびにキーボードおよび、ユーザがコンピュータに入力を提供することができる、たとえばマウスまたはトラックボールなどのポインティングデバイスを有するコンピュータ上に実装することができる。他の種類のデバイスを使用して、ユーザとの対話を提供することもでき、たとえばユーザに提供されるフィードバックは、たとえば視覚フィードバック、聴覚フィードバック、または触覚フィードバックなどの任意の形態の感覚フィードバックとすることができ、ユーザからの入力は、音響、音声、または触覚入力を含む任意の形態で受信することができる。さらに、コンピュータは、たとえばウェブブラウザから受信された要求に応答して、ユーザのデバイス上のウェブブラウザにウェブページを送信することによってなどのユーザによって使用されるデバイスとの間でドキュメントを送受信することによってユーザと対話することができる。また、コンピュータは、テキストメッセージまたは他の形態のメッセージをパーソナルデバイス、たとえばメッセージングアプリケーションを実行しているスマートフォンに送信し、代わりにユーザから応答メッセージを受信することによってユーザと対話することができる。 To provide interaction with the user, embodiments of the subject matter described herein are display devices for displaying information to the user, such as a CRT (cathode tube) or LCD (liquid crystal display) monitor. It can also be implemented on a keyboard and a computer having a pointing device such as a mouse or trackball where the user can provide input to the computer. Other types of devices can also be used to provide interaction with the user, eg, the feedback provided to the user can be any form of sensory feedback, such as visual feedback, auditory feedback, or tactile feedback. The input from the user can be received in any form, including acoustic, voice, or tactile input. In addition, the computer sends and receives documents to and from the device used by the user, for example by sending a web page to the web browser on the user's device in response to a request received from the web browser. Allows you to interact with the user. The computer can also interact with the user by sending a text message or other form of message to a personal device, such as a smartphone running a messaging application, and instead receiving a response message from the user.
機械学習モデルを実装するためのデータ処理装置はまた、たとえば機械学習のトレーニングまたは製作、すなわち推論、作業負荷の共通部分および計算集約的部分を処理するための専用ハードウェアアクセラレータユニットを含むことができる。 A data processor for implementing a machine learning model can also include, for example, a dedicated hardware accelerator unit for training or building machine learning, ie, processing inference, intersections of workloads and computationally intensive parts. ..
機械学習モデルは、機械学習フレームワーク、たとえばTensorFlowフレームワーク、Microsoft Cognitive Toolkitフレームワーク、Apache Singaフレームワーク、またはApache MXNetフレームワークを使用して実装および展開することができる。 Machine learning models can be implemented and deployed using machine learning frameworks such as the TensorFlow framework, Microsoft Cognitive Toolkit framework, Apache Singa framework, or Apache MXNet framework.
本明細書に記載される主題の実施形態は、たとえばデータサーバとしてのバックエンド構成要素を含む、またはたとえばアプリケーションサーバなどのミドルウェア構成要素を含む、またはたとえば、ユーザが本明細書に記載された主題の実装と対話することができる、グラフィカルユーザインタフェース、ウェブブラウザ、またはアプリを有するたとえばクライアントコンピュータなどのフロントエンド構成要素を含む、または1つもしくは複数のそのようなバックエンド、ミドルウェア、またはフロントエンド構成要素の任意の組合せを含むコンピューティングシステムにおいて実装することができる。システムの構成要素は、たとえば通信ネットワークなどの任意の形式または媒体のデジタルデータ通信によって相互接続することができる。通信ネットワークの例には、ローカルエリアネットワーク(LAN)およびワイドエリアネットワーク(WAN)、たとえばインターネットがある。 Embodiments of the subject matter described herein include, for example, a back-end component as a data server, or, for example, a middleware component such as an application server, or, for example, a subject described herein by a user. Includes front-end components such as client computers that have a graphical user interface, web browser, or app that can interact with the implementation of, or one or more such back-end, middleware, or front-end configurations. It can be implemented in a computing system that contains any combination of elements. The components of the system can be interconnected by digital data communication in any form or medium, such as a communication network. Examples of communication networks are local area networks (LANs) and wide area networks (WANs), such as the Internet.
コンピューティングシステムは、クライアントおよびサーバを含むことができる。クライアントとサーバは、一般に互いに遠隔であり、典型的には通信ネットワークを介して対話する。クライアントとサーバとの関係は、それぞれのコンピュータ上で実行され、互いにクライアント−サーバ関係を有するコンピュータプログラムのおかげで生じる。いくつかの実施形態では、サーバは、たとえばクライアントとして動作するデバイスと対話しているユーザにデータを表示し、ユーザからユーザ入力を受信するために、データ、たとえばHTMLページをユーザデバイスに送信する。たとえば、ユーザ対話の結果などのユーザデバイスにおいて生成されたデータは、デバイスからサーバにおいて受信することができる。 The computing system can include clients and servers. Clients and servers are generally remote from each other and typically interact over a communication network. The client-server relationship arises thanks to computer programs that run on their respective computers and have a client-server relationship with each other. In some embodiments, the server displays data to a user interacting with, for example, a device acting as a client, and sends data, eg, an HTML page, to the user device to receive user input from the user. For example, data generated on a user device, such as the result of a user interaction, can be received from the device on the server.
本明細書は、多くの具体的な実施の詳細を含むが、これらは、いかなる発明の範囲または特許請求される可能性のある範囲に対する限定ではなく、むしろ特定の発明の特定の実施形態に固有であり得る特徴の説明として解釈されるものとする。別個の実施形態の文脈において本明細書で説明されるいくつかの特徴は、単一の実施形態において組み合わせて実装することもできる。逆に、単一の実施形態の文脈で記載されている様々な特徴は、複数の実施形態で別々にまたは任意の適切な部分組合せで実装することもできる。さらに、特徴は、いくつかの組合せで作用するものとして上述されており、当初はそのように請求されているものであるが、いくつかの場合には、請求された組合せからの1つまたは複数の特徴を、組合せから切り取ることができ、請求された組合せは、部分組合せ、または部分組合せの変形を対象としてもよい。 The present specification includes many specific embodiments, but these are not limitations to the scope of any invention or claims, but rather are specific to a particular embodiment of a particular invention. It shall be interpreted as an explanation of the possible features. Some features described herein in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely, the various features described in the context of a single embodiment can also be implemented separately in multiple embodiments or in any suitable subcombination. In addition, the features are described above as acting in several combinations, which were initially claimed as such, but in some cases one or more from the claimed combinations. Features can be cut out from the combinations, and the claimed combinations may be subject to partial combinations or variants of the partial combinations.
同様に、動作が図面に示され、特許請求の範囲に特定の順序で記載されているが、これは、そのような動作が、示された特定の順序で、または順番に実行されること、あるいは望ましい結果を達成するために、図示されたすべての動作が実行されることを必要とするものとして理解されないものとする。いくつかの状況では、マルチタスキングおよび並列処理が有利であり得る。さらに、上述した実施形態における様々なシステムモジュールおよび構成要素の分離は、すべての実施形態においてそのような分離を必要とするものとして理解されないものとし、記述されたプログラム構成要素およびシステムが、一般に単一のソフトウェア製品に一緒に組み入れられ、または複数のソフトウェア製品にパッケージ化することができることを理解されたい。 Similarly, the actions are shown in the drawings and are described in the claims in a particular order, which means that such actions are performed in the particular order shown or in order. Alternatively, it shall not be understood as requiring all the illustrated actions to be performed in order to achieve the desired result. In some situations, multitasking and parallelism can be advantageous. Moreover, the separation of the various system modules and components in the embodiments described above shall not be understood as requiring such separation in all embodiments, and the described program components and systems are generally simply simple. It should be understood that it can be incorporated together into one software product or packaged into multiple software products.
主題の特定の実施形態が記載されている。他の実施形態は、以下の特許請求の範囲内にある。たとえば、特許請求の範囲に列挙されたアクションは、異なる順序で実行され、依然として望ましい結果を達成することができる。一例として、添付の図面に示されるプロセスは、望ましい結果を達成するために、示された特定の順序または逐次的な順序を必ずしも必要としない。いくつかの場合には、マルチタスキングおよび並列処理が有利であり得る。 Specific embodiments of the subject are described. Other embodiments are within the scope of the following claims. For example, the actions listed in the claims can be performed in a different order and still achieve the desired result. As an example, the process shown in the accompanying drawings does not necessarily require the specific order or sequential order shown to achieve the desired result. In some cases, multitasking and parallelism can be advantageous.
100 ニューラルアーキテクチャ検索システム
102 トレーニングデータ
104 検証セット
110 コントローラニューラルネットワーク
112 シーケンスのバッチ
120 トレーニングエンジン
130 コントローラパラメータ更新エンジン
150 アーキテクチャデータ
202〜214 時間ステップ
220 層
230 層
232 隠れ状態
242〜254 出力層
300 プロセス
100 Neural Architecture Search System
102 training data
104 verification set
110 Controller Neural Network
112 Sequence batch
120 training engine
130 Controller parameter update engine
150 architecture data
202-214 hour steps
220 layers
230 layers
232 Hidden state
242 to 254 Output layer
300 processes
Claims (22)
複数のコントローラパラメータを有するコントローラニューラルネットワークによって、前記コントローラパラメータの現在値に従って、出力シーケンスのバッチを生成するステップであって、前記バッチ内の各出力シーケンスが、特定のニューラルネットワークタスクを実行するように構成される子ニューラルネットワークのそれぞれのアーキテクチャを定義する、ステップと、
トレーニングエンジンによって、前記バッチ内の出力シーケンスごとに、
前記特定のニューラルネットワークタスクを実行するために、前記出力シーケンスによって定義された前記アーキテクチャを有する前記子ニューラルネットワークのそれぞれのインスタンスをトレーニングするステップと、
前記特定のニューラルネットワークタスクにおける前記子ニューラルネットワークの前記トレーニング済みインスタンスの性能メトリックを決定するために、前記特定のニューラルネットワークタスクにおける前記子ニューラルネットワークの前記トレーニング済みインスタンスの性能を評価するステップと
を含み、
コントローラパラメータ更新エンジンによって、前記コントローラニューラルネットワークの前記コントローラパラメータの前記現在値を調整するために、前記子ニューラルネットワークの前記トレーニング済みインスタンスの前記性能メトリックを使用するステップと
を含む、方法。 A method performed by one or more computers
The controller neural network having a plurality of controller parameters, according to the current value of the controller parameter, comprising: generating a batch of the output sequence, so that each output sequence in the batch, to perform specific neural network task Steps and steps that define each architecture of the child neural network to be constructed
By the training engine, for each output sequence in the batch
A step of training each instance of the child neural network having the architecture defined by the output sequence to perform the particular neural network task.
Including a step of evaluating the performance of the trained instance of the child neural network in the particular neural network task to determine the performance metric of the trained instance of the child neural network in the particular neural network task. ,
A method comprising the step of using the performance metric of the trained instance of the child neural network to adjust the current value of the controller parameter of the controller neural network by the controller parameter update engine .
強化学習技法を使用して性能メトリックが向上した子ニューラルネットワークをもたらす出力シーケンスを生成するように、前記コントローラニューラルネットワークをトレーニングするステップ
を含む、請求項1に記載の方法。 A step of using the performance metric of the trained instance of the child neural network to adjust the current value of the controller parameter of the controller neural network.
The method of claim 1, comprising the step of training the controller neural network to generate an output sequence that results in a child neural network with improved performance metrics using reinforcement learning techniques.
所与の出力シーケンスについて、各時間ステップで、
前記所与の出力シーケンスにおいて、前の時間ステップにおけるハイパーパラメータの前記値を入力として受信し、かつリカレントニューラルネットワークの現在の隠れ状態を更新するように、前記入力を処理する
ように構成される1つまたは複数のリカレントニューラルネットワーク層と、
時間ステップごとのそれぞれの出力層であって、各出力層が、前記所与の出力シーケンスについて、
前記時間ステップで前記更新された隠れ状態を含む出力層入力を受信し、かつ前記時間ステップで前記ハイパーパラメータの可能な値にわたるスコア分布を定義する前記時間ステップの出力を生成する
ように構成されるそれぞれの出力層と
を含むリカレントニューラルネットワークである、請求項5に記載の方法。 The controller neural network
For a given output sequence, at each time step,
Oite to said given output sequence, received as inputs the values of the hyper parameters in the previous time step, and to update the current hidden state of the recurrent neural network, is configured to process the input With one or more recurrent neural network layers,
Each output layer for each time step, with each output layer for the given output sequence.
The time step is configured to receive the output layer input containing the updated hidden state and to generate the output of the time step that defines the score distribution over the possible values of the hyperparameters. The method according to claim 5, which is a recurrent neural network including each output layer.
前記時間ステップでの前記ハイパーパラメータの可能な値にわたるスコア分布を定義する前記時間ステップの出力を生成するために、前記出力シーケンスにおいて、前の時間ステップにおける前記ハイパーパラメータの前記値を、前記コントローラニューラルネットワークへの入力として提供するステップと、
前記出力シーケンス内の前記時間ステップにおける前記ハイパーパラメータの前記値を決定するために前記スコア分布に従って前記可能な値からサンプリングするステップと
を含む、請求項6に記載の方法。 Using a controller neural network with multiple controller parameters, the steps to generate a batch of output sequences according to the current values of the controller parameters are for each output sequence within the batch and for each of the plurality of time steps. ,
In order to generate the output of the time step that defines the score distribution over the possible values of the hyperparameter in the time step, in the output sequence , the value of the hyperparameter in the previous time step is referred to by the controller neural. and providing as an input to the network,
The method of claim 6, comprising sampling from the possible values according to the score distribution to determine the values of the hyperparameters in the time steps in the output sequence.
フィルタの数、
フィルタごとのフィルタ高さ、
フィルタごとのフィルタ幅、
フィルタごとのストライド高さ、または
フィルタごとのストライド幅
のうちの1つまたは複数を含む、請求項8に記載の方法。 The hyperparameters for each of the convolutional neural network layers
Number of filters,
Filter height for each filter,
Filter width per filter,
8. The method of claim 8, comprising one or more of the stride height per filter or the stride width per filter.
前記子ニューラルネットワーク内の前記現在の層よりも前の各層に対応するそれぞれのノードを含み、各ノードが、
前記対応する以前の層が前記子ニューラルネットワーク内の前記現在の層に接続される尤度を表すスコアを生成するためのパラメータのセットの現在値に従って、前記アンカーポイント時間ステップについての前記更新された隠れ状態、および前記対応する以前の層の前記アンカーポイント時間ステップについての前記更新された隠れ状態を処理して前記スコアを生成する
ように構成される、
請求項11に記載の方法。 The plurality of time steps include the respective anchor point time steps for each of the one or more layers for which the hyperparameters are skip connection hyperparameters, and the output for the anchor point time steps of the current layer. Layers
Each node contains a node corresponding to each layer prior to the current layer in the child neural network.
The updated for the anchor point time step according to the current value of a set of parameters for generating a score representing the likelihood that the corresponding previous layer will be connected to the current layer in the child neural network. It is configured to process the hidden state and the updated hidden state for the anchor point time step of the corresponding previous layer to generate the score .
The method of claim 11.
をさらに含む、請求項1〜16のいずれか一項に記載の方法。 The method of any one of claims 1-16, further comprising generating a final output sequence that defines the final architecture of the child neural network according to the adjusted values of the controller parameters.
をさらに含む、請求項17に記載の方法。 17. Claim 17, further comprising performing the particular neural network task on the received network input by processing the received network input using a child neural network having the final architecture. Method.
1つまたは複数のコンピュータによって実施されるコントローラニューラルネットワークであって、前記コントローラニューラルネットワークが、
特定のニューラルネットワークタスクを実行するように構成される子ニューラルネットワークのアーキテクチャを定義するハイパーパラメータ値の出力シーケンス内の各時間ステップにおいて、
前記出力シーケンスにおいて、前の時間ステップに対応する前記子ニューラルネットワークのハイパーパラメータの値を入力として受信し、
リカレントニューラルネットワークの現在の隠れ状態を更新するように、前記入力を処理する
ように構成される1つまたは複数のリカレントニューラルネットワーク層
を含むリカレントニューラルネットワークであるコントローラニューラルネットワークと、
前記出力シーケンス内の各時間ステップに対応するそれぞれの出力層であって、各出力層が、
前記対応する時間ステップにおいて前記更新された隠れ状態を含む出力層入力を受信し、前記対応する時間ステップに対応する前記子ニューラルネットワークのハイパーパラメータの可能な値にわたるスコア分布を定義する前記対応する時間ステップの出力を生成する
ように構成される、出力層と
を含む、システム。 It's a system
A controller neural network implemented by one or more computers, said controller neural network.
At each time step in the output sequence of hyperparameter values that defines the architecture of the child neural network that is configured to perform a particular neural network task.
In the output sequence , the hyperparameter values of the child neural network corresponding to the previous time step are received as inputs.
A controller neural network, which is a recurrent neural network containing one or more recurrent neural network layers configured to process the input so as to update the current hidden state of the recurrent neural network.
Each output layer corresponding to each time step in the output sequence.
The corresponding time that receives the output layer input containing the updated hidden state in the corresponding time step and defines the score distribution over possible values of the hyperparameters of the child neural network corresponding to the corresponding time step. A system that includes an output layer that is configured to produce the output of the steps.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201662414300P | 2016-10-28 | 2016-10-28 | |
US62/414,300 | 2016-10-28 | ||
PCT/US2017/058760 WO2018081563A1 (en) | 2016-10-28 | 2017-10-27 | Neural architecture search |
Related Child Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2020215172A Division JP7210531B2 (en) | 2016-10-28 | 2020-12-24 | neural architecture search |
Publications (2)
Publication Number | Publication Date |
---|---|
JP2019533257A JP2019533257A (en) | 2019-11-14 |
JP6817431B2 true JP6817431B2 (en) | 2021-01-20 |
Family
ID=60473590
Family Applications (3)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2019522868A Active JP6817431B2 (en) | 2016-10-28 | 2017-10-27 | Neural architecture search |
JP2020215172A Active JP7210531B2 (en) | 2016-10-28 | 2020-12-24 | neural architecture search |
JP2022177577A Pending JP2023024993A (en) | 2016-10-28 | 2022-11-04 | neural architecture search |
Family Applications After (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2020215172A Active JP7210531B2 (en) | 2016-10-28 | 2020-12-24 | neural architecture search |
JP2022177577A Pending JP2023024993A (en) | 2016-10-28 | 2022-11-04 | neural architecture search |
Country Status (6)
Country | Link |
---|---|
US (3) | US11030523B2 (en) |
JP (3) | JP6817431B2 (en) |
KR (2) | KR102532658B1 (en) |
CN (1) | CN108021983A (en) |
DE (2) | DE202017106532U1 (en) |
WO (1) | WO2018081563A1 (en) |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2021064390A (en) * | 2016-10-28 | 2021-04-22 | グーグル エルエルシーＧｏｏｇｌｅ ＬＬＣ | Neural architecture search |
Families Citing this family (54)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10565493B2 (en) * | 2016-09-22 | 2020-02-18 | Salesforce.Com, Inc. | Pointer sentinel mixture architecture |
US20180336453A1 (en) * | 2017-05-19 | 2018-11-22 | Salesforce.Com, Inc. | Domain specific language for generation of recurrent neural network architectures |
JP7043596B2 (en) * | 2017-10-27 | 2022-03-29 | グーグル エルエルシー | Neural architecture search |
US11741342B2 (en) * | 2018-05-18 | 2023-08-29 | Baidu Usa Llc | Resource-efficient neural architects |
US11514543B2 (en) * | 2018-06-05 | 2022-11-29 | Beijing Didi Infinity Technology And Development Co., Ltd. | System and method for ride order dispatching |
CN112513886B (en) * | 2018-08-03 | 2024-03-22 | 索尼公司 | Information processing method, information processing apparatus, and information processing program |
CN110826686A (en) * | 2018-08-07 | 2020-02-21 | 艾玛迪斯简易股份公司 | Machine learning system and method with attribute sequence |
CN109255374A (en) * | 2018-08-27 | 2019-01-22 | 中共中央办公厅电子科技学院 | A kind of aesthetic properties evaluation method based on intensive convolutional network and multitask network |
CN109189973B (en) * | 2018-08-30 | 2021-07-30 | 清华大学 | Large-scale image retrieval method and device based on strategy gradient |
EP3617953A1 (en) | 2018-08-30 | 2020-03-04 | Koninklijke Philips N.V. | An adaptable neural network |
CN109065076B (en) * | 2018-09-05 | 2020-11-27 | 深圳追一科技有限公司 | Audio label setting method, device, equipment and storage medium |
US11334791B2 (en) * | 2018-09-05 | 2022-05-17 | Siemens Healthcare Gmbh | Learning to search deep network architectures |
CN110889487A (en) * | 2018-09-10 | 2020-03-17 | 富士通株式会社 | Neural network architecture search apparatus and method, and computer-readable recording medium |
KR102066009B1 (en) * | 2018-09-14 | 2020-01-14 | 가천대학교 산학협력단 | Image reconstruction system on medical imaging apparatus using recurrent neural network |
US11645509B2 (en) * | 2018-09-27 | 2023-05-09 | Salesforce.Com, Inc. | Continual neural network learning via explicit structure learning |
EP3629246B1 (en) * | 2018-09-27 | 2022-05-18 | Swisscom AG | Systems and methods for neural architecture search |
US20200104715A1 (en) * | 2018-09-28 | 2020-04-02 | Xilinx, Inc. | Training of neural networks by including implementation cost as an objective |
US11604992B2 (en) * | 2018-11-02 | 2023-03-14 | Microsoft Technology Licensing, Llc | Probabilistic neural network architecture generation |
CN111144561B (en) * | 2018-11-05 | 2023-05-02 | 杭州海康威视数字技术股份有限公司 | Neural network model determining method and device |
US11775812B2 (en) | 2018-11-30 | 2023-10-03 | Samsung Electronics Co., Ltd. | Multi-task based lifelong learning |
CN109615073B (en) * | 2018-12-03 | 2021-06-04 | 郑州云海信息技术有限公司 | Neural network model construction method, device and storage medium |
US11556778B2 (en) * | 2018-12-07 | 2023-01-17 | Microsoft Technology Licensing, Llc | Automated generation of machine learning models |
CN111325311B (en) * | 2018-12-14 | 2024-03-29 | 深圳云天励飞技术有限公司 | Neural network model generation method for image recognition and related equipment |
US11114103B2 (en) * | 2018-12-28 | 2021-09-07 | Alibaba Group Holding Limited | Systems, methods, and computer-readable storage media for audio signal processing |
CN113424199A (en) | 2019-01-23 | 2021-09-21 | 谷歌有限责任公司 | Composite model scaling for neural networks |
US11790212B2 (en) * | 2019-03-18 | 2023-10-17 | Microsoft Technology Licensing, Llc | Quantization-aware neural architecture search |
US11630990B2 (en) | 2019-03-19 | 2023-04-18 | Cisco Technology, Inc. | Systems and methods for auto machine learning and neural architecture search |
US20200302270A1 (en) * | 2019-03-19 | 2020-09-24 | Cisco Technology, Inc. | Budgeted neural network architecture search system and method |
DE102019204136A1 (en) * | 2019-03-26 | 2020-10-01 | Robert Bosch Gmbh | Method and device for training and producing an artificial neural network |
CN110110861B (en) * | 2019-05-09 | 2021-11-26 | 北京市商汤科技开发有限公司 | Method and device for determining model hyper-parameters and training model and storage medium |
CN111684471A (en) * | 2019-05-31 | 2020-09-18 | 深圳市大疆创新科技有限公司 | Method and apparatus for network structure search, computer storage medium, and computer program product |
CN110288084A (en) * | 2019-06-06 | 2019-09-27 | 北京小米智能科技有限公司 | Super-network training method and device |
DE102019210167A1 (en) * | 2019-07-10 | 2021-01-14 | Robert Bosch Gmbh | More robust training for artificial neural networks |
CN110490320B (en) * | 2019-07-30 | 2022-08-23 | 西北工业大学 | Deep neural network structure optimization method based on fusion of prediction mechanism and genetic algorithm |
CN110428046B (en) * | 2019-08-28 | 2023-12-15 | 腾讯科技（深圳）有限公司 | Method and device for acquiring neural network structure and storage medium |
CN110598852A (en) * | 2019-08-29 | 2019-12-20 | 北京小米移动软件有限公司 | Sub-network sampling method, and method and device for constructing super-network topology structure |
CN110598629B (en) * | 2019-09-11 | 2023-06-06 | 北京百度网讯科技有限公司 | Super-network search space construction method and device and electronic equipment |
CN110543944B (en) * | 2019-09-11 | 2022-08-02 | 北京百度网讯科技有限公司 | Neural network structure searching method, apparatus, electronic device, and medium |
CN110956262A (en) * | 2019-11-12 | 2020-04-03 | 北京小米智能科技有限公司 | Hyper network training method and device, electronic equipment and storage medium |
CN112884118A (en) * | 2019-11-30 | 2021-06-01 | 华为技术有限公司 | Neural network searching method, device and equipment |
CN112990461B (en) * | 2019-12-16 | 2023-09-19 | 杭州海康威视数字技术股份有限公司 | Method, device, computer equipment and storage medium for constructing neural network model |
CA3165790A1 (en) * | 2020-01-27 | 2021-08-05 | Akkio, Inc. | Methods and systems for dynamically generating a plurality of machine learning systems during processing of a user data set |
US11521028B2 (en) | 2020-04-10 | 2022-12-06 | Toyota Research Institute, Inc. | Meta-learning neural architecture search via graph networks on search space lattices |
CN111516700A (en) * | 2020-05-11 | 2020-08-11 | 安徽大学 | Driver distraction fine-granularity monitoring method and system |
KR20210152402A (en) * | 2020-06-05 | 2021-12-15 | 에이치티씨 코퍼레이션 | Machine learning method and machine learning system involving data augmentation |
US11436498B2 (en) * | 2020-06-09 | 2022-09-06 | Toyota Research Institute, Inc. | Neural architecture search system for generating a neural network architecture |
JP6885553B1 (en) * | 2020-07-14 | 2021-06-16 | エッジコーティックス ピーティーイー． リミテッド | Joint exploration of hardware and neural architecture |
EP3975060A1 (en) * | 2020-09-29 | 2022-03-30 | Samsung Electronics Co., Ltd. | Method and apparatus for analysing neural network performance |
KR102264571B1 (en) * | 2020-10-30 | 2021-06-15 | 주식회사 애자일소다 | Hierarchical decision agent |
CN113469078B (en) * | 2021-07-07 | 2023-07-04 | 西安电子科技大学 | Hyperspectral image classification method based on automatic design of long and short-term memory network |
WO2023009766A1 (en) * | 2021-07-28 | 2023-02-02 | Google Llc | Evaluating output sequences using an auto-regressive language model neural network |
KR102610429B1 (en) * | 2021-09-13 | 2023-12-06 | 연세대학교 산학협력단 | Artificial neural network and computational accelerator structure co-exploration apparatus and method |
KR20230100914A (en) | 2021-12-29 | 2023-07-06 | 경희대학교 산학협력단 | Neural architecture search method and computing device for executing the method |
KR20230159938A (en) | 2022-05-16 | 2023-11-23 | 주식회사 뷰노 | Method for analyzing bio-signal |
Family Cites Families (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6553357B2 (en) | 1999-09-01 | 2003-04-22 | Koninklijke Philips Electronics N.V. | Method for improving neural network architectures using evolutionary algorithms |
CN102402712B (en) | 2011-08-31 | 2014-03-05 | 山东大学 | Robot reinforced learning initialization method based on neural network |
US10275719B2 (en) | 2015-01-29 | 2019-04-30 | Qualcomm Incorporated | Hyper-parameter selection for deep convolutional networks |
JP2017102906A (en) | 2015-11-25 | 2017-06-08 | キヤノン株式会社 | Information processing apparatus, information processing method, and program |
US9899672B2 (en) | 2016-05-17 | 2018-02-20 | Nanotek Instruments, Inc. | Chemical-free production of graphene-encapsulated electrode active material particles for battery applications |
DE202017106532U1 (en) | 2016-10-28 | 2018-02-05 | Google Llc | Search for a neural architecture |
-
2017
- 2017-10-27 DE DE202017106532.4U patent/DE202017106532U1/en active Active
- 2017-10-27 JP JP2019522868A patent/JP6817431B2/en active Active
- 2017-10-27 KR KR1020227011808A patent/KR102532658B1/en active IP Right Grant
- 2017-10-27 DE DE102017125256.8A patent/DE102017125256A1/en active Pending
- 2017-10-27 WO PCT/US2017/058760 patent/WO2018081563A1/en active Application Filing
- 2017-10-27 KR KR1020197012084A patent/KR102386806B1/en active IP Right Grant
- 2017-10-30 CN CN201711037649.0A patent/CN108021983A/en active Pending
-
2019
- 2019-04-29 US US16/397,641 patent/US11030523B2/en active Active
-
2020
- 2020-12-24 JP JP2020215172A patent/JP7210531B2/en active Active
-
2021
- 2021-06-07 US US17/340,959 patent/US11829874B2/en active Active
-
2022
- 2022-11-04 JP JP2022177577A patent/JP2023024993A/en active Pending
-
2023
- 2023-07-26 US US18/226,527 patent/US20230368024A1/en active Pending
Cited By (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2021064390A (en) * | 2016-10-28 | 2021-04-22 | グーグル エルエルシーＧｏｏｇｌｅ ＬＬＣ | Neural architecture search |
JP7210531B2 (en) | 2016-10-28 | 2023-01-23 | グーグル エルエルシー | neural architecture search |
US11829874B2 (en) | 2016-10-28 | 2023-11-28 | Google Llc | Neural architecture search |
Also Published As
Publication number | Publication date |
---|---|
DE202017106532U1 (en) | 2018-02-05 |
WO2018081563A1 (en) | 2018-05-03 |
CN108021983A (en) | 2018-05-11 |
US11829874B2 (en) | 2023-11-28 |
WO2018081563A9 (en) | 2019-03-07 |
JP7210531B2 (en) | 2023-01-23 |
KR102532658B1 (en) | 2023-05-15 |
KR20190052143A (en) | 2019-05-15 |
DE102017125256A1 (en) | 2018-05-03 |
US11030523B2 (en) | 2021-06-08 |
US20190251439A1 (en) | 2019-08-15 |
US20210295163A1 (en) | 2021-09-23 |
JP2021064390A (en) | 2021-04-22 |
KR102386806B1 (en) | 2022-04-14 |
KR20220047688A (en) | 2022-04-18 |
JP2023024993A (en) | 2023-02-21 |
US20230368024A1 (en) | 2023-11-16 |
JP2019533257A (en) | 2019-11-14 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
JP6817431B2 (en) | Neural architecture search | |
US11651259B2 (en) | Neural architecture search for convolutional neural networks | |
JP7043596B2 (en) | Neural architecture search | |
JP7157154B2 (en) | Neural Architecture Search Using Performance Prediction Neural Networks | |
JP6889270B2 (en) | Neural network architecture optimization | |
JP6790286B2 (en) | Device placement optimization using reinforcement learning | |
KR102392094B1 (en) | Sequence processing using convolutional neural networks | |
US10922611B2 (en) | Neural network optimizer search | |
CN111602148A (en) | Regularized neural network architecture search | |
US20220019869A1 (en) | Hardware-optimized neural architecture search |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A621 | Written request for application examination |
Free format text: JAPANESE INTERMEDIATE CODE: A621Effective date: 20190607 |
|
A977 | Report on retrieval |
Free format text: JAPANESE INTERMEDIATE CODE: A971007Effective date: 20200624 |
|
A131 | Notification of reasons for refusal |
Free format text: JAPANESE INTERMEDIATE CODE: A131Effective date: 20200713 |
|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20201012 |
|
TRDD | Decision of grant or rejection written | ||
A01 | Written decision to grant a patent or to grant a registration (utility model) |
Free format text: JAPANESE INTERMEDIATE CODE: A01Effective date: 20201124 |
|
A61 | First payment of annual fees (during grant procedure) |
Free format text: JAPANESE INTERMEDIATE CODE: A61Effective date: 20201224 |
|
R150 | Certificate of patent or registration of utility model |
Ref document number: 6817431Country of ref document: JPFree format text: JAPANESE INTERMEDIATE CODE: R150 |
|
R250 | Receipt of annual fees |
Free format text: JAPANESE INTERMEDIATE CODE: R250 |