JP2022523666A - Composite model scaling for neural networks - Google Patents
Composite model scaling for neural networks Download PDFInfo
- Publication number
- JP2022523666A JP2022523666A JP2021542494A JP2021542494A JP2022523666A JP 2022523666 A JP2022523666 A JP 2022523666A JP 2021542494 A JP2021542494 A JP 2021542494A JP 2021542494 A JP2021542494 A JP 2021542494A JP 2022523666 A JP2022523666 A JP 2022523666A
- Authority
- JP
- Japan
- Prior art keywords
- baseline
- factor
- architecture
- resolution
- depth
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
- 238000013528 artificial neural network Methods 0.000 title claims abstract description 77
- 239000002131 composite material Substances 0.000 title claims abstract description 40
- 238000000034 method Methods 0.000 claims abstract description 47
- 238000010801 machine learning Methods 0.000 claims abstract description 29
- 238000003860 storage Methods 0.000 claims description 16
- 150000001875 compounds Chemical class 0.000 claims description 3
- 238000012545 processing Methods 0.000 description 16
- 230000008569 process Effects 0.000 description 15
- 238000004590 computer program Methods 0.000 description 14
- 238000013527 convolutional neural network Methods 0.000 description 14
- 230000009471 action Effects 0.000 description 10
- 230000001537 neural effect Effects 0.000 description 9
- 238000004891 communication Methods 0.000 description 6
- 238000012549 training Methods 0.000 description 5
- 230000000306 recurrent effect Effects 0.000 description 4
- 238000013461 design Methods 0.000 description 3
- 230000004044 response Effects 0.000 description 3
- 238000010586 diagram Methods 0.000 description 2
- 230000006870 function Effects 0.000 description 2
- 230000003993 interaction Effects 0.000 description 2
- 238000003062 neural network model Methods 0.000 description 2
- 230000003287 optical effect Effects 0.000 description 2
- 238000013515 script Methods 0.000 description 2
- 238000000926 separation method Methods 0.000 description 2
- 241000009334 Singa Species 0.000 description 1
- 230000004913 activation Effects 0.000 description 1
- 230000001149 cognitive effect Effects 0.000 description 1
- 238000005520 cutting process Methods 0.000 description 1
- 238000001514 detection method Methods 0.000 description 1
- 239000004973 liquid crystal related substance Substances 0.000 description 1
- 238000004519 manufacturing process Methods 0.000 description 1
- 230000004048 modification Effects 0.000 description 1
- 238000012986 modification Methods 0.000 description 1
- 238000005457 optimization Methods 0.000 description 1
- 230000001902 propagating effect Effects 0.000 description 1
- 238000005070 sampling Methods 0.000 description 1
- 239000004065 semiconductor Substances 0.000 description 1
- 230000001953 sensory effect Effects 0.000 description 1
- 238000010200 validation analysis Methods 0.000 description 1
- 230000000007 visual effect Effects 0.000 description 1
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/082—Learning methods modifying the architecture, e.g. adding, deleting or silencing nodes or connections
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/045—Combinations of networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/06—Physical realisation, i.e. hardware implementation of neural networks, neurons or parts of neurons
- G06N3/063—Physical realisation, i.e. hardware implementation of neural networks, neurons or parts of neurons using electronic means
Abstract
特定の機械学習タスクを実施するニューラルネットワークの最終アーキテクチャを決定するための方法について説明される。方法は、ニューラルネットワークのベースラインアーキテクチャを受信することであって、ベースラインアーキテクチャが、ネットワーク幅次元、ネットワーク深さ次元、および解像度次元を有する、受信することと、ベースラインアーキテクチャをスケーリングするのに使用される追加の計算リソースを制御する複合係数を定義したデータを受信することと、ベースライン幅係数、ベースライン深さ係数、およびベースライン解像度係数を決定するように探索を実施することであって、ベースライン幅係数、ベースライン深さ係数、およびベースライン解像度係数はそれぞれ、追加の計算リソースをベースラインアーキテクチャのネットワーク幅次元、ネットワーク深さ次元、および解像度次元にどのように割り当てるかを指定するものである、実施することと、ベースライン幅係数、ベースライン深さ係数、およびベースライン解像度係数、ならびに複合係数に基づいて、幅係数、深さ係数、および解像度係数を決定することと、ベースラインアーキテクチャのネットワーク幅次元、ネットワーク深さ次元、および解像度次元を、対応する幅係数、深さ係数、および解像度係数に基づいてスケーリングした最終アーキテクチャを生成することとを含む。Describes how to determine the final architecture of a neural network that performs a particular machine learning task. The method is to receive the baseline architecture of the neural network, where the baseline architecture has a network width dimension, a network depth dimension, and a resolution dimension, to receive and to scale the baseline architecture. Receiving data defining complex coefficients that control the additional computational resources used, and performing a search to determine the baseline width factor, baseline depth factor, and baseline resolution factor. The baseline width factor, baseline depth factor, and baseline resolution factor specify how to allocate additional computational resources to the network width, network depth, and resolution dimensions of the baseline architecture, respectively. To do, to determine the width factor, depth factor, and resolution factor based on the baseline width factor, baseline depth factor, and baseline resolution factor, as well as the composite factor. Includes generating the final architecture by scaling the network width, network depth, and resolution dimensions of the baseline architecture based on the corresponding width, depth, and resolution coefficients.
Description
関連出願の相互参照
本出願は、2019年1月23日に出願した米国仮出願第62/796,034号の優先権を主張するものである。先行出願の開示は、本出願の開示の一部と見なされ、参照により本出願の開示に組み込まれている。
Cross-reference to related applications This application claims the priority of US Provisional Application No. 62 / 796,034 filed January 23, 2019. The disclosure of the prior application is considered part of the disclosure of this application and is incorporated by reference into the disclosure of this application.
本明細書は、畳み込みニューラルネットワークのアーキテクチャを決定することに関する。 This specification relates to determining the architecture of a convolutional neural network.
ニューラルネットワークは、非線形ユニットの1つまたは複数の層を用いて、受信した入力についての出力を予測する、機械学習モデルである。一部のニューラルネットワークは、出力層に加えて、1つまたは複数の隠れ層を含む。各隠れ層の出力が、ネットワーク内の次の層、すなわち次の隠れ層または出力層への入力として使用される。ネットワークの各層が、受信した入力から、それぞれに対応するパラメータセットの現在値に従って出力を生成する。 A neural network is a machine learning model that uses one or more layers of a nonlinear unit to predict the output for a received input. Some neural networks include one or more hidden layers in addition to the output layer. The output of each hidden layer is used as an input to the next layer in the network, namely the next hidden layer or output layer. Each layer of the network produces an output from the received input according to the current value of the corresponding parameter set.
一部のニューラルネットワークは、再帰型ニューラルネットワークである。再帰型ニューラルネットワークは、入力系列を受信し、入力系列から出力系列を生成する、ニューラルネットワークである。具体的には、再帰型ニューラルネットワークは、現在の時間ステップにおける出力を計算する際に、以前の時間ステップからのネットワークの内部状態の一部または全部を使用することができる。再帰型ニューラルネットワークの一例が、長短期(LSTM)ニューラルネットワークであり、これは、1つまたは複数のLSTMメモリブロックを含むものである。各LSTMメモリブロックは、1つまたは複数のセルを含むことができ、セルはそれぞれ、入力ゲート、忘却ゲート、および出力ゲートを含み、それらのゲートにより、セルが、例えば現在の活性化を生じさせる際に使用する、またはLSTMニューラルネットワークの他のコンポーネントに提供される、そのセルの以前の状態を格納することが可能になっている。 Some neural networks are recurrent neural networks. A recurrent neural network is a neural network that receives an input sequence and generates an output sequence from the input sequence. Specifically, recurrent neural networks can use some or all of the internal state of the network from the previous time step when calculating the output at the current time step. An example of a recurrent neural network is a long short-term (LSTM) neural network, which contains one or more LSTM memory blocks. Each LSTM memory block can contain one or more cells, each of which contains an input gate, an oblivion gate, and an output gate, through which the cell causes, for example, the current activation. It is possible to store the previous state of the cell, which is used when or provided to other components of the LSTM neural network.
本明細書では、1つまたは複数の位置にある1つまたは複数のコンピュータ上にコンピュータプログラムとして実装され、ベースラインアーキテクチャからニューラルネットワークの最終アーキテクチャを決定する、システムについて説明する。下で説明するように、最終アーキテクチャは、最終アーキテクチャのターゲット計算リソース使用量に基づいて決定される。したがって、システムは、最終アーキテクチャによる使用に利用できる低レベルの計算リソース(例えば1秒当たりの浮動小数点演算回数、すなわちFLOPS)に適合する最終アーキテクチャを決定することができる。さらに、システムはそれを、広範なハイパーパラメータチューニングを必要とすることのある従来の手法よりも効率的に行うことができる。ニューラルネットワークは、それに限定されないが画像処理(例えば画像分類)など、特定の機械学習タスクを実施するように構成されている。 This specification describes a system that is implemented as a computer program on one or more computers in one or more locations and determines the final architecture of the neural network from the baseline architecture. As described below, the final architecture is determined based on the target computational resource usage of the final architecture. Therefore, the system can determine the final architecture that fits the low-level computational resources available for use by the final architecture (eg, the number of floating point operations per second, or FLOPS). Moreover, the system can do it more efficiently than traditional methods that may require extensive hyperparameter tuning. Neural networks are configured to perform specific machine learning tasks, such as, but not limited to, image processing (eg, image classification).
本明細書において説明する本主題は、特定の実施形態において、次の利点のうちの1つまたは複数を実現するように実装することができる。畳み込みニューラルネットワークは一般に、固定の計算コストで開発され、次いで、より多くのリソースが与えられた場合に、より良好な精度を得るためにより大型のネットワークにスケールアップされる。本明細書において説明するモデルスケーリング技法では、ターゲットリソース制約が与えられると、モデル効率を維持しながら、単純ではあるが大いに効果的な複合係数を使用してベースラインニューラルネットワークモデルをターゲットのモデルにスケーリングする。従来の方法では、スケーリング中にネットワークの幅、または深さ、または解像度を任意に増大させており、その結果、精度および効率が低く、またニューラルネットワークモデルをスケールアップするプロセスが、これら3つの要素のバランスをとるために必要なハイパーパラメータチューニングのため、非効率で計算コストの高いものとなっている。対照的に、ここで説明する技法では、ベースラインモデルのネットワークの幅、深さ、および解像度を、複合係数を使用して線形スケーリングし、したがって、著しい計算リソースをハイパーパラメータチューニングに費やすことが回避されている。加えて、本明細書において説明するモデルスケーリング技法では、ベースラインモデルが非常に効果的にスケールアップされることが可能であり、その結果、以前の最先端モデルよりもパラメータが少ないながらも最先端の精度を凌駕する、より大型のモデルがもたらされる。同時に、これらのより大型のモデルは、特定の機械学習タスクを、以前の最先端モデルが使用するよりも少ない回数の演算を使用して実施することができ、したがって、これらのより大型のモデルのほうがトレーニングおよび推論時に高速である。 The subject matter described herein can be implemented to realize one or more of the following advantages in a particular embodiment: Convolutional neural networks are generally developed at a fixed computational cost and then scaled up to larger networks for better accuracy given more resources. The model scaling techniques described herein, given target resource constraints, use a simple but highly effective composite coefficient to model the baseline neural network model while maintaining model efficiency. Scale. Traditional methods arbitrarily increase the width, depth, or resolution of the network during scaling, resulting in low accuracy and efficiency, and the process of scaling up the neural network model is these three factors. Due to the hyperparameter tuning required to balance the above, it is inefficient and expensive to calculate. In contrast, the techniques described here linearly scale the network width, depth, and resolution of the baseline model using compound coefficients, thus avoiding spending significant computational resources on hyperparameter tuning. Has been done. In addition, the model scaling techniques described herein allow the baseline model to be scaled up very effectively, resulting in less parameters but cutting edge than previous state-of-the-art models. It brings a larger model that surpasses the accuracy of. At the same time, these larger models can perform certain machine learning tasks using fewer operations than previous state-of-the-art models use, and therefore of these larger models. It is faster during training and reasoning.
本明細書において説明する本主題の1つまたは複数の実施形態の詳細は、添付の図面および下の説明中に記載されている。本主題の他の特徴、態様、および利点が、説明、図面、および特許請求の範囲から明らかとなろう。 Details of one or more embodiments of the subject described herein are described in the accompanying drawings and in the description below. Other features, aspects, and advantages of this subject will become apparent from the description, drawings, and claims.
さまざまな図面中の同様の参照番号および名称は、同様の要素を示す。 Similar reference numbers and names in various drawings indicate similar elements.
本明細書では、1つまたは複数の位置にある1つまたは複数のコンピュータ上にコンピュータプログラムとして実装され、ベースラインアーキテクチャからニューラルネットワークの最終アーキテクチャを決定する、ニューラルアーキテクチャ探索システムについて説明する。ニューラルネットワークは、特定の機械学習タスクを実施するように構成されている。 This specification describes a neural architecture search system that is implemented as a computer program on one or more computers in one or more locations and determines the final architecture of the neural network from the baseline architecture. Neural networks are configured to perform specific machine learning tasks.
一般に、ニューラルネットワークは、ネットワーク入力を受信するように、またそのネットワーク入力を処理してその入力についてのネットワーク出力を生成するように構成される。 In general, a neural network is configured to receive a network input and to process the network input to produce a network output for that input.
いくつかの場合には、ニューラルネットワークは、入力画像を受信するように、またその入力画像を処理してその入力画像についてのネットワーク出力を生成するように、すなわち何らかの種類の画像処理タスクを実施するように構成された、畳み込みニューラルネットワークである。 In some cases, the neural network performs some sort of image processing task to receive the input image and to process the input image to produce network output for the input image. It is a convolutional neural network configured as follows.
例えば、タスクは画像分類とすることができ、ニューラルネットワークによって所与の画像について生成される出力は、物体カテゴリセットのそれぞれについてのスコアであって、各スコアが、画像がそのカテゴリに属する物体の画像を含む推定可能性を表す、スコアとすることができる。 For example, the task can be an image classification, and the output produced by the neural network for a given image is a score for each of the object category sets, where each score is for an object to which the image belongs to that category. It can be a score that represents the estimability including the image.
別の例として、タスクは画像埋め込み(image embedding)の生成とすることができ、ニューラルネットワークによって生成される出力は、入力画像の数値埋め込みとすることができる。例として、それぞれの入力画像について生成された埋め込み間の埋め込み空間内での近接性は、それらの画像間の類似性を表すものであり得る。 As another example, the task can be the generation of an image embedding, and the output generated by the neural network can be the numerical embedding of the input image. As an example, the proximity within the embedding space between the embeddings generated for each input image can represent the similarity between those images.
さらに別の例として、タスクは物体検出とすることができ、ニューラルネットワークによって生成される出力は、入力画像中の、特定のタイプの物体が描かれた位置を特定することができる。 As yet another example, the task can be object detection, and the output produced by the neural network can pinpoint where a particular type of object is drawn in the input image.
他のいくつかの場合には、タスクはビデオ分類とすることができ、ニューラルネットワークは、入力としてビデオまたはビデオの一部分を受信するように、またその入力ビデオまたはビデオの一部分が1つまたは複数のどのような話題に関係するかを特定する出力を生成するように構成される。 In some other cases, the task can be a video classification, so that the neural network receives the video or part of the video as input, and the input video or part of the video is one or more. It is configured to generate output that identifies what topic it relates to.
いくつかの他の場合には、タスクは音声認識とすることができ、ニューラルネットワークは、入力としてオーディオデータを受信するように、また所与の音声による発話(spoken utterance)について、その発話が表す1つまたは複数の言葉を特定する出力を生成するように構成される。 In some other cases, the task can be speech recognition, and the neural network represents to receive audio data as input, and for a given spoken utterance. It is configured to produce output that identifies one or more words.
いくつかの他の場合には、タスクはテキスト分類とすることができ、ニューラルネットワークは、入力テキストセグメントを受信するように、また入力テキストセグメントが1つまたは複数のどのような話題に関係するかを特定する出力を生成するように構成される。 In some other cases, the task can be a text classification, so that the neural network receives the input text segment, and what topic the input text segment relates to, one or more. It is configured to produce output that identifies.
図1は、ベースラインアーキテクチャから、特定の機械学習タスクを実施するように構成されているニューラルネットワークの最終アーキテクチャを決定するように構成された、例示的なニューラルアーキテクチャ探索システム100を示す。ニューラルアーキテクチャ探索システム100は、1つまたは複数の位置にある1つまたは複数のコンピュータ上にコンピュータプログラムとして実装されたシステムの例であり、下で説明するシステム、コンポーネント、および技法はこのシステムにおいて実装することができる。 FIG. 1 shows an exemplary neural architecture exploration system 100 configured to determine the final architecture of a neural network that is configured to perform a particular machine learning task from a baseline architecture. The Neural Architecture Search System 100 is an example of a system implemented as a computer program on one or more computers in one or more locations, and the systems, components, and techniques described below are implemented in this system. can do.
一般に、ニューラルアーキテクチャ探索システム100は、ニューラルネットワークのベースラインアーキテクチャ102と、ベースラインアーキテクチャをスケーリングするのに使用される追加の計算リソースを制御する複合係数103を定義した入力データ104とを取得し、ベースラインアーキテクチャ102の全ての次元を、単純ではあるが大いに効果的な複合係数を使用して一様にスケーリングし、特定の機械学習タスクを実施するニューラルネットワークの最終アーキテクチャ126を生成する、システムである。 In general, the neural architecture search system 100 obtains the baseline architecture 102 of the neural network and the input data 104 defining the composite factor 103 that controls the additional computational resources used to scale the baseline architecture. In a system that uniformly scales all dimensions of baseline architecture 102 using simple but highly effective composite coefficients to produce the final architecture 126 of a neural network that performs specific machine learning tasks. be.
システム100は、ベースラインアーキテクチャ102および入力データ104を、多様な方途のいずれかで受信することができる。例えば、システム100は、ベースラインアーキテクチャ102およびターゲットリソース使用量データ104を、例えばシステム100が利用可能にしているアプリケーションプログラミングインターフェース(API)を使用して、システムの遠隔ユーザからのアップロードとしてデータ通信ネットワーク経由で受信することができる。別の例として、システム100は、システム100によってすでに維持されているどのデータを、ベースラインアーキテクチャ102を特定するデータとして、またターゲットリソース使用量データ104として使用すべきかを特定する、ユーザからの入力を受信することができる。 The system 100 can receive the baseline architecture 102 and the input data 104 in any of a variety of ways. For example, the system 100 may upload the baseline architecture 102 and the target resource usage data 104, eg, using the application programming interface (API) made available by the system 100, as a data communication network as an upload from a remote user of the system. It can be received via. As another example, system 100 specifies from user input which data already maintained by system 100 should be used as data to identify baseline architecture 102 and as target resource usage data 104. Can be received.
入力データ104は、ベースラインアーキテクチャをスケーリングするのに使用される追加の計算リソースを制御する複合係数103を定義する。換言すれば、複合係数103は、ベースラインアーキテクチャが使用するリソースに比べてスケーリング後の最終アーキテクチャが使用することのできる計算リソース量を制御する。いくつかの場合には、システム100は、複合係数の値を、ユーザの制約に基づいて生成することができる。例えば、ユーザがベースラインアーキテクチャ(102)をN倍大きくしたい場合、システムは複合係数φ=log2(N)を生成することができる。例として、ユーザがベースラインアーキテクチャを4倍拡大したい場合、φ=2である。ユーザがベースラインモデルを32倍拡大したい場合、φ=5である。 The input data 104 defines a composite factor 103 that controls the additional computational resources used to scale the baseline architecture. In other words, the composite factor 103 controls the amount of computational resources available to the scaled final architecture compared to the resources used by the baseline architecture. In some cases, the system 100 can generate the value of the composite factor based on the user's constraints. For example, if the user wants to increase the baseline architecture (102) by N times, the system can generate a composite coefficient φ = log 2 (N). As an example, if the user wants to scale the baseline architecture four times, φ = 2. If the user wants to magnify the baseline model 32 times, φ = 5.
入力データ104はさらに、最終アーキテクチャによって使用されるターゲット計算リソース量を指定することができる。具体的には、ターゲットリソース使用量データは、(i)最終アーキテクチャを作成するために許容される最大メモリサイズを示すターゲットメモリサイズ、すなわち、最終アーキテクチャのパラメータおよびアーキテクチャデータによって占有され得る最大記憶容量、ならびに(ii)特定の機械学習タスクを実施するために最終アーキテクチャが実行することのできる最大演算回数を示すターゲット演算回数(例えばFLOPS)を指定する。 The input data 104 can also specify the amount of target computational resources used by the final architecture. Specifically, the target resource usage data is (i) the target memory size that indicates the maximum memory size allowed to create the final architecture, i.e., the maximum storage capacity that can be occupied by the parameters and architecture data of the final architecture. , And (ii) specify a target number of operations (eg FLOPS) that indicates the maximum number of operations that the final architecture can perform to perform a particular machine learning task.
ベースラインアーキテクチャ102は、特定の機械学習タスクを実施するようにトレーニングされたアーキテクチャである。ベースラインアーキテクチャ102は、ネットワーク幅次元、ネットワーク深さ次元、および解像度次元を有する。ベースラインアーキテクチャ102は、複数のニューラルネットワーク層を有する。いくつかの実装形態では、ベースラインアーキテクチャ102は、複数のネットワークステージを有し、複数のネットワークステージがそれぞれ、複数のニューラルネットワーク層を有する。ネットワークステージは、同一タイプのニューラルネットワーク層からなるグループを含む。それは、ベースラインアーキテクチャの各ネットワークステージ内の複数のニューラルネットワーク層が、同一アーキテクチャを共有する、すなわち同一サイズの入力テンソルに対して同一タイプの演算を実施して同一サイズの出力テンソルを生成する、ということを意味する。 Baseline architecture 102 is an architecture trained to perform specific machine learning tasks. The baseline architecture 102 has a network width dimension, a network depth dimension, and a resolution dimension. The baseline architecture 102 has a plurality of neural network layers. In some implementations, the baseline architecture 102 has multiple network stages, each with a plurality of neural network layers. The network stage contains a group of neural network layers of the same type. That is, multiple neural network layers within each network stage of the baseline architecture share the same architecture, i.e. perform the same type of operations on input tensors of the same size to produce output tensors of the same size. It means that.
ベースラインアーキテクチャ102のネットワーク深さ次元は、ベースラインアーキテクチャの複数のネットワークステージ内の層の数のセットである。ベースラインアーキテクチャ102内の各ニューラルネットワーク層は、前層から入力テンソルを受信するように、またその入力テンソルについて、次ニューラルネットワーク層に入力として供給される出力テンソルを生成するように構成される。任意の所与の層への入力テンソルは、高さ次元、幅次元、および入力テンソル内のチャネルの数を指定するチャネル次元を有する。 The network depth dimension of baseline architecture 102 is a set of layers within multiple network stages of the baseline architecture. Each neural network layer in baseline architecture 102 is configured to receive an input tensor from the previous layer and for that input tensor to generate an output tensor that is fed as input to the next neural network layer. The input tensor to any given layer has a height dimension, a width dimension, and a channel dimension that specifies the number of channels in the input tensor.
ベースラインアーキテクチャ102のネットワーク幅次元は、ベースラインアーキテクチャ102の複数のニューラルネットワーク層への入力テンソルに関連する入力チャネルの数のセットである。 The network width dimension of baseline architecture 102 is a set of number of input channels associated with an input tensor to multiple neural network layers of baseline architecture 102.
ベースラインアーキテクチャ102の解像度次元は、ベースラインアーキテクチャ102の複数のニューラルネットワーク層への入力テンソルの高さ次元と幅次元のセットである。 The resolution dimension of baseline architecture 102 is a set of height and width dimensions of the input tensors to multiple neural network layers of baseline architecture 102.
例えば、ベースラインアーキテクチャ102は、
図3は、5つのステージを有するベースラインアーキテクチャ102の例を示す。この例示的なアーキテクチャでは、空間次元(高さ次元および幅次元)は次第に縮小されているが、チャネル次元は層にわたって、例えば初期入力形状(224,224,3)から最終出力形状(7,7,512)に拡張されている。 Figure 3 shows an example of a baseline architecture 102 with five stages. In this exemplary architecture, the spatial dimensions (height and width dimensions) are gradually reduced, but the channel dimensions span layers, eg, from the initial input shape (224,224,3) to the final output shape (7,7,512). It has been expanded.
最良の層アーキテクチャFiを見出すこと(すなわち層Fiによって実施される最良タイプの演算を見出すこと)に主として焦点をあてた以前の手法とは異なり、本明細書において説明するモデルスケーリング技法は、ベースラインアーキテクチャ102における事前定義されたFiを変更することなく、ネットワークの長さ(Li)、幅(Ci)、および/または解像度(Hi;Wi)を拡張させる。層Fiの演算タイプを固定することによって、本明細書において説明するモデルスケーリング技法は、以前の手法に比べて、新たなリソース制約についての設計の問題を単純にする。しかし、各層について異なるLi;Ci;Hi;Wiの可能な組合せを探求すべき大きな設計空間が依然として残っている。設計空間をさらに低減させるために、システム100は、全ての層が一定比で一様にスケーリングされなければならないという制限をかけることができる。 Unlike previous methods that primarily focused on finding the best layer architecture Fi (ie, finding the best type of operations performed by layer Fi ), the model scaling techniques described herein are: Extend network length (L i ), width (C i ), and / or resolution (H i ; Wi ) without changing the predefined Fi in baseline architecture 102. By fixing the operational type of layer Fi, the model scaling technique described herein simplifies the design problem with new resource constraints compared to previous techniques. However, there is still a large design space to explore possible combinations of different L i ; C i ; H i ; Wi i for each layer. To further reduce the design space, the system 100 can impose a restriction that all layers must be scaled uniformly at a constant ratio.
入力データ104によって指定されたターゲット計算リソース量が与えられると、システム100は、所与の計算リソース制約についてモデル精度を最大化しようとし、これは、以下の最適化問題として定式化することができる。
上式で、w、d、rはそれぞれ、ネットワーク幅次元、ネットワーク深さ次元、および解像度次元をスケーリングするための幅係数、深さ係数、および解像度係数であり、
一般に、ベースラインアーキテクチャから最終アーキテクチャを決定するために、システム100は複合スケーリング方法を用い、これは、複合係数φを使用して、ネットワーク幅次元ネットワーク深さ次元、および解像度次元を、一定の原則に基づいて一様にスケーリングするものである。例えば、複合スケーリング方法は次のように表現することができる。
深さ:d=αφ
幅:w=βφ
解像度:r=γφ (3)
s.t. α・β2・γ2≒2
α≧1、β≧1、γ≧1
上式で、α、β、γはそれぞれ、ベースライン深さ係数、ベースライン幅係数、およびベースライン解像度係数である。α、β、γは、上記の式2および式3に基づいて、探索によって、例えばグリッドサーチによって決定することができる。直感的には、φは、モデルスケーリングにあとどれだけのリソースが利用可能であるかを制御し、一方、α、β、γはそれぞれ、これらの追加のリソースをネットワーク深さ次元、ネットワーク幅次元、および解像度次元にどのように割り当てるかを指定するものである。通常の畳み込み演算の演算回数(すなわちFLOPS)は、d、w2、r2に比例し、すなわち、ネットワーク深さ次元を2倍にすると、FLOPSは2倍になるが、ネットワーク幅次元または解像度次元を2倍にすると、FLOPSは4倍に増加することに留意されよう。ベースラインアーキテクチャが畳み込みニューラルネットワークであるとき、畳み込み演算がベースラインアーキテクチャにおける計算コストを支配しており、したがって、ベースラインアーキテクチャを式3を用いてスケーリングすると、合計FLOPSがおよそ(α・β2・γ2)φだけ増加する。α・β2・γ2≒2という制約により、任意の複合係数φについて、合計演算(すなわちFLOPS())がおよそ2φだけ増加することが確実になる。
In general, to determine the final architecture from the baseline architecture, the system 100 uses a composite scaling method, which uses the composite factor φ to determine the network width dimension, the network depth dimension, and the resolution dimension, in a certain principle. It scales uniformly based on. For example, the composite scaling method can be expressed as follows.
Depth: d = α φ
Width: w = β φ
Resolution: r = γ φ (3)
st α ・ β 2・ γ 2 ≒ 2
α ≧ 1, β ≧ 1, γ ≧ 1
In the above equation, α, β, and γ are the baseline depth coefficient, the baseline width coefficient, and the baseline resolution coefficient, respectively. α, β, γ can be determined by search, for example, by grid search, based on the above equations 2 and 3. Intuitively, φ controls how much more resources are available for model scaling, while α, β, and γ use these additional resources in the network depth dimension and network width dimension, respectively. , And how to assign to the resolution dimension. The number of operations of a normal convolution operation (ie FLOPS) is proportional to d, w 2 , r 2 , that is, doubling the network depth dimension doubles FLOPS, but the network width dimension or resolution dimension. Note that doubling will increase FLOPS by a factor of four. When the baseline architecture is a convolutional neural network, the convolutional operation dominates the computational cost in the baseline architecture, so scaling the baseline architecture using Equation 3 yields a total FLOPS of approximately (α · β 2 ·. γ 2 ) Increases by φ . The constraint α · β 2 · γ 2 ≈ 2 ensures that the sum operation (ie FLOPS ()) increases by approximately 2 φ for any composite coefficient φ.
最終アーキテクチャ126を決定するために、システム100は、ベースライン深さ係数α(110)、ベースライン幅係数β(108)、およびベースライン解像度係数γ(112)を探索するように探索(例えばグリッドサーチ、ランダムサーチ、または他の探索ストラテジ)を実施し、ベースライン深さ係数α(110)、ベースライン幅係数β(108)、およびベースライン解像度係数γ(112)はそれぞれ、追加の計算リソースをベースラインアーキテクチャのネットワーク深さ次元、ネットワーク幅次元、および解像度次元にどのように割り当てるかを指定するものである。探索の実施については、下で図2を参照して詳細に説明する。 To determine the final architecture 126, the system 100 searches to search for the baseline depth factor α (110), baseline width factor β (108), and baseline resolution factor γ (112) (eg, grid). Perform a search, random search, or other search strategy), and the baseline depth factor α (110), baseline width factor β (108), and baseline resolution factor γ (112) are additional computational resources, respectively. Specifies how to assign to the network depth dimension, network width dimension, and resolution dimension of the baseline architecture. The implementation of the search will be described in detail with reference to Figure 2 below.
システム100は、複合係数103の値およびベースライン幅係数108に基づいて、幅係数114を生成し、複合係数103の値およびベースライン深さ係数110に基づいて、深さ係数116を生成し、複合係数103の値およびベースライン解像度係数112に基づいて、解像度係数118を生成する。
The system 100 generates a width factor 114 based on the value of the composite factor 103 and a
例えば、いくつかの実装形態では、システム100は、上記の式3を使用して幅係数、深さ係数、および解像度係数を生成することができる。 For example, in some implementations, the system 100 can use Equation 3 above to generate the width factor, depth factor, and resolution factor.
いくつかの他の実装形態では、下の式4に示すように、システム100は、定数と、ベースライン幅係数108と複合係数103の値の積とを加算することによって、幅係数114を生成することができる。システム100は、定数と、ベースライン深さ係数110と複合係数103の値の積とを加算することによって、深さ係数116を生成することができる。システム100は、定数と、ベースライン解像度係数112と複合係数103の値の積とを加算することによって、解像度係数118を生成することができる。
式4:
ネットワーク深さ係数:d=1+α・φ
ネットワーク幅係数:w=1+β・φ
ネットワーク解像度係数:r=1+γ・φ
In some other implementations, system 100 produces a width factor 114 by adding a constant and the product of the
Equation 4:
Network depth coefficient: d = 1 + α ・ φ
Network width coefficient: w = 1 + β ・ φ
Network resolution coefficient: r = 1 + γ ・ φ
複合係数について深さ係数、幅係数、および解像度係数(d,w,r)が生成された後、システム100は、ベースラインアーキテクチャ102のネットワーク深さ次元、ネットワーク幅次元、および解像度次元を、対応する深さ係数、幅係数、および解像度係数に基づいてスケーリングすることによって、最終アーキテクチャ126を生成する。具体的には、システム100は、ベースラインアーキテクチャ102のネットワーク幅次元を、幅係数によってスケーリングし、ベースラインアーキテクチャ102のネットワーク深さ次元を、深さ係数によってスケーリングし、ベースラインアーキテクチャ102の解像度を、解像度係数によってスケーリングして、最終アーキテクチャ126を生成する。 After the depth factor, width factor, and resolution factor (d, w, r) are generated for the composite factor, System 100 accommodates the network depth dimension, network width dimension, and resolution dimension of baseline architecture 102. Generate the final architecture 126 by scaling based on the depth factor, width factor, and resolution factor. Specifically, the system 100 scales the network width dimension of the baseline architecture 102 by the width factor, the network depth dimension of the baseline architecture 102 by the depth factor, and the resolution of the baseline architecture 102. , Scaling by the resolution factor to produce the final architecture 126.
次いで、システム100は、ニューラルネットワークの最終アーキテクチャを指定するアーキテクチャデータ150、すなわち、最終アーキテクチャの一部である層、これらの層間の接続性、およびこれらの層によって実施される演算を指定するデータを出力することができる。例えば、システム100は、アーキテクチャデータ150を、トレーニングデータをサブミットしたユーザに出力することができる。いくつかの場合には、データ150は、最終アーキテクチャとして特定された候補アーキテクチャのトレーニングからの、最終アーキテクチャのパラメータのトレーニング済みの値も含む。 The system 100 then provides architectural data 150 that specifies the final architecture of the neural network, that is, the layers that are part of the final architecture, the connectivity between these layers, and the data that specifies the operations performed by these layers. Can be output. For example, the system 100 can output the architecture data 150 to the user who submitted the training data. In some cases, the data 150 also includes trained values of the final architecture parameters from the training of the candidate architecture identified as the final architecture.
いくつかの実装形態では、アーキテクチャデータ150を出力する代わりにまたはそれに加えて、システム100は、最終アーキテクチャを有するニューラルネットワークのインスタンスを、例えば最初から、または最終アーキテクチャとして特定された候補アーキテクチャをトレーニングした結果として生成されたパラメータ値を微調整するように、トレーニングし、次いで、トレーニング済みのニューラルネットワークを使用して、例えばシステム100によって提供されるAPIを通じてユーザによって受信された要求を処理する。すなわち、システム100は、処理すべき入力を受信し、最終アーキテクチャを有するトレーニング済みのニューラルネットワークを使用してその入力を処理し、受信した入力に応答してトレーニング済みのニューラルネットワークによって生成された出力またはその生成された出力から得られたデータを提供することができる。 In some implementations, instead of or in addition to outputting architecture data 150, System 100 trained an instance of a neural network with the final architecture, eg, from the beginning, or a candidate architecture identified as the final architecture. It is trained to fine-tune the resulting parameter values and then uses a trained neural network to process requests received by the user, for example through the API provided by System 100. That is, the system 100 receives the input to be processed, processes the input using a trained neural network with the final architecture, and the output produced by the trained neural network in response to the received input. Alternatively, the data obtained from the generated output can be provided.
図2は、特定の機械学習タスクを実施するニューラルネットワークの最終アーキテクチャを決定するための、例示的なプロセスのフロー図である。便宜上、プロセス200については、1つまたは複数の位置にある1つまたは複数のコンピュータからなるシステムによって実施されているものとして説明する。例えば、適切にプログラムされた、ニューラルアーキテクチャ探索システム、例えば図1のニューラルアーキテクチャ探索システム100が、プロセス200を実施することができる。
FIG. 2 is a flow diagram of an exemplary process for determining the final architecture of a neural network that performs a particular machine learning task. For convenience,
システムは、ニューラルネットワークのベースラインアーキテクチャを受領する(ステップ202)。ベースラインアーキテクチャは、特定の機械学習タスクを実施するようにトレーニングされたものである。ベースラインアーキテクチャは、ネットワーク幅次元、ネットワーク深さ次元、および解像度次元を有する。ベースラインアーキテクチャは、複数のネットワークステージを有し、複数のネットワークステージがそれぞれ、複数のニューラルネットワーク層を有する。ベースラインアーキテクチャの各ネットワークステージ内の複数のニューラルネットワーク層は、同一アーキテクチャを共有する。 The system receives the baseline architecture of the neural network (step 202). The baseline architecture is trained to perform specific machine learning tasks. The baseline architecture has a network width dimension, a network depth dimension, and a resolution dimension. The baseline architecture has a plurality of network stages, each of which has a plurality of neural network layers. Multiple neural network layers within each network stage of the baseline architecture share the same architecture.
ベースラインアーキテクチャのネットワーク深さ次元は、ベースラインアーキテクチャの複数のネットワークステージ内の層の数のセットである。ベースラインアーキテクチャ内の各ニューラルネットワーク層は、前層から入力テンソルを受信するように、またその入力テンソルについて、次ニューラルネットワーク層に入力として供給される出力テンソルを生成するように構成される。入力テンソルは、高さ次元、幅次元、および入力テンソル内のチャネルの数を指定するチャネル次元を有する。 The network depth dimension of a baseline architecture is a set of layers within multiple network stages of the baseline architecture. Each neural network layer in the baseline architecture is configured to receive an input tensor from the previous layer and for that input tensor to generate an output tensor that is fed as input to the next neural network layer. The input tensor has a height dimension, a width dimension, and a channel dimension that specifies the number of channels in the input tensor.
ベースラインアーキテクチャのネットワーク幅次元は、ベースラインアーキテクチャの複数のニューラルネットワーク層への入力テンソルに関連する入力チャネルの数のセットである。 The network width dimension of a baseline architecture is a set of number of input channels associated with an input tensor to multiple neural network layers of the baseline architecture.
ベースラインアーキテクチャの解像度次元は、ベースラインアーキテクチャの複数のニューラルネットワーク層への入力テンソルの高さ次元と幅次元のセットである。 The resolution dimension of the baseline architecture is a set of height and width dimensions of the input tensors to multiple neural network layers of the baseline architecture.
システムは、ベースラインアーキテクチャをスケーリングするのに使用される追加の計算リソースを制御する複合係数を定義した入力データを受領する(ステップ204)。換言すれば、複合係数は、ベースラインアーキテクチャが使用するリソースに比べてスケーリング後の最終アーキテクチャが使用することのできる計算リソース量を制御する。いくつかの場合には、システムは、複合係数の値を、ユーザの制約に基づいて生成することができる。例えば、ユーザがベースラインアーキテクチャ(102)をN倍大きくしたい場合、システムは複合係数φ=log2(N)を生成することができる。例として、ユーザがベースラインアーキテクチャを4倍拡大したい場合、φ=2である。ユーザがベースラインモデルを32倍拡大したい場合、φ=5である。 The system receives input data that defines the complex coefficients that control the additional computational resources used to scale the baseline architecture (step 204). In other words, the composite factor controls the amount of computational resources available to the scaled final architecture compared to the resources used by the baseline architecture. In some cases, the system can generate the value of the composite factor based on the user's constraints. For example, if the user wants to increase the baseline architecture (102) by N times, the system can generate a composite coefficient φ = log 2 (N). As an example, if the user wants to scale the baseline architecture four times, φ = 2. If the user wants to magnify the baseline model 32 times, φ = 5.
入力データはさらに、最終アーキテクチャによって使用されるターゲット計算リソース量を指定することができる。具体的には、ターゲットリソース使用量データは、(i)最終アーキテクチャを作成するために許容される最大メモリサイズを示すターゲットメモリサイズ、すなわち、最終アーキテクチャのパラメータおよびアーキテクチャデータによって占有され得る最大記憶容量、ならびに(ii)特定の機械学習タスクを実施するために最終アーキテクチャが実行することのできる最大演算回数を示すターゲット演算回数を指定する。 The input data can also specify the amount of target computational resources used by the final architecture. Specifically, the target resource usage data is (i) the target memory size that indicates the maximum memory size allowed to create the final architecture, i.e., the maximum storage capacity that can be occupied by the parameters and architecture data of the final architecture. , And (ii) specify a target number of operations that indicates the maximum number of operations that the final architecture can perform to perform a particular machine learning task.
最終アーキテクチャを生成するために、システムは、ベースライン幅係数β、ベースライン深さ係数α、およびベースライン解像度係数γを決定するように探索(例えばグリッドサーチ、ランダムサーチ、または他の探索ストラテジ)を実施し、ベースライン幅係数β、ベースライン深さ係数α、およびベースライン解像度係数γはそれぞれ、追加の計算リソースをベースラインアーキテクチャのネットワーク幅次元、ネットワーク深さ次元、および解像度次元にどのように割り当てるかを指定するものである(ステップ206)。例えば、複合係数の値が1であると仮定し、より大型のモデルに2倍の量のリソースが利用可能であると仮定すると、システムは、式2および式3に基づいてα、β、γのグリッドサーチを実施し、これらのベースライン係数にとって最良の値を次のように見い出す:α・β2・γ2≒2という制約の下でα=1.2、β=1.1、γ=1.15。 To generate the final architecture, the system searches to determine the baseline width factor β, baseline depth factor α, and baseline resolution factor γ (eg grid search, random search, or other search strategy). And how the baseline width factor β, baseline depth factor α, and baseline resolution factor γ each add additional computational resources to the network width dimension, network depth dimension, and resolution dimension of the baseline architecture. Specifies whether to assign to (step 206). For example, assuming that the value of the composite factor is 1, and that twice the amount of resources is available for the larger model, the system will be α, β, γ based on Equations 2 and 3. Perform a grid search of and find the best values for these baseline coefficients as follows: α = 1.2, β = 1.1, γ = 1.15 under the constraint of α · β 2 · γ 2 ≒ 2.
グリッドサーチを実施するために、システムは以下の、
(a)ベースライン幅係数の探索値、ベースライン深さ係数の探索値、およびベースライン解像度係数の探索値を選択するステップと、
(b)(i)複合係数の所与の値、ならびに(ii)ベースライン幅係数の探索値、ベースライン深さ係数の探索値、およびベースライン解像度係数の探索値に基づいて、(例えば式3または式4を使用することによって)探索幅係数w'、探索深さ係数d'、および探索解像度係数r'を生成するステップと、
(c)ベースラインアーキテクチャ、ならびに探索幅係数、探索深さ係数、および探索解像度係数を使用して(例えばベースラインアーキテクチャのネットワーク幅次元を、探索幅係数によってスケーリングし、ベースラインアーキテクチャのネットワーク深さ次元を、探索深さ係数によってスケーリングし、ベースラインアーキテクチャの解像度を、探索解像度係数によってスケーリングすることによって)、探索候補アーキテクチャを生成するステップと、
(d)その探索候補アーキテクチャについて、探索候補アーキテクチャの、特定の機械学習タスクに対する性能を表す性能スコアを特定するステップとを繰り返し実施する。例えば、性能スコアは、探索候補アーキテクチャの、特定の機械学習タスクに対する精度を表す精度スコアとすることができる。具体的には、システムは、探索候補アーキテクチャを有するニューラルネットワークインスタンスを、特定の機械学習タスクに対してトレーニングして、探索候補アーキテクチャを有するこのニューラルネットワークインスタンスのパラメータの値を決定することができる。次いで、システムは、トレーニング済みのニューラルネットワークインスタンスの、特定のニューラルネットワークタスクに対する性能に基づいて、トレーニング済みのニューラルネットワークインスタンスの精度スコアを特定することができる。例えば、精度スコアは、トレーニング済みのインスタンスの、検証セットに対する精度を、適切な精度指標によって測定したものを表すことができる。例として、精度スコアは、出力が系列であるときはパープレキシティ指標(perplexity measure)とすることができ、または特定のニューラルネットワークタスクが分類タスクであるときは誤分類率とすることができる。別の例として、精度スコアは、インスタンスのトレーニングの最終の2回、5回、または10回のエポックのそれぞれについての、インスタンスの精度の平均値または最大値とすることができる。
In order to carry out grid search, the system is as follows,
(a) Steps to select the search value for the baseline width factor, the search value for the baseline depth factor, and the search value for the baseline resolution factor.
Based on (b) (i) a given value of the composite factor, and (ii) a search value for the baseline width factor, a search value for the baseline depth factor, and a search value for the baseline resolution factor (eg, equation). With the steps to generate the search width factor w', the search depth factor d', and the search resolution factor r'(by using 3 or Equation 4),
(c) Using the baseline architecture, as well as the search width factor, search depth factor, and search resolution factor (eg, scaling the network width dimension of the baseline architecture by the search width factor, and the network depth of the baseline architecture. By scaling the dimensions by the search depth factor and the resolution of the baseline architecture by the search resolution factor), the steps to generate the search candidate architecture,
(d) For the search candidate architecture, the step of specifying the performance score representing the performance of the search candidate architecture for a specific machine learning task is repeatedly performed. For example, the performance score can be an accuracy score that represents the accuracy of the search candidate architecture for a particular machine learning task. Specifically, the system can train a neural network instance with a search candidate architecture for a particular machine learning task to determine parameter values for this neural network instance with a search candidate architecture. The system can then determine the accuracy score of the trained neural network instance based on the performance of the trained neural network instance for a particular neural network task. For example, the accuracy score can represent the accuracy of a trained instance against a validation set, measured by an appropriate accuracy index. As an example, the accuracy score can be a perplexity measure when the output is a series, or a misclassification rate when a particular neural network task is a classification task. As another example, the accuracy score can be the mean or maximum accuracy of the instance for each of the last two, five, or ten epochs of training the instance.
次いで、システムは、生成された全ての探索候補アーキテクチャの性能スコアのうちの最大性能スコアに関連する探索値を、ベースライン深さ係数、ベースライン幅係数、およびベースライン解像度係数の最終値として選択する。 The system then selects the search value associated with the maximum performance score of all the generated search candidate architecture performance scores as the final values for the baseline depth factor, baseline width factor, and baseline resolution factor. do.
システムは、ステップ(a)において、ベースライン幅係数、ベースライン深さ係数、およびベースライン解像度係数の探索値を、(ある制約に従うことを条件として)探索について取り得る値のグリッドから各係数の値をサンプリングすることによって、選択することができる。例えば、システムは、α・β2・γ2≒2という制約の下で1から2の間で取り得る値のグリッドから各係数の値をサンプリングすることができる。 In step (a), the system sets the search values for the baseline width factor, baseline depth factor, and baseline resolution factor from a grid of possible values for the search (provided that certain constraints are obeyed). It can be selected by sampling the value. For example, the system can sample the value of each coefficient from a grid of possible values between 1 and 2 under the constraint α, β 2 , γ 2 ≈ 2.
ベースライン幅係数β、ベースライン深さ係数α、およびベースライン解像度係数γを取得した後で、システムは、幅係数、深さ係数、および解像度係数を決定する(ステップ208)。 After obtaining the baseline width factor β, the baseline depth factor α, and the baseline resolution factor γ, the system determines the width factor, depth factor, and resolution factor (step 208).
いくつかの実装形態では、システムは、ベースライン幅係数、ベースライン深さ係数、およびベースライン解像度係数、ならびに複合係数の値に基づいて、式3を使用して幅係数、深さ係数、および解像度係数を生成することができる。 In some implementations, the system uses Equation 3 to use Equation 3 based on the values of the baseline width factor, baseline depth factor, and baseline resolution factor, as well as the composite factor. A resolution factor can be generated.
いくつかの他の実装形態では、式4に示すように、システムは、定数と、ベースライン幅係数と複合係数の値の積とを加算することによって、幅係数を生成することができる。システムは、定数と、ベースライン深さ係数と複合係数の値の積とを加算することによって、深さ係数を生成することができる。システムは、定数と、ベースライン解像度係数と複合係数の値の積とを加算することによって、解像度係数を生成することができる。 In some other implementation, the system can generate a width factor by adding a constant and the product of the baseline width factor and the value of the composite factor, as shown in Equation 4. The system can generate a depth factor by adding a constant and the product of the baseline depth factor and the value of the composite factor. The system can generate a resolution factor by adding a constant to the product of the baseline resolution factor and the value of the composite factor.
システムは、ベースラインアーキテクチャのネットワーク幅次元、ネットワーク深さ次元、および解像度次元をそれぞれ、対応する幅係数、深さ係数、および解像度係数に基づいてスケーリングすることによって、最終アーキテクチャを生成する(ステップ210)。具体的には、システムは、ベースラインアーキテクチャのネットワーク幅次元を、幅係数によってスケーリングし、ベースラインアーキテクチャのネットワーク深さ次元を、深さ係数によってスケーリングし、ベースラインアーキテクチャの解像度を、解像度係数によってスケーリングして、最終アーキテクチャを生成する。 The system produces the final architecture by scaling the network width dimension, network depth dimension, and resolution dimension of the baseline architecture based on the corresponding width, depth, and resolution coefficients, respectively (step 210). ). Specifically, the system scales the network width dimension of the baseline architecture by the width factor, the network depth dimension of the baseline architecture by the depth factor, and the resolution of the baseline architecture by the resolution factor. Scale to produce the final architecture.
次いで、特定された最終アーキテクチャによるニューラルネットワークは、機械学習タスクを実施するために使用され得る。それに加えてまたはその代わりに、特定された最終アーキテクチャを特徴付ける情報が、その最終アーキテクチャを有するニューラルネットワークの構築に使用できるように(例えば遠隔コンピュータシステムに)出力されてもよい。 Neural networks with the identified final architecture can then be used to perform machine learning tasks. In addition to or instead, information characterizing the identified final architecture may be output (eg, to a remote computer system) for use in building neural networks with that final architecture.
いくつかの実装形態では、システムは、プロセス200を複数の異なる複合係数について実施することによって、複数のより大型のアーキテクチャを生成することができる。これにより、システムまたはユーザが、どのより大型のアーキテクチャが最良に適合するか(例えば、生成された複数のより大型のアーキテクチャのうち、どのより大型のアーキテクチャが最良の性能スコアを有するか)を、そのアーキテクチャを任意の所与の時点で実行するのに利用可能なリソース量が与えられた場合(例えば入力データによって指定されたターゲット計算リソース量が与えられた場合)、選択することが可能になり得る。
In some implementations, the system can generate multiple larger architectures by performing
図4は、上述したモデルスケーリング技法を使用してさまざまな最終アーキテクチャを生成するために使用することのできる、別の例示的なベースラインアーキテクチャを示す。ベースラインアーキテクチャ300は、畳み込みニューラルネットワーク層302と、それに続く複数のFusedConvニューラルネットワーク層304と、それに続く複数のMBConvニューラルネットワーク層306とを含む。
Figure 4 shows another exemplary baseline architecture that can be used to generate a variety of final architectures using the model scaling techniques described above. The
FusedConvは、通常の畳み込みニューラルネットワーク副層と、それに続くチャネル方向の(pointwise)畳み込みニューラルネットワーク副層とを含む、畳み込みニューラルネットワーク層の一タイプである。FusedConvでは、空間方向の(depthwise)畳み込みニューラルネットワーク副層は使用されない。 FusedConv is a type of convolutional neural network layer that includes a regular convolutional neural network sublayer followed by a pointwise convolutional neural network sublayer. FusedConv does not use the spatially (depthwise) convolutional neural network sublayer.
MBConvは、チャネル方向の畳み込みニューラルネットワーク副層と、それに続く空間方向の畳み込みニューラルネットワーク副層と、それに続くチャネル方向の畳み込みニューラルネットワーク副層とを含む、畳み込みニューラルネットワーク層の一タイプである。MBConvの例は、Sandler, M.、Howard, A.、Zhu, M.、Zhmoginov, A.、およびChen, L.-C. Mobilenetv2: Inverted residuals and linear bottlenecks. CVPR、2018、ならびにTan, M.、Chen, B.、Pang, R.、Vasudevan, V.、Sandler, M.、Howard, A.、およびLe, Q. V. MnasNet: Platform-aware neural architecture search for mobile. CVPR、2019に見い出すことができる。 MBConv is a type of convolutional neural network layer that includes a channel-direction convolutional neural network sub-layer, followed by a spatial-direction convolutional neural network sub-layer, and a subsequent channel-direction convolutional neural network sub-layer. Examples of MBConv are Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., and Chen, L.-C. Mobilenetv2: Inverted residuals and linear bottlenecks. CVPR, 2018, and Tan, M. , Chen, B., Pang, R., Vasudevan, V., Sandler, M., Howard, A., and Le, Q. V. MnasNet: Platform-aware neural architecture search for mobile. CVPR, 2019.
ベースラインアーキテクチャ300を、複合係数を使用してスケーリングすることによって生成される最終アーキテクチャは、「EfficientNet-Edge TPU」アーキテクチャとも呼ばれることがあり、これは、クラウドにおいてではなくデバイス上で(例えばGoogleのEdge TPU上で)実行されるように設計された専用ハードウェアアクセラレータ上で、最適に実行されるようにカスタマイズされたものである。そのようなモデルカスタマイゼーションを通じて、EfficientNet-Edge TPUアーキテクチャは、実時間画像分類性能をもたらすと同時に、一般にはデータセンタにおいてはるかに大型の計算量の多いモデルを実行する際にしか見られない精度を達成することが可能である。
The final architecture produced by scaling the
本明細書では、システムおよびコンピュータプログラムコンポーネントに関連して「構成される」という用語を使用している。1つまたは複数のコンピュータからなるシステムが、特定の動作またはアクションを実施するように構成されるとは、システムがその上に、動作の際にシステムにその動作またはアクションを実施させるソフトウェア、ファームウェア、ハードウェア、またはそれらの組合せをインストールされる、ということを意味する。1つまたは複数のコンピュータプログラムが、特定の動作またはアクションを実施するように構成されるとは、1つまたは複数のプログラムが、データ処理装置によって実行されると装置にその動作またはアクションを実施させる命令を含む、ということを意味する。 As used herein, the term "configured" is used in connection with system and computer program components. When a system consisting of one or more computers is configured to perform a particular action or action, the software, firmware, software, firmware, on which the system causes the system to perform that action or action upon operation. It means that the hardware, or a combination of them, will be installed. When one or more computer programs are configured to perform a particular action or action, one or more programs cause the device to perform that action or action when executed by the data processing device. It means that it contains an instruction.
本明細書において説明した本主題および機能的動作の実施形態は、デジタル電子回路として、有形に具現化されたコンピュータソフトウェアもしくはファームウェアとして、本明細書において開示した構造およびそれらの構造的等価物を含むコンピュータハードウェアとして、またはそれらのうちの1つもしくは複数のものの組合せとして、実装することができる。本明細書において説明した本主題の実施形態は、データ処理装置によって実行する目的で、またはデータ処理装置の動作を制御するために、有形の非一時的記憶媒体上に符号化された、1つまたは複数のコンピュータプログラム、すなわちコンピュータプログラム命令の1つまたは複数のモジュールとして、実装することができる。コンピュータ記憶媒体は、機械可読記憶デバイス、機械可読記憶基板、ランダムアクセスもしくはシリアルアクセスのメモリデバイス、またはそれらのうちの1つもしくは複数のものの組合せとすることができる。その代わりにまたはそれに加えて、プログラム命令は、情報をデータ処理装置によって実行する目的で適切なレシーバ装置に送信できるように符号化するために生成される、人工的に生成された伝搬信号、例えば機械により生成された電気信号、光信号、または電磁信号上に符号化することもできる。 The subject matter and embodiments of functional operation described herein include, as digital electronic circuits, tangibly embodied computer software or firmware, the structures disclosed herein and their structural equivalents. It can be implemented as computer hardware or as a combination of one or more of them. One embodiment of the subject described herein is encoded on a tangible non-temporary storage medium for the purpose of being performed by a data processing device or to control the operation of the data processing device. Or it can be implemented as multiple computer programs, i.e. one or more modules of computer program instructions. The computer storage medium can be a machine-readable storage device, a machine-readable storage board, a random access or serial access memory device, or a combination of one or more of them. Alternatively or in addition, the program instruction is an artificially generated propagating signal, eg, generated to encode the information so that it can be transmitted to the appropriate receiver device for the purpose of performing it by the data processing device. It can also be encoded on machine-generated electrical, optical, or electromagnetic signals.
「データ処理装置」という用語は、データ処理ハードウェアを指し、例としてプログラマブルプロセッサ、コンピュータ、または複数のプロセッサもしくはコンピュータを含む、データを処理するためのあらゆる種類の装置、デバイス、および機械を包含する。装置は、専用論理回路、例えばFPGA(フィールドプログラマブルゲートアレイ)またはASIC(特定用途向け集積回路)とすることもでき、あるいはそれをさらに含むこともできる。装置は任意選択で、ハードウェアに加えて、コンピュータプログラムのための実行環境を作り出すコード、例えばプロセッサファームウェア、プロトコルスタック、データベース管理システム、オペレーティングシステム、またはそれらのうちの1つもしくは複数のものの組合せを構成するコードを含むこともできる。 The term "data processing equipment" refers to data processing hardware and includes all types of equipment, devices, and machines for processing data, including, for example, programmable processors, computers, or multiple processors or computers. .. The device can be a dedicated logic circuit, such as an FPGA (field programmable gate array) or ASIC (application specific integrated circuit), or can further include it. The device is optional, in addition to the hardware, code that creates an execution environment for computer programs, such as processor firmware, protocol stacks, database management systems, operating systems, or a combination of one or more of them. It can also contain the code that makes up it.
プログラム、ソフトウェア、ソフトウェアアプリケーション、アプリ、モジュール、ソフトウェアモジュール、スクリプト、またはコードとも呼ばれるかまたは説明されることのあるコンピュータプログラムは、コンパイル型言語もしくはインタープリタ型言語、または宣言型言語もしくは手続き型言語を含む、任意の形態のプログラミング言語で記述することができ、またそれは、スタンドアロンプログラムとして、またはモジュール、コンポーネント、サブルーチン、もしくはコンピューティング環境において使用するのに適した他のユニットとして、を含む、任意の形態でデプロイすることができる。プログラムは、その必要はないが、ファイルシステム内のファイルに対応してよい。プログラムは、他のプログラムもしくはデータを保持するファイルの一部分、例えばマークアップ言語ドキュメント内に格納された1つもしくは複数のスクリプト内に、当該のプログラムに専用の単一のファイル内に、または複数の連係されたファイル、例えばコードの1つもしくは複数のモジュール、サブプログラム、もしくは部分を格納するファイル内に格納することができる。コンピュータプログラムは、1つのコンピュータ上で、または1つのサイトに位置するかもしくは複数のサイトにわたって分散され、データ通信ネットワークによって相互接続された複数のコンピュータ上で実行されるように、デプロイすることができる。本明細書では、「データベース」という用語は、データの任意の集合を指すために広義に使用され、データは、任意の特定の様式で構造化されている必要も、全く構造化されている必要もなく、1つまたは複数の位置にある記憶デバイス上に格納されてよい。したがって、例えば、索引データベースは、そのそれぞれが別様に編成およびアクセスされてよいデータの複数の集合を含むことができる。 Computer programs, sometimes referred to or described as programs, software, software applications, apps, modules, software modules, scripts, or code, include compiled or interpreted languages, or declarative or procedural languages. Can be written in any form of programming language, including as a stand-alone program or as a module, component, subroutine, or other unit suitable for use in a computing environment. Can be deployed with. The program does not have to, but may correspond to the files in the file system. A program may be part of a file that holds other programs or data, such as in one or more scripts stored in a markup language document, in a single file dedicated to that program, or in multiples. It can be stored in a linked file, such as a file that contains one or more modules, subprograms, or parts of code. Computer programs can be deployed to run on one computer, or on multiple computers located at one site or distributed across multiple sites and interconnected by a data communication network. .. As used herein, the term "database" is used broadly to refer to any set of data, which needs to be structured in any particular fashion, or even totally structured. It may be stored on a storage device in one or more locations. Thus, for example, an index database can contain multiple sets of data, each of which may be organized and accessed differently.
同様に、本明細書では、「エンジン」という用語は、1つまたは複数の特定の機能を実施するようにプログラムされたソフトウェアベースのシステム、サブシステム、またはプロセスを指すために広義に使用される。一般に、エンジンは、1つまたは複数の位置にある1つまたは複数のコンピュータ上にインストールされた1つまたは複数のソフトウェアモジュールまたはソフトウェアコンポーネントとして実装される。いくつかの場合には、1つまたは複数のコンピュータが特定のエンジンに専用であり、他の場合には、複数のエンジンが、同じ1つまたは複数のコンピュータ上にインストールされ、その上で実行されていてよい。 Similarly, herein, the term "engine" is used broadly to refer to a software-based system, subsystem, or process programmed to perform one or more specific functions. .. Engines are typically implemented as one or more software modules or software components installed on one or more computers in one or more locations. In some cases, one or more computers are dedicated to a particular engine, in other cases multiple engines are installed and run on the same one or more computers. You may be.
本明細書において説明したプロセスおよび論理フローは、機能を実施するための1つまたは複数のコンピュータプログラムを、入力データに作用し出力を生成することにより実行する、1つまたは複数のプログラマブルコンピュータによって実施され得る。プロセスおよび論理フローはまた、専用論理回路、例えばFPGAもしくはASICによって、または専用論理回路と1つもしくは複数のプログラムされたコンピュータとの組合せによって、実施され得る。 The processes and logical flows described herein are performed by one or more programmable computers that execute one or more computer programs to perform functions by acting on input data and producing outputs. Can be done. Processes and logic flows can also be performed by dedicated logic circuits, such as FPGAs or ASICs, or by a combination of dedicated logic circuits and one or more programmed computers.
コンピュータプログラムの実行に適したコンピュータは、汎用マイクロプロセッサ、もしくは専用マイクロプロセッサ、もしくはその両方、または他の任意の種類の中央処理装置に基づいていてよい。一般に、中央処理装置は、読出し専用メモリ、またはランダムアクセスメモリ、またはその両方から、命令およびデータを受信する。コンピュータの必須要素は、命令を実施または実行するための中央処理装置、ならびに命令およびデータを格納するための1つまたは複数のメモリデバイスである。中央処理装置およびメモリは、専用論理回路によって補完するか、またはそれに組み込むことができる。一般に、コンピュータはまた、データを格納するための1つまたは複数の大容量記憶デバイス、例えば磁気ディスク、光磁気ディスク、または光ディスクを含むか、またはそこからデータを受信し、もしくはそこにデータを転送し、もしくはその両方を行うために動作可能に結合される。しかし、コンピュータは、そのようなデバイスを有している必要はない。さらに、コンピュータは別のデバイスに、例えば、ほんの数例を挙げると、モバイル電話、パーソナルデジタルアシスタント(PDA)、モバイルオーディオプレーヤもしくはモバイルビデオプレーヤ、ゲームコンソール、グローバルポジショニングシステム(GPS)レシーバ、またはポータブル記憶デバイス、例えばユニバーサルシリアルバス(USB)フラッシュドライブに埋め込むことができる。 A suitable computer for executing a computer program may be based on a general purpose microprocessor, a dedicated microprocessor, or both, or any other type of central processing unit. In general, the central processing unit receives instructions and data from read-only memory, random access memory, or both. Essential elements of a computer are a central processing unit for executing or executing instructions, as well as one or more memory devices for storing instructions and data. Central processing units and memory can be complemented or incorporated into dedicated logic circuits. In general, a computer also includes or receives data from or transfers data to one or more mass storage devices for storing data, such as magnetic disks, magneto-optical disks, or optical disks. And / or are operably combined to do both. However, the computer does not have to have such a device. In addition, the computer may be another device, for example, a mobile phone, personal digital assistant (PDA), mobile audio player or mobile video player, game console, Global Positioning System (GPS) receiver, or portable storage, to name just a few. It can be embedded in a device, such as a Universal Serial Bus (USB) flash drive.
コンピュータプログラム命令およびデータを格納するのに適したコンピュータ可読媒体としては、例として半導体メモリデバイス、例えばEPROM、EEPROM、およびフラッシュメモリデバイス;磁気ディスク、例えば内蔵ハードディスクまたはリムーバブルディスク;光磁気ディスク;ならびにCD ROMディスクおよびDVD-ROMディスクを含む、あらゆる形態の不揮発性のメモリ、媒体、およびメモリデバイスがある。 Computer-readable media suitable for storing computer program instructions and data include, for example, semiconductor memory devices such as EPROM, EEPROM, and flash memory devices; magnetic disks such as internal hard disks or removable disks; magneto-optical disks; and CDs. There are all forms of non-volatile memory, media, and memory devices, including ROM disks and DVD-ROM disks.
ユーザとの対話を可能にするために、本明細書において説明した本主題の実施形態は、ユーザに情報を表示するためのディスプレイデバイス、例えばCRT(陰極線管)またはLCD(液晶ディスプレイ)モニタと、ユーザがそれによってコンピュータに入力することのできるキーボードおよびポインティングデバイス、例えばマウスまたはトラックボールとを有するコンピュータ上に実装することができる。他の種類のデバイスを使用して、ユーザとの対話を可能にすることもでき、例えば、ユーザに提供されるフィードバックは、任意の形態の感覚フィードバック、例えば視覚フィードバック、聴覚フィードバック、または触覚フィードバックとすることができ、ユーザからの入力は、音響入力、音声入力、または触覚入力を含む、任意の形態で受信することができる。加えて、コンピュータはユーザと、ユーザが使用するデバイスにドキュメントを送り、そこからドキュメントを受信することによって、例えば、ユーザのデバイス上のウェブブラウザに、そのウェブブラウザから受信した要求に応答してウェブページを送ることによって、対話することができる。また、コンピュータはユーザと、メッセージングアプリケーションを実行しているパーソナルデバイス、例えばスマートフォンに、テキストメッセージまたは他の形態のメッセージを送り、ユーザから返信として応答メッセージを受信することによって、対話することもできる。 To enable interaction with the user, embodiments of the subject described herein include display devices for displaying information to the user, such as a CRT (cathode tube) or LCD (liquid crystal display) monitor. It can be implemented on a computer that has a keyboard and pointing device that allows the user to enter into the computer, such as a mouse or trackball. Other types of devices can also be used to enable interaction with the user, for example, the feedback provided to the user may be any form of sensory feedback, such as visual feedback, auditory feedback, or tactile feedback. The input from the user can be received in any form, including acoustic input, voice input, or tactile input. In addition, the computer sends documents to and from the user and the device used by the user, and by receiving the document, for example, to a web browser on the user's device, in response to a request received from that web browser, the web. You can interact by sending pages. The computer can also interact with the user by sending a text message or other form of message to a personal device running a messaging application, such as a smartphone, and receiving a response message as a reply from the user.
機械学習モデルを実装するためのデータ処理装置は、例えば、機械学習のトレーニングの作業負荷または実稼働すなわち推論の作業負荷の、共通の計算集約的部分を処理するための、専用ハードウェアアクセラレータユニットを含むこともできる。 The data processing device for implementing the machine learning model is, for example, a dedicated hardware accelerator unit for processing a common computationally intensive part of the machine learning training workload or production or inference workload. It can also be included.
機械学習モデルは、機械学習フレームワーク、例えばTensorFlowフレームワーク、Microsoft Cognitive Toolkitフレームワーク、Apache Singaフレームワーク、またはApache MXNetフレームワークを使用して、実装およびデプロイすることができる。 Machine learning models can be implemented and deployed using machine learning frameworks such as the TensorFlow framework, Microsoft Cognitive Toolkit framework, Apache Singa framework, or Apache MXNet framework.
本明細書において説明した本主題の実施形態は、例えばデータサーバとしてのバックエンドコンポーネントを含むか、またはミドルウェアコンポーネント、例えばアプリケーションサーバを含むか、またはフロントエンドコンポーネント、例えば本明細書において説明した本主題の実装形態とそれを通じてユーザが対話することのできるグラフィカルユーザインターフェース、ウェブブラウザ、もしくはアプリを有するクライアントコンピュータを含むか、または1つもしくは複数のそのようなバックエンドコンポーネント、ミドルウェアコンポーネント、もしくはフロントエンドコンポーネントの任意の組合せを含む、コンピューティングシステム内に実装することができる。システムのコンポーネント同士は、任意の形態または媒体のデジタルデータ通信、例えば通信ネットワークによって、相互接続され得る。通信ネットワークの例としては、ローカルエリアネットワーク(LAN)、および広域ネットワーク(WAN)、例えばインターネットがある。 The embodiments of the subject described herein include, for example, a back-end component as a data server, or include a middleware component, such as an application server, or a front-end component, eg, the subject described herein. Implementations and client computers with a graphical user interface, web browser, or app through which users can interact, or one or more such back-end, middleware, or front-end components. Can be implemented within a computing system, including any combination of. The components of the system may be interconnected by any form or medium of digital data communication, such as a communication network. Examples of communication networks are local area networks (LANs) and wide area networks (WANs), such as the Internet.
コンピューティングシステムは、クライアントおよびサーバを含むことができる。クライアントとサーバは一般に、互いに遠隔にあり、典型的には、通信ネットワークを通じて対話する。クライアントとサーバの関係は、それぞれに対応するコンピュータ上で実行され、互いにクライアント-サーバ関係を有する、コンピュータプログラムによって生じる。いくつかの実施形態では、サーバは、データ、例えばHTMLページをユーザデバイスに、例えばクライアントとしての役割を果たすデバイスと対話しているユーザにデータを表示し、そのユーザからユーザ入力を受信する目的で、送信する。ユーザデバイスにおいて生成されたデータ、例えばユーザ対話の結果は、デバイスからサーバにおいて受信され得る。本明細書は、実装形態の多くの具体的な詳細を含んでいるが、これらは、任意の発明の範囲に対する、または特許請求され得るものの範囲に対する限定と解釈するのではなく、特定の発明の特定の実施形態に固有であり得る特徴についての説明と解釈すべきである。本明細書において別々の実施形態の文脈の中で説明されるいくつかの特徴は、単一の実施形態において組み合わせて実装することもできる。反対に、単一の実施形態の文脈の中で説明されるさまざまな特徴は、複数の実施形態において別々に、または任意の適切な部分組合せで実装することもできる。さらに、特徴については上で、ある特定の組合せで作用するものとして説明されていることがあり、そういうものとして最初に特許請求されていることすらあるが、特許請求された組合せからの1つまたは複数の特徴を、場合によっては、その組合せから削除することができ、特許請求された組合せが、部分組合せまたは部分組合せの変形を対象としていてよい。 The computing system can include clients and servers. Clients and servers are generally remote from each other and typically interact through communication networks. The client-server relationship is created by a computer program that runs on the corresponding computer and has a client-server relationship with each other. In some embodiments, the server displays data, eg, an HTML page, to a user device, eg, a user interacting with a device that acts as a client, for the purpose of receiving user input from that user. ,Send. Data generated on the user device, such as the result of a user dialogue, can be received from the device on the server. The present specification contains many specific details of the embodiments, but these are not construed as limitations to the scope of any invention or claims, but rather to a particular invention. It should be interpreted as an explanation of features that may be unique to a particular embodiment. Some features described herein in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely, the various features described in the context of a single embodiment can also be implemented separately in multiple embodiments or in any suitable subcombination. In addition, features may be described above as acting in a particular combination, and may even be first claimed as such, but one or more from the claimed combination. A plurality of features may be removed from the combination in some cases, and the claimed combination may be subject to a partial combination or a modification of the partial combination.
同様に、動作については特定の順序で図面中に描かれ、特許請求の範囲において記載されているが、これは、望ましい結果を達成するために、そのような動作が図示の特定の順序で、もしくは順番に実施されること、または示された全ての動作が実施されることを要求するものと理解すべきではない。ある特定の状況下では、マルチタスキングおよび並列処理が有利となることがある。さらに、上で説明した実施形態におけるさまざまなシステムモジュールおよびシステムコンポーネントの分離は、そのような分離を全ての実施形態において要求するものと理解すべきではなく、説明したプログラムコンポーネントとシステムは一般に、単一のソフトウェア製品に一緒に統合するか、または複数のソフトウェア製品にパッケージ化できる、ということを理解されたい。 Similarly, the movements are drawn in the drawings in a particular order and are described in the claims, but in order to achieve the desired result, such movements are drawn in the particular order shown. Or it should not be understood as requiring that it be performed in sequence or that all the indicated actions be performed. Under certain circumstances, multitasking and parallelism can be advantageous. Moreover, the separation of the various system modules and system components in the embodiments described above should not be understood as requiring such separation in all embodiments, and the program components and systems described are generally simply simple. It should be understood that they can be integrated together into one software product or packaged into multiple software products.
本主題の特定の実施形態について説明してきた。他の実施形態が、添付の特許請求の範囲内に含まれる。例えば、特許請求の範囲において記載されたアクションを、異なる順序で実施し、それでもなお望ましい結果を達成することができる。一例として、添付の図中に描いたプロセスは、望ましい結果を達成するために、図示の特定の順序、または順番を必ずしも要求するとは限らない。場合によっては、マルチタスキングおよび並列処理が有利となることがある。 Specific embodiments of this subject have been described. Other embodiments are included within the scope of the appended claims. For example, the actions described in the claims can be performed in a different order and still achieve the desired result. As an example, the processes depicted in the attached figures do not necessarily require the specific order, or order shown, to achieve the desired result. In some cases, multitasking and parallel processing can be advantageous.
100 ニューラルアーキテクチャ探索システム
102 ベースラインアーキテクチャ
103 複合係数
104 入力データ、ターゲットリソース使用量データ
108 ベースライン幅係数β、ベースライン幅係数
110 ベースライン深さ係数α、ベースライン深さ係数
112 ベースライン解像度係数γ、ベースライン解像度係数
114 幅係数
116 深さ係数
118 解像度係数
126 最終アーキテクチャ
150 アーキテクチャデータ
200 プロセス
300 ベースラインアーキテクチャ
302 畳み込みニューラルネットワーク層
304 FusedConvニューラルネットワーク層
306 MBConvニューラルネットワーク層
100 Neural Architecture Search System
102 Baseline architecture
103 Composite coefficient
104 Input data, target resource usage data
108 Baseline width factor β, Baseline width factor
110 Baseline depth factor α, Baseline depth factor
112 Baseline resolution factor γ, Baseline resolution factor
114 Width factor
116 Depth coefficient
118 resolution factor
126 Final architecture
150 Architectural data
200 processes
300 baseline architecture
302 Convolutional Neural Network Layer
304 FusedConv Neural network layer
306 MB Conv Neural Network Layer
Claims (17)
前記ニューラルネットワークのベースラインアーキテクチャを受信するステップであって前記ベースラインアーキテクチャが、前記特定の機械学習タスクを実施するようにトレーニングされたものであり、前記ベースラインアーキテクチャが、ネットワーク幅次元、ネットワーク深さ次元、および解像度次元を有する、ステップと、
前記ベースラインアーキテクチャをスケーリングするのに使用される追加の計算リソースを制御する複合係数を定義したデータを受信するステップと、
ベースライン幅係数、ベースライン深さ係数、およびベースライン解像度係数を決定するように探索を実施するステップであって、前記ベースライン幅係数、前記ベースライン深さ係数、および前記ベースライン解像度係数がそれぞれ、前記追加の計算リソースを前記ベースラインアーキテクチャの前記ネットワーク幅次元、前記ネットワーク深さ次元、および前記解像度次元にどのように割り当てるかを指定するものである、ステップと、
前記ベースライン幅係数、前記ベースライン深さ係数、前記ベースライン解像度係数、および前記複合係数に基づいて、幅係数、深さ係数、および解像度係数を決定するステップと、
前記ベースラインアーキテクチャの前記ネットワーク幅次元、前記ネットワーク深さ次元、および前記解像度次元を、対応する前記幅係数、前記深さ係数、および前記解像度係数に基づいてスケーリングした前記最終アーキテクチャを生成するステップと
を含む、コンピュータ実装方法。 A computer implementation method that determines the final architecture of a neural network that performs a particular machine learning task.
A step of receiving the baseline architecture of the neural network, wherein the baseline architecture is trained to perform the particular machine learning task, and the baseline architecture is the network width dimension, network depth. Steps and steps that have a dimension, and a resolution dimension,
The step of receiving data that defines the complex coefficients that control the additional computational resources used to scale the baseline architecture, and
A step of performing a search to determine a baseline width factor, a baseline depth factor, and a baseline resolution factor, wherein the baseline width factor, the baseline depth factor, and the baseline resolution factor are: Steps and steps that specify how the additional computational resources are allocated to the network width dimension, the network depth dimension, and the resolution dimension of the baseline architecture, respectively.
A step of determining a width factor, a depth factor, and a resolution factor based on the baseline width factor, the baseline depth factor, the baseline resolution factor, and the composite factor.
With steps to generate the final architecture in which the network width dimension, the network depth dimension, and the resolution dimension of the baseline architecture are scaled based on the corresponding width factor, depth factor, and resolution factor. Computer implementation methods, including.
前記複合係数および前記ベースライン幅係数に基づいて、前記幅係数を生成するステップと、
前記複合係数および前記ベースライン深さ係数に基づいて、前記深さ係数を生成するステップと、
前記複合係数および前記ベースライン解像度係数に基づいて、前記解像度係数を生成するステップと
を含む、請求項1から7のいずれか一項に記載の方法。 A step of determining the width factor, the depth factor, and the resolution factor based on the baseline width factor, the baseline depth factor, the baseline resolution factor, and the composite factor.
A step of generating the width factor based on the composite factor and the baseline width factor,
A step of generating the depth coefficient based on the compound coefficient and the baseline depth coefficient, and
The method according to any one of claims 1 to 7, comprising the step of generating the resolution factor based on the composite factor and the baseline resolution factor.
前記ベースラインアーキテクチャの前記ネットワーク幅次元を、前記幅係数によってスケーリングするステップと、
前記ベースラインアーキテクチャの前記ネットワーク深さ次元を、前記深さ係数によってスケーリングするステップと、
前記ベースラインアーキテクチャの解像度を、前記解像度係数によってスケーリングするステップと
を含む、請求項11に記載の方法。 The step to generate the final architecture is
A step of scaling the network width dimension of the baseline architecture by the width factor.
A step of scaling the network depth dimension of the baseline architecture by the depth factor.
11. The method of claim 11, comprising scaling the resolution of the baseline architecture by the resolution factor.
各係数のさまざまな値に対してグリッドサーチを実施するとともに、前記複合係数を使用して、前記ベースライン幅係数、前記ベースライン深さ係数、および前記ベースライン解像度係数を決定するステップ
を含む、請求項1から12のいずれか一項に記載の方法。 The step of performing the search to determine the baseline width factor, the baseline depth factor, and the baseline resolution factor is
A grid search is performed on various values of each coefficient, and the composite coefficient is used to determine the baseline width coefficient, the baseline depth coefficient, and the baseline resolution coefficient. The method according to any one of claims 1 to 12.
をさらに含む、請求項1から13のいずれか一項に記載の方法。 A step of identifying a performance score of the final architecture that represents performance for the particular machine learning task, in which the final architecture is trained for the particular machine learning task and the values of the parameters of the final architecture. The method of any one of claims 1-13, further comprising:
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
JP2023085645A JP2023120204A (en) | 2019-01-23 | 2023-05-24 | Compound model scaling for neural networks |
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201962796034P | 2019-01-23 | 2019-01-23 | |
US62/796,034 | 2019-01-23 | ||
PCT/US2020/014839 WO2020154536A1 (en) | 2019-01-23 | 2020-01-23 | Compound model scaling for neural networks |
Related Child Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2023085645A Division JP2023120204A (en) | 2019-01-23 | 2023-05-24 | Compound model scaling for neural networks |
Publications (2)
Publication Number | Publication Date |
---|---|
JP2022523666A true JP2022523666A (en) | 2022-04-26 |
JP7286774B2 JP7286774B2 (en) | 2023-06-05 |
Family
ID=69726764
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2021542494A Active JP7286774B2 (en) | 2019-01-23 | 2020-01-23 | Composite model scaling for neural networks |
JP2023085645A Pending JP2023120204A (en) | 2019-01-23 | 2023-05-24 | Compound model scaling for neural networks |
Family Applications After (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2023085645A Pending JP2023120204A (en) | 2019-01-23 | 2023-05-24 | Compound model scaling for neural networks |
Country Status (6)
Country | Link |
---|---|
US (2) | US10909457B2 (en) |
EP (1) | EP3912099A1 (en) |
JP (2) | JP7286774B2 (en) |
KR (1) | KR20210105976A (en) |
CN (1) | CN113424199A (en) |
WO (1) | WO2020154536A1 (en) |
Families Citing this family (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP7140191B2 (en) * | 2018-07-31 | 2022-09-21 | 日本電気株式会社 | Information processing device, control method, and program |
CN112116090B (en) * | 2020-09-28 | 2022-08-30 | 腾讯科技（深圳）有限公司 | Neural network structure searching method and device, computer equipment and storage medium |
KR102508106B1 (en) * | 2020-11-24 | 2023-03-08 | 한남대학교 산학협력단 | IoT Application Generation Automation Method for supporting Neuromorphic Hardware |
CN112836801A (en) * | 2021-02-03 | 2021-05-25 | 上海商汤智能科技有限公司 | Deep learning network determination method and device, electronic equipment and storage medium |
US11720784B2 (en) * | 2021-04-01 | 2023-08-08 | Mythic, Inc. | Systems and methods for enhancing inferential accuracy of an artificial neural network during training on a mixed-signal integrated circuit |
CN114399018B (en) * | 2021-12-17 | 2023-10-10 | 西北大学 | Efficient ientNet ceramic fragment classification method based on sparrow optimization of rotary control strategy |
Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JPH05108593A (en) * | 1991-10-14 | 1993-04-30 | Sanyo Electric Co Ltd | Neuro development supporting device |
JPH0991263A (en) * | 1995-09-20 | 1997-04-04 | Hitachi Medical Corp | Method and device for optimizing neural network structure |
JP2017037392A (en) * | 2015-08-07 | 2017-02-16 | トヨタ自動車株式会社 | Neural network learning device |
JP2019533257A (en) * | 2016-10-28 | 2019-11-14 | グーグル エルエルシー | Neural architecture search |
-
2020
- 2020-01-23 CN CN202080010508.3A patent/CN113424199A/en active Pending
- 2020-01-23 EP EP20708313.0A patent/EP3912099A1/en active Pending
- 2020-01-23 WO PCT/US2020/014839 patent/WO2020154536A1/en unknown
- 2020-01-23 US US16/751,081 patent/US10909457B2/en active Active
- 2020-01-23 KR KR1020217023377A patent/KR20210105976A/en unknown
- 2020-01-23 JP JP2021542494A patent/JP7286774B2/en active Active
-
2021
- 2021-01-08 US US17/144,450 patent/US11893491B2/en active Active
-
2023
- 2023-05-24 JP JP2023085645A patent/JP2023120204A/en active Pending
Patent Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JPH05108593A (en) * | 1991-10-14 | 1993-04-30 | Sanyo Electric Co Ltd | Neuro development supporting device |
JPH0991263A (en) * | 1995-09-20 | 1997-04-04 | Hitachi Medical Corp | Method and device for optimizing neural network structure |
JP2017037392A (en) * | 2015-08-07 | 2017-02-16 | トヨタ自動車株式会社 | Neural network learning device |
JP2019533257A (en) * | 2016-10-28 | 2019-11-14 | グーグル エルエルシー | Neural architecture search |
Also Published As
Publication number | Publication date |
---|---|
JP2023120204A (en) | 2023-08-29 |
US10909457B2 (en) | 2021-02-02 |
KR20210105976A (en) | 2021-08-27 |
CN113424199A (en) | 2021-09-21 |
US11893491B2 (en) | 2024-02-06 |
US20200234132A1 (en) | 2020-07-23 |
JP7286774B2 (en) | 2023-06-05 |
US20210133578A1 (en) | 2021-05-06 |
WO2020154536A1 (en) | 2020-07-30 |
EP3912099A1 (en) | 2021-11-24 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US20210334624A1 (en) | Neural architecture search using a performance prediction neural network | |
US11869530B2 (en) | Generating audio using neural networks | |
JP7286774B2 (en) | Composite model scaling for neural networks | |
KR102469261B1 (en) | Adaptive artificial neural network selection techniques | |
JP2020201971A (en) | Processing of sequences using convolutional neural networks | |
US20220121906A1 (en) | Task-aware neural network architecture search | |
US11488067B2 (en) | Training machine learning models using teacher annealing | |
KR20190117713A (en) | Neural Network Architecture Optimization | |
WO2019084558A1 (en) | Selecting answer spans from electronic documents using machine learning | |
CN111133458B (en) | Enhanced neural network | |
US20240135955A1 (en) | Generating audio using neural networks | |
US11900222B1 (en) | Efficient machine learning model architecture selection | |
CN115454641A (en) | Data resource processing method and device, electronic equipment and storage medium |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A621 | Written request for application examination |
Free format text: JAPANESE INTERMEDIATE CODE: A621Effective date: 20210921 |
|
A977 | Report on retrieval |
Free format text: JAPANESE INTERMEDIATE CODE: A971007Effective date: 20220927 |
|
A131 | Notification of reasons for refusal |
Free format text: JAPANESE INTERMEDIATE CODE: A131Effective date: 20221011 |
|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20221227 |
|
TRDD | Decision of grant or rejection written | ||
A01 | Written decision to grant a patent or to grant a registration (utility model) |
Free format text: JAPANESE INTERMEDIATE CODE: A01Effective date: 20230424 |
|
A61 | First payment of annual fees (during grant procedure) |
Free format text: JAPANESE INTERMEDIATE CODE: A61Effective date: 20230524 |
|
R150 | Certificate of patent or registration of utility model |
Ref document number: 7286774Country of ref document: JPFree format text: JAPANESE INTERMEDIATE CODE: R150 |