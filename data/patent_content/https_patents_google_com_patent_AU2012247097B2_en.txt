AU2012247097B2 - Visual search history - Google Patents
Visual search history Download PDFInfo
- Publication number
- AU2012247097B2 AU2012247097B2 AU2012247097A AU2012247097A AU2012247097B2 AU 2012247097 B2 AU2012247097 B2 AU 2012247097B2 AU 2012247097 A AU2012247097 A AU 2012247097A AU 2012247097 A AU2012247097 A AU 2012247097A AU 2012247097 B2 AU2012247097 B2 AU 2012247097B2
- Authority
- AU
- Australia
- Prior art keywords
- resource
- response
- image
- search
- presented
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Ceased
Links
- 230000000007 visual effect Effects 0.000 title claims abstract description 27
- 230000004044 response Effects 0.000 claims abstract description 60
- 230000003993 interaction Effects 0.000 claims abstract description 53
- 238000000034 method Methods 0.000 claims abstract description 22
- 238000004590 computer program Methods 0.000 claims abstract description 14
- 238000012545 processing Methods 0.000 claims description 24
- 238000009877 rendering Methods 0.000 claims description 7
- 238000001514 detection method Methods 0.000 claims description 4
- 230000009471 action Effects 0.000 description 10
- 238000004891 communication Methods 0.000 description 8
- 230000008569 process Effects 0.000 description 7
- 238000010586 diagram Methods 0.000 description 4
- 238000013515 script Methods 0.000 description 4
- 230000003287 optical effect Effects 0.000 description 3
- 230000000644 propagated effect Effects 0.000 description 3
- 230000008859 change Effects 0.000 description 2
- 230000000694 effects Effects 0.000 description 2
- 230000002452 interceptive effect Effects 0.000 description 2
- 238000010295 mobile communication Methods 0.000 description 2
- 238000000926 separation method Methods 0.000 description 2
- 230000007704 transition Effects 0.000 description 2
- 206010000210 abortion Diseases 0.000 description 1
- 230000004075 alteration Effects 0.000 description 1
- 230000005540 biological transmission Effects 0.000 description 1
- 238000005282 brightening Methods 0.000 description 1
- 239000003086 colorant Substances 0.000 description 1
- 230000001143 conditioned effect Effects 0.000 description 1
- 230000009193 crawling Effects 0.000 description 1
- 230000007717 exclusion Effects 0.000 description 1
- 239000004973 liquid crystal related substance Substances 0.000 description 1
- 238000012986 modification Methods 0.000 description 1
- 230000004048 modification Effects 0.000 description 1
- 238000012552 review Methods 0.000 description 1
- 239000004065 semiconductor Substances 0.000 description 1
- 230000001953 sensory effect Effects 0.000 description 1
- 239000000758 substrate Substances 0.000 description 1
- 238000012546 transfer Methods 0.000 description 1
- 239000013598 vector Substances 0.000 description 1
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/33—Querying
- G06F16/338—Presentation of query results
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/951—Indexing; Web crawling techniques
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/953—Querying, e.g. by the use of web search engines
- G06F16/9538—Presentation of query results
Abstract
Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for presenting a visual search history. Presentation data is received indicating that a resource has been presented by a user device, the resource 5 having been presented in response to user interaction with a search result that referenced the resource. In response to receipt of the presentation data, an image of the resource is acquired. The acquired image is associated with a search query for which the search result was provided. In response to receipt of a request for a search history for the user device, the acquired image and the associated search query are displayed. Receiving data that a resource has been presented in 402 response to user interaction with a search result Acquiring an image of the resource Associating the acquired image with a search query Receiving a request for a search history Displaying the acquired image and associated search query Receiving history interaction data with the acquired image Increasing the presentation size of the image Replacing the image with the resource l'in A
Description
AUSTRALIA Regulation 3.2 Patents Act 1990 Complete Specification Standard Patent Convention APPLICANT: Google Inc. Invention Title: VISUAL SEARCH HISTORY The following statement is a full description of this invention, including the best method of performing it known to me: VISUAL SEARCH HISTORY CROSS-REFERENCE TO RELATED APPLICATION This application claims priority of U.S. Provisional Application No. 61/559,468, filed November 14, 2011, the entirety of which is hereby incorporated by reference as if 5 fully set forth therein. BACKGROUND This specification relates to data processing and information retrieval. The Internet provides access to a wide variety of resources such as images, video or audio files, web pages for particular subjects, book articles, or news articles. A search 10 system can identify resources in response to a search query that includes one or more search terms or phrases. The search system ranks the resources based on their relevance to the query and on measures of quality of the resources and provides search results that link to the identified resources. The search results are typically ordered for viewing according to the rank. 15 A user may later wish to review their search history and return to a resource that was previously accessed. If the user cannot remember the name or web address of the search result, the user may not be able to quickly locate and return to the resource. Thus, the user may experience difficulty in obtaining information that can help the user satisfy his or her informational need. 20 SUMMARY In general, one innovative aspect of the subject matter described in this specification can be embodied in methods that include the actions of receiving presentation data indicating that a resource has been presented by a user device, the resource having been presented in response to user interaction with a search result that 25 referenced the resource; in response to receipt of the presentation data, acquiring an image of the resource; associating the acquired image with a search query for which the search result was provided; receiving a request for a search history for the user device; and in response to receipt of the request, displaying the acquired image and the associated search query. Other embodiments of this aspect include corresponding systems, 30 apparatus, and computer programs, configured to perform the actions of the methods, encoded on computer storage devices. 1 These and other embodiments can each optionally include one or more of the following features. Methods can further include the actions of receiving additional presentation data indicating that an additional resource has been presented by the user device; in response to receipt of the additional presentation data, acquiring an additional 5 image of the additional resource; associating the additional image with the search query; and in response to receipt of the request, displaying a visual grouping of images associated with the search query, the visual grouping including the acquired image and a graphic indicative of the additional image. In response to user interaction with the visual grouping of images, at least the acquired and additional images can be displayed 10 individually.... Methods can further include the actions of receiving history interaction data indicating that user interaction with the acquired image has occurred; in response to receipt of the history interaction data: increasing a presentation size of the acquired image; and rendering at least a portion of the resource; determining that at least a 15 threshold portion of the resource has been rendered; and in response to the determination, replacing the image with the resource. Methods can further include the action of modifying the image to be visually distinct from the rendered resource. Receiving a request for the search history can include determining that a user swipe occurred during a presentation of search results, the determination that the user 20 swipe has occurred being based, at least in part, on detection of a pointer at multiple locations along a path that extends from a first display location to a second display location. Methods can further include the actions of determining that the resource was fully rendered and presented by the user device. Receiving the presentation data can include 25 receiving the presentation data in response to the determination that the resource was fully rendered and presented by the user device. Particular embodiments of the subject matter described in this specification can be implemented so as to realize one or more of the following advantages. Images of resources can be generated and indexed on a per-resource basis, and each resource can be 30 stored in relation to the search query that resulted in the resource being selected. Presenting the user with images rather than text in order to find previously-visited sites may increase the ease of recognition and facilitate easier return to those sites. Acquiring and storing images based on the actual rendered content of the resource allows for reproducing what the user actually saw when the resource was originally displayed, and 2 makes reduces the need for the device to request or render resources while the user browses search history. Grouping the images according to search query supports quicker browsing through different search queries, while expanding each group allows for each individual resource to be represented by its own image. 5 The details of one or more embodiments of the subject matter described in this specification are set forth in the accompanying drawings and the description below. Other features, aspects, and advantages of the subject matter will become apparent from the description, the drawings, and the claims. BRIEF DESCRIPTION OF THE DRAWINGS 10 FIG. 1 is a block diagram of an example environment in which a search system provides search services. FIG. 2 is a screen shot of an example search results page. FIGS. 3A-3C are screen shots of an example visual search history presentation. FIGS. 3D-3G are screen shots of an image enlarged and presented to a user in 15 place of a resource. FIG. 4 is a flow chart of an example process for presenting a visual search history. FIG. 5 is block diagram of an example computer system. Like reference numbers and designations in the various drawings indicate like elements. 20 DETAILED DESCRIPTION A visual search history is provided to a user. The visual search history associates each web page previously visited with an image of that web page, obtained at the time that the website was last rendered to display to the user. The user can scroll through the images to find a web page previously visited, and can return to the page by selecting it. 25 Each web page is associated with the search query for which the web page was identified as responsive. In some implementations, a "stack" graphic may be used to indicate that a group of several images are available for a particular query, where each image represents a web page that was referenced by a search result that was 1) generated for that search query and 2) visited by the user. User interaction with the "stack graphic" 30 may cause presentation of the individual images. FIG. 1 is a block diagram of an example environment 100 in which a search system 110 provides search services. The example environment 100 includes a network 3 102, e.g., a local area network (LAN), wide area network (WAN), the Internet, or a combination of them, connects web sites 104, user devices 106, and the search system 110. The environment 100 may include many thousands of web sites 104 and user devices 106. 5 A web site 104 is one or more resources 105 associated with a domain name and hosted by one or more servers. An example web site is a collection of web pages formatted in hypertext markup language (HTML) that can contain text, images, multimedia content, and programming elements, e.g., scripts. Each web site 104 is maintained by a publisher, e.g., an entity that manages and/or owns the web site. 10 A resource 105 is any data that can be provided by a web site 104 over the network 102 and that is associated with a resource address. Resources 105 include HTML pages, word processing documents, and portable document format (PDF) documents, images, video, and feed sources, to name just a few. The resources 105 can include content, e.g., words, phrases, images and sounds and may include embedded 15 information (e.g., meta information and hyperlinks) and/or embedded instructions (e.g., scripts). A user device 106 is an electronic device that is under control of a user and is capable of requesting and receiving resources 105 over the network 102. Example user devices 106 include personal computers, mobile communication devices, tablet 20 computing devices, and other devices that can send and receive data over the network 102. A user device 106 typically includes a user application, e.g., a web browser, to facilitate the sending and receiving of data over the network 102. To facilitate searching of resources 105, the search system 110 identifies the resources 105 by crawling and indexing the resources 105 provided on web sites 104. 25 Data about the resources 105 can be indexed based on the resource to which the data corresponds. The indexed and, optionally, cached copies of the resources 105 are stored in a search index 112. The user devices 106 submit search queries 109 to the search system 110. In response, the search system 110 accesses the search index 112 to identify resources 105 30 that are relevant to (e.g., have at least a minimum specified relevance score for) the search query 109. The search system 110 identifies the resources 105, generates search results 111 that identify the resources 105, and returns the search results 111 to the user devices 106. A search result 111 is data generated by the search system 110 that identifies a resource 105 that is responsive to a particular search query, and includes a link to the 4 resource 105. An example search result 111 can include a web page title, a snippet of text or a portion of an image extracted from the web page, and the URL of the web page. For a search of textual content, the search results are ranked based, at least in part, on scores related to the resources 105 identified by the search results 111, such as 5 information retrieval ("IR") scores, and optionally a quality score of each resource relative to other resources. In some implementations, the IR scores are computed from dot products of feature vectors corresponding to a search query 109 and a resource 105, and the ranking of the search results is based on initial relevance scores that are a combination of the IR scores and page quality scores. The search results 111 are ordered 10 according to these initial relevance scores and provided to the user device 106 according to the order. The user devices 106 receive the search results 111, e.g., in the form of one or more web pages, and render the search results for presentation to users. In response to the user interacting with (e.g., affirmatively selecting or hovering over) a link in a search 15 result at a user device 106, the user device 106 requests the resource 105 identified by the link. For brevity, this document refers to user interactions with search results as clicks of links, but user interactions are not limited to clicks. For example, a user touching a touch screen at a location at which a search result is presented is considered a user interaction with the search result. Also, a pointer being "hovered" over a target for more than a 20 threshold amount of time can be considered user interaction with the target. The web site 104 hosting the resource 105 receives the request for the resource from the user device 106 and provides the resource 105 to the requesting user device 106. The user device 106 renders and displays the resource 105 to the user. The device 106 also creates an image of the resource 105, which may be a screen-shot of a web page. 25 The image depicts the appearance of the resource 105 as displayed to the user. The image may then be included in an index of explored search results (e.g., search results with which a user interacted) associated with the search query for which the result was generated. Images associated with retrieved resources may be stored locally on the user device 106, remotely in conjunction with the search system 110, or some combination of 30 the two. These stored images may be used to generate a visual search history, as illustrated in FIGS. 3A-3C. FIG. 2 shows a touch-screen user device 200 upon which is displayed a search results page 202. Swiping from the left edge of the page 202 to the right as shown by the action of the user's hand 204 may reveal a visual search history display 300, 5 shown in FIG. 3A. Here, images of previously requested resources are grouped according to search query. A first search query group 302 includes a search query button 304 showing the search query with which the group 302 is associated. User interaction with the search query button 304 causes submission of the search query to the search system, 5 and the search results page for the search query that is listed on the button 304 can be presented to the user. Below the button 304 is a timestamp 306 that indicates when this particular search query was most recently entered by the user. This timestamp may instead be based on other events, such as the last time the device responded to a user interaction with a search 10 result associated with this query or the last time the search results page was presented to the user, whether or not the query was resubmitted to the search system. In some implementations, further submissions or re-submissions of the same search query may be shown as separate search query groups, with separate timestamps and distinct results histories; in other implementations, explored results associated with the same search 15 query are aggregated and the timestamp updated when a search is re-run. A stack graphic 308 represents the record of multiple resources associated with the search query group 302. A top image 310a on the stack is visible, representing a first specific resource. A caption 312a below the graphic 308 shows a title and web address of the resource associated with the top image 310a. Images representing resources may be 20 ordered in a number of different ways, including placing the first visited or most recently visited result on top, placing on top the visited result that ranked highest on the search results page, or even alphabetizing the web addresses or titles. A second search query group 314 has similar features. Additional query groups may be available by horizontal scrolling (e.g., swiping across the display from left to right or right to left). 25 As illustrated by FIG. 3A, the client device 200 can change the manner in which a search history is presented, for example, in response to detecting user interaction with the search history. For example, when the client device 200 detects a user's hand 316 (or another pointer) interacting with the stack graphic 308 in a predefined way (such as pinching the corner, as shown), the client device 200 can replace the stack graphic 308 30 with individual images, as shown in FIG. 3B. Here, the search query group 302 has been expanded to show multiple images 31 Oa, 31 Ob each associated with a different resource. Each image representing a resource also includes its own caption 314a, 314b giving the title and web address of that resource. When the client device 200 detects user interaction with an image the client device 200 can again request the resource and then render and 6 display the resource to the user as described above. Grouping and ungrouping the resources listed under each search query can also be performed in response to user interaction with buttons 318, 320. As further illustrated in FIG. 3C, the client device 200 may be configured to 5 selectively maintain items within the search history, such that a user can eliminate records from the search history and/or prevent records from being included in the search history. For example, upon user interaction with an "Edit" button 322 shown in FIGS. 3A and 3B, the display 300 modifies to include edit capabilities as shown. Single results, or full stacks of results representing search query groups, can be deleted with the use of delete 10 buttons 324 adjacent to the images of records to be deleted. User interaction with a "Clear All" button 326 may eliminate all search history records (but may first require the user to confirm the "Clear All" with an additional dialog box). User interaction with the "Done" button 328 eliminates the edit-specific display elements 324, 326 and returns the display 300 to what is shown in FIGS. 3A or 3B. 15 It may also be optional as to whether the device maintains a record of search results. For example, the client device 200 may be configured such that a user may be able to elect to turn off search history. If the user elects to turn the search history off, further searches and resources followed from those searches will not be recorded. However, turning off search history may not automatically delete previously-recorded 20 search history, such that a user can selectively choose to not record search history during specific sessions while still maintaining search history generated during other sessions. These options may be available to the user through a search options page, on the search history page, or on the search page itself The device may also selectively present dialog boxes prompting the user to select whether to record search history. In some 25 implementations, such dialog boxes may be presented the first time (e.g., during a particular browsing session) the device presents search results to the user and at further intervals measured by number of sessions, by number of queries submitted, by number of resources presented , by elapsed time, or any combination of these. In some implementations, when a user selects an image in order to return to the 30 resource represented by the image, the image is presented as a placeholder while the resource is rendered. The image may be enlarged to substantially fill the display, sized and positioned similarly to how the rendered resource will appear. When a certain rendering threshold is reached for the rendering of the resource (e.g., 50% of the resource rendered or a pre-specified time elapsing), the rendered resource displaces the image on 7 the display. Until that time, there may be some alteration of the image, such as a differing border around the image or a change in brightness or color, to indicate to the user that what is displayed is an image and that the actual resource, along with hyperlinks and/or other interactive features the resource includes, is not yet displayed. 5 FIG. 3D shows a search history page 300 including an image 330 associated with a previously accessed resource. Upon user interaction with the image 330, such as a click, the device uses animation to present the image as expanding to fill the page. FIGS. 3E and 3F show the image 330 enlarged and filling a greater area of the page as time elapses. FIG. 3G shows the image 330 enlarged and being presented in substantially the 10 same position as the resource that it represents. In some implementations, other animation features may be included in the page transition. For example, the image may appear to lift off of the search history page and move to land in a browser window or other search client interface. This animation takes time to complete, giving the device additional time to render the resource and reducing 15 the amount of time that the user is presented with the image replacement. In some implementations, a variety of filters may be applied to the image to differentiate it from the rendered resource. The resource may be substantially altered, for example, in the area outside of the broken line 332 using brightening, smearing, or other processing in order to better present the nature of the image. The replacement of the 20 image 330 with the associated resource is thus visually indicated by the absence of these modifications in displaying the rendered resource. FIG. 4 is a flow chart of an example process 400 for providing a visual search history to a user. Although the process is illustrated as a series of method steps performed by or on a user device, it will be understood that in some implementations, 25 certain steps may be performed away from the device by other components on the network, such as a web server with the ability to index content and maintain a cache of images. Presentation data is received, where the presentation data indicates that a resource has been presented in response to user interaction with a search result (402). In some 30 implementations, the user interaction and corresponding presentation occurs on a mobile device that may include a touch interface. The device may be network-capable such that the query can be sent to a search system for processing and search results can be received in response to the request. These search results can reference resources that are considered relevant to the user's search query. Generally, more relevant search results 8 are displayed earlier on the page (e.g., higher on the page), although many factors contribute to the order in which results are presented. When a user selects (i.e., interacts with) a search result that was presented in response to the search request and that corresponds to a resource, the device receives and 5 renders the resource, and in turn, displays the resource to the user. If the resource is a web page associated with a website, the device may respond to input from the user by presenting further content on the website and other linked sites, by returning to the device page to make available other results, or by submitting additional search queries. An image of the resource is acquired in response to receiving the presentation data 10 (404). Again, this may be carried out by the same device that presents the search results and the resource to the user. Acquisition of the image may occur when the resource is considered all or mostly rendered, as indicated by the presentation data, so that the image substantially matches what the user sees when the device displays it. In some implementations, the presentation data is received in response to 15 determining that the resource was fully rendered and presented (i.e., at least a threshold portion of the resource was rendered and presented) by the user device. For example, the receipt of the presentation data may be conditioned on 90% of the resource being rendered by the user device and/or the amount of resource presented filling at least 90% of the available display area (e.g., a browser window). Thus, if the user aborts the 20 loading of the page such that it does not completely render, an image may not be acquired. The device may acquire the image by generating it, such as by producing a screen capture image of the rendered (or mostly rendered) resource. In some implementations, presentation data is received each time that a resource is presented, and an image of each resource can be acquired in response to receipt of the 25 presentation data. For example, following user interaction with an initial search result, the resource that is referenced by that search result can be presented by the device, and an image of that resource can be acquired in response to receipt of the presentation data indicating that the resource was presented. Following user interaction with the first search result, the user may request additional resources through interaction with elements 30 on the presented resource and/or selecting additional search results from the search results page. In response to the request for the additional resource, the additional resource can be presented by the device, and additional presentation data may be received indicating 9 that the additional resource was presented at the device. Receipt of the additional presentation data can cause the device to acquire an image of the additional resource. The acquired image is associated with a search query (406). The search query with which the acquired image is associated is the search query for which the search 5 result was provided. The acquired image can be associated with the search query, for example, by being indexed according to and/or stored with a reference to the search query. The acquired image and/or associated search query may be stored in the local memory of the device, or may be stored elsewhere and retrieved over a network upon request. Other information about the resource and the users' access of the resource - such 10 as the rank of the resource's search result among the search results, the time that the resource was accessed by the user, and the title and link of the resource - may also be recorded and included along with the image and search query. This information may collectively form an object or record in a database of similar records associated with the user's search history. 15 As described above, additional images may be acquired through user interaction with multiple search results and/or requests for resources that are requested subsequent to interaction with one of the search results. Each of the additional images that is acquired can also be associated with the search query, such that a per-query browsing history can be maintained. 20 A request for a search history for the user device is received (408). The request may be received, in response to user interaction with the device, for example, by interacting with a visual search history presentation as described above. For example, from a search results page, the search history may be available by swiping from the left side of the page to the right, visually dragging the edge of the page over in order to reveal 25 text related to instructions for obtaining a visual search history. The device may detect the swipe as multiple sequential points of contact on the touch screen moving between the left edge and a point further to the right. The acquired image is displayed, as well as the associated search query (410). In some implementations, the acquired image and associated search query are displayed in 30 response to receipt of the request for the search history. Other information associated with the resource may also be displayed with the acquired image and the associated search query. Where the image and related data are stored and indexed locally, display of the acquired image and associated search query may require little or no network communication, as the acquired image and associated search query are locally retrieved 10 and displayed on the device. This image and resource may again be displayed in the context of other images and resources; a user interface may allow for visual movement of the image in the context of other images in order to locate the desired resource. Once the image depicting the resource is located, a user may interact with the image in order to 5 request presentation of that resource. In some implementations, history interaction data indicative of user interaction with the acquired image is received (412). The user interaction with the acquired image can be, for example, a click on the image, a pointer contacting a touch screen location at which the image is presented, or another interaction with the image that causes the device 10 to present the associated resource again. Requesting the resource may require communication over the network, and then receiving data and rendering the resource may take some amount of time. While these processes are taking place, the image may be used as a placeholder. The presentation size of the image is increased (414). In some implementations, 15 the presentation size of the image is increased to fill the area of the browser or search client, and may substantially match the size and position of the rendered resource. By doing so, the image may smooth the transition to the rendered resource. Because the image is not itself the rendered resource, it is generally not interacted with in the same ways as the rendered resource may be able to be interacted with, 20 particularly if the resource includes hypertext or other interactive elements. Therefore, in some implementations, the image may be modified in some way to visually differentiate it from the resource. For example, the image colors may be muted, or some highlighting or other border effect may be added to the image. The image is replaced with the resource (416). This may be done in response to 25 determining that the resource has been sufficiently rendered. In some implementations, a predetermined threshold value may be used; the replacement occurs when the percentage of the resource that has been rendered exceeds a predetermined amount, or when some other variable used to represent how much of the resource has been rendered reaches the threshold. A time limit may also be employed so that the replacement occurs after a set 30 interval of time has elapsed even if the amount rendered has not yet reached the established threshold amount by that time. Transitional effects may or may not be used to switch between the image and the rendered resource. FIG. 5 is block diagram of an example computer system 500 that can be used to perform operations described above. The system 500 includes a processor 510, a memory 11 520, a storage device 530, and an input/output device 540. Each of the components 510, 520, 530, and 540 can be interconnected, for example, using a system bus 550. The processor 510 is capable of processing instructions for execution within the system 500. In one implementation, the processor 510 is a single-threaded processor. In another 5 implementation, the processor 510 is a multi-threaded processor. The processor 510 is capable of processing instructions stored in the memory 520 or on the storage device 530. The memory 520 stores information within the system 500. In one implementation, the memory 520 is a computer-readable medium. In one implementation, the memory 520 is a volatile memory unit. In another implementation, 10 the memory 520 is a non-volatile memory unit. The storage device 530 is capable of providing mass storage for the system 500. In one implementation, the storage device 530 is a computer-readable medium. In various different implementations, the storage device 530 can include, for example, a hard disk device, an optical disk device, a storage device that is shared over a network by 15 multiple computing devices (e.g., a cloud storage device), or some other large capacity storage device. The input/output device 540 provides input/output operations for the system 500. In one implementation, the input/output device 540 can include one or more of a network interface devices, e.g., an Ethernet card, a serial communication device, e.g., and RS-232 20 port, and/or a wireless interface device, e.g., and 802.11 card. In another implementation, the input/output device can include a touch screen interface to receive input data and display data to the user, e.g., a tablet computer or mobile communications device. Other implementations, however, can also be used, such as a keyboard, printer, and display devices 560, set-top box television client devices, etc. 25 Although an example processing system has been described in FIG. 5, implementations of the subject matter and the functional operations described in this specification can be implemented in other types of digital electronic circuitry, or in computer software, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them. 30 Embodiments of the subject matter and the operations described in this specification can be implemented in digital electronic circuitry, or in computer software, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them. Embodiments of the subject matter described in this specification can be implemented as one or more 12 computer programs, i.e., one or more modules of computer program instructions, encoded on computer storage medium for execution by, or to control the operation of, data processing apparatus. Alternatively or in addition, the program instructions can be encoded on an artificially-generated propagated signal, e.g., a machine-generated 5 electrical, optical, or electromagnetic signal, that is generated to encode information for transmission to suitable receiver apparatus for execution by a data processing apparatus. A computer storage medium can be, or be included in, a computer-readable storage device, a computer-readable storage substrate, a random or serial access memory array or device, or a combination of one or more of them. Moreover, while a computer storage 10 medium is not a propagated signal, a computer storage medium can be a source or destination of computer program instructions encoded in an artificially-generated propagated signal. The computer storage medium can also be, or be included in, one or more separate physical components or media (e.g., multiple CDs, disks, or other storage devices). 15 The operations described in this specification can be implemented as operations performed by a data processing apparatus on data stored on one or more computer readable storage devices or received from other sources. The term "data processing apparatus" encompasses all kinds of apparatus, devices, and machines for processing data, including by way of example a programmable 20 processor, a computer, a system on a chip, or multiple ones, or combinations, of the foregoing The apparatus can include special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit). The apparatus can also include, in addition to hardware, code that creates an execution environment for the computer program in question, e.g., code that constitutes processor 25 firmware, a protocol stack, a database management system, an operating system, a cross platform runtime environment, a virtual machine, or a combination of one or more of them. The apparatus and execution environment can realize various different computing model infrastructures, such as web services, distributed computing and grid computing infrastructures. 30 A computer program (also known as a program, software, software application, script, or code) can be written in any form of programming language, including compiled or interpreted languages, declarative or procedural languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, object, or other unit suitable for use in a computing environment. A computer program 13 may, but need not, correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data (e.g., one or more scripts stored in a markup language document), in a single file dedicated to the program in question, or in multiple coordinated files (e.g., files that store one or more modules, sub-programs, or 5 portions of code). A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network. The processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to 10 perform actions by operating on input data and generating output. The processes and logic flows can also be performed by, and apparatus can also be implemented as, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit). Processors suitable for the execution of a computer program include, by way of 15 example, both general and special purpose microprocessors, and any one or more processors of any kind of digital computer. Generally, a processor will receive instructions and data from a read-only memory or a random access memory or both. The essential elements of a computer are a processor for performing actions in accordance with instructions and one or more memory devices for storing instructions and data. 20 Generally, a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks. However, a computer need not have such devices. Moreover, a computer can be embedded in another device, e.g., a mobile telephone, a personal digital assistant (PDA), a mobile audio or video player, a game 25 console, a Global Positioning System (GPS) receiver, or a portable storage device (e.g., a universal serial bus (USB) flash drive), to name just a few. Devices suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, e.g., internal hard disks 30 or removable disks; magneto-optical disks; and CD-ROM and DVD-ROM disks. The processor and the memory can be supplemented by, or incorporated in, special purpose logic circuitry. To provide for interaction with a user, embodiments of the subject matter described in this specification can be implemented on a computer having a display device, 14 e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to the user and a keyboard and a pointing device, e.g., a mouse or a trackball, by which the user can provide input to the computer. Other kinds of devices can be used to provide for interaction with a user as well; for example, feedback provided to the user 5 can be any form of sensory feedback, e.g., visual feedback, auditory feedback, or tactile feedback; and input from the user can be received in any form, including acoustic, speech, or tactile input. In addition, a computer can interact with a user by sending documents to and receiving documents from a device that is used by the user; for example, by sending web pages to a web browser on a user's client device in response to 10 requests received from the web browser. Embodiments of the subject matter described in this specification can be implemented in a computing system that includes a back-end component, e.g., as a data server, or that includes a middleware component, e.g., an application server, or that includes a front-end component, e.g., a client computer having a graphical user interface 15 or a Web browser through which a user can interact with an implementation of the subject matter described in this specification, or any combination of one or more such back-end, middleware, or front-end components. The components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include a local area 20 network ("LAN") and a wide area network ("WAN"), an inter-network (e.g., the Internet), and peer-to-peer networks (e.g., ad hoc peer-to-peer networks). The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs 25 running on the respective computers and having a client-server relationship to each other. In some embodiments, a server transmits data (e.g., an HTML page) to a client device (e.g., for purposes of displaying data to and receiving user input from a user interacting with the client device). Data generated at the client device (e.g., a result of the user interaction) can be received from the client device at the server. 30 While this specification contains many specific implementation details, these should not be construed as limitations on the scope of any inventions or of what may be claimed, but rather as descriptions of features specific to particular embodiments of particular inventions. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single 15 embodiment. Conversely, various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Moreover, although features may be described above as acting in certain combinations and even initially claimed as such, one or more features from a 5 claimed combination can in some cases be excised from the combination, and the claimed combination may be directed to a subcombination or variation of a subcombination. Similarly, while operations are depicted in the drawings in a particular order, this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order, or that all illustrated operations be performed, to 10 achieve desirable results. In certain circumstances, multitasking and parallel processing may be advantageous. Moreover, the separation of various system components in the embodiments described above should not be understood as requiring such separation in all embodiments, and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into 15 multiple software products. Thus, particular embodiments of the subject matter have been described. Other embodiments are within the scope of the following claims. In some cases, the actions recited in the claims can be performed in a different order and still achieve desirable results. In addition, the processes depicted in the accompanying figures do not 20 necessarily require the particular order shown, or sequential order, to achieve desirable results. In certain implementations, multitasking and parallel processing may be advantageous. Throughout this specification and the claims which follow, unless the context requires otherwise, the word "comprise", and variations such as "comprises" and 25 "comprising", will be understood to imply the inclusion of a stated integer or step or group of integers or steps but not the exclusion of any other integer or step or group of integers or steps. The reference to any prior art in this specification is not, and should not be taken as, an acknowledgement or any form of suggestion that the prior art forms part of the 30 common general knowledge in Australia. What is claimed is: 16
Claims (18)
1. A computer-implemented method, comprising: receiving presentation data indicating that a resource has been presented in a browser by a user device, the resource having been presented in response to user interaction with a search result that referenced the resource; in response to receipt of the presentation data, acquiring an image of the resource; associating the acquired image with a search query for which the search result was provided; receiving a request for a search history for the user device; in response to receipt of the request, displaying the acquired image and the associated search query in a given browser window; receiving history interaction data indicating that user interaction with the acquired image has occurred; in response to receipt of the history interaction data: requesting the resource from a domain of the resource; animating the acquired image, the animating including expanding, based on a size at which the resource received from the domain will be presented in the given browser window, a presentation size of the acquired image within the given browser window while maintaining a size of the given browser window; and rendering, while the acquired image is presented in the given browser window at the expanded presentation size, at least a portion of the resource received from the domain of the resource in response to the request; determining that at least a threshold portion of the resource has been rendered; and in response to the determination, replacing, in the given browser window, the acquired image with the resource.
2. The method of claim 1 further comprising: receiving additional presentation data indicating that an additional resource has been presented by the user device; in response to receipt of the additional presentation data, acquiring an additional image of 17 the additional resource; associating the additional image with the search query; and in response to receipt of the request, displaying a visual grouping of images associated with the search query, the visual grouping including the acquired image and a graphic indicative of the additional image.
3. The method of claim 2, further comprising: in response to user interaction with the visual grouping of images, displaying at least the acquired and additional images individually.
4. The method of claim 1, further comprising: modifying the image to be visually distinct from the rendered resource.
5. The method of claim 1, wherein receiving a request for the search history comprises determining that a user swipe occurred during a presentation of search results, the determination that the user swipe has occurred being based, at least in part, on detection of a pointer at multiple locations along a path that extends from a first display location to a second display location.
6. The method of claim 1, further comprising: determining that the resource was fully rendered and presented by the user device; wherein receiving the presentation data comprises receiving the presentation data in response to the determination that the resource was fully rendered and presented by the user device.
7. A system comprising: a display in which search results are presented to a user; one or more processors configured to determine that user interaction with the display has occurred, the one or more processors further configured to perform operations comprising: receiving presentation data indicating that a resource has been presented by a user device, the resource having been presented in response to user interaction with a search result that referenced the resource; in response to receipt of the presentation data, acquiring an image of the resource; 18 associating the acquired image with a search query for which the search result was provided; receiving a request for a search history for the user device; in response to receipt of the request, displaying the acquired image and the associated search query in a given browser window; receiving history interaction data indicating that user interaction with the acquired image has occurred; in response to receipt of the history interaction data: requesting the resource from a domain of the resource; animating the acquired image, the animating including expanding, based on a size at which the resource received from the domain will be presented in the given browser window, a presentation size of the acquired image within the given browser window while maintaining a size of the given browser window; and rendering, while the acquired image is presented in the given browser window at the expanded presentation size, at least a portion of the resource received from the domain of the resource in response to the request; determining that at least a threshold portion of the resource has been rendered; and in response to the determination, replacing, in the given browser window, the image with the resource.
8. The system of claim 7, wherein the one or more processors are configured to perform operations further comprising: receiving additional presentation data indicating that an additional resource has been presented by the user device; in response to receipt of the additional presentation data, acquiring an additional image of the additional resource; associating the additional image with the search query; and in response to receipt of the request, displaying a visual grouping of images associated with the search query, the visual grouping including the acquired image and a graphic indicative of the additional image. 19
9. The system of claim 8, wherein the one or more processors are configured to perform operations further comprising: in response to user interaction with the visual grouping of images, displaying at least the acquired and additional images individually.
10. The system of claim 7, wherein the one or more processors are configured to perform operations further comprising: modifying the image to be visually distinct from the rendered resource.
11. The system of claim 7, wherein receiving a request for the search history comprises determining that a user swipe occurred during a presentation of search results, the determination that the user swipe has occurred being based, at least in part, on detection of a pointer at multiple locations along a path that extends from a first display location to a second display location.
12. The system of claim 7, wherein the one or more processors are configured to perform operations further comprising: determining that the resource was fully rendered and presented by the user device; wherein receiving the presentation data comprises receiving the presentation data in response to the determination that the resource was fully rendered and presented by the user device.
13. A non-transitory computer storage medium encoded with a computer program, the program comprising instructions that when executed by data processing apparatus cause the data processing apparatus to perform operations comprising: receiving presentation data indicating that a resource has been presented by a user device, the resource having been presented in response to user interaction with a search result that referenced the resource; in response to receipt of the presentation data, acquiring an image of the resource; associating the acquired image with a search query for which the search result was provided; receiving a request for a search history for the user device; 20 in response to receipt of the request, displaying the acquired image and the associated search query in a given browser window; receiving history interaction data indicating that user interaction with the acquired image has occurred; in response to receipt of the history interaction data: requesting the resource from a domain of the resource; animating the acquired image, the animating including expanding, based on a size at which the resource received from the domain will be presented in the given browser window, a presentation size of the acquired image within the given browser window while maintaining a size of the given browser window; and rendering, while the acquired image is presented in the browser at the presentation size, at least a portion of the resource received from the domain of the resource in response to the request; determining that at least a threshold portion of the resource has been rendered; and in response to the determination, replacing, in the given browser window, the image with the resource.
14. The computer storage medium of claim 13, wherein the program includes instructions that when executed by the data processing apparatus cause the data processing apparatus to perform operations further comprising: receiving additional presentation data indicating that an additional resource has been presented by the user device; in response to receipt of the additional presentation data, acquiring an additional image of the additional resource; associating the additional image with the search query; and in response to receipt of the request, displaying a visual grouping of images associated with the search query, the visual grouping including the acquired image and a graphic indicative of the additional image.
15. The computer storage medium of claim 14, wherein the program includes instructions that when executed by the data processing apparatus cause the data processing apparatus to 21 perform operations further comprising: in response to user interaction with the visual grouping of images, displaying at least the acquired and additional images individually.
16. The computer storage medium of claim 13, wherein the program includes instructions that when executed by the data processing apparatus cause the data processing apparatus to perform operations further comprising: modifying the image to be visually distinct from the rendered resource.
17. The computer storage medium of claim 13, wherein receiving a request for the search history comprises determining that a user swipe occurred during a presentation of search results, the determination that the user swipe has occurred being based, at least in part, on detection of a pointer at multiple locations along a path that extends from a first display location to a second display location.
18. The computer storage medium of claim 13, wherein the program includes instructions that when executed by the data processing apparatus cause the data processing apparatus to perform operations further comprising: determining that the resource was fully rendered and presented by the user device; wherein receiving the presentation data comprises receiving the presentation data in response to the determination that the resource was fully rendered and presented by the user device. 22
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201161559468P | 2011-11-14 | 2011-11-14 | |
US61/559,468 | 2011-11-14 |
Publications (2)
Publication Number | Publication Date |
---|---|
AU2012247097A1 AU2012247097A1 (en) | 2013-05-30 |
AU2012247097B2 true AU2012247097B2 (en) | 2015-04-16 |
Family
ID=48281621
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
AU2012247097A Ceased AU2012247097B2 (en) | 2011-11-14 | 2012-11-14 | Visual search history |
Country Status (3)
Country | Link |
---|---|
US (1) | US20130124511A1 (en) |
AU (1) | AU2012247097B2 (en) |
CA (1) | CA2795569A1 (en) |
Families Citing this family (9)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9360940B2 (en) * | 2011-11-14 | 2016-06-07 | Google Inc. | Multi-pane interface |
US20150169708A1 (en) * | 2012-04-24 | 2015-06-18 | Google Inc. | Providing recently selected images |
KR20140137259A (en) * | 2013-05-22 | 2014-12-02 | 한국전자통신연구원 | System for inspecting harmful information of mobile device and method thereof |
US20150106723A1 (en) * | 2013-10-10 | 2015-04-16 | Jones International, Ltd. | Tools for locating, curating, editing, and using content of an online library |
US20160299985A1 (en) * | 2015-04-13 | 2016-10-13 | Eric Poindessault | Method for accessing last search |
US9996222B2 (en) | 2015-09-18 | 2018-06-12 | Samsung Electronics Co., Ltd. | Automatic deep view card stacking |
US10459609B2 (en) * | 2018-04-03 | 2019-10-29 | Palantir Technologies Inc. | Multi-stage data page rendering |
CN111475725B (en) * | 2020-04-01 | 2023-11-07 | 百度在线网络技术（北京）有限公司 | Method, apparatus, device and computer readable storage medium for searching content |
CN113239212A (en) * | 2021-05-12 | 2021-08-10 | 维沃移动通信有限公司 | Information processing method and device and electronic equipment |
Citations (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20050165742A1 (en) * | 2003-12-30 | 2005-07-28 | Weisheke Chin | Searching previously viewed web sites |
US20110107226A1 (en) * | 2009-11-05 | 2011-05-05 | Heo Keunjae | Mobile terminal and method of providing information using the same |
Family Cites Families (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8479122B2 (en) * | 2004-07-30 | 2013-07-02 | Apple Inc. | Gestures for touch sensitive input devices |
US6396520B1 (en) * | 2000-01-05 | 2002-05-28 | Apple Computer, Inc. | Method of transition between window states |
US8464177B2 (en) * | 2006-07-26 | 2013-06-11 | Roy Ben-Yoseph | Window resizing in a graphical user interface |
-
2012
- 2012-11-14 CA CA2795569A patent/CA2795569A1/en not_active Abandoned
- 2012-11-14 AU AU2012247097A patent/AU2012247097B2/en not_active Ceased
- 2012-11-14 US US13/676,230 patent/US20130124511A1/en not_active Abandoned
Patent Citations (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20050165742A1 (en) * | 2003-12-30 | 2005-07-28 | Weisheke Chin | Searching previously viewed web sites |
US20110107226A1 (en) * | 2009-11-05 | 2011-05-05 | Heo Keunjae | Mobile terminal and method of providing information using the same |
Also Published As
Publication number | Publication date |
---|---|
US20130124511A1 (en) | 2013-05-16 |
AU2012247097A1 (en) | 2013-05-30 |
CA2795569A1 (en) | 2013-05-14 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
AU2012247097B2 (en) | Visual search history | |
US11687208B2 (en) | Evaluation of interactions with a user interface | |
US11907289B2 (en) | Methods, systems, and media for searching for video content | |
US9268469B2 (en) | Image display environment | |
US9727587B2 (en) | Previewing search results | |
JP6050327B2 (en) | Dynamic image display area and image display in web search results | |
US9360940B2 (en) | Multi-pane interface | |
US20150370833A1 (en) | Visual refinements in image search | |
US9460167B2 (en) | Transition from first search results environment to second search results environment | |
US20140188894A1 (en) | Touch to search | |
US9201925B2 (en) | Search result previews | |
US9135313B2 (en) | Providing a search display environment on an online resource |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
FGA | Letters patent sealed or granted (standard patent) | ||
MK14 | Patent ceased section 143(a) (annual fees not paid) or expired |