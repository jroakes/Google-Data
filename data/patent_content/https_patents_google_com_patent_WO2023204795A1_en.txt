WO2023204795A1 - Wearable computing device having optical sensors to indirectly determine a location of a force applied to a user interface - Google Patents
Wearable computing device having optical sensors to indirectly determine a location of a force applied to a user interface Download PDFInfo
- Publication number
- WO2023204795A1 WO2023204795A1 PCT/US2022/025198 US2022025198W WO2023204795A1 WO 2023204795 A1 WO2023204795 A1 WO 2023204795A1 US 2022025198 W US2022025198 W US 2022025198W WO 2023204795 A1 WO2023204795 A1 WO 2023204795A1
- Authority
- WO
- WIPO (PCT)
- Prior art keywords
- computing device
- force
- wearable computing
- user
- display
- Prior art date
Links
- 230000003287 optical effect Effects 0.000 title claims abstract description 131
- 230000006870 function Effects 0.000 claims description 141
- 238000013186 photoplethysmography Methods 0.000 claims description 139
- 238000000034 method Methods 0.000 claims description 53
- 230000004044 response Effects 0.000 claims description 47
- 230000000875 corresponding effect Effects 0.000 description 32
- 210000003811 finger Anatomy 0.000 description 28
- 230000033001 locomotion Effects 0.000 description 13
- 210000003813 thumb Anatomy 0.000 description 13
- 238000005259 measurement Methods 0.000 description 7
- 230000001276 controlling effect Effects 0.000 description 5
- 238000010586 diagram Methods 0.000 description 5
- 230000000007 visual effect Effects 0.000 description 5
- 230000004872 arterial blood pressure Effects 0.000 description 4
- 239000008280 blood Substances 0.000 description 4
- 210000004369 blood Anatomy 0.000 description 4
- 230000036772 blood pressure Effects 0.000 description 4
- 230000036541 health Effects 0.000 description 4
- 210000000707 wrist Anatomy 0.000 description 4
- 230000008901 benefit Effects 0.000 description 3
- 210000004204 blood vessel Anatomy 0.000 description 3
- 230000008859 change Effects 0.000 description 3
- 238000004891 communication Methods 0.000 description 3
- 230000000694 effects Effects 0.000 description 3
- 238000001914 filtration Methods 0.000 description 3
- 238000012986 modification Methods 0.000 description 3
- 230000004048 modification Effects 0.000 description 3
- 238000012545 processing Methods 0.000 description 3
- 229920001621 AMOLED Polymers 0.000 description 2
- 241001025261 Neoraja caerulea Species 0.000 description 2
- 238000010521 absorption reaction Methods 0.000 description 2
- 238000007792 addition Methods 0.000 description 2
- 230000004075 alteration Effects 0.000 description 2
- 238000013459 approach Methods 0.000 description 2
- 230000017531 blood circulation Effects 0.000 description 2
- 238000001514 detection method Methods 0.000 description 2
- 238000005516 engineering process Methods 0.000 description 2
- 239000011521 glass Substances 0.000 description 2
- 238000011478 gradient descent method Methods 0.000 description 2
- 239000004973 liquid crystal related substance Substances 0.000 description 2
- 238000010801 machine learning Methods 0.000 description 2
- 210000003205 muscle Anatomy 0.000 description 2
- 230000002093 peripheral effect Effects 0.000 description 2
- 210000002435 tendon Anatomy 0.000 description 2
- 238000007476 Maximum Likelihood Methods 0.000 description 1
- 230000009471 action Effects 0.000 description 1
- 230000000747 cardiac effect Effects 0.000 description 1
- 239000004020 conductor Substances 0.000 description 1
- 230000002596 correlated effect Effects 0.000 description 1
- 230000003247 decreasing effect Effects 0.000 description 1
- 230000003205 diastolic effect Effects 0.000 description 1
- 210000004247 hand Anatomy 0.000 description 1
- 230000006872 improvement Effects 0.000 description 1
- 230000003993 interaction Effects 0.000 description 1
- 230000001788 irregular Effects 0.000 description 1
- 230000031700 light absorption Effects 0.000 description 1
- 239000007788 liquid Substances 0.000 description 1
- 239000000463 material Substances 0.000 description 1
- 239000013307 optical fiber Substances 0.000 description 1
- 230000010412 perfusion Effects 0.000 description 1
- 230000035790 physiological processes and functions Effects 0.000 description 1
- 238000003825 pressing Methods 0.000 description 1
- 230000008569 process Effects 0.000 description 1
- 239000004065 semiconductor Substances 0.000 description 1
- 239000000758 substrate Substances 0.000 description 1
- 210000001519 tissue Anatomy 0.000 description 1
- 239000012780 transparent material Substances 0.000 description 1
- XLYOFNOQVPJJNP-UHFFFAOYSA-N water Substances O XLYOFNOQVPJJNP-UHFFFAOYSA-N 0.000 description 1
Classifications
-
- A—HUMAN NECESSITIES
- A61—MEDICAL OR VETERINARY SCIENCE; HYGIENE
- A61B—DIAGNOSIS; SURGERY; IDENTIFICATION
- A61B5/00—Measuring for diagnostic purposes; Identification of persons
- A61B5/02—Detecting, measuring or recording pulse, heart rate, blood pressure or blood flow; Combined pulse/heart-rate/blood pressure determination; Evaluating a cardiovascular condition not otherwise provided for, e.g. using combinations of techniques provided for in this group with electrocardiography or electroauscultation; Heart catheters for measuring blood pressure
- A61B5/024—Detecting, measuring or recording pulse rate or heart rate
- A61B5/02416—Detecting, measuring or recording pulse rate or heart rate using photoplethysmograph signals, e.g. generated by infrared radiation
-
- A—HUMAN NECESSITIES
- A61—MEDICAL OR VETERINARY SCIENCE; HYGIENE
- A61B—DIAGNOSIS; SURGERY; IDENTIFICATION
- A61B5/00—Measuring for diagnostic purposes; Identification of persons
- A61B5/68—Arrangements of detecting, measuring or recording means, e.g. sensors, in relation to patient
- A61B5/6801—Arrangements of detecting, measuring or recording means, e.g. sensors, in relation to patient specially adapted to be attached to or worn on the body surface
- A61B5/6802—Sensor mounted on worn items
- A61B5/681—Wristwatch-type devices
-
- A—HUMAN NECESSITIES
- A61—MEDICAL OR VETERINARY SCIENCE; HYGIENE
- A61B—DIAGNOSIS; SURGERY; IDENTIFICATION
- A61B5/00—Measuring for diagnostic purposes; Identification of persons
- A61B5/68—Arrangements of detecting, measuring or recording means, e.g. sensors, in relation to patient
- A61B5/6801—Arrangements of detecting, measuring or recording means, e.g. sensors, in relation to patient specially adapted to be attached to or worn on the body surface
- A61B5/6843—Monitoring or controlling sensor contact pressure
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F1/00—Details not covered by groups G06F3/00 - G06F13/00 and G06F21/00
- G06F1/16—Constructional details or arrangements
- G06F1/1613—Constructional details or arrangements for portable computers
- G06F1/163—Wearable computers, e.g. on a belt
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/011—Arrangements for interaction with the human body, e.g. for user immersion in virtual reality
- G06F3/014—Hand-worn input/output arrangements, e.g. data gloves
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/017—Gesture based interaction, e.g. based on a set of recognized hand gestures
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/03—Arrangements for converting the position or the displacement of a member into a coded form
- G06F3/041—Digitisers, e.g. for touch screens or touch pads, characterised by the transducing means
- G06F3/0416—Control or interface arrangements specially adapted for digitisers
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/03—Arrangements for converting the position or the displacement of a member into a coded form
- G06F3/041—Digitisers, e.g. for touch screens or touch pads, characterised by the transducing means
- G06F3/042—Digitisers, e.g. for touch screens or touch pads, characterised by the transducing means by opto-electronic means
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0487—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser
- G06F3/0488—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser using a touch-screen or digitiser, e.g. input of commands through traced gestures
Definitions
- the disclosure relates generally to wearable computing devices. More particularly, the disclosure relates to wearable computing devices which can determine a location of a force applied to a user interface of the wearable computing device using optical sensors.
- Wearable computing devices can include a display to display content (e.g., time, date, functions of the wearable computing device, etc.) to a user.
- Some wearable computing devices can gather data regarding activities performed by the user, or regarding the user's physiological state. Such data may include data representative of the ambient environment around the user or the user's interaction with the environment. For example, the data can include motion data regarding the user's movements and/or physiological data obtained by measuring various physiological characteristics of the user, such as heart rate, perspiration levels, and the like.
- Some wearable computing devices may include a touch-sensitive display, while other wearable computing devices may include a non-touch-sensitive display.
- a wearable computing device includes a housing having an upper side and a lower side, where the lower side of the housing is opposite to the upper side of the housing and is configured to be in contact with a body part of a user when the wearable computing device is worn by the user.
- the wearable computing device also includes a user interface disposed on the upper side of the housing and sensors which are disposed on the lower side of the housing. The sensors are configured to output one or more optical readings when a force is applied to the user interface.
- the wearable computing device may further include one or more processors configured to determine a location at which the force is applied to the user interface based on the one or more optical readings output by the sensors.
- the sensors may include photoplethysmography (PPG) sensors configured to monitor a heart rate of the user when the wearable computing device is worn by the user, and the PPG sensors include one or more light-emitting diodes and a plurality of detectors.
- PPG photoplethysmography
- the sensors may include at least three photoplethysmography (PPG) sensors, and at least one PPG sensor of the at least three PPG sensors is spaced apart from another PPG sensor of the at least three PPG sensors in a first direction and a second direction.
- PPG photoplethysmography
- the one or more processors may be configured to execute one or more functions of the wearable computing device based on the location at which the force is applied to the display as determined by the one or more processors.
- the one or more processors may be configured to determine the location at which the force is applied to the user interface based on whether an area of the user interface to which the force is applied corresponds to a first area or a second area, the first area being different from than the second area.
- the first area may be larger than the second area.
- the one or more processors may be configured to determine an amplitude of each of the one or more optical readings based on a first model having a first scale parameter which reflects a first variance of the force applied to the user interface, and when the area of the display to which the force is applied corresponds to the second area, the one or more processors may be configured to determine the amplitude of each of the one or more optical readings based on a second model having a second scale parameter which reflects a second variance of the force applied to the user interface, the second variance being different from the first variance.
- the one or more processors may be configured to determine the location at which the force is applied to the user interface based on a value of each of the optical readings output by the sensors and by applying a loss function to minimize a difference between an actual location at which the force is applied and an estimated location at which the force is applied.
- the one or more processors may be configured to determine the location at which the force is applied to the user interface using a value of each of the one or more optical readings output by the sensors and known (i.e., predefined and stored) positions of the sensors to estimate the location at which the force is applied by applying a loss function. An estimated location resulting from minimizing the loss function may then be used as the determined location at which the force is applied.
- determining the location at which the force is applied may therefore include using an estimate of the location resulting from applying a loss function, where the loss function includes values of each of the one or more optical readings and known positions of the sensors at the lower side of the wearable computing device’s housing.
- the loss function may further include a probability density function determining a probability of an optical reading output by an optical sensor being corrupted by measurement noise.
- the probability density function may be a standard Gaussian function which is used for reconstructing a location of the application of a force based on measurements from the one or more sensors.
- the one or more processors may be configured to apply the loss function by performing a two-dimensional grid search method or a gradient descent search method.
- the user interface includes a non-touch sensitive display configured to display a plurality of elements corresponding to a plurality of selectable functions of the wearable computing device.
- the one or more processors may be configured to control the display to stop the display of one or more of the plurality of elements, and in response to determining the location at which the force is applied to the display corresponds to a remaining first element of the plurality of elements displayed on the display, the one or more processors may be further configured to execute a first selectable function of the plurality of selectable functions which corresponds to the remaining first element, based on the determined location.
- the user interface includes a plurality of faux buttons which respectively correspond to a plurality of selectable functions of the wearable computing device, and in response to determining the location at which the force is applied to a first faux button of the plurality of faux buttons of the user interface, the one or more processors are configured to execute a first selectable function of the plurality of selectable functions which corresponds to the first faux button, based on the determined location.
- the user interface includes a display, and the display is anon-touch sensitive display.
- the sensors may include photoplethysmography (PPG) sensors configured to monitor a heart rate of the user when the wearable computing device is worn by the user, and the one or more processors may be configured to identify a gesture of the user based on the one or more optical readings output by the PPG sensors.
- the one or more processors may be configured to execute a function of the computer wearable device based on the gesture of the user identified by the one or more processors.
- the wearable computing device may further include at least one of an accelerometer or a gyroscope, and the one or more processors may be configured to identify the gesture of the user based on the one or more optical readings output by the PPG sensors and one or more outputs of the at least one of the accelerometer or the gyroscope.
- a computer-implemented method includes receiving (e.g., by one or more processors of a wearable computing device) optical readings output by sensors disposed on a lower side of a housing of the wearable computing device, when a force is applied to a user interface disposed on an upper side of the housing.
- the lower side of the housing is opposite to the upper side of the housing and is configured to be in contact with a body part of a user when the wearable computing device is worn by the user.
- the method may further include determining, by the one or more processors of the wearable computing device, a location at which the force is applied to the user interface based on the one or more received optical readings.
- the method may further include executing one or more functions of the wearable computing device based on the location at which the force is applied to the user interface as determined by the one or more processors.
- the method may further include displaying on a display of the user interface instructions indicating to a user to calibrate the wearable computing device by indicating an area of the display to which the force is to be applied to the display.
- the method may further include, when the area of the force indicated by the user corresponds to a first area, determining an amplitude of each of the one or more optical readings based on a first model having a first scale parameter which reflects a first variance of the force to be applied to the display, and when the area of the force indicated by the user corresponds to a second area, determining the amplitude of each of the one or more optical readings based on a second model having a second scale parameter which reflects a second variance of the force to be applied to the display, the first area being greater than the second area, and the first variance being greater than the second variance.
- the method may further include determining the location at which the force is applied to the user interface based on a value of each of the optical readings output by the sensors and by applying a loss function to minimize a difference between an actual location at which the force is applied and an estimated location at which the force is applied.
- the method may further include displaying, on a nontouch sensitive display of the user interface, a plurality of elements corresponding to a plurality of selectable functions of the wearable computing device, and in response to a noise level of the sensors increasing beyond a threshold, controlling the display to stop the display of one or more of the plurality of elements, and in response to determining the location at which the force is applied to the user interface corresponds to a remaining first element of the plurality of elements displayed on the display, executing a first selectable function of the plurality of selectable functions which corresponds to the remaining first element, based on the determined location.
- a non-transitory computer-readable medium which stores instructions that are executable by one or more processors of a wearable computing device.
- the non-transitory computer-readable medium stores instructions including instructions to cause the one or more processors to receive one or more optical readings output by sensors disposed on a lower side of a housing of the wearable computing device, when a force is applied to a user interface disposed on an upper side of the housing, wherein the lower side of the housing is opposite to the upper side of the housing and configured to be in contact with a body part of a user when the wearable computing device is worn by the user.
- the non-transitory computer-readable medium stores instructions including instructions to cause the one or more processors to determine a location at which the force is applied to the user interface based on the one or more received optical readings.
- the non-transitory computer-readable medium stores instructions including instructions to execute one or more functions of the wearable computing device based on the location at which the force is applied to the user interface as determined by the one or more processors.
- the non-transitory computer-readable medium may store additional instructions to execute other aspects of the wearable computing device and computer-implemented method as described herein.
- FIG. 1 depicts an example wearable computing device according to according to one or more example embodiments of the disclosure
- FIG. 2 depicts an exploded view of an example wearable computing device according to one or more example embodiments of the disclosure
- FIG. 3 depicts an example block diagram of the wearable computing device according to one or more example embodiments of the disclosure
- FIGS. 4A and 4B depict top views of example wearable computing devices according to one or more example embodiments of the disclosure
- FIG. 4C depicts a bottom view of an example wearable computing device according to one or more example embodiments of the disclosure.
- FIGS. 5A and 5B depict a force applied to a display of the wearable computing device and a corresponding signal response diagram of sensors, according to one or more example embodiments of the disclosure
- FIGS. 6A and 6B depict example press Gaussian responses corresponding to different scale parameters, according to one or more example embodiments of the disclosure;
- FIGS. 7A and 7B depict example observation values according to one or more example embodiments of the disclosure;
- FIGS. 8A and 8B depict an example determination of the location of a force applied to the display based on a loss function result, according to one or more example embodiments of the disclosure
- FIGS. 9A and 9B depict another example determination of the location of a force applied to the display based on a loss function result, according to one or more example embodiments of the disclosure
- FIGS. 10A and 10B depict an example determination of the location of a force applied to the display based on a loss function result in a noisy environment, according to one or more example embodiments of the disclosure;
- FIG. 11 depicts example response signals of various sensors of the wearable computing device to detect a gesture of a user, according to one or more example embodiments of the disclosure;
- FIGS. 12A and 12B depict example one-handed gestures of a user and corresponding heatmaps reconstructed from PPG sensors, according to one or more example embodiments of the disclosure.
- FIGS. 13 and 14 each illustrate a flow diagram of an example, non-limiting computer-implemented method according to one or more example embodiments of the disclosure.
- first element may be termed as a second element
- second element may be termed as a first element
- the term "and / or” includes a combination of a plurality of related listed items or any item of the plurality of related listed items.
- the scope of the expression or phrase “A and/or B” includes the item “A”, the item “B”, and the combination of items "A and B”.
- the scope of the expression or phrase "at least one of A or B” is intended to include all of the following: (1) at least one of A, (2) at least one of B, and (3) at least one of A and at least one of B.
- the scope of the expression or phrase "at least one of A, B, or C” is intended to include all of the following: (1) at least one of A, (2) at least one of B, (3) at least one of C, (4) at least one of A and at least one of B, (5) at least one of A and at least one of C, (6) at least one of B and at least one of C, and (7) at least one of A, at least one of B, and at least one of C.
- Examples of the disclosure are directed to a wearable computing device that can be worn, for example, on a user’s wrist.
- the wearable computing device may include a watch.
- the wearable computing device includes a housing having an upper side and a lower side. The lower side of the housing is opposite to the upper side of the housing and is configured to be in contact with a body part of a user when the wearable computing device is worn by the user.
- the wearable computing device further includes a user interface disposed on the upper side of the housing and sensors disposed on the lower side of the housing. The sensors may be configured to output one or more optical readings when a force is applied to the user interface.
- the wearable computing device may further include one or more processors configured to determine a location at which the force is applied to the user interface based on the one or more optical readings output by the sensors and a loss function described herein.
- the user interface is a tangible medium by which a user interacts with the wearable computing device.
- a user interface which is disposed on the upper side of the housing may include, for example, a display (which may be non-touch sensitive), one or more faux buttons, or the combination of the display and one or more faux buttons.
- the wearable computing device can include a housing with a display (which may be non-touch sensitive) on an upper side of the housing and sensors on a lower side of the housing.
- the lower side of the housing is opposite to the upper side of the housing and is configured to be in contact with a body part of a user when the wearable computing device is worn by the user.
- the sensors may be used to indirectly sense a location of a touch by a user on the display. For example, when a user presses the display, optical readings from the sensors may fluctuate based on where the user presses. Optical readings from a sensor which is located closer to the location where the user presses sense more of the optical back-reflections compared to another sensor which is located further away from the location where the user presses.
- one or more processors can determine a location where the user touches on the display and a function of the wearable computing device corresponding to the determined location can be carried out. Determining the location may involve an estimate of location parameters, e.g., location coordinates, based on a loss function implemented with the optical readings.
- the display may display on a graphical user interface of the display four different visual elements, each visual element corresponding to a separate function of the wearable computing device, in respective quadrants of the display. If a user applies a force to an upper left quadrant of the display, for example to “select” the function represented by the visual element displayed in that quadrant, the sensors may output respective optical readings in response to the applied force. For example, a first sensor which is located closest to a location at which the force is applied to the display may output a signal with a higher amplitude or higher value compared to a second sensor which is located further away from the location at which the force is applied to the display.
- the one or more processors may receive one or more optical readings from each of the sensors and determine a location at which the force is applied to the display based on the one or more optical readings output by the sensors. If the one or more processors determine that the force is applied to a location corresponding to the upper left quadrant of the display based on the received one or more optical readings, the one or more processors may execute the function corresponding to the visual element displayed in the upper left quadrant of the display.
- the sensors can include, for example, multipath photoplethysmography (PPG) sensors which can also be used to monitor a heart rate of the user.
- PPG sensors may include one or more emitters (e.g., light-emitting diodes (LEDs)) and a plurality of detectors (e.g., two or more photodiodes).
- the detectors may be spaced apart from one another at various locations on the lower side of the housing so as to increase the accuracy of estimating the location of the touch by the user on the display.
- the sensors may include at least three PPG sensors, and at least one PPG sensor of the at least three PPG sensors is spaced apart from another PPG sensor of the at least three PPG sensors in a first direction (e.g., X-axis) and a second direction (e.g., Y- axis). That is, the at least three PPG sensors are not arranged in a linear manner.
- the one or more processors may be configured to determine the location at which the force is applied to the display based on whether an area of the display to which the force is applied corresponds to a first area or a second area, where the first area is different from the second area. For example, if a user applies their thumb to the display, then the area of the display to which the force is applied is larger than if the user were to apply their index finger to the display. As another example, if a user has large fingers (e.g., relative to an average human finger size for a male and/or female), it can be considered that the area of the display to which the force is applied would be larger than a user having average size fingers.
- a user may provide an input to the wearable computing device (e.g., via a mechanical button) indicating the size or area of the display which is to receive the force applied from the user.
- the input may indicate the area size (e.g., a first area or a second area), which can be used to determine a value for a scale parameter (e.g., a first scale parameter or a second scale parameter).
- the value for the scale parameter may indicate or describe a diffuseness of a Gaussian response used to analyze the optical signals output from the sensors for determining a location of the force applied to the display.
- a Gaussian response when graphed generally has a symmetric "bell curve" shape.
- a size of an area to which the force is applied affects the magnitude of the pressure and an amplitude of the force is greatest at a central location of the force.
- a distribution of the amplitude of the force (and correspondingly the pressure) declines (e.g., exponentially) at points located further away from the central location of the force.
- a larger area will have greater diffuseness than a smaller area.
- a higher-variance response would be experienced, and a higher scale parameter may be appropriate (e.g., a value of 10).
- a lower-variance response would be experienced, and a lower scale parameter value may be appropriate (e.g., a value of 1).
- the scale parameter values may be implemented in a model which describes the touch response amplitude of the sensors which is registered by the wearable computing device.
- (x, y) represents the coordinate of the particular sensor (i.e., the coordinate of the particular detector which may be a photodiode) reading the PPG fluctuations.
- the term (x_press, y_press) represents the ground truth coordinates of the location at which a force is applied to the top of the wearable computing device.
- the scale parameter describes the “diffuseness” of the Gaussian response, as explained above, and is used in modeling the captured optical readings based on the Gaussian function for taking into account an area covered by a touch which is user specific or user-group specific.
- the one or more processors may be configured to determine an amplitude of each of the one or more optical readings output by the sensors based on a first model having a first scale parameter (e.g., having a value of 10) which reflects or describes a first variance of the force applied to the user interface.
- a first scale parameter e.g., having a value of 10.
- the one or more processors may be configured to utilize a first Gaussian model to determine a location at which the force is applied to the user interface using a first loss function having the first scale parameter (e.g., having the value of 10) which reflects or describes the first variance of the force applied to the user interface.
- a first Gaussian model to determine a location at which the force is applied to the user interface using a first loss function having the first scale parameter (e.g., having the value of 10) which reflects or describes the first variance of the force applied to the user interface.
- the one or more processors may be configured to determine the amplitude of each of the one or more optical readings output by the sensors based on a second model having a second scale parameter (e.g., having a value of 1) which reflects a second variance of the force applied to the user interface.
- a second scale parameter e.g., having a value of 1
- the one or more processors may be configured to utilize a second Gaussian model to determine the location at which the force is applied to the user interface using a second loss function having the second scale parameter (e.g., having the value of 1) which reflects or describes the second variance of the force applied to the user interface.
- the first variance is different from (e.g., greater than) the second variance.
- the one or more processors may be configured to determine the location of the force applied to the user interface based on a first scale parameter when the force applied to the user interface corresponds to a first area of the user interface (e.g., corresponding to the size of a user’s thumb), and the one or more processors may be configured to determine the location of the force applied to the user interface based on a second scale parameter when the force applied to the user interface corresponds to a second area of the user interface (e.g., corresponding to the size of a user’s index finger).
- the first scale parameter is greater than the second scale parameter
- the first area is greater than the second area.
- the one or more processors of the wearable computing device may receive a number of observations from the sensors at a given point in time which corresponds to the number of sensors. For example, if the wearable computing device has N PPG sensors (in particular N detectors), then the one or more processors of the wearable computing device may receive N observations from the detectors.
- the one or more processors of the wearable computing device may receive 3 observations (i.e. , 1 observation from each of the detectors) at a given point in time.
- the one or more processors may be configured to determine the location at which the force is applied to the display based on an optical reading of a sensor among the sensors having a highest value, among the one or more optical readings output by the sensors.
- the one or more processors may be configured to determine the location at which the force is applied to the display based on a highest amplitude among the amplitudes of the one or more optical readings output from the sensors.
- the one or more processors may be configured to determine the location at which the force is applied to the display based on one or more of the amplitudes of the one or more optical readings output from the sensors and a loss function described herein.
- Examples of the disclosure are also directed to a non-transitory computer- readable medium which stores instructions that are executable by one or more processors of a wearable computing device.
- the instructions may include instructions to cause the one or more processors to receive one or more optical readings output by sensors disposed on a lower side of a housing of the wearable computing device, when a force is applied to a display disposed on an upper side of the housing.
- the lower side of the housing may be opposite to the upper side of the housing and be configured to be in contact with a body part of a user when the wearable computing device is worn by the user.
- the instructions may further include instructions to cause the one or more processors to determine a location at which the force is applied to the display based on the one or more received optical readings.
- the instructions may further include instructions to cause the one or more processors to execute one or more functions of the wearable computing device based on the location at which the force is applied to the display.
- Example functions of the wearable computing device may include checking health information about the user such as a blood pressure, making and/or receiving a phone call, sending and/or receiving a text message, obtaining a current time, setting a timer, a stopwatch function, controlling an external device such as a home appliance, and the like.
- the instructions may further include instructions to cause the one or more processors to display a graphical user interface indicating to a user to calibrate the wearable computing device by indicating an area of the display to which a force is to be applied to the display.
- the instructions further include instructions to cause the one or more processors to determine an amplitude of each of the one or more optical readings based on a first model having a first scale parameter which reflects a first variance of the force to be applied to the display.
- the instructions further include instructions to cause the one or more processors to determine the amplitude of each of the one or more optical readings based on a second model having a second scale parameter which reflects a second variance of the force to be applied to the display.
- the first area may be greater than the second area
- the first variance may be greater than the second variance.
- the instructions may further include instructions to cause the one or more processors to determine the location at which the force is applied to the display based on a highest amplitude among the amplitudes of the one or more optical readings.
- the instructions may further include instructions to cause the one or more processors to determine the location at which the force is applied to the display based on an optical reading of a sensor among the sensors having a highest value, among the one or more optical readings received by the one or more processors.
- Examples of the disclosure are also directed to computer implemented methods of a wearable computing device.
- the method may include receiving one or more optical readings output by sensors disposed on a lower side of a housing of the wearable computing device, when a force is applied to a display disposed on an upper side of the housing.
- the lower side of the housing may be opposite to the upper side of the housing and be configured to be in contact with a body part of a user when the wearable computing device is worn by the user.
- the method may further include determining, by one or more processors of the wearable computing device, a location at which the force is applied to the display based on the one or more received optical readings.
- the method may further include executing one or more functions of the wearable computing device based on the location at which the force is applied to the display.
- Example functions of the wearable computing device may include checking health information about the user such as a blood pressure, making and/or receiving a phone call, sending and/or receiving a text message, obtaining a current time, setting a timer, a stopwatch function, controlling an external device such as a home appliance, and the like.
- the method may further include displaying a graphical user interface indicating to a user to calibrate the wearable computing device by indicating an area of the display to which a force is to be applied to the display.
- the method may include determining an amplitude of each of the one or more optical readings based on a first model having a first scale parameter which reflects a first variance of the force to be applied to the display.
- the method may include determining the amplitude of each of the one or more optical readings based on a second model having a second scale parameter which reflects a second variance of the force to be applied to the display.
- the first area may be greater than the second area, and the first variance may be greater than the second variance.
- the method may include determining the location at which the force is applied to the display based on a highest amplitude among the amplitudes of the one or more optical readings.
- the method may include determining the location at which the force is applied to the display based on one or more of the amplitudes of the one or more optical readings output from the sensors and a loss function described herein.
- the method may include determining the location at which the force is applied to the display based on an optical reading of a sensor among the sensors having a highest value, among the one or more optical readings received by the one or more processors.
- the one or more processors of the wearable computing device may determine the location of a user touching an element or part of the wearable computing device at an upper side by calculating an estimate of location parameters, e.g., location coordinates, based on a loss function that is optimized to find a ground truth coordinate location of where the force is applied to the upper side of the wearable computing device.
- location parameters e.g., location coordinates
- the probabilistic channel given that an observation (for example, obs l) could be corrupted by Gaussian measurement noise, may be written as: p(obs_l
- (x_press, y_press)) G[ EXP ⁇ -[ (x_l, y_l) - (x_press, y_press) ] A 2 / scale k ⁇ - obs_l ].
- the G(.) function describes the probability density of a standard Gaussian function which may be used to reconstruct the location of the application of the force using measurements obtained from the detectors, which are sparsely provided and distributed. For example, a probability of receiving the values observed for each of the observations N is calculated based on candidate touch events (i.e. , candidate locations where the force is estimated to be applied). Whatever candidate touch event maximizes the probability (or minimizes the loss) may be considered as the most likely location of the force (i.e., touch event). For example, an expression of the negative log likelihood of all the observations may be used to find the ground truth press coordinates, as follows:
- the terms “x_l, y_l”, “x_2, y_2”, and “x_N, y_N” correspond to the location of each PPG detector, which is known.
- the terms “obs l”, “obs_2”, and “obs_N” correspond to the observed values of the respective detectors.
- the term “scale k” is the scale parameter value which describes the diffuseness of the Gaussian response as described herein.
- the terms “x_press, y_press” corresponds to the value that is to be estimated (i.e., the X, Y coordinate value of the location of the force). For example, in a three channel PPG sensor, where there are three detectors, N may be equal to three.
- a two-dimensional grid search may be performed to estimate (x_press, y_press) by finding the global loss minimizer.
- the one or more processors may be configured to execute a program to perform a direct search in which every X, Y coordinate pair (e.g., corresponding to the area of the display) is tested as candidate touch events to obtain a result which achieves the minimal loss.
- the candidate touch event achieving the lowest loss (i.e., a minimal error) between may correspond to the estimated touch location.
- the one or more processors may implement a known gradient descent method to obtain a result (X, Y coordinate) which obtains the minimal loss.
- the gradient descent search method may utilize random candidate touch events (i. e. , random candidate X, Y coordinates) to obtain a result which achieves the minimal loss rather than a direct search report in which all of the candidate touch events are tested.
- the gradient descent search method may use a smaller search space and thus be less computationally expensive than the direct search approach, saving energy and time.
- the disclosure is not limited to a direct search method or gradient descent search method, and other methods for minimizing a loss function may also be implemented.
- the user interface may include a non-touch sensitive display which displays a plurality of selectable functions of the wearable computing device.
- the one or more processors may be configured to control the display so that a number of the plurality of selectable functions displayed on the display may be reduced, and the one or more processors may be configured to execute a function among the plurality of selectable functions based on the location at which the one or more processors determines the force is applied to the display.
- a noise level of the sensors may increase when the wearable computing device is not securely held to the body part of the user and/or due to a low battery condition, such that the one or more optical readings may be affected by noise, and the accuracy of the sensors may be reduced.
- a number of the plurality of selectable functions displayed on the display may be reduced (e.g., reducing icons displayed on the display from ten icons to four icons) when the noise level of the sensors exceeds a threshold (e.g., a signal-to-noise ratio being greater than lOdB).
- Stopping the displaying of one or more of the plurality of selectable functions may enlarge a space on the display for each of the remaining selectable functions to be displayed.
- a likelihood that the one or more processors may accurately execute a function that the user intends to select may be increased, even though an accuracy of the detection or determination of the location of the force applied to the display may be reduced due to the noise encountered or experienced by the sensors.
- the noisy condition encountered by the sensors may be masked.
- the user interface may additionally, or alternatively, include a plurality of faux buttons which respectively correspond to a plurality of selectable functions of the wearable computing device.
- the one or more processors may be configured to execute a function of the computer wearable device among the plurality of selectable functions based on the location at which the force is applied with respect to respective locations of the plurality of faux buttons.
- the faux buttons (or faux switch) may represent or indicate functions of the wearable computing device that can be performed by the wearable computing device.
- the faux buttons may not be mechanically or electrically connected (e.g., via a switch or capacitive sensors) to implement a function of the wearable computing device.
- the one or more processors may be configured to execute a function of the computer wearable device among the plurality of selectable functions based on the location at which the force is applied with respect to respective locations of the plurality of faux buttons.
- the wearable computing device may further include an accelerometer and/or a gyroscope to detect or sense motion data (e.g., for counting steps of a user) of the wearable computing device.
- the sensors may include PPG sensors which are also configured to monitor a heart rate of the user of the wearable computing device.
- Motion of a user’s hand affects arterial pressure and volumetric structure (muscle/tendon), creating a signature dip in reflection/absorption reflected in the PPG signal.
- the PPG sensors may capture the arterial pressure profiles spatially over a two-dimensional area (e.g., in x and y directions) on the lower side of the housing of the wearable computing device.
- the one or more processors may be configured to identify a gesture of the user based on the one or more optical readings output by the PPG sensors, and the one or more processors may be configured to execute a function of the computer wearable device (or another device) based on the gesture of the user identified by the one or more processors.
- the one or more processors may be configured to identify the gesture of the user based on the one or more optical readings output by the PPG sensors together with one or more outputs of the accelerometer and/or the gyroscope.
- the gesture of the user may include hand gestures including clinching of a fist, a pinching gesture with the fingers, squeezing of a hand, and the like.
- the gestures may be mapped to respective functions of the wearable computing device (e.g., to make a phone call), or a function of another device (e.g., to operate a home appliance) which may be controllable via the wearable computing device by the identification of the gesture.
- the wearable computing device may identify a gesture based on the one or more optical readings output by the PPG sensors. For example, each gesture may correspond to a respective optical signal output by the PPG sensors so that a gesture may be correctly identified.
- optical signals output by the PPG sensors may be analyzed to identify the gesture (e.g., via machine learning algorithms to classify the output optical readings, by comparing the optical signals with known optical signals corresponding to respective gestures, etc.).
- portions of the optical readings which are attributed to a heart rate of the user may be filtered out. For example, a high pass heart rate filtering operation may be performed with respect to the optical readings to notch out the heart rate (arterial pulse), so that the majority of the optical readings which are used to identify the gesture corresponds to or is attributed to, the movement of the user’s body part (e.g., the hand).
- Example of the disclosure provide several technical effects, benefits, and/or improvements in computing technology and the technology of wearable computing devices.
- a location of a touch on a display may be indirectly sensed by sensors disposed on a lower side of a housing of the wearable computing device which is in contact with a body part of a user when the wearable computing device is worn by the user.
- the wearable computing device need not have a touch-sensitive display, thereby reducing the number of parts included in the wearable computing device.
- the wearable computing device leverages sensors which may be pre-existing in the wearable computing device.
- the pre-existing sensors may include PPG sensors used for other purposes, such as detecting a heart rate of a user. Therefore, it is not necessary to add further sensors to the wearable computing device to determine a location of a touch by a user on the display.
- the wearable computing device may utilize less power than a wearable computing device which includes a touch-sensitive display.
- the wearable computing device may utilize less space than a wearable computing device which includes a touch-sensitive display. Therefore, the wearable computing device may be smaller and sleeker, or may provide space for other components which might not otherwise be installable if a touch-sensitive display were provided in the wearable computing device.
- the wearable computing device may not include a display at all, and functions of the wearable computing device may be implemented using faux buttons which are associated with corresponding functions of the wearable computing device.
- the wearable computing device may include a display as well as faux buttons, where functions of the wearable computing device may be implemented using the display and faux buttons, or only the faux buttons which are associated with corresponding functions of the wearable computing device.
- FIGS. 1 through 4B illustrate examples of a wearable computing device 100 according to examples of the disclosure.
- FIG. 1 illustrates an example wearable computing device 100 which can be worn, for example, on an arm 102 (e.g., wrist) of a user.
- the wearable computing device 100 can include a housing 110 (e.g., a body).
- FIG. 2 illustrates an exploded view of the wearable computing device 100 where the housing 110 includes an upper side 110a and a lower side 110b, and the housing 110 can define a cavity 112 in which one or more electronic components (e.g., disposed on one or more printed circuit boards) are disposed.
- one or more electronic components e.g., disposed on one or more printed circuit boards
- the wearable computing device 100 can include a printed circuit board 120 disposed within the cavity 112. Furthermore, one or more electronic components can be disposed on the printed circuit board 120.
- the wearable computing device 100 can further include a battery (not shown) that is disposed within the cavity 112 defined by the housing 110.
- the wearable computing device 100 can further include various sensors 170 that are disposed within the cavity 112 defined by the housing 110.
- the sensors 170 may include multipath photoplethysmography (PPG) sensors 172 disposed at the lower side 110b of the housing 110 which may be used to monitor a heart rate of the user.
- PPG multipath photoplethysmography
- the PPG sensors 172 may include one or more emitters (e.g., light-emitting diodes (LEDs)) and a plurality of detectors (e.g., photodiodes). Light emitted from the one or more emitters is transmitted in a direction toward the user’s body part (e.g., a portion of a user’s wrist) which is in contact with the lower side 110b of the housing 110. The light then interacts with blood vessels of the user, where it is modified to a degree that is influenced by the current blood volume in the blood vessels. The modified light is directed back toward the PPG detectors by reflection and/or refraction.
- LEDs light-emitting diodes
- detectors e.g., photodiodes
- the PPG detectors generate data (e.g., one or more signals) which is reflective of the current blood volume of the blood vessels of the user which received the light emitted from the one or more emitters.
- the sensors 170 may also include an accelerometer 174 which may be used to capture motion information with respect to the wearable computing device 100.
- the sensors 170 may also include a gyroscope 176 which may also be used to capture motion information with respect to the wearable computing device 100.
- the wearable computing device 100 can include a first band 130 and a second band 132. As shown, the first band 130 can be coupled to the housing 110 at a first location thereon. Conversely, the second band 132 can be coupled to the housing 110 at a second location thereon. Furthermore, the first band 130 and the second band 132 can be coupled to one another to secure the housing 110 to the arm 102 of the user.
- the first band 130 can include a buckle or clasp (not shown). Additionally, the second band 132 can include a plurality of apertures (not shown) spaced apart from one another along a length of the second band 132. In such implementations, a prong of the buckle associated with the first band 130 can extend through one of the plurality of openings defined by the second band 132 to couple the first band 130 to the second band 132. It should be appreciated that the first band 130 can be coupled to the second band 132 using any suitable type of fastener. For example, in some implementations, the first band 130 and the second band 132 can include a magnet. In such implementations, the first band 130 and the second band 132 can be magnetically coupled to one another to secure the housing 110 to the arm 102 of the user.
- the wearable computing device 100 can include a cover 140 positioned on the housing 110 so that the cover 140 is positioned on top of (over) the display 182. In this manner, the cover 140 can protect the display 182 from being scratched.
- the wearable computing device 100 can include a seal (not shown) positioned between the housing 110 and the cover 140. For instance, a first surface of the seal can contact the housing 110 and a second surface of the seal can contact the cover 140. In this manner, the seal between the housing 110 and the cover 140 can prevent a liquid (e.g., water) from entering the cavity 112 defined by the housing 110.
- a liquid e.g., water
- the cover 140 can be optically transparent so that the user can view information being displayed on the display 182.
- the cover 140 can include a glass material. It should be understood, however, that the cover 140 can include any suitable optically transparent material.
- FIG. 3 illustrates an example block diagram of the wearable computing device 100 according to one or more example embodiments of the disclosure.
- the wearable computing device 100 may include one or more processors 150, one or more memory devices 160, one or more sensors 170, and a user interface 180.
- the one or more processors 150 can be any suitable processing device that can be included in a wearable computing device 100.
- a processor 150 may include one or more of a processor, processor cores, a controller and an arithmetic logic unit, a central processing unit (CPU), a graphics processing unit (GPU), a digital signal processor (DSP), an image processor, a microcomputer, a field programmable array, a programmable logic unit, an application-specific integrated circuit (ASIC), a microprocessor, a microcontroller, etc., and combinations thereof, including any other device capable of responding to and executing instructions in a defined manner.
- the one or more processors 150 can be a single processor or a plurality of processors that are operatively connected, for example in parallel.
- the memory 160 can include one or more non-transitory computer-readable storage mediums, such as such as a Read Only Memory (ROM), Programmable Read Only Memory (PROM), Erasable Programmable Read Only Memory (EPROM), and flash memory, a USB drive, a volatile memory device such as a Random Access Memory (RAM), a hard disk, floppy disks, a blue-ray disk, or optical media such as CD ROM discs and DVDs, and combinations thereof.
- ROM Read Only Memory
- PROM Programmable Read Only Memory
- EPROM Erasable Programmable Read Only Memory
- flash memory a USB drive
- RAM Random Access Memory
- examples of the memory 160 are not limited to the above description, and the memory 160 may be realized by other various devices and structures as would be understood by those skilled in the art.
- memory 160 can store instructions, that when executed, cause the one or more processors 150 to determine a location at which a force is applied to the display 182 based on one or more received optical readings output by PPG sensors 172, as described according to examples of the disclosure.
- memory 160 can store instructions, that when executed, cause the one or more processors 150 to execute one or more functions of the wearable computing device 100 based on the determined location, as described according to examples of the disclosure.
- Memory 160 can also include data 162 and instructions 164 that can be retrieved, manipulated, created, or stored by the one or more processor(s) 150. In some example embodiments, such data can be accessed and used as input to determine a location at which a force is applied to the display 182 based on one or more optical readings (signals) output by the PPG sensors 172. In some examples, the memory 160 can include data used to perform one or more processes and instructions that execute one or more functions of the wearable computing device 100 based on the location at which the force is applied to the display 182 as determined by the one or more processors.
- the wearable computing device 100 can include a user interface 180 configured to receive an input from a user by the user applying a force to the user interface (e.g., via a thumb, finger, or an input device such as a stylus or pen).
- the wearable computing device 100 may execute a function in response to receiving the input from the user (e.g., checking health information about the user such as a blood pressure, making and/or receiving a phone call, sending and/or receiving a text message, obtaining a current time, setting a timer, a stopwatch function, controlling an external device such as a home appliance, and the like).
- the wearable computing device 100 may be connected to one or more external devices 190 in a wireless and/or wired manner.
- the wearable computing device 100 may be connected to the external device 190 over a network 300 such as a local area network (LAN), wireless local area network (WLAN), wide area network (WAN), personal area network (PAN), virtual private network (VPN), or the like.
- a network 300 such as a local area network (LAN), wireless local area network (WLAN), wide area network (WAN), personal area network (PAN), virtual private network (VPN), or the like.
- wireless communication between the wearable computing device 100 and the external device 190 may be performed via a wireless LAN, Wi-Fi, Bluetooth, ZigBee, Wi-Fi direct (WFD), ultra wideband (UWB), infrared data association (IrDA), Bluetooth low energy (BLE), near field communication (NFC), a radio frequency (RF) signal, and the like.
- the wired communication connection may be performed via a USB cable, a pair cable, a coaxial cable, an optical fiber cable, an Ethernet cable, and the like.
- the user interface 180 may include a display 182 which displays information viewable by the user (e.g., time, date, biometric information, notifications, etc.).
- the display 182 may be anon-touch sensitive display.
- the display 182 may include a liquid crystal display (LCD), a light emitting diode (LED) display, an organic light emitting diode (OLED) display, active matrix organic light emitting diode (AMOLED), flexible display, 3D display, a plasma display panel (PDP), a cathode ray tube (CRT) display, and the like, for example.
- LCD liquid crystal display
- LED light emitting diode
- OLED organic light emitting diode
- AMOLED active matrix organic light emitting diode
- flexible display 3D display
- PDP plasma display panel
- CRT cathode ray tube
- the non-touch sensitive display 182 may not be capable of sensing a touch event via conduction using electrical conductors (e.g., like a capacitive touch display or resistive display) to change a capacitance or resistance of a circuit.
- the nontouch sensitive display 182 does not include a touch panel which may include conductive layers and/or resistive layers of circuitry.
- the display 182 may include various layers, including one or more of a display surface, polarizing layers, liquid crystal layer, backlight, glass substrate, and the like.
- the display 182 may have a square or rectangular shape, or may be annular in shape (e.g., elliptical, circular, etc.). However, it should be appreciated that the display 182 can have any suitable shape.
- the display 182 displays various functions Fl, F2, F3, F4 in respective quadrants of the display 182 that the wearable computing device 100 is capable of performing.
- the functions may be displayed using visual elements such as text and/or by using symbols (e.g., icons) which inform the user of the respective function to be performed.
- PPG detectors 172a, 172b, 172c may output respective optical readings (signals) SI, S2, S3 (see FIGS. 4C and 5A-5B) in response to the applied force.
- a first PPG detector 172a which is located closest to the location at which the force is applied to the display 182 may output a signal SI with a higher amplitude or higher value compared to the outputs S2 and S3 of second and third PPG detectors 172b, 172c which are located further away from the location at which the force is applied to the display 182.
- One or more processors 150 may receive one or more optical readings (signals) from each of the PPG detectors 172a, 172b, 172c and determine a location at which the force is applied to the display 182 based on the one or more optical readings (signals) output by the PPG detectors 172a, 172b, 172c.
- the one or more processors 150 may execute the function F4 which is displayed in the lower right quadrant of the display 182.
- the user interface 180 may additionally, or alternatively, include one or more buttons 184 to receive an input from a user by the user applying a force to the one or more buttons 184.
- one or more buttons 184c may be included on one or more peripheral sides of the wearable computing device 100 as shown in FIG. 1, for example.
- the one or more buttons 184c may be a known button which includes mechanical components and/or electrical circuitry to implement a function of the wearable computing device 100 (e.g., setting a time, changing a setting and/or view of the display 182, selecting an option displayed on the display 182).
- the one or more buttons 184 may also include one or more faux buttons 184a, 184b. For example, in FIG.
- faux buttons 184a, 184b are disposed on an upper side 110a of the housing 110 adjacent to the display 182.
- the faux buttons 184a, 184b may represent or indicate functions F3, F4 of the wearable computing device 100 that can be performed by the wearable computing device 100.
- the faux button 184a may include a label, symbol, or other indication to inform the user of the function F3 to be performed
- the faux button 184b may include a label, symbol, or other indication to inform the user of the function F4 to be performed.
- the wearable computing device 100 may not include the display 182 and the upper side of the housing 110 may include one or more faux buttons 184a, 184b to receive a user input.
- the faux buttons 184a, 184b may not be mechanically and/or electrically connected (e.g., via a switch or capacitive sensors) to other components of the wearable computing device 100 to implement a function of the wearable computing device 100.
- PPG detectors 172a, 172b, 172c may output respective optical readings (signals) SI, S2, S3 (see FIGS. 4C and 5A-5B) in response to the applied force.
- a first PPG detector 172a which is located closest to the location at which the force is applied to the faux button 184b may output a signal SI with a higher amplitude or higher value compared to the outputs S2 and S3 of second and third PPG detectors 172b, 172c which are located further away from the location at which the force is applied to the faux button 184b.
- One or more processors 150 may receive one or more optical readings (signals) from each of the PPG detectors 172a, 172b, 172c and determine a location at which the force is applied to the upper side of the housing 110 based on the one or more optical readings (signals) output by the PPG detectors 172a, 172b, 172c. In response to the one or more processors 150 determining that the force is applied to a location corresponding to the faux button 184b based on the received one or more optical readings (signals), the one or more processors 150 may execute the function F4 which is represented by faux button 184b.
- the wearable computing device 100 may include a plurality of PPG sensors, for example to assist in rejecting motion artifacts.
- Each PPG sensor may correspond to a combination of a light source and a respective detector.
- FIG. 4C there are three PPG sensors: the combination of LED 172d with detector 172a, the combination of LED 172d with detector 172b, and the combination of LED 172d with detector 172c.
- the disclosure is not limited to the example of FIG. 4C and the wearable computing device 100 may include two PPG sensors or more than three PPG sensors.
- more than one LED may be included such that different detectors may be combined with different LEDs and/or each detector may be combined with one or more LEDs to output a PPG signal.
- the plurality of detectors may be disposed in a circular or elliptical arrangement, where the plurality of detectors may be spaced apart from each other at regular or irregular intervals.
- detector 172a is spaced apart from detector 172c in the horizontal or “X” direction, and is spaced apart from detector 172b in both the horizontal (X) direction and the vertical or “Y” direction.
- Detector 172b is spaced apart from both detectors 172a and 172c in the horizontal (X) direction and vertical (Y) direction.
- Detector 172c is spaced apart from detector 172a in the horizontal (X) direction, and is spaced apart from detector 172b in both the horizontal (X) direction and the vertical (Y) direction.
- LED 172d is spaced apart from detector 172b in the vertical (Y) direction and is spaced apart from both detectors 172a and 172c in each of the horizontal (X) and vertical (Y) directions.
- the configuration of the detectors and LED may be different from that illustrated in FIG. 4C, and the disclosure is not limited to the example of FIG. 4C.
- the PPG sensors may optically measure biometric information such as a heart rate, using a light source and a photodetector at the surface of a user’s body part to measure the volumetric variations of blood circulation.
- the light source e.g., one or more LEDs
- the light source emits light to a body part and the photodetector measures the reflected light from the body part, where the amount of reflected light may indicate biometric information about the user (e.g., blood flow, volume of blood, etc.).
- the light source may emit infrared light, and the color of the LED may be red, green, or yellow.
- the PPG signal may include various components, such as a DC component (or DC offset), which represents the constant absorption of light passing through the tissues, and an AC component generated by heartbeats (cardiac activity) affecting blood volume, which depends on the systolic and diastolic phases.
- DC component or DC offset
- AC component generated by heartbeats cardiac activity
- PPG signals output by the PPG sensors may also be affected when a force (e.g., a direct or indirect force) is applied to a body part of the user where the PPG sensors are located.
- the changes in the PPG signals due to this force may be used to detect an event (e.g., a touch event on the display 182 when a force is applied to the display 182 of the wearable computing device 100).
- optical readings (signals) from the PPG sensors 172 disposed on a lower surface of the wearable computing device 100 fluctuate based on where the user is applying the force. For example, a detector of the PPG sensor which is closest to the location of the force application will sense more of the optical back-reflections compared to another detector which is located further away from the location of the force application.
- the one or more processors may be configured to determine or estimate (e.g., using a sparse- pixel maximum likelihood decoder) the location at which the force is applied to the display (e.g., an X, Y position on the user interface 180 including the display 182 and/or faux buttons 184a, 184b).
- (x, y) represents the coordinate of the particular detector (e.g., photodiode) reading the PPG fluctuations.
- the term (x_press, y_press) represents the ground truth coordinates of the location at which a force is applied to the upper part of the wearable computing device.
- the scale parameter k describes the “diffuseness” of the Gaussian response, which is explained in more detail with reference to FIGS. 6A-10B.
- a scale parameter k may be determined based on whether an area of the display to which the force is applied corresponds to a first area or a second area, where the first area is larger than the second area. For example, if a user applies their thumb to the display, then the area of the display to which the force is applied is larger than if the user were to apply their index finger to the display. As another example, if a user has large fingers (e.g., relative to an average human finger size for a male and/or female), it can be considered that the area of the display to which the force is applied would be larger than a user having average size fingers.
- a user may provide an input to the wearable computing device indicating the size or area of the display which is to receive the force applied from the user.
- the input may indicate the area size (e.g., a first area or a second area), which can be used to determine a scale parameter (e.g., a first scale parameter kl or a second scale parameter k2).
- the scale parameter may indicate or describe a diffuseness of the Gaussian response which can be used to analyze the optical signals output from the PPG sensors 172 for determining a location of the force applied to the display 182.
- FIGS. 6A and 6B depict example press Gaussian responses corresponding to different scale parameters, according to one or more example embodiments of the disclosure
- a higher- variance response 610 would be experienced, and a higher scale parameter kl may be appropriate (e.g., a value of 10).
- a lower-variance response 620 would be experienced, and a lower scale parameter value k2 may be appropriate (e.g., a value of 1).
- the one or more processors 150 may be configured to determine an amplitude of each of the one or more optical readings output by the PPG sensors 172 based on a first model having a first scale parameter kl (e.g., having a value of 10) which reflects or describes a first variance of the force applied to the display 182.
- a first scale parameter kl e.g., having a value of 10.
- the one or more processors 150 may be configured to determine the amplitude of each of the one or more optical readings output by the PPG sensors 172 based on a second model having a second scale parameter k2 (e.g., having a value of 1) which reflects a second variance of the force applied to the display 182.
- the first variance is greater than the second variance.
- the one or more processors 150 may be configured to determine the location of the force applied to the display 182 based on a first scale parameter kl when the force applied to the display 182 corresponds to a first area of the display 182 (e.g., corresponding to the size or surface area of a user’s thumb), and the one or more processors 150 may be configured to determine the location of the force applied to the display 182 based on a second scale parameter k2 when the force applied to the display 182 corresponds to a second area of the display 182 (e.g., corresponding to the size or surface area of a user’s index finger).
- a first scale parameter kl when the force applied to the display 182 corresponds to a first area of the display 182 (e.g., corresponding to the size or surface area of a user’s thumb)
- the one or more processors 150 may be configured to determine the location of the force applied to the display 182 based on a second scale parameter k2 when the force applied to the display 182
- the first scale parameter kl is greater than the second scale parameter k2, and the first area is greater than the second area.
- the first area and second area may correspond to known or empirically obtained values for average fingertip areas of a thumb or index finger, and may additionally be categorized according to a gender of the user.
- a first area may correspond to about 5 cm 2 to 6 cm 2 (an approximate surface area of the tip of a thumb) and a second area may correspond to about 2.5 cm 2 to 3.5 cm 2 (an approximate surface area of the tip of an index finger).
- a user may provide an input to the wearable computing device 100 indicating the size or area of the display 182 which is to receive a force applied from the user.
- the wearable computing device 100 may display information on the display 182 which requests that the user indicate a preferred digit (e.g., a thumb or index finger) to be used for providing an input (force) to the display 182.
- the user may select the preferred digit using a button 184c disposed on an outer peripheral portion of the wearable computing device 100 similar to a manner in which a user may set a time or date as in known watches.
- the user may additionally and/or alternatively input their gender for further determination of the scale parameter k for selecting an appropriate model to be utilized.
- the one or more processors 150 of the wearable computing device 100 may receive a number of observations from the PPG sensors 172 at a given point in time which corresponds to the number of sensors. For example, if the wearable computing device has N PPG sensors 172 (in particular N detectors 172a-c), then the one or more processors 150 of the wearable computing device 100 may receive N observations from the detectors 172a-172c.
- the wearable computing device 100 has three detectors 172a- 172c.
- the one or more processors 150 of the wearable computing device 100 may receive three observations (i.e., one observation from each of the detectors 172a-172c) at a given point in time.
- FIGS. 7A and 7B depict example observation values according to one or more example embodiments of the disclosure.
- outputs of the detectors 172a-172c are overlaid on top of a press Gaussian function 710, where darker shading indicates the center of the Gaussian function corresponding to the actual touch location, detector 172c outputs a value of 0.98 while detectors 172a and 172b output values of 0.92 and 0.94 respectively.
- the one or more processors 150 may determine or estimate that the location of the force applied to the display 182 is in a middle right portion of the display 182 based on the values of each of the detectors 172a-172c. For example, in FIG. 7B, detector 172c outputs a value of 0.91 while detectors 172a and 172b output values of 0.83 and 0.89 respectively.
- the one or more processors 150 may determine or estimate that the location of the force applied to the display 182 is in an upper right portion of the display 182, based on the values of each of the detectors 172a-172c, noting that detectors 172b and 172c have relatively similar values compared to the value output by detector 172a.
- the one or more processors 150 may be configured to determine the location at which the force is applied to the display 182 based on optical reading values of a PPG sensor 172 among the PPG sensors 172 having a highest value, e.g., a highest voltage value.
- the one or more processors 150 may be configured to determine the location at which the force is applied to the display 182 based on a highest amplitude among the amplitudes of the one or more optical reading values output from the PPG sensors 172.
- the one or more processors 150 may be configured to determine the location at which the force is applied to the display 182 based on a loss function that is optimized to find a ground truth coordinate location of where the force is applied to the display 182.
- the probabilistic channel given that an observation (for example, obs l) could be corrupted by Gaussian measurement noise may be written as: p(obs_l
- (x_press, y_press)) G[ EXP ⁇ -[ (x_l, y_l) - (x_press, y_press) ] A 2 / scale k ⁇ - obs_l ].
- the G(.) function describes the probability density of a standard Gaussian function which may be used to reconstruct the location of the application of the force using measurements obtained from the detectors, which are sparsely provided and distributed. For example, a probability of receiving the values observed for each of the observations N is calculated based on candidate touch events (i.e. , candidate locations where the force is estimated to be applied). Whatever candidate touch event maximizes the probability (or minimizes the loss) may be considered as the most likely location of the force (i.e., touch event). For example, an expression of the negative log likelihood of all the observations may be used to find the ground truth press coordinates, as follows:
- x_I, y_l”, “x_2, y_2”, and “x_N, y_N” correspond to the location of each PPG detector, which is known.
- the terms “obs 1”, “obs_2”, and “obs_N” correspond to the observed values of the respective detectors.
- scale k is the scale parameter value which describes the diffuseness of the Gaussian response as described herein.
- x_press, y_press corresponds to the value that is to be estimated (i.e., the X, Y coordinate value of the location of the force). For example, in a three channel PPG sensor, where there are three detectors, N may be equal to three.
- the example loss function is variable up to two parameters of interest (x_press, y_press), which at the time of observation are unknowns
- a two-dimensional grid search may be performed to estimate (x_press, y_press) by finding the global loss minimizes
- the one or more processors 150 may be configured to execute a program to perform a direct search in which every X, Y coordinate pair (e.g., corresponding to the area of the display) is tested as candidate touch events to obtain a result which achieves the minimal loss.
- the candidate touch event achieving the lowest loss (i.e., a minimal error) between may correspond to the estimated touch location.
- the one or more processors 150 may implement a known gradient descent method to obtain a result (X, Y coordinate) which achieves the minimal loss.
- the gradient descent search method may utilize random candidate touch events (i.e., random candidate X, Y coordinates) to obtain a result which obtains the minimal loss rather than a direct search report in which all of the candidate touch events are tested.
- the gradient descent search method may use a smaller search space and thus be less computationally expensive than the direct search approach, saving energy and time.
- the disclosure is not limited to a direct search method or gradient descent search method, and other methods for minimizing a loss function may also be implemented.
- FIGS. 8 A and 8B illustrate an example estimate of the location of a force applied to the display based on a loss function result, according to one or more example embodiments of the disclosure.
- an estimated location of a force applied to the display 182 (upper right comer) is denoted by reference numeral 810.
- the location of the force has been calculated or determined by the one or more processors 150 using values output by detectors configured as in the example of FIG. 4C.
- the ground truth (actual) location of the force is denoted by reference numeral 820.
- the Gaussian press response 830 is also shown in the background to provide additional context. For example, FIG.
- FIGS. 9A and 9B illustrate another example estimate of the location of a force applied to the display based on a loss function result, according to one or more example embodiments of the disclosure.
- an estimated or determined location of a force applied to the display 182 (lower right comer) is denoted by reference numeral 910.
- the location of the force has been calculated or determined by the one or more processors 150 using values output by detectors configured as in the example of FIG. 4C.
- the ground truth (actual) location of the force is denoted by reference numeral 920.
- the Gaussian press response 930 is also shown in the background to provide additional context.
- FIG. 9B illustrates a corresponding loss function result 940 where an outer band 950 denotes the most likely location of a minimizing result, in which the estimated location 910 also corresponds.
- noise may affect the output of the PPG sensors 172.
- a noise level experienced by the PPG sensors 172 may increase when the wearable computing device 100 is not securely held to a body part of the user.
- a noise level experienced by the PPG sensors 172 may increase due to a low battery condition where the amount of light output by the light source (e.g., LED 172d) is decreased (e.g., a low power mode).
- the optical readings may be affected by the noise, and the accuracy of the PPG sensors 172 may be reduced.
- FIGS. 10A and 10B illustrate an example estimate of the location of a force applied to the display based on a loss function result in a noisy environment, according to one or more example embodiments of the disclosure.
- an estimated location of a force applied to the display 182 (lower right comer) is denoted by reference numeral 1010, and is located further away from the ground truth value 1020 compared to the example of FIG. 9A.
- the location of the force has been calculated or determined by the one or more processors 150 using values output by detectors configured as in the example of FIG. 4C.
- the Gaussian press response 1030 is also shown in the background to provide additional context.
- FIG. 10B illustrates a corresponding loss function result 1040 where an outer band 1050 denotes the most likely location of a minimizing result, in which the estimated location 1010 also corresponds.
- the one or more processors 150 may be configured to control the display 182 so that a number of the plurality of selectable functions displayed on the display 182 may be reduced.
- functions F1-F4 displayed on the display 182 in FIG. 4A may be reduced to display only functions Fl (on the upper half of the display 182) and F2 (on the lower half of the display 182).
- a number of the plurality of selectable functions displayed on the display 182 may be reduced when the noise level of the sensors exceeds a threshold (e.g., reducing icons displayed on the display 182 from ten icons to four icons).
- Stopping the displaying of one or more of the plurality of selectable functions may enlarge a space on the display 182 for each of the remaining selectable functions to be displayed.
- a likelihood that the one or more processors 150 may accurately execute a function that the user intends to select may be increased, even though an accuracy of the detection or determination of the location of the force applied to the display 182 may be reduced due to the noise encountered or experienced by the PPG sensors 172.
- the noisy condition encountered by the PPG sensors 172 may be masked and go unnoticed by the user, thereby improving the user experience.
- the wearable computing device 100 may include an accelerometer 174 and/or a gyroscope 176 to detect or sense motion data of the wearable computing device 100.
- the wearable computing device 100 may include PPG sensors 172 which are configured to monitor a heart rate of the user when the user wears the wearable computing device 100.
- Motion of a user’s hand affects arterial pressure and volumetric structure (muscle/tendon), creating a signature dip in reflection/absorption reflected in the PPG signal.
- the PPG sensors 172 may capture the arterial pressure profiles spatially over a two- dimensional area (e.g., in x and y directions) on the lower side 110b of the housing 110 of the wearable computing device 100.
- the one or more processors 150 may be configured to identify a gesture of the user based on the one or more optical readings output by the PPG sensors 172, and the one or more processors 150 may be configured to execute a function of the computer wearable device 100 (or another device) based on the gesture of the user identified by the one or more processors 150.
- the one or more processors 150 may be configured to identify the gesture of the user based on the one or more optical readings output by the PPG sensors 172 together with one or more outputs of the accelerometer 174 and/or the gyroscope 176.
- the outputs of the accelerometer 174 and/or the gyroscope 176 may additionally or alternatively be used to confirm the validity of the outputs of the PPG sensors 172 that a gesture is being performed by the user.
- the gesture of the user may include hand gestures including clinching of a fist, a pinching gesture with the fingers, squeezing of a hand, and the like.
- the gestures may be mapped to respective functions of the wearable computing device (e.g., to make a phone call), or a function of another device (e.g., to operate a home appliance) which may be controllable via the wearable computing device 100 by the identification of the gesture.
- the one or more processors 150 may identify a gesture based on the one or more optical readings output by the PPG sensors 172. For example, each gesture may correspond to a respective optical signal output by the PPG sensors 172 so that a gesture may be correctly identified.
- optical signals output by the PPG sensors 172 may be analyzed to identify the gesture (e.g., via machine learning algorithms to classify the output optical readings, by comparing the optical signals with known optical signals corresponding to respective gestures, etc.).
- portions of the optical readings which are attributed to a heart rate of the user may be filtered out. For example, a high pass heart rate filtering operation may be performed with respect to the optical readings to notch out the heart rate (arterial pulse), so that the majority of the optical readings which are used to identify the gesture corresponds to or is attributed to, the movement of the user’s hand.
- FIG. 11 illustrates example response signals of various sensors of the wearable computing device to detect a gesture of a user, according to one or more example embodiments of the disclosure.
- a user makes a pinch gesture at times corresponding to reference characters 1110a, 1110b, and 1110c
- a distinctive or significant change in the output signals of the accelerometer 174, gyroscope 176, and PPG sensors 172 occurs.
- the PPG signals shown in FIG. 11 are obtained after high-pass heart rate filtering which results in a distinctive wavelet-like pattern in the PPG signal.
- motion information / data is collected via the accelerometer along three axes (Y-axis 1120a, X-axis 1120b, and Z-axis 1120c).
- motion information / data is collected via the gyroscope along three axes (Y-axis 1130a, X-axis 1130b, and Z-axis 1130c).
- the PPG optical readings includes information / data collected from six channels: PPG channel 1 data 1140a, PPG channel 2 data 1140b, PPG channel 3 data 1140c, channel 4 data 1140d, PPG channel 5 data 1140e, and PPG channel 6 data 1140f.
- the signals output by the accelerometer 174 and/or gyroscope 176 may be analyzed in conjunction with the signals output by the PPG sensors 172 to determine the gesture of the user’s hand (e.g., the pinch gesture). However, in some examples only the signals output by the PPG sensors 172 may be used to determine the gesture of the user’s hand. Based on the determination of the gesture, a corresponding function of the wearable computing device 100 and/or of an external device 190 may be performed.
- a plurality of PPG optical readings may be obtained through a multiplexing operation.
- a plurality of LEDs may also be used to obtain a plurality of optical readings from different combinations of the detectors and the LEDs, to thereby obtain spatial backscatter diversity.
- each of the three detectors may receive reflected light and output a respective signal.
- each of the three detectors When a second LED is next turned on, each of the three detectors may receive reflected light and output a respective second signal, and when a third LED is lastly turned on, each of the three detectors may receive reflected light and output a respective third signal.
- a total of nine PPG optical readings may be obtained to provide a spatial perfusion index profile change for accurate classification of hand states.
- the signals output by the accelerometer 174 and/or gyroscope 176 may be analyzed in conjunction with the signals output by the PPG sensors 172 to determine the gesture of the user’s hand. However, in some examples only the signals output by the PPG sensors 172 may be used to determine the gesture of the user’s hand.
- FIGS. 12A and 12B depict example one-handed gestures of a user and corresponding heatmaps reconstructed from output optical readings from the PPG sensors, according to one or more example embodiments of the disclosure.
- a first gesture e.g. by tilting a hand upward
- a second gesture e.g. by tilting a hand downward
- a second heat map 1230 is generated.
- a heat signature corresponding to the portion 1220 in FIG. 12A is very different from a heat signature corresponding to the portion 1240 in FIG. 12B.
- Each gesture may have a unique or identifiable heat map that can be correlated with the output optical readings from the PPG sensors 172, so that the wearable computing device 100 can identify or determine a gesture based on the output optical readings from the PPG sensors 172.
- the determination of the gesture may be performed using the probability density of a standard Gaussian function which may be used to determine the gesture using measurements obtained from the detectors 172a-172c, which are sparsely provided and distributed, similar to the method described above for determining a location of a touch on a user interface 180 of the wearable computing device 100. Based on the determination of the gesture, a corresponding function of the wearable computing device 100 and/or of an external device 190 may be performed.
- FIGS. 13 and 14 each illustrate a flow diagram of an example, non-limiting computer-implemented method according to one or more example embodiments of the disclosure.
- one or more processors 150 may receive optical readings (signals) output by PPG sensors 172 when a force is applied to a user interface 180 (e.g., including a display and/or one or more faux buttons 184a, 184b) disposed on an upper side 110a of the housing 110.
- the PPG sensors 172 are disposed on a lower side 110b of the housing 110 which is disposed opposite to the upper side 110a of the housing 110 (e.g., as shown in FIG. 2 of the drawings).
- the lower side 110b of the housing 110 may be configured to be in contact with a body part of a user when the wearable computing device 100 is worn by the user.
- the method may further include determining, by one or more processors 150 of the wearable computing device 100, a location at which the force is applied to the user interface 180 based on the one or more received optical readings.
- the method may further include the one or more processors 150 executing one or more functions of the wearable computing device 100 based on the determined location at which the force is applied to the user interface 180.
- Example functions of the wearable computing device 100 may include checking health information about the user such as a blood pressure, making and/or receiving a phone call, sending and/or receiving a text message, obtaining a current time, setting a timer, a stopwatch function, controlling an external device 190 such as a home appliance, an electronic device such as a television, and the like.
- a graphical user interface is displayed on the display 182 indicating to a user to calibrate the wearable computing device 100 by indicating an area of the display 182 to which a force is to be applied to the display 182.
- the calibration instructions may ask the user whether the user prefers to use an index finger (second area) to provide inputs or a thumb (first area).
- the calibration instructions may ask the user whether the user is male or female.
- the calibration instructions may ask the user whether the user has hands and/or fingers which are larger than a threshold value which may imply that a first area should be set (larger than the threshold value) or a second area should be set (equal to or less than the threshold value). For example, if a user has a ring size greater than ten, a first area setting may be assumed. For example, if a user has a finger length greater than 7.5 inches (measured from the tip of the longest finger to the crease under the palm), a first area setting may be assumed.
- the user may provide an input (e.g., via one or more buttons 184c located on a periphery of the wearable computing device 100 as shown in FIG. 1), indicating an area of the force as a first area or a second area.
- the method may include operation 1430, which includes determining an amplitude of each of the one or more optical readings based on a first model having a first scale parameter kl which reflects a first variance of the force to be applied to the display 182.
- the method may include operation 1450, which is determining the amplitude of each of the one or more optical readings based on a second model having a second scale parameter k2 which reflects a second variance of the force to be applied to the display 182.
- the first area may be greater than the second area
- the first variance may be greater than the second variance.
- the method may include the one or more processors 150 determining the location at which the force is applied to the display 182 based on a highest amplitude among the amplitudes of the one or more optical readings. The method may also include determining the location at which the force is applied to the display 182 based on an optical reading of a PPG sensor 172 among the PPG sensors 172 having a highest value, among the one or more optical readings received by the one or more processors 150.
- Other operations of the calibration procedure may include asking the user to apply a force to the display 182 at various known (predetermined) points of the display 182, and saving the signals which are output in response to memory 160 as data 162 which may be used as a lookup table for comparing future output signals obtained from PPG sensors 172 and/or for guiding a decision in determining the location of an application of force according to the loss function as described herein.
- non- transitory computer-readable media including program instructions to implement various operations embodied by a computer.
- the media may also include, alone or in combination with the program instructions, data files, data structures, and the like.
- Examples of non- transitory computer-readable media include magnetic media such as hard disks, floppy disks, and magnetic tape; optical media such as CD ROM disks, Blue-Ray disks, and DVDs; magneto-optical media such as optical discs; and other hardware devices that are specially configured to store and perform program instructions, such as semiconductor memory, readonly memory (ROM), random access memory (RAM), flash memory, USB memory, and the like.
- Examples of program instructions include both machine code, such as produced by a compiler, and files containing higher level code that may be executed by the computer using an interpreter.
- the program instructions may be executed by one or more processors.
- the described hardware devices may be configured to act as one or more software modules in order to perform the operations of the above-described embodiments, or vice versa.
- a non-transitory computer-readable storage medium may be distributed among computer systems connected through a network and computer-readable codes or program instructions may be stored and executed in a decentralized manner.
- the non- transitory computer-readable storage media may also be embodied in at least one application specific integrated circuit (ASIC) or Field Programmable Gate Array (FPGA).
- ASIC application specific integrated circuit
- FPGA Field Programmable Gate Array
- Each block of the flowchart illustrations may represent a unit, module, segment, or portion of code, which comprises one or more executable instructions for implementing the specified logical function(s). It should also be noted that in some alternative implementations, the functions noted in the blocks may occur out of order. For example, two blocks shown in succession may in fact be executed substantially concurrently (simultaneously) or the blocks may sometimes be executed in the reverse order, depending upon the functionality involved.
Abstract
A wearable computing device includes a housing having an upper side and a lower side, where the lower side of the housing is opposite to the upper side of the housing and is configured to be in contact with a body part of a user when the wearable computing device is worn by the user. The wearable computing device further includes a user interface disposed on the upper side of the housing. The wearable computing device further includes sensors, disposed on the lower side of the housing, which output one or more optical readings when a force is applied to the user interface. The wearable computing device further includes one or more processors which determine a location at which the force is applied to the user interface based on the one or more optical readings output by the sensors.
Description
WEARABLE COMPUTING DEVICE HAVING OPTICAL SENSORS TO INDIRECTLY
DETERMINE A LOCATION OF A FORCE APPLIED TO A USER INTERFACE
FIELD
[0001] The disclosure relates generally to wearable computing devices. More particularly, the disclosure relates to wearable computing devices which can determine a location of a force applied to a user interface of the wearable computing device using optical sensors.
BACKGROUND
[0002] Wearable computing devices (e.g., wrist watches) can include a display to display content (e.g., time, date, functions of the wearable computing device, etc.) to a user. Some wearable computing devices can gather data regarding activities performed by the user, or regarding the user's physiological state. Such data may include data representative of the ambient environment around the user or the user's interaction with the environment. For example, the data can include motion data regarding the user's movements and/or physiological data obtained by measuring various physiological characteristics of the user, such as heart rate, perspiration levels, and the like. Some wearable computing devices may include a touch-sensitive display, while other wearable computing devices may include a non-touch-sensitive display.
SUMMARY
[0003] Aspects and advantages of embodiments of the disclosure will be set forth in part in the following description, or can be learned from the description, or can be learned through practice of the example embodiments.
[0004] In an example embodiment, a wearable computing device is provided. The wearable computing device includes a housing having an upper side and a lower side, where the lower side of the housing is opposite to the upper side of the housing and is configured to be in contact with a body part of a user when the wearable computing device is worn by the user. The wearable computing device also includes a user interface disposed on the upper side of the housing and sensors which are disposed on the lower side of the housing. The sensors are configured to output one or more optical readings when a force is applied to the user interface. The wearable computing device may further include one or more processors configured to determine a location at which the force is applied to the user interface based on
the one or more optical readings output by the sensors.
[0005] In some implementations, the sensors may include photoplethysmography (PPG) sensors configured to monitor a heart rate of the user when the wearable computing device is worn by the user, and the PPG sensors include one or more light-emitting diodes and a plurality of detectors.
[0006] In some implementations, the sensors may include at least three photoplethysmography (PPG) sensors, and at least one PPG sensor of the at least three PPG sensors is spaced apart from another PPG sensor of the at least three PPG sensors in a first direction and a second direction.
[0007] In some implementations, the one or more processors may be configured to execute one or more functions of the wearable computing device based on the location at which the force is applied to the display as determined by the one or more processors.
[0008] In some implementations, the one or more processors may be configured to determine the location at which the force is applied to the user interface based on whether an area of the user interface to which the force is applied corresponds to a first area or a second area, the first area being different from than the second area. For example, the first area may be larger than the second area.
[0009] In some implementations, when the area of the display to which the force is applied corresponds to the first area, the one or more processors may be configured to determine an amplitude of each of the one or more optical readings based on a first model having a first scale parameter which reflects a first variance of the force applied to the user interface, and when the area of the display to which the force is applied corresponds to the second area, the one or more processors may be configured to determine the amplitude of each of the one or more optical readings based on a second model having a second scale parameter which reflects a second variance of the force applied to the user interface, the second variance being different from the first variance.
[0010] In some implementations, the one or more processors may be configured to determine the location at which the force is applied to the user interface based on a value of each of the optical readings output by the sensors and by applying a loss function to minimize a difference between an actual location at which the force is applied and an estimated location at which the force is applied. In such an implementation, the one or more processors may be configured to determine the location at which the force is applied to the user interface using a value of each of the one or more optical readings output by the sensors and known (i.e., predefined and stored) positions of the sensors to estimate the location at which the
force is applied by applying a loss function. An estimated location resulting from minimizing the loss function may then be used as the determined location at which the force is applied. In particular, determining the location at which the force is applied may therefore include using an estimate of the location resulting from applying a loss function, where the loss function includes values of each of the one or more optical readings and known positions of the sensors at the lower side of the wearable computing device’s housing. The loss function may further include a probability density function determining a probability of an optical reading output by an optical sensor being corrupted by measurement noise. In some implementations the probability density function may be a standard Gaussian function which is used for reconstructing a location of the application of a force based on measurements from the one or more sensors.
[0011] In some implementations, the one or more processors may be configured to apply the loss function by performing a two-dimensional grid search method or a gradient descent search method.
[0012] In some implementations, the user interface includes a non-touch sensitive display configured to display a plurality of elements corresponding to a plurality of selectable functions of the wearable computing device. In response to a noise level of the sensors increasing beyond a threshold, the one or more processors may be configured to control the display to stop the display of one or more of the plurality of elements, and in response to determining the location at which the force is applied to the display corresponds to a remaining first element of the plurality of elements displayed on the display, the one or more processors may be further configured to execute a first selectable function of the plurality of selectable functions which corresponds to the remaining first element, based on the determined location.
[0013] In some implementations, the user interface includes a plurality of faux buttons which respectively correspond to a plurality of selectable functions of the wearable computing device, and in response to determining the location at which the force is applied to a first faux button of the plurality of faux buttons of the user interface, the one or more processors are configured to execute a first selectable function of the plurality of selectable functions which corresponds to the first faux button, based on the determined location.
[0014] In some implementations, the user interface includes a display, and the display is anon-touch sensitive display.
[0015] In some implementations, the sensors may include photoplethysmography (PPG) sensors configured to monitor a heart rate of the user when the wearable computing device is
worn by the user, and the one or more processors may be configured to identify a gesture of the user based on the one or more optical readings output by the PPG sensors. The one or more processors may be configured to execute a function of the computer wearable device based on the gesture of the user identified by the one or more processors.
[0016] In some implementations, the wearable computing device may further include at least one of an accelerometer or a gyroscope, and the one or more processors may be configured to identify the gesture of the user based on the one or more optical readings output by the PPG sensors and one or more outputs of the at least one of the accelerometer or the gyroscope.
[0017] In an example embodiment, a computer-implemented method is provided. The computer-implemented method includes receiving (e.g., by one or more processors of a wearable computing device) optical readings output by sensors disposed on a lower side of a housing of the wearable computing device, when a force is applied to a user interface disposed on an upper side of the housing. The lower side of the housing is opposite to the upper side of the housing and is configured to be in contact with a body part of a user when the wearable computing device is worn by the user. The method may further include determining, by the one or more processors of the wearable computing device, a location at which the force is applied to the user interface based on the one or more received optical readings.
[0018] In some implementations, the method may further include executing one or more functions of the wearable computing device based on the location at which the force is applied to the user interface as determined by the one or more processors.
[0019] In some implementations, the method may further include displaying on a display of the user interface instructions indicating to a user to calibrate the wearable computing device by indicating an area of the display to which the force is to be applied to the display. [0020] In some implementations, the method may further include, when the area of the force indicated by the user corresponds to a first area, determining an amplitude of each of the one or more optical readings based on a first model having a first scale parameter which reflects a first variance of the force to be applied to the display, and when the area of the force indicated by the user corresponds to a second area, determining the amplitude of each of the one or more optical readings based on a second model having a second scale parameter which reflects a second variance of the force to be applied to the display, the first area being greater than the second area, and the first variance being greater than the second variance.
[0021] In some implementations, the method may further include determining the
location at which the force is applied to the user interface based on a value of each of the optical readings output by the sensors and by applying a loss function to minimize a difference between an actual location at which the force is applied and an estimated location at which the force is applied.
[0022] In some implementations, the method may further include displaying, on a nontouch sensitive display of the user interface, a plurality of elements corresponding to a plurality of selectable functions of the wearable computing device, and in response to a noise level of the sensors increasing beyond a threshold, controlling the display to stop the display of one or more of the plurality of elements, and in response to determining the location at which the force is applied to the user interface corresponds to a remaining first element of the plurality of elements displayed on the display, executing a first selectable function of the plurality of selectable functions which corresponds to the remaining first element, based on the determined location.
[0023] In an example embodiment, a non-transitory computer-readable medium which stores instructions that are executable by one or more processors of a wearable computing device is provided. The non-transitory computer-readable medium stores instructions including instructions to cause the one or more processors to receive one or more optical readings output by sensors disposed on a lower side of a housing of the wearable computing device, when a force is applied to a user interface disposed on an upper side of the housing, wherein the lower side of the housing is opposite to the upper side of the housing and configured to be in contact with a body part of a user when the wearable computing device is worn by the user. The non-transitory computer-readable medium stores instructions including instructions to cause the one or more processors to determine a location at which the force is applied to the user interface based on the one or more received optical readings. The non-transitory computer-readable medium stores instructions including instructions to execute one or more functions of the wearable computing device based on the location at which the force is applied to the user interface as determined by the one or more processors. The non-transitory computer-readable medium may store additional instructions to execute other aspects of the wearable computing device and computer-implemented method as described herein.
[0024] These and other features, aspects, and advantages of various embodiments of the disclosure will become better understood with reference to the following description, drawings, and appended claims. The accompanying drawings, which are incorporated in and constitute a part of this specification, illustrate example embodiments of the disclosure and,
together with the description, serve to explain the related principles.
BRIEF DESCRIPTION OF THE DRAWINGS
[0025] Detailed discussion of example embodiments directed to one of ordinary skill in the art is set forth in the specification, which makes reference to the appended drawings, in which:
[0026] FIG. 1 depicts an example wearable computing device according to according to one or more example embodiments of the disclosure;
[0027] FIG. 2 depicts an exploded view of an example wearable computing device according to one or more example embodiments of the disclosure;
[0028] FIG. 3 depicts an example block diagram of the wearable computing device according to one or more example embodiments of the disclosure;
[0029] FIGS. 4A and 4B depict top views of example wearable computing devices according to one or more example embodiments of the disclosure;
[0030] FIG. 4C depicts a bottom view of an example wearable computing device according to one or more example embodiments of the disclosure;
[0031] FIGS. 5A and 5B depict a force applied to a display of the wearable computing device and a corresponding signal response diagram of sensors, according to one or more example embodiments of the disclosure;
[0032] FIGS. 6A and 6B depict example press Gaussian responses corresponding to different scale parameters, according to one or more example embodiments of the disclosure; [0033] FIGS. 7A and 7B depict example observation values according to one or more example embodiments of the disclosure;
[0034] FIGS. 8A and 8B depict an example determination of the location of a force applied to the display based on a loss function result, according to one or more example embodiments of the disclosure;
[0035] FIGS. 9A and 9B depict another example determination of the location of a force applied to the display based on a loss function result, according to one or more example embodiments of the disclosure;
[0036] FIGS. 10A and 10B depict an example determination of the location of a force applied to the display based on a loss function result in a noisy environment, according to one or more example embodiments of the disclosure;
[0037] FIG. 11 depicts example response signals of various sensors of the wearable computing device to detect a gesture of a user, according to one or more example embodiments of the disclosure;
[0038] FIGS. 12A and 12B depict example one-handed gestures of a user and corresponding heatmaps reconstructed from PPG sensors, according to one or more example embodiments of the disclosure; and
[0039] FIGS. 13 and 14 each illustrate a flow diagram of an example, non-limiting computer-implemented method according to one or more example embodiments of the disclosure.
DETAILED DESCRIPTION
[0040] Reference now will be made to embodiments of the disclosure, one or more examples of which are illustrated in the drawings. Each example is provided by way of explanation of the disclosure and is not intended to limit the disclosure. In fact, it will be apparent to those skilled in the art that various modifications and variations can be made to disclosure without departing from the scope or spirit of the disclosure. For instance, features illustrated or described as part of one embodiment can be used with another embodiment to yield a still further embodiment. Thus, it is intended that the disclosure covers such modifications and variations as come within the scope of the appended claims and their equivalents.
[0041] Terms used herein are used to describe the example embodiments and are not intended to limit and / or restrict the disclosure. The singular forms “a,” “an” and “the” are intended to include the plural forms as well, unless the context clearly indicates otherwise. In this disclosure, terms such as "including", "having", “comprising”, and the like are used to specify features, numbers, steps, operations, elements, components, or combinations thereof, but do not preclude the presence or addition of one or more of the features, elements, steps, operations, elements, components, or combinations thereof.
[0042] It will be understood that, although the terms first, second, third, etc., may be used herein to describe various elements, the elements are not limited by these terms.
Instead, these terms are used to distinguish one element from another element. For example, without departing from the scope of the disclosure, a first element may be termed as a second element, and a second element may be termed as a first element.
[0043] The term "and / or" includes a combination of a plurality of related listed items or any item of the plurality of related listed items. For example, the scope of the expression or
phrase "A and/or B" includes the item "A", the item "B", and the combination of items "A and B”.
[0044] In addition, the scope of the expression or phrase "at least one of A or B" is intended to include all of the following: (1) at least one of A, (2) at least one of B, and (3) at least one of A and at least one of B. Likewise, the scope of the expression or phrase "at least one of A, B, or C" is intended to include all of the following: (1) at least one of A, (2) at least one of B, (3) at least one of C, (4) at least one of A and at least one of B, (5) at least one of A and at least one of C, (6) at least one of B and at least one of C, and (7) at least one of A, at least one of B, and at least one of C.
[0045] Examples of the disclosure are directed to a wearable computing device that can be worn, for example, on a user’s wrist. For example, the wearable computing device may include a watch. The wearable computing device includes a housing having an upper side and a lower side. The lower side of the housing is opposite to the upper side of the housing and is configured to be in contact with a body part of a user when the wearable computing device is worn by the user. The wearable computing device further includes a user interface disposed on the upper side of the housing and sensors disposed on the lower side of the housing. The sensors may be configured to output one or more optical readings when a force is applied to the user interface. The wearable computing device may further include one or more processors configured to determine a location at which the force is applied to the user interface based on the one or more optical readings output by the sensors and a loss function described herein. The user interface is a tangible medium by which a user interacts with the wearable computing device. In an example, a user interface which is disposed on the upper side of the housing may include, for example, a display (which may be non-touch sensitive), one or more faux buttons, or the combination of the display and one or more faux buttons. [0046] In an example embodiment, the wearable computing device can include a housing with a display (which may be non-touch sensitive) on an upper side of the housing and sensors on a lower side of the housing. The lower side of the housing is opposite to the upper side of the housing and is configured to be in contact with a body part of a user when the wearable computing device is worn by the user. The sensors may be used to indirectly sense a location of a touch by a user on the display. For example, when a user presses the display, optical readings from the sensors may fluctuate based on where the user presses. Optical readings from a sensor which is located closer to the location where the user presses sense more of the optical back-reflections compared to another sensor which is located further away from the location where the user presses. For example, based on the optical
readings obtained from the sensors, one or more processors can determine a location where the user touches on the display and a function of the wearable computing device corresponding to the determined location can be carried out. Determining the location may involve an estimate of location parameters, e.g., location coordinates, based on a loss function implemented with the optical readings.
[0047] As an example, the display may display on a graphical user interface of the display four different visual elements, each visual element corresponding to a separate function of the wearable computing device, in respective quadrants of the display. If a user applies a force to an upper left quadrant of the display, for example to “select” the function represented by the visual element displayed in that quadrant, the sensors may output respective optical readings in response to the applied force. For example, a first sensor which is located closest to a location at which the force is applied to the display may output a signal with a higher amplitude or higher value compared to a second sensor which is located further away from the location at which the force is applied to the display. The one or more processors may receive one or more optical readings from each of the sensors and determine a location at which the force is applied to the display based on the one or more optical readings output by the sensors. If the one or more processors determine that the force is applied to a location corresponding to the upper left quadrant of the display based on the received one or more optical readings, the one or more processors may execute the function corresponding to the visual element displayed in the upper left quadrant of the display.
[0048] The sensors can include, for example, multipath photoplethysmography (PPG) sensors which can also be used to monitor a heart rate of the user. The PPG sensors may include one or more emitters (e.g., light-emitting diodes (LEDs)) and a plurality of detectors (e.g., two or more photodiodes). The detectors may be spaced apart from one another at various locations on the lower side of the housing so as to increase the accuracy of estimating the location of the touch by the user on the display.
[0049] In an example, the sensors may include at least three PPG sensors, and at least one PPG sensor of the at least three PPG sensors is spaced apart from another PPG sensor of the at least three PPG sensors in a first direction (e.g., X-axis) and a second direction (e.g., Y- axis). That is, the at least three PPG sensors are not arranged in a linear manner.
[0050] The one or more processors may be configured to determine the location at which the force is applied to the display based on whether an area of the display to which the force is applied corresponds to a first area or a second area, where the first area is different from the second area. For example, if a user applies their thumb to the display, then the area of the
display to which the force is applied is larger than if the user were to apply their index finger to the display. As another example, if a user has large fingers (e.g., relative to an average human finger size for a male and/or female), it can be considered that the area of the display to which the force is applied would be larger than a user having average size fingers. Accordingly, during a calibration of the wearable computing device a user may provide an input to the wearable computing device (e.g., via a mechanical button) indicating the size or area of the display which is to receive the force applied from the user. The input may indicate the area size (e.g., a first area or a second area), which can be used to determine a value for a scale parameter (e.g., a first scale parameter or a second scale parameter). The value for the scale parameter may indicate or describe a diffuseness of a Gaussian response used to analyze the optical signals output from the sensors for determining a location of the force applied to the display. As is known, a Gaussian response when graphed generally has a symmetric "bell curve" shape. For a given application of force to a particular location, a size of an area to which the force is applied affects the magnitude of the pressure and an amplitude of the force is greatest at a central location of the force. A distribution of the amplitude of the force (and correspondingly the pressure) declines (e.g., exponentially) at points located further away from the central location of the force. A larger area will have greater diffuseness than a smaller area.
[0051] For example, if the user applies a force to the display with a thumb, then a higher-variance response would be experienced, and a higher scale parameter may be appropriate (e.g., a value of 10). On the other hand, if a user applies a force to the display with an index finger, a lower-variance response would be experienced, and a lower scale parameter value may be appropriate (e.g., a value of 1).
[0052] The scale parameter values may be implemented in a model which describes the touch response amplitude of the sensors which is registered by the wearable computing device. For example, the touch response amplitude that is registered by the wearable computing device may be approximately modeled as a one-mode Gaussian function: f_press(x, y) = EXP { -[ (x, y) - (x_press, y_press) ]A2 / scale }.
[0053] Here, (x, y) represents the coordinate of the particular sensor (i.e., the coordinate of the particular detector which may be a photodiode) reading the PPG fluctuations. The term (x_press, y_press) represents the ground truth coordinates of the location at which a force is applied to the top of the wearable computing device. The scale parameter describes the “diffuseness” of the Gaussian response, as explained above, and is used in modeling the
captured optical readings based on the Gaussian function for taking into account an area covered by a touch which is user specific or user-group specific.
[0054] For example, when the area of the user interface (e.g., a display and/or faux buttons) to which the force is applied corresponds to a first area (e.g., for a large finger size or for a thumb), the one or more processors may be configured to determine an amplitude of each of the one or more optical readings output by the sensors based on a first model having a first scale parameter (e.g., having a value of 10) which reflects or describes a first variance of the force applied to the user interface. Alternatively, or in addition, when the area of the user interface (e.g., a display and/or faux buttons) to which the force is applied corresponds to a first area, the one or more processors may be configured to utilize a first Gaussian model to determine a location at which the force is applied to the user interface using a first loss function having the first scale parameter (e.g., having the value of 10) which reflects or describes the first variance of the force applied to the user interface.
[0055] For example, when the area of the user interface (e.g., a display and/or faux buttons) to which the force is applied corresponds to a second area (e.g., for a normal or small finger size or for an index finger), the one or more processors may be configured to determine the amplitude of each of the one or more optical readings output by the sensors based on a second model having a second scale parameter (e.g., having a value of 1) which reflects a second variance of the force applied to the user interface. Alternatively, or in addition, when the area of the user interface (e.g., a display and/or faux buttons) to which the force is applied corresponds to the second area, the one or more processors may be configured to utilize a second Gaussian model to determine the location at which the force is applied to the user interface using a second loss function having the second scale parameter (e.g., having the value of 1) which reflects or describes the second variance of the force applied to the user interface. Here, the first variance is different from (e.g., greater than) the second variance.
[0056] Stated differently, the one or more processors may be configured to determine the location of the force applied to the user interface based on a first scale parameter when the force applied to the user interface corresponds to a first area of the user interface (e.g., corresponding to the size of a user’s thumb), and the one or more processors may be configured to determine the location of the force applied to the user interface based on a second scale parameter when the force applied to the user interface corresponds to a second area of the user interface (e.g., corresponding to the size of a user’s index finger). In this case
the first scale parameter is greater than the second scale parameter, and the first area is greater than the second area.
[0057] According to an example of the disclosure, the one or more processors of the wearable computing device may receive a number of observations from the sensors at a given point in time which corresponds to the number of sensors. For example, if the wearable computing device has N PPG sensors (in particular N detectors), then the one or more processors of the wearable computing device may receive N observations from the detectors. obs l = f_press(x_PPG_l, y_PPG_l) # PPG l measures this value obs_2 = f_press(x_PPG_2, y_PPG_2) # PPG 2 measures this value obs_N = f_press(x_PPG_N, y_PPG_N) # PPG_N measures this value
[0058] Thus, if the wearable computing device has 3 detectors, then the one or more processors of the wearable computing device may receive 3 observations (i.e. , 1 observation from each of the detectors) at a given point in time.
[0059] According to some implementations, the closer the detector observation point of a sensor is from the center of the Gaussian response of the force applied to the display, then the sensor reads more PPG fluctuations, and an output value of the sensor may be higher (e.g. a value of 0.98). The further the PD is the output value may decrease (e.g., from 0.98 to 0.92).
[0060] For example, the one or more processors may be configured to determine the location at which the force is applied to the display based on an optical reading of a sensor among the sensors having a highest value, among the one or more optical readings output by the sensors. For example, the one or more processors may be configured to determine the location at which the force is applied to the display based on a highest amplitude among the amplitudes of the one or more optical readings output from the sensors. For example, the one or more processors may be configured to determine the location at which the force is applied to the display based on one or more of the amplitudes of the one or more optical readings output from the sensors and a loss function described herein.
[0061] Examples of the disclosure are also directed to a non-transitory computer- readable medium which stores instructions that are executable by one or more processors of a wearable computing device. The instructions may include instructions to cause the one or more processors to receive one or more optical readings output by sensors disposed on a lower side of a housing of the wearable computing device, when a force is applied to a display disposed on an upper side of the housing. The lower side of the housing may be
opposite to the upper side of the housing and be configured to be in contact with a body part of a user when the wearable computing device is worn by the user. The instructions may further include instructions to cause the one or more processors to determine a location at which the force is applied to the display based on the one or more received optical readings. [0062] The instructions may further include instructions to cause the one or more processors to execute one or more functions of the wearable computing device based on the location at which the force is applied to the display. Example functions of the wearable computing device may include checking health information about the user such as a blood pressure, making and/or receiving a phone call, sending and/or receiving a text message, obtaining a current time, setting a timer, a stopwatch function, controlling an external device such as a home appliance, and the like.
[0063] The instructions may further include instructions to cause the one or more processors to display a graphical user interface indicating to a user to calibrate the wearable computing device by indicating an area of the display to which a force is to be applied to the display. When the area of the force indicated by the user corresponds to a first area, the instructions further include instructions to cause the one or more processors to determine an amplitude of each of the one or more optical readings based on a first model having a first scale parameter which reflects a first variance of the force to be applied to the display. When the area of the force indicated by the user corresponds to a second area, the instructions further include instructions to cause the one or more processors to determine the amplitude of each of the one or more optical readings based on a second model having a second scale parameter which reflects a second variance of the force to be applied to the display. For example, the first area may be greater than the second area, and the first variance may be greater than the second variance. The instructions may further include instructions to cause the one or more processors to determine the location at which the force is applied to the display based on a highest amplitude among the amplitudes of the one or more optical readings.
[0064] The instructions may further include instructions to cause the one or more processors to determine the location at which the force is applied to the display based on an optical reading of a sensor among the sensors having a highest value, among the one or more optical readings received by the one or more processors.
[0065] Examples of the disclosure are also directed to computer implemented methods of a wearable computing device. The method may include receiving one or more optical readings output by sensors disposed on a lower side of a housing of the wearable computing
device, when a force is applied to a display disposed on an upper side of the housing. The lower side of the housing may be opposite to the upper side of the housing and be configured to be in contact with a body part of a user when the wearable computing device is worn by the user. The method may further include determining, by one or more processors of the wearable computing device, a location at which the force is applied to the display based on the one or more received optical readings.
[0066] The method may further include executing one or more functions of the wearable computing device based on the location at which the force is applied to the display. Example functions of the wearable computing device may include checking health information about the user such as a blood pressure, making and/or receiving a phone call, sending and/or receiving a text message, obtaining a current time, setting a timer, a stopwatch function, controlling an external device such as a home appliance, and the like.
[0067] The method may further include displaying a graphical user interface indicating to a user to calibrate the wearable computing device by indicating an area of the display to which a force is to be applied to the display. When the area of the force indicated by the user corresponds to a first area, the method may include determining an amplitude of each of the one or more optical readings based on a first model having a first scale parameter which reflects a first variance of the force to be applied to the display. When the area of the force indicated by the user corresponds to a second area, the method may include determining the amplitude of each of the one or more optical readings based on a second model having a second scale parameter which reflects a second variance of the force to be applied to the display. For example, the first area may be greater than the second area, and the first variance may be greater than the second variance. The method may include determining the location at which the force is applied to the display based on a highest amplitude among the amplitudes of the one or more optical readings. The method may include determining the location at which the force is applied to the display based on one or more of the amplitudes of the one or more optical readings output from the sensors and a loss function described herein. [0068] The method may include determining the location at which the force is applied to the display based on an optical reading of a sensor among the sensors having a highest value, among the one or more optical readings received by the one or more processors.
[0069] According to examples described herein, the one or more processors of the wearable computing device may determine the location of a user touching an element or part of the wearable computing device at an upper side by calculating an estimate of location
parameters, e.g., location coordinates, based on a loss function that is optimized to find a ground truth coordinate location of where the force is applied to the upper side of the wearable computing device. In an example, the probabilistic channel given that an observation (for example, obs l) could be corrupted by Gaussian measurement noise, may be written as: p(obs_l | (x_press, y_press))= G[ EXP { -[ (x_l, y_l) - (x_press, y_press) ]A2 / scale k } - obs_l ].
[0070] Here the G(.) function describes the probability density of a standard Gaussian function which may be used to reconstruct the location of the application of the force using measurements obtained from the detectors, which are sparsely provided and distributed. For example, a probability of receiving the values observed for each of the observations N is calculated based on candidate touch events (i.e. , candidate locations where the force is estimated to be applied). Whatever candidate touch event maximizes the probability (or minimizes the loss) may be considered as the most likely location of the force (i.e., touch event). For example, an expression of the negative log likelihood of all the observations may be used to find the ground truth press coordinates, as follows:
LOSS = { EXP { -[ (x_l, y_l) - (x_press, y_press) ]A2 / scale k } - obs_l } A 2
+ { EXP { -[ (x_2, y_2) - (x_press, y_press) ]A2 / scale k } - obs_l } A 2
... + { EXP { -[ (x_N, y_N) - (x_press, y_press) ]A2 / scale k } - obs_N } A 2 }
[0071] In the above expression, the terms “x_l, y_l”, “x_2, y_2”, and “x_N, y_N” correspond to the location of each PPG detector, which is known. The terms “obs l”, “obs_2”, and “obs_N” correspond to the observed values of the respective detectors. The term “scale k” is the scale parameter value which describes the diffuseness of the Gaussian response as described herein. The terms “x_press, y_press” corresponds to the value that is to be estimated (i.e., the X, Y coordinate value of the location of the force). For example, in a three channel PPG sensor, where there are three detectors, N may be equal to three.
[0072] Because the example loss function is variable up to two parameters of interest (x_press, y_press), which at the time of observation are unknowns, a two-dimensional grid search may be performed to estimate (x_press, y_press) by finding the global loss minimizer. For example, the one or more processors may be configured to execute a program to perform a direct search in which every X, Y coordinate pair (e.g., corresponding to the area of the display) is tested as candidate touch events to obtain a result which achieves the minimal loss. The candidate touch event achieving the lowest loss (i.e., a minimal error) between may
correspond to the estimated touch location. As another example, the one or more processors may implement a known gradient descent method to obtain a result (X, Y coordinate) which obtains the minimal loss. The gradient descent search method may utilize random candidate touch events (i. e. , random candidate X, Y coordinates) to obtain a result which achieves the minimal loss rather than a direct search report in which all of the candidate touch events are tested. The gradient descent search method may use a smaller search space and thus be less computationally expensive than the direct search approach, saving energy and time. The disclosure is not limited to a direct search method or gradient descent search method, and other methods for minimizing a loss function may also be implemented.
[0073] In one or more examples, the user interface may include a non-touch sensitive display which displays a plurality of selectable functions of the wearable computing device. In response to a noise level of the sensors increasing beyond a threshold (e.g., a signal-to- noise ratio being greater than lOdB), the one or more processors may be configured to control the display so that a number of the plurality of selectable functions displayed on the display may be reduced, and the one or more processors may be configured to execute a function among the plurality of selectable functions based on the location at which the one or more processors determines the force is applied to the display. For example, a noise level of the sensors may increase when the wearable computing device is not securely held to the body part of the user and/or due to a low battery condition, such that the one or more optical readings may be affected by noise, and the accuracy of the sensors may be reduced. A number of the plurality of selectable functions displayed on the display may be reduced (e.g., reducing icons displayed on the display from ten icons to four icons) when the noise level of the sensors exceeds a threshold (e.g., a signal-to-noise ratio being greater than lOdB).
Stopping the displaying of one or more of the plurality of selectable functions (i.e., reducing the number of the plurality of selectable functions displayed on the display) may enlarge a space on the display for each of the remaining selectable functions to be displayed. Thus, a likelihood that the one or more processors may accurately execute a function that the user intends to select may be increased, even though an accuracy of the detection or determination of the location of the force applied to the display may be reduced due to the noise encountered or experienced by the sensors. By changing the number of selectable functions displayed on the display, the noisy condition encountered by the sensors may be masked. [0074] In one or more examples, the user interface may additionally, or alternatively, include a plurality of faux buttons which respectively correspond to a plurality of selectable
functions of the wearable computing device. The one or more processors may be configured to execute a function of the computer wearable device among the plurality of selectable functions based on the location at which the force is applied with respect to respective locations of the plurality of faux buttons. For example, the faux buttons (or faux switch) may represent or indicate functions of the wearable computing device that can be performed by the wearable computing device. However, the faux buttons may not be mechanically or electrically connected (e.g., via a switch or capacitive sensors) to implement a function of the wearable computing device. Instead, the one or more processors may be configured to execute a function of the computer wearable device among the plurality of selectable functions based on the location at which the force is applied with respect to respective locations of the plurality of faux buttons.
[0075] In one or more examples, the wearable computing device may further include an accelerometer and/or a gyroscope to detect or sense motion data (e.g., for counting steps of a user) of the wearable computing device. The sensors may include PPG sensors which are also configured to monitor a heart rate of the user of the wearable computing device.
[0076] Motion of a user’s hand affects arterial pressure and volumetric structure (muscle/tendon), creating a signature dip in reflection/absorption reflected in the PPG signal. The PPG sensors may capture the arterial pressure profiles spatially over a two-dimensional area (e.g., in x and y directions) on the lower side of the housing of the wearable computing device. The one or more processors may be configured to identify a gesture of the user based on the one or more optical readings output by the PPG sensors, and the one or more processors may be configured to execute a function of the computer wearable device (or another device) based on the gesture of the user identified by the one or more processors.
The one or more processors may be configured to identify the gesture of the user based on the one or more optical readings output by the PPG sensors together with one or more outputs of the accelerometer and/or the gyroscope.
[0077] In one or more examples, the gesture of the user may include hand gestures including clinching of a fist, a pinching gesture with the fingers, squeezing of a hand, and the like. The gestures may be mapped to respective functions of the wearable computing device (e.g., to make a phone call), or a function of another device (e.g., to operate a home appliance) which may be controllable via the wearable computing device by the identification of the gesture. In one or more examples, the wearable computing device may identify a gesture based on the one or more optical readings output by the PPG sensors. For example, each gesture may correspond to a respective optical signal output by the PPG sensors so that
a gesture may be correctly identified. In an example, optical signals output by the PPG sensors may be analyzed to identify the gesture (e.g., via machine learning algorithms to classify the output optical readings, by comparing the optical signals with known optical signals corresponding to respective gestures, etc.). To more accurately analyze the optical signals, portions of the optical readings which are attributed to a heart rate of the user may be filtered out. For example, a high pass heart rate filtering operation may be performed with respect to the optical readings to notch out the heart rate (arterial pulse), so that the majority of the optical readings which are used to identify the gesture corresponds to or is attributed to, the movement of the user’s body part (e.g., the hand).
[0078] Example of the disclosure provide several technical effects, benefits, and/or improvements in computing technology and the technology of wearable computing devices. For example, according to one or more examples of the disclosure, a location of a touch on a display may be indirectly sensed by sensors disposed on a lower side of a housing of the wearable computing device which is in contact with a body part of a user when the wearable computing device is worn by the user. Accordingly, the wearable computing device need not have a touch-sensitive display, thereby reducing the number of parts included in the wearable computing device. Furthermore, according to one or more examples of the disclosure the wearable computing device leverages sensors which may be pre-existing in the wearable computing device. For example, the pre-existing sensors may include PPG sensors used for other purposes, such as detecting a heart rate of a user. Therefore, it is not necessary to add further sensors to the wearable computing device to determine a location of a touch by a user on the display. As another example, according to one or more examples of the disclosure the wearable computing device may utilize less power than a wearable computing device which includes a touch-sensitive display. As another example, according to one or more examples of the disclosure the wearable computing device may utilize less space than a wearable computing device which includes a touch-sensitive display. Therefore, the wearable computing device may be smaller and sleeker, or may provide space for other components which might not otherwise be installable if a touch-sensitive display were provided in the wearable computing device. As another example, according to one or more examples of the disclosure the wearable computing device may not include a display at all, and functions of the wearable computing device may be implemented using faux buttons which are associated with corresponding functions of the wearable computing device. Alternatively, according to one or more examples of the disclosure the wearable computing device may include a display as well as faux buttons, where functions of the wearable computing device may be
implemented using the display and faux buttons, or only the faux buttons which are associated with corresponding functions of the wearable computing device.
[0079] Referring now to the drawings, FIGS. 1 through 4B illustrate examples of a wearable computing device 100 according to examples of the disclosure. FIG. 1 illustrates an example wearable computing device 100 which can be worn, for example, on an arm 102 (e.g., wrist) of a user. For example, the wearable computing device 100 can include a housing 110 (e.g., a body). FIG. 2 illustrates an exploded view of the wearable computing device 100 where the housing 110 includes an upper side 110a and a lower side 110b, and the housing 110 can define a cavity 112 in which one or more electronic components (e.g., disposed on one or more printed circuit boards) are disposed. For example, the wearable computing device 100 can include a printed circuit board 120 disposed within the cavity 112. Furthermore, one or more electronic components can be disposed on the printed circuit board 120. The wearable computing device 100 can further include a battery (not shown) that is disposed within the cavity 112 defined by the housing 110. The wearable computing device 100 can further include various sensors 170 that are disposed within the cavity 112 defined by the housing 110. For example, the sensors 170 may include multipath photoplethysmography (PPG) sensors 172 disposed at the lower side 110b of the housing 110 which may be used to monitor a heart rate of the user. The PPG sensors 172 may include one or more emitters (e.g., light-emitting diodes (LEDs)) and a plurality of detectors (e.g., photodiodes). Light emitted from the one or more emitters is transmitted in a direction toward the user’s body part (e.g., a portion of a user’s wrist) which is in contact with the lower side 110b of the housing 110. The light then interacts with blood vessels of the user, where it is modified to a degree that is influenced by the current blood volume in the blood vessels. The modified light is directed back toward the PPG detectors by reflection and/or refraction. The PPG detectors generate data (e.g., one or more signals) which is reflective of the current blood volume of the blood vessels of the user which received the light emitted from the one or more emitters. For example, the sensors 170 may also include an accelerometer 174 which may be used to capture motion information with respect to the wearable computing device 100. For example, the sensors 170 may also include a gyroscope 176 which may also be used to capture motion information with respect to the wearable computing device 100.
[0080] The wearable computing device 100 can include a first band 130 and a second band 132. As shown, the first band 130 can be coupled to the housing 110 at a first location
thereon. Conversely, the second band 132 can be coupled to the housing 110 at a second location thereon. Furthermore, the first band 130 and the second band 132 can be coupled to one another to secure the housing 110 to the arm 102 of the user.
[0081] In some examples, the first band 130 can include a buckle or clasp (not shown). Additionally, the second band 132 can include a plurality of apertures (not shown) spaced apart from one another along a length of the second band 132. In such implementations, a prong of the buckle associated with the first band 130 can extend through one of the plurality of openings defined by the second band 132 to couple the first band 130 to the second band 132. It should be appreciated that the first band 130 can be coupled to the second band 132 using any suitable type of fastener. For example, in some implementations, the first band 130 and the second band 132 can include a magnet. In such implementations, the first band 130 and the second band 132 can be magnetically coupled to one another to secure the housing 110 to the arm 102 of the user.
[0082] The wearable computing device 100 can include a cover 140 positioned on the housing 110 so that the cover 140 is positioned on top of (over) the display 182. In this manner, the cover 140 can protect the display 182 from being scratched. In some implementations, the wearable computing device 100 can include a seal (not shown) positioned between the housing 110 and the cover 140. For instance, a first surface of the seal can contact the housing 110 and a second surface of the seal can contact the cover 140. In this manner, the seal between the housing 110 and the cover 140 can prevent a liquid (e.g., water) from entering the cavity 112 defined by the housing 110.
[0083] It should be understood that the cover 140 can be optically transparent so that the user can view information being displayed on the display 182. For instance, in some implementations, the cover 140 can include a glass material. It should be understood, however, that the cover 140 can include any suitable optically transparent material.
[0084] FIG. 3 illustrates an example block diagram of the wearable computing device 100 according to one or more example embodiments of the disclosure. The wearable computing device 100 may include one or more processors 150, one or more memory devices 160, one or more sensors 170, and a user interface 180.
[0085] For example, the one or more processors 150 can be any suitable processing device that can be included in a wearable computing device 100. For example, such a processor 150 may include one or more of a processor, processor cores, a controller and an arithmetic logic unit, a central processing unit (CPU), a graphics processing unit (GPU), a digital signal processor (DSP), an image processor, a microcomputer, a field programmable
array, a programmable logic unit, an application-specific integrated circuit (ASIC), a microprocessor, a microcontroller, etc., and combinations thereof, including any other device capable of responding to and executing instructions in a defined manner. The one or more processors 150 can be a single processor or a plurality of processors that are operatively connected, for example in parallel.
[0086] The memory 160 can include one or more non-transitory computer-readable storage mediums, such as such as a Read Only Memory (ROM), Programmable Read Only Memory (PROM), Erasable Programmable Read Only Memory (EPROM), and flash memory, a USB drive, a volatile memory device such as a Random Access Memory (RAM), a hard disk, floppy disks, a blue-ray disk, or optical media such as CD ROM discs and DVDs, and combinations thereof. However, examples of the memory 160 are not limited to the above description, and the memory 160 may be realized by other various devices and structures as would be understood by those skilled in the art.
[0087] For example, memory 160 can store instructions, that when executed, cause the one or more processors 150 to determine a location at which a force is applied to the display 182 based on one or more received optical readings output by PPG sensors 172, as described according to examples of the disclosure. For example, memory 160 can store instructions, that when executed, cause the one or more processors 150 to execute one or more functions of the wearable computing device 100 based on the determined location, as described according to examples of the disclosure.
[0088] Memory 160 can also include data 162 and instructions 164 that can be retrieved, manipulated, created, or stored by the one or more processor(s) 150. In some example embodiments, such data can be accessed and used as input to determine a location at which a force is applied to the display 182 based on one or more optical readings (signals) output by the PPG sensors 172. In some examples, the memory 160 can include data used to perform one or more processes and instructions that execute one or more functions of the wearable computing device 100 based on the location at which the force is applied to the display 182 as determined by the one or more processors.
[0089] The wearable computing device 100 can include a user interface 180 configured to receive an input from a user by the user applying a force to the user interface (e.g., via a thumb, finger, or an input device such as a stylus or pen). The wearable computing device 100 may execute a function in response to receiving the input from the user (e.g., checking health information about the user such as a blood pressure, making and/or receiving a phone
call, sending and/or receiving a text message, obtaining a current time, setting a timer, a stopwatch function, controlling an external device such as a home appliance, and the like). [0090] For example, the wearable computing device 100 may be connected to one or more external devices 190 in a wireless and/or wired manner. The wearable computing device 100 may be connected to the external device 190 over a network 300 such as a local area network (LAN), wireless local area network (WLAN), wide area network (WAN), personal area network (PAN), virtual private network (VPN), or the like. For example, wireless communication between the wearable computing device 100 and the external device 190 may be performed via a wireless LAN, Wi-Fi, Bluetooth, ZigBee, Wi-Fi direct (WFD), ultra wideband (UWB), infrared data association (IrDA), Bluetooth low energy (BLE), near field communication (NFC), a radio frequency (RF) signal, and the like. For example, the wired communication connection may be performed via a USB cable, a pair cable, a coaxial cable, an optical fiber cable, an Ethernet cable, and the like.
[0091] The user interface 180 may include a display 182 which displays information viewable by the user (e.g., time, date, biometric information, notifications, etc.). For example, the display 182 may be anon-touch sensitive display. The display 182 may include a liquid crystal display (LCD), a light emitting diode (LED) display, an organic light emitting diode (OLED) display, active matrix organic light emitting diode (AMOLED), flexible display, 3D display, a plasma display panel (PDP), a cathode ray tube (CRT) display, and the like, for example. However, the disclosure is not limited to these example displays and may include other types of displays. That is, the non-touch sensitive display 182 may not be capable of sensing a touch event via conduction using electrical conductors (e.g., like a capacitive touch display or resistive display) to change a capacitance or resistance of a circuit. Thus, the nontouch sensitive display 182 does not include a touch panel which may include conductive layers and/or resistive layers of circuitry. The display 182 may include various layers, including one or more of a display surface, polarizing layers, liquid crystal layer, backlight, glass substrate, and the like. In some implementations, the display 182 may have a square or rectangular shape, or may be annular in shape (e.g., elliptical, circular, etc.). However, it should be appreciated that the display 182 can have any suitable shape.
[0092] In the example of FIG. 4A, the display 182 displays various functions Fl, F2, F3, F4 in respective quadrants of the display 182 that the wearable computing device 100 is capable of performing. For example, the functions may be displayed using visual elements such as text and/or by using symbols (e.g., icons) which inform the user of the respective
function to be performed. For example, in response to a user applying a force to the lower right quadrant of the display 182 where the function F4 is represented, PPG detectors 172a, 172b, 172c may output respective optical readings (signals) SI, S2, S3 (see FIGS. 4C and 5A-5B) in response to the applied force. For example, a first PPG detector 172a which is located closest to the location at which the force is applied to the display 182 may output a signal SI with a higher amplitude or higher value compared to the outputs S2 and S3 of second and third PPG detectors 172b, 172c which are located further away from the location at which the force is applied to the display 182. One or more processors 150 may receive one or more optical readings (signals) from each of the PPG detectors 172a, 172b, 172c and determine a location at which the force is applied to the display 182 based on the one or more optical readings (signals) output by the PPG detectors 172a, 172b, 172c. In response to the one or more processors 150 determining that the force is applied to a location corresponding to the lower right quadrant of the display 182 based on the received one or more optical readings (signals), the one or more processors 150 may execute the function F4 which is displayed in the lower right quadrant of the display 182.
[0093] The user interface 180 may additionally, or alternatively, include one or more buttons 184 to receive an input from a user by the user applying a force to the one or more buttons 184. For example, one or more buttons 184c may be included on one or more peripheral sides of the wearable computing device 100 as shown in FIG. 1, for example. The one or more buttons 184c may be a known button which includes mechanical components and/or electrical circuitry to implement a function of the wearable computing device 100 (e.g., setting a time, changing a setting and/or view of the display 182, selecting an option displayed on the display 182). In addition, or alternatively, the one or more buttons 184 may also include one or more faux buttons 184a, 184b. For example, in FIG. 4B, faux buttons 184a, 184b are disposed on an upper side 110a of the housing 110 adjacent to the display 182. The faux buttons 184a, 184b may represent or indicate functions F3, F4 of the wearable computing device 100 that can be performed by the wearable computing device 100. For example, the faux button 184a may include a label, symbol, or other indication to inform the user of the function F3 to be performed, and the faux button 184b may include a label, symbol, or other indication to inform the user of the function F4 to be performed. In another example, the wearable computing device 100 may not include the display 182 and the upper side of the housing 110 may include one or more faux buttons 184a, 184b to receive a user input. The faux buttons 184a, 184b may not be mechanically and/or electrically connected (e.g., via a switch or capacitive sensors) to other components of the wearable computing
device 100 to implement a function of the wearable computing device 100.
[0094] For example, in response to a user applying a force to the faux button 184b, PPG detectors 172a, 172b, 172c may output respective optical readings (signals) SI, S2, S3 (see FIGS. 4C and 5A-5B) in response to the applied force. For example, a first PPG detector 172a which is located closest to the location at which the force is applied to the faux button 184b may output a signal SI with a higher amplitude or higher value compared to the outputs S2 and S3 of second and third PPG detectors 172b, 172c which are located further away from the location at which the force is applied to the faux button 184b. One or more processors 150 may receive one or more optical readings (signals) from each of the PPG detectors 172a, 172b, 172c and determine a location at which the force is applied to the upper side of the housing 110 based on the one or more optical readings (signals) output by the PPG detectors 172a, 172b, 172c. In response to the one or more processors 150 determining that the force is applied to a location corresponding to the faux button 184b based on the received one or more optical readings (signals), the one or more processors 150 may execute the function F4 which is represented by faux button 184b.
[0095] With reference to FIG. 4C, a bottom view of an example wearable computing device is illustrated according to one or more example embodiments of the disclosure. The wearable computing device 100 may include a plurality of PPG sensors, for example to assist in rejecting motion artifacts. Each PPG sensor may correspond to a combination of a light source and a respective detector. For example, in FIG. 4C there are three PPG sensors: the combination of LED 172d with detector 172a, the combination of LED 172d with detector 172b, and the combination of LED 172d with detector 172c. However, the disclosure is not limited to the example of FIG. 4C and the wearable computing device 100 may include two PPG sensors or more than three PPG sensors. Furthermore, more than one LED may be included such that different detectors may be combined with different LEDs and/or each detector may be combined with one or more LEDs to output a PPG signal. For example, the plurality of detectors may be disposed in a circular or elliptical arrangement, where the plurality of detectors may be spaced apart from each other at regular or irregular intervals. In FIG. 4C, detector 172a is spaced apart from detector 172c in the horizontal or “X” direction, and is spaced apart from detector 172b in both the horizontal (X) direction and the vertical or “Y” direction. Detector 172b is spaced apart from both detectors 172a and 172c in the horizontal (X) direction and vertical (Y) direction. Detector 172c is spaced apart from detector 172a in the horizontal (X) direction, and is spaced apart from detector 172b in both
the horizontal (X) direction and the vertical (Y) direction. LED 172d is spaced apart from detector 172b in the vertical (Y) direction and is spaced apart from both detectors 172a and 172c in each of the horizontal (X) and vertical (Y) directions. However, the configuration of the detectors and LED may be different from that illustrated in FIG. 4C, and the disclosure is not limited to the example of FIG. 4C.
[0096] The PPG sensors may optically measure biometric information such as a heart rate, using a light source and a photodetector at the surface of a user’s body part to measure the volumetric variations of blood circulation. The light source (e.g., one or more LEDs) emits light to a body part and the photodetector measures the reflected light from the body part, where the amount of reflected light may indicate biometric information about the user (e.g., blood flow, volume of blood, etc.). The light source may emit infrared light, and the color of the LED may be red, green, or yellow. The PPG signal may include various components, such as a DC component (or DC offset), which represents the constant absorption of light passing through the tissues, and an AC component generated by heartbeats (cardiac activity) affecting blood volume, which depends on the systolic and diastolic phases.
[0097] As disclosed herein, PPG signals output by the PPG sensors may also be affected when a force (e.g., a direct or indirect force) is applied to a body part of the user where the PPG sensors are located. The changes in the PPG signals due to this force may be used to detect an event (e.g., a touch event on the display 182 when a force is applied to the display 182 of the wearable computing device 100).
[0098] For example, when a user applies a force (e.g., a pressing action) to an upper side 110a of the wearable computing device 100 (e.g., the user interface 180 including the display 182 and/or faux buttons 184a, 184b), optical readings (signals) from the PPG sensors 172 disposed on a lower surface of the wearable computing device 100 fluctuate based on where the user is applying the force. For example, a detector of the PPG sensor which is closest to the location of the force application will sense more of the optical back-reflections compared to another detector which is located further away from the location of the force application. The one or more processors may be configured to determine or estimate (e.g., using a sparse- pixel maximum likelihood decoder) the location at which the force is applied to the display (e.g., an X, Y position on the user interface 180 including the display 182 and/or faux buttons 184a, 184b).
[0099] For example, a touch response amplitude of a detector that is output when a force
is applied to the upper part of the wearable computing device 100 (e.g., the display 182) may be approximately modeled as a one-mode Gaussian function: f_press(x, y) = EXP { - [ (x, y) - (x_press, y_press) ]A2 / scale k }. Here, (x, y) represents the coordinate of the particular detector (e.g., photodiode) reading the PPG fluctuations. The term (x_press, y_press) represents the ground truth coordinates of the location at which a force is applied to the upper part of the wearable computing device. The scale parameter k describes the “diffuseness” of the Gaussian response, which is explained in more detail with reference to FIGS. 6A-10B.
[0100] For example, generally for a given application of a force to a particular location, an amplitude of the force is greatest at a central location of the force, and a distribution of the amplitude of the force declines (e.g., exponentially) at points located further away from the central location of the force. In modeling the Gaussian response, a scale parameter k may be determined based on whether an area of the display to which the force is applied corresponds to a first area or a second area, where the first area is larger than the second area. For example, if a user applies their thumb to the display, then the area of the display to which the force is applied is larger than if the user were to apply their index finger to the display. As another example, if a user has large fingers (e.g., relative to an average human finger size for a male and/or female), it can be considered that the area of the display to which the force is applied would be larger than a user having average size fingers.
[0101] Accordingly, during a calibration of the wearable computing device a user may provide an input to the wearable computing device indicating the size or area of the display which is to receive the force applied from the user. The input may indicate the area size (e.g., a first area or a second area), which can be used to determine a scale parameter (e.g., a first scale parameter kl or a second scale parameter k2). The scale parameter may indicate or describe a diffuseness of the Gaussian response which can be used to analyze the optical signals output from the PPG sensors 172 for determining a location of the force applied to the display 182.
[0102] FIGS. 6A and 6B depict example press Gaussian responses corresponding to different scale parameters, according to one or more example embodiments of the disclosure For example, if the user applies a force to the display 182 with a thumb, then a higher- variance response 610 would be experienced, and a higher scale parameter kl may be appropriate (e.g., a value of 10). On the other hand, if a user applies a force to the display 182 with an index finger, a lower-variance response 620 would be experienced, and a lower scale parameter value k2 may be appropriate (e.g., a value of 1).
[0103] The scale parameter values (e.g., kl and k2) may be implemented in the model described above (e.g., using the Gaussian function f_press(x, y) = EXP { -[ (x, y) - (x_press, y_press) ]A2 / scale k) which describes the touch response amplitude of the PPG sensors 172 which is registered by the wearable computing device 100.
[0104] For example, when the area of the display 182 to which the force is applied corresponds to a first area (e.g., for a large finger size or for a thumb), the one or more processors 150 may be configured to determine an amplitude of each of the one or more optical readings output by the PPG sensors 172 based on a first model having a first scale parameter kl (e.g., having a value of 10) which reflects or describes a first variance of the force applied to the display 182.
[0105] For example, when the area of the display 182 to which the force is applied corresponds to a second area (e.g., for a normal or small finger size or for an index finger), the one or more processors 150 may be configured to determine the amplitude of each of the one or more optical readings output by the PPG sensors 172 based on a second model having a second scale parameter k2 (e.g., having a value of 1) which reflects a second variance of the force applied to the display 182. Here, the first variance is greater than the second variance.
[0106] Stated differently, the one or more processors 150 may be configured to determine the location of the force applied to the display 182 based on a first scale parameter kl when the force applied to the display 182 corresponds to a first area of the display 182 (e.g., corresponding to the size or surface area of a user’s thumb), and the one or more processors 150 may be configured to determine the location of the force applied to the display 182 based on a second scale parameter k2 when the force applied to the display 182 corresponds to a second area of the display 182 (e.g., corresponding to the size or surface area of a user’s index finger). In this case the first scale parameter kl is greater than the second scale parameter k2, and the first area is greater than the second area. For example, the first area and second area may correspond to known or empirically obtained values for average fingertip areas of a thumb or index finger, and may additionally be categorized according to a gender of the user. As an example, a first area may correspond to about 5 cm2 to 6 cm2 (an approximate surface area of the tip of a thumb) and a second area may correspond to about 2.5 cm2 to 3.5 cm2 (an approximate surface area of the tip of an index finger).
[0107] For example, during a calibration of the wearable computing device 100 a user
may provide an input to the wearable computing device 100 indicating the size or area of the display 182 which is to receive a force applied from the user. For example, the wearable computing device 100 may display information on the display 182 which requests that the user indicate a preferred digit (e.g., a thumb or index finger) to be used for providing an input (force) to the display 182. For example, the user may select the preferred digit using a button 184c disposed on an outer peripheral portion of the wearable computing device 100 similar to a manner in which a user may set a time or date as in known watches. The user may additionally and/or alternatively input their gender for further determination of the scale parameter k for selecting an appropriate model to be utilized.
[0108] According to examples of the disclosure, the one or more processors 150 of the wearable computing device 100 may receive a number of observations from the PPG sensors 172 at a given point in time which corresponds to the number of sensors. For example, if the wearable computing device has N PPG sensors 172 (in particular N detectors 172a-c), then the one or more processors 150 of the wearable computing device 100 may receive N observations from the detectors 172a-172c. obs l = f_press(x_PPG_l, y_PPG_l) # PPG l measures this value obs_2 = f_press(x_PPG_2, y_PPG_2) # PPG 2 measures this value obs_N = f_press(x_PPG_N, y_PPG_N) # PPG_N measures this value
[0109] As illustrated in FIG. 4C, the wearable computing device 100 has three detectors 172a- 172c. The one or more processors 150 of the wearable computing device 100 may receive three observations (i.e., one observation from each of the detectors 172a-172c) at a given point in time.
[0110] FIGS. 7A and 7B depict example observation values according to one or more example embodiments of the disclosure. As described previously, according to some implementations, the closer the detector observation point of a detector is from the center of the Gaussian response of the force applied to the display 182, then the detector reads more PPG fluctuations, and an output value of the detector may be higher while detectors located further away have lower values. For example, in FIG. 7A, outputs of the detectors 172a-172c are overlaid on top of a press Gaussian function 710, where darker shading indicates the center of the Gaussian function corresponding to the actual touch location, detector 172c outputs a value of 0.98 while detectors 172a and 172b output values of 0.92 and 0.94 respectively. The one or more processors 150 may determine or estimate that the location of
the force applied to the display 182 is in a middle right portion of the display 182 based on the values of each of the detectors 172a-172c. For example, in FIG. 7B, detector 172c outputs a value of 0.91 while detectors 172a and 172b output values of 0.83 and 0.89 respectively. The one or more processors 150 may determine or estimate that the location of the force applied to the display 182 is in an upper right portion of the display 182, based on the values of each of the detectors 172a-172c, noting that detectors 172b and 172c have relatively similar values compared to the value output by detector 172a.
[Oil 1] The one or more processors 150 may be configured to determine the location at which the force is applied to the display 182 based on optical reading values of a PPG sensor 172 among the PPG sensors 172 having a highest value, e.g., a highest voltage value. For example, the one or more processors 150 may be configured to determine the location at which the force is applied to the display 182 based on a highest amplitude among the amplitudes of the one or more optical reading values output from the PPG sensors 172.
[0112] The one or more processors 150 may be configured to determine the location at which the force is applied to the display 182 based on a loss function that is optimized to find a ground truth coordinate location of where the force is applied to the display 182. In an example, the probabilistic channel given that an observation (for example, obs l) could be corrupted by Gaussian measurement noise, may be written as: p(obs_l | (x_press, y_press))= G[ EXP { -[ (x_l, y_l) - (x_press, y_press) ]A2 / scale k } - obs_l ].
[0113] Here the G(.) function describes the probability density of a standard Gaussian function which may be used to reconstruct the location of the application of the force using measurements obtained from the detectors, which are sparsely provided and distributed. For example, a probability of receiving the values observed for each of the observations N is calculated based on candidate touch events (i.e. , candidate locations where the force is estimated to be applied). Whatever candidate touch event maximizes the probability (or minimizes the loss) may be considered as the most likely location of the force (i.e., touch event). For example, an expression of the negative log likelihood of all the observations may be used to find the ground truth press coordinates, as follows:
LOSS = { EXP { -[ (x_l, y_l) - (x_press, y_press) ]A2 / scale k } - obs_l } A 2
+ { EXP { -[ (x_2, y_2) - (x_press, y_press) ]A2 / scale k } - obs_l } A 2
... + { EXP { -[ (x_N, y_N) - (x_press, y_press) ]A2 / scale k } - obs_N } A 2 }
[0114] In the above expression, the terms “x_I, y_l”, “x_2, y_2”, and “x_N, y_N”
correspond to the location of each PPG detector, which is known. The terms “obs 1”, “obs_2”, and “obs_N” correspond to the observed values of the respective detectors. The term “scale k” is the scale parameter value which describes the diffuseness of the Gaussian response as described herein. The terms “x_press, y_press” corresponds to the value that is to be estimated (i.e., the X, Y coordinate value of the location of the force). For example, in a three channel PPG sensor, where there are three detectors, N may be equal to three.
[0115] Because the example loss function is variable up to two parameters of interest (x_press, y_press), which at the time of observation are unknowns, a two-dimensional grid search may be performed to estimate (x_press, y_press) by finding the global loss minimizes For example, the one or more processors 150 may be configured to execute a program to perform a direct search in which every X, Y coordinate pair (e.g., corresponding to the area of the display) is tested as candidate touch events to obtain a result which achieves the minimal loss. The candidate touch event achieving the lowest loss (i.e., a minimal error) between may correspond to the estimated touch location. As another example, the one or more processors 150 may implement a known gradient descent method to obtain a result (X, Y coordinate) which achieves the minimal loss. The gradient descent search method may utilize random candidate touch events (i.e., random candidate X, Y coordinates) to obtain a result which obtains the minimal loss rather than a direct search report in which all of the candidate touch events are tested. The gradient descent search method may use a smaller search space and thus be less computationally expensive than the direct search approach, saving energy and time. The disclosure is not limited to a direct search method or gradient descent search method, and other methods for minimizing a loss function may also be implemented.
[0116] FIGS. 8 A and 8B illustrate an example estimate of the location of a force applied to the display based on a loss function result, according to one or more example embodiments of the disclosure. For example, in FIG. 8A, an estimated location of a force applied to the display 182 (upper right comer) is denoted by reference numeral 810. The location of the force has been calculated or determined by the one or more processors 150 using values output by detectors configured as in the example of FIG. 4C. The ground truth (actual) location of the force is denoted by reference numeral 820. The Gaussian press response 830 is also shown in the background to provide additional context. For example, FIG. 8B illustrates a corresponding loss function result 840 where an outer band 850 denotes the most likely location of a minimizing result, in which the estimated location 810 also corresponds.
[0117] FIGS. 9A and 9B illustrate another example estimate of the location of a force applied to the display based on a loss function result, according to one or more example embodiments of the disclosure. For example, in FIG. 9A, an estimated or determined location of a force applied to the display 182 (lower right comer) is denoted by reference numeral 910. The location of the force has been calculated or determined by the one or more processors 150 using values output by detectors configured as in the example of FIG. 4C. The ground truth (actual) location of the force is denoted by reference numeral 920. The Gaussian press response 930 is also shown in the background to provide additional context. For example, FIG. 9B illustrates a corresponding loss function result 940 where an outer band 950 denotes the most likely location of a minimizing result, in which the estimated location 910 also corresponds.
[0118] In some circumstances, noise may affect the output of the PPG sensors 172. For example, a noise level experienced by the PPG sensors 172 may increase when the wearable computing device 100 is not securely held to a body part of the user. In another example, a noise level experienced by the PPG sensors 172 may increase due to a low battery condition where the amount of light output by the light source (e.g., LED 172d) is decreased (e.g., a low power mode). When noise is experienced by the PPG sensors 172, the optical readings may be affected by the noise, and the accuracy of the PPG sensors 172 may be reduced.
[0119] FIGS. 10A and 10B illustrate an example estimate of the location of a force applied to the display based on a loss function result in a noisy environment, according to one or more example embodiments of the disclosure. For example, in FIG. 10A, an estimated location of a force applied to the display 182 (lower right comer) is denoted by reference numeral 1010, and is located further away from the ground truth value 1020 compared to the example of FIG. 9A. The location of the force has been calculated or determined by the one or more processors 150 using values output by detectors configured as in the example of FIG. 4C. The Gaussian press response 1030 is also shown in the background to provide additional context. For example, FIG. 10B illustrates a corresponding loss function result 1040 where an outer band 1050 denotes the most likely location of a minimizing result, in which the estimated location 1010 also corresponds.
[0120] In one or more example embodiments, in response to a noise level of the PPG sensors 172 increasing beyond a threshold, the one or more processors 150 may be configured to control the display 182 so that a number of the plurality of selectable functions displayed on the display 182 may be reduced. For example, functions F1-F4 displayed on the
display 182 in FIG. 4A may be reduced to display only functions Fl (on the upper half of the display 182) and F2 (on the lower half of the display 182). Thus, a number of the plurality of selectable functions displayed on the display 182 may be reduced when the noise level of the sensors exceeds a threshold (e.g., reducing icons displayed on the display 182 from ten icons to four icons). Stopping the displaying of one or more of the plurality of selectable functions (i.e., reducing the number of the plurality of selectable functions displayed on the display 182) may enlarge a space on the display 182 for each of the remaining selectable functions to be displayed. Thus, a likelihood that the one or more processors 150 may accurately execute a function that the user intends to select may be increased, even though an accuracy of the detection or determination of the location of the force applied to the display 182 may be reduced due to the noise encountered or experienced by the PPG sensors 172. In addition, by changing (reducing) the number of selectable functions displayed on the display 182 to increase the accuracy of the determination of the location), the noisy condition encountered by the PPG sensors 172 may be masked and go unnoticed by the user, thereby improving the user experience.
[0121] In one or more examples, the wearable computing device 100 may include an accelerometer 174 and/or a gyroscope 176 to detect or sense motion data of the wearable computing device 100. As described herein, the wearable computing device 100 may include PPG sensors 172 which are configured to monitor a heart rate of the user when the user wears the wearable computing device 100.
[0122] Motion of a user’s hand affects arterial pressure and volumetric structure (muscle/tendon), creating a signature dip in reflection/absorption reflected in the PPG signal. The PPG sensors 172 may capture the arterial pressure profiles spatially over a two- dimensional area (e.g., in x and y directions) on the lower side 110b of the housing 110 of the wearable computing device 100. The one or more processors 150 may be configured to identify a gesture of the user based on the one or more optical readings output by the PPG sensors 172, and the one or more processors 150 may be configured to execute a function of the computer wearable device 100 (or another device) based on the gesture of the user identified by the one or more processors 150. The one or more processors 150 may be configured to identify the gesture of the user based on the one or more optical readings output by the PPG sensors 172 together with one or more outputs of the accelerometer 174 and/or the gyroscope 176. The outputs of the accelerometer 174 and/or the gyroscope 176 may additionally or alternatively be used to confirm the validity of the outputs of the PPG sensors
172 that a gesture is being performed by the user.
[0123] In one or more examples, the gesture of the user may include hand gestures including clinching of a fist, a pinching gesture with the fingers, squeezing of a hand, and the like. The gestures may be mapped to respective functions of the wearable computing device (e.g., to make a phone call), or a function of another device (e.g., to operate a home appliance) which may be controllable via the wearable computing device 100 by the identification of the gesture. In one or more examples, the one or more processors 150 may identify a gesture based on the one or more optical readings output by the PPG sensors 172. For example, each gesture may correspond to a respective optical signal output by the PPG sensors 172 so that a gesture may be correctly identified. In an example, optical signals output by the PPG sensors 172 may be analyzed to identify the gesture (e.g., via machine learning algorithms to classify the output optical readings, by comparing the optical signals with known optical signals corresponding to respective gestures, etc.). To more accurately analyze the optical signals, portions of the optical readings which are attributed to a heart rate of the user may be filtered out. For example, a high pass heart rate filtering operation may be performed with respect to the optical readings to notch out the heart rate (arterial pulse), so that the majority of the optical readings which are used to identify the gesture corresponds to or is attributed to, the movement of the user’s hand.
[0124] FIG. 11 illustrates example response signals of various sensors of the wearable computing device to detect a gesture of a user, according to one or more example embodiments of the disclosure. In FIG. 11, when a user makes a pinch gesture at times corresponding to reference characters 1110a, 1110b, and 1110c, a distinctive or significant change in the output signals of the accelerometer 174, gyroscope 176, and PPG sensors 172 occurs. The PPG signals shown in FIG. 11 are obtained after high-pass heart rate filtering which results in a distinctive wavelet-like pattern in the PPG signal.
[0125] For example, in FIG. 11 motion information / data is collected via the accelerometer along three axes (Y-axis 1120a, X-axis 1120b, and Z-axis 1120c). For example, in FIG. 11 motion information / data is collected via the gyroscope along three axes (Y-axis 1130a, X-axis 1130b, and Z-axis 1130c). For example, in FIG. 11 the PPG optical readings includes information / data collected from six channels: PPG channel 1 data 1140a, PPG channel 2 data 1140b, PPG channel 3 data 1140c, channel 4 data 1140d, PPG channel 5 data 1140e, and PPG channel 6 data 1140f. The signals output by the accelerometer 174 and/or gyroscope 176 may be analyzed in conjunction with the signals output by the PPG
sensors 172 to determine the gesture of the user’s hand (e.g., the pinch gesture). However, in some examples only the signals output by the PPG sensors 172 may be used to determine the gesture of the user’s hand. Based on the determination of the gesture, a corresponding function of the wearable computing device 100 and/or of an external device 190 may be performed.
[0126] For example, a plurality of PPG optical readings may be obtained through a multiplexing operation. For example, a plurality of LEDs may also be used to obtain a plurality of optical readings from different combinations of the detectors and the LEDs, to thereby obtain spatial backscatter diversity. For example, in a configuration in which three LEDs and three detectors are included in the PPG sensor 172, in a multiplexing operation in which a first LED is turned on (illuminated), each of the three detectors may receive reflected light and output a respective signal. When a second LED is next turned on, each of the three detectors may receive reflected light and output a respective second signal, and when a third LED is lastly turned on, each of the three detectors may receive reflected light and output a respective third signal. In such a configuration a total of nine PPG optical readings may be obtained to provide a spatial perfusion index profile change for accurate classification of hand states. Also, as discussed above, the signals output by the accelerometer 174 and/or gyroscope 176 may be analyzed in conjunction with the signals output by the PPG sensors 172 to determine the gesture of the user’s hand. However, in some examples only the signals output by the PPG sensors 172 may be used to determine the gesture of the user’s hand.
[0127] FIGS. 12A and 12B depict example one-handed gestures of a user and corresponding heatmaps reconstructed from output optical readings from the PPG sensors, according to one or more example embodiments of the disclosure. In FIG. 12A, when a user makes a first gesture (e.g. by tilting a hand upward) a first heat map 1210 is generated, and in FIG. 12B when a user makes a second gesture (e.g. by tilting a hand downward) a second heat map 1230 is generated. As can be seen by comparing FIG. 12A with a FIG. 12B, a heat signature corresponding to the portion 1220 in FIG. 12A is very different from a heat signature corresponding to the portion 1240 in FIG. 12B. Each gesture may have a unique or identifiable heat map that can be correlated with the output optical readings from the PPG sensors 172, so that the wearable computing device 100 can identify or determine a gesture based on the output optical readings from the PPG sensors 172. The determination of the gesture may be performed using the probability density of a standard Gaussian function which may be used to determine the gesture using measurements obtained from the detectors
172a-172c, which are sparsely provided and distributed, similar to the method described above for determining a location of a touch on a user interface 180 of the wearable computing device 100. Based on the determination of the gesture, a corresponding function of the wearable computing device 100 and/or of an external device 190 may be performed.
[0128] Examples of the disclosure are also directed to computer implemented methods of a wearable computing device. FIGS. 13 and 14 each illustrate a flow diagram of an example, non-limiting computer-implemented method according to one or more example embodiments of the disclosure.
[0129] Referring to FIG. 13, in an example computer implemented method 1300 at operation 1310 one or more processors 150 may receive optical readings (signals) output by PPG sensors 172 when a force is applied to a user interface 180 (e.g., including a display and/or one or more faux buttons 184a, 184b) disposed on an upper side 110a of the housing 110. The PPG sensors 172 are disposed on a lower side 110b of the housing 110 which is disposed opposite to the upper side 110a of the housing 110 (e.g., as shown in FIG. 2 of the drawings). The lower side 110b of the housing 110 may be configured to be in contact with a body part of a user when the wearable computing device 100 is worn by the user. At operation 1320 the method may further include determining, by one or more processors 150 of the wearable computing device 100, a location at which the force is applied to the user interface 180 based on the one or more received optical readings. At operation 1330 the method may further include the one or more processors 150 executing one or more functions of the wearable computing device 100 based on the determined location at which the force is applied to the user interface 180. Example functions of the wearable computing device 100 may include checking health information about the user such as a blood pressure, making and/or receiving a phone call, sending and/or receiving a text message, obtaining a current time, setting a timer, a stopwatch function, controlling an external device 190 such as a home appliance, an electronic device such as a television, and the like.
[0130] Referring to FIG. 14, in an example computer implemented method 1400 at operation 1410 a graphical user interface is displayed on the display 182 indicating to a user to calibrate the wearable computing device 100 by indicating an area of the display 182 to which a force is to be applied to the display 182. For example, the calibration instructions may ask the user whether the user prefers to use an index finger (second area) to provide inputs or a thumb (first area). For example, in addition or alternatively, the calibration instructions may ask the user whether the user is male or female. For example, in addition or
alternatively, the calibration instructions may ask the user whether the user has hands and/or fingers which are larger than a threshold value which may imply that a first area should be set (larger than the threshold value) or a second area should be set (equal to or less than the threshold value). For example, if a user has a ring size greater than ten, a first area setting may be assumed. For example, if a user has a finger length greater than 7.5 inches (measured from the tip of the longest finger to the crease under the palm), a first area setting may be assumed. At operation 1420 the user may provide an input (e.g., via one or more buttons 184c located on a periphery of the wearable computing device 100 as shown in FIG. 1), indicating an area of the force as a first area or a second area.
[0131] When the area of the force indicated by the user corresponds to the first area, the method may include operation 1430, which includes determining an amplitude of each of the one or more optical readings based on a first model having a first scale parameter kl which reflects a first variance of the force to be applied to the display 182. When the area of the force indicated by the user corresponds to a second area, the method may include operation 1450, which is determining the amplitude of each of the one or more optical readings based on a second model having a second scale parameter k2 which reflects a second variance of the force to be applied to the display 182. For example, the first area may be greater than the second area, and the first variance may be greater than the second variance. At each of operations 1440 and 1460, the method may include the one or more processors 150 determining the location at which the force is applied to the display 182 based on a highest amplitude among the amplitudes of the one or more optical readings. The method may also include determining the location at which the force is applied to the display 182 based on an optical reading of a PPG sensor 172 among the PPG sensors 172 having a highest value, among the one or more optical readings received by the one or more processors 150.
[0132] Other operations of the calibration procedure may include asking the user to apply a force to the display 182 at various known (predetermined) points of the display 182, and saving the signals which are output in response to memory 160 as data 162 which may be used as a lookup table for comparing future output signals obtained from PPG sensors 172 and/or for guiding a decision in determining the location of an application of force according to the loss function as described herein.
[0133] Aspects of the above-described example embodiments may be recorded in non- transitory computer-readable media including program instructions to implement various operations embodied by a computer. The media may also include, alone or in combination
with the program instructions, data files, data structures, and the like. Examples of non- transitory computer-readable media include magnetic media such as hard disks, floppy disks, and magnetic tape; optical media such as CD ROM disks, Blue-Ray disks, and DVDs; magneto-optical media such as optical discs; and other hardware devices that are specially configured to store and perform program instructions, such as semiconductor memory, readonly memory (ROM), random access memory (RAM), flash memory, USB memory, and the like. Examples of program instructions include both machine code, such as produced by a compiler, and files containing higher level code that may be executed by the computer using an interpreter. The program instructions may be executed by one or more processors. The described hardware devices may be configured to act as one or more software modules in order to perform the operations of the above-described embodiments, or vice versa. In addition, a non-transitory computer-readable storage medium may be distributed among computer systems connected through a network and computer-readable codes or program instructions may be stored and executed in a decentralized manner. In addition, the non- transitory computer-readable storage media may also be embodied in at least one application specific integrated circuit (ASIC) or Field Programmable Gate Array (FPGA).
[0134] Each block of the flowchart illustrations may represent a unit, module, segment, or portion of code, which comprises one or more executable instructions for implementing the specified logical function(s). It should also be noted that in some alternative implementations, the functions noted in the blocks may occur out of order. For example, two blocks shown in succession may in fact be executed substantially concurrently (simultaneously) or the blocks may sometimes be executed in the reverse order, depending upon the functionality involved.
[0135] While the disclosure has been described with respect to various example embodiments, each example is provided by way of explanation, not limitation of the disclosure. Those skilled in the art, upon attaining an understanding of the foregoing, can readily produce alterations to, variations of, and equivalents to such embodiments. Accordingly, the disclosure does not preclude inclusion of such modifications, variations and/or additions to the disclosed subject matter as would be readily apparent to one of ordinary skill in the art. For example, features illustrated or described as part of one embodiment can be used with another embodiment to yield a still further embodiment. Thus, it is intended that the disclosure covers such alterations, variations, and equivalents.
Claims
1. A wearable computing device, comprising: a housing including an upper side and a lower side, wherein the lower side of the housing is opposite to the upper side of the housing and is configured to be in contact with a body part of a user when the wearable computing device is worn by the user; a user interface disposed on the upper side of the housing; sensors, disposed on the lower side of the housing, configured to output one or more optical readings when a force is applied to the user interface; and one or more processors configured to determine a location at which the force is applied to the user interface based on the one or more optical readings output by the sensors.
2. The wearable computing device according to claim 1, wherein the sensors include photoplethysmography (PPG) sensors configured to monitor a heart rate of the user when the wearable computing device is worn by the user, and the PPG sensors include one or more light-emitting diodes and a plurality of detectors.
3. The wearable computing device according to claim 1, wherein the sensors include at least three photoplethysmography (PPG) sensors, and at least one PPG sensor of the at least three PPG sensors is spaced apart from another PPG sensor of the at least three PPG sensors in a first direction and a second direction.
4. The wearable computing device according to claim 1, wherein the one or more processors are configured to execute one or more functions of the wearable computing device based on the location at which the force is applied to the user interface as determined by the one or more processors.
5. The wearable computing device according to claim 1, wherein the one or more processors are configured to determine the location at which the force is applied to the user interface based on whether an area of the user interface to which the force is applied corresponds to a first area or a second area, the first area being different from the second area.
6. The wearable computing device according to claim 5, wherein:
when the area of the user interface to which the force is applied corresponds to the first area, the one or more processors are configured to determine an amplitude of each of the one or more optical readings based on a first model having a first scale parameter which reflects a first variance of the force applied to the user interface, and when the area of the user interface to which the force is applied corresponds to the second area, the one or more processors are configured to determine the amplitude of each of the one or more optical readings based on a second model having a second scale parameter which reflects a second variance of the force applied to the user interface, the second variance being different from the first variance.
7. The wearable computing device according to claim 6, wherein the one or more processors are configured to determine the location at which the force is applied to the user interface based on a value of each of the one or more optical readings output by the sensors and by applying a loss function to minimize a difference between an actual location at which the force is applied and an estimated location at which the force is applied.
8. The wearable computing device according to claim 7, wherein the one or more processors are configured to apply the loss function by performing a two-dimensional grid search method or a gradient descent search method.
9. The wearable computing device according to claim 1, wherein the user interface includes a non-touch sensitive display configured to display a plurality of elements corresponding to a plurality of selectable functions of the wearable computing device, in response to a noise level of the sensors increasing beyond a threshold, the one or more processors are configured to control the non-touch sensitive display to stop displaying of one or more of the plurality of elements, and in response to determining the location at which the force is applied to the non-touch sensitive display corresponds to a remaining first element of the plurality of elements displayed on the non-touch sensitive display, the one or more processors are further configured to execute a first selectable function of the plurality of selectable functions which corresponds to the remaining first element, based on the determined location.
10. The wearable computing device according to claim 1, wherein the user interface includes a plurality of faux buttons which respectively correspond to a plurality of selectable functions of the wearable computing device, and in response to determining the location at which the force is applied to a first faux button of the plurality of faux buttons of the user interface, the one or more processors are configured to execute a first selectable function of the plurality of selectable functions which corresponds to the first faux button, based on the determined location.
11. The wearable computing device according to claim 1, wherein the user interface includes a non-touch sensitive display.
12. The wearable computing device according to claim 1, wherein the sensors include photoplethysmography (PPG) sensors configured to monitor a heart rate of the user when the wearable computing device is worn by the user, the one or more processors are configured to identify a gesture of the user based on the one or more optical readings output by the PPG sensors, and the one or more processors are configured to execute a function of the computer wearable device based on the gesture of the user identified by the one or more processors.
13. The wearable computing device according to claim 12, further comprising: at least one of an accelerometer or a gyroscope, wherein the one or more processors are configured to identify the gesture of the user based on the one or more optical readings output by the PPG sensors and one or more outputs of the at least one of the accelerometer or the gyroscope.
14. A computer-implemented method, comprising: receiving one or more optical readings output by sensors disposed on a lower side of a housing of a wearable computing device, when a force is applied to a user interface disposed on an upper side of the housing, wherein the lower side of the housing is opposite to the upper side of the housing and is configured to be in contact with a body part of a user when the wearable computing device is worn by the user; and
determining, by one or more processors of the wearable computing device, a location at which the force is applied to the user interface based on the one or more received optical readings output by the sensors.
15. The computer-implemented method of claim 14, further comprising: executing one or more functions of the wearable computing device based on the location at which the force is applied to the user interface as determined by the one or more processors.
16. The computer-implemented method of claim 14, further comprising: displaying on a display of the user interface instructions indicating to a user to calibrate the wearable computing device by indicating an area of the display to which the force is to be applied to the display.
17. The computer-implemented method of claim 16, further comprising: when the area of the force indicated by the user corresponds to a first area, determining an amplitude of each of the one or more optical readings based on a first model having a first scale parameter which reflects a first variance of the force to be applied to the display, and when the area of the force indicated by the user corresponds to a second area, determining the amplitude of each of the one or more optical readings based on a second model having a second scale parameter which reflects a second variance of the force to be applied to the display, the first area being greater than the second area, and the first variance being greater than the second variance.
18. The computer-implemented method of claim 14, further comprising determining the location at which the force is applied to the user interface based on a value of each of the one or more optical readings output by the sensors and by applying a loss function to minimize a difference between an actual location at which the force is applied and an estimated location at which the force is applied.
19. The computer-implemented method of claim 14, further comprising: displaying, on a non-touch sensitive display of the user interface, a plurality of elements corresponding to a plurality of selectable functions of the wearable computing device; in response to a noise level of the sensors increasing beyond a threshold, controlling the display to stop the display of one or more of the plurality of elements; and in response to determining the location at which the force is applied to the user interface corresponds to a remaining first element of the plurality of elements displayed on the display, executing a first selectable function of the plurality of selectable functions which corresponds to the remaining first element, based on the determined location.
20. A non-transitory computer-readable medium which stores instructions that are executable by one or more processors of a wearable computing device, the instructions comprising: instructions to cause the one or more processors to receive one or more optical readings output by sensors disposed on a lower side of a housing of the wearable computing device, when a force is applied to a user interface disposed on an upper side of the housing, wherein the lower side of the housing is opposite to the upper side of the housing and configured to be in contact with a body part of a user when the wearable computing device is worn by the user; and instructions to cause the one or more processors to determine a location at which the force is applied to the user interface based on the one or more received optical readings.
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/US2022/025198 WO2023204795A1 (en) | 2022-04-18 | 2022-04-18 | Wearable computing device having optical sensors to indirectly determine a location of a force applied to a user interface |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/US2022/025198 WO2023204795A1 (en) | 2022-04-18 | 2022-04-18 | Wearable computing device having optical sensors to indirectly determine a location of a force applied to a user interface |
Publications (1)
Publication Number | Publication Date |
---|---|
WO2023204795A1 true WO2023204795A1 (en) | 2023-10-26 |
Family
ID=81850424
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
PCT/US2022/025198 WO2023204795A1 (en) | 2022-04-18 | 2022-04-18 | Wearable computing device having optical sensors to indirectly determine a location of a force applied to a user interface |
Country Status (1)
Country | Link |
---|---|
WO (1) | WO2023204795A1 (en) |
Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20140275852A1 (en) * | 2012-06-22 | 2014-09-18 | Fitbit, Inc. | Wearable heart rate monitor |
US20170251935A1 (en) * | 2016-03-07 | 2017-09-07 | Fitbit, Inc. | Blood pressure sensors |
US20200113442A1 (en) * | 2018-10-12 | 2020-04-16 | ViviPulse, LLC | Blood pressure measuring device and method |
US20200245900A1 (en) * | 2016-12-29 | 2020-08-06 | BioMech Sensor LLC | Systems and methods for real-time data quantification, acquisition, analysis, and feedback |
US10874348B1 (en) * | 2015-09-30 | 2020-12-29 | Apple Inc. | Force sensing for PPG heart-rate performance enhancement and contact detection |
US20210330261A1 (en) * | 2020-04-23 | 2021-10-28 | Samsung Electronics Co., Ltd. | Sensor array and device |
-
2022
- 2022-04-18 WO PCT/US2022/025198 patent/WO2023204795A1/en unknown
Patent Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20140275852A1 (en) * | 2012-06-22 | 2014-09-18 | Fitbit, Inc. | Wearable heart rate monitor |
US10874348B1 (en) * | 2015-09-30 | 2020-12-29 | Apple Inc. | Force sensing for PPG heart-rate performance enhancement and contact detection |
US20170251935A1 (en) * | 2016-03-07 | 2017-09-07 | Fitbit, Inc. | Blood pressure sensors |
US20200245900A1 (en) * | 2016-12-29 | 2020-08-06 | BioMech Sensor LLC | Systems and methods for real-time data quantification, acquisition, analysis, and feedback |
US20200113442A1 (en) * | 2018-10-12 | 2020-04-16 | ViviPulse, LLC | Blood pressure measuring device and method |
US20210330261A1 (en) * | 2020-04-23 | 2021-10-28 | Samsung Electronics Co., Ltd. | Sensor array and device |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
DK180839B1 (en) | CONCENTRIC CONSTRUCTION FOR OPTICAL REGISTRATION | |
US9510779B2 (en) | Analyte monitoring using one or more accelerometers | |
US10390730B1 (en) | Methods, systems, and devices for determining a respiration rate | |
CN109984727B (en) | Biological component measuring device and biological component measuring method | |
KR102249824B1 (en) | Apparatus and Method for sensing body imformation thereof | |
CN105579929B (en) | Human-computer interaction based on gesture | |
EP2434945B1 (en) | Multiuse optical sensor | |
US8988372B2 (en) | Obtaining physiological measurements using a portable device | |
US10874348B1 (en) | Force sensing for PPG heart-rate performance enhancement and contact detection | |
US10335087B2 (en) | Biosignal processing apparatus and biosignal processing method | |
US11627887B2 (en) | PPG sensor having light arrival angle control at detector | |
WO2017053049A1 (en) | System and method for obtaining vital measurements using a mobile device | |
WO2015041717A1 (en) | Contact lens with integrated pulse oximeter | |
JP2017507406A (en) | Apparatus and method for operating with reduced sensitivity in a touch sensing device | |
CN111528820A (en) | Apparatus for estimating biological information | |
CN113613557A (en) | Physiological monitoring system for measuring blood oxygen concentration | |
CN111954488A (en) | Cardiovascular health monitoring device | |
WO2023204795A1 (en) | Wearable computing device having optical sensors to indirectly determine a location of a force applied to a user interface | |
US20220273207A1 (en) | System and method for robust pulse oximetry | |
AU2020100281A4 (en) | Concentric architecture for optical sensing | |
CN116098579A (en) | Electronic device and method for estimating biological information using the same | |
TWM501597U (en) | Mouse for detecting physiological feature | |
KR20200074571A (en) | Photoplethysmography sensor, electronic apparatus including the same and method for controlling the electronic apparatus | |
JP7419563B2 (en) | Touch control for wearable devices | |
US20230007884A1 (en) | Apparatus and method for estimating bio-information |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
121 | Ep: the epo has been informed by wipo that ep was designated in this application |
Ref document number: 22725954Country of ref document: EPKind code of ref document: A1 |