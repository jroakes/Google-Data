US8612990B1 - Prioritized rate scheduler for a storage system - Google Patents
Prioritized rate scheduler for a storage system Download PDFInfo
- Publication number
- US8612990B1 US8612990B1 US13/280,883 US201113280883A US8612990B1 US 8612990 B1 US8612990 B1 US 8612990B1 US 201113280883 A US201113280883 A US 201113280883A US 8612990 B1 US8612990 B1 US 8612990B1
- Authority
- US
- United States
- Prior art keywords
- usage
- particular user
- operations
- users
- maximum allowed
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/06—Digital input from, or digital output to, record carriers, e.g. RAID, emulated record carriers or networked record carriers
- G06F3/0601—Interfaces specially adapted for storage systems
- G06F3/0628—Interfaces specially adapted for storage systems making use of a particular technique
- G06F3/0653—Monitoring storage devices or systems
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/46—Multiprogramming arrangements
- G06F9/50—Allocation of resources, e.g. of the central processing unit [CPU]
- G06F9/5005—Allocation of resources, e.g. of the central processing unit [CPU] to service a request
- G06F9/5011—Allocation of resources, e.g. of the central processing unit [CPU] to service a request the resources being hardware resources other than CPUs, Servers and Terminals
- G06F9/5016—Allocation of resources, e.g. of the central processing unit [CPU] to service a request the resources being hardware resources other than CPUs, Servers and Terminals the resource being the memory
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/06—Digital input from, or digital output to, record carriers, e.g. RAID, emulated record carriers or networked record carriers
- G06F3/0601—Interfaces specially adapted for storage systems
- G06F3/0602—Interfaces specially adapted for storage systems specifically adapted to achieve a particular effect
- G06F3/061—Improving I/O performance
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/06—Digital input from, or digital output to, record carriers, e.g. RAID, emulated record carriers or networked record carriers
- G06F3/0601—Interfaces specially adapted for storage systems
- G06F3/0628—Interfaces specially adapted for storage systems making use of a particular technique
- G06F3/0629—Configuration or reconfiguration of storage systems
- G06F3/0635—Configuration or reconfiguration of storage systems by changing the path, e.g. traffic rerouting, path reconfiguration
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/06—Digital input from, or digital output to, record carriers, e.g. RAID, emulated record carriers or networked record carriers
- G06F3/0601—Interfaces specially adapted for storage systems
- G06F3/0628—Interfaces specially adapted for storage systems making use of a particular technique
- G06F3/0655—Vertical data movement, i.e. input-output transfer; data movement between one or more hosts and one or more storage devices
- G06F3/0659—Command handling arrangements, e.g. command buffers, queues, command scheduling
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/06—Digital input from, or digital output to, record carriers, e.g. RAID, emulated record carriers or networked record carriers
- G06F3/0601—Interfaces specially adapted for storage systems
- G06F3/0668—Interfaces specially adapted for storage systems adopting a particular infrastructure
- G06F3/067—Distributed or networked storage systems, e.g. storage area networks [SAN], network attached storage [NAS]
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/06—Digital input from, or digital output to, record carriers, e.g. RAID, emulated record carriers or networked record carriers
- G06F3/0601—Interfaces specially adapted for storage systems
- G06F3/0668—Interfaces specially adapted for storage systems adopting a particular infrastructure
- G06F3/0671—In-line storage system
- G06F3/0683—Plurality of storage devices
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F2206/00—Indexing scheme related to dedicated interfaces for computers
- G06F2206/10—Indexing scheme related to storage interfaces for computers, indexing schema related to group G06F3/06
- G06F2206/1012—Load balancing
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F2209/00—Indexing scheme relating to G06F9/00
- G06F2209/50—Indexing scheme relating to G06F9/50
- G06F2209/5021—Priority
Definitions
- Certain computing applications may access data provided by a distributed storage system made up of numerous storage devices or clusters of storage devices.
- a particular storage system may include hundreds or thousands of storage devices that may be accessed by a number of client applications or users.
- the storage system may perform constant monitoring and error detection to obtain fault tolerant operation.
- a computing device implemented method may include receiving, by the device, operations for a storage device, from a number of users associated with priorities; monitoring, by the computing device, usage levels of the storage device, for the users; determining, by the computing device, scores for a particular user, based on the usage level of the particular user, a target usage level for the particular user that defines an allotted usage level of the storage device and for the particular user, a maximum allowed usage level for the particular user, and a priority of the particular user.
- the method may further include selecting one of the received operations, based on the scores; and transmitting the selected one of the received operations, to the storage device.
- a storage system may include a set of storage devices and a controller to arbitrate among operations for execution by the set of storage devices, where the operations are received from users that are associated with priority levels.
- the controller may include: a number of queues, corresponding to the users, to queue operations from the users; a scoring component to maintain a score for each queue of the queues, where the score is calculated based on usage of storage devices in the set of storage devices by a particular user of the users, a target usage level for the particular user that defines an allotted usage level of the set of storage devices by the particular user, a maximum allowed usage level for the particular user, and the priority level for the particular user.
- the controller may also include an arbitrator to choose, from the queues and based on the score of each queue, one of the operations to service.
- the storage system may further include a management device, coupled to the controller.
- the management device may receive usage updates, from the controller, reflecting usage of the set of storage devices, by the users.
- the management device may further calculate maximum allowed usage levels, for the users, based on the received usage updates, and transmit the calculated maximum usage levels to the controller.
- a device may include at least one storage interface to connect to storage devices; one or more network interfaces to receive operations, from a number of users, for access to the storage devices, where each of the users is associated with a priority level; and at least one processor.
- the processor operate to: maintain a number of queues, associated with the users, to store the received operations; monitor usage levels, of the storage devices, by the users; determine scores for the users, each score being based on a usage level of a particular user, a target usage level for the particular user that defines an allotted amount of storage device usage for the particular user, a maximum allowed usage level for the particular user, and a priority level of the particular user; and select one of the received operations, stored in the queues, based on the scores, where the selected one of the received operations is granted access to the corresponding one or more of the storage devices.
- FIG. 1 is a diagram conceptually illustrating the operation of an example storage system
- FIG. 2 is a block diagram of an example storage system
- FIG. 3 shows an example of a generic computing device which may be used with the techniques described herein;
- FIG. 4 is a diagram of example functional components of one of the storage controllers shown in FIG. 2 ;
- FIG. 5 is a flow chart of an example process for performing priority scheduling
- FIG. 6 is a flow chart of an example of another process for performing priority scheduling.
- FIGS. 7 and 8 are diagrams illustrating examples of the operation of a prioritized rate scheduler.
- FIG. 1 is a diagram conceptually illustrating the operation of an example storage system.
- a single storage controller 110 controls three disk drives 120 .
- Disk drives 120 are illustrated as being accessed by two users 130 .
- Users 130 may, for example, transmit storage write requests or read requests to storage controller 110 , which may forward the requests to the appropriate one of disk drives 120 .
- a particular disk drive 120 may be only able to handle a single access request, such as a read request or a write request, at a time.
- An access request will be generally referred to herein as an operation.
- the number of operations could potentially overwhelm the disk drive 120 and/or cause the operations of one of users 130 to be blocked by the operations of the other one of users 130 .
- storage controller 110 may arbitrate between operations. The arbitration may include storing incoming requests in queues 150 , each of which may be associated with a particular user 130 and scheduling operations, from the queues 150 and for a disk drive 120 , in a particular order.
- the particular order may be based on a usage quota (TARGET USAGE) assigned to each user, and a maximum allowed usage level (MAX ALLOWED USAGE) assigned to each user, and a priority level (PRIORITY) assigned to each user.
- TARGET USAGE a usage quota assigned to each user
- MAX ALLOWED USAGE a maximum allowed usage level assigned to each user
- PRIORITY a priority level assigned to each user.
- These values may be received from a management device 140 .
- Management device 140 may calculate these values based on usage information (i.e., information quantifying how much a particular user has, in the recent past, accessed one or more of disk drives 120 ) that is transmitted from storage controller 110 to management device 140 .
- the scheduling technique discussed herein may be particularly suited to operations from non-coordinated users, in which different users may be associated with different priorities and in which it may be desirable to assign different target usage quotas for different users (e.g., a first user may be allocated 10% of the total disk throughput of the storage system while another may be allocated 5%).
- the scheduling technique may provide fair access to different users while allowing operation bursts at the local storage device level.
- the terms “users” or “clients,” as used herein, may refer to entities that generate operations, such as read or write requests, that are to be serviced by storage devices.
- the entity that generates the operations may include a particular application or application type.
- a server-based email application may be considered to be a single user for the purpose of the storage system.
- the email application may provide email services to accounts (e.g., millions of human users), the email application may be considered to be a single user by the storage system.
- there may be a relatively small number of users where each user may refer to a particular application or service, such as an email service, a web indexing service, etc.
- a user or client may refer to each individual that accesses the storage system.
- FIG. 2 is a diagram of an example storage system 200 .
- Storage system 200 may generally implement a distributed storage system in which data may be written and/or read.
- Storage system 200 may include a load balancer 220 , storage controllers 230 - 1 through 230 -N (N ⁇ 1) (referred to collectively as “storage controllers 230 ” or individually as “storage controller 230 ”), a management device 240 , and one or more storage devices connected to each storage controller.
- the storage devices are illustrated as storage devices 250 - 1 through 250 -J (J ⁇ 1) (referred to collectively as “storage devices 250 ” or individually as “storage devices 250 ”), which may connect to and be controlled by storage controller 230 - 1 , and storage devices 255 - 1 through 255 -K (K ⁇ 1) (referred to collectively as “storage devices 255 ” or individually as “storage device 255 ”), which may connect to and be controlled by storage controller 230 -N.
- Load balancer 220 may receive operations from a number of users. The operations may include read requests and/or write requests for data. In some situations, such as for a write operation, load balancer 220 may balance the received operations over storage devices 250 / 255 , such as by randomly selecting a storage device 250 / 255 to handle the operation. In other situations, such as for a read operation, the particular storage device to handle the operation may be included as part of the operation or looked-up by load balancer 220 (or another device). In either situation, load balancer 220 may forward the received operations to the corresponding one or more storage controllers 230 , which may schedule the operations for delivery to storage devices 250 / 255 .
- load balancer 220 may be omitted or may be bypassed for certain operations.
- the user issuing the read operation may know the storage devices 250 / 255 and/or storage controller 230 to which the read operation should be directed and may thus issue the read operation directly to the appropriate storage controller 250 .
- Write operations may similarly be issued directly to a storage controller 230 and/or storage device 250 / 255 .
- the user may be told that the next 8 MB (or another quantity) of write operations are to be issued to particular storage device 250 / 255 or storage controller 250 .
- Storage controllers 230 may include computing devices to receive the operations from load balancer 220 . As will be described in more detail below, storage controllers 230 may maintain queues corresponding to each user, priority level, and/or storage device, and use the queues to prioritize the scheduling of operations to the appropriate storage devices 250 / 255 . In one implementation, each queue may correspond to operations for a particular storage device, from a particular user, and having a particular priority level. A storage controller 230 may calculate a score for each queue, and choose operations from the queues based on the scores. In this manner, storage controller 230 may act as a prioritized rate scheduler that determines the order in which operations, received for a particular storage device, are sent to that storage device.
- Management device 240 may include one or more computing devices that provide a global level of control over storage controllers 230 .
- Management device 240 may transmit parameters relating prioritized rate scheduling to storage controllers 230 .
- the parameters may be calculated based on information received from storage controllers 230 .
- storage controllers 230 may periodically send usage information to management device 240 , where the usage information quantifies how much of each of storage devices 250 / 255 was accessed by each user or each queue.
- the usage information may be transmitted, by storage controllers 230 , at periodic intervals (e.g., every 10 seconds usage update messages may be sent to management device 240 ).
- storage controller 230 may send information when requested.
- management device 240 may calculate the parameters relating to prioritized rate scheduling (as performed by storage controllers 230 ).
- multiple management devices 240 may collaborate in determining the global parameters.
- the parameters may include, for example, a maximum allowed usage level for a user or queue and a target usage level for the user or queue.
- Other parameters such as the priority level assigned to each user may, at certain times (e.g., during system initialization), also be transmitted by the management device 230 to the storage controllers 230 .
- Storage devices 250 / 255 may include any type of storage device, such as a hard disk drive, flash drive, writeable optical drive, dynamic random access memory (DRAM), other volatile storage, etc.
- a number of storage devices 250 / 255 may be coupled to each storage controller 230 .
- storage devices 250 / 255 may include commodity storage devices, such as hard disk drives designed for consumer use.
- FIG. 2 shows example components of storage system 200
- storage system 200 may contain fewer components, different components, differently arranged components, and/or additional components than those depicted in FIG. 2 .
- one or more components of storage system 200 may perform one or more other tasks described as being performed by one or more other components of storage system 200 .
- load balancer 220 is illustrated as being directly connected to storage controllers 230 and storage controllers 230 are illustrated as being directly connected to storage devices 250 / 255 .
- one or more networks such as local Ethernet networks, fiber channel, or InfiniBand networks may be used to connect these devices.
- FIG. 3 shows an example of a generic computing device 300 , which may be used with the techniques described herein.
- Computing device 300 may correspond to, for example, load balancer 220 , storage controllers 230 , and/or management device 240 .
- Each of load balancers 220 , storage controllers 230 , and/or management devices 240 may include one or more computing devices 300 .
- Computing device 300 is intended to represent various forms of digital computers, such as laptops, desktops, workstations, personal digital assistants, servers, blade servers, mainframes, and other appropriate computers.
- the components shown here, their connections and relationships, and their functions, are meant to be examples only, and are not meant to limit implementations described and/or claimed in this document.
- Computing device 300 may include a processor 302 , memory 304 , a storage device 306 , a high-speed interface 308 connecting to memory 304 and high-speed expansion ports 310 , and a low speed interface 312 connecting to low speed bus 314 and storage device 306 .
- Each of the components 302 , 304 , 306 , 308 , 310 , and 312 may be interconnected using various busses, and may be mounted on a common motherboard or in other manners as appropriate.
- Processor 302 may process instructions for execution within computing device 300 , including instructions stored in the memory 304 or on storage device 306 to display graphical information for a graphical user interface (GUI) on an external input/output device, such as display 316 coupled to high speed interface 308 .
- GUI graphical user interface
- multiple processors and/or multiple buses may be used, as appropriate, along with multiple memories and types of memory.
- multiple computing devices 300 may be connected, with each device providing portions of the necessary operations (e.g., as a server bank, a group of blade servers, or a multi-processor system, etc.).
- Memory 304 may store information within computing device 300 .
- memory 304 may include a volatile memory unit or units.
- memory 304 may include a non-volatile memory unit or units.
- Memory 304 may also be another form of computer-readable medium, such as a magnetic or optical disk.
- a computer-readable medium may be defined as a non-transitory memory device.
- a memory device may include memory space within a single physical memory device or spread across multiple physical memory devices.
- Storage device 306 may provide mass storage for computing device 300 .
- storage device 306 may include a computer-readable medium, such as a floppy disk device, a hard disk device, an optical disk device, or a tape device, a flash memory or other similar solid state memory device, or an array of devices, including devices in a storage area network or other configurations.
- a computer program product may be tangibly embodied in an information carrier.
- the computer program product may also contain instructions that, when executed, perform one or more methods, such as those described below.
- the information carrier may include a computer or machine-readable medium, such as memory 304 , storage device 306 , or memory included within processor 302 .
- High speed controller 308 may manage bandwidth-intensive operations for computing device 300 , while low speed controller 312 may manage lower bandwidth-intensive operations. Such allocation of functions is an example only.
- high-speed controller 308 may be coupled to memory 304 , display 316 (e.g., through a graphics processor or accelerator), and to high-speed expansion ports 310 , which may accept various expansion cards (not shown).
- low-speed controller 312 may be coupled to storage device 306 and to low-speed expansion port 314 .
- Low-speed expansion port 314 which may include various communication ports (e.g., USB, Bluetooth, Ethernet, wireless Ethernet) may be coupled to one or more input/output devices, such as a keyboard, a pointing device, a scanner, or a networking device, such as a switch or router, e.g., through a network adapter.
- input/output devices such as a keyboard, a pointing device, a scanner, or a networking device, such as a switch or router, e.g., through a network adapter.
- Computing device 300 may be implemented in a number of different forms, as shown in FIG. 3 . For example, it may be implemented as a standard server 320 , or multiple times in a group of such servers. It may also be implemented as part of a rack server system 324 . Additionally or alternatively, computing device 300 may be implemented in a personal computer, such as a laptop computer 322 .
- implementations of the systems and techniques described herein may be realized in digital electronic circuitry, integrated circuitry, specially designed ASICs (application specific integrated circuits), computer hardware, firmware, software, and/or combinations thereof.
- ASICs application specific integrated circuits
- These various implementations may include implementation in one or more computer programs that are executable and/or interpretable on a programmable system including at least one programmable processor, which may be special or general purpose, coupled to receive data and instructions from, and to transmit data and instructions to, a storage system, at least one input device, and at least one output device.
- the systems and techniques described herein may be implemented on a computer having a display device (e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor) for displaying information to the user and a keyboard and a pointing device (e.g., a mouse or a trackball) by which the user can provide input to the computer.
- a display device e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor
- a keyboard and a pointing device e.g., a mouse or a trackball
- Other kinds of devices may be used to provide for interaction with a user as well; for example, feedback provided to the user may be any form of sensory feedback (e.g., visual feedback, auditory feedback, or tactile feedback); and input from the user may be received in any form, including acoustic, speech, or tactile input.
- the systems and techniques described herein may be implemented in a computing system that includes a back end component (e.g., as a data server), or that includes a middleware component (e.g., an application server), or that includes a front end component (e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the systems and techniques described here), or any combination of such back end, middleware, or front end components.
- the components of the system may be interconnected by any form or medium of digital data communication (e.g., a communication network). Examples of communication networks include a local area network (“LAN”), a wide area network (“WAN”), and the Internet.
- LAN local area network
- WAN wide area network
- the Internet the global information network
- computing device 300 may include fewer components, different components, additional components, or differently arranged components than depicted in FIG. 3 . Additionally or alternatively, one or more components of computing device 300 may perform one or more tasks described as being performed by one or more other components of computing device 300 .
- FIG. 4 is a diagram of example functional components of one of storage controllers 230 .
- Storage controller 230 may include storage device controller(s) 410 , usage monitor 420 , and priority rate scheduler 430 .
- Each of storage device controller(s) 410 , usage monitor 420 , and priority rate scheduler 430 may be implemented using one or more of the components of computing device 300 , illustrated in FIG. 3 .
- Storage device controller 410 may provide an interface to storage devices 250 .
- Storage device controller 410 may receive read and/or write commands from priority rate scheduler 430 , convert the commands into signals appropriate for the interface provided by storage devices 250 , and transmit the signals to storage device 250 .
- Storage device controller 410 may be designed based on the specific protocol implemented by storage devices 250 , such as SATA (serial advanced technology attachment), SCSI (small computer system interface), or IDE (Integrated Drive Electronics).
- Usage monitor 420 may monitor or record usage of storage devices 250 . Usage monitor 420 may transmit the monitored usage information to management device 240 , such as by periodically (e.g., every 10 seconds) transmitting messages quantifying the usage of storage devices 250 . Alternatively, usage monitor 420 may transmit the monitored usage information to management device 240 in response to polling requests from management device 240 . Usage of storage devices 250 may be represented, for example, as the amount of time that a particular user, of a particular priority level or set of priority levels, uses a particular storage device 250 . For example, usage monitor 420 may calculate, over a sliding window (e.g., a sliding ten second window), the amount of storage device time that was attributable to a particular queue. Other indications of “usage” of a storage device 250 may alternatively be used, such as the portion (percentage) of the window attributable to a user or queue, the bandwidth written or read by a user or queue, or other measurement indications.
- a sliding window e.g.,
- Priority rate scheduler 430 may generally operate to schedule the order of delivery of operations to storage devices 250 .
- Priority rate scheduler 430 may, for example, delay an operation from a low priority user until operations from a high priority user have been handled by a storage device 250 .
- Priority rate scheduler 430 may include queues 432 , arbitrator component 434 , and score calculation component 436 .
- Queues 432 may include a number of buffers (e.g., first-in-first-out (FIFO) queues).
- queues 432 may be implemented on a per-user, per-priority, and per-storage device basis. That is, priority rate scheduler 430 may maintain a separate queue for each combination of a user, priority, and storage device.
- Incoming operations, received from load balancer 220 may be input to the appropriate one of queues 432 .
- Arbitrator component 434 may operate to selectively remove operations from queues 432 and forward the operations to storage device controller 410 , whenever a storage device 250 is available (i.e., can handle a new operation) and at least one queue 432 , corresponding to the available storage device, contains operations.
- Arbitrator component 434 may determine which queue 432 to select based on a score calculated for each queue 432 . For example, arbitrator component 434 may select the queue having a lowest score.
- arbitrator component 434 may select queues and/or operations based on factors other than selecting the queue having the lowest score. For example, for a system in which storage devices 250 / 255 include disk drives, arbitrator component 434 may additionally take into account the head location of the disk drives, as it is desirable to minimize the head movement of a disk drive to increase throughput. For instance, arbitrator component 434 may select the queue having a score that is within a certain threshold value of the lowest score and that minimizes disk head movement.
- the scores for queues 432 may be maintained by score calculation component 436 .
- Score calculation component 436 may calculate the scores for queues 432 based on parameters received from management device 240 and based on usage information determined by usage monitor 420 .
- a user such as an application
- an application may need to perform certain operations as quickly as possible, such as through high priority operations, while other operations may not be as time sensitive and may be performed using lower priority operations.
- the priority, p may be defined where 0 ⁇ p ⁇ 1, where one represents the highest priority and zero represents the lowest priority;
- disks or number_disks is the total number of storage devices 250 / 255 (e.g., hard disks) in storage system 200 ;
- quota p (u) represents the number of storage devices that have been purchased or assigned to a user, u, at priority, p.
- the user's target share of storage system 100 for priority p, may be expressed as TS p (u), where
- TS p ⁇ ( u ) ⁇ q ⁇ p ⁇ quota q ⁇ ( u ) number_disks .
- Eq . ⁇ 1 ) TS p (u) (or quota p (u)) may be received by storage controller 230 from management device 240 .
- Management device 240 may receive TS p (u) (or quota p (u)) from an administrator of storage system 200 .
- management device 240 may update TS p (u) during operation of storage system 100 , such as in response to a change in the number of storage devices 250 / 255 that are included in system 100 , updated information from an administrator, or other information.
- ⁇ p (u) may represent the average portion of the storage device that is used for user, u, at priority, p, and ⁇ p (u) may represent the standard deviation of the portion of the storage device that is used for user, u, at priority, p.
- LD p (u) may represent the average portion of the storage device that is used for user, u, at priority, p
- ⁇ p (u) may represent the standard deviation of the portion of the storage device that is used for user, u, at priority, p.
- other calculations for LD p (u), that allow LD p (u) to go over TS p (u) are additionally possible.
- U p (u) may represent the recent local disk usage at this priority, p, and higher.
- the score for user, u, at priority, p may be defined to be:
- k may be chosen as a constant such that S p (u) ⁇ S q (v) when p>q for all users u and v.
- the score, S p (u) for a higher priority operation may, thus, always be less than the score for a lower priority operation.
- Score calculation component 436 may calculate scores corresponding to each of queues 432 .
- Arbitrator component 434 may select queued operations, corresponding to a storage device 250 , as the next operation having the lowest score. In some implementations, if a user's score, S p (u), is the lowest score, but the user has queued operations at different priorities, arbitrator component 434 may select the operations across the multiple queues of the user using a weighted picking scheme to avoid the situation in which low priority operations may be starved. Weighted picking is described in more detail below.
- LD p (u) by providing a maximum allowed usage threshold that may be greater than TS p (u), may allow temporary access bursts at a storage device 250 .
- the ⁇ p (u) and ⁇ p (u) values, which are used to calculate LD p (u) may be calculated as the average and standard deviation of U p (u).
- certain priority levels may not be given a target quota (i.e., TS p (u) may be set to ⁇ for the highest priority levels).
- LD p (u) may not need to be calculated for priority levels that are not assigned a target quota.
- LD p (u) may be set to TS p (u).
- a less drastic enforcement mechanism may be used in which it may be possible to bring the user into compliance with a smaller modification to LD p (u).
- TS p (u) may then be set to r j , where j is the largest value such that f(j) ⁇ TS p (u)*#disks.
- additional assumptions about the shape of the user's distribution may allow for a more efficient computation of LD p (u).
- FIG. 5 is a flow chart of an example process 500 for performing priority scheduling.
- Process 500 may be performed, for example, by management device 240 .
- some or all of process 500 may be performed by one or more devices separate from, or in combination with management device 240 .
- some or all of processes 500 may be performed by storage controller 230 .
- Process 500 may include receiving initial parameters relating to the priority scheduling, such as an identification of the authorized users of storage system 200 , the target usage levels of the users, and the priority levels of the users (block 510 ).
- the initial parameters may be parameters determined by a system administrator or another entity.
- the user “mail_system” may refer to an email application that includes processes that may perform storage operations at different priority levels.
- the user “research” may refer to a user account given to researchers that tend to perform operations that are not time critical.
- the user “search_service” may correspond to a search application, such as a web search application.
- the user “misc_apps” may correspond to one or more other applications that are given access to storage system 200 .
- the priority level, p is segmented into three distinct levels: low latency, batch, and best effort.
- the low latency priority level may refer to the highest priority level.
- the priority level “batch” may refer to a priority level below low latency.
- the target usage levels which may correspond to TS(u), are provided as a percent of system usage. For example, the user “research” may be allocated 5% of the capacity of storage system 200 .
- Process 500 may further include receiving usage information from storage controllers 230 (block 520 ).
- the usage information may correspond to the previously discussed values usage p (u).
- the usage information may be generated periodically be storage controllers 230 , such as for every ten second window.
- management device 240 may receive messages from storage controllers 230 , where each message may include one or more usage values describing the usage of a particular user, at a particular priority level, over the previous window.
- the usage values may be specified for a particular storage device 250 / 255 .
- the usage values may be expressed as an average usage level over the set of storage devices connected to a storage controller 230 .
- the usage values may be expressed as, for example, a percentage value, a time value (e.g., 300 milli-seconds of usage), a value based on bandwidth used, etc.
- Process 500 may further include, based on the usage information, updating the maximum allowed usage level at storage controllers 230 (block 530 ).
- management device 240 may calculate, the LD p (u) values discussed above using equation (2). If any of these values change from the previous time window, management device 240 may broadcast the updated value(s) to storage controllers 230 .
- management device 230 may transmit other parameters to storage controllers 230 . For example, the target usage levels may occasionally be updated and broadcast to storage controllers 230 . In general, any of the parameters, that are used by storage controllers 230 to implement the prioritized scheduling, may be transmitted to storage controllers 230 .
- FIG. 6 is a flow chart of an example of another process 600 for performing priority scheduling.
- Process 600 may be performed, for example, by each of storage controllers 230 .
- Process 600 may include receiving an identification of the users, target usage levels for each user and priority, and the priority level of each user (block 610 ). This information may be received from management device 240 , such as during initial setup of storage system 200 .
- This information may be received from management device 240 , such as during initial setup of storage system 200 .
- One example of a set of users, target usage levels, and priority levels is shown in Table I.
- Process 600 may further include setting up and maintaining queues 432 for each user (block 620 ).
- Queues 432 may include FIFO queues and a separate queue may be maintained for each combination of user, priority, and storage device 250 / 255 .
- Queues 432 may receive incoming operations, from the users, and buffer the operations until the operations are transmitted, for execution, to the corresponding storage devices 250 / 255 .
- data structures other than FIFO queues may be used.
- blocks 610 and 620 may be performed during initialization of storage system 200 .
- the operations of blocks 610 and 620 may be performed as a new user is added to storage system 200 .
- Blocks 630 , 640 , 650 , and 660 in contrast, may correspond to operations that are repeatedly performed during runtime operation of storage system 200 .
- Process 600 may further include receiving the maximum allowed usage level for each user and priority (block 630 ).
- the maximum allowed usage level, LD p (u) may be determined by management device 240 and transmitted to storage controllers 230 .
- management device 240 may periodically calculate, according to equation (2), the maximum allowed usage level.
- storage controllers 230 may locally calculate and/or modify the maximum allowed usage level, LD p (u).
- storage controllers 230 may receive other parameters, in addition to the maximum allowed usage level, from management device 240 (e.g., updated target usage levels or other parameters may be received).
- Process 600 may further include measuring and/or monitoring the usage levels corresponding to each queue (block 640 ).
- usage monitor 410 may monitor the usage, of storage devices 250 / 255 , for each user and priority level.
- the usage values may be expressed as a percentage value, a time value, a value based on bandwidth used, etc., that are measured/monitored by usage monitor 410 within a predetermined time window.
- Process 600 may further include calculating scores for each user, priority, an storage device (block 650 ) (i.e., a score may be calculated for each queue 432 ).
- a score may be calculated for each queue 432 .
- the calculated scores, S p (u) may be based on each user's priority level, target usage level, measured usage level (e.g., as measured in block 640 ), and maximum allowed usage level (block 650 ).
- the scores, S p (u) may be calculated, for example, using equation (4).
- Process 600 may further include selecting among the received storage operations, such as those stored in queues 432 , based on the calculated scores (block 660 ). For example, arbitrator component 434 may select the operations from the queues 432 , for a particular storage device 250 / 255 , in an order based on the scores for the queues (e.g., the operation, in the queue with the lowest score, may be selected first). The selected operation may then be forwarded to the storage device 250 / 255 corresponding to the queue from which the operation was selected.
- arbitrator component 434 may select the operations from the queues 432 , for a particular storage device 250 / 255 , in an order based on the scores for the queues (e.g., the operation, in the queue with the lowest score, may be selected first).
- the selected operation may then be forwarded to the storage device 250 / 255 corresponding to the queue from which the operation was selected.
- a number of modifications may be made to the basic arbitration scheme of simply selecting queues, that include queued operations, based on the scores, S p (u). For example, once a queue is chosen by arbitrator component 434 , it may normally be desirable to run the highest priority operation from the user but occasionally it may desirable to run a lower priority operation, from the same user, in order to avoid starvation of the user's lower priority operations.
- a number of scheduling techniques may be used to choose per-priority queues from the queues for a particular user's queues. For example, a self-clocked fair queuing (SCFQ) technique may be used.
- SCFQ self-clocked fair queuing
- SCFQ and SFQ may differ by whether they rank operations based on virtual start times or virtual finish times of the operations. Both SCFQ and SFQ may achieve relatively equal fairness but SCFQ may allow queues with higher priority operations to burst but may then starve that flow while servicing other computing queues.
- WRR weighted round robin
- a single usage rate window may be used to schedule operations from users having multiple different priorities. Higher priority operations may be prioritized to allow the higher priority operations to achieve lower latency, which may be an important factor for certain classes of applications. Further, with the techniques described above, even though a target usage rate is set, higher priority operations from a user may continue to be serviced over lower priority operations up until the user exceeds the maximum allowed usage rate. Further, with the technique described herein, operations of the same priority are not necessarily treated the same. For instance, the prioritized scheduling may favor users who have not recently run operations. This may allow users to see better latency by keeping their queues short and underutilizing their allotted usage quota.
- FIG. 7 is a diagram illustrating three example queues 710 , 720 , and 730 , which may correspond to a disk drive 740 .
- queue 710 may be a queue for the user, USER 1 , and may correspond to a high priority (LOW LATENCY) queue.
- Queue 720 may include a second queue for USER 1 , although queue 720 may correspond to lower priority operations (BATCH) from USER 1 .
- Queue 730 may be a queue for the user, USER 2 , and may correspond to a high priority (LOW LATENCY) queue.
- FIG. 7 is a diagram illustrating three example queues 710 , 720 , and 730 , which may correspond to a disk drive 740 .
- queue 710 may be a queue for the user, USER 1 , and may correspond to a high priority (LOW LATENCY) queue.
- BATCH lower priority operations
- Queue 730 may be a queue for the user, USER 2 , and may
- queue 710 is assigned a target usage of 20%
- queue 720 is assigned a target usage of 10%
- queue 730 is assigned a target usage of 30%.
- the maximum allowed usage values which may be received from management device 240 , are illustrated as 35% (queue 710 ), 17% (queue 720 ), and 35% (queue 730 ).
- Usage monitor 410 may measure actual usage of disk drive 740 . For this example, assume that actual usage is expressed as a percent of time, over the measurement window, at which operations from a particular queue are being serviced by disk drive 740 .
- the measured usage values for the latest window are illustrated as 20% (queue 710 ), 10% (queue 720 ), and 20% (queue 730 ).
- U p (u) which may represent the usage by a user at a particular priority and higher, may correspondingly be calculated as 20% (queue 710 ), 30% (queue 720 ), and 20% (queue 730 ).
- a technique such as SCFQ may be used to occasionally also service operations from queue 720 , to ensure that queue 720 , which corresponds to the same user as queue 710 , is not starved.
- the scores were selected based on a single calculation of the scores S p (u).
- the scores may be constantly updated (or updated at some small interval), in response to changing usage values for disk drive 740 .
- Each updating of the scores may correspond to a potential change in the selection order of the operations still in queues 710 - 730 .
- FIG. 8 is a diagram illustrating the queues 710 , 720 , and 730 , and disk drive 740 , as shown in FIG. 7 .
- FIG. 8 assume that operations OP 6 and OP 7 , from queue 730 , have executed, and a new operation, OP 8 , was received for queue 730 .
- monitored usage levels may now be 10% (queue 710 ), 0% (queue 720 ), and 70% (queue 730 ).
- U p (u) which may represent the usage of a user at a particular priority and higher, may correspondingly be calculated as 10% (queue 710 ), 10% (queue 720 ), and 70% (queue 730 ).
- Queue 730 for which U p (u) is now greater than the maximum allowed usage of queue 730 , may have its score, S p (u), set to an arbitrarily high value (shown as ⁇ ).
- Queue 730 which has exceeded its maximum allowed usage, may be cutoff until all the other queues are empty (or until the usage of queue 730 is recalculated and the calculated usage is below the maximum allowed value).
- An example of the selected order of the operations in queue 710 , 720 , and 730 is shown by ordered list 760 , in which operation OP 1 is the first executed operation and operation OP 8 is the last.
- U p (u) may be modified to penalize users for recent use of lower priorities.
- U p (u) may be modified as:
- U p ⁇ ( u ) ⁇ q ⁇ p ⁇ usage q ⁇ ( u ) + ⁇ q ⁇ p ⁇ q * usage q ⁇ ( u ) .
- ⁇ u LD p (u) may be bounded so that higher priorities do not starve lower priorities even when all of the higher priorities are active on a storage device 250 / 255 .
- the maximum allowed usage calculation could be rounded up, such as: max(TS p (u), ⁇ p (u)+2p ⁇ (u)).
Abstract
Description
TSp(u) (or quotap(u)), may be received by
LD p(u)=max(TS p(u),μp(u)+2σp(u)); for p>0, and
LD 0(u)=0; for p=0 (Eq. 2)
where μp(u) may represent the average portion of the storage device that is used for user, u, at priority, p, and σp(u) may represent the standard deviation of the portion of the storage device that is used for user, u, at priority, p. In alternative implementations, other calculations for LDp(u), that allow LDp(u) to go over TSp(u), are additionally possible.
U p(u)=Σq≧pusageq(u), (Eq. 3)
where usagep(u) may represent the usage over a previous window, such as a ten second window, for this user and priority, as calculated locally by
Here, k may be chosen as a constant such that Sp(u)<Sq(v) when p>q for all users u and v. The score, Sp(u), for a higher priority operation may, thus, always be less than the score for a lower priority operation. The notation, Sp(u)=∞, may, in practice, be implemented by setting Sp(u) to an arbitrarily high value, or by limiting the value of the variable in which Sp(u) is stored, so that all scores that are calculated using the first equation for Sp(u) will be lower than Sp(u)=∞.
TS p(u)*#disks=Σi=0 #disksmin(r i ,LD p(u)) (Eq. 5)
where #disks represents the total number of
TABLE I | ||
USER | TARGET USAGE | PRIORITY |
mail_system | 15% | low latency |
mail_system | 10% | batch |
Research | 5% | best effort |
search_service | 40% | low latency |
misc_apps | 30% | batch |
As another example, for higher priorities, Σu LDp(u) may be bounded so that higher priorities do not starve lower priorities even when all of the higher priorities are active on a
Claims (22)
Priority Applications (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US13/280,883 US8612990B1 (en) | 2011-10-25 | 2011-10-25 | Prioritized rate scheduler for a storage system |
US14/107,349 US9262093B1 (en) | 2011-10-25 | 2013-12-16 | Prioritized rate scheduler for a storage system |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US13/280,883 US8612990B1 (en) | 2011-10-25 | 2011-10-25 | Prioritized rate scheduler for a storage system |
Related Child Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US14/107,349 Continuation US9262093B1 (en) | 2011-10-25 | 2013-12-16 | Prioritized rate scheduler for a storage system |
Publications (1)
Publication Number | Publication Date |
---|---|
US8612990B1 true US8612990B1 (en) | 2013-12-17 |
Family
ID=49725942
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US13/280,883 Active 2032-06-15 US8612990B1 (en) | 2011-10-25 | 2011-10-25 | Prioritized rate scheduler for a storage system |
US14/107,349 Active 2032-06-13 US9262093B1 (en) | 2011-10-25 | 2013-12-16 | Prioritized rate scheduler for a storage system |
Family Applications After (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US14/107,349 Active 2032-06-13 US9262093B1 (en) | 2011-10-25 | 2013-12-16 | Prioritized rate scheduler for a storage system |
Country Status (1)
Country | Link |
---|---|
US (2) | US8612990B1 (en) |
Cited By (10)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20140115598A1 (en) * | 2012-10-24 | 2014-04-24 | Dell Products L.P. | System and method for controlled sharing of consumable resources in a computer cluster |
US8856400B1 (en) * | 2013-03-15 | 2014-10-07 | Emc Corporation | I/O performance quotas |
US9225871B2 (en) * | 2014-01-31 | 2015-12-29 | Kyocera Document Solutions Inc. | Data storage apparatus and data storage method |
US9262093B1 (en) | 2011-10-25 | 2016-02-16 | Google Inc. | Prioritized rate scheduler for a storage system |
US9436391B1 (en) | 2014-03-28 | 2016-09-06 | Formation Data Systems, Inc. | Efficient scalable I/O scheduling |
US9491114B2 (en) | 2012-10-24 | 2016-11-08 | Messageone, Inc. | System and method for optimizing resource utilization in a clustered or cloud environment |
US9781054B1 (en) | 2014-07-25 | 2017-10-03 | Google Inc. | Quota-based resource scheduling |
US20220121367A1 (en) * | 2020-10-16 | 2022-04-21 | Western Digital Technologies, Inc. | Resource Utilization Tracking Within Storage Devices |
US20220374166A1 (en) * | 2021-05-18 | 2022-11-24 | Micron Technology, Inc. | Command scheduling in a memory subsystem according to a selected scheduling ordering |
US11620155B2 (en) * | 2018-06-08 | 2023-04-04 | Capital One Services, Llc | Managing execution of data processing jobs in a virtual computing environment |
Citations (18)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20040199635A1 (en) * | 2002-10-16 | 2004-10-07 | Tuan Ta | System and method for dynamic bandwidth provisioning |
US20040236740A1 (en) * | 2000-12-08 | 2004-11-25 | Ingenuity Systems, Inc. | Method and system for performing information extraction and quality control for a knowledgebase |
US20050177538A1 (en) * | 2004-01-30 | 2005-08-11 | Yusuke Shimizu | Preference information managing apparatus which stores users' usage history of packaged contents, calculates scores of the usage history and outputs the result of the calculation as a preference information, and preference information managing apparatus which stores users' usage history of packaged contents and the other contents, and calculates scores of the usage history in such a manner that a usage history of packaged contents is considered to be more valuable than a usuage history of other contents, and outputs the result of the calculation as a preference information |
US20070081554A1 (en) * | 2003-09-29 | 2007-04-12 | Saffre Fabrice T P | Bandwidth allocation |
US20070101334A1 (en) * | 2005-10-27 | 2007-05-03 | Atyam Balaji V | Dynamic policy manager method, system, and computer program product for optimizing fractional resource allocation |
US20070133409A1 (en) * | 2000-05-19 | 2007-06-14 | Mckinnon Martin W Iii | Allocating access across shared communication medium to user classes |
US20090245115A1 (en) * | 2008-03-28 | 2009-10-01 | Verizon Data Services, Llc | Method and system for porviding holistic, interative, rule-based traffic management |
US20090282346A1 (en) * | 2008-02-22 | 2009-11-12 | Accenture Global Services Gmbh | System for managing a collaborative environment |
US7702779B1 (en) * | 2004-06-30 | 2010-04-20 | Symantec Operating Corporation | System and method for metering of application services in utility computing environments |
US7747723B2 (en) * | 2005-09-20 | 2010-06-29 | Hitachi, Ltd. | Communication system and communication management method |
US20100217558A1 (en) * | 2009-02-26 | 2010-08-26 | Apple Inc. | Minimization of false trigger in a mobile electronic system |
US20100229218A1 (en) * | 2009-03-05 | 2010-09-09 | Microsoft Corporation | Quota management for network services |
US20100325327A1 (en) * | 2009-06-17 | 2010-12-23 | Freescale Semiconductor, Inc. | Programmable arbitration device and method therefor |
US20110069666A1 (en) * | 2009-09-24 | 2011-03-24 | Colin Kahn | Method and apparatus for managing allocation of resources in a network |
US20110087777A1 (en) * | 2009-10-09 | 2011-04-14 | Sony Corporation | Information-processing device, information-processing method, and program |
US7984151B1 (en) * | 2008-10-09 | 2011-07-19 | Google Inc. | Determining placement of user data to optimize resource utilization for distributed systems |
US8149699B2 (en) * | 2008-12-02 | 2012-04-03 | Electronics And Telecommunications Research Institute | Method and apparatus for controlling traffic according to user |
US20120233325A1 (en) * | 2009-11-30 | 2012-09-13 | Zte Corporation | Method and system for implementing usage monitoring control |
Family Cites Families (12)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6141346A (en) * | 1995-07-19 | 2000-10-31 | Fujitsu Network Communications, Inc. | Point-to-multipoint transmission using subqueues |
US6314110B1 (en) * | 1998-03-06 | 2001-11-06 | Cisco Technology, Inc. | Method and apparatus for distributed bandwidth allocation for a bi-directional ring media with spatial and local reuse |
US6434559B1 (en) * | 1998-10-09 | 2002-08-13 | Xpandable Technology, Inc. | Critical resource management |
US7668966B2 (en) * | 2001-11-02 | 2010-02-23 | Internap Network Services Corporation | Data network controller |
US7584475B1 (en) * | 2003-11-20 | 2009-09-01 | Nvidia Corporation | Managing a video encoder to facilitate loading and executing another program |
US20050240934A1 (en) * | 2004-04-21 | 2005-10-27 | Hewlett-Packard Development Company, L.P. | Task management based on system utilization |
US7797756B2 (en) * | 2006-04-18 | 2010-09-14 | Hewlett-Packard Development Company, L.P. | System and methods for managing software licenses in a variable entitlement computer system |
KR101116615B1 (en) * | 2007-03-28 | 2012-03-07 | 삼성전자주식회사 | Resource management system and method for applications and threads in JAVA Virtual Machine |
US7530072B1 (en) * | 2008-05-07 | 2009-05-05 | International Business Machines Corporation | Method to segregate suspicious threads in a hosted environment to prevent CPU resource exhaustion from hung threads |
US20100299447A1 (en) * | 2009-05-25 | 2010-11-25 | Nilesh Anant Salvi | Data Replication |
US9008673B1 (en) * | 2010-07-02 | 2015-04-14 | Cellco Partnership | Data communication device with individual application bandwidth reporting and control |
US8612990B1 (en) | 2011-10-25 | 2013-12-17 | Google Inc. | Prioritized rate scheduler for a storage system |
-
2011
- 2011-10-25 US US13/280,883 patent/US8612990B1/en active Active
-
2013
- 2013-12-16 US US14/107,349 patent/US9262093B1/en active Active
Patent Citations (20)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20070133409A1 (en) * | 2000-05-19 | 2007-06-14 | Mckinnon Martin W Iii | Allocating access across shared communication medium to user classes |
US20080112429A1 (en) * | 2000-05-19 | 2008-05-15 | Scientific Atlanta | Allocations of Access Across a Communications Medium |
US20040236740A1 (en) * | 2000-12-08 | 2004-11-25 | Ingenuity Systems, Inc. | Method and system for performing information extraction and quality control for a knowledgebase |
US20100192213A1 (en) * | 2002-10-16 | 2010-07-29 | Eric | System and method for dynamic bandwidth provisioning |
US20040199635A1 (en) * | 2002-10-16 | 2004-10-07 | Tuan Ta | System and method for dynamic bandwidth provisioning |
US20070081554A1 (en) * | 2003-09-29 | 2007-04-12 | Saffre Fabrice T P | Bandwidth allocation |
US20050177538A1 (en) * | 2004-01-30 | 2005-08-11 | Yusuke Shimizu | Preference information managing apparatus which stores users' usage history of packaged contents, calculates scores of the usage history and outputs the result of the calculation as a preference information, and preference information managing apparatus which stores users' usage history of packaged contents and the other contents, and calculates scores of the usage history in such a manner that a usage history of packaged contents is considered to be more valuable than a usuage history of other contents, and outputs the result of the calculation as a preference information |
US7702779B1 (en) * | 2004-06-30 | 2010-04-20 | Symantec Operating Corporation | System and method for metering of application services in utility computing environments |
US7747723B2 (en) * | 2005-09-20 | 2010-06-29 | Hitachi, Ltd. | Communication system and communication management method |
US20070101334A1 (en) * | 2005-10-27 | 2007-05-03 | Atyam Balaji V | Dynamic policy manager method, system, and computer program product for optimizing fractional resource allocation |
US20090282346A1 (en) * | 2008-02-22 | 2009-11-12 | Accenture Global Services Gmbh | System for managing a collaborative environment |
US20090245115A1 (en) * | 2008-03-28 | 2009-10-01 | Verizon Data Services, Llc | Method and system for porviding holistic, interative, rule-based traffic management |
US7984151B1 (en) * | 2008-10-09 | 2011-07-19 | Google Inc. | Determining placement of user data to optimize resource utilization for distributed systems |
US8149699B2 (en) * | 2008-12-02 | 2012-04-03 | Electronics And Telecommunications Research Institute | Method and apparatus for controlling traffic according to user |
US20100217558A1 (en) * | 2009-02-26 | 2010-08-26 | Apple Inc. | Minimization of false trigger in a mobile electronic system |
US20100229218A1 (en) * | 2009-03-05 | 2010-09-09 | Microsoft Corporation | Quota management for network services |
US20100325327A1 (en) * | 2009-06-17 | 2010-12-23 | Freescale Semiconductor, Inc. | Programmable arbitration device and method therefor |
US20110069666A1 (en) * | 2009-09-24 | 2011-03-24 | Colin Kahn | Method and apparatus for managing allocation of resources in a network |
US20110087777A1 (en) * | 2009-10-09 | 2011-04-14 | Sony Corporation | Information-processing device, information-processing method, and program |
US20120233325A1 (en) * | 2009-11-30 | 2012-09-13 | Zte Corporation | Method and system for implementing usage monitoring control |
Non-Patent Citations (5)
Title |
---|
John C.R. Bennett, et al.; "WB2Q: Worst-case Fair Weighted Fair Queueing"; Proc. IEEE INFOCOM'96, San Francisco, CA; Mar. 1996, pp. 120-128. |
Kenneth J. Duda, et al.; "Borrowed-Virtual-Time (BVT) scheduling: supporting latency-sensitive threads in a general-purpose schedule"; SOSP-17; Kiawah Island, South Carolina, Dec. 1999, 16 pages. |
Pawan Goyal, et al.; "Start-time Fair Queuing: A Scheduling Algorithm for Integrated Services Packet Switching Networks", Proc. ACM-SIGCOMM'96, Palo Alto, CA, Aug. 1996, pp. 157-168. |
S. J. Golestani; "A Self-Clocked Fair Queueing Scheme for Broadband Applications"; Proc. INFOCOM'94, Apr. 1994, pp. 636-646. |
Sanjay Ghemawat, et al.; "The Google File System", SOSP'03, Bolton Landing, New York, Oct. 19-22, 2003, 15 pages. |
Cited By (17)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9262093B1 (en) | 2011-10-25 | 2016-02-16 | Google Inc. | Prioritized rate scheduler for a storage system |
US11321118B2 (en) * | 2012-10-24 | 2022-05-03 | Messageone, Inc. | System and method for controlled sharing of consumable resources in a computer cluster |
US20140115598A1 (en) * | 2012-10-24 | 2014-04-24 | Dell Products L.P. | System and method for controlled sharing of consumable resources in a computer cluster |
US9491114B2 (en) | 2012-10-24 | 2016-11-08 | Messageone, Inc. | System and method for optimizing resource utilization in a clustered or cloud environment |
US9158591B2 (en) | 2012-10-24 | 2015-10-13 | Metric Holdings, Llc | System and method for controlled sharing of consumable resources in a computer cluster |
US8856400B1 (en) * | 2013-03-15 | 2014-10-07 | Emc Corporation | I/O performance quotas |
US9501226B1 (en) * | 2013-03-15 | 2016-11-22 | EMC IP Holding Company LLC | I/O performance quotas |
US9225871B2 (en) * | 2014-01-31 | 2015-12-29 | Kyocera Document Solutions Inc. | Data storage apparatus and data storage method |
US9436391B1 (en) | 2014-03-28 | 2016-09-06 | Formation Data Systems, Inc. | Efficient scalable I/O scheduling |
US10257111B1 (en) | 2014-07-25 | 2019-04-09 | Google Llc | Quota-based resource scheduling |
US10931592B1 (en) | 2014-07-25 | 2021-02-23 | Google Llc | Quota-based resource scheduling |
US9781054B1 (en) | 2014-07-25 | 2017-10-03 | Google Inc. | Quota-based resource scheduling |
US11620155B2 (en) * | 2018-06-08 | 2023-04-04 | Capital One Services, Llc | Managing execution of data processing jobs in a virtual computing environment |
US20220121367A1 (en) * | 2020-10-16 | 2022-04-21 | Western Digital Technologies, Inc. | Resource Utilization Tracking Within Storage Devices |
US11500539B2 (en) * | 2020-10-16 | 2022-11-15 | Western Digital Technologies, Inc. | Resource utilization tracking within storage devices |
US20220374166A1 (en) * | 2021-05-18 | 2022-11-24 | Micron Technology, Inc. | Command scheduling in a memory subsystem according to a selected scheduling ordering |
US11526306B1 (en) * | 2021-05-18 | 2022-12-13 | Micron Technology, Inc. | Command scheduling in a memory subsystem according to a selected scheduling ordering |
Also Published As
Publication number | Publication date |
---|---|
US9262093B1 (en) | 2016-02-16 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US8612990B1 (en) | Prioritized rate scheduler for a storage system | |
US8321627B1 (en) | Memory operation command latency management | |
US9703285B2 (en) | Fair share scheduling for mixed clusters with multiple resources | |
CN107579926B (en) | QoS setting method of Ceph cloud storage system based on token bucket algorithm | |
JP5041805B2 (en) | Service quality controller and service quality method for data storage system | |
US9208116B2 (en) | Maintaining I/O priority and I/O sorting | |
US9201816B2 (en) | Data processing apparatus and a method for setting priority levels for transactions | |
US7929438B2 (en) | Scheduler pipeline design for hierarchical link sharing | |
US10754706B1 (en) | Task scheduling for multiprocessor systems | |
US7647444B2 (en) | Method and apparatus for dynamic hardware arbitration | |
US8195784B2 (en) | Linear programming formulation of resources in a data center | |
US20170177221A1 (en) | Dynamic core allocation for consistent performance in a non-preemptive scheduling environment | |
US8522244B2 (en) | Method and apparatus for scheduling for multiple memory controllers | |
US7383548B2 (en) | CPU usage regulation | |
US20100083262A1 (en) | Scheduling Requesters Of A Shared Storage Resource | |
US20110276972A1 (en) | Memory-controller-parallelism-aware scheduling for multiple memory controllers | |
Nguyen et al. | A hybrid scheduling algorithm for data intensive workloads in a mapreduce environment | |
US11100604B2 (en) | Multiple application cooperative frame-based GPU scheduling | |
US9436391B1 (en) | Efficient scalable I/O scheduling | |
JP2008234659A (en) | Data processing apparatus and method for arbitrating between messages routed over communication channel | |
JP5471822B2 (en) | I / O control program, information processing apparatus, and I / O control method | |
US20100115154A1 (en) | Information processing system and method of allocating i/o to paths in same | |
US20200259747A1 (en) | Dynamic buffer management in multi-client token flow control routers | |
US10785300B2 (en) | Storage rate limiting for information handling system with multiple storage controllers | |
CN106155810B (en) | The input/output scheduling device of workload-aware in software definition mixing stocking system |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:GREENFIELD, LAWRENCE E.;KHESIN, ALEXANDER;REEL/FRAME:027117/0133Effective date: 20111024 |
|
FEPP | Fee payment procedure |
Free format text: PAYOR NUMBER ASSIGNED (ORIGINAL EVENT CODE: ASPN); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
FPAY | Fee payment |
Year of fee payment: 4 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044101/0299Effective date: 20170929 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 8TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1552); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 8 |