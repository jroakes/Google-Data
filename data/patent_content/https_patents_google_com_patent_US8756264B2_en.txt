US8756264B2 - Parallel pseudorandom number generation - Google Patents
Parallel pseudorandom number generation Download PDFInfo
- Publication number
- US8756264B2 US8756264B2 US11/716,379 US71637907A US8756264B2 US 8756264 B2 US8756264 B2 US 8756264B2 US 71637907 A US71637907 A US 71637907A US 8756264 B2 US8756264 B2 US 8756264B2
- Authority
- US
- United States
- Prior art keywords
- sub
- streams
- processors
- processor
- stream
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F7/00—Methods or arrangements for processing data by operating upon the order or content of the data handled
- G06F7/58—Random or pseudo-random number generators
- G06F7/582—Pseudo-random number generators
Definitions
- the disclosed embodiments relate generally to random number generation, and more particularly, to generating parallel streams of random numbers.
- PRNG Pseudorandom number generation
- RNG Physical Network Generation
- Improper PRNG can result in generation of highly correlated and statistically dependent pseudorandom numbers that produce incorrect simulation results.
- splitting linear congruential generators for use in parallel computing environments may produce highly correlated parallels streams of pseudorandom numbers.
- PRNG can also be computationally demanding, thereby limiting simulation performance.
- inversive generators that compute an inverse modulus function may limit performance when implemented using traditional iterative techniques.
- FIGS. 1A & 1B are schematic diagrams illustrating a random number sequence broken into sub-sequences in accordance with some embodiments.
- FIG. 2A is a block diagram of first and second processing elements, wherein the first processing element is configured to maintain and advance the state of a PRN generator implemented in the second processing element, in accordance with some embodiments.
- FIG. 2B is a block diagram of a cluster of CPUs in accordance with some embodiments.
- FIGS. 3A-3C are flow diagrams illustrating methods for generating pseudo-random numbers on a parallel processing system in accordance with some embodiments.
- FIG. 4 is a block diagram illustrating a computer in accordance with some embodiments.
- a method of generating pseudo-random numbers on a parallel processing system comprises generating a plurality of sub-streams of pseudo-random numbers, wherein the sub-streams are generated in parallel by one or more co-processors, and providing the plurality of sub-streams to respective processing elements, wherein the respective processing elements employ the plurality of sub-streams to execute an application.
- a method of generating pseudo-random numbers on a parallel processing system comprises generating a plurality of sub-streams of pseudo-random numbers, wherein the sub-streams are generated in parallel.
- Generating the plurality of sub-streams comprises storing, in a first processing element, a state associated with a first element in a respective sub-stream of the plurality of sub-streams; advancing the state in the first processing element.
- Generating the plurality of sub-streams further comprises providing the advanced state to a second processing element, wherein the second processing element calculates a second element in the respective sub-stream in accordance with the advanced state.
- the plurality of sub-streams is provided to respective processing elements, wherein the respective processing elements employ the plurality of sub-streams to execute an application.
- a method of generating pseudo-random numbers on a parallel processing system comprises generating a plurality of sub-streams of pseudo-random numbers, wherein the sub-streams are generated in parallel.
- a respective sub-stream in the plurality of sub-streams is generated by a non-linear random number generator.
- Generating the respective sub-stream comprises computing an index location and reading from an indexed table a value stored at the computed index location.
- the plurality of sub-streams is provided to respective processing elements, wherein the respective processing elements employ the plurality of sub-streams to execute an application.
- a parallel processing system for generating pseudo-random numbers comprises one or more co-processors configured to generate in parallel a plurality of sub-streams of pseudo-random numbers and one or more processing elements configured to receive the plurality of sub-streams and to employ the plurality of sub-streams to execute an application.
- a computer program product for use in conjunction with a parallel processing system comprises a computer readable storage medium and a computer program mechanism embedded therein.
- the computer program mechanism comprises instructions for generating a plurality of sub-streams of pseudo-random numbers, wherein the sub-streams are generated in parallel by one or more co-processors, and instructions for providing the plurality of sub-streams to respective processing elements, wherein the respective processing elements employ the plurality of sub-streams to execute an application.
- a parallel processing system for generating pseudo-random numbers comprises means for generating a plurality of sub-streams of pseudo-random numbers, wherein the sub-streams are generated in parallel by one or more co-processors, and means for providing the plurality of sub-streams to respective processing elements, wherein the respective processing elements employ the plurality of sub-streams to execute an application.
- PRNGs pseudorandom number generators
- PRNs are referred to as pseudorandom because they are repeatable and deterministic, unlike true random numbers.
- RNGs are used to solve stochastic differential equations, for example to determine stock option pricing.
- RNGs are used in the well-known optimization technique of simulated annealing. Simulated annealing may be used, for example, in electronic circuit place-and-route applications.
- RNGs are used in scheduling algorithms, for example in disk scheduling or in production planning and scheduling.
- RNGs are used to generate sequences and permutations, for exampling to analyze DNA sequence shuffling.
- RNGs are used to implement graph partitioning algorithms for applications such as data clustering and information retrieval.
- RNGs are used in cryptographic applications. Numerous other RNG applications are possible.
- RNGs are implemented in parallel-processing computer systems.
- parallel-processing computer system refers to a computing system that is capable of performing multiple operations simultaneously.
- a parallel-processing computer system may contain one or more processing elements including, but not limited to, processors, co-processors, and hybrid processors, which may be deployed on a single computer or a plurality of computers linked (wired and/or wireless) by a network in a cluster or grid or other types of configuration.
- a co-processor is a processor used to supplement the functions of a central processing unit (CPU), in accordance with some embodiments.
- CPU central processing unit
- GPUs graphics processing units
- math accelerators that perform floating point arithmetic
- signal processors encryption processors
- FPGAs or ASICs configured to supplement CPU functions.
- a hybrid processor performs functions associated with both CPUs and GPUs.
- a processing element includes one or more cores, which may share at least a portion of the same instruction set or use completely different instruction sets.
- the cores within a processing element may share at least a portion of a common memory space and/or have their own memory spaces.
- Mechanisms used to implement parallel execution of the operations include, but are not limited to, multiple-instruction-multiple-data (MIMD) execution of multiple instruction sequences, single-instruction-multiple-data (SIMD) execution of a single instruction sequence, vector processing, pipelining, hardware multi-threading, very-long-instruction-word (VLIW) or explicitly-parallel-instruction-computing (EPIC) instructions, superscalar execution, and a combination of at least two of the aforementioned mechanisms.
- MIMD multiple-instruction-multiple-data
- SIMD single-instruction-multiple-data
- VLIW very-long-instruction-word
- EPIC explicitly-parallel-instruction-computing
- superscalar execution and a combination of at least two of the aforementioned mechanisms.
- the parallel-processing computer system as a whole may use a single system image, multiple system images, or have no underlying operating system.
- a processing element or a core within a processing element may or may not run an operating system or a virtual machine monitor (e.g., hypervisor) that manages one or more operating systems running on a computer system at the same time.
- processors and co-processors include GPUs by nVidia and ATI, single-core and multiple-core x86 and Itanium processors by Intel, single- and multiple-core x86 and x86-64 processors by AMD, single-core and multiple-core PowerPC processors by IBM, the Cell processor by STI, the Niagara processor by Sun Microsystems, and the Threadstorm processor or X1E multi-streaming processor by Cray, Inc.
- a processing element may be a thread, such as an application-level thread, kernel thread, or hardware thread, running on a physical processor or virtual machine.
- a processing element may be a virtual machine running inside a hypervisor.
- a processing element may be a functional unit within a physical processor or a virtual machine.
- RNGs are implemented as combined generators, which combine multiple PRN sequences generated by multiple respective RNGs.
- An example of a combined generator is a combined explicit inverse congruential generator (CEICG).
- CEICGs For explicit generators such as CEICGs, each element in the resulting PRN sequence is a function of the element's location in the sequence and not of previous elements in the sequence.
- CEICGs thus require a small amount of seed or state data, which makes them a suitable choice for a processor with large numbers of virtual threads and a limited number of outputs per thread.
- combined generators such as CEICGs are used in applications with processors having thousands of virtual threads, or having millions of virtual threads.
- a CEICG is computed from two or more explicit inverse congruential generators (EICGs).
- An EICG is computed from the formulas:
- a is the multiplier
- m is the modulus
- c is the increment
- n 0 is the seed
- u n is the normalized nth element of the PRN sequence ⁇ u 0 , u 1 , u 2 , . . . ⁇ generated by the EICG.
- EICGs and CEICGs are thus types of inversive generators. More broadly, EICGs and CEICGs are types of non-linear generators, defined as generators whose basic operations are not limited to multiplication, addition, and modulus. They also are explicit generators: each value in the random number sequence can be explicitly computed from the index n, and does not depend on any previous values in the sequence.
- the period of the sequence ⁇ u n ⁇ produced by an EICG is equal to the modulus m.
- two or more sequences generated by respective EICGs are combined to generate a CEICG sequence with a longer period than the periods of each of the two or more sequences.
- the output of several EICGs can be written:
- x n ⁇ ⁇ 1 EICG ⁇ ( m 1 , a 1 , c 1 , n 01 )
- x nj EICG ⁇ ( m j , a j , c j , n 0 ⁇ j ) ( 3 )
- x nj is the n th output of the j th EICG.
- the CEICG sequence ⁇ u n ⁇ is given by summing the normalized elements and discarding the integer portion of the result, an operation that is written as:
- each parallel thread or process has a statistically independent sequence of PRNs.
- a PRN sequence e.g., a sequence generated by a combined generator
- cycle-splitting algorithms in which the sequence is broken into sub-sequences.
- a sequence may be broken into P sub-sequences of length B.
- Two exemplary methods of implementing cycle-splitting are the leapfrog method and the blocking method.
- FIG. 1A is a schematic diagram illustrating a random number sequence 100 broken into P subsequences 102 of length B by the blocking method, where P and B are integers, in accordance with some embodiments.
- Sequence 100 comprises a total of PB random numbers, or elements, where each element is labeled by a sequential element number 106 .
- the first B elements in the sequence 100 are assigned to a first sub-sequence 102 - 1 .
- Each sub-sequence 102 comprises B elements labeled by sequential element numbers 104 .
- An i th sub-sequence produced by the blocking method thus equals ⁇ u iB , U iB+1 , U iB+2 , . . . ⁇ .
- FIG. 1B is a schematic diagram illustrating a random number sequence 120 broken into P subsequences 122 of length B by a leapfrogging method, in accordance with some embodiments.
- Sequence 120 comprises a total of PB random numbers, or elements, where each element is labeled by a sequential element number 126 .
- Every Pth element is assigned to a first sub-sequence 122 - 1 .
- every Pth element is assigned to a second subsequence (not shown). This process of assigning every Pth element in sequence 120 to a particular sub-sequence 122 is continued until P sub-sequences 122 have been created.
- Each sub-sequence 122 comprises B elements labeled by sequential element numbers 124 .
- An i th sub-sequence produced by the leapfrog method thus equals ⁇ u i , u i+P , u i+2P , . . . ⁇ .
- a deterministic stream of PRNs is created regardless of the order in which the sub-sequences are generated.
- leapfrogging can be used to assign consecutive values of a sequence to components of the vectors.
- a 4-vector of results may be generated using the relation:
- the formulation of equation (6) is used on a GPU with Single Instruction, Multiple Data processing units (e.g., native float4 processing units).
- Single Instruction, Multiple Data processing units e.g., native float4 processing units.
- the scalar equations are used.
- a combined generator for a sub-sequence s with block size B is
- the modulus, multiplier, and increment are different for each component generator (e.g., each component EICG), but the block size is a property of the combined generator and thus is the same for each component generator.
- the state of the generator is represented by the small set of numbers ⁇ n 1 , n 2 , . .
- n j ( k mod m ) mod m (9)
- Equation (8) may also be performed using no more bits of storage than required by the modulus m j .
- the state of a generator is maintained and advanced by the same processing element that generates the corresponding PRNs.
- the co-processor maintains and advances the state of the generator.
- the state of the generator is maintained and advanced by a separate processing element.
- FIG. 2A is a block diagram of a first processing element 200 and a second processing element 208 (e.g., a GPU), wherein the first processing element 200 is configured to maintain and advance the state of a PRN generator implemented in the second processing element 208 , in accordance with some embodiments.
- first processing element 200 is a CPU or a core of a multi-core CPU.
- second processing element 208 is a co-processor, such as a GPU.
- second processing element 208 is a core of a multi-core CPU that is distinct from first processing element 200 .
- the first processing element 200 stores an initial seed 202 , which serves as an initial state and is provided to state maintenance operation 204 .
- State maintenance operation 204 provides the state of the generator to the generator 210 in second processing element 208 .
- Generator 210 generates an element or parallel elements corresponding to the provided state.
- State advancement operation 206 advances the state stored by state maintenance operation 204 , which provides the updated state to generator 210 to generate the next sequential element or parallel elements.
- the generator 210 provides the resulting PRNs (i.e., the resulting elements) to an application 212 .
- PRN generator 210 is a CEICG
- the state corresponds to the index n j and state advancement operation 206 advances the state in accordance with equation (10).
- state advancement operation 206 generates and state maintenance operation 204 stores a plurality of sequential states, which are provided to generator 210 in a batch. For example, four to six sequential states may be provided to generator 210 in a batch. In other examples, ten or more sequential states, or a hundred or more sequential states may be provided to generator 210 in a batch. Generator 210 then generates the sequential elements corresponding to the sequential states in the batch.
- first processing element 200 may re-seed the state by providing a new seed to state maintenance operation 204 .
- state advancement operation 206 advances the states corresponding to respective sub-sequences forward or backward by an arbitrary offset. For example, this facilitates the use of a random number generator in a cluster computing environment, where each cluster node has an offset seed.
- FIG. 2B is a block diagram of a cluster of CPUs 232 in accordance with some embodiments. Coupled to a CPU 232 are one or more GPUs 234 . Alternately, one or more co-processors other than GPUs are coupled to CPU 232 . In some embodiments the one or more GPUs 234 coupled to a respective CPU 232 in the cluster compute a respective block or sub-sequence of a RNG. In some embodiments, the CPUs 232 maintain and advance state information while the GPUs 234 generate random numbers, as illustrated for a single CPU in FIG. 2A . Numerous cluster architectures for interconnecting the CPUs 232 are possible.
- the inverse modulus function which in some embodiments is performed by EICGs that constitute a CEICG, defines a sequence of period m. For example, if m is 7, the sequence is given by:
- a period of the sequence may be stored in a table in memory.
- the parent sequence of each component generator is iterated through many times, since the period of the combined generator is larger than the periods of each of the components. If the parent sequence is stored in a table, the algorithm for generating the output of a CEICG becomes dominated by computing table indices and reading from memory at those index locations.
- Equation (11) Equation (12)
- Equation (12) Equation (8)
- Equation (9) Equation (9) where the modulus operation may be brought inside the inverse modulus operation.
- the index for the reads for two adjacent streams s and s+1 are separated by the quantity (B mod m j ), with the possible exception of the indices near the end of the tables of length m j , which have the property of “wrapping around” to the beginning of the table.
- the memory access pattern and thus the memory bandwidth may be improved by optimizing the value of the block size B and thus the parameter (B mod m j ). For example, in some embodiments values of B may be chosen that tend to make the memory access more sequential, thereby improving memory bandwidth.
- a CEICG is implemented in a DirectX 9 generation GPU, such as an AMD X1900 series GPU with 500 MHz clock and 594 MHz memory clock. Tiling modes of the X1900 are described in the AMD document “ATI CTM Guide: Technical Reference Manual” (2006), the contents of which are hereby incorporated by reference in their entirety.
- a 6-component generator i.e., a CEICG comprising six EICGs
- 12-bit moduli implemented on the X1900 requires only 96 KB to store the lookup tables for computed inverse modulus functions and produces a sequence having a total sequence length ⁇ 2 72 .
- the six largest primes less than 2 12 are used for the moduli. Parameters of such an embodiment are shown below.
- the tables of inverse moduli are stored in the GPU's texture memory.
- a texture represents a set of values at pixel positions.
- a float4 texture stores four floating point values at each position (i,j), denoted R, G, B, and Alpha.
- a float1 texture stores a single floating point value at each position.
- the X1900 series GPU supports more than one mode of reading from textures. In the normal reading mode for float1 textures, a single float may be read at position (i,j). In the 2 ⁇ 2 tiled reading mode for float1 textures, four floats may be simultaneously read from four adjacent positions (i+1,j), (i,j+1), (i+1,j+1), and (i,j).
- Table 2 shows the table layout below for the normal reading mode, with four bold boxes indicating four consecutive read operations for a component, corresponding to float4 (SIMD) output using the leapfrog method as shown in Equation (6). To make index computations simpler for the four consecutive reads, this table layout also accounts for the wrapping due to the modulus operation.
- the dimensions of this texture are 4096 ⁇ 6, with one column for each component EICG. There is unused space at the end of all columns except the first.
- the lookup tables (e.g., Table 3, below) use 2 columns that are shifted by 2 per component EICG, in such a way that a single read instruction on the GPU reads four consecutive values from a given component table.
- the total space used by the table in this example is 192 KB, due to duplicating each column.
- the extra space beyond the end of the tables, which are each of length less than 4096, is filled with values copied from the beginning of the table so that reads near the end of the table do not have to be split.
- the layout of the 4096 ⁇ 12 texture storing the six component tables is shown below.
- the four bold boxes indicate where a single read operation for the 1 st component generator (which has prime modulus 4093) will gather 4 consecutive elements, accounting for the wrapping that occurs due to the modulus operation.
- each pixel position (x,y) may be thought of as being in a separate thread of execution.
- the hardware manages the scheduling of the actual threads running on the 48 float4 processing cores.
- the number of pixel positions is determined by the maximum framebuffer size, which is 4096 ⁇ 4096 float4s for the X1900.
- the block size B for each sub-sequence must obey the restriction:
- some sub-sequence length may be sacrificed to optimize the values of (B mod m j ).
- reducing the sub-sequence length by no more than 0.025% from B max yields 68 billion possible combinations of the parameters (B mod m j ) that may be searched to optimize the rate of random number generation.
- performance is substantially improved or optimized when at least one of the (B mod m j ) values of component EICGs is either 1 or (m j ⁇ 1).
- performance is substantially improved or optimized when at least one of the (B mod m j ) values of component EICGs is zero.
- a component EICG for which (B mod m j ) equals zero is said to have zero stride: its value is the same for a given seed for all parallel threads.
- the speed of a RNG that computes inverse modulus functions by performing table lookups is limited by the rate of reading the lookup tables. Therefore, additional floating point operations may be coupled with the generator at zero or near-zero cost. In some embodiments, these additional floating point operations are used to condition the PRNs generated by the RNG. For example, a Gaussian random number generator may be created, based on a RNG that uses table lookups, using the Box-Muller method.
- operations for other applications that use random number sequences generated by a RNG may be combined with operations for the RNG in compiled programs, such as a compiled GPU program.
- the generated pseudorandom numbers are stored in registers during execution of the program, and need never be written to main memory. For example, PRNs may be generated, consumed, and discarded in a local program running on a particular thread, independently of other threads.
- multiple RNG evaluations with different seeds may be packed into a single compiled program with the common instructions factored out.
- Linear generators are defined as generators whose basic operations consist only of multiplication, addition, and modulus.
- linear generators are implemented in GPUs having multiple outputs per thread.
- a linear generator may involve thousands or tens of thousands of outputs per thread.
- a linear generator is implemented in a GPU based on nVidia's Compute Unified Device Architecture (CUDA), such as the G80 processor (e.g., the GeForce 8800), for which the number of outputs per thread is arbitrary.
- CUDA Compute Unified Device Architecture
- G80 processor e.g., the GeForce 8800
- multiple outputs per thread are provided by a hardware scatter operation, in which a thread may write to multiple locations in an output target.
- Pixel position in the GPU designates a particular random number sub-sequence whose state may be read from input textures
- a linear generator referred to as MRG32k3a is implemented in a GPU with multiple outputs per thread.
- the basic update step of MRG32k3a is
- numbers are represented by partitioning them into 2 or 3 values, depending on whether they are 32-bit generator state or 53-bit intermediate quantities, respectively.
- the algorithm to add or subtract two such extended range integers is an extension of a paper and pencil method with carry and borrow.
- each thread computes a block from a linear random number generator such as MRG32k3a.
- the number of threads is chosen to be small enough that the state information is manageable. In an example involving MRG32k3a, which has a state of 48 bytes, a limit of 4 MB of state information would correspond to 87,000 threads.
- a Wichmann-Hill generator is implemented on a GPU with numerous outputs per thread.
- the Wichmann-Hill generator is a family of 273 generators, each of which may be further split, for example by blocking, by leapfrogging, and/or by parameterizing sub-sequences.
- the update step for the Wichmann-Hill generator is
- 256 sub-sequences would each output 65536 values to fill up a render target of size (4096, 4096).
- the constants vary in the range 16718909 ⁇
- a generator such as the Wichmann-Hill generator may be “skipped ahead”: the sub-sequence state may be updated, for example, on a CPU while a GPU computes random numbers, as illustrated in FIG. 2 .
- FIG. 3A is a flow diagram illustrating a method 300 of generating pseudo-random numbers on a parallel processing system in accordance with some embodiments.
- a plurality of sub-streams of pseudo-random numbers (PRNs) is generated in parallel by one or more co-processors ( 302 ).
- co-processors 302
- thousands of sub-streams are generated in parallel, or millions of sub-streams are generated in parallel.
- a respective sub-stream in the plurality of sub-streams is generated in accordance with a blocking algorithm (e.g., sub-sequences 102 , FIG. 1A ) or with a leapfrogging algorithm (e.g., sub-sequences 122 , FIG. 1B ) ( 304 ).
- a blocking algorithm e.g., sub-sequences 102 , FIG. 1A
- a leapfrogging algorithm e.g., sub-sequences 122 , FIG. 1B
- the one or more co-processors include one or more GPUs ( 306 ). In some embodiments, the one or more co-processors include one or more hybrid processors ( 308 ).
- the plurality of sub-streams is provided to respective processing elements that employ the plurality of sub-streams to execute an application ( 310 ).
- the application is a Monte Carlo simulation ( 312 ).
- the application is one of stock option pricing, electronic circuit place-and-route, controller optimization, disk scheduling, production planning, analysis of DNA sequence shuffling, data clustering, information retrieval, or cryptography ( 314 ).
- FIG. 3B is a flow diagram illustrating a method 330 of generating pseudo-random numbers on a parallel processing system in accordance with some embodiments.
- a plurality of sub-streams of pseudo-random numbers (PRNs) is generated in parallel ( 332 ).
- Generating the plurality of sub-streams includes storing in a first processing element (e.g., processing element 200 , FIG. 2A ) a state associated with a first element (i.e., a particular pseudo-random number) in a respective sub-stream ( 334 ).
- the first processing element is a CPU or a first core of a multi-core CPU.
- the state is advanced ( 336 ).
- state advancement operation 206 advances the state stored by state maintenance operation 204 .
- the advanced state is provided to a second processing element (e.g., processing element 208 , FIG. 2A ).
- the second processing element is a co-processor (e.g., a GPU) or a second core of the multi-core CPU.
- the second processing element calculates a second element in the respective sub-stream in accordance with the advanced state ( 338 ).
- a respective sub-stream in the plurality of sub-streams is generated in accordance with a blocking algorithm (e.g., sub-sequences 102 , FIG. 1A ) or with a leapfrogging algorithm (e.g., sub-sequences 122 , FIG. 1B ) ( 340 ).
- a blocking algorithm e.g., sub-sequences 102 , FIG. 1A
- a leapfrogging algorithm e.g., sub-sequences 122 , FIG. 1B
- the plurality of sub-streams is provided to respective processing elements that employ the plurality of sub-streams to execute an application ( 310 ).
- the application is a Monte Carlo simulation ( 312 ).
- the application is one of stock option pricing, electronic circuit place-and-route, controller optimization, disk scheduling, production planning, analysis of DNA sequence shuffling, data clustering, information retrieval, or cryptography ( 314 ).
- FIG. 3C is a flow diagram illustrating a method 360 of generating pseudo-random numbers on a parallel processing system in accordance with some embodiments.
- a plurality of sub-streams of pseudo-random numbers (PRNs) is generated in parallel.
- a respective sub-stream is generated with a non-linear random number generator.
- Generating the respective sub-stream includes computing an index location and reading from an indexed table a value stored at the computed index location ( 362 ).
- the indexed table is stored in a texture memory of a GPU ( 364 ). In some embodiments, the indexed table is stored in a processor's local cache memory, in a processor's on-chip RAM, or in a processor's off-chip RAM ( 366 ). In some embodiments, the indexed table stores a sequence of values corresponding to one or more inverse modulus functions ( 368 ). Index locations may be computed, for example, according to equation (11).
- the non-linear random number generator is a CEICG ( 370 ).
- the CEICG comprises a plurality of EICGs, wherein each respective EICG is characterized by a distinct prime modulus m.
- each respective EICG is further characterized by a length B, and a value of (B mod m) for a respective EICG equals one of (m ⁇ 1) and 1.
- the plurality of sub-streams is generated by one or more co-processors. In some embodiments, the plurality of sub-streams is generated by one or more cores of one or more multi-core CPUs. In some embodiments, the plurality of sub-streams is generated by a cluster of computer systems. In some embodiments, the plurality of sub-streams is generated by a plurality of processors, wherein two or more processors of the plurality of processors have distinct instruction set architectures.
- a respective sub-stream in the plurality of sub-streams is generated in accordance with a blocking algorithm (e.g., sub-sequences 102 , FIG. 1A ) or with a leapfrogging algorithm (e.g., sub-sequences 122 , FIG. 1B ) ( 372 ).
- a blocking algorithm e.g., sub-sequences 102 , FIG. 1A
- a leapfrogging algorithm e.g., sub-sequences 122 , FIG. 1B
- the plurality of sub-streams is provided to respective processing elements that employ the plurality of sub-streams to execute an application ( 310 ).
- the application is a Monte Carlo simulation ( 312 ).
- the application is one of stock option pricing, electronic circuit place-and-route, controller optimization, disk scheduling, production planning, analysis of DNA sequence shuffling, data clustering, information retrieval, or cryptography ( 314 ).
- FIG. 4 is a block diagram illustrating a computer 400 in accordance with some embodiments.
- a RNG process such as processes 300 , 330 , or 360 are implemented on computer 400 .
- the computer 400 typically includes one or more central processing units (CPUs) 402 , one or more graphics processing units (GPUs) 404 , one or more network or other communications interfaces 406 , memory 416 , and one or more communication buses 414 for interconnecting these components.
- the one or more CPUs 402 and/or the one or more GPUs 404 may include respective registers 403 and 407 that may store generated pseudorandom numbers.
- the computer 400 also may include one or more co-processors (not shown) in place of or in addition to GPU(s) 404 .
- the one or more network or other communications interfaces 406 may connect computer 400 to other computers in a cluster of computer systems.
- the communication buses 414 may include circuitry (sometimes called a chipset) that interconnects and controls communications between system components.
- the client computer 400 may also include a user interface 408 comprising a display device 410 and a keyboard and/or mouse (or other pointing device) 412 .
- Memory 416 includes high-speed random access memory, such as DRAM, SRAM, DDR RAM or other random access solid state memory devices; and may include non-volatile memory (including a non-transitory computer readable storage medium), such as one or more magnetic disk storage devices, optical disk storage devices, flash memory devices, or other non-volatile solid state storage devices.
- the memory 416 may optionally include one or more storage devices remotely located from the CPU(s) 402 .
- Memory 416 may also include a GPU texture memory 406 .
- memory 404 stores the following programs, modules and data structures, or a subset thereof:
- Each of the above identified elements in FIG. 4 may be stored in one or more of the previously mentioned memory devices.
- Each of the above identified programs, modules, and applications corresponds to a set of instructions for performing a function described above.
- the above identified modules or programs i.e., sets of instructions
- memory 404 may store a subset of the modules and data structures identified above.
- memory 404 may store additional modules and data structures not described above.
Abstract
Description
where a is the multiplier, m is the modulus, c is the increment, n0 is the seed, and un is the normalized nth element of the PRN sequence {u0, u1, u2, . . . } generated by the EICG. The horizontal bar indicates inversion modulo m, where m is a prime number, with special handling of zero argument:
k·
EICGs and CEICGs are thus types of inversive generators. More broadly, EICGs and CEICGs are types of non-linear generators, defined as generators whose basic operations are not limited to multiplication, addition, and modulus. They also are explicit generators: each value in the random number sequence can be explicitly computed from the index n, and does not depend on any previous values in the sequence.
where xnj is the nth output of the jth EICG. The CEICG sequence {un} is given by summing the normalized elements and discarding the integer portion of the result, an operation that is written as:
x n,s=
The length of the resulting CEICG sequence is given by L=P·B.
In this example, if leapfrogging is combined with blocking, then the length of each sub-sequence is B/4 and each thread produces four sub-sequences.
where each component generator sub-sequence is computed from:
x nj,s=
In some embodiments, the modulus, multiplier, and increment are different for each component generator (e.g., each component EICG), but the block size is a property of the combined generator and thus is the same for each component generator. The state of the generator is represented by the small set of numbers {n1, n2, . . . , nj)}, which can be considered a global quantity since it is independent of the sub-sequence. After each call to the generator, the nj values are incremented by 1. In some embodiments, to avoid having to store any numbers larger than the prime modulus m, the following relation is used:
In some embodiments, for example, when the state of the generator is advanced, the following algorithm is used:
n j←(n j+1)mod m j (10)
k |
0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | . . . | ||
| 0 | 1 | 4 | 5 | 2 | 3 | 6 | 0 | 1 | 4 | 5 | 2 | . . . |
If m is small enough, a period of the sequence (shown in bold) may be stored in a table in memory. In some embodiments, in a CEICG the parent sequence of each component generator is iterated through many times, since the period of the combined generator is larger than the periods of each of the components. If the parent sequence is stored in a table, the algorithm for generating the output of a CEICG becomes dominated by computing table indices and reading from memory at those index locations. A table index can be computed from:
k j,s=(n j +n 0j +s(B mod m i))mod m j (11)
The table Tj stores the precomputed values of the sequence for the jth component EICG in the CEICG:
T(k)=
TABLE 1 |
Parameters for a 6-Component CEICG |
j | mj | aj | |
||
1 | 4093 | 7 | 0 | ||
2 | 4091 | 11 | 0 | ||
3 | 4079 | 13 | 0 | ||
4 | 4073 | 17 | 0 | ||
5 | 4057 | 19 | 0 | ||
6 | 4051 | 23 | 0 | ||
Total period L = 4572003881581124177747 ≈ 272 |
TABLE 2 |
Layout of inverse modulus tables in float1 texture |
for |
4th | |||||||
|
1st |
2nd |
3rd | EICG | 5th EICG | 6th EICG | |
0 | k = 0 | 0 | 0 | 0 | 0 | 0 | |
1 | 1 | 1 | 1 | 1 | 1 | 1 | |
2 | 2 | 2 | 2 | 2 | 2 | 2 | |
3 | 3 | 3 | 3 | 3 | 3 | 3 | |
. | . | . | . | . | . | . | |
. | . | . | . | . | . | . | |
. | . | . | . | . | . | . | |
4090 | 4090 | 4090 | |||||
4091 | 4091 | 0 | |||||
4092 | 4092 | 1 | |||||
4093 | 0 | 2 | |||||
4094 | 1 | unused | |||||
4095 | 2 | unused | |||||
TABLE 3 |
Layout of inverse modulus tables in float1 texture for 2 × 2 tiled read |
row |
1st |
2nd |
3rd |
4th |
5th EICG | 6th EICG | |
0 | k = 0 | 2 | 0 | 2 | 0 | 2 | 0 | 2 | 0 | 2 | 0 | 2 |
1 | 1 | 3 | 1 | 3 | 1 | 3 | 1 | 3 | 1 | 3 | 1 | 3 |
2 | 2 | 4 | 2 | 4 | 2 | 4 | 2 | 4 | 2 | 4 | 2 | 4 |
3 | 3 | 5 | 3 | 5 | 3 | 5 | 3 | 5 | 3 | 5 | 3 | 5 |
. | . | . | . | . | . | . | . | . | . | . | . | . |
. | . | . | . | . | . | . | . | . | . | . | . | . |
. | . | . | . | . | . | . | . | . | . | . | . | . |
4090 | 4090 | 4092 | 4090 | 1 | ||||||||
4091 | 4091 | 0 | 0 | 2 | ||||||||
4092 | 4092 | 1 | unused | unused | ||||||||
4093 | 0 | 2 | unused | unused | ||||||||
4094 | unused | unused | unused | unused | ||||||||
4095 | unused | unused | unused | unused | ||||||||
s=x+4096y (13)
When B=Bmax the sub-sequence associated with each pixel position is the maximum possible length. However, for values of B<Bmax, some sub-sequence length may be sacrificed to optimize the values of (B mod mj). For example, reducing the sub-sequence length by no more than 0.025% from Bmax yields 68 billion possible combinations of the parameters (B mod mj) that may be searched to optimize the rate of random number generation. In some embodiments, performance is substantially improved or optimized when at least one of the (B mod mj) values of component EICGs is either 1 or (mj−1). These values imply that two adjacent pixel positions will be reading from adjacent memory in the lookup table, for at least one of the six component generators. A search of the possible combinations of the parameters (B mod mj) may be limited to those combinations for which at least one of the (B mod mj) values of component EICGs is either 1 or (mj−1). For example, a brute-force search through this set of values may be performed to optimize the rate of random number generation. Table 4 shows an example of values of (B mod mj) for an optimized block size B for an embodiment in which the six largest primes less than 212 are used for the moduli.
TABLE 4 |
Values of (B mod mj) for optimized block size Bopt |
j | mj | Bopt mod mj |
1 | 4093 | 1362 |
2 | 4091 | 2338 |
3 | 4079 | 1360 |
4 | 4073 | 1891 |
5 | 4057 | 1 |
6 | 4051 | 4050 |
where the values of the constants are given in Table 5.
TABLE 5 |
MRG32k3a Parameters |
constant | value | ||
m1 | 4294967087 | ||
m2 | 4294944443 | ||
a | 1403580 | ||
b | 810728 | ||
c | 527612 | ||
d | 1370589 | ||
x=x 0 +x 1224 +x 2248 (18)
if 53 bits are required, and x2=0 if only 32 bits are required. The algorithm to add or subtract two such extended range integers is an extension of a paper and pencil method with carry and borrow. The algorithm to multiply two such numbers relies on further factoring the numbers according to
x=x 1+4096x h (19)
and again keeping track of the carry digits as in the paper and pencil method. The modulus may be computed by the Barrett modular reduction algorithm, which relies on storing the numbers [264/mk] and using multiplication and division by powers of 2. Finally the division by mk in Equation (17) is done by storing 1/mk in the form
1/m k =
that produces sufficient accuracy in the final floating point result.
In an embodiment, 256 sub-sequences would each output 65536 values to fill up a render target of size (4096, 4096). In this example, the constants vary in the range
16718909≦m k≦16776971
112≦c k≦127
-
- an
operating system 418 that includes procedures for handling various basic system services and for performing hardware dependent tasks; - a
network communication module 420 that is used for connectingcomputer 400 to other computers via the one or more communication network interfaces 406 and one or more communication networks, such as the Internet, other wide area networks, local area networks, metropolitan area networks, and so on; - a set of
instructions 422 for implementing a combined inversive generator (e.g., a CEICG), including one or more sets of instructions 424 for implementing component inversive generators (e.g., EICGs); - a set of
instructions 426 for implementing a combined linear generator (e.g., MRG32k3a or Wichmann-Hill), including one or more sets of instructions 428 for implementing component linear generators; - a look-up table 430 (e.g., for storing a set of values corresponding to an inverse modulus function); and
- an application 432 (e.g., a Monte Carlo simulation).
- an
Claims (13)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US11/716,379 US8756264B2 (en) | 2006-06-20 | 2007-03-09 | Parallel pseudorandom number generation |
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US81553206P | 2006-06-20 | 2006-06-20 | |
US90318807P | 2007-02-23 | 2007-02-23 | |
US11/716,379 US8756264B2 (en) | 2006-06-20 | 2007-03-09 | Parallel pseudorandom number generation |
Publications (2)
Publication Number | Publication Date |
---|---|
US20070294508A1 US20070294508A1 (en) | 2007-12-20 |
US8756264B2 true US8756264B2 (en) | 2014-06-17 |
Family
ID=38862869
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US11/716,379 Active 2031-09-12 US8756264B2 (en) | 2006-06-20 | 2007-03-09 | Parallel pseudorandom number generation |
Country Status (1)
Country | Link |
---|---|
US (1) | US8756264B2 (en) |
Cited By (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
EP3203400A1 (en) | 2016-02-03 | 2017-08-09 | Universitat Rovira I Virgili | A computer implemented method of generation of statistically uncorrelated molecule's conformations and computer programs |
US10048940B2 (en) * | 2016-06-02 | 2018-08-14 | International Business Machines Corporation | Parallel generation of random numbers |
US10942909B2 (en) * | 2018-09-25 | 2021-03-09 | Salesforce.Com, Inc. | Efficient production and consumption for data changes in a database under high concurrency |
Families Citing this family (22)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN101657795B (en) | 2007-04-11 | 2013-10-23 | 苹果公司 | Data parallel computing on multiple processors |
US11836506B2 (en) | 2007-04-11 | 2023-12-05 | Apple Inc. | Parallel runtime execution on multiple processors |
US8341611B2 (en) * | 2007-04-11 | 2012-12-25 | Apple Inc. | Application interface on multiple processors |
US8286196B2 (en) | 2007-05-03 | 2012-10-09 | Apple Inc. | Parallel runtime execution on multiple processors |
US8276164B2 (en) | 2007-05-03 | 2012-09-25 | Apple Inc. | Data parallel computing on multiple processors |
US8225325B2 (en) | 2008-06-06 | 2012-07-17 | Apple Inc. | Multi-dimensional thread grouping for multiple processors |
US8286198B2 (en) | 2008-06-06 | 2012-10-09 | Apple Inc. | Application programming interfaces for data parallel computing on multiple processors |
FR2938943B1 (en) * | 2008-11-21 | 2010-11-12 | Thales Sa | MULTIPROCESSOR SYSTEM. |
US8386403B2 (en) * | 2010-03-02 | 2013-02-26 | Empire Technology Development Llc | Distributed-type Markov chain Monte Carlo |
US10635062B2 (en) | 2010-06-29 | 2020-04-28 | International Business Machines Corporation | Systems and methods for highly parallel processing of parameterized simulations |
JP5059928B2 (en) | 2010-10-28 | 2012-10-31 | みずほ第一フィナンシャルテクノロジー株式会社 | Parallelization of random number generation processing using GPU |
US20130159680A1 (en) * | 2011-12-19 | 2013-06-20 | Wei-Yu Chen | Systems, methods, and computer program products for parallelizing large number arithmetic |
US10061562B2 (en) | 2012-09-29 | 2018-08-28 | Pivotal Software, Inc. | Random number generator in a parallel processing database |
US8874602B2 (en) | 2012-09-29 | 2014-10-28 | Pivotal Software, Inc. | Random number generator in a MPP database |
US10310904B2 (en) * | 2014-11-26 | 2019-06-04 | Dropbox, Inc. | Distributed technique for allocating long-lived jobs among worker processes |
JP6270765B2 (en) * | 2015-03-26 | 2018-01-31 | 三菱電機株式会社 | Parallel simulation device |
US10922052B2 (en) * | 2015-10-12 | 2021-02-16 | Oracle International Corporation | Generating pseudorandom number sequences by nonlinear mixing of multiple subsidiary pseudorandom number generators |
CN108023661B (en) * | 2016-10-31 | 2019-08-06 | 深圳市中兴微电子技术有限公司 | A kind of method and apparatus obtaining pseudo-random sequence |
US10503475B1 (en) * | 2016-11-09 | 2019-12-10 | The Florida State University Research Foundation, Inc. | Forensically reproducible random number generator and associated method of use |
AU2018248439C1 (en) * | 2017-04-06 | 2021-09-30 | Goldman Sachs & Co. LLC | General-purpose parallel computing architecture |
CN109005005B (en) * | 2018-11-05 | 2019-04-05 | 湖南继善高科技有限公司 | A kind of pseudo-random signal hybrid coding method and system |
JP2022096222A (en) * | 2020-12-17 | 2022-06-29 | 富士通株式会社 | Random number generation program and random number generation method |
Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5327365A (en) * | 1991-08-23 | 1994-07-05 | Fujitsu Limited | Generating system of random-number sequences for a parallel computer system |
US5519736A (en) * | 1993-09-09 | 1996-05-21 | Nec Corporation | Synchronous pseudo-noise code sequence generation circuit |
US6594680B1 (en) * | 1999-12-30 | 2003-07-15 | Texas Instruments Incorporated | Psuedo-random noise sequence generating system |
US6831905B1 (en) * | 1995-06-30 | 2004-12-14 | Interdigital Technology Corporation | Spread spectrum system assigning information signals to message-code signals |
-
2007
- 2007-03-09 US US11/716,379 patent/US8756264B2/en active Active
Patent Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5327365A (en) * | 1991-08-23 | 1994-07-05 | Fujitsu Limited | Generating system of random-number sequences for a parallel computer system |
US5519736A (en) * | 1993-09-09 | 1996-05-21 | Nec Corporation | Synchronous pseudo-noise code sequence generation circuit |
US6831905B1 (en) * | 1995-06-30 | 2004-12-14 | Interdigital Technology Corporation | Spread spectrum system assigning information signals to message-code signals |
US6594680B1 (en) * | 1999-12-30 | 2003-07-15 | Texas Instruments Incorporated | Psuedo-random noise sequence generating system |
Non-Patent Citations (27)
Title |
---|
Advanced Micro Devices, AMD Core Math Library (ACML), Chapter 6, Ver. 4.0.0, http://developer.amd.com, 2003-2007. |
Blythe, D., "The Direct3D 10 System," ACM Transactions on Graphics, vol. 25, No. 3, Jul. 2006. |
Engel, W., "Programming Vertex and Pixel Shaders," Charles River Media, Inc., 2004, pp. 3-24, 341-389. |
Entacher, K., "A Collection of Selected Pseudorandom Number Generators with Linear Structures," Tech. Rep. TR-97-1, ACPC, Austrian Center for Parallel Computation, 1997, 24 pages. |
Entacher, K., et al., "Linear and Inversive Pseudorandom Numbers for Parallel and Distributed Simulation," IEEE Proceedings of the 12th Workshop on Parallel and Distributed Simulation, 1997, pp. 90-97. |
Hars, L., "Modular Inverse Algorithms Without Multiplications for Cryptographic Applications," EURASIP J. on Embedded Systems, 2006, pp. 1-13. |
Intel Corporation, "Intel Math Kernel Library-Vector Statistical Library Notes," 2003-2007. |
Intel Corporation, "Intel Math Kernel Library—Vector Statistical Library Notes," 2003-2007. |
Knuth, D.E., "The Art of Computer Programming" 3 ed., vol. 2: Seminumerical Algorithms, Addison-Wesley, 1997, Chapter 3, pp. 1-193. |
L'Ecuyer, P., "Combined Multiple Recursive Random Number Generators," Operations Research 44, 5 (1995). |
L'Ecuyer, P., "Good Parameters and Implementations for Combined Multiple Recursive Random Number Generators," http:// iro.umontreal.ca, May 4, 1998, 19 pages. |
L'Ecuyer, P., et al., "An Object-Oriented Random-Number Package with Many Long Streams and Substreams," Operations Research, vol. 50, No. 6, 2002. |
L'Ecuyer, P., et al., "TestU01: A C Library for Empirical Testing of Random Number Generators," ACM Transactions on Mathematical Software, vol. V, No. N, 2005. |
Leeb, H., "Random Numbers for Computer Simulation," Master's Thesis, University of Salzburg, 1995. |
Lindholm, E., et al., "A User-Programmable Vertex Engine," ACM SIGGRAPH 2001, Los Angeles, California, Aug. 12-17, 2001, pp. 149-158. |
Maclaren, M.D., et al., "Uniform Random Number Generators," J. of Association of Computing Machinery, vol. 12, No. 1, Jan. 1965), pp. 83-89. |
Maclaren, N.M., "The Generation of Multiple Independent Sequences of Pseudorandom Numbers," Applied Statistics, vol. 38, No. 2, 1989, pp. 351-359. |
Mascagni, M., et al., "SPRNG: A Scalable Library for Pseudorandom Number Generation," Recent Advances in Numerical Methods and Applications II, Proceedings of NMA, 1998. |
Matsumoto, M., et al., "Merssene Twister: A 623-Dimensionally Equidistributed Uniform Pseudo-Random Number Generator," ACM Trans. on Modeling and Computer Simulations, vol. 8, No. 1, Jan. 1998, pp. 3-30. |
Menezes, A., et al., "Handbook of Applied Cryptography," CRC Press, Chapter 5, 1996. |
Olano, M., "Modified Noise for Evaluation on Graphics Hardware," Graphics Hardware, 2005. |
Owens, J.D., et al., "A Survey of General-Purpose Computation on Graphics Hardware," Eurographics 2005 State of the Art Report, 2005, pp. 21-51. |
Peakstream, Inc., "The Peakstream Platform: High Productivity Software Development for Multi-Core Processors," 2006. |
Schoo, M., et al., "A Survey and Empirical Comparison of Modern Pseudo-Random Number Generators for Distributed Stochastic Simulations," Tech. Rep. TR-CSSE-03/05, University of Canterbury, New Zealand, 2005. |
Stipcevic, M., "The Diehard Battery of Stringent Statistical Randomness Tests," http://random.com.hr/products/random/manual/html/diehard.html, 2001. |
Sussman, M., et al., "Pseudorandom Number Generation on the GPU," Graphics Hardware, 2006, pp. 1-8. |
Wegenkittl, S., "Are there hyperbolas in the scatter plots of inversive congruential pseudorandom numbers?" J. of Computational and Applied Mathematics, vol. 95, issue 1-2, Aug. 1998, pp. 117-125. |
Cited By (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
EP3203400A1 (en) | 2016-02-03 | 2017-08-09 | Universitat Rovira I Virgili | A computer implemented method of generation of statistically uncorrelated molecule's conformations and computer programs |
WO2017134512A1 (en) | 2016-02-03 | 2017-08-10 | Universitat Rovira I Virgili | A computer implemented method of generation of statistically uncorrelated molecule's conformations and computer programs |
US10048940B2 (en) * | 2016-06-02 | 2018-08-14 | International Business Machines Corporation | Parallel generation of random numbers |
US10942909B2 (en) * | 2018-09-25 | 2021-03-09 | Salesforce.Com, Inc. | Efficient production and consumption for data changes in a database under high concurrency |
US20210117400A1 (en) * | 2018-09-25 | 2021-04-22 | Salesforce.Com, Inc. | Efficient production and consumption for data changes in a database under high concurrency |
US11860847B2 (en) * | 2018-09-25 | 2024-01-02 | Salesforce, Inc. | Efficient production and consumption for data changes in a database under high concurrency |
Also Published As
Publication number | Publication date |
---|---|
US20070294508A1 (en) | 2007-12-20 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US8756264B2 (en) | Parallel pseudorandom number generation | |
Obrecht et al. | A new approach to the lattice Boltzmann method for graphics processing units | |
Weber et al. | Comparing hardware accelerators in scientific applications: A case study | |
KR20220054357A (en) | Method for performing PROCESSING-IN-MEMORY (PIM) operations on serially allocated data, and related memory devices and systems | |
Tian et al. | High-performance quasi-monte carlo financial simulation: FPGA vs. GPP vs. GPU | |
Thibault et al. | Accelerating incompressible flow computations with a Pthreads-CUDA implementation on small-footprint multi-GPU platforms | |
US8438370B1 (en) | Processing of loops with internal data dependencies using a parallel processor | |
Bradley et al. | Parallelization techniques for random number generators | |
Demchik | Pseudo-random number generators for Monte Carlo simulations on ATI Graphics Processing Units | |
Romero et al. | High performance implementations of the 2D Ising model on GPUs | |
Waidyasooriya et al. | Highly-parallel FPGA accelerator for simulated quantum annealing | |
Siro et al. | Exact diagonalization of the Hubbard model on graphics processing units | |
Weigel | Monte Carlo methods for massively parallel computers | |
Sussman et al. | Pseudorandom number generation on the GPU | |
Passerat-Palmbach et al. | Pseudo-random number generation on GP-GPU | |
Arbenz et al. | Batched transpose-free ADI-type preconditioners for a Poisson solver on GPGPUs | |
Jost et al. | An efficient multi-algorithms sparse linear solver for GPUs | |
Sætra | Shallow water simulation on GPUs for sparse domains | |
Meng et al. | Hardware accelerated alignment algorithm for optical labeled genomes | |
Kah et al. | High performance linear equation solver using nvidia gpus | |
Dubois et al. | Sparse matrix-vector multiplication on a reconfigurable supercomputer with application | |
Ghalsasi | Max-plus matrix multiplication library for GPUs-MPMML | |
Gupta | Implementation of the Deflated Preconditioned Conjugate Gradient Method for Bubbly Flow on the Graphical Processing Unit (GPU) | |
Rémy | Solving dense linear systems on accelerated multicore architectures | |
Davina et al. | Optimized analysis of isotropic high-nuclearity spin clusters with GPU acceleration |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: PEAKSTREAM INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:SUSSMAN, MYLES A.;CRUTCHFIELD, WILLIAM Y.;PAPAKIPOS, MATTHEW N.;REEL/FRAME:019346/0393Effective date: 20070419 |
|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:PEAKSTREAM, INC.;REEL/FRAME:022963/0317Effective date: 20090701 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044277/0001Effective date: 20170929 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 4TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1551)Year of fee payment: 4 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 8TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1552); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 8 |