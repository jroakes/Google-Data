CN112119454A - Automated assistant that accommodates multiple age groups and/or vocabulary levels - Google Patents
Automated assistant that accommodates multiple age groups and/or vocabulary levels Download PDFInfo
- Publication number
- CN112119454A CN112119454A CN201980032199.7A CN201980032199A CN112119454A CN 112119454 A CN112119454 A CN 112119454A CN 201980032199 A CN201980032199 A CN 201980032199A CN 112119454 A CN112119454 A CN 112119454A
- Authority
- CN
- China
- Prior art keywords
- user
- model
- natural language
- output
- given
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
- 238000000034 method Methods 0.000 claims abstract description 58
- 238000012545 processing Methods 0.000 claims abstract description 18
- 230000004044 response Effects 0.000 claims description 42
- 230000015572 biosynthetic process Effects 0.000 claims description 18
- 238000003786 synthesis reaction Methods 0.000 claims description 18
- 238000010801 machine learning Methods 0.000 claims description 15
- 230000015654 memory Effects 0.000 claims description 9
- 238000012549 training Methods 0.000 description 18
- 230000008569 process Effects 0.000 description 12
- 230000002452 interceptive effect Effects 0.000 description 11
- 230000009471 action Effects 0.000 description 10
- 235000013550 pizza Nutrition 0.000 description 10
- 239000013598 vector Substances 0.000 description 10
- 239000003795 chemical substances by application Substances 0.000 description 9
- 238000013528 artificial neural network Methods 0.000 description 8
- 241001465754 Metazoa Species 0.000 description 7
- 238000005352 clarification Methods 0.000 description 7
- 230000003993 interaction Effects 0.000 description 7
- 241000282326 Felis catus Species 0.000 description 5
- 238000013473 artificial intelligence Methods 0.000 description 5
- 235000013305 food Nutrition 0.000 description 5
- 239000000463 material Substances 0.000 description 5
- 239000008267 milk Substances 0.000 description 5
- 210000004080 milk Anatomy 0.000 description 5
- 235000013336 milk Nutrition 0.000 description 5
- 241000283086 Equidae Species 0.000 description 4
- 230000006399 behavior Effects 0.000 description 4
- 238000004891 communication Methods 0.000 description 4
- 238000010586 diagram Methods 0.000 description 4
- 230000000007 visual effect Effects 0.000 description 4
- 230000006870 function Effects 0.000 description 3
- 230000000694 effects Effects 0.000 description 2
- 230000007246 mechanism Effects 0.000 description 2
- 230000003278 mimic effect Effects 0.000 description 2
- 230000002093 peripheral effect Effects 0.000 description 2
- 230000007704 transition Effects 0.000 description 2
- 238000013519 translation Methods 0.000 description 2
- 241000894006 Bacteria Species 0.000 description 1
- 240000005561 Musa balbisiana Species 0.000 description 1
- 235000018290 Musa x paradisiaca Nutrition 0.000 description 1
- 208000003028 Stuttering Diseases 0.000 description 1
- 230000003190 augmentative effect Effects 0.000 description 1
- 244000052616 bacterial pathogen Species 0.000 description 1
- 230000008901 benefit Effects 0.000 description 1
- 230000008859 change Effects 0.000 description 1
- 230000001427 coherent effect Effects 0.000 description 1
- 238000004590 computer program Methods 0.000 description 1
- 238000012790 confirmation Methods 0.000 description 1
- 230000001351 cycling effect Effects 0.000 description 1
- 230000007812 deficiency Effects 0.000 description 1
- 230000001419 dependent effect Effects 0.000 description 1
- 238000001514 detection method Methods 0.000 description 1
- 235000013399 edible fruits Nutrition 0.000 description 1
- 230000000763 evoking effect Effects 0.000 description 1
- 230000001815 facial effect Effects 0.000 description 1
- 239000000796 flavoring agent Substances 0.000 description 1
- 235000019634 flavors Nutrition 0.000 description 1
- 239000011521 glass Substances 0.000 description 1
- 230000000977 initiatory effect Effects 0.000 description 1
- 238000003780 insertion Methods 0.000 description 1
- 230000037431 insertion Effects 0.000 description 1
- 201000003723 learning disability Diseases 0.000 description 1
- 239000004973 liquid crystal related substance Substances 0.000 description 1
- 238000013507 mapping Methods 0.000 description 1
- 235000012054 meals Nutrition 0.000 description 1
- 238000012986 modification Methods 0.000 description 1
- 230000004048 modification Effects 0.000 description 1
- 238000003058 natural language processing Methods 0.000 description 1
- 230000003287 optical effect Effects 0.000 description 1
- 244000052769 pathogen Species 0.000 description 1
- 230000001717 pathogenic effect Effects 0.000 description 1
- 230000002085 persistent effect Effects 0.000 description 1
- 238000001556 precipitation Methods 0.000 description 1
- 230000009467 reduction Effects 0.000 description 1
- 238000009877 rendering Methods 0.000 description 1
- 235000013580 sausages Nutrition 0.000 description 1
- 230000011273 social behavior Effects 0.000 description 1
- 238000010561 standard procedure Methods 0.000 description 1
- 230000001052 transient effect Effects 0.000 description 1
- 230000001960 triggered effect Effects 0.000 description 1
- 230000001755 vocal effect Effects 0.000 description 1
Images
Classifications
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/08—Speech classification or search
- G10L15/18—Speech classification or search using natural language modelling
- G10L15/1815—Semantic context, e.g. disambiguation of the recognition hypotheses based on word meaning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/903—Querying
- G06F16/9032—Query formulation
- G06F16/90332—Natural language query formulation or dialogue systems
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/903—Querying
- G06F16/9035—Filtering based on additional data, e.g. user or group profiles
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/16—Sound input; Sound output
- G06F3/167—Audio in a user interface, e.g. using voice commands for navigating, audio feedback
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/30—Semantic analysis
- G06F40/35—Discourse or dialogue representation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/40—Processing or translation of natural language
- G06F40/55—Rule-based translation
- G06F40/56—Natural language generation
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/08—Speech classification or search
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/08—Speech classification or search
- G10L15/18—Speech classification or search using natural language modelling
- G10L15/183—Speech classification or search using natural language modelling using context dependencies, e.g. language models
- G10L15/19—Grammatical context, e.g. disambiguation of the recognition hypotheses based on word sequence rules
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/22—Procedures used during a speech recognition process, e.g. man-machine dialogue
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/08—Speech classification or search
- G10L15/18—Speech classification or search using natural language modelling
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/22—Procedures used during a speech recognition process, e.g. man-machine dialogue
- G10L2015/223—Execution procedure of a spoken command
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/22—Procedures used during a speech recognition process, e.g. man-machine dialogue
- G10L2015/226—Procedures used during a speech recognition process, e.g. man-machine dialogue using non-speech characteristics
- G10L2015/227—Procedures used during a speech recognition process, e.g. man-machine dialogue using non-speech characteristics of the speaker; Human-factor methodology
Abstract
Techniques are described herein for enabling an automatic assistant to adjust its behavior depending on a detected age range and/or "vocabulary level" of a user being engaged with the automatic assistant. In various implementations, data indicative of utterances of a user may be used to estimate one or more of the age range and/or vocabulary level of the user. The estimated age range/vocabulary level may be used to affect various aspects of the data processing pipeline employed by the automated assistant. In various implementations, aspects of the data processing pipeline that may be affected by the age range/vocabulary level of the user may include one or more of the following: automatic assistant invocation, speech-to-text ("STT") processing, intent matching, intent parsing (or fulfillment), natural language generation, and/or text-to-speech ("TTS") processing. In some implementations, one or more tolerance thresholds associated with one or more of these aspects, such as grammar tolerance, lexical tolerance, and the like, may be adjusted.
Description
Background
People may engage in human-computer conversations with interactive software applications, also referred to herein as "automated assistants" (also referred to as "chat robots," "interactive personal assistants," "intelligent personal assistants," "personal voice assistants," "session agents," etc.). For example, a human being (which may be referred to as a "user" when they interact with an automated assistant) may provide commands, queries, and/or requests (collectively referred to herein as "queries") using free-form natural language input, which may include spoken utterances and/or typed free-form natural language input that are converted to text and then processed.
A user may engage with the automated assistant using a variety of different types of computing devices, such as a smart phone, a laptop computer, a tablet computer, and so forth. An "assistant device" is a computing device designed primarily or even exclusively to facilitate a human-machine conversation between a user and an automated assistant. One common example of an assistant device is a stand-alone interactive speaker that enables a user to verbally engage with an automatic assistant, e.g., by issuing a predetermined invocation phrase to activate the automatic assistant so that the automatic assistant can respond to the user's next utterance.
The interest in oral interaction by assistant devices makes them particularly suitable for use by children. However, many features built into or otherwise accessible using commercially available automated assistants may not be suitable for children. For example, if a child were to ask whether the Tooth Fairy is real, a conventional automated assistant may reply to the child's Tooth child to pull loose teth (not, the Tooth Fairy is a fictional character that the parent evoked to encourage the child to pull loose teeth) based on an online document "No. As another example, an automated assistant may be configured to engage with independent agents, such as third-party applications, that enable users to order goods/services, such as pizzas, movies, toys, etc. -this capability can be used by children who may not be able to judge all consequences of their actions. Additionally, conventional automated assistants are designed to interact with people with a fully developed vocabulary. If the user's input is not clear enough, the automated assistant may request clarification and/or disambiguation rather than attempting to resolve the user's request based on a "best guess" about the user's intent. Such long trips can cause excessive consumption of various computer and/or network resources (e.g., as a result of generating and rendering requests for clarification and/or processing the resulting input) and/or can be frustrating for children with limited vocabulary.
Disclosure of Invention
Techniques are described herein for enabling an automatic assistant to adjust its behavior depending on a detected age range and/or "vocabulary level" of a user being engaged with the automatic assistant. Thus, the automated assistant is able to use one mode, such as a "child mode," when interacting with children, and another mode, such as a "normal" or "adult" mode, when interacting with users that are not considered children (e.g., teenagers and elderly). In some implementations, the automated assistant may be capable of transitioning between a series of modes, each mode being associated with a particular age range (or alternatively, transitioning between a series of modes associated with multiple vocabulary levels). Various aspects of the behavior of the automated assistant, such as (i) recognition of the user's intent, (ii) parsing the user's intent, and (iii) how to output results of parsing the user's intent, may be affected by patterns selected based on the user's age range (or vocabulary level).
As described in greater detail herein, various implementations can enable an automated assistant to generate responses to various inputs that would not be parsable in the absence of the techniques described herein. As additionally described herein, various implementations can mitigate the need for an automated assistant to request clarification of various inputs, thereby conserving various computer and/or network resources that would otherwise be used to generate and render such requests for clarification and/or process further inputs in response to requests for clarification. In addition, an automated assistant configured with selected aspects of the present disclosure may facilitate more efficient interaction with a user in situations where the user may be generally difficult to interact with the assistant device. This may occur, for example, when the user's speech is less intelligible than the speech of an ordinary user of such a device (e.g., when the subsequent user is a young child, a disabled person with a speech affecting clarity, and/or a non-native speaker).
Although the examples herein primarily relate to determining the age range of a user and acting accordingly, this is not intended to be limiting. Various user characteristics, such as gender, location, etc., may be detected and used to influence the behavior of the automated assistant. For example, in some implementations, the vocabulary level of a user may be estimated rather than their age range, such that younger users with higher-ranked vocabulary will be properly engaged with by the automatic assistant (i.e., such that the high-ranked vocabulary children are not "refuted" by the automatic assistant). Similarly, an elderly user with a voice that utters adult sounds but with a limited vocabulary (e.g., due to learning disabilities, non-native language, etc.) may be engaged by the automated assistant in a manner that facilitates their limited vocabulary. Further, when the automated assistant communicates with the user at the same level of vocabulary used by the user, this may allow the user to know the fact that he or she has "made" his or her language "popular when communicating with the automated assistant. This may encourage the user to speak more naturally.
An automated assistant configured with selected aspects of the present disclosure may be configured to enter various age-related modes, such as "standard" (e.g., for adults) and "child mode" (e.g., for children), based on various signals. In some implementations, a parent or other adult (e.g., guardian, teacher) may cause the automated assistant to manually transition into a child mode, e.g., on demand and/or during a predetermined time interval when the child is likely to engage with the automated assistant.
Additionally or alternatively, in some embodiments, the automated assistant may automatically detect (e.g., predict, estimate) the age range of the user, for example, based on characteristics of the user's voice such as tempo, pitch, phonemes, vocabulary, grammar, pronunciation, and so forth. In some implementations, a machine learning model can be trained to generate an output indicative of a predicted age of a user based on data indicative of utterances (e.g., audio recordings, feature vectors, embedded) spoken by the user. For example, the feed-forward neural network may be trained, e.g., using training examples in the form of audio samples labeled by the age (or range of ages) of the speaker, to generate a plurality of probabilities associated with a plurality of ranges of ages (e.g., 2-4 years: 25%; 5-6 years: 38%; 7-9 years: 22%; 10-14 years: 10%; under 14 years: 5%). In various implementations, the age range with the highest probability may be selected as the factual age range for the user. In other implementations, other types of artificial intelligence models and/or algorithms may be employed to estimate the age of the user.
Additionally or alternatively, in some implementations, the automated assistant can employ voice recognition, for example, in response to a configuration of one or more users, to distinguish and identify individual speakers. For example, a family may configure one or more assistant devices in his home to recognize the voices of all family members so that each member's profile may be active when the member engages with an automated assistant. In some such implementations, the profile for each family member may include their age (e.g., date of birth), such that when identifying a speaker, the automated assistant is also able to determine the age of the speaker.
Once the age and/or age range (or vocabulary level) of the user/speaker is determined, it may affect various aspects of how the automated assistant operates. For example, in some implementations, when a speaker is determined to be a child (or another user with limited language capabilities), the automated assistant may be less strict as to what utterances will qualify as invocation phrases than if the speaker is determined to be an adult or other skilled speaker. In some implementations, the predetermined invocation phrase may be detected locally, e.g., on the client device, using one or more on-device models (e.g., trained artificial intelligence models). If it is detected that the speaker is a child, in some implementations, a calling model specifically designed for the child may be employed. Additionally or alternatively, if a single invocation model is used for all users, one or more thresholds that must be met to classify the user's utterance as a proper invocation may be lowered, e.g., so that a child's attempt to misphone at the time of invocation may still be classified as a proper invocation phrase.
As another example, the estimated age range and/or vocabulary level of the user may be used in detecting the user's intent. In various implementations, one or more candidate "query understanding models," each associated with a particular age range, may be available for use by the automated assistant. Each query understanding model may be useful in determining a user's intent, but may operate differently than other query understanding models. A "standard" query understanding model designed for adults may have a particular "grammar tolerance" that is, for example, lower than a grammar tolerance (tolerance) associated with a "children" query understanding model. For example, the child query understanding model may have such a grammar tolerance (e.g., minimum confidence threshold): even when the user's grammar/vocabulary is imperfect, the automated assistant is granted considerable room to "guess" the user's intent, as is often the case with young children. Conversely, when the automated assistant selects a "standard" query understanding model, it may have a lower grammar tolerance and thus may seek disambiguation and/or clarification from the user more quickly, rather than "guessing" or selecting a relatively lower confidence candidate intent as the user's actual intent.
Additionally or alternatively, in some implementations, the query understanding model may affect speech-to-text ("STT") processing employed by or on behalf of the automatic assistant. For example, a conventional STT processor may not be able to process a child's "giggy-like mezzo" utterance. Rather than generating a speech recognition output (e.g., text) that tracks the speech made by the user, the STT process may simply reject the utterance (e.g., because no words are identified in the dictionary), and the automated assistant may speak something like "I'm sorry, I didn't catch that (I don't understand)" and so on. However, STT processors configured with selected aspects of the present disclosure may be more tolerant of mispronunciations and/or lower-than-average grammars/vocabularies in response to determining that the speaker is a child. When a child speaker is detected, the STT processor generates speech recognition output (e.g., textual interpretations of utterances, embeddings, etc.) that tracks speech made by the user, even though the speech recognition output includes some words/phrases that are not found in the dictionary. Likewise, the natural language understanding module may utilize a child-centric query understanding model to interpret the text "giggy" as "kitty," whereas the word "giggy" may not be interpretable if an adult-centric query understanding model is used.
In some implementations, the STT processor may use a dedicated parsing module in processing the simplified syntax used by the child. In some such implementations, the dedicated parsing module may use STT models that are trained using existing techniques, but with more noisy (e.g., incomplete, grammatically ambiguous, etc.) training data. For example, in some implementations, the training data may be generated at least in part from data originally generated from an adult, but transformed according to a model of the child's vocal range form and/or by adding noise to the text input to represent an incomplete grammar.
In general, automated assistants configured with selected aspects of the present disclosure may be more active than conventional automated assistants in engaging with children. For example, and as previously described, it may be more desirable to "guess" what the child's intent is. Additionally, the automated assistant may be less critical as to the need to invoke a phrase when it detects a child speaker. For example, in some implementations, if a child yells an animal name, the automated assistant may, upon determining that the speaker is a child, forgo the requirement that the child speak the invocation phrase, and may alternatively mimic the sound made by the animal. Additionally or alternatively, the automated assistant may attempt to "teach" the child the appropriate grammar, pronunciation, and/or vocabulary, for example, in response to a grammatically incorrect and/or mispronounced voice.
Various actions and/or information may not be appropriate for the child with respect to the resolution of the user's intent. Thus, in various embodiments, based on the predicted age range of the user, the automated assistant may determine whether the user's intent is parsable. For example, if it is determined that the user is a child, the automated assistant may restrict the online corpus of data that it can use to retrieve information in response to the user's request, e.g., to a "white list" of child-friendly websites and/or a "black list" away from non-child-friendly websites. For example, the same may apply to music. If the child says "play music! (play music!) ", the automated assistant may limit the music it plays to a library of child-friendly music, rather than an adult-centric library that includes music that is typically intended for elderly individuals. The automated assistant may also not require the child user to specify a playlist or artist, and may simply play music that is appropriate for the user's detected age. Conversely, an adult "play music" request may cause the automated assistant to seek additional information about what music is to be played. In some such implementations, the volume may also be adjusted while the automated assistant is in the pediatric mode, for example, to have a lower limit than would otherwise be available in an adult situation. As another example, various actions, such as ordering goods/services through a third party application, may not be appropriate for a child. Thus, when the automated assistant determines that it is engaging with a child, it may refuse to perform various actions that may, for example, spend money or facilitate online engaging with strangers.
With respect to outputting results that resolve the user's intent, in various embodiments, the automated assistant may select a given speech synthesis model from a plurality of candidate speech synthesis models that is associated with a predetermined age group predicted for the user. For example, the default speech synthesis model employed by the automated assistant may be an adult speech that speaks at a relatively fast pace (e.g., similar to a real-life conversation between adults). Conversely, the speech synthesis model employed by the automated assistant when engaging with the child user may be the speech of a cartoon character and/or may speak at a relatively slow pace.
Additionally or alternatively, in some implementations, the automated assistant may output more or less detail depending on the predicted age of the user. This may be accomplished, for example, by providing multiple natural language generative models each tailored to a particular age group. As an example, when engaged with a user determined to be between two and four, the automated assistant may employ a suitable natural language generation model to cause the automated assistant to use simple words and short sentences. As the detected age of the speaker increases, the vocabulary used by the automated assistant may grow (e.g., according to the natural language generating model it selects) such that it uses longer sentences and more complex or advanced words. In some embodiments, the automated assistant may provide output that encourages the child user to speak in a more complete sentence, suggest alternative words, and so forth. In some implementations, words and/or phrases that would not normally require interpretation by an adult may be more fully explained by an automated assistant when engaged with a child.
Additionally or alternatively, in some implementations, a natural language generation ("NLG") template may include logic that specifies providing one natural language output when the estimated user is in a first age range and another natural language output when the estimated user is in a second age range. Thus, children may hear output intended for them (e.g., using words and/or slang appropriate for children), while adults may hear different output.
As another example, one use case commonly encountered by automated assistants is a summary of a web page (or a portion of a web page). For example, users often ask random questions that automated assistants may answer using online encyclopedia entries. The automated assistant may employ various techniques to summarize the intimate portion of the web page into a coherent answer. Using the techniques described herein, an automated assistant may consider a user's estimated age range and/or vocabulary level in summarizing an intimate portion of a web page. For example, a child may receive only advanced and/or easily understood concepts described in a web page, whereas an adult may receive more details and/or descriptions. In some embodiments, if the summary is not only abstract, but also generative, it can even be powered by and/or combined with an automatic machine translation system (e.g., an "adult english to simple english" translation system).
In some implementations, the automated assistant can be configured to report grammatical and/or lexical advances of the child. For example, when the automated assistant determines that it is engaged with an adult, or particularly when it recognizes the voice of a parent, the adult/parent user may ask the automated assistant for progress in one or more children's interactions with the automated assistant. In various implementations, the automated assistant may provide various data in response to such queries, such as words or syllables that the child often mispronounces or is stuck with, whether a stuttering tendency was detected in the child, what questions the child has asked, how the child progressed in the interactive game, and so forth.
In some implementations, a method performed by one or more processors is provided, the method comprising: receiving, at one or more input components of one or more client devices, a voiced utterance from a user; applying data indicative of a voiced utterance across a trained machine learning model to generate an output; determining, based on the output, that the user falls into a predetermined age group; selecting a given query understanding model associated with a predetermined age group from a plurality of candidate query understanding models; determining a user's intent using a given query understanding model; determining, based on a predetermined age group, that the user's intent is parsable; parsing the user's intent to generate response data; and outputting the response data at one or more output components of the one or more client devices.
In various implementations, the plurality of candidate query understanding models may include at least one candidate query understanding model having a different grammar tolerance than the grammar tolerance of the given query understanding model. In various implementations, the data indicative of the voiced utterance may include an audio recording of the utterance of the user, and the machine learning model is trained to generate an output indicative of the age of the user based on one or more phonemes contained in the audio recording.
In various implementations, the method may further include: a given natural language generative model associated with a predetermined age group is selected from a plurality of candidate natural language generative models, wherein the selected given natural language output model is used to generate response data. In various implementations, the plurality of candidate natural language generative models may include at least one candidate natural language generative model that uses a more complex vocabulary than that used by the given natural language output model.
In various implementations, the method may further include: a given speech synthesis model associated with a predetermined age group is selected from a plurality of candidate speech synthesis models, wherein outputting the response data is performed using the given speech synthesis model. In various implementations, a given query understanding model may be applied to perform speech-to-text processing of a voiced utterance. In various implementations, a given query understanding model may be applied to perform natural language understanding of speech recognition output generated from a voiced utterance.
In another aspect, a method performed by one or more processors is provided, the method comprising: receiving, at one or more input components of one or more client devices, a voiced utterance from a user; applying data indicative of a voiced utterance across a trained machine learning model to generate an output; based on the output, determining that the user falls within a given vocabulary level of a plurality of predetermined vocabulary levels; selecting a given query understanding model associated with a given vocabulary level from a plurality of candidate query understanding models; determining a user's intent using a given query understanding model; determining, based on a predetermined vocabulary level, that a user's intent is parsable; parsing the user's intent to generate response data; and outputting the response data at one or more output components of the one or more client devices.
Additionally, some embodiments include one or more processors of one or more computing devices, wherein the one or more processors are operable to execute instructions stored in an associated memory, and wherein the instructions are configured to cause performance of any of the aforementioned methods. Some embodiments also include one or more non-transitory computer-readable storage media storing computer instructions executable by one or more processors to perform any of the foregoing methods.
It should be understood that all combinations of the foregoing concepts and additional concepts described in greater detail herein are considered a part of the subject matter disclosed herein. For example, all combinations of claimed subject matter appearing at the end of this disclosure are considered part of the subject matter disclosed herein.
Drawings
FIG. 1 is a block diagram of an example environment in which embodiments disclosed herein may be implemented.
Fig. 2 depicts an exemplary process flow illustrating various aspects of the present disclosure, in accordance with various embodiments.
Fig. 3A and 3B depict example conversations between a user and an automated assistant, according to various embodiments.
Fig. 4A and 4B depict example conversations between a user and an automated assistant, according to various embodiments.
Fig. 5A and 5B depict example conversations between a user and an automated assistant, according to various embodiments.
Fig. 6 depicts a flowchart illustrating an example method according to embodiments disclosed herein.
Fig. 7 illustrates an example architecture of a computing device.
Detailed Description
Turning now to fig. 1, an example environment is illustrated in which the techniques disclosed herein may be implemented. The example environment includes one or more client computing devices 106. Each client device 106 may execute a respective instance of the automated assistant client 118. May be communicatively coupled to the client device 106 via one or more local and/or wide area networks (e.g., the internet), indicated generally at 1141-NOne or more cloud-based automated assistant components 119, such as a natural language understanding engine 135, are implemented on one or more computing systems (collectively "cloud" computing systems).
In various embodiments, the instance of the automated assistant client 108 through its interaction with the one or more cloud-based automated assistant components 119 may form what appears from the user's perspective to be a logical instance of the automated assistant 120 with which the user may engage in a human-machine conversation. An example of such an automated assistant 120 is depicted in dashed lines in fig. 1. Thus, it should be understood that each user engaged with the automated assistant client 108 executing on the client device 106 may actually engage with his or her own logical instance of the automated assistant 120. For the sake of brevity and simplicity, the term "automated assistant" as used herein to "service" a particular user will refer to a combination of an automated assistant client 108 executing on a client device 106 operated by the user and one or more cloud-based automated assistant components 119 (which may be shared among multiple automated assistant clients 108). It should also be understood that in some implementations, the automated assistant 120 may respond to requests from any user regardless of whether that particular instance of the automated assistant 120 actually "serves" that user.
The one or more client devices 106 may include, for example, one or more of the following: a desktop computing device, a laptop computing device, a tablet computing device, a mobile phone computing device, a computing device of a user's vehicle (e.g., an in-vehicle communication system, an in-vehicle entertainment system, an in-vehicle navigation system), a standalone interactive speaker, a smart appliance such as a smart television (and/or a standalone television equipped with a networked dongle with automated help capabilities), and/or a wearable apparatus including a user of a computing device (e.g., a watch of a user with a computing device, glasses of a user with a computing device, a virtual or augmented reality computing device). Additional and/or alternative client computing devices may be provided.
As described in greater detail herein, the automated assistant 120 engages in a human-machine conversation session with one or more users via user interface input and output devices of one or more client devices 106. In some implementations, the automated assistant 120 can engage in a human-machine conversation session with the user in response to user interface input provided by the user via one or more user interface input devices of one of the client devices 106. In some of those implementations, the user interface input is explicitly directed to the automated assistant 120. For example, the user may speak a predetermined invocation phrase, such as "OK, Assistant" or "Hey, Assistant," to cause the automated Assistant 120 to begin active listening.
In some implementations, the automatic assistant 120 can participate in a human-machine conversation session in response to user interface inputs even when the user interface inputs are not explicitly directed to the automatic assistant 120. For example, the automated assistant 120 may examine the content of the user interface input and participate in the conversation session in response to certain terms present in the user interface input and/or based on other prompts. In many implementations, the automated assistant 120 can utilize speech recognition to convert utterances from the user into text and respond to the text, for example, by providing search results, general information, and/or taking one or more responsive actions (e.g., playing media, starting a game, ordering a dish, etc.). In some implementations, the automated assistant 120 can additionally or alternatively respond to utterances without converting the utterances to text. For example, the automated assistant 120 may convert the speech input into an embedding, into an entity representation (indicating the entity/entities present in the speech input) and/or other "non-text" representations, and operate on such non-text representations. Thus, embodiments described herein as operating based on text converted from speech input may additionally and/or alternatively operate directly on speech input and/or other non-text representations of speech input.
Each of the client computing device 106 and the computing devices operating the cloud-based automated assistant component 119 may include one or more memories for storing data and software applications, one or more processors for accessing data and executing applications, and other components that facilitate communication over a network. The operations performed by the client computing device 106 and/or by the automated assistant 120 may be distributed across multiple computer systems. The automated assistant 120 may be implemented, for example, as a computer program running on one or more computers in one or more locations coupled to each other over a network.
As described above, in various implementations, the client computing device 106 may operate the automated assistant client 108. In various implementations, the automated assistant client 108 may include a voice capture module 110, a proficiency detector 111, and/or an invocation module 112. In other implementations, one or more aspects of the voice capture module 110, proficiency detector 111, and/or invocation module 112 may be implemented separately from the automated assistant client 108, e.g., by one or more cloud-based automated assistant components 119. In various implementations, the voice capture module 110 may interface with hardware such as a microphone (not depicted) to capture an audio recording of the user utterance. Various types of processing may be performed on the audio recording for various purposes, as described below.
In various implementations, the proficiency detector 111, which may be implemented using any combination of hardware or software, may be configured to analyze audio recordings captured by the voice capture module 110 to make one or more determinations based on the user's apparent speech proficiency. In some implementations, these determinations may include making predictions or estimates of the age of the user, such as, for example, classifying the user as one of a plurality of age ranges. Additionally or alternatively, these determinations may include making predictions or estimates of the user's vocabulary level, or classifying the user as one of a plurality of vocabulary levels. As will be described below, the determinations made by the proficiency detector 111 may be used, for example, by various components of the automatic assistant 120 to accommodate users of multiple different age groups and/or vocabulary levels.
The proficiency detector 111 may employ various techniques to make the determination regarding the user's speaking proficiency. For example, in fig. 1, proficiency detector 111 is communicatively coupled with proficiency model database 113 (which may be integrated with client device 106 and/or hosted remotely from client device 106, e.g., in the cloud). Proficiency model database 113 may include one or more artificial intelligence (or machine learning) models that are trained to generate an output indicative of the user's speaking proficiency. In various implementations, an artificial intelligence (or machine learning) model may be trained to generate an output indicative of the age of the user based on one or more phonemes contained in the audio recording, pitch of the user's voice detected in the audio recording, pronunciation, and so forth.
As one non-limiting example, the neural network may be trained (and stored in the database 113) such that an audio recording of the user's utterance, or feature vectors extracted from the audio recording, may be applied as input across the neural network. In various implementations, the neural network may generate a plurality of outputs, each output corresponding to an age range and an associated probability. In some such implementations, the age range with the highest probability may be used as a prediction of the user's age range. Such a neural network may be trained using various forms of training examples, such as audio recordings (or feature vectors generated therefrom) of users tagged by their respective ages (or age ranges). When applying training examples across a network, differences between the generated output and the labels associated with the training examples may be used, for example, to minimize a loss function. The various weights of the neural network may then be adjusted, for example, using standard techniques such as gradient descent and/or back propagation.
The voice capture module 110 may be configured to capture the user's speech, for example, via a microphone (not depicted), as previously described. Additionally or alternatively, in some implementations, the voice capture module 110 may be further configured to convert the captured audio to text and/or other representations or embedding, for example, using speech-to-text ("STT") processing techniques. Additionally or alternatively, in some implementations, the voice capture module 110 may be configured to convert text to computer-synthesized speech, for example, using one or more speech synthesizers. However, because the client device 106 may be relatively constrained in terms of computing resources (e.g., processor cycles, memory, battery, etc.), the voice capture module 110 local to the client device 106 may be configured to convert a limited number of different spoken phrases, particularly phrases that invoke the automated assistant 120, into text (or other forms, such as lower-dimensional embedding). Other voice inputs may be sent to the cloud-based automatic assistant component 119, which may include the cloud-based TTS module 116 and/or the cloud-based STT module 117.
In some implementations, the client device 106 can include an invocation module 112 configured to determine whether the utterance of the user qualifies as an invocation phrase that should initiate a human-to-machine conversation session with the automated assistant 120. Once the age (or age range) of the user is estimated by the proficiency detector 111, in some implementations, the invocation module 112 may analyze data indicative of the utterance of the user, such as an audio recording or a feature vector extracted from the audio recording in conjunction with the estimated age range of the user (e.g., embedded). In some implementations, the threshold employed by the invocation module 112 to determine whether to invoke the automated assistant 120 may be lowered as the estimated age of the user falls within one or more age ranges, such as age ranges associated with young children. Thus, when engaged with a small child, phrases such as "OK assisa," which are different from the appropriate call phrase "OK assistant," but are somewhat similar in pronunciation to the appropriate call phrase, may still be accepted as calls.
Additionally or alternatively, the on-device invocation model may be used by the invocation module 112 to determine whether an utterance qualifies as an invocation. Such on-device invocation models may be trained to detect common changes to the invocation phrase. For example, in some implementations, an on-device call model (e.g., one or more neural networks) may be trained using training examples, each of which includes an audio recording (or extracted feature vector) of a child's utterance. Some training examples may include attempts by children to issue appropriate call phrases; such training examples may be positive training examples. Additionally, in some implementations, some training examples may include other utterances from the child that are not attempts to speak the invocation phrase. These other training examples may be used as negative training examples. Training examples (positive and/or negative) can be applied as input across on-device invocation models to generate output. The output may be compared to labels associated with training examples (e.g., positive or negative), and the on-device call model may be trained using the difference (error function), e.g., using techniques such as gradient descent and/or backpropagation. In some implementations, if the on-device call model indicates that the utterance qualifies as a call, but the confidence score associated with the output is relatively low (e.g., because the utterance was generated by a child who is prone to mispronunciation), the low confidence score itself may be used, for example, by the proficiency detector 111 to estimate the age of the child.
Cloud-based TTS module 116 may be configured to leverage the potentially larger computing resources of the cloud to convert text data (e.g., natural language responses formulated by automated assistant 120) into computer-generated speech output. In some implementations, the TTS module 116 can provide the computer-generated speech output to the client device 106 to be directly output, e.g., using one or more speakers. In other implementations, text data (e.g., natural language responses) generated by the automated assistant 120 can be provided to the voice capture module 110, which can then convert the text data into locally output computer-generated voice. In some implementations, cloud-based TTS module 116 can be operatively coupled with database 115 that includes a plurality of speech synthesis models. When interacting with users having particular spoken language capabilities and/or in particular age groups, the automated assistant 120 may employ each speech synthesis model to generate computer speech that simulates a particular type of speech, e.g., a man, a woman, a cartoon character, a speaker having a particular accent, etc.
In some implementations, the TTS module 116 may employ a particular speech synthesis model as desired. For example, assume that automated Assistant 120 is typically called with the phrase "Hey Assistant". In some implementations, the model used to detect this phrase (e.g., the previously described on-device call model) can be modified, for example, so that it responds to any utterance of "Hey, < entity >,". In some such implementations, the requested < entity > may be used by TTS module 116 to select the speech synthesis model to employ. Thus, if a child invokes an automated assistant by speaking something like "Hey, synthetic Hippo," a speech synthesis modality associated with the entity "synthetic Hippo" can be employed.
The cloud-based STT module 117 may be configured to utilize the potentially larger computing resources of the cloud to convert the audio data captured by the voice capture module 110 into text, which may then be provided to the natural language understanding module 135. In various implementations, cloud-based STT module 117 may employ one or more custom parsers and/or STT models (sometimes referred to herein in terms of the colossal term "query understanding model") that are specifically tailored for interpreting utterances of a user, such as a child, having limited and/or underdeveloped vocabulary and/or syntax.
For example, in some implementations, the cloud-based STT module 117 can be operatively coupled with one or more databases 118 that store a plurality of query understanding models. Each query understanding model may be configured for use with users of a particular age range. In some implementations, each query understanding model can include an artificial intelligence model (e.g., a neural network of various flavors) trained to generate text from speech based on audio input (or data indicative of audio input, such as phonemes and/or other features of the audio input extracted into feature vectors). In some such implementations, the training data for such models may include audio recordings from adults (or data indicative thereof) tagged with actual text, e.g., speech, having noise injected therein. Additionally or alternatively, in some implementations, the training data may include an audio recording from the child tagged with text of the child's voice.
In some implementations, the cloud-based STT module 117 can convert the audio recording of the voice to one or more phonemes and then convert the one or more phonemes to text. Additionally or alternatively, in some implementations, the STT module 117 may employ a state decoding graph. In some implementations, the STT module 117 can generate a plurality of candidate text interpretations of the user's utterance. With a conventional automated assistant 120, the candidate text interpretation with the highest associated confidence score may be accepted as a free-form input by the user, as long as the confidence score meets a certain threshold and/or has a confidence score that is sufficiently better than the confidence scores associated with other candidate text interpretations. Otherwise, the automated assistant 120 may ask the user to clarify and/or disambiguate. Such thresholds may be lowered with the STT module 117 configured with selected aspects of the present disclosure. Thus, even if the user's utterance (e.g., a statement from a toddler) demonstrates a grammar/vocabulary deficiency, the automated assistant 120 may be more likely to attempt to satisfy the user's intent.
The automatic assistant 120, and in particular the cloud-based automatic assistant component 119, may include a natural language understanding module 135, the aforementioned TTS module 116, the aforementioned STT module 117, and other components that will be described in greater detail below. In some implementations, one or more modules and/or modules of the automated assistant 120 may be omitted, combined, and/or implemented in a component separate from the automated assistant 120. In some implementations, to protect privacy, one or more of the components of the automatic assistant 120, such as the natural language processor 122, the TTS module 116, the STT module 117, etc., may be implemented at least partially on the client device 106 (e.g., excluded from the cloud).
In some implementations, the automated assistant 120 responds to the request by the client device 106 during a human-to-machine conversation session with the automated assistant 1201-NOne of the various inputs generated by the user generates responsive content. The automated assistant 120 can provide response content (e.g., over one or more networks when separate from the user's client device) for presentation to the user as part of a conversation session. For example, the automated assistant 120 may generate responsive content in response to free-form natural language input provided via the client device 106. As used herein, free-form input is input that is formulated by a user and is not constrained to be presented to the user as a set of options for selection.
As used herein, a "conversation session" may include a logically self-contained exchange of one or more messages between a user and the automated assistant 120 (and in some cases, other human participants). The automatic assistant 120 can distinguish between multiple dialog sessions with the user based on various signals, such as time lapse between sessions, changes in user context between sessions (e.g., location, before/during/after scheduled meetings, etc.), detection of one or more intervening interactions between the user and client devices other than the dialog between the user and the automatic assistant (e.g., the user temporarily switches applications, the user goes away and then returns to a separate voice-activated product later), locking/sleeping of client devices between sessions, changes in client devices for interacting with one or more instances of the automatic assistant 120, and so forth.
The natural language processor 122 of the natural language understanding module 135 processes natural language input generated by a user via the client device 106 and may generate annotated output (e.g., in textual form) for use by one or more other components of the automated assistant 120.For example, the natural language processor 122 may process data received by a user via the client device 1061The one or more user interface input devices of (a) generating a natural language free form input. The generated annotation output includes one or more annotations of the natural language input and one or more (e.g., all) of the terms of the natural language input.
In some implementations, the natural language processor 122 is configured to recognize and annotate various types of grammatical information in the natural language input. For example, the natural language processor 122 may include a lexical module that may separate individual words into morphemes and/or annotate the morphemes, e.g., with their categories. The natural language processor 122 may also include a part-of-speech tagger that is configured to annotate the term with its grammatical role. For example, a part-of-speech tagger may tag each term with a part-of-speech of the term, such as "noun," "verb," "adjective," "pronoun," and so on. Further, for example, in some implementations, the natural language processor 122 may additionally and/or alternatively include a dependency parser (not depicted) configured to determine syntactic relationships between terms in the natural language input. For example, a dependency parser may determine which terms modify other terms, subjects and verbs of sentences, and so on (e.g., parse trees) — and may annotate such dependencies.
In some implementations, the natural language processor 122 can additionally and/or alternatively include an entity annotator (not depicted) configured to annotate entity references, such as references to persons (including, e.g., literary characters, celebrities, public characters, etc.), organizations, locations (both real and fictional), and so forth, in one or more paragraphs. In some implementations, data about the entities may be stored in one or more databases, such as in a knowledge graph (not depicted). In some implementations, the knowledge graph can include nodes representing known entities (and in some cases, entity attributes), and edges connecting the nodes and representing relationships between the entities. For example, a "banana" node may be connected (e.g., as a child) to a "fruit" node, which may in turn be connected (e.g., as a child) to a "product" and/or "food" node. As another example, a restaurant called a "virtual cafe" may be represented by a node that also includes attributes such as its address, the type of food served, business hours, contact information, and the like. In one embodiment, the "contextual Caf" node may be connected by edges (e.g., representing a child-to-parent relationship) to one or more other nodes, such as a "restaurant" node, a "business" node, a node representing a city and/or state in which the restaurant is located, and so forth.
The entity annotator of the natural language processor 122 can annotate references to entities at a higher level of granularity (e.g., enabling identification of all references to an entity category such as a person) and/or a lower level of granularity (e.g., enabling identification of all references to a particular entity such as a particular person). The entity annotator can rely on the content of the natural language input to resolve (resolve) a particular entity and/or can optionally communicate with a knowledge graph or other entity database to resolve a particular entity.
In some implementations, the natural language processor 122 may additionally and/or alternatively include a coreference parser (not depicted) configured to group or "cluster" references to the same entity based on one or more contextual cues. For example, a coreference parser may be utilized to parse the term "there" in the natural language input "I liked contextual Caf time we ate there" (I likes the Hypothetical cafe where he last had a meal) into "contextual Caf".
In some implementations, one or more components of the natural language processor 122 may rely on annotations from one or more other components of the natural language processor 122. For example, in some implementations, the named entity tagger can rely on annotations from the coreference parser and/or the dependency parser in annotating all mentions of a particular entity. Also, for example, in some implementations, when clustering references to the same entity, the coreference resolver may rely on annotations from dependent resolvers. In some implementations, in processing a particular natural language input, one or more components of the natural language processor 122 may use related previous inputs and/or other related data in addition to the particular natural language input to determine one or more annotations.
The natural language understanding module 135 may also include an intent matcher 136 configured to determine the intent of a user participating in a human-machine conversation session with the automatic assistant 120. Although depicted separately from the natural language processor 122 in fig. 1, in other implementations, the intent matcher 136 may be an integral part of the natural language processor 122 (or more generally, a pipeline that includes the natural language processor 122). In some implementations, the natural language processor 122 and the intent matcher 136 may collectively form the aforementioned "natural language understanding" module 135.
The intent matcher 136 may use various techniques to determine the intent of the user, for example, based on the output from the natural language processor 122 (which may include annotations and words of the natural language input). In some implementations, the intent matcher 136 may be capable of accessing one or more databases 137 that include, for example, a plurality of mappings between grammars and response actions (or, more generally, intents). In many cases, these grammars may be selected and/or learned over time and may represent the most common intent of the user. For example, a syntax "play < artist >" may be mapped to an intent to invoke a responsive action that causes music of < artist > to be played on a client device 106 operated by the user. Another grammar "[ weather | forecast ] today" may be able to match user queries such as "what's the weather today" and "what's the weather for today". In addition to or instead of a grammar, in some implementations, the intent matcher 136 may employ one or more trained machine learning models, alone or in combination with one or more grammars. These trained machine learning models may also be stored in one or more databases 137 and may be trained to identify intents, for example, by embedding data indicative of the user's utterance into a reduced-dimensional space, and then determining which other insertions (and thus intents) are closest, for example, using techniques such as euclidean distance, cosine similarity, and the like.
As seen in the "play < artist >" example syntax, some syntaxes have slots (e.g., < artist >) that can be filled with slot values (or "parameters"). The slot value may be determined in various ways. Often the user will actively provide the slot value. For example, for the grammar "Order me a < ordering > pizza", the user is likely to speak the phrase "Order me a usage pizza" (Order me a sausage pizza) "in which case the slot < ordering > is automatically filled. Additionally or alternatively, if the user invokes a grammar that includes slots to be filled with slot values, without the user actively providing the slot values, the automated assistant 120 may solicit those slot values from the user (e.g., "what type of crust you want on your pizza.
In some implementations, the automated assistant 120 can facilitate (or "arrange") transactions between the user and the agent, which can be separate software processes that receive input and provide responsive output. Some agents may take the form of third party applications that may or may not operate on a computing system separate from the computing system that operates, for example, cloud-based automated assistant component 119. One user intent that may be identified by the intent matcher 136 is to engage a third party application. For example, the automated assistant 120 may provide a pizza delivery service with access to an application programming interface ("API"). The user may invoke the automated assistant 120 and provide a command such as "I'd like to order a pizza". The intent matcher 136 may map this command to a grammar that triggers the automated assistant 120 to engage with third party pizza delivery services (which may be added to the database 137 by third parties in some cases). The third party pizza delivery service may provide the automated assistant 120 with a minimal list of slots that need to be filled in order to fulfill the pizza delivery order. The automated assistant 120 may generate and provide (via the client device 106) to the user a natural language output that solicits parameters for the slot.
In various implementations, the intent matcher 136 may be capable of accessing a library of multiple sets of grammars and/or training models, for example, in a database 137. Each grammar and/or model set may be designed to facilitate interaction between the automated assistant 120 and users of a particular age range and/or vocabulary level. In some implementations, these grammars and/or models can be part of the aforementioned "query understanding model" in addition to or instead of the model described above with respect to the STT module 117 (e.g., stored in the database 118). Thus, in some implementations, the query understanding model may include components used during both STT processing and intent matching. In other implementations, the query understanding model may include components that are used only during STT processing. In still other implementations, the query understanding model may include components that are used only during intent matching and/or natural language processing. Any combination of these variations is contemplated herein. If a query understanding model is employed during both STT processing and intent matching, in some implementations, databases 118 and 137 may be combined.
As an example, a first set of grammars and/or models (or "query understanding models") stored in database 137 may be configured to facilitate interaction with very young children, such as toddlers under the age of two. In some such implementations, such a set of grammars/models may be relatively tolerant of errors in grammar, vocabulary, pronunciation, etc., and may do something like making animal noise, for example, when a child speaks the name of an animal. Another grammar and/or set of models may be configured to facilitate engagement with children between the ages of two and four and/or others with a limited vocabulary (e.g., users in the process of learning a language employed by the automated assistant 120). Such a set of grammars and/or models may have a somewhat lower tolerance for errors, but it may still be relatively loose. Another grammar and/or model set may be configured to facilitate engagement with "next" age ranges and/or vocabularies, such as five to seven years of age and/or intermediate speakers, and may be even less error tolerant. Yet another grammar and/or model set may be configured to facilitate "normal" engagement with adults, older children, and/or other relatively skilled speakers-the tolerance for errors in grammar, vocabulary, and/or pronunciation may be relatively low for such grammar/model sets.
The fulfillment module 124 may be configured to receive the predicted/estimated intent and associated slot values output by the intent matcher 136 (whether actively provided by or solicited from the user), and to fulfill (or "resolve") the intent. In various implementations, fulfillment (or "resolution") of the user's intent may cause various fulfillment information (also referred to as "response" information or data) to be generated/obtained, for example, by fulfillment module 124. As will be described below, the fulfillment information may be provided in some implementations to a natural language generator (in some figures, "NLG") 126, which may generate a natural language output based on the fulfillment information.
Fulfillment information may take various forms as the intent can be fulfilled in various ways. Suppose that a user requests pure information, such as "Where wee The outdoor notes of The Shining' filed? (where is the outdoor shot of ' sprite) ' the user's intent may be determined, for example, by the intent matcher 136 as a search query. The intent and content of the search query may be provided to a fulfillment module 124, which, as depicted in fig. 1, may be in communication with one or more search modules 150 configured to search a corpus of documents and/or other data sources (e.g., knowledge graphs, etc.) for responsive information. The fulfillment module 124 may provide data indicative of the search query (e.g., text of the query, dimension reduction embedding, etc.) to the search module 150. The search module 150 may provide responsive information such as GPS coordinates or other more explicit information such as "Timberline Lodge, Mt. hood, Oregon (the Huddling line Stack, Oregon)". This response information may form part of the fulfillment information generated by fulfillment module 124.
Additionally or alternatively, fulfillment module 124 may be configured to receive the user's intent and any slot values provided by or determined using other means (e.g., the user's GPS coordinates, user preferences, etc.) and trigger responsive actions, e.g., from natural language understanding module 135. The responsive action may include, for example, ordering goods/services, starting a timer, setting a reminder, initiating a phone call, playing media, sending a message, etc. In some such implementations, fulfillment information may include slot values associated with fulfillment, confirmation responses (which may be selected from predetermined responses in some cases), and so on.
In some implementations, and similar to other components herein, such as STT module 117, intent matcher 136, fulfillment module 124 may be able to access a database 125 that stores a library of rules, heuristics, etc., for various age ranges and/or vocabulary levels. For example, the database 125 may store one or more white lists and/or black lists of websites, Universal Resource Identifiers (URIs), Universal Resource Locators (URLs), domains, etc., that specify what the user can and cannot access depending on the age of the user. Database 125 may also include one or more rules that specify how and/or whether the user can engage automated assistant 120 with third party applications that, as noted above, can be used, for example, to order goods or services.
As noted above, the natural language generator 126 may be configured to generate and/or select natural language output (e.g., words/phrases designed to mimic human speech) based on data obtained from various sources. In some implementations, the natural language generator 126 may be configured to receive as input fulfillment information associated with fulfillment of the intent, and generate a natural language output based on the fulfillment information. Additionally or alternatively, the natural language generator 126 may receive information from other sources, such as third party applications (e.g., required slots), which it may use to compose a natural language output for the user.
If the user's intent is to search for general information, the natural language generator 126 may generate a natural language output that conveys information responsive to the user, for example, in sentence form. In some instances, the natural language output may be extracted, for example, by the natural language generator 126, not altered from the document (e.g., because it is already in full sentence form) and provided as is. Additionally or alternatively, in some implementations, the responsive content may not be in full sentence form (e.g., a request for weather today may include high temperature and precipitation opportunities as separate pieces of data), in which case the natural language generator 126 may formulate one or more full sentences or phrases that present the responsive content as natural language output.
In some implementations, the natural language generator 126 can generate natural language output by relying on what will be referred to herein as a "natural language generation template" (or "NLG template"). In some implementations, the NLG template can be stored in the database 127. The NLG template may include logic (e.g., if/else statements, loops, other programming logic) that specifies formulating natural language output in response to various information from various sources, such as pieces of data that include fulfillment information generated by fulfillment module 124. Thus, in some ways the NLG templates may actually constitute state machines and may be created using any known programming language or other modeling language (e.g., a unified modeling language, a specification and description language, an extensible markup language, etc.).
As an example, the NLG template may be configured to respond to english language requests for weather information. The NLG template may specify which of a plurality of candidate natural language outputs to provide in a plurality of instances. For example, assume that the fulfillment information generated by fulfillment module 124 indicates that the temperature will be above, for example, 80 degrees fahrenheit and will be free of clouds. The logic set forth in the NLG template (e.g., if/else statements) may specify that the natural language output selected by the natural language generator 126 is a phrase such as "It's gonna be a scorcher, don't for get your sunglass (weather may be hot, forget your sunglasses else)". Assume that the fulfillment information generated by fulfillment module 124 indicates that the temperature will be below, for example, 30degrees fahrenheit and there will be snow. The logic set forth in the NLG template may specify that the natural language output selected by the natural language generator 126 is a phrase such as "It's gonna be hilly, you might wait a hat and gloves, and be careful on the road" and the like.
In some implementations, the NLG template can include logic that is affected by the detected vocabulary level and/or age range of the user. For example, an NLG template may have the logic: the first natural language output is caused to be provided if the predicted user is within a first age range, and the second natural language output is caused to be provided if the predicted user is within another, e.g., older, age range. The first natural language output may use more explanatory words and/or phrases with simpler languages so that a younger user may be more likely to understand it. The second natural language output may be less complex than the first natural language output under the assumption that older users do not need as much explanation.
In the weather example above, adults and children may be told different things based on logic in the NLG template. For example, if the weather is cold, a detected child may be provided with a natural language output that alerts the child to take precautionary measures that would not require alerting an adult. For example, the natural language output provided to the child may be: "It's gonana be COOOLLDD outtide and may even grow snow! Don't get your coat, scarf, mitens, and hat. In contrast, the natural language output provided to adults under the same circumstances may be "It's going to be 30degrees Fahrenheit with a 20% change of snow (weather would be 30degrees Fahrenheit with a 20% chance of snowing)".
As another example, an NLG template may be configured to query as to whether some entity Is real or imaginary, e.g., "Is < entry _ name > real? (< do entity _ name > is true) "responds. Such NLG templates may include logic that is chosen from a plurality of options depending on the predicted age range of the user. Suppose that the user asks "Is the tooth facial real? (is it true) "if the user is predicted to be a small child, then logic within the NLG template can specify an answer somewhat like" Yes, the tooth hair leaves one under pillow of child's wooly (Yes, when the child falls off their teeth) "to the child. If the predicted user is an adult, logic within the NLG template may specify an answer in the form of a "No," the tooth face is a make-believe entry embedded by entries and guides to mobile child in order to get money in exchange for a false tooth adopted by parents and guardians.
Fig. 2 demonstrates an example of how utterances from the user 201 may be processed by the various components of fig. 1 depending on the predicted/estimated age of the user 201. Components related to the techniques described herein are depicted, but this is not intended to be limiting, and various other components not depicted in fig. 2 may be used as part of processing the user's utterance.
When a user provides a voiced utterance, an input/output ("I/O") component of a client device (e.g., 106) operated by the user 201, such as a microphone, can capture the utterance of the user as an audio recording ("audio recording" in fig. 2). The audio recording may be provided to the proficiency detector 111, which predicts and/or estimates the age range and/or vocabulary level of the user 201 as described above.
The estimated age range or vocabulary level is then provided to the invocation module 112. Based on the estimated age range and data indicative of the user's utterance (e.g., audio recording, feature vector, embedding), the invocation module 112 may classify the user's utterance as intended or not intended to trigger the automatic assistant 120. As noted above, for a child or another user with a relatively low vocabulary level, the threshold that must be met for the invocation module 112 to classify the utterance as a proper invocation may be lowered.
In some implementations, the threshold employed by the invocation module 112 may also be lowered based on other signals, such as detected ambient noise, motion (e.g., driving a vehicle), etc. One reason for lowering the threshold based on these other signals is that there may be more noise in the user's utterance when these other signals are detected than if the user's utterance were made in a quiet environment. In such cases, it may be desirable for the automated assistant 120 to be more easily invoked, particularly if the user is driving or cycling.
Referring again to fig. 2, once the automatic assistant 120 is triggered, the STT module 117 may use the audio recording (or data indicative of the user's utterance) in conjunction with the estimated age range/vocabulary level to select one or more thresholds and/or models (e.g., from the database 113). As noted above, these thresholds/models may be part of a "query understanding model". The STT module 117 may then generate as output a textual interpretation of the user's utterance. This text interpretation may be provided to the natural language processor 122, which annotates and/or otherwise processes the text interpretation as described above. The output of the natural language processor 122 is provided to the intent matcher 136 along with the estimated age range or vocabulary level of the user 201.
The intent matcher 136 may select one or more grammars and/or models, for example, from the database 137 based on the detected/predicted age of the user 201. In some implementations, some intentions may not be available due to the predicted/estimated age range or vocabulary level of the user 201. For example, when the estimated age range or vocabulary level of the user is determined to be, for example, below a threshold, an intent related to the automated assistant 120 interacting with a third-party application, particularly a third-party application that requires capital expenditures and/or is otherwise unsuitable for children, may not be allowed, for example, by one or more rules stored in the database 137. Additionally or alternatively, in some implementations, the rules may be stored and/or implemented elsewhere, such as in database 125.
The intent determined by the intent matcher 136, as well as the estimated age range or vocabulary level and any user-provided slot values (if applicable), may be provided to the fulfillment module 124. Fulfillment module 124 may fulfill the intent in accordance with various rules and/or heuristics stored in database 125. The fulfillment information generated by the fulfillment module 124 may be passed to the natural language generator 126, e.g., along with the estimated age range and/or vocabulary level of the user. The natural language generator 126 may be configured to generate a natural language output in accordance with the fulfillment information and the estimated age range and/or vocabulary level of the user. For example, and as previously described, the natural language generator 126 may implement one or more NLG templates that include logic to generate natural language output depending on the user's estimated age range and/or vocabulary level.
The text output generated by the natural language generator 126 may be provided to the TTS module 116 along with the user's estimated age range and/or vocabulary level. The TTS module 116 may select one or more voice synthesizers from the database 115 to be used by the automatic assistant 120 to deliver audio output to the user based on the estimated age range and/or vocabulary level of the user. The audio output generated by TTS module 116 may be provided to one or more I/O components 250 of a client device operated by user 201 such that the audio output may be audibly output via one or more speakers and/or visually on one or more displays.
Fig. 3A and 3B depict example scenarios in which techniques described herein may be employed. In fig. 3A, a first user 301A is a relatively young child that is attempting to engage with an automated assistant 120 operating at least partially on a client device 306. In this example, the client device 306 takes the form of an assistant device and more specifically a stand-alone interactive speaker, although this is not intended to be limiting.
The first user 301A speaks "OK, Assisa, wanna music" (good, assistant, want music) "that can be captured as an audio recording and/or as a vector of features extracted from the audio recording. The automated assistant 120 may first estimate the age range of the user 301A based on the audio recordings/feature vectors. In some implementations, the proficiency detector 111 may analyze features such as phonemes, pitch, tempo, and so forth to estimate the age of the user 301A. Additionally or alternatively, in some implementations, the audio recording may be processed by other components of the automatic assistant 120 (such as the STT module 117) to generate a textual explanation of the user's utterance. This textual explanation may be analyzed, for example, by proficiency detector 111, to estimate/predict grammatical and/or lexical proficiency of user 301A (which may be used as a proxy for the age of the user in some cases).
Once the automated assistant 120 has been invoked, it may analyze the remainder of the utterance from the user 301A, the "Wanna music". Such phrases may cause a conventional automated assistant to seek disambiguation and/or clarification from the user 301A. However, an automated assistant 120 configured with selected aspects of the present disclosure may have a higher tolerance for grammatical, lexical, and/or pronunciation errors than conventional automated assistants. Thus, and using a process such as that previously described with respect to fig. 2, various components of the automated assistant 120 may use the estimated age range and/or vocabulary level to select various models, rules, grammars, heuristics, etc. at different points in the pipeline of fig. 2 to process and fulfill the user's request. In this case, the automated assistant 120 may respond by outputting music (e.g., nursery rhymes, songs from children's televisions and movies, educational music, etc.) for the child (output music for children).
Fig. 3B depicts another example of another child user 301B again interacting with the automated assistant 120 using the client device 306. In this example, user 301B again speaks "Hay assisi, Giggy gat," which is not interpretable by a conventional automated assistant. However, the automated assistant 120 configured with selected aspects of the present disclosure may estimate/predict that the user 301B is in a low age range, e.g., 2-3 years old. Thus, the automated assistant 120 may be more tolerant of grammatical, lexical, and/or pronunciation errors. Because it is a child engaged with the automated assistant, the phrase "Giggy gat" may be more loosely interpreted as "kitty cat".
Further, if an adult user is where to invoke the automated assistant 120 and simply says "kitty cat," the automated assistant 120 may not be able to respond because the adult user's intent is unclear. However, using the techniques described herein, the automated assistant 120, e.g., through the intent matcher 136 and/or fulfillment module 124, may determine the intent of the user 301B as the sound to be made by the cat based on such interpretation and the estimated age range of the user 301B. As a result, the automated assistant 120 can output a sound of cat mewing (outputs sound of cat viewing).
Fig. 4A depicts yet another example of a child user 401A interacting with an automated assistant 120 operating at least partially on a client device 406A, again in the form of an assistant device, and more particularly a stand-alone interactive speaker. In this example, user 401A asks "OK assisa, what grown numbers put mill in frigger? (good assistant, why is the adult put milk in the refrigerator)' such a problem may not be explained by a conventional automatic assistant due to its various grammatical and lexical errors and various wrong sounds. However, an automated assistant 120 configured with selected aspects of the present disclosure may be more tolerant of such errors, and thus may be able to handle the problem from user 401A. Additionally, in some implementations, the automated assistant 120 can be configured to teach the user 401A the appropriate grammar and/or vocabulary. This is true whether the user is a child (as shown in fig. 4A) or a user whose language used by the automated assistant 120 is not native.
In FIG. 4A, before answering The user's question, The automated assistant 120 states "The person way to ask at query is,' what do grown null put mile in The repeater? (ask that question in a suitable way is "why is the adult put the milk in the refrigerator)". This statement is intended to guide the user 401A with respect to the appropriate grammar, vocabulary, and/or pronunciation. In some implementations, the automated assistant 120 can monitor utterances of a particular user over time to determine whether the user's vocabulary is improving. In some such implementations, if the user demonstrates an increased vocabulary level from one dialog session to the next, the automatic assistant 120 may congratulate the user or otherwise provide encouragement, e.g., so that the user continues to improve linguistically. In some implementations, another user, such as a parent, teacher, or guardian of the child, may ask the automated assistant 120 for updates regarding the language advancement of the child. The automated assistant 120 may be configured to provide data indicative of the progress of the child (e.g., as a natural language output, as a result of display on a screen, etc.).
Once the automated assistant 120 has provided the user 401A with language guidance, it then provides information (e.g., obtained by the fulfillment module 124 from one or more websites) that is responsive to the user's query, but in a manner selected based on the estimated age range and/or vocabulary of the user 401A. In this example, the automated assistant 120 states "because a pathogen grows in milk outside the refrigerator and makes it unpalatable". "such an answer is obviously customized for the child. This can be done in various ways. In some implementations, components such as fulfillment module 124 and/or natural language generator 126 may replace relatively complex words such as "bacteria", "spot", "transient" or "curdle" with simple words such as "germs" and "yucky" based on an estimate that user 401A is a child. If the adult asks the same question, the automated assistant 120 may have generated an answer such as: "Milk is a durable food and a therorefield is at a risk while key out of a food refragerator, Milk is a perishable food and therefore risks when held outside the refrigerator. In other implementations, one or more NLG templates may be employed to influence the output to the estimated age range and/or vocabulary level of user 401A.
In various implementations, various different functionalities may be provided (or blocked) depending on the predicted age of the user. For example, in some implementations, various games or other activities directed to a child may be provided to a child user. In some such implementations, different games may be provided and/or recommended to the user depending on the predicted age range of the user. Additionally or alternatively, the same game may be available/recommended, but may be set more difficult for users in a higher age range.
Fig. 4B depicts another example scenario in which a child user 401B interacts with the automated assistant 120. Unlike the previous example, in this example, the automated assistant 120 operates at least in part on a client device 406B in the form of a smart television or a standard television equipped with a digital media player dongle (not depicted). In this example, it can be assumed that the automated assistant 120 has predicted/estimated that the user 401B is a young child, e.g., in the range of two to four years of age.
In this example, user 401B issues "Let's play a game". Based on the predicted age range of the user, the automated assistant 120 may, for example, randomly select a game to play from a set of games customized for the age range of the user 401B and/or randomly from all games (where games for the age range of the user 401B are weighted more heavily). Additionally or alternatively, user 401B may be presented with a list of games that are appropriate for user 401B (e.g., viewable on client device 406B).
The automated assistant 120 then causes the client device 406B to visibly render four zebras (e.g., still images, animations, etc.) on its display. The automated assistant 120 asks "How zebras do you see? (how many zebras you see. In other implementations, the user can speak something like "I se this many" (I see so much) "and lift her finger. The automated assistant 120 may count the fingers, for example, by analyzing digital images captured by a camera (not depicted) of the client device 406B. Either way, the automated assistant 120 may determine that "four" matches the number of rendered zebras and may respond to the "Great job! (Tai excellent!) ".
In fig. 4B, user 401B uses a smart television (or a standard television equipped with a smart television dongle) exclusively to engage with automated assistant 120. However, this is not intended to be limiting. In other implementations, user 401B may engage with automated assistant 120 using a different client device, such as a stand-alone interactive speaker, and may still render the visual aspects of this example on a television screen. For example, the smart television and interactive standalone speaker may be part of the same coordinated "ecosystem" of client devices, e.g., controlled by a single user (e.g., a parent or homeowner) or associated with all members of a family (or other groups such as colleagues, neighbors, etc.).
In some implementations, the detected/predicted/estimated features of the user may be used, for example, by the automated assistant 120 as slot values for use in performing various tasks. These tasks may include, for example, automated assistant 120 engaging with one or more "agents". As previously noted, as used herein, an "agent" may refer to a process that receives input, such as a slot value, intent, etc., for example, from an automated assistant or elsewhere, and provides output in response. A Web service is an example of a proxy. The third party application can also be considered a proxy. The agent may use the slot values provided by the automated assistant for various purposes, such as fulfilling the user's request.
Fig. 5A and 5B depict one example of how a user's age range may be used as a slot value that causes different responses to be elicited from the same agent, which in this example is a third party application in the form of a joke service. In this example, the third party agent accepts a slot value indicating the age of the user and selects an appropriate joke based at least in part on the slot value. In that way, the joke spoken by the automated assistant 120 is suitable for the viewer.
In fig. 5A, a user 501A is a small child. Thus, when he requests a joke, automated assistant 120 (again in the form of a stand-alone interactive speaker), executing at least in part on client device 506, provides the predicted/estimated age range of the child to the third party joke service. The joke service selects and provides an age-appropriate joke: "what did the birdiei go to the hospital? To get a tweet (why is the bird going To the hospital).
In contrast to fig. 5B, the user 501B is an adult in this case. In this example, user 501B makes exactly the same request: "OK, Assistant, tell me a joke (good, Assistant, speak a joke to me)". Because the utterance from the user 501B is better formed and/or syntactically more correct than the utterance made by the user 501A in fig. 5A, the user 501B is identified as an adult (or at least not a small child). Thus, user 501B is provided with a joke that is more age-appropriate for her: "What's the difference between a tax and a tax collector? The taxi dermist only takes The skin (what is The difference between The animal specimen decorator and The tax collector).
Examples described herein relate to estimating the age (or age range) and vocabulary level of a user and operating an automated assistant 120 in a manner that accommodates these estimates. However, this is not intended to be limiting. Other characteristics of the user may be predicted/estimated based on the utterance of the user. For example, in some implementations, the gender of the user may be estimated and used to affect various aspects of how the automated assistant 120 operates. As an example, assume that a user is experiencing a particular medical condition that represents different things for different genders. In some implementations, the automated assistant 120 may use the predicted gender of the user to select a patch appropriate to the gender of the user from a plurality of potentially conflicting patches of information from information obtained from various medical websites. As another example, in the joke context of fig. 5A and 5B, a male user and a female user may be presented with different jokes.
Fig. 6 is a flow diagram illustrating an example method 600 in accordance with implementations disclosed herein. For convenience, the operations of the flow diagrams are described with reference to a system that performs the operations. This system may include various components of various computer systems, such as one or more components of a computing system implementing the automated assistant 120. Further, while the operations of method 600 are shown in a particular order, this is not intended to be limiting. One or more operations may be reordered, omitted, or added.
At block 602, the system may receive a voiced utterance from a user at one or more input components (e.g., microphones) of one or more client devices. At block 604, the system (e.g., by proficiency detector 111) may apply data indicative of the voiced utterance (e.g., audio recordings, feature vectors) across the trained machine learning model to generate an output. At block 606, the system may determine, based on the output generated at block 604, that the user falls into (or should be classified as) a predetermined age group, for example, among a plurality of predefined age groups. In other implementations, users may be classified into other categories, such as gender.
At block 608, the system (e.g., invoking module 112) may determine that the user invoked automatic assistant 120 based on the user's predetermined age group and data indicative of the utterance. For example, the on-device model used by the invocation module 112 may be trained to classify the user's utterance as an invocation or not, e.g., depending on whether the model-based generated invocation score satisfies a certain threshold. In some implementations, this threshold may be altered, for example, downward or upward, when it is determined that the user is a child or otherwise insufficient in language. Thus, if it is detected that the user is a child, it is more likely that the child's utterance will be classified as an invocation than if the user is an adult. In other words, it may be easier for a child (or other user) with a limited vocabulary to invoke the automated assistant 120 than for an adult or other user with a relatively high level of vocabulary.
At block 610, the system may select a given query understanding model associated with a predetermined age group from a plurality of candidate query understanding models. As noted above, this query understanding model may include components used by the STT module 117 to generate speech recognition output and/or components used by the intent matcher 136 to determine the intent of the user.
At block 612, the system, e.g., through intent matcher 136, may determine the intent of the user using a given query understanding model. As previously described, in some implementations, a given query understanding model may require less precision when determining the user's intent when the user is a child and his utterance is syntactically incorrect or not easily understood than when the user is an adult and a higher precision is expected.
At block 614, the system may determine that the user's intent is parsable based on the predetermined age group. For example, if the predetermined age group is that of a small child, the intent to require payment of funds for fulfillment may not be resolvable. At block 616, the system, e.g., through fulfillment module 124, may fulfill (or parse) the user's intent to generate response data (e.g., previously described fulfillment data). At block 618, the system may output the response data at one or more output components (e.g., speakers, display screens, etc.) of one or more client devices.
In the examples described herein, the automated assistant 120 may be transitioned into a child mode so that less than perfect grammars may be more tolerated, output appropriate for the child may be provided, it may be ensured that the child is not able to access inappropriate content and/or trigger actions such as spending money. However, this is not intended to be limiting, and other aspects of how the client device operates may be affected by the automatic assistant 120 transitioning into a pediatric mode. For example, in some implementations, the volume setting may be limited while in the child mode to protect the hearing of the child.
Additionally, and as alluded to previously, in some implementations, the automated assistant 120 may use basic client device features to provide various games when in child mode, such as guessing animals based on output animal noise, guessing numbers between 1 and 100 (higher/lower), answering puzzles or trivia, and so forth. For example, a puzzle or trivia problem may be selected based on the difficulty of the puzzle or trivia and the estimated age range of the user: younger users may receive easier puzzle/trivia questions.
It may sometimes be the case that a particular assistant device is primarily used by a child. For example, a stand-alone interactive speaker may be deployed in a child play area. In some implementations, such an assistant device may be configured, for example, by a parent, such that by default, an automated assistant that is using the assistant device to engage is in a child mode. When in the default child mode, the automated assistant may exhibit one or more of the various behaviors previously described, e.g., being more tolerant of grammatical and/or lexical errors, being more active in engaging with the child, etc. If an adult, such as a parent, desires to engage with the automated assistant 120 using that particular assistant device, the adult may (at least temporarily) cause the assistant device to transition to a non-pediatric mode, for example, by speaking a special invocation phrase that is baked into the invocation model employed by invocation module 112.
In some implementations, rather than predicting or estimating an age range of a speaker, the automated assistant 120 may be configured to perform voice recognition to authenticate the speaker. For example, members of the family may each train the automated assistant 120 to recognize their voices, e.g., so that the automated assistant 120 knows who it is engaged with. The user may have a profile that includes, among other things, their age/birthday. In some implementations, the automated assistant 120 may use these profiles to deterministically ascertain the precise age of the user, rather than estimating their age range. Once the age of the user is determined, the automated assistant 120 may operate in a manner appropriate to the age of the user as described above.
FIG. 7 is a block diagram of an example computing device 710, which example computing device 710 may optionally be used to perform one or more aspects of the techniques described herein. In some implementations, one or more of the client computing device, the user-controlled resource module 130, and/or other components can include one or more components of the example computing device 710.
The user interface input device 722 may include a keyboard; a pointing device such as a mouse, trackball, touchpad, or tablet; a scanner; a touch screen incorporated into the display; an audio input device such as a voice recognition system; a microphone; and/or other types of input devices. In general, use of the term "input device" is intended to include all possible types of devices and ways to input information into computing device 710 or a communication network.
User interface output devices 720 may include a display subsystem, a printer, a facsimile machine, or a non-visual display such as an audio output device. The display subsystem may include a Cathode Ray Tube (CRT), a flat panel device such as a Liquid Crystal Display (LCD), a projection device, or other mechanism for creating a visual image. The display subsystem may also provide non-visual displays, such as via an audio output device. In general, use of the term "output device" is intended to include all possible types of devices and ways to output information from computing device 710 to a user or to another machine or computing device.
These software modules are typically executed by processor 714 alone or in combination with other processors. Memory 725 used in storage subsystem 724 may include a number of memories including a main Random Access Memory (RAM)730 for storing instructions and data during program execution and a Read Only Memory (ROM)732 for storing fixed instructions. File storage subsystem 726 may provide persistent storage for program and data files, and may include a hard disk drive, a floppy disk drive along with associated removable media, a CD-ROM drive, an optical disk drive, or removable media cartridges. Modules implementing the functionality of certain embodiments may be stored by file storage subsystem 726 in storage subsystem 724 or in other machines accessible to processor 714.
Where the systems described herein collect or otherwise monitor personal information about a user, or may use personal and/or monitored information, the user may be provided with an opportunity to control whether programs or features collect user information (e.g., information about the user's social network, social behavior or activity, profession, the user's preferences, or the user's current geographic location), or whether and/or how to receive content from a content server that is more relevant to the user. Also, some data may be processed in one or more ways before it is stored or used, so that the personal identity information is deleted. For example, the identity of the user may be treated such that no personal identity information can be determined for the user, or the geographic location of the user for which geographic location information is obtained (such as a city, zip code, or state level) may be summarized such that no particular geographic location of the user can be determined. Thus, the user may control how information about the user is collected and/or usage information. For example, in some implementations, the user may choose not to have the automated assistant 120 attempt to estimate their age range and/or vocabulary level.
While several embodiments have been described and illustrated herein, various other means and/or structures for performing the function and/or obtaining the result and/or one or more of the advantages described herein may be utilized and each of these variations and/or modifications is considered to be within the scope of the embodiments described herein. More generally, all parameters, dimensions, materials, and configurations described herein are intended to be exemplary, and the actual parameters, dimensions, materials, and/or configurations will depend on the particular application or uses for which the teachings are used. Those skilled in the art will recognize, or be able to ascertain using no more than routine experimentation, many equivalents to the specific embodiments described herein. It is, therefore, to be understood that the foregoing embodiments are presented by way of example only and that, within the scope of the appended claims and equivalents thereto, embodiments may be practiced otherwise than as specifically described and claimed. Embodiments of the present disclosure are directed to each individual feature, system, article, material, kit, and/or method described herein. In addition, any combination of two or more such features, systems, articles, materials, kits, and/or methods, if such features, systems, articles, materials, kits, and/or methods are not mutually inconsistent, is included within the scope of the present disclosure.
Claims (20)
1. A method implemented using one or more processors, comprising:
receiving, at one or more input components of one or more client devices, a voiced utterance from a user;
applying data indicative of the voiced utterance across a trained machine learning model to generate an output;
determining, based on the output, that the user falls into a predetermined age group;
selecting a given query understanding model associated with the predetermined age group from a plurality of candidate query understanding models;
determining an intent of the user using the given query understanding model;
determining that the user's intent is parsable based on the predetermined age group;
parsing the user's intent to generate response data; and
outputting the response data at one or more output components of one or more of the client devices.
2. The method of claim 1, wherein the plurality of candidate query understanding models includes at least one candidate query understanding model having a different grammar tolerance than that of the given query understanding model.
3. The method of claim 1 or claim 2, wherein the data indicative of the voiced utterance comprises an audio recording of an utterance of the user, and the machine learning model is trained to generate an output indicative of an age of the user based on one or more phonemes contained in the audio recording.
4. The method according to any preceding claim, further comprising selecting a given natural language generative model associated with the predetermined age group from a plurality of candidate natural language generative models, wherein the selected given natural language output model is used to generate the response data.
5. The method of claim 4, wherein the plurality of candidate natural language generative models comprises at least one candidate natural language generative model that uses a vocabulary that is more complex than the vocabulary used by the given natural language output model.
6. The method according to any preceding claim, further comprising selecting a given speech synthesis model associated with the predetermined age group from a plurality of candidate speech synthesis models, wherein outputting the response data is performed using the given speech synthesis model.
7. The method of any preceding claim, wherein the given query understanding model is applied to perform speech-to-text processing of the voiced utterance.
8. The method of any preceding claim, wherein the given query understanding model is applied to perform natural language understanding of a speech recognition output generated from the voiced utterance.
9. A method implemented using one or more processors, comprising:
receiving, at one or more input components of one or more client devices, a voiced utterance from a user;
applying data indicative of the voiced utterance across a trained machine learning model to generate an output;
based on the output, determining that the user falls within a given vocabulary level of a plurality of predetermined vocabulary levels;
selecting a given query understanding model associated with the given vocabulary level from a plurality of candidate query understanding models;
determining an intent of the user using the given query understanding model;
determining, based on the predetermined vocabulary level, that the user's intent is parsable;
parsing the user's intent to generate response data; and
outputting the response data at one or more output components of one or more of the client devices.
10. The method of claim 9, wherein the plurality of candidate query understanding models includes at least one candidate query understanding model having a different grammar tolerance than that of the given query understanding model.
11. The method of claim 9 or claim 10, wherein the data indicative of the voiced utterance comprises an audio recording of an utterance of the user, and the machine learning model is trained to generate an output indicative of a vocabulary level of the user based on one or more phonemes contained in the audio recording.
12. The method of any of claims 9 to 11, further comprising selecting a given natural language generative model associated with the predetermined vocabulary level from a plurality of candidate natural language generative models, wherein the selected given natural language output model is used to generate the response data.
13. The method of claim 12, wherein the plurality of candidate natural language generative models comprises at least one candidate natural language generative model that uses a vocabulary that is more complex than the vocabulary used by the given natural language output model.
14. The method of any of claims 9-13, further comprising selecting a given speech synthesis model associated with the predetermined vocabulary level from a plurality of candidate speech synthesis models, wherein outputting the response data is performed using the given speech synthesis model.
15. The method of any of claims 9 to 14, wherein the given query understanding model is applied to perform speech-to-text processing of the voiced utterance.
16. The method of any of claims 9 to 15, wherein the given query understanding model is applied to perform natural language understanding of a speech recognition output generated from the voiced utterance.
17. A system comprising one or more processors and memory operatively coupled with the one or more processors, wherein the memory stores instructions that, in response to execution of the instructions by the one or more processors, cause the one or more processors to:
receiving, at one or more input components of one or more client devices, a voiced utterance from a user;
applying data indicative of the voiced utterance across a trained machine learning model to generate an output;
determining, based on the output, that the user falls into a predetermined age group;
selecting a given query understanding model associated with the predetermined age group from a plurality of candidate query understanding models;
determining an intent of the user using the given query understanding model;
determining that the user's intent is parsable based on the predetermined age group;
parsing the user's intent to generate response data; and
outputting the response data at one or more output components of one or more of the client devices.
18. The system of claim 17, wherein the plurality of candidate query understanding models includes at least one candidate query understanding model having a different grammar tolerance than that of the given query understanding model.
19. The system of claim 17 or claim 18, wherein the data indicative of the voiced utterance comprises an audio recording of an utterance of the user, and the machine learning model is trained to generate an output indicative of an age of the user based on one or more phonemes contained in the audio recording.
20. The system according to any one of claims 17 to 19, further comprising instructions for selecting a given natural language generative model associated with the predetermined age group from a plurality of candidate natural language generative models, wherein the selected given natural language output model is used to generate the response data.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US15/954,174 US10573298B2 (en) | 2018-04-16 | 2018-04-16 | Automated assistants that accommodate multiple age groups and/or vocabulary levels |
US15/954,174 | 2018-04-16 | ||
PCT/US2019/027598 WO2019204252A1 (en) | 2018-04-16 | 2019-04-16 | Automated assistants that accommodate multiple age groups and/or vocabulary levels |
Publications (2)
Publication Number | Publication Date |
---|---|
CN112119454A true CN112119454A (en) | 2020-12-22 |
CN112119454B CN112119454B (en) | 2024-05-14 |
Family
ID=
Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2009104020A (en) * | 2007-10-25 | 2009-05-14 | Panasonic Electric Works Co Ltd | Voice recognition device |
US20150206533A1 (en) * | 2014-01-20 | 2015-07-23 | Huawei Technologies Co., Ltd. | Speech interaction method and apparatus |
US20150332665A1 (en) * | 2014-05-13 | 2015-11-19 | At&T Intellectual Property I, L.P. | System and method for data-driven socially customized models for language generation |
CN106648082A (en) * | 2016-12-09 | 2017-05-10 | 厦门快商通科技股份有限公司 | Intelligent service device capable of simulating human interactions and method |
Patent Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2009104020A (en) * | 2007-10-25 | 2009-05-14 | Panasonic Electric Works Co Ltd | Voice recognition device |
US20150206533A1 (en) * | 2014-01-20 | 2015-07-23 | Huawei Technologies Co., Ltd. | Speech interaction method and apparatus |
US20150332665A1 (en) * | 2014-05-13 | 2015-11-19 | At&T Intellectual Property I, L.P. | System and method for data-driven socially customized models for language generation |
CN106648082A (en) * | 2016-12-09 | 2017-05-10 | 厦门快商通科技股份有限公司 | Intelligent service device capable of simulating human interactions and method |
Also Published As
Publication number | Publication date |
---|---|
US20230031521A1 (en) | 2023-02-02 |
US20200135181A1 (en) | 2020-04-30 |
EP4296846A3 (en) | 2024-03-20 |
US20200286473A1 (en) | 2020-09-10 |
US11495217B2 (en) | 2022-11-08 |
KR20220133312A (en) | 2022-10-04 |
KR102627948B1 (en) | 2024-01-23 |
US11521600B2 (en) | 2022-12-06 |
JP2022103191A (en) | 2022-07-07 |
KR20200142066A (en) | 2020-12-21 |
WO2019204252A1 (en) | 2019-10-24 |
JP7064018B2 (en) | 2022-05-09 |
US11756537B2 (en) | 2023-09-12 |
EP3602543A1 (en) | 2020-02-05 |
US10573298B2 (en) | 2020-02-25 |
EP3602543B1 (en) | 2023-12-20 |
KR102446962B1 (en) | 2022-09-23 |
US20190325864A1 (en) | 2019-10-24 |
EP4296846A2 (en) | 2023-12-27 |
KR20240013280A (en) | 2024-01-30 |
US20190348030A1 (en) | 2019-11-14 |
US10679614B2 (en) | 2020-06-09 |
JP2021513119A (en) | 2021-05-20 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11756537B2 (en) | Automated assistants that accommodate multiple age groups and/or vocabulary levels | |
US10977452B2 (en) | Multi-lingual virtual personal assistant | |
US11100384B2 (en) | Intelligent device user interactions | |
KR102048030B1 (en) | Facilitate end-to-end multilingual communication with automated assistants | |
EP3642833B1 (en) | Dynamic and/or context-specific hot words to invoke automated assistant | |
EP4350569A1 (en) | User-programmable automated assistant | |
US11347801B2 (en) | Multi-modal interaction between users, automated assistants, and other computing services | |
US11423885B2 (en) | Utilizing pre-event and post-event input streams to engage an automated assistant | |
US20220246140A1 (en) | Dynamic and/or context-specific hot words to invoke automated assistant | |
CN113412515A (en) | Adapting automated assistant for use in multiple languages | |
JP6551793B2 (en) | Dialogue method, dialogue system, dialogue apparatus, and program | |
CN112119454B (en) | Automatic assistant adapted to multiple age groups and/or vocabulary levels | |
JP7486540B2 (en) | Automated assistants that address multiple age groups and/or vocabulary levels | |
Sicilia et al. | ISABEL: An Inclusive and Collaborative Task-Oriented Dialogue System |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
GR01 | Patent grant |