US7337110B2 - Structured VSELP codebook for low complexity search - Google Patents
Structured VSELP codebook for low complexity search Download PDFInfo
- Publication number
- US7337110B2 US7337110B2 US10/227,725 US22772502A US7337110B2 US 7337110 B2 US7337110 B2 US 7337110B2 US 22772502 A US22772502 A US 22772502A US 7337110 B2 US7337110 B2 US 7337110B2
- Authority
- US
- United States
- Prior art keywords
- codebook
- codevector
- excitation
- modeled
- vselp
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
Images
Classifications
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L19/00—Speech or audio signals analysis-synthesis techniques for redundancy reduction, e.g. in vocoders; Coding or decoding of speech or audio signals, using source filter models or psychoacoustic analysis
- G10L19/04—Speech or audio signals analysis-synthesis techniques for redundancy reduction, e.g. in vocoders; Coding or decoding of speech or audio signals, using source filter models or psychoacoustic analysis using predictive techniques
- G10L19/08—Determination or coding of the excitation function; Determination or coding of the long-term prediction parameters
- G10L19/12—Determination or coding of the excitation function; Determination or coding of the long-term prediction parameters the excitation function being a code excitation, e.g. in code excited linear prediction [CELP] vocoders
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L19/00—Speech or audio signals analysis-synthesis techniques for redundancy reduction, e.g. in vocoders; Coding or decoding of speech or audio signals, using source filter models or psychoacoustic analysis
- G10L19/04—Speech or audio signals analysis-synthesis techniques for redundancy reduction, e.g. in vocoders; Coding or decoding of speech or audio signals, using source filter models or psychoacoustic analysis using predictive techniques
- G10L19/08—Determination or coding of the excitation function; Determination or coding of the long-term prediction parameters
- G10L19/12—Determination or coding of the excitation function; Determination or coding of the long-term prediction parameters the excitation function being a code excitation, e.g. in code excited linear prediction [CELP] vocoders
- G10L19/135—Vector sum excited linear prediction [VSELP]
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L19/00—Speech or audio signals analysis-synthesis techniques for redundancy reduction, e.g. in vocoders; Coding or decoding of speech or audio signals, using source filter models or psychoacoustic analysis
- G10L2019/0001—Codebooks
- G10L2019/0013—Codebook search algorithms
Definitions
- the present invention generally relates to digital speech coding for efficient modeling, quantization, and error minimization of waveform signal components and speech prediction residual signals at low bit rates, and more particularly to improved methods for coding the excitation information for code-excited linear predictive speech coders.
- LPC linear predictive coding
- CELP code-excited linear prediction
- This class of speech coding is also known as vector-excited linear prediction or stochastic coding, which is used in numerous speech communications and speech synthesis applications.
- CELP is also particularly applicable to digital speech encryption and digital radiotelephone communication systems wherein speech quality, data rate, size, and cost are significant issues.
- the LPC system of a CELP speech coder typically employs long term (“pitch”) and short term (“formant”) predictors that model the characteristics of the input speech signal and are incorporated in a set of time-varying linear filters.
- An excitation signal for the filters is chosen from a codebook of stored innovation sequences, or codevectors.
- the speech coder applies each individual codevector to the filters to generate a reconstructed speech signal, and compares the original input speech signal to the reconstructed signal to create an error signal.
- the error signal is then weighted by passing it through a weighting filter having a response based on human auditory perception.
- the optimum excitation signal is determined by selecting the codevector that produces the weighted error signal with the minimum energy for the current frame.
- LPC linear predictive coding
- the stored excitation codevectors generally include independent random white Gaussian sequences.
- One codevector from the codebook is used to represent each block of N excitation samples.
- Each stored codevector is represented by a codeword, i.e., the address of the codevector memory location. It is this codeword that is subsequently sent over a communications channel to the speech synthesizer to reconstruct the speech frame at the receiver. See, M. R. Schroeder and B. S. Atal, “Code-Excited Linear Prediction (CELP): High-Quality Speech at Very Low Bit Rates”, Proceedings of the EEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Vol. 3, pp. 937-40, March 1985, for a detailed explanation of CELP.
- CELP Code-Excited Linear Prediction
- the difficulty of the CELP speech coding technique lies in the extremely high computational complexity of performing an exhaustive search of all the excitation codevectors in the codebook.
- the memory allocation requirement to store the codebook of independent random vectors is also exorbitant.
- a 640 kilobit read-only-memory (ROM) would be required to store all 1024 codevectors, each having 40 samples, each sample represented by a 16-bit word.
- substantial computational efforts are required to search the entire codebook, e.g., 1024 vectors, for the best fit—an unreasonable task for real-time implementation with today's digital signal processing technology.
- Another alternative for reducing the computational complexity is to structure the excitation codebook such that the codevectors are no longer independent of each other. In this manner, the filtered version of a codevector can be computed from the filtered version of the previous codevector, again using only a single filter computation MAC per sample. Examples of these types of codebooks are given in the article entitled “Speech Coding Using Efficient Pseudo-Stochastic Block Codes”, Proc. ICASSP, Vol. 3, pp. 1354-7, April 1987, by D. Lin. Nevertheless, 24,000,000 MACs per second would still be required to do the search.
- the ROM size is based on 2 M ⁇ n bits/word, where M is the number of bits in the codeword such that the codebook contains 2 M codevectors. Therefore, the memory requirements still increase exponentially with the number of bits used to encode the frame of excitation information. For example, the ROM requirements increase to 64 kilobits when using 12 bit codewords.
- VSELP Vector Sum Excited Prediction
- all 2 M excitation codevectors may be generated as a linear combination of M basis vectors, where codeword I specifies the polarity of each of the M basis vectors in the linear combination.
- the entire codebook can be searched using only M+3 multiply-accumulate operations per codevector evaluation.
- Other advantages of a VSELP codebook are efficient codebook storage (only the M basis vectors need to be stored, instead of 2 M codevectors), resilience to channel errors, and an ability to optimize the VSELP basis vectors utilizing an off line codebook training procedure.
- FIG. 1 is a general block diagram of a code-excited linear predictive speech coder utilizing the vector sum excitation signal generation technique in accordance with the present invention
- FIG. 2 is a detailed block diagram of the Vector Sum Excitation signal generator block of FIG. 1 , illustrating the vector sum technique of the present invention
- FIGS. 3A and 3B are detailed flowchart diagrams illustrating the sequence of operations performed by an embodiment of the speech coder of FIG. 1 ;
- FIGS. 4A-4H are detailed diagrams, included to illustrate the sequence of operations for outputting codewords in progression as performed in accordance with the present invention as embodied in the speech coder of FIG. 1 .
- a class of analysis-by-synthesis speech coders includes a family of speech coders known as Code-Excited Linear Prediction (CELP) coders.
- CELP coder the excitation codebook is searched to identify an excitation codevector, which when processed by a long term predictor (LTP) filter and the short term predictor (STP) filter, also called a synthesis filter, will best match the input speech vector.
- LTP long term predictor
- STP short term predictor
- synthesis filter also called a synthesis filter
- the decoder uses the transmitted index, which it received from the encoder, to extract the excitation codevector from the excitation codebook, which is identical to the excitation codebook used by the encoder.
- the extracted excitation codevector is then typically applied to the LTP filter and the STP filter to reconstruct the synthetic speech.
- the gain (or scale factor) for codevector I is quantized, as are the parameters defining the LTP filter and the STP filter.
- the indices of those quantized parameters are transmitted from the encoder to the decoder, in addition to the index I, and are used by the decoder to reconstruct the synthetic speech.
- the speech coder parameters are partitioned into distinct parameter classes, where each parameter class is updated at a unique rate.
- the speech coder parameters may be partitioned into frame parameters and subframe parameters, where a frame is defined as a time interval corresponding to some number of input samples and spans at least one subframe. Define N to be the subframe length in samples.
- the STP filter parameters are updated at a frame rate, while excitation codevector index I, the quantized gain associated with it, and the LTP filter parameters are updated at subframe rate, which is a multiple of the frame rate.
- VSELP codebook is one type of a structured codebook.
- the present invention provides an improved codebook searching technique having reduced computation complexity for “code-excited” or “vector-excited” excitation sequences in applications where the speech coder uses vector quantization for the excitation.
- An improved digital speech coding technique produces high quality speech at low bit rates.
- An efficient excitation vector generating technique further reduces memory and digital signal processing technology requirements.
- the result is an improved speech coding technique that addresses both the problems of extremely high computational complexity for codebook searching given large values of M, as well as the vast memory requirements for storing the excitation codevectors with solutions for making long codevector length codebook practical.
- the present invention in its most efficient embodiment relates to a codebook excited linear prediction coding system providing improved digital speech coding for high quality speech at low bit rates with side-by-side codebooks for segments of the modeled input signal to reduce the complexity of the codebook search.
- a linear predictive filter responsive to an input signal desired to be modeled is used to select a codevector from a first codebook over predetermined intervals as a subset of the input signal.
- a long term predictor and an excitation vector quantizer may provide synthetic excitation of modeled waveform signal components corresponding to the input signal desired to be modeled from side-by-side codebooks by providing codevectors with concatenated signals identified from the basis vector over the predetermined intervals with respect to the side-by-side codebooks.
- a concatenated codevector is formed as a concatenation of VSELP codevectors selected up to but not including the current segment to form a carry-along basis vector, used as an additional basis vector at the current segment.
- the present invention presents a solution for efficiently searching an excitation codebook specified by a large number of bits, i.e., where M is a large number, and where the excitation codebook is based on a VSELP codebook.
- the VSELP codebook (Gerson, U.S. Pat. No. 4,817,157) forms the basis for this invention.
- the codebook search strategy is as follows: The first VSELP codebook is searched to select a VSELP codevector. The VSELP codevector so selected is treated as an additional VSELP basis vector for searching the 2-nd VSELP codebook.
- the second VSELP codebook is defined by M 2 bits, for the purpose of the codebook search it may be viewed as an M 2 +1 bit codebook. Note that to further reduce the computational complexity, the polarity of the additional basis vector may be fixed (i.e., not allowed to change) during the search of the 2 nd VSELP codebook.
- the additional basis vector (termed the carry-along basis vector) would still participate in defining the optimal value of the gain factor for each VSELP codevector being evaluated from the 2 nd VSELP codebook. If J>2, the codevector selected from the 2 nd VSELP codebook is constructed, and used to update the additional basis vector for searching the 3 rd VSELP codebook.
- the additional basis vector for the search of the j-th VSELP codebook, where 2 ⁇ j ⁇ J, is defined to be a linear superposition of the VSELP codevectors selected from VSELP codebooks 1 through j ⁇ 1.
- VSELP codebooks 1 through j ⁇ 1 If the polarity of the carry-along basis vector is allowed to change during the search of the j-th VSELP codebook, the codewords for VSELP codebooks 1 through j ⁇ 1, need to be updated to reflect the corresponding polarity change in VSELP codevectors up to j ⁇ 1 stage. It is clear that this approach can be extended to arbitrarily large values of J.
- the codebook search strategy is as follows: The first of the J codebooks is searched for the best codevector. Once that codevector is identified, the codebook at the next segment is searched, but now that codebook is defined by M′+1 basis vectors, instead of by M′ basis vectors. Since the codevector (or a concatenation of codevectors) is selected up to but not including the current segment, the codevector is treated as an additional basis vector for the VSELP codebook search at the current segment. Note that in this case, where identical side-by-side codebooks are employed, the excitation codevector is formed as a concatenation of VSELP codevectors selected from the J VSELP codebooks.
- the excitation codevector is formed as a linear superposition of the J codevectors selected from their respective VSELP codebooks, where the J VSELP codebooks may be placed in a side-by-side configuration.
- the construction of the additional basis vector can be characterized as being a linear superposition of the VSELP codevectors selected up to but not including the current segment, where the J VSELP codebooks are placed in a side-by-side configuration.
- FIG. 1 there is shown a general block diagram of code excited linear predictive speech coder 100 utilizing the excitation signal generation technique according to the VSELP technique.
- the known CELP techniques of digital speech coding employing vector excitation sources as discussed in U.S. Pat. No. 4,817,157 issued Mar. 28, 1989 to Gerson for “Digital Speech Coder Having Improved Vector Excitation Source” assigned to applicant's assignee are hereby incorporated by reference.
- the VSELP codebook, disclosed in that patent forms the building block for the present invention, and is now described for completeness.
- An input signal to be analyzed is applied to speech coder 100 at microphone 102 .
- the input signal typically a speech signal, is then applied to filter 104 .
- Filter 104 generally will exhibit bandpass filter characteristics. However, if the input signal is already band limited, filter 104 may comprise a direct wire connection.
- the analog speech signal from filter 104 is then converted into a sequence of digital samples, and the amplitude of each sample is then represented by a digital code in analog-to-digital (A/D) converter 108 , as known in the art.
- the sampling rate is determined by sampling clock, which represents an 8.0 kHz rate in the preferred embodiment.
- the sampling clock is generated along with the frame clock (FC) via clock 112 .
- the filtered or band limited input signal s(n) from the A/D converter 108 and the frame clock 112 are provided to a coefficient analyzer block 110 , which provides filter parameters used in the speech coder 100 .
- the VSELP block 116 outputs a codevector based on the index parameter i, which is scaled and summed with the output of the long term predictor block, if used, to provide a synthetic excitation to a short term predictor (STP) 122 generating signal s′ i (n), from which a difference error signal is generated at a subtractor 130 .
- the error signal is passed through a weighting filter, block 132 , whose output is squared and summed in block 134 to produce an energy E i , representing the weighted Mean Square Error (MSE) corresponding to the use of codevector i.
- MSE Mean Square Error
- FIG. 2 illustrating a representative hardware configuration for codebook generator 116 , will now be used to describe the vector sum technique.
- Generator block 220 provides codebook generator, while memory 214 corresponds to codebook (CB) basis vector storage 114 .
- Memory block 214 stores all of the M basis vectors v 1 (n) through v M (n), wherein 1 ⁇ m ⁇ M, and wherein 1 ⁇ n ⁇ N. All M basis vectors are applied to multipliers 261 through 264 of generator 220 .
- the i-th excitation codeword is applied to converter 260 . This excitation information is then converted into a plurality of interim data signals ⁇ i1 through ⁇ iM , wherein 1 ⁇ m ⁇ M, by converter 260 .
- the interim data signals are based on the value of the individual bits of the selector codeword i, such that each interim data signal ⁇ im represents the sign corresponding to the m-th bit of the i-th excitation codeword. For example, if bit one of excitation codeword i is 0, the ⁇ i1 would be ⁇ 1. Similarly, if the second bit of excitation codeword i is 1, then ⁇ i2 would be +1. It is contemplated, however, that the interim data signals may alternatively be any other transformation from i to ⁇ im , e.g., as determined by a ROM look-up table. Also note that the number of bits in the codeword do not have to be the same as the number of basis vectors. For example, codeword i could have 2M bits where each pair of bits defines 4 values for each ⁇ im , i.e., 0, 1, 2, 3, or +1, ⁇ 1, +2, ⁇ 2, etc.
- the interim data signals are also applied to multipliers 261 through 264 .
- the multipliers are used to multiply the set of basis vectors v m (n) by the set of interim data signals ⁇ im to produce a set of interim vectors that are then summed together in summation network 265 to produce the single excitation codevector u i (n).
- the vector sum technique is described by the equation:
- u i (n) is the n-th sample of the i-th excitation codevector, and where 1 ⁇ n ⁇ N.
- FIGS. 3A and 3B are detailed flow chart diagrams illustrating the sequence of operations performed by the speech coder 100 relative to the VSELP codebook search.
- the difference vector p(n) is then used as the target vector in the codebook searching process to identify a codeword I for the VSELP codebook.
- G i is the power in the i-th filtered codevector.
- P the power in p(n), the input vector to be matched over the subframe, is defined to be:
- E i may be equivalently defined as:
- this term must be evaluated for each of the 2 M codebook vectors—not the M basis vectors.
- this parameter can be calculated for each codeword based on parameters associated with the M basis vectors rather than the 2 M codevectors.
- the zero state response vector q m (n) must be computed for each basis vector v m (n) in step 314 .
- step 316 the first cross-correlator computes cross-correlation array R m according to the equation:
- Array R m represents the cross-correlation between the m-th filtered basis vector q m (n) and p(n).
- the second cross-correlator computes cross-correlation matrix D mj in step 318 according to the equation:
- Matrix D mj represents the cross-correlation between pairs of individual filtered basis vectors. Note that D mj is a symmetric matrix. Therefore, approximately half of the terms need only be evaluated as shown by the limits of the subscripts.
- f i (n) is the zero state response of the filters to excitation vector u i (n)
- q m (n) is the zero state response of the filters to basis vector v m (n) Equation ⁇ 11 ⁇ :
- the parameters ⁇ im are initialized to ⁇ 1 for 1 ⁇ m ⁇ M. These ⁇ im parameters represent the M interim data signals that would be used to generate the current codevector as described by equation ⁇ 1 ⁇ . (The i subscript in ⁇ im was dropped in the figures for simplicity.)
- the best correlation term C b is set equal to the pre-calculated correlation C 0
- the best energy term G b is set equal to the pre-calculated G 0 .
- the codeword I which represents the codeword for the best excitation vector u I (n) for the particular input speech frame s(n), is set equal to 0.
- a counter variable k is initialized to zero, and is then incremented in step 326 .
- step 328 the counter k is tested in step 328 to see if all 2 M combinations of basis vectors have been tested.
- the maximum value of k is 2 M ⁇ 1 , since a codeword and its complement are evaluated at the same time as described above. If k is less than 2 M ⁇ 1 , then step 330 proceeds to define a function “flip” wherein the variable 1 represents the location of the next bit to flip in codeword i. This function is performed since the present invention utilizes a Gray code to sequence through the codevectors changing only one bit at a time. Therefore, it can be assumed that each successive codeword differs from the previous codeword in only one bit position.
- Step 330 also sets ⁇ l to ⁇ l to reflect the change of bit 1 in the codeword.
- step 334 the new energy term G k is computed according to the equation:
- Step 342 computes the excitation codeword I from the ⁇ m parameter by setting bit m of codeword I equal to 1 if ⁇ m is +1, and by setting bit m of codeword I equal to 0 if ⁇ m is ⁇ 1, for all m bits 1 ⁇ m ⁇ M. Control then returns to step 326 to test the next codeword, as would be done immediately if the first quantity was not greater than the second quantity.
- step 346 checks to see if the correlation term C b is less than zero. This is done to compensate for the fact that the codebook was searched by pairs of complementary codewords. If C b is less than zero, then the gain factor ⁇ is set equal to ⁇ [C b /G b ] in step 350 , and the codeword I is complemented in step 352 . If C b is not negative, then the gain factor ⁇ is just set equal to C b /G b in step 348 . This ensures that the gain factor ⁇ is positive.
- Step 358 then proceeds to compute the reconstructed weighted speech vector y′(n) by using the best excitation codeword I.
- Codebook generator uses codeword I and the basis vectors v m (n) to generate excitation vector u I (n) according to equation ⁇ 1 ⁇ .
- Codevector u I (n) is then scaled by the gain factor ⁇ in gain block, and filtered by filter string # 1 to generate y′(n). Filter string # 1 is the weighted synthesis filter.
- Filter string # 1 is used to update the filter states FS by transferring them to filter string # 2 to compute the zero input response vector d(n) for the next frame.
- Filter string # 2 uses the same filter coefficients as filter string # 1 . Accordingly, control returns to step 302 to input the next speech frame s(n).
- the gain factor ⁇ is computed at the same time as the codeword I is optimized. In this way, the optimal gain factor for each codeword can be found.
- the algorithm described above has been configured so as to reduce computational complexity.
- M Care must be taken when selecting M in a speech coder design because the number of codevector searches is a function of M. That is because given an M bit codebook, 2 M codevectors may be constructed, and 2 M ⁇ 1 codevector evaluations are done to identify the codevector that yields the lowest weighted MSE. This constrains the largest value of M to be typically less than 12 bits for a practical speech coder implementation. If a large number of bits is budgeted for an excitation codebook, the choice facing the speech coder designer is to partition those bits among several codebooks, arranged either in a multi-stage fashion, in a side-by-side configuration, or some combination of the two. Traditionally each codevector would have a gain associated with it.
- VSELP codebook A methodology for structuring a VSELP codebook has been developed, which allows M to be a large number, while maintaining low codebook search complexity.
- This codebook structure retains the inherent advantages of the VSELP codebook, such as resilience to channel errors, low search complexity, and the ability to train the VSELP basis vectors to optimize the prediction gain due to the excitation codebook.
- M the budget of bits/subframe for coding the excitation is large, computational complexity can be reduced by the use of J smaller codebooks used in side-by-side configuration.
- the VSELP codebook is defined by M basis vectors each spanning K samples, where K is typically equal to the subframe length N ( FIG. 1 ).
- K is typically equal to the subframe length N ( FIG. 1 ).
- K is typically equal to the subframe length N ( FIG. 1 ).
- the first of the J codebooks is searched for the best codevector.
- the codebook search is done over the first K samples of the weighted target vector p(n) as shown in FIG. 4A .
- that codevector is identified, it is constructed and weighted (see FIG. 4B ) to be used at the next segment as an additional weighted basis vector—(M′+1 th ) basis vector—for searching the codebook at that segment (see FIG. 4C ).
- M′+1 th additional weighted basis vector
- the codevector (or a concatenation of codevectors) selected up to but not including the current segment, is treated as an additional basis vector for the VSELP codebook search at the current segment.
- the codebook search at the j-th segment seeks to identify the VSELP codevector from the j-th codebook, which minimizes the weighted MSE over the first j*K samples of the subframe. If the side-by-side codebooks are identical, as described, it is possible to significantly reduce the complexity of the VSELP codebook search by precomputing and storing the terms for the code search that do not change from segment to segment.
- the denominator terms (G's) for the VSELP codebook search may be precomputed and stored at the first of the J segments, and subsequently combined at each of the following segments with the recursively computed portion of the denominator term that is unique for a given segment (i.e., is a function of the additional basis vector) to yield the effective G for the codevector being evaluated up to and including the current segment, by invoking linear superposition.
- the calculation of the correlation between the target signal for the codebook search and the additional weighted basis vector may be recursively computed to further reduce computation.
- a version of the convolution function that assumes zero-state and a version of the convolution function that assumes zero-input, may be employed to eliminate the multiplications that involve deterministically located 0 valued samples.
- the convolution functions are needed to convolve the unweighted basis vectors with the impulse response of the perceptually weighted synthesis filter.
- the length of the additional (M′+1 th ) weighted basis vector is j*K, where 2 ⁇ j ⁇ J and j is the index of the current segment.
- a concatenation of codevectors or carry-along basis vector are formed as a concatenation of VSELP codevectors selected up to but not including the current segment.
- This updating entails constructing the unweighted VSELP codevector corresponding to the best codeword identified for the previous segment, and appending it onto the content of the memory location reserved to storing the carry-along-basis vector.
- the convolution operation with h(n) the impulse response of the weighted synthesis filter is resumed, over the VSELP codevector selected at the previous segment, to obtain an updated filtered version of the carry-along basis vector.
- the filtered carry-along basis vector is defined up to (but not including) the beginning of the current segment.
- the zero input response of the carry-along basis vector is computed for the current segment. This is done by setting the sample values of the unfiltered carry-along basis vector to 0 for the interval of the current segment, and continuing the convolution operation of the unfiltered carry-along basis vector with h(n) into the current segment.
- the section of the filtered carry-along basis vector that lines up with the current segment contains the zero input response of the carry-along basis vector to h(n).
- the process of constructing and weighing (by convolving with h(n)) of the carry-along basis vector is indicated in FIGS.
- the carry along-basis vector becomes M′+1 th basis vector for the VSELP codebook search at the current segment, as shown in FIGS. 4C , 4 E, and 4 G, for the cases where the j is 2, 3, and 4 respectively.
- the polarity of the carry-along basis vector may be allowed to change, or may be fixed for the M′+1 basis vector codebook search. If the polarity of the carry-along basis vector is allowed to change and is changed, the codewords for the codevectors that constitute the carry along basis vector are complemented.
- VSELP codevector Once a VSELP codevector is selected for the current segment, it will be used at the next segment to replace the zero input response to h(n), by being actually convolved with h(n) as was already described above.
- the (M′+1 th ) basis vector is employed so that the contribution to the minimization of the weighted MSE of the concatenation of codevectors selected at j ⁇ 1 segments, is taken into account when searching the VSELP codebook at the j-th segment for a codevector that minimizes the weighted MSE over the first j*K samples of the subframe.
- FIG. 4H shows the concatenation of the selected codevectors, where I 1 , I 2 , I 3 , and I 4 are the corresponding codewords. This concatenation of selected codevectors over J segments becomes the selected excitation codevector for the subframe.
- the selected codewords I 1 , I 2 , I 3 , and I 4 may be applied to an output codeword generator that forms an M bit codeword I, which is the index of the selected excitation codevector from the excitation codebook, and is then transmitted to the decoder.
- the output codeword generator may simply output codewords I 1 . . . I 4 .
- the decoder uses the transmitted index (or indices), which it received from the encoder, to generate the selected excitation codevector from the excitation codebook, which is identical to the excitation codebook used by the encoder.
- the extracted excitation codevector is then typically applied to the LTP filter and the STP filter to reconstruct the synthetic speech.
- the gain (or scale factor) for excitation codevector I is quantized, as are the parameters defining the LTP filter and the STP filter.
- the indices of those quantized parameters are transmitted from the encoder to the decoder, in addition to the index I (or indices I 1 , I 2 , I 3 , and I 4 ), and are used by the decoder to reconstruct the synthetic speech.
- the carry-along basis vector may be viewed simply as an additional basis vector, albeit an adaptively generated one, to supplement an M′ bit VSELP codebook, the assumption that the weighted error due to each VSELP codevector being evaluated uses optimal value of the gain for that codevector is still valid. This means that although the waveform shape of the carry-along basis vector is fixed at a given segment, its amplitude is multiplied by the optimal value of the gain, corresponding to the VSELP codevector being evaluated. This optimal value of the gain is assumed to scale all M′+1 basis vectors, from which the current codevector under evaluation is derived.
- the weighted codevector need not be explicitly constructed to compute the weighted error corresponding to it, but the weighted error calculation is based on precomputed correlation items C and power terms G, which are updated recursively.
- the algorithm described above has been configured so as to reduce computational complexity. Other configurations, less computationally efficient but potentially more optimal (because less structured), are possible. For instance the side-by-side codebooks do not need to be identical nor specified by the same number of bits. If the codebooks are not identical, the denominator terms for the codebook search would need to be computed individually for each codebook, with no reuse from segment to segment. Another possible configuration, would start out with an M bit VSELP codebook, with each basis vector spanning the full subframe length. If M′ ⁇ M, the VSELP codebook search may be conducted assuming M′ bit VSELP codebook, i.e., using only the first M′ basis vectors for the search.
- the M′ basis vectors are used to construct the selected codevector, and that codevector may be viewed as a single basis vector.
- the M′ bit codevector becomes the first basis vector for the subsequent codebook search of the resulting M-M′+1 basis vector codebook.
- This search strategy can be extended to codebook search with more than two stages. Or a VSELP codebook structure can be defined, which combines some or all of the configurations described thus far.
- Yet another embodiment of the invention would not require the initial carry-along basis vector to be constructed using the VSELP technique.
- Any type of an excitation codebook may be employed to generate a selected codevector, with that codevector becoming the (M+1 th ) basis vector (or equivalently the carry-along basis vector) of a VSELP codebook defined by M′ basis vectors, at the next segment or stage.
- the relative energy variation in the ideal excitation sequence among the J segments may be vector quantized to allow the codebook excitation to better track the energy variation in the target signal for the codebook search. This may be efficiently incorporated into the codebook search methodology outlined.
- any type of basis vector may be used with the vector sum technique described herein.
- a VSELP codebook optimization procedure is used to generate a set of basis vectors, with the minimization of the weighted error energy being the optimization criterion.
- different computations may be performed on the basis vectors to achieve the same goal of reducing the computational complexity of the codebook search procedure. All such modifications that retain the basic underlying principles disclosed and claimed herein are within the scope of this invention.
Abstract
Description
where ui(n) is the n-th sample of the i-th excitation codevector, and where 1≦n≦N.
p(n)=y(n)−d(n). {2}
The difference vector p(n) is then used as the target vector in the codebook searching process to identify a codeword I for the VSELP codebook. For an exhaustive search of an M bit codebook this involves performing 2M MSE calculations at a subframe to identify the index I of the codevector that minimizes the MSE. For a VSELP codebook it is sufficient to explicitly evaluate the MSE for 2M−1 codevectors, since for each codevector a VSELP codebook also implicitly contains its complement. Ei, the MSE corresponding to the i-th codevector, assuming that an optimal codevector gain γi is used, is given by:
and it can be shown that the optimal gain γi is:
Ci is the correlation between p(n), the weighted vector to be approximated, and pi(n), the i-th filtered codevector. Gi is the power in the i-th filtered codevector. P, the power in p(n), the input vector to be matched over the subframe, is defined to be:
Given those definitions, Ei may be equivalently defined as:
From {6} it can be seen that since P≧0 and
minimizing E1 involves identifying the index of the codevector for which the value of
is maximized over all the codevectors in the codebook, or, equivalently, the codevector that maximizes:
Array Rm represents the cross-correlation between the m-th filtered basis vector qm(n) and p(n). Similarly, the second cross-correlator computes cross-correlation matrix Dmj in
where 1≦m≦j≦M. Matrix Dmj represents the cross-correlation between pairs of individual filtered basis vectors. Note that Dmj is a symmetric matrix. Therefore, approximately half of the terms need only be evaluated as shown by the limits of the subscripts.
can be used to derive fi(n) as follows:
where fi(n) is the zero state response of the filters to excitation vector ui(n), and where qm(n) is the zero state response of the filters to basis vector vm(n) Equation {11}:
can be rewritten using equation {10} as:
Using equation {8}, this can be simplified to:
which is computed in
into the following:
which may be expanded to be:
Substituting by using equation {9} yields:
By noting that a codeword and its complement, i.e., wherein all the codeword bits are inverted, both have the same value of [Ci]2/Gi, both codevectors can be evaluated at the same time. The codeword computations are then halved. Thus, using equation {19} evaluated for i=0, the first energy term G0 becomes:
which is computed in
C k =C k−1+2θ1 R 1 {21}
This was derived from equation {13} by substituting −θl for θl.
which assumes that Djk is stored as a symmetric matrix with only values for j≦k being stored. Equation {22} was derived from equation {19} in the same manner.
2M≧2M
TABLE 1 |
|
The first of the J codebooks is searched for the best codevector. The codebook search is done over the first K samples of the weighted target vector p(n) as shown in
Claims (24)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US10/227,725 US7337110B2 (en) | 2002-08-26 | 2002-08-26 | Structured VSELP codebook for low complexity search |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US10/227,725 US7337110B2 (en) | 2002-08-26 | 2002-08-26 | Structured VSELP codebook for low complexity search |
Publications (2)
Publication Number | Publication Date |
---|---|
US20040039567A1 US20040039567A1 (en) | 2004-02-26 |
US7337110B2 true US7337110B2 (en) | 2008-02-26 |
Family
ID=31887524
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US10/227,725 Active 2025-08-30 US7337110B2 (en) | 2002-08-26 | 2002-08-26 | Structured VSELP codebook for low complexity search |
Country Status (1)
Country | Link |
---|---|
US (1) | US7337110B2 (en) |
Cited By (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20090304496A1 (en) * | 2006-09-19 | 2009-12-10 | Dresser-Rand Company | Rotary separator drum seal |
US20110097216A1 (en) * | 2009-10-22 | 2011-04-28 | Dresser-Rand Company | Lubrication system for subsea compressor |
US8079805B2 (en) | 2008-06-25 | 2011-12-20 | Dresser-Rand Company | Rotary separator and shaft coupler for compressors |
US8231336B2 (en) | 2006-09-25 | 2012-07-31 | Dresser-Rand Company | Fluid deflector for fluid separator devices |
US10262646B2 (en) | 2017-01-09 | 2019-04-16 | Media Overkill, LLC | Multi-source switched sequence oscillator waveform compositing system |
CN111034062A (en) * | 2017-06-23 | 2020-04-17 | 株式会社Ntt都科摩 | User terminal and wireless communication method |
US11721349B2 (en) | 2014-04-17 | 2023-08-08 | Voiceage Evs Llc | Methods, encoder and decoder for linear predictive encoding and decoding of sound signals upon transition between frames having different sampling rates |
Families Citing this family (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
DK2831757T3 (en) * | 2012-03-29 | 2019-08-19 | Ericsson Telefon Ab L M | Vector quantizer |
CN104282308B (en) | 2013-07-04 | 2017-07-14 | 华为技术有限公司 | The vector quantization method and device of spectral envelope |
Citations (18)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4817157A (en) | 1988-01-07 | 1989-03-28 | Motorola, Inc. | Digital speech coder having improved vector excitation source |
US5241650A (en) | 1989-10-17 | 1993-08-31 | Motorola, Inc. | Digital speech decoder having a postfilter with reduced spectral distortion |
US5253269A (en) | 1991-09-05 | 1993-10-12 | Motorola, Inc. | Delta-coded lag information for use in a speech coder |
US5265219A (en) | 1990-06-07 | 1993-11-23 | Motorola, Inc. | Speech encoder using a soft interpolation decision for spectral parameters |
US5359696A (en) | 1988-06-28 | 1994-10-25 | Motorola Inc. | Digital speech coder having improved sub-sample resolution long-term predictor |
US5434947A (en) | 1993-02-23 | 1995-07-18 | Motorola | Method for generating a spectral noise weighting filter for use in a speech coder |
US5485581A (en) * | 1991-02-26 | 1996-01-16 | Nec Corporation | Speech coding method and system |
US5490230A (en) | 1989-10-17 | 1996-02-06 | Gerson; Ira A. | Digital speech coder having optimized signal energy parameters |
US5528723A (en) | 1990-12-28 | 1996-06-18 | Motorola, Inc. | Digital speech coder and method utilizing harmonic noise weighting |
US5642368A (en) | 1991-09-05 | 1997-06-24 | Motorola, Inc. | Error protection for multimode speech coders |
US5657418A (en) | 1991-09-05 | 1997-08-12 | Motorola, Inc. | Provision of speech coder gain information using multiple coding modes |
US5675702A (en) | 1993-03-26 | 1997-10-07 | Motorola, Inc. | Multi-segment vector quantizer for a speech coder suitable for use in a radiotelephone |
US5692101A (en) | 1995-11-20 | 1997-11-25 | Motorola, Inc. | Speech coding method and apparatus using mean squared error modifier for selected speech coder parameters using VSELP techniques |
US5768613A (en) * | 1990-07-06 | 1998-06-16 | Advanced Micro Devices, Inc. | Computing apparatus configured for partitioned processing |
US5936605A (en) * | 1994-06-27 | 1999-08-10 | Kodak Limited | Lossy compression and expansion algorithm for image representative data |
US6073092A (en) * | 1997-06-26 | 2000-06-06 | Telogy Networks, Inc. | Method for speech coding based on a code excited linear prediction (CELP) model |
US6269332B1 (en) * | 1997-09-30 | 2001-07-31 | Siemens Aktiengesellschaft | Method of encoding a speech signal |
US6397178B1 (en) * | 1998-09-18 | 2002-05-28 | Conexant Systems, Inc. | Data organizational scheme for enhanced selection of gain parameters for speech coding |
Family Cites Families (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5621852A (en) * | 1993-12-14 | 1997-04-15 | Interdigital Technology Corporation | Efficient codebook structure for code excited linear prediction coding |
JP3273455B2 (en) * | 1994-10-07 | 2002-04-08 | 日本電信電話株式会社 | Vector quantization method and its decoder |
US6704703B2 (en) * | 2000-02-04 | 2004-03-09 | Scansoft, Inc. | Recursively excited linear prediction speech coder |
-
2002
- 2002-08-26 US US10/227,725 patent/US7337110B2/en active Active
Patent Citations (20)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4817157A (en) | 1988-01-07 | 1989-03-28 | Motorola, Inc. | Digital speech coder having improved vector excitation source |
US5359696A (en) | 1988-06-28 | 1994-10-25 | Motorola Inc. | Digital speech coder having improved sub-sample resolution long-term predictor |
US5241650A (en) | 1989-10-17 | 1993-08-31 | Motorola, Inc. | Digital speech decoder having a postfilter with reduced spectral distortion |
US5490230A (en) | 1989-10-17 | 1996-02-06 | Gerson; Ira A. | Digital speech coder having optimized signal energy parameters |
US5265219A (en) | 1990-06-07 | 1993-11-23 | Motorola, Inc. | Speech encoder using a soft interpolation decision for spectral parameters |
US5768613A (en) * | 1990-07-06 | 1998-06-16 | Advanced Micro Devices, Inc. | Computing apparatus configured for partitioned processing |
US5528723A (en) | 1990-12-28 | 1996-06-18 | Motorola, Inc. | Digital speech coder and method utilizing harmonic noise weighting |
US5485581A (en) * | 1991-02-26 | 1996-01-16 | Nec Corporation | Speech coding method and system |
US5657418A (en) | 1991-09-05 | 1997-08-12 | Motorola, Inc. | Provision of speech coder gain information using multiple coding modes |
US5253269A (en) | 1991-09-05 | 1993-10-12 | Motorola, Inc. | Delta-coded lag information for use in a speech coder |
US5642368A (en) | 1991-09-05 | 1997-06-24 | Motorola, Inc. | Error protection for multimode speech coders |
US5434947A (en) | 1993-02-23 | 1995-07-18 | Motorola | Method for generating a spectral noise weighting filter for use in a speech coder |
US5570453A (en) | 1993-02-23 | 1996-10-29 | Motorola, Inc. | Method for generating a spectral noise weighting filter for use in a speech coder |
US5675702A (en) | 1993-03-26 | 1997-10-07 | Motorola, Inc. | Multi-segment vector quantizer for a speech coder suitable for use in a radiotelephone |
US5826224A (en) | 1993-03-26 | 1998-10-20 | Motorola, Inc. | Method of storing reflection coeffients in a vector quantizer for a speech coder to provide reduced storage requirements |
US5936605A (en) * | 1994-06-27 | 1999-08-10 | Kodak Limited | Lossy compression and expansion algorithm for image representative data |
US5692101A (en) | 1995-11-20 | 1997-11-25 | Motorola, Inc. | Speech coding method and apparatus using mean squared error modifier for selected speech coder parameters using VSELP techniques |
US6073092A (en) * | 1997-06-26 | 2000-06-06 | Telogy Networks, Inc. | Method for speech coding based on a code excited linear prediction (CELP) model |
US6269332B1 (en) * | 1997-09-30 | 2001-07-31 | Siemens Aktiengesellschaft | Method of encoding a speech signal |
US6397178B1 (en) * | 1998-09-18 | 2002-05-28 | Conexant Systems, Inc. | Data organizational scheme for enhanced selection of gain parameters for speech coding |
Cited By (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20090304496A1 (en) * | 2006-09-19 | 2009-12-10 | Dresser-Rand Company | Rotary separator drum seal |
US8231336B2 (en) | 2006-09-25 | 2012-07-31 | Dresser-Rand Company | Fluid deflector for fluid separator devices |
US8079805B2 (en) | 2008-06-25 | 2011-12-20 | Dresser-Rand Company | Rotary separator and shaft coupler for compressors |
US20110097216A1 (en) * | 2009-10-22 | 2011-04-28 | Dresser-Rand Company | Lubrication system for subsea compressor |
US11721349B2 (en) | 2014-04-17 | 2023-08-08 | Voiceage Evs Llc | Methods, encoder and decoder for linear predictive encoding and decoding of sound signals upon transition between frames having different sampling rates |
US10262646B2 (en) | 2017-01-09 | 2019-04-16 | Media Overkill, LLC | Multi-source switched sequence oscillator waveform compositing system |
CN111034062A (en) * | 2017-06-23 | 2020-04-17 | 株式会社Ntt都科摩 | User terminal and wireless communication method |
Also Published As
Publication number | Publication date |
---|---|
US20040039567A1 (en) | 2004-02-26 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US5826224A (en) | Method of storing reflection coeffients in a vector quantizer for a speech coder to provide reduced storage requirements | |
CA2275266C (en) | Speech coder and speech decoder | |
EP0422232B1 (en) | Voice encoder | |
US4817157A (en) | Digital speech coder having improved vector excitation source | |
US5717825A (en) | Algebraic code-excited linear prediction speech coding method | |
US5359696A (en) | Digital speech coder having improved sub-sample resolution long-term predictor | |
US6055496A (en) | Vector quantization in celp speech coder | |
EP0773533B1 (en) | Method of synthesizing a block of a speech signal in a CELP-type coder | |
EP0824750B1 (en) | A gain quantization method in analysis-by-synthesis linear predictive speech coding | |
CN101847414B (en) | Method and apparatus for voice coding | |
US7337110B2 (en) | Structured VSELP codebook for low complexity search | |
US6807527B1 (en) | Method and apparatus for determination of an optimum fixed codebook vector | |
US6751585B2 (en) | Speech coder for high quality at low bit rates | |
CA2598870C (en) | Multi-stage vector quantization apparatus and method for speech encoding | |
KR100955126B1 (en) | Vector quantization apparatus | |
Bhattacharya | Efficient vector quantization of LPC parameters for harmonic speech coding | |
Kao | Thesis Report | |
JPH09269800A (en) | Video coding device |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: MOTOROLA, INC., ILLINOISFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:JASIUK, MARK A.;REEL/FRAME:013235/0749Effective date: 20020822 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
CC | Certificate of correction | ||
AS | Assignment |
Owner name: MOTOROLA MOBILITY, INC, ILLINOISFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:MOTOROLA, INC;REEL/FRAME:025673/0558Effective date: 20100731 |
|
FPAY | Fee payment |
Year of fee payment: 4 |
|
AS | Assignment |
Owner name: MOTOROLA MOBILITY LLC, ILLINOISFree format text: CHANGE OF NAME;ASSIGNOR:MOTOROLA MOBILITY, INC.;REEL/FRAME:029216/0282Effective date: 20120622 |
|
AS | Assignment |
Owner name: GOOGLE TECHNOLOGY HOLDINGS LLC, CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:MOTOROLA MOBILITY LLC;REEL/FRAME:034420/0001Effective date: 20141028 |
|
FPAY | Fee payment |
Year of fee payment: 8 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 12TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1553); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 12 |