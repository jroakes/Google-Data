CN115485694A - Machine learning algorithm search - Google Patents
Machine learning algorithm search Download PDFInfo
- Publication number
- CN115485694A CN115485694A CN202180012813.0A CN202180012813A CN115485694A CN 115485694 A CN115485694 A CN 115485694A CN 202180012813 A CN202180012813 A CN 202180012813A CN 115485694 A CN115485694 A CN 115485694A
- Authority
- CN
- China
- Prior art keywords
- machine learning
- candidate
- learning algorithm
- algorithm
- function
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/004—Artificial life, i.e. computing arrangements simulating life
- G06N3/006—Artificial life, i.e. computing arrangements simulating life based on simulated virtual individual or collective life forms, e.g. social simulations or particle swarm optimisation [PSO]
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F18/00—Pattern recognition
- G06F18/20—Analysing
- G06F18/21—Design or setup of recognition systems or techniques; Extraction of features in feature space; Blind source separation
- G06F18/217—Validation; Performance evaluation; Active pattern learning techniques
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F18/00—Pattern recognition
- G06F18/20—Analysing
- G06F18/285—Selection of pattern recognition techniques, e.g. of classifiers in a multi-classifier system
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/082—Learning methods modifying the architecture, e.g. adding, deleting or silencing nodes or connections
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/086—Learning methods using evolutionary algorithms, e.g. genetic algorithms or genetic programming
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N5/00—Computing arrangements using knowledge-based models
- G06N5/01—Dynamic search techniques; Heuristics; Dynamic trees; Branch-and-bound
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N7/00—Computing arrangements based on specific mathematical models
- G06N7/01—Probabilistic graphical models, e.g. probabilistic networks
Abstract
A method for searching output Machine Learning (ML) algorithms to perform ML tasks is described. The method comprises the following steps: a set of training examples and a set of validation examples are received, and a sequence of candidate ML algorithms is generated to perform a task. For each candidate ML algorithm in the sequence, the method comprises: the method may include setting one or more training parameters for a candidate ML algorithm by executing a respective candidate set function, training the candidate ML algorithm by processing a set of training examples using a respective candidate prediction function and a respective candidate learning function, and evaluating performance of the trained candidate ML algorithm by executing the respective candidate prediction function on a set of validation examples to determine a performance metric. The method includes selecting a training candidate ML algorithm having a best performance metric as an output ML algorithm for the task.
Description
Cross Reference to Related Applications
This application is a non-provisional application of U.S. provisional patent application No.62/971,786, filed on 7/2/2020 and claiming priority, the entire contents of which are incorporated herein by reference.
Background
The present description relates to determining a machine learning algorithm to perform a machine learning task.
The machine learning algorithm can be, for example, a trained neural network that has been trained to perform a task.
Neural networks are machine learning models that employ one or more layers of nonlinear units to predict an output for a received input. In addition to the output layer, some neural networks include one or more hidden layers. The output of each hidden layer is used as an input to the next layer in the network, i.e. the next hidden layer or output layer. Each layer of the network generates an output from the received input in accordance with the current values of the respective set of parameters.
Disclosure of Invention
This specification describes a system implemented as a computer program on one or more computers in one or more locations that determines output machine learning algorithms to perform a particular machine learning task.
The subject matter described in this specification can be implemented in particular embodiments to realize one or more of the following advantages. Instead of building a neural network by combining complex, manually designed components (e.g., convolution, batch norm, and discard) as in previous neural architecture search methods, the techniques described in this specification allow the system to automatically search the entire machine learning algorithm (e.g., starting from zero), with little restriction on the form of the algorithm, and using only basic mathematical operations as building blocks. Thus, compared to conventional techniques for automated machine learning research, the system requires much less human design, saves human research time and allows for the discovery of non-neural network algorithms (because the system does not assume the presence of neural networks or gradients when defining the search space), which focus primarily on the architecture of neural networks and rely on using layers of complex expert design as building blocks or similarly constrained search spaces that rely heavily on human design. Furthermore, by moving away from the search space designed by experts, the described techniques can reduce human bias and can ultimately lead to creative new machine learning concepts. In addition, using the subject matter described herein to construct machine learning algorithms can result in improved performance of machine learning models over particular machine learning tasks. For example, where the machine learning task is an image/audio classification task, the accuracy and/or efficiency of the classification may be improved.
The details of one or more embodiments of the subject matter of this specification are set forth in the accompanying drawings and the description below. Other features, aspects, and advantages of the subject matter will become apparent from the description, the drawings, and the claims.
Drawings
FIG. 1 illustrates an example machine learning algorithm search system.
Fig. 2 is a flow diagram of an example process for searching one or more candidate machine learning algorithms.
FIG. 3 is a flow diagram of an example process for searching output machine learning algorithms to perform machine learning tasks.
Fig. 4 illustrates an example of a mutation for modifying a parent candidate machine learning algorithm to generate one or more child candidate machine learning algorithms.
Fig. 5 illustrates an example of an output machine learning algorithm.
Like reference numbers and designations in the various drawings indicate like elements.
Detailed Description
This specification describes a system implemented as a computer program on one or more computers in one or more locations that determines output machine learning algorithms to perform a particular machine learning task (or set of machine learning tasks).
The machine learning algorithm defines a model architecture of a machine learning model (neural network) for performing a task, hyper-parameters for training the model to perform the task, and pre-processing techniques (e.g., data augmentation strategies) applied to the input during, after, or both training.
The machine learning model can be configured to perform any kind of machine learning task, i.e., can be configured to receive any kind of digital data input and generate any kind of score, classification, or regression output based on the input.
In some cases, the machine learning model is a neural network configured to perform image processing tasks, i.e., receiving input images and processing the input images to generate network outputs of the input images. For example, the task may be image classification, and the output generated by the neural network for a given image may be a score for each of a set of classes of objects, where each score represents an estimated likelihood that the image contains an image of an object belonging to the class. As another example, the task can be image embedding generation, and the output generated by the neural network can be numerical embedding of the input image. As yet another example, the task can be object detection, and the output generated by the neural network can identify a location in the input image depicting a particular type of object. As yet another example, the task can be image segmentation, and the output generated by the neural network can assign each pixel of the input image to a class from a set of classes.
As another example, if the input to the neural network is an internet resource (e.g., a web page), a document, or a portion of a document, or a feature extracted from an internet resource, document, or portion of a document, the task can be to classify the resource or document, i.e., the output generated by the neural network for a given internet resource, document, or portion of a document can be a score for each of a set of topics, each score representing an estimated likelihood that the internet resource, document, or portion of a document is about that topic.
As another example, if the input to the neural network is characteristic of the impression context (context) of a particular advertisement, the output generated by the neural network may be a score representing an estimated likelihood that the particular advertisement will be clicked.
As another example, if the input to the neural network is a feature of a personalized recommendation for the user, e.g., a feature characterizing the context of the recommendation, e.g., a feature characterizing an action previously taken by the user, the output generated by the neural network may be a score for each content item in the set of content items, where each score represents an estimated likelihood that the user will respond favorably to being recommended that content item.
As another example, if the input to the neural network is a sequence of text in one language, the output generated by the neural network may be a score for each text segment in a set of text segments in another language, where each score represents an estimated likelihood that a text segment in the other language is a correct translation of the input text to the other language.
As another example, the task may be an audio processing task. For example, if the input to the neural network is a sequence representing a spoken utterance, the output generated by the neural network may be a score for each text segment in the set of text segments, each score representing an estimated likelihood that the text segment is a correct transcription of the utterance. As another example, if the input to the neural network is a sequence representing a spoken utterance, the output generated by the neural network can indicate whether a particular word or phrase ("hotword") was spoken in the utterance. As another example, if the input to the neural network is a sequence representing a spoken utterance, the output generated by the neural network can identify the natural language in which the utterance was spoken.
As another example, a task can be a natural language processing or understanding task that operates on a text sequence of some natural language, such as an implication task, a paraphrase task, a text similarity task, an emotion task, a sentence completion task, a grammar task, and so forth.
As another example, the task can be a text-to-speech task, where the input is text in natural language or a feature of the text in natural language, and the network output is a spectrogram or other data defining audio of the text spoken in natural language.
As another example, the task can be a health prediction task, where the input is electronic health record data for the patient and the output is a prediction related to the patient's future health, e.g., a predicted treatment that should be prescribed to the patient, a likelihood that the patient will have an adverse health event, or a predicted diagnosis of the patient.
As another example, a task can be an agent control task, where the input is an observation characterizing a state of the environment and the output defines an action performed by the agent in response to the observation. The agent can be, for example, a real-world or simulated robot, a control system for an industrial installation, or a control system controlling a different kind of agent.
Fig. 1 illustrates an example machine learning algorithm search system 100. System 100 is an example of a system implemented as a computer program on one or more computers at one or more locations where the systems, components, and techniques described below can be implemented.
To determine an output machine learning algorithm (e.g., output machine learning algorithm 150) to perform a particular machine learning task, system 100 includes an algorithm search subsystem 120 that receives training data set 102. The training data set 102 includes a set of training examples. Each training example in the set of training examples includes an example input for a particular machine learning task and a corresponding example output for the particular machine learning task.
The algorithm search subsystem 120 also receives a verification data set 104 that includes a set of verification examples. Each validation example in the set of validation examples includes a validation input for the particular machine learning task and a corresponding validation output for the particular machine learning task. For example, a larger training data set may have been randomly partitioned to generate training data 102 and validation set 104.
The system 100 can receive the training data 102 and the validation set 104 in any of a variety of ways. For example, the system 100 can receive the training data as an upload from a remote user of the system over a data communication network, e.g., using an Application Programming Interface (API) available by the system 100, and randomly partition the uploaded data into the training data 102 and the validation set 104. As another example, the system 100 can receive input from a user specifying which data that has been maintained by the system 100 should be used to train the trainee neural network, and then divide the specified data into training data 102 and validation sets 104.
After receiving the training data set 102 and the validation data set 104, the subsystem 120 generates a sequence of candidate machine learning algorithms (e.g., candidate algorithms 106, 108, 110) to perform a particular machine learning task. Each candidate machine learning algorithm in the sequence can be represented as a computer program having three component functions including (i) a respective candidate set function represented as Setup (), (ii) a respective candidate learning function represented as Learn (), and (iii) a respective candidate prediction function represented as Predict ().
The respective candidate setup function initializes one or more training parameters of the candidate machine learning algorithm. The training parameters are parameters of operations in the machine learning model that are learned or adjusted through training of the machine learning model. For example, the training parameters may be weights of a neural network layer of the machine learning model. Optionally, the candidate setup function initializes a hyper-parameter (e.g., a learning rate) for training the machine learning model to perform a particular machine learning task.
The corresponding candidate learning function adjusts the training parameters of the candidate machine learning algorithm. The respective candidate prediction functions predict outputs for the particular machine learning task for a given input of the particular machine learning task using the adjusted training parameters.
More specifically, the candidate prediction function and the candidate learning function are alternately executed during training of the machine learning model using the training data 102. The candidate prediction function is executed on a batch of a plurality of training examples, and the candidate learning function is executed on an output generated by the candidate prediction function for the batch of the plurality of training examples. Specifically, for a given training example (x, y) in a batch of training examples of training data 102, the candidate prediction function takes example input x as input and processes the example input x using current training parameters to generate a predicted output y' of the example input x for a particular machine learning task. The candidate learning function takes as input the example output y and the prediction output y 'in the training example (x, y), and adjusts the training parameters of the candidate machine learning algorithm based on the error between y and y'. The above process is repeated for the next training example in the batch (i.e., the candidate prediction function takes as input the next example input in the next training example of the batch, and processes the next example input using the adjusted training parameters to generate the next prediction output, and so on).
The sequence of candidate machine learning algorithms includes at least a subset of the algorithms in which two or more of the set function, the prediction function, and the learning function are different from each other.
In some implementations, the subsystem 120 may initialize the sequence of candidate ML algorithms to an empty sequence, i.e., none of the three component functions has any instructions or lines of code.
In some other implementations, the subsystem 120 may initialize the sequence of candidate ML algorithms by initializing each of the candidate setup function, the candidate prediction function, and the candidate prediction function of the first candidate machine learning algorithm in the sequence of candidate machine learning algorithms with one or more instructions (e.g., random instructions).
To generate a sequence of candidate machine learning algorithms, the subsystem 120 searches one or more candidate machine learning algorithms through a machine learning algorithm search space.
The candidate machine learning algorithm can be represented as a computer program, which is a sequence of instructions that act on virtual memory.
The machine learning algorithm search space is defined by a sequence of instructions including (i) instructions specifying operations to be performed by a set-up function of a given candidate machine learning algorithm, (ii) instructions specifying operations to be performed by a learning function of the given candidate machine learning algorithm, and (iii) instructions specifying operations to be performed by a prediction function of the given candidate machine learning algorithm.
Each instruction includes an operation (also referred to as an op) from a predetermined set of operations. For example, the set of operations may include one or more of arithmetic operations (e.g., "multiply scalar by vector"), trigonometric operations, pre-calculus operations, linear algebraic operations, or probabilistic and statistical operations. In some cases, operations in the operation set may require real-valued constants (e.g., μ and σ for random gaussian sampling operations) that are also searched. To avoid biasing the selection of operations, a criterion may be applied to a predetermined set of operations to force none of the operations in the set to exceed a threshold level of complexity.
In addition, each instruction includes a set of arguments. For example, the arguments may be addresses in virtual memory (e.g., "read input from scalar address 0 and vector address 3; write output to vector address 2").
In some implementations, the subsystem 120 searches for one or more candidate machine learning algorithms through a machine learning algorithm search space by performing a regularized evolutionary search process. In particular, at each iteration of the process, the subsystem 120 selects a parent candidate machine learning algorithm from the current sequence of candidate machine learning algorithms. The subsystem 120 modifies the parent candidate machine learning algorithm by using the mutation to generate one or more child candidate machine learning algorithms (also referred to as "child algorithms" for simplicity). The mutations that generate the sub-algorithms from the parent algorithm are customized to the search space. For example, the subsystem 120 may use random selection among the following types of mutations: inserting a random instruction at a random location in the component function, (ii) removing an instruction at a random location in the component function, (iii) randomizing all instructions in the component function, or (iv) modifying one of the arguments of an instruction in the component function by replacing one of the arguments of the instruction in the component function with a random selection (e.g., "swap output addresses" or "change values of constants"). Examples of mutations are described in further detail below with reference to fig. 4.
In some other implementations, instead of using a regularized evolutionary search, the subsystem 120 searches for one or more candidate Machine Learning (ML) algorithms through a machine learning algorithm search space by performing a random search process, wherein the one or more candidate machine learning algorithms are randomly selected from the search space according to a particular distribution.
After searching for the one or more candidate ML algorithms, the subsystem 120 adds the one or more candidate ML algorithms to the current sequence of candidate ML algorithms.
In some implementations, the subsystem 120 can remove existing candidate machine learning algorithms from the current sequence of candidate machine learning algorithms after one or more new candidate ML algorithms are added to the sequence. For example, the subsystem 120 may remove the oldest candidate machine learning algorithm in the current sequence of candidate machine learning algorithms.
The subsystem 120 may repeat the search process multiple times until a criterion is satisfied, e.g., until the number of candidate ML algorithms in the sequence has reached a threshold number, or until a predetermined level of accuracy of the candidate ML algorithms in the sequence is obtained.
The process for searching one or more candidate machine learning algorithms to generate a sequence of candidate ML algorithms is described in more detail below with reference to fig. 2.
For each of the candidate ML algorithms in the sequence, the subsystem 120 sets one or more training parameters for the candidate machine learning algorithm by executing a candidate set function associated with the candidate ML algorithm. Subsystem 120 trains the candidate machine learning algorithm on training data 102 to adjust one or more training parameters by processing the training sample set using the candidate prediction function and the candidate learning function associated with the candidate ML algorithm. The subsystem 120 may train the candidate machine learning algorithm until one or more criteria are met (e.g., until convergence, or until a predetermined performance level is obtained).
The subsystem 120 evaluates the performance of the trained candidate machine learning algorithm by executing the candidate prediction function on the set of validation examples to determine a performance metric for the trained candidate machine learning algorithm. For example, as shown in FIG. 1, subsystem 120 determines performance metrics 112, 114, and 116 for candidate ML algorithms 106, 108, and 110, respectively. The performance metric can be, for example, a validation loss, a training loss, a weighted combination of validation loss and training loss, or any metric suitable for a particular machine learning task.
In some implementations, the subsystem 120 can evaluate the performance of the trained candidate machine learning algorithm by performing a candidate prediction function of the trained candidate ML algorithm on a validation instance of a single validation dataset (e.g., validation dataset 104).
In some other implementations, the subsystem 120 may evaluate the performance of the trained candidate machine learning algorithm by performing a candidate prediction function of the trained candidate ML algorithm on validation examples of the plurality of validation data sets. This would allow for a better generalization of the new data set (or new machine learning task) by the output machine learning algorithm.
After evaluating the algorithms, in some embodiments, subsystem 120 selects the trained candidate machine learning algorithm with the best performance metric among the trained candidate machine learning algorithms as output machine learning algorithm 150 for the particular machine learning task. In some other implementations, the subsystem 120 selects a plurality of trained candidate machine learning algorithm sets with the highest performance metrics, trains each candidate machine learning algorithm in the set longer, and then selects the algorithm with the best performance metric among the algorithms in the set as the output machine learning algorithm 150 for the particular machine learning task. FIG. 5 shows an example of an output machine learning algorithm that may be generated by the above-described process.
In some embodiments, to achieve higher search speeds, the subsystem 120 may perform the search process in parallel by using parallel budgets of workers and using a central server. Each worker runs the regularized evolution on its own population (i.e., its own sequence of candidate ML algorithms). The worker is able to exchange algorithms through migration. That is, the worker can periodically upload the randomly selected candidate algorithm to the central server. The central server replies with a candidate algorithm sampled randomly across all workers and replaces a portion (e.g., half, one-third, one-fourth, or any other portion) of the local population (i.e., random migration).
For example, for each predetermined number of evaluations of the performance of the candidate machine learning algorithm (e.g., for each 100 to 10000 evaluations), each worker uploads a plurality of candidate algorithms to the central server to replace corresponding portions of the local population. For example, the work implement can upload
In some embodiments, to further speed up the search process (e.g., 4, 8, or 10 times faster), the subsystem 120 may use a Functional Equivalence Check (FEC) technique to detect equivalent candidate ML algorithms. This technique is useful because the search space is not heavily designed, so it allows for abrupt changes that have no impact on accuracy (e.g., adding instructions to write addresses that have never been read). When these mutations occur, the child algorithm behaves the same as its parent algorithm. FEC techniques prevent these same-function algorithms from being evaluated repeatedly (i.e., trained and validated many times in full), thus saving time and computational resources that would otherwise be required to evaluate these equivalent algorithms.
In general, the subsystem 120 uses FEC techniques as follows. The subsystem 120 performs a novelty check that confirms whether the sub-candidate machine learning algorithm has a different behavior than the current sequence of candidate machine learning algorithms. In response to determining that the novelty check is yes (which means that the sub-candidate machine learning algorithm has a different behavior than the current sequence of candidate machine learning algorithms), the system adds the sub-candidate machine learning algorithm to the current sequence of candidate machine learning algorithms. In response to determining that the novelty check is no, the subsystem 120 skips evaluation of the sub-candidate machine learning algorithm.
More specifically, the subsystem 120 maintains a cache that maps the evaluated algorithm fingerprints to their accuracy. Before evaluating the candidate algorithm, the subsystem 120 fingerprints it and queries the cache to see if it has already been evaluated. If it has already been evaluated, the subsystem 120 reuses the stored accuracy, rather than computing it again. In this way, for diversity, the subsystem 120 can maintain different implementations of the same candidate algorithm: although they now yield the same accuracy, they may behave differently upon further mutation.
For example, to fingerprint a candidate algorithm, the subsystem 120 trains the algorithm for 10 steps and verifies the algorithm over 10 verification examples. The 20 resulting predictions are then truncated and hashed to produce an integer fingerprint. The cache may hold a large number of fingerprint-accuracy pairs (e.g., 100,000 fingerprint-accuracy pairs).
Other techniques may be used to additionally improve the quality of the search. For example, in addition to training data for a particular machine learning task, some workers can be allowed to search over training data for additional machine learning tasks to promote diversity.
In some embodiments, after the output machine learning algorithm 150 is determined, the system 100 deploys the machine learning model defined by the output ML algorithm 150 and then uses the model to process, for example, requests received from users through APIs provided by the system. In other words, the system uses the machine learning model defined by the output ML algorithm 150 to generate new network outputs for the new network inputs.
Instead of or in addition to using the machine learning model defined by the output ML algorithm 150, the system 100 can provide data specifying the output machine learning algorithm 150 to a user submitting a request to find the machine learning model, e.g., through an API, to perform a particular ML task.
Fig. 2 is a flow diagram of an example process 200 for searching one or more candidate machine learning algorithms. For convenience, process 200 will be described as being performed by a system of one or more computers located at one or more locations. For example, a machine learning algorithm search system suitably programmed in accordance with the present description, such as machine learning algorithm search system 100 of fig. 1, can perform process 200.
Although process 200 describes searching candidate machine learning algorithms using an evolutionary search, more generally, the system can search candidate machine learning algorithms using any suitable technique, such as a random search or a search using reinforcement learning or bayesian optimization.
The system selects a parent candidate machine learning algorithm (also referred to as a "parent algorithm") from the current sequence of candidate machine learning algorithms (step 202). The parent candidate machine learning algorithm includes a parent setup function, a parent prediction function, and a parent learning function.
In some implementations, to select the parent algorithm, the system randomly selects a plurality of candidate machine learning algorithms from a current sequence of candidate machine learning algorithms.
In these embodiments, the system selects the selected candidate machine learning algorithm with the highest performance metric among the plurality of candidate machine learning algorithms as the parent candidate machine learning algorithm.
In some other embodiments, to select the parent algorithm, the system selects a plurality of highest performing candidate machine learning algorithms from the current sequence of candidate machine learning algorithms. For example, the system selects the two highest performing algorithms, or selects the ten current highest performing algorithms, and then randomly selects two of them. The system then randomly selects one of these selected highest performing algorithms as the parent algorithm.
The system modifies the parent candidate machine learning algorithm to generate one or more child candidate machine learning algorithms (step 204). Each sub-candidate machine learning algorithm (also referred to as a "sub-algorithm") includes a sub-set function, a sub-prediction function, and a sub-learning function.
To generate one or more sub-algorithms from a parent algorithm, the system performs the following steps one or more times.
The system performs one or more mutations from the set of mutations for at least one of a parent set function, a parent prediction function, or a parent learning function of the parent algorithm. The set of mutations includes, for example, at least one of: the method may include (i) inserting a random instruction (e.g., an instruction having a random operation and/or a set of random arguments) into a random location in the current component function, (ii) removing the instruction at the random location in the current component function, (iii) randomizing all instructions in the current component function, or (iv) modifying a random argument of another random instruction in the current component function. The system creates a sub-algorithm with a sub-setup function, a sub-prediction function, and a sub-learning function that are created by modifying at least one of the parent setup function, the parent prediction function, or the parent learning function, respectively, as described above.
The system adds one or more sub-candidate machine learning algorithms to the current sequence of candidate machine learning algorithms (step 206).
Before adding the sub-algorithms to the current sequence of candidate machine learning algorithms, the system performs a novelty check that confirms whether each sub-candidate machine learning algorithm has a different behavior than the current sequence of candidate machine learning algorithms. In response to determining that the novelty check is yes (which means that the sub-candidate machine learning algorithm has a different behavior than the current sequence of candidate machine learning algorithms), the system adds the sub-candidate machine learning algorithm to the current sequence of candidate machine learning algorithms. In response to determining that the novelty check is no, the system skips evaluation of the sub-candidate machine learning algorithm and does not add the sub-algorithm to the current sequence. The novelty check is performed by using a functionally equivalent checking technique.
In some implementations, the system evaluates each sub-candidate ML algorithm before adding the sub-algorithm to the current sequence of candidate machine learning algorithms. In some implementations, the system does not evaluate the sub-algorithms before adding them to the current sequence of candidate machine learning algorithms. Instead, when the system selects them from the sequence, the system evaluates them to determine the parent algorithm.
To evaluate the candidate machine learning algorithm, the system sets one or more training parameters of the candidate machine learning algorithm by executing a set function of the candidate ML algorithm, trains the candidate machine learning algorithm to adjust the one or more training parameters by processing a set of training examples using a candidate prediction function and the candidate learning function of the candidate ML algorithm, and determines a performance metric of the trained candidate machine learning algorithm by executing the candidate prediction function of the candidate ML algorithm on a set of validation samples.
In some implementations, the system can remove existing candidate machine learning algorithms from the current sequence of candidate machine learning algorithms after one or more sub-candidate ML algorithms are added to the sequence. For example, the system may remove the oldest candidate machine learning algorithm in the current sequence of candidate machine learning algorithms or the worst performing candidate algorithm in the current sequence.
The system can repeat the above-described search process multiple times until a criterion is satisfied, e.g., until the number of candidate ML algorithms in the sequence has reached a threshold number, or until a predetermined level of accuracy of the candidate ML algorithms in the sequence is obtained.
Fig. 3 is a flow diagram of an example process 300 for searching output machine learning algorithms to perform a machine learning task. For convenience, process 300 will be described as being performed by a system of one or more computers located at one or more locations. For example, a machine learning algorithm search system suitably programmed in accordance with the subject specification, such as machine learning algorithm search system 100 of fig. 1, can perform process 300.
The system receives a set of training examples (step 302). Each training example in the set of training examples includes an example input and an example output.
The system receives a set of verification examples (step 304). Each verification instance in the set of verification instances includes a verification input and a verification output.
The system generates a sequence of candidate machine learning algorithms to perform a particular machine learning task (step 306). Each candidate machine learning algorithm in the sequence includes a respective candidate setup function that initializes one or more training parameters of the candidate machine learning algorithm, a respective candidate learning function that adjusts the training parameters of the candidate machine learning algorithm, and a respective candidate prediction function that predicts an output for a given input using the adjusted training parameters. The process for generating a sequence of candidate machine learning algorithms is described in more detail above with reference to fig. 1 and 2.
For each of the candidate ML algorithms in the sequence, the system performs steps 308-312 as follows.
The system sets one or more training parameters for the candidate machine learning algorithm by executing a candidate set-up function associated with the candidate ML algorithm (step 308).
The system trains a candidate machine learning algorithm to adjust one or more training parameters by processing a set of training examples using a candidate prediction function and a candidate learning function associated with the candidate ML algorithm (310).
The system evaluates the performance of the trained candidate machine learning algorithm by performing a candidate prediction function on the set of validation examples to determine a performance metric for the trained candidate machine learning algorithm (step 312).
The system then selects the trained candidate machine learning algorithm with the best performance metric among the trained candidate machine learning algorithms as the output machine learning algorithm for the particular machine learning task (step 314). An example of an output machine learning algorithm that may be generated by the above-described process is shown in FIG. 5.
Fig. 4 illustrates an example of a mutation for modifying a parent candidate machine learning algorithm (also referred to as a "parent algorithm") to generate one or more child candidate machine learning algorithms (also referred to as "child algorithms"). In fig. 4, the parent algorithm is on the left and the child algorithm is on the right. In this example, the parent and child algorithms are represented as computer programs that act on a small virtual memory with separate address spaces for scalar, vector, and matrix variables (e.g., s1, v1, m 1), all of which are floating point and share the dimensions of the input features (F) for the input of a particular machine learning task. A program is a sequence of instructions. Each instruction has an operation or op that determines its function (e.g., "multiply scalar by vector"). Table S1 includes a list of possible operations for the operations shown in the parent and child algorithms of fig. 4.
In the type (i) mutation example, a child algorithm is created by inserting random instructions into the corresponding parent algorithm. In the type (ii) mutation example, a child algorithm is created by replacing one or more instructions of the corresponding parent algorithm with a randomized instruction set. In the type (iii) mutation example, a child algorithm is created by modifying the arguments of the instructions corresponding to the parent algorithm.
Table S1: the operation of the vocabulary s is carried out,
Table S1: operational vocabulary (continue)
Fig. 5 shows an example of an output machine learning algorithm 500. In this example, the particular machine learning task is image classification, and the output generated by the machine learning model defined by the output machine learning algorithm for a given image is a score for each object class in a set of object classes, where each score represents an estimated likelihood that the image contains an image of an object belonging to that class.
In particular, the instructions 502 in the Setup () function in fig. 5 initialize a hyper-parameter (e.g., learning rate) for training the machine learning model to perform the image classification task.
The Predict () function, including instructions 504, receives the input features v0 of the example input x in the training example (x, y), and processes the input features v0 using the current training parameters of the output algorithm 500 to generate the predicted output s1 of the input features v0 for the image classification task.
The Learn () function, which includes instructions 506, takes as input the example output y (i.e., label s 0) and the prediction output s1 in the training example (x, y). The Learn () function adjusts the training parameters of the output algorithm 500 based on the error s3 between s0 and s1.
The term "configured" is used herein in connection with system and computer program components. For a system of one or more computers to be configured to perform a particular operation or action, it is meant that the system has installed thereon software, firmware, hardware, or a combination thereof that, when executed, causes the system to perform the operation or action. For one or more computer programs to be configured to perform particular operations or actions, it is meant that the one or more programs include instructions that, when executed by a data processing apparatus, cause the apparatus to perform the operations or actions.
Embodiments of the subject matter and the functional operations described in this specification can be implemented in digital electronic circuitry, in tangibly embodied computer software or firmware, in computer hardware comprising the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them. Embodiments of the subject matter described in this specification can be implemented as one or more computer programs, i.e., one or more modules of computer program instructions encoded on a tangible, non-transitory storage medium for execution by, or to control the operation of, data processing apparatus. The computer storage medium can be a machine-readable storage device, a machine-readable storage substrate, a random or serial access memory device, or a combination of one or more of them. Alternatively or in addition, the program instructions can be encoded on an artificially generated propagated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal, that is generated to encode information for transmission to suitable receiver apparatus for execution by data processing apparatus.
The term "data processing apparatus" refers to data processing hardware and encompasses all types of apparatus, devices, and machines for processing data, including by way of example a programmable processor, a computer, or multiple processors or computers. The apparatus can be or further comprise special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit). The apparatus can optionally include, in addition to hardware, code that creates a run-time environment for the computer program, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, or a combination of one or more of them.
A computer program, which may also be referred to or described as a program, software, a software application, an application, a module, a software module, a script, or code, can be written in any form of programming language, including compiled or interpreted languages, or declarative or procedural languages; and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, or other unit suitable for use in a computing environment. A program may, but need not, correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data, e.g., one or more scripts stored in a markup language document, in a single file dedicated to the program in question, or in multiple coordinated files, e.g., files that store one or more modules, sub programs, or portions of code. A computer program can be deployed to be run on one computer or on multiple computers at one site or distributed across multiple sites and interconnected by a data communication network.
In this specification, the term "database" is used broadly to refer to any collection of data: the data need not be structured in any particular way, or at all, and may be stored in a storage device in one or more locations. Thus, for example, the index database can include multiple data collections, each of which can be organized and accessed differently.
Similarly, in this specification, the term "engine" is used broadly to refer to a software-based system, subsystem, or process that is programmed to perform one or more particular functions. Typically, the engine will be implemented as one or more software modules or components installed on one or more computers in one or more locations. In some cases, one or more computers will be dedicated to a particular engine; in other cases, multiple engines can be installed and run on the same computer or computers.
The processes and logic flows described in this specification can be performed by one or more programmable computers executing one or more computer programs to perform functions by operating on input data and generating output. The processes and logic flows can also be performed by, and performed by, special purpose logic circuitry, e.g., an FPGA or an ASIC, or a combination of special purpose logic circuitry and one or more programmed computers.
A computer adapted to execute a computer program can be based on a general-purpose or special-purpose microprocessor or both, or any other kind of central processing unit. Generally, a central processing unit will receive instructions and data from a read-only memory or a random access memory or both. The essential elements of a computer are a central processing unit for executing or executing instructions, and one or more memory devices for storing instructions and data. The central processing unit and the memory can be supplemented by, or incorporated in, special purpose logic circuitry. Generally, a computer will also include, or be operatively coupled to receive data from and/or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks. However, a computer need not have such devices. Further, the computer can be embedded in another device, e.g., a mobile telephone, a Personal Digital Assistant (PDA), a mobile audio or video player, a game controller, a Global Positioning System (GPS) receiver, or a portable storage device, e.g., a Universal Serial Bus (USB) flash drive, to name a few.
Computer-readable media suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, e.g., internal hard disks or removable disks; magneto-optical disks; and CD-ROM and DVD-ROM disks.
To provide for interaction with a user, embodiments of the subject matter described in this specification can be implemented on a computer having a display device, e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to the user and a keyboard and a pointing device, e.g., a mouse or a trackball, by which the user can provide input to the computer. Other types of devices can also be used to provide for interaction with a user; for example, feedback provided to the user can be any form of sensory feedback, e.g., visual feedback, auditory feedback, or tactile feedback; and input from the user can be received in any form, including acoustic, speech, or tactile input. In addition, the computer is able to interact with the user by sending and receiving documents to and from the device used by the user; for example, by sending a web page to a web browser on the user device in response to a request received from the web browser. In addition, computers can interact with users by sending text messages or other forms of messages to personal devices, such as smart phones that are running messaging applications, and then receiving response messages from the users.
The data processing apparatus for implementing the machine learning model can also include, for example, a dedicated hardware accelerator unit for processing common and computationally intensive portions of the machine learning training or production, i.e., inference, workload.
The machine learning model can be implemented and deployed using a machine learning framework, such as the TensorFlow framework, the Microsoft cognitive toolkit framework, the Apache Singa framework, or the Apache MXNet framework.
Embodiments of the subject matter described in this specification can be implemented in a computing system that includes a back-end component, e.g., as a data server, or that includes a middleware component, e.g., an application server, or that includes a front-end component, e.g., a client computer having a graphical user interface, a web browser, or an app through which a user can interact with an implementation of the subject matter described in this specification, or any combination of one or more such back-end, middleware, or front-end components. The components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include a Local Area Network (LAN) and a Wide Area Network (WAN), e.g., the internet.
The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other. In some embodiments, the server sends data, e.g., HTML pages, to the user device, e.g., for the purpose of displaying data to and receiving user input from a user interacting with the device as a client. Data generated at the user device, e.g., a result of the user interaction, can be received at the server from the device.
While this specification contains many specific implementation details, these should not be construed as limitations on the scope of any inventions or of what may be claimed, but rather as descriptions of features specific to particular embodiments of particular inventions. Certain features that are described in this specification in the context of separate embodiments can also be combined or implemented in a single embodiment. Conversely, various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Moreover, although features may be described above as acting in certain combinations and even initially claimed as such, one or more features from a claimed combination can in some cases be excised from the combination, and the claimed combination may be directed to a subcombination or variation of a subcombination.
Similarly, while operations are depicted in the drawings and are recited in the claims in a particular order, this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order, or that all illustrated operations be performed, to achieve desirable results. In some cases, multitasking and parallel processing may be advantageous. Moreover, the separation of various system modules and components in the embodiments described above should not be understood as requiring such separation in all embodiments, and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.
Specific embodiments of the subject matter have been described. Other embodiments are within the scope of the following claims. For example, the actions recited in the claims can be performed in a different order and still achieve desirable results. As one example, the processes depicted in the accompanying figures do not necessarily require the particular order shown, or sequential order, to achieve desirable results. In some cases, multitasking and parallel processing may be advantageous.
Claims (19)
1. A method for searching output machine learning algorithms to perform a particular machine learning task, the method comprising:
receiving a set of training examples, each training example in the set of training examples including an example input and an example output;
receiving a set of verification examples, each verification example in the set of verification examples comprising a verification input and a verification output;
generating a sequence of candidate machine learning algorithms to perform the particular machine learning task, each candidate machine learning algorithm in the sequence comprising a respective candidate setup function that initializes one or more training parameters of the candidate machine learning algorithm, a respective candidate learning function that adjusts the training parameters of the candidate machine learning algorithm, and a respective candidate prediction function that uses the adjusted training parameters to predict an output for a given input;
for each candidate machine learning algorithm in the sequence:
setting one or more training parameters for the candidate machine learning algorithm by executing the candidate set-up function,
training the candidate machine learning algorithm to adjust the one or more training parameters by processing the set of training examples using the candidate prediction function and the candidate learning function, an
Evaluating performance of the trained candidate machine learning algorithm by executing the candidate prediction function on the set of validation examples to determine a performance metric of the trained candidate machine learning algorithm; and
selecting the trained candidate machine learning algorithm having the best performance metric among the trained candidate machine learning algorithms as the output machine learning algorithm for the particular machine learning task.
2. The method of claim 1, wherein the particular machine learning task is one of: a classification task, a regression task, or an image recognition task.
3. The method of any of claims 1 or 2, wherein generating the sequence of candidate machine learning algorithms comprises: searching one or more candidate machine learning algorithms through a machine learning algorithm search space,
wherein the machine-learning-algorithm search space is defined by a sequence of instructions, wherein the sequence of instructions includes (i) instructions specifying operations to be performed by a set-up function of a given candidate machine-learning algorithm, (ii) instructions specifying operations to be performed by a learning function of the given candidate machine-learning algorithm, and (iii) instructions specifying operations to be performed by a prediction function of the given candidate machine-learning algorithm.
4. The method of claim 3, wherein each instruction comprises (i) an operation from a predetermined set of operations and (ii) a set of arguments.
5. The method of any of claims 3 or 4, further comprising: initializing, with one or more instructions, each of a first candidate setup function, a first candidate prediction function, and the first candidate prediction function of the first candidate machine learning algorithm in the sequence of candidate machine learning algorithms.
6. The method of any of claims 3-5, wherein searching the machine learning algorithm search space for one or more candidate machine learning algorithms comprises performing a random search process.
7. The method according to any one of claims 3-5, wherein searching the one or more candidate machine learning algorithms through the machine learning algorithm search space comprises searching using reinforcement learning or Bayesian optimization.
8. The method of any of claims 3-5, wherein searching the machine learning algorithm search space for one or more candidate machine learning algorithms comprises performing a regularized evolutionary search process comprising:
selecting a parent candidate machine learning algorithm from a current sequence of candidate machine learning algorithms, the parent candidate machine learning algorithm comprising a parent setup function, a parent prediction function, and a parent learning function, an
Modifying the parent candidate machine learning algorithm to generate one or more child candidate machine learning algorithms, each child candidate machine learning algorithm comprising a child setup function, a child prediction function, and a child learning function.
9. The method of claim 8, wherein selecting the parent candidate machine learning algorithm from the current sequence of candidate machine learning algorithms comprises:
randomly selecting a plurality of candidate machine learning algorithms from the current sequence of candidate machine learning algorithms, an
Selecting the selected candidate machine learning algorithm having the highest performance metric among the plurality of candidate machine learning algorithms as the parent candidate machine learning algorithm.
10. The method of any of claims 8 or 9, wherein modifying the parent candidate machine learning algorithm to generate the one or more child candidate machine learning algorithms comprises:
performing the following steps one or more times:
for at least one of the parent set-up function, the parent prediction function, or the parent learning function of the parent algorithm, performing at least one of: (ii) insert a random instruction into a random location in the current function, (ii) remove an instruction at a random location in the current function, (iii) randomize all instructions in the current function, or (iv) modify a random argument of another random instruction in the current function, and
creating a child candidate machine learning algorithm based on at least one of the modified parent setup function, the modified parent prediction function, or the modified parent learning function.
11. The method of claim 10, further comprising: adding the one or more sub-candidate machine learning algorithms to a current sequence of the candidate machine learning algorithms.
12. The method of claim 11, further comprising: removing a candidate machine learning algorithm from the current sequence of candidate machine learning algorithms.
13. The method of claim 12, wherein the remove candidate machine learning algorithm is an oldest candidate machine learning algorithm in the current sequence of candidate machine learning algorithms.
14. The method of any of claims 7-13, wherein the regularized evolutionary search process is performed in parallel.
15. The method of any of claims 11-14, wherein adding a sub-candidate machine learning algorithm from the one or more sub-candidate machine learning algorithms to the current sequence of candidate machine learning algorithms further comprises:
performing a novelty check that confirms whether the child candidate machine learning algorithm has a different behavior than a current sequence of the candidate machine learning algorithm,
in response to determining that the novelty check is yes, adding the sub-candidate machine learning algorithm to the current sequence of candidate machine learning algorithms, or
In response to determining that the novelty check is no, skipping evaluation of the sub-candidate machine learning algorithm.
16. The method of claim 15, wherein the novelty check is performed using a functionally equivalent checking technique.
17. The method according to any one of claims 1-16, wherein the output machine learning algorithm defines: (i) A model architecture of a machine learning model for performing the particular machine learning task, (ii) hyper-parameters for training the machine learning model to perform the particular machine learning task, and (ii) a pre-processing technique applied to input during the training, after the training, or both.
18. A system comprising one or more computers and one or more storage devices storing instructions that, when executed by the one or more computers, cause the one or more computers to perform operations of the respective methods of any of claims 1-17.
19. One or more computer storage media storing instructions that, when executed by one or more computers, cause the one or more computers to perform the operations of the respective methods of any of claims 1-17.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US202062971786P | 2020-02-07 | 2020-02-07 | |
US62/971,786 | 2020-02-07 | ||
PCT/US2021/016997 WO2021159046A1 (en) | 2020-02-07 | 2021-02-08 | Machine learning algorithm search |
Publications (1)
Publication Number | Publication Date |
---|---|
CN115485694A true CN115485694A (en) | 2022-12-16 |
Family
ID=74798105
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202180012813.0A Pending CN115485694A (en) | 2020-02-07 | 2021-02-08 | Machine learning algorithm search |
Country Status (4)
Country | Link |
---|---|
US (1) | US20220383195A1 (en) |
EP (1) | EP4081949A1 (en) |
CN (1) | CN115485694A (en) |
WO (1) | WO2021159046A1 (en) |
Families Citing this family (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
TWI724515B (en) * | 2019-08-27 | 2021-04-11 | 聯智科創有限公司 | Machine learning service delivery method |
-
2021
- 2021-02-08 CN CN202180012813.0A patent/CN115485694A/en active Pending
- 2021-02-08 WO PCT/US2021/016997 patent/WO2021159046A1/en unknown
- 2021-02-08 US US17/795,087 patent/US20220383195A1/en active Pending
- 2021-02-08 EP EP21708884.8A patent/EP4081949A1/en active Pending
Also Published As
Publication number | Publication date |
---|---|
EP4081949A1 (en) | 2022-11-02 |
WO2021159046A1 (en) | 2021-08-12 |
US20220383195A1 (en) | 2022-12-01 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11544536B2 (en) | Hybrid neural architecture search | |
CN111602148B (en) | Regularized neural network architecture search | |
US20230093469A1 (en) | Regularizing machine learning models | |
US11087201B2 (en) | Neural architecture search using a performance prediction neural network | |
US11113479B2 (en) | Utilizing a gated self-attention memory network model for predicting a candidate answer match to a query | |
KR102170199B1 (en) | Classify input examples using comparison sets | |
US20210019599A1 (en) | Adaptive neural architecture search | |
US20200090043A1 (en) | Generating output data items using template data items | |
EP4094197A1 (en) | Neural architecture search with weight sharing | |
US20220383119A1 (en) | Granular neural network architecture search over low-level primitives | |
CN115485694A (en) | Machine learning algorithm search | |
US20230107409A1 (en) | Ensembling mixture-of-experts neural networks | |
US20230063686A1 (en) | Fine-grained stochastic neural architecture search | |
US20230121404A1 (en) | Searching for normalization-activation layer architectures | |
US20220019856A1 (en) | Predicting neural network performance using neural network gaussian process | |
CN115398446A (en) | Machine learning algorithm search using symbolic programming | |
US20220129760A1 (en) | Training neural networks with label differential privacy | |
US20230206030A1 (en) | Hyperparameter neural network ensembles | |
JP2024519265A (en) | Neural network with feedforward spatial transformation units | |
CN114416970A (en) | Text classification model with role and dialog text classification method and device |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |