DE202020101664U1 - Computer-aided graph optimization - Google Patents
Computer-aided graph optimization Download PDFInfo
- Publication number
- DE202020101664U1 DE202020101664U1 DE202020101664.4U DE202020101664U DE202020101664U1 DE 202020101664 U1 DE202020101664 U1 DE 202020101664U1 DE 202020101664 U DE202020101664 U DE 202020101664U DE 202020101664 U1 DE202020101664 U1 DE 202020101664U1
- Authority
- DE
- Germany
- Prior art keywords
- embedding
- task
- neural network
- graph
- node
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/084—Backpropagation, e.g. using gradient descent
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F18/00—Pattern recognition
- G06F18/20—Analysing
- G06F18/21—Design or setup of recognition systems or techniques; Extraction of features in feature space; Blind source separation
- G06F18/211—Selection of the most significant subset of features
- G06F18/2115—Selection of the most significant subset of features by evaluating different subsets according to an optimisation criterion, e.g. class separability, forward selection or backward elimination
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F18/00—Pattern recognition
- G06F18/20—Analysing
- G06F18/21—Design or setup of recognition systems or techniques; Extraction of features in feature space; Blind source separation
- G06F18/217—Validation; Performance evaluation; Active pattern learning techniques
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F18/00—Pattern recognition
- G06F18/20—Analysing
- G06F18/29—Graphical models, e.g. Bayesian networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/045—Combinations of networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/049—Temporal neural networks, e.g. delay elements, oscillating neurons or pulsed inputs
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F8/00—Arrangements for software engineering
- G06F8/40—Transformation of program code
- G06F8/41—Compilation
- G06F8/44—Encoding
- G06F8/443—Optimisation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/06—Physical realisation, i.e. hardware implementation of neural networks, neurons or parts of neurons
- G06N3/063—Physical realisation, i.e. hardware implementation of neural networks, neurons or parts of neurons using electronic means
Abstract
System, das einen oder mehrere Computer umfasst, und eine oder mehrere Speichervorrichtungen, die Anweisungen speichern, die dann, wenn sie durch den einen oder die mehreren Computer ausgeführt werden, betreibbar sind, um zu veranlassen, dass der eine oder die mehreren Computer Operationen zum Erzeugen einer Aufgabenausgabe zum Ausführen einer Vielzahl von Operationen eines neuronalen Netzes auf einer oder mehreren Verarbeitungsvorrichtungen durchführt oder durchführen, wobei die Aufgabenausgabe für jede der Vielzahl von Operationen des neuronalen Netzes eine jeweilige Entscheidung für eine bestimmte Optimierungsaufgabe umfasst, wobei die Operationen folgendes umfassen:
Erhalten von Daten, die einen Graphen darstellen, der die Vielzahl von Operationen des neuronalen Netzes charakterisiert, wobei jeder Knoten des Graphen eine Operation des neuronalen Netzes charakterisiert und jede Kante des Graphen eine Datenabhängigkeit zwischen den Operationen charakterisiert;
Verarbeiten der Daten, die den Graphen darstellen, unter Verwendung eines neuronalen Netzes zur Grapheneinbettung, um eine Einbettung des Graphen zu erzeugen; und
Verarbeiten der Einbettung des Graphen unter Verwendung eines neuronalen Netzes für Konzepte, um die Aufgabenausgabe zu erzeugen.
A system comprising one or more computers and one or more storage devices that store instructions that, when executed by the one or more computers, are operable to cause the one or more computers to perform operations on the Generating a task output for carrying out a plurality of operations of a neural network on one or more processing devices, the task output for each of the plurality of operations of the neural network comprising a respective decision for a specific optimization task, the operations comprising:
Obtaining data representing a graph characterizing the plurality of operations of the neural network, each node of the graph characterizing an operation of the neural network and each edge of the graph characterizing a data dependency between the operations;
Processing the data representing the graph using a graph embedding neural network to produce an embedding of the graph; and
Process the embedding of the graph using a neural network for concepts to generate the task output.
Description
HINTERGRUNDBACKGROUND
Diese Beschreibung betrifft ein Verarbeiten von rechnergestützten Graphen unter Verwendung neuronaler Netze.This description concerns processing of computational graphs using neural networks.
Neuronale Netze sind Maschinenlernmodelle, die eine oder mehrere Schichten von nichtlinearen Einheiten verwenden, um eine Ausgabe für eine empfangene Eingabe vorherzusagen. Einige neuronale Netze enthalten eine oder mehrere versteckte Schichten zusätzlich zu einer Ausgabeschicht. Die Ausgabe jeder versteckten Schicht wird als Eingabe zu mehreren anderen Schichten im Netz, d.h. einer oder mehreren anderen versteckten Schichten, der Ausgabeschicht oder beiden, verwendet.Neural networks are machine learning models that use one or more layers of nonlinear units to predict output for a received input. Some neural networks contain one or more hidden layers in addition to an output layer. The output of each hidden layer is used as input to several other layers in the network, i.e. one or more other hidden layers, the output layer or both.
ZUSAMMENFASSUNGSUMMARY
Diese Beschreibung beschreibt ein als Computerprogramme auf einem oder mehreren Computern bei einem oder mehreren Standorten implementiertes System, das als Eingabe Daten empfängt, die ein neuronales Netz charakterisieren, und ein Ausführungsoptimierungskonzept zum Optimieren der Ausführung der Operationen des neuronalen Netzes auf einer oder mehreren Verarbeitungsvorrichtungen erzeugt. In dieser Beschreibung sind ein „Ausführungsoptimierungskonzept“ für ein neuronales Netz Daten, die für jede Operation des neuronalen Netzes eine jeweilige Entscheidung für jede von einer oder mehreren unterschiedlichen Ausführungsoptimierungsaufgaben spezifizieren.This description describes a system implemented as computer programs on one or more computers at one or more locations that receives as input data characterizing a neural network and generates an execution optimization concept for optimizing the execution of the operations of the neural network on one or more processing devices. In this description, an “execution optimization concept” for a neural network is data that specify a respective decision for each of one or more different execution optimization tasks for each operation of the neural network.
Das System kann das neuronale Netz unter Verwendung eines rechnergestützten Graphen (der der Einfachheit halber auch „Graph“ genannt wird) darstellen, der Knoten enthält, von welchen wenigstens einige durch Kanten verbunden sind. Jeder Knoten des Graphen stellt eine Operation des neuronalen Netzes dar und jede Kante des Graphen stellt eine Datenabhängigkeit zwischen Operationen des neuronalen Netzes dar. Unter Verwendung des Graphen kann das System das Ausführungsoptimierungskonzept für das neuronale Netz erzeugen. Die eine oder mehreren Verarbeitungsvorrichtungen können dann die Entscheidungen für jede Ausführungsoptimierungsaufgabe verwenden, um die Operationen des neuronalen Netzes auszuführen.The system can represent the neural network using a computerized graph (also called a "graph" for simplicity) that includes nodes, at least some of which are connected by edges. Each node of the graph represents an operation of the neural network and each edge of the graph represents a data dependency between operations of the neural network. Using the graph, the system can generate the execution optimization concept for the neural network. The one or more processing devices can then use the decisions for each execution optimization task to perform the neural network operations.
Der in dieser Beschreibung beschriebene Gegenstand kann in bestimmten Ausführungsformen implementiert sein, um einen oder mehrere der folgenden Vorteile zu realisieren.The subject matter described in this specification can be implemented in certain embodiments to realize one or more of the following advantages.
In dieser Beschreibung beschriebene Techniken lassen zu, die Ausführung der Operationen eines neuronalen Netzes durch Erzeugen eines Konzepts für eine oder mehrere Ausführungsoptimierungsaufgaben zu optimieren. Einige in dieser Beschreibung beschriebene Konzepterzeugungssysteme können so trainiert werden, dass sie gegenüber der zugrundeliegenden Topologie des Graphen invariant sind und daher Konzepte für ein breites Spektrum von Eingabegraphen erzeugen können. Somit kann die Architektur gut auf zuvor ungesehene Graphen verallgemeinern.Techniques described in this specification make it possible to optimize the execution of the operations of a neural network by generating a concept for one or more execution optimization tasks. Some of the concept generation systems described in this specification can be trained to be invariant to the underlying topology of the graph and therefore to generate concepts for a wide range of input graphs. Thus, the architecture can generalize well to previously unseen graphs.
Einige in dieser Beschreibung beschriebene Techniken lassen zu, ein Konzept für mehrere unterschiedliche Ausführungsoptimierungsaufgaben auf einmal zu erzeugen. Weil Graphen-Ausführungsoptimierungsprobleme stark gekoppelt sein können, kann ein gemeinsames Optimieren für mehrere unterschiedliche Ausführungsoptimierungsaufgaben zu Lösungen führen, die die Laufzeit und Vorrichtungsnutzung der Ausführung des neuronalen Netzes verbessern.Some of the techniques described in this description make it possible to create a concept for several different execution optimization tasks at once. Because graph execution optimization problems can be tightly coupled, optimizing together for several different execution optimization tasks can lead to solutions that improve the run time and device utilization of the neural network execution.
Einige existierende Systeme beruhen auf per Hand eingestellten Heuristiken, um die Ausführung eines bestimmten neuronalen Netzes zu optimieren. Diese per Hand eingestellten Heuristiken können vorrichtungsspezifisch sein und können somit nicht auf andere Vorrichtungen verallgemeinert werden. Weiterhin müssen die Heuristiken zur Anpassung an neue Fälle, die aus zuvor ungesehenen Modellarchitekturen entstehen, unter Verwendung von Expertendomänenwissen konstant modifiziert und fein eingestellt bzw. abgestimmt werden. In dieser Beschreibung beschriebene Techniken sind flexibel für einen weiten Bereich von Vorrichtungen und Modellarchitekturen, einschließlich Architekturen, denen während eines Trainierens der neuronalen Netze nicht begegnet wurde.Some existing systems rely on manually adjusted heuristics to optimize the execution of a particular neural network. These manually set heuristics can be device-specific and thus cannot be generalized to other devices. Furthermore, the heuristics for adapting to new cases that arise from previously unseen model architectures must be constantly modified and fine-tuned or coordinated using expert domain knowledge. Techniques described in this specification are flexible for a wide range of device and model architectures, including architectures that were not encountered during training of the neural networks.
Einige existierende System zielen darauf ab, Ausführungsoptimierungskonzepte zum Ausführen der Operationen eines einzelnen bestimmten neuronalen Netzes zu lernen. Das bedeutet, dass die existierenden Systeme für jedes individuelle neuronale Netz neu trainiert werden und die trainierten Parameter der existierenden Systeme nicht auf ein Erzeugen von Konzepten für andere neuronale Netze übertragbar sind. Unter Verwendung von in dieser Beschreibung beschriebenen Techniken kann ein Konzepterzeugungssystem trainiert werden, um Ausführungsoptimierungskonzepte für eine weite Vielfalt von unterschiedlichen neuronalen Netzen zu erzeugen. Diese Techniken können auf rechnergestützte Graphen angewendet werden, die drastisch unterschiedliche Architekturen haben. Weiterhin können diese Techniken zulassen, Ausführungsoptimierungskonzepte für Graphen von realistisch bemaßten Arbeitsbelastungen, z.B. Graphen mit mehr als 1 M oder 10M Knoten, zu erzeugen.Some existing systems aim to learn execution optimization concepts for performing the operations of a single particular neural network. This means that the existing systems are retrained for each individual neural network and the trained parameters of the existing systems cannot be transferred to generating concepts for other neural networks. Using techniques described in this specification, a concept generation system can be trained to generate execution optimization concepts for a wide variety of different neural networks. These techniques can be applied to computational graphs that have drastically different architectures. Furthermore, these techniques can allow execution optimization concepts for graphs of realistically dimensioned workloads, e.g. Create graphs with more than 1M or 10M nodes.
Einige existierende Techniken, die darauf abzielen, Ausführungsoptimierungskonzepte zum Ausführen der Operationen eines neuronalen Netzes zu lernen, sind rechenintensiv, wie z.B. durch Erzeugen von Entscheidungen für einen einzelnen Knoten pro Iteration eines neuronalen Netzes. Ein System, wie es in dieser Beschreibung beschrieben ist, kann ein Ausführungsoptimierungskonzept für ein bestimmtes neuronales Netz auf eine einmalige Weise erzeugen, was die Zeit drastisch reduziert, die erforderlich ist, um ein solches Ausführungsoptimierungskonzept zu erzeugen. Some existing techniques aimed at learning execution optimization concepts for performing neural network operations are computationally intensive, such as by generating decisions for a single node per iteration of a neural network. A system as described in this specification can generate an execution optimization concept for a particular neural network in a unique way, which drastically reduces the time which is required to generate such an execution optimization concept.
Die Details von einer oder mehreren Ausführungsformen des Gegenstands dieser Beschreibung sind in den beigefügten Zeichnungen und der nachstehenden Beschreibung dargelegt. Andere Merkmale, Aspekte und Vorteile des Gegenstands werden aus der Beschreibung, den Zeichnungen und den Ansprüchen offensichtlich werden.The details of one or more embodiments of the subject matter of this specification are set forth in the accompanying drawings and the description below. Other features, aspects and advantages of the subject matter will become apparent from the description, drawings, and claims.
FigurenlisteFigure list
-
1 ist eine graphische Darstellung eines bespielhaften Konzepterzeugungssystems.1 Figure 4 is a diagram of an exemplary concept generation system. -
2 ist eine graphische Darstellung eines beispielhaften neuronalen Netzes für Konzepte.2 Figure 3 is a graphical representation of an exemplary concept neural network. -
3 ist eine graphische Darstellung eines beispielhaften Aufgaben-Unternetzes.3 Figure 4 is a graphical representation of an exemplary task subnet. -
4 ist ein Ablaufdiagramm eines bespielhaften Prozesses zum Erzeugen eines Ausführungsoptimierungskonzepts.4th Figure 4 is a flow diagram of an exemplary process for generating an execution optimization concept. -
5 ist ein Ablaufdiagramm eines bespielhaften Prozesses zum Erzeugen von mehreren Aufgabenausgaben.5 Figure 13 is a flow diagram of an exemplary process for generating multiple task outputs.
Gleiche Bezugszeichen und Bezeichnungen in den verschiedenen Zeichnungen zeigen gleiche Elemente an.The same reference numbers and designations in the different drawings indicate the same elements.
DETAILLIERTE BESCHREIBUNGDETAILED DESCRIPTION
Diese Beschreibung beschreibt ein System, das ein Ausführungsoptimierungskonzept zum Optimieren der Ausführung der Operationen eines neuronalen Netzes auf einer oder mehreren Verarbeitungsvorrichtungen erzeugt. Die Operationen des neuronalen Netzes können Operationen des neuronalen Netzes enthalten, die durch eine oder mehrere Verarbeitungsvorrichtungen während eines Trainierens des neuronalen Netzes ausgeführt werden. Stattdessen oder zusätzlich können die Operationen des neuronalen Netzes Operationen des neuronalen Netzes enthalten, die durch eine oder mehrere Verarbeitungsvorrichtungen während einer Inferenzzeit ausgeführt werden, nachdem das neuronale Netz trainiert worden ist. Das System kann eine Aufgabenausgabe für jede von einer oder mehreren Ausführungsoptimierungsaufgaben erzeugen. Die Aufgabenausgabe für ein bestimmte Ausführungsoptimierungsaufgabe kann für jede Operation des neuronalen Netzes eine jeweilige Entscheidung für die bestimmte Ausführungsoptimierungsaufgabe enthalten.This description describes a system that generates an execution optimization concept for optimizing the execution of the operations of a neural network on one or more processing devices. The neural network operations may include neural network operations performed by one or more processing devices during training of the neural network. Instead, or in addition, the neural network operations may include neural network operations that are performed by one or more processing devices during an inference time after the neural network has been trained. The system can generate a task output for each of one or more execution optimization tasks. The task output for a specific execution optimization task can contain a respective decision for the specific execution optimization task for each operation of the neural network.
Das System kann die Operationen des neuronalen Netzes als einen rechnergestützten Graph darstellen, wo jeder Knoten des Graphen eine Operation des neuronalen Netzes darstellt und jede Kante des Graphen eine Datenabhängigkeit zwischen den Operationen des neuronalen Netzes darstellt.The system may represent the neural network operations as a computerized graph where each node of the graph represents a neural network operation and each edge of the graph represents a data dependency between the neural network operations.
Zum Beispiel kann eine der Ausführungsoptimierungsaufgaben eine Vorrichtungsplatzierung sein, wo jede Operation des neuronalen Netzes zugeordnet ist, um auf einer bestimmten von mehreren Verarbeitungsvorrichtung ausgeführt zu werden. Die Vorrichtungen können irgendwelche geeigneten Typen von Computerhardwarevorrichtungen enthalten, d.h. irgendwelche Vorrichtungen, die wenigstens einige der in dem rechnergestützten Graph dargestellten Operationen durchführen können. Bei einigen Implementierungen sind die Vorrichtungen heterogen. Zum Beispiel können die Vorrichtungen eine Kombination von irgendwelchen von zentralen Verarbeitungseinheiten (CPUs), Grafikverarbeitungseinheiten (GPUs), Tensor-Verarbeitungseinheiten (TPUs), anderen anwendungsspezifischen integrierten Schaltungen (ASICs) oder anderen feldprogrammierbaren Gate-Arrays (FPGAs) mit spezieller Hardware und so weiter sein. Bei einigen anderen Implementierungen sind die Vorrichtungen homogen, d.h. sie enthalten nur Vorrichtungen von demselben Vorrichtungstyp, d.h. nur Vorrichtungen von einem der obigen Typen oder nur Vorrichtungen, die aus derselben Kombination von Vorrichtungen der obigen Typen zusammengesetzt sind. Somit ist die Aufgabenausgabe für diese Ausführungsoptimierungsaufgabe eine Identifikation für jeden Knoten des rechnergestützten Graphen einer bestimmten Verarbeitungsvorrichtung, welcher die durch den Knoten dargestellte Operation zugeordnet ist, d.h. eine 1-aus-n-Codierung, die eine Verarbeitungsvorrichtung identifiziert.For example, one of the execution optimization tasks may be device placement, where each neural network operation is assigned to be performed on a particular one of several processing devices. The devices can include any suitable types of computer hardware devices, i. any devices capable of performing at least some of the operations illustrated in the computerized graph. In some implementations, the devices are heterogeneous. For example, the devices can be a combination of any of central processing units (CPUs), graphics processing units (GPUs), tensor processing units (TPUs), other application specific integrated circuits (ASICs) or other field programmable gate arrays (FPGAs) with specialized hardware, and so on be. In some other implementations, the devices are homogeneous, i. they only contain devices of the same type of device, i. only devices of any of the above types or only devices composed of the same combination of devices of the above types. Thus, the task output for this execution optimization task is an identification for each node of the computerized graph of a particular processing device with which the operation represented by the node is associated, i. a 1-of-n encoding that identifies a processing device.
Als ein weiteres Beispiel kann eine der Ausführungsoptimierungsaufgaben eine Operationszeitplanung sein, wo das System einen Zeitplan für die Ausführung der Operationen des neuronalen Netzes erzeugt. Als ein bestimmtes Beispiel kann das System einen prioritätsbasierten Zeitplaner verwenden, wo jede einer bestimmten Vorrichtung zugeordnete Operation in eine Prioritätswarteschlange gelegt wird, wenn die Operation bereit ist, ausgeführt zu werden (d.h. wenn alle Eingaben zur Operation verfügbar sind). Hier kann die Aufgabenausgabe für diese Ausführungsoptimierungsaufgabe eine Identifikation eines Prioritätswerts für jede Operation des neuronalen Netzes sein, z.B. eine 1-aus-n-Codierung, die den Prioritätswert identifiziert. Der jeweilige Prioritätswert für jede Operation des neuronalen Netzes kann dann durch die Verarbeitungsvorrichtung verwendet werden, die zugeordnet ist, um die Operation auszuführen, wenn Operationen einer Push- und Pop-Verarbeitung bei der Prioritätswarteschlange unterzogen werden.As another example, one of the execution optimization tasks may be operation scheduling, where the system creates a schedule for the execution of the neural network operations. As a particular example, the system may use a priority-based scheduler where any operation associated with a particular device is placed in a priority queue when the operation is ready to be performed (ie, when all inputs to the operation are available). Here the task output for this execution optimization task can be an identification of a priority value for each operation of the neural network, for example a 1-out-of-n coding which identifies the priority value. The respective Priority value for each neural network operation can then be used by the processing device assigned to perform the operation when operations are push and pop processing on the priority queue.
Als ein weiteres Beispiel kann eine der Ausführungsoptimierungsaufgaben eine Operationsverbindung bzw. -fusion sein, wo mehrere Operationen des neuronalen Netzes vereinigt werden, so dass die Verarbeitungsvorrichtung, die zugeordnet ist, um die mehreren Operationen auszuführen, die mehreren Operationen als eine einzige Operation behandelt. Eine Operationsverbindung kann zum Beispiel nützlich sein, wenn die Ausgabe einer ersten Operation die Eingabe zu einer zweiten Operation ist. In diesem Fall muss dann, wenn die Verarbeitungsvorrichtung die zwei Operationen als eine einzige Operation behandelt, die Vorrichtung die Ausgabe der ersten Operation nicht zu einem Speicher schreiben und später, wenn die Vorrichtung gerade die zweite Operation ausführt, die Ausgabe zurück aus dem Speicher lesen. Somit kann die Aufgabenausgabe für diese Ausführungsoptimierungsaufgabe eine Identifikation von zwei oder mehr Knoten des rechnergestützten Graphen sein, die durch die zugeordnete Verarbeitungsvorrichtung als eine einzige Operation zu behandeln sind.As another example, one of the execution optimization tasks may be an operation fusion, where multiple neural network operations are merged so that the processing device associated to perform the multiple operations treats the multiple operations as a single operation. An operation association can be useful, for example, when the output of a first operation is the input to a second operation. In this case, if the processing device treats the two operations as a single operation, the device need not write the output of the first operation to memory and later, when the device is performing the second operation, read the output back from memory. Thus, the task output for this execution optimization task may be an identification of two or more nodes of the computerized graph that are to be treated as a single operation by the associated processing device.
Diese Ausführungsoptimierungsaufgaben können jeweils stark gekoppelt sein, d.h. die für eine Ausführungsoptimierungsaufgabe getroffenen Entscheidungen können die optimale Entscheidung für eine weitere Ausführungsoptimierungsaufgabe beeinflussen. Als ein bestimmtes Beispiel kann das System dann, wenn das System die während einer Operationsverbindung getroffenen Entscheidungen berücksichtigt, wenn es eine Vorrichtungsplatzierung durchführt, zwei Operationen, die gute Kandidaten für eine Verbindung sein würden, derselben Vorrichtung zuordnen. Als ein weiteres bestimmtes Beispiel kann das System dann, wenn das System die während einer Operationszeitplanung berücksichtigt, wenn es eine Vorrichtungsplatzierung durchführt, die Operationen hoher Priorität gleichmäßig über alle Vorrichtungen verteilen und die Operationen niedriger Priorität gleichmäßig über alle Vorrichtungen verteilen, was zu einer hohen Vorrichtungsnutzung führt. Das bedeutet, dass das System dann, wenn man mehrere unterschiedliche Ausführungsoptimierungsaufgaben gemeinsam betrachtet, ein gemeinsames Nutzen bzw. Teilen von Wissen quer über die mehreren Aufgaben wirksam einsetzen, um optimale Aufgabenausgaben für jede von den mehreren Aufgaben zu erzeugen.These execution optimization tasks can each be strongly coupled, i. the decisions made for one execution optimization task can influence the optimal decision for another execution optimization task. As a specific example, if the system takes into account the decisions made during an operational connection when performing device placement, the system can associate two operations that would be good candidates for connection with the same device. As another specific example, if the system takes into account the operation scheduling when performing device placement, the system may distribute the high priority operations evenly across all devices and distribute the low priority operations evenly across all devices, resulting in high device usage leads. This means that when several different execution optimization tasks are viewed collectively, the system will leverage a shared knowledge across the multiple tasks to produce optimal task outputs for each of the multiple tasks.
Das Konzepterzeugungssystem
Das Konzepterzeugungssystem
Das Graphendarstellungs-Untersystem
Das Graphendarstellungs-Untersystem
Jeder Knoten des Graphen kann in den Graphendaten
Bei einigen anderen Implementierungen ist die anfängliche Knoteneinbettung für jeden Knoten des Graphen eine Kombination aus den Merkmalen der entsprechenden Operation, wie es in den Operationsdaten
In dieser Beschreibung ist eine Einbettung eine geordnete Sammlung von numerischen Werten, die eine Eingabe in einem bestimmten Einbettungsraum darstellten. Zum Beispiel kann die Einbettung ein Vektor von Gleitkomma- oder anderen numerischen Werten sein, der eine feste Dimensionalität hat.In this description, an embed is an ordered collection of numerical values that represented an input in a particular embedding space. For example, the embedding can be a vector of floating point or other numeric values that has a fixed dimensionality.
Die Graphendaten können auch eine Adjazenzmatrix der Knoten für den Graphen enthalten. Eine Adjazenzmatrix für einen Graphen von n Knoten ist eine n × n - Matrix, wo das (i,j)te Element eine 1 ist, wenn es eine Kante zwischen dem Knoten i und dem Knoten j gibt, und sonst 0.The graph data can also include an adjacency matrix of the nodes for the graph. An adjacency matrix for a graph of n nodes is an n × n matrix, where the (i, j) th element is a 1 if there is an edge between node i and node j and 0 otherwise.
Das neuronale Netz zur Grapheneinbettung
Das neuronale Netz zur Grapheneinbettung
Bei einigen Implementierungen kann das neuronale Netz zur Grapheneinbettung
Bei einem gegebenen Einbettungs-Zeitschritt kann das neuronale Netz zur Grapheneinbettung
Das neuronale Netz zur Grapheneinbettung
Das neuronale Netz zur Grapheneinbettung
Bei einigen Implementierungen können das neuronale Netz zur Grapheneinbettung
Bei einigen Implementierungen kann das Trainingssystem das Konzepterzeugungssystem
Als ein weiteres bestimmtes Beispiel kann das Trainingssystem das Konzepterzeugungssystem
Bei einigen Implementierungen kann das Trainingssystem eine proximale Konzeptoptimierung verwenden, um die Zielfunktion zu optimieren.In some implementations, the training system can use proximal concept optimization to optimize the objective function.
Bei einigen Implementierungen kann das Trainingssystem erzeugte Ausführungsoptimierungskonzepte an realen Systemen bewerten, z.B. durch Ausführen der Operationen des neuronalen Netzes auf einer oder mehreren realen Verarbeitungsvorrichtungen und Messen der Laufzeit. Stattdessen oder zusätzlich kann das Trainingssystem die durch das Konzepterzeugungssystem
Das neuronale Netz für Konzepte
Das neuronale Netz für Konzepte
Bei einigen Implementierungen sind die Aufmerksamkeitsschichten eines neuronalen Netzes bidirektional. Das bedeutet, dass für jede Knoteneinbettung bei den Knoteneinbettungen
Bei einigen anderen Implementierungen sind die Aufmerksamkeitsschichten eines neuronalen Netzes unidirektional oder „maskiert“. Das bedeutet, dass für jede bestimmte Knoteneinbettung bei den Knoteneinbettungen
Bei einigen solchen Implementierungen verwenden die Aufmerksamkeitsschichten eines neuronalen Netzes einen Segmentebenen-Rekurrenzmechanismus. Das bedeutet, dass die Knoteneinbettungen
Bei den Implementierungen, bei welchen das neuronale Netz für Konzepte
Bei den Implementierungen, bei welchen das neuronale Netz für Konzepte
Insbesondere kann das erste Aufgaben-Unternetz
Das zweite Aufgaben-Unternetz
Die Sequenz kann bis zu dem schließlichen Aufgaben-Unternetz
Bei einigen Implementierungen kann das neuronale Netz für Konzepte
Ein Konditionieren von einer oder mehreren Schichten des neuronalen Netzes für Konzepte
Das Aufgaben-Unternetz
Das Aufgaben-Unternetz
Das Aufgaben-Unternetz
Bei einigen solchen Implementierungen kann jedes Aufgabenaufmerksamkeits-Unternetz
Das System erhält Daten, die einen Graphen darstellen, der die Operationen eines ersten neuronalen Netzes charakterisiert (Schritt
Das System verarbeitet die Daten, die den Graphen darstellen, unter Verwendung eines neuronalen Netzes zur Grapheneinbettung, um eine Einbettung des Graphen zu erzeugen (Schritt
Das System verarbeitet die Einbettung des Graphen unter Verwendung eines neuronalen Netzes für Konzepte, um ein Ausführungsoptimierungskonzept für das erste neuronale Netz zu erzeugen (Schritt
Das System stellt das erzeugte Ausführungsoptimierungskonzept einer oder mehreren Verarbeitungsvorrichtungen zur Verfügung bzw. liefert es dorthin (Schritt
Das System empfängt eine Einbettung eines Graphen, der die Operationen eines ersten neuronalen Netzes darstellt (Schritt
Bei einem ersten Zeitschritt verarbeitet das System die Einbettung des Graphen, um einen ersten Aufgabeneinbettungsschritt zu erzeugen (Schritt
Beim ersten Zeitschritt verarbeitet das System die erste Aufgabeneinbettung, um eine erste Aufgabenausgabe zu erzeugen (Schritt
Bei einem nachfolgenden Zeitschritt verarbeitet das System die erste Aufgabenausgabe des ersten Zeitschritts, um eine nachfolgende Aufgabeneinbettung zu erzeugen (Schritt
Bei einem nachfolgenden Zeitschritt verarbeitet das System die nachfolgende Aufgabeneinbettung, um eine nachfolgende Aufgabenausgabe zu erzeugen (Schritt
Das System bestimmt, ob alle Aufgabenausgaben erzeugt worden sind (Schritt
Wenn beim Schritt
Wenn beim Schritt
Diese Beschreibung verwendet den Ausdruck „konfiguriert“ in Verbindung mit Systemen und Computerprogrammkomponenten. Für ein System aus einem oder mehreren Computern bedeutet es, konfiguriert zu sein, bestimmte Operationen oder Aktionen durchzuführen, dass das System auf ihm Software, Firmware, Hardware oder eine Kombination von ihnen installiert hat, die bei einem Betrieb veranlassen, dass das System die Operationen oder Aktionen durchführt. Für ein oder mehrere Computerprogramme bedeutet es, konfiguriert zu sein, bestimmte Operationen oder Aktionen durchzuführen, dass das eine oder die mehreren Computerprogramme Anweisungen enthalten, die dann, wenn sie durch eine Datenverarbeitungsvorrichtung ausgeführt werden, veranlassen, dass die Vorrichtung die Operationen oder Aktionen durchführt.This description uses the term “configured” in connection with systems and computer program components. For a system of one or more computers, being configured to perform certain operations or actions means that the system has software, firmware, hardware, or a combination of them installed on it that, when operated, cause the system to perform the operations or take action. For one or more computer programs to be configured to perform certain operations or actions, it means that the one or more computer programs contain instructions which, when executed by a data processing device, cause the device to perform the operations or actions.
Ausführungsformen des Gegenstands und die funktionellen Operationen, die in dieser Beschreibung beschrieben sind, können in einer digitalen elektronischen Schaltung, in konkret ausgestalteter Computer-Software oder -Firmware, in Computer-Hardware, einschließlich der Strukturen, die in dieser Beschreibung offenbart sind, und ihrer strukturellen Äquivalente oder in Kombinationen von einem oder mehreren von ihnen implementiert sein. Ausführungsformen des in dieser Beschreibung beschriebenen Gegenstands können als ein oder mehrere Computerprogramme implementiert sein, d.h. als ein oder mehrere Module von Computerprogrammanweisungen, die auf einem konkreten nichtflüchtigen Speichermedium zur Ausführung durch eine Datenverarbeitungsvorrichtung oder zum Steuern der Operation von dieser codiert sind. Das Computerspeichermedium kann eine maschinenlesbare Speichervorrichtung, ein maschinenlesbares Speichersubstrat, eine Speichervorrichtung für zufälligen oder seriellen Zugriff oder eine Kombination von einem oder mehreren von ihnen sein. Alternativ oder zusätzlich können die Programmanweisungen auf einem künstlich erzeugten ausgebreiteten Signal codiert sein, z.B. einem maschinenerzeugten elektrischen, optischen oder elektromagnetischen Signal, das erzeugt ist, um Information zur Übertragung zu einer geeigneten Empfängervorrichtung zur Ausführung durch eine Datenverarbeitungsvorrichtung zu codieren.Embodiments of the subject matter and the functional operations described in this specification can be implemented in a digital electronic circuit, in specifically designed computer software or firmware, in computer hardware, including the structures disclosed in this specification and their structural equivalents or combinations of one or more of them. Embodiments of the subject matter described in this specification can be implemented as one or more computer programs, i. as one or more modules of computer program instructions encoded on a particular non-volatile storage medium for execution by or for controlling the operation of a data processing device. The computer storage medium may be a machine readable storage device, a machine readable storage substrate, a random or serial access storage device, or a combination of one or more of them. Alternatively or additionally, the program instructions may be encoded on an artificially generated propagated signal, e.g. a machine generated electrical, optical, or electromagnetic signal generated to encode information for transmission to a suitable receiving device for execution by a computing device.
Der Ausdruck „Datenverarbeitungsvorrichtung“ bezieht sich auf Datenverarbeitungshardware und umfasst alle Arten von Vorrichtungen, Geräten und Maschinen zum Verarbeiten von Daten, einschließlich, anhand eines Beispiels, eines programmierbaren Prozessors, eines Computers oder mehrerer Prozessoren oder Computer. Die Vorrichtung kann auch eine spezielle Schaltung, z.B. ein FPGA (feldprogrammierbares Gate-Array) oder eine ASIC (anwendungsspezifische Schaltung) sein oder dies weiterhin enthalten. Die Vorrichtung kann optional zusätzlich zu Hardware einen Code enthalten, der eine Ausführungsumgebung für Computerprogramme erzeugt, wie z.B. einen Code, der Prozessor-Firmware, einen Protokollstapel, ein Datenbankmanagementsystem, ein Betriebssystem oder eine Kombination aus einem oder mehreren von ihnen bildet.The term "data processing device" refers to data processing hardware and includes all types of devices, devices and machines for processing data including, by way of example, a programmable processor, a computer, or multiple processors or computers. The device can also have a special circuit, e.g. an FPGA (field programmable gate array) or an ASIC (application-specific circuit) or still contain this. The device may optionally contain, in addition to hardware, code that creates an execution environment for computer programs, e.g. code that forms processor firmware, a protocol stack, a database management system, an operating system, or a combination of one or more of them.
Ein Computerprogramm, auf das auch als ein Programm, Software, eine Softwareanwendung, eine App, ein Modul, ein Softwaremodul, ein Skript oder ein Code Bezug genommen werden kann oder das als solches beschrieben werden kann, kann in irgendeiner Form einer Programmiersprache geschrieben sein, einschließlich kompilierter oder interpretierter Sprachen oder deklarativer Sprachen oder Verfahrenssprachen; und es kann in irgendeiner Form genutzt werden, einschließlich als alleinstehendes Programm oder als ein Modul, eine Komponente, ein Unterprogramm oder eine andere Einheit, die zur Verwendung in einer Computerumgebung geeignet ist. Ein Programm kann, muss es aber nicht, einer Datei in einem Dateiensystem entsprechen. Ein Programm kann in einem Teilbereich einer Datei gespeichert sein, die andere Programme oder Daten hält, wie z.B. einem oder mehreren Skripten, die in einem Aufzeichnungssprachendokument gespeichert sind, in einer einzigen Datei, die für das in Frage stehende Programm bestimmt ist, oder in mehreren koordinierten Dateien, wie z.B. Dateien, die ein oder mehrere Module, Unterprogramme oder Teilbereiche eines Codes speichern. Ein Computerprogramm kann genutzt werden, um auf einem Computer oder auf mehreren Computern, die an einer Stelle oder über mehrere Stellen verteilt und durch ein Kommunikationsnetzwerk miteinander verbunden sind, ausgeführt zu werden.A computer program, which can also be referred to as or which can be described as a program, software, software application, app, module, software module, script, or code, can be written in some form of programming language, including compiled or interpreted languages or declarative languages or procedural languages; and it can be used in any form, including as a stand-alone program, or as a module, component, sub-program, or other entity suitable for use in a computing environment. A program can or does not have to correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data, such as one or more scripts stored in a recording language document, in a single file dedicated to the program in question, or in several coordinated files, e.g. Files that store one or more modules, subprograms or parts of a code. A computer program can be used to run on one computer or on several computers that are distributed at one point or over several points and connected to one another by a communication network.
In dieser Beschreibung wird der Ausdruck „Datenbank“ allgemein verwendet, um auf irgendeine Sammlung von Daten Bezug zu nehmen: die Daten müssen nicht auf irgendeine besondere Weise strukturiert sein oder überhaupt strukturiert sein und sie können auf Speichervorrichtungen bei einem oder mehreren Standorten gespeichert sein. Somit kann zum Beispiel die Index-Datenbank mehrere Sammlungen von Daten enthalten, von welchen jede unterschiedlich organisiert und zugreifbar sein kann.In this specification the term "database" is used broadly to refer to any collection of data: the data need not be structured in any particular way, or be structured at all, and it can be stored on storage devices at an or stored in multiple locations. Thus, for example, the index database can contain multiple collections of data, each of which can be organized and accessible differently.
Gleichermaßen wird in dieser Beschreibung der Ausdruck „Maschine“ allgemein verwendet, um auf ein softwarebasiertes System, ein Untersystem oder einen Prozess Bezug zu nehmen, das oder der programmiert ist, um eine oder mehrere Funktionen durchzuführen. Allgemein wird eine Maschine als ein oder mehrere Softwaremodule oder Komponenten implementiert sein, die auf einem oder mehreren Computern bei einem oder mehreren Standorten installiert sind. In einigen Fällen wird oder werden ein oder mehrere Computer für eine bestimmte Maschine bestimmt sein; in anderen Fällen können mehrere Maschinen installiert sein und auf demselben Computer oder denselben Computern laufen.Likewise, throughout this specification the term “machine” is used broadly to refer to a software-based system, subsystem, or process that is programmed to perform one or more functions. Generally, a machine will be implemented as one or more software modules or components that are installed on one or more computers at one or more locations. In some cases, one or more computers will be or will be dedicated to a particular machine; in other cases, multiple machines can be installed and run on the same computer or computers.
Die Prozesse und logischen Abläufe, die in dieser Beschreibung beschrieben sind, können durch einen oder mehrere programmierbare Computer durchgeführt werden, der oder die ein oder mehrere Computerprogramme ausführt oder ausführen, um Funktionen durch Arbeiten an Eingangsdaten und Erzeugen einer Ausgabe durchzuführen. Die Prozesse und logischen Abläufe können auch durchgeführt werden durch eine spezielle logische Schaltung, wie z.B. ein FPGA oder eine ASIC, oder durch eine Kombination aus einer speziellen logischen Schaltung und einem oder mehreren programmierten Computern.The processes and logic described in this specification may be performed by one or more programmable computers that execute or execute one or more computer programs to perform functions by working on input data and generating output. The processes and logic operations can also be carried out by a special logic circuit, e.g. an FPGA or an ASIC, or a combination of a special logic circuit and one or more programmed computers.
Computer, die für die Ausführung eines Computerprogramms geeignet sind, können auf allgemeinen oder speziellen Mikroprozessoren oder beiden oder irgendeiner anderen Art einer zentralen Verarbeitungseinheit basieren. Allgemein wird eine zentrale Verarbeitungseinheit Anweisungen und Daten von einem Nurlesespeicher oder einem Direktzugriffsspeicher oder beiden empfangen. Die wesentlichen Elemente eines Computers sind eine zentrale Verarbeitungseinheit zum Durchführen oder Ausführen von Anweisungen und eine oder mehrere Speichervorrichtungen zum Speichern von Anweisungen und Daten. Die zentrale Verarbeitungseinheit und der Speicher können durch eine spezielle logische Schaltung ergänzt sein oder darin enthalten sein. Allgemein wird ein Computer auch eine oder mehrere Massenspeichervorrichtungen zum Speichern von Daten enthalten oder operativ damit gekoppelt sein, um Daten von diesem oder diesen zu empfangen oder Daten zu diesem oder diesen zu transferieren, oder beides, wie z.B. magnetische, magnetooptische Platten oder optische Platten. Jedoch muss ein Computer solche Vorrichtungen nicht haben. Darüber hinaus kann ein Computer in einer anderen Vorrichtung eingebettet sein, wie z.B. ein Mobiltelefon, ein persönlicher digitaler Assistent (PDA), ein mobiles Audio- oder Videoabspielgerät, eine Spielkonsole, ein Empfänger eines globalen Positioniersystems (GPS) oder eine tragbare Speichervorrichtung, wie z.B. ein USB-Speicherstick, um nur einige zu nennen.Computers capable of executing a computer program may be based on general or dedicated microprocessors, or both, or some other type of central processing unit. Generally, a central processing unit will receive instructions and data from read-only memory or random access memory, or both. The essential elements of a computer are a central processing unit for carrying out or executing instructions and one or more storage devices for storing instructions and data. The central processing unit and the memory can be supplemented by a special logic circuit or can be contained therein. In general, a computer will also include, or be operatively coupled to, one or more mass storage devices for storing data for receiving or transferring data to, or both, such as e.g. magnetic, magneto-optical disks or optical disks. However, a computer need not have such devices. In addition, a computer can be embedded in another device, such as e.g. a mobile phone, a personal digital assistant (PDA), a mobile audio or video player, a game console, a global positioning system (GPS) receiver, or a portable storage device such as e.g. a USB memory stick, to name a few.
Computerlesbare Medien, die zum Speichern von Computerprogrammanweisungen und Daten geeignet sind, enthalten alle Formen eines nichtflüchtigen Speichers, von Medien und Speichervorrichtungen, einschließlich, anhand eines Beispiels, von Halbleiterspeichervorrichtungen, wie z.B. EPROM, EEPROM, und Flash-Speichervorrichtungen; magnetische Platten, z.B. interne Festplatten oder entfernbare Platten; magnetooptische Platten; und CD-ROM und DVD-ROM-Scheiben.Computer readable media suitable for storing computer program instructions and data include all forms of non-volatile memory, media and storage devices, including, by way of example, semiconductor storage devices such as e.g. EPROM, EEPROM, and flash memory devices; magnetic disks, e.g. internal hard drives or removable disks; magneto-optical disks; and CD-ROM and DVD-ROM disks.
Um für eine Interaktion mit einem Anwender zu sorgen, können Ausführungsformen des Gegenstands auf einem Computer implementiert sein, der eine Anzeigevorrichtung hat, wie z.B. einen CRT-(Kathodenstrahlröhren-) oder einen LCD-(Flüssigkristallanzeigen-)Monitor, zum Anzeigen von Information zum Anwender, und eine Tastatur und eine Zeigevorrichtung, wie z.B. eine Maus oder einen Trackball, wodurch der Anwender eine Eingabe zum Computer liefern kann. Andere Arten von Vorrichtungen können ebenso gut verwendet werden, um für eine Interaktion mit einem Anwender zu sorgen; zum Beispiel kann eine zum Anwender gelieferte Rückkopplung irgendeine Form von sensorischer Rückkopplung sein, wie z.B. eine visuelle Rückkopplung, eine akustische Rückkopplung oder eine taktile Rückkopplung; und eine Eingabe vom Anwender kann in irgendeiner Form empfangen werden, einschließlich einer akustischen, einer sprachlichen oder einer taktilen Eingabe. Zusätzlich kann ein Computer mit einem Anwender durch Senden von Dokumenten zu und Empfangen von Dokumenten von einer Vorrichtung interagieren, die durch den Anwender verwendet wird; zum Beispiel durch Senden von Internetseiten zu einem Webbrowser auf einer Vorrichtung eines Anwenders in Reaktion auf vom Webbrowser empfangene Anfragen. Ebenso kann ein Computer mit einem Anwender durch Senden von Textnachrichten oder anderen Formen einer Nachricht zu einer persönlichen Vorrichtung interagieren, wie z.B. einem Smartphone, das eine Nachrichtenübermittlungsdienstanwendung laufen lässt, und durch Empfangen von Antwortnachrichten vom Anwender im Gegenzug.In order to provide for interaction with a user, embodiments of the article can be implemented on a computer having a display device, such as e.g. a CRT (cathode ray tube) or an LCD (liquid crystal display) monitor, for displaying information to the user, and a keyboard and pointing device, e.g. a mouse or trackball, which allows the user to provide input to the computer. Other types of devices can also be used to provide interaction with a user; for example, feedback provided to the user can be some form of sensory feedback, such as a visual feedback, an acoustic feedback, or a tactile feedback; and input from the user can be received in any form, including audible, spoken, or tactile input. In addition, a computer can interact with a user by sending documents to and receiving documents from a device used by the user; for example, by sending Internet pages to a web browser on a user's device in response to requests received from the web browser. Likewise, a computer can interact with a user by sending text messages or other forms of message to a personal device such as a a smartphone running a messaging service application and receiving reply messages from the user in return.
Eine Datenverarbeitungsvorrichtung zum Implementieren von Maschinenlernmodellen kann zum Beispiel auch Hardwarebeschleunigereinheiten zum Verarbeiten von gemeinsamen bzw. häufigen und rechenintensiven Teilen von Maschinenlerntraining oder Produktion, z.B. Inferenz, Arbeitsbelastung, enthalten.A data processing device for implementing machine learning models can, for example, also include hardware accelerator units for processing common or frequent and computationally intensive parts of machine learning training or production, e.g. Inference, workload, included.
Maschinenlernmodelle können unter Verwendung eines Maschinenlern-Frameworks, wie z.B. des TensorFlow-Frameworks, des Microsoft Cognitive Toolkit-Frameworks, des Apache Singa-Frameworks oder des Apache MXNet-Frameworks implementiert und genutzt werden. Machine learning models can be implemented and used using a machine learning framework such as the TensorFlow framework, the Microsoft Cognitive Toolkit framework, the Apache Singa framework or the Apache MXNet framework.
Ausführungsformen des in dieser Beschreibung beschriebenen Gegenstands können in einem Computersystem implementiert sein, das eine Backend-Komponente enthält, wie z.B. als einen Datenserver, oder das eine Middleware-Komponente enthält, wie z.B. einen Anwendungsserver, oder das eine Frontend-Komponente enthält, wie z.B. einen Client-Computer, der eine graphische Anwenderschnittstelle oder einen Webbrowser hat, oder eine App, wodurch ein Anwender mit einer Implementierung des in dieser Beschreibung beschriebenen Gegenstands interagieren kann, oder irgendeine Kombination von einer oder mehreren von solchen Backend-, Middleware- oder Frontend-Komponenten. Die Komponenten des Systems können durch irgendeine Form oder ein Medium einer digitalen Datenkommunikation miteinander verbunden sein, wie z.B. ein Kommunikationsnetzwerk. Beispiele von Kommunikationsnetzwerken enthalten ein lokales Netz („LAN“) und ein Weitverkehrsnetz („WAN“), wie z.B. das Internet.Embodiments of the subject matter described in this specification can be implemented in a computer system that includes a backend component, such as e.g. as a data server, or that contains a middleware component, e.g. an application server, or that contains a front-end component, such as a client computer that has a graphical user interface or a web browser, or an app whereby a user can interact with an implementation of the subject matter described in this description, or any combination of one or more of such backend, middleware or frontend Components. The components of the system may be interconnected by any form or medium of digital data communication, such as e.g. a communication network. Examples of communication networks include a local area network ("LAN") and a wide area network ("WAN"), such as the Internet.
Das Computersystem kann Clients und Server enthalten. Ein Client und ein Server sind allgemein entfernt voneinander und interagieren typischerweise durch ein Kommunikationsnetzwerk. Die Beziehung von Client und Server entsteht aufgrund von Computerprogrammen, die auf den jeweiligen Computern laufen und die eine Client-Server-Beziehung zueinander haben. Bei einigen Ausführungsformen sendet ein Server Daten, wie z.B. eine HTML-Seite, zu einer Anwendervorrichtung, z.B. zu Zwecken eines Anzeigens von Daten zu und eines Empfangens einer Anwendereingabe von einem Anwender, der mit der Vorrichtung intragiert, die als ein Client agiert. Bei der Anwendervorrichtung erzeugte Daten, wie z.B. ein Ergebnis der Anwenderinteraktion, können beim Server von der Vorrichtung empfangen werden.The computer system can contain clients and servers. A client and server are generally remote from one another and typically interact through a communication network. The relationship between client and server arises on the basis of computer programs that run on the respective computers and that have a client-server relationship with one another. In some embodiments, a server sends data such as an HTML page, to a user device, e.g. for purposes of displaying data to and receiving user input from a user engaging with the device acting as a client. Data generated at the user device, e.g. a result of the user interaction can be received by the device at the server.
Zusätzlich zu den oben beschriebenen Ausführungsformen sind auch die folgenden Ausführungsformen innovativ:
- Eine Ausführungsform 1 ist ein System, das einen oder mehrere Computer und eine oder mehrere Speichervorrichtungen umfasst, die Anweisungen speichern, die dann, wenn sie durch den einen oder die mehreren Computer ausgeführt werden, betreibbar sind, um zu veranlassen, dass der eine oder die mehreren Computer Operationen zum Erzeugen einer Aufgabenausgabe zum Ausführen einer Vielzahl von Operationen eines neuronalen Netzes auf einer oder mehreren Verarbeitungsvorrichtungen durchführt oder durchführen, wobei die Aufgabenausgabe für jede der Vielzahl von Operationen des neuronalen Netzes eine jeweilige Entscheidung für eine bestimmte Optimierungsaufgabe umfasst, wobei die Operationen folgendes umfassen:
- Erhalten von Daten, die einen Graphen darstellen, der die Vielzahl von Operationen des neuronalen Netzes charakterisiert, wobei jeder Knoten des Graphen eine Operation des neuronalen Netzes charakterisiert und jede Kante des Graphen eine Datenabhängigkeit zwischen den Operationen charakterisiert;
- Embodiment 1 is a system that includes one or more computers and one or more storage devices that store instructions that, when executed by the one or more computers, are operable to cause the one or more computers A plurality of computers performs or performs operations for generating a task output for performing a plurality of operations of a neural network on one or more processing devices, the task output for each of the plurality of operations of the neural network comprising a respective decision for a specific optimization task, the operations as follows include:
- Obtaining data representing a graph characterizing the plurality of operations of the neural network, each node of the graph characterizing an operation of the neural network and each edge of the graph characterizing a data dependency between the operations;
Verarbeiten der Daten, die den Graphen darstellen, unter Verwendung eines neuronalen Netzes zur Grapheneinbettung, um eine Einbettung des Graphen zu erzeugen; und
Verarbeiten der Einbettung des Graphen unter Verwendung eines neuronalen Netzes für Konzepte, um die Aufgabenausgabe zu erzeugen.Processing the data representing the graph using a graph embedding neural network to produce an embedding of the graph; and
Process the embedding of the graph using a neural network for concepts to generate the task output.
Eine Ausführungsform 2 ist das System der Ausführungsform 1, wobei die Einbettung des Graphen eine jeweilige Knoteneinbettung jedes Knotens des Graphen umfasst.
Eine Ausführungsform 3 ist das System der Ausführungsform 2, wobei ein Verarbeiten der Daten, die den Graphen darstellen, unter Verwendung des neuronalen Netzes zur Grapheneinbettung bei jedem einer Vielzahl von Einbettungs-Zeitschritten folgendes umfasst:
- Empfangen einer aktuellen Einbettung jedes Knotens des Graphen, die während eines vorherigen Einbettungs-Zeitschritts erzeugt ist;
- Kombinieren, für jeden bestimmten Knoten des Graphen, der jeweiligen aktuellen Einbettung jedes Nachbarknotens des bestimmten Knotens, um eine Nachbareinbettung des bestimmten Knotens zu erzeugen; und
- Kombinieren, für jeden Koten des Graphen, der aktuellen Einbettung des Knotens und der Nachbareinbettung des Knotens, um eine neue Einbettung des Knotens zu erzeugen.
- Receiving a current embed of each node of the graph generated during a previous embed time step;
- Combining, for each particular node of the graph, the respective current embedding of each neighboring node of the particular node in order to generate a neighboring embedding of the particular node; and
- Combine, for each node of the graph, the current embedding of the node and the neighboring embedding of the node to create a new embedding of the node.
Eine Ausführungsform 4 ist das System der Ausführungsform 3, wobei ein Verarbeiten der Daten, die den Graphen darstellen, unter Verwendung des neuronalen Netzes zur Grapheneinbettung bei einem ersten Einbettungs-Zeitschritt folgendes umfasst:
- Erzeugen einer anfänglichen Einbettung für jeden Knoten des Graphen unter Verwendung von Merkmalen des Knotens, wobei die Merkmale eines oder mehreres von folgendem umfassen:
- einen Operationstyp der durch den Knoten charakterisierten Operation,
- eine Ausgabeform einer Ausgabe der durch den Knoten charakterisierten Operation, oder
- eine jeweilige Identifikation für jeden Nachbarknoten des Knotens.
- Generate an initial embedding for each node of the graph using features of the node, the features including one or more of the following:
- an operation type of the operation characterized by the knot,
- an output form of an output of the operation characterized by the node, or
- a respective identification for each neighboring node of the node.
Eine Ausführungsform 5 ist das System von einer der Ausführungsform 3 oder 4, wobei ein Kombinieren der aktuellen Einbettung eines bestimmten Knotens und der Nachbareinbettung des bestimmten Knotens folgendes umfasst:
- Verketten der aktuellen Einbettung des bestimmten Knotens und der Nachbarschaftseinbettung des bestimmten Knotens, um eine kombinierte Einbettung des bestimmten Knotens zu erzeugen; und
- Verarbeiten der kombinierten Einbettung des bestimmten Knotens unter Verwendung von einer oder mehreren vollständig verbundenen Schichten eines neuronalen Netzes, um die neue Einbettung des bestimmten Knotens zu erzeugen.
- Concatenating the current embedding of the particular node and the neighborhood embedding of the particular node to produce a combined embedding of the particular node; and
- Processing the combined embedding of the particular node using one or more fully connected layers of a neural network to generate the new embedding of the particular node.
Eine Ausführungsform 6 ist das System von einer der Ausführungsformen 3-5, wobei ein Kombinieren der jeweiligen Einbettung jedes Nachbarknotens eines bestimmten Knotens folgendes umfasst:
- Verarbeiten, für jeden Nachbarknoten des bestimmten Knotens, der aktuellen Einbettung des Nachbarknotens unter Verwendung einer affinen Transformation, um eine verarbeitete Einbettung für den Nachbarknoten zu erzeugen;
- Verarbeiten, für jeden Nachbarknoten des bestimmten Knotens, der verarbeiteten Einbettung des Nachbarknotens unter Verwendung einer Sigmoid-Aktivierungsfunktion, um eine Aktivierungseinbettung für den Nachbarknoten zu erzeugen; und
- Kombinieren der jeweiligen Aktivierungseinbettung jedes Nachbarknotens des bestimmten Knotens durch Verarbeiten der Aktivierungseinbettungen unter Verwendung einer MaxPooling-Schicht.
- Processing, for each neighboring node of the particular node, the current embedding of the neighboring node using an affine transformation in order to generate a processed embedding for the neighboring node;
- Processing, for each neighboring node of the particular node, the processed embedding of the neighboring node using a sigmoid activation function to generate an activation embedding for the neighboring node; and
- Combining the respective activation embedding of each neighboring node of the particular node by processing the activation embeddings using a MaxPooling layer.
Eine Ausführungsform 7 ist das System von einer der Ausführungsformen 1-6, wobei die bestimmte Optimierungsaufgabe eine von folgenden ist:
- eine Vorrichtungsplatzierungsaufgabe, wobei jede der Vielzahl von Operationen des neuronalen Netzes einer bestimmten Verarbeitungsvorrichtung von der einen oder den mehreren Verarbeitungsvorrichtung zugeordnet wird;
- eine Operationszeitplanungsaufgabe, wobei jede der Vielzahl von Operationen des neuronalen Netzes einer Priorität zugeordnet wird, und wobei jede Verarbeitungsvorrichtung einen prioritätsbasierten Zeitplaner umfasst, der eine Prioritätswarteschlange der zu der Verarbeitungsvorrichtung zugeordneten Operationen beibehält; oder
- eine Operationsverbindungsaufgabe, wobei eine Vielzahl der Operationen des neuronalen Netzes bestimmt wird, derart ausgeführt zu werden, als ob die ausgewählten Operationen eine einzige Operation wären.
- a device placement task, wherein each of the plurality of neural network operations is assigned to a particular processing device by the one or more processing devices;
- an operation scheduling task, wherein each of the plurality of neural network operations is assigned a priority, and wherein each processing device includes a priority-based scheduler that maintains a priority queue of operations assigned to the processing device; or
- an operation connection task wherein a plurality of the operations of the neural network are determined to be performed as if the selected operations were a single operation.
Eine Ausführungsform 8 ist das System von einer der Ausführungsformen 1-7, wobei das neuronale Netz zur Grapheneinbettung und das neuronale Netz für Konzepte durch Updaten von Parametern θ des neuronalen Netzes unter Verwendung einer Zielfunktion, die eine erwartete Laufzeit von jeweiligen durch jeden einer Vielzahl von Kandidatengraphen charakterisierten Operationen charakterisiert, Ende-zu-Ende trainiert worden sind.Embodiment 8 is the system of any one of Embodiments 1-7, wherein the neural network for graph embedding and the neural network for concepts by updating parameters θ of the neural network using an objective function that has an expected running time of each of a plurality of Candidate graphs characterized operations that have been end-to-end trained.
Eine Ausführungsform 9 ist das System der Ausführungsformen 8, wobei die Zielfunktion folgende ist:
Eine Ausführungsform 10 ist das System von einer der Ausführungsformen 8-9, wobei das neuronale Netz zur Grapheneinbettung und das neuronale Netz für Konzepte durch Optimieren der Zielfunktion unter Verwendung einer proximalen Konzeptoptimierung (Proximal Policy Optimization) trainiert worden sind.Embodiment 10 is the system of one of Embodiments 8-9, wherein the graph embedding neural network and the concepts neural network have been trained by optimizing the objective function using proximal policy optimization.
Eine Ausführungsform 11 ist das System von einer der Ausführungsformen 1-10, wobei das neuronale Netz für Konzepte auf Merkmale des Graphen konditioniert ist.An embodiment 11 is the system of any one of the embodiments 1-10, wherein the neural network is conditioned for concepts on features of the graph.
Eine Ausführungsform 12 ist das System der Ausführungsform 11, wobei ein Konditionieren des neuronalen Netzes für Konzepte auf Merkmale des Graphen ein Berechnen einer Ausgabe x(l+1) einer Schicht eines neuronalen Netzes l des neuronalen Netze für Konzepte folgendes umfasst:
Eine Ausführungsform 13 ist das System von einer der Ausführungsformen 1-12, wobei die Operationen weiterhin ein Ausführen der Vielzahl von Operationen des neuronalen Netzes auf der einen oder den mehreren Verarbeitungsvorrichtung unter Verwendung der erzeugten Aufgabenausgabe umfassen.Embodiment 13 is the system of any one of Embodiments 1-12, wherein the operations further include performing the plurality of neural network operations on the one or more processing devices using the generated task output.
Eine Ausführungsform 14 ist das System von einer der Ausführungsformen 1-13, wobei das neuronale Netz für Konzepte eine Vielzahl von Aufmerksamkeitsschichten eines neuronalen Netzes umfasst.Embodiment 14 is the system of any one of Embodiments 1-13, wherein the concept neural network includes a plurality of neural network attentional layers.
Eine Ausführungsform 15 ist das System der Ausführungsform 14, wobei die Vielzahl von Aufmerksamkeitsschichten eines neuronalen Netzes einen Segmentebenen-Rekurrenzmechanismus umfassen.Embodiment 15 is the system of embodiment 14, wherein the plurality of neural network attention layers comprise a segment level recurrence mechanism.
Eine Ausführungsform 16 ist das System von einer der Ausführungsformen 1-16, wobei die Operationen weiterhin ein Erzeugen einer jeweiligen Aufgabenausgabe für jede einer Vielzahl von Optimierungsaufgaben umfassen, wobei jede Aufgabenausgabe für jede der Vielzahl von Operationen des neuronalen Netzes eine jeweilige Entscheidung für die entsprechende Optimierungsaufgabe umfasst und wobei ein Verarbeiten der Einbettung des Graphen unter Verwendung eines neuronalen Netze für Konzepte folgendes umfasst:
- bei einem ersten Zeitschritt entsprechend einer ersten Optimierungsaufgabe der Vielzahl von Optimierungsaufgaben:
- Erzeugen einer ersten Aufgabeneinbettung aus der Einbettung des Graphen; und
- Verarbeiten der ersten Aufgabeneinbettung unter Verwendung des neuronalen Netzes für Konzepte, um eine erste Aufgabenausgabe für die erste Optimierungsaufgabe zu erzeugen; und
- bei jedem von einem oder mehreren nachfolgenden Zeitschritten jeweils entsprechend einer jeweiligen Optimierungsaufgabe der Vielzahl von Optimierungsaufgaben:
- Verarbeiten der Aufgabenausgabe eines vorherigen Zeitschritts, um eine nachfolgende Aufgabeneinbettung zu erzeugen; und
- Verarbeiten der nachfolgenden Aufgabeneinbettung unter Verwendung des neuronalen Netzes für Konzepte, um eine nachfolgende Aufgabenausgabe für die entsprechende Optimierungsaufgabe zu erzeugen.
- with a first time step corresponding to a first optimization task of the multitude of optimization tasks:
- Generating a first task embedding from the embedding of the graph; and
- Processing the first task embedding using the concept neural network to generate a first task output for the first optimization task; and
- for each of one or more subsequent time steps, each corresponding to a respective optimization task of the multitude of optimization tasks:
- Processing the task output of a previous time step to generate a subsequent task embed; and
- Processing the subsequent task embedding using the neural network for concepts to generate a subsequent task output for the corresponding optimization task.
Eine Ausführungsform 17 ist das System der Ausführungsform 16, wobei ein Verarbeiten der Aufgabenausgabe eines vorherigen Zeitschritts ein Kombinieren der Aufgabeneinbettung des vorherigen Zeitschritts und der Aufgabenausgabe des vorherigen Zeitschritts umfasst, um die nachfolgende Aufgabeneinbettung zu erzeugen.An embodiment 17 is the system of embodiment 16, wherein processing the task output of a previous time step comprises combining the task embedding of the previous time step and the task output of the previous time step to generate the subsequent task embedding.
Eine Ausführungsform 18 ist das System der Ausführungsform 17, wobei ein Kombinieren der Aufgabeneinbettung des vorherigen Zeitschritts und der Aufgabenausgabe des vorherigen Zeitschritts, um eine nachfolgende Aufgabeneinbettung zu erzeugen, folgendes umfasst:
- Berechnen einer Summe aus der Aufgabeneinbettung und der Aufgabenausgabe des vorherigen Zeitschritts, um eine summierte Darstellung zu erzeugen; und
- Verarbeiten der summierten Darstellung unter Verwendung einer Schichtennormalisierung, um die nachfolgende Aufgabeneinbettung zu erzeugen.
- Computing a sum of the task embedding and the task output of the previous time step to produce a summed representation; and
- Processing the summed representation using a slice normalization to produce the subsequent task embedding.
Eine Ausführungsform 19 ist das System von einer der Ausführungsformen 16-18, wobei:
- das neuronale Netz für Konzepte ein Konzepteinbettungs-Unternetz umfasst, das eine Vielzahl von Aufmerksamkeitsschichten eines neuronalen Netzes umfasst; und
- ein Erzeugen der ersten Aufgabeneinbettung aus der Einbettung des Graphen ein Verarbeiten der Einbettung des Graphen unter Verwendung des Konzepteinbettungs-Unternetzes umfasst.
- the concept neural network comprises a concept embedding subnet comprising a plurality of neural network attentional layers; and
- generating the first task embedding from the embedding of the graph comprises processing the embedding of the graph using the conceptual embedding subnet.
Eine Ausführungsform 20 ist das System von einer der Ausführungsformen 16-19, wobei das neuronale Netz für Konzepte folgendes umfasst:
- ein jeweiliges Aufgabenaufmerksamkeits-Unternetz für jede der Vielzahl von Optimierungsaufgaben, wobei jedes Aufgabenaufmerksamkeits-Unternetz eine oder mehrere Aufmerksamkeitsschichten eines neuronalen Netzes umfasst; und
- ein jeweiliges Aufgabenkonzept-Unternetz für jede der Vielzahl von Optimierungsaufgaben,
- wobei ein Verarbeiten einer Aufgabeneinbettung für eine bestimmte Optimierungsaufgabe unter Verwendung des neuronalen Netzes für Konzepte folgendes umfasst:
- Verarbeiten der Aufgabeneinbettung unter Verwendung des Aufgabenaufmerksamkeits-Unternetzes entsprechend der bestimmten Optimierungsaufgabe, um eine Aufmerksamkeitseinbettung zu erzeugen; und
- Verarbeiten der Aufmerksamkeitseinbettung unter Verwendung des Aufgabenkonzept-Unternetzes entsprechend der bestimmten Optimierungsaufgabe, um die Aufgabenausgabe für die bestimmte Optimierungsaufgabe zu erzeugen.
- a respective task attention subnet for each of the plurality of optimization tasks, each task attention subnet comprising one or more attention layers of a neural network; and
- a respective task concept subnet for each of the multitude of optimization tasks,
- processing a task embedding for a particular optimization task below Using the neural network for concepts includes:
- Processing the task embedding using the task attention subnet in accordance with the determined optimization task to generate an attention embedding; and
- Processing the attention embedding using the task concept subnet according to the particular optimization task to generate the task output for the particular optimization task.
Eine Ausführungsform 21 ist das System der Ausführungsform 20, wobei die Aufgabenaufmerksamkeits-Unternetze von jeder der Vielzahl von Optimierungsaufgaben eine Vielzahl von Parametern gemeinsam nutzen bzw. teilen.An embodiment 21 is the system of embodiment 20, wherein the task attention subnets of each of the plurality of optimization tasks share a plurality of parameters.
Eine Ausführungsform 22 ist das System von einer der Ausführungsformen 20-21, wobei das jeweilige Aufgabenaufmerksamkeits-Unternetz entsprechend jeder Optimierungsaufgabe eine oder mehrere Restverbindungen mit jedem von einem oder mehreren anderen Aufgabenaufmerksamkeits-Unternetzen entsprechend anderen Optimierungsaufgaben gemeinsam nutzt bzw. teilt.An embodiment 22 is the system of one of the embodiments 20-21, wherein the respective task attention subnetwork according to each optimization task uses or shares one or more residual connections with each of one or more other task attention subnetworks according to other optimization tasks.
Eine Ausführungsform 23 ist ein System, das einen oder mehrere Computer umfasst, und eine oder mehrere Speichervorrichtungen, die Anweisungen speichern, die dann, wenn sie durch den einen oder die mehreren Computer ausgeführt werden, betreibbar sind, um zu veranlassen, dass der eine oder die mehreren Computer Operationen zum Erzeugen eines Optimierungskonzepts zum Ausführen einer Vielzahl von Operationen eines neuronalen Netzes auf einer oder mehreren Verarbeitungsvorrichtungen durchführt oder durchführen, wobei:
- das Optimierungskonzept eine Aufgabenausgabe für jede einer Vielzahl von Optimierungsaufgaben umfasst, und
- jede Aufgabenausgabe für jede der Vielzahl von Operationen des neuronalen Netzes eine jeweilige Entscheidung für die entsprechende Optimierungsaufgabe umfasst,
- wobei die Operationen folgendes umfassen:
- Erhalten von Daten, die einen Graphen darstellen, der die Vielzahl von Operationen des neuronalen Netzes charakterisiert, wobei jeder Knoten des Graphen eine Operation des neuronalen Netzes charakterisiert und jede Kante des Graphen eine Datenabhängigkeit zwischen den Operationen charakterisiert;
- Verarbeiten der Daten, die den Graphen darstellen, unter Verwendung eines neuronalen Netzes zur Grapheneinbettung, um eine Einbettung des Graphen zu erzeugen; und
- Verarbeiten der Einbettung des Graphen unter Verwendung eines neuronalen Netzes für Konzepte, um die jeweilige Aufgabenausgabe für jede der Vielzahl von Optimierungsaufgaben zu erzeugen, wobei die Verarbeitung folgendes umfasst:
- bei einem ersten Zeitschritt entsprechend einer ersten Optimierungsaufgabe der Vielzahl von Optimierungsaufgaben:
- Erzeugen einer ersten Aufgabeneinbettung aus der Einbettung des Graphen; und
- Verarbeiten der ersten Aufgabeneinbettung unter Verwendung des neuronalen Netzes für Konzepte, um eine erste Aufgabenausgabe für die erste Optimierungsaufgabe zu erzeugen; und
- bei jedem von einem oder mehreren nachfolgenden Zeitschritten jeweils entsprechend einer jeweiligen Optimierungsaufgabe der Vielzahl von Optimierungsaufgaben:
- Verarbeiten der Aufgabenausgabe eines vorherigen Zeitschritts, um eine nachfolgende Aufgabeneinbettung zu erzeugen; und
- Verarbeiten der nachfolgenden Aufgabeneinbettung unter Verwendung des neuronalen Netzes für Konzepte, um eine nachfolgende Aufgabenausgabe für die entsprechende Optimierungsaufgabe zu erzeugen.
- bei einem ersten Zeitschritt entsprechend einer ersten Optimierungsaufgabe der Vielzahl von Optimierungsaufgaben:
- the optimization concept includes a task output for each of a plurality of optimization tasks, and
- each task output for each of the multitude of operations of the neural network includes a respective decision for the corresponding optimization task,
- where the operations include:
- Obtaining data representing a graph characterizing the plurality of operations of the neural network, each node of the graph characterizing an operation of the neural network and each edge of the graph characterizing a data dependency between the operations;
- Processing the data representing the graph using a graph embedding neural network to produce an embedding of the graph; and
- Processing the embedding of the graph using a concept neural network to produce the respective task output for each of the plurality of optimization tasks, the processing comprising:
- with a first time step corresponding to a first optimization task of the multitude of optimization tasks:
- Generating a first task embedding from the embedding of the graph; and
- Processing the first task embedding using the concept neural network to generate a first task output for the first optimization task; and
- for each of one or more subsequent time steps, each corresponding to a respective optimization task of the multitude of optimization tasks:
- Processing the task output of a previous time step to generate a subsequent task embed; and
- Processing the subsequent task embedding using the neural network for concepts to generate a subsequent task output for the corresponding optimization task.
- with a first time step corresponding to a first optimization task of the multitude of optimization tasks:
Eine Ausführungsform 24 ist das System der Ausführungsform 23, wobei ein Verarbeiten der Aufgabenausgabe eines vorherigen Zeitschritts ein Kombinieren der Aufgabeneinbettung des vorherigen Zeitschritts und der Aufgabenausgabe des vorherigen Zeitschritts umfasst, um die nachfolgende Aufgabeneinbettung zu erzeugen.Embodiment 24 is the system of embodiment 23, wherein processing the task output of a previous time step comprises combining the task embedding of the previous time step and the task output of the previous time step to produce the subsequent task embedding.
Eine Ausführungsform 25 ist das System der Ausführungsform 24, wobei ein Kombinieren der Aufgabeneinbettung des vorherigen Zeitschritts und der Aufgabenausgabe des vorherigen Zeitschritts, um eine nachfolgende Aufgabeneinbettung zu erzeugen, folgendes umfasst:
- Berechnen einer Summe aus der Aufgabeneinbettung und der Aufgabenausgabe des vorherigen Zeitschritts, um eine summierte Darstellung zu erzeugen; und
- Verarbeiten der summierten Darstellung unter Verwendung einer Schichtennormalisierung, um die nachfolgende Aufgabeneinbettung zu erzeugen.
- Computing a sum of the task embedding and the task output of the previous time step to produce a summed representation; and
- Processing the summed representation using a slice normalization to produce the subsequent task embedding.
Eine Ausführungsform 26 ist das System von einer der Ausführungsformen 23-25, wobei die Einbettung des Graphen eine jeweilige Knoteneinbettung jedes Knotens des Graphen umfasst.Embodiment 26 is the system of any of Embodiments 23-25, wherein the Embedding the graph comprises a respective node embedding of each node of the graph.
Eine Ausführungsform 27 ist das System der Ausführungsform 26, wobei ein Verarbeiten der Daten, die den Graphen darstellen, unter Verwendung des neuronalen Netzes zur Grapheneinbettung bei jedem einer Vielzahl von Einbettungs-Zeitschritten folgendes umfasst:
- Empfangen einer aktuellen Einbettung jedes Knotens des Graphen, die während eines vorherigen Einbettungs-Zeitschritts erzeugt ist;
- Kombinieren, für jeden bestimmten Knoten des Graphen, der jeweiligen aktuellen Einbettung jedes Nachbarknotens des bestimmten Knotens, um eine Nachbareinbettung des bestimmten Knotens zu erzeugen; und
- Kombinieren, für jeden Koten des Graphen, der aktuellen Einbettung des Knotens und der Nachbareinbettung des Knotens, um eine neue Einbettung des Knotens zu erzeugen.
- Receiving a current embed of each node of the graph generated during a previous embed time step;
- Combining, for each particular node of the graph, the respective current embedding of each neighboring node of the particular node in order to generate a neighboring embedding of the particular node; and
- Combine, for each node of the graph, the current embedding of the node and the neighboring embedding of the node to create a new embedding of the node.
Eine Ausführungsform 28 ist das System der Ausführungsform 27, wobei ein Verarbeiten der Daten, die den Graphen darstellen, unter Verwendung des neuronalen Netzes zur Grapheneinbettung bei einem ersten Einbettungs-Zeitschritt folgendes umfasst:
- Erzeugen einer anfänglichen Einbettung für jeden Knoten des Graphen unter Verwendung von Merkmalen des Knotens, wobei die Merkmale eines oder mehreres von folgendem umfassen:
- einen Operationstyp der durch den Knoten charakterisierten Operation,
- eine Ausgabeform einer Ausgabe der durch den Knoten charakterisierten Operation, oder
- eine jeweilige Identifikation für jeden Nachbarknoten des Knotens.
- Generate an initial embedding for each node of the graph using features of the node, the features including one or more of the following:
- an operation type of the operation characterized by the knot,
- an output form of an output of the operation characterized by the node, or
- a respective identification for each neighboring node of the node.
Eine Ausführungsform 29 ist das System von einer der Ausführungsform 27-28, wobei ein Kombinieren der aktuellen Einbettung eines bestimmten Knotens und der Nachbareinbettung des bestimmten Knotens folgendes umfasst:
- Verketten der aktuellen Einbettung des bestimmten Knotens und der Nachbarschaftseinbettung des bestimmten Knotens, um eine kombinierte Einbettung des bestimmten Knotens zu erzeugen; und
- Verarbeiten der kombinierten Einbettung des bestimmten Knotens unter Verwendung von einer oder mehreren vollständig verbundenen Schichten eines neuronalen Netzes, um die neue Einbettung des bestimmten Knotens zu erzeugen.
- Concatenating the current embedding of the particular node and the neighborhood embedding of the particular node to produce a combined embedding of the particular node; and
- Processing the combined embedding of the particular node using one or more fully connected layers of a neural network to generate the new embedding of the particular node.
Eine Ausführungsform 30 ist das System von einer der Ausführungsformen 27-29, wobei ein Kombinieren der jeweiligen Einbettung jedes Nachbarknotens eines bestimmten Knotens folgendes umfasst:
- Verarbeiten, für jeden Nachbarknoten des bestimmten Knotens, der aktuellen Einbettung des Nachbarknotens unter Verwendung einer affinen Transformation, um eine verarbeitete Einbettung für den Nachbarknoten zu erzeugen;
- Verarbeiten, für jeden Nachbarknoten des bestimmten Knotens, der verarbeiteten Einbettung des Nachbarknotens unter Verwendung einer Sigmoid-Aktivierungsfunktion, um eine Aktivierungseinbettung für den Nachbarknoten zu erzeugen; und
- Kombinieren der jeweiligen Aktivierungseinbettung jedes Nachbarknotens des bestimmten Knotens durch Verarbeiten der Aktivierungseinbettungen unter Verwendung einer MaxPooling-Schicht.
- Processing, for each neighboring node of the particular node, the current embedding of the neighboring node using an affine transformation in order to generate a processed embedding for the neighboring node;
- Processing, for each neighboring node of the particular node, the processed embedding of the neighboring node using a sigmoid activation function to generate an activation embedding for the neighboring node; and
- Combining the respective activation embedding of each neighboring node of the particular node by processing the activation embeddings using a MaxPooling layer.
Eine Ausführungsform 31 ist das System von einer der Ausführungsformen 23-30, wobei die bestimmte Optimierungsaufgabe eine von folgenden ist:
- eine Vorrichtungsplatzierungsaufgabe, wobei jede der Vielzahl von Operationen des neuronalen Netzes einer bestimmten Verarbeitungsvorrichtung von der einen oder den mehreren Verarbeitungsvorrichtung zugeordnet wird;
- eine Operationszeitplanungsaufgabe, wobei jede der Vielzahl von Operationen des neuronalen Netzes einer Priorität zugeordnet wird, und wobei jede Verarbeitungsvorrichtung einen prioritätsbasierten Zeitplaner umfasst, der eine Prioritätswarteschlange der zu der Verarbeitungsvorrichtung zugeordneten Operationen beibehält; oder
- eine Operationsverbindungsaufgabe, wobei eine Vielzahl der Operationen des neuronalen Netzes bestimmt wird, derart ausgeführt zu werden, als ob die ausgewählten Operationen eine einzige Operation wären.
- a device placement task, wherein each of the plurality of neural network operations is assigned to a particular processing device by the one or more processing devices;
- an operation scheduling task, wherein each of the plurality of neural network operations is assigned a priority, and wherein each processing device includes a priority-based scheduler that maintains a priority queue of operations assigned to the processing device; or
- an operation connection task wherein a plurality of the operations of the neural network are determined to be performed as if the selected operations were a single operation.
Eine Ausführungsform 32 ist das System von einer der Ausführungsformen 23-31, wobei das neuronale Netz zur Grapheneinbettung und das neuronale Netz für Konzepte durch Updaten von Parametern θ des neuronalen Netzes unter Verwendung einer Zielfunktion, die eine erwartete Laufzeit von jeweiligen durch jeden einer Vielzahl von Kandidatengraphen charakterisierten Operationen charakterisiert, Ende-zu-Ende trainiert worden sind.Embodiment 32 is the system of one of Embodiments 23-31, wherein the neural network for graph embedding and the neural network for concepts by updating parameters θ of the neural network using an objective function that has an expected running time of each of a plurality of Candidate graphs characterized operations that have been end-to-end trained.
Eine Ausführungsform 33 ist das System der Ausführungsformen 32, wobei die Zielfunktion folgende ist:
Eine Ausführungsform 34 ist das System von einer der Ausführungsformen 32-33, wobei das neuronale Netz zur Grapheneinbettung und das neuronale Netz für Konzepte durch Optimieren der Zielfunktion unter Verwendung einer proximalen Konzeptoptimierung (Proximal Policy Optimization) trainiert worden sind.Embodiment 34 is the system of any of Embodiments 32-33, wherein the graph embedding neural network and the concepts neural network have been trained by optimizing the objective function using proximal policy optimization.
Eine Ausführungsform 35 ist das System von einer der Ausführungsformen 23-34, wobei das neuronale Netz für Konzepte auf Merkmale des Graphen konditioniert ist.An embodiment 35 is the system of any of embodiments 23-34, wherein the neural network is conditioned for concepts on features of the graph.
Eine Ausführungsform 36 ist das System der Ausführungsform 35, wobei ein Konditionieren des neuronalen Netzes für Konzepte auf Merkmale des Graphen ein Berechnen einer Ausgabe x(l+1) einer Schicht eines neuronalen Netzes / des neuronalen Netze für Konzepte folgendes umfasst:
Eine Ausführungsform 37 ist das System von einer der Ausführungsformen 23-36, wobei die Operationen weiterhin folgendes umfassen:
- Ausführen der Vielzahl von Operationen des neuronalen Netzes auf der einen oder den mehreren Verarbeitungsvorrichtungen unter Verwendung des erzeugten Optim ieru ngskonzepts.
- Carrying out the plurality of operations of the neural network on the one or more processing devices using the generated optimization concept.
Eine Ausführungsform 38 ist das System von einer der Ausführungsformen 23-37, wobei:
- das neuronale Netz für Konzepte ein Konzepteinbettungs-Unternetz umfasst, das eine Vielzahl von rekurrenten Aufmerksamkeitsschichten eines neuronalen Netzes umfasst; und
- ein Erzeugen der ersten Aufgabeneinbettung aus der Einbettung des Graphen ein Verarbeiten der Einbettung des Graphen unter Verwendung des Konzepteinbettungs-Unternetzes umfasst.
- the concepts neural network includes a concept embedding subnet that includes a plurality of recurrent neural network attentional layers; and
- generating the first task embedding from the embedding of the graph comprises processing the embedding of the graph using the conceptual embedding subnet.
Eine Ausführungsform 39 ist das System von einer der Ausführungsformen 23-38, wobei das neuronale Netz für Konzepte folgendes umfasst:
- ein jeweiliges Aufgabenaufmerksamkeits-Unternetz für jede der Vielzahl von Optimierungsaufgaben, wobei jedes Aufgabenaufmerksamkeits-Unternetz eine oder mehrere Aufmerksamkeitsschichten eines neuronalen Netzes umfasst; und
- ein jeweiliges Aufgabenkonzept-Unternetz für jede der Vielzahl von Optimierungsaufgaben,
- wobei ein Verarbeiten einer Aufgabeneinbettung für eine bestimmte Optimierungsaufgabe unter Verwendung des neuronalen Netzes für Konzepte folgendes umfasst:
- Verarbeiten der Aufgabeneinbettung unter Verwendung des Aufgabenaufmerksamkeits-Unternetzes entsprechend der bestimmten Optimierungsaufgabe, um eine Aufmerksamkeitseinbettung zu erzeugen; und
- Verarbeiten der Aufmerksamkeitseinbettung unter Verwendung des Aufgabenkonzept-Unternetzes entsprechend der bestimmten Optimierungsaufgabe, um die Aufgabenausgabe für die bestimmte Optimierungsaufgabe zu erzeugen.
- a respective task attention subnet for each of the plurality of optimization tasks, each task attention subnet comprising one or more attention layers of a neural network; and
- a respective task concept subnet for each of the multitude of optimization tasks,
- wherein processing a task embedding for a particular optimization task using the neural network for concepts comprises:
- Processing the task embedding using the task attention subnet in accordance with the determined optimization task to generate an attention embedding; and
- Processing the attention embedding using the task concept subnet according to the particular optimization task to generate the task output for the particular optimization task.
Eine Ausführungsform 40 ist das System der Ausführungsform 39, wobei die Aufgabenaufmerksamkeits-Unternetze von jeder der Vielzahl von Optimierungsaufgaben eine Vielzahl von Parametern gemeinsam nutzen bzw. teilen.An embodiment 40 is the system of embodiment 39 wherein the task attention subnets of each of the plurality of optimization tasks share a plurality of parameters.
Eine Ausführungsform 41 ist das System von einer der Ausführungsformen 39-40, wobei das jeweilige Aufgabenaufmerksamkeits-Unternetz entsprechend jeder Optimierungsaufgabe eine oder mehrere Restverbindungen mit jedem von dem einen oder den mehreren anderen Aufgabenaufmerksamkeits-Unternetzen entsprechend anderen Optimierungsaufgaben gemeinsam nutzt bzw. teilt.An embodiment 41 is the system of one of the embodiments 39-40, wherein the respective task attention subnetwork uses or shares one or more residual connections with each of the one or more other task attention subnets corresponding to other optimization tasks in accordance with each optimization task.
Eine Ausführungsform 42 ist ein Computerspeichermedium, das mit einem Computerprogramm codiert ist, wobei das Programm Anweisungen umfasst, die dann, wenn sie durch eine Datenverarbeitungsvorrichtung ausgeführt werden, betreibbar sind, um zu veranlassen, dass die Datenverarbeitungsvorrichtung die Operationen von irgendeiner der Ausführungsformen 1 bis 41 durchführt.One embodiment 42 is a computer storage medium encoded with a computer program, the program including instructions that, when executed by a computing device, are operable to cause the computing device to perform the operations of any one of Embodiments 1-41 performs.
Während diese Beschreibung viele spezifische Implementierungsdetails enthält, sollten diese nicht als Beschränkungen für den Schutzumfang von irgendeiner Erfindung oder für den Schutzumfang von dem, was beansprucht sein kann, angesehen werden, sondern vielmehr als Beschreibungen von Merkmalen, die spezifisch für bestimmte Ausführungsformen von bestimmten Erfindungen sind. Bestimmte Merkmale, die in dieser Beschreibung in dem Zusammenhang von separaten Ausführungsformen beschrieben sind, können auch in Kombination in einer einzigen Ausführungsform implementiert sein. Gegensätzlich dazu können verschiedene Merkmale, die im Zusammenhang mit einer einzigen Ausführungsform beschrieben sind, auch in mehreren Ausführungsformen separat oder in irgendeiner geeigneten Unterkombination implementiert sein. Darüber hinaus können, obwohl Merkmale oben derart beschrieben sein können, dass sie in bestimmten Kombinationen agieren, und sogar anfänglich als solches beansprucht sind, ein oder mehrere Merkmale aus einer beanspruchten Kombination in einigen Fällen von der Kombination ausgeschlossen werden, und die beanspruchte Kombination kann auf eine Unterkombination oder eine Variation einer Unterkombination gerichtet sein.While this description contains many specific implementation details, these should not be viewed as limitations on the scope of any invention or on the scope of what may be claimed, but rather as descriptions of features that are specific to particular embodiments of particular inventions . Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. In contrast, various features that are described in connection with a single embodiment can also be implemented in multiple embodiments separately or in any suitable sub-combination. Furthermore, although features above may be described as acting in certain combinations, and even initially claimed as such, in some instances one or more features from a claimed combination may be excluded from the combination, and the claimed combination may include a subcombination or a variation of a subcombination may be directed.
Gleichermaßen sollte, während Operationen in einer bestimmten Reihenfolge in den Zeichnungen gezeigt und in den Ansprüchen vorgetragen sind, dies nicht derart verstanden werden, dass es erforderlich ist, dass solche Operationen in der gezeigten bestimmten Reihenfolge oder in einer sequentiellen Reihenfolge durchgeführt werden oder dass alle dargestellten Operationen durchgeführt werden, um erwünschte Ergebnisse zu erreichen. Unter gewissen Umständen können Multitasking und Parallelverarbeitung vorteilhaft sein. Darüber hinaus sollte die Trennung von verschiedenen Systemkomponenten bei den oben beschriebenen Ausführungsformen nicht derart verstanden werden, dass eine solche Trennung bei allen Ausführungsformen erforderlich ist, und es sollte verstanden werden, dass die beschriebenen Programmkomponenten und Systeme allgemein miteinander in einem einzigen Softwareprodukt integriert oder in mehrere Softwareprodukte gepackt sein können.Likewise, while operations are shown in a particular order in the drawings and recited in the claims, it should not be construed as requiring that such operations be performed in the particular order shown, or in a sequential order, or all of them depicted Operations are performed to achieve desired results. In certain circumstances, multitasking and parallel processing can be beneficial. Furthermore, the separation of various system components in the embodiments described above should not be understood in such a way that such separation is necessary in all embodiments, and it should be understood that the described program components and systems are generally integrated with one another in a single software product or in several Software products can be packaged.
Bestimmte Ausführungsformen des Gegenstands sind beschrieben worden. Andere Ausführungsformen sind innerhalb des Schutzumfangs der folgenden Ansprüche. Zum Beispiel können die in den Ansprüchen vorgetragenen Aktionen in einer anderen Reihenfolge durchgeführt werden und noch erwünschte Ergebnisse erreichen. Als ein Beispiel erfordern die in den beigefügten Figuren dargestellten Prozesse nicht notwendigerweise die gezeigte bestimmte Reihenfolge, um erwünschte Ergebnisse zu erreichen. In einigen Fällen kann Multitasking und Parallelverarbeitung vorteilhaft sein.Certain embodiments of the subject matter have been described. Other embodiments are within the scope of the following claims. For example, the actions recited in the claims can be performed in a different order and still achieve desired results. As an example, the processes illustrated in the accompanying figures do not necessarily require the particular order shown in order to achieve desired results. In some cases, multitasking and parallel processing can be beneficial.
Claims (23)
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US202062971891P | 2020-02-07 | 2020-02-07 | |
US62,971,891 | 2020-02-07 |
Publications (1)
Publication Number | Publication Date |
---|---|
DE202020101664U1 true DE202020101664U1 (en) | 2020-07-07 |
Family
ID=71739364
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
DE202020101664.4U Active DE202020101664U1 (en) | 2020-02-07 | 2020-03-27 | Computer-aided graph optimization |
Country Status (5)
Country | Link |
---|---|
US (2) | US11657289B2 (en) |
EP (1) | EP4100888A1 (en) |
CN (1) | CN115066694A (en) |
DE (1) | DE202020101664U1 (en) |
WO (1) | WO2021158267A1 (en) |
Cited By (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN111814977A (en) * | 2020-08-28 | 2020-10-23 | 支付宝(杭州)信息技术有限公司 | Method and device for training event prediction model |
CN114816997A (en) * | 2022-03-29 | 2022-07-29 | 湖北大学 | Defect prediction method based on graph neural network and bidirectional GRU feature extraction |
Families Citing this family (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11815943B1 (en) | 2020-06-05 | 2023-11-14 | State Farm Mutual Automobile Insurance Company | Systems and methods for processing using directed acyclic graphs |
US20230108001A1 (en) * | 2021-09-27 | 2023-04-06 | Advanced Micro Devices, Inc. | Priority-based scheduling with limited resources |
CN113703741B (en) * | 2021-10-29 | 2022-02-22 | 深圳思谋信息科技有限公司 | Neural network compiler configuration method and device, computer equipment and storage medium |
Family Cites Families (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
EP3580698B1 (en) | 2017-07-21 | 2024-02-14 | Google LLC | Hierarchical device placement with reinforcement learning |
CN111353091A (en) * | 2018-12-24 | 2020-06-30 | 北京三星通信技术研究有限公司 | Information processing method and device, electronic equipment and readable storage medium |
US20200249998A1 (en) * | 2019-02-01 | 2020-08-06 | Alibaba Group Holding Limited | Scheduling computation graph heterogeneous computer system |
-
2020
- 2020-03-27 DE DE202020101664.4U patent/DE202020101664U1/en active Active
- 2020-04-03 US US16/840,191 patent/US11657289B2/en active Active
- 2020-10-15 CN CN202080095991.XA patent/CN115066694A/en active Pending
- 2020-10-15 EP EP20801119.7A patent/EP4100888A1/en active Pending
- 2020-10-15 WO PCT/US2020/055848 patent/WO2021158267A1/en unknown
-
2023
- 2023-05-22 US US18/321,691 patent/US20230306266A1/en active Pending
Cited By (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN111814977A (en) * | 2020-08-28 | 2020-10-23 | 支付宝(杭州)信息技术有限公司 | Method and device for training event prediction model |
CN114816997A (en) * | 2022-03-29 | 2022-07-29 | 湖北大学 | Defect prediction method based on graph neural network and bidirectional GRU feature extraction |
CN114816997B (en) * | 2022-03-29 | 2023-08-18 | 湖北大学 | Defect prediction method based on graph neural network and bidirectional GRU feature extraction |
Also Published As
Publication number | Publication date |
---|---|
US20210248445A1 (en) | 2021-08-12 |
US20230306266A1 (en) | 2023-09-28 |
US11657289B2 (en) | 2023-05-23 |
EP4100888A1 (en) | 2022-12-14 |
CN115066694A (en) | 2022-09-16 |
WO2021158267A1 (en) | 2021-08-12 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
DE202020101664U1 (en) | Computer-aided graph optimization | |
DE112018006047T5 (en) | DEFENSE OF FUNCTIONAL FUNCTIONS IN QUANTUM APPROXIMATION OPTIMIZATION | |
DE202020101701U1 (en) | Training neural networks using data augmentation strategies | |
DE102018111905A1 (en) | Domain-specific language for generating recurrent neural network architectures | |
DE102018202497A1 (en) | Technologies for optimized machine learning training | |
DE112019003405T5 (en) | AUTOMATIC FINE TUNING DEVICE FOR EMBEDDING CLOUD MICRO-SERVICES | |
DE102017121887A1 (en) | Perform core traversal in hardware | |
DE102018100239A1 (en) | Loop and library fusion | |
DE112018005227T5 (en) | CHARACTERISTICS EXTRACTION BY MULTI-TASK LEARNING | |
DE202017007517U1 (en) | Aggregate characteristics for machine learning | |
DE112016002292T5 (en) | STACK PROCESSING IN A NEURONAL NETWORK PROCESSOR | |
DE112018005205T5 (en) | Compression of completely connected / recurring layers from one or more deep networks by enforcing spatial locality for weight matrices and effecting frequency compression | |
DE102012216029A1 (en) | A SCALABLE ADAPTABLE MAP REDUCE FRAMEWORK WITH DISTRIBUTED DATA | |
DE102017109239A1 (en) | COMPUTER IMPLEMENTED PROCESS, COMPUTER READABLE MEDIA AND HETEROGICAL COMPUTER SYSTEM | |
DE102020108374A1 (en) | METHOD AND DEVICE FOR THE MULTIPLE RUN-TIME PLANNING OF SOFTWARE EXECUTED IN A HETEROGENIC SYSTEM | |
DE202017107393U1 (en) | Predicting a search engine map signal value | |
DE112021006232T5 (en) | PROACTIVE ANOMAL DETECTION | |
DE102017213160B4 (en) | Compilation for node device GPU-based parallel processing | |
DE112019005048T5 (en) | Hyperparameter optimization method, device and program | |
DE112020002344T5 (en) | FEATURE ENGINEERING FOR THE OPTIMIZATION OF NEURAL NETWORKS | |
DE112021003747T5 (en) | DETECTING ANOMALIES IN A NETWORK TOPOLOGY | |
DE112020003744T5 (en) | AUTOMATED OPERATING DATA MANAGEMENT REQUIRED BY QUALITY OF SERVICE CRITERIA | |
DE212021000487U1 (en) | Runtime task scheduling through imitation learning for heterogeneous systems with many cores | |
EP2386949B1 (en) | Method and device for allocating a number of sub-tasks from a task to a number of computing units in a pre-defined processor architecture | |
DE112021001767T5 (en) | STREAMLINE COMPUTING OPTIMIZATIONS FOR WORKLOADS WITH MACHINE LEARNING |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
R207 | Utility model specification | ||
R150 | Utility model maintained after payment of first maintenance fee after three years |