CN116490849A - Prioritized application updates - Google Patents
Prioritized application updates Download PDFInfo
- Publication number
- CN116490849A CN116490849A CN202180071770.3A CN202180071770A CN116490849A CN 116490849 A CN116490849 A CN 116490849A CN 202180071770 A CN202180071770 A CN 202180071770A CN 116490849 A CN116490849 A CN 116490849A
- Authority
- CN
- China
- Prior art keywords
- application
- update
- computing device
- applications
- machine learning
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
- 238000010801 machine learning Methods 0.000 claims abstract description 300
- 238000009434 installation Methods 0.000 claims abstract description 105
- 230000004044 response Effects 0.000 claims abstract description 31
- 238000000034 method Methods 0.000 claims description 119
- 238000012913 prioritisation Methods 0.000 claims description 7
- 230000006870 function Effects 0.000 description 35
- 238000007726 management method Methods 0.000 description 35
- 238000012549 training Methods 0.000 description 28
- 238000011156 evaluation Methods 0.000 description 20
- 238000005457 optimization Methods 0.000 description 17
- 238000004891 communication Methods 0.000 description 8
- 238000010586 diagram Methods 0.000 description 8
- 238000005516 engineering process Methods 0.000 description 7
- 230000008569 process Effects 0.000 description 6
- 238000012545 processing Methods 0.000 description 6
- 230000001413 cellular effect Effects 0.000 description 5
- 229920001621 AMOLED Polymers 0.000 description 4
- 238000001514 detection method Methods 0.000 description 4
- 238000009499 grossing Methods 0.000 description 4
- 230000006872 improvement Effects 0.000 description 4
- 230000003287 optical effect Effects 0.000 description 4
- 230000003068 static effect Effects 0.000 description 4
- 230000007774 longterm Effects 0.000 description 3
- 230000006855 networking Effects 0.000 description 3
- 238000004806 packaging method and process Methods 0.000 description 3
- 230000002787 reinforcement Effects 0.000 description 3
- 238000013528 artificial neural network Methods 0.000 description 2
- 239000000835 fiber Substances 0.000 description 2
- 230000003993 interaction Effects 0.000 description 2
- 238000012417 linear regression Methods 0.000 description 2
- 239000004973 liquid crystal related substance Substances 0.000 description 2
- 239000011159 matrix material Substances 0.000 description 2
- 230000000007 visual effect Effects 0.000 description 2
- 241000288113 Gallirallus australis Species 0.000 description 1
- 235000014749 Mentha crispa Nutrition 0.000 description 1
- 244000078639 Mentha spicata Species 0.000 description 1
- 241001180976 Nonea Species 0.000 description 1
- 230000004913 activation Effects 0.000 description 1
- 230000006978 adaptation Effects 0.000 description 1
- 230000003044 adaptive effect Effects 0.000 description 1
- 238000003491 array Methods 0.000 description 1
- 239000003795 chemical substances by application Substances 0.000 description 1
- 238000004590 computer program Methods 0.000 description 1
- 238000013500 data storage Methods 0.000 description 1
- 230000000694 effects Effects 0.000 description 1
- 238000013210 evaluation model Methods 0.000 description 1
- 230000002068 genetic effect Effects 0.000 description 1
- 230000001939 inductive effect Effects 0.000 description 1
- 230000000977 initiatory effect Effects 0.000 description 1
- 238000013450 outlier detection Methods 0.000 description 1
- 238000012552 review Methods 0.000 description 1
- 239000004984 smart glass Substances 0.000 description 1
- 238000010897 surface acoustic wave method Methods 0.000 description 1
- 238000013526 transfer learning Methods 0.000 description 1
- 239000013598 vector Substances 0.000 description 1
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F8/00—Arrangements for software engineering
- G06F8/60—Software deployment
- G06F8/65—Updates
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/46—Multiprogramming arrangements
- G06F9/48—Program initiating; Program switching, e.g. by interrupt
- G06F9/4806—Task transfer initiation or dispatching
- G06F9/4843—Task transfer initiation or dispatching by program, e.g. task dispatcher, supervisor, operating system
- G06F9/4881—Scheduling strategies for dispatcher, e.g. round robin, multi-level priority queues
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
Abstract
The computing system may receive a request for application update information for one or more applications installed on the computing device. The computing system determines a set of applications that need to be updated based on the request for application update information and applies a machine learning model to determine a respective update priority score for each application from the set of applications. The computing system sends an indication of the respective updated priority scores for the application sets to the computing device. In response to receiving an update request from a computing device, the computing system initiates installation of a pending update for at least one application from the set of applications.
Description
Background
In recent years, computing devices such as mobile phones have proliferated. These devices may be equipped with a processor, memory, and the ability to communicate over local and wide area networks, including the internet. These devices may be equipped with an operating system that allows the devices to execute a wide range of computer programs and software applications, commonly referred to as "apps. A user of a computing device may download and install an application by communicating directly with a computing system (e.g., a server hosting an application store) via a cellular network or a wireless local area network. Developers of these applications update the applications regularly and push updated versions of the applications to the computing system so that the updated versions of the applications are available for installation by the computing device. However, managing application updates may be difficult for a user due to the number of application updates that may need to be installed.
Disclosure of Invention
Techniques are described in which a computing system and computing device may operate to prioritize the installation of updates to a set of applications installed on the computing device. In general, a user of a computing device may manage application updates by manually downloading the application updates or selecting to push the application updates automatically to the computing device once the application updates become available ("auto-updates"). While automatic updating facilitates installation of application updates without user interaction from the user, handling automatic updates of all applications equally in terms of update prioritization may result in relatively unimportant applications being updated (e.g., successfully installed) and relatively important applications not being updated (e.g., unsuccessfully installed) to the user for various reasons.
Rather than automatically installing application updates without evaluating application update priorities, the techniques of this disclosure enable a computing device to identify successfully installed application updates with a higher likelihood while also prioritizing the updates of the most frequently used applications by the user. In general, a computing device and/or cloud computing system may apply a machine learning model to one or more of: application usage history, application update installation history, network settings for automatic updates, etc., to determine an update priority score for a set of application updates. The computing device and/or cloud computing system may prioritize (e.g., rank) the application updates based on the update priority scores for the application sets. Using the application update ranking, the computing device may prioritize at least one of downloading and installing the highest ranked application updates.
In this way, aspects of the technology may enable a computing device to identify application updates that have a higher likelihood of successful installation and are more important to the user. By prioritizing the updates in this manner, the number of failed application update installations may be reduced, which may reduce bandwidth, processor, and power usage of the device. Furthermore, by prioritizing application updates for those applications in which the user of the computing device is most interested and/or more frequently used, application updates for relatively unimportant applications may not be downloaded or downloaded less frequently (e.g., due to lower priority), which may also reduce bandwidth usage (e.g., by not downloading undesired application updates) and reduce CPU usage (e.g., by prioritizing updates that are more likely to be successfully installed, resulting in less failed installations). Furthermore, prioritizing updates for applications frequently used by users may help reduce crashes or other errors in such applications.
In some examples, a method includes: receiving, by the computing system and from the computing device, a request for application update information for one or more applications installed on the computing device; a set of applications requiring updating is determined by the computing system and based on the request for application update information, wherein each application of the set of applications is associated with a respective pending update, and a machine learning model is applied by the computing system to determine a respective update priority score for each application from the set of applications. The method may further comprise: transmitting, from the computing system to the computing device, an indication of the respective updated priority scores for the application set; receiving, by the computing system and from the computing device, an update request for at least one application from the set of applications, the at least one application from the set of applications selected by the computing device based on the respective update priority scores; and in response to receiving the update request, initiate, by the computing system, installation of a pending update for at least one application of the set of applications.
In some examples, a computing system includes a memory and one or more processors. The one or more processors may be configured to receive, from the computing device, a request for application update information for one or more applications installed on the computing device, determine a set of applications that need to be updated based on the request for application update information, wherein each application from the set of applications is associated with a respective pending update, and apply a machine learning model to determine a respective update priority score for each application of the set of applications. The one or more processors may be further configured to send an indication of a respective update priority score for the set of applications to the computing device, receive an update request from the computing device for at least one application of the set of applications, the at least one application from the set of applications selected by the computing device based on the respective update priority score, and initiate installation of a pending update for the at least one application from the set of applications in response to receiving the update request.
In some examples, a non-transitory computer-readable storage medium encoded with instructions that, when executed by one or more processors of a computing system, cause the one or more processors to receive, from a computing device, a request for application update information for one or more applications installed on the computing device, determine a set of applications that need to be updated based on the request for application update information, wherein each application from the set of applications is associated with a respective pending update, and apply a machine learning model to determine a respective update priority score for each application of the set of applications. The instructions may also cause the one or more processors to send, to the computing device, an indication of a respective update priority score for the set of applications, receive, from the computing device, an update request for at least one application of the set of applications, the at least one application from the set of applications selected by the computing device based on the respective update priority score, and initiate installation of a pending update for the at least one application from the set of applications in response to receiving the update request.
In some examples, a method includes sending, by a computing device to a computing system, a request for application update information for one or more applications installed on the computing device, receiving, by the computing device and from the computing system, an indication of a respective update priority score for each application from a set of applications having a respective pending update, wherein each respective update priority score is determined by the computing system by applying at least a machine learning model to each application of the set of applications having a corresponding pending update, and selecting, by the computing device and based on the respective update priority ranks, at least one corresponding pending update to request from the computing system. The method may further comprise: an update request for the at least one corresponding pending update is sent by the computing device to the computing system, and the at least one corresponding pending update is installed by the computing device in response to receiving the at least one corresponding pending update from the computing system by the computing device.
In some examples, an apparatus includes: means for sending a request to the computing system for application update information for one or more applications installed on the computing device; means for receiving, from the computing system, an indication of a respective update priority score for each application from the set of applications having respective pending updates, wherein each respective update priority score is determined by the computing system by applying at least a machine learning model to each application of the set of applications having corresponding pending updates, and means for selecting at least one corresponding pending update to be requested from the computing system based on the respective update priority ranks. The apparatus may also include means for sending an update request to the computing system for at least one corresponding pending update, and means for installing the at least one corresponding pending update in response to receiving the at least one corresponding pending update from the computing system.
In some examples, a method includes: determining, by the computing system, validity of the first machine learning model based on a set of application updates installed on the first computing device, the application updates prioritized based on respective first update priority scores for each application generated by the first machine learning model; determining, by the computing system, validity of the second machine learning model based on a set of application updates installed on the second computing device, the application updates prioritized based on respective second update priority scores for each application generated by the second machine learning model, and selecting, by the computing system and based on the validity of the first machine learning model and the validity of the second machine learning model, a more valid one of the first machine learning model and the second machine learning model as a preferred machine learning model for prioritizing future application updates.
In some examples, a computing device includes a memory storing one or more modules and one or more processors. The one or more processors execute the one or more modules to: determining validity of the first machine learning model based on a set of application updates installed on the first computing device, the application updates prioritized based on respective first update priority scores for each application generated by the first machine learning model; determining validity of the second machine learning model based on a set of application updates installed on the second computing device, the application updates prioritized based on respective second update priority scores for each application generated by the second machine learning model; and selecting a more efficient one of the first machine learning model and the second machine learning model as a preferred machine learning model based on the validity of the first machine learning model and the validity of the second machine learning model for prioritizing future application updates.
In some examples, a non-transitory computer-readable storage medium encoded with instructions that, when executed by one or more processors of a computing system, cause the one or more processors to: determining validity of the first machine learning model based on a set of application updates installed on the first computing device, the application updates prioritized based on respective first update priority scores for each application generated by the first machine learning model; determining validity of the second machine learning model based on a set of application updates installed on the second computing device, the application updates prioritized based on respective second update priority scores for each application generated by the second machine learning model; and selecting a more efficient one of the first machine learning model and the second machine learning model as a preferred machine learning model based on the validity of the first machine learning model and the validity of the second machine learning model for prioritizing future application updates.
The details of one or more examples are set forth in the accompanying drawings and the description below. Other features, objects, and advantages of the disclosure will be apparent from the description and drawings, and from the claims.
Drawings
FIG. 1 is a conceptual diagram illustrating an example computing system and computing device for prioritizing application updates in accordance with the techniques of this disclosure.
FIG. 2 is a block diagram illustrating an example computing device for prioritizing application updates in accordance with the techniques of this disclosure.
FIG. 3 is a block diagram illustrating aspects of an example machine learning model for prioritizing application updates in accordance with the techniques of this disclosure.
FIG. 4 is a block diagram illustrating exemplary operation of a machine learning model in accordance with the techniques of this disclosure.
FIG. 5 is a flowchart illustrating exemplary operations of a computing system and computing device in accordance with the techniques of this disclosure.
FIG. 6 is a flowchart illustrating another exemplary operation of a computing system and computing device in accordance with the techniques of this disclosure.
Fig. 7 is a flowchart illustrating exemplary operation of a computing device in accordance with the techniques of this disclosure.
Detailed Description
FIG. 1 is a conceptual diagram illustrating an example computing system and computing device for prioritizing application updates in accordance with the techniques of this disclosure. As shown in the example of fig. 1, computing device 100 and computing system 110 may facilitate management of application updates by prioritizing installation of updates to a set of applications installed on computing device 100 in accordance with one or more techniques of the present disclosure.
In the example of fig. 1, computing device 100 is a mobile computing device. However, computing device 100 may be any mobile or non-mobile computing device, such as a cellular telephone, smart phone, personal Digital Assistant (PDA), desktop computer, laptop computer, tablet computer, portable gaming device, portable media player, electronic book reader, watch (including so-called smart watches), additional devices (such as projection devices), smart glasses, game controller, or other types of computing devices.
Similarly, computing system 110 may be any suitable remote computing system capable of sending and receiving information via network 108, such as one or more desktop computers, laptop computers, mainframes, servers, cloud computing systems, virtual machines, and the like. In some examples, computing system 110 may represent a cloud computing system that provides one or more services via network 108. That is, in some examples, computing system 110 may be a distributed computing system. One or more computing devices, such as computing device 100, may access services provided by the cloud by communicating with computing system 110. Although described herein as being at least partially performed by computing system 110, any or all of the techniques of this disclosure may be performed by one or more other devices, such as computing device 100. That is, in some examples, computing device 100 may be operable to individually perform one or more techniques of the present disclosure.
Computing device 100 may include an application management module 107, a presence-sensitive display 120, and a communication ("COMM") component 124. The display 120 may be a presence-sensitive display that functions as an input device and an output device. For example, a presence-sensitive display may be used as an input device using a presence-sensitive input component, such as a resistive touch screen, a surface acoustic wave touch screen, a capacitive touch screen, a projected capacitive touch screen, a pressure-sensitive screen, an acoustic pulse recognition touch screen, or another presence-sensitive display technology. The presence-sensitive display may be used as an output (e.g., display) device using any of one or more display components, such as a Liquid Crystal Display (LCD), dot matrix display, light Emitting Diode (LED) display, micro LED display, organic Light Emitting Diode (OLED) display, electronic ink, active Matrix Organic Light Emitting Diode (AMOLED) display, or similar monochrome or color display capable of outputting visual information to a user of computing device 100.
The COMM component 124 may receive and transmit various types of information over the network 108, such as information regarding pending updates associated with one or more applications 106 installed on the computing device 100. The network 108 may include a wide area network such as the Internet, a Local Area Network (LAN), a Personal Area Network (PAN) (e.g., a Personal Area Network (PAN) ) Enterprise network, noneA network, a cellular network, a telephone network, a metropolitan area network (e.g., WIFI, WAN, wiMAX, etc.), one or more other types of networks, or a combination of two or more different types of networks (e.g., a combination of a cellular network and the Internet).
COMM component 124 may include a wireless communication device capable of transmitting and/or receiving communication signals using network 108, such as cellular radio, 3G radio, 4G radio, 5G radio, network 108,A radio (or any other PAN radio), an NFC radio or a WIFI radio (or any other WLAN radio). Additionally or alternatively, COMM component 124 may include a wired communication device capable of transmitting and/or receiving communication signals via a direct link over a wired communication medium (e.g., universal serial bus ("USB") cable).
Computing device 100 may download, install, and execute one or more applications 106 (e.g., using one or more COMM components 124). Applications 106A-N (collectively, "applications 106") may represent first party applications developed and provided as applications integrated into an operating system or third party applications obtained by a user of computing device 100 via application store services provided through the operating system. The application 106 may extend the software functionality of the computing device 100, where the application 106 may execute within an execution environment presented by an operating system. As a few examples, the application 106 may provide game services (e.g., video games), email services, web browsing services, text messaging and/or chat services, web conferencing services, video conferencing services, music services (including streaming music services), video services (including video streaming services), navigation services, word processing services, spreadsheet services, slide and/or presentation services, assistant services, text input services, or any other services typically provided by an application.
In accordance with the techniques of this disclosure, computing device 100 may execute application management module 107 to facilitate management of application updates by operating in conjunction with application update module 117 of computing system 110 to intelligently prioritize application updates. For example, the computing device 100 may use the application management module 107 to generate application management information identifying the applications 106 installed on the computing device 100. In various examples, the application management module 107 may be a client application associated with an application repository or store managed and/or provided by the computing system 110. That is, the computing device 100 may execute the application management module 107 to present an online application store graphical user interface (e.g., GUI 104) via the presence-sensitive display 120 for the online application store. The application store may be hosted or otherwise provided by computing system 110 and may enable a user of computing device 100 to browse, search, select, purchase, download, and install various applications and application updates on computing device 100.
From time to time, developers of various applications may add new features, fix various errors, or update the software code of the application. The developer may publish application updates (e.g., for application 106A) to an online application store provided by computing system 110. When the computing device 110 checks for any available updates for the application 106, the computing system 110 may identify the published application updates for the application 106A as new updates available to the application 106A.
Computing device 100 may automatically send requests for application update information to computing system 110 using one or more COMM components 124 (e.g., on a predetermined schedule, based on application usage history, etc.), or may send such application update information requests in response to receiving user input. The request for application update information may include information identifying the computing device 100, information about one or more applications 106, device storage information, user settings for application updates (e.g., automatically updated settings), and other configuration information for the computing device 100. The information about the applications 106 may include information such as names or other text-based identifiers, version information of installed applications, historical application usage information for each installed application, results of previous application update attempts of the installed applications, and the like.
As one example, the application 106A installed on the computing device 100 may be a photographic application and the application 106N may be a music application. In such an example, the application management module 107 may generate application update requests for the photography application 106A and the music application 106N. The application management module 107 may then send an application update request to the computing system 110.
Although examples are described in which a computing device and/or computing system analyzes information associated with the computing device and a user of the computing device (e.g., application usage, device usage, installation history, etc.), the computing device and/or computing system may analyze information only when the computing device receives permission to analyze the information from the user of the computing device. For example, in the context of the following discussion, before information associated with a user may be collected or available to a computing device or computing system, the user may be provided with an opportunity to provide input to control whether programs or features of the computing device and/or computing system may collect and utilize user information (e.g., information about the user's current location, current speed, etc.), or to instruct the device and/or system whether and/or how to receive content that may be relevant to the user. In addition, certain data may be processed in one or more ways to remove personally identifiable information before such data is stored or used by a computing device and/or computing system. Thus, the user may control how information about the user is collected and used by the computing device and computing system.
The computing system 110 may determine the set of applications installed on the computing device 100 that need to be updated based on the request for application update information. For example, the computing system 100 may determine that each of the applications 106A (e.g., photographic applications) and 106N (e.g., music applications) may have pending application updates available (e.g., on an application store) based on the list of applications and the respective version information for each installed application.
As shown in fig. 1, computing system 110 includes one or more processors 113 and memory 114. Processor 113 may implement functionality and/or execute instructions associated with computing system 110. Examples of processor 113 include an application processor, a display controller, an auxiliary processor, one or more sensor hubs, and any other hardware configured to act as a processor, processing unit, or processing device. The machine learning model 116, the application update module 117, the model evaluation module 118, the model trainer 119, and the like may be operable (or in other words, executed) by the processor 113 to perform various actions, operations, or functions of the computing system 110. That is, the modules 116-119 may form executable bytecodes that, when executed, cause the processor 113 to perform particular operations in accordance with various aspects of the technology described herein (e.g., to cause the computing system 110 to be a particular purpose computer by which to execute).
Computing system 110 may also include memory 114. Memory 114 may store an application update repository 115, a machine learning model 116, an application update module 117, and a model evaluation module 118. In some examples, memory 114 may be described as a computer-readable storage medium. In some examples, memory 114 is temporary, meaning that the primary purpose of memory 114 is not long-term storage. Memory 114 may also be described as volatile memory, meaning that memory 114 does not retain stored content when computing system 110 is powered off. Examples of volatile memory include Random Access Memory (RAM), dynamic Random Access Memory (DRAM), static Random Access Memory (SRAM), and other forms of volatile memory known in the art. In some examples, memory 114 may be used to store program instructions for execution by processor 113. Memory 114 may be used by software or applications running on computing system 110 (e.g., software needed to analyze applications available through an online application store) to temporarily store information during program execution.
In response to receiving the request for application update information, the application update module 117 may determine that the application set from the application 106 has an incomplete update (i.e., an update that has not been successfully installed on the computing device 100). For example, the application update module 117 may perform a lookup in the application update repository 115 to determine which applications, if any, identified in the application update information have incomplete updates. As one example, the application update information includes an indication that the photography application 106A, the music application 106N, and the social networking application are installed on the computing device 100. The application update module 117 may execute queries to retrieve current version information for one or more of these applications. The application update module may compare the retrieved current version information with currently installed versions of the photography application 106A, the music application 106N, and the social networking application. Based on the version information comparison, the application update module 117 may determine that one or more of the applications have incomplete updates.
To facilitate prioritization of application updates, the computing system 110 may determine an updated priority score for each application from the set of applications by applying the machine learning model 116. The machine learning model 116 may use input data stored in the application update repository 115 to provide output data, such as update priority scores. Input data in the application update repository 115 may include application usage, installation history, device-specific automated application update network settings, and the like. For example, the computing system 110 may provide at least some information included in the request for application update information to the machine learning model 116, as well as other information, such as historical application usage information (e.g., user-specific usage, global usage, user-like usage, etc.) collected and stored by the computing system 110. The machine learning model 116 processes the input and generates update priority scores for applications (e.g., the photography application 106A and the music application 106N) with pending updates.
As shown by elements 108A and 108N in GUI 104, machine learning module 116 generates an update priority score for photography application 106A of 90 and an update priority score for music application 106N of 85. The magnitude of the update priority score may indicate the priority of the application update. Thus, an update priority score of 90 may indicate that the application update for the photography application 106A has a higher priority than the music application 106N. Although fig. 1 includes GUI 104, in various examples, computing device 100 may not output a GUI that includes updated priority scores for one or more applications 106. Instead, as a non-limiting example, computing device 100 may simply process the application update based at least in part on the update priority score without outputting GUI 104 at all, or may output a list of incomplete application updates based at least in part on the update priority score.
Computing system 110 may send an indication of the updated priority score or the priority score itself to computing device 100. In response to receiving the indication of the priority score, the application management module 107 may determine an order in which to request application updates based on the indication of the updated priority score such that application updates with a higher likelihood of successful installation and application updates for applications that are most frequently used by the user are prioritized over other application updates. For example, the order of application updates may indicate that computing device 100 should first send an update request for application 106A because application 106A has the largest update priority score. The order of application updates may also indicate that the update request for the application 106N is second, as the application 106N has the second greatest update priority score.
The computing device 100 may generate an update request for one or more applications in the set of applications with pending updates. For example, the computing device may generate an update request for the photography application 106A because the photography application 106A has a greater update priority score (e.g., 90) than the music application 106N (e.g., 85), indicating that installing an update to the photography application 106A has a higher priority than installing an update to the music application 106N. The update request may identify an application to update, a license setting (e.g., network preferences), and so on.
Computing device 100 may send an update request to computing system 110. In response to receiving the update request, the application update module 117 may initiate installation of at least one application update at the computing device 100. For example, the application update module 117 may send one or more application update installation packages to the computing device 110 via the network 108. In response to receiving the application update installation package, the application management module may initiate installation of at least one application update installation package.
In some examples, computing system 110 may use model evaluation module 118 to determine the validity of one or more machine learning models based on various metrics. For example, the computing system 110 may use the model evaluation module 118 to determine the validity of the first machine learning model based on a set of application updates installed on the first computing device, the application updates being prioritized based on a respective first update priority score for each application generated by the first machine learning model. The computing system 110 may also use the model evaluation module 118 to determine the validity of the second machine learning model based on a set of application updates installed on the second computing device, the application updates being prioritized based on a respective second update priority score for each application generated by the second machine learning model. The computing system 110 may then select a more efficient one of the first machine learning model and the second machine learning model as a preferred machine learning model based on the validity of the first machine learning model and the validity of the second machine learning model for prioritizing future application updates.
The computing system 110 may also include a model trainer 119. Model trainer 119 may train machine learning model 116 to increase the effectiveness of machine learning model 116. Model trainer 119 may train machine learning model 116 in an offline manner or in an online manner. In offline training (also referred to as batch learning), the machine learning model 216 may be trained on the entirety of a static set of training data. In online learning, the machine learning model 216 may be continuously trained (or retrained) as new training data becomes available (e.g., as new information about application usage, installation history, and context is generated).
Although described as being stored and executed by computing system 110, in some examples, some or all of application update repository 115, machine learning model 116, application update module 117, and model evaluation module 118 may be stored and/or executed at computing device 100 such that the functionality provided by one or more of application update repository 115, machine learning model 116, application update module 117, and model evaluation module 118 may be provided by computing device 100 without computing device 100 transmitting and receiving information with computing system 110. In other words, some or all of the techniques described in this disclosure may be performed locally at computing device 100.
Various aspects of the technology may improve operation of computing device 100 by increasing the likelihood of successful installation of application updates to applications that are relatively important to the user. By prioritizing the updates in this manner, the number of failed application update installations may be reduced, which may reduce bandwidth, processor, and power usage of the device. Furthermore, by prioritizing application updates for those applications in which the user of the computing device is most interested and/or more frequently used, application updates for relatively unimportant applications may not be downloaded, which may also reduce bandwidth usage (e.g., by not downloading undesired application updates) and reduce CPU usage (e.g., by prioritizing updates that are more likely to be successfully installed, resulting in fewer failed installations). Furthermore, prioritizing updates to applications frequently used by users may help reduce crashes or other errors in such applications.
FIG. 2 is a conceptual diagram illustrating an example computing device for prioritizing application updates in accordance with the techniques of this disclosure. The computing device 200 shown in the example of fig. 2 is one example of the computing device 100 shown in fig. 1. Further, the computing device 200 shown in the example of fig. 2 implements the machine learning model locally and performs one or more other tasks that might otherwise be performed by the computing system 110.
As shown in the example of fig. 2, computing device 200 includes: a presence-sensitive display 220, which may be similar if not substantially similar to 120, one or more processors 222, one or more COMM components 224, which may be similar if not substantially similar to 124, and one or more storage devices 226. The storage device 226 of the computing device 200 may include an operating system 205 that provides an execution environment for one or more applications 206 and modules, as well as an application management module 207, a machine learning model 216, an application update module 217, a model evaluation model 218, and a model trainer 219. If the modules 206-219 are not substantially similar to the modules 106-119, the modules 206-219 may be similar.
Presence-sensitive display 220 of computing device 200 may include the functionality of input components and/or output components. In the example of fig. 2, presence-sensitive display 220 may include a presence-sensitive input (PSI) component 228 ("PSI component 228"), such as a presence-sensitive screen or a touch-sensitive screen. In some examples, presence-sensitive input component 228 may detect objects at and/or near the presence-sensitive input component. As one example range, presence-sensitive input component 228 may detect objects, such as fingers or styluses, that are within two inches or less of presence-sensitive input component 228. The presence-sensitive input component 228 may determine a location (e.g., (x, y) coordinates) of the presence-sensitive input component that detected the object. In another example range, the presence-sensitive input component 228 may detect objects two inches or less from the presence-sensitive input component 228, and other ranges are possible. The presence-sensitive input component 228 may use capacitive, inductive, and/or optical recognition techniques to determine the location of the presence-sensitive input component 228 selected by the user's finger.
In some examples, presence-sensitive display 220 may also provide output to a user using tactile, audio, or video stimuli. For example, presence-sensitive display 220 may include a display component 230 that displays a graphical user interface. Display component 230 may be any type of output component that provides visual output, such as a Liquid Crystal Display (LCD), dot matrix display, light Emitting Diode (LED) display, micro LED display, organic Light Emitting Diode (OLED) display, electronic ink, active Matrix Organic Light Emitting Diode (AMOLED) display, and the like. Although shown as an integrated component of computing device 200, in some examples presence-sensitive display 220 may be an external component that shares a data or information path with other components of computing device 200 for transmitting and/or receiving inputs and outputs.
For example, presence-sensitive display 220 may be a built-in component of computing device 200 that is located within an external package of computing device 200 and physically connected to the external package of computing device 200. In another example, presence-sensitive display 220 may be an external component of computing device 200 that is external to computing device 200 and physically separate from the packaging of computing device 200. In some examples, presence-sensitive display 220, when located outside of the packaging of computing device 200 and physically separate from the packaging of computing device 200, may be implemented by two separate components: a presence-sensitive input component 228 for receiving input and a display component 230 for providing output.
The one or more processors 222 may implement the functions and/or execute instructions associated with the computing device 200. Examples of processor 222 include an application processor, a display controller, an auxiliary processor, one or more sensor hubs, and any other hardware configured to function as a processor, a processing unit, or a processing device. The operating system 205, applications 206, application management module 207, machine learning model 216, etc. may be operable (or in other words, executed) by the processor 222 to perform various actions, operations, or functions of the computing device 200. That is, the modules 205-219 may form executable bytecodes that, when executed, cause the processor 222 to perform particular operations in accordance with various aspects of the technology described herein (e.g., to cause the computing device 200 to be a special purpose computer by which to execute). For example, the processor 222 of the computing device 200 may retrieve and execute instructions stored by the storage device 226 that cause the processor 222 to perform operations described herein as being attributed to the operating system 205, the applications 206, and the projection application 220. The instructions, when executed by the processor 222, may cause the computing device 200 to store information within the storage device 226, such as in the application update repository 215.
One or more storage devices 226 within computing device 200 may store information for processing during operation of computing device 200 (e.g., computing device 200 may store data accessed by operating system 205 during execution at computing device 200). The storage device 226 may also store data associated with the application update repository 215, the machine learning model 216, the application management module 217, the model evaluation module 218, and the model trainer 219.
In some examples, the storage device 226 is temporary storage, meaning that the primary purpose of the storage device 226 is not long-term storage. The storage device 226 on the computing device 200 may be configured to store information as volatile memory for a short period of time and, thus, not retain stored content if powered down. Examples of volatile memory include Random Access Memory (RAM), dynamic Random Access Memory (DRAM), static Random Access Memory (SRAM), and other forms of volatile memory known in the art.
In some examples, storage device 226 may also include one or more computer-readable storage media. In some examples, storage device 226 includes one or more non-transitory computer-readable storage media. The storage device 226 may be configured to store larger amounts of information than is typically stored by volatile memory. The storage device 226 may also be configured as a non-volatile memory space for long-term storage of information and retain information after power on/off cycles. Examples of non-volatile memory include magnetic hard disks, optical disks, flash memory, or forms of electrically programmable memory (EPROM) or Electrically Erasable Programmable (EEPROM) memory. Storage device 226 may store program instructions and/or information (e.g., data) associated with operating system 205, applications 206, and application management module 207.
As further shown in the example of fig. 2, the application update repository includes information about application usage 215A, installation history 215B, and context 215C. Application usage 215A may include information regarding the frequency, duration, etc. of usage of each application 206 by a user of computing device 200. Further, the application usage 215A may include such information for any device or user that downloads, installs, or otherwise interacts with the application store provided by the computing system 110 of fig. 1. For example, the information about the frequency with which the user uses each application may include the number of times the user opens the application, the number of times the user interacted with the application, the amount of time the user interacted with the application, etc., for a predetermined period of time (e.g., one day, one week, one month, etc.).
The installation history 215B may include information regarding attempts by the computing device 200 to install each application from the set of applications. For example, the information regarding the attempts by the computing device 200 may include the number of times the computing device 200 attempts to install an application update, the number of successful application update attempts, the number of unsuccessful application update attempts, the amount of time since the previous application update was installed by the computing device 200, and the like for a predetermined period of time.
The context 215C may include information about failed attempts to install an application update for each application from the set of applications. For example, information about failed attempts to install an application update may include available memory space, size of the application update, automatic application update network settings activation at the time of attempted application update installation, and so forth.
Although examples are described in which a computing device and/or computing system analyzes information associated with the computing device and a user of the computing device (e.g., application usage, device usage, installation history, etc.), the computing device and/or computing system may analyze information only when the computing device receives permission from the user of the computing device to analyze the information. For example, in the context of the following discussion, before information associated with a user may be collected or available to a computing device or computing system, the user may be provided with an opportunity to provide input to control whether programs or features of the computing device and/or computing system may collect and utilize user information (e.g., information about a user's current location, current speed, etc.), or to instruct the device and/or system whether and/or how to receive content that may be relevant to the user. In addition, certain data may be processed in one or more ways to remove personally identifiable information before such data is stored or used by a computing device and/or computing system. Thus, the user may control how information about the user is collected and used by the computing device and computing system.
In various examples, computing device 200 may communicate the update request and data associated with the application update without any interaction or activity on the user portion of computing device 200. The device user need not, for example, review the request, enter commands to the computing device 200 to install the application update, or otherwise interact with the device for installation to occur.
In some examples, computing device 200 may include model evaluation module 218. For example, computing device 200 may determine the validity of one or more machine learning models based on various metrics using model evaluation module 218. Computing device 200 may then select the most efficient one as the preferred machine learning model based on the validity of the one or more machine learning models for prioritizing future application updates.
The computing device 200 may also include a model trainer 219. That is, the model trainer 219 may train the machine learning model 216 in an offline manner or in an online manner. In offline training (also referred to as batch learning), the machine learning model 216 may be trained on the entirety of a static set of training data. In online learning, the machine learning model 216 may be continuously trained (or retrained) as new training data becomes available (e.g., as new information about application usage, installation history, and context is generated). Model trainer 219 may perform a centralized training of machine learning model 216 (e.g., based on a centrally stored dataset). In other examples, discrete training techniques such as distributed training, joint learning, or the like may be used to train, update, or personalize the machine learning model 216.
In some examples, the machine learning model 216 may be trained by optimizing an objective function, such as the validity of the machine learning model 216. The objective function may be or include a loss function that compares output data generated by the model from the training data to a label (e.g., a ground truth label) associated with the training data (e.g., determines a difference therebetween). For example, the loss function may evaluate the sum or average of the squared differences between the output data and the tag. In some examples, the objective function may be or include a cost function describing the cost of a certain result or output data. Other examples of objective functions may include boundary-based techniques such as, for example, triplet loss or maximum boundary training.
One or more of a variety of optimization techniques may be performed to optimize the objective function. For example, the optimization technique may minimize or maximize the objective function. Example optimization techniques include Hessian-based techniques and gradient-based techniques, among others. Other optimization techniques include black box optimization techniques and heuristics.
In some examples, the machine learning model 216 may be trained using backward propagation of errors in conjunction with optimization techniques (e.g., gradient-based techniques) (e.g., when the machine learning model is a multi-layer model such as an artificial neural network). For example, an iterative loop of propagation and model parameter (e.g., weight) updates may be performed to train the machine learning model 216. Example back propagation techniques include back propagation of truncated transit times, levenberg-Marquardt back propagation, and the like.
To prioritize application updates in accordance with the techniques of this disclosure, computing device 200 may execute application management module 207 (e.g., by using operating system 205, processor 222, storage device 226, etc.) to send a request for application update information for one or more applications 206 installed on computing device 100 to application update module 217. The applications 206 may include an application 206A and an application 206N, which may be, for example, a photographic application and a music application, respectively. The request for application update information may include application management information that the computing device 200 may access using the application management module 207.
The application management information may include information identifying the computing device 200 and configuration information related to the computing device 200. The application management information may also identify one or more applications installed on the computing device 200. The application management information may include, for example, a list of applications (e.g., application 206A, application 206N, etc.) installed on the computing device 200. The information identifying the installed application may include information such as a name (e.g., "photographic application," "music application," etc.) or other text-based identifier and version information for the installed application.
The application management information may also identify one or more authorized license settings associated with each installed application. The permissions settings for each installed application may control how each application interacts with other portions of computing device 200, with network 108 and computing system 110, and with other devices. The permission settings may include connectionsAnd (5) setting. The connection settings may control how the computing device 200 uses, for example, USB,WIFI or other communication methods communicate with other devices.
The connection settings may also include options for the device user to set network preferences for downloading application updates. For example, a device user may set network preferences that automatically download application updates only when computing device 200 is connected to the internet via WIFI. Network preferences for downloading application updates (e.g., based on the size of the application updates) may be set for all applications installed on computing device 200 or on an application-by-application basis. Further, the connection settings may include applying update size restrictions. For example, application updates beyond a certain size may be limited to automatically updating in the presence of a WIFI connection.
The application update module 217 may use the application management information to determine the set of applications installed on the computing device 200 that need to be updated. For example, the application update module 217 may determine that each of the photography application 206A and the music application 206N has pending application updates available. To facilitate prioritization of application updates, the application update module 217 may cause the computing device 200 to apply the machine learning model 216 to information and/or data stored in the application update repository 215 to determine an update priority score for each application from the set of applications. That is, the machine learning model 216 may use input data stored in the application update repository 215, such as application usage 215A, installation history 215B, context 215C, and the like, to provide output data in the form of updated priority scores.
By using information in the application update repository 215 (e.g., application usage 215A, installation history 215B, context 215C, etc.), the machine learning model 216 may provide an update priority score that indicates the likelihood of successful installation of an application update and the relative importance of each application from the set of applications (e.g., based on the frequency and amount of time the user uses the application). Thus, in this regard, updating the priority value may facilitate prioritization of application updates by identifying application updates that have a higher likelihood of successful installation and a relatively high importance to the user.
The machine learning model 216 may represent one or more of a variety of different types of machine learning models. In particular, in some examples, machine learning model 216 may perform regression, clustering, anomaly detection, and/or other tasks.
In some examples, the machine learning model 216 may perform regression to provide output data in the form of continuous values. The consecutive numerical values may correspond to any number of different metrics or numerical representations, including, for example, monetary values, scores, or other numerical representations. As an example, the machine learning model 216 may perform linear regression, polynomial regression, or non-linear regression. As an example, the machine learning model 216 may perform a simple regression or a multiple regression. As described above, in some examples, a Softmax function or other function or layer may be used to compact real-value sets respectively associated with two or more possible categories into real-value sets in a range (0, 1) of 1 in total.
The machine learning model 216 may perform various types of clustering. For example, the machine learning model 216 may identify one or more previously defined clusters to which the input data most likely corresponds. The machine learning model 216 may identify one or more clusters within the input data. That is, in instances where the input data includes multiple objects, documents, or other entities, the machine learning model 216 may classify the multiple entities included in the input data into multiple clusters. In some examples where the machine learning model 216 performs clustering, the machine learning model 216 may be trained using unsupervised learning techniques.
The machine learning model 216 may perform anomaly detection or outlier detection. For example, the machine learning model 216 may identify input data that does not conform to an expected pattern or other characteristic (e.g., as previously observed from previous input data). As an example, anomaly detection may be used to detect a failure to install an application update.
After applying the machine learning model 216 to determine the updated priority scores for the application set, the application update module 217 may send an indication of the updated priority scores to the application management module 207. For example, the indications of updated priority scores for the photography application 206A and the music application 206N may be 90 and 85, respectively. Computing device 200 and/or an application management module may then send an update request for at least one application from the set of applications to a computing system (e.g., computing system 110) based on the update priority scores using COMM component 224. The update request may identify an application to update, a license setting (e.g., network preferences), and so on. For example, the update request may identify the photographic application 206A as the application to be updated when the computing device 200 is connected to WIFI, because the photographic application 206A has the largest update priority score among the set of applications. In response to the update request, the computing system 110 may initiate installation of at least one application update installed on the computing device 200.
In some examples, computing device 200 may include model evaluation module 218. The computing device 200 may determine the validity of one or more machine learning models based on various metrics using the model evaluation module 218. Metrics may include, but are not limited to, an application freshness metric, an application freshness for active user metrics, an application update coverage metric, and an application update efficiency metric.
The application freshness metric may represent a percentage of computing devices of the most recent version of the application that have been installed for the first time ("fresh install") and therefore run until the date of installation that are included in the installation library of the application within a predetermined period of time. Applying the freshness metric can be evaluated using the following equation:
as used herein, fresh Apps may be defined as fresh installation of an application within a predetermined period of time. Apps may be defined as the size of the installation library of an application. Thus, appFreshness may represent the number of fresh installations of an application over a predetermined period of time divided by the number of computing devices that have installed the application.
The application freshness for the active user metrics may represent a percentage of computing devices included in an installation library of applications that have freshly installed applications within a first predetermined period of time and whose users have used applications within a second predetermined period of time (e.g., based on the number of times the user opened the application, the number of times the user interacted with the application, the amount of time the user interacted with the application, etc.). Application freshness for active user metrics can be evaluated using the following equation:
As used herein, freshly used Apps may be defined as fresh installations of applications within a first predetermined period of time that have also been used by a user of a computing device within a second predetermined period of time. The used Apps may be defined as the size of the installation library of applications including only a subset of applications that have been used within the second predetermined period of time. Thus, the AppFreshness may represent the number of freshly installed applications within a first predetermined period of time that have been used by a user of the computing device within a second predetermined period of time divided by the number of computing devices that have been running applications within the second predetermined period of time.
The application update coverage metric may represent a percentage of computing devices included in an installation library of the application that run a stale version of the application (e.g., an outdated version of the application) for a first predetermined period of time and whose users use the application for a second predetermined period of time. Applying the updated coverage metric may be evaluated using the following equation:
as used herein, an update on an fossilized use Apps may be defined as a fossilized version of an application that has also been used by a user of a computing device for a second predetermined period of time that is updated to a most recent version of the application for a first predetermined period of time. The fossilized usage Apps may be defined as the size of a subset of the installation library of applications that includes only the fossilized version of the computing device that is also used by the user of the computing device to run the application for the first predetermined period of time during the second predetermined period of time. Thus, updateCoverage may represent the number of stale versions of an application that have been updated in a first predetermined period of time that have been used by a user of a computing device in a second predetermined period of time divided by the number of computing devices that have been used by a user of a computing device in the second predetermined period of time that have run stale versions of an application in the first predetermined period of time.
The application update efficiency metric may represent a percentage of computing devices included in an installation library of the application that run a stale version of the application for a first predetermined period of time and whose users use the application after updating the application for a second predetermined period of time. Applying the update efficiency metric may be evaluated using the following equation:
as used herein, an update on a stale Apps may be defined as the size of a subset of the installation library of an application that includes only a stale version of the computing device running the updated application for a first predetermined period of time. Thus, updateEfficiency may represent the number of stale versions of an application that have been updated within a first predetermined period of time that have been used by a user of a computing device within a second predetermined period of time divided by the number of computing devices running stale versions of the updated application within the first predetermined period of time.
The data necessary to evaluate these metrics may be collected periodically, intermittently, and/or according to application management instructions (e.g., from the OS 205, the application management module 207, etc.) and using known techniques. For example, data may be aggregated, packaged and stored in storage device 226 daily for at least 35 days. The model evaluation module 218 may then use this data to determine the validity of the machine learning model 216.
In some examples, model evaluation module 218 may assign respective weights to application freshness metrics, application freshness of active user metrics, application update coverage metrics, and application update efficiency metrics. Model evaluation module 218 may then determine the validity of machine learning model 216 based on the metrics using an algorithm.
In some examples, computing device 200 may determine the validity of one or more machine learning models based on these metrics using model evaluation module 218. For example, the model evaluation module 218 may use these metrics to evaluate the validity of a set of prioritized application updates installed on the first computing device based on the respective first update priority scores for each application generated by the first machine learning model. Similarly, the computing device 200 may also determine the validity of the second machine learning model based on a set of application updates installed on the second computing device that are prioritized based on a respective second update priority score for each application generated by the second machine learning model using the model evaluation module 218. The computing device 200 may then select the more efficient one of the first machine learning model and the second machine learning model as the preferred machine learning model for prioritizing future application updates based on the validity of the first machine learning model (e.g., the output of the metric-based algorithm) and the validity of the second machine learning model.
Model trainer 219 may train machine learning model 216 using one or more metrics (e.g., application freshness metric, application freshness for active user metrics, application update coverage metric, application update efficiency metric, etc.). For example, model trainer 219 may attempt to optimize an objective function. The objective function may maximize the effectiveness of the machine learning model 216 based on the application freshness metric, the application freshness for the active user metric, the application update coverage metric, and the application update efficiency metric. As a result, the model trainer 219 may increase the effectiveness of the machine learning model 216 that outputs an update priority score indicating the likelihood of successful installation of an application update and the relative importance of the application update to the user.
Although computing device 200 of fig. 2 is illustrated as including machine learning module 216, application update module 217, model evaluation module 218, and model trainer 219, in other examples, one or more of modules 216, 217, 218, or 219 may be stored at a remote computing system (e.g., computing system 110 of fig. 1), and the functionality provided by modules 216, 217, 218, or 219 may be provided by such a remote computing system. By including one or more of modules 216, 217, 218, or 219, computing device 200 may perform the techniques of this disclosure on a device (i.e., without sending application usage information, network setup information, application installation information, application update history information, etc. to a remote computing system).
FIG. 3 is a block diagram illustrating aspects of an example machine learning model for prioritizing application updates in accordance with the techniques of this disclosure. As shown in fig. 3, the machine learning model 316, which may be similar if not substantially similar to the machine learning models 116, 216, is trained to receive one or more types of input data and, in response, to provide one or more types of output data. Thus, FIG. 3 illustrates a machine learning model 316 that performs inference. The input data may include one or more features associated with the instance or example. In some examples, one or more features associated with an instance or example may be organized into feature vectors. In some examples, the output data may include one or more predictions. Predictions may also be referred to as inferences. Thus, given features associated with a particular instance, the machine learning model 316 may output predictions for the instance based on the features.
The application update repository 315, which may be similar if not substantially similar to 115, 215, may store input data for the machine learning model 316 for access. The application update repository 315 may include application usage 315A, installation history 315B, and context 315C, which may be similar if not substantially similar to application usage 215A, installation history 215B, and context 215, respectively.
The application usage 315A may include information regarding the frequency of usage by a user of a computing device (e.g., computing device 100, 200) from each application in the application set. For example, the information about the frequency with which the user uses each application may include the number of times the user opens the application, the number of times the user interacted with the application, the amount of time the user interacted with the application, etc., for a predetermined period of time (e.g., one day, one week, one month, etc.).
The installation history 315B may include information regarding the likelihood of successful installation 340A. The likelihood of successful installation 340A may be a statistic calculated by the computing device based on the number of installation attempts, the number of successful application update installations, the number of unsuccessful application update installations, and so forth. For example, if the computing device attempts to install one or more application updates for an application (e.g., application 206A) 10 times, and 7 of these attempts succeed and 3 failed, the computing device may store a likelihood of successful installation 340A for the application of 70%.
The installation history 315B may also include information about the time since the previous application update for the application was installed. For example, the computing device may store (e.g., in seconds, minutes, hours, days, etc.) an amount of time between when the computing device last downloaded and installed a previous application update, when the computing device last checked for updates, when the computing device installed the latest version of an available application update, etc.
The context 315C can include information about the computing device memory 342A. Computing device memory 342A may include information regarding available memory of the computing device for installing one or more application updates. The computing device memory 342A may also include information regarding available storage of the computing device for installing one or more application updates.
The context 315C may also include information about the network preferences 342B. The network preferences 342B may include information regarding network connections through which the computing device may download one or more application updates (e.g., from the computing system 110, 210). The network preferences 342B for downloading application updates may be set for all applications installed on the computing device 200 or on an application-by-application basis (e.g., based on the size of the application updates). Further, the connection settings may include applying update size restrictions. For example, application updates beyond a certain size may be limited to automatically updating in the presence of a WIFI connection.
The machine learning model 316 may receive input data (e.g., application usage 315A, installation history 315B, context 315C, etc.) from the application update repository 315 to provide output data in the form of update priority scores 332. The update priority score 332 may be based on the input data and thus indicate the input data. For example, the update priority score 332 may indicate a likelihood of successfully installing an application update, an application usage history for the application (e.g., which may in turn indicate importance), and a degree of staleness of the application (e.g., an amount of time since a previous application update was installed 340B).
To determine the update priority score, the machine learning model may calculate a scoring function to formulate an expected value of freshness improvement (e.g., the difference between the update priority score of the application prior to the application update followed by the update priority score of the application update) by using the following equation:
Score(C i )＝f(P success-install (C i )，P app-open (C i )，F freshness-lift (C i ))
wherein C is i Representing candidate application updates, P success-install (C i ) Is a value representing the likelihood of an application being successfully installed being updated (e.g., between 0 and 1), where P app-open (C i ) Is a value (e.g., between 0 and 1) representing the likelihood of an application being opened and/or used (e.g., within a predetermined period of time), and F freshness-lift (C i ) Is a smoothing function applied to apply updated staleness. For example F freshness-lift (C i ) It may simply be the degree of staleness applied over several days. Alternatively, F freshness-lift (C i ) May be a barreled value calculated using known techniques.
f(P success-install (C i )，P app-open (C i )，F freshness-linft (C i ) A probability expectation value may be indicated. f (P) success-install (C i )，P app-open (C i ) To indicate how the application update will likely contribute to freshness improvement, F freshness-lift (C i ) The amount of freshness improvement can be quantified. F (F) freshness-lift May be a manually adjusted and/or designed smoothing function. Machine learning model 316 may estimate P succes-install (C i ) And P app-open (C i )。
The probabilistic expectation value may be used as a priority score for the update or may be used as a basis for generating the priority score for the update. For example, the computing system 110 may provide the computing device 100 with a probability value generated for each application with incomplete updates. In some examples, the application update module 117 may normalize, weight, or adjust the probabilistic expectations generated by the machine learning model 316 to generate the update priority score.
FIG. 4 is a block diagram illustrating exemplary operation of a machine learning model in accordance with the techniques of this disclosure. As shown in FIG. 4, an example training process 450 is used to train the machine learning model 416, which may be similar if not substantially similar to the machine learning models 116, 216, 316. The machine learning model 416 is trained on training data 451 that includes input data 452 with labels 453. Training process 450 is an example training process; other training procedures may also be used.
The training data 451 used by the training process 450 may include anonymous usage logs of shared streams when a user grants access to such data for training, e.g., content items that are shared together, bundled pieces of content that have been identified as belonging together, e.g., from entities in a knowledge graph, etc. In some examples, the training data 451 may include examples (e.g., application usage 315A, installation history 315B, context 315C, etc.) of input data 452 corresponding to output data 454 (e.g., update priority score 332) that has been assigned a tag 453 corresponding to the output data 454.
In some examples, the machine learning model 416 may be trained by optimizing an objective function, such as the objective function 455. For example, in some examples, the objective function 455 may be or include a loss function that compares (e.g., determines the difference between) the output data generated by the model to the training data and the output data associated with the training data (e.g., ground truth update priority scores). For example, the loss function may estimate the sum or average of the squared differences between the output data and the tag. In some examples, the objective function 455 may be or include a cost function describing the cost of a certain result or output data. Other examples of objective functions 455 may include boundary-based techniques such as, for example, triplet loss or maximum boundary training.
One or more of a variety of optimization techniques may be performed to optimize the objective function 455. For example, the optimization technique may minimize or maximize the objective function 455. Example optimization techniques include Hessian-based techniques and gradient-based techniques, such as, for example, coordinate descent; gradient descent (e.g., random gradient descent); a sub-gradient method; etc. Other optimization techniques include black box optimization techniques and heuristics.
In some examples, the machine learning model 416 may be trained using backward propagation of errors in conjunction with optimization techniques (e.g., gradient-based techniques) (e.g., when the machine learning model is a multi-layer model such as an artificial neural network). For example, an iterative loop of propagation and model parameter (e.g., weight) updates may be performed to train the machine learning model 416. Example back propagation techniques include back propagation of truncated transit times, levenberg-Marquardt back propagation, and the like.
In some examples, the machine learning model 416 described herein may be trained using unsupervised learning techniques to increase the effectiveness of the machine learning model 416 (e.g., based on application freshness metrics, application freshness for active user metrics, etc.). Unsupervised learning may include inferring a function describing hidden structures from unlabeled data. For example, a classification or categorization may not be included in the data. Unsupervised learning techniques may be used to generate machine learning models capable of performing clustering, anomaly detection, learning latent variable models, or other tasks.
The machine learning model 416 may be trained to increase the effectiveness of the machine learning model 416 using semi-supervised techniques that combine aspects of supervised learning and unsupervised learning. The machine learning model 416 may be trained or otherwise generated by evolutionary techniques or genetic algorithms. In some examples, the machine learning model 416 described herein may be trained using reinforcement learning. In reinforcement learning, agents (e.g., models) may take actions in the environment and learn to maximize rewards caused by such actions and/or minimize penalties caused by such actions. Reinforcement learning may be different from supervised learning problems because correct input/output pairs are not presented, nor do suboptimal actions explicitly corrected.
In some examples, the machine learning model 416 described herein may include, or be otherwise affected by, a plurality of super parameters, such as, for example, a learning rate, a number of layers, a number of nodes in each layer, a number of leaves in a tree, a number of clusters, and the like. Hyper-parameters may affect model performance. The hyper-parameters may be manually selected, or may be by techniques such as, for example, grid searching; black box optimization techniques (e.g., bayesian optimization, random search, etc.); optimizing based on gradient; etc. -are automatically selected. Example techniques and/or tools for performing automatic hyper-parametric optimization include Hyperopt; automatic WEKA; spearmint; metric Optimization Engine (MOE), etc.
In some examples, various techniques may be used to optimize and/or adapt the learning rate when training the model. Example techniques and/or tools for performing learning rate optimization or adaptation include adagard; adaptive moment estimation (ADAM); adadelta; RMSprop, etc.
In some examples, transfer learning techniques may be used to provide an initial model from which to begin training the machine learning model 416 described herein.
In some examples, the machine learning model 416 described herein may be included in different portions of computer readable code on a computing device. In one example, the machine learning model 416 may be included in and used by a particular application or program (e.g., exclusively). Thus, in one example, a computing device may include multiple applications, and one or more such applications may contain their own respective machine learning libraries and machine learning models.
In another example, the machine learning model 416 described herein may be included in an operating system of a computing device (e.g., in a central intelligent layer of the operating system) and may be invoked or otherwise used by one or more applications that interact with the operating system. In some examples, each application may communicate with the central intelligence layer (and the models stored therein) using an Application Programming Interface (API) (e.g., a public disclosure API across all applications).
In some examples, the central intelligence layer may communicate with the central device data layer. The central device data layer may be a centralized data repository for computing devices. The central device data layer may be in communication with a plurality of other components of the computing device, such as, for example, one or more sensors, a context manager, a device status component, and/or additional components. In some examples, the central device data layer may communicate with each device component using an API (e.g., a dedicated API).
To train the machine learning model 416 in accordance with the techniques of this disclosure, a model trainer (e.g., model trainer 219) may use training data 451, which training data 451 includes the following input data 452 that has been assigned a label 453 corresponding to output data 454. In some examples, machine learning model 416 may independently determine a respective update priority score for each application update. Thus, using this method (e.g., f (P) success-install (C i )，P app-open (C i )，F freshness-linft (C i ) A) the determined order of update priority scores may rank the application updates in a relative order. In another example, the machine learning model 316 may determine a relative order between a pair of application updates. In this example, machine learning model 316 may use a scoring function similar to that described above, but apply it to ground truth values (e.g., binary values) to label both The desired order of updating is applied. That is, the machine learning model 316 may use the following equation:
Score(C i )＝f(is_success_install(C i )，is_app_open(C i )，F freshness-lift (C i ))
further, the sequence tags may be defined using the following algorithm:
label order (C i ，C j )＝Score(C i )＞Score(C j )
FIG. 5 is a flowchart illustrating exemplary operations of a computing system and computing device in accordance with the techniques of this disclosure. In the example of fig. 5, computing device 100 and computing system 110 may operate to prioritize the installation of updates to a set of applications installed on computing device 100 by identifying application updates that have a higher likelihood of being successfully installed while also prioritizing the updates to the most frequently used applications by the user. The computing device 100 and the computing system 110 may then apply the machine learning model 116 to determine an update priority score for the set of application updates, which the computing device 100 may use to prioritize (e.g., rank) the application updates.
As shown in fig. 5, the application update module 117 of the computing system 110 may receive a request from the computing device 100 for application update information for one or more applications 106 installed on the computing device (500). Computing device 100 may execute application management module 107 to send a request for application update information to application update module 117 (e.g., by using COMM component 124). The applications 106 may include an application 106A and an application 106N, which may be, for example, a photographic application and a music application, respectively. The request for application update information may include application management information that the computing device 210 may access using the application management module 107.
The computing system 110 may determine a set of applications that need to be updated based on the request for application update information (502). For example, the application update module 117 may perform a lookup in the application update repository 115 to determine which applications, if any, identified in the application update information have incomplete updates. The application update module 117 may execute queries to retrieve current version information for one or more of these applications. The application update module may compare the retrieved current version information with the currently installed versions of the photography application 106A, the music application 106N, and the social networking application. Based on the version information comparison, the application update module 117 may determine that one or more applications have incomplete updates and include those applications in the application set.
The computing system may apply the machine learning model 116 to determine a respective update priority score (e.g., update priority score 332) for each application from the set of applications (504). The machine learning model 116 may determine a corresponding update priority score based on input data stored in the application update repository. For example, the machine learning model 116 may use input data (e.g., application usage 215A, installation history 215B, context 215C, etc.) stored in the application update repository 115 to provide output data in the form of updated priority scores. The updated priority score for each application may indicate the importance of the application to the user of computing device 100 (e.g., based on application usage 215A, installation history 215B, context 215C, etc.).
Computing system 110 may send an indication of the corresponding updated priority scores for the application set to computing device 100 (506). The update priority score may indicate the likelihood of successful installation of the application update and the relative importance of each application from the application set (e.g., based on the frequency and amount of time the application was used by the user). Thus, in this regard, updating the priority value may facilitate prioritization of application updates by identifying application updates that have a higher likelihood of successful installation, a relatively higher importance to the user, and a greater amount of freshness improvement.
Computing system 110 may receive an update request from computing device 100 for at least one application from the set of applications (508). The computing device 100 may send the update request in response to and based on the corresponding update priority score. At least one application from the set of applications may be selected by the computing device 100 based on the respective updated priority scores (e.g., ranks). The computing system 110, in response to receiving the update request, may then initiate installation of a pending update from at least one application in the set of applications (510).
FIG. 6 is a flowchart illustrating another exemplary operation of a computing system and computing device in accordance with the techniques of this disclosure. In the example of fig. 6, the computing system 110 may determine the validity of the one or more machine learning models 116 to select the most valid one as the preferred machine learning model for prioritizing future application updates based on the validity of the one or more machine learning models. However, it should be appreciated that computing device 100 may also determine the validity of one or more machine learning models in accordance with the techniques of this disclosure.
As shown in fig. 6, computing system 110 may determine the validity of the first machine learning model based on a set of application updates installed on the first computing device, the application updates prioritized based on a respective first update priority score for each application score generated by the first machine learning model (600). The computing system 100 may determine the validity of the first machine learning model based on an application freshness metric, an application freshness for an active user metric, an application update coverage metric, an application update efficiency metric, and the like. For example, the model evaluation module 118 may use metrics to evaluate the validity of a set of application updates installed on the first computing device, the application updates prioritized based on a respective first update priority score for each application generated by the first machine learning model.
The computing system 110 may also determine validity of the second machine learning model based on a set of application updates installed on the second computing device, the application updates prioritized based on respective second update priority scores for each application generated by the second machine learning model (602). Similarly, computing system 110 may determine the validity of the second machine learning model based on an application freshness metric, an application freshness for an active user metric, an application update coverage metric, an application update efficiency metric, and the like.
The computing system 110 may select a more efficient one of the first machine learning model and the second machine learning model as a preferred machine learning model for prioritizing future application updates based on the validity of the first machine learning model and the validity of the second machine learning model (604). For example, computing system 110 may select a machine learning model that performs better (e.g., has a higher score) for application freshness metrics, application freshness for active user metrics, application update coverage metrics, application update efficiency metrics, and so forth.
Further, the computing system 110 may use the selected machine learning model as a preferred machine learning model for prioritizing future application updates (606). For example, the computing system 110 may receive a subsequent request for application update information for one or more applications installed on the first computing device. The computing system 110 may determine a set of subsequent applications that need to be updated based on subsequent requests for application update information, where each application from the set of subsequent applications is associated with a respective subsequent pending update. The computing system 110 may apply a preferred machine learning model to determine a respective subsequent updated priority score for each application from the set of subsequent applications and send an indication of the respective subsequent updated priority score for the set of subsequent applications to the first computing device. The computing device 100 may then send at least one subsequent update request to the computing system based on the corresponding subsequent update priority scores.
In this manner, the computing system 110 may receive at least one subsequent update request for at least one application from a subsequent set of applications, the at least one application from the subsequent set of applications selected by the first computing device based at least in part on the respective subsequent update priority scores (608). The computing system 100, in response to receiving the subsequent update request, may initiate installation of a subsequent pending update from at least one application in the subsequent set of applications.
Fig. 7 is a flowchart illustrating exemplary operation of a computing device in accordance with the techniques of this disclosure. In the example of fig. 7, computing device 100 implements the machine learning model locally and performs one or more other tasks that might otherwise be performed by computing system 110. The computing device 100 may operate to prioritize the installation of updates to a set of applications installed on the computing device by identifying application updates that have a higher likelihood of being successfully installed while also prioritizing the updates to the applications most frequently used by the user. The computing device 100 may then apply the machine learning model 116 to determine an update priority score for the set of application updates, which the computing device 100 may use to prioritize the application updates.
As shown in fig. 7, computing device 100 may send a request to computing system 110 for application update information for one or more applications installed on the computing device (700). For example, the computing device 100 may use the application management module 107 to generate application management information identifying the applications 106 installed on the computing device 100. In various examples, the application management module 107 may be a client application associated with an application repository or application store managed and/or provided by the computing system 110. That is, the computing device 100 may execute the application management module 107 to present an online application store graphical user interface (e.g., GUI 104) via the presence-sensitive display 120 for the online application store. The application store may be hosted or otherwise provided by computing system 110 and may enable a user of computing device 100 to browse, search, select, purchase, download, and install various applications and application updates on computing device 100.
The computing device 100 may receive an indication of a respective update priority score from the computing system 110 for each application from the set of applications having a respective pending update (702). The computing system 110 may determine each respective update priority score by applying at least a machine learning model to each application of the set of applications having a respective pending update. For example, the computing system may apply the machine learning model 116 to determine a respective update priority score (e.g., update priority score 332) for each application from the set of applications. The machine learning model 116 may determine a corresponding update priority score based on input data stored in the application update repository. For example, the machine learning model 116 may use input data (e.g., application usage 215A, installation history 215B, context 215C, etc.) stored in the application update repository 115 to provide output data in the form of updated priority scores.
The computing device 100 may select at least one corresponding pending update to request from the computing system 110 based on the priority ranking of the respective updates (704). For example, if the application 106A has a maximum update priority score, the computing device 100 may select a pending update for the application 106A that indicates that the application is first in the order of the update priority scores and that the corresponding application update is the most important application update available.
The computing device 100 may send 706 an update request for the at least one corresponding pending update to the computing system 110. For example, computing device 100 may generate an update request for one or more applications (e.g., 106A) in the set of applications that have pending updates, and send the update request (e.g., by using COMM component 124). The computing device 100 may then install at least one corresponding pending update in response to the computing system 110 initiating the installation, the at least one corresponding pending update being installed by the computing device (708).
The present disclosure includes the following examples.
Example 1: a method, comprising: receiving, by the computing system and from the computing device, a request for application update information for one or more applications installed on the computing device; determining, by the computing system and based on the request for application update information, a set of applications that need to be updated, wherein each application from the set of applications is associated with a respective pending update; applying, by the computing system, a machine learning model to determine a respective updated priority score for each application from the set of applications; transmitting, from the computing system to the computing device, an indication of the respective updated priority scores for the application set; receiving, by the computing system and from the computing device, an update request for at least one application from the set of applications, the at least one application from the set of applications selected by the computing device based on the respective update priority scores; and in response to receiving the update request, initiate, by the computing system, installation of a pending update for at least one application from the set of applications.
Example 2: the method of example 1, wherein the computing device is a first computing device, wherein the machine learning model is a first machine learning model, and wherein the update priority score is a first update priority score, the method further comprising: determining, by the computing system, validity of the first machine learning model based on a set of application updates installed on the first computing device, the application updates prioritized based on respective first update priority scores for each application generated by the first machine learning model; determining, by the computing system, validity of the second machine learning model based on a set of application updates installed on the second computing device, the application updates prioritized based on respective second update priority scores for each application generated by the second machine learning model; and selecting, by the computing system and based on the validity of the first machine learning model and the validity of the second machine learning model, a more valid one of the first machine learning model and the second machine learning model as a preferred machine learning model for prioritizing future application updates.
Example 3: the method of example 2, further comprising: receiving, by the computing system, a subsequent request for application update information for one or more applications installed on the first computing device; determining, by the computing system and based on a subsequent request for application update information, a set of subsequent applications that need to be updated, wherein each application from the set of subsequent applications is associated with a respective subsequent pending update; applying, by the computing system, a preferred machine learning model to determine a respective subsequent updated priority score for each application from the set of subsequent applications; transmitting, from the computing system to the first computing device, an indication of a respective subsequent update priority score for the set of subsequent applications; receiving, by the computing system and from the first computing device, a subsequent update request for at least one application from a subsequent set of applications, the at least one application from the subsequent set of applications selected by the first computing device based at least in part on the respective subsequent update priority scores; and in response to receiving the subsequent update request, initiate, by the computing system, installation of a subsequent pending update for at least one application from the subsequent set of applications.
Example 4: the method of example 2 or 3, wherein determining the validity of the first machine learning model is further based on one or more of: an application freshness metric, an application freshness for an active user metric, an application update coverage metric, and an application update efficiency metric.
Example 5: the method of any of examples 1-4, wherein the machine learning model determines a respective updated priority score for each application from the set of applications based at least in part on one or more of: one or more of the available memory of the computing device, a usage history of each application from the set of applications, a network preference for installing the update, an amount of time since a previous update of at least one application from the set of applications was last installed, a corresponding likelihood of successful installation of the update for each application, and an amount of time since the previous update of each application for the at least one application was last installed.
Example 6: the method of any of examples 1-5, wherein the machine learning model determines the respective update priority scores for each application by multiplying a probability that a pending update for the application is being installed by a probability that the application opens within a predetermined period of time.
Example 7: the method of example 6, wherein the machine learning model determines a respective update priority score for each application by also applying a smoothing function.
Example 8: the method of any of examples 1-7, wherein the machine learning model independently determines a respective update priority score for each application.
Example 9: the method of any of examples 1-8, wherein the machine learning model determines respective updated priority scores for the first application relative to the second application.
Example 10: a computing system comprising: a memory; and one or more processors configured to: receiving, from a computing device, a request for application update information for one or more applications installed on the computing device; determining a set of applications that need to be updated based on the request for application update information, wherein each application from the set of applications is associated with a respective pending update; applying a machine learning model to determine a respective updated priority score for each application from the set of applications; sending, to the computing device, an indication of the respective updated priority scores for the application set; receiving, from the computing device, an update request for at least one application from the set of applications, the at least one application from the set of applications selected by the computing device based on the respective update priority scores; and in response to receiving the update request, initiate installation of a pending update for at least one application from the set of applications.
Example 11: the computing system of example 10, wherein the computing device is a first computing device, wherein the machine learning model is a first machine learning model, and wherein the update priority score is a first update priority score, wherein the one or more processors are further configured to: determining validity of the first machine learning model based on a set of application updates installed on the first computing device, the application updates prioritized based on respective first update priority scores for each application generated by the first machine learning model; determining validity of the second machine learning model based on a set of application updates installed on the second computing device, the application updates prioritized based on respective second update priority scores for each application generated by the second machine learning model; and selecting a more efficient one of the first machine learning model and the second machine learning model as a preferred machine learning model for prioritizing future application updates based on the validity of the first machine learning model and the validity of the second machine learning model.
Example 12: the computing system of example 11, wherein the one or more processors are further configured to: after selecting the preferred machine learning model: receiving a subsequent request for application update information for one or more applications installed on the first computing device; determining a subsequent set of applications requiring an update based on a subsequent request for application update information, wherein each application from the subsequent set of applications is associated with a respective subsequent pending update; applying a preferred machine learning model to determine a respective subsequent updated priority score for each application from the set of subsequent applications; sending, to the first computing device, an indication of respective subsequent updated priority scores for the set of subsequent applications; receiving, from the first computing device, a subsequent update request for at least one application from a subsequent set of applications, the at least one application from the subsequent set of applications selected by the first computing device based at least in part on the respective subsequent update priority scores; and in response to receiving the subsequent update request, initiate installation of a subsequent pending update for at least one application from the subsequent set of applications.
Example 13: the computing system of example 11 or 12, wherein the one or more processors are configured to determine validity of the first machine learning model based further on one or more of: an application freshness metric, an application freshness for an active user metric, an application update coverage metric, and an application update efficiency metric.
Example 14: the computing system of any of examples 10 to 13, wherein the machine learning model determines a respective updated priority score for each application from the set of applications based at least in part on one or more of: one or more of the available memory of the computing device, a usage history of each application from the set of applications, a network preference for installing the update, an amount of time since a previous update of at least one application from the set of applications was last installed, a corresponding likelihood of successful installation of the update for each application, and an amount of time since the previous update of each application for the at least one application was last installed.
Example 15: the computing system of any of examples 10 to 14, wherein the machine learning model determines the respective update priority scores for each application by multiplying a probability that a pending update for the application is being installed by a probability that the application opens within a predetermined period of time.
Example 16: the computing system of example 15, wherein the machine learning model determines a respective update priority score for each application by also applying a smoothing function.
Example 17: the computing system of any of examples 10 to 16, wherein the machine learning model independently determines a respective update priority score for each application.
Example 18: the computing system of any of examples 10 to 17, wherein the machine learning model determines respective updated priority scores for the first application relative to the second application.
Example 19: a non-transitory computer-readable storage medium encoded with instructions that, when executed by one or more processors of a computing system, cause the one or more processors to: receiving, from a computing device, a request for application update information for one or more applications installed on the computing device; determining a set of applications that need to be updated based on the request for application update information, wherein each application from the set of applications is associated with a respective pending update; applying a machine learning model to determine a respective updated priority score for each application from the set of applications; sending, to the computing device, an indication of the respective updated priority scores for the application set; receiving, from the computing device, an update request for at least one application from the set of applications, the at least one application from the set of applications selected by the computing device based on the respective update priority scores; and in response to receiving the update request, initiate installation of a pending update for at least one application from the set of applications.
Example 20: the non-transitory computer-readable storage medium of example 19, wherein the computing device is a first computing device, wherein the machine learning model is a first machine learning model, and wherein the update priority score is a first update priority score, wherein the instructions further cause the one or more processors to: determining validity of the first machine learning model based on a set of application updates installed on the first computing device, the application updates prioritized based on respective first update priority scores for each application generated by the first machine learning model; determining validity of the second machine learning model based on a set of application updates installed on the second computing device, the application updates prioritized based on respective second update priority scores for each application generated by the second machine learning model; and selecting a more efficient one of the first machine learning model and the second machine learning model as a preferred machine learning model for prioritizing future application updates based on the validity of the first machine learning model and the validity of the second machine learning model.
Example 21: the non-transitory computer-readable storage medium of example 20, wherein the instructions further cause the one or more processors to, after selecting the preferred machine learning model: receiving a subsequent request for application update information for one or more applications installed on the first computing device; determining a subsequent set of applications requiring an update based on a subsequent request for application update information, wherein each application from the subsequent set of applications is associated with a respective subsequent pending update; applying a preferred machine learning model to determine a respective subsequent updated priority score for each application from the set of subsequent applications; sending, to the first computing device, an indication of respective subsequent updated priority scores for the set of subsequent applications; receiving, from the first computing device, a subsequent update request for at least one application from a subsequent set of applications, the at least one application from the subsequent set of applications selected by the first computing device based at least in part on the respective subsequent update priority scores; and in response to receiving the subsequent update request, initiate installation of a subsequent pending update for at least one application from the subsequent set of applications.
Example 22: the computing system of example 20 or 21, wherein the instructions further cause the one or more processors to determine validity of the first machine learning model based further on one or more of: an application freshness metric, an application freshness for an active user metric, an application update coverage metric, and an application update efficiency metric.
Example 23: the non-transitory computer-readable storage medium of any one of examples 19 to 22, wherein the instructions cause the machine learning model to be applied in accordance with the one or more processors to determine a respective updated priority score for each application from the set of applications based at least in part on one or more of: one or more of the available memory of the computing device, a usage history of each application from the set of applications, a network preference for installing the update, an amount of time since a previous update of at least one application from the set of applications was last installed, a corresponding likelihood of successful installation of the update for each application, and an amount of time since the previous update of each application for the at least one application was last installed.
Example 24: the non-transitory computer-readable storage medium of any of examples 19 to wherein the instructions cause the one or more processors to apply a machine learning model to determine a respective update priority score for each application by multiplying a probability that a pending update for the application is being installed by a probability that the application is open for a predetermined period of time.
Example 25: a computing system comprising means for performing any combination of the methods of examples 1-9.
Example 26: a method, comprising: transmitting, by the computing device to the computing system, a request for application update information for one or more applications installed on the computing device; receiving, by the computing device and from the computing system, an indication of a respective update priority score for each application from the set of applications having a corresponding pending update, wherein each respective update priority score is determined by the computing system by applying at least a machine learning model to each application of the set of applications having a corresponding pending update; selecting, by the computing device and based on the respective update priority scores, at least one corresponding pending update to be requested from the computing system; transmitting, by the computing device, an update request to the computing system for at least one corresponding pending update; and installing, by the computing device, the at least one corresponding pending update in response to receiving, by the computing device, the at least one corresponding pending update from the computing system.
Example 27: the method of example 26, wherein the request for application update information includes one or more of: information identifying the computing device, configuration information related to the computing device, a name of each application installed on the computing device, version information for each application, or network preferences for each application.
Example 28: the method of example 26 or 27, further comprising: a graphical user interface is output by the computing device, the graphical user interface including an indication of one or more applications from a set of one or more applications having corresponding pending updates and a respective update priority score for each of the one or more applications.
Example 29: the method of example 28, further comprising receiving, by the computing device, a selection of an application from one or more applications included in the graphical user interface as the selected application, wherein selecting at least one corresponding pending update comprises selecting a corresponding pending update associated with the selected application.
Example 30: the method of any of examples 26 to 29, wherein selecting at least one corresponding pending update comprises: determining a maximum update priority ranking from the respective update priority ranks; and selecting, from the computing system, a corresponding pending update of the application associated with the greatest update prioritization as at least one corresponding pending update to be requested.
Example 28: an apparatus comprising means for any combination of the methods of examples 26-30.
Example 29: a computer-readable storage medium encoded with instructions that, when executed by one or more processors of a computing system, cause the one or more processors to perform any combination of the methods of examples 26-30.
Example 30: a method, comprising: determining, by the computing system, validity of the first machine learning model based on a set of application updates installed on the first computing device, the application updates prioritized based on respective first update priority scores for each application generated by the first machine learning model; determining, by the computing system, validity of the second machine learning model based on a set of application updates installed on the second computing device, the application updates prioritized based on respective second update priority scores for each application generated by the second machine learning model; and selecting, by the computing system and based on the validity of the first machine learning model and the validity of the second machine learning model, a more valid one of the first machine learning model and the second machine learning model as a preferred machine learning model for prioritizing future application updates.
Example 31: the method of example 30, further comprising: receiving, by the computing system, a subsequent request for application update information for one or more applications installed on the first computing device; determining, by the computing system and based on a subsequent request for application update information, a subsequent set of applications that need to be updated, wherein each application from the subsequent set of applications is associated with a respective subsequent pending update; applying, by the computing system, a preferred machine learning model to determine a respective subsequent updated priority score for each application from the set of subsequent applications; transmitting, from the computing system to the first computing device, an indication of a respective subsequent update priority score for the set of subsequent applications; receiving, by the computing system and from the first computing device, a subsequent update request for at least one application from a subsequent set of applications, the at least one application from the subsequent set of applications selected by the first computing device based at least in part on the respective subsequent update priority scores; and in response to receiving the subsequent update request, initiate, by the computing system, installation of a subsequent pending update from at least one application in the subsequent set of applications.
Example 32: the method of example 31, wherein determining the validity of the first machine learning model is further based on one or more of: an application freshness metric, an application freshness for an active user metric, an application update coverage metric, and an application update efficiency metric.
Example 33: the method of example 32, wherein the application freshness metric represents a set of computing devices included in an installation library of the application, wherein a user of the set of computing devices installs the application for a first time within a predetermined period of time.
Example 34: the method of example 32 or 33, wherein the application freshness for the active user metrics represents a set of computing devices included in an installation library of the application, wherein a user of the set of computing devices installs the application for a first time within a first predetermined period of time and uses the application for a second predetermined period of time.
Example 35: the method of any of examples 32 to 34, wherein the application update coverage metric represents a set of computing devices included in an installation library of the application, wherein a user of the set of computing devices has not installed a most recent update for the application within a first predetermined period of time and has used the application within a second predetermined period of time.
Example 36: the method of any of examples 32 to 35, wherein the application update efficiency metric represents a set of computing devices included in an installation library of the application, wherein a user of the set of computing devices has not installed a most recent update of the application within a first predetermined period of time and has used the application after installing the update for the application within a second predetermined period of time.
Example 37: a computing device comprising: a memory storing one or more modules; and one or more processors executing one or more modules to: determining validity of the first machine learning model based on a set of application updates installed on the first computing device, the application updates prioritized based on respective first update priority scores for each application generated by the first machine learning model; determining validity of the second machine learning model based on a set of application updates installed on the second computing device, the application updates prioritized based on respective second update priority scores for each application generated by the second machine learning model; and selecting a more efficient one of the first machine learning model and the second machine learning model as a preferred machine learning model for prioritizing future application updates based on the validity of the first machine learning model and the validity of the second machine learning model.
Example 38: the computing device of example 37, wherein the one or more processors are further configured to execute the one or more modules after selecting the preferred machine learning model to: receiving a subsequent request for application update information for one or more applications installed on the first computing device; determining a subsequent set of applications requiring an update based on a subsequent request for application update information, wherein each application from the subsequent set of applications is associated with a respective subsequent pending update; applying a preferred machine learning model to determine a respective subsequent updated priority score for each application from the set of subsequent applications; sending, to the first computing device, an indication of respective subsequent updated priority scores for the set of subsequent applications; receiving, from the first computing device, a subsequent update request for at least one application from a subsequent set of applications, the at least one application from the subsequent set of applications selected by the first computing device based at least in part on the respective subsequent update priority scores; and in response to receiving the subsequent update request, initiate installation of a subsequent pending update from at least one application in the subsequent set of applications.
Example 39: the computing device of example 38, wherein the one or more processors execute the one or more modules to determine validity of the first machine learning model based further on one or more of: an application freshness metric, an application freshness for an active user metric, an application update coverage metric, and an application update efficiency metric.
Example 40: the computing device of example 39, wherein the application freshness metric represents a set of computing devices included in an installation library of the application, wherein a user of the set of computing devices installs the application for a first time within a predetermined period of time.
Example 41: the computing device of example 39 or 40, wherein the application freshness for the active user metrics represents a set of computing devices included in an installation library of the application, wherein a user of the set of computing devices installs the application for a first time within a first predetermined period of time and uses the application for a second predetermined period of time.
Example 42: the computing device of any of examples 39-41, wherein the application update coverage metric represents a set of computing devices included in an installation library of the application, wherein a user of the set of computing devices has not installed a most recent update for the application for a first predetermined period of time and has used the application for a second predetermined period of time.
Example 43: the computing device of any of examples 39-42, wherein the application update efficiency metric represents a set of computing devices included in an installation library of the application, wherein a user of the set of computing devices has not installed a most recent update of the application within a first predetermined period of time and has used the application after having installed an update for the application within a second predetermined period of time.
Example 44: a non-transitory computer-readable storage medium encoded with instructions that, when executed by one or more processors of a computing system, cause the one or more processors to: determining validity of the first machine learning model based on a set of application updates installed on the first computing device, the application updates prioritized based on respective first update priority scores for each application generated by the first machine learning model; determining validity of the second machine learning model based on a set of application updates installed on the second computing device, the application updates prioritized based on respective second update priority scores for each application generated by the second machine learning model; and selecting a more efficient one of the first machine learning model and the second machine learning model as a preferred machine learning model for prioritizing future application updates based on the validity of the first machine learning model and the validity of the second machine learning model.
Example 45: the non-transitory computer-readable storage medium of example 44, wherein the one or more processors further execute the instructions to, after selecting the preferred machine learning model: receiving a subsequent request for application update information for one or more applications installed on the first computing device; determining a subsequent set of applications requiring an update based on a subsequent request for application update information, wherein each application from the subsequent set of applications is associated with a respective subsequent pending update; applying a preferred machine learning model to determine a respective subsequent updated priority score for each application from the set of subsequent applications; sending, to the first computing device, an indication of respective subsequent updated priority scores for the set of subsequent applications; receiving, from the first computing device, a subsequent update request for at least one application from a subsequent set of applications, the at least one application from the subsequent set of applications selected by the first computing device based at least in part on the respective subsequent update priority scores; and in response to receiving the subsequent update request, initiate installation of a subsequent pending update from at least one application in the subsequent set of applications.
Example 46: the non-transitory computer-readable storage medium of example 45, wherein the one or more processors execute the one or more modules to determine validity of the first machine learning model further based on one or more of: an application freshness metric, an application freshness for an active user metric, an application update coverage metric, and an application update efficiency metric.
Example 47: the non-transitory computer-readable storage medium of example 46, wherein the application freshness metric represents a set of computing devices included in an installation library of the application, wherein a user of the set of computing devices installs the application for a first time within a predetermined period of time.
Example 48: the non-transitory computer-readable storage medium of example 46 or 47, wherein the application freshness for the active user metrics represents a set of computing devices included in an installation library of the application, wherein a user of the set of computing devices installs the application for a first time within a first predetermined time period and uses the application for a second predetermined time period.
Example 49: the non-transitory computer-readable storage medium of any of examples 46-48, wherein the application update coverage metric represents a set of computing devices included in an installation library of the application, wherein a user of the set of computing devices has not installed a most recent update for the application for a first predetermined period of time and has used the application for a second predetermined period of time.
Example 50: the non-transitory computer-readable storage medium of any of examples 46-49, wherein the application update efficiency metric represents a set of computing devices included in an installation library of the application, wherein a user of the set of computing devices has not installed a most recent update of the application within a first predetermined period of time and has used the application after having installed the update for the application within a second predetermined period of time.
Example 51: a computing system comprising means for performing any combination of the methods of examples 30-36.
By way of example, and not limitation, such computer-readable storage media can comprise RAM, ROM, EEPROM, CD-ROM or other optical disk storage, magnetic disk storage, or other magnetic storage devices, flash memory, or any other storage medium that can be used to store desired program code in the form of instructions or data structures and that can be accessed by a computer. Also, any connection is properly termed a computer-readable medium. For example, if the instructions are transmitted from a website, server, or other remote source using a coaxial cable, fiber optic cable, twisted pair, digital Subscriber Line (DSL), or wireless technologies such as infrared, radio, and microwave, then the coaxial cable, fiber optic cable, twisted pair, DSL, or wireless technologies such as infrared, radio, and microwave are included in the definition of medium. It should be understood, however, that computer-readable storage media and media, as well as data storage media, do not include connections, carrier waves, signals, or other transitory media, but are instead directed to non-transitory, tangible storage media. Disk and disc, as used herein, includes Compact Disc (CD), laser disc, optical disc, digital Versatile Disc (DVD), floppy disk and blu-ray disc where disks usually reproduce data magnetically, while discs reproduce data with lasers. Combinations of the above should also be included within the scope of computer-readable media.
The instructions may be executed by one or more processors, such as one or more Digital Signal Processors (DSPs), general purpose microprocessors, application Specific Integrated Circuits (ASICs), field programmable logic arrays (FPGAs), or other equivalent integrated or discrete logic circuitry. Thus, the term "processor" as used herein may refer to any of the foregoing structure or any other structure suitable for implementation of the techniques described herein. Furthermore, in some aspects, the functionality described herein may be provided within dedicated hardware and/or software modules. Moreover, these techniques may be fully implemented in one or more circuits or logic elements.
The techniques of this disclosure may be implemented in various devices or apparatuses including a wireless handset, an Integrated Circuit (IC), or a group of ICs (e.g., a chipset). Various components, modules, or units are described in this disclosure to emphasize functional aspects of devices configured to perform the disclosed techniques but do not necessarily require realization by different hardware units. Rather, as noted above, the various units may be combined in hardware units with appropriate software and/or firmware or provided by a collection of interoperable hardware units including one or more processors as noted above.
Various examples have been described. These and other examples are within the scope of the following claims.
Claims (24)
1. A method, comprising:
receiving, by a computing system and from a computing device, a request for application update information for one or more applications installed on the computing device;
determining, by the computing system and based on the request for the application update information, a set of applications that need to be updated, wherein each application from the set of applications is associated with a respective pending update;
applying, by the computing system, a machine learning model to determine a respective updated priority score for each application from the set of applications;
sending, from the computing system to the computing device, an indication of the respective updated priority scores for the set of applications;
receiving, by the computing system and from the computing device, an update request for at least one application from the set of applications, the at least one application from the set of applications selected by the computing device based on the respective update priority scores; and
in response to receiving the update request, an installation of the pending update for the at least one application from the set of applications is initiated by the computing system.
2. The method of claim 1, wherein the computing device is a first computing device, wherein the machine learning model is a first machine learning model, and wherein the update priority score is a first update priority score, the method further comprising:
determining, by the computing system, validity of the first machine learning model based on a set of application updates installed on the first computing device, the application updates installed on the first computing device prioritized based on a respective first update priority score for each application generated by the first machine learning model;
determining, by the computing system, validity of a second machine learning model based on a set of application updates installed on a second computing device, the application updates installed on the second computing device prioritized based on a respective second update priority score for each application generated by the second machine learning model; and
a more efficient one of the first machine learning model and the second machine learning model is selected by the computing system and based on the validity of the first machine learning model and the validity of the second machine learning model as a preferred machine learning model for prioritizing future application updates.
3. The method of claim 2, further comprising, after selecting the preferred machine learning model:
receiving, by the computing system, a subsequent request for application update information for the one or more applications installed on the first computing device;
determining, by the computing system and based on the subsequent request for the application update information, a set of subsequent applications that need to be updated, wherein each application from the set of subsequent applications is associated with a respective subsequent pending update;
applying, by the computing system, the preferred machine learning model to determine a respective subsequent updated priority score for each application from the set of subsequent applications;
sending, from the computing system and to the first computing device, an indication of respective subsequent update priority scores for the set of subsequent applications;
receiving, by the computing system and from the first computing device, a subsequent update request for at least one application from the subsequent set of applications, the at least one application from the subsequent set of applications selected by the first computing device based at least in part on the respective subsequent update priority scores; and
In response to receiving the subsequent update request, an installation of the subsequent pending update for the at least one application from the subsequent application set is initiated by the computing system.
4. A method according to claim 2 or 3, wherein determining the validity of the first machine learning model is further based on one or more of: an application freshness metric, an application freshness for an active user metric, an application update coverage metric, and an application update efficiency metric.
5. The method of any of claims 1-4, wherein the machine learning model determines the respective updated priority score for each application from the set of applications based at least in part on one or more of:
one or more of the available memory of the computing device,
a history of use of each application from the set of applications,
for installing the updated network preferences,
the amount of time since the last installation of the previous update of the at least one application from the set of applications,
a corresponding likelihood of successful installation of updates for each application, and
the amount of time since the last installation of the previous update for each of the at least one application.
6. The method of any of claims 1-5, wherein the machine learning model determines the respective update priority scores for each application by multiplying a probability that the pending update for that application is being installed by a probability that the application opens within a predetermined period of time.
7. A computing system comprising means for performing any combination of the methods of claims 1-6.
8. A computer-readable storage medium encoded with instructions that, when executed by one or more processors of a computing system, cause the one or more processors to perform any combination of the methods of claims 1-6.
9. A method, comprising:
transmitting, by a computing device and to a computing system, a request for application update information for one or more applications installed on the computing device;
receiving, by the computing device and from the computing system, an indication of a respective update priority score for each application from a set of applications having a corresponding pending update, wherein each respective update priority score is determined by the computing system by applying at least a machine learning model to each application of the set of applications having the corresponding pending update;
Selecting, by the computing device and based on the respective update priority scores, at least one corresponding pending update to be requested from the computing system;
sending, by the computing device and to the computing system, an update request for the at least one corresponding pending update; and
the at least one corresponding pending update is installed by the computing device in response to receiving the at least one corresponding pending update by the computing device and from the computing system.
10. The method of claim 9, wherein the request for application update information comprises one or more of: information identifying the computing device, configuration information related to the computing device, a name of each application installed on the computing device, version information for each application, or network preferences for each application.
11. The method of claim 9 or 10, further comprising:
a graphical user interface is output by the computing device, the graphical user interface including an indication of one or more applications from a set of one or more applications having corresponding pending updates and the respective update priority scores for each of the one or more applications.
12. The method of claim 11, further comprising:
receiving by the computing device a selection of an application from the one or more applications included in the graphical user interface as the selected application,
wherein selecting the at least one corresponding pending update comprises selecting a corresponding pending update associated with the selected application.
13. The method of any of claims 9 to 12, wherein selecting the at least one corresponding pending update comprises:
determining a maximum update priority ranking from the respective update priority ranks; and
a corresponding pending update of the application associated with the maximum update prioritization is selected as the at least one corresponding pending update to be requested from the computing system.
14. An apparatus comprising means for performing any combination of the methods of claims 9-13.
15. A computer-readable storage medium encoded with instructions that, when executed by one or more processors of a computing device, cause the one or more processors to perform any combination of the methods of claims 9-13.
16. A method, comprising:
determining, by a computing system, validity of a first machine learning model based on a set of application updates installed on a first computing device, the application updates installed on the first computing device prioritized based on a respective first update priority score for each application generated by the first machine learning model;
Determining, by the computing system, validity of a second machine learning model based on a set of application updates installed on a second computing device, the application updates installed on the second computing device prioritized based on respective second update priority scores for each application generated by the second machine learning model; and
selecting, by the computing system and based on the validity of the first machine learning model and the validity of the second machine learning model, a more valid one of the first machine learning model and the second machine learning model as a preferred machine learning model for prioritizing future application updates.
17. The method of claim 16, further comprising, after selecting the preferred machine learning model:
receiving, by the computing system, a subsequent request for application update information for the one or more applications installed on the first computing device;
determining, by the computing system and based on a subsequent request for the application update information, a subsequent set of applications that need to be updated, wherein each application from the subsequent set of applications is associated with a respective subsequent pending update;
Applying, by the computing system, the preferred machine learning model to determine a respective subsequent updated priority score for each application from the set of subsequent applications;
sending, from the computing system and to the first computing device, an indication of the respective subsequent update priority scores for the set of subsequent applications;
receiving, by the computing system and from the first computing device, a subsequent update request for at least one application from the subsequent set of applications, the at least one application from the subsequent set of applications selected by the first computing device based at least in part on the respective subsequent update priority scores; and
in response to receiving the subsequent update request, an installation of the subsequent pending update from the at least one application in the subsequent application set is initiated by the computing system.
18. The method of claim 17, wherein determining the validity of the first machine learning model is further based on one or more of: an application freshness metric, an application freshness for an active user metric, an application update coverage metric, and an application update efficiency metric.
19. The method of claim 18, wherein the application freshness metric represents a set of computing devices included in an installation library of an application, wherein a user of the set of computing devices has installed the application for the first time within a predetermined period of time.
20. The method of claim 18 or 19, wherein the application freshness representation for the active user metrics comprises a set of computing devices included in an installation library of applications, wherein a user of the set of computing devices has installed the application for a first time within a first predetermined period of time and has used the application for a second predetermined period of time.
21. The method of any of claims 18 to 20, wherein the application update coverage metric represents a set of computing devices included in an installation library of applications, wherein a user of the set of computing devices has not installed a most recent update for the applications within a first predetermined period of time and has used the applications within a second predetermined period of time.
22. The method of any of claims 18 to 21, wherein the application update efficiency metric represents a set of computing devices included in an installation library of an application, wherein a user of the set of computing devices has not installed a most recent update of the application within a first predetermined period of time and has used the application after having installed an update for the application within a second predetermined period of time.
23. A computing system comprising means for performing any combination of the methods of claims 16-22.
24. A computer-readable storage medium encoded with instructions that, when executed by one or more processors of a computing system, cause the one or more processors to perform any combination of the methods of claims 16-22.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US202063116709P | 2020-11-20 | 2020-11-20 | |
US63/116,709 | 2020-11-20 | ||
PCT/US2021/041434 WO2022108628A1 (en) | 2020-11-20 | 2021-07-13 | Prioritized application updates |
Publications (1)
Publication Number | Publication Date |
---|---|
CN116490849A true CN116490849A (en) | 2023-07-25 |
Family
ID=77265213
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202180071770.3A Pending CN116490849A (en) | 2020-11-20 | 2021-07-13 | Prioritized application updates |
Country Status (5)
Country | Link |
---|---|
US (1) | US20230376297A1 (en) |
EP (1) | EP4248308A1 (en) |
CN (1) | CN116490849A (en) |
DE (1) | DE112021006069T5 (en) |
WO (1) | WO2022108628A1 (en) |
Families Citing this family (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20230086203A1 (en) * | 2021-09-15 | 2023-03-23 | International Business Machines Corporation | Stale data recognition |
Family Cites Families (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10606575B2 (en) * | 2018-04-03 | 2020-03-31 | Accenture Global Solutions Limited | Efficiency of computing resource consumption via improved application portfolio deployment |
US10789057B2 (en) * | 2018-07-16 | 2020-09-29 | Dell Products L.P. | Predicting a success rate of deploying a software bundle |
CN111638892A (en) * | 2020-04-16 | 2020-09-08 | 合肥联宝信息技术有限公司 | Method, device, system and storage medium for optimizing application update sequencing |
-
2021
- 2021-07-13 CN CN202180071770.3A patent/CN116490849A/en active Pending
- 2021-07-13 US US18/043,634 patent/US20230376297A1/en active Pending
- 2021-07-13 DE DE112021006069.4T patent/DE112021006069T5/en active Pending
- 2021-07-13 WO PCT/US2021/041434 patent/WO2022108628A1/en active Application Filing
- 2021-07-13 EP EP21752320.8A patent/EP4248308A1/en active Pending
Also Published As
Publication number | Publication date |
---|---|
WO2022108628A1 (en) | 2022-05-27 |
DE112021006069T5 (en) | 2023-09-21 |
EP4248308A1 (en) | 2023-09-27 |
US20230376297A1 (en) | 2023-11-23 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
EP3757843B1 (en) | Security monitoring platform for managing access rights associated with cloud applications | |
US10673708B2 (en) | Auto tuner for cloud micro services embeddings | |
CN114556884B (en) | Message passing selection system in network environment | |
US10938678B2 (en) | Automation plan generation and ticket classification for automated ticket resolution | |
US20190122156A1 (en) | Orchestration Engine Blueprint Milestones | |
JP6564023B2 (en) | Compute instance startup time | |
EP3430511A1 (en) | Batching inputs to a machine learning model | |
US20210089944A1 (en) | Optimizing generation of a forecast | |
US11645575B2 (en) | Linking actions to machine learning prediction explanations | |
US11074058B1 (en) | Deployment operations based on deployment profiles in a deployment system | |
US20240112229A1 (en) | Facilitating responding to multiple product or service reviews associated with multiple sources | |
US20220129794A1 (en) | Generation of counterfactual explanations using artificial intelligence and machine learning techniques | |
CN114208127A (en) | Machine learning to predict quality of service in an operational data management system | |
US20210073653A1 (en) | Information technology service management system replacement | |
WO2020081858A2 (en) | Data analytics platform | |
CN116490849A (en) | Prioritized application updates | |
US11362906B2 (en) | Targeted content selection using a federated learning system | |
US20220027778A1 (en) | Runtime environment determination for software containers | |
US11900325B2 (en) | Utilizing a combination of machine learning models to determine a success probability for a software product | |
US11727119B2 (en) | Migration risk assessment, recommendation, and implementation | |
US11797891B1 (en) | Contextual bandits-based ecosystem recommender system for synchronized personalization | |
US20220180225A1 (en) | Determining a counterfactual explanation associated with a group using artificial intelligence and machine learning techniques | |
US11580466B2 (en) | Utilizing machine learning models to aggregate applications and users with events associated with the applications | |
US20230111043A1 (en) | Determining a fit-for-purpose rating for a target process automation | |
US20230367774A1 (en) | Pattern identification in structured event data |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |