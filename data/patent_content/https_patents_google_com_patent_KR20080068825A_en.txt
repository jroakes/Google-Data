KR20080068825A - Selecting high quality reviews for display - Google Patents
Selecting high quality reviews for display Download PDFInfo
- Publication number
- KR20080068825A KR20080068825A KR1020087010131A KR20087010131A KR20080068825A KR 20080068825 A KR20080068825 A KR 20080068825A KR 1020087010131 A KR1020087010131 A KR 1020087010131A KR 20087010131 A KR20087010131 A KR 20087010131A KR 20080068825 A KR20080068825 A KR 20080068825A
- Authority
- KR
- South Korea
- Prior art keywords
- reviews
- review
- predefined
- selecting
- instructions
- Prior art date
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q50/00—Systems or methods specially adapted for specific business sectors, e.g. utilities or tourism
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/20—Natural language analysis
- G06F40/253—Grammatical analysis; Style critique
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q30/00—Commerce
- G06Q30/02—Marketing; Price estimation or determination; Fundraising
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q30/00—Commerce
- G06Q30/02—Marketing; Price estimation or determination; Fundraising
- G06Q30/0282—Rating or review of business operators or products
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q99/00—Subject matter not provided for in other groups of this subclass
Abstract
Description
본 출원은 아래의 출원들에 관한 것이며, 그 각각은 참조로 본 발명에 포함된다:This application relates to the following applications, each of which is incorporated herein by reference:
2005년 9월 30일자로 제출된 미국 특허출원번호 제11/241,698호, "Selecting Representative Reviews for Display";US Patent Application No. 11 / 241,698 filed September 30, 2005, entitled "Selecting Representative Reviews for Display";
2005년 9월 30일자로 제출된 미국 특허출원번호 제11/241,702호, "Selecting High Quality Text Within Identified Reviews for Display in Review Snippets";US Patent Application No. 11 / 241,702, filed September 30, 2005, entitled "Selecting High Quality Text Within Identified Reviews for Display in Review Snippets";
2005년 9월 30일자로 제출된 미국 특허출원번호 제11/241,694호, "Identifying Clusters of Similar Reviews and Displaying Representative Reviews from Multiple Clusters"; 및US Patent Application No. 11 / 241,694, "Identifying Clusters of Similar Reviews and Displaying Representative Reviews from Multiple Clusters", filed September 30, 2005; And
2005년 9월 30일자로 제출된 미국 특허출원번호 제11/241,693호, "System and Methods for Reputation Management". US Patent Application No. 11 / 241,693, "System and Methods for Reputation Management," filed September 30, 2005.
개시된 실시예들은 일반적으로 검색 엔진들에 관한 것이다. 보다 구체적으로는, 개시된 실시예들은 프리젠테이션을 위한 리뷰들로부터의 콘텐츠 선택 및 리뷰들의 선택을 위한 방법 및 시스템에 관한 것이다.The disclosed embodiments generally relate to search engines. More specifically, the disclosed embodiments relate to a method and system for selecting content from reviews for presentations and for selecting reviews.
많은 인터넷 사용자들은 제품 또는 서비스를 획득하기 이전에 이를 검색한다. 또한, 많은 인터넷 사용자들은 그 제공자를 후원하기 이전에 제품 또는 서비스의 제공자를 검색한다. 현재, 많은 사용자들이 추종하는 방법은 제품들, 서비스들 및/또는 이들의 제공자들에 대한 등급(rating) 및 리뷰(review)를 제공하는 웹 사이트를 이용하는 것이다. 예를 들어, www.pricegrabber.com, www.bizrate.com, 및 www.resellerratings.com과 같은 웹 사이트들은 제품들과 그 제공자들에 대한 등급 및 리뷰를 제공한다.Many Internet users search for a product or service before obtaining it. In addition, many Internet users search for a provider of a product or service before sponsoring that provider. Currently, a method that many users follow is to use a website that provides ratings and reviews of products, services, and / or their providers. For example, websites such as www.pricegrabber.com, www.bizrate.com, and www.resellerratings.com provide ratings and reviews for products and their providers.
제품, 서비스, 또는 제공자에 대한 등급과 리뷰의 전체적인 뷰(holistic view)를 획득하기 위해, 사용자는 등급과 리뷰를 제공하는 다수의 웹 사이트들을 방문하고, 그러한 웹 사이트들에 의해 제공되는 다수의 등급들 및 리뷰들을 읽는다. 그러나, 이러한 프로세스는 매우 시간-소모적이고 성가시다. 사용자들은 다양한 웹 사이트들에 대한 리뷰들과 등급들을 통한 시간 소모를 방지하기 위해, 등급들과 리뷰들의 간단한 요약에 만족할 수 있다.In order to obtain a holistic view of ratings and reviews for a product, service, or provider, a user visits a number of websites that provide ratings and reviews, and a number of ratings provided by those websites. Read books and reviews. However, this process is very time-consuming and cumbersome. Users may be satisfied with a brief summary of ratings and reviews in order to avoid time consuming through reviews and ratings for various web sites.
따라서, 사용자들이 확득하고자 관심을 갖는(예, 구매, 임대, 렌탈, 또는 다른 유사한 거래에 의해) 제품들과 서비스들에 대한 검색을 보다 효율적으로 수행할 수 있도록 하는 것이 매우 바람직하다.Thus, it is highly desirable to enable users to more efficiently perform searches for products and services that they are interested in acquiring (eg, by purchase, lease, rental, or other similar transaction).
본 발명의 몇몇 실시예들에서, 리뷰들을 처리하는 방법은, 다수의 리뷰들을 식별하는 단계; 적어도 미리 규정된 품질 기준을 기초로 상기 다수의 리뷰들의 서브세트를 선택하는 단계; 및 상기 선택된 서브세트로부터 콘텐츠를 포함하는 응답을 생성하는 단계를 포함한다.In some embodiments of the present invention, a method of processing reviews comprises: identifying a plurality of reviews; Selecting a subset of the plurality of reviews based at least on predefined quality criteria; And generating a response comprising content from the selected subset.
도 1은 본 발명의 몇몇 실시예들에 따른 네트워크를 도시한다.1 illustrates a network in accordance with some embodiments of the present invention.
도 2는 본 발명의 몇몇 실시예들에 따른 리뷰 요약들에 대한 요청들을 수신 및 응답하기 위한 프로세스의 흐름도이다.2 is a flow diagram of a process for receiving and responding to requests for review summaries in accordance with some embodiments of the present invention.
도 3은 본 발명의 몇몇 실시예들에 따른 대표적인 리뷰들을 선택하기 위한 프로세스의 흐름도이다.3 is a flowchart of a process for selecting exemplary reviews in accordance with some embodiments of the present invention.
도 4는 본 발명의 몇몇 실시예들에 따른 고품질 리뷰들을 선택하기 위한 프로세스의 흐름도이다.4 is a flowchart of a process for selecting high quality reviews in accordance with some embodiments of the present invention.
도 5는 본 발명의 몇몇 실시예들에 따라, 리뷰들을 클러스터링하고 클러스터들로부터 리뷰들을 선택하기 위한 프로세스의 흐름도이다.5 is a flowchart of a process for clustering reviews and selecting reviews from clusters, in accordance with some embodiments of the present invention.
도 6은 본 발명의 몇몇 실시예들에 따라, 리뷰 내의 고품질 콘텐츠로부터 스니피트를 생성하기 위한 프로세스의 흐름도이다.6 is a flowchart of a process for generating snippets from high quality content in a review, in accordance with some embodiments of the present invention.
도 7은 본 발명의 몇몇 실시예들에 따른 리뷰들을 처리하기 위한 시스템을 도시한다.7 illustrates a system for processing reviews in accordance with some embodiments of the present invention.
도면들에 걸쳐서 동일한 참조 번호들은 동일한 부분들을 지칭한다.Like reference numerals refer to like parts throughout the drawings.
서브젝트(subject)(제품, 서비스, 또는 그 제공자)에 대한 검색을 수행하는 사용자들은 몇몇 웹 사이트들에서 많은 리뷰들 및 등급들(ratings)을 읽는 시간을 소비하길 원하지 않을 수 있고, 서브젝트에 대한 리뷰들 및 등급들의 요약에 만족 할 수 있다. 요약은 서브젝트에 대한 리뷰들의 샘플을 포함할 수 있다. 그러나, 샘플의 포함을 위해 단지 임의로 리뷰들을 선택하는 것은 사용자에게 유용하지 않다. 개시된 실시예들은 미리 규정된 넌-랜덤(non-random) 기준을 기초로 리뷰 샘플의 포함을 위해 리뷰들을 선택하고, 리뷰의 스니피트(snippet)의 사용을 위해 리뷰로부터 텍스트를 선택한다.Users who perform a search for a subject (product, service, or provider) may not want to spend time reading many reviews and ratings on some websites, and reviewing a subject You can be satisfied with the summary of these and ratings. The summary can include a sample of reviews for the subject. However, it is not useful for the user to simply select reviews for inclusion of the sample. The disclosed embodiments select reviews for inclusion of a review sample based on predefined non-random criteria, and select text from the review for use of a snippet of the review.
도 1은 본 발명의 몇몇 실시예들에 따른 네트워크를 도시한다. 네트워크(100)는 하나 이상의 클라이언트들(102), 하나 이상의 문서 호스트들(104), 및 리뷰 엔진(106)을 포함한다. 네트워크(100)는 또한 이러한 구성요소들을 결합하는 네트워크(108)를 포함한다.1 illustrates a network in accordance with some embodiments of the present invention. The
문서 호스트들(104)은 문서들을 저장하고 문서들에 대한 액세스를 제공한다. 문서는 텍스트, 그래픽, 멀티미디어 콘텐츠 등의 임의의 조합을 포함하는 임의의 기계-판독가능한 데이터일 수 있다. 몇몇 실시예들에서, 문서는 텍스트, 그래픽, 및 하이퍼텍스트 마크업 언어(HTML)로 기록된 가능한 다른 형태의 정보, 즉 웹 페이지들의 조합일 수 있다. 문서는 다른 문서들로의 하나 이상의 하이퍼링크들을 포함할 수 있다. 문서 호스트(102)에 저장된 문서는 고유 리소스 로케이터(URL), 또는 웹 어드레스, 또는 임의의 다른 적절한 형태의 식별 및/또는 위치에 의해 식별 및/또는 위치될 수 있다. 또한, 문서 호스트들(104)은 사용자들에 의해 이들에게 제출된 리뷰들을 저장하고, 웹 페이지들과 같은 문서들을 통한 리뷰들에 대한 액세스를 제공한다.Document hosts 104 store documents and provide access to documents. The document can be any machine-readable data, including any combination of text, graphics, multimedia content, and the like. In some embodiments, the document may be a combination of text, graphics, and other possible forms of information, ie, web pages, written in hypertext markup language (HTML). The document can include one or more hyperlinks to other documents. Documents stored at
클라이언트(102)는 사용자들이 웹 페이지들과 같은 문서들에 액세스할 수 있 는 클라이언트 애플리케이션들을 포함한다. 몇몇 실시예들에서, 클라이언트 애플리케이션들은 웹 브라우저를 포함한다. 웹 브라우저들의 예들은 Firefox, Internet Explorer 및 Opera를 포함한다. 몇몇 실시예들에서, 사용자들은 문서 호스트들(104)로 리뷰을 제출할 수 있거나, 클라이언트(102)를 통하여 리뷰 엔진(106)으로 리뷰들을 제출할 수 있다.
리뷰는 서브젝트 또는 세브젝트들의 클래스에 관한 콘텐츠(예, 코멘트, 평가, 견해 등)를 포함한다. 몇몇 실시예들에서, 콘텐츠는 텍스트이다. 다른 실시예들에서, 콘텐츠는 오디오, 비디오, 또는 텍스트, 오디오 및 비디오의 임의의 조합을 포함할 수 있다.Reviews include content about the subject or class of subjects (eg, comments, ratings, views, etc.). In some embodiments, the content is text. In other embodiments, the content may include audio, video, or any combination of text, audio, and video.
리뷰의 서브젝트는 리뷰내의 콘텐츠가 코멘트, 평가, 견해 등을 제공하는 임의의 특정한 실체 또는 대상이다. 몇몇 실시예들에서, 리뷰의 서브젝트는 서브젝트의 타입에 따라 분류될 수 있다. 서브젝트 타입의 예들은 제품들, 서비스들, 제품들의 제공자들, 서비스들의 제공자들 등을 포함한다. 리뷰는 서브젝트들의 클래스에 관한 것일 수 있다. 서브젝트들의 클래스는 공통의 특색, 특성 또는 특징을 공유하는 다수의 특정한 실체들 또는 대상들을 포함한다. 예를 들어, 특정한 제품 라인은 리뷰의 서브젝트일 수 있는 서브젝트들의 클래스일 수 있다. 다른 예로서, 특정 브랜드를 가진 모든 제품들은 리뷰의 서브젝트일 수 있는 서브젝트들의 클래스일 수 있다.The subject of a review is any particular entity or object for which content in the review provides comments, ratings, views, and the like. In some embodiments, the subject of the review may be classified according to the type of subject. Examples of subject types include products, services, providers of products, providers of services, and the like. The review may relate to the class of subjects. The class of subjects includes a number of specific entities or objects that share a common feature, characteristic or characteristic. For example, a particular product line may be a class of subjects that may be subjects of a review. As another example, all products with a particular brand may be a class of subjects that may be subjects of a review.
등급은 리뷰와 연관되고 리뷰와 함께 저장될 수 있다. 등급(또는 "등급 스코어(rating score")는 리뷰의 서브젝트(또는 서브젝트들의 클래스)에 대한 미리 규정된 스케일의 스코어를 나타낸다. 등급의 형태는 수치값일 수 있거나, 수치값으로 맵핑될 수 있는 임의의 비-수치 형태일 수 있다. 예를 들어, 비-수치 만족(thumbs-up) 또는 불만족(thumbs-down) 등급들은 각각 이진값 1 또는 0으로 맵핑될 수 있다. 등급들의 형태들의 예들은 심볼 또는 서술적 형태들(포지티브/네거티브, 만족/불만족 등) 및 수치 형태들(1-3, 1-5, 1-10, 1-100)을 포함한다. 몇몇 실시예들에서, 등급과 더불어, 리뷰는 특정 실시예들의 서브젝트에 대한 서브-등급들과 연관될 수도 있다. 서브-등급들은 특정 실시예들의 서브젝트에 대한 스코어일 수 있다.The rating may be associated with the review and stored with the review. A rating (or “rating score”) represents a score of a predefined scale for a subject (or class of subjects) of a review.The form of the rating may be a numerical value or any that may be mapped to a numerical value. For example, non-numeric thumb-up or dissatisfied ratings may be mapped to binary values 1 or 0. Examples of forms of ratings may be symbols or Descriptive forms (positive / negative, satisfaction / dissatisfaction, etc.) and numerical forms (1-3, 1-5, 1-10, 1-100) In some embodiments, in addition to the rating, review May be associated with sub-classes for a subject of certain embodiments, which may be a score for the subject of certain embodiments.
리뷰 엔진(106)은 리뷰 서버(110), 리뷰 저장소(repository)(112), 및 리뷰 수집기(114), 및 문서 저장소(116)를 포함한다. 리뷰 서버(110)는 클라이언트들(102)로의 전송을 위해 리뷰들의 스니피트들 및/또는 리뷰들을 포함하는 응답들을 생성한다. 또한, 리뷰 서버(110)는 리뷰들과 등급들을 리뷰 엔진(106)으로 제출하기 위한 클라어인트들(102)의 사용자들에 대한 인터페이스를 제공한다. The review engine 106 includes a
리뷰 수집기(114)는 문서들로부터 리뷰들을 수집한다. 리뷰 수집기(114)는 문서들을 파싱(parsing)하고, 문서들로부터 리뷰들, 등급들, 및 다른 적절한 정보(리뷰들의 독자, 리뷰 날짜, 리뷰의 서브젝트들과 같은)를 추출한다. 추출된 리뷰들은 저장을 위해 리뷰 저장소(112)로 전송된다. 리뷰 수집기(114)가 리뷰들을 추출하는 문서들은 문서 호스트들(104) 및/또는 문서 저장소(116)에 저장될 수 있다.The
문서 저장소(116)는 문서 호스트들(104)에 저장된 적어도 서브세트의 문서들의 복사본들의 저장소이다. 문서 저장소(116)에 저장된 문서들은 문서 호스트 들(104)로부터 수집되고 검색 엔진(106)에 의해 저장될 수 있다. 몇몇 실시예들에서, 문서 저장소(116)는 리뷰 엔진(106)에 액세스가능한 검색 엔진(미도시)에 위치될 수 있고, 검색 엔진은 문서 호스트들(104)로부터 문서들을 수집하고 이들을 문서 저장소(116)에 저장하기 위한 것이다.
리뷰 엔진(106)에 저장된 리뷰들은 클라이언트들(102)의 사용자들에 의해 기록되고 문서 호스트들(104) 또는 리뷰 엔진(106)으로 제출된다. 문서 호스트들(104)에 제출된 리뷰들은 문서 호스트들(104)에 저장된 문서들로부터 또는 문서 저장소(116)에 저장된 문서들의 복사본들로부터 추출될 수 있다. 또한, 리뷰들은 사용자들에 의해 리뷰 엔진(106)에 제출될 수 있다. 리뷰 엔진(106)에 제출된 리뷰들 및 문서들로부터 추출된 리뷰들은 저장을 위해 리뷰 저장소(112)로 전송된다.Reviews stored in the review engine 106 are recorded by the users of the
문서 호스트들(104) 또는 검색 엔진(106)은 사용자들이 리뷰들을 이들에게 제출하는 능력을 제공할 수 있다. 예를 들어, 문서 호스트들(104) 또는 리뷰 엔진(106)은 사용자들이 이들의 리뷰들과 등급들을 기입한 다음 제출할 수 있도록, 온라인 서식들(online forms)을 제공할 수 있다. 리뷰들은 제출 및 저장 이후, 웹 페이지들과 같은 문서들을 통해 다른 사용자들에 의해 액세스될 수 있다.Document hosts 104 or search engine 106 may provide the ability for users to submit reviews to them. For example, document hosts 104 or review engine 106 may provide online forms for users to fill out and then submit their reviews and ratings. Reviews can be accessed by other users via documents such as web pages after submission and storage.
리뷰의 소스는 리뷰가 제출된 실체(entity)이다. 소스는 리뷰가 제출되었던 문서 호스트(104)의 위치 및/또는 식별자에 의해 식별될 수 있다. 몇몇 실시예들에서, 리뷰의 소스는 리뷰가 제출된 문서 호스트(104)의 도메인에 의해 식별될 수 있다. 예를 들어, 리뷰가 도메인 "www.xyz.com" 하에서 문서 호스트에 제출되었다면, 추출된 리뷰의 소스는 "xyz.com"일 수 있다. 사용자들에 의해 리뷰 엔진(106) 으로 제출된 리뷰들의 경우, 리뷰 엔진(106)은 소스로서 고려될 수 있다.The source of the review is the entity to which the review was submitted. The source may be identified by the location and / or identifier of the
리뷰 저장소(112)는 리뷰들 및 연관된 등급들을 저장한다. 또한, 리뷰 저장소(112)는 각각의 리뷰에 대해, 서브젝트 또는 서브젝트들의 클래스, 및 서브젝트 타입(즉, 서브젝트 또는 서브젝트들의 클래스가 제품, 제품 제공자 등인지 여부)을 저장한다. 리뷰 저장소(112)는 소스, 독자, 및 각각의 리뷰에 대한 날짜를 저장할 수도 있다. 몇몇 실시예들에서, 리뷰 및 등급은 리뷰 저장소(112)에서, 리뷰 및 등급 자체의 하나 이상의 평가들과 연관될 수 있다. 리뷰 및 등급의 평가는 리뷰 및 등급의 유용성 및/또는 신뢰성을 평가할 수 있다. 예를 들어, 리뷰 및 등급의 평가는 유용한/무용한 등급을 포함할 수 있다. 다른 예로서, 리뷰 및 등급은 그 독자의 평판(reputation)의 측정치를 기초로 하는 계측값과 연관될 수 있다. 평판-기반 계측값의 일 예는 2005년 9월 30일자로 제출된 미국 특허출원번호 제11/241,693호, "Systems and Methods for Reputation Management"에 개시되어 있고, 그 명세서는 참조로 본 발명에 포함된다.
리뷰 엔진(106)의 각각의 구성요소들은 다수의 컴퓨터들에 대해 분배될 수 있다는 것을 고려해야 한다. 예를 들어, 리뷰 저장소(112)는 리뷰들이 각각의 M 서버들에 저장되는지를 결정하는데 사용되는 "모듈로(modulo) M" 기능과 같은 맵핑 기능을 갖는 M 서버들에 대해 배치될 수 있다. 유사하게, 리뷰 서버(110)가 다수의 서버들에 대해 분배될 수 있고, 리뷰 수집기(114)와 문서 저장소(116)는 다수의 컴퓨터들에 대해 각각 분배될 수 있다. 그러나, 설명의 편의를 위해, 단일 컴퓨터에서 구현되는 것으로서 리뷰 엔진(106)의 구성요소들을 논의할 것이다.It should be considered that each component of the review engine 106 may be distributed to multiple computers. For example, the
도 2는 본 발명의 몇몇 실시예들에 따라, 리뷰 요약들에 대한 요청들을 수신 및 응답하기 위한 프로세스의 흐름도이다. 전술한 것처럼, 검색 엔진(106)은 사용자들에 의해 검색 엔진(106)에 제출된 리뷰들 뿐만 아니라, 문서 호스트들(104)에 제출된 리뷰들을 수집 및 저장한다. 사용자들은 제품, 서비스, 또는 제공자와 같은 서브젝트에 대한 리뷰 정보를 클라이언트(102)를 통하여 리뷰 엔진으로부터 요청할 수 있다. 예를 들어, 사용자는 클라이언트(102)상에 디스플레이되는 웹 페이지에서 링크를 클릭하여, 리뷰 엔진(106)에 대한 요청의 전송을 트리거한다. 그러한 요청을 처리하기 위한 예시적인 프로세스는 이하에서 기술된다.2 is a flowchart of a process for receiving and responding to requests for review summaries, in accordance with some embodiments of the present invention. As mentioned above, search engine 106 collects and stores reviews submitted to document
클라이언트(102)를 통하여, 사용자는 리뷰 엔진(106)으로부터 서브젝트 또는 서브젝트들의 클래스에 대한 리뷰 요약을 요청할 수 있다. 리뷰 엔진(106)은 서브젝트에 대한 리뷰 요약에 대한 요청을 클라이언트(102)로부터 수신한다(202). 리뷰 저장소(112)에 저장된 서브젝트에 대한 리뷰들이 식별된다(204). 식별된 리뷰들의 서브세트가 선택된다(206). 선택된 서브세트로부터의 콘텐츠를 포함하는 응답이 생성된다(208). 응답은 클라이언트(102)로 전송된다(210). 응답 수신시, 클라이언트(102)는 사용자에게 표시하기 위해, 웹 브라우저와 같은 클라이언트 애플리케이션에서 응답을 제공한다.Through the
생성된 응답은 사용자에게 제공 및 표시를 위해 클라이언트(102)로 전송되는 문서이다. 응답 문서는 서브젝트에 대한 리뷰 요약을 포함할 수 있다. 리뷰 요약은 서브젝트에 대한 종합 등급과 같은 정보를 포함하고, 그 추가적인 세부사항들은 도 3과 관련하여 이하에서 기술된다. 리뷰 요약은 가능하다면, 리뷰 소스들에 의 해 주어진 서브젝트에 대한 집합적인 등급들(collective ratings)을 포함할 수도 있다. 리뷰 소스에 의해 서브젝트에 주어진 집합적인 등급은 그 소스에 제출된 서브젝트에 대한 리뷰들과 연관된 등급들을 기초로, 리뷰 소스에 의해 결정되는 등급이다. 집합적인 등급이 결정되는 방법은 리뷰 소스에 의해 변화될 수 있지만 본 발명의 관심사는 아니다. 다양한 이유들 때문에 모든 리뷰 소스들이 서브젝트에 대한 집합적 등급을 갖는 것은 아니다. 예를 들어, 몇몇 리뷰 소스들은 집합적 등급들을 전혀 갖지 않도록 결정할 수 있는 반면에, 다른 리뷰 소스들은 집합적 등급이 결정되어 주어지기 이전에, 서브젝트에 대한 등급들의 수가 미리 규정된 최소치에 도달할 것을 요구할 수 있다. 리뷰 요약에 집합적 등급들의 포함은 선택사항이다.The generated response is a document that is sent to the
또한, 리뷰 요약은 리뷰 샘플을 포함한다. 몇몇 실시예들에서, 리뷰 샘플은 선택된 리뷰들 중 적어도 일부의 전체 콘텐츠를 포함할 수 있다. 텍스트-기반 리뷰들에 대해, 리뷰의 전체 콘텐츠는 리뷰의 전체 텍스트이다. 비디오-기반 리뷰들에 대해, 리뷰의 전체 콘텐츠는 리뷰의 전체 비디오 클립이다. 몇몇 다른 실시예들에서, 리뷰 샘플은 선택된 리뷰들 중 적어도 일부의 스니피트들을 포함할 수 있고, 그 추가적인 세부사항들은 도 6과 관련하여 이하에서 기술된다. 그러나, 몇몇 실시예들에서, 리뷰 샘플은 몇몇 선택된 리뷰들의 전체 콘텐츠 및 다른 선택된 리뷰들의 스니피트들을 모두 포함할 수 있다는 것을 고려해야 한다. 리뷰 샘플은 전체 콘텐츠 또는 스니피트들이 리뷰 샘플에 포함되는 리뷰들의 소스들에 대한 하나 이상의 링크들을 포함할 수도 있다.The review summary also includes a review sample. In some embodiments, the review sample can include the entire content of at least some of the selected reviews. For text-based reviews, the full content of the review is the full text of the review. For video-based reviews, the full content of the review is the full video clip of the review. In some other embodiments, the review sample may include snippets of at least some of the selected reviews, further details of which are described below with respect to FIG. 6. However, it should be considered that in some embodiments, a review sample may include both the full content of some selected reviews and snippets of other selected reviews. The review sample may include one or more links to sources of reviews for which the entire content or snippets are included in the review sample.
도 3은 본 발명의 몇몇 실시예들에 따른 대표 리뷰들을 선택하기 위한 프로세스의 흐름도이다. 서브젝트에 대한 리뷰 요약에 대한 요청을 사용자로부터 수신할 때, 리뷰 엔진(106)은 서브젝트의 리뷰 샘플에 포함시키기 위해, 다수의 리뷰들을 선택할 수 있고, 이에 따라 샘플의 리뷰들이 서브젝트에 대한 종합 등급(overall rating)을 대표한다.3 is a flowchart of a process for selecting representative reviews in accordance with some embodiments of the present invention. Upon receiving a request from the user for a review summary for a subject, the review engine 106 may select multiple reviews to include in the subject's review sample, whereby the reviews of the sample may be combined into a comprehensive rating for the subject. overall rating).
특정 서브젝트에 대한 리뷰들 및 리뷰들의 소스들이 식별된다(302). 리뷰들은 특정 서브젝트와 연관된 모든 리뷰들에 대해 리뷰 저장소(112)를 검색함으로써 리뷰 저장소(112)로부터 식별될 수 있다. 식별된 리뷰들은 특정 서브젝트에 대한 리뷰들의 코퍼스(corpus)를 형성한다. 서브젝트에 대한 집합적 등급들은 가능하다면, 각각의 식별된 소스로부터 식별된다(304). 각각의 식별된 리뷰 소스에 대해, 각각의 소스에 있는 코퍼스의 리뷰들의 수가 식별된다(306). 이는 얼마나 많은 코퍼스의 리뷰들이 각각의 소스에 포함되어 있는지에 대한 간단한 카운트이다.Reviews for the particular subject and sources of reviews are identified 302. Reviews can be identified from the
서브젝트에 대해 종합 등급 스코어가 결정된다(308). 종합 등급 스코어는 리뷰 소스들에 의해 주어진 서브젝트에 대한 집합적 등급들의 수학적 조합일 수 있다. 몇몇 실시예들에서, 종합 등급 스코어는 집합적 등급들의 가중 평균이다. 가중치들은 각각의 소스에 포함되는 코퍼스의 리뷰들의 수를 기초로 한다. 따라서, 코퍼스의 많은 리뷰들을 갖는 소스들로부터 집합적 등급들은 가중 평균을 받는다. 종합 등급을 계산하기 위한 예시적인 공식은 다음과 같다:A comprehensive grade score is determined for the subject (308). The composite grade score may be a mathematical combination of collective grades for a subject given by review sources. In some embodiments, the composite grade score is the weighted average of the collective grades. The weights are based on the number of corpus reviews included in each source. Thus, collective ratings from sources with many reviews of corpus receive a weighted average. An exemplary formula for calculating the overall rating is as follows:
여기서, OR은 종합 등급이고, S는 코퍼스의 적어도 하나의 리뷰(즉 서브젝트에 대한 적어도 하나의 리뷰)를 갖는 리뷰 소스들의 수이며, 서브젝트에 대한 합산 등급(aggregated rating) ri는 소스 i로부터의 집합적 등급(collective rating)이며, ni는 소스 i에 있는 코퍼스의 리뷰들의 수이다. 리뷰 소스들이 각각 이들의 집합적 등급들에 대한 상이한 스케일들 및/또는 서식들(forms)을 이용하면, 집합적 등급들은 먼저 종합 등급에 대해 사용된 스케일/서식과 동일한 스케일 및 서식으로 변환 및/또는 정규화된다. 몇몇 실시예들에서, 종합 등급은 1-5 수치 등급 스케일을 기초로 하고, 이에 따라 집합적 등급들은 그 스케일로 변환 및/또는 정규화될 수 있다. 그러나, 대안적인 등급 스케일들이 종합 등급에 대해 사용될 수 있다는 것을 고려해야 한다. 몇몇 실시예들에서, 집합적 등급들은 상기 공식에 나타낸 것처럼, 각각의 리뷰 소스에 있는 코퍼스의 리뷰들의 개수들의 로그(logarithms)에 의해 가중된다. 로그는 베이스 2, 베이스 10 또는 베이스 e와 같은 임의의 적절한 베이스일 수 있다. 몇몇 다른 실시예들에서, 집합적 등급들은 다음의 공식에 나타낸 것처럼, 각각의 리뷰 소스에 있는 코퍼스의 리뷰들의 개수들에 의해 가중된다:Where OR is an overall rating, S is the number of review sources having at least one review of the corpus (ie at least one review of the subject), and an aggregated rating r i for the subject from source i The collective rating, n i is the number of corpus reviews in source i. If the review sources each use different scales and / or forms for their collective ratings, then the collective ratings are first converted to the same scale and format as the scale / format used for the overall rating. Or normalized. In some embodiments, the composite grade is based on a 1-5 numerical grade scale, so collective grades may be converted and / or normalized to that scale. However, it should be taken into account that alternative grade scales may be used for the overall grade. In some embodiments, the collective ratings are weighted by the logarithms of the number of reviews of the corpus in each review source, as shown in the formula above. The log can be any suitable base such as base 2, base 10 or base e. In some other embodiments, the collective ratings are weighted by the number of corpus reviews in each review source, as shown in the following formula:
종합 등급을 결정할 때, 전제 등급이 속하는 등급 범위가 식별된다(310). 등급 스케일은 2개 이상의 등급 범위들로 분할될 수 있다. 예를 들어, 1-5 스케일은 3 범위들로 분할될 수 있다. 3.66 내지 5의 등급은 포괄적으로, 서브젝트의 경험이 전체적으로 포지티브(positive)였다는 것을 나타낼 수 있다. 1 내지 2.33의 등급은 포괄적으로, 서브젝트의 경험이 전체적으로 네거티브(negative)였다는 것을 나타낼 수 있다. 2.34 내지 3.65의 등급은 포괄적으로, 서브젝트의 경험이 전체적으로 혼합되어있다는 것을 나타낼 수 있다. 다른 예로서, 동일한 1-5 스케일은 4 범위들로 분할될 수 있다. 4.1 내지 5의 등급은 포괄적으로, 우수한(excellent) 등급을 나타낼 수 있다. 3.1 내지 4의 등급은 포괄적으로, 양호한(good) 등급을 의미할 수 있다. 2.1 내지 3의 등급은 포괄적으로, 적정(fair) 등급을 의미할 수 있다. 1 내지 2의 등급은 포괄적으로, 나쁜(poor) 등급을 의미할 수 있다. 상기한 등급 범위 예들은 단지 예시적인 것이며 대안적인 방식의 등급 스케일 분할이 사용될 수 있다는 것을 고려해야 한다. 그러나, 설명의 편의를 위해, 등급 스케일이 다음의 3개의 범위들로 분할되는 것으로서 도 3에 도시된 프로세스를 논의할 것이다: 높음/포지티브 범위, 낮음/네거티브 범위, 및 중간/혼합된 범위.When determining the overall grade, the grade range to which the predicate grade belongs is identified (310). The rating scale may be divided into two or more rating ranges. For example, a 1-5 scale can be divided into 3 ranges. A rating of 3.66-5 may collectively indicate that the subject's experience was overall positive. A rating of 1 to 2.33 can collectively indicate that the subject's experience was overall negative. A rating of 2.34 to 3.65, inclusive, may indicate that the subject's experience is mixed overall. As another example, the same 1-5 scale may be divided into 4 ranges. A rating of 4.1 to 5 may be inclusive, indicating an excellent rating. A rating of 3.1 to 4 may broadly mean a good rating. A rating of 2.1 to 3 may broadly mean a fair rating. A rating of 1 to 2 may broadly mean a poor rating. It should be contemplated that the above grade range examples are illustrative only and alternative scale scale divisions may be used. However, for ease of explanation, the process shown in FIG. 3 will be discussed as the rating scale is divided into three ranges: high / positive range, low / negative range, and medium / mixed range.
종합 등급이 낮은 범위에 속하는 경우(310 - 낮음), 낮은 범위의 등급들에 연관된 코퍼스의 리뷰들이 선택된다(312). 리뷰들은 전체적으로 코퍼스로부터 선 택되거나 단위 소스 기반으로 선택될 수 있다. 리뷰들이 단위 소스 기반으로 선택되면, 낮은 범위의 등급들과 연관된 미리 규정된 제 1 리뷰 개수까지 각각의 소스로부터 선택될 수 있다. 리뷰들이 전체적으로 코퍼스로부터 선택되면, 리뷰 소스와의 관련 없이, 미리 규정된 제 2 리뷰 개수까지 코퍼스로부터 선택될 수 있다.If the overall rating falls in the low range (310-low), reviews of the corpus associated with the low range ratings are selected 312. Reviews can be selected entirely from the corpus or on a unit source basis. If the reviews are selected on a unit source basis, they can be selected from each source up to a predefined first number of reviews associated with the lower range of ratings. Once the reviews are entirely selected from the corpus, they can be selected from the corpus up to a second predefined number of reviews, irrespective of the review source.
종합 등급이 중간 범위에 속하는 경우(310 - 중간), 높은 범위의 등급들과 연관된 코퍼스에 있는 리뷰들, 및 낮은 범위의 등급들과 연관된 코퍼스에 있는 리뷰들이 선택된다(314). 즉, 선택된 리뷰들 중에서, 높은 범위의 등급들과 연관된 리뷰들 및 낮은 범위의 등급들과 연관된 리뷰들이 있다. 대안적인 실시예들에서, 중간 범위의 등급들과 연관된 코퍼스의 리뷰들이 선택된다. 전술한 것처럼, 리뷰들은 단위 소스 기반으로 선택되거나 전반적으로 코퍼스로부터 선택될 수 있다.If the overall rating falls in the middle range (310-medium), reviews in the corpus associated with the high range ratings, and reviews in the corpus associated with the low range ratings are selected (314). That is, among the selected reviews, there are reviews associated with high range ratings and reviews associated with low range ratings. In alternative embodiments, reviews of the corpus associated with the middle range of ratings are selected. As discussed above, reviews may be selected on a unit source basis or may be selected from the corpus as a whole.
종합 등급이 높은 범위에 속하는 경우(310 - 높음), 높은 범위의 등급들과 연관된 코퍼스에 있는 리뷰들이 선택된다(316). 전술한 것처럼, 리뷰들은 단위 소스 기반으로 선택되거나 전체적으로 리뷰들의 세트로부터 선택될 수 있다.If the overall rating is in the high range (310-high), reviews in the corpus associated with the high range of ratings are selected (316). As discussed above, reviews may be selected on a unit source basis or from a set of reviews as a whole.
몇몇 실시예들에서, 부가적인 선택 기준이 포함될 수 있다. 예를 들어, 부가적인 기준은 선택될 리뷰들이 세속적 또는 성적 노골적인 콘텐츠와 같은 불쾌한 콘텐츠를 갖지 않도록 하는 것일 수 있다. 다른 예로서, 부가적인 기준은 선택될 리뷰들이 미리 규정된 임계치를 초과하는 평판-기반 계측값을 가져야 하는 것일 수 있다. 보다 일반적으로, 종합 등급이 속하고 제로 이상의 다른 미리 규정된 기준을 충족시키는, 등급 범위의 등급들과 연관된 리뷰들이 선택될 수 있다.In some embodiments, additional selection criteria may be included. For example, an additional criterion may be that the reviews to be selected do not have offensive content, such as secular or sexually explicit content. As another example, an additional criterion may be that the reviews to be selected should have a reputation-based measure that exceeds a predefined threshold. More generally, reviews associated with ratings in the rating range may be selected that belong to the overall rating and meet zero or more other predefined criteria.
선택된 리뷰들로부터의 콘텐츠를 포함하는 응답이 생성된다(318). 생성된 응답은 사용자에게 제공 및 프리젠테이션하기 위해 클라이언트(102)로 전송되는 문서이다. 응답 문서는 서브젝트에 대한 리뷰 요약을 포함한다. 리뷰 요약은 서브젝트에 대한 종합 등급, 및 선택사항으로서 리뷰 소스들에 의해 주어진 서브젝트에 대한 집합적 등급들과 같은 정보를 포함할 수 있다. 또한, 리뷰 요약은 전술한 것처럼, 선택된 리뷰들 또는 이들의 스니피트를 포함하는 리뷰 샘플을 포함한다.A response is generated 318 that includes content from the selected reviews. The generated response is a document sent to the
도 4는 본 발명의 몇몇 실시예들에 따라, 고품질 리뷰들을 선택하기 위한 프로세스의 흐름도이다. 서브젝트에 대한 리뷰 요약에 대한 요청을 사용자로부터 수신할 때, 리뷰 엔진(106)은 서브젝트의 리뷰 샘플에 포함하기 위한 리뷰들의 개수를 선택함으로써, 리뷰들이 고품질 콘텐츠를 포함한다.4 is a flowchart of a process for selecting high quality reviews, in accordance with some embodiments of the present invention. Upon receiving a request from the user for a review summary for a subject, the review engine 106 selects the number of reviews to include in the subject's review sample, whereby the reviews contain high quality content.
특정 서브젝트에 대한 리뷰들 및 리뷰들의 소스들이 식별된다(402). 리뷰들은 특정 서브젝트에 연관된 모든 리뷰들에 대해 리뷰 저장소(112)를 검색함으로써 리뷰 저장소(112)로부터 식별될 수 있다. 식별된 리뷰들은 서브젝트에 대한 리뷰들의 코퍼스를 형성한다. 몇몇 실시예들에서, 불쾌한 콘텐츠를 포함한 임의의 리뷰들을 제거하기 위해, 처음에 또는 프로세스의 나중 단계에서, 식별된 리뷰들이 필터링된다(402).Reviews for the particular subject and sources of reviews are identified (402). Reviews can be identified from the
각각의 식별된 리뷰에 대해 품질 스코어가 결정된다(404). 품질 스코어는 리뷰의 콘텐츠의 품질의 측정치이다. 품질 스코어는 리뷰들을 이들의 품질과 관련하여 서로 비교하기 위한 근거를 제공한다. 품질 스코어는 하나 이상의 미리 규정된 인자들을 기초로 할 수 있다. 몇몇 실시예들에서, 미리 규정된 인자들은 리뷰의 길이, 리뷰의 문장들의 길이, 리뷰의 단어들과 연관된 값들, 및 리뷰의 문법적 품질을 포함한다. 리뷰에 대한 품질 스코어를 결정하도록 결합되는 서브-스코어들 및 각각의 인자를 기초로, 서브-스코어가 리뷰에 대해 결정될 수 있다. 그러나, 부가적인 및/또는 대안적인 인자들이 포함될 수 있다는 것을 고려해야 한다.A quality score is determined 404 for each identified review. The quality score is a measure of the quality of the content of the review. Quality scores provide a basis for comparing reviews to each other in terms of their quality. The quality score may be based on one or more predefined factors. In some embodiments, the predefined factors include the length of the review, the length of the sentences of the review, the values associated with the words of the review, and the grammatical quality of the review. Based on the sub-scores and each factor combined to determine a quality score for the review, the sub-scores may be determined for the review. However, it should be considered that additional and / or alternative factors may be included.
리뷰의 문법적 품질과 관련하여, 적절한 문법 및 대문자사용(예, 실제적인 사용 문장들, 전체적으로 대문자가 아닌 리뷰)이 선호된다. 따라서, "적절한" 문법 및 대문자사용을 가진 리뷰들은 이러한 인자에 대해 더 높은 서브-스코어들을 획득한다. 나쁜 문법 및 부적절한 대문자사용을 가진 리뷰들은 읽히지 않는 경향이 있다. 더욱이, 전체적으로 대문자인 리뷰들은 종종 조잡한(rude) 것으로 간주된다. 몇몇 실시예들에서, 리뷰의 문장들의 검출은 리뷰 주기들과 같은, 문장 구획문자(delimiter)의 검출을 기초로 할 수 있다. 몇몇 실시예들에서, 리뷰들은 주어-동사 일치, 행바꾸기 없는(run-on) 문장들 또는 단편들(fragments)의 부재 등과 같은 문법적 품질의 부가적인 표시에 대한 충실도에 대해 평가될 수 있다. 몇몇 실시예들에서, 리뷰의 문법 및 대문자사용의 평가는 문법 검사기(grammar checker)를 이용하여 수행될 수 있고, 이는 종래기술에 공지되어 있으며 추가적으로 기술될 필요가 없다.With regard to the grammatical quality of the review, appropriate grammar and capitalization (eg actual use sentences, reviews that are not entirely capitalized) are preferred. Thus, reviews with "proper" grammar and capitalization obtain higher sub-scores for this factor. Reviews with bad grammar and improper capitalization tend not to be read. Moreover, reviews that are generally capitalized are often considered rude. In some embodiments, detection of sentences in the review may be based on detection of sentence delimiters, such as review periods. In some embodiments, reviews may be evaluated for fidelity for additional indications of grammatical quality, such as subject-verb agreement, absence of run-on sentences or fragments, and the like. In some embodiments, evaluation of the grammar and capitalization of the review may be performed using a grammar checker, which is known in the art and need not be described further.
리뷰의 길이에 관하여, 너무 길지 않고 너무 짧지 않은 리뷰들이 선호된다. 짧은 리뷰들(예, 몇 단어들)은 정보 가치가 없는 경향이 있고, 긴 리뷰들(예, 많은 문단들)은 보다 짧은 리뷰만큼 읽히지 않는 경향이 있다. 몇몇 실시예들에서, 리뷰 길이는 단어 카운트를 기초로 할 수 있다. 몇몇 다른 실시예들에서, 리뷰 길이는 문자 카운트 또는 문장 카운트를 기초로 할 수 있다. 리뷰 길이 서브-스코어는 리뷰의 길이와 미리 규정된 "최적" 리뷰 길이 간의 차이를 기초로 할 수 있다.Regarding the length of the review, reviews that are not too long and not too short are preferred. Short reviews (eg a few words) tend to have no information value, and long reviews (eg many paragraphs) tend not to read as shorter reviews. In some embodiments, the review length may be based on word count. In some other embodiments, the review length may be based on a character count or sentence count. The review length sub-score may be based on the difference between the length of the review and the predefined "optimal" review length.
몇몇 실시예들에서, 리뷰들의 문장들의 길이들 또한 고려될 수 있다. 리뷰 엔진은 매우 길거나 짧은 문장들보다는 "적절한(reasonable)" 길이의 문장들을 선호할 수 있다. 몇몇 실시예들에서, 리뷰에 대한 문장 길이 서브-스코어는 리뷰의 문장들의 길이들과 미리 규정된 "최적" 문장 길이 간의 차이들의 평균을 기초로 할 수 있다.In some embodiments, the lengths of sentences of reviews may also be considered. The review engine may prefer sentences of "reasonable" length rather than very long or short sentences. In some embodiments, the sentence length sub-score for the review may be based on the average of the differences between the lengths of the sentences of the review and the predefined “optimal” sentence length.
리뷰의 단어들에 연관된 값들과 관련하여, 높은 값 단어들을 갖는 리뷰들은 낮은 값 단어들을 가진 리뷰들에 비해 선호된다. 몇몇 실시예들에서, 단어 값들은 단어들과 연관된 역 문서 빈도(Inverse Document Frequency:IDF)를 기초로 한다. 높은 IDF 값들을 가진 단어들은 일반적으로 보다 "가치있는" 것으로서 고려된다. 단어의 IDF는 단어의 적어도 하나의 발생(occurence)을 포함하는 세트에서 텍스트들의 수로 나누어지는 텍스트들의 세트의 텍스트들 수를 기초로 한다. 리뷰 엔진(106)은 리뷰 저장소(112)의 리뷰들에 대한 IDF 값들을 결정하고, 하나 이상의 테이블들에 값들을 저장할 수 있다. 몇몇 실시예들에서, IDF 값들의 테이블들은 각각의 타입의 리뷰들에 대해 생성된다. 예를 들어, IDF 값들의 테이블은 모든 제품 리뷰들에 대해 생성되고; 모든 제품 제공자 리뷰들에 대해 테이블이 생성된다. 즉, 제품 리뷰들에 대한 IDF 값들의 테이블을 결정하기 위해 사용되는 텍스트들의 세트는 리뷰 저장소(112)의 모든 제품 리뷰들이고; 제품 제공자 리뷰들에 대한 IDF 값들의 테이블을 결정하기 위해 사용되는 텍스트들의 세트는 리뷰 저장소(11)의 모든 제품 제공자 리뷰들이다. 각각의 서브젝트 타입은 하나의 서브젝트 타입에 대 한 리뷰들에서 가치있는 단어들이 다른 서브젝트 타입에 대한 리뷰들에서 가치가 없을 수 있기 때문에, 그 자신의 IDF 값들의 테이블을 갖는다.With respect to the values associated with the words of the review, reviews with high value words are preferred over reviews with low value words. In some embodiments, word values are based on an Inverse Document Frequency (IDF) associated with the words. Words with high IDF values are generally considered to be more "worthy". The IDF of a word is based on the number of texts in the set of texts divided by the number of texts in the set containing at least one occurrence of the word. The review engine 106 may determine IDF values for the reviews of the
임의의 식별된 리뷰에 대해, 리뷰의 각각의 개별 단어에 대한 빈도는 그 단어에 대한 IDF에 의해 결정 및 곱해진다. 리뷰에 대한 단어 값 서브-스코어는 다음과 같다:For any identified review, the frequency for each individual word of the review is determined and multiplied by the IDF for that word. The word value sub-score for the review is as follows:
여기서, WVR은 리뷰 R에 대한 단어 값 서브-스코어이고, fw,R은 리뷰 R에서 개별 단어 w의 발생 개수(용어 빈도 또는 "TF")이며, log IDFw는 단어 w에 대한 IDF 값의 로그이다. 단어들 w에 대한 IDF 값들은 리뷰의 서브젝트 타입에 적절한 IDF 값들의 테이블로부터 획득된다. 예를 들어, 리뷰 R의 서브젝트가 제품이면, IDFw 값들은 제품 리뷰들에 대한 IDF 값들의 테이블로부터 획득된다.Where WV R is the word value sub-score for review R, f w, R is the number of occurrences (term frequency or “TF”) of individual words w in review R, and log IDF w is the IDF value for word w Is the log of IDF values for the words w are obtained from a table of IDF values appropriate for the subject type of the review. For example, if the subject of review R is a product, IDF w values are obtained from a table of IDF values for product reviews.
몇몇 다른 실시예들에서, 단어 값들은 리뷰 문맥상 가치있는 것으로 간주된 단어들의 미리 규정된 사전을 기초로 한다. 상이한 단어들이 상이한 서브젝트 타입들에 관한 리뷰들에 사용하기에 가치가 있을 수 있기 때문에, 개별 사전들이 상이한 서브젝트 타입들에 대해 규정될 수 있다. 예를 들어, 서브젝트가 제품인 리뷰들에 대한 가치있는 단어들의 사전, 및 서브젝트가 제공자인 리뷰들에 대한 가치있는 단어들의 다른 사전이 있을 수 있다. 이러한 실시예들에서, 단어 값 서브-스코어는 미리 규정된 사전에 얼마나 많은 단어들이 각각의 리뷰에 포함되는지의 카 운트를 기초로 할 수 있다.In some other embodiments, word values are based on a predefined dictionary of words deemed valuable in a review context. Since different words may be valuable for use in reviews regarding different subject types, individual dictionaries may be defined for different subject types. For example, there may be a dictionary of valuable words for reviews in which the subject is a product, and another dictionary of valuable words for reviews in which the subject is a provider. In such embodiments, the word value sub-score may be based on a count of how many words are included in each review in the predefined dictionary.
리뷰 엔진(106)은 각각의 미리 규정된 인자를 기초로 각각의 식별된 리뷰를 평가하고, 그 평가를 기초로 각각의 인자에 대한 서브-스코어를 결정한다. 각각의 인자들에 대한 서브-스코어들은 아래의 예시적인 식을 이용하는 품질 스코어에 조합될 수 있다:The review engine 106 evaluates each identified review based on each predefined factor and determines a sub-score for each factor based on that evaluation. Sub-scores for each factor can be combined into a quality score using the following example equation:
여기서, Q는 리뷰에 대한 품질 스코어이고, F는 품질 스코어에 들어가는 인자들의 개수, qj는 인자 j에 대한 서브-스코어, weightj는 인자 j에 대한 가중치이다. 몇몇 실시예들에서, 가중치들은 모두 1과 같고, 이 경우 품질 스코어 Q는 인자들에 대한 스코어들의 합이다. 몇몇 다른 실시예들에서, 가중치들은 각각의 인자에 대해 상이하게 규정될 수 있다. 일반적으로, 가중치들은 품질 스코어에 대한 각각의 인자의 중요도, 및 인자가 리뷰의 품질에 포지티브 또는 네거티브 기여하는지 여부를 기초로 규정될 수 있다.Where Q is the quality score for the review, F is the number of factors entering the quality score, q j is the sub-score for factor j, and weight j is the weight for factor j. In some embodiments, the weights are all equal to 1, in which case the quality score Q is the sum of the scores for the factors. In some other embodiments, the weights may be defined differently for each factor. In general, the weights may be defined based on the importance of each factor for the quality score, and whether the factor contributes positive or negative to the quality of the review.
몇몇 실시예들에서, 리뷰의 시기(age)는 리뷰의 품질 스코어의 인자로서 고려될 수 있다. 일반적으로, 리뷰 서브젝트의 최근 경험을 보다 반영하기 때문에, 보다 새로운 리뷰들이 선호된다. 품질 스코어를 증가시키는 보너스 포인트들이 리뷰의 시기를 기초로 리뷰의 품질 스코어에 적용될 수 있다. 예를 들어, 하루가 경과한 리뷰는 품질 스코어의 증가를 획득하는 반면에(덧셈 또는 곱셈에 의해), 일년이 지난 리뷰는 보너스를 획득하지 못한다. In some embodiments, the age of the review may be considered as a factor of the quality score of the review. In general, newer reviews are preferred because they more reflect the recent experience of the review subject. Bonus points that increase the quality score may be applied to the quality score of the review based on the timing of the review. For example, a review that is over one day gets an increase in the quality score (by addition or multiplication), while a review that is over one year does not earn a bonus.
리뷰들은 품질 스코어들을 기초로 선택된다(406). 가장 높은 품질 스코어들을 가진 리뷰들이 선택된다. 리뷰들은 단위 소스 기반으로 선택되거나, 전체적으로 코퍼스로부터 선택될 수 있다. 리뷰들이 단위 소스 기반으로 선택되면, 각각의 소스에 대한 최상위 스코어링 리뷰들의 수가 선택된다. 예를 들어, 10 최상위 스코어링 리뷰들이 소스 당 선택될 수 있다. 몇몇 실시예들에서, 선택은 품질 스코어들에 의해 리뷰들을 분류함으로써 수행되고, 리뷰들은 목표된 수의 리뷰들이 선택될 때까지 최상위 스코어링 리뷰들로부터 획득된다. Reviews are selected based on quality scores (406). Reviews with the highest quality scores are selected. Reviews may be selected on a unit source basis or may be selected from the corpus as a whole. If the reviews are selected on a unit source basis, the number of top scoring reviews for each source is selected. For example, 10 top scoring reviews may be selected per source. In some embodiments, the selection is performed by classifying reviews by quality scores, and reviews are obtained from the top scoring reviews until a desired number of reviews are selected.
몇몇 실시예들에서, 미리 규정된 콘텐츠 기준은 리뷰들을 선택하기 위한 부가적인 기준일 수도 있다. 미리 규정된 기준을 충족시키는 콘텐츠와 관련하여, 세속적 및 성적으로 불쾌한 콘텐츠, 서브젝트의 이해와 거의 무관하거나 전혀 무관하여 리뷰들을 읽는 사용자를 불편하게 할 수 있는 단어들 및 문장들과 같은, 사용자에게 불쾌할 수 있는 리뷰들의 콘텐츠를 갖는 리뷰들을 제외시키기 위해, 기준이 규정될 수 있다. 무례하거나 불쾌한 콘텐츠와 일반적으로 연관된 콘텐츠의 사전을 규정하고 사전에 대해 리뷰의 콘텐츠를 매칭함으로써, 미리 규정된 기준을 충족시키는 콘텐츠에 대한 리뷰의 평가가 수행될 수 있다. 세속적 또는 성적으로 불쾌한 언어와 같은 불쾌한 콘텐츠를 갖는 리뷰는 선택을 위한 고려에서 제외된다. 미리 규정된 콘텐츠 기준을 충족시키는 콘텐츠에 대한 리뷰의 콘텐츠의 평가는 스코어 결정 동안(404) 또는 리뷰 선택시 수행될 수 있고, 평가가 수행되는 시기는 설계의 선택 사항이다.In some embodiments, the predefined content criterion may be an additional criterion for selecting reviews. With respect to content that meets predefined criteria, it is offensive to the user, such as secular and sexually offensive content, words and sentences that may be uncomfortable for the user to read reviews that have little or no understanding of the subject. In order to exclude reviews having content of reviews that can be made, criteria may be defined. By defining a dictionary of content generally associated with rude or offensive content and matching the content of the review against the dictionary, evaluation of the review for content that meets the predefined criteria can be performed. Reviews with offensive content, such as secular or sexually offensive language, are excluded from consideration for selection. Evaluation of the content of the review for content that meets predefined content criteria may be performed during score determination (404) or upon review selection, and when the evaluation is performed is a design option.
몇몇 실시예들에서, 등급 스코어 기준은 리뷰 선택을 위한 부가적인 기준일 수 있다. 예를 들어, 전술한 것처럼, 대표적인 리뷰들을 선택하기 위한 프로세스는 서브젝트의 종합 등급을 대표하는 고품질 리뷰들이 선택되도록 하기 위해, 현재의 프로세스와 조합될 수 있다. 따라서, 종합 등급이 속하는 등급 범위의 등급들과 연관되고 고품질 스코어들을 갖는 리뷰들이 선택될 수 있다.In some embodiments, the rating score criterion may be an additional criterion for review selection. For example, as described above, the process for selecting representative reviews may be combined with the current process to ensure that high quality reviews representative of the overall rating of the subject are selected. Thus, reviews can be selected that are associated with grades in the grade range to which the overall grade belongs and have high quality scores.
전술한 부가적인 기준은 단지 예시적인 것이며, 상기 기준 및 다른 기준의 임의의 조합이 리뷰 선택을 위해 부가적으로 고려될 수 있다는 것을 이해해야 한다. 보다 일반적으로, 리뷰 엔진은 제로 이상의 다른 미리 규정된 기준을 충족시키는 최상위 스코어링(품질 스코어 면에서) 리뷰들을 선택할 수 있다.It is to be understood that the additional criteria described above are merely exemplary and that any combination of these and other criteria may additionally be considered for review selection. More generally, the review engine may select the highest scoring (in terms of quality score) reviews that meet zero or more other predefined criteria.
선택된 리뷰들을 포함하는 응답이 생성된다(408). 생성된 응답은 사용자에게 제공 및 프리젠테이션하기 위해 클라이언트(102)로 전송되는 문서이다. 응답 문서는 서브젝트에 대한 리뷰 요약을 포함한다. 리뷰 요약은 서브젝트에 대한 종합 등급, 및 선택사항으로서 리뷰 소스들에 의해 주어진 서브젝트에 대한 집합적 등급들과 같은 정보를 포함할 수 있다. 또한, 리뷰 요약은 도 2와 관련하여 전술한 것처럼, 선택된 리뷰들로부터의 콘텐츠를 포함하는 리뷰 샘플을 포함한다.A response is generated 408 that includes the selected reviews. The generated response is a document sent to the
도 5는 본 발명의 몇몇 실시예들에 따라, 리뷰들을 클러스터링하고 클러스터들(clusters)로부터 리뷰들을 선택하기 위한 프로세스의 흐름도이다. 특정 서브젝트에 대한 리뷰들이 식별된다(502). 리뷰들은 특정 서브젝트와 연관된 모든 리뷰들에 대해 리뷰 저장소(112)를 검색함으로써 리뷰 저장소(112)로부터 식별될 수 있다. 식별된 리뷰들은 서브젝트에 대한 리뷰들의 코퍼스를 형성한다.5 is a flowchart of a process for clustering reviews and selecting reviews from clusters, in accordance with some embodiments of the present invention. Reviews for a particular subject are identified (502). Reviews can be identified from the
리뷰들의 단어 값 벡터들이 생성된다(504). 단어 값 벡터들은 용어 빈도 - 리뷰들에 있는 단어들에 대한 역 문서 빈도 값들을 포함한다. 용어 빈도 - 역 문서 빈도("TF-IDF" 또는 "TFIDF"로서 공지됨)는 문서에서 또는 이러한 실시예들의 경우 리뷰에서, 단어들의 중요도를 평가하기 위한 기술이다. 리뷰에 관련된 단어의 값은 단어가 리뷰에 나타나는 횟수에 의해 증가되지만, 그 단어를 포함하는 리뷰들의 코퍼스에 있는 리뷰들의 수에 의해 오프셋된다. 식별된 리뷰들의 코퍼스의 임의의 리뷰에 대해, 단어 값들의 벡터가 생성될 수 있다. 예를 들어, 리뷰 R은 가중 벡터를 가질 수 있다:Word value vectors of the reviews are generated 504. Word value vectors include term frequency—inverse document frequency values for words in reviews. The term frequency—inverse document frequency (known as “TF-IDF” or “TFIDF”) is a technique for evaluating the importance of words in a document or in the case of reviews in these embodiments. The value of a word related to a review is increased by the number of times the word appears in the review, but offset by the number of reviews in the corpus of reviews that include the word. For any review of the corpus of identified reviews, a vector of word values may be generated. For example, the review R may have a weight vector:
여기서, v1 내지 vn은 리뷰 T와 관련하여, 리뷰들의 코퍼스에 있는 모든 개별 단어들의 단어 값들이다. 몇몇 실시예들에서, 단어 및 그 관련 서식들은 함께 카운트된다. 예를 들어, 동사의 동사 시제(tense)들은 스펠링이 상이할 수 있기 때문에 단순히 개별 단어들로서가 아니라, 동일한 동사의 발생으로서 카운트될 수 있다. Where v 1 to v n are the word values of all individual words in the corpus of reviews, with respect to review T. In some embodiments, a word and its associated forms are counted together. For example, verb tense of verbs may be counted as the occurrence of the same verb, not just as individual words because spelling may be different.
리뷰 R에 관한 단어 w의 값은 다음과 같은 예시적인 식에 의해 결정될 수 있다:The value of the word w for review R can be determined by the following example equation:
여기서, vw,R은 리뷰 R에 관한 단어 w의 값이고, fw,R은 리뷰 R내에 있는 단어 w의 발생 수(용어 빈도)이며, log IDFw는 전술한 것처럼, 단어 w에 대한 IDF 값의 로그이다. 리뷰 R이 단어 w(fw,R=0)을 갖는 경우, 단어 값 vw,R은 0이다. fw,R≥0이고(발생 횟수는 (-)가 아님) log IDFw≥0이므로, 단어 값 vw,R은 (-)일 수 없다.Where v w, R is the value of word w for review R, f w, R is the number of occurrences (term frequency) of word w in review R, and log IDF w is the IDF for word w, as described above. It is a log of values. If the review R has the word w (f w, R = 0), the word value v w, R is zero. Since f w, R ≥ 0 (the number of occurrences is not negative) and log IDF w ≥ 0, the word values v w, R cannot be negative.
코퍼스에 있는 각각의 리뷰에 대하여 단어 값 벡터들의 생성시, 코퍼스의 리뷰들은 단어 값 벡터들을 기초로 클러스터들로 구성된다(506). 단어 값 벡터들은 벡터 공간내에 포함되고, 각각의 단어 값 벡터는 그 벡터 공간내의 "점(point)"이다. "점들"은 클러스터링 알고리즘을 이용하여 하나 이상의 클러스터들로 그룹화될 수 있다. 하나의 예시적인 클러스터링 알고리즘은 K-평균 클러스터링 알고리즘이다. K-평균 클러스터링 알고리즘은 종래기술에 공지되어 있다. 그러나, 개시된 실시예들의 이해를 돕기 위해, K-평균 알고리즘은 아래에서 기술된다.Upon generation of the word value vectors for each review in the corpus, the reviews of the corpus are organized into clusters based on the word value vectors (506). Word value vectors are contained in a vector space, and each word value vector is a "point" in that vector space. "Points" can be grouped into one or more clusters using a clustering algorithm. One example clustering algorithm is the K-means clustering algorithm. K-means clustering algorithms are known in the art. However, to aid in understanding the disclosed embodiments, the K-average algorithm is described below.
이하의 의사코드(pseudocode)는 K-평균 알고리즘의 기본 단계들을 도시한다:The following pseudocode illustrates the basic steps of the K-means algorithm:
K-평균 알고리즘에서, 임의의 수 k가 미리 규정된다. 몇몇 실시예들에서, k는 2 내지 16의 값이고, 몇몇 다른 실시예들에서 k는 2 내지 50의 값이다. 단어 값 벡터들의 벡터 공간에 있는 K 랜덤 벡터들이 생성된다. k 랜덤 벡터들은 벡터 공간에 대한 초기 중심들(initial centroids)이다. 각각의 초기 중심은 클러스터의 "중심"을 나타낸다. 즉, k 초기 클러스터들 및 이들의 중심들은 임의로 규정된다. 각각의 단어 값 벡터는 각각의 단어 값 벡터와 각각의 중심 간의 유사성(거리)을 기초로 k 클러스터들 중 하나에 할당된다. 단어 값 벡터는 가장 유사한 중 심(가장 짧은 거리)에 할당된다.In the K-average algorithm, any number k is predefined. In some embodiments k is a value from 2 to 16 and in some other embodiments k is a value from 2 to 50. K random vectors in the vector space of the word value vectors are generated. k random vectors are the initial centroids for the vector space. Each initial center represents the "center" of the cluster. That is, k initial clusters and their centers are arbitrarily defined. Each word value vector is assigned to one of the k clusters based on the similarity (distance) between each word value vector and each center. The word value vector is assigned to the closest center (shortest distance).
몇몇 실시예들에서, 단어 값 벡터와 중심 사이의 유사성(거리)은 코사인 유사성("코사인 거리"로도 공지됨)이다:In some embodiments, the similarity (distance) between the word value vector and the center is cosine similarity (also known as "cosine distance"):
여기서, X·Y는 벡터 X 및 Y의 도트 곱이고, Where XY is the dot product of the vectors X and Y,
몇몇 실시예들에서, 미리 규정된 다수의 정규(canonical) 리뷰들이 초기 중심들로서 사용될 수 있다. 정규 리뷰들은 특정 실시예들의 서브젝트에 대해 코멘트하는 리뷰들의 예들로서 제공되는 미리 규정된 리뷰들의 세트이다. 정규 리뷰들의 세트는 리뷰들의 코퍼스의 서브젝트가 무엇인지에 따라 변화될 수 있다. 예를 들어, 사용의 용이함 및 성능과 같은 특징들에 대한 정규 리뷰들을 포함할 수 있는 제품인 서브젝트에 대한 정규 리뷰들의 세트는, 고객 서비스 및 선적 스케쥴과 같 은 특징들에 대한 정규 리뷰들을 포함할 수 있는 제품 제공자인 서브젝트에 대한 정규 리뷰들의 세트와 상이할 수 있다. In some embodiments, a number of predefined canonical reviews may be used as the initial centers. Regular reviews are a set of predefined reviews provided as examples of reviews to comment on the subject of certain embodiments. The set of regular reviews may vary depending on what the subject of the corpus of reviews is. For example, a set of regular reviews for a subject, which may include regular reviews of features such as ease of use and performance, may include regular reviews of features such as customer service and shipping schedules. May differ from a set of regular reviews for a subject that is a product provider.
단어 값 벡터들이 k 클러스터들에 할당된 이후, k 클러스터들에 대한 중심들이 다시 결정된다. 즉, 각각의 클러스터에 대해 중심들이 재결정된다. 클러스터에 대한 중심은 클러스터의 단어 값 벡터들의 "평균치"를 취함으로써 결정될 수 있다(초기 중심을 포함하지 않음; 초기 중심은 단지 초기 클러스터 할당에 관련됨). 중심 C를 결정하기 위한 식은 다음과 같다:After the word value vectors are assigned to k clusters, the centroids for the k clusters are again determined. In other words, the centers are re-determined for each cluster. The center for the cluster can be determined by taking the "average" of the word value vectors of the cluster (not including the initial center; the initial center is only related to the initial cluster assignment). The equation for determining the center C is:
여기서, CS는 클러스터의 사이즈이고(클러스터의 단어 값 벡터들의 수), Vi는 클러스터의 단어 값 벡터들의 정규화된(단위 길이의 벡터들로 변환된) 벡터들이다.Where CS is the size of the cluster (the number of word value vectors in the cluster) and V i is the normalized (converted to unit length vectors) of the cluster's word value vectors.
새로운 중심들의 결정시, 단어 벡터 값들은 새로운 중심들에 대한 유사성을 기초로 클러스터들에 재할당된다. 단어 값 벡터는 가장 유사한 중심에 할당된다. 각각의 단어 값 벡터가 클러스터에 재할당된 이후, 중심들의 재결정 및 단어 값 벡터들의 재할당의 반복이 계속된다. 반복은 종결 조건이 충족될 때까지 계속된다. 몇몇 실시예들에서, 종결 조건은 수렴(convergence) 기준이 충족될 때이다. 수렴 기준은 반복의 종료 이후 단어 값 벡터들이 상이한 클러스터에 재할당되지 않는 것일 수 있다. 몇몇 다른 실시예들에서, 종결 조건은 미리 규정된 수의 반복들이 수 행되는 것이다.In determining new centers, word vector values are reassigned to clusters based on similarity to the new centers. The word value vector is assigned to the most similar center. After each word value vector is reassigned to the cluster, the repetition of the re-determination of centers and the reassignment of word value vectors continues. The iteration continues until the termination condition is met. In some embodiments, the termination condition is when a convergence criterion is met. The convergence criterion may be that word value vectors are not reallocated to different clusters after the end of the iteration. In some other embodiments, the termination condition is that a predefined number of iterations are performed.
계층적 클러스터링, 퍼지 c-평균 알고리즘 등과 같은 클러스터링의 대안적 방식들이 사용될 수 있다는 것을 고려해야 한다.It should be taken into account that alternative ways of clustering such as hierarchical clustering, fuzzy c-means algorithm, etc. may be used.
리뷰들을 클러스터들로 그룹화할 때, 리뷰 클러스터들의 사이즈들이 식별된다(508). 이는 간단히 각각의 클러스터의 리뷰들의 수이다(중심을 포함하지 않는 단어 값 벡터들에 의해 나타냄).When grouping reviews into clusters, sizes of review clusters are identified 508. This is simply the number of reviews in each cluster (represented by word value vectors that do not include the center).
리뷰들은 각각의 클러스터로부터 선택된다(510). 몇몇 실시예들에서, 리뷰들은 클러스터 사이즈들에 비례하여 각각의 클러스터로부터 선택된다. 미리 규정된 총 수의 리뷰들은 리뷰들의 코퍼스의 샘플로서 제공하기 위해 리뷰들의 코퍼스로부터 선택된다. 샘플의 리뷰들은 클러스터들의 사이즈들에 비례하여 클러스터들로부터 선택된다. 샘플은 더 작은 클러스터보다 더 큰 클러스터로부터 선택된 더 많은 리뷰들을 갖는다. 몇몇 실시예들에서, 매우 작은 클러스터(예, 리뷰들의 미리 규정된 수 미만 또는 코퍼스의 총 리뷰들의 수의 미리 규정된 퍼센티지 미만)는 리뷰 선택에서 제외될 수 있고; 그 클러스터로부터 리뷰가 샘플에 포함시키기 위해 선택될 것이다. 클러스터가 제외되면, 하나 이상의 리뷰들이 다른 클러스터들로부터 선택되어 샘플의 리뷰들의 수가 미리 규정된 총 수에 도달할 수 있다.Reviews are selected from each cluster (510). In some embodiments, reviews are selected from each cluster in proportion to the cluster sizes. The predefined total number of reviews is selected from the corpus of reviews to serve as a sample of the corpus of reviews. Reviews of the sample are selected from the clusters in proportion to the sizes of the clusters. The sample has more reviews selected from the larger cluster than the smaller cluster. In some embodiments, a very small cluster (eg, less than a predefined number of reviews or less than a predefined percentage of the total number of reviews of a corpus) may be excluded from the review selection; Reviews from that cluster will be selected for inclusion in the sample. If a cluster is excluded, one or more reviews may be selected from other clusters such that the number of reviews of the sample reaches a predefined total number.
몇몇 실시예들에서, 리뷰들은 부가적인 미리 규정된 기준을 기초로 클러스터로부터 선택될 수 있다. 예를 들어, 리뷰들은 도 4와 관련하여 전술한 것처럼, 리뷰들의 품질을 기초로 클러스터로부터 선택될 수 있다. 높은 품질의 리뷰들은 일반적으로 낮은 품질의 리뷰들보다 더 정보 가치가 있고 더 용이하게 읽힌다. 따라 서, 예를 들어, 10 리뷰들이 클러스터로부터 선택되면, 부가적인 품질 기준에 의해, 그 클러스터로부터 10 최상위 품질 리뷰들이 선택될 수 있다. 다른 예로서, 리뷰들은 도 3과 관련하여 전술한 선택 프로세스와 같은, 리뷰들과 연관된 등급들을 기초로 클러스터로부터 선택될 수 있다. 보다 일반적으로, 클러스터가 클러스터 사이즈에 비례하는 리뷰들의 수의 리뷰 샘플에 기여하는 한, 그 클러스터로부터의 리뷰들은 제로 이상의 미리 규정된 기준을 기초로 선택될 수 있다.In some embodiments, reviews can be selected from a cluster based on additional predefined criteria. For example, reviews may be selected from a cluster based on the quality of the reviews, as described above with respect to FIG. 4. Higher quality reviews are generally more informative and easier to read than lower quality reviews. Thus, for example, if 10 reviews are selected from a cluster, by the additional quality criterion 10 top quality reviews may be selected from that cluster. As another example, reviews may be selected from a cluster based on ratings associated with reviews, such as the selection process described above with respect to FIG. 3. More generally, as long as the cluster contributes a review sample of the number of reviews proportional to the cluster size, reviews from that cluster may be selected based on zero or more predefined criteria.
선택된 리뷰들을 포함하는 응답이 생성된다(512). 생성된 응답은 사용자에게 제공 및 프리젠테이션하기 위해 클라이언트(102)로 전송되는 문서이다. 응답 문서는 서브젝트에 대한 리뷰 요약을 포함한다. 리뷰 요약은 서브젝트에 대한 종합 등급, 및 선택사항으로서 리뷰 소스들에 의해 주어진 서브젝트에 대한 집합적 등급들과 같은 정보를 포함할 수 있다. 또한, 리뷰 요약은 도 2와 관련하여 전술한 것처럼, 선택된 리뷰들로부터의 콘텐츠를 포함하는 리뷰 샘플을 포함한다.A response is generated 512 that includes the selected reviews. The generated response is a document sent to the
리뷰들을 클러스터링하고 클러스터들로부터 리뷰들을 선택함으로써, 리뷰들의 토픽 포커스를 대표하는 리뷰 샘플이 선택된다. 클러스터링은 서브젝트의 특정한 특징들에 초점을 맞춘 리뷰들을 식별한다. 리뷰가 포커스하는 특징에 의해 리뷰들을 분리시키고 리뷰 샘플에 포함시키기 위해 클러스터들로부터 리뷰들을 선택함으로써, 리뷰 샘플이 나타날 때, 사용자는 서브젝트의 어떤 특징들이 특히 주목할만한지 또는 서브젝트의 어떤 특징들이 서브젝트를 경험한 다른 사용자들에게 특한 관심이 있었는지를 보다 잘 이해할 수 있다.By clustering reviews and selecting reviews from the clusters, a review sample is selected that represents the topic focus of the reviews. Clustering identifies reviews that focus on specific features of the subject. By separating the reviews by the feature that the review focuses and selecting reviews from the clusters to include in the review sample, when the review sample appears, the user experiences what the subject is particularly noteworthy or which features of the subject experience the subject. You can better understand whether you were of particular interest to other users.
도 6은 본 발명의 몇몇 실시예들에 따라, 리뷰내의 고품질 콘텐츠로부터 스 니피트를 생성하기 위한 프로세스의 흐름도이다. 시간을 절약하기 위해, 사용자는 리뷰들의 전체 콘텐츠 보다는 리뷰들의 일부만을 읽기를 선호할 수 있다. 리뷰 엔진은 리뷰 스니피트들로서 리뷰 샘플에 포함시키기 위한 리뷰들내의 특정 콘텐츠를 선택할 수 있다.6 is a flowchart of a process for generating snippets from high quality content in a review, in accordance with some embodiments of the present invention. To save time, a user may prefer to read only a portion of the reviews rather than the entire content of the reviews. The review engine may select specific content within the reviews to include in the review sample as review snippets.
리뷰가 식별된다(602). 식별된 리뷰는 파티션들로 분할된다(604). 몇몇 실시예들에서, 파티션들은 리뷰의 문장들이다. 즉, 리뷰의 각각의 문장은 리뷰의 파티션이다. 리뷰의 문장들은 중심들과 같은 문장 구획문자들을 기초로 식별될 수 있다. 리뷰가 하나의 문장만을 갖는 경우처럼, 리뷰가 하나의 파티션만을 갖는 경우가 있을 수 있다. 설명의 편의를 위해, 도 5의 프로세스는 리뷰들의 파티션들이 리뷰들의 문장들인 것으로서 이하에서 기술될 것이다. 그러나, 리뷰들을 분할하는 대안적인 방식들(예, Z 단어들의 파티션들, 여기서 Z는 미리 규정된 총 수)이 사용될 수 있다는 것을 고려해야 한다.The review is identified (602). The identified review is divided into partitions (604). In some embodiments, partitions are sentences of a review. In other words, each sentence of the review is a partition of the review. Sentences in the review can be identified based on sentence delimiters such as centroids. There may be cases where a review has only one partition, such as when a review has only one sentence. For convenience of description, the process of FIG. 5 will be described below as the partitions of reviews are sentences of reviews. However, it should be taken into account that alternative ways of dividing reviews (eg, partitions of Z words, where Z is a predefined total number) can be used.
품질 스코어는 리뷰의 각각의 문장에 대해 결정된다(606). 리뷰 문장에 대한 품질 스코어는 도 4와 관련하여 전술한 것처럼, 리뷰에 대한 품질 스코어와 유사하다. 문장 품질 스코어는 품질과 관련된 리뷰의 문장들의 상대적 순서(ordering)에 대한 근거를 제공한다. 품질 스코어는 하나 이상의 인자들을 기초로 할 수 있다. 서브-스코어는 각각의 인자들을 기초로 결정될 수 있다. 서브-스코어들은 상기 도 3과 관련하여 기술된 것과 유사한 가중된 합 방정식을 이용하여, 문장에 대한 품질 스코어에 결합될 수 있다. 몇몇 실시예들에서, 미리 규정된 인자들은 문장의 길이, 문장의 단어들과 연관된 값들, 및 리뷰내의 문장의 위치를 포 함한다.A quality score is determined 606 for each sentence of the review. The quality score for the review sentence is similar to the quality score for the review, as described above with respect to FIG. 4. Sentence quality scores provide a basis for the relative ordering of sentences in a review related to quality. The quality score may be based on one or more factors. The sub-score may be determined based on the respective factors. The sub-scores can be combined into a quality score for a sentence using a weighted sum equation similar to that described with respect to FIG. 3 above. In some embodiments, the predefined factors include the length of the sentence, the values associated with the words of the sentence, and the position of the sentence within the review.
리뷰 문장의 길이와 관련하여, 너무 길지 않고 너무 짧지 않은 문장들(즉, "적절한 길이"의 문장)이 선호된다. 매우 짧은 문장들은 많은 정보를 포함하지 않을 수 있고, 매우 긴 문장들은 읽기가 힘들 수 있다. 몇몇 실시예들에서, 문장 길이를 기초로 한 서브-스코어는 미리 규정된 "최적" 문장 길이로부터 리뷰의 문장들의 편차를 기초로 할 수 있다. 문장 길이는 단어 카운트 또는 문자 카운트를 기초로 할 수 있다.Regarding the length of the review sentence, sentences that are not too long and not too short (ie, sentences of "proper length") are preferred. Very short sentences may not contain much information, and very long sentences may be difficult to read. In some embodiments, a sub-score based on sentence length may be based on a deviation of sentences of the review from a predefined “optimal” sentence length. Sentence length may be based on word count or character count.
문장의 단어들과 연관된 값들과 관련하여, 높은 값 단어들을 갖는 문장들은 낮은 값 단어들을 갖는 문장들에 비해 선호된다. 몇몇 실시예들에서, 단어 값들은 도 4와 관련하여 전술한 리뷰들의 스코어링에 사용되는 단어 값 인자와 유사한, 단어들과 연관된 역 문서 빈도(IDF) 값들을 기초로 한다. 문장에 대해, 문장의 각각의 개별 단어에 대한 빈도는 그 단어에 대한 IDF에 의해 결정 및 곱해진다. 리뷰에 대한 단어 값 서브-스코어는 다음과 같다:With regard to values associated with words in a sentence, sentences with high value words are preferred over sentences with low value words. In some embodiments, the word values are based on inverse document frequency (IDF) values associated with the words, similar to the word value factor used for scoring the reviews described above with respect to FIG. 4. For a sentence, the frequency for each individual word in the sentence is determined and multiplied by the IDF for that word. The word value sub-score for the review is as follows:
여기서, WVP는 문장 P에 대한 단어 값 서브-스코어이고, fw,P는 문장 P의 단어 w의 발생 수, log IDFW는 단어 w에 대한 IDF 값의 로그이다.Where WV P is the word value sub-score for sentence P, f w, P is the number of occurrences of word w in sentence P, and log IDF W is the log of IDF value for word w.
몇몇 다른 실시예들에서, 단어 값들은 리뷰 문맥에서 가치있는 것으로 간주되는 단어들의 미리 규정된 사전을 기초로 한다. 상이한 단어들이 상이한 서브젝트 타입들에 대한 리뷰들에 사용하기에 가치가 있을 수 있기 때문에, 개별 사전들 은 상이한 서브젝트 타입들에 대해 규정될 수 있다. 예를 들어, 서브젝트가 제품인 리뷰들에 대한 가치있는 단어들의 사전, 및 서브젝트가 제공자인 리뷰들에 대해 가치있는 단어들의 다른 사전이 존재할 수 있다. 이러한 실시예들에서, 단어 값 서브-스코어는 미리 규정된 사전의 얼마나 많은 단어들이 각각의 문장에 포함되는지의 카운트를 기초로 할 수 있다.In some other embodiments, word values are based on a predefined dictionary of words that are considered valuable in a review context. Since different words may be worth using in reviews for different subject types, individual dictionaries may be defined for different subject types. For example, there may be a dictionary of valuable words for reviews for which the subject is a product, and another dictionary of valuable words for reviews for which the subject is a provider. In such embodiments, the word value sub-score may be based on a count of how many words of the predefined dictionary are included in each sentence.
리뷰내의 문장의 위치와 관련하여, 몇몇 실시예들에서, 리뷰 엔진은 리뷰의 시작부분에 있는 문장들을 선호할 수 있다. 따라서, 위치를 기초로 하는 서브-스코어는 리뷰의 문장들의 수에 대해 정규화된 리뷰의 문장의 위치를 기초로 할 수 있다. 예를 들어, 10 문장들을 갖는 리뷰의 4번째 문장에 대해, 그 문장에 대한 위치 서브-스코어는 4/10 = 0.2일 수 있다.Regarding the position of a sentence within a review, in some embodiments, the review engine may prefer sentences at the beginning of the review. Thus, the location-based sub-score may be based on the location of the sentence of the review normalized to the number of sentences in the review. For example, for the fourth sentence of a review with 10 sentences, the position sub-score for that sentence may be 4/10 = 0.2.
문자에 대한 서브-스코어들의 결정시, 서브-스코어들은 도 4와 관련하여 전술한 것과 유사한 식을 이용하여, 문장에 대한 품질 스코어에 수학적으로 조합될 수 있다.In determining the sub-scores for the character, the sub-scores may be mathematically combined in the quality score for the sentence, using an equation similar to that described above with respect to FIG. 4.
리뷰 문장들의 조합들이 식별된다(608). 각각의 조합은 미리 규정된 길이 기준을 충족시키는 리뷰의 하나 이상의 연속적인 문장들을 포함한다. 몇몇 실시예들에서, 길이 기준은 조합 길이가 미리 규정된 최대 스니피트 길이와 동일하거나(단어 카운트 또는 문자 카운트를 기초로 할 수 있음), 조합의 마지막 문장의 일부분에 의해 최대 스니피트 길이를 초과하는 것이다. 조합들을 식별하기 위한 예시적인 알고리즘은 아래의 의사코드에 의해 나타낸다:Combinations of review sentences are identified (608). Each combination includes one or more consecutive sentences of the review that meet a predefined length criterion. In some embodiments, the length criterion may be that the combination length is equal to the predefined maximum snippet length (which may be based on word count or character count) or exceeds the maximum snippet length by a portion of the last sentence of the combination. It is. An example algorithm for identifying combinations is represented by the following pseudocode:
상기 의사코드에 나타낸 것처럼, 조합은 리뷰의 하나의 문장으로서 시작되고, 후속적인 문장들은 조합의 길이가 최대 스니피트 길이보다 크거나 같도록 하는 제 1 문장까지 및 제 1 문장을 포함하는, 상기 조합에 첨부된다. 따라서, 조합은조합에 부가될 때 조합 길이가 최대 스니피트 길이보다 크거나 같도록 하는 가능한 하나의 부가적인 문장과 더불어, 조합 길이가 최대 스니피트 길이를 초과하도록 하지 않으면서 리뷰의 가능한 많은 연속적인 문장들의 연결이다. As indicated in the pseudocode, the combination begins as one sentence of the review, and subsequent sentences include the first sentence and the first sentence, such that the length of the combination is greater than or equal to the maximum snippet length. Is attached. Thus, the combination is combined with as many additional sentences as possible in the review without causing the combination length to exceed the maximum snippet length, with one additional possible statement that, when added to the combination, causes the combination length to be greater than or equal to the maximum snippet length. It is a concatenation of sentences.
몇몇 다른 실시예들에서, 알고리즘은 첨부될 얼마나 많은 문장이 최대 스니피트 길이내에 있는지, 즉 얼마나 많은 "공간"이 부가적인 문장을 수용하도록 조합에 유지되는지를 고려하기 위해, 정제(refine)될 수 있다. 예를 들어, 조합이 최대 스니피트 길이의 짧은 하나 또는 두 단어들인 경우 조합에 부가적인 문장이 첨부되지 않도록 하는 것이 보다 가치있을 수 있다.In some other embodiments, the algorithm may be refined to consider how many sentences to be appended are within the maximum snippet length, ie how many "spaces" are kept in combination to accommodate additional sentences. have. For example, if the combination is one short or two words of maximum snippet length, it may be more valuable not to append additional sentences to the combination.
최상위 조합 품질 스코어을 갖는 조합이 선택된다(610). 몇몇 실시예들에서, 조합에 대한 조합된 품질 스코어는 조합내의 문장들의 품질 스코어의 간단한 합이다. 몇몇 다른 실시예들에서, 조합된 품질 스코어는 가중 합, 간단한 평균, 또는 조합내의 문장들의 품질 스코어들의 가중 평균일 수 있다.The combination with the highest combination quality score is selected (610). In some embodiments, the combined quality score for the combination is a simple sum of the quality scores of the sentences in the combination. In some other embodiments, the combined quality score may be a weighted sum, a simple mean, or a weighted average of the quality scores of the sentences within the combination.
스니피트는 선택된 조합을 이용하여 생성된다(612). 스니피트는 최대 스니피트 길이까지 선택된 조합을 포함한다. 조합이 최대 스니피트 길이를 초과하는 경우, 콘텐츠는 조합 길이가 최대 스니피트 길이와 동일할 때까지 조합의 끝단에서 절단된다. 몇몇 실시예들에서, 조합은 최대 스니피트 길이에 대한 절단 이후 조합의 마지막 문장의 단지 작은 부분(예, 하나 또는 두 단어들)만이 유지되는 경우 최대 스니피트 길이보다 더 짧게 절단될 수 있다. 즉, 문장의 몇몇 단어들만이 최대 스니피트 길이로 조합을 절단한 이후 유지되는 경우, 조합의 마지막 문장을 제거함으로써 절단하는 것이 보다 바람직할 수 있다. Snippets are generated 612 using the selected combination. Snippets include selected combinations up to the maximum snippet length. If the combination exceeds the maximum snippet length, the content is truncated at the end of the combination until the combination length is equal to the maximum snippet length. In some embodiments, the combination may be cut shorter than the maximum snippet length if only a small portion (eg, one or two words) of the last sentence of the combination is maintained after truncation to the maximum snippet length. That is, if only a few words in a sentence are retained after cutting the combination to the maximum snippet length, it may be more desirable to cut by removing the last sentence of the combination.
스니피트를 포함하는 응답이 생성된다(614). 생성된 응답은 사용자에게 제공 및 프리젠테이션하기 위해 클라이언트(102)로 전송되는 문서이다. 응답 문서는 서브젝트에 대한 리뷰 요약을 포함한다. 리뷰 요약은 서브젝트에 대한 종합 등급, 및 선택사항으로서 리뷰 소스들에 의해 주어진 서브젝트에 대한 집합적 등급들과 같은 정보를 포함할 수 있다. 또한, 리뷰 요약은 도 2와 관련하여 전술한 것처럼, 선택된 리뷰들로부터의 콘텐츠를 포함하는 리뷰 샘플을 포함한다.A response is generated that includes the snippet (614). The generated response is a document sent to the
리뷰 엔진(106)은 리뷰 저장소로부터 리뷰들을 선택하고, 클라이언트(102)로의 전송을 위해 선택된 리뷰들(전체 리뷰들 및/또는 스니피트들과 같은)로부터 콘텐츠를 포함하는 응답을 생성한다. 도 3, 4 및 5는 샘플에 대해 리뷰들을 선택하기 위한 3개의 프로세스들을 도시한다. 도 6은 도 3, 4 및/또는 5의 프로세스에서 선택된 리뷰일 수 있는 리뷰의 스니피트를 생성하기 위한 프로세스를 도시한다. 상기 프로세스들은 조합될 수 있다는 것을 이해해야 한다. 예를 들어, 리뷰 엔진(106)은 종합 등급이 속하는 등급 범위에 해당하고 고품질 스코어들을 갖는 리뷰들의 수를 선택할 수 있다. 다른 예로서, 리뷰 엔진(106)은 서브젝트에 대한 리뷰 들을 클러스터링하고, 각각의 클러스터로부터 클러스터 사이즈들에 비례하여, 종합 등급이 속하는 등급 범위에 해당하고 고품질 스코어들을 갖는 리뷰들을 선택한다. 이러한 선택된 리뷰들의 스니피트들이 생성되고, 스니피트들을 포함하는 응답이 생성된다. 보다 일반적으로, 리뷰들은 하나 이상의 미리 규정된 기준을 기초로 선택될 수 있고, 이러한 리뷰들의 스니피트들이 생성되어 클라이언트(102)로 전송된 응답에 포함될 수 있다.The review engine 106 selects reviews from the review repository and generates a response that includes the content from the selected reviews (such as full reviews and / or snippets) for transmission to the
도 7은 본 발명의 몇몇 실시예들에 따른 리뷰 처리 시스템(700)을 도시하는 블럭도이다. 시스템(700)은 전형적으로 하나 이상의 처리 유닛들(CPU's)(702), 하나 이상의 네트워크 또는 다른 통신 인터페이스들(710), 메모리(712), 및 이러한 컴포넌트들을 상호접속하기 위한 하나 이상의 통신 버스들(714)을 포함한다. 시스템(700)은 디스플레이 장치(706) 및 키보드/마우스(708)를 포함하는 사용자 인터페이스(704)를 선택적으로 포함할 수 있다. 메모리(712)는 DRAM, SRAM, DDR RAM 또는 다른 랜덤 액세스 고상 메모리 장치들과 같은 고속 랜덤 액세스 메모리를 포함하고; 하나 이상의 자기 디스크 저장 장치들, 광 디스크 저장 장치들, 플래시 메모리 장치들, 또는 다른 비휘발성 고상 저장 장치들과 같은 비휘발성 메모리를 포함할 수 있다. 메모리(712)는 CPU(들)(702)로부터 원격지에 위치된 하나 이상의 저장 장치들을 선택적으로 포함할 수 있다. 몇몇 실시예들에서, 메모리(712)는 이하의 프로그램들, 모듈들 및 데이터 구조들, 또는 이들의 서브세트를 저장한다:7 is a block diagram illustrating a
● 다양한 기본 시스템 서비스들을 처리하고 하드웨어 의존 태스트들을 수행하기 위한 프로시저들을 포함하는 운영체제(716);An
● 인터넷, 다른 광역 네트워크들, 로컬 영역 네트워크들, 도시권 통신망 등과 같은 하나 이상의 통신 네트워크 인터페이스들(710)(유선 또는 무선)을 통해 리뷰 처리 시스템(700)을 다른 컴퓨터들에 접속하기 위해 사용되는 네트워크 통신 모듈(718);A network used to connect the
● 리뷰 저장 시스템과 인터페이싱하는 리뷰 저장 인터페이스(720);A
● 리뷰들의 소스들을 식별하는 소스 식별 모듈(722);A source identification module 722 that identifies sources of reviews;
● 리뷰들 및 연관된 등급들을 리뷰 소스들로부터 식별하는 리뷰 식별 모듈(724);A
● 서브젝트에 대한 종합 등급을 결정하고, 종합 등급이 속하는 등급 범위를 결정하는 종합 등급 모듈(726);A
● 리뷰들에 대한 품질 스코어들을 결정하는 리뷰 품질 스코어링 모듈(728);A review
● 리뷰들을 클러스터들로 구성하는 리뷰 클러스터링 모듈(730);A
● 리뷰들을 파티션들로 분할하고, 파티션들에 대한 품질 스코어들을 결정하며, 파티션들의 조합들을 식별하고, 최상위 조합 품질 스코어와의 조합을 선택하는, 리뷰 파티션 모듈(732);A
● 하나 이상의 미리 규정된 기준을 기초로 리뷰들을 선택하는 리뷰 선택 모듈(734);A
● 불쾌한 콘텐츠와 같은 미리 규정된 콘텐츠 기준을 충족시키는 콘텐츠에 대해 리뷰들 및 리뷰 파티션들을 평가하는 콘텐츠 필터(736); 및A
● 리뷰들 및/또는 리뷰들의 스니피트들을 포함하는 응답들을 생성하는 응답 생성 모듈(738).A
또한, 시스템(700)은 리뷰 저장 시스템(740)을 포함한다. 리뷰 저장 시스템(740)은 리뷰들 및 연관된 등급들을 저장한다. 리뷰 저장 시스템(740)은 리뷰들의 스니피트들을 생성하는 스니피트 생성기(742)를 포함한다. 몇몇 실시예들에서, 스니피트 생성기(742)는 리뷰 저장 시스템(740)이 아닌 메모리(712)에 위치될 수 있다.
각각의 상기 식별된 엘리먼트들은 하나 이상의 이전에 언급된 메모리 장치들에 저장될 수 있고, 전술한 기능을 수행하기 위한 명령어들 세트에 해당한다. 상기 식별된 모듈들 또는 프로그램들(즉, 명령어들 세트)은 개별 소프트웨어 프로그램들, 프로시저들 또는 모듈들로서 구현될 필요는 없으며, 이에 따라 이러한 모듈들의 다양한 서브세트들이 조합되거나 다양한 실시예들에서 재배치될 수 있다. 몇몇 실시예들에서, 메모리(712)는 모듈들의 서브세트 및 상기 식별된 데이터 구조들을 저장할 수 있다. 더욱이, 메모리(712)는 상기에서 기술되지 않은 부가적인 모듈들 및 데이터 구조들을 저장할 수 있다.Each of the identified elements may be stored in one or more previously mentioned memory devices, and corresponds to a set of instructions for performing the aforementioned function. The identified modules or programs (ie, a set of instructions) need not be implemented as individual software programs, procedures or modules, such that various subsets of these modules may be combined or rearranged in various embodiments. Can be. In some embodiments, memory 712 may store a subset of modules and the identified data structures. Moreover, memory 712 may store additional modules and data structures not described above.
도 7은 "리뷰 처리 시스템"을 도시하지만, 도 7은 본 발명에서 기술된 실시예들의 구조적 개념이라기 보다는 서버들의 세트에 존재할 수 있는 다양한 특징들의 기능적 설명으로서 의도된다. 실제로, 통상의 당업자에 의해 인식되는 것처럼, 개별적으로 도시된 아이템들이 조합될 수 있고, 일부 아이템들은 분리될 수 있다. 예를 들어, 도 7에 개별적으로 도시된 일부 아이템들은 단일 서버들에서 구현될 수 있고, 단일 아이템들은 하나 이상의 서버들에 의해 구현될 수 있다. 리뷰 처리 시 스템을 구현하는데 사용되는 서버들의 실제 개수 및 이들 중에서 특징들이 할당되는 방법은 하나의 구현예와 다른 구현예간에 변화될 수 있고, 평균 사용 주기 동안 및 피크 사용 주기 동안 시스템이 처리해야 하는 데이터 트래픽의 양에 부분적으로 좌우될 수 있다.Although FIG. 7 illustrates a “review processing system”, FIG. 7 is intended as a functional description of the various features that may exist in a set of servers rather than the architectural concept of embodiments described herein. Indeed, as will be appreciated by one of ordinary skill in the art, items shown separately may be combined and some items may be separated. For example, some items shown separately in FIG. 7 may be implemented in single servers, and single items may be implemented by one or more servers. The actual number of servers used to implement the review processing system and how features are assigned among them can vary between one implementation and another, and the system must handle during average and peak usage cycles. It may depend in part on the amount of data traffic.
상기 상세한 설명은 이들의 애플리케이션을 순수하게 텍스트인, 즉 문자들의 열들로 이루어진 리뷰들로 제한하지 않는다는 것을 고려해야 한다. 상세한 설명은 오디오, 비디오, 또는 다른 형태의 미디어를 포함하는 리뷰들에 적용할 수 있다. 예를 들어, 오디오를 포함하는 리뷰(오디오-단독 리뷰들 또는 오디오 트랙을 갖는 비디오 리뷰들)에 대해, 오디오는 종래기술에 알려진 음성 대 텍스트 변환을 이용하여 텍스트로 변환될 수 있다. 변환된 텍스트는 전술한 선택 및 스니피트 생성 프로세스들에 대한 "리뷰"로서 사용될 수 있다. 오디오 또는 비디오 리뷰의 스니피트는 리뷰의 변환된 텍스트를 기초로 스니피트에 대해 선택된 단어들을 갖는 음성을 가진 오디오 또는 비디오의 부분이다. 리뷰 품질이 오디오/비디오 리뷰들을 선택하기 위한 기준이면, 문법적 품질 인자가 매체에 대해 적용될 수 있다. 예를 들어, 대문자사용은 리뷰의 콘텐츠가 텍스트가 아닌 음성일 때 매우 부적절하므로, 무시될 수 있다.It is to be considered that the above detailed description does not limit their application to reviews that are purely text, ie columns of characters. The detailed description may apply to reviews including audio, video, or other forms of media. For example, for reviews that include audio (audio-only reviews or video reviews with audio tracks), the audio can be converted to text using speech-to-text conversion known in the art. The translated text can be used as a "review" for the selection and snippet creation processes described above. The snippet of an audio or video review is the portion of audio or video with speech that has words selected for the snippet based on the converted text of the review. If the review quality is a criterion for selecting audio / video reviews, a grammatical quality factor can be applied for the medium. For example, capitalization can be ignored because the content of the review is very inappropriate when the content of the review is voice, not text.
전술한 상세한 설명은 설명을 목적으로 특정한 실시예들을 참조로 기술되었다. 그러나, 상기 예시적인 논의들은 개시된 정확한 형태들로 본 발명을 제한하거나 독점적으로 의도되지 않는다. 많은 변형들과 변화들이 상기 기술들의 관점에서 가능할 수 있다. 실시예들은 본 발명 및 그 실제적 애플리케이션들의 원리들을 최 상으로 설명하기 위해 선택 및 기술되었고, 이에 따라 통상의 당업자가 고려되는 특정한 사용에 적합하도록 다양한 변형들을 갖는 다양한 실시예들 및 본 발명을 최상으로 활용할 수 있도록 한다. The foregoing detailed description has been described with reference to specific embodiments for purposes of explanation. However, the illustrative discussions above are not intended to be exhaustive or to limit the invention to the precise forms disclosed. Many variations and modifications may be possible in light of the above techniques. The embodiments have been selected and described in order to best explain the principles of the invention and its practical applications, and thus best suit the invention and various embodiments with various modifications to suit the particular use contemplated by one of ordinary skill in the art. Make it available.
Claims (19)
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US11/241,701 US20070078670A1 (en) | 2005-09-30 | 2005-09-30 | Selecting high quality reviews for display |
US11/241,701 | 2005-09-30 | ||
PCT/US2006/038552 WO2007041545A2 (en) | 2005-09-30 | 2006-09-29 | Selecting high quality reviews for display |
Publications (2)
Publication Number | Publication Date |
---|---|
KR20080068825A true KR20080068825A (en) | 2008-07-24 |
KR101498001B1 KR101498001B1 (en) | 2015-03-04 |
Family
ID=37902943
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
KR1020087010131A KR101498001B1 (en) | 2005-09-30 | 2006-09-29 | Selecting high quality reviews for display |
Country Status (7)
Country | Link |
---|---|
US (1) | US20070078670A1 (en) |
EP (2) | EP2428928A1 (en) |
JP (3) | JP5281405B2 (en) |
KR (1) | KR101498001B1 (en) |
CN (1) | CN101313330A (en) |
CA (2) | CA2624066A1 (en) |
WO (1) | WO2007041545A2 (en) |
Families Citing this family (57)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8249915B2 (en) * | 2005-08-04 | 2012-08-21 | Iams Anthony L | Computer-implemented method and system for collaborative product evaluation |
US7827052B2 (en) * | 2005-09-30 | 2010-11-02 | Google Inc. | Systems and methods for reputation management |
US8010480B2 (en) * | 2005-09-30 | 2011-08-30 | Google Inc. | Selecting high quality text within identified reviews for display in review snippets |
US8438469B1 (en) | 2005-09-30 | 2013-05-07 | Google Inc. | Embedded review and rating information |
US7676463B2 (en) * | 2005-11-15 | 2010-03-09 | Kroll Ontrack, Inc. | Information exploration systems and method |
KR100752351B1 (en) * | 2006-07-03 | 2007-08-27 | (주)이즈메이커 | System and method realtime question and answers by communication media which can transfer interactively data or voice |
US7895127B2 (en) * | 2006-09-29 | 2011-02-22 | Weiser Anatoly S | Rating-based sorting and displaying of reviews |
US7711684B2 (en) | 2006-12-28 | 2010-05-04 | Ebay Inc. | Collaborative content evaluation |
US8763136B2 (en) * | 2007-03-22 | 2014-06-24 | Red Hat, Inc. | Privacy enhanced browser |
US20090083096A1 (en) * | 2007-09-20 | 2009-03-26 | Microsoft Corporation | Handling product reviews |
US20090106226A1 (en) * | 2007-10-19 | 2009-04-23 | Erik Ojakaar | Search shortcut pullquotes |
US20090144226A1 (en) * | 2007-12-03 | 2009-06-04 | Kei Tateno | Information processing device and method, and program |
US8032471B2 (en) * | 2007-12-21 | 2011-10-04 | Yahoo! Inc. | System and method for annotating and analyzing reviews with inferred analytics |
US9208262B2 (en) * | 2008-02-22 | 2015-12-08 | Accenture Global Services Limited | System for displaying a plurality of associated items in a collaborative environment |
US9298815B2 (en) | 2008-02-22 | 2016-03-29 | Accenture Global Services Limited | System for providing an interface for collaborative innovation |
US8645516B2 (en) | 2008-02-22 | 2014-02-04 | Accenture Global Services Limited | System for analyzing user activity in a collaborative environment |
US9009601B2 (en) * | 2008-02-22 | 2015-04-14 | Accenture Global Services Limited | System for managing a collaborative environment |
US8239228B2 (en) * | 2008-02-22 | 2012-08-07 | Accenture Global Services Limited | System for valuating users and user generated content in a collaborative environment |
US20090216578A1 (en) * | 2008-02-22 | 2009-08-27 | Accenture Global Services Gmbh | Collaborative innovation system |
US20090216608A1 (en) * | 2008-02-22 | 2009-08-27 | Accenture Global Services Gmbh | Collaborative review system |
US20100185498A1 (en) * | 2008-02-22 | 2010-07-22 | Accenture Global Services Gmbh | System for relative performance based valuation of responses |
US8954867B2 (en) | 2008-02-26 | 2015-02-10 | Biz360 Inc. | System and method for gathering product, service, entity and/or feature opinions |
US8117207B2 (en) * | 2008-04-18 | 2012-02-14 | Biz360 Inc. | System and methods for evaluating feature opinions for products, services, and entities |
US8645391B1 (en) | 2008-07-03 | 2014-02-04 | Google Inc. | Attribute-value extraction from structured documents |
US20100235311A1 (en) * | 2009-03-13 | 2010-09-16 | Microsoft Corporation | Question and answer search |
KR20100127036A (en) * | 2009-05-25 | 2010-12-03 | 엘지전자 주식회사 | A method for providing idea maps by using classificaion in terms of viewpoints |
US11238465B2 (en) * | 2009-08-26 | 2022-02-01 | Consumeron, Llc | System and method for remote acquisition and delivery of goods |
JP2011095906A (en) * | 2009-10-28 | 2011-05-12 | Sony Corp | Information processing apparatus, information processing method, and program |
US8990124B2 (en) | 2010-01-14 | 2015-03-24 | Microsoft Technology Licensing, Llc | Assessing quality of user reviews |
WO2012002349A1 (en) * | 2010-06-29 | 2012-01-05 | 楽天株式会社 | Information providing device, method of processing reward payment, reward payment processing program, and recording medium with reward payment processing program recorded theron |
EP2521343B1 (en) * | 2011-05-06 | 2019-07-03 | Telia Company AB | Rating a communication party |
US8676596B1 (en) | 2012-03-05 | 2014-03-18 | Reputation.Com, Inc. | Stimulating reviews at a point of sale |
US10636041B1 (en) | 2012-03-05 | 2020-04-28 | Reputation.Com, Inc. | Enterprise reputation evaluation |
CN104272301B (en) | 2012-04-25 | 2018-01-23 | 国际商业机器公司 | For extracting method, computer-readable medium and the computer of a part of text |
US8918312B1 (en) | 2012-06-29 | 2014-12-23 | Reputation.Com, Inc. | Assigning sentiment to themes |
US10417679B1 (en) * | 2013-06-06 | 2019-09-17 | Intuit Inc. | Transaction validation scoring |
US20150052077A1 (en) * | 2013-08-14 | 2015-02-19 | Andrew C. Gorton | Review transparency indicator system and method |
CN104216934B (en) * | 2013-09-29 | 2018-02-13 | 北大方正集团有限公司 | A kind of Knowledge Extraction Method and system |
JP5636082B1 (en) | 2013-10-08 | 2014-12-03 | 株式会社ワイズ | Advertising information sharing system |
CN103778235A (en) * | 2014-01-26 | 2014-05-07 | 北京京东尚科信息技术有限公司 | Method and device for processing commodity assessment information |
US10339487B2 (en) * | 2014-04-07 | 2019-07-02 | HomeAway.com, Inc. | Systems and methods to reconcile free-text with structured data |
US20170249389A1 (en) * | 2014-09-02 | 2017-08-31 | Feelter Sales Tools Ltd | Sentiment rating system and method |
JP6537340B2 (en) * | 2015-04-28 | 2019-07-03 | ヤフー株式会社 | Summary generation device, summary generation method, and summary generation program |
US10140646B2 (en) * | 2015-09-04 | 2018-11-27 | Walmart Apollo, Llc | System and method for analyzing features in product reviews and displaying the results |
US11164223B2 (en) | 2015-09-04 | 2021-11-02 | Walmart Apollo, Llc | System and method for annotating reviews |
CN105354227B (en) * | 2015-09-30 | 2019-06-14 | 北京奇虎科技有限公司 | The method and device of offer high quality reviews information based on search |
US10679264B1 (en) | 2015-11-18 | 2020-06-09 | Dev Anand Shah | Review data entry, scoring, and sharing |
US10417671B2 (en) | 2016-11-01 | 2019-09-17 | Yext, Inc. | Optimizing dynamic review generation for redirecting request links |
JP6906430B2 (en) * | 2017-11-20 | 2021-07-21 | ヤフー株式会社 | Information processing equipment, information processing methods and information processing programs |
CN108427546B (en) * | 2018-05-03 | 2022-03-08 | 深圳Tcl新技术有限公司 | Full screen adaptation method of display device, display device and storage medium |
JP7142559B2 (en) * | 2018-12-20 | 2022-09-27 | ヤフー株式会社 | Provision device, provision method, and provision program |
JP7176443B2 (en) * | 2019-03-11 | 2022-11-22 | トヨタ自動車株式会社 | Recommendation statement generation device, recommendation statement generation method, and recommendation statement generation program |
US11017171B2 (en) * | 2019-06-06 | 2021-05-25 | International Business Machines Corporation | Relevancy as an indicator for determining document quality |
US11774264B2 (en) | 2020-02-13 | 2023-10-03 | Naver Corporation | Method and system for providing information to a user relating to a point-of-interest |
KR102430972B1 (en) * | 2020-09-15 | 2022-08-09 | 이상용 | System and method for review and makemoney platform operation |
KR102340807B1 (en) | 2021-03-30 | 2021-12-20 | 쿠팡 주식회사 | Operating method for electronic apparatus for offering item information and electronic apparatus supporting thereof |
JP7401950B1 (en) | 2023-07-25 | 2023-12-20 | 株式会社すなおネット | Information provision system |
Family Cites Families (67)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5544650A (en) * | 1988-04-08 | 1996-08-13 | Neuromedical Systems, Inc. | Automated specimen classification system and method |
US6092105A (en) * | 1996-07-12 | 2000-07-18 | Intraware, Inc. | System and method for vending retail software and other sets of information to end users |
US6285999B1 (en) * | 1997-01-10 | 2001-09-04 | The Board Of Trustees Of The Leland Stanford Junior University | Method for node ranking in a linked database |
US6064980A (en) * | 1998-03-17 | 2000-05-16 | Amazon.Com, Inc. | System and methods for collaborative recommendations |
US6317722B1 (en) * | 1998-09-18 | 2001-11-13 | Amazon.Com, Inc. | Use of electronic shopping carts to generate personal recommendations |
US6260064B1 (en) * | 1999-01-08 | 2001-07-10 | Paul J. Kurzrok | Web site with automatic rating system |
US6598026B1 (en) * | 1999-01-25 | 2003-07-22 | Nextag.Com, Inc. | Methods and apparatus for brokering transactions |
US7302429B1 (en) * | 1999-04-11 | 2007-11-27 | William Paul Wanker | Customizable electronic commerce comparison system and method |
US7433832B1 (en) * | 1999-11-19 | 2008-10-07 | Amazon.Com, Inc. | Methods and systems for distributing information within a dynamically defined community |
US8321496B2 (en) * | 1999-12-13 | 2012-11-27 | Half.Com, Inc. | User evaluation of content on distributed communication network |
US6546388B1 (en) * | 2000-01-14 | 2003-04-08 | International Business Machines Corporation | Metadata search results ranking system |
JP2001209655A (en) * | 2000-01-28 | 2001-08-03 | Nec Corp | Information providing device, information updating method, recording medium having information providing program recorded thereon and information providing system |
US20040205065A1 (en) * | 2000-02-10 | 2004-10-14 | Petras Gregory J. | System for creating and maintaining a database of information utilizing user opinions |
US6963848B1 (en) * | 2000-03-02 | 2005-11-08 | Amazon.Com, Inc. | Methods and system of obtaining consumer reviews |
JP2001265792A (en) * | 2000-03-15 | 2001-09-28 | Rikogaku Shinkokai | Device and method for automatically generating summary sentence and medium having the method recorded thereon |
US7246110B1 (en) * | 2000-05-25 | 2007-07-17 | Cnet Networks, Inc. | Product feature and relation comparison system |
US6892179B1 (en) * | 2000-06-02 | 2005-05-10 | Open Ratings Inc. | System and method for ascribing a reputation to an entity |
US6892178B1 (en) * | 2000-06-02 | 2005-05-10 | Open Ratings Inc. | Method and system for ascribing a reputation to an entity from the perspective of another entity |
US20020046203A1 (en) * | 2000-06-22 | 2002-04-18 | The Sony Corporation/Sony Electronics Inc. | Method and apparatus for providing ratings of web sites over the internet |
US6807566B1 (en) * | 2000-08-16 | 2004-10-19 | International Business Machines Corporation | Method, article of manufacture and apparatus for processing an electronic message on an electronic message board |
KR100418388B1 (en) * | 2000-08-31 | 2004-02-11 | 유종오 | A method to support determination of a purchase at electronic commerce and a system thereof |
KR20010025294A (en) * | 2000-12-08 | 2001-04-06 | 한동철 | A method for furnishing goods' review information |
JP2002183033A (en) * | 2000-12-11 | 2002-06-28 | Connect Corp | Electronic bulletin board system |
US7406436B1 (en) * | 2001-03-22 | 2008-07-29 | Richard Reisman | Method and apparatus for collecting, aggregating and providing post-sale market data for an item |
US7428496B1 (en) * | 2001-04-24 | 2008-09-23 | Amazon.Com, Inc. | Creating an incentive to author useful item reviews |
US7013303B2 (en) * | 2001-05-04 | 2006-03-14 | Sun Microsystems, Inc. | System and method for multiple data sources to plug into a standardized interface for distributed deep search |
US20020193066A1 (en) * | 2001-06-15 | 2002-12-19 | Connelly Jay H. | Methods and apparatus for providing rating feedback for content in a broadcast system |
US20040030525A1 (en) * | 2001-10-18 | 2004-02-12 | Gary Robinson | Method and system for identifying high-quality items |
WO2003034637A2 (en) * | 2001-10-18 | 2003-04-24 | Transpose, Llc | System and method for measuring rating reliability through rater prescience |
US7039631B1 (en) * | 2002-05-24 | 2006-05-02 | Microsoft Corporation | System and method for providing search results with configurable scoring formula |
US6983280B2 (en) * | 2002-09-13 | 2006-01-03 | Overture Services Inc. | Automated processing of appropriateness determination of content for search listings in wide area network searches |
US7461051B2 (en) * | 2002-11-11 | 2008-12-02 | Transparensee Systems, Inc. | Search method and system and system using the same |
US7031970B2 (en) * | 2002-12-16 | 2006-04-18 | Palo Alto Research Center Incorporated | Method and apparatus for generating summary information for hierarchically related information |
US7467206B2 (en) * | 2002-12-23 | 2008-12-16 | Microsoft Corporation | Reputation system for web services |
US7028029B2 (en) * | 2003-03-28 | 2006-04-11 | Google Inc. | Adaptive computation of ranking |
US20040225672A1 (en) * | 2003-05-05 | 2004-11-11 | Landers Kevin D. | Method for editing a web site |
JP4253532B2 (en) * | 2003-06-02 | 2009-04-15 | シャープ株式会社 | Information recommendation device, information recommendation program, and recording medium |
JP3921540B2 (en) * | 2003-08-08 | 2007-05-30 | 独立行政法人情報通信研究機構 | Document set classification device and program thereof |
US7363214B2 (en) * | 2003-08-08 | 2008-04-22 | Cnet Networks, Inc. | System and method for determining quality of written product reviews in an automated manner |
US7516086B2 (en) * | 2003-09-24 | 2009-04-07 | Idearc Media Corp. | Business rating placement heuristic |
US7165119B2 (en) * | 2003-10-14 | 2007-01-16 | America Online, Inc. | Search enhancement system and method having rankings, explicitly specified by the user, based upon applicability and validity of search parameters in regard to a subject matter |
US8200477B2 (en) * | 2003-10-22 | 2012-06-12 | International Business Machines Corporation | Method and system for extracting opinions from text documents |
US7885850B2 (en) * | 2003-11-20 | 2011-02-08 | Ebay Inc. | Automated feedback cancellation in a network-based transaction facility |
US20050131918A1 (en) * | 2003-12-12 | 2005-06-16 | W. Daniel Hillis | Personalized profile for evaluating content |
US20050137939A1 (en) * | 2003-12-19 | 2005-06-23 | Palo Alto Research Center Incorporated | Server-based keyword advertisement management |
JP2005234635A (en) * | 2004-02-17 | 2005-09-02 | Fuji Xerox Co Ltd | Document summarizing device and method |
EP1743287A4 (en) * | 2004-02-27 | 2009-02-25 | Daniel Abrahamsohn | Method of and system for obtaining data from multiple sources and raking documents based on meta data obtained through collaborative filtering and other matching techniques |
US7343374B2 (en) * | 2004-03-29 | 2008-03-11 | Yahoo! Inc. | Computation of page authority weights using personalized bookmarks |
US20070294127A1 (en) * | 2004-08-05 | 2007-12-20 | Viewscore Ltd | System and method for ranking and recommending products or services by parsing natural-language text and converting it into numerical scores |
US7493320B2 (en) * | 2004-08-16 | 2009-02-17 | Telenor Asa | Method, system, and computer program product for ranking of documents using link analysis, with remedies for sinks |
US20060143158A1 (en) * | 2004-12-14 | 2006-06-29 | Ruhl Jan M | Method, system and graphical user interface for providing reviews for a product |
US7962461B2 (en) * | 2004-12-14 | 2011-06-14 | Google Inc. | Method and system for finding and aggregating reviews for a product |
CA2591441A1 (en) * | 2004-12-14 | 2006-06-22 | Google, Inc. | Method, system and graphical user interface for providing reviews for a product |
US7519562B1 (en) * | 2005-03-31 | 2009-04-14 | Amazon Technologies, Inc. | Automatic identification of unreliable user ratings |
US20060277290A1 (en) * | 2005-06-02 | 2006-12-07 | Sam Shank | Compiling and filtering user ratings of products |
US20060282762A1 (en) * | 2005-06-10 | 2006-12-14 | Oracle International Corporation | Collaborative document review system |
US8249915B2 (en) * | 2005-08-04 | 2012-08-21 | Iams Anthony L | Computer-implemented method and system for collaborative product evaluation |
US7693901B2 (en) * | 2005-08-10 | 2010-04-06 | Microsoft Corporation | Consumer-focused results ordering |
US20070078669A1 (en) * | 2005-09-30 | 2007-04-05 | Dave Kushal B | Selecting representative reviews for display |
US7827052B2 (en) * | 2005-09-30 | 2010-11-02 | Google Inc. | Systems and methods for reputation management |
US7558769B2 (en) * | 2005-09-30 | 2009-07-07 | Google Inc. | Identifying clusters of similar reviews and displaying representative reviews from multiple clusters |
US20070078851A1 (en) * | 2005-10-05 | 2007-04-05 | Grell Mathew L | System and method for filtering search query results |
US7620651B2 (en) * | 2005-11-15 | 2009-11-17 | Powerreviews, Inc. | System for dynamic product summary based on consumer-contributed keywords |
US8015484B2 (en) * | 2006-02-09 | 2011-09-06 | Alejandro Backer | Reputation system for web pages and online entities |
US8615440B2 (en) * | 2006-07-12 | 2013-12-24 | Ebay Inc. | Self correcting online reputation |
US7509230B2 (en) * | 2006-11-17 | 2009-03-24 | Irma Becerra Fernandez | Method for rating an entity |
US8977631B2 (en) * | 2007-04-16 | 2015-03-10 | Ebay Inc. | Visualization of reputation ratings |
-
2005
- 2005-09-30 US US11/241,701 patent/US20070078670A1/en not_active Abandoned
-
2006
- 2006-09-29 JP JP2008533768A patent/JP5281405B2/en not_active Expired - Fee Related
- 2006-09-29 KR KR1020087010131A patent/KR101498001B1/en active IP Right Grant
- 2006-09-29 CA CA002624066A patent/CA2624066A1/en not_active Abandoned
- 2006-09-29 EP EP11189258A patent/EP2428928A1/en not_active Withdrawn
- 2006-09-29 WO PCT/US2006/038552 patent/WO2007041545A2/en active Application Filing
- 2006-09-29 EP EP06825371A patent/EP1949332A4/en not_active Withdrawn
- 2006-09-29 CA CA2755195A patent/CA2755195A1/en not_active Abandoned
- 2006-09-29 CN CNA2006800436207A patent/CN101313330A/en active Pending
-
2012
- 2012-04-18 JP JP2012094673A patent/JP5662961B2/en active Active
-
2013
- 2013-06-03 JP JP2013117227A patent/JP2013168186A/en active Pending
Also Published As
Publication number | Publication date |
---|---|
JP5281405B2 (en) | 2013-09-04 |
CA2755195A1 (en) | 2007-04-12 |
JP2009510637A (en) | 2009-03-12 |
WO2007041545A3 (en) | 2007-11-29 |
CA2624066A1 (en) | 2007-04-12 |
CN101313330A (en) | 2008-11-26 |
KR101498001B1 (en) | 2015-03-04 |
JP2013168186A (en) | 2013-08-29 |
JP2012160201A (en) | 2012-08-23 |
WO2007041545A2 (en) | 2007-04-12 |
EP1949332A2 (en) | 2008-07-30 |
EP2428928A1 (en) | 2012-03-14 |
EP1949332A4 (en) | 2011-08-24 |
JP5662961B2 (en) | 2015-02-04 |
US20070078670A1 (en) | 2007-04-05 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
KR101498001B1 (en) | Selecting high quality reviews for display | |
US8010480B2 (en) | Selecting high quality text within identified reviews for display in review snippets | |
US7558769B2 (en) | Identifying clusters of similar reviews and displaying representative reviews from multiple clusters | |
US20070078669A1 (en) | Selecting representative reviews for display | |
KR101721338B1 (en) | Search engine and implementation method thereof | |
JP5731250B2 (en) | System and method for recommending interesting content in an information stream | |
US7756720B2 (en) | Method and system for the objective quantification of fame | |
KR101700352B1 (en) | Generating improved document classification data using historical search results | |
US7966337B2 (en) | System and method for prioritizing websites during a webcrawling process | |
US8346792B1 (en) | Query generation using structural similarity between documents | |
US20100125531A1 (en) | System and method for the automated filtering of reviews for marketability | |
JP2008507041A (en) | Personalize the ordering of place content in search results | |
US20140067832A1 (en) | Establishing "is a" relationships for a taxonomy | |
EP3622444A1 (en) | Improved onboarding of entity data | |
JP4569380B2 (en) | Vector generation method and apparatus, category classification method and apparatus, program, and computer-readable recording medium storing program | |
US20050102619A1 (en) | Document processing device, method and program for summarizing evaluation comments using social relationships | |
US20140095411A1 (en) | Establishing "is a" relationships for a taxonomy | |
JP4883644B2 (en) | RECOMMENDATION DEVICE, RECOMMENDATION SYSTEM, RECOMMENDATION DEVICE CONTROL METHOD, AND RECOMMENDATION SYSTEM CONTROL METHOD | |
CN111737607A (en) | Data processing method, data processing device, electronic equipment and storage medium | |
JP4755834B2 (en) | Attribute evaluation apparatus, attribute evaluation method, and attribute evaluation program | |
JP2009187384A (en) | Retrieval device, retrieval method, retrieval program, and recording medium | |
JP4977004B2 (en) | Related keyword extraction method and apparatus, program, and computer-readable recording medium | |
JP2007052693A (en) | Webpage information display apparatus, processing method and program | |
JP6655981B2 (en) | Keyword extraction device, keyword extraction method, and program | |
Rosnes | Evaluating Feature-Specific Similarity Metrics using Human Judgments for Norwegian News |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A201 | Request for examination | ||
E902 | Notification of reason for refusal | ||
E601 | Decision to refuse application | ||
J201 | Request for trial against refusal decision | ||
J301 | Trial decision |
Free format text: TRIAL DECISION FOR APPEAL AGAINST DECISION TO DECLINE REFUSAL REQUESTED 20131007Effective date: 20141208 |
|
S901 | Examination by remand of revocation | ||
GRNO | Decision to grant (after opposition) | ||
GRNT | Written decision to grant | ||
FPAY | Annual fee payment |
Payment date: 20180208Year of fee payment: 4 |
|
FPAY | Annual fee payment |
Payment date: 20190212Year of fee payment: 5 |
|
FPAY | Annual fee payment |
Payment date: 20200214Year of fee payment: 6 |