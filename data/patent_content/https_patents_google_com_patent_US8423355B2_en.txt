US8423355B2 - Encoder for audio signal including generic audio and speech frames - Google Patents
Encoder for audio signal including generic audio and speech frames Download PDFInfo
- Publication number
- US8423355B2 US8423355B2 US12/844,199 US84419910A US8423355B2 US 8423355 B2 US8423355 B2 US 8423355B2 US 84419910 A US84419910 A US 84419910A US 8423355 B2 US8423355 B2 US 8423355B2
- Authority
- US
- United States
- Prior art keywords
- frame
- audio
- samples
- coded
- frames
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Expired - Fee Related, expires
Links
Images
Classifications
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L19/00—Speech or audio signals analysis-synthesis techniques for redundancy reduction, e.g. in vocoders; Coding or decoding of speech or audio signals, using source filter models or psychoacoustic analysis
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L19/00—Speech or audio signals analysis-synthesis techniques for redundancy reduction, e.g. in vocoders; Coding or decoding of speech or audio signals, using source filter models or psychoacoustic analysis
- G10L19/04—Speech or audio signals analysis-synthesis techniques for redundancy reduction, e.g. in vocoders; Coding or decoding of speech or audio signals, using source filter models or psychoacoustic analysis using predictive techniques
- G10L19/16—Vocoder architecture
- G10L19/18—Vocoders using multiple modes
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L19/00—Speech or audio signals analysis-synthesis techniques for redundancy reduction, e.g. in vocoders; Coding or decoding of speech or audio signals, using source filter models or psychoacoustic analysis
- G10L19/04—Speech or audio signals analysis-synthesis techniques for redundancy reduction, e.g. in vocoders; Coding or decoding of speech or audio signals, using source filter models or psychoacoustic analysis using predictive techniques
- G10L19/16—Vocoder architecture
- G10L19/18—Vocoders using multiple modes
- G10L19/20—Vocoders using multiple modes using sound class specific coding, hybrid encoders or object based coding
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L19/00—Speech or audio signals analysis-synthesis techniques for redundancy reduction, e.g. in vocoders; Coding or decoding of speech or audio signals, using source filter models or psychoacoustic analysis
- G10L19/02—Speech or audio signals analysis-synthesis techniques for redundancy reduction, e.g. in vocoders; Coding or decoding of speech or audio signals, using source filter models or psychoacoustic analysis using spectral analysis, e.g. transform vocoders or subband vocoders
- G10L19/0212—Speech or audio signals analysis-synthesis techniques for redundancy reduction, e.g. in vocoders; Coding or decoding of speech or audio signals, using source filter models or psychoacoustic analysis using spectral analysis, e.g. transform vocoders or subband vocoders using orthogonal transformation
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L19/00—Speech or audio signals analysis-synthesis techniques for redundancy reduction, e.g. in vocoders; Coding or decoding of speech or audio signals, using source filter models or psychoacoustic analysis
- G10L19/04—Speech or audio signals analysis-synthesis techniques for redundancy reduction, e.g. in vocoders; Coding or decoding of speech or audio signals, using source filter models or psychoacoustic analysis using predictive techniques
- G10L19/08—Determination or coding of the excitation function; Determination or coding of the long-term prediction parameters
- G10L19/12—Determination or coding of the excitation function; Determination or coding of the long-term prediction parameters the excitation function being a code excitation, e.g. in code excited linear prediction [CELP] vocoders
Definitions
- the present disclosure relates generally to speech and audio processing and, more particularly, to an encoder for processing an audio signal including generic audio and speech frames.
- LPC Linear Predictive Coding
- CELP Code Excited Linear Prediction
- FIG. 1 illustrates an audio gap produced between a processed speech frame and a processed generic audio frame in a sequence of output frames.
- FIG. 1 also illustrates, at 102 , a sequence of input frames that may be classified as speech frames (m ⁇ 2) and (m ⁇ 1) followed by generic audio frames (m) and (m+1).
- the sample index n corresponds to the samples obtained at time n within the series of frames.
- frame (m) may be processed after 320 new samples have been accumulated, which are combined with 160 previously accumulated samples, for a total of 480 samples.
- the sampling frequency is 16 kHz and the corresponding frame size is 20 milliseconds, although many sampling rates and frame sizes are possible.
- the speech frames may be processed using Linear Predictive Coding (LPC) speech coding, wherein the LPC analysis windows are illustrated at 104 .
- a processed speech frame (m ⁇ 1) is illustrated at 106 and is preceded by a coded speech frame (m ⁇ 2), which is not illustrated, corresponding to the input frame (m ⁇ 2).
- the generic audio analysis/synthesis windows correspond to the amplitude envelope of the processed generic audio frame.
- the sequence of processed frames 106 and 108 are offset in time relative to the sequence of input frames 102 due to algorithmic processing delay, also referred to herein as look-ahead delay and overlap-add delay for the speech and generic audio frames, respectively.
- the overlapping portions of the coded generic audio frames (m) and (m+1) at 108 in FIG. 1 provide an additive effect on the corresponding sequential processed generic audio frames (m) and (m+1) at 110 .
- the leading tail of the coded generic audio frame (m) at 108 does not overlap with a trailing tail of an adjacent generic audio frame since the preceding frame is a coded speech frame.
- the leading portion of the corresponding processed generic audio frame (m) at 108 has reduced amplitude.
- the result of combining the sequence of coded speech and generic audio frames is an audio gap between the processed speech frame and the processed generic audio frame in the sequence of processed output frames, as shown in the composite output frames at 110 .
- U.S. Publication No. 2006/0173675 entitled “Switching Between Coding Schemes” discloses a hybrid coder that accommodates both speech and music by selecting, on a frame-by-frame basis, between an adaptive multi-rate wideband (AMR-WB) codec and a codec utilizing a modified discrete cosine transform (MDCT), for example, an MPEG 3 codec or a (AAC) codec, whichever is most appropriate.
- AMR-WB adaptive multi-rate wideband
- MDCT modified discrete cosine transform
- MPEG 3 codec MPEG 3 codec
- AAC AAC
- the special MDCT analysis/synthesis window disclosed by Nokia comprises three constituent overlapping sinusoidal based windows, H 0 (n), H 1 (n) and H 2 (n) that are applied to the first input music frame following a speech frame to provide an improved processed music frame.
- This method may be subject to signal discontinuities that may arise from under-modeling of the associated spectral regions defined by H 0 (n), H 1 (n) and H 2 (n). That is, the limited number of bits that may be available need to be distributed across the three regions, while still being required to produce a nearly perfect waveform match between the end of the previous speech frame and the beginning of region H 0 (n).
- FIG. 1 illustrates a conventionally processed sequence of speech and generic audio frames having an audio gap.
- FIG. 2 is a schematic block diagram of a hybrid speech and generic audio signal coder.
- FIG. 3 is a schematic block diagram of a hybrid speech and generic audio signal decoder.
- FIG. 4 illustrates an audio signal encoding process
- FIG. 5 illustrates a sequence of speech and generic audio frames subject to a non-conventional coding process.
- FIG. 6 illustrates a sequence of speech and generic audio frames subject to another non-conventional coding process.
- FIG. 7 illustrates an audio decoding process
- FIG. 2 illustrates a hybrid core coder 200 configured to code an input stream of frames some of which are speech frames and others of which are less speech-like frames.
- the less speech like frames are referred to herein as generic audio frames.
- the hybrid core codec comprises a mode selector 210 that processes frames of an input audio signal s(n), where n is the sample index.
- Frame lengths may comprise 320 samples of audio when the sampling rate is 16 k samples per second, which corresponds to a frame time interval of 20 milliseconds, although many other variations are possible.
- the mode selector is configured to assess whether a frame in the sequence of input frames is more or less speech-like based on an evaluation of attributes or characteristics specific to each frame.
- a mode selection codeword is provided to a multiplexor 220 .
- the codeword indicates, on a frame by frame basis, the mode by which a corresponding frame of the input signal was processed.
- an input audio frame may be processed as a speech signal or as a generic audio signal, wherein the codeword indicates how the frame was processed and particularly what type of audio coder was used to process the frame.
- the codeword may also convey information regarding a transition from speech to generic audio. Although the transition information may be implied from the previous frame classification type, the channel over which the information is transmitted may be lossy and therefore information about the previous frame type may not be available.
- the codec generally comprises a first coder 230 suitable for coding speech frames and a second coder 240 suitable for coding generic audio frames.
- the speech coder is based on a source-filter model suitable for processing speech signals and the generic audio coder is a linear orthogonal lapped transform based on time domain aliasing cancellation (TDAC).
- TDAC time domain aliasing cancellation
- the speech coder may utilize Linear Predictive Coding (LPC) typical of a Code Excited Linear Predictive (CELP) coder, among other coders suitable for processing speech signals.
- LPC Linear Predictive Coding
- CELP Code Excited Linear Predictive
- the generic audio coder may be implemented as Modified Discrete Cosine Transform (MDCT) codec or a Modified Discrete Sine Transform (MSCT) or forms of the MDCT based on different types of Discrete Cosine Transform (DCT) or DCT/Discrete Sine Transform (DST) combinations.
- MDCT Modified Discrete Cosine Transform
- MSCT Modified Discrete Sine Transform
- DCT Discrete Cosine Transform
- DST DCT/Discrete Sine Transform
- the first and second coders 230 and 240 have inputs coupled to the input audio signal by a selection switch 250 that is controlled based on the mode selected or determined by the mode selector 210 .
- the switch 250 may be controlled by a processor based on the codeword output of the mode selector.
- the switch 250 selects the speech coder 230 for processing speech frames and the switch selects the generic audio coder for processing generic audio frames.
- Each frame may be processed by only one coder, e.g., either the speech coder or the generic audio coder, by virtue of the selection switch 250 . More generally, while only two coders are illustrated in FIG. 2 , the frames may be coded by one of several different coders. For example, one of three or more coders may be selected to process a particular frame of the input audio signal. In other embodiments, however, each frame may be coded by all coders as discussed further below.
- each codec produces an encoded bitstream and a corresponding processed frame based on the corresponding input audio frame processed by the coder.
- the processed frame produced by the speech coder is indicated by ⁇ s (n), while the processed frame produced by the generic audio coder is indicated by ⁇ a (n).
- a switch 252 on the output of the coders 230 and 240 couples the coded output of the selected coder to the multiplexer 220 . More particularly, the switch couples the encoded bitstream output of the coder to the multiplexor.
- the switch 252 is also controlled based on the mode selected or determined by the mode selector 210 . For example, the switch 252 may be controlled by a processor based on the codeword output of the mode selector.
- the multiplexor multiplexes the codeword with the encoded bitstream output of the corresponding coder selected based on the codeword.
- the switch 252 couples the output of the generic audio coder 240 to the multiplexor 220
- the switch 252 couples the output of the speech coder 230 to the multiplexor.
- a special “transition mode” frame is utilized in accordance with the present disclosure.
- the transition mode encoder comprises generic audio coder 240 and audio gap encoder 260 , the details of which are described as follows.
- FIG. 4 illustrates a coding process 400 implemented in a hybrid audio signal processing codec, for example the hybrid codec of FIG. 2 .
- a first frame of coded audio samples is produced by coding a first audio frame in a sequence of frames.
- the first coded frame of audio samples is a coded speech frame produced or generated using a speech codec.
- an input speech/audio frame sequence 502 comprises sequential speech frames (m ⁇ 2) and (m ⁇ 1) and a subsequent generic audio frame (m).
- the speech frames (m ⁇ 2) and (m ⁇ 1) may be coded based in part on LPC analysis windows, both illustrated at 504 .
- a coded speech frame corresponding to the input speech frame (m ⁇ 1) is illustrated at 506 .
- This frame may be preceded by another coded speech frame, not illustrated, corresponding to the input frame (m ⁇ 2).
- the coded speech frames are delayed relative to the corresponding input frames by an interval resulting from algorithmic delay associated with the LPC “look-ahead” processing buffer, i.e., the audio samples ahead of the frame that are required to estimate the LPC parameters that are centered around the end (or near the end) of the coded speech frame.
- At 420 at least a portion of a second frame of coded audio samples is produced by coding at least a portion of a second audio frame in the sequence of frames.
- the second frame is adjacent the first frame.
- the second coded frame of audio samples is a coded generic audio frame produced or generated using a generic audio codec.
- frame “m” in the input speech/audio frame sequence 502 is a generic audio frame that is coded based on a TDAC based linear orthogonal lapped transform analysis/synthesis window (m) illustrated at 508 .
- a subsequent generic audio frame (m+1) in the sequence of input frames 502 is coded with an overlapping analysis/synthesis window (m+1) illustrated at 508 .
- FIG. 5 frame “m” in the input speech/audio frame sequence 502 is a generic audio frame that is coded based on a TDAC based linear orthogonal lapped transform analysis/synthesis window (m) illustrated at 508 .
- a subsequent generic audio frame (m+1) in the sequence of input frames 502 is code
- the generic audio analysis/synthesis windows correspond in amplitude to the processed generic audio frame.
- the overlapping portions of the analysis/synthesis windows (m) and (m+1) at 508 in FIG. 5 provide an additive effect on the corresponding sequential processed generic audio frames (m) and (m+1) of the input frame sequence. The result is that the trailing tail of the processed generic audio frame corresponding to the input frame (m) and the leading tail of the adjacent processed frame corresponding to input frame (m+1) are not attenuated.
- the MDCT output in the overlap region between ⁇ 480 and ⁇ 400 is zero. It is not known how to have alias free generation of all 320 samples of the generic audio frame (m), and at the same time generate some samples for overlap add with the MDCT output of the subsequent generic audio frame (m+1) using the MDCT of the same order as the MDCT order of the regular audio frame. According to one aspect of the disclosure, compensation is provided for the audio gap that would otherwise occur between a processed generic audio frame following a processed speech frame, as discussed below.
- n is the sample index within the current frame
- w m (n) is the corresponding analysis and synthesis window at frame m
- M is the associated frame length.
- w ⁇ ( n ) sin ⁇ [ ( n + 1 2 ) ⁇ ⁇ 2 ⁇ M ] , 0 ⁇ n ⁇ 2 ⁇ M , ( 3 )
- the algorithmic delay of the generic audio coding overlap-add process is reduced by zero-padding the 2M frame structure as follows:
- w ⁇ ( n ) ⁇ 0 , 0 ⁇ n ⁇ M 4 , sin ⁇ [ ( n - M 4 + 1 2 ) ⁇ ⁇ M ] , M 4 ⁇ n ⁇ 3 ⁇ M 4 , 1 , 3 ⁇ M 4 ⁇ n ⁇ 5 ⁇ M 4 , cos ⁇ [ ( n - 5 ⁇ M 4 + 1 2 ) ⁇ ⁇ M ] , 5 ⁇ M 4 ⁇ n ⁇ 7 ⁇ M 4 , 0 , 7 ⁇ M 4 ⁇ n ⁇ 2 ⁇ M , ( 4 )
- the speech-to-audio frame transition window is given in the present disclosure as:
- w ⁇ ( n ) ⁇ 0 , 0 ⁇ n ⁇ M 2 , 1 , M 2 ⁇ n ⁇ 5 ⁇ M 4 , cos ⁇ [ ( n - 5 ⁇ M 4 + 1 2 ) ⁇ ⁇ 2 ⁇ M ] , 5 ⁇ M 4 ⁇ n ⁇ 7 ⁇ M 4 , 0 , 7 ⁇ M 4 ⁇ n ⁇ 2 ⁇ M , ( 9 )
- the “audio gap” is then formed as the samples corresponding to 0 ⁇ n ⁇ M/2, which occur after the end of the speech frame (m ⁇ 1), are forced to zero.
- parameters for generating audio gap filler samples or compensation samples are produced, wherein the audio gap filler samples may be used to compensate for the audio gap between the processed speech frame and the processed generic audio frame.
- the parameters are generally multiplexed as part of the coded bitstream and stored for later use or communicated to the decoder, as described further below.
- FIG. 2 we call them the “audio gap samples coded bitstream”.
- the audio gap filler samples constitute a coded gap frame indicated by ⁇ g (n) as discussed further below.
- the parameters are representative of a weighted segment of the first frame of coded audio samples and/or a weighted segment of the portion of the second frame of coded audio samples.
- the audio gap filler samples generally constitute a processed audio gap frame that fills the gap between the processed speech frame and the processed generic audio frame.
- the parameters may be stored or communicated to another device and used to generate the audio gap filler samples, or frame, for filling the audio gap between the processed speech frame and the processed generic audio frame, as described further below.
- the encoder does not necessarily generate the audio gap filler samples although in some use cases it is desirable to generate audio gap filler samples at the encoder.
- the parameters include a first weighting parameter and a first index for a weighted segment of the first frame, e.g., the speech frame, of coded audio samples, and a second weighting parameter and a second index for a weighted segment of the portion of the second frame, e.g., the generic audio frame, of coded audio samples.
- the parameters may be constant values or functions.
- the first index specifies a first time offset from a reference audio gap sample in the sequence of input frames to a corresponding sample in the segment of the first frame of coded audio samples (e.g., the coded speech frame), and the second index specifies a second time offset from the reference audio gap sample to a corresponding sample in the segment of the portion of the second frame of coded audio samples (e.g., the coded generic speech frame).
- the first weighting parameter comprises a first gain factor that is applied to the corresponding samples in the indexed segment of the first frame.
- the second weighting parameter comprises a second gain factor that is applied to the corresponding samples in the indexed segment of the portion of the second frame.
- the first offset is T 1 and the second offset is T 2 .
- ⁇ represents the first weighting parameter and ⁇ represents the second weighting parameter.
- the reference audio gap sample could be any location in the audio gap between the coded speech frame and the coded generic audio frame, for example, the first or last locations or a sample there between.
- We refer to the reference gap samples as s g (n), where n 0, . . . , L ⁇ 1, and L is the number of gap samples.
- the parameters are generally selected to reduce distortion between the audio gap filler samples that are generated using the parameters and a set of samples, s g (n), in the sequence of frames corresponding to the audio gap, wherein the set of samples are referred to as a set of reference audio gap samples.
- the parameters may be based on a distortion metric that is a function of a set of reference audio gap samples in the sequence of input frames.
- the distortion metric is a squared error distortion metric.
- the distortion metric is a weighted mean squared error distortion metric.
- the first index is determined based on a correlation between a segment of the first frame of coded audio samples and a segment of reference audio gap samples in the sequence of frames.
- the second index is also determined based on a correlation between a segment of the portion of the second frame of coded audio samples and the segment of reference audio gap samples.
- the first offset and weighted segment ⁇ s (n ⁇ T 1 ) are determined by correlating the set of reference gap samples s g (n) in the sequence of frames 502 with the coded speech frame at 506 .
- the second offset and weighted segment ⁇ a (n+T 2 ) are determined by correlating the set of samples s g (n) in the sequence of frames 502 with the coded generic audio frame at 508 .
- the audio gap filler samples are generated based on specified parameters and based on the first and/or second frames of coded audio samples.
- the coded gap frame ⁇ g (n) comprising such coded audio gap filler samples is illustrated at 510 in FIG. 5 .
- the coded gap frame samples ⁇ g (n) may be combined with the coded generic audio frame (m) to provide a relatively continuous transition with the coded speech frame (m ⁇ 1) as illustrated at 512 in FIG. 5 .
- the gap region is coded by generating an estimate ⁇ g from the speech frame output ⁇ s of the previous frame (m ⁇ 1) and the portion of the generic audio frame output ⁇ a of the current frame (m).
- ⁇ s ( ⁇ T) be a vector of length L starting from T th past sample of ⁇ s
- ⁇ a (T) be a vector of length L starting from the T th future sample of ⁇ a (see FIG. 5 ).
- T 1 , T 2 , ⁇ , and ⁇ are obtained to minimize a distortion between s g and ⁇ g .
- T 1 and T 2 are integer valued where 160 ⁇ T 1 ⁇ 260 and 0 ⁇ T 2 ⁇ 80.
- a 6 bit scalar quantizer is used for coding each of the parameters ⁇ and ⁇ .
- the gap is coded using 25 bits.
- a method for determining these parameters is given as follows.
- W is a weighting matrix used for finding optimal parameters
- T denotes the vector transpose.
- W is a positive definite matrix and is preferably a diagonal matrix. If W is an identity matrix, then the distortion is a mean squared distortion.
- Equation (20) The values of ⁇ and ⁇ are subsequently quantized using six bit scalar quantizers.
- a joint exhaustive search method for T 1 and T 2 has been described above.
- the joint search is generally complex however various relatively low complexity approaches may be adopted for this search.
- the search for T 1 and T 2 can be first decimated by a factor greater than 1 and then the search can be localized.
- the first weighted segment ⁇ s ( ⁇ T 1 ) or the second weighted segment ⁇ a (T 2 ) may be used to construct the coder audio gap filler samples represented ⁇ g . That is, in one embodiment, it is possible that only one set of parameters for the weighted segments is generated and used by the decoder to reconstruct the audio gap filler samples. Furthermore, there may be embodiments which consistently favor one weighted segment over the other. In such cases, the distortion may be reduced by considering only one of the weighted segments.
- the input speech and audio frame sequence 602 , the LPC speech analysis window 604 , and the coded gap frame 610 are the same as in FIG. 5 .
- the trailing tail of the coded speech frame is tapered, as illustrated at 606 in FIG. 6
- the leading tail of the coded gap frame is tapered as illustrated in 612 .
- the leading tail of the coded generic audio frame is tapered, as illustrated at 608 in FIG. 6
- the trailing tail of the coded gap frame is tapered as illustrated in 612 . Artifacts related to time-domain discontinuities are likely reduced most effectively when both the leading and trailing tails the coded gap frame are tapered.
- the combine output speech frame (m ⁇ 1) and the generic frame (m) include the coded gap frame having the tapered tails.
- not all samples of the generic audio frame (m) at 502 are included in the generic audio analysis/synthesis window at 508 .
- the first L samples of the generic audio frame (m) at 502 are excluded from the generic audio analysis/synthesis window.
- the number of samples excluded depends generally on the characteristic of the generic audio analysis/synthesis window forming the envelope for the processed generic audio frame. In one embodiment, the number of samples that are excluded is equal to 80. In other embodiments, a fewer or a greater number of samples may be excluded.
- the length of the remaining, non-zero region of the MDCT window is L less than the length of the MDCT window in regular audio frames.
- a window with the left end having a rectangular shape is preferred.
- using a window with a rectangular shape may result in more energy in the high frequency MDCT coefficients, which may be more difficult to code without significant loss using a limited number of bits.
- w ⁇ ( n ) ⁇ 0 , 0 ⁇ n ⁇ M 2 , sin ⁇ [ ( n - M 2 + 1 2 ) ⁇ ⁇ 2 ⁇ M 1 ] , M 2 ⁇ n ⁇ M 2 + M 1 , 1 , M 2 + M 1 ⁇ n ⁇ 5 ⁇ M 4 , cos ⁇ [ ( n - 5 ⁇ M 4 + 1 2 ) ⁇ ⁇ M ] , 5 ⁇ M 4 ⁇ n ⁇ 7 ⁇ M 4 , 0 , 7 ⁇ M 4 ⁇ n ⁇ 2 ⁇ M , ( 25 )
- weighted mean square methods are typically good for low frequency signals and tend to decrease the energy of high frequency signals.
- the audio mode output ⁇ a may have a tapering analysis and synthesis window and hence ⁇ a for delay T 2 such that ⁇ a (T 2 ) overlaps with the tapering region of ⁇ a .
- the gap region s g may not have a very good correlation with ⁇ a (T 2 ).
- it may be preferable to multiply ⁇ a with an equalizer window E to get an equalized audio signal: ⁇ ae E ⁇ a (26)
- Equation (10) Equation (10) and discussion following Equation (10).
- the Forward/Backward estimation method used for coding of the gap frame generally produces a good match for the gap signal but it sometimes results in discontinuities at both the end points, i.e., at the boundary of the speech part and gap regions as well at the boundary between the gap region and the generic audio coded part (see FIG. 5 ).
- the output of the speech part is first extended, for example by 15 samples.
- the extended speech may be obtained by extending the excitation using frame error mitigation processing in the speech coder, which is normally used to reconstruct frames that are lost during transmission.
- This extended speech part is overlap added (trapezoidal) with the first 15 samples of ⁇ g to obtain smoothed transition at the boundary of speech part and the gap.
- the last 50 samples of ⁇ g are first multiplied by (1 ⁇ w m 2 (n)) and then added to first 50 samples of ⁇ a .
- FIG. 3 illustrates a hybrid core decoder 300 configured to decode an encoded bitstream, for example, the combined bitstream encoded by the coder 200 of FIG. 2 .
- the coder 200 of FIG. 2 and the decoder 300 of FIG. 3 are combined to form a codec.
- the coder and decoder may be embodied or implemented separately.
- a demultiplexer separates constituent elements of a combined bitstream.
- the bitstream may be received from another entity over a communication channel, for example, over a wireless or wire-line channel, or the bitstream may be obtained from a storage medium accessible to or by the decoder.
- FIG. 3 illustrates a hybrid core decoder 300 configured to decode an encoded bitstream, for example, the combined bitstream encoded by the coder 200 of FIG. 2 .
- the coder 200 of FIG. 2 and the decoder 300 of FIG. 3 are combined to form a codec.
- the coder and decoder may be embodied or implemented separately.
- the combined bitstream is separated into a codeword and a sequence of coded audio frames comprising speech and generic audio frames.
- the codeword indicates on a frame-by-frame basis whether a particular frame in the sequence is a speech (SP) frame or generic audio (GA) frame.
- SP speech
- GA generic audio
- the transition information may be implied from the previous frame classification type, the channel over which the information is transmitted may be lossy and therefore information about the previous frame type may not be reliable or available.
- the codeword may also convey information regarding a transition from speech to generic audio.
- the decoder generally comprises a first decoder 320 suitable for coding speech frames and a second coder 330 suitable for decoding generic audio frames.
- the speech decoder is based on a source-filter model decoder suitable for processing decoding speech signals and the generic audio decoder is a linear orthogonal lapped transform decoder based on time domain aliasing cancellation (TDAC) suitable for decoding generic audio signals as described above. More generally, the configuration of the speech and generic audio decoders must complement that of the coder.
- one of the first and second decoders 320 and 330 have inputs coupled to the output of the demultiplexor by a selection switch 340 that is controlled based on the codeword or other means.
- the switch may be controlled by a processor based on the codeword output of the mode selector.
- the switch 340 selects the speech decoder 320 for processing speech frames and the generic audio decoder 330 for processing generic audio frames, depending on the audio frame type output by the demultiplexor.
- Each frame is generally processed by only one coder, e.g., either the speech coder or the generic audio coder, by virtue of the selection switch 340 .
- the selection may occur after decoding each frame by both decoders. More generally, while only two decoders are illustrated in FIG. 3 , the frames may be decoded by one of several decoders.
- FIG. 7 illustrates a decoding process 700 implemented in a hybrid audio signal processing codec or at least the hybrid decoder portion of FIG. 3 .
- the process also includes generation of an audio gap filler samples as described further below.
- a first frame of coded audio samples is produced and at 720 at least a portion of a second frame of coded audio samples is produced.
- FIG. 3 for example, when the bitstream output from the demultiplxor 310 includes a coded speech frame and a coded generic audio frame, a first frame of coded samples is produced using the speech decoder 320 and then at least a portion of a second frame of coded audio samples is produced using the generic audio decoder 330 .
- an audio gap is sometimes formed between the first frame of coded audio samples and the portion of the second frame of coded audio samples resulting in undesirable noise at the user interface.
- audio gap filler samples are generated based on parameters representative of a weighted segment of the first frame of coded audio samples and/or a weighted segment of the portion of the second frame of coded audio samples.
- an audio gap samples decoder 350 generates audio gap filler samples ⁇ g (n) from the processed speech frame ⁇ s (n) generated by the decoder 320 and/or from the processed generic audio frame ⁇ a (n) generated by the generic audio decoder 330 based on the parameters.
- the parameters are communicated to the audio gap decoder 350 as part of the coded bitstream.
- the parameters generally reduce distortion between the audio gap samples generated and a set of reference audio gap samples described above.
- the parameters include a first weighting parameter and a first index for the weighted segment of the first frame of coded audio samples, and a second weighting parameter and a second index for the weighted segment of the portion of the second frame of coded audio samples.
- the first index specifies a first time offset from a the audio gap filler sample to a corresponding sample in the segment of the first frame of coded audio samples
- the second reference specifies a second time offset from the audio gap filler sample to a corresponding sample in the segment of the portion of the second frame of coded audio samples.
- the audio filler gap samples generated by the audio gap decoder 350 are communicated to a sequencer 360 that combines the audio gap samples ⁇ g (n) with the second frame of coded audio samples ⁇ a (n) produced by the generic audio decoder 330 .
- the sequencer generally forms a sequence of sample that includes at least the audio gap filler samples and the portion of the second frame of coded audio samples.
- the sequence also includes the first frame of coded audio samples, wherein the audio gap filler samples at least partially fill an audio gap between the first frame of coded audio samples and the portion of the second frame of coded audio samples.
- the audio gap frame fills at least a portion of the audio gap between the first frame of coded audio samples and the portion of the second frame of coded audio sample, thereby eliminating or at least reducing any audible noise that may be perceived by the user.
- a switch 370 selects either the output of the speech decoder 320 or the combiner 360 based on the codeword, such that the decoded frames are recombined in an output sequence.
Abstract
Description
w m−1 2(M+n)+w m 2(n)=1,0≦n<M, and (1)
w m−1(M+n)w m−1(2M−n−1)−w m(M−n−1)=0,0≦n<M, (2)
w m 2(n)=1,0≦n<M, and (5)
w m(n)w m(M−n−1)=0,0≦n<M. (6)
w m(n)=1,M/2≦n<M, and (7)
w m(n)=0,0≦n<M/2. (8)
ŝ g =α·ŝ s(−T 1)+β·ŝ a(T 2) (10)
D=|s g −ŝ g|T ·W·|s g −ŝ g|, (11)
R gs =s g T ·W·ŝ s(−T 1), (12)
R ga =s g T ·W·ŝ a(T 2), (13)
R aa =ŝ a(T 2)T ·W·ŝ a(T 2), (14)
R ss =ŝ s(−T 1)T ·W·ŝ s(−T 1), and (15)
R as =ŝ a(T 2)T ·W·ŝ s(−T). (16)
δ(T 1 ,T 2)=R ss R aa −R as R as, (17)
η(T 1 ,T 2)=R aa R gs −R as R ga, (18)
γ(T 1 ,T 2)=R ss R ga −R as R gs. (19)
S=(η·R gs +γ·R ga)/δ. (20)
α=η(T 1 *,T 2*)/δ(T 1 *,T 2*) and (21)
β=γ(T 1 *,T 2*)/δ(T 1 *,T 2*) (22)
S=R gs R gs /R ss ,R ss>0, (23)
or
S=R ga R ga /R aa ,R>0 (24)
ŝ ae =E·ŝ a (26)
Claims (13)
ŝ g(n)=α·ŝ s(−T 1)+β·ŝ a(T 2)
D=|s g −ŝ g|T ·|s g −ŝ g|
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
IN217/KOL/2010 | 2010-03-05 | ||
IN217KO2010 | 2010-03-05 |
Publications (2)
Publication Number | Publication Date |
---|---|
US20110218797A1 US20110218797A1 (en) | 2011-09-08 |
US8423355B2 true US8423355B2 (en) | 2013-04-16 |
Family
ID=44278589
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US12/844,199 Expired - Fee Related US8423355B2 (en) | 2010-03-05 | 2010-07-27 | Encoder for audio signal including generic audio and speech frames |
Country Status (8)
Country | Link |
---|---|
US (1) | US8423355B2 (en) |
EP (1) | EP2543036B1 (en) |
KR (1) | KR101430332B1 (en) |
CN (1) | CN102834862B (en) |
BR (2) | BR112012022446A2 (en) |
CA (1) | CA2789297C (en) |
DK (1) | DK2543036T3 (en) |
WO (1) | WO2011109361A1 (en) |
Cited By (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20140088973A1 (en) * | 2012-09-26 | 2014-03-27 | Motorola Mobility Llc | Method and apparatus for encoding an audio signal |
US9256579B2 (en) | 2006-09-12 | 2016-02-09 | Google Technology Holdings LLC | Apparatus and method for low complexity combinatorial coding of signals |
US20160225387A1 (en) * | 2013-08-28 | 2016-08-04 | Dolby Laboratories Licensing Corporation | Hybrid waveform-coded and parametric-coded speech enhancement |
Families Citing this family (26)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8576096B2 (en) * | 2007-10-11 | 2013-11-05 | Motorola Mobility Llc | Apparatus and method for low complexity combinatorial coding of signals |
US8175888B2 (en) | 2008-12-29 | 2012-05-08 | Motorola Mobility, Inc. | Enhanced layered gain factor balancing within a multiple-channel audio coding system |
KR101137652B1 (en) * | 2009-10-14 | 2012-04-23 | 광운대학교 산학협력단 | Unified speech/audio encoding and decoding apparatus and method for adjusting overlap area of window based on transition |
WO2012086485A1 (en) * | 2010-12-20 | 2012-06-28 | 株式会社ニコン | Audio control device and image capture device |
US9942593B2 (en) * | 2011-02-10 | 2018-04-10 | Intel Corporation | Producing decoded audio at graphics engine of host processing platform |
JP5625126B2 (en) | 2011-02-14 | 2014-11-12 | フラウンホーファー−ゲゼルシャフト・ツール・フェルデルング・デル・アンゲヴァンテン・フォルシュング・アインゲトラーゲネル・フェライン | Linear prediction based coding scheme using spectral domain noise shaping |
PL3239978T3 (en) | 2011-02-14 | 2019-07-31 | Fraunhofer-Gesellschaft zur Förderung der angewandten Forschung e.V. | Encoding and decoding of pulse positions of tracks of an audio signal |
CA2827249C (en) | 2011-02-14 | 2016-08-23 | Fraunhofer-Gesellschaft Zur Foerderung Der Angewandten Forschung E.V. | Apparatus and method for processing a decoded audio signal in a spectral domain |
TWI488176B (en) | 2011-02-14 | 2015-06-11 | Fraunhofer Ges Forschung | Encoding and decoding of pulse positions of tracks of an audio signal |
CN103503062B (en) * | 2011-02-14 | 2016-08-10 | 弗劳恩霍夫应用研究促进协会 | For using the prediction part of alignment by audio-frequency signal coding and the apparatus and method of decoding |
JP5849106B2 (en) | 2011-02-14 | 2016-01-27 | フラウンホーファー−ゲゼルシャフト・ツール・フェルデルング・デル・アンゲヴァンテン・フォルシュング・アインゲトラーゲネル・フェライン | Apparatus and method for error concealment in low delay integrated speech and audio coding |
KR101525185B1 (en) | 2011-02-14 | 2015-06-02 | 프라운호퍼 게젤샤프트 쭈르 푀르데룽 데어 안겐반텐 포르슝 에. 베. | Apparatus and method for coding a portion of an audio signal using a transient detection and a quality result |
BR112012029132B1 (en) | 2011-02-14 | 2021-10-05 | Fraunhofer - Gesellschaft Zur Förderung Der Angewandten Forschung E.V | REPRESENTATION OF INFORMATION SIGNAL USING OVERLAY TRANSFORMED |
CN103534754B (en) | 2011-02-14 | 2015-09-30 | 弗兰霍菲尔运输应用研究公司 | The audio codec utilizing noise to synthesize during the inertia stage |
US9037456B2 (en) | 2011-07-26 | 2015-05-19 | Google Technology Holdings LLC | Method and apparatus for audio coding and decoding |
US9043201B2 (en) | 2012-01-03 | 2015-05-26 | Google Technology Holdings LLC | Method and apparatus for processing audio frames to transition between different codecs |
US9065576B2 (en) * | 2012-04-18 | 2015-06-23 | 2236008 Ontario Inc. | System, apparatus and method for transmitting continuous audio data |
KR102259112B1 (en) * | 2012-11-15 | 2021-05-31 | 가부시키가이샤 엔.티.티.도코모 | Audio coding device, audio coding method, audio coding program, audio decoding device, audio decoding method, and audio decoding program |
BR112015017222B1 (en) * | 2013-02-05 | 2021-04-06 | Telefonaktiebolaget Lm Ericsson (Publ) | CONFIGURED METHOD AND DECODER TO HIDE A LOST AUDIO FRAME FROM A RECEIVED AUDIO SIGNAL, RECEIVER, AND, LEGIBLE MEDIA BY COMPUTER |
EP2981956B1 (en) | 2013-04-05 | 2022-11-30 | Dolby International AB | Audio processing system |
EP2980794A1 (en) * | 2014-07-28 | 2016-02-03 | Fraunhofer-Gesellschaft zur Förderung der angewandten Forschung e.V. | Audio encoder and decoder using a frequency domain processor and a time domain processor |
EP2980795A1 (en) | 2014-07-28 | 2016-02-03 | Fraunhofer-Gesellschaft zur Förderung der angewandten Forschung e.V. | Audio encoding and decoding using a frequency domain processor, a time domain processor and a cross processor for initialization of the time domain processor |
EP2980796A1 (en) | 2014-07-28 | 2016-02-03 | Fraunhofer-Gesellschaft zur Förderung der angewandten Forschung e.V. | Method and apparatus for processing an audio signal, audio decoder, and audio encoder |
FR3024582A1 (en) * | 2014-07-29 | 2016-02-05 | Orange | MANAGING FRAME LOSS IN A FD / LPD TRANSITION CONTEXT |
US9595269B2 (en) * | 2015-01-19 | 2017-03-14 | Qualcomm Incorporated | Scaling for gain shape circuitry |
EP3483879A1 (en) * | 2017-11-10 | 2019-05-15 | Fraunhofer-Gesellschaft zur Förderung der angewandten Forschung e.V. | Analysis/synthesis windowing function for modulated lapped transformation |
Citations (76)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4560977A (en) | 1982-06-11 | 1985-12-24 | Mitsubishi Denki Kabushiki Kaisha | Vector quantizer |
US4670851A (en) | 1984-01-09 | 1987-06-02 | Mitsubishi Denki Kabushiki Kaisha | Vector quantizer |
US4727354A (en) | 1987-01-07 | 1988-02-23 | Unisys Corporation | System for selecting best fit vector code in vector quantization encoding |
US4853778A (en) | 1987-02-25 | 1989-08-01 | Fuji Photo Film Co., Ltd. | Method of compressing image signals using vector quantization |
US5006929A (en) | 1989-09-25 | 1991-04-09 | Rai Radiotelevisione Italiana | Method for encoding and transmitting video signals as overall motion vectors and local motion vectors |
US5067152A (en) | 1989-01-30 | 1991-11-19 | Information Technologies Research, Inc. | Method and apparatus for vector quantization |
US5327521A (en) | 1992-03-02 | 1994-07-05 | The Walt Disney Company | Speech transformation system |
US5394473A (en) | 1990-04-12 | 1995-02-28 | Dolby Laboratories Licensing Corporation | Adaptive-block-length, adaptive-transforn, and adaptive-window transform coder, decoder, and encoder/decoder for high-quality audio |
WO1997015983A1 (en) | 1995-10-27 | 1997-05-01 | Cselt Centro Studi E Laboratori Telecomunicazioni S.P.A. | Method of and apparatus for coding, manipulating and decoding audio signals |
EP0932141A2 (en) | 1998-01-22 | 1999-07-28 | Deutsche Telekom AG | Method for signal controlled switching between different audio coding schemes |
US5956674A (en) | 1995-12-01 | 1999-09-21 | Digital Theater Systems, Inc. | Multi-channel predictive subband audio coder using psychoacoustic adaptive bit allocation in frequency, time and over the multiple channels |
US6236960B1 (en) | 1999-08-06 | 2001-05-22 | Motorola, Inc. | Factorial packing method and apparatus for information coding |
US6253185B1 (en) | 1998-02-25 | 2001-06-26 | Lucent Technologies Inc. | Multiple description transform coding of audio using optimal transforms of arbitrary dimension |
US6263312B1 (en) | 1997-10-03 | 2001-07-17 | Alaris, Inc. | Audio compression and decompression employing subband decomposition of residual signal and distortion reduction |
US6304196B1 (en) | 2000-10-19 | 2001-10-16 | Integrated Device Technology, Inc. | Disparity and transition density control system and method |
US20020052734A1 (en) | 1999-02-04 | 2002-05-02 | Takahiro Unno | Apparatus and quality enhancement algorithm for mixed excitation linear predictive (MELP) and other speech coders |
US6493664B1 (en) | 1999-04-05 | 2002-12-10 | Hughes Electronics Corporation | Spectral magnitude modeling and quantization in a frequency domain interpolative speech codec system |
US20030004713A1 (en) | 2001-05-07 | 2003-01-02 | Kenichi Makino | Signal processing apparatus and method, signal coding apparatus and method , and signal decoding apparatus and method |
US6504877B1 (en) | 1999-12-14 | 2003-01-07 | Agere Systems Inc. | Successively refinable Trellis-Based Scalar Vector quantizers |
WO2003073741A2 (en) | 2002-02-21 | 2003-09-04 | The Regents Of The University Of California | Scalable compression of audio and other signals |
US20030220783A1 (en) | 2002-03-12 | 2003-11-27 | Sebastian Streich | Efficiency improvements in scalable audio coding |
US6658383B2 (en) | 2001-06-26 | 2003-12-02 | Microsoft Corporation | Method for coding speech and music signals |
US6662154B2 (en) | 2001-12-12 | 2003-12-09 | Motorola, Inc. | Method and system for information signal coding using combinatorial and huffman codes |
US6691092B1 (en) | 1999-04-05 | 2004-02-10 | Hughes Electronics Corporation | Voicing measure as an estimate of signal periodicity for a frequency domain interpolative speech codec system |
US6704705B1 (en) | 1998-09-04 | 2004-03-09 | Nortel Networks Limited | Perceptual audio coding |
US6775654B1 (en) * | 1998-08-31 | 2004-08-10 | Fujitsu Limited | Digital audio reproducing apparatus |
US6813602B2 (en) | 1998-08-24 | 2004-11-02 | Mindspeed Technologies, Inc. | Methods and systems for searching a low complexity random codebook structure |
US20040252768A1 (en) | 2003-06-10 | 2004-12-16 | Yoshinori Suzuki | Computing apparatus and encoding program |
EP1533789A1 (en) | 2002-09-06 | 2005-05-25 | Matsushita Electric Industrial Co., Ltd. | Sound encoding apparatus and sound encoding method |
US6940431B2 (en) | 2003-08-29 | 2005-09-06 | Victor Company Of Japan, Ltd. | Method and apparatus for modulating and demodulating digital data |
US20050261893A1 (en) | 2001-06-15 | 2005-11-24 | Keisuke Toyama | Encoding Method, Encoding Apparatus, Decoding Method, Decoding Apparatus and Program |
US6975253B1 (en) | 2004-08-06 | 2005-12-13 | Analog Devices, Inc. | System and method for static Huffman decoding |
EP1619664A1 (en) | 2003-04-30 | 2006-01-25 | Matsushita Electric Industrial Co., Ltd. | Speech coding apparatus, speech decoding apparatus and methods thereof |
US20060022374A1 (en) | 2004-07-28 | 2006-02-02 | Sun Turn Industrial Co., Ltd. | Processing method for making column-shaped foam |
US20060047522A1 (en) | 2004-08-26 | 2006-03-02 | Nokia Corporation | Method, apparatus and computer program to provide predictor adaptation for advanced audio coding (AAC) system |
US7031493B2 (en) | 2000-10-27 | 2006-04-18 | Canon Kabushiki Kaisha | Method for generating and detecting marks |
US20060173675A1 (en) | 2003-03-11 | 2006-08-03 | Juha Ojanpera | Switching between coding schemes |
US20060190246A1 (en) | 2005-02-23 | 2006-08-24 | Via Telecom Co., Ltd. | Transcoding method for switching between selectable mode voice encoder and an enhanced variable rate CODEC |
US20060241940A1 (en) | 2005-04-20 | 2006-10-26 | Docomo Communications Laboratories Usa, Inc. | Quantization of speech and audio coding parameters using partial information on atypical subsequences |
US7130796B2 (en) | 2001-02-27 | 2006-10-31 | Mitsubishi Denki Kabushiki Kaisha | Voice encoding method and apparatus of selecting an excitation mode from a plurality of excitation modes and encoding an input speech using the excitation mode selected |
US20060265087A1 (en) | 2003-03-04 | 2006-11-23 | France Telecom Sa | Method and device for spectral reconstruction of an audio signal |
US7161507B2 (en) | 2004-08-20 | 2007-01-09 | 1St Works Corporation | Fast, practically optimal entropy coding |
US7180796B2 (en) | 2000-05-25 | 2007-02-20 | Kabushiki Kaisha Toshiba | Boosted voltage generating circuit and semiconductor memory device having the same |
WO2007063910A1 (en) | 2005-11-30 | 2007-06-07 | Matsushita Electric Industrial Co., Ltd. | Scalable coding apparatus and scalable coding method |
US7231091B2 (en) | 1998-09-21 | 2007-06-12 | Intel Corporation | Simplified predictive video encoder |
US7230550B1 (en) | 2006-05-16 | 2007-06-12 | Motorola, Inc. | Low-complexity bit-robust method and system for combining codewords to form a single codeword |
US20070171944A1 (en) | 2004-04-05 | 2007-07-26 | Koninklijke Philips Electronics, N.V. | Stereo coding and decoding methods and apparatus thereof |
EP1818911A1 (en) | 2004-12-27 | 2007-08-15 | Matsushita Electric Industrial Co., Ltd. | Sound coding device and sound coding method |
US20070239294A1 (en) | 2006-03-29 | 2007-10-11 | Andrea Brueckner | Hearing instrument having audio feedback capability |
EP1845519A2 (en) | 2003-12-19 | 2007-10-17 | Telefonaktiebolaget LM Ericsson (publ) | Encoding and decoding of multi-channel audio signals based on a main and side signal representation |
US20070271102A1 (en) | 2004-09-02 | 2007-11-22 | Toshiyuki Morii | Voice decoding device, voice encoding device, and methods therefor |
US20080065374A1 (en) | 2006-09-12 | 2008-03-13 | Motorola, Inc. | Apparatus and method for low complexity combinatorial coding of signals |
EP1912206A1 (en) | 2005-08-31 | 2008-04-16 | Matsushita Electric Industrial Co., Ltd. | Stereo encoding device, stereo decoding device, and stereo encoding method |
US20080120096A1 (en) | 2006-11-21 | 2008-05-22 | Samsung Electronics Co., Ltd. | Method, medium, and system scalably encoding/decoding audio/speech |
WO2008063035A1 (en) | 2006-11-24 | 2008-05-29 | Lg Electronics Inc. | Method for encoding and decoding object-based audio signal and apparatus thereof |
US7414549B1 (en) | 2006-08-04 | 2008-08-19 | The Texas A&M University System | Wyner-Ziv coding based on TCQ and LDPC codes |
US20090030677A1 (en) | 2005-10-14 | 2009-01-29 | Matsushita Electric Industrial Co., Ltd. | Scalable encoding apparatus, scalable decoding apparatus, and methods of them |
US20090076829A1 (en) | 2006-02-14 | 2009-03-19 | France Telecom | Device for Perceptual Weighting in Audio Encoding/Decoding |
US20090100121A1 (en) | 2007-10-11 | 2009-04-16 | Motorola, Inc. | Apparatus and method for low complexity combinatorial coding of signals |
US20090112607A1 (en) | 2007-10-25 | 2009-04-30 | Motorola, Inc. | Method and apparatus for generating an enhancement layer within an audio coding system |
US20090234642A1 (en) | 2008-03-13 | 2009-09-17 | Motorola, Inc. | Method and Apparatus for Low Complexity Combinatorial Coding of Signals |
US20090259477A1 (en) | 2008-04-09 | 2009-10-15 | Motorola, Inc. | Method and Apparatus for Selective Signal Coding Based on Core Encoder Performance |
US20090276212A1 (en) * | 2005-05-31 | 2009-11-05 | Microsoft Corporation | Robust decoder |
US20090306992A1 (en) | 2005-07-22 | 2009-12-10 | Ragot Stephane | Method for switching rate and bandwidth scalable audio decoding rate |
US20090326931A1 (en) | 2005-07-13 | 2009-12-31 | France Telecom | Hierarchical encoding/decoding device |
WO2010003663A1 (en) | 2008-07-11 | 2010-01-14 | Fraunhofer-Gesellschaft zur Förderung der angewandten Forschung e.V. | Audio encoder and decoder for encoding frames of sampled audio signals |
US20100088090A1 (en) | 2008-10-08 | 2010-04-08 | Motorola, Inc. | Arithmetic encoding for celp speech encoders |
US20100169101A1 (en) | 2008-12-29 | 2010-07-01 | Motorola, Inc. | Method and apparatus for generating an enhancement layer within a multiple-channel audio coding system |
US20100169099A1 (en) | 2008-12-29 | 2010-07-01 | Motorola, Inc. | Method and apparatus for generating an enhancement layer within a multiple-channel audio coding system |
US20100169100A1 (en) | 2008-12-29 | 2010-07-01 | Motorola, Inc. | Selective scaling mask computation based on peak detection |
US20100169087A1 (en) | 2008-12-29 | 2010-07-01 | Motorola, Inc. | Selective scaling mask computation based on peak detection |
US7761290B2 (en) | 2007-06-15 | 2010-07-20 | Microsoft Corporation | Flexible frequency and time partitioning in perceptual transform coding of audio |
US7840411B2 (en) | 2005-03-30 | 2010-11-23 | Koninklijke Philips Electronics N.V. | Audio encoding and decoding |
US7885819B2 (en) | 2007-06-29 | 2011-02-08 | Microsoft Corporation | Bitstream syntax for multi-process audio decoding |
US7889103B2 (en) | 2008-03-13 | 2011-02-15 | Motorola Mobility, Inc. | Method and apparatus for low complexity combinatorial coding of signals |
US20110161087A1 (en) | 2009-12-31 | 2011-06-30 | Motorola, Inc. | Embedded Speech and Audio Coding Using a Switchable Model Core |
Family Cites Families (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP3137805B2 (en) * | 1993-05-21 | 2001-02-26 | 三菱電機株式会社 | Audio encoding device, audio decoding device, audio post-processing device, and methods thereof |
KR100711280B1 (en) * | 2002-10-11 | 2007-04-25 | 노키아 코포레이션 | Methods and devices for source controlled variable bit-rate wideband speech coding |
JP5154934B2 (en) * | 2004-09-17 | 2013-02-27 | コーニンクレッカ フィリップス エレクトロニクス エヌ ヴィ | Joint audio coding to minimize perceptual distortion |
-
2010
- 2010-07-27 US US12/844,199 patent/US8423355B2/en not_active Expired - Fee Related
-
2011
- 2011-03-01 WO PCT/US2011/026640 patent/WO2011109361A1/en active Application Filing
- 2011-03-01 BR BR112012022446A patent/BR112012022446A2/en not_active Application Discontinuation
- 2011-03-01 EP EP11707326.2A patent/EP2543036B1/en not_active Not-in-force
- 2011-03-01 CN CN201180012387.7A patent/CN102834862B/en active Active
- 2011-03-01 CA CA2789297A patent/CA2789297C/en active Active
- 2011-03-01 BR BR112012022444A patent/BR112012022444A2/en not_active IP Right Cessation
- 2011-03-01 KR KR1020127023129A patent/KR101430332B1/en active IP Right Grant
- 2011-03-01 DK DK11707326.2T patent/DK2543036T3/en active
Patent Citations (85)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4560977A (en) | 1982-06-11 | 1985-12-24 | Mitsubishi Denki Kabushiki Kaisha | Vector quantizer |
US4670851A (en) | 1984-01-09 | 1987-06-02 | Mitsubishi Denki Kabushiki Kaisha | Vector quantizer |
US4727354A (en) | 1987-01-07 | 1988-02-23 | Unisys Corporation | System for selecting best fit vector code in vector quantization encoding |
US4853778A (en) | 1987-02-25 | 1989-08-01 | Fuji Photo Film Co., Ltd. | Method of compressing image signals using vector quantization |
US5067152A (en) | 1989-01-30 | 1991-11-19 | Information Technologies Research, Inc. | Method and apparatus for vector quantization |
US5006929A (en) | 1989-09-25 | 1991-04-09 | Rai Radiotelevisione Italiana | Method for encoding and transmitting video signals as overall motion vectors and local motion vectors |
US5394473A (en) | 1990-04-12 | 1995-02-28 | Dolby Laboratories Licensing Corporation | Adaptive-block-length, adaptive-transforn, and adaptive-window transform coder, decoder, and encoder/decoder for high-quality audio |
US5327521A (en) | 1992-03-02 | 1994-07-05 | The Walt Disney Company | Speech transformation system |
WO1997015983A1 (en) | 1995-10-27 | 1997-05-01 | Cselt Centro Studi E Laboratori Telecomunicazioni S.P.A. | Method of and apparatus for coding, manipulating and decoding audio signals |
US6108626A (en) | 1995-10-27 | 2000-08-22 | Cselt-Centro Studi E Laboratori Telecomunicazioni S.P.A. | Object oriented audio coding |
US5956674A (en) | 1995-12-01 | 1999-09-21 | Digital Theater Systems, Inc. | Multi-channel predictive subband audio coder using psychoacoustic adaptive bit allocation in frequency, time and over the multiple channels |
US6263312B1 (en) | 1997-10-03 | 2001-07-17 | Alaris, Inc. | Audio compression and decompression employing subband decomposition of residual signal and distortion reduction |
US20030009325A1 (en) | 1998-01-22 | 2003-01-09 | Raif Kirchherr | Method for signal controlled switching between different audio coding schemes |
EP0932141A2 (en) | 1998-01-22 | 1999-07-28 | Deutsche Telekom AG | Method for signal controlled switching between different audio coding schemes |
US6253185B1 (en) | 1998-02-25 | 2001-06-26 | Lucent Technologies Inc. | Multiple description transform coding of audio using optimal transforms of arbitrary dimension |
US6813602B2 (en) | 1998-08-24 | 2004-11-02 | Mindspeed Technologies, Inc. | Methods and systems for searching a low complexity random codebook structure |
US6775654B1 (en) * | 1998-08-31 | 2004-08-10 | Fujitsu Limited | Digital audio reproducing apparatus |
US6704705B1 (en) | 1998-09-04 | 2004-03-09 | Nortel Networks Limited | Perceptual audio coding |
US7231091B2 (en) | 1998-09-21 | 2007-06-12 | Intel Corporation | Simplified predictive video encoder |
US20020052734A1 (en) | 1999-02-04 | 2002-05-02 | Takahiro Unno | Apparatus and quality enhancement algorithm for mixed excitation linear predictive (MELP) and other speech coders |
US6453287B1 (en) | 1999-02-04 | 2002-09-17 | Georgia-Tech Research Corporation | Apparatus and quality enhancement algorithm for mixed excitation linear predictive (MELP) and other speech coders |
US6493664B1 (en) | 1999-04-05 | 2002-12-10 | Hughes Electronics Corporation | Spectral magnitude modeling and quantization in a frequency domain interpolative speech codec system |
US6691092B1 (en) | 1999-04-05 | 2004-02-10 | Hughes Electronics Corporation | Voicing measure as an estimate of signal periodicity for a frequency domain interpolative speech codec system |
US6236960B1 (en) | 1999-08-06 | 2001-05-22 | Motorola, Inc. | Factorial packing method and apparatus for information coding |
US6504877B1 (en) | 1999-12-14 | 2003-01-07 | Agere Systems Inc. | Successively refinable Trellis-Based Scalar Vector quantizers |
US7180796B2 (en) | 2000-05-25 | 2007-02-20 | Kabushiki Kaisha Toshiba | Boosted voltage generating circuit and semiconductor memory device having the same |
US6304196B1 (en) | 2000-10-19 | 2001-10-16 | Integrated Device Technology, Inc. | Disparity and transition density control system and method |
US7031493B2 (en) | 2000-10-27 | 2006-04-18 | Canon Kabushiki Kaisha | Method for generating and detecting marks |
US7130796B2 (en) | 2001-02-27 | 2006-10-31 | Mitsubishi Denki Kabushiki Kaisha | Voice encoding method and apparatus of selecting an excitation mode from a plurality of excitation modes and encoding an input speech using the excitation mode selected |
US6593872B2 (en) | 2001-05-07 | 2003-07-15 | Sony Corporation | Signal processing apparatus and method, signal coding apparatus and method, and signal decoding apparatus and method |
US20030004713A1 (en) | 2001-05-07 | 2003-01-02 | Kenichi Makino | Signal processing apparatus and method, signal coding apparatus and method , and signal decoding apparatus and method |
US20050261893A1 (en) | 2001-06-15 | 2005-11-24 | Keisuke Toyama | Encoding Method, Encoding Apparatus, Decoding Method, Decoding Apparatus and Program |
US7212973B2 (en) | 2001-06-15 | 2007-05-01 | Sony Corporation | Encoding method, encoding apparatus, decoding method, decoding apparatus and program |
US6658383B2 (en) | 2001-06-26 | 2003-12-02 | Microsoft Corporation | Method for coding speech and music signals |
US6662154B2 (en) | 2001-12-12 | 2003-12-09 | Motorola, Inc. | Method and system for information signal coding using combinatorial and huffman codes |
WO2003073741A2 (en) | 2002-02-21 | 2003-09-04 | The Regents Of The University Of California | Scalable compression of audio and other signals |
EP1483759B1 (en) | 2002-03-12 | 2006-09-06 | Nokia Corporation | Scalable audio coding |
US20030220783A1 (en) | 2002-03-12 | 2003-11-27 | Sebastian Streich | Efficiency improvements in scalable audio coding |
EP1533789A1 (en) | 2002-09-06 | 2005-05-25 | Matsushita Electric Industrial Co., Ltd. | Sound encoding apparatus and sound encoding method |
US20060265087A1 (en) | 2003-03-04 | 2006-11-23 | France Telecom Sa | Method and device for spectral reconstruction of an audio signal |
US20060173675A1 (en) | 2003-03-11 | 2006-08-03 | Juha Ojanpera | Switching between coding schemes |
EP1619664A1 (en) | 2003-04-30 | 2006-01-25 | Matsushita Electric Industrial Co., Ltd. | Speech coding apparatus, speech decoding apparatus and methods thereof |
US20040252768A1 (en) | 2003-06-10 | 2004-12-16 | Yoshinori Suzuki | Computing apparatus and encoding program |
US6940431B2 (en) | 2003-08-29 | 2005-09-06 | Victor Company Of Japan, Ltd. | Method and apparatus for modulating and demodulating digital data |
EP1845519A2 (en) | 2003-12-19 | 2007-10-17 | Telefonaktiebolaget LM Ericsson (publ) | Encoding and decoding of multi-channel audio signals based on a main and side signal representation |
US20070171944A1 (en) | 2004-04-05 | 2007-07-26 | Koninklijke Philips Electronics, N.V. | Stereo coding and decoding methods and apparatus thereof |
US20060022374A1 (en) | 2004-07-28 | 2006-02-02 | Sun Turn Industrial Co., Ltd. | Processing method for making column-shaped foam |
US6975253B1 (en) | 2004-08-06 | 2005-12-13 | Analog Devices, Inc. | System and method for static Huffman decoding |
US7161507B2 (en) | 2004-08-20 | 2007-01-09 | 1St Works Corporation | Fast, practically optimal entropy coding |
US20060047522A1 (en) | 2004-08-26 | 2006-03-02 | Nokia Corporation | Method, apparatus and computer program to provide predictor adaptation for advanced audio coding (AAC) system |
US20070271102A1 (en) | 2004-09-02 | 2007-11-22 | Toshiyuki Morii | Voice decoding device, voice encoding device, and methods therefor |
EP1818911A1 (en) | 2004-12-27 | 2007-08-15 | Matsushita Electric Industrial Co., Ltd. | Sound coding device and sound coding method |
US20060190246A1 (en) | 2005-02-23 | 2006-08-24 | Via Telecom Co., Ltd. | Transcoding method for switching between selectable mode voice encoder and an enhanced variable rate CODEC |
US7840411B2 (en) | 2005-03-30 | 2010-11-23 | Koninklijke Philips Electronics N.V. | Audio encoding and decoding |
US20060241940A1 (en) | 2005-04-20 | 2006-10-26 | Docomo Communications Laboratories Usa, Inc. | Quantization of speech and audio coding parameters using partial information on atypical subsequences |
US20090276212A1 (en) * | 2005-05-31 | 2009-11-05 | Microsoft Corporation | Robust decoder |
US20090326931A1 (en) | 2005-07-13 | 2009-12-31 | France Telecom | Hierarchical encoding/decoding device |
US20090306992A1 (en) | 2005-07-22 | 2009-12-10 | Ragot Stephane | Method for switching rate and bandwidth scalable audio decoding rate |
EP1912206A1 (en) | 2005-08-31 | 2008-04-16 | Matsushita Electric Industrial Co., Ltd. | Stereo encoding device, stereo decoding device, and stereo encoding method |
US20090030677A1 (en) | 2005-10-14 | 2009-01-29 | Matsushita Electric Industrial Co., Ltd. | Scalable encoding apparatus, scalable decoding apparatus, and methods of them |
WO2007063910A1 (en) | 2005-11-30 | 2007-06-07 | Matsushita Electric Industrial Co., Ltd. | Scalable coding apparatus and scalable coding method |
EP1959431B1 (en) | 2005-11-30 | 2010-06-23 | Panasonic Corporation | Scalable coding apparatus and scalable coding method |
US20090076829A1 (en) | 2006-02-14 | 2009-03-19 | France Telecom | Device for Perceptual Weighting in Audio Encoding/Decoding |
US20070239294A1 (en) | 2006-03-29 | 2007-10-11 | Andrea Brueckner | Hearing instrument having audio feedback capability |
US7230550B1 (en) | 2006-05-16 | 2007-06-12 | Motorola, Inc. | Low-complexity bit-robust method and system for combining codewords to form a single codeword |
US7414549B1 (en) | 2006-08-04 | 2008-08-19 | The Texas A&M University System | Wyner-Ziv coding based on TCQ and LDPC codes |
US7461106B2 (en) | 2006-09-12 | 2008-12-02 | Motorola, Inc. | Apparatus and method for low complexity combinatorial coding of signals |
US20080065374A1 (en) | 2006-09-12 | 2008-03-13 | Motorola, Inc. | Apparatus and method for low complexity combinatorial coding of signals |
US20090024398A1 (en) | 2006-09-12 | 2009-01-22 | Motorola, Inc. | Apparatus and method for low complexity combinatorial coding of signals |
US20080120096A1 (en) | 2006-11-21 | 2008-05-22 | Samsung Electronics Co., Ltd. | Method, medium, and system scalably encoding/decoding audio/speech |
WO2008063035A1 (en) | 2006-11-24 | 2008-05-29 | Lg Electronics Inc. | Method for encoding and decoding object-based audio signal and apparatus thereof |
US7761290B2 (en) | 2007-06-15 | 2010-07-20 | Microsoft Corporation | Flexible frequency and time partitioning in perceptual transform coding of audio |
US7885819B2 (en) | 2007-06-29 | 2011-02-08 | Microsoft Corporation | Bitstream syntax for multi-process audio decoding |
US20090100121A1 (en) | 2007-10-11 | 2009-04-16 | Motorola, Inc. | Apparatus and method for low complexity combinatorial coding of signals |
US20090112607A1 (en) | 2007-10-25 | 2009-04-30 | Motorola, Inc. | Method and apparatus for generating an enhancement layer within an audio coding system |
US20090234642A1 (en) | 2008-03-13 | 2009-09-17 | Motorola, Inc. | Method and Apparatus for Low Complexity Combinatorial Coding of Signals |
US7889103B2 (en) | 2008-03-13 | 2011-02-15 | Motorola Mobility, Inc. | Method and apparatus for low complexity combinatorial coding of signals |
US20090259477A1 (en) | 2008-04-09 | 2009-10-15 | Motorola, Inc. | Method and Apparatus for Selective Signal Coding Based on Core Encoder Performance |
WO2010003663A1 (en) | 2008-07-11 | 2010-01-14 | Fraunhofer-Gesellschaft zur Förderung der angewandten Forschung e.V. | Audio encoder and decoder for encoding frames of sampled audio signals |
US20100088090A1 (en) | 2008-10-08 | 2010-04-08 | Motorola, Inc. | Arithmetic encoding for celp speech encoders |
US20100169100A1 (en) | 2008-12-29 | 2010-07-01 | Motorola, Inc. | Selective scaling mask computation based on peak detection |
US20100169087A1 (en) | 2008-12-29 | 2010-07-01 | Motorola, Inc. | Selective scaling mask computation based on peak detection |
US20100169099A1 (en) | 2008-12-29 | 2010-07-01 | Motorola, Inc. | Method and apparatus for generating an enhancement layer within a multiple-channel audio coding system |
US20100169101A1 (en) | 2008-12-29 | 2010-07-01 | Motorola, Inc. | Method and apparatus for generating an enhancement layer within a multiple-channel audio coding system |
US20110161087A1 (en) | 2009-12-31 | 2011-06-30 | Motorola, Inc. | Embedded Speech and Audio Coding Using a Switchable Model Core |
Non-Patent Citations (60)
Title |
---|
"Enhanced Variable Rate Codec, Speech Service Options 3, 68, and 70 for Wideband Spread Spectrum Digital Systems", 3GPP2 TSG-C Working Group 2, XX, XX, No. C. S0014-C, Jan. 1, 2007, pp. 1-5. |
3GPP TS 26.290 V7.0.0 (Mar. 2007); 3rd Generation Partnership Project; Techinical Specification Group Service and System Aspects; Audio Codec Processing Functions; Extended Adaptive Multi-Rate-Wideband (AMR-WB+) Codec; Transcoding Functions (Release 7). |
Anderson et al.; Reverse Water-Filling in Predictive Encoding of Speech; Department of Speech, Music and Hearing, Royal Institute of Technology; Stockholm, Sweden; 3 pages, 1999. |
Ashley, et al., Wideband Coding of Speech Using a Scalable Pulse Codebook, Proceedings of the 2000 IEEE Workshop on Speech Coding, Sep. 17-20, 2000, pp. 148-150. |
B. Elder, "Coding of Audio Signals with Overlapping Block Transform and Adaptive Window Functions", Frequenz; Zeitschrift fur Schwingungs-und Schwachstromtechnik, 1989, vol. 43, pp. 252-256. |
Boris Ya Ryabko et al.: "Fast and Efficient Construction of an Unbiased Random Sequence", IEEE Transactions on Information Theory, IEEE, US, vol. 46, No. 3, May 1, 2000, ISSN: 0018-9448, pp. 1090-1093. |
Bruno Bessette: Universal Speech/Audio Coding using Hybrid ACELP/TCX techniques, Acoustics, Speech, and Signal Processing, 2005. Proceedings. (ICASSP '05). IEEE International Conference, Mar. 18-23, 2005, ISSN : III-301-III-304, Print ISBN: 0-7803-8874-7, all pages. |
Chan et al.; Frequency Domain Postfiltering for Multiband Excited Linear Predictive Coding of Speech; Electronics Letters; Jun. 6, 1996, vol. 32 No. 12; 3 pages. |
Chen et al.; Adaptive Postfiltering for Quality Enhancement of Coded Speech; IEEE Transactions on Speech and Audio Processing, vol. 3. No. 1, Jan. 1995; 13 pages. |
Chinese Patent Office (SIPO), 1st Office Action for Chinese Patent Application No. 200980153318.0 dated Sep. 12, 2012, 6 pages. |
Cover, T.M., "Enumerative Source Encoding" IEEE Transactions on Information Theory, IEEE Press, USA vol. IT-19, No. 1; Jan. 1, 1973, pp. 73-77. |
Daniele Cadel, et al. "Pyramid Vector Coding for High Quality Audio Compression", IEEE 1997, pp. 343-346, Cefriel, Milano, Italy and Alcatel Telecom, Vimercate Italy. |
European Patent Office, Supplementary Search Report for EPC Patent Application No. 07813290.9 dated Jan. 4, 2013, 8 pages. |
Faller, et al., "Technical Advances in Digital Audio Radio Broadcasting," Proceedings of the IEEE, vol. 90, Issue 8, Aug. 2002, pp. 1303-1333. |
Fuchs et al. "A Speech Coder Post-Processor Controlled by Side-Information" 2005, pp. IV-433-IV-436. |
Hung et al., Error-Resilient Pyramid Vector Quantization for Image Compression, IEEE Transactions on Image Processing, 1994 pp. 583-587. |
Hung, et al., "Error-Resilient Pyramid Vector Quantization for Image Compression," IEEE Transactions on Image Processing, vol. 7, Issue 10, Oct. 1998, pp. 1373-1386. |
Ido Tal et al.: "On Row-by-Row Coding for 2-D Constraints", Information Theory, 2006 IEEE International Symposium on, IEEE, PI, Jul. 1, 2006, pp. 1204-1208. |
International Telecommunication Union, "G.729.1, Series G: Transmission Systems and Media, Digital Systems and Networks, Digital Terminal Equipments-Coding of analogue signals by methods other than PCM,G.729 based Embedded Variable bit-rate coder: An 8-32 kbit/s scalable wideband coder bitstream interoperable with G.729," ITU-T Recomendation G.729.1, May 2006, Cover page, pp. 11-18. Full document available at: http://www.itu.int/rec/T-REC-G.729.1-200605-I/en. |
J. Fessler, "Chapter 2; Discrete-time signals and systems" May 27, 2004, pp. 2.1-2.21. |
Jelinek et al. "Classification-Based Techniques for Improving the Robustness of CELP Coders" 2007, pp. 1480-1484. |
Jelinek et al. "ITU-T G.EV-VBR Baseline CODEC" Apr. 4, 2008, pp. 4749-4752. |
Kim et al.; "A New Bandwidth Scalable Wideband Speech/Audio Coder" Proceedings of Proceedings of International Conference on Acoustics, Speech, and Signal Processing, ICASSP; Orlando, FL; vol. 1, May 13, 2002 pp. 657-660. |
Korean Intellectual Property Office, Notice of Preliminary Rejection for Korean Patent Application No. 10-2010-0725140 dated Jan. 4, 2013. |
Kovesi, et al., "A Scalable Speech and Adiuo Coding Scheme with Continuous Bitrate Flexibility," Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing 2004 (ICASSP '04) Montreal, Quebec, Canada, May 17-21, 2004, vol. 1, pp. 273-276. |
Mackay, D., "Information Theory, Inference, and Learning Algorithms" in: "Information Theory, Inference, and Learning Algorithms", Jan. 1, 2004; pp. 1-10. |
Makinen, et al., "AMR-WB+: A New Audio Coding Standard for 3rd Generation Mobile Audio Service," Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing, 2005, ICASSP'05, vol. 2, Mar. 18-23, 2005, pp. ii/1109-ii/1112. |
Markas et al. "Multispectral Image Compression Algorithms"; Data Compression Conference, 1993; Snowbird, UT USA Mar. 30-Apr. 2, 1993; pp. 391-400. |
Mexican Patent Office, 2nd Office Action, Mexican Patent Application MX/a/2010/004479 dated Jan. 31, 2012, 5 pages. |
Mittal, et al., "Coding Unconstrained FCB Excitation Using Combinatorial and Huffman Codes," Proceedings of the 2002 IEEE Workshop on Speech Coding, Oct. 6-9, 2002, pp. 129-131. |
Mittal, et al.,"Low Complexity Factorial Pulse Coding of MDCT Coefficients using Approximation of Combinatorial Functions," IEEE International Conference on Acoustics, Speech and Signal Processing, 2007, ICASSP 2007, Apr. 15-20, 2007, pp. I-289-I-292. |
Neuendorf, et al., "Unified Speech Audio Coding Scheme for High Quality oat Low Bitrates" ieee International Conference on Accoustics, Speech and Signal Processing, Apr. 19, 2009, 4 pages. |
Office Action for U.S. Appl. No. 12/047,632, mailed Oct. 18, 2011. |
Office Action for U.S. Appl. No. 12/099,842, mailed Oct. 12, 2011. |
Office Action for U.S. Appl. No. 12/187,423, mailed Sep. 30, 2011. |
Office Action for U.S. Appl. No. 12/345,141, mailed Sep. 19, 2011. |
Office Action for U.S. Appl. No. 12/345,165, mailed Sep. 1, 2011. |
Patent Cooperation Treaty, "PCT Search Report and Written Opinion of the International Searching Authority" for International Application No. PCT/US2008/077693 Dec. 15, 2008, 12 pages. |
Patent Cooperation Treaty, "PCT Search Report and Written Opinion of the International Searching Authority" for International Application No. PCT/US2009/036479 Jul. 28, 2009, 15 pages. |
Patent Cooperation Treaty, "PCT Search Report and Written Opinion of the International Searching Authority" for International Application No. PCT/US2009/036481 Jul. 20, 2009, 15 pages. |
Patent Cooperation Treaty, "PCT Search Report and Written Opinion of the International Searching Authority" for International Application No. PCT/US2009/039984 Aug. 13, 2009, 14 pages. |
Patent Cooperation Treaty, "PCT Search Report and Written Opinion of the International Searching Authority" for International Application No. PCT/US2009/066163 Mar. 15, 2010, 14 pages. |
Patent Cooperation Treaty, "PCT Search Report and Written Opinion of the International Searching Authority" for International Application No. PCT/US2009/066627 Mar. 5, 2010, 13 pages. |
Patent Cooperation Treaty, "PCT Search Report and Written Opinion of the International Searching Authority" for International Application No. PCT/US2011/0266400 Aug. 5, 2011, 11 pages. |
Patent Cooperation Treaty, "PCT Search Report and Written Opinion of the International Searching Authority" for International Application No. PCT/US2011/026660 Jun. 15, 2011, 10 pages. |
Princen, et al, "Subband/Transform Coding Using Filter Bank Designs Based on Time Domain Aliasing Cancellation", IEEE 1987 pp. 2161-2164. |
Ramo et al. "Quality Evaluation of the G.EV-VBR Speech CODEC" Apr. 4, 2008, pp. 4745-4748. |
Ramprashad, "A Two Stage Hybrid Embedded Speech/Audio Coding Structure," Proceedings of Internationnal Conference on Acoustics, Speech, and Signal Processing, ICASSP 1998, May 1998, vol. 1, pp. 337-340, Seattle, Washington. |
Ramprashad, "Embedded Coding Using a Mixed Speech and Audio Coding Paradigm," International Journal of Speech Technology, Kluwer Academic Publishers, Netherlands, vol. 2, No. 4, May 1999, pp. 359-372. |
Ramprashad, "High Quality Embedded Wideband Speech Coding Using an Inherently Layered Coding Paradigm," Proceedings of International Conference on Acoustics, Speech, and Signal Processing, ICASSP 2000, vol. 2, Jun. 5-9, 2000, pp. 1145-1148. |
Ratko V. Tomic: "Fast, Optimal Entropy Coder" 1stWorks Corporation Technical Report TR04-0815, Aug. 15, 2004, pp. 1-52. |
Ratko V. Tomic: "Quantized Indexing: Background Information", May 16, 2006, URL: http://web.archive.org/ web/20060516161324/www.1stworks.com/ref/TR/tr05-0625a.pdf, pp. 1-39. |
Salami, et al., "Extended AMR-WB for High-Quality Audio on Mobile Devices," IEEE Communications Magazine, vol. 44, Issue 5, May 2006, pp. 90-97. |
Tancerel, et al., "Combined Speech and Audio Coding by Discrimination"; Proceedings of the 2000 IEEE Workshop on Speech Coding, Sep. 17-20, 2000, pp. 154-156. |
Udar Mittal et al., "Decoder for Audio Signal Including Generic Audio and Speech Frames", U.S. Appl. No. 12/844,206, filed Sep. 9, 2010. |
United States Patent and Trademark Office, "Non-Final Office Action" for U.S. Appl. No. 12/196,414 dated Jun. 4, 2012, 9 pages. |
United States Patent and Trademark Office, "Non-Final Rejection" for U.S. Appl. No. 12/047,632 dated Mar. 2, 2011, 20 pages. |
United States Patent and Trademark Office, "Non-Final Rejection" for U.S. Appl. No. 12/099,842 dated Apr. 15, 2011, 21 pages. |
United States Patent and Trademark Office, "Notice of Allowance and Fee(s) Due" for U.S. Appl. No. 12/047,586 dated Nov. 20, 2009, 20 pages. |
Virette, et al., "Adaptive Time-Frequency Resolution in Modulated Transform at Reduced Delay", Orange Labs, France; IEEE 2008; pp. 3781-3784. |
Cited By (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9256579B2 (en) | 2006-09-12 | 2016-02-09 | Google Technology Holdings LLC | Apparatus and method for low complexity combinatorial coding of signals |
US20140088973A1 (en) * | 2012-09-26 | 2014-03-27 | Motorola Mobility Llc | Method and apparatus for encoding an audio signal |
US9129600B2 (en) * | 2012-09-26 | 2015-09-08 | Google Technology Holdings LLC | Method and apparatus for encoding an audio signal |
US20160225387A1 (en) * | 2013-08-28 | 2016-08-04 | Dolby Laboratories Licensing Corporation | Hybrid waveform-coded and parametric-coded speech enhancement |
US10141004B2 (en) * | 2013-08-28 | 2018-11-27 | Dolby Laboratories Licensing Corporation | Hybrid waveform-coded and parametric-coded speech enhancement |
US10607629B2 (en) | 2013-08-28 | 2020-03-31 | Dolby Laboratories Licensing Corporation | Methods and apparatus for decoding based on speech enhancement metadata |
Also Published As
Publication number | Publication date |
---|---|
CN102834862B (en) | 2014-12-17 |
BR112012022444A2 (en) | 2017-10-03 |
WO2011109361A1 (en) | 2011-09-09 |
KR20120125513A (en) | 2012-11-15 |
DK2543036T3 (en) | 2018-01-22 |
BR112012022446A2 (en) | 2017-11-21 |
CN102834862A (en) | 2012-12-19 |
KR101430332B1 (en) | 2014-08-13 |
US20110218797A1 (en) | 2011-09-08 |
CA2789297C (en) | 2016-04-26 |
EP2543036B1 (en) | 2017-12-06 |
CA2789297A1 (en) | 2011-09-09 |
EP2543036A1 (en) | 2013-01-09 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US8423355B2 (en) | Encoder for audio signal including generic audio and speech frames | |
US8428936B2 (en) | Decoder for audio signal including generic audio and speech frames | |
KR101941978B1 (en) | Audio decoder and method for providing a decoded audio information using an error concealment modifying a time domain excitation signal | |
KR101854297B1 (en) | Audio decoder and method for providing a decoded audio information using an error concealment based on a time domain excitation signal | |
EP2382621B1 (en) | Method and appratus for generating an enhancement layer within a multiple-channel audio coding system | |
EP2382626B1 (en) | Selective scaling mask computation based on peak detection | |
EP2382627B1 (en) | Selective scaling mask computation based on peak detection | |
KR101698905B1 (en) | Apparatus and method for encoding and decoding an audio signal using an aligned look-ahead portion |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: MOTOROLA, INC., ILLINOISFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:MITTAL, UDAR;GIBBS, JONATHAN A.;ASHLEY, JAMES P.;SIGNING DATES FROM 20100312 TO 20100315;REEL/FRAME:024746/0902 |
|
AS | Assignment |
Owner name: MOTOROLA MOBILITY INC., ILLINOISFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:MOTOROLA INC.;REEL/FRAME:026561/0001Effective date: 20100731 |
|
AS | Assignment |
Owner name: MOTOROLA MOBILITY LLC, ILLINOISFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:MOTOROLA MOBILITY, INC.;REEL/FRAME:028829/0856Effective date: 20120622 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
AS | Assignment |
Owner name: GOOGLE TECHNOLOGY HOLDINGS LLC, CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:MOTOROLA MOBILITY LLC;REEL/FRAME:034286/0001Effective date: 20141028 |
|
AS | Assignment |
Owner name: GOOGLE TECHNOLOGY HOLDINGS LLC, CALIFORNIAFree format text: CORRECTIVE ASSIGNMENT TO CORRECT THE REMOVE INCORRECT PATENT NO. 8577046 AND REPLACE WITH CORRECT PATENT NO. 8577045 PREVIOUSLY RECORDED ON REEL 034286 FRAME 0001. ASSIGNOR(S) HEREBY CONFIRMS THE ASSIGNMENT;ASSIGNOR:MOTOROLA MOBILITY LLC;REEL/FRAME:034538/0001Effective date: 20141028 |
|
FPAY | Fee payment |
Year of fee payment: 4 |
|
FEPP | Fee payment procedure |
Free format text: MAINTENANCE FEE REMINDER MAILED (ORIGINAL EVENT CODE: REM.); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
LAPS | Lapse for failure to pay maintenance fees |
Free format text: PATENT EXPIRED FOR FAILURE TO PAY MAINTENANCE FEES (ORIGINAL EVENT CODE: EXP.); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
STCH | Information on status: patent discontinuation |
Free format text: PATENT EXPIRED DUE TO NONPAYMENT OF MAINTENANCE FEES UNDER 37 CFR 1.362 |
|
FP | Lapsed due to failure to pay maintenance fee |
Effective date: 20210416 |