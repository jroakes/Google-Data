CN113286153B - Method for encoding/decoding group of pictures in video stream and encoder/decoder - Google Patents
Method for encoding/decoding group of pictures in video stream and encoder/decoder Download PDFInfo
- Publication number
- CN113286153B CN113286153B CN202011117122.0A CN202011117122A CN113286153B CN 113286153 B CN113286153 B CN 113286153B CN 202011117122 A CN202011117122 A CN 202011117122A CN 113286153 B CN113286153 B CN 113286153B
- Authority
- CN
- China
- Prior art keywords
- reference picture
- collocated
- list
- picture
- pictures
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
- 238000000034 method Methods 0.000 title claims abstract description 64
- 238000012545 processing Methods 0.000 claims description 7
- 239000003550 marker Substances 0.000 claims description 3
- 230000008569 process Effects 0.000 description 17
- 230000002123 temporal effect Effects 0.000 description 16
- 239000013598 vector Substances 0.000 description 10
- 238000004891 communication Methods 0.000 description 9
- 230000006835 compression Effects 0.000 description 8
- 238000007906 compression Methods 0.000 description 8
- 230000003044 adaptive effect Effects 0.000 description 5
- 238000010586 diagram Methods 0.000 description 4
- 241000023320 Luma <angiosperm> Species 0.000 description 3
- 230000000903 blocking effect Effects 0.000 description 3
- 238000013500 data storage Methods 0.000 description 3
- OSWPMRLSEDHDFF-UHFFFAOYSA-N methyl salicylate Chemical compound COC(=O)C1=CC=CC=C1O OSWPMRLSEDHDFF-UHFFFAOYSA-N 0.000 description 3
- 238000005192 partition Methods 0.000 description 3
- 230000004044 response Effects 0.000 description 3
- 230000011664 signaling Effects 0.000 description 3
- 101100520660 Drosophila melanogaster Poc1 gene Proteins 0.000 description 2
- 101100520662 Saccharomyces cerevisiae (strain ATCC 204508 / S288c) PBA1 gene Proteins 0.000 description 2
- 238000013459 approach Methods 0.000 description 2
- 238000012986 modification Methods 0.000 description 2
- 230000004048 modification Effects 0.000 description 2
- 230000003287 optical effect Effects 0.000 description 2
- 238000000638 solvent extraction Methods 0.000 description 2
- 230000003068 static effect Effects 0.000 description 2
- 108010001267 Protein Subunits Proteins 0.000 description 1
- 230000008859 change Effects 0.000 description 1
- 230000003247 decreasing effect Effects 0.000 description 1
- 238000001914 filtration Methods 0.000 description 1
- 230000007257 malfunction Effects 0.000 description 1
- 230000007246 mechanism Effects 0.000 description 1
- 238000005070 sampling Methods 0.000 description 1
- 230000008054 signal transmission Effects 0.000 description 1
- 230000000153 supplemental effect Effects 0.000 description 1
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/103—Selection of coding mode or of prediction mode
- H04N19/114—Adapting the group of pictures [GOP] structure, e.g. number of B-frames between two anchor frames
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/50—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding
- H04N19/503—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding involving temporal prediction
- H04N19/51—Motion estimation or motion compensation
- H04N19/577—Motion compensation with bidirectional frame interpolation, i.e. using B-pictures
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/50—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/70—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals characterised by syntax aspects related to video coding, e.g. related to compression standards
Abstract
Disclosed are a method of encoding/decoding a group of pictures in a video stream and an encoder/decoder, wherein the method for encoding and decoding a group of pictures in a video stream includes: identifying a current picture in the group of pictures for encoding or decoding; determining a prediction type of the current picture; when the prediction type of the current picture is not equal to the I type: identifying a collocated reference picture in a group of pictures, the collocated reference picture being a reference picture for encoding or decoding a current picture, determining whether an index of the collocated reference picture in a reference picture list should be accessed using syntax to identify the collocated reference picture; and identifying the collocated reference picture in the reference picture list using the index only when the index should be accessed to identify the collocated reference picture, otherwise, identifying the collocated reference picture in the reference picture list using a default index; and encoding or decoding a current picture using the collocated reference picture.
Description
The present application is a divisional application of patent application of the invention having the application date 2013, 02, 01, application number "201380008039.1" and the name of "signal transmission explicitly of juxtaposed reference pictures for video coding".
Cross Reference to Related Applications
The present application claims priority from earlier filed U.S. provisional application No. 61/595,061 filed 2/4/2012 under 35 u.s.c. ≡119 (e) and is part of the following applications: U.S. patent application Ser. No. 13/680,531, filed 11/19 in 2012; U.S. patent application Ser. No. 13/681,237, filed 11/19 in 2012; U.S. patent application Ser. No. 13/681,254 filed 11/19/2012; all of the above applications claim priority from earlier filed U.S. provisional application No. 61/561,270, 11, 19, 2011; the above application is incorporated by reference.
Technical Field
The present disclosure relates to the field of video compression, and in particular to video compression using High Efficiency Video Coding (HEVC) with block processing.
Background
Fig. 1 depicts a content distribution system 100 that includes an encoding system 110 and a decoding system 140 that may be used to transmit and receive HEVC data. In some embodiments, the encoding system 110 may include an input interface 130, a controller 111, a counter 112, a frame memory 113, an encoding unit 114, a transmitter buffer 115, and an output interface 135. The decoding system 140 may include a receiver buffer 150, a decoding unit 151, a frame memory 152, and a controller 153. The encoding system 110 and the decoding system 140 may be coupled to each other via a transmit path that may carry the compressed bit stream 105. The controller 111 of the encoding system 110 may control the amount of data to be transmitted based on the capacity of the receiver buffer 150 and may control the encoding unit 114 to prevent malfunction of the received signal decoding operation of the decoding system 140. The controller 111 may be a processor or include, by way of non-limiting example, a microcomputer with a processor, random access memory, and read only memory.
Source picture 120 supplied from a content provider by way of non-limiting example may include a sequence of video frames including source pictures in a video sequence. Source picture 120 may be uncompressed or compressed. If source picture 120 is uncompressed, encoding system 110 may have encoding functionality. If source picture 120 is compressed, encoding system 110 may have transcoding functionality. A coding unit (coding unit) may be derived from the source picture using the controller 111. The frame memory 113 may have a first area that may be used to store incoming frames from the source picture 120 and a second area that may be used to read out frames and output them to the encoding unit 114. The controller 111 may output the area switching control signal 123 to the frame memory 113. The zone switch control signal 123 may indicate whether the first zone or the second zone is to be utilized.
The controller 111 may output the encoding control signal 124 to the encoding unit 114. The encoding control signal 124 may cause the encoding unit 114 to start an encoding operation, such as preparing encoding units based on the source picture. In response to the encoding control signal 124 from the controller 111, the encoding unit 114 may start reading out the prepared encoding unit to a high-efficiency encoding process (such as a predictive encoding process or a transform encoding process) that generates the prepared encoding unit of video compression data based on the source picture processing associated with the encoding unit.
The encoding unit 114 may pack the generated video compressed data into a Packetized Elementary Stream (PES) including the video packets. The encoding unit 114 may map video packets into the encoded video signal 122 using control information and a Program Time Stamp (PTS) and the encoded video signal 122 may be transmitted to the transmitter buffer 115.
The encoded video signal 122 including the generated video compression data may be stored in the transmitter buffer 115. The information amount counter 112 may be incremented to indicate the total amount of data in the transmitter buffer 115. As data is retrieved and removed from the buffer, the counter 122 may be decremented to reflect the amount of data in the transmitter buffer 115. The occupied area information signal 126 may be transmitted to the counter 112 to indicate whether data from the encoding unit 114 has been added or removed from the transmitter buffer 115 so that the counter 112 may be incremented or decremented. The controller 111 may control the generation of video packets generated by the encoding unit 114 based on occupied area information 126 that may be communicated in order to anticipate, avoid, block, and/or detect the occurrence of an overflow or underflow in the transmitter buffer 115.
The information amount counter 112 may be reset in response to a preset signal 128 generated and output by the controller 111. After the information counter 112 is reset, it may count the data output by the encoding unit 114 and or the amount of video packets and/or video compression data that has been generated. The information amount counter 112 may supply an information amount signal 129 representing the obtained information amount to the controller 111. The controller 111 may control the encoding unit 114 such that there is no overflow at the transmitter buffer 115.
In some embodiments, decoding system 140 may include an input interface 170, a receiver buffer 150, a controller 153, a frame memory 152, a decoding unit 151, and an output interface 175. The receiver buffer 150 of the decoding system 140 may temporarily store the compressed bitstream 105, including video compressed data and video packets based on the receipt of source pictures from the source pictures 120. The decoding system 140 may read presentation time stamp information and control information associated with the video packet in the received data and output a frame number signal 163 that may be applied to the controller 153. The controller 153 may supervise the counted number of frames at predetermined intervals. By way of non-limiting example, the controller 153 may monitor the counted number of frames each time the decoding unit 151 completes a decoding operation.
In some embodiments, the controller 153 may output the decoding start signal 164 to the decoding unit 151 when the frame number signal 163 indicates that the receiver buffer 150 is at a predetermined capacity. When the frame number signal 163 indicates that the receiver buffer 150 is below the predetermined capacity, the controller 153 may wait for the occurrence of a situation in which the counted frame number becomes equal to the predetermined amount. The controller 153 may output the decoding start signal 164 when this occurs. By way of non-limiting example, the controller 153 may output the decode start signal 164 when the frame number signal 163 indicates that the receiver buffer 150 is at a predetermined capacity. The encoded video packets and video compression data may be decoded in a monotonic order (e.g., increasing or decreasing) based on presentation time stamps associated with the encoded video packets.
In response to the decoding start signal 164, the decoding unit 151 may decode data, which is collectively one picture associated with a frame and compressed video data associated with the picture associated with a video packet from the receiver buffer 150. The decoding unit 151 may write the decoded video signal 162 into the frame memory 152. The frame memory 152 may have a first area into which the decoded video signal is written and a second area for reading out the decoded picture 160 to the output interface 175.
In various embodiments, the encoding system 110 may be incorporated into or otherwise associated with a front-end transcoder or encoding apparatus, and the decoding system 140 may be incorporated into or otherwise associated with a downstream device (such as a mobile device, a set-top box, or a transcoder).
The encoding system 110 and decoding system 140 may be used separately or together to encode and decode video data according to various encoding formats including High Efficiency Video Coding (HEVC). HEVC is a block-based hybrid spatial and temporal predictive coding scheme. In HEVC, an input image, such as a video frame, may be divided into square blocks called Coding Tree Units (CTUs) 200, as shown in fig. 2. CTUs 200 may each be up to 128x128 pixels, unlike other coding schemes that divide an input image into macroblocks of 16x16 pixels. As shown in fig. 3, each CTU 200 may be partitioned by splitting the CTU 200 into four Coding Units (CUs) 202. CU 202 may be square blocks each one-quarter the size of CTU 200. Each CU 202 may be further split into four smaller CUs 202 that are each one-fourth the size of the larger CU 202. By way of non-limiting example, the CU 202 in the upper right corner of the CTU 200 depicted in fig. 3 may be divided into four smaller CUs 202. In some embodiments, these smaller BU 202 may be further split into even smaller sized quarter, and this process of splitting CU 202 into smaller CUs 202 may be done multiple times.
Disclosure of Invention
According to one embodiment, there is provided a method for use in encoding and decoding a set of pictures in a video stream, comprising: identifying a current picture in the set of pictures for encoding or decoding; determining a slice type for the current picture; when the slice type for the current picture is not equal to I type: a collocated reference picture in the set of pictures is identified using syntax, the collocated reference picture being a reference picture for encoding or decoding a current picture, and the collocated reference picture is used to encode or decode the current picture. Wherein identifying collocated reference pictures in the set of pictures using syntax comprises: determining a reference picture list using syntax; using syntax to determine whether an index of the collocated reference picture within the reference picture list should be accessed to identify the collocated reference picture; and identifying the collocated reference picture within the reference picture list using the index only if the syntax determines that the index should be accessed to identify the collocated reference picture.
According to another embodiment, there is provided a decoder for processing an encoded video stream comprising a set of pictures, the decoder comprising: a processor; a memory is communicatively coupled to the processor. The memory stores a plurality of instructions including instructions that cause the processor to: determining a current picture in the set of pictures for decoding; determining a slice type for the current picture; when the slice type for the current picture is not equal to I type: a collocated reference picture in the set of pictures is identified using syntax, the collocated reference picture being a reference picture for decoding a current picture, and the collocated reference picture is used to decode the current picture. Wherein identifying collocated reference pictures in the set of pictures using syntax comprises: determining a reference picture list using syntax; using syntax to determine whether an index of the collocated reference picture within the reference picture list should be accessed to identify the collocated reference picture; and identifying the collocated reference picture within the reference picture list using the index only if the syntax determines that the index should be accessed to identify the collocated reference picture.
According to another embodiment, there is also provided an encoder for encoding a video stream containing a set of pictures, the encoder comprising: a processor; a memory communicatively coupled to the processor, the memory storing a plurality of instructions including instructions that cause the processor to: identifying a current picture in the set of pictures for encoding; determining a slice type for the current picture; when the slice type for the current picture is not equal to I type: a collocated reference picture in the set of pictures is identified using syntax, the collocated reference picture being a reference picture for encoding a current picture, the collocated reference picture being used to encode the current picture. Wherein identifying collocated reference pictures in the set of pictures using syntax comprises: determining a reference picture list using syntax; using syntax to determine whether an index of the collocated reference picture within the reference picture list should be accessed to identify the collocated reference picture; and identifying the collocated reference picture within the reference picture list using the index only if the syntax determines that the index should be accessed to identify the collocated reference picture.
According to another embodiment, there is also provided a method for use in encoding and decoding a set of pictures in a video stream, comprising: identifying a current picture in the set of pictures for encoding or decoding; determining a slice type for the current picture; when the slice type for the current picture is not equal to I type: determining the state of the mark; determining an index value for concatenating the reference pictures in the first reference picture list only if the first reference picture list comprises more than one reference picture when the flag is in the first state; determining an index value for the collocated reference picture in the second reference picture list only when the second reference picture list comprises more than one reference picture when the flag is in the second state; selecting a collocated reference picture using the index value; and encoding or decoding the current picture using the collocated reference picture.
Drawings
Further details of particular embodiments are described with the aid of the accompanying drawings, in which:
FIG. 1 depicts an embodiment of a content distribution system;
FIG. 2 depicts an embodiment of an input image divided into code tree units;
FIG. 3 depicts an embodiment of a coding tree unit divided into coding units;
FIG. 4 depicts a quadtree representation of coding genus units divided into coding units;
FIG. 5 depicts a possible exemplary arrangement of prediction units within a coding unit;
FIG. 6A depicts a block diagram of an embodiment of a method for encoding and/or decoding prediction units;
FIG. 6B depicts an example of a decoder according to one embodiment;
FIG. 7 depicts an exemplary embodiment of a coding unit divided into prediction units and transform units;
FIG. 8 depicts an exemplary embodiment of a quadtree representation of coding units divided into transform units;
FIG. 9 provides a syntactic enumeration illustrating one embodiment for identifying collocated reference pictures for use in decoding a current picture using two reference picture lists list0 and list 1;
FIG. 10 illustrates a set of pictures for illustrating how differences in picture order count between a current picture and a reference picture are determined;
FIG. 11 provides a flow chart illustrating coding syntax steps that may be used to identify collocated reference pictures to support decoding and encoding of a current picture;
FIG. 12A provides a syntax enumeration illustrating another embodiment for identifying collocated reference pictures for use in decoding a current picture using a common reference picture enumeration;
FIG. 12B depicts a simplified flowchart of a method for encoding video according to one embodiment;
FIG. 12C depicts a simplified flowchart of a method for decoding video according to one embodiment; and
FIG. 13 depicts an exemplary embodiment of computer hardware that may be used to implement particular embodiments.
Detailed Description
In one embodiment, a method for use in encoding and decoding a set of pictures in a video stream is provided. The method identifies a current picture in the set of pictures for encoding or decoding and determines a slice type for the current picture. When the slice type for the current picture is not equal to the I type, the method identifies a collocated reference picture in the set of pictures using a syntax for determining whether the collocated reference picture index should be accessed to identify the collocated reference picture and uses the collocated reference picture to encode or decode the current picture.
In one embodiment, there is provided a decoder for processing an encoded video stream containing a set of pictures, the decoder comprising: a processor; a memory communicatively coupled to the processor, the memory storing a plurality of instructions including instructions that cause the processor to: determining a current picture in the set of pictures for decoding; determining a slice type for the current picture; when the slice type for the current picture is not equal to the I type, performing: determining a collocated reference picture in the set of pictures using syntax; and decoding the current picture using the collocated reference picture.
In one embodiment, there is provided an encoder for encoding a video stream containing a set of pictures, the encoder comprising: a processor; a memory communicatively coupled to the processor, the memory storing a plurality of instructions including instructions that cause the processor to: identifying a current picture in the set of pictures for encoding; determining a slice type for the current picture; when the slice type for the current picture is not equal to the I type, performing: identifying collocated reference pictures in the set of pictures using syntax; and encoding the current picture using the collocated reference picture.
In one embodiment, a method for use in encoding and decoding a set of pictures in a video stream is provided, comprising: identifying a current picture in the set of pictures for encoding or decoding; determining a slice type for the current picture; when the slice type for the current picture is not equal to the I type, performing: determining the state of the mark; determining a value for concatenating the reference pictures in the first list while the flag is in the first state; determining, when the flag is in the second state, a value for concatenating the reference pictures in the second list; and encoding or decoding the current picture using the collocated reference picture.
In HEVC, an input image (such as a video frame) is decomposed into CUs that are then identified in the code. Although HEVC is described, other video compression standards may be appreciated. The CU is then further decomposed into sub-units, which are encoded as will be described later.
Initially, for encoding, a quadtree data representation may be used to describe the partitioning of CTUs 200 in fig. 2. The quadtree representation may have nodes corresponding to CTUs 200 and CUs 202. At each node of the quadtree representation, a flag "1" may be assigned if the CTU200 or CU202 is split into four CUs 202. If the node is not split into CUs 202, a flag of "0" may be assigned. By way of non-limiting example, the quadtree representation shown in fig. 4 may describe the CTU partitioning shown in fig. 3, where the CTU200 is split into 4 CUs 202 and the second CU202 is split into four smaller CUs 202. The binary data representation of the quadtree may be a CU split flag, which may be encoded and transmitted as a general overhead (overhead) along with other data, such as a skip mode flag, a merge mode flag, and a PU coding mode described later. By way of non-limiting example, the CU split-marker quadtree representation shown in fig. 4 may be encoded as a binary data representation "10100".
At each leaf of the quadtree, the final CU202 may be decomposed into one or more blocks called Prediction Units (PUs) 204. PU 204 may be square or rectangular. A CU202 having a size of 2Nx2N may have one of 4 example arrangements of PUs 204 shown in fig. 5, where a PU 204 has a size of 2Nx2N, 2NxN, nx2N, or NxN.
The PU may be obtained by spatial or temporal prediction. Temporal prediction is related to inter mode pictures. Spatial prediction is related to intra mode pictures. The PUs 204 of each CU202 may thus be encoded in either intra-mode or inter-mode. Features of encoding related to intra-mode and inter-mode pictures are described in the following paragraphs.
Intra mode encoding may encode an I picture using data from a current input picture without reference to other pictures. In intra mode, PU 204 may be spatially predictively encoded. Each PU 204 of the CU202 may have its own spatial prediction direction. The spatial prediction direction may be horizontal, vertical, 45 degree diagonal, 135 degree diagonal, DC, planar, or other directions. The spatial prediction direction for PU 204 may be encoded as a syntax element. In some embodiments, the luminance information (luminance) and the color information (chrominance) for PU 204 may be predicted separately. In HEVC, the number of luma intra prediction modes for all block sizes may be 35. The additional mode may be used for chroma intra prediction mode. In some embodiments, the chroma prediction mode may be referred to as "intra (intra luma) from luma".
Inter-mode encoding may encode "P" pictures and/or "B" pictures using data from a current input image and one or more reference images. In some cases and/or embodiments, inter-mode coding may result in better compression than intra-mode coding. In inter mode, the PUs 204 may be temporally predictively encoded such that each PU204 of the CU 202 may have one or more motion vectors and one or more associated reference pictures. Temporal prediction may be performed by a motion estimation operation that searches for a best match prediction for PU204 over an associated reference picture. The best match prediction may be described by a motion vector and an associated reference picture. The P picture uses data from the current input image and one or more reference images and may have up to one motion vector. The B picture may use data from the current input image and one or more reference images and may have up to two motion vectors. The motion vectors and reference pictures may be encoded in an encoded bitstream. In some embodiments, the motion vector may be a syntax element "MV" and the reference picture may be a syntax element "refIdx". In some embodiments, inter modes may allow both spatial and temporal predictive coding.
Fig. 6A depicts a block diagram of an encoder that may encode or decode PU204 (x). At 606, the predicted PU 206 (x') predicted by the intra mode at 602 or the inter mode at 604 as described above may be subtracted from the current PU204 (x) to obtain the residual PU 208 (e). At 608, residual PU 208 (E) may be transformed into one or more Transform Units (TUs) 210 (E) using a block transform. Each TU 210 may include one or more transform coefficients 212. In some embodiments, the block transform may be square. In alternative embodiments, the block transform may be non-square.
As shown in fig. 7, in HEVC, a set of different size block transforms may be performed on CUs 202 such that some PUs 204 may be divided into smaller TUs 210 and other PUs 204 may have TUs 210 of the same size as PUs 204. The division of CU 202 and PU204 into TUs 210 may be illustrated by a quadtree representation. By way of non-limiting example, the quadtree shown in fig. 8 represents an arrangement of TUs 210 depicted within CU 202 shown in fig. 7.
Referring back to fig. 6A, at 610, transform coefficients 212 of tu 210 (E) may be quantized into one of a limited number of possible values. In some embodiments, this is a lossy operation, where quantized data loss may not be recoverable. After the transform coefficients 212 have been quantized, at 612, the quantized transform coefficients 212 may be entropy encoded to obtain final compressed bits 214. The entropy coding scheme that may be applied during step 612 may include context-based adaptive binary arithmetic coding (CABAC) and context-adaptive variable length coding CAVLC.
At 614, quantized transform coefficients 212 may be dequantized into dequantized transform coefficients 216 (E'). The dequantized transform coefficients 216 (E ') may then be inverse transformed 616 to reconstruct the residual PU 218 (E'). The reconstructed residual PU 218 (e ') may then be added to the corresponding predicted PU 206 (x') obtained by either the spatial prediction at 602 or the temporal prediction at 604 to obtain the reconstructed PU 220 (x "), at 618. Particular embodiments may be used in determining predictions, such as temporal prediction 604 being used in a prediction process for determining collocated pictures to use. At block 620, a deblocking filter may be used on the reconstructed PU 220 (x ") to reduce blocking artifacts (blocking artifact). Also, at block 620, a sampling adaptive offset process is provided that may be conditionally performed to compensate for pixel value offset between the reconstructed pixel and the original pixel. In addition, at block 620, the reconstructed PU 220 (x') may conditionally use an adaptive loop filter to reduce or minimize coding distortion between the input and output images.
If the reconstructed image is a reference image that may be used for future temporal prediction in inter mode encoding, the reconstructed image may be stored in a reference buffer 622. An intra-mode encoded image may be a possible point at which decoding may begin without additional reconstructed images.
Fig. 6B depicts an example of a decoder according to one embodiment. The general operation of the decoder will now be described; however, it will be appreciated that those skilled in the art will appreciate variations to the described decoding process based on the disclosure and teachings herein. The decoder receives input bits from an encoder for encoded video content.
The entropy decoding block 630 performs entropy decoding on the input bitstream to generate quantized transform coefficients of the residual PU. The dequantizer 632 dequantizes the quantized transform coefficients of the residual PU. The dequantizer 632 then outputs the dequantized transform coefficients E' of the residual PU. The inverse transform block 634 receives the dequantized transform coefficients, which are then inverse transformed resulting in a reconstructed residual PU (e').
The reconstructed residual PU (e ') is then added to the corresponding prediction (x') in space or time to form a new reconstructed PU (x "). Loop filter 636 performs deblocking on reconstructed PU 220 (x ") to reduce blocking artifacts. Additionally, loop filter 636 may perform a sample adaptive offset process that compensates for pixel value offset between reconstructed pixels and original pixels after completing a deblocking filter process for decoded pictures. Also, loop filter 636 may perform adaptive loop filtering over the reconstructed PU, which minimizes coding distortion between the input and output pictures. Additionally, if the reconstructed picture is a reference picture, the reference picture is stored in the reference buffer 638 for future temporal prediction.
The predicted PU (x') is obtained by either spatial prediction or temporal prediction. Spatial prediction block 640 may receive decoded spatial prediction directions per PU, such as horizontal, vertical, 45 degree diagonal, 135 degree diagonal, DC (monotonically average), and plane. The spatial prediction direction is used to determine a prediction PU (x').
The temporal prediction block 642 performs temporal prediction by a motion estimation operation. Particular embodiments may be used in determining predictions, such as temporal prediction 642 being used in a prediction process for determining collocated pictures to use. The decoded motion vector is used to determine the predicted PU (x'). Interpolation may be used in the motion estimation operation.
Particular embodiments provide advances in identifying reference pictures to aid in encoding and decoding of current pictures. In particular, if the current picture is part of a non-I type slice, identifying the collocated reference picture is provided to support more efficient encoding and decoding of the associated current picture. The motion vector from the collocated reference picture may be used as one of the candidates for Advanced Motion Vector Picture (AMVP) and as a merge/skip mode for the block in the current picture. Information on how to identify the collocated reference picture for the current picture is described for the subsequent embodiments.
I. Summary-collocated reference picture identification
In one example, the associated collocated reference picture for the current picture may reside in a previous or subsequent picture that is decoded or encoded. The motion vector from the collocated reference picture may be used as a candidate for supporting AMVP and a merge/skip mode for the current picture.
The collocated reference picture provides a reference picture and is used in one method to identify the collocated reference picture when a B-type picture is used, the collocated reference picture may be specified in one of two lists called list0 or list1. A flag labeled as localized_from_10_flag may be used to indicate which of the two lists (list 0 or list 1) includes the collocated reference picture. A flag may be set to 1 to indicate that the picture should be derived from list0, otherwise the picture should be derived from list1. If not present in the bitstream containing a group of pictures for encoding or decoding, the default value of the allocated_from_10_flag is 1.
In particular, the following provides steps that may be used in more conventional approaches to identify collocated reference pictures. In step, the label allocated_from_10_flag as identified above is used with variables labeled list0 and list1 for RefPicList0[ ] and RefPicList1[ ]. The additional variable colPic identifies the collocated reference picture. The two steps (a) and (B) for the process are as follows:
(A) If slice_type is equal to B and allocated_from_10_flag is equal to 0, then the variable colPic indicates the picture containing the collocated partition as indicated by RefPicList1[0], meaning that the first entry in list1 is considered to be the collocated reference picture.
(B) Otherwise, when slice_type is equal to B and allocated_from_10_flag is equal to 1 or slice_type is equal to P, the variable colPic indicates the picture containing the collocated partition as indicated by RefPicList0[0], which means that the first entry in list0 is considered as the collocated reference picture.
Depending on the value of the flag (registered_from_10_flag), this first "implicit" method is used to identify the collocated reference picture as the first reference picture in list0 or list 1. However, this implicit method for defining collocated reference pictures may not be optimal. In an ideal case, the collocated reference picture should be the reference picture closest to the current picture. However, the first reference picture in list0 or list1 may not necessarily be the reference picture closest to the current picture. In addition, refPicList0[0] or RefPicList1[0] for different slices within the same picture may not point to the same collocated reference picture, which complicates the hardware implementation of the encoder or decoder. Thus, it may be useful to provide an alternative way of signaling collocated reference pictures.
Improved explicit collocated reference picture identification
To have flexibility for selecting the optimal collocated reference picture, the collocated reference picture may be explicitly signaled as an implicit alternative. For explicit signaling, when the current picture is included in a slice that is not a type I slice, the syntax element is used to explicitly represent the collocated reference picture by using a procedure that includes an embodiment that may not use the first entry reference picture in List0 or List1, or alternatively the reference picture to identify the collocated reference picture from a single List rather than two separate lists. Depending on where new syntax elements are placed to explicitly represent the collocated reference picture, one or both syntax elements for list0 and list1 may be needed, or alternatively a single list that effectively removes the need for both reference list0 and list1 may be used in more efficient coding. Additionally, when the current slice is of the I type, syntax elements for explicitly representing the collocated reference picture may not be transmitted in the encoded bitstream.
A. Explicit syntax using List0 and List1
In an embodiment method of explicitly identifying collocated reference pictures, absolute Picture Order Count (POC) differences are used to represent reference pictures. This method is implemented by using POC and the difference between the current picture POC and the reference picture POC. POC and delta POC are used to construct a Reference Picture Set (RPS). The RPS is then used to create two lists list0 and list1 that identify collocated reference pictures that can be used to encode and decode the current picture. The method of this embodiment for identifying collocated reference pictures may be performed using the syntax of fig. 9.
Fig. 9 begins by identifying a reference picture set index ref_pic_set (idx) and identifying a plurality of negative pictures (negative pictures) and positive pictures (positive pictures) for this reference picture set. The syntax variables used to identify the same number of negative and positive variables as the number of pictures in list0 and list1 are num_negative_pics and num_pos_pics. As can be explained with reference to fig. 10, the negative and positive films help determine the pictures in list0 and list 1. Fig. 10 illustrates a current picture 3 in a set of seven slices, where Picture Order Count (POC) for a picture ranges from 0 to 6. The negative film (or the picture preceding the current picture 3) includes pictures 0-2. The feature film (or the picture following the current picture 3) includes pictures 4-6. As shown above, the negative film in list0 is denoted as L0[2,1,0] in order after the current picture 3, where those numbers in brackets are the POC number of the reference picture in list0, and for example, the first entry in list0 is POC 2 and the second entry in list0 is POC1, and so on. Similarly, the feature films in list1 are denoted as L1[4,5,6] in the order following the current picture 3. Bearing in mind that pictures with POC1, 2, 3, 4,5 and 6 are encoded or decoded before picture 3.
The syntax of fig. 9 continues by determining the difference between the current picture and the reference picture in terms of POC. This supports that the list values for L0 and L1 shown in fig. 10 are transformed into more reasonable values by using difference coding. For example, using the syntactic step:
for(I＝0；I＜num_negative_pics；i++)
delta_poc_s0_minusl[i]
used_by_current_pic_s0_flag[i].
these steps subtract the enumerated picture from the current picture in POC to transform list L0[2,1,0] into a new delta POC list L0[1,2,3], to make it easier to encode the delta POC rather than the POC itself. Meanwhile, a further step sets the current picture by using the used_by_current_pic_s0_flag to indicate whether the picture in the reference list0 is used. Similarly, using the syntactic step:
for(I＝0；1＜nulm_positivc_pics；i++)
delta_poc_s1_minusl[i]
used_by_current__pic_s1_flag[i].
these steps subtract the enumerated picture from the current picture in POC to transform list L1[4,5,6] into a new delta POC list L1[ -1, -2, -3], and set the current picture by using the used_by_current_pic_s1_flag to indicate whether the picture in reference list1 is used.
Fig. 9 also includes important syntax labeled "×". In this syntax, two variables are provided for the indices of list0 and list1 in the reference picture set ref_pic_set (idx), labeled as labeled as labeled_picture_idx_list 0 and labeled_picture_idx_list 1, which specify the indices for the collocated reference pictures in list0 and list1, respectively. Further, in this important syntax, two variables for the number of current reference picture sets, labeled numrpsburr 0 and numrpsburr 1, are provided, which are also referred to as the picture numbers for list0 and list1, respectively. Variables NumRpsCurr0 and NumRpsCurr1 identify the number of entries in the current reference picture set, refPicSetCurr0 and RefPicSetCurr1, respectively.
With this important syntax in fig. 9, the collocated reference picture is explicitly signaled by the aligned_picture_idx_list0 and aligned_picture_idx_list1 in one of list0 and list1, respectively. First, in the important syntax, the number of pictures in the current reference picture set for list0, numRpsCurr0, is checked to determine if it is greater than 1. If NumRpsCurr0 is zero, nothing in list0, and if NumRpsCurr0 is one, one reference picture listed in list0 must be a collocated reference picture. However, if NumRpsCurr0 is greater than one, then syntactic aligned_picture_idx_list 0 is checked to determine which reference picture is designated as the collocated reference picture. If localized_picture_idx_list 0 does not exist, it is presumed to be equal to 0.
Second, in the important syntax of fig. 9, the number of pictures NumRpsCurr1 in the current reference picture set for list1 is checked to determine if it is greater than 1. If NumRpsCurr1 is zero, nothing in list1 is found, and if NumRpsCurr1 is one, one reference picture listed in list1 must be a collocated reference picture. However, if NumRpsCurr1 is greater than one, then syntactic aligned_picture_idx_list 1 is checked to determine which reference picture is designated as the collocated reference picture. If the localized_picture_idx_list 1 does not exist, it is presumed to be equal to 0.
Although not shown in the syntax of fig. 9, a separate flag may be provided to identify which of the two lists list0 and list1 identifies the collocated reference picture. The variable allocated_from_10_flag for marking may have two states, 1 or 0. If the allocated_from_10_flag is equal to 1, the reference picture in list0 indicated by allocated_picture_idx_list 0 will be used as the collocated reference picture, otherwise the reference picture in list1 indicated by allocated_picture_idx_list 1 will be used as the collocated reference picture.
For slice/picture types other than B-like, the allocated_picture_idx_list 0 may not exist and the decoder may be set to 1 as a default value to indicate that list0 is to be used by default. For B slice pictures, the allocated_from_10_flag may have a value of 0 or 1 to indicate which of list0 or list1 is to be used. For I slice pictures, the allocated_picture_idx_list0 and allocated_picture_idx_list1 may not be used because intra pictures do not use temporal prediction.
In practice, the method illustrated by the syntax of fig. 9 may be implemented for selecting a picture from a set of pictures as a collocated reference picture for a current picture. Several examples are provided subsequently.
In a first example using the syntax of fig. 9, the ordered_from_10_flag is 1 and NumRpsCurr0 is 5. The delta POC of the reference picture in the reference picture set labeled RefPicSetCurr0 is {2,5,1,4,3}. If the registered_picture_idx_list 0 is 2, then the reference picture from list0 with delta POC as 1 will be used as the collocated reference picture for the current picture/slice.
In a second example, the registered_from_10_flag is 0 and NumRpsCurr1 is 5. The delta POC of the reference picture in RefPicSetCurr0 is {3,1,2,4,5}. If localized_picture_idx_list 1 is 1, then the reference picture from list1 with delta POC as 1 will be used as the collocated reference picture for the current picture/slice.
Fig. 11 provides a flow chart of a compilation of syntax steps that may be used to identify collocated reference pictures to support decoding and encoding of a current picture. First, in step 300, a current picture in a group of pictures identified for encoding or decoding is provided. In step 302, the slice type of the current picture is identified for determining whether it is type B. If so, then the flag must be accessed in step 304 to determine if the collocated reference picture is identified in either list0 or list 1. If decision step 304 is used, the flag state determination method proceeds to step 306 to check list0 for collocated reference pictures, or it proceeds to step 308 to check list. If the picture is of a type other than B type, such as P type, the method proceeds directly to step 306 and the enumeration with collocated reference pictures is assumed to be list0. If the picture is of a type other than B-type and P-type, such as I-type, the method then ends, as the I-type picture does not need to send any syntax for identifying the collocated reference picture.
If list0 is to be checked, step 306 checks to see if the current number of pictures in list0 is greater than 1. If so, control proceeds to step 310 to identify a collocated reference picture from list 0. If the number of pictures is equal to one in step 306, the process proceeds to step 312 to identify the collocated reference picture as the only picture in list 0.
If list1 is to be checked, step 308 checks to see if the current number of pictures in list1 is greater than 1. If so, control proceeds to step 314 to identify a collocated reference picture from list 1. If the number of pictures is equal to one in step 308, the process proceeds to step 312 to identify the collocated reference picture as the only picture in list 1.
Finally, once the collocated reference picture is identified, the method proceeds to step 318. Step 318 provides collocated reference pictures to support encoding or decoding of the current picture.
B. Explicit syntax using a single reference list
As an alternative to the procedure illustrated by the syntax of fig. 9, a syntax-allocated_picture_idx designating an index for a collocated reference picture as one of list0 or list1 may be used at the slice header to explicitly signal the collocated reference picture for the current slice, as illustrated in the syntax enumeration of fig. 12A. This approach allows the use of the ordered_from_10_flag to determine which of list0 or list1 will be used before accessing the reference picture list. However, the syntax allocated_picture_idx may be placed after the allocated_from_10_flag. With this order, it will not be necessary to have two syntaxes. The syntax of fig. 12A may thus provide a more efficient system than the system of fig. 9.
For the syntax of fig. 12A, initially, the slice type is identified with the syntax variable slice_type. At 1202, a determination is made as to whether the tile type is B. If the slice type is B, a flag allocated_from_10_flag is used and encoded in the bitstream. The flag allocated_from_10_flag is set based on whether the collocated reference picture will come from list0 or list 1. For other slice types (e.g., I-type and P-type), the allocated_from_10_flag may not exist and the value of the allocated_from_10_flag is presumed to be equal to 1, which means that the collocated reference picture is always from list0. Therefore, the above syntax checks whether the allocated_from_10_flag should be set to a value.
After checking if the tile type is B type, it is then checked if the tile type is not equal to I type 1204. That is, the slice type is not equal to the B type or the P type. If this check is not included, the following procedure will be performed even if the slice type is type I. That is, the variable registered_picture_idx will be set to a value even if the I-type slice does not use a collocated reference picture. Still using the localized_picture_idx variable and encoding the localized_picture_idx variable in the bitstream will increase overhead. Thus, if the slice type is an I type, the allocated_picture_idx variable is not included in the encoded bitstream.
Unlike the embodiment of fig. 9, in fig. 12A, a single collocated_picture_idx that can identify collocated reference pictures is consulted. The flag collocated_from_10_flag may be set to 1 to indicate that the picture containing the collocated partition will result from checking the "if" syntax of the picture by using the collocated_picture_idx from list0, otherwise the collocated reference picture will be derived after the "else" statement from list 1.
Similar to the embodiment of fig. 9, in fig. 12A, two variables for the number of current reference picture sets, labeled num_ref_idx_l0_active_minus1 and num_ref_idx_11_active_minus1, are provided. The variables num_ref_idx_l0_active_minus1 and num_ref_idx_l1_active_minus1 (or the number of reference pictures in list0 and list1, respectively) identify the number of entries in the current reference picture set minus 1. Other variables, such as NumRpsCurr0 and NumRpsCurr1, may also be used, which identify the number of entries in the current reference picture set without subtracting 1. However, in syntax, num_ref_idx_l0_active_minus1 is checked to determine if it is greater than zero (if NumRpsCurr0 and NumRpsCurr1 are used, the variables will be checked for 1) at 1206. If this statement is not true, there is one reference picture available in list 0. Thus, the position of the reference picture in list0 may not need to be signaled or evaluated. However, in some embodiments, if only one reference picture is available in list0, the variable registered_picture_idx may be set to 0, which identifies the first and only reference picture in list 0. In other embodiments, the variable localized_picture_idx is not used and encoded in the bitstream. If the statement is true, this means that there is more than one reference picture available in list 0. If more than one reference picture is available, the variable collocated_picture_idx is set to the position of the reference picture including the collocated reference picture.
At 1208, if the registered_from_10_flag is set to 0 (and thus the else statement is evaluated), the variable num_ref_idx_l1_active_minus1 is checked to determine if it is greater than zero. If this is not true, there is one reference picture available in list 1. Therefore, the position of the reference picture in list1 need not be signaled or evaluated. However, in some embodiments, if only one reference picture is available in list1, the variable registered_picture_idx may be set to 0, which identifies the first and only reference picture in list 0. In other embodiments, the variable localized_picture_idx is not used and encoded in the bitstream. If the statement is true, this means that there is more than one reference picture available in list 1. If more than one reference picture is available in list1, the variable registered_picture_idx is set to the position of the reference picture in list1 that includes the collocated reference picture.
Fig. 12B depicts a simplified flowchart 1220 of a method for encoding video according to one embodiment. At 1222, the encoder (e.g., as shown in fig. 6A) determines the encoded block in the current slice of the current picture. A slice may be a set of blocks within the current picture. Also, a block may be a Prediction Unit (PU), but may also be the current picture or other part of a slice.
At 1224, the encoder determines whether the slice type is B type for the current picture/current block. At 1226, if the slice type is equal to the B type, the variable allocated_from_10_flag is used and the encoder sets the value to the value "0" or "1" depending on whether the collocated reference picture is found in list0 or list1, respectively. If the slice type is not equal to the B type (i.e., the slice type is equal to the I type or the P type), the encoder does not set the variable allocated_from_10_flag to any value and it uses a default value, e.g., 1.
At 1228, the encoder determines whether the slice type is not equal to the I type (i.e., the slice type is equal to the B type or the P type). At 1230, if the slice type is equal to the I type, the encoder does not set the variable allocated_picture_idx to any value. The encoder then does not encode the variable allocated_from_10_flag and the variable allocated_picture_idx in the encoded bitstream. This is because pictures in the I slice will not use temporal prediction and signaling, whether list0 or list1 will be used or the location in list0 and list1 for the collocated reference picture is not necessary.
At 1232, if the slice type is not equal to the I type or the slice type is B type, the encoder determines whether the variable allocated_from_10_flag indicates that list0 contains a collocated reference picture (e.g., allocated_from_10_flag=1). When the allocated_from_10_flag is equal to 1, then the collocated reference picture is found in list 0. At 1234, if the allocated_from_10_flag is equal to 1, the encoder determines if the variable num_ref_idx_l0_active_minus1 is greater than zero. At 1236, if the variable num_ref_idx_l0_active_minus1 is greater than zero, the encoder sets the value of the variable specified_picture_idx to the position of the collocated reference picture in list 0. When the value of the variable num_ref_idx_l0_active_minus1 is greater than zero, this means that there is more than one reference picture available in list 0. The encoder uses various methods to determine which reference picture in list0 contains the collocated reference picture. The encoder then sets the variable collocated_picture_idx to the position of the collocated reference picture. At 1238, if the variable num_ref_idx_l0_active_minus1 is not greater than zero, the encoder may not set the value of the variable registered_picture_idx to the position of the collocated reference picture in list 0. This is because there is only one reference picture in list0 and it is not necessary to identify the location. In another embodiment, the encoder may set the value of the variable assigned_picture_idx to a default value of 0.
At 1240, if the allocated_from_10_flag is equal to zero, the encoder determines if the variable num_ref_idx_l1_active_minus1 is greater than zero. When the collocated_from_10_flag is equal to zero, the collocated reference picture is found in list 1. At 1242, if the variable num_ref_idx_l1_active_minus1 is greater than zero, the encoder sets the value of the variable specified_picture_idx to the position of the collocated reference picture in list 1. When the value of the variable num_ref_idx_l1_active_minus1 is greater than zero, this means that there is more than one reference picture available in list 1. The encoder uses various methods to determine which reference picture in list1 contains the collocated reference picture. The encoder then sets the value of the variable collocated_picture_idx to the position of the collocated reference picture. At 1244, if the variable num_ref_idx_l1_active_minus1 is not greater than zero, the encoder may not set the value of the variable registered_picture_idx to the position of the collocated reference picture in list 1. This is because there is only one reference picture in list1 and it is not necessary to identify the location. In another embodiment, the encoder may set the value of the variable assigned_picture_idx to a default value of 0.
The encoder then encodes the variables allocated_from_10_flag and allocated_picture_idx in the encoded bitstream at 1246.
Fig. 12C depicts a simplified flow diagram 1250 for a method of decoding video according to one embodiment. At 1252, the decoder determines a decoded block in the current slice of the current picture (e.g., as shown in fig. 6B). A slice may be a set of blocks within the current picture. Also, a block may be a Prediction Unit (PU), but may also be the current picture or other part of a slice.
At 1254, the decoder determines whether the slice type is B type for the current picture/current block. At 1256, if the slice type is equal to the B type, the variable allocated_from_10_flag is used and the decoder determines the value of allocated_from_10_flag, which may be a value of "0" or "1", depending on whether the collocated reference picture is found in list0 or list1, respectively. At 1258, if the slice type is not equal to type B (i.e., the slice type is equal to type I or P), the decoder does not need to look up the variable allocated_from_10_flag in the encoded bitstream. In contrast, the decoder assumes a value of 1 for the allocated_from_10_flag (i.e., list0 contains the collocated reference picture if the current slice type is P-type).
At 1260, the decoder determines whether the slice type is not equal to the I type (i.e., the slice type is equal to the B type or the P type). At 1262, if the slice type is equal to the I type, the decoder does not look up the variable registered_picture_idx. This is because the type I slice does not use temporal prediction and thus the encoder may not have signaled the position in either list0 or list1 that contains the collocated reference picture. The decoder then does not need to decode the allocated_from_10_flag and variable allocated_picture_idx in the encoded bitstream 1264.
At 1266, if the slice type is not equal to the I type, the decoder determines whether the variable allocated_from_10_flag indicates that list0 contains collocated reference pictures (e.g., allocated_from_10_flag=1). When the allocated_from_10_flag is equal to 1, then the collocated reference picture is found in list 0. At 1268, if the allocated_from_10_flag is equal to 1, the decoder determines if the variable num_ref_idx_l0_active_minus1 is greater than zero. At 1270, if the variable num_ref_idx_l0_active_minus1 is greater than zero, the decoder determines the value of the variable specified_picture_idx, which indicates the position of the collocated reference picture in list 0. When the value of the variable num_ref_idx_l0_active_minus1 is greater than zero, this means that there is more than one reference picture available in list 0. Using the value of the variable allocated_picture_idx, the decoder now knows the collocated reference picture for the current block/current picture. At 1272, if the variable num_ref_idx_l0_active_minus1 is not greater than zero, the decoder may determine that the only reference picture in list0 is a collocated reference picture if available.
At 1274, if the allocated_from_10_flag is equal to zero, the decoder determines if the variable num_ref_idx_l1_active_minus1 is greater than zero. When the allocated_from_10_flag is equal to zero, then the collocated reference picture is found in list 1. At 1276, if the variable num_ref_idx_l1_active_minus1 is greater than zero, the decoder determines the value of the variable specified_picture_idx, which indicates the position of the collocated reference picture in list 1. When the value of the variable num_ref_idx_l1_active_minus1 is greater than zero, this means that there is more than one reference picture available in list 1. Using the value of the variable registered_picture_idx, the decoder now knows the collocated reference picture. At 1278, if the variable num_ref_idx_l0_active_minus1 is not greater than zero, the decoder may determine that the only reference picture in list1 is a collocated reference picture if available.
The decoder then decodes (if applicable) the encoded bitstream using the information for the variables allocated_from_10_flag and allocated_picture_idx at 1280.
C. Explicit collocated reference pictures with efficient syntax
Features common to both the syntax for parts a and B above illustrate that an explicit method for identifying collocated reference pictures may be performed if performed. The syntactic use of part a may require more resources to identify collocated reference pictures. For example, a search through two separate lists (allocated_picture_idx_list 0 and allocated_picture_idx_list 1) must be performed to identify collocated reference pictures. The syntax of part B eliminates the required resources by taking an advanced step in the system of part B to eliminate the need to search through one of the lists by initially referencing the registered_from_10_flag. Further, in part B, the slice type is checked even before the reference mark, because if the slice type is I-type or P-type instead of B-type, the mark status will be known in advance.
Similar to the change from the syntax of part a to part B, other modifications of the syntax may also be performed to make it more efficient to identify collocated reference pictures. Common features of the syntax of parts a and B include (1) identifying a current picture in a group of pictures for decoding or encoding; (2) If the current picture is part of a slice that is not of type I, (2 a) providing syntax for identifying collocated reference pictures in a group of pictures; and (2 b) decoding or encoding the current picture using the identified collocated reference picture.
Coding and encoding using the proposed syntax of fig. 9 and 12A may be performed in several ways. One possible way to encode either the localized_picture_idx_list 0, localized_picture_idx_list 1, or localized_picture_idx is to use fixed length encoding. The maximum bit for these syntax is indicated as variable Ceil (Log 2 (max_num_ref_frame), where max_num_ref_frame specifies the maximum number of reference frames, the pair of supplemental reference fields and the unpaired reference field that can be used by the decoding process for inter prediction of any picture in the sequence.
For actual encoding, various conditions apply. For example, if the allocated_from_10_flag is 1 and num_ref_idx_l0_active_minus1 is also 0, then no encoded allocated_picture_idx_list 0 or allocated_picture_idx may be encoded. Likewise, if the allocated_from_10_flag is 1 and num_ref_idx_l1_active_minus1 is 0, then the allocated_picture_idx_lis1 or allocated_picture_idx may not be encoded. Depending on the encoding process, the process following the syntax encoding rules for encoding may be used for decoding.
Execution of the sequences of instructions required to practice a particular embodiment may be performed by one or more computers in the system of fig. 1. A computer system 400 that may be used will be described with reference to fig. 13, fig. 13 being a block diagram of the functional components of computer system 400. As used herein, the term computer system 400 is used broadly to describe any computing device that can store and independently run one or more programs.
Computer system 400 may include a communication interface 414 coupled to bus 406. Communication interface 414 provides two-way communication between computer systems 400. The communication interface 414 of the corresponding computer system 400 transmits and receives electrical, electromagnetic or optical signals that include information representing various types of signals (e.g., instructions, messages, and data). Communication link 415 links one computer system 400 with another computer system 400. For example, communication link 415 may be a LAN, an Integrated Services Digital Network (ISDN) card, a modem, or the Internet.
Computer system 400 may receive messages, data, and instructions, including programs, e.g., applications, code, through its respective communication link 415 and communication interface 414. The received program code may be executed by respective processor 407 as it is received, and/or stored in storage device 410, or other associated non-volatile medium, for later execution.
In an embodiment, computer system 400 operates in conjunction with a data storage system 431 (e.g., data storage system 431) containing a database 432, which database 432 is readily accessible by computer system 400. Computer system 400 communicates with data storage system 431 over data interface 433.
Computer system 400 may include a bus 406 or other communication mechanism for communicating instructions, messages, and data, collectively, information, and one or more processors 407 coupled with bus 406 for processing information. Computer system 400 also includes a Random Access Memory (RAM) or other dynamic storage device coupled to bus 406 for storing dynamic data and instructions to be executed by processor 407. Computer system 400 may also include a Read Only Memory (ROM) 409 or other static storage device coupled to bus 406 for storing static data and instructions for processor 407. A storage device 410, such as a magnetic disk or optical disk, may also be provided and coupled to bus 406 for storing data and instructions for processor 407.
Computer system 400 may be coupled via bus 406 to a display device 411, such as an LCD screen. An input device 412, such as alphanumeric and other keys, is coupled to bus 406 for communicating information and command selections to processor 407.
According to one embodiment, individual computer systems 400 perform specific operations by their respective processors 407 executing one or more sequences of one or more instructions contained in main memory 408. Such instructions may be read into main memory 408 from another computer-usable medium, such as ROM 409 or storage device 410. Execution of the sequences of instructions contained in main memory 408 causes processor 407 to perform the processes described herein. In alternative embodiments, hard-wired circuitry may be used in place of or in combination with software instructions. Thus, embodiments are not limited to any specific combination of hardware circuitry and/or software.
Although specific embodiments have been described above in particular, this is merely to teach one of ordinary skill in the art how to make and use the specific embodiments. Many additional modifications will fall within the scope of the description, which is defined by the following claims.
Claims (24)
1. A method for encoding and decoding a group of pictures in a video stream, the method comprising:
identifying a current picture in the group of pictures for encoding or decoding;
determining a prediction type of the current picture;
when the prediction type of the current picture is not equal to the I type:
identifying a collocated reference picture in a group of pictures, the collocated reference picture being a reference picture for encoding or decoding a current picture, determining whether an index of the collocated reference picture in a reference picture list should be accessed using syntax to identify the collocated reference picture; and
identifying the collocated reference picture in the reference picture list using the index only when the index should be accessed to identify the collocated reference picture, otherwise, identifying the collocated reference picture in the reference picture list using a default index; and
the collocated reference picture is used to encode or decode a current picture.
2. The method of claim 1, wherein the grammar comprises at least one of:
a reference picture set number, which is a number of pictures in a reference picture set forming the reference picture list and including a picture preceding a current picture in decoding order, to determine whether the reference picture set number minus 1 is greater than 0; or alternatively
It is determined whether a flag of the collocated reference picture can be located using the first reference picture list or the second reference picture list as a reference picture list.
3. The method of claim 1, wherein identifying the collocated reference picture comprises:
providing a first reference picture set number including reference picture sets of all reference pictures that precede the current picture in decoding order and that can be used in inter prediction of the current picture;
determining whether the first reference picture set number minus 1 is greater than 0, and if so, providing a first reference picture list for the reference picture set;
providing a second reference picture set number including reference picture sets of all reference pictures that precede the current picture in decoding order and that can be used in inter prediction of the current picture; and
Determining whether the second reference picture set number minus 1 is greater than 0, and if so, providing a second reference picture list in the reference picture set, wherein at least one of the first reference picture list and the second reference picture list is determined to be the reference picture list.
4. A method as in claim 3, further comprising:
when the prediction type for the current picture is not equal to I-type, it is determined whether the collocated reference picture can be positioned using the first reference picture list or the second reference picture list as the reference picture list according to a state of a flag.
5. A method as in claim 3, further comprising:
determining whether the collocated reference picture can be located using either the first reference picture list or the second reference picture list as the reference picture list according to the prediction type.
6. The method of claim 5, wherein the collocated reference picture is located using either the first reference picture list or the second reference picture list when the prediction type is a B type, but is only able to be located using the first reference picture list when the prediction type is a P type.
7. A method as in claim 3, further comprising:
determining, according to the prediction type, whether the collocated reference picture can be located using either the first reference picture list or the second reference picture list as the reference picture list; and
it is determined whether the collocated reference picture can be located using the first reference picture list or using the second reference picture list according to a state of a flag.
8. The method of claim 1, wherein identifying the collocated reference picture comprises:
based on the state of the flag, indicating which reference picture in the first reference picture list and the second reference picture list includes the collocated reference picture;
if the flag is in the first state and the prediction type of the current picture is not equal to type I:
providing a first reference picture set number that counts all reference pictures preceding a current picture in decoding order in the first reference picture list and that can be used in inter prediction of the current picture; and
determining whether the first reference picture set number minus 1 is greater than 0, and if so, identifying the collocated reference picture using an index for the collocated reference picture from the first reference picture list;
If the flag is in the second state and the prediction type of the current picture is not equal to type I:
providing a second reference picture set number that counts all reference pictures preceding the current picture in decoding order in the second reference picture list and that can be used in inter prediction of the current picture; and
it is determined whether the second reference picture set number minus 1 is greater than 0, and if so, the collocated reference picture is identified using an index for the collocated reference picture from the second reference picture list.
9. A decoder for processing an encoded video stream containing groups of pictures, the decoder comprising:
a processor;
a memory communicatively coupled to the processor, the memory storing a plurality of instructions including instructions that cause the processor to:
determining a current picture in the group of pictures for decoding;
determining a prediction type of the current picture;
when the prediction type of the current picture is not equal to the I type:
determining a collocated reference picture in a group of pictures, the collocated reference picture being a reference picture for decoding a current picture, using syntax by:
Determining, using syntax, whether an index of the collocated reference picture in the reference picture list should be accessed to identify the collocated reference picture; and
identifying the collocated reference picture in the reference picture list using the index only when the index should be accessed to identify the collocated reference picture, otherwise, identifying the collocated reference picture in the reference picture list using a default index; and
the collocated reference picture is used to decode a current picture.
10. The decoder of claim 9, wherein the syntax includes at least one of:
a reference picture set number, which is a number of pictures in a reference picture set forming the reference picture list and including a picture preceding a current picture in decoding order, to determine whether the reference picture set number minus 1 is greater than 0; or alternatively
It is determined whether a flag of the collocated reference picture can be located using the first reference picture list or the second reference picture list as a reference picture list.
11. The decoder of claim 9, wherein to identify the collocated reference picture, the instructions further cause the processor to:
Providing a first reference picture set number including reference picture sets of all reference pictures that precede the current picture in decoding order and that can be used in inter prediction of the current picture;
determining whether the first reference picture set number minus 1 is greater than 0, and if so, providing a first reference picture list for the reference picture set;
providing a second reference picture set number including reference picture sets of all reference pictures that precede the current picture in decoding order and that can be used in inter prediction of the current picture; and
determining whether the second reference picture set number minus 1 is greater than 0, and if so, providing a second reference picture list in the reference picture set, wherein at least one of the first reference picture list and the second reference picture list is determined to be the reference picture list.
12. The decoder of claim 11, wherein to identify the collocated reference picture, the instructions further cause the processor to:
when the prediction type for the current picture is not equal to I-type, it is determined whether the collocated reference picture can be positioned using the first reference picture list or the second reference picture list as the reference picture list according to a state of a flag.
13. The decoder of claim 11, wherein to identify the collocated reference picture, the instructions further cause the processor to:
determining whether the collocated reference picture can be located using either the first reference picture list or the second reference picture list as the reference picture list according to the prediction type.
14. The decoder of claim 11, wherein to identify the collocated reference picture, the instructions further cause the processor to:
indicating which of the first reference picture list and the second reference picture list provides a collocated reference picture based on the status of the flag;
if the flag is in the first state and the prediction type of the current picture is not equal to type I:
providing a first reference picture set number that counts all reference pictures preceding a current picture in decoding order in the first reference picture list and that can be used in inter prediction of the current picture; and
determining whether the first reference picture set number minus 1 is greater than 0, and if so, identifying the collocated reference picture using an index for the collocated reference picture from the first reference picture list;
If the flag is in the second state and the prediction type of the current picture is not equal to type I:
providing a second reference picture set number that counts all reference pictures preceding the current picture in decoding order in the second reference picture list and that can be used in inter prediction of the current picture; and
it is determined whether the second reference picture set number minus 1 is greater than 0, and if so, the collocated reference picture is identified using an index for the collocated reference picture from the second reference picture list.
15. An encoder for processing an encoded video stream comprising groups of pictures, the encoder comprising:
a processor;
a memory communicatively coupled to the processor, the memory storing a plurality of instructions including instructions that cause the processor to:
identifying a current picture in the group of pictures for encoding;
determining a prediction type of the current picture;
when the prediction type of the current picture is not equal to the I type:
identifying collocated reference pictures in the group of pictures, the collocated reference pictures being reference pictures for encoding a current picture, determining whether an index of the collocated reference pictures in a reference picture list should be accessed using syntax to identify the collocated reference pictures; and
Identifying the collocated reference picture in the reference picture list using the index only when the index should be accessed to identify the collocated reference picture, otherwise, identifying the collocated reference picture in the reference picture list using a default index; and
the collocated reference picture is used to encode the current picture.
16. The encoder of claim 15, wherein the syntax includes at least one of:
a reference picture set number, which is a number of pictures in a reference picture set forming the reference picture list and including a picture preceding a current picture in decoding order, to determine whether the reference picture set number minus 1 is greater than 0; or alternatively
It is determined whether a flag of the collocated reference picture can be located using the first reference picture list or the second reference picture list as a reference picture list.
17. The encoder of claim 15, wherein to identify the collocated reference picture, the instructions further cause the processor to:
providing a first reference picture set number including reference picture sets of all reference pictures that precede the current picture in decoding order and that can be used in inter prediction of the current picture;
Determining whether the first reference picture set number minus 1 is greater than 0, and if so, providing a first reference picture list for the reference picture set;
providing a second reference picture set number including reference picture sets of all reference pictures that precede the current picture in decoding order and that can be used in inter prediction of the current picture; and
determining whether the second reference picture set number minus 1 is greater than 0, and if so, providing a second reference picture list in the reference picture set, wherein at least one of the first reference picture list and the second reference picture list is determined to be the reference picture list.
18. The encoder of claim 17, wherein to identify the collocated reference picture, the instructions further cause the processor to:
when the prediction type for the current picture is not equal to I-type, it is determined whether the collocated reference picture can be positioned using the first reference picture list or the second reference picture list as the reference picture list according to a state of a flag.
19. The encoder of claim 17, wherein to identify the collocated reference picture, the instructions further cause the processor to:
determining whether the collocated reference picture can be located using either the first reference picture list or the second reference picture list as the reference picture list according to the prediction type.
20. The encoder of claim 17, wherein to identify the collocated reference picture, the instructions further cause the processor to:
indicating which of the first reference picture list and the second reference picture list provides a collocated reference picture based on the status of the flag;
if the flag is in the first state and the prediction type of the current picture is not equal to type I:
providing a first reference picture set number that counts all reference pictures preceding a current picture in decoding order in the first reference picture list and that can be used in inter prediction of the current picture; and
determining whether the first reference picture set number minus 1 is greater than 0, and if so, identifying the collocated reference picture using an index of the collocated reference picture from the first reference picture list;
If the flag is in the second state and the prediction type of the current picture is not equal to type I:
providing a second reference picture set number that counts all reference pictures preceding the current picture in decoding order in the second reference picture list and that can be used in inter prediction of the current picture; and
it is determined whether the second reference picture set number minus 1 is greater than 0, and if so, the collocated reference picture is identified using an index of the collocated reference picture from the second reference picture list.
21. A method for encoding and decoding a group of pictures in a video stream, the method comprising:
identifying a current picture in the group of pictures for encoding or decoding;
determining a prediction type of the current picture;
when the prediction type of the current picture is not equal to the I type:
determining the state of the mark;
determining an index value for concatenating reference pictures in a first reference picture list only when the first reference picture list comprises more than one reference picture when the flag is in a first state;
determining an index value for concatenating reference pictures in a second reference picture list only when the second reference picture list comprises more than one reference picture when the flag is in a second state;
When an index value is determined, selecting a collocated reference picture using the index value; and
the current picture is encoded or decoded using the collocated reference picture.
22. The method of claim 21, wherein the marker comprises a first marker, the method further comprising:
determining whether the prediction type is equal to the B type; and
if the prediction type is equal to the B type, the second flag is set such that its state indicates the state of the first reference picture list or the second reference picture list.
23. The method of claim 21, further comprising:
if the number of reference pictures in the first reference picture list does not exceed one reference picture, the index value for the collocated reference picture in the first reference picture list is not encoded or the index value for the collocated reference picture in the first reference picture list is decoded.
24. The method of claim 21, further comprising:
if the number of reference pictures in the second reference list does not exceed one reference picture, the index value for the collocated reference picture in the second reference picture list is not encoded or the index value for the collocated reference picture in the second reference picture list is decoded.
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
CN202011117122.0A CN113286153B (en) | 2012-02-04 | 2013-02-01 | Method for encoding/decoding group of pictures in video stream and encoder/decoder |
Applications Claiming Priority (7)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201261595061P | 2012-02-04 | 2012-02-04 | |
US61/595,061 | 2012-02-04 | ||
US13/753,388 US9392235B2 (en) | 2011-11-18 | 2013-01-29 | Explicit way for signaling a collocated reference picture for video coding |
US13/753,388 | 2013-01-29 | ||
PCT/US2013/024294 WO2013116608A1 (en) | 2012-02-04 | 2013-02-01 | Explicit way for signaling a collocated reference picture for video coding |
CN201380008039.1A CN104969557B (en) | 2012-02-04 | 2013-02-01 | Explicit signaling of collocated reference pictures for video coding |
CN202011117122.0A CN113286153B (en) | 2012-02-04 | 2013-02-01 | Method for encoding/decoding group of pictures in video stream and encoder/decoder |
Related Parent Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201380008039.1A Division CN104969557B (en) | 2012-02-04 | 2013-02-01 | Explicit signaling of collocated reference pictures for video coding |
Publications (2)
Publication Number | Publication Date |
---|---|
CN113286153A CN113286153A (en) | 2021-08-20 |
CN113286153B true CN113286153B (en) | 2024-04-02 |
Family
ID=47722559
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201380008039.1A Active CN104969557B (en) | 2012-02-04 | 2013-02-01 | Explicit signaling of collocated reference pictures for video coding |
CN202011117122.0A Active CN113286153B (en) | 2012-02-04 | 2013-02-01 | Method for encoding/decoding group of pictures in video stream and encoder/decoder |
Family Applications Before (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201380008039.1A Active CN104969557B (en) | 2012-02-04 | 2013-02-01 | Explicit signaling of collocated reference pictures for video coding |
Country Status (4)
Country | Link |
---|---|
US (1) | US9392235B2 (en) |
EP (1) | EP2810439B1 (en) |
CN (2) | CN104969557B (en) |
WO (1) | WO2013116608A1 (en) |
Families Citing this family (17)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
PL231159B1 (en) | 2011-09-09 | 2019-01-31 | Kt Corp | Method for achieving temporary predictive vector of motion and the device for application of this method |
US9185408B2 (en) | 2011-11-18 | 2015-11-10 | Google Technology Holdings LLC | Efficient storage of motion information for high efficiency video coding |
CN103959791B (en) | 2011-11-18 | 2017-07-04 | 谷歌技术控股有限责任公司 | The explicit way of juxtaposition picture is sent with signal for high efficiency video code (HEVC) |
BR112014012187A2 (en) | 2011-11-21 | 2017-05-30 | Motorola Mobility Llc | implicit determination and combined implicit and explicit determination of placed image for temporal prediction |
WO2013101643A1 (en) | 2011-12-26 | 2013-07-04 | General Instrument Corporation | Implicit determination of collocated picture for temporal prediction |
WO2013154673A1 (en) | 2012-04-11 | 2013-10-17 | Motorola Mobility Llc | Signaling of temporal motion vector predictor (mvp) flag for temporal prediction |
US9549177B2 (en) | 2012-04-11 | 2017-01-17 | Google Technology Holdings LLC | Evaluation of signaling of collocated reference picture for temporal prediction |
US9319681B2 (en) | 2012-07-18 | 2016-04-19 | Google Technology Holdings LLC | Signaling of temporal motion vector predictor (MVP) enable flag |
JP6239472B2 (en) * | 2014-09-19 | 2017-11-29 | 株式会社東芝 | Encoding device, decoding device, streaming system, and streaming method |
WO2016138513A1 (en) * | 2015-02-27 | 2016-09-01 | Arris Enterprises, Inc. | Modification of unification of intra block copy and inter signaling related syntax and semantics |
WO2016143972A1 (en) * | 2015-03-11 | 2016-09-15 | 엘지전자(주) | Method and apparatus for encoding/decoding video signal |
US11425390B2 (en) | 2018-01-26 | 2022-08-23 | Electronics And Telecommunications Research Institute | Method and apparatus for image encoding and image decoding using temporal motion information |
WO2019147067A1 (en) * | 2018-01-26 | 2019-08-01 | 한국전자통신연구원 | Method and apparatus for image encoding and image decoding using temporal motion information |
KR102609949B1 (en) * | 2018-08-17 | 2023-12-04 | 후아웨이 테크놀러지 컴퍼니 리미티드 | Reference image management in video coding |
US11758193B2 (en) * | 2019-11-04 | 2023-09-12 | Hfi Innovation Inc. | Signaling high-level information in video and image coding |
JP7464742B2 (en) | 2020-03-21 | 2024-04-09 | 北京字節跳動網絡技術有限公司 | Reference Picture Resampling |
WO2021254379A1 (en) | 2020-06-20 | 2021-12-23 | Beijing Bytedance Network Technology Co., Ltd. | Inter layer prediction with different coding block size |
Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN101039423A (en) * | 2002-07-15 | 2007-09-19 | 株式会社日立制作所 | Moving picture encoding method and decoding method |
CN101208957A (en) * | 2005-06-24 | 2008-06-25 | 株式会社Ntt都科摩 | Method and apparatus for video encoding and decoding using adaptive interpolation |
CN101356822A (en) * | 2006-01-10 | 2009-01-28 | 汤姆逊许可公司 | Method and apparatus for constructing reference picture lists for scalable video coding svc. |
Family Cites Families (41)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7466843B2 (en) * | 2000-07-07 | 2008-12-16 | Pryor Timothy R | Multi-functional control and entertainment systems |
WO2002025323A2 (en) * | 2000-09-20 | 2002-03-28 | Dataplay, Inc. | Etched micro lens and method and apparatus for fabricating |
US6961055B2 (en) | 2001-05-09 | 2005-11-01 | Free Radical Design Limited | Methods and apparatus for constructing virtual environments |
US7822120B2 (en) | 2002-07-26 | 2010-10-26 | Panasonic Corporation | Moving picture encoding method, moving picture decoding method, and recording medium |
US7227901B2 (en) | 2002-11-21 | 2007-06-05 | Ub Video Inc. | Low-complexity deblocking filter |
PL378138A1 (en) | 2003-05-20 | 2006-03-06 | Lego A/S | Method and system for manipulating a digital representation of a three-dimensional object |
US7609763B2 (en) | 2003-07-18 | 2009-10-27 | Microsoft Corporation | Advanced bi-directional predictive coding of video frames |
JP4262014B2 (en) * | 2003-07-31 | 2009-05-13 | キヤノン株式会社 | Image photographing apparatus and image processing method |
US7567617B2 (en) | 2003-09-07 | 2009-07-28 | Microsoft Corporation | Predicting motion vectors for fields of forward-predicted interlaced video frames |
US7400681B2 (en) | 2003-11-28 | 2008-07-15 | Scientific-Atlanta, Inc. | Low-complexity motion vector prediction for video codec with two lists of reference pictures |
JP3879741B2 (en) | 2004-02-25 | 2007-02-14 | ソニー株式会社 | Image information encoding apparatus and image information encoding method |
US20080267290A1 (en) | 2004-04-08 | 2008-10-30 | Koninklijke Philips Electronics N.V. | Coding Method Applied to Multimedia Data |
EP1589763A2 (en) | 2004-04-20 | 2005-10-26 | Sony Corporation | Image processing apparatus, method and program |
IL165190A (en) | 2004-11-14 | 2012-05-31 | Elbit Systems Ltd | System and method for stabilizing an image |
US7261266B2 (en) | 2005-03-31 | 2007-08-28 | Satterfield Johnny A | Deployable video arm |
US8385427B2 (en) | 2005-04-15 | 2013-02-26 | Apple Inc. | Reduced resolution video decode |
EP1915871B1 (en) | 2005-07-21 | 2017-07-05 | Thomson Licensing | Method and apparatus for weighted prediction for scalable video coding |
WO2007116551A1 (en) | 2006-03-30 | 2007-10-18 | Kabushiki Kaisha Toshiba | Image coding apparatus and image coding method, and image decoding apparatus and image decoding method |
US8270492B2 (en) | 2006-05-12 | 2012-09-18 | Panasonic Corporation | Moving picture decoding device |
US8254455B2 (en) * | 2007-06-30 | 2012-08-28 | Microsoft Corporation | Computing collocated macroblock information for direct mode macroblocks |
US8896712B2 (en) | 2007-07-20 | 2014-11-25 | Omnivision Technologies, Inc. | Determining and correcting for imaging device motion during an exposure |
US8908765B2 (en) | 2007-11-15 | 2014-12-09 | General Instrument Corporation | Method and apparatus for performing motion estimation |
EP2081386A1 (en) | 2008-01-18 | 2009-07-22 | Panasonic Corporation | High precision edge prediction for intracoding |
US9078007B2 (en) | 2008-10-03 | 2015-07-07 | Qualcomm Incorporated | Digital video coding with interpolation filters and offsets |
US20100180100A1 (en) * | 2009-01-13 | 2010-07-15 | Mavrix Technology, Inc. | Matrix microprocessor and method of operation |
US8917769B2 (en) | 2009-07-03 | 2014-12-23 | Intel Corporation | Methods and systems to estimate motion based on reconstructed reference frames at a video decoder |
WO2011050641A1 (en) | 2009-10-28 | 2011-05-05 | Mediatek Singapore Pte. Ltd. | Video coding methods and video encoders and decoders with localized weighted prediction |
US8594200B2 (en) | 2009-11-11 | 2013-11-26 | Mediatek Inc. | Method of storing motion vector information and video decoding apparatus |
US9083984B2 (en) | 2010-03-19 | 2015-07-14 | Texas Instruments Incorporated | Adaptive coding structure and adaptive FCode determination in video coding |
US10104391B2 (en) | 2010-10-01 | 2018-10-16 | Dolby International Ab | System for nested entropy encoding |
AU2011362447B2 (en) | 2011-03-14 | 2015-09-24 | Hfi Innovation Inc. | Method and apparatus for deriving temporal motion vector prediction |
US8934552B2 (en) | 2011-03-31 | 2015-01-13 | Qualcomm Incorporated | Combined reference picture list construction and mapping |
CN103959791B (en) * | 2011-11-18 | 2017-07-04 | 谷歌技术控股有限责任公司 | The explicit way of juxtaposition picture is sent with signal for high efficiency video code (HEVC) |
US9185408B2 (en) * | 2011-11-18 | 2015-11-10 | Google Technology Holdings LLC | Efficient storage of motion information for high efficiency video coding |
BR112014012187A2 (en) | 2011-11-21 | 2017-05-30 | Motorola Mobility Llc | implicit determination and combined implicit and explicit determination of placed image for temporal prediction |
WO2013101643A1 (en) | 2011-12-26 | 2013-07-04 | General Instrument Corporation | Implicit determination of collocated picture for temporal prediction |
JP6421931B2 (en) * | 2012-03-06 | 2018-11-14 | サン パテント トラスト | Moving picture coding method and moving picture coding apparatus |
US9549177B2 (en) | 2012-04-11 | 2017-01-17 | Google Technology Holdings LLC | Evaluation of signaling of collocated reference picture for temporal prediction |
WO2013154673A1 (en) | 2012-04-11 | 2013-10-17 | Motorola Mobility Llc | Signaling of temporal motion vector predictor (mvp) flag for temporal prediction |
US9319681B2 (en) | 2012-07-18 | 2016-04-19 | Google Technology Holdings LLC | Signaling of temporal motion vector predictor (MVP) enable flag |
US20140056356A1 (en) | 2012-08-21 | 2014-02-27 | Motorola Mobility Llc | Method and apparatus for efficient signaling of weighted prediction in advanced coding schemes |
-
2013
- 2013-01-29 US US13/753,388 patent/US9392235B2/en active Active
- 2013-02-01 WO PCT/US2013/024294 patent/WO2013116608A1/en active Application Filing
- 2013-02-01 CN CN201380008039.1A patent/CN104969557B/en active Active
- 2013-02-01 EP EP13704860.9A patent/EP2810439B1/en active Active
- 2013-02-01 CN CN202011117122.0A patent/CN113286153B/en active Active
Patent Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN101039423A (en) * | 2002-07-15 | 2007-09-19 | 株式会社日立制作所 | Moving picture encoding method and decoding method |
CN101208957A (en) * | 2005-06-24 | 2008-06-25 | 株式会社Ntt都科摩 | Method and apparatus for video encoding and decoding using adaptive interpolation |
CN101356822A (en) * | 2006-01-10 | 2009-01-28 | 汤姆逊许可公司 | Method and apparatus for constructing reference picture lists for scalable video coding svc. |
Non-Patent Citations (1)
Title |
---|
The Improvements on Reference Picture Buffering and List Construction;Yu Yue 等;Joint Collaborative Team on Video Coding (JCT-VC) of ITU-T SG16 WP3 and ISO/IEC JTC1/SC29/WG11 7th Meeting: Geneva, CH, 21-30 November, 2011;20111130;全文 * |
Also Published As
Publication number | Publication date |
---|---|
WO2013116608A1 (en) | 2013-08-08 |
US20130202034A1 (en) | 2013-08-08 |
WO2013116608A8 (en) | 2014-11-27 |
US9392235B2 (en) | 2016-07-12 |
CN104969557B (en) | 2020-11-06 |
CN113286153A (en) | 2021-08-20 |
CN104969557A (en) | 2015-10-07 |
EP2810439A1 (en) | 2014-12-10 |
EP2810439B1 (en) | 2021-10-27 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN113286153B (en) | Method for encoding/decoding group of pictures in video stream and encoder/decoder | |
CN107347160B (en) | Explicit way to signal collocated pictures for efficient video coding | |
KR102034938B1 (en) | Method of intra picture block copy for screen content and video coding | |
US9467694B2 (en) | Implicit determination and combined implicit and explicit determination of collocated picture for temporal prediction | |
KR101350597B1 (en) | Methods and apparatuses for multi-view video coding | |
US9300959B2 (en) | Implicit determination of collocated picture for temporal prediction | |
US20140023142A1 (en) | Signaling of temporal motion vector predictor (mvp) enable flag | |
JP2022533056A (en) | Adaptive motion vector difference decomposition for affine mode | |
CN113039782B (en) | Method and device for deblocking subblocks in video encoding and decoding | |
US20230031699A1 (en) | Methods and apparatuses for signaling of syntax elements in video coding | |
CN111183641A (en) | Video encoding device, video decoding device, video encoding method, video decoding method, and program | |
CN113574890A (en) | Construction of paired motion candidate columns based on specified candidates | |
KR101366288B1 (en) | A method and apparatus for decoding a video signal | |
CN111586419B (en) | Video decoding method, video encoding method and device |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
GR01 | Patent grant | ||
GR01 | Patent grant |