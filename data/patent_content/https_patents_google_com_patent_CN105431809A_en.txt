CN105431809A - Virtual keyboard input for international languages - Google Patents
Virtual keyboard input for international languages Download PDFInfo
- Publication number
- CN105431809A CN105431809A CN201380076553.9A CN201380076553A CN105431809A CN 105431809 A CN105431809 A CN 105431809A CN 201380076553 A CN201380076553 A CN 201380076553A CN 105431809 A CN105431809 A CN 105431809A
- Authority
- CN
- China
- Prior art keywords
- character strings
- candidate character
- grid
- probability
- calculation element
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/018—Input/output arrangements for oriental characters
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/02—Input arrangements using manually operated switches, e.g. using keyboards or dials
- G06F3/023—Arrangements for converting discrete items of information into a coded form, e.g. arrangements for interpreting keyboard generated codes as alphanumeric codes, operand codes or instruction codes
- G06F3/0233—Character input methods
- G06F3/0237—Character input methods using prediction or retrieval techniques
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0487—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser
- G06F3/0488—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser using a touch-screen or digitiser, e.g. input of commands through traced gestures
- G06F3/04883—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser using a touch-screen or digitiser, e.g. input of commands through traced gestures for inputting data by handwriting, e.g. gesture or text
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0487—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser
- G06F3/0488—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser using a touch-screen or digitiser, e.g. input of commands through traced gestures
- G06F3/04886—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser using a touch-screen or digitiser, e.g. input of commands through traced gestures by partitioning the display area of the touch-screen or the surface of the digitising tablet into independently controllable areas, e.g. virtual keyboards or menus
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/20—Natural language analysis
- G06F40/274—Converting codes to words; Guess-ahead of partial word inputs
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F2203/00—Indexing scheme relating to G06F3/00 - G06F3/048
- G06F2203/041—Indexing scheme relating to G06F3/041 - G06F3/045
- G06F2203/04101—2.5D-digitiser, i.e. digitiser detecting the X/Y position of the input means, finger or stylus, also when it does not touch, but is proximate to the digitiser's interaction surface and also measures the distance of the input means within a short range in the Z direction, possibly with a separate measurement setup
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F2203/00—Indexing scheme relating to G06F3/00 - G06F3/048
- G06F2203/048—Indexing scheme relating to G06F3/048
- G06F2203/04803—Split screen, i.e. subdividing the display area or the window area into separate subareas
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F2203/00—Indexing scheme relating to G06F3/00 - G06F3/048
- G06F2203/048—Indexing scheme relating to G06F3/048
- G06F2203/04808—Several contacts: gestures triggering a specific function, e.g. scrolling, zooming, right-click, when the user establishes several contacts with the surface simultaneously; e.g. using several fingers or a combination of fingers and pen
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/03—Arrangements for converting the position or the displacement of a member into a coded form
- G06F3/041—Digitisers, e.g. for touch screens or touch pads, characterised by the transducing means
- G06F3/044—Digitisers, e.g. for touch screens or touch pads, characterised by the transducing means by capacitive means
Abstract
In one example, a computing device includes at least one processor configured to output for display, a graphical keyboard. The at least one processor may also be configured to model, in a first lattice, a plurality of candidate character strings that include symbols of a first alphabet. The first lattice may indicate spatial probabilities of the plurality of candidate character strings. The at least one processor may be configured to determine, using a second lattice that indicates probabilities of one or more words of a second language based at least in part on the spatial probabilities of the plurality of candidate character strings, a probability that the at least one of the plurality of candidate character strings corresponds to at least one word included in the second language. The at least one processor may be configured to output for display, the one or more symbols representing at least one word.
Description
Background technology
Some calculation elements (such as, mobile phone, flat computer etc.) can provide graphic keyboard as a part for graphic user interface, there is sensitive display (such as screen) write text to use.Graphic keyboard can make the user of calculation element can input text (such as, Email, text message or document etc.).Such as, there is exportable figure (or " soft ") keyboard making user can be inputted data by the key indicating (such as, by rapping) to there is the display of sensitive display place of sensitive display in calculation element.
In some cases, calculation element can present graphic keyboard, user by rap keyboard each key or by the his or her finger that slides on the region be associated with key with substantially mutual with this graphic keyboard than marking word.Like this, graphic keyboard provides the input method allowing user to be come input character, word or one group of word by one or more gesture.Therefore, graphic keyboard can allow user to realize efficiency to a certain degree by fast and accurately input text.
There is provided the calculation element of graphic keyboard that word prediction, automatic calibration and/or proposed techniques can be utilized to determine word from user's input.Under some international linguistic context, the key of graphic keyboard can be associated with the character in the alphabet of first language (such as English).User can select one or more keys of graphic keyboard to represent the character string of the word that second language (such as, Chinese, Korean, Japanese etc.) comprises and/or character with input.Make word prediction, automatic calibration and/or proposed techniques can accelerate Text Input and reduce misspelling.But one or more in these technology have some shortcoming.Such as, in some instances, provide graphic keyboard and depend on possibly word and/or the character correctly cannot determining the second language desired by user from user's input of one or more calculation elements in above-mentioned technology.Therefore, user may need to carry out other effort to input character and or the word of second language.
Summary of the invention
In one example, a kind of method comprises and comprises the graphic keyboard of multiple key with display by calculation element output.At least one in described multiple key can be associated with the one or more symbols in the first alphabet being included in first language.Described method also can comprise in response to receiving in the instruction that there is at least one gesture that sensitizing input device place detects, to each multiple candidate character strings modelings comprising the first alphabetic(al) symbol in the first grid.Described first grid can indicate the Spatial Probability of each in described multiple candidate character strings, and wherein said Spatial Probability is at least in part based on the instruction of at least one gesture described.Described method can comprise at least one in described multiple candidate character strings at least in part based on the Spatial Probability of described multiple candidate character strings use second grid of probability of one or more words of instruction second language determine in described multiple candidate character strings described at least one probability corresponding at least one word be included in second language.At least one word described represents by corresponding with second language second alphabetic(al) one or more symbol.Described method can comprise in response to determining that described probability meets threshold value, is exported represent that described one or more symbol of at least one word described is with display by calculation element.
In one example, a kind of computer-readable recording medium coding has instruction, and described instruction makes the output of at least one processor comprise the graphic keyboard of multiple key with display when being performed.At least one in described multiple key can be associated with the one or more symbols in the first alphabet being included in first language.Described computer-readable recording medium codified has instruction, and described instruction makes at least one processor described in response to receiving there is the instruction of at least one gesture that sensitizing input device place detects to each multiple candidate character strings modelings comprising the first alphabetic(al) symbol in the first grid.Described first grid can indicate the Spatial Probability of each in described multiple candidate character strings, and wherein said Spatial Probability is at least in part based on the instruction of at least one gesture described.Described computer-readable recording medium codified has instruction, described instruction make at least one processor described at least one in described multiple candidate character strings at least in part based on the Spatial Probability of described multiple candidate character strings use the second grid of the probability of one or more words of instruction second language determine in described multiple candidate character strings described at least one probability corresponding at least one word be included in second language.At least one word described represents by corresponding with second language second alphabetic(al) one or more symbol.Described computer-readable recording medium codified has instruction, and described instruction makes at least one processor described in response to determining that described probability meets threshold value, exports and represents that described one or more symbol of at least one word described is with display.
In one example, a kind of calculation element can comprise at least one processor, and wherein, at least one processor described is configured to export the graphic keyboard that comprises multiple key with display.At least one in described multiple key can be associated with the one or more symbols in the first alphabet being included in first language.At least one processor described of described calculation element can be configured in response to receiving in the instruction that there is at least one gesture that sensitizing input device place detects, to each multiple candidate character strings modelings comprising the first alphabetic(al) symbol in the first grid.Described first grid can indicate the Spatial Probability of each in described multiple candidate character strings, and wherein said Spatial Probability is at least in part based on the instruction of at least one gesture described.At least one processor described of described calculation element can be configured to at least one in described multiple candidate character strings, at least in part based on the Spatial Probability of described multiple candidate character strings use second grid of probability of one or more words of instruction second language determine in described multiple candidate character strings described at least one probability corresponding at least one word be included in second language.At least one word described represents by corresponding with second language second alphabetic(al) one or more symbol.At least one processor described of described calculation element can be configured in response to determining that described probability meets threshold value, exports and represents that described one or more symbol of at least one word described is with display.
The details of one or more example is set forth in the accompanying drawings and the description below.Other features, objects and advantages of the present disclosure will from described description and accompanying drawing and claims apparent.
Accompanying drawing explanation
Fig. 1 illustrates being configured at least in part based on the concept map selecting the user of the character be included in the alphabet of first language input to determine one or more character of second language and/or the EXEMPLARY COMPUTING DEVICE of word according to one or more aspect of the present disclosure.
Fig. 2 is the block diagram of the further details of an example of the calculation element as shown in Figure 1 illustrated according to one or more technology of the present disclosure.
Fig. 3 illustrates that output pattern content according to one or more technology of the present disclosure is with the block diagram of the EXEMPLARY COMPUTING DEVICE shown at remote-control device place.
Fig. 4 is the concept map of the grid (lattice) illustrated according to technology of the present disclosure, and calculation element can generate described grid based on the instruction of user's input of the alphabetic(al) character selected in first language and use it to determine the word of second language.
Fig. 5 be illustrate according to one or more technology of the present disclosure at least in part based on the block diagram selecting the continuous gesture being included in character in the alphabet of first language to determine the further details of an example of the calculation element shown in one or more character of second language and/or Fig. 1 of word.
Fig. 6 A-6B is the process flow diagram of the exemplary operations of the calculation element from gesture determination word and/or phrase illustrated according to one or more technology of the present disclosure.
Fig. 7 be illustrate according to one or more aspect of the present disclosure at least in part based on the process flow diagram selecting the user's input being included in character in the alphabet of first language to determine the exemplary operations of one or more character of second language and/or the calculation element of word.
Fig. 8 be illustrate according to one or more aspect of the present disclosure at least in part based on the process flow diagram selecting the user's input being included in character in the alphabet of first language to determine the exemplary operations of one or more character of second language and/or the calculation element of word.
Fig. 9 is the concept map of the grid illustrated according to technology of the present disclosure, and calculation element can generate described grid based on the instruction of user's input of the alphabetic(al) character selected in first language and use it to determine the word of second language.
Embodiment
Usually, the disclosure relates to following technology: receive user at the graphic keyboard place comprising the key corresponding with the alphabetic(al) character of first language and input, and determines one or more character and/or the word of second language based on described user's input at least in part.Such as, under international linguistic context, the key of graphic keyboard may correspond to the alphabetic(al) character in first language (such as English).In order to input character and/or the word of second language (such as Chinese, Korean, Japanese etc.), user can provide user's input of the one group of character selecting first language, and this group character is jointly that one or more character of second language and/or the pronunciation of word represent.Such as, pinyin string can be one group of Latin character, and this group Latin character is jointly that the pronunciation of Chinese character or word represents.
Technology of the present disclosure can be improved under international linguistic context, use graphic keyboard to the automatic Prediction of character and/or word and/or automatic calibration.Such as, according to technology of the present disclosure, calculation element can determine the instruction that the user corresponding with the zones of different of graphic keyboard inputs.Along with each instruction incrementally determined by calculation element, calculation element can construct one or more candidate character strings of the character of the key of the zones of different comprised close to selected graphic keyboard.Calculation element can incrementally structural implications based on the first grid of the probability of the candidate character strings of the character of the key of the zones of different close to selected graphic keyboard.In some instances, the prefix of correctly and/or improperly spelling that the pronunciation of word that candidate character strings can comprise in second language represents.
Along with calculation element receives the instruction of user's input, calculation element also can construct the second grid based on candidate character strings, and this second grid indicates the probability of one or more words of second language based on vocabulary and spatial information.Calculation element can use the second grid to determine that the word of second language corresponds to the probability of candidate character strings.In some instances, one or more words of joining of the exportable probability correlation with meeting threshold value of calculation element are to show.
Like this, be different from and use static key to map, with probabilistic manner, the instruction of user's input that calculation element can represent based on the pronunciation of the character selected in second language and/or word determines that user may be intended to the word of the second language inputted.Therefore, transliteration technique of the present disclosure can improve accuracy and/or the speed that calculation element exports the word of second language.Described technology can reduce or prevent calculation element automatic calibration or predict character string from gesture input error mistakenly.Like this, described technology can reduce and/eliminate user corrects the word of automatic calibration or prediction needs when inputting word.Therefore, calculation element can receive less input to input word and/or manually error recovery, the thus effort of minimizing user inputs character string from user.In some instances, the calculation element receiving less input can perform less operation and therefore consume less electric power.
Fig. 1 illustrates being configured at least in part based on the concept map selecting the user of the character be included in the alphabet of first language input to determine one or more character of second language and/or the EXEMPLARY COMPUTING DEVICE of word according to one or more aspect of the present disclosure.In the example of fig. 1, calculation element 2 can be mobile phone.But, in other example, calculation element 2 can be the calculation element of flat computer, personal digital assistant (PDA), laptop computer, portable type game device, portable electronic device, E-book reader, wrist-watch, TV platform or another type.
As shown in Figure 1, calculation element 2 comprises and there is sensitive display 4.The sensitive display 4 that exists of calculation element 2 can be used as the input media of calculation element 2 and is used as output unit.In some instances, there is sensitive display 4 can comprise and integrated there is sensitizing input device and display device.Such as, exist sensitive display 4 can be used as using there is sensitive screen there is sensitizing input device, such as resistive touch screen, surface acoustic wave touch screen, capacitive touch screen, projection-type capacitive touch screen, pressure-sensitive screen, sound pulse identification touch-screen or another there is sensitive screen technology.Exist sensitive display 4 can use in liquid crystal display (LCD), dot-matrix display, light emitting diode (LED) display, Organic Light Emitting Diode (OLED) display, electric ink or the similar monochrome or color monitor visual information can being exported to the user of calculation element 2 any one or be multiplely used as output unit.
Calculation element 2 exist sensitive display 4 can comprise can from the user of calculation element 2 detect user input there is sensitive screen.Exist sensitive display 4 rap by user's (such as, utilize finger or pointer to touch or point to and there is the user of one or more positions of sensitive display 4) one or more detected from calculation element 2 and/or non-tapping gesture and/or continuously gesture to receive the instruction of user's input.There is sensitive screen and can present output to user in what there is sensitive display 4.There are the various user interfaces that sensitive display 4 can be presented on the application (such as electronic information application, Internet-browser application etc.) that calculation element 2 place performs.Alternately one or more during the user of calculation element 2 comes to apply with these by the respective user interfaces of each application, carry out n-back test in order to calculation element 2.
Calculation element 2 can comprise user interface (" UI ") module 6 and Keysheet module 8.Module 6 and 8 can perform to use and reside in calculation element 2 and the operation of the mix description of the software performed on calculation element 2, hardware, firmware or hardware, software and firmware.Calculation element 2 can utilize multiple processor to carry out execution module 6 and 8.Module 6 and 8 can perform as the virtual machine performed on underlying hardware by calculation element 2.Module 6 and 8 can realize according to various mode.Such as, UI module 6 and/or Keysheet module 8 can be implemented as and can download or the application of pre-installation or " app ".In another example, UI module 6 and/or Keysheet module 8 can be implemented as a part for the operating system of calculation element 2.
The UI module 6 of calculation element 2 can be received in from existing sensitive display 4 the one or more instructions that there is user's input that sensitive display 4 detects.Usually, there is sensitive display 4 at every turn and receive when the instruction of user's input of the position detection that there is sensitive screen, UI module 6 can receive from existing sensitive display 4 information inputted about user.UI module 6 can by from the time ordered sets that there is information that sensitive display 4 receives and be assembled into the event of instruction gesture, such as touch event sequence.Each touch event in sequence can comprise represent parameter (such as, when, where, initiator to) data or component, there is existence and/or the movement of the input at sensitive screen place in described parameter characterization.Each touch event in sequence can comprise the location components corresponding with the position that there is sensitive display 4, with exist sensitive display 4 when detect the user of this position input relevant time component and with touch event correspond to this position on carry or under push away relevant motion components.In addition, one or more event can have concurrent time component, and such event is only described to touch event for illustrative purposes, can indicate any type of gesture that there is sensitizing input device place.
UI module 6 can determine based on touch event sequence one or more characteristics that user inputs, and comprises the information about these the one or more characteristics in each touch event in touch event sequence.Such as, UI module 6 can determine the curvature of reference position that user inputs, the end position of user's input, the density of a part for user's input, the speed of a part for user's input, the direction of a part for user's input and a part for user's input.One or more touch events in touch event sequence can comprise (except time as above, position and motion components) characteristic component, and it comprises the information of the one or more characteristics (such as density, speed etc.) about user's input.UI module 6 can send comprise component or the parametric data be associated with each touch event touch event sequence as the output to Keysheet module 8.
In the example of fig. 1, UI module 6 can make to there is sensitive display 4 output example user interface 14.In this example, user interface 14 comprises the graphic element being presented at the position that there is sensitive display 4.Fig. 1 illustrates the editing area 16A of user interface 14, the graphic keyboard 16B of user interface 14 and suggestion word region 18A-18C.Editing area 16A can comprise the graphic element of such as image, object, hyperlink, text character etc.Graphic keyboard 16B comprises the graphic element being shown as key.Suggestion word region 18A and 18B comprises suggestion word, and it represents the selectable spelling correction or word suggestion of replacing the character string be included in editing area 16A.In the example of fig. 1, editing area 16A comprises the graphic element (such as word) being shown as text character 22A-22B.The user of calculation element 2 provides user to input input text in editing area 16A by the position that there is sensitive display 4 of the key at display graphics keyboard 16B.
Intermediary between each assembly that UI module 6 can serve as calculation element 2 is to carry out determining based on there is input that sensitive display 4 detects and to generate by the output that there is sensitive display 4 and present.Such as, UI module 6 can receive the information of the expression of the keyboard layout comprising key included graphic keyboard 16B from Keysheet module 8.UI module 6 can generate touch event based on about the information that there is user's input that sensitive display 4 detects.UI module 6 can determine the selection (such as, UI module 6 can determine the position of one or more touch event corresponding to the region that there is sensitive display 4 that present graphic keyboard 16B) of one or more location components close to one or more key based on the location components in touch event sequence.As the output to Keysheet module 8, touch event sequence can send together with the position that there is sensitive display 4 and present each key by UI module 6.Responsively, UI module 6 can receive character string and one or more suggestion word as the input from Keysheet module 8.The one or more suggestion words be associated with character string, character string to be included in editing area 16A, are included in suggestion word region 16C by the renewable user interface 14 of UI module 6.UI module 6 can make to exist the user interface 14 that sensitive display 4 presents renewal.
As the output (comprising for the graphic keyboard 16B as user interface 14) to UI module 6, the Keysheet module 8 of calculation element 2 can send the keyboard layout comprising the multiple keys relevant with one or more written language (such as English, Spanish etc.).One or more character or operation can be assigned to each key in the multiple keys in keyboard layout by Keysheet module 8.Such as, Keysheet module 8 can generate qwerty keyboard layout, and it comprises the key of the character used when representing and key in English.Qwerty keyboard layout also can comprise the key (such as backspace key, delete key, space bar, enter key etc.) of the operation used when representing and key in English.
Keysheet module 8 can receive from UI module 6 data representing touch event sequence.Touch event can comprise the data that there is the position of sensitive screen representing and there is sensitive display 4 at each key place that there is sensitive display 4 and present graphic keyboard 16B.Keysheet module 8 can use such as spatial model 10 and language model 12 to determine that touch event sequence represents the selection to one or more key based on the position of key.
In order to determine the one or more keys corresponding with touch event sequence, Keysheet module 8 can use one or more spatial model, such as spatial model 10.Usually, Keysheet module 8 can generate and input based on user one or more probability that the position data be associated have selected one or more particular key of graphic keyboard by usage space model 10.In some instances, spatial model 10 comprises the bivariate Gauss model for each key.The bivariate Gauss model of key can comprise the distribution of the coordinate corresponding with the position that there is sensitive display 4 presenting given key (such as (x, y) coordinate to).More particularly, in some instances, the bivariate Gauss model of key can comprise the distribution of the coordinate corresponding with the position that there is sensitive display 4 that the user when user view selects given key selects the most continually.Distance between the position data of user's input and the high-density region of spatial model 10 is shorter, and the key be associated with spatial model 10 is higher by the probability selected.Distance between the position data of user's input and the high-density region of spatial model 10 is larger, and the key be associated with spatial model 10 is lower by the probability selected.
The relevant position of the location components (such as coordinate) of the one or more touch events in touch event sequence with one or more keys of graphic keyboard 16B can compare by usage space model 10 by Keysheet module 8, and compares based on these probability generating and key occurs and selects.In some instances, Keysheet module 8 can usage space model 10 span Model score.Spatial model score value can at least in part based on the probability being indicated selected key by the position that there is sensitive display 4 of rapping or gesture is crossed over continuously.In some instances, spatial model score value can indicate the combined probability of the key of a group selection at least in part based on the position of the UI device 12 crossed over by gesture.
The key position of the location components of each touch event in touch event sequence and the particular key of graphic keyboard 16B can compare by usage space model 10 by Keysheet module 8.The location components of each touch event in sequence can comprise the position that there is sensitive display 4.The key position (barycenter of such as key) of the key in graphic keyboard 16B can comprise the diverse location that there is sensitive display 4.Keysheet module 8 can determine between two positions Euclidean distance by usage space model 10, and generates key by the probability selected based on Euclidean distance.Share the key of larger Euclidean distance compared to one or more touch event, spatial model 10 can indicate high probability for the key sharing less Euclidean distance with one or more touch event.Based on the spatial model probability be associated with each key, each key with most high spatial model probability can be selected the time series being assembled into key by Keysheet module 8, and then Keysheet module 8 can determine corresponding character representation character string.The combined probability of each key be associated with the character in character string can represent the spatial model score value of character string.As described further below, Keysheet module 8 can determine the probability corresponding with multiple keys of the position close to touch event for touch event.That is, if touch event instruction is close to the position of " Z " key of graphic keyboard 16B, then Keysheet module 8 can determine that " Z " key is by the spatial model probability selected, and can determine that " X " key and " S " key are by the spatial model probability selected.
Keysheet module 8 can use language model 12 based on one or more character of the candidate character strings determination language corresponding with the key sequence indicated by touch event and or word.Candidate character strings can represent the character of the different possible key sequence indicated by touch event.Along with Keysheet module 8 receives the instruction of user's input, Keysheet module 8 can determine one or more character and/or the word of language concomitantly based on candidate's string.Keysheet module 8 may have access to language model 12 and is output for being presented at the word that there is sensitive display 4 place with prediction and/or automatic calibration.
Usually, the language model 12 of calculation element 2 can comprise one group of word in language vocabulary.In some instances, language model 12 can based on and/or the set of words that comprises in the dictionary being stored in calculation element 2 or the addressable remote computing device place of calculation element 2.The frequency that language model 12 can occur in given linguistic context based on word indicates the probability of each corresponding words.Language model 12 can realize one or more n gram language model.N gram language model can be provided in continuous items sequence middle term x based on the item before in sequence
iprobability distribution (that is, the P (x of (letter, word, punctuation mark or other separator)
i| x
i-(n-1)..., x
i-1)).Language model 12 further describes in this article.
The instruction that technology of the present disclosure can input based on the user that the key of the graphic keyboard with the alphabetic(al) associated characters as first language (such as English) is corresponding determines character and/or the word of the second language (such as Chinese) that user may be intended to input with probabilistic manner.Such as, based on input pronunciation, calculation element 2 can represent that this type of character and/or the word of second language are determined in the instruction of user's input of (such as pinyin string).User can use the graphic keyboard comprising the key corresponding with the alphabetic(al) character of first language to input to pronounce to represent.By according to technology of the present disclosure with the character of probabilistic manner determination second language and/or word, this type of technology can reduce user cursorily and/or inaccurately rap or gesticulated one or more key time user input the ability of this type of character and/or word.
For illustrative purposes, described technology is described in detail with further reference to Fig. 1.In the example of fig. 1, calculation element 2 output comprises the graphic keyboard 16B of multiple key with display.Such as, Keysheet module 8 can generate the data of the expression comprising graphic keyboard 16B.UI module 6 can generate the expression that comprises user interface 14 and based on the data of presentation graphic keyboard 16B graphic keyboard 16B is included in the data in user interface 14.UI module 8 can send information to existing sensitive display 4, described information comprise for exist sensitive display 4 place display user interface 14 instruction.There is sensitive display 4 can receive described data and make to exist sensitive display 4 and present the user interface 14 comprising editing area 16A, graphic keyboard 16B and suggestion word region 16C.Graphic keyboard 16B can comprise multiple key.As shown in Figure 1, described multiple key can be associated with the one or more symbols (such as character, word or other suitable expression any) in the first alphabet being included in first language.Such as, the key of graphic keyboard 16B can be associated with " Z " character of English alphabet.In other example, multiple character can be associated with the key of graphic keyboard 16B.Such as, character " A ", " Β " and " C " can all be associated with single key, and different user's inputs can cause each in selection three kinds of characters.
In the example of fig. 1, user can perform at input position 20A-20I place and a series ofly rap input.For illustrative purposes, indicated by circle in FIG and eachly rap position 20A-20I, but in some instances, there is sensitive display 4 and can not export this type of broken circle, and in various different example, such part can be larger and/or less.Such as, user may wish the pinyin string that input comprises " zhong " and the pronunciation of " guo " represents, it forms Chinese word " zhongguo " jointly.Word " zhongguo " refers to this country of China and the meaning is " China ".As shown in Figure 1, user may attempt enter key sequence z-h-o-n-g-g-u-o; But user cursorily may rap z-h-o-n-g-h-u-o.Such as, user can provide the input selecting input position 20A-20I in the following order: 20A → 20B → 20C → 20D → 20E → 20F → 20G → 20F → 20G → 20H → 201.At input position 20F place, compared with the barycenter starting " g " key of pinyin string " guo " with user view, user may cursorily rap closer to the barycenter of " h " key.As further described herein, although user cursorily raps z-h-o-n-g-h-u-o, realize the Chinese word " China " of the exportable expection of calculation element 2 of technology of the present disclosure.
UI module 6 can incrementally receive from existing sensitive display 4 information that position 20A-20I is rapped in instruction, and described information is assembled into the time series (such as, each touch event comprises location components, time component and motion components) of touch event.Touch event can be sent to Keysheet module 8 by UI module 6.The information (such as, position, time, action etc.) that Keysheet module 8 can receive touch event from UI module 6 and be associated with each touch event.
In response to receiving in the instruction that there is at least one gesture that sensitive display 4 place is detected, Keysheet module 8 can determine that the one group one or more different candidate corresponding from touch event sequence goes here and there.Such as, Keysheet module 8 can be determined to rap " z " key that position 20A corresponds to graphic keyboard 16B by usage space model 10, raps position 20B and corresponds to " h " key, rap position 20C and correspond to " O " key, rap position 20D and correspond to " n " key, rap position 20E and correspond to " g " key.The character string corresponding with corresponding key jointly represents that the first candidate goes here and there " zhong ".Keysheet module 8 also can be determined to rap " z " key that position 20A corresponds to graphic keyboard 16B by usage space model 10, rap position 20B and correspond to " h " key, rap position 20C and correspond to " O " key, rap position 20D and correspond to " m " key, rap position 20E and correspond to " v " key.The character string corresponding with corresponding key jointly represents that the second candidate goes here and there " zhomv ".Therefore, along with Keysheet module 8 receives touch event from UI module 6, Keysheet module 8 incrementally can generate multiple candidate string, the various combination of the character that its each expression is corresponding with the close key rapping position 20A-20H.
In some instances, each character in candidate character strings can have corresponding spatial model score value, and the probability that position corresponds to the key be associated with respective symbols is rapped in its instruction.That is, character " z " can be associated with the spatial model score value of 0.64, raps to indicate the probability that input 20A corresponds to " z " key of graphic keyboard 16B.In some instances, Keysheet module 8 is the spatial model score value that each candidate concatenates into that expression is included in the gross space Model score of the character in candidate character strings.Such as, Keysheet module 8 can be the product that first candidate's string " zhong " span Model score is the independent spatial model score value of each character in first candidate's string.
According to technology of the present disclosure, along with Keysheet module 8 receives the instruction that there is the tapping gesture at sensitive display 4 place, Keysheet module 8 incrementally can determine candidate character strings and the spatial model probability corresponding with corresponding candidate character string.As previously mentioned, candidate character strings can comprise the character of English alphabet.In some instances, Keysheet module 8 will comprise one or more modelings in multiple candidate character strings of the character of the first alphabet (such as English) in the first grid.In some instances, each pronunciation represents that (such as pinyin string) and/or candidate's string can be referred to as " mark ", and the first grid can be referred to as " mark grid ".Mark grid can indicate as mentioned above can at least in part based on the one or more Spatial Probability in multiple candidate character strings of the instruction of tapping gesture.
As further illustrated in Figure 4, mark grid can be the figure comprising the summit connected by limit.Each summit can be identified by index.In some instances, the candidate character strings with n character by be 0 from index summit carry out modeling to the limit that index is the summit of n.Such as, candidate character strings " zhong " can be associated with from summit 0 to the limit on summit 5 by Keysheet module 8.As further described in FIG 4, Keysheet module 8 can use any amount of suitable data structure to realize mark grid, the status information of described data structure storage about limit, summit and other corresponding informance of mark grid.
As a part of candidate character strings being carried out to modeling, weight also can be associated with each bar corresponding sides by Keysheet module 8.In some instances, described weight indicates the spatial model probability of the candidate character strings be associated with limit.Such as, the weight of the spatial model probability of instruction candidate's string " zhong " can be assigned to the limit from 0 to summit, summit 5 be associated with candidate character strings " zhong ".In various example, along with being determined by Keysheet module 8 that user inputs (such as, corresponding with rapping position 20A-20H raps) or the instruction of the continuous part of gesture (illustrating further in Fig. 5-6B), Keysheet module 8 can incrementally use mark grid to carry out modeling to each in multiple candidate character strings.
Keysheet module 8 can use the second grid of the probability of one or more words of instruction second language based on the candidate character strings of modeling in mark grid, determine one or more candidate word of second language (such as Chinese) based on the Spatial Probability of multiple candidate character strings at least in part.One or more candidate word of second language can be represented by one or more symbols of second alphabet (such as Chinese) of second language (such as, character, word or other suitable pictorial symbolization).Such candidate word can represent the corresponding word of can going here and there with the candidate that user inputs from second language prediction.
In some instances, each character in second language and/or word can be referred to as " word " usually, and the second grid can be referred to as " word grid ".As mark grid, word grid can be the figure comprising the summit connected by limit.Each summit also can be identified by index.In some instances, the candidate word comprising alphabetic(al) n character of second language by be 0 from index summit carry out modeling to the limit that index is the summit of n.Such as, Keysheet module 8 can along from the limit on 0 to summit, summit 2 to comprise two Chinese character " in " and the candidate word " China " of " state " carry out modeling.In some instances, composer module 50 pairs of word grids 120 carry out modeling, make the summit of word grid 120 share the vertex index identical with the vertex index of mark grid 110.That is, in some instances, word grid 120 can comprise the summit with the vertex index identical with mark grid 110.Further example is illustrated in Fig. 9.As further described in FIG 4, Keysheet module 8 can use any amount of suitable data structure to realize word grid, and described data structure storage is about the information of the status information on limit, summit and other correspondence of mark grid.
As a part of candidate's string being carried out to modeling, weight also can be associated with each corresponding sides by Keysheet module 8.The weight on limit can represent be included in the one or more words in second language condition next organize the probability of one or more candidate string.Keysheet module 8 can determine weight based on space and probabilistic language model.Such as, the weight on limit can at least in part based on the probabilistic language model of " zhonghuo " under the condition of Chinese word " China ", and Chinese word " China " can be included in the Chinese word in language model 12.In other words, Keysheet module 8 can be determined to suppose that Chinese word " China " (" zuhongguo ") is the word of user view input, and user inputs the probability of candidate's string " zhonghuo " (comprising two candidates's string " zhong " and " huo ").As further described in FIG 4, under the condition of " China ", the probabilistic language model of " zhonghuo " can appear at frequency in Chinese, receive the linguistic context (such as, using n gram language model) etc. of the instruction of user's input based on such as " China ".Indicate above as previous, user cursorily may key in " huo " instead of character string " guo " when " zhongguo " that intention input is corresponding with Chinese word " China ".Therefore Keysheet module 8 can create many limits in word grid, the probability of these limits instruction different candidate character strings combination under the condition of Chinese word " China ".Like this, if user cursorily raps unexpected or incorrect character (such as, input " guo " time " h " key but not " g "), then Keysheet module 8 provides the technology determining the word of second language by testing multiple different candidate character strings.Like this, described technology provides the word forecasting techniques that more can adapt to user's input error, thus improves Consumer's Experience and reduce the effort of user input text.
Keysheet module 8 can determine the weight on the limit of " zhonghuo " at least in part based on the spatial model probability of the combination of " zhong " and " huo " (it jointly can comprise the character string " zhonghuo " corresponding with the limit in the word grid of word " China ").That is, in some instances, Keysheet module 8 can determine the spatial model probability of the combination of the product comprising the spatial model probability of candidate's string " zhong " and the spatial model probability of candidate's string " huo ".
In some instances, Keysheet module 8 for given word included in language model 12 (such as, " China ") and one group of one or more candidate string (such as, " zhonghuo ") determine the weight on the limit in word grid at least in part based on the spatial model probability of combination and probabilistic language model.In some instances, the spatial model probability of combination can be added with probabilistic language model or be multiplied by Keysheet module 8, with the combining weights of the general probability of the condition next one or multiple candidate string that generate instruction word included in language model.The probability of the word of the second language corresponding with this limit desired by user can be indicated more greatly higher to the weight of deckle.Lower to the weight of the deckle probability of word desired by user that more I instruction is corresponding with this limit.In various example, along with Keysheet module 8 determines the instruction that user inputs, Keysheet module 8 incrementally can make word grid to determine based on candidate's string one or more words of being included in language model 12.
One or more candidate word or phrase and the weight be associated can be exported to UI module 6 in the editing area 16A being included in user interface 14 or as the independent suggestion word in suggestion word region 18A and 18B of user interface 14 by Keysheet module 8.Such as, Keysheet module 8 can determine one or more candidate word of being associated with the limit with the weight meeting threshold value.As an example, Keysheet module 8 can determine two candidate word with two highest weighting from word grid.Keysheet module 8 can will represent that the data of these two word candidates send to UI module 6.UI module 6 can receive from Keysheet module 8 and represent one or more candidate word or the data of phrase (comprising former character string) and the weight of described one or more candidate word or phrase or the sequence corresponding with weight.
UI module 6 is by comprising coming more new suggested word region 18A by the highest ranked candidate word as suggestion word " China ".UI module 6 is by comprising coming more new suggested word region 18B using the second high candidate word as suggestion word " taskwork ".From user interface 14, user provides by rapping or provide input close to the position that there is sensitive display 4 that there is sensitive display 4 and export suggestion word 18A and inputs the user of suggestion word 18A rapping position 201 place.Such as, user raps on the position that there is sensitive display 4 that there is sensitive display 4 and present suggestion word 18A (such as, " China ").Suggestion word 38A raps and can make " China " of UI module 6 more in new user interface 14 and editing area 16A.
Like this, technology of the present disclosure can make calculation element can export character and/or the word of the second language desired by user, although the instruction of user's input can comprise carelessness and/or incorrect user input.Such as, in the examples described above, although user may cursorily rap " huo " instead of desired " guo ", Keysheet module 8 exports the word " China " of expecting based on the weight of word grid.Therefore, described technology can make user to use the alphabetic(al) keyboard comprising first language to input the text of second language more quickly at calculation element place.Because user can provide less input with correction calculation device and/or input text, the calculation element realizing technology of the present disclosure can perform less operation, and result consumes less electric power.
Fig. 2 is the block diagram of the EXEMPLARY COMPUTING DEVICE illustrated according to one or more aspect of the present disclosure.The calculation element 2 of Fig. 2 is described below under the background of Fig. 1.Fig. 2 only illustrates a particular example of calculation element 2, and other examples many of calculation element 2 can use and can comprise the subset of assembly included in EXEMPLARY COMPUTING DEVICE 2 or can comprise the unshowned add-on assemble of Fig. 2 in other example.
As shown in the example of Fig. 2, calculation element 2 comprises and there is sensitive display 4, one or more processor 40, one or more input media 42, one or more communication unit 44, one or more output unit 46 and one or more memory storage 48.The memory storage 48 of calculation element 2 also comprises UI module 6, Keysheet module 8, inputs and search module 48, composer module 50, decoder module 52, one or more grid 54, spatial model 10 and language module 12.Each assembly 4,40,42,44,46,48,8,48,50,52,6,54,10 and 12 can interconnect for inter-component communication (physically, communicatedly and/or operatively) by communication channel 50.In some instances, communication channel 50 can comprise system bus, network connection, interprocess communication data structure or any other method for data communication.
One or more input medias 42 of calculation element 2 can receive input.The example of input is sense of touch, the sense of hearing and video input.In one example, the input media 42 of calculation element 2 comprises mouse, keyboard, voice response system, video camera, microphone or the device for other type any of detecting the input from people or machine.In some instances, input media 42 can be there is sensitizing input device, and it can comprise and there is sensitive screen, touch sensitive screen etc.
One or more output units 46 of calculation element 2 can generate output.The example exported is sense of touch, the sense of hearing and video frequency output.In one example, the output unit 46 of calculation element 2 comprises and there is sensitive display, sound card, video graphics adaptor, loudspeaker, cathode-ray tube (CRT) (CRT) monitor, liquid crystal display (LCD) or the device for other type any of generating the output to people or machine.Output unit 46 can comprise the display device of such as cathode-ray tube (CRT) (CRT) monitor, liquid crystal display (LCD) or the device for generating other type any that vision exports.
One or more communication units 44 of calculation element 2 can via one or more network by sending and/or receiving network signal and communication with external apparatus on described one or more network.Such as, calculation element 2 can use communication unit 44 send on the radio net of such as cellular radio network and/or receive radio signals.Equally, communication unit 44 can send and/or receiving satellite signal on the satellite network of such as GPS network network.The example of communication unit 44 comprises network interface unit (such as, Ethernet card), optical transceiver, radio-frequency (RF) transceiver, GPS or can send and/or receive the device of other type any of information.Other example of communication unit 44 can comprise and being present in mobile device
gPS, 3G, 4G and
radio and USB (universal serial bus) (USB) controller.
In some instances, there is the function that sensitive display 4 can comprise input media 42 and/or output unit 46 in calculation element 2.In the figure 2 example, there is sensitive display 4 and can be or can comprise and there is sensitizing input device such as there is sensitive screen, touch sensitive screen etc.In some instances, there is sensitive screen can detect and there is sensitive screen place and/or neighbouring object.As an example ranges, there is sensitive screen and can detect there is the object in sensitive screen 2 inches or shorter distance (such as, finger or pointer).There is the position (such as, (x, y) coordinate) that there is sensitive screen that sensitive screen can determine to detect object.In another example ranges, there is sensitive screen and can detect the object that distance exists sensitive screen 6 inches or shorter distance, other scope is also possible.There is the position that sensitive screen can use electric capacity, inductance and/or optical recognition to determine the screen selected by the finger of user.In some instances, as described in about output unit 46, exist sensitive display 4 use sense of touch, audio or video stimulate provide output to user.In the figure 2 example, there is sensitive display 4 and present user interface, the user interface 14 of such as Fig. 1.
Although be shown as the intraware of calculation element 2, there is sensitive display 4 and also can represent and share data routing for the external module sending and/or receive input and output with other assembly of calculation element 2.Such as, in one example, exist sensitive display 4 represent the outer enclosure that is positioned at calculation element 2 and with the installed with built-in component (screen such as, on mobile phone) of its calculation element 2 be physically connected.In another example, exist sensitive display 4 can be positioned at the encapsulation of calculation element 2 outer and with the external module (such as, sharing wired and/or wireless data pathway monitor, projector etc. with flat computer) of its calculation element 2 be physically separated.
One or more memory storages 48 in calculation element 2 can store during the operation of calculation element 2 for the treatment of information.In some instances, memory storage 48 is temporary storages, and the fundamental purpose meaning memory storage 48 is not longer-term storage.Memory storage 48 on calculation element 2 can be configured to the short-term storage of volatile memory for information, if therefore power-off, does not retain the content of storage.The example of volatile memory comprises the volatile memory of random access memory (RAM), dynamic RAM (DRAM), static RAM (SRAM) and other form known in the art.
In some instances, memory storage 48 also comprises one or more computer-readable recording medium.Memory storage 48 can be configured to store information more more substantial than volatile memory.Memory storage 48 also can be configured to the longer-term storage of nonvolatile storage space for information, and retains information after power supply opening/pass closed loop.The example of nonvolatile memory comprises the form of magnetic hard disk, CD, floppy disk, flash memory or electrically-programmable memory (EPROM) or electrically erasable (EEPROM) storer.Memory storage 48 can store with UI module 6, Keysheet module 8, input and search the programmed instruction and/or data that module 48, composer module 50, decoder module 52, one or more grid 54, spatial model 10 and language module 12 be associated.
One or more processor 40 can practical function and/or execution instruction in calculation element 2.Such as, processor 40 on calculation element 2 can receive and perform the instruction stored by memory storage 48, and it performs UI module 6, Keysheet module 8, inputs the function of searching module 48, composer module 50, decoder module 52, one or more grid 54, spatial model 10 and language module 12.These instructions performed by processor 40 can make calculation element 2 program the term of execution at memory storage 48 inner storag information.The display of sensitive display 4 place is there is and has the user interface 14 of editing area 16A, graphic keyboard 16B and suggestion word region 18A-18B in the instruction that processor 40 can perform UI module 6, module 48, composer module 50, decoder module 52, one or more grid 54, spatial model 10 and language module 12 are searched in Keysheet module 8, input to make to exist sensitive display 4.Namely, module UI module 6, Keysheet module 8, input are searched module 48, composer module 50, decoder module 52, one or more grid 54, spatial model 10 and language module 12 and can be operated to perform various action by processor 40, are included in instruction and making that the position that there is sensitive screen that there is sensitive display 4 receives gesture and there is sensitive display 4 there is sensitive display 4 place and present user interface 14.
According to aspect of the present disclosure, Keysheet module 8 initially can send data to make there is sensitive display 4 output pattern keyboard with display to UI module 6.This graphic keyboard can comprise multiple key.At least one in described multiple key can be associated with the one or more symbols in the first alphabet being included in first language.Such as, in some instances, one or more key can be associated with the single character be included in English alphabet.In another example, one or more key can be associated with the multiple characters be included in English alphabet separately.Although for illustrative purposes, it is English that example of the present disclosure can relate to first language, and first language can be any language, and the first alphabet of first language can be any alphabet.Other figure of the composition that symbol can refer in character, word or alphabet and/or language usually represents.
In some instances, user can rap and/or continuous gesture with the execution of the region place of display at the output pattern keyboard that there is sensitive display 4.In response to receiving in the instruction that there is at least one gesture that sensitizing input device 4 place detects, composer module 50 can to each multiple character string modelings comprising the first alphabetic(al) symbol in the first grid.First grid can indicate the Spatial Probability of each in multiple character string.In some instances, Spatial Probability is at least in part based on the instruction of at least one gesture.
In some instances, composer module 50 can second grid of probability of one or more words of instruction second language to be used to determine in described multiple character string at least one in described multiple character string based on the Spatial Probability of multiple character string at least in part at least one correspond to probability of at least one word included in second language.As further described in FIG 4, the limit of word grid 120 can indicate at least one probability corresponding at least one word included in second language in described multiple character string.At least one word described can be represented by corresponding with second language second alphabetic(al) one or more symbol.
In some instances, in response to determining that a probability meets threshold value, decoder module 52 can send data to UI module 6 and represent that one or more symbols of at least one word are with display to make there is sensitive display 4 output.Such as, as further described in FIG 4, decoder module 52 can determine the weight on one or more limit of word grid 120 as illustrated in fig. 4.Decoder module 52 can determine that the weight on one or more limit meets threshold value.Such as, decoder module 52 can determine that one or more weight is greater than threshold value.In such an example, decoder module 52 can send data to UI module 6 and export the word that is associated with limit to show to make to exist sensitive display 4.Although describe technology of the present disclosure about the word exporting second language, described technology also can be used for prediction, automatic calibration and/or exports single character, many words phrase, sentence etc.
Fig. 3 illustrates that output pattern content according to one or more technology of the present disclosure is with the block diagram of the EXEMPLARY COMPUTING DEVICE shown at remote-control device place.Usually, graphical content can comprise any visual information that can be output to show, such as text, image, moving image group etc.Example shown in Fig. 3 comprises calculation element 60, there is sensitive display 64, communication unit 70, projector 80, projecting apparatus screen 82, mobile device 86 and visual display unit 90.Although in fig. 1 and 2 in order to the object of example is shown as free-standing calculation element 10, the such as calculation element of calculation element 60 can be comprise processor or for any assembly of other suitable calculating computing environment of executive software instruction or system usually, and such as, do not need to comprise to there is sensitive display.
As shown in the example of Fig. 3, calculation element 60 can be comprise the processor as the function described about the processor 40 in Fig. 2.In such an example, calculation element 60 is operationally coupled to by communication channel 62A (can be system bus or other suitable connection) and there is sensitive display 64.Calculation element 60 is also operationally coupled to communication unit 70 (further describing) below by communication channel 62B (also can be system bus or other suitable connection).Although as the example in Fig. 3 illustrates individually, calculation element 60 is operationally coupled to by any amount of communication channel in one or more communication channel exists sensitive display 64 and communication unit 70.
In other example, shown in such as, calculation element 10 in previously passed Fig. 1-2, calculation element can refer to portable or mobile device, such as mobile phone (comprising smart phone), laptop computer etc.In some instances, calculation element can be desk-top computer, flat computer, intelligent television platform, camera, personal digital assistant (PDA), server, main frame etc.
There is sensitive display 64 (similar as shown in Figure 1 there is sensitive display 4) display device 66 can be comprised and there is sensitizing input device 68.Display device 66 such as can receive data and display graphics content from calculation element 60.In some instances, there is sensitizing input device 68 can use electric capacity, inductance and/or optical recognition to determine the one or more users that there is sensitive display 64 place to input (such as, continuous gesture, many touch gestures, single touch gestures etc.), and use communication channel 62A that the instruction that such user inputs is sent to calculation element 60.In some instances, there is sensitizing input device 68 and can be physically located at display device 66 top, make when above input block to be positioned at the graphic element shown by display device 66 by user, the position that there is sensitizing input device 68 corresponds to the position of the display device 66 of display graphics element.
As shown in Figure 3, calculation element 60 also can comprise and/or operationally be coupled to communication unit 70.Communication unit 70 can comprise the function of the communication unit 44 as described in Fig. 2.The device of other type any that the example of communication unit 70 can comprise network interface unit, Ethernet card, optical transceiver, radio-frequency (RF) transceiver or can send and receive information.Other example of such communication unit can comprise bluetooth, 3G and Wi-Fi radio, USB (universal serial bus) (USB) interface etc.Calculation element 60 also can comprise and/or operationally be coupled in Fig. 3 such as, for simple and clear and illustrate object and unshowned other device one or more, input media, output unit, storer, memory storage etc.
Fig. 3 also illustrates projector 80 and projecting apparatus screen 82.Other this type of example of projection arrangement can comprise electronic whiteboard, holographic display and other the suitable device any for display graphics content.Projector 80 and projecting apparatus screen 82 can comprise one or more communication units that related device can be communicated with calculation element 60.In some instances, one or more communication unit can allow the communication between projector 80 and projecting apparatus screen 82.Projector 80 can receive from calculation element 60 data comprising graphical content.In response to receiving described data, graphical content can project on projecting apparatus screen 82 by projector 80.In some instances, projector 80 can use optical identification or other suitable technology to determine one or more user's inputs at projecting apparatus screen place (such as, continuous gesture, many touch gestures, single touch gestures etc.), and utilize one or more communication unit that the instruction that such user inputs is sent to calculation element 60.In such an example, projecting apparatus screen 82 may be unnecessary, and graphical content can be projected on any suitable medium by projector 80, and uses optical identification or other so suitable technology to detect one or more user input.
In some instances, projecting apparatus screen 82 can comprise and there is sensitive display 84.There are subset or all functions that sensitive display 84 can comprise the function of UI device 4 as described in this disclosure.In some instances, there is sensitive display 84 and can comprise additional function.Projecting apparatus screen 82 (such as, electronic whiteboard) can receive data and display graphics content from calculation element 60.In some instances, there is sensitive display 84 can use electric capacity, inductance and/or optical recognition to determine one or more user's inputs at projecting apparatus screen 82 place (such as, continuous gesture, many touch gestures, single touch gestures etc.), and use one or more communication unit that the instruction that such user inputs is sent to calculation element 60.
Fig. 3 also illustrates mobile device 86 and visual display unit 90.Mobile device 86 and visual display unit 90 can comprise calculating and concatenation ability separately.The example of mobile device 86 can comprise electronic reading apparatus, convertible notebook device, mixing plate-like devices etc.The example of visual display unit 90 can comprise other semi-stationary devices of such as TV, computer monitor etc.As shown in Figure 3, mobile device 86 can comprise and there is sensitive display 88.Visual display unit 90 can comprise and there is sensitive display 92.There is sensitive display 88,92 and can comprise the subset that there is the function of sensitive display 4 as described in this disclosure or all functions.In some instances, there is sensitive display 88,92 and can comprise additional function.Under any circumstance, such as, there is sensitive display 92 and can receive data and display graphics content from calculation element 60.In some instances, there is sensitive display 92 can use electric capacity, inductance and/or optical recognition to determine one or more user's inputs at projecting apparatus screen place (such as, continuous gesture, many touch gestures, single touch gestures etc.), and use one or more communication unit that the instruction that such user inputs is sent to calculation element 60.
As mentioned above, in some instances, there is sensitive display 64 place to be presented in the exportable graphical content of calculation element 60, and it is coupled to calculation element 60 by system bus or other suitable communication channel.Calculation element 60 also exportable graphical content to be presented at one or more remote-control device places of such as projector 80, projecting apparatus screen 82, mobile device 86 and visual display unit 90.Such as, calculation element 60 can perform one or more instruction to generate and/or amendment graphical content according to technology of the present disclosure.The data comprising graphical content can be exported to the communication unit of calculation element 60 by calculation element 60, such as communication unit 70.It is one or more that described data can send in the remote-control device of such as projector 80, projecting apparatus screen 82, mobile device 86 and/or visual display unit 90 by communication unit 70.Like this, the exportable graphical content of calculation element 60 is to be presented at one or more remote-control device place.In some instances, one or more remote-control device graphical content can be exported be included in corresponding remote-control device and/or be operationally coupled to corresponding remote-control device there is sensitive display place.
In some instances, calculation element 60 graphical content can not be exported operationally be coupled to calculation element 60 there is sensitive display 64 place.In other example, the exportable graphical content of calculation element 60 be presented at be coupled to calculation element 60 by communication channel 62A there is sensitive display 64 and one or more remote-control device place.In such an example, graphical content side by side can show substantially at each related device place.Such as, can be introduced some postpone due to the data comprising graphical content are sent to the communication delay of remote-control device.In some instances, generated by calculation element 60 and export be presented at the graphical content that there is sensitive display 64 can be different from export be presented at one or more remote-control device place graphical content display.
Calculation element 60 can use any suitable communication technology to transmit and receive data.Such as, calculation element 60 can use network link 72A to be operationally coupled to external network 74.Each remote-control device shown in Fig. 3 is operationally coupled to network-external network 74 by corresponding network link 72B, 72C and 72D.External network 74 can comprise the hub, the network switch, network router etc. that operationally intercouple, thus is provided for the message exchange between the remote-control device shown in calculation element 60 and Fig. 3.In some instances, network link 72A – 72D can be that Ethernet, ATM or other network connect.Such connection can be wireless and/or wired connection.
In some instances, calculation element 60 can use on-line equipment communication 78 to be operationally coupled to one or more remote-control devices included in Fig. 3.On-line equipment communication 78 can comprise such communication, calculation element 60 by its use wired or wireless communication directly and remote-control device transmit and receive data.That is, in some examples of on-line equipment communication 78, the data sent by calculation element 60 can not forwarded by one or more attachment device before remote-control device is received, and vice versa.The example of on-line equipment communication 78 can comprise bluetooth, near-field communication, USB (universal serial bus), Wi-Fi, infrared etc.One or more remote-control devices shown in Fig. 3 are operationally coupled with calculation element 60 by communication link 76A – 76D.In some instances, communication link 76A – 76D uses bluetooth, near-field communication, USB (universal serial bus), infrared etc. connection.Such connection can be wireless and/or wired connection.
According to technology of the present disclosure, calculation element 60 can use external network 74 to be operationally coupled to visual display unit 90.Sensitive display 92 place is there is in the exportable graphic keyboard of calculation element 60 for being presented at.Such as, the data of the expression comprising graphic keyboard can be sent to communication unit 70 by calculation element 60.Communication unit 70 can use external network 74 that the data of the expression comprising graphic keyboard are sent to visual display unit 90.Receive described data in response to use external network 74, visual display unit 90 can make to there is sensitive display 92 output pattern keyboard.Perform gesture in response to user there is sensitive display 92 place (such as, the region place that there is sensitive display 92 at output pattern keyboard), visual display unit 90 can use external network 74 that the instruction of gesture is sent to calculation element 60.Communication unit 70 can receive the instruction of gesture and this instruction is sent to calculation element 60.
In response to receiving in the instruction that there is at least one gesture that sensitizing input device place detects, calculation element 60 can to the multiple character string modelings comprising the first alphabetic(al) symbol separately in the first grid.First grid can indicate the Spatial Probability of each in multiple character string.In some instances, described Spatial Probability is at least in part based on the instruction of at least one gesture.Calculation element 60 can at least in part based on described multiple character string of at least one probability corresponding at least one word be included in the second language Spatial Probability of multiple character string to use second grid of probability of one or more words of instruction second language to determine in to(for) at least one in described multiple character string.At least one word described can be represented by corresponding with second language second alphabetic(al) one or more symbol.In response to determining that a probability meets threshold value, one or more symbols of at least one word of the exportable expression of calculation element 60 are with display.Such as, calculation element 60 can will represent that the data of at least one word described send to communication unit 70.Communication unit 70 can send data via external network 74 to visual display unit 90.Visual display unit 90 can make to there is sensitive display 92 and export by least one word of described data representation.
Fig. 4 is the concept map of the grid illustrated according to technology of the present disclosure, and calculation element can generate described grid based on the instruction of user's input of the alphabetic(al) character selected in first language and use it to determine the word of second language.About the calculation element 2 as shown in the example of Fig. 1-2, technology of the present disclosure is described for illustrative purposes.In some instances, along with UI module 6 determines the instruction that user inputs (such as, tapping gesture), UI module 6 can generate touch event as described in previous Fig. 1-2.Touch event can comprise the location components corresponding with the position that there is sensitive display 4, with exist sensitive display 4 when this position detect user input relevant time component and/or with touch event be correspond to this position on carry or under push away relevant motion components.Touch event can send to input to search module 48 by UI module 6, as shown in Figure 2.
Module 48 is searched in input can determine the list of neighbours' key based on the one or more positions that there is sensitive screen 4 indicated in touch event.The list of neighbours' key can comprise the block graphics key close to one or more positions indicated in touch event.Such as, one group of key that module 48 can be determined in touch event in the threshold distance of indicated one or more positions is searched in input.In other example, load module 48 can determine one group of key that the minor increment between position indicated in key and touch event is corresponding.Such as, input is searched module 48 and can be comprised two keys the shortest with the distance of indicated one or more positions in touch event in the list of neighbours' key.In some instances, input search module 48 can distance between the barycenter of OK button and one or more touch location.In other example, load module 48 can determine the distance from any suitable position of key to one or more touch location.
In some instances, the spatial model probability that module 48 determines each key in the list of neighbours' key is searched in input.Such as, in response to the touch event rapping position 20A determined Fig. 1, the list of neighbours' key can comprise the key information corresponding with " z " key and " x " key.Use this key information and spatial model 10, the spatial model probability that module 48 can determine " z " key is searched in input.Similarly, the spatial model probability that module 48 can determine " x " key is searched.In present exemplary, search module 48 and can determine that the spatial model probability of " z " key is 0.64, the spatial model probability of " x " key is 0.36.In some instances, input is searched module 48 and the corresponding spatial model probability of each key included in the list of neighbours' key and the list of neighbours' key can be sent to composer module 50.
Composer module 50 can receive the corresponding spatial model probability of each key in the list of neighbours' key and the list of neighbours' key.Usually, composer module 50 can according to the one or more grid of technique construction of the present disclosure.Such as, as shown in Figure 4, composer module 50 can generate character grid 100.Character grid 100 can to the character constructing model corresponding with each input gesture (such as, one or more rap and/or continuous gesture).Composer module 50 can generate character grid 100 as the oriented other than ring type figure with summit (such as, summit 102A-102C) and limit (such as, limit 104A-104D).
Rap input along with user provides, composer module 50 incrementally can receive the close neighbours' key list of rapping the key of input of instruction from load module 48.Each summit can be generated and corresponding to rapping input.Every bar limit may correspond in inputting corresponding possible character with rapping.Rap input for what first determine, composer module 50 can generate from the summit 102A with index 0 to one or more limit of summit 102B with index 1.Each summit can be associated from different indexes, and wherein, root summit can be assigned index value 0.Composer module 50 can generate from summit 102A to the corresponding edge of summit 102B for each key in the list of neighbours' key.Such as, composer module 50 can generate limit 104A for key " z ", generates limit 104B for key " x ".The spatial model probability of " z " key (such as, 0.64) also can be associated with the limit 104A corresponding to " z " key by composer module 50, makes spatial model probability be the weight of limit 104A.Similarly, the spatial model probability (such as, 0.36) of " x " key can be associated with the limit 104B corresponding to " x " key by composer module 50.Therefore, composer module 50 can determine the spatial model probability of the key of the graphic keyboard close to the position of rapping input.In some instances, when the position of key and the distance of rapping between input meet threshold value, the key of graphic keyboard can close to the position rapping input.Such as, if the position of key and the distance of rapping between input are less than threshold value, then this threshold value can be met.In one example, described distance can be the distance in the scope of 0-100 millimeter determined.In some instances, the position of key can be the barycenter of key.In other example, the position of key can be any position corresponding with key.In some instances, when the position of key and the pixel count rapped between input meet threshold value, the key of graphic keyboard can close to the position rapping input.In one example, described pixel count can be the pixel count in the scope of 0-1000 determined.
Rap input along with composer module 50 incrementally receives, composer module 50 generates adds summit 102B, 102C etc., and is generated to the limit 104A-104D etc. of the respective vertices of character grid 100.Each is follow-up raps input next increment index on summit can be utilized to carry out modeling.That is, composer module 50 generates from the summit with index 0 to the limit on summit with index 1 for the character rapping input modeling based on first.Composer module 50 generates from the summit with index 1 to the limit on summit with index 1 for the character rapping input modeling based on second, and the rest may be inferred.Like this, along with user raps " zhonghuo " at graphic keyboard 16B place, composer module 50 can for inputting corresponding possible key and generate limit with rapping.Therefore, composer module 50 can generate separately corresponding with the close key rapping the graphic keyboard of the position of input limit in the 3rd grid.Therefore, character grid can the indicating user corresponding probability of different keys that may may rap when providing and rapping input.The spatial model score value of key is higher can indicating user intention select the probability of this key higher, and the spatial model score value of key is lower can indicating user intention select the probability of this key lower.
Along with UI module 6 generates touch event in response to user's input, composer module 50 also incrementally can construct mark grid 110, as shown in Figure 4.Mark grid 110 also can be implemented as the oriented other than ring type figure on summit and the limit had as shown in Figure 4.In some instances, mark grid 110 can comprise the vertex index summit identical with character grid 100.Such as, summit 112A can comprise the index identical with summit 102A, and summit 112B can comprise the index identical with 102B, and summit 112C can comprise the index identical with summit 103C, etc.
Composer module 50 also can generate the limit corresponding with candidate character strings.Described in previous Fig. 1, candidate character strings can represent the combination of the character that the possible key that raps with user is corresponding.With pronunciation, each candidate character strings can represent that (pinyin string such as, representing Chinese character) is corresponding.In some instances, candidate character strings can be comprise the semanteme of such as syllable, word etc. and/or one group of character of voice unit.In some instances, candidate character strings can be the accurate spelling that pronunciation represents, such as " zhong " and " guo ".
Composer module 50 can select the one group one or more character corresponding with the limit of character grid 100 to form candidate character strings, and is associated on the limit of candidate character strings with mark grid 110.Such as, candidate character strings " zhong " can be associated with limit 114C by composer module 50.The index of the first summit 112A of limit 114C may correspond in 0, and the index of tail summit 112D may correspond in 5.That is, the index on tail summit can be defined as equaling n by composer module 50, and wherein n is the number of characters during candidate goes here and there.Such as, in the diagram, candidate character strings " zhong " comprises 5 characters, and therefore composer module 50 can determine that the tail summit of limit 114C is summit 112D and has index 5.
As shown in Figure 4, composer module 50 also can generate the limit 114A from summit 112D to summit 112E.Limit 114A may correspond in candidate character strings " guo ".Composer module 50 also can generate the limit 114B from summit 112D to summit 112E.Limit 114A may correspond in candidate character strings " huo ".As described further below, composer module 50 can be determined any amount of candidate character strings from character grid 100 and is associated on the limit of corresponding candidate character string with mark grid 110.
Every bar limit of mark grid 110 also can comprise weight.The weight on the limit in mark grid 110 can indicate the gross space model probability of the candidate character strings be associated with this limit.Gross space model probability can represent and the combining weights that the every bar limit in the character grid 100 corresponding to the character in candidate character strings is associated.Such as, the gross space model probability (that is, the weight of limit 114C) of " zhong " can based on the weight on the limit in the character grid 100 corresponding with character " z ", " h ", " o ", " n ", " g ".In one example, composer module 50 can determine that the weight of limit 114C equals following product: 0.64 × 0.78 × 0.65 × 0.55 × 0.58=0.104.That is, composer module 50 can determine one group of character being included in the candidate character strings in multiple candidate character strings, and determines the spatial model probability of the key corresponding with the character be included in candidate character strings.Determine based on described, composer module 50 determines the gross space model probability of candidate character strings at least in part based on the spatial model probability of the key corresponding with the character be included in candidate character strings.Composer module 50 can determine the weight of limit 114A and 114B similarly.
The starting and ending character of character string that composer module 50 can use various technology to determine the quantity of the character in each candidate character strings of the quantity on the limit be included in mark grid 110, mark grid 110 and determine from character grid 100.In some instances, composer module 50 can determine the quantity (therefore, the quantity of candidate's string) on the limit be included in mark grid 110 based on threshold value.Such as, composer module 50 can comprise at mark grid 110 limit that quantity is less than threshold value.In some instances, the quantity being included in the limit in mark grid 110 can based on time window and/or thump amount window.Like this, along with receiving additional character and/or having gone over additional period from initial input, the life-span on limit can decay, and limit can remove from mark grid 110 by final composer module 50.In other example, in response to determining separator or determining that user have selected one or more character and/or word, limit can remove from mark grid 110 by composer module 50.
In some instances, composer module 50 can determine the character quantity in each candidate character strings be associated with the limit of mark grid 110 based on one or more rule.In some instances, described one or more rule can realize in the dictionary comprising different possible candidate character strings.The linguistic context etc. that described rule can follow the frequency of other given character based on such as character, character is transfused to indicates the probability of candidate character strings group, as further described below this paper.
Dictionary can be represented by a series of data structures of such as array, list and/or tree.Such as, in some instances, calculation element 2 can be included in the dictionary realized in lexicographic tree (trie) data structure.Dictionary can comprise the list of word, and can comprise the additional information about listed word.Lexicographic tree data structure can comprise multiple node, and each node can represent letter.First node in lexicographic tree can be referred to as Ingress node, and it can not correspond to letter.In other example, Ingress node may correspond in letter.Each node can be included in one or more branches of one or more child node.Such as, Ingress node can have 26 child nodes, and each child node corresponds to the letter of alphabet (such as English alphabet).These 26 child nodes eachly can have the one or more branches corresponding with additional node.Each additional node can be associated with character.Child node can comprise probability, and the probability after the letter of father node followed in the letter of its instruction child node.The frequency etc. that described probability can occur based on the character of one or more word and/or character n gram language model, child node.Like this, the path in lexicographic tree can comprise the child node chain corresponding with candidate character strings.Such as, the child node chain from Ingress node can comprise character " z ", " h ", " o ", " n ", " g ", and wherein each child node comprises in character.
The subset of the node in lexicographic tree can comprise the mark that instructs node is terminal node separately.Each terminal node of lexicographic tree can indicate full candidate string.Therefore, the candidate character strings indicated by terminal node can be risked from Ingress node along the path of node to the letter indicated by the node of terminal node.In some instances, lexicographic tree is based on the dictionary be arranged on calculation element 2.In other example, lexicographic tree can based on multiple source, and it can be stored in calculation element 2 place or is stored in one or more remote computing device place and can be visited via one or more communication channel by calculation element 2.
Dictionary can indicate the corpus of possible candidate character strings.Such as, the pronunciation of the dictionary character and/or word that can comprise second language (such as Chinese) represents.That is, comprise at dictionary in the example of Chinese phonetic alphabet string, dictionary can comprise such as the pinyin string of " zhong ", " huo ", " guo " etc.
If node is from the child node the node path of Ingress node, and be included in the character string comprising word included in dictionary along the character in the ancestor node in this path, then the node in lexicographic tree can comprise the mark of indicating terminal mark.Such as, comprise [< entrance >, " z ", " h ", " o ", " n ", " g "] and can comprise as the path of six nodes of analog value the mark that instruction comprises the terminal node in the 6th node of letter " g ".Like this, when traveling through lexicographic tree from Ingress node to terminal node, calculation element 2 can determine beginning and the end of candidate character strings.
In some instances, in some instances, the node of the lexicographic tree language model frequency information that can comprise based on such as n gram language model comprises the probability of character in node.N gram language model may be provided in continuous items sequence middle term x
i(letter or word) is based on probability distribution (that is, the P (x of the item before in sequence
i| x
i-(n-1)..., x
i-1)).Such as, two gram language model (wherein the n meta-model of n=2) can provide letter " o " to follow probability after sequence " zh ".In some instances, lexicographic tree can comprise the language model frequency information of integration.Such as, each node of lexicographic tree can comprise the expression of letter and probable value.
In some instances, composer module 50 can determine beginning and the termination character (such as, being included in one group of character in character grid 100) of candidate character strings based on the end mark be included in the terminal node of lexicographic tree.Such as, along with composer module 50 incrementally builds character grid 100, composer module 50 can store the status information about possible candidate character strings (such as, being included in the character in each candidate character strings).Character string can incrementally compare with the node of lexicographic tree by composer module 50.If composer module 50 determines that character corresponds to terminal node included in the path of lexicographic tree, then composer module 50 can determine that the character corresponding with the node in this path constructs candidate character strings included in the dictionary of dictionary.Such as, composer module 50 can receive the touch event of instruction close to the position of the key corresponding with character " g ".Composer module 50 can comprise the status information about candidate's string " zhon " at present, therefore determines the path had in the lexicographic tree of the node corresponding with " zhong ".The node corresponding with " g " can comprise and indicate it to be the mark of terminal node.In response to the mark determining indicating terminal node, composer module 50 can generate the limit 114C corresponding with " zhong " in mark grid 110.
In some instances, in response to determining terminal node, composer module 50 can determine the follow-up character rapping input and may correspond in different candidate character strings.Such as, based on terminal node " g ", composer module 50 can determine that " zhong " is the candidate's string be included in dictionary.Therefore, next raps to input and may correspond in different candidate character strings.Such as, ensuing two characters corresponding with possible key can be " h " and " g ", as in character grid 100 from the summit with index 5 to have index 6 summit limit indicated by.Like this, composer module 50 can maintain the state of the different candidates string started with character " h " and " g " respectively.Input corresponding character determined along with follow-up rapping, candidate's string " huo " and " guo " and lexicographic tree can such as compare by composer module 50.In lexicographic tree for each in " huo " and " guo " determine terminal node time, composer module 50 can be added for the limit 114A of " guo " and the limit 114B for " huo " to mark grid 110.Like this, composer module 50 can determine character between the character group in character grid 100 and word border, and adds corresponding candidate character strings to mark grid 110.
In some instances, composer module 50 can select one or more candidate character strings based on lexicographic tree, even if the node corresponding with the last letter of character string is not terminal node.Such as, composer module 50 can determine the general probability of the character string corresponding with the multiple nodes in the path of lexicographic tree.The probability that described general probability can be associated based on the node independent along given path and each.As implied above, the frequency etc. that the probability be associated with independent node can occur based on the character of one or more word and/or character n gram language model, child node.Composer module 50 can determine described one or more candidate character strings based on the general probability of one or more candidate character strings.Such as, if the general probability of candidate character strings meets threshold value (such as, general probability is greater than threshold value), then mark grid 110 can be added in the limit corresponding with candidate character strings by composer module 50.
Although as shown in exemplified earlier, composer module 50 can use lexicographic tree to carry out beginning and the termination character of identification of candidate character string based on the character be included in character grid 100, and composer module 50 also can use other technology to determine beginning and termination character.Such as, composer module 50 can use length threshold when determining beginning and termination character.Length threshold can based on the statistical information of the possible length of instruction candidate character strings.In other example, length threshold can be the value that user limits.In Chinese, the most common ground of phonetic value can character length between lower bound threshold value and upper bound threshold value.As a non-limiting example, lower bound threshold value can be 2 characters, and upper bound threshold value can be 4 characters.In response to determine can with close to rapping the corresponding character string of the key of input, composer module 50 can to word grid 110 add and length be 2,3,4 and 5 the corresponding limit of candidate character strings.Such as, composer module 50 can add limit for candidate character strings " zh ", " zho ", " zhon " and " zhong ", even if one or more in these candidate character strings may not be included in dictionary and/or are not modeled in lexicographic tree.
In an alternative example, composer module 110 can build middle mark grid, and it carries out modeling to the candidate character strings of the misspellings comprising candidate character strings included in dictionary.That is, composer module 110 can determine the outer candidate character strings of vocabulary and by the corresponding candidate character strings modeling in the dictionary similar with the outer candidate character strings of vocabulary in mark grid 110.Such as, composer module 110 can determine candidate character strings " zhomv ", and it also may be the misspellings that pronunciation represents " zhong ".In some instances, composer module 50 can generate limit for the candidate character strings comprising both misspellings that pronunciation represents in middle mark grid.In some instances, composer module 110 can determine the similarity degree between the candidate character strings (such as, misspellings or the outer candidate character strings of vocabulary) corresponding to limit in intermediate grid and the one or more candidate character strings in dictionary from probability.In some instances, composer module 110 can use lexicographic tree or one or more Jaccard coefficient to determine similarity degree.If the similarity degree between the candidate character strings in misspellings and dictionary meets threshold value (such as, similarity degree is greater than threshold value), then the limit corresponding with candidate character strings included in dictionary can be included in mark grid 110 by composer module 110.
Along with calculation element 2 receives the instruction of user's input, composer module 50 can incrementally build word grid 120.Composer module 50 can generate the limit be associated with single and/or multiple candidate character strings.That is, on the limit of mark grid 110, the candidate character strings of modeling may correspond in Chinese phonetic alphabet string, and the limit on word grid 120 may correspond to the combination in single Chinese phonetic alphabet string or Chinese phonetic alphabet string.In some instances, the combination of one or more candidate character strings may correspond to one or more character in second language and/or word.Such as, the combination of one or more Chinese phonetic alphabet string can comprise Chinese word or comprise the Chinese phrase of multiple word.As an example, pinyin string " zhongguo " can be the expression of Chinese word " China " (i.e. " china ").As run through indicated by instructions, although Chinese is shown as a non-limiting example of second language, technology of the present disclosure is applicable to any language usually.
In some instances, composer module 50 can create the limit corresponding with one or more characters of second language, word or many words phrase in word grid 120.In order to select one or more characters of second language, word or many words phrase with modeling in word grid 120, composer module 50 can use lexicographic tree data structure.Lexicographic tree data structure can be implemented as the tree with multiple node.Each node may correspond in candidate character strings (such as, in the case of chinese, pinyin string).Such as, lexicographic tree data structure can comprise empty root node.Root node can comprise the child node corresponding with candidate character strings " zhong ".In addition, the node for " zhong " can be associated with the character of the second language (such as Chinese) corresponding to candidate character strings, word or many words phrase.Such as, corresponding with candidate character strings " zhong " child node can with Chinese character " in " be associated.The child node corresponding with " zhong " also can comprise child node corresponding with " huo " and " guo " respectively.Each in corresponding child node can be associated with " state " and " work ".
In order to generate limit in word grid 120, composer module 50 can create the limit corresponding with one or more candidate character strings of word grid 110 in word grid 120.Such as, composer module 50 can travel through word grid 110 and select the candidate character strings " zhong " corresponding with limit 114C.Composer module 50 can create the limit 124A corresponding with candidate character strings " zhong " in word grid 120.Composer module 50 also can by character " in " be associated with limit 124A because character " in " be associated with the node corresponding to candidate character strings " zhong " in lexicographic tree.As described further below, probabilistic language model included in the weight of limit (such as, 124B) based on character " in " and candidate character strings " zhong ".The index value on the summit of the limit 124A in word grid 120 may correspond to identical beginning and the end vertex of the limit 114C in mark grid 110.Composer module 50 can generate limit 124D and 124E according to similar mode.
In some instances, composer module 50 can generate the limit 124B corresponding with combining characters, word or many words phrase based on the candidate character strings of modeling in word grid 110.Such as, composer module 50 can travel through lexicographic tree, and determines the path through multiple nodes corresponding from the different candidate character strings of modeling in word grid 110 respectively.Such as, composer module 50 can select " zhong " corresponding with limit 114C and " guo " corresponding with limit 114A from word grid 110.In lexicographic tree, composer module 110 from root node traversal to first child node corresponding with " zhong ", and can travel through to second child node corresponding with " guo " further.In some instances, the second corresponding with " guo " child node can be terminal node.Terminal node can indicate " guo " to be last candidate character strings in one group of candidate character strings of such as " zhong " " guo " (correspond to " zhongguo ").As shown in Figure 4, composer module 120 generates the limit 124B corresponding with the combination of candidate character strings " zhongguo " by " China " being associated with limit.Composer module 120 can generate limit 124C similarly.
Can as can be seen from Figure 4, any amount of limit that composer module 120 can be determined based on the candidate character strings corresponding with the limit of word grid 110 for word grid 120.Such as, if " zhongguo " is corresponding to multiple different character, word or the many words phrase in Chinese, then composer module 50 can for one or more possibility combination producing limit.Such as, " zhong " may correspond to " weight " in Chinese and " in ", it can differently pronounce separately.In lexicographic tree, the independent node corresponding with { zhong, heavy } and { zhong, in } can be there is.Each independent node can have two child nodes corresponding with { guo, state } and { huo lives } separately.Therefore, when composer module 50 travels through lexicographic tree, composer module 50 can generate the independent limit corresponding with such as { zhongguo, heavy state }, { zhonghuo, taskwork }, { zhongguo, China } and { zhonghuo, middle work } in word grid 120.Like this, composer module 50 can to multiple various combination modelings of the corresponding candidate character strings of the kinds of characters/word/many words phrase with second language on the limit in word grid 120.In addition, composer module 120 can determine any amount of combination of the candidate character strings (such as, " zhong " and " guo ") corresponding with the single edge (such as, " zhongguo ") word grid 120 from mark grid 110.
In some instances, composer module 50 can determine weight for every bar limit of word grid 120, and wherein every bar limit of word grid 120 corresponds to the combination of one or more candidate character strings.As shown in Figure 4, limit 124A corresponds to candidate character strings " zhong ", and limit 124B corresponds to candidate character strings " zhongguo ", and limit 124C corresponds to candidate character strings " zhonghuo ", and limit 124D corresponds to " guo ", and limit 124E corresponds to " huo ".In one example, composer module 50 can based on the limit in the mark grid 110 corresponding with the candidate character strings of modeling on the 124A of limit (such as, the starting and ending summit (122A and 122B) of limit 124A is determined on starting and ending summit (such as, 112A and 112D) 114C).If to multiple candidate character strings modeling in the single edge in word grid 120, then the index of the initial vertex 122A in word grid 120 can be defined as the index of the initial vertex 112A on the limit in the mark grid 110 corresponding with the first candidate character strings included in described multiple candidate character strings by composer module 50.The index of the ending summit 122C in word grid 120 can equal the ending index 112E on the limit in the mark grid 110 corresponding with the last candidate character strings in described multiple candidate character strings.Such as, as shown in Figure 4, the index of the initial vertex of limit 124B equals the index of the initial vertex of limit 114C, and the index on the ending summit of limit 124B equals the index on the ending summit of limit 114A.
The weight on the limit in word grid 120 can based on total weight of the word grid 110 of corresponding with limit one group of one or more candidate character strings.The weight on the limit in word grid 120 can based on language model score value.In some instances, the weight on limit can based on total weight of mark grid 110 and language model score value.
As shown in Figure 4, limit 124C can based on total weight of " zhonghuo " (such as spatial model score value) and language model score value.Total weight can equal 0.104 × 0.308, and it can indicate the gross space probability of the key corresponding with the character in " zhonghuo ".Composer module 50 also can determine the probabilistic language model (or " language model score value ") of limit 124C.In some instances, probabilistic language model can indicate the probability of one group of one or more candidate character strings of the alphabetic(al) character comprising first language under the condition of the word of second language.Such as, the probabilistic language model of limit 124C can indicate the probability of under the condition of Chinese word " middle work " " zhonghuo ".In other words, composer module 50 can be determined to suppose that Chinese word " middle work " (" zhonghuo ") is the word of user view input, and user's input comprises the probability of candidate's string " zhonghuo " of two candidate character strings " zhong " and " huo ".That is, the probabilistic language model of limit 124C can indicate Chinese word " middle work " 124C to may correspond to the probability of the probability pronounced with " zhonghuo " in " middle work ".More generally say, the probability that the probabilistic language model of limit 124C can indicate the character of second language, word or phrase to pronounce according to one group of one or more candidate character strings.In some instances, probabilistic language model can be expressed from the next:
In formula 1, s can be one group of one or more candidate character strings, and t can be one or more words included in the language model based on the word of second language and/or the dictionary of phrase.Like this, the language model score value of limit 124C can be expressed from the next:
In some instances, composer module 50 can use language model 12 to determine probabilistic language model.Language model 12 can comprise one group of word in language vocabulary table, the group of such as, Chinese word in Chinese vocabulary table.In some instances, language model 12 can based on and/or comprise the set of the word in the dictionary being stored in the remote computing device place that calculation element 2 place or calculation element 2 can be accessed.Language model 12 can indicate the probability of each corresponding words based on the word frequency appeared in given linguistic context.Language model 12 can realize one or more n gram language model.N gram language model may be provided in continuous items sequence middle term x
i(letter, word, punctuation mark or other separator) is based on probability distribution (that is, the P (x of the item before in sequence
i| x
i-(n-1)..., x
i-1)).
Composer module 50 can determine the weight of each in the 124A-124C of limit.As above previously as described in, along with calculation element 2 receives the instruction of user's input, composer module 50 incrementally can construct grid 100,110 and 120.Along with grid is constructed, decoder module 52 periodically and/or continuously can determine the limit of the word grid 120 be associated with highest weighting.In other example, decoder module 52 can based on the limit increasing progressively the word grid 120 determining to be associated with highest weighting of user's input.That is, decoder module 52 can determine the number of thresholds on the limit with highest weighting.
Such as, decoder module 52 can use viterbi algorithm, other similar dynamic programming technique or (usually) any suitable search technique to carry out the limit weight of search word grid 120, with search word grid.Such as, decoder module 52 can search for the wing footpath through word grid 120 comprising the limit with n total weight the highest.Such as, decoder module 52 initially can determine to have highest weighting from which bar limit of summit 122A to 122B.Composer module 50 also can determine to have highest weighting from which bar limit of summit 122B to 122C.
Decoder module 52 can continue search highest weighting along the possible limit of word grid 120.In some instances, decoder module 52 can total weight in path of definite threshold quantity.Such as, composer module 50 can determine total weight of 3 paths, and wherein the number of thresholds in path is such as 3.In some instances, decoder module 52 can determine the limit of maximum quantity based on every path, the limit of number of thresholds.That is, decoder module 52 can determine total weight in the path on the limit (equaling such as 2) with maximum quantity.In such an example, decoder module 52 can determine total weight in the path comprising two limits.In order to determine total weight of limit 124A and 124D, decoder module 52 can determine the product of the weight of limit 124A and 124D.
When determining one group of one or more character, the word work phrase of second language indicated in word grid 120, the exportable character of calculation element 2, word or phrase are for display.As an example, user interface 14 can comprise two word suggestion areas 18A and 18B.Therefore, decoder module 52 can determine that the number of thresholds on limit can equal two.Therefore, decoder module 52 can determine corresponding one or more words of being associated to the limit with two highest weighting.Such as, in the diagram, decoder module 52 can determine that the weight of limit 124B and 124C has two the highest weights.In response to determining limit 124B and 124C, decoder module 52 can will represent that the data of word " China " and " taskwork " send to UI module 6.Word " China " and " taskwork " can be presented in word suggestion areas 18A and 18B by UI module 6.In other example, the word be associated with the limit with highest weighting can be presented in editing area 16A by UI module 6.In other example, calculation element 2 can be received in and rap the instruction that position 201 place performs the user of tapping gesture, and it then can make to there is sensitive display 4 and export word " China " in the user interface 14 with character 22A and 22B.Like this, although rap position 20A-20H can look like the key selected close to " zhonghuo ", the technology of use grid 100,110 and 120 of the present disclosure can make to there is sensitive display 4 and export " China " (such as, " zhongguo ").Therefore, the pronunciation that display technique can comprise the alphabetic(al) character of first language in input represents to provide the larger Fault recovery to user's input when exporting character and/or the word of second language.
Fig. 5 be illustrate according to one or more technology of the present disclosure at least in part based on the block diagram selecting the continuous gesture of character included in the alphabet of first language to determine the further details of an example of the calculation element shown in one or more character of second language and/or Fig. 1 of word.As shown in the concept example of Fig. 5, calculation element 2 can comprise and there is sensitive display 4, UI module 6, Keysheet module 8, spatial model 10, language module 12, movable bundle 56 and lower a branch of 58.GUI140 can comprise graphic keyboard 142B, and it can comprise qwerty keyboard.
As shown in the example of Fig. 1, user may expect in calculation element 2, to input one or more candidate character strings (such as, such as the pronunciation of Chinese phonetic alphabet string represents) by performing continuous gesture at graphic keyboard 142B place.While user performs continuous gesture, calculation element 2 can detect the gesture path 146 corresponding with continuous gesture.In some instances, continuous gesture can refer to that user utilizes input block (such as, finger, pointer etc.) to perform in the gesture that there is the detection of sensitive display 4 place, and wherein said input block traversal is through the gesture path of diverse location.While still input block can being detected existing sensitive display 4 place, there is sensitive display 4 place detection gesture.When there is sensitive display 4 place and input block no longer being detected, calculation element 2 can determine that gesture stops.Like this, user can perform the continuous gesture of multiple keys of traversal graphic keyboard with input text.In the example of hgure 5, calculation element 2 is shown as and detects gesture path 146.Although shown in Fig. 5, the techniques described herein the term of execution, gesture path 146 and/or alignment point 148A-148H can be invisible.Alignment point can be along gesture path can the point of key in multiple keys included in indicating graphic keyboard.Alignment point can comprise the one or more coordinates corresponding with the position of determined alignment point.Such as, alignment point can comprise the Cartesian coordinates corresponding with the point in graphic user interface.In order to determine that the key of graphic keyboard is associated with gesture path, calculation element 2 can determine the feature of one group of alignment point, such as the length of gesture section, and wherein, described section is included in the path that there is sensitive display place and traveled through by gesture; The direction of gesture section; The curvature of gesture section; Represent the local velocity of the speed that gesture section is detected; Represent the global speed etc. of the speed that gesture is detected.Such as, slow down and change direction along with input block near key, the curvature in gesture path can be higher.The feature in the gesture path determined based on the alignment point corresponding with gesture indicating user intention can select this key.
Keysheet module 8 can determine candidate character strings based on one group of key at least in part according to technology disclosed in as shown in Figure 5.Be different from and generate character grid (such as, character grid 100), Keysheet module 8 can incrementally be determined candidate character strings based on one or more continuous gesture and is associated with the limit in mark grid 110 by such string.Such as, user can perform continuous gesture at graphic keyboard 148A place, and in response to determining that candidate character strings " zhong " is corresponding to continuous gesture, " zhong " can be associated with the limit of mark grid 110 by Keysheet module 8.As described in previous Fig. 4, Keysheet module 8 incrementally can determine character and or word based on word grid 120.Technology is further described referring now to Fig. 5.
In order to determine that one or more candidate goes here and there based on continuous gesture input, Keysheet module 8 can use language model 150.Language model 150 can comprise dictionary.In some instances, dictionary can comprise the list of word and the additional information that can comprise about listed word.Dictionary can be represented by one or more data structure (such as, by array, list, tree or other data structure one or more).Such as, language model 150 can comprise the dictionary be stored in lexicographic tree data structure.Lexicographic tree data structure can comprise multiple node.Each node of lexicographic tree can represent letter.First node in lexicographic tree can be regarded as Ingress node, and it can not correspond to letter.In other example, Ingress node may correspond in letter.Each node can have one or more child node.Such as, Ingress node can have 26 child nodes, and each child node corresponds to the letter of English alphabet.
The subset of the node in lexicographic tree can comprise the mark that instructs node is terminal node separately.Each terminal node of lexicographic tree can indicate the candidate character strings be included in dictionary.Such as, dictionary can based on the dictionary of effective candidate character strings (such as, Chinese phonetic alphabet string).The candidate character strings indicated by terminal node can be risked along the letter indicated by the node of node path from Ingress node to terminal node.In some instances, language model 150 can be the default dictionary that calculation element 2 is installed.In some examples, language model 150 can comprise one group of predefined phrase.In other example, language model 150 can comprise multiple Dictionary Source, and it can be stored in calculation element 2 place or be stored in one or more remote computing device places that calculation element 2 can access via one or more communication channel.
In response to the part of initial detecting to gesture path 146, Keysheet module 8 can determine alignment point 148A along the gesture path 146 of the gesture traversal performed by user.In response to the part gesture path 146 corresponding with alignment point 148A being detected, Keysheet module 8 can create word level mark and be pushed by this word level mark in movable bundle 56.Content now on movable bundle 56 can be represented by following table 1.
Table 1
Index | Father's index | The letter key of present node | Letter chain | Value at cost |
0 | - | - | - | 0 |
As shown in Figure 5, calculation element 2 can comprise movable bundle 56.In some instances, movable bundle 56 is configured to store the one or more marks (such as, one or more word level mark) generated by Keysheet module 8.Movable bundle 56 can be included in memory storage 48.Calculation element 2 also can comprise lower a branch of 58.In some instances, lower a branch of 58 be configured to store the one or more marks (such as, one or more word level mark) generated by gesture module 8.Lower a branch of 56 also can be included in memory storage 48.
In Table 1, often row represents independent word level mark, index column represents the unique identifier of each word level mark, father's index column represents that listed word level mark is the index value of the word level mark of its child node, the letter key represented by present node of word level mark is shown in the letter key list of present node, the all letter keys represented by node from the Ingress node of word level mark to present node are shown in the list of letter chain, and the value at cost of word level mark is shown in value at cost list.As shown in table 1, the word level mark created has index 0 (that is, word level mark
0), do not have father's index, do not have the letter key of present node, do not have alphabetical chain, value at cost is zero.
In order to determine the text indicated by gesture, Keysheet module 8 can create the copy of each word level mark in its child node.That is, each word level mark can be advanced the child node of the next stage in the lexicographic tree of language model 150.In some instances, Ingress node can have 26 child nodes (each letter child node of English alphabet).For the sake of simplicity, in the example of hgure 5, Ingress node only can have two child nodes on letter " Z " and " X ".Therefore, Keysheet module 8 can at child node " Z " (that is, word level mark
1) and child node " X " (that is, word level mark
2) above create the copy with the word level mark of index 0.For each word level mark copy created, Keysheet module 8 can determine value at cost.That is, the corresponding value at cost of each during calculation element 2 can determine in multiple key at least two keys.The alignment point that corresponding value at cost can represent in one group of alignment point separately indicates the probability of the key in multiple key.Value at cost can based on probabilistic language model, and its instruction is at the probability of the condition lower word fundamental chain of the letter key of present node.Probabilistic language model can based on one or more characters of instruction probability of character, word and/or phrase under the condition of one or more character, word and/or phrase, word and/or phrase level n unit.Value at cost can at least in part based on the spatial model probability that gesture is corresponding with the letter key of present node.In some instances, value at cost is at least in part based on probabilistic language model and spatial model probability.
Each word level mark copy can be pushed to lower a branch of 58 by Keysheet module 8, and its content can be represented by following table 2.
Table 2
Index | Father's index | The letter key of present node | Letter chain | Value at cost |
1 | 0 | Z | Z | CV1 |
2 | 0 | X | X | CV2 |
Entry shown in table 2 is similar to the entry shown in table 1 on form.In table 2, word level mark
1there is value at cost CV1, word level mark
2there is value at cost CV2.After establishment word level mark copy, Keysheet module 8 can determine word level mark
0not not terminal node and discardable word level mark
0.Subsequently, Keysheet module 8 can determine that whether movable bundle 56 is empty (that is, not sign of inclusion).In response to determining that movable bundle 56 is for empty, calculation element 2 by the lower content replication of a branch of 58 to movable bundle 56, and can abandon the content of lower a branch of 56A.
Keysheet module 8 also can determine alignment point 148B-148E along gesture path 146.Along with Keysheet module 8, determine can each in the alignment point 148B-148E corresponding with one or more keys of graphic keyboard 142B, and for each word level mark in activity bundle 56, Keysheet module 8 can incrementally create a Copy in each child node.In the example of hgure 5, when determining alignment point 148B, word level mark
1with word level mark
2each child node with band letter key " G " and " H ".For each word level mark copy created, calculation element 2 can determine value at cost as described above.Each word level mark copy can be pushed in lower a branch of 58 by calculation element 2, and its content can be represented by following table 3.
Table 3
Index | Father's index | The letter key of present node | Letter chain | Value at cost |
3 | 1 | G | ZHONG | CV3 |
4 | 1 | H | ZHONH | CV4 |
5 | 2 | G | XHONG | CV5 |
6 | 2 | H | XHONG | CV6 |
Entry shown in table 3 is similar to the entry shown in table 1 and table 2 on form.In table 3, the value at cost of each word level mark comprises the value at cost of letter above and the value at cost of current letter.Calculation element 2 can determine which (if any) word level mark is on terminal node.Such as, calculation element 2 can determine word level mark
3on terminal node, because the character string (that is, its alphabetical chain) " ZHONG " of its prediction represents candidate word included in (such as, pinyin string dictionary) in dictionary.
In response to determining that word level mark is on terminal node, Keysheet module 8 can create limit in the mark grid 110 corresponding with alphabetical chain (such as, candidate character strings).In some instances, Keysheet module 8 can be determined the spatial model of character string and the weight of spatial model as the limit in the mark grid 110 corresponding with candidate character strings is associated.Like this, along with Keysheet module 8 determine with candidate character strings (such as, Chinese phonetic alphabet string) corresponding letter changes, limit can be included in mark grid 22 by Keysheet module 8, it is used with character and/or the word of determining second language with word grid 120 further by Keysheet module 8, as shown in Figure 4.
In addition, in response to determining that word level mark is on terminal node, calculation element 2 can generate next word mark that the key next selected in the multiple key of instruction is the prefix of the second word level mark.Next word mark can be regarded as the Ingress node of the second word level mark.Next word mark (that is, the Ingress node of the second word level mark) can be pushed in movable bundle 56 by calculation element 2, and its content can be represented by following table 4.
Table 4
Index | Father's index | The letter key of present node | Letter chain | Value at cost |
3 | 1 | G | ZHONG | CV3 |
4 | 1 | H | ZHONH | CV4 |
5 | 2 | G | XHONG | CV5 |
6 | 2 | H | XHONH | CV6 |
7 | 3 | - | - | 0 |
Entry shown in table 4 is similar to the entry shown in table 1, table 2 and table 3 on form.As shown in table 4, the word level mark corresponding with next word mark created has index 7 (that is, word level mark
7), father's index is 3 (that is, corresponding to word level mark
3), there is no the letter key of present node, there is no alphabetical chain, and value at cost is zero.As shown in table 4, the word level mark with index 7 can store father's index of previous candidate character string (such as " zhong ") as status information, and Keysheet module 8 can be determined and the candidate character strings that the alphabetical chain of father's index is associated.Like this, Keysheet module 8 can determine one or more alphabetical chain group be associated, and it can be corresponding with the word in dictionary and/or phrase.
Keysheet module 8 can when receiving the continuous gesture corresponding with multiple candidate character strings with determining that terminal node comes together to maintain status information to identify word border.That is, Keysheet module 8 can determine " zhong " with subsequently and transition probabilities between the candidate character strings that index 7 is corresponding.Keysheet module 8 can store the part of this transition probabilities as the status information of next the word mark corresponding with index 7.Transition probabilities can based on one or more n metacharacter and/or word language model, and it indicates the boarder probability between candidate character strings and can based on the dictionary of candidate character strings.In one example, in response to receiving in the instruction that there is at least one gesture that sensitizing input device place detects, Keysheet module 8 can determine multiple character " zhonghuo ".At least one border of (such as, between " zhong " and " huo ") between multiple characters that Keysheet module 8 can determine to represent different candidate character strings based on language model.At least one border described can indicate second group of character corresponding with the second candidate character strings " huo " in first group of character corresponding with the first candidate character strings " zhong " in multiple character and multiple character.As further described in the example of hgure 5 below, Keysheet module 8 can generate the first limit be associated with the first candidate character strings " zhong " in mark grid, wherein, the first limit from the first summit 112A and second 112D place, summit terminate.Keysheet module 8 can generate the Second Edge 114B be associated with the second candidate character strings " huo " in mark grid, wherein, Second Edge from the second summit 112D and the 3rd 112D place, summit terminate.In some instances, Keysheet module 8 can use transition probabilities to determine whether and character string " zhong " and " huo " is concatenated into " zhonghuo " on the limit of word grid 120.
In the example of hgure 5, Keysheet module 8 also can determine alignment point 148F-148H along gesture path 146.For each word level mark in activity bundle 56, Keysheet module 8 can create a Copy in each child node.In the example of hgure 5, mark
3to mark
6there is child node respectively with letter key " G " and " H " separately.In addition, mark
7the Ingress node of the word level mark with index 7 can be regarded as.Therefore, Keysheet module 8 also can at word level mark
7child node place create a Copy.For created each word level mark copy, Keysheet module 8 can determine value at cost as mentioned above.Each word level mark copy can be pushed in lower a branch of 58 by Keysheet module 8, and its content can be represented by following table 5.
Table 5
Index | Father's index | The letter key of present node | Letter chain | Value at cost |
8 | 3 | O | ZHONGGUO | CV8 |
9 | 3 | O | ZHONHHUO | CV9 |
10 | 4 | O | XHONGGUO | CV10 |
11 | 4 | O | XHONGHUO | CV11 |
12 | 7 | O | GUO | CV12 |
13 | 7 | O | HUO | CV13 |
n | m | x | <alphabetical chain> | CNn |
Entry shown in table 5 is similar to the entry of table shown in 1-4 on form.In table 5, the value at cost of each word level mark comprises the value at cost of letter above and the value at cost of current letter.Therefore, calculation element 2 can at least in part based on representing that the word level mark of candidate word included in dictionary and the prediction of character keys are selected to determine one or more word level mark.Like this, in response to the instruction receiving the continuous gesture selecting one group of key included in graphic keyboard, Keysheet module 8 can determine word level mark.Along with Keysheet module 8 receives the further instruction of gesture, Keysheet module 8 can continue incrementally to determine one or more word level mark, thus makes user that single gesture can be provided to select one group of key of word or phrase.
As mentioned above, when determining terminal node, Keysheet module 8 can generate the limit of correspondence letter chain (such as, candidate character strings) comprising terminal node on word grid 112.In other example, based on value at cost, Keysheet module 8 can determine that alphabetical chain is included in mark grid 110 with alternatively character string.That is, Keysheet module 8 can determine the value at cost meeting threshold value.Such as, Keysheet module 8 can be determined to be greater than the value at cost of threshold value and in mark grid 110, generate limit for the alphabetical chain be associated with value at cost respectively.Therefore, in some instances, in response to the combination of OK button value at cost (such as, the value at cost be associated with the alphabetical chain of expression candidate character strings) meet threshold value, by calculation element, the limit of candidate character strings with word grid is associated, wherein, character string comprises the character be associated with the combination of key.In some instances, the difference between the index of initial vertex and the index on ending summit can equal the quantity of the character in candidate character strings.Such as, if determined candidate character strings is " zhong ", then the index of initial vertex can be zero, and the index on ending summit can be 5.If determine multiple candidate character strings based on border from single string, such as " zhong ", " huo ", then the beginning summit of the second candidate character strings can start from having the summit of index 5 and end to have the summit of index 8.
Fig. 6 A-6B is the process flow diagram of the exemplary operations of the calculation element from gesture determination word and/or phrase illustrated according to one or more technology of the present disclosure.Only for illustration object, under the background of the calculation element 2 such as such as shown in Fig. 1, Fig. 2 and Fig. 5, exemplary operations is described below.
In the example of Fig. 6 A-6B, calculation element 2 can initially export comprise multiple key graphic keyboard (such as, graphic keyboard 16B) to show (150).Calculation element 2 can detect the gesture (152) that there is sensitive display place.Such as, there is sensitive display 4 and can detect the gesture with gesture path 140.The UI module 6 performed on the one or more processors can be received in the instruction that there is the gesture that sensitive display 4 place detects.In response to receiving in the instruction that there is the gesture that sensitive display place detects, calculation element 2 can be the word level mark (154) of zero in the Ingress node place manufacturing cost value being stored in the dictionary on calculation element 2 as lexicographic tree.Word level mark can be pushed to movable intrafascicular (156) by calculation element 2.Such as, word level mark can be pushed in movable bundle 56 by calculation element 2.
Calculation element 2 can select word level mark (158) from activity bundle.Calculation element 2 can create the copy (160) of word level mark in each child node of word level mark.Calculation element 2 can select word level mark copy (162) and along gesture determination alignment point (164).Calculation element 2 can determine the value at cost of the probability of the letter key of the node representing alignment point deictic words level mark copy place, and adds this value at cost to word level mark copy (166).Word level mark copy can be pushed to next intrafascicular (168) by calculation element 2.Calculation element 2 can be determined that activity is intrafascicular and whether remain any word level mark copy (170).If residue has word level mark copy (172), then calculation element 2 can select new word level mark copy (162).
If do not have residue to have any word level mark copy (174), then calculation element 2 can determine that whether word level mark is at the terminal node place (176) of lexicographic tree.Such as, calculation element 2 can use language model 12 to determine the candidate word whether word level mark represents included in dictionary (such as, English).If word level mark is in terminal node place (178), then calculation element 2 as shown in Figure 5ly can create limit in mark grid 110, wherein this limit corresponds to alphabetical chain (such as, candidate character strings) (182) indicated by terminal node.The key that next calculation element 2 can be selected in multiple keys of generation indicating graphic keyboard as shown in Figure 5 is next word mark (184) of the prefix of the second word level mark.After candidate character strings being copied to mark grid 110 and generate next word mark, if or word level mark not in terminal node place (180), calculation element 2 discardable word level mark (186).
Calculation element 2 can be determined that activity is intrafascicular and whether remain any word level mark (188).If movable intrafascicular residue has word level mark (190), then calculation element 2 can select new word level mark (158) from activity bundle.Intrafascicularly do not remained word level mark (192) if movable, then calculation element 2 can determine whether next has intrafascicularly remained any word level mark (194).If next intrafascicular residue has word level mark (196), then calculation element 2 a branch ofly can copy to lower movable bundle (198) and select new word level mark (158) from activity bundle.Do not remained word level mark (200) if next is intrafascicular, then in some instances, calculation element 2 determines next instruction that user inputs, such as touch event (202).
Fig. 7 be illustrate according to one or more aspect of the present disclosure at least in part based on the process flow diagram selecting the user of character included in the alphabet of first language input to determine the exemplary operations of one or more character of second language and/or the calculation element of word.Only for illustration object, under the background of the calculation element 2 such as such as shown in Fig. 1 and Fig. 2, exemplary operations is described below.
Calculation element 2 can initially export comprise multiple key graphic keyboard to show (220).Such as, there is sensitive display 4 place to be presented in the exportable QWERT keyboard of calculation element 2.Calculation element 2 can be received in the instruction (222) that there is the gesture that sensitive display place detects.Such as, calculation element 2 can receive and rap input, continuously gesture and/or its combination.Like this, user can gently sweep and rap the two mixing, makes user can perform continuous gesture gently to sweep a part for candidate character strings (such as, pinyin string) and to rap the remainder of candidate character strings.
In response to the instruction receiving gesture, calculation element 2 can determine one group of one or more candidate character strings (224) based on the instruction of gesture.Such as, calculation element 2 can rap input modeling to one or more on the grid of such as character grid 100.Calculation element 2 as shown in Figure 4ly can be determined one or more candidate character strings from character grid and create limit mark grid 110.In some instances, calculation element 2 can determine one or more candidate character strings based on lexicographic tree as described in Fig. 5-6B.Such as, as described in Fig. 5-6B, calculation element 2 can determine one or more candidate character strings and to character string modeling in mark grid 110.
In some instances, calculation element 2 can determine the probability (226) of one group of one or more candidate character strings.Such as, calculation element 2 can determine the spatial model probability of one or more candidate character strings.As described in Fig. 4-6B, calculation element 2 can determine the spatial model probability of candidate character strings based on the additional space model probability of one or more characters corresponding with one or more keys of graphic keyboard in candidate character strings.
In some instances, calculation element 2 can to one or more candidate character strings modeling (228) in mark grid 110.Such as, the spatial model probability of candidate character strings and correspondence thereof can be associated with the limit in mark grid 110 by calculation element 2.Calculation element 2 also can to one or more candidate character strings modelings (230) of mark grid 110 in word grid 120.In one example, calculation element 2 can travel through mark grid 110 to determine to have the path of maximum probability.The limit of the serial connection of character string with word grid 120 can be associated from mark grid 110 by calculation element 2 by multiple candidate character strings serial connection.
Calculation element 2 can determine that probability that the serial connection that can be associated with limit is associated is as limit weight.Then, calculation element 2 can be used to determine whether such serial connection of candidate character strings corresponds to the one or more words in language.Such as, the probability be associated with the limit in word grid 120 higher can indicating user to be intended to input the possibility of the word be associated with this limit larger.Therefore, in some instances, calculation element 2 can determine whether the probability be associated with the word in word grid meets threshold value (232).Such as, if described probability meets threshold value (236) (such as, described probability is greater than threshold value), then calculation element 2 at least one word exportable is to show (238).If described probability does not meet threshold value, then calculation element 2 can not export at least one word to show (234).In some instances, calculation element 2 can perform the technology of Fig. 7, and the instruction that user inputs incrementally determined by calculation element 2.That is, for each each part of rapping input and/or gesture input, calculation element 2 can incrementally use character grid determination word to export for display.
Fig. 8 be illustrate according to one or more aspect of the present disclosure at least in part based on the process flow diagram selecting the user of character included in the alphabet of first language input to determine the exemplary operations of one or more character of second language and/or the calculation element of word.Only for illustration object, under the background of the calculation element 2 such as such as shown in Fig. 1 and Fig. 2, exemplary operations is described below.
Calculation element 2 can initially export comprise multiple key graphic keyboard to show (260).In some instances, at least one in described multiple key is associated with one or more symbols included in the first alphabet of first language.In response to receiving in the instruction that there is sensitive display 4 (can comprise and there is sensitizing input device) at least one gesture that place detects, calculation element 2 can to each multiple character string modelings (262) comprising the first alphabetic(al) symbol in the first grid.In some instances, the first grid indicates the Spatial Probability of each in multiple character string, and wherein said Spatial Probability is at least in part based on the instruction of at least one gesture.
In some instances, calculation element 2 can at least one in multiple character string use the second grid of the probability of one or more words of instruction second language at least in part based on the Spatial Probability of described multiple character string determine in multiple character string at least one correspond to probability (264) of at least one word included in second language.In some instances, at least one word described is represented by corresponding with second language second alphabetic(al) one or more symbol.In some instances, in response to determining that at least one probability meets threshold value, one or more symbols of at least one word of the exportable expression of calculation element 2 are to show (266).
In one example, described method can comprise: determined one group of character included in the candidate character strings in multiple candidate character strings by calculation element; The spatial model probability of the key corresponding with character included in candidate character strings is determined by calculation element; Determined the gross space model probability of candidate character strings at least in part based on the spatial model probability of the key corresponding with character included in candidate character strings by calculation element; And generating the limit in the first grid by calculation element, the gross space model probability of wherein said candidate character strings and character string is associated with this limit.
In one example, described method can comprise: the spatial model probability being determined the key of the graphic keyboard close to the position of rapping input by calculation element; Generate the limit in the 3rd grid by calculation element, described limit corresponds to the key of the graphic keyboard close to the position of rapping input separately; By calculation element by close to rap input position graphic keyboard character and be associated with limit close to the additional space model probability of key of graphic keyboard of the position of rapping input; Many articles of limits in the 3rd grid are determined by calculation element; And in the first grid, the limit be associated with candidate character strings is generated by calculation element, wherein candidate character strings generates based on many articles of limits in the 3rd grid at least in part.
In one example, described method can comprise: determine that the first spatial model probability of the first candidate character strings meets threshold value by calculation element, wherein said first candidate character strings corresponds to the first limit of the first grid, and wherein said first limit is from the first summit and terminate at the second summit place; Determine that the second space model probability of the second candidate character strings meets threshold value by calculation element, wherein said second candidate character strings corresponds to the Second Edge of the first grid, and wherein said Second Edge is from the second summit and terminate at the 3rd summit place; And the 3rd limit of the probability of at least one word described in included by calculation element generates in instruction second language based on the first spatial model probability and second space model probability at least in part in the second grid.
In one example, described method can comprise: be connected in series the first candidate character strings and the second candidate character strings to generate the 3rd candidate character strings by calculation element; By calculation element, the 3rd candidate character strings is associated with the 3rd limit in the second grid; And the probability of the 3rd candidate character strings under the condition of the word of second language is determined by calculation element.
In one example, described method can comprise: determine candidate character strings based on one group of key by calculation element at least in part in response to the instruction receiving at least one gesture, wherein saidly determines to comprise: determined the one group of alignment point traveled through by gesture by calculation element; The corresponding value at cost of each at least two keys in described multiple key is determined, the probability of the key in the described multiple key of alignment point instruction in the described one group of alignment point of each expression in wherein said corresponding value at cost by calculation element; Value at cost in response to the combination of OK button meets threshold value, is associated on the limit of candidate character strings with the first grid by calculation element, and wherein said character string comprises the character be associated with the combination of described key.
In one example, described method can comprise: by calculation element in response to receiving in the instruction that there is at least one gesture that sensitizing input device detects, determine multiple character; At least one border between described multiple character is determined, second group of character corresponding with the second candidate character strings in first group of character corresponding with the first candidate character strings and described multiple character in the described multiple character of wherein said at least one border instruction by calculation element; In the first grid, generated the first limit be associated with the first candidate character strings by calculation element, wherein said first limit is from the first summit and terminate at the second summit place; In the first grid, generated the Second Edge be associated with the second candidate character strings by calculation element, wherein said Second Edge is from the second summit and terminate at the 3rd summit place; And the probability of the first candidate character strings and the second candidate character strings under the condition of the word of second language is determined by calculation element.
Fig. 9 is the concept map of the grid illustrated according to technology of the present disclosure, and calculation element can generate described grid based on the instruction of user's input of the alphabetic(al) character selected in first language and use it to determine the word of second language.Fig. 9 illustrates character grid 100, mark grid 110 and word grid 120 as described in previous Fig. 4.In addition, Fig. 9 illustrate the Chinese character Z1 corresponding with " weight ", with " in " corresponding Z2, the H corresponding with " work ".Fig. 9 also illustrates the Chinese word ZG corresponding with " China ".As shown in Figure 9, only for illustrative purposes, word grid 120 comprises the limit different from shown in Fig. 4 and combines (the double-head arrow limit between the node boundary 285 indicated by the vertical dotted line extended from corresponding node 281 indicates).Composer module 50 can according to the technology described in Fig. 4 to the limit modeling in Fig. 9.
Fig. 9 also illustrates the Viterbi path 280 and 282 can determined by decoder module 52.Such as, the limit of decoder module 52 searchable word grid 120 is to find the path (being jointly made up of one or more limit) with highest weighting.As an example, decoder module 52 can determine Viterbi path 280 when search word grid 120.Viterbi path 280 may correspond to the limit 302 in the word grid 120 be associated with Chinese word ZG (i.e. China).Decoder module 52 can determine probability P (ZG), its can appear at frequency in Chinese with Chinese word ZG (i.e. China) or probability corresponding.Decoder module 52 also can determine probability P in Viterbi path 280 (" zhong ", " guo " | ZG).P (" zhong ", " guo " | ZG) can indicate the probability of candidate character strings " zhong ", " guo " under the condition of Chinese word ZG.Finally, Viterbi path 280 can comprise P
spatial(" zhong ") P
spatial(" guo "), it may correspond to the additional space model probability on limit corresponding with " zhong " and " guo " in mark grid 110.Decoder module 52 can determine total weight on limit 302 based on the product of probability:
P(ZG)P(‘zhong’，‘guo’|ZG)P
spatial(‘zhong’)P
spatial(‘guo’)
Decoder module 52 can determine Viterbi path for any amount of limit in word grid 120.Such as, as shown in Figure 9, decoder module 52 also can determine Viterbi path 282 for the limit 304 and 306 in word grid 120.Decoder module 52 can determine probability P (Z1), and it may correspond to and appears at frequency in Chinese or probability in Chinese character Zl (that is, heavy).Probability P (Z1) can be referred to as unitary probability.Decoder module 52 also can determine the probability P (H|Z1) in Viterbi path 282.Probability P (H|Z1) may correspond to the probability of character H under the condition of the appearance at character Zl.Here, probability P (H|Z1) may correspond in bivariate probability.Decoder module 52 also can determine the probability P corresponding with limit 304 (" zhong " | Z1).P (" zhong " | Z1) can represent the probability of candidate character strings " zhong " under the condition of Chinese character Z1.Similarly, decoder module 52 can determine the probability P corresponding with limit 306 (" huo " | H).P (" huo " | H) can represent the probability of candidate character strings " huo " under the condition of Chinese character H.Decoder module 52 can determine the P corresponding with the spatial model score value on the limit 304 and 306 determined from the corresponding sides in mark grid 110
spatial(" zhong ") P
spatial(" huo ").Decoder module 52 can determine total weight in the path comprising limit 304 and 306 based on the product of probability:
P(Z1)P(H|Z1)P(‘zhong’|Z1)P(‘huo’|H)P
spatial(‘zhong’)P
spatial(‘huo’)
Finally, in some instances, formula 283 indicates decoder module 52 can come to have in search word grid 120 based on space and language model score value the limit of maximum probability.Such as, P (t) may correspond to the probability in the character of second language, word or many words phrase; P (s'|1) may correspond to the probability in the character providing one or more candidate character strings second language, word or many words phrase; And P (s|s') may correspond to the spatial model probability in one or more candidate character strings.
Fig. 9 also show user interface (UI) element 284.In some instances, decoder module 52 can send data to UI module 6 and export UI element 284 to make there is sensitive display 4.UI element 284 can present one or more characters of the second language determined based on technology of the present disclosure, word and/or many words phrase.Such as, at first, user can provide the user of input " zhong " the one or more instructions inputted.Based on technology of the present disclosure, decoder module 52 can determine the limit 304 of the word grid 120 corresponding with " zhong ".Decoder module 52 can determine that the score value be associated with limit 304 meets in one group of highest score of threshold value, therefore to UI module 6 send data with make to exist sensitive display 4 export the character corresponding with limit 304 " in " 288.Decoder module 52 also can be determined that the score value be associated with limit 302 is included in and meet in described one group of highest score of threshold value, therefore as Suo Shi 284, exports " China ".
In some instances, user can provide select character " in " instruction of the user of 288 input (such as, by output character " in " position that there is sensitive display 4 of 288 sits gesture).In response to the instruction determining gesture, UI module 6 can make to exist sensitive display 4 replace existing sensitive display 4 previously display " zhong " output character " in " 209.Determine to select character " in " instruction of the gesture of 288 time, decoder module 52 also can determine the one or more paths comprising the limit be associated with " zhong " at word grid 120, and such as word grid 120 comprises the path on limit 304 and limit 306.Decoder module 52 also can determine limit 308 and 310.Because " zhong " is selected in the instruction of user's input, so decoder module 52 can be determined the candidate character strings that is associated with the limit in path and comprise " zhong ".Such as, the exportable candidate character strings " guo " corresponding with limit 306 and 310 respectively of decoder module 52 and " huo ", it is corresponding with the limit 304 and 308 that " zhong " is associated further.Calculation element 294 can receive the instruction of the subsequent user input selecting candidate character strings 300.As shown in Figure 9, decoder module 52 previously can make to there is sensitive display 4 and export " guo ", because the limit be associated with " zhongguo " can have highest weighting in word grid 120, therefore exportable as most probable word.But, because user have selected the candidate character strings 300 corresponding with " huo ", so UI module 6 can make to there is sensitive display 4 export the character " work " corresponding with such as " huo ", make in UI element 284, to replace " middle guo " to show.Like this, along with user incrementally provides user the instruction inputted, user can select the character being presented at the expectation in UI element 284, word or the many words phrase determined based on word grid 120 and decoder module 52.
In one or more example, described function can be implemented in hardware, software, firmware or its any combination.If be implemented in software, then described function can be used as one or more instruction or code is stored on a computer-readable medium or machine computer-readable recording medium sends as calculated, and is performed by hardware based processing unit.Computer-readable medium can comprise: computer-readable recording medium, and it corresponds to the tangible medium of such as data storage medium; Or communication media, it comprises and such as facilitates computer program to be sent to any medium in another place from the three unities according to communication protocol.Like this, computer-readable medium may correspond in the tangible computer readable storage medium storing program for executing of (1) non-transient usually; Or (2) communication media of such as signal or carrier wave.Data storage medium can be any usable medium, its can by one or more computing machine or one or more processor access with search instruction, code and/or data structure for the technology realized described in the disclosure.Computer program finished product can comprise computer-readable medium.
Exemplarily unrestricted, such computer-readable recording medium can comprise RAM, ROM, EEPROM, CD-ROM or other optical disc storage, disk storage or other magnetic memory apparatus, flash memory or can be used for storing with the form of instruction or data structure the program code expected and can by other medium any of computer access.In addition, any connection is properly termed computer-readable medium.Such as, if use coaxial cable, optical fiber cable, twisted-pair feeder, digital subscribe lines (DSL) or such as infrared, radio and microwave wireless technology from website, server or other remote source send instruction, then the wireless technology of coaxial cable, optical fiber cable, twisted-pair feeder, DSL or such as infrared, radio and microwave is included in the definition of medium.But, should be appreciated that, computer-readable recording medium and data storage medium do not comprise be connected, carrier wave, signal or other transient medium, and relate to non-momentary tangible media.The disk used and CD comprise compact disk (CD), laser disk, optical disc, digital versatile disc (DVD), floppy disk and Blu-ray disc, wherein disk is usually with magnetic mode rendering data, and cd-rom using laser rendering data to be optically.Above-mentioned combination also should be included in the scope of computer-readable medium.
Instruction can be performed by one or more processor, and described processor is one or more digital signal processor (DSP), general purpose microprocessor, special IC (ASIC), field programmable logic array (FPLA) (FPGA) or other equivalent integrated or discrete logical circuit such as.Therefore, the term " processor " used can refer to above-mentioned any structure or be suitable for other structure any of the technology described by realization.In addition, in some respects, described function can provide in specialized hardware and/or software module.In addition, described technology can be completely achieved in one or more circuit or logic element.
Technology of the present disclosure can be implemented in various device or equipment, comprises wireless headset, integrated circuit (IC) or IC collection (such as chipset).Describe various assembly, module or unit in the disclosure to focus on the function aspects of the device of the technology be configured to disclosed in execution, and inevitable requirement is not realized by different hardware cells.On the contrary, as mentioned above, various unit can be combined in hardware cell or by the set of the hardware cell that cooperates and provide, and comprises one or more processor as above, in conjunction with suitable software and/or firmware.
To recognize, depend on embodiment, some behavior of any method as herein described or event can perform according to different orders, can be added, merge or leave out together (practice such as, for method is not that described all behaviors or event are necessary).In addition, in certain embodiments, behavior or event such as can carry out concurrence performance by multiple threads, terminal processes or multiprocessor, and non-sequentially performs.
Describe various example.These and other example within the scope of the appended claims.
Claims (21)
1. comprise a calculation element at least one processor, at least one processor wherein said is configured to:
Output comprises the graphic keyboard of multiple key with display, and at least one in wherein said multiple key is associated with the one or more symbols in the first alphabet being included in first language;
In response to receiving in the instruction that there is at least one gesture that sensitizing input device place detects, to each multiple candidate character strings modelings comprising described first alphabetic(al) symbol in the first grid, the Spatial Probability of each in the described multiple candidate character strings of wherein said first grid instruction, wherein said Spatial Probability is at least in part based on the described instruction of at least one gesture described;
For at least one in described multiple candidate character strings, at least in part based on the described Spatial Probability of described multiple candidate character strings use the second grid of the probability of one or more words of instruction second language determine in described multiple candidate character strings described at least one corresponds to probability of at least one word included in described second language, at least one word wherein said is represented by corresponding with described second language second alphabetic(al) one or more symbol; And
In response to determining that described probability meets threshold value, exporting and representing that described one or more symbol of at least one word described is with display.
2. calculation element according to claim 1, wherein, at least one processor described is configured to:
Determine one group of character included in a candidate character strings in described multiple candidate character strings;
Determine the spatial model probability of the key corresponding with character included in described candidate character strings;
At least in part based on spatial model probability and the corresponding gross space model probability determining described candidate character strings of character included in described candidate character strings of described key; And
Determine the limit in described first grid, the described gross space model probability of wherein said candidate character strings and described character string is associated with described limit.
3. calculation element according to claim 1, wherein, comprise further in the described described instruction that there is at least one gesture that sensitizing input device place detects and rap input, at least one processor wherein said is configured to:
Determine close to described in rap the spatial model probability of the key of the described graphic keyboard of the position of input;
Generate in the 3rd grid each and close to described in rap the corresponding limit of the key of the described graphic keyboard of the position of input;
By close to described in rap the described graphic keyboard of the position of input character and close to described in rap the key of the described graphic keyboard of the position of input additional space model probability be associated with described limit;
Determine many articles of limits in described 3rd grid; And
In described first grid, generate the limit be associated with candidate character strings, wherein said candidate character strings generates based on the described many articles of limits in described 3rd grid at least in part.
4. calculation element according to claim 1, wherein, at least one processor described is configured to:
Determine that the first spatial model probability of the first candidate character strings meets threshold value, wherein said first candidate character strings corresponds to the first limit of described first grid, and wherein said first limit is from the first summit and terminate at the second summit place;
Determine that the second space model probability of the second candidate character strings meets described threshold value, wherein said second candidate character strings corresponds to the Second Edge of described first grid, and wherein said Second Edge is from described second summit and terminate at the 3rd summit place; And
At least in part based on described first spatial model probability and described second space model probability generate in described second grid instruction be included in described second language described in the 3rd limit of probability of at least one word.
5. calculation element according to claim 4, wherein, at least one processor described is configured to:
Described first candidate character strings and described second candidate character strings are connected in series to generate the 3rd candidate character strings;
Described 3rd candidate character strings is associated with described 3rd limit in described second grid; And
Determine the probability of described 3rd candidate character strings under the condition of institute's predicate of described second language.
6. calculation element according to claim 1, wherein, comprise the input of continuous gesture further in the described described instruction that there is at least one gesture that sensitizing input device place detects, at least one processor wherein said is configured to:
In response to the instruction receiving at least one gesture, determine candidate character strings based on one group of key at least in part, wherein saidly determine to comprise:
Determine one group of alignment point that described gesture travels through;
Determine the corresponding value at cost of each at least two keys in described multiple key, the probability of a key in a described multiple key of alignment point instruction in the described one group of alignment point of each expression in wherein said corresponding value at cost;
Value at cost in response to OK button combination meets threshold value, and be associated on the limit of candidate character strings with described first grid by described calculation element, wherein said character string comprises the character be associated with described key combination.
7. calculation element according to claim 1, wherein, at least one processor described is configured to:
In response to receiving in the instruction that there is at least one gesture that sensitizing input device place detects, determine multiple character;
Determine at least one border between described multiple character, second group of character corresponding with the second candidate character strings in first group of character corresponding with the first candidate character strings and described multiple character in the described multiple character of wherein said at least one border instruction;
In described first grid, generate the first limit of being associated with described first candidate character strings, wherein said first limit is from the first summit and terminate at the second summit place;
In described first grid, generate the Second Edge that is associated with described second candidate character strings, wherein said Second Edge is from described second summit and terminate at the 3rd summit place; And
Determine the probability of described first candidate character strings and described second candidate character strings under the condition of institute's predicate of described second language.
8. coding has a computer-readable recording medium for instruction, and described instruction makes at least one processor when being performed:
Output comprises the graphic keyboard of multiple key with display, and at least one in wherein said multiple key is associated with the one or more symbols in the first alphabet being included in first language;
In response to receiving in the instruction that there is at least one gesture that sensitizing input device place detects, to each multiple candidate character strings modelings comprising described first alphabetic(al) symbol in the first grid, the Spatial Probability of each in the described multiple candidate character strings of wherein said first grid instruction, wherein said Spatial Probability is at least in part based on the described instruction of at least one gesture described;
For at least one in described multiple candidate character strings, at least in part based on the described Spatial Probability of described multiple candidate character strings use the second grid of the probability of one or more words of instruction second language determine in described multiple candidate character strings described at least one corresponds to probability of at least one word included in described second language, at least one word wherein said is represented by corresponding with described second language second alphabetic(al) one or more symbol; And
In response to determining that described probability meets threshold value, exporting and representing that described one or more symbol of at least one word described is with display.
9. coding according to claim 8 has the computer-readable recording medium of instruction, and described instruction makes at least one processor when being performed:
Determine one group of character included in a candidate character strings in described multiple candidate character strings;
Determine the spatial model probability of the key corresponding with character included in described candidate character strings;
At least in part based on spatial model probability and the corresponding gross space model probability determining described candidate character strings of character included in described candidate character strings of described key; And
Determine the limit in described first grid, the described gross space model probability of wherein said candidate character strings and described character string is associated with described limit.
10. computer-readable recording medium according to claim 8, wherein, comprise further in the described described instruction that there is at least one gesture that sensitizing input device place detects and rap input, wherein said computer-readable recording medium coding has instruction, and described instruction is when being performed:
Determine close to described in rap the spatial model probability of the key of the described graphic keyboard of the position of input;
Generate in the 3rd grid each and close to described in rap the corresponding limit of the key of the described graphic keyboard of the position of input;
By close to described in rap the described graphic keyboard of the position of input character and close to described in rap the key of the described graphic keyboard of the position of input additional space model probability be associated with described limit;
Determine many articles of limits in described 3rd grid; And
In described first grid, generate the limit be associated with candidate character strings, wherein said candidate character strings generates based on the described many articles of limits in described 3rd grid at least in part.
11. codings according to claim 8 have the computer-readable recording medium of instruction, and described instruction makes at least one processor when being performed:
Determine that the first spatial model probability of the first candidate character strings meets threshold value, wherein said first candidate character strings corresponds to the first limit of described first grid, and wherein said first limit is from the first summit and terminate at the second summit place;
Determine that the second space model probability of the second candidate character strings meets described threshold value, wherein said second candidate character strings corresponds to the Second Edge of described first grid, and wherein said Second Edge is from described second summit and terminate at the 3rd summit place; And
3rd limit of the probability of at least one word described in included by generating in described second grid in the described second language of instruction based on described first spatial model probability and described second space model probability at least in part.
12. codings according to claim 11 have the computer-readable recording medium of instruction, and described instruction makes at least one processor when being performed:
Described first candidate character strings and described second candidate character strings are connected in series to generate the 3rd candidate character strings;
Described 3rd candidate character strings is associated with described 3rd limit in described second grid; And
Determine the probability of described 3rd candidate character strings under the condition of institute's predicate of described second language.
13. computer-readable recording mediums according to claim 8, wherein, the input of continuous gesture is comprised further in the described described instruction that there is at least one gesture that sensitizing input device place detects, wherein said computer-readable recording medium coding has instruction, and described instruction is when being performed:
In response to the instruction receiving at least one gesture, determine candidate character strings based on one group of key at least in part, wherein, describedly determine to comprise:
One group of alignment point of true described gesture traversal;
Determine the corresponding value at cost of each at least two keys in described multiple key, the probability of a key in a described multiple key of alignment point instruction in the described one group of alignment point of each expression in wherein said corresponding value at cost;
Value at cost in response to OK button combination meets threshold value, and be associated on the limit of candidate character strings with described first grid by described calculation element, wherein said character string comprises the character be associated with described key combination.
14. codings according to claim 8 have the computer-readable recording medium of instruction, and described instruction makes at least one processor when being performed:
In response to receiving in the instruction that there is at least one gesture that sensitizing input device place detects, determine multiple character;
Determine at least one border between described multiple character, second group of character corresponding with the second candidate character strings in first group of character corresponding with the first candidate character strings and described multiple character in the described multiple character of wherein said at least one border instruction;
In described first grid, generate the first limit of being associated with described first candidate character strings, wherein said first limit is from the first summit and terminate at the second summit place;
In described first grid, generate the Second Edge that is associated with described second candidate character strings, wherein said Second Edge is from described second summit and terminate at the 3rd summit place; And
Determine the probability of described first candidate character strings and described second candidate character strings under the condition of institute's predicate of described second language.
15. 1 kinds of methods, comprising:
Comprise the graphic keyboard of multiple key with display by calculation element output, at least one in wherein said multiple key is associated with the one or more symbols in the first alphabet being included in first language;
In response to receiving in the instruction that there is at least one gesture that sensitizing input device place detects, to each multiple candidate character strings modelings comprising described first alphabetic(al) symbol in the first grid, the Spatial Probability of each in the described multiple candidate character strings of wherein said first grid instruction, wherein said Spatial Probability is at least in part based on the described instruction of at least one gesture described;
For at least one in described multiple candidate character strings, at least in part based on the described Spatial Probability of described multiple candidate character strings use the second grid of the probability of one or more words of instruction second language determine in described multiple candidate character strings described at least one probability corresponding at least one word be included in described second language, wherein, at least one word described is represented by corresponding with described second language second alphabetic(al) one or more symbol; And
In response to determining that described probability meets threshold value, being exported by described calculation element and representing that described one or more symbol of at least one word described is with display.
16. methods according to claim 15, wherein, comprise further each multiple candidate character strings modelings comprising described first alphabetic(al) symbol in the first grid:
One group of character included in the candidate character strings in described multiple candidate character strings is determined by described calculation element;
The spatial model probability of the key corresponding with character included in described candidate character strings is determined by described calculation element;
By described calculation element at least in part based on spatial model probability and the corresponding gross space model probability determining described candidate character strings of character included in described candidate character strings of described key; And
Generate the limit in described first grid by described calculation element, wherein, the described gross space model probability of described candidate character strings and described character string is associated with described limit.
17. methods according to claim 15, wherein, comprise further in the described described instruction that there is at least one gesture that sensitizing input device place detects and rap input, described method comprises further:
By described calculation element determine close to described in rap the spatial model probability of the key of the described graphic keyboard of the position of input;
By described calculation element generate in the 3rd grid each and close to described in rap the corresponding limit of the key of the described graphic keyboard of the position of input;
By described calculation element by close to described in rap the described graphic keyboard of the position of input character and close to described in rap the key of the described graphic keyboard of the position of input additional space model probability be associated with described limit;
Many articles of limits in described 3rd grid are determined by described calculation element; And
In described first grid, generated the limit be associated with candidate character strings by described calculation element, wherein said candidate character strings generates based on the described many articles of limits in described 3rd grid at least in part.
18. methods according to claim 15, comprise further:
Determine that the first spatial model probability of the first candidate character strings meets threshold value by described calculation element, wherein said first candidate character strings corresponds to the first limit of described first grid, and wherein said first limit is from the first summit and terminate at the second summit place;
Determine that the second space model probability of the second candidate character strings meets described threshold value by described calculation element, wherein said second candidate character strings corresponds to the Second Edge of described first grid, and wherein said Second Edge is from described second summit and terminate at the 3rd summit place; And
By described calculation element at least in part based on described first spatial model probability and described second space model probability generate in described second grid instruction be included in described second language described in the 3rd limit of probability of at least one word.
19. methods according to claim 18, comprise further:
By described calculation element, described first candidate character strings and described second candidate character strings are connected in series to generate the 3rd candidate character strings;
By described calculation element, described 3rd candidate character strings is associated with described 3rd limit in described second grid; And
The probability of described 3rd candidate character strings under the condition of institute's predicate of described second language is determined by described calculation element.
20. methods according to claim 15, wherein, comprise the input of continuous gesture further in the described described instruction that there is at least one gesture that sensitizing input device place detects, described method comprises further:
By described calculation element in response to the instruction receiving at least one gesture, determine candidate character strings based on one group of key at least in part, wherein saidly determine to comprise:
One group of alignment point that described gesture travels through is determined by described calculation element;
The corresponding value at cost of each at least two keys in described multiple key is determined, the probability of a key in a described multiple key of alignment point instruction in the described one group of alignment point of each expression in wherein said corresponding value at cost by described calculation element;
Value at cost in response to OK button combination meets threshold value, and be associated on the limit of candidate character strings with described first grid by described calculation element, wherein said character string comprises the character be associated with described key combination.
21. methods according to claim 15, comprise further:
Multiple character is determined in response to receiving in the instruction that there is at least one gesture that sensitizing input device detects by described calculation element;
At least one border between described multiple character is determined, second group of character corresponding with the second candidate character strings in first group of character corresponding with the first candidate character strings and described multiple character in the described multiple character of wherein said at least one border instruction by described calculation element;
In described first grid, generated the first limit be associated with described first candidate character strings by described calculation element, wherein said first limit is from the first summit and terminate at the second summit place;
In described first grid, generated the Second Edge be associated with described second candidate character strings by described calculation element, wherein said Second Edge is from the second summit and terminate at the 3rd summit place; And
The probability of described first candidate character strings and described second candidate character strings under the condition of institute's predicate of described second language is determined by described calculation element.
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/CN2013/072755 WO2014139173A1 (en) | 2013-03-15 | 2013-03-15 | Virtual keyboard input for international languages |
Publications (2)
Publication Number | Publication Date |
---|---|
CN105431809A true CN105431809A (en) | 2016-03-23 |
CN105431809B CN105431809B (en) | 2018-12-18 |
Family
ID=51535850
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201380076553.9A Active CN105431809B (en) | 2013-03-15 | 2013-03-15 | Dummy keyboard for International Language inputs |
Country Status (5)
Country | Link |
---|---|
US (1) | US10073536B2 (en) |
JP (1) | JP6151381B2 (en) |
KR (1) | KR102078785B1 (en) |
CN (1) | CN105431809B (en) |
WO (1) | WO2014139173A1 (en) |
Cited By (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN107817942A (en) * | 2016-09-14 | 2018-03-20 | 北京搜狗科技发展有限公司 | A kind of slide input method, system and a kind of device for being used to slide input |
CN108475157A (en) * | 2016-03-25 | 2018-08-31 | 华为技术有限公司 | Characters input method, device and terminal |
CN108701123A (en) * | 2016-04-04 | 2018-10-23 | 谷歌有限责任公司 | The dynamic key of graphic keyboard maps |
CN108701124A (en) * | 2016-05-17 | 2018-10-23 | 谷歌有限责任公司 | It predicts next letter and shows them in the key of graphic keyboard |
CN110888577A (en) * | 2018-09-10 | 2020-03-17 | 百度在线网络技术（北京）有限公司 | Character correction method, device, equipment and storage medium |
CN113227946A (en) * | 2018-11-03 | 2021-08-06 | 宗刚 | Alphabetic writing input method |
Families Citing this family (143)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8677377B2 (en) | 2005-09-08 | 2014-03-18 | Apple Inc. | Method and apparatus for building an intelligent automated assistant |
US9318108B2 (en) | 2010-01-18 | 2016-04-19 | Apple Inc. | Intelligent automated assistant |
US8977255B2 (en) | 2007-04-03 | 2015-03-10 | Apple Inc. | Method and system for operating a multi-function portable electronic device using voice-activation |
US10002189B2 (en) | 2007-12-20 | 2018-06-19 | Apple Inc. | Method and apparatus for searching using an active ontology |
US9330720B2 (en) | 2008-01-03 | 2016-05-03 | Apple Inc. | Methods and apparatus for altering audio output signals |
US8996376B2 (en) | 2008-04-05 | 2015-03-31 | Apple Inc. | Intelligent text-to-speech conversion |
US20100030549A1 (en) | 2008-07-31 | 2010-02-04 | Lee Michael M | Mobile device having human language translation capability with positional feedback |
US8676904B2 (en) | 2008-10-02 | 2014-03-18 | Apple Inc. | Electronic devices with voice command and contextual data processing capabilities |
US10706373B2 (en) | 2011-06-03 | 2020-07-07 | Apple Inc. | Performing actions associated with task items that represent tasks to perform |
US10241752B2 (en) | 2011-09-30 | 2019-03-26 | Apple Inc. | Interface for a virtual digital assistant |
US10276170B2 (en) | 2010-01-18 | 2019-04-30 | Apple Inc. | Intelligent automated assistant |
US8682667B2 (en) | 2010-02-25 | 2014-03-25 | Apple Inc. | User profiling for selecting user specific voice input processing information |
US9262612B2 (en) | 2011-03-21 | 2016-02-16 | Apple Inc. | Device access using voice authentication |
US10057736B2 (en) | 2011-06-03 | 2018-08-21 | Apple Inc. | Active transport based notifications |
US10134385B2 (en) | 2012-03-02 | 2018-11-20 | Apple Inc. | Systems and methods for name pronunciation |
US10417037B2 (en) | 2012-05-15 | 2019-09-17 | Apple Inc. | Systems and methods for integrating third party services with a digital assistant |
US9721563B2 (en) | 2012-06-08 | 2017-08-01 | Apple Inc. | Name recognition system |
CN103677299A (en) * | 2012-09-12 | 2014-03-26 | 深圳市世纪光速信息技术有限公司 | Method and device for achievement of intelligent association in input method and terminal device |
US9547647B2 (en) | 2012-09-19 | 2017-01-17 | Apple Inc. | Voice-based media searching |
CN104969289B (en) | 2013-02-07 | 2021-05-28 | 苹果公司 | Voice trigger of digital assistant |
US10652394B2 (en) | 2013-03-14 | 2020-05-12 | Apple Inc. | System and method for processing voicemail |
US10748529B1 (en) | 2013-03-15 | 2020-08-18 | Apple Inc. | Voice activated device for use with a voice-based digital assistant |
WO2014197334A2 (en) | 2013-06-07 | 2014-12-11 | Apple Inc. | System and method for user-specified pronunciation of words for speech synthesis and recognition |
WO2014197335A1 (en) | 2013-06-08 | 2014-12-11 | Apple Inc. | Interpreting and acting upon commands that involve sharing information with remote devices |
KR101959188B1 (en) | 2013-06-09 | 2019-07-02 | 애플 인크. | Device, method, and graphical user interface for enabling conversation persistence across two or more instances of a digital assistant |
US10176167B2 (en) | 2013-06-09 | 2019-01-08 | Apple Inc. | System and method for inferring user intent from speech inputs |
US9898187B2 (en) | 2013-06-09 | 2018-02-20 | Apple Inc. | Managing real-time handwriting recognition |
US10928924B2 (en) * | 2013-11-26 | 2021-02-23 | Lenovo (Singapore) Pte. Ltd. | Typing feedback derived from sensor information |
US10296160B2 (en) | 2013-12-06 | 2019-05-21 | Apple Inc. | Method for extracting salient dialog usage from live data |
US10170123B2 (en) | 2014-05-30 | 2019-01-01 | Apple Inc. | Intelligent assistant for home automation |
US9430463B2 (en) | 2014-05-30 | 2016-08-30 | Apple Inc. | Exemplar-based natural language processing |
US9633004B2 (en) | 2014-05-30 | 2017-04-25 | Apple Inc. | Better resolution when referencing to concepts |
US9966065B2 (en) | 2014-05-30 | 2018-05-08 | Apple Inc. | Multi-command single utterance input method |
US9715875B2 (en) | 2014-05-30 | 2017-07-25 | Apple Inc. | Reducing the need for manual start/end-pointing and trigger phrases |
US9785630B2 (en) * | 2014-05-30 | 2017-10-10 | Apple Inc. | Text prediction using combined word N-gram and unigram language models |
US9338493B2 (en) | 2014-06-30 | 2016-05-10 | Apple Inc. | Intelligent automated assistant for TV user interactions |
US9818400B2 (en) | 2014-09-11 | 2017-11-14 | Apple Inc. | Method and apparatus for discovering trending terms in speech requests |
US10074360B2 (en) | 2014-09-30 | 2018-09-11 | Apple Inc. | Providing an indication of the suitability of speech recognition |
US9668121B2 (en) | 2014-09-30 | 2017-05-30 | Apple Inc. | Social reminders |
US10127911B2 (en) | 2014-09-30 | 2018-11-13 | Apple Inc. | Speaker identification and unsupervised speaker adaptation techniques |
US10152299B2 (en) | 2015-03-06 | 2018-12-11 | Apple Inc. | Reducing response latency of intelligent automated assistants |
US9721566B2 (en) | 2015-03-08 | 2017-08-01 | Apple Inc. | Competing devices responding to voice triggers |
US9886953B2 (en) | 2015-03-08 | 2018-02-06 | Apple Inc. | Virtual assistant activation |
US10567477B2 (en) | 2015-03-08 | 2020-02-18 | Apple Inc. | Virtual assistant continuity |
US10460227B2 (en) | 2015-05-15 | 2019-10-29 | Apple Inc. | Virtual assistant in a communication session |
US10200824B2 (en) | 2015-05-27 | 2019-02-05 | Apple Inc. | Systems and methods for proactively identifying and surfacing relevant content on a touch-sensitive device |
US10009341B1 (en) * | 2015-05-27 | 2018-06-26 | Assa Abloy Ab | External keyboard with OTP capability |
US10083688B2 (en) | 2015-05-27 | 2018-09-25 | Apple Inc. | Device voice control for selecting a displayed affordance |
US9578173B2 (en) | 2015-06-05 | 2017-02-21 | Apple Inc. | Virtual assistant aided communication with 3rd party service in a communication session |
US11025565B2 (en) | 2015-06-07 | 2021-06-01 | Apple Inc. | Personalized prediction of responses for instant messaging |
US20160378747A1 (en) | 2015-06-29 | 2016-12-29 | Apple Inc. | Virtual assistant for media playback |
US10740384B2 (en) | 2015-09-08 | 2020-08-11 | Apple Inc. | Intelligent automated assistant for media search and playback |
US10671428B2 (en) | 2015-09-08 | 2020-06-02 | Apple Inc. | Distributed personal assistant |
US10747498B2 (en) | 2015-09-08 | 2020-08-18 | Apple Inc. | Zero latency digital assistant |
US10331312B2 (en) | 2015-09-08 | 2019-06-25 | Apple Inc. | Intelligent automated assistant in a media environment |
US10691473B2 (en) | 2015-11-06 | 2020-06-23 | Apple Inc. | Intelligent automated assistant in a messaging environment |
US10956666B2 (en) | 2015-11-09 | 2021-03-23 | Apple Inc. | Unconventional virtual assistant interactions |
US10049668B2 (en) | 2015-12-02 | 2018-08-14 | Apple Inc. | Applying neural network language models to weighted finite state transducers for automatic speech recognition |
US10223066B2 (en) | 2015-12-23 | 2019-03-05 | Apple Inc. | Proactive assistance based on dialog communication between devices |
US11227589B2 (en) | 2016-06-06 | 2022-01-18 | Apple Inc. | Intelligent list reading |
US10049663B2 (en) | 2016-06-08 | 2018-08-14 | Apple, Inc. | Intelligent automated assistant for media exploration |
US10509862B2 (en) * | 2016-06-10 | 2019-12-17 | Apple Inc. | Dynamic phrase expansion of language input |
US10586535B2 (en) | 2016-06-10 | 2020-03-10 | Apple Inc. | Intelligent digital assistant in a multi-tasking environment |
US10067938B2 (en) | 2016-06-10 | 2018-09-04 | Apple Inc. | Multilingual word prediction |
DK179415B1 (en) | 2016-06-11 | 2018-06-14 | Apple Inc | Intelligent device arbitration and control |
DK201670540A1 (en) | 2016-06-11 | 2018-01-08 | Apple Inc | Application integration with a digital assistant |
DK179329B1 (en) * | 2016-06-12 | 2018-05-07 | Apple Inc | Handwriting keyboard for monitors |
US20180039608A1 (en) * | 2016-08-03 | 2018-02-08 | Google Inc. | Correction of previously received textual messages based on one or more later received textual messages |
US10474753B2 (en) | 2016-09-07 | 2019-11-12 | Apple Inc. | Language identification using recurrent neural networks |
KR101791929B1 (en) * | 2016-09-23 | 2017-10-31 | (주)신성이노테크 | Integrated keyboard for inputting multiple languages |
US10043516B2 (en) | 2016-09-23 | 2018-08-07 | Apple Inc. | Intelligent automated assistant |
US10884610B2 (en) | 2016-11-04 | 2021-01-05 | Myscript | System and method for recognizing handwritten stroke input |
US11281993B2 (en) | 2016-12-05 | 2022-03-22 | Apple Inc. | Model and ensemble compression for metric learning |
US10546063B2 (en) * | 2016-12-13 | 2020-01-28 | International Business Machines Corporation | Processing of string inputs utilizing machine learning |
US10061435B2 (en) * | 2016-12-16 | 2018-08-28 | Nanning Fugui Precision Industrial Co., Ltd. | Handheld device with one-handed input and input method |
US10593346B2 (en) | 2016-12-22 | 2020-03-17 | Apple Inc. | Rank-reduced token representation for automatic speech recognition |
US11204787B2 (en) | 2017-01-09 | 2021-12-21 | Apple Inc. | Application integration with a digital assistant |
US10318632B2 (en) | 2017-03-14 | 2019-06-11 | Microsoft Technology Licensing, Llc | Multi-lingual data input system |
CN107145242B (en) * | 2017-03-24 | 2020-09-29 | 北京百度网讯科技有限公司 | Method, device and equipment for displaying error-correcting words and storage medium |
US10417266B2 (en) | 2017-05-09 | 2019-09-17 | Apple Inc. | Context-aware ranking of intelligent response suggestions |
DK201770383A1 (en) | 2017-05-09 | 2018-12-14 | Apple Inc. | User interface for correcting recognition errors |
US10395654B2 (en) | 2017-05-11 | 2019-08-27 | Apple Inc. | Text normalization based on a data-driven learning network |
DK201770439A1 (en) | 2017-05-11 | 2018-12-13 | Apple Inc. | Offline personal assistant |
DK180048B1 (en) | 2017-05-11 | 2020-02-04 | Apple Inc. | MAINTAINING THE DATA PROTECTION OF PERSONAL INFORMATION |
US10726832B2 (en) | 2017-05-11 | 2020-07-28 | Apple Inc. | Maintaining privacy of personal information |
DK179745B1 (en) | 2017-05-12 | 2019-05-01 | Apple Inc. | SYNCHRONIZATION AND TASK DELEGATION OF A DIGITAL ASSISTANT |
US11301477B2 (en) | 2017-05-12 | 2022-04-12 | Apple Inc. | Feedback analysis of a digital assistant |
DK179496B1 (en) | 2017-05-12 | 2019-01-15 | Apple Inc. | USER-SPECIFIC Acoustic Models |
DK201770427A1 (en) | 2017-05-12 | 2018-12-20 | Apple Inc. | Low-latency intelligent automated assistant |
DK201770431A1 (en) | 2017-05-15 | 2018-12-20 | Apple Inc. | Optimizing dialogue policy decisions for digital assistants using implicit feedback |
DK201770432A1 (en) | 2017-05-15 | 2018-12-21 | Apple Inc. | Hierarchical belief states for digital assistants |
US10311144B2 (en) | 2017-05-16 | 2019-06-04 | Apple Inc. | Emoji word sense disambiguation |
US20180336892A1 (en) | 2017-05-16 | 2018-11-22 | Apple Inc. | Detecting a trigger of a digital assistant |
DK179560B1 (en) | 2017-05-16 | 2019-02-18 | Apple Inc. | Far-field extension for digital assistant services |
US10403278B2 (en) | 2017-05-16 | 2019-09-03 | Apple Inc. | Methods and systems for phonetic matching in digital assistant services |
US10303715B2 (en) | 2017-05-16 | 2019-05-28 | Apple Inc. | Intelligent automated assistant for media exploration |
US10324537B2 (en) * | 2017-05-31 | 2019-06-18 | John Park | Multi-language keyboard system |
US10657328B2 (en) | 2017-06-02 | 2020-05-19 | Apple Inc. | Multi-task recurrent neural network architecture for efficient morphology handling in neural language modeling |
US10445429B2 (en) | 2017-09-21 | 2019-10-15 | Apple Inc. | Natural language understanding using vocabularies with compressed serialized tries |
US10755051B2 (en) | 2017-09-29 | 2020-08-25 | Apple Inc. | Rule-based natural language processing |
US10636424B2 (en) | 2017-11-30 | 2020-04-28 | Apple Inc. | Multi-turn canned dialog |
US10733982B2 (en) | 2018-01-08 | 2020-08-04 | Apple Inc. | Multi-directional dialog |
US10733375B2 (en) | 2018-01-31 | 2020-08-04 | Apple Inc. | Knowledge-based framework for improving natural language understanding |
US10789959B2 (en) | 2018-03-02 | 2020-09-29 | Apple Inc. | Training speaker recognition models for digital assistants |
US10592604B2 (en) | 2018-03-12 | 2020-03-17 | Apple Inc. | Inverse text normalization for automatic speech recognition |
US10818288B2 (en) | 2018-03-26 | 2020-10-27 | Apple Inc. | Natural assistant interaction |
US10909331B2 (en) | 2018-03-30 | 2021-02-02 | Apple Inc. | Implicit identification of translation payload with neural machine translation |
US11145294B2 (en) | 2018-05-07 | 2021-10-12 | Apple Inc. | Intelligent automated assistant for delivering content from user experiences |
US10928918B2 (en) | 2018-05-07 | 2021-02-23 | Apple Inc. | Raise to speak |
US10984780B2 (en) | 2018-05-21 | 2021-04-20 | Apple Inc. | Global semantic word embeddings using bi-directional recurrent neural networks |
DK179822B1 (en) | 2018-06-01 | 2019-07-12 | Apple Inc. | Voice interaction at a primary device to access call functionality of a companion device |
DK180639B1 (en) | 2018-06-01 | 2021-11-04 | Apple Inc | DISABILITY OF ATTENTION-ATTENTIVE VIRTUAL ASSISTANT |
US10892996B2 (en) | 2018-06-01 | 2021-01-12 | Apple Inc. | Variable latency device coordination |
DK201870355A1 (en) | 2018-06-01 | 2019-12-16 | Apple Inc. | Virtual assistant operation in multi-device environments |
US11386266B2 (en) | 2018-06-01 | 2022-07-12 | Apple Inc. | Text correction |
US10496705B1 (en) | 2018-06-03 | 2019-12-03 | Apple Inc. | Accelerated task performance |
US11010561B2 (en) | 2018-09-27 | 2021-05-18 | Apple Inc. | Sentiment prediction from textual data |
US10839159B2 (en) | 2018-09-28 | 2020-11-17 | Apple Inc. | Named entity normalization in a spoken dialog system |
US11170166B2 (en) | 2018-09-28 | 2021-11-09 | Apple Inc. | Neural typographical error modeling via generative adversarial networks |
US11462215B2 (en) | 2018-09-28 | 2022-10-04 | Apple Inc. | Multi-modal inputs for voice commands |
US11475898B2 (en) | 2018-10-26 | 2022-10-18 | Apple Inc. | Low-latency multi-speaker speech recognition |
US11638059B2 (en) | 2019-01-04 | 2023-04-25 | Apple Inc. | Content playback on multiple devices |
US11348573B2 (en) | 2019-03-18 | 2022-05-31 | Apple Inc. | Multimodality in digital assistant systems |
US11423908B2 (en) | 2019-05-06 | 2022-08-23 | Apple Inc. | Interpreting spoken requests |
US11475884B2 (en) | 2019-05-06 | 2022-10-18 | Apple Inc. | Reducing digital assistant latency when a language is incorrectly determined |
US11307752B2 (en) | 2019-05-06 | 2022-04-19 | Apple Inc. | User configurable task triggers |
DK201970509A1 (en) | 2019-05-06 | 2021-01-15 | Apple Inc | Spoken notifications |
US11140099B2 (en) | 2019-05-21 | 2021-10-05 | Apple Inc. | Providing message response suggestions |
US11496600B2 (en) | 2019-05-31 | 2022-11-08 | Apple Inc. | Remote execution of machine-learned models |
DK180129B1 (en) | 2019-05-31 | 2020-06-02 | Apple Inc. | User activity shortcut suggestions |
US11289073B2 (en) | 2019-05-31 | 2022-03-29 | Apple Inc. | Device text to speech |
DK201970510A1 (en) | 2019-05-31 | 2021-02-11 | Apple Inc | Voice identification in digital assistant systems |
US11360641B2 (en) | 2019-06-01 | 2022-06-14 | Apple Inc. | Increasing the relevance of new available information |
US11227599B2 (en) | 2019-06-01 | 2022-01-18 | Apple Inc. | Methods and user interfaces for voice-based control of electronic devices |
US11194467B2 (en) | 2019-06-01 | 2021-12-07 | Apple Inc. | Keyboard management user interfaces |
US11488406B2 (en) | 2019-09-25 | 2022-11-01 | Apple Inc. | Text detection using global geometry estimators |
US11043220B1 (en) | 2020-05-11 | 2021-06-22 | Apple Inc. | Digital assistant hardware abstraction |
US11061543B1 (en) | 2020-05-11 | 2021-07-13 | Apple Inc. | Providing relevant data items based on context |
US11490204B2 (en) | 2020-07-20 | 2022-11-01 | Apple Inc. | Multi-device audio adjustment coordination |
US11438683B2 (en) | 2020-07-21 | 2022-09-06 | Apple Inc. | User identification using headphones |
CN113743409A (en) * | 2020-08-28 | 2021-12-03 | 北京沃东天骏信息技术有限公司 | Text recognition method and device |
US11347323B2 (en) * | 2021-06-10 | 2022-05-31 | Baidu International Technology (Shenzhen) Co., Ltd. | Method for determining target key in virtual keyboard |
US20230206669A1 (en) * | 2021-12-28 | 2023-06-29 | Snap Inc. | On-device two step approximate string matching |
Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN101641661A (en) * | 2007-01-05 | 2010-02-03 | 苹果公司 | Method and system for providing word recommendations for text input |
CN101667099A (en) * | 2009-10-16 | 2010-03-10 | 神形互联有限公司 | Method for inputting stroke connection keyboard characters and device therefor |
CN101719022A (en) * | 2010-01-05 | 2010-06-02 | 汉王科技股份有限公司 | Character input method for all-purpose keyboard and processing device thereof |
US20120310626A1 (en) * | 2011-06-03 | 2012-12-06 | Yasuo Kida | Autocorrecting language input for virtual keyboards |
JP2012248153A (en) * | 2011-05-31 | 2012-12-13 | Kddi Corp | Character input device and program |
CN102937871A (en) * | 2011-09-12 | 2013-02-20 | 微软公司 | Soft keyboard interface |
Family Cites Families (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JPH10275046A (en) * | 1997-03-31 | 1998-10-13 | Toshiba Corp | Device and method for word input |
US7098896B2 (en) | 2003-01-16 | 2006-08-29 | Forword Input Inc. | System and method for continuous stroke word-based text input |
US20110063231A1 (en) * | 2009-09-14 | 2011-03-17 | Invotek, Inc. | Method and Device for Data Input |
GB201200643D0 (en) * | 2012-01-16 | 2012-02-29 | Touchtype Ltd | System and method for inputting text |
-
2013
- 2013-03-15 CN CN201380076553.9A patent/CN105431809B/en active Active
- 2013-03-15 JP JP2015561894A patent/JP6151381B2/en active Active
- 2013-03-15 WO PCT/CN2013/072755 patent/WO2014139173A1/en active Application Filing
- 2013-03-15 US US14/775,978 patent/US10073536B2/en active Active
- 2013-03-15 KR KR1020157029527A patent/KR102078785B1/en active IP Right Grant
Patent Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN101641661A (en) * | 2007-01-05 | 2010-02-03 | 苹果公司 | Method and system for providing word recommendations for text input |
CN101667099A (en) * | 2009-10-16 | 2010-03-10 | 神形互联有限公司 | Method for inputting stroke connection keyboard characters and device therefor |
CN101719022A (en) * | 2010-01-05 | 2010-06-02 | 汉王科技股份有限公司 | Character input method for all-purpose keyboard and processing device thereof |
JP2012248153A (en) * | 2011-05-31 | 2012-12-13 | Kddi Corp | Character input device and program |
US20120310626A1 (en) * | 2011-06-03 | 2012-12-06 | Yasuo Kida | Autocorrecting language input for virtual keyboards |
CN102937871A (en) * | 2011-09-12 | 2013-02-20 | 微软公司 | Soft keyboard interface |
Cited By (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN108475157A (en) * | 2016-03-25 | 2018-08-31 | 华为技术有限公司 | Characters input method, device and terminal |
CN108701123A (en) * | 2016-04-04 | 2018-10-23 | 谷歌有限责任公司 | The dynamic key of graphic keyboard maps |
CN108701124A (en) * | 2016-05-17 | 2018-10-23 | 谷歌有限责任公司 | It predicts next letter and shows them in the key of graphic keyboard |
CN107817942A (en) * | 2016-09-14 | 2018-03-20 | 北京搜狗科技发展有限公司 | A kind of slide input method, system and a kind of device for being used to slide input |
CN110888577A (en) * | 2018-09-10 | 2020-03-17 | 百度在线网络技术（北京）有限公司 | Character correction method, device, equipment and storage medium |
US10929014B2 (en) | 2018-09-10 | 2021-02-23 | Baidu Online Network Technology (Beijing) Co., Ltd. | Character correction method and apparatus, device, and storage medium |
CN113227946A (en) * | 2018-11-03 | 2021-08-06 | 宗刚 | Alphabetic writing input method |
Also Published As
Publication number | Publication date |
---|---|
KR102078785B1 (en) | 2020-02-19 |
KR20150131299A (en) | 2015-11-24 |
JP6151381B2 (en) | 2017-06-21 |
US10073536B2 (en) | 2018-09-11 |
US20160026258A1 (en) | 2016-01-28 |
JP2016509456A (en) | 2016-03-24 |
CN105431809B (en) | 2018-12-18 |
WO2014139173A1 (en) | 2014-09-18 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN105431809A (en) | Virtual keyboard input for international languages | |
US10489508B2 (en) | Incremental multi-word recognition | |
US20210132792A1 (en) | System and method for inputting text into electronic devices | |
US9798393B2 (en) | Text correction processing | |
US9026428B2 (en) | Text/character input system, such as for use with touch screens on mobile phones | |
US9841895B2 (en) | Alternative hypothesis error correction for gesture typing | |
US9471220B2 (en) | Posture-adaptive selection | |
US9552080B2 (en) | Incremental feature-based gesture-keyboard decoding | |
US10445424B2 (en) | System and method for inputting text into electronic devices | |
KR101484583B1 (en) | Gesture keyboard input of non-dictionary character strings using substitute scoring | |
JP2014147063A (en) | Text input method and apparatus | |
CN105074643A (en) | Gesture keyboard input of non-dictionary character strings | |
US9298276B1 (en) | Word prediction for numbers and symbols |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
C06 | Publication | ||
PB01 | Publication | ||
C10 | Entry into substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
CB02 | Change of applicant information | ||
CB02 | Change of applicant information |
Address after: American CaliforniaApplicant after: Google limited liability companyAddress before: American CaliforniaApplicant before: Google Inc. |
|
GR01 | Patent grant | ||
GR01 | Patent grant |