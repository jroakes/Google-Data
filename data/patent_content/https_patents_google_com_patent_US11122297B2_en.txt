US11122297B2 - Using border-aligned block functions for image compression - Google Patents
Using border-aligned block functions for image compression Download PDFInfo
- Publication number
- US11122297B2 US11122297B2 US16/402,297 US201916402297A US11122297B2 US 11122297 B2 US11122297 B2 US 11122297B2 US 201916402297 A US201916402297 A US 201916402297A US 11122297 B2 US11122297 B2 US 11122297B2
- Authority
- US
- United States
- Prior art keywords
- block
- basis functions
- border
- transform
- compressed bitstream
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/60—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using transform coding
- H04N19/625—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using transform coding using discrete cosine transform [DCT]
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/12—Selection from among a plurality of transforms or standards, e.g. selection between discrete cosine transform [DCT] and sub-band transform or selection between H.263 and H.264
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/103—Selection of coding mode or of prediction mode
- H04N19/105—Selection of the reference unit for prediction within a chosen coding or prediction mode, e.g. adaptive choice of position and number of pixels used for prediction
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/134—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or criterion affecting or controlling the adaptive coding
- H04N19/136—Incoming video signal characteristics or properties
- H04N19/14—Coding unit complexity, e.g. amount of activity or edge presence estimation
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/169—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding
- H04N19/17—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding the unit being an image region, e.g. an object
- H04N19/176—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding the unit being an image region, e.g. an object the region being a block, e.g. a macroblock
Definitions
- Image content (e.g., still images or frames of video) represents a significant amount of online content.
- a web page may include multiple images, and a large portion of the time and resources spent rendering the web page are dedicated to rendering those images for display.
- the amount of time and resources required to receive and render an image for display depends in part on the manner in which the image is compressed. As such, an image can be rendered faster by reducing the total data size of the image using lossy compression and decompression techniques.
- Lossy compression techniques seek to represent image content using fewer bits than the number of bits in the original image. Lossy compression techniques can introduce visual artefacts, such as ringing artefacts, into the decompressed image. Higher compression levels can result in more observable ringing artefacts. It is desirable to minimize the ringing artefacts while maintaining high levels of compression.
- One aspect of this disclosure is a method for encoding a block of a frame.
- the method includes receiving the block that is in the spatial domain; selecting, based on a border that crosses the block, a set of basis functions for transforming the block to a transform domain; transforming the block using the set of basis functions to obtain a transform block; encoding, in a compressed bitstream, an indication of the set of basis functions; and encoding, in the compressed bitstream, the transform block.
- the apparatus includes a processor and a memory.
- the memory includes instructions executable by the processor to receive the block, which is in the spatial domain; select, based on a shape that partitions the block, a set of basis functions for transforming the block to a transform domain; transform the block using the set of basis functions to obtain a transform block; encode, in a compressed bitstream, an indication of the set of basis functions; and encode, in the compressed bitstream, the transform block.
- the apparatus includes a processor and a memory.
- the memory includes instructions executable by the processor to decode, from a compressed bitstream, an indication of a set of basis functions for inverse transforming the block, where the block includes a shape, the set of basis functions corresponds to the shape; and the set of basis functions corresponds to eigenfunctions of a graph Laplacian that is formed based on the shape; decode, from the compressed bitstream, a transform block; and inverse-transform the transform block using the set of basis functions to obtain the block.
- FIG. 1 is a diagram of a computing device in accordance with implementations of this disclosure.
- FIG. 2 is a diagram of a computing and communications system in accordance with implementations of this disclosure.
- FIG. 3 is a diagram of a video stream for use in encoding and decoding in accordance with implementations of this disclosure.
- FIG. 4 is a block diagram of an encoder in accordance with implementations of this disclosure.
- FIG. 5 is a block diagram of a decoder in accordance with implementations of this disclosure.
- FIG. 6 illustrates the DCT-II basis functions that are used in JPEG image compression.
- FIG. 7 illustrates an example of generating basis functions for a given border line according to implementations of this disclosure.
- FIG. 8 illustrates an example of lines crossing a block at different angles according to implementations of this disclosure.
- FIG. 9 illustrates an example of lines crossing a block at different translational shifts according to implementations of this disclosure.
- FIG. 10 is an example of borders crossing a block according to implementation of this disclosure.
- FIGS. 11A-11D are examples of sets of basis functions according to an implementation of this disclosure.
- FIG. 12 is an example of equivalent function sets according to implementations of this disclosure.
- FIG. 13 is an example of canonical sets of function sets according to implementations of this disclosure.
- FIG. 14 is an example of a flowchart diagram of a process for encoding a block of a frame according to an implementation of this disclosure.
- FIG. 15 is an example of a flowchart diagram of a process for decoding a block of a frame according to an implementation of this disclosure.
- FIG. 16 is an example of an interleaved tower of eigenvalues according to implementations of this disclosure.
- Lossy compression can be used to code visual information of an image.
- a lossy compression technique can be applied to a source image to produce a compressed image.
- the inverse of the lossy technique can be applied to the compressed image to produce a decompressed image.
- the lossy aspect of a lossy compression technique can be attributed, at least partially, to the quantizing of frequency domain information (as further described below).
- Lossy compression aims to describe (i.e., code, compress, etc.) an image with the least number of bits while preserving, as much as possible, the quality of the image when the compressed image is decompressed. That is, lossy compression techniques seek to compress an image without degrading the quality of the image beyond an unacceptable level that would be perceivable, for example, by the human eye.
- the blocks can be of size 8 ⁇ 8. However, other sizes are possible.
- the image data (which can also be referred to as the pixel values, the pixel domain data, or the spatial domain data) in each such block can then be re-expressed in a function basis that separates contributions with slow spatial variation from contributions with fast spatial variation.
- this new form (which can also be referred to as the frequency domain or the transform domain), it then becomes possible to perform visually lossless data reduction by discretizing spatial variations in a way that cannot be perceived by the human eye under normal viewing conditions of the image.
- a frequency-based transform such as the Discrete Cosine Transform (DCT) can be used to re-express (e.g., transform) the spatial domain data to the frequency domain.
- DCT Discrete Cosine Transform
- FIG. 6 which is further described below, illustrates the basis functions 600 of the DCT-II transform that are used in JPEG image compression.
- a shape (such as a sharp boundary, a line, a border, etc.) may partition one or more blocks of an image into distinct areas.
- a pole that casts a sharp shadow on a pavement can divide at least some blocks of the image into shadow areas and sunny areas.
- a wall that blocks a view of the sky in an image divides at least one block of the image into a portion that includes a portion of the wall and another portion that includes a portion of the sky.
- Such ‘occlusion boundaries’ are a very common phenomenon in images.
- Ringing artefacts can result from compressing high frequency signals. Ringing artefacts may appear as bands and/or ghosts near edges of objects in a decompressed image. The ringing artefacts are due to undershoots and overshoots around edges. “Undershoot” means that a value of a pixel in the decompressed image is less than the value of the same pixel in the source image. That is, “undershoot” can mean that pixels around the edges (e.g., the borders or edges of shapes that partition a block) are de-emphasized. “Overshoot” means that a value of a pixel in the decompressed image is greater than the value of the same pixel in the source image. That is, “overshoot” can mean that some pixels around the edges are accentuated. That is, as a result of the lossy compression, some parts of a bright (dark) background can become even brighter (darker) in the decompressed image.
- Overshoots and undershoots can result from frequency-domain sinc-type oscillations. For example, in an image that includes a bright (dark) background that is partially occluded by a dark (bright) foreground object, a step-like function exists at the edge of the background and the foreground object. If the edge is compressed based on a frequency-based transform, increased levels of quantization result in the sinc-type oscillations at the proximity of the edge due to the frequency-limiting properties of quantization. As mentioned, undershoots and overshoots can be observed around edges.
- Implementations according to this disclosure can reduce ringing and other artefacts attributable to shapes, such as a sharp straight boundary, running through image blocks.
- Described herein is a scheme for coding (encoding and decoding) spatial variations for an image block that includes a shape (e.g., a sharp straight boundary) running through the image block. Additionally, the scheme described herein results in the selection of a set of basis functions so that bits (e.g., for additional transform coefficients) are not expended to suppress ringing in a part of a block.
- the scheme described herein selects, for transforming a block, a set of basis functions such that the set of basis functions is based on the shape that runs through the block.
- a line e.g., an edge, a border
- the disclosure herein is not limited to shapes that are lines.
- a set of candidate sets of basis functions can be available.
- a candidate set of basis functions is simply referred to as “candidate functions” or “a candidate set.”
- a candidate set is selected for encoding a block.
- the candidate set that is selected can depend on the direction of the border that crosses the block, where the border crosses the block, or a combination thereof.
- a first candidate set can be related (and derived from) a second candidate set using at least one of rotation, mirroring, or similar operations.
- a “set of basis functions” is also referred to as a “function-set” or a “function set.”
- FIG. 1 is a diagram of a computing device 100 (e.g., an apparatus) in accordance with implementations of this disclosure.
- the computing device 100 shown includes a memory 110 , a processor 120 , a user interface (UI) 130 , an electronic communication unit 140 , a sensor 150 , a power source 160 , and a bus 170 .
- UI user interface
- the term “computing device” includes any unit, or combination of units, capable of performing any method, or any portion or portions thereof, disclosed herein.
- the computing device 100 may be a stationary computing device, such as a personal computer (PC), a server, a workstation, a minicomputer, or a mainframe computer; or a mobile computing device, such as a mobile telephone, a personal digital assistant (PDA), a laptop, or a tablet PC.
- PC personal computer
- PDA personal digital assistant
- the user interface 130 and processor 120 can be integrated in a first physical unit
- the memory 110 can be integrated in a second physical unit.
- the memory 110 can include any non-transitory computer-usable or computer-readable medium, such as any tangible device that can, for example, contain, store, communicate, or transport data 112 , instructions 114 , an operating system 116 , or any information associated therewith, for use by or in connection with other components of the computing device 100 .
- the non-transitory computer-usable or computer-readable medium can be, for example, a solid state drive, a memory card, removable media, a read-only memory (ROM), a random-access memory (RAM), any type of disk including a hard disk, a floppy disk, an optical disk, a magnetic or optical card, an application-specific integrated circuit (ASIC), or any type of non-transitory media suitable for storing electronic information, or any combination thereof.
- ROM read-only memory
- RAM random-access memory
- ASIC application-specific integrated circuit
- the memory 110 may include multiple physical units, such as one or more primary memory units, such as random-access memory units, one or more secondary data storage units, such as disks, or a combination thereof.
- the data 112 , or a portion thereof, the instructions 114 , or a portion thereof, or both may be stored in a secondary storage unit and may be loaded or otherwise transferred to a primary storage unit in conjunction with processing the respective data 112 , executing the respective instructions 114 , or both.
- the memory 110 or a portion thereof, may be removable memory.
- the data 112 can include information, such as input audio and/or visual data, encoded audio and/or visual data, decoded audio and/or visual data, or the like.
- the visual data can include still images, frames of video sequences, and/or video sequences.
- the instructions 114 can include directions, such as code, for performing any method, or any portion or portions thereof, disclosed herein.
- the instructions 114 can be realized in hardware, software, or any combination thereof.
- the instructions 114 may be implemented as information stored in the memory 110 , such as a computer program, that may be executed by the processor 120 to perform any of the respective methods, algorithms, aspects, or combinations thereof, as described herein.
- the instructions 114 may be implemented as a special-purpose processor, or circuitry, that can include specialized hardware for carrying out any of the methods, algorithms, aspects, or combinations thereof, as described herein. Portions of the instructions 114 can be distributed across multiple processors on the same machine or different machines or across a network, such as a local area network, a wide area network, the Internet, or a combination thereof.
- the processor 120 can include any device or system, now-existing or hereafter developed, capable of manipulating or processing a digital signal or other electronic information, including optical processors, quantum processors, molecular processors, or a combination thereof.
- the processor 120 can include a special-purpose processor, a central processing unit (CPU), a digital signal processor (DSP), a plurality of microprocessors, one or more microprocessors in association with a DSP core, a controller, a microcontroller, an Application Specific Integrated Circuit (ASIC), a Field Programmable Gate Array (FPGA), a programmable logic array, a programmable logic controller, microcode, firmware, any type of integrated circuit (IC), a state machine, or any combination thereof.
- the term “processor” includes a single processor or multiple processors.
- the user interface 130 can include any unit capable of interfacing with a user, such as a virtual or physical keypad, a touchpad, a display, a touch display, a speaker, a microphone, a video camera, a sensor, or any combination thereof.
- the user interface 130 may be an audio-visual display device, and the computing device 100 may present audio, such as decoded audio, using the user interface 130 audio-visual display device, such as in conjunction with displaying video, such as decoded video.
- the user interface 130 may include one or more physical units.
- the user interface 130 may include an audio interface for performing audio communication with a user, and a touch display for performing visual and touch-based communication with the user.
- the electronic communication unit 140 can transmit, receive, or transmit and receive signals via a wired or wireless electronic communication medium 180 , such as a radio frequency (RF) communication medium, an ultraviolet (UV) communication medium, a visible light communication medium, a fiber-optic communication medium, a wireline communication medium, or a combination thereof.
- a wired or wireless electronic communication medium 180 such as a radio frequency (RF) communication medium, an ultraviolet (UV) communication medium, a visible light communication medium, a fiber-optic communication medium, a wireline communication medium, or a combination thereof.
- RF radio frequency
- UV ultraviolet
- the electronic communication interface 142 is shown as a wireless antenna in FIG. 1
- the electronic communication interface 142 can be a wireless antenna, as shown, a wired communication port, such as an Ethernet port, an infrared port, a serial port, or any other wired or wireless unit capable of interfacing with a wired or wireless electronic communication medium 180 .
- FIG. 1 shows a single electronic communication unit 140 and a single electronic communication interface 142 , any number of electronic communication units and any number of electronic communication interfaces can be used.
- the sensor 150 may include, for example, an audio-sensing device, a visible light-sensing device, a motion-sensing device, or a combination thereof.
- the sensor 150 may include a sound-sensing device, such as a microphone, or any other sound-sensing device, now existing or hereafter developed, that can sense sounds in the proximity of the computing device 100 , such as speech or other utterances, made by a user operating the computing device 100 .
- the sensor 150 may include a camera, or any other image-sensing device, now existing or hereafter developed, that can sense an image, such as the image of a user operating the computing device.
- the computing device 100 may include a number of sensors 150 .
- the computing device 100 may include a first camera oriented with a field of view directed toward a user of the computing device 100 and a second camera oriented with a field of view directed away from the user of the computing device 100 .
- the power source 160 can be any suitable device for powering the computing device 100 .
- the power source 160 can include a wired external power source interface; one or more dry cell batteries, such as nickel-cadmium (NiCd), nickel-zinc (NiZn), nickel metal hydride (NiMH), lithium-ion (Li-ion); solar cells; fuel cells; or any other device capable of powering the computing device 100 .
- dry cell batteries such as nickel-cadmium (NiCd), nickel-zinc (NiZn), nickel metal hydride (NiMH), lithium-ion (Li-ion); solar cells; fuel cells; or any other device capable of powering the computing device 100 .
- a single power source 160 is shown in FIG. 1
- the computing device 100 may include multiple power sources 160 , such as a battery and a wired external power source interface.
- the electronic communication unit 140 , the electronic communication interface 142 , the user interface 130 , the power source 160 , or portions thereof, may be configured as a combined unit.
- the electronic communication unit 140 , the electronic communication interface 142 , the user interface 130 , and the power source 160 may be implemented as a communications port capable of interfacing with an external display device, providing communications, power, or both.
- One or more of the memory 110 , the processor 120 , the user interface 130 , the electronic communication unit 140 , the sensor 150 , or the power source 160 may be operatively coupled via a bus 170 .
- a bus 170 may include multiple buses.
- the memory 110 , the processor 120 , the user interface 130 , the electronic communication unit 140 , the sensor 150 , and the bus 170 may receive power from the power source 160 via the bus 170 .
- the memory 110 , the processor 120 , the user interface 130 , the electronic communication unit 140 , the sensor 150 , the power source 160 , or a combination thereof may communicate data, such as by sending and receiving electronic signals, via the bus 170 .
- one or more of the processor 120 , the user interface 130 , the electronic communication unit 140 , the sensor 150 , or the power source 160 may include internal memory, such as an internal buffer or register.
- the processor 120 may include internal memory (not shown) and may read data 112 from the memory 110 into the internal memory (not shown) for processing.
- the memory 110 can be integrated in one or more electronic units, circuits, or chips.
- FIG. 2 is a diagram of a computing and communications system 200 in accordance with implementations of this disclosure.
- the computing and communications system 200 shown includes computing and communication devices 100 A, 100 B, 100 C, access points 210 A, 210 B, and a network 220 .
- the computing and communications system 200 can be a multiple access system that provides communication, such as voice, audio, data, video, messaging, broadcast, or a combination thereof, to one or more wired or wireless communicating devices, such as the computing and communication devices 100 A, 100 B, 100 C.
- FIG. 2 shows three computing and communication devices 100 A, 100 B, 100 C, two access points 210 A, 210 B, and one network 220 , any number of computing and communication devices, access points, and networks can be used.
- a computing and communication device 100 A, 100 B, or 100 C can be, for example, a computing device, such as the computing device 100 shown in FIG. 1 .
- the computing and communication devices 100 A, 100 B may be user devices, such as a mobile computing device, a laptop, a thin client, or a smartphone, and the computing and communication device 100 C may be a server, such as a mainframe or a cluster.
- the computing and communication device 100 A and the computing and communication device 100 B are described as user devices, and the computing and communication device 100 C is described as a server, any computing and communication device may perform some or all of the functions of a server, some or all of the functions of a user device, or some or all of the functions of a server and a user device.
- the server computing and communication device 100 C may receive, encode, process, store, transmit, or a combination thereof, audio data; and one or both of the computing and communication device 100 A and the computing and communication device 100 B may receive, decode, process, store, present, or a combination thereof, the audio data.
- Each computing and communication device 100 A, 100 B, 100 C which may include a user equipment (UE), a mobile station, a fixed or mobile subscriber unit, a cellular telephone, a personal computer, a tablet computer, a server, consumer electronics, or any similar device, can be configured to perform wired or wireless communication, such as via the network 220 .
- the computing and communication devices 100 A, 100 B, 100 C can be configured to transmit or receive wired or wireless communication signals.
- each computing and communication device 100 A, 100 B, 100 C is shown as a single unit, a computing and communication device can include any number of interconnected elements.
- Each access point 210 A, 210 B can be any type of device configured to communicate with a computing and communication devices 100 A, 100 B, 100 C, a network 220 , or both via wired or wireless communication links 180 A, 180 B, 180 C.
- an access point 210 A, 210 B can include a base station, a base transceiver station (BTS), a Node-B, an enhanced Node-B (eNode-B), a Home Node-B (HNode-B), a wireless router, a wired router, a hub, a relay, a switch, or any similar wired or wireless device.
- BTS base transceiver station
- eNode-B enhanced Node-B
- HNode-B Home Node-B
- a wireless router a wired router, a hub, a relay, a switch, or any similar wired or wireless device.
- each access point 210 A, 210 B is shown as a single unit, an access point can include any number of inter
- the network 220 can be any type of network configured to provide services, such as voice, data, applications, voice over internet protocol (VoIP), or any other communications protocol or combination of communications protocols, over a wired or wireless communication link.
- the network 220 can be a local area network (LAN), wide area network (WAN), virtual private network (VPN), a mobile or cellular telephone network, the Internet, or any other means of electronic communication.
- the network can use a communication protocol, such as the Transmission Control Protocol (TCP), the User Datagram Protocol (UDP), the Internet Protocol (IP), the Real-time Transport Protocol (RTP), the HyperText Transport Protocol (HTTP), or a combination thereof.
- TCP Transmission Control Protocol
- UDP User Datagram Protocol
- IP Internet Protocol
- RTP Real-time Transport Protocol
- HTTP HyperText Transport Protocol
- the computing and communication devices 100 A, 100 B, 100 C can communicate with each other via the network 220 using one or more wired or wireless communication links, or via a combination of wired and wireless communication links.
- the computing and communication devices 100 A, 100 B can communicate via wireless communication links 180 A, 180 B
- computing and communication device 100 C can communicate via a wired communication link 180 C.
- Any of the computing and communication devices 100 A, 100 B, 100 C may communicate using any wired or wireless communication link or links.
- a first computing and communication device 100 A can communicate via a first access point 210 A using a first type of communication link
- a second computing and communication device 100 B can communicate via a second access point 210 B using a second type of communication link
- a third computing and communication device 100 C can communicate via a third access point (not shown) using a third type of communication link.
- the access points 210 A, 210 B can communicate with the network 220 via one or more types of wired or wireless communication links 230 A, 230 B.
- FIG. 2 shows the computing and communication devices 100 A, 100 B, 100 C in communication via the network 220
- the computing and communication devices 100 A, 100 B, 100 C can communicate with each other via any number of communication links, such as a direct wired or wireless communication link.
- communications between one or more of the computing and communication devices 100 A, 100 B, 100 C may omit communicating via the network 220 and may include transferring data via another medium (not shown), such as a data storage device.
- the server computing and communication device 100 C may store audio data, such as encoded audio data, in a data storage device, such as a portable data storage unit, and one or both of the computing and communication device 100 A or the computing and communication device 100 B may access, read, or retrieve the stored audio data from the data storage unit, such as by physically disconnecting the data storage device from the server computing and communication device 100 C and physically connecting the data storage device to the computing and communication device 100 A or the computing and communication device 100 B.
- the network 220 can be an ad-hoc network and can omit one or more of the access points 210 A, 210 B.
- the computing and communications system 200 may include devices, units, or elements not shown in FIG. 2 .
- the computing and communications system 200 may include many more communicating devices, networks, and access points.
- FIG. 3 is a diagram of a video stream 300 for use in encoding and decoding in accordance with implementations of this disclosure.
- a video stream 300 such as a video stream captured by a video camera or a video stream generated by a computing device, may include a video sequence 310 .
- the video sequence 310 may include a sequence of adjacent frames 320 . Although three adjacent frames 320 are shown, the video sequence 310 can include any number of adjacent frames 320 .
- Each frame 330 from the adjacent frames 320 may represent a single image from the video stream.
- a frame 330 may include one or more segments, tiles, or planes, which may be coded, or otherwise processed, independently, such as in parallel.
- a frame 330 may include blocks 340 .
- a block can include pixels.
- a block can include a 16 ⁇ 16 group of pixels, an 8 ⁇ 8 group of pixels, an 8 ⁇ 16 group of pixels, or any other group of pixels.
- the term “block” can include a superblock, a macroblock, a segment, a slice, or any other portion of a frame.
- a frame, a block, a pixel, or a combination thereof can include display information, such as luminance information, chrominance information, or any other information that can be used to store, modify, communicate, or display the video stream or a portion thereof.
- a frame that is not part of a video stream is encoded and decoded in accordance with implementations of this disclosure.
- FIG. 4 is a block diagram of an encoder 400 in accordance with implementations of this disclosure.
- Encoder 400 can be implemented in a device, such as the computing device 100 shown in FIG. 1 or the computing and communication devices 100 A, 100 B, 100 C shown in FIG. 2 , as, for example, a computer software program stored in a data storage unit, such as the memory 110 shown in FIG. 1 .
- the computer software program can include machine-readable instructions that may be executed by a processor, such as the processor 120 shown in FIG. 1 , and may cause the device to encode video data as described herein.
- the encoder 400 can be implemented as specialized hardware included, for example, in the computing device 100 .
- the encoder 400 can encode an input video stream 402 , such as the video stream 300 shown in FIG. 3 , to generate an encoded (compressed) bitstream 404 .
- the encoder 400 may include a forward path for generating the compressed bitstream 404 .
- the input video stream 402 can be a single image or a collection of images.
- the forward path may include an intra/inter prediction unit 410 , a transform unit 420 , a quantization unit 430 , an entropy encoding unit 440 , or any combination thereof.
- the encoder 400 may include a reconstruction path (indicated by the broken connection lines) to reconstruct a frame for encoding of further blocks.
- the reconstruction path may include a dequantization unit 450 , an inverse transform unit 460 , a reconstruction unit 470 , a filtering unit 480 , or any combination thereof.
- Other structural variations of the encoder 400 can be used to encode the video stream 402 .
- each frame within the video stream 402 can be processed in units of blocks.
- a current block may be identified from the blocks in a frame, and the current block may be encoded.
- the current block can be encoded using either intra-frame prediction, which may be within a single frame, or inter-frame prediction, which may be from frame to frame.
- Intra-prediction may include generating a prediction block from samples in the current frame that have been previously encoded and reconstructed.
- Inter-prediction may include generating a prediction block from samples in one or more previously constructed reference frames.
- Generating a prediction block for a current block in a current frame may include performing motion estimation to generate a motion vector indicating an appropriate reference portion of the reference frame.
- the intra/inter prediction unit 410 can encode the image using intra-frame prediction.
- the intra/inter prediction unit 410 may subtract the prediction block from the current block (raw block) to produce a residual block.
- the transform unit 420 may perform a block-based transform, which may include transforming the residual block into transform coefficients in, for example, the frequency domain.
- block-based transforms include the Karhunen-Loève Transform (KLT), the Discrete Cosine Transform (DCT), the Singular Value Decomposition Transform (SVD), the Fourier transform (FT), the Discrete Sine Transform (DST), and the Asymmetric Discrete Sine Transform (ADST).
- the DCT may include transforming a block into the frequency domain.
- the DCT may include using transform coefficient values based on spatial frequency, with the lowest frequency (i.e., DC) coefficient at the top-left of the matrix and the highest frequency coefficient at the bottom-right of the matrix.
- the quantization unit 430 may convert the transform coefficients into discrete quantum values, which may be referred to as quantized transform coefficients or quantization levels.
- the quantized transform coefficients can be entropy encoded by the entropy encoding unit 440 to produce entropy-encoded coefficients.
- Entropy encoding can include using a probability distribution metric.
- the entropy-encoded coefficients and information used to decode the block, which may include the type of prediction used, motion vectors, and quantizer values, can be output to the compressed bitstream 404 .
- the compressed bitstream 404 can be formatted using various techniques, such as run-length encoding (RLE) and zero-run coding.
- the reconstruction path can be used to maintain reference frame synchronization between the encoder 400 and a corresponding decoder, such as the decoder 500 shown in FIG. 5 .
- the reconstruction path may be similar to the decoding process discussed below and may include decoding the encoded frame, or a portion thereof, which may include decoding an encoded block, which may include dequantizing the quantized transform coefficients at the dequantization unit 450 and inverse transforming the dequantized transform coefficients at the inverse transform unit 460 to produce a derivative residual block.
- the reconstruction unit 470 may add the prediction block generated by the intra/inter prediction unit 410 to the derivative residual block to create a decoded block.
- the filtering unit 480 can be applied to the decoded block to generate a reconstructed block, which may reduce distortion, such as blocking artefacts.
- filtering the decoded block may include loop filtering, deblocking filtering, or other types of filtering or combinations of types of filtering.
- the reconstructed block may be stored or otherwise made accessible as a reconstructed block, which may be a portion of a reference frame, for encoding another portion of the current frame, another frame, or both, as indicated by the broken line at 482 .
- Coding information, such as deblocking threshold index values, for the frame may be encoded, included in the compressed bitstream 404 , or both, as indicated by the broken line at 484 .
- encoder 400 can be used to encode the compressed bitstream 404 .
- a non-transform based encoder 400 can quantize the residual block directly without the transform unit 420 .
- the quantization unit 430 and the dequantization unit 450 may be combined into a single unit.
- FIG. 5 is a block diagram of a decoder 500 in accordance with implementations of this disclosure.
- the decoder 500 can be implemented in a device, such as the computing device 100 shown in FIG. 1 or the computing and communication devices 100 A, 100 B, 100 C shown in FIG. 2 , as, for example, a computer software program stored in a data storage unit, such as the memory 110 shown in FIG. 1 .
- the computer software program can include machine-readable instructions that may be executed by a processor, such as the processor 120 shown in FIG. 1 , and may cause the device to decode video data as described herein.
- the decoder 500 can be implemented as specialized hardware included, for example, in the computing device 100 .
- the decoder 500 may receive a compressed bitstream 502 , such as the compressed bitstream 404 shown in FIG. 4 , and may decode the compressed bitstream 502 to generate an output video stream 504 .
- the decoder 500 may include an entropy decoding unit 510 , a dequantization unit 520 , an inverse transform unit 530 , an intra/inter prediction unit 540 , a reconstruction unit 550 , a filtering unit 560 , or any combination thereof. Other structural variations of the decoder 500 can be used to decode the compressed bitstream 502 .
- the entropy decoding unit 510 may decode data elements within the compressed bitstream 502 using, for example, Context Adaptive Binary Arithmetic Decoding, to produce a set of quantized transform coefficients.
- the dequantization unit 520 can dequantize the quantized transform coefficients, and the inverse transform unit 530 can inverse transform the dequantized transform coefficients to produce a derivative residual block, which may correspond to the derivative residual block generated by the inverse transform unit 460 shown in FIG. 4 .
- the intra/inter prediction unit 540 may generate a prediction block corresponding to the prediction block created in the encoder 400 .
- the prediction block can be added to the derivative residual block to create a decoded block.
- the filtering unit 560 can be applied to the decoded block to reduce artefacts, such as blocking artefacts, which may include loop filtering, deblocking filtering, or other types of filtering or combinations of types of filtering, and which may include generating a reconstructed block, which may be output as the output video stream 504 .
- decoder 500 can be used to decode the compressed bitstream 502 .
- the decoder 500 can produce the output video stream 504 without the deblocking filtering unit 570 .
- FIG. 6 illustrates the basis functions 600 that are used in JPEG image compression.
- a transform block, T can be generated using the formula:
- T pq are the DCT (i.e., transform) coefficients of the block A.
- the very first basis function, a function 602 is a constant function. The function 602 , when multiplied by a coefficient value (also known as the DC coefficient), can be interpreted as the average brightness of that block.
- the other DCT basis functions of the basis functions 600 add corrections (positive or negative corrections) to the average value.
- basis functions 604 and 606 provide approximation (i.e., corrections) of the vertical brightness variation and horizontal brightness variation, respectively.
- Basis function 608 , 610 , 612 provide the next level of correction.
- the basis function 608 , 610 , 612 provide diagonal brightness variation as well as faster brightness variation that doesn't simply cycle from bright to dark over the width of one block or the height of one block, rather the brightness variation also cycles from bright to dark to bright again.
- the DCT transformation is premised on the fact that brightness for many images doesn't vary rapidly from pixel to pixel. As such, an image is not merely a random noise of brightness (i.e., unrelated pixel values); rather, there is assumed to be a strong correlation between the brightness of one pixel and the brightness of an adjacent pixel.
- the DCT basis functions take the correlation into account. Typically, smoother variations are retained, and the spatial fast variation are discarded. Fast spatial variations correspond to the high frequency components, which are toward the bottom and the right of the basis functions 600 .
- the basis functions 600 can be characterized as solutions to an eigenvalue problem; namely, the problem of finding eigenfunctions of a discretized Laplace operator given specific boundary conditions.
- the specific boundary conditions can be the “open” (i.e., Neumann) boundary conditions.
- Such an intuition can be used as the basis of the candidate sets of basis functions described herein.
- other boundary conditions can be used.
- Non-open boundary conditions may be more difficult to implement and may require that the image block be cut along at least a second, fictitious border, which may be mostly independent of the type of boundary conditions at the block-boundaries.
- FIG. 7 illustrates an example 700 of generating basis functions for a given border line according to implementations of this disclosure.
- the example 700 is described with respect to a block that is of size 4 ⁇ 4.
- the block can be of any size.
- a graph 710 illustrates a fully connected graph where each node is connected to each of its immediate neighbors. That is, each node is connected by respective edges to neighbors of the node.
- the image block can be a block of a source image or can be a residual block. More generally, the image block can be any block that is to be transformed to another domain, such as for the purpose of energy compaction, prior to encoding the transform block into a bitstream, such as the compressed bitstream 404 of FIG. 4 .
- the encoding can include quantizing the transform block.
- a graph 710 illustrates a connected graph that does not take into account a border line 722 that may be crossing the image block.
- the border line 722 splits the image block into two visually distinct parts.
- Each pixel of the image block is represented by a node in the graph 710 .
- the nodes of the graph 710 are labeled from 0 to 15, where a label corresponds to a particular (x, y) location of the image block. In this example, the nodes are labeled according to a raster scan order (i.e., left-to-right and top-to-bottom).
- An initial graph Laplacian matrix L can be generated for the image block. Given an image block of size M ⁇ M, the matrix L includes M 2 rows and M 2 columns: one row and one column for each of the nodes. As such, given an image block of size 4 ⁇ 4, the graph Laplacian matrix L includes 16 rows and 16 columns.
- each node is connected to its immediate neighbors.
- the node 5 is connected to the nodes 1, 4, 6, and 9; and node 15 is connected to the nodes 11 and 14.
- the degree matrix, D is a diagonal matrix where each diagonal value, corresponding to a node, indicates the number of nodes that the node is connected to.
- the adjacency matrix, A is such that the cell value (x, y) is set to 1 if node x is connected to y in the graph and x ⁇ y, otherwise (x, y) is set 0.
- a partial listing of the matrix L is shown below. The part of the matrix that corresponds to nodes 0-7 and the links between those nodes is shown in the matrix L.
- the cell value at (5, 5) is ⁇ 4 indicating that the node 5 is connected to 4 other nodes; namely the nodes 1, 4, 9, and 6.
- the value in each of the cells (5, 1), (5, 4), (5, 6), and (5, 9) is 1.
- the cell (5, 9) is not shown in the above matrix L.
- the cell value at (0, 0) is ⁇ 2 indicating that the node 0 is connected to 2 other nodes; namely the nodes 1, and 4.
- the value in each of the cells (0, 1) and (0, 4) is 1.
- a graph 720 illustrates a graph Laplacian where connections that are crossed by the border line 722 are removed from the graph.
- the corresponding partial graph Laplacian matrix (i.e., the part of the matrix that corresponds to nodes 0-7 and the links between those nodes) is given by:
- the cell value at (5, 5) is ⁇ 2 indicating that the node 5 is now connected to only 2 other nodes; namely the nodes 1 and 6.
- the value in each of the cells (5, 1) and (5, 6) is 1.
- the cell value at (0, 0) is ⁇ 1 indicating that the node 0 is connected to only 1 other node; namely the node 1.
- the value in the cells (0, 1) is 1.
- the signs in the above matrix would be reversed: positive integers at the diagonals and negative 1 elsewhere (i.e., where 2 nodes are connected).
- the graph Laplacian (and the corresponding graph Laplacian matrix) can be generated using all eight neighbors of a pixel.
- the eight neighbors of the node 6 are the nodes 1, 2, 3, 5, 7, 9, 10, and 11.
- different weights can be used for short neighbors (i.e., the immediate neighbors, such as 2, 5, 7, and 10) as compared to the long neighbors (i.e., the diagonal neighbors, such as 1, 3, 9, and 11).
- a ‘long’ neighbor edge contributes twice as much to the diagonal matrix entry as a short edge.
- Other relative weights are also possible.
- the border line 722 splits the image block into two visually distinct parts; namely a first part that includes the pixels corresponding to the nodes 0-3, 5-7, 10-11, and 15; and a second part that includes the pixels corresponding to the nodes 4, 8-9, and 12-14.
- the set of basis functions to be used for transforming the image block are the eigenfunctions (i.e., eigenvectors) of the graph 720 .
- the basis functions are the eigenfunctions of a modified graph from in which all the edges that are cut (e.g., crossed) by the border line are removed.
- a connected component of the graph that contains k nodes/pixels is associated with a set of k eigenfunctions that are zero on all the nodes/pixels that do not belong to this connected component.
- References herein to eigenfunctions (or eigenvectors) should be understood to encompass the corresponding eigenvalues.
- the eigenfunctions constitute a new set of basis functions that correspond to the way that a line (i.e., the border line 722 ) splits the block.
- an encoder and a decoder may use the same algorithm when determining (e.g., selecting, retrieving, storing, calculating, etc.) the basis functions.
- some tricks/techniques for handling floating point numbers may be employed. For some symmetric, and hence degenerate, configurations, such as splitting an 8 ⁇ 8 block into two 8 ⁇ 4 blocks, the resulting basis functions may have precisely the same eigenvalue. In such a situation, any linear combination of two eigenfunctions for the same eigenvalue is also an eigenfunction for this eigenvalue.
- a simple trick to circumvent the problem can be to, instead of attributing the precise value of +1 or ⁇ 1 to an edge of the graph Laplacian, attribute (e.g., use, assign, etc.), for each possible edge in an 8 ⁇ 8 block, a fixed pseudorandom number that is known both to the encoder and decoder and that is very close to 1.
- the pseudorandom number can be 1.000053.
- other pseudorandom number values are possible.
- the pseudorandom number can be used as a multiplier for the edge's contribution.
- the pseudorandom number can also be used in calculating the degree values (i.e., the diagonal values) of the matrix Laplacian.
- FIG. 7 is described with respect to a line (i.e., the border line 722 ) crossing the image block, the shape that crosses the block does not need to be a line.
- the process for determining the eigenfunctions remains the same. That is, the fully connected graph can be disconnected according to how the shape crosses the block and the eigenfunctions (i.e., the set of basis functions) of the resulting graph Laplacian are then calculated. The set of basis functions can then be used to transform the image block.
- an encoder can encode (such as in the compressed bitstream) parameters describing the shape and the transform coefficients resulting from transforming the block using the basis functions.
- a decoder can reconstitute the shape from the parameters and calculate the eigenfunctions. The decoder can then use the eigenfunctions (and corresponding eigenvalues) to inverse transform the transform coefficients into an image block.
- the equation 3*x ⁇ 7*y ⁇ 0.1>0 can be used to generate a first line that splits an image block into two regions.
- the first line can be used to calculate the corresponding set of basis functions for the split of the image block.
- Subsequent lines can be derived by subsequent rotations of the line.
- the parameters 3, ⁇ 7 and ⁇ 0.1 can be encoded.
- the shape can be a corner, such as one that splits the block according to (1 if x ⁇ 4 else 0)*(1 if y ⁇ 4 else 0); that is, a pixel belong to a first region if the x coordinate of the pixel is less than 4 or the y coordinate of the pixel is less than 4, otherwise the pixel belong to a second region.
- the shape can be a curved line (i.e., a quadric or a part of a quadric) that can be approximated by a quadratic equation. As such, the shape can be an ellipse, a parabola, a hyperbola, or the like.
- the coefficients of the quadratic equation can be encoded in the bitstream. It should be noted that it only matters for which edges the endpoints have opposite sign with respect to the splitting equation(s). There can be multiple ways to describe equations for which the level set intersects the edges to be removed. In an example, an equation is selected such that the resulting set of coefficients is easy to encode. In some implementations, small deviations that split the block in a way that is slightly different from the intended split can be used, if such an alternative split can be described with coefficients that can be encoded with fewer bits.
- a border can cross an image block in may possible ways.
- a first border line can cross the image block at a first angle (e.g., with respect to some line) and a second border line can cross the image block at a second angle that differs, even if slightly from the first angle.
- a third border line and a fourth borderline can have the same angle but can cross the image block at different locations.
- a closest matching line to the shape can be determined and the image block is encoded using the set of basis functions of the closest matching line. While in some implementations, sets of basis functions corresponding to each way that a line can cross an image block, such implementations may be impractical and/or unnecessary. It may not be necessary to consider all possible and distinct ways that a line can cross an image block because, at least, may such distinct cases are indistinguishable (e.g., imperceptible).
- FIG. 8 illustrates an example 800 of lines crossing a block at different angles according to implementations of this disclosure.
- the example 800 includes blocks 802 , 804 , and 806 .
- Each of the blocks 802 - 806 is of size 8 ⁇ 8.
- a block according to disclosure is not limited to the size of 8 ⁇ 8.
- the block can be smaller (such as a 4 ⁇ 4 or 2 ⁇ 2 block) or larger (such as 16 ⁇ 16, 32 ⁇ 32, 64 ⁇ 64, or larger).
- the block need not be a square block.
- the teachings herein can be easily adapted to non-square pixel grids, such as triangular, hexagonal, or parallelogram lattices.
- each of the black circles, such as a circle 808 indicates a corresponding pixel location in the respective block.
- the block 802 is crossed by a line 810 ; the block 804 is crossed by a line 812 ; and the block 806 is crossed by a line 814 .
- Each of the lines 810 , 812 , and 814 is comprised of all the star-shaped non-integer pixel locations of the blocks 802 , 804 , and 806 , respectively.
- the lines 810 , 812 , and 814 are not shown as straight lines. It is noted that the blocks 802 , 804 , and 806 are considered to be zoomed blocks and the lines 810 , 812 , and 814 are pixelated lines.
- Each of lines 810 , 812 , and 814 defines two types of pixels: Those pixels that are on one side of the line and those pixels that are on the other side of the line. No pixel of the blocks 802 , 804 , 806 is on the respective line that crosses the block.
- the lines 810 , 812 , and 814 can be considered to be fictitious lines that cross between the pixels of a block. Again, each pixel of a block is either one side of the line or the other side of the line; and none of pixels are on the line. This in turn can mean that a splitting line is not parametrized in such a way that the center of a pixel lands exactly on the line.
- the lines 810 and 812 are practically the same line. Effectively, the line 812 is a left 1-pixel shift of the line 810 . That is, the line 812 is the same as the line 810 with the exception that the line 812 is shifted to the left by 1 pixel. As such, the steps down in the lines 810 and 812 are at slightly different locations.
- the lines 810 and 812 are sufficiently close such that the same set of basis functions can be used for transforming (e.g., encoding) the blocks 802 and 804 . Visually, the blocks 802 and 804 are almost indiscernible (after approximating the contents of the blocks 802 and 804 ). Contrastingly, the line 814 may be considered to be sufficiently different from the lines 810 and 812 . Accordingly, a set of basis functions corresponding to the way that the line 814 splits the block 806 can be used for transforming the block 806 .
- FIG. 9 illustrates an example 900 of lines crossing a block at different translational shifts according to implementations of this disclosure.
- the example 900 includes blocks 902 , 904 , and 906 , which can be as described with respect to FIG. 8 .
- the black circles are integer pixel locations.
- a line 908 crosses the block 902 ; a line 910 crosses the block 904 ; and a line 912 crosses the block 906 .
- the lines 908 , 910 , and 912 cross the respective blocks at non-integer pixel locations. That is, the center of no pixels of blocks 902 , 904 , and 906 lands exactly on the lines 908 , 910 , and 912 , respectively.
- the lines 908 , 910 , 912 have the same direction.
- the lines 908 , 910 , 912 cross the respective blocks at different locations.
- the lines 908 , 910 , and 912 split the blocks 902 , 904 , and 906 , respectively, into 2 components: a first component including those pixels that are on one side of the line and a second component including those pixels that are on the other side of the line.
- the pattern of the block 902 can be obtained from the pattern of the block 906 by mirroring the pattern of the block 906 across the SouthWest-NorthEast diagonal line of the block 906 , and vice versa.
- the number of possible splitting lines of a block can be significantly high, in an implementation, the number of lines can be limited. That is, of the many different line directions and translational shifts, a subset can be selected for the purpose of selecting basis function sets.
- водн ⁇ е ⁇ е ⁇ е ⁇ ество eight (8) line directions can be selected.
- the line directions can correspond to the angles 0 degrees, 22.5 degrees, 45 degrees, 67.5 degrees, 90 degrees, 112.5 degrees, 135 degrees, and 157.5 degrees. It is noted that 180 degrees gives the same direction as 0 degrees, 202.5 degrees is the same as 22.5 degrees, and so on.
- eight (8) different translational shifts can be used with each of the selected angles.
- every row and column can be represented. That is, for the directions of 0 (90) degrees, a line crossing (e.g., being coincident with) each of the rows (columns) of the image block can be represented in the set of basis function sets.
- the selected set of basis functions that corresponds to a line and that is used for transforming the block is such that extra bits need not be expended in order to suppress ringing in a part of the block.
- having a set of basis functions that mostly solves the problem of suppressing ringing with fewer bits (for example as compared to the DCT basis functions) but that slightly mis-estimates the location of the border can be considered to be visually acceptable.
- 64 different sets of basis functions i.e., candidate sets
- the 64 candidate sets corresponding to eight line directions and eight ways (i.e., translational shifts) that each of the lines can cross a block. That is, the 64 different sets of basis functions correspond to how a line splits the block.
- the candidate set of sets of basis functions can be calculated by a codec (e.g, encoder and/or decoder) at, for example, startup time of the codec and stored for later use.
- a set of basis functions can be calculated on demand (and cached for later use). That is, when a block is determined to be crossed by a certain line, the set of basis of functions corresponding to that line can be calculated.
- the codec can include an eigenvalue solver, which can be used to determine the eigenfunctions for the graph Laplacians, as described with respect to FIG. 7 .
- the candidate sets of basis functions can be precalculated and stored in (or are accessible by) the codec.
- Each basis function can be represented by (e.g., stored as) a two-dimensional array (e.g., matrix) of real values along with their corresponding eigenvalues.
- a line that crosses the block thereby splitting the block into two distinct regions can be characterized (e.g., identified) by a pixel (i.e., a pixel of the block) on the line that is closest to the origin of the block.
- a pixel i.e., a pixel of the block
- the origin of the block can be considered to be a center point of the block.
- the origin of the block can be any other pixel that can be used a reference point for the block.
- the origin can be the top-left pixel of the block.
- the center of the block may be at a point that is at a subpixel location, such as in the case of an M ⁇ M block where M is a positive, even integer.
- the closest pixel can be the pixel (e.g., the pixel location) obtained by drawing a perpendicular line from the origin to the line.
- the location of intersection of the line and the perpendicular line is the pixel (e.g., point) of the line that is closest to the origin.
- the location of the closest pixel uniquely identifies the direction of the line and where the line crosses the block.
- the closest pixel can be in any octant (i.e., triangle, 1 ⁇ 8 th slice) of the block. If the closest pixel is in one octant, the closest pixel can be mapped to another pixel location in a second octant using rotation and/or mirroring operations. In an example, the closest pixel, regardless of what other octant it may be in, can be mapped to the north-northeast octant using at least one of rotation or mirroring. As such, the 64 candidate sets can be canonized to only eight candidate sets. That is, the set of 64 candidate sets of basis functions can be reduced to a set of eight sets of basis functions. As such, only eight sets of basis functions can be stored (or calculated). In an example, however, if the splitting lines include lines that are at 0 degrees and 90 degrees, then the orbit of a set of basis functions under symmetry, for those two directions, would have four elements, instead of eight.
- the splitting lines include lines that are at 0 degrees and 90 degrees, then the orbit of
- pre-stored sets of basis functions may be associated with shapes other than lines.
- the shape can be a circle, an oval, a quadric, a corner, or some other shape.
- a subset of the ways that the shape can be placed in, or splits, the image block thereby dividing the image block into distinct regions can be selected.
- the eigenfunctions corresponding to the graph Laplacian i.e., the graph resulting from disconnecting edge according to the placement
- the eigenvectors can be calculated (such as by a decoder) in response to receiving parameters in a compressed bitstream, such as the compressed bitstream 404 of FIG. 5 , describing the shape and the placement of the shape.
- FIG. 10 is an example of borders 1000 crossing a block according to implementation of this disclosure.
- the borders 1000 correspond to eight splitting directions of a block.
- Line 1002 - 1016 correspond, respectively, to the direction of the short hand (i.e., the hour hand) of an analog clock at 0:22:30, 1:07:30, 1:52:30, 2:37:30, 3:22:30, 4:07:30, 4:52:30, and 5:37:30.
- the line 1002 which indicates a direction of the short hand at the time 0:22:30
- each of the lines 1004 - 1016 is offset from the preceding line by a 45-minute increment.
- the next (i.e., 45 minutes from 5:37:30) hand direction would correspond to the time 6:22:30, which can be represented by the same, the line 1002 .
- the directions of the lines 1002 - 1016 can divided into two sets of four directions, each: 1) four directions (namely, the lines 1002 , 1008 , 1010 , and 1016 ) that are more horizontal or vertical than diagonal; and 2) four directions (namely, the lines 1004 , 1006 , 1012 , and 1014 ) that are more diagonal than horizontal or vertical.
- Each of these two sets is the orbit of a line under the (rotating and mirroring) symmetries of the square. That is, symmetries of the square transform a line of the one type into another line of the same type, and never a line of the other type.
- FIGS. 11A-11D are examples of sets of basis functions according to an implementation of this disclosure.
- each set of basis function can be calculated (e.g., derived) using an eigenvalue solver.
- Each set of basis functions corresponds to generating the eigenfunctions (and, as mentioned above, the corresponding eigenvalues) of a graph Laplacian matrix that corresponds to a line having a certain direction and crossing an image block at a certain translational shift location.
- FIGS. 11A-11D illustrate sets of basis functions for some, but not all, of the lines 1002 - 1016 of FIG. 10 .
- FIG. 11A includes eight sets of basis functions; namely, basis function sets 1111 - 1118 , and similarly for FIGS. 11B-11D .
- Sets of basis functions 1130 of FIG. 11B correspond to the line 1006 of FIG. 10 crossing an 8 ⁇ 8 image block at different locations.
- Sets of basis functions 1150 of FIG. 11C correspond to the line 1004 of FIG. 10 crossing an 8 ⁇ 8 image block at different locations.
- Sets of basis functions 1170 of FIG. 11D correspond to the line 1002 of FIG. 10 crossing an 8 ⁇ 8 image block at different locations.
- each of the basis function sets 1171 - 1178 of FIG. 11D can be obtained, respectively, from a corresponding one of the basis function set 1111 - 1118 of FIG. 11A using a reflection along the NorthWest-SouthEast diagonal.
- a split 1120 of FIG. 11A indicates that the line 1008 crosses (i.e., splits) the block into a first portion that includes 2 pixels near a corner of the block and a second portion that includes the remaining 62 pixels.
- the split 1120 is technically a basis function. However, because the split 1120 visually illustrates how a line crosses the block, it is referred to as a split. Similarly for other basis functions that are referred as splits.
- the set of basis functions can be obtained from the basis function sets 1111 using rotation and/or mirroring.
- the basis functions for spatial variations is such that a constant-across-the-block function is part of the set.
- the DCT basis functions includes the function 602 , which is the constant-across-the-block function.
- the two lowest energy basis functions correspond to an eigenvalue of zero (or approximately zero).
- a basis function 1121 and the basis function corresponding to the split 1120 each corresponds to an eigenvalue of zero; similarly, a basis function 1123 and the basis function corresponding to the split 1122 each corresponds to an eigenvalue of zero; and so on. That is, each of such two eigenfunctions have the same energy; namely, zero.
- these two independent basis functions represent ‘no spatial variation between graph-neighbors’. These can be picked as taking on the value 1 on one graph component, and 0 or the other.
- one function can be picked to actually be constant across the entire block, and the other one having values +1 and ⁇ 1 on the two different graph components (i.e., on different sides of the boundary).
- the eigenfunction can be normalized. That is, the eigenfunction can be scaled such that the sum of the squares of the 64-vector is 1. As such, the eigenfunctions can be unit vectors.
- the eigenvalue-degeneracy that comes from the constant-on-each-component functions may not be avoidable. It often is the case that other components of an image compression system assume that a constant-brightness block can be described with a single coefficient for the leading basis function. Implementations according to this disclosure can also ensure that the constant brightness can be described with a single coefficient via a redefinition of the basis of the eigenvalue-0 eigenspace.
- each set of basis functions constitutes two interleaved towers of basis functions: one set being zero on one part of the split graph and spatially varying on the other, and the other set vice versa, with the roles of the components exchanged.
- the eigenvalues corresponding to eigenfunctions that are zero on the one component (e.g., the small component that includes the nodes 4, 8-9, and 12-14 of FIG. 7 ) of the graph Laplacian may be 0.0, 1.3, 2.4, 3.0, 3.5, 4.3, . . .
- the eigenvalues corresponding to eigenfunctions that are zero on the other component (e.g., the large component of the FIG. 7 ) of the graph Laplacian may be 0.0, 2.8, 4.2, 4.7, . . . . These values can be visualized as shown in FIG. 16 .
- This ‘energy ordering’ automatically provides a desired (for compression, in particular quantization) ordering in terms of increasingly rapid spatial variation. As such, in an implementation, it is possible to consistently truncate all spatial variations that oscillate more rapidly than a given threshold by thresholding the graph energy-eigenvalue.
- Truncating can mean ignoring the corresponding eigenfunctions with fast spatial variations. Equivalently, truncating can mean setting the coefficients to zero that multiply them. It is noted that, for example, if a choice is made such as to ignore all spatial variations that have a length scale of less than 1 ⁇ 3 the edge length of the block, then this decision corresponds to picking a threshold on the eigenvalue of the Laplace matrix. That is, it is not the case, for example, that this threshold would eliminate spatial variations above a first characteristic size S_a for a first component of the graph and variations above a second characteristic size S_b for a second component of the graph. Rather, the picked threshold corresponds to the same characteristic size on both, the first and the second, graph components.
- each of the sets of basis functions of FIGS. 11A-11D is ordered in terms of increasing frequency.
- each of the function sets of FIGS. 11A-11D if read in raster order (e.g., first row, from left to right, followed by the second row from left to right, and so on), corresponds to increasing energy of oscillations.
- each function-set has 7 other equivalent function sets. That is, each of the 8 function sets can be derived from one of the other seven via rotation and/or mirroring.
- the lines described with respect to FIG. 10 do not include vertical and horizontal lines. As such, block splits based on a horizontal (vertical) line can be approximated by the split using the line 1008 ( 1002 ).
- each of the added function sets corresponds to chopping 1, 2, 3, and 4 lines off the block. That is, each of the added function sets corresponds to (e.g., crossing) the block at a first, second, third, or fourth row (or column).
- a coordinate-parallel line i.e., a vertical line or a horizontal line.
- Each of 80 ways of splitting a block can have a corresponding function set.
- some of the function sets can be derived from others using rotation and/or mirroring.
- the 80 function sets can be reduced without loss. For example, as mentioned below with respect to split corresponding to the function set 1140 , some rotations or mirroring of such a split are indistinguishable. As such, any redundant (e.g., duplicate, indistinguishable) spits need not be duplicated. In the example splits described herein, there are 4 pairs of duplicates, including the split corresponding to the function set 1140 .
- the shape that crosses (e.g., splits, partitions) the block can be a corner.
- the possible ways of splitting a block using a corner can include coordinate-aligned corners such that each corner-edge is at least a certain number of pixels from the block edge.
- the certain number of pixels can be 3.
- Some other corners can be approximated by a straight line split.
- a straight-line split mostly along the 6-pixel edge can be used as a good approximation.
- the basis function set 1113 can be used as an approximation for the transforming a block that includes a 2 ⁇ 6 corner.
- FIG. 12 is an example of equivalent function sets 1200 according to implementations of this disclosure.
- the equivalent function sets 1200 includes the basis function set 1172 of FIG. 10D .
- the basis function set 1172 is the function-set given a L-shaped split of a block, as illustrated by a split 1202 .
- the split according to the split 1202 has 7 equivalents as can be appreciated by inspection of bases functions 1204 , 1206 , 1208 , 1210 , 1212 , 1214 , an 1216 .
- each of the 8 function sets of FIG. 12 can be derived from one of the other seven via rotation and/or mirroring.
- the sets of basis function 1130 of FIG. 11B includes a function set 1140 that corresponds to a split of an image block into a corner that includes three (3) pixels and the rest of the pixels (e.g., 61 pixels, in the case of an 8 ⁇ 8 block).
- the three (3) pixels are the corner pixel, its neighboring pixel to the right, and a neighboring pixel that is below the corner pixel.
- This case is invariant under one reflection; namely, the reflection across the NorthWest-SouthEast diagonal. As such, for some line directions and/or crossing locations, less than seven equivalents may be required to be generated and/or stored.
- FIG. 13 is an example of canonical sets of function sets 1300 according to implementations of this disclosure.
- the functions sets illustrated in FIG. 13 can be the function sets that are stored (or computed at startup time) in a codec and from which all other function sets can be derived.
- FIG. 14 is an example of a flowchart diagram of a process 1400 for encoding a block of a frame according to an implementation of this disclosure.
- the frame can be a standalone image.
- the frame can be frame of a video stream.
- the block can be of any rectangular or square size.
- the block can be 4 ⁇ 4, 8 ⁇ 8, 12 ⁇ 12, of smaller, or larger size.
- the block is a block of pixels, each having a pixel value. That is, the block is in the spatial (or pixel) domain.
- the block can include a border. That is, a border (or line) splits the blocks into at least two distinct regions.
- the process 1400 converts the block, which is in the pixel domain, to a transform block, which is in the frequency domain, to compact the energy in the block.
- the transform block includes transform coefficients and can be of the same size as the block.
- the process 1400 selects a set of basis functions that takes into consideration the border, such as the orientation of the border and where the border crosses the block.
- the set of basis functions considering the border, the number of non-zero coefficients in the transform block can be reduced (for example, as compared to not using a set of basis function that takes the border into consideration). Consequently, the number of bits required to encode the transform block can be reduced.
- the process 1400 can be implemented, for example, as a software program that can be executed by a computing device, such as the computing device 100 of FIG. 1 or one of the computing and communication devices 100 A, 100 B, 100 C of FIG. 2 .
- the software program can include machine-readable instructions (e.g., executable instructions) that can be stored in a memory, such as the memory 110 of FIG. 1 , and that can be executed by a processor, such as the processor 120 of FIG. 1 , to cause the computing device to perform the process 1400 .
- the process 1400 can be implemented in an encoder, such as the encoder 400 of FIG. 4 . In at least some implementations, the process 1400 can be performed in whole or in part by the transform unit 420 of the encoder 400 of FIG. 4 .
- the process 1400 can be implemented using specialized hardware or firmware. Some computing devices can have multiple memories, multiple processors, or both. The steps or operations of the process 1400 can be distributed using different processors, memories, or both. Use of the terms “processor” or “memory” in the singular encompasses computing devices that have one processor or one memory as well as devices that have multiple processors or multiple memories that can be used in the performance of some or all of the recited steps or operations.
- the process 1400 receives the block.
- “receive” can mean create, form, produce, select, construct, determine, specify, generate, or other receive in any manner whatsoever.
- the block can be a source image block. That is, the block can be one of the blocks 340 of FIG. 3 .
- the block can be a residual block, such as described with respect to intra/inter prediction unit 410 of FIG. 4 .
- the block can be received by a transform unit, such as the transform unit 420 of FIG. 4 .
- the block can be a luma block, a chroma block, other color component block, or any block that contains image data.
- the process 1400 selects, based on the border that crosses the block, a set of basis functions for transforming the block to the transform domain.
- the border can be one or more lines that cross (e.g., partition) the block. While, for simplicity of explanation, the disclosure herein is generally described with respect to one line or shape, the teachings herein are applicable and generalizable to multiples lines and/or shapes.
- the block can be analyzed to determine whether a border crosses the block. For example, an edge detection technique can be used to determine whether a border crosses the block. Once the border is identified, the direction (e.g., orientation) of the border and the location at which the border crosses the block can be used to select a set of basis functions for transforming the block. In an example, a lookup table that maps border orientation and crossing locations combination to sets of basis functions can be used to select the set of basis functions (e.g., a canonical function set).
- a lookup table that maps border orientation and crossing locations combination to sets of basis functions can be used to select the set of basis functions (e.g., a canonical function set).
- each of the available candidate sets can be used to encode the block resulting in respective transform blocks.
- the one of the candidate sets resulting in the best coding efficiency can be selected for transforming the block.
- coding efficiency can be measured in terms of both rate (e.g., bitrate) and distortion, as a rate-distortion value.
- Rate refers to the number of bits required for encoding (such as encoding a block, a frame, etc.).
- Distortion measures the quality loss between, for example, a source image block and a reconstructed version of source video block.
- the distortion can be calculated as a sum of absolute differences between pixel values of the image block and the reconstructed version of source video block.
- a hypothetical encoder can be used to determine the rate.
- the hypothetical encoder can carry out the coding steps but does not output bits into a compressed bitstream, such as the compressed bitstream 404 of FIG. 4 .
- the purpose of the hypothetical encoder is to estimate a bitrate (or a simply rate).
- a hypothetical encoding process may be regarded as, or called, a rate estimation process.
- the hypothetical encoder can compute an estimate the number of bits required to encode a respective transform block.
- 64 candidate sets can be available.
- eight candidate sets i.e., canonical function sets
- the block can be subjected to orientation and/or mirroring operations resulting in oriented blocks.
- Each of the oriented blocks can be transformed using the eight canonical sets.
- mirroring and/or mirroring can be applied to the canonical sets to obtain the 64 candidate sets and each of the candidate sets is used to transform the block.
- selecting the set of basis functions for transforming the block to the transform domain can include selecting a candidate set of basis functions for transforming the block, and obtaining the set of basis functions from the candidate set of basis functions using at least one of a rotation or mirroring.
- Transforming the block using set of basis functions, for the purpose of selecting the set of basis functions amounts to taking the inner product of the block with each of the basis functions, as shown in formula (1).
- c ⁇ B,m ⁇ ⁇ all i E ⁇ B,m;i ⁇ *d ⁇ B,i ⁇ (1)
- c ⁇ B, m ⁇ is the transform block of the image block, d ⁇ B, i ⁇ ; and E ⁇ B, i ⁇ is the ordered list of orthonormal eigenfunctions that corresponds to the boundary(ies) B.
- only a subset of the set of basis functions can be used to select the set of basis functions. For example, only the first two of the basis functions corresponding to the lowest energy basis functions are used. For example, the basis function corresponding to the average brightness (such as the basis function 1121 of FIG. 11A ) and the basis function illustrated by the split 1120 of FIG. 11A are used. In another example, other subsets can be used. For example, if four basis functions are selected, then the four basis functions corresponding to the lowest energy basis functions are used.
- selecting the set of basis functions for transforming the block can include selecting, from candidate sets of basis functions, the set of basis functions as an optimal set of basis function by applying, to the block, from each candidate set of basis functions less than all (e.g., at least a subset) of the functions of the candidate set.
- the process 1400 transforms the block using the set of basis functions to obtain a transform block.
- the transform block includes transform coefficients.
- the transform block can be obtained using the formula (1).
- the transform block is a block of unquantized transform coefficients.
- the unquantized transform coefficients can be scaled and rounded to integer values (i.e., quantized transform coefficients) using a quantization matrix.
- JPEG uses only one set of basis functions, JPEG uses one particular choice of quantization matrix, which indicates how each coefficient is to be scaled prior to rounding the scaled value to an integer.
- each transform coefficient, c ⁇ B, m ⁇ can be scaled according to a function of the corresponding eigenvalue, e ⁇ B, m ⁇ , of the Laplacian that is associated with the eigenvector. This is so because the eigenvalue is a measure for the characteristic length scale of spatial variations and/or the square of such a length scale.
- the process 1400 can encode, in the compressed bitstream, an indication of the set of basis functions.
- encoding the indication of the basis function can include encoding, in the compressed bitstream, a direction of the border and encoding a displacement of the border.
- the displacement e.g., the translational shift
- each combination of direction and displacement can correspond to a respective index value.
- each combination can correspond to an index value of 0 to 63.
- a direction index can be 0 to 7 and a displacement index can be 0 to 7.
- encoding the indication of the basis function can include encoding in the compressed bitstream, a pixel of the block that is on the border and that is closest to an origin of the block.
- the (x, y) coordinates of the pixel can be encoded.
- a scan order position of the pixel can be encoded.
- encoding a transform block uses a scan order to traverse the coefficients of the transform block. As such, the scan order position corresponding to the location of the pixel in the block can be encoded.
- encoding the indication of the set of basis functions can include encoding that the block is split by the border and how the block is split by the border. Encoding that the block is split can require at most one bit. If, for example, only 20% of all the blocks in an image are split, then, on average, much less than one bit may be used to indicate that the block is split. Encoding how the block is split corresponds to encoding which one of the candidate sets (e.g., which one of the 64 candidate sets) is used.
- the process 1400 encodes the transform block in the compressed bitstream.
- encoding the transform block can include quantizing, such as by a quantization unit, the transform block and encoding the quantized transform coefficients.
- the quantization unit can be the quantization unit 430 of FIG. 4 .
- an image block that is split into two regions (a first region including only black pixels and a second region including only white pixels) separated by a straight line can be encoded using a first integer in the range 0 . . . 63 that indicates the function-set, a second integer providing the number of non-zero coefficients (here, 2), and a third and a fourth number providing the grayscale values for each of the two different regions.
- the block includes two distinct levels of gray (e.g., a black and while block) that are separated by the line
- the set of basis functions for transforming the block results in the transform block consisting of no more than two non-zero coefficients.
- encoding such block uses significantly fewer bits than those normally required by JPEG.
- the DCT basis functions of JPEG (shown in FIG. 6 ) are not tailored to (e.g., cannot deal with) image blocks that are split into distinct regions by a line (or more generally, by a shape).
- JPEG compression many transform coefficients may need to be encoded.
- the process 1400 is described with respect to one block of a frame.
- the selected set of basis functions for a block of a frame can be used across frames of a sequence of frames or a collection of frames or images.
- the choice of basis functions for a block can be carried forward into future frames of the collection of frames.
- the set of basis functions can be used for co-located blocks of the future frames.
- the set of basis functions of a reference block can be used for blocks whose motion vectors refer to the reference block.
- FIG. 15 is an example of a flowchart diagram of a process 1500 for decoding a block of a frame according to an implementation of this disclosure.
- the frame can be a standalone image.
- the frame can be frame of a video stream.
- the block can be of any rectangular or square size.
- the block can be 4 ⁇ 4, 8 ⁇ 8, 12 ⁇ 12, of smaller, or larger size.
- the block includes pixel values. That is, the block is in the spatial (or pixel) domain.
- the block can include a shape.
- the shape can be a border (or line) that splits the blocks into at least two distinct regions.
- the process 1400 receives a transform block, which is in the frequency domain, and inverse-transforms the transform block to obtain the block, which is in the pixel domain.
- the transform block includes transform coefficients and can be of the same size as the block.
- the process 1500 selects a set of basis functions that takes into consideration the shape. For example, in the case of a border, the set of basis functions can take into consideration the orientation of the border and where the border crosses the block. By selecting the set of basis functions considering the border, ringing in the block can be suppressed.
- inverse-transforming the transform block can include de-quantizing the transform block and inverse-transforming the deq-quantized transform block.
- the process 1500 can be implemented, for example, as a software program that can be executed by a computing device, such as the computing device 100 of FIG. 1 or one of the computing and communication devices 100 A, 100 B, 100 C of FIG. 2 .
- the software program can include machine-readable instructions (e.g., executable instructions) that can be stored in a memory, such as the memory 110 of FIG. 1 , and that can be executed by a processor, such as the processor 120 of FIG. 1 , to cause the computing device to perform the process 1500 .
- the process 1500 can be implemented in a decoder, such as the decoder 500 of FIG. 5 . In at least some implementations, the process 1500 can be performed in whole or in part by the inverse transform unit 530 of the encoder 500 of FIG. 5 .
- the process 1500 can be implemented using specialized hardware or firmware. Some computing devices can have multiple memories, multiple processors, or both. The steps or operations of the process 1500 can be distributed using different processors, memories, or both. Use of the terms “processor” or “memory” in the singular encompasses computing devices that have one processor or one memory as well as devices that have multiple processors or multiple memories that can be used in the performance of some or all of the recited steps or operations.
- the process 1500 decodes, from a compressed bitstream, an indication of a set of basis functions for inverse transforming the block.
- the indication can be as described with respect to the process 1400 .
- the set of basis functions corresponds to eigenfunctions (and corresponding eigenvalues) of a graph Laplacian that is formed based on the shape.
- decoding the indication of the set of basis functions can include decoding, from the compressed bitstream, a direction of the border; and decoding, from the compressed bitstream, a displacement of the border.
- decoding the indication of the set of basis functions can include decoding, from the compressed bitstream, a pixel of the block that is on the border and that is closest to an origin of the block.
- the indication can be used to select the set of basis functions.
- a canonical function set is first selected; then, based on the indication, the set of basis functions can be selected (e.g., obtained) by at least one of mirroring or rotation.
- the process 1500 decodes, from the compressed bitstream, a transform block.
- the transform block includes transform coefficients.
- the transform coefficients can be quantized transform coefficients.
- decoding the transform block can include dequantizing the quantized transform coefficients to obtain the transform block.
- the dequantizing can be performed by a dequantization unit, such as the dequantization unit 520 of FIG. 5 .
- the process 1500 inverse-transforms the transform block using the set of basis functions to obtain the block.
- the inverse-transforming can include dequantizing the transform block before applying the formula 2.
- a dequantization function that is the inverse of the quantization function, Q, described above can be used.
- the set of basis functions can be selected from stored candidate sets of basis functions.
- the set of basis functions can calculated, such as by an eigenvalue solver, based on indication of the set of basis functions.
- a graph Laplacian matrix can be formed by disconnecting edges according to the indication and the eigenfunctions obtained.
- the above described relationship between an image block, the transformed block, and the eigenvectors and eigenvalues can be further elaborated, in an example, as follows.
- the block is assumed to be of size 8 ⁇ 8.
- the disclosure is not so limited.
- a graph Laplacian that includes more than one connected component is obtained.
- the associated graph Laplacian is a matrix that depends on B.
- L ⁇ B ⁇ denote the graph Laplacian matrix.
- the graph Laplacian matrix, L ⁇ B ⁇ is a real symmetric matrix.
- Hermitian matrix which means that all its eigenvalues are real. There are as many eigenvalues as there are pixels in the block. However, in some situations (such as, for example, in the case of a symmetric split of an 8 ⁇ 8 graph into two 4 ⁇ 8 pieces), some of the eigenvalues can occur more than once.
- the eigenvalues and eigenvectors also depend on the block-splitting boundary(ies) B.
- the 8 ⁇ 8 eigenvalues are denoted e ⁇ B, i ⁇ ; and the associated eigenvectors are denoted E ⁇ B, i ⁇ .
- the eigenvalue 0 can be expected to be found K times. This corresponds to the space of functions that are constant on each graph component.
- K such functions i.e., indicator functions
- the K indicator functions of the connected components can be selected, suitably re-scaled to have length- 1 with respect to the standard scalar product.
- the indicator function of a component can take on the value of 1 on all the nodes that belong to the component, and 0 on all other nodes.
- the eigenfunctions E ⁇ B, i ⁇ can be ordered. No specific order may be necessary. However, an encoder and a decoder must have the same ordering. In an example, the order can be achieved by sorting the eigenfunctions E ⁇ B, i ⁇ by increasing magnitude of the associated eigenvalue e ⁇ B, i ⁇ .
- edge-strengths can eliminate the degeneracy for all eigenfunctions except for the zero eigenvalues.
- Both the encoder and the decoder can use basis functions that are obtained by a specific (e.g., the same) eigenvalue algorithm.
- a QR-decomposition-based eigenvalue algorithm can be used.
- other algorithms are possible.
- eigenfunctions are only determined up to an overall factor of ⁇ 1. It must be ensured that both encoder and decoder use the same signs.
- the eigenspace for eigenvalue 0 is special as it contains the DC basis function.
- a convention can be used to ensure that the very first basis function is constantly 1 on all nodes.
- a deterministic algorithm can be used to obtain a complete orthonormal basis for that space.
- a basic basis exchange algorithm can be used.
- any other deterministic algorithm can also be used.
- the scalar product of the m th eigenvector E ⁇ B, m ⁇ with the vector of 64 image-coefficients, listed in node order is obtained using the formula 1.
- transform coefficients, c ⁇ B, m ⁇ may be scaled and rounded (i.e., quantized) to integer values.
- quantization function can also be used as described with respect to formulae (1a) and (2a).
- implementations according to this disclosure use fewer bits for coding the transform coefficients than other schemes at least because fewer or no coefficients are required to suppress ringing.
- a concrete example is now provided with respect to the coding of a 500 ⁇ 400 pixel image (e.g., frame) whereby the coding includes dividing the image 8 ⁇ 8 blocks, which are coded separately. Since 500 is not a multiple of eight, there would be 4 ⁇ 8 blocks at the right border. Each 4 ⁇ 8 block may be enlarged into an 8 ⁇ 8 block by padding with black pixel values. After decoding, the padded half of the block may be cut off.
- Encoding such a half-black 8 ⁇ 8 block with conventional encoding techniques may require using 128 bits or so for the entire block. A substantial number of the bits may be required to suppress ringing near the borders of the block: on the visible side (i.e., the right edge of the 4 ⁇ 8 block) as well as on the ignorable side (i.e., the right edge 8 ⁇ 8 block). If some of the coefficients were to be dropped, ringing artefacts may be visible to the left of the right edge of the 4 ⁇ 8 block as well as on the to-be-thrown-away part (i.e., the padded 4 ⁇ 8 part).
- extended (i.e., padded) block can be encoded, according to implementations of this disclosure, as a split block with a vertical line running through the middle, where the right half of the block is black (i.e., only includes black pixel values).
- the visible half-block i.e., the original 4 ⁇ 8 image block
- example or “exemplary” are used herein to mean serving as an example, instance, or illustration. Any aspect or design described herein as “example” or “exemplary” is not necessarily to be construed as preferred or advantageous over other aspects or designs. Rather, use of the words “example” or “exemplary” is intended to present concepts in a concrete fashion.
- the term “or” is intended to mean an inclusive “or” rather than an exclusive “or.” That is, unless specified otherwise or clear from context, “X includes A or B” is intended to mean any of the natural inclusive permutations thereof.
- the terms “determine” and “identify,” or any variations thereof, include selecting, ascertaining, computing, looking up, receiving, determining, establishing, obtaining, or otherwise identifying or determining in any manner whatsoever using one or more of the devices shown in FIG. 1 .
- the implementations of the transmitting computing and communication device 100 A and/or the receiving computing and communication device 100 B can be realized in hardware, software, or any combination thereof.
- the hardware can include, for example, computers, intellectual property (IP) cores, application-specific integrated circuits (ASICs), programmable logic arrays, optical processors, programmable logic controllers, microcode, microcontrollers, servers, microprocessors, digital signal processors, or any other suitable circuit.
- IP intellectual property
- ASICs application-specific integrated circuits
- programmable logic arrays optical processors
- programmable logic controllers microcode, microcontrollers
- servers microprocessors, digital signal processors, or any other suitable circuit.
- signal processors should be understood as encompassing any of the foregoing hardware, either singly or in combination.
- signals and “data” are used interchangeably. Further, portions of the transmitting computing and communication device 100 A and the receiving computing and communication device 100 B do not necessarily have to be implemented in the same manner.
- the transmitting computing and communication device 100 A or the receiving computing and communication device 100 B can be implemented using a computer program that, when executed, carries out any of the respective methods, algorithms, and/or instructions described herein.
- a special-purpose computer/processor which can contain specialized hardware for carrying out any of the methods, algorithms, or instructions described herein, can be utilized.
- the transmitting computing and communication device 100 A and the receiving computing and communication device 100 B can, for example, be implemented on computers in a real-time video system.
- the transmitting computing and communication device 100 A can be implemented on a server, and the receiving computing and communication device 100 B can be implemented on a device separate from the server, such as a hand-held communications device.
- the transmitting computing and communication device 100 A can encode content using an encoder 400 into an encoded video signal and transmit the encoded video signal to the communications device.
- the communications device can then decode the encoded video signal using a decoder 500 .
- the communications device can decode content stored locally on the communications device, for example, content that was not transmitted by the transmitting computing and communication device 100 A.
- the receiving computing and communication device 100 B can be a generally stationary personal computer rather than a portable communications device, and/or a device including an encoder 400 may also include a decoder 500 .
- implementations can take the form of a computer program product accessible from, for example, a tangible computer-usable or computer-readable medium.
- a computer-usable or computer-readable medium can be any device that can, for example, tangibly contain, store, communicate, or transport the program for use by or in connection with any processor.
- the medium can be, for example, an electronic, magnetic, optical, electromagnetic, or semiconductor device. Other suitable mediums are also available.
Abstract
Description
c{B,m}=Σ all i E{B,m;i}*d{B,i} (1)
c{B,m}=roundToInteger(Q(e{B,m}*Σ all i E{B,m;i}*d{B,i}) (1a)
d{B,i}=Σ all m E{B,m;i}*c{B,m} (2)
d{B,i}=(Σall m E{B,m;i}*c{B,m})/Q(e{B,i}) (2a)
L{B}E{B,i}=e{B,i}E{B,i} (3)
c{B,m}=Σ all i E{B,m;i}*d{B,i} (1)
d{B,i}=Σ all m E{B,m;i}*c{B,m} (2)
Claims (20)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US16/402,297 US11122297B2 (en) | 2019-05-03 | 2019-05-03 | Using border-aligned block functions for image compression |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US16/402,297 US11122297B2 (en) | 2019-05-03 | 2019-05-03 | Using border-aligned block functions for image compression |
Publications (2)
Publication Number | Publication Date |
---|---|
US20200351520A1 US20200351520A1 (en) | 2020-11-05 |
US11122297B2 true US11122297B2 (en) | 2021-09-14 |
Family
ID=73016005
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US16/402,297 Active US11122297B2 (en) | 2019-05-03 | 2019-05-03 | Using border-aligned block functions for image compression |
Country Status (1)
Country | Link |
---|---|
US (1) | US11122297B2 (en) |
Families Citing this family (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2022167299A (en) * | 2021-04-23 | 2022-11-04 | 富士通株式会社 | Flow rule generation device, flow rule generation program, and flow rule generation method |
CN114339230B (en) * | 2022-03-03 | 2022-09-02 | 杭州未名信科科技有限公司 | Transformation core selection method and device for video coding, storage medium and terminal |
Citations (142)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4774574A (en) | 1987-06-02 | 1988-09-27 | Eastman Kodak Company | Adaptive block transform image coding method and apparatus |
US5068724A (en) | 1990-06-15 | 1991-11-26 | General Instrument Corporation | Adaptive motion compensation for digital television |
US5091782A (en) | 1990-04-09 | 1992-02-25 | General Instrument Corporation | Apparatus and method for adaptively compressing successive blocks of digital video |
US5121216A (en) | 1989-07-19 | 1992-06-09 | Bell Communications Research | Adaptive transform coding of still images |
US5146324A (en) | 1990-07-31 | 1992-09-08 | Ampex Corporation | Data compression using a feedforward quantization estimator |
US5224062A (en) | 1992-03-17 | 1993-06-29 | Sun Microsystems, Inc. | Method and apparatus for fast implementation of inverse discrete cosine transform in a digital image processing system using optimized lookup tables |
US5235623A (en) | 1989-11-14 | 1993-08-10 | Nec Corporation | Adaptive transform coding by selecting optimum block lengths according to variatons between successive blocks |
US5260782A (en) | 1991-08-30 | 1993-11-09 | Matsushita Electric Industrial Co., Ltd. | Adaptive DCT/DPCM video signal coding method |
US5274442A (en) | 1991-10-22 | 1993-12-28 | Mitsubishi Denki Kabushiki Kaisha | Adaptive blocking image signal coding system |
US5341440A (en) | 1991-07-12 | 1994-08-23 | Earl Joseph G | Method and apparatus for increasing information compressibility |
US5422963A (en) | 1993-10-15 | 1995-06-06 | At&T Corp. | Block transform coder for arbitrarily shaped image segments |
US5444800A (en) | 1988-11-18 | 1995-08-22 | At&T Corp. | Side-match and overlap-match vector quantizers for images |
US5635938A (en) | 1993-12-28 | 1997-06-03 | Oki Electric Industry Co., Ltd. | Quantizing and dequantizing circuit with reduced size |
US5737020A (en) | 1995-03-27 | 1998-04-07 | International Business Machines Corporation | Adaptive field/frame encoding of discrete cosine transform |
US5764805A (en) | 1995-10-25 | 1998-06-09 | David Sarnoff Research Center, Inc. | Low bit rate video encoder using overlapping block motion compensation and zerotree wavelet coding |
US5767908A (en) | 1994-12-19 | 1998-06-16 | Samsung Electronics Co., Ltd. | Adaptive orthogonal transform coding apparatus |
US5872866A (en) | 1995-04-18 | 1999-02-16 | Advanced Micro Devices, Inc. | Method and apparatus for improved video decompression by predetermination of IDCT results based on image characteristics |
WO1999018735A1 (en) | 1997-10-07 | 1999-04-15 | Thomson Consumer Electronics, Inc. | Picture masking and compositing in the frequency domain |
US5903669A (en) | 1995-01-31 | 1999-05-11 | Canon Kabushiki Kaisha | Image processing apparatus and method |
US6108383A (en) | 1997-07-15 | 2000-08-22 | On2.Com, Inc. | Method and apparatus for compression and decompression of video images |
US6115501A (en) | 1995-07-10 | 2000-09-05 | Hyundai Electronics Industries Co., Ltd. | Grid moving method for minimizing image information of an object |
US6134350A (en) | 1998-02-18 | 2000-10-17 | Dome Imaging Systems, Inc. | Method of producing wavelets and compressing digital images and of restoring the digital images |
US6167161A (en) | 1996-08-23 | 2000-12-26 | Nec Corporation | Lossless transform coding system having compatibility with lossy coding |
US6408025B1 (en) | 1997-01-31 | 2002-06-18 | Siemens Aktiengesellschaft | Method and configuration for coding and decoding digitized pictures |
US20020168114A1 (en) | 2001-02-06 | 2002-11-14 | Valente Stephane Edouard | Preprocessing method applied to textures of arbitrarily shaped objects |
US20020196983A1 (en) | 1997-10-22 | 2002-12-26 | Yoshikazu Kobayashi | Image encoding apparatus, image encoding method, and recording medium in which image encoding program is recorded |
US6522783B1 (en) | 1999-11-23 | 2003-02-18 | Sharp Laboratories Of America, Inc. | Re-indexing for efficient compression of palettized images |
US6522784B1 (en) | 2000-04-11 | 2003-02-18 | International Business Machines Corporation | Enhanced compression of gray-level images |
US20030048943A1 (en) | 1997-11-27 | 2003-03-13 | Seiko Epson Corporation | Encoding method of a color image and its encoding device and a decoding method of the color image and its decoding device |
US20030146925A1 (en) | 1997-11-12 | 2003-08-07 | Canon Kabushiki Kaisha | Generating and using a color palette |
US6683991B1 (en) | 1998-10-30 | 2004-01-27 | Canon Kabushiki Kaisha | Method and apparatus for representing a digital image to provide a coded representation |
US20040057519A1 (en) | 2002-09-24 | 2004-03-25 | Matsushita Electric Industrial Co., Ltd. | Image coding method and apparatus |
US20040125204A1 (en) | 2002-12-27 | 2004-07-01 | Yoshihisa Yamada | Moving picture coding apparatus and moving picture decoding apparatus |
US20040184537A1 (en) | 2002-08-09 | 2004-09-23 | Ralf Geiger | Method and apparatus for scalable encoding and method and apparatus for scalable decoding |
US6819793B1 (en) | 2000-06-30 | 2004-11-16 | Intel Corporation | Color distribution for texture and image compression |
US20050025246A1 (en) | 2003-07-18 | 2005-02-03 | Microsoft Corporation | Decoding jointly coded transform type and subblock pattern information |
US20050053151A1 (en) | 2003-09-07 | 2005-03-10 | Microsoft Corporation | Escape mode code resizing for fields and slices |
US20050147163A1 (en) | 2003-12-30 | 2005-07-07 | Microsoft Corporation | Scalable video transcoding |
US6917651B1 (en) | 2000-01-28 | 2005-07-12 | Samsung Electronics Co., Ltd. | Variable length coding method and apparatus |
US20050249291A1 (en) | 2004-05-07 | 2005-11-10 | Stephen Gordon | Method and system for generating a transform size syntax element for video decoding |
US20060045368A1 (en) | 2002-06-28 | 2006-03-02 | Microsoft Corporation | Rate allocation for mixed content video |
US20060098738A1 (en) | 2003-01-09 | 2006-05-11 | Pamela Cosman | Video encoding methods and devices |
US20060115168A1 (en) | 2004-11-30 | 2006-06-01 | Canon Kabushiki Kaisha | Image coding apparatus and image coding method |
US20060133682A1 (en) | 2004-12-17 | 2006-06-22 | Microsoft Corporation | Reversible overlap operator for efficient lossless data compression |
US7082221B1 (en) | 2000-09-29 | 2006-07-25 | Intel Corporation | Bandwidth determination for multiple layer digital video |
US20060210181A1 (en) | 1996-07-03 | 2006-09-21 | Hsi-Jung Wu | Digital image coding system having self-adjusting selection criteria for selecting a transform function |
US20060239575A1 (en) | 2002-04-15 | 2006-10-26 | Kiyofumi Abe | Picture coding method and picture decoding method |
US20060251330A1 (en) | 2003-05-20 | 2006-11-09 | Peter Toth | Hybrid video compression method |
US20070036223A1 (en) | 2005-08-12 | 2007-02-15 | Microsoft Corporation | Efficient coding and decoding of transform blocks |
US20070078661A1 (en) | 2005-09-30 | 2007-04-05 | Portalplayer, Inc. | Configurable system for performing repetitive actions and method for configuring and operating same |
US20070140349A1 (en) | 2004-03-01 | 2007-06-21 | Koninklijke Philips Electronics, N.V. | Video encoding method and apparatus |
US20070183500A1 (en) | 2006-02-09 | 2007-08-09 | Nagaraj Raghavendra C | Video encoding |
US20070201554A1 (en) | 2006-02-24 | 2007-08-30 | Samsung Electronics Co., Ltd. | Video transcoding method and apparatus |
US7266149B2 (en) | 2001-12-17 | 2007-09-04 | Microsoft Corporation | Sub-block transform coding of prediction residuals |
US20070211953A1 (en) | 2006-03-07 | 2007-09-13 | Yukihiro Sasagawa | Signal processor |
US20070223583A1 (en) | 2000-10-31 | 2007-09-27 | Takeshi Nagai | Data transmission apparatus and method |
US20080008246A1 (en) | 2006-07-05 | 2008-01-10 | Debargha Mukherjee | Optimizing video coding |
US20080043848A1 (en) | 1999-11-29 | 2008-02-21 | Kuhn Peter M | Video/audio signal processing method and video/audio signal processing apparatus |
US20080084929A1 (en) | 2006-10-05 | 2008-04-10 | Xiang Li | Method for video coding a sequence of digitized images |
US20080123736A1 (en) | 2005-09-20 | 2008-05-29 | Mitsubishi Electric Corporation | Image encoding method and image decoding method, image encoder and image decoder, and image encoded bit stream and recording medium |
US20080123947A1 (en) | 2005-07-22 | 2008-05-29 | Mitsubishi Electric Corporation | Image encoding device, image decoding device, image encoding method, image decoding method, image encoding program, image decoding program, computer readable recording medium having image encoding program recorded therein |
US20080123977A1 (en) | 2005-07-22 | 2008-05-29 | Mitsubishi Electric Corporation | Image encoder and image decoder, image encoding method and image decoding method, image encoding program and image decoding program, and computer readable recording medium recorded with image encoding program and computer readable recording medium recorded with image decoding program |
US7409099B1 (en) | 2004-08-10 | 2008-08-05 | On2 Technologies, Inc. | Method of improved image/video compression via data re-ordering |
US20080253463A1 (en) | 2007-04-13 | 2008-10-16 | Apple Inc. | Method and system for video encoding and decoding |
US20080310512A1 (en) | 2007-06-15 | 2008-12-18 | Qualcomm Incorporated | Separable directional transforms |
US20090041128A1 (en) | 2002-02-28 | 2009-02-12 | At&T Intellectual Property Ii, L.P., Formerly Known As At&T Corp. | System and method for using pattern vectors for video and image coding and decoding |
US7492823B2 (en) | 1997-07-16 | 2009-02-17 | Samsung Electronics Co., Ltd. | Signal adaptive filtering method, signal adaptive filter and computer readable medium for storing program therefor |
US20090049641A1 (en) | 2006-03-08 | 2009-02-26 | Pullins Alan T | Vacuum cleaner with wand activated conversion valve |
US20090067503A1 (en) | 2006-01-07 | 2009-03-12 | Electronics And Telecommunications Research Institute | Method and apparatus for video data encoding and decoding |
US20090123066A1 (en) | 2005-07-22 | 2009-05-14 | Mitsubishi Electric Corporation | Image encoding device, image decoding device, image encoding method, image decoding method, image encoding program, image decoding program, computer readable recording medium having image encoding program recorded therein, |
US20090122864A1 (en) | 2005-11-08 | 2009-05-14 | Matsushita Electric Industrial Co., Ltd. | Moving picture coding method, moving picture decoding method, and apparatuses of the same |
US20090228290A1 (en) | 2002-09-04 | 2009-09-10 | Microsoft Corporation | Mixed lossless audio compression |
US20090274382A1 (en) | 2008-05-02 | 2009-11-05 | Novateck Microelectronics Corp. | Entropy decoding circuit, entropy decoding method, and entropy decoding method using pipeline manner |
US20100020867A1 (en) | 2007-01-18 | 2010-01-28 | Thomas Wiegand | Quality Scalable Video Data Stream |
WO2010039288A1 (en) | 2008-10-03 | 2010-04-08 | Qualcomm Incorporated | Digital video coding with interpolation filters and offsets |
WO2010039015A2 (en) | 2008-10-02 | 2010-04-08 | 한국전자통신연구원 | Apparatus and method for coding/decoding image selectivly using descrete cosine/sine transtorm |
US20100086049A1 (en) | 2008-10-03 | 2010-04-08 | Qualcomm Incorporated | Video coding using transforms bigger than 4x4 and 8x8 |
JP2010199959A (en) | 2009-02-25 | 2010-09-09 | Nippon Telegr & Teleph Corp <Ntt> | Image-coding apparatus, image-coding method and image-coding program |
US20100246951A1 (en) | 2009-03-31 | 2010-09-30 | Canon Kabushiki Kaisha | Colour correcting foreground colours for visual quality improvement |
US20100290520A1 (en) | 2009-05-14 | 2010-11-18 | Massachusetts Institute Of Technology | Selecting transforms for compressing visual data |
US20100309286A1 (en) | 2009-06-05 | 2010-12-09 | Qualcomm Incorporated | Encoding of three-dimensional conversion information with two-dimensional video sequence |
US20110032983A1 (en) | 2009-08-07 | 2011-02-10 | Osman Gokhan Sezer | Probabilistic Bit-Rate and Rate-Distortion Cost Estimation for Video Coding |
US7894530B2 (en) | 2004-05-07 | 2011-02-22 | Broadcom Corporation | Method and system for dynamic selection of transform size in a video decoder based on signal content |
US7912318B2 (en) | 2007-10-29 | 2011-03-22 | Canon Kabushiki Kaisha | Data transform apparatus and control method thereof |
US20110090959A1 (en) | 2008-04-16 | 2011-04-21 | Fraunhofer-Gesellschaft Zur Foerderung Der Angewandten Forschung E.V. | Bit-depth scalability |
WO2011049399A2 (en) | 2009-10-24 | 2011-04-28 | Park Chul | Method for processing advertising message |
US7936820B2 (en) | 2004-12-22 | 2011-05-03 | Nec Corporation | Moving-picture compression encoding method, apparatus and program |
US20110182352A1 (en) | 2005-03-31 | 2011-07-28 | Pace Charles P | Feature-Based Video Compression |
US8000546B2 (en) | 2008-08-01 | 2011-08-16 | National Cheng Kung University | Adaptive scan method for image/video coding |
US20110206135A1 (en) | 2008-10-28 | 2011-08-25 | Virginie Drugeon | Image coding method, image decoding method, image coding apparatus, image decoding apparatus, integrated circuit and program |
US20110243249A1 (en) | 2010-04-05 | 2011-10-06 | Samsung Electronics Co., Ltd. | Method and apparatus for encoding video by performing in-loop filtering based on tree-structured data unit, and method and apparatus for decoding video by performing the same |
US20110268183A1 (en) | 2009-01-27 | 2011-11-03 | Thomson Licensing | Method and apparatus for transform selection in video encoding and decoding |
US20110274162A1 (en) | 2010-05-04 | 2011-11-10 | Minhua Zhou | Coding Unit Quantization Parameters in Video Coding |
US20110293012A1 (en) | 2010-05-27 | 2011-12-01 | The Hong Kong University Of Science And Technology | Motion estimation of images |
US20110293009A1 (en) | 2010-05-27 | 2011-12-01 | Freescale Semiconductor Inc. | Video processing system, computer program product and method for managing a transfer of information between a memory unit and a decoder |
WO2012005099A1 (en) | 2010-07-09 | 2012-01-12 | ソニー株式会社 | Image processing device, and image processing method |
US20120008683A1 (en) | 2010-07-09 | 2012-01-12 | Qualcomm Incorporated | Signaling selected directional transform for video coding |
US20120057360A1 (en) | 2010-09-02 | 2012-03-08 | S&S Precision, Llc | Integrated Illumination Device Mount |
US20120057630A1 (en) | 2010-09-08 | 2012-03-08 | Samsung Electronics Co., Ltd. | Low complexity transform coding using adaptive dct/dst for intra-prediction |
US20120128066A1 (en) | 2009-08-06 | 2012-05-24 | Panasonic Corporation | Encoding method, decoding method, encoding device and decoding device |
US20120162455A1 (en) | 2010-12-23 | 2012-06-28 | Samsung Electronics Co., Ltd. | Digital image processing apparatus including handshake correction module and methods of controlling the digital image processing apparatus |
US20120170649A1 (en) | 2010-12-29 | 2012-07-05 | Qualcomm Incorporated | Video coding using mapped transforms and scanning modes |
US20120177116A1 (en) | 2011-01-12 | 2012-07-12 | General Instrument Corporation | Efficient Transform Unit Representation |
US20120195378A1 (en) | 2011-01-28 | 2012-08-02 | Qualcomm Incorporated | Pixel level adaptive intra-smoothing |
US20120201298A1 (en) | 2011-02-04 | 2012-08-09 | General Instrument Corporation | Implicit Transform Unit Representation |
US20120230418A1 (en) | 2011-03-08 | 2012-09-13 | Qualcomm Incorporated | Coding of transform coefficients for video coding |
US20120230411A1 (en) | 2011-03-09 | 2012-09-13 | Mediatek Singapore Pte. Ltd. | Method and Apparatus of Transform Unit Partition with Reduced Complexity |
WO2012166959A1 (en) | 2011-06-02 | 2012-12-06 | Qualcomm Incorporated | Fast computing of discrete cosine and sine transforms of types vi and vii |
US20120308128A1 (en) | 2011-05-30 | 2012-12-06 | Fujifilm Corporation | Image data coding apparatus, method of controlling operation of same, and program therefor |
US20130003859A1 (en) | 2011-06-30 | 2013-01-03 | Qualcomm Incorporated | Transition between run and level coding modes |
US20130003828A1 (en) | 2011-07-01 | 2013-01-03 | Cohen Robert A | Method for Selecting Transform Types From Mapping Table for Prediction Modes |
US20130003824A1 (en) | 2011-07-01 | 2013-01-03 | Qualcomm Incorporated | Applying non-square transforms to video data |
US20130022107A1 (en) | 2011-07-19 | 2013-01-24 | Qualcomm Incorporated | Deblocking of non-square blocks for video coding |
US20130034152A1 (en) | 2010-04-16 | 2013-02-07 | Sk Telecom Co., Ltd. | Apparatus and method for encoding/decoding images |
US20130034169A1 (en) | 2011-08-05 | 2013-02-07 | Mangesh Devidas Sadafale | Block-Based Parallel Deblocking Filter in Video Coding |
US20130070845A1 (en) | 2009-08-07 | 2013-03-21 | Korea Advanced Institute Of Science And Technology | Motion picture encoding apparatus and method thereof |
US20130089145A1 (en) | 2011-10-11 | 2013-04-11 | Qualcomm Incorporated | Most probable transform for intra prediction coding |
US20130089138A1 (en) | 2011-06-27 | 2013-04-11 | Qualcomm Incorporated | Coding syntax elements using vlc codewords |
US20130114730A1 (en) | 2011-11-07 | 2013-05-09 | Qualcomm Incorporated | Coding significant coefficient information in transform skip mode |
US20130128974A1 (en) | 2011-11-18 | 2013-05-23 | Qualcomm Incorporated | Adaptive overlapped block motion compensation |
US20130136175A1 (en) | 2011-09-12 | 2013-05-30 | Qualcomm Incorporated | Non-square transform units and prediction units in video coding |
US20130176211A1 (en) | 2010-09-13 | 2013-07-11 | Sony Computer Entertainment Inc. | Image processing device for displaying moving image and image processing method thereof |
US8494290B2 (en) | 2011-05-05 | 2013-07-23 | Mitsubishi Electric Research Laboratories, Inc. | Method for coding pictures using hierarchical transform units |
US20130243083A1 (en) | 2012-03-16 | 2013-09-19 | Texas Instruments Incorporated | Low-Complexity Two-Dimensional (2D) Separable Transform Design with Transpose Buffer Management |
US20130272422A1 (en) | 2010-06-11 | 2013-10-17 | Joo Hyun Min | System and method for encoding/decoding videos using edge-adaptive transform |
US20130315303A1 (en) | 2009-08-17 | 2013-11-28 | Samsung Electronics Co., Ltd. | Method and apparatus for encoding video, and method and apparatus for decoding video |
US20130336410A1 (en) | 2012-06-15 | 2013-12-19 | Research In Motion Limited | Methods and devices for coding binary symbols as n-tuples |
US20140010295A1 (en) | 2011-01-21 | 2014-01-09 | Thomson Licensing | Methods and Apparatus for Geometric-Based Intra Prediction |
WO2014031544A1 (en) | 2012-08-21 | 2014-02-27 | Qualcomm Incorporated | Alternative transform in scalable video coding |
US20140086314A1 (en) | 2012-09-26 | 2014-03-27 | Magnum Semiconductor, Inc. | Apparatuses and methods for optimizing rate-distortion of syntax elements |
US8687699B1 (en) | 2006-05-16 | 2014-04-01 | Geo Semiconductor Inc | Method and/or apparatus for optimized video coding |
US20140092956A1 (en) | 2012-09-29 | 2014-04-03 | Motorola Mobility Llc | Adaptive transform options for scalable extension |
WO2014078703A1 (en) | 2012-11-19 | 2014-05-22 | Qualcomm Incorporated | Intra base layer transform selection (dst vs. dct) in video coding |
WO2014075552A1 (en) | 2012-11-15 | 2014-05-22 | Mediatek Inc. | Inter-layer texture coding with adaptive transform and multiple inter-layer motion candidates |
US20140204999A1 (en) | 2011-09-20 | 2014-07-24 | Lg Electronics Inc. | Method and apparatus for encoding/decoding image information |
US20140247872A1 (en) * | 2011-11-11 | 2014-09-04 | Fraunhofer-Gesellschaft Zur Foerderung Der Angewandten Forschung E.V. | Effective wedgelet partition coding |
US9106933B1 (en) | 2010-05-18 | 2015-08-11 | Google Inc. | Apparatus and method for encoding video using different second-stage transform |
US9219915B1 (en) | 2013-01-17 | 2015-12-22 | Google Inc. | Selection of transform size in video coding |
US9565451B1 (en) | 2014-10-31 | 2017-02-07 | Google Inc. | Prediction dependent transform coding |
US20180338143A1 (en) * | 2015-10-16 | 2018-11-22 | Sisvel Technology S.R.L. | Apparatuses and methods for encoding and decoding images |
US10257543B2 (en) * | 2011-01-10 | 2019-04-09 | Qualcomm Incorporated | Identification of samples in a transition zone |
US10356420B2 (en) * | 2014-11-16 | 2019-07-16 | Lg Electronics Inc. | Video signal processing method using graph based transform and device therefor |
-
2019
- 2019-05-03 US US16/402,297 patent/US11122297B2/en active Active
Patent Citations (151)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4774574A (en) | 1987-06-02 | 1988-09-27 | Eastman Kodak Company | Adaptive block transform image coding method and apparatus |
US5444800A (en) | 1988-11-18 | 1995-08-22 | At&T Corp. | Side-match and overlap-match vector quantizers for images |
US5121216A (en) | 1989-07-19 | 1992-06-09 | Bell Communications Research | Adaptive transform coding of still images |
US5235623A (en) | 1989-11-14 | 1993-08-10 | Nec Corporation | Adaptive transform coding by selecting optimum block lengths according to variatons between successive blocks |
US5091782A (en) | 1990-04-09 | 1992-02-25 | General Instrument Corporation | Apparatus and method for adaptively compressing successive blocks of digital video |
US5068724A (en) | 1990-06-15 | 1991-11-26 | General Instrument Corporation | Adaptive motion compensation for digital television |
US5146324A (en) | 1990-07-31 | 1992-09-08 | Ampex Corporation | Data compression using a feedforward quantization estimator |
US5341440A (en) | 1991-07-12 | 1994-08-23 | Earl Joseph G | Method and apparatus for increasing information compressibility |
US5260782A (en) | 1991-08-30 | 1993-11-09 | Matsushita Electric Industrial Co., Ltd. | Adaptive DCT/DPCM video signal coding method |
US5274442A (en) | 1991-10-22 | 1993-12-28 | Mitsubishi Denki Kabushiki Kaisha | Adaptive blocking image signal coding system |
US5224062A (en) | 1992-03-17 | 1993-06-29 | Sun Microsystems, Inc. | Method and apparatus for fast implementation of inverse discrete cosine transform in a digital image processing system using optimized lookup tables |
US5422963A (en) | 1993-10-15 | 1995-06-06 | At&T Corp. | Block transform coder for arbitrarily shaped image segments |
US5635938A (en) | 1993-12-28 | 1997-06-03 | Oki Electric Industry Co., Ltd. | Quantizing and dequantizing circuit with reduced size |
US5767908A (en) | 1994-12-19 | 1998-06-16 | Samsung Electronics Co., Ltd. | Adaptive orthogonal transform coding apparatus |
US5903669A (en) | 1995-01-31 | 1999-05-11 | Canon Kabushiki Kaisha | Image processing apparatus and method |
US5737020A (en) | 1995-03-27 | 1998-04-07 | International Business Machines Corporation | Adaptive field/frame encoding of discrete cosine transform |
US5872866A (en) | 1995-04-18 | 1999-02-16 | Advanced Micro Devices, Inc. | Method and apparatus for improved video decompression by predetermination of IDCT results based on image characteristics |
US6115501A (en) | 1995-07-10 | 2000-09-05 | Hyundai Electronics Industries Co., Ltd. | Grid moving method for minimizing image information of an object |
US5764805A (en) | 1995-10-25 | 1998-06-09 | David Sarnoff Research Center, Inc. | Low bit rate video encoder using overlapping block motion compensation and zerotree wavelet coding |
US20060210181A1 (en) | 1996-07-03 | 2006-09-21 | Hsi-Jung Wu | Digital image coding system having self-adjusting selection criteria for selecting a transform function |
US6167161A (en) | 1996-08-23 | 2000-12-26 | Nec Corporation | Lossless transform coding system having compatibility with lossy coding |
US6408025B1 (en) | 1997-01-31 | 2002-06-18 | Siemens Aktiengesellschaft | Method and configuration for coding and decoding digitized pictures |
US6108383A (en) | 1997-07-15 | 2000-08-22 | On2.Com, Inc. | Method and apparatus for compression and decompression of video images |
US7492823B2 (en) | 1997-07-16 | 2009-02-17 | Samsung Electronics Co., Ltd. | Signal adaptive filtering method, signal adaptive filter and computer readable medium for storing program therefor |
WO1999018735A1 (en) | 1997-10-07 | 1999-04-15 | Thomson Consumer Electronics, Inc. | Picture masking and compositing in the frequency domain |
US20020196983A1 (en) | 1997-10-22 | 2002-12-26 | Yoshikazu Kobayashi | Image encoding apparatus, image encoding method, and recording medium in which image encoding program is recorded |
US20030146925A1 (en) | 1997-11-12 | 2003-08-07 | Canon Kabushiki Kaisha | Generating and using a color palette |
US20030048943A1 (en) | 1997-11-27 | 2003-03-13 | Seiko Epson Corporation | Encoding method of a color image and its encoding device and a decoding method of the color image and its decoding device |
US6134350A (en) | 1998-02-18 | 2000-10-17 | Dome Imaging Systems, Inc. | Method of producing wavelets and compressing digital images and of restoring the digital images |
US6683991B1 (en) | 1998-10-30 | 2004-01-27 | Canon Kabushiki Kaisha | Method and apparatus for representing a digital image to provide a coded representation |
US6522783B1 (en) | 1999-11-23 | 2003-02-18 | Sharp Laboratories Of America, Inc. | Re-indexing for efficient compression of palettized images |
US20080043848A1 (en) | 1999-11-29 | 2008-02-21 | Kuhn Peter M | Video/audio signal processing method and video/audio signal processing apparatus |
US6917651B1 (en) | 2000-01-28 | 2005-07-12 | Samsung Electronics Co., Ltd. | Variable length coding method and apparatus |
US6934419B2 (en) | 2000-04-11 | 2005-08-23 | International Business Machines Corporation | Enhanced compression of gray-level images |
US6522784B1 (en) | 2000-04-11 | 2003-02-18 | International Business Machines Corporation | Enhanced compression of gray-level images |
US6819793B1 (en) | 2000-06-30 | 2004-11-16 | Intel Corporation | Color distribution for texture and image compression |
US7082221B1 (en) | 2000-09-29 | 2006-07-25 | Intel Corporation | Bandwidth determination for multiple layer digital video |
US20070223583A1 (en) | 2000-10-31 | 2007-09-27 | Takeshi Nagai | Data transmission apparatus and method |
US20020168114A1 (en) | 2001-02-06 | 2002-11-14 | Valente Stephane Edouard | Preprocessing method applied to textures of arbitrarily shaped objects |
US7266149B2 (en) | 2001-12-17 | 2007-09-04 | Microsoft Corporation | Sub-block transform coding of prediction residuals |
US20090041128A1 (en) | 2002-02-28 | 2009-02-12 | At&T Intellectual Property Ii, L.P., Formerly Known As At&T Corp. | System and method for using pattern vectors for video and image coding and decoding |
US20060239575A1 (en) | 2002-04-15 | 2006-10-26 | Kiyofumi Abe | Picture coding method and picture decoding method |
US20060045368A1 (en) | 2002-06-28 | 2006-03-02 | Microsoft Corporation | Rate allocation for mixed content video |
US20040184537A1 (en) | 2002-08-09 | 2004-09-23 | Ralf Geiger | Method and apparatus for scalable encoding and method and apparatus for scalable decoding |
US20090228290A1 (en) | 2002-09-04 | 2009-09-10 | Microsoft Corporation | Mixed lossless audio compression |
US7292634B2 (en) | 2002-09-24 | 2007-11-06 | Matsushita Electric Industrial Co., Ltd. | Image coding method and apparatus |
US20040057519A1 (en) | 2002-09-24 | 2004-03-25 | Matsushita Electric Industrial Co., Ltd. | Image coding method and apparatus |
US20040125204A1 (en) | 2002-12-27 | 2004-07-01 | Yoshihisa Yamada | Moving picture coding apparatus and moving picture decoding apparatus |
US20060098738A1 (en) | 2003-01-09 | 2006-05-11 | Pamela Cosman | Video encoding methods and devices |
US20060251330A1 (en) | 2003-05-20 | 2006-11-09 | Peter Toth | Hybrid video compression method |
US20050025246A1 (en) | 2003-07-18 | 2005-02-03 | Microsoft Corporation | Decoding jointly coded transform type and subblock pattern information |
US20050053151A1 (en) | 2003-09-07 | 2005-03-10 | Microsoft Corporation | Escape mode code resizing for fields and slices |
US20050147163A1 (en) | 2003-12-30 | 2005-07-07 | Microsoft Corporation | Scalable video transcoding |
US20070140349A1 (en) | 2004-03-01 | 2007-06-21 | Koninklijke Philips Electronics, N.V. | Video encoding method and apparatus |
US7894530B2 (en) | 2004-05-07 | 2011-02-22 | Broadcom Corporation | Method and system for dynamic selection of transform size in a video decoder based on signal content |
US20050249291A1 (en) | 2004-05-07 | 2005-11-10 | Stephen Gordon | Method and system for generating a transform size syntax element for video decoding |
US8116374B2 (en) | 2004-05-07 | 2012-02-14 | Broadcom Corporation | Method and system for generating a transform size syntax element for video decoding |
US7409099B1 (en) | 2004-08-10 | 2008-08-05 | On2 Technologies, Inc. | Method of improved image/video compression via data re-ordering |
US20060115168A1 (en) | 2004-11-30 | 2006-06-01 | Canon Kabushiki Kaisha | Image coding apparatus and image coding method |
US20060133682A1 (en) | 2004-12-17 | 2006-06-22 | Microsoft Corporation | Reversible overlap operator for efficient lossless data compression |
US7936820B2 (en) | 2004-12-22 | 2011-05-03 | Nec Corporation | Moving-picture compression encoding method, apparatus and program |
US20110182352A1 (en) | 2005-03-31 | 2011-07-28 | Pace Charles P | Feature-Based Video Compression |
US20080123977A1 (en) | 2005-07-22 | 2008-05-29 | Mitsubishi Electric Corporation | Image encoder and image decoder, image encoding method and image decoding method, image encoding program and image decoding program, and computer readable recording medium recorded with image encoding program and computer readable recording medium recorded with image decoding program |
US20080123947A1 (en) | 2005-07-22 | 2008-05-29 | Mitsubishi Electric Corporation | Image encoding device, image decoding device, image encoding method, image decoding method, image encoding program, image decoding program, computer readable recording medium having image encoding program recorded therein |
US20090123066A1 (en) | 2005-07-22 | 2009-05-14 | Mitsubishi Electric Corporation | Image encoding device, image decoding device, image encoding method, image decoding method, image encoding program, image decoding program, computer readable recording medium having image encoding program recorded therein, |
US20070036223A1 (en) | 2005-08-12 | 2007-02-15 | Microsoft Corporation | Efficient coding and decoding of transform blocks |
US20080123736A1 (en) | 2005-09-20 | 2008-05-29 | Mitsubishi Electric Corporation | Image encoding method and image decoding method, image encoder and image decoder, and image encoded bit stream and recording medium |
US20070078661A1 (en) | 2005-09-30 | 2007-04-05 | Portalplayer, Inc. | Configurable system for performing repetitive actions and method for configuring and operating same |
US20090122864A1 (en) | 2005-11-08 | 2009-05-14 | Matsushita Electric Industrial Co., Ltd. | Moving picture coding method, moving picture decoding method, and apparatuses of the same |
US20090067503A1 (en) | 2006-01-07 | 2009-03-12 | Electronics And Telecommunications Research Institute | Method and apparatus for video data encoding and decoding |
US20070183500A1 (en) | 2006-02-09 | 2007-08-09 | Nagaraj Raghavendra C | Video encoding |
US20070201554A1 (en) | 2006-02-24 | 2007-08-30 | Samsung Electronics Co., Ltd. | Video transcoding method and apparatus |
US8094950B2 (en) | 2006-03-07 | 2012-01-10 | Panasonic Corporation | Signal processor |
US20070211953A1 (en) | 2006-03-07 | 2007-09-13 | Yukihiro Sasagawa | Signal processor |
US20090049641A1 (en) | 2006-03-08 | 2009-02-26 | Pullins Alan T | Vacuum cleaner with wand activated conversion valve |
US8687699B1 (en) | 2006-05-16 | 2014-04-01 | Geo Semiconductor Inc | Method and/or apparatus for optimized video coding |
US20080008246A1 (en) | 2006-07-05 | 2008-01-10 | Debargha Mukherjee | Optimizing video coding |
US20080084929A1 (en) | 2006-10-05 | 2008-04-10 | Xiang Li | Method for video coding a sequence of digitized images |
US20100020867A1 (en) | 2007-01-18 | 2010-01-28 | Thomas Wiegand | Quality Scalable Video Data Stream |
US8582656B2 (en) | 2007-04-13 | 2013-11-12 | Apple Inc. | Method and system for video encoding and decoding |
US20080253463A1 (en) | 2007-04-13 | 2008-10-16 | Apple Inc. | Method and system for video encoding and decoding |
US20080310512A1 (en) | 2007-06-15 | 2008-12-18 | Qualcomm Incorporated | Separable directional transforms |
US7912318B2 (en) | 2007-10-29 | 2011-03-22 | Canon Kabushiki Kaisha | Data transform apparatus and control method thereof |
US20110090959A1 (en) | 2008-04-16 | 2011-04-21 | Fraunhofer-Gesellschaft Zur Foerderung Der Angewandten Forschung E.V. | Bit-depth scalability |
US20090274382A1 (en) | 2008-05-02 | 2009-11-05 | Novateck Microelectronics Corp. | Entropy decoding circuit, entropy decoding method, and entropy decoding method using pipeline manner |
US8000546B2 (en) | 2008-08-01 | 2011-08-16 | National Cheng Kung University | Adaptive scan method for image/video coding |
US20110286516A1 (en) | 2008-10-02 | 2011-11-24 | Electronics And Telecommunications Research Instit | Apparatus and method for coding/decoding image selectivly using descrete cosine/sine transtorm |
WO2010039015A2 (en) | 2008-10-02 | 2010-04-08 | 한국전자통신연구원 | Apparatus and method for coding/decoding image selectivly using descrete cosine/sine transtorm |
US20100086049A1 (en) | 2008-10-03 | 2010-04-08 | Qualcomm Incorporated | Video coding using transforms bigger than 4x4 and 8x8 |
WO2010039288A1 (en) | 2008-10-03 | 2010-04-08 | Qualcomm Incorporated | Digital video coding with interpolation filters and offsets |
US20110206135A1 (en) | 2008-10-28 | 2011-08-25 | Virginie Drugeon | Image coding method, image decoding method, image coding apparatus, image decoding apparatus, integrated circuit and program |
US20110268183A1 (en) | 2009-01-27 | 2011-11-03 | Thomson Licensing | Method and apparatus for transform selection in video encoding and decoding |
JP2010199959A (en) | 2009-02-25 | 2010-09-09 | Nippon Telegr & Teleph Corp <Ntt> | Image-coding apparatus, image-coding method and image-coding program |
US20100246951A1 (en) | 2009-03-31 | 2010-09-30 | Canon Kabushiki Kaisha | Colour correcting foreground colours for visual quality improvement |
US20100290520A1 (en) | 2009-05-14 | 2010-11-18 | Massachusetts Institute Of Technology | Selecting transforms for compressing visual data |
US20100309286A1 (en) | 2009-06-05 | 2010-12-09 | Qualcomm Incorporated | Encoding of three-dimensional conversion information with two-dimensional video sequence |
US20120128066A1 (en) | 2009-08-06 | 2012-05-24 | Panasonic Corporation | Encoding method, decoding method, encoding device and decoding device |
US20130070845A1 (en) | 2009-08-07 | 2013-03-21 | Korea Advanced Institute Of Science And Technology | Motion picture encoding apparatus and method thereof |
US20110032983A1 (en) | 2009-08-07 | 2011-02-10 | Osman Gokhan Sezer | Probabilistic Bit-Rate and Rate-Distortion Cost Estimation for Video Coding |
US20130315303A1 (en) | 2009-08-17 | 2013-11-28 | Samsung Electronics Co., Ltd. | Method and apparatus for encoding video, and method and apparatus for decoding video |
WO2011049399A2 (en) | 2009-10-24 | 2011-04-28 | Park Chul | Method for processing advertising message |
US20110243249A1 (en) | 2010-04-05 | 2011-10-06 | Samsung Electronics Co., Ltd. | Method and apparatus for encoding video by performing in-loop filtering based on tree-structured data unit, and method and apparatus for decoding video by performing the same |
US20130034152A1 (en) | 2010-04-16 | 2013-02-07 | Sk Telecom Co., Ltd. | Apparatus and method for encoding/decoding images |
US20110274162A1 (en) | 2010-05-04 | 2011-11-10 | Minhua Zhou | Coding Unit Quantization Parameters in Video Coding |
US9106933B1 (en) | 2010-05-18 | 2015-08-11 | Google Inc. | Apparatus and method for encoding video using different second-stage transform |
US20110293012A1 (en) | 2010-05-27 | 2011-12-01 | The Hong Kong University Of Science And Technology | Motion estimation of images |
US20110293009A1 (en) | 2010-05-27 | 2011-12-01 | Freescale Semiconductor Inc. | Video processing system, computer program product and method for managing a transfer of information between a memory unit and a decoder |
US20130272422A1 (en) | 2010-06-11 | 2013-10-17 | Joo Hyun Min | System and method for encoding/decoding videos using edge-adaptive transform |
US20120008683A1 (en) | 2010-07-09 | 2012-01-12 | Qualcomm Incorporated | Signaling selected directional transform for video coding |
WO2012005099A1 (en) | 2010-07-09 | 2012-01-12 | ソニー株式会社 | Image processing device, and image processing method |
US20130156328A1 (en) | 2010-07-09 | 2013-06-20 | Peng Wang | Image processing device and image processing method |
US20120008682A1 (en) * | 2010-07-09 | 2012-01-12 | Qualcomm Incorporated | Video coding using directional transforms |
US20120057360A1 (en) | 2010-09-02 | 2012-03-08 | S&S Precision, Llc | Integrated Illumination Device Mount |
US8885701B2 (en) | 2010-09-08 | 2014-11-11 | Samsung Electronics Co., Ltd. | Low complexity transform coding using adaptive DCT/DST for intra-prediction |
US20120057630A1 (en) | 2010-09-08 | 2012-03-08 | Samsung Electronics Co., Ltd. | Low complexity transform coding using adaptive dct/dst for intra-prediction |
US20130176211A1 (en) | 2010-09-13 | 2013-07-11 | Sony Computer Entertainment Inc. | Image processing device for displaying moving image and image processing method thereof |
US20120162455A1 (en) | 2010-12-23 | 2012-06-28 | Samsung Electronics Co., Ltd. | Digital image processing apparatus including handshake correction module and methods of controlling the digital image processing apparatus |
US20120170649A1 (en) | 2010-12-29 | 2012-07-05 | Qualcomm Incorporated | Video coding using mapped transforms and scanning modes |
US10257543B2 (en) * | 2011-01-10 | 2019-04-09 | Qualcomm Incorporated | Identification of samples in a transition zone |
US20120177116A1 (en) | 2011-01-12 | 2012-07-12 | General Instrument Corporation | Efficient Transform Unit Representation |
US20140010295A1 (en) | 2011-01-21 | 2014-01-09 | Thomson Licensing | Methods and Apparatus for Geometric-Based Intra Prediction |
US20120195378A1 (en) | 2011-01-28 | 2012-08-02 | Qualcomm Incorporated | Pixel level adaptive intra-smoothing |
US20120201298A1 (en) | 2011-02-04 | 2012-08-09 | General Instrument Corporation | Implicit Transform Unit Representation |
US20120230418A1 (en) | 2011-03-08 | 2012-09-13 | Qualcomm Incorporated | Coding of transform coefficients for video coding |
US20120230411A1 (en) | 2011-03-09 | 2012-09-13 | Mediatek Singapore Pte. Ltd. | Method and Apparatus of Transform Unit Partition with Reduced Complexity |
US8494290B2 (en) | 2011-05-05 | 2013-07-23 | Mitsubishi Electric Research Laboratories, Inc. | Method for coding pictures using hierarchical transform units |
US20120308128A1 (en) | 2011-05-30 | 2012-12-06 | Fujifilm Corporation | Image data coding apparatus, method of controlling operation of same, and program therefor |
WO2012166959A1 (en) | 2011-06-02 | 2012-12-06 | Qualcomm Incorporated | Fast computing of discrete cosine and sine transforms of types vi and vii |
US20130089138A1 (en) | 2011-06-27 | 2013-04-11 | Qualcomm Incorporated | Coding syntax elements using vlc codewords |
US20130003859A1 (en) | 2011-06-30 | 2013-01-03 | Qualcomm Incorporated | Transition between run and level coding modes |
US20130003824A1 (en) | 2011-07-01 | 2013-01-03 | Qualcomm Incorporated | Applying non-square transforms to video data |
US20130003828A1 (en) | 2011-07-01 | 2013-01-03 | Cohen Robert A | Method for Selecting Transform Types From Mapping Table for Prediction Modes |
US20130022107A1 (en) | 2011-07-19 | 2013-01-24 | Qualcomm Incorporated | Deblocking of non-square blocks for video coding |
US20130034169A1 (en) | 2011-08-05 | 2013-02-07 | Mangesh Devidas Sadafale | Block-Based Parallel Deblocking Filter in Video Coding |
US20130136175A1 (en) | 2011-09-12 | 2013-05-30 | Qualcomm Incorporated | Non-square transform units and prediction units in video coding |
US20140204999A1 (en) | 2011-09-20 | 2014-07-24 | Lg Electronics Inc. | Method and apparatus for encoding/decoding image information |
US20130089145A1 (en) | 2011-10-11 | 2013-04-11 | Qualcomm Incorporated | Most probable transform for intra prediction coding |
US20130114730A1 (en) | 2011-11-07 | 2013-05-09 | Qualcomm Incorporated | Coding significant coefficient information in transform skip mode |
US20140247872A1 (en) * | 2011-11-11 | 2014-09-04 | Fraunhofer-Gesellschaft Zur Foerderung Der Angewandten Forschung E.V. | Effective wedgelet partition coding |
US20130128974A1 (en) | 2011-11-18 | 2013-05-23 | Qualcomm Incorporated | Adaptive overlapped block motion compensation |
US20130243083A1 (en) | 2012-03-16 | 2013-09-19 | Texas Instruments Incorporated | Low-Complexity Two-Dimensional (2D) Separable Transform Design with Transpose Buffer Management |
US20130336410A1 (en) | 2012-06-15 | 2013-12-19 | Research In Motion Limited | Methods and devices for coding binary symbols as n-tuples |
WO2014031544A1 (en) | 2012-08-21 | 2014-02-27 | Qualcomm Incorporated | Alternative transform in scalable video coding |
US20140086314A1 (en) | 2012-09-26 | 2014-03-27 | Magnum Semiconductor, Inc. | Apparatuses and methods for optimizing rate-distortion of syntax elements |
US20140092956A1 (en) | 2012-09-29 | 2014-04-03 | Motorola Mobility Llc | Adaptive transform options for scalable extension |
WO2014075552A1 (en) | 2012-11-15 | 2014-05-22 | Mediatek Inc. | Inter-layer texture coding with adaptive transform and multiple inter-layer motion candidates |
WO2014078703A1 (en) | 2012-11-19 | 2014-05-22 | Qualcomm Incorporated | Intra base layer transform selection (dst vs. dct) in video coding |
US9219915B1 (en) | 2013-01-17 | 2015-12-22 | Google Inc. | Selection of transform size in video coding |
US9565451B1 (en) | 2014-10-31 | 2017-02-07 | Google Inc. | Prediction dependent transform coding |
US10356420B2 (en) * | 2014-11-16 | 2019-07-16 | Lg Electronics Inc. | Video signal processing method using graph based transform and device therefor |
US20180338143A1 (en) * | 2015-10-16 | 2018-11-22 | Sisvel Technology S.R.L. | Apparatuses and methods for encoding and decoding images |
Non-Patent Citations (36)
Title |
---|
"Introduction to Video Coding Part 1: Transform Coding", Mozilla, Mar. 2012, 171 pp. |
"Overview VP7 Data Format and Decoder", Version 1.5, On2 Technologies, Inc., Mar. 28, 2005, 65 pp. |
Aguiar et al.; "Maximizing compression efficiency through block rotation"; https://www.researchgate.net/publication/268452118; Nov. 2014. |
Bankoski et al. "Technical Overview of VP8, an Open Source Video Codec for the Web". Dated Jul. 11, 2011. |
Bankoski et al., "VP8 Data Format and Decoding Guide draft-bankoski-vp8-bitstream-02", Network Working Group, Internet-Draft, May 18, 2011, 288 pp. |
Bankoski et al., "VP8 Data Format and Decoding Guide", Independent Submission RFC 6389, Nov. 2011, 305 pp. |
Bross, B, H. Kirchofter, H. Schwarz, T. Wiegand,"Fast intra encoding for fixed maximum depth of transform quadtree," JCTVC-C311_r1 , Guangzhou, CN, Oct. 2010. |
Bross, B, W.-J Han, J.-R. Ohm, G. J. Sullivan, T. Wiegand: "High efficiency video coding (HEVC) text specification draft 7", Document of Joint Collaborative Team on Video Coding, JCTVC-I1003-d4, Apr. 27-May 7, 2012. |
Chen J. et al "Description of scalable video coding technology proposal by Qualcomm (configuration)", 11. JCT-VC Meeting; 102. MPEG Meeting; Oct. 10, 2012 Oct. 19, 2012; Shanghai; (Joint Collaborative Team on Video Coding of ISO/IEC JTC1/SC29/WG11 and ITU-T SG.16); URL:http:/wftp3.itu.int/av-arch/jctvc-site/, No. JCTVC-K0035, Oct. 2, 2012, all pages. |
Chen J. et al., "TE:Simulation results for various max number of transform quadtree depth," MPEG Meeting, Guangzhou, Chima; No. M18236; Oct. 28, 2010. |
Chen P. et al., "Video coding using extended block sizes," VCEG Meeting, San Diego, US; No. VCEG-AJ23, Oct. 15, 2008. |
Chen, Y, J. Han, T. Nanjundaswamy, and K. Rose, "A joint spatio-temporal filtering approach to efficient prediction in video compression," Picture Coding Symposium, 2013. |
Guo L et al.: "Transform Selection for Inter-Layer Texture Prediction in Scalable Video Coding", 11. JCT-VC Meeting; 102; MPEG Meeting; Oct. 10-19, 2012; Shanghai; (Joint Collaborative Team on Video Coding of ISO/IEC JTC1/WG11 and ITU-T SG.16); URL:http://wftp3.itu.int/av-arch/jctvc-site/,, No. JCTVC-K0321, Oct. 7, 2012, all pages. |
Han et al., "Jointly Optimized Spatial Prediction and Block Transform for Video and Image Coding," IEEE Transactions on Image Processing, vol. 21, No. 4 (Apr. 2012). |
Han et al., "Toward Jointly Optimal Spatial Prediction and Adaptive Transform in Video/Image Coding," ICASSP 2010 (Dallas, TX, Mar. 14-19, 2010). |
International Preliminary Report and Written Opinion of the International Searching Authority for International Application No. PCT/US2013062216 dated Mar. 31, 2015. |
Krit Panusopone et al., "Flexible Picture Partitioning", JCT-VC (Joint Collaborative Team on Video Coding) JCTVC-C260, Meeting, Oct. 7-15, 2010. |
Krit Panusopone, et al. "Efficient Transform Unit Representation," Joint Collaborative Team on Video Coding (JCT-VC) of UTU-T SG16 WP3 and ISO/IEC JTC1/SC29/WG11 4nd Meeting: Daegu, KR, Jan. 22, 2011. |
Lee B. et al., "Hierarchical variable block transform," JCT-VC Meeting, Geneva, Switzerland; No. JCTVC-B050; Jul. 24, 2010. |
Lee T et al.: "TE12.1: Experimental results of transform unit quadtree/2-level test", 3 JCT-VC Meeting; 94. MPEG Meeting; Oct. 7-15, 2010; Guangzhou; (Joint Collaborative Team on Video Coding of ISO/IEC JTC1/SC29/WG11 and ITU-T SG.16); URL:http://wtfp3.itu.int/av-arch/jctvc-site/,, No. JCTVC-C200, Oct. 2, 2010, all pages. |
McCann et al., "Samsung's Response to the call for proposals on video compression technology" JCTVC of ITU-T SG16 WP3 and ISO/IEC JTC1/SC29/WG11; 1st meeting; Dresden, DE, Apr. 15-23, 2010; JCTVC124; 42 pages. |
McCann K. et al.; "Video coding technology proposal by samsung (and BBC)," JCT-VC Meeting; Dresden, Germany, Apr. 15, 2010. |
Park et al.; "Accurate Image Rotation using Hermite Expansions" IEEE Trans Image Process. Sep. 2009; 18(9):1988-2003. |
Saxena A et al.: "On secondary transforms for Intra BVL residue", 13. JCT-VC Meeting; 104. MPEG Meeting; Apr. 18-26, 2013; IncHEON; (Joint Collaborative Team on Video Coding of ISO/IEC JTC1/SC29/WG11 and ITU-T SG.16); URL:http://wftp3.itu.int/av-arch/jctvc-site/, No. JCTVC-M0033, Apr. 9, 2013, all pages. |
Saxena A et al.: "On secondary transforms for intra/inter prediction residual", 9. JCT-VC Meeting; 100. MPEG Meeting; Apr. 27-May 7, 2012; Geneva; (Joint Collaborative Team on Video Coding of ISO/IEC JTC1/SC29/WG11 and ITU-T SG.16); URL:http:/wftp3.itu.int/av-arch/jctvc-site/,, No. JCTVC-10232, Apr. 17, 2012, all pages. |
Series H: Audiovisual and Multimedia Systems, Infrastructure of audiovisual services—Coding of moving video, Advanced video coding for generic audiovisual services, Amendment 1: Support of additional colour spaces and removal of the High 4:4:4 Profile, International Telecommunication Union, Jun. 2006, 16 pp. |
Series H: Audiovisual and Multimedia Systems, Infrastructure of audiovisual services—Coding of moving video, Advanced video coding for generic audiovisual services, Version 3, International Telecommunication Union, Mar. 2005, 343 pp. |
Series H: Audiovisual and Multimedia Systems, Infrastructure of audiovisual services—Coding of moving video, Amendment 2: New profiles for professional applications, International Telecommunication Union, Apr. 2007, 75 pp. |
Sikora, T. et al, Shape-adaptive DCT for generic coding of video, Circuits and Systems for Video Technology, IEEE Transactions on vol. 5, Issue 1, p. 59-62, Feb. 1, 1995. |
VP6 Bitstream and Decoder Specification, Version 1.03, (On2 Technologies, Inc.), Dated Oct. 29, 2007. |
Wiegand et al, "Overview of the H 264/AVC Video Coding Standard," IEEE Transactions on Circuits and Systems for Video Technology, vol. 13, No. 7, pp. 568, 569, Jul. 1, 2003. |
Wiegand et al. "BoG report: residual quadtree structure" JCTVC-C319_r1, Guangzhou, CN Oct. 2010. |
Wiegand, T; B. Bross, J. Ohm, G. Sullivan, "WD1: Working Draft 1 of High-Efficiency Video Coding," JCTVC-C403, Guangzhou, CN, Oct. 7-15, 2010. |
Wiegand, Thomas, et al.; "Rate-Distortion Optimized Mode Selection for Very Low Bit Rate Video Coding and the Emerging H.263 Standard", IEEE Transactions on Circuits and Systems for Video Technology, vol. 6, No. 2, Apr. 1996, 9 pp. |
Wiegand, Thomas, et al.; Long-Term Memory Motion-Compensated Prediction, date unknown. |
Xin, J., K. N. Ngan, and G. Zhu, "Combined inter-intra prediction for high definition video coding," Picture Coding Symposium, 2007. |
Also Published As
Publication number | Publication date |
---|---|
US20200351520A1 (en) | 2020-11-05 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US10992939B2 (en) | Directional intra-prediction coding | |
US11457239B2 (en) | Block artefact reduction | |
US10104398B2 (en) | Super-transform video coding | |
US10848787B2 (en) | Lossy image compression using palettization of locally mixed colors | |
US10542258B2 (en) | Tile copying for video compression | |
US11917156B2 (en) | Adaptation of scan order for entropy coding | |
US11153588B2 (en) | Dual deblocking filter thresholds | |
US9998753B1 (en) | Prediction dependent transform coding | |
US11122297B2 (en) | Using border-aligned block functions for image compression | |
US10652552B1 (en) | Efficient noise reduction coding | |
US11849113B2 (en) | Quantization constrained neural image coding | |
US11695919B2 (en) | Lossy image compression using palettization of locally mixed colors | |
US10567807B1 (en) | Adjustable per-symbol entropy coding probability updating for image and video coding | |
US10645418B2 (en) | Morphological anti-ringing filter for lossy image compression | |
US20240089433A1 (en) | Chroma Transform Type Determination | |
US11012714B1 (en) | Image coding using lexicographic coding order with floating block-partitioning | |
US11234022B2 (en) | Iterative IDCT with adaptive non-linear filtering | |
US20230291925A1 (en) | Inter-Intra Prediction With Implicit Models |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:FISCHBACHER, THOMAS;VANDEVENNE, LODE;REEL/FRAME:049069/0654Effective date: 20190423 |
|
FEPP | Fee payment procedure |
Free format text: ENTITY STATUS SET TO UNDISCOUNTED (ORIGINAL EVENT CODE: BIG.); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: ADVISORY ACTION MAILED |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: DOCKETED NEW CASE - READY FOR EXAMINATION |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NOTICE OF ALLOWANCE MAILED -- APPLICATION RECEIVED IN OFFICE OF PUBLICATIONS |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: PUBLICATIONS -- ISSUE FEE PAYMENT VERIFIED |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |