JP5524965B2 - Inspection in geographic information system - Google Patents
Inspection in geographic information system Download PDFInfo
- Publication number
- JP5524965B2 JP5524965B2 JP2011522976A JP2011522976A JP5524965B2 JP 5524965 B2 JP5524965 B2 JP 5524965B2 JP 2011522976 A JP2011522976 A JP 2011522976A JP 2011522976 A JP2011522976 A JP 2011522976A JP 5524965 B2 JP5524965 B2 JP 5524965B2
- Authority
- JP
- Japan
- Prior art keywords
- tour
- time
- virtual camera
- feature
- geographic information
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
- 238000007689 inspection Methods 0.000 title claims description 66
- 230000009471 action Effects 0.000 claims description 67
- 238000000034 method Methods 0.000 claims description 40
- 230000008859 change Effects 0.000 claims description 7
- 230000004044 response Effects 0.000 claims description 7
- 238000010586 diagram Methods 0.000 description 12
- 230000003993 interaction Effects 0.000 description 5
- 230000007704 transition Effects 0.000 description 4
- 230000000694 effects Effects 0.000 description 3
- 230000006870 function Effects 0.000 description 3
- 238000004091 panning Methods 0.000 description 2
- 238000012545 processing Methods 0.000 description 2
- 241000220010 Rhode Species 0.000 description 1
- 230000006978 adaptation Effects 0.000 description 1
- 238000013459 approach Methods 0.000 description 1
- 238000004891 communication Methods 0.000 description 1
- 238000012986 modification Methods 0.000 description 1
- 230000004048 modification Effects 0.000 description 1
- 230000002441 reversible effect Effects 0.000 description 1
- 238000012546 transfer Methods 0.000 description 1
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T17/00—Three dimensional [3D] modelling, e.g. data description of 3D objects
- G06T17/05—Geographic models
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T19/00—Manipulating 3D models or images for computer graphics
- G06T19/003—Navigation within 3D models or images
Description
本発明は、地理情報システムにおいてナビゲートすることに関する。 The present invention relates to navigating in a geographic information system.
地理情報システム（ＧＩＳ）は、データ要素の地理座標に従ってインデックスされたデータをアーカイブ、検索、表示、および／または操作するためのシステムである。データ要素は、例えば、建物および地形、ならびに他の地理的特徴の画像、地図、モデル等の多様なデータタイプであり得る。 A geographic information system (GIS) is a system for archiving, searching, displaying, and / or manipulating data indexed according to the geographic coordinates of data elements. Data elements can be a variety of data types, for example, images of buildings and terrain, and other geographic features, maps, models, and the like.
地理情報システムは、仮想カメラの視点から、地理情報をユーザに表示することができる。仮想カメラの視点は、位置および配向によって定義され得る。仮想カメラの位置および配向を変更することによって、ユーザは、地理情報内において見物することが可能である。例えば、ユーザは、仮想カメラの視点をエッフェルタワーを表現するものの方向へ向けることによって、ＧＩＳ内のエッフェルタワーを「見学する」ことができる。 The geographic information system can display geographic information to the user from the viewpoint of the virtual camera. The viewpoint of the virtual camera can be defined by position and orientation. By changing the position and orientation of the virtual camera, the user can see in the geographic information. For example, the user can “see” the Eiffel Tower in the GIS by directing the virtual camera's viewpoint toward the one representing the Eiffel Tower.
仮想カメラの視点は、キーホールマークアップ言語（ＫＭＬ）等の言語において保管され得る。ＫＭＬを解釈して、ＧＩＳは、光景を表示するために仮想カメラを保管された視点に移動させることができる。保管された視点を使用して、ユーザは光景に戻ることが可能である。さらに、ＫＭＬは、視点のシーケンスを保管することが可能である。ＫＭＬを解釈して、ＧＩＳは、仮想カメラをある視点から次の視点へと反復して移動させることができる。これによって、ユーザは、一連の光景、例えば、エッフェルタワー、ビッグベン時計台等を見ることが可能になる。しかしながら、この手法は、限定されたユーザ体験を提供するだけの場合がある。 Virtual camera viewpoints can be stored in languages such as Keyhole Markup Language (KML). Interpreting KML, GIS can move the virtual camera to a stored viewpoint to display the scene. Using the stored viewpoint, the user can return to the scene. Furthermore, KML can store a sequence of viewpoints. Interpreting KML, the GIS can repeatedly move the virtual camera from one viewpoint to the next. This allows the user to see a series of sights, such as the Eiffel Tower, Big Ben Clock Tower, etc. However, this approach may only provide a limited user experience.
地理情報における満足度の高いユーザ体験を提供する見物するための方法およびシステムが必要とされる。 What is needed is a method and system for viewing that provides a satisfying user experience in geographic information.
本発明は、地理情報システムにおいてナビゲートすることに関する。実施形態において、方法は、地理情報システム内の地理情報を視察する。視察のための一式の動作が受信される。各動作は、視察時間を含む。動作のうちの少なくとも１つの視察時間は、ユーザによって定義される。一式の動作の中の各動作は、地理情報システム内の地理情報を視察するように実行される。 The present invention relates to navigating in a geographic information system. In an embodiment, the method inspects geographic information in the geographic information system. A set of actions for a tour is received. Each operation includes an inspection time. The tour time for at least one of the actions is defined by the user. Each operation in the set of operations is performed to view geographic information in the geographic information system.
第２の実施形態において、地理情報システムは、地理情報を視察する。地理情報システムは、視察のための一式の動作を受信する視察コントローラを含む。各動作は、視察時間を含む。動作のうちの少なくとも１つの視察時間は、ユーザによって定義され、地理情報システム内の地理情報を視察するように、一式の動作の中の各動作を実行する。 In the second embodiment, the geographic information system inspects geographic information. The geographic information system includes a tour controller that receives a set of operations for the tour. Each operation includes an inspection time. The tour time of at least one of the operations is defined by the user and performs each operation in the set of operations to tour the geographic information in the geographic information system.
第３の実施形態において、方法は、地理情報システム内の地理情報を視察する。視察のための一式の動作が受信される。一式の動作の中の少なくとも１つの動作は、地物時間を含む。地物が受信される。地物は、地理情報内の関連地物期間および位置を有する。一式の動作の中の各動作は、地理情報システム内の地理情報を視察するように実行される。現在の地物時間は、現在の視察時間に基づいて決定される。現在の地物が関連地物期間内にあり、かつ位置が仮想カメラの視錐台内にある時、地物が表示される。 In a third embodiment, the method inspects geographic information in the geographic information system. A set of actions for a tour is received. At least one operation in the set of operations includes feature time. A feature is received. A feature has an associated feature period and location in the geographic information. Each operation in the set of operations is performed to view geographic information in the geographic information system. The current feature time is determined based on the current tour time. A feature is displayed when the current feature is within the relevant feature period and the position is within the view frustum of the virtual camera.
本発明のさらなる実施形態、特長、および利点、ならびに本発明の多様な実施形態の構造および操作は、添付の図面を参照して以下に詳細を説明する。
本明細書は、例えば、以下を提供する。
（項目１）
地理情報システム内の地理情報を視察するための方法であって、
（ａ）視察のための一式の動作を受信することであって、各動作は、視察時間を含み、該動作のうちの少なくとも１つの視察時間は、ユーザによって定義されることと、
（ｂ）該地理情報システム内の地理情報を視察するように、該一式の動作の各動作を実行することと
を含む、方法。
（項目２）
上記実行すること（ｂ）は、上記地理情報を視察するように、上記一式の動作の中の少なくとも１つの動作に従い、上記地理情報システムの仮想カメラを移動させることを含む、項目１に記載の方法。
（項目３）
上記受信すること（ａ）は、上記視察のための一式の動作を受信することを含み、該一式の動作の中の少なくとも１つの動作は、地物時間を含む、項目２に記載の方法。
（項目４）
（ｃ）上記地理情報内の関連地物期間および位置を有する地物を受信することと、
（ｄ）現在の視察時間に基づいて現在の地物時間を決定することと、
（ｅ）該現在の地物時間が該関連地物期間中にあり、かつ該位置が上記仮想カメラの視錐台内にある場合に、該地物を表示することと
をさらに含む、項目３に記載の方法。
（項目５）
（ｃ）上記一式の動作の中の２つ以上の動作に基づいて、スプラインを補間することをさらに含み、
上記実行すること（ｂ）は、該スプラインに沿って上記仮想カメラを移動させることをさらに含む、
項目２に記載の方法。
（項目６）
（ｃ）ユーザが、上記視察を一時停止、巻き戻し、または早送りすることを可能にすることをさらに含む、項目２に記載の方法。
（項目７）
（ｃ）ユーザが、上記一式の動作を定義することを可能にすることをさらに含む、項目２に記載の方法。
（項目８）
上記可能にすること（ｃ）は、
（ｉ）ユーザが、上記仮想カメラを移動させるための動作を定義することを可能にすることと、
（ｉｉ）上記仮想カメラの位置を記録することと
を含む、項目７に記載の方法。
（項目９）
（ｃ）第１のユーザ入力に応答して、上記視察をオーバーライドすることをさらに含む、項目２に記載の方法。
（項目１０）
上記オーバーライドすること（ｃ）は、第２のユーザ入力に応答して、上記仮想カメラの配向を変更することを含む、項目９に記載の方法。
（項目１１）
上記オーバーライドすること（ｃ）は、
（ｉ）第２のユーザ入力に従って、上記仮想カメラを上記視察の経路の外に移動させることと、
（ｉｉ）第３のユーザ入力に応答して、該仮想カメラを該視察の経路に戻すことと
を含む、項目９に記載の方法。
（項目１２）
上記受信すること（ａ）は、ＫＭＬファイルを解析することを含む、項目２に記載の方法。
（項目１３）
上記実行すること（ｂ）は、仮想カメラを写真の中に移動させることをさらに含む、項目２に記載の方法。
（項目１４）
上記一式の動作の中の動作に従い、音を再生することをさらに含む、項目２に記載の方法。
（項目１５）
上記一式の動作の中の動作に従い、上記地理情報システム内の地物に関連する状態値を更新することをさらに含む、項目２に記載の方法。
（項目１６）
地理情報を視察するための地理情報システムであって、
視察コントローラを備え、該視察コントローラは、
視察のための一式の動作を受信することであって、各動作は、視察時間を含み、該動作のうちの少なくとも１つの視察時間は、ユーザによって定義される、ことと、
該地理情報システム内の地理情報を視察するように、該一式の動作の中の各動作を実行することと
を行う、システム。
（項目１７）
上記視察コントローラは、上記地理情報を視察するように、上記一式の動作の中の少なくとも１つの動作に従い、上記地理情報システムの仮想カメラを移動させる、項目１６に記載のシステム。
（項目１８）
上記一式の動作の中の少なくとも１つの動作は、地物時間を含む、項目１７に記載のシステム。
（項目１９）
上記視察コントローラは、上記地理情報内の関連地物期間および位置を有する地物を受信し、上記視察内の現在時間に基づいて、現在の地物時間を決定し、該現在の地物時間が該関連地物期間中にあり、該位置が上記仮想カメラの視錐台内にある場合に、該地物を表示するように、信号を送信する、項目１８に記載のシステム。
（項目２０）
上記視察コントローラは、上記一式の動作の中の２つ以上の動作に基づいて、スプラインを補間し、該スプラインに沿って上記仮想カメラを移動させる、項目１９に記載のシステム。
（項目２１）
上記視察コントローラは、ユーザが、上記視察を一時停止、巻き戻し、または早送りすることを可能にする、項目１６に記載のシステム。
（項目２２）
ユーザが上記一式の動作を定義することを可能にする、視察エディタをさらに備えている、項目１６に記載のシステム。
（項目２３）
仮想カメラの位置を記録する、視察レコーダをさらに備えている、項目２２に記載のシステム。
（項目２４）
上記視察コントローラは、ユーザ入力に応答して、上記視察をオーバーライドする、項目１６に記載のシステム。
（項目２５）
上記視察コントローラは、ユーザ入力に従って、上記仮想カメラの配向を変更する、項目２４に記載のシステム。
（項目２６）
上記視察コントローラは、上記視察を一時停止する、項目２４に記載のシステム。
（項目２７）
視察インタプリタが、ＫＭＬファイルを解析する、項目２４に記載のシステム。
（項目２８）
上記視察コントローラは、ユーザ入力に従って、上記仮想カメラの配向を変更する、項目２７に記載のシステム。
（項目２９）
上記視察コントローラは、上記一式の動作の中の動作に従って、仮想カメラを写真の中に移動させる、項目１６に記載のシステム。
（項目３０）
上記視察コントローラは、上記一式の動作の中の動作に従い、音を再生する、項目１６に記載のシステム。
（項目３１）
上記視察コントローラは、情報吹き出しを表示する、項目１６に記載のシステム。
（項目３２）
上記視察コントローラは、制御命令を受信し、該制御命令に基づいて、上記一式の動作の中の動作を実行する、項目１６に記載のシステム。
（項目３３）
上記制御命令は、上記視察コントローラに、上記動作のうちの少なくとも一部を繰り返し実行するように命令する、項目３２に記載のシステム。
（項目３４）
地理情報システム内の地理情報を視察するための方法であって、
（ａ）視察のための一式の動作を受信することであって、該一式の動作の中の少なくとも１つの動作は、地物時間を含む、ことと、
（ｂ）該地理情報内の関連地物期間および位置を有する地物を受信することと、
（ｃ）該地理情報システム内の地理情報を視察するように、該一式の動作の中の各動作を実行することと、
（ｄ）現在の視察時間に基づいて現在の地物時間を決定することと、
（ｅ）該現在の地物時間が該関連地物期間中にあり、かつ該位置が仮想カメラの視錐台内にある場合に、該地物を表示することと
を含む、方法。
（項目３５）
地理情報システム内の地理情報を視察するためのシステムであって、
視察のための一式の動作を受信するための手段であって、各動作は、視察時間を含み、該動作のうちの少なくとも１つの視察時間は、ユーザによって定義される、手段と、
該地理情報システム内の地理情報を視察するように、該一式の動作の中の各動作を実行する手段と
を備えている、システム。
Further embodiments, features, and advantages of the present invention, as well as the structure and operation of the various embodiments of the present invention, are described in detail below with reference to the accompanying drawings.
This specification provides the following, for example.
(Item 1)
A method for inspecting geographic information in a geographic information system, comprising:
(A) receiving a set of actions for a tour, each action including a tour time, at least one of the visits being defined by the user;
(B) performing each operation of the set of operations to inspect the geographic information in the geographic information system;
Including a method.
(Item 2)
The item of claim 1, wherein performing (b) includes moving a virtual camera of the geographic information system in accordance with at least one of the operations of the set to observe the geographic information. Method.
(Item 3)
The method of item 2, wherein receiving (a) includes receiving a set of actions for the tour, wherein at least one action in the set includes feature time.
(Item 4)
(C) receiving a feature having an associated feature period and position in the geographic information;
(D) determining the current feature time based on the current visit time;
(E) displaying the feature if the current feature time is during the related feature period and the position is within the view frustum of the virtual camera;
The method according to item 3, further comprising:
(Item 5)
(C) further comprising interpolating a spline based on two or more operations in the set of operations;
Said performing (b) further comprises moving said virtual camera along said spline;
Item 3. The method according to Item 2.
(Item 6)
(C) The method of item 2, further comprising allowing a user to pause, rewind, or fast forward the visit.
(Item 7)
(C) The method of item 2, further comprising allowing a user to define the set of actions.
(Item 8)
The above enabling (c)
(I) allowing a user to define an action for moving the virtual camera;
(Ii) recording the position of the virtual camera;
The method according to item 7, comprising:
(Item 9)
(C) The method of item 2, further comprising overriding the visit in response to a first user input.
(Item 10)
10. The method of item 9, wherein overriding (c) includes changing the orientation of the virtual camera in response to a second user input.
(Item 11)
The overriding (c)
(I) moving the virtual camera out of the tour path in accordance with a second user input;
(Ii) in response to a third user input, returning the virtual camera to the tour path;
The method according to item 9, comprising:
(Item 12)
The method according to item 2, wherein the receiving (a) includes analyzing the KML file.
(Item 13)
The method of item 2, wherein performing (b) further comprises moving a virtual camera into the photograph.
(Item 14)
The method of item 2, further comprising playing a sound according to an action in the set of actions.
(Item 15)
The method of item 2, further comprising updating a state value associated with a feature in the geographic information system according to an operation in the set of operations.
(Item 16)
A geographic information system for inspecting geographic information,
An inspection controller, the inspection controller comprising:
Receiving a set of actions for a tour, each action including a visit time, at least one of the visits being defined by the user;
Performing each operation in the set of operations to inspect the geographic information in the geographic information system;
Do the system.
(Item 17)
The system according to item 16, wherein the inspection controller moves a virtual camera of the geographic information system according to at least one operation in the set of operations so as to observe the geographic information.
(Item 18)
18. The system of item 17, wherein at least one operation in the set of operations includes feature time.
(Item 19)
The tour controller receives a feature having an associated feature period and position in the geographic information, determines a current feature time based on the current time in the tour, and the current feature time. 19. The system of item 18, wherein the system transmits a signal to display the feature when it is during the related feature period and the position is within the frustum of the virtual camera.
(Item 20)
20. The system of item 19, wherein the inspection controller interpolates a spline and moves the virtual camera along the spline based on two or more actions in the set of actions.
(Item 21)
17. The system of item 16, wherein the tour controller allows a user to pause, rewind, or fast forward the tour.
(Item 22)
Item 18. The system of item 16, further comprising a tour editor that allows a user to define the set of actions.
(Item 23)
The system according to item 22, further comprising an inspection recorder for recording the position of the virtual camera.
(Item 24)
17. The system of item 16, wherein the tour controller overrides the tour in response to user input.
(Item 25)
25. A system according to item 24, wherein the inspection controller changes the orientation of the virtual camera according to a user input.
(Item 26)
The system according to Item 24, wherein the inspection controller temporarily stops the inspection.
(Item 27)
25. A system according to item 24, wherein the inspection interpreter analyzes the KML file.
(Item 28)
28. The system according to item 27, wherein the inspection controller changes the orientation of the virtual camera according to a user input.
(Item 29)
The system according to item 16, wherein the inspection controller moves the virtual camera into the photograph according to an operation in the set of operations.
(Item 30)
Item 17. The system according to Item 16, wherein the inspection controller reproduces sound according to an operation in the set of operations.
(Item 31)
The system according to item 16, wherein the inspection controller displays an information balloon.
(Item 32)
The system according to item 16, wherein the inspection controller receives a control command and executes an operation in the set of operations based on the control command.
(Item 33)
33. A system according to item 32, wherein the control command instructs the inspection controller to repeatedly execute at least a part of the operations.
(Item 34)
A method for inspecting geographic information in a geographic information system, comprising:
(A) receiving a set of actions for a tour, wherein at least one action in the set includes feature time;
(B) receiving a feature having an associated feature period and location in the geographic information;
(C) performing each operation in the set of operations to inspect the geographic information in the geographic information system;
(D) determining the current feature time based on the current visit time;
(E) displaying the feature if the current feature time is during the related feature period and the position is within the view frustum of the virtual camera;
Including a method.
(Item 35)
A system for inspecting geographic information in a geographic information system,
Means for receiving a set of actions for a tour, each action including a tour time, wherein at least one of the visit times is defined by a user;
Means for performing each operation in the set of operations to inspect the geographic information in the geographic information system;
System.
本明細書に組み入れられ、仕様の一部を形成する添付の図面は、本発明を図説し、さらに、詳細説明と併せて本発明の原理を説明し、当業者が本発明を作製および使用することを可能にすることを目的とする。
要素が最初に示される図面は、典型的に、対応する参照番号の左端の数字によって示される。図面において、同様な参照番号は、同一または機能的に類似の要素を示し得る。 The drawing in which an element is first shown is typically indicated by the leftmost digit (s) in the corresponding reference number. In the drawings, like reference numbers can indicate identical or functionally similar elements.
本発明は、地理情報システムにおいて視察することに関する。以下の実施形態の詳細説明において、「一実施形態」、「実施形態」、「例示的実施形態」等への参照は、説明される実施形態が、特定の特長、構造、または特性を含むことができるが、あらゆる実施形態が、特定の特長、構造、または特性を必ずしも含まなくてもよいことを示す。さらに、このような語句は、必ずしも同じ実施形態を参照していない。その上、特定の特長、構造、または特性が、実施形態に関係して説明される時、明示的に説明されているかどうかに関わらず、このような特長、構造、または特性を他の実施形態に関係して達成することは、当業者の知識の範囲内であると考えられる。 The present invention relates to viewing in a geographic information system. In the detailed description of the embodiments below, references to “one embodiment”, “embodiments”, “exemplary embodiments” and the like include the specific features, structures, or characteristics of the described embodiments. However, it is shown that every embodiment may not necessarily include a particular feature, structure, or characteristic. Moreover, such phrases are not necessarily referring to the same embodiment. Moreover, when a particular feature, structure, or characteristic is described in connection with an embodiment, such feature, structure, or characteristic may be used in other embodiments regardless of whether it is explicitly described. To achieve within the scope of knowledge of those skilled in the art.
実施形態は、ｈｔｔｐ：／／ｅａｒｔｈ．ｇｏｏｇｌｅ．ｃｏｍで利用可能である、Ｇｏｏｇｌｅ（登録商標）Ｅａｒｔｈシステム等のＧＩＳにおいて、案内付き視察体験を提供する。案内付き視察体験を提供するために、実施形態は視察のための時系列を維持する。仮想カメラを新しい位置に移動させる等の視察に関する各動作は、視察時系列内の視察時間を有する。視察時系列上の定義される時間に動作を実行することによって、実施形態は、より満足度の高いユーザ体験を提供する。 Embodiments can be found at http: // earth. Google. A guided tour experience is provided at GIS, such as the Google® Earth system, available at In order to provide a guided tour experience, embodiments maintain a timeline for the tour. Each operation related to the inspection such as moving the virtual camera to a new position has an inspection time within the inspection time series. By performing actions at defined times on the tour timeline, embodiments provide a more satisfying user experience.
実施形態において、ユーザは、視察のための一式の動作を定義することができる。本明細書においてフライツー動作として参照され得る、一種の動作は、地理データ内の視察時間および位置を含むことができる。フライツー動作から、地理情報を通る経路が決定され得る。仮想カメラは、経路に沿って移動することができる。経路を通じて移動する場合、フライツー動作の視察時間に従って、仮想カメラの速度が決定され得る。一実施形態において、動作の視察時間は、カメラが、動作によって定義される位置に到達する時間を特定することができる。別の実施形態において、視察時間は、カメラが特定の位置で静止する期間を指定することができる。仮想カメラの速度を規制するために動作の視察時間を使用することによって、本発明の実施形態は、ユーザにより満足度の高いユーザ体験を提供する。 In an embodiment, the user can define a set of actions for the tour. One type of operation, which may be referred to herein as a fly-to operation, may include tour time and location within geographic data. From the fly-to operation, a route through the geographic information can be determined. The virtual camera can move along the path. When moving through the path, the speed of the virtual camera may be determined according to the tour time of the fly-to operation. In one embodiment, the motion tour time may specify the time for the camera to reach a position defined by the motion. In another embodiment, the tour time can specify a period of time during which the camera is stationary at a particular location. By using motion tour time to regulate virtual camera speed, embodiments of the present invention provide a more satisfying user experience for the user.
実施形態において、ユーザは視察をオーバーライドすることができる。例えば、ユーザは、一時停止、巻き戻し、早送り、および章のスキップ等の時系列制御で、視察を中断することができる。これらの制御を使用して、ユーザは、視察時間の経過を制御することができる。さらに、視察が中断される時、ユーザは、周囲の三次元環境を探索するように、視察経路から外れることができる。ユーザは、視察を再開することができ、これによって、仮想カメラを視察経路に戻す。 In an embodiment, the user can override the tour. For example, the user can interrupt the inspection by time-series control such as pause, rewind, fast-forward, and chapter skip. Using these controls, the user can control the course of the tour time. Further, when the tour is interrupted, the user can leave the tour path to explore the surrounding 3D environment. The user can resume the tour, thereby returning the virtual camera to the tour path.
別の実施例において、ユーザは、仮想カメラの配向を変更することによって、視察をオーバーライドすることができる。この様式において、ユーザは、視察中に「周囲を見物する」ことができる。周囲を見物することによって、視察の進行を妨げる場合も妨げない場合もある。これらの特長もまた、より満足度の高いユーザ体験を提供する。 In another example, the user can override the tour by changing the orientation of the virtual camera. In this manner, the user can “look around” during the tour. Viewing the surroundings may or may not interfere with the progress of the tour. These features also provide a more satisfying user experience.
さらなる実施形態において、視察は、ＧＩＳにおいて定義される過去を通って巡回する。空間的に登録されることに加えて、ＧＩＳ内の地物（ｆｅａｔｕｒｅ）は、時間的に登録され得る。例えば、ＧＩＳは、空間的にギリシャのローデス島に登録され、かつ時間的に紀元前２８０〜２２６年に登録されるアポロ像を有することができる。明確化のために、ＧＩＳ内の地物に関連する時間は、本明細書では「地物時間」と称される。視察は、ユーザに地物時間を通過させることができる。例えば、各動作は、それに関連する地物時間を有することができる。動作に基づいて、視察時間と、地物時間と、位置との間の関係が決定され得る。視察時間が経過するにつれて、仮想カメラの位置および地物時間のどちらも変化することができる。この様式において、視察を再生しているＧＩＳは、ユーザに、古代ギリシャのアポロ像の後に、現代のパリのエッフェルタワーを見せることができる。これらの実施形態は、図面を参照して以下に詳細を説明する。 In a further embodiment, the tour patrols through the past as defined in the GIS. In addition to being registered spatially, features in the GIS can be registered temporally. For example, a GIS can have an Apollo image that is spatially registered on Rhodes Island, Greece, and temporally registered in 280-226 BC. For clarity, the time associated with a feature in the GIS is referred to herein as “feature time”. The visit can allow the user to pass feature time. For example, each operation can have a feature time associated with it. Based on the action, a relationship between the tour time, the feature time, and the position can be determined. As the tour time elapses, both the position of the virtual camera and the feature time can change. In this manner, the GIS playing the tour can show the user the modern Eiffel Tower in Paris after the ancient Greek Apollo statue. These embodiments will be described in detail below with reference to the drawings.
図１Ａは、本発明の実施形態に従い、視察を示すＧＩＳの画面例１００を示す。実施形態において、ＧＩＳは、視察をプレビューするために画面例１００を表示することができる。視察はまた、他のコンテンツとともにパネル１０２にリストされる。経路１０４は、視察中に仮想カメラによって選択される経路を示す。画面例１００は、編集制御１０６で視察を編集する機会をユーザに提供する。視察の編集は以下に詳細を説明する。画面例１００はまた、フレーム１０８内に視察を簡潔に説明する。フレーム１０８は、ボタン１１０を含む。ユーザがボタン１１０を選択すると、ＧＩＳは、図１Ｂに示されるように、視察の再生を開始することができる。
FIG. 1A shows an example screen 100 of a GIS showing a tour in accordance with an embodiment of the present invention. In an embodiment, the GIS may display an example screen 100 for previewing the tour. The tour is also listed on the
図１Ｂは、実施形態に従い、視察を再生するＧＩＳの画面例１５０を示す。視察を再生するにつれて、ＧＩＳは、視察動作および対応する経路によって設定されるように、異なる光景をユーザに表示する。ユーザは、視察制御１５２および１５４を使用して視察をオーバーライドすることを可能にすることができる。視察制御１５２は、ユーザが視察時系列を制御することを可能にすることができる。例えば、視察制御１５２は、ユーザが、視察を一時停止、巻き戻し、早送り、および章をスキップすることを可能にすることができる。
FIG. 1B shows an
実施形態において、ＧＩＳは、視察時間が経過する速度を制御することによって、視察制御１５２を実行することができる。例えば、一時停止コマンドは、視察時間の経過を停止させることができる。視察時間が停止すると、仮想カメラは、静止状態にとどまることができ、ユーザに、興味ある光景を見る追加時間を費やすことを可能にする。早送りコマンドは、視察時間をより迅速に経過させることができる。視察時間がより迅速に経過すると、仮想カメラの運動を加速することができる。巻き戻しコマンドは、視察時間をさかのぼることができる。視察時間をさかのぼると、カメラを、経路に沿って逆方向に移動させることができる。最後に、章のスキップは、視察時間を次または前の動作の視察時間に変更することができる。この結果、仮想カメラは、次または前の視察動作の位置に移動することができる。このように、視察時系列を制御することによって、ユーザは視察をオーバーライドすることが可能である。視察制御１５２のユーザインターフェース要素は、以下に詳細を説明する＜ＴｏｕｒＣｏｎｔｒｏｌ＞ＫＭＬタグとは異なることに注意されたい。
In an embodiment, the GIS can perform the
ユーザはまた、視察時系列を中断することなく、視察をオーバーライドすることも可能である。例えば、視察制御１５４は、ユーザに、視察が進行中に周囲を見物することを可能にすることができる。周囲を見物することは、仮想カメラが視察の経路に沿って移動を継続する間に、仮想カメラの配向を変更することであり得る。別の実施例において、ユーザは、データまたはユーザインターフェース要素の可視性を変更することによって、視察をオーバーライドすることができる。
The user can also override the tour without interrupting the tour timeline. For example,
前述のように、視察は、関連視察時間を有する動作から定義され得る。図２は、実施形態に従い、視察内の動作のシーケンスを示す図２００である。各動作は、持続期間値を含む。動作の持続期間値は、動作を完了するために経過する視察時間を定義する。動作がシーケンスである場合、視察時系列内で動作が発生する時点は、シーケンス内の以前の動作全ての持続期間を合計することによって、決定され得る。 As mentioned above, a tour can be defined from an action having an associated tour time. FIG. 2 is a diagram 200 illustrating a sequence of operations within a tour according to an embodiment. Each action includes a duration value. The duration value of the action defines the tour time that elapses to complete the action. If the action is a sequence, the point in time when the action occurs within the tour timeline can be determined by summing the durations of all previous actions in the sequence.
本明細書において、フライツー動作と称され得る、１種の動作は、仮想カメラを新しい位置に移動させることができる。各フライツー動作はまた、視察を新しい地物時間期間に移行させることもできる。動作のシーケンスは、フライツー動作２０２で開始する。フライツー動作２０２は、仮想カメラに新しい位置へ「バウンスする」ように命令する。仮想カメラをバウンスさせることは、仮想カメラが、（おそらく放物線の）軌道を進み、新しい位置で静止状態になることを意味することができる。８秒の持続期間は、仮想カメラが８秒間にその新しい位置で静止状態になるように、ＧＩＳに仮想カメラの速度を規制するように命令することができる。
One type of motion, which may be referred to herein as fly-to motion, can move the virtual camera to a new location. Each fly-to action can also shift the visit to a new feature time period. The sequence of operations begins with a fly-to
仮想カメラが新しい位置で静止状態になる時、動作２０４は、ＧＩＳに情報吹き出しを表示するように命令する。ユーザに表示される情報吹き出しによって、動作２０６は、ユーザが情報吹き出しを見る時間を提供するように、５秒の継続時間、仮想カメラにその位置で一時停止するように命令する。次いで、情報吹き出しは、動作２０８で消去される。
When the virtual camera becomes stationary at the new location,
動作２０８の次は、連続したシーケンスのスムーズなフライツー動作２１０である。スムーズなフライツー動作は、仮想カメラに一定の速度で新しい位置へ移動するように命令することができる。バウンスするフライツー動作とは対照的に、スムーズなフライツー動作は、必ずしも、仮想カメラに新しい位置で静止状態になるように命令しない。シーケンスのスムーズなフライツー動作２１０は、仮想カメラに一連の位置（および可能な地物時間）を通って、継続的に飛行するように命令する。仮想カメラが飛行する経路は、スプライン補間を使用して決定され得る。持続期間値は、仮想カメラが経路に沿って移動する速度を制御することができる。例えば、フライツー動作２１２は、仮想カメラが、０．４秒内に新しい場所に到達するような速度で移動することを指定することができる。このように、連続したシーケンスのスムーズなフライツー動作（２１０等）は、指定の速度で、カメラの継続的で補間された経路を指定することができる。スムーズなフライツー動作のシーケンスは、仮想カメラに停止するように命令する動作によって休止され得る。例えば、シーケンスは、バウンスするフライツー動作（フライツー動作２０２等）または一時停止動作（動作２２２等）によって休止される場合がある。
Following the
スムーズなフライツー動作２１０のシーケンスは、動作２２２で終了する。動作２２２は、カメラに３．５秒間一時停止するように命令する。一時停止後、フライツー動作２２４は、カメラに新しい位置にバウンスするように命令する。その新しい位置で、仮想カメラは、動作２２６によって命令されるように、１０秒間一時停止することができる。これで、図２００に特定される視察が終了する。
The sequence of smooth fly-to operations 210 ends at
図２００に関して説明されるように、動作のシーケンスは、視察を特定することができる。実施形態において、ＧＩＳは、ユーザが視察を作成かつ編集することを可能にし得る。ＧＩＳはまた、視察を再生するために動作のシーケンスを中断することができる。図３は、実施形態に従い、視察を編集かつ再生するＧＩＳ３００を示す図である。ＧＩＳ３００は、インターネット等の１つ以上のネットワーク３３０を経由してＧＩＳサーバ３４０に接続されるＧＩＳクライアント３０２を含む。
As described with respect to FIG. 200, the sequence of operations can identify a tour. In an embodiment, the GIS may allow a user to create and edit tours. The GIS can also interrupt the sequence of operations to replay the tour. FIG. 3 is a diagram illustrating a
ＧＩＳクライアント３０２は、ユーザ相互作用モジュール３１０およびレンダラモジュール３２２を含む。ユーザ相互作用モジュール３１０は、運動モデル３１４を含む。概して、ＧＩＳクライアント３０２は、次のように操作する。ユーザ相互作用モジュール３１０は、ユーザが表示を所望する場所に関するユーザ入力を受信し、運動モデル３１４を介して、仮想カメラを定義する表示仕様を構築する。レンダラモジュール３２２は、表示仕様を使用して、描画されるデータを決定し、データを描画する。レンダラモジュール３２２が、ＧＩＳクライアント３０２が有さないデータを描画することが必要な場合、ＧＩＳクライアントは、ＧＩＳサーバ３４０に追加のデータの要求を送信する。
The GIS client 302 includes a user interaction module 310 and a
運動モデル３１４は、表示仕様を構築する。表示仕様は、視錐台として周知の、３次元空間内の仮想カメラの可視ボリューム、および地理データ内の視錐台の位置および配向を定義する。実施形態において、視錐台は、角錐台の形状である。視錐台は、視界環境に依存して変化することが可能な、最小および最大の視界距離を有する。このため、表示仕様を変更すると、仮想カメラの可視ボリュームにカリングされる地理データが変化する。カリングされた地理データは、レンダラモジュール３２２によって描画される。
The
表示仕様は、仮想カメラの３つの主なパラメータセットである、カメラ三脚、カメラレンズ、およびカメラ焦点機能を指定することができる。カメラ三脚パラメータセットは、仮想カメラの位置（Ｘ、Ｙ、Ｚ座標）、方向角（例えば、北？、南？、その間？）、ピッチ（例えば、水平？下向き？上向き？その間？）、およびヨー／ロール（例えば、水平？右回り？左回り？その間？）等の仮想カメラがデフォルトの配向に対して配向される向きを指定する。レンズパラメータセットは、水平方向の視野（例えば、望遠？通常の人間の眼−約５５度？または広角？）、および縦方向の視野（例えば、望遠？、通常の人間の眼−約５５度？または広角？）を指定する。焦点パラメータセットは、近位クリップ平面までの距離（例えば、仮想カメラが見ることができる「レンズ」までの近さ、これより近接の物体は描画されない）、および遠位クリップ平面までの距離（例えば、仮想カメラが見ることができるレンズからの距離、これより遠い物体は描画されない）を指定する。 The display specification can specify the three main parameter sets of the virtual camera, camera tripod, camera lens, and camera focus function. The camera tripod parameter set includes the virtual camera position (X, Y, Z coordinates), direction angle (eg, north ?, south ?, between?), Pitch (eg, horizontal? Down? Up ??), and yaw. Specifies the orientation in which the virtual camera is oriented relative to the default orientation, such as / roll (eg, horizontal, clockwise, counterclockwise, in the meantime) The lens parameter set includes a horizontal field of view (eg, telephoto—normal human eye—about 55 degrees? Or wide angle?) And a vertical field of view (eg, telephoto—normal human eye—about 55 degrees?). Or wide angle?). The focus parameter set includes the distance to the proximal clip plane (eg, the proximity to the “lens” that the virtual camera can see, no closer objects are drawn), and the distance to the distal clip plane (eg, , The distance from the lens that the virtual camera can see, and objects farther than this are not drawn).
運動モデル３１４に加えて、ユーザ相互作用モジュール３１０は、視察コントローラ３１２、視察インタプリタ３１６、および視察エディタ３１８を含む。視察インタプリタ３１６は、視察のための動作のシーケンスを受信する。一実施形態において、視察インタプリタ３１６は、動作のシーケンスを含む、キーホールマークアップ言語（ＫＭＬ）ファイルを解析することができる。動作のシーケンスにおいて、各動作は、地理情報内の位置、および視察時間の持続期間、および地物時間の期間を含むことができる。視察インタプリタ３１８はまた、例えば、ＫＭＬファイル内の地物も受信することができる。地物は、地理情報内の関連地物期間および位置を有することができる。
In addition to the
視察インタプリタ３１６が、視察のデータを受信すると、視察コントローラ３１２は視察を再生する。視察を再生するために、視察コントローラ３１２は、視察時間が経過するにつれて、仮想カメラの位置（および可能性として配向）を変更する。視察コントローラ３１２はまた、地物時間を決定し、地物時間に従って地物を表示する。
When the
視察コントローラ３１２は、フライツー動作のシーケンスに基づいて仮想カメラの経路を決定することができる。経路を決定するために、視察コントローラ３１２は、スプラインを補間することができる。フライツー動作の持続期間値に基づいて、視察コントローラは、仮想カメラを経路に沿って移動させる速度を決定する。また、視察コントローラ３１２は、視察時間が経過するにつれて、地物時間が経過する程度を決定する。実施形態においては、視察コントローラ３１２は、視察の再生前に、カメラの経路、速度、および地物時系列を決定することができる。別の実施形態において、視察コントローラ３１２は、視察をリアルタイムで再生しながら、これらの決定を行うことができる。
The
視察コントローラ３１２は、ユーザが再生中の視察をオーバーライドすることを可能にしてもよい。ユーザ入力に応答して、視察コントローラ３１２は、視察中に一時停止、巻き戻し、早送り、または章のスキップをすることができる。これらの操作を実施するために、視察コントローラ３１２は、視察時間を制御することができる。視察時間に基づいて、視察コントローラ３１２は、カメラの位置および地物時間を調整することができる。視察を一時停止するために、視察コントローラ３１２は、視察時間を停止することができる。視察を巻き戻すために、視察コントローラ３１２は、視察時間をさかのぼることができる。視察を早送りするために、視察コントローラ３１２は、視察時間をより速い速度で進めることができる。章をスキップするために、視察コントローラ３１２は、視察時間を次または前の動作の視察時間に設定することができる。
The
視察は可逆的であり得る。例えば、視察をその開始まで巻き戻すことは、ＧＩＳを視察が開始した時点の状態に戻すことであり得る。視察コントローラ３１２は、クライアントの状態を変更させる「＜Ｕｐｄａｔｅ＞」ＫＭＬタグ等の命令を受信することができる。結果として、視察コントローラ３１２は視察を再生している時にＧＩＳの状態を更新し得る。しかし、可逆性を維持するために、視察コントローラ３１２は視察を巻き戻す時、または視察を抜け出す時にＧＩＳをその前の状態に戻し得る。「＜Ｕｐｄａｔｅ＞」ＫＭＬタグは、以下でより詳細に説明される。
The inspection can be reversible. For example, rewinding the tour to its start may be returning the GIS to the state at the time the tour started. The
視察コントローラ３１２はまた、ユーザが周囲を見物することによって、再生中の視察をオーバーライドすることを可能にし得る。ユーザは、例えば、マウスを移動させる、またはキーボード上の矢印キーを選択することによって、周囲を見物することができる。ユーザ入力に応答して、視察コントローラ３１２は、仮想カメラの配向を調整することができる。仮想カメラの配向が変化する場合であっても、視察時間は継続して経過することができ、仮想カメラは、継続して視察を通って移動することができる。この様式において、ユーザは、視察を通して継続しながら、周囲を見ることが可能である。
The
前述のように、視察コントローラ３１２は、動作のシーケンスに従って、視察を再生することができる。動作のシーケンスは、視察エディタ３１８によって決定され得る。実施例において、視察エディタ３１８は、ユーザに動作を定義することを可能にするユーザインターフェースを提供することができる。視察のいずれかのフライツー動作を含めて、動作は、次いで、ＫＭＬ等のフォーマットにエンコードされ得る。ＫＭＬは、次いで、視察のスプラインを補間するように、視察コントローラ３１２によって読み込まれ得る。代替実施形態において、視察エディタ３１８は、ユーザに、経時的に仮想カメラの継続的な経路を定義することを可能にすることができる。継続的な経路では、視察コントローラ３１２がスプラインを補間する必要が存在しない。継続的な経路を定義するために、ユーザは、仮想カメラを地理情報を通じて移動することができ、視察レコーダ３２０は、仮想カメラの位置（および可能性として配向）を記録することができる。視察エディタ３１８および視察コントローラ３１２によって使用され得る例示的なユーザインターフェースは、図６Ａ〜Ｂに関して説明される。
As described above, the
カメラの位置に加えて、視察レコーダ３２０は、他の動作を記録することができる。他の動作として、情報吹き出しのポップアップ表示、およびＧＩＳクライアントの状態値の更新が挙げられる。以下に説明されるように、状態値の更新は、可視性、不透明性、および位置等の地理的特徴の属性を変更することができる。
In addition to the camera position, the
ＧＩＳクライアント３０２およびＧＩＳサーバ３４０の各々は、任意の演算装置上に実装され得る。このような装置は、命令の実行および格納のためのプロセッサおよびメモリを有するデバイスを含むことができるが、これに限定されない。このようなデバイスは、ソフトウェア、ファームウェア、およびハードウェアを含むことができる。ソフトウェアは、ブラウザ、およびオペレーティングシステム等の１つ以上のアプリケーションを含むことができる。ハードウェアは、プロセッサ、メモリ、グラフィカルユーザインターフェースディスプレイ、および通信インターフェースを含む可能性があるが、これらに限定されない。例えば、概して、ＧＩＳクライアント３０２およびＧＩＳサーバ３０４は各々、コンピュータ、モバイルデバイス（ハンドヘルド、移動電話、パーソナルデータアシスタント、ＰＤＡ、またはノートパソコン等）、ワークステーション、埋め込み型システム、ゲーム機、キオスク、セットトップボックス、テレビ、またはコンピュータ群を含むがこれらに限定されない、任意の演算装置（または演算装置群）上に実装される場合がある。一部の用途において、ＧＩＳクライアント３０１は、携帯性、またはモバイルデバイスまたはコンピュータ等の処理能力およびメモリ容量の少ない比較的安価な演算装置を好むユーザによって使用される場合があるが、一方で、ＧＩＳサーバ３０４は、コンピュータ、コンピュータ群またはワークステーション等の処理能力およびメモリ容量が比較的高い演算装置であり得る。
Each of GIS client 302 and
ユーザ相互作用モジュール３１０、視察コントローラ３１２、運動モジュール３１４、視察インタプリタ３１６、視察エディタ３１８、視察レコーダ３２０、およびレンダラモジュール３２２の各々は、ハードウェア、ソフトウェア、ファームウェア、またはこれらの任意の組み合わせに実装され得る。
Each of user interaction module 310,
図４は、視察を再生するための方法４００を示すフローチャートで、ＧＩＳ３００の操作において使用され得る。方法４００は、ステップ４０２で視察経路を決定することで開始する。ステップ４０２は、方法４００の開始時点に示されるが、当業者は、仮想カメラの経路は視察中にリアルタイムで決定され得ることを認識するであろう。視察経路は、一連のフライツー動作から、スプラインを補間することによって決定され得る。
FIG. 4 is a flowchart illustrating a
概して、ステップ４０４から４１４は、ループを形成する。ループの開始時点で、視察時間はゼロに設定され得る。視察時間に基づいて、ステップ４０４で仮想カメラが移動し、ステップ４０６で地物時間が決定される。地物は、４０８で地物時間に従って表示され得る。ループの間、ステップ４１０および４１２で、視察時間は、ユーザ制御に従って進行または変更することができる。最終的に、ステップ４１４で視察の終了に到達する時、ループが終了する。各ステップは以下に詳細を説明する。
In general, steps 404 through 414 form a loop. At the start of the loop, the tour time can be set to zero. Based on the tour time, the virtual camera moves in
ステップ４０４で、仮想カメラは、視察時間に従って、新しい位置、および可能性として配向に移動する。視察時間がゼロに設定されると、仮想カメラは、視察の開始点に位置付けられる。視察時間が進むと、仮想カメラは、ステップ４０２において決定された経路に沿って移動することができる。
At
ステップ４０６で、地物時間が決定される。地物時間は、視察時間に従って決定され得る。ステップ４０８で、ステップ４０６において決定される地物時間を備える地物に相応する地物が表示される。ステップ４０６および４０８は、図５に関して詳細を説明する。
At
図５は、実施形態に従い、視察時間が地物時間にどのように対応することができるかを図説する図５００を示す。図５００は、視察時系列５２０が地物時系列５１０にどのように対応することができるか示す。前述のように、各地物は地物時間を有することができる。視察上の各動作は、視察時間および地物時間期間を有することができる。動作の視察時間で、地物時間期間内の地物時間を有する地物だけが表示され得る。動作と動作との間に、地物時間期間は補間され得、補間された地物時間期間内に収まる地物時間を有する地物だけが表示され得る。このように、視察時間が経過するにつれて、表示される地物は、それらの地物時間に従って異なる。地物時間が視察時間でどのように異なるかの実施例は、図５００に関して説明する。
FIG. 5 shows a diagram 500 illustrating how a tour time can correspond to a feature time according to an embodiment. The diagram 500 shows how the
図５００において、動作５２２は、０秒の視察時間、および１８２０年１月１日から１８７０年１月１日までの地物時間期間を有する。したがって、視察の開始時点では、１８２０年１月１日から１８７０年１月１日までの間の地物時間を有する地物だけが表示され得る。実施例において、テキサス共和国は、ＧＩＳ内の地物時間を備える地物として表現され得る。テキサス共和国地物は、１８３６年３月１日の地物時間を有することができる。この実施例において、視察の開始時点では、１８３６年３月１日は、１８２０年１月１日と１８７０年１月１日との間にあるため、テキサス共和国地物が表示される。
In diagram 500,
代替実施形態において、各地物は、地物時間期間を有することができる。例えば、テキサス共和国地物は、１８３６年３月１日から１８４５年１２月２９日までの地物時間期間を有することができる。この実施例において、動作の地物時間期間のいずれかの部分が、１８３６年３月１日と１８４５年１２月２９日との間に収まる場合、地物が表示され得る。 In an alternative embodiment, each feature may have a feature time period. For example, a Texas Republic feature may have a feature time period from March 1, 1836 to December 29, 1845. In this example, if any part of the feature time period of operation falls between 1 March 1836 and 29 December 1845, the feature may be displayed.
視察において、次の動作５２６は、５秒の視察時間を有することができる。動作５２６は、１８４９年７月４日から７月５日までという、はるかに短い地物時間期間を有する。テキサス共和国地物の地物時間は、動作５２６の時間期間にはない。このため、テキサス共和国地物は、視察時間が５秒である時には表示されない。
In a tour, the
前述のように、テキサス共和国地物は、地物時間が、動作５２２によって定義されるように０秒である時には表示されるが、動作５２６によって定義されるように５秒では表示されない。次の疑問は、０秒と５秒との間にどの地物が表示されるかである。地物時間期間を定義するために０秒と５秒との間の視察時間を有する動作は存在しない。しかしながら、地物時間期間は、補間５２４によって示されるように補間され得る。図は、直線的補間を示すが、しかしながら、他の補間が使用され得る。動作の間に地物時間を補間することによって、表示される地物は、時間期間の間を徐々に移行する。
As described above, a feature of the Republic of Texas is displayed when the feature time is 0 seconds as defined by
図４をもう一度参照すると、ステップ４１０で任意の視察コマンドが実行される。前述のように、一部の視察コマンドは視察を中断しない。視察を中断しないコマンドとして、周囲を見物すること、地理データの可視性を変更すること、およびユーザインターフェース表示を変更することが挙げられ得る。他の視察コマンドは、視察の時系列を制御するコマンドを含む。これらのコマンドとして、一時停止、巻き戻し、早送り、および章のスキップが挙げられる。このコマンドは、ステップ４１２で視察時間がどのように変更されるかに影響し得る。視察時系列を制御するコマンドが受信されない場合、視察時間は、所定の量だけ進行する。
Referring back to FIG. 4, at
視察コマンドは、図１Ｂに関して説明されるように、ユーザによって入力され得る。代替として、視察コマンドは、例えば、ＫＭＬでエンコードされる動作として受信され得る。一実施例において、ＫＭＬでエンコードされる視察コマンドは、ユーザ入力が受信されるまで、視察時間を一時停止することができる。別の実施例において、ＫＭＬでエンコードされる視察コマンドは、視察が進むループを指定することができる。 The tour command may be entered by the user, as described with respect to FIG. 1B. Alternatively, the tour command may be received, for example, as an operation encoded in KML. In one embodiment, a tour command encoded in KML can pause the tour time until user input is received. In another example, a tour command encoded in KML may specify a loop through which the tour proceeds.
ステップ４１４で、視察時間は、視察の期間に比較され得る。視察時間が視察の期間以上である場合、ループは終了し、視察が終了する。
At
前述のように、ＧＩＳは、ユーザに視察を作成かつ編集することを可能にする視察エディタを含むことができる。図６Ａ〜Ｂは、視察エディタを含むＧＩＳの画面例を示す。 As mentioned above, the GIS can include a tour editor that allows the user to create and edit tours. 6A and 6B show examples of GIS screens including an inspection editor.
図６Ａは、ＧＩＳの画面例６００を示す。画面例６００は、場所メニュー６１０を含む。場所メニュー６１０は、視察オプション６０２を有する。オプション６０２をダブルクリックすると、サンフランシスコの視察を再生することができる。オプション６０２を右クリックすると、メニュー６０４を表示することができる。メニュー６０４は、ユーザに編集オプション６０６および再生オプション６０８を提供する。ここでも、再生オプション６０８は、視察を再生することができる。編集オプション６０６は、図６Ｂのように、ユーザを編集インターフェースに移行することができる。
FIG. 6A shows a screen example 600 of GIS. Screen example 600 includes a
図６Ｂは、視察を編集するためのインターフェースを示す画面例６５０を示す。画面例６５０は、パネル６６０を含む。パネル６６０は、視察に関する動作を表すサムネイル画像を有する。サムネイル画像６６２等のサムネイル画像は、動作の位置から仮想カメラの視点をプレビューする。パネル６６０はまた、視察に関して他の可能な動作のアイコンも有する。例えば、アイコン６６２は、情報吹き出しが表示されることを示し、アイコン６６６は、視察の一時停止を示す。
FIG. 6B shows an
画面例６５０はまた、記録ボタン６６８も有する。記録ボタン６６８が選択されると、ＧＩＳは、仮想カメラの位置の記録を開始する。例えば、ＧＩＳは、仮想カメラの位置からのフライツー動作を作成することができる。代替として、ＧＩＳは、経時的な仮想カメラの経路を記録することができる。ＧＩＳはまた、吹き出しのポップアップ表示、ＫＭＬ地物の可視性の切替等の地理空間コンテンツの更新、または地物の位置および／または不透明性の変更のような他の動作を記録することもできる。
The
図７は、視察を指定するために使用され得る例示的なＫＭＬスキーマを示す図７００である。図７００は、従来のＫＭＬ要素に含まれないいくつかの新しい、または変更されたＫＭＬ要素を示す。新しい、または変更されたＫＭＬ要素は、Ｔｏｕｒ要素７０２、ＡｂｓｔｒａｃｔＶｉｅｗ要素７０４、Ｋｅｙｆｒａｍｅ要素７０６、およびＡｂｓｔｒａｃｔＡｃｔｉｏｎ要素７０８を含む。
FIG. 7 is a diagram 700 illustrating an example KML schema that may be used to specify a tour. Diagram 700 shows some new or modified KML elements that are not included in conventional KML elements. New or modified KML elements include a
Ｔｏｕｒ要素７０２は、視察を指定する。例えば、Ｔｏｕｒ要素７０２は、図２に示されるような視察を指定することができる。Ｔｏｕｒ要素７０２は、Ｆｅａｔｕｒｅ要素７１０から派生することができる。Ｔｏｕｒ要素７０２は、表題および説明等の視察に関する情報を含むことができる。さらに、Ｔｏｕｒ要素７０２は、ＡｂｓｔｒａｃｔＡｃｔｉｏｎ要素７０８のシーケンスを含むプレイリストを含む。実施形態において、Ｔｏｕｒ要素７０２は、以下のスキーマを有することができる。
A
Ｗａｉｔ要素７２４は、指定の持続期間、視察を一時停止するようにＧＩＳに命令する。持続期間、仮想カメラは静止したままであり得、表示される地物時間期間は、変化しなくてもよい。一方で、視察時間の経過は継続することができる。実施例において、Ｗａｉｔ要素７２４を含むＫＭＬスニペットは、以下の通りである。 The Wait element 724 instructs the GIS to pause the visit for a specified duration. For a duration, the virtual camera may remain stationary and the displayed feature time period may not change. On the other hand, the course of the inspection time can be continued. In an example, a KML snippet that includes a Wait element 724 is as follows.
Ｕｐｄａｔｅ要素７２８は、ＧＩＳクライアントの状態値を変更する。状態値は、ＫＭＬファイルにエンコードされる地物等の地理的特徴の属性であり得る。実施例において、地物は、Ｐｌａｃｅｍａｒｋ、ＧｒｏｕｎｄＯｖｅｒｌａｙ、ＳｃｒｅｅｎＯｖｅｒｌａｙ、または他の地理的特徴であり得る。地物は、可視性、位置、配向、不透明性、およびサイズ等の属性を有することができる。可視性属性を更新することによって、Ｕｐｄａｔｅ要素７２８は、地物を表示または非表示にすることができる。位置属性を更新することによって、Ｕｐｄａｔｅ要素７２８は地物を移動させることができる。
The
Ｕｐｄａｔｅ要素７２８は、一定期間の間に属性を新しい状態に移行することができる。このため、Ｕｐｄａｔｅ要素７２８は、状態移行の間に視察時間がどの程度経過すべきかを示す持続期間値を含むことができる。例えば、Ｕｐｄａｔｅ要素は、地物の位置を点Ｙに変更する。Ｕｐｄａｔｅ要素は、５秒の持続期間を有する。地物は、視察時間が０秒にある時、点Ｘに位置付けられ得る。５秒後、地物は、点Ｙに配置され得る。０秒と５秒との間、地物の位置は補間される。この様式において、Ｕｐｄａｔｅ要素７２８は、地物を新しい場所に徐々に移行するために使用され得、アニメーションの効果を作成する。Ｕｐｄａｔｅ要素７２８はまた、アニメーション効果を作成し、ジオコード化されるコンテンツを探索するように、サイズ、不透明性、配向、色および形状等の他の地物属性を徐々に変更することができる。例えば、地物は、第１の多角形のような形状であり得、形状属性を変更することによって、第２の多角形形状に移行することができる。
The
ＦｌｙＴｏ要素７２２は、動作をエンコードする。ＦｌｙＴｏ要素７２２は、ＧＩＳに仮想カメラを視察上の新しい位置に移動するように命令する。ＦｌｙＴｏ要素７２２は、地理情報内の場所およびオプションの地物時間をエンコードする。図２で説明されるように、ＦｌｙＴｏ要素７２２は、仮想カメラをどのように移動するかを指定する、「バウンス」および「スムーズ」の２つのタイプのうちの１つを有することができる。最終的に、ＦｌｙＴｏ要素７２２は、移行する場所および地物時間を定義するＡｂｓｔｒａｃｔＶｉｅｗ要素７０４を含むことができる。実施形態において、ＦｌｙＴｏ要素７２２は、以下のスキーマを有することができる。
The
さらに、ＫＭＬスキーマは、ＰｈｏｔｏＯｖｅｒｌａｙ要素を有することができる。ＰｈｏｔｏＯｖｅｒｌａｙ要素は、ＧＩＳに、仮想カメラを写真内で飛行させるように命令することができる。実施形態において、ＧＩＳは、仮想カメラを写真の焦点へ飛行させることができ、ユーザに写真ナビゲーションモードで写真内をナビゲートすることを可能にすることができる。 Furthermore, the KML schema can have a PhotoOverlay element. The PhotoOverlay element can instruct the GIS to fly the virtual camera in the photo. In an embodiment, the GIS can fly the virtual camera to the focus of the photo and can allow the user to navigate through the photo in photo navigation mode.
実施形態において、ユーザを写真ナビゲーションモード内で飛行させると、仮想カメラを写真の本来の原点に効果的に移動させる。本来の原点は、写真を撮影したカメラの焦点距離における、またはこれをわずかに超える画像面の前にある点である。仮想カメラは、仮想カメラがこの面をのぞき込むように、面に対して垂直に配向される。ＧＩＳが写真ナビゲーションモードに入る時、ＧＩＳは、写真を撮影したカメラの焦点距離および視錐台に一致するように、仮想カメラの焦点距離および視錐台を変更することができる。 In an embodiment, flying the user in the photo navigation mode effectively moves the virtual camera to the original origin of the photo. The original origin is that point in front of the image plane at or slightly beyond the focal length of the camera that took the picture. The virtual camera is oriented perpendicular to the plane so that the virtual camera looks into this plane. When the GIS enters the photo navigation mode, the GIS can change the focal length and viewing frustum of the virtual camera to match the focal length and viewing frustum of the camera that took the photo.
写真ナビゲーションモード内のナビゲーション操作は、パンニング（ｐａｎｎｉｎｇ）、ズーミング、自動操縦、およびジョイスティック運動を含むことができる。パンニングは、マウスボタンが押下されている間、画像をマウスの運動に沿ってドラッグする。ズーミングは、カメラが写真に接近することをシミュレーションする。ズーミングは、画像ピラミッドから表示されているより高解像度の画像タイルをもたらし得る。ユーザがある点をダブルクリックすると、自動操縦運動は、カメラを画像のその点を中心とする円滑な表示をシミュレーションすることができる。自動操縦は、ユーザがダブルクリックしたマウスのボタンに依存して、ズームインまたはズームアウトすることができる。ジョイスティック運動は、キーボード矢印またはジョイスティックのいずれかのインターフェースを使用して、例えば、一定の速度で表示を周囲に移動させる。 Navigation operations within the photo navigation mode can include panning, zooming, autopilot, and joystick movement. Panning drags the image along the mouse movement while the mouse button is pressed. Zooming simulates the camera approaching a photograph. Zooming can result in higher resolution image tiles being displayed from the image pyramid. When the user double-clicks on a point, the autopilot movement can simulate a smooth display with the camera centered on that point in the image. Autopilot can zoom in or out depending on the mouse button that the user double-clicks. Joystick motion uses either the keyboard arrow or joystick interface to move the display around, for example, at a constant rate.
ＫＭＬスキーマはまた、音を再生する要素も含むことができる。ＫＭＬ要素は、ＭＰ３またはＷＡＶファイル等のサウンドファイルへの参照を含むことができる。この要素を使用して、視察は付随のサウンドトラックを有することができる。 The KML schema can also include elements that play sounds. The KML element can include a reference to a sound file such as an MP3 or WAV file. Using this element, the tour can have an accompanying soundtrack.
図８は、図７００に示されるスキーマに従って、視察を定義するＫＭＬコード８００を示す。ＫＭＬコード８００は、アメリカ革命地物およびボストンティーパーティ地物を含むいくつかの地物を定義するコード部分８０２を含む。各地物は、関連地物時間スパンを有する。アメリカ革命地物は、１７７５年に開始して、１７７６年に終了し、ボストンティーパーティは、１７７３年１２月１６日に開始して、１７７３年１２月１７日に終了する。
FIG. 8 shows
コード部分８０２の次は、視察を定義するコード部分８１０である。視察は、ＦｌｙＴｏ要素８１２で開始し、これによって、仮想カメラは、１０秒間に新しい位置へバウンスすることになる。次いで、Ｗａｉｔ要素８１４は、仮想カメラを１秒間静止状態にする。Ｗａｉｔ要素８１４の次は、ＴｏｕｒＣｏｎｔｒｏｌ要素８１６である。ＴｏｕｒＣｏｎｔｒｏｌ要素８１６は、視察を再開する命令を含むユーザ入力が受信されるまで、視察を一時停止する。ユーザ入力が受信された後、Ｗａｉｔ要素８１８は、仮想カメラを０．２秒間静止状態にする。次いで、ＦｌｙＴｏ要素８２０は、仮想カメラを新しい場所へバウンスさせる。新しい場所で、Ｗａｉｔ要素８２２は、カメラを５秒間静止状態にする。５秒の経過後、視察は終了する。
Following the
この様式において、本発明の実施形態は、経時的に仮想カメラの位置を制御する。これによって、視察のユーザ体験を向上させる。 In this manner, embodiments of the present invention control the position of the virtual camera over time. This improves the user experience of the inspection.
発明の概要および要約の項は、本発明者らによって検討されるような、本発明の全てではないが１つ以上の例示的実施形態を説明し得、したがって、決して本発明および添付の図面を制限することを目的としない。 The Summary and Summary section may describe one or more, but not all, exemplary embodiments of the present invention as discussed by the inventors, and thus never refer to the present invention and the accompanying drawings. It is not intended to be restricted.
特定の機能の実装およびその関係を例証する機能的構成要素を用いて、本発明を上記で説明している。これらの機能的構成要素の境界は、説明の便宜上、本明細書では任意に画定されている。特定の機能およびその関係が適切に実施される限り、代替境界を画定することができる。 The present invention has been described above using functional components that illustrate the implementation of specific functions and their relationships. The boundaries of these functional components are arbitrarily defined herein for convenience of explanation. Alternative boundaries can be defined as long as certain functions and relationships are properly implemented.
具体的実施形態の先述の説明は、本発明の一般概念から逸脱することなく、必要以上の実験を伴わずに、当技術分野内の知識を適用することによって、他者が種々の用途についてそのような具体的実施形態を容易に修正および／または適合させることができる、本発明の一般的性質を完全に明らかにする。したがって、そのような適合および修正は、本明細書で提示される教示および指導に基づいて、開示された実施形態の同等物の意味および範囲内となることを目的とする。本明細書の用語または表現が、教示および指導に照らして当業者によって解釈されるように、本明細書の表現または用語は、限定ではなく説明の目的によるものであると理解されたい。 The foregoing description of specific embodiments has been described by others for various uses by applying knowledge within the art without undue experimentation without departing from the general concept of the invention. Such general embodiments can be readily modified and / or adapted to fully reveal the general nature of the invention. Accordingly, such adaptations and modifications are intended to be within the meaning and scope of the equivalents of the disclosed embodiments based on the teachings and guidance presented herein. It should be understood that the terminology or terminology herein is for purposes of illustration and not limitation, as the terminology or terminology herein will be interpreted by one of ordinary skill in the art in light of the teachings and guidance.
本発明の幅および範囲は、上記の例示的実施形態のうちのいずれかによって決して制限されるべきではないが、以下の請求項およびそれらの同等物のみに従って定義されるべきである。 The breadth and scope of the present invention should in no way be limited by any of the above-described exemplary embodiments, but should be defined only in accordance with the following claims and their equivalents.
Claims (23)
該方法は、
（ａ）視察のための一式の動作を受信することであって、各動作は、視察時間を含み、該動作のうちの少なくとも１つの視察時間は、該視察を見ているユーザが該動作を定義および編集することを可能にするインターフェースを有する視察エディタによって定義され、該一式の動作は、該視察エディタによって定義された位置値を含むフライツー動作を含み、該位置値は、該地理情報内の地理的特徴に関連付けられている、ことと、
（ｂ）該地理情報システム内の地理情報を視察するように、該一式の動作の各動作を実行することと
を含み、
該実行することは、該フライツー動作に関連付けられた視察時間によって特定される時間において、該フライツー動作に含まれる該位置値に従い、該地理情報システムの３次元環境を通して、経路を形成するように該仮想カメラを移動させ、その結果、該関連付けられた地理的特徴が表示されるようにすることを含み、
該３次元環境を通して移動する該仮想カメラの第１の速度は、第１のフライツー動作に関連付けられた第１の視察時間に基づいており、該３次元環境を通して移動する該仮想カメラの第２の速度は、該第１のフライツー動作とは異なる第２のフライツー動作に関連付けられた第２の視察時間に基づいており、該第１の速度は、該第２の速度とは別個に定義され、
該仮想カメラは、少なくとも部分的に、該地理情報システム内のどの地理情報を表示するかを特定する、方法。 A method for inspecting geographic information in a three-dimensional geographic information system, the geographic information including geographic features displayed to a user from a virtual camera perspective;
The method
(A) comprises receiving the operation of the set for inspection, the operation includes a tour time, at least one tour time of said operating, the user watching the tour is a said operating Defined by a tour editor having an interface that allows definition and editing , the set of operations including a fly-to operation including a location value defined by the tour editor, the location value in the geographic information Associated with geographic features ,
(B)該地to inspect the geographic information of the management information in the system, see containing and performing the operations of the operation of the set,
The performing is configured to form a path through the three-dimensional environment of the geographic information system according to the position value included in the fly-to operation at a time specified by a tour time associated with the fly-to operation. Moving a virtual camera so that the associated geographic features are displayed;
The first speed of the virtual camera moving through the three-dimensional environment is based on a first visit time associated with a first fly-to action, and a second speed of the virtual camera moving through the three-dimensional environment. The speed is based on a second visit time associated with a second fly-to action that is different from the first fly-to action, the first speed being defined separately from the second speed;
A method in which the virtual camera identifies at least in part which geographic information in the geographic information system is to be displayed .
（ｄ）現在の視察時間に基づいて現在の地物時間を決定することと、
（ｅ）該現在の地物時間が該関連地物期間中にあり、かつ該位置が前記仮想カメラの視錐台内にある場合に、該地物を表示することと
をさらに含む、請求項２に記載の方法。 (C) receiving a feature having an associated feature period and position in the geographic information;
(D) determining the current feature time based on the current visit time;
Further comprising: (e) displaying the feature if the current feature time is during the related feature period and the position is within a view frustum of the virtual camera. 2. The method according to 2 .
をさらに含み、
前記実行すること（ｂ）は、該スプラインに沿って前記仮想カメラを移動させることをさらに含む、
請求項１に記載の方法。 (C ) further comprising interpolating a spline based on two or more positions , each position being associated with a different action in the set of actions ;
Said performing (b) further comprises moving said virtual camera along said spline;
The method of claim 1 .
をさらに含む、請求項１に記載の方法。 (C) the inspection editor further comprises allowing the inspection pause, to rewind, or fast forward method of claim 1.
をさらに含み、該可能にすること（ｃ）は、
（ｉ）該視察を見ているユーザが、前記仮想カメラを移動させるための動作を定義することを可能にすることと、
（ｉｉ）該仮想カメラの位置を記録することと
を含む、請求項１に記載の方法。 (C) the inspection editor, see further contains that makes it possible to define the behavior of the set, enabling the (c) is,
(I) allowing a user viewing the tour to define an action for moving the virtual camera;
(Ii) recording the position of the virtual camera;
Including method of claim 1.
をさらに含む、請求項１に記載の方法。 (C) Thus in a first user input, further comprising changing the orientation of the virtual camera, The method of claim 1.
（ｄ）第２のユーザ入力に応答して、該仮想カメラを該視察の経路に戻すことと
をさらに含む、請求項１に記載の方法。 (C ) moving the virtual camera out of the tour path in accordance with a first user input;
And (d) in response to a second user input, further comprising a returning to the path of the tour the virtual camera, The method of claim 1.
該システムは、
視察コントローラを備え、該視察コントローラは、
（ｉ）視察のための一式の動作を受信することであって、各動作は、視察時間を含み、該動作のうちの少なくとも１つの視察時間は、該視察を見ているユーザが該動作を定義および編集することを可能にするインターフェースを有する視察エディタによって定義され、該一式の動作は、位置値を含むフライツー動作を含み、該位置値は、該地理情報内の地理的特徴に関連付けられている、ことと、
（ｉｉ）該地理情報システム内の地理情報を視察するように、該一式の動作の中の各動作を実行することと
を行うように構成されており、
該視察コントローラは、該フライツー動作に関連付けられた視察時間によって特定される時間において、該フライツー動作に含まれる該位置値に従い、該地理情報システムの３次元環境を通して、経路を形成するように該仮想カメラを移動させ、その結果、該関連付けられた地理的特徴が表示されるようにするように構成されており、
該３次元環境を通して移動する該仮想カメラの第１の速度は、第１のフライツー動作に関連付けられた第１の視察時間に基づいており、該３次元環境を通して移動する該仮想カメラの第２の速度は、該第１のフライツー動作とは異なる第２のフライツー動作に関連付けられた第２の視察時間に基づいており、該第１の速度は、該第２の速度とは別個に定義され、
該仮想カメラは、少なくとも部分的に、該地理情報システム内のどの地理情報を表示するかを特定する、システム。 A geographic information system for inspecting geographic information in a three-dimensional geographic information system, the geographic information including geographic features displayed from the viewpoint of a virtual camera,
The system
An inspection controller, the inspection controller comprising:
(I) the method comprising: receiving an operation of the set for inspection, the operation includes a tour time, at least one tour time of said operating, the user watching the tour is a said operating Defined by a tour editor having an interface that allows definition and editing , the set of actions includes a fly-to action that includes a position value, the position value being associated with a geographic feature in the geographic information It is, and that,
(Ii) configured to perform each operation in the set of operations so as to inspect the geographic information in the geographic information system ;
The tour controller is configured to form the virtual path through the three-dimensional environment of the geographic information system according to the position value included in the fly-to operation at a time specified by a tour time associated with the fly-to operation. Configured to move the camera so that the associated geographic features are displayed,
The first speed of the virtual camera moving through the three-dimensional environment is based on a first visit time associated with a first fly-to action, and a second speed of the virtual camera moving through the three-dimensional environment. The speed is based on a second visit time associated with a second fly-to action that is different from the first fly-to action, the first speed being defined separately from the second speed;
A system wherein the virtual camera identifies at least in part which geographic information within the geographic information system is to be displayed .
をさらに含む、請求項１３に記載のシステム。 Tour interpreter configured to parse keyhole markup language ( KML ) files
The system of claim 13 , further comprising :
The system of claim 22 , wherein the control instruction instructs the tour controller to repeatedly perform at least some of the operations.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US13609308P | 2008-08-12 | 2008-08-12 | |
US61/136,093 | 2008-08-12 | ||
PCT/US2009/004565 WO2010019205A1 (en) | 2008-08-12 | 2009-08-10 | Touring in a geographic information system |
Publications (2)
Publication Number | Publication Date |
---|---|
JP2011530766A JP2011530766A (en) | 2011-12-22 |
JP5524965B2 true JP5524965B2 (en) | 2014-06-18 |
Family
ID=41258439
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2011522976A Active JP5524965B2 (en) | 2008-08-12 | 2009-08-10 | Inspection in geographic information system |
Country Status (9)
Country | Link |
---|---|
US (2) | US8302007B2 (en) |
EP (1) | EP2324460B1 (en) |
JP (1) | JP5524965B2 (en) |
KR (1) | KR101626038B1 (en) |
CN (1) | CN102177530B (en) |
AU (1) | AU2009282475B2 (en) |
CA (1) | CA2733274C (en) |
DK (1) | DK2324460T3 (en) |
WO (1) | WO2010019205A1 (en) |
Families Citing this family (42)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8584013B1 (en) | 2007-03-20 | 2013-11-12 | Google Inc. | Temporal layers for presenting personalization markers on imagery |
JP4760896B2 (en) * | 2008-11-04 | 2011-08-31 | ソニー株式会社 | Camera control apparatus and camera control method |
US20110113316A1 (en) * | 2008-12-31 | 2011-05-12 | Microsoft Corporation | Authoring tools for rich interactive narratives |
US9092437B2 (en) * | 2008-12-31 | 2015-07-28 | Microsoft Technology Licensing, Llc | Experience streams for rich interactive narratives |
US9007379B1 (en) * | 2009-05-29 | 2015-04-14 | Two Pic Mc Llc | Methods and apparatus for interactive user control of virtual cameras |
US20120124471A1 (en) * | 2010-09-23 | 2012-05-17 | Gusky Jeffrey S | Virtual tour, display and commerce |
GB2489685B (en) * | 2011-03-31 | 2017-01-25 | Geovs Ltd | A Display System |
US9189891B2 (en) * | 2011-08-16 | 2015-11-17 | Google Inc. | Systems and methods for navigating a camera |
US10152722B2 (en) | 2011-09-15 | 2018-12-11 | Stephan HEATH | System and method for providing combination of online coupons, products or services with advertisements, geospatial mapping, related company or local information, and social networking |
US10127564B2 (en) | 2011-09-15 | 2018-11-13 | Stephan HEATH | System and method for using impressions tracking and analysis, location information, 2D and 3D mapping, mobile mapping, social media, and user behavior and information for generating mobile and internet posted promotions or offers for, and/or sales of, products and/or services |
US20130073374A1 (en) * | 2011-09-15 | 2013-03-21 | Stephan HEATH | System and method for providing combined coupon/geospatial mapping/ company-local & socially conscious information and social networking (c-gm-c/l&sc/i-sn) |
US9710821B2 (en) | 2011-09-15 | 2017-07-18 | Stephan HEATH | Systems and methods for mobile and online payment systems for purchases related to mobile and online promotions or offers provided using impressions tracking and analysis, location information, 2D and 3D mapping, mobile mapping, social media, and user behavior and |
US10129211B2 (en) | 2011-09-15 | 2018-11-13 | Stephan HEATH | Methods and/or systems for an online and/or mobile privacy and/or security encryption technologies used in cloud computing with the combination of data mining and/or encryption of user's personal data and/or location data for marketing of internet posted promotions, social messaging or offers using multiple devices, browsers, operating systems, networks, fiber optic communications, multichannel platforms |
US10127563B2 (en) * | 2011-09-15 | 2018-11-13 | Stephan HEATH | System and method for providing sports and sporting events related social/geo/promo link promotional data sets for end user display of interactive ad links, promotions and sale of products, goods, gambling and/or services integrated with 3D spatial geomapping, company and local information for selected worldwide locations and social networking |
US10217117B2 (en) * | 2011-09-15 | 2019-02-26 | Stephan HEATH | System and method for social networking interactions using online consumer browsing behavior, buying patterns, advertisements and affiliate advertising, for promotions, online coupons, mobile services, products, goods and services, entertainment and auctions, with geospatial mapping technology |
US10140620B2 (en) * | 2011-09-15 | 2018-11-27 | Stephan HEATH | Mobile device system and method providing combined delivery system using 3D geo-target location-based mobile commerce searching/purchases, discounts/coupons products, goods, and services, or service providers-geomapping-company/local and socially-conscious information/social networking (“PS-GM-C/LandSC/I-SN”) |
JP2013089130A (en) * | 2011-10-20 | 2013-05-13 | Sony Corp | Information processing apparatus, information processing method, program, and recording medium |
CN103208225B (en) * | 2012-01-12 | 2015-10-28 | 中国科学院遥感应用研究所 | A kind of tile map method for making and system |
US8737691B2 (en) * | 2012-07-05 | 2014-05-27 | Verizon Patent And Licensing Inc. | Methods and systems for creating virtual trips from sets of user content items |
US10931920B2 (en) * | 2013-03-14 | 2021-02-23 | Pelco, Inc. | Auto-learning smart tours for video surveillance |
USD738911S1 (en) * | 2013-05-29 | 2015-09-15 | Microsoft Corporation | Display screen with icon |
US9542724B1 (en) * | 2013-07-09 | 2017-01-10 | Google Inc. | Systems and methods for stroke rendering on digital maps |
US9805057B2 (en) | 2013-10-15 | 2017-10-31 | Google Inc. | Automatic generation of geographic imagery tours |
USD781317S1 (en) | 2014-04-22 | 2017-03-14 | Google Inc. | Display screen with graphical user interface or portion thereof |
USD781318S1 (en) | 2014-04-22 | 2017-03-14 | Google Inc. | Display screen with graphical user interface or portion thereof |
US9972121B2 (en) * | 2014-04-22 | 2018-05-15 | Google Llc | Selecting time-distributed panoramic images for display |
USD780777S1 (en) | 2014-04-22 | 2017-03-07 | Google Inc. | Display screen with graphical user interface or portion thereof |
US9934222B2 (en) | 2014-04-22 | 2018-04-03 | Google Llc | Providing a thumbnail image that follows a main image |
US9471695B1 (en) * | 2014-12-02 | 2016-10-18 | Google Inc. | Semantic image navigation experiences |
EP3065108A1 (en) * | 2015-03-04 | 2016-09-07 | Samsung Electronics Co., Ltd. | Displaying a virtual tour |
US9679413B2 (en) | 2015-08-13 | 2017-06-13 | Google Inc. | Systems and methods to transition between viewpoints in a three-dimensional environment |
KR20200061279A (en) | 2018-11-23 | 2020-06-02 | 삼성전자주식회사 | Electronic apparatus and control method thereof |
EP3863277A4 (en) * | 2018-11-23 | 2022-05-04 | Samsung Electronics Co., Ltd. | Electronic device and control method thereof |
JP7411455B2 (en) * | 2020-03-06 | 2024-01-11 | 株式会社Ｉｈｉアグリテック | work equipment |
US11368991B2 (en) | 2020-06-16 | 2022-06-21 | At&T Intellectual Property I, L.P. | Facilitation of prioritization of accessibility of media |
US11233979B2 (en) | 2020-06-18 | 2022-01-25 | At&T Intellectual Property I, L.P. | Facilitation of collaborative monitoring of an event |
US11411757B2 (en) | 2020-06-26 | 2022-08-09 | At&T Intellectual Property I, L.P. | Facilitation of predictive assisted access to content |
US11037443B1 (en) | 2020-06-26 | 2021-06-15 | At&T Intellectual Property I, L.P. | Facilitation of collaborative vehicle warnings |
US11184517B1 (en) | 2020-06-26 | 2021-11-23 | At&T Intellectual Property I, L.P. | Facilitation of collaborative camera field of view mapping |
US11356349B2 (en) | 2020-07-17 | 2022-06-07 | At&T Intellectual Property I, L.P. | Adaptive resource allocation to facilitate device mobility and management of uncertainty in communications |
US11768082B2 (en) | 2020-07-20 | 2023-09-26 | At&T Intellectual Property I, L.P. | Facilitation of predictive simulation of planned environment |
CN111859194B (en) * | 2020-08-03 | 2024-01-30 | 哈尔滨文投控股集团有限公司 | Intelligent travel service platform and automatic travel path planning method based on same |
Family Cites Families (42)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20030093790A1 (en) * | 2000-03-28 | 2003-05-15 | Logan James D. | Audio and video program recording, editing and playback systems using metadata |
JP2938845B1 (en) * | 1998-03-13 | 1999-08-25 | 三菱電機株式会社 | 3D CG live-action image fusion device |
US6572662B2 (en) * | 1998-05-15 | 2003-06-03 | International Business Machines Corporation | Dynamic customized web tours |
US6388688B1 (en) * | 1999-04-06 | 2002-05-14 | Vergics Corporation | Graph-based visual navigation through spatial environments |
US6839880B1 (en) * | 1999-10-21 | 2005-01-04 | Home Debut, Inc. | Electronic property viewing system for providing virtual tours via a public communications network, and a method of exchanging the same |
JP2001195491A (en) * | 1999-11-02 | 2001-07-19 | Matsushita Electric Works Ltd | Selling support method for commodity associated with living space, method and system for charging the same and recording medium |
AU4148901A (en) * | 2000-02-14 | 2001-08-27 | Virtuacities, Inc. | Methods and systems for presenting a virtual representation of a real city |
AU2001235814A1 (en) * | 2000-03-31 | 2001-10-15 | British Telecommunications Public Limited Company | Handling unscheduled tasks in a scheduling process |
US7225040B2 (en) | 2001-11-14 | 2007-05-29 | Exxon Mobil Oil Corporation | Method and system for reducing lead-time in the packaging industry |
US7240108B2 (en) * | 2001-08-30 | 2007-07-03 | International Business Machines Corporation | Customized tours using handheld devices |
US7096428B2 (en) * | 2001-09-28 | 2006-08-22 | Fuji Xerox Co., Ltd. | Systems and methods for providing a spatially indexed panoramic video |
US20030212536A1 (en) * | 2002-05-08 | 2003-11-13 | Cher Wang | Interactive real-scene tour simulation system and method of the same |
WO2004003852A1 (en) * | 2002-06-04 | 2004-01-08 | Iwane Laboratories, Ltd. | Sightseeing tour system via the internet |
WO2004003842A1 (en) * | 2002-06-27 | 2004-01-08 | Mjw Corporation | Interactive video tour system editor |
AU2002951345A0 (en) | 2002-08-15 | 2002-09-26 | Hanika Pty Ltd, | Interactive property tour |
US9756349B2 (en) * | 2002-12-10 | 2017-09-05 | Sony Interactive Entertainment America Llc | User interface, system and method for controlling a video stream |
US20040218910A1 (en) | 2003-04-30 | 2004-11-04 | Chang Nelson L. | Enabling a three-dimensional simulation of a trip through a region |
US7149961B2 (en) | 2003-04-30 | 2006-12-12 | Hewlett-Packard Development Company, L.P. | Automatic generation of presentations from “path-enhanced” multimedia |
US6968973B2 (en) * | 2003-05-31 | 2005-11-29 | Microsoft Corporation | System and process for viewing and navigating through an interactive video tour |
CA2569524A1 (en) * | 2004-06-01 | 2005-12-15 | Supun Samarasekera | Method and system for performing video flashlight |
US20080129528A1 (en) * | 2004-11-16 | 2008-06-05 | Michael Phipps Guthrie | Apparatus and method for guided tour |
JP2006155231A (en) * | 2004-11-29 | 2006-06-15 | Kokuyo Co Ltd | Viewing system and program |
KR20060094176A (en) * | 2005-02-23 | 2006-08-29 | 삼성전자주식회사 | Method, system, and portable device for gallery guide using guide tour with stored guide data and work of art data |
US7769819B2 (en) * | 2005-04-20 | 2010-08-03 | Videoegg, Inc. | Video editing with timeline representations |
US7353114B1 (en) | 2005-06-27 | 2008-04-01 | Google Inc. | Markup language for an interactive geographic information system |
EP1922697A4 (en) | 2005-07-20 | 2009-09-23 | Geosim Systems Ltd | Web enabled three-dimensional visualization |
US9258259B2 (en) * | 2005-09-30 | 2016-02-09 | Nokia Technologies Oy | Retrieval of offline instant messages |
US20070098357A1 (en) * | 2005-10-28 | 2007-05-03 | Microsoft Corporation | DVR content skip navigation |
US7617246B2 (en) * | 2006-02-21 | 2009-11-10 | Geopeg, Inc. | System and method for geo-coding user generated content |
US7904483B2 (en) | 2005-12-23 | 2011-03-08 | Geopeg, Inc. | System and method for presenting geo-located objects |
US9031964B2 (en) | 2006-04-25 | 2015-05-12 | Google Inc. | Shared geo-located objects |
US20070256023A1 (en) * | 2006-04-28 | 2007-11-01 | Microsoft Corporation | Demonstration scripting using random-access frame presentation |
US8307286B2 (en) * | 2006-05-07 | 2012-11-06 | Wellcomemat Llc | Methods and systems for online video-based property commerce |
US20080033641A1 (en) * | 2006-07-25 | 2008-02-07 | Medalia Michael J | Method of generating a three-dimensional interactive tour of a geographic location |
US20080055306A1 (en) * | 2006-09-05 | 2008-03-06 | William Ming Yi Kwok | Virtual three-dimensional environment |
US20080177793A1 (en) * | 2006-09-20 | 2008-07-24 | Michael Epstein | System and method for using known path data in delivering enhanced multimedia content to mobile devices |
US20080109433A1 (en) * | 2006-11-06 | 2008-05-08 | Rose Norvell S | Internet-based real estate searching system and process |
US20080184122A1 (en) * | 2007-01-13 | 2008-07-31 | Grant Michael A | System and method for conducting on-line discussions. |
AU2008207288A1 (en) * | 2007-01-17 | 2008-07-24 | Hear Here Satellite Narration Pty Limited | Contextually enhanced multi channel location based tour guidance system |
WO2008147874A2 (en) * | 2007-05-22 | 2008-12-04 | Vidsys, Inc. | Event capture, cross device event correlation, and responsive actions |
DE102007029841B4 (en) * | 2007-06-28 | 2011-12-22 | Airbus Operations Gmbh | Interactive information system for an aircraft |
US20090109223A1 (en) * | 2007-10-29 | 2009-04-30 | The Boeing Company | System and Method for Virtual Journey Futuring |
-
2009
- 2009-08-10 DK DK09789098.2T patent/DK2324460T3/en active
- 2009-08-10 WO PCT/US2009/004565 patent/WO2010019205A1/en active Application Filing
- 2009-08-10 CN CN200980139901.6A patent/CN102177530B/en active Active
- 2009-08-10 US US12/538,590 patent/US8302007B2/en active Active
- 2009-08-10 AU AU2009282475A patent/AU2009282475B2/en active Active
- 2009-08-10 JP JP2011522976A patent/JP5524965B2/en active Active
- 2009-08-10 CA CA2733274A patent/CA2733274C/en active Active
- 2009-08-10 KR KR1020117005743A patent/KR101626038B1/en active IP Right Grant
- 2009-08-10 EP EP09789098.2A patent/EP2324460B1/en not_active Not-in-force
-
2012
- 2012-09-05 US US13/603,717 patent/US9230365B2/en active Active
Also Published As
Publication number | Publication date |
---|---|
CN102177530B (en) | 2014-09-03 |
US20100042923A1 (en) | 2010-02-18 |
US9230365B2 (en) | 2016-01-05 |
CN102177530A (en) | 2011-09-07 |
US8302007B2 (en) | 2012-10-30 |
KR101626038B1 (en) | 2016-05-31 |
DK2324460T3 (en) | 2013-09-30 |
AU2009282475A1 (en) | 2010-02-18 |
AU2009282475B2 (en) | 2014-12-04 |
KR20110052706A (en) | 2011-05-18 |
EP2324460B1 (en) | 2013-06-19 |
EP2324460A1 (en) | 2011-05-25 |
JP2011530766A (en) | 2011-12-22 |
US20120331416A1 (en) | 2012-12-27 |
CA2733274A1 (en) | 2010-02-18 |
WO2010019205A1 (en) | 2010-02-18 |
CA2733274C (en) | 2016-11-29 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
JP5524965B2 (en) | Inspection in geographic information system | |
CN110944727B (en) | System and method for controlling virtual camera | |
US11099654B2 (en) | Facilitate user manipulation of a virtual reality environment view using a computing device with a touch sensitive surface | |
JP7248859B2 (en) | Methods and systems for generating and displaying 3D video within virtual, augmented, or mixed reality environments | |
US10657693B2 (en) | Method for scripting inter-scene transitions | |
US10142561B2 (en) | Virtual-scene control device | |
US9367942B2 (en) | Method, system and software program for shooting and editing a film comprising at least one image of a 3D computer-generated animation | |
US8271962B2 (en) | Scripted interactive screen media | |
US8508534B1 (en) | Animating objects using relative motion | |
KR101575092B1 (en) | Method, system and computer-readable recording medium for creating motion sequence of animation | |
TW200839647A (en) | In-scene editing of image sequences | |
JP2020523668A (en) | System and method for configuring virtual camera | |
US8797315B1 (en) | Segmented editor for tours of a geographic information system, and applications thereof | |
Hayashi et al. | Virtual Museum Equipped with Automatic Video Content Generator | |
US20130156399A1 (en) | Embedding content in rich media | |
CN117482531A (en) | Method and device for processing motion editing in game, storage medium and electronic equipment |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A621 | Written request for application examination |
Free format text: JAPANESE INTERMEDIATE CODE: A621Effective date: 20120809 |
|
A977 | Report on retrieval |
Free format text: JAPANESE INTERMEDIATE CODE: A971007Effective date: 20130820 |
|
A131 | Notification of reasons for refusal |
Free format text: JAPANESE INTERMEDIATE CODE: A131Effective date: 20130903 |
|
A601 | Written request for extension of time |
Free format text: JAPANESE INTERMEDIATE CODE: A601Effective date: 20131202 |
|
A602 | Written permission of extension of time |
Free format text: JAPANESE INTERMEDIATE CODE: A602Effective date: 20131209 |
|
A601 | Written request for extension of time |
Free format text: JAPANESE INTERMEDIATE CODE: A601Effective date: 20131227 |
|
A602 | Written permission of extension of time |
Free format text: JAPANESE INTERMEDIATE CODE: A602Effective date: 20140110 |
|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20140127 |
|
TRDD | Decision of grant or rejection written | ||
A01 | Written decision to grant a patent or to grant a registration (utility model) |
Free format text: JAPANESE INTERMEDIATE CODE: A01Effective date: 20140320 |
|
A61 | First payment of annual fees (during grant procedure) |
Free format text: JAPANESE INTERMEDIATE CODE: A61Effective date: 20140410 |
|
R150 | Certificate of patent or registration of utility model |
Ref document number: 5524965Country of ref document: JPFree format text: JAPANESE INTERMEDIATE CODE: R150 |
|
R250 | Receipt of annual fees |
Free format text: JAPANESE INTERMEDIATE CODE: R250 |
|
S533 | Written request for registration of change of name |
Free format text: JAPANESE INTERMEDIATE CODE: R313533 |
|
R350 | Written notification of registration of transfer |
Free format text: JAPANESE INTERMEDIATE CODE: R350 |
|
R250 | Receipt of annual fees |
Free format text: JAPANESE INTERMEDIATE CODE: R250 |
|
R250 | Receipt of annual fees |
Free format text: JAPANESE INTERMEDIATE CODE: R250 |
|
R250 | Receipt of annual fees |
Free format text: JAPANESE INTERMEDIATE CODE: R250 |
|
R250 | Receipt of annual fees |
Free format text: JAPANESE INTERMEDIATE CODE: R250 |
|
R250 | Receipt of annual fees |
Free format text: JAPANESE INTERMEDIATE CODE: R250 |
|
R250 | Receipt of annual fees |
Free format text: JAPANESE INTERMEDIATE CODE: R250 |
|
R250 | Receipt of annual fees |
Free format text: JAPANESE INTERMEDIATE CODE: R250 |