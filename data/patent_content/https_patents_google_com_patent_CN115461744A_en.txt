CN115461744A - Processing machine learning modeling data to improve accuracy of classification - Google Patents
Processing machine learning modeling data to improve accuracy of classification Download PDFInfo
- Publication number
- CN115461744A CN115461744A CN202180019134.6A CN202180019134A CN115461744A CN 115461744 A CN115461744 A CN 115461744A CN 202180019134 A CN202180019134 A CN 202180019134A CN 115461744 A CN115461744 A CN 115461744A
- Authority
- CN
- China
- Prior art keywords
- user
- mpc
- application
- model
- computing system
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/60—Protecting data
- G06F21/62—Protecting access to data via a platform, e.g. using keys or access control rules
- G06F21/6218—Protecting access to data via a platform, e.g. using keys or access control rules to a system of files or objects, e.g. local or distributed file system or database
- G06F21/6245—Protecting personal data, e.g. for financial or medical purposes
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/953—Querying, e.g. by the use of web search engines
- G06F16/9535—Search customisation based on user profiles and personalisation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N5/00—Computing arrangements using knowledge-based models
- G06N5/04—Inference or reasoning models
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L67/00—Network arrangements or protocols for supporting network services or applications
- H04L67/2866—Architectures; Arrangements
- H04L67/30—Profiles
- H04L67/306—User profiles
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04W—WIRELESS COMMUNICATION NETWORKS
- H04W12/00—Security arrangements; Authentication; Protecting privacy or anonymity
- H04W12/02—Protecting privacy or anonymity, e.g. protecting personally identifiable information [PII]
Abstract
A first multi-party computing (MPC) system of an MPC cluster can receive an inference request from an application on a client device, the inference request including a first share and a performance threshold for a given user profile of a user of the application. A nearest neighbor set of the user profile can be identified by performing a secure MPC process using the trained machine learning model in cooperation with one or more second MPC systems. One or more nearest neighbors can be selected from the nearest neighbor set that have a performance metric that satisfies a performance threshold. The first MPC system may be capable of passing data derived from one or more nearest neighbors to the application.
Description
Technical Field
The subject matter described herein relates to training and using machine learning models in a manner that protects user privacy, ensures data security, and improves classification accuracy.
Background
Some machine learning models are trained based on data collected from multiple sources (e.g., across multiple websites and/or native applications). However, the data may include private or sensitive data that should not be shared or allowed to be revealed to other parties.
Disclosure of Invention
The present disclosure relates to training and using machine learning models in a manner that protects user privacy and ensures data security. For example, aspects of the present disclosure relate to machine learning models, data input to such models, and data output from such models to accurately classify users into groups of users while protecting user privacy and ensuring data security even if third party cookies are blocked (e.g., blocked by a browser) or otherwise not used. Modification of data input into the model can be referred to as preprocessing, and modification of data output from the model can be referred to as post-processing. As described herein, the pre-processing of data input into the machine learning model and/or the post-processing of data output from the machine learning model allows for more accurate expansion of user groups in order to more accurately classify users into a respective user group or groups.
In one aspect, a first multi-party computing (MPC) system of an MPC cluster can receive an inference request from an application on a client device, the inference request including a first share and a performance threshold for a given user profile for a user of the application. A nearest neighbor set of the user profile can be identified by performing a secure MPC process using the trained machine learning model in cooperation with one or more second MPC systems. One or more nearest neighbors having a performance metric that satisfies a performance threshold can be selected from the set of nearest neighbors. The first MPC system can communicate data derived from one or more nearest neighbors to the application.
In some embodiments, one or more of the following can additionally be implemented, individually or in any feasible combination. The user profile can be generated by an application. The user profile can include data indicative of interactions between a user of the application and digital content presented on the application. Interactions can include transformations and lack of transformations. The machine learning model can be a nearest neighbor model. The nearest neighbors of the nearest neighbor model can be represented by respective centroids associated with corresponding user groups. The first MPC system can assign a weight to each user of the corresponding group of users to compute the respective centroids. The weight can be based on at least one of a user's interaction or user information related to the performance metric. The centroid of each user group can be the center represented by the mean of the user profiles of the users that are members of the user group. The machine learning model can be one or more of a centroid model or a nearest neighbor model. The performance metric for each nearest neighbor can include at least one of a user interaction rate with the one or more digital components corresponding to the nearest neighbor or a conversion rate of the one or more digital components corresponding to the nearest neighbor. The machine learning model can include a k-nearest neighbor model, and each neighbor in the k-nearest neighbor model represents a user profile of the user. The machine learning model can include a k-nearest neighbor model, and each neighbor in the k-nearest neighbor model represents a user group of the plurality of users. The performance threshold is a threshold. The conversion rate of the one or more digital components can be the number of conversions divided by the number of times the one or more digital components are displayed to the user in the group of users. The inference request can be a request to infer whether a user is to be added to a group of users.
Related methods, techniques, systems, and computer program products are also described. For example, in another aspect, a system is described that can include at least one programmable processor and a machine-readable medium storing instructions that, when executed by the at least one programmable processor, cause the at least one programmable processor to perform the operations described herein. In another aspect, one or more computer program products (which, in some embodiments, can be a non-transitory computer program product) are described that can store instructions that, when executed by at least one programmable processor, cause the at least one programmable processor to perform the operations described herein.
The subject matter described in this specification can be implemented in particular embodiments to realize one or more of the following advantages. Encryption techniques such as secure multi-party computing (MPC) can be used to solve problems that arise when third party cookies cannot be used to collect data. For example, encryption techniques enable user group extensions based on similarities in user profiles without using third party cookies, which protects user privacy without negatively impacting the ability to extend user groups, and in some cases, provide better user group extensions based on a more complete profile than can be achieved using third party cookies. MPC techniques can ensure that as long as one of the computing systems in an MPC cluster is old (e.g., does not reveal portions of its underlying data in clear), no user data is available in clear by either the computing system or another party. Thus, the claimed method allows for the identification, grouping and transmission of user data, including cross-domain user data, in a secure manner without the need to use third party cookies to determine any relationships between user data. This is a different privacy protection approach than using the plain text user profile, typically collected by third party cookies, to determine the relationship between data (which can expose user data to the entity receiving the third party cookie). By grouping the user data in this way, the efficiency of transferring data content to the user equipment is increased, since no data content not relevant to a particular user needs to be transferred. In particular, third party cookies are not needed, thereby avoiding the storage of third party cookies and improving the storage use. Exponential decay techniques can be used to build a user profile at a client device to reduce the data size of the raw data needed to build the user profile, thereby reducing data storage requirements.
Furthermore, the pre-processing and post-processing of the modeling data ensures that users are more accurately classified into one or more respective user groups. In some embodiments, the k-NN model can be based on such a group of users; such modeling can advantageously be less complex than k-NN models in which users form different points in a high-dimensional space, since there are typically significantly fewer user groups than users. For example, a content platform can have billions of users, but millions of user groups. In this case, training the k-NN model with each neighbor defined as a user group rather than a user can reduce the model by a factor of 1000. Such a narrowing of the model can advantageously require lower data storage requirements to store data (here, a user group and associated data, such as a mapping between different elements) and faster processing to determine whether to add a user to the user group.
The details of one or more variations of the subject matter described herein are set forth in the accompanying drawings and the description below. Other features and advantages of the subject matter described herein will be apparent from the description, the drawings, and the claims.
Drawings
FIG. 1 is a block diagram of an environment in which a secure MPC cluster generates a machine learning model and the machine learning model is used to extend a group of users.
FIG. 2 is a swim lane diagram of an exemplary process for generating a centroid model and adding a user to a user group using the centroid model.
Fig. 3 is a flow diagram illustrating an exemplary process for generating and sending a user profile to an MPC cluster.
FIG. 4 is a flow diagram illustrating an exemplary process for generating a centroid model.
FIG. 5 is a swim lane diagram illustrating an exemplary process for adding a user to a user group using a centroid model.
FIG. 6 is a swim lane diagram showing an exemplary process for generating a centroid model and adding a user to a user group corresponding to the centroid model using the centroid model.
FIG. 7 is a flow diagram illustrating an exemplary process for determining user group results based on user profile data and a centroid model for a user.
FIG. 8 is a swim lane diagram of an exemplary process for training a k-NN model and adding users to a user group using the k-NN model.
Fig. 9 is a flow diagram illustrating an exemplary process for generating a user profile and sending shares of the user profile to an MPC cluster.
FIG. 10 is a flow diagram illustrating an exemplary process for generating a k-NN model.
FIG. 11 is a flow diagram illustrating an exemplary process for adding a user to a user group using a k-NN model.
FIG. 12 is a flow diagram illustrating an exemplary process for training and deploying k-NN models to efficiently classify users into one or more respective user groups.
FIG. 13 is a block diagram of an exemplary computer system.
Like reference symbols in the various drawings indicate like elements.
Detailed Description
In general, this document describes systems and techniques for training and using machine learning models to extend user group membership while protecting user privacy and ensuring data security even if third-party cookies are blocked (e.g., by a browser) and/or collection of user profiles is otherwise not feasible. Typically, rather than creating and maintaining a user profile at a computing system of another entity, such as a content platform, a user profile is maintained at a client device of a user. To train the machine learning model, a user's client device can optionally send its encrypted user profile (e.g., as a secret share of the user profile) along with other data to multiple computing systems of a secure multi-party computing (MPC) cluster via a content platform. For example, each client device can generate two or more shares of the user profile, e.g., secret shares, and send the respective secret shares to each computing system. In some implementations, different subsets of the information in each user profile are provided to each computing system such that there is no overlap in the user profile data sent to each computing system.
The computing systems of the MPC cluster can use MPC techniques to train a machine learning model for suggesting user groups for a user based on the user's profile in a manner that prevents any computing system of the MPC cluster (or other party other than the user itself) from obtaining any user's profile in the clear, thereby protecting user privacy. Plaintext (which can also be referred to as plaintext) is text written in code or data (including binary files) in a form without computational marking, special formatting, or in a form that can be viewed or used without the need for a key or other decryption device or other decryption process. The machine learning model can be a centroid model and/or a k-nearest neighbor (k-NN) model. In the centroid model, the centroid model of the user group can represent a center of the user profile, such as a center (e.g., an average) of the user profiles of the users that are members of the user group. In the k-NN model, the model assumes that similar users exist in close proximity, enabling similar users to be classified into the same or similar user groups.
After the machine learning model is trained, the machine learning model can be used to suggest one or more user groups for each user based on their profile. For example, a user's client device can query the MPC cluster for the user's suggested group of users, or determine whether the user should be added to a particular group of users. In an embodiment where a centroid model is deployed, the MPC cluster can use the user profile of the user to identify a group of users having centroids within a threshold distance of the user profile of the user. In embodiments using k-NN models, user groups can be identified using various inference techniques, such as binary classification, regression (e.g., using arithmetic mean or root mean square), and/or multi-class classification. User group memberships for a user can be used in a privacy-protected and secure manner to provide content (e.g., digital content) to the user.
The MPC cluster is capable of selecting a group of users for the user based on the performance metrics for the group of users. For example, the MPC cluster can select a group of users having a user interaction rate (e.g., click-through rate (CTR)) or conversion rate that meets (e.g., meets or exceeds) a performance threshold. The performance metrics of the user group can reflect performance of one or more digital components corresponding to the user group, e.g., performance of digital components distributed to the user based on the user being a member of the user group.
Exemplary System for generating and Using machine learning models
FIG. 1 is a block diagram of an environment 100 in which secure MPCs 130 cluster train machine learning models and the machine learning models are used to extend user groups. The exemplary environment 100 includes a data communication network 105, such as a Local Area Network (LAN), a Wide Area Network (WAN), the internet, a mobile network, or a combination thereof. Network 105 connects client devices 110, secure MPC cluster 130, publishers 140, websites 142, and content platforms 150. Exemplary environment 100 may include many different client devices 110, secure MPC clusters 130, publishers 140, websites 142 and content platforms 150.
The client device 110 is an electronic device capable of communicating over the network 105. Exemplary client devices 110 include personal computers, mobile communication devices (e.g., smart phones), and other devices capable of sending and receiving data over the network 105. The client device can also include a digital assistant device that accepts audio input through a microphone and outputs audio output through a speaker. When the digital assistant detects a "hot word" or "hot phrase" that activates the microphone to accept audio input, the digital assistant can be placed in a listening mode (e.g., ready to accept audio input). The digital assistant device can also include a camera and/or a display to capture images and visually present information. The digital assistant can be implemented in different forms of hardware devices, including a wearable device (e.g., a watch or glasses), a smartphone, a speaker device, a tablet device, or another hardware device. The client device can also include a digital media device, such as a streaming device that plugs into a television or other display to stream video to the television, a game console, or a virtual reality system.
The client device 110 typically includes an application 112, such as a web browser and/or a native application, to facilitate sending and receiving data over the network 105. A native application is an application developed for a particular platform or a particular device (e.g., a mobile device with a particular operating system). The publisher 140 can develop and provide the native application to the client device 110, e.g., making it available for download. The web browser can request the resource 145 from a web server hosting the publisher's 140 website 142, for example, in response to a user of the client device 110 entering a resource address of the resource 145 or selecting a link referencing the resource address in an address bar of the web browser. Similarly, the native application can request application content from a publisher's remote server.
Some resources, application pages, or other application content can include a digital component slot for rendering a digital component having a resource 145 or application page. As used throughout this document, the phrase "digital component" refers to a discrete unit of digital content or digital information (e.g., a video clip, an audio clip, a multimedia clip, an image, text, or another unit of content). The digital components can be electronically stored in the physical memory device as a single file or in a collection of files, and the digital components can take the form of video files, audio files, multimedia files, image files, or text files, and include advertising information such that the advertisement is one type of digital component. For example, the digital component may be content intended to supplement the content of a web page or other resource presented by the application 112. More specifically, the digital components may include digital content related to the resource content (e.g., the digital components may relate to the same subject matter as the web page content, or to related subject matter). Thus, the provision of digital components can supplement and generally enhance web page or application content.
When application 112 loads a resource (or application content) that includes one or more slots for digital components, application 112 can request digital components for each slot. In some implementations, the digital component slot can include code (e.g., script) that causes the application 112 to request the digital component from a digital component distribution system that selects and provides the digital component to the application 112 for presentation to a user of the client device 110.
Some publishers 140 use SSPs to manage the process of obtaining digital components for their digital component slots for their resources and/or applications. SSPs are technical platforms implemented in hardware and/or software that automate the process of obtaining digital components for resources and/or applications. Each publisher 140 can have a corresponding SSP or SSPs. Some publishers 140 may use the same SSP.
The digital component provider 160 can create (or otherwise publish) digital components that are presented in digital component slots of publishers' resources and applications. The digital component provider 160 can use the DSP to manage its provisioning of digital components for rendering in the digital component slots. A DSP is a hardware and/or software implemented technology platform that automates the process of distributing digital components for presentation with resources and/or applications. The DSP can interact with multiple vendor platforms SSP on behalf of a digital component provider 160 to provide digital components for presentation with multiple different publisher 140 resources and/or applications. In general, the DSP can receive a request for a digital component (e.g., from the SSP), generate (or select) selection parameters for one or more digital components created by one or more digital component providers based on the request, and provide data related to the digital component (e.g., the digital component itself) and the selection parameters to the SSP. The SSP can then select a digital component for presentation at the client device 110 and provide the client device 110 with data that causes the client device 110 to present the digital component.
In some cases, it may be beneficial for a user to receive digital components related to web pages, application pages, or other electronic resources that the user previously accessed and/or interacted with. To distribute such digital components to users, users can be assigned to groups of users, e.g., groups of user interests, groups of similar users, or other group types involving similar user data, when the users access a particular resource or perform a particular action at a resource, e.g., interact with a particular item presented on a web page, such as (a) click on a link to the particular item, (b) complete a conversion of the particular item by, e.g., adding the item to a virtual shopping cart or purchasing the item, and/or (c) view the particular item for more than a preset amount of time. While the model is described as generating or identifying a user group of users in response to an interaction, in other embodiments the model can perform some interactions in response to and based on the user but lack subsequent interactions — e.g., view digital components, but not click; click on a component, but not translate, etc. -to generate or identify a user group. To make such a distribution, the model is first trained on such data (i.e., signals) that indicate the user's particular interaction type. Training a model based on a signal in which a user performs a particular interaction but lacks subsequent interactions (e.g., the user is displayed the digital component but does not click on it, or the user clicks on the digital component but does not translate it) can be advantageous over models that do not consider such a signal, as it can allow for more accurate training of the model and subsequent deployment of those trained models.
The user group can be generated by the digital component provider 160 or the content platform 150 or the publisher 140. That is, each digital component provider 160 is capable of assigning a user to its group of users when the user accesses the electronic resources of the digital component provider 160. In another example, the content platform 150 can create a user group for the digital component provider 160. In another example, the publisher 140 can create a user group for users who access their website.
To protect user privacy, group membership of a user can be maintained at the user's client device 110, e.g., by one of the applications 112 or the operating system of the client device 110, rather than by a digital component provider, content platform, or other party. In a particular example, a trusted program (e.g., a web browser or operating system) can maintain a list of user group identifiers of users using the web browser or another application ("user group list"). The user group list can comprise a group identifier for each user group to which the user has been added. The digital component provider 160 that creates the user group can specify the user group identifier for its user group. The user group identifier of the user group can describe the group (e.g., a gardening group) or a code (e.g., a non-descriptive alphanumeric sequence) representing the group. The user group list of the user can be stored in a secure storage at the client device 110 and/or can be encrypted at the time of storage to prevent others from accessing the group.
When the application 112 presents resources or application content related to a web page on the digital component provider 160 or the website 142, the resource can request that the application 112 add one or more user group identifiers to the user group list. In response, the application 112 can add one or more user group identifiers to the user group list and securely store the user group list.
The content platform 150 can use the user group membership of the user to select digital components or other content that may be of interest to the user or that may be otherwise beneficial to the user/user device. For example, such digital components or other content may include data that improves the user experience, improves the operation of the user device, or is otherwise beneficial to the user or user device in some other way. However, the user group identifier of the user's user group list can be provided in a manner that prevents the content platform 150 from associating the user group identifier with a particular user, or otherwise accessing the clear text user group identifier, thereby protecting user privacy when using the user group membership data to select digital components.
The application 112 can provide the user group identifier from the user group list to a trusted computing system that interacts with the content platform 150 to select digital components for presentation at the client device 110 based on the user group membership in a manner that prevents the content platform 150 or any other entity that is not the user itself from knowing the full user group membership of the user.
In some cases, it may be beneficial for users and for digital component providers to extend a user group to include users with similar interests or other similar data as users who are already members of the user group. Effectively, this can be accomplished without the use of third party cookies. For example, the first user may be interested in skiing and may be a member of a user group of a particular skiing resort. The second user may also be interested in skiing, but not aware of the ski resort and not a member of the ski resort. If the two users have similar interests or data, such as similar user profiles, the second user may be added to a group of users at the ski resort such that the second user receives content, such as digital components, related to the ski resort, and that content may be of interest to or otherwise beneficial to the second user or its user device. In other words, a user group may be extended to include other users with similar user data.
The secure MPC cluster 130 can train a machine learning model that suggests user groups to the user (or its applications 112) based on the user's profile or can be used to generate suggestions of user groups to the user (or its applications 112) based on the user's profile. The secure MPC cluster 130 includes two computing systems MPC that execute secure MPC techniques to train machine learning models 1 And MPC 2 . Although the example MPC cluster 130 includes two computing systems, more computing systems can be used to perform the MPC process as long as the MPC cluster 130 includes more than one computing system. For example, the MPC cluster 130 can include three computing systems, four computing systems, or another suitable number of computing systems. Using more computing systems in the MPC cluster 130 can provide more security and fault tolerance, but can also increase the complexity of the MPC process.
Computing system MPC within MPC cluster 130 1 And MPC 2 Can be operated by different entities. In this way, each entity may not have access to the full user profile in the clear. For example, a computing system MPC 1 Or MPC 2 Can be operated by a different trusted party than the user, publisher 140, content platform 150, and digital component provider 160. For example, an industry group, government group, or browser developer may maintain and operate a computing system MPC 1 And MPC 2 One of them. Another computing system may be operated by a different one of the groups, such that a different trusted party operates each computing system MPC 1 And MPC 2 . Preferably, the MPC of the different computing systems is operated 1 And MPC 2 Have no incentive to collude to compromise user privacy. In some embodiments, a computing system MPC 1 And MPC 2 Are architecturally separate and are monitored to not communicate with each other outside of performing the secure MPC process described in this document.
In some implementations, the MPC cluster 130 trains one or more machine learning models (e.g., centroid models and/or k-NN models) for each content platform 150 (e.g., each DSP and/or each SSP) and/or for each digital component provider 160. For example, content platform 150 can enable MPC cluster 130 to train machine learning models (e.g., centroid models or k-NN models) for any subset of one or more user groups managed by or to which the content platform has at least read access. For example, each content platform 150 can manage the distribution of digital components of one or more digital component providers 160. The content platform 150 can request that the MPC cluster 130 train a machine learning model (e.g., a centroid model or a k-NN model) for one or more of the digital component providers 160 for which the content platform 150 manages the distribution of digital components. In general, the digital component provider 160 enables the MPC cluster 130 to train a centroid model and/or a k-NN model for one or more user groups created and maintained by the digital component provider 160. Each content platform may implement a different machine learning model that can be uniquely identified by a respective unique model identifier. An exemplary process for training the centroid model and the k-NN model is described in more detail further below.
For embodiments that deploy a centroid model, the centroid model can embed the user into an n-dimensional space. Users in profile space are represented by an n-dimensional vector X = { X = { (X) 1 ，x 2 ，...x n Represents it. The user group R has m users: { X 1 ，X 2 ，...X m }. The centroid of the user group R in the model can becontent platform 150 or the digital component provider 160 may want to find all user groups R such that | X' -Centroid (model, R) | < d, where d is a parameter representing a threshold distance of the Centroid model, e.g., specified by the content platform 150. For ease of subsequent description and brevity, the remaining description related to the centroid model is primarily in terms of training and deploying the centroid model for the content platform 150 (e.g., DSPs and SSPs).However, systems and techniques for generating a centroid model for a digital component provider 160, publisher 140, or other entity and querying the centroid model on behalf of the digital component provider 160 or other entity can also be performed.
After training the machine learning model (e.g., the centroid or k-NN model) for the content platform 150, the content platform 150 can query or cause the application 112 of the client device 110 to query the machine learning model to identify one or more user groups of the user of the client device 110.
More specifically, in embodiments using a centroid model, the content platform 150 can query or request that the application 112 query the centroid model of the content platform 150 to determine whether the user should join any group of users of the content platform 150. In general, MPC cluster 130 is able to determine whether a user profile of a user is within a threshold distance of the centroid of a group of users of content platform 150. If so, the MPC cluster 130 can request that the application 112 add users whose user profiles are within a threshold distance of the centroid to the user group. In some implementations, the model can be queried based on performance metrics (e.g., interaction rates or conversion rates), and a user can be added to a particular group of users if the performance metrics meet respective thresholds.
In some implementations using the k-NN model, the content platform 150 can query or request the application 112 to query the k-NN model to determine whether a threshold number "k" of user profiles closest to the user are members of a particular user group. If so, the content platform 150 may add the user to the user group. If a user group is identified for the user, content platform 150 or MPC cluster 130 can request application 112 to add the user to the user group.
In some implementations, the machine learning model can additionally or alternatively be queried based on a threshold performance metric. At query time, the MPC cluster 130 can identify the k user profiles that are closest to the user profile of the user. For each user group that includes at least one of the k users as a member, the MPC cluster 130 can compute performance metrics for the group based on the user's interactions or transformations and the lack of interactions and transformations with respect to one or more digital components of the user group. The MPC cluster 130 can compare the calculated performance metric to a threshold. For any user group with a performance metric that meets the threshold, the MPC cluster 130 can request that the user be added to that user group. For user groups with performance metrics that do not meet the threshold, the MPC cluster 130 may not request that users be added to the user group.
In some embodiments, the MPC cluster 130 trains the machine learning model based on a group of users rather than individual users. For example, the k-NN model can be trained based on a group of users rather than individual users. In such an example, performance metrics can be computed for each user group in the k-NN model. The k-NN model can then be queried using threshold performance metrics. In this example, the MPC cluster 130 can identify k user groups having aggregated user profiles (e.g., based on the centroid of the group) that are closest to the user's user profile. For any user group with a performance metric that meets the threshold, the MPC cluster 130 can request that the user be added to that user group. For user groups with performance metrics that do not meet the threshold, the MPC cluster 130 may not request that users be added to the user group.
If approved by the user and/or the application 112, the application 112 can add the user group identifier for the user group to a list of user groups stored at the client device 110.
In some implementations, the application 112 can provide a user interface that enables a user to manage the user group to which the user is assigned. For example, the user interface can enable the user to remove the user group identifier, preventing all or certain resources 145, publishers 140, content platforms 150, digital component providers 160, and/or MPC cluster 130 from adding the user to the user group (e.g., preventing entities from adding the user group identifier to a list of user group identifiers maintained by the application 112). This provides better transparency and control for the user.
In addition to the description throughout this document, a user may be provided with controls (e.g., user interface elements with which the user can interact by viewing, clicking, or translating) allowing the user to make selections as to whether and when the systems, programs, or features described herein may enable the gathering of user information (e.g., information about the user's social network, social actions or activities, profession, the user's preferences, or the user's current location), and whether to send content or communications from a server to the user. In addition, certain data may be processed in one or more ways before it is stored or used, so that personally identifiable information is removed. For example, the identity of the user may be processed such that personally identifiable information of the user cannot be determined, or the geographic location of the user (such as to a city, zip code, or state level) may be summarized where location information is obtained such that a particular location of the user cannot be determined. Thus, the user may have control over what information is collected about the user, how the information is used, and what information is provided to the user.
Exemplary Processes for generating and Using centroid models
FIG. 2 is a swim lane diagram of an exemplary process 200 for generating a centroid model and adding a user to a user group using the centroid model. The operation of the process 200 can be performed, for example, by a client device 110, a computing system MPC of an MPC cluster 130 1 And MPC 2 And a content platform 150. The operations of process 200 can also be implemented as instructions stored on one or more computer-readable media, which may be non-transitory, and execution of the instructions by one or more data processing apparatus can cause the one or more data processing apparatus to perform the operations of process 200. Although the following process 200 and other processes are described in terms of two computing system MPC clusters 130, MPC clusters having more than two computing systems can also be used to perform similar processes.
In this exemplary process, a centroid model is used to add the user to the user group. The computation of the centroids of the user group can also be used as a pre-processing stage for other machine learning models (e.g., k-NN models based on the user group rather than the individual user profile). For example, each user group in the k-NN model can be represented by a centroid of the user group.
The content platform 150 can initiate the generation and/or updating of one or more of its centroid models by requesting that the applications 112 running on the client devices 110 generate user profiles for their respective users and upload secret shares and/or encrypted versions of the user profiles to the MPC cluster 130. For the purposes of this document, a secret share of a user profile can be considered an encrypted version of the user profile, since the secret share is not in the clear. In generating, each application 112 can store data of a user profile and generate an updated user profile in response to receiving a request from the content platform 150. Since the content and machine learning models of the user profile differ for different content platforms 150, the application 112 running on the user's client device 110 is able to maintain data for multiple user profiles and generate multiple user profiles, each user profile specific to a particular content platform or specific to a particular center of mass model.
Since the content platform 150 (or digital component provider 160) can have multiple centroid models, e.g., one for each set of one or more user groups, the content platform 150 (or digital component provider 160) can request that the application 112 generate a user profile and simultaneously upload user profiles for multiple user groups and/or multiple centroid models, e.g., with a single request.
The application 112 running on the client device 110 constructs a user profile for a user of the client device 110 (202). The user profile of the user can include data related to events initiated by the user and/or events that can have been initiated by the user with respect to an electronic resource (e.g., a web page or application content). The events can include a view of the electronic resource, a view of the digital component, a user interaction (e.g., one or more of a user's view, click, or conversion of the electronic resource and/or the digital component), or a lack of user interaction with the electronic resource or the digital component (e.g., a lack of user's view, click, or conversion of the electronic resource and/or the digital component), a conversion that occurs (or does not occur) after the user interacts with the electronic resource, and/or other suitable events related to the user and the electronic resource. Since the user profile can change over time, the constructed user profile can be referred to as the current user profile P current 。
The user profile of the user can be specific to the content platform 150 or a selected center of mass model owned by the content platform 150. For example, as described in more detail below with reference to fig. 3, each content platform 150 can request that the application 112 generate or update a user profile specific to that content platform 150. In another example, the content platform 150 can request that the application generate or update a respective user profile for each centroid model of the content platform 150.
User profile P of a user current Can be in the form of a feature vector. For example, a user profile P current Can be an n-dimensional feature vector. Each of the N dimensions can correspond to a particular feature, and the value of each dimension can be a value of a feature of the user. For example, one dimension may be for whether a particular digital component is presented to (or interacts with) a user. In this example, the value of the feature can be "1" if the digital component is presented to (or interacts with) the user, or "0" if the digital component has not been presented to (or interacts with) the user. An exemplary process for generating a user profile for a user is shown in FIG. 3 and described below.
The application 112 generates a user profile P for the user current Is determined (204). In this example, application 112 generates a user profile P current Two secret shares of [ P ] current ,1]And [ P current ,2]One secret share for each computing system of the MPC cluster 130. For the purposes of this document, square bracket 2 is used]Representing secret shares around secret shared elements (e.g., values, vectors, etc.), e.g., for a secret share of the element "secret share, [ secret share")]. For example, the application can associate a user profile P current Splitting into secret shares to protect the user profile P current Is immune to compromised computing systems in the MPC cluster 130. Note that each secret share can itself be a random value that itself does not reveal anything about the user profile. The two secret shares will need to be combined to obtain the user profile. If the MPC cluster 130 includes more computing systems participating in the training of the machine learning model, the application 112 will generate more secret sharesOne secret share for each computing system. An exemplary process for constructing a user profile and generating secret shares for the user profile is shown in FIG. 3 and described below.
In some embodiments where it is desirable to train the model based on user conversions to digital components, it may be considered that the occurrence of conversions can often occur long after a show or click, in which case it can be advantageous to keep the MPC cluster 130 available to perform other tasks in order to optimize the bandwidth, storage, and processing of the content platform 150. In such embodiments, operations 206 and 208 can be replaced by another alternative process in which (i) the application 112 transmits the encrypted shares of the user profile and the tag to a requiring party platform (DSP) along with a first party cookie, which in some embodiments can be part of the content platform 150, and in other embodiments is separate from the content platform 150, (ii) the DSP then uses the first party cookie to map (i.e., associate) the encrypted shares of the user profile and the tag with interaction data that can be specific to the translation (e.g., whether the translation occurred within a preset time period such as 30 days), and (iii) the DSP then transmits the mapping to the computing system MPC 1 Or MPC 2 To train the machine learning model. While the description focuses on converted interactions, the architecture and functionality can be extended to any other interaction (e.g., show or click), or any combination of interactions (e.g., show, click, and/or convert).
Computing system MPC 1 And MPC 2 A centroid model (210) is generated. Computing system MPC 1 And MPC 2 Can be a requestThe centroid model is generated for multiple user groups of the content platform 150 or the digital component provider 160 that the client device 110 uploads the user profile. Each time a new machine learning model is generated based on user profile data can be referred to as a training session. Computing system MPC 1 And MPC 2 A centroid model can be generated based on secret shares of user profiles received from a plurality of client devices. For example, a computing system MPC 1 And MPC 2 MPC techniques can be used to generate a centroid model based on secret shares of the user profile. Typically, generating the centroid model for the user group includes calculating a centroid of a user profile of the user that is a member of the user group. An exemplary process for generating the centroid model is shown in fig. 4 and 6 and described below.
Each centroid model generated and maintained by the MPC cluster 130 can have a corresponding unique identifier. This enables application 112 to query the centroid model using the model identifier. For example, the request to generate the centroid model can include a model identifier for the centroid model, which can be assigned by an owner (e.g., the content platform 150 or the digital component provider 160). The owner can then use the model identifier to request that application 112 query the centroid model to determine whether to add the user to the user group corresponding to the centroid model.
The application 112 submits a user group update request to the MPC cluster 130 (212). The user group update request can include the current user profile P of the user current . In some implementations, the application 112 can integrate the user profile P current Send to each computing system MPC 1 And MPC 2 . In other embodiments, to protect user privacy, the application 112 can configure the user profile P current Is sent to each computing system MPC 1 And MPC 2 。
The user group update request can also include a model identifier for each of the one or more centroid models to query to determine whether the user should be added to the user group corresponding to the centroid model. In some implementations, the application 112 sends a separate user group update request for each centroid model. In this example, each user group request includes a model identifier for one centroid model.
Each user group update request can also include a threshold distance, such as a maximum distance, for the query. If the user profile of the user is within a threshold distance of the centroid of the user group, the MPC cluster 130 can request the application 112 to add the user to the corresponding user group. Exemplary data formats and techniques for transmitting a user group update request are described with reference to fig. 5.
The MPC cluster 130 determines whether the user should be added to one or more user groups (214). In general, this can include determining whether the user profile of the user is within a threshold distance of a centroid for each of the one or more user groups. Computing system MPC 1 And MPC 2 Enabling execution of a secure MPC process to determine if a user should be added to one or more groups of users enables a computing system MPC 1 And MPC 2 Neither any user profile in clear text nor a user group identifier in clear text to be suggested for the user. An exemplary process for determining a user group for a user is shown in fig. 5 and 6 and described below.
The MPC cluster 130 provides zero or more user group identifiers to the application 112 (216). The MPC cluster 130 can provide a user group identifier for each user group to which a user should be added. That is, the MPC cluster 130 can provide a user group identifier for each user group having a centroid of the user profile of the user within a threshold distance. To protect user privacy, each computing system MPC 1 And MPC 2 A part of the user group identifier or a secret share of the user group identifier is provided as described below with reference to fig. 5 and 6.
The content platform 150 transmits the content to the application 112 (222). For example, the content platform 150 can select a digital component based on the user group identifier(s) and provide the digital component to the application 112. In some implementations, the content platform 150 selects the digital component based on the user group identifier(s) in cooperation with the application 112 or device operating system without revealing the user group identifier(s) outside of the application 112 or user device 110.
The application 112 displays or otherwise implements the received content (224). For example, the application 112 can display the received digital component in a digital component slot of the electronic resource.
Exemplary Process for generating a user Profile for a centroid model
Fig. 3 is a flow diagram illustrating an exemplary process 300 for generating and sending a user profile to an MPC cluster. The operations of process 300 can be implemented, for example, by client device 110 of fig. 1, e.g., by application 112 running on client device 110 or an operating system of client device 110. The operations of process 300 can also be implemented as instructions stored on one or more computer-readable media, which may be non-transitory, and execution of the instructions by one or more data processing apparatus can cause the one or more data processing apparatus to perform the operations of process 300.
The application 112 executing on the user's client device 110 receives data for the event (302). An event can be, for example, a presentation of an electronic resource at client device 110, a presentation of a digital component at client device 110, a user interaction with an electronic resource or digital component at client device 110, or a translation of a digital component, or a lack of user interaction or translation with a presented electronic resource or digital component. Some examples of user interactions by a user can be interactions with a particular item presented on a web page, such as one or more of the following: clicking on a link to a particular item, (b) completing a conversion of the particular item by, for example, adding the item to a virtual shopping cart or purchasing the item, (c) viewing the particular item for more than a preset amount of time. Some examples of the lack of a particular user interaction can be that the user performs some interaction but lacks subsequent interaction, e.g., the user views the digital component but does not click; click on the number component, but not translate (e.g., click to go to a checkout web page but not purchase an item); and so on. The transformation can be defined differently in different embodiments. For example, in some implementations, the conversion can be the user navigating to a checkout page. In some embodiments, the conversion can be a user attempting to purchase an item. In other embodiments, the conversion can be a user purchasing an item. When an event occurs, the content platform 150 or the digital component provider 160 can provide data related to the event to the application 112 for use in generating a user profile for the user.
The application 112 can generate a different user profile for each content platform 150 or digital component provider 160. That is, the user's and user profile for a particular content platform 150 may only include event data received from the particular content platform 150. This protects user privacy by not sharing data related to events of other content platforms with the content platform. In some implementations, the application 112 can generate a different user profile for each centroid model owned by the content platform 150, as requested by the content platform 150. Different centroid models may require different training data based on design goals. For example, the first model may be used to determine whether to add a user to a group of users. The second model may be used to predict whether the user will interact with the digital component (e.g., view, click, and/or translate). In this example, the user profile of the second model can include additional data that the user profile of the first model does not have, e.g., whether the user interacted with the digital component.
TABLE 1
The model identifier identifies a centroid model for which the user profile is to be used for training or for user group inferences. A profile record is an n-dimensional feature vector that includes event-specific data, such as the type of event, electronic resources or digital components, the time at which the event occurred, and/or other suitable event data that the content platform 150 (or digital component provider 160) wants to use in training the centroid model and making user group inferences. The operation instruction application 112 updates the user profile based on the profile record. The digital signature is generated based on the seven entries using the private key of the content platform 150.
In some embodiments, to protect the update token M during transmission update The content platform 150 is updating the token M update Update token M before sending to application 112 update And performing encryption. For example, the content platform 150 can use a public key of an application (e.g., pubKeyEnc (M) update Application _ public _ key)) to encrypt the update token M update 。
In some implementations, the content platform 150 can send the event data to the application 112 without updating the token M with the profile update Form coding ofEvent data or update requests. For example, scripts originating from the content platform 150 running inside the application 112 may directly communicate event data and update requests to the application 112 via a script API, where the application 112 relies on a security model based on world wide web consortium (W3C) origin and/or (hypertext transfer protocol secure) HTTPS to protect event data and update requests from forgery or leakage or man-in-the-middle attacks.
The application 112 stores data of the event (304). If the event data is encrypted, the application 112 can decrypt the event data using its private key corresponding to the public key used to encrypt the event data. If the event data is updated with the token M update Is sent, the application 112 can verify the update token M before storing the event data update . Application 112 can verify update token M by update : (i) Verify the digital signature using a public key of the content platform 150 corresponding to a private key of the content platform 150 used to generate the digital signature, and (ii) ensure that the token creation timestamp is not stale, e.g., the time indicated by the timestamp is within a threshold amount of time of the current time at which the verification was performed. If the token M is updated update Valid, the application 112 can store the event data, for example, by storing an n-dimensional profile record. If any of the verifications fail, the application 112 may ignore the update request, for example, by not storing the event data.
For each centroid model, for example, for each unique model identifier, application 112 can store event data for that model. For example, the application 112 can maintain a data structure including a set of n-dimensional feature vectors (e.g., profile records of update tokens) for each unique model identifier and an expiration time for each feature vector. An exemplary data structure for the model identifier is shown in table2 below.
Feature vector | Out of date |
n-dimensional feature vector | Expiration time |
… | … |
TABLE2
Upon receipt of a valid update token M update Application 112 can update token M update Is added to the data structure to update the signature token M comprised in the update token update The data structure of the model identifier in (1). Periodically, the application 112 can clear outdated feature vectors from the data structure to reduce storage size. Expiration time in Table2 and update token M shown in Table 1 update The same.
Upload token M upload Can have and update token M update Similar structure, but with different operations (e.g., "update server" instead of "accumulate user profile"). Upload token M upload Additional entries for operation delays can also be included. As the application 112 accumulates more event data (e.g., more feature vectors), the operational delay can instruct the application 112 to delay computing and uploading secret shares of the user profile. This enables the centroid model to capture user event data immediately before and after some critical events (e.g., joining a user group). The operation delay can specify a delay period. In this exampleThe digital signature can be generated based on the other seven entries in table 1 and the operation delay using the private key of the content platform. The content platform 150 can update the token M with update (e.g., pubKeyEnc (M) upload Application _ public _ key)) in a similar manner, the upload token M is encrypted using the public key of the application upload To protect the upload token M during transmission upload 。
In some implementations, the content platform 150 can request the application 112 to upload the user profile without uploading the token M with the profile upload Encodes the upload request. For example, a script originating from the content platform 150 running inside the application 112 may directly communicate the upload request to the application 112 via a script API, where the application 112 relies on a security model based on W3C origin and/or HTTPS to protect the upload request from forgery or leakage or man-in-the-middle attacks.
If a determination is made not to generate a user profile, process 302 can return to operation 302 and wait for additional event data from content platform 150. If a determination is made to generate a user profile, application 112 generates a user profile (308).
The application 112 can generate a user profile based on stored event data, such as data stored in a data structure shown in Table2A user profile. Application 112 can be based on the model identifier included in the request (e.g., upload token M) upload The content platform tld +1 field of entry 1 and the model identifier of entry 2) to access the appropriate data structure.
In some implementations, the decay rate can be used to calculate a user profile. Since there may be many content platforms 150 that use MPC cluster 130 to train centroid models, and each content platform 150 may have multiple centroid models, storing user feature vector data may result in significant data storage requirements. For the purpose of generating a user profile for training the machine learning model, the use of decay techniques can significantly reduce the amount of data stored at each client device 110.
Assume that, for a given centroid model, there are k eigenvectors { F } 1 ,F 2 ,…F k Each feature vector is an n-dimensional vector and their corresponding times of presence (records _ age _ in _ seconds) i ). The application 112 can calculate the user profile using the following relation 1:
in the relational expression, a parameter record _ age _ in _ seconds i Is the amount of time in seconds that the profile record has been stored at the client device 110, and the parameter decay _ rate _ in _ seconds is (e.g., at the update token M) update Received in entry 6) of profile records in seconds. In this way, the updated feature vector carries more weight.This also enables the application 112 to avoid storing feature vectors and to store profile records with only constant storage. Application 112 need only store the n-dimensional vector P and the timestamp user profile time for each model identifier, rather than storing multiple separate feature vectors for each model identifier.
In the relational expression, a parameter record _ age _ in _ seconds i Is the amount of time in seconds that the profile record has been stored at the client device 110, and the parameter decay _ rate _ in _ seconds is (e.g., at the update token M) update Received in entry 6) of profile records in seconds. In this way, the updated feature vector carries more weight. This also enables the application 112 to avoid storing feature vectors and to store profile records with only constant storage. Instead of storing multiple separate feature vectors for each model identifier, the application 112 need only store the n-dimensional vector P and the timestamp user _ profile _ time for each model identifier.
To initialize the n-dimensional vector user profile P and timestamps, the application can set the vector P to a vector of n-dimensions, with each dimension having a value of zero, and set user _ profile _ time to an epoch. In order to use a new feature vector F at any time x To update the user profile P, the application 112 can use the following relation 2:
when updating the user profile using relation 2, the application 112 can also update the user profile time to the current time (current _ time). Note that if the application 112 calculates the user profile using the decay Rate algorithm described above, operation 304 is omitted.
The application 112 generates a secret share of the user profile (310). The application 112 can use a pseudo-random function to profile the user P current (e.g., n-dimensional vector P current ) Split into secret shares. That is, application 112 can use a pseudo-random function PRF (P) i ) Generating a user profile P current Two secret shares of { [ P ] current,1 ],[P current,2 ]}. The exact split can depend on the secret sharing algorithm and the cryptographic library used by the application 112. In some embodiments, the application uses a Shamir secret sharing scheme.
In some embodiments, the application uses an additive secret sharing scheme, i.e., application 112 generates a random (or pseudo-random) n-dimensional vector nonce. In this example, the application can be generated as P current The first secret share sum of + nonce as P current -a second secret share of nonces. Application 112 can then delete the n-dimensional vector nonce.
To prevent malicious application 112 from abusing the upload API for uploading secret shares of a user profile, MPC cluster 130 can require a trust token issuer to sign the secret shares. For the identifier L of a subscriber group i Each of the represented m user groups and the computing systems MPCs in the MPC cluster 130 1 And MPC 2 Can initiate a trust token redemption process with a trust token issuer to obtain a Signed Redemption Record (SRR). The M user groups can be (i) uploaded by sending the token M upload And (ii) a user group that includes the user as a member, e.g., a user group identified in a user group list maintained by the application 112.
In the trust token redemption process, the application 112 can redeem trust tokens previously issued to the application 112 based on the application 112 and/or the client device 110 being considered trusted. This can include associating trust tokens and information (e.g., computing system MPC) 1 Or MPC 2 And eTLD + 1) is sent to the trust token issuer along with a request to redeem the trust token. The trust token issuer can respond by providing the SRR to the application 112. The application 112 can redeem the trust token for each SRR. An exemplary format of the SRR is shown in table 3 below.
TABLE 3
The application 112 can authenticate a message authentication code (e.g., a hash-based message authentication code (HMAC)) of a model identifier, a secret share of a user profile for which an SRR is generated, a user group L i And the public key (application _ public _ key) of application 112 as a binding. For example, a binding can be represented as HMAC (model _ id, share, L) i Application _ public _ key). For a given user profile and a given centroid model, application 112 can compute the code twice, for user profile P current Once per secret share, thus for each computing system MPC 1 And MPC 2 Once each. For example, a computing system MPC 1 The parameter "share" of the SRR of (A) can be [ P ] current,1 ]And computing the system MPC 2 The SRR parameter "share" of (c) can be [ Pcurrent, 2 ]。
the trust token issuer is able to generate a timestamp and a digital signature. The trust token issuer can generate a digital signature using a private key of the trust token issuer. This enables the recipient of the SRR to verify the signature using the public key corresponding to the private key.
For the identifier L of a subscriber group i Each of the represented m user groups and the computing systems MPCs in MPC cluster 130 1 And MPC 2 Application 112 can then create a user profile update token M profileupdate For transmission to the MPC cluster 130. User profile update token M profileupdate An exemplary format of (a) is shown in table 4 below.
TABLE 4
The application 112 can generate a timestamp and a digital signature. Application 112 can generate a digital signature using the private key of application 112 corresponding to the public key in entry 4. This enables the user profile to update the token M profileupdate The receiver of (a) can verify the signature using a public key corresponding to the private key.
The compromised application 112 may initiate the user profile update operation itself, rather than using the user profile update token M according to the content platform 150 profileupdate The request to do so. To enable the MPC cluster 130 to detect this, the application 112 can optionally update the token M received from the content platform 150 update Involving updating the token M in the user profile profileupdate In (1).
The application 112 transmits a request to update the user profile of the model(s) at the MPC cluster 130 using the user profile of the user (312). Each request can include a secret share of the user profile. For example, the application 112 can have a user profile P current First secret share of [ P ] current,1 ]User profile update token M profileupdate To a computing system MPC 1 And will have a user profile P current Second secret share of [ P ] current,2 ]User profile update token M profileupdate To a computing system MPC 2 . Application 112 can perform this operation on each model identifier for which a user profile update token was created.
In this process, MPC is scheduled for two computing systems in the MPC cluster 130 1 And MPC 2 The application 112 sends m requests to update the user profile, one for each of the m user groups. The m requests may be correlated by a compromised computing system in MPC cluster 130. Such an attack may allow the compromised computing system to learn that application 112 (and its users) may belong to multiple user groups and identifiers of those groups.
To mitigate this risk, an MPC cluster 130 can be utilized. In order to upload secret shares to a computing system MPC 1 Application 112 can send a MPC to a computing system 2 Sending a single request with a first secret share of the user profile P current,1 ]Is intended for a computing system MPC 1 Utilizing computing system MPC separately 1 Is encrypted. The single request can include a set of encrypted results in the form of: pubKeyEnc (M) profileupdate_1 ,MPC 1 ),PubKeyEnc(M profileupdate_2 ,MPC 1 ),…PubKeyEnc(M profileupdate_m ,MPC 1 ) Wherein PubKeyEnc represents a probabilistic asymmetric cryptography algorithm, and MPC 1 Representing a computing system MPC 1 The asymmetric public key of (2).
The probabilistic nature of PubKeyEnc provides semantic security. A semantic security scheme is one in which only negligible information can be extracted from the encrypted result. In a non-coherent computing system MPC 1 In the case of collusion, the computing system MPC 2 No information can be inferred from the encrypted token list. Computing system MPC 2 Capable of decomposing token lists and forwarding to a computing system MPC 1 Sending M requests, each user profile update token M profileupdate One for each request. Computing system MPC 2 A random or pseudo-random delay between successive requests can be used. In another example, a computing system MPC 2 Enabling bulk uploads of multiple requests from multiple applications 112 running on multiple client devices 110 to a computing system MPC 1 To prevent correlating requests from the same application 112.
Computing system MPC 1 And MPC 2 Each received request to update the user profile can be verified. After receiving the encryption result PubKeyEnc (M) profileupdate_i ,MPC j ) Where j is 1 or 2, depending on the computing system, computing system MPC j User profile update token M decrypting the encrypted result to recover the plaintext profileupdate_i . Computing system MPC j Validating user profile update token M profileupdate_i . To this end, the computing system MPC j The digital signature in entry 1.5 of the SRR is verified using the public key extracted from the trust token issuer domain in entry 1.4 of the SRR (see table 3). Computing system MPC j M can also be used profileupdate_i The public key of the application 112 sent to the MPC cluster 130 to verify the user profile update token M profileupdate_i The digital signature in entry 7 of (see table 4).
Computing system MPC j The staleness of the signature timestamp of entry 1.3 of the SRR can also be verified, for example, by ensuring that the timestamp is within a threshold duration of the current time at which the verification was performed. Computing system MPC j It is also possible to verify the publisher origin and current computing system MPC in entry 1.2 of SRR j Is matched. Computing system MPC j It is also possible to verify the value of the binding in entry 1.1 of the SRR and update the token M from the user profile profileupdate_i HMAC (model _ id, share, L) calculated for entry 1-4 in (1) i Application _ public _ key). The computing system MPC can also be able to make sure that the token creation timestamp is being created, for example by ensuring that the token creation timestamp is beingVerifying the user profile update token M within a threshold duration of the current time of performing the verification profileupdate_i The token creation timestamp in entry 5 of (a) is not stale. Computing system MPC j The token creation timestamp can also be used to detect potential replay attacks, e.g., updating the token based on multiple user profiles with the same token creation timestamp. Computing system MPC if any of these verifications fail j The request can be ignored.
MPC for each computing system 1 And MPC 2 A table (or other suitable data structure) can be maintained that includes data for each centroid model. For example, the table can be in the form of table 5 below.
Model ID | User group ID | Sum of all fractions | Number of applications |
model_id | L i | sum_of_shares | number_of_applications |
… | … | … | … |
TABLE 5
A row of the centroid model includes a model identifier (model _ id), a user group identifier (L) for a user group included in the model i ) A sum of all shares of the user profile received for the centroid model, and a number of unique applications 112 (e.g., a number of unique client devices) that submitted secret shares of the user profile of the centroid model and whose secret shares are included in the sum of all shares of the centroid model. The sum of all shares is an n-dimensional vector corresponding to the n-dimensional vector of the user profile.
When receiving a computing system MPC j Model/user group pair { model _ id, L, never received before i When the start time is reached, the MPC of the system is calculated j The sum of all the shares of the centroid model can be initialized to the zero vector and the number of applications to zero. To handle efficient requests to update a user profile for a centroid model comprising a particular model/user group pair, a computing system MPC j Rows for the centroid model/user pair can be found in the table and the sum of all shares and the number of applications for the centroid model/user pair updated. For example, a computing system MPC j The secret shares of the received user profile can be added to the sum of all shares of the centroid model/user group pair and the number of applications increased by one.
Exemplary Process for generating and Using centroid models
FIG. 4 is a flow diagram illustrating an exemplary process 400 for generating a centroid model. The operations of process 400 can be implemented, for example, by MPC cluster 130 of fig. 1. The operations of process 400 can also be implemented as instructions stored on one or more computer-readable media, which may be non-transitory, and execution of the instructions by one or more data processing apparatus can cause the one or more data processing apparatus to perform the operations of process 400. Although process 400 is described in terms of generating multiple centroid models, process 400 can also be used to generate a single centroid model for a single user group. As described above, the process for computing centroids can also be used in a pre-processing phase for k-NN or other machine learning models based on user groups rather than individual user profiles.
MPC for each computing system 1 And MPC 2 A user profile data table is obtained (402). For example, the table can be in the form of table 5 above. Computing system MPC 1 A first secret share [ P ] can be obtained for each model identifier and user group pair including a user group included in the centroid model identifier received from application 112 via the model identifier and user group ID current,1 ]Table of the sum of (a). Similarly, computing system MPC 2 A second secret share [ P ] can be obtained for each model identifier and user group pair including a second secret share received from application 112 through the model identifier and user group ID for the user group included in the centroid model identifier current ,2]Table of the sum of (a).
Each computing system MPC 1 And MPC 2 A user group size threshold is enforced for each model identifier (404). For example, each computing system MPC 1 And MPC 2 A size threshold can be enforced on each row of its table. To enforce the user group size threshold, each computing system MPC 1 And MPC 2 It can be determined whether the number of applications for the model identifier exceeds a predefined size threshold.
Computing system MPC 1 And MPC 2 Rows of the table that meet the size threshold (e.g., information for each model identifier/user group ID pair) are notified to each other (406). For example, a computing system MPC 1 Capable of providing MPC to a computing system 2 The model identifier, the user group identifier, and the number of applications per row for which the number of applications exceeds a size threshold are sent. In addition, computing system MPC 1 Enabling a computing system MPC 2 Sending a sum of the share vectors (sum of shares) for each of the rows 1 ) Second half of (second half) to the computing system MPC 2 . Sum of shares only 1 The transmission of the second half is based on the horizontal partitioning strategy discussed below.
Similarly, computing system MPC 2 Capable of providing MPC to a computing system 1 Sending the model identifier, the user group identifier, and the number of applications per row for which the number of applications exceeds a size threshold. In additionOutside, computing system MPC 2 Enabling a computing system MPC 1 Sending a sum of share vectors (sum of shares) for each of the rows 2 ) First half of (first half) to the computing system MPC 1 。
Computing system MPC 1 Associating the rows in the table for which the number of applications exceeds the size threshold with the slave computing system MPC 2 The received rows are matched. For example, a computing system MPC 1 The model identifiers and/or user group identifiers of the rows can be used to match corresponding rows for the same model and user group. Similarly, computing system MPC 2 Associating the rows in the table for which the number of applications exceeds the size threshold with the slave computing system MPC 1 The received rows are matched. For example, a computing system MPC 2 The model identifiers and/or user group identifiers of the rows can be used to match corresponding rows for the same model and user group. In the following table 6 is shown the MPC in the computing system 1 Example results of this size threshold enforcement and cross notification in tabular form.
TABLE 6
Similarly, in Table 7 below, the MPC is shown in the computing system 2 Example results of enforcement and cross-notification in a size threshold in tabular form.
TABLE 7
For each row, ideally, "from MPC 1 Of "and" from the MPC 2 The value in "number of applications should be the same if both exist for a given pattern identifier. These two values may have a slight difference due to processing delay. If both values are present and both values change significantly, or if one of the values does not exceed a size threshold, then providing noComputing systems that exceed a value of the size threshold may be compromised. For "from MPC 1 Of the application "and" from MPC 2 Those rows whose values in "number of applications meet a proximity threshold (e.g., within a threshold difference of each other) and both exceed a size threshold, the computing system is able to compute its centroid.
Computing system MPC 1 And MPC 2 A centroid of the centroid model is calculated (408). Computing system MPC 1 The first half of the centroid vector for the group of users in the row that satisfies the proximity (e.g., within the threshold difference) and size thresholds can be calculated. Computing system MPC 1 The centroid (centroid) of the model identifier and user group (e.g., for a row) can be calculated using the following relation 3.
Relation 3:
similarly, computing system MPC 2 The centroid of the model identifier and user group (e.g., for a row) can be calculated using relation 4 below.
Relation 4:
the centroid of a user group is typically not privacy sensitive and cannot be easily manipulated to allow malicious applications 112 of MPC cluster 130, content platform 150, or computing system MPC 1 And MPC 2 The user profile is stolen.
At the end of the process, the system MPC is calculated 1 The first half of the centroids of all lists that have a list size threshold exceeded. Examples of the results of this process are shown in tabular form in table 8 below. Computing system MPC 2 The second half of the centroid vector for each model identifier and user group identifier has the same data. The trained centroid models for the user group can include a first centroid model and a second centroid model, the first centroid modelThe heart model comprises a first half of the centroid for each of the user groups, and the second centroid model comprises a second half of the centroid for each of the user groups.
TABLE 8
FIG. 5 is a swim lane diagram illustrating an exemplary process 500 for adding a user to a user group using a centroid model. The operations of process 500 can be implemented, for example, by MPC cluster 130 and client device 110 of fig. 1 (e.g., application 112 running on client device 110). The operations of process 500 can also be implemented as instructions stored on one or more computer-readable media, which may be non-transitory, and execution of the instructions by one or more data processing apparatus can cause the one or more data processing apparatus to perform the operations of process 500.
An application 112 running on a client device 110 can query the MPC cluster 130 for a user's suggested group of users in response to a request from the content platform 150 or digital component provider 160. For example, the request can be to use a centroid model generated for and owned by the requestor to determine whether the user should be added to a group of users owned by the requestor. For example, content platform 150 can manage many user groups, and MPC cluster 130 can train and use one or more centroid models for the user groups to determine whether a user should be added to those user groups.
To request an application to query the centroid model, the requestor can transmit a download group token M to the client device 110 download . Token M download Can have the following entries shown and described in table 9 below.
TABLE 9
In some implementations, the content platform 150 can encrypt the download group token M using the public key of the application 112 download . The content platform 150 can then call the application's API to extract the user group identifier via its own script or the SSP's script. Application 112 can update token M with its decrypted and verified user profile profileupdate In the same way to decrypt and verify the download group token M download 。
For a given tuple of model _ id, user profile P, and threshold distance d, the application 112 should extract all user group identifiers L i Wherein, | P-Centroid (model _ id, li) | < d. In this example, the function Centroid (model _ id, li) is returned from the model _ id and L in Table 8 i The value in the Centroid (Centroid) column of the marked row.
To prevent computing system MPC 1 Or MPC 2 Knowing the user profile P as a whole, the application 112 divides the user profile P of the user into a plurality of portions (502). The application 112 can divide the user profile into respective portions for each computing system of the MPC cluster 130. In this example, the application 112 is able to split the user profile into two parts, the first part for the computing system MPC 1 And the second part is for computing system MPC 2 . Suppose that the user profile P is an n-dimensional vector and the user profile P = { P = 1 ,p 2 ,…,p n Are two halves P 1 And P 2 Will be P 1 ＝{p 1 ,p 2 ,…,p n/2 And P 2 ＝{p n/2+1 ,…,p n }. Computing system MPC 1 And MPC 2 The centroids of their user groups, i.e. centroids Centroid (model _ id, L), can be calculated accordingly i ) Become Centroid 1 (model_id,L i ) And Centroid 2 (model_id,L i )。
In some implementations, the application 112 can also add differential privacy noise to better protect user privacy. For example, the application 112 can add the one-time user noise Δ P to the user profile P, e.g., before splitting the user profile P into multiple parts.
Let P' = P + Δ P. Application 112 applies horizontal partitioning to divide P' into two halves, P 1 ' and P 2 '. Let d' = d + | Δ P |. Application 112 will half P 1 ' send to computing System MPC 1 (504). For example, the application 112 can send a computing system MPC 1 Sending with two parameters P 1 ', d' }. The request can be to extract all subscriber group identifiers L i Wherein, | P 1 ’–Centroid 1 (model_id,L i )|<d’。
Similarly, application 112 will couple the posterior half P 2 ' send to computing System MPC 2 (506). For example, application 112 can send a computing system MPC 2 Sending with two parameters P 2 ', d' }. The request can be to extract all subscriber group identifiers L i Wherein, | P 2 ’–Centroid 1 (model_id,L i )|<d’。
In some embodiments where it is desirable to train the model based on user conversions to digital components, it may be considered that the occurrence of conversions can often occur long after a show or click, in which case it can be advantageous to keep the MPC cluster 130 available to perform other tasks in order to optimize the bandwidth, storage, and processing of the content platform 150. In such embodiments, operations 504 and 508 can be replaced by an alternative process in which (i) the application 112 transmits the encrypted shares of the user profile and the tag to a requiring party platform (DSP) that in some embodiments can be part of the content platform 150, and in other embodiments is separate from the content platform 150, along with a first party cookie, (ii) the DSP then uses the first party cookie to map (i.e., associate) the encrypted shares of the user profile and the tag with interaction data that can be specific to the translation (e.g., whether the translation occurred within a preset time period such as 30 days), and (iii) the DSP then transmits the mapping to the computing system MPC 1 Or MPC 2 To train the machine learning model. While the description focuses on translated interactions, the architecture and functionality can be extended to any other interaction (e.g., such asA show or click), or any combination of interactions (e.g., show, click, and/or conversion).
Computing system MPC 1 Can determine that the first half P of the profile P' is in 1 'a set of centroids within a threshold distance d' (508). Computing system MPC 1 The first half P can be determined for each user group 1 ' distance from the centroid of a user group, i.e. | P 1 ’–Centroid 1 (model_id,L i ) L. The application 112 can then determine which user groups have distances less than the distance d'. The user group identifiers of these user groups can be represented by U 1 And (4) showing.
Similarly, computing system MPC 2 Can be determined to have a profile in the second half P of the user profile P 2 'a set of centroids within a threshold distance d' (510). Computing system MPC 2 The latter half P can be determined for each user group 2 ' distance from the centroid of the user group, i.e. | P 2 ’–Centroid 2 (model_id,L i ) L. the method is used for the preparation of the medicament. The application 112 can then determine which user groups have distances less than the distance d'. The subscriber group identifiers of these subscriber groups can be represented by U 2 And (4) showing.
Computing system MPC 1 Grouping user group identifiers U 1 To the application 110 (512). Similarly, computing system MPC 2 Grouping user group identifiers U 2 To the application 110 (514).
Previous methods assumed that the centroids of user groups were not privacy sensitive and revealed that browsers should join the MPC 1 And MPC 2 A superset of the user groups of any one of (i.e., U) 1 U 1 And U 2 U 2 ) Is acceptable. In the case where stronger privacy protection is required, the following method can be used. FIG. 6 is a swim lane diagram illustrating an exemplary process 600 for generating a centroid model and using the centroid model to add a user to a group of users corresponding to the centroid model with greater privacy protection. The operations of process 600 can be implemented, for example, by MPC cluster 130 and client device 110 of fig. 1 (e.g., application 112 running on client device 110). The operations of process 600 can also be implemented as instructions stored on one or more computer-readable media, which can be non-transitory, and execution of the instructions by one or more data processing apparatus can cause the one or more data processing apparatus to perform the operations of process 600.
The MPC cluster 130 can train a centroid model for one or more user groups. In this example, the centroid model is queried using secret shares of the user profile. Thus, each computing system MPC 1 And MPC 2 The secret shares of the user profiles of the training set (e.g., the secret shares of the user profiles uploaded by the client device 110) can be used to determine respective secret shares of the centroids of the user groups.
For each user group, computing system MPC 1 A first secret share of a centroid of a user group is computed (602). Centroid model identified by model identifier model _ id and by user group identifier L i The centroid of an identified user group can be represented as sum _ of _ profile (model _ id, L) i ). For as a user group L i All user profiles P of the members of i First secret share [ sum _ of _ profile ] model_id,i,1 ]＝Σ[P j,1 ]. That is, the user group L i Represents the user group L i In (1) user profile P i Is received by the first secret share of (a).
For each user group, computing system MPC 2 A second secret share of the centroid of the user group is computed (604). Centroid model identified by model identifier model _ id and by user group identifier L i Use of marksThe centroid of a household group can be represented as sum _ of _ profile (model _ id, L) i ). For as a user group L i All user profiles P of the members of i Second secret share [ sum _ of _ profile ] model_id,i,2 ]＝Σ[P j,2 ]. That is, the user group L i Represents the user group L i In (1) user profile P i Is given by the sum of the second secret shares of (a).
The centroid model can include a first share of the centroid for each user group and a second share of the centroid for each user group. Enabling MPC in a computing system 1 The first share of each centroid is maintained confidentially and can be MPC at the computing system 2 The second share of each centroid is maintained confidentially.
The application 112 running on the client device 110 divides the user profile of the user into secret shares (606). For example, application 112 can compute a MPC for a computing system 1 Is a first secret share of the user profile P 1 ]And for computing systems MPC 2 Second secret share of user profile P 2 ]. The exact split can depend on the secret sharing algorithm and the cryptographic library used by the application 112. In some embodiments, the application uses a Shamir secret sharing scheme.
TABLE 9
In some embodiments, the application 112 can send two separate requests, as shown in FIG. 6. To conserve bandwidth and battery consumption of client device 110, application 112 can send two requests (e.g., two query tokens M) query1 And M query2 ) Combine into a single request and send the single request to the computing system MPC 1 Or MPC 2 One of them. To this end, the application 112 can be paired to a MPC intended for another computing system 1 Or MPC 2 The query token of (2) is encrypted. For example, application 112 can use a computing system MPC 2 Encrypts the query token M (e.g., using a probabilistic asymmetric public key algorithm) query2 . For example, application 112 can use a computing system MPC 2 To generate an encryption result PubKeyEnc (M) query2 ,MPC 2 ). Application 112 can then query token M query1 And an encryption result PubKeyEnc (M) query2 ,MPC 2 ) Sending to a computing System MPC 1 。
Computing system MPC 1 Can be used to calculate the system MPC 1 Verifying update token M profileupdate Verification of the query token M in a similar manner query1 As described above with reference to fig. 3. Computing system MPC 1 It is also possible to have the encryption result PubKeyEnc (M) query2 ,MPC 2 ) Is transmitted to the computing system MPC 2 . Computing system MPC 2 Enabling use of and for encrypting a query token M query2 Its private key corresponding to the public key of (1) decrypts the encrypted result. Then, computing the system MPC 2 Can be used to calculate the system MPC 2 Verifying update token M profileupdate Verification of the query token M in a similar manner query2 As described above with reference to fig. 3.
In some embodiments, each computing system MPC 1 And MPC 2 A user group eligibility _ group for a user group can be determined for each of a plurality of user groups associated with a centroid model i Of the corresponding secret share. User profile and user group eligibility of user group i Indicating whether the user profile of the user is within a threshold distance of a centroid of the user group based on the centroid model.
In this example, each compute MPC 1 And MPC 2 It is possible to find all user groups L associated with the model identifier model _ id i Where 1 ≦ i ≦ N and N is the number of user groups associated with the model identifier model _ id. For each user group L i Computing system MPC 1 The euclidean distance d can be calculated using the following relation 5 i,1 ]The first secret share of the square of (a).
Relation 5:
[d i，1 ]＝∑([P 1 ]×num_apps_group i -[sum_of_profile_modgl_id i，1 ]) 2
in relation 5, the parameter num _ apps _ group i Representing the number of applications in a user group (e.g. the number of unique users) and for which a user profile is used to generate the user group L i The center of mass of (c). Then, computing the system MPC 1 The user profile and the user group eligibility _ group of the user group can be calculated using the following relation 6 i First secret share [ origin _ group ] i，1 ]：
Relation 6:
[eligible_group i，1 ]＝[d i，1 ]＜(num_apps_group i ×d) 2
that is, computing system MPC 1 It can be calculated whether the first secret share of the euclidean distance is less than a threshold distance. Computing system MPC 2 The user profile and the user group eligibility _ group of the user group can be calculated in a similar manner using the following relations 7 and 8 i Second secret share [ origin _ group ] i，2 ]。
Relation 7:
[d i，2 ]＝∑([P 2 ]×num_apps_group i -[sum_of_profile_model_id i，2 ]) 2
relation 8:
[eligible_group i，2 ]＝[d i，2 ]＜(num_apps_group i ×d) 2
MPC for each computing system 1 And MPC 2 Their respective secret shares of the user group qualifications can be communicated to the application 112. The application 112 can then combine the secret shares to determine whether to add the user to the user group. Since the response size is proportional to the number of user groups in the model, the response size can be large for content platforms having a large number of user groups associated with the centroid model. However, when the number of user groups is small or bandwidth consumption is not an issue, such a technique for determining whether to add a user to a user group can be used. The remaining operations of the process 600 provide an improvement over this technique, which can be used when the number of user groups may be large, and greatly reduce the response size.
Conceptually, the user group qualification eligible _ group for a user profile and a user group i Application 112 can randomly or pseudo-randomly generate two numbers g i And h i Each number has a value of zero or one with equal probability. In this example, g i And h i The sum of (c) will be zero with a probability of 25%, one with a probability of 50%, or two with a probability of 25%.
The application 112 can qualify the user group as eligible group i Is estimated as (g) i +h i ) =1. Via table 10 below, the mpc cluster 130 can inform the application 112 whether its estimation is correct.
Watch 10
For example, if g i +h i =1 and eligible _ group i =1, the application correctly estimates the eligible _ group i Such that the value of the corresponding cell is 1. On the other hand, if g i +h i =2 and eligible _ group i =1, the application 112 incorrectly estimates the eligible _ group i Such that the value of the corresponding cell is0. In this case, the application 112 can flip its estimate so that the application 112 can correctly estimate the eligible _ group i The value of (c). It can be verified that the above table is equivalent to:
(1-eligible_group i )×(1-(g i +h i -1) 2 )+eligible_group i ×(g i +h i -1) 2
to implement this concept using secure MPC, the application 112 can generate two random (or pseudo-random) seed (e.g., 16 bytes or another suitable data size) 1 And seed 2 (612). The application 112 can seed the first seed 1 Sending to a computing System MPC 1 . The application 112 can seed the second seed 2 Sending to a computing System MPC 2 。
The MPC cluster 130 can use a pseudo-random function (PRF) and a seed to generate the number g i And h i They may be random or pseudo-random. The PRF can be a function that generates a value of 0 or 1 with 50% probability. For example, the PRF can be one such that PRF (seed, i) → {0,1}. Computing system MPC 1 Can use PRF and seed 1 To generate g i (e.g., PRF (seed) 1,i ) And computing system MPC 2 Can use PRF and seed 2 To generate h i (e.g., PRF (seed) 2,i )). Number g i And h i Is g i +h i Is the application's pair of whether the user should be added to the user group L i Estimate of) which can be expressed as [ g ] i ]And [ h ] i ]To indicate that they are secret shares.
The MPC cluster 130 is not computed in the clear (1-eligible _ group) i )×(1-(g i +h i -1) 2 )+eligible_group i ×(g i +h i -1) 2 But rather as a secret share (1- [ identity _ group) i ])×(1-([g i +h i ]-1) 2 )+[eligible_group i ]×([g i +h i ]-1) 2 . Note that in this equation, it includes the square of the secret share and the multiplication between two secret shares.Using a computing system MPC 1 And MPC 2 The calculation of the sum-of-squares multiplication of the secure MPC process in between can require two computing systems MPC 1 And MPC 2 One round of Remote Procedure Calls (RPC) in between. All other operations can be at each computing system MPC 1 And MPC 2 Internal local execution.
In particular, a computing system MPC 1 And MPC 2 Can calculate each user group L i Is estimated flag i The secret share of (c). Estimated flag of user group i Indicating whether the application 112 correctly evaluated whether the user should be correctly added to the user group.
Computing system MPC 1 Calculating L for each user group i Is estimated flag i First secret share [ flag ] of i，1 ](618). Computing system MPC 1 Each user group L can be calculated using the following relation 9 i Is evaluated for the first secret share of the flag flagi [ flagi ，1 ]。
Relation 9:
[flag i，1 ]＝(1-[eligible_group i，1 ])×(1-([g i ]-1) 2 )+[eligible_group i，1 ]×([g i ]-1) 2
computing system MPC 2 Calculating L for each user group i Is estimated flag i Second secret share [ flag ] i，2 ](620). Computing system MPC 2 Each user group L can be calculated using the following relation 10 i Is estimated flag i Second secret share [ flag ] i，2 ]。
Relation 10:
[flag i，2 ]＝(1-[eligible_group i，2 ])×(1-([h i ]-1) 2 )+[eligible_group i，2 ]×([h i ]-1) 2
computing system MPC 1 And MPC 2 Reconstructing L per user group i Is estimated flag i (622). Computing system MPC 1 And MPC 2 Capable of using two computing systemsMPC 1 And MPC 2 One RPC in between, based on two secret shares flag i,1 ]To reconstruct each user group L i Is estimated flag i . If the user group L i Is estimated by the flag i Is one, the application accurately estimates whether the user should be added to the user group L i . Because of the computing system MPC 1 And MPC 2 Does not know what the application 112 actually estimated, so knows the user group L i Is estimated by the flag i Will not give the computing system MPC a value of 1 Or MPC 2 Revealing any information.
Computing system MPC 1 Each user group L i Is estimated by the flag i To the application 112 (624). For example, a computing system MPC 1 Flag capable of indicating user group 1 ,flag 2 \8230; } to the application 112. Clear text flag i Has a value of zero or one, i.e. indicates whether it is estimated correctly or incorrectly. That is, a value of one means that the application 112 correctly estimates whether the user should be added to the ith group, and if not, the value is zero. Thus, each plaintext flag i Can be represented by 1 bit.
Computing system MPC for each user group associated with a centroid model 1 Capable of returning a single bit (flag) i ). For a centroid model with one million user groups, the response size would be 128 Kilobytes (KB), which is practical based on the required delay of requests and the frequency with which requests are submitted to the MPC cluster 130.
The application 112 determines whether to add the user to the user group based on the evaluation flag (626). For each user group, the application can calculate the flag i ＝＝(g i +h i = 1). The operation "= =" means an equality operation that returns true if the two values are equal. If the calculation is true, then the application 112 should join the ith user group associated with the centroid model.
The application 112 can then request from the MPC cluster 130 a user group identifier for the user group to which the application 112 should join. To this end, the application 112 can utilize any suitable dense private information retrieval(PIR) Algorithm and embodiments to initiate MPC to a computing system 1 And MPC 2 Dense Private Information Retrieval (PIR). Some embodiments rely on a Distributed Point Function (DPF). For the ith user group that application 112 should join, application 112 can generate two DPFs, g i And h i Such that g if j = i i (j)+h i (j) =1, otherwise g i (j)+h i (j)＝0。
Function g for each point i Computing system MPC 1 A first secret share of the user group identifier result is computed and returned to the application 112 (634). The application 112 can calculate a first secret share of the subscriber group identifier result using the following relation 11.
Relation 11: result i，1 ＝∑ j g i (j)×group_id j
For each point function h i Computing system MPC 2 A second secret share of the user group identifier result is computed and returned to the application 112 (636). The application 112 can calculate a second secret share of the subscriber group identifier result using the following relationship 12.
Relation 12: result i，2 ＝∑ j h i (j)×group_id j
The application 112 can add the user to one or more user groups (638). Application 112 can use the first quota of the user group i,1 And a second fraction result i,2 To reconstruct the user group identifier for each user group that the user should join. For example, if the two secret shares are additive secret shares, the application 112 can sum the two secret shares to obtain the user group identifier for the user group. Application 112 can then applyThe user group identifier is added to the user group list.
In the process 600 of FIG. 6, neither the computing systems in the MPC cluster 130 know the centroid of the user group in the clear, nor the application query parameters, i.e., the user profile, nor the user group to which the user will join, thereby protecting user privacy.
In cases with relaxed privacy requirements, e.g. computing system MPC 1 And MPC 2 Capable of knowing the results of plain text queries, computing system MPC 1 And MPC 2 Being able to reconstruct the user group eligibility _ group from two secret shares i As a result, and if corresponding eligible _ group i If true, the subscriber group identifier L is only used in the query response i Back to the application 112.
In some implementations, the training of the centroid model and the querying of the centroid model can be performed by an aggregation service. The aggregation service can include MPC cluster 130 and communicate with content platform 150, e.g., rather than with client devices 110. In this case, when querying which user groups the application 112 should join, the application 112 may not send the user profile of the user to the content platform 150 for forwarding to the MPC cluster 130 for privacy reasons. One option would be to configure the content platform 150 to communicate the centroids of the user group to the application 112. However, this can consume a large amount of bandwidth.
Another option is for the content platform 150 to infer a user group for use based on the user's secure mobile ID (e.g., flo ID), the first-party cookie data received from the first-party cookie, and the URL of the digital component request. However, this may not be as accurate as the techniques described above.
FIG. 7 is a flow diagram illustrating an exemplary process 700 for determining user group results (i.e., whether the application 112 should join one or more user groups) based on the user profile data and the centroid model of the user. The operations of the process 700 can be implemented, for example, by the MPC cluster 130. The operations of process 700 can also be implemented as instructions stored on one or more computer-readable media, which can be non-transitory, and execution of the instructions by one or more data processing apparatus can cause the one or more data processing apparatus to perform the operations of process 700.
A first request for a subscriber group identifier is received (702). A first computing system of the MPC cluster 130 (e.g., MPC) 1 ) The first request can be received from an application 112 running on the client device 110. The application 112 can provide the MPC cluster 130 with each of the other computing systems (e.g., MPCs) 2 ) A corresponding second request is sent. The request can be for a user group identifier of a user group to which the user is to be added, e.g., each user group whose user profile is within a threshold distance of a centroid of the user group.
In general, each request can include user profile data for a user profile of the user. The first request can include first user profile data, and each second request sent to each second computing system can include corresponding second user profile data. The user profile data can vary based on the cryptographic technique used.
For example, if the MPC process and horizontal partitioning are used to determine the centroid, as described with reference to FIG. 4, each requested user profile data can include a corresponding portion of the user's user profile. If each computing system of the MPC cluster 130 has a secret share of the centroid, each requested user profile data can include a corresponding secret share of the user's user profile. In either case, the user profile data can also include a model identifier of the centroid model and a threshold distance.
A set of user groups corresponding to the model identifier is identified (704). For example, the content platform 150 or the digital component provider 160 can cause the MPC cluster 130 to generate a centroid model for a set of user groups. Each computing system in MPC cluster 130 can store data identifying a user group identifier for the user group corresponding to the centroid model, for example, by linking a model identifier with each user group identifier. The first computing system can identify a set of user groups based on the stored data. Each user group identifier and model identifier can be referred to as a centroid model and user group identifier pair.
For each user group in the set of user groups, a centroid of the user group is identified (706). When the MPC cluster 130 generates the centroid model, the MPC cluster 130 can determine the centroid for each user group corresponding to the centroid model. The form of the centroid can vary based on the cryptographic technique used. For example, if the centroid is determined using the MPC process and horizontal partitioning, as described with reference to fig. 4, each computing system of the MPC cluster 130 can have a centroid for the group of users determined based on a portion (e.g., half) of the sum of the secret shares of the user profile used to generate the centroid. If secret shares are used, each computing system of the MPC cluster 130 can have a secret share of the centroid of the user group.
A user group result is determined (708). The user group results indicate one or more user groups to which the user is to be added. For example, the user group results can indicate a user group having a centroid within a threshold distance of the user profile of the user.
The user group results are transmitted (710). For example, the first computing system can transmit its user group results to an application 112 running on the client device 110.
The first computing system can determine the user group results in different ways depending on the cryptographic technique used, and the user group results can vary based on the cryptographic technique used. For example, if horizontal partitioning is used, the first computing system can determine, for each user group in the set of user groups, whether a first portion of the user profile included in the first user profile data is within a threshold distance of a centroid of the user group previously determined by the first computing system, as described with reference to fig. 5. In this example, the user group result can include a user group identifier for the user group with a centroid within a threshold distance of the user profile of the user. Each other computing system can perform a similar process using its centroid and the received portion of the user profile. Each computing system can provide a user group result that includes a user group identifier for the user group having a centroid within a threshold distance of the user profile of the user. The application of the client device can then determine a user group list to which to add the user based on the user group results received from each computing system, as described with reference to fig. 5.
If secret shares are used, the user group result can include an estimated flag for each user group in the set of user groups, as described with reference to FIG. 6. The evaluation flag of the user group indicates whether the application correctly evaluated whether the user is to be added to the user group. The application 112 can use the evaluation flag to determine whether to add the user to the user group, e.g., based on whether the application 112 evaluates that the user should be added to the user group and whether the evaluation is correct. If so, the application 112 can query the MPC cluster 130 for a user group identifier corresponding to the estimation flag.
Exemplary Processes for generating and Using k-NN models
FIG. 8 is a swim lane diagram of an exemplary process 800 for training a machine learning model and adding a user to a user group using the machine learning model. The operation of the process 800 can be performed, for example, by a client device 110, a computing system MPC of an MPC cluster 130 1 And MPC 2 And a content platform 150. The operations of process 800 can also be implemented as instructions stored on one or more computer-readable media, which may be non-transitory, and execution of the instructions by one or more data processing apparatus can cause the one or more data processing apparatus to perform the operations of process 800. Although the process 800 and the other processes below are described in terms of two computing system MPC clusters 130, MPC clusters having more than two computing systems can also be used to perform similar processes.
The machine learning model can be a k-NN model representing the distance between user profiles of users or user profiles of groups of users. When the k-NN model represents the distance between the user profiles of a user group, each user group can be represented in a model that uses the centroid of the user group.
The content platform 150 can initiate training and/or updating of one of its machine learning models by requesting the applications 112 running on the client devices 110 to generate user profiles for their respective users and upload secret shares and/or encrypted versions of the user profiles to the MPC cluster 130. For the purposes of this document, a secret share of a user profile can be considered an encrypted version of the user profile, since the secret share is not in the clear. In generating, each application 112 can store data of a user profile and generate an updated user profile in response to receiving a request from the content platform 150. Because the content and machine learning models of the user profile are different for different content platforms 150, the application 112 running on the user's client device 110 can maintain data for multiple user profiles and generate multiple user profiles each specific to a particular content platform.
The application 112 running on the client device 110 builds a user profile for the user of the client device 110 (802). The user profile of the user can include data related to events initiated by the user and/or events that can have been initiated by the user with respect to an electronic resource (e.g., a web page or application content). The events can include a view of the electronic resource, a view of the digital component, a user interaction with the electronic resource or the digital component (e.g., a selection of the electronic resource or the digital component) or a lack of user interaction with the electronic resource or the digital component (e.g., a selection of the electronic resource or the digital component), a conversion that occurs after the user interacts with the electronic resource, and/or other suitable events related to the user and the electronic resource. Some examples of user interactions by a user can be interactions with a particular item presented on a web page, such as one or more of the following: clicking on a link for a particular item, (b) completing a conversion of the particular item by, for example, adding the item to a virtual shopping cart or purchasing the item, (c) viewing the particular item for more than a preset amount of time. Some examples of the lack of a particular user interaction can be that the user performs some interaction but lacks a subsequent interaction, e.g., the user views the digital component but does not click; click on the number component, but not translate (e.g., click to go to a checkout web page but not purchase an item); and so on. The transformation can be defined differently in different embodiments. For example, in some implementations, the conversion can be the user navigating to a checkout page. In some embodiments, the conversion can be a user attempting to purchase an item. In other embodiments, the conversion can be a user purchasing an item.
The user profile of the user can be specific to the content platform 150, or a selected machine learning model owned by the content platform 150. For example, as described in more detail below with reference to fig. 9, each content platform 150 can request that the application 112 generate or update a user profile specific to that content platform 150.
The user profile of the user can be in the form of a feature vector. For example, the user profile can be an n-dimensional feature vector. Each of the n dimensions can correspond to a particular feature, and the value of each dimension can be a value of a feature of the user. For example, one dimension may be used for whether a particular digital component is presented to (or interacts with) a user. In this example, the value of the feature can be "1" if the digital component is presented to (or interacts with) the user, or "0" if the digital component has not been presented to (or interacts with) the user. An exemplary process for generating a user profile for a user is shown in FIG. 9 and described below.
In some implementations, the content platform 150 may want to train the machine learning model based on additional signals (such as context signals, signals related to particular digital components, or user-related signals that the application 112 may not know or the application 112 may not have access to, such as the current weather at the user's location). For example, if a digital component is presented to a user in a particular context, the content platform 150 may want to train a machine learning model to predict whether the user will interact with the particular digital component. In this example, for each presentation of a digital component to the user, the context signals can include the geographic location of the client device 110 at the time (if the user granted permission), signals describing the content of the electronic resource with which the digital component is presented, and signals describing the digital component, e.g., the content of the digital component, the type of the digital component, where on the electronic resource the digital component is presented, etc. In another example, one dimension may be used to determine whether a digital component presented to a user is of a particular type. In this example, the value can be 1 for travel, 2 for cooking, 3 for movie, and so on. For convenience of subsequent description, P i Will represent the user profile and additional signals (e.g., contextual information) associated with the ith user profileNumber and/or digital component level signals).
In some embodiments, the application 112 may also be capable of providing one or more tags to the MPC cluster 130. Although the labels may not be used in training machine learning models of certain architectures (e.g., k-NN), the labels can be used to fine-tune hyper-parameters (e.g., the value of k) that control the model training process, or to evaluate the quality of the trained machine learning model, or to make predictions, i.e., to determine whether to suggest user groups for the user. The tags can include, for example, one or more of the user group identifiers of the user and accessible to the content platform 150. That is, the tag can include a user group identifier for a user group managed by the content platform 150 or to which the content platform 150 has read access. In some embodiments, a single tag includes multiple user group identifiers for a user. In some implementations, a user's tags can be heterogeneous and include all user groups that contain the user as a member and additional information, such as whether the user interacts with (e.g., views, clicks, and/or conversions of) a given digital component. This enables the k-NN model to be used to predict whether another user will interact with a given digital component. The tags of each user profile can indicate user group membership of the user corresponding to the user profile.
The tags of the user profile predict a user group to which the user corresponding to the input will be or should be added. For example, the tags corresponding to the k nearest neighbor user profiles of the input user profile predict a user group to which the user corresponding to the input user profile will or should join, e.g., based on similarities between the user profiles. These predictive tags can be used to suggest groups of users to the user or to request that the application add the user to the group of users corresponding to the tags.
If a label is included, application 112 can also associate each label i Splitting into portions, e.g. [ label i,1 ]And [ label i,2 ]. In this manner, MPC is performed at a computing system 1 And MPC 2 Without collusion between them, computing system MPC 1 And MPC 2 Can not be driven from [ P ] i,1 ]Or [ P i,2 ]Reconstruction of P i Or from [ label i,1 ]Or [ label i,2 ]Reconstruction Label label i 。
The content platform 150 can receive shares of user profiles and shares of tags from a plurality of client devices. Content platform 150 can upload the user profile's share to the computing system MPC 1 And MPC 2 To initiate training of the machine learning model. Although the tags may not be used during the training process, the content platform 150 is able to upload the share of the tags to the computing system MPC 1 And MPC 2 For use in evaluating model quality or later querying the model.
The content platform 150 encrypts the first encrypted share (e.g., pubKeyEncrypt ([ P ]) received from each client device 110 i,1 ]||[label i,1 ],MPC 1 ) Upload to computing System MPC 1 (810). Similarly, the content platform 150 encrypts a second encrypted share (e.g., pubKeyEncrypt ([ P ]) i,2 ]||[label i,2 ],MPC 2 ) Upload to computing System MPC 2 (812). The two uploads can be bulk and can include encrypted shares of the user profile and the label received during a particular time period for training the machine learning model.
In some implementations, content platform 150 uploads the first encrypted share to computing system MPC 1 Must be in order to upload the second encrypted share to computing system MPC with content platform 150 2 Are matched. This enables a computing system MPC 1 And MPC 2 Two shares of the same secret, e.g. two shares of the same user profile, can be matched appropriately.
In some implementations, the content platform 150 can explicitly assign the same pseudo-random or sequentially generated identifiers to shares of the same secret to facilitate matching. While some MPC techniques can rely on random shuffling of inputs or intermediate results, MPC techniques described in this document may not include such random shuffling and may instead rely on an upload order to match.
In some implementations, operations 808, 810, and 812 can be replaced by an alternative process, where application 112 directly substitutes [ P [ ] i,1 ]||[label i,1 ]Upload to MPC 1 And will [ P ] i,2 ]||[label i,2 ]Upload to MPC 2 . This alternative process can reduce the infrastructure cost of the content platform 150 to support operations 808, 810, and 812, and reduce the start of training or updating the MPC 1 And MPC 2 The delay of the machine learning model in (1).
In some embodiments where it is desirable to train the model based on user conversions to digital components, it may be considered that the conversion can often occur long after a show or click, in which case it can be advantageous to keep the content platform 150 available to perform other tasks in order to optimize the bandwidth, storage, and processing of the content platform 150. In such an embodiment, operations 808, 810, and 812 can be replaced by another alternative process in which (i) the application 112 transmits the encrypted shares of the user profile and the tag to a requiring party platform (DSP) along with a first party cookie, which in some embodiments can be part of the content platform 150, and in other embodiments is separate from the content platform 150, (ii) the DSP then uses the first party cookie to map (i.e., associate) the encrypted shares of the user profile and the tag with interaction data that can be specific to the translation (e.g., whether the translation occurred within a preset time period such as 30 days), and (iii) the DSP transmits the mapping to the computing system MPC 1 Or MPC 2 To train the machine learning model. Other functions of the content platform 150 as described with reference to operations 808, 810, and 812 can be performed by the DSP in these embodiments. While the description focuses on translated interactions, the architecture and functionality can be extended to any other interaction (e.g., show or click), or any combination of interactions(e.g., show, click and/or convert).
Computing system MPC 1 And MPC 2 A machine learning model is generated (814). Each time a new machine learning model is generated based on user profile data can be referred to as a training session. Computing system MPC 1 And MPC 2 The machine learning model can be trained based on the encrypted shares of the user profile received from the client device 110. For example, a computing system MPC 1 And MPC 2 MPC techniques can be used to train the k-NN model based on the share of the user profile.
To minimize or at least reduce cryptographic computations, and thus to minimize or at least reduce placing of computing system MPCs during both model training and inference in order to protect user privacy and data 1 And MPC 2 With the computational burden on, the MPC cluster 130 can use a stochastic projection technique, such as SimHash, to quickly, safely, and probabilistically quantify the two user profiles P i And P j The similarity between them. By determining the representation of two user profiles P i And P j Determine two user profiles P by the hamming distance between two bit vectors i And P j The hamming distance is proportional with high probability to the cosine distance between the two user profiles.
Conceptually, for each training session, m randomly projected hyperplanes U = { U } can be generated 1 ,U 2 ,…,U m }. The random projection hyperplane can also be referred to as a random projection plane. Computing system MPC 1 And MPC 2 One purpose of the multi-step computation in between is for each user profile P used in the training of the k-NN model i Creating a bit vector B of length m i . At the bit vector B i In each bit B i，j Representing projection plane U j One of which is associated with a user profile P i I.e. for all j e 1, m]，B i，j ＝sign(U j ⊙P i ) Wherein an |, indicates the dot product of two vectors of equal length. That is, each bit represents a user profile P i In the plane U j Which side of the frame. Bit value one representationA positive sign, and a bit value of zero indicates a negative sign.
At each end of the multi-step computation, the two computing systems MPC 1 And MPC 2 Each of which generates an intermediate result that includes the bit vector of each user profile, the share of each user profile, and the share of the tag of each user profile in clear text. For example, a computing system MPC 1 The intermediate results of (a) can be the data shown in table 11 below. Computing system MPC 2 There will be similar intermediate results but with different shares per user profile and per label. To add additional privacy protection, each of the two servers in the MPC cluster 130 can only obtain half of the m-dimensional bit vector in the clear, e.g., computing system MPC 1 Obtaining the first m/2-dimension of all m-dimension bit vectors, calculating the MPC of the system 2 The last m/2 dimensions of all m-dimensional bit vectors are obtained.
Bit vector of plaintext | P i MPC of 1 Portion(s) of | label i MPC of 1 Portion(s) of |
… | … | … |
B i | … | … |
B i+1 | … | … |
… | … | … |
TABLE 11
Two arbitrary user profile vectors P of given unit length i ≠ j i And P j It has been shown that two user profile vectors P, provided that the number of random projections m is sufficiently large i And P j Bit vector B of i And B j Hamming distance between with high probability and user profile vector P i And P j The cosine distance between them.
Based on the intermediate results shown above and because of the bit vector B i Is in the clear, so each computing system MPC 1 And MPC 2 The corresponding k-NN models can be independently created by using the k-NN algorithm (e.g., through training). Computing system MPC 1 And MPC 2 The same or different k-NN algorithms can be used. An exemplary process for training the k-NN model is shown in FIG. 10 and described below. Once the k-NN model is trained, the application 112 can query the k-NN model to determine whether to add the user to the user group.
The application 112 submits an inference request to the MPC cluster 130 (816). In this example, application 112 communicates an inference request to computing system MPC 1 . In other examples, application 112 can communicate an inference request to computing system MPC 2 . The application 112 can submit the inference request in response to a request from the content platform 150 to submit the inference request. For example, the content platform 150 can request that the application 112 query the k-NN model to determine whether the user of the client device 110 should be added to a particular user group. This request can be referred to as an inference request to infer whether a user should be added to a group of users.
To initiate an inference request, content platform 150 can send an inference request token M to application 112 infer . Inference request token M infer Enabling MPC cluster 130 can verify that the application 112 is authorized to query for a particular machine learning model owned by a particular domain. If the model access control is optional, then the request token M is inferred infer Is optional. Inference request token M infer Can have the following entries shown and described in table 12 below.
TABLE 12
In this example, the inference request token M infer Including seven entries and a digital signature generated based on the seven entries using the private key of the content platform 150. eTLD +1 is the valid top level field (eTLD) plus one more level than the common suffix. An exemplary eTLD +1 is "example.com", where ". Com" is the top-level domain.
To request an inference of a particular user, the content platform 150 can generate an inference request token M infer And sends the token to an application 112 running on the user's client device 110. In some implementations, the content platform 150 uses the public key pair inference request token M of the application 112 infer Encryption is performed such that only the application 112 is able to decrypt the inference request token M using its secret private key corresponding to the public key infer . That is, the content platform is able to send PubKeyEnc (M) to the application 112 infer ,application_public_key)。
Conceptually, the inference request can include a model identifier of the machine learning model, the current user profile P i K (number of nearest neighbors to extract), optional additional signals (e.g., context signals or digital component signals), aggregation functions, and aggregation function parameters. However, to prevent clear text of the user profile P i Leakage to computing system MPC 1 Or MPC 2 To protect user privacy, the application 112 can profile the user P i Split into separate parts for MPC 1 And MPC 2 Two shares of [ P ] i,1 ]And [ P i,2 ]. The application 112 can then select two computing systems MPCs for the query, e.g., randomly or pseudo-randomly 1 Or MPC 2 One of them. If application 112 selects computing system MPC 1 Then the application 112 can send the computing system MPC 1 Sending with a first quota P i,1 ]And an encrypted version of the second share (e.g., pubKeyEncrypt ([ P ]) i,2 ],MPC 2 ) A single request for the request. In this example, application 112 uses a computing system MPC 2 To encrypt the second share P i,2 ]To prevent computing system MPC 1 Accessing [ P ] i,2 ]This will enable the computing system MPC 1 Can be selected from [ P ] i,1 ]And [ P i,2 ]Reconstructing a user profile P i 。
As described in more detail below, a computing system MPC 1 And MPC 2 Cooperatively computing a user profile P i K nearest neighbors. Then, computing the system MPC 1 And MPC 2 One of several possible machine learning techniques (e.g., binary classification, multi-class classification, regression, etc.) can be used to determine whether to add a user to a user group based on the k nearest neighbor user profiles. For example, the aggregation function can identify machine learning techniques (e.g., binary, multi-class, regression), and the aggregation function parameters can be based on the aggregation function.
In some embodiments, aggregation function parameters can includeThe context platform 150 is querying the user group identifiers for the user groups of the k-NN model for the user. For example, the content platform 150 may want to know whether to add a user to a user group that is related to hiking and has a user group identifier "hiking". Generally, a computing system MPC 1 And MPC 2 Whether to add a user to a user group can be determined based on the number k of nearest neighbors that are members of the user group (e.g., based on their labels).
The MPC cluster 130 provides the inference result to the application 112 (818). In this example, a computing system MPC receiving a query 1 The inference is sent to application 112. The inference results can indicate whether the application 112 should add the user to zero or more user groups. For example, the user group result can specify a user group identifier for the user group. However, in this example, a computing system MPC 1 The user group will be known. To prevent this, the computing system MPC 1 The share of the inference can be calculated and the system MPC calculated 2 Another share of the same inference can be calculated. Computing system MPC 2 Enabling a computing system MPC 1 An encrypted version of its shares is provided, where the shares are encrypted using the public key of the application 112. Computing system MPC 1 Computing system MPC capable of providing its share of inferred results and user group results to application 112 2 An encrypted version of the share of (a). Application 112 is capable of decrypting computing system MPC 2 And an inference result is calculated from the two shares. An exemplary process for querying the k-NN model to determine whether to add a user to a user group is illustrated in FIG. 11 and described below. In some embodiments, to prevent computing system MPC 1 Counterfeit computing system MPC 2 Calculating the result of (2), calculating the system MPC 2 The results of the application 112 are digitally signed before or after their results are encrypted using their public key. Application 112 uses MPC 2 To verify a computing system MPC 2 The digital signature of (2).
The application 112 displays or otherwise implements the received content (826). For example, the application 112 can display the received digital component in a digital component slot of the electronic resource.
Exemplary Process for generating user profiles Using k-NN models
Fig. 9 is a flow diagram illustrating an exemplary process 900 for generating a user profile and sending shares of the user profile to an MPC cluster. The operations of process 900 can be implemented, for example, by client device 110 of fig. 1, e.g., by application 112 running on client device 110. The operations of process 900 can also be implemented as instructions stored on one or more computer-readable media, which may be non-transitory, and execution of the instructions by one or more data processing apparatus can cause the one or more data processing apparatus to perform the operations of process 900.
An application 112 executing on a user's client device 110 receives data for an event (902). An event can be, for example, a presentation of an electronic resource at client device 110, a presentation of a digital component at client device 110, a user interaction with an electronic resource or digital component at client device 110, or a translation of a digital component, or a lack of user interaction or translation with a presented electronic resource or digital component. Some examples of user interactions by a user can be interactions with a particular item presented on a web page, such as one or more of: clicking on a link to a particular item, (b) completing a conversion of the particular item by, for example, adding the item to a virtual shopping cart or purchasing the item, (c) viewing the particular item for more than a preset amount of time. Some examples of the lack of a particular user interaction can be that the user performs some interaction but lacks subsequent interaction, e.g., the user views the digital component but does not click; click on the number component, but not translate (e.g., click to go to a checkout web page but not purchase an item); and so on. The transformation can be defined differently in different embodiments. For example, in some implementations, the conversion can be the user navigating to a checkout page. In some embodiments, the conversion can be a user attempting to purchase an item. In other embodiments, the conversion can be a user purchasing an item. When an event occurs, the content platform 150 can provide data related to the event to the application 112 for use in generating a user profile for the user.
The application 112 can generate a different user profile for each content platform 150. That is, the user's and user profile for a particular content platform 150 may only include event data received from the particular content platform 150. This protects user privacy by not sharing data related to events of other content platforms with the content platform. In some implementations, the application 112 can generate a different user profile for each machine learning model owned by the content platform 150, as requested by the content platform 150. Different machine learning models may require different training data based on design goals. For example, the first model may be used to determine whether to add a user to a group of users. The second model may be used to predict whether the user will interact with the digital component. In this example, the user profile of the second model can include additional data that the user profile of the first model does not have, e.g., whether the user interacted with the digital component.
The model identifiers identify machine learning models, such as k-NN models, for which the user profiles are to be used for training or for user group inferences. A profile record is an n-dimensional feature vector that includes event-specific data, such as the type of event, electronic resources or digital components, the time at which the event occurred, and/or other suitable event data that the content platform 150 wants to use in training machine learning models and making user group inferences. The digital signature is generated based on the seven entries using the private key of the content platform 150.
In some embodiments, to protect the update token M during transmission update The content platform 150 is updating the token M update Update token M before sending to application 112 update Encryption is performed. For example, the content platform 150 can use a public key of an application (e.g., pubKeyEnc (M) update Application _ public _ key)) to encrypt the update token M update 。
In some implementations, the content platform 150 can send the event data to the application 112 without updating the token M with the profile update Encodes event data or update requests. For example, scripts originating from the content platform 150 running inside the application 112 may directly communicate event data and update requests to the application 112 via a script API, where the application 112 relies on a security model and/or HTTPS based on W3C origin to protect the event data and update requests from forgery or leakage.
The application 112 stores the data for the event (904). If the event data is encrypted, the application 112 can decrypt the event data using its private key corresponding to the public key used to encrypt the event data. If event dataTo update the token M update Is sent, the application 112 can verify the update token M before storing the event data update . Application 112 can verify update token M by update : (i) Verify the digital signature using a public key of the content platform 150 corresponding to a private key of the content platform 150 used to generate the digital signature, and (ii) ensure that the token creation timestamp is not stale, e.g., the time indicated by the timestamp is within a threshold amount of time of the current time at which the verification was performed. If the token M is updated update Valid, the application 112 can store the event data, for example, by storing an n-dimensional profile record. If any of the verifications fail, the application 112 may ignore the update request, for example, by not storing the event data.
For each machine learning model, for example, for each unique model identifier, application 112 can store event data for that model. For example, the application 112 can maintain a data structure including a set of n-dimensional feature vectors (e.g., profile records of update tokens) for each unique model identifier and an expiration time for each feature vector. An exemplary data structure for the model identifier is shown in Table2 above.
Upon receipt of a valid update token M update Application 112 can update token M update Is added to the data structure to update the update token M included in the update token update The data structure of the model identifier in (1). Periodically, the application 112 can clear outdated feature vectors from the data structure to reduce storage size.
Upload token M upload Can have and update token M update Similar structure, but with different operations (e.g., "update server" instead of "accumulate user profile"). Upload token M upload Additional entries for operation delays can also be included. As the application 112 accumulates more event data (e.g., more feature vectors), the operational delay can indicate to the application 112 to delay calculating and uploading shares of the user profile. This enables the machine learning model to capture user event data immediately before and after some critical events (e.g., joining a user group). The operational delay can specify a delay period. In this example, the digital signature can be generated based on the other seven entries in table 1 and the operational delays using the private key of the content platform. The content platform 150 can update the token M with update (e.g., pubKeyEnc (M) upload Application _ public _ key)) in a similar manner, the public key of the application is used to encrypt the upload token M upload To protect the upload token M during transmission upload 。
In some implementations, the content platform 150 can request the application 112 to upload the user profile without uploading the token M with the profile upload Form ofA code upload request. For example, scripts originating from the content platform 150 running inside the application 112 may directly communicate the upload request to the application 112 via a script API, where the application 112 relies on a security model based on W3C origin and/or HTTPS to protect the upload request from forgery or disclosure.
If a determination is made not to generate a user profile, process 902 can return to operation 902 and wait for additional event data from content platform 150. If a determination is made to generate a user profile, the application 112 generates a user profile (908).
The application 112 can generate a user profile based on stored event data, such as data stored in a data structure shown in table 2. Application 112 can be based on the model identifier included in the request (e.g., upload token M) upload The content platform tld +1 field of entry 1 and the model identifier of entry 2) to access the appropriate data structure.
In some implementations, the decay rate can be used to calculate a user profile. Since there may be many content platforms 150 that use MPC cluster 130 to train machine learning models, and each content platform 150 may have multiple machine learning models, storing user feature vector data may result in significant data storage requirements. For the purpose of generating a user profile for training the machine learning model, the use of decay techniques can significantly reduce the amount of data stored at each client device 110.
Suppose that, for a given machine learning model, there are k feature vectors { F } 1 ,F 2 ,…F k Each feature vector is an n-dimensional vector and their corresponding time of existence(record_age_in_seconds i ). The application 112 can calculate the user profile using the following relation 13:
in the relational expression, a parameter record _ age _ in _ seconds i Is the amount of time in seconds that the profile record has been stored at the client device 110, and the parameter decay _ rate _ in _ seconds is (e.g., at the update token M) update Received in entry 6) of the profile record in seconds. In this way, the updated feature vector carries more weight. This also enables the application 112 to avoid storing feature vectors and to store profile records with only constant storage. Application 112 need only store the n-dimensional vector P and the timestamp user profile time for each model identifier, rather than storing multiple separate feature vectors for each model identifier.
To initialize the n-dimensional vector user profile P and timestamps, the application can set the vector P to a vector of n-dimensions, with each dimension having a value of zero, and set user _ profile _ time to an epoch. In order to use a new feature vector F at any time x Updating the user profile P, the application 112 can use the following relation 14:
when updating the user profile using relation 14, application 112 can also update the user profile time to the current time. Note that operation 904 is omitted if the application 112 calculates the user profile using the decay rate algorithm described above. .
The application 112 generates a share of the user profile (910). Application 112 can use a pseudo-random function to associate a user profile P i (e.g., n-dimensional vector P) is split into shares. That is, application 112 can use a pseudo-random function PRF (P) i ) Generating a user profile P i Two shares of { [ P ] i,1 ],[P i,2 ]}. The exact split can depend on the secret sharing algorithm and the cryptographic library used by the application 112. In some embodiments, the application uses the Shamir secret sharing scheme. The application 112 can also generate a share of the label if a share of one or more labels is being provided.
Exemplary Processes for generating and Using k-NN models
FIG. 10 is a flow diagram illustrating an exemplary process 1000 for generating a machine learning model. The operations of the process 1000 can be implemented, for example, by the MPC cluster 130 of fig. 1. The operations of process 1000 can also be implemented as instructions stored on one or more computer-readable media, which may be non-transitory, and execution of the instructions by one or more data processing apparatus can cause the one or more data processing apparatus to perform the operations of process 1000.
The MPC cluster 130 obtains a share of the user profile (1002). The content platform 150 can request the MPC cluster 130 to train the machine learning model by transmitting a share of the user profile to the MPC cluster 130. The content platform 150 can access encrypted shares for the machine learning model received from the client devices 110 over a given period of time and upload those shares to the MPC cluster 130.
For example, content platform 150 can send a MPC to a computing system 1 Transmitting for each user profile P i Of a user profileThe encrypted first share and the encrypted first share of its tag (e.g., pubKeyEncrypt ([ P ]) i,1 ]||[label i,1 ]). Similarly, content platform 150 can send MPC to a computing system 2 Transmitting for each user profile P i And an encrypted second share of its tag (e.g., pubKeyEncrypt ([ P ]) i,2 ]||[label i,2 ])。
In some embodiments where the application 112 sends the secret share of the user profile directly to the MPC cluster 130, the content platform 150 can request the MPC cluster 130 to train the machine learning model by transmitting a training request to the MPC cluster 130.
Computing system MPC 1 And MPC 2 A random projection plane is created (1004). Computing system MPC 1 And MPC 2 Can collaboratively create m random projection planes U = { U = } 1 ,U 2 ,…,U m }. These random projection planes should be kept as two computing systems MPC 1 And MPC 2 Secret share between. In some embodiments, a computing system MPC 1 And MPC 2 Random projection planes are created and Diffie-Hellman key exchange techniques are used to maintain their privacy.
As described in more detail below, a computing system MPC 1 And MPC 2 Projecting their share of each user profile onto each random projection plane, and determining for each random projection plane whether the share of the user profile is on one side of the random projection plane. Then, each computing system MPC 1 And MPC 2 The bit vectors in the secret shares can be constructed from the secret shares of the user profile based on the results of each random projection. Partial knowledge of a user's bit vector (e.g., user profile P) i Whether or not in the projection plane U k One side of) enabling computing system MPC 1 Or MPC 2 Obtain information about P i Some knowledge of the distribution of (a) to the user profile P i The a priori knowledge of unit length is incremental. To prevent computing system MPC 1 And MPC 2 Obtaining access to this information (e.g., where user privacy and/or data security is desired or required)In preferred embodiments), in some embodiments, the random projection plane is in secret shares, thus computing the system MPC 1 And MPC 2 The random projection plane of the plaintext is not accessible. In other embodiments, a random bit flipping pattern can be applied on the random projection results using a secret sharing algorithm, as described in optional operations 1006-1008.
To illustrate how bits are flipped via secret shares, assume that there are two secrets x and y whose values are zero or one with equal probability. If y = =0, then the equation operates [ x = = =0]＝＝[y]The bits of x will be flipped and will be retained if y = =1. In this example, the operation will randomly flip bit x with a 50% probability. The operation can require two computing systems MPC 1 And MPC 2 Remote Procedure Calls (RPCs) in between, and the number of rounds depends on the data size and the selected secret sharing algorithm.
MPC for each computing system 1 And MPC 2 A secret m-dimensional vector is created (1006). Computing system MPC 1 Capable of creating a secret m-dimensional vector S 1 ,S 2 ,…S m In which each element S i With equal probability having a value of zero or one. Computing system MPC 1 Split its m-dimensional vector into two shares, a first share [ S ] 1,1 ],[S 2,1 ],…[S m,1 ]And a second share { [ S ] 1,2 ],[S 2,2 ],…[S m,2 ]}. Computing system MPC 1 Capable of keeping a first share secret and providing a second share to a computing system MPC 2 . Then, computing system MPC 1 The m-dimensional vector S can be discarded 1 ,S 2 ,…S m }。
Computing system MPC 2 It is possible to create a secret m-dimensional vector T 1 ,T 2 ,…T m Wherein each element T i Having a value of zero or one. Computing system MPC 2 Split its m-dimensional vector into two shares, the first share [ T 1,1 ],[T 2,1 ],…[T m,1 ]And a second share { [ T ] 1,2 ],[T 2,2 ],…[T m,2 ]}. Computing system MPC 2 Capable of keeping a first share secretAnd providing the second share to the computing system MPC 1 . Then, computing the system MPC 2 The m-dimensional vector T can be discarded 1 ,T 2 ,…T m }。
Two computing systems MPC 1 And MPC 2 The share of the bit flipping pattern is calculated using secure MPC techniques (1008). Computing system MPC 1 And MPC 2 Can use MPC with computing system 1 And MPC 2 Multiple round trips in between, the secure-share MPC equation tests to compute the share of the bit flip pattern. The bit flip pattern can be based on the operation [ x ] described above]＝＝[y]. That is, the bit flipping pattern can be S 1 ＝＝T 1 ,S 2 ＝＝T 2 ,…S m ＝＝T m }. Let each ST i ＝(S i ＝＝T i ). Each ST i Have a value of zero or one. After MPC operation is completed, computing system MPC 1 First share with bit flip pattern { [ ST { [ 1,1 ],[ST 2,1 ],…[ST m,1 ]And computing the system MPC 2 Second share with bit flip pattern { [ ST { [ 1,2 ],[ST 2,2 ],…[ST m,2 ]}. Each ST i Is such that the two computing systems MPC 1 And MPC 2 Can be applied to two computing systems MPC 1 And MPC 2 Any of which flip bits in the bit vector in an opaque manner.
Each computing system MPC 1 And MPC 2 Its share of each user profile is projected onto each random projection plane (1010). That is, for a computing system MPC 1 Receiving each user profile of the share, computing the system MPC 1 Can reduce the share [ P ] i,1 ]Projected onto each projection plane U j The above. For each share of the user profile and each random projection plane U j This operation is performed resulting in a matrix R in z x m dimensions, where z is the number of available user profiles and m is the number of random projection planes. Each element R in the matrix R i,j Capable of calculating a projection plane U j And fraction [ P i,1 ]By dot product of, e.g., R i,j ＝U j ⊙[P i，1 ]. The operation |, indicates the dot product of two vectors of equal length.
Computing system MPC if bit flipping is used 1 Can be used in a computing system MPC 1 And MPC 2 Between to modify one or more elements R in the matrix i,j The value of (c). For each element R in the matrix R i,j Computing system MPC 1 Can calculate [ ST j,1 ]＝＝sign(R i,j ) As element R i,j The value of (c). Thus, if the element R is i,j Bit in bit flip mode [ ST j,1 ]Has a zero value for its corresponding bit, the element R i,j Will be reversed in sign. The computation can require a MPC to the computing system 2 A plurality of RPCs.
Similarly, for a computing system MPC 2 Calculating the System MPC for each user Profile of the received quota 2 Can adjust the portion [ P i,2 ]Projected to each projection plane U j The above. For each share of the user profile and each random projection plane U j This operation is performed resulting in a matrix R' in the z x m dimension, where z is the number of available user profiles and m is the number of random projection planes. Each element R in the matrix R i,j ' capable of calculating the projection plane U j And fraction [ P ] i,2 ]By dot product of, e.g., R i,’j ＝U j ⊙[P i，2 ]. The operation |, indicates the dot product of two vectors of equal length.
Computing system MPC if bit flipping is used 2 Can be used in a computing system MPC 1 And MPC 2 Between to modify one or more elements R in the matrix i,j The value of. For each element R in the matrix R i,j ', computing system MPC 2 Can calculate [ ST j,2 ]＝＝sign(R i,j ') as element R i,j A value of. Thus, if the element R is i,j ' bits ST in bit flipping mode j Has a value of zero for its corresponding bit, the element R i,j The sign of' will be reversed. The calculation can require a MPC to the computing system 1 A plurality of RPCs.
Computing system MPC 1 And MPC 2 The bit vector is reconstructed 1012. Computing system MPC 1 And MPC 2 The bit vector of the user profile can be reconstructed based on matrices R and R' having exactly the same size. For example, a computing system MPC 1 Can send a part of the columns of the matrix R and calculate the system MPC 2 The remainder of the columns of matrix R' can be sent to the MPC 1 . In a particular example, a computing system MPC 1 It is possible to send the first half of the columns of the matrix R to the computing system MPC 2 And computing the system MPC 2 The second half of the columns of matrix R' can be sent to the MPC 1 . Although columns are used for horizontal reconstruction in this example and are preferred for protecting user privacy, rows can be used for vertical reconstruction in other examples.
In this example, computing system MPC 2 The first half of the columns of matrix R' can be coupled to slave computing system MPC 1 The first half of the columns of the received matrix R are combined to reconstruct the first half of the bit vector in plaintext (i.e., m/2 dimensions). Similarly, computing system MPC 1 The second half of the columns of the matrix R can be coupled to the slave computing system MPC 2 The second half of the columns of the received matrix R' are combined to reconstruct the second half of the bit vector of the plaintext (i.e., m/2 dimensions). Conceptually, a computing system MPC 1 And MPC 2 The corresponding shares in the two matrices R and R' have now been combined to reconstruct the bit matrix B in the clear. This bit matrix B will include the bit vectors of the projection results (onto each projection plane) for each user profile of the share of the machine learning model received from the content platform 150. Each of the two servers in MPC cluster 130 has half of bit matrix B in the clear.
However, if bit flipping is used, the system MPC is calculated 1 And MPC 2 The bits of the elements in the matrices R and R' have been flipped in a random pattern that is fixed for use in the machine learning model. The random bit flipping mode for two computing systems MPC 1 And MPC 2 Is opaque so that the computing system MPC 1 And MPC 2 The original user profile cannot be inferred from the bit vector of the projected result. Cryptographic design further prevents MPC 1 Or MPC 2 Inferring the original user profile by horizontal partitioning of bit vectors, i.e. computing systems MPC 1 The second half of the bit vector of the projection result is kept in plaintext and the system MPC is calculated 2 The first half of the bit vector of the projection result is kept in plaintext.
Computing system MPC 1 And MPC 2 A machine learning model is generated (1014). Computing system MPC 1 The second half of the bit vector can be used to generate the k-NN model. Similarly, computing system MPC 2 The first half of the bit vector can be used to generate the k-NN model. Generating a model using bit flipping and horizontal partitioning of a matrix applies the principles of depth defense to protect the privacy of the user profile used to generate the model.
In general, each k-NN model represents a cosine similarity (or distance) between the user profiles of a set of users. By a computing system MPC 1 The generated k-NN model represents the similarity between the second half of the bit vector and is calculated by the computing system MPC 2 The generated k-NN model represents the similarity between the first half of the bit vector. For example, each k-NN model can define cosine similarities between its halves of the bit vector.
By a computing system MPC 1 And MPC 2 The two generated k-NN models can be referred to as k-NN models, which have unique model identifiers as described above. Computing system MPC 1 And MPC 2 Their models and the share of the tags for each user profile used to generate the models can be stored. The content platform 150 can then query the model to infer a user group for the user.
Exemplary Process for inferring user groups Using k-NN models
FIG. 11 is a flow diagram illustrating an exemplary process 1100 for adding a user to a user group using a machine learning model. The operations of process 1100 can be implemented, for example, by MPC cluster 130 and client device 110 of fig. 1 (e.g., application 112 running on client device 110). The operations of process 1100 can also be implemented as instructions stored on one or more computer-readable media, which can be non-transitory, and execution of the instructions by one or more data processing apparatus can cause the one or more data processing apparatus to perform the operations of process 1100.
The MPC cluster 130 receives an inference request for a given user profile (1102). An application 112 running on a user's client device 110 can communicate an inference request to the MPC cluster 130, for example, in response to a request from the content platform 150. For example, the content platform 150 can communicate an upload token M to the application 112 infer To request that the application 112 submit an inference request to the MPC cluster 130. The inference request can be a query as to whether the user should be added to any number of groups of users.
Inference request token M infer Can include shares of a given user profile of the user, a model identifier of a machine learning model (e.g., a k-NN model) and owner domain for inference, a number k of nearest neighbors of the given user profile for inference, an additional signal (e.g., a context or digital component signal), an aggregation function for inference and any aggregation function parameters for inference, and a signature over all of the above information created by the owner domain using the owner domain secret privacy key.
As mentioned above, to prevent a given user profile P from being presented in clear text i Divulging to a computing system MPC 1 Or MPC 2 To protect user privacy, the application 112 can assign a given user profile P i Split into separate portions for MPC 1 And MPC 2 Two shares of [ P ] i,1 ]And [ P i,2 ]. Application 112 can then send the MPC to the computing system 1 Sending a first share P with a given user profile i,1 ]And an encrypted version of a second share of the given user profile (e.g., pubKeyEncrypt ([ P) i,2 ],MPC 2 ) A single inference request. The inference request may also include an inference request token M infer Enabling the MPC cluster 130 to authenticate the inference request. By sending an inference request comprising a first share and an encrypted second share, the number of outgoing requests sent by the application 112 is reduced, resulting in a request at the clientComputing and battery savings at the end device 110.
In other implementations, the application 112 can apply a first share [ P ] of a given user profile i,1 ]Send to computing system MPC 1 And a second share of the given user profile P i,2 ]Sending to a computing System MPC 2 . By dividing a second share P of a given user profile i,2 ]Sending to a computing System MPC 2 Without going through the computing system MPC 1 The second share does not need to be encrypted to prevent the computing system MPC from being encrypted 1 Accessing a second share P of a given user profile i,2 ]。
MPC for each computing system 1 And MPC 2 K nearest neighbors of a given user profile in the secret share representation are identified (1104). Computing system MPC 1 Can use a first share P of a given user profile i,1 ]To compute its half of the bit vector for a given user profile. To generate the bit vector, the system MPC is calculated 1 Operations 1010 and 1012 of process 1000 of figure 10 can be used. That is, computing system MPC 1 The shares P of a given user profile can be projected using random projection vectors generated for the k-NN model i,1 ]And creates a secret share of the bit vector for a given user profile. Computing System MPC if bit flipping is used to generate a k-NN model 1 First share of bit flipping pattern used to generate k-NN model can be used { [ ST { [ 1,1 ],[ST 2,1 ],…[ST m,1 ]The secret share of the bit vector of a given user profile.
Similarly, computing system MPC 1 Capable of providing MPC to a computing system 2 Providing an encrypted second share of PubKeyEncrypt ([ P ] P) of a given user profile i,2 ],MPC 2 ). Computing system MPC 2 The second share P of a given user profile can be decrypted using its private key i,2 ]And using a second share of the given user profile P i,2 ]To calculate its half of the bit vector for a given user profile. That is, computing system MPC 2 The shares [ P ] of a given user profile can be projected using random projection vectors generated for the k-NN model i,2 ]And is given byThe user profile creates a bit vector. Computing System MPC if bit flipping is used to generate k-NN model 2 Second share { [ ST ] capable of using bit flipping patterns for generating k-NN model 1,2 ],[ST 2,2 ],…[ST m,2 ]The elements of the bit vector of a given user profile. Then, computing system MPC 1 And MPC 2 The bit vectors are reconstructed using horizontal partitioning, as described in operation 1012 in FIG. 10. After reconstruction is complete, the system MPC is calculated 1 The first half of the global bit vector with a given user profile, and the system MPC is calculated 2 The second half of the global bit vector with a given user profile.
MPC for each computing system 1 And MPC 2 Identifying k 'nearest neighbor user profiles using a half of a bit vector of a given user profile and a k-NN model thereof, wherein k' = a × k, wherein a is empirically determined based on actual production data and statistical analysis. For example, a =3 or another suitable number. Computing system MPC 1 The hamming distance between the first half of the overall bit vector and the bit vector of each user profile of the k-NN model can be calculated. Then, computing system MPC 1 K 'nearest neighbors, e.g., k' user profiles with the lowest hamming distances, are identified based on the computed hamming distances. In other words, computing system MPC 1 A set of nearest neighbor user profiles is identified based on the shares of a given user profile and a k-nearest neighbor model trained using a plurality of user profiles. Example results in tabular form are shown in table 13 below.
Line ID | Hamming distance (in plaintext) | User profile share | Fraction of label |
i | d i1 | [P i1 ] | [label i1 ] |
… | … | … | … |
Watch 13
In table 13, each row is for a particular nearest neighbor user profile and includes that user profile with the user profile as determined by the computing system MPC 1 A hamming distance between the given user profiles calculated. The row for a particular nearest neighbor user profile also includes a first share of the user profile and a first share of a label associated with the user profile.
Similarly, computing system MPC 2 The hamming distance between the second half of the overall bit vector and the bit vector of each user profile of the k-NN model can be calculated. Then, computing system MPC 2 K 'nearest neighbors, e.g., k' user profiles with the lowest hamming distances, are identified based on the computed hamming distances. Example results in tabular form are shown in table 14 below.
Line ID | Hamming distance (in plaintext) | Shares of a user profile | Share of label |
j | d j2 | [P j2 ] | [label j2 ] |
… | … | … | … |
TABLE 14
In table 14, each row is for a particular nearest neighbor user profile and includes that user profile with the user profile as determined by the computing system MPC 2 A hamming distance between the given user profiles is calculated. The row for a particular nearest neighbor user profile also includes a second share of the user profile and a second share of the label associated with the user profile.
Computing system MPC 1 And MPC 2 A list of row identifiers (row IDs) and hamming distance pairs can be exchanged with each other. Thereafter, each computing system MPC 1 And MPC 2 The k nearest neighbors can be independently selected using the same algorithm and input data. For example, a computing system MPC 1 Enabling slave computing systems MPC 1 And MPC 2 Both find the row identifier common to the partial query results. For each i in the common row identifier, compute system MPC 1 Calculating a combined Hamming distance d from the two partial Hamming distances i E.g. d i ＝d i,1 +d i,2 . Then, computing the system MPC 1 Can be based on a combined Hamming distance d i The common row identifiers are sorted and k nearest neighbors are selected. k nearest neighbor row identifiers can be represented is ID = { ID 1 ,…id k }. It can be demonstrated that if a is sufficiently large, then the above calculation is performedThe k nearest neighbors determined in the method are true k nearest neighbors with high probability. However, a large value of a results in high calculation cost.
A determination is made whether to add the user to the user group (1106). This determination can be made based on the k nearest neighbor profiles and their associated labels. The determination is also based on the aggregation function used and any aggregation parameters of the aggregation function. Aggregation functions can include, for example, binary classification, regression (e.g., using arithmetic mean or root mean square), multi-class classification, and weighted k-NN. Each way of determining whether to add a user to a user group can include different interactions between the MPC cluster 130 and the applications 112 running on the clients 110, as described in more detail below.
If a determination is made not to add the user to the user group, the application 112 may not add the user to the user group (1108). If a determination is made to add the user to the user group, the application 112 can add the user to the user group (1110), for example, by updating a user group list stored at the client device 110 to include a user group identifier for the user group.
Exemplary binary class inference techniques Using k-NN models
For binary classification, the inference request can include threshold, L true And L false As an aggregation function parameter. The tag value is of the boolean type, true or false. the threshold parameter can indicate that a truth label must be had in order to add a user to the user group L true Is determined by the threshold percentage of k nearest neighbor profiles. Otherwise, the user will be added to the user group L false . In one approach, if the number of nearest neighbor user profiles with a tag value of true is greater than the product of threshold and k, the MPC cluster 130 can instruct the application 112 to add the user to the user group L true (otherwise L) false ). However, computing system MPC 1 The inference results will be learned, e.g. the user group that the user should join.
To protect user privacy, inference requests can include clear text thresholds for computing system MPC 1 First fraction of [ L ] true,1 ]And [ L false,1 ]And for computing system MPC 2 Encrypted second share of PubKeyEncrypt ([ L) true,2 ]||[L false,2 ]||application_public_key,MPC 2 ). In this example, application 112 can be selected from [ L ] true,2 ]、[L fasle,2 ]And the public key of application 112, generates a composite message, as represented by the symbol | |, and uses computing system MPC 2 The public key of (a) to encrypt the composite message. Slave computing system MPC 1 The inferred response to the application 112 can include a calculation system MPC 1 First share [ L ] of the determined inference result result,1 ]And by a computing system MPC 2 Second share [ L ] of the determined inference result result,2 ]。
To prevent the second share from being calculated by the system MPC 1 Accessing and thus enabling a computing system MPC 1 Capable of obtaining an inference result in the clear, computing a system MPC 2 A second share [ L ] of the inferred result result,2 ]An encrypted (and optionally digitally signed) version of (a), e.g., pubKeySign (PubKeyEncrypt ([ L ]) result,2 ],application_public_key),MPC 2 ) Send to computing system MPC 1 For inclusion in the inferred response sent to application 112. In this example, application 112 can use a computing system MPC for generating digital signatures 2 Computing system MPC corresponding to private key of 2 Verifies the digital signature and uses the second share L for encrypting the inference result result,2 ]The application 112 private key corresponding to the public key of (application _ public _ key) to decrypt the second share L of the inference result result,2 ]。
Then, the application 112 can start with the first quota [ L ] result,1 ]And a second fraction [ L result,2 ]Reconstruction of the inference result L result . Using digital signatures to enable application 112 to detect, for example, by computing system MPC 1 For MPC from computing system 2 Forgery of the result of (1). Depending on the desired level of security, what parties are operating the computing systems of the MPC cluster 130, and the assumed security model, a digital signature may not be needed.
Computing system MPC 1 And MPC 2 The fraction [ L ] of binary classification results can be determined using MPC techniques result,1 ]And [ L result,2 ]. In binary classification, the label of a user profile 1 Is zero (false) or one (true). Assume that the selected k nearest neighbor identifiers id 1 ,…id k Identification, calculating system MPC 1 And MPC 2 A sum of the labels of the k nearest neighbor user profiles (sum of labels) can be calculated, wherein the sum is represented by the following relation 15:
relation 15: sum of labels = ∑ Σ i∈{id1，...idk} label i
To determine the sum, the system MPC is calculated 1 To a computing system MPC 2 Sending ID (i.e., { ID }) 1 ,…id k }). Computing system MPC 2 It can be verified that the number of row identifiers in the ID is greater than a threshold to enforce k-anonymity. Then, computing the system MPC 2 The second share of the sum of the tags sum of can be calculated using the following relation 16 2 ]：
Relation 16: [ sum _ of _ labels) 2 ]＝∑ i∈{id1，...idk} [label i，2 ]
Computing system MPC 1 The first share of the sum of the tags SUm _ of _ labels can also be calculated using the following relation 17 1 ]：
Relation 17: [ sum _ of _ labels) 1 ]＝∑ i∈{id1，...idk} [label i，1 ]
If the sum of labels sum _ of _ labels is the computing system MPC 1 And MPC 2 Confidential information that should be known as little as possible, the computing system MPC 1 The first share of the sum of the labels [ sum _ of _ labels ] can be calculated 1 ]Whether or not it is below a threshold, e.g. [ below _ threshold ] 1 ]＝[sum_of_labels 1 ]<threshold × k. Similarly, computing system MPC 2 A second share [ sum _ of _ labels ] of the sum of the labels can be calculated 2 ]Whether or not it is below a threshold, e.g., [ below _ threshold [ ] 2 ]＝[sum_of_labels 2 ]<threshold × k. Computing system MPC 1 Can be used for cleaningPer [ below _ threshold 1 ]×[L false,1 ]+(1-[below_threshold 1 ])×[L true,1 ]Continue to calculate the inferred result [ L result,1 ]. Similarly, computing system MPC 2 Can pass through [ below _ threshold 2 ]×[L false,2 ]+(1-[below_threshold 2 ])×[L true,2 ]To calculate [ L ] result,2 ]。
If the sum of the labels sum of labels, sum _ of _ labels, is not confidential information, the computing system MPC is calculated 1 And MPC 2 Can be selected from [ sum _ of _ labels [ ] 1 ]And [ sum _ of _ labels [ ] 2 ]Sum of labels are reconstructed. Then, computing the system MPC 1 And MPC 2 The parameter below _ threshold can be set to sum _ of _ labels<threshold x k, for example, has a value of one if it is below the threshold, or zero if it is not below the threshold.
After calculating the parameter below _ threshold, the system MPC is calculated 1 And MPC 2 Can continue to determine the inference result L result . For example, a computing system MPC 2 Can be based on the value of below _ threshold, [ L ] result,2 ]Is set as [ L true,2 ]Or [ L false,2 ]. For example, if the sum of tags is not below a threshold, the system MPC is calculated 2 Can be combined with [ L result,2 ]Is set as [ L true,2 ]Or if the sum of the tags is below a threshold, the system MPC is calculated 2 Can be combined with [ L result,2 ]Is set as [ L false,2 ]. Then, computing the system MPC 2 Enabling a computing system MPC 1 An encrypted second share (PubKeyEncrypt (L) that returns an inference result result,2 ]Application _ public _ key)) or a digitally signed version of the result.
Similarly, computing system MPC 1 Can be based on the value of below _ threshold, [ L ] result,1 ]Is set as [ L true,1 ]Or [ L false,1 ]. For example, if the sum of tags is not below a threshold, the system MPC is calculated 1 Can be combined with [ L result,1 ]Is set as [ L true,1 ]Or if the sum of the tags is below a threshold, the system MPC is calculated 1 Can be combined with [ L result,1 ]Is arranged as[L false,1 ]. Computing system MPC 1 Can deduce a first share [ L ] of the result result,1 ]And an encrypted second share [ L ] of the inference result result,2 ]As an inference response to the application 112. The application 112 can then calculate an inference result based on the two shares, as described above.
Exemplary Multi-class Classification inference techniques Using k-NN models
For multi-class classification, the labels associated with each user profile can be classification features. The content platform 150 can specify a look-up table that maps any possible classification value to a corresponding user group identifier. The look-up table can be one of the aggregation function parameters included in the inference request.
Within the k nearest neighbors found, the MPC cluster 130 finds the most common label value. The MPC cluster 130 can then find the user group identifier corresponding to the most common tag value in the lookup table and request the application 112 to add the user to the user group corresponding to the user group identifier, for example, by adding the user group identifier to a list of user groups stored at the client device 110.
Similar to binary classification, it may be preferable to assign a computing system MPC 1 And MPC 2 Hiding inference result L result . To this end, the application 112 or the content platform 150 can create two lookup tables, each mapping a classification value to an inference result L result The corresponding share of (c). For example, the application can create a mapping of the classification value to a first share [ L [ ] result1 ]And mapping the classification value to a second share L result2 ]The second lookup table of (1). MPC from application to computing system 1 Can include a request for inference of a computing system MPC 1 Is used in the computing system MPC 2 The encrypted version of the second lookup table. Capable of using a computing system MPC 2 The second look-up table is encrypted. For example, a computing system MPC can be used 2 Public key (e.g., pubKeyEncrypt (lookup table2| | | application _ public _ key, MPC) 2 ) To encrypt a composite hash of a public key comprising a second lookup table and an applicationAnd (4) information.
By a computing system MPC 1 The inferred response sent can include a calculation system MPC 1 First share [ L ] of the generated inference result result1 ]. Similar to binary classification, to prevent the second share from being calculated by the system MPC 1 Accessing and thus enabling a computing system MPC 1 Capable of obtaining an inference result in the clear, computing a system MPC 2 A second share [ L ] of the inference result result,2 ]An encrypted (and optionally digitally signed) version of (e.g., pubKeySign ([ L ] L) result,2 ],application_public_key),MPC 2 ) Send to computing system MPC 1 For inclusion in the inference results sent to application 112. Application 112 can be selected from [ L ] result1 ]And [ L result2 ]Reconstructed inference result L result 。
Assume that there are w valid labels { l ] for a multi-class classification problem 1 ,l 2 ,…l w }. To determine inferences L in multiple classes result Fraction of (A) [ L ] result1 ]And [ L result2 ]Computing system MPC 1 Will ID (i.e., { ID }) 1 ,…id k }) to the computing system MPC 2 . Computing system MPC 2 It can be verified that the number of row identifiers in the ID is greater than a threshold to enforce k-anonymity. In general, k in k-NN can be significantly larger than k in k-anonymity. Then, computing the system MPC 2 Can calculate the jth label l j,2 ]Second frequency share [ frequency ] j,2 ]Which is defined using the following relation 18.
similarly, computing system MPC 1 Calculate jth tag [ l ] j,1 ]First frequency share of [ frequency ] j,1 ]Which is defined using the following relation 19.
assume the frequency (frequency) of the tags within k nearest neighbors i ) Not sensitive, then calculating the system MPC 1 And MPC 2 Can be derived from two shares of the tag [ frequency i,1 ]And [ frequency ] i,2 ]Rebuilding frequency i . Then, computing the system MPC 1 And MPC 2 An index parameter (index) can be determined, where frequency index With a maximum value, e.g. index = argmax i (frequency i )。
Then, computing the system MPC 2 Can look up in its look-up table the share L corresponding to the label with the highest frequency result,2 ]And PubKeyEncrypt ([ L ] L) result,2 ]Application _ public _ key) back to the computing system MPC 1 . Computing system MPC 1 The share corresponding to the label with the highest frequency L can be similarly looked up in its look-up table result,1 ]. Then, computing the system MPC 1 An inference response can be sent to the application 112 that includes two shares (e.g., [ L ] result,1 ]And PubKeyEncrypt ([ L) result,2 ]Application _ public _ key)). As described above, the second share can be digitally signed to prevent the computing system MPC 1 Counterfeit computing system MPC 2 In response to (2). Then, as described above, the application 112 can calculate an inference result based on the two shares and add the user to the group of users identified by the inference result.
Exemplary regression inference techniques
In order to regress, the label associated with each user profile P must be numeric. The content platform 150 can specify an ordered list of thresholds (e.g., - ∞ < t) 0 ＜t 1 ＜…＜t n < ∞) and a list of user group identifiers (e.g., { L ∞) 0 ,L 1 ,…L n ,L n+1 }). In addition, the content platform 150 can specify an aggregation function, such as an arithmetic mean or root mean square.
Within the k nearest neighbors found, the MPC cluster 130 computes the average of the label values (result), and then uses the result to look up the mapping to find the inference knotFruit L result . For example, MPC cluster 130 can use the following relation 20 to identify tags based on an average of tag values:
relation 20:
if result is less than t 0 Then L is result ←L 0 ；
If result > t n Then L is result ←L n+1 ；
If t is x ＜result≤t x+1 Then L is result ←L x+1 。
I.e. if the result is less than or equal to the threshold t o Then conclude result L result Is L 0 . If the result is greater than the threshold t n Then conclude the result L result Is L n+1 . Otherwise, if the result is greater than the threshold t x And is less than or equal to the threshold value t x +1, the result L is deduced result Is L x +1. Then, computing the system MPC 1 For example by sending the inclusion inference result L to the application 112 result Request application 112 to add the user to the inference result L result A corresponding group of users.
Similar to the other classification techniques described above, the inference result L result Capable of operating on a computing system MPC 1 And MPC 2 And (4) hiding. To this end, the inference request from application 112 can include information for the computing system MPC 1 First share of the label [ L ] i,1 ]And for computing systems MPC 2 Encrypted second share L of the tag of i,2 ](e.g., pubKeyEncrypt ([ L) 0,2 ||…||L n+1,2 ||application_public_key,MPC 2 ))。
By a computing system MPC 1 The inference result sent can include a calculation system MPC 1 First share [ L ] of the generated inference result result1 ]. Similar to binary classification, to prevent the second share from being calculated by the system MPC 1 Accessing and thus enabling a computing system MPC 1 Capable of obtaining an inference result in the clear, computing a system MPC 2 A second share [ L ] of the inference result result,2 ]Is encrypted (andoptionally digitally signed) version (e.g., pubKeySign (PubKeyEncrypt ([ L) result,2 ],application_public_key),MPC 2 ) Send to computing system MPC 1 For inclusion in the inference results sent to application 112. Application 112 can be selected from [ L ] result,1 ]And [ L result,2 ]Reconstruction of the inference result L result 。
Computing a system MPC when the aggregation function is an arithmetic mean 1 And MPC 2 The sum of labels, is computed, similar to binary classification. Computing System MPC if the sum of tags is not sensitive 1 And MPC 2 Two shares can be calculated 1 ]And [ sum _ of _ labels [ ] 2 ]Then sum of labels is reconstructed based on the two shares. Then, computing the system MPC 1 And MPC 2 The average of the labels can be calculated by dividing the sum of the labels by the number of nearest neighbor labels (e.g., by k).
Then, computing the system MPC 1 The average can be compared to a threshold using relation 20 to identify the label corresponding to the average and the first share L result,1 ]Set as the identified tag. Similarly, computing system MPC 2 The average can be compared to a threshold using relation 20 to identify the label corresponding to the average and the second share L result,2 ]Set as an identifier tag. Computing system MPC 2 The second share L can be encrypted using the public key of the application 112 result,2 ](e.g., pubKeyEncrypt ([ L) result,2 ]Application _ public _ key) and sends the encrypted second share to the computing system MPC 1 . Computing system MPC 1 The first share and the encrypted second share (which can optionally be digitally signed as described above) can be provided to the application 112. The application 112 can then add the user to the label (e.g., user group identifier) L result An identified group of users.
Computing a system MPC if the sum of tags is sensitive 1 And MPC 2 It may not be possible to construct sum of labels in plaintext. In contrast, computing system MPC 1 Can be aligned with
In addition, computing system MPC 1 Can calculateMPC cluster 130 will then pair
the corresponding password embodiment can be represented by the following relations 22 and 23.
these calculations do not require the computing system MPC 1 And MPC 2 Any round trip calculations in between. Computing system MPC 1 Two shares of the result (e.g., [ L ]) can be provided to the application 112 result,1 ]And [ L result,2 ]) Wherein the second share is encrypted and optionally digitally signed as described above. In this manner, application 112 can determine inference result L result Without the need for a computing system MPC 1 Or MPC 2 Any content is known about the instant or final result.
For root mean square, calculate system MPC 1 To a computing system MPC 2 Sending ID (i.e., { ID }) 1 ,…id k }). Computing system MPC 2 It can be verified that the number of row identifiers in the ID is greater than a threshold to enforce k-anonymity. Computing system MPC 2 The second contribution (e.g., sum of squares of the label values) of the sum of square parameters can be calculated using the following relation 24.
similarly, computing system MPC 1 The first share of the sum of square labels parameter can be calculated using the following relation 25.
assuming that the sum of square labels parameter is not sensitive, the calculation system MPC 1 And MPC 2 Can be derived from two shares [ sum of square _ labels 1 ]And [ sum _ of _ square _ labels 2 ]Reconstruct the sum of square labels parameter. Computing system MPC 1 And MPC 2 The root mean square of the tags can be calculated by dividing sum of squares labels by the number of nearest neighbor tags (e.g., by k) and then calculating the square root.
Whether the mean is calculated via an arithmetic mean or a root mean square, the calculation system MPC 1 The average can then be compared to a threshold using relation 20 to identify the label corresponding to the average and the first share L result,1 ]Set as the identified tag. Similarly, computing system MPC 2 The average can be compared to a threshold using relation 20 to identify the label corresponding to the average and the second share L result,2 ]Set as an identifier tag. Computing system MPC 2 The second share L can be encrypted using the public key of the application 112 result,2 ](e.g., pubKeyEncrypt ([ L) result,2 ]Application _ public _ key) and sends the encrypted second share to the computing system MPC 1 . Computing system MPC 1 The first share and the encrypted second share (which can optionally be digitally signed as described above) can be provided to the application 112 as an inference result. Application 112 can then add the user to the user list L result The tag (e.g., user group identifier) of (a) identifies the user group. If the sum of square labels parameter is sensitive, the system MPC is calculated 1 And MPC 2 A cryptographic protocol similar to that used in the arithmetic mean example can be executed to compute the shares of the inference results.
In the above technique of inferring the results of the classification and regression problem, all k nearest neighbors have equal influence, e.g., equal weight, on the final inference result. For many classification and regression problems, if each of the k neighbors is assigned a current neighbor and a query parameter P i When the Hamming distance between them increasesThe reduced weights are adjusted, and the quality of the model can be improved. A common kernel function with this property is the Epanechnikov (parabolic) kernel function. Both hamming distance and weight can be computed in the clear.
Improvement of definition of neighbors in k-NN model
In some embodiments, the k nearest neighbors refer to the k users in high dimensional space that are most similar to the user of the querying application (e.g., browser), as described above. However, the algorithm used to train or deploy the k-NN model can be independent of how the neighbors are defined. Thus, in some additional embodiments, the term neighbor can refer to a group of users, where a point in a high dimensional space is a group of users rather than a user. In this example, each user group can be represented by its centroid.
Such a user group based k-NN model can advantageously be less complex than a k-NN model in which the users form different points in a high dimensional space, since there are typically a much smaller number of user groups than the number of users. For example, a content platform can have billions of users, but millions of user groups; in this case, training the k-NN model with each neighbor defined as a user group rather than a user can reduce the model by a factor of 1000. Such a narrowing of the model can advantageously require lower data storage requirements to store data (here a user group and associated data, such as a mapping between different elements) and faster processing to determine whether to add a user to the user group.
To implement a k-NN model in which each point in the high-dimensional space is a corresponding user group, the points in the high-dimensional points are built as follows. Two computing systems MPC 1 And MPC 2 Each user group is evaluated to determine the number of users in each user group. If the number of users in the list is less than a preset threshold, the list is not considered a point in the high dimensional space. This can help determine that a point in the high dimensional space is only occupied by a list having more than a preset number of users (e.g., 100 users, 1000 users, or any other threshold number of users). This can protect user privacy by ensuring that groups of users are not targeted to particular users.
Once the list is built, the two computing systems MPC 1 And MPC 2 The centroid for each user group can be determined based on the number of users in the user group. The centroid can be defined as the mean, as described above, but is calculated for all users in the group of users. The average value as described above relates to the calculation of the sum of all user profiles of the users in the group divided by the number of users in the group. To determine the mean value to determine the center of mass, two computing systems MPC 1 And MPC 2 Can have secret shares per user profile as received from the user's client device. For example, each client device can generate two or more secret shares of the user profile and send the respective secret shares to each computing system before determining the centroid. In some implementations, different subsets of the information in each user profile are provided to each computing system such that there is no overlap in the user profile data sent to each computing system. The calculation to determine the average of the centroid may require a round trip of data between the MPC cluster 130 and the client device 110, and this round trip of particular data may vary based on the particular secret sharing algorithm being implemented. The centroid can be calculated as described above (e.g., see discussion of fig. 1).
Such centroids of each user group form points in a high dimensional space. For each application that makes a query, k nearest neighbors are represented by k points (which represent k user groups) within the high-dimensional space. Each neighbor is a respective group of users. The other modeling aspects and techniques mentioned above with reference to FIGS. 8-11 can be used to train and deploy such a k-NN model, except that each point (which represents a neighbor) in this high-dimensional space is a user group.
Computing system MPC 1 And MPC 2 One of several possible machine learning techniques can be used, such as multi-class classification, to determine whether to add a user to a group of user groups based on k nearest neighbor user profiles. Unlike the more machine learning techniques used in the above embodiments, where points in a high dimensional space represent users (including regression and binary classification), for each of themMachine learning techniques of embodiments in which the user group forms a point in a high-dimensional space may exclude regression or binary classification.
Adding interaction-based weights to a user
For the digital component provider 160, all user interactions (e.g., views, clicks, and/or conversions) may not be of equal value, and some user interactions may be more important than the same interactions of other users. For example, a particular interaction (e.g., view, click, or conversion) of a user that appears to have a higher purchasing power (e.g., by living in an expensive zip code, spending more in a preset amount of time in the past, etc.) may be more important than a particular interaction of another user that appears to have a lower purchasing power.
For models in which each point in the high dimensional space is a respective group of users, this change in importance based on interaction is taken into account during the calculation of the centroid by assigning higher interaction-based weights to users interacting with digital components that promote more expensive products and lower interaction-based weights to users interacting with digital components that promote less expensive products while the model is being trained. In some embodiments, the weights are determined based on other traffic objectives. The centroid calculation is described above as the average of all users. Here, however, the centroid is calculated as a weighted average of all users. The weighted average is the sum of the weighted values divided by the sum of the weights.
For models where each point in the high dimensional space is a user, the importance based on the interaction is considered after the model has been trained and when the model is used for prediction. For this model, due to the algorithm used, the timing for considering the change in importance of the interaction (i.e. during prediction, which occurs after training of the model) is different from the timing for the model in which each point in the high-dimensional space is the user (i.e. after calculation of the centroid). In this model, where each point in the high dimensional space is a user, the model is implemented as described above such that the model makes predictions that the user is assigned to particular categories or groups of users. The importance based interaction can be considered in two ways, which can be implemented separately or in combination.
In a first way, a user may be excluded from the assigned user group if less than a preset amount of nearest neighbors are part of the user group. For example, if only 3 or fewer of the 10 nearest neighbors are part of a user group, then the user is excluded from the assigned group.
In a second approach, each user is assigned a weight based on its interaction (e.g., more weight for interaction with digital components promoting expensive products and less weight for interaction with digital components promoting inexpensive products), and a user is excluded from the assigned group if the mathematical product of the weight and the preset amount of nearest neighbors that are part of the user group is less than a threshold. For example, if the threshold is 4, then only 2 neighbors of the user are part of the assigned group (which would exclude the user from the assigned group in the first manner described above), and the weight assigned to the user is 3, then the user would not be excluded from the assigned group in this second manner, because the mathematical product of the weight and the preset amount of nearest neighbors that are part of the user group-i.e., 6 calculated by multiplying 3 by 2-exceeds the threshold 4.
The weights assigned to the users can be specified by a requiring side platform (DSP), which can be part of the content platform 150. In some implementations, the weight can be defined as or take into account a purchase price of a product promoted by a digital component with which the user interacts (e.g., by showing, clicking on, and/or converting) in response to the user's interaction with the digital component that promoted the product. In some embodiments, the weight can be defined as or take into account the profit to be obtained on such a product. In some embodiments, the weight can be defined based on a frequency metric (e.g., a weight defined as the number of times a user purchases a product whose price is greater than a preset value) and/or a recency metric (e.g., a weight defined as the number of times a product has been purchased within a preset amount of time in the past). The DSP may define the weights in any other way.
The DSP may provide the user's weights to the MPC cluster 130 for modeling calculations, including pre-processing or post-processing calculations, by providing the weights to scripts running inside an application (e.g., browser). The script is configured to provide weights to the MPC cluster 130 when it uploads the user profile of the user to the MPC cluster 130 or the script provides weights to the MPC cluster 130 when it uploads the user profile of the user to the MPC cluster 130. The script can send the weights in secret shares or plain text, depending on the security requirements imposed by the architecture. For example, because the weights are simply numbers without too much additional data, in some embodiments, security may not be compromised by sending the weights in plain text. In other embodiments, weights may also be transmitted in secret shares to further improve privacy.
FIG. 12 is a flow diagram illustrating an exemplary process for training and deploying k-NN models to efficiently classify users into one or more respective user groups. The k-NN model can be trained using the user profiles of individual users or the centroids of a group of users.
The training data can be preprocessed by the MPC cluster 130 prior to training the k-NN model. For example, if the k-NN model is based on user groups, the MPC cluster 130 could compute the centroid for each user group. Additionally, the MPC cluster 130 can compute one or more performance metrics for each user group. As described above, the performance metrics can include interaction rate and conversion rate. When using weights, the MPC cluster 130 can use the weights to compute performance metrics, as described above.
To calculate the user interaction rates for a group of users, MPC cluster 130 can determine, for users in the group of users, the total number of times one or more digital components for which training models are displayed to users in the group of users and the total number of times users in the group of users interacted with the digital components by the users in the group of users. The MPC cluster 130 can determine the quotient as the user interaction rate by dividing the total number of user interactions by the total number of times the digital component(s) are displayed to the users in the user group.
To calculate the conversion rate for a group of users, the MPC cluster 130 can determine the total number of conversions made by the users of the group of users. The MPC cluster 130 can determine the quotient as the conversion rate by dividing the total number of conversions by the total number of times the digital component(s) are displayed to the users in the user group.
A first MPC system of MPC cluster 130 can receive an inference request from an application 112 on a client device 110, the inference request including a first share and a performance threshold for a given user profile of a user of the application 112 (1202). One or more second MPC systems of the MPC cluster 130 can each receive a corresponding second share of the given user profile.
Each inference request can include a share of a user profile, an identifier of a machine learning model used for the inference request, a number k of nearest neighbors identified using the machine learning model, and a threshold performance metric for use in the inference. In some implementations, the inference request can also include a domain of the owner of the model (e.g., the owner's eTLD + 1) and a digital signature of the rest of the inference request. The use of digital signatures ensures that requests are received from the appropriate client device 110 and that the content of the inference request is not modified after the request is generated.
The first MPC system is capable of identifying k nearest neighbor sets of the user profile by performing a secure MPC process using the trained machine learning model in cooperation with one or more second MPC systems within the MPC cluster 130 (1204). The MPC cluster 130 can identify the nearest neighbor set using the value of k included in the inference request in a manner similar to that described with reference to fig. 11.
The first MPC system 130 can select one or more nearest neighbors from the set of nearest neighbors that have a performance metric that satisfies a performance threshold (1206). This can vary based on the performance metrics included in the query and based on how the k-NN model is trained.
If the k-NN model is trained using user profiles of a group of users instead of individual users, the first MPC system is able to identify each user group in the nearest neighbor set that has a performance metric that satisfies a performance threshold. That is, the first MPC system is capable of comparing the performance metric for each of the k user groups to the threshold performance metric to determine whether the performance metric meets or exceeds the threshold performance metric.
If the k-NN model is trained using user profiles instead of user groups, the first MPC system is able to identify the user groups that include at least one of the k user profiles as a member. For example, consider a value of k of three, where users A, B, and C are the nearest neighbors to infer the requested user profile. If user a is a member of groups 1 and 2, user B is a member of group 2, and user C is a member of groups 3, 4, and 5, the user groups in this example would be 1, 2, 3, 4, and 5, as each of these groups includes at least one member of the k nearest neighbors.
For each group, the first MPC system calculates an aggregate performance metric for the user profiles in the group. If the threshold performance metric is a user interaction rate, the first MPC system is able to calculate a user interaction rate of the digital component(s) of the user profile, for example, by dividing the number of user interactions of the user in the group by the total number of times the digital component(s) are displayed to the user in the group. If the threshold performance metric is conversion, the first MPC system can calculate the conversion of the digital component(s) of the user in the group, for example, by dividing the number of conversions of the corresponding user in the group by the total number of times the digital component(s) are displayed to the users in the group. After calculating the performance metric, the first MPC system can compare the calculated performance metric to a threshold performance metric. The first MPC system can then determine which groups have performance metrics that meet or exceed the threshold performance metric. Each second MPC system can perform the same process to identify groups of users that meet the threshold performance metric.
The first MPC system can communicate data representing one or more nearest neighbors to the application 112 (1208). For example, the first MPC system can transmit data representing each group of users having a performance metric that meets or exceeds a threshold performance metric. Similarly, each second MPC system is capable of transmitting data representative of each group of users having a performance metric that meets or exceeds a threshold performance metric.
The user profile may be generated by the application 112. The user profile can include data indicative of interactions between a user of the application 112 and digital content presented on the application 112. Interactions can include transformations and lack of transformations.
The machine learning model can be a nearest neighbor model. The nearest neighbors of the nearest neighbor model are represented by respective centroids associated with corresponding user groups. The first MPC system can assign a weight to each user of the corresponding group of users to compute the respective centroid. The weights can be based on user interaction. The centroid of each user group can be the center represented by the average of the user profiles of the users that are members of the user group.
The machine learning model can be one or more of a centroid model or a nearest neighbor model. For example, k-NN can be used to classify users into user groups or lists, and a centroid model can be used to preprocess data of the user group approach.
The performance metric for each nearest neighbor can include at least one of a user interaction rate with the one or more digital components corresponding to the nearest neighbor or a conversion rate of the one or more digital components corresponding to the nearest neighbor.
The machine learning model can include a k-nearest neighbor model. In some embodiments, each neighbor in the k-nearest neighbor model can represent a user profile of the user. In some embodiments, each neighbor in the k-nearest neighbor model can represent a user group of multiple users.
FIG. 13 is a block diagram of an example computer system 1300 that can be used to perform the operations described above. System 1300 includes a processor 1310, a memory 1320, a storage device 1330, and an input/output device 1340. Each of the components 1310, 1320, 1330, and 1340 can be interconnected, for example, using a system bus 1350. The processor 1310 is capable of processing instructions for execution within the system 1300. In some implementations, the processor 1310 is a single-threaded processor. In another implementation, the processor 1310 is a multi-threaded processor. The processor 1310 is capable of processing instructions stored in the memory 1320 or the storage device 1330.
The storage device 1330 can provide mass storage for the system 1300. In some implementations, the storage device 1330 is a computer-readable medium. In various different implementations, the storage device 1330 can include, for example, a hard disk device, an optical disk device, a storage device shared by multiple computing devices over a network (e.g., a cloud storage device), or some other mass storage device.
The input/output device 1340 provides input/output operations for the system 1300. In some implementations, the input/output devices 1340 can include one or more of the following: a network interface device, such as an ethernet card, a serial communication device, such as an RS-232 port, and/or a wireless interface device, such as an 802.11 card. In another embodiment, the input/output devices can include driver devices configured to receive input data and send output data to external devices 1360 (e.g., keyboards, printers, and display devices). However, other implementations can also be used, such as mobile computing devices, mobile communication devices, set-top box television client devices, and so forth.
Although an example processing system has been described in FIG. 13, implementations of the subject matter and the functional operations described in this specification can be implemented in other types of digital electronic circuitry, or in computer software, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them.
Embodiments of the subject matter and the operations described in this specification can be implemented in digital electronic circuitry, or in computer software, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them. Embodiments of the subject matter described in this specification can be implemented as one or more computer programs, i.e., one or more modules of computer program instructions, encoded on a computer storage medium (or media) for execution by, or to control the operation of, data processing apparatus. Alternatively or additionally, the program instructions can be encoded on an artificially generated propagated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal, that is generated to encode information for transmission to suitable receiver apparatus for execution by the data processing apparatus. The computer storage medium can be or be included in a computer-readable storage device, a computer-readable storage substrate, a random or serial access memory array or device, or a combination of one or more of them. Further, while the computer storage medium is not a propagated signal, the computer storage medium can be a source or destination of computer program instructions encoded in an artificially generated propagated signal. The computer storage medium can also be or be included in one or more separate physical components or media (e.g., multiple CDs, disks, or other storage devices).
The operations described in this specification can be implemented as operations performed by data processing apparatus on data stored on one or more computer-readable storage devices or received from other sources.
The term "data processing apparatus" encompasses all kinds of apparatus, devices, and machines for processing data, including by way of example a programmable processor, a computer, a system on a chip, or a plurality or combination of the foregoing. The apparatus can comprise special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit). The apparatus can include, in addition to hardware, code that creates an execution environment for the computer program in question, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, a cross-platform runtime environment, a virtual machine, or a combination of one or more of them. The apparatus and execution environment are capable of implementing a variety of different computing model infrastructures, such as web services, distributed computing and grid computing infrastructures.
A computer program (also known as a program, software application, script, or code) can be written in any form of programming language, including compiled or interpreted languages, declarative or procedural languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, object, or other unit suitable for use in a computing environment. A computer program may, but need not, correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data (e.g., one or more scripts stored in a markup language document), in a single file dedicated to the program in question, or in multiple coordinated files (e.g., files that store one or more modules, sub programs, or portions of code). A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.
The processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform actions by operating on input data and generating output. The processes and logic flows can also be performed by, and apparatus can also be implemented as, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit).
Processors suitable for the execution of a computer program include, by way of example, both general and special purpose microprocessors. Generally, a processor will receive instructions and data from a read-only memory or a random access memory or both. The essential elements of a computer are a processor for performing actions in accordance with instructions and one or more memory devices for storing instructions and data. Generally, a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks. However, a computer need not have such a device. Further, the computer can be embedded in another device, e.g., a mobile telephone, a Personal Digital Assistant (PDA), a mobile audio or video player, a game console, a Global Positioning System (GPS) receiver, or a portable storage device (e.g., a Universal Serial Bus (USB) flash drive), to name a few. Devices suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, such as internal hard disks or removable disks; a magneto-optical disk; and CD-ROM and DVD-ROM disks. The processor and the memory can be supplemented by, or incorporated in, special purpose logic circuitry.
To provide for interaction with a user, embodiments of the subject matter described in this specification can be implemented on a computer having a display device, e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to the user and a keyboard and a pointing device, e.g., a mouse or a trackball, by which the user can provide input to the computer. Other types of devices can also be used to provide for interaction with a user; for example, feedback provided to the user can be any form of sensory feedback, such as visual feedback, auditory feedback, or tactile feedback; and input from the user can be received in any form, including acoustic, speech, or tactile input. Further, the computer is able to interact with the user by sending and receiving documents to and from the device used by the user; for example, by sending a web page to an application on the user's client device in response to a request received from the application (e.g., browser).
Implementations of the subject matter described in this specification can be implemented in a computing system that includes a back-end component (e.g., as a data server), or that includes a middleware component (e.g., an application server), or that includes a front-end component (e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the subject matter described in this specification), or any combination of one or more such back-end, middleware, or front-end components. The components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include local area networks ("LANs") and wide area networks ("WANs"), the internet (e.g., the internet), and peer-to-peer networks (e.g., ad hoc peer-to-peer networks).
The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other. In some implementations, the server transmits data (e.g., HTML pages) to the client device (e.g., for displaying data to a user interacting with the client device and receiving user input from the user). Data generated at the client device (e.g., a result of the user interaction) can be received at the server from the client device.
While this specification contains many specific implementation details, these should not be construed as limitations on the scope of any innovations or of what may be claimed, but rather as descriptions of features specific to particular implementations of particular innovations. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely, various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Moreover, although features may be described above as acting in certain combinations and even initially claimed as such, one or more features from a claimed combination can in some cases be excised from the combination, and the claimed combination may be directed to a subcombination or variation of a subcombination.
Similarly, while operations are depicted in the drawings in a particular order, this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order, or that all illustrated operations be performed, to achieve desirable results. In some cases, multitasking and parallel processing may be advantageous. Moreover, the separation of various system components in the embodiments described above should not be understood as requiring such separation in all embodiments, and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.
Thus, particular embodiments of the subject matter have been described. Other embodiments are within the scope of the following claims. In some cases, the actions recited in the claims can be performed in a different order and still achieve desirable results. Moreover, the processes depicted in the accompanying figures do not necessarily require the particular order shown, or sequential order, to achieve desirable results. In some embodiments, multitasking and parallel processing may be advantageous.
Claims (20)
1. A method, comprising:
receiving, by a first multi-party computing (MPC) system of an MPC cluster, an inference request from an application on a client device, the inference request including a first share of a given user profile and a performance threshold for a user of the application;
identifying a nearest neighbor set of the user profile by performing a secure MPC process using a trained machine learning model in cooperation with one or more second MPC systems;
selecting one or more nearest neighbors from the set of nearest neighbors that have a performance metric that satisfies the performance threshold;
communicating, by the first MPC system, data derived from the one or more nearest neighbors to the application.
2. The method of claim 1, wherein the user profile is generated by the application, wherein the user profile includes data indicative of interactions between a user of the application and digital content presented on the application, wherein the interactions include conversions and lack of conversions.
3. The method according to claim 1 or 2, wherein the machine learning model is a nearest neighbor model, wherein nearest neighbors of the nearest neighbor model are represented by respective centroids associated with corresponding user groups.
4. The method of claim 3, wherein the first MPC system assigns a weight to each user in the corresponding group of users to compute a respective centroid, wherein the weight is based on at least one of interactions of the users or user information related to the performance metrics.
5. The method of claim 4, wherein the centroid of each user group is a center represented by a mean of user profiles of users that are members of the user group.
6. The method of any preceding claim, wherein the machine learning model is one or more of a centroid model or a nearest neighbor model.
7. The method of any preceding claim, wherein each nearest neighbor's performance metric comprises at least one of a user interaction rate with one or more digital components corresponding to the nearest neighbor or a conversion rate of the one or more digital components corresponding to the nearest neighbor.
8. A method as claimed in any preceding claim, wherein the machine learning model comprises a k-nearest neighbor model, and each neighbor in the k-nearest neighbor model represents a user profile of a user.
9. The method of any of claims 1 to 7, wherein the machine learning model comprises a k-nearest neighbor model, and each neighbor in the k-nearest neighbor model represents a user group of multiple users.
10. The method of any preceding claim, wherein the performance threshold is a threshold, wherein the conversion rate of the one or more digital components is a number of conversions divided by a number of times the one or more digital components are displayed to a user in a group of users, wherein the inference request is a request to infer whether the user is to be added to a group of users.
11. A system, comprising:
at least one programmable processor; and
a machine-readable medium storing instructions that, when executed by the at least one programmable processor, cause the at least one programmable processor to perform operations comprising:
receiving, by a first multi-party computing (MPC) system of an MPC cluster, an inference request from an application on a client device, the inference request including a first share of a given user profile and a performance threshold for a user of the application;
identifying a nearest neighbor set of the user profile by performing a secure MPC process using a trained machine learning model in cooperation with one or more second MPC systems;
selecting one or more nearest neighbors from the set of nearest neighbors that have a performance metric that satisfies the performance threshold;
communicating, by the first MPC system, data derived from the one or more nearest neighbors to the application.
12. The system of claim 11, wherein the user profile is generated by the application, wherein the user profile includes data indicative of interactions between a user of the application and digital content presented on the application, wherein the interactions include conversions and lack of conversions.
13. The system of claim 11 or 12, wherein the machine learning model is a nearest neighbor model, wherein a nearest neighbor of the nearest neighbor model is represented by a respective centroid associated with a corresponding user group.
14. The system of claim 13, wherein the first MPC system assigns a weight to each user in the corresponding group of users to compute a respective centroid, wherein the weight is based on at least one of interactions of the users or user information related to the performance metrics.
15. The system of claim 14, wherein the centroid of each user group is a center represented by an average of user profiles of users who are members of the user group.
16. The system of any of claims 11 to 15, wherein the machine learning model is one or more of a centroid model or a nearest neighbor model.
17. The system of any of claims 11 to 16, wherein each nearest-neighbor performance metric comprises at least one of a user interaction rate with one or more digital components corresponding to the nearest neighbor or a conversion rate of the one or more digital components corresponding to the nearest neighbor.
18. The system of any of claims 11 to 17, wherein the machine learning model comprises a k-nearest neighbor model, and each neighbor in the k-nearest neighbor model represents a user profile of a user.
19. The system of any of claims 11 to 18, wherein the machine learning model comprises a k-nearest neighbor model, and each neighbor in the k-nearest neighbor model represents a user group of a plurality of users.
20. One or more computer program products storing instructions that, when executed by at least one programmable processor, cause the at least one programmable processor to perform operations comprising:
receiving, by a first multi-party computing (MPC) system of an MPC cluster, an inference request from an application on a client device, the inference request including a first share of a given user profile and a performance threshold for a user of the application;
identifying a nearest neighbor set of the user profile by performing a secure MPC process using a trained machine learning model in cooperation with one or more second MPC systems;
selecting one or more nearest neighbors from the nearest neighbor set that have a performance metric that satisfies the performance threshold;
communicating, by the first MPC system, data derived from the one or more nearest neighbors to the application.
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/US2021/026618 WO2022216293A1 (en) | 2021-04-09 | 2021-04-09 | Processing of machine learning modeling data to improve accuracy of categorization |
Publications (1)
Publication Number | Publication Date |
---|---|
CN115461744A true CN115461744A (en) | 2022-12-09 |
Family
ID=75888152
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202180019134.6A Pending CN115461744A (en) | 2021-04-09 | 2021-04-09 | Processing machine learning modeling data to improve accuracy of classification |
Country Status (6)
Country | Link |
---|---|
US (1) | US20230274183A1 (en) |
EP (1) | EP4097619A1 (en) |
JP (1) | JP7422892B2 (en) |
KR (1) | KR20220140759A (en) |
CN (1) | CN115461744A (en) |
WO (1) | WO2022216293A1 (en) |
Families Citing this family (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11907392B2 (en) * | 2021-05-12 | 2024-02-20 | Seagate Technology Llc | System and method utilizing function secret sharing with conditional disclosure of secrets |
CN115408985B (en) * | 2022-10-31 | 2023-04-07 | 天津联想协同科技有限公司 | Online spreadsheet worksheet name display method, device and storage medium |
Family Cites Families (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN102473183A (en) | 2009-07-14 | 2012-05-23 | 索尼公司 | Content recommendation system, content recommendation method, content recommendation device, and information recording medium |
EP2688264B1 (en) | 2012-07-16 | 2016-08-24 | Alcatel Lucent | Method and apparatus for privacy protected clustering of user interest profiles |
JP2016510913A (en) | 2013-08-09 | 2016-04-11 | トムソン ライセンシングＴｈｏｍｓｏｎ Ｌｉｃｅｎｓｉｎｇ | Privacy protection recommendation method and system based on matrix factorization and ridge regression |
WO2018135334A1 (en) | 2017-01-19 | 2018-07-26 | ソニー株式会社 | Information processing device and information processing method, and computer program |
EP3688921B1 (en) | 2017-09-29 | 2021-07-14 | Robert Bosch GmbH | Method for faster secure multiparty inner product computation with spdz |
CN110325996B (en) | 2018-10-17 | 2022-12-20 | 创新先进技术有限公司 | Sharing secrets with a trusted initializer |
-
2021
- 2021-04-09 US US17/798,152 patent/US20230274183A1/en active Pending
- 2021-04-09 KR KR1020227029827A patent/KR20220140759A/en unknown
- 2021-04-09 WO PCT/US2021/026618 patent/WO2022216293A1/en unknown
- 2021-04-09 JP JP2022553151A patent/JP7422892B2/en active Active
- 2021-04-09 CN CN202180019134.6A patent/CN115461744A/en active Pending
- 2021-04-09 EP EP21724827.7A patent/EP4097619A1/en active Pending
Also Published As
Publication number | Publication date |
---|---|
WO2022216293A1 (en) | 2022-10-13 |
JP7422892B2 (en) | 2024-01-26 |
JP2023524356A (en) | 2023-06-12 |
EP4097619A1 (en) | 2022-12-07 |
US20230274183A1 (en) | 2023-08-31 |
KR20220140759A (en) | 2022-10-18 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US20230214684A1 (en) | Privacy preserving machine learning using secure multi-party computation | |
JP7361928B2 (en) | Privacy-preserving machine learning via gradient boosting | |
JP7438361B2 (en) | Privacy-preserving centroid model using secure multiparty computation | |
US20230274183A1 (en) | Processing of machine learning modeling data to improve accuracy of categorization | |
US20230078704A1 (en) | Privacy preserving machine learning labelling | |
JP7471445B2 (en) | Privacy-preserving machine learning for content delivery and analytics | |
Kaleli et al. | SOM-based recommendations with privacy on multi-party vertically distributed data | |
US20220405407A1 (en) | Privacy preserving cross-domain machine learning | |
US20240163341A1 (en) | Privacy preserving centroid models using secure multi-party computation | |
Gao et al. | A verifiable and privacy-preserving framework for federated recommendation system | |
JP7354427B2 (en) | Online privacy protection techniques | |
Ma et al. | Blockchain-Based Privacy-Preserving Federated Learning for Mobile Crowdsourcing | |
CN115428395A (en) | Enhanced performance for secure multi-party computing |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |