JP7143327B2 - Methods, Computer Systems, Computing Systems, and Programs Implemented by Computing Devices - Google Patents
Methods, Computer Systems, Computing Systems, and Programs Implemented by Computing Devices Download PDFInfo
- Publication number
- JP7143327B2 JP7143327B2 JP2019563257A JP2019563257A JP7143327B2 JP 7143327 B2 JP7143327 B2 JP 7143327B2 JP 2019563257 A JP2019563257 A JP 2019563257A JP 2019563257 A JP2019563257 A JP 2019563257A JP 7143327 B2 JP7143327 B2 JP 7143327B2
- Authority
- JP
- Japan
- Prior art keywords
- audio data
- digital audio
- song
- songs
- computing device
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/60—Information retrieval; Database structures therefor; File system structures therefor of audio data
- G06F16/68—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
- G06F16/683—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using metadata automatically derived from the content
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/16—Sound input; Sound output
- G06F3/165—Management of the audio stream, e.g. setting of volume, audio stream path
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/60—Information retrieval; Database structures therefor; File system structures therefor of audio data
- G06F16/63—Querying
- G06F16/635—Filtering based on additional data, e.g. user or group profiles
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10H—ELECTROPHONIC MUSICAL INSTRUMENTS; INSTRUMENTS IN WHICH THE TONES ARE GENERATED BY ELECTROMECHANICAL MEANS OR ELECTRONIC GENERATORS, OR IN WHICH THE TONES ARE SYNTHESISED FROM A DATA STORE
- G10H2210/00—Aspects or methods of musical processing having intrinsic musical character, i.e. involving musical theory or musical parameters or relying on musical knowledge, as applied in electrophonic musical tools or instruments
- G10H2210/031—Musical analysis, i.e. isolation, extraction or identification of musical elements or musical parameters from a raw acoustic signal or from an encoded audio signal
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10H—ELECTROPHONIC MUSICAL INSTRUMENTS; INSTRUMENTS IN WHICH THE TONES ARE GENERATED BY ELECTROMECHANICAL MEANS OR ELECTRONIC GENERATORS, OR IN WHICH THE TONES ARE SYNTHESISED FROM A DATA STORE
- G10H2210/00—Aspects or methods of musical processing having intrinsic musical character, i.e. involving musical theory or musical parameters or relying on musical knowledge, as applied in electrophonic musical tools or instruments
- G10H2210/031—Musical analysis, i.e. isolation, extraction or identification of musical elements or musical parameters from a raw acoustic signal or from an encoded audio signal
- G10H2210/046—Musical analysis, i.e. isolation, extraction or identification of musical elements or musical parameters from a raw acoustic signal or from an encoded audio signal for differentiation between music and non-music signals, based on the identification of musical parameters, e.g. based on tempo detection
Description
背景
最新のコンピューティング装置の多くは、電話音声の録音、ノイズキャンセルのための外部ノイズの特定、音声入力の受信などの様々な目的に使用されるマイクロフォンを含む。マイクロフォンのもう１つの用途は、音声を録音して、コンピューティング装置がその音声をリモートサーバシステムに送信して解析することによって、歌曲として認識することである。音声をリモートサーバシステムに送信して解析することは、計算コストが高く、時間がかかる。
BACKGROUND Many modern computing devices include microphones that are used for a variety of purposes, such as recording telephone speech, identifying external noise for noise cancellation, and receiving audio input. Another use of microphones is to record sound and have a computing device transmit the sound to a remote server system for analysis and recognition as a song. Sending speech to a remote server system for analysis is computationally expensive and time consuming.
概要
本明細書は、検出された音声が音楽を表すまたは含むか否かを判断し、その音楽を特定の歌曲として識別するための技術、方法、システムおよび他のメカニズムを説明する。本明細書に記載されたメカニズムを実現する装置は、上記のプロセスを継続的に実行することができる。したがって、ユーザが現在環境内のスピーカから再生している歌曲の名前を知りたいと思うときに、装置は、既にこの歌曲を特定し、歌曲の曲名を表示装置に出力している。いくつかの例において、本明細書に記載の音楽検出メカニズムおよび歌曲識別メカニズムが全てポータブルコンピューティング装置上で実行され、ポータブルコンピューティング装置が周囲音声の録音から生成されたデータを解析のためにリモート電子システムに送信しないため、ネットワーク接続が利用できない場合でも、ポータブルコンピューティング装置が音楽を認識および識別することができる。この機能によって、ローカルに記録された音声データをリモート電子システムに送信して、歌曲を認識および識別する必要がない。
Overview This specification describes techniques, methods, systems and other mechanisms for determining whether detected speech represents or contains music and identifying that music as a particular song. A device that implements the mechanisms described herein can perform the above processes continuously. Therefore, when the user wants to know the name of the song that is currently playing from the speakers in the environment, the device has already identified this song and output the name of the song to the display. In some examples, the music detection mechanisms and song identification mechanisms described herein are all executed on a portable computing device, and the portable computing device sends data generated from ambient audio recordings remotely for analysis. Because it is not transmitted to an electronic system, the music can be recognized and identified by the portable computing device even if a network connection is not available. This feature eliminates the need to transmit locally recorded audio data to a remote electronic system for song recognition and identification.
いくつかの例において、音楽判断プロセスおよび歌曲識別プロセスは、２つの段階で実行されてもよい。第１段階は、（例えば、継続的な監視プロセスに基づいて）コンピューティング装置によって検出された音声が音楽を表すかまたは含むか否かを認識することを含む。第１段階を連続的にまたは少なくとも一定の期間に連続的に作動する必要があるため、第１段階は、コンピューティング装置に動作可能に結合されまたは含まれ、コンピューティング装置のメインプロセッサとは異なる低電力プロセッサによって実行される。この低電力プロセッサは、メインプロセッサよりも低い電圧およびクロック速度で動作するため、音楽検出プロセスによるバッテリの消費を最小限に抑えることができる。低電力プロセッサは、メインプロセッサから物理的に分離されてもよい。したがって、低電力プロセッサは、メインプロセッサとは異なるコンピューティング装置の部分（例えば、別個の回路基板、モジュール、またはハウジング）に収容されてもよい。 In some examples, the music determination process and song identification process may be performed in two stages. The first step involves recognizing whether sounds detected by the computing device represent or contain music (eg, based on an ongoing monitoring process). Because the first stage must operate continuously or at least continuously for a period of time, the first stage is operably coupled to or included in the computing device and distinct from the main processor of the computing device. It is executed by a low power processor. This low-power processor operates at a lower voltage and clock speed than the main processor, thus minimizing battery consumption by the music detection process. A low power processor may be physically separate from the main processor. Accordingly, the low-power processor may be housed in a different portion of the computing device (eg, separate circuit board, module, or housing) than the main processor.
低電力プロセッサによって周囲音声が音楽を表すまたは含むと判断した後、メインプロセッサは、歌曲識別プロセスにおいて記録された音声を解析することを含む第２段階を実行する。歌曲識別プロセスは、２つのステップを含むことができる。第１ステップにおいて、記録された音声の特徴を、数千曲の参照歌曲の特徴を識別するための数千曲の参照歌曲の装置上データセットと比較することによって、１組の候補歌曲を識別する。第１ステップにおいて、比較的低い解像度の特徴を使用することによって、候補歌曲を識別するための速度を上げることができる。１組の候補歌曲を識別すると、歌曲識別プロセスは、記録された音声とマッチングする候補歌曲（存在する場合）を識別するための第２ステップを実行する。第２ステップにおいて、比較的高い解像度の特徴を使用することによって、歌曲マッチング精度を最大化することができる。 After the low power processor has determined that the ambient sound represents or contains music, the main processor performs a second step involving analyzing the recorded sound in the song identification process. The song identification process can include two steps. In a first step, a set of candidate songs is identified by comparing the recorded audio features to an on-device data set of thousands of reference songs for identifying features of the thousands of reference songs. do. By using relatively low resolution features in the first step, the speed for identifying candidate songs can be increased. Having identified the set of candidate songs, the song identification process performs a second step to identify candidate songs (if any) that match the recorded audio. In the second step, song matching accuracy can be maximized by using relatively high resolution features.
歌曲を識別すると、コンピューティング装置は、再生されている歌曲を示す表記を提示することができる。例えば、コンピューティング装置がスマートフォンであり且つ「ロック」されている（すなわち、殆どアクセスされていないまたは完全にアクセスされていないセキュリティ状態にある）場合、コンピューティング装置は、装置の「ロック画面」または「常時表示画面」に歌曲の名前を表示することができる。コンピューティング装置がロックされていない場合、コンピューティング装置は、装置の画面（例えば、スマートフォンの通知画面）に歌曲の名前を表示することができる。このように連続的な方法で歌曲を識別することによって、ユーザは、専用の歌曲識別アプリケーションを起動して音声を録音するボタンを選択する必要がなく、歌曲の名前を確認することができる。そのため、ユーザは、歌曲識別アプリケーションを起動するためにコンピューティング装置上で行われている動作を停止する必要がなく、環境内のスピーカから再生されている歌曲を識別することができる。また、歌曲識別アプリケーションの起動および実行には時間がかかるため、ユーザが歌曲識別アプリケーションを起動して実行する前に、歌曲の再生が終了してしまう場合がある。さらに、装置は、歌曲を識別できない場合があり、ユーザが歌曲識別アプリケーションを起動および実行しても、歌曲を識別できないという失望感を体験するため、自動歌曲識別プロセスは、ユーザが歌曲識別アプリケーションを起動および実行する回数を制限する。 Upon identifying the song, the computing device can present a notation indicating the song being played. For example, if the computing device is a smartphone and is "locked" (i.e., in a rarely accessed or fully accessed security state), the computing device may display the device's "lock screen" or The name of the song can be displayed on the "always on display screen". When the computing device is unlocked, the computing device can display the name of the song on the screen of the device (eg, the smartphone notification screen). By identifying songs in this sequential manner, the user can see the name of the song without having to launch a dedicated song identification application and select a button to record the audio. As such, the user can identify songs that are playing from speakers in the environment without having to stop actions taking place on the computing device to launch the song identification application. Also, since launching and running the song identification application is time consuming, the song may finish playing before the user launches and executes the song identification application. In addition, the automatic song identification process does not allow the user to run the song identification application because the device may not be able to identify the song, and the user launches and runs the song identification application and experiences the frustration of not being able to identify the song. Limit the number of times it starts and runs.
以下に記載される実施形態の追加の説明として、本開示は、以下の実施形態を記載する。 As additional description of the embodiments described below, this disclosure describes the following embodiments.
実施形態１は、コンピュータによって実施される方法である。この方法は、コンピューティング装置を用いて、複数の参照歌曲の中の各参照歌曲の複数の音声特徴を識別する参照歌曲特徴データを格納することを含む。この方法は、コンピューティング装置を用いて、マイクロフォンによって記録された音声を表すデジタル音声データを受信することを含む。この方法は、コンピューティング装置を用いて、音楽判断プロセスに従って、デジタル音声データが音楽を表すか否かを判断することを含む。この方法は、デジタル音声データが音楽を表すことを判断した後、コンピューティング装置を用いて、デジタル音声データが複数の参照歌曲の中の特定の参照歌曲を表すことを認識することを含む。この方法は、デジタル音声データが複数の参照歌曲の中の特定の参照歌曲を表すという判断に応答して、コンピューティング装置を用いて、特定の参照歌曲を示す表記を出力することを含む。
実施形態２は、実施形態１に記載のコンピュータによって実施される方法である。この場合、複数の参照歌曲は、少なくとも１万曲の参照歌曲を含み、参照歌曲特徴データは、少なくとも１万曲の参照歌曲の音声特徴を識別する。
Embodiment 2 is the computer-implemented method of
実施形態３は、実施形態１または２のいずれか１つに記載のコンピュータによって実施される方法である。この場合、複数の参照歌曲の中の参照歌曲の参照歌曲特徴値は、各特徴値が二進値１または二進値０に限定されるように、二進値１または二進値０に限定される。
Embodiment 3 is the computer-implemented method of any one of
実施形態４は、実施形態１から３のいずれか１つに記載のコンピュータによって実施される方法である。この場合、デジタル音声データが音楽を表すか否かを判断することは、デジタル音声データを時間領域形式から周波数領域形式に変換することと、周波数領域形式のデジタル音声データを音楽判断プロセスに使用することと、デジタル音声データが音楽を表すという表記を出力することとを含む。 Embodiment 4 is the computer-implemented method of any one of embodiments 1-3. In this case, determining whether the digital audio data represents music involves converting the digital audio data from a time-domain format to a frequency-domain format and using the frequency-domain format of the digital audio data in a music determination process. and outputting a notation that the digital audio data represents music.
実施形態５は、実施形態４に記載のコンピュータによって実施される方法である。この場合、音楽判断プロセスは、音声が音楽を表すか否かを判断するように訓練された機械学習システムを実行することを含む。 Embodiment 5 is the computer-implemented method of embodiment 4. In this case, the music determination process involves running a machine learning system trained to determine whether the speech represents music.
実施形態６は、実施形態１から５のいずれか１つに記載のコンピュータによって実施される方法である。この場合、コンピューティング装置は、複数の参照歌曲の中の各参照歌曲の複数の音声特徴を識別する参照歌曲特徴データにアクセスすることなく、デジタル音声データが音楽を表すか否かを判断する。 Embodiment 6 is the computer-implemented method of any one of embodiments 1-5. In this case, the computing device determines whether the digital audio data represents music without accessing reference song feature data that identifies multiple audio features for each reference song in the multiple reference songs.
実施形態７は、実施形態１から６のいずれか１つに記載のコンピュータによって実施される方法である。この場合、デジタル音声データが音楽を表すか否かを判断することは、デジタル音声データが音楽を表すことを判断する前に、音楽判断プロセスを開始するためのユーザ入力を受信することなく、コンピューティング装置を用いてデジタル音声データが音楽を表さないことを複数回判断することを含む。 Embodiment 7 is the computer-implemented method of any one of embodiments 1-6. In this case, determining whether the digital audio data represents music may be performed by a computer without receiving user input to initiate a music determination process prior to determining that the digital audio data represents music. determining multiple times that the digital audio data does not represent music using a ringing device.
実施形態８は、実施形態４から７のいずれか１つに記載のコンピュータによって実施される方法である。この場合、周波数領域形式は、第１周波数領域形式であり、周波数領域変換プロセスは、第１周波数領域変換プロセスであり、デジタル音声データが特定の参照歌曲を表すことを認識することは、（ｉ）第２周波数領域変換プロセスにおいて、デジタル音声データを時間領域形式から第２周波数領域形式に変換することと、（ｉｉ）第２周波数領域形式のデジタル音声データを受信し、デジタル音声データの複数の特徴値を出力する音楽特徴決定プロセスにおいて、第２周波数領域形式のデジタル音声データを使用することと、（ｉｉｉ）デジタル音声データの複数の特徴値を複数の参照歌曲の少なくとも一部の歌曲の中の各歌曲の複数の特徴値と比較することによって、特定の参照歌曲の複数の特徴値がデジタル音声データの複数の特徴値に最も関連していると判断することとを含む。 Embodiment 8 is the computer-implemented method of any one of embodiments 4-7. In this case, the frequency domain format is a first frequency domain format, the frequency domain transform process is a first frequency domain transform process, and recognizing that the digital audio data represents a particular reference song is (i (ii) receiving the digital audio data in the second frequency domain format and transforming the digital audio data into a plurality of (iii) using the digital audio data in a second frequency domain format in a music feature determination process that outputs feature values; determining that the plurality of feature values of the particular reference song are most associated with the plurality of feature values of the digital audio data by comparing with the plurality of feature values of each song of the .
実施形態９は、実施形態８に記載のコンピュータによって実施される方法である。この場合、第２周波数領域形式および第１周波数領域形式は、異なる数の周波数ビンを解析する。 Embodiment 9 is the computer-implemented method of embodiment 8. In this case, the second frequency domain format and the first frequency domain format analyze different numbers of frequency bins.
実施形態１０は、実施形態８または９のいずれか１つに記載のコンピュータによって実施される方法である。この場合、音楽特徴決定プロセスは、音楽の特徴を決定するように訓練された機械学習システムによって実行される。 Embodiment 10 is the computer-implemented method of any one of embodiments 8 or 9. In this case, the music characterization process is performed by a machine learning system trained to characterize music.
実施形態１１は、実施形態８から１０のいずれか１つに記載のコンピュータによって実施される方法である。この場合、デジタル音声データの複数の特徴値を複数の参照歌曲の少なくとも一部の歌曲の中の各歌曲の複数の特徴値と比較することは、別のコンピューティング装置に歌曲特徴データを要求するためのリクエストを送信することなく、コンピューティング装置によって格納された複数の参照歌曲の少なくとも一部の歌曲の中の各歌曲の複数の特徴値にアクセスすることによって実行される。 Embodiment 11 is the computer-implemented method of any one of embodiments 8-10. In this case, comparing the plurality of feature values of the digital audio data to the plurality of feature values of each song in at least a portion of the plurality of reference songs requires the song feature data from another computing device. by accessing a plurality of feature values for each song in at least some of the plurality of reference songs stored by the computing device without sending a request to perform the processing.
実施形態１２は、実施形態８から１１のいずれか１つに記載のコンピュータによって実施される方法である。この場合、コンピューティング装置は、デジタル音声データの複数の特徴値を、複数の候補歌曲の一部の歌曲の中の各歌曲の複数の特徴値のみと比較し、方法は、デジタル音声データの複数の特徴値の中の特徴値を、複数の候補歌曲の中の各歌曲の複数の特徴値と比較することによって、複数の参照歌曲から一部の歌曲を選択することをさらに含む。 Embodiment 12 is the computer-implemented method of any one of embodiments 8-11. In this case, the computing device compares the plurality of feature values of the digital audio data only to the plurality of feature values of each song in the portion of the plurality of candidate songs, and the method comprises: comparing the plurality of feature values of the digital audio data; selecting the subset of songs from the plurality of reference songs by comparing the feature values in the feature values of to the plurality of feature values for each song in the plurality of candidate songs.
実施形態１３は、実施形態８から１２のいずれか１つに記載のコンピュータによって実施される方法である。この場合、デジタル音声データの複数の特徴値の中の特徴値を、二進値０および１に限定されない値から二進値０および１に限定された値に変換することをさらに含み、デジタル音声の複数の特徴値の中の特徴値を、複数の候補歌曲の中の各歌曲の複数の特徴値と比較することは、（ａ）二進値０および二進値１に限定されたデジタル音声データの特徴値と、（ｂ）二進値０および二進値１に限定された複数の歌曲の中の各歌曲の特徴値との比較を含む。
Embodiment 13 is the computer-implemented method of any one of embodiments 8-12. In this case, further comprising converting a feature value among the plurality of feature values of the digital audio data from a value not limited to
実施形態１４は、実施形態８から１３のいずれかに記載のコンピュータによって実施される方法である。この場合、デジタル音声データの複数の特徴値を、複数の参照歌曲の少なくとも一部の歌曲の中の各歌曲の複数の特徴値と比較することは、（ａ）二進値０および二進値１以外の値を表す実数を含むデジタル音声データの特徴値と、（ｂ）二進値０および二進値１に限定された複数の歌曲の少なくとも一部の歌曲の中の各歌曲の特徴値との比較を含む。
Embodiment 14 is the computer-implemented method of any of embodiments 8-13. In this case, comparing the plurality of feature values of the digital audio data to the plurality of feature values of each song in at least a portion of the plurality of reference songs includes (a) the
実施形態１５は、実施形態１から１３のいずれか１つに記載のコンピュータによって実施される方法である。この場合、デジタル音声データが音楽を表すか否かを判断することは、コンピューティング装置の第１プロセッサによって実行され、デジタル音声データが複数の参照歌曲の中の特定の参照歌曲を表すことを認識することは、コンピューティング装置の第２プロセッサによって実行される。 Embodiment 15 is the computer-implemented method of any one of embodiments 1-13. In this case, determining whether the digital audio data represents music is performed by a first processor of the computing device to recognize that the digital audio data represents a particular reference song among the plurality of reference songs. Doing is performed by a second processor of the computing device.
実施形態１６は、実施形態１５に記載のコンピュータによって実施される方法である。この場合、第１プロセッサは、第２プロセッサよりも低い電圧で動作する。 Embodiment 16 is the computer-implemented method of embodiment 15. In this case, the first processor operates at a lower voltage than the second processor.
実施形態１７は、実施形態１５に記載のコンピュータによって実施される方法である。この場合、第２プロセッサは、第１プロセッサが動作するクロック信号よりも少なくとも一桁速いクロック信号で動作する。 Embodiment 17 is the computer-implemented method of embodiment 15. In this case, the second processor operates with a clock signal that is at least one order of magnitude faster than the clock signal with which the first processor operates.
実施形態１８は、実施形態１から１７のいずれか１つに記載のコンピュータによって実施される方法である。この場合、特定の参照歌曲が再生されていることを示す表記を出力することは、ユーザ入力によって歌曲識別プロセスを実行するようにコンピューティング装置を促すことなく、連続した歌曲識別プロセスを有効にすることによって、コンピューティング装置のロック画面、コンピューティング装置の常時オン画面、またはコンピューティング装置のロック解除画面に表示された通知に、特定の参照歌曲の名前を提示することを含む。 Embodiment 18 is the computer-implemented method of any one of embodiments 1-17. In this case, outputting an indication that a particular reference song is being played enables a continuous song identification process without prompting the computing device to perform the song identification process with user input. by presenting the name of the particular reference song in a notification displayed on the computing device's lock screen, the computing device's always-on screen, or the computing device's unlock screen.
実施形態１９は、実施形態１から１７のいずれか１つに記載のコンピュータによって実施される方法である。この場合、コンピューティング装置は、マイクロフォンを含む。 Embodiment 19 is the computer-implemented method of any one of embodiments 1-17. In this case, the computing device includes a microphone.
実施形態２０は、コンピュータシステムに関する。このコンピュータシステムは、１つ以上のプロセッサと、１つ以上のプロセッサによって実行されると、実施形態１から１９のいずれか１つに記載の方法を実行させる命令を含む１つ以上のコンピュータ可読装置とを含む。 Embodiment 20 relates to a computer system. The computer system comprises one or more processors and one or more computer readable devices comprising instructions that, when executed by the one or more processors, cause the method of any one of embodiments 1-19 to be performed. including.
実施形態２１は、コンピューティングシステムに関する。コンピューティングシステムは、音声信号を記録するように構成されたマイクロフォンを備えている。コンピューティングシステムは、記録された音声信号からデジタル音声データを生成するように構成されたアナログ－デジタルコンバータを備えている。コンピューティングシステムは、（ｉ）複数の参照歌曲の中の各参照歌曲の複数の音声特徴を識別する参照歌曲特徴データと、（ｉｉ）プロセッサによって実行可能であり、プロセッサの動作を構成するための命令とを格納する１つ以上のコンピュータ可読メモリ装置を備えている。コンピューティングシステムは、デジタル音声データが音楽を表すと判断した場合、デジタル音声データが音楽を表すことを示す表記を出力するように構成された第１プロセッサを備えている。コンピューティングシステムは、第１プロセッサからデジタル音声データが音楽を表すことを示す表記を受信し、デジタル音声データが複数の参照歌曲の中の特定の参照歌曲を表すことを認識するように構成された第２プロセッサを備えている。コンピューティングシステムは、第２プロセッサによって、デジタル音声データが複数の参照歌曲の中の特定の参照歌曲を表すことを認識したことに応答して、特定の参照歌曲の識別子を提示するように構成された表示装置を備えている。 Embodiment 21 relates to a computing system. A computing system includes a microphone configured to record audio signals. A computing system includes an analog-to-digital converter configured to generate digital audio data from a recorded audio signal. A computing system comprising: (i) reference song feature data identifying a plurality of audio features for each reference song in a plurality of reference songs; and (ii) executable by a processor for configuring the operation of the processor. One or more computer readable memory devices for storing instructions. The computing system comprises a first processor configured to output a notation indicating that the digital audio data represents music when determining that the digital audio data represents music. A computing system configured to receive from the first processor a notation indicating that the digital audio data represents music, and to recognize that the digital audio data represents a particular reference song among the plurality of reference songs. A second processor is provided. The computing system is configured by the second processor to present an identifier of the particular reference song in response to recognizing that the digital audio data represents the particular reference song of the plurality of reference songs. display device.
実施形態２２は、実施形態２１に記載のコンピューティングシステムである。この場合、コンピューティングシステムは、モバイルコンピューティング装置を含み、このモバイルコンピューティング装置は、マイクロフォンと、アナログデジタルコンバータと、１つ以上のコンピュータ可読メモリ装置と、第１プロセッサと、第２プロセッサとを備える。
実施形態２３は、実施形態２１または２２のいずれか１つに記載のコンピューティングシステムである。この場合、第１プロセッサは、第２プロセッサよりも低い電圧またはワット数で動作する。
Embodiment 23 is the computing system of any one of
実施形態２４は、実施形態２１から２３のいずれか１つに記載のコンピューティングシステムである。この場合、第２プロセッサは、第１プロセッサが動作するクロック信号より少なくとも一桁速いクロック信号で動作する。 Embodiment 24 is the computing system of any one of embodiments 21-23. In this case, the second processor operates with a clock signal that is at least one order of magnitude faster than the clock signal with which the first processor operates.
実施形態２５は、実施形態２２から２４のいずれか１つに記載のコンピューティングシステムである。この場合、第１プロセッサは、デジタル音声データが音楽を表すことを示す表記を出力するように構成され、第２プロセッサは、コンピューティング装置がデジタル音声データをコンピューティング装置以外のコンピューティングシステムに送信することなく、デジタル音声データが特定の参照歌曲を表すことを認識するように構成される。 Embodiment 25 is a computing system according to any one of embodiments 22-24. In this case, the first processor is configured to output a notation indicating that the digital audio data represents music, and the second processor is configured to output the notation that the computing device transmits the digital audio data to a computing system other than the computing device. It is configured to recognize that the digital audio data represents a particular reference song without having to do so.
実施形態２６は、実施形態２２から２５のいずれか１つに記載のコンピューティングシステムである。この場合、第１プロセッサは、デジタル音声データが音楽を表すことを示す表記を出力するように構成され、第２プロセッサは、コンピューティング装置がネットワークを介して外部装置に接続することなく、デジタル音声データが特定の参照歌曲を表すことを認識するように構成される。 Embodiment 26 is the computing system of any one of embodiments 22-25. In this case, the first processor is configured to output a notation indicating that the digital audio data represents music, and the second processor outputs the digital audio without the computing device connecting to an external device over a network. It is configured to recognize that the data represents a particular reference song.
実施形態２７は、実施形態２２から２６のいずれか１つに記載のコンピューティングシステムである。この場合、デジタル音声データが音楽を表すことを判断することは、第１プロセッサを用いてデジタル音声データが音楽を表すことを判断する前に、音楽判断プロセスを開始するためのユーザ入力を受信することなく、コンピューティング装置を用いてデジタル音声データが音楽を表さないことを複数回判断することを含む。 Embodiment 27 is the computing system of any one of embodiments 22-26. In this case, determining that the digital audio data represents music includes receiving user input to initiate a music determination process prior to determining with the first processor that the digital audio data represents music. determining multiple times that the digital audio data does not represent music using a computing device.
実施形態２８は、実施形態２１から２７のいずれか１つに記載のコンピューティングシステムである。この場合、複数の参照歌曲の中の参照歌曲の参照歌曲特徴値は、各特徴値が二進値１または二進値０に限定されるように、二進値１または二進値０に限定される。
Embodiment 28 is the computing system of any one of embodiments 21-27. In this case, the reference song feature values of the reference songs in the plurality of reference songs are limited to binary 1 or
実施形態２９は、実施形態２１から２８のいずれか１つに記載のコンピューティングシステムである。この場合、複数の参照歌曲は、少なくとも１万曲の参照歌曲を含み、１つ以上のコンピュータ可読メモリ装置によって格納された参照歌曲特徴データは、少なくとも１万曲の参照歌曲の音声特徴を識別する。 Embodiment 29 is the computing system of any one of embodiments 21-28. In this case, the plurality of reference songs includes at least ten thousand reference songs, and the reference song feature data stored by the one or more computer readable memory devices identifies audio features of the at least ten thousand reference songs. .
実施形態３０は、実施形態２１から２９のいずれか１つに記載のコンピューティングシステムである。この場合、第１プロセッサは、周波数領域変換プロセスにおいて、デジタル音声データを時間領域形式から周波数領域形式に変換することと、周波数領域形式のデジタル音声データを受信し、デジタル音声データが音楽を表すことを示す表記を出力する音楽判断プロセスにおいて、周波数領域形式のデジタル音声データを使用することとを行うことによって、デジタル音声データが音楽を表すことを判断するように構成される。
実施形態３１は、実施形態３０に記載のコンピューティングシステムである。この場合、音楽判断プロセスは、音声が音楽を表すか否かを判断するように訓練された機械学習システムを実行することを含む。
Embodiment 31 is the computing system according to
実施形態３２は、実施形態３０に記載のコンピューティングシステムである。この場合、音楽判断プロセスは、低電力プロセッサ上で重畳型ニューラルネットワークを実行することを含む。
Embodiment 32 is the computing system according to
実施形態３３は、実施形態２１から３２のいずれか１つに記載のコンピューティングシステムである。この場合、周波数領域形式は、第１周波数領域形式であり、周波数領域変換プロセスは、第１周波数領域変換プロセスであり、第２プロセッサは、（ｉ）第２周波数領域変換プロセスにおいて、デジタル音声データを時間領域形式から第２周波数領域形式に変換することと、（ｉｉ）第２周波数領域形式のデジタル音声データを受信し、デジタル音声データの複数の特徴値を出力する音楽特徴決定プロセスにおいて、第２周波数領域形式のデジタル音声データを使用することと、（ｉｉｉ）デジタル音声データの複数の特徴値を複数の参照歌曲の一部の歌曲の中の各歌曲の複数の特徴値と比較することによって、特定の参照歌曲の複数の特徴値がデジタル音声データの複数の特徴値に最も関連していると判断することとを行うことによって、デジタル音声データが複数の参照歌曲の中の特定の参照歌曲を表すことを認識するように構成される。 Embodiment 33 is a computing system according to any one of embodiments 21-32. In this case, the frequency domain format is a first frequency domain format, the frequency domain transform process is a first frequency domain transform process, and the second processor performs (i) in the second frequency domain transform process, the digital audio data; from a time domain format to a second frequency domain format; and (ii) in a music feature determination process receiving digital audio data in the second frequency domain format and outputting a plurality of feature values of the digital audio data, a second by using digital audio data in a dual frequency domain format; and (iii) comparing a plurality of feature values of the digital audio data with a plurality of feature values for each song in a sub-song of a plurality of reference songs. and determining that the feature values of the particular reference song are most relevant to the feature values of the digital audio data. is configured to recognize that it represents
実施形態３４は、実施形態３３に記載のコンピューティングシステムである。この場合、第２周波数領域形式および第１周波数領域形式は、異なる数の周波数ビンを解析する。 A thirty-fourth embodiment is the computing system according to the thirty-third embodiment. In this case, the second frequency domain format and the first frequency domain format analyze different numbers of frequency bins.
実施形態３５は、実施形態３３または３４のいずれか１つに記載のコンピューティングシステムである。この場合、音楽特徴決定プロセスは、音楽の特徴を決定するように訓練された機械学習システムによって実行される。 Embodiment 35 is a computing system according to any one of embodiments 33 or 34. In this case, the music characterization process is performed by a machine learning system trained to characterize music.
実施形態３６は、実施形態３３から３５のいずれか１つに記載のコンピューティングシステムである。この場合、記デジタル音声データの複数の特徴値を複数の参照歌曲の一部の歌曲の中の各歌曲の複数の特徴値と比較することは、別のコンピューティング装置に歌曲特徴データを要求するためのリクエストを送信することなく、コンピューティング装置によって格納された複数の参照歌曲の一部の歌曲の中の各歌曲の複数の特徴値にアクセスすることによって実行される。 Embodiment 36 is a computing system according to any one of embodiments 33-35. In this case, comparing the plurality of feature values of the digitized audio data to the plurality of feature values of each song in the sub-song of the plurality of reference songs requires song feature data from another computing device. by accessing a plurality of feature values for each song in a portion of the plurality of reference songs stored by the computing device without sending a request for the song.
実施形態３７は、実施形態３３から３６のいずれか１つに記載のコンピューティングシステムである。この場合、デジタル音声データの複数の特徴値の中の特徴値を、複数の候補歌曲の中の各歌曲の複数の特徴値と比較することによって、複数の参照歌曲から一部の歌曲を選択することをさらに含む。 Embodiment 37 is a computing system according to any one of embodiments 33-36. In this case, selecting a subset of songs from the plurality of reference songs by comparing feature values in the plurality of feature values of the digital audio data to a plurality of feature values for each song in the plurality of candidate songs. further including
実施形態３８は、実施形態３３から３７のいずれか１つに記載のコンピューティングシステムである。この場合、デジタル音声データの複数の特徴値を、二進値０および１に限定されない値から二進値０および１に限定された値に変換することをさらに含み、デジタル音声データの複数の特徴値を複数の候補歌曲の中の各歌曲の複数の特徴値と比較することは、（ａ）二進値０および二進値１に限定されたデジタル音声データの特徴値と、（ｂ）二進値０および二進値１に限定された複数の歌曲の中の各歌曲の特徴値との比較を含む。
Embodiment 38 is a computing system according to any one of embodiments 33-37. In this case, further comprising converting the plurality of feature values of the digital audio data from values not limited to
実施形態３９は、実施形態３３から３８のいずれか１つに記載のコンピューティングシステムである。この場合、デジタル音声データの複数の特徴値を複数の参照歌曲の少なくとも一部の歌曲の中の各歌曲の複数の特徴値と比較することは、（ａ）二進値０および二進値１以外の値を表す実数を含むデジタル音声データの特徴値と、（ｂ）二進値０および二進値１に限定された複数の歌曲の少なくとも一部の歌曲の中の各歌曲の特徴値との比較を含む。
Embodiment 39 is a computing system according to any one of embodiments 33-38. In this case, comparing the plurality of feature values of the digital audio data to the plurality of feature values of each song in at least a portion of the plurality of reference songs includes (a) a binary value of 0 and a binary value of 1; and (b) feature values for each song in at least a portion of a plurality of songs limited to
実施形態４０は、コンピュータによって実施される方法である。この方法は、コンピューティング装置を用いて、複数の参照歌曲の中の各参照歌曲の複数の音声特徴を識別する参照歌曲特徴データを格納することを含む。この方法は、コンピューティング装置を用いて、マイクロフォンによって記録された音声を表すデジタル音声データを受信することを含む。この方法は、コンピューティング装置を用いて、デジタル音声データを時間領域形式から周波数領域形式に変換することを含む。この方法は、コンピューティング装置を用いて、周波数領域形式のデジタル音声データをデジタル音声データの複数の特徴値を出力する音楽特徴決定プロセスに使用することとを含み、特徴値の少なくとも一部は、二進値０および二進値１以外の値を表す。この方法は、コンピューティング装置を用いて、デジタル音声データの複数の特徴値を複数の参照歌曲の中の各参照歌曲の複数の特徴値と比較することによって、複数の参照歌曲から、デジタル音声データの複数の特徴値に対応する一部の参照歌曲を複数の候補歌曲として選択することを含む。この方法は、コンピューティング装置を用いて、デジタル音声データの複数の特徴値を複数の候補歌曲の中の各参照歌曲の複数の特徴値と比較することによって、デジタル音声データの複数の特徴値が特定の参照歌曲の複数の特徴値に最も関連していると判断することを含む。この方法は、デジタル音声データの複数の特徴値が特定の参照歌曲の複数の特徴値に最も関連しているという判断に応答して、コンピューティング装置を用いて、特定の参照歌曲を示す表記を出力することを含む。
Embodiment 40 is a computer-implemented method. The method includes using a computing device to store reference song feature data identifying a plurality of audio features of each reference song in a plurality of reference songs. The method includes using a computing device to receive digital audio data representing audio recorded by a microphone. The method includes converting digital audio data from a time domain format to a frequency domain format using a computing device. The method includes using, with a computing device, digital audio data in frequency domain form to a music feature determination process that outputs a plurality of feature values of the digital audio data, at least some of the feature values being: Represents values other than binary 0 and
実施形態４１は、実施形態４０に記載のコンピュータによって実施される方法である。この場合、音楽特徴決定プロセスは、音楽の特徴を決定するように訓練された機械学習システムによって実行される。 Embodiment 41 is the computer-implemented method of embodiment 40. In this case, the music characterization process is performed by a machine learning system trained to characterize music.
実施形態４２は、実施形態４０または４１のいずれか１つに記載のコンピュータによって実施される方法である。この場合、デジタル音声データの複数の特徴値を複数の参照歌曲の中の各参照歌曲の複数の特徴値と比較することは、別のコンピューティング装置に歌曲特徴データを要求するためのリクエストを送信することなく、コンピューティング装置によって格納された複数の参照歌曲の中の各参照歌曲の複数の特徴値にアクセスすることによって実行される。 Embodiment 42 is the computer-implemented method of any one of embodiments 40 or 41. In this case, comparing the plurality of feature values of the digital audio data to the plurality of feature values of each reference song in the plurality of reference songs sends a request to another computing device for the song feature data. by accessing a plurality of feature values for each reference song in a plurality of reference songs stored by the computing device, without having to do so.
実施形態４３は、実施形態４０から４２のいずれか１つに記載のコンピュータによって実施される方法である。この場合、デデジタル音声データの複数の特徴値を、二進値０および１に限定されない値から二進値０および１に限定された値に変換することをさらに含み、デジタル音声データの複数の特徴値を、複数の参照歌曲の中の各歌曲の複数の特徴値と比較することは、（ａ）二進値０および二進値１に限定されたデジタル音声データの特徴値と、（ｂ）二進値０および二進値１に限定された複数の歌曲の中の各歌曲の特徴値との比較を含む。
Embodiment 43 is the computer-implemented method of any one of embodiments 40-42. In this case, further comprising converting the plurality of feature values of the dedigitized audio data from values not limited to
実施形態４４は、実施形態４０から４３のいずれか１つに記載のコンピュータによって実施される方法である。この場合、デジタル音声データの複数の特徴値を、複数の候補歌曲の中の各参照歌曲の複数の特徴値と比較することは、（ａ）二進値０および二進値１以外の値を表す実数を含むデジタル音声データの特徴値と、（ｂ）二進値０および二進値１に限定された複数の候補歌曲の中の各参照歌曲の特徴値との比較を含む。
Embodiment 44 is the computer-implemented method of any one of embodiments 40-43. In this case, comparing the plurality of feature values of the digital audio data to the plurality of feature values of each reference song in the plurality of candidate songs can be performed by: (a) determining values other than binary 0 and
実施形態４５は、実施形態４０から４４のいずれか１つに記載のコンピュータによって実施される方法である。この場合、複数の参照歌曲の中の参照歌曲の参照歌曲特徴値は、各特徴値が二進値１または二進値０に限定されるように、二進値１または二進値０に限定される。
Embodiment 45 is the computer-implemented method of any one of embodiments 40-44. In this case, the reference song feature values of the reference songs in the plurality of reference songs are limited to binary 1 or
実施形態４６は、実施形態４０から４５のいずれか１つに記載のコンピュータによって実施される方法である。この場合、複数の参照歌曲は、少なくとも１万曲の参照歌曲を含み、参照歌曲特徴データは、少なくとも１万曲の参照歌曲の音声特徴を識別する。 Embodiment 46 is the computer-implemented method of any one of embodiments 40-45. In this case, the plurality of reference songs includes at least ten thousand reference songs, and the reference song feature data identifies audio features of the at least ten thousand reference songs.
実施形態４７は、実施形態４０から４６のいずれか１つに記載のコンピュータによって実施される方法である。この場合、コンピューティング装置を用いて、音楽判断プロセスに従って、デジタル音声データが音楽を表すか否かを判断することをさらに含み、コンピューティング装置は、音楽判断プロセスに従って、デジタル音声データが音楽を表すことを判断した後、デジタル音声データの複数の特徴値を、複数の参照歌曲の中の各参照歌曲の複数の特徴値と比較する。 Embodiment 47 is the computer-implemented method of any one of embodiments 40-46. The case further comprising using the computing device to determine whether the digital audio data represents music according to the music determination process, wherein the computing device determines whether the digital audio data represents music according to the music determination process. After determining that, the plurality of feature values of the digital audio data is compared to the plurality of feature values for each reference song in the plurality of reference songs.
実施形態４８は、実施形態４０から４７のいずれか１つに記載のコンピュータによって実施される方法である。この場合、周波数領域形式は、第１周波数領域形式であり、周波数領域変換プロセスは、第１周波数領域変換プロセスであり、デジタル音声データが音楽を表すか否かを判断することは、第２周波数領域変換プロセスにおいて、デジタル音声データを時間領域形式から第２周波数領域形式に変換することと、第２周波数領域形式のデジタル音声データを受信し、デジタル音声データが音楽を表すか否かを示す表記を出力する音楽特徴決定プロセスにおいて、第２周波数領域形式のデジタル音声データを使用することとを含む。 Embodiment 48 is the computer-implemented method of any one of embodiments 40-47. In this case, the frequency domain format is a first frequency domain format, the frequency domain transform process is a first frequency domain transform process, and determining whether the digital audio data represents music is a second frequency domain format. A notation indicating that a domain transformation process transforms digital audio data from a time domain format to a second frequency domain format, receives digital audio data in the second frequency domain format, and whether the digital audio data represents music. using the digital audio data in the second frequency domain format in a music feature determination process that outputs .
実施形態４９は、実施形態４７または４８のいずれか１つに記載のコンピュータによって実施される方法である。この場合、音楽判断プロセスは、音声が音楽を表すか否かを判断するように訓練された機械学習システムを実行することを含む。 Embodiment 49 is the computer-implemented method of any one of embodiments 47 or 48. In this case, the music determination process involves running a machine learning system trained to determine whether the speech represents music.
実施形態５０は、実施形態４７から４９のいずれか１つに記載のコンピュータによって実施される方法である。この場合、コンピューティング装置は、複数の参照歌曲の中の各参照歌曲の複数の音声特徴を識別する参照歌曲特徴データにアクセスすることなく、デジタル音声データが音楽を表すか否かを判断する。 Embodiment 50 is the computer-implemented method of any one of embodiments 47-49. In this case, the computing device determines whether the digital audio data represents music without accessing reference song feature data that identifies multiple audio features for each reference song in the multiple reference songs.
実施形態５１は、実施形態４７から５０のいずれか１つに記載のコンピュータによって実施される方法である。この場合、コンピューティング装置を用いて、音楽判断プロセスに従ってデジタル音声データが音楽を表すか否かを判断することは、デジタル音声データが音楽を表すことを判断する前に、音楽判断プロセスを開始するためのユーザ入力を受信することなく、コンピューティング装置を用いて、デジタル音声データが音楽を表さないことを複数回判断することを含む。 Embodiment 51 is the computer-implemented method of any one of embodiments 47-50. In this case, using the computing device to determine whether the digital audio data represents music according to the music determination process initiates the music determination process before determining that the digital audio data represents music. determining, using a computing device, multiple times that the digital audio data does not represent music without receiving user input for the music.
実施形態５２は、実施形態４７から５１のいずれか１つに記載のコンピュータによって実施される方法である。この場合、第２周波数領域形式と第１周波数領域形式は、異なる数の周波数ビンを解析する、
実施形態５３は、実施形態４７から５２のいずれか１つに記載のコンピュータによって実施される方法である。この場合、デジタル音声データが音楽を表すか否かを判断することは、コンピューティング装置の第１プロセッサによって実行され、デジタル音声データの複数の特徴値を、複数の参照歌曲の中の各参照歌曲の複数の特徴値と比較することは、コンピューティング装置の第２プロセッサによって実行され、デジタル音声データの複数の特徴値を、複数の候補歌曲の中の各参照歌曲の複数の特徴値と比較することは、コンピューティング装置の第２プロセッサによって実行される。
Embodiment 52 is the computer-implemented method of any one of embodiments 47-51. In this case, the second frequency domain format and the first frequency domain format analyze different numbers of frequency bins.
Embodiment 53 is the computer-implemented method of any one of embodiments 47-52. In this case, determining whether the digital audio data represents music is performed by a first processor of the computing device, wherein the plurality of characteristic values of the digital audio data are evaluated for each reference song in the plurality of reference songs. is performed by a second processor of the computing device to compare the plurality of feature values of the digital audio data to the plurality of feature values of each reference song in the plurality of candidate songs It is performed by a second processor of the computing device.
実施形態５４は、実施形態５３に記載のコンピュータによって実施される方法である。この場合、第１プロセッサは、第２プロセッサよりも低い電圧またはワット数で動作する。 Embodiment 54 is the computer-implemented method of embodiment 53. In this case, the first processor operates at a lower voltage or wattage than the second processor.
実施形態５５は、実施形態５３または５４のいずれか１つに記載のコンピュータによって実施される方法である。この場合、第２プロセッサは、第１プロセッサが動作するクロック信号より少なくとも一桁速いクロック信号で動作する。 Embodiment 55 is the computer-implemented method of any one of embodiments 53 or 54. In this case, the second processor operates with a clock signal that is at least one order of magnitude faster than the clock signal with which the first processor operates.
実施形態５６は、実施形態４０から５５のいずれか１つに記載のコンピュータによって実施される方法である。この場合、特定の参照歌曲を示す表記を出力することは、ユーザ入力によって歌曲識別プロセスを実行するようにコンピューティング装置を促すことなく、連続した歌曲識別プロセスを有効にすることによって、コンピューティング装置のロック画面、コンピューティング装置の常時オン画面、またはコンピューティング装置のロック解除画面に表示された通知に、特定の参照歌曲の名前を提示することを含む。 Embodiment 56 is the computer-implemented method of any one of embodiments 40-55. In this case, outputting a notation that indicates a particular reference song can be performed by the computing device by enabling a continuous song identification process without prompting the computing device to perform the song identification process with user input. including presenting the name of the particular reference song in a notification displayed on the lock screen of the , the always-on screen of the computing device, or the unlock screen of the computing device.
実施形態５７は、コンピュータシステムに関する。このコンピュータシステムは、１つ以上のプロセッサと、１つ以上のプロセッサによって実行されると、実施形態４０から５６のいずれか１つに記載の方法を実行させる命令を含む１つ以上のコンピュータ可読装置とを含む。 Embodiment 57 relates to a computer system. The computer system comprises one or more processors and one or more computer readable devices comprising instructions that, when executed by the one or more processors, cause the method of any one of embodiments 40-56 to be performed. including.
１つ以上の実施例の詳細は、添付の図面および以下の説明に記載されている。他の特徴、目的および利点は、説明および図面ならびに特許請求の範囲から明らかになるであろう。 The details of one or more implementations are set forth in the accompanying drawings and the description below. Other features, objects and advantages will be apparent from the description and drawings and from the claims.
詳細な説明
様々な図面において、同様の参照記号は、同様の要素を示す。
DETAILED DESCRIPTION In the various drawings, like reference symbols indicate like elements.
本明細書は、一般的に、検出された周囲音声が音楽を表すまたは含むことを判断した後、周囲音声に含まれた歌曲を識別するためのメカニズムを説明する。この開示は、まず、図１を参照してこのプロセスの要点を説明し、次に図２～１０を参照して当該プロセスの追加の詳細を提供する。 This specification generally describes a mechanism for identifying songs contained in the ambient sound after determining that the detected ambient sound represents or contains music. This disclosure first describes the gist of this process with reference to FIG. 1 and then provides additional details of the process with reference to FIGS.
図１は、自動音楽判断および歌曲識別を実行するためのコンピューティング装置１００と、コンピューティング装置１００に参照歌曲データを提供するためのリモートサーバシステム１５０とを示している。コンピューティング装置１００は、図１においてタッチスクリーンスマートフォンとして示されているが、コンピューティング装置１００は、他の種類のモバイルコンピューティング装置または非モバイルコンピューティング装置、例えば、タブレット、スマートウォッチ、デスクトップコンピュータおよびスマート家電であってもよい。
FIG. 1 shows a
コンピューティング装置１００は、音声データ１０２を連続的に記録し、音声データ１０２を解析することによって、検出された周囲音声に音楽が含まれているか否かを判断するように構成されている。音声データ１０２は、マイクロフォンを用いてアナログ形式に記録され、その後、低電力プロセッサ１０４に提供される。低電力プロセッサ１０４は、音声データ１０２をアナログ形式からデジタル形式に変換する。
The
低電力プロセッサ１０４は、デジタル形式の音声データ１０２をバッファに格納し、音声データ１０２を容易に解析するように、（例えば、音声データ１０２に対して高速フーリエ変換を実行することによって）音声データ１０２を時間領域形式から周波数領域形式に変換する。低電力プロセッサ１０４は、一定の間隔（例えば、１０ミリ秒ごと、２０ミリ秒ごと、４０ミリ秒ごと、または別の適切な値）で、この変換プロセスを定期的に実行することができる。高速フーリエ変換は、上記の間隔よりも長い時間窓上で動作することができる（例えば、１０ミリ秒の間隔で２５ミリ秒の時間窓上で動作することができる）。
The
低電力プロセッサ１０４は、一定の秒数（例えば、５秒、１０秒、２０秒、または別の値）の配列をバッファに保存し、最後の秒数（例えば、５秒）よりも長い各間隔（例えば、１０ミリ秒の間隔、２０ミリ秒の間隔、４０ミリ秒の間隔）に対して、コンピューティング装置は、異なる周波数範囲の複数の「ビン」（例えば、３２ビン、６４ビン、１２８ビン）の各々の周波数コンテンツのパワーを特定する。バッファは、一定の秒数（例えば、５秒）よりも古い配列が新たに生成された配列によって置換されるような循環型バッファであってもよい。低電力プロセッサ１０４は、このプロセスを連続的に（すなわち、プロセスを開始するためのユーザの反復入力を必要せず、定期的に繰り返して）実行することができる。
低電力プロセッサ１０４は、一定の間隔（例えば、１秒ごと、２秒ごと、５秒ごと）で、５秒間のバッファを解析することによって、最近取得した音声データ１０２がコンピューティング装置１００の周囲環境で再生されている音楽を表すか否かを判断する。いくつかの例において、この解析は、低電力プロセッサ１０４上で動作する機械学習システム、例えば重畳型ニューラルネットワークによって実行される。機械学習システムは、数万個の音声録音および各音声録音が音楽を表すか否かを示す表記を機械学習システムに入力することによって、別個のコンピューティングシステム上で訓練される。これらの入力は、最終的に機械学習システムを訓練し、訓練された機械学習システムは、（例えば、機械学習システムの構成データを転送することによって）コンピューティング装置１００および類似する他の装置に転送することができる。コンピューティング装置１００は、機械学習システムの随時更新を受信することができる。
At regular intervals (e.g., every 1 second, every 2 seconds, every 5 seconds), the
低電力プロセッサ１０４は、各間隔（例えば、１秒ごと、２秒ごと、または５秒ごと）で、音楽推定結果（例えば、信頼値および／または「はい」または「いいえ」という判断）のバッファを生成することによって、音声データ１０２が音楽を表すか否かを識別することができる。低電力プロセッサ１０４は、これらの音楽推定結果を別のバッファに格納することができ、音楽推定結果の最近の履歴を解析することによって、これらの音楽推定結果が、音楽がコンピューティング装置１００を配置している周囲環境に実際に再生されていることを示す表記を出力するための所定の基準を満たしているか否かを判断することができる。いくつかの例において、低電力プロセッサ１０４は、過去の判断の少なくとも特定の部分（例えば、最後の７つの１秒判断のうち５つ）が「はい」（すなわち、検出された周囲音声が音楽を含むこと）を示す場合、音楽が再生されていることを示す結果を出力することができる。７つの個別の判断に対するこの「表決」（voting）は、例えば、低電力プロセッサ１０４によって出力された音楽判断結果の信頼性を高め、（例えば、テレビ広告において）２秒または３秒のみの音楽クリップが再生されている場合に、低電力プロセッサ１０４が、音楽が再生されていることを示さないことを保証する。表決は、いくつかの偽陽性分類が存在する場合にも有用である。
At each interval (eg, every 1 second, 2 seconds, or 5 seconds), the
低電力プロセッサ１０４は、検出された周囲音声に音楽が含まれていることを判断した後、高電力プロセッサ１１０に命令１０８を送信して、高出力プロセッサ１１０に再生されている歌曲を識別させる。また、低電力プロセッサ１０４は、音楽が再生されていることを判断したときに基づいた基礎音声データ１０６を高電力プロセッサ１１０に送信する。低電力プロセッサ１０４は、時間領域形式の基礎音声データ１０６を送信し、高電力プロセッサは、低電力プロセッサ１０４によって生成された音声データ１０２の表現よりも高い解像度の周波数領域表現を生成することができる。低電力プロセッサ１０４が高電力プロセッサ１１０に送信したバッファは、分類窓とは異なるサイズであってもよい（例えば、分類が最後の５秒間に実行されても、バッファは、最後の８秒間であってもよい）。
After the
高電力プロセッサ１１０は、音声データ１０６を受信し、音声データ１０６の解析を行うために、音声データ１０６を周波数領域形式に変換する。高速フーリエ変換プロセスを用いて周波数領域変換を実行することによって、音声データ１０６の比較的高解像度の周波数領域表現を生成することができる。この高解像度の周波数領域表現は、（例えば、ビンの数に対応する長さを有する配列を生成するために）各変換に対応する特定の数のビン（例えば、２５６ビン、５１２ビン、１０２４ビン）を含む。高電力プロセッサ１１０は、低電力プロセッサ１０４から受信した音声データ１０６に対して、一定の間隔（例えば、４６ミリ秒の間隔、９２ミリ秒の間隔、１８４ミリ秒の間隔）で周波数領域変換プロセスを実行することができる。高電力プロセッサ１１０は、生成された配列をバッファに格納することができる。したがって、高電力プロセッサ１１０は、低電力プロセッサ１０４から時間領域形式の音声データ１０６を取得し、周波数領域形式の音声データ１０６を表す値の配列をバッファに格納する。
A
次に、高電力プロセッサ１１０は、バッファに格納された周波数領域形式の音声データ１０６を解析することによって、音声データ１０６の特徴を決定する。例えば、高電力プロセッサ１１０は、周波数領域形式の音声データ１０６を、特徴値セットを生成するように訓練された機械学習システム（例えば、ニューラルネットワーク）に提供することができる。各特徴値セットは、音声の特徴を決定するための一定数の値（例えば、４８個の値、９６個の値、１９２個の値、または別の適切な数の値）を有する。本実施例において、高電力プロセッサ１１０は、単一セットの値を生成してバッファ内の音声データ１０６の全ての特徴を決定するのではなく、バッファの全体に対して１秒の間隔で特徴決定プロセスを実行し、一回に音声データ１０２の２秒間の特徴を決定することができる。よって、バッファの長さが８秒である場合、高電力プロセッサ１１０は、７セットの特徴値（１つのセット：０～２秒、次のセット：１～３秒、別のセット：２～４秒、以下同様）を生成する。各特徴値は、「浮動」値（float value）に含まれている実数（例えば、小数部分が「７８３」である実数０．７８３）であってもよい。機械学習システムを用いてバッファ内の音声データ１０６を解析する前に、高電力プロセッサ１１０は、例えば、周波数ビンの重み付けまたは特徴スケーリング／正規化（例えば、０の平均、１の標準偏差）を行うことによって、バッファ内の値を処理することができる。
The
高電力プロセッサ１１０は、このような特徴データを作成し、コンピューティング装置１００が記録した音声データ１０６を、同様に作成され、コンピューティング装置１００によって装置上歌曲データベース１１６に保存されている数千曲の歌曲の参照歌曲特徴データ１１８と比較する。コンピューティング装置１００は、リモートサーバシステム１５０から参照歌曲特徴データ１１８を受信し、装置上歌曲データベース１１６に保存することができる。リモートサーバシステム１５０は、数十万または数百万曲の歌曲の特徴データを格納するグローバル歌曲データベース１２０を含むことができ、歌曲選別プロセス１２２を用いてコンピューティング装置１００に送信する歌曲特徴データを選択することができる。
The high-
例えば、グローバル歌曲データベース１２０は、世界中で人気のある歌曲の特徴データを含むが、一部の歌曲の参照歌曲特徴データ１１８のみをコンピューティング装置１００に送信してもよい。例えば、リモートサーバシステム１５０によってコンピューティング装置１００が北米に位置していると判断された場合、コンピューティング装置１００に送信される参照歌曲特徴データ１１８は、北米で人気のある歌曲のみを含むことができる。コンピューティング装置１００が位置する地理区域に異なる歌曲が人気になるため、リモートサーバシステム１５０は、参照歌曲データ１１８の更新リストをコンピューティング装置１００に定期的に送信することができる。グローバル歌曲データベース１２０の全ての歌曲から参照歌曲特徴データ１１８を選択するための基準は、地理位置以外の要素、例えば、ユーザの年齢（例えば、若い人にポップミュージック、年寄の人にクラシック歌曲を提供する）、装置の記憶容量（例えば、より大きい容量を有する装置またはユーザがより多くの歌曲特徴データの記憶を許可した装置により多くの歌曲データを提供する）、日中時間（例えば、ユーザの好みに基づいて、夜にディスコ音楽、朝にトレーニング歌曲を提供する）、年間時間（例えば、１２月により多くの祝日音楽を提供する）、ユーザの趣味（例えば、ソーシャルネットワークのプロファイルまたはメッセージから収集された情報に基づいて音楽を提供する）の組み合わせに基づくことができる。このような個人データの収集および使用は、ユーザのオプトインリクエスト（opt-in request）に応じて実行される。したがって、ユーザが個人データを参照歌曲特徴データ１１８のカスタマイズに使用することを明確に認めない限り、個人データが利用または使用されない。参照歌曲特徴データ１１８は、上記で説明したように、コンピューティング装置１００上で記録された音声データ１０６に対して実行されたプロセスと類似または同様の特徴決定プロセスを用いて生成されてもよい。換言すれば、リモートサーバシステム１５０は、全ての参照歌曲に対して、参照歌曲の１秒の間隔で一定数の特徴値（例えば、４８個の値、９６個の値、１９２個の値、または別の適切な値）を生成することができる。参照歌曲特徴データ１１８は、二進値で保存され、各特徴値は、公称値から切り捨てまたは切り上げることによって「０」または「１」にする。これによって、記憶スペースを節約し、迅速な比較を容易にする。一方、コンピューティング装置１００によって生成された特徴データは、実数（「浮動」値、例えば、０．７８３に含まれた実数）として格納される。
For example, the
高電力プロセッサ１１０は、（例えば、機械学習システムを用いて）音声データ１０６の特徴を決定することによって、音声データ１０６を歌曲特徴データに変換すると、その歌曲特徴データを参照歌曲特徴化データ１１４と比較して、記録された音声データ１０６が装置上歌曲データベース１１６内の歌曲と一致するか否かを判断することができる。この比較プロセスは、２つのステップで実行されてもよい。第１ステップにおいて、高電力プロセッサ１１０は、装置上歌曲データベース１１６内の全ての歌曲に対して軽量比較を実行することによって、コンピューティング装置によって記録された音声データ１０６に類似する１組の候補歌曲を特定する。これらの候補歌曲は、第２ステップに実行されるより詳細な解析の対象である。
The
いくつかの例において、候補歌曲を特定するための軽量比較は、音声データ１０６から生成された特徴値の一部（例えば、６４個の値、４８個の値、３２個の値、または別の適切な数の値）を選択することと、（端数処理プロセスを用いて）各々の特徴値を二進値「０」または二進値「１」に変換することとを含む。次に、高電力プロセッサ１１０は、数千個曲の参照歌曲の各歌曲の１秒間隔ごとに、記録された音声データ１０６から生成された二進値特徴値の一部を、装置上歌曲データベース１１６に格納された対応する６４個の二進値特徴値と比較する。この比較プロセスは、数十万回の比較を含む。例えば、記録された音声１０６から生成された特徴値セットが７つであり、各々の特徴値セットは、装置上歌曲データベース１１６に保存されている各歌曲の１秒間隔の特徴値セットと比較される。例えば、各歌曲の長さが約２００秒であると仮定する場合、この比較プロセスは、装置上歌曲データベース１１６内の各歌曲に対して１４００回の比較を実行する。比較される値の両方が二進値であり、プロセッサ比較命令を使用できるため、高電力プロセッサ１１０は、これらの比較を比較的迅速に実行することができる。
In some examples, a lightweight comparison for identifying candidate songs is a subset of feature values generated from audio data 106 (e.g., 64 values, 48 values, 32 values, or another and converting (using a rounding process) each feature value to a binary value of '0' or a binary value of '1'. The
高電力プロセッサ１１０は、候補歌曲（例えば、記録された音声データ１０６と一致する歌曲または類似度比較プロセスによって生成された高い類似度スコアを有する歌曲）のリストを生成した後、記録された音声データ１０６と候補歌曲とのより詳細な比較を含む第２ステップを実行することができる。このより詳細な比較は、（候補識別プロセスと同様に、二進表現ではなく）実数値形式の全ての特徴値（例えば、４８個の値、９６個の値、１９２個の値、または別の適切な数の値）を、装置上歌曲データベース内の対応する特徴値と比較することを含む。
After the
比較プロセスに実数値（例えば、小数点を有する値）を使用することによって、単に「一致」または「不一致」という結果ではなく、記録された音声データ１０６の特徴値と参照歌曲特徴データ１１８の対応する参照歌曲の特徴値との間の類似度を示す値の配列を含む結果を出力することができる。数十万回の比較を実行した後、高電力プロセッサ１１０は、記録された音声データ１０６と最も高い類似度を有する候補歌曲（少なくとも候補歌曲の特徴値と記録された音声データ１０６の特徴値との間の類似度が所定の閾値を超えるべきである）を、周囲環境に再生されている歌曲として特定する。
By using real-valued values (e.g., values with decimal points) in the comparison process, the feature values in the recorded
いくつかの例において、コンピューティング装置１００は、周囲環境に再生されている歌曲を特定したことを視覚的または聴覚的に表示する。例えば、コンピューティング装置１００は、歌曲情報１１２（例えば、歌曲の曲名および歌手の名前）をコンピューティング装置１００のディスプレイ上に表示することができる。例えば、コンピューティング装置１００は、歌曲情報１１２を通知画面またはバックグラウンドディスプレイの一部に表示することができる。
In some examples, the
以下、本開示は、残りの図面を参照して、このプロセスをさらに詳細に説明する。
図２は、例示的なコンピューティング装置の現在環境に音楽が再生されていることを検出および判断するために使用された例示的なコンピューティング装置の構成要素、動作およびデータ構造を示す概念図である。図２に示すように、例えば、（図１に示された低電力プロセッサ１０４と同様の）低電力プロセッサ２０２を用いて、デジタル音声データを連続的に処理し、デジタル音声データが音楽を表すか否かを判断することができる。例えば、低電力プロセッサ２０２は、装置のマイクロフォンからの信号を処理するように構成された専用オーディオコーデックチップに含まれた専用デジタル信号プロセッサ（ＤＳＰ）である。低電力プロセッサ２０２は、メインプロセッサ（例えば、中央処理装置（ＣＰＵ））よりも低い電圧またはワット数で動作し、メインプロセッサのクロック信号よりも少なくとも５倍、１０倍、２０倍、または３０倍遅いクロック信号で動作する。したがって、低電力プロセッサ２０２は、低い量の装置バッテリ電力（例えば、バッテリ容量の１％未満）を消費しながら、装置のマイクロフォンによって検出された周囲音声を継続的に監視することができる。検出された周囲音声に音楽が含まれていることを判断するために使用された低電力プロセッサ２０２の構成要素、動作およびデータ構造は、図３Ａおよび３Ｂを参照してさらに詳細に説明される。
The present disclosure will now describe this process in greater detail with reference to the remaining figures.
FIG. 2 is a conceptual diagram illustrating the components, operations and data structures of an exemplary computing device used to detect and determine that music is playing in the current environment of the exemplary computing device. be. As shown in FIG. 2, for example, a low power processor 202 (similar to the
図３Ａおよび３Ｂは、例示的なコンピューティング装置の現在環境に音楽が再生されていることを判断するための例示的なプロセスを示す図である。一般的に、具体的なユーザ入力がなくても、このプロセスを継続的に実行することができる。例えば、ユーザは、プロセスを開始する前の適切な時点で、装置の構成設定を変更することによって、装置の電源がオンになったときにプロセスを継続的に実行する指示を装置に提供することができる。その後、装置は、さらなるユーザ入力がなくても、装置がオンになるたびにこのプロセスを実行することができる。検出された周囲音声に音楽が含まれていることを判断するための動作は、例えば、（図２に示された）低電力プロセッサ２０２によって実行することができる。 3A and 3B illustrate an exemplary process for determining that music is playing in the current environment of an exemplary computing device. In general, this process can run continuously without specific user input. For example, the user may provide instructions to the device to continue executing the process when the device is powered on by changing the configuration settings of the device at an appropriate time before starting the process. can be done. The device can then perform this process each time the device is turned on without further user input. The operations for determining that the detected ambient sound includes music may be performed, for example, by low power processor 202 (shown in FIG. 2).
ボックス３０２において、マイクロフォンによって捕捉された音声入力を受信する。例えば、（図１に示された）コンピューティング装置１００は、マイクロフォンによって検出された周囲音声を継続的に監視および記録することができる。
At
ボックス３０４において、音声入力をアナログ形式からデジタル形式に変換する。図２を参照して、周囲音声信号（例えば、装置のマイクロフォンによって生成されたアナログ音声信号）は、アナログ－デジタル（Ａ／Ｄ）コンバータ２０４によって受信される。アナログ－デジタルコンバータ２０４は、アナログ音声信号を時間領域形式のデジタル音声データに変換することができる。いくつかの例において、アナログ－デジタルコンバータ２０４は、低電力プロセッサ２０２とは別個の集積回路として実装されてもよい。いくつかの例において、アナログ－デジタルコンバータ２０４は、低電力プロセッサ２０２上に実装されてもよい。
At
ボックス３０６において、デジタル音声データをデジタル音声バッファに保存する。例えば、アナログ－デジタルコンバータ２０４は、デジタル音声データの連続ストリームを出力することができ、このデジタル音声データの連続ストリームは、低電力プロセッサ２０２のデジタル音声バッファ２０６に保存される。いくつかの例において、デジタル音声バッファ２０６は、特定の秒数（例えば、４秒、８秒、１６秒）より古いデジタル音声が新たに受信されたデジタル音声データによって上書きされるような循環型バッファであってもよい。
At
ボックス３０８において、デジタル音声データが音楽を表すか否かを判断する。例えば、低電力プロセッサ２０２は、デジタル音声バッファ２０６からのデジタル音声データストリームを連続的に処理することができ、この処理に基づいて、デジタル音声データの特定の断片が音楽を表すか否かを定期的に判断することができる。
At
ボックス３１０において、デジタル音声データが音楽を表すか否かを判断することは、第１周波数領域変換プロセスにおいて、デジタル音声データを時間領域形式から第１周波数領域形式に変換することを含む。例えば、低電力プロセッサ２０２は、周期的に（例えば、１０ミリ秒、２０ミリ秒、４０ミリ秒または別の適切な時間間隔で）周波数変換プロセス２０８を実行することができる。これによって、デジタル音声バッファ２０６からの特定の時間窓（例えば、２５ミリ秒、５０ミリ秒、１００ミリ秒または別の適切な時間窓）のデジタル音声データは、時間領域形式から第１周波数領域形式に変換される。本実施例において、低電力プロセッサ２０２は、２０ミリ秒ごとに１回に、デジタル音声バッファ２０６からの最近の５０ミリ秒のデジタル音声をサンプリングおよび処理するように、周波数変換プロセス２０８を実行する。例えば、周波数変換プロセス２０８は、特定数のビン（例えば、１６個のビン、３２個のビン、６４個のビン、または別の適切な数のビン）を含むデータフレーム２１０を出力する。各ビンは、周波数範囲に関連付けられ、サンプリング期間中に周波数範囲内の音声の強度を表す関連値を有する。本実施例において、データフレーム２１０は、１６個のビンを含み、各ビンは、音声範囲（例えば、可聴音声範囲）の異なる部分に関連付けられ、音声範囲の一部の音声の強度を表す浮動値を有する。いくつかの例において、周波数変換プロセス２０８は、高速フーリエ変換（ＦＦＴ）アルゴリズムを用いて、サンプリングされたデジタル音声データを時間領域形式から第１周波数領域形式のデータフレームに変換することができる。
In
ボックス３１２において、デジタル音声データが音楽を表すか否かを判断することは、第１周波数領域形式のデジタル音声データをバッファに格納することを含む。例えば、低電力プロセッサ２０２は、（例えば、デジタル音声バッファ２０６の最近の５０ミリ秒のデジタル音声を表す）データフレーム２１０を周波数変換バッファ２１２に追加することができる。周波数変換バッファ２１２は、過去のサンプリング期間中に周波数変換プロセス２０８によって生成された一連のデータフレームを含む。本実施例において、周波数変換バッファ２１２は、過去の５秒間に亘って生成されたデータフレームを含む。いくつかの例において、周波数変換バッファ２１２は、特定の秒数（例えば、５秒）よりも古いデータフレームが新たに生成されたデータフレームによって上書きされるような循環型バッファであってもよい。
Determining whether the digital audio data represents music in
ボックス３１４において、デジタル音声データが音楽を表すか否かを判断することは、第１周波数領域形式のデジタル音声データを、第１周波数領域形式のデジタル音声データを受信する音楽判断プロセスに提供することを含む。例えば、音楽判断プロセスの一部として、低電力プロセッサ２０２は、周波数変換バッファ２１２に保存されている過去に生成されたデータフレームの一部または全体に対して、音楽推定プロセス２１４を定期的に（例えば、毎秒１回に）実行することができる。本実施例において、音楽推定プロセス２１４は、第１周波数領域形式で格納された音声データからサンプリングされた最後の５秒の音声データを含む周波数変換バッファ２１２の全体を入力として受信する。
Determining whether the digital audio data represents music in
ボックス３１６において、音楽判断プロセスは、音声データが音楽を表すか否かを判断するように訓練された機械学習システムを含む。例えば、周波数変換バッファ２１２が音楽を表すか否かを判断するために、音楽推定プロセス２１４は、オフラインで（例えば、予めサーバシステム１５０で）訓練され、低電力プロセッサ２０２に提供された機械学習モデルを参照することを含むことができる。機械学習モデルを用いて、第１周波数領域形式のデジタル音声データ（例えば、周波数変換バッファ２１２内の一連のデータフレーム）が音楽を表すまたは音楽を表さないか否かに関して二項分類を実行することができる。いくつかの例において、機械学習モデルは、低電力プロセッサ２０２上で連続的に動作する小さな量子化重畳型ニューラルネットワークであってもよい。
At
ボックス３２０において、デジタル音声データが音楽を表すか否かを判断することは、デジタル音声データが音楽を表すか否かを示す値を音楽推定結果バッファ２１６に保存することを含む。例えば、音楽推定プロセス２１４を実行した後、低電力プロセッサ２０２は、第１周波数領域形式のデジタル音声データが音楽を表すか否かを示す二進値２１８（例えば、音楽を示す場合「１」、音楽を示ない場合「０」）を音楽推定結果バッファ２１６に追加することができる。いくつかの例において、音楽推定結果バッファ２１６は、特定数（例えば、７つ）の最新の音楽推定結果値が保存され、より古い決定値が新しい決定値によって上書きされるような循環型バッファであってもよい。
Determining whether the digital audio data represents music in
ボックス３２２において、デジタル音声データが音楽を表すか否かを判断することは、過去の音楽推定結果がデジタル音声が音楽を表すことを示す表記を出力するための所定の基準を満たすか否かを判断することを含む。例えば、二進値２１８を音楽推定結果バッファ２１６に追加した後、低電力プロセッサ２０２は、音楽推定結果バッファ２１６内の過去の音楽推定結果の一部または全体を入力として受信する音楽判断プロセス２２０を実行することができる。本実施例において、音楽判断プロセス２２０は、１秒の間隔で生成された過去の７つの音楽推定結果を含む音楽推定結果バッファ２１６の全体を入力として受信する。いくつかの例において、デジタル音声が音楽を表すことを示す表記を出力するための所定の基準は、音楽推定結果バッファ２１６内の過去の音楽推定結果の閾値数（例えば、７つのうち５つ）が第１周波数領域形式のデジタル音声が音楽を表すことを示すか否かを判断することを含む。いくつかの例において、デジタル音声が音楽を表すことを示す表記を出力するための所定の基準は、音楽推定結果バッファ２１６内の過去の連続した音楽推定結果の閾値数（例えば、４つの連続した結果）が第１周波数領域形式のデジタル音声が音楽を表すことを示すか否かを判断することを含む。
Determining whether the digital audio data represents music in
ボックス３２４において、デジタル音声データが音楽を表すか否かを判断することは、デジタル音声データが音楽を表すことを示す表記を出力することを含む。例えば、音楽判断プロセス２２０によって第１周波数領域形式のデジタル音声データが音楽を表すという判断に応答して、低電力プロセッサ２０２は、音声を解析するための命令２２２およびデジタル音声バッファ２０６からの対応するデジタル音声２２４を（図４に示された）高電力プロセッサ４０２に提供することができる。本実施例において、（例えば、時間領域形式で記録された過去８秒のデジタル音声データを含む）デジタル音声バッファ２０６の全てのコンテンツは、高電力プロセッサに提供され、さらに処理される。
In
ボックス３２６において、デジタル音声データが音楽を表すか否かを判断することは、デジタル音声データが音楽を表すか否かを判断する前に、音楽判断プロセスを開始するためのユーザ入力を受信することなく、デジタル音声データが音楽を表さないことを複数回（例えば、数千回）に判断することを含む。例えば、コンピューティング装置１００は、音楽の周囲音声を継続的に監視することによって、音楽が存在しないと判断することができる。音楽が存在する場合（例えば、音楽が装置の近くに再生される場合、または装置が音楽のある場所に移動される場合）、コンピューティング装置１００は、装置のユーザから音楽を判断するプロセスを開始するための入力なしで、音楽を検出することができる。
Determining whether the digital audio data represents music at
図４は、参照歌曲データを受信および格納し、例示的なコンピューティング装置の現在環境に再生されている歌曲を識別するために使用される例示的なコンピューティング装置の構成要素、動作およびデータ構造を示す概念図である。図４に示すように、（例えば、図１に示された高電力プロセッサ１１０と同様の）高電力プロセッサ４０２を用いて、再生中の歌曲を示すデータが（例えば、図１に示された装置上歌曲データベース１１６と同様の）装置上歌曲データベース４０４に格納された歌曲を示すデータと一致するか否かを判断することができる。高電力プロセッサ４０２は、例えば、装置のメインプロセッサ（例えば、中央処理装置（ＣＰＵ））であってもよい。高電力プロセッサ４０２は、（図２に示された）低電力プロセッサ２０２よりも高い電圧またはワット数で動作し、低電力プロセッサ２０２のクロック信号より少なくとも１桁速い（例えば、５倍、１０倍、２０倍、または３０倍速い）クロック信号で動作する。いくつかの例において、高電力プロセッサ４０２は、２つ以上のＣＰＵコアを含んでもよい。いくつかの例において、装置上歌曲データベース４０４は、永続的なメモリを使用して実装することができ、装置上歌曲データベース４０４内のデータの一部または全ては、歌曲識別プロセスを促進するように、装置のランダムアクセスメモリ（ＲＡＭ）にロードすることができる。参照歌曲データを受信し、装置上歌曲データベース４０４に格納するための要素、操作およびデータ構造は、図５を参照してさらに詳細に説明する。高電力プロセッサ４０２によって使用され、再生中の歌曲を識別するための要素、操作およびデータ構造は、図６Ａおよび６Ｂを参照してさらに詳細に説明する。
FIG. 4 illustrates the components, operations and data structures of an exemplary computing device used to receive and store reference song data and identify songs playing in the current environment of an exemplary computing device. It is a conceptual diagram showing As shown in FIG. 4, using a high power processor 402 (e.g., similar to
図５は、参照歌曲データを受信および格納するための例示的なプロセスを示す図である。一般的に、このプロセスは、定期的に（例えば、毎日、毎週）実行することができ、装置の変更（例えば、装置の場所の変更）に応じて実行することができ、および／またはユーザ入力に応じて実行することができる。図１を参照して、例えば、新しい歌曲を表すデータをグローバル歌曲データベース１２０に追加することができる。それに応じて、参照歌曲データ１１８は、コンピューティング装置１００に提供され、装置上参照歌曲データベース１１６に格納される。別の例として、コンピューティング装置１１０の位置を変更することができる。それに応じて、コンピューティング装置１１０の現在位置に関連する参照歌曲データ１１８は、装置上参照歌曲データベース１１６に提供され、格納される。別の例として、コンピューティング装置１１０のユーザは、最新の参照歌曲データ１１８を装置上参照歌曲データベース１１６に保存する要求をトリガーするための特定の入力をサーバシステム１５０に提供することができる。
FIG. 5 illustrates an exemplary process for receiving and storing reference song data. In general, this process can be performed periodically (eg, daily, weekly), can be performed in response to device changes (eg, device location changes), and/or can be based on user input. can be executed according to Referring to FIG. 1, for example, data representing new songs may be added to the
ボックス５０２において、コンピューティング装置は、リモートコンピューティングシステムから参照歌曲特徴データを受信する。再び図１を参照して、コンピューティング装置１００は、例えば、サーバシステム１５０から参照歌曲データ１１８を受信する。サーバシステム１５０は、グローバル歌曲データベース１２０から、参照歌曲データ１１８によって表される歌曲を選択することができる。例えば、サーバシステム１５０は、歌曲選別プロセス１２２を用いて、装置の位置、装置ユーザの音楽趣味および他の関連要素に基づいて、コンピューティング装置１００に送信する特定の歌曲セットを選択することができる。
At
歌曲の参照歌曲特徴データは、歌曲の特徴を決定するためのデータを含む。このデータは、ニューラルネットワークを用いて、歌曲に含まれる一連の時間窓の各々の特徴ベクトルセットを生成する歌曲特徴プロセスによって生成される。一般的に、歌曲の特徴ベクトルセットを生成するプロセスは、（例えば、高速フーリエ変換（ＦＦＴ）アルゴリズムを用いて）歌曲のデジタル音声を時間領域形式から周波数領域形式に変換することと、周波数領域形式のデータをニューラルネットワークに提供することによって、歌曲の識別特徴（fingerprint）を生成する。歌曲の識別特徴は、例えば、歌曲に含まれた各々の２秒窓の９６個の特徴ベクトルセットを含むことができる。 Reference song feature data for a song includes data for determining features of the song. This data is generated by a song feature process that uses a neural network to generate a set of feature vectors for each of a series of time windows contained in the song. In general, the process of generating a feature vector set for a song consists of transforming the digital audio of the song from a time-domain format to a frequency-domain format (e.g., using a Fast Fourier Transform (FFT) algorithm); data to a neural network to generate a fingerprint of the song. The identifying features of a song can include, for example, a set of 96 feature vectors for each 2-second window included in the song.
いくつかの例において、各々の特徴ベクトルに対して、平滑化プロセスを実行することができる。これによって、先行および／または後続の時間窓に対応する特徴ベクトル値に基づいて、所定の時間窓の特定の特徴ベクトル値を調整することができる。例えば、
平滑化された値［ｔ］＝
１×値［ｔ－２］＋
３×値［ｔ－１］＋
４×値［ｔ］＋
３×値［ｔ＋１］＋
１×値［ｔ＋２］
いくつかの例において、特徴ベクトル値は、浮動値から二進値に変換することができる。例えば、特徴ベクトル値は、ゼロ平均値に分布されている正値および負値を含むことができる。例えば、各特徴ベクトル値を平滑化した後、これらの値を二進値に変換して、正値を真（例えば、１）にマッピングし、ゼロおよび負値を偽（例えば、－１）にマッピングすることができる。いくつかの例において、平滑化された値［ｔ］は、特定の特徴ベクトルの各値に対して生成される。例えば、特徴ベクトル値を二値化および平滑化することによって、各歌曲のコンパクトな識別特徴を生成することができる。
In some examples, a smoothing process can be performed on each feature vector. This allows adjustment of a particular feature vector value for a given time window based on feature vector values corresponding to preceding and/or subsequent time windows. for example,
Smoothed value [t] =
1 x value [t-2] +
3 x value [t-1] +
4 x value [t] +
3 x value [t+1]+
1 x value [t+2]
In some examples, the feature vector values can be converted from float values to binary values. For example, the feature vector values can include positive and negative values that are distributed with a zero mean value. For example, after smoothing each feature vector value, convert these values to binary values, mapping positive values to true (e.g., 1) and zero and negative values to false (e.g., -1). can be mapped. In some examples, a smoothed value [t] is generated for each value of a particular feature vector. For example, by binarizing and smoothing the feature vector values, compact identifying features for each song can be generated.
ボックス５０４において、複数の参照歌曲の中の各参照歌曲の複数の音声特徴を識別する参照歌曲特徴データを格納する。図４を参照して、参照歌曲特徴データ（例えば、図１に示された参照歌曲データ１１８）は、装置上歌曲データベース４０４に格納されてもよい。
At
ボックス５０６において、格納された複数の参照歌曲の中の各参照歌曲の参照歌曲特徴データは、複数の音声特徴に対応する複数の参照歌曲特徴値を含む。本実施例において、歌曲の各２秒窓は、９６個の歌曲特徴値に関連し、各々の歌曲特徴値は、異なる音声特徴に対応する。
At
ボックス５０８において、格納された複数の参照歌曲の中の全ての参照歌曲の参照歌曲特徴データは、同じ量の音声特徴を有する。本実施例において、各歌曲は、９６個の音声特徴を有する。 ボックス５１０において、複数の参照歌曲の全ての参照歌曲の参照歌曲特徴値は、二進値１または二進値０である（すなわち、各値は、二進値１または二進値０に限定される）。本実施例において、各歌曲および歌曲の各２秒窓の各歌曲特徴には、二進値１または二進値０が割り当てられる。
At
ボックス５１２において、複数の参照歌曲は、少なくとも１万曲の参照歌曲を含み、参照歌曲特徴データは、少なくとも１万曲の参照歌曲の音声特徴を識別する。各々の歌曲がコンパクトでありながら詳細な識別特徴を有するため、例えば、装置上歌曲データベース４０４に大量の参照歌曲の識別特徴データを保存することができる。
At
図６Ａおよび６Ｂは、例示的なコンピューティング装置の現在環境に再生されている歌曲を識別するための例示的なプロセスを示す図である。一般的に、このプロセスは、（図３Ａおよび３Ｂを参照して上述したように）検出された周囲音声に音楽が含まれているという判断に応じて、コンピューティング装置によって自動的に開始されてもよい。例えば、（図１に示された）コンピューティング装置１００は、（図１に示された）低電力プロセッサ１０４を用いて、可能な音楽を検出するための環境内の周囲音声を継続的に監視し、音楽が検出された場合のみ、コンピューティング装置１００は、（図１に示された）高電力プロセッサ１１０を用いて、複数の参照歌曲から、再生されている特定の歌曲を識別することができる。
6A and 6B illustrate an exemplary process for identifying songs currently playing in the current environment of an exemplary computing device. Typically, this process is automatically initiated by the computing device in response to a determination that the detected ambient sounds include music (as described above with reference to FIGS. 3A and 3B). good too. For example, computing device 100 (shown in FIG. 1), using low-power processor 104 (shown in FIG. 1), continuously monitors ambient sounds in the environment to detect possible music. However, only if music is detected,
ボックス６０２において、音声を解析するための命令を受信する。例えば、（図２に示された、図１の低電力プロセッサ１０４と同様の）低電力プロセッサ２０２は、デジタル音声データが音楽を表すという判断に応じて、音声２２２を解析するための命令を（図４に示された、図１の高電力プロセッサ１１０と同様の）高電力プロセッサ４０２に提供することができる。
At
ボックス６０４において、音声を解析するための命令を受信することは、対応するデジタル音声２２４を受信することを含むことができる。例えば、対応するデジタル音声２２４は、（図２に示された）デジタル音声バッファ２０６のコンテンツの一部または全てを含むことができる。本実施例において、対応するデジタル音声２２４は、記録および変換された時間領域形式のデジタル音声データの過去の８秒を含む。このデジタル音声データは、低電力プロセッサ１０４が音楽が再生されているという判断を行うときに基づいた音声コンテンツと少なくとも同様であってもよい。
At
ボックス６０６において、コンピューティング装置は、デジタル音声データが複数の参照歌曲の中の特定の参照歌曲を表すことを認識する。例えば、高電力プロセッサ４０２は、対応するデジタル音声２２４が、装置上歌曲データベース４０４内の歌曲のいずれかの参照歌曲特徴データと一致するか否かを判断することができる。
At
ボックス６０８において、デジタル音声データが特定の参照歌曲を表すことを認識することは、第２周波数領域変換プロセスにおいて、デジタル音声データを時間領域形式から第２周波数領域形式に変換することと、変換されたデジタル音声データをバッファに格納することとを含むことができる。例えば、高電力プロセッサ４０２は、対応するデジタル音声２２４を時間領域形式から第２周波数領域形式に変換する周波数変換プロセス４０８を実行することができる。例えば、高電力プロセッサ４０２は、特定の間隔（４６ミリ秒の間隔、６９ミリ秒の間隔、９２ミリ秒の間隔）で、特定の長さのサンプリング窓（例えば、９２ミリ秒のサンプリング窓、１３８ミリ秒のサンプリング窓、１８４ミリ秒のサンプリング窓、または別の適切な長さのサンプリング窓）を用いて、対応するデジタル音声２２４に対して周波数変換プロセス４０８を実行することができる。各サンプリング窓において、周波数変換プロセス４０８は、対応するデータフレーム（例えば、データフレーム４１０）を出力する。このデータフレームは、特定数の周波数ビン（例えば、２５６ビン、５１２ビン、１０２４ビン、または別の適切な数の周波数ビン）に対応するデータ値を含み、各周波数ビンは、周波数範囲に関連する。各ビンの値は、サンプリング期間中に周波数範囲内の音声強度を表す。いくつかの例において、周波数変換プロセス４０８は、高速フーリエ変換（ＦＦＴ）アルゴリズムを用いて、サンプリングされたデジタル音声データの一部を時間領域形式から第２周波数領域形式のデータフレームに変換することができる。生成された各データフレームは、例えば、高電力プロセッサ４０２によって、一連の周波数サンプルバッファ４１２に格納されてもよい。
At
ボックス６１０において、異なる数の周波数ビンを解析するための第２周波数領域形式および第１周波数領域形式を生成するプロセスによって、第２周波数領域形式は、第１周波数領域形式とは異なる。ビンを計算する周波数範囲（例えば、各ビンを得るために、解析された周波数の幅および／または周波数の全幅）は、第２周波数領域形式と第１周波数領域形式との間で異なってもよい。本実施例に示されたように、（図４に示された）高電力プロセッサ４０２によって実行され、音声周波数に対して一連の比較的高い解像度のデータフレーム（例えば、２５６個の周波数ビンを有するデータフレーム）を生成する周波数変換プロセス４０８に比べて、（図２に示された）低電力プロセッサ２０２によって実行された周波数変換プロセス２０８は、音声周波数に対して一連の比較的低い解像度のデータフレーム（例えば、１６個の周波数ビンを有するデータフレーム）を生成する。また、サンプリングレートは、２つの周波数変換プロセスの間に異なる場合がある。本実施例に示されたように、高電力プロセッサ４０２によって実行され、比較的長い時間窓（例えば、１８４ミリ秒）を有する一連のデータフレームを生成する周波数変換プロセス４０８に比べて、低電力プロセッサ２０２によって実行された周波数変換プロセス２０８は、比較的短い時間窓（例えば、５０ミリ秒）を有する一連のデータフレームを生成する。
At
ボックス６１２において、第２周波数領域形式のデジタル音声データは、第２周波数領域形式の音声データを受信する音楽特徴決定プロセスに提供される。例えば、高電力プロセッサ４０２は、周波数サンプルバッファ４１２を受信し、バッファに対して音楽特徴決定プロセス４１６を実行することができる。音楽特徴決定プロセス４１６は、１秒の間隔でサンプリングされた２秒窓上でバッファを処理する。本実施例において、歌曲特徴決定プロセス４０６は、各々の２秒窓に対して９６個の歌曲特徴セット（例えば、特徴ベクトルまたは９６個の値）を出力するため、８秒の周波数サンプルバッファ４１２に対して７セットの９６個の歌曲特徴を生成する。いくつかの例において、音楽特徴決定プロセス４０６は、１２８個の歌曲特徴セットを出力する。様々な例において、窓間の間隔は、０．５秒または１秒である。
At
ボックス６１４において、音楽の特徴を決定するように訓練された機械学習システムを用いて、音楽特徴決定プロセスを実行することができる。例えば、歌曲特徴セットを生成するために、音楽特徴決定プロセス４１６は、オフラインで（例えば、以前にサーバシステム１５０で）訓練され、高電力プロセッサ４０２に提供された機械学習モデルを参照することができる。機械学習モデルを用いて、音楽の前後セクションの歌曲特徴セットと共に、歌曲の周波数サンプリング窓（例えば、２秒窓）から将来に使用可能な歌曲特徴セット（例えば、特徴ベクトル）を生成することによって、歌曲を鑑別または識別することができる。いくつかの例において、機械学習モデルは、高電力プロセッサ４０２上で動作する小さな量子化重畳型ニューラルネットワークであってもよい。
At
ボックス６１６において、デジタル音声データの複数の特徴値を出力することができる。例えば、歌曲特徴決定プロセス４１６の出力（例えば、８秒間の周波数サンプルバッファ４１２の７セットの９６個の歌曲特徴）は、現在歌曲特徴４１８として装置のメモリに記憶および／または保存することができる。各歌曲特徴は、浮動値（例えば、０．４４３などの実数値）で表される。
At
ボックス６１８において、デジタル音声データの複数の特徴値の二進表現を参照歌曲の複数の特徴値と比較することによって、複数の候補歌曲を選択する。選択された候補歌曲は、周囲音声の特徴値の二進表現に関連するまたは一致する歌曲である。例えば、高電力プロセッサ４０２は、候補識別プロセス４２０を実行することができる。候補識別プロセス４２０は、現在歌曲特徴４１８の一部または全てを受信し、装置上歌曲データベース４０４から参照された歌曲の音声特徴（例えば、特徴ベクトル）の一部または全てを受信し、比較することによって、一致する可能性がある複数の歌曲を識別する。本実施例において、候補識別プロセス４２０は、現在歌曲特徴４１８から一部の特徴（例えば、９６個の特徴から４８個の特徴）を選択し、各々の２秒窓に対応する値（例えば、７組の４８個値）を受信し、各値を浮動値から二進値に変換する。また、候補識別プロセス４２０は、装置上歌曲データベース４０４に保存された歌曲の各々に対応する４８個の音声特徴の各々の二進値を受信する。
At
いくつかの例において、コンピューティング装置は、２秒歌曲特徴の窓が順番上に一致するか否かを考慮せず、各２秒間の現在歌曲特徴セットと各２秒間の参照歌曲特徴セットとを比較する。例えば、この比較は、現在歌曲特徴セットおよび参照歌曲特徴セットの連続性を考慮せず、各セットの現在歌曲特徴と他のセットの参照歌曲特徴との間のハミング距離を特定する。したがって、現在歌曲の８秒間の全てのバッファデータが対応する参照歌曲の８秒間のバッファデータと一致しなくても、現在歌曲の１つ以上の２秒窓のデータが参照歌曲の１つ以上の２秒窓のデータと一致した場合、コンピューティング装置は、参照歌曲をマッチング候補として特定することができる。 In some examples, the computing device may combine each two-second current song feature set and each two-second reference song feature set without considering whether the windows of two-second song features match in order. compare. For example, this comparison does not consider the continuity of the current song feature set and the reference song feature set, but identifies the Hamming distance between each set of current song features and the other set of reference song features. Therefore, even if all the current song's 8-second buffer data does not match the corresponding reference song's 8-second buffer data, the current song's one or more 2-second windows of data may not match one or more of the reference song's buffer data. If there is a match with the two-second window of data, the computing device can identify the reference song as a candidate match.
いくつかの例において、参照歌曲に重みを付ける。これによって、全体としてより人気である（または特定のユーザに関連する基準、例えば、上述した地理位置、傾聴好みにより関連している）と判断された歌曲は、一致する可能性のある歌曲として特定される可能性が高くなる。 In some examples, the reference songs are weighted. Songs that are determined to be more popular overall (or more related to criteria relevant to a particular user, e.g., geolocation, listening preferences as discussed above) are thereby identified as potential matches. more likely to be
図７を参照して、コンピューティング装置によって実行された例示的な候補識別プロセス（例えば、候補識別プロセス４２０）の概念図が示されている。図７に示されたように、現在歌曲特徴４１８は、（図４に示された）周波数サンプルバッファ４１２の各サンプリング窓の歌曲特徴セットを含み、各サンプリング窓は、隣接するサンプリング窓と部分的に重なり合う。本実施例において、現在歌曲の特徴は、０～２秒のバッファ部分の特徴セット７０２ａ、１～３秒のバッファ部分の特徴セット７０２ｂ、２～４秒のバッファ部分の特徴セット７０２ｃ、３～５秒のバッファ部分の特徴セット７０２ｄ、４～６秒のバッファ部分の特徴セット７０２ｅ、５～７秒のバッファ部分の特徴セット７０２ｆ、および６～８秒のバッファ部分の特徴セット７０２ｇを含む。比較７０４は、高電力プロセッサ４０２（図４に示す）によって実行され、全ての歌曲に対して、現在歌曲の各特徴セットを参照歌曲の各特徴セットと比較することを含む。例えば、全ての歌曲に対して、現在歌曲の連続的な特徴セット７０２ａ～７０２ｇは、同じセット数（例えば、７）を有する参照歌曲の連続的な特徴セットと各々比較される。本実施例において、現在歌曲の７つの連続的な特徴セット７０２ａ～７０２ｇは、参照歌曲＃１の７つの連続的な特徴セットと比較される。この比較は、参照セット７１２ａ（例えば、０～２秒間の歌曲の特徴）から始まり、参照セット７１２ｂ（例えば、１～３秒の歌曲の特徴）、参照セット７１２ｃ（例えば、２～４秒の歌曲の特徴）、参照セット７１２ｄ（例えば、３～５秒の歌曲の特徴）、以下同様、６～８秒のバッファ部分の現在歌曲の特徴セット７０２ｇが参照歌曲の最後の２秒間の歌曲の特徴セット７１２ｎと比較されるまで実行される。
Referring to FIG. 7, a conceptual diagram of an exemplary candidate identification process (eg, candidate identification process 420) performed by a computing device is shown. As shown in FIG. 7, the current song features 418 include a set of song features for each sampling window of the frequency sample buffer 412 (shown in FIG. 4), where each sampling window is partially aligned with an adjacent sampling window. overlaps. In this example, the features of the current song are 0-2 second buffer portion feature set 702a, 1-3 second buffer portion feature set 702b, 2-4 second buffer portion feature set 702c, 3-5 It includes a second buffer portion feature set 702d, a 4-6 second buffer portion feature set 702e, a 5-7 second buffer portion feature set 702f, and a 6-8 second buffer
いくつかの例において、現在歌曲の各特徴セットを参照歌曲の各特徴セットと比較することは、現在歌曲の連続的な特徴セットの各特徴セットと同じセット数（例えば、７）を有する参照歌曲の連続的な特徴セットの各特徴セットとの間のハミング距離を計算することを含み得る。例えば、ハミング距離を合計することによって、特定のオフセット位置にある特定の参照歌曲のスコアを計算することができる。特定のオフセット位置にある特定の参照歌曲が閾値を満たすスコアを有する場合（例えば、スコアが閾値よりも低い場合）、その歌曲を一致する可能性のある歌曲として特定し、候補歌曲リストに追加することができる。さらなる処理を容易にするように、参照歌曲と関連するオフセット位置との情報を（例えば、メモリに）保存することができる。 In some examples, comparing each feature set of the current song to each feature set of the reference song includes matching the reference song with the same number of sets (e.g., 7) as each feature set of the continuous feature sets of the current song. , and computing the Hamming distance between each of the successive feature sets. For example, the score for a particular reference song at a particular offset can be calculated by summing the Hamming distances. If a particular reference song at a particular offset has a score that meets a threshold (e.g. if the score is lower than the threshold), identify that song as a potential match and add it to the candidate song list. be able to. Information about the reference song and the associated offset location can be saved (eg, in memory) to facilitate further processing.
いくつかの例において、候補識別プロセス４２０は、解析木を実行することを含む。解析木において、現在歌曲の特徴（二進値）は、解析木の入力として提供され、候補歌曲は、参照歌曲の特徴値に応じて解析木の枝に位置する。したがって、高電力プロセッサ１１０は、現在歌曲の特徴を、装置上歌曲データベース１１６内の全ての参照歌曲の全ての特徴と比較せず、解析木に移動して、現在歌曲の特徴を有するゼロ以上の候補歌曲を特定する。
In some examples, the
ボックス６２０において、デジタル音声データの複数の特徴値を、複数の参照歌曲の中の少なくとも一部の候補歌曲の各歌曲の複数の特徴値と比較する。再び図４を参照して、例えば、高電力プロセッサ４０２は、歌曲識別プロセス４２２を実行することによって、候補歌曲のリスト（例えば、百曲の歌曲）から１つの一致する歌曲（または一致しない歌曲）を特定することができる。いくつかの例において、ボックス６２０の操作は、ボックス６１８で識別された候補歌曲セットに対して実行される。いくつかの例において、ボックス６２０の操作は、候補歌曲セットを予め識別することなく実行されてもよい。
At
ボックス６２２において、デジタル音声データの特徴値を複数の参照歌曲の少なくとも一部の歌曲の中の各歌曲の複数の特徴値と比較することは、（ａ）実数であるデジタル音声データの特徴値と、（ｂ）二進値０および二進値１に限定された複数の歌曲の少なくとも一部の歌曲の中の各歌曲の特徴値との比較を含む。例えば、歌曲識別プロセス４２２は、現在歌曲特徴４１８の一部または全てを受信することができ、装置上歌曲データベース４０４に保存され且つ候補歌曲リストに含まれた歌曲の音声特徴（例えば、特徴ベクトル）の一部または全てを受信することができる。例えば、現在歌曲特徴４１８の特徴値の各々は、浮動値であり得るが、装置上歌曲データベース４０４に保存された歌曲の特徴値の各々は、二進値であってもよい。
In box 622, comparing the feature values of the digital audio data to the plurality of feature values of each song in the songs of at least a portion of the plurality of reference songs includes (a) the feature values of the digital audio data that are real numbers; , (b) comparing the feature values of each song in at least a portion of the plurality of songs limited to binary 0's and binary 1's. For example, the
いくつかの例において、デジタル音声データの特徴値を参照歌曲の特徴値と比較することは、全ての歌曲特徴よりも少ない特徴の比較を含むことができる。例えば、候補歌曲リスト内の候補歌曲を選別するために、歌曲識別プロセス４２２は、以前に識別されたオフセット位置にある各参照歌曲のスコアを再計算することを含むことができる。例えば、スコアを再計算することは、非対称二進値距離（例えば、現在歌曲の特徴の二進値と対応する参照歌曲の特徴の浮動値との間の余弦距離、偽＝－１および真＝１）を計算することを含むことができる。本実施例において、選別プロセスは、９６個の特徴のうち４８個の特徴を使用することができる。特定のオフセット位置にある特定の参照歌曲のスコアが閾値を満たさない場合（例えば、スコアが閾値以上である場合）、その歌曲を候補歌曲リストから削除することができる。
In some examples, comparing the feature values of the digital audio data to the feature values of the reference song may involve comparing fewer than all song features. For example, to screen candidate songs in the candidate song list, the
いくつかの例において、デジタル音声データの特徴値を参照歌曲の特徴値と比較することは、全ての歌曲特徴の比較を含むことができる。例えば、候補歌曲リストから１つの一致する歌曲を特定するために（または一致する歌曲が存在しないことを判断するために）、歌曲識別プロセス４２２は、以前に識別されたオフセット位置にある各参照歌曲のスコアを再計算することを含むことができる。例えば、スコアを再計算することは、全ての９６個の特徴の非対称二進値距離（例えば、現在歌曲の特徴の二進値と対応する参照歌曲の特徴の浮動値との間の余弦距離、偽＝－１および真＝１）を計算することを含むことができ、様々な適応スコアリング手法を含むことができる。別の例として、歌曲識別プロセス４２２は、候補参照歌曲の各々の類似度マップ４２４を用いて、対角線に沿ってスコアを計算することによって、スコアを再計算することができる。別の例として、歌曲識別プロセス４２２は、比較解析木を用いて、スコアを再計算することができる。
In some examples, comparing the feature values of the digital audio data to the feature values of the reference song can include comparing all song features. For example, to identify one matching song from the candidate song list (or to determine that there are no matching songs), the
ボックス６２４において、デジタル音声データの特徴値を複数の参照歌曲の少なくとも一部の歌曲の中の各歌曲の複数の特徴値と比較することは、関連するデータを要求するためのリクエストをリモートコンピューティング装置に送信せず、コンピューティング装置上の複数の歌曲の少なくとも一部の歌曲の中の各歌曲の複数の特徴値にアクセスすることによって実行される。例えば、装置上歌曲データベース４０４は、数万曲の歌曲のコンパクトな識別特徴を含むことができるため、モバイル装置からサーバに識別するための音声データを送信する必要なく、モバイル装置上で歌曲を識別することができる。モバイル装置上で歌曲を識別することによって、歌曲の識別を迅速に実行することができ、ネットワーク接続が利用できない状況にも実行することができる。また、モバイル装置からサーバに音声データを送信する必要なく、歌曲の識別を実行することによって、ユーザのプライバシーを維持することができる。
At box 624, comparing the feature values of the digital audio data to the plurality of feature values for each song in at least a portion of the plurality of reference songs sends a request to the remote computing device for the associated data. It is performed by accessing a plurality of feature values for each song in at least a portion of the plurality of songs on the computing device without transmission to the device. For example, the on-
いくつかの例において、候補歌曲のスコアを計算することは、現在歌曲のデータのバッファの全体が対応する候補歌曲のデータのバッファの全体と一致する程度を説明することができる。現在歌曲のバッファが８秒であり、７つの２秒窓のデータを含む例において、これらの７つの２秒窓のデータと、候補歌曲の７つの２秒窓のデータと順次に一致する程度が、計算された候補歌曲のスコアに影響を与える可能性がある。他の例において、バッファ全体が互いに一致する必要はないが、順次に一致した数は、計算された候補歌曲のスコアに影響を与える可能性がある。 In some examples, calculating a score for a candidate song may describe the extent to which the entire buffer of data for the current song matches the entire buffer of data for the corresponding candidate song. In an example where the buffer of the current song is 8 seconds and contains data for seven 2-second windows, the degree to which these seven 2-second windows of data sequentially match the data of the seven 2-second windows of the candidate song is , can influence the calculated candidate song score. In other examples, the entire buffer need not match each other, but the number of matches in sequence can affect the calculated candidate song score.
いくつかの例において、参照歌曲に重みを付ける。これによって、全体としてより人気である（または特定のユーザに関連する基準、例えば、地理位置、傾聴好みにより関連している）と判断された歌曲は、一致する歌曲として特定される可能性が高くなる。 In some examples, the reference songs are weighted. Songs determined by this to be more popular overall (or more relevant to criteria relevant to a particular user, e.g., geolocation, listening preferences) are more likely to be identified as matching songs. Become.
ボックス６２６において、特定の参照歌曲の複数の特徴値がデジタル音声データの複数の特徴値に最も関連していることを判断する。例えば、歌曲識別プロセス４２２は、計算されたスコアに従って、残りの候補歌曲の各々にランキングを付けることができ、全ての残りの候補歌曲のうち、特定の候補歌曲が最も高いランキングを有し且つ特定の候補歌曲のスコアが閾値を満たす場合、特定の候補歌曲を、現在歌曲特徴４１８と一致する歌曲特徴を有する歌曲として識別することができる。例えば、候補歌曲のいずれも閾値を満たすスコアを有しない場合、歌曲識別プロセスは、現在歌曲特徴４１８と一致する歌曲特徴を有する歌曲として識別しない。軽量化プロセスを用いて大量の歌曲を比較的少量の候補歌曲に選別処理した後、より計算集約的なプロセスを用いて少量の候補歌曲から一致する歌曲を識別する２段階で歌曲の識別を実行することによって、処理リソースを節約しながら、一致する歌曲を迅速且つ正確に識別することができる。
At
ボックス６２８において、特定の参照歌曲の複数の特徴値がデジタル音声データの複数の特徴値に最も関連しているという判断に応答して、コンピューティング装置は、特定の参照歌曲が再生されていることを示す表記を出力する。例えば、歌曲識別プロセス４２２は、識別された歌曲を示す表記４３０を出力することができる。
At
ボックス６３０において、特定の参照歌曲が再生されていることを示す表記を出力することは、ユーザ入力によって歌曲識別プロセスを実行するようにコンピューティング装置を促すことなく、少なくとも数時間前（例えば、少なくとも４時間前、少なくとも数日前、または少なくとも１か月前）に連続した歌曲識別プロセスを有効にすることによって、コンピューティング装置のロック画面に特定の参照歌曲の名前を提示することを含む。図８を参照して、例えば、（図１に示された）コンピューティング装置１００のロック画面上に表示される例示的なユーザインターフェイス８００を示している。例えば、ユーザインターフェイス８００は、現在識別された歌曲の視覚表記８０２を含む。視覚表記８０２は、歌曲に関連するテキスト情報、例えば、歌曲の曲名、歌手の名前、アルバム名および他の関連情報を含むことができる。いくつかの例において、特定の参照歌曲が再生されていることを示す表記を出力することは、特定の参照歌曲を特定するための音声を再生することを含むことができる。例えば、音声は、歌曲の曲名、歌手の名前、アルバム名およびその他の関連情報を告知することができる。
At
ボックス６３２において、特定の参照歌曲が再生されていることを示す表記を出力することは、ユーザ入力によって歌曲識別プロセスを実行するようにコンピューティング装置を促すことなく、少なくとも数時間前（例えば、少なくとも４時間前、少なくとも数日前、または少なくとも１か月前）に連続した歌曲識別プロセスを有効にすることによって、コンピューティング装置のロック解除画面の通知パネルに特定の参照歌曲の名前を提示することを含む。コンピューティング装置１００は、例えば、最近再生された過去の１つ以上の歌曲および／または前日の同じ時間に再生された歌曲の履歴情報を表示することもできる。再び図８を参照して、例えば、例示的なユーザインターフェイス８１０は、（図１に示された）コンピューティング装置１００のロック解除画面の通知パネル８１２に特定の参照歌曲の名前を提示する。例えば、通知パネル８１２は、現在識別された歌曲に関連するテキスト情報、例えば、歌曲の曲名、歌手の名前、アルバム名および他の関連情報を含む通知を提示することができる。コンピューティング装置１００は、通知を（例えば、プルダウンメニューではなく）ポップアップダイアログボックスに提示することができ、通知を変化テキストとして装置ホーム画面のバックグラウンドディスプレイに提示することもできる。
At
いくつかの例において、ユーザと提示された歌曲識別制御との相互作用は、コンピューティング装置に、識別された歌曲に関する１つ以上の動作を実行させることができる。例えば、ユーザとユーザインターフェイス８００の視覚表記８０２との相互作用８０４（例えば、タッチ入力）またはユーザとユーザインターフェイス８１０の通知パネル８１２との相互作用８１４（例えば、タッチ入力）に応じて、（図１に示された）コンピューティング装置１００は、現在識別された歌曲および以前に識別された歌曲のさらなる情報（例えば、発売年、歌詞、アルバムカバーの画像、関連するウェブコンテンツへのリンク）および／または利用可能なオプションを表示させるインターフェイス８２０を提示することができる。本実施例において、インターフェイス８２０は、再生制御８２２、視聴制御８２４、および以前に識別された歌曲のリスト８２６を含む。例えば、ユーザによる再生制御８２２の選択に応じて、現在識別された歌曲をコンピューティング装置１００で再生することを開始することができる。例えば、ユーザによる視聴制御８２４の選択に応答して、コンピューティング装置１００は、現在識別された歌曲のビデオを再生することができる。例えば、以前に識別された歌曲のリスト８２６内の歌曲の選択に応答して、コンピューティング装置１００は、選択された歌曲のオプションおよび／または追加情報を提示することができる。
In some examples, interaction of the user with the presented song identification control can cause the computing device to perform one or more actions with respect to the identified song. For example, in response to user interaction 804 (eg, touch input) with
いくつかの例において、歌曲識別プロセスの主要部分または全ては、クライアント側ではなくサーバ側で実行される。このような例において、サーバ側のコンピューティングシステムは、歌曲の特徴データをクライアント装置に送信せず、代わりに、クライアント装置で記録された音声から生成された音声データまたは歌曲の特徴データをクライアント装置から受信し、歌曲の識別を実行することができる。例えば、サーバ側のコンピューティングシステムは、ボックス６０２～６２６の操作を実行し、一致があった場合、サーバ側のコンピューティングシステムは、（例えば、ボックス６２８～６３２で説明したように）一致する歌曲を識別する情報を送信し、音声を録音したクライアント装置によって提示される。このような例において、サーバ側のコンピューティングシステムは、（例えば、ボックス３０８～３２６で説明したように）音楽が再生されているか否かを判断するための操作を実行する必要がない。これによって、歌曲を含まないと判断された音声の処理を回避することができる。また、ユーザが歌曲の識別を明確に要求した場合に、サーバ側のコンピューティングシステムは、音声を解析することができる。この場合、「音楽が再生されているか否か」を判断する操作をスキップして、単に「どの歌曲が再生されているか」を判断する操作を実行することは、合理的である。すなわち、音楽判断プロセスは、オプションであり、音楽判断プロセスおよび歌曲識別プロセスの両方をクライアント側またはサーバ側で実行することができ、または、一方をクライアントで実行し、他方をサーバで実行することもできる。 In some examples, a major portion or all of the song identification process is performed on the server side rather than the client side. In such an example, the server-side computing system does not send the song feature data to the client device, but instead sends audio data generated from audio recorded on the client device or song feature data to the client device. and perform song identification. For example, the server-side computing system performs the operations in boxes 602-626, and if there is a match, the server-side computing system creates a matching song (eg, as described in boxes 628-632). presented by the client device that transmitted the information identifying the and recorded the audio. In such an example, the server-side computing system need not perform operations to determine whether music is playing (eg, as described in boxes 308-326). This can avoid processing audio that is determined not to contain a song. The server-side computing system can also parse the audio if the user specifically requests the identification of the song. In this case, it would be reasonable to skip the operation of determining "whether music is playing" and simply perform the operation of determining "what song is playing". That is, the music determination process is optional and both the music determination process and the song identification process can be performed on the client side or the server side, or one can be performed on the client and the other on the server. can.
図９を参照して、本明細書に記載されたシステムおよび方法を実施する例示的なシステムの概念図を示している。このシステムにおいて、モバイルコンピューティング装置９１０は、基地局９４０と無線通信することができる。基地局９４０は、ネットワーク９５０を介して、多くのホストサービス９６０への無線アクセスをモバイルコンピューティング装置に提供することができる。
Referring to FIG. 9, a conceptual diagram of an exemplary system for implementing the systems and methods described herein is shown. In this system,
この図において、モバイルコンピューティング装置９１０は、モバイルコンピューティング装置９１０のユーザにコンテンツを提示し、ユーザからタッチベース入力を受け取るためのタッチスクリーン式ディスプレイ装置９１２を含む携帯式モバイル電話（例えば、スマートフォンまたはアプリケーション電話）として示されている。他の視覚的出力要素、触覚的出力要素および聴覚的出力要素（例えば、ＬＥＤライト、触覚出力用の振動機構、または音色出力、音声生成または録音出力を提供するためのスピーカ）ならびに様々な異なる入力要素（例えば、キーボード９１４、物理ボタン、トラックボール、加速度計、ジャイロスコープ、磁力計）を設けることもできる。
In this illustration, a
ディスプレイ装置９１２の形にした例示的な視覚的出力メカニズムは、抵抗性または容量性タッチ機能を備えたディスプレイであってもよい。表示装置は、ビデオ、グラフィックス、画像およびテキストを表示することができ、ユーザのタッチ入力位置を情報表示位置に合わせて調整することができる。したがって、装置９１０は、表示されたアイテムの位置に対するユーザのタッチをそのアイテムに関連付けることができる。代替的に、モバイルコンピューティング装置９１０は、ラップトップコンピュータ、タブレットまたはスレートコンピュータ、携帯情報端末、組込みシステム（例えば、カーナビシステム）、デスクトップパーソナルコンピュータ、またはコンピュータワークステーションであってもよい。
An exemplary visual output mechanism in the form of
ユーザ入力を受信するための例示的なメカニズムは、キーボード９１４を含む。キーボード９１４は、標準のQWERTYキーボードであってもよく、数字「０～９」、「＊」および「＃」キーを含む従来のキーパッドであってもよい。ユーザがキーボードのキーを物理的に接触または押下したときに、キーボード９１４は、入力を受け取る。ユーザは、トラックボール９１６を操作するまたはトラックパッドと相互作用することによって、（例えば、ディスプレイ装置９１２上のカーソルの位置を操作する）動作の方向および速度情報をモバイルコンピューティング装置９１０に提供することができる。
An exemplary mechanism for receiving user input includes
モバイルコンピューティング装置９１０は、タッチスクリーン式ディスプレイ装置９１２との物理的接触の位置（例えば、指またはスタイラスによる接触の位置）を判断することができる。タッチスクリーン９１２を用いて、様々な「仮想」入力メカニズムを生成することができる。この場合、ユーザは、グラフィカルユーザインターフェイス要素に接触することにより、タッチスクリーン９１２に示されたグラフィカルユーザインターフェイス要素と対話する。「仮想」入力メカニズムの例は、「ソフトウェアキーボード」である。この場合、キーボードは、タッチスクリーンに表示され、ユーザは、各キーに対応するタッチスクリーン９１２の領域を押すことでキーを選択する。
モバイルコンピューティング装置９１０は、機械式またはタッチ感応式ボタン９１８ａ～９１８ｄを含むことができる。さらに、モバイルコンピューティング装置は、１つ以上のスピーカ９２０による出力音量を調整するためのボタン、およびモバイルコンピューティング装置をオンまたはオフにするためのボタンを含むことができる。モバイルコンピューティング装置９１０は、マイクロフォン９２２を用いて、可聴音を電気信号に変換することができる。変換後の電気信号は、デジタル信号にエンコードされ、コンピュータ可読メモリに保存されるまたは別のコンピューティング装置に送信される。モバイルコンピューティング装置９１０は、デジタルコンパス、加速度計、近接センサ、および周囲光センサを含むこともできる。
オペレーティングシステムは、モバイルコンピューティング装置のハードウェア（例えば、入出力機構、およびコンピュータ可読媒体から取得された命令を実行するプロセッサ）とソフトウェアとの間のインターフェイスを提供することができる。オペレーティングシステムは、例示として、ＡＮＤＲＯＩＤ（登録商標）、ＣＨＲＯＭＥ、ＩＯＳ、ＭＡＣ ＯＳ Ｘ、ＷＩＮＤＯＷＳ（登録商標）７、ＷＩＮＤＯＷＳ ＰＨＯＮＥ ７、ＳＹＭＢＩＡＮ（登録商標）、ＢＬＡＣＫＢＥＲＲＹ（登録商標）、ＷＥＢＯＳ、様々なＵＮＩＸ（登録商標）オペレーティングシステム、またはコンピュータ化装置用の専用オペレーティングシステムを含む。オペレーティングシステムは、コンピューティング装置とユーザとの間の相互作用を容易にするアプリケーションプログラムを実行するためのプラットフォームを提供することができる。 An operating system can provide an interface between the mobile computing device hardware (eg, input/output mechanisms and a processor that executes instructions obtained from computer-readable media) and software. Operating systems include, by way of example, ANDROID®, CHROME, IOS, MAC OS X, WINDOWS® 7, WINDOWS PHONE 7, SYMBIAN®, BLACKBERRY®, WEBOS, various UNIX ( (registered trademark) operating system, or a proprietary operating system for a computerized device. An operating system can provide a platform for executing application programs that facilitate interaction between a computing device and a user.
モバイルコンピューティング装置９１０は、タッチスクリーン９１２を用いて、グラフィカルユーザインターフェイスを形成することができる。グラフィカルユーザインターフェイスは、１つ以上のグラフィカルインターフェイス要素を含み、静的であってもよく（例えば、ディスプレイは、一定の期間に同様である）または動的であってもよい（例えば、グラフィカルユーザインターフェイスは、ユーザ入力なしで動画化するグラフィカルインターフェイス要素を含む）。
グラフィカルインターフェイス要素は、テキスト、線、形状、画像、またはそれらの組み合わせであってもよい。例えば、グラフィカルインターフェイス要素は、デスクトップに表示されるアイコンおよびアイコンに関連するテキストであってもよい。いくつかの例において、グラフィカルインターフェイス要素は、ユーザ入力によって選択可能である。例えば、ユーザは、グラフィカルインターフェイス要素の表示に対応するタッチスクリーンの領域を押すことによって、グラフィカルインターフェイス要素を選択することができる。いくつかの例において、ユーザは、トラックボールを操作することによって、フォーカスを有するように単一のグラフィカルインターフェイス要素を強調表示することができる。ユーザによるグラフィカルインターフェイス要素の選択は、モバイルコンピューティング装置によって事前定義された動作を呼び出すことができる。いくつかの例において、追加的にまたは代替的には、選択可能なグラフィカルインターフェイス要素は、キーボード９０４上のボタンに対応してもよい。ユーザによるボタンの選択は、事前定義された動作を呼び出すことができる。 Graphical interface elements may be text, lines, shapes, images, or combinations thereof. For example, the graphical interface elements may be icons displayed on the desktop and text associated with the icons. In some examples, graphical interface elements are selectable by user input. For example, a user can select a graphical interface element by pressing an area of the touch screen corresponding to the representation of the graphical interface element. In some examples, the user can highlight a single graphical interface element to have focus by manipulating the trackball. Selection of graphical interface elements by a user can invoke actions predefined by the mobile computing device. In some examples, additionally or alternatively, the selectable graphical interface elements may correspond to buttons on keyboard 904 . Selection of a button by a user can invoke a predefined action.
いくつかの例において、オペレーティングシステムは、モバイルコンピューティング装置９１０をオンにした後、スリープ状態からモバイルコンピューティング装置９１０を起動した後、モバイルコンピューティング装置９１０を「ロック解除」した後、またはユーザによって「ホーム」ボタン９１８ｃを選択した後に、「デスクトップ」グラフィカルユーザインターフェイスを形成する。デスクトップグラフィカルユーザインターフェイスは、選択されると対応するアプリケーションプログラムを呼び出すいくつかのグラフィカルインターフェイス要素を表示することができる。呼び出されたアプリケーションプログラムは、終了されるまたは隠されるまで、デスクトップグラフィカルユーザインターフェイスを置換するグラフィカルインターフェイスを形成することができる。
In some examples, the operating system is activated after turning on the
ユーザ入力は、モバイルコンピューティング装置９１０の動作の実行順序に影響を与えることができる。例えば、単一動作のユーザ入力（例えば、タッチスクリーンのシングルタップ、タッチスクリーンのスワイプ、ボタンとの接触、または同時に発生するこれら動作の組み合わせ）は、ユーザインターフェイスの表示を変更する操作を呼び出すことができる。ユーザ入力がない場合、ユーザインターフェイスは、特定の時点で変更されなくてもよい。例えば、マッピングアプリケーションがデフォルトで数秒後にズームインする場合でも、タッチスクリーン９１２に対するマルチタッチユーザ入力は、マッピングアプリケーションを呼び出して、ある位置で「ズームイン」することができる。
User input can affect the execution order of operations on
デスクトップグラフィカルインターフェイスは、「ウィジェット」を表示することもできる。ウィジェットは、実行中のアプリケーションプログラムに関連し、実行中のアプリケーションプログラムによって制御されるデスクトップコンテンツ上に表示される１つ以上のグラフィカルインターフェイス要素である。モバイル装置の電源をオンにすると、ウィジェットのアプリケーションプログラムが起動する場合がある。さらに、ウィジェットは、全画面を占有しなくてもよい。代わりに、ウィジェットは、デスクトップの小さな一部のみを「占有」し、デスクトップのこの部分にコンテンツを表示し、ユーザのタッチスクリーン入力を受け取ることができる。 A desktop graphical interface can also display "widgets." A widget is one or more graphical interface elements that are associated with and displayed on desktop content controlled by a running application program. When the mobile device is powered on, the widget's application program may start. Furthermore, widgets do not have to occupy the entire screen. Instead, widgets can "occupy" only a small portion of the desktop, display content on this portion of the desktop, and receive the user's touchscreen input.
モバイルコンピューティング装置９１０は、１つ以上の位置特定機構を含むことができる。位置特定機構は、モバイル装置の地理位置の推定値をオペレーティングシステムおよびアプリケーションプログラムに提供するためのハードウェアおよびソフトウェアを含むことができる。位置特定機構は、衛星測位技術、基地局送信アンテナ特定、複数の基地局三角測量、インターネットアクセスポイントＩＰ位置決定、検索エンジンクエリに基づくユーザ位置の推定、および（例えば、ユーザから場所の「チェックイン」を受信することによって）ユーザによって提供された位置の特定を使用することができる。
モバイルコンピューティング装置９１０は、他のアプリケーション、コンピューティングサブシステム、およびハードウェアを含むことができる。通話処理ユニットは、着信電話の表示を受信し、着信電話に応答する機能をユーザに提供することができる。ユーザは、メディアプレーヤーを用いて、モバイルコンピューティング装置９１０のローカルメモリに保存されている音楽を聴いたり、映画を再生したりすることができる。モバイルコンピューティング装置９１０は、デジタルカメラセンサ、および対応する画像および動画を取得または編集するためのソフトウェアを含むことができる。ユーザは、インターネットブラウザを用いて、ウェブページに対応するアドレスを入力するまたはウェブページへのリンクを選択することによってウェブページのコンテンツを閲覧することができる。
モバイルコンピューティング装置９１０は、基地局９４０と無線で情報を通信するためのアンテナを含むことができる。基地局９４０は、モバイルコンピューティング装置が地理的に移動しても、モバイルコンピューティング装置９１０とネットワーク９５０との通信を維持する複数の基地局（例えば、携帯電話セルラーネットワーク）のうちの１つであってもよい。代替的または追加的に、コンピューティング装置９１０は、Ｗｉ－Ｆｉ（登録商標）ルータまたは有線接続（例えば、イーサネット（登録商標）、ＵＳＢまたはファイアワイヤ）を介して、ネットワーク９５０と通信することができる。コンピューティング装置９１０は、ブルートゥース（登録商標）プロトコルを用いて他のコンピューティング装置と無線で通信することができ、またはアドホック無線ネットワークを使用することもできる。
基地局のネットワークを運営するサービスプロバイダは、モバイルコンピューティング装置９１０をネットワーク９５０に接続することによって、モバイルコンピューティング装置９１０とサービス９６０を提供する他のコンピューティングシステムとの間の通信を可能にする。様々なネットワーク（例えば、サービスプロバイダの内部ネットワーク、公衆交換電話網、およびインターネット）を介してサービス９６０を提供することができるが、ネットワーク９５０は、単一のネットワークとして示されている。サービスプロバイダは、モバイルコンピューティング装置９１０とサービス９６０に関連するコンピューティングシステムとの間に情報パケットおよび音声データをルーティングするサーバシステム９５２を稼動することができる。
A service provider that operates a network of base stations connects
ネットワーク９５０は、モバイルコンピューティング装置９１０と別のコンピューティング装置との間の音声通信またはファックス通信を確立するために、モバイルコンピューティング装置９１０をＰＳＴＮ（Public Switched Telephone Network：公衆交換電話網）９６２に接続することができる。例えば、サービスプロバイダのサーバシステム９５２は、ＰＳＴＮ９６２から、モバイルコンピューティング装置９１０への着信電話の指示を受信することができる。逆に、モバイルコンピューティング装置９１０は、ＰＳＴＮ９６２を介してアクセス可能な装置に関連する電話番号を用いて、通話を開始するための通信をサービスプロバイダのサーバシステム９５２に送信することができる。
ネットワーク９５０は、ＰＳＴＮとは対照的に、モバイルコンピューティング装置９１０を、ＩＰネットワークを介して音声通信をルーティングするＶｏＩＰ（Voice over Internet Protocol：ボイスオーバーインターネットプロトコル）サービス９６４に接続することができる。例えば、モバイルコンピューティング装置９１０のユーザは、ＶｏＩＰアプリケーションを呼び出し、呼び出したアプリケーションを使用して通話を開始することができる。サービスプロバイダサーバシステム９５２は、通話の音声データをＶｏＩＰサービスに転送することができ、ＶｏＩＰサービスは、インターネットを介して、場合によって接続の最終部分にＰＳＴＮを用いて、通話を対応するコンピューティング装置にルーティングすることができる。
アプリケーションストア９６６は、リモートに格納されたアプリケーションプログラムのリストをモバイルコンピューティング装置９１０のユーザに提供することができる。よって、ユーザは、ネットワーク９５０を介してアプリケーションプログラムをダウンロードし、モバイルコンピューティング装置９１０にインストールすることができる。アプリケーションストア９６６は、第三者のアプリケーション開発者によって開発されたアプリケーションのリポジトリとして機能する。モバイルコンピューティング装置９１０にインストールされたアプリケーションプログラムは、ネットワーク９５０を介して、アプリケーションプログラム用に指定されたサーバシステムと通信することができる。例えば、ユーザは、アプリケーションストア９６６からダウンロードしたＶｏＩＰアプリケーションプログラムを用いて、ＶｏＩＰサービス９６４と通信することができる。
モバイルコンピューティング装置９１０は、ネットワーク９５０を介して、インターネット９６８上のコンテンツにアクセスすることができる。例えば、モバイルコンピューティング装置９１０のユーザは、ウェブブラウザアプリケーションを呼び出して、指定のＵＲＬでアクセス可能なリモートコンピューティング装置からデータを要求することができる。様々な例において、サービス９６０の一部は、インターネットを介してアクセスすることができる。
モバイルコンピューティング装置は、パーソナルコンピュータ９７０と通信することができる。例えば、パーソナルコンピュータ９７０は、モバイルコンピューティング装置９１０のユーザが使用しているホームコンピュータであってもよい。したがって、ユーザは、自分のパーソナルコンピュータ９７０からメディアを再生することができる。また、ユーザは、自分のパーソナルコンピュータ９７０のファイル構造を閲覧し、コンピュータ装置の間に選択した文書を転送することができる。
A mobile computing device can communicate with a
音声認識サービス９７２は、モバイルコンピューティング装置のマイクロフォン９２２で記録された音声通信データを受信し、音声通信データを対応するテキストデータに変換することができる。いくつかの例において、変換されたテキストは、ウェブクエリとして検索エンジンに提供され、検索エンジンからの検索結果は、モバイルコンピューティング装置９１０に送信される。
The
モバイルコンピューティング装置９１０は、ソーシャルネットワーク９７４と通信することができる。ソーシャルネットワークは、多数のメンバを含むことができ、そのうちの一部は、知り合いとして帰属される。モバイルコンピューティング装置９１０上のアプリケーションプログラムは、ソーシャルネットワーク９７４にアクセスして、モバイルコンピューティング装置のユーザの知り合いに基づいて情報を取得することができる。例えば、「アドレス帳」アプリケーションプログラムは、ユーザの知り合いの電話番号を取得することができる。様々な例において、メンバおよび相互の関連性を示すソーシャルネットワークグラフにおけるユーザと他のメンバとのソーシャルネットワーク上の距離に基づいて、モバイルコンピューティング装置９１０にコンテンツを配信することができる。例えば、ユーザと「親しい」メンバ（「友達」または「友達の友達」）からの広告およびニュース記事との絡み程度に基づいて、これらのコンテンツを選択してユーザに提供することができる。
モバイルコンピューティング装置９１０は、ネットワーク９５０を介して個人連絡先９７６にアクセスすることができる。各連絡先は、個人を特定し、その人に関する情報（例えば、電話番号、電子メールアドレスおよび誕生日）を含むことができる。連絡先は、モバイルコンピューティング装置９１０に対してリモートでホストされているため、ユーザは、複数の装置から共通の連絡先としての連絡先９７６にアクセスし、保存することができる。
モバイルコンピューティング装置９１０は、クラウドベースアプリケーションプログラム９７８にアクセスすることができる。クラウドコンピューティングは、アプリケーションプログラム（例えば、ワードプロセッサまたは電子メールプログラム）を提供することができる。これらのアプリケーションプログラムは、モバイルコンピューティング装置９１０に対してリモートでホストされ、装置９１０は、ウェブブラウザまたは専用プログラムを介してアクセス可能である。クラウドベースアプリケーションプログラムの例は、ＧＯＯＧＬＥ（登録商標）ドキュメントワードプロセッサおよびスプレッドシートサービス、ＧＯＯＧＬＥ ＧＭＡＩＬウェブメールサービス、ＰＩＣＡＳＡピクチャマネージャを含む。
マッピングサービス９８０は、モバイルコンピューティング装置９１０にストリートマップ、ルート計画情報、および衛星画像を提供することができる。マッピングサービスの例は、ＧＯＯＧＬＥマップを含む。また、マッピングサービス９８０は、クエリを受信し、特定の位置を示す結果を返すことができる。例えば、モバイルコンピューティング装置９１０は、モバイルコンピューティング装置の推定位置および「ピザ店」を探すユーザクエリをマッピングサービス９８０に送信することができる。マッピングサービス９８０は、スーパーインポーズ「マーカ」で近くの「ピザ店」の地理位置を標記したストリートマップを返すことができる。
ターンバイターンサービス９８２は、ユーザが指定した目的地へのターンバイターン方向をモバイルコンピューティング装置９１０に提供することができる。例えば、ターンバイターンサービス９８２は、装置９１０の推定位置のストリートビューを装置９１０に配信すると共に、音声コマンドおよびスーパーインポーズ矢印を使用して、装置９１０のユーザを目的地まで誘導することができる。
Turn-by-
モバイルコンピューティング装置９１０は、様々なストリーミングメディア９８４をリクエストすることができる。例えば、コンピューティング装置９１０は、事前に録画したビデオファイル、ライブテレビ番組またはライブラジオ番組のストリームをリクエストすることができる。ストリーミングメディアを提供するサービスの例は、YouTube（登録商標）およびPandoraを含む。
マイクロブログサービス９８６は、モバイルコンピューティング装置９１０から、投稿の受信者を指定しないユーザ投稿を受け取ることができる。マイクロブログサービス９８６は、ユーザの投稿を購読したマイクロブログサービス９８６の他のメンバに投稿を配布することができる。
検索エンジン９８８は、モバイルコンピューティング装置９１０からユーザが入力したテキストクエリまたは音声クエリを受信し、クエリに対応するインターネットアクセス可能なドキュメントを決定し、対応するドキュメントの検索結果のリストを示す情報を装置９１０に提供することができる。音声クエリを受信した場合、音声認識サービス９７２は、受信した音声をテキストクエリに変換して、検索エンジンに送信する。
これらのサービスおよび他のサービスは、サーバシステム９９０で実施されてもよい。サーバシステムは、サービスまたは複数のサービスを提供するハードウェアとソフトウェアの組み合わせであってもよい。例えば、物理的に独立なコンピュータ装置およびネットワーク接続したコンピュータ装置は、論理サーバシステムユニットとして協働して必要な操作を処理することによって、数百台のコンピューティング装置にサービスを提供することができる。このようなサーバシステムは、本明細書においてコンピューティングシステムとも呼ばれる。
These services and others may be implemented on
様々な実施形態において、別の操作（例えば、判断または識別）「に応答して」または「の結果として」実行される操作は、先行の操作が失敗した場合（例えば、判断が行われていない場合）、実行されない。「自動的に」実行される操作は、ユーザの介入（ユーザ入力）なしで実行される操作である。本明細書において、条件付き言語で記載された特徴は、その実装が選択的であることを意味する。いくつかの例において、第１装置から第２装置に「送信」することは、第１装置が第２装置によって受信されるデータをネットワークに配置することを含むが、第２装置がデータを受信することを含まなくてもよい。逆に、第１装置から「受信」することは、ネットワークからデータを受信することを含むが、第１装置がデータを送信することを含まなくてもよい。 In various embodiments, an operation that is performed "in response to" or "as a result of" another operation (e.g., determining or identifying) is performed if the preceding operation fails (e.g., no determination has been made). case), it is not executed. Operations that are performed "automatically" are operations that are performed without user intervention (user input). In this specification, features described in conditional language imply that their implementation is optional. In some examples, "transmitting" from a first device to a second device includes the first device placing data on a network to be received by the second device, but the second device receiving the data. It does not have to involve doing Conversely, "receiving" from the first device may include receiving data from the network, but not transmitting data from the first device.
コンピューティングシステムによる「判断」することは、別の装置が判断を実行し、その結果を当該コンピューティングシステムに供給することを要求することを含むことができる。また、コンピューティングシステムによる「表示」または「提示」することは、コンピューティングシステムがデータを別の装置に送信して、別の装置に参照情報を表示または提示させることを含むことができる。 "Determining" by a computing system can include requesting that another device perform the determination and provide the results to the computing system. Also, "displaying" or "presenting" by a computing system can include the computing system sending data to another device to cause the other device to display or present the reference information.
図１０は、クライアントとしてもしくはサーバまたは複数のサーバとして、本明細書に記載のシステムおよび方法を実現するために使用されたコンピューティング装置１０００、１０５０を示すブロック図である。コンピューティング装置１０００は、ラップトップ、デスクトップ、ワークステーション、ＰＤＡ（Personal Digital Assistant）、サーバ、ブレードサーバ、メインフレームおよび他の適切なコンピュータなどの様々な形態のデジタルコンピュータを表すように意図されている。コンピューティング装置１０５０は、パーソナルデジタルアシスタント、携帯電話、ＰＤＡ、携帯電話、スマートフォンおよび他の類似するコンピューティング装置などの様々な形態のモバイル装置を表すように意図されている。図示された構成要素、それらの接続および関係並びにそれらの機能は、例示的なものに過ぎず、本明細書に記載および／または請求される発明の実施を限定するものではない。
FIG. 10 is a block diagram illustrating
コンピューティング装置１０００は、プロセッサ１００２と、メモリ１００４と、記憶装置１００６と、メモリ１００４および高速拡張ポート１０１０を連結する高速インターフェイス１００８と、低速バス１０１４および記憶装置１００６を連結する低速インターフェイス１０１２とを含む。構成要素１００２、１００４、１００６、１００８、１０１０および１０１２は、様々なバスを使用して相互に接続され、共通のマザーボード上に実装されてもよく、または適切な他の方法で実装されてもよい。プロセッサ１００２は、メモリ１００４または記憶装置１００６に記憶された命令を含むコンピューティング装置１０００内に実行される命令を処理することによって、外部入力／出力装置のＧＵＩに、例えば高速インターフェイス１００８に接続されたディスプレイ１０１６にグラフィック情報を表示することができる。他の実施態様において、複数のプロセッサおよび／または複数のバスは、複数のメモリおよび複数種類のメモリと共に、適切に使用されることができる。また、各装置が（例えば、サーババンク、一群のブレードサーバ、またはマルチプロセッサシステムとして）必要な動作の一部を実行するように、複数のコンピューティング装置１０００を接続することができる。
メモリ１００４は、コンピューティング装置１０００に情報を格納する。一実現例において、メモリ１００４は、揮発性メモリユニットである。別の実現例において、メモリ１００４は、不揮発性メモリユニットである。メモリ１００４は、別の形態のコンピュータ可読媒体、例えば、磁気ディスクまたは光ディスクであってもよい。
記憶装置１００６は、コンピューティング装置１０００に大容量の記憶を提供することができる。一実現例において、記憶装置１００６は、例えば、フロッピー（登録商標）ディスク装置、ハードディスク装置、光学ディスク装置、テープディスク装置、フラッシュメモリまたは他の同様の固体メモリ装置、または記憶エリアネットワークまたは他の構成内の装置を含むアレイ記憶装置などのコンピュータ可読媒体を含むことができる。コンピュータプログラム製品は、情報担体に有形的に具体化することができる。また、コンピュータプログラム製品は、命令を含むことができる。これらの命令は、実行されると、上述したような１つ以上の方法を実行することができる。情報担体は、例えば、メモリ１００４、記憶装置１００６、またはプロセッサ１００２上のメモリなどのコンピュータ可読媒体または機械可読媒体である。
高速コントローラ１００８は、コンピューティング装置１０００の高速の帯域幅集約動作を管理し、低速コントローラ１０１２は、低速の帯域幅集約動作を管理する。このような機能の割り当ては、例示に過ぎない。一実現例において、高速コントローラ１００８は、メモリ１００４、（例えば、グラフィックプロセッサまたはアクセラレータを介して）ディスプレイ１０１６、および様々な拡張カード（図示せず）を挿入できる高速拡張ポート１０１０に連結される。この実現例において、低速コントローラ１０１２は、記憶装置１００６および低速拡張ポート１０１４に連結される。様々な通信ポート（例えば、ＵＳＢ、ブルートゥース（登録商標）、イーサネット（登録商標）、無線イーサネット）を含み得る低速拡張ポートは、例えば、キーボード、ポインティング装置、スキャナなどの１つ以上の入出力装置に連結されてもよく、またはネットワークアダプタを介して、スイッチまたはルータなどのネットワーキング装置に連結されてもよい。
図示のように、コンピューティング装置１０００は、いくつかの異なる形態で実装されることができる。例えば、コンピューティング装置１０００は、標準サーバ１０２０として実装されてもよく、または標準サーバのグループ内に複数回実装されてもよい。また、コンピューティング装置１０００は、サーバラックシステム１０２４の一部として実装されてもよい。さらに、コンピューティング装置１０００は、ラップトップコンピュータ１０２２のようなパーソナルコンピュータに実装されてもよい。代替的には、コンピューティング装置１０００の要素は、装置１０５０などのモバイル装置（図示せず）内の他の要素と組み合わてもよい。このような装置の各々は、１つ以上のコンピューティング装置１０００、１０５０を含んでもよく、システムの全体は、互いに通信できる複数のコンピューティング装置１０００、１０５０から構成されてもよい。
As shown,
コンピューティング装置１０５０は、プロセッサ１０５２、メモリ１０６４、ディスプレイ１０５４などの入出力装置、通信インターフェイス１０６６、およびトランシーバ５６８を含む。装置１０５０は、追加の記憶を提供するために、マイクロドライブまたは他の素子などの記憶装置を備えることもできる。要素１０５０、１０５２、１０６４、１０５４、１０６６および１０６８は、様々なバスを介して相互に接続され、一部の要素は、共通のマザーボード上に実装されてもよく、または適切な他の方法で実装されてもよい。
プロセッサ１０５２は、メモリ５６４に格納された命令を含むコンピューティング装置１０５０内の命令を実行することができる。このプロセッサは、互いに独立している複数のアナログプロセッサおよびデジタルプロセッサを備えるチップのチップセットとして実装されてもよい。また、いくつかのアーキテクチャのいずれかを用いて、プロセッサを実装することができる。例えば、プロセッサは、ＣＩＳＣ（複合命令セットコンピュータ）プロセッサ、ＲＩＳＣ（縮小命令セットコンピュータ）プロセッサ、またはＭＩＳＣ（最小命令セットコンピュータ）プロセッサであってもよい。このプロセッサは、装置１０５０の他の要素の協調、例えば、ユーザインターフェイスの制御、装置１０５０によるアプリケーションの実行、および装置１０５０による無線通信を提供することができる。
プロセッサ１０５２は、制御インターフェイス１０５８およびディスプレイ１０５４に結合されたディスプレイインターフェイス１０５６を介してユーザと通信することができる。ディスプレイ１０５４は、例えば、ＴＦＴディスプレイ（薄膜トランジスタ液晶ディスプレイ）またはＯＬＥＤ（有機発光ダイオードディスプレイ）、または他の適切なディスプレイ技術を使用することができる。表示インターフェイス１０５６は、グラフィック情報および他の情報をユーザに表示するために、ディスプレイ１０５４を駆動する適切な回路を含むことができる。制御インターフェイス１０５８は、ユーザからの指令を受信し、変換してからプロセッサ１０５２に提供することができる。また、プロセッサ１０５２と通信するように外部インターフェイス１０６２を設けることによって、装置１０５０は、他の装置と近距離通信を行うことができる。外部インターフェイス１０６２は、例えば、いくつかの実現例において有線通信を提供することができ、他の実現例において無線通信を提供することができる。複数のインターフェイスを使用することもできる。
メモリ１０６４は、コンピューティング装置１０５０に情報を格納する。メモリ１０６４は、コンピュータ可読媒体、揮発性メモリユニット、または不揮発性メモリユニットのうち、１つまたは複数として実装することができる。拡張メモリ１０７４は、例えば、ＳＩＭＭ（Single In Line Memory Module）カードインターフェイスを含む拡張インターフェイス１０７２を介して、装置１０５０に提供され、接続されてもよい。具体的には、拡張メモリ１０７４は、上述したプロセスを実行するまたは補足するための命令を格納することができ、セキュリティ情報を格納することもできる。したがって、拡張メモリ１０７４は、例えば、装置１０５０のセキュリティモジュールとして提供されてもよく、装置１０５０の安全使用を可能にする命令でプログラムされてもよい。さらに、ＳＩＭＭカードを介して、追加情報と共に、セキュリティアプリケーションを配置することができる。例えば、ハッキングできない方法で、ＳＩＭＭカード上に識別情報を配置することができる。
以下に説明するように、メモリは、例えば、フラッシュメモリおよび／またはＮＶＲＡＭメモリを含むことができる。一実現例において、コンピュータプログラム製品は、情報担体に有形的に具体化される。コンピュータプログラム製品は、命令を含み、これらの命令は、実行されると、上述したような１つ以上の方法を実行する。情報担体は、例えば、メモリ１０６４、拡張メモリ１０７４、またはプロセッサ１０５２上のメモリなどのコンピュータ可読媒体または機械可読媒体であり、トランシーバ１０６８または外部インターフェイス１０６２を介して受信動作を実行してもよい。
The memory may include, for example, flash memory and/or NVRAM memory, as described below. In one implementation, a computer program product is tangibly embodied in an information carrier. The computer program product contains instructions that, when executed, perform one or more methods as described above. The information carrier is, for example, a computer-readable or machine-readable medium such as
装置１０５０は、必要に応じてデジタル信号処理回路を含む通信インターフェイス１０６６を介して無線通信を行うことができる。通信インターフェイス１０６６は、とりわけ、ＧＳＭ（登録商標）通話、ＳＭＳ、ＥＭＳ、またはＭＭＳメッセージング、ＣＤＭＡ、ＴＤＭＡ、ＰＤＣ、ＷＣＤＭＡ（登録商標）、ＣＤＭＡ２０００、またはＧＰＲＳなどの様々なモードまたはプロトコルに基づいて、通信を提供することができる。このような通信は、例えば、高周波トランシーバ１０６８を介して行われてもよい。また、ブルートゥース（登録商標）、ＷｉＦｉ（登録商標）、または他のトランシーバ（図示せず）を用いて、短距離通信を行うことができる。さらに、ＧＰＳ（全地球測位システム）受信モジュール１０７０は、追加のナビゲーション関連無線データおよび位置関連無線データを装置１０５０に提供することができる。これらの無線データは、装置１０５０上で動作するアプリケーションに適宜に使用される。
また、装置１０５０は、音声コーデック１０６０を使用して音声通信を行うことができる。音声コーデック１０６０は、ユーザから受信した音声情報を使用可能なデジタル情報に変換することができる。同様に、音声コーデック１０６０は、例えば、装置１０５０の送受話器内のスピーカを介して、ユーザに可聴な音声を生成することができる。このような音声は、音声電話からの音声を含むことができ、記録された音声（例えば、音声メッセージ、音楽ファイル）を含むことができ、装置１０５０上で動作するアプリケーションによって生成された音声を含むこともできる。
図示のように、コンピューティング装置１０５０は、いくつかの異なる形態で実装されてもよい。例えば、コンピューティング装置１０５０は、携帯電話１０８０として実装されてもよく、スマートフォン１０８２、ＰＤＡまたは他の類似するモバイル装置の一部として実装されてもよい。
As shown,
また、コンピューティング装置１０００または１０５０は、ユニバーサルシリアルバス（ＵＳＢ）フラッシュドライブを含むことができる。ＵＳＢフラッシュドライブは、オペレーティングシステムおよび他のアプリケーションを格納することができる。ＵＳＢフラッシュドライブは、入力／出力要素、例えば、別のコンピューティング装置のＵＳＢポートに挿入することができるワイヤレストランスミッタまたはＵＳＢコネクタを含むことができる。
本明細書に記載のシステムおよび技術の様々な実装は、デジタル電子回路、集積回路、特別に設計されたＡＳＩＣ（特定用途向け集積回路）、コンピュータハードウェア、ファームウェア、ソフトウェアおよび／またはそれらの組み合わせで実現することができる。これらの様々な実装は、プログラム可能なシステム上で実行可能および／または解釈可能な１つ以上のコンピュータプログラムにおける実装を含むことができる。このプログラム可能なシステムは、記憶システムからデータおよび命令を受信し、データおよび命令を記憶システムに送信するように記憶システムに連結された少なくとも１つのプログラム可能な専用または汎用のプロセッサ、少なくとも１つの入力要素、および少なくとも１つの出力装置を含む。 Various implementations of the systems and techniques described herein may be implemented in digital electronic circuits, integrated circuits, specially designed ASICs (Application Specific Integrated Circuits), computer hardware, firmware, software and/or combinations thereof. can be realized. These various implementations may include implementation in one or more computer programs executable and/or interpretable on a programmable system. The programmable system includes at least one programmable special purpose or general purpose processor coupled to the storage system to receive data and instructions from the storage system and to transmit data and instructions to the storage system; elements, and at least one output device.
（プログラム、ソフトウェア、ソフトウェアアプリケーションまたはコードとしても知られている）これらのコンピュータプログラムは、プログラム可能なプロセッサ用の機械命令を含み、高度な手続き型プログラミング言語および／または高度なオブジェクト指向プログラミング言語で実装することができ、および／またはアセンブリ言語／機械言語で実装することができる。「機械可読媒体」という用語は、本明細書に使用された場合、プログラム可能なプロセッサに機械命令および／またはデータを提供するために使用された機械可読信号としての機械命令を受け取る機械可読媒体を含む任意のコンピュータプログラム製品、機械および／または装置（例えば、磁気ディスク、光学ディスク、メモリ、プログラム可能な論理装置（ＰＬＤ））を指す。「機械可読信号」という用語は、機械命令および／またはデータをプログラム可能なプロセッサに提供するために使用された任意の信号を指す。 These computer programs (also known as programs, software, software applications or code) contain machine instructions for a programmable processor and are implemented in a high level procedural and/or high level object oriented programming language. and/or implemented in assembly/machine language. The term "machine-readable medium," as used herein, refers to a machine-readable medium that receives machine instructions as machine-readable signals used to provide machine instructions and/or data to a programmable processor. Refers to any computer program product, machine and/or apparatus (eg, magnetic disk, optical disk, memory, programmable logic device (PLD)) containing a computer program product. The term "machine-readable signal" refers to any signal used to provide machine instructions and/or data to a programmable processor.
ユーザとの情報交換を提供するために、本開示に記載されたシステムおよび技術は、情報をユーザに提示するための表示装置（例えば、ＣＲＴ（陰極線管）モニタまたはＬＣＤ（液晶ディスプレイ）モニタ）、ユーザがコンピュータに入力を提供することができるキーボードおよびポインティング装置（例えば、マウスまたはトラックボール）を備えたコンピュータ上で実装することができる。他の種類の装置を用いて、ユーザとの対話を提供することもできる。例えば、ユーザに提供されるフィードバックは、任意種類の感覚フィードバック、例えば視覚フィードバック、聴覚フィードバックまたは触覚フィードバックであってもよく、ユーザからの入力は、音響入力、音声入力または触覚入力を含む任意の形で受信することができる。 To provide information exchange with a user, the systems and techniques described in this disclosure include a display device (e.g., a CRT (cathode ray tube) monitor or LCD (liquid crystal display) monitor) for presenting information to the user; It can be implemented on a computer with a keyboard and pointing device (eg, mouse or trackball) that allows a user to provide input to the computer. Other types of devices can also be used to provide user interaction. For example, the feedback provided to the user may be any kind of sensory feedback, such as visual, auditory or tactile feedback, and the input from the user may be in any form including acoustic, audio or tactile input. can be received at
本明細書に記載のシステムおよび技術は、バックエンド要素（例えば、データサーバ）を含むコンピューティングシステム、またはミドルウェア要素（例えば、アプリケーションサーバ）を含むコンピューティングシステム、またはフロントエンド要素（例えば、ユーザが本明細書に記載のシステムおよび技術の実装と情報交換を行うことができるグラフィカルユーザインターフェイスまたはウェブブラウザを含むクライアントコンピュータ）を含むコンピューティングシステム、またはバックエンド要素、ミドルウェア要素およびフロントエンド要素の任意の組み合わせを含むコンピューティングシステムに実装されてもよい。これらのシステム要素は、任意の形式または媒体のデジタルデータ通信（例えば、通信ネットワーク）によって相互接続することができる。通信ネットワークの例は、ローカルエリアネットワーク（ＬＡＮ）、ワイドエリアネットワーク（ＷＡＮ）、ピアツーピアネットワーク（アドホックまたは静的メンバを有する）、グリッドコンピューティングインフラストラクチャ、およびインターネットを含む。 The systems and techniques described herein may be a computing system that includes back-end elements (e.g., data servers), or a computing system that includes middleware elements (e.g., application servers), or front-end elements (e.g., when users any of the back-end, middleware, and front-end elements; It may be implemented in a computing system containing combinations. These system elements can be interconnected by any form or medium of digital data communication (eg, a communication network). Examples of communication networks include local area networks (LANs), wide area networks (WANs), peer-to-peer networks (with ad-hoc or static members), grid computing infrastructures, and the Internet.
コンピューティングシステムは、クライアントおよびサーバを含むことができる。クライアントとサーバとは、一般的に互いに遠隔であり、典型的には通信ネットワークを介して情報交換を行う。クライアントとサーバとの関係は、各々のコンピュータ上で動作しており、互いにクライアント－サーバ関係を有するコンピュータプログラムに依存する。 The computing system can include clients and servers. A client and server are generally remote from each other and typically exchange information through a communication network. The relationship of client and server relies on computer programs running on the respective computers and having a client-server relationship to each other.
上記でいくつかの実施例を詳細に説明したが、他の変更も可能である。また、本明細書に記載のシステムおよび方法を実行するために、他のメカニズムを使用することもできる。さらに、望ましい結果を達成するために、図示の論理フローは、示された特定の順序でまたは逐次に行う必要がない。図示のフローに他のステップを追加してもよく、または図示のフローから他のステップを省いてもよい。記載のシステムに他の要素を追加してもよく、システムから他の要素を除去してもよい。したがって、他の実施例は、添付の特許請求の範囲内に含まれる。 Although several implementations have been described in detail above, other modifications are possible. Other mechanisms can also be used to implement the systems and methods described herein. Moreover, the illustrated logic flow need not occur in the particular order shown or sequential to achieve the desired results. Other steps may be added to the illustrated flow, or other steps may be omitted from the illustrated flow. Other elements may be added to or removed from the systems described. Accordingly, other implementations are within the scope of the following claims.
Claims (46)
前記コンピューティング装置を用いて、複数の参照歌曲の中の各参照歌曲の複数の音声特徴を識別する参照歌曲特徴データを格納することと、
前記コンピューティング装置を用いて、マイクロフォンによって記録された音声を表すデジタル音声データを受信することと、
前記コンピューティング装置の第１プロセッサを用いて、音楽判断プロセスに従って、前記デジタル音声データが音楽を表すか否かを判断することと、
前記デジタル音声データが音楽を表すことを判断した後、前記コンピューティング装置の第２プロセッサを用いて、前記デジタル音声データが前記複数の参照歌曲の中の特定の参照歌曲を表すことを認識することと、
前記デジタル音声データが前記複数の参照歌曲の中の特定の参照歌曲を表すという認識に応答して、前記コンピューティング装置を用いて、前記特定の参照歌曲を示す表記を出力することとを含み、
前記デジタル音声データが音楽を表すか否かを判断することは、前記デジタル音声データを時間領域形式から第１周波数領域形式に変換することを含み、
前記デジタル音声データが前記複数の参照歌曲の中の特定の参照歌曲を表すことを認識することは、前記デジタル音声データを前記時間領域形式から第２周波数領域形式に変換することを含み、
前記第１プロセッサは、前記第２プロセッサよりも低い電圧で動作する、コンピュータによって実施される方法。 A method implemented by a computing device, comprising:
using the computing device to store reference song feature data identifying a plurality of audio features of each reference song in a plurality of reference songs;
receiving, with the computing device, digital audio data representing audio recorded by a microphone;
determining, with a first processor of the computing device, whether the digital audio data represents music according to a music determination process;
After determining that the digital audio data represents music, recognizing, with a second processor of the computing device, that the digital audio data represents a particular reference song among the plurality of reference songs. When,
responsive to recognizing that the digital audio data represents a particular reference song among the plurality of reference songs, using the computing device to output a notation indicative of the particular reference song;
determining whether the digital audio data represents music includes transforming the digital audio data from a time domain format to a first frequency domain format;
recognizing that the digital audio data represents a particular reference song among the plurality of reference songs includes converting the digital audio data from the time domain format to a second frequency domain format;
The computer-implemented method, wherein the first processor operates at a lower voltage than the second processor.
前記音楽判断プロセスにおいて、前記第１周波数領域形式の前記デジタル音声データを使用することと、
前記デジタル音声データが音楽を表すという表記を出力することとを含む、請求項１に記載の方法。 Determining whether the digital audio data represents music includes:
using the digital audio data in the first frequency domain format in the music determination process;
and outputting a notation that the digital audio data represents music.
前記デジタル音声データが前記特定の参照歌曲を表すことを認識することは、
（ｉ）第２周波数領域変換プロセスにおいて、前記デジタル音声データを前記時間領域形式から前記第２周波数領域形式に変換することと、
（ｉｉ）前記第２周波数領域形式の前記デジタル音声データを受信し、前記デジタル音声データの複数の特徴値を出力する音楽特徴決定プロセスにおいて、前記第２周波数領域形式の前記デジタル音声データを使用することと、
（ｉｉｉ）前記デジタル音声データの前記複数の特徴値を前記複数の参照歌曲の少なくとも一部の歌曲の中の各歌曲の複数の特徴値と比較することによって、前記特定の参照歌曲の前記複数の特徴値が前記デジタル音声データの前記複数の特徴値に最も関連していると判断することとを含む、請求項２に記載のコンピュータによって実施される方法。 converting the digital audio data from the time domain format to the first frequency domain format is a first frequency domain transform process;
recognizing that the digital audio data represents the particular reference song;
(i) converting the digital audio data from the time domain format to the second frequency domain format in a second frequency domain transform process;
(ii) receiving the digital audio data in the second frequency domain format and using the digital audio data in the second frequency domain format in a music characterization process that outputs a plurality of feature values of the digital audio data; and
(iii) comparing the feature values of the digital audio data to the feature values of each song in at least a portion of the songs of the plurality of reference songs; and determining which feature value is most relevant to the plurality of feature values of the digital audio data.
前記方法は、
前記デジタル音声データの前記複数の特徴値の中の特徴値を、前記複数の参照歌曲の中の各歌曲の前記複数の特徴値と比較することによって、前記複数の参照歌曲の前記一部の歌曲を選択することをさらに含む、請求項３から５のいずれか一項に記載の方法。 the computing device compares the plurality of feature values of the digital audio data only to the plurality of feature values of each song in the portion of songs of the plurality of reference songs;
The method includes:
songs of the portion of the plurality of reference songs by comparing feature values in the plurality of feature values of the digital audio data to the plurality of feature values of each song in the plurality of reference songs; 6. The method of any one of claims 3-5, further comprising selecting
前記デジタル音声データの前記複数の特徴値の中の特徴値を、前記複数の参照歌曲の中の各歌曲の前記複数の特徴値と比較することは、（ａ）二進値０および二進値１に限定された前記デジタル音声データの前記特徴値と、（ｂ）二進値０および二進値１に限定された前記複数の参照歌曲の中の各歌曲の前記特徴値との比較を含む、請求項３から６のいずれか一項に記載の方法。 further comprising converting feature values among the plurality of feature values of the digital audio data from values not limited to binary values 0 and 1 to values limited to binary values 0 and 1;
Comparing a feature value in the plurality of feature values of the digital audio data to the plurality of feature values for each song in the plurality of reference songs comprises (a) a binary value of 0 and a binary value of (b) comparing said feature value of said digital audio data limited to 1 with said feature value of each song in said plurality of reference songs limited to binary 0 and binary 1; , a method according to any one of claims 3 to 6.
１つ以上のプロセッサと、
前記１つ以上のプロセッサによって実行されると、以下の動作を実行させる命令を含む１つ以上のコンピュータ可読メモリ装置とを含み、
前記動作は、
前記コンピュータシステムを用いて、複数の参照歌曲の中の各参照歌曲の複数の音声特徴を識別する参照歌曲特徴データを格納することと、
前記コンピュータシステムを用いて、マイクロフォンによって記録された音声を表すデジタル音声データを受信することと、
前記１つ以上のプロセッサのうちの第１プロセッサを用いて、音楽判断プロセスに従って、前記デジタル音声データが音楽を表すか否かを判断することと、
前記デジタル音声データが音楽を表すことを判断した後、前記１つ以上のプロセッサのうちの第２プロセッサを用いて、前記デジタル音声データが前記複数の参照歌曲の中の特定の参照歌曲を表すことを認識することと、
前記デジタル音声データが前記複数の参照歌曲の中の特定の参照歌曲を表すという認識に応答して、前記コンピュータシステムを用いて、前記特定の参照歌曲を示す表記を出力することとを含み、
前記デジタル音声データが音楽を表すか否かを判断することは、前記デジタル音声データを時間領域形式から第１周波数領域形式に変換することを含み、
前記デジタル音声データが前記複数の参照歌曲の中の特定の参照歌曲を表すことを認識することは、前記デジタル音声データを前記時間領域形式から第２周波数領域形式に変換することを含み、
前記第１プロセッサは、前記第２プロセッサよりも低い電圧で動作する、コンピュータシステム。 a computer system,
one or more processors;
one or more computer readable memory devices containing instructions that, when executed by the one or more processors, cause the following actions to be performed;
The operation is
using the computer system to store reference song feature data identifying a plurality of audio features of each reference song in a plurality of reference songs;
receiving, with the computer system, digital audio data representing audio recorded by a microphone;
determining, with a first processor of the one or more processors, whether the digital audio data represents music according to a music determination process;
After determining that the digital audio data represents music, with a second one of the one or more processors, the digital audio data represents a particular reference song among the plurality of reference songs. and
responsive to recognizing that the digital audio data represents a particular reference song among the plurality of reference songs, using the computer system to output a notation indicative of the particular reference song;
determining whether the digital audio data represents music includes transforming the digital audio data from a time domain format to a first frequency domain format;
recognizing that the digital audio data represents a particular reference song among the plurality of reference songs includes converting the digital audio data from the time domain format to a second frequency domain format;
The computer system, wherein the first processor operates at a lower voltage than the second processor.
音声信号を記録するように構成されたマイクロフォンと、
記録された音声信号からデジタル音声データを生成するように構成されたアナログ－デジタルコンバータと、
（ｉ）複数の参照歌曲の中の各参照歌曲の複数の音声特徴を識別する参照歌曲特徴データと、（ｉｉ）プロセッサによって実行可能であり、前記プロセッサの動作を設定するための命令とを格納する１つ以上のコンピュータ可読メモリ装置と、
前記デジタル音声データが音楽を表すと判断した場合、前記デジタル音声データが音楽を表すことを示す表記を出力するように構成された第１プロセッサと、
前記第１プロセッサから前記デジタル音声データが音楽を表すことを示す前記表記を受信し、前記デジタル音声データが前記複数の参照歌曲の中の特定の参照歌曲を表すことを認識するように構成された第２プロセッサと、
前記第２プロセッサによって、前記デジタル音声データが前記複数の参照歌曲の中の前記特定の参照歌曲を表すことを認識したことに応答して、前記特定の参照歌曲の識別子を提示するように構成された表示装置とを含み、
前記デジタル音声データが音楽を表すと判断することは、前記デジタル音声データを時間領域形式から第１周波数領域形式に変換することを含み、
前記デジタル音声データが前記複数の参照歌曲の中の特定の参照歌曲を表すことを認識することは、前記デジタル音声データを前記時間領域形式から第２周波数領域形式に変換することを含み、
前記第１プロセッサは、前記第２プロセッサよりも低い電圧で動作する、コンピューティングシステム。 A computing system,
a microphone configured to record an audio signal;
an analog-to-digital converter configured to generate digital audio data from a recorded audio signal;
storing (i) reference song feature data identifying a plurality of audio features for each reference song in a plurality of reference songs; and (ii) instructions executable by a processor for configuring operation of said processor. one or more computer readable memory devices for
a first processor configured to, upon determining that the digital audio data represents music, output a notation indicating that the digital audio data represents music;
configured to receive from the first processor the notation indicating that the digital audio data represents music, and to recognize that the digital audio data represents a particular reference song among the plurality of reference songs; a second processor;
configured by the second processor to present an identifier of the particular reference song in response to recognizing that the digital audio data represents the particular reference song among the plurality of reference songs; a display device;
determining that the digital audio data represents music includes transforming the digital audio data from a time domain format to a first frequency domain format;
recognizing that the digital audio data represents a particular reference song among the plurality of reference songs includes converting the digital audio data from the time domain format to a second frequency domain format;
A computing system, wherein the first processor operates at a lower voltage than the second processor.
前記モバイルコンピューティング装置は、前記マイクロフォンと、前記アナログ－デジタルコンバータと、前記１つ以上のコンピュータ可読メモリ装置と、前記第１プロセッサと、前記第２プロセッサとを備える、請求項１２に記載のコンピューティングシステム。 the computing system includes a mobile computing device;
13. The computing device of claim 12, wherein said mobile computing device comprises said microphone, said analog-to-digital converter, said one or more computer-readable memory devices, said first processor, and said second processor. system.
前記第２プロセッサは、前記モバイルコンピューティング装置が前記デジタル音声データを前記モバイルコンピューティング装置以外のコンピューティングシステムに送信することなく、前記デジタル音声データが前記特定の参照歌曲を表すことを認識するように構成される、請求項１３に記載のコンピューティングシステム。 the first processor is configured to output a notation indicating that the digital audio data represents music;
The second processor causes the mobile computing device to recognize that the digital audio data represents the particular reference song without transmitting the digital audio data to a computing system other than the mobile computing device. 14. The computing system of claim 13, configured for:
前記第２プロセッサは、前記モバイルコンピューティング装置がネットワークを介して外部装置に接続することなく、前記デジタル音声データが前記特定の参照歌曲を表すことを認識するように構成される、請求項１３に記載のコンピューティングシステム。 the first processor is configured to output a notation indicating that the digital audio data represents music;
14. The method of claim 13, wherein the second processor is configured to recognize that the digital audio data represents the particular reference song without the mobile computing device connecting to an external device over a network. The computing system described.
前記第１プロセッサを用いて、前記デジタル音声データが音楽を表すことを判断する前に、音楽判断プロセスを開始するためのユーザ入力を受信することなく、前記デジタル音声データが音楽を表さないことを複数回判断することを含む、請求項１３から１６のいずれか一項に記載のコンピューティングシステム。 Determining that the digital audio data represents music includes:
The digital audio data does not represent music without receiving user input to initiate a music determination process prior to determining, with the first processor, that the digital audio data represents music. 17. A computing system as claimed in any one of claims 13 to 16, comprising determining that multiple times.
前記１つ以上のコンピュータ可読メモリ装置によって格納された前記参照歌曲特徴データは、前記少なくとも１万曲の参照歌曲の音声特徴を識別する、請求項１２から１８のいずれか一項に記載のコンピューティングシステム。 the plurality of reference songs includes at least 10,000 reference songs;
19. Computing according to any one of claims 12 to 18, wherein the reference song feature data stored by the one or more computer readable memory devices identifies audio features of the at least ten thousand reference songs. system.
前記第１周波数領域形式の前記デジタル音声データを受信し、前記デジタル音声データが音楽を表すことを示す表記を出力する音楽判断プロセスにおいて、前記第１周波数領域形式の前記デジタル音声データを使用すること
を行うことによって、前記デジタル音声データが音楽を表すことを判断するように構成される、請求項１２から１９のいずれか一項に記載のコンピューティングシステム。 The first processor
Using the digital audio data in the first frequency domain format in a music judgment process that receives the digital audio data in the first frequency domain format and outputs a notation indicating that the digital audio data represents music. 20. A computing system as claimed in any one of claims 12 to 19, arranged to determine that the digital audio data represents music by performing a.
前記第２プロセッサは、
（ｉ）第２周波数領域変換プロセスにおいて、前記デジタル音声データを前記時間領域形式から前記第２周波数領域形式に変換することと、
（ｉｉ）前記第２周波数領域形式の前記デジタル音声データを受信し、前記デジタル音声データの複数の特徴値を出力する音楽特徴決定プロセスにおいて、前記第２周波数領域形式の前記デジタル音声データを使用することと、
（ｉｉｉ）前記デジタル音声データの前記複数の特徴値を前記複数の参照歌曲の一部の歌曲の中の各歌曲の複数の特徴値と比較することによって、前記特定の参照歌曲の前記複数の特徴値が前記デジタル音声データの前記複数の特徴値に最も関連していると判断することと
を行うことによって、前記デジタル音声データが前記複数の参照歌曲の中の特定の参照歌曲を表すことを認識するように構成される、請求項１２から２２のいずれか一項に記載のコンピューティングシステム。 converting the digital audio data from the time domain format to the first frequency domain format is a first frequency domain transform process;
The second processor
(i) converting the digital audio data from the time domain format to the second frequency domain format in a second frequency domain transform process;
(ii) receiving the digital audio data in the second frequency domain format and using the digital audio data in the second frequency domain format in a music characterization process that outputs a plurality of feature values of the digital audio data; and
(iii) said plurality of features of said particular reference song by comparing said plurality of feature values of said digital audio data to said plurality of feature values of each song in a song of said plurality of reference songs; determining that the value is most relevant to the plurality of characteristic values of the digital audio data, thereby recognizing that the digital audio data represents a particular reference song among the plurality of reference songs. 23. A computing system as claimed in any one of claims 12 to 22, configured to:
前記デジタル音声データの前記複数の特徴値の中の特徴値を前記複数の参照歌曲の中の各歌曲の前記複数の特徴値と比較することは、（ａ）二進値０および二進値１に限定された前記デジタル音声データの前記特徴値と、（ｂ）二進値０および二進値１に限定された前記複数の参照歌曲の中の各歌曲の前記特徴値との比較を含む、請求項２３から２７のいずれか一項に記載のコンピューティングシステム。 further comprising converting feature values among the plurality of feature values of the digital audio data from values not limited to binary values 0 and 1 to values limited to binary values 0 and 1;
Comparing a feature value in the plurality of feature values of the digital audio data to the plurality of feature values for each song in the plurality of reference songs comprises (a) a binary value of 0 and a binary value of 1; with the feature value of the digital audio data limited to (b) the feature value of each song in the plurality of reference songs limited to the binary values 0 and 1; A computing system according to any one of claims 23-27.
前記コンピューティング装置を用いて、複数の参照歌曲の中の各参照歌曲の複数の音声特徴を識別する参照歌曲特徴データを格納することと、
前記コンピューティング装置を用いて、マイクロフォンによって記録された音声を表すデジタル音声データを受信することと、
前記コンピューティング装置を用いて、前記デジタル音声データを時間領域形式から周波数領域形式に変換することと、
前記コンピューティング装置を用いて、前記周波数領域形式の前記デジタル音声データを前記デジタル音声データの複数の特徴値を出力する音楽特徴決定プロセスに使用することとを含み、前記特徴値の少なくとも一部は、二進値０および二進値１以外の値を表し、前記方法は、
前記コンピューティング装置を用いて、前記デジタル音声データの前記複数の特徴値の少なくとも一部を、二進値０および１に限定されない値から二進値０および１に限定された値に変換することと、
前記コンピューティング装置を用いて、前記デジタル音声データの前記複数の特徴値の変換された前記少なくとも一部を前記複数の参照歌曲の中の各参照歌曲の複数の特徴値と比較することによって、前記複数の参照歌曲から、前記デジタル音声データの前記複数の特徴値に対応する一部の参照歌曲を複数の候補歌曲として選択することと、を含み、前記デジタル音声データの前記複数の特徴値の変換された前記少なくとも一部は二進値０および１に限定され、前記複数の参照歌曲の中の各参照歌曲の前記複数の特徴値は二進値０および１に限定され、前記方法は、
前記コンピューティング装置を用いて、前記デジタル音声データの前記複数の特徴値を前記複数の候補歌曲の中の各参照歌曲の前記複数の特徴値と比較することによって、前記デジタル音声データの前記複数の特徴値が前記複数の候補歌曲の中の特定の参照歌曲の前記複数の特徴値に最も関連していると判断することと、
前記デジタル音声データの前記複数の特徴値が前記特定の参照歌曲の前記複数の特徴値に最も関連しているという判断に応答して、前記コンピューティング装置を用いて、前記特定の参照歌曲を示す表記を出力することとを含み、
前記デジタル音声データの前記複数の特徴値を、前記複数の候補歌曲の中の各参照歌曲の前記複数の特徴値と比較することは、（ａ）二進値０および二進値１以外の値を表す実数を含む前記デジタル音声データの前記特徴値と、（ｂ）二進値０および二進値１に限定された前記複数の候補歌曲の中の各参照歌曲の前記特徴値との比較を含む、方法。 A method implemented by a computing device, comprising:
using the computing device to store reference song feature data identifying a plurality of audio features of each reference song in a plurality of reference songs;
receiving, with the computing device, digital audio data representing audio recorded by a microphone;
converting the digital audio data from a time domain format to a frequency domain format using the computing device;
using the computing device to use the digital audio data in frequency domain form in a music characterization process that outputs a plurality of characteristic values of the digital audio data, wherein at least some of the characteristic values are , representing values other than binary 0 and binary 1, the method comprising:
converting at least a portion of the plurality of feature values of the digital audio data from values not limited to binary values 0 and 1 to values limited to binary values 0 and 1 using the computing device; When,
by comparing, with the computing device, the transformed at least a portion of the plurality of feature values of the digital audio data to a plurality of feature values of each reference song among the plurality of reference songs; selecting, from a plurality of reference songs, a portion of reference songs corresponding to the plurality of feature values of the digital audio data as a plurality of candidate songs, wherein the conversion of the plurality of feature values of the digital audio data. said at least a portion of which is defined to be binary values 0 and 1, said plurality of characteristic values of each reference song among said plurality of reference songs is limited to binary values 0 and 1, said method comprising:
using the computing device to compare the plurality of feature values of the digital audio data to the plurality of feature values of each reference song in the plurality of candidate songs; determining which feature values are most relevant to the plurality of feature values of a particular reference song among the plurality of candidate songs ;
responsive to determining that the plurality of feature values of the digital audio data are most relevant to the plurality of feature values of the particular reference song, using the computing device to indicate the particular reference song; and outputting the notation ;
Comparing the plurality of feature values of the digital audio data to the plurality of feature values of each reference song in the plurality of candidate songs includes (a) values other than binary 0 and binary 1; and (b) the feature value of each reference song in the plurality of candidate songs limited to binary 0 and binary 1. including , method.
前記参照歌曲特徴データは、前記少なくとも１万曲の参照歌曲の音声特徴を識別する、請求項１および３０から３３のいずれか一項に記載の方法。 the plurality of reference songs includes at least 10,000 reference songs;
34. The method of any one of claims 1 and 30-33 , wherein said reference song feature data identifies audio features of said at least 10,000 reference songs.
前記コンピューティング装置は、前記音楽判断プロセスに従って、前記デジタル音声データが音楽を表すことを判断した後、前記デジタル音声データの前記複数の特徴値を、前記複数の参照歌曲の中の各参照歌曲の前記複数の特徴値と比較する、請求項３０から３２のいずれか一項に記載の方法。 further comprising using the computing device to determine whether the digital audio data represents music according to a music determination process;
After the computing device determines that the digital audio data represents music according to the music determination process, the computing device compares the plurality of feature values of the digital audio data to each reference song in the plurality of reference songs. 33. A method according to any one of claims 30 to 32 , wherein said plurality of feature values are compared.
前記デジタル音声データを前記時間領域形式から前記周波数領域形式に変換することは、第１周波数領域変換プロセスであり、
前記デジタル音声データが音楽を表すか否かを判断することは、
第２周波数領域変換プロセスにおいて、前記デジタル音声データを時間領域形式から第２周波数領域形式に変換することと、
前記第２周波数領域形式の前記デジタル音声データを受信し、前記デジタル音声データが音楽を表すか否かを示す表記を出力する音楽特徴決定プロセスにおいて、前記第２周波数領域形式の前記デジタル音声データを使用することとを含む、請求項３０から３２のいずれか一項に記載の方法。 the frequency domain format is a first frequency domain format;
converting the digital audio data from the time domain format to the frequency domain format is a first frequency domain transform process;
Determining whether the digital audio data represents music includes:
converting the digital audio data from a time domain format to a second frequency domain format in a second frequency domain transform process;
A musical feature determination process for receiving the digital audio data in the second frequency domain format and outputting a notation indicating whether the digital audio data represents music, wherein the digital audio data in the second frequency domain format is 33. The method of any one of claims 30-32 , comprising using.
前記デジタル音声データの前記複数の特徴値の変換された前記少なくとも一部を、前記複数の参照歌曲の中の各参照歌曲の前記複数の特徴値と比較することは、前記コンピューティング装置の第２プロセッサによって実行され、
前記デジタル音声データの前記複数の特徴値を、前記複数の候補歌曲の中の各参照歌曲の前記複数の特徴値と比較することは、前記コンピューティング装置の前記第２プロセッサによって実行される、請求項３５に記載の方法。 determining whether the digital audio data represents music is performed by a first processor of the computing device;
Comparing the transformed at least a portion of the plurality of feature values of the digital audio data with the plurality of feature values of each reference song among the plurality of reference songs comprises a second step of the computing device; executed by the processor,
Comparing said plurality of feature values of said digital audio data with said plurality of feature values of each reference song among said plurality of candidate songs is performed by said second processor of said computing device. Item 36. The method of Item 35 .
１つ以上のプロセッサと、
前記１つ以上のプロセッサによって実行されると、以下の動作を実行させる命令を含む１つ以上のコンピュータ可読メモリ装置とを含み、
前記動作は、
前記コンピュータシステムを用いて、複数の参照歌曲の中の各参照歌曲の複数の音声特徴を識別する参照歌曲特徴データを格納することと、
前記コンピュータシステムを用いて、マイクロフォンによって記録された音声を表すデジタル音声データを受信することと、
前記コンピュータシステムを用いて、前記デジタル音声データを時間領域形式から周波数領域形式に変換することと、
前記コンピュータシステムを用いて、前記周波数領域形式の前記デジタル音声データを前記デジタル音声データの複数の特徴値を出力する音楽特徴決定プロセスに使用することとを含み、前記特徴値の少なくとも一部は、二進値０および二進値１以外の値を表し、前記動作は、
前記コンピュータシステムを用いて、前記デジタル音声データの前記複数の特徴値の少なくとも一部を、二進値０および１に限定されない値から二進値０および１に限定された値に変換することと、
前記コンピュータシステムを用いて、前記デジタル音声データの前記複数の特徴値の変換された前記少なくとも一部を前記複数の参照歌曲の中の各参照歌曲の複数の特徴値と比較することによって、前記複数の参照歌曲から、前記デジタル音声データの前記複数の特徴値に対応する一部の参照歌曲を複数の候補歌曲として選択することと、を含み、前記デジタル音声データの前記複数の特徴値の変換された前記少なくとも一部は二進値０および１に限定され、前記複数の参照歌曲の中の各参照歌曲の前記複数の特徴値は二進値０および１に限定され、前記動作は、
前記コンピュータシステムを用いて、前記デジタル音声データの前記複数の特徴値を前記複数の候補歌曲の中の各参照歌曲の前記複数の特徴値と比較することによって、前記デジタル音声データの前記複数の特徴値が前記複数の候補歌曲の中の特定の参照歌曲の前記複数の特徴値に最も関連していると判断することと、
前記デジタル音声データの前記複数の特徴値が前記特定の参照歌曲の前記複数の特徴値に最も関連しているという判断に応答して、前記コンピュータシステムを用いて、前記特定の参照歌曲を示す表記を出力することとを含み、
前記デジタル音声データの前記複数の特徴値を、前記複数の候補歌曲の中の各参照歌曲の前記複数の特徴値と比較することは、（ａ）二進値０および二進値１以外の値を表す実数を含む前記デジタル音声データの前記特徴値と、（ｂ）二進値０および二進値１に限定された前記複数の候補歌曲の中の各参照歌曲の前記特徴値との比較を含む、コンピュータシステム。 a computer system,
one or more processors;
one or more computer readable memory devices containing instructions that, when executed by the one or more processors, cause the following actions to be performed;
The operation is
using the computer system to store reference song feature data identifying a plurality of audio features of each reference song in a plurality of reference songs;
receiving, with the computer system, digital audio data representing audio recorded by a microphone;
converting the digital audio data from a time domain format to a frequency domain format using the computer system;
using the computer system to use the digital audio data in frequency domain form in a music characterization process that outputs a plurality of characteristic values of the digital audio data, wherein at least some of the characteristic values are: Representing values other than binary 0 and binary 1, the operation includes:
converting at least a portion of the plurality of feature values of the digital audio data from values not limited to binary values 0 and 1 to values limited to binary values 0 and 1 using the computer system; ,
comparing, with the computer system, the transformed at least a portion of the plurality of feature values of the digital audio data to a plurality of feature values of each reference song among the plurality of reference songs; selecting, as a plurality of candidate songs, a portion of reference songs corresponding to the plurality of feature values of the digital audio data from the reference songs of the digital audio data, wherein the plurality of feature values of the digital audio data are transformed into said at least a portion of which is limited to binary values 0 and 1, said plurality of characteristic values of each reference song among said plurality of reference songs is limited to binary values 0 and 1, said operation comprising:
using the computer system to determine the plurality of characteristics of the digital audio data by comparing the plurality of characteristic values of the digital audio data to the plurality of characteristic values of each reference song in the plurality of candidate songs; determining which value is most relevant to the plurality of feature values for a particular reference song among the plurality of candidate songs ;
responsive to determining that the plurality of feature values of the digital audio data are most relevant to the plurality of feature values of the particular reference song, using the computer system a notation indicative of the particular reference song; and outputting
Comparing the plurality of feature values of the digital audio data to the plurality of feature values of each reference song in the plurality of candidate songs includes (a) values other than binary 0 and binary 1; and (b) the feature value of each reference song in the plurality of candidate songs limited to binary 0 and binary 1. computer system.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201762567755P | 2017-10-03 | 2017-10-03 | |
US62/567,755 | 2017-10-03 | ||
PCT/US2018/053766 WO2019070588A1 (en) | 2017-10-03 | 2018-10-01 | Identifying the music as a particular song |
Publications (2)
Publication Number | Publication Date |
---|---|
JP2020537198A JP2020537198A (en) | 2020-12-17 |
JP7143327B2 true JP7143327B2 (en) | 2022-09-28 |
Family
ID=64024071
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2019563257A Active JP7143327B2 (en) | 2017-10-03 | 2018-10-01 | Methods, Computer Systems, Computing Systems, and Programs Implemented by Computing Devices |
Country Status (5)
Country | Link |
---|---|
US (3) | US10809968B2 (en) |
EP (1) | EP3679484A1 (en) |
JP (1) | JP7143327B2 (en) |
CN (1) | CN110622155A (en) |
WO (1) | WO2019070588A1 (en) |
Families Citing this family (14)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10962623B1 (en) | 2017-05-17 | 2021-03-30 | Heathkit Company, Inc. | Accurate and model-based measurement and management systems and methods |
CN110622155A (en) | 2017-10-03 | 2019-12-27 | 谷歌有限责任公司 | Identifying music as a particular song |
US11151464B2 (en) * | 2018-01-03 | 2021-10-19 | International Business Machines Corporation | Forecasting data based on hidden cycle evidence |
US10595083B2 (en) * | 2018-04-20 | 2020-03-17 | The Nielsen Company (Us), Llc | Methods and apparatus to determine audio source impact on an audience of media |
US11922006B2 (en) * | 2018-06-03 | 2024-03-05 | Apple Inc. | Media control for screensavers on an electronic device |
USD988349S1 (en) | 2019-08-22 | 2023-06-06 | Meta Platforms, Inc. | Display screen or portion thereof with a graphical user interface |
US11282509B1 (en) * | 2019-08-22 | 2022-03-22 | Facebook, Inc. | Classifiers for media content |
US11354900B1 (en) | 2019-08-22 | 2022-06-07 | Meta Platforms, Inc. | Classifiers for media content |
TWI727432B (en) * | 2019-09-24 | 2021-05-11 | 驊訊電子企業股份有限公司 | Singing scoring method and singing scoring system based on streaming media |
US11935520B1 (en) * | 2019-12-17 | 2024-03-19 | Auddia Inc. | Identifying shifts in audio content via machine learning |
US20220027407A1 (en) * | 2020-07-27 | 2022-01-27 | Audible Magic Corporation | Dynamic identification of unknown media |
SE544738C2 (en) * | 2020-12-22 | 2022-11-01 | Algoriffix Ab | Method and system for recognising patterns in sound |
US20230095263A1 (en) * | 2021-09-24 | 2023-03-30 | Apple Inc. | Devices, Methods, and Graphical User Interfaces For Interactions with a Headphone Case |
GB2612994A (en) * | 2021-11-18 | 2023-05-24 | Audoo Ltd | Media identification system |
Citations (8)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
WO2002065339A1 (en) | 2001-01-09 | 2002-08-22 | Fujitsu Limited | Multimedia information sorting/arranging device and sorting/arranging method |
WO2006004050A1 (en) | 2004-07-01 | 2006-01-12 | Nippon Telegraph And Telephone Corporation | System for detection section including particular acoustic signal, method and program thereof |
JP2008192102A (en) | 2007-02-08 | 2008-08-21 | Sony Computer Entertainment Inc | Metadata generation device and metadata generation method |
JP2010277023A (en) | 2009-06-01 | 2010-12-09 | Nippon Hoso Kyokai <Nhk> | Telephone voice section detector and program of the same |
JP2012185195A (en) | 2011-03-03 | 2012-09-27 | Jvc Kenwood Corp | Audio data feature extraction method, audio data collation method, audio data feature extraction program, audio data collation program, audio data feature extraction device, audio data collation device, and audio data collation system |
JP2016045859A (en) | 2014-08-26 | 2016-04-04 | 株式会社エクシング | Program for searching musical piece |
JP2017509009A (en) | 2014-01-07 | 2017-03-30 | クアルコム，インコーポレイテッド | Track music in an audio stream |
US20170178681A1 (en) | 2015-12-21 | 2017-06-22 | Invensense, Inc. | Music detection and identification |
Family Cites Families (32)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6816468B1 (en) | 1999-12-16 | 2004-11-09 | Nortel Networks Limited | Captioning for tele-conferences |
US7752546B2 (en) * | 2001-06-29 | 2010-07-06 | Thomson Licensing | Method and system for providing an acoustic interface |
AU2002346116A1 (en) * | 2001-07-20 | 2003-03-03 | Gracenote, Inc. | Automatic identification of sound recordings |
US7091409B2 (en) | 2003-02-14 | 2006-08-15 | University Of Rochester | Music feature extraction using wavelet coefficient histograms |
SG140445A1 (en) | 2003-07-28 | 2008-03-28 | Sony Corp | Method and apparatus for automatically recognizing audio data |
US7558729B1 (en) | 2004-07-16 | 2009-07-07 | Mindspeed Technologies, Inc. | Music detection for enhancing echo cancellation and speech coding |
US7130795B2 (en) | 2004-07-16 | 2006-10-31 | Mindspeed Technologies, Inc. | Music detection with low-complexity pitch correlation algorithm |
US8126706B2 (en) | 2005-12-09 | 2012-02-28 | Acoustic Technologies, Inc. | Music detector for echo cancellation and noise reduction |
US20100093393A1 (en) | 2007-04-23 | 2010-04-15 | Nils Graef | Systems and Methods for Music Recognition |
US8321217B2 (en) | 2007-05-22 | 2012-11-27 | Telefonaktiebolaget Lm Ericsson (Publ) | Voice activity detector |
US20100086107A1 (en) | 2008-09-26 | 2010-04-08 | Tzruya Yoav M | Voice-Recognition Based Advertising |
JP5282548B2 (en) | 2008-12-05 | 2013-09-04 | ソニー株式会社 | Information processing apparatus, sound material extraction method, and program |
US9405752B2 (en) | 2009-02-13 | 2016-08-02 | T-Mobile Usa, Inc. | System and method for automatically presenting a media file on a mobile device based on relevance to a user |
US8886531B2 (en) | 2010-01-13 | 2014-11-11 | Rovi Technologies Corporation | Apparatus and method for generating an audio fingerprint and using a two-stage query |
US8805683B1 (en) | 2012-02-24 | 2014-08-12 | Google Inc. | Real-time audio recognition protocol |
US9280599B1 (en) | 2012-02-24 | 2016-03-08 | Google Inc. | Interface for real-time audio recognition |
US8681950B2 (en) * | 2012-03-28 | 2014-03-25 | Interactive Intelligence, Inc. | System and method for fingerprinting datasets |
US20130318114A1 (en) * | 2012-05-13 | 2013-11-28 | Harry E. Emerson, III | Discovery of music artist and title by broadcast radio receivers |
US10424321B1 (en) | 2013-02-12 | 2019-09-24 | Google Llc | Audio data classification |
US20140337021A1 (en) | 2013-05-10 | 2014-11-13 | Qualcomm Incorporated | Systems and methods for noise characteristic dependent speech enhancement |
US9224385B1 (en) | 2013-06-17 | 2015-12-29 | Google Inc. | Unified recognition of speech and music |
US9002835B2 (en) | 2013-08-15 | 2015-04-07 | Google Inc. | Query response using media consumption history |
US9275427B1 (en) | 2013-09-05 | 2016-03-01 | Google Inc. | Multi-channel audio video fingerprinting |
JP6237230B2 (en) | 2013-12-27 | 2017-11-29 | 富士通株式会社 | Memory management program, memory management method, and memory management device |
US20150186509A1 (en) | 2013-12-30 | 2015-07-02 | Google Inc. | Power-efficient music playlist identification |
US9620105B2 (en) * | 2014-05-15 | 2017-04-11 | Apple Inc. | Analyzing audio input for efficient speech and music recognition |
CN107111642B (en) * | 2014-12-31 | 2020-12-18 | Pcms控股公司 | System and method for creating a listening log and a music library |
US10747498B2 (en) * | 2015-09-08 | 2020-08-18 | Apple Inc. | Zero latency digital assistant |
US10678828B2 (en) * | 2016-01-03 | 2020-06-09 | Gracenote, Inc. | Model-based media classification service using sensed media noise characteristics |
US20170039190A1 (en) | 2016-08-05 | 2017-02-09 | Joseph Ricardo | Two Way (+) Language Translation Communication Technology |
CN106782591B (en) * | 2016-12-26 | 2021-02-19 | 惠州Tcl移动通信有限公司 | Device and method for improving speech recognition rate under background noise |
CN110622155A (en) | 2017-10-03 | 2019-12-27 | 谷歌有限责任公司 | Identifying music as a particular song |
-
2018
- 2018-10-01 CN CN201880031926.3A patent/CN110622155A/en active Pending
- 2018-10-01 JP JP2019563257A patent/JP7143327B2/en active Active
- 2018-10-01 WO PCT/US2018/053766 patent/WO2019070588A1/en unknown
- 2018-10-01 US US16/148,338 patent/US10809968B2/en active Active
- 2018-10-01 EP EP18793726.3A patent/EP3679484A1/en not_active Ceased
- 2018-10-01 US US16/148,401 patent/US10761802B2/en active Active
-
2020
- 2020-09-02 US US17/010,694 patent/US11256472B2/en active Active
Patent Citations (8)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
WO2002065339A1 (en) | 2001-01-09 | 2002-08-22 | Fujitsu Limited | Multimedia information sorting/arranging device and sorting/arranging method |
WO2006004050A1 (en) | 2004-07-01 | 2006-01-12 | Nippon Telegraph And Telephone Corporation | System for detection section including particular acoustic signal, method and program thereof |
JP2008192102A (en) | 2007-02-08 | 2008-08-21 | Sony Computer Entertainment Inc | Metadata generation device and metadata generation method |
JP2010277023A (en) | 2009-06-01 | 2010-12-09 | Nippon Hoso Kyokai <Nhk> | Telephone voice section detector and program of the same |
JP2012185195A (en) | 2011-03-03 | 2012-09-27 | Jvc Kenwood Corp | Audio data feature extraction method, audio data collation method, audio data feature extraction program, audio data collation program, audio data feature extraction device, audio data collation device, and audio data collation system |
JP2017509009A (en) | 2014-01-07 | 2017-03-30 | クアルコム，インコーポレイテッド | Track music in an audio stream |
JP2016045859A (en) | 2014-08-26 | 2016-04-04 | 株式会社エクシング | Program for searching musical piece |
US20170178681A1 (en) | 2015-12-21 | 2017-06-22 | Invensense, Inc. | Music detection and identification |
Non-Patent Citations (3)
Title |
---|
井上 晋輔 ほか，聴覚障害者のための認知レベルに基づく効果音の視覚表現手法，電子情報通信学会技術研究報告，日本，社団法人電子情報通信学会，2006年03月15日，第105巻第681号，p. 13-17 |
柏野 邦夫 ほか，同じ音や映像を高速に探す技術―学習アクティブ探索法，ＮＴＴ Ｒ＆Ｄ，社団法人電気通信協会，2003年02月10日，第52巻第2号，p. 115-121 |
柏野 邦夫 ほか，時系列アクティブ探索法に基づく音や映像の高速ＡＮＤ／ＯＲ探索，ＮＴＴ Ｒ＆Ｄ，社団法人電気通信協会，2001年11月10日，第50巻第11号，p. 895-901 |
Also Published As
Publication number | Publication date |
---|---|
US20190102458A1 (en) | 2019-04-04 |
WO2019070588A1 (en) | 2019-04-11 |
EP3679484A1 (en) | 2020-07-15 |
US20200401367A1 (en) | 2020-12-24 |
US20190102144A1 (en) | 2019-04-04 |
US10809968B2 (en) | 2020-10-20 |
US11256472B2 (en) | 2022-02-22 |
US10761802B2 (en) | 2020-09-01 |
CN110622155A (en) | 2019-12-27 |
JP2020537198A (en) | 2020-12-17 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
JP7143327B2 (en) | Methods, Computer Systems, Computing Systems, and Programs Implemented by Computing Devices | |
US10839805B2 (en) | Disambiguating input based on context | |
US9646609B2 (en) | Caching apparatus for serving phonetic pronunciations | |
CN107112008B (en) | Prediction-based sequence identification | |
US9460209B1 (en) | Identifying non-search actions based on a search query | |
KR101894499B1 (en) | State-dependent query response | |
MX2012011426A (en) | Using context information to facilitate processing of commands in a virtual assistant. | |
US11575624B2 (en) | Contextual feedback, with expiration indicator, to a natural understanding system in a chat bot | |
KR20130116269A (en) | Loading a mobile computing device with media files | |
US20200380076A1 (en) | Contextual feedback to a natural understanding system in a chat bot using a knowledge model | |
US10528144B1 (en) | Adjusting movement of a display screen to compensate for changes in speed of movement across the display screen | |
AU2017100208B4 (en) | A caching apparatus for serving phonetic pronunciations |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20200615Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20200609 |
|
A621 | Written request for application examination |
Free format text: JAPANESE INTERMEDIATE CODE: A621Effective date: 20200609 |
|
A977 | Report on retrieval |
Free format text: JAPANESE INTERMEDIATE CODE: A971007Effective date: 20210528 |
|
A131 | Notification of reasons for refusal |
Free format text: JAPANESE INTERMEDIATE CODE: A131Effective date: 20210706 |
|
A601 | Written request for extension of time |
Free format text: JAPANESE INTERMEDIATE CODE: A601Effective date: 20211005 |
|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20211129 |
|
A131 | Notification of reasons for refusal |
Free format text: JAPANESE INTERMEDIATE CODE: A131Effective date: 20220510 |
|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20220728 |
|
TRDD | Decision of grant or rejection written | ||
A01 | Written decision to grant a patent or to grant a registration (utility model) |
Free format text: JAPANESE INTERMEDIATE CODE: A01Effective date: 20220816 |
|
A61 | First payment of annual fees (during grant procedure) |
Free format text: JAPANESE INTERMEDIATE CODE: A61Effective date: 20220914 |
|
R150 | Certificate of patent or registration of utility model |
Ref document number: 7143327Country of ref document: JPFree format text: JAPANESE INTERMEDIATE CODE: R150 |