JP2021177428A - On-device machine learning platform - Google Patents
On-device machine learning platform Download PDFInfo
- Publication number
- JP2021177428A JP2021177428A JP2021127571A JP2021127571A JP2021177428A JP 2021177428 A JP2021177428 A JP 2021177428A JP 2021127571 A JP2021127571 A JP 2021127571A JP 2021127571 A JP2021127571 A JP 2021127571A JP 2021177428 A JP2021177428 A JP 2021177428A
- Authority
- JP
- Japan
- Prior art keywords
- context
- training
- application
- computing device
- case
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/44—Arrangements for executing specific programs
- G06F9/445—Program loading or initiating
- G06F9/44505—Configuring for program initiating, e.g. using registry, configuration files
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N5/00—Computing arrangements using knowledge-based models
- G06N5/04—Inference or reasoning models
Abstract
Description
本開示は概して機械学習に関する。より詳細には、本開示は、オンデバイス予測、訓練、事例収集および/または他の機械学習タスクもしくは機能性を可能にするオンデバイス機械学習プラットフォームおよび関連技術に関する。 The present disclosure relates generally to machine learning. More specifically, the present disclosure relates to on-device machine learning platforms and related technologies that enable on-device prediction, training, case-gathering and / or other machine learning tasks or functionality.
近年、コンピューティングデバイスのユーザに改善されたサービスを提供するために、機械学習がますます使用されている。特に、多くのアプリケーションまたは他のコンピューティングプログラムもしくはシステムが1つまたは複数の機械学習済みモデルに依存して、プログラム、デバイスおよび/またはユーザと関連する入力データに基づいて推論を発生する。アプリケーションは推論を使用して、任意の種類のタスクもしくはサービスを行うまたはそれに影響を与えることができる。 In recent years, machine learning has been increasingly used to provide improved services to users of computing devices. In particular, many applications or other computing programs or systems rely on one or more machine-learned models to generate inferences based on the input data associated with the program, device and / or user. Applications can use inference to perform or influence any kind of task or service.
機械学習問題を解決するための1つの従来の訓練方式は、複数のコンピューティングデバイス(例えば、スマートフォンなどのユーザデバイス)から複数の訓練事例を集中位置(例えばサーバデバイス)において収集することを含む。収集した訓練事例に基づいて集中位置において次いで機械学習済みモデルを訓練できる。 One traditional training method for solving machine learning problems involves collecting multiple training cases from multiple computing devices (eg, user devices such as smartphones) in a centralized location (eg, server devices). Machine-learned models can then be trained in concentrated locations based on the training cases collected.
加えて、一部の実例では、訓練したモデルは集中位置において記憶できる。モデルから推論を受信するために、ユーザコンピューティングデバイスは、ネットワークを通じてサーバコンピューティングデバイスに入力データを送信し、サーバデバイスが機械学習済みモデルを実装して送信データに基づいて推論を発生するのを待ち、次いで再びネットワークを通じてサーバコンピューティングデバイスから推論を受信することが要求される。 In addition, in some examples, the trained model can be memorized in a concentrated position. To receive inferences from the model, the user computing device sends input data to the server computing device over the network, allowing the server device to implement a machine-learned model to generate inferences based on the transmitted data. It is required to wait and then again receive inferences from the server computing device over the network.
そのようなシナリオでは、訓練事例および/または推論は、ネットワークを通じてユーザコンピューティングデバイスとサーバコンピューティングデバイスとの間で送信されることが要求される。ネットワークを通じて送信されるデータは傍受を受けやすいので、そのようなネットワーク送信はデータセキュリティリスクを表す。加えて、そのようなネットワーク送信はネットワークトラフィックを増加させ、結果として低下された通信速度になり得る。更に、ネットワークを通じてデータを行ったり来たり送信することと関連する待ち時間は、アプリケーションのサービスを提供する際に遅延をもたらし得る。 In such a scenario, training cases and / or inferences are required to be transmitted between the user computing device and the server computing device over the network. Such network transmissions represent a data security risk, as data transmitted over the network is vulnerable to interception. In addition, such network transmissions can increase network traffic, resulting in reduced communication speeds. In addition, the latency associated with moving data back and forth over the network can result in delays in servicing the application.
最近では、或るアプリケーションが、アプリケーション内に記憶されてユーザデバイス上にアプリケーションによって実装される機械学習済みモデルを含んだ。しかしながら、このアーキテクチャは実装困難でもあり資源集約的でもある。例えば、そのようなシナリオでは、アプリケーションは、1つまたは複数の機械学習済みモデルを記憶、管理、訓練および/または実装することが要求される。アプリケーション自体内へのモデルおよび対応するサポートサービスの包含はアプリケーションのデータサイズを増加させ、結果としてより大きなメモリフットプリントになり得る。 More recently, an application has included a machine-learned model that is stored within the application and implemented by the application on the user device. However, this architecture is both difficult to implement and resource intensive. For example, in such a scenario, the application is required to store, manage, train and / or implement one or more machine-learned models. Inclusion of models and corresponding support services within the application itself can increase the data size of the application, resulting in a larger memory footprint.
アプリケーション内の機械学習は、より頻繁なアプリケーション更新も必要とし得る。例えば、アプリケーションは、基底となる機械学習エンジンが更新されるまたはさもなければ進化するにつれて更新される必要があり得る。アプリケーション更新は、更新がダウンロードおよびインストールされるときにユーザに対してネットワーク使用およびダウンタイムを望ましくなく必要とし得る。 Machine learning within an application may also require more frequent application updates. For example, an application may need to be updated as the underlying machine learning engine is updated or otherwise evolved. Application updates can undesirably require network usage and downtime for users when updates are downloaded and installed.
更には、アプリケーション内の機械学習は、追加のサービスがアプリケーション自体へ組み込まれる必要があるので、アプリケーション開発も複雑にし得る。このように、開発者は、種々の機械学習エンジンの複雑さを知って、それらに通じていることが要求されることがある。 Furthermore, in-application machine learning can complicate application development as additional services need to be built into the application itself. As such, developers may be required to be aware of and familiar with the intricacies of various machine learning engines.
本開示の実施形態の態様および利点は以下の説明に部分的に明らかにされることになる、または同説明から知ることができる、または実施形態の実施を通して知ることができる。 The embodiments and advantages of the embodiments of the present disclosure will be partially revealed in the following description, or can be found from the description, or can be found through the implementation of the embodiments.
本開示の1つの態様は、コンピューティングデバイスを対象とする。コンピューティングデバイスは、1つまたは複数のプロセッサと、1つまたは複数の非一時的コンピュータ可読媒体とを含む。1つまたは複数の非一時的コンピュータ可読媒体は、1つまたは複数のプロセッサによって実装される1つまたは複数のアプリケーションと、1つまたは複数のアプリケーションから受け取られる訓練事例を記憶する集中事例データベースと、1つまたは複数のプロセッサによって実行されると、コンピューティングデバイスに、動作を行うオンデバイス機械学習プラットフォームを実装させる命令とを記憶する。同動作は、収集アプリケーションプログラミングインタフェースを介して1つまたは複数のアプリケーションのうちの第1のアプリケーションから新たな訓練事例を受け取ることを含む。同動作は、コンピューティングデバイスと関連するコンテキストを記述した1つまたは複数のコンテキスト特徴を決定することを含む。同動作は、コンピューティングデバイスによって記憶される機械学習済みモデルを訓練する際の使用のために集中事例データベースに1つまたは複数のコンテキスト特徴と共に新たな訓練事例を記憶することを含む。 One aspect of the disclosure is directed to computing devices. Computing devices include one or more processors and one or more non-transitory computer-readable media. One or more non-temporary computer-readable media include one or more applications implemented by one or more processors, and a centralized case database that stores training cases received from one or more applications. When executed by one or more processors, it stores instructions that cause a computing device to implement an on-device machine learning platform that operates. The operation involves receiving a new training case from the first application of one or more applications via the collection application programming interface. The behavior involves determining one or more context features that describe the context associated with the computing device. The behavior involves storing new training cases with one or more context features in a centralized case database for use in training machine-learned models stored by computing devices.
本開示の別の態様は、1つまたは複数のプロセッサによって実行されると、コンピューティングデバイスに、動作を行うオンデバイス機械学習プラットフォームを実装させる命令を記憶する1つまたは複数の非一時的コンピュータ可読媒体を対象とする。同動作は、予測アプリケーションプログラミングインタフェースを介してコンピューティングデバイスに記憶される1つまたは複数のアプリケーションのうちの第1のアプリケーションから入力データを受け取ることを含む。同動作は、コンピューティングデバイスと関連するコンテキストを記述した1つまたは複数のコンテキスト特徴を決定することを含む。同動作は、コンピューティングデバイスに記憶される1つまたは複数の機械学習済みモデルのうちの少なくとも第1の機械学習済みモデルを利用して、入力データに少なくとも部分的に基づいてかつ更に1つまたは複数のコンテキスト特徴に少なくとも部分的に基づいて少なくとも1つの推論を生成することを含む。同動作は、予測アプリケーションプログラミングインタフェースを介して第1のアプリケーションに第1の機械学習済みモデルによって生成される少なくとも1つの推論を提供することを含む。 Another aspect of the disclosure is one or more non-transitory computer readables that, when executed by one or more processors, store instructions that cause a computing device to implement an on-device machine learning platform that operates. Target the medium. The behavior involves receiving input data from a first of one or more applications stored in a computing device via a predictive application programming interface. The behavior involves determining one or more context features that describe the context associated with the computing device. The behavior utilizes at least the first machine-learned model of one or more machine-learned models stored in the computing device and is at least partially based on the input data and one more or more. Includes generating at least one inference based on at least partly based on multiple context features. The behavior involves providing the first application with at least one inference generated by the first machine-learned model via the predictive application programming interface.
本開示の別の態様は、コンピュータで実行される方法を対象とする。本方法は、収集アプリケーションプログラミングインタフェースを介してコンピューティングデバイスによって、コンピューティングデバイスによって記憶される1つまたは複数のアプリケーションのうちの第1のアプリケーションから新たな訓練事例を受け取ることを含む。本方法は、コンピューティングデバイスによって、コンピューティングデバイスと関連するコンテキストを記述した1つまたは複数のコンテキスト特徴を決定することを含む。本方法は、コンピューティングデバイスによって、コンピューティングデバイスによって記憶される機械学習済みモデルを訓練する際の使用のためにコンピューティングデバイスの集中事例データベースに1つまたは複数のコンテキスト特徴と共に新たな訓練事例を記憶することを含む。 Another aspect of the disclosure is directed to a method performed on a computer. The method comprises receiving a new training case from a first application of one or more applications stored by the computing device by the computing device via a collection application programming interface. The method comprises determining by a computing device one or more context features that describe the context associated with the computing device. This method provides a centralized case database of computing devices with new training cases with one or more contextual features for use in training machine-learned models stored by the computing device. Including remembering.
本開示の他の態様は、様々なシステム、装置、非一時的コンピュータ可読媒体、ユーザインタフェースおよび電子デバイスを対象とする。 Other aspects of the disclosure cover a variety of systems, devices, non-transient computer-readable media, user interfaces and electronic devices.
本開示の様々な実施形態のこれらおよび他の特徴、態様および利点は、以下の説明および添付の請求項を参照しつつよりよく理解されるようになるであろう。添付図面は、本明細書に組み込まれてその一部を構成するが、本開示の実施形態例を例示し、かつ説明と共に、関連原理を説明する役目をする。 These and other features, aspects and advantages of the various embodiments of the present disclosure will be better understood with reference to the following description and the accompanying claims. The accompanying drawings, which are incorporated herein by reference and constitute a portion thereof, serve as an example of embodiments of the present disclosure, and together with explanations, explain related principles.
当業者を対象とする実施形態の詳細な考察が、添付の図を参照しつつ、本明細書に明らかにされる。 A detailed discussion of embodiments intended for those of skill in the art is provided herein with reference to the accompanying figures.
概して、本開示は、オンデバイス機械学習のためのシステムおよび方法を対象とする。特に、本開示は、「機械学習機能」と集合的に称されてよい、オンデバイス予測、訓練、事例収集および/または他の機械学習タスクもしくは機能性を可能にするオンデバイス機械学習プラットフォームおよび関連技術を対象とする。 In general, the present disclosure covers systems and methods for on-device machine learning. In particular, the disclosure is an on-device machine learning platform and association that enables on-device prediction, training, case-gathering and / or other machine learning tasks or functionality, collectively referred to as "machine learning capabilities." Target technology.
オンデバイス機械学習プラットフォームは、コンピューティングデバイスまたは端末(例えば、スマートフォンまたはタブレット)にローカルに記憶される1つまたは複数のコンピュータプログラムの形態でよく、それらは、ユーザデバイスまたは端末によって実行されると、1つまたは複数のローカルに記憶されるアプリケーション、ルーチンまたは他のローカルクライアントのためのオンデバイス機械学習機能の遂行を可能にする機械学習管理動作を行うように構成される。オンデバイス機械学習機能の少なくとも一部は、コンピューティングデバイスまたは端末にローカルに実装される1つまたは複数の機械学習エンジンを使用して行われてよい。1つまたは複数のローカルに記憶されるアプリケーションまたはルーチン(「クライアント」と称されてよい)のためのオンデバイス機械学習機能の遂行は、それらのクライアントへの集中サービスとして提供されてよく、それらは1つまたは複数のアプリケーションプログラミングインタフェース(API)を介してオンデバイス機械学習プラットフォームと対話してよい。 On-device machine learning platforms may be in the form of one or more computer programs stored locally on a computing device or terminal (eg, a smartphone or tablet), and when they are executed by the user device or terminal, It is configured to perform machine learning management operations that allow the performance of on-device machine learning functions for one or more locally stored applications, routines or other local clients. At least some of the on-device machine learning capabilities may be performed using one or more machine learning engines implemented locally on the computing device or terminal. Performing on-device machine learning capabilities for one or more locally stored applications or routines (which may be referred to as "clients") may be provided as a centralized service to those clients. You may interact with the on-device machine learning platform through one or more application programming interfaces (APIs).
加えて、一部の実装例では、オンデバイス機械学習プラットフォームは、予測/推論を生成するために使用される収集した訓練事例および/またはクライアント提供の入力データへコンテキスト特徴を確実に注入するコンテキストプロバイダを含むことができる。このように、オンデバイス機械学習プラットフォームは、アプリケーションまたは他のクライアントへのサービスとして集中訓練事例収集、モデル訓練および機械学習済みモデルの使用を可能にすることができる。 In addition, in some implementations, the on-device machine learning platform ensures that contextual features are injected into the collected training cases and / or client-supplied input data used to generate predictions / inferences. Can be included. In this way, the on-device machine learning platform can enable intensive training case collection, model training and the use of machine learning models as a service to applications or other clients.
より詳細には、例えば、モバイルコンピューティングデバイス(例えば、スマートフォン)などのコンピューティングデバイスが1つまたは複数のアプリケーション(例えば、モバイルアプリケーション)を記憶するまたはその他含むことができる。コンピューティングデバイスは、オンデバイス機械学習プラットフォームおよび1つまたは複数の機械学習済みモデルも含むおよび実装することができる。例えば、機械学習済みモデルは、プラットフォームによって管理される集中モデル層にデバイスによって記憶できる。 More specifically, a computing device, such as a mobile computing device (eg, a smartphone), may store or include one or more applications (eg, a mobile application). Computing devices can also include and implement on-device machine learning platforms and one or more machine-learned models. For example, a machine-learned model can be stored by a device in a centralized model layer managed by the platform.
本開示の1つの態様によれば、アプリケーションは、API(「予測API」と称されてよい)を介してオンデバイス機械学習プラットフォームと通信して、入力データを提供し、そして機械学習済みモデルの1つまたは複数から入力データに基づいて予測を得ることができる。一例として、一部の実装例では、予測プラン(例えば、モデルを走らせて推論/予測を得るための命令)およびモデルパラメータに対する統一資源識別子(URI)が与えられると、オンデバイス機械学習プラットフォームは、URI内容(例えば、予測プランおよびパラメータ)をダウンロードし、そしてモデルを走らせることによって(例えば、機械学習エンジンと対話してエンジンによるモデルの実装をもたらすことによって)1つまたは複数の推論/予測を得ることができる。加えて、プラットフォームは、同内容が以降の予測要求に対して使用できるようにそれをキャッシュできる。 According to one aspect of the disclosure, the application communicates with an on-device machine learning platform via an API (sometimes referred to as a "predictive API") to provide input data, and of a machine-learned model. Predictions can be obtained from one or more based on the input data. As an example, in some implementations, given a predictive plan (eg, an instruction to run a model to get inferences / predictions) and a Unified Resource Identifier (URI) for model parameters, the on-device machine learning platform Make one or more inferences / predictions by downloading the URI content (eg, prediction plans and parameters) and running the model (eg, by interacting with the machine learning engine to bring the engine to implement the model). Obtainable. In addition, the platform can cache it for future forecast requests.
このように、オンデバイス機械学習済みモデルは、アプリケーションによってクライアント/サービス関係を介してオンデバイス機械学習プラットフォームと通信することによってアクセスできる。特に、一部の実装例では、機械学習プラットフォームは、アプリケーションによって参照できるスタンドアロンマルチテナントサービスであることができる。そのため、所与のアプリケーションは、機械学習済みモデルを記憶、管理、訓練および/または実装することは要求されず、代わりに単にオンデバイス機械学習プラットフォームと通信して、モデルに推論を要求して受け取れる。 In this way, the on-device machine learning model can be accessed by the application by communicating with the on-device machine learning platform via a client / service relationship. In particular, in some implementations, the machine learning platform can be a stand-alone multi-tenant service that can be referenced by the application. As such, a given application is not required to store, manage, train and / or implement a machine-learned model, but instead simply communicate with the on-device machine learning platform to request and receive inferences from the model. ..
本開示の別の態様によれば、コンピューティングデバイスは、1つまたは複数のアプリケーションから受け取られる訓練事例を記憶する集中事例データベースをさらに含むことができる。特に、オンデバイス機械学習プラットフォームは、API(「収集API」と称されてよい)を介してアプリケーションから訓練事例を受け取ることができ、そして集中事例データベースにおける事例の記憶を管理できる。例えば、プラットフォームのクライアントまたはテナントである各アプリケーションは、集中事例データベース内に記憶されるそれ自身の事例の集合を有することができ、そして同集合はオンライン方式で補足および/または管理できる。 According to another aspect of the disclosure, the computing device may further include a centralized case database that stores training cases received from one or more applications. In particular, on-device machine learning platforms can receive training cases from applications via APIs (sometimes referred to as "collection APIs") and can manage case memory in a centralized case database. For example, each application that is a client or tenant of the platform can have its own set of cases stored in a centralized case database, which can be supplemented and / or managed online.
一部の実装例では、オンデバイス機械学習プラットフォームは、訓練事例を提供するアプリケーションと関連する1つまたは複数のオプションパラメータに従ってアプリケーションから受け取られる各訓練事例の記憶(例えば、その対応する集合内の)をもたらすことができる。1つの例として、オプションパラメータは、訓練事例が記憶される(例えば、更にその後に削除される)期間を定義する生存時間パラメータを含むことができる。一部の実装例では、オプションパラメータは、収集APIを介してプラットフォームに提供される命令を通じて予め定義および/または調整できる。 In some implementations, the on-device machine learning platform remembers each training case (eg, in its corresponding set) received from the application according to one or more optional parameters associated with the application providing the training case. Can be brought. As an example, the optional parameter can include a time-to-live parameter that defines how long the training case is stored (eg, deleted afterwards). In some implementations, optional parameters can be predefined and / or adjusted through instructions provided to the platform via the collection API.
本開示の別の態様によれば、一部の実装例では、オンデバイス機械学習プラットフォームは、訓練事例へコンピューティングデバイスと関連するコンテキストを記述したコンテキスト特徴を確実に注入できる。例えば、アプリケーションから訓練事例を受け取った上で、オンデバイスプラットフォームのコンテキストプロバイダコンポーネントが1つまたは複数のコンテキスト特徴を決定でき、そして集中事例データベースに訓練事例と共にそのようなコンテキスト特徴を記憶できる。例えば、コンテキスト特徴および新たな訓練事例に提供されるデータは単一のデータベースエントリとして記憶できる。特定のアプリケーションから受け取られる訓練事例と共に決定されて次いで注入もしくはその他関連付けおよび/または記憶される特定のコンテキスト特徴は、そのような特定のアプリケーションに対するオプションパラメータによって特定できる。上記したように、これらのオプション特徴は収集APIを介して調整または予め定義できる。このように、アプリケーションは、どのコンテキスト特徴またはコンテキスト型がその訓練事例へ注入されるかを制御できる(例えば、オプションパラメータを定義することを介して)。 According to another aspect of the disclosure, in some implementations, the on-device machine learning platform can reliably inject contextual features that describe the context associated with the computing device into the training case. For example, upon receiving a training case from an application, the on-device platform context provider component can determine one or more context features, and the centralized case database can store such context features along with the training case. For example, contextual features and data provided for new training cases can be stored as a single database entry. Specific contextual features that are determined along with the training case received from a particular application and then injected or otherwise associated and / or stored can be identified by optional parameters for such particular application. As mentioned above, these optional features can be tuned or predefined via the collection API. In this way, the application can control which context features or types are injected into the training case (eg, through defining optional parameters).
一部の実装例では、コンテキスト特徴はサービス側で注入され、そのためコンテキスト特徴は、アプリケーションに直接利用可能になる必要は決してない。特に、一部の実装例では、集中事例データベースは1つまたは複数のアプリケーションによって直接アクセス可能でなく、そのため特定の訓練事例と共に記憶されるコンテキスト情報は、同訓練事例を提供したアプリケーションにさえアクセス可能でない。 In some implementations, context features are injected on the service side, so context features never need to be directly available to the application. In particular, in some implementations, the centralized case database is not directly accessible by one or more applications, so the contextual information stored with a particular training case is not even accessible to the application that provided the training case. ..
一部の実装例では、コンテキスト特徴は、幾つかの異なるコンテキスト型に従ってグループ化またはその他分類できる。一般に、各コンテキスト型は、周知の名前および周知の型を持つ一組のコンテキスト特徴を特定するまたは含むことができる。1つのコンテキスト型例は、以下のコンテキスト特徴例を含むデバイス情報である:音声状態、ネットワーク状態、電力接続等。 In some implementations, context features can be grouped or otherwise classified according to several different context types. In general, each context type can identify or include a set of context features with a well-known name and well-known type. One context type example is device information that includes the following context feature examples: voice state, network state, power connection, etc.
一部の実装例では、コンテキストプロバイダは、注入時/点でデバイスに(例えば、デバイスのコンテキストマネージャに)所与のコンテキスト特徴に対して注入される値を要求する。代替的または追加的に、コンテキストプロバイダは、1つまたは複数のコンテキスト更新のリスナとして登録でき、そして1つまたは複数のコンテキスト更新に基づいてコンテキスト特徴に対する現在値のコンテキスト特徴キャッシュを維持できる。次いで、コンテキスト特徴が注入されるとき、コンテキストプロバイダは単に、コンテキスト特徴キャッシュにアクセスし、そして特定のコンテキスト特徴に対するキャッシュに維持される現在値を注入できる。 In some implementations, the context provider requires a value to be injected into the device (eg, the device's context manager) at injection time / point for a given context feature. Alternatively or additionally, the context provider can register as a listener for one or more context updates, and can maintain a current context feature cache for context features based on one or more context updates. Then, when the context feature is injected, the context provider can simply access the context feature cache and inject the current value maintained in the cache for a particular context feature.
記憶時の訓練事例へのコンテキスト特徴の注入に加えてまたは代替的に、コンテキストプロバイダは、推論時のコンテキスト特徴の注入も行える。特に、訓練事例収集のための上記したプロセスに類似して、特定のアプリケーションまたは他のクライアントが或るクライアント提供の入力データを基礎として推論が生成されることを要求すると(例えば、予測APIを介して)、コンテキストプロバイダは、入力データと一緒に対応する機械学習済みモデルへの入力のための補足的コンテキスト特徴を注入または提供できる。このように、クライアント提供の入力データに加えてコンテキスト情報に少なくとも部分的に基づいて推論を行うことができ、これは推論の精度を改善するのを促進できる。 In addition to or as an alternative to injecting contextual features into the training case during memory, the context provider can also inject contextual features during inference. In particular, similar to the process described above for training case collection, when a particular application or other client requires that inferences be generated based on input data provided by a client (eg, via a predictive API). The context provider can inject or provide complementary context features for input to the corresponding machine-learned model along with the input data. In this way, inferences can be made at least partially based on contextual information in addition to client-provided input data, which can help improve the accuracy of inferences.
重要なことには、本明細書に記載される訓練事例およびコンテキスト特徴は単に、訓練事例と共に記憶され得るまたはオンデバイスプラットフォームによって推論を提供するために使用され得るデータ例を例示する目的で与えられる。しかしながら、そのようなデータは、どんなデータが収集されてそのようなデータがどのように使用されるかが通知された後にユーザが同意を与えない限り、収集、使用または分析されない。更に、ユーザには、許可の範囲を破棄または修正するツールを与えることができる。加えて、或る情報またはデータは、それが記憶または使用される前に1つまたは複数の仕方で処理でき、その結果、個人識別可能情報は除去されるまたは暗号化されて記憶される。 Importantly, the training cases and contextual features described herein are provided solely for the purpose of exemplifying data examples that can be stored with the training cases or used to provide inference by the on-device platform. .. However, such data will not be collected, used or analyzed unless the user gives consent after being notified of what data is collected and how such data will be used. In addition, the user can be provided with a tool to revoke or modify the scope of permission. In addition, certain information or data can be processed in one or more ways before it is stored or used, so that personally identifiable information is removed or encrypted and stored.
別の態様によれば、或るアプリケーションまたは他のクライアントがコンテキスト特徴またはコンテキスト型の幾つかのみにアクセスする許可を有してよいので(例えば、デバイスユーザによって定義または制御されるように)、コンテキストプロバイダはクライアント許可制御を行える。特に、一部の実装例では、オンデバイス機械学習プラットフォームまたは他のデバイスコンポーネントは、どのクライアントがどのコンテキスト型にアクセスする許可を有するかのマッピングを維持できる。コンテキスト特徴が注入されることになるとき(例えば、記憶のための訓練事例へか、推論時にクライアント提供の入力データを補足するためか)、コンテキストプロバイダは、注入されることになるコンテキスト特徴またはコンテキスト型に対する対応するアプリケーションまたは他のクライアントの許可状況を確認できる。例えば、特定のアプリケーションおよびコンテキスト型に対する許可状況は、そのようなアプリケーションがそのようなコンテキスト型にアクセスする許可を有するかどうかを説明できる。コンテキストプロバイダは、アプリケーションがアクセスする許可を有するコンテキスト型に含まれるコンテキスト特徴のみを注入することになり、それによってアプリケーションが、それがアクセスする許可を有しないコンテキスト特徴/型にアクセスするのを(間接的な方式でさえ)防止する。 According to another aspect, the context because an application or other client may have permission to access only some of the context features or context types (eg, as defined or controlled by the device user). The provider can control client permissions. In particular, in some implementations, the on-device machine learning platform or other device component can maintain a mapping of which clients have permission to access which context type. When a context feature is to be injected (for example, to a training case for memory or to supplement client-supplied input data during inference), the context provider will inject the context feature or context to be injected. You can check the permission status of the corresponding application or other client for the type. For example, the permission status for a particular application and context type can explain whether such application has permission to access such context type. The context provider will only inject context features contained in the context type that the application has permission to access, thereby preventing the application from accessing the context feature / type that the application does not have permission to access (indirect). (Even the traditional method) to prevent.
上記した生存時間オプションパラメータに類似して、一部の実装例では、各コンテキスト特徴は、それと関連するまたはそれに割り当てられる満了期間を有することができる。この満了期間情報は、コンテキスト特徴を含む各訓練事例と関連付けできる。一部の実装例では、特定の訓練事例に提供される特定のコンテキスト特徴に対する満了期間の終結において、そのようなコンテキスト特徴に対する値はそのような訓練事例から削除またはその他除去できる。代替的に、訓練事例全体が削除またはその他除去できる。 Similar to the time-to-live option parameter described above, in some implementations each context feature can have an expiration period associated with it or assigned to it. This expiration period information can be associated with each training case, including contextual features. In some implementations, at the end of the expiration period for a particular context feature provided for a particular training case, the value for such context feature can be removed or otherwise removed from such training case. Alternatively, the entire training case can be deleted or otherwise removed.
更には、一部の実装例では、特定のコンテキスト特徴またはコンテキスト型に対する特定のアプリケーションまたは他のクライアントに対する許可状況の変化に応じて、オンデバイスプラットフォームは、特定のアプリケーションと関連する訓練事例と関連付けられるそのようなコンテキスト特徴または型に対するいかなる値またはエントリも集中事例データベースから削除できる。加えて、一部の実装例では、対応するモデルは、コンテキスト特徴値の削除後に残りのデータで再訓練できる。 Furthermore, in some implementations, the on-device platform is associated with training cases associated with a particular application, in response to changes in permission status for a particular application or other client for a particular context feature or context type. Any value or entry for such a context feature or type can be deleted from the centralized case database. In addition, in some implementations, the corresponding model can be retrained with the rest of the data after removing the context feature values.
本開示の更に別の態様によれば、アプリケーションは、API(「訓練API」と称されてよい)を介してオンデバイス機械学習プラットフォームと通信して、集中事例データベースに記憶される訓練事例に基づいて機械学習済みモデルの再訓練または更新をもたらすことができる。一例として、一部の実装例では、訓練プラン(例えば、モデルを訓練するための命令)に対するURIが与えられると、オンデバイス機械学習プラットフォームは、以前に収集した事例に基づいてモデルの訓練を行える(例えば、機械学習エンジンと対話してエンジンによるモデルの訓練をもたらすことによって)。例えば、訓練は、予定時におよび/またはデバイスがアイドルであるときにバックグラウンドで行える。 According to yet another aspect of the disclosure, the application communicates with the on-device machine learning platform via an API (sometimes referred to as a "training API") and is based on training cases stored in a centralized case database. Can result in retraining or updating of machine-learned models. As an example, in some implementations, given a URI for a training plan (eg, an instruction to train a model), the on-device machine learning platform can train the model based on previously collected cases. (For example, by interacting with a machine learning engine to train the model with the engine). For example, training can be done at the scheduled time and / or in the background when the device is idle.
モデルの再訓練後に、再訓練済みモデルは、本明細書に他の場所で記載されるように推論を提供するために使用できる。典型的に、モデルがユーザに固有であるデータで再訓練されたので、これらの推論はより高い精度を有することになる。このように、オンデバイス機械学習プラットフォームは、アプリケーションまたは他のクライアントへのサービスとして集中事例データ収集および機械学習済みモデルの対応する個別化を可能にすることができる。 After retraining the model, the retrained model can be used to provide inference as described elsewhere herein. Typically, these inferences will have higher accuracy as the model has been retrained with user-specific data. In this way, the on-device machine learning platform can enable centralized case data collection and corresponding personalization of machine learning models as a service to applications or other clients.
別の態様によれば、一部の実装例では、機械学習プラットフォームは、機械学習メトリックの詳細な分析のためにクラウドに機械学習済みモデルに関するログまたは他の更新をアップロードできる。一例として、一部の実装例では、オンデバイスプラットフォームは、再訓練した機械学習済みモデルのパラメータまたはモデルの再訓練中に発生した機械学習済みモデルのパラメータの変更を記述する更新を決定できる。プラットフォームは、他のコンピューティングデバイスによって提供される他の更新との集約のために中央サーバコンピューティングデバイス(例えば、「クラウド」)に更新を送信できる。このように、プラットフォームは、「連合学習」として知られるプロセスへの参加を可能にすることができ、そこではデバイスが、ローカルに記憶されるデータに基づいてモデルのローカルな更新を決定し、次いで集約のためにクラウドサービスにローカルな更新を伝達して(例えば、プライバシーを保護し通信効率的な方式で)モデルのグローバルな更新を生成する。 According to another aspect, in some implementations, the machine learning platform can upload logs or other updates about machine learning models to the cloud for detailed analysis of machine learning metrics. As an example, in some implementations, the on-device platform can determine updates that describe changes in the parameters of the retrained machine-learned model or the parameters of the machine-learned model that occurred during model retraining. The platform can send updates to a central server computing device (eg, the "cloud") for aggregation with other updates provided by other computing devices. In this way, the platform can allow participation in a process known as "federated learning", where the device decides to update the model locally based on locally stored data, and then Propagate local updates to cloud services for aggregation (eg, in a privacy-friendly and communication-efficient manner) to generate global updates for the model.
別の態様によれば、一部の実装例では、アプリケーションを互いから保護するために、各アプリケーションは、オンデバイスプラットフォームによって与えられる或る機能性のための(例えば、機能性ごとの)それ自身の孤立領域を有することができる。例えば、プラットフォームは、プラットフォームにアクセスするためのインタフェースがファクトリを介してアプリケーションに返される前に、アプリケーションを認証できる。返されたインタフェースは、その場合プラットフォームにおけるアプリケーションの孤立領域の唯一のビューを表せる。このプロセスの1つの実装例では、アプリケーションがプラットフォームのAPIに接続するとき、アプリケーションは、アプリケーションの識別情報を検証する署名済みパッケージトークンを提供できる。アプリケーションは、この認証に合格することなくAPIインタフェースを得ることはできない。 According to another aspect, in some implementations, in order to protect the applications from each other, each application is itself for some functionality (eg, per functionality) provided by the on-device platform. Can have an isolated area of. For example, the platform can authenticate the application before the interface for accessing the platform is returned to the application through the factory. The returned interface can then represent the only view of the isolated area of the application on the platform. In one implementation of this process, when an application connects to the platform's API, the application can provide a signed package token that validates the application's identity. The application cannot get the API interface without passing this authentication.
本開示の別の態様によれば、一部の実装例では、オンデバイス機械学習プラットフォームは、基底となる機械学習エンジンから完全に抽象化できる。例えば、機械学習エンジンは、TensorFlowエンジン、ニューラルネットワークライブラリ、または推論および/もしくは訓練のための機械学習済みモデルの実装を可能にする他のエンジンであることができる。そのような抽象化のため、機械学習プラットフォームはモデルアーチファクトを、クラウドにおいて発生され、次いでデバイスに送られる(例えば、動的モデルダウンロードを介して)ブロブとみなすことができ、ここで、それらは次いでマッチングエンジンによって解釈される。そのような方式では、機械学習プラットフォームおよびそのサポートされるアプリケーションは、機械学習エンジンの変更に対して弾力的であり、かつ/または利用される特定のエンジンもしくはエンジン型に非依存/柔軟であることができる。 According to another aspect of the disclosure, in some implementations, the on-device machine learning platform can be completely abstracted from the underlying machine learning engine. For example, a machine learning engine can be a TensorFlow engine, a neural network library, or any other engine that allows the implementation of machine-learned models for inference and / or training. Due to such an abstraction, machine learning platforms can consider model artifacts as blobs that occur in the cloud and then sent to the device (eg, via dynamic model download), where they then Interpreted by the matching engine. In such a scheme, the machine learning platform and its supported applications are flexible to changes in the machine learning engine and / or independent / flexible of the particular engine or engine type used. Can be done.
別の態様によれば、オンデバイスプラットフォームに補完的であるツールキットが、デバイスにモデルがアーチファクトとして送られる前にクラウドにおいてそれらを作成およびシミュレートする一組のツール(例えば、Pythonツール)を提供できる。一部の実装例では、ツールキットは、異なるバージョンの機械学習エンジン、または異なるエンジン型(例えば、モバイル向けTensorFlow Lite対ニューラルネットワークライブラリ等)に対してさえ同じソースアーチファクト(例えば、Pythonソースアーチファクト)から生成できる。 In another aspect, a toolkit that is complementary to the on-device platform provides a set of tools (eg, Python tools) that create and simulate models in the cloud before they are sent to the device as artifacts. can. In some implementations, the toolkit is from different versions of machine learning engines, or even from the same source artifacts (eg Python source artifacts) even for different engine types (eg TensorFlow Lite vs. neural network libraries for mobile). Can be generated.
一部の実装例では、オンデバイス機械学習プラットフォームは、例えば、モバイルアプリケーションなどのアプリケーションに含めることが、またはそれとして実装することができる。例えば、Androidオペレーティングシステムのコンテキストでは、オンデバイス機械学習プラットフォームは、ダウンロードおよび/または更新できるAndroidパッケージキット(APK)に含めることができる。1つの特定の例では、オンデバイス機械学習プラットフォームは、他のアプリケーションまたはデバイス自体に幾つかの異なるサポートサービスを提供するより大きなアプリケーションの一部分に含めることが、またはそれとして実装することができる。例えば、オンデバイス機械学習プラットフォームに加えて、より大きなアプリケーションは、コンピューティングデバイスがデジタル配信サービス(例えば、「アプリストア」からアプリケーションおよび/もしくは更新をダウンロードする)ならびに/または他のサービスと対話することを可能にするサービスを提供できる。別の例では、オンデバイス機械学習プラットフォームは、スタンドアロンアプリケーションとしてよりもむしろ、デバイスのオペレーティングシステムの一部分に含めることが、またはそれとして実装することができる。 In some implementation examples, the on-device machine learning platform can be included in or implemented as an application, for example, a mobile application. For example, in the context of the Android operating system, on-device machine learning platforms can be included in Android Package Kits (APKs) that can be downloaded and / or updated. In one particular example, the on-device machine learning platform can be included or implemented as part of a larger application that provides several different support services to other applications or the device itself. For example, in addition to on-device machine learning platforms, larger applications allow computing devices to interact with digital distribution services (eg, downloading applications and / or updates from the "app store") and / or other services. Can provide services that enable. In another example, the on-device machine learning platform can be included or implemented as part of the device's operating system rather than as a stand-alone application.
本開示のシステムおよび方法は幾つかの技術的効果および利益を提供する。1つの技術的効果および利益例として、オンデバイス機械学習プラットフォームは、ローカルに記憶されるデバイス固有の訓練事例に基づいて機械学習済みモデルの個別化を可能にすることができ、それによって、より高精度の推論に至る。類似して、本明細書に他の場所で記載されるように、オンデバイスプラットフォームは、「連合学習」へのデバイスの参加を可能にすることができ、そこではローカルな更新が集約されてグローバルな更新を生成し、それによって全ての個人に対して改善されたグローバルなモデル精度に至る。 The systems and methods of the present disclosure provide some technical benefits and benefits. As an example of technical benefits and benefits, on-device machine learning platforms can enable personalization of machine-learned models based on locally stored device-specific training cases, thereby higher. It leads to inference of accuracy. Similarly, as described elsewhere herein, on-device platforms can allow devices to participate in "federated learning", where local updates are aggregated and global. Updates, thereby leading to improved global model accuracy for all individuals.
別の技術的効果および利益例として、オンデバイス機械学習プラットフォームは、訓練事例および/または推論入力へのコンテキスト信号の確実な包含を可能にすることができる。すなわち、プライバシーを維持し、かつユーザ定義の許可を遵守する方式で訓練事例または推論入力にコンテキスト特徴を付加できる。コンテキスト情報の包含を通して、機械学習済みモデルによって提供される推論の精度が改善できる。 As another technical benefit and benefit example, on-device machine learning platforms can enable reliable inclusion of context signals in training cases and / or inference inputs. That is, contextual features can be added to training cases or inference inputs in a manner that maintains privacy and complies with user-defined permissions. Through the inclusion of contextual information, the accuracy of the inference provided by the machine-learned model can be improved.
別の技術的効果および利益例として、オンデバイス機械学習プラットフォームは、アプリケーションが機械学習済みモデルを管理(例えば、訓練および/もしくは実行)するまたは機械学習エンジンと対話する必要がないように集中サービスを提供できる。そのため、所与のアプリケーションは、機械学習済みモデルを記憶、管理、訓練および/または実装することは要求されず、代わりに単にオンデバイス機械学習プラットフォームと通信して、モデルに推論を要求して受け取れる。これは、アプリケーションのデータサイズが小さくなることを可能にすることができる。アプリケーション開発者が各異なる機械学習エンジンの複雑さを知ることを要求されず、代わりに単にプラットフォームAPIの使用に依存できるので、アプリケーションまたは他のクライアントの開発および展開も単純化できる。 As another technical benefit and benefit example, on-device machine learning platforms provide centralized services so that applications do not have to manage (eg, train and / or run) machine-learned models or interact with machine learning engines. Can be provided. As such, a given application is not required to store, manage, train and / or implement a machine-learned model, but instead simply communicate with the on-device machine learning platform to request and receive inferences from the model. .. This can allow the data size of the application to be reduced. It also simplifies the development and deployment of applications or other clients, as application developers are not required to know the complexity of each different machine learning engine and can instead simply rely on the use of platform APIs.
先の効果および利益と類似して、オンデバイス機械学習プラットフォームは、全てのアプリケーションよりもむしろ単一の集中サービスの簡単な更新も可能にすることができる。例えば、新たなバージョンまたは型の機械学習エンジンが起動されるとき、アプリケーションまたは他のクライアントがエンジンと対話せず、代わりにそれらのためにプラットフォームにそうしてもらうので、オンデバイスプラットフォームのみが典型的に、更新して新たなエンジンと対話することを要求される。これにより、アプリケーションはエンジン技術が進化するにつれて最新であり続けるために代わりにオンデバイスプラットフォームに依存できるので、それらが最新バージョンの機械学習エンジンと適合していることを、それらが常に保証する必要性を排除できる。 Similar to previous benefits and benefits, on-device machine learning platforms can also allow for easy updates of a single centralized service rather than all applications. For example, only on-device platforms are typical because when a new version or type of machine learning engine is launched, the application or other client does not interact with the engine and instead asks the platform to do so for them. Is required to update and interact with the new engine. This allows applications to rely on on-device platforms instead to stay up-to-date as engine technology evolves, so they need to constantly ensure that they are compatible with the latest versions of machine learning engines. Can be eliminated.
更に別の技術的効果および利益例として、オンデバイス機械学習プラットフォームは、通信ネットワーク効率および使用を改善できる。すなわち、機械学習がオンデバイスよりもむしろサーバによって行われる過去のパラダイム下では、様々な種類の情報(例えば、入力データ、訓練事例、推論、モデルパラメータ等)が通信ネットワーク(例えば、インターネット)を通じてサーバによってデバイスに送信されることを要求された。しかしながら、本開示がオンデバイス予測、訓練、事例収集および/または他の機械学習タスクもしくは機能性を可能にするので、そのような情報は通信ネットワークを通じて送信されること(少なくともインスタンスごとに)が要求されない。したがって、通信ネットワークトラフィック、効率および使用が改善される。加えて、入力データ、訓練事例等がサーバに/から送信されないので、データのセキュリティを増すことができる。 As yet another technical benefit and benefit example, on-device machine learning platforms can improve communication network efficiency and use. That is, under the past paradigm where machine learning is done by servers rather than on-devices, various types of information (eg input data, training cases, inferences, model parameters, etc.) are servered through communication networks (eg, the Internet). Was requested to be sent to the device. However, as this disclosure enables on-device prediction, training, case-gathering and / or other machine learning tasks or functionality, such information is required to be transmitted over the communication network (at least per instance). Not done. Therefore, communication network traffic, efficiency and usage are improved. In addition, input data, training cases, etc. are not sent to / from the server, so data security can be increased.
ここで図を参照しつつ、本開示の実施形態例が更に詳細に述べられることになる。 Here, examples of embodiments of the present disclosure will be described in more detail with reference to the figures.
デバイスおよびシステム例
図1は、本開示の実施形態例に係るオンデバイス機械学習プラットフォーム122を含むコンピューティングデバイス例102のブロック図を示す。
Device and System Examples FIG. 1 shows a block diagram of a computing device example 102 including an on-device
コンピューティングデバイス102は、例えば、デスクトップ、ラップトップ、タブレットコンピューティングデバイス、スマートフォン、着用できるコンピューティングデバイス、ゲーム機、組込みコンピューティングデバイス、または他の形態のコンピューティングデバイスを含め、任意の種類のコンピューティングデバイスであることができる。このように、一部の実装例では、コンピューティングデバイス102は、モバイルコンピューティングデバイスおよび/またはユーザコンピューティングデバイスであることができる。
The
コンピューティングデバイス102は、1つまたは複数のプロセッサ112およびメモリ114を含む。1つまたは複数のプロセッサ112は、任意の適切な処理デバイス(例えば、プロセッサコア、マイクロプロセッサ、ASIC、FPGA、コントローラ、マイクロコントローラ等)であることができ、かつ1つのプロセッサまたは作動的に接続される複数のプロセッサであることができる。メモリ114は、RAM、ROM、EEPROM、EPROM、フラッシュメモリデバイス、磁気ディスク等、およびその組合せなどの、1つまたは複数の非一時的コンピュータ可読記憶媒体を含むことができる。メモリ114は、データ、およびプロセッサ112によって実行されてコンピューティングデバイス102に動作を行わせる命令を記憶できる。コンピューティングデバイス102は、1つまたは複数のネットワーク(例えば、インターネット)を通じて通信を可能にするネットワークインタフェース116も含むことができる。
The
オンデバイス機械学習プラットフォーム122は、「機械学習機能」と集合的に称されてよい、オンデバイス予測、訓練、事例収集および/または他の機械学習タスクもしくは機能性を可能にすることができる。
On-device
オンデバイス機械学習プラットフォーム122は、コンピューティングデバイス102(例えば、スマートフォンまたはタブレット)にローカルに記憶される1つまたは複数のコンピュータプログラムの形態でよく、それらは、デバイス102によって実行されると、1つまたは複数のローカルに記憶されるアプリケーション120a〜cまたは他のローカルクライアントのためのオンデバイス機械学習機能の遂行を可能にする機械学習管理動作を行うように構成される。オンデバイス機械学習機能の少なくとも一部は、コンピューティングデバイス102にローカルに実装される1つまたは複数の機械学習エンジン128を使用して行われてよい。1つまたは複数のローカルに記憶されるアプリケーション120a〜cまたはルーチン(「クライアント」と称されてよい)のためのオンデバイス機械学習機能の遂行は、それらのクライアントへの集中サービスとして提供されてよく、それらは1つまたは複数のアプリケーションプログラミングインタフェース(API)を介してオンデバイス機械学習プラットフォーム122と対話してよい。
The on-device
加えて、一部の実装例では、オンデバイス機械学習プラットフォーム122は、予測/推論を生成するために使用される収集した訓練事例および/またはクライアント提供の入力データへコンテキスト特徴を確実に注入するコンテキストプロバイダを含むことができる。このように、オンデバイス機械学習プラットフォーム122は、アプリケーション120a〜cまたは他のクライアントへのサービスとして集中訓練事例収集、モデル訓練および機械学習済みモデル132a〜cの使用を可能にすることができる。
In addition, in some implementations, the on-device
より詳細には、コンピューティングデバイス102は、1つまたは複数のアプリケーション120a〜c(例えば、モバイルアプリケーション)を記憶するまたはその他含むことができる。コンピューティングデバイス102は、オンデバイス機械学習プラットフォーム122および1つまたは複数の機械学習済みモデル132a〜cも含むおよび実装することができる。例えば、機械学習済みモデル132a〜cは、プラットフォーム122によって管理される集中モデルリポジトリ130にデバイス102によって記憶できる。
More specifically, the
本開示の1つの態様によれば、アプリケーション120a〜cは、API(「予測API」と称されてよい)を介してオンデバイス機械学習プラットフォーム122と通信して、入力データを提供し、そして機械学習済みモデル132a〜cの1つまたは複数から入力データに基づいて予測を得ることができる。一例として、一部の実装例では、予測プラン(例えば、モデルを走らせて推論/予測を得るための命令)およびモデルパラメータに対する統一資源識別子(URI)が与えられると、オンデバイス機械学習プラットフォーム122は、URI内容(例えば、予測プランおよびパラメータ)をダウンロードし、そしてモデルを走らせることによって(例えば、機械学習エンジン128と対話してエンジンによるモデルの実装をもたらすことによって)1つまたは複数の推論/予測を得ることができる。加えて、プラットフォーム122は、同内容が以降の予測要求に対して使用できるようにそれをキャッシュできる(例えば、リポジトリ130内に)。
According to one aspect of the disclosure, applications 120a-c communicate with the on-device
このように、オンデバイス機械学習済みモデル132a〜cは、アプリケーション120a〜cによってクライアント/サービス関係を介してオンデバイス機械学習プラットフォーム122と通信することによってアクセスできる。例えば、それぞれの機械学習済みモデル132a〜cは、各アプリケーション120a〜cに対して設けられ、そしてプラットフォーム122によって管理できる。他の実装例では、2つ以上のアプリケーション120a〜cが単一の機械学習済みモデル132a〜cを共有できる、または単一のアプリケーション120a〜cが2つ以上のモデル132a〜cを有することができる。
Thus, the on-device
一部の実装例では、機械学習プラットフォーム122は、アプリケーション120a〜cによって参照できるスタンドアロンマルチテナントサービスであることができる。そのため、所与のアプリケーション120a〜cは、機械学習済みモデル132a〜cを記憶、管理、訓練および/または実装することは要求されず、代わりに単にオンデバイス機械学習プラットフォーム122と通信して、モデル132a〜cに推論を要求して受け取れる。
In some implementations, the
本開示の別の態様によれば、コンピューティングデバイス102は、アプリケーション120a〜cから受け取られる訓練事例を記憶する集中事例データベース124をさらに含むことができる。特に、オンデバイス機械学習プラットフォーム122は、API(「収集API」と称されてよい)を介してアプリケーション120a〜cから訓練事例を受け取ることができ、そして集中事例データベース124における事例の記憶を管理できる。例えば、プラットフォーム122のクライアントまたはテナントである各アプリケーション120a〜cは、集中事例データベース124内に記憶されるそれ自身の事例の集合を有することができ、そして同集合はオンライン方式で補足および/または管理できる。
According to another aspect of the disclosure, the
一部の実装例では、オンデバイス機械学習プラットフォーム122は、訓練事例を提供するアプリケーション120a〜cと関連する1つまたは複数のオプションパラメータに従ってアプリケーション120a〜cから受け取られる各訓練事例の記憶(例えば、その対応する集合内の)をもたらすことができる。1つの例として、オプションパラメータは、訓練事例が記憶される(例えば、更にその後に削除される)期間を定義する生存時間パラメータを含むことができる。一部の実装例では、オプションパラメータは、収集APIを介してプラットフォーム122に提供される命令を通じて予め定義および/または調整できる。
In some implementations, the on-device
本開示の別の態様によれば、一部の実装例では、オンデバイス機械学習プラットフォーム122は、訓練事例へコンピューティングデバイス102と関連するコンテキストを記述したコンテキスト特徴を確実に注入できる。例えば、アプリケーション120a〜cから訓練事例を受け取った上で、オンデバイスプラットフォーム122のコンテキストプロバイダコンポーネントが1つまたは複数のコンテキスト特徴を決定でき、そして集中事例データベース124に訓練事例と共にそのようなコンテキスト特徴を記憶できる。例えば、コンテキスト特徴および新たな訓練事例に提供されるデータは単一のデータベースエントリとして記憶できる。特定のアプリケーション120a〜cから受け取られる訓練事例と共に決定されて次いで注入もしくはその他関連付けおよび/または記憶される特定のコンテキスト特徴は、そのような特定のアプリケーション120a〜cに対するオプションパラメータによって特定できる。上記したように、これらのオプション特徴は収集APIを介して調整または予め定義できる。このように、アプリケーション120a〜cは、どのコンテキスト特徴またはコンテキスト型がその訓練事例へ注入されるかを制御できる(例えば、オプションパラメータを定義することを介して)。
According to another aspect of the present disclosure, in some implementations, the on-device
一部の実装例では、コンテキスト特徴はサービス側で注入され、そのためコンテキスト特徴は、アプリケーション120a〜cに直接利用可能になる必要は決してない。特に、一部の実装例では、集中事例データベース124は1つまたは複数のアプリケーション120a〜cによって直接アクセス可能でなく、そのため特定の訓練事例と共に記憶されるコンテキスト情報は、同訓練事例を提供したアプリケーション120a〜cにさえアクセス可能でない。
In some implementations, context features are injected on the service side, so context features never need to be directly available to applications 120a-c. In particular, in some implementations, the
一部の実装例では、コンテキスト特徴は、幾つかの異なるコンテキスト型に従ってグループ化またはその他分類できる。一般に、各コンテキスト型は、周知の名前および周知の型を持つ一組のコンテキスト特徴を特定するまたは含むことができる。1つのコンテキスト型例は、以下のコンテキスト特徴例を含むデバイス情報である:音声状態、ネットワーク状態、電力接続等。 In some implementations, context features can be grouped or otherwise classified according to several different context types. In general, each context type can identify or include a set of context features with a well-known name and well-known type. One context type example is device information that includes the following context feature examples: voice state, network state, power connection, etc.
一部の実装例では、コンテキストプロバイダは、注入時/点でデバイスに(例えば、デバイスのコンテキストマネージャ126に)所与のコンテキスト特徴に対して注入される値を要求する。代替的または追加的に、コンテキストプロバイダは、コンテキストマネージャ126からの1つまたは複数のコンテキスト更新のリスナとして登録でき、そして1つまたは複数のコンテキスト更新に基づいてコンテキスト特徴に対する現在値のコンテキスト特徴キャッシュを維持できる。次いで、コンテキスト特徴が注入されるとき、コンテキストプロバイダは単に、コンテキスト特徴キャッシュにアクセスし、そして特定のコンテキスト特徴に対するキャッシュに維持される現在値を注入できる。
In some implementations, the context provider requires the device to be injected at the time of injection / point (for example, to the device's context manager 126) for a given context feature. Alternatively or additionally, the context provider can register as a listener for one or more context updates from
記憶時の訓練事例へのコンテキスト特徴の注入に加えてまたは代替的に、コンテキストプロバイダは、推論時のコンテキスト特徴の注入も行える。特に、訓練事例収集のための上記したプロセスに類似して、特定のアプリケーション120a〜cまたは他のクライアントが或るクライアント提供の入力データを基礎として推論が生成されることを要求すると(例えば、予測APIを介して)、コンテキストプロバイダは、入力データと一緒に対応する機械学習済みモデル132a〜cへの入力のための補足的コンテキスト特徴を注入または提供できる。このように、クライアント提供の入力データに加えてコンテキスト情報に少なくとも部分的に基づいて推論を行うことができ、これは推論の精度を改善するのを促進できる。
In addition to or as an alternative to injecting contextual features into the training case during memory, the context provider can also inject contextual features during inference. In particular, similar to the process described above for training case collection, certain applications 120a-c or other clients require that inferences be generated on the basis of input data provided by a client (eg, prediction). Through the API), the context provider can inject or provide supplemental context features for input to the corresponding machine-learned
別の態様によれば、或るアプリケーション120a〜cまたは他のクライアントがコンテキスト特徴またはコンテキスト型の幾つかのみにアクセスする許可を有してよいので(例えば、デバイスユーザによって定義または制御される通りに)、コンテキストプロバイダはクライアント許可制御を行える。特に、一部の実装例では、オンデバイス機械学習プラットフォーム122または他のデバイスコンポーネントは、どのクライアントがどのコンテキスト型またはコンテキスト特徴にアクセスする許可を有するかのマッピングを維持できる。コンテキスト特徴が注入されることになるとき(例えば、記憶のための訓練事例へか、推論時にクライアント提供の入力データを補足するためか)、コンテキストプロバイダは、注入されることになるコンテキスト特徴またはコンテキスト型に対する対応するアプリケーション120a〜cまたは他のクライアントの許可状況を確認できる。例えば、特定のアプリケーション120a〜cおよびコンテキスト型に対する許可状況は、そのようなアプリケーション120a〜cがそのようなコンテキスト型にアクセスする許可を有するかどうかを説明できる。コンテキストプロバイダは、アプリケーション120a〜cがアクセスする許可を有するコンテキスト型に含まれるコンテキスト特徴のみを注入することになり、それによってアプリケーション120a〜cが、それがアクセスする許可を有しないコンテキスト特徴/型にアクセスするのを(間接的な方式でさえ)防止する。
According to another aspect, one application 120a-c or another client may have permission to access only some of the context features or context types (eg, as defined or controlled by the device user). ), The context provider can control client permissions. In particular, in some implementations, the on-device
上記した生存時間オプションパラメータに類似して、一部の実装例では、各コンテキスト特徴は、それと関連するまたはそれに割り当てられる満了期間を有することができる。この満了期間情報は、コンテキスト特徴を含む各訓練事例と関連付けできる。一部の実装例では、特定の訓練事例に提供される特定のコンテキスト特徴に対する満了期間の終結において、そのようなコンテキスト特徴に対する値はそのような訓練事例から削除またはその他除去できる。代替的に、訓練事例全体が削除またはその他除去できる。 Similar to the time-to-live option parameter described above, in some implementations each context feature can have an expiration period associated with it or assigned to it. This expiration period information can be associated with each training case, including contextual features. In some implementations, at the end of the expiration period for a particular context feature provided for a particular training case, the value for such context feature can be removed or otherwise removed from such training case. Alternatively, the entire training case can be deleted or otherwise removed.
更には、一部の実装例では、特定のコンテキスト特徴またはコンテキスト型に対する特定のアプリケーション120a〜cまたは他のクライアントに対する許可状況の変化に応じて、オンデバイスプラットフォーム122は、特定のアプリケーション120a〜cと関連する訓練事例と関連付けられるそのようなコンテキスト特徴または型に対するいかなる値またはエントリも集中事例データベース124から削除できる。加えて、一部の実装例では、対応するモデル132a〜cは、コンテキスト特徴値の削除後に残りのデータで再訓練できる。
Furthermore, in some implementations, the on-
本開示の更に別の態様によれば、アプリケーション120a〜cは、API(「訓練API」と称されてよい)を介してオンデバイス機械学習プラットフォーム122と通信して、集中事例データベース124に記憶される訓練事例に基づいて機械学習済みモデル132a〜cの再訓練または更新をもたらすことができる。一例として、一部の実装例では、訓練プラン(例えば、モデルを訓練するための命令)に対するURIが与えられると、オンデバイス機械学習プラットフォーム122は、以前に収集した事例に基づいてモデル132a〜cの訓練を行える(例えば、機械学習エンジン128と対話してエンジン128によるモデル132a〜cの訓練をもたらすことによって)。例えば、訓練は、予定時におよび/またはデバイスがアイドルであるときにバックグラウンドで行える。
According to yet another aspect of the disclosure, applications 120a-c communicate with the on-device
モデル132a〜cの再訓練後に、再訓練済みモデル132a〜cは、本明細書に他の場所で記載されるように推論を提供するために使用できる。典型的に、モデル132a〜cがユーザに固有であるデータで再訓練されたので、これらの推論はより高い精度を有することになる。このように、オンデバイス機械学習プラットフォーム122は、アプリケーション120a〜cまたは他のクライアントへのサービスとして集中事例データ収集および機械学習済みモデル132a〜cの対応する個別化を可能にすることができる。
After retraining
別の態様によれば、一部の実装例では、機械学習プラットフォーム122は、機械学習メトリックの詳細な分析のためにクラウドに機械学習済みモデル132a〜cに関するログまたは他の更新をアップロードできる。一例として、一部の実装例では、オンデバイスプラットフォーム122は、再訓練した機械学習済みモデル132a〜cのパラメータまたはモデル132a〜cの再訓練中に発生した機械学習済みモデル132a〜cのパラメータの変更(例えば「勾配」)を記述する更新を決定できる。プラットフォーム122は、他のコンピューティングデバイスによって提供される他の更新との集約のために中央サーバコンピューティングデバイス(例えば、「クラウド」)に更新を送信できる。このように、プラットフォーム122は、「連合学習」として知られるプロセスへの参加を可能にすることができ、そこではデバイスが、ローカルに記憶されるデータに基づいてモデル132a〜cのローカルな更新を決定し、次いで集約のためにクラウドサービスにローカルな更新を伝達して(例えば、プライバシーを保護し通信効率的な方式で)モデル132a〜cのグローバルな更新を生成する。
According to another embodiment, in some implementations, the
別の態様によれば、一部の実装例では、アプリケーション120a〜cを互いから保護するために、各アプリケーション120a〜cは、オンデバイスプラットフォーム122によって与えられる或る機能性のための(例えば、機能性ごとの)それ自身の孤立領域を有することができる。例えば、プラットフォーム122は、プラットフォーム122にアクセスするためのインタフェースがファクトリを介してアプリケーション120a〜cに返される前に、アプリケーション120a〜cを認証できる。返されたインタフェースは、その場合プラットフォーム122におけるアプリケーションの孤立領域の唯一のビューを表せる。このプロセスの1つの実装例では、アプリケーション120a〜cがプラットフォーム122のAPIに接続するとき、アプリケーション120a〜cは、アプリケーション120a〜cの識別情報を検証する署名済みパッケージトークンを提供できる。アプリケーション120a〜cは、この認証に合格することなくAPIインタフェースを得ることはできない。
According to another embodiment, in some implementations, to protect applications 120a-c from each other, each application 120a-c is for some functionality provided by the on-device platform 122 (eg, for example. It can have its own isolated area (per functionality). For example,
一部の実装例では、プラットフォーム122内の各アプリケーションの孤立領域はアカウント独立している。このように、コンピューティングデバイス102上の同じユーザプロファイルと関連する複数アカウントが同じ訓練データおよび状態を共有できる。これは、大抵の場合の複数アカウントが同じユーザに対してであり、そしてコンピューティングデバイス上の異なるユーザは代わりに異なるユーザプロファイルを使用するであろうことを反映する。
In some implementations, the isolated areas of each application within
一部の実装例では、或る機能性(例えば、コンテキストにアクセス)のために、許可が必要とされる。そのため、一部の実装例では、プラットフォーム122における特定のコンテキストを使用したいアプリケーション120a〜cは、たとえそれが決してコンテキストに直接作用しなくても、コンテキストがプラットフォーム122内に存在するので、特定のコンテキストにアクセスする許可を有することが要求される。一部の実装例では、全ての関連した許可はクライアントにおいて検証し、次いでプラットフォーム呼出しに渡すことができ、論理的にプラットフォーム122をこの一組の許可で動作させる。一部の実装例では、プラットフォーム122は、プラットフォーム122が全ての許可へのアクセスを有することにユーザが同意することを要求できる。一部の事例では、コンテキストが、特定のユーザがログインすることも必要としてよい。そのようなユーザは、それらの場合のためにアプリケーションによって特定でき、またはコンテキスト注入のためにオプションの任意選択のフィールドによって特定できる。しかしながら、一部の実装例では、ユーザは、プラットフォーム122によって自動的に検出されなくてよい。一部の実装例では、API自体は、そのような具体的なユーザアカウントとの認証を必要としない。
In some implementations, permission is required for some functionality (eg, accessing the context). Therefore, in some implementations, applications 120a-c that want to use a particular context on
本開示の別の態様によれば、一部の実装例では、オンデバイス機械学習プラットフォーム122は、基底となる機械学習エンジン128から完全に抽象化できる。例えば、機械学習エンジン128は、TensorFlowエンジン、ニューラルネットワークライブラリ、または推論および/もしくは訓練のための機械学習済みモデル132a〜cの実装を可能にする他のエンジンであることができる。そのような抽象化のため、機械学習プラットフォーム122はモデルアーチファクト132a〜cを、クラウドにおいて発生され、次いでデバイスに送られる(例えば、動的モデルダウンロードを介して)ブロブとみなすことができ、ここで、それらは次いでマッチングエンジン128によって解釈される。そのような方式では、機械学習プラットフォーム122およびそのサポートされるアプリケーション120a〜cは、機械学習エンジン128の変更に対して弾力的であり、かつ/または利用される特定のエンジン128もしくはエンジン型に非依存/柔軟であることができる。
According to another aspect of the present disclosure, in some implementations, the on-device
別の態様によれば、オンデバイスプラットフォーム122に補完的であるツールキットが、デバイスにモデルがアーチファクトとして送られる前にクラウドにおいてそれらを作成およびシミュレートする一組のツール(例えば、Pythonツール)を提供できる。一部の実装例では、ツールキットは、異なるバージョンの機械学習エンジン、または異なるエンジン型(例えば、モバイル向けTensorFlow Lite対ニューラルネットワークライブラリ等)に対してさえ同じソースアーチファクト(例えば、Pythonソースアーチファクト)から生成できる。
In another aspect, the toolkit, which is complementary to the on-
一部の実装例では、オンデバイス機械学習プラットフォーム122は、例えば、モバイルアプリケーションなどのアプリケーションに含めることが、またはそれとして実装することができる。例えば、Androidオペレーティングシステムのコンテキストでは、オンデバイス機械学習プラットフォーム122は、ダウンロードおよび/または更新できるAndroidパッケージキット(APK)に含めることができる。1つの特定の例では、オンデバイス機械学習プラットフォーム122は、他のアプリケーション120a〜cまたはデバイス102自体に幾つかの異なるサポートサービスを提供するより大きなアプリケーションの一部分に含めることが、またはそれとして実装することができる。例えば、オンデバイス機械学習プラットフォーム122に加えて、より大きなアプリケーションは、コンピューティングデバイス102がデジタル配信サービス(例えば、「アプリストア」からアプリケーションおよび/もしくは更新をダウンロードする)ならびに/または他のサービスと対話することを可能にするサービスを提供できる。別の例では、オンデバイス機械学習プラットフォーム122は、スタンドアロンアプリケーションとしてよりもむしろ、デバイス102のオペレーティングシステムの一部分に含めることが、またはそれとして実装することができる。
In some implementation examples, the on-device
図2は、本開示の実施形態例に係る機械学習済みモデル展開例のグラフィック図を示す。特に、アプリケーション開発者202は、ツールキットと対話してモデル204を生成およびテストできる。モデルは、推論プラン206および訓練プラン208へ分割またはその他それらによって少なくとも部分的に表現できる。
FIG. 2 shows a graphic diagram of a machine-learned model deployment example according to the embodiment of the present disclosure. In particular,
「プラン」は、グラフ(例えば、TensorFlowグラフ)およびグラフを実行する仕方に関する命令を含むプロトコルバッファ(別名「protobuf」)を含むことができる。1つの例として、プランは、グラフ(例えば、TensorFlowグラフ)自体も組み込む、グラフに行うことになる一連の動作の宣言的記述であることができる。プランには、訓練データの収集について問い合わせる仕方、それをグラフへ入れる仕方、ならびに/または出力を発生および送出する仕方を記述できる。 A "plan" can include a graph (eg, a TensorFlow graph) and a protocol buffer (also known as "protobuf") that contains instructions on how to run the graph. As an example, a plan can be a declarative description of the sequence of actions that will be made to the graph, including the graph itself (eg, the TensorFlow graph). The plan can describe how to inquire about the collection of training data, how to graph it, and / or how to generate and send output.
図2は、2つの択一的(しかし任意選択で相補的)展開方式を例示する。第1の方式では、推論プラン206も訓練プラン208もクラウドサーバ210に展開される。クラウドサーバ210は推論プラン206および訓練プラン208をデバイス214に提供する。
Figure 2 illustrates two alternative (but optionally complementary) deployment schemes. In the first method, both the
デバイス214は、推論プラン206を実装して推論を生成できる。デバイス214は、代替的または追加的に訓練プラン208を実装して、ローカルに記憶されるデータに基づいてオンデバイス訓練を行うことができ、これは「個別化」または「個別学習」とも称することができる。
第2の展開方式では、推論プラン206は上記したようにクラウドサーバ210に展開される。クラウドサーバは推論プラン206をデバイス216に提供する。デバイス216は、推論プラン206を実装して推論を生成できる。
In the second deployment method, the
しかしながら、クラウドサーバ210への推論プラン206の展開に加えてまたは代替的に、第2の方式では、訓練プラン208は連合サーバ212に展開される。連合サーバ212は訓練プラン208をデバイス216に提供する。デバイス216は、訓練プラン208を実装して、ローカルに記憶されるデータに基づいてオンデバイス訓練を行える。そのようなオンデバイス学習後に、デバイス216は連合サーバ212に更新を提供できる。例えば、更新には、再訓練済みモデルの1つもしくは複数のパラメータまたはモデルの再訓練中に発生したモデルのパラメータの1つもしくは複数の変更を記述できる。
However, in addition to or as an alternative to deploying the
連合サーバ212は、複数デバイスからそのような更新を多く受信でき、そして更新を集約して更新済みグローバルモデルを生成できる。更新済みグローバルモデルは次いでデバイス216に再送できる。
The
加えて、一部の実装例では、デバイス216は、機械学習メトリックの詳細な分析を得るために開発者202によって(例えば、ツールキットと連動して)使用できる機械学習済みモデルに関するログ218または他の更新を更に提供できる。一部の実装例でログ218に基づいて計算できるメトリック例には、チェックイン要求結果のプロット、グラフもしくは可視化、トラフィック(例えば、ボリューム)、損失および精度モデルメトリック、フェーズ時間、または他のメトリックを含む。
In addition, in some implementations,
図3は、本開示の実施形態例に係る個別化および連合学習データフロー例のグラフィック図を示す。 FIG. 3 shows a graphic diagram of an example of individualized and associative learning data flow according to an example of the embodiment of the present disclosure.
より詳細には、図3は、一部の実例では相補的に使用されてよい3つの異なる学習データフローを示す。主に図3の下部に破線で図示される第1のデータフローでは、ユーザデバイス上で訓練データが生成される。訓練データは中央局にアップロードされ、そこでアップロードされたデータに基づいて機械学習済みモデルを訓練または再訓練する。モデルは次いで使用(例えば、オンデバイス推論)のためにユーザデバイスに送られる。 More specifically, FIG. 3 shows three different training data flows that may be used complementarily in some examples. In the first data flow, which is mainly illustrated by the dashed line at the bottom of FIG. 3, training data is generated on the user device. The training data is uploaded to the central office, where the machine-learned model is trained or retrained based on the uploaded data. The model is then sent to the user device for use (eg, on-device inference).
個別化または個別学習と称することができる第2のデータフローでは、ユーザデバイス上で作成される訓練データは、デバイス上でモデルを訓練または再訓練するために使用される。再訓練済みモデルは次いでそのようなデバイスによって使用される。この個別学習は、デバイスごとのモデルが集中データ収集なしで訓練および評価されることを可能にし、それによってデータセキュリティおよびユーザプライバシーを強化する。 In a second data flow, which can be referred to as individualization or individual training, the training data created on the user device is used to train or retrain the model on the device. The retrained model is then used by such devices. This tutoring allows device-specific models to be trained and evaluated without centralized data collection, thereby enhancing data security and user privacy.
連合学習と称することができる第3のデータフローでは、ユーザデバイス上で作成される訓練データは、デバイス上でモデルを訓練または再訓練するために使用される。このように、実際のユーザ固有の訓練データはクラウドにアップロードされず、それによってデータセキュリティおよびユーザプライバシーを強化する。 In a third data flow, which can be referred to as federated learning, the training data created on the user device is used to train or retrain the model on the device. In this way, the actual user-specific training data is not uploaded to the cloud, thereby enhancing data security and user privacy.
そのようなオンデバイス学習後に、ユーザデバイスは中央局に更新を提供できる。例えば、更新には、再訓練済みモデルの1つもしくは複数のパラメータまたはモデルの再訓練中に発生したモデルのパラメータの1つもしくは複数の変更を記述できる。 After such on-device learning, the user device can provide updates to the central station. For example, an update can describe one or more parameters of the retrained model or one or more changes of the parameters of the model that occurred during the retraining of the model.
中央局は、複数デバイスからそのような更新を多く受信でき、そして更新を集約して更新済みグローバルモデルを生成できる。更新済みグローバルモデルは次いでユーザデバイスに再送できる。この方式は、クロスデバイスモデルが集中データ収集なしで訓練および評価されることを可能にする。 The central station can receive many such updates from multiple devices and can aggregate the updates to generate an updated global model. The updated global model can then be resent to the user device. This scheme allows cross-device models to be trained and evaluated without centralized data collection.
図4は、本開示の実施形態例に係るオンデバイス機械学習プラットフォーム例のブロック図を示す。図4を参照しつつ例示および記載されるプラットフォームは1つの実装例としてのみ提供される。本明細書に記載されるオンデバイス機械学習プラットフォームの多くの異なる実装例が可能である。オンデバイス機械学習プラットフォーム例はメインプロセス402およびバックグラウンドプロセス404を含むまたは実装することができる。
FIG. 4 shows a block diagram of an example of an on-device machine learning platform according to an embodiment of the present disclosure. The platforms illustrated and described with reference to Figure 4 are provided as only one implementation example. Many different implementations of the on-device machine learning platforms described herein are possible. An example on-device machine learning platform can include or implement a main process 402 and a
メインプロセス402は全てのAPI要求を扱える。メインプロセス402は、収集API410を介して訓練事例収集サービスを提供する収集APIサービス420、予測API412を介して推論生成サービスを提供する予測APIサービス422、および訓練API414を介してモデル訓練サービスを提供する訓練APIサービス424を提供できる。
The main process 402 can handle all API requests. The main process 402 provides a
一部の実装例では、収集APIサービス420は自動保持ポリシーで訓練事例を持続できる。一部の実装例では、訓練APIサービス424は、事例集合からデータを引き出す不可視のプロセスとして予定時間および条件で訓練セッションを自動的に実行できる。一部の実装例では、予測APIサービス422は、クライアントが所与のモデルに基づいて推論を行うことを許可できるが、同モデルは訓練器にまたは外部ソースに由来してよい。
In some implementations, the
一部の実装例では、バックグラウンドプロセス404は訓練および他の定期整備タスクのみをホストできる。それはトランザクション型であり、かつ分解されるように設計することができる。一部の実装例では、バックグラウンドプロセス404はその状態を専らメインプロセス402から得る。
In some implementations,
以下に更に述べられることになるように、コンテキストプロバイダ430は、収集APIサービス420に対しても予測APIサービス422に対しても、事例へコンテキスト情報を注入する。記憶コンポーネント440は、事例(例えば、集中事例データベース124に)ならびにブックキーピング状態の記憶を可能にするおよび行うことができる。それはLevelDBに基づくことができる。
As further described below,
複数の予測エンジン432が、予測プラン型に応じて、予測APIサービス422によってアクセスできる。予測および訓練プランならびにモデルパラメータが、アーチファクトマネージャ434によって提供またはその他管理される。アーチファクトマネージャ434は、クラウドサーバ210から、アプリケーションアセットから、および/またはファイルからアーチファクトを検索することをサポートできる。それは、例えば、予測器または別の訓練器によって消費される訓練結果を記憶するための可変アーチファクトもサポートできる。
バックグラウンドプロセス404は、訓練プランに基づいて選ばれる複数の訓練エンジン406をホストできる。連合学習のため、バックグラウンドプロセス404は、連合学習サーバと通信して、プライバシー保護技術(例えば、セキュアな集約)を使用して蓄積のために訓練結果をアップロードできる。
ログマネージャ444は、機械学習メトリックの詳細な分析のためにクラウドサーバ210に機械学習済みモデルに関するログをアップロードできる。
より詳細には、一部の実装例では、収集APIサービス420は、バックグラウンドプロセス404による(例えば、バックグラウンド訓練を行うための)後の検索のために集中事例データベース124における訓練事例の記憶を許可する、管理する、かつ/または行う機能であることができる。例えば、収集APIサービス420は、記憶コンポーネント440と対話して、集中事例データベース124における訓練事例の記憶を管理できる。
More specifically, in some implementations, the
収集API410は単純であることができる:一旦クライアントが認証されたならば、それは以下のコード例に例証されるようにオブジェクトへのアクセスを得る(ここでTaskは非同期API呼出しを表す手法であり、Task<Void>は無視されても、またはエラーを観察するためにリッスンされてもよい):
class Learning {
...
static CollectionClient getCollectionClient(CollectionOptions options);
...
}
interface CollectionClient {
Task<Void> add(Example example);
Task<Void> clear();
}
class Learning {
...
static CollectionClient getCollectionClient (CollectionOptions options);
...
}
interface CollectionClient {
Task <Void> add (Example example);
Task <Void> clear ();
}
Learning.getCollectionClient(options)は、exampleCollectionへのアクセスおよびその構成を許可できる。「options」パラメータは、少なくとも集合の名前を含むことができる。更なるオプションが提供されなければ、デフォルトまたは以前に構成したオプションが使用できる。オプション例には、内容の生存時間、およびそれがデータベース124に記憶される前に学習イベントへ注入されるべきであるコンテキストを含む。
Learning.getCollectionClient (options) can allow access to and its configuration of exampleCollection. The "options" parameter can contain at least the name of the set. If no further options are provided, the default or previously configured options are available. Examples of options include the time to live of the content and the context in which it should be injected into the learning event before it is stored in
CollectionClient.add(example)は、記憶に新たな事例を追加できる。 CollectionClient.add (example) can add new cases to memory.
CollectionClient.clear()は、集合の内容のリセットを許可できる。 CollectionClient.clear () can allow resetting the contents of the set.
訓練API414および対応する訓練APIサービス424は、バックグラウンドプロセス404をスケジュールして訓練を行える。バックグラウンドプロセス404は、1つまたは複数の訓練エンジン406を実装またはそれと対話して、事例集合からデータを引き出し、そして訓練プランを実行できる。プランは、グラフ(例えば、TensorFlowグラフ)自体も組み込む、グラフに行うことになる一連の動作の宣言的記述であることができる。プランには、訓練データの収集について問い合わせる仕方、それをグラフへ入れる仕方、ならびに/または出力を発生および送出する仕方を記述できる。
各訓練プラン型が訓練プランエンジン406と関連付けできる。オンデバイス機械学習プラットフォームは、このように新たなプランの型によって拡張でき、それを、バックグラウンド訓練の一般モデルに適合するいかなる種類の機械学習実行も表すことを可能にする。
Each training plan type can be associated with the
1つの例として、訓練器に対するAPI例が以下に提供される:
class Learning {
...
static TrainerClient getTrainerClient(TrainerOptions options);
...
}
interface TrainerClient {
Task<Void> start(@Schedule int schedule);
Task<Void> stop();
}
As an example, the API example for the trainer is provided below:
class Learning {
...
static TrainerClient getTrainerClient (TrainerOptions options);
...
}
interface TrainerClient {
Task <Void> start (@Schedule int schedule);
Task <Void> stop ();
}
Learning.getTrainerClient(options)は、少なくとも訓練器セッション名を含むオプションをとることができ、そして訓練セッションを作成または再構成できる。セッション名は、アプリケーションによって選ばれる、パッケージ名に類似の、定数であることができ、そしてセッション自体は永久であることができる。オプションは、プラン型、プランが得られるメソッド、およびプラン型に固有の任意のパラメータも特定できる。プランはプラン型に応じて異なる仕方で得られてよく、例えば、連合のためには、プランは連合学習サーバからダウンロードでき、個別化のためには、それはアセットに含まれても、またはクラウドサーバ210からダウンロードされてもよい。 Learning.getTrainerClient (options) can take options that include at least the trainer session name, and can create or reconfigure training sessions. The session name can be a constant, similar to the package name, chosen by the application, and the session itself can be permanent. Options can also identify the plan type, the method from which the plan is obtained, and any parameters specific to the plan type. Plans may be obtained in different ways depending on the plan type, for example, for federation, the plan can be downloaded from the federated learning server, for personalization it may be included in an asset, or a cloud server. It may be downloaded from 210.
TrainerClient.start(schedule)は、インタフェース作成時にかつ所与の予定で渡されるオプションに基づいて訓練セッションを開始できる。予定は連続的か一回限りかであることができる。一部の実装例では、いずれの場合にも、訓練は、デバイス条件が許可する場合にのみ予定されることになる。一例として、一部の実装例では、訓練は、デバイスがアイドルでも充電中でもある場合にのみ予定されるまたはその他行われることになる。 TrainerClient.start (schedule) can start a training session when the interface is created and based on the options passed at a given schedule. Appointments can be continuous or one-off. In some implementations, in each case, training will only be scheduled if the device conditions allow. As an example, in some implementations, training will only be scheduled or otherwise done if the device is idle or charging.
TrainerClient.stop()は、訓練セッションの取消しおよび/または除去を許可できる。 TrainerClient.stop () can allow the cancellation and / or removal of training sessions.
予測API412は、クライアントが入力を与えて、訓練済みモデルに基づいてそれから予測を導出することを許可できる。訓練器のように、予測器は、一部の実装例ではプラン駆動でき、ここでプランは、グラフにどんな動作を行うか、および入力を得て出力を発生する仕方の宣言的記述である。
1つの例として、予測APIコード例は次の通りである:
class Learning {
...
static PredictorClient getPredictorClient(PredictorOptions options);
...
}
interface PredictorClient {
Task<PredictionResult> predictRank(Example example, Map<String, Example> candidates);
}
As an example, the predictive API code example is:
class Learning {
...
static PredictorClient getPredictorClient (PredictorOptions options);
...
}
interface PredictorClient {
Task <PredictionResult> predictRank (Example example, Map <String, Example>candidates);
}
Learning.getPredictorClient()は、所与のオプションに基づいて予測器を返せる。オプションは、予測のためのプランおよびモデルパラメータを得る仕方を特定できる。それらは、どのコンテキスト特徴が予測エンジンに渡される前の候補事例へ自動的に注入されるべきであるかも特定できる。 Learning.getPredictorClient () can return a predictor based on a given option. Options can identify how to obtain plans and model parameters for forecasting. They can also identify which contextual features should be automatically injected into the candidate case before it is passed to the prediction engine.
predictRank()は、所与のコンテキスト例および指定の候補から導出されるランキング問題に対する予測を返せる。追加的なアプリケーション固有の予測方法が時間とともに導入できる。 predictRank () can return a prediction for a ranking problem derived from a given context example and a given candidate. Additional application-specific forecasting methods can be introduced over time.
以下のコードは、図4を参照しつつ記載される3つのAPI例410、412および414の1つの使用例を例示する。 The code below illustrates one use case of the three API examples 410, 412, and 414, which are described with reference to Figure 4.
第1に、構成のためのオプションが定義できる。概して、それらのオプションは、表現型構成コンポーネント442からアプリケーションによって得ることができるが、簡略化の理由で、それらは静的定数として定義できる:
class MyLearningConfig {
static final ExampleCollectionOptions COLLECTION_OPTIONS =
ExampleCollectionOptions.create("myCollection)
.setTimeToLive(TimeUnit.DAYS.toMillis(7))
.addContext(ContextType.USER_LOCATION);
static final TrainerOptions TRAINER_OPTIONS =
TrainerOptions.create("myTrainer")
.setCollectionName(COLLECTION_OPTIONS.getCollectionName())
.setPersonalized(
"mrepo://myApp/training_plan",
"mrepo://myApp/initial_params",
"file:trained_params");
static final PredictorOptions PREDICTOR_OPTIONS =
PredictorOptions.create("myPredictor")
.setRanking(
"mrepo://myApp/prediction_plan",
TRAINER_OPTIONS.getTrainedParamsUri())
.addContext(ContextType.USER_LOCATION);
}
First, options for configuration can be defined. In general, those options can be obtained by the application from the
class MyLearningConfig {
static final ExampleCollectionOptions COLLECTION_OPTIONS =
ExampleCollectionOptions.create ("myCollection)
.setTimeToLive (TimeUnit.DAYS.toMillis (7))
.addContext (ContextType.USER_LOCATION);
static final TrainerOptions TRAINER_OPTIONS =
TrainerOptions.create ("myTrainer")
.setCollectionName (COLLECTION_OPTIONS.getCollectionName ())
.setPersonalized (
"mrepo: // myApp / training_plan",
"mrepo: // myApp / initial_params",
"file: trained_params");
static final PredictorOptions PREDICTOR_OPTIONS =
PredictorOptions.create ("myPredictor")
.setRanking (
"mrepo: // myApp / prediction_plan",
TRAINER_OPTIONS.getTrainedParamsUri ())
.addContext (ContextType.USER_LOCATION);
}
訓練および予測プランならびにモデルパラメータを記述するアーチファクトを参照するためにURIがどのように使用できるかに留意されたい。プランは、グラフ(例えば、TensorFlowグラフ)およびグラフを実行する仕方の情報を符号化できる。一部の実装例では、プランは、対応するツールボックスに含まれるツール(例えば、Pythonツール)によって作成できる。一部の実装例では、モデルパラメータは、プランと関連する重みの不透明な表現であることができる。URIは「モデルリポジトリ」(mrepo:)を参照でき、それらがデバイスに(例えばクラウドサーバ210から)ダウンロードされるが、ローカルにキャッシュされるファイル(file:)も参照できることを意味する。例えば、アーチファクトマネージャ434がサーバ210からのモデルアーチファクトのダウンロードおよび/または他のモデル管理タスクを管理できる。
Note how URIs can be used to refer to artifacts that describe training and prediction plans as well as model parameters. Plans can encode graphs (eg, TensorFlow graphs) and information on how to run the graphs. In some implementations, plans can be created by tools included in the corresponding toolbox (eg Python tools). In some implementations, model parameters can be an opaque representation of the weights associated with the plan. URIs can refer to "model repositories" (mrepo :), which means they can be downloaded to the device (eg from cloud server 210), but also locally cached files (file :). For example,
ファイルアーチファクトの場合、依存関係がAPI間で定義できる。例えば、TrainerOptionsは、予測APIサービスによって消費される訓練済みパラメータを持つファイルアーチファクトを生成するために定義できる。オンデバイス機械学習プラットフォームは、必要とされる入力がまだ発生されていなければ、動作を遅延させるまたは適切なエラーコードでそれらを拒否することによって、そのような入出力従属性を内部的に扱える。 For file artifacts, dependencies can be defined between APIs. For example, TrainerOptions can be defined to generate file artifacts with trained parameters consumed by the predictive API service. On-device machine learning platforms can handle such input / output dependencies internally by delaying operation or rejecting them with appropriate error codes if the required inputs have not yet occurred.
以上の構成を与えて、プラットフォームは、訓練事例が集合へ連続的に入れられる或るAPIコードを含むことができる。1つの例として、以下のコードが追加の訓練事例を含むことができる:
ExampleCollectionClient collection =
Learning.getExampleCollectionClient(COLLECTION_OPTIONS);
...
void onSomeEvent(SomeEvent event) {
collection.add(eventToExample(event));
}
Given the above configuration, the platform can contain some API code that continuously puts training cases into a set. As an example, the following code can include additional training cases:
ExampleCollectionClient collection =
Learning.getExampleCollectionClient (COLLECTION_OPTIONS);
...
void onSomeEvent (SomeEvent event) {
collection.add (eventToExample (event));
}
事例がキャッシュに追加されるたびに、COLLECTION_OPTIONSで特定されたコンテキストを特徴として追加できる。ユーザは追加データの限定サイズまたは寿命に注意する必要はなく、それは提供されるオプションに基づいて扱える。 Each time a case is added to the cache, the context specified by COLLECTION_OPTIONS can be added as a feature. The user does not have to worry about the limited size or lifetime of the additional data, which can be handled based on the options provided.
訓練を予定するために、アプリケーションは、バックグラウンド訓練が現在のオプションを使用して構成され、そして予定されることを典型的に作成時に保証できる。一部の実装例では、訓練が既に以前に予定されており、構成が変化しなければ、それはこの事例呼出しによって影響を受けることはない:
void onCreated() {
TrainerClient trainer = Learning.getTrainerClient(TRAINER_OPTIONS);
trainer.start(Schedule.CONTINUOUSLY);
}
To schedule training, the application can typically guarantee at creation that background training is configured and scheduled using the current options. In some implementations, training was already scheduled earlier and it would not be affected by this case call if the configuration did not change:
void onCreated () {
TrainerClient trainer = Learning.getTrainerClient (TRAINER_OPTIONS);
trainer.start (Schedule.CONTINUOUSLY);
}
最後に、別のコード例が予測APIを使用して訓練結果を活かせる。1つの例として、これは、以下のコード例に与えられるように見え得る:
PredictorClient predictor = Learning.getPredictorClient(PREDICTOR_OPTIONS);
...
SomeEvent predict(SomeEvent event, Map<String, SomeEvent> candidates) {
PredictionResult result = predictor.predictRank(eventToExample(event), candsToExample(candidates));
if (result.notAvailable()) {
//これは、アーチファクトが訓練によりダウンロードされること、または計算されることが未だ行われていない場合に起こる可能性がある。
Log.warn(「予測がまだ利用可能でない、デフォルトを使用」)
return candidates.iterator().next();
}
return candidates.get(result.getKeys()[0]);
}
Finally, another code example can leverage the training results using the prediction API. As an example, this can appear to be given in the code example below:
PredictorClient predictor = Learning.getPredictorClient (PREDICTOR_OPTIONS);
...
SomeEvent predict (SomeEvent event, Map <String, SomeEvent> candidates) {
PredictionResult result = predictor.predictRank (eventToExample (event), candsToExample (candidates));
if (result.notAvailable ()) {
// This can happen if the artifact has not yet been downloaded or calculated by training.
Log.warn ("Forecast not yet available, use default")
return candidates.iterator (). next ();
}
return candidates.get (result.getKeys () [0]);
}
既に述べたように、一部の実装例では、オンデバイス機械学習プラットフォームのコンテキストプロバイダ430は学習イベントへコンテキスト特徴を注入できる。これはサービス側で発生でき、そのためコンテキストは、アプリケーションに直接利用可能になる必要は決してない。
As already mentioned, in some implementations, the
コンテキストを注入できる2つの位置例は:
1.事例が事例集合へ記憶される前。注入されるコンテキストはCollectionOptionsによって特定できる。
2.事例が予測エンジンに渡される前。注入されるコンテキストはPredictorOptionsによって特定できる。
Two location examples where you can inject context are:
1. Before the case is stored in the case set. The context to be injected can be specified by Collection Options.
2. Before the case is passed to the prediction engine. The context to be injected can be identified by Predictor Options.
一般に、各コンテキストカテゴリは、事例(例えば、TensorFlow事例プロト)に追加される周知の名前および周知の型を持つ一組の特徴を特定できる。所与のコンテキスト特徴に対して注入される値は注入点でシステムに要求されてよく、またはそれは、プラットフォームの内部コンテキストプロバイダ430が定期的に更新するキャッシュ値でよい。
In general, each context category can identify a set of features with well-known names and well-known types that are added to the case (eg, TensorFlow case proto). The value injected for a given context feature may be required by the system at the injection point, or it may be a cache value that is regularly updated by the platform's
コンテキスト特徴例には、音声状態、日属性、カレンダ、検出アクティビティ、ユーザ固有の場所(例えば、「自宅」対「職場」)、ネットワーク状態、電力接続、画面特徴、ユーザ位置、ユーザ位置予測、WiFiスキャン情報、天気、または他のコンテキスト特徴を含む。 Examples of context features include voice state, day attributes, calendar, detection activity, user-specific location (eg, "home" vs. "work"), network state, power connection, screen features, user location, user location prediction, WiFi. Includes scan information, weather, or other contextual features.
以上の説明に加えて、ユーザには、本明細書に記載されるシステム、プログラムまたは特徴がユーザ情報(例えば、訓練事例およびコンテキスト特徴)の収集を可能にしてよいか、更にいつ可能かに関しても、ユーザにサーバからコンテンツまたは通信が送られるかに関しても、ユーザが選択をすることを許可する制御手段が与えられてよい。加えて、或るデータは、それが記憶または使用される前に1つまたは複数の仕方で処理されてよく、その結果、個人識別可能情報は除去される。例えば、ユーザに対して個人識別可能情報が確定できないようにユーザの識別情報が処理されてよい、または位置情報が得られる程度(都市、郵便番号もしくは州レベルなど)にユーザの地理的位置が一般化されてよく、その結果ユーザの特定の位置は確定できない。このように、ユーザは、ユーザについてどんな情報が収集されるか、その情報がどのように使用されるか、およびどんな情報がユーザに提供されるかに対する制御手段を有してよい。 In addition to the above description, the user may also be assured of when, and when, the systems, programs or features described herein may allow the collection of user information (eg, training cases and contextual features). A control means may also be provided that allows the user to make choices as to whether the server sends content or communications. In addition, some data may be processed in one or more ways before it is stored or used, so that personally identifiable information is removed. For example, the user's geographic location is generally to the extent that the user's identity may be processed so that the personally identifiable information cannot be determined for the user, or location information is available (such as city, zip code or state level). As a result, the specific position of the user cannot be determined. In this way, the user may have control over what information is collected about the user, how that information is used, and what information is provided to the user.
オンデバイスプラットフォームはいかなるコンテキスト自体も必要としないので、コンテキストプロバイダ430がクライアントアプリケーションのためにコンテキストを収集する。例えば、クライアントアプリケーションがその機械学習モデルに対する特徴として「位置」を必要としてよい。そのようなアプリケーションは、「位置」コンテキストが必要とされることをオンデバイスプラットフォームに明示的に通知できる。
The on-device platform does not require any context itself, so the
オンデバイスプラットフォームは、クライアントアプリケーションがデバイス位置にアクセスする許可を有するかどうかを最初に確認できる。そうでなければ、プラットフォームはクライアントにコンテキストを与えない。一方、アプリケーションが許可を有すれば、一旦クライアントがプラットフォームに訓練事例を送ると、クライアントに対して位置コンテキストが読み込まれることになる。このように、一部の実装例では、クライアントがオンデバイスプラットフォームに事例を送ることが生じるごとに、プラットフォームはそれらの許可を調べて、それらが請求したコンテキストにアクセスする許可をクライアントが有するかどうかを決定する。 The on-device platform can first check if the client application has permission to access the device location. Otherwise, the platform gives no context to the client. On the other hand, if the application has permission, once the client sends the training case to the platform, the location context will be loaded for the client. Thus, in some implementations, each time a client sends a case to an on-device platform, the platform examines their permissions to see if the client has permission to access the context they requested. To determine.
一部の実装例では、実際のコンテキスト内容はアプリケーションに提供されないことに留意されたい。代わりに、コンテキストは単にクライアントに対して訓練事例と共に読み込まれる。訓練事例はオンデバイスプラットフォームデータベース内に保たれることになるので、クライアントは真のコンテキスト内容にはアクセスできない。 Note that some implementations do not provide the actual context content to the application. Instead, the context is simply loaded into the client with the training case. The training case will be kept in the on-device platform database, so the client will not have access to the true contextual content.
一部の実装例では、場所エイリアスおよびカレンダの様な、或る型のコンテキストは、アクセスするのにユーザアカウントを必要とする。一部の実装例では、コンテキストプロバイダ430自体は、コンテキストに対してどのアカウントを使用するかを示さない。そのような場合、クライアントアプリケーションがアカウントを特定するべきである。一部の実装例では、クライアントによってアカウントが特定されなければ、アカウントを必要としないコンテキストのみがクライアントに提供されることになる。
In some implementations, some types of contexts, such as location aliases and calendars, require a user account to access. In some implementations, the
オンデバイスプラットフォームが使用しているコンテキストは、一般にコンテキストマネージャ(例えば、図1に図示される126)によって提供される。コンテキストマネージャは、例えば、プラットフォーム内、プラットフォームを含むアプリケーション内、および/またはデバイスのオペレーティングシステム内を含め、幾つかの場所に設けることができる。一部の実装例では、性能を改善するために、コンテキストプロバイダ430は、コンテキストマネージャのリスナを登録でき、そしてオンデバイスプラットフォームメモリに常に最新のコンテキスト更新を保つ。
The context used by the on-device platform is typically provided by a context manager (eg, 126 illustrated in Figure 1). Context managers can be located in several locations, including, for example, within the platform, within the application that includes the platform, and / or within the operating system of the device. In some implementations, to improve performance,
一部の実装例では、オンデバイスプラットフォームは、無効コンテキスト失効を行うまたは含むことができる。一部の実装例では、ユーザがデバイス上のコンテキスト信号を切る場合(例えば、位置またはアクティビティ認識を切る)、コンテキストマネージャは、コンテキストが切られたことをオンデバイスプラットフォームに通知しない。代わりに、コンテキストマネージャは、単にオンデバイスプラットフォームにこれらのコンテキストに対するコンテキスト更新を送るのを止める。このように、将来のイベントに対する無効コンテキストの使用を回避するために、プラットフォームは、無効コンテキストに失効させることができる。特に、コンテキストプロパティに基づいて、各コンテキスト特徴またはコンテキスト種類に対して異なる失効時限を定義できる。一旦コンテキストがその失効時限に達すると、それは削除できる。 In some implementations, the on-device platform can perform or include invalid context revocation. In some implementations, when the user disconnects the context signal on the device (eg, disconnects position or activity awareness), the context manager does not notify the on-device platform that the context has been disconnected. Instead, the context manager simply stops sending context updates for these contexts to the on-device platform. Thus, to avoid the use of invalid contexts for future events, the platform can revoke invalid contexts. In particular, different expiration times can be defined for each context feature or context type based on context properties. Once the context reaches its expiration time, it can be deleted.
別のコンテキスト特徴例は場所エイリアスコンテキスト特徴を含む。特に、ユーザが自宅にいるか職場にいるかが多くのクライアントアプリケーションにとって重要な特徴である。ユーザの自宅/職場が頻繁に変わらないことを考えれば、一旦コンテキストプロバイダ430が構築されると、プラットフォームは現在の自宅/職場エイリアスを求めることができる。ユーザがそのような情報の使用に同意すれば、ユーザの自宅/職場はキャッシュでき、そしてコンテキストプロバイダ430は、位置コンテキストを使用して、位置コンテキストをキャッシュ位置と比較することによってユーザが自宅にいるか職場にいるかを判定できる。一部の実装例では、場所エイリアス情報は、コンテキストマネージャからまたは場所APIから受け取ることができる。
Another context feature example includes a location alias context feature. In particular, whether the user is at home or at work is an important feature for many client applications. Given that the user's home / work does not change frequently, once the
コンテキストマネージャは、少なくとも2つの以下の仕方でコンテキストを送出できる。第1の例では、オンデバイスプラットフォームはリスナとして登録できる。この場合、オンデバイスプラットフォームは更新されたコンテキストのキャッシュを維持でき、これは、一部の実装例では、オンデバイスプラットフォームが常時オンのサービスであることも意味する。リスナによって、更新されたデータをキャッシュに保つことができる。 The context manager can send contexts in at least two ways: In the first example, the on-device platform can be registered as a listener. In this case, the on-device platform can maintain a cache of updated contexts, which also means that in some implementations the on-device platform is always on service. The listener can keep the updated data in the cache.
リスナとして登録することの利益は以下を含む:
1.短い待ち時間。全てのコンテキストがオンデバイスプラットフォーム内にキャッシュされ、そして機械学習に配慮した形式に変換される。
2.オンデバイスプラットフォームへのIPC(プロセス間呼出し)が高速であれば、コンテキストをキャッシュすることでバッテリを節約する。
The benefits of registering as a listener include:
1. Short waiting time. All contexts are cached within the on-device platform and transformed into a machine learning friendly format.
2. If IPC (interprocess invocation) to the on-device platform is fast, cache the context to save battery.
第2の例では、オンデバイスプラットフォームはワンショットで現在のコンテキストを得ることができる。この場合、コンテキストマネージャは、ワンショットで全ての現在のコンテキストを得るための別のAPIを提供することができる。このAPIが使用されれば、オンデバイスプラットフォームは典型的にコンテキストのキャッシュを維持せず、代わりに要求に応じて現在のコンテキストを得る。 In the second example, the on-device platform can get the current context in one shot. In this case, the context manager can provide another API to get all the current contexts in one shot. When this API is used, on-device platforms typically do not maintain a cache of contexts, instead getting the current contexts on demand.
このモードでは、コンテキストマネージャは、プラットフォームに対して更新されたコンテキストを保つように求められるので、プラットフォームは典型的に、第1のオプションでは必要とされない、追加のUDC許可を得る。 In this mode, the context manager is asked to keep the updated context for the platform, so the platform typically gets additional UDC permissions that are not required by the first option.
ワンショットモードの利益には、オンデバイスプラットフォームへのIPCが低速であれば、それがバッテリを節約できることを含む。 The benefits of one-shot mode include that if the IPC to the on-device platform is slow, it can save battery.
一部の実装例では、オンデバイスプラットフォームは、上記した全てのコンテキストに対するユーザ許可を得てもよいが、或るクライアントは、オンデバイスプラットフォームが有するのと同じ許可を有しなくてもよい。そこで、プラットフォームはクライアントに対する許可を制御できる。一部の実装例では、これは、パッケージマネージャを使用して、クライアントアプリケーションと関連する許可を抽出することによって行える。プラットフォームは、許可に対するコンテキスト間のマッピングを維持できる。このように、クライアントは典型的に、それがオンデバイスプラットフォームにそれ自体を登録するときにそれがどんなコンテキストを使用したいかを明示的に主張することになる。プラットフォームは、クライアントが要求したコンテキストにアクセスする許可を有するかどうかを確認する。アプリケーションが許可を有するコンテキストのみが、対応するモデルを訓練および推論するために使用されることになる。 In some implementations, the on-device platform may have user permissions for all of the contexts described above, but some clients may not have the same permissions that the on-device platform has. The platform can then control the permissions on the client. In some implementations, this can be done by using a package manager to extract the permissions associated with the client application. The platform can maintain a mapping between contexts for permissions. Thus, the client typically explicitly asserts what context it wants to use when registering itself on the on-device platform. The platform checks to see if it has permission to access the context requested by the client. Only the context for which the application has permission will be used to train and infer the corresponding model.
加えて、クライアントの許可がオンザフライで変更されることが可能である。例えば、ユーザは、アプリケーションが有用であろうと自分が感じるときにアプリケーションが自分の位置を使用するのを承認するが、その後に許可を撤回してよい。このケースを扱うために、クライアントから新たなイベントが来るたびに、プラットフォームは、それらの既存の許可を確認し、そして対応するコンテキストを訓練するイベントと関係させることができる。 In addition, client permissions can be changed on the fly. For example, the user may authorize the application to use its position when it finds it useful, but then withdraw the permission. To handle this case, each time a new event comes in from the client, the platform can check those existing permissions and associate them with the event that trains the corresponding context.
推論の間、プラットフォームは、現在のクライアント許可も分析して、予測のためにコンテキスト特徴の使用を許可できる。そのため、一部の実装例では、機械学習済みモデルは、訓練および推論のために不足している特徴を受け入れることができる。 During inference, the platform can also analyze current client permissions and allow the use of contextual features for prediction. Therefore, in some implementations, the machine-learned model can accept features that are missing for training and inference.
別の態様によれば、一部の実装例では、オンデバイスプラットフォームAPIを使用するために、クライアントは、それらのアプリケーションにAPIキーを追加できる。例えば、アプリケーションは、クライアントが秘密キーを保持するデジタル証明書で署名できる。アプリケーションは、APIを管理する中央局に登録することによってキーを得ることができる。 According to another aspect, in some implementations, clients can add API keys to their applications in order to use the on-device platform APIs. For example, an application can be signed with a digital certificate that the client holds a private key. The application can get the key by registering with the central office that manages the API.
1つの認可手順例は以下を含むことができる:
1.オンデバイスプラットフォームは、クライアントがオンデバイスプラットフォームに登録するときにパッケージ名およびAPIキーペアを得る。オンデバイスプラットフォームは、検証のために中央局にパッケージ名およびAPIキーペアを送る。
2.一旦クライアントが検証されると、オンデバイスプラットフォームは、クライアントがそのデバイスで使用するためのプラットフォームキーを生成することになる。
3.そのデバイスにおける将来のAPI呼出しのために、クライアントは、オンデバイスプラットフォームにプラットフォームキーを提供するべきである。
An example authorization procedure can include:
1. The on-device platform gets the package name and API key pair when the client registers with the on-device platform. The on-device platform sends the package name and API key pair to the central office for verification.
2. Once the client is validated, the on-device platform will generate a platform key for the client to use on that device.
3. The client should provide the platform key to the on-device platform for future API calls on that device.
オンデバイスプラットフォームは、プラットフォームキーがパッケージ名およびAPIキーと一致するかどうかを確認できる。しかしながら、オンデバイスプラットフォームは典型的に、再び検証するためにそれらを中央局に送ることはしない。 The on-device platform can check if the platform key matches the package name and API key. However, on-device platforms typically do not send them to the central station for revalidation.
一部の実例では、デバイスは2人以上のユーザによって共有できる。そのため、APIが使用されるときに、オンデバイスプラットフォームはリストから主アカウントを抽出できる。オンデバイスプラットフォームは、主アカウントに訓練データを結び付け、そして関連モデルを更新できる。アカウントに対するモデルがデバイス上で入手可能でなければ、オンデバイスプラットフォームは、クラウドからクライアントアプリケーションに対するモデルをダウンロードできる、またはベースモデル(例えば、連合学習の平均モデル)を使用できる。 In some examples, the device can be shared by two or more users. Therefore, the on-device platform can extract the primary account from the list when the API is used. The on-device platform can bind training data to the primary account and update related models. If the model for the account is not available on the device, the on-device platform can download the model for the client application from the cloud, or use the base model (eg, the average model of federated learning).
別の態様によれば、一部の実装例では、ユーザは自分の位置履歴またはアカウント履歴をクリアできる。そのような実例では、オンデバイスプラットフォームは全ての対応するコンテキストを除去できる。加えて、一部の実装例では、プラットフォームは、この場合このユーザに対する残りのコンテキストを使用してモデルを再訓練できる。 According to another aspect, in some implementations, the user can clear his location history or account history. In such an example, the on-device platform can eliminate all corresponding contexts. In addition, in some implementations, the platform can retrain the model using the remaining context for this user in this case.
例として、図5Aおよび図5Bは、本開示の実施形態例に係るコンテキスト特徴を注入する機械学習プラットフォーム例122のブロック図を示す。特に、図5Aは、事例が事例集合へ記憶される前にコンテキストプロバイダ430がコンテキスト特徴を注入するのを示し、その一方図5Bは、事例が機械学習済みモデルを実装する予測エンジンに渡される前にコンテキストプロバイダ430がコンテキスト特徴を注入するのを示す。
As an example, FIGS. 5A and 5B show a block diagram of a machine learning platform example 122 that injects contextual features according to an embodiment of the present disclosure. In particular, Figure 5A shows that the
図6Aおよび図6Bは、本開示の実施形態例に係るモデル訓練を行うデバイス例のブロック図を示す。特に、図6Aおよび図6Bはバックグラウンド訓練プロセスを例示する。 6A and 6B show a block diagram of an example device for performing model training according to the embodiment of the present disclosure. In particular, FIGS. 6A and 6B illustrate the background training process.
図6Aに例示されるように、アプリケーションプロセスが訓練データストアへ訓練データを入れることができる。訓練プロセスはバックグラウンドで予定できる(例えば、アイドル状態および/またはプラグイン状態などの、或るデバイス条件によって許可される場合)。 As illustrated in Figure 6A, an application process can populate the training data store with training data. The training process can be scheduled in the background (for example, if allowed by certain device conditions, such as idle and / or plug-in states).
訓練プロセスは、モデル状態および訓練プランを取り込み、キャッシュからデータを繰り返し取り込んでモデルを訓練し、次いで最終的に統計およびモデル更新メッセージを公開できる(例えば、クラウドサーバに)。一部の実装例では、訓練フェーズが長い場合があるので(例えば、分単位)、訓練プロセスは、変化するデバイス条件に基づいて中断および再開できる。 The training process can capture the model state and training plan, iteratively fetch data from the cache to train the model, and finally publish statistics and model update messages (eg to a cloud server). In some implementations, the training phase may be long (eg, in minutes), so the training process can be interrupted and resumed based on changing device conditions.
図6Bは、それが連合学習を可能にする連合学習サービスを含むことを除いて、図6Aに類似している。図6Bに例示されるように、訓練プランおよびモデルは連合学習サービスによって配布できる。訓練プロセスはバックグラウンドで訓練を行ってモデル更新を生成できる。モデル更新は連合学習サービスにアップロードできる(例えば、集約に使用するために)。加えて、一部の実装例では、品質保証(例えば、半自動品質保証)が学習済みモデルを抽出し、そしてデバイスへモデルを配布できる。 FIG. 6B is similar to FIG. 6A, except that it includes an associative learning service that enables associative learning. Training plans and models can be distributed by the Federated Learning Service, as illustrated in Figure 6B. The training process can be trained in the background to generate model updates. Model updates can be uploaded to a federated learning service (for example, for use in aggregation). In addition, in some implementations, quality assurance (eg, semi-automatic quality assurance) can extract trained models and distribute the models to devices.
図7は、本開示の実施形態例に係る連合学習プロセス例のグラフィック図を示す。 FIG. 7 shows a graphic diagram of an example of the associative learning process according to the embodiment of the present disclosure.
方法例
図8は、本開示の実施形態例に係る機械学習済みモデルを使用して推論を生成する方法例800のフローチャートを示す。
Method Example FIG. 8 shows a flowchart of Method Example 800 for generating inferences using the machine-learned model according to the embodiment of the present disclosure.
802で、コンピューティングシステムは、予測アプリケーションプログラミングインタフェースを介して第1のアプリケーションから入力データを受け取ることができる。 In 802, the computing system can receive input data from the first application via the predictive application programming interface.
804で、コンピューティングシステムは、第1のアプリケーションによって要求され、かつ第1のアプリケーションがアクセスする許可を有するコンテキスト特徴で入力データを補足できる。一部の実装例では、804で、コンピューティングシステムは、1つまたは複数のコンテキスト型の各々に対する第1のアプリケーションの許可状況を決定できる。一部の実装例では、入力データは、第1のアプリケーションがアクセスする許可を有するコンテキスト型に含まれるコンテキスト特徴のみで補足される。 At 804, the computing system can supplement the input data with contextual features that are requested by the first application and that the first application has permission to access. In some implementations, in 804, the computing system can determine the authorization status of the first application for each of one or more context types. In some implementations, the input data is supplemented only by the context features contained in the context type that the first application has permission to access.
806で、コンピューティングシステムは、第1の機械学習済みモデルを利用して、入力データに少なくとも部分的に基づいてかつ補足的コンテキスト特徴に少なくとも部分的に基づいて少なくとも1つの推論を生成できる。808で、コンピューティングシステムは、予測アプリケーションプログラミングインタフェースを介して第1のアプリケーションに少なくとも1つの推論を提供できる。 At 806, the computing system can utilize the first machine-learned model to generate at least one inference based on at least partly based on the input data and at least partly based on the complementary contextual features. At 808, the computing system can provide at least one inference to the first application through the predictive application programming interface.
図9は、本開示の実施形態例に係る機械学習を行うための訓練事例を収集する方法例900のフローチャートを示す。 FIG. 9 shows a flowchart of Method Example 900 for collecting training cases for performing machine learning according to the embodiment of the present disclosure.
902で、コンピューティングシステムは、収集アプリケーションプログラミングインタフェースを介して第1のアプリケーションから新たな訓練事例を受け取ることができる。904で、コンピューティングシステムは、第1のアプリケーションによって要求され、かつ第1のアプリケーションがアクセスする許可を有するコンテキスト特徴で新たな訓練事例を補足できる。一部の実装例では、904で、コンピューティングシステムは、1つまたは複数のコンテキスト型の各々に対する第1のアプリケーションの許可状況を決定できる。一部の実装例では、新規な訓練事例は、第1のアプリケーションがアクセスする許可を有するコンテキスト型に含まれるコンテキスト特徴のみで補足される。 At 902, the computing system can receive new training cases from the first application via the collect application programming interface. At 904, the computing system can supplement new training cases with contextual features that are required by the first application and that the first application has permission to access. In some implementations, at 904, the computing system can determine the authorization status of the first application for each of one or more context types. In some implementations, the new training case is supplemented only by the context features contained in the context type that the first application has permission to access.
906で、コンピューティングシステムは、集中事例データベースにコンテキスト特徴と共に新たな訓練事例を記憶できる。一部の実装例では、906で新たな訓練事例を記憶することは、収集アプリケーションプログラミングインタフェースを介して第1のアプリケーションに対して以前に定義された1つまたは複数のオプションパラメータに従って集中事例データベースに新たな訓練事例を記憶することを含むことができる。1つの例として、1つまたは複数のオプションパラメータは、訓練事例が記憶される期間を定義する生存時間パラメータを少なくとも含むことができる。 At 906, the computing system can store new training cases along with contextual features in a centralized case database. In some implementations, memorizing new training cases in the 906 is in a centralized case database according to one or more optional parameters previously defined for the first application via the Collected Application Programming Interface. It can include memorizing new training cases. As an example, one or more optional parameters can include at least a time-to-live parameter that defines how long the training case is stored.
一部の実装例では、906で新たな訓練事例を記憶することは、1つまたは複数のコンテキスト特徴のうちの少なくとも第1のコンテキスト特徴に満了期間を割り当てることを含むことができる。方法900は、第1のコンテキスト特徴に割り当てられる満了期間の終結において集中事例データベースから第1のコンテキスト特徴または新たな訓練事例全体を削除することをさらに含むことができる。
In some implementations, remembering a new training case in 906 can include assigning an expiration period to at least the first context feature of one or more context features.
一部の実装例では、方法900は、少なくとも1つのコンテキスト型に対する第1のアプリケーションの許可状況の変化の指示を受け取ること、および許可状況の変化に応じて、第1のアプリケーションと関連する訓練事例と関連付けられる少なくとも1つのコンテキスト型のいかなるコンテキスト特徴も集中事例データベースから削除することをさらに含むことができる。加えて、一部の実装例では、方法900は、コンテキスト特徴を削除した後に、集中事例データベースにおいて第1のアプリケーションと関連する訓練事例を使用して第1のアプリケーションと関連する1つまたは複数の機械学習済みモデルを再訓練することをさらに含むことができる。
In some implementations,
図10は、本開示の実施形態例に係る機械学習済みモデルを訓練する方法例1000のフローチャートを示す。 FIG. 10 shows a flowchart of Method Example 1000 for training a machine-learned model according to an embodiment of the present disclosure.
1002で、コンピューティングシステムは、訓練アプリケーションプログラミングインタフェースを介して第1のアプリケーションから、集中事例データベースによって記憶される1つまたは複数の訓練事例に少なくとも部分的に基づいて第1の機械学習済みモデルを再訓練するようにとの命令を受け取ることができる。 At 1002, the computing system transfers the first machine-learned model from the first application via the training application programming interface, at least partially based on one or more training cases stored by the centralized case database. You can receive an order to retrain.
1004で、コンピューティングシステムは、集中事例データベースによって記憶される1つまたは複数の訓練事例に少なくとも部分的に基づいて第1の機械学習済みモデルを再訓練できる。 At 1004, the computing system can retrain the first machine-learned model based at least in part on one or more training cases stored by the centralized case database.
1006で、コンピューティングシステムは、再訓練済みモデルの1つもしくは複数のパラメータまたはモデルの再訓練中に発生した1つもしくは複数のパラメータの1つもしくは複数の変更を記述する更新を決定できる。 At 1006, the computing system can determine an update that describes one or more parameters of the retrained model or one or more changes of one or more parameters that occurred during the retraining of the model.
1008で、コンピューティングシステムは、他のコンピューティングデバイスによって提供される他の更新との集約のために中央サーバコンピューティングデバイスに更新を送信できる。 At 1008, a computing system can send updates to a central server computing device for aggregation with other updates provided by other computing devices.
追加開示
本明細書に述べた技術は、サーバ、データベース、ソフトウェアアプリケーションおよび他のコンピュータベースのシステムならびに、取られる措置およびそのようなシステムに/から送られる情報に言及する。コンピュータベースのシステムの固有の柔軟性がコンポーネント間でのタスクおよび機能性の各種の可能な構成、組合せおよび分割を可能にする。例えば、本明細書に述べたプロセスは単一のデバイスもしくはコンポーネントまたは組み合わさって作用する複数デバイスもしくはコンポーネントを使用して実装できる。データベースおよびアプリケーションは単一のシステムに実装できるまたは複数システムにわたって分散できる。分散されたコンポーネントは順次にまたは並列に動作できる。
Additional Disclosure The techniques described herein refer to servers, databases, software applications and other computer-based systems, as well as the measures taken and the information sent to / from such systems. The inherent flexibility of computer-based systems allows for various possible configurations, combinations and divisions of tasks and functionality between components. For example, the processes described herein can be implemented using a single device or component or multiple devices or components that work in combination. Databases and applications can be implemented on a single system or distributed across multiple systems. Distributed components can operate sequentially or in parallel.
本対象がその様々な具体的な実施形態例に関して詳細に記載されたが、各例は説明として提供されており、本開示の限定ではない。当業者は、上記の理解を達成した上で、そのような実施形態の変更、変形および等価物を直ちに生産できる。したがって、本開示は、当業者にとって直ちに明らかであろう本対象への修正、変形および/または追加の包含を排除しない。例えば、1つの実施形態の一部として例示または記載される特徴が別の実施形態と使用されて、更なる実施形態を生ずることができる。このように、本開示がそのような変更、変形および等価物を包含することが意図される。 Although the subject matter has been described in detail with respect to its various specific embodiments, each example is provided as an explanation and is not a limitation of the present disclosure. One of ordinary skill in the art can immediately produce such modifications, modifications and equivalents of the embodiment, achieving the above understanding. Accordingly, this disclosure does not preclude modifications, modifications and / or additional inclusions to this subject that will be immediately apparent to those skilled in the art. For example, features exemplified or described as part of one embodiment can be used with another embodiment to give rise to further embodiments. Thus, the present disclosure is intended to include such modifications, modifications and equivalents.
特に、図8〜図10が例示および考察の目的で特定の順に行われるステップをそれぞれ示すが、本開示の方法は特に例示した順または配列に限定されない。方法800、900および1000の様々なステップは、本開示の範囲から逸脱することなく様々な方法で省略、再配列、結合および/または適合できる。
In particular, FIGS. 8-10 show the steps performed in a particular order for purposes of illustration and discussion, respectively, but the methods of the present disclosure are not limited to the order or sequence specifically exemplified. The various steps of
102 コンピューティングデバイス
112 プロセッサ
114 メモリ
116 ネットワークインタフェース
120a アプリケーション
120b アプリケーション
120c アプリケーション
122 オンデバイス機械学習プラットフォーム
124 集中事例データベース
126 コンテキストマネージャ
128 機械学習エンジン
130 集中モデルリポジトリ
132a 機械学習済みモデル
132b 機械学習済みモデル
132c 機械学習済みモデル
202 アプリケーション開発者
204 モデル
206 推論プラン
208 訓練プラン
210 クラウドサーバ
212 連合サーバ
214 デバイス
216 デバイス
218 ログ
402 メインプロセス
404 バックグラウンドプロセス
406 訓練エンジン
410 収集API
412 予測API
414 訓練API
420 収集APIサービス
422 予測APIサービス
424 訓練APIサービス
430 コンテキストプロバイダ
432 予測エンジン
434 アーチファクトマネージャ
440 記憶コンポーネント
442 表現型構成コンポーネント
444 ログマネージャ
102 Computing device
112 processor
114 memory
116 Network interface
120a application
120b application
120c application
122 On-device machine learning platform
124 Centralized case database
126 Context manager
128 Machine learning engine
130 Centralized model repository
132a Machine-learned model
132b Machine-learned model
132c Machine-learned model
202 Application Developer
204 model
206 Inference Plan
208 training plan
210 cloud server
212 Union Server
214 devices
216 devices
218 logs
402 Main process
404 background process
406 training engine
410 Collection API
412 Prediction API
414 Training API
420 Collection API service
422 Prediction API Service
424 Training API service
430 Context provider
432 Prediction engine
434 Artist Manager
440 storage component
442 Phenotypic component
444 Log Manager
Claims (15)
1つまたは複数のコンピュータ可読記憶媒体とを備えたコンピューティングデバイスであって、前記1つまたは複数のコンピュータ可読記憶媒体が、
前記1つまたは複数のプロセッサによって実装される複数のアプリケーションと、
前記複数のアプリケーションから受け取られた訓練事例を記憶する集中事例データベースと、
前記複数のアプリケーションに推論を提供するように動作可能な機械学習済みモデルと、
前記1つまたは複数のプロセッサに、以下の動作を行うオンデバイス機械学習プラットフォームを実装させる命令とを記憶し、前記動作が、
収集アプリケーションプログラミングインタフェースを介して、前記複数のアプリケーションのうちの第1のアプリケーションから第1の訓練事例を受け取ることと、
前記第1の訓練事例が前記複数のアプリケーションのうちの他のアプリケーションにアクセス可能でないように、前記機械学習済みモデルを訓練する際の使用のために前記集中事例データベースに前記第1の訓練事例を記憶することと、
予測アプリケーションプログラミングインタフェースを介して前記複数のアプリケーションのうちの第2のアプリケーションから入力データを受け取ることと、
少なくとも前記機械学習済みモデルを利用して、前記入力データに少なくとも部分的に基づいて少なくとも1つの推論を生成することと、
前記予測アプリケーションプログラミングインタフェースを介して前記第2のアプリケーションに、前記機械学習済みモデルによって生成された前記少なくとも1つの推論を提供することとを含む、
コンピューティングデバイス。 With one or more processors
A computing device comprising one or more computer-readable storage media, wherein the one or more computer-readable storage media is the same.
With multiple applications implemented by the one or more processors
A centralized case database that stores training cases received from the multiple applications,
A machine-learned model that can act to provide inference to the multiple applications,
It stores instructions that cause the one or more processors to implement an on-device machine learning platform that performs the following operations, and the operations are
To receive the first training case from the first application of the plurality of applications via the collection application programming interface.
The first training case is stored in the centralized case database for use in training the machine-learned model so that the first training case is not accessible to other applications of the plurality of applications. To remember and
Receiving input data from a second of the plurality of applications via the predictive application programming interface
Using at least the machine-learned model to generate at least one inference based on the input data, at least in part.
To provide the second application via the predictive application programming interface with at least one inference generated by the machine-learned model.
Computing device.
訓練アプリケーションプログラミングインタフェースを介して前記第1のアプリケーションから、前記集中事例データベースに記憶されている1つまたは複数の訓練事例に少なくとも部分的に基づいて前記機械学習済みモデルを再訓練するようにとの命令を受け取ることと、
前記命令に応じて、前記機械学習済みモデルを、前記第1の訓練事例に少なくとも部分的に基づいて再訓練させることとをさらに含む、
請求項1に記載のコンピューティングデバイス。 The above operation
Training application To retrain the machine-learned model from the first application via the programming interface, at least in part, based on one or more training cases stored in the centralized case database. Receiving orders and
In response to the instruction, the machine-learned model is further retrained based on at least a part of the first training case.
The computing device according to claim 1.
前記第1の訓練事例を記憶する前に、前記コンピューティングデバイスと関連するコンテキストを記述した1つまたは複数のコンテキスト特徴を決定することとをさらに含み、
前記第1の訓練事例を記憶することが、前記集中事例データベースの前記1つまたは複数のコンテキスト特徴と共に前記第1の訓練事例を記憶することを含む、
請求項1または2に記載のコンピューティングデバイス。 The above operation
Further including determining one or more context features that describe the context associated with the computing device before storing the first training case.
Remembering the first training case includes storing the first training case along with the one or more context features of the centralized case database.
The computing device according to claim 1 or 2.
前記1つまたは複数のコンテキスト特徴と共に前記第1の訓練事例を記憶することが、前記第1のアプリケーションがアクセスする許可を有するコンテキスト型に含まれるコンテキスト特徴のみと共に第1の訓練事例を記憶することを含む、
請求項3に記載のコンピューティングデバイス。 Before storing the first training case, determining the permission status of the first application for each of the one or more context types, the permission for the first application and each context type. Further including that the situation describes whether the first application has permission to access the context type.
Remembering the first training case with the one or more context features means remembering the first training case with only the context features contained in the context type that the first application has permission to access. including,
The computing device according to claim 3.
前記1つまたは複数のコンテキスト更新に基づいて、コンテキスト特徴のコンテキスト特徴キャッシュを維持することとをさらに含み、
前記コンピューティングデバイスと関連する前記コンテキストを記述した前記1つまたは複数のコンテキスト特徴を決定することが、前記コンテキスト特徴キャッシュから前記1つまたは複数のコンテキスト特徴にアクセスすることを含む、
請求項3または4に記載のコンピューティングデバイス。 Registering as a listener for one or more context updates,
Further including maintaining a context feature cache of context features based on the one or more context updates mentioned above.
Determining the one or more context features that describe the context associated with the computing device comprises accessing the one or more context features from the context feature cache.
The computing device according to claim 3 or 4.
請求項3から5のいずれか一項に記載のコンピューティングデバイス。 The centralized case database is not directly accessible by the one or more applications, whereby the one or more context features are not accessible to the first application.
The computing device according to any one of claims 3 to 5.
前記動作が、前記第1のコンテキスト特徴に割り当てられる前記満了期間の終結において前記集中事例データベースから前記第1のコンテキスト特徴または前記第1の訓練事例全体を削除することをさらに含む、
請求項3から6のいずれか一項に記載のコンピューティングデバイス。 Retaining the first training case with the one or more context features in the centralized case database assigns an expiration period to at least one of the one or more context features. Including
The action further comprises deleting the first context feature or the entire first training case from the centralized case database at the end of the expiration period assigned to the first context feature.
The computing device according to any one of claims 3 to 6.
少なくとも1つのコンテキスト型に対する前記第1のアプリケーションの許可状況の変化の指示を受け取ることと、
前記許可状況の前記変化に応じて、前記第1のアプリケーションと関連する訓練事例と関連付けられる前記少なくとも1つのコンテキスト型のいかなるコンテキスト特徴も前記集中事例データベースから削除することとをさらに含む、
請求項3から7のいずれか一項に記載のコンピューティングデバイス。 The above operation
Receiving an instruction to change the permission status of the first application for at least one context type,
Further including removing from the centralized case database any contextual feature of the at least one context type associated with the training case associated with the first application in response to the change in the permission status.
The computing device according to any one of claims 3 to 7.
請求項8に記載のコンピューティングデバイス。 The behavior removes the context feature and then uses the training case associated with the first application in the centralized case database to generate one or more machine-learned models associated with the first application. Including further retraining,
The computing device of claim 8.
収集アプリケーションプログラミングインタフェースを介してコンピューティングデバイスによって、前記コンピューティングデバイスに記憶されている複数のアプリケーションのうちの第1のアプリケーションから第1の訓練事例を受け取るステップと、
前記第1の訓練事例が前記1つまたは複数のアプリケーションのうちの他のアプリケーションにアクセス可能でないように、前記コンピューティングデバイスによって、前記コンピューティングデバイスに記憶されている機械学習済みモデルを訓練する際の使用のために、前記複数のアプリケーションから受け取った訓練事例を含む前記コンピューティングデバイスの集中事例データベースに前記第1の訓練事例を記憶するステップであって、前記機械学習済みモデルが前記複数のアプリケーションに推論を提供するように動作可能である、ステップと、
予測アプリケーションプログラミングインタフェースを介して前記コンピューティングデバイスによって、前記複数のアプリケーションのうちの第2のアプリケーションから入力データを受け取るステップと、
前記コンピューティングデバイスによって、少なくとも前記機械学習済みモデルを利用して、前記入力データに少なくとも部分的に基づいて少なくとも1つの推論を生成するステップと、
前記予測アプリケーションプログラミングインタフェースを介して前記コンピューティングデバイスによって、前記機械学習済みモデルによって生成された前記少なくとも1つの推論を前記第2のアプリケーションに提供するステップとを含む、
コンピュータで実行される方法。 It ’s a method that runs on a computer.
Collecting application A step of receiving a first training case from a first application of a plurality of applications stored in the computing device by a computing device via a programming interface.
When training a machine-learned model stored in the computing device by the computing device so that the first training case is not accessible to other applications of the one or more applications. A step of storing the first training case in a centralized case database of the computing device, including training cases received from the plurality of applications, wherein the machine-learned model is the plurality of applications. Can act to provide inference to, steps, and
A step of receiving input data from a second application of the plurality of applications by the computing device via a predictive application programming interface.
A step of generating at least one inference based on the input data at least partially by the computing device, utilizing at least the machine-learned model.
A step of providing the second application with at least one inference generated by the machine-learned model by the computing device via the predictive application programming interface.
How it runs on your computer.
前記第1の訓練事例を記憶するステップが、前記集中事例データベースの前記1つまたは複数のコンテキスト特徴と共に前記第1の訓練事例を記憶するステップを含む、
請求項10に記載のコンピュータで実行される方法。 Prior to remembering the first training case, it further includes the step of determining one or more context features that describe the context associated with the computing device.
The step of storing the first training case includes the step of storing the first training case together with the one or more context features of the centralized case database.
The method performed on the computer according to claim 10.
前記コンピューティングデバイスによって、前記1つまたは複数のコンテキスト特徴と共に前記第1の訓練事例を記憶するステップが、前記コンピューティングデバイスによって、第1のアプリケーションがアクセスする許可を有するコンテキスト型に含まれるコンテキスト特徴のみと共に前記第1の訓練事例を記憶するステップを含む、
請求項11に記載のコンピュータで実行される方法。 A step of determining the authorization status of the first application for each of one or more context types by the computing device prior to storing the first training case, wherein the first application and The permission status for each context type further includes a step that describes whether the first application has permission to access the context type.
The step of storing the first training case with the one or more context features by the computing device is included in the context type that the computing device has permission to access by the first application. Including the step of remembering the first training case with only
The method performed on the computer according to claim 11.
前記命令に応じて、前記コンピューティングデバイスによって、前記機械学習済みモデルを前記第1の訓練事例に少なくとも部分的に基づいて再訓練させるステップとをさらに含む、
請求項10から12のいずれか一項に記載のコンピュータで実行される方法。 Training application The computing device via the programming interface retrains the machine-learned model from the first application, at least in part, based on one or more training cases contained in the centralized case database. Steps to receive instructions to do,
In response to the instruction, the computing device further includes a step of retraining the machine-learned model based on at least a part of the first training case.
The method performed on the computer according to any one of claims 10 to 12.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US15/674,910 | 2017-08-11 | ||
US15/674,910 US11138517B2 (en) | 2017-08-11 | 2017-08-11 | On-device machine learning platform |
JP2019565187A JP6926240B2 (en) | 2017-08-11 | 2018-04-26 | On-device machine learning platform |
Related Parent Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2019565187A Division JP6926240B2 (en) | 2017-08-11 | 2018-04-26 | On-device machine learning platform |
Publications (2)
Publication Number | Publication Date |
---|---|
JP2021177428A true JP2021177428A (en) | 2021-11-11 |
JP7252286B2 JP7252286B2 (en) | 2023-04-04 |
Family
ID=62152682
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2019565187A Active JP6926240B2 (en) | 2017-08-11 | 2018-04-26 | On-device machine learning platform |
JP2021127571A Active JP7252286B2 (en) | 2017-08-11 | 2021-08-03 | On-device machine learning platform |
Family Applications Before (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2019565187A Active JP6926240B2 (en) | 2017-08-11 | 2018-04-26 | On-device machine learning platform |
Country Status (6)
Country | Link |
---|---|
US (2) | US11138517B2 (en) |
EP (2) | EP3491588B1 (en) |
JP (2) | JP6926240B2 (en) |
KR (2) | KR102459835B1 (en) |
CN (1) | CN110869949B (en) |
WO (1) | WO2019032157A1 (en) |
Families Citing this family (27)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
WO2018217635A1 (en) * | 2017-05-20 | 2018-11-29 | Google Llc | Application development platform and software development kits that provide comprehensive machine learning services |
US11341429B1 (en) * | 2017-10-11 | 2022-05-24 | Snap Inc. | Distributed machine learning for improved privacy |
EP3499459A1 (en) * | 2017-12-18 | 2019-06-19 | FEI Company | Method, device and system for remote deep learning for microscopic image reconstruction and segmentation |
US11501156B2 (en) * | 2018-06-28 | 2022-11-15 | International Business Machines Corporation | Detecting adversarial attacks through decoy training |
US11429853B2 (en) * | 2018-11-13 | 2022-08-30 | Gyrfalcon Technology Inc. | Systems and methods for determining an artificial intelligence model in a communication system |
KR20200109819A (en) * | 2019-03-14 | 2020-09-23 | 삼성전자주식회사 | Electronic apparatus and controlling method thereof |
JP7238610B2 (en) * | 2019-06-04 | 2023-03-14 | 富士フイルムビジネスイノベーション株式会社 | Information processing device and program |
CN110399804A (en) * | 2019-07-01 | 2019-11-01 | 浙江师范大学 | A kind of food inspection recognition methods based on deep learning |
CN110362586B (en) * | 2019-07-12 | 2021-08-03 | 之江实验室 | Multi-center biomedical data cooperative processing system and method without patient data sharing |
US11907810B2 (en) * | 2019-07-18 | 2024-02-20 | Qualcomm Incorporated | Concurrent optimization of machine learning model performance |
US11392796B2 (en) * | 2019-08-20 | 2022-07-19 | Micron Technology, Inc. | Feature dictionary for bandwidth enhancement |
US11836615B2 (en) | 2019-09-20 | 2023-12-05 | International Business Machines Corporation | Bayesian nonparametric learning of neural networks |
US11134039B1 (en) * | 2019-10-18 | 2021-09-28 | Twitter, Inc. | Dynamically controlling messaging platform client-side and server-side behavior |
US20210125105A1 (en) * | 2019-10-23 | 2021-04-29 | The United States Of America, As Represented By The Secretary Of The Navy | System and Method for Interest-focused Collaborative Machine Learning |
US11500929B2 (en) * | 2019-11-07 | 2022-11-15 | International Business Machines Corporation | Hierarchical federated learning using access permissions |
US20230010095A1 (en) * | 2019-12-18 | 2023-01-12 | Telefonaktiebolaget Lm Ericsson (Publ) | Methods for cascade federated learning for telecommunications network performance and related apparatus |
US20210232981A1 (en) * | 2020-01-23 | 2021-07-29 | swarmin.ai | Method and system for incremental training of machine learning models on edge devices |
US11948096B2 (en) | 2020-03-13 | 2024-04-02 | International Business Machines Corporation | Adaptively adjusting influence in federated learning model updates |
EP3885704A1 (en) * | 2020-03-17 | 2021-09-29 | HERE Global B.V. | Method and apparatus for federated location fingerprinting |
KR102567565B1 (en) * | 2020-03-31 | 2023-08-21 | 한국전자기술연구원 | Apparatus and system for managing federated learning resource, and resource efficiency method thereof |
CN112150280B (en) * | 2020-10-16 | 2023-06-30 | 北京百度网讯科技有限公司 | Federal learning method and device for improving matching efficiency, electronic device and medium |
US11929079B2 (en) | 2020-10-27 | 2024-03-12 | Samsung Electronics Co., Ltd | Electronic device for managing user model and operating method thereof |
KR102526261B1 (en) * | 2020-12-04 | 2023-04-27 | 한국전자기술연구원 | Method for dynamic Artificial Intelligence model select based on space-time context |
CN114764967A (en) * | 2021-01-14 | 2022-07-19 | 新智数字科技有限公司 | Equipment fault alarm method under combined learning framework |
CN115271087A (en) * | 2021-04-29 | 2022-11-01 | 华为云计算技术有限公司 | Method and device for acquiring knowledge |
CN113515895B (en) * | 2021-07-30 | 2024-03-01 | 北京中网易企秀科技有限公司 | Cross-platform model prediction method and device |
CN114048864A (en) * | 2022-01-11 | 2022-02-15 | 中兴通讯股份有限公司 | Method for managing federal learning data, electronic device and storage medium |
Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2008204174A (en) * | 2007-02-20 | 2008-09-04 | Ntt Docomo Inc | Terminal unit and program |
JP2016525983A (en) * | 2013-08-12 | 2016-09-01 | 三菱電機株式会社 | How to adjust the settings in the vehicle |
US20160300156A1 (en) * | 2015-04-10 | 2016-10-13 | Facebook, Inc. | Machine learning model tracking platform |
Family Cites Families (24)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6968334B2 (en) * | 2001-05-15 | 2005-11-22 | Nokia Corporation | Method and business process to maintain privacy in distributed recommendation systems |
US8170841B2 (en) | 2004-04-16 | 2012-05-01 | Knowledgebase Marketing, Inc. | Predictive model validation |
JP2006134080A (en) * | 2004-11-05 | 2006-05-25 | Ntt Docomo Inc | Portable terminal, and individual adaptive context acquiring method |
US8214308B2 (en) | 2007-10-23 | 2012-07-03 | Sas Institute Inc. | Computer-implemented systems and methods for updating predictive models |
US8682814B2 (en) * | 2010-12-14 | 2014-03-25 | Symantec Corporation | User interface and workflow for performing machine learning |
US8606728B1 (en) | 2011-06-15 | 2013-12-10 | Google Inc. | Suggesting training examples |
US8935277B2 (en) * | 2012-03-30 | 2015-01-13 | Sap Se | Context-aware question answering system |
US9519647B2 (en) * | 2012-04-17 | 2016-12-13 | Sandisk Technologies Llc | Data expiry in a non-volatile device |
US8429103B1 (en) * | 2012-06-22 | 2013-04-23 | Google Inc. | Native machine learning service for user adaptation on a mobile platform |
US9336494B1 (en) | 2012-08-20 | 2016-05-10 | Context Relevant, Inc. | Re-training a machine learning model |
US8533148B1 (en) | 2012-10-01 | 2013-09-10 | Recommind, Inc. | Document relevancy analysis within machine learning systems including determining closest cosine distances of training examples |
US9218574B2 (en) | 2013-05-29 | 2015-12-22 | Purepredictive, Inc. | User interface for machine learning |
US9286574B2 (en) | 2013-11-04 | 2016-03-15 | Google Inc. | Systems and methods for layered training in machine-learning architectures |
US10318882B2 (en) * | 2014-09-11 | 2019-06-11 | Amazon Technologies, Inc. | Optimized training of linear machine learning models |
US20160092793A1 (en) * | 2014-09-26 | 2016-03-31 | Thomson Reuters Global Resources | Pharmacovigilance systems and methods utilizing cascading filters and machine learning models to classify and discern pharmaceutical trends from social media posts |
US9412046B2 (en) | 2014-10-10 | 2016-08-09 | Facebook, Inc. | Training image adjustment preferences |
US20160110657A1 (en) * | 2014-10-14 | 2016-04-21 | Skytree, Inc. | Configurable Machine Learning Method Selection and Parameter Optimization System and Method |
US10713594B2 (en) | 2015-03-20 | 2020-07-14 | Salesforce.Com, Inc. | Systems, methods, and apparatuses for implementing machine learning model training and deployment with a rollback mechanism |
US10084743B2 (en) * | 2015-04-15 | 2018-09-25 | General Electric Company | Methods and systems for adaptive and contextual collaboration in a network |
US9626654B2 (en) | 2015-06-30 | 2017-04-18 | Linkedin Corporation | Learning a ranking model using interactions of a user with a jobs list |
US10380500B2 (en) | 2015-09-24 | 2019-08-13 | Microsoft Technology Licensing, Llc | Version control for asynchronous distributed machine learning |
US20170185723A1 (en) * | 2015-12-28 | 2017-06-29 | Integer Health Technologies, LLC | Machine Learning System for Creating and Utilizing an Assessment Metric Based on Outcomes |
US10586173B2 (en) | 2016-01-27 | 2020-03-10 | Bonsai AI, Inc. | Searchable database of trained artificial intelligence objects that can be reused, reconfigured, and recomposed, into one or more subsequent artificial intelligence models |
US11210583B2 (en) * | 2016-07-20 | 2021-12-28 | Apple Inc. | Using proxies to enable on-device machine learning |
-
2017
- 2017-08-11 US US15/674,910 patent/US11138517B2/en active Active
-
2018
- 2018-04-26 KR KR1020217035225A patent/KR102459835B1/en active IP Right Grant
- 2018-04-26 WO PCT/US2018/029571 patent/WO2019032157A1/en unknown
- 2018-04-26 EP EP18724422.3A patent/EP3491588B1/en active Active
- 2018-04-26 EP EP20183226.8A patent/EP3739527B1/en active Active
- 2018-04-26 JP JP2019565187A patent/JP6926240B2/en active Active
- 2018-04-26 CN CN201880046455.3A patent/CN110869949B/en active Active
- 2018-04-26 KR KR1020197038030A patent/KR102321924B1/en active IP Right Grant
-
2021
- 2021-08-03 JP JP2021127571A patent/JP7252286B2/en active Active
- 2021-09-20 US US17/479,364 patent/US20220004929A1/en active Pending
Patent Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2008204174A (en) * | 2007-02-20 | 2008-09-04 | Ntt Docomo Inc | Terminal unit and program |
JP2016525983A (en) * | 2013-08-12 | 2016-09-01 | 三菱電機株式会社 | How to adjust the settings in the vehicle |
US20160300156A1 (en) * | 2015-04-10 | 2016-10-13 | Facebook, Inc. | Machine learning model tracking platform |
Also Published As
Publication number | Publication date |
---|---|
JP7252286B2 (en) | 2023-04-04 |
KR20200010480A (en) | 2020-01-30 |
WO2019032157A1 (en) | 2019-02-14 |
CN110869949A (en) | 2020-03-06 |
EP3491588A1 (en) | 2019-06-05 |
KR20210134822A (en) | 2021-11-10 |
CN110869949B (en) | 2024-04-09 |
EP3491588B1 (en) | 2020-07-01 |
US20220004929A1 (en) | 2022-01-06 |
KR102321924B1 (en) | 2021-11-04 |
US11138517B2 (en) | 2021-10-05 |
JP2020528588A (en) | 2020-09-24 |
US20190050749A1 (en) | 2019-02-14 |
EP3739527B1 (en) | 2022-12-21 |
EP3739527A1 (en) | 2020-11-18 |
JP6926240B2 (en) | 2021-08-25 |
KR102459835B1 (en) | 2022-10-27 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
JP6926240B2 (en) | On-device machine learning platform | |
JP6923676B2 (en) | On-device machine learning platform | |
US11356440B2 (en) | Automated IoT device registration | |
US20230098885A1 (en) | On-device Machine Learning Platform to Enable Sharing of Machine Learned Models between Applications | |
US10346443B2 (en) | Managing services instances | |
US10430171B2 (en) | Extensions for deployment patterns | |
US20210211363A1 (en) | QoS-OPTIMIZED SELECTION OF A CLOUD MICROSERVICES PROVIDER | |
CN110832458B (en) | Stealth patterns for personalized machine learning models | |
US11586470B2 (en) | Scalable workflow engine with a stateless orchestrator | |
US20210109895A1 (en) | Determining user interface contexts for requested resources | |
US10678752B2 (en) | Closure-based container volumes with ratio-based modeling | |
US20230068816A1 (en) | Providing a machine learning model based on desired metric values | |
US11983613B2 (en) | Incognito mode for personalized machine-learned models |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A621 | Written request for application examination |
Free format text: JAPANESE INTERMEDIATE CODE: A621Effective date: 20210805 |
|
A131 | Notification of reasons for refusal |
Free format text: JAPANESE INTERMEDIATE CODE: A131Effective date: 20221024 |
|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20230119 |
|
TRDD | Decision of grant or rejection written | ||
A01 | Written decision to grant a patent or to grant a registration (utility model) |
Free format text: JAPANESE INTERMEDIATE CODE: A01Effective date: 20230227 |
|
A61 | First payment of annual fees (during grant procedure) |
Free format text: JAPANESE INTERMEDIATE CODE: A61Effective date: 20230323 |
|
R150 | Certificate of patent or registration of utility model |
Ref document number: 7252286Country of ref document: JPFree format text: JAPANESE INTERMEDIATE CODE: R150 |