US8296283B2 - DHT-based distributed file system for simultaneous use by millions of frequently disconnected, world-wide users - Google Patents
DHT-based distributed file system for simultaneous use by millions of frequently disconnected, world-wide users Download PDFInfo
- Publication number
- US8296283B2 US8296283B2 US12/758,417 US75841710A US8296283B2 US 8296283 B2 US8296283 B2 US 8296283B2 US 75841710 A US75841710 A US 75841710A US 8296283 B2 US8296283 B2 US 8296283B2
- Authority
- US
- United States
- Prior art keywords
- group
- network devices
- content
- computer systems
- values determined
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L67/00—Network arrangements or protocols for supporting network services or applications
- H04L67/01—Protocols
- H04L67/10—Protocols in which an application is distributed across nodes in the network
- H04L67/104—Peer-to-peer [P2P] networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/10—File systems; File servers
- G06F16/18—File system types
- G06F16/182—Distributed file systems
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L67/00—Network arrangements or protocols for supporting network services or applications
- H04L67/01—Protocols
- H04L67/10—Protocols in which an application is distributed across nodes in the network
- H04L67/104—Peer-to-peer [P2P] networks
- H04L67/1061—Peer-to-peer [P2P] networks using node-based peer discovery mechanisms
- H04L67/1065—Discovery involving distributed pre-established resource-based relationships among peers, e.g. based on distributed hash tables [DHT]
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L67/00—Network arrangements or protocols for supporting network services or applications
- H04L67/01—Protocols
- H04L67/10—Protocols in which an application is distributed across nodes in the network
- H04L67/104—Peer-to-peer [P2P] networks
- H04L67/1074—Peer-to-peer [P2P] networks for supporting data block transmission mechanisms
- H04L67/1076—Resource dissemination mechanisms or network resource keeping policies for optimal resource availability in the overlay network
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L67/00—Network arrangements or protocols for supporting network services or applications
- H04L67/01—Protocols
- H04L67/10—Protocols in which an application is distributed across nodes in the network
- H04L67/1095—Replication or mirroring of data, e.g. scheduling or transport for data synchronisation between network nodes
Definitions
- the present invention generally relates to the field of distributed file systems and, more particularly, to such file systems that are based on distributed hash tables.
- File systems are well-known means for storing and organizing computer files and the data they contain.
- Distributed file systems provide means for storing and organizing information on multiple computer systems which are connected with one another through a network.
- An important characteristic of a distributed file system is that it presents a unified view to data and files stored therein, such that all of the data can be accessed without regard to which particular computer system, or plurality of computer systems, in the network the data is actually stored on.
- CDNs are intended as distributed systems for the rapid delivery of immutable content (usually via the Internet), such as audio-video content. This is accomplished by strategically placing copies of the content on computer systems which are located close (logically and/or physically) to users of the content and which are therefore able to quickly deliver the content to the users.
- An important characteristic of a CDN is that it is read-only: once content is placed in a CDN, the content cannot be changed—i.e., only reads by users are accelerated and there are no writes. If there is even a minute change to the content, the entire copy of the revised content must be republished in the CDN by storing a fresh copy and redistributing it throughout the network.
- BitTorrent is a very popular CDN algorithm for distribution of content on peer-to-peer (P2P) networks.
- P2P peer-to-peer
- BitTorrent is a CDN algorithm as there are no means of modifying content that is distributed in the system.
- content is divided into chunks and different computers (nodes) on the network download chunks separately.
- nodes Upon downloading a chunk, each node becomes a peer—a node capable of serving the chunk to another node.
- seeds There are also tracker nodes that keep track of peers and seeds for a given content item.
- Chunks for popular content will generally be readily available on the network, as there will be many nodes that have downloaded such chunks (the number of such downloads is indicative of the relative popularity of the chunks).
- This organic nature in the increase in availability of popular content gives BitTorrent very important read scalability where the more reads (requests for download) there are, there will be more servers (nodes that have completed downloads) to fulfill the read requests.
- the system is capable of naturally balancing and increasing serving capacity with increases in popularity and number of reads, in stark contrast to conventional centralized client-server systems where an increase in read loads placed on a single, or a fixed plurality of servers, will slow the system down.
- a distributed system includes a plurality of computer systems communicatively coupled to one another via one or more networks.
- Each of the computer systems includes a computer-readable storage device, and collectively these computer-readable storage devices store content items.
- Each content item is stored at a location in an address space of the distributed network defined by a key of a distributed hash table, and at redundant ones of the computer systems defined by three redundancy factors: R1 which is less than R2 which is less than R3, where R1 number of the computer systems of the distributed system with unique identifiers closest to a respective key of a subject content item have a redundant copy of the subject content item, at least R2 number of the computer systems have copies of any respective one of the content items for all of the content items, and none of the computer systems farther than R3 in the address space of the distributed system have a copy of the subject content item.
- a further embodiment of the present invention provides for storing content items in a distributed system by writing each content item to a storage device of a computer system of the distributed system defined by a respective key, and copying each such content item to a further R1 computer systems of the distributed system which have unique identifiers closest to a value of the respective key, where R1 is less than R2 which is less than R3, where at least R2 number of the computer systems have copies of any respective one of the content items for all of the content items, and none of the computer systems farther than R3 in an address space of the distributed system have a copy of the subject content item.
- Modifications of an individual one of the content items can be synchronized across all instances of the individual content item stored on the storage devices of the computer systems which comprise the distributed system responsive to a put operation to store a modified version of the individual content item and/or at periodic intervals. Synchronization of differences of replicas on multiple ones of the computer systems is performed by exchanging messages. When sending messages about copies each computer system stores, it is not necessary to send the entire copy but only a hash, or a sequence of hashes of pieces of content, preferably pieces of size 1 ⁇ 2 N for some integer N. The hashes indicate differences only in sub-pieces of the copy so only those sub-pieces need to be exchanged and not the entire copy.
- Still another embodiment of the present invention provides for the creation of an Internet search index by analyzing, at a first of a plurality of computer systems which are organized as a distributed system, pages stored in a local Web cache; producing, for each such analyzed page, a set of terms appearing in the analyzed page; for each occurrence k of a term in each Web page p that has been analyzed, creating an index entry IDX(k,p), and issuing a put operation into a distributed hash table distributed file system comprised of the plurality of computer systems in the distributed system, said put operation having as a key a hash value computed for term k, and having as a value an index entry for page p in a termlist for term k, the index entry including information to be displayed in response to Internet search queries.
- the value of the index entry may include one or more of: a uniform resource locator (URL) for page p; text of a link for page p; a string created by extraction of some or all of the text of the page, and a graphical image of the page p or an image contained within page p considered to be a good graphical representation of the page p.
- a uniform resource locator URL
- text of a link for page p text of a link for page p
- a string created by extraction of some or all of the text of the page and a graphical image of the page p or an image contained within page p considered to be a good graphical representation of the page p.
- FIG. 1 illustrates an example of a distributed system within which embodiments of the present invention may be implemented.
- FIG. 2 illustrates an example of a process for synchronizing content across a DHTFS in accordance with an embodiment of the invention.
- FIG. 3 illustrates an example of a computer system which may participate in a distributed system such as that shown in FIG. 1 .
- Described herein is a distributed hash table-based distributed file system (DHTFS).
- DHTFS distributed hash table-based distributed file system
- data can be written to and modified in a DHTFS.
- the present invention finds particular advantage in distributed applications, for example Internet search. Before discussing such applications, however, consider the distributed hash table (DHT) which underlies the DHTFS.
- DHT distributed hash table
- a hash function (or hash table) is a function that uniformly and, often uniquely, maps strings to a range of numbers. The number to which a hash function maps a given string is called the key for that string.
- a DHT then is a means for partitioning the space of all possible keys among a set of computers connected through a network.
- FIG. 1 illustrates an example of a distributed system 100 which includes multiple individual computer systems 102 a - 102 n , communicatively coupled with one another via one or more networks 104 .
- computer systems 102 a - 102 n form an overlay network for the present DHTFS. Notice that none of the individual computer systems 102 a - 102 n is indicated as a controller. This is the nature of a distributed system, where the operations for storing, modifying and synchronizing content consistent with the present invention are provided at each node of the network.
- Network 104 may, in one implementation, be the Internet, but could also be or include one or more local or wide area network within one or more enterprises.
- Each instance of a computer system 102 a - 102 n may be configured to perform the data storage and synchronization processes discussed herein, for example through the use of appropriately coded computer-readable instructions stored on computer-readable media and executed by computer processors associated with each computer system. These computer-readable instructions, when being executed, adapt the general purpose computer system to the specific functionalities discussed herein.
- each of these computer systems includes a storage device and the DHTFS stores content across the address space defined by these storage devices using the DHT keys as partitions for that address space.
- a DHT overlaid across distributed system 100 provides the structure for a distributed file system. That is, the file system used by distributed system 100 relies on the mappings provided by the DHT to partition the storage of content items within the distributed system so that content items are stored at individual ones of computer systems 102 a - 102 n , but are accessible to all such computer systems.
- the storage and retrieval of content items are facilitated through two principal kinds of messages in a DHT:
- Content items are organized and stored within distributed system 100 at locations identified by the DHT, which locations are distributed across the plurality of computers 102 a - 102 n .
- the number of individual computer systems that make up distributed system 100 may be very large and the individual computer systems may be interconnected across vast physical and/or logical distances through multiple network equipments (such as routers, switches, etc.).
- the present DHTFS provides strict guarantees of latencies for read and write accesses by having limits on number of accesses. The limits are bound by log M N, where N is the number of nodes in the network (i.e., the number of individual computer systems over which content is distributed), and M is a constant.
- M could be 2, in a binary organization, but it is desirable to have M>2 to reduce number of routing hops. Larger M are obtained by increasing the size of the routing table (which is stored at each node of the distributed system) and the number of nodes contacted in every routing step.
- the DHT algorithm automatically routes messages (i.e., stores content) to the particular computer in the overlay network responsible for a set of keys to which a given key belongs.
- messages i.e., stores content
- There are several choices for routing algorithms in a DHT but one of the principal requirements for a DHT routing algorithm is that it has a log(N) network diameter, meaning that the worst case delay in routing a message to a node in the DHT is a logarithmic function of the number of nodes N in the network.
- Each node has a permanent binary identification (ID) assigned to it, within range 0 ⁇ ID ⁇ S, where S is the size of the key space.
- ID permanent binary identification
- a DHT routing algorithm called Kademlia is used. This algorithm is described in Petar Maymounkov and David Mazines, Kademlia: A Peer - to - peer information System Based on the XOR Metric , presented at the 1 st International Workshop on Peer-to-peer Systems 2002.
- Kademlia DHT nodes are organized in a binary tree and each node has a routing table of size k*log(S), where S is a power of two representing the number of all possible different keys in the DHT.
- each node In Kademlia, the routing table for each node is organized into buckets, where each bucket represents contact information for nodes in progressively larger complete binary sub-trees adjacent to the node in question. For instance, the first bucket contains, at most, one node that is the immediate neighbor of the node in question and whose ID differs from the current node ID in a single bit. The next bucket contains nodes from three possible nodes in a sub-tree rooted by a node two levels up the tree, and so on.
- nodes can be frequently disconnected in an arbitrary fashion. For example, users may turn off their computers located anywhere, at any time. Therefore, in order to support consistency and availability of data, all data in the DHTFS is replicated across multiple nodes (i.e., multiple ones of computer systems 102 a - 102 n ).
- the subject data is written to a plurality of R computer systems (or, more generally, R storage locations associated with individual computer systems), where R is a redundancy factor.
- R is a redundancy factor.
- each piece of data, represented as sequence of bytes is written under a key, with a put operation to R computers with IDs currently closest to the value of the key.
- closest means that the absolute value of the difference between the binary IDs of the computer system identified by the key and the computer system under test (i.e., a candidate computer system at which to replicate the content) is a minimum.
- nodes in distributed system 100 can be arbitrarily disconnected, values stored on the nodes can become unavailable.
- nodes that were previously closest to some keys can cease to be closest.
- the nodes constantly communicate among themselves and exchange messages about the range of values each node stores. While the nodes could exchange their complete contents with one another as part of such synchronization messages, such a scheme would not be very efficient. So, in embodiments of the invention nodes do not send their complete contents, instead they send only a hash, or sequences of hashes, of the pieces of contents they hold. In one embodiment, this may be pieces of size 1 ⁇ 2 N for some integer N.
- the hashes indicate differences only in sub-pieces of the copies of the content so only those sub-pieces need to be exchanged and not entire copies of the content. If the number of changes in contents between two nodes is small, then the differences in hashes will also be small resulting in exchanging and updating only a small amount of content that is different.
- each piece of data has a tracker.
- the tracker for a given piece of data is assigned by the corresponding key for the data. If the value of a given key falls within the range of values for which a given node is responsible, then the node will keep the tracker. Further, all data is organized and split into chunks. Trackers keep complete lists of nodes holding all chunks at all times.
- Chunks are stored, organized and distributed independently. Each node that receives a chunk can become a server for that chunk. Upon receiving a chunk and becoming a server, the node is recorded on the tracker. This scheme ensures read scalability since the more popular chunks will be more widely distributed and all the nodes holding them will be able to satisfy higher number of requests per given period.
- the present DHTFS supports writes, through DHT puts.
- the DHTFS synchronization scheme ensures that copies of content are always kept in a consistent state, where differences are minimized. In particular, checking of the consistency and synchronization of the content between nodes is done on every DHT put operation and may further be done periodically, according to an established time interval.
- the single redundancy constant R is replaced by three constants R1, R2 and R3. These constants obey the relationship R1 ⁇ R2 ⁇ R3 During the consistency and synchronization check, the system ensures the following:
- R1 ⁇ R2 the system does not need to perform synchronization constantly, trying to always maintain the condition that all R2 redundant copies are always closest. This requirement is relaxed so the system tries to maintain only the condition that R1 nodes closest to a key have the corresponding data.
- R2 nodes, which do not need to be closest must have data so there need not be synchronization if a new node with an ID farther than R1 but less than R2 from a given key joins the network.
- FIG. 2 illustrates a process 200 that exemplifies the procedure for synchronizing content across the DHTFS.
- a content item is read by a node of the network.
- the content item may be read by determining its storage location in the DHTFS using the above-described routing algorithm. The read may be accomplished using a get operation.
- the content item may be a termlist for a key word from an Internet search.
- the content item is modified. This may be done in any of several ways. For example, if the content item is a document, the document may be modified in some fashion by adding or removing text, images, etc.
- a termlist may be modified if a new Web page including a key word for which the term list exists is discovered (e.g., an instance of that. Web page is downloaded and the key word is identified, resulting in a need to update the termlist.
- the modified document is written back to its storage location as determined by the DHT routing algorithm. This involves writing the document to a storage device of a computer system of the distributed system defined by a respective key. Then, at 208 , the document is synchronized so that multiple instances of the document exist in the DHTFS in the even one or more nodes storing the content item become unavailable.
- Synchronization is accomplished by copying the document to a further R1 computer systems of the distributed system which have unique identifiers closest to a value of the respective key, where R1 is less than R2 which is less than R3, at least R2 number of the computer systems having copies of any respective document for all of the documents stored in the system, and none of the computer systems farther than R3 in an address space of the distributed system having a copy of the subject document.
- consistency of chunks is maintained at all times. Every node periodically sends to the tracker confirmation about chunks that it holds, so that the tracker can know if the node is active and if it still contains the subject chunk. Trackers also use the confirmation of chunks in reissuing puts for all keys, to maintain consistency and redundancy. Trackers are also periodically refreshed so that inactive chunk holders are removed from tracker lists. In case there is an insufficient number of holders for a chunk, active nodes are chosen and instructed to download such chunks.
- a distributed search engine can be implemented on top of the present DHTFS by using trackers to hold data for termlists for keywords—lists of pages containing the keywords. Users viewing Web pages on the Internet through their browsers are provided browser extensions that are capable of analyzing keywords on a page, with special attention given to important keywords as denoted by factors such as occurrences in titles, heading, bolded font, position in the page, etc.
- information contained in copies of Web pages and Web histories of the pages retrieved from the Internet is used to create a distributed search index.
- the system builds termlists for all keywords and stores them in the DHTFS.
- termlists are built up through puts issued upon analysis of pages viewed by users.
- pages are obtained through distributed crawling from individual client machines.
- Web caching is a well-known practice.
- caches deployed throughout the Web examples include buffers in the Internet core and at edge routers, caches deployed by Internet service providers to better control the behavior of their networks, caches deployed by the operators of CDNs, operating system buffers on individual computers of users that hold information transmitted through Internet and many other locations.
- HTML pages received in response to user requests are cached by a user's browser, and such caches can grow to significant sizes.
- each page in a local Web cache or history is analyzed and a set of terms appearing in the page is produced for the analyzed page.
- an index entry IDX(k,p) is created.
- a put operation is issued into the DHTFS comprised of the plurality of individual user's computers in the system.
- An example of such a DHTFS put operation is as follows:
- the browser extension may be configured to indicate to a user whether it considers a subject page to be public, and therefore subject to sharing and publication within the DHTFS, or considers the page to be private and not subject to sharing.
- the user can be provided an opportunity to override such a determination of page status and force any page to be private and not shared, or alternately, force a page to be considered public and shared.
- intersections of lists of results for each keyword need to be performed.
- One way in which to determine such an intersection is to fetch all required termlists and then intersect them. Such a process would, however, be prohibitively expensive in a distributed system in terms of the time required to fetch the termlists.
- each search result is hashed to a key.
- the system first sends bitmasks corresponding to small prefixes of keys for results.
- bitmasks are much smaller than complete lists of results and this way the system is able to discard all the results where there are no matches even with small prefixes since such results could not possibly match with full prefixes. It is possible to have a false positive, where prefixes match but full keys do not, but such cases are easily resolved upon fetching of full results with keys.
- the probability of such partial matches is very low.
- various embodiments of the present invention may be implemented with the aid of computer-implemented processes or methods (i.e., computer programs or routines) or on any programmable or dedicated hardware implementing digital logic.
- Such processes may be rendered in any computer language including, without limitation, a object oriented programming language, assembly language, markup languages, and the like, as well as object-oriented environments such as the Common Object Request Broker Architecture (CORBA), JavaTM and the like, or on any programmable logic hardware like CPLD, FPGA and the like.
- CORBA Common Object Request Broker Architecture
- JavaTM JavaTM
- CPLD programmable logic hardware
- Such apparatus may be specially constructed for the required purposes, or may be appropriately programmed, or selectively activated or reconfigured by a computer-readable instructions stored in or on computer-readable storage media (such as, but not limited to, any type of disk including floppy disks, optical disks, hard disks, CD-ROMs, and magnetic-optical disks, or read-only memories (ROMs), random access memories (RAMs), erasable ROMs (EPROMs), electrically erasable ROMs (EEPROMs), magnetic or optical cards, or any type of media suitable for storing computer-readable instructions) to perform the operations.
- ROMs read-only memories
- RAMs random access memories
- EPROMs erasable ROMs
- EEPROMs electrically erasable ROMs
- magnetic or optical cards or any type of media suitable for storing computer-readable instructions
- Computer system 300 upon which an embodiment of the invention may be implemented, includes a bus 302 or other communication mechanism for communicating information, and a processor 304 coupled with the bus 302 for processing information.
- Computer system 300 also includes a main memory 306 , such as a RAM or other dynamic storage device, coupled to the bus 302 for storing information and instructions to be executed by processor 304 .
- Main memory 306 also may be used for storing temporary variables or other intermediate information during execution of instructions to be executed by processor 304 .
- Computer system 300 further includes a ROM 308 or other static storage device coupled to the bus 302 for storing static information and instructions for the processor 304 .
- a storage device 310 such as a hard disk, is provided and coupled to the bus 302 for storing information and instructions.
- Computer system 300 may be coupled via the bus 302 to a display 312 for displaying information to a computer user.
- An input device 314 is coupled to the bus 302 for communicating information and command selections to the processor 304 .
- cursor control device 316 is Another type of user input device, such as a mouse, a trackball, or cursor direction keys for communicating direction information and command selections to processor 304 and for controlling cursor movement on the display 312 .
- Computer system 300 also includes a communication interface 318 coupled to the bus 302 .
- Communication interface 308 provides for two-way, wired and/or wireless data communication to/from computer system 300 , for example, via a local area network (LAN).
- Communication interface 318 sends and receives electrical, electromagnetic or optical signals which carry digital data streams representing various types of information.
- two or more computer systems 300 may be networked together in a conventional manner with each using a respective communication interface 318 .
- Network link 320 typically provides data communication through one or more networks to other data devices.
- network link 320 may provide a connection through LAN 322 to a host computer 324 or to data equipment operated by an Internet service provider (ISP) 326 .
- ISP 326 in turn provides data communication services through the Internet 328 , which, in turn, may provide connectivity to multiple remote computer systems 330 a - 330 n (any or all of which may be similar to computer system 300 .
- LAN 322 and Internet 328 both use electrical, electromagnetic or optical signals which carry digital data streams.
- Computer system 300 can send messages and receive data through the network(s), network link 320 and communication interface 318 .
- Note that computer system 300 may be an example of a computer system 102 a - 102 n from FIG. 1 .
- a distributed hash table-based distributed file system which finds particular advantage in distributed applications has been described.
- DHT items e.g., keyword and URL trackers
- a hybrid system that includes the above-described distributed system and a logically centralized collection of computers.
- the DHT items stored in this centralized collection of computers may be used less frequently than those which are stored in the distributed system, for example because they are associated with rare keywords that infrequently appear in queries or rare URLs which infrequently appear in ranked results.
- the use of such a collection of computers increases the efficiency of the overall system by using the distributed portion of the system for storing and caching frequently used keyword trackers and URL trackers.
- both the distributed system and the centralized system that includes a collection of computers connected through a network may be combined with a document partitioned system for rare and less frequently accessed documents.
- the more frequently accessed documents and queries may be answered by the distributed system and queries may be simultaneously submitted to the centralized portion.
- Such a hybrid system would increase efficiencies and the coverage of distributed system with a fixed capacity by enhancing the results from the distributed system with the results from a document partitioned, centralized system.
- the entire corpus of documents may be partitioned among a collection of computers, each computer being responsible for a subset of the entire corpus. Queries may be sent to all computers and results assembled for groups of results obtained from each computer responsible for a subset of the entire corpus.
- lists of DHTFS distributed hash identifiers stored on keyword trackers can be partitioned, with partitions stored in the DHTFS on multiple machines in a distributed fashion.
Abstract
Description
-
- put(key,value)
- get(key)
The DHT put message is used for storing an arbitrary sequence of bytes value under the key. The DHT get message returns the last value stored in the DHT under a given key.
R1<R2<R3
During the consistency and synchronization check, the system ensures the following:
-
- 1. R1 nodes with IDs closest to the key of the data being put have the data.
- 2. At least R2 nodes have the copies of given data for all data. This ensures that there are always enough redundant trackers so no information is lost. In the present system, information can be lost only when all R2 nodes holding copies of some data leave the network between puts or synchronizations.
- 3. No nodes farther than R3 in the current node ID space have the data. This ensures that there are no nodes that hold the tracker for some data and are outside of K nodes returned when a find-k operation is performed on a given key. A find-k operation in Kademlia always returns K IDs closest to a given key. If there was a node holding data with a given key outside of the K closest nodes, the successive puts would not go to such a node and it could not be synchronized. The condition that no nodes farther than R3 from a given key hold the corresponding data is ensured by deleting the data from such nodes that are too far.
-
- 1. They are not able to access dynamic Web pages that are generated in response to Hypertext Transport Protocol (HTTP) GET and POST queries submitted by users through HTML FORM elements.
- 2. There are very significant restrictions in robots.txt files on Web sites on how fast crawlers are able to crawl them; in addition there are many restrictions on what pages can be crawled.
- 3. Due to the size of the Web, complexities of the ranking algorithms and issues related to other aspects of operation of Web-wide search engines, the information in the search indices of major search engines is updated only infrequently, typically on the order of weeks.
-
- 1. The local Web caches and histories contain copies of dynamic pages inaccessible to crawlers because users themselves submitted the information in HTML FORM elements required to get responses; such pages are inaccessible to crawlers since crawlers have no way of knowing what information to include and submit in HTML FORM elements.
- 2. There are no restrictions on how fast and what Web pages can be retrieved since the pages have been fetched by users through their browsers and are not subject to limitations imposed on crawlers in robots.txt files.
- 3. Because users are allowed to access Web sites as often as they wish, a large enough plurality of users is capable of accessing a site much faster than a crawler even for pages which crawlers are allowed to access.
- 4. Information about what links users click on can be used to improve ranking and the quality of search results.
-
- put(hash(k),IDX(URL(p), TITLE(p),SUMMARY(p),PICT(p)))
where hash(k) is the hash value computed for term k; URL(p) is the URL for page p; TITLE(p) is the text of the link for page p; SUMMARY(p) is a string created by extraction of some or all of the text of the page, stripped of HTML formatting; and PICT(p) is a graphical image of the entire page or some image contained within the page that is considered as a good graphical representation of the page. Entries URL(p), SUMMARY(p), TITLE(p) and PICT(p) represent the index entry for page p in the termlist for the term k. The index entry for the page can be defined in other ways by including more, or less, of the pieces of information that should be displayed in results.
- put(hash(k),IDX(URL(p), TITLE(p),SUMMARY(p),PICT(p)))
Claims (20)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US12/758,417 US8296283B2 (en) | 2009-10-29 | 2010-04-12 | DHT-based distributed file system for simultaneous use by millions of frequently disconnected, world-wide users |
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US12/608,932 US7716179B1 (en) | 2009-10-29 | 2009-10-29 | DHT-based distributed file system for simultaneous use by millions of frequently disconnected, world-wide users |
US12/758,417 US8296283B2 (en) | 2009-10-29 | 2010-04-12 | DHT-based distributed file system for simultaneous use by millions of frequently disconnected, world-wide users |
Related Parent Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US12/608,932 Continuation US7716179B1 (en) | 2009-10-29 | 2009-10-29 | DHT-based distributed file system for simultaneous use by millions of frequently disconnected, world-wide users |
Publications (2)
Publication Number | Publication Date |
---|---|
US20110106758A1 US20110106758A1 (en) | 2011-05-05 |
US8296283B2 true US8296283B2 (en) | 2012-10-23 |
Family
ID=42139431
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US12/608,932 Active US7716179B1 (en) | 2009-10-29 | 2009-10-29 | DHT-based distributed file system for simultaneous use by millions of frequently disconnected, world-wide users |
US12/758,417 Active 2029-12-24 US8296283B2 (en) | 2009-10-29 | 2010-04-12 | DHT-based distributed file system for simultaneous use by millions of frequently disconnected, world-wide users |
Family Applications Before (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US12/608,932 Active US7716179B1 (en) | 2009-10-29 | 2009-10-29 | DHT-based distributed file system for simultaneous use by millions of frequently disconnected, world-wide users |
Country Status (2)
Country | Link |
---|---|
US (2) | US7716179B1 (en) |
WO (1) | WO2011053376A1 (en) |
Families Citing this family (18)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8326827B2 (en) * | 2008-04-14 | 2012-12-04 | Magic Network Sarl | Network peer-to-peer goods and services delivery system and method for ranking peers by degrees of association |
US7716179B1 (en) * | 2009-10-29 | 2010-05-11 | Wowd, Inc. | DHT-based distributed file system for simultaneous use by millions of frequently disconnected, world-wide users |
US8301596B2 (en) | 2010-01-15 | 2012-10-30 | Hulu Llc | Method and apparatus for providing supplemental video content for third party websites |
US20120221546A1 (en) * | 2011-02-24 | 2012-08-30 | Rafsky Lawrence C | Method and system for facilitating web content aggregation initiated by a client or server |
US8838968B2 (en) * | 2012-05-14 | 2014-09-16 | Ca, Inc. | System and method for virtual machine data protection in a public cloud |
JP2014044553A (en) * | 2012-08-27 | 2014-03-13 | Fujitsu Ltd | Program, information processing device, and information processing system |
CN103902632B (en) * | 2012-12-31 | 2018-01-02 | 华为技术有限公司 | The method, apparatus and electronic equipment of file system are built in key assignments storage system |
CN103488433B (en) * | 2013-09-18 | 2016-05-11 | 北京思特奇信息技术股份有限公司 | A kind of batch documents method of operating and system based on distributed file system |
US9495457B2 (en) * | 2013-12-26 | 2016-11-15 | Iac Search & Media, Inc. | Batch crawl and fast crawl clusters for question and answer search engine |
US9800575B1 (en) * | 2014-09-24 | 2017-10-24 | Ebay Inc. | Assigning storage responsibility in a distributed data storage system with replication |
US11095715B2 (en) | 2014-09-24 | 2021-08-17 | Ebay Inc. | Assigning storage responsibility in a distributed data storage system with replication |
US10503791B2 (en) | 2017-09-04 | 2019-12-10 | Borislav Agapiev | System for creating a reasoning graph and for ranking of its nodes |
CN110022222B (en) * | 2018-01-10 | 2022-02-25 | 中兴通讯股份有限公司 | Management method, network node, management node and system of DHT network |
US10732940B2 (en) | 2018-04-27 | 2020-08-04 | EMC IP Holding Company LLC | Enterprise services framework for presentation layer management |
US10740537B2 (en) * | 2018-11-01 | 2020-08-11 | Dell Products L.P. | Enterprise form dependency visualization and management |
US20190278765A1 (en) * | 2018-12-19 | 2019-09-12 | Alibaba Group Holding Limited | Shared secret-based blockchain storage |
US11456877B2 (en) * | 2019-06-28 | 2022-09-27 | Intel Corporation | Unified accelerator for classical and post-quantum digital signature schemes in computing environments |
CN110381157A (en) * | 2019-07-26 | 2019-10-25 | 正链科技(深圳)有限公司 | A kind of distributed directional data storage P2P network based on Kademlia algorithm |
Citations (20)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20020129014A1 (en) * | 2001-01-10 | 2002-09-12 | Kim Brian S. | Systems and methods of retrieving relevant information |
US20040267809A1 (en) | 2003-06-23 | 2004-12-30 | Microsoft Corporation | Resynchronization of multiple copies of a database after a divergence in transaction history |
US20050198286A1 (en) | 2004-01-30 | 2005-09-08 | Zhichen Xu | Selecting nodes close to another node in a network using location information for the nodes |
US20060224775A1 (en) | 2003-08-01 | 2006-10-05 | Nitgen Technologies Inc. | Contents synchronization system in network enviroment and a method therefor |
US20060262726A1 (en) | 2005-03-25 | 2006-11-23 | Microsoft Corporation | Self-evolving distributed system |
US20070133554A1 (en) | 2005-07-12 | 2007-06-14 | Werner Ederer | Data storage method and system |
US20070162462A1 (en) | 2006-01-03 | 2007-07-12 | Nec Laboratories America, Inc. | Wide Area Networked File System |
US20080005188A1 (en) | 2006-06-30 | 2008-01-03 | Microsoft Corporation | Content Synchronization in a File Sharing Environment |
US20080130516A1 (en) | 2004-12-21 | 2008-06-05 | Electronics And Telecommunications Research Institute | P2p Overplay Network Construction Method and Apparatus |
US20080181135A1 (en) | 2007-01-31 | 2008-07-31 | Praveen Yalagandula | Distributed network distance detemination using a distributed hash table overlay network |
US20080201335A1 (en) | 2007-02-20 | 2008-08-21 | Nec Laboratories America, Inc. | Method and Apparatus for Storing Data in a Peer to Peer Network |
US7418454B2 (en) | 2004-04-16 | 2008-08-26 | Microsoft Corporation | Data overlay, self-organized metadata overlay, and application level multicasting |
US20080208996A1 (en) | 2007-02-28 | 2008-08-28 | Solid State Networks, Inc.(An Arizona Corporation) | Methods and apparatus for data transfer in networks using distributed file location indices |
US20080225780A1 (en) * | 2007-03-13 | 2008-09-18 | Nortel Networks Limited | Use of distributed hashtables for wireless access mobility management |
US7447684B2 (en) | 2006-04-13 | 2008-11-04 | International Business Machines Corporation | Determining searchable criteria of network resources based on a commonality of content |
WO2009031156A2 (en) | 2007-09-09 | 2009-03-12 | Ingrid Networks Ltd | Method and apparatus for grid based data protection |
US20090125637A1 (en) | 2007-11-09 | 2009-05-14 | Nokia Corporation | Method, Apparatus and Computer Program Product for Providing Data Management in a P2P Network |
US7536470B2 (en) | 2004-09-03 | 2009-05-19 | Microsoft Corp. | Random access read/write media format for an on-demand distributed streaming system |
US7587426B2 (en) | 2002-01-23 | 2009-09-08 | Hitachi, Ltd. | System and method for virtualizing a distributed network storage as a single-view file system |
US7716179B1 (en) | 2009-10-29 | 2010-05-11 | Wowd, Inc. | DHT-based distributed file system for simultaneous use by millions of frequently disconnected, world-wide users |
-
2009
- 2009-10-29 US US12/608,932 patent/US7716179B1/en active Active
-
2010
- 2010-04-12 US US12/758,417 patent/US8296283B2/en active Active
- 2010-04-12 WO PCT/US2010/030774 patent/WO2011053376A1/en active Application Filing
Patent Citations (21)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20020129014A1 (en) * | 2001-01-10 | 2002-09-12 | Kim Brian S. | Systems and methods of retrieving relevant information |
US7587426B2 (en) | 2002-01-23 | 2009-09-08 | Hitachi, Ltd. | System and method for virtualizing a distributed network storage as a single-view file system |
US20040267809A1 (en) | 2003-06-23 | 2004-12-30 | Microsoft Corporation | Resynchronization of multiple copies of a database after a divergence in transaction history |
US20060224775A1 (en) | 2003-08-01 | 2006-10-05 | Nitgen Technologies Inc. | Contents synchronization system in network enviroment and a method therefor |
US20050198286A1 (en) | 2004-01-30 | 2005-09-08 | Zhichen Xu | Selecting nodes close to another node in a network using location information for the nodes |
US7418454B2 (en) | 2004-04-16 | 2008-08-26 | Microsoft Corporation | Data overlay, self-organized metadata overlay, and application level multicasting |
US7536470B2 (en) | 2004-09-03 | 2009-05-19 | Microsoft Corp. | Random access read/write media format for an on-demand distributed streaming system |
US20080130516A1 (en) | 2004-12-21 | 2008-06-05 | Electronics And Telecommunications Research Institute | P2p Overplay Network Construction Method and Apparatus |
US20060262726A1 (en) | 2005-03-25 | 2006-11-23 | Microsoft Corporation | Self-evolving distributed system |
US20070133554A1 (en) | 2005-07-12 | 2007-06-14 | Werner Ederer | Data storage method and system |
US20070162462A1 (en) | 2006-01-03 | 2007-07-12 | Nec Laboratories America, Inc. | Wide Area Networked File System |
US7447684B2 (en) | 2006-04-13 | 2008-11-04 | International Business Machines Corporation | Determining searchable criteria of network resources based on a commonality of content |
US20080005188A1 (en) | 2006-06-30 | 2008-01-03 | Microsoft Corporation | Content Synchronization in a File Sharing Environment |
US20080181135A1 (en) | 2007-01-31 | 2008-07-31 | Praveen Yalagandula | Distributed network distance detemination using a distributed hash table overlay network |
US20080201428A1 (en) | 2007-02-20 | 2008-08-21 | Nec Laboratories America, Inc. | Method for Operating a Fixed Prefix Peer to Peer Network |
US20080201335A1 (en) | 2007-02-20 | 2008-08-21 | Nec Laboratories America, Inc. | Method and Apparatus for Storing Data in a Peer to Peer Network |
US20080208996A1 (en) | 2007-02-28 | 2008-08-28 | Solid State Networks, Inc.(An Arizona Corporation) | Methods and apparatus for data transfer in networks using distributed file location indices |
US20080225780A1 (en) * | 2007-03-13 | 2008-09-18 | Nortel Networks Limited | Use of distributed hashtables for wireless access mobility management |
WO2009031156A2 (en) | 2007-09-09 | 2009-03-12 | Ingrid Networks Ltd | Method and apparatus for grid based data protection |
US20090125637A1 (en) | 2007-11-09 | 2009-05-14 | Nokia Corporation | Method, Apparatus and Computer Program Product for Providing Data Management in a P2P Network |
US7716179B1 (en) | 2009-10-29 | 2010-05-11 | Wowd, Inc. | DHT-based distributed file system for simultaneous use by millions of frequently disconnected, world-wide users |
Non-Patent Citations (9)
Title |
---|
Antony Rowstron & Peter Druschel, Pastry: Scalable, Decentralized Object Location, and Routing for Large-Scale Peer-to-Peer Systems, Lecture Notes in Computer Science, vol. 2218, Proceedings of the IFIP/ACM International Conference on Distributed Systems Platforms, Heidelberg, pp. 329-350, 2001. |
Author: Kaashoek et al Title: A imple degree-optimal distributed hash table Date: 2003 Publisher: IRIS project http://project-iris.net Pertinent pp. 6. * |
Ion Stoica et al., Chord: A Scalable Peer-to-Peer Lookup Service for Internet Applications, Proceedings of the 2001 Conference on Applications, Technologies, Architectures, and Protocols for Computer Communications (San Diego, California) SIGCOMM '01, pp. 149-160, ACM, New York, NY, 2001. |
M. Frans Kaashoek and David R. Karger, Koorde: A simple degree-optimal distributed hash table; IRIS Project; http://project-iris.net; 2003, 6pp. |
Ribeiro, H.B. et al., Implementing a Peer-to-Peer Web Browser for Publishing and Searching Web Pages on Internet, 21st International Conference on Advanced Information Networking and Applications, 2007. AINA '07., pp. 754-761, May 21-23, 2007, Niagra Falls, ON, Canada. |
Sylvia Ratnasamy et al., A scalable content-addressable network, ACM SIGCOMM Computer Communication Review, vol. 31, issue 4 (Oct. 2001), pp. 161-172, 2001. |
Wenhui Ma et al., Scalable keyword search based on semantic in DHT based peer-to-peer system, Proceedings of the 2nd international conference on Scalable information systems, Suzhou, China, ACM International Conference Proceeding Series; vol. 304 archive,article No. 304, 2007. |
WOWD, Inc.; International Application No. PCT/US2010/030774 filed Apr. 12, 2010; International Search Report and Written Opinion; Nov. 19, 2010; ISA/KR; 9pp. |
Zhu, Y. Hu, Y., Efficient, proximity-aware load balancing for DHT-based P2P systems, IEEE Transactions on Parallel and Distributed Systems, issue 4, pp. 349-361, Apr. 2005. |
Also Published As
Publication number | Publication date |
---|---|
WO2011053376A1 (en) | 2011-05-05 |
US7716179B1 (en) | 2010-05-11 |
US20110106758A1 (en) | 2011-05-05 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US8296283B2 (en) | DHT-based distributed file system for simultaneous use by millions of frequently disconnected, world-wide users | |
Reynolds et al. | Efficient peer-to-peer keyword searching | |
US9967298B2 (en) | Appending to files via server-side chunking and manifest manipulation | |
US7529723B2 (en) | Multi-tiered structure for file sharing based on social roles | |
US9183213B2 (en) | Indirection objects in a cloud storage system | |
AU2010235939B2 (en) | Systems, methods and programming for routing and indexing globally addressable objects and associated business models | |
US8676855B2 (en) | Distributed storage system, management apparatus, node apparatus, recording medium on which node program is recorded, page information acquisition method, recording medium on which page information sending program is recorded, and page information sending method | |
US7877457B2 (en) | Peer to peer gateway | |
Stribling et al. | OverCite: A cooperative digital research library | |
KR20060047899A (en) | Distributed hosting of web content using partial replication | |
Khudhur et al. | Siva-The IPFS search engine | |
JP2008102795A (en) | File management device, system, and program | |
Mohammadi et al. | Data replication mechanisms in the peer‐to‐peer networks | |
Yang et al. | An efficient interest-group based search mechanism in unstructured peer-to-peer networks | |
Liu et al. | Supporting efficient keyword-based file search in peer-to-peer file sharing systems | |
Yasin et al. | Intelligent cooperative least recently used web caching policy based on J48 classifier | |
Sahni | Information Retrieval in Resource Constrained Environment | |
Li | Ontological Directory and Directory Load-Balancing for Large-Scale Grids | |
Skobeltsyn | Query-driven indexing in large-scale distributed systems | |
Anand et al. | Index partitioning strategies for peer-to-peer web archival | |
Savage et al. | Search on the cloud file system | |
Yasin et al. | Cooperative Web Proxy Caching for Media Objects Based on Peer-to-Peer Systems | |
Kim et al. | Efficient resource management for the P2P Web caching | |
Kim et al. | P2P support for web proxy caching with web characteristics | |
Lopes et al. | Using distributed balanced trees over dhts for building large-scale indexes |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: WOWD, INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:AGAPIEV, BORISLAV;KABILJO, IGOR;SIGNING DATES FROM 20090922 TO 20090928;REEL/FRAME:026323/0207 |
|
FEPP | Fee payment procedure |
Free format text: ENTITY STATUS SET TO UNDISCOUNTED (ORIGINAL EVENT CODE: BIG.); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:WOWD, INC.;REEL/FRAME:027008/0060Effective date: 20110623 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
FEPP | Fee payment procedure |
Free format text: PAYOR NUMBER ASSIGNED (ORIGINAL EVENT CODE: ASPN); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
FPAY | Fee payment |
Year of fee payment: 4 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044101/0405Effective date: 20170929 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 8TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1552); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 8 |