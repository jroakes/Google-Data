CN103503000A - Facial recognition - Google Patents
Facial recognition Download PDFInfo
- Publication number
- CN103503000A CN103503000A CN201280018045.0A CN201280018045A CN103503000A CN 103503000 A CN103503000 A CN 103503000A CN 201280018045 A CN201280018045 A CN 201280018045A CN 103503000 A CN103503000 A CN 103503000A
- Authority
- CN
- China
- Prior art keywords
- user identifier
- user
- face
- digital photos
- template
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V40/00—Recognition of biometric, human-related or animal-related patterns in image or video data
- G06V40/10—Human or animal bodies, e.g. vehicle occupants or pedestrians; Body parts, e.g. hands
- G06V40/16—Human faces, e.g. facial parts, sketches or expressions
- G06V40/172—Classification, e.g. identification
- G06V40/173—Classification, e.g. identification face re-identification, e.g. recognising unknown faces across different face tracks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/20—Image preprocessing
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/40—Extraction of image or video features
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/70—Arrangements for image or video recognition or understanding using pattern recognition or machine learning
- G06V10/74—Image or video pattern matching; Proximity measures in feature spaces
- G06V10/75—Organisation of the matching processes, e.g. simultaneous or sequential comparisons of image or video features; Coarse-fine approaches, e.g. multi-scale approaches; using context analysis; Selection of dictionaries
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V20/00—Scenes; Scene-specific elements
- G06V20/30—Scenes; Scene-specific elements in albums, collections or shared content, e.g. social network photos or video
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V40/00—Recognition of biometric, human-related or animal-related patterns in image or video data
- G06V40/50—Maintenance of biometric data or enrolment thereof
Abstract
Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for performing facial recognition. In one aspect, a method includes accessing a first digital photograph. A first face template is generated for each face detected in the first digital photograph. Second user identifiers that are associated with a first user identifier are determined. A digital photograph index of photographs, user identifiers, and areas in the digital photographs in which a face of a user identified by user identifier is located is accessed. Second user identifiers are selected, and second face templates are generated from the faces of the user the digital photographs.; First face templates that match second face templates are identified, and for each first face template that matches a second face template, data is generated specifying the area in the first digital photograph in which the face of the second user is located.
Description
PRIORITY CLAIM
The application requires the U.S. Patent Application Serial Number No.61/444 submitted on February 18th, 2011 according to 35USC § 119 (e), 425 right of priority, merge its full content hereby by reference.
Background technology
This instructions relates to in the situation that do not need the longer-term storage of biometric information to carry out the process of face recognition.Exist and wherein can process to identify the existence of people's face and the system of position to digital picture now.Part in these systems is determined that eigenwert (for example, the relative position of eyes, nose, lower jaw and spacing) is determined and have people's face in image.
Also exist now for identified face being identified the system for the facial title of identification automatically.The biometric model of the many faces based on formulating known person in these systems, and store this biometric model with the form of face recognition template.When unknown face being detected after a while in digital picture, this unknown face is analyzed characteristic information extraction, and this information and the biometric model set of the known face of having stored are compared to determine approaching coupling.Then, the identifier that this unknown is facial and biometric model with coupling is associated is associated.
Yet, usually unpractical, safeguard the database of such template.Unrealistic may be due to system resource constraints and other nonsystematic resource limitations.For example, for example, agreement (nonsystematic resource limitation) between memory stores (, system resource constraints) and privacy concern, legal provisions, litigant can limit the ability of safeguarding template database.A solution is that " immediately " generates the face recognition template when the needs face-recognition procedure.Yet system may be safeguarded millions of photographs, and may be consuming time to the generation of template, because need many resources to come comparison film to be processed.
Summary of the invention
This instructions has been described and following relevant technology: in the situation that basically do not use the biometric information of having stored, carry out method and the technology of automatic face identification.
Generally speaking, described theme innovation aspect can be specialized in comprising the method for following actions in this manual: at the data processing equipment place, access the first digital photos; For each face detected in the first digital photos generates the first facial template; Determine the second user identifier be associated with the first user identifier, first user identifier and the second user identifier identification user; Access digital print reference, it carries out index by the user identifier comparison film, and be each digital photos and each user identifier that this digital photos is carried out to index, the user's that the designated user identifier is identified face is arranged in the zone of this digital photos wherein; Select the second user identifier, and, for each in selected the second user identifier, each in the face of the user from the predefine zone of the digital photos at this second user identifier institute index generates the second face template for this second user identifier; The first facial template that identification and the second face template are complementary; And be each the first facial template be complementary with the second face template, the second user's that the second user identifier of generation appointment the second face template is identified face is arranged in the data in the zone of the first digital photos wherein.Other embodiment of this aspect comprise the action that is configured to carry out described method, are coded in correspondence system, device and computer program on computer memory device.
Various embodiment can comprise part in following characteristics, all or not comprise following characteristics.Each face template can be stored in the perishability storer, and is not retained after the first facial template that can be complementary at identification and the second face template.Determine that the second user identifier be associated with the first user identifier can be included as each in a plurality of the second user identifiers, generate intimate property score value, the second user's that the first user that its expression first user identifier is identified and the second user identifier are identified relation; And determine that the second user identifier with the intimate property score value that meets threshold value is associated with the first user identifier.Described action may further include according to intimate property score value the second user identifier is sorted, and sorts to select the second user identifier, is that the second user identifier generates the second face template, and the first facial template that is complementary of identification and the second face template according to this.For each in a plurality of the second user identifiers generates each digital photos that intimate property score value can be included as first user identifier institute index, determine the second user identifier that this digital photos is carried out to index, and be each second user identifier, the proportional value of quantity of the digital photos of part based on to by first user identifier and the second user identifier index is determined intimate property score value.Intimate property score value is part each time be generated based in digital photos further.Determine intimate property score value for each in a plurality of the second user identifiers generates the proportional value of quantity that intimate property score value can comprise the digital photos of part based on to the second user, wherein said first user has carried out described the second user's of mark described digital photos with described the second user's described identifier.Intimate property score value is each the time of part based in first user reference numerals photo further.Definite the second user identifier be associated with the first user identifier can comprise by the contacts list for the first user identifier selects the second user identifier be associated with the first user identifier.Described action may further include selects the 3rd user identifier, each the 3rd user identifier is in the digital photos index, also the digital photos of the one or more index in first user identifier and the second user identifier carries out the user identifier of index, for each in selected the 3rd user identifier, the face of user from the predefine zone of the digital photos at the 3rd user identifier institute index is that the 3rd user identifier generates the 3rd face template, the first facial template that identification and the 3rd face template are complementary, and be each the first facial template be complementary with the 3rd face template, the 3rd user's that the 3rd user identifier of generation appointment the 3rd face template is identified face is arranged in the data in the zone of the first digital photos wherein.Described action may further include each the first facial template be complementary for the second face template with the second user identifier, for this first facial template generates quality score, determine whether this quality score surpasses the quality score threshold value, if and this quality score surpasses the quality score threshold value, the data that will carry out index to the first photo by the second user identifier are stored in the digital photos index, and specify the second user's that the second user identifier identifies face to be arranged in the zone of digital photos wherein.
Another innovation aspect of described theme can be specialized in comprising the method for following actions in this manual: at the data processing equipment place, access the first digital photos, for each face detected in the first digital photos generates face template, for each face template: determine user identifier, each user identifier is identified the user that its face detected in the first digital photos has been used to generate this face template, for this face template generates quality score, determine whether this quality score surpasses the quality score threshold value, if and this quality score surpasses the quality score threshold value, will be by for the definite user identifier of this face template, the first photo being carried out to the data of index, the data that the user's that this quality score and appointment first user identifier are identified face is arranged in the zone of the first digital photos wherein are stored in the digital photos index.Other embodiment of this aspect comprise the action that is configured to carry out described method, are coded in correspondence system, device and computer program on computer memory device.
Various embodiment can comprise part in following characteristics, all or not comprise following characteristics.Determine whether quality score surpasses the quality score threshold value and comprise: by user identifier, access digital print reference; The quality score of other face templates of the user who identifies from this user identifier of digital photos indexed search, the zone that the face of each user who identifies from user identifier in these other face templates is arranged in different digital photo wherein generates; And when the quality score of the face template of the first digital photos surpass from the digital photos indexed search to the user's that identifies of user identifier the quality score of other face templates at least one the time, determine that quality score surpasses the quality score threshold value.In response to the face template of determining the first digital photos surpass from the digital photos indexed search to the user's that identifies of user identifier the quality score of other face templates at least one, remove from the digital photos index different digital photo that the user's that user identifier is identified face is positioned at wherein and carry out index, and generate the data of this corresponding face template quality score from it.
Can realize the specific embodiment of described theme in this manual, so that realize one or more in following advantages.By for selected user identifier collection, optionally generating face template, with respect to being that much bigger photograph collection generates face template, reduced and carried out required processing resource and the time of face-recognition procedure.The required time can be so that the reduction that does not cause the user to experience as delay that the user perceived.In addition, face template needn't be retained longer-term storage, and can after carrying out face-recognition procedure, from storer, remove, thereby guarantees to observe one or more nonsystematic resource limitations.
At accompanying drawing with the middle one or more embodiments of the detail of described theme in this manual of having set forth are described below.According to description, accompanying drawing and claim, other features, aspect and the advantage of this theme will become apparent.
The accompanying drawing explanation
Fig. 1 is according to embodiment of the present disclosure, for carrying out the block diagram in the system of the face recognition of digital picture.
Fig. 2 diagram according to embodiment of the present disclosure, for use the conceptual model of face-image in face-recognition procedure.
Fig. 3 diagram according to embodiment of the present disclosure, for use another conceptual model of the face-image in digital photo in face-recognition procedure.
Fig. 4 is according to embodiment of the present disclosure, for the process flow diagram of the instantiation procedure of carrying out face recognition.
Fig. 5 is according to embodiment of the present disclosure, for selecting to treat to carry out into it process flow diagram of instantiation procedure of user identifier of user of face recognition.
Fig. 6 is according to embodiment of the present disclosure, for the process flow diagram of the selected user's of discriminating digit image instantiation procedure.
Fig. 7 is according to embodiment of the present disclosure, for upgrading the process flow diagram of digital picture index with the instantiation procedure that uses in face-recognition procedure.
Fig. 8 is the block diagram of disposal system able to programme.
In each accompanying drawing, identical reference number and mark are indicated identical element.
Embodiment
This document described according to embodiment of the present disclosure for especially in the situation of social networks, in the situation that do not use the biometric data of having stored, carry out system and the technology of face recognition.As described below, for the face-image in the digital photo that is submitted to computer system is manual, semi-automatic or automatic mark is associated described face-image with people's the identifier under them.For select to participate in such system and permit the people that their face is automatically recognized, the digital photo set with face of identification is associated with the various people of shooting in photograph online identifier.When needed, the photograph set that is associated with particular person or the face-image in them are analyzed and created interim face recognition model for this people.Then, this model and the feature of extracting from unknown face-image are compared to identify possible coupling, then, delete this model.
From wherein retain with to know template or other biological continuous data that others is associated different for some facial-recognition security systems of following identifying operation.The longer-term storage of biometric data may cause privacy concern in various people, and, in some jurisdiction, such longer-term storage of biometric data may be limited by legal provisions.Following system and technology, by eliminate the longer-term storage of biometric data for automatic face identification, solve these problems.
Fig. 1 is according to embodiment of the present disclosure, for carrying out the block diagram in the system 100 of the face recognition of digital picture.Generally speaking, the user can submit digital photos to system 100, and system 100 will attempt to identify the face of the people in this photo, described face belongs to for example, in other user's groups (identifier list of, enumerating, group of contacts, list of friends or other relations based on being used for defining the user identifier collection) that are associated with this user other people.
The for example classification of the relation based on user and other users of group.In some instances, relation can be implicit expression or explicit.For example, the user can specify its social networking contact person, and controls better distribution and the observability of social networking model.
For illustration purposes, under the situation of group, example embodiment has been described.Group defines by the data set that is defined in computer implemented social networking service the linkman set that is mutually related.Can from be the people that connects each other socially specific collection center individual angle or from the overall angle of the people's that connects each other socially set, group is described.In some instances, group can have narrowly-defined border.For example, some group may have familiar member mutually, and adds group may need to permit for the member.In some embodiments, user's definitions section of social networking service, and can reflect this user's real-life social groups as this group of the data set of definition linkman set.These are examples of organizing as used in this specification.Yet group is not necessarily limited to these examples.
The example of the group that implicit relationship is identified is implicitly identified, so that form the user of the group that is different from larger all user's groups.Such implicit relationship can be based between user and other users frequent contact, this user and other users co-occurrence, the user that this user takes and the user who has taken in photo, only list.
For example, contacts list, communication that system 100 can check the user are (for example, the people that this user often sends e-mails with it), second and the contact person of higher degree (for example, friend's friend), social networking group and (for example be subordinate to mechanism, fan's page of following, alumnus group membership) or other user's groups of specific social groups definition, other users that this user has with it social networks identified.Then, carry out to build interim face recognition model with the image of these other users' previous identification in the perishability storer.Then, the interim face recognition template interim face recognition model and face for being arranged in submitted to photo generated compares.If the coupling of finding, be associated the identifier of coupling with the face of identifying in submitted to photo.In some embodiments, do not retain interim face recognition template; Discharge interim face template from storer after carrying out the face recognition operation.
In the example of system 100, user " Bu Lade " and subscriber equipment 104(are for example, personal computer, cell phone, plate (pad) computing machine, flat board (tablet) computing machine, personal digital assistant, be configured to upload the camera of photograph) by network 110(for example come alternately, wireless or wired public network, such as the Internet) digital photos 106 is uploaded to server apparatus 108.Digital photos 106 comprises the face-image 112 of user Bu Lade, the strong Buddhist nun's of user face-image 114 and the face-image 116 of user's Neil.
In some embodiments, server system 108 can be individual server or the server computer set of function of other suitable Computer Service of carrying out web server, communication service, social networking service, digital photo trusteeship service, maybe can accepting the submission of digital photos.Server system 108 is stored in digital photos 106 in digital photos index 118.Digital photos index 118 is can be used for storing digital photos and e-file storage vault or the database of the user identifier of the photo submitted to for the user.
User Bu Lade be marked as " UID in diagram
1" user identifier 120 be associated.Server apparatus 108 is the identifier " UID with user Bu Lade by digital photos 106 therefore
1" 120 be associated.In some embodiments, digital photos 106 can be associated with the user's who has submitted digital photos 106 to identifier.In some embodiments, digital photos can with the user's who has taken this photo identifier (for example, be embedded in the user ID in this photo as metadata) or the user's that is associated with equipment with being used to take this photo identifier (for example, (MAC) ID is controlled in the media interviews of the known network cameras by specific user's management) be associated.
Identifier " the UID of user Bu Lade
1" 120 with other user identifier set 122, be associated.Other user identifier set 122 are included in the identifier of other users in the social groups of user Bu Lade.In some embodiments, other user identifier set 122 can comprise explicit definite contact person.For example, user Bu Lade can be his wives' part of configuration online profiles (for example, as) or rely on and " become friends " and stated to server 108 by social networking service and user's Neil to the strong Buddhist nuns of server 108 statement user.In another example, user Bu Lade can add contact person's explicitly to the e-mail contacts set.
In some embodiments, other set of identifiers 122 can comprise the contact person that implicit expression is definite.For example, gather 122 and can automatically comprise following identifier: the people that user Bu Lade often sends e-mails with it or communicates by letter, the people that user Bu Lade often takes pictures therewith, be the fan of public social networking group or club member's people, common people or theme or tagger, maybe can be used for other of two mutual implicit expression associations of user suitably associated.In some embodiments, two or more users can based on claim independently, common trait carrys out mutual implicit expression association.For example, the social networking website can ask the user to identify its senior middle school and graduation time, and this information can be used to the identifier " UID of user Bu Lade
1" 120 implicitly associated with its classmate's identifier.
108 pairs of digital photos 106 of server system analyze to detect the existence of the image of mankind's face.For example, server system 108 can for example, be scanned digital photos 106 for generally appearing at characteristic pattern in the people's face outward appearance cup head of two eyes of the line isolated, that formation is substantially vertical with the bridge of the nose (, with).If the existence of one or more people's faces detected in digital photos 106, the identifier " UID of server system 108 based on Bu Lade
1" 120, other digital photos of digital photos index 118 had before been submitted in other user identifier set 122, Bu Lade and other users of identification in other user identifier set 122 upload to other digital photos of digital photos index 118, built interim face template.
In illustrated example, the identifier " UID of user Bu Lade
1" carrying out discriminating digit collection of photographs 130a-130n, it comprises the facial zone set 132a-132n of image of the face of the known user of comprising Bu Lade.Generally speaking, facial zone is the subregion of digital photos, and basically by the image of independent people's face, is occupied, that is, each facial zone is the zone that the user's that identifies of user identifier face is arranged in digital photos wherein.
The digital photos that can will be stored in digital photos index 118 by several different processes is associated with user identifier.In some embodiments, can manually complete this association.For example, the instrument that the user can provide with server system 108 is consulted digital photos, is identified in the one or more facial zones in this photo and identifies the user in present facial zone.In some embodiments, can semi-automatically carry out this association.For example, server system 108 can detect the existence in the facial zone of identifying of people's face in digital photos, and the request user is associated facial zone with its relative users identifier.In another example, server system 108 can further be determined the user identifier of suggestion for the face detected in photo, and the request user confirms or the refusal suggestion.In some embodiments, can automatically perform this association.For example, server system 108 is in the situation that there is no user intervention, determines that interrelated between the outward appearance of Unidentified face and known users surpassed predetermined threshold value, and the known users identity is associated with Unidentified face.
Identify user's Neil and be included in the identifier " UID in other user identifier set 122
z" 124 be used to discriminating digit collection of photographs 140a-140m.Digital photos 140a-140m comprises the facial zone set 142a-142m of the face of user's Neil.Also will be stored in index 118 for the data that particular user identifier is described corresponding facial zone, with the position of specifying facial zone and get rid of the necessity of initial facial identification scanning while particular photos being processed at every turn.
In some embodiments, some digital photos may occur in more than a set.In illustrated example, digital photos 130a and 140a are identical photos, and wherein two of user Bu Lade and Neils all appear in the different facial zones of " photograph 1 "." photograph 1 " appears in the set 130a-130n be associated with user Bu Lade as digital photos 130a, and appears in the photograph set 140a-140m be associated with user's Neil as digital photos 140a.
Facial regional ensemble 132a-132n, 142a-142m are processed and for the user of imaging therein, create interim face recognition template.Facial zone 132a-132n is for example analyzed to determine interim face template set 134a-134n(, the discernible characteristic of the terrestrial reference of visible structure or other machines in face-image).For example, can for example, by all features of face (facial regional ensemble 132a-132n, 142a-142m being processed measure, eyes, ear, nose, the corners of the mouth, cheekbone) between distance, and can, for those apart from producing comparing rate, create interim face recognition template.Then, on mathematics, interim face template set 134a-134n is combined to form the identifier " UID with user Bu Lade
1" the 120 interim mask 150a that are associated.Similarly, can analyze to determine interim face template set 144a-144m to facial zone 142a-142m.Then, on mathematics, interim face template set 144a-144m is combined to form the identifier " UID with user's Neil
z" the 124 interim mask 150z that are associated.For example, in some embodiments, each interim mask 150 is face template collection.For example, interim mask 150a is as by set symbol { FT
a1, FT
a2... FT
anthe indication face template collection 134a, 134b ... 134n.In other embodiments, interim mask 150a can be based on each the single face template of measurement in the face template of the formation in set.Single face template can be for example based on the central tendency value, its respective value based on concentrated at face template.
Then, use interim mask 150a-150z, to attempt identification, take the face-image 112-116 in digital photos 106.To in the description of Fig. 2-7, describe for using the process of these interim mask 150a-150z.When identifying completes basically, destroy rather than store interim face template 134a-134n, 144a-144m and interim mask 150a-150z.As an alternative, not destroying template and model, but it is buffered in storer, is not that they are transplanted on to the permanent file storage.As long as cache resources can be used, template and model will remain in storer.
In some embodiments, server system 108 can and/or be used interim mask 150a-150z according to definite sequential build.For example, server system 108 can build beginning by first using interim mask 150a, for example, because submitted user (, user Bu Lade, the UID of photograph to
1) may very likely be taken in this photograph.Similarly, server system 108 can be submitted the user to the interim face template of other users' sequential build and search for the face that they mean according to reflection.For example, process and search order can comprise search other users that submit to user self, frequent submitted user to take pictures, other users that submit to the user often to be taken pictures therewith, often be other users of submitting to the user to take pictures, contact person on the contacts list of submitting the user to, the submission user often communicates by letter with it other people, submission user's contact person's friend and other suitable users.
In some embodiments, by attempting, according to definite order identification face, can to avoid unnecessary processing.For example, for example, by the order according to definite (, at first searching for most important or possible face), process and identify face, can in this process, do sth. in advance the identification face, and avoid building the demand of other interim face template.
Fig. 2 diagram according to embodiment of the present disclosure, for use the conceptual model 200 of face-image in face-recognition procedure.In model 200, digital photos 106 is processed to determine to the existence of people's face, and identification comprises the facial zone of determined people's face.In illustrated example, facial zone 202a, facial zone 202b and facial zone 202c have been identified in digital photos 106.
To facial zone, 202a-202c is analyzed, form interim face template 210a with the face based on being included in facial zone 202a, face based on being included in facial zone 202b forms interim face template 210b, and the face based on being included in facial zone 202c forms interim face template 210c.
Form interim mask 220a from the image before be associated with the identifier 120 of user Bu Lade, and from previous with the identifier " UID of user's Neil
z" 124 images that are associated form interim mask 220c.For example, from other users (, the user that other user identifier set 122 of Fig. 1 are identified) with submitting to the user to there is social networks, such as with identifier " UID
5" 222 users that are associated, the image of previous identification form other interim mask, such as interim mask 220b.
In illustrated example, found interim face template 210
athere is corresponding relation (FT with interim mask 220a
a=FM
1), and found interim face template 210c and interim mask 220z to there is corresponding relation (FT
c=FM
z).Yet, for interim face template 210b, do not find coupling (FT
b=null) (for example, the strong Buddhist nun of user and user Bu Lade may not be friends on social networks, and the strong Buddhist nun of user may not have identifier on social networks, may not have digital photos of wherein before having identified the strong Buddhist nun of user etc.).After template matches in having identified digital photos 106 and corresponding people, interim face template and model is destroyed or as an alternative, the immersed existence in buffer memory.
Fig. 3 diagram according to embodiment of the present disclosure, for use another conceptual model 300 of the face-image 112-116 found in digital photos 106 in face-recognition procedure.Generally speaking, conceptual model 300 is expansions of the represented process of the conceptual model 200 of Fig. 2.Wherein conceptual model 200 illustrates the interim mask of picture construction of the social networks from submitting the user to, and conceptual model 300 illustrates except the face template of Fig. 2, can based on second or more the high-level contact person build interim mask.In some embodiments, more the high-level contact person can comprise friend friend, appear at user in the photo identical with other users, discretely appear at user in the photo of taking substantially the same position, discretely appear at user in the photo that approximately same time is taken basically, maybe can be by other users of common people, place and mutual indirect association of time.
In the example of conceptual model 200, for interim face template 210b, do not find coupling.Refer again to Fig. 3 and conceptual model 300, for interim face template 210b finds coupling.
For each in the selected user identifier in the user identifier be included in other user identifier set 310,320, from the interim face template of picture construction of those users' of before having identified digital photos face.As example, user identifier " UID
51" 330 with user identifier " UID
5" (for example, UID is associated
5and UID
51represented user contacts by social networks).Then, from wherein before having identified UID
51represented user's existing collection of photographs (not shown) obtains interim face template set 340.On mathematics, interim face template set 340 is combined to form interim mask 350.Then template matches process 230 determines that interim mask 350 and interim face template 210b have interrelated (FM
51=FT
b).After template matches in having identified digital photos 106 and corresponding people, interim face template and model are destroyed or as an alternative, are stored in buffer memory.
Therefore, in view of the process of Fig. 2 for example, to two other user identifiers of level and picture data (, the user identifier UID that is associated
1as the first user identifier, and user identifier UID
2, UID
5... UID
zas the second user identifier) to be processed, the process of Fig. 3 is processed a plurality of other user identifiers of level.For example, be second level user identifier UID
5select the 3rd user identifier UID
1, UID
51, UID
52... UID
5z.Each the 3rd user identifier is in the digital photos index, also the one or more digital photos that carry out index in the second user identifier carry out the user identifier of index.Then, the template generated from the picture data of each the 3rd user identifier institute index and the template generated from photograph 106 are compared.
Fig. 4 is according to embodiment of the present disclosure, for the process flow diagram of the instantiation procedure 400 of carrying out face recognition.In some embodiments, process 400 can be carried out by the server system 108 of Fig. 1, maybe can be the template matches process 230 of Fig. 2 and 3.
Process 400 starts in step 405, detects at that time the face in digital photos.For example, can to analyze to find out to digital photos 106 may be the pattern (for example, analyzing pattern and the spacing of eyes, face, nose) of people's face to server system 108 in digital photos 106.The user that photo is identified by the first user identifier submits to.
In step 410, build the interim face template of each the unknown face in digital photo.For example, digital photos 106 comprises three face-images 112,114 and 116.For each in face-image 112-116, build interim face template.
In step 415, carry out contact person to the user, appear at the identification that people in photograph and user are its people who takes pictures continually together with the user, cause the identification to the second user identifier.In some embodiments, can carry out the identification to other users with user's indirect intercourse.For example, can identify the friend's who is common contacts user.In another example, the user can upload the digital photos of social event, such as class, meets again.May submit the photograph of identical social event to not explicit associated other users of user.Server system 108 can (for example, by timestamp and geographical labels) detects these two photo albums 108 and is taken in substantially the same time and place, and determines these two user concealed contacts (for example, they are old school fellows).
In step 420, search the index of the user's corresponding with in user identifier one mug shot.For example, digital photos 106 is by having user identifier " UID
1" 120 user Bu Lade submits to, therefore, process 400 is from the user identifier of Bu Lade.Retrieve the facial zone set 132a-132n of the image of the face that comprises user Bu Lade from digital photos index 118.In step 425, it is the face generation casual user face template of the user in each photograph.For example, be facial zone set 132a-132n, generate corresponding interim face template 134a-134n, and it is stored in the perishability storer.
In step 430, from generated casual user's face template collection, identify the set of best user's face template.For example, the facial zone that may fuzzyly, fuzzy, inappropriate from face upset, the part of object wherein illuminate, not too is applicable to out of focus or in addition carrying out the establishment of interim face template builds the part interim face template 134a-134n.Server system 108 can be according to interim face template 134a-134n well-formedness for selected user in face-recognition procedure, interim face template 134a-134n is carried out to rank, and safeguard the preferably index of the interim corresponding facial zone of face template in digital photos.While having identified user's the other example of face in the digital photos in being stored in digital photos index 118, the facial zone of newly identifying can be defined as be more suitable for carrying out face recognition, and the photo be associated with those facial zones can be replaced existing, the so unsuitable photo in index.In the description of Fig. 7, discussed for determining the instantiation procedure of digital picture index to use in face-recognition procedure.
In step 435, each and each the unknown face template in user's face template is compared to identify possible coupling.In some embodiments, can user's face template be combined into to the template mask of combination on mathematics, wherein unknown face template can be compared with it.For example, if mask is user's face template collection, each and each the unknown face template in user's face template is compared to identify possible coupling.As an alternative, if mask is each the single face template obtained from user's face template, this single template and each unknown face template can be compared.
In step 440, make determining of about whether pending other user identifier.For example, if pending other user identifier (, explicit for the user or implicitly identified other contact person or people, and all templates that not generate from the photo of uploading are all mated), in step 445, select another in user identifier, and this process continues in step 420.Yet, if no longer include user's identifier, still to treat processedly, process 400 finishes.
In some embodiments, interim face template and model can not retained than process 400 needs them long a lot; When process 400 finishes, from the perishability storer, delete interim face template and model.
Fig. 5 is according to embodiment of the present disclosure, for selecting to treat to carry out into it process flow diagram of instantiation procedure 500 of user identifier of user of face recognition.Generally speaking, for the face in the discriminating digit photo and distinguish the purpose of priority ranking of the processing of its corresponding face template, other users that process 500 identification submits to users to know, and filtering and submission user have weaker relation or other users that it doesn't matter.In some embodiments, process 500 can be carried out by the server system 108 of Fig. 1, maybe can be the template matches process 230 of Fig. 2 and 3.In some embodiments, process 500 can be the part of the step 415 of Fig. 4.
Process 500 starts in step 510, the second user identifier wherein be associated with the first user identifier from the second identified user identifier Resource selection.For example, server system 108 can be selected from all users set or have first, second or other suitable user identifier of obtaining with implicit expression first user or the explicit user's set contacted predetermined more high-level.
In step 520, generate the intimate property score value of the relation that means first user and the second user.For example, the second user can be the contact person of first user, may appear in the captured a plurality of photographs of first user, and may often with first user, communicate by letter, these can indicate the strong social networks between these two users alternately so, therefore can be given relatively high intimate property score value.In another example, the second user can be the friend's of first user friend, wherein between these two, there is no other known connection, and these facts can be indicated the weak social networks that can be given relatively low intimate property score value so.
In some embodiments, can determine and also this digital photos be carried out other user identifiers of index by each digital photos of the identifier index for by submitting the user to, become intimate property score value next life.For each in other user identifiers, the proportional value of quantity of the digital photos of the identifier of part based on to by submitting the user to and these other users' identifier index is determined intimate property score value.In some embodiments, intimate property score value can also part each time be generated based in digital photos.For example, if two users both all in photograph, be identified recently, intimate property score value can be relatively higher than the intimate property score value that can generate for the similar photograph that close-perspective recording is not taken the photograph so.
In some embodiments, submission user and another user's intimate property score value is the proportional value of quantity of the digital photos based on to this another user partly, wherein submits to the user with this another user's described identifier, to carry out this another user's of mark described digital photos.In some embodiments, these intimate property score values can be further each the time of part based on submitting in user's reference numerals photo.For example, other users of mark can be relatively higher recently for submitting the user to for intimate property score value, and intimate property score value can be relatively lower for the user who is labeled not long ago.
In step 530, make definite.If intimate property score value does not meet threshold value, process 500 continues in step 540.For example, if the social networks between first user and the second user too a little less than, do not make the second user identifier be associated with the first user identifier.Yet, in step 530, if intimate property score value meets threshold value, in step 550, the second user identifier is associated with the first user identifier.For example, the second user identifier can be added to the identifier " UID with user Bu Lade
1" 120 other user identifier set 122 that are associated.
In step 540, make definite.If have the second other user identifier in the second identified user identifier set, process 500 continues in step 510.If no longer there is the second user identifier, process 500 finishes.
Fig. 6 is according to embodiment of the present disclosure, for the process flow diagram of the selected user's of discriminating digit image instantiation procedure.Generally speaking, for the purpose of the face in the discriminating digit photo, process 600 is carried out rank with the obvious intensity of the social networking relation of submitting the user to other users according to other users.In some embodiments, process 600 can be carried out by the server system 108 of Fig. 1, maybe can be the template matches process 230 of Fig. 2 and 3.In some embodiments, process 600 can be the continuation of process 500.
Process 600 starts in step 610, wherein according to intimate property score value, the second user identifier is sorted.For example, the intimate property score value that can determine according to the step 520 at Fig. 5 carries out rank to other user identifier set 122.
In step 620, select the second user identifier, and in step 630, for described the second user identifier generates the second face template.For example, for each in other user identifiers 122, from the known image collection that comprises selected other users' image of server system 108 retrieval, and it is processed to generate selected other users' face template.
In step 640, according to order, identify the first facial template be complementary with the second face template.For example, at first server system 108 can be attempted the face of the unknown in digital photos 106 and the face of submitting user 112 to are complementary, then attempt the contact person's of match user 112 face, then appear at continually the face of other users in photograph together with user 112, then user 112 is its user who takes pictures etc. continually.
In some embodiments, can limit search.For example, when having identified all faces in the digital photos, search can finish.In another example, only for the face that enough quality are arranged in digital photos, searched for (for example, can skip the face of the people in background, because they are too little or out of focus).In another example, can compare pre-determining second user who only there is the highest intimate property score value of quantity and the unknown face in digital photos.In another example again, predetermined time quantum passed or predetermined processing effort depleted (for example, in order to limit with the photograph of a large amount of faces and/or user with very large social networks, searched all over the processing charge capacity consumed) afterwards, can finish search.
Fig. 7 is according to embodiment of the present disclosure, for upgrading the process flow diagram of digital picture index for the instantiation procedure 700 used in face-recognition procedure.Generally speaking, can be by the following process that strengthens face recognition: identification in advance comprises the photograph set of image of the selected user's that can be used for creating the interim face template of high-quality face, be identified in the facial zone in those photographs, and store explicitly information with selected user's identifier, make the facial zone of can quick-searching identifying in advance and it is processed to create interim mask.Interim face template and model can be used for the face in the discriminating digit photograph, then deleted, rather than are retained.
In some embodiments, the photograph set can be limited in to the photo that pre-determines quantity.For example, set can be limited in to the photo of the individual index in best " N " (for example, 10,20,50,100).When having identified the better example of facial zone, but previous index so unsuitable photo can be replaced by the photo of new identification in index.So, the oeverall quality that is used for generating the index of interim mask can be improved along with using.In some embodiments, process 700 can be carried out by the server system 108 of Fig. 1.
Process 700 starts in step 710, accesses at that time digital photos.For example, server system 108 can be from digital photos index 118 key numbers photos 106.In step 720, for each face detected in digital photos generates face template.For example, server system 108 can generate interim face template 210a-210c from facial zone 202a-202c.
In step 730, in the face template of selecting to generate one.In step 740, determine that its face detected of identification is used for generating the user's of selected face template user identifier.For example, server system 108 can determine that interim face template 210c is the coupling of interim mask 220a, and definite facial zone 202c describes the identifier " UIDz " 124 of user's Neil.
In step 750, generate the quality score of face template.For example, can be analyzed interim face template 210c and/or facial zone 202c, and the quality of face template can the photograph of part based on obtain template from it blur level or the illumination condition sharpness, photograph (for example, too bright or too secretly can make to measure inaccurate) or the similarity degree (for example, not needing to retain two copies of same template) of template and existing template.In some embodiments, different templates can be for model.For example, wherein the user smiling, frown, laugh, from different perspectives, under various illumination conditions, see or the template of other suitable views of user can be used for improving this user's interim mask.
In step 760, make quality score and whether meet determining of threshold value.If quality score does not meet threshold value, process 700 continues in step 730, wherein selects another face template.If in step 760, quality score meets threshold value, and process 700 continues in step 770.In step 770, the user's that storage quality score and appointment are identified face is positioned at the data in zone wherein.For example, server system 108 can be stored in the description of the identifier of quality score, digital photos 106, user identifier and facial zone 202c in digital photos index 118.
In some embodiments, quality score may surpass quality score previous and that the respective user identifier be stored explicitly, and information that can be corresponding by the quality score with higher is replaced and lower quality score canned data relatively.For example, the minimum quality score value be associated with user identifier can be used as to the quality score threshold value.When the user for being associated has determined higher quality score, the quality score that this is higher and information associated with it are replaced the information be associated with the quality score threshold value.Therefore, digital print reference is carried out to continuous updating and carry out the photo for the top n grade estimation of each user identifier index.
The embodiment of described theme and operation can, with Fundamental Digital Circuit or with computer software, firmware or hardware, comprise disclosed in this manual structure and structural equivalents thereof or realize with the one or more combination in them in this manual.The embodiment of described theme in this manual can be embodied as to one or more computer programs, be coded on computer-readable storage medium, carry out or control one or more computer program instructions modules of the operation of data processing equipment for data processing equipment.Computer-readable storage medium can be following or be included in following in: computer readable storage devices, computer-readable storage substrate, random or serial access memory array or equipment or above one or more combination.Computer-readable storage medium can also be following or be included in following in: one or more independent physical assemblies or medium (for example, a plurality of CD, dish or other memory devices).
Described in this manual operation can be embodied as to data processing equipment for the operation that is stored on one or more computer readable storage devices or the data that receive from other sources are carried out.
Term " data processing equipment " comprises all types of devices, equipment and the machine for the treatment of data, comprises for example programmable processor, computing machine, SOC (system on a chip) or a plurality of aforementioned or aforesaid combination.Described device can comprise dedicated logic circuit, for example the FPGA(field programmable gate array) or the ASIC(special IC).Except hardware, described device can also be included as the code that in question computer program creates execution environment, for example forms the code of processor firmware, protocol stack, data base management system (DBMS), operating system, cross-platform runtime environment, virtual machine or above one or more combination.Described device and execution environment can be realized various computation model foundation structure, such as web services, Distributed Calculation and grid computing foundation structure.
Computer program (being also referred to as program, software, software application, script or code) can be write by programming language in any form, comprise compiling or interpretative code, illustrative or process programming language, and it can be disposed in any form, comprise as stand-alone program or as module, assembly, subroutine, object or other unit of being suitable for using in computing environment.Computer program can but needn't be corresponding to the file in file system.(for example program can be stored in to the file of other programs of maintenance or data, be stored in the one or more scripts in marking language document) a part, the Single document that is exclusively used in question program or a plurality of coordinative file (for example, storing the file of one or more modules, subroutine or partial code) in.Computer program can be deployed as on a computing machine or be positioned at the three unities or across a plurality of places distribute and a plurality of computing machines by interconnection of telecommunication network on carry out.
Described in this manual process and logic flow can be carried out by one or more programmable processors of carrying out one or more computer programs, to input data by operation and to generate output, perform an action.Described process and logic flow can also be carried out by dedicated logic circuit, and the device can also be implemented as dedicated logic circuit, this dedicated logic circuit is the FPGA(field programmable gate array for example) or the ASIC(special IC).
The processor that is suitable for computer program comprises for example general and special microprocessor, and any one or more processors of the digital machine of any type.Usually, processor will receive instruction and data from ROM (read-only memory) or random access memory or both.The main element of computing machine is processor for performing an action according to instruction and for storing one or more memory devices of instruction and data.Usually, computing machine also will comprise for storing one or more mass memory units of data, for example magnetic, magneto-optic disk or CD, or operationally couple receive data from described one or more mass memory units or transmit data to described one or more mass memory units, or both.Yet computing machine needn't have such equipment.In addition, computing machine can be embedded in another equipment, for example mobile phone, PDA(Personal Digital Assistant), Mobile audio frequency or video player, game console, GPS (GPS) receiver or portable memory apparatus are (for example, USB (universal serial bus) (USB) flash drive), only list.The equipment that is suitable for storing computer program instructions and data comprises and for example comprises nonvolatile memory, medium and the memory devices of form of ownership: semiconductor memory devices, for example EPROM, EEPROM and flash memory device; Disk, for example internal hard drive or removable dish; Magneto-optic disk; And CD-ROM and DVD-ROM dish.Processor and storer can be by supplemented, or integrate with dedicated logic circuit.
For mutual with the user is provided, the embodiment of the theme described in this instructions can realize having on following computing machine: for example, for show the display device of information, CRT(cathode-ray tube (CRT) to the user) or the LCD(liquid crystal display) monitor; And the user can provide to computing machine keyboard and the indicating equipment of input, for example mouse or tracking ball by it.Mutual with the user also can be provided with the equipment of other types; For example, the feedback that offers the user can be any type of perceptible feedback, for example visual feedback, audio feedback or tactile feedback; And can comprise acoustics, speech or sense of touch input in any form, receive the input from the user.In addition, computing machine can send document and receive document and user interactions from this equipment by the equipment of using to the user; For example, send webpage by the request of the reception of the web browser the client device in response to from the user to this web browser.
The embodiment of described theme can realize in computing system in this manual, and described computing system comprises aft-end assembly, for example, as data server; Or comprise middleware component, for example application server; Or comprise front end assemblies, for example there is graphic user interface that the user can be mutual with the realization of described theme in this manual by it or the client computer of Web browser; Or any combination of one or more such rear end, middleware or front end assemblies.The assembly of system can for example, by the digital data communication interconnection of any form or medium, communication network.The example of communication network comprises LAN (Local Area Network) (" LAN ") and wide area network (" WAN "), internet (for example, the Internet) and peer-to-peer network (for example, self-organization peer-to-peer network).
Computing system can comprise client and server.It is mutual that client and server passes through communication network usually away from each other and typically.The relation of client and server relies on each computing machine the computer program generation that moves and have each other the client-server relation.In certain embodiments, server (for example, for to showing data with the mutual user of client device and receiving the purpose of user's input from this user) for example, to client device transmission data (, html page).Can be received in from client device the data (for example, the result of user interactions) that client device generates at the server place.
The example of the computing machine of such type has been shown in Fig. 8, has wherein shown and be suitable for implement device or carry out the block diagram of the disposal system able to programme 800 of the method for the various aspects of described theme in this manual.System 800 comprises processor 810, random-access memory (ram) 820, memory device 830 and I/O (I/O) controller 840 coupled by processor (CPU) bus 850.System 800 for example programmed in ROM or its program that can pass through to load from another source (for example,, from floppy disk, CD-ROM or another computing machine) be programmed (and reprogramming).
I/O controller 840 receives with the analog or digital form and transmission data (for example, still frame, picture, film and the animation for importing to complex) by the communication link such as serial link, LAN (Local Area Network), wireless link and parallel link.
What be couple to equally I/O controller 840 is output device 860, and it can comprise display, keyboard, printer and other input and output peripherals in various embodiments.
Although this instructions comprises many embodiment details, but these details should not be interpreted as the restriction of the scope of the content that maybe can advocate any invention, and should be interpreted as can be specific to the description of the feature of the specific embodiment of specific invention.Some Feature Combination of describing in the situation of the embodiment separated in this manual can also be realized in single embodiment.On the contrary, also the various character separations ground of describing in the situation of single embodiment can be realized or realized in any suitable sub-portfolio in a plurality of embodiment.In addition, although may describe feature as in the above in some combination, work, even initial opinion so, but can be in some cases, to from this combination, leave out from one or more features of advocated combination, and the combination of advocating can be for the variant of sub-portfolio or sub-portfolio.
Similarly, although described operation according to particular order in the accompanying drawings, but this should be interpreted as need to according to shown in particular order or carry out such operation or need to carry out all illustrated operations according to consecutive order, just can reach the result of expectation.In some cases, multitask and parallel processing can be favourable.In addition, the separation of various system components in the above-described embodiments should be interpreted as and all need in all embodiments such separation, and should be understood that, usually can by described program assembly and the system integration to together with become single software product or be encapsulated as a plurality of software products.
Therefore, the specific embodiment of this theme has been described.Other embodiment within the scope of the appended claims.In some cases, can execute claims the action of middle record according to different orders and still reach the result of expectation.In addition, particular order or the consecutive order shown in the process of describing in the accompanying drawings not necessarily needs, just can reach the result of expectation.In some embodiments, multitask and parallel processing can be favourable.
Claims (32)
1. a method of being carried out by data processing equipment, described method comprises:
At the data processing equipment place, access the first digital photos;
For each face detected in described the first digital photos generates the first facial template;
Determine the second user identifier be associated with the first user identifier, described first user identifier and the second user identifier identification user;
Access digital print reference, described digital photos index carries out index by the user identifier comparison film, and be each digital photos and each user identifier that described digital photos is carried out to index, the zone of the described digital photos that the user's that appointment is identified by user identifier face is arranged in;
Select the second user identifier, and, for each in selected the second user identifier, each in the face of the user from the predefine zone of the described digital photos by described the second user identifier index generates the second face template for described the second user identifier;
The first facial template that identification and the second face template are complementary; And
For each the first facial template be complementary with the second face template, generate the data in the zone of described the first digital photos that the second user's who specifies described the second user identifier identification by described the second face template face is arranged in.
2. method according to claim 1, wherein each face template is stored in the perishability storer, and is not retained after the first facial template be complementary at identification and the second face template.
3. method according to claim 1, wherein:
Determine that the second user identifier be associated with described first user identifier comprises:
For each in a plurality of the second user identifiers, generate intimate property score value, described intimate property divides value representation by the first user of described first user identifier identification and the second user's who identifies by described the second user identifier relation; And
Determine that the second user identifier with the intimate property score value that meets threshold value is associated with described first user identifier.
4. method according to claim 3 further comprises:
According to described intimate property score value, described the second user identifier is sorted; And
Select described the second user identifier, for described the second user identifier, generate the first facial template that described the second face template and identification and described the second face template are complementary according to described sequence.
5. method according to claim 3 wherein comprises for each in a plurality of the second user identifiers generates intimate property score value:
For by each digital photos of described first user identifier index, determine the second user identifier that described digital photos is carried out to index; And
For each the second user identifier, the proportional value of quantity of the digital photos of part based on to by described first user identifier and described the second user identifier index is determined described intimate property score value.
6. method according to claim 5, wherein said intimate property score value is part each time be generated based in described digital photos further.
7. method according to claim 3, wherein for each in a plurality of the second user identifiers generates intimate property score value, comprise: the proportional value of quantity of the digital photos of part based on to described the second user is determined described intimate property score value, and wherein said first user has carried out described the second user's of mark described digital photos with described the second user's described identifier.
8. method according to claim 7, wherein said intimate property score value is each the time of part based in the described digital photos of described first user mark further.
9. method according to claim 1, wherein:
Determine that the second user identifier be associated with described first user identifier comprises:
Select the second user identifier be associated with described first user identifier by the contacts list for described first user identifier.
10. method according to claim 1 further comprises:
Select the 3rd user identifier, each the 3rd user identifier is in described digital photos index, also the digital photos of the one or more index in described first user identifier and the second user identifier carries out the user identifier of index;
For each in selected the 3rd user identifier, each in the face of the user from the predefine zone of the described digital photos by described the 3rd user identifier index is that described the 3rd user identifier generates the 3rd face template;
The first facial template that identification and the 3rd face template are complementary; And
For each the first facial template be complementary with the 3rd face template, generate the data in the zone of described the first digital photos that the 3rd user's who specifies described the 3rd user identifier identification by described the 3rd face template face is arranged in.
11. method according to claim 1, further comprise, each the first facial template be complementary for the second face template with for the second user identifier:
For described first facial template generates quality score;
Determine whether described quality score surpasses the quality score threshold value; And
If described quality score surpasses described quality score threshold value, the data that will carry out index to described the first photo by the second user identifier are stored in described digital photos index, and the zone of the described data described digital photos of specifying the face of the second user by the second user identifier identification to be arranged in.
12. a coding has the computer-readable storage medium of computer program, described program comprises the instruction that impels described data processing equipment executable operations when being carried out by data processing equipment, and described operation comprises:
Access the first digital photos;
For each face detected in described the first digital photos generates the first facial template;
Determine the second user identifier be associated with the first user identifier, described first user identifier and the second user identifier identification user;
Access digital print reference, described digital photos index carries out index by the user identifier comparison film, and be each digital photos and each user identifier that described digital photos is carried out to index, the zone of the described digital photos that the user's that appointment is identified by user identifier face is arranged in;
Select the second user identifier, and, for each in selected the second user identifier, each in the face of the user from the predefine zone of the digital photos by described the second user identifier index generates the second face template for described the second user identifier;
The first facial template that identification and the second face template are complementary; And
For each the first facial template be complementary with the second face template, generate the data in the zone of described the first digital photos that the second user's who specifies described the second user identifier identification by described the second face template face is arranged in.
13. computer-readable storage medium according to claim 12, wherein:
Determine that the second user identifier be associated with described first user identifier comprises:
For each in a plurality of the second user identifiers, generate intimate property score value, described intimate property divides value representation by the first user of described first user identifier identification and the second user's who identifies by described the second user identifier relation; And
Determine that the second user identifier with the intimate property score value that meets threshold value is associated with described first user identifier.
14. computer-readable storage medium according to claim 13, described operation further comprises:
According to described intimate property score value, described the second user identifier is sorted; And
Select described the second user identifier, for described the second user identifier, generate the first facial template that described the second face template and identification and described the second face template are complementary according to described sequence.
15. computer-readable storage medium according to claim 14 wherein comprises for each in a plurality of the second user identifiers generates intimate property score value:
For by each digital photos of described first user identifier index, determine the second user identifier that described digital photos is carried out to index; And
For each the second user identifier, the proportional value of quantity of the digital photos of part based on to by described first user identifier and described the second user identifier index is determined described intimate property score value.
16. computer-readable storage medium according to claim 12, described operation further comprises, each the first facial template be complementary for the second face template with for the second user identifier:
For described first facial template generates quality score;
Determine whether described quality score surpasses the quality score threshold value; And
If described quality score surpasses described quality score threshold value, the data that will carry out index to described the first photo by the second user identifier are stored in described digital photos index, and the zone of the described data described digital photos of specifying the face of the second user by the second user identifier identification to be arranged in.
17. a system comprises:
Data processing equipment; And
With the memory storage apparatus of described data processing equipment data communication and storage instruction, described instruction can be carried out and when such execution, be impelled described data processing equipment executable operations by described data processing equipment, and described operation comprises:
Access the first digital photos;
For each face detected in described the first digital photos generates the first facial template;
Determine the second user identifier be associated with the first user identifier, described first user identifier and the second user identifier identification user;
Access digital print reference, described digital photos index carries out index by the user identifier comparison film, and be each digital photos and each user identifier that described digital photos is carried out to index, the zone of the described digital photos that the user's that appointment is identified by user identifier face is arranged in;
Select the second user identifier, and, for each in selected the second user identifier, each in the face of the user from the predefine zone of the digital photos by described the second user identifier index generates the second face template for described the second user identifier;
The first facial template that identification and the second face template are complementary; And
For each the first facial template be complementary with the second face template, generate the data in the zone of described the first digital photos that the second user's who specifies described the second user identifier identification by described the second face template face is arranged in.
18. system according to claim 17, wherein:
Determine that the second user identifier be associated with described first user identifier comprises:
For each in a plurality of the second user identifiers, generate intimate property score value, described intimate property divides value representation by the first user of described first user identifier identification and the second user's who identifies by described the second user identifier relation; And
Determine that the second user identifier with the intimate property score value that meets threshold value is associated with described first user identifier.
19. system according to claim 17 wherein comprises for each in a plurality of the second user identifiers generates intimate property score value:
For by each digital photos of described first user identifier index, determine the second user identifier that described digital photos is carried out to index; And
For each the second user identifier, the proportional value of quantity of the digital photos of part based on to by described first user identifier and described the second user identifier index is determined described intimate property score value.
20. system according to claim 17, described operation further comprises, each the first facial template be complementary for the second face template with for the second user identifier:
For described first facial template generates quality score;
Determine whether described quality score surpasses the quality score threshold value; And
If described quality score surpasses described quality score threshold value, the data that will carry out index to described the first photo by the second user identifier are stored in described digital photos index, and the zone of the described data described digital photos of specifying the face of the second user by the second user identifier identification to be arranged in.
21. a method of being carried out by data processing equipment, described method comprises:
At the data processing equipment place, access the first digital photos;
For each face detected in described the first digital photos generates face template;
For each face template:
Determine user identifier, each user identifier identification user, wherein this user's the face be detected in described the first digital photos is used to generate described face template;
For described face template generates quality score;
Determine whether described quality score surpasses the quality score threshold value; And
If described quality score surpasses described quality score threshold value, the data in the zone by described the first digital photos of for the definite user identifier of described face template, described the first photo being carried out to the data of index, described quality score and specifying the face of the user by the identification of first user identifier to be arranged in are stored in to the digital photos index.
22. method according to claim 21 wherein determines whether described quality score surpasses the quality score threshold value and comprise:
Access described digital photos index by described user identifier;
Quality score from described digital photos indexed search by other face templates of the described user of described user identifier identification, the zone generation of the different digital photo that each in described other face templates is arranged in from the described user's that identify by user identifier face; And
When the described quality score of the described face template for described the first digital photos surpass from described digital photos indexed search at least one of described quality score of other face templates of the described user who pass through described user identifier identification the time, determine that described quality score is over the quality score threshold value.
23. method according to claim 22 further comprises:
In response to the described face template of determining described the first digital photos surpass from described digital photos indexed search to the described quality score of other face templates that pass through the described user that described user identifier identifies at least one, remove that described different digital photo that the described face of the described user to identifying by user identifier is arranged in carries out index and generate the data of a described corresponding described face template of described quality score from it from described digital photos index.
24. method according to claim 21 further comprises:
Access the first digital photos;
For each face detected in described the first digital photos generates the first facial template;
Determine the second user identifier be associated with the first user identifier, described first user identifier and the second user identifier identification user;
Access described digital photos index;
Select the second user identifier, and, for each in selected the second user identifier, each in the face of the user from the predefine zone of the digital photos by described the second user identifier index described digital photos index generates the second face template for described the second user identifier;
The first facial template that identification and the second face template are complementary; And
For each the first facial template be complementary with the second face template, generate the data in the zone of described the first digital photos that the second user's who specifies the second user identifier identification by described the second face template face is arranged in.
25. a coding has the computer-readable storage medium of computer program, described program comprises the instruction that impels described data processing equipment executable operations when being carried out by data processing equipment, and described operation comprises:
Access the first digital photos;
For each face detected in described the first digital photos generates face template;
For each face template:
Determine user identifier, each user identifier is identified the user that its face detected in described the first digital photos has been used to generate described face template;
For described face template generates quality score;
Determine whether described quality score surpasses the quality score threshold value; And
If described quality score surpasses described quality score threshold value, the data in the zone by described the first digital photos of for the definite user identifier of described face template, described the first photo being carried out to the data of index, described quality score and specifying the face of the user by the identification of first user identifier to be arranged in are stored in to the digital photos index.
26. computer-readable storage medium according to claim 25 wherein determines whether described quality score surpasses the quality score threshold value and comprise:
Access described digital photos index by described user identifier;
Quality score from described digital photos indexed search by other face templates of the described user of described user identifier identification, the zone generation of the different digital photo that each in described other face templates is arranged in from the described user's that identify by user identifier face; And
When the described quality score of the described face template of described the first digital photos surpass from described digital photos indexed search to the described user's who pass through described user identifier identification the described quality score of other face templates at least one the time, determine that described quality score is over the quality score threshold value.
27. computer-readable storage medium according to claim 26, described operation further comprises:
In response to the described face template that is identified for described the first digital photos surpass from described digital photos indexed search to the described quality score of other face templates that pass through the described user that described user identifier identifies at least one, remove that described different digital photo that the described face of the described user to identifying by user identifier is arranged in carries out index and generate the data of a described corresponding described face template of described quality score from it from described digital photos index.
28. computer-readable storage medium according to claim 25, described operation further comprises:
Access the first digital photos;
For each face detected in described the first digital photos generates the first facial template;
Determine the second user identifier be associated with the first user identifier, described first user identifier and the second user identifier identification user;
Access described digital photos index;
Select the second user identifier, and, for each in selected the second user identifier, each in the face of the user from the predefine zone of the digital photos by described the second user identifier index described digital photos index generates the second face template for described the second user identifier;
The first facial template that identification and the second face template are complementary; And
For each the first facial template be complementary with the second face template, generate the data in the zone of described the first digital photos that the second user's who specifies the second user identifier identification by described the second face template face is arranged in.
29. a system comprises:
Data processing equipment; And
With the memory storage apparatus of described data processing equipment data communication and storage instruction, described instruction can be carried out and when such execution, be impelled described data processing equipment executable operations by described data processing equipment, and described operation comprises:
Access the first digital photos;
For each face detected in described the first digital photos generates face template;
For each face template:
Determine user identifier, each user identifier is identified the user that its face detected in described the first digital photos has been used to generate described face template;
For described face template generates quality score;
Determine whether described quality score surpasses the quality score threshold value; And
If described quality score surpasses described quality score threshold value, the data in the zone by described the first digital photos of for the definite user identifier of described face template, described the first photo being carried out to the data of index, described quality score and specifying the face of the user by the identification of first user identifier to be arranged in are stored in to the digital photos index.
30. system according to claim 29 wherein determines whether described quality score surpasses the quality score threshold value and comprise:
Access described digital photos index by described user identifier;
Quality score from described digital photos indexed search by other face templates of the described user of described user identifier identification, the zone generation of the different digital photo that each in described other face templates is arranged in from the described user's that identify by user identifier face; And
When the described quality score of the described face template for described the first digital photos surpass from described digital photos indexed search at least one of described quality score of other face templates of the described user who pass through described user identifier identification the time, determine that described quality score is over the quality score threshold value.
31. system according to claim 30, described operation further comprises:
In response to the described face template that is identified for described the first digital photos surpass from described digital photos indexed search to the described quality score of other face templates that pass through the described user that described user identifier identifies at least one, remove that described different digital photo that the described face of the described user to identifying by user identifier is arranged in carries out index and generate the data of a described corresponding described face template of described quality score from it from described digital photos index.
32. system according to claim 29, described operation further comprises:
Access the first digital photos;
For each face detected in described the first digital photos generates the first facial template;
Determine the second user identifier be associated with the first user identifier, described first user identifier and the second user identifier identification user;
Access described digital photos index;
Select the second user identifier, and, for each in selected the second user identifier, each in the face of the user from the predefine zone of the digital photos by described the second user identifier index described digital photos index generates the second face template for described the second user identifier;
The first facial template that identification and the second face template are complementary; And
For each the first facial template be complementary with the second face template, generate the data in the zone of described the first digital photos that the second user's who specifies the second user identifier identification by described the second face template face is arranged in.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201161444425P | 2011-02-18 | 2011-02-18 | |
US61/444,425 | 2011-02-18 | ||
PCT/US2012/025934 WO2012112992A2 (en) | 2011-02-18 | 2012-02-21 | Facial recognition |
Publications (2)
Publication Number | Publication Date |
---|---|
CN103503000A true CN103503000A (en) | 2014-01-08 |
CN103503000B CN103503000B (en) | 2017-09-12 |
Family
ID=45809669
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201280018045.0A Active CN103503000B (en) | 2011-02-18 | 2012-02-21 | Face recognition |
Country Status (8)
Country | Link |
---|---|
US (2) | US9135500B2 (en) |
EP (1) | EP2676222B1 (en) |
JP (1) | JP5795650B2 (en) |
KR (1) | KR101551417B1 (en) |
CN (1) | CN103503000B (en) |
AU (1) | AU2012219277B2 (en) |
BR (1) | BR112013021009B1 (en) |
WO (1) | WO2012112992A2 (en) |
Cited By (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN105657250A (en) * | 2015-12-24 | 2016-06-08 | 广东欧珀移动通信有限公司 | Photographing control method and device, display control method and device and photographing system |
CN105721778A (en) * | 2016-03-25 | 2016-06-29 | 宇龙计算机通信科技(深圳)有限公司 | Shot data processing method, shot data processing apparatus and terminal |
CN112449701A (en) * | 2018-07-30 | 2021-03-05 | 谷歌有限责任公司 | Learning template representation library |
Families Citing this family (44)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9143573B2 (en) | 2008-03-20 | 2015-09-22 | Facebook, Inc. | Tag suggestions for images on online social networks |
WO2009116049A2 (en) | 2008-03-20 | 2009-09-24 | Vizi Labs | Relationship mapping employing multi-dimensional context including facial recognition |
WO2012046583A1 (en) * | 2010-10-04 | 2012-04-12 | 日本電気株式会社 | Access control device, access control system, access control method, and access control program |
JP5795650B2 (en) | 2011-02-18 | 2015-10-14 | グーグル・インク | Face recognition |
CA2913461C (en) * | 2013-05-30 | 2016-05-24 | Facebook, Inc. | Tag suggestions for images on online social networks |
KR101534808B1 (en) * | 2013-12-30 | 2015-07-08 | 주식회사 시어스랩 | Method and System for managing Electronic Album using the Facial Recognition |
KR102200950B1 (en) * | 2014-03-14 | 2021-01-12 | 삼성전자주식회사 | Object recognition apparatus and control method thereof |
US9721143B2 (en) * | 2014-03-21 | 2017-08-01 | International Business Machines Corporation | Modification of visual depictions |
US20160012426A1 (en) | 2014-07-11 | 2016-01-14 | Google Inc. | Hands-free transactions with a challenge and response |
US10185960B2 (en) | 2014-07-11 | 2019-01-22 | Google Llc | Hands-free transactions verified by location |
JP2016021184A (en) * | 2014-07-15 | 2016-02-04 | 東芝テック株式会社 | Face identification system and program |
KR102077260B1 (en) | 2014-08-08 | 2020-02-13 | 삼성전자주식회사 | Method and apparatus of face recognition using confidence based on probabilistic model |
US20170255820A1 (en) * | 2014-09-16 | 2017-09-07 | Jiwen Liu | Identification of individuals in images and associated content delivery |
US9171352B1 (en) * | 2014-12-04 | 2015-10-27 | Google Inc. | Automatic processing of images |
AU2016262874A1 (en) * | 2015-05-21 | 2017-12-07 | Facewatch Limited | Systems, methods, and devices for information sharing and matching |
US10094655B2 (en) | 2015-07-15 | 2018-10-09 | 15 Seconds of Fame, Inc. | Apparatus and methods for facial recognition and video analytics to identify individuals in contextual video streams |
WO2017044910A1 (en) | 2015-09-10 | 2017-03-16 | I'm In It, Llc | Methods, devices, and systems for determining a subset for autonomous sharing of digital media |
EP3365838A4 (en) | 2015-10-21 | 2019-08-28 | 15 Seconds Of Fame, Inc. | Methods and apparatus for false positive minimization in facial recognition applications |
CN108701225B (en) | 2016-02-26 | 2023-04-04 | 日本电气株式会社 | Face recognition system, face recognition method, and storage medium |
EP3424004A4 (en) * | 2016-03-01 | 2019-08-28 | Google LLC | Direct settlement of hands-free transactions |
KR102084174B1 (en) | 2016-03-01 | 2020-04-23 | 구글 엘엘씨 | Modify face profile for hands-free trading |
US10198625B1 (en) | 2016-03-26 | 2019-02-05 | Videomining Corporation | Association of unique person to a mobile device using repeat face image matching |
US10083358B1 (en) | 2016-07-26 | 2018-09-25 | Videomining Corporation | Association of unique person to point-of-sale transaction data |
US10474879B2 (en) | 2016-07-31 | 2019-11-12 | Google Llc | Automatic hands free service requests |
CN106899567B (en) * | 2016-08-24 | 2019-12-13 | 阿里巴巴集团控股有限公司 | User body checking method, device and system |
US10614436B1 (en) | 2016-08-25 | 2020-04-07 | Videomining Corporation | Association of mobile device to retail transaction |
CN106778585B (en) * | 2016-12-08 | 2019-04-16 | 腾讯科技（上海）有限公司 | A kind of face key point-tracking method and device |
US10552471B1 (en) * | 2017-04-21 | 2020-02-04 | Stripe, Inc. | Determining identities of multiple people in a digital image |
US10395056B2 (en) * | 2017-05-01 | 2019-08-27 | International Business Machines Corporation | Protecting privacy of digital images |
US10997809B2 (en) * | 2017-10-13 | 2021-05-04 | Alcatraz AI, Inc. | System and method for provisioning a facial recognition-based system for controlling access to a building |
CN107679235B (en) * | 2017-10-25 | 2021-09-21 | 成都尽知致远科技有限公司 | Retrieval system based on cloud platform |
AU2018201311B2 (en) * | 2018-02-22 | 2023-11-30 | Artlife Solutions Pty Ltd | A system and method for sorting digital images |
CN108882033B (en) * | 2018-07-19 | 2021-12-14 | 上海影谱科技有限公司 | Character recognition method, device, equipment and medium based on video voice |
JP7027280B2 (en) * | 2018-08-10 | 2022-03-01 | 本田技研工業株式会社 | Personal identification device and personal identification method |
CN110875060A (en) | 2018-08-31 | 2020-03-10 | 阿里巴巴集团控股有限公司 | Voice signal processing method, device, system, equipment and storage medium |
US10936856B2 (en) | 2018-08-31 | 2021-03-02 | 15 Seconds of Fame, Inc. | Methods and apparatus for reducing false positives in facial recognition |
CN109543638A (en) * | 2018-11-29 | 2019-03-29 | 与德科技有限公司 | A kind of face identification method, device, equipment and storage medium |
US11568451B2 (en) * | 2019-03-04 | 2023-01-31 | Iris.TV Inc. | Dual-optimization of targeted digital assets under volume and position constraints |
US11010596B2 (en) | 2019-03-07 | 2021-05-18 | 15 Seconds of Fame, Inc. | Apparatus and methods for facial recognition systems to identify proximity-based connections |
CN110472077A (en) * | 2019-07-12 | 2019-11-19 | 浙江执御信息技术有限公司 | The preposition method of calibration of Identification of Images, system, medium and electronic equipment |
US11341351B2 (en) | 2020-01-03 | 2022-05-24 | 15 Seconds of Fame, Inc. | Methods and apparatus for facial recognition on a user device |
WO2022147411A1 (en) | 2020-12-30 | 2022-07-07 | Assa Abloy Ab | Facial expression to augment face id and presentation attack detection |
US20220374840A1 (en) * | 2021-05-24 | 2022-11-24 | Celential.ai Inc | System and method for artificial intelligence (ai) modeling for virtual recruiting |
KR102308373B1 (en) | 2021-06-08 | 2021-10-06 | 주식회사 스누아이랩 | Video Deblurring Device for Face Recognition and Driving Method Thereof |
Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN101159011A (en) * | 2006-08-04 | 2008-04-09 | 索尼株式会社 | Face detection device, imaging apparatus and face detection method |
US20090252383A1 (en) * | 2008-04-02 | 2009-10-08 | Google Inc. | Method and Apparatus to Incorporate Automatic Face Recognition in Digital Image Collections |
CN101601053A (en) * | 2006-12-01 | 2009-12-09 | 谷歌公司 | Use the face recognition recognition image |
US20100054600A1 (en) * | 2008-08-28 | 2010-03-04 | Microsoft Corporation | Tagging Images With Labels |
Family Cites Families (14)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6606398B2 (en) | 1998-09-30 | 2003-08-12 | Intel Corporation | Automatic cataloging of people in digital photographs |
JP2003150617A (en) * | 2001-11-12 | 2003-05-23 | Olympus Optical Co Ltd | Image processor and program |
US20050197846A1 (en) | 2004-03-04 | 2005-09-08 | Peter Pezaris | Method and system for generating a proximity index in a social networking environment |
US8402094B2 (en) | 2006-08-11 | 2013-03-19 | Facebook, Inc. | Providing a newsfeed based on user affinity for entities and monitored actions in a social network environment |
US7669123B2 (en) | 2006-08-11 | 2010-02-23 | Facebook, Inc. | Dynamically providing a news feed about a user of a social network |
US7945653B2 (en) | 2006-10-11 | 2011-05-17 | Facebook, Inc. | Tagging digital media |
US7783085B2 (en) | 2006-05-10 | 2010-08-24 | Aol Inc. | Using relevance feedback in face recognition |
US8031914B2 (en) * | 2006-10-11 | 2011-10-04 | Hewlett-Packard Development Company, L.P. | Face-based image clustering |
US20080270425A1 (en) | 2007-04-27 | 2008-10-30 | James Cotgreave | System and method for connecting individuals in a social networking environment based on facial recognition software |
WO2009116049A2 (en) | 2008-03-20 | 2009-09-24 | Vizi Labs | Relationship mapping employing multi-dimensional context including facial recognition |
US8670597B2 (en) | 2009-08-07 | 2014-03-11 | Google Inc. | Facial recognition with social network aiding |
AU2009243486B2 (en) * | 2009-12-02 | 2012-12-13 | Canon Kabushiki Kaisha | Processing captured images having geolocations |
US20110243397A1 (en) * | 2010-03-30 | 2011-10-06 | Christopher Watkins | Searching digital image collections using face recognition |
JP5795650B2 (en) | 2011-02-18 | 2015-10-14 | グーグル・インク | Face recognition |
-
2012
- 2012-02-21 JP JP2013554676A patent/JP5795650B2/en active Active
- 2012-02-21 AU AU2012219277A patent/AU2012219277B2/en active Active
- 2012-02-21 US US13/401,076 patent/US9135500B2/en active Active
- 2012-02-21 EP EP12707445.8A patent/EP2676222B1/en active Active
- 2012-02-21 BR BR112013021009-5A patent/BR112013021009B1/en active IP Right Grant
- 2012-02-21 KR KR1020137024614A patent/KR101551417B1/en active IP Right Grant
- 2012-02-21 CN CN201280018045.0A patent/CN103503000B/en active Active
- 2012-02-21 WO PCT/US2012/025934 patent/WO2012112992A2/en active Application Filing
-
2015
- 2015-08-11 US US14/823,863 patent/US9996735B2/en active Active
Patent Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN101159011A (en) * | 2006-08-04 | 2008-04-09 | 索尼株式会社 | Face detection device, imaging apparatus and face detection method |
CN101601053A (en) * | 2006-12-01 | 2009-12-09 | 谷歌公司 | Use the face recognition recognition image |
US20090252383A1 (en) * | 2008-04-02 | 2009-10-08 | Google Inc. | Method and Apparatus to Incorporate Automatic Face Recognition in Digital Image Collections |
US20100054600A1 (en) * | 2008-08-28 | 2010-03-04 | Microsoft Corporation | Tagging Images With Labels |
Non-Patent Citations (3)
Title |
---|
JAE YOUNG CHOI，ET AL.: "Collaborative Face Recognition for Improved Face Annotation in Personal Photo Collections Shared on Online Social Networks", 《IEEE TRANSACTIONS ON MULTIMEDIA》 * |
RALPH GROSS,ET AL.: "Information Revelation and Privacy in Online Social Networks", 《PROCEEDINGS OF THE 2005 ACM WORKSHOP ON PRIVACY IN THE ELECTRONIC SOCIETY》 * |
ZAK STONE，ET AL.: "Toward Large-Scale Face Recognition Using Social Network Context", 《PROCEEDINGS OF THE IEEE》 * |
Cited By (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN105657250A (en) * | 2015-12-24 | 2016-06-08 | 广东欧珀移动通信有限公司 | Photographing control method and device, display control method and device and photographing system |
CN105721778A (en) * | 2016-03-25 | 2016-06-29 | 宇龙计算机通信科技(深圳)有限公司 | Shot data processing method, shot data processing apparatus and terminal |
CN112449701A (en) * | 2018-07-30 | 2021-03-05 | 谷歌有限责任公司 | Learning template representation library |
Also Published As
Publication number | Publication date |
---|---|
WO2012112992A2 (en) | 2012-08-23 |
US20160070957A1 (en) | 2016-03-10 |
EP2676222A2 (en) | 2013-12-25 |
BR112013021009B1 (en) | 2022-03-03 |
JP2014515842A (en) | 2014-07-03 |
WO2012112992A3 (en) | 2013-03-07 |
US20120213420A1 (en) | 2012-08-23 |
US9996735B2 (en) | 2018-06-12 |
CN103503000B (en) | 2017-09-12 |
KR101551417B1 (en) | 2015-09-08 |
AU2012219277B2 (en) | 2016-10-20 |
US9135500B2 (en) | 2015-09-15 |
KR20130139338A (en) | 2013-12-20 |
JP5795650B2 (en) | 2015-10-14 |
EP2676222B1 (en) | 2018-09-19 |
BR112013021009A2 (en) | 2016-10-11 |
AU2012219277A1 (en) | 2013-05-09 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN103503000A (en) | Facial recognition | |
US11941912B2 (en) | Image scoring and identification based on facial feature descriptors | |
US10755084B2 (en) | Face authentication to mitigate spoofing | |
US9552511B2 (en) | Identifying images using face recognition | |
JP5673765B2 (en) | SEARCH SYSTEM, SEARCH METHOD, AND COMPUTER PROGRAM | |
TWI724552B (en) | Method and device for identifying risky merchants | |
WO2018072028A1 (en) | Face authentication to mitigate spoofing | |
WO2021189911A1 (en) | Target object position detection method and apparatus based on video stream, and device and medium | |
CN111860377A (en) | Live broadcast method and device based on artificial intelligence, electronic equipment and storage medium | |
CN110502694A (en) | Lawyer's recommended method and relevant device based on big data analysis | |
US20210019553A1 (en) | Information processing apparatus, control method, and program | |
WO2021139493A1 (en) | Visitor identity authentication method and apparatus based on machine learning, and computer device | |
CA2827639C (en) | Facial recognition | |
WO2021164122A1 (en) | Intelligent user recognition method and device, and computer readable storage medium | |
CN114973374A (en) | Expression-based risk evaluation method, device, equipment and storage medium | |
CN113095284A (en) | Face selection method, device, equipment and computer readable storage medium | |
CN113780424A (en) | Real-time online photo clustering method and system based on background similarity | |
Hoshino et al. | Inferencing the best AI service using Deep Neural Networks | |
CN114004843A (en) | Effective fingerprint image generation method and device, electronic equipment and storage medium | |
CN116127129A (en) | Group case identification method and device based on surface review video, electronic equipment and medium | |
CN113920582A (en) | Human body action scoring method, device, equipment and storage medium | |
CN114511856A (en) | Method, system, device and medium for judging medical sheet type | |
CN113591916A (en) | Data processing method and device based on two-classification model |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
C06 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
GR01 | Patent grant | ||
GR01 | Patent grant | ||
CP01 | Change in the name or title of a patent holder |
Address after: American CaliforniaPatentee after: Google limited liability companyAddress before: American CaliforniaPatentee before: Google Inc. |
|
CP01 | Change in the name or title of a patent holder |