US8805104B1 - Selecting example-based predictors based on spatial continuity - Google Patents
Selecting example-based predictors based on spatial continuity Download PDFInfo
- Publication number
- US8805104B1 US8805104B1 US13/105,610 US201113105610A US8805104B1 US 8805104 B1 US8805104 B1 US 8805104B1 US 201113105610 A US201113105610 A US 201113105610A US 8805104 B1 US8805104 B1 US 8805104B1
- Authority
- US
- United States
- Prior art keywords
- dictionary
- image
- predictor
- entries
- entry
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Expired - Fee Related, expires
Links
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/90—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using coding techniques not provided for in groups H04N19/10-H04N19/85, e.g. fractals
- H04N19/97—Matching pursuit coding
Definitions
- the present invention generally relates to the field of video compression, and more specifically, to methods of selecting dictionary predictor entries in example-based compression.
- the H.264 standard for video compression predicts the structure of each macroblock of a given frame using motion fields from other reference frames.
- the encoder can search through available predictions to select one that will be best, in terms of compression rate and rate-distortion.
- the compression technique also uses predictor-selection and transmission to encode an image or video.
- the number of available predictors available to the encoder is much larger than the number of predictors available to other video codecs.
- a dictionary used in example-based compression may comprise a massive collection of predictors on the order of millions rather than thousands. Due to the size of the dictionary used in example-based compression, the speed in which current techniques select the best predictor from the dictionary needs improvement.
- An image processing system for encoding images based on example-based compression.
- the image processing system comprises a database of dictionary predictor entries that are used to encode images.
- the dictionary predictor entries are whole images or portions of reference images which are used as dictionary predictor entries, or portions thereof, for encoding other images.
- the dictionary entries may be partitioned into a plurality of dictionaries based on content. Based on the content of an image for encoding, the image processing system selects dictionary predictor entries from an appropriate dictionary in which to encode the image.
- the image processing system selects a set of candidate dictionary predictor entries to encode a portion of an image. For each portion of an image to be encoded (target image) the image processing system selects a randomly chosen dictionary predictor entry as a candidate. Based on metadata associated with the image, the image processing system may perform a localized search of the database of dictionary predictor entries for entries associated with content included in the image. The randomly chosen entries are considered initial dictionary predictor entries for the portions of the image.
- the image processing system further selects additional candidates for each portion of the image based on spatial locality.
- a portion of an image to be encoded has a location relative to neighboring portions in the target image. The position of a portion of the target image relative to its neighbors is represented as an offset vector. The offset vector is used to select candidate predictors for encoding the portion of the image.
- the spatial continuity between portions of the image is exploited by the image processing system by selecting corresponding dictionary predictor entries that have the same offset vector as the portion of the image and its neighbors. For a given portion, the image processing system identifies the initial dictionary predictor entries selected for the neighbors of the portion. As previously discussed above, a dictionary predictor entry may be a portion of a whole image. The image processing system may identify for each portion, a dictionary predictor entry that is located an offset from the initial dictionary predictor entry selected for the neighbor where the offset corresponds to the offset vector between the portion and the neighbor.
- FIG. 1 is a high-level block diagram of an image processing system in accordance with one embodiment.
- FIGS. 2A and 2B illustrate dictionary entries for use as candidate dictionary predictor entries and FIG. 2C illustrates a target frame for encoding using the dictionary entries in accordance with one embodiment.
- FIG. 3 illustrates steps performed by an image processing server to select dictionary predictor entries to encode an image in accordance with one embodiment.
- FIG. 1 is a high-level block diagram illustrating a detailed view of an image processing system 100 for encoding frames of images or videos using example-based compression.
- a target frame for encoding is divided into macroblocks where each macroblock is individually encoded using a dictionary predictor entry from an example-based dictionary.
- the example based dictionary can comprise a single dictionary or a plurality of dictionaries where each dictionary is associated with a particular subject matter.
- Each dictionary includes dictionary predictor entries associated with the subject matter.
- a dictionary predictor entry may be a whole image or a portion of an image. Due to the size of the dictionary, selection of the dictionary prediction entries used for encoding can be a time consuming process.
- the image processing system 100 exploits the natural spatial relationship between macroblocks within the target frame in order to select dictionary predictor entries used to encode the macroblocks of the target frame. By selecting candidate dictionary predictor entries for a macroblock of the target frame based on the spatial continuity between the macroblock and its neighboring macroblocks, the speed of the encoding process is improved.
- a client 115 executing a decoder 117 is in communication with the image processing system 100 via a network 113 such as the Internet or any combination of a LAN, a MAN, a WAN, a mobile, wired or wireless network, a private network, or a virtual private network. While only a single client 115 is shown in FIG. 1 , in general very large numbers (e.g., millions) of clients are supported and can be in communication with the image processing system 100 at any time.
- the client 115 can be implemented using any of a variety of different computing devices, some examples of which are personal computers, digital assistants, personal digital assistants, cellular phones, mobile phones, smart phones and laptop computers.
- the client 115 receives content such as images or videos from the image processing system 100 .
- the decoder 117 decodes (i.e., reconstructs) image or videos using dictionary information provided by the image processing system 100 .
- the image processing system 100 comprises an encoder module 101 , a dictionary database 109 , and a content database 111 .
- Other modules and/or databases may be included in the image processing system 100 in other embodiments.
- the content database 111 stores content for encoding (i.e., compression).
- content includes image data in general, such as individual still image files or frames of images from a video file.
- the term frame may describe a target image which is encoded by the image processing system 100 as well as portions of the target frame.
- Each frame may be associated with metadata describing the frame.
- the metadata may include tags describing the substance (i.e., content) of the frame, the video associated with the frame, an author of the content or other descriptive information. This information may be used to select candidate dictionary predictor entries for encoding the frame.
- the content in the content database 111 may be obtained from a variety of sources, such as from an organization producing professional images or videos. Likewise, images and videos may be obtained from users, e.g. as submitted by a user uploading images to a photo repository such as PICASA WEB, or a video repository such as YOUTUBE or GOOGLE VIDEO.
- a photo repository such as PICASA WEB
- a video repository such as YOUTUBE or GOOGLE VIDEO.
- the dictionary database 109 stores example-based dictionaries used to encode frames of content from the content database 111 .
- the dictionary database 109 stores a plurality of example-based dictionaries where each dictionary is associated with a particular type of content. The type of content may be enumerated with respect to the subject matter of the content, source of the content, or author of the content, or any combination of thereof.
- the dictionary database 109 may comprise a beach dictionary associated with beach images, a building dictionary associated with images of buildings or urban environments, and a vehicle dictionary associated with images of vehicles, etc. Images for each subject matter dictionary can be manually curated or selected automatically based on analysis of metadata such as keywords, tags, title, as well as automated image analysis and object recognition methods.
- Each dictionary may then be further organized into sub-dictionaries based on sub-classes of the subject matter of content associated with the dictionary.
- the vehicle dictionary may include sub-dictionaries for automobiles and motorcycles, and then into further sub-dictionaries by manufacturer.
- Each dictionary in the dictionary database 109 comprises dictionary predictor entries.
- a dictionary predictor entry may comprise of an image.
- the images constituting the dictionary entries may comprise whole images.
- a dictionary predictor entry may comprise an image patch that is formed from a smaller portion (i.e., regions) or blocks (sub-window) of a whole image. Typical patch sizes can range from 2 ⁇ 2 pixels to 128 ⁇ 128 pixels.
- a dictionary entry may be a video cube that comprises a plurality of frames that are temporally related to one another, for example a set of 30 frames over a 2 second period, at 15 fps.
- the dictionary entries may be indexed into tables of a relational database, although other database schemes may be used to store the dictionary entries.
- FIG. 2A and FIG. 2B there is shown a schematic example of plurality of dictionary predictor entries that collectively represent images 201 and 203 respectively.
- image 201 is represented by a plurality of dictionary predictor entries 1 A through 16 A.
- Image 203 is similarly represented by a plurality of dictionary predictor entries 1 B through 16 B.
- Each dictionary predictor entry for an image is a portion or block of the image.
- the example dictionary predictor entries illustrated in FIGS. 2A and 2B represent beach scenes within a beach dictionary.
- the encoder module 101 encodes frames of content from the content database 111 .
- the encoder module 101 encodes the frames using example-based dictionary predictor entries selected from the dictionary database 109 . After one or more dictionary predictor entries are selected to encode a target frame, the encoder module 101 may communicate the selected dictionary entry information to the decoder 117 in order for the decoder 117 to decode (i.e. reconstruct) the image using the information.
- the encoder module 101 comprises a frame division module 103 , a prediction module 105 , and an evaluation module 107 .
- the encoder module 101 may include other modules that are used to perform the encoding process of a target frame as is known in the art of example-based encoding. Additionally, the encoder module 101 may include other modules other than those illustrated in FIG. 1 .
- the frame division module 103 divides frames of content in the content database 111 into macroblocks. Each macroblock may be 16 ⁇ 16 pixels in size but other sizes may be used in alternative embodiments. Specifically, for each frame, the frame division module 103 divides the frame into a grid of macroblocks (blocks or portions) which are separately encoded by the encoder 101 .
- FIG. 2C illustrates an example of a target frame 205 which has been divided into a plurality of macroblocks. As shown in FIG. 2C , target frame 205 is divided into 16 macroblocks by the frame division module 103 .
- the frame division module 103 For each macroblock of an image, the frame division module 103 identifies the macroblock's neighbors. In one embodiment, the neighbors of a given macroblock are the macroblocks that are directly adjacent to the block in the horizontal, vertical, and diagonal directions. For most macroblocks the frame division module 103 identifies eight spatial neighbor macroblocks. However, the frame division module 103 identifies only three or five neighbors for the macroblocks that are respectively located at the corners of a frame or at one of the non-corner edge regions of the frame. For each macroblock, the frame division module 103 establishes a list of the macroblock's neighbors and their spatial offset within the frame, relative to a given block.
- the neighbor list indicates the pair offset vectors for each of a given macroblocks neighbors.
- each offset vector in the list describes a normalized position of a neighbor relative to a given macroblock in the horizontal (x) and vertical (y) directions.
- the normalized (unit) position is representative of the offset vector or distance between anchor points (origins) of a pair of blocks.
- the anchor points of a pair of macroblocks may be located 16 pixels from one another in both the positive x and y directions.
- the normalized offset representing the location of a neighbor relative to the macroblock in this example is (1, 1) which represents an offset of (16, 16).
- the frame division module 103 identifies the list of three offset vectors for this macroblock to identify macroblocks 9, 10, and 14 as neighbors of macroblock 13.
- the frame division module 103 assigns a class indication to each macroblock indicative of the macroblock's position within the image.
- the indication describes whether the macroblock is an interior block, a corner block, or a border block based on the macroblock's position within the image.
- a corner block is a macroblock located at the corners of the image.
- macroblocks 1, 4, 13, and 16 are considered as corner blocks.
- a border block is a macroblock located at the perimeter (boundary) of the image that is not a corner of the image.
- macroblocks 2, 3, 5, 8, 9, 12, 14, and 15 are border blocks.
- an interior block is a macroblock located at a position within the image that is not at the perimeter or corner of the image. For example, in FIG. 2C macroblocks 5, 7, 10, and 11 are interior blocks.
- the frame division module 103 may also indicate whether the block is located at the top-left corner, bottom-left corner, top-right corner, or bottom-right corner of the image. Similarly, for each non-corner border block, the frame division module 103 may indicate whether the block is located at the left border, right border, top border, or bottom border of the image. Sub-classes of corner and border blocks are identified as the neighbors of corner blocks and border blocks vary based on sub-class.
- the above list indicates the offset vectors in the horizontal (x) and vertical (y) directions of a given macroblocks neighbors.
- the value of j indicates a particular neighbor of a given macroblock. Based on macroblock's position within an image, the amount of neighbors may vary.
- the list shown above is a general representation of the list of offset vectors of a macroblock's neighbors.
- the following lists of offset vectors indicates one embodiment of the lists of offset vectors based on the different types of macroblocks described previously:
- Each list of offset vectors indicates pairs of unit value (normalized) offsets that describe the location of a given macroblock's neighbors relative to the location of the macroblock based on the macroblock's class. From the list of offset vectors, the frame division module 103 identifies the list of neighbors for each macroblock based on the macroblocks position within the image.
- the prediction module 105 selects candidate dictionary predictor entries from the dictionary database 109 to encode target frames from the content database 111 . Specifically, for each macroblock within a target frame (i.e., an image), the prediction module 105 assigns (i.e., selects) a set of candidate dictionary predictor entries to encode the macroblock. From the set of candidates for the given macroblock, the prediction module 105 selects a single dictionary predictor entry to encode the macroblock. In one embodiment, the prediction module 105 selects dictionary predictor entries as candidates to encode a given macroblock until a time threshold is met and/or a quality threshold in terms of compression and rate-distortion is met.
- a given macroblock (T i ) is represented by a set of coordinates (x, y) that correspond to the anchor point of the block.
- the set of candidate dictionary predictor entries (C) for the macroblock (T i ) is represented according to the variables below:
- an initial predictor entry is a dictionary predictor entry that was randomly chosen from the dictionary database 109 to encode a macroblock as will be described in further detail below.
- IPT i dictionary predictor entry (D n,a ) where a is a position (x, y) in image n;
- IPT Oj dictionary predictor entry (D m,b ) where b is a position (x, y) in image m;
- the set of candidate dictionary predictor entries (C) for macroblock T i comprises the initial dictionary predictor entry (IPT i ) selected for macroblock T i and a plurality of spatial dictionary predictor entries (IPT Oj +O j ) that are chosen based on the initial dictionary predictor entries selected for the neighbors (T Oj ) of T i .
- a spatial dictionary predictor entry for macroblock T i is located at an offset O j from the location of the initial dictionary predictor (IPT Oj ) entry selected for the neighbor T Oj .
- the offset Oj is selected based on the corresponding offset vector from the neighbor T Oj to macroblock T i as indicated in the list of offsets vectors previously described above.
- the index j is indicative of a corresponding neighbor of macroblock T i and ranges from 1 to 8 depending on the class of macroblock T i .
- the set of candidate dictionary predictor entries for macroblock T i can be further expanded to consider candidates that derive from the initial set of candidates by some further spatial offset vector ( ⁇ s x, ⁇ s y), in addition to the already indicated O j .
- the additional offset vectors can be selected to correspond to a simple grid search of offsets or a coarse-to-fine style grid of offsets.
- the initial dictionary predictor entry for macroblock T i is a dictionary predictor entry (D n,a ) from the dictionary database 109 where n references the image associated with the entry and a references a specific sub-block of the image.
- n may correspond to image 203 shown in FIG. 2B and a references a particular sub-block (e.g., 11 B) from image 203 .
- a may correspond to the position of the sub-block in terms of x and y coordinates.
- the sub-block positions used within the prediction image need not correspond to an integer multiple of the macroblock size.
- the initial dictionary predictor entry (IPT Oj ) for the neighbor T Oj of macroblock T i is a dictionary entry (D m,b ) from the dictionary database 109 where m references the image associated with the entry and b references a specific sub-block of the image in terms of x and y coordinates.
- m may correspond to image 201 shown in FIG. 2A and b is associated with a sub-block (e.g., 6 A) from image 201 .
- image n and image m may or may not correspond to the same image.
- the prediction module 105 to select an initial dictionary predictor entry (IPT i ) for a macroblock (T i ) of a target frame, the prediction module 105 performs a pseudo-random search of the dictionary database 109 .
- the prediction module 105 searches the dictionary database 109 for the initial dictionary predictor entry to encode the macroblock for evaluation purposes.
- the prediction module 105 may simultaneously identify the initial dictionary predictor entry for each macroblock of the target frame or may sequentially identify the initial dictionary predictor entry for each macroblock.
- the prediction module 105 may perform a number of pseudo-random searches initial predictor entries for macroblock T i .
- the initial dictionary prediction entry may represent a previous initial dictionary prediction entry identified in a previous search.
- the prediction module 105 randomly selects the initial dictionary predictor entry from an appropriate dictionary in the dictionary database 109 based on the content of the frame.
- the prediction module 105 may select the initial dictionary predictor entry based on a metadata match.
- each dictionary entry may comprise metadata describing the image associated with the entry.
- the prediction module 105 may locate a dictionary from the dictionary database 109 that comprises entries associated with the content of the target frame. For example, if the target frame includes content about beaches, the prediction module 105 searches the beach dictionary for entries.
- the prediction module 105 selects spatial dictionary predictor entries as candidates to encode the macroblock T i .
- Spatial dictionary predictor entries are dictionary predictor entries that are selected by the prediction module 105 based on the spatial relationship between macroblock T i and its neighboring macroblocks T Oj in the target frame. As described above, the neighbors T Oj of a given macroblock in a target frame are the macroblocks that are directly adjacent to the macroblock T i in the horizontal, vertical, and diagonal directions.
- Macroblocks encoded using spatial dictionary predictor entries selected from the example-based dictionaries share a natural spatial relationship with the dictionary entries due to the macroblocks corresponding spatial locality within the dictionary entries. For example, consider neighboring macroblocks land 6 in target frame 205 with their origins (i.e., anchor points) represented as the pixel locations of top-left corners of the macroblocks. The location (L) of the origins of the macroblocks are separated from each other by a horizontal shift of x pixels, and a vertical shift of y pixels, representing an offset vector from macroblock 1 to macroblock 6.
- dictionary predictor entries may be sub-blocks of an image.
- the prediction module 105 may exploit spatial continuity by selecting for a macroblock, spatial dictionary predictor entries based on the offset vectors of the macroblock and its neighbors. In other words, for each target macroblock within the target frame, the prediction module 105 collects a set of spatial dictionary predictor entries for evaluation based on the offset vectors for the macroblock and its neighboring blocks.
- the prediction module 105 To select the spatial dictionary predictor entries for the macroblock (T i ) based on the neighboring macroblocks (T Oj ), the prediction module 105 identifies the initial dictionary predictor entry previously selected for each of the macroblock's neighbors. That is, the prediction module 105 identifies the initial dictionary predictor entry (IPT Oj ) that was randomly selected to encode each of the macroblock's neighbors (T Oj ). Because predictor entries may be sub-blocks of an image, the prediction module 105 identifies as the spatial dictionary predictor entries for the macroblock, a sub-block of the image that is located a distance from the initial dictionary predictor entry for the neighbor that is equivalent to the offset vector (O j ) for the macroblock (Ti) and the neighbor (T Oj ).
- the prediction module 105 identifies a corresponding spatial dictionary predictor entry for the macroblock (Ti) based on the offset vector (O j ) for the macroblock (T i ) and its neighbor (T Oj ) and the initial dictionary predictor entry selected for the neighbor (IPT Oj ).
- the evaluation module 107 evaluates the resulting compression of macroblocks of target images using the candidate dictionary predictor entries selected by the prediction module 105 .
- the evaluation module 107 compares the quality of compression resulting from each candidate entry to a quality threshold in terms of compression and rate-distortion. Based on the comparison, the evaluation module 107 identifies a candidate dictionary predictor entry that will be used to encode the macroblock. If the comparison results in a quality below the quality threshold, the evaluation module 107 may communicate with the prediction module 105 to select additional candidate dictionary predictor entries for the given macroblock based on the spatial dictionary predictor entries of the macroblock's neighbors.
- the evaluation module 107 prunes the total number of candidates considered for each macroblock of the target image.
- the evaluation module 107 may only consider spatial dictionary predictor entries that yielded an evaluation above a threshold value for the neighbor macroblock itself. That is, a spatial dictionary predictor entry is selected as a candidate if the initial dictionary predictor for the neighbor from which the spatial entry was identified results in an evaluation above the threshold value for the neighbor macroblock. This allows the evaluation module 107 to identify or learn the set of candidate dictionary predictor entries for the region of the image that result in a compression that is above the threshold value (i.e. good compression).
- the evaluation module 107 may communicate with the prediction module 105 to abort (i.e., stop) the search of the dictionary database 109 for additional candidate dictionary predictor entries even though the time threshold has not been met.
- the evaluation module 107 may communicate a mode bit and a selector index to the decoder.
- the mode bit indicates to the decoder 117 that the predictor is a spatial dictionary predictor entry and the selector index indicates which of the neighbors is the basis for the spatial candidate. Because the decoder 117 is aware of the offset vectors between macroblocks of a target image, the decoder can identify the dictionary predictor entry knowing only the neighbor that formed the basis of the selection of the dictionary entry.
- the selector index may either be a simple index indicating the neighbor of each block, or the selector index may denote the rank of the neighbor within an ordering of the neighbors of the block.
- the rank may be indicative of the quality of the encoding using the entries based on the neighbor. Because the selector index is much smaller than a global dictionary index, the speed of the decoding process is improved.
- FIG. 3 is one embodiment of a method performed by the image processing system 100 to select a dictionary predictor entry for encoding a macroblock of an image. Other embodiments perform the illustrated steps in different orders, and/or perform different or additional steps.
- the image processing system 100 performs one or more passes in which it selects candidate dictionary predictor entries to encode the macroblock of the image. Although only two passes are shown in the embodiment illustrated in FIG. 3 , additional passes may be performed by the image processing system 100 to select a dictionary predictor entry to encode the macroblock in other embodiments.
- the image processing system 100 selects 301 candidate dictionary predictor entries for the macroblock.
- the image processing system 100 selects an initial dictionary predictor entry as a candidate to encode the macroblock by performing a pseudo-random search of the dictionary database 109 based on the content of the target frame associated with the macroblock. For example, consider an example of selecting a dictionary predictor entry for encoding macroblock 6 of target frame 205 shown in FIG. 2C . Given that target frame 205 illustrates a beach scene, the image processing system 100 performs a search of a beach dictionary and randomly selects an initial candidate dictionary predictor entry from the beach dictionary. For example, the image processing system 100 may select dictionary predictor entry 11 corresponding to image 203 shown in FIG. 2B as the initial dictionary predictor entry to encode macroblock 6 of the target frame 205 .
- the image processing system 100 selects candidate spatial dictionary predictor entries for the macroblock.
- the selection of the spatial dictionary predictor entries is based on the initial candidate dictionary predictor entries selected for the macroblock's neighbors.
- the image processing system 100 identifies the offset vector between an anchor point of the macroblock to an anchor point of the neighbor.
- the anchor point may be represented by the center of the macroblock/neighbor or may be located at the top left corner of the macroblock/neighbor or at other locations.
- macroblocks 1, 2, 3, 4, 7, 9, 10, and 11 are considered the neighbors of macroblock 6. Accordingly, the image processing system 100 identifies the offset vectors between the target macroblock and each of its neighbors.
- the image processing system may select spatial dictionary predictor entries for the target macroblock based on the identified offset vectors for the macroblock relative to its neighbors.
- the image processing system 100 may select a spatial dictionary predictor entry for the target macroblock that is located a distance from the initial dictionary predictor entry for the neighbor according to the offset vector.
- the image processing system 100 identifies a spatial dictionary predictor entry based on the initial dictionary predictor entry selected for the neighbor and the offset vector between the target macroblock and the neighbor.
- target macroblock 6 of image 205 whose neighbor is macroblock 7.
- the image processing system 100 identifies for example the offset vector of 16 pixels in the horizontal direction and 0 pixels in the vertical direction (i.e., offset (16, 0)) for macroblock 6 and macroblock 7.
- the target block 6 is located 16 pixels to the left of macroblock 7.
- the image processing system 100 may have identified dictionary predictor entry 11 of image 201 shown in FIG. 2A as the initial dictionary predictor entry for block 7 of target frame 205 .
- the image processing server 100 selects the dictionary predictor entry located 16 pixels to the left of dictionary predictor entry 11 of image 201 (i.e., the distance of the offset vector) as a suitable dictionary predictor entry for target macroblock 6 due to spatial continuity.
- dictionary predictor entry 10 of dictionary predictor entry 201 may be considered as a spatial candidate to encode macroblock 6 of the target frame 205 .
- the image processing server 100 repeats this process for each of target macroblock 6's neighboring blocks.
- the image processing server 100 evaluates 303 the quality of the compression of the target macroblock using the selected candidate dictionary predictor entries. To evaluate the quality, the image processing server 100 determines the compression and rate-distortion resulting from encoding the target block with the initial candidate dictionary predictor entry and the spatial candidate dictionary predictor entries. In one embodiment, to improve the speed in which the target block is encoded, the image processing server 100 may prune the total number of candidate dictionary predictor entries for the target block. The image processing server 100 may only evaluate spatial candidate dictionary predictor entries for those candidates whose associated initial candidate dictionary predictor entries resulted in a quality of encoding above a threshold value for the neighbor itself.
- the image processing server 100 may perform an optional second pass to identify alternative dictionary predictor entries to encode the target macroblock.
- the image processing server 100 may perform the second pass in response to the quality of the compression using the identified candidates during the first pass being below a quality threshold and/or if there is still time remaining to identify predictors for the target macroblock.
- the second pass may not be performed by the image processing server 100 if the spatial candidate dictionary predictor entries already yield a quality encoding.
- the image processing server 100 selects 305 additional candidate dictionary predictor entries for the target block based on the neighbors of the neighbors of the target macroblock according to similar steps performed during the first pass described above.
- the image processing server 100 may perform another pseudo-random search of the dictionary database 109 for candidates.
- the image processing server 100 evaluates 307 the quality of the compression of the target macroblock using the additional candidate dictionary predictor entries.
- the image processing server 100 selects 309 a dictionary predictor entry for encoding the target macroblock from the candidate dictionary predictor entries identified during steps 301 and 305 .
- the image processing server 100 may select the dictionary predictor entry that results in the best quality in terms of compression and rate-distortion according to one embodiment.
- the image processing server 100 may then notify the decoder 117 of the selected predictor in which to decode the target frame.
- Certain aspects of the present invention include process steps and instructions described herein in the form of an algorithm. It should be noted that the process steps and instructions of the present invention could be embodied in software, firmware or hardware, and when embodied in software, could be downloaded to reside on and be operated from different platforms used by real time network operating systems.
- the image processing system 100 comprises various modules.
- the term module refers to computer program logic utilized to provide the specified functionality.
- a module can be implemented in hardware, firmware, and/or software.
- program modules are stored on a storage device, loaded into memory, and executed by a computer processor or can be provided from computer program products (e.g., as computer executable instructions) that are stored in non-transitory computer-readable storage mediums (e.g., RAM, hard disk, or optical/magnetic media).
- non-transitory computer-readable storage mediums e.g., RAM, hard disk, or optical/magnetic media.
- the present invention is well suited to a wide variety of computer network systems over numerous topologies.
- the configuration and management of large networks comprise storage devices and computers that are communicatively coupled to dissimilar computers and storage devices over a network, such as the Internet.
Abstract
Description
O j=(offset— x j,offset— y j) where j≧1;
-
- OIJ={(−1, 1), (0, 1), (1, 1), (−1, 0), (1, 0), (−1, −1), (0, −1), and (1, −1)} where OIj represents a list of offset vectors of neighbors of an interior block and j=1→8;
- OLBj={(0, 1), (1, 1), (1, 0), (1, −1), and (0,−1)} where OLBj represents a list of offset vectors of neighbors of a left border block and j=1→5;
- ORBj={(0, 1), (−1, 1), (−1, 0), (−1, −1), and (0,−1)} where ORBj represents a list of offset vectors of neighbors of a right border block and j=1→5;
- OTBj={(−1, 0), (1, 0), (−1, −1), (0, −1), and (1, −1)} where OTBj represents a list of offset vectors of neighbors of a top border block and j=1→5;
- OBBj={(−1, 0), (1, 0), (−1, 1), (0, 1), and (1, 1)} where OBBj represents a list of offset vectors of neighbors of a bottom border block and j=1→5;
- OTLCj={(1, 0), (1, −1), and (0, −1)} where OTLCj represents a list of offset vectors of neighbors of a top left corner block and j=1→3;
- OBLCj={(0, 1), (1, 1), and (0, 1)} where OBLCj represents a list of offset vectors of neighbors of a bottom left corner block and j=1→3;
- OTRCj={(−1, 0), (−1, −1), and (0, −1)} where OTRCj represents a list of offset vectors of neighbors of a top right corner block and j=1→3; and
- OBRCj={(−1, 0), (−1, 1), and (0, 1)} where OBRCj represents a list of offset vectors of neighbors of a bottom right corner block and j=1→3;
-
- IPTi=initial (or previous iteration) dictionary predictor for Ti;
- IPTOj=initial (or previous iteration) dictionary predictor for neighbor TOj of Ti;
C={IPT i . . . (IPT Oj +O j)}
L 6 =O 1+(offset— x,offset— y)=(x 1 ,y 1)+(offset— x,offset— y)
As noted previously, dictionary predictor entries may be sub-blocks of an image. Thus, if some sub-block at an offset (offset_x, offset_y) from the origin of a dictionary entry is selected as the dictionary predictor entry for a given macroblock at location, then by spatial continuity, the dictionary predictor entry (i.e., a sub-block of the image) at a position Pj=Pi+(offset_x, offset_y) is potentially a good dictionary predictor entry for the macroblock.
Claims (20)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US13/105,610 US8805104B1 (en) | 2011-05-11 | 2011-05-11 | Selecting example-based predictors based on spatial continuity |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US13/105,610 US8805104B1 (en) | 2011-05-11 | 2011-05-11 | Selecting example-based predictors based on spatial continuity |
Publications (1)
Publication Number | Publication Date |
---|---|
US8805104B1 true US8805104B1 (en) | 2014-08-12 |
Family
ID=51267384
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US13/105,610 Expired - Fee Related US8805104B1 (en) | 2011-05-11 | 2011-05-11 | Selecting example-based predictors based on spatial continuity |
Country Status (1)
Country | Link |
---|---|
US (1) | US8805104B1 (en) |
Cited By (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20140314330A1 (en) * | 2013-03-19 | 2014-10-23 | Thomson Licensing | Inter-image prediction method and device and corresponding coding method and apparatus |
US20160212448A1 (en) * | 2014-05-28 | 2016-07-21 | Peking University Shenzhen Graduate School | Method and device for video encoding or decoding based on dictionary database |
US11240492B2 (en) | 2019-01-22 | 2022-02-01 | Apple Inc. | Neural network based residual coding and prediction for predictive coding |
Citations (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6792157B1 (en) * | 1999-08-25 | 2004-09-14 | Fuji Xerox Co., Ltd. | Image encoding apparatus and quantization characteristics determining apparatus |
US20100254622A1 (en) * | 2009-04-06 | 2010-10-07 | Yaniv Kamay | Methods for dynamically selecting compression method for graphics remoting |
US20110222836A1 (en) * | 2010-03-12 | 2011-09-15 | Sony Corporation | Video editing with a pc data linked to a video capture device |
US8103112B2 (en) * | 2007-02-09 | 2012-01-24 | Olympus Imaging Corp. | Decoding method, decoding apparatus, storage medium in which decoding program is stored, and electronic camera |
US20120250764A1 (en) * | 2009-06-22 | 2012-10-04 | Thomson Licensing | Process for coding video data of a sequence of images |
US8351721B2 (en) * | 2009-12-11 | 2013-01-08 | Kddi R&D Laboratories, Inc. | Image encoding device |
US8515193B1 (en) * | 2011-04-08 | 2013-08-20 | Google Inc. | Image compression using exemplar dictionary based on hierarchical clustering |
-
2011
- 2011-05-11 US US13/105,610 patent/US8805104B1/en not_active Expired - Fee Related
Patent Citations (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6792157B1 (en) * | 1999-08-25 | 2004-09-14 | Fuji Xerox Co., Ltd. | Image encoding apparatus and quantization characteristics determining apparatus |
US8103112B2 (en) * | 2007-02-09 | 2012-01-24 | Olympus Imaging Corp. | Decoding method, decoding apparatus, storage medium in which decoding program is stored, and electronic camera |
US20100254622A1 (en) * | 2009-04-06 | 2010-10-07 | Yaniv Kamay | Methods for dynamically selecting compression method for graphics remoting |
US20120250764A1 (en) * | 2009-06-22 | 2012-10-04 | Thomson Licensing | Process for coding video data of a sequence of images |
US8351721B2 (en) * | 2009-12-11 | 2013-01-08 | Kddi R&D Laboratories, Inc. | Image encoding device |
US20110222836A1 (en) * | 2010-03-12 | 2011-09-15 | Sony Corporation | Video editing with a pc data linked to a video capture device |
US8515193B1 (en) * | 2011-04-08 | 2013-08-20 | Google Inc. | Image compression using exemplar dictionary based on hierarchical clustering |
Non-Patent Citations (13)
Title |
---|
Baluja, S., et al., "Beyond "Near-Duplicates": Learning Hash Codes for Efficient Similar-Image Retrieval" ICPR'10, International Conference on Pattern Recognition, Aug. 20, 2010, pp. 543-547. |
Barnes, C., et al., "PatchMatch: A Randomized Correspondence Algorithm for Structural Image Editing," ACM Transactions on Graphics (Proc. SIGGRAPH), Aug. 2009, 10 pages. |
Cui, J., et al., "Example-Based Image Commpression," 17th IEEE International Conference on Image Processina (ICIP}, 2010, 4 Pages. * |
Cui, J., et al., "Example-Based Image Commpression," 17th IEEE International Conference on Image Processing (ICIP), 2010, 4 Pages. |
Datar, M., et al., "Locality Sensitive Hashing Scheme Based on p-Stable Distributions," SoCG'04, Jun. 9-11, 2004, New York, USA, ACM, 10 Pages. |
Grundmann, M., et al., "Efficient Hierarchical Graph-Based Video Segmentation," CVPR, 2010, pp. 1-8. |
Khan, A., et al., "Content Classification Based on Objective Video Quality Evaluation for MPEG4 Video Streaming over Wireless Networks," Proceedings of the World Congress on Engineering 2009, vol. I WCE 2009, Jul. 1-3, 2009, London, U.K., 6 pages. |
Kleinberg, J., et al., "Algorithm Design," Chapter 1, Introduction: Some Representative Problems, Pearson Education Inc., 2006, 13 pages. |
MacQueen, J. B., "Some Methods for classification and Analysis of Multivariate Observations," Proceedings of 5-th Berkeley Symposium on Mathematical Statistics and Probability, 1967, Berkeley, University of California Press, vol. 1, pp. 281-297. |
Nuno M. M. Rodrigues et al., "On Dictionary Adaptation for Recurrent Pattern Image Coding", IEEE Transactions on Image Processing, vol. 17, No. 9, Sep. 2008, pp. 1640-1653. * |
Shlens, J., "A Tutorial on Principal Component Analysis-Derivation, Discussion and Singular Value Decomposition," Mar. 25, 2003, PCA-Tutorial-Intuition, Version 1, pp. 1-16, available at . |
Shlens, J., "A Tutorial on Principal Component Analysis-Derivation, Discussion and Singular Value Decomposition," Mar. 25, 2003, PCA-Tutorial-Intuition, Version 1, pp. 1-16, available at <URL:http://www.cs.princeton.edu/picasso/mats/PCA-Tutorial-Intuition—jp.pdf>. |
Yianilos, P., "Data Structures and Algorithms for Nearest Neighbor Search in General Metric Spaces," NEC Research Institute Technical Report Fourth, Jun. 1992, 11 pages. |
Cited By (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20140314330A1 (en) * | 2013-03-19 | 2014-10-23 | Thomson Licensing | Inter-image prediction method and device and corresponding coding method and apparatus |
US9547915B2 (en) * | 2013-03-19 | 2017-01-17 | Thomson Licensing | Inter-image prediction method and device and corresponding coding method and apparatus |
US20160212448A1 (en) * | 2014-05-28 | 2016-07-21 | Peking University Shenzhen Graduate School | Method and device for video encoding or decoding based on dictionary database |
US11240492B2 (en) | 2019-01-22 | 2022-02-01 | Apple Inc. | Neural network based residual coding and prediction for predictive coding |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US10284848B2 (en) | Image predictive encoding and decoding device | |
Chen et al. | Automatic detection of object-based forgery in advanced video | |
Wu et al. | Lossless compression of JPEG coded photo collections | |
US10116934B2 (en) | Image processing method and apparatus | |
Zhang et al. | A joint compression scheme of video feature descriptors and visual content | |
US20120207367A1 (en) | Alignment of an ordered stack of images from a specimen | |
US10154281B2 (en) | Method and apparatus for keypoint trajectory coding on compact descriptor for video analysis | |
US20160255357A1 (en) | Feature-based image set compression | |
US20130088645A1 (en) | Method of Processing Moving Picture and Apparatus Thereof | |
Chao et al. | Keypoint encoding for improved feature extraction from compressed video at low bitrates | |
US8805104B1 (en) | Selecting example-based predictors based on spatial continuity | |
US20080112631A1 (en) | Method of obtaining a motion vector in block-based motion estimation | |
JP2006517069A (en) | Motion vector prediction method and system | |
Perra et al. | Cloud-scale Image Compression Through Content Deduplication. | |
JP2007527126A (en) | Image part compression method and apparatus | |
CN106611043B (en) | Video searching method and system | |
CN108712655B (en) | group image coding method for similar image set merging | |
US20120106638A1 (en) | Decoder-Side Motion Derivation with Motion Vector Predictors | |
US8724701B1 (en) | Using object decomposition to improve the selection of example-based predictors | |
Milani et al. | Compression of photo collections using geometrical information | |
Guru et al. | Histogram based split and merge framework for shot boundary detection | |
Bakkouri et al. | An adaptive CU size decision algorithm based on gradient boosting machines for 3D-HEVC inter-coding | |
US10397566B2 (en) | Image coding apparatus, image coding method, and program | |
Hu et al. | Improved color image coding schemes based on single bit map block truncation coding | |
Mishra et al. | Comparative study of motion estimation techniques in video |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:COVELL, MICHELE;KWATRA, VIVEK;HAN, MEI;AND OTHERS;SIGNING DATES FROM 20110429 TO 20110511;REEL/FRAME:026263/0890 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
CC | Certificate of correction | ||
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044277/0001Effective date: 20170929 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 4TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1551)Year of fee payment: 4 |
|
FEPP | Fee payment procedure |
Free format text: MAINTENANCE FEE REMINDER MAILED (ORIGINAL EVENT CODE: REM.); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
LAPS | Lapse for failure to pay maintenance fees |
Free format text: PATENT EXPIRED FOR FAILURE TO PAY MAINTENANCE FEES (ORIGINAL EVENT CODE: EXP.); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
STCH | Information on status: patent discontinuation |
Free format text: PATENT EXPIRED DUE TO NONPAYMENT OF MAINTENANCE FEES UNDER 37 CFR 1.362 |
|
FP | Lapsed due to failure to pay maintenance fee |
Effective date: 20220812 |