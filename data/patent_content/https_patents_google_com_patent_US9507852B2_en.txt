US9507852B2 - Techniques for discriminative dependency parsing - Google Patents
Techniques for discriminative dependency parsing Download PDFInfo
- Publication number
- US9507852B2 US9507852B2 US14/102,087 US201314102087A US9507852B2 US 9507852 B2 US9507852 B2 US 9507852B2 US 201314102087 A US201314102087 A US 201314102087A US 9507852 B2 US9507852 B2 US 9507852B2
- Authority
- US
- United States
- Prior art keywords
- tokens
- computing device
- pos
- sequence
- parsing
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Expired - Fee Related, expires
Links
Images
Classifications
-
- G06F17/30654—
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/33—Querying
- G06F16/332—Query formulation
- G06F16/3329—Natural language query formulation or dialogue systems
-
- G06F17/2775—
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/20—Natural language analysis
- G06F40/279—Recognition of textual entities
- G06F40/289—Phrasal analysis, e.g. finite state techniques or chunking
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/08—Speech classification or search
- G10L15/18—Speech classification or search using natural language modelling
- G10L15/1822—Parsing for meaning understanding
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/26—Speech to text systems
Definitions
- the present disclosure relates to syntactic analysis and, more particularly, to techniques for discriminative dependency parsing.
- Dependency parsing is typically modeled as a pipeline of independent tasks: (1) tokenization, (2) part-of-speech (POS) tagging, and (3) parsing.
- Tokenization involves partitioning an input string of characters into a set of tokens, e.g., words.
- POS tagging involves assigning a POS tag to each token.
- Parsing involves determining a syntactic head of each token and building a parse tree that represents relationships between tokens. Tokenization can be difficult for languages that do not use white space to separate words (Chinese, Japanese, Korean, etc.) and for languages that have a rich morphology (Arabic, Hebrew, Turkish, etc.).
- POS part-of-speech
- a computer-implemented method can include receiving, at a computing device having one or more processors, a speech input representing a question.
- the method can include converting, at the computing device, the speech input to a string of characters in a natural language.
- the method can include obtaining, at the computing device, tokens corresponding to the string of characters in the natural language, each token representing a potential word including at least one character of the string of characters.
- the method can include determining, at the computing device, one or more part-of-speech (POS) tags for each token.
- the method can include determining, at the computing device, sequences of the POS tags for the tokens, each sequence of the POS tags including one POS tag per token.
- POS part-of-speech
- the method can include determining, at the computing device, one or more parses for each sequence of the POS tags for the tokens.
- the method can include determining, at the computing device, a most-likely parse and its corresponding sequence of the POS tags for the tokens to obtain a selected parse and a selected sequence of the POS tags for the tokens.
- the method can include determining, at the computing device, a most-likely answer to the question using the selected parse and the selected sequence of the POS tags for the tokens.
- the method can also include outputting, by the computing device, the most-likely answer to the question.
- determining the most-likely parse and its corresponding sequence of the POS tags for the tokens includes solving, at the computing device, a maximum-a-posteriori (MAP) inference problem defined as:
- solving the MAP inference problem includes solving, at the computing device, an integer linear program (ILP) defined as:
- solving the ILP includes utilizing, at the computing device, an exact dynamic programming algorithm.
- solving the ILP includes utilizing, at the computing device, relaxed parsing with independent contextual tagging.
- solving the ILP further includes performing, at the computing device, coarse-to-fine pruning to increase a speed of determining the most-likely parse and its corresponding sequence of the POS tags for the tokens.
- solving the ILP utilizing relaxed parsing with independent contextual tagging includes solving, at the computing device, the ILP as a Lagrangian dual decomposition defined as follows:
- the method further comprises receiving, at the computing device, the string of characters in the natural language, and tokenizing, at the computing device, the string of characters to obtain the tokens.
- a computing device is also presented.
- the computing device can include a communication device and one or more processors.
- the communication device can be configured to receive a speech input representing a question.
- the communication device can also be configured to output a most-likely answer to the question.
- the one or more processors can be configured to convert the speech input to a string of characters in a natural language.
- the one or more processors can be configured to obtain tokens corresponding to the string of characters in the natural language, each token representing a potential word including at least one character of the string of characters.
- the one or more processors can be configured to determine one or more part-of-speech (POS) tags for each token.
- POS part-of-speech
- the one or more processors can be configured to determine sequences of the POS tags for the tokens, each sequence of the POS tags including one POS tag per token.
- the one or more processors can be configured to determine one or more parses for each sequence of the POS tags for the tokens.
- the one or more processors can be configured to determine a most-likely parse and its corresponding sequence of the POS tags for the tokens to obtain a selected parse and a selected sequence of the POS tags for the tokens.
- the one or more processors can also be configured to determine the most-likely answer to the question using the selected parse and the selected sequence of the POS tags for the tokens.
- the one or more processors are configured to determine the most-likely parse and its corresponding sequence of the POS tags for the tokens by solving a maximum-a-posteriori (MAP) inference problem defined as:
- the one or more processors are configured to solve the MAP inference problem by solving an integer linear program (ILP) defined as:
- the one or more processors are configured to solve the ILP by utilizing an exact dynamic programming algorithm.
- the one or more processors are configured to solve the ILP by utilizing relaxed parsing with independent contextual tagging.
- the one or more processors are configured to solve the ILP further by performing coarse-to-fine pruning to increase a speed of determining the most-likely parse and its corresponding sequence of the POS tags for the tokens.
- the one or more processors are configured to solve the ILP utilizing relaxed parsing with independent contextual tagging by solving the ILP as a Lagrangian dual decomposition defined as follows:
- the communication device is further configured to receive the string of characters in the natural language, and wherein the one or more processors are further configured to tokenize the string of characters to obtain the tokens.
- a non-transitory, computer-readable medium can have instructions stored thereon that, when executed by one or more processors of a computing device, cause the computing device to perform operations including receiving a speech input representing a question.
- the operations can include converting the speech input to a string of characters in a natural language.
- the operations can include obtaining tokens corresponding to the string of characters in the natural language, each token representing a potential word including at least one character of the string of characters.
- the operations can include determining, at the computing device, one or more part-of-speech (POS) tags for each token.
- the operations can include determining sequences of the POS tags for the tokens, each sequence of the POS tags including one POS tag per token.
- POS part-of-speech
- the operations can include determining one or more parses for each sequence of the POS tags for the tokens.
- the operations can include determining a most-likely parse and its corresponding sequence of the POS tags for the tokens to obtain a selected parse and a selected sequence of the POS tags for the tokens.
- the operations can include determining a most-likely answer to the question using the selected parse and the selected sequence of the POS tags for the tokens.
- the operations can also include outputting the most-likely answer to the question.
- determining the most-likely parse and its corresponding sequence of the POS tags for the tokens includes solving a maximum-a-posteriori (MAP) inference problem defined as:
- solving the MAP inference problem includes solving an integer linear program (ILP) defined as:
- the operations further include tokenizing the string of characters to obtain the tokens.
- FIG. 1 is a functional block diagram of a computing network including an example computing device according to some implementations of the present disclosure
- FIG. 2 is a functional block diagram of the example computing device of FIG. 1 ;
- FIG. 3 is an illustration of an example sentence showing part-of-speech (POS) tags and parses according to some implementations of the present disclosure.
- FIG. 4 is a flow diagram of an example technique for discriminative dependency parsing according to some implementations of the present disclosure.
- a computing device 104 (a desktop computer, a laptop computer, a tablet computer, a mobile phone, a server, etc.) can receive input from and/or provide output to a user 108 .
- the computing device 104 can communicate with other computing devices via a network 112 .
- the network 112 can include a local area network (LAN), a wide area network (WAN), e.g., the Internet, or a combination thereof.
- the computing device 104 can communicate with another computing device 200 via the network 112 .
- the other computing device 200 may take the form of a server as illustrated.
- server can refer to both a single server and two or more servers operating in a parallel or distributed architecture.
- the computing device 200 can be configured to perform the discriminative dependency parsing techniques described below. It should be appreciated, however, that the computing device 104 can also wholly or partially perform these discriminative dependency parsing techniques.
- the user 108 can provide a user input at the computing device 104 .
- the user input can be, for example, a speech input or a text input.
- the computing device 104 can convert the speech input to a text input using a suitable speech-to-text algorithm.
- the user input may be a question that the user 108 is requesting an answer to, such as “Where is the nearest gas station?”
- the computing device 104 can transmit the user input to the other computing device 200 via the network 112 .
- the computing device 104 can then receive a most-likely parse of the text input and its corresponding sequence of POS tags from the other computing device 200 via the network 112 , as described more fully below.
- the answer can be determined using this information by the computing device 200 and/or the computing device 104 .
- this most-likely parse of the text input can be used to obtain an answer to the user's question, such as “1.2 miles ahead on the left.”
- the computing device 104 can then output this answer to the user 108 (via text and/or audio).
- the discriminative dependency parsing techniques of the present disclosure may be particularly suitable for situations where a user provides a speech input representing a question to a computing device to obtain an answer to the question. In these situations, the user is providing the question in real-time and is expecting an immediate or very quick answer in return, as if the user was having an actual conversation with the computing device. Discriminative dependency parsing techniques, therefore, may require a minimum degree of both speed and accuracy in order to be utilized for these question-answer situations. Because the discriminative dependency parsing techniques of the present disclosure jointly-maximize POS tagging and parsing, high quality (accurate) answers can be determined and provided to the user. Further, because the discriminative dependency parsing techniques of the present disclosure take advantage of various assumptions and filtering/pruning methods, the answer can be quickly determined and provided.
- the computing device 200 can include a communication device 204 , a processor 208 , and a memory 212 .
- the communication device 204 can control communication between the computing device 200 and other devices via the network 112 .
- the communication device 204 can include any suitable components for communication via the network 112 , e.g., a transceiver.
- the communication device 204 can control communication between the computing device 200 and the computing device 104 via the network 112 .
- the communication device 204 can receive a string of characters, e.g., representing a question, and can output a most-likely parse of the string of characters and its corresponding sequence of POS tags via the network 112 .
- the string of characters is received as a sequence of tokens, and the communication device 204 can receive the sequence of tokens representing words of the string of characters.
- the processor 208 can control operation of the computing device 200 . It should be appreciated that the term “processor” as used herein can refer to either a single processor or two or more processors operating in a parallel or distributed architecture. For example, the processor 208 can perform functions including, but not limited to loading and executing an operating system of the computing device 200 , controlling information input to and/or output from the computing device 200 , controlling communication over the network 112 via the communication device 204 , and/or controlling read/write operations at the memory 212 .
- the memory 212 can be any suitable storage medium (flash, hard disk, etc.) configured to store information at the computing device 200 .
- the processor 208 can also execute the techniques according to the present disclosure.
- the computing device 200 is configured to perform discriminative dependency parsing of a text input.
- Discriminative dependency parsing generally refers to the technique of analyzing a text to determine its grammatical structure. Discriminative dependency parsing can be utilized in machine translation as well as in other fields. In one example implementation, discriminative dependency parsing can be utilized to determine a grammatical structure of a text input representing a question, e.g., obtained from speech-to-text of a speech input, in order to determine and then output a best possible answer, e.g., a most relevant answer, to the question. For example only, the user 108 may input a question to the computing device 104 .
- the question may be a string of characters or may be speech input that is converted to the string of characters using suitable speech-to-text techniques.
- the computing device 104 may transmit the question to the computing device 200 for syntactic analysis to obtain a best answer to the question.
- the computing device 200 can implement the techniques of the present disclosure to determine a best (most-likely) parse and POS tagging of the string of characters. This information can then be used to obtain a best (most-likely) answer to the question.
- the computing device 200 can then transmit the answer to the question back to the computing device 104 to be provided to the user 108 .
- the discriminative dependency parsing techniques of the present disclosure and their possible applicability/use are described in greater detail below.
- the sentence 300 reads “How does a bee fly?” and has already been tokenized from an input text into words “How”, “does”, “a”, “bee”, and “fly”, punctuation “?”, and a special start token “*” indicating a start of the sentence 300 .
- the sentence 300 can also be referred to as w (the set of all the words). Notation [n] can be used to denote the set of tokens ⁇ 1 . . . n ⁇ and notation [n] 0 can be used to denote the set of tokens ⁇ 0 . . . n ⁇ .
- the sentence 300 also has been annotated with POS tags.
- tags can be used as short-hand for the terms “POS tag,” “POS tagger,” and “POS tagging,” respectively.
- Each token can have one or more POS tags associated with it.
- the token “bee” is associated with POS tags “NN” (noun) and “JJ” (adjective), e.g., because the token “bee” does not appear in a corresponding training data
- the token “fly” is associated with POS tags “VB” (verb) and “NN” (noun).
- parses of the sentence 300 can be illustrated by the parse tree 304 .
- a parse can refer to a specific syntactic analysis or interpretation of a string of characters according to specific grammar rules.
- the parse tree 304 illustrates four potential sequences of POS tags for the sentence 300 (represented by line connectors 308 ) and defines dependencies between the POS tags (represented by arrows 312 ).
- the parsing problem is discussed in greater detail below after an initial discussion of the tagging problem.
- a most-likely parse can be indicated by the bold connectors 308 .
- the tagging problem can be modeled as a linear-chain conditional random field (CRF).
- CRF linear-chain conditional random field
- a trigram CRF can be used to increase accuracy compared to a bigram CRF.
- an index set B(w) can be defined over trigrams of the sentence w.
- n ⁇ ) and t represents a POS tag from a set of POS tags T
- a set of all valid taggings can be defined by binary vectors, e.g., X(w) ⁇ 0,1 ⁇
- B and X can be used to represent B(w) and X(w) when a dependence on w is unambiguous.
- the trigram CRF can assume a score of the tagging factors into a linear function of the elements of B parameterized by a tagging weight vector ⁇ T , which can be a portion R
- the features can be defined by a tagging feature matrix F (w) .
- the tagging feature matrix F (w) can be defined as shown below, which is parameterized by the sentence w: F (w) ⁇ R
- a product of F (w) and x can produce the feature vector of a full tagging. Combining these elements, a maximum a posteriori (MAP) inference problem for tagging can be represented.
- MAP maximum a posteriori
- the MAP inference problem can be defined as follows:
- x * arg ⁇ ⁇ max x ⁇ X ⁇ ( w ) ⁇ ⁇ ⁇ T T ⁇ F ( w ) ⁇ x , ( 3 )
- x* represents a specific tagging or, rather, a specific sequence of POS tags, of the set of all valid taggings X
- ⁇ T T represents a transform of the tagging weight vector ⁇ T .
- max-marginals m T : B ⁇ R
- p represents a probability
- x represents a sequence of tags from the set of all valid taggings X
- ⁇ T T represents a transform of the tagging weight vector ⁇ T
- F (w) represents the tagging feature matrix.
- the dependency parsing problem can also be modeled as a CRF, e.g., a trigram CRF.
- the parse tree 304 can define dependencies between POS tags, which are illustrated by the arrows 312 .
- the arrows 312 can also be referred to as arcs, and thus the parse tree 304 can be divided into a set of arcs A.
- the arcs can describe an arc-factored or first-order model.
- An index set of first-order dependency arcs for the sentence w (hereinafter A(w)) can then be defined.
- the head index h can identify a specific token as a head having a modifier identified by the modifier index m.
- a set of possible parses Y(w) can then be defined using the index set of first-order dependency arcs A(w).
- a and Y can be used to represent A(w) and Y(w) when a dependence on w is unambiguous.
- the set of possible parses Y(w) can then be defined, e.g., Y(w) ⁇ 0,1 ⁇
- a parsing feature matrix G (x,w) describing the parsing features can be constructed.
- the parsing feature matrix G (x,w) can be constructed as shown below, parameterized by the sentence w and its one-best tagging x: G (x,w) ⁇ R
- MAP inference problem for dependency parsing can be represented.
- the MAP inference problem for dependency parsing can be defined as follows:
- y * arg ⁇ ⁇ max y ⁇ Y ⁇ ( w ) ⁇ ⁇ ⁇ P T ⁇ G ( x , w ) ⁇ y , ( 7 )
- y* represents a specific parsing of the set of all parses Y
- ⁇ P T represents a transform of the parsing weight vector ⁇ P
- G (x,w) represents the parsing feature matrix.
- a MAP inference problem for joint tagging and parsing can be represented as a combination of the individual MAP inference problems described above.
- the MAP inference problem for joint tagging and parsing can be defined as follows:
- One manner to decrease the MAP inference cost for joint tagging and parsing is to decrease or restrict the size of the parsing feature matrix G (x,w) . Less features, however, typically results in decreased accuracy. Therefore, the feature structure of parsing can be exploited to linearize the MAP inference problem above for joint tagging and parsing. More particularly, soft assignments of features can be utilized to maintain increased accuracy.
- the parsing feature matrix G (x,w) can be divided into three categories of features: (1) arc features, (2) contextual features, and (3) between features.
- Arc features can depend on the words and tags directly associated with the head and modifier indices h and m, respectively.
- Contextual features can depend on combinations of the tags in the immediate (neighboring) context of the head and the modifier. Between features can depend on the tags between the head and the modifier.
- ⁇ A A ⁇ [
- Each column of the parsing feature matrix G (x,w) can correspond to index value ⁇ A (h,m) for some head position h and some modifier position m.
- each column can consist of a small set of “on” features having a value of 1.
- the full set of features for a column can be summarized as follows: ([ w h ,w m ,( w h ,x h ),( w m ,x m ),( w h ,x m ),( x h ,x m )]+[( x h ,x h+u ,x m ,x m+v ): u,v ⁇ 1,1 ⁇ ]) ⁇ [( h ⁇ m ), ⁇ ] (9), where w h represents a head word, w m represents a modifier word, x h represents a head tag, and x m represents a modifier tag, and u and v represent each represent integers from ⁇ 1 to 1,
- a new joint index set J can be defined to include the arc features and relevant contextual features.
- This new joint index set J can make it possible to remove the dependence on the parsing feature matrix G (x,w) on the tag sequence x.
- the parsing feature matrix G (x,w) can then be factored into a new matrix H(w) ⁇ R
- H(w) the MAP inference problem for joint tagging and parsing can be rewritten.
- the MAP inference problem for joint tagging and parsing can be redefined as follows:
- This rewritten MAP inference problem for joint tagging and parsing can also be linearized by introducing a new variable z to replace the cubic terms y(j arc )x(j ht )x(j mt ).
- an integer linear program (ILP) for joint tagging and parsing can be obtained.
- ILP integer linear program
- the best (most-likely) sequence of tags (tagging) and parsing can be determined and selected.
- the ILP for joint tagging and parsing can be described as follows:
- the ILP for joint tagging and parsing can be subject to three different constraints.
- a first constraint (14) can ensure that z produces a valid parse structure by constraining it to x ⁇ X.
- a second constraint (15) can ensure that when a token is used as a modifier, its tag context agrees with the tagging y ⁇ Y.
- a third constraint (16) can similarly ensure that if a token is used as a head, its tag context agrees with the same valid tagging y ⁇ Y.
- these second and third constraints (15) and (16) can enforce tag consistency.
- a first method of solving the ILP for joint tagging and parsing can involve using an exact dynamic programming algorithm.
- the exact dynamic programming algorithm can involve treating all the possible local tag contexts for every token in a sentence as possible words senses for each token instead of adjacent tags. Any suitable dependency parsing algorithm that uses word senses can then be applied to solve the ILP for joint tagging and parsing. This process can also be sped up by exploiting the fact that neighboring tokens constrain each other's contexts.
- a second method of solving the ILP for joint tagging and parsing can involve utilizing a relaxed method.
- the relaxed method may be faster than the exact dynamic programming algorithm.
- the relaxed method can involve parsing with independent tagging. More specifically, tag consistency can be ignored to develop a faster, relaxed algorithm for parsing with independent tagging. It should be appreciated, however, that other suitable techniques can be utilized to solve the ILP for joint tagging and parsing other than the two methods described herein.
- a discrete set Z can be formed by dropping the second and third constraints (15) and (16), which enforced tag consistency in the ILP for joint tagging and parsing.
- the discrete set Z can be defined as follows:
- This maximization can be calculated efficiently by dynamic programming. More specifically, instead of treating the tag contexts as word senses, they can be treated as arc labels, i.e., each arc can be labeled with its chosen head and modifier context. This algorithm, however, may perform poorly on its own, and thus other techniques can be utilized to increase system speed/efficiency.
- a new set C can be utilized that enforces the tag consistency constraints (15) and (16) from the ILP and that were dropped from the discrete set Z.
- this new set C can be defined as follows:
- the ILP for joint tagging and parsing can then be rewritten with Z and C.
- the ILP can be redefined as follows:
- Lagrangian dual problem of this rewritten ILP can then be formed by relaxing both constraints with dual variables ⁇ R
- and ⁇ R
- the Lagrangian dual problem can be defined as follows:
- Problem (20) can be solved using a Viterbi algorithm for trigram tagging MAP.
- Problem (21) can be solved using the dynamic programming algorithm for parsing with independent tagging described above.
- Problem (22) can be represented as a Markov random field (MRF) and this problem and the corresponding max-marginal problem can be solved using a MAP algorithm with high-order potentials (HOP-MAP). It should be appreciated, however, that other suitable algorithms can be used to solve one or more of Problems (20), (21), and (22).
- the dual objective can be optimized.
- This approach can also be referred to as dual decomposition.
- the dual decomposition can involve sub-gradient or augmented Lagrangian methods for dual decomposition. It should be appreciated that other suitable dual decomposition methods can be used.
- max-marginals can also be used to update dual parameters as opposed to just the MAP solution. Dual decomposition can result in increased system speed/efficiency with minimal or no effects to accuracy.
- coarse-to-fine pruning can be utilized to solve the rewritten ILP.
- This approach can be used as an approximation method for speeding up solving of an inference problem and, in particular, dependency parsing.
- Coarse-to-fine pruning can involve reducing portions of a search space without losing overall system accuracy.
- the effectiveness of the coarse-to-fine pruning approach can be determined by the choice of its coarse models.
- the relaxations derived from the Lagrangian dual problem above can be utilized, which can also be referred to as structured ensemble cascades.
- the computing device 200 can receive tokens corresponding to a string of characters in a natural language, each token representing a potential word including at least one character of the string of characters.
- the string of characters can represent a question, e.g., received from the user 108 via the computing device 104 .
- the computing device 200 can determine one or more POS tags for each token.
- the computing device 200 can determine sequences of the POS tags for the tokens, each sequence of the POS tags including one POS tag per token.
- the computing device 200 can determine one or more parses for each sequence of the POS tags for the tokens.
- the computing device 200 can determine a most-likely parse and its corresponding sequence of the POS tags for the tokens to obtain a selected parse and a selected sequence of the POS tags for the tokens.
- the computing device 200 can output the selected parse and the selected sequence of the POS tags for the tokens.
- the selected parse and the selected sequence of POS tags for the tokens can be used to determine an answer to the question, which can then be output, e.g., to the computing device 104 .
- the technique 400 can then end or return to 404 for one or more additional cycles.
- Example embodiments are provided so that this disclosure will be thorough, and will fully convey the scope to those who are skilled in the art. Numerous specific details are set forth such as examples of specific components, devices, and methods, to provide a thorough understanding of embodiments of the present disclosure. It will be apparent to those skilled in the art that specific details need not be employed, that example embodiments may be embodied in many different forms and that neither should be construed to limit the scope of the disclosure. In some example embodiments, well-known procedures, well-known device structures, and well-known technologies are not described in detail.
- first, second, third, etc. may be used herein to describe various elements, components, regions, layers and/or sections, these elements, components, regions, layers and/or sections should not be limited by these terms. These terms may be only used to distinguish one element, component, region, layer or section from another region, layer or section. Terms such as “first,” “second,” and other numerical terms when used herein do not imply a sequence or order unless clearly indicated by the context. Thus, a first element, component, region, layer or section discussed below could be termed a second element, component, region, layer or section without departing from the teachings of the example embodiments.
- module may refer to, be part of, or include: an Application Specific Integrated Circuit (ASIC); an electronic circuit; a combinational logic circuit; a field programmable gate array (FPGA); a processor or a distributed network of processors (shared, dedicated, or grouped) and storage in networked clusters or datacenters that executes code or a process; other suitable components that provide the described functionality; or a combination of some or all of the above, such as in a system-on-chip.
- the term module may also include memory (shared, dedicated, or grouped) that stores code executed by the one or more processors.
- code may include software, firmware, byte-code and/or microcode, and may refer to programs, routines, functions, classes, and/or objects.
- shared means that some or all code from multiple modules may be executed using a single (shared) processor. In addition, some or all code from multiple modules may be stored by a single (shared) memory.
- group means that some or all code from a single module may be executed using a group of processors. In addition, some or all code from a single module may be stored using a group of memories.
- the techniques described herein may be implemented by one or more computer programs executed by one or more processors.
- the computer programs include processor-executable instructions that are stored on a non-transitory tangible computer readable medium.
- the computer programs may also include stored data.
- Non-limiting examples of the non-transitory tangible computer readable medium are nonvolatile memory, magnetic storage, and optical storage.
- the present disclosure also relates to an apparatus for performing the operations herein.
- This apparatus may be specially constructed for the required purposes, or it may comprise a general-purpose computer selectively activated or reconfigured by a computer program stored on a computer readable medium that can be accessed by the computer.
- a computer program may be stored in a tangible computer readable storage medium, such as, but is not limited to, any type of disk including floppy disks, optical disks, CD-ROMs, magnetic-optical disks, read-only memories (ROMs), random access memories (RAMs), EPROMs, EEPROMs, magnetic or optical cards, application specific integrated circuits (ASICs), or any type of media suitable for storing electronic instructions, and each coupled to a computer system bus.
- the computers referred to in the specification may include a single processor or may be architectures employing multiple processor designs for increased computing capability.
- the present disclosure is well suited to a wide variety of computer network systems over numerous topologies.
- the configuration and management of large networks comprise storage devices and computers that are communicatively coupled to dissimilar computers and storage devices over a network, such as the Internet.
Abstract
Description
where x* and y* represent a specific sequence of the POS tags and a specific parse, respectively, X represents a set of the POS tags x, Y represents a set of the parses y, θT T represents a transformed tagging weight vector, F(w) represents a tagging feature matrix, θP T represents a transformed parsing weight vector, and G(x,w) represents a parsing feature matrix.
where J represents a set of joint features j, each joint feature j corresponding to a head position h, a modifier position m, a trigram context t centered at the head, and a trigram context u centered at the modifier, H represents a parsing feature matrix based on the feature matrix G(x,w) but having a dependency on x removed, z represents a variable replacing cubic terms y(jarc)x(jht)x(jmt) with jarc=(h,m), jht=(h,t), jmt=(m,u), and jmod=m, a represents a specific arc of a set of first-order dependency arcs A, b represents a specific trigram of a set of trigrams B, and [n] represents a set of the tokens.
where Z represents a set of all z, λT and βT represent transforms of matrices λεR|B| and β=R|J|, R represents parameters of the tagger θTεRt and the parser θPεRp, x=x′, and z=z′, and where C represents a set defined as:
where x* and y* represent a specific sequence of the POS tags and a specific parse, respectively, X represents a set of the POS tags x, Y represents a set of the parses y, θT T represents a transformed tagging weight vector, F(w) represents a tagging feature matrix, θP T represents a transformed parsing weight vector, and G(x,w) represents a parsing feature matrix.
where J represents a set of joint features j, each joint feature j corresponding to a head position h, a modifier position m, a trigram context t centered at the head, and a trigram context u centered at the modifier, H represents a parsing feature matrix based on the feature matrix G(x,w) but having a dependency on x removed, z represents a variable replacing cubic terms y(jarc)x(jht)x(jmt) with jarc=(h,m), jht=(h,t), jmt=(m,u), and jmod=m, a represents a specific arc of a set of first-order dependency arcs A, b represents a specific trigram of a set of trigrams B, and [n] represents a set of the tokens.
where Z represents a set of all z, λT and βT represent transforms of matrices λεR|B| and β=R|J|, R represents parameters of the tagger θTεRt and the parser θPεRp, x=x′, and z=z′, and where C represents a set defined as:
where x* and y* represent a specific sequence of the POS tags and a specific parse, respectively, X represents a set of the POS tags x, Y represents a set of the parses y, θT T represents a transformed tagging weight vector, F(w) represents a tagging feature matrix, θP T represents a transformed parsing weight vector, and G(x,w) represents a parsing feature matrix.
where J represents a set of joint features j, each joint feature j corresponding to a head position h, a modifier position m, a trigram context t centered at the head, and a trigram context u centered at the modifier, H represents a parsing feature matrix based on the feature matrix G(x,w) but having a dependency on x removed, z represents a variable replacing cubic terms y(jarc)x(jht)x(jmt) with jarc=(h,m), jht=(h,t), jmt=(m,u), and jmod=m, a represents a specific arc of a set of first-order dependency arcs A, b represents a specific trigram of a set of trigrams B, and [n] represents a set of the tokens.
B(w)={(i,t):iε[n],tεT 3} (1),
where i represents an index from the set of tokens [n] ({1 . . . n}) and t represents a POS tag from a set of POS tags T, A set of all valid taggings can be defined by binary vectors, e.g., X(w)⊂{0,1}|B(w)|. B and X can be used to represent B(w) and X(w) when a dependence on w is unambiguous.
F (w) εR |θ
where x* represents a specific tagging or, rather, a specific sequence of POS tags, of the set of all valid taggings X, and θT T represents a transform of the tagging weight vector θT. Another related problem is calculating max-marginals (mT: B→R) under this model. In one implementation, the max-marginals mT can be defined as follows:
where p represents a probability, x represents a sequence of tags from the set of all valid taggings X, θT T represents a transform of the tagging weight vector θT, and F(w) represents the tagging feature matrix.
A(w)={(h,m):hε[n] 0 ,mεn} (5),
where h is a head index, m is a modifier index, and [n]0 represents the set of tokens {0 . . . n}.
G (x,w) εR |θ
where G(x,y) represents the parsing feature matrix, R represents a portion of the parameters for the parser, θP represents the parsing feature vector, and A(w) represents the index set of first-order dependency arcs.
where y* represents a specific parsing of the set of all parses Y, θP T represents a transform of the parsing weight vector θP, and G(x,w) represents the parsing feature matrix. As previously discussed, however, performing tagging and parsing as independent tasks as described above can cause tagging errors that can propagate and negatively affect the parser. Again, another related problem is calculating max-marginals (mP: A→R) under this model.
where (x*, y*) represents a specific sequence of POS tags and a specific parse. The second summand of this equation, however, is no longer linear: it depends on both x (the tagging) and y (the parsing). This can result in the MAP inference cost becoming very large, which can cause system delay (slow/inefficient processing).
([w h ,w m,(w h ,x h),(w m ,x m),(w h ,x m),(x h ,x m)]+[(x h ,x h+u ,x m ,x m+v):u,vε{−1,1}])×[(h−m),φ] (9),
where wh represents a head word, wm represents a modifier word, xh represents a head tag, and xm represents a modifier tag, and u and v represent each represent integers from −1 to 1,
J={(h,m,t,u):(h,m)εA,(h,t),(m,u)εB} (10),
where t represents a trigram context centered at a specific head token and u represents a specific trigram context centered at its specific modifier token. To simplify the notation, the following projections can be defined for j=(h,t,m,u)εJ:
j arc=(h,m), j ht=(h,t),
j mt=(m,u), and j mod =m (11).
where φJ(j) represents specific features.
where a represents a specific arc of the set of first-order dependency arcs A and b represents a specific trigram of the set of trigrams B.
This discrete set Z can enforce that all structures z are valid parses with contextual tags, but can allow each arc to choose its contextual tag independently. For example only, in
This maximization can be calculated efficiently by dynamic programming. More specifically, instead of treating the tag contexts as word senses, they can be treated as arc labels, i.e., each arc can be labeled with its chosen head and modifier context. This algorithm, however, may perform poorly on its own, and thus other techniques can be utilized to increase system speed/efficiency.
Note that two redundant constraints can be added to enforce that each token is tagged only once and is a modifier exactly once, respectively.
where x=x′, and z=z′. The Lagrangian dual problem of this rewritten ILP can then be formed by relaxing both constraints with dual variables λεR|B| and β=R|J|, where R represents parameters of the tagger θTεRt and the parser θPεRp. In one implementation, after redistributing terms, the Lagrangian dual problem can be defined as follows:
Claims (17)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/102,087 US9507852B2 (en) | 2013-12-10 | 2013-12-10 | Techniques for discriminative dependency parsing |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/102,087 US9507852B2 (en) | 2013-12-10 | 2013-12-10 | Techniques for discriminative dependency parsing |
Publications (2)
Publication Number | Publication Date |
---|---|
US20150161996A1 US20150161996A1 (en) | 2015-06-11 |
US9507852B2 true US9507852B2 (en) | 2016-11-29 |
Family
ID=53271807
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US14/102,087 Expired - Fee Related US9507852B2 (en) | 2013-12-10 | 2013-12-10 | Techniques for discriminative dependency parsing |
Country Status (1)
Country | Link |
---|---|
US (1) | US9507852B2 (en) |
Cited By (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20210406320A1 (en) * | 2020-06-25 | 2021-12-30 | Pryon Incorporated | Document processing and response generation system |
US11551672B2 (en) * | 2019-12-12 | 2023-01-10 | Lg Electronics Inc. | Method for generating acoustic model |
Families Citing this family (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
WO2017161320A1 (en) * | 2016-03-18 | 2017-09-21 | Google Inc. | Generating dependency parses of text segments using neural networks |
US10380259B2 (en) * | 2017-05-22 | 2019-08-13 | International Business Machines Corporation | Deep embedding for natural language content based on semantic dependencies |
CN107480133B (en) * | 2017-07-25 | 2020-07-28 | 广西师范大学 | Subjective question self-adaptive scoring method based on answer implication and dependency relationship |
WO2020069048A1 (en) * | 2018-09-25 | 2020-04-02 | Archuleta Michelle | Reinforcement learning approach to modify sentence reading grade level |
CN110473540B (en) * | 2019-08-29 | 2022-05-31 | 京东方科技集团股份有限公司 | Voice interaction method and system, terminal device, computer device and medium |
Citations (34)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20020035537A1 (en) * | 1999-01-26 | 2002-03-21 | Waller Matthew A. | Method for economic bidding between retailers and suppliers of goods in branded, replenished categories |
US20030012347A1 (en) * | 2001-05-11 | 2003-01-16 | Volker Steinbiss | Method for the training or adaptation of a speech recognition device |
US20030191625A1 (en) * | 1999-11-05 | 2003-10-09 | Gorin Allen Louis | Method and system for creating a named entity language model |
US20040030556A1 (en) * | 1999-11-12 | 2004-02-12 | Bennett Ian M. | Speech based learning/training system using semantic decoding |
US20040138893A1 (en) * | 2003-01-13 | 2004-07-15 | Ran Mochary | Adaptation of symbols |
US20040215458A1 (en) * | 2003-04-28 | 2004-10-28 | Hajime Kobayashi | Voice recognition apparatus, voice recognition method and program for voice recognition |
US20040243409A1 (en) * | 2003-05-30 | 2004-12-02 | Oki Electric Industry Co., Ltd. | Morphological analyzer, morphological analysis method, and morphological analysis program |
US6832191B1 (en) * | 1999-09-02 | 2004-12-14 | Telecom Italia Lab S.P.A. | Process for implementing a speech recognizer, the related recognizer and process for speech recognition |
US20050038643A1 (en) * | 2003-07-02 | 2005-02-17 | Philipp Koehn | Statistical noun phrase translation |
US20050071149A1 (en) * | 2001-04-23 | 2005-03-31 | Microsoft Corporation | System and method for identifying base noun phrases |
US6882972B2 (en) * | 2000-10-10 | 2005-04-19 | Sony International (Europe) Gmbh | Method for recognizing speech to avoid over-adaptation during online speaker adaptation |
US20050143999A1 (en) * | 2003-12-25 | 2005-06-30 | Yumi Ichimura | Question-answering method, system, and program for answering question input by speech |
US20060149558A1 (en) * | 2001-07-17 | 2006-07-06 | Jonathan Kahn | Synchronized pattern recognition source data processed by manual or automatic means for creation of shared speaker-dependent speech user profile |
US20060195321A1 (en) * | 2005-02-28 | 2006-08-31 | International Business Machines Corporation | Natural language system and method based on unisolated performance metric |
US7143036B2 (en) * | 2000-07-20 | 2006-11-28 | Microsoft Corporation | Ranking parser for a natural language processing system |
US20070100624A1 (en) * | 2005-11-03 | 2007-05-03 | Fuliang Weng | Unified treatment of data-sparseness and data-overfitting in maximum entropy modeling |
US20090099841A1 (en) * | 2007-10-04 | 2009-04-16 | Kubushiki Kaisha Toshiba | Automatic speech recognition method and apparatus |
US20090119103A1 (en) * | 2007-10-10 | 2009-05-07 | Franz Gerl | Speaker recognition system |
US7533023B2 (en) * | 2003-02-12 | 2009-05-12 | Panasonic Corporation | Intermediary speech processor in network environments transforming customized speech parameters |
US7657431B2 (en) * | 2005-02-18 | 2010-02-02 | Fujitsu Limited | Voice authentication system |
US20110282661A1 (en) * | 2010-05-11 | 2011-11-17 | Nice Systems Ltd. | Method for speaker source classification |
US20120290302A1 (en) * | 2011-05-10 | 2012-11-15 | Yang Jyh-Her | Chinese speech recognition system and method |
US8348029B2 (en) * | 2007-02-21 | 2013-01-08 | GM Global Technology Operations LLC | Single fastener strut top mount and method of optimizing same |
US8374866B2 (en) * | 2010-11-08 | 2013-02-12 | Google Inc. | Generating acoustic models |
US20130204606A1 (en) * | 2010-08-09 | 2013-08-08 | Institute Of Automation, Chinese Academy Of Sciences | Method for labeling semantic role of bilingual parallel sentence pair |
US8554559B1 (en) * | 2012-07-13 | 2013-10-08 | Google Inc. | Localized speech recognition with offload |
US8571859B1 (en) * | 2012-05-31 | 2013-10-29 | Google Inc. | Multi-stage speaker adaptation |
US8583432B1 (en) * | 2012-07-18 | 2013-11-12 | International Business Machines Corporation | Dialect-specific acoustic language modeling and speech recognition |
US8639508B2 (en) * | 2011-02-14 | 2014-01-28 | General Motors Llc | User-specific confidence thresholds for speech recognition |
US8775174B2 (en) * | 2010-06-23 | 2014-07-08 | Telefonica, S.A. | Method for indexing multimedia information |
US8788266B2 (en) * | 2009-04-30 | 2014-07-22 | Nec Corporation | Language model creation device, language model creation method, and computer-readable storage medium |
US8812312B2 (en) * | 2007-08-31 | 2014-08-19 | International Business Machines Corporation | System, method and program for speech processing |
US20140278418A1 (en) * | 2013-03-15 | 2014-09-18 | Broadcom Corporation | Speaker-identification-assisted downlink speech processing systems and methods |
US8938391B2 (en) * | 2011-06-12 | 2015-01-20 | Microsoft Corporation | Dynamically adding personalization features to language models for voice search |
-
2013
- 2013-12-10 US US14/102,087 patent/US9507852B2/en not_active Expired - Fee Related
Patent Citations (34)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20020035537A1 (en) * | 1999-01-26 | 2002-03-21 | Waller Matthew A. | Method for economic bidding between retailers and suppliers of goods in branded, replenished categories |
US6832191B1 (en) * | 1999-09-02 | 2004-12-14 | Telecom Italia Lab S.P.A. | Process for implementing a speech recognizer, the related recognizer and process for speech recognition |
US20030191625A1 (en) * | 1999-11-05 | 2003-10-09 | Gorin Allen Louis | Method and system for creating a named entity language model |
US20040030556A1 (en) * | 1999-11-12 | 2004-02-12 | Bennett Ian M. | Speech based learning/training system using semantic decoding |
US7143036B2 (en) * | 2000-07-20 | 2006-11-28 | Microsoft Corporation | Ranking parser for a natural language processing system |
US6882972B2 (en) * | 2000-10-10 | 2005-04-19 | Sony International (Europe) Gmbh | Method for recognizing speech to avoid over-adaptation during online speaker adaptation |
US20050071149A1 (en) * | 2001-04-23 | 2005-03-31 | Microsoft Corporation | System and method for identifying base noun phrases |
US20030012347A1 (en) * | 2001-05-11 | 2003-01-16 | Volker Steinbiss | Method for the training or adaptation of a speech recognition device |
US20060149558A1 (en) * | 2001-07-17 | 2006-07-06 | Jonathan Kahn | Synchronized pattern recognition source data processed by manual or automatic means for creation of shared speaker-dependent speech user profile |
US20040138893A1 (en) * | 2003-01-13 | 2004-07-15 | Ran Mochary | Adaptation of symbols |
US7533023B2 (en) * | 2003-02-12 | 2009-05-12 | Panasonic Corporation | Intermediary speech processor in network environments transforming customized speech parameters |
US20040215458A1 (en) * | 2003-04-28 | 2004-10-28 | Hajime Kobayashi | Voice recognition apparatus, voice recognition method and program for voice recognition |
US20040243409A1 (en) * | 2003-05-30 | 2004-12-02 | Oki Electric Industry Co., Ltd. | Morphological analyzer, morphological analysis method, and morphological analysis program |
US20050038643A1 (en) * | 2003-07-02 | 2005-02-17 | Philipp Koehn | Statistical noun phrase translation |
US20050143999A1 (en) * | 2003-12-25 | 2005-06-30 | Yumi Ichimura | Question-answering method, system, and program for answering question input by speech |
US7657431B2 (en) * | 2005-02-18 | 2010-02-02 | Fujitsu Limited | Voice authentication system |
US20060195321A1 (en) * | 2005-02-28 | 2006-08-31 | International Business Machines Corporation | Natural language system and method based on unisolated performance metric |
US20070100624A1 (en) * | 2005-11-03 | 2007-05-03 | Fuliang Weng | Unified treatment of data-sparseness and data-overfitting in maximum entropy modeling |
US8348029B2 (en) * | 2007-02-21 | 2013-01-08 | GM Global Technology Operations LLC | Single fastener strut top mount and method of optimizing same |
US8812312B2 (en) * | 2007-08-31 | 2014-08-19 | International Business Machines Corporation | System, method and program for speech processing |
US20090099841A1 (en) * | 2007-10-04 | 2009-04-16 | Kubushiki Kaisha Toshiba | Automatic speech recognition method and apparatus |
US20090119103A1 (en) * | 2007-10-10 | 2009-05-07 | Franz Gerl | Speaker recognition system |
US8788266B2 (en) * | 2009-04-30 | 2014-07-22 | Nec Corporation | Language model creation device, language model creation method, and computer-readable storage medium |
US20110282661A1 (en) * | 2010-05-11 | 2011-11-17 | Nice Systems Ltd. | Method for speaker source classification |
US8775174B2 (en) * | 2010-06-23 | 2014-07-08 | Telefonica, S.A. | Method for indexing multimedia information |
US20130204606A1 (en) * | 2010-08-09 | 2013-08-08 | Institute Of Automation, Chinese Academy Of Sciences | Method for labeling semantic role of bilingual parallel sentence pair |
US8374866B2 (en) * | 2010-11-08 | 2013-02-12 | Google Inc. | Generating acoustic models |
US8639508B2 (en) * | 2011-02-14 | 2014-01-28 | General Motors Llc | User-specific confidence thresholds for speech recognition |
US20120290302A1 (en) * | 2011-05-10 | 2012-11-15 | Yang Jyh-Her | Chinese speech recognition system and method |
US8938391B2 (en) * | 2011-06-12 | 2015-01-20 | Microsoft Corporation | Dynamically adding personalization features to language models for voice search |
US8571859B1 (en) * | 2012-05-31 | 2013-10-29 | Google Inc. | Multi-stage speaker adaptation |
US8554559B1 (en) * | 2012-07-13 | 2013-10-08 | Google Inc. | Localized speech recognition with offload |
US8583432B1 (en) * | 2012-07-18 | 2013-11-12 | International Business Machines Corporation | Dialect-specific acoustic language modeling and speech recognition |
US20140278418A1 (en) * | 2013-03-15 | 2014-09-18 | Broadcom Corporation | Speaker-identification-assisted downlink speech processing systems and methods |
Cited By (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11551672B2 (en) * | 2019-12-12 | 2023-01-10 | Lg Electronics Inc. | Method for generating acoustic model |
US20210406320A1 (en) * | 2020-06-25 | 2021-12-30 | Pryon Incorporated | Document processing and response generation system |
Also Published As
Publication number | Publication date |
---|---|
US20150161996A1 (en) | 2015-06-11 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US9507852B2 (en) | Techniques for discriminative dependency parsing | |
Gu et al. | Insertion-based decoding with automatically inferred generation order | |
US11354506B2 (en) | Coreference-aware representation learning for neural named entity recognition | |
Zeng et al. | A convolution BiLSTM neural network model for Chinese event extraction | |
US10061766B2 (en) | Systems and methods for domain-specific machine-interpretation of input data | |
US9053089B2 (en) | Part-of-speech tagging using latent analogy | |
US20210110258A1 (en) | Method and apparatus with model training and/or sequence recognition | |
CN109074517B (en) | Global normalized neural network | |
US9779087B2 (en) | Cross-lingual discriminative learning of sequence models with posterior regularization | |
CN117933221A (en) | Construction and processing of computational graphs for dynamically structured machine learning models | |
Cheng et al. | Learning an executable neural semantic parser | |
US20120150531A1 (en) | System and method for learning latent representations for natural language tasks | |
US20040024584A1 (en) | Linguistic disambiguation system and method using string-based pattern training to learn to resolve ambiguity sites | |
US8914279B1 (en) | Efficient parsing with structured prediction cascades | |
Mahajani et al. | A comprehensive survey on extractive and abstractive techniques for text summarization | |
Kong et al. | Dragnn: A transition-based framework for dynamically connected neural networks | |
US10732937B2 (en) | Programming by voice | |
US20150066836A1 (en) | Methods and Systems of Four-Valued Simulation | |
Silfverberg et al. | FinnPos: an open-source morphological tagging and lemmatization toolkit for Finnish | |
US20230009946A1 (en) | Generative relation linking for question answering | |
US9658999B2 (en) | Language processing method and electronic device | |
CN113190675A (en) | Text abstract generation method and device, computer equipment and storage medium | |
US20220222442A1 (en) | Parameter learning apparatus, parameter learning method, and computer readable recording medium | |
Chong et al. | Efficient automatic speech recognition on the gpu | |
Chernyshov et al. | Intelligent processing of natural language search queries using semantic mapping for user intention extracting |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:PETROV, SLAV;RUSH, ALEXANDER;SIGNING DATES FROM 20131127 TO 20131210;REEL/FRAME:031986/0272 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044129/0001Effective date: 20170929 |
|
FEPP | Fee payment procedure |
Free format text: MAINTENANCE FEE REMINDER MAILED (ORIGINAL EVENT CODE: REM.); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
LAPS | Lapse for failure to pay maintenance fees |
Free format text: PATENT EXPIRED FOR FAILURE TO PAY MAINTENANCE FEES (ORIGINAL EVENT CODE: EXP.); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
STCH | Information on status: patent discontinuation |
Free format text: PATENT EXPIRED DUE TO NONPAYMENT OF MAINTENANCE FEES UNDER 37 CFR 1.362 |
|
FP | Lapsed due to failure to pay maintenance fee |
Effective date: 20201129 |