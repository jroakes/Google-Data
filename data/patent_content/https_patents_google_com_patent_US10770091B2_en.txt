US10770091B2 - Blind source separation using similarity measure - Google Patents
Blind source separation using similarity measure Download PDFInfo
- Publication number
- US10770091B2 US10770091B2 US15/412,812 US201715412812A US10770091B2 US 10770091 B2 US10770091 B2 US 10770091B2 US 201715412812 A US201715412812 A US 201715412812A US 10770091 B2 US10770091 B2 US 10770091B2
- Authority
- US
- United States
- Prior art keywords
- similarity
- audio signals
- frequency
- clustering
- matrix
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
- 238000011524 similarity measure Methods 0.000 title claims abstract description 58
- 238000000926 separation method Methods 0.000 title claims description 27
- 238000000034 method Methods 0.000 claims abstract description 67
- 230000005236 sound signal Effects 0.000 claims abstract description 37
- 238000012545 processing Methods 0.000 claims abstract description 20
- 239000011159 matrix material Substances 0.000 claims description 84
- 239000013598 vector Substances 0.000 claims description 33
- 238000004590 computer program Methods 0.000 claims description 17
- 238000007781 pre-processing Methods 0.000 claims description 5
- 230000004931 aggregating effect Effects 0.000 claims description 4
- 230000015654 memory Effects 0.000 description 35
- 230000006870 function Effects 0.000 description 22
- 238000013459 approach Methods 0.000 description 21
- 238000004422 calculation algorithm Methods 0.000 description 16
- 238000004891 communication Methods 0.000 description 16
- 230000000875 corresponding effect Effects 0.000 description 11
- 230000008569 process Effects 0.000 description 10
- 238000012546 transfer Methods 0.000 description 10
- 239000000203 mixture Substances 0.000 description 9
- 238000012805 post-processing Methods 0.000 description 7
- 230000003595 spectral effect Effects 0.000 description 7
- 230000008901 benefit Effects 0.000 description 6
- 230000006399 behavior Effects 0.000 description 4
- 238000004364 calculation method Methods 0.000 description 4
- 230000000694 effects Effects 0.000 description 4
- 238000000354 decomposition reaction Methods 0.000 description 3
- 238000012880 independent component analysis Methods 0.000 description 3
- 230000003287 optical effect Effects 0.000 description 3
- 230000001953 sensory effect Effects 0.000 description 3
- 230000001413 cellular effect Effects 0.000 description 2
- 230000001419 dependent effect Effects 0.000 description 2
- 238000005516 engineering process Methods 0.000 description 2
- 239000000284 extract Substances 0.000 description 2
- 238000000605 extraction Methods 0.000 description 2
- 230000003993 interaction Effects 0.000 description 2
- 230000002452 interceptive effect Effects 0.000 description 2
- 239000004973 liquid crystal related substance Substances 0.000 description 2
- 239000000047 product Substances 0.000 description 2
- 230000004044 response Effects 0.000 description 2
- 239000004065 semiconductor Substances 0.000 description 2
- 238000012935 Averaging Methods 0.000 description 1
- 230000003044 adaptive effect Effects 0.000 description 1
- 238000004458 analytical method Methods 0.000 description 1
- 230000003190 augmentative effect Effects 0.000 description 1
- 230000008859 change Effects 0.000 description 1
- 230000001268 conjugating effect Effects 0.000 description 1
- 230000002596 correlated effect Effects 0.000 description 1
- 238000013461 design Methods 0.000 description 1
- 230000008034 disappearance Effects 0.000 description 1
- 230000008451 emotion Effects 0.000 description 1
- 238000013507 mapping Methods 0.000 description 1
- 238000012986 modification Methods 0.000 description 1
- 230000004048 modification Effects 0.000 description 1
- 230000036651 mood Effects 0.000 description 1
- 230000008450 motivation Effects 0.000 description 1
- 230000006855 networking Effects 0.000 description 1
- 238000010606 normalization Methods 0.000 description 1
- 230000009467 reduction Effects 0.000 description 1
- 238000009877 rendering Methods 0.000 description 1
- 239000007787 solid Substances 0.000 description 1
- 239000013589 supplement Substances 0.000 description 1
- 230000000007 visual effect Effects 0.000 description 1
Images
Classifications
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L21/00—Processing of the speech or voice signal to produce another audible or non-audible signal, e.g. visual or tactile, in order to modify its quality or its intelligibility
- G10L21/02—Speech enhancement, e.g. noise reduction or echo cancellation
- G10L21/0272—Voice signal separating
- G10L21/0308—Voice signal separating characterised by the type of parameter measurement, e.g. correlation techniques, zero crossing techniques or predictive techniques
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L21/00—Processing of the speech or voice signal to produce another audible or non-audible signal, e.g. visual or tactile, in order to modify its quality or its intelligibility
- G10L21/02—Speech enhancement, e.g. noise reduction or echo cancellation
- G10L21/0272—Voice signal separating
- G10L21/028—Voice signal separating using properties of sound source
Definitions
- This document relates, generally, to blind source separation using a similarity measure.
- Computer-based audio processing and management is sometimes performed on signals generated by a set of talkers who are talking at a meeting, such as in a dedicated meeting room. It is useful to be able to separate the speech associated with the individual talkers. For example, combined with speech recognition this would allow one to create a written record of a meeting fully automatically. Combined with other existing technology, this could also allow one to find passages where a particular person has a particular mood (e.g., happy, angry, sad). The method would facilitate the reduction of noise in a recording. For example, the method could have low computational complexity and high reliability.
- a method includes: receiving time instants of audio signals generated by a set of microphones at a location; determining a distortion measure between frequency components of at least some of the received audio signals; determining a similarity measure for the frequency components using the determined distortion measure, the similarity measure measuring a similarity of the audio signals at different time instants for a frequency; and processing the audio signals based on the determined similarity measure.
- Implementations can include any or all of the following features. Determining the distortion measure comprises determining a correlation measure of vector directionality that relates events at different times.
- the correlation measure includes a distance computation based on inner product.
- the similarity measure comprises a kernelized similarity measure.
- the method further includes applying a weighting to the similarity measure, the weighting corresponding to relative importance across a band of frequency components for a time pair. Multiple similarity measures are determined, the method further comprising generating a similarity matrix for the frequency components based on the determined similarity measures.
- the method further includes performing clustering using the generated similarity matrix, the clustering indicating for which time segments a particular cluster is active, the cluster corresponding to a source of sound at the location. Performing the clustering comprises performing centroid-based clustering.
- Performing the clustering comprises performing exemplar-based clustering.
- the method further includes using the clustering to perform demixing in time.
- the method further includes using the clustering as a pre-processing step.
- the method further comprises computing a mixing matrix for each frequency and then determining a demixing matrix from the mixing matrix. Determining the demixing matrix comprises using a pseudo-inverse of the mixing matrix. Determining the demixing matrix comprises using a minimum-variance demixing.
- the processing of the audio signals comprises speech recognition of participants.
- the processing of the audio signals comprises performing a search of the audio signal for audio content from a participant.
- a computer program product is tangibly embodied in a non-transitory storage medium, the computer program product including instructions that when executed cause a processor to perform operations including: receiving time instants of audio signals generated by a set of microphones at a location; determining a distortion measure between frequency components of at least some of the received audio signals; determining a similarity measure for the frequency components using the determined distortion measure, the similarity measure measuring a similarity of the audio signals at different time instants for a frequency; and processing the audio signals based on the determined similarity measure.
- a system includes: a processor; and a computer program product tangibly embodied in a non-transitory storage medium, the computer program product including instructions that when executed cause the processor to perform operations including: receiving time instants of audio signals generated by a set of microphones at a location; determining a distortion measure between frequency components of at least some of the received audio signals; determining a similarity measure for the frequency components using the determined distortion measure, the similarity measure measuring a similarity of the audio signals at different time instants for a frequency; and processing the audio signals based on the determined similarity measure.
- the similarity measure comprises a kernelized similarity measure.
- FIG. 1 shows an example of a system.
- FIG. 2 shows an example of a blind source separation component.
- FIG. 3 shows an example of a kernelized similarity measure.
- FIG. 4A shows an example of clustering and demixing.
- FIG. 4B shows an example of a demixing matrix
- FIG. 5 shows an example of a computer device and a mobile computer device that can be used to implement the techniques described here.
- a similarity matrix can be defined that characterizes the similarity of the spatial signature of the observations at different time instants within a frequency band.
- Each entry of the similarity matrix can be the sum of a set of kernelized similarity measures for coefficients pairs of a time-frequency transform.
- the kernelization can result in high similarity resolution for similar time-frequency pairs and low similarity resolution for dissimilar time-frequency pairs. Clustering by means of affinity propagation can provide the separation of talkers.
- a single frequency band generally can work well, giving robust performance at low computational complexity.
- the clusters can be used directly for separation, or, to name another example, they can be used as a global pre-processing method that identifies sources for an adaptive demixing procedure that, for subsequent short time segment extracts each identified source that is active in that segment, given the interference to that source present in that time segment.
- BSS Blind source separation
- s ⁇ P ⁇ M be a complex matrix describing P unknown discrete-time source signals over a time segment of length M.
- A is the mixing matrix.
- the equation (1) can describe any linear time-invariant mixing process, including convolutive mixing. For acoustic signals observed by microphones, equation (1) can be written separately for each frequency bin of a time-frequency representation, and that can motivate the use of complex signals.
- FIG. 1 shows an example of a system 100 .
- a number of talkers 104 are gathered around a table 106 . Sound from one or more talkers can be captured using sensory devices 108 , such as an array of microphones.
- the sensory devices 108 can deliver signals to a blind source separation module 110 .
- the blind source separation module 110 performs BSS.
- An output from the blind source separation module 110 can be provided to a processing module 112 .
- the processing module 112 can perform audio processing on audio signals, including, but not limited to, speech recognition and/or searching for a characteristic exhibited by one or more talkers.
- An output of the processing module 112 can be provided to an output device 114 .
- data or other information regarding processed audio can be displayed on a monitor, played on one or more loudspeakers, or be stored in digital form.
- ICA independent-component analysis
- a ratio vector is defined as the vector of observations normalized by the first entry.
- the ratio vector is commonly referred to as the relative transfer function. Whenever the ratio vector is relatively constant over a time segment it is highly probable that a single source is active. This then allows for the computation of the row of the A matrix corresponding to that source. The TIFROM requirement for consecutive samples of a particular source in time can be relaxed. Once the matrix A is known, the signal s can be determined from the observations with the pseudo-inverse of A.
- Some implementations can use a kernelized similarity measure to identify time-frequency observations that belong to different sources.
- a kernelized approach can facilitate flexibility in the similarity measure that separates the different sources and allowing operation over frequency bands rather than single frequency bins. This can be exploited for improved performance.
- Spectral clustering a particular kernelized approach, can be used in the context of single-channel speech separation and in multichannel arrangements based on this principle.
- Some implementations are characterized in their kernel definition, the use of vector observations, and in the clustering method.
- x(k, m) be the observation vector at frequency k and time m.
- x(k, m 2 ) a kernelized measure of similarity between x(k, m 1 ), x(k, m 2 ).
- ⁇ ( m 1 , m 2 ) ⁇ ( x ⁇ ( k , m 1 ) , x ⁇ ( k , m 2 ) ) . ( 2 )
- the demixing matrix can then be determined from the mixing matrix directly by way of a pseudo-inverse or another suitable matrix inversion method. Alternatively, one can consider the mixing matrix as a global description and then, for consecutive short signal blocks, extract each of the identified sources, when present in the block, using methods that describe the local remainder signal as interference, for example as described below.
- Some implementations can provide at least three advantages over existing sparsity-based methods for finding a mixing matrix.
- a method can combine frequency bins within a frequency band for clustering to obtain increased robustness. This may not assume that the mixing matrix A(k) is the same for all frequency bins k within the band. When the microphones are not spatially close, the transfer function may change rapidly as a function of frequency, rendering the assumption of a single mixing matrix over a frequency band inaccurate.
- the second advantage is associated with the first advantage. If one aggregates the frequency bins over frequency bands prior to performing the clustering, the method may have low computational cost, despite the fact that one does not necessarily assume that the mixing matrices are constant over frequency.
- the third advantage may be that frequency bins that contain no relevant signal power can be included without negatively affecting performance. This may be a direct result of the kernelization of the similarity measures of the similarity coefficients. As the spatial signature of a source is largely determined by the relative phase of the components of the vectors, this can lead to robust performance. At least in principle, this robustness can be further improved by making the similarity measure ( ⁇ , ⁇ ) a function of signal power as outlined below.
- Some implementations can be used for separating the speech of talkers in a meeting room.
- the demixed speech signals can then be attributed to a particular person, and speech recognition can be used to produce a transcript that shows who said what with the option of playing out the associated acoustic signal where desired.
- the method can form a platform for adding additional capabilities such as the search for time segments where a particular talker displays a particular emotion, which may be of value, for example, to journalists analyzing debates.
- FIG. 2 shows an example of a blind source separation component 200 .
- a time-frequency vector signal with a discrete set of frequencies.
- the vector signal is the linear time-invariant mixture of a set of source signals represented by the vector s: ⁇ ⁇ P where P is the set of source signals.
- A(k) ⁇ Q ⁇ P is a frequency dependent mixing matrix, k is frequency and m is time.
- An objective can be to find A(k) from observations of x(k, m), and the knowledge that the components of the vector signal s(k, m) are statistically independent and sparse in the time-frequency representation.
- the sparsity assumption can be natural for a time-frequency representation of speech as spoken in meeting environments.
- Voiced speech is sparse in frequency because of harmonicity.
- speech has a large dynamic range, which implies that in a particular time-frequency bin a particular talker almost always dominates, even when multiple talkers talk simultaneously.
- spatial signatures of frequency bins they can usually be attributed to a particular talker. This property can also hold true, but to a lesser extent, if one uses frequency bands. It is this property that is exploited in the approach to BSS in some implementations.
- the aim of the similarity matrix of a signal segment can be to identify which signal segments within a band are dominated by the same source signal (talker).
- a clustering algorithm operating on the similarity matrix identifies an appropriate set of sources, and when they are active.
- the main task in defining the similarity matrix can be the definition of a good distance measure between the observation vectors of different times within a particular frequency bin.
- the selection of the similarity matrix can be flexible and other similarity matrices than selected here may provide better performance.
- the similarity measure aims to resolve the distinction between a signal vector generated by a first source and a signal vector generated by any second source.
- the overall similarity matrix (equation (2)) is an addition of terms. To obtain robust overall performance, outliers should not dominate this summation. This can be done by the proper design of the similarity measure % to be constructed such that outliers cannot occur.
- a natural measure of similarity for vector directionality can be correlation. While correlation is well-defined for real vectors, its analytic continuation to the complex case allows different choices. One can use
- the BSS component 200 can include a correlation component 210 that performs some or all of the above calculations.
- the BSS component 200 can include a distortion component 220 that performs some or all of the above calculations.
- s ⁇ ( x , ( k , m 1 ) , x ⁇ ( k , m 2 ) ) ⁇ ⁇ ( k , m 1 , m 2 ) ⁇ e - D ⁇ ( x ⁇ ( k , m 1 ) , x ⁇ ( k , m 2 ) ) Q ⁇ ⁇ ⁇ 2 , ( 5 )
- the variance ⁇ 2 is a parameter that determines the decay behavior of the similarity measure and where ⁇ (k, m 1 , m 2 ) is an optional weighting that can improve the robustness further.
- equations (5) and (2) can define a similarity matrix relating time instants in the frequency band .
- the BSS component 200 can include a similarity matrix 230 for some or all of the above calculations.
- the similarity measure % of equation (5) can be any suitable kernel, including, but not limited to, a standard Gaussian kernel as used in equation (5), that can be used in the context of spectral clustering. One can interpret the method as a mapping to a high-dimensional feature space and a conventional inner-product based distance computation in this feature space.
- the Gaussian kernel is chosen, but other kernels can be used.
- the equation (5) can be augmented by using the weighting ⁇ (k, m 1 , m 2 ) as a measure of relative importance across the band of the frequency components for a certain time pair (m 1 , m 2 ).
- the importance of a time-frequency vector is generally related to the relative loudness of that time-frequency vector.
- One measure of relative importance can provide a similar contribution to all vector pairs that have significant power relative to some noise power level ⁇ 2 .
- the noise level can be adapted or set to some fixed value.
- An effective example of such a relative importance measure is the sigmoid
- Clustering of the observations in time can be performed, where is a sequence of subsequent time indices. Based on the similarity matrix, each cluster gathers the time instants in where a particular source is active in the band .
- the definition of the similarity matrix in equation (2) can be seen as an overall kernelization of the similarity metric.
- the kernelization can allow one to select an appropriate similarity metric and forms an important attribute of the clustering algorithm.
- the next step can be to decide on a clustering algorithm that operates on the similarity matrix.
- spectral clustering One approach for clustering based on a similarity matrix is spectral clustering. This can be used in some implementations. Spectral clustering methods do not use the notion of an exemplar or centroid for a cluster, but instead separate regions of relatively high data density by regions of relatively low data density.
- spectral clustering may be undesirable for some implementations. Although this happens sparingly because of the large dynamic range of speech, the simultaneous activity of multiple sources can generate some observations where the relative transfer function is a linear mixture with similarly-sized contributions of the transfer functions of the distinct sources. Such data points can “bridge” the dense relative transfer function regions of the individual sources. Hence, spectral clustering sometimes combines distinct sound sources into a single cluster. This disadvantage can outweigh the advantage of spectral clustering that it can track a slowly moving source.
- centroid based clustering approach To avoid the problem of linking distinct sources, one can use an exemplar or centroid based clustering approach. However, one might like to retain the flexibility in the similarity metric, and hence combine the exemplar or centroid based approach with the earlier kernelized similarity measure.
- the outcome of the clustering process is an indicator function : ⁇ 0, 1 ⁇ for a frequency band that indicates for which time instants m ⁇ cluster p ⁇ is active.
- the computational effort is low if the number of bands is small. In many scenarios only a single band for computation of the clustering suffices. If multiple bands are used, the band clusters can be linked together to define wide-band source by performing a cross-correlation on the indicator functions, as discussed below.
- the BSS component 200 can include a clustering component 240 that performs some or all of the above calculations.
- FIG. 3 shows an example of a kernelized similarity measure 300 .
- the kernelized similarity measure 300 can be used in a similarity determination, such as using equation (5).
- an input 310 corresponding to x(k, m 1 ) and an input 320 corresponding to x(k, m 2 ) can be provided to the measure 300 .
- multiple instances of the kernelized similarity measure 300 are combined by summing over k to obtain a similarity measure for time-instants for the entire frequency band.
- FIG. 4A shows an example of clustering and demixing.
- a clustering component 400 can perform clustering, for example as described herein.
- a demixing component 410 can perform demixing based on input from the clustering component 400 .
- a second approach uses the clustering process as a pre-processing step. For example, it first computes a mixing matrix for each frequency k and then determines the demixing matrix from the mixing matrix either by using a pseudo-inverse or more sophisticated methods such as the one described below. One can improve the second approach further by postprocessing where required.
- FIG. 4B shows an example of a demixing matrix 420 .
- a clustering component 430 can provide pre-processing to a mixing matrix 440 , from which the demixing matrix 420 is determined.
- the following relates to nonlinear demixing in time. If only a single frequency band is used, then one can associate the time segments m corresponding to the sequence of time observations belonging to a cluster associated with a particular sound source p using the indicator function .
- the sequences of masked observations x ( k,m ) ( m ) (8) with a particular sound-source (cluster) p can then be placed in a single stream for each frequency bin k.
- One can then perform the inverse time-frequency transform ⁇ 1 on this stream and play out a particular scalar channel i of the vector signal: ( ⁇ 1 x(k, m) (m)) i (n) where n is time. This represents the source p as observed by microphone i at time sample n.
- the availability of multi-channel signals for the single source facilitates the application of dereverberation algorithms.
- the quality of nonlinear demixing in time can be excellent when the source signals do not overlap in time.
- the approach can perform well in a meeting scenario. For time segments where the talkers talk simultaneously, the system switches rapidly in time. The performance can then deteriorate rapidly with the number of talkers.
- the mixing matrix can be found for each frequency bin.
- Each frequency bin k must be assigned to a band 1 . It is natural to associate a bin k to the band 1 that it is contained in, or the band that it is closest to. Note again that a single frequency band may suffice.
- the following describes an exemplar based mixing matrix which can advantageously be used.
- the exemplar for each cluster p in a band contains an observation vector for each frequency bin k that is within . Conjugating and normalizing this vector to unit length provides a row p of a mixing matrix A(k). For frequency bins associated with but not in , one can take the observation vector associated with the time instant corresponding to the exemplar of cluster p. The exemplar-based determination of the mixing matrix will not be accurate for the frequency bins where the source p has low signal power in the exemplar.
- the following describes a singular value decomposition (SVD) based mixing matrix.
- SVD singular value decomposition
- p be the set of time instants associated with a cluster p in band 1 .
- One can perform a singular value decomposition on the matrix of concatenated observation vectors X (p) (k) for a frequency k to obtain the row of the mixing matrix A(k) for that particular source. It may be possible to improve the result by omitting time instants that have relatively low similarity to the exemplar, as indicated by the similarity matrix.
- a H ⁇ ( k ) ⁇ U ⁇ 1 ( p ) ⁇ p ⁇ P , ( 11 ) where all frequency and band indices have been omitted.
- a p ⁇ H ⁇ ( k ) ⁇ 1 x 1 ⁇ ( k , m ) ⁇ x ⁇ ( k , m ) ⁇ g ⁇ 0 ⁇ ( ⁇ x ⁇ ( k , m ) ⁇ ) ( 12 )
- g ⁇ 0 :[0, ⁇ ) ⁇ [0,1] is a sigmoidal function with parameterization ⁇ ⁇ , and where the observation is normalized by its first coefficient x 1 (k, m) and where an appropriate norm is used.
- a demixing matrix W(k) of a frequency bin k can be computed from the mixing matrix A(k) by means of the pseudo-inverse.
- the pseudo-inverse minimizes the unexplained variance in the observation vectors X(k, m) for the overdetermined case, ⁇ 3 , that is considered in this example.
- ⁇ 3 the overdetermined case
- the pseudo-inverse can lead to poor results if the true steering vectors are not aligned with the estimated rows of mixing matrix.
- This problem can be removed by rescaling the rows of the demixing matrix to unit norm.
- the resulting method can be interpreted as a projection onto the component of the row of the mixing matrix that is orthogonal to the other rows (i.e., the estimated steering vectors) of the other sources, followed by a renormalization.
- s p ( s ) ⁇ ( k , m ) s p ⁇ ( k , m ) - x ⁇ ( k , m ) ⁇ ⁇ ( A p ⁇ ) ⁇ b ( 14 )
- b arg ⁇ ⁇ min b ⁇ R ( Q - 1 ) ⁇ 1 ⁇ ⁇ ⁇ s p ⁇ ( k , m ) - x ⁇ ( k , m ) ⁇ ⁇ ( A p ⁇ ) ⁇ b ⁇ 2 .
- Low variance of the interference process can identify where the interference process is dominated by leakage of the desired source because of misalignment of the real and estimated steering vectors.
- the second term in equation (14) can be omitted.
- the boundaries of the time segments used for the enhancement approach can be selected based on the behavior of the similarity matrix.
- the similarity matrix can show when different sources and combinations of sources are active, and the boundaries of such regions can be used to select the time segments.
- the set may not be used directly as it does not flag mixtures.
- a method can perform better, particularly when one or more of the following conditions occurs: i) the number of sources P is small and the observation dimensionality is high, ii) the sources are intermittently active (e.g., talkers in a meeting, or instruments in a song), iii) the background noise has a nonuniform spatial profile.
- R N (k) be the empirical covariance matrix of the microphones without the contribution of the source p for the segment.
- R X (k) be the empirical covariance matrix of the microphones for the segment.
- R X (k) R N (k)+A p ⁇ H (k)A p ⁇ (k).
- the linear minimum-variance distortionless response (MVDR) estimator is then, for source p,
- equations (15) and (16) follows from the Woodbury matrix identity. Both equations (15) and (16) can be used to extract a particular source given its relative transfer function A p ⁇ H (k). This principle is similar to the application of the generalized side-lobe canceller to the relative transfer function in the beamformer.
- the time segments can be selected based on the behavior of the similarity matrix.
- the similarity matrix can generally show clearly when the mixture of sources changes.
- the following relates to nonlinear postprocessing.
- the postprocessing operation is aimed at reducing or removing signal leakage to the extracted signal for a source p when that source is not active. Leakage is often present because the p'th row W p ⁇ of W is not perfectly orthogonal to the relative transfer function of active sources.
- Equation (18) restricts the effect of postprocessing to time instants in the band that resemble the exemplar.
- equation (18) For complex shaped clusters one can replace the exemplar in equation (18) by the nearest neighbor time instant in the cluster.
- the simplest approach to linking existing exemplars to a new clustering operation may be to include the exemplars as a data point in the new clustering operation and find the cluster they are included into.
- new clusters can be added that correspond to sources that did not occur before in the data set.
- it may be natural to retain the exemplars, if possible with the associated data points (clusters) for each clustering operation, as well as the links between the exemplars of different clustering operations. Inconsistent linkages can occur that link clusters within a subset through clusters in other subsets. It may then be natural to break the links between clusters that are weakest according to the similarity measure in the corresponding similarity matrix.
- the ability to use of a subset of the data allows one to introduce a time constraint for the subset. That is, one can determine an update rule that selects a time interval [t 0 , t 1 ] for clustering for each subsequent time instant t for which a cluster association is being sought, where t 0 ⁇ t ⁇ t 1 . It is natural for a sequence of subsequent time instants to share a single clustering operation to save computation effort.
- the algorithmic delay is the maximum of the difference t 1 ⁇ t over all t being processed. Increased delay and an appropriate interval length will improve the ability of the separation system to handle scenarios that are not time-invariant (moving sources, the appearance and disappearance of sources).
- FIG. 5 shows an example of a generic computer device 500 and a generic mobile computer device 550 , which may be used with the techniques described here.
- Computing device 500 is intended to represent various forms of digital computers, such as laptops, desktops, tablets, workstations, personal digital assistants, televisions, servers, blade servers, mainframes, and other appropriate computing devices.
- Computing device 550 is intended to represent various forms of mobile devices, such as personal digital assistants, cellular telephones, smart phones, and other similar computing devices.
- the components shown here, their connections and relationships, and their functions, are meant to be exemplary only, and are not meant to limit implementations of the inventions described and/or claimed in this document.
- Computing device 500 includes a processor 502 , memory 504 , a storage device 506 , a high-speed interface 508 connecting to memory 504 and high-speed expansion ports 510 , and a low speed interface 512 connecting to low speed bus 514 and storage device 506 .
- the processor 502 can be a semiconductor-based processor.
- the memory 504 can be a semiconductor-based memory.
- Each of the components 502 , 504 , 506 , 508 , 510 , and 512 are interconnected using various busses, and may be mounted on a common motherboard or in other manners as appropriate.
- the processor 502 can process instructions for execution within the computing device 500 , including instructions stored in the memory 504 or on the storage device 506 to display graphical information for a GUI on an external input/output device, such as display 516 coupled to high speed interface 508 .
- an external input/output device such as display 516 coupled to high speed interface 508 .
- multiple processors and/or multiple buses may be used, as appropriate, along with multiple memories and types of memory.
- multiple computing devices 500 may be connected, with each device providing portions of the necessary operations (e.g., as a server bank, a group of blade servers, or a multi-processor system).
- the memory 504 stores information within the computing device 500 .
- the memory 504 is a volatile memory unit or units.
- the memory 504 is a non-volatile memory unit or units.
- the memory 504 may also be another form of computer-readable medium, such as a magnetic or optical disk.
- the storage device 506 is capable of providing mass storage for the computing device 500 .
- the storage device 506 may be or contain a computer-readable medium, such as a floppy disk device, a hard disk device, an optical disk device, or a tape device, a flash memory or other similar solid state memory device, or an array of devices, including devices in a storage area network or other configurations.
- a computer program product can be tangibly embodied in an information carrier.
- the computer program product may also contain instructions that, when executed, perform one or more methods, such as those described above.
- the information carrier is a computer- or machine-readable medium, such as the memory 504 , the storage device 506 , or memory on processor 502 .
- the high speed controller 508 manages bandwidth-intensive operations for the computing device 500 , while the low speed controller 512 manages lower bandwidth-intensive operations.
- the high-speed controller 508 is coupled to memory 504 , display 516 (e.g., through a graphics processor or accelerator), and to high-speed expansion ports 510 , which may accept various expansion cards (not shown).
- low-speed controller 512 is coupled to storage device 506 and low-speed expansion port 514 .
- the low-speed expansion port which may include various communication ports (e.g., USB, Bluetooth, Ethernet, wireless Ethernet) may be coupled to one or more input/output devices, such as a keyboard, a pointing device, a scanner, or a networking device such as a switch or router, e.g., through a network adapter.
- input/output devices such as a keyboard, a pointing device, a scanner, or a networking device such as a switch or router, e.g., through a network adapter.
- the computing device 500 may be implemented in a number of different forms, as shown in the figure. For example, it may be implemented as a standard server 520 , or multiple times in a group of such servers. It may also be implemented as part of a rack server system 524 . In addition, it may be implemented in a personal computer such as a laptop computer 522 . Alternatively, components from computing device 500 may be combined with other components in a mobile device (not shown), such as device 550 . Each of such devices may contain one or more of computing device 500 , 550 , and an entire system may be made up of multiple computing devices 500 , 550 communicating with each other.
- Computing device 550 includes a processor 552 , memory 564 , an input/output device such as a display 554 , a communication interface 566 , and a transceiver 568 , among other components.
- the device 550 may also be provided with a storage device, such as a microdrive or other device, to provide additional storage.
- a storage device such as a microdrive or other device, to provide additional storage.
- Each of the components 550 , 552 , 564 , 554 , 566 , and 568 are interconnected using various buses, and several of the components may be mounted on a common motherboard or in other manners as appropriate.
- the processor 552 can execute instructions within the computing device 550 , including instructions stored in the memory 564 .
- the processor may be implemented as a chipset of chips that include separate and multiple analog and digital processors.
- the processor may provide, for example, for coordination of the other components of the device 550 , such as control of user interfaces, applications run by device 550 , and wireless communication by device 550 .
- Processor 552 may communicate with a user through control interface 558 and display interface 556 coupled to a display 554 .
- the display 554 may be, for example, a TFT LCD (Thin-Film-Transistor Liquid Crystal Display) or an OLED (Organic Light Emitting Diode) display, or other appropriate display technology.
- the display interface 556 may comprise appropriate circuitry for driving the display 554 to present graphical and other information to a user.
- the control interface 558 may receive commands from a user and convert them for submission to the processor 552 .
- an external interface 562 may be provide in communication with processor 552 , so as to enable near area communication of device 550 with other devices. External interface 562 may provide, for example, for wired communication in some implementations, or for wireless communication in other implementations, and multiple interfaces may also be used.
- the memory 564 stores information within the computing device 550 .
- the memory 564 can be implemented as one or more of a computer-readable medium or media, a volatile memory unit or units, or a non-volatile memory unit or units.
- Expansion memory 574 may also be provided and connected to device 550 through expansion interface 572 , which may include, for example, a SIMM (Single In Line Memory Module) card interface.
- SIMM Single In Line Memory Module
- expansion memory 574 may provide extra storage space for device 550 , or may also store applications or other information for device 550 .
- expansion memory 574 may include instructions to carry out or supplement the processes described above, and may include secure information also.
- expansion memory 574 may be provide as a security module for device 550 , and may be programmed with instructions that permit secure use of device 550 .
- secure applications may be provided via the SIMM cards, along with additional information, such as placing identifying information on the SIMM card in a non-hackable manner.
- the memory may include, for example, flash memory and/or NVRAM memory, as discussed below.
- a computer program product is tangibly embodied in an information carrier.
- the computer program product contains instructions that, when executed, perform one or more methods, such as those described above.
- the information carrier is a computer- or machine-readable medium, such as the memory 564 , expansion memory 574 , or memory on processor 552 , that may be received, for example, over transceiver 568 or external interface 562 .
- Device 550 may communicate wirelessly through communication interface 566 , which may include digital signal processing circuitry where necessary. Communication interface 566 may provide for communications under various modes or protocols, such as GSM voice calls, SMS, EMS, or MMS messaging, CDMA, TDMA, PDC, WCDMA, CDMA2000, or GPRS, among others. Such communication may occur, for example, through radio-frequency transceiver 568 . In addition, short-range communication may occur, such as using a Bluetooth, WiFi, or other such transceiver (not shown). In addition, GPS (Global Positioning System) receiver module 570 may provide additional navigation- and location-related wireless data to device 550 , which may be used as appropriate by applications running on device 550 .
- GPS Global Positioning System
- Device 550 may also communicate audibly using audio codec 560 , which may receive spoken information from a user and convert it to usable digital information. Audio codec 560 may likewise generate audible sound for a user, such as through a loudspeaker, e.g., in a handset of device 550 . Such sound may include sound from voice telephone calls, may include recorded sound (e.g., voice messages, music files, etc.) and may also include sound generated by applications operating on device 550 .
- Audio codec 560 may receive spoken information from a user and convert it to usable digital information. Audio codec 560 may likewise generate audible sound for a user, such as through a loudspeaker, e.g., in a handset of device 550 . Such sound may include sound from voice telephone calls, may include recorded sound (e.g., voice messages, music files, etc.) and may also include sound generated by applications operating on device 550 .
- the computing device 550 may be implemented in a number of different forms, as shown in the figure. For example, it may be implemented as a cellular telephone 580 . It may also be implemented as part of a smart phone 582 , personal digital assistant, or other similar mobile device.
- implementations of the systems and techniques described here can be realized in digital electronic circuitry, integrated circuitry, specially designed ASICs (application specific integrated circuits), computer hardware, firmware, software, and/or combinations thereof.
- ASICs application specific integrated circuits
- These various implementations can include implementation in one or more computer programs that are executable and/or interpretable on a programmable system including at least one programmable processor, which may be special or general purpose, coupled to receive data and instructions from, and to transmit data and instructions to, a storage system, at least one input device, and at least one output device.
- the systems and techniques described here can be implemented on a computer having a display device (e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor) for displaying information to the user and a keyboard and a pointing device (e.g., a mouse or a trackball) by which the user can provide input to the computer.
- a display device e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor
- a keyboard and a pointing device e.g., a mouse or a trackball
- Other kinds of devices can be used to provide for interaction with a user as well; for example, feedback provided to the user can be any form of sensory feedback (e.g., visual feedback, auditory feedback, or tactile feedback); and input from the user can be received in any form, including acoustic, speech, or tactile input.
- the systems and techniques described here can be implemented in a computing system that includes a back end component (e.g., as a data server), or that includes a middleware component (e.g., an application server), or that includes a front end component (e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the systems and techniques described here), or any combination of such back end, middleware, or front end components.
- the components of the system can be interconnected by any form or medium of digital data communication (e.g., a communication network). Examples of communication networks include a local area network (“LAN”), a wide area network (“WAN”), and the Internet.
- LAN local area network
- WAN wide area network
- the Internet the global information network
- the computing system can include clients and servers.
- a client and server are generally remote from each other and typically interact through a communication network.
- the relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other.
Abstract
Description
x=As, (1)
where A is the mixing matrix. The equation (1) can describe any linear time-invariant mixing process, including convolutive mixing. For acoustic signals observed by microphones, equation (1) can be written separately for each frequency bin of a time-frequency representation, and that can motivate the use of complex signals.
x(k,m)=A(k)s(k,m). (3)
where A(k)ϵ
D(x(k,m 1),x(k,m 2))=1−|x H(k,m 1),x(k,m 2)|. (4)
where the variance σ2 is a parameter that determines the decay behavior of the similarity measure and where α(k, m1, m2) is an optional weighting that can improve the robustness further.
x(k,m)
with a particular sound-source (cluster) p can then be placed in a single stream for each frequency bin k. One can then perform the inverse time-frequency transform
X (p) =U (p) D (p) V (p)H, (9)
where U(p)ϵ
X (p) ≈D 11 (p) U ⋅1 (p) V ⋅1 (p)H, (10)
where one can interpret U⋅1 (p) as the relative transfer function and V⋅1 (p) as the driving signal for the cluster. One can now build the conjugate transpose of the mixing matrix for the frequency bin k as
where all frequency and band indices have been omitted.
where gα
s(k,m)=W(k)x(k,m). (13)
W H(k)=GR X −1(k)A H, (17)
where G is a diagonal matrix with elements Gp⋅=(Ap⋅(k)RX −1(k)Ap⋅ H(k))−1. Equation (17) is here different from the standard pseudo-inverse of A(k). Moreover, in some implementations the mixing matrix A(k) is advantageously estimated over longer intervals, whereas the covariance matrices RX(k) and equation (17) are evaluated for shorter time intervals. The demixing matrix can be used to obtain the sources using equation (13).
s p(k,m)=W pω x(k,m)g α
where gα
(19)
Claims (20)
Priority Applications (4)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US15/412,812 US10770091B2 (en) | 2016-12-28 | 2017-01-23 | Blind source separation using similarity measure |
PCT/US2017/049926 WO2018125308A1 (en) | 2016-12-28 | 2017-09-01 | Blind source separation using similarity measure |
CN201780058185.3A CN110088835B (en) | 2016-12-28 | 2017-09-01 | Blind source separation using similarity measures |
EP17765053.8A EP3501026B1 (en) | 2016-12-28 | 2017-09-01 | Blind source separation using similarity measure |
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201662439824P | 2016-12-28 | 2016-12-28 | |
US15/412,812 US10770091B2 (en) | 2016-12-28 | 2017-01-23 | Blind source separation using similarity measure |
Publications (2)
Publication Number | Publication Date |
---|---|
US20180182412A1 US20180182412A1 (en) | 2018-06-28 |
US10770091B2 true US10770091B2 (en) | 2020-09-08 |
Family
ID=62625709
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US15/412,812 Active 2038-02-13 US10770091B2 (en) | 2016-12-28 | 2017-01-23 | Blind source separation using similarity measure |
Country Status (4)
Country | Link |
---|---|
US (1) | US10770091B2 (en) |
EP (1) | EP3501026B1 (en) |
CN (1) | CN110088835B (en) |
WO (1) | WO2018125308A1 (en) |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11373355B2 (en) * | 2018-08-24 | 2022-06-28 | Honda Motor Co., Ltd. | Acoustic scene reconstruction device, acoustic scene reconstruction method, and program |
Families Citing this family (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN108962276B (en) * | 2018-07-24 | 2020-11-17 | 杭州听测科技有限公司 | Voice separation method and device |
CN110148422B (en) * | 2019-06-11 | 2021-04-16 | 南京地平线集成电路有限公司 | Method and device for determining sound source information based on microphone array and electronic equipment |
CN112151061B (en) * | 2019-06-28 | 2023-12-12 | 北京地平线机器人技术研发有限公司 | Signal ordering method and device, computer readable storage medium and electronic equipment |
US10984075B1 (en) * | 2020-07-01 | 2021-04-20 | Sas Institute Inc. | High dimensional to low dimensional data transformation and visualization system |
CN114863944B (en) * | 2022-02-24 | 2023-07-14 | 中国科学院声学研究所 | Low-delay audio signal overdetermined blind source separation method and separation device |
CN117037836B (en) * | 2023-10-07 | 2023-12-29 | 之江实验室 | Real-time sound source separation method and device based on signal covariance matrix reconstruction |
Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20080215651A1 (en) * | 2005-02-08 | 2008-09-04 | Nippon Telegraph And Telephone Corporation | Signal Separation Device, Signal Separation Method, Signal Separation Program and Recording Medium |
US20120295649A1 (en) * | 2011-05-20 | 2012-11-22 | Willem Bastiaan Kleijn | Distributed blind source separation |
US20150206727A1 (en) * | 2014-01-17 | 2015-07-23 | Rudjer Boskovic Institute | Method and apparatus for underdetermined blind separation of correlated pure components from nonlinear mixture mass spectra |
US20150242626A1 (en) * | 2014-02-27 | 2015-08-27 | National Chiao Tung University | Method of generating in-kernel hook point candidates to detect rootkits and the system thereof |
WO2016152511A1 (en) | 2015-03-23 | 2016-09-29 | ソニー株式会社 | Sound source separating device and method, and program |
Family Cites Families (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20100138010A1 (en) * | 2008-11-28 | 2010-06-03 | Audionamix | Automatic gathering strategy for unsupervised source separation algorithms |
CN101667425A (en) * | 2009-09-22 | 2010-03-10 | 山东大学 | Method for carrying out blind source separation on convolutionary aliasing voice signals |
US9460732B2 (en) * | 2013-02-13 | 2016-10-04 | Analog Devices, Inc. | Signal source separation |
US9338551B2 (en) * | 2013-03-15 | 2016-05-10 | Broadcom Corporation | Multi-microphone source tracking and noise suppression |
CN105230044A (en) * | 2013-03-20 | 2016-01-06 | 诺基亚技术有限公司 | Space audio device |
US10657973B2 (en) * | 2014-10-02 | 2020-05-19 | Sony Corporation | Method, apparatus and system |
CN105845148A (en) * | 2016-03-16 | 2016-08-10 | 重庆邮电大学 | Convolution blind source separation method based on frequency point correction |
-
2017
- 2017-01-23 US US15/412,812 patent/US10770091B2/en active Active
- 2017-09-01 WO PCT/US2017/049926 patent/WO2018125308A1/en unknown
- 2017-09-01 EP EP17765053.8A patent/EP3501026B1/en active Active
- 2017-09-01 CN CN201780058185.3A patent/CN110088835B/en active Active
Patent Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20080215651A1 (en) * | 2005-02-08 | 2008-09-04 | Nippon Telegraph And Telephone Corporation | Signal Separation Device, Signal Separation Method, Signal Separation Program and Recording Medium |
US20120295649A1 (en) * | 2011-05-20 | 2012-11-22 | Willem Bastiaan Kleijn | Distributed blind source separation |
US20150206727A1 (en) * | 2014-01-17 | 2015-07-23 | Rudjer Boskovic Institute | Method and apparatus for underdetermined blind separation of correlated pure components from nonlinear mixture mass spectra |
US20150242626A1 (en) * | 2014-02-27 | 2015-08-27 | National Chiao Tung University | Method of generating in-kernel hook point candidates to detect rootkits and the system thereof |
WO2016152511A1 (en) | 2015-03-23 | 2016-09-29 | ソニー株式会社 | Sound source separating device and method, and program |
US20180047407A1 (en) * | 2015-03-23 | 2018-02-15 | Sony Corporation | Sound source separation apparatus and method, and program |
Non-Patent Citations (24)
Title |
---|
Abrard, et al., "A time-frequency blind signal separation method applicable to underdetermined mixture of dependent sources", Signal Processing, vol. 85, No. 7, 2005, pp. 1389-1403. |
Bach, et al., "Spectral clustering for speech separation", Automatic Speech and Speaker Recognition, 2009, pp. 221-250. |
Cohen, "Relative transfer function identification using speech signals", IEEE Transactions on Speech and Audio Processing, vol. 12, No. 5, Sep. 2004, pp. 451-459. |
Comon, "Independent component analysis, a new concept?", Signal Processing, vol. 36, No. 3, 1994, pp. 287-314. |
Frey, et al., "Clustering by passing messages between data points", Science, vol. 315, Feb. 16, 2007, pp. 972-976. |
Gannot, et al., "Signal enhancement using beamforming and nonstationarity with applications to speech", IEEE Trans. Signal Processing, vol. 49, 2001, pp. 1614-1626. |
Girolami, "Mercer kernel based clustering in feature space", IEEE Trans. Neural Networks, vol. 13, No. 3, 2002, pp. 780-784. |
Gribonval, et al., "A survey of sparse component analysis for blind source separation: principles, perspectives and new challenges", 14th European Symposium on Artificial Neural Networks, 2006, pp. 323-330. |
Hoshuyama, et al., "A robust adaptive beam-former for microphone arrays with a blocking matrix using constrained adaptive filters", IEEE Trans. Signal Processing, vol. 47, 1999, pp. 2677-2684. |
Hyvaerinen, et al., "Independent component analysis: algorithms and applications", Neural networks, vol. 13, No. 4, 2000, pp. 411-430. |
International Search Report and Written Opinion for PCT/US2017/049926, dated Oct. 25, 2017, 8 pages. |
Kleijn, et al., "Robust and Low-Complexity Blind Source Separation for Meeting Rooms", Hands-free Speech Communications and Microphone Arrays (HSCMA), 2017, pp. 156-160. |
Li, et al., "Underdetermined blind source separation based on sparse representation", IEEE Transactions on Signal Processing, vol. 54, No. 2, Feb. 2006, pp. 423-437. |
Miyabe, et al., "Kernel-based Nonlinear Independent Component Analysis for Underdetermined Blind Source Separation", International Conference on Acoustics, Speech and Signal Processing, 2009, pp. 1641-1644. |
Ng, et al., "On spectral clustering: analysis and an algorithm", Advances in Neural Information Processing Systems, MIT Press, vol. 14, 2002, 8 pages. |
Ozerov, et al., "Multichannel nonnegative matrix factorization in convolutive mixtures for audio source separation", IEEE Transactions on Audio, Speech, and Language Processing, vol. 18, No. 3, 2010, pp. 550-563. |
Shalvi, et al., "System identification using nonstationary signals", IEEE Trans. Signal Processing, vol. 44, No. 8, Aug. 1996, pp. 2055-2063. |
Shi, et al., "Normalized cuts and image segmentation", IEEE Trans. Pattern Anal. Mach. Intell., vol. 22, No. 8, 2000, pp. 888-905. |
Shigeki Miyabe et al., Kernel-Based Nonlinear Independent Component Analysis for Underdetermined Blind Source Separation, Apr. 19, 2009, pp. 1641-1644. (Year: 2009). * |
Van Dongen, "Graph clustering by flow simulation", Ph.D. dissertation, University of Utrecht, 2001, 173 pages. |
Vlasblom, et al., "Markov clustering versus affinity propagation for the partitioning of protein interaction graphs", BMC Bioinformatics, vol. 10, No. 1, 2009, 14 pages. |
Von Luxburg, et al., "A tutorial on spectral clustering", Statistics and Computing, vol. 17, No. 4, 2007, pp. 395-416. |
W. Bastiaan Kleijn and Felicia Lim, Robust and Low-complexity blind source separation for meeting rooms, 2017 (Year: 2017). * |
Yilmaz, et al., "Blind separation of speech mixtures via time-frequency masking", IEEE Transactions on Signal Processing, vol. 52, No. 7, 2004, pp. 1830-1847. |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11373355B2 (en) * | 2018-08-24 | 2022-06-28 | Honda Motor Co., Ltd. | Acoustic scene reconstruction device, acoustic scene reconstruction method, and program |
Also Published As
Publication number | Publication date |
---|---|
US20180182412A1 (en) | 2018-06-28 |
CN110088835A (en) | 2019-08-02 |
WO2018125308A1 (en) | 2018-07-05 |
EP3501026A1 (en) | 2019-06-26 |
CN110088835B (en) | 2024-03-26 |
EP3501026B1 (en) | 2021-08-25 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US10770091B2 (en) | Blind source separation using similarity measure | |
EP3776535B1 (en) | Multi-microphone speech separation | |
Wang et al. | Over-determined source separation and localization using distributed microphones | |
Drude et al. | SMS-WSJ: Database, performance measures, and baseline recipe for multi-channel source separation and recognition | |
US9008329B1 (en) | Noise reduction using multi-feature cluster tracker | |
US9626970B2 (en) | Speaker identification using spatial information | |
CN106663446B (en) | User environment aware acoustic noise reduction | |
US7383178B2 (en) | System and method for speech processing using independent component analysis under stability constraints | |
Li et al. | Multiple-speaker localization based on direct-path features and likelihood maximization with spatial sparsity regularization | |
EP3289586A1 (en) | Impulsive noise suppression | |
Seki et al. | Underdetermined source separation based on generalized multichannel variational autoencoder | |
Pertilä | Online blind speech separation using multiple acoustic speaker tracking and time–frequency masking | |
Yin et al. | Multi-talker Speech Separation Based on Permutation Invariant Training and Beamforming. | |
Yamaoka et al. | CNN-based virtual microphone signal estimation for MPDR beamforming in underdetermined situations | |
US20230116052A1 (en) | Array geometry agnostic multi-channel personalized speech enhancement | |
Jahanirad et al. | Blind source computer device identification from recorded VoIP calls for forensic investigation | |
Atkins et al. | Visualization of Babble–Speech Interactions Using Andrews Curves | |
Al-Saegh | Independent component analysis for separation of speech mixtures: a comparison among thirty algorithms | |
Corey et al. | Relative transfer function estimation from speech keywords | |
Wang et al. | Low-latency real-time independent vector analysis using convolutive transfer function | |
Li et al. | Speech separation based on reliable binaural cues with two-stage neural network in noisy-reverberant environments | |
Kleijn et al. | Robust and low-complexity blind source separation for meeting rooms | |
Li et al. | A visual-pilot deep fusion for target speech separation in multitalker noisy environment | |
CN113808606B (en) | Voice signal processing method and device | |
Takada et al. | Semi-supervised enhancement and suppression of self-produced speech using correspondence between air-and body-conducted signals |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:KLEIJN, WILLEM BASTIAAN;LIM, SZE CHIE;REEL/FRAME:041127/0015Effective date: 20170120 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044567/0001Effective date: 20170929 |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: FINAL REJECTION MAILED |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: ADVISORY ACTION MAILED |
|
STCV | Information on status: appeal procedure |
Free format text: NOTICE OF APPEAL FILED |
|
STCV | Information on status: appeal procedure |
Free format text: APPEAL BRIEF (OR SUPPLEMENTAL BRIEF) ENTERED AND FORWARDED TO EXAMINER |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NOTICE OF ALLOWANCE MAILED -- APPLICATION RECEIVED IN OFFICE OF PUBLICATIONS |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 4TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1551); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 4 |