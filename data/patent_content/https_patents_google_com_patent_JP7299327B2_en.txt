JP7299327B2 - Generate video - Google Patents
Generate video Download PDFInfo
- Publication number
- JP7299327B2 JP7299327B2 JP2021544221A JP2021544221A JP7299327B2 JP 7299327 B2 JP7299327 B2 JP 7299327B2 JP 2021544221 A JP2021544221 A JP 2021544221A JP 2021544221 A JP2021544221 A JP 2021544221A JP 7299327 B2 JP7299327 B2 JP 7299327B2
- Authority
- JP
- Japan
- Prior art keywords
- video
- sub
- data
- target object
- videos
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
Images
Classifications
-
- G—PHYSICS
- G11—INFORMATION STORAGE
- G11B—INFORMATION STORAGE BASED ON RELATIVE MOVEMENT BETWEEN RECORD CARRIER AND TRANSDUCER
- G11B27/00—Editing; Indexing; Addressing; Timing or synchronising; Monitoring; Measuring tape travel
- G11B27/02—Editing, e.g. varying the order of information signals recorded on, or reproduced from, record carriers
- G11B27/031—Electronic editing of digitised analogue information signals, e.g. audio or video signals
-
- G—PHYSICS
- G11—INFORMATION STORAGE
- G11B—INFORMATION STORAGE BASED ON RELATIVE MOVEMENT BETWEEN RECORD CARRIER AND TRANSDUCER
- G11B27/00—Editing; Indexing; Addressing; Timing or synchronising; Monitoring; Measuring tape travel
- G11B27/10—Indexing; Addressing; Timing or synchronising; Measuring tape travel
- G11B27/19—Indexing; Addressing; Timing or synchronising; Measuring tape travel by using information detectable on the record carrier
- G11B27/28—Indexing; Addressing; Timing or synchronising; Measuring tape travel by using information detectable on the record carrier by using information signals recorded by the same method as the main recording
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/43—Processing of content or additional data, e.g. demultiplexing additional data from a digital video stream; Elementary client operations, e.g. monitoring of home network or synchronising decoder's clock; Client middleware
- H04N21/44—Processing of video elementary streams, e.g. splicing a video clip retrieved from local storage with an incoming video stream, rendering scenes according to MPEG-4 scene graphs
- H04N21/44016—Processing of video elementary streams, e.g. splicing a video clip retrieved from local storage with an incoming video stream, rendering scenes according to MPEG-4 scene graphs involving splicing one content stream with another content stream, e.g. for substituting a video clip
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T7/00—Image analysis
- G06T7/20—Analysis of motion
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V20/00—Scenes; Scene-specific elements
- G06V20/40—Scenes; Scene-specific elements in video content
- G06V20/41—Higher-level, semantic clustering, classification or understanding of video scenes, e.g. detection, labelling or Markovian modelling of sport events or news items
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V20/00—Scenes; Scene-specific elements
- G06V20/40—Scenes; Scene-specific elements in video content
- G06V20/49—Segmenting video sequences, i.e. computational techniques such as parsing or cutting the sequence, low-level clustering or determining units such as shots or scenes
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V20/00—Scenes; Scene-specific elements
- G06V20/50—Context or environment of the image
- G06V20/52—Surveillance or monitoring of activities, e.g. for recognising suspicious objects
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/43—Processing of content or additional data, e.g. demultiplexing additional data from a digital video stream; Elementary client operations, e.g. monitoring of home network or synchronising decoder's clock; Client middleware
- H04N21/435—Processing of additional data, e.g. decrypting of additional data, reconstructing software from modules extracted from the transport stream
- H04N21/4355—Processing of additional data, e.g. decrypting of additional data, reconstructing software from modules extracted from the transport stream involving reformatting operations of additional data, e.g. HTML pages on a television screen
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/43—Processing of content or additional data, e.g. demultiplexing additional data from a digital video stream; Elementary client operations, e.g. monitoring of home network or synchronising decoder's clock; Client middleware
- H04N21/44—Processing of video elementary streams, e.g. splicing a video clip retrieved from local storage with an incoming video stream, rendering scenes according to MPEG-4 scene graphs
- H04N21/4402—Processing of video elementary streams, e.g. splicing a video clip retrieved from local storage with an incoming video stream, rendering scenes according to MPEG-4 scene graphs involving reformatting operations of video signals for household redistribution, storage or real-time display
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/47—End-user applications
- H04N21/472—End-user interface for requesting content, additional data or services; End-user interface for interacting with content, e.g. for content reservation or setting reminders, for requesting event notification, for manipulating displayed content
- H04N21/47205—End-user interface for requesting content, additional data or services; End-user interface for interacting with content, e.g. for content reservation or setting reminders, for requesting event notification, for manipulating displayed content for manipulating displayed content, e.g. interacting with MPEG-4 objects, editing locally
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T2207/00—Indexing scheme for image analysis or image enhancement
- G06T2207/10—Image acquisition modality
- G06T2207/10016—Video; Image sequence
Description
本明細書は、ビデオの生成に関する。 This specification relates to video generation.
インターネットは、地球を横断する、ユーザ間での情報の交換を容易にする。ビデオを含む、複数の異なるプロバイダからのコンテンツが単一の電子文書の中に組み込まれて、複合文書を作成することができる。たとえば、電子文書の中に含まれるコンテンツの一部分が、電子文書の発行者によって選択(または、指定)されてよい。コンテンツ(たとえば、ビデオを含む、サードパーティのコンテンツ)の様々な部分は、サードパーティ(たとえば、電子文書の発行者でないエンティティ)によって提供され得、電子文書の中に組み込まれて、複数の異なるソースからのコンテンツを含む複合文書を形成することができる。 The Internet facilitates the exchange of information between users across the globe. Content from multiple different providers, including video, can be incorporated into a single electronic document to create a compound document. For example, a portion of the content contained within the electronic document may be selected (or designated) by the publisher of the electronic document. Various portions of the content (e.g., third-party content, including video) may be provided by third parties (e.g., entities other than the electronic document's publisher) and may be incorporated into the electronic document and distributed from multiple different sources. A compound document can be formed that includes content from .
本明細書は、各々がターゲットオブジェクトタイプのそれぞれのオブジェクトを表示する入力ビデオから複数のサブビデオを抽出するために入力ビデオを処理することができる、1つまたは複数のロケーションにおいて1つまたは複数のコンピュータ上でコンピュータプログラムとして実装されるシステムを説明する。システムは、(たとえば、所与のトピック(topic)に関係するターゲットオブジェクトタイプを含む)「トピカル(topical)」ビデオを生成するために、ターゲットオブジェクトタイプのオブジェクトを表示するサブビデオを組み合わせることができる。トピカルビデオは、たとえば、検索結果の横またはサードパーティのウェブサイト上のブロックの中でユーザデバイスにおいて電子文書と一緒に提示するために送信される、デジタルコンポーネントの中に組み込まれてよい。 This specification describes one or more sub-videos at one or more locations that can process the input video to extract multiple sub-videos from the input video, each displaying a respective object of the target object type. A system implemented as a computer program on a computer is described. The system can combine sub-videos showing objects of a target object type to generate a "topic" video (e.g., containing target object types related to a given topic). . The topical video may be incorporated into a digital component that is sent for presentation alongside the electronic document at the user device, for example, next to search results or in blocks on third-party websites.
第1の態様によれば、1つまたは複数のデータ処理装置によって実行される方法が提供され、方法は、(i)ビデオフレームのシーケンスを備える入力ビデオ、および(ii)ターゲットオブジェクトタイプを示すデータを受信することと、入力ビデオの中のターゲットオブジェクトタイプのターゲットオブジェクトの1つまたは複数のインスタンスの視覚的ロケーションを識別および追跡する追跡データを生成するために、入力ビデオを処理することと、サブビデオごとに、ターゲットオブジェクトタイプの識別されたターゲットオブジェクトの中から所与のターゲットオブジェクトのそれぞれのインスタンスを含むように、各々が入力ビデオのそれぞれのビデオフレームから抽出されるサブビデオフレームのそれぞれのシーケンスを生成することを含む、入力ビデオおよび追跡データに基づいて複数のサブビデオを生成することであって、サブビデオフレームのうちの少なくとも1つが、それぞれのビデオフレームのコンテンツを全体よりも小さく含むように、入力ビデオのそれぞれのビデオフレームからクロップ(crop)されることと、複数のサブビデオを備える出力ビデオを生成することとを備える。 According to a first aspect, there is provided a method, performed by one or more data processing devices, comprising: (i) an input video comprising a sequence of video frames; processing the input video to generate tracking data that identifies and tracks the visual location of one or more instances of a target object of the target object type in the input video; For each video, a respective sequence of sub-video frames each extracted from a respective video frame of the input video to contain a respective instance of a given target object among the identified target objects of the target object type generating a plurality of sub-videos based on the input video and the tracking data, wherein at least one of the sub-video frames contains less than the entire content of the respective video frame; 2, cropping from each video frame of the input video; and generating an output video comprising a plurality of sub-videos.
いくつかの実装形態では、追跡データを生成するために入力ビデオを処理することは、入力ビデオの中のターゲットオブジェクトタイプのターゲットオブジェクトのインスタンスごとに、入力ビデオの複数のビデオフレームの各々に対して、ビデオフレームの中のターゲットオブジェクトのインスタンスを囲むそれぞれのバウンディングボックス(bounding box)を決定することを備える。 In some implementations, processing the input video to generate tracking data includes: for each instance of a target object of the target object type in the input video, for each of a plurality of video frames of the input video , determining each bounding box surrounding an instance of the target object in the video frame.
いくつかの実装形態では、サブビデオごとに、サブビデオフレームのそれぞれのシーケンスを生成することは、サブビデオに対応する所与のターゲットオブジェクトのインスタンスを囲むそれぞれのバウンディングボックスを、入力ビデオの複数のビデオフレームの各々からクロップすることを備える。 In some implementations, generating a respective sequence of sub-video frames for each sub-video includes a respective bounding box that encloses a given target object instance corresponding to the sub-video, and a plurality of frames of the input video. A crop is provided from each of the video frames.
いくつかの実装形態では、サブビデオごとに、サブビデオフレームのそれぞれのシーケンスを生成することは、入力ビデオの複数のビデオフレームの各々の中のサブビデオに対応する所与のターゲットオブジェクトのインスタンスを囲む同じバウンディングボックスを、追跡データに基づいて決定することと、入力ビデオの複数のビデオフレームの各々から同じバウンディングボックスをクロップすることとを備える。 In some implementations, generating a respective sequence of sub-video frames for each sub-video includes instantiating a given target object corresponding to the sub-video in each of the plurality of video frames of the input video. determining a same enclosing bounding box based on the tracking data; and cropping the same bounding box from each of a plurality of video frames of the input video.
いくつかの実装形態では、第1のサブビデオのサブビデオフレームおよび第2のサブビデオのサブビデオフレームが各々、入力ビデオの同じビデオフレームからクロップされる。 In some implementations, the sub-video frame of the first sub-video and the sub-video frame of the second sub-video are each cropped from the same video frame of the input video.
いくつかの実装形態では、複数のサブビデオを備える出力ビデオを生成することは、複数のサブビデオを組み合わせるためのフォーマットを規定するビデオテンプレートの中のそれぞれのスロットに、複数のサブビデオの各サブビデオを割り当てることを備える。 In some implementations, generating an output video comprising multiple sub-videos includes placing each sub-video of the multiple sub-videos into a respective slot in a video template that defines a format for combining the multiple sub-videos. Provision for allocating videos.
いくつかの実装形態では、方法は、1つまたは複数の追加のデータ要素を受信することと、ビデオテンプレートの中のそれぞれのスロットに追加の各データ要素を割り当てることとをさらに備える。 In some implementations, the method further comprises receiving one or more additional data elements and assigning each additional data element to a respective slot in the video template.
いくつかの実装形態では、追加の各データ要素は、画像データ、テキストデータ、またはその両方を備える。 In some implementations, each additional data element comprises image data, text data, or both.
いくつかの実装形態では、出力ビデオは、複数のサブビデオのサブビデオのうちの少なくとも2つを同時に表示する。 In some implementations, the output video simultaneously displays at least two of the sub-videos of the plurality of sub-videos.
いくつかの実装形態では、方法は、デジタルコンポーネントを求める要求を受信することと、出力ビデオを含むデジタルコンポーネントが要求に応答することを決定することと、検索結果の横またはサードパーティのウェブページ上での要求の提示に応答して、出力ビデオを含むデジタルコンポーネントを提供することとをさらに備える。 In some implementations, the method comprises: receiving a request for a digital component; determining that the digital component that includes the output video is responsive to the request; providing a digital component comprising the output video in response to submitting the request at the .
いくつかの実装形態では、ターゲットオブジェクトタイプを示すデータを受信することは、キーワードを指定するデータを受信することと、キーワードからの、可能なターゲットオブジェクトタイプの既定のセットへのマッピングに従って、ターゲットオブジェクトタイプにキーワードをマッピングすることとを備える。 In some implementations, receiving data indicating a target object type includes receiving data specifying a keyword and determining the target object according to a mapping from the keyword to a predefined set of possible target object types. and mapping keywords to types.
別の態様によれば、1つまたは複数のデータ処理装置と命令を記憶する1つまたは複数の記憶デバイスとを備えるシステムが提供され、命令は、1つまたは複数のデータ処理装置によって実行されたとき、上記で説明した方法の動作を1つまたは複数のデータ処理装置に実行させる。 According to another aspect, a system is provided comprising one or more data processors and one or more storage devices for storing instructions, the instructions executed by the one or more data processors. When it causes one or more data processing devices to perform the operations of the method described above.
別の態様によれば、命令を記憶するコンピュータ可読記憶媒体が提供され、命令は、1つまたは複数のデータ処理装置によって実行されたとき、上記で説明した方法の動作を1つまたは複数のデータ処理装置に実行させる。 According to another aspect, there is provided a computer-readable storage medium storing instructions which, when executed by one or more data processors, cause the operations of the above-described method to be performed on one or more data. Let the processor do it.
本明細書で説明する主題の特定の実施形態は、以下の利点のうちの1つまたは複数を実現するように実施され得る。 Particular embodiments of the subject matter described herein can be implemented to realize one or more of the following advantages.
本明細書は、入力ビデオを処理して、各々がターゲットオブジェクトタイプのそれぞれのオブジェクトを表示する複数のサブビデオを抽出することができ、次いで、サブビデオを組み合わせてトピカルビデオを生成することができる、ビデオ生成システムを説明する。ビデオ生成システムは、たとえば、ビデオテンプレートの中にサブビデオを差し入れることによって、サブビデオを組み合わせてよく、ここで、複数のサブビデオは同時に表示されてよい。トピカルビデオは、入力ビデオよりも短い持続時間を潜在的に有し、入力ビデオよりも小さい、メモリの中の空間を占有し、かつ/または通信ネットワーク(たとえば、インターネット)を介して送信するために入力ビデオよりも小さい帯域幅を必要としながら、ターゲットオブジェクトタイプに関係する入力ビデオのコンテンツを効果的に要約し得る。たとえば、(たとえば、トピカルビデオを構成する)各サブビデオの各サブビデオフレームは、ビデオフレームのコンテンツを全体よりも小さく含むように、入力ビデオのそれぞれのビデオフレームからクロップされるので、かつ/または各サブビデオが、入力ビデオのビデオフレームのサブセットからのコンテンツを備えるので、トピカルビデオは、入力ビデオよりも小さい、メモリの中の空間を占有し得、かつ/または通信ネットワークを介して送信するために入力ビデオよりも小さい帯域幅を必要とし得る。言い換えれば、各サブビデオは、入力ビデオのコンテンツの空間的かつ/または時間的なサブセットを備える。その上、コンテンツのこのサブセットは、入力ビデオの中のターゲットオブジェクトタイプのターゲットオブジェクトの1つまたは複数のインスタンスの視覚的ロケーションを識別および追跡する、生成された追跡データに基づく。このことは、入力ビデオのターゲットにされる部分を識別および選択するために入力ビデオのコンテンツをフィルタ処理することを通じて、ビデオのより効率的な生成をもたらす。入力ビデオ全体が分散システムへ送信されるのではなく、入力ビデオのターゲットにされるサブセットを備えるトピカルビデオが生成され得、特定のシステムへ送信され得る。このことは、入力ビデオの中に含まれるコンテンツに対して要求が受信されるときに入力ビデオのコンテンツを送信するために必要とされる、帯域幅を低減することができる。したがって、ビデオ生成システムは、計算リソース、たとえば、メモリ、帯域幅、および計算能力の、より効率的な使用を可能にし得る。追加として、サブビデオを組み合わせることによってターゲットオブジェクトタイプに関係する入力ビデオのコンテンツを要約することによって、入力ビデオからのターゲットオブジェクトタイプについての情報が、より凝縮した形態で、かつユーザが入力ビデオの全体を見ることを必要とすることなく、提示され得る。このことは、ターゲットオブジェクトタイプについての情報をユーザに提示するために必要とされるネットワーク帯域幅の量を低減し、ターゲットオブジェクトタイプについての情報を提示するために必要とされる時間の量も低減する。 We can process the input video to extract multiple sub-videos, each displaying a respective object of the target object type, and then combine the sub-videos to generate the topical video. , describes a video generation system. A video generation system may combine sub-videos, for example, by inserting the sub-videos into a video template, where multiple sub-videos may be displayed simultaneously. A topical video can potentially have a shorter duration than the input video, occupy less space in memory, and/or be transmitted over a communication network (e.g., the Internet). It can effectively summarize the content of the input video related to the target object type while requiring less bandwidth than the input video. For example, each sub-video frame of each sub-video (e.g., making up the topical video) is cropped from the respective video frame of the input video to contain less than the entire content of the video frame, and/or Because each sub-video comprises content from a subset of the video frames of the input video, the topical video may occupy less space in memory than the input video and/or for transmission over a communication network. may require less bandwidth than the input video. In other words, each sub-video comprises a spatial and/or temporal subset of the content of the input video. Moreover, this subset of content is based on generated tracking data that identifies and tracks the visual location of one or more instances of target objects of the target object type in the input video. This results in more efficient generation of video through filtering the content of the input video to identify and select targeted portions of the input video. Rather than sending the entire input video to a distributed system, a topical video comprising a targeted subset of the input video can be generated and sent to a particular system. This can reduce the bandwidth required to transmit the content of the input video when a request is received for content contained within the input video. Accordingly, the video production system may enable more efficient use of computing resources, such as memory, bandwidth, and computing power. Additionally, by summarizing the content of the input video in relation to the target object type by combining sub-videos, the information about the target object type from the input video is obtained in a more condensed form and the user can view the entire input video. can be presented without needing to see the This reduces the amount of network bandwidth required to present information about the target object type to the user and also reduces the amount of time required to present information about the target object type. do.
本明細書で説明するビデオ生成システムは、たとえば、入力ビデオを提供しターゲットオブジェクトタイプを指定すること以外に手作業のユーザ入力をほとんどまたはまったく必要とせずに、視覚的に満足なトピカルビデオを(たとえば、わずか数分間で)迅速に生成することができる。対照的に、トピカルビデオを手作業で生成することは費用および時間がかかる場合があり、たとえば、数時間または数日と、著しい量の専門知識とを必要とする。したがって、本明細書で説明するビデオ生成システムは、トピカルビデオを生成するタスクを自動化することによって、時間およびリソースのより効率的な割振りを可能にする。 The video generation system described herein can, for example, produce visually pleasing topical videos ( It can be generated quickly (for example, in just a few minutes). In contrast, manually generating topical videos can be costly and time consuming, eg, requiring hours or days and a significant amount of expertise. Accordingly, the video production system described herein enables more efficient allocation of time and resources by automating the task of producing topical videos.
本明細書の主題の1つまたは複数の実施形態の詳細が、添付図面および以下の説明において説明される。本主題の他の特徴、態様、および利点は、説明、図面、および特許請求の範囲から明らかとなろう。 The details of one or more embodiments of the subject matter of this specification are set forth in the accompanying drawings and the description below. Other features, aspects, and advantages of the present subject matter will become apparent from the description, drawings, and claims.
様々な図面における同様の参照番号および名称は、同様の要素を示す。 Like reference numbers and designations in the various drawings indicate like elements.
図1は、例示的なビデオ生成システム100を示す。ビデオ生成システム100は、以下で説明するシステム、構成要素、および技法が実施される、1つまたは複数のロケーションにおいて1つまたは複数のコンピュータ上でコンピュータプログラムとして実装されるシステムの一例である。 FIG. 1 shows an exemplary video production system 100. As shown in FIG. Video production system 100 is an example of a system implemented as a computer program on one or more computers at one or more locations in which the systems, components, and techniques described below are implemented.
システム100は、トピカルビデオ106を生成するために、(i)入力ビデオ102、および(ii)「ターゲット」オブジェクトタイプ104を識別するデータを処理するように構成される。
System 100 is configured to process data identifying (i)
入力ビデオ102は、ビデオフレームのシーケンスを含んでよく、ここで、各ビデオフレームは、数値のアレイとして表されてよく、入力ビデオ102におけるそれぞれの時点に関連し得る。
ターゲットオブジェクトタイプ104は、可能なオブジェクトタイプの既定のセットからの可能なオブジェクトタイプであってよい。可能なオブジェクトタイプのセットは、任意の適切なオブジェクトタイプ、たとえば、食品タイプ(たとえば、ピザ、サンドイッチなど)、飲料タイプ(たとえば、ワイン、ビールなど)、衣料タイプ(たとえば、ドレス、ズボン、シャツ、ブラウスなど)、アクセサリタイプ(たとえば、帽子、ハンドバッグ、眼鏡など)、電子装置タイプ(たとえば、コンピュータ、スマートフォンなど)、動物タイプ(たとえば、犬、猫など)、車両タイプ(たとえば、トラック、セダン、スポーツ用多目的車(SUV)など)、健康/美容タイプ(たとえば、口紅、パレット、マニキュア液など)、スポーツ用品タイプ(たとえば、フットボール、サッカーボール、テニスラケット、水中眼鏡など)、家庭用器具タイプ(たとえば、食器洗い機、冷蔵庫など)、家具タイプ(たとえば、椅子、ソファなど)、および/または人物タイプ(たとえば、男性、女性、子供など)を含んでよい。いくつかの実装形態では、可能なオブジェクトタイプのセットは、たとえば、特定の製品、たとえば、特定のメーカーおよびモデルの車両を識別する、粒度の細かいオブジェクトタイプを含んでよい。 Target object type 104 may be a possible object type from a predefined set of possible object types. The set of possible object types is any suitable object type, e.g. food types (e.g. pizza, sandwiches, etc.), beverage types (e.g. wine, beer, etc.), clothing types (e.g. dresses, trousers, shirts, blouse, etc.), accessory type (e.g., hat, handbag, glasses, etc.), electronic device type (e.g., computer, smartphone, etc.), animal type (e.g., dog, cat, etc.), vehicle type (e.g., truck, sedan, sport utility vehicle (SUV), etc.), health/beauty type (e.g. lipstick, palette, nail polish, etc.), sporting goods type (e.g. football, soccer ball, tennis racket, swimming goggles, etc.), household appliance type (e.g. , dishwasher, refrigerator, etc.), furniture type (eg, chair, sofa, etc.), and/or person type (eg, male, female, child, etc.). In some implementations, the set of possible object types may include, for example, fine-grained object types that identify a particular product, eg, a particular make and model of vehicle.
システム100は、入力ビデオ102から抽出(たとえば、クロップ)される複数の「サブビデオ」を含むトピカルビデオ106を生成するために、入力ビデオ102およびターゲットオブジェクトタイプ104を処理し、ここで、各サブビデオは、ターゲットオブジェクトタイプ104のそれぞれのオブジェクトを表示(たとえば、描写)する。すなわち、システム100は、ターゲットオブジェクトタイプ104のオブジェクトを表示する、入力ビデオ102の部分を含む、トピカルビデオ106を生成する。
System 100
システム100は、様々な適用例のうちのいずれかのために使用され得る。たとえば、システム100は、図3および図4を参照しながらより詳細に説明するように、たとえば、検索結果の横またはサードパーティのウェブサイト上のブロックの中でユーザデバイスにおいて電子文書と一緒に提示するために送信されるデジタルコンポーネントの中に組み込まれる、トピカルビデオを生成するために使用され得る。 System 100 may be used for any of a variety of applications. For example, the system 100 may present the electronic document along with the electronic document at the user device, e.g., next to search results or in a block on a third-party website, as described in more detail with reference to FIGS. It can be used to generate a topical video that is embedded within a digital component that is sent to do so.
システム100は、追跡エンジン108、クロッピングエンジン110、および合成エンジン112を含み、その各々が次により詳細に説明される。
System 100 includes tracking engine 108, cropping
追跡エンジン108は、入力ビデオ102、およびターゲットオブジェクトタイプ104を識別するデータを処理して、入力ビデオ102の中のターゲットオブジェクトタイプ104のオブジェクトの1つまたは複数のインスタンスの視覚的ロケーションを識別し、ラベル付けし、かつ追跡する、追跡データ114を生成するように構成される。便宜上、本明細書全体にわたって、ターゲットオブジェクトタイプ104のオブジェクトは「ターゲットオブジェクト」と呼ばれることがある。
tracking engine 108 processes
追跡データ114は、1つまたは複数の「ターゲットオブジェクト軌跡」を規定するデータを含んでよく、ここで、各ターゲットオブジェクト軌跡は、ターゲットオブジェクトのそれぞれのインスタンスに対応し、複数のビデオフレームのシーケンスの中の各ビデオフレームを通じてターゲットオブジェクトの位置を追跡する。より詳細には、ターゲットオブジェクトに対応するターゲットオブジェクト軌跡は、たとえば、ビデオフレームの中のターゲットオブジェクトを囲む、各ビデオフレームに対応するそれぞれのバウンディングボックスを指定することによって、ビデオフレームのシーケンスの中の各ビデオフレームの中のターゲットオブジェクトの位置を指定し得る。ビデオフレームに対応するバウンディングボックスは、たとえば、バウンディングボックスの頂点の座標によって規定されてよく、ここで、座標は、ビデオフレームの基準のフレームの中で表現される。本明細書全体にわたって使用される、ビデオフレームの中の「バウンディングボックス」は、任意の適切な形状、たとえば、正方形形状、長方形形状、または円形形状を有する、ビデオフレームの領域を指定し得る。
ビデオフレームの中のターゲットオブジェクトの位置を指定するバウンディングボックスは、たとえば、バウンディングボックスがビデオフレームの少なくとも一部を除外するように、ビデオフレームを全体よりも小さく囲み得る(ただし、場合によっては、ビデオフレームの中のバウンディングボックスはビデオフレームの全体を囲むことがある)。その上、各ターゲットオブジェクト軌跡は、入力ビデオのビデオフレームのシーケンス全体の真部分集合である、ビデオフレームのシーケンスを通じて、対応するターゲットオブジェクトの位置を追跡し得る。 A bounding box specifying the position of the target object within the video frame may enclose less than the entire video frame, for example, such that the bounding box excludes at least a portion of the video frame (although in some cases the video A bounding box within a frame may enclose the entire video frame). Moreover, each target object trajectory may track the position of the corresponding target object through a sequence of video frames that is a proper subset of the entire sequence of video frames of the input video.
追跡エンジン108は、追跡データ114のターゲットオブジェクト軌跡を生成するために、任意の適切なオブジェクト検出および追跡技法を使用し得る。一例として、追跡エンジン108は、J.Henriques、R.Caseiro、P.Martins、J.Batista、「High-speed tracking with kernelized correlation filters」、IEEE Transactions on Pattern Analysis and Machine Intelligence、第37巻、第3号、583～596頁(2014)に記載される、オブジェクト検出および追跡技法を使用し得る。別の例として、追跡エンジン108は、N.Wojke、A.Bewley、D.Paulus、「Simple online and realtime tracking with a deep association metric」、2017 IEEE International Conference on Image Processing (ICIP)、3645～3649頁(2017)に記載される、オブジェクト検出および追跡技法を使用し得る。
Tracking engine 108 may use any suitable object detection and tracking technique to generate target object trajectories for tracking
特定の例では、追跡データ114を生成するために、追跡エンジン108は、ビデオフレームを処理してオブジェクト検出出力を生成するように構成されるオブジェクト検出ニューラルネットワークを使用して、入力ビデオ102の各ビデオフレームを処理し得る。オブジェクト検出出力は、(i)ビデオフレームの中で描写されるそれぞれのオブジェクトを各々が囲む1つまたは複数のバウンディングボックス、および(ii)バウンディングボックスごとに、バウンディングボックスによって囲まれるオブジェクトのタイプを識別するラベルを含んでよい。追跡エンジン108は、他のバウンディングボックスを廃棄しながら(たとえば、そのさらなる処理を控えながら)、ターゲットオブジェクトタイプ104のオブジェクトを囲むものとしてラベル付けされるバウンディングボックスを保持し得る。追跡エンジン108は、第1のバウンディングボックスと第2のバウンディングボックスとの間の類似性尺度がしきい値を超えることを決定することによって、第1のフレームの中の第1のバウンディングボックスおよび第2の(たとえば、後続の)フレームの中の第2のバウンディングボックスが、同じオブジェクトを囲むことを決定し得る。類似性尺度は、(i)第1のバウンディングボックスのコンテンツと第2のバウンディングボックスのコンテンツとの間の視覚的類似性、および(ii)第1のバウンディングボックスと第2のバウンディングボックスとの間のオーバーラップに基づいてよい。第1のバウンディングボックスおよび第2のバウンディングボックスが同じオブジェクトを囲むという決定に応答して、追跡エンジン108は、第1のバウンディングボックスおよび第2のバウンディングボックスが同じターゲットオブジェクト軌跡の中に含まれることを決定してよく、たとえば、それによって、第1のフレームから第2のフレームまでオブジェクトの位置を追跡する。
In the particular example, to generate tracking
クロッピングエンジン110は、1つまたは複数のサブビデオ116を生成するために、入力ビデオ102および追跡データ114を処理するように構成される。より詳細には、クロッピングエンジン110は、追跡データ114によって指定される各ターゲットオブジェクト軌跡に対応するそれぞれのサブビデオ116を生成し得る。本明細書全体にわたって使用される「サブビデオ」とは、サブビデオの各サブビデオフレームがビデオ102のそれぞれのビデオフレームからクロップされるような、「サブビデオフレーム」と呼ばれるビデオフレームのシーケンスを有するビデオを指す。ビデオ102の対応するビデオフレームからクロップされるサブビデオ116のサブビデオフレームは、たとえば、サブビデオフレームが、対応するビデオフレームの少なくとも一部分を除外するように、対応するビデオフレームを全体よりも小さく含んでよい(ただし、場合によっては、サブビデオフレームはビデオ102の対応するビデオフレームの全体を含むことがある)。特定の例では、ビデオフレームは寸法がa×bであってよく、ただし、aは、ビデオフレームの幅(たとえば、ビデオフレームの幅空間次元に沿ったピクセル数)であり、bは、ビデオフレームの高さ(たとえば、ビデオフレームの高さ空間次元に沿ったピクセル数)である。この例では、ビデオフレームからクロップされるサブビデオフレームは寸法がc×dであってよく、ただし、cはaよりも小さく、dはbよりも小さい。
本明細書全体にわたって使用される、ビデオフレーム(または、サブビデオフレーム、もしくはビデオフレームの中のバウンディングボックス)の「寸法」とは、(i)ビデオフレームの幅(たとえば、ビデオフレームの幅空間次元に沿ったピクセル数)、および(ii)ビデオフレームの高さ(たとえば、ビデオフレームの高さ空間次元に沿ったピクセル数)を指定するデータを指してよい。 As used throughout this specification, the "dimensions" of a video frame (or a sub-video frame, or a bounding box within a video frame) refer to (i) the width of the video frame (e.g., the width spatial dimension of the video frame; and (ii) data specifying the height of a video frame (eg, the number of pixels along the height spatial dimension of the video frame).
クロッピングエンジン110は、ターゲットオブジェクトのターゲットオブジェクト軌跡に対応するサブビデオ116を様々な方法で生成することができる。クロッピングエンジン110のいくつかの例示的な実装形態が、次により詳細に説明される。
一実装形態では、クロッピングエンジン110は、ビデオフレームの中のターゲットオブジェクトの位置に基づいてビデオフレームの一部分を抽出することによって、ターゲットオブジェクト軌跡に対応する各ビデオフレームからそれぞれのサブビデオフレームを抽出し得る。たとえば、ターゲットオブジェクト軌跡は、ビデオフレームの中のターゲットオブジェクトを囲む、ビデオフレームごとのそれぞれのバウンディングボックスを指定してよく、クロッピングエンジン110は、ビデオフレームに対してバウンディングボックスによって囲まれる、各ビデオフレームの部分を抽出してよい。すなわち、クロッピングエンジン110は、ビデオフレームの中のターゲットオブジェクトを囲むものとしてターゲットオブジェクト軌跡によって指定されるバウンディングボックスによって囲まれる、対応するビデオフレームの部分を抽出することによって、各サブビデオフレームを生成し得る。この例では、追跡エンジン108は、たとえば、抽出されるサブビデオフレームの各々が同じ寸法を有するような、ビデオフレームごとに固定された寸法(たとえば、幅および高さ)を有するバウンディングボックスを指定するターゲットオブジェクト軌跡を生成するように構成され得る。
In one implementation, cropping
別の実装形態では、ターゲットオブジェクト軌跡に対応するサブビデオ116を生成するために、クロッピングエンジン110は、「スーパー」バウンディングボックスの寸法(たとえば、幅および高さ)および位置(たとえば、中心)を決定し得る。詳細には、クロッピングエンジン110は、ターゲットオブジェクト軌跡に対応する各ビデオフレームの中でターゲットオブジェクトがスーパーバウンディングボックスによって囲まれるような、スーパーバウンディングボックスの寸法および位置を決定し得る。たとえば、ターゲットオブジェクト軌跡は、ビデオフレームの中のターゲットオブジェクトを囲む、ビデオフレームごとのそれぞれのバウンディングボックスを指定してよく、クロッピングエンジン110は、ターゲットオブジェクト軌跡によって指定されるバウンディングボックスの各々を囲むスーパーバウンディングボックスを識別し得る。すなわち、クロッピングエンジン110は、(依然として各ビデオフレームを全体よりも小さく囲みながら)ターゲットオブジェクト軌跡によって指定されるバウンディングボックスのセットの和集合を囲むスーパーバウンディングボックスを識別し得る。スーパーバウンディングボックスの寸法および位置を決定した後、クロッピングエンジン110は、スーパーバウンディングボックスによって囲まれる、対応するビデオフレームの部分を抽出することによって、各サブビデオフレームを生成し得る。各ビデオフレームに対して同じであるスーパーバウンディングボックスを使用してサブビデオ116を生成することは、たとえば、元のビデオ102の映画的な効果、たとえば、パンおよびズームをより良好に維持することによって、サブビデオ116の視覚的品質を改善し得る。
In another implementation, cropping
場合によっては、クロッピングエンジン110によって生成されるいくつかのサブビデオ116は、「時間的にオーバーラップしている」ことがあり、たとえば、サブビデオのうちのそのような2つ以上は、入力ビデオ102の同じビデオフレームから抽出されるそれぞれのサブビデオフレームを含む。このことは、たとえば、追跡エンジン108がビデオの中の同じビデオフレームを通じてターゲットオブジェクトの2つの異なるインスタンスを追跡するときに起こる場合がある。
In some cases, some
合成エンジン112は、トピカルビデオ106を生成するためにサブビデオ116およびビデオテンプレート118を処理するように構成される。ビデオテンプレート118は、複数のサブビデオ116を組み合わせてサブビデオの各々を含む複合ビデオ(たとえば、トピカルビデオ106)にするためのフォーマットを規定する。たとえば、ビデオテンプレートは、「スロット」と呼ばれる1つまたは複数の下位領域への(たとえば、形状が正方形または長方形の)2次元(2-D)領域の区分を規定し得る。合成エンジン112は、ビデオテンプレート118の中のそれぞれのスロットに各サブビデオ116を割り当てることによってトピカルビデオ106を生成する。ビデオテンプレート118は、トピカルビデオ106の持続時間にわたって動的に変化してよく、たとえば、トピカルビデオの持続時間にわたってスロットが除去されてよく、スロットが追加されてよく、またはスロットのサイズが変更されてよい。
例示的なビデオテンプレート200が図2を参照しながら示される。ビデオテンプレート200は、3つのスロット- すなわち、スロット202、スロット204、およびスロット206を含む。合成エンジン112は、たとえば、各スロットの中のサブビデオが同時に表示されるような、ビデオテンプレート200の各スロットにそれぞれのサブビデオ116を割り当てることによってトピカルビデオ106を生成し得る。図2を参照しながら示す例では、ターゲットオブジェクトタイプは「車両」であってよく、車両のインスタンスを表示するそれぞれのサブビデオが各スロットに割り当てられてよい。
An exemplary video template 200 is shown with reference to FIG. Video template 200 includes three slots—
別の例では、ビデオテンプレート118は、任意のサブビデオが同時に表示されるのではなく、各サブビデオ116が連続的に、たとえば、次々に表示されるように規定され得る。 In another example, video template 118 may be defined such that each sub-video 116 is displayed sequentially, eg, one after the other, rather than any of the sub-videos being displayed simultaneously.
トピカルビデオ106を生成することの一部として、合成エンジン112は、ビデオテンプレート118の中のスロットにサブビデオ116を割り当てる前に、サブビデオ116を修正し得る。たとえば、合成エンジン112は、たとえば、ビデオテンプレート118の中の対応するスロットの寸法にサブビデオの寸法を整合させるために、サブビデオのサブビデオフレームの寸法(たとえば、幅および/または高さ)を修正(たとえば、短縮)してよい。別の例として、合成エンジン112は、スロットの持続時間にサブビデオの持続時間を整合させるために、(たとえば、サブビデオの1つまたは複数のサブビデオフレームを除去することによって)サブビデオの持続時間を短縮してよい。スロットの持続時間とは、たとえば、テンプレートから除去される前にスロットがテンプレートの中に含められている時間の長さを指してよい。
As part of generating
合成エンジン112は、様々な方法のうちのいずれかで、ビデオテンプレート118のスロットへのサブビデオ116の割当てを決定し得る。一例では、合成エンジン112は、ビデオテンプレート118のそれぞれのスロットにサブビデオ116をランダムに割り当ててよい。別の例では、合成エンジン112は、たとえば、サブビデオをそれらの割り当て済みのスロットに合わせるための、サブビデオに適用される修正を最小限に抑えるために、(たとえば、すべてのスロットの中から)サブビデオ116の寸法に最も類似の寸法を有する対応するスロットに各サブビデオ116を割り当ててよい。
場合によっては、ビデオテンプレート118の中のスロットにサブビデオ116を割り当てる前に、合成エンジン112は、サブビデオごとにそれぞれのスコアを決定してよく、ここで、サブビデオに対するスコアは、サブビデオの品質を特徴づける。合成エンジン112は、1つまたは複数の基準、たとえば、サブビデオのシャープネスおよびサブビデオにおける動きの量に基づいて、サブビデオごとにスコアを決定してよい。サブビデオのシャープネスは、たとえば、サブビデオフレームをラプラシアンカーネル(Laplacian kernel)と畳み込んだ後、サブビデオフレームの中の最大ピクセル強度値を算出することによって、任意の適切なシャープネス尺度を使用して算出され得る。サブビデオにおける動きの量は、たとえば、サブビデオフレームに対応するオプティカルフローフレームのセットの平均値を算出することによって、算出され得る。合成エンジン112は、たとえば、サブビデオのシャープネスを特徴づけるシャープネススコアとサブビデオにおける動きの量を特徴づける動きスコアとの線形結合に基づいて、サブビデオに対する全体的なスコアを生成し得る。合成エンジン112は、よりシャープでありより多くの動きを含むサブビデオに対して、より高いスコアを生成してよい。
In some cases, prior to assigning
合成エンジン112は、どのサブビデオ116がトピカルビデオ106の中に含められるべきであるのかを決定するために、サブビデオ116に対するスコアを使用し得る。たとえば、合成エンジン112は、スコアが最も高いサブビデオ116の真部分集合のみが、トピカルビデオ106の中に含められるべきであることを決定し得る。別の例として、合成エンジン112は、(たとえば、しきい値を超えることによって)既定のしきい値を満たさないスコアを有する任意のサブビデオ116が、トピカルビデオ106の中に含められるべきでないことを決定し得る。
いくつかの実装形態では、システム100は、たとえば、入力ビデオ102から抽出されるサブビデオ116以外の、トピカルビデオ106の中に含められるべき1つまたは複数のデータ要素120を受信し得る。データ要素120は、たとえば、画像、またはテキストの部分を含んでよい。合成エンジン112は、ビデオテンプレート118のそれぞれのスロットにデータ要素を割り当てることによって、トピカルビデオ106の中にデータ要素120を含めてよい。
In some implementations, system 100 may receive one or more data elements 120 to be included in
ビデオ生成システム100によって生成されるトピカルビデオ106は、様々な適用例のうちのいずれかにおいて使用され得る。いくつかの例示的な適用例が、次により詳細に説明される。
The
一例では、たとえば、図3および図4を参照しながらより詳細に説明するように、ビデオ生成システム100によって生成されるトピカルビデオ106が、デジタルコンポーネント要求に応答して提供されるデジタルコンポーネントの中に含められてよい。
In one example, the
別の例では、ビデオ生成システム100は、対応するトピカルビデオ106を生成するために、(i)たとえば、1つまたは複数の監視カメラ(セキュリティカメラ)によって生成される、入力ビデオ、および(ii)ユーザによって指定されるターゲットオブジェクトタイプ104を処理し得る。監視カメラによって生成される入力ビデオは長期にわたることがあり、たとえば、数時間または数日という持続時間を有する。ビデオ生成システム100は、対象のオブジェクト、たとえば、ペット、人物、または車両をユーザに表示するトピカルビデオを生成するために、監視カメラによって生成されるビデオの迅速な処理を可能にし得る。監視カメラとは、所与の位置(たとえば、自宅の表玄関の横)に配置され、かつ所与の位置の近傍にある領域のビデオを継続的にキャプチャする、カメラを指してよい。
In another example, video generation system 100 generates corresponding
別の例では、ビデオ生成システム100は、対応するトピカルビデオ106を生成するために、(i)ユーザデバイス、たとえば、スマートフォンのビデオカメラによって生成される、入力ビデオ、および(ii)ユーザによって指定されるターゲットオブジェクトタイプ104を処理し得る。
In another example, the video generation system 100 generates the corresponding
図3は、例示的なデジタルコンポーネント生成システム300を示す。デジタルコンポーネント生成システム300は、以下で説明するシステム、構成要素、および技法が実施される、1つまたは複数のロケーションにおいて1つまたは複数のコンピュータ上でコンピュータプログラムとして実装されるシステムの一例である。 FIG. 3 shows an exemplary digital component generation system 300. As shown in FIG. Digital component generation system 300 is an example of a system implemented as a computer program on one or more computers at one or more locations in which the systems, components, and techniques described below are implemented.
デジタルコンポーネント生成システム300は、コンテンツプロバイダから1つまたは複数のキーワード302および入力ビデオ102を受信し、それぞれのキーワード302に関連するトピカルビデオ106を含む1つまたは複数のデジタルコンポーネント306を生成するように構成される。コンテンツプロバイダは、たとえば、発行者、広告主、または他のコンテンツソースであってよい。
A digital component generation system 300 receives one or
本明細書全体にわたって使用されるデジタルコンポーネントという句は、たとえば、画像、ビデオクリップ(たとえば、トピカルビデオ)、オーディオクリップ、マルチメディアクリップ、テキストセグメント、またはユニフォームリソースロケータ(URL)のうちの1つまたは複数を含むことができる、デジタルコンテンツまたはデジタル情報の個別単位を指す。デジタルコンポーネントは、単一のファイルとして、またはファイルの集合をなして、物理メモリデバイスの中に電子的に記憶することができ、デジタルコンポーネントは、ビデオファイル、オーディオファイル、マルチメディアファイル、画像ファイル、またはテキストファイルの形態をとることができ、ストリーミングビデオ、ストリーミングオーディオ、ソーシャルネットワークポスト、ブログポスト、および/または広告が、あるタイプのデジタルコンポーネントであるような、広告情報を含むことができる。デジタルコンポーネントは、1つまたは複数のソースからのデータ(たとえば、天気情報、リアルタイムのイベント情報、または他のソースから取得される他の情報)を用いて拡張され得る。 The phrase digital component as used throughout this specification refers to, for example, one of an image, video clip (e.g., topical video), audio clip, multimedia clip, text segment, or uniform resource locator (URL); Refers to a discrete unit of digital content or digital information that may contain multiples. A digital component can be stored electronically in a physical memory device, either as a single file or as a collection of files, and can be video files, audio files, multimedia files, image files, or may take the form of a text file and may contain advertising information such that streaming video, streaming audio, social network posts, blog posts, and/or advertisements are some type of digital component. A digital component may be augmented with data from one or more sources (eg, weather information, real-time event information, or other information obtained from other sources).
システム300は、キーワードマッピングエンジン308および(図1を参照しながら説明したような)ビデオ生成システム100を含む。加えて、システム300は、以下でより詳細に説明するように、コンテンツプロバイダがシステム300と相互作用することを可能にするユーザインターフェース(たとえば、グラフィカルユーザインターフェース、または任意の他の適切な種類のユーザインターフェース)に関連し得る。 System 300 includes keyword mapping engine 308 and video generation system 100 (as described with reference to FIG. 1). In addition, system 300 includes a user interface (e.g., graphical user interface, or any other suitable type of user interface) that enables content providers to interact with system 300, as described in more detail below. interface).
キーワードマッピングエンジン308は、たとえば、キーワードからの、可能なオブジェクトタイプへの既定のマッピングに従って、可能なオブジェクトタイプのセットからの対応するターゲットオブジェクトタイプ104に各キーワード302をマッピングするように構成される。たとえば、キーワードマッピングエンジン308は、キーワード「眼鏡(spectacles)」、「眼鏡(specs)」、「読書用眼鏡(reading glasses)」、「サングラス(sunglasses)」、および「眼鏡(eyeglasses)」の各々を、「眼鏡(glasses)」という可能なオブジェクトタイプにマッピングし得る。可能なオブジェクトタイプのセットとは、ビデオの中を識別および追跡するためにビデオ生成システム100の追跡エンジンがトレーニング(または、別の方法で構成)されるオブジェクトタイプのセットであってよい。いくつかの実装形態では、システム300は、キーワード302に対応するターゲットオブジェクトタイプ104の表示をコンテンツプロバイダに提供してよく、コンテンツプロバイダがターゲットオブジェクトタイプ104の各々を「承認する」(たとえば、受け付けるためのアクションを実行する)ことを要求してよい。
The keyword mapping engine 308 is configured to map each
システム300は、たとえば、ビデオ生成システム100を使用してターゲットオブジェクトタイプ104および入力ビデオ102を処理することによって、各ターゲットオブジェクトタイプ104に対応する1つまたは複数のそれぞれのトピカルビデオ106を生成するために、ビデオ生成システム100を使用し得る。ビデオ生成システム100は、たとえば、可能なビデオテンプレート310のセットからの異なるビデオテンプレートを使用してトピカルビデオ106を生成することによって、入力ビデオから抽出されるサブビデオの異なる組合せを使用してトピカルビデオ106を生成することによって、入力ビデオ102のサブビデオがビデオテンプレートの中のスロットの異なる組合せに割り当てられるトピカルビデオ106を生成することによって、または異なるオーディオサウンドトラックをトピカルビデオ106の上にオーバーレイすることによって、単一のターゲットオブジェクトタイプ104に対応する複数のトピカルビデオ106を生成し得る。システム300は、トピカルビデオ106の生成を制御する様々な要因、たとえば、トピカルビデオ106を生成するために、どのビデオテンプレート310および/またはオーディオサウンドトラックがビデオ生成システム100によって使用されるべきであるのかを、(たとえば、ユーザインターフェースを通じて)コンテンツプロバイダが指定することを可能にし得る。
The system 300 generates one or more respective
キーワード302および入力ビデオ102に加えて、コンテンツプロバイダはまた、トピカルビデオ106の中に含められるべき1つまたは複数の他のデータ要素(たとえば、画像、またはテキストの部分)をシステム300に提供し得る。ビデオ生成システム100は、たとえば、図1を参照しながら説明したように、提供されたデータ要素をトピカルビデオの中に含めてよい。
In addition to
システム300は、それぞれのデジタルコンポーネント306の中に含められるべきトピカルビデオ106のうちの1つまたは複数をコンテンツプロバイダが選択することを可能にし得る。各デジタルコンポーネント306は、コンテンツプロバイダによって提供され得るトピカルビデオ106および他のデータ要素(たとえば、ビデオ、画像、テキストの部分、URL)を含んでよい。
The system 300 may allow content providers to select one or more of the
コンテンツプロバイダは、システム300によって生成されたデジタルコンポーネント306をデジタルコンポーネント配信システム、たとえば、図4を参照しながら説明するデジタルコンポーネント配信システム410に提供し得る。デジタルコンポーネント配信システムは、たとえば、検索結果の横またはサードパーティのウェブサイト上のブロックの中でユーザデバイスにおいて電子文書とともに提示されるべきデジタルコンポーネントを求める要求に応答して、デジタルコンポーネント306を送信することができる。
A content provider may provide the digital component 306 generated by system 300 to a digital component distribution system, such as digital
システム300の有用性を示す特定の例では、コンテンツプロバイダは、ファッションショーの数時間の映像を含む入力ビデオ102、および「ハンドバッグ」というキーワード302を、システム300に提供し得る。システム300は、ハンドバッグのインスタンスを表示する入力ビデオの複数のサブビデオをその各々が含むトピカルビデオ106の対応するセットを生成するために、入力ビデオ102およびキーワード302を処理してよく、ここで、サブビデオが、自動的に編集されて視覚的に満足なビデオテンプレートになり、埋められたビデオテンプレートが入力ビデオ102の持続時間(たとえば、ファッションショーの数時間の映像)よりも短い持続時間(たとえば、30秒、1分、2分、または別の持続時間)を有するように、入力ビデオの部分を割愛する。コンテンツプロバイダは、次いで、デジタルコンポーネント配信システムに提供されるデジタルコンポーネントの中に含められるべき、トピカルビデオ106のうちの1つまたは複数を選択し得る。
In a particular example of the utility of the system 300, a content provider may provide the system 300 with an
図4は、デジタルコンポーネント配信システム410が、電子文書と一緒に提示するためにデジタルコンポーネントデータベース416からデジタルコンポーネントを送信する、例示的な環境400のブロック図である。コンテンツプロバイダは、(図3を参照しながら説明した)デジタルコンポーネント生成システム300を使用してデジタルコンポーネントを生成してよく、生成されたデジタルコンポーネントをデジタルコンポーネント配信システム410に提供してよい。
FIG. 4 is a block diagram of an exemplary environment 400 in which digital
例示的な環境400は、ローカルエリアネットワーク(LAN)、ワイドエリアネットワーク(WAN)、インターネット、またはそれらの組合せなどの、ネットワーク402を含む。ネットワーク402は、電子文書サーバ404、クライアントデバイス406、デジタルコンポーネントサーバ408、およびデジタルコンポーネント配信システム410(「配信システム」410とも呼ばれる)を接続する。例示的な環境400は、多くの異なる電子文書サーバ404、クライアントデバイス406、およびデジタルコンポーネントサーバ408を含んでよい。
Exemplary environment 400 includes a
クライアントデバイス406は、ネットワーク402を介してリソースを要求および受信することが可能な電子デバイスである。例示的なクライアントデバイス406は、パーソナルコンピュータ、モバイル通信デバイス(たとえば、モバイルフォン)、ならびにネットワーク402を介してデータを送ることおよび受信することができる他のデバイスを含む。クライアントデバイス406は、通常、ネットワーク402を介してデータを送ることおよび受信することを容易にするために、ウェブブラウザなどのユーザアプリケーションを含むが、クライアントデバイス406によって実行されるネイティブアプリケーションも、ネットワーク402を介してデータを送ることおよび受信することを容易にすることができる。
電子文書とは、クライアントデバイス406においてコンテンツのセットを提示するデータである。電子文書の例は、ウェブページ、ワードプロセシング文書、ポータブルドキュメントフォーマット(PDF)文書、画像、ビデオ、検索結果ページ、およびフィードソースを含む。モバイルコンピューティングデバイス、タブレットコンピューティングデバイス、またはデスクトップコンピューティングデバイス上にインストールされたアプリケーションなどのネイティブアプリケーション(たとえば、「アプリ(app)」)も、電子文書の例である。電子文書は、電子文書サーバ404(「電子ドキュメントサーバ(Electronic Doc Server)」)によってクライアントデバイス406に提供され得る。たとえば、電子文書サーバ404は、発行者ウェブサイトをホストするサーバを含むことができる。この例では、クライアントデバイス406は、所与の発行者ウェブページを求める要求を開始することができ、所与の発行者ウェブページをホストする電子サーバ404は、クライアントデバイス406における所与のウェブページの提示を開始する機械実行可能命令を送ることによって、要求に応答することができる。
An electronic document is data that presents a set of content on
別の例では、電子文書サーバ404は、クライアントデバイス406がそこからアプリをダウンロードできるアプリサーバを含むことができる。この例では、クライアントデバイス406は、クライアントデバイス406においてアプリをインストールするために必要とされるファイルをダウンロードすることができ、次いで、ダウンロードされたアプリを局所的に実行することができる。
In another example,
電子文書は、様々なコンテンツを含むことができる。たとえば、電子文書は、電子文書自体内にあり、かつ/または経時的に変化しない、静的コンテンツ(たとえば、テキストまたは他の指定されたコンテンツ)を含むことができる。電子文書はまた、経時的にまたは要求ごとに変化することがある動的コンテンツを含むことができる。たとえば、所与の電子文書の発行者は、電子文書の部分を埋めるために使用されるデータソースを保持することができる。この例では、所与の電子文書は、所与の電子文書がクライアントデバイス406によって処理(たとえば、レンダリングまたは実行)されると、クライアントデバイス406に、データソースにコンテンツを要求するようにさせる、1つまたは複数のタグまたはスクリプトを含むことができる。クライアントデバイス406は、データソースから取得されたコンテンツを所与の電子文書の中に組み込んで、データソースから取得されたコンテンツを含む複合電子文書を作成する。
Electronic documents can contain a variety of content. For example, an electronic document can contain static content (eg, text or other specified content) that is within the electronic document itself and/or does not change over time. Electronic documents may also contain dynamic content that may change over time or from request to request. For example, the publisher of a given electronic document may maintain data sources used to populate portions of the electronic document. In this example, a given electronic document causes
いくつかの状況では、所与の電子文書は、デジタルコンポーネント配信システム410を参照する、1つまたは複数のデジタルコンポーネントタグまたはデジタルコンポーネントスクリプトを含むことができる。これらの状況では、デジタルコンポーネントタグまたはデジタルコンポーネントスクリプトは、所与の電子文書がクライアントデバイス406によって処理されるとき、クライアントデバイス406によって実行される。デジタルコンポーネントタグまたはデジタルコンポーネントスクリプトの実行は、1つまたは複数のデジタルコンポーネントを求める要求412(「コンポーネント要求」と呼ぶ)を生成するようにクライアントデバイス406を構成し、そうした要求は、ネットワーク402を介してデジタルコンポーネント配信システム410へ送信される。たとえば、デジタルコンポーネントタグまたはデジタルコンポーネントスクリプトは、ヘッダおよびペイロードデータを含むパケット化されたデータ要求をクライアントデバイス406が生成することを可能にすることができる。コンポーネント要求412は、デジタルコンポーネントを要求されているサーバの名称(または、ネットワークロケーション)、要求しているデバイス(たとえば、クライアントデバイス406)の名称(または、ネットワークロケーション)、および/または要求に応答して提供される1つもしくは複数のデジタルコンポーネントを選択するためにデジタルコンポーネント配信システム410が使用できる情報などの、機能を指定するイベントデータを含むことができる。コンポーネント要求412は、クライアントデバイス406によってネットワーク402(たとえば、電気通信ネットワーク)を介してデジタルコンポーネント配信システム410のサーバへ送信される。
In some situations, a given electronic document may include one or more digital component tags or digital component scripts that reference the digital
コンポーネント要求412は、電子文書が要求されること、およびデジタルコンポーネントが提示され得る電子文書のロケーションの特性などの、他のイベント機能を指定するイベントデータを含むことができる。たとえば、デジタルコンポーネントがその中に提示される電子文書(たとえば、ウェブページ)への参照(たとえば、URL)、デジタルコンポーネントを提示するために利用可能な電子文書の利用可能なロケーション、利用可能なロケーションのサイズ、および/またはそのロケーションにおいて提示するのに適格なメディアタイプを指定する、イベントデータが、デジタルコンポーネント配信システム410に提供され得る。同様に、電子文書に関連するキーワード(「文書キーワード」)、または電子文書によって参照されるエンティティ(たとえば、人間、場所、または物)を指定する、イベントデータも、電子文書とともに提示するのに適格なデジタルコンポーネントの識別を容易にするために、(たとえば、ペイロードデータとして)コンポーネント要求412の中に含めることができ、デジタルコンポーネント配信システム410に提供され得る。イベントデータはまた、検索結果ページ、ならびに/あるいは検索結果および/または検索結果の中に含まれるテキストコンテンツ、音響コンテンツ、もしくは他の視覚コンテンツを指定するデータを取得するために、クライアントデバイス406からサブミットされた、検索クエリを含むことができる。
コンポーネント要求412はまた、クライアントデバイスのユーザが提供している情報、コンポーネント要求がそこからサブミットされた州もしくは地域を示す地理情報、またはデジタルコンポーネントが表示される環境(たとえば、コンポーネント要求の時刻、コンポーネント要求の曜日、モバイルデバイスまたはタブレットデバイスなどのデジタルコンポーネントが表示されるデバイスのタイプ)に対するコンテキストを提供する他の情報などの、他の情報に関係するイベントデータを含むことができる。コンポーネント要求412は、たとえば、パケット化ネットワークを介して送信することができ、コンポーネント要求412自体は、ヘッダおよびペイロードデータを有するパケット化されたデータとしてフォーマットされ得る。ヘッダは、パケットの宛先を指定することができ、ペイロードデータは、上記で説明した情報のうちのいずれかを含むことができる。
The
コンポーネント配信システム410は、コンポーネント要求412の受信に応答して、かつ/またはコンポーネント要求412の中に含まれる情報を使用して、所与の電子文書とともに提示されるデジタルコンポーネントを選ぶ。いくつかの実装形態では、デジタルコンポーネントは、デジタルコンポーネントの遅延した選択によって引き起こされることがあるエラーを回避するために、1秒未満のうちに(本明細書で説明する技法を使用して)選択される。たとえば、コンポーネント要求412に応答してデジタルコンポーネントを提供する際の遅延は、クライアントデバイス406においてページロードエラーをもたらすことがあり、または電子文書の他の部分がクライアントデバイス406において提示された後でも電子文書の部分を埋められないままにさせることがある。また、デジタルコンポーネントをクライアントデバイス406に提供する際の遅延が大きくなるにつれて、デジタルコンポーネントがクライアントデバイス406に送付されるとき、電子文書がもはやクライアントデバイス406において提示されない可能性が高く、それによって、電子文書とのユーザの体験に悪影響を及ぼす。さらに、デジタルコンポーネントを提供する際の遅延は、たとえば、デジタルコンポーネントが提供されるときに電子文書がもはやクライアントデバイス406において提示されない場合、デジタルコンポーネントの送付の失敗という結果になることがある。
In response to receiving
いくつかの実装形態では、デジタルコンポーネント配信システム410は、たとえば、相互接続されているサーバおよび複数のコンピューティングデバイスのセット414を含む分散コンピューティングシステムの中に実装され、要求412に応答してデジタルコンポーネントを識別および配信する。複数のコンピューティングデバイスのセット414は、数百万個の利用可能なデジタルコンポーネント(DC1-x)のコーパスから、電子文書の中で提示されるのに適格なデジタルコンポーネントのセットを識別するように一緒に動作する。数百万個の利用可能なデジタルコンポーネントは、たとえば、デジタルコンポーネントデータベース416の中で、インデックスが付けられ得る。各デジタルコンポーネントインデックスエントリは、対応するデジタルコンポーネントを参照することができ、かつ/または対応するデジタルコンポーネントの配信/送信に寄与する(たとえば、それを調整または限定する)配信パラメータ(DP1～DPx)を含むことができる。たとえば、配信パラメータは、デジタルコンポーネントの配信パラメータのうちの1つに(たとえば、厳密に、またはいくつかの事前指定されたレベルの類似度を伴ってのいずれかで)整合する、少なくとも1つの基準をコンポーネント要求が含むことを要求することによって、デジタルコンポーネントの送信に寄与することができる。
In some implementations, the digital
いくつかの実装形態では、特定のデジタルコンポーネント用の配信パラメータは、デジタルコンポーネントが提示するのに適格であるように、(たとえば、電子文書、文書キーワード、またはコンポーネント要求412の中で指定された用語によって)整合されなければならない配信キーワードを含むことができる。言い換えれば、配信パラメータは、ネットワーク402を介したデジタルコンポーネントの配信(たとえば、送信)をトリガするために使用される。配信パラメータはまた、デジタルコンポーネントが提示するのに適格であるように、特定の地理的領域(たとえば、国または州)を指定する情報、および/またはコンポーネント要求412が特定のタイプのクライアントデバイス(たとえば、モバイルデバイスまたはタブレットデバイス)において生じたことを指定する情報を、コンポーネント要求412が含むことを要求することができる。
In some implementations, the delivery parameters for a particular digital component are such that the digital component is eligible to present (e.g., an electronic document, a document keyword, or a term specified in the component request 412 (by) can contain delivery keywords that must be matched. In other words, the distribution parameters are used to trigger distribution (eg, transmission) of digital components over
配信パラメータはまた、たとえば、コンポーネント評価プロセスによって、配信/送信にとってのデジタルコンポーネントの適格性を(たとえば、他の利用可能なデジタルコンポーネントの間で)評価するために使用される、適格性値(たとえば、ランク付けスコア、つけ値、またはいくつかの他の指定された値)を指定することができる。いくつかの状況では、適格性値は、(たとえば、デジタルコンポーネントとのユーザ対話などの、デジタルコンポーネントの提示に帰属する特定のイベントのインスタンスごとに)デジタルコンポーネントのプロバイダがデジタルコンポーネントの送信に応答してサブミットする意思がある最高の代償額を指定することができる。 Distribution parameters also include eligibility values (e.g., , ranking score, bid, or some other specified value) can be specified. In some circumstances, the eligibility value is the response of the provider of the digital component to the submission of the digital component (e.g., for each instance of a particular event attributed to the presentation of the digital component, such as user interaction with the digital component). You can specify the highest compensation amount you are willing to submit.
適格なデジタルコンポーネントの識別は、次いで複数のコンピューティングデバイスのセット414内のコンピューティングデバイスの間で割り当てられる、複数のタスク417a～417cにセグメント化され得る。たとえば、セット414の中の異なるコンピューティングデバイスは各々、デジタルコンポーネントデータベース416の異なる部分を分析して、コンポーネント要求412の中に含まれる情報に整合する配信パラメータを有する様々なデジタルコンポーネントを識別することができる。いくつかの実装形態では、セット414の中の所与の各コンピューティングデバイスは、様々なデータディメンション(または、ディメンションのセット)を分析することができ、分析の結果(Res1～Res3)418a～418cをデジタルコンポーネント配信システム410に戻して渡すこと(たとえば、送信すること)ができる。たとえば、セット414の中のコンピューティングデバイスの各々によって提供される結果418a～418cは、コンポーネント要求に応答して配信するのに適格なデジタルコンポーネントのサブセット、および/またはいくつかの配信パラメータを有するデジタルコンポーネントのサブセットを識別し得る。デジタルコンポーネントのサブセットの識別は、たとえば、イベントデータを配信パラメータと比較すること、およびイベントデータの少なくともいくつかの特徴に整合する配信パラメータを有するデジタルコンポーネントのサブセットを識別することを含むことができる。
The identification of eligible digital components may then be segmented into
デジタルコンポーネント配信システム410は、複数のコンピューティングデバイスのセット414から受信された結果418a～418cを集約し、集約された結果に関連する情報を使用して、(i)要求412に応答して提供される1つまたは複数のデジタルコンポーネントを選択し、(ii)1つまたは複数のデジタルコンポーネントにとっての送信要件を決定する。たとえば、デジタルコンポーネント配信システム410は、1つまたは複数のコンポーネント評価プロセスの成果に基づいて、勝者のデジタルコンポーネントのセット(1つまたは複数のデジタルコンポーネント)を選択することができる。そして次に、デジタルコンポーネント配信システム410は、クライアントデバイス406が勝者のデジタルコンポーネントのセットを所与の電子文書の中に組み込むことを可能にする返答データ420(たとえば、返答を表すデジタルデータ)を生成すること、およびネットワーク402を介してそれを送信することができ、その結果、勝者のデジタルコンポーネントのセットおよび電子文書のコンテンツが、クライアントデバイス406のディスプレイにおいて一緒に提示される。
The digital
いくつかの実装形態では、クライアントデバイス406は、返答データ420の中に含まれる命令を実行し、命令は、1つまたは複数のデジタルコンポーネントサーバから勝者のデジタルコンポーネントのセットを取得するようにクライアントデバイス406を構成し、かつクライアントデバイス406がそれを取得することを可能にする。たとえば、返答データ420の中の命令は、デジタルコンポーネントサーバ408から所与の勝者のデジタルコンポーネントを取得するために、ネットワークロケーション(たとえば、ユニフォームリソースロケータ(URL))、およびクライアントデバイス406にサーバ要求(SR:server request)421をデジタルコンポーネントサーバ408へ送信させるスクリプトを含むことができる。要求に応答して、デジタルコンポーネントサーバ408は、サーバ要求421の中で指定された(たとえば、複数のデジタルコンポーネントを記憶するデータベース内の)所与の勝者のデジタルコンポーネントを識別し、クライアントデバイス406において電子文書の中で所与の勝者のデジタルコンポーネントを提示するデジタルコンポーネントデータ(DCデータ)422を、クライアントデバイス406へ送信する。
In some implementations, the
電子文書の検索を容易にするために、環境400は、電子文書をクロール(crawl)するとともに電子文書にインデックスを付ける(たとえば、電子文書のクロールされたコンテンツに基づいてインデックスが付けられる)ことによって電子文書を識別する検索システム450を含むことができる。電子文書についてのデータは、データが関連する電子文書に基づいてインデックスが付けられ得る。電子文書のインデックス付きの随意にキャッシュされたコピーが、検索インデックス452(たとえば、ハードウェアメモリデバイス)の中に記憶される。電子文書に関連するデータは、電子文書の中に含まれるコンテンツを表すデータ、および/または電子文書用のメタデータである。
To facilitate searching of electronic documents, the environment 400 crawls the electronic documents and indexes the electronic documents (eg, indexed based on crawled content of the electronic documents). A
クライアントデバイス406は、ネットワーク402を介して検索クエリを検索システム450にサブミットすることができる。それに応答して、検索システム450は、検索インデックス452にアクセスして、検索クエリに関連する電子文書を識別する。検索システム450は、検索結果の形態での電子文書を識別し、検索結果ページの中でクライアントデバイス406に検索結果を戻す。検索結果は、特定の検索クエリに応答する(たとえば、関連する)電子文書を識別する、検索システム450によって生成されるデータであり、検索結果とのユーザ対話に応答して、クライアントデバイスに、指定されたネットワークロケーション(たとえば、URL)にデータを要求するようにさせる、アクティブリンク(たとえば、ハイパーテキストリンク)を含む。例示的な検索結果は、ウェブページタイトル、ウェブページから抽出されたテキストの断片または画像の一部分、およびウェブページのURLを含むことができる。別の例示的な検索結果は、ダウンロード可能なアプリケーションのタイトル、ダウンロード可能なアプリケーションを記述するテキストの断片、ダウンロード可能なアプリケーションのユーザインターフェースを描写する画像、および/またはアプリケーションがそこからクライアントデバイス406にダウンロードされ得るロケーションへのURLを含むことができる。いくつかの状況では、サブミットされた検索クエリに関連するダウンロード可能なアプリケーションについての情報を提示するために、検索システム450は、クライアントデバイス406においてインストールするためにアプリケーションがそこからダウンロードされ得るアプリケーションストア(または、オンラインポータル)の一部であり得るか、またはそれと対話し得る。他の電子文書と同様に、検索結果ページは、デジタルコンポーネント(たとえば、広告、ビデオクリップ、オーディオクリップ、画像、または他のデジタルコンポーネント)がその中に提示され得る1つまたは複数のスロットを含むことができる。
コンポーネント要求に応答して送信されるべきデジタルコンポーネントを選択するために、配信システム410は、コンポーネント要求に応答して送信されるのに適格なデジタルコンポーネントのセットを識別し得る。配信システム410は、次いで、たとえば、オークション手順を通じて送信されるべき、適格なデジタルコンポーネントのうちの1つまたは複数を選択し得る。いくつかの実装形態では、配信システム410は、それらのそれぞれの適格性値に従って、適格なデジタルコンポーネントをランク付けすること、およびコンポーネント要求に応答して送信されるべき、最も高くランク付けされた1つまたは複数のデジタルコンポーネントを選択することによって、オークション手順を実行する。
To select digital components to be transmitted in response to a component request,
図5は、トピカルビデオを生成するための例示的なプロセス500のフロー図である。便宜上、プロセス500は、1つまたは複数のロケーションに位置する1つまたは複数のコンピュータのシステムによって実行されるものとして説明される。たとえば、ビデオ生成システム、たとえば、本明細書に従って適切にプログラムされた、図1のビデオ生成システム100は、プロセス500を実行することができる。 FIG. 5 is a flow diagram of an exemplary process 500 for generating topical videos. For convenience, process 500 is described as being performed by a system of one or more computers located at one or more locations. For example, a video production system, such as video production system 100 of FIG. 1, suitably programmed according to this specification, can perform process 500.
システムは、(i)ビデオフレームのシーケンスを含む入力ビデオ、および(ii)ターゲットオブジェクトタイプを示すデータを受信する(502)。たとえば、システムは、キーワード(たとえば、「サングラス」)を指定するデータを受信してよく、次いで、キーワードからの、可能なターゲットオブジェクトタイプの既定のセットへのマッピングに従って、対応するターゲットオブジェクトタイプ(たとえば、「眼鏡」)に、受信されたキーワードをマッピングし得る。随意に、システムはまた、1つまたは複数の追加のデータ要素、たとえば、画像、テキストの部分、またはその両方を受信してよい。 The system receives (i) an input video comprising a sequence of video frames and (ii) data indicating a target object type (502). For example, the system may receive data specifying a keyword (eg, "sunglasses"), and then follow a mapping from the keyword to a predefined set of possible target object types to correspond to the target object type (eg, , “glasses”). Optionally, the system may also receive one or more additional data elements, such as images, portions of text, or both.
システムは、入力ビデオの中のターゲットオブジェクトタイプのターゲットオブジェクトの1つまたは複数のインスタンスの視覚的ロケーションを識別および追跡する追跡データを生成するために、入力ビデオを処理する(504)。たとえば、入力ビデオの中のターゲットオブジェクトタイプのターゲットオブジェクトのインスタンスごとに、システムは、入力ビデオの複数のビデオフレームの各々の中のターゲットオブジェクトのインスタンスを囲むそれぞれのバウンディングボックスを決定し得る。システムは、たとえば、図1を参照しながら説明したように、追跡データを生成するために、任意の適切なオブジェクト検出および追跡技法を使用し得る。 The system processes the input video to generate tracking data that identifies and tracks the visual location of one or more instances of target objects of the target object type in the input video (504). For example, for each instance of a target object of target object type in the input video, the system may determine a respective bounding box surrounding the instance of the target object in each of multiple video frames of the input video. The system may use any suitable object detection and tracking technique to generate tracking data, eg, as described with reference to FIG.
システムは、入力ビデオおよび追跡データに基づいて複数のサブビデオを生成する(506)。サブビデオごとに、システムは、(i)それぞれのビデオフレームのコンテンツを全体よりも小さく、かつ(ii)ターゲットオブジェクトタイプの識別されたターゲットオブジェクトの中から所与のターゲットオブジェクトのそれぞれのインスタンスを含むように、各々が入力ビデオのそれぞれのビデオフレームからクロップされるサブビデオフレームのそれぞれのシーケンスを生成し得る。いくつかの実装形態では、サブビデオフレームの各々が、それぞれのビデオフレームのコンテンツを全体よりも小さく含むようにクロップされるのではなく、サブビデオフレームのうちの少なくとも1つが、少なくとも1つのそれぞれのビデオフレームのコンテンツを全体よりも小さく含むように、入力ビデオの少なくとも1つのそれぞれのビデオフレームからクロップされる。そのような実装形態では、たとえば、ターゲットオブジェクトが、それらのそれぞれのビデオフレームの中の、それぞれのビデオフレームのすべてまたはそれぞれのビデオフレームの大部分を占有するので、サブビデオフレームのうちの1つまたは複数は、それぞれのビデオフレームの全体のコンテンツを備えてよい。サブビデオフレームは、それぞれのビデオフレームの全体のコンテンツのサブセットを備えてよく、サブセットは、それぞれのビデオフレームの全体のコンテンツよりも小さいかまたはそれに等しい。いくつかの実装形態では、システムは、所与のターゲットオブジェクトのインスタンスを囲むそれぞれのバウンディングボックスを、入力ビデオの複数のビデオフレームの各々からクロップすることによって、所与のターゲットオブジェクトのインスタンスに対応するサブビデオのサブビデオフレームのシーケンスを生成し得る。所与のターゲットオブジェクトのインスタンスを囲むバウンディングボックスは、追跡データによって指定され得る。いくつかの実装形態では、所与のターゲットオブジェクトのインスタンスに対応するサブビデオのサブビデオフレームのシーケンスを生成するために、システムは、入力ビデオの複数のビデオフレームの各々の中の所与のターゲットオブジェクトのインスタンスを囲む同じバウンディングボックスを、追跡データに基づいて決定し得る。システムは、次いで、入力ビデオの複数のビデオフレームの各々から同じバウンディングボックスをクロップすることによって、サブビデオのサブビデオフレームのシーケンスを生成し得る。 The system generates (506) multiple sub-videos based on the input video and tracking data. For each sub-video, the system includes (i) less than the entire content of each video frame, and (ii) each instance of a given target object among the identified target objects of the target object type. As such, a respective sequence of sub-video frames may be generated, each cropped from a respective video frame of the input video. In some implementations, rather than each of the sub-video frames being cropped to contain less than the entire content of the respective video frame, at least one of the sub-video frames has at least one respective At least one respective video frame of the input video is cropped to contain less than the content of the video frame. In such implementations, for example, the target objects occupy all of the respective video frames or most of the respective video frames in their respective video frames, so that one of the sub-video frames Or multiple may comprise the entire content of each video frame. A sub-video frame may comprise a subset of the total content of the respective video frame, the subset being less than or equal to the total content of the respective video frame. In some implementations, the system responds to a given target object instance by cropping respective bounding boxes surrounding the given target object instance from each of multiple video frames of the input video. A sequence of sub-video frames of the sub-video may be generated. A bounding box surrounding a given target object instance may be specified by the tracking data. In some implementations, to generate a sequence of sub-video frames of sub-videos corresponding to instances of a given target object, the system processes the given target in each of the multiple video frames of the input video. The same bounding box surrounding an instance of an object can be determined based on tracking data. The system may then generate a sequence of sub-video frames of the sub-video by cropping the same bounding box from each of multiple video frames of the input video.
場合によっては、いくつかのサブビデオが「時間的にオーバーラップしている」ことがあり、たとえば、サブビデオのうちのそのような2つ以上は、入力ビデオの同じビデオフレームから抽出されるそれぞれのサブビデオフレームを含む。このことは、たとえば、システムが入力ビデオの中の同じビデオフレームを通じてターゲットオブジェクトの2つの異なるインスタンスを追跡するときに起こる場合がある。 In some cases, some sub-videos may be "overlapping in time", e.g. two or more such sub-videos are each extracted from the same video frame of the input video. sub-video frames. This may occur, for example, when the system tracks two different instances of the target object through the same video frame in the input video.
システムは、サブビデオを含む出力ビデオを生成する(508)。たとえば、出力ビデオを生成するために、システムは、サブビデオを組み合わせるためのフォーマットを規定するビデオテンプレートの中のそれぞれのスロットに各サブビデオを割り当ててよい。出力ビデオを生成することの一部として、システムは、サブビデオごとにそれぞれのスコアを(たとえば、サブビデオのシャープネスに基づいて)決定してよく、出力ビデオの中に含めるためのサブビデオの真部分集合(たとえば、最高のスコアを有する、既定の個数のサブビデオ)を選択してよい。場合によっては、出力ビデオは、サブビデオのうちの少なくとも2つを同時に表示してよく、他の場合には、出力ビデオは、サブビデオの各々を連続的に、たとえば、次々に表示してよい。出力ビデオを生成することの一部として、システムは、ビデオテンプレートの中のそれぞれのスロットに、1つまたは複数の追加のデータ要素(たとえば、502を参照しながら説明したような、テキストデータ要素または画像データ要素)の各々を割り当ててよい。 The system generates (508) an output video that includes sub-videos. For example, to generate the output video, the system may assign each sub-video to a respective slot in a video template that defines the format for combining the sub-videos. As part of generating the output video, the system may determine for each sub-video a respective score (e.g., based on the sub-video's sharpness) and determine the accuracy of the sub-videos for inclusion in the output video. A subset (eg, a predetermined number of sub-videos with the highest scores) may be selected. In some cases, the output video may display at least two of the sub-videos simultaneously, in other cases the output video may display each of the sub-videos sequentially, e.g., one after the other. . As part of generating the output video, the system inserts one or more additional data elements (e.g., text data elements or image data elements) may be assigned.
システムによって生成された出力ビデオは、デジタルコンポーネント要求に応答して提供され、かつその次に検索結果の横またはサードパーティのウェブページ上で提示される、デジタルコンポーネントの中に含められてよい。 Output video generated by the system may be included in digital components that are provided in response to digital component requests and then presented alongside search results or on third-party web pages.
本明細書は、システムおよびコンピュータプログラム構成要素に関して「構成される」という用語を使用する。1つまたは複数のコンピュータのシステムの場合、特定の動作またはアクションを実行するように構成されることは、動作においてシステムに動作またはアクションを実行させる、ソフトウェア、ファームウェア、ハードウェア、またはそれらの組合せが、システムにインストールされていることを意味する。1つまたは複数のコンピュータプログラムの場合、特定の動作またはアクションを実行するように構成されることは、1つまたは複数のプログラムが、データ処理装置によって実行されたとき、装置に動作またはアクションを実行させる命令を含むことを意味する。 This specification uses the term "configured" with respect to system and computer program components. In the case of a system of one or more computers, being configured to perform a particular operation or action means that the software, firmware, hardware, or combination thereof in operation causes the system to perform the operation or action. , which means it is installed on your system. In the case of one or more computer programs, being configured to perform a particular operation or action means that the one or more programs, when executed by a data processing apparatus, cause the apparatus to perform the operation or action. is meant to contain an instruction to
本明細書で説明した主題および機能的動作の実施形態は、デジタル電子回路構成において、有形に具現されたコンピュータソフトウェアまたはファームウェアにおいて、本明細書で開示する構造およびそれらの構造的均等物を含むコンピュータハードウェアにおいて、あるいはそれらのうちの1つまたは複数の組合せにおいて実施され得る。本明細書で説明した主題の実施形態は、1つまたは複数のコンピュータプログラム、たとえば、データ処理装置による実行のための、またはデータ処理装置の動作を制御するための、有形非一時的記憶媒体上で符号化されたコンピュータプログラム命令の1つまたは複数のモジュールとして実施され得る。コンピュータ記憶媒体は、機械可読記憶デバイス、機械可読記憶基板、ランダムアクセスメモリデバイスもしくはシリアルアクセスメモリデバイス、またはそれらのうちの1つまたは複数の組合せであり得る。代替的にまたは追加として、プログラム命令は、データ処理装置による実行のための好適な受信機装置への送信用に情報を符号化するために生成される、人工的に生成された伝搬信号、たとえば、機械生成された電気信号、光信号、または電磁信号において符号化され得る。 The subject matter and functional operational embodiments described herein may be tangibly embodied in digital electronic circuitry, in computer software or firmware, or in a computer including the structures disclosed herein and their structural equivalents. It may be implemented in hardware, or in any combination of one or more thereof. Embodiments of the subject matter described herein include one or more computer programs, e.g., stored on tangible, non-transitory storage media, for execution by or for controlling operation of a data processing apparatus. may be implemented as one or more modules of computer program instructions encoded in A computer storage medium may be a machine-readable storage device, a machine-readable storage substrate, a random-access memory device or a serial-access memory device, or a combination of one or more thereof. Alternatively or additionally, the program instructions may be implemented in an artificially generated propagated signal, e.g. , may be encoded in a machine-generated electrical, optical, or electromagnetic signal.
「データ処理装置」という用語はデータ処理ハードウェアを指し、例として、プログラマブルプロセッサ、コンピュータ、または複数のプロセッサもしくはコンピュータを含む、データを処理するためのすべての種類の装置、デバイス、および機械を包含する。装置はまた、専用論理回路構成、たとえば、FPGA(フィールドプログラマブルゲートアレイ)またはASIC(特定用途向け集積回路)であり得るか、またはそれをさらに含むことができる。装置は、ハードウェアに加えて、コンピュータプログラム用の実行環境を作成するコード、たとえば、プロセッサファームウェア、プロトコルスタック、データベース管理システム、オペレーティングシステム、またはそれらのうちの1つまたは複数の組合せを構成するコードを随意に含むことができる。 The term "data processing apparatus" refers to data processing hardware and includes, by way of example, all types of apparatus, devices and machines for processing data, including programmable processors, computers, or multiple processors or computers. do. The device may also be or may further include dedicated logic circuitry, such as FPGAs (Field Programmable Gate Arrays) or ASICs (Application Specific Integrated Circuits). The apparatus includes, in addition to hardware, code that creates an execution environment for computer programs, e.g. code that makes up processor firmware, protocol stacks, database management systems, operating systems, or combinations of one or more can optionally be included.
プログラム、ソフトウェア、ソフトウェアアプリケーション、アプリ、モジュール、ソフトウェアモジュール、スクリプト、またはコードと呼ばれることもあり、またはそのように説明されることもある、コンピュータプログラムは、コンパイル型言語もしくはインタープリタ型言語、または宣言型言語もしくは手続き型言語を含む、任意の形式のプログラミング言語で書くことができ、スタンドアロンプログラムとして、またはモジュールとして、コンピューティング環境において使用するのに適したコンポーネント、サブルーチン、または他のユニットを含む、任意の形態で展開され得る。プログラムは、ファイルシステムの中のファイルに対応してよいが、そのことは必須ではない。プログラムは、他のプログラムまたはデータ、たとえば、マークアップ言語文書の中、当該のプログラムに専用の単一のファイルの中、あるいは複数の協調ファイル、たとえば、1つまたは複数のモジュール、サブプログラム、またはコードの部分を記憶するファイルの中に記憶された、1つまたは複数のスクリプトを保持するファイルの一部分の中に、記憶され得る。コンピュータプログラムは、1つのサイトに位置するか、または複数のサイトにわたって分散されデータ通信ネットワークによって相互接続される、1つのコンピュータ上または複数のコンピュータ上で実行されるように展開され得る。 A computer program, sometimes called or described as a program, software, software application, app, module, software module, script, or code, may be written in a compiled or interpreted language, or in a declarative Any form of programming language, including any language or procedural language, containing components, subroutines, or other units suitable for use in a computing environment, either as a stand-alone program or as a module can be deployed in the form of A program may correspond to a file in a file system, but that is not required. A program may contain other programs or data, e.g., in markup language documents, in a single file dedicated to that program, or in multiple collaborative files, e.g., in one or more modules, subprograms, or It may be stored in a portion of a file holding one or more scripts stored in a file storing portions of code. A computer program can be deployed to be executed on one computer or on multiple computers located at one site or distributed across multiple sites and interconnected by a data communication network.
本明細書では、「エンジン」という用語は、ソフトウェアベースのシステム、サブシステム、または1つもしくは複数の特定の機能を実行するようにプログラムされるプロセスを指すために広く使用される。概して、エンジンは、1つまたは複数のロケーションにおける1つまたは複数のコンピュータ上にインストールされた、1つまたは複数のソフトウェアモジュールまたは構成要素として実装される。いくつかの場合には、1つまたは複数のコンピュータは特定のエンジンに専用であり、他の場合には、複数のエンジンが1つまたは複数の同じコンピュータにおいてインストールされ得るとともに実行中であり得る。 The term "engine" is used broadly herein to refer to a software-based system, subsystem, or process programmed to perform one or more specific functions. Generally, the engine is implemented as one or more software modules or components installed on one or more computers in one or more locations. In some cases, one or more computers are dedicated to a particular engine, and in other cases, multiple engines may be installed and running on the same computer or computers.
本明細書で説明したプロセスおよび論理フローは、入力データに対して動作するとともに出力を生成することによって機能を実行するために、1つまたは複数のプログラマブルコンピュータが1つまたは複数のコンピュータプログラムを実行することによって実行され得る。プロセスおよび論理フローはまた、専用論理回路構成、たとえば、FPGAもしくはASICによって、または専用論理回路構成と、プログラムされた1つもしくは複数のコンピュータとの組合せによって実行され得る。 The processes and logic flows described herein involve one or more programmable computers executing one or more computer programs to perform functions by operating on input data and generating output. can be performed by The processes and logic flows may also be performed by dedicated logic circuitry, such as FPGAs or ASICs, or by a combination of dedicated logic circuitry and programmed computer(s).
コンピュータプログラムの実行に適したコンピュータは、汎用マイクロプロセッサもしくは専用マイクロプロセッサまたはその両方、あるいは任意の他の種類の中央処理ユニットに基づくことができる。概して、中央処理ユニットは、読取り専用メモリもしくはランダムアクセスメモリまたはその両方から命令およびデータを受け取る。コンピュータの必須要素は、命令を実行(perform)または実行(execute)するための中央処理ユニット、ならびに命令およびデータを記憶するための1つまたは複数のメモリデバイスである。中央処理ユニットおよびメモリは、専用論理回路構成によって増補され得るか、または専用論理回路構成の中に組み込まれ得る。概して、コンピュータはまた、データを記憶するための1つまたは複数の大容量記憶デバイス、たとえば、磁気ディスク、光磁気ディスク、または光ディスクを含むか、あるいはそれらからデータを受け取ること、もしくはそれらにデータを転送すること、またはその両方を行うように動作可能に結合される。しかしながら、コンピュータは、そのようなデバイスを有することは必須ではない。その上、コンピュータは、別のデバイス、たとえば、ほんのいくつかの例を挙げれば、携帯電話、携帯情報端末(PDA)、モバイルオーディオプレーヤもしくはモバイルビデオプレーヤ、ゲーム機、全地球測位システム(GPS)受信機、またはポータブル記憶デバイス、たとえば、ユニバーサルシリアルバス(USB)フラッシュドライブの中に組み込まれ得る。 Computers suitable for the execution of computer programs may be based on general and/or special purpose microprocessors, or any other kind of central processing unit. Generally, a central processing unit receives instructions and data from read-only memory and/or random-access memory. The essential elements of a computer are a central processing unit for performing or executing instructions, and one or more memory devices for storing instructions and data. The central processing unit and memory may be augmented by, or incorporated within, dedicated logic circuitry. Generally, a computer also includes, receives data from, or transmits data to one or more mass storage devices for storing data, such as magnetic, magneto-optical, or optical disks. operably coupled to transfer, or both. However, a computer need not have such a device. Additionally, the computer may be used by other devices such as mobile phones, personal digital assistants (PDAs), mobile audio or video players, game consoles, global positioning system (GPS) reception, to name just a few examples. machine, or a portable storage device, such as a universal serial bus (USB) flash drive.
コンピュータプログラム命令およびデータを記憶するのに適したコンピュータ可読媒体は、例として、半導体メモリデバイス、たとえば、EPROM、EEPROM、およびフラッシュメモリデバイス、磁気ディスク、たとえば、内部ハードディスクまたはリムーバルディスク、光磁気ディスク、ならびにCD-ROMディスクおよびDVD-ROMディスクを含む、すべての形態の不揮発性メモリ、不揮発性媒体、および不揮発性メモリデバイスを含む。 Computer-readable media suitable for storing computer program instructions and data include, by way of example, semiconductor memory devices such as EPROM, EEPROM, and flash memory devices, magnetic disks such as internal hard disks or removable disks, magneto-optical disks, and all forms of nonvolatile memory, nonvolatile media, and nonvolatile memory devices, including CD-ROM and DVD-ROM discs.
ユーザとの対話を行うために、本明細書で説明した主題の実施形態は、情報をユーザに表示するためのディスプレイデバイス、たとえば、CRT(陰極線管)モニタまたはLCD(液晶ディスプレイ)モニタ、ならびにユーザがそれによってコンピュータに入力を与えることができるキーボードおよびポインティングデバイス、たとえば、マウスまたはトラックボールを有する、コンピュータ上で実施され得る。ユーザとの対話を行うために他の種類のデバイスも使用することができ、たとえば、ユーザに提供されるフィードバックは、任意の形態の知覚フィードバック、たとえば、視覚フィードバック、聴覚フィードバック、または触覚フィードバックであり得、ユーザからの入力は、音響入力、音声入力、または触覚入力を含む、任意の形態で受け取ることができる。加えて、コンピュータは、ユーザによって使用されるデバイスへ文書を送ること、およびそうしたデバイスから文書を受信することによって、たとえば、ユーザのデバイス上のウェブブラウザから受信された要求に応答してそのウェブブラウザへウェブページを送ることによって、ユーザと対話することができる。また、コンピュータは、パーソナルデバイス、たとえば、メッセージングアプリケーションを動作させているスマートフォンへテキストメッセージまたは他の形式のメッセージを送ること、および見返りとしてユーザから応答メッセージを受信することによって、ユーザと対話することができる。 To interact with a user, embodiments of the subject matter described herein include a display device, such as a CRT (cathode ray tube) monitor or LCD (liquid crystal display) monitor, for displaying information to the user, as well as a user can be implemented on a computer having a keyboard and pointing device, such as a mouse or trackball, through which input can be provided to the computer. Other types of devices can also be used to interact with the user, e.g., the feedback provided to the user can be any form of sensory feedback, e.g., visual, auditory, or tactile feedback. Additionally, input from the user can be received in any form, including acoustic, speech, or tactile input. In addition, the computer may send documents to and receive documents from devices used by the user, for example, in response to requests received from the web browser on the user's device. You can interact with users by sending web pages to . Computers can also interact with users by sending text messages or other forms of messages to personal devices, such as smart phones running messaging applications, and in return receiving reply messages from the users. can.
機械学習モデルを実施するためのデータ処理装置はまた、たとえば、機械学習トレーニングまたは機械学習産物の共通の部分および計算集約的な部分、たとえば、推論、作業負荷を処理するための、専用ハードウェアアクセラレータユニットを含むことができる。 Data processors for implementing machine learning models also include dedicated hardware accelerators, e.g., for processing common and computationally intensive parts of machine learning training or machine learning products, e.g., inference, workloads can contain units.
機械学習モデルは、機械学習フレームワーク、たとえば、TensorFlowフレームワーク、Microsoft Cognitive Toolkitフレームワーク、Apache Singaフレームワーク、またはApache MXNetフレームワークを使用して実装および展開され得る。 Machine learning models may be implemented and deployed using machine learning frameworks, such as the TensorFlow framework, Microsoft Cognitive Toolkit framework, Apache Singa framework, or Apache MXNet framework.
本明細書で説明した主題の実施形態は、たとえば、データサーバとしての、バックエンド構成要素を含むか、またはミドルウェア構成要素、たとえば、アプリケーションサーバを含むか、またはフロントエンド構成要素、たとえば、本明細書で説明した主題の実装形態とユーザがそれを通じて対話できるグラフィカルユーザインターフェース、ウェブブラウザ、もしくはアプリを有するクライアントコンピュータを含む、コンピューティングシステム、あるいは1つまたは複数のそのようなバックエンド構成要素、ミドルウェア構成要素、またはフロントエンド構成要素の任意の組合せにおいて実施され得る。システムの構成要素は、デジタルデータ通信の任意の形態または媒体、たとえば、通信ネットワークによって、相互接続され得る。通信ネットワークの例は、ローカルエリアネットワーク(LAN)およびワイドエリアネットワーク(WAN)、たとえば、インターネットを含む。 Embodiments of the subject matter described herein include back-end components, eg, as data servers, or include middleware components, eg, application servers, or front-end components, eg, A computing system, or one or more such back-end components, middleware, including a client computer having a graphical user interface, web browser, or app through which a user can interact with an implementation of the subject matter described in the book It can be implemented in any combination of components, or front-end components. The components of the system may be interconnected by any form or medium of digital data communication, eg, a communication network. Examples of communication networks include local area networks (LAN) and wide area networks (WAN), such as the Internet.
コンピューティングシステムは、クライアントおよびサーバを含むことができる。クライアントおよびサーバは、一般に互いからリモートであり、通常は通信ネットワークを通じて相互作用する。クライアントとサーバとの関係は、それぞれのコンピュータ上で動作しており互いにクライアントサーバ関係を有するコンピュータプログラムによって生じる。いくつかの実施形態では、サーバは、たとえば、クライアントとして働くデバイスと対話するユーザにデータを表示し、かつそうしたユーザからユーザ入力を受信するために、データ、たとえば、HTMLページを、ユーザデバイスへ送信する。ユーザデバイスにおいて生成されるデータ、たとえば、ユーザ対話の結果は、サーバにおいてデバイスから受信され得る。 The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other. In some embodiments, the server sends data, e.g., HTML pages, to user devices, e.g., to display data to and receive user input from users interacting with the device, e.g., acting as clients. do. Data generated at the user device, eg, results of user interactions, may be received from the device at the server.
本明細書は多くの特定の実装詳細を含むが、これらは、任意の発明の範囲において、または特許請求され得るものの範囲において、限定として解釈されるべきではなく、むしろ特定の発明の特定の実施形態に特有であり得る特徴の説明として解釈されるべきである。本明細書において別個の実施形態のコンテキストで説明されるいくつかの特徴はまた、単一の実施形態において組合せで実施され得る。反対に、単一の実施形態のコンテキストで説明される様々な特徴はまた、複数の実施形態において別個にまたは任意の好適な部分組合せで実施され得る。その上、特徴はいくつかの組合せで作用するものとして上記で説明されることがあり、さらには当初はそのように特許請求されることがあるが、特許請求される組合せからの1つまたは複数の特徴は、場合によっては、その組合せから削除することができ、特許請求される組合せは、部分組合せまたは部分組合せの変形を対象とすることがある。 While this specification contains many specific implementation details, these should not be construed as limitations on the scope of any invention or what may be claimed, but rather specific implementations of the particular invention. It should be construed as a description of features that may be unique to the form. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely, various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Moreover, although features may be described above, and even originally claimed as working in some combination, one or more from the claimed combination features may optionally be omitted from the combination, and the claimed combination may cover subcombinations or variations of subcombinations.
同様に、動作は特定の順序で図面の中に描写され特許請求の範囲の中に記載されるが、このことは、望ましい結果を達成するために、そのような動作が、示された特定の順序または連続的な順序で実行されること、またはすべての図示した動作が実行されることを必要とするものと、理解されるべきではない。いくつかの環境では、マルチタスキングおよび並列処理が有利であり得る。その上、上記で説明した実施形態における様々なシステムモジュールおよび構成要素の分離は、すべての実施形態においてそのような分離を必要とするものと理解されるべきではなく、説明したプログラム構成要素およびシステムが、一般に、単一のソフトウェア製品の中に一緒に組み込まれ得るか、または複数のソフトウェア製品の中にパッケージ化され得ることを理解されたい。 Similarly, although acts are depicted in the drawings and recited in the claims in a particular order, it is understood that such acts may be performed in the specific order shown to achieve the desired results. It should not be understood to require that all illustrated acts be performed in an order or sequential order. Multitasking and parallel processing can be advantageous in some environments. Moreover, the separation of various system modules and components in the embodiments described above should not be understood to require such separation in all embodiments, rather than the program components and systems described. may generally be incorporated together in a single software product or packaged in multiple software products.
本主題の特定の実施形態が説明されている。他の実施形態が以下の特許請求の範囲内に入る。たとえば、特許請求の範囲において記載されるアクションは、異なる順序で実行することができ、依然として望ましい結果を達成することができる。一例として、添付の図面の中に示すプロセスは、望ましい結果を達成するために、必ずしも図示の特定の順序または連続的な順序を必要とするとは限らない。場合によっては、マルチタスキングおよび並列処理が有利であり得る。 Particular embodiments of the subject matter have been described. Other embodiments are within the scope of the following claims. For example, the actions recited in the claims can be performed in a different order and still achieve desirable results. As an example, the processes illustrated in the accompanying figures do not necessarily require the particular order shown or sequential order to achieve desirable results. In some cases, multitasking and parallel processing can be advantageous.
100 ビデオ生成システム
102 入力ビデオ
104 ターゲットオブジェクトタイプ
106 トピカルビデオ
108 追跡エンジン
110 クロッピングエンジン
112 合成エンジン
114 追跡データ
116 サブビデオ
118 ビデオテンプレート
120 データ要素
200 ビデオテンプレート
202、204、206 スロット
300 デジタルコンポーネント生成システム
302 キーワード
306 デジタルコンポーネント
308 キーワードマッピングエンジン
310 ビデオテンプレート
400 環境
402 ネットワーク
404 電子文書サーバ
406 クライアントデバイス
408 デジタルコンポーネントサーバ
410 デジタルコンポーネント配信システム
412 コンポーネント要求
414 コンピューティングデバイスのセット
416 デジタルコンポーネントデータベース
417 タスク
418 分析の結果
420 返答データ
421 サーバ要求(SR)
422 デジタルコンポーネントデータ(DCデータ)
450 検索システム
452 検索インデックス
100 video generation system
102 input video
104 target object type
106 Topical Videos
108 Tracking Engine
110 Cropping Engine
112 Synthesis Engine
114 tracking data
116 sub videos
118 video templates
120 data elements
200 video templates
202, 204, 206 slots
300 digital component generation system
302 Keywords
306 Digital Components
308 Keyword Mapping Engine
310 video templates
400 environment
402 network
404 Electronic Document Server
406 client device
408 Digital Component Server
410 Digital Component Distribution System
412 Component Request
Set of 414 computing devices
416 Digital Component Database
417 tasks
418 Analysis Results
420 Response data
421 Server Request (SR)
422 digital component data (DC data)
450 search system
452 search index
Claims (9)
(i)ビデオフレームのシーケンスを備える入力ビデオ、および(ii)ターゲットオブジェクトタイプを示すデータを受信するステップと、
前記入力ビデオの中の前記ターゲットオブジェクトタイプのターゲットオブジェクトの1つまたは複数のインスタンスの視覚的ロケーションを識別および追跡する追跡データを生成するために、前記入力ビデオを処理するステップと、
サブビデオごとに、前記ターゲットオブジェクトタイプの前記識別されたターゲットオブジェクトの中から所与のターゲットオブジェクトのそれぞれのインスタンスを含むように、各々が前記入力ビデオのそれぞれのビデオフレームから抽出されるサブビデオフレームのそれぞれのシーケンスを生成するステップであって、前記サブビデオフレームのうちの少なくとも1つが、前記それぞれのビデオフレームのコンテンツを全体よりも小さく含むように、前記入力ビデオのそれぞれのビデオフレームからクロップされる、ステップを含む、
前記入力ビデオおよび前記追跡データに基づいて複数のサブビデオを生成するステップと、 前記複数のサブビデオを備える出力ビデオを生成するステップと、を備え、
サブビデオごとに、サブビデオフレームの前記それぞれのシーケンスを生成するステップが、
前記入力ビデオの複数のビデオフレームの各々の中の前記サブビデオに対応する前記所与のターゲットオブジェクトの前記インスタンスを囲む同じバウンディングボックスを、前記追跡データに基づいて決定するステップであって、前記複数のビデオフレームの各々の中で前記所与のターゲットオブジェクトが前記同じバウンディングボックスによって囲まれるような、前記同じバウンディングボックスの寸法および位置を決定するステップを含む、決定するステップと、
前記入力ビデオの前記複数のビデオフレームの各々から前記同じバウンディングボックスをクロップするステップと、を含む、
方法。 A method performed by one or more data processing apparatus, comprising:
receiving (i) an input video comprising a sequence of video frames and (ii) data indicative of a target object type;
processing the input video to generate tracking data that identifies and tracks the visual location of one or more instances of target objects of the target object type in the input video;
sub-video frames each extracted from a respective video frame of said input video to contain, for each sub-video, a respective instance of a given target object among said identified target objects of said target object type wherein at least one of said sub-video frames is cropped from a respective video frame of said input video to contain less than the entire content of said respective video frame. including steps,
generating a plurality of sub-videos based on said input video and said tracking data; and generating an output video comprising said plurality of sub-videos ;
generating said respective sequence of sub-video frames for each sub-video;
determining, based on the tracking data, the same bounding box surrounding the instance of the given target object corresponding to the sub-video in each of a plurality of video frames of the input video, wherein the plurality of determining the dimensions and position of the same bounding box such that the given target object is surrounded by the same bounding box in each of the video frames of
cropping the same bounding box from each of the plurality of video frames of the input video;
How .
前記複数のサブビデオを組み合わせるためのフォーマットを規定するビデオテンプレートの中のそれぞれのスロットに、前記複数のサブビデオの各サブビデオを割り当てるステップを備える、
請求項1または2に記載の方法。 generating the output video comprising the plurality of sub-videos;
assigning each sub-video of the plurality of sub-videos to a respective slot in a video template defining a format for combining the plurality of sub-videos;
3. A method according to claim 1 or 2 .
前記ビデオテンプレートの中のそれぞれのスロットに追加の各データ要素を割り当てるステップと
をさらに備え、
追加の各データ要素が、画像データ、テキストデータ、またはその両方を備える、
請求項3に記載の方法。 receiving one or more additional data elements other than the sub-video extracted from the input video ;
assigning each additional data element to a respective slot in the video template;
each additional data element comprising image data, text data, or both;
4. The method of claim 3 .
前記出力ビデオを含むデジタルコンポーネントが前記要求に応答することを決定するステップと、
前記要求に応答して、検索結果に並べてまたはサードパーティのウェブページ上で提示される、前記出力ビデオを含む前記デジタルコンポーネントを提供するステップと
をさらに備える、請求項1から5のいずれか一項に記載の方法。 receiving a request for a digital component;
determining that a digital component comprising said output video will respond to said request;
6. Providing said digital component, including said output video, presented alongside search results or on a third party web page in response to said request. The method described in .
キーワードを指定するデータを受信するステップと、
キーワードからの、可能なターゲットオブジェクトタイプの既定のセットへのマッピングに従って、前記ターゲットオブジェクトタイプに前記キーワードをマッピングするステップとを備える、
請求項1から6のいずれか一項に記載の方法。 receiving data indicative of the target object type;
receiving data specifying a keyword;
mapping said keywords to said target object types according to a mapping from keywords to a predefined set of possible target object types;
7. A method according to any one of claims 1-6 .
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/US2020/038963 WO2021262137A1 (en) | 2020-06-22 | 2020-06-22 | Generating videos |
Publications (2)
Publication Number | Publication Date |
---|---|
JP2022541361A JP2022541361A (en) | 2022-09-26 |
JP7299327B2 true JP7299327B2 (en) | 2023-06-27 |
Family
ID=71608058
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2021544221A Active JP7299327B2 (en) | 2020-06-22 | 2020-06-22 | Generate video |
Country Status (5)
Country | Link |
---|---|
US (1) | US11915724B2 (en) |
EP (1) | EP3956810B1 (en) |
JP (1) | JP7299327B2 (en) |
CN (1) | CN114080818A (en) |
WO (1) | WO2021262137A1 (en) |
Families Citing this family (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
EP4246465B1 (en) * | 2022-03-16 | 2024-01-03 | Axis AB | Improved masking of objects in an image stream |
EP4276772A1 (en) * | 2022-05-12 | 2023-11-15 | Fraunhofer-Gesellschaft zur Förderung der angewandten Forschung e.V. | Method, computer program and system for analysing one or more moving objects in a video |
CN115278338B (en) * | 2022-07-28 | 2023-09-19 | 广州市百果园信息技术有限公司 | Video wallpaper processing method and device, equipment and medium thereof |
Citations (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2005094799A (en) | 2004-11-15 | 2005-04-07 | Chuo Electronics Co Ltd | Integrated video display device |
JP2019140526A (en) | 2018-02-09 | 2019-08-22 | キヤノン株式会社 | Information processing apparatus, information processing method, program, and storage medium |
Family Cites Families (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10218954B2 (en) | 2013-08-15 | 2019-02-26 | Cellular South, Inc. | Video to data |
US20160034956A1 (en) * | 2014-07-29 | 2016-02-04 | Facebook, Inc. | Presenting targeting criteria options for inclusion in targeting criteria associated with content items |
EP3249651B1 (en) | 2016-05-23 | 2018-08-29 | Axis AB | Generating a summary video sequence from a source video sequence |
CN110188719B (en) * | 2019-06-04 | 2022-03-29 | 北京字节跳动网络技术有限公司 | Target tracking method and device |
CN110139158B (en) * | 2019-06-21 | 2021-04-02 | 上海摩象网络科技有限公司 | Video and sub-video generation method and device, and electronic equipment |
-
2020
- 2020-06-22 WO PCT/US2020/038963 patent/WO2021262137A1/en unknown
- 2020-06-22 US US17/423,623 patent/US11915724B2/en active Active
- 2020-06-22 JP JP2021544221A patent/JP7299327B2/en active Active
- 2020-06-22 EP EP20740118.3A patent/EP3956810B1/en active Active
- 2020-06-22 CN CN202080011238.8A patent/CN114080818A/en active Pending
Patent Citations (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2005094799A (en) | 2004-11-15 | 2005-04-07 | Chuo Electronics Co Ltd | Integrated video display device |
JP2019140526A (en) | 2018-02-09 | 2019-08-22 | キヤノン株式会社 | Information processing apparatus, information processing method, program, and storage medium |
Also Published As
Publication number | Publication date |
---|---|
JP2022541361A (en) | 2022-09-26 |
CN114080818A (en) | 2022-02-22 |
EP3956810A1 (en) | 2022-02-23 |
EP3956810B1 (en) | 2023-12-27 |
WO2021262137A1 (en) | 2021-12-30 |
US11915724B2 (en) | 2024-02-27 |
US20230095856A1 (en) | 2023-03-30 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11947897B2 (en) | Systems and methods for video content association | |
JP6400772B2 (en) | Providing content to users across multiple devices | |
JP7299327B2 (en) | Generate video | |
US10657310B2 (en) | Ordinal positioning of content items based on viewport | |
JP6334696B2 (en) | Hashtag and content presentation | |
AU2012253364B2 (en) | Dynamic image display area and image display within web search results | |
US8374914B2 (en) | Advertising using image comparison | |
CN105745643B (en) | System and method for creating image-based content based on text-based content | |
US20230186348A1 (en) | Image Recognition Based Content Item Selection | |
US10445753B1 (en) | Determining popular and trending content characteristics | |
US20100312608A1 (en) | Content advertisements for video | |
US20090287645A1 (en) | Search results with most clicked next objects | |
Mei et al. | ImageSense: Towards contextual image advertising | |
US20130117110A1 (en) | Dynamic determination of number of served advertisements | |
JP7267453B2 (en) | image augmentation neural network | |
US11775994B2 (en) | Distributing electronic surveys via third-party content | |
US11336737B2 (en) | Opt-out compliance | |
US20240161783A1 (en) | Generating videos | |
EP3327652A1 (en) | Automatic selection of items for a computerized graphical advertisement display using a computer-generated multidimensional vector space | |
US11250475B2 (en) | Neural network architecture for efficient resource allocation | |
US11468675B1 (en) | Techniques for identifying objects from video content | |
US20160260125A1 (en) | Systems and Methods for Cold-start and Continuous-learning via Evolutionary Explorations | |
CN106709036B (en) | Method and device for displaying search result page | |
US10891653B1 (en) | Approaches for retrieval of electronic advertisements | |
CN110622159A (en) | Improving opt-out compliance |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A621 | Written request for application examination |
Free format text: JAPANESE INTERMEDIATE CODE: A621Effective date: 20210927 |
|
A131 | Notification of reasons for refusal |
Free format text: JAPANESE INTERMEDIATE CODE: A131Effective date: 20221205 |
|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20230221 |
|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20230301 |
|
TRDD | Decision of grant or rejection written | ||
A01 | Written decision to grant a patent or to grant a registration (utility model) |
Free format text: JAPANESE INTERMEDIATE CODE: A01Effective date: 20230522 |
|
A61 | First payment of annual fees (during grant procedure) |
Free format text: JAPANESE INTERMEDIATE CODE: A61Effective date: 20230615 |
|
R150 | Certificate of patent or registration of utility model |
Ref document number: 7299327Country of ref document: JPFree format text: JAPANESE INTERMEDIATE CODE: R150 |