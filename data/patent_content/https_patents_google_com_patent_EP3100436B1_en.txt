EP3100436B1 - Maintaining routing information for a distributed service provided by service instances - Google Patents
Maintaining routing information for a distributed service provided by service instances Download PDFInfo
- Publication number
- EP3100436B1 EP3100436B1 EP14808761.2A EP14808761A EP3100436B1 EP 3100436 B1 EP3100436 B1 EP 3100436B1 EP 14808761 A EP14808761 A EP 14808761A EP 3100436 B1 EP3100436 B1 EP 3100436B1
- Authority
- EP
- European Patent Office
- Prior art keywords
- index value
- address
- service instance
- index
- provisioned
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
- 238000000034 method Methods 0.000 claims description 34
- 230000008859 change Effects 0.000 claims description 3
- 238000010586 diagram Methods 0.000 description 13
- 238000013507 mapping Methods 0.000 description 9
- 238000004891 communication Methods 0.000 description 7
- 230000008569 process Effects 0.000 description 7
- 238000004590 computer program Methods 0.000 description 6
- 238000012545 processing Methods 0.000 description 5
- 230000006870 function Effects 0.000 description 3
- 230000003287 optical effect Effects 0.000 description 2
- 238000013515 script Methods 0.000 description 2
- 239000004065 semiconductor Substances 0.000 description 2
- 238000000926 separation method Methods 0.000 description 2
- RJKFOVLPORLFTN-LEKSSAKUSA-N Progesterone Chemical compound C1CC2=CC(=O)CC[C@]2(C)[C@@H]2[C@@H]1[C@@H]1CC[C@H](C(=O)C)[C@@]1(C)CC2 RJKFOVLPORLFTN-LEKSSAKUSA-N 0.000 description 1
- 238000013459 approach Methods 0.000 description 1
- 238000004364 calculation method Methods 0.000 description 1
- 230000001419 dependent effect Effects 0.000 description 1
- 239000000284 extract Substances 0.000 description 1
- 230000003993 interaction Effects 0.000 description 1
- 238000012986 modification Methods 0.000 description 1
- 230000004048 modification Effects 0.000 description 1
- 239000000758 substrate Substances 0.000 description 1
- 230000001052 transient effect Effects 0.000 description 1
- 230000000007 visual effect Effects 0.000 description 1
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L45/00—Routing or path finding of packets in data switching networks
- H04L45/54—Organization of routing tables
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L67/00—Network arrangements or protocols for supporting network services or applications
- H04L67/01—Protocols
- H04L67/10—Protocols in which an application is distributed across nodes in the network
- H04L67/1001—Protocols in which an application is distributed across nodes in the network for accessing one among a plurality of replicated servers
- H04L67/1004—Server selection for load balancing
Definitions
- a distributed computing service can be provided to client devices by multiple instances of the computing service.
- a client device can interact with any one of the instances to access the distributed computing service.
- the instances of the computing service may be hosted by multiple computing devices and/or virtual servers. Load balancers distribute client requests across the multiple instances, so as to keep the multiple computing devices and/or virtual servers from becoming over-burdened.
- Network devices generally process data packets based on address information associated with the data packets. For example, a router typically forwards a received data packet to a next network destination (a "next-hop") based on an address associated with the data packet, e.g., a destination address indicated in header information for the received data packet.
- a next-hop a next network destination based on an address associated with the data packet, e.g., a destination address indicated in header information for the received data packet.
- Document EP 1 094 645 A2 discloses a system that uses a packet distribution table to distribute packets to server nodes in a cluster of nodes that operate in concert to provide at least one service.
- the system operates by receiving a packet at an interface node in the cluster of nodes.
- This packet includes a source address specifying a location of a client that the packet originated from, and a destination address specifying a service provided by the cluster of nodes.
- the system uses the destination address to lookup a packet distribution table.
- the system then performs a function that maps the source address to an entry in the packet distribution table, and retrieves an identifier specifying a server node from the entry in the packet distribution table.
- the system forwards the packet to the server node specified by the identifier so that the server node can perform a service for the client.
- packets directed to a service specified by a single destination address are distributed across multiple server nodes in a manner specified by the packet distribution table.
- Document US 2005/165885 A1 discloses methods and apparatus for forwarding a data packet addressed to a cluster of servers.
- a connection request is received from a client
- a connection identifier is formed according to the connection request.
- the connection request is forwarded to a first-identified server in the cluster of servers.
- the connection identifier is associated with a responding server in the cluster of servers. Subsequent traffic received from the client associated with the connection identifier is forwarded to the responding server associated with the connection identifier.
- the disclosure relates to a method of maintaining routing information for a distributed service provided by a plurality of service instances.
- the method includes providing an address table with a number of entries less than or equal to a number of index values in a set of provisioned index values, each of the entries assigned to a respective provisioned index value and an instance of a distributed service.
- the method includes adding a new service instance to the address table by obtaining an assignable index value to assign to the new service instance, identifying an assigned index value that is a companion index value to the obtained index value, dividing a packet source address set associated with the companion index value into a first address subset and a second address subset, and assigning the first address subset to the service instance entry in the address table associated with the assigned companion index value and the second address subset to an entry in the address table associated with the obtained index value and the newly added service instance.
- the method includes obtaining an assignable index value to assign to the new service instance by performing the operations of identifying an existing, unassigned, index value in the set of provisioned index values and, when there is no unassigned index value available, increasing the number of index values in the set of provisioned index values and selecting a newly provisioned index value.
- the method includes removing a service instance from the address table by identifying a third address subset assigned to a service instance entry in the address table, associated with a first index value, for the service instance to be removed; identifying a fourth address subset assigned to a service instance entry in the address table associated with a second index value that is a companion index value to the first index value; assigning a combined address subset, which is the third address subset and the fourth address subset, to the service instance entry in the address table associated with the second index value; and clearing the service instance entry associated with the first index value from the table.
- the disclosure relates to a network device controller.
- the network device controller includes memory storing an address table with a number of entries less than or equal to a number of index values in a set of provisioned index values. Each of the entries is assigned to a respective provisioned index value and an instance of a distributed service.
- the network device controller includes at least one processor configured to add a new service instance to the address table by performing the operations of obtaining an assignable index value to assign to the new service instance, identifying an assigned index value that is a companion index value to the obtained index value, dividing a packet source address set associated with the companion index value into a first address subset and a second address subset, and assigning the first address subset to the service instance entry in the address table associated with the assigned companion index value and the second address subset to an entry in the address table associated with the obtained index value and the newly added service instance.
- the at least one processor is configured to obtain an assignable index value to assign to the new service instance by performing the operations of identifying an existing, unassigned, index value in the set of provisioned index values and, when there is no unassigned index value available, increasing the number of index values in the set of provisioned index values and selecting a newly provisioned index value.
- the at least one processor is configured to remove a service instance from the address table by performing the operations of identifying a third address subset assigned to a service instance entry in the address table, associated with a first index value, for the service instance to be removed; identifying a fourth address subset assigned to a service instance entry in the address table associated with a second index value that is a companion index value to the first index value; assigning a combined address subset, which is the third address subset and the fourth address subset, to the service instance entry in the address table associated with the second index value; and clearing the service instance entry associated with the first index value from the table.
- the disclosure relates to tangible computer readable storage media storing non-transient processor-executable instructions that, when executed by a computing device comprising the storage media and one or more processors, cause the one or more processors to perform the operations of storing, in computer readable memory, an address table with a number of entries less than or equal to a number of index values in a set of provisioned index values, each of the entries assigned to a respective provisioned index value and an instance of a distributed service.
- the instructions cause the one or more processor to add a new service instance to the address table by obtaining an assignable index value to assign to the new service instance, identifying an assigned index value that is a companion index value to the obtained index value, dividing a packet source address set associated with the companion index value into a first address subset and a second address subset, and assigning the first address subset to the service instance entry in the address table associated with the assigned companion index value and the second address subset to an entry in the address table associated with the obtained index value and the newly added service instance.
- the instructions cause the one or more processor to obtain an assignable index value to assign to the new service instance by performing the operations of identifying an existing, unassigned, index value in the set of provisioned index values and, when there is no unassigned index value available, increasing the number of index values in the set of provisioned index values and selecting a newly provisioned index value.
- the instructions cause the one or more processor to remove a service instance from the address table by identifying a third address subset assigned to a service instance entry in the address table, associated with a first index value, for the service instance to be removed; identifying a fourth address subset assigned to a service instance entry in the address table associated with a second index value that is a companion index value to the first index value; assigning a combined address subset, which is the third address subset and the fourth address subset, to the service instance entry in the address table associated with the second index value; and clearing the service instance entry associated with the first index value from the table.
- requests to a distributed service may be load balanced by routing different requests to different instances of the service.
- the different instances may be hosted on different physical or virtual server hosts.
- a network device such as a switch or router, in a network path determines the service instance to which a particular request should be forwarded.
- the network device can implement a set of load-balancing rules that are applied to each incoming packet.
- all of the traffic being load-balanced arrives at the network device addressed to the same destination address, e.g., a virtual address for the distributed service.
- Load-balancing rules may be implemented in a manner similar to a destination-based routing table, except that the load-balancing rules route traffic based on a characteristic, such as a source address, of incoming packets that can serve as a consistent identifier.
- the load-balancing rules route data packets from a client to a particular host for an instance of the distributed service selected based on the last few (the least significant) bits of the client's 32-bit IPv4 network address.
- the load-balancing rules may be selected so that adding new service instances, and removing service instances, has minimal impact on the existing routes and route tables.
- Figure 1A is a block diagram of an example network device 130.
- Figure 1B is a block diagram of an example network device 130 connecting multiple hosts 150a-150n for a distributed service to a broader data network 110.
- the illustrated network device 130 has a control module 144 and a forwarding engine 134.
- the control module maintains the aforementioned rules in a memory 136 for use by the forwarding engine 134 in processing data packets.
- the network device 130 has a plurality of network interfaces 138, with one or more of the network interfaces 138 linked to other network devices in various subnets 112a-112n of a data network 110 and/or hosts 150a-150n.
- the network device 130 participates in the data network 110 by receiving and sending data packets via the network interfaces 138.
- Each network interface 138 may be connected to other network devices, e.g., via a data plane.
- the connections are bi-directional data links.
- the connections are uni-directional data links, where each link is either ingress or egress.
- the other network devices send data packets to the network device 130, which may then forward them to another network device according to its configuration (e.g. rules or routing information stored in memory 136).
- a data packet may arrive at the network device 130 via a first interface (e.g., network interface 138a), causing the network device 130 to process the received data packet and (for example) forward it to an appropriate next-hop via a second interface (e.g., network interface 238b).
- the forwarding engine 134 determines which network interface 138 to use to forward each data packet received.
- the data network 110 is a network facilitating interactions between computing devices.
- An illustrative example data network 110 is the Internet; however, other networks may be used.
- the data network 110 may be composed of multiple connected sub-networks 112a-112n.
- the data network 110 can be a local-area network (LAN), such as a company intranet, a metropolitan area network (MAN), a wide area network (WAN), an inter-network such as the Internet, or a peer-to-peer network, e.g., an ad hoc WiFi peer-to-peer network.
- the data network 110 may be any type and/or form of data network and/or communication network.
- the data network 110 may be public, private, or a combination of public and private networks. In general, the data network 110 is used to convey information between computing devices, and the network device 130 facilitates this communication according to its configuration.
- the network device 130 includes a control module 144 and memory 136 storing configuration data, rules, and/or routing data.
- the control module 144 is implemented as a special purpose circuit (e.g., an ASIC).
- the control module 144 is implemented as a set of computer executable instructions stored in computer accessible memory and executed by one or more computing processors.
- the network device control module 144 receives configuration and routing information and updates the configuration and routing data stored in memory 136.
- the control module 144 receives routing data from other network devices in the network 110, e.g., using ICMP or BGP messages.
- the control module 144 creates and maintains the data structures described herein, using the received routing data.
- the network device 130 participates in a software-defined network ("SDN") and the network device control module 144 receives configuration and routing information from an SDN controller, e.g., via a control plane.
- the control module 144 receives the load-balancing rules described herein from an SDN controller.
- the control module 144 stores these load-balancing rules in the memory 136.
- the forwarding engine 134 uses the configuration and routing data in memory 136 to manage the data traffic at the network interface ports 138.
- the network device memory 136 may be any device suitable for storing computer readable data.
- the memory 136 may be similar to the memory 670 or cache 675 illustrated in Figure 6 and described below. Examples include, but are not limited to, semiconductor memory devices such as EPROM, EEPROM, SDRAM, and flash memory devices.
- a network device 130 may have any number of memory devices 136.
- the forwarding engine 134 uses the rules, configuration, and routing data stored in memory 136 to manage the data traffic received at the network interfaces 138.
- the forwarding engine 134 is implemented as a special purpose circuit (e.g., an ASIC).
- the forwarding engine 134 is implemented as a set of computer executable instruction sets stored in computer accessible memory and executed by one or more computing processors.
- the forwarding engine 134 extracts address information from a data packet (e.g., an IP address from a packet header) and processes it to determine how to handle the data packet (e.g., whether to forward the data packet and/or which network interface 13 8 to use for forwarding the data packet) using the load-balancing rules and methods described herein.
- the load-balancing rules route traffic based on a characteristic, such as a source address, of incoming packets that can serve as a consistent identifier.
- the load-balancing rules route data packets from a client to a particular host for an instance of the distributed service selected based on the last few (the least significant) bits of the client's 32-bit IPv4 network address.
- the load-balancing rules route data packets from a client to a particular host for an instance of the distributed service selected based on an identifier made up of multiple values, e.g., a source address and TCP source port.
- sets of addresses (or identifiers) are assigned to various instances of the distributed service.
- each set (that is, the number of addresses in each set) is roughly the same as the size of any other set.
- each set of addresses is either a first size or a second size that is half the first size. As new service instances are added, the sets that are the first size are split up such that the new service instance is assigned a set of address that is half the first size.
- a network controller treats each service instance as having a companion instance.
- the network controller identifies the companion instance for the new service instance, and divides the set of addresses assigned to the companion instance into two sets, one for the preexisting companion instance and the other for the new service instance.
- the network controller re-assigns the addresses for the removed service instance back to the companion instance.
- the pairings between peer service instance companions is redistributed such that each service instance has a companion instance, as needed.
- Each service instance is assigned or associated with an index used in identification of a companion instance.
- each index value is paired with a companion index based on the total number of service instances.
- the pairing is based on the number of service instances k and the largest power of two less than the number of service instances (i.e., using ⁇ to denote the exponent for a power of two, 2 ⁇ ⁇ k ⁇ 2 ⁇ +1 ), where k is the number of service instances after adding a service instance or before removing a service instance.
- Figure 2 is a diagram of example index pairings. Illustrated are three sets of companion maps: a first map 220 for a set of four instances in two pairs, a second map 230 for a set of eight instances in four pairs, and a third map 240 for a set of sixteen instances in eight pairs.
- These maps (220, 230, and 240) are visual examples of the pairs calculated using the above equations. For example, for a range of three to four service instances, numbered 0 through 3, the first map 220 pairs 0 with 2 and 1 with 3. However, if a fifth instance is added (numbered 4), the range of three to four service instances is exceeded and would be expanded, e.g., to a range of five to eight service instances.
- the second map 230 illustrates that the newly added instance 4 would be paired with 0, which had been paired with 2 in the first map 220. Additional service instances may be added, up to the new threshold of eight instances. Index number 5 is paired with 1, index 6 is paired with 2, and index 7 (corresponding to the eighth service instance) is paired with 3. If a ninth instance is added (numbered 8), the range of five to eight service instances is exceeded and would be expanded, e.g., to a range of nine to sixteen service instances.
- the third map 240 illustrates that the newly added instance 8 would be paired with 0, which had been paired with 2 in the first map 220 and with 4 in the second map 230.
- Figure 3 is a diagram illustrating an example address table 360 mapping sets of addresses to service instances.
- the address table 360 maps seven sets of addresses to service instances.
- the table 360 is illustrated with rows of example data, where each row is an example rule for a service instance, and with three columns: Index, End Bits, and Result.
- the "Index” corresponds to the index numbers introduced above, starting at 0.
- the "Result” is a value designating how packets satisfying the rule are handled, e.g., a service instance identifier or a network interface identifier for forwarding the packets to a service instance.
- the "End Bits" values are binary numbers; an address matches a rule if it ends with the same bits as the rule's end bits value.
- An "x” in the bits indicates a bit that can be either a 1 or a 0, i.e., a "don't care” bit.
- the row 362 has an End Bits value of "x11,” indicating that any address with the last two bits equal to "11" would match.
- No other rule in the table 360 has an End Bits value ending in 11.
- the address table 360 includes entries for eight potential index value/address set pairings. These eight index values can be considered to be “provisioned" in the table. Seven of the eight entries are populated, having address sets assigned to the respective index values. One entry, associated with index value 7, is not assigned to any address set, and thus is available for assignment. While the table may include additional entries, with index values greater than 7, such entries are not considered assignable (and thus are not shown) given the limited number of entries needed to handle the active number of service instances. After the number of active instances exceeds a threshold (typically a number equal to a power of 2), additional entries and their respective index values are provisioned, and thus are made available for assignment.
- a threshold typically a number equal to a power of 2
- each address set can be defined solely by the values of the addresses' least significant bits. The value of those bits are considered to inherently serve as an index value for the set of addresses. For example, all addresses with the last four significant bits of 0101 (i.e., 5) are considered to inherently be part of the address group associated with index number 5. Similarly, addresses with the last four significant bits of 0001, are inherently associated with the index number 1. In such implementations, no explicit address grouping allocation is necessary, and instead relies merely on the structure of the addresses themselves. The number of bits used to define these inherent address sets depends on the number of service instances the addresses are being split between.
- each group is defined by a network address mask in CIDR notation and the group is split by adding an address mask selected to be halfway between two address masks (e.g., an average). Any approach may be used to describe the set of addresses associated with each service instance and to divide the set of addresses into smaller subsets.
- FIG. 4A is a flowchart for an example method in which a service instance is added to an address table.
- a method 400 begins with a network device obtaining an assignable index value to assign to a new service instance (stage 410).
- the network device identifies an assigned index value that is a companion index value to the obtained index value (stage 420) and divides a packet source-address set associated with the companion index value into a first address subset and a second address subset (stage 430).
- the network device assigns the first address subset to the service instance entry in the address table associated with the assigned companion index value (stage 440) and assigns the second address subset to an entry in the address table associated with the obtained index value and the newly added service instance (stage 450).
- the method 400 begins with a network device (e.g., the network device 130, illustrated in Figure 1A ) obtaining an assignable index value to assign to a new service instance (stage 410).
- the network device obtains an assignable index value by identifying an existing, unassigned index value in a set of provisioned index values. Index values are said to be provisioned if they are already assigned or are available for assignment. If there are no existing, unassigned, index values in the set of provisioned index values, the network device increases the number of index values in the set of provisioned index values and selects a newly provisioned index value. In some implementations, the network device increases the number of index values by doubling the number of index values provisioned and re-determining the pairing between service instance companions based on the new number of index values provisioned.
- the network device identifies an assigned index value that is a companion index value to the obtained index value (stage 420).
- the network device divides a packet source-address set associated with the companion index value into a first address subset and a second address subset (stage 430). In some implementations, the division is equal, such that the first address subset and the second address subset are of the same size.
- addresses can be grouped into subsets sharing a common set of End Bits and "not caring" about the values of any higher order bits in the address (these "don't care” bits may be expressed as "x" bits). Such a grouping can be effectively split in half by increasing by one the number of bits in the set of End Bits that are specifically defined (i.e., which are not x bits).
- a set of addresses can be split by converting the lowest order x bit in the End Bits to a 0 or a 1 and adding a corresponding new entry to the table where that bit is set to the other of 0 or 1.
- a set of addresses defined by End bits xx001 can be split evenly into two groups with End Bits x0001 and x1001.
- the network device then assigns the first address subset to the service instance entry in the address table associated with the assigned companion index value (stage 440) and assigns the second address subset to an entry in the address table associated with the obtained index value and the newly added service instance (stage 450).
- modifications to the address table can be limited under some situations to only modifying the entry in the address table at stage 440 and adding a new entry at stage 450. This enables a low impact change.
- Figures 4B and 4C are diagrams illustrating examples of adding a new service instance to a table mapping sets of addresses to service instances.
- the address table 360 first illustrated in Figure 3 is modified to become an address table 370, which maps eight sets of address to service instances.
- the address table 370, which maps, eight sets of addresses to service instances is modified to become an address table 380, mapping nine sets of address to service instances.
- Figure 4B illustrates a scenario wherein there is an available assignable index.
- Figure 4C illustrates a scenario wherein there is no available assignable index.
- the address table 360 mapping seven sets of addresses to service instances is modified to become the address table 370 mapping eight sets of address to service instances.
- a service instance "H" is added (e.g., using the method described above in reference to Figure 4A ).
- the new service instance is assigned index 7, which has a companion index of 3.
- the entry 462 for index 3 is a rule for addresses with the last two bits equal to "11.”
- the table 360 is modified to become a table 370 with the new rule, in which the entry 474 for index 3 is a rule for addresses with the last three bits equal to "011" and the entry 476 for index 7 is a rule for addresses with the last three bits equal to "111.”
- the number of index values provisioned brings the total number of provisioned index values up the next highest power of 2.
- a fifth index is provisioned (exceeding 2 2 )
- an additional four index values are provisioned to bring the total number of provisioned index values up to 8, i.e., 23.
- 8 additional index values are provisioned, bringing the total number to 16, i.e., 2 4 , and so forth.
- adding an eighth service instance does not require a total number of provisioned index values to exceed a power of 2, and thus no new index values are needed or provisioned.
- the address table 370 which maps eight sets of addresses to service instances is modified to become an address table 380, mapping nine sets of address to service instances.
- a service instance "J" is added (e.g., using the method described above in reference to Figure 4A ).
- the new service instance is assigned index 8, which has a companion index of 0.
- the entry 472 for index 0 is a rule for addresses with the last three bits equal to "000.”
- the table 370 is modified to become a table 380 with the new rule, in which the entry 484 for index 0 is a rule for addresses with the last four bits equal to "0000" and the entry 486 for index 8 is a rule for addresses with the last four bits equal to "1000.”
- the number of indices provisioned at any given time is equal to a power of 2.
- adding a ninth service instance (9 being one greater than 2 3 ) requires the provisioning of additional index values.
- an additional seven index values are provisioned, as well, taking the total number of provisioned index values up to 16.
- the address table is updated to re-combine the set of addresses for the removed service instance and its companion instance. If the removed service instance does not have a companion instance (e.g., "D" at index 3 in the table 380, illustrated in Figure 3B ) then the table may need to be rebuilt. Otherwise, only the rules for the removed service instance and its companion need to be updated. Thus, the number of entries that need to be modified for a topology change is minimal.
- Figure 5A is a flowchart for an example method in which a service instance is removed from a table.
- the method 500 begins with a network device identifying a first address subset assigned to a service instance entry in the address table, associated with a first index value, for a service instance to be removed (stage 510).
- the network device identifies a second address subset assigned to a service instance entry in the address table associated with a second index value that is a companion index value to the first index value (stage 520) and assigns a combined address subset to the service instance entry in the address table associated with the second index value (stage 530).
- the network device can then clear the service instance entry associated with the first index value from the table (stage 540).
- the method 500 begins with a network device identifying a first address subset assigned to a service instance entry in the address table, associated with a first index value, for a service instance to be removed (stage 510).
- a service instance may be removed, for example, in the event of a service failure, a host failure, or a communication link failure. If the distributed service is underutilized, one or more service instances may be shut down to consolidate service load.
- the network device identifies a second address subset assigned to a service instance entry in the address table associated with a second index value that is a companion index value to the first index value (stage 520).
- the network device then assigns a combined address subset to the service instance entry in the address table associated with the second index value (stage 530) and clears the service instance entry associated with the first index value from the table (stage 540).
- the network device uses the lower value of the second index value and the first index value when assigning the combined address subset to a service instance entry in the address table.
- the combined address subset is created by transitioning a bit from each of the sub-groups being merged into a "don't care" bit (indicated with an x in Figure 5B ).
- the distribution is fair in that each service instance is associated with the same number (1/ k ) of the source addresses.
- the number of service instances ( k ) is between two powers of two (2 ⁇ ⁇ k ⁇ 2 ⁇ + 1 )
- there is some imbalance in the distribution-some service instances will be associated with a number of addresses that is twice the number associated with other service instances.
- the percentage of addresses (1/2 ⁇ + 1 ) assigned to 2( k -2 ⁇ ) service instances will be half the percentage of addresses (1/2 ⁇ ) assigned to the remaining 2 ⁇ + 1 - k service instances.
- an address table 370 mapping eight sets of address to service instances is modified to become an address table 360 mapping seven sets of addresses to service instances.
- a service instance "H" is removed (e.g., using the method described above in reference to Figure 5A ).
- the service instance being removed was assigned index 7, which has a companion index of 3.
- the entry 576 for index 7 is a rule for addresses with the last three bits equal to "111,” and the entry 574 for index 3 is a rule for addresses with the last three bits equal to "011.”
- the table 370 is modified to become a table 360, in which the entry 562 for index 3 is a combined rule for addresses with the last three bits equal to "011" or "111" and there is no entry for index 7, i.e., the rule at index 7 has been cleared.
- FIG. 6 is a block diagram of a computing system for use in implementing the computerized components described herein, in accordance with an illustrative implementation.
- the computing system includes at least one processor 650 for performing actions in accordance with instructions and one or more memory devices 670 or 675 for storing instructions and data.
- the illustrated example computing system 610 includes one or more processors 650 in communication, via a bus 615, with at least one network interface controller 620 with network interface ports 622 (a-n) connecting to network devices 612 (a-n) , memory 670, and any other devices 680, e.g., an I/O interface.
- a processor 650 will execute instructions received from memory.
- the processor 650 illustrated incorporates, or is directly connected to, cache memory 675.
- the processor 650 may be any logic circuitry that processes instructions, e.g., instructions fetched from the memory 670 or cache 675.
- the processor 650 is a microprocessor unit or special purpose processor.
- the computing device 610 may be based on any processor, or set of processors, capable of operating as described herein.
- the processor 650 may be a single core or multi-core processor.
- the processor 650 may be multiple processors.
- the memory 670 may be any device suitable for storing computer readable data.
- the memory 670 may be a device with fixed storage or a device for reading removable storage media. Examples include all forms of non-volatile memory, media and memory devices, semiconductor memory devices (e.g., EPROM, EEPROM, SDRAM, and flash memory devices), magnetic disks, magneto optical disks, and optical discs (e.g., CD ROM, DVD-ROM, and Blu-Ray® discs).
- a computing system 610 may have any number of memory devices 670.
- the cache memory 675 is generally a form of computer memory placed in close proximity to the processor 650 for fast read times. In some implementations, the cache memory 675 is part of, or on the same chip as, the processor 650. In some implementations, there are multiple levels of cache 675, e.g., L2 and L3 cache layers.
- the network interface controller 620 manages data exchanges via the network interfaces 622 (a-n) (also referred to as network interface ports).
- the network interface controller 620 handles the physical and data link layers of the OSI model for network communication. In some implementations, some of the network interface controller's tasks are handled by the processor 650. In some implementations, the network interface controller 620 is part of the processor 650.
- a computing system 610 has multiple network interface controllers 620.
- the network interfaces 622 (a-n) are connection points for physical network links. In some implementations, the network interface controller 620 supports wireless network connections and an interface port 622 is a wireless receiver/transmitter.
- a computing device 610 exchanges data with other computing devices 612 (a-n) via physical or wireless links to a network interface 622 (a-n) .
- the network interface controller 620 implements a network protocol such as Ethernet.
- the other computing devices 612 (a-n) are connected to the computing device 610 via a network interface port 622.
- the other computing devices 612 (a-n) may be peer computing devices, network devices, or any other computing device with network functionality.
- a first computing device 612 (a) may be a network device such as a hub, a bridge, a switch, or a router, connecting the computing device 610 to a data network such as the Internet.
- the other devices 680 may include an I/O interface, external serial device ports, and any additional co-processors.
- a computing system 610 may include an interface (e.g., a universal serial bus (USB) interface) for connecting input devices (e.g., a keyboard, microphone, mouse, or other pointing device), output devices (e.g., video display, speaker, or printer), or additional memory devices (e.g., portable flash drive or external media drive).
- a computing device 610 includes an additional device 680 such as a co-processor, e.g., a math co-processor can assist the processor 650 with high precision or complex calculations.
- Implementations of the subject matter and the operations described in this specification can be implemented in digital electronic circuitry, or in computer software embodied on a tangible medium, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them. Implementations of the subject matter described in this specification can be implemented as one or more computer programs embodied on a tangible medium, i.e., one or more modules of computer program instructions, encoded on one or more computer storage media for execution by, or to control the operation of, a data processing apparatus.
- a computer storage medium can be, or be included in, a computer-readable storage device, a computer-readable storage substrate, a random or serial access memory array or device, or a combination of one or more of them.
- the computer storage medium can also be, or be included in, one or more separate components or media (e.g., multiple CDs, disks, or other storage devices).
- the computer storage medium may be tangible and non-transitory.
- the operations described in this specification can be implemented as operations performed by a data processing apparatus on data stored on one or more computer-readable storage devices or received from other sources.
- a computer program (also known as a program, software, software application, script, or code) can be written in any form of programming language, including compiled or interpreted languages, declarative or procedural languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, object, or other unit suitable for use in a computing environment.
- a computer program may, but need not, correspond to a file in a file system.
- a program can be stored in a portion of a file that holds other programs or data (e.g., one or more scripts stored in a markup language document), in a single file dedicated to the program in question, or in multiple coordinated files (e.g., files that store one or more modules, sub programs, or portions of code).
- a computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.
- Examples of communication networks include a local area network ("LAN”) and a wide area network (“WAN”), an inter-network (e.g., the Internet), and peer-to-peer networks (e.g., ad hoc peer-to-peer networks).
- the processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform actions by operating on input data and generating output.
- the processes and logic flows can also be performed by, and apparatus can also be implemented as, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application specific integrated circuit).
- references to "or” may be construed as inclusive so that any terms described using “or” may indicate any of a single, more than one, and all of the described terms.
- the labels “first,” “second,” “third,” an so forth are not necessarily meant to indicate an ordering and are generally used merely to distinguish between like or similar items or elements.
Description
- A distributed computing service can be provided to client devices by multiple instances of the computing service. Typically, a client device can interact with any one of the instances to access the distributed computing service. The instances of the computing service may be hosted by multiple computing devices and/or virtual servers. Load balancers distribute client requests across the multiple instances, so as to keep the multiple computing devices and/or virtual servers from becoming over-burdened.
- Network devices generally process data packets based on address information associated with the data packets. For example, a router typically forwards a received data packet to a next network destination (a "next-hop") based on an address associated with the data packet, e.g., a destination address indicated in header information for the received data packet.
-
Document EP 1 094 645 A2 discloses a system that uses a packet distribution table to distribute packets to server nodes in a cluster of nodes that operate in concert to provide at least one service. The system operates by receiving a packet at an interface node in the cluster of nodes. This packet includes a source address specifying a location of a client that the packet originated from, and a destination address specifying a service provided by the cluster of nodes. The system uses the destination address to lookup a packet distribution table. The system then performs a function that maps the source address to an entry in the packet distribution table, and retrieves an identifier specifying a server node from the entry in the packet distribution table. Next, the system forwards the packet to the server node specified by the identifier so that the server node can perform a service for the client. In this way, packets directed to a service specified by a single destination address are distributed across multiple server nodes in a manner specified by the packet distribution table. - Document
US 2005/165885 A1 discloses methods and apparatus for forwarding a data packet addressed to a cluster of servers. According to one method, when a connection request is received from a client, a connection identifier is formed according to the connection request. The connection request is forwarded to a first-identified server in the cluster of servers. The connection identifier is associated with a responding server in the cluster of servers. Subsequent traffic received from the client associated with the connection identifier is forwarded to the responding server associated with the connection identifier. - The present invention is defined in the independent claims. The dependent claims define advantageous embodiments thereof.
- In one aspect, the disclosure relates to a method of maintaining routing information for a distributed service provided by a plurality of service instances. The method includes providing an address table with a number of entries less than or equal to a number of index values in a set of provisioned index values, each of the entries assigned to a respective provisioned index value and an instance of a distributed service. The method includes adding a new service instance to the address table by obtaining an assignable index value to assign to the new service instance, identifying an assigned index value that is a companion index value to the obtained index value, dividing a packet source address set associated with the companion index value into a first address subset and a second address subset, and assigning the first address subset to the service instance entry in the address table associated with the assigned companion index value and the second address subset to an entry in the address table associated with the obtained index value and the newly added service instance. The method includes obtaining an assignable index value to assign to the new service instance by performing the operations of identifying an existing, unassigned, index value in the set of provisioned index values and, when there is no unassigned index value available, increasing the number of index values in the set of provisioned index values and selecting a newly provisioned index value. In some implementations, the method includes removing a service instance from the address table by identifying a third address subset assigned to a service instance entry in the address table, associated with a first index value, for the service instance to be removed; identifying a fourth address subset assigned to a service instance entry in the address table associated with a second index value that is a companion index value to the first index value; assigning a combined address subset, which is the third address subset and the fourth address subset, to the service instance entry in the address table associated with the second index value; and clearing the service instance entry associated with the first index value from the table.
- In one aspect, the disclosure relates to a network device controller. The network device controller includes memory storing an address table with a number of entries less than or equal to a number of index values in a set of provisioned index values. Each of the entries is assigned to a respective provisioned index value and an instance of a distributed service. The network device controller includes at least one processor configured to add a new service instance to the address table by performing the operations of obtaining an assignable index value to assign to the new service instance, identifying an assigned index value that is a companion index value to the obtained index value, dividing a packet source address set associated with the companion index value into a first address subset and a second address subset, and assigning the first address subset to the service instance entry in the address table associated with the assigned companion index value and the second address subset to an entry in the address table associated with the obtained index value and the newly added service instance. The at least one processor is configured to obtain an assignable index value to assign to the new service instance by performing the operations of identifying an existing, unassigned, index value in the set of provisioned index values and, when there is no unassigned index value available, increasing the number of index values in the set of provisioned index values and selecting a newly provisioned index value. In some implementations, the at least one processor is configured to remove a service instance from the address table by performing the operations of identifying a third address subset assigned to a service instance entry in the address table, associated with a first index value, for the service instance to be removed; identifying a fourth address subset assigned to a service instance entry in the address table associated with a second index value that is a companion index value to the first index value; assigning a combined address subset, which is the third address subset and the fourth address subset, to the service instance entry in the address table associated with the second index value; and clearing the service instance entry associated with the first index value from the table.
- In one aspect, the disclosure relates to tangible computer readable storage media storing non-transient processor-executable instructions that, when executed by a computing device comprising the storage media and one or more processors, cause the one or more processors to perform the operations of storing, in computer readable memory, an address table with a number of entries less than or equal to a number of index values in a set of provisioned index values, each of the entries assigned to a respective provisioned index value and an instance of a distributed service. The instructions cause the one or more processor to add a new service instance to the address table by obtaining an assignable index value to assign to the new service instance, identifying an assigned index value that is a companion index value to the obtained index value, dividing a packet source address set associated with the companion index value into a first address subset and a second address subset, and assigning the first address subset to the service instance entry in the address table associated with the assigned companion index value and the second address subset to an entry in the address table associated with the obtained index value and the newly added service instance. The instructions cause the one or more processor to obtain an assignable index value to assign to the new service instance by performing the operations of identifying an existing, unassigned, index value in the set of provisioned index values and, when there is no unassigned index value available, increasing the number of index values in the set of provisioned index values and selecting a newly provisioned index value. In some implementations, the instructions cause the one or more processor to remove a service instance from the address table by identifying a third address subset assigned to a service instance entry in the address table, associated with a first index value, for the service instance to be removed; identifying a fourth address subset assigned to a service instance entry in the address table associated with a second index value that is a companion index value to the first index value; assigning a combined address subset, which is the third address subset and the fourth address subset, to the service instance entry in the address table associated with the second index value; and clearing the service instance entry associated with the first index value from the table.
- The above and related objects, features, and advantages of the present disclosure will be more fully understood by reference to the following detailed description, when taken in conjunction with the following figures, wherein:
-
Figure 1A is a block diagram of an example network device; -
Figure 1B is a block diagram of an example network device connecting multiple hosts for a distributed service to a broader data network; -
Figure 2 is a block diagram of example index pairings; -
Figure 3 is a diagram illustrating an example table mapping sets of addresses to service instances; -
Figure 4A is a flowchart for an example method in which a service instance is added to an address table; -
Figures 4B and 4C are diagrams illustrating examples of adding a new service instance to a table; -
Figure 5A is a flowchart for an example method in which a service instance is removed from an address table; -
Figure 5B is a diagram illustrating an example of removing a service instance from a table; and -
Figure 6 is a block diagram of a computing system in accordance with an illustrative implementation. - Like reference numbers and designations in the various drawings indicate like elements.
- Aspects and implementations of the present disclosure generally relate to load balancing. Generally, requests to a distributed service may be load balanced by routing different requests to different instances of the service. The different instances may be hosted on different physical or virtual server hosts. A network device, such as a switch or router, in a network path determines the service instance to which a particular request should be forwarded. The network device can implement a set of load-balancing rules that are applied to each incoming packet. In some implementations, all of the traffic being load-balanced arrives at the network device addressed to the same destination address, e.g., a virtual address for the distributed service. Load-balancing rules may be implemented in a manner similar to a destination-based routing table, except that the load-balancing rules route traffic based on a characteristic, such as a source address, of incoming packets that can serve as a consistent identifier. In some implementations, the load-balancing rules route data packets from a client to a particular host for an instance of the distributed service selected based on the last few (the least significant) bits of the client's 32-bit IPv4 network address. The load-balancing rules may be selected so that adding new service instances, and removing service instances, has minimal impact on the existing routes and route tables.
-
Figure 1A is a block diagram of anexample network device 130.Figure 1B is a block diagram of anexample network device 130 connecting multiple hosts 150a-150n for a distributed service to abroader data network 110. In broad overview, the illustratednetwork device 130 has acontrol module 144 and aforwarding engine 134. The control module maintains the aforementioned rules in amemory 136 for use by theforwarding engine 134 in processing data packets. Thenetwork device 130 has a plurality ofnetwork interfaces 138, with one or more of thenetwork interfaces 138 linked to other network devices in various subnets 112a-112n of adata network 110 and/or hosts 150a-150n. - In more detail, the
network device 130 participates in thedata network 110 by receiving and sending data packets via thenetwork interfaces 138. Eachnetwork interface 138 may be connected to other network devices, e.g., via a data plane. In some implementations, the connections are bi-directional data links. In some implementations, the connections are uni-directional data links, where each link is either ingress or egress. The other network devices send data packets to thenetwork device 130, which may then forward them to another network device according to its configuration (e.g. rules or routing information stored in memory 136). For example, a data packet may arrive at thenetwork device 130 via a first interface (e.g., network interface 138a), causing thenetwork device 130 to process the received data packet and (for example) forward it to an appropriate next-hop via a second interface (e.g., network interface 238b). Theforwarding engine 134 determines whichnetwork interface 138 to use to forward each data packet received. - The
data network 110 is a network facilitating interactions between computing devices. An illustrativeexample data network 110 is the Internet; however, other networks may be used. Thedata network 110 may be composed of multiple connected sub-networks 112a-112n. Thedata network 110 can be a local-area network (LAN), such as a company intranet, a metropolitan area network (MAN), a wide area network (WAN), an inter-network such as the Internet, or a peer-to-peer network, e.g., an ad hoc WiFi peer-to-peer network. Thedata network 110 may be any type and/or form of data network and/or communication network. Thedata network 110 may be public, private, or a combination of public and private networks. In general, thedata network 110 is used to convey information between computing devices, and thenetwork device 130 facilitates this communication according to its configuration. - The
network device 130 includes acontrol module 144 andmemory 136 storing configuration data, rules, and/or routing data. In some implementations, thecontrol module 144 is implemented as a special purpose circuit (e.g., an ASIC). In some implementations, thecontrol module 144 is implemented as a set of computer executable instructions stored in computer accessible memory and executed by one or more computing processors. The networkdevice control module 144 receives configuration and routing information and updates the configuration and routing data stored inmemory 136. In some implementations, thecontrol module 144 receives routing data from other network devices in thenetwork 110, e.g., using ICMP or BGP messages. In some implementations, thecontrol module 144 creates and maintains the data structures described herein, using the received routing data. In some implementations, thenetwork device 130 participates in a software-defined network ("SDN") and the networkdevice control module 144 receives configuration and routing information from an SDN controller, e.g., via a control plane. In some such implementations, thecontrol module 144 receives the load-balancing rules described herein from an SDN controller. In general, thecontrol module 144 stores these load-balancing rules in thememory 136. Theforwarding engine 134 uses the configuration and routing data inmemory 136 to manage the data traffic at thenetwork interface ports 138. - The
network device memory 136 may be any device suitable for storing computer readable data. Thememory 136 may be similar to thememory 670 orcache 675 illustrated inFigure 6 and described below. Examples include, but are not limited to, semiconductor memory devices such as EPROM, EEPROM, SDRAM, and flash memory devices. Anetwork device 130 may have any number ofmemory devices 136. - The
forwarding engine 134 uses the rules, configuration, and routing data stored inmemory 136 to manage the data traffic received at the network interfaces 138. In some implementations, theforwarding engine 134 is implemented as a special purpose circuit (e.g., an ASIC). In some implementations, theforwarding engine 134 is implemented as a set of computer executable instruction sets stored in computer accessible memory and executed by one or more computing processors. Theforwarding engine 134 extracts address information from a data packet (e.g., an IP address from a packet header) and processes it to determine how to handle the data packet (e.g., whether to forward the data packet and/or whichnetwork interface 13 8 to use for forwarding the data packet) using the load-balancing rules and methods described herein. - The load-balancing rules route traffic based on a characteristic, such as a source address, of incoming packets that can serve as a consistent identifier. In some implementations, the load-balancing rules route data packets from a client to a particular host for an instance of the distributed service selected based on the last few (the least significant) bits of the client's 32-bit IPv4 network address. In some implementations, the load-balancing rules route data packets from a client to a particular host for an instance of the distributed service selected based on an identifier made up of multiple values, e.g., a source address and TCP source port. In some implementations, sets of addresses (or identifiers) are assigned to various instances of the distributed service. In general, the size of each set (that is, the number of addresses in each set) is roughly the same as the size of any other set. In some implementations, each set of addresses is either a first size or a second size that is half the first size. As new service instances are added, the sets that are the first size are split up such that the new service instance is assigned a set of address that is half the first size.
- To achieve this distribution, a network controller treats each service instance as having a companion instance. When a new service instance is added, the network controller identifies the companion instance for the new service instance, and divides the set of addresses assigned to the companion instance into two sets, one for the preexisting companion instance and the other for the new service instance. When a service instance is removed, the network controller re-assigns the addresses for the removed service instance back to the companion instance. In some situations, the pairings between peer service instance companions is redistributed such that each service instance has a companion instance, as needed.
- Each service instance is assigned or associated with an index used in identification of a companion instance. In general, each index value is paired with a companion index based on the total number of service instances. In some implementations, the pairing is based on the number of service instances k and the largest power of two less than the number of service instances (i.e., using ρ to denote the exponent for a power of two, 2ρ < k ≤ 2 ρ+1), where k is the number of service instances after adding a service instance or before removing a service instance. In some implementations, in precise mathematical terms, for a number of service instances k, each service instance of index r (starting at 0) is paired with a companion service instance of index c, where:
-
Figure 2 is a diagram of example index pairings. Illustrated are three sets of companion maps: afirst map 220 for a set of four instances in two pairs, asecond map 230 for a set of eight instances in four pairs, and athird map 240 for a set of sixteen instances in eight pairs. These maps (220, 230, and 240) are visual examples of the pairs calculated using the above equations. For example, for a range of three to four service instances, numbered 0 through 3, thefirst map 220pairs 0 with 2 and 1 with 3. However, if a fifth instance is added (numbered 4), the range of three to four service instances is exceeded and would be expanded, e.g., to a range of five to eight service instances. Thesecond map 230 illustrates that the newly addedinstance 4 would be paired with 0, which had been paired with 2 in thefirst map 220. Additional service instances may be added, up to the new threshold of eight instances.Index number 5 is paired with 1,index 6 is paired with 2, and index 7 (corresponding to the eighth service instance) is paired with 3. If a ninth instance is added (numbered 8), the range of five to eight service instances is exceeded and would be expanded, e.g., to a range of nine to sixteen service instances. Thethird map 240 illustrates that the newly addedinstance 8 would be paired with 0, which had been paired with 2 in thefirst map 220 and with 4 in thesecond map 230. -
Figure 3 is a diagram illustrating an example address table 360 mapping sets of addresses to service instances. In broad overview, the address table 360 maps seven sets of addresses to service instances. The table 360 is illustrated with rows of example data, where each row is an example rule for a service instance, and with three columns: Index, End Bits, and Result. The "Index" corresponds to the index numbers introduced above, starting at 0. The "Result" is a value designating how packets satisfying the rule are handled, e.g., a service instance identifier or a network interface identifier for forwarding the packets to a service instance. The "End Bits" values are binary numbers; an address matches a rule if it ends with the same bits as the rule's end bits value. An "x" in the bits indicates a bit that can be either a 1 or a 0, i.e., a "don't care" bit. For example, therow 362 has an End Bits value of "x11," indicating that any address with the last two bits equal to "11" would match. No other rule in the table 360 has an End Bits value ending in 11. - As shown in
Figure 3 , the address table 360 includes entries for eight potential index value/address set pairings. These eight index values can be considered to be "provisioned" in the table. Seven of the eight entries are populated, having address sets assigned to the respective index values. One entry, associated withindex value 7, is not assigned to any address set, and thus is available for assignment. While the table may include additional entries, with index values greater than 7, such entries are not considered assignable (and thus are not shown) given the limited number of entries needed to handle the active number of service instances. After the number of active instances exceeds a threshold (typically a number equal to a power of 2), additional entries and their respective index values are provisioned, and thus are made available for assignment. - In some implementations, each address set can be defined solely by the values of the addresses' least significant bits. The value of those bits are considered to inherently serve as an index value for the set of addresses. For example, all addresses with the last four significant bits of 0101 (i.e., 5) are considered to inherently be part of the address group associated with
index number 5. Similarly, addresses with the last four significant bits of 0001, are inherently associated with theindex number 1. In such implementations, no explicit address grouping allocation is necessary, and instead relies merely on the structure of the addresses themselves. The number of bits used to define these inherent address sets depends on the number of service instances the addresses are being split between. - In some implementations, each group is defined by a network address mask in CIDR notation and the group is split by adding an address mask selected to be halfway between two address masks (e.g., an average). Any approach may be used to describe the set of addresses associated with each service instance and to divide the set of addresses into smaller subsets.
-
Figure 4A is a flowchart for an example method in which a service instance is added to an address table. In broad overview, amethod 400 begins with a network device obtaining an assignable index value to assign to a new service instance (stage 410). The network device then identifies an assigned index value that is a companion index value to the obtained index value (stage 420) and divides a packet source-address set associated with the companion index value into a first address subset and a second address subset (stage 430). The network device assigns the first address subset to the service instance entry in the address table associated with the assigned companion index value (stage 440) and assigns the second address subset to an entry in the address table associated with the obtained index value and the newly added service instance (stage 450). - In more detail, the
method 400 begins with a network device (e.g., thenetwork device 130, illustrated inFigure 1A ) obtaining an assignable index value to assign to a new service instance (stage 410). The network device obtains an assignable index value by identifying an existing, unassigned index value in a set of provisioned index values. Index values are said to be provisioned if they are already assigned or are available for assignment. If there are no existing, unassigned, index values in the set of provisioned index values, the network device increases the number of index values in the set of provisioned index values and selects a newly provisioned index value. In some implementations, the network device increases the number of index values by doubling the number of index values provisioned and re-determining the pairing between service instance companions based on the new number of index values provisioned. - The network device then identifies an assigned index value that is a companion index value to the obtained index value (stage 420). As introduced above, in some implementations, the companion index value for a given index value is function of the given index value. That is, the companion index value c is determined as: c = r + 2ρ modulo 2 ρ+1 , where r is the given index value and ρ is the exponent for the largest power of two less than or equal to the highest index value in use (that is, ρ = └log 2 k-1┘, where kis the total number of service instances and index values start at zero).
- The network device divides a packet source-address set associated with the companion index value into a first address subset and a second address subset (stage 430). In some implementations, the division is equal, such that the first address subset and the second address subset are of the same size. As described above, addresses can be grouped into subsets sharing a common set of End Bits and "not caring" about the values of any higher order bits in the address (these "don't care" bits may be expressed as "x" bits). Such a grouping can be effectively split in half by increasing by one the number of bits in the set of End Bits that are specifically defined (i.e., which are not x bits). By the nature of the binary number system, the value of this bit for half of the addresses in the prior grouping will be 0 and for the other half will be 1. Thus a set of addresses can be split by converting the lowest order x bit in the End Bits to a 0 or a 1 and adding a corresponding new entry to the table where that bit is set to the other of 0 or 1. For example, a set of addresses defined by End bits xx001 can be split evenly into two groups with End Bits x0001 and x1001.
- The network device then assigns the first address subset to the service instance entry in the address table associated with the assigned companion index value (stage 440) and assigns the second address subset to an entry in the address table associated with the obtained index value and the newly added service instance (stage 450). In some implementations, modifications to the address table can be limited under some situations to only modifying the entry in the address table at
stage 440 and adding a new entry atstage 450. This enables a low impact change. -
Figures 4B and 4C are diagrams illustrating examples of adding a new service instance to a table mapping sets of addresses to service instances. In broad overview, inFigure 4B , the address table 360 first illustrated inFigure 3 is modified to become an address table 370, which maps eight sets of address to service instances. Likewise, inFigure 4C , the address table 370, which maps, eight sets of addresses to service instances is modified to become an address table 380, mapping nine sets of address to service instances.Figure 4B illustrates a scenario wherein there is an available assignable index.Figure 4C illustrates a scenario wherein there is no available assignable index. - In
Figure 4B , the address table 360 mapping seven sets of addresses to service instances is modified to become the address table 370 mapping eight sets of address to service instances. In more detail, a service instance "H" is added (e.g., using the method described above in reference toFigure 4A ). The new service instance is assignedindex 7, which has a companion index of 3. Theentry 462 forindex 3 is a rule for addresses with the last two bits equal to "11." The table 360 is modified to become a table 370 with the new rule, in which theentry 474 forindex 3 is a rule for addresses with the last three bits equal to "011" and theentry 476 forindex 7 is a rule for addresses with the last three bits equal to "111." - In some implementations, when new indices are provisioned, the number of index values provisioned brings the total number of provisioned index values up the next highest power of 2. Thus, when a fifth index is provisioned (exceeding 22), an additional four index values are provisioned to bring the total number of provisioned index values up to 8, i.e., 23. When a ninth index value is needed, 8 additional index values are provisioned, bringing the total number to 16, i.e., 24, and so forth. In this case, adding an eighth service instance does not require a total number of provisioned index values to exceed a power of 2, and thus no new index values are needed or provisioned.
- In
Figure 4C , the address table 370, which maps eight sets of addresses to service instances is modified to become an address table 380, mapping nine sets of address to service instances. In more detail, a service instance "J" is added (e.g., using the method described above in reference toFigure 4A ). The new service instance is assignedindex 8, which has a companion index of 0. Theentry 472 forindex 0 is a rule for addresses with the last three bits equal to "000." The table 370 is modified to become a table 380 with the new rule, in which theentry 484 forindex 0 is a rule for addresses with the last four bits equal to "0000" and theentry 486 forindex 8 is a rule for addresses with the last four bits equal to "1000." As indicated above, in some implementations, the number of indices provisioned at any given time is equal to a power of 2. Thus, adding a ninth service instance (9 being one greater than 23) requires the provisioning of additional index values. When provision the ninth index value, an additional seven index values are provisioned, as well, taking the total number of provisioned index values up to 16. - If a service instance is removed, e.g., using the method described below in reference to
Figure 5 , then the address table is updated to re-combine the set of addresses for the removed service instance and its companion instance. If the removed service instance does not have a companion instance (e.g., "D" atindex 3 in the table 380, illustrated inFigure 3B ) then the table may need to be rebuilt. Otherwise, only the rules for the removed service instance and its companion need to be updated. Thus, the number of entries that need to be modified for a topology change is minimal. -
Figure 5A is a flowchart for an example method in which a service instance is removed from a table. In broad overview, themethod 500 begins with a network device identifying a first address subset assigned to a service instance entry in the address table, associated with a first index value, for a service instance to be removed (stage 510). The network device identifies a second address subset assigned to a service instance entry in the address table associated with a second index value that is a companion index value to the first index value (stage 520) and assigns a combined address subset to the service instance entry in the address table associated with the second index value (stage 530). The network device can then clear the service instance entry associated with the first index value from the table (stage 540). - In more detail, the
method 500 begins with a network device identifying a first address subset assigned to a service instance entry in the address table, associated with a first index value, for a service instance to be removed (stage 510). A service instance may be removed, for example, in the event of a service failure, a host failure, or a communication link failure. If the distributed service is underutilized, one or more service instances may be shut down to consolidate service load. - The network device identifies a second address subset assigned to a service instance entry in the address table associated with a second index value that is a companion index value to the first index value (stage 520). As introduced above, in some implementations, the companion index value for a given index value is function of the given index value. That is, the companion index value c is determined as: c = r + 2ρ modulo 2 ρ+1, where r is the given index value and ρ is the exponent for the largest power of two less than or equal to the highest index value in use (that is, ρ = └log 2 k-1┘, where k is the total number of service instances prior to removing the service instance and index values start at zero).
- The network device then assigns a combined address subset to the service instance entry in the address table associated with the second index value (stage 530) and clears the service instance entry associated with the first index value from the table (stage 540). In some implementations, the network device uses the lower value of the second index value and the first index value when assigning the combined address subset to a service instance entry in the address table. In some implementations, the combined address subset is created by transitioning a bit from each of the sub-groups being merged into a "don't care" bit (indicated with an x in
Figure 5B ). - Thus, as described above, in some implementations where the number of service instances (k) is a power of two (k = 2ρ ), the distribution is fair in that each service instance is associated with the same number (1/k) of the source addresses. Where the number of service instances (k) is between two powers of two (2 ρ < k < 2 ρ+1 ), in some implementations, there is some imbalance in the distribution-some service instances will be associated with a number of addresses that is twice the number associated with other service instances. In particular, the percentage of addresses (1/2 ρ+1 ) assigned to 2(k-2 ρ ) service instances will be half the percentage of addresses (1/2 ρ ) assigned to the remaining 2 ρ+1 -k service instances.
- In
Figure 5B , an address table 370 mapping eight sets of address to service instances is modified to become an address table 360 mapping seven sets of addresses to service instances. In more detail, a service instance "H" is removed (e.g., using the method described above in reference toFigure 5A ). The service instance being removed was assignedindex 7, which has a companion index of 3. Theentry 576 forindex 7 is a rule for addresses with the last three bits equal to "111," and theentry 574 forindex 3 is a rule for addresses with the last three bits equal to "011." The table 370 is modified to become a table 360, in which theentry 562 forindex 3 is a combined rule for addresses with the last three bits equal to "011" or "111" and there is no entry forindex 7, i.e., the rule atindex 7 has been cleared. -
Figure 6 is a block diagram of a computing system for use in implementing the computerized components described herein, in accordance with an illustrative implementation. In broad overview, the computing system includes at least oneprocessor 650 for performing actions in accordance with instructions and one ormore memory devices example computing system 610 includes one ormore processors 650 in communication, via abus 615, with at least onenetwork interface controller 620 withnetwork interface ports 622(a-n) connecting to networkdevices 612(a-n),memory 670, and anyother devices 680, e.g., an I/O interface. Generally, aprocessor 650 will execute instructions received from memory. Theprocessor 650 illustrated incorporates, or is directly connected to,cache memory 675. - In more detail, the
processor 650 may be any logic circuitry that processes instructions, e.g., instructions fetched from thememory 670 orcache 675. In many embodiments, theprocessor 650 is a microprocessor unit or special purpose processor. Thecomputing device 610 may be based on any processor, or set of processors, capable of operating as described herein. Theprocessor 650 may be a single core or multi-core processor. Theprocessor 650 may be multiple processors. - The
memory 670 may be any device suitable for storing computer readable data. Thememory 670 may be a device with fixed storage or a device for reading removable storage media. Examples include all forms of non-volatile memory, media and memory devices, semiconductor memory devices (e.g., EPROM, EEPROM, SDRAM, and flash memory devices), magnetic disks, magneto optical disks, and optical discs (e.g., CD ROM, DVD-ROM, and Blu-Ray® discs). Acomputing system 610 may have any number ofmemory devices 670. - The
cache memory 675 is generally a form of computer memory placed in close proximity to theprocessor 650 for fast read times. In some implementations, thecache memory 675 is part of, or on the same chip as, theprocessor 650. In some implementations, there are multiple levels ofcache 675, e.g., L2 and L3 cache layers. - The
network interface controller 620 manages data exchanges via the network interfaces 622(a-n) (also referred to as network interface ports). Thenetwork interface controller 620 handles the physical and data link layers of the OSI model for network communication. In some implementations, some of the network interface controller's tasks are handled by theprocessor 650. In some implementations, thenetwork interface controller 620 is part of theprocessor 650. In some implementations, acomputing system 610 has multiplenetwork interface controllers 620. The network interfaces 622(a-n) are connection points for physical network links. In some implementations, thenetwork interface controller 620 supports wireless network connections and aninterface port 622 is a wireless receiver/transmitter. Generally, acomputing device 610 exchanges data withother computing devices 612(a-n) via physical or wireless links to anetwork interface 622(a-n). In some implementations, thenetwork interface controller 620 implements a network protocol such as Ethernet. - The
other computing devices 612(a-n) are connected to thecomputing device 610 via anetwork interface port 622. Theother computing devices 612(a-n) may be peer computing devices, network devices, or any other computing device with network functionality. For example, afirst computing device 612(a) may be a network device such as a hub, a bridge, a switch, or a router, connecting thecomputing device 610 to a data network such as the Internet. - The
other devices 680 may include an I/O interface, external serial device ports, and any additional co-processors. For example, acomputing system 610 may include an interface (e.g., a universal serial bus (USB) interface) for connecting input devices (e.g., a keyboard, microphone, mouse, or other pointing device), output devices (e.g., video display, speaker, or printer), or additional memory devices (e.g., portable flash drive or external media drive). In some implementations, acomputing device 610 includes anadditional device 680 such as a co-processor, e.g., a math co-processor can assist theprocessor 650 with high precision or complex calculations. - Implementations of the subject matter and the operations described in this specification can be implemented in digital electronic circuitry, or in computer software embodied on a tangible medium, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them. Implementations of the subject matter described in this specification can be implemented as one or more computer programs embodied on a tangible medium, i.e., one or more modules of computer program instructions, encoded on one or more computer storage media for execution by, or to control the operation of, a data processing apparatus. A computer storage medium can be, or be included in, a computer-readable storage device, a computer-readable storage substrate, a random or serial access memory array or device, or a combination of one or more of them. The computer storage medium can also be, or be included in, one or more separate components or media (e.g., multiple CDs, disks, or other storage devices). The computer storage medium may be tangible and non-transitory.
- The operations described in this specification can be implemented as operations performed by a data processing apparatus on data stored on one or more computer-readable storage devices or received from other sources.
- A computer program (also known as a program, software, software application, script, or code) can be written in any form of programming language, including compiled or interpreted languages, declarative or procedural languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, object, or other unit suitable for use in a computing environment. A computer program may, but need not, correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data (e.g., one or more scripts stored in a markup language document), in a single file dedicated to the program in question, or in multiple coordinated files (e.g., files that store one or more modules, sub programs, or portions of code). A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network. Examples of communication networks include a local area network ("LAN") and a wide area network ("WAN"), an inter-network (e.g., the Internet), and peer-to-peer networks (e.g., ad hoc peer-to-peer networks).
- The processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform actions by operating on input data and generating output. The processes and logic flows can also be performed by, and apparatus can also be implemented as, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application specific integrated circuit).
- While this specification contains many specific implementation details, these should not be construed as limitations on the scope of any inventions or of what may be claimed, but rather as descriptions of features specific to particular implementations of particular inventions. Certain features that are described in this specification in the context of separate implementations can also be implemented in combination in a single implementation. Conversely, various features that are described in the context of a single implementation can also be implemented in multiple implementations separately or in any suitable sub-combination. Moreover, although features may be described above as acting in certain combinations and even initially claimed as such, one or more features from a claimed combination can in some cases be excised from the combination, and the claimed combination may be directed to a sub-combination or variation of a sub-combination.
- Similarly, while operations are depicted in the drawings in a particular order, this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order, or that all illustrated operations be performed, to achieve desirable results. In certain circumstances, multitasking and parallel processing may be advantageous. Moreover, the separation of various system components in the implementations described above should not be understood as requiring such separation in all implementations, and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.
- References to "or" may be construed as inclusive so that any terms described using "or" may indicate any of a single, more than one, and all of the described terms. The labels "first," "second," "third," an so forth are not necessarily meant to indicate an ordering and are generally used merely to distinguish between like or similar items or elements.
- Thus, particular implementations of the subject matter have been described. Other implementations are within the scope of the following claims. In some cases, the actions recited in the claims can be performed in a different order and still achieve desirable results. In addition, the processes depicted in the accompanying figures do not necessarily require the particular order shown, or sequential order, to achieve desirable results. In certain implementations, multitasking or parallel processing may be utilized.
Claims (14)
- A method of maintaining routing information for a distributed service provided by a plurality of service instances, comprising:providing an address table (360) including a set of entries, wherein:the address table has a number of entries less than or equal to a number of index values in a set of provisioned index values, and wherein each of the entries is assigned to a respective provisioned index value and an instance of the distributed service; andadding a new service instance to the address table (400) by:obtaining, by a network device controller (144, 650), an assignable index value to assign to the new service instance (410) by 1) identifying an existing, unassigned, index value in the set of provisioned index values, or by 2) increasing the number of index values in the set of provisioned index values and selecting a newly provisioned index value;identifying, by the network device controller, an assigned index value that is a companion index value to the obtained index value (420);dividing, by the network device controller, a packet source address set associated with the companion index value into a first address subset and a second address subset (430); andassigning, by the network device controller, the first address subset to the service instance entry in the address table associated with the assigned companion index value (440) and the second address subset to an entry in the address table associated with the obtained index value and the newly added service instance (450).
- The method of claim 1, further comprising:removing a service instance from the address table (500) by:identifying, by the network device controller (144, 650), a third address subset assigned to a service instance entry in the address table, associated with a first index value, for the service instance to be removed (510);identifying, by the network device controller, a fourth address subset assigned to a service instance entry in the address table associated with a second index value that is a companion index value to the first index value (520);assigning, by the network device controller, a combined address subset, comprising the third address subset and the fourth address subset, to the service instance entry in the address table associated with the second index value (530); andclearing, by the network device controller, the service instance entry associated with the first index value from the table (540).
- The method of claim 2, further comprising:determining, by the network device controller, that the first index value is less than the second index value;changing, by the network device controller, the association for the service instance entry in the address table, associated with the second index value, from an association with the second index value to an association with the first index value.
- The method of claim 1, comprising generating the address table.
- A network device (130, 610) controller comprising:memory (136, 670, 675) storing an address table (360) including a set of entries, wherein the address table has a number of entries less than or equal to a number of index values in a set of provisioned index values, and wherein each of the entries is assigned to a respective provisioned index value and an instance of a distributed service provided by a plurality of service instances; andat least one processor (144, 650), the at least one processor configured to add a new service instance to the address table by performing the operations of:obtaining an assignable index value to assign to the new service instance by 1) identifying an existing, unassigned, index value in the set of provisioned index values, or by 2) increasing the number of index values in the set of provisioned index values and selecting a newly provisioned index value;identifying an assigned index value that is a companion index value to the obtained index value;dividing a packet source address set associated with the companion index value into a first address subset and a second address subset; andassigning the first address subset to the service instance entry in the address table associated with the assigned companion index value and the second address subset to an entry in the address table associated with the obtained index value and the newly added service instance.
- The network device controller (130, 610) of claim 5, wherein
the at least one processor is further configured to remove a service instance from the address table by performing the operations of:identifying a third address subset assigned to a service instance entry in the address table, associated with a first index value, for the service instance to be removed;identifying a fourth address subset assigned to a service instance entry in the address table associated with a second index value that is a companion index value to the first index value;assigning a combined address subset, comprising the third address subset and the fourth address subset, to the service instance entry in the address table associated with the second index value; andclearing the service instance entry associated with the first index value from the table. - The network device controller (130, 610) of claim 6, wherein the at least one processor is further configured to perform the operations of:determining that the first index value is less than the second index value;changing the association for the service instance entry in the address table, associated with the second index value, from an association with the second index value to an association with the first index value.
- The network device (130, 610) controller of claim 5, wherein the at least one processor is further configured to generate the address table.
- Tangible computer readable media storing instructions which, when executed by one or more computing processors, cause the one or more computing processors to:provide an address table including a set of entries, wherein:the address table has a number of entries less than or equal to a number of index values in a set of provisioned index values, and wherein each of the entries is assigned to a respective provisioned index value and an instance of a distributed service; andadd a new service instance to the address table by:obtaining an assignable index value to assign to the new service instance by 1) identifying an existing, unassigned, index value in the set of provisioned index values, or by 2) increasing the number of index values in the set of provisioned index values and selecting a newly provisioned index value;identifying, by the network device controller, an assigned index value that is a companion index value to the obtained index value;dividing a packet source address set associated with the companion index value into a first address subset and a second address subset; andassigning the first address subset to the service instance entry in the address table associated with the assigned companion index value and the second address subset to an entry in the address table associated with the obtained index value and the newly added service instance.
- The computer readable media of claim 9, the instructions comprising instructions to cause the one or more processors to
remove a service instance from the address table by:identifying a third address subset assigned to a service instance entry in the address table, associated with a first index value, for the service instance to be removed;identifying a fourth address subset assigned to a service instance entry in the address table associated with a second index value that is a companion index value to the first index value;assigning a combined address subset, comprising the third address subset and the fourth address subset, to the service instance entry in the address table associated with the second index value; andclearing the service instance entry associated with the first index value from the table. - The computer readable media of claim 10, the instructions comprising instructions to cause the one or more processors to:determine that the first index value is less than the second index value;change the association for the service instance entry in the address table, associated with the second index value, from an association with the second index value to an association with the first index value.
- The method of claim 1, the network device controller of claim 5 or the computer readable media of claim 9, wherein the number of provisioned index values in the set of provisioned index values is a power of two.
- The method, the network device controller or the computer readable media of claim 12, wherein increasing the number of index values in the set of provisioned index values comprises doubling the number of provisioned index values.
- The method, the network device controller or the computer readable media of claim 12, wherein identifying a companion index value for a particular index value comprises adding half the number of provisioned index values in the set of provisioned index values to the particular index value, modulo the number of provisioned index values in the set of provisioned index values.
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/169,776 US9391884B2 (en) | 2014-01-31 | 2014-01-31 | Consistent hashing using exact matching with application to hardware load balancing |
PCT/US2014/064823 WO2015116291A1 (en) | 2014-01-31 | 2014-11-10 | Consistent hashing using exact matching with application to hardware load balancing |
Publications (2)
Publication Number | Publication Date |
---|---|
EP3100436A1 EP3100436A1 (en) | 2016-12-07 |
EP3100436B1 true EP3100436B1 (en) | 2018-02-21 |
Family
ID=52011301
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
EP14808761.2A Active EP3100436B1 (en) | 2014-01-31 | 2014-11-10 | Maintaining routing information for a distributed service provided by service instances |
Country Status (5)
Country | Link |
---|---|
US (1) | US9391884B2 (en) |
EP (1) | EP3100436B1 (en) |
CN (1) | CN106063228B (en) |
DE (1) | DE202014010912U1 (en) |
WO (1) | WO2015116291A1 (en) |
Families Citing this family (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9886740B2 (en) * | 2014-05-14 | 2018-02-06 | Intel Corporation | Degradation coverage-based anti-aliasing |
CN109688191B (en) * | 2018-10-24 | 2021-02-12 | 华为技术有限公司 | Traffic scheduling method and communication device |
CN109167696A (en) * | 2018-11-13 | 2019-01-08 | 京信通信系统（中国）有限公司 | A kind of monitoring method and device |
US11233824B2 (en) * | 2020-04-06 | 2022-01-25 | Vmware, Inc. | Site aware policy-based proximity routing and policy-based proximity routing |
CN113014489B (en) * | 2020-12-31 | 2022-02-22 | 腾讯科技（深圳）有限公司 | Data forwarding method and device, server and storage medium |
Family Cites Families (17)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6185619B1 (en) | 1996-12-09 | 2001-02-06 | Genuity Inc. | Method and apparatus for balancing the process load on network servers according to network and serve based policies |
US6363077B1 (en) | 1998-02-13 | 2002-03-26 | Broadcom Corporation | Load balancing in link aggregation and trunking |
US6434115B1 (en) * | 1998-07-02 | 2002-08-13 | Pluris, Inc. | System and method for switching packets in a network |
US6556541B1 (en) | 1999-01-11 | 2003-04-29 | Hewlett-Packard Development Company, L.P. | MAC address learning and propagation in load balancing switch protocols |
US6424650B1 (en) * | 1999-02-09 | 2002-07-23 | 3Com Corporation | Network address filter device |
US6742045B1 (en) * | 1999-07-02 | 2004-05-25 | Cisco Technology, Inc. | Handling packet fragments in a distributed network service environment |
US6667980B1 (en) * | 1999-10-21 | 2003-12-23 | Sun Microsystems, Inc. | Method and apparatus for providing scalable services using a packet distribution table |
US6807172B1 (en) * | 1999-12-21 | 2004-10-19 | Cisco Technology, Inc. | Method and apparatus for learning and switching frames in a distributed network switch |
US6735198B1 (en) * | 1999-12-21 | 2004-05-11 | Cisco Technology, Inc. | Method and apparatus for updating and synchronizing forwarding tables in a distributed network switch |
DE10143754A1 (en) * | 2001-09-06 | 2003-04-03 | Siemens Ag | Scalable peer-to-peer network with a directory service |
US20050165885A1 (en) * | 2003-12-24 | 2005-07-28 | Isaac Wong | Method and apparatus for forwarding data packets addressed to a cluster servers |
US20070076709A1 (en) * | 2005-07-01 | 2007-04-05 | Geoffrey Mattson | Apparatus and method for facilitating a virtual private local area network service with realm specific addresses |
US20090113021A1 (en) * | 2007-10-24 | 2009-04-30 | Telefonaktiebolaget Lm Ericsson (Publ) | System and method for generating functional addresses |
US8908527B2 (en) * | 2011-01-31 | 2014-12-09 | Cisco Technology, Inc. | Using context labels to scale MAC tables on computer network edge devices |
CN106850444B (en) | 2011-08-17 | 2020-10-27 | Nicira股份有限公司 | Logical L3 routing |
CN103731288B (en) * | 2012-10-16 | 2017-04-12 | 杭州华三通信技术有限公司 | Message forwarding method and device |
US9647941B2 (en) * | 2013-10-04 | 2017-05-09 | Avago Technologies General Ip (Singapore) Pte. Ltd. | Hierarchical hashing for longest prefix matching |
-
2014
- 2014-01-31 US US14/169,776 patent/US9391884B2/en active Active
- 2014-11-10 EP EP14808761.2A patent/EP3100436B1/en active Active
- 2014-11-10 DE DE202014010912.5U patent/DE202014010912U1/en active Active
- 2014-11-10 CN CN201480076610.8A patent/CN106063228B/en active Active
- 2014-11-10 WO PCT/US2014/064823 patent/WO2015116291A1/en active Application Filing
Also Published As
Publication number | Publication date |
---|---|
WO2015116291A1 (en) | 2015-08-06 |
CN106063228B (en) | 2019-10-18 |
CN106063228A (en) | 2016-10-26 |
US20150222532A1 (en) | 2015-08-06 |
DE202014010912U1 (en) | 2017-02-09 |
US9391884B2 (en) | 2016-07-12 |
EP3100436A1 (en) | 2016-12-07 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
EP3281369B1 (en) | Server load balancing | |
EP3018869B1 (en) | Deterministic and optimized bit index explicit replication (bier) forwarding | |
EP3100436B1 (en) | Maintaining routing information for a distributed service provided by service instances | |
US20200220807A1 (en) | Systems and methods for software defined networking service function chaining | |
DK3143734T3 (en) | METHOD AND SYSTEM FOR GENERATING A REDUCED FORWARD TABLE. | |
US10355930B2 (en) | System and method of subnetting a virtual network identifier | |
US9692695B2 (en) | Techniques for aggregating hardware routing resources in a multi-packet processor networking system | |
US9246810B2 (en) | Hash-based load balancing with per-hop seeding | |
US20160134518A1 (en) | Deterministic and optimized bit index explicit replication (bier) forwarding | |
WO2015120539A8 (en) | Method to route packets in a distributed direct interconnect network | |
US20160112299A1 (en) | Configuring forwarding information | |
US20150381478A1 (en) | Proxy for port to service instance mapping | |
WO2016036391A1 (en) | Firewall port access rule generation | |
WO2016177321A1 (en) | Packet forwarding | |
EP3113412B1 (en) | Deterministic and optimized bit index explicit replication (bier) forwarding | |
US9853903B1 (en) | Simultaneous redirecting and load balancing | |
EP3292660B1 (en) | Packet forwarding in a vxlan switch | |
US10177935B2 (en) | Data transfer system, data transfer server, data transfer method, and program recording medium | |
US20150195122A1 (en) | Method and System for Transparent Network Acceleration | |
WO2015170179A3 (en) | Method and apparatus for selecting a next hop | |
US9544226B1 (en) | Efficient address-based rule resolution in a network employing a bit-mapped index | |
CN104734984B (en) | A kind of message forwarding method and device | |
WO2017091219A1 (en) | Processing virtual local area network |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
REG | Reference to a national code |
Ref country code: DERef legal event code: R138Ref document number: 202014010912Country of ref document: DEFree format text: GERMAN DOCUMENT NUMBER IS 602014021379 |
|
PUAI | Public reference made under article 153(3) epc to a published international application that has entered the european phase |
Free format text: ORIGINAL CODE: 0009012 |
|
17P | Request for examination filed |
Effective date: 20160819 |
|
AK | Designated contracting states |
Kind code of ref document: A1Designated state(s): AL AT BE BG CH CY CZ DE DK EE ES FI FR GB GR HR HU IE IS IT LI LT LU LV MC MK MT NL NO PL PT RO RS SE SI SK SM TR |
|
AX | Request for extension of the european patent |
Extension state: BA ME |
|
DAX | Request for extension of the european patent (deleted) | ||
GRAP | Despatch of communication of intention to grant a patent |
Free format text: ORIGINAL CODE: EPIDOSNIGR1 |
|
INTG | Intention to grant announced |
Effective date: 20170821 |
|
RAP1 | Party data changed (applicant data changed or rights of an application transferred) |
Owner name: GOOGLE LLC |
|
REG | Reference to a national code |
Ref country code: HKRef legal event code: DERef document number: 1232033Country of ref document: HK |
|
GRAS | Grant fee paid |
Free format text: ORIGINAL CODE: EPIDOSNIGR3 |
|
GRAA | (expected) grant |
Free format text: ORIGINAL CODE: 0009210 |
|
AK | Designated contracting states |
Kind code of ref document: B1Designated state(s): AL AT BE BG CH CY CZ DE DK EE ES FI FR GB GR HR HU IE IS IT LI LT LU LV MC MK MT NL NO PL PT RO RS SE SI SK SM TR |
|
REG | Reference to a national code |
Ref country code: GBRef legal event code: FG4D |
|
REG | Reference to a national code |
Ref country code: CHRef legal event code: EP |
|
REG | Reference to a national code |
Ref country code: ATRef legal event code: REFRef document number: 972906Country of ref document: ATKind code of ref document: TEffective date: 20180315 |
|
REG | Reference to a national code |
Ref country code: IERef legal event code: FG4D |
|
REG | Reference to a national code |
Ref country code: DERef legal event code: R096Ref document number: 602014021379Country of ref document: DE |
|
REG | Reference to a national code |
Ref country code: NLRef legal event code: FP |
|
REG | Reference to a national code |
Ref country code: LTRef legal event code: MG4D |
|
REG | Reference to a national code |
Ref country code: ATRef legal event code: MK05Ref document number: 972906Country of ref document: ATKind code of ref document: TEffective date: 20180221 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: ESFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20180221Ref country code: LTFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20180221Ref country code: CYFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20180221Ref country code: HRFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20180221Ref country code: NOFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20180521Ref country code: FIFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20180221 |
|
REG | Reference to a national code |
Ref country code: HKRef legal event code: GRRef document number: 1232033Country of ref document: HK |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: GRFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20180522Ref country code: ATFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20180221Ref country code: LVFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20180221Ref country code: SEFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20180221Ref country code: BGFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20180521Ref country code: RSFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20180221 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: EEFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20180221Ref country code: PLFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20180221Ref country code: ITFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20180221Ref country code: ALFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20180221Ref country code: ROFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20180221 |
|
REG | Reference to a national code |
Ref country code: DERef legal event code: R097Ref document number: 602014021379Country of ref document: DE |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: DKFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20180221Ref country code: CZFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20180221Ref country code: SKFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20180221Ref country code: SMFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20180221 |
|
PLBE | No opposition filed within time limit |
Free format text: ORIGINAL CODE: 0009261 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: NO OPPOSITION FILED WITHIN TIME LIMIT |
|
26N | No opposition filed |
Effective date: 20181122 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: SIFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20180221 |
|
REG | Reference to a national code |
Ref country code: CHRef legal event code: PL |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: LUFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20181110Ref country code: MCFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20180221 |
|
REG | Reference to a national code |
Ref country code: BERef legal event code: MMEffective date: 20181130 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: LIFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20181130Ref country code: CHFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20181130 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: BEFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20181130 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: MTFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20181110 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: TRFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20180221 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: PTFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20180221 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: MKFree format text: LAPSE BECAUSE OF NON-PAYMENT OF DUE FEESEffective date: 20180221Ref country code: HUFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMIT; INVALID AB INITIOEffective date: 20141110 |
|
PG25 | Lapsed in a contracting state [announced via postgrant information from national office to epo] |
Ref country code: ISFree format text: LAPSE BECAUSE OF FAILURE TO SUBMIT A TRANSLATION OF THE DESCRIPTION OR TO PAY THE FEE WITHIN THE PRESCRIBED TIME-LIMITEffective date: 20180621 |
|
REG | Reference to a national code |
Ref country code: DERef legal event code: R079Ref document number: 602014021379Country of ref document: DEFree format text: PREVIOUS MAIN CLASS: H04L0029080000Ipc: H04L0065000000 |
|
P01 | Opt-out of the competence of the unified patent court (upc) registered |
Effective date: 20230508 |
|
PGFP | Annual fee paid to national office [announced via postgrant information from national office to epo] |
Ref country code: NLPayment date: 20231126Year of fee payment: 10 |
|
PGFP | Annual fee paid to national office [announced via postgrant information from national office to epo] |
Ref country code: GBPayment date: 20231127Year of fee payment: 10 |
|
PGFP | Annual fee paid to national office [announced via postgrant information from national office to epo] |
Ref country code: IEPayment date: 20231127Year of fee payment: 10Ref country code: FRPayment date: 20231127Year of fee payment: 10Ref country code: DEPayment date: 20231129Year of fee payment: 10 |