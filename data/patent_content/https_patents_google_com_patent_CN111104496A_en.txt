CN111104496A - Retrieving context from previous sessions - Google Patents
Retrieving context from previous sessions Download PDFInfo
- Publication number
- CN111104496A CN111104496A CN201911132153.0A CN201911132153A CN111104496A CN 111104496 A CN111104496 A CN 111104496A CN 201911132153 A CN201911132153 A CN 201911132153A CN 111104496 A CN111104496 A CN 111104496A
- Authority
- CN
- China
- Prior art keywords
- search
- query
- session
- sessions
- previous
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/33—Querying
- G06F16/3331—Query processing
- G06F16/334—Query execution
- G06F16/3344—Query execution using natural language analysis
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/24—Querying
- G06F16/245—Query processing
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/29—Geographical information databases
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/953—Querying, e.g. by the use of web search engines
- G06F16/9537—Spatial or temporal dependent retrieval, e.g. spatiotemporal queries
Abstract
Embodiments of the present invention relate to retrieving context from a previous session. And in particular to a method, system, and apparatus, including a computer program encoded on a computer storage medium, for retrieving and using contextual data from a previous conversational session in a conversational search. In one aspect, a method comprises: receiving a first query for a first user session; determining that the first query relates to one or more tags in a first repository, the first repository associating respective identifiers with respective tags, each identifier representing a corresponding user session; determining one or more specific identifiers associated with one or more tags in a first repository; retrieving the particular context data associated with the determined particular identifier in a second repository, the second repository associating the respective identifier with the respective context data associated with the corresponding user session represented by the respective identifier; and performing an action in response to the first query based on the retrieved specific context data.
Description
The present application is a divisional application of an invention patent application having an international application date of 2015, 09/06, and a chinese application number of 201510314119.0 and an invention name of "search context from previous session".
Technical Field
This specification relates to natural language processing.
Background
The internet provides access to a variety of resources, such as video files, image files, audio files, or Web pages, including content on a particular topic, book articles, or news stories. The search system may select one or more resources in response to receiving a search query. A search query is data submitted by a user to a search engine to satisfy the user's informational needs. The search query may be in the form of text, audio, or video, for example. The search system selects and scores resources to provide search results, for example, based on their association with the search query and based on their importance relative to other resources. The search results are typically sorted according to score and presented according to this order.
Disclosure of Invention
This specification describes retrieving and using context (contextual) data from previous sessions in a conversational search by: determining that the query relates to one or more tags in the index repository; determining one or more specific session identifiers associated with the tags in the index repository; retrieving, in a data repository, particular context data associated with a particular session identifier; and performing an action in response to the query based on the retrieved specific context data.
In general, one innovative aspect of the subject matter described in this specification can be embodied in methods that include the actions of: receiving a first query for a first user session; determining that the first query relates to one or more tags in a first repository, the first repository associating respective identifiers with respective tags, each identifier representing a corresponding user session; determining one or more specific identifiers associated with one or more tags in a first repository; retrieving the particular context data associated with the determined particular identifier in a second repository, the second repository associating the respective identifier with the respective context data associated with the corresponding user session represented by the respective identifier; and performing an action in response to the first query based on the retrieved specific context data.
In another general embodiment, a method may include the acts of: receiving, by one or more computers, a query for a user session; determining, by one or more computers, that the query involves a time indicator, the time indicator indicating a time earlier than the user session; determining, by one or more computers, that a query relates to one or more entry (item) tags in an index repository, the index repository associating respective user sessions with respective time tags for the user sessions and respective entry tags for queries in the user sessions; determining, by one or more computers, a plurality of candidate user sessions in an index repository, each candidate user session associated with a respective time stamp corresponding to a time indicator; determining, by the one or more computers, one or more particular user sessions associated with the one or more item tags within the determined candidate user sessions; retrieving, by the one or more computers, the particular contextual data associated with the determined particular user session in a data repository, the data repository associating the respective user session with the respective contextual data for the user session; and performing, by the one or more computers, an action in response to the query based on the retrieved specific context data.
Other embodiments of this aspect include corresponding computer systems, apparatus, and computer programs, recorded on one or more computer storage devices, each configured to perform the actions of the methods described above. For a system of one or more computers to be configured to perform a particular operation or action, it is meant that the system has installed thereon software, firmware, hardware, or a combination thereof that, when operated, causes the system to perform the operation or action. For one or more computer programs to be configured to perform particular operations or actions, it is meant that the one or more programs include instructions, which when executed by a data processing apparatus, cause the apparatus to perform the operations or actions.
Each of the above and other embodiments may optionally include one or more of the following features, either alone or in combination. For example, the conversational search system may determine, for each of the tags, a plurality of respective candidate identifiers associated with the tags in the first repository, and select a particular identifier from the determined respective candidate identifiers by determining an overlap of the determined respective candidate identifiers. Each of the specific identifiers may be associated with each of the tags in the first repository. In some cases, the one or more tags may include a time tag indicating a time earlier than the first user session. The conversational search system may determine a plurality of candidate identifiers associated with time tags in the first repository, and select one or more particular identifiers from the plurality of candidate identifiers based on remaining tags of the one or more tags.
In some examples, the one or more tags include at least one of a session tag or an entry tag. The session tag may be associated with information about a particular corresponding user session for a particular identifier. The entry tags can be associated with at least one of a particular query in a particular corresponding user session or a particular search result responsive to a particular query. The conversational search system may determine that at least one of a particular query or a particular search result relates to a particular entry corresponding to an entry tag, and may perform an action in response to the first query based on the determined particular entry. In some cases, prior to determining that the first query relates to one or more tags in the first repository, the conversational search system may determine that the first query lacks additional information needed to perform the action, and may determine that the first query is not associated with a previous query for the first user session.
In some implementations, the conversational search system receives a second query from the user for a second user session, and determines that at least one of the second query or a second search result responsive to the second query relates to a second entry in the database. The database associates respective entries with respective entry tags. The conversational search system may determine one or more second item tags associated with a second item in the database, store the second item tag in the first repository, and associate the second item tag with a second identifier representing a second user session in the first repository. In some cases, the conversational search system determines one or more second session tags for the second user session. The second session tag may include at least one of: a timestamp for the second user session, a user location for the second user session, or an action associated with the user prior to the second user session. The conversational search system may store the second session tag in the first repository and associate the second session tag with the second identifier in the first repository. In some cases, the conversational search system determines second contextual data for the second query. The second contextual data may include the second query, the second search result, and metadata associated with the second query and the second search result. The conversational search system may store the second context data in a second repository and associate the second context data with the second identifier in the second repository.
In another general embodiment, a computer-implemented method includes: receiving, by a search engine and from a speech-to-text engine, a search query based on an utterance of a user detected by a digital assistant device during a current search session; determining, by the search engine, that the search query involves a time indicator, the time indicator indicating a time earlier than the current search session; determining, by the search engine, that the search query relates to one or more other query terms; determining, by the search engine and in accordance with session data stored in a repository associated with the search engine, a first set of related previous search sessions from a second set of previous search sessions, wherein the second set of previous search sessions includes more previous search sessions than the first set of related previous search sessions, wherein each of the first set of related previous search sessions is associated with a respective timestamp corresponding to the time indicator; identifying, by the search engine, a particular prior search session from the first set of related prior search sessions determined from session data stored in a repository associated with the search engine based on the one or more other query terms associated with the search query of the current search session without searching for any prior search sessions from a second set of prior search sessions that are not in the first set of related prior search sessions; identifying, by the search engine, one or more entities associated with one or more search queries or search results of a particular previous search session based on the one or more other query terms of the search query of the current search session; and providing, from a text-to-speech engine, (i) a response to the search query, the response including representations of one or more of the entities configured to be output on a speaker of the digital assistant device in response to the search query of the current search session, and (ii) metadata related to the one or more entities configured to be rendered on a graphical user interface of the digital assistant device during outputting at least a portion of the response to the search query using the speaker of the digital assistant device.
In another general embodiment, a system includes: a data processing device; and a non-transitory computer-readable storage medium in data communication with the data processing apparatus and storing instructions executable by the data processing apparatus and that upon such execution cause the data processing apparatus to perform operations comprising: receiving, by a search engine and from a speech-to-text engine, a search query based on an utterance of a user detected by a digital assistant device during a current search session; determining, by the search engine, that the search query involves a time indicator, the time indicator indicating a time earlier than the current search session; determining, by the search engine, that the search query relates to one or more other query terms; determining, by the search engine and in accordance with session data stored in a repository associated with the search engine, a first set of related previous search sessions from a second set of previous search sessions, wherein the second set of previous search sessions includes more previous search sessions than the first set of related previous search sessions, wherein each of the first set of related previous search sessions is associated with a respective timestamp corresponding to the time indicator; identifying, by the search engine, a particular prior search session from the first set of related prior search sessions determined from session data stored in a repository associated with the search engine based on the one or more other query terms associated with the search query of the current search session without searching for any prior search sessions from a second set of prior search sessions that are not in the first set of related prior search sessions; identifying, by the search engine, one or more entities associated with one or more search queries or search results of a particular previous search session based on the one or more other query terms of the search query of the current search session; and providing, from a text-to-speech engine, (i) a response to the search query, the response including representations of one or more of the entities configured to be output on a speaker of the digital assistant device in response to the search query of the current search session, and (ii) metadata related to the one or more entities configured to be rendered on a graphical user interface of the digital assistant device during outputting at least a portion of the response to the search query using the speaker of the digital assistant device.
In another general embodiment, a non-transitory computer-readable storage medium storing instructions executable by a data processing apparatus and that upon such execution cause the data processing apparatus to perform operations comprising: receiving, by a search engine and from a speech-to-text engine, a search query based on an utterance of a user detected by a digital assistant device during a current search session; determining, by the search engine, that the search query involves a time indicator, the time indicator indicating a time earlier than the current search session; determining, by the search engine, that the search query relates to one or more other query terms; determining, by the search engine and in accordance with session data stored in a repository associated with the search engine, a first set of related previous search sessions from a second set of previous search sessions, wherein the second set of previous search sessions includes more previous search sessions than the first set of related previous search sessions, wherein each of the first set of related previous search sessions is associated with a respective timestamp corresponding to the time indicator; identifying, by the search engine, a particular prior search session from the first set of related prior search sessions determined from session data stored in a repository associated with the search engine based on the one or more other query terms associated with the search query of the current search session without searching for any prior search sessions from a second set of prior search sessions that are not in the first set of related prior search sessions; identifying, by the search engine, one or more entities associated with one or more search queries or search results of a particular previous search session based on the one or more other query terms of the search query of the current search session; and providing, from a text-to-speech engine, (i) a response to the search query, the response including representations of one or more of the entities configured to be output on a speaker of the digital assistant device in response to the search query of the current search session, and (ii) metadata related to the one or more entities configured to be rendered on a graphical user interface of the digital assistant device during outputting at least a portion of the response to the search query using the speaker of the digital assistant device.
Particular embodiments of the subject matter described in this specification can be implemented to realize one or more of the following advantages. First, the conversational search system may make conversational searches more intelligent and natural by quickly and seamlessly retrieving and using contextual data from a previous conversational search to a current conversational search. This may enhance the user experience. For example, a conversational search system allows a partial task to complete and start from where the user previously left. Second, the conversational search system may determine relevant prior searches based on little, limited, or partial information in the user's memory, which minimizes user input and assists the user in searching. Third, the conversational search system may efficiently provide a quick response, for example, by: associating short conversational sessions with session tags (e.g., time tags, user location tags, user action tags, and/or co-presence information tags) and/or entry tags in an index repository; and searches the index repository for relevant conversational sessions based on the query segment corresponding to the token, rather than searching all previous queries and answers (which may produce a large number of false matches at the time of retrieval). For example, a clue (keyed) may be provided to the index repository by the user's location when the user makes a query, which may be used later, e.g., "what restaurants i talk about when i am in san francisco today? ". Clues may be provided to the index repository through entity annotations, such as "what books i talk about in the morning today? ". The user may have used the title in a previous query without mentioning the word "book" and the conversational search system may determine the word "book" based on the entity annotation. Clues may also be provided to the index repository by attributes of the entity (e.g., address of restaurant) and other metadata of the entity (e.g., customer rating of restaurant). Fourth, the conversational search system may achieve high accuracy and reliability by, for example, determining entry markers for entries, such as entities, based on an annotation database that stores millions of entries and associated entry markers. Fifth, the conversational search system may be extensible to any suitable language, including English.
The details of one or more embodiments of the subject matter described in this specification are set forth in the accompanying drawings and the description below. Other features, aspects, and advantages of the subject matter will become apparent from the description, the drawings, and the claims.
Drawings
FIG. 1A is a block diagram of an environment in which a search engine retrieves and uses contextual data from previous sessions in a conversational search;
FIG. 1B is a pictorial illustration of a conversational search in an example search conversational user interface;
2A-2C are flowcharts of an example process for storing and indexing context data for entry tags and user sessions; and
3A-3B are flow diagrams of example processes for retrieving and using contextual data from a previous session in a conversational search.
Like reference numbers and designations in the various drawings indicate like elements.
Detailed Description
FIG. 1A is a block diagram of an example environment 100 in which a search engine 110 provides a conversational search service. The search engine 110 enables retrieval and use of contextual data associated with previous user sessions in a conversational search. The search engine 110 stores and indexes previous user sessions associated with tags in the index repository. When a query is received in a new conversational search, the search engine 110 determines that the query involves one or more tags (e.g., time tags) in the index repository, and then determines one or more previous sessions that were indexed using the tags. The search engine 110 then retrieves contextual data associated with the determined previous session, for example, in a data repository, and performs an action in response to the query based on the retrieved contextual data.
A computer network 102, such as a Local Area Network (LAN), Wide Area Network (WAN), the internet, or a combination thereof, connects the publisher web site 104, the user devices 106, and the search engine 110. The online environment 100 may include thousands of publisher websites 104 and user devices 106.
The publisher website 104 includes one or more resources 105 associated with a domain and hosted by one or more servers at one or more locations. Generally, a website is a collection of web pages formatted in hypertext markup language (HTML) that may contain text, images, multimedia content, and programming elements (e.g., scripts). Each publisher web site 104 is maintained by a content publisher, which is an entity that controls, manages, and/or owns the publisher web site 104.
A resource is any data that may be provided by the publisher web site 104 over the network 102 and has a resource address, such as a Uniform Resource Locator (URL). The resource 105 may be an HTML page, an electronic document, an image file, a video file, an audio file, a seed source, and the like. The resources may include embedded information (e.g., meta information and hyperlinks) and/or embedded instructions (e.g., client-side scripts).
An example user device 106 may be capable of requesting and receiving resources over the network 102. Example user devices 106 may include personal computers, mobile communication devices, smart phones, tablets, TVs, set-top boxes (STBs), multi-mode devices such as wearable computing devices, e.g., google glass, hybrid gesture recognition/voice recognition systems (e.g., Xbox/Kinect), automotive information systems, general home entertainment systems, and other devices that can send and receive data over the network 102. The user devices 106 typically include a user application (e.g., a web browser) to facilitate sending and receiving data over the network 102. A web browser may enable a user to display and interact with text, images, video, audio, music, and other information typically located on web pages of web sites of the world wide web or local area networks. The user device 106 may include a microphone and/or a speaker for playing voice that enables a user to record voice queries or to audibly input voice queries.
To facilitate searching these resources 105, the search engine 110 identifies the resources by searching (crawl) the publisher sites 104 and indexing the resources 105 provided by the publisher sites 104. The resources 105 are indexed and the index data is stored in the resource index 112.
The user device 106 submits a search query 109 to a search engine 110. The search query 109 may be in the form of a text query, a voice query (e.g., via a microphone in the user device 106), a picture query, a video query, and so forth. The search query 109 is submitted in the form of a search request, the search query 109 comprising the search request and optionally a unique identifier identifying the user device 106 that submitted the request. The unique identifier may be data from a short piece of textual information (cookie) stored at the user device, or a user account identifier if the user maintains an account with the search engine 110, or some other identifier that identifies the user device 106 or the user using the user device.
In response to a search request, the search engine 110 uses the resource index 112 to identify resources relevant to the query. The search engine 110 identifies resources in the form of search results and returns the search results to the user device 106 in a search results page resource 111. Search results are data generated by the search engine 110 that identifies resources satisfying a particular search query or that provides information satisfying a particular search query. The search results for the resource may include a web page title, a small piece of text extracted from the web page, and a resource locator for the resource (e.g., a URL of the web page).
The search results are ranked based on a score, such as an information retrieval ("IR") score, associated with the resource identified using the search results, and the ranking of each resource is optionally separated relative to the other resources. The search results are ranked according to the scores and the search results are provided to the user device according to this order.
The user device 106 can receive the search results page resource 111 and render the page for presentation to the user. In response to a user selecting a search result at the user device 106, the user device 106 requests the resource 105 identified by the resource locator included in the selected search result. A publisher of publisher website 104 hosting resource 105 receives a request for a resource from user device 106 and provides resource 105 to the requesting user device 106.
Search queries 109 issued from user devices 106 may be stored in query logs 116 in repository 114. The selection data for the query and the web pages referenced by the search results and selected by the user are stored in a selection log 118 in repository 114. Query log 116 and selection log 118 define search history data 119, search history data 119 including data from and relating to previous search requests associated with unique identifiers.
In some implementations, the data is associated with identifiers from the search request such that the search history for each identifier can be accessed. The selection log 118 and the query log 116 may thus be used by the search engine 110 to determine the corresponding sequence of queries submitted by the user device 106, the actions taken in response to the queries, and the frequency with which the queries are submitted.
In cases where the system discussed herein collects personal information about a user or personal information may be used, the user may be provided with an opportunity to control whether programs or features collect user information (e.g., information about the user's social network, social actions or activities, profession, the user's preferences, or the user's current location), or may be provided with an opportunity to control whether and/or how to receive content from a content server that may be more relevant to the user. Further, certain data may be processed in one or more ways before it is stored or used, such that personally identifiable information is removed. For example, the identity of the user may be treated so that no personally identifiable information can be determined for the user, or the user's geographic location (such as to a city, zip code, or state level) at which location information is obtained may be summarized so that a particular location of the user cannot be determined. Thus, the user may control how information is collected about the user and how the content server uses the information.
Each user session may be assigned a unique Identifier (ID) representing the user session, such as a number identifier, an alphabetic identifier, a combination thereof, or the like. The search engine 110 associates the respective identifier with the respective context data of the user session represented by the identifier in the session data repository 122. Thus, the search engine 110 may retrieve particular contextual data for a particular user session by: a specific identifier for a specific user session is determined and specific context data is sought in the session data repository 122 using the specific identifier.
In some implementations, the user session is defined using a time interval (e.g., 30 seconds, 60 seconds, or 120 seconds) for sequencing the search query. The search engine 110 determines whether sequential search queries are received within a time interval and determines whether the sequential search queries are associated with each other. The length of the user session may depend on the time period for receiving the associated sequence query in the user session. Assume that the specific time period is 60 seconds. In this case, the user session may have a longer duration (e.g., 5 minutes) or a shorter duration (e.g., 40 seconds).
In some examples, the search engine 110 determines whether the query is associated with a previous query by: determining whether the query is an incomplete query lacking additional information needed to perform an action in response to the query and/or determining whether the additional information can be obtained from context data associated with a previous query. If the search engine 110 determines that the query provides additional information for an incomplete query and/or context data for a previous query, the search engine determines that the query is associated with the previous query.
In some examples, the search engine 110 determines whether the query is associated with a previous query by: it is determined whether the query or search results responsive to the query include explicit or implicit references to previous queries. In a particular example, if the previous query relates to an entity and the query includes a corresponding pronoun for the entity, the search engine 110 determines that the query is associated with the previous query. In another particular example, if the query has the same intent as the previous query (e.g., using a template as described further below), the search engine 110 determines that the query is associated with the previous query.
In some cases, if a query is received within a time interval after receiving a previous query and the query is determined to be associated with the previous query, then the query is determined to be in the same user session as the previous query. If a query is received within a time interval but the query is determined to be unassociated with a previous query, the query is determined not to be in the same user session as the previous query. If a query is not received within a time interval after a previous query, it is determined that the query is not in the same user session as the previous query. Upon determining that the query is not in the same user session as the previous query, the search engine 110 may determine that the user session for the previous query is over and associate the query with the new user session.
In some implementations, a user session is defined as a series of search queries from the same user device or the same device identifier within a certain period of time (e.g., 1 minute, 2 minutes, or 5 minutes) after the user session begins (e.g., when the first one of the queries is received). The search engine 110 may determine whether the series of search queries are associated with each other.
In some cases, the search engine 110 determines that a second query of the queries is associated with the user session if the second query is associated with the first query or a previous query of the user session. If a second query of the queries is not associated with the first query or a previous query, the search engine 110 determines that the second query is not associated with the user session. In some cases, a user session may include one or more sub-sessions. Each sub-session may be assigned a unique identifier. Queries within a sub-session are associated with each other. Queries in the same sub-session may or may not be sequential. A query in a sub-session may be unassociated with a query in another sub-session.
In some implementations, the search engine 110 includes an annotation database 120 in the repository 114. The annotation database 120 stores information relating to a large number of entries (e.g., entities, events, or actions). A large number of entries may be stored under different categories or collections (e.g., collections/people, collections/businesses, collections/flights, collections/games, or collections/actions) in the annotation database 120. In some implementations, the annotation database 120 is hosted in a server external to the search engine 110. The search engine 110 may communicate with the annotation database 120 via the network 102 or any suitable data communication channel.
The annotation database 120 associates each entry with one or more entry tags, labels, or annotations. The item tag may be associated with a property or attribute of the item. For example, if an item relates to a person (e.g., "Lady Gaga"), the item tags associated with the person may include professional tags (e.g., "musicians," "composers," and/or "popular singers"), national tags (e.g., "americas"), or gender tags ("women"). If the item relates to a book (e.g., "rich dad port dad"), the item tag associated with the book may include a category tag (e.g., "book"), an author tag (e.g., "robert. If the item relates to a restaurant (e.g., "GaryDanko"), the item label associated with the restaurant may include a category label ("restaurant"), a street label (e.g., "Point street"), a city label (e.g., "san francisco"), or a cuisine type label (e.g., "french").
Two entries may have the same value for a first object label but different values for a second, different object label. For example, the entry relates to restaurant "Zuni cafe". The entry "Zuni Caf" has the same category label "restaurant" as the entry "Gary Danko", but has a street label "market Avenue" that is different from the street label "point Avenue" for the entry "Gary Danko".
After receiving the search query 109 for the user session from the user device 106, the search engine 110 may determine that the search query 109 relates to an entry and search for the entry in the annotation database 120. In some cases, the search engine 110 determines that an entry is found within the annotation database 120. Search engine 110 may determine one or more item tags associated with the items and associate the determined item tags with search query 109 and/or the user session, e.g., in repository 114.
In some cases, the search engine 110 determines that the entry to which the search query 109 relates is not found in the annotation database 120. The search engine 110 may, for example, search the network 102 for information about the item and determine one or more item tags for the item. The entry tag may be determined based on criteria of the annotation database 120 that define the entry tag for the entry. For example, the criteria for an entry "book" may define the corresponding entry tag as a category tag, an author tag, a publisher tag, and so on. The search engine 110 may then determine the value of the corresponding entry tag for the entry. The search engine 110 may, for example, automatically or after precise validation, submit the entry and the determined entry tag to update the annotation database 120. In some cases, the annotation database 120 is manually updated, for example, by a system administrator, using the entries and associated entry tags.
In some implementations, search engine 110 includes a session index repository 124 in repository 114. The session index repository 124 associates the respective identifier for the user session with the respective entry tag and/or entry for the user session, i.e., the session index repository 124 maps the entry tag to the identifier for the user session. The item tag and/or the item may be associated with or mapped to one or more identifiers. The identifier may be associated with or mapped to one or more entry tags or entries. Based on the association or mapping in the session index repository 124, the search engine 110 may determine one or more particular identifiers based on one or more particular entry tags and/or particular entries.
In some examples, after receiving the search query 109 for the user session from the user device 106, the search engine 110 may determine the search query 109 or that the search results responsive to the search query 109 relate to an entry, for example, by parsing the search query 109 based on the grammar rules and/or the annotation database 120.
In some cases, the search results responsive to the query correspond to answers responsive to the query or answers to the query. For example, assume that the search query 109 is "which restaurant is the best french restaurant in san francisco," and the search engine 110 determines that the search result is "Gary Danko. The search engine 110 may determine that the search result relates to the entry "Gary Danko".
After determining the entry, the search engine 110 may also determine whether the entry is within the annotation database 120. As a result of determining that the entry is within the annotation database 120, the search engine 110 determines one or more entry tags associated with the entry in the annotation database 120. For example, assume that the entry is "Gary Danko", as indicated above, and the entry label associated with "GaryDanko" includes the category label "restaurant", the street label "Point street", the city label "san francisco", and the cuisine type label "french". The search engine 110 may store the determined entry tags and/or entries in the session index repository 124 and associate the entry tags and/or entries with a unique identifier for the user session in the session index repository 124.
In some implementations, the search engine 110 determines one or more session tags for user sessions that include the search query 109. The search tags are associated with information about the user session.
In some examples, the session tags include time tags, such as timestamps, that indicate when the user session started and ended. For example, a user session starts at 8:30 am on 7/1/2013 and ends at 8:35 am on 7/1/2013. The time tags for the user session may be 8:30 to 8:35 am on 7/1/2013. The search engine 110 may map the precise time to a broader time reference, such as "early morning", "noon", "afternoon", "evening", or "midnight", and use the broader time reference as a time tag. For example, assuming that a user session occurs at 8:30 am, the time tag for the user session may be "early morning" or "morning". The time tag may include a data tag for the user session, such as "7 months and 1 day 2013".
In some examples, the session tag includes a location tag that indicates a location of the user when the user session occurred. The search engine 110 may determine the user's location based on a locator (e.g., Global Positioning System (GPS)) in the user device 106 used by the user or the IP address of the user device 106. The location tag may be an exact address, such as "200 market avenue, san Francisco, CA, 94111" or "market avenue". In some examples, the search engine 110 refers the precise address to the reference location based on information about the user or the user device. The location tag may include a reference location, such as "home," my office, "or" my wife's office.
In some examples, the session tags include action tags that indicate actions taken by the user during the user session or actions taken by the user prior to the user session. The search engine 110 may determine the action tag based on actions associated with previous user sessions or actions the user is taking with the user device 106. For example, the action tag may be "just after me calls my wife," just after me sets an alert, "or" while me is exercising.
In some examples, the session tag includes a co-presence information tag indicating whether the user is co-located with a person during the user session. For example, the co-presence information tag may be "wife co-located".
After determining one or more session tags for the user session, the search engine 110 may store the session tags in the session index repository 124 and associate the session tags with a unique identifier for the user session in the session index repository 124. In a later user session, based on the associations in the session index repository 124, the search engine may determine an identifier for the user session based on one or more session tags, one or more entry tags, and/or entries.
For a user session, session index repository 124 may associate an identifier for the user session with one or more session tags for the user session and associate an identifier for the user session with one or more entry tags and/or entries associated with a series of queries in the user session.
As noted above, the search engine 110 may provide a conversational search service to the user. In some implementations, the search engine 110 includes a speech-to-text engine 126 (e.g., an Automatic Speech Recognizer (ASR) or an automatic speech recognition engine), a dialog session module 128, a query execution module 130, and a response engine 132. The response engine 132 may include an action engine 134 and a text-to-speech (TTS) engine 136.
The search engine 110 may receive a query, such as a voice query, a text query, etc., from the user device 106 in a user session. The speech-to-text engine 126 may recognize the speech query and convert the speech query into a transcription (transcription). The speech-to-text engine 126 can correct or compensate for errors in the speech query, for example, based on spelling and/or grammar.
In some implementations, the search engine 110 provides the transcription of the voice query to the user device 106 for presentation to the user. The user of the user device 106 may check the presented transcription to check whether the search engine 110 correctly understands the voice query. The user may update the voice query as needed. The speech-to-text engine 126 may pass the transcription of the voice query to the dialog session module 128.
As noted above, the search engine 110 (e.g., the dialog session module 128) may determine whether the query is associated with a previous query in the user session or a sub-session of the user session. In some examples, if the dialog session module 128 determines that the query is associated with a previous query, the query is determined to be associated with a user session. Context data associated with the query may be stored in the session data repository 122 and associated with the identifier for the user session in the session data repository 122.
The search engine 110 (e.g., the query execution module 130) may determine that the query or search results responsive to the query relate to an entry. In response to determining the entry, the query execution module 130 may determine one or more entry tags associated with the entry, for example, by searching the annotation database 120 for the entry. After determining the entry tag, the search engine 110 may store the entry tag and/or the entry in the session index repository 124 and associate the entry tag and/or the entry with an identifier for the user session in the session index repository 124.
In some examples, the dialog session module 128 determines that the query is not associated with a previous query in the user session, for example, by: the query is determined to be a complete query in which the search engine 110 enables actions to be performed in response to the query without additional information. In response to determining that the query is not associated with a previous query, the dialog session module 128 determines that the query is not associated with a user session and associates the query with a new user session.
In some examples, if the dialog session module 128 determines that the query is an incomplete query and the voice query is not associated with a previous query, the dialog session module 128 may determine that the query is relevant to a previous user session. After determining that the query is relevant to the previous user session, the search engine 110 may search the session data repository 122 and the session index repository 124 for additional information for the query.
In some examples, the conversation session module 128 determines that the query is relevant to the previous user session by determining that the query has a past tense (e.g., "what book i are talking at that time"). In some examples, the conversation session module 128 determines that the query is relevant to the previous user session by: for example, parsing the query based on grammatical rules to determine that the query includes one or more session tags indicating an earlier time, such as a time tag "morning today" or "yesterday morning", a location tag "when i are at home", an action tag "just after i call me wife" or a co-existing information tag "when i are at the same time as me wife".
In some examples, the dialog session module 128 uses a large number of templates based on grammar rules to determine entry tags and/or session tags for the query and/or intent of the query. For example, the template may include:
what is my [ "time tag" ] talking about [ "item tag" ]
(e.g., the query is "what I talk about the book in the morning today")
What is an [ "entry tag" ] on [ "entry tag" ]
(e.g. query as "what is the place on castro street")
-what is said when i am at [ "position tag" ]
(e.g., query as "what I talk about when I are at home")
In response to determining that the query involves one or more tags, the search engine 110 (e.g., query execution module 130) may search the session index repository 124 to determine whether the one or more tags are associated with one or more particular identifiers in the session index repository 124. One or more specific identifiers are associated with each of the one or more tags.
The search engine 110 may first determine a number of candidate identifiers associated with each tag in the session index repository 124 and select one or more particular identifiers from the number of candidate identifiers by determining an overlap of the determined respective identifiers, as discussed in further detail in fig. 3B.
In response to determining that the tag is associated with a particular identifier in the session index repository 124, the search engine 110 (e.g., the query execution module 130) may search the session data repository 122 to determine particular context data associated with the particular identifier.
The search engine 110 (e.g., response engine 132) may retrieve particular contextual data from the session data repository 122 and perform an action in response to the query, e.g., by action engine 134, based on the retrieved particular contextual data. The action may include a search action, a reminder action, or a navigation action.
In some examples, the action engine 134 establishes one or more alert notifications and sends the alert notifications to the user device 106 at predetermined points in time. In some examples, the action engine 134 performs a navigation action and gives directions from a departure location (e.g., a current address) to a destination location.
In some examples, the action engine 134 performs a search action in response to the query and provides the search results web page resource 111 to the user device 106. The search engine 110 may generate a response based on the search results. The response may be an overview or summary of the search results used to respond to the search query. The response may be based on the search results that are most relevant to the search query and/or have the highest rank score among the search results.
The text-to-speech engine 136 may transform the response from transcription to speech. The user device 106 may receive a digital representation of the voice of the response so that the user may listen to the response through a speaker in the user device 106. In some cases, the user device 106 receives both the digital representation of the answered speech and the search results page resource 111 presented on the user device 106.
In some implementations, the search engine 110 determines a user identifier for the user and/or a device identifier for the user device 106. The search engine 110 associates user identifiers and/or device identifiers with corresponding session data in the session data repository 122 and corresponding session indexes in the session index repository 124. The session data and the session index are associated with a user session for a user or user device. When a user enters a query using the user device 106, the search engine 110 may determine a user identifier and/or a device identifier and then determine and use associated session data in the session data repository 122 and/or an associated session index in the session index repository 124.
In some implementations, session data and/or session indexes associated with the user and/or user device 106 can be stored in the user device 106. When a user enters a query using user device 106, search engine 110 may request access to stored session data and/or session index for conversational searching with the user and/or user device 106. In some examples, the session data is stored in the user device 106. The session index may be stored in a session index repository 124 in the search engine 110. In a conversational search, the search engine 110 may determine one or more particular user sessions based on the search query and the session index and request access to session data in the user device 106.
In some implementations, the search engine 110 is configured to retrieve and use context from previous sessions in a conversational search for international languages including english (e.g., chinese, korean, japanese, russian, hindi, french, or german). To accomplish this, the search engine 110 may include language code based maps to support various language scenarios.
FIG. 1B is an illustration of a conversational search in an example search conversational user interface. The search engine 110 provides a search dialog user interface 150a for display on the user device 106. The search dialog user interface 150a includes a search box 152a for receiving a query and a microphone icon 154 for receiving a voice query from a user. The user enters a voice query, for example, by clicking on the microphone icon 154 in the user interface 150 a.
In user session X, the search engine 110 receives a voice query 138 from the user (e.g., "which restaurant is the best French restaurant in san Francisco"). The search engine 110 determines that the search results responsive to the voice query relate to an entry (e.g., "GaryDanko"). The search engine 110 then determines that the entry "Gary Danko" is within the annotation database 120, and determines one or more entry tags associated with the entries within the annotation database 120, including the category tag "restaurant", the street tag "Point street" and the cuisine type tag "French".
The search engine 110 stores the determined entry tags and entries in the session index repository 124 and associates the entry tags and entries with a unique identifier "X" for the user session in the session index repository 124 as a session index 140. The search engine 110 also determines one or more session tags for user session X (e.g., time tag "8: 30 am 7/1/2013"), and stores the time tag in the session index repository 124 and associates the time tag with identifier "X" in the session index 140 in the session index repository 124.
The search engine 110 determines contextual data associated with the voice query. The contextual data includes search results responsive to the voice query and metadata associated with the voice query and the search results. The metadata may include information about "Gary Danko," such as customer ratings, addresses, phone numbers, open times, and menus, and/or include information about other French restaurants in san Francisco. The search engine 110 stores the contextual data in the session data repository 122 and associates the contextual data with an identifier "X" for user session X in the session data repository 122.
In a later user session Y, for example 6:00 PM on 1 st 7/2013, the user enters a new voice query. When the user begins to input a voice query, user interface 150a becomes user interface 150 b. The voice query is recognized and converted to a transcription, for example, by the speech-to-text engine 126. For example, transmitting the transcript to the user device 106 in real-time or after completion of the voice query for display on the user interface 150b, for example, the string 152b "tell me about restaurants in the morning today".
The search engine 110 determines that the transcription of the voice query relates to the entry tag "restaurant" and the time tag "morning today". The search engine 110 determines, based on the grammar rules and the timestamp for user session Y, that the voice query relates to an earlier time "morning today", e.g., 6:00 am to 12:00 pm on 7.1.7.2013.
The search engine 110 searches for one or more specific identifiers associated with the entry tag "restaurant" and the time tag "morning today" in the session index repository 124. The search engine 110 may determine a number of first candidate identifiers (e.g., "M," P, "and" X ") associated with the time tag" morning today "and a number of second candidate identifiers (e.g.," N "and" X ") associated with the entry tag" restaurant. The overlap of the first candidate identifier and the second candidate identifier is "X". The search engine 110 then determines that the particular identifier associated with both the entry tag and the time tag is an "X" corresponding to the user session X.
In some examples, the search engine 110 first determines a first candidate identifier (e.g., "M," "P," and "X") associated with the time tag, and then determines a particular identifier (e.g., "X") from the determined first candidate identifier.
The search engine 110 may determine, based on the session index repository 124, that the search result in response to the voice query is "Gary Danko", which is an entry associated with the entry tag "restaurant" and is stored in the session index repository 124. Search engine 110 may retrieve the context data stored and associated with the particular identifier "X" from session index repository 122 and determine that the entry tag "restaurant" relates to "Gary Danko".
Search engine 110 (e.g., response engine 132) delivers search results to user device 106. The user interface 150b becomes the user interface 150c that includes the string 152c "Gary Danko" (e.g., the determined search results in the search box 152 c). The user interface 150c also includes an ordered set of search results 158c responsive to the string 152 c. The search engine 110 generates a response, such as "you see Gary Danko restaurants," based on the search results and predetermined grammar rules or templates. The user device 106 receives the responsive text to the speech engine 160c, which is played out through the speaker of the user device 106.
To continue the conversation, the user clicks on the microphone icon 154 in the user interface 150 c. This is the case when the user enters the second speech query "yes. Navigate there, "user interface 150c becomes user interface 150 d. The search engine 110 determines that the second voice query includes an explicit reference "there" to "Gary Danko" in the response to the previous voice query, and performs a navigational action in response to the second voice query, e.g., by the action engine 134.
Fig. 2A-2C are flow diagrams of an example process 200 for storing and indexing item tags and context data for a user session. Process 200 may be performed by a search engine (e.g., search engine 110 of FIGS. 1A-1B) to provide to a user device (e.g., FIGS. 1A-1B)
A search engine receives a query for a user session (202). For example, a search engine receives a query from a user device during a user session. The search engine may determine that the query is associated with a previous query and is associated with the same user session as the previous query. The search engine may determine that the query is not associated with a previous query and associate the query with a user session different from the user session used for the previous query.
The search engine determines that at least one of the query or search results responsive to the query relate to an entry in the database (204). The search engine may parse the query or search results to determine that the query or search results relate to an entry, e.g., based on a grammar rule or a predetermined template. The items may be entities, events, actions, etc. The search engine may search a database (e.g., annotation database 120 of fig. 1A) for entries. The database stores a large number of items and associates each item with a large number of item tags.
The search engine determines one or more entry tags for entries in the database (206). After determining that the entry is within the database, the search engine determines one or more entry tags associated with the entry in the database. For example, assuming an item is "rich dad port dad," the item tags associated with "books" in the database may include a category tag (e.g., "book"), an author tag (e.g., "Robert t. In some cases, the query or search results responsive to the query include only "rich dad pos" and not "books". The search engine is still able to determine, based on the database, that the entry "rich dad port dad" is associated with the category tag "book".
The search engine stores the entry tag in the session index repository (208) and associates the entry tag with an identifier representing the user session in the session index repository (210). The session index repository may be the session index repository 124 of fig. 1A-1B. The session index repository associates respective identifiers for user sessions with respective entry tags and/or entries and/or session tags. The search engine or session index repository may assign identifiers to user sessions, such as numeric identifiers, alphabetic identifiers, combinations thereof, or the like. In some examples, the search engine also stores the entry in a session index repository, and associates the entry with the identifier and the entry tag in the session index repository.
FIG. 2B is a flow diagram of an example process 250 optionally performed by a search engine. The search engine determines one or more session tags for the user session (252). The session tag is associated with information about the user session. As noted above, the session tags may include time tags (e.g., timestamps) indicating when the user session started and ended, location tags indicating the location of the user when the user session occurred, action tags indicating actions taken by the user during the user session or actions taken by the user prior to the user session, and/or co-presence information indicating whether the user was co-located with someone during the user session.
The search engine stores the session tags in the session index repository (254) and associates the session tags with identifiers for user sessions in the session index repository (256). In some examples, the user session includes a series of queries. Identifiers may be associated in the session index repository with entry tags and/or entries for each query in a user session and session tags for the user session.
FIG. 2C is a flow diagram of an example process 260 optionally performed by a search engine. The search engine determines contextual data for the query (262). The search engine may determine the contextual data by searching in a network (e.g., the network of FIG. 1A) and/or a database (e.g., annotation database 120). The contextual data may include search results responsive to the query and metadata associated with the query and the search results. The metadata may include the determined entry and entry tag for the query.
The search engine stores the contextual data in a session data repository (264) and associates the contextual data with an identifier for the user session in a second repository (266). The session data repository may be the session data repository 122 of fig. 1A. In some embodiments, the session index repository and the session data repository are included in the same repository (e.g., repository 114 of fig. 1A). A user session may include a series of queries. The identifier may be associated with context data for each query in the user session in a session data repository.
Fig. 3A-3B are flow diagrams of an example process 300 for retrieving and using contextual data from a previous session in a conversational search. The process 300 may be used by a search engine (e.g., the search engine 110 of fig. 1A-1B or the search engine of fig. 2A-2C) to provide a conversational search service to a user device (e.g., the user device 106 of fig. 1A-1B).
A search engine receives a query for a user session (302). The query may be entered by a user using a user device. The search engine may determine whether the query is associated with a previous query. If the search engine determines that the query is associated with a previous query, the search engine may perform an action in response to the query based on contextual data associated with the previous query. If the search engine determines that the query is not associated with a previous query and the query is a complete query, the search engine may perform actions in response to the query independent of other queries.
In some examples, the search engine determines that the query is not associated with a previous query and that the query is an incomplete query lacking additional information needed to perform an action in response to the query. In response to determining that the query is not associated with a previous query and is an incomplete query, the search engine may determine that the query is relevant to a previous user session. In some cases, the search engine determines that the query is relevant to the previous user session by determining that the query has a past tense or includes a time indicator relating to an earlier time.
The search engine determines that the query relates to one or more tags in the session index repository (304). The session index repository associates respective identifiers for user sessions with respective tags and/or entries in the user sessions. The session index repository may be the session index repository 124 of fig. 1A-1B.
The search engine may parse the query to determine that the query relates to one or more tags based on, for example, grammar rules and/or predetermined templates. The search engine may also determine the intent of the query. In some examples, the search engine determines that the query includes one or more query segments by parsing the first query, and determines one or more tags in the session index repository by determining that the one or more tags correspond to the one or more query segments.
The one or more tags include at least one or more entry tags or one or more session tags. In some examples, the one or more tags include one or more tag objects. For example, the query may be "what is a restaurant on castro street". The search engine determines that the query includes a category label "restaurant" and an address label or street label "castro street". The search engine may also determine that the user's intent is to find restaurants on castro street in san francisco or its vicinity.
In some examples, the one or more tags include one or more session tags. For example, assume the query is "what I talk about when I are at home in the morning today". The search engine determines that the query includes 2 session tags: location label "home" and time label "morning today".
In some examples, the one or more tags include one or more session tags and one or more entry tags. For example, the query may be "what restaurants i are looking for in the morning today". The search engine determines that the query includes an entry tag (i.e., the category tag "restaurant") and a session tag (i.e., the time tag "morning today").
After determining that the query involves one or more tags, the search engine may search the session index repository to determine whether the one or more tags are within the session index repository.
The search engine determines one or more specific identifiers for tags in the session index repository (306). In response to determining that the one or more tags are within the session index repository, the search engine determines whether the one or more tags in the session index repository are associated with one or more particular identifiers. A particular identifier may be associated with each of the tags.
Fig. 3B is a flow diagram of an example process 350 for determining a particular identifier based on a tag in a session index repository. For purposes of illustration, in process 350, it is assumed that the tags include 2 tags. The search engine may use a process similar to process 350 to determine the particular identifiers associated with more than two tags.
The search engine determines a plurality of first identifiers associated with a first one of the tags in the session index repository (352). In some examples, the tag includes a time tag, such as "morning today". The search engine may first determine the plurality of first identifiers associated with the time tag by searching the session index repository to select the first identifier associated with the time tag "morning today".
The search engine may determine that "morning today" is the relevant timestamp and then determine the time based on the timestamp for the user session in step 302. For example, assume a timestamp of "6:00 PM on 7 months 1 in 2013". The search engine determines that "morning today" means "6:00 am to 12:00 pm on 7.1.2013". The search engine then determines a plurality of first identifiers associated with each time tag that refers to an absolute time within a time range of "6:00 am to 12:00 pm on 7 months 1 in 2013". The first identifier may include identifier "0001" with time label "7:01 am", identifier "0005" with time label "8:00 am", identifier "0009" with time label "10:51 am", and identifier "0018" with time label "11:00 am". All first identifiers have a date label "2013, 7 month, 1 day".
The search engine determines a plurality of second identifiers associated with a second one of the tags from the determined first identifiers (354). The second tag may be a session tag (e.g., location tag "at home") or an entry tag (e.g., category tag "restaurant"). Without searching in the session data repository, the search engine determines a second identifier within the determined first identifier. Since the first identifier is associated with the first tag, the determined second identifier is associated with both the first tag and the second tag. For example, the determined second identifier may include identifier "0001" and identifier "0018".
If the tags include only the first tag and the second tag, the search engine may determine that the second identifier is a particular identifier. In some examples, if the search engine determines that the second identifier includes only identifiers such as identifier "0018," the search engine may also determine that the second identifier is a particular identifier. If the tags include tags other than the first tag and the second tag, the search engine may proceed to determine the particular identifier associated with each tag from the second identifier (356).
In some implementations, the search engine determines a plurality of second identifiers associated with second ones of the tags in the session index repository (358). The search engine may, for example, perform step 352 and step 358 separately and/or simultaneously. The search engine determines a particular identifier associated with each tag from the overlap of the first identifier and the second identifier (360).
In a particular example, assume that the first identifiers associated with the first tag are "0001", "0005", "0009", and "0018", and the second identifiers associated with the second tag are "0001", "0018", and "0020". The overlap of the first identifier and the second identifier includes identifier "0001" and identifier "0018". If the tags include only the first tag and the second tag, the search engine determines that the specific identifier is an overlapping identifier, i.e., "0001" and "0018".
The search engine may individually determine a plurality of candidate identifiers associated with each of the tags in the session index repository. In some cases, the search engine determines multiple identifiers from the overlap of candidate identifiers for each tag. In some cases, if the tags include a time tag, the search system first determines a plurality of candidate identifiers associated with the time tag, e.g., step 302, and then determines a particular identifier from the determined candidate identifiers based on the remaining tags, e.g., by: an identifier associated with each of the remaining tags is determined and an overlap of the determined identifiers is selected.
In some cases, the search engine determines an order for the candidate identifiers based on a number of associated tags, and determines that a particular identifier is the identifier with the highest ranking score. Assume for example that the tags comprise 5 tags. From the overlap of candidate identifiers of 5 tags, the search engine determines that the first candidate identifier is associated with 3 tags and the second candidate identifier is associated with 4 tags. No identifier is associated with 5 tags. The search engine may determine that the particular identifier is a second candidate identifier.
Referring back to FIG. 3A, the search engine retrieves particular context data for a particular identifier in the session data repository (308). After determining that the particular identifier is associated with the tag in the session index repository, the search engine determines and retrieves particular context data associated with the determined particular identifier in the session data repository. The session data repository may be the session data repository 122 of fig. 1A and associates respective identifiers of user sessions with respective context data. The particular contextual data may include a search query in a user session represented by the particular query, search results responsive to the search query, and metadata associated with the search query and the search results.
The search engine performs an action in response to the query based on the particular contextual data (310). The search engine may use the retrieved particular contextual data to perform an action in response to the query. The action may be a search action, a navigation action, a reminder action, etc.
In some examples, the search engine determines that the search query or search results in the retrieved contextual data relate to one or more particular entries corresponding to one or more tags to which the query relates. The search engine may perform an action in response to the query based on the determined entry.
For example, assume the query is "tell me about a restaurant in the morning today". If a search query or search result in the retrieved contextual data relates to the entry "Gary Danko" corresponding to the entry tag "restaurant" in the query, the search engine provides a response in response to the query, e.g., "you have looked at Gary Danko restaurants," based on the entry "Gary Danko" and/or grammatical rules and/or templates.
In a particular example, in an earlier user session X, which occurred in the morning today, the user was looking for a restaurant in san Francisco to have lunch. The search engine determines that at least one of the query in user session X or the search results responsive to the query relates to restaurants "Gary Danko", "Zuni Caf", and "strained Door Restaurant".
The search engine determines the category label "restaurant" and city label "san francisco" for all 3 restaurants in a database (e.g., annotation database 120 of fig. 1A). The search engine also determines that the address label of "Gary Danko" is "Point street", "Zuni Caf" is "Market street" and "controlled Door Restaurant" is "Ferry building". The search engine stores the determined tag for the restaurant in the session index repository and associates the determined tag with the session identifier X in the session index repository. The search engine also determines contextual data for the query, such as restaurant name, address, open time, phone number, type of cook, and customer rating. The search engine stores the contextual data in a session data repository and associates the contextual data with user session X in the session data repository.
In a later user session Y, for example, the evening on the same day as user session X, the user uses the search engine for a conversational search. The search engine may retrieve and use contextual data of user session X to answer queries from the user. The query (Q) and answer or response (a) may be as follows:
q1: tell me the situation at a restaurant in the morning today
A1: you see Gary Danko restaurant
Q2: there is another family
A2: that is, Zuni cafe on market street in san Francisco
Q3: where is the Ferry building
A3: that is a strained Door reserve
Q4: that is, the family is sent to the wife
Q5: navigate thereto
In response to Q4, the search engine may transmit a message or email to the user's wife. In response to Q5, the search engine may perform a navigation action to search for a route from the user's current address to the address of the contained Door Restaurant.
Embodiments of the subject matter and the operations described in this specification can be implemented in digital electronic circuitry, or in computer software, firmware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them. Embodiments of the subject matter described in this specification can be implemented as one or more computer programs, e.g., one or more modules of computer program instructions, encoded on a computer storage medium for execution by, or to control the operation of, data processing apparatus. Alternatively or in addition, the program instructions may be encoded on an artificially generated propagated signal (e.g., a machine-generated electrical, optical, or electromagnetic signal) that is generated to encode information for transmission to suitable receiving apparatus for execution by the data processing apparatus. The computer storage media may be or be embodied in, or include, a computer-readable storage device, a computer-readable storage substrate, a random or sequential access memory array or device, or a combination of one or more of them. Additionally, although a computer storage medium is not a propagated signal, a computer storage medium can be a source or destination of computer program instructions encoded with an artificially generated propagated signal. The computer storage medium may also be, or be included in, one or more separate physical components or media (e.g., multiple CDs, disks, or other storage devices).
The operations described in this specification may be implemented as operations performed by data processing apparatus on data stored on one or more computer-readable storage devices or received from other sources.
The term "data processing apparatus" includes all kinds of apparatus, devices, and machines for processing data, including by way of example a programmable processor, a computer, a system on a chip, or multiple items or combinations thereof. An apparatus may comprise special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit). In addition to hardware, an apparatus can also include code that creates an execution environment for the computer program in question, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, a cross-platform runtime environment, a virtual machine, or a combination of one or more of them. The apparatus and execution environment may implement a variety of different computing model architectures, such as web services, distributed computing architectures, and grid computing architectures.
A computer program (also known as a program, software application, script, or code) can be written in any form of programming language, including compiled or interpreted languages, declarative or procedural languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, object, or other unit suitable for use in a computing environment. A computer program may, but need not, correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data (e.g., one or more scripts stored in a markup language document), in a single file dedicated to the program in question, or in multiple coordinated files (e.g., files that store one or more modules, sub programs, or portions of code). A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.
The processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform actions by performing operations on input data and generating output. The processes and logic flows can also be performed by, and apparatus can also be implemented as, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit).
Processors suitable for the execution of a computer program include, by way of example, both general and special purpose microprocessors, and any one or more processors of any kind of digital computer. Generally, a processor will receive instructions and data from a read-only memory or a random access memory or both. The essential elements of a computer are a processor for performing actions in accordance with the instructions and one or more memory devices for storing instructions and data. Generally, a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks. However, a computer need not have such a device. Additionally, the computer may be embedded in another device, e.g., a mobile telephone, a Personal Digital Assistant (PDA), a mobile audio or video player, a game player, a Global Positioning System (GPS) receiver, or a portable storage device (e.g., a Universal Serial Bus (USB) flash memory device), etc. Devices suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example: semiconductor memory devices such as EPROM, EEPROM, and flash memory devices; magnetic disks, such as internal hard disks or removable disks; magneto-optical disks; and CD-ROM and DVD-ROM disks. The processor and the memory can be supplemented by, or incorporated in, special purpose logic circuitry.
To provide for interaction with a user, embodiments of the subject matter described in this specification can be implemented on a computer having a display device, e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) display, for displaying information to the user and a keyboard and a pointing device, e.g., a mouse or a trackball, by which the user can provide input to the computer. Other kinds of devices may also be used to provide for interaction with the user; for example, feedback provided to the user can be any form of sensory feedback, such as visual feedback, auditory feedback, or tactile feedback; input from the user may be received in any form, including acoustic input, speech input, or tactile input. In addition, the computer may interact with the user by sending documents to and receiving documents from a device used by the user; for example by sending a web page to a web browser on a user device of the user in response to a request received from the web browser.
Embodiments of the subject matter described in this specification can be implemented in a computer system that includes a back-end component (e.g., as a data server), or that includes a middleware component (e.g., an application server), or that includes a front-end component (e.g., a user computer having a graphical user interface or a web browser through which a user can interact with an implementation of the subject matter described in this specification), or any combination of one or more such back-end, middleware, or front-end components. The components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include Local Area Networks (LANs) and Wide Area Networks (WANs), cross-networks (e.g., the internet), and peer-to-peer networks (e.g., private peer-to-peer networks).
The computing system may include a user and a server. A user and server are generally remote from each other and typically interact through a communication network. The relationship of user and server arises by virtue of computer programs running on the respective computers and having a user-server relationship to each other. In some embodiments, the server transmits data (e.g., HTML pages) to the user device (e.g., for the purpose of displaying data to the user device and receiving user input from a user interacting with the user device). Data generated at the user device (e.g., a result of the user interaction) may be received at the server from the user device.
While this specification contains many specific implementation details, these should not be construed as limiting the scope of what may be claimed, but rather as describing specific features of particular embodiments. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely, various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. In addition, although features may be described above as acting and even claimed as such in certain embodiments, one or more features from a claimed combination can in some cases be excised from the combination, and the claimed combination may be directed to a subcombination or variation of a subcombination.
Similarly, while operations are depicted in the drawings in a particular order, this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order, nor should it be understood as requiring that all illustrated operations be performed, to achieve desirable results. In some cases, multitasking and parallel processing may be advantageous. Moreover, the separation of various system components in the embodiments described above should not be understood as requiring such separation in all embodiments, and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.
Thus, particular embodiments of the subject matter have been described. Other embodiments are within the scope of the following claims. In some cases, the actions set forth in the claims can be performed in a different order and still achieve desirable results. In addition, the processes depicted in the accompanying figures do not necessarily require the particular order shown, or sequential order, to achieve desirable results. In some embodiments, multitasking and parallel processing may be advantageous.
Claims (28)
1. A computer-implemented method, comprising:
receiving, by a search engine and from a speech-to-text engine, a search query based on an utterance of a user detected by a digital assistant device during a current search session;
determining, by the search engine, that the search query involves a time indicator, the time indicator indicating a time earlier than the current search session;
determining, by the search engine, that the search query relates to one or more other query terms;
determining, by the search engine and in accordance with session data stored in a repository associated with the search engine, a first set of related previous search sessions from a second set of previous search sessions, wherein the second set of previous search sessions includes more previous search sessions than the first set of related previous search sessions, wherein each of the first set of related previous search sessions is associated with a respective timestamp corresponding to the time indicator;
identifying, by the search engine, a particular prior search session from the first set of related prior search sessions determined from session data stored in a repository associated with the search engine based on the one or more other query terms associated with the search query of the current search session without searching for any prior search sessions from a second set of prior search sessions that are not in the first set of related prior search sessions;
identifying, by the search engine, one or more entities associated with one or more search queries or search results of a particular previous search session based on the one or more other query terms of the search query of the current search session; and
providing, from a text-to-speech engine, (i) a response to the search query that includes representations of one or more of the entities that are configured to be output on a speaker of the digital assistant device in response to the search query of the current search session, and (ii) metadata related to the one or more entities that are configured to be rendered on a graphical user interface of the digital assistant device during outputting at least a portion of the response to the search query using the speaker of the digital assistant device.
2. The method of claim 1, wherein identifying a particular prior search session from the first set of related prior search sessions comprises:
for each of the first set of related previous search sessions, determining a plurality of query terms associated with the one or more search queries or search results of the previous search session;
determining a score based on a comparison of the plurality of query terms associated with the one or more search queries or search results of the previous search session with the one or more other query terms of the search query of the current search session; and
identifying a particular prior search session from the first set of related prior search sessions based on the score.
3. The method of claim 1, wherein operations further comprise:
determining that the search query is not associated with a previous query of the current search session prior to determining that the search query relates to the time indicator.
4. The method of claim 1, wherein operations further comprise:
determining that the search query relates to a user location indicator, the user location indicator indicating a location of the user during a previous search session; and
a plurality of previous search sessions is determined, each previous search session associated with a respective location marker corresponding to the user location indicator.
5. The method of claim 1, wherein determining a first set of related previous search sessions from a second set of previous search sessions comprises: previous search sessions associated with timestamps within a time range associated with the time indicator are identified.
6. The method of claim 1, wherein operations further comprise:
a user identifier of a user is determined prior to receiving a search query during a current search session.
7. The method of claim 6, wherein determining a first set of related previous search sessions from a second set of previous search sessions comprises: a plurality of previous search sessions associated with the user identifier is determined.
8. The method of claim 1, wherein operations further comprise:
performing an action based on the representation of one or more of the entities in response to the search query of the current search session.
9. The method of claim 8, wherein the action is a navigation action.
10. A system, comprising:
a data processing device; and
a non-transitory computer-readable storage medium in data communication with the data processing apparatus and storing instructions executable by the data processing apparatus and that upon such execution cause the data processing apparatus to perform operations comprising:
receiving, by a search engine and from a speech-to-text engine, a search query based on an utterance of a user detected by a digital assistant device during a current search session;
determining, by the search engine, that the search query involves a time indicator, the time indicator indicating a time earlier than the current search session;
determining, by the search engine, that the search query relates to one or more other query terms;
determining, by the search engine and in accordance with session data stored in a repository associated with the search engine, a first set of related previous search sessions from a second set of previous search sessions, wherein the second set of previous search sessions includes more previous search sessions than the first set of related previous search sessions, wherein each of the first set of related previous search sessions is associated with a respective timestamp corresponding to the time indicator;
identifying, by the search engine, a particular prior search session from the first set of related prior search sessions determined from session data stored in a repository associated with the search engine based on the one or more other query terms associated with the search query of the current search session without searching for any prior search sessions from a second set of prior search sessions that are not in the first set of related prior search sessions;
identifying, by the search engine, one or more entities associated with one or more search queries or search results of a particular previous search session based on the one or more other query terms of the search query of the current search session; and
providing, from a text-to-speech engine, (i) a response to the search query that includes representations of one or more of the entities that are configured to be output on a speaker of the digital assistant device in response to the search query of the current search session, and (ii) metadata related to the one or more entities that are configured to be rendered on a graphical user interface of the digital assistant device during outputting at least a portion of the response to the search query using the speaker of the digital assistant device.
11. The system of claim 10, wherein identifying a particular prior search session from the first set of related prior search sessions comprises:
for each of the first set of related previous search sessions, determining a plurality of query terms associated with the one or more search queries or search results of the previous search session;
determining a score based on a comparison of the plurality of query terms associated with the one or more search queries or search results of the previous search session with the one or more other query terms of the search query of the current search session; and
identifying a particular prior search session from the first set of related prior search sessions based on the score.
12. The system of claim 10, wherein the operations further comprise:
determining that the search query is not associated with a previous query of the current search session prior to determining that the search query relates to the time indicator.
13. The system of claim 10, wherein the operations further comprise:
determining that the search query relates to a user location indicator, the user location indicator indicating a location of the user during a previous search session; and
a plurality of previous search sessions is determined, each previous search session associated with a respective location marker corresponding to the user location indicator.
14. The system of claim 10, wherein determining a first set of related previous search sessions from a second set of previous search sessions comprises: previous search sessions associated with timestamps within a time range associated with the time indicator are identified.
15. The system of claim 10, wherein the operations further comprise:
a user identifier of a user is determined prior to receiving a search query during a current search session.
16. The system of claim 15, wherein determining a first set of related previous search sessions from a second set of previous search sessions comprises: a plurality of previous search sessions associated with the user identifier is determined.
17. The system of claim 10, wherein the operations further comprise:
performing an action based on the representation of one or more of the entities in response to the search query of the current search session.
18. The system of claim 17, wherein the action is a navigation action.
19. A non-transitory computer-readable storage medium storing instructions executable by a data processing apparatus and that upon such execution cause the data processing apparatus to perform operations comprising:
receiving, by a search engine and from a speech-to-text engine, a search query based on an utterance of a user detected by a digital assistant device during a current search session;
determining, by the search engine, that the search query involves a time indicator, the time indicator indicating a time earlier than the current search session;
determining, by the search engine, that the search query relates to one or more other query terms;
determining, by the search engine and in accordance with session data stored in a repository associated with the search engine, a first set of related previous search sessions from a second set of previous search sessions, wherein the second set of previous search sessions includes more previous search sessions than the first set of related previous search sessions, wherein each of the first set of related previous search sessions is associated with a respective timestamp corresponding to the time indicator;
identifying, by the search engine, a particular prior search session from the first set of related prior search sessions determined from session data stored in a repository associated with the search engine based on the one or more other query terms associated with the search query of the current search session without searching for any prior search sessions from a second set of prior search sessions that are not in the first set of related prior search sessions;
identifying, by the search engine, one or more entities associated with one or more search queries or search results of a particular previous search session based on the one or more other query terms of the search query of the current search session; and
providing, from a text-to-speech engine, (i) a response to the search query that includes representations of one or more of the entities that are configured to be output on a speaker of the digital assistant device in response to the search query of the current search session, and (ii) metadata related to the one or more entities that are configured to be rendered on a graphical user interface of the digital assistant device during outputting at least a portion of the response to the search query using the speaker of the digital assistant device.
20. The computer-readable storage medium of claim 19, wherein identifying a particular prior search session from the first set of related prior search sessions comprises:
for each of the first set of related previous search sessions, determining a plurality of query terms associated with the one or more search queries or search results of the previous search session;
determining a score based on a comparison of the plurality of query terms associated with the one or more search queries or search results of the previous search session with the one or more other query terms of the search query of the current search session; and
identifying a particular prior search session from the first set of related prior search sessions based on the score.
21. The computer-readable storage medium of claim 19, wherein the operations further comprise:
determining that the search query is not associated with a previous query of the current search session prior to determining that the search query relates to the time indicator.
22. The computer-readable storage medium of claim 19, wherein the operations further comprise:
determining that the search query relates to a user location indicator, the user location indicator indicating a location of the user during a previous search session; and
a plurality of previous search sessions is determined, each previous search session associated with a respective location marker corresponding to the user location indicator.
23. The computer-readable storage medium of claim 19, wherein determining a first set of related previous search sessions from a second set of previous search sessions comprises: previous search sessions associated with timestamps within a time range associated with the time indicator are identified.
24. The computer-readable storage medium of claim 19, wherein the operations further comprise:
a user identifier of a user is determined prior to receiving a search query during a current search session.
25. The computer-readable storage medium of claim 24, wherein determining a first set of related previous search sessions from a second set of previous search sessions comprises: a plurality of previous search sessions associated with the user identifier is determined.
26. The computer-readable storage medium of claim 19, wherein the operations further comprise:
performing an action based on the representation of one or more of the entities in response to the search query of the current search session.
27. The computer-readable storage medium of claim 26, wherein the action is a navigation action.
28. The computer-readable storage medium of claim 26, wherein the action is a reminder action.
Applications Claiming Priority (5)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201462010294P | 2014-06-10 | 2014-06-10 | |
US62/010,294 | 2014-06-10 | ||
US14/448,547 | 2014-07-31 | ||
US14/448,547 US10275485B2 (en) | 2014-06-10 | 2014-07-31 | Retrieving context from previous sessions |
CN201510314119.0A CN105224586B (en) | 2014-06-10 | 2015-06-09 | retrieving context from previous sessions |
Related Parent Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201510314119.0A Division CN105224586B (en) | 2014-06-10 | 2015-06-09 | retrieving context from previous sessions |
Publications (2)
Publication Number | Publication Date |
---|---|
CN111104496A true CN111104496A (en) | 2020-05-05 |
CN111104496B CN111104496B (en) | 2021-01-26 |
Family
ID=53274415
Family Applications (3)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201510314119.0A Active CN105224586B (en) | 2014-06-10 | 2015-06-09 | retrieving context from previous sessions |
CN201911132163.4A Active CN110825835B (en) | 2014-06-10 | 2015-06-09 | Retrieving context from previous session |
CN201911132153.0A Active CN111104496B (en) | 2014-06-10 | 2015-06-09 | Retrieving context from previous sessions |
Family Applications Before (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201510314119.0A Active CN105224586B (en) | 2014-06-10 | 2015-06-09 | retrieving context from previous sessions |
CN201911132163.4A Active CN110825835B (en) | 2014-06-10 | 2015-06-09 | Retrieving context from previous session |
Country Status (3)
Country | Link |
---|---|
US (4) | US10275485B2 (en) |
EP (1) | EP2955643A1 (en) |
CN (3) | CN105224586B (en) |
Families Citing this family (32)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10275485B2 (en) | 2014-06-10 | 2019-04-30 | Google Llc | Retrieving context from previous sessions |
US9547690B2 (en) | 2014-09-15 | 2017-01-17 | Google Inc. | Query rewriting using session information |
US9942122B2 (en) * | 2016-02-29 | 2018-04-10 | Airmagnet, Inc. | Fast packet retrieval based on flow ID and metadata |
US9872072B2 (en) * | 2016-03-21 | 2018-01-16 | Google Llc | Systems and methods for identifying non-canonical sessions |
US10853872B1 (en) * | 2016-06-20 | 2020-12-01 | Amazon Technologies, Inc. | Advanced item associations in an item universe |
CN106355450B (en) * | 2016-08-31 | 2020-04-24 | 深圳市联动精准科技有限公司 | User behavior analysis system and method |
US10482885B1 (en) * | 2016-11-15 | 2019-11-19 | Amazon Technologies, Inc. | Speaker based anaphora resolution |
US10446144B2 (en) | 2016-11-21 | 2019-10-15 | Google Llc | Providing prompt in an automated dialog session based on selected content of prior automated dialog session |
KR20180075009A (en) * | 2016-12-26 | 2018-07-04 | 현대자동차주식회사 | Speech processing apparatus, vehicle having the same and speech processing method |
CN108270660A (en) * | 2017-01-04 | 2018-07-10 | 腾讯科技（深圳）有限公司 | The quickly revert method and device of message |
US11366864B2 (en) * | 2017-02-09 | 2022-06-21 | Microsoft Technology Licensing, Llc | Bot integration in a web-based search engine |
JP6920878B2 (en) * | 2017-04-28 | 2021-08-18 | フォルシアクラリオン・エレクトロニクス株式会社 | Information providing device and information providing method |
US10652170B2 (en) | 2017-06-09 | 2020-05-12 | Google Llc | Modification of audio-based computer program output |
US10614122B2 (en) | 2017-06-09 | 2020-04-07 | Google Llc | Balance modifications of audio-based computer program output using a placeholder field based on content |
US10657173B2 (en) | 2017-06-09 | 2020-05-19 | Google Llc | Validate modification of audio-based computer program output |
KR102471071B1 (en) * | 2017-06-09 | 2022-11-25 | 구글 엘엘씨 | Modification of audio-based computer program output |
US10600409B2 (en) | 2017-06-09 | 2020-03-24 | Google Llc | Balance modifications of audio-based computer program output including a chatbot selected based on semantic processing of audio |
US20180364798A1 (en) * | 2017-06-16 | 2018-12-20 | Lenovo (Singapore) Pte. Ltd. | Interactive sessions |
US10659451B2 (en) * | 2017-07-18 | 2020-05-19 | Bank Of America Corporation | System and method for injecting a tag into a computing resource |
US11436469B2 (en) | 2017-07-31 | 2022-09-06 | Microsoft Technology Licensing, Llc | Knowledge graph for conversational semantic search |
US20190068527A1 (en) * | 2017-08-28 | 2019-02-28 | Moveworks, Inc. | Method and system for conducting an automated conversation with a virtual agent system |
US20190065498A1 (en) * | 2017-08-29 | 2019-02-28 | Chirrp, Inc. | System and method for rich conversation in artificial intelligence |
EP3704601A4 (en) * | 2017-10-31 | 2020-09-09 | Yext, Inc. | Knowledge search engine platform for enhanced business listings |
CN110019725A (en) * | 2017-12-22 | 2019-07-16 | 科沃斯商用机器人有限公司 | Man-machine interaction method, system and its electronic equipment |
US10726206B2 (en) * | 2018-01-30 | 2020-07-28 | Disney Enterprises, Inc. | Visual reference resolution using attention memory for visual dialog |
US11537428B2 (en) | 2018-05-17 | 2022-12-27 | Spotify Ab | Asynchronous execution of creative generator and trafficking workflows and components therefor |
US20190355372A1 (en) | 2018-05-17 | 2019-11-21 | Spotify Ab | Automated voiceover mixing and components therefor |
US11403663B2 (en) * | 2018-05-17 | 2022-08-02 | Spotify Ab | Ad preference embedding model and lookalike generation engine |
CN111291072B (en) * | 2020-01-21 | 2023-06-27 | 奇安信科技集团股份有限公司 | Session data extraction method and device, computer system and readable storage medium |
US11803400B2 (en) * | 2020-06-25 | 2023-10-31 | International Business Machines Corporation | Method and system for asynchronous notifications for users in contextual interactive systems |
US11468052B2 (en) | 2020-06-25 | 2022-10-11 | Google Llc | Combining parameters of multiple search queries that share a line of inquiry |
US11782961B2 (en) * | 2021-04-16 | 2023-10-10 | Amadeus S.A.S. | Device, system and method for providing descriptions to communication devices using machine learning generated templates |
Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20090055355A1 (en) * | 2007-03-27 | 2009-02-26 | Brunner Josie C | Systems, methods, and apparatus for seamless integration for user, contextual, and social awareness in search results through layer approach |
US20110040768A1 (en) * | 2009-08-14 | 2011-02-17 | Google Inc. | Context based resource relevance |
US20110225192A1 (en) * | 2010-03-11 | 2011-09-15 | Imig Scott K | Auto-detection of historical search context |
CN102246171A (en) * | 2008-12-11 | 2011-11-16 | 微软公司 | Providing recent history with search results |
CN103548023A (en) * | 2011-05-27 | 2014-01-29 | 国际商业机器公司 | Automated self-service user support based on ontology |
Family Cites Families (36)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6980984B1 (en) * | 2001-05-16 | 2005-12-27 | Kanisa, Inc. | Content provider systems and methods using structured data |
WO2003019917A2 (en) * | 2001-08-28 | 2003-03-06 | Zow Ltd. | Method and system of caller interaction with an entertainment system over a voice network |
US7398209B2 (en) | 2002-06-03 | 2008-07-08 | Voicebox Technologies, Inc. | Systems and methods for responding to natural language speech utterance |
US7054420B2 (en) | 2002-09-11 | 2006-05-30 | Telstrat International, Ltd. | Voice over IP telephone recording architecture |
US20070136251A1 (en) * | 2003-08-21 | 2007-06-14 | Idilia Inc. | System and Method for Processing a Query |
WO2005020091A1 (en) * | 2003-08-21 | 2005-03-03 | Idilia Inc. | System and method for processing text utilizing a suite of disambiguation techniques |
US8612208B2 (en) * | 2004-04-07 | 2013-12-17 | Oracle Otc Subsidiary Llc | Ontology for use with a system, method, and computer readable medium for retrieving information and response to a query |
US7580921B2 (en) * | 2004-07-26 | 2009-08-25 | Google Inc. | Phrase identification in an information retrieval system |
US7856441B1 (en) * | 2005-01-10 | 2010-12-21 | Yahoo! Inc. | Search systems and methods using enhanced contextual queries |
US7949642B2 (en) * | 2004-10-12 | 2011-05-24 | Wendy W Yang | System and method for managing and presenting entity information |
US7707201B2 (en) * | 2004-12-06 | 2010-04-27 | Yahoo! Inc. | Systems and methods for managing and using multiple concept networks for assisted search processing |
US8150872B2 (en) | 2005-01-24 | 2012-04-03 | The Intellection Group, Inc. | Multimodal natural language query system for processing and analyzing voice and proximity-based queries |
US7472119B2 (en) * | 2005-06-30 | 2008-12-30 | Microsoft Corporation | Prioritizing search results by client search satisfaction |
US7797303B2 (en) * | 2006-02-15 | 2010-09-14 | Xerox Corporation | Natural language processing for developing queries |
JP4338145B2 (en) * | 2007-03-08 | 2009-10-07 | インターナショナル・ビジネス・マシーンズ・コーポレーション | Technology to search for keywords that determine the occurrence of an event |
US8015005B2 (en) | 2008-02-15 | 2011-09-06 | Motorola Mobility, Inc. | Method and apparatus for voice searching for stored content using uniterm discovery |
US8452805B2 (en) * | 2009-03-05 | 2013-05-28 | Kinpoint, Inc. | Genealogy context preservation |
US9858925B2 (en) * | 2009-06-05 | 2018-01-02 | Apple Inc. | Using context information to facilitate processing of commands in a virtual assistant |
US8538973B1 (en) * | 2010-04-05 | 2013-09-17 | Google Inc. | Directions-based ranking of places returned by local search queries |
US9361387B2 (en) * | 2010-04-22 | 2016-06-07 | Microsoft Technology Licensing, Llc | Context-based services |
US20110270819A1 (en) | 2010-04-30 | 2011-11-03 | Microsoft Corporation | Context-aware query classification |
US9194716B1 (en) * | 2010-06-18 | 2015-11-24 | Google Inc. | Point of interest category ranking |
US20120030021A1 (en) * | 2010-08-02 | 2012-02-02 | Yahoo! Inc. | Selecting advertisements using same session queries |
US20120158685A1 (en) * | 2010-12-16 | 2012-06-21 | Microsoft Corporation | Modeling Intent and Ranking Search Results Using Activity-based Context |
US9443026B2 (en) * | 2010-12-28 | 2016-09-13 | Yahoo! Inc. | Method and system to utilize session queries in real time to improve geo precision of sponsored listings |
US8688667B1 (en) * | 2011-02-08 | 2014-04-01 | Google Inc. | Providing intent sensitive search results |
US9576573B2 (en) * | 2011-08-29 | 2017-02-21 | Microsoft Technology Licensing, Llc | Using multiple modality input to feedback context for natural language understanding |
US9116994B2 (en) * | 2012-01-09 | 2015-08-25 | Brightedge Technologies, Inc. | Search engine optimization for category specific search results |
US9223537B2 (en) * | 2012-04-18 | 2015-12-29 | Next It Corporation | Conversation user interface |
US8995716B1 (en) * | 2012-07-12 | 2015-03-31 | Google Inc. | Image search results by seasonal time period |
US9424233B2 (en) | 2012-07-20 | 2016-08-23 | Veveo, Inc. | Method of and system for inferring user intent in search input in a conversational interaction system |
US20140095596A1 (en) * | 2012-09-28 | 2014-04-03 | Avaya Inc. | System and method for long-lived contextual interactions |
US9069825B1 (en) * | 2013-03-15 | 2015-06-30 | Google Inc. | Search dialogue user interface |
US9875494B2 (en) * | 2013-04-16 | 2018-01-23 | Sri International | Using intents to analyze and personalize a user's dialog experience with a virtual personal assistant |
US20150112963A1 (en) * | 2013-10-23 | 2015-04-23 | Tilofy, Inc. | Time and location based information search and discovery |
US10275485B2 (en) * | 2014-06-10 | 2019-04-30 | Google Llc | Retrieving context from previous sessions |
-
2014
- 2014-07-31 US US14/448,547 patent/US10275485B2/en active Active
-
2015
- 2015-05-22 EP EP15169051.8A patent/EP2955643A1/en not_active Ceased
- 2015-06-09 CN CN201510314119.0A patent/CN105224586B/en active Active
- 2015-06-09 CN CN201911132163.4A patent/CN110825835B/en active Active
- 2015-06-09 CN CN201911132153.0A patent/CN111104496B/en active Active
-
2019
- 2019-03-15 US US16/355,212 patent/US11269873B2/en active Active
-
2022
- 2022-03-04 US US17/687,487 patent/US11709829B2/en active Active
-
2023
- 2023-06-26 US US18/341,422 patent/US20230334044A1/en active Pending
Patent Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20090055355A1 (en) * | 2007-03-27 | 2009-02-26 | Brunner Josie C | Systems, methods, and apparatus for seamless integration for user, contextual, and social awareness in search results through layer approach |
CN102246171A (en) * | 2008-12-11 | 2011-11-16 | 微软公司 | Providing recent history with search results |
US20110040768A1 (en) * | 2009-08-14 | 2011-02-17 | Google Inc. | Context based resource relevance |
US20110225192A1 (en) * | 2010-03-11 | 2011-09-15 | Imig Scott K | Auto-detection of historical search context |
CN103548023A (en) * | 2011-05-27 | 2014-01-29 | 国际商业机器公司 | Automated self-service user support based on ontology |
Also Published As
Publication number | Publication date |
---|---|
US11269873B2 (en) | 2022-03-08 |
EP2955643A1 (en) | 2015-12-16 |
US20230334044A1 (en) | 2023-10-19 |
CN111104496B (en) | 2021-01-26 |
CN105224586B (en) | 2019-12-13 |
CN105224586A (en) | 2016-01-06 |
CN110825835A (en) | 2020-02-21 |
CN110825835B (en) | 2023-06-27 |
US10275485B2 (en) | 2019-04-30 |
US20220188302A1 (en) | 2022-06-16 |
US11709829B2 (en) | 2023-07-25 |
US20190251083A1 (en) | 2019-08-15 |
US20150356136A1 (en) | 2015-12-10 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11709829B2 (en) | Retrieving context from previous sessions | |
US11514035B1 (en) | Query refinements using search data | |
US9582757B1 (en) | Scalable curation system | |
US10354647B2 (en) | Correcting voice recognition using selective re-speak | |
US20150363401A1 (en) | Ranking search results | |
US20130019202A1 (en) | Methods and apparatus for delivering information of various types to a user | |
RU2685991C1 (en) | Instant context-based search recommendations | |
US10503733B2 (en) | Assistive browsing using context | |
US20170200455A1 (en) | Suggested query constructor for voice actions | |
US20180285444A1 (en) | Rewriting contextual queries | |
US11003667B1 (en) | Contextual information for a displayed resource | |
US11392589B2 (en) | Multi-vertical entity-based search system | |
US9811592B1 (en) | Query modification based on textual resource context | |
US9275034B1 (en) | Exceptions to action invocation from parsing rules | |
US11425071B2 (en) | Uniform resource identifier and image sharing for contextual information display | |
US10467300B1 (en) | Topical resource recommendations for a displayed resource | |
RU2691851C1 (en) | Query composition system | |
CN106462603B (en) | Disambiguation of queries implied by multiple entities | |
US10831791B1 (en) | Using location aliases | |
US10528564B2 (en) | Identifying teachable moments for contextual search |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
GR01 | Patent grant | ||
GR01 | Patent grant |