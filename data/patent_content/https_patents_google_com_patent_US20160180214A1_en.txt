US20160180214A1 - Sharp discrepancy learning - Google Patents
Sharp discrepancy learning Download PDFInfo
- Publication number
- US20160180214A1 US20160180214A1 US14/577,301 US201414577301A US2016180214A1 US 20160180214 A1 US20160180214 A1 US 20160180214A1 US 201414577301 A US201414577301 A US 201414577301A US 2016180214 A1 US2016180214 A1 US 2016180214A1
- Authority
- US
- United States
- Prior art keywords
- neural network
- gradient
- output layer
- training
- parameters
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Abandoned
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/045—Combinations of networks
-
- G06N99/005—
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/06—Creation of reference templates; Training of speech recognition systems, e.g. adaptation to the characteristics of the speaker's voice
- G10L15/063—Training
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/08—Speech classification or search
- G10L2015/088—Word spotting
Definitions
- Automatic speech recognition is one technology that is used in mobile devices.
- One task that is a common goal for this technology is to be able to use voice commands to wake up and have basic spoken interactions with the device. For example, it may be desirable to recognize a “hotword” that signals that the mobile device should activate when the mobile device is in a sleep state.
- Training speech recognition models for decoding and identification tasks is based on learning parameters for correct and incorrect model states in neural networks.
- the training may include selecting one model from a set of allowed models that minimizes some cost criterion, often achieved through the employment of some form of gradient descent algorithm.
- one innovative aspect of the subject matter described in this specification can be embodied in methods that include the actions of providing training data to a neural network that includes an output layer and one or more hidden layers, each of the hidden layers comprising multiple nodes and corresponding parameters; calculating a gradient for the neural network by applying a sharp discrepancy output layer objective function to the output layer, wherein the sharp discrepancy output layer objective function is dependent on the training data and parameters; and training the neural network using the gradient to determine a probability that data received by the neural network has features similar to key features of one or more keywords or key phrases, wherein training the neural network using the gradient comprises using the gradient to update the parameters.
- inventions of this aspect include corresponding computer systems, apparatus, and computer programs recorded on one or more computer storage devices, each configured to perform the actions of the methods.
- a system of one or more computers can be configured to perform particular operations or actions by virtue of software, firmware, hardware, or any combination thereof installed on the system that in operation may cause the system to perform the actions.
- One or more computer programs can be configured to perform particular operations or actions by virtue of including instructions that, when executed by data processing apparatus, cause the apparatus to perform the actions.
- the method may comprise providing the trained neural network for use in a speech recognition system, wherein the speech recognition system uses sharp discrepancy learning on real data.
- calculating the gradient for the neural network by applying a sharp discrepancy output layer objective function to the output layer may comprise calculating the gradient of a cross-entropy function.
- the sharp discrepancy output layer objective function may comprise a class of functions with a fraction whose denominator is a product of shifted label scores over a set of labels that correspond to a set of states that are designated as incorrect states.
- the label scores each comprise an exponential of a product of a label, parameter matrix and training data point.
- the class of sharp discrepancy objective functions may comprise functions with a fraction whose numerator is a non-negative label score associated with a state that is designated as a correct state.
- calculating the gradient for the neural network may comprise calculating each component of the gradient separately. In certain aspects calculating the gradient may comprise calculating each component of the gradient in parallel.
- the neural network may comprise a deep neural network.
- the neural network may comprise a deep belief network.
- the method may comprise providing training data to a neural network wherein the training data comprises a plurality of feature vectors and a plurality of label vectors that each indicate whether the corresponding feature vector corresponds to i) one of the keywords or key phrases, or ii) not.
- each of the plurality of feature vectors may represent a different portion of an audio waveform from a received digital representation of speech.
- the digital representation of speech may comprise recorded speech data.
- each of the plurality of label vectors may correspond to one of the feature vectors and may specify a probability distribution for whether the corresponding feature vector corresponds to i) one of the keywords or key phrases, or ii) not.
- the probability distribution may comprise a multinomial distribution.
- training the neural network using the gradient may comprise iterating the parameter updates until an end criteria is met.
- the method may comprise calculating, using the hidden layers, an exponential of a product of a value of one of the parameters and a point from the training data.
- a system trained with sharp discrepancy learning determines numerical values of parameters for correct states that are more separated, for example in terms of numerical distances, from the numerical values of parameters for alternative, incorrect states to reduce a quantity of inference errors at an inference stage, for example a recognition or identification stage.
- a system trained with sharp discrepancy learning may be beneficial, for example, in situations where there may not be enough training data, or the training data is difficult to process and is too noisy to easily learn distinctions between correct and incorrect states, or both.
- a system trained with sharp discrepancy learning may produce better separation of parameter space for correct states versus incorrect states that may lead to higher speech recognition, higher speech identification accuracy, or both.
- a system trained with sharp discrepancy learning may achieve an improvement in recognition accuracy and relative improvement for speaker identification using noisy languages, e.g., Icelandic, French and English.
- a system trained with sharp discrepancy learning allows for faster training of speech recognition models.
- a system trained with sharp discrepancy learning allows for parallelization of the computation of the gradient that is used to train the model, and may improve the computational efficiency, time, and/or resources required.
- a system trained with sharp discrepancy learning uses an objective function that allows parallel computation of second order statistics to reduce computation resource use.
- a system trained with sharp discrepancy learning may be simple to implement using existing infrastructures of training modules and/or may be applied to almost any existing system for training neural networks, for example in settings such as voice search command control, transcription systems, vision processing, image recognition, voice and image identification, machine learning technologies.
- a system may use sharp discrepancy learning when training a recurrent neural network.
- a system trained with sharp discrepancy learning may produce a training model that differs from existing training models produced by standard means. In some implementations, a system trained with sharp discrepancy learning may be used in conjunction with standard training methods and models, for example to reduce a decoding error rate.
- FIG. 1 is an example of a speech recognition process with a neural network.
- FIG. 2 is a flow diagram of a general scheme for sharp discrepancy learning.
- FIG. 3 is a flow diagram of an efficient gradient computation.
- FIG. 4 is a block diagram of a computing system that can be used in connection with the computer-implemented methods described in this document.
- a speech recognition model using neural networks is trained by learning parameters for correct and incorrect model states.
- a neural network receives training data, for example recorded speech data aligned with words that represent the speech content, given by a collection of feature vectors. Each feature vector is connected to a label vector that specifies a probability distribution.
- the neural network may include several layers, and each layer may be associated with a set of parameters that are learned during the training process. In some implementations, the neural network may be a deep neural network or a deep belief network.
- the output layer of the neural network uses an objective function to classify parameters for correct and incorrect model states.
- a sharp discrepancy objective function is constructed for a neural network with a softmax output and cross entropy function.
- the sharp discrepancy objective function is obtained from a typical objective function, for example log-likelihood or cross entropy, comprising a sum of terms for all frames of audio data in a training dataset. For each frame, this term can be represented as a function of a ratio of a numerator and a denominator. In the case of a softmax activation function, the ratio is given by Equation (1).
- the numerator is generally some non-negative parameter value associated with a correct state and the denominator is a sum of parameter values for a set of incorrect states.
- the sharp discrepancy objective function replaces the sum in Equation (1) with a product of shifted parameter values.
- the denominator becomes larger, thus increasing the discrimination between correct and incorrect parameter values achieved during training, and in turn producing more robust and accurate speech and identification recognition.
- the neural network applies a cross-entropy error criterion that results in a minimization problem to be solved for the output layer of the neural network with respect to the parameter values.
- the minimization problem may include minimizing a linear combination of the logarithm of the sharp discrepancy objective function.
- the neural network minimizes the cross-entropy by computing a gradient of the cross-entropy, that is by computing first and second order statistics.
- the particular form of the sharp discrepancy function enables such calculations to be computed independently and therefore the computation of the gradient may be parallelized.
- the neural network updates the parameters accordingly, and the process repeats until all data is processed or until some END criteria is reached.
- a user device may use the neural network to analyze received audio waveforms and determine if a sequence of frames from an audio waveform include a digital representation of a specific keyword or key phrase that correspond with the training data set. Upon determination that a sequence of frames contains a digital representation of a specific keyword, or has probability above a threshold probability that the sequence of frames contains a digital representation of a specific keyword, the user device may perform an action that corresponds with the one of the specific keywords. For instance, the user device may exit a standby state, launch an application, or perform another action.
- FIG. 1 is an example of a speech recognition process 100 with a neural network.
- the speech recognition process 100 includes a feature extraction phase 102 , a neural network phase 106 , and a posterior handling phase 108 .
- the feature extraction phase 102 performs voice-activity detection and generates a feature vector for every frame of audio data, e.g., from an audio waveform.
- the speech recognition process 100 may receive a digital representation of speech, e.g., as a continuous stream of data, and split the stream into multiple frames of data, e.g., where each frame is associated with 10 milliseconds of audio stream data.
- the feature extraction phase 102 may analyze each of the frames to determine feature values for the frames and places the features values in feature vectors which can be stacked, e.g., using left and right context of adjacent feature vectors, to create a larger feature vector.
- the neural network phase 106 provides a feature vector, for a single frame or a stacked vector for multiple frames, to the neural network 104 that is trained to predict posterior probabilities from the features values included in a feature vector.
- the posterior probabilities correspond with entire words or sub-word units for the keywords or key phrases and represent the probability that a keyword or key phrase is included in a frame or multiple consecutive frames.
- the posterior handling phase 108 may combine the posterior probabilities from multiple feature vectors into a confidence score used to determine whether or not a keyword or a key phrase was included in the digital representation of speech, e.g., included in the frames that correspond with the feature vectors.
- the speech recognition process 100 may receive a digital representation of speech for a window of time where the digital representation of speech includes data representing the key-phrase “okay google”.
- the speech recognition process 100 divides the window into twelve frames.
- the feature extraction phase 102 determines features values for each of the twelve frames, creates feature vectors with the corresponding feature values for the twelve frames, and provides the twelve feature vectors to the neural network phase 106 .
- the neural network phase 106 uses a neural network 104 that was trained to identify probabilities for three categories of content including the probability that a feature vector corresponds with the keywords “okay”, and “google”, and the probability that the feature vector does not correspond with either of the keywords, e.g., and is “filler”.
- the neural network 104 analyzes each of the twelve feature vectors and generates frame-level posterior probabilities for each of the three categories.
- the neural network phase 106 provides the frame-level posterior probabilities to the posterior handling phase 108 .
- the posterior handling phase 108 combines the probabilities for the frames to determine a final confidence score for the received window. For example, the posterior handling phase 108 combines the probabilities and determines that the window included “filler” in the first two frames, the keyword “okay” in the next three frames, e.g., where each of the frames is associated with a different portion of the keyword, the keyword “google” in frames six through ten, and “filler” in the remaining two frames. The determination may be specific to a particular frame or for the entire window.
- the feature extraction phase 102 analyzes only the portions of a digital representation of speech that are determined to include speech to reduce computation.
- the feature extraction phase 102 may include a voice-activity detector that may use thirteen-dimensional perceptual linear prediction (PLP) features and their deltas and double-deltas as input to a thirty-component diagonal covariance Gaussian Markov Model, to generate speech and non-speech posteriors for each frame.
- PLP perceptual linear prediction
- the feature extraction phase 102 may perform temporal smoothing on the speech and non-speech posteriors to identify regions where the speech posteriors exceed a threshold and the corresponding frame is likely to include speech.
- the feature extraction phase 102 may generate acoustic features based on forty-dimensional log-filterbank energies computed every ten milliseconds over a window of twenty-five milliseconds.
- the feature extraction phase 102 may stack contiguous frames to add sufficient left and right context, e.g., as the speech recognition process 100 receives additional data and the analysis of the frames progresses, and provide feature vectors for the stack of frames to the neural network 104 .
- the input window may be asymmetric since each recently received frame may add about ten milliseconds of latency to the speech recognition process 100 .
- the speech recognition process 100 stacks ten recently received frames and thirty previously received frames.
- the neural network phase 106 may utilize a fully connected deep neural network 104 with L hidden layers and n hidden nodes per layer where each node computes a non-linear function of the weighted sum of the output of the previous layer. In some implementations, some of the layers may have a different number of nodes.
- the nodes in the output layer may use an objective function, for example a softmax activation function, to determine an estimate of the posterior probability of each output category.
- the nodes in the hidden layers of the neural network 104 may use rectified linear unit (ReLU) functions to determine output using the received input from the previous layer or the values from the feature vectors, e.g., for the initial layer of nodes.
- ReLU rectified linear unit
- the size of the neural network 104 is determined based on the number of output categories, e.g., keywords and/or key phrases and filler.
- the output categories of the neural network 104 can represent entire words or sub-word units in a keyword or a key-phrase. For instance, during keyword or key-phrase detection, the output categories of the neural network 104 can represent entire words.
- the neural network 104 may receive the output categories during training and the output categories may be context dependent, e.g., specific to a particular device, software application, or user. For example, the output categories may be generated at training time via forced alignment using a standard Gaussian mixture model based large vocabulary continuous speech recognition system, e.g., a dictation system.
- the neural network 104 is trained to determine a posterior probability y t i for the i th output category and the t th frame x t , where the values of i are between 1 and N, with N the number of total categories.
- 1 corresponds with the category for non-keyword content, e.g., content that corresponds with the “filler” category.
- Equation (2) ⁇ t i is the network output for the physical state i and the t th training example and is dependent on the parameter vector connected to the last L th neural network layer ⁇ L .
- the neural network 104 may be trained with a software framework that supports distributed computation on multiple CPUs in neural networks. In some implementations, the neural network 104 is trained using asynchronous stochastic gradient descent with an exponential decay for the learning rate.
- the neural network phase 106 provides the posterior probabilities to the posterior handling phase 108 .
- the posterior handling phase 108 may smooth the posterior probabilities 110 over a fixed time window of size W smooth to remove noise from the posterior probabilities, e.g., where posterior probabilities corresponding with multiple frames are used to determine whether a keyword was included in a window. For example, to generate a smoothed posterior probability y′ t i from the posterior probability y t i , for the i th output category and the t th frame x t , where the values of i are between 0 and N ⁇ 1, with N the number of total categories, the posterior handling phase 108 may use Equation (3) below.
- the posterior handling phase 108 may determine a confidence score for the t th frame x t within a sliding window of size w max using Equation (4) below.
- the speech recognition process 100 is a large vocabulary conversational speech recognition process.
- FIG. 2 is a flow diagram of an example process 200 for sharp discrepancy learning.
- the process 200 can be implemented in the neural network phase of the process 100 .
- the process receives some training data ( 201 ).
- the speech recognition process 100 may receive a digital representation of speech as a continuous stream of data that is aligned with words that represent speech content.
- the continuous stream of data may also be split into multiple frames of data, for example, where each frame is associated with 10 milliseconds of audio stream data.
- the data can be represented as a collection of vectors, which are referred to as data points, as shown in Equation (5).
- the process connects each data point x t , where t ⁇ 1,2, . . . , T ⁇ , with a label vector y t that specifies a probability distribution ( 202 ), for example a multinomial distribution over N physical states.
- the process connects a parameter vector ⁇ L to the output layer of the neural network ( 203 ), the entries of which may include a set of initial values or a set of previously learned values.
- the entries of the parameter vectors also called weights, are trained using the training data set.
- the parameters may include parameters in a deep neural network, or the parameters of a hidden Markov model, for example.
- the process associates a collection of label scores with the data points, labels and parameters ( 204 ).
- an index in a label vector may have an entry equal to 1. This entry, i t , may be referred to as a true label of a data point x t .
- the label score associated with the true label of a data point and corresponding parameters is given by e ⁇ i t x t .
- the shift may take an arbitrary value. In some implementations the shift may equal 1.
- the process may calculate the ratio of a true label score and the product of shifted label scores over a set of labels for some parameter and data point ( 206 ), as given by Equation (6).
- ⁇ t i t represents the network output for the physical state i t and the t th training example, and is dependent on the parameter vector ⁇ .
- the physical state i t is the true label of the data point x t .
- the process uses the calculated logarithms of values in Equation (6) to determine an updated score comprising a sum of label scores taken over a subset of data points and parameters ( 207 ).
- the neural network employs an objective function for prediction and minimizes cross-entropy loss. For example, using the cross-entropy error criterion may result in the minimization problem given by Equation (7).
- the process minimizes the updated score function as given by Equation (7) with respect to the parameter vector ⁇ L ( 208 ). Minimization may be achieved using various methods, examples of which include calculating a gradient using first and second order statistics or computing a stochastic gradient.
- the process applies a training process whereby the calculated gradient is used to train and update the parameter vector and determine a set of minimizing parameters ( 209 ).
- the process associates a collection of label scores with the data points, labels and updated parameters and may iterate until some END criteria is met.
- the denominator in Equation (6) is larger than the denominator for a standard softmax activation function, which instead comprises a sum of label scores. Therefore, a larger discrepancy may be achieved using the sharp discrepancy objective function. In some implementations it may be beneficial to take a weighted sum of a sharp discrepancy function with a softmax activation function.
- the sharp discrepancy function may also be applied to other neural network typologies such as recurrent neural networks. It may also be extended with other objective functions that involve probabilities comprising ratios with a sum in the denominator, by replacing the sums with products of shifted parameter values.
- FIG. 3 is a flow diagram of an efficient gradient computation used for training the neural network parameters.
- the process receives some training data ( 301 ).
- the speech recognition process 100 may receive a digital representation of speech as a continuous stream of data that is aligned with words that represent speech content.
- the continuous stream of data may also be split into multiple frames of data, for example, where each frame is associated with 10 milliseconds of audio stream data.
- the data can be represented as a collection of vectors, which are referred to as data points, as shown in Equation (5).
- the process connects each data point x t , where t ⁇ 1,2, . . . , T ⁇ , with a label vector y t that specifies a probability distribution ( 302 ), for example a multinomial distribution over N physical states.
- the process connects a parameter vector ⁇ L to the output layer of the neural network ( 303 ), the entries of which may include a set of initial values or a set of previously learned values.
- the entries of the parameter vectors also called weights, are trained using the training data set.
- the parameters may include parameters in a deep neural network, or the parameters of a hidden Markov model, for example.
- the process associates a collection of label scores with the data points, labels and parameters ( 304 ).
- an index in a label vector may have an entry equal to 1. This entry, i t , may be referred to as a true label of a data point x t .
- the label score associated with the true label of a data point and corresponding parameters is given by e ⁇ i t x t .
- the shift may take an arbitrary value. In some implementations the shift may equal 1.
- the process may calculate the ratio of a true label score and the product of shifted label scores over a set of labels for some parameter and data point ( 305 ), as given by Equation (6).
- the process uses the calculated logarithms of values in Equation (6) to determine an updated score comprising a sum of label scores taken over a subset of data points and parameters.
- the neural network employs an objective function for prediction and minimizes cross-entropy loss. For example, using the cross-entropy error criterion may result in the minimization problem given by Equation (7).
- the process minimizes the cross entropy function given by Equation (7), for example by calculating a gradient vector whose components are the partial derivatives of the cross entropy function with respect to each parameter and use the gradient to update the parameter vector.
- the cross-entropy may be written as given by Equation (8), since the logarithm of the product of scores can be split into a sum or logarithm of individual scores.
- the cross entropy is a linear function with respect to the logarithm.
- the complete gradient vector may therefore be computed as a sum of individual gradients corresponding to each component of the gradient vector.
- the process calculates the gradient components ( 306 ).
- the labels y t are hard and may be represented by sparse normalized vectors consisting of a single non-zero entry. In such a setting, the gradient components are given by Equation (9).
- the process passes the gradient components to the updated gradient block, which collects the individual components and is then used to calculate a complete gradient ( 307 ).
- the process applies a training process whereby the calculated gradient is used to train and update the parameter vector and determine a set of minimizing parameters ( 308 ).
- the process associates a collection of label scores with the data points, labels and updated parameters and may iterate until some END criteria is met ( 309 ).
- Equation (9) shows the linear separation of indices that may be achieved using the described process.
- the gradient components may be calculated separately and in parallel, unlike a standard softmax scheme, for example, which requires the computation of each ⁇ j i before computing the gradient.
- the parallelization of the computation of the gradient that is used to train the model may improve the computational efficiency, time and resources required by the system.
- Embodiments of the subject matter and the functional operations described in this specification can be implemented in digital electronic circuitry, in tangibly-embodied computer software or firmware, in computer hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them.
- Embodiments of the subject matter described in this specification can be implemented as one or more computer programs, i.e., one or more modules of computer program instructions encoded on a tangible non-transitory program carrier for execution by, or to control the operation of, data processing apparatus.
- the program instructions can be encoded on an artificially-generated propagated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal, that is generated to encode information for transmission to suitable receiver apparatus for execution by a data processing apparatus.
- the computer storage medium can be a machine-readable storage device, a machine-readable storage substrate, a random or serial access memory device, or a combination of one or more of them.
- data processing apparatus refers to data processing hardware and encompasses all kinds of apparatus, devices, and machines for processing data, including by way of example a programmable processor, a computer, or multiple processors or computers.
- the apparatus can also be or further include special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit).
- the apparatus can optionally include, in addition to hardware, code that creates an execution environment for computer programs, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, or a combination of one or more of them.
- a computer program which may also be referred to or described as a program, software, a software application, a module, a software module, a script, or code, can be written in any form of programming language, including compiled or interpreted languages, or declarative or procedural languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, or other unit suitable for use in a computing environment.
- a computer program may, but need not, correspond to a file in a file system.
- a program can be stored in a portion of a file that holds other programs or data, e.g., one or more scripts stored in a markup language document, in a single file dedicated to the program in question, or in multiple coordinated files, e.g., files that store one or more modules, sub-programs, or portions of code.
- a computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.
- the processes and logic flows described in this specification can be performed by one or more programmable computers executing one or more computer programs to perform functions by operating on input data and generating output.
- the processes and logic flows can also be performed by, and apparatus can also be implemented as, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit).
- special purpose logic circuitry e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit).
- Computers suitable for the execution of a computer program include, by way of example, general or special purpose microprocessors or both, or any other kind of central processing unit.
- a central processing unit will receive instructions and data from a read-only memory or a random access memory or both.
- the essential elements of a computer are a central processing unit for performing or executing instructions and one or more memory devices for storing instructions and data.
- a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks.
- mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks.
- a computer need not have such devices.
- a computer can be embedded in another device, e.g., a mobile telephone, a personal digital assistant (PDA), a mobile audio or video player, a game console, a Global Positioning System (GPS) receiver, or a portable storage device, e.g., a universal serial bus (USB) flash drive, to name just a few.
- PDA personal digital assistant
- GPS Global Positioning System
- USB universal serial bus
- Computer-readable media suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, e.g., internal hard disks or removable disks; magneto-optical disks; and CD-ROM and DVD-ROM disks.
- semiconductor memory devices e.g., EPROM, EEPROM, and flash memory devices
- magnetic disks e.g., internal hard disks or removable disks
- magneto-optical disks e.g., CD-ROM and DVD-ROM disks.
- the processor and the memory can be supplemented by, or incorporated in, special purpose logic circuitry.
- a computer having a display device, e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to the user and a keyboard and a pointing device, e.g., a mouse or a trackball, by which the user can provide input to the computer.
- a display device e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor
- a keyboard and a pointing device e.g., a mouse or a trackball
- Other kinds of devices can be used to provide for interaction with a user as well; for example, feedback provided to the user can be any form of sensory feedback, e.g., visual feedback, auditory feedback, or tactile feedback; and input from the user can be received in any form, including acoustic, speech, or tactile input.
- a computer can interact with a user by sending documents to and receiving documents from a device that is used by the user; for example, by sending web pages to
- Embodiments of the subject matter described in this specification can be implemented in a computing system that includes a back-end component, e.g., as a data server, or that includes a middleware component, e.g., an application server, or that includes a front-end component, e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the subject matter described in this specification, or any combination of one or more such back-end, middleware, or front-end components.
- the components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include a local area network (LAN) and a wide area network (WAN), e.g., the Internet.
- LAN local area network
- WAN wide area network
- the computing system can include clients and servers.
- a client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other.
- a server transmits data, e.g., an HTML page, to a user device, e.g., for purposes of displaying data to and receiving user input from a user interacting with the user device, which acts as a client.
- Data generated at the user device e.g., a result of the user interaction, can be received from the user device at the server.
- FIG. 4 shows a schematic diagram of a generic computer system 400 .
- the system 400 can be used for the operations described in association with any of the computer-implement methods described previously, according to one implementation.
- the system 400 includes a processor 410 , a memory 420 , a storage device 430 , and an input/output device 440 .
- Each of the components 410 , 420 , 430 , and 440 are interconnected using a system bus 450 .
- the processor 410 is capable of processing instructions for execution within the system 400 .
- the processor 410 is a single-threaded processor.
- the processor 410 is a multi-threaded processor.
- the processor 410 is capable of processing instructions stored in the memory 420 or on the storage device 430 to display graphical information for a user interface on the input/output device 440 .
- the memory 420 stores information within the system 400 .
- the memory 420 is a computer-readable medium.
- the memory 420 is a volatile memory unit.
- the memory 420 is a non-volatile memory unit.
- the storage device 430 is capable of providing mass storage for the system 400 .
- the storage device 430 is a computer-readable medium.
- the storage device 430 may be a floppy disk device, a hard disk device, an optical disk device, or a tape device.
- the input/output device 440 provides input/output operations for the system 400 .
- the input/output device 440 includes a keyboard and/or pointing device.
- the input/output device 440 includes a display unit for displaying graphical user interfaces.
Abstract
Description
- Automatic speech recognition is one technology that is used in mobile devices. One task that is a common goal for this technology is to be able to use voice commands to wake up and have basic spoken interactions with the device. For example, it may be desirable to recognize a “hotword” that signals that the mobile device should activate when the mobile device is in a sleep state.
- Training speech recognition models for decoding and identification tasks is based on learning parameters for correct and incorrect model states in neural networks. The training may include selecting one model from a set of allowed models that minimizes some cost criterion, often achieved through the employment of some form of gradient descent algorithm.
- In general, one innovative aspect of the subject matter described in this specification can be embodied in methods that include the actions of providing training data to a neural network that includes an output layer and one or more hidden layers, each of the hidden layers comprising multiple nodes and corresponding parameters; calculating a gradient for the neural network by applying a sharp discrepancy output layer objective function to the output layer, wherein the sharp discrepancy output layer objective function is dependent on the training data and parameters; and training the neural network using the gradient to determine a probability that data received by the neural network has features similar to key features of one or more keywords or key phrases, wherein training the neural network using the gradient comprises using the gradient to update the parameters. Other embodiments of this aspect include corresponding computer systems, apparatus, and computer programs recorded on one or more computer storage devices, each configured to perform the actions of the methods. A system of one or more computers can be configured to perform particular operations or actions by virtue of software, firmware, hardware, or any combination thereof installed on the system that in operation may cause the system to perform the actions. One or more computer programs can be configured to perform particular operations or actions by virtue of including instructions that, when executed by data processing apparatus, cause the apparatus to perform the actions.
- The foregoing and other embodiments can each optionally include one or more of the following features, alone or in combination. The method may comprise providing the trained neural network for use in a speech recognition system, wherein the speech recognition system uses sharp discrepancy learning on real data.
- In certain aspects, calculating the gradient for the neural network by applying a sharp discrepancy output layer objective function to the output layer may comprise calculating the gradient of a cross-entropy function.
- In some implementations, the sharp discrepancy output layer objective function may comprise a class of functions with a fraction whose denominator is a product of shifted label scores over a set of labels that correspond to a set of states that are designated as incorrect states. In additional aspects the label scores each comprise an exponential of a product of a label, parameter matrix and training data point.
- In some implementations the class of sharp discrepancy objective functions may comprise functions with a fraction whose numerator is a non-negative label score associated with a state that is designated as a correct state.
- In some implementations calculating the gradient for the neural network may comprise calculating each component of the gradient separately. In certain aspects calculating the gradient may comprise calculating each component of the gradient in parallel.
- In some implementations, the neural network may comprise a deep neural network.
- In some implementations, the neural network may comprise a deep belief network.
- In certain aspects, the method may comprise providing training data to a neural network wherein the training data comprises a plurality of feature vectors and a plurality of label vectors that each indicate whether the corresponding feature vector corresponds to i) one of the keywords or key phrases, or ii) not.
- In some implementations each of the plurality of feature vectors may represent a different portion of an audio waveform from a received digital representation of speech. In certain aspects the digital representation of speech may comprise recorded speech data.
- In some implementations each of the plurality of label vectors may correspond to one of the feature vectors and may specify a probability distribution for whether the corresponding feature vector corresponds to i) one of the keywords or key phrases, or ii) not. In certain aspects the probability distribution may comprise a multinomial distribution.
- In additional aspects training the neural network using the gradient may comprise iterating the parameter updates until an end criteria is met. The method may comprise calculating, using the hidden layers, an exponential of a product of a value of one of the parameters and a point from the training data.
- The subject matter described in this specification can be implemented in particular embodiments so as to realize one or more of the following advantages. In some implementations, a system trained with sharp discrepancy learning determines numerical values of parameters for correct states that are more separated, for example in terms of numerical distances, from the numerical values of parameters for alternative, incorrect states to reduce a quantity of inference errors at an inference stage, for example a recognition or identification stage. In some implementations, a system trained with sharp discrepancy learning may be beneficial, for example, in situations where there may not be enough training data, or the training data is difficult to process and is too noisy to easily learn distinctions between correct and incorrect states, or both. In some implementations, a system trained with sharp discrepancy learning may produce better separation of parameter space for correct states versus incorrect states that may lead to higher speech recognition, higher speech identification accuracy, or both. In some implementations, a system trained with sharp discrepancy learning may achieve an improvement in recognition accuracy and relative improvement for speaker identification using noisy languages, e.g., Icelandic, French and English.
- In some implementations, a system trained with sharp discrepancy learning allows for faster training of speech recognition models. In some implementations, a system trained with sharp discrepancy learning allows for parallelization of the computation of the gradient that is used to train the model, and may improve the computational efficiency, time, and/or resources required. In some implementations, a system trained with sharp discrepancy learning uses an objective function that allows parallel computation of second order statistics to reduce computation resource use.
- In some implementations, a system trained with sharp discrepancy learning may be simple to implement using existing infrastructures of training modules and/or may be applied to almost any existing system for training neural networks, for example in settings such as voice search command control, transcription systems, vision processing, image recognition, voice and image identification, machine learning technologies. In some implementations, a system may use sharp discrepancy learning when training a recurrent neural network.
- In some implementations, a system trained with sharp discrepancy learning may produce a training model that differs from existing training models produced by standard means. In some implementations, a system trained with sharp discrepancy learning may be used in conjunction with standard training methods and models, for example to reduce a decoding error rate.
- The details of one or more embodiments of the subject matter of this specification are set forth in the accompanying drawings and the description below. Other features, aspects, and advantages of the subject matter will become apparent from the description, the drawings, and the claims.
-
FIG. 1 is an example of a speech recognition process with a neural network. -
FIG. 2 is a flow diagram of a general scheme for sharp discrepancy learning. -
FIG. 3 is a flow diagram of an efficient gradient computation. -
FIG. 4 is a block diagram of a computing system that can be used in connection with the computer-implemented methods described in this document. - Like reference numbers and designations in the various drawings indicate like elements.
- A speech recognition model using neural networks is trained by learning parameters for correct and incorrect model states. A neural network receives training data, for example recorded speech data aligned with words that represent the speech content, given by a collection of feature vectors. Each feature vector is connected to a label vector that specifies a probability distribution. The neural network may include several layers, and each layer may be associated with a set of parameters that are learned during the training process. In some implementations, the neural network may be a deep neural network or a deep belief network.
- The output layer of the neural network uses an objective function to classify parameters for correct and incorrect model states. A sharp discrepancy objective function is constructed for a neural network with a softmax output and cross entropy function. The sharp discrepancy objective function is obtained from a typical objective function, for example log-likelihood or cross entropy, comprising a sum of terms for all frames of audio data in a training dataset. For each frame, this term can be represented as a function of a ratio of a numerator and a denominator. In the case of a softmax activation function, the ratio is given by Equation (1). The numerator is generally some non-negative parameter value associated with a correct state and the denominator is a sum of parameter values for a set of incorrect states.
-
- The sharp discrepancy objective function replaces the sum in Equation (1) with a product of shifted parameter values. The denominator becomes larger, thus increasing the discrimination between correct and incorrect parameter values achieved during training, and in turn producing more robust and accurate speech and identification recognition.
- The neural network applies a cross-entropy error criterion that results in a minimization problem to be solved for the output layer of the neural network with respect to the parameter values. The minimization problem may include minimizing a linear combination of the logarithm of the sharp discrepancy objective function.
- The neural network minimizes the cross-entropy by computing a gradient of the cross-entropy, that is by computing first and second order statistics. The particular form of the sharp discrepancy function enables such calculations to be computed independently and therefore the computation of the gradient may be parallelized. The neural network updates the parameters accordingly, and the process repeats until all data is processed or until some END criteria is reached.
- A user device may use the neural network to analyze received audio waveforms and determine if a sequence of frames from an audio waveform include a digital representation of a specific keyword or key phrase that correspond with the training data set. Upon determination that a sequence of frames contains a digital representation of a specific keyword, or has probability above a threshold probability that the sequence of frames contains a digital representation of a specific keyword, the user device may perform an action that corresponds with the one of the specific keywords. For instance, the user device may exit a standby state, launch an application, or perform another action.
-
FIG. 1 is an example of aspeech recognition process 100 with a neural network. Thespeech recognition process 100 includes afeature extraction phase 102, aneural network phase 106, and aposterior handling phase 108. Thefeature extraction phase 102 performs voice-activity detection and generates a feature vector for every frame of audio data, e.g., from an audio waveform. For example, thespeech recognition process 100 may receive a digital representation of speech, e.g., as a continuous stream of data, and split the stream into multiple frames of data, e.g., where each frame is associated with 10 milliseconds of audio stream data. - The
feature extraction phase 102 may analyze each of the frames to determine feature values for the frames and places the features values in feature vectors which can be stacked, e.g., using left and right context of adjacent feature vectors, to create a larger feature vector. - The
neural network phase 106 provides a feature vector, for a single frame or a stacked vector for multiple frames, to theneural network 104 that is trained to predict posterior probabilities from the features values included in a feature vector. The posterior probabilities correspond with entire words or sub-word units for the keywords or key phrases and represent the probability that a keyword or key phrase is included in a frame or multiple consecutive frames. - The
posterior handling phase 108 may combine the posterior probabilities from multiple feature vectors into a confidence score used to determine whether or not a keyword or a key phrase was included in the digital representation of speech, e.g., included in the frames that correspond with the feature vectors. - For example, as shown in
FIG. 1 , thespeech recognition process 100 may receive a digital representation of speech for a window of time where the digital representation of speech includes data representing the key-phrase “okay google”. Thespeech recognition process 100 divides the window into twelve frames. Thefeature extraction phase 102 determines features values for each of the twelve frames, creates feature vectors with the corresponding feature values for the twelve frames, and provides the twelve feature vectors to theneural network phase 106. - In the example shown in
FIG. 1 , theneural network phase 106 uses aneural network 104 that was trained to identify probabilities for three categories of content including the probability that a feature vector corresponds with the keywords “okay”, and “google”, and the probability that the feature vector does not correspond with either of the keywords, e.g., and is “filler”. Theneural network 104 analyzes each of the twelve feature vectors and generates frame-level posterior probabilities for each of the three categories. Theneural network phase 106 provides the frame-level posterior probabilities to theposterior handling phase 108. - The
posterior handling phase 108 combines the probabilities for the frames to determine a final confidence score for the received window. For example, theposterior handling phase 108 combines the probabilities and determines that the window included “filler” in the first two frames, the keyword “okay” in the next three frames, e.g., where each of the frames is associated with a different portion of the keyword, the keyword “google” in frames six through ten, and “filler” in the remaining two frames. The determination may be specific to a particular frame or for the entire window. - In some implementations, the
feature extraction phase 102 analyzes only the portions of a digital representation of speech that are determined to include speech to reduce computation. For example, thefeature extraction phase 102 may include a voice-activity detector that may use thirteen-dimensional perceptual linear prediction (PLP) features and their deltas and double-deltas as input to a thirty-component diagonal covariance Gaussian Markov Model, to generate speech and non-speech posteriors for each frame. Thefeature extraction phase 102 may perform temporal smoothing on the speech and non-speech posteriors to identify regions where the speech posteriors exceed a threshold and the corresponding frame is likely to include speech. - For frames that include speech regions, the
feature extraction phase 102 may generate acoustic features based on forty-dimensional log-filterbank energies computed every ten milliseconds over a window of twenty-five milliseconds. Thefeature extraction phase 102 may stack contiguous frames to add sufficient left and right context, e.g., as thespeech recognition process 100 receives additional data and the analysis of the frames progresses, and provide feature vectors for the stack of frames to theneural network 104. For example, the input window may be asymmetric since each recently received frame may add about ten milliseconds of latency to thespeech recognition process 100. In some implementations, thespeech recognition process 100 stacks ten recently received frames and thirty previously received frames. - The
neural network phase 106 may utilize a fully connected deepneural network 104 with L hidden layers and n hidden nodes per layer where each node computes a non-linear function of the weighted sum of the output of the previous layer. In some implementations, some of the layers may have a different number of nodes. - The nodes in the output layer may use an objective function, for example a softmax activation function, to determine an estimate of the posterior probability of each output category. The nodes in the hidden layers of the
neural network 104 may use rectified linear unit (ReLU) functions to determine output using the received input from the previous layer or the values from the feature vectors, e.g., for the initial layer of nodes. - In some implementations, the size of the
neural network 104 is determined based on the number of output categories, e.g., keywords and/or key phrases and filler. - The output categories of the
neural network 104 can represent entire words or sub-word units in a keyword or a key-phrase. For instance, during keyword or key-phrase detection, the output categories of theneural network 104 can represent entire words. Theneural network 104 may receive the output categories during training and the output categories may be context dependent, e.g., specific to a particular device, software application, or user. For example, the output categories may be generated at training time via forced alignment using a standard Gaussian mixture model based large vocabulary continuous speech recognition system, e.g., a dictation system. - The
neural network 104 is trained to determine a posterior probability yt i for the ith output category and the tth frame xt, where the values of i are between 1 and N, with N the number of total categories. In some implementations, 1 corresponds with the category for non-keyword content, e.g., content that corresponds with the “filler” category. The parameters, e.g., the weights and biases, of theneural network 104, θ, may be estimated by minimizing the cross-entropy training criterion over the labeled training data (xt, yt)t=2 T using Equation (2) below. -
- In Equation (2), ŷt i is the network output for the physical state i and the tth training example and is dependent on the parameter vector connected to the last Lth neural network layer θL.
- In some implementations, the
neural network 104 may be trained with a software framework that supports distributed computation on multiple CPUs in neural networks. In some implementations, theneural network 104 is trained using asynchronous stochastic gradient descent with an exponential decay for the learning rate. - The
neural network phase 106 provides the posterior probabilities to theposterior handling phase 108. Theposterior handling phase 108 may smooth theposterior probabilities 110 over a fixed time window of size Wsmooth to remove noise from the posterior probabilities, e.g., where posterior probabilities corresponding with multiple frames are used to determine whether a keyword was included in a window. For example, to generate a smoothed posterior probability y′t i from the posterior probability yt i, for the ith output category and the tth frame xt, where the values of i are between 0 and N−1, with N the number of total categories, theposterior handling phase 108 may use Equation (3) below. -
- In Equation (3), hsmooth=max {1, t−wsmooth+1} is the index of the first frame within the smoothing window. In some implementations, wsmooth=30 frames.
- The
posterior handling phase 108 may determine a confidence score for the tth frame xt within a sliding window of size wmax using Equation (4) below. -
- In Equation (4), y′k i is the smoothed state posterior, and hmax=max {1, t−wmax+1} is the index of the first frame within the sliding window. In some implementations, wmax=100. In some implementations, when Equation (4) does not enforce the order of the sub-word unit sequence, stacked feature vectors are fed as input to the
neural network 104 to help encode contextual information. - In some implementations, the
speech recognition process 100 is a large vocabulary conversational speech recognition process. -
FIG. 2 is a flow diagram of anexample process 200 for sharp discrepancy learning. For example, theprocess 200 can be implemented in the neural network phase of theprocess 100. - The process receives some training data (201). For example, the
speech recognition process 100 may receive a digital representation of speech as a continuous stream of data that is aligned with words that represent speech content. The continuous stream of data may also be split into multiple frames of data, for example, where each frame is associated with 10 milliseconds of audio stream data. The data can be represented as a collection of vectors, which are referred to as data points, as shown in Equation (5). -
χ={x 1 ,x 2 , . . . ,x T} (5) - The process connects each data point xt, where tε{1,2, . . . , T}, with a label vector yt that specifies a probability distribution (202), for example a multinomial distribution over N physical states. The process provides the training data set {xt, yt}t=1 T where ∀t: Σj=1 N[yt]j=1, called the labeled training data, to the neural network for training.
- The process connects a parameter vector θL to the output layer of the neural network (203), the entries of which may include a set of initial values or a set of previously learned values. The entries of the parameter vectors, also called weights, are trained using the training data set. The parameters may include parameters in a deep neural network, or the parameters of a hidden Markov model, for example.
- The process associates a collection of label scores with the data points, labels and parameters (204). The label scores are exponentials of a product of a corresponding label, parameter matrix θ and a data point, that is {ey
t θxt }t=1 T≡{eθt xt }t=1 T. In some implementations, an index in a label vector may have an entry equal to 1. This entry, it, may be referred to as a true label of a data point xt. The label score associated with the true label of a data point and corresponding parameters is given by eθi txt . - The process may then use the set of label scores to calculate a product of shifted label scores over a set of labels for some parameter and data point (205), for example Πk=1 N(1+exp(θkt Txt)). The shift may take an arbitrary value. In some implementations the shift may equal 1.
- The process may calculate the ratio of a true label score and the product of shifted label scores over a set of labels for some parameter and data point (206), as given by Equation (6).
-
- In Equation (6), ŷt i
t represents the network output for the physical state it and the tth training example, and is dependent on the parameter vector θ. The physical state it is the true label of the data point xt. - The process uses the calculated logarithms of values in Equation (6) to determine an updated score comprising a sum of label scores taken over a subset of data points and parameters (207). In some implementations, the neural network employs an objective function for prediction and minimizes cross-entropy loss. For example, using the cross-entropy error criterion may result in the minimization problem given by Equation (7).
-
- The process minimizes the updated score function as given by Equation (7) with respect to the parameter vector θL (208). Minimization may be achieved using various methods, examples of which include calculating a gradient using first and second order statistics or computing a stochastic gradient.
- The process applies a training process whereby the calculated gradient is used to train and update the parameter vector and determine a set of minimizing parameters (209). The process associates a collection of label scores with the data points, labels and updated parameters and may iterate until some END criteria is met.
- In many cases the denominator in Equation (6) is larger than the denominator for a standard softmax activation function, which instead comprises a sum of label scores. Therefore, a larger discrepancy may be achieved using the sharp discrepancy objective function. In some implementations it may be beneficial to take a weighted sum of a sharp discrepancy function with a softmax activation function. The sharp discrepancy function may also be applied to other neural network typologies such as recurrent neural networks. It may also be extended with other objective functions that involve probabilities comprising ratios with a sum in the denominator, by replacing the sums with products of shifted parameter values.
-
FIG. 3 is a flow diagram of an efficient gradient computation used for training the neural network parameters. - The process receives some training data (301). For example, the
speech recognition process 100 may receive a digital representation of speech as a continuous stream of data that is aligned with words that represent speech content. The continuous stream of data may also be split into multiple frames of data, for example, where each frame is associated with 10 milliseconds of audio stream data. The data can be represented as a collection of vectors, which are referred to as data points, as shown in Equation (5). - The process connects each data point xt, where tε{1,2, . . . , T}, with a label vector yt that specifies a probability distribution (302), for example a multinomial distribution over N physical states. The process provides the training data set {xt, yt}t=1 T where ∀t: Σj=1 N[yt]j=1, called the labeled training data, to the neural network for training.
- The process connects a parameter vector θL to the output layer of the neural network (303), the entries of which may include a set of initial values or a set of previously learned values. The entries of the parameter vectors, also called weights, are trained using the training data set. The parameters may include parameters in a deep neural network, or the parameters of a hidden Markov model, for example.
- The process associates a collection of label scores with the data points, labels and parameters (304). The label scores are exponentials of a product of a corresponding label, parameter matrix θ and a data point, that is {ey
t θxt }t=1 T≡{eθt xt }t=1 T. In some implementations, an index in a label vector may have an entry equal to 1. This entry, it, may be referred to as a true label of a data point xt. The label score associated with the true label of a data point and corresponding parameters is given by eθi txt . - The process may then use the set of label scores to calculate a product of shifted label scores over a set of labels for some parameter and data point, for example Πk=1 N(1+exp(θkt Txt)). The shift may take an arbitrary value. In some implementations the shift may equal 1.
- The process may calculate the ratio of a true label score and the product of shifted label scores over a set of labels for some parameter and data point (305), as given by Equation (6).
- The process uses the calculated logarithms of values in Equation (6) to determine an updated score comprising a sum of label scores taken over a subset of data points and parameters. In some implementations, the neural network employs an objective function for prediction and minimizes cross-entropy loss. For example, using the cross-entropy error criterion may result in the minimization problem given by Equation (7).
- The process minimizes the cross entropy function given by Equation (7), for example by calculating a gradient vector whose components are the partial derivatives of the cross entropy function with respect to each parameter and use the gradient to update the parameter vector. Using the sharp discrepancy objective function as an output layer activation the cross-entropy may be written as given by Equation (8), since the logarithm of the product of scores can be split into a sum or logarithm of individual scores.
-
- As shown by Equation (8), the cross entropy is a linear function with respect to the logarithm. The complete gradient vector may therefore be computed as a sum of individual gradients corresponding to each component of the gradient vector.
- The process calculates the gradient components (306). In some implementations, the labels yt are hard and may be represented by sparse normalized vectors consisting of a single non-zero entry. In such a setting, the gradient components are given by Equation (9).
-
- The process passes the gradient components to the updated gradient block, which collects the individual components and is then used to calculate a complete gradient (307).
- The process applies a training process whereby the calculated gradient is used to train and update the parameter vector and determine a set of minimizing parameters (308). The process associates a collection of label scores with the data points, labels and updated parameters and may iterate until some END criteria is met (309).
- In many cases Equation (9) shows the linear separation of indices that may be achieved using the described process. The gradient components may be calculated separately and in parallel, unlike a standard softmax scheme, for example, which requires the computation of each ŷj i before computing the gradient. The parallelization of the computation of the gradient that is used to train the model may improve the computational efficiency, time and resources required by the system.
- Embodiments of the subject matter and the functional operations described in this specification can be implemented in digital electronic circuitry, in tangibly-embodied computer software or firmware, in computer hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them. Embodiments of the subject matter described in this specification can be implemented as one or more computer programs, i.e., one or more modules of computer program instructions encoded on a tangible non-transitory program carrier for execution by, or to control the operation of, data processing apparatus. Alternatively or in addition, the program instructions can be encoded on an artificially-generated propagated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal, that is generated to encode information for transmission to suitable receiver apparatus for execution by a data processing apparatus. The computer storage medium can be a machine-readable storage device, a machine-readable storage substrate, a random or serial access memory device, or a combination of one or more of them.
- The term “data processing apparatus” refers to data processing hardware and encompasses all kinds of apparatus, devices, and machines for processing data, including by way of example a programmable processor, a computer, or multiple processors or computers. The apparatus can also be or further include special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit). The apparatus can optionally include, in addition to hardware, code that creates an execution environment for computer programs, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, or a combination of one or more of them.
- A computer program, which may also be referred to or described as a program, software, a software application, a module, a software module, a script, or code, can be written in any form of programming language, including compiled or interpreted languages, or declarative or procedural languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, or other unit suitable for use in a computing environment. A computer program may, but need not, correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data, e.g., one or more scripts stored in a markup language document, in a single file dedicated to the program in question, or in multiple coordinated files, e.g., files that store one or more modules, sub-programs, or portions of code. A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.
- The processes and logic flows described in this specification can be performed by one or more programmable computers executing one or more computer programs to perform functions by operating on input data and generating output. The processes and logic flows can also be performed by, and apparatus can also be implemented as, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit).
- Computers suitable for the execution of a computer program include, by way of example, general or special purpose microprocessors or both, or any other kind of central processing unit. Generally, a central processing unit will receive instructions and data from a read-only memory or a random access memory or both. The essential elements of a computer are a central processing unit for performing or executing instructions and one or more memory devices for storing instructions and data. Generally, a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks. However, a computer need not have such devices. Moreover, a computer can be embedded in another device, e.g., a mobile telephone, a personal digital assistant (PDA), a mobile audio or video player, a game console, a Global Positioning System (GPS) receiver, or a portable storage device, e.g., a universal serial bus (USB) flash drive, to name just a few.
- Computer-readable media suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, e.g., internal hard disks or removable disks; magneto-optical disks; and CD-ROM and DVD-ROM disks. The processor and the memory can be supplemented by, or incorporated in, special purpose logic circuitry.
- To provide for interaction with a user, embodiments of the subject matter described in this specification can be implemented on a computer having a display device, e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to the user and a keyboard and a pointing device, e.g., a mouse or a trackball, by which the user can provide input to the computer. Other kinds of devices can be used to provide for interaction with a user as well; for example, feedback provided to the user can be any form of sensory feedback, e.g., visual feedback, auditory feedback, or tactile feedback; and input from the user can be received in any form, including acoustic, speech, or tactile input. In addition, a computer can interact with a user by sending documents to and receiving documents from a device that is used by the user; for example, by sending web pages to a web browser on a user's device in response to requests received from the web browser.
- Embodiments of the subject matter described in this specification can be implemented in a computing system that includes a back-end component, e.g., as a data server, or that includes a middleware component, e.g., an application server, or that includes a front-end component, e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the subject matter described in this specification, or any combination of one or more such back-end, middleware, or front-end components. The components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include a local area network (LAN) and a wide area network (WAN), e.g., the Internet.
- The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other. In some embodiments, a server transmits data, e.g., an HTML page, to a user device, e.g., for purposes of displaying data to and receiving user input from a user interacting with the user device, which acts as a client. Data generated at the user device, e.g., a result of the user interaction, can be received from the user device at the server.
- An example of one such type of computer is shown in
FIG. 4 , which shows a schematic diagram of ageneric computer system 400. Thesystem 400 can be used for the operations described in association with any of the computer-implement methods described previously, according to one implementation. Thesystem 400 includes a processor 410, a memory 420, a storage device 430, and an input/output device 440. Each of the components 410, 420, 430, and 440 are interconnected using a system bus 450. The processor 410 is capable of processing instructions for execution within thesystem 400. In one implementation, the processor 410 is a single-threaded processor. In another implementation, the processor 410 is a multi-threaded processor. The processor 410 is capable of processing instructions stored in the memory 420 or on the storage device 430 to display graphical information for a user interface on the input/output device 440. - The memory 420 stores information within the
system 400. In one implementation, the memory 420 is a computer-readable medium. In one implementation, the memory 420 is a volatile memory unit. In another implementation, the memory 420 is a non-volatile memory unit. - The storage device 430 is capable of providing mass storage for the
system 400. In one implementation, the storage device 430 is a computer-readable medium. In various different implementations, the storage device 430 may be a floppy disk device, a hard disk device, an optical disk device, or a tape device. - The input/output device 440 provides input/output operations for the
system 400. In one implementation, the input/output device 440 includes a keyboard and/or pointing device. In another implementation, the input/output device 440 includes a display unit for displaying graphical user interfaces. - While this specification contains many specific implementation details, these should not be construed as limitations on the scope of any invention or on the scope of what may be claimed, but rather as descriptions of features that may be specific to particular embodiments of particular inventions. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely, various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Moreover, although features may be described above as acting in certain combinations and even initially claimed as such, one or more features from a claimed combination can in some cases be excised from the combination, and the claimed combination may be directed to a subcombination or variation of a subcombination.
- Similarly, while operations are depicted in the drawings in a particular order, this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order, or that all illustrated operations be performed, to achieve desirable results. In certain circumstances, multitasking and parallel processing may be advantageous. Moreover, the separation of various system modules and components in the embodiments described above should not be understood as requiring such separation in all embodiments, and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.
- Particular embodiments of the subject matter have been described. Other embodiments are within the scope of the following claims. For example, the actions recited in the claims can be performed in a different order and still achieve desirable results. As one example, the processes depicted in the accompanying figures do not necessarily require the particular order shown, or sequential order, to achieve desirable results. In some cases, multitasking and parallel processing may be advantageous.
Claims (20)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/577,301 US20160180214A1 (en) | 2014-12-19 | 2014-12-19 | Sharp discrepancy learning |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/577,301 US20160180214A1 (en) | 2014-12-19 | 2014-12-19 | Sharp discrepancy learning |
Publications (1)
Publication Number | Publication Date |
---|---|
US20160180214A1 true US20160180214A1 (en) | 2016-06-23 |
Family
ID=56129825
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US14/577,301 Abandoned US20160180214A1 (en) | 2014-12-19 | 2014-12-19 | Sharp discrepancy learning |
Country Status (1)
Country | Link |
---|---|
US (1) | US20160180214A1 (en) |
Cited By (29)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN106919918A (en) * | 2017-02-27 | 2017-07-04 | 腾讯科技（上海）有限公司 | A kind of face tracking method and device |
CN107622274A (en) * | 2016-07-15 | 2018-01-23 | 北京市商汤科技开发有限公司 | Neural network training method, device and computer equipment for image procossing |
CN107665706A (en) * | 2016-07-29 | 2018-02-06 | 科大讯飞股份有限公司 | Rapid Speech exchange method and system |
CN108021537A (en) * | 2018-01-05 | 2018-05-11 | 南京大学 | A kind of softmax implementations based on hardware platform |
WO2018099085A1 (en) * | 2016-11-29 | 2018-06-07 | 华为技术有限公司 | Neural network model training method and device, and chip |
US20180322865A1 (en) * | 2017-05-05 | 2018-11-08 | Baidu Online Network Technology (Beijing) Co., Ltd . | Artificial intelligence-based acoustic model training method and apparatus, device and storage medium |
US20180366107A1 (en) * | 2017-06-16 | 2018-12-20 | Baidu Online Network Technology (Beijing) Co., Ltd. | Method and device for training acoustic model, computer device and storage medium |
US20190147855A1 (en) * | 2017-11-13 | 2019-05-16 | GM Global Technology Operations LLC | Neural network for use in speech recognition arbitration |
US10304440B1 (en) * | 2015-07-10 | 2019-05-28 | Amazon Technologies, Inc. | Keyword spotting using multi-task configuration |
US10388276B2 (en) * | 2017-05-16 | 2019-08-20 | Baidu Online Network Technology (Beijing) Co., Ltd. | Method and device for waking up via speech based on artificial intelligence and computer device |
CN110288089A (en) * | 2019-06-28 | 2019-09-27 | 北京百度网讯科技有限公司 | Method and apparatus for sending information |
CN110855485A (en) * | 2019-11-08 | 2020-02-28 | 西北工业大学青岛研究院 | Method and system for determining network flow of IP backbone network |
CN111027671A (en) * | 2019-11-12 | 2020-04-17 | 华中科技大学 | Distributed deep learning communication method and system based on model structure characteristics |
CN111144582A (en) * | 2019-12-31 | 2020-05-12 | 第四范式（北京）技术有限公司 | Method and corresponding device for training and updating machine learning model |
CN111444255A (en) * | 2018-12-29 | 2020-07-24 | 杭州海康存储科技有限公司 | Training method and device of data model |
CN111602146A (en) * | 2018-01-16 | 2020-08-28 | 奥林巴斯株式会社 | Data processing system and data processing method |
CN111652378A (en) * | 2019-05-23 | 2020-09-11 | 谷歌有限责任公司 | Learning to select vocabulary of category features |
US20200387789A1 (en) * | 2019-06-06 | 2020-12-10 | Riskfuel Analytics Inc. | Neural network training |
CN112288342A (en) * | 2020-12-29 | 2021-01-29 | 曜立科技(北京)有限公司 | Data processing method and system for improving multi-center cooperation quality control |
US11093816B2 (en) * | 2017-10-05 | 2021-08-17 | Salesforce.Com, Inc. | Convolutional neural network (CNN)-based anomaly detection |
US11188909B2 (en) | 2017-12-07 | 2021-11-30 | Bank Of America Corporation | Automated event processing computing platform for handling and enriching blockchain data |
US11196747B2 (en) | 2017-12-07 | 2021-12-07 | Bank Of America Corporation | Automated event processing computing platform for handling and enriching blockchain data |
CN113902921A (en) * | 2018-11-30 | 2022-01-07 | 腾讯科技（深圳）有限公司 | Image processing method, device, equipment and storage medium |
US11308974B2 (en) * | 2017-10-23 | 2022-04-19 | Iflytek Co., Ltd. | Target voice detection method and apparatus |
US11468901B2 (en) * | 2016-09-12 | 2022-10-11 | Pindrop Security, Inc. | End-to-end speaker recognition using deep neural network |
US11514901B2 (en) * | 2016-03-21 | 2022-11-29 | Amazon Technologies, Inc. | Anchored speech detection and speech recognition |
US11657823B2 (en) | 2016-09-19 | 2023-05-23 | Pindrop Security, Inc. | Channel-compensated low-level features for speaker recognition |
US11670304B2 (en) | 2016-09-19 | 2023-06-06 | Pindrop Security, Inc. | Speaker recognition in the call center |
US11870932B2 (en) | 2019-02-06 | 2024-01-09 | Pindrop Security, Inc. | Systems and methods of gateway detection in a telephone network |
Citations (9)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6018728A (en) * | 1996-02-09 | 2000-01-25 | Sarnoff Corporation | Method and apparatus for training a neural network to learn hierarchical representations of objects and to detect and classify objects with uncertain training data |
US6128606A (en) * | 1997-03-11 | 2000-10-03 | At&T Corporation | Module for constructing trainable modular network in which each module inputs and outputs data structured as a graph |
US20120072215A1 (en) * | 2010-09-21 | 2012-03-22 | Microsoft Corporation | Full-sequence training of deep structures for speech recognition |
US20140040748A1 (en) * | 2011-09-30 | 2014-02-06 | Apple Inc. | Interface for a Virtual Digital Assistant |
US20140257803A1 (en) * | 2013-03-06 | 2014-09-11 | Microsoft Corporation | Conservatively adapting a deep neural network in a recognition system |
US20140279771A1 (en) * | 2013-03-12 | 2014-09-18 | Oracle International Corporation | Novel Quadratic Regularization For Neural Network With Skip-Layer Connections |
US20150161995A1 (en) * | 2013-12-06 | 2015-06-11 | Nuance Communications, Inc. | Learning front-end speech recognition parameters within neural network training |
US20160071515A1 (en) * | 2014-09-09 | 2016-03-10 | Disney Enterprises, Inc. | Sectioned memory networks for online word-spotting in continuous speech |
US20160189058A1 (en) * | 2013-07-22 | 2016-06-30 | Aselsan Elektronik Sanayi Ve Ticaret Anonim Sirketi | Incremental learner via an adaptive mixture of weak learners distributed on a non-rigid binary tree |
-
2014
- 2014-12-19 US US14/577,301 patent/US20160180214A1/en not_active Abandoned
Patent Citations (9)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6018728A (en) * | 1996-02-09 | 2000-01-25 | Sarnoff Corporation | Method and apparatus for training a neural network to learn hierarchical representations of objects and to detect and classify objects with uncertain training data |
US6128606A (en) * | 1997-03-11 | 2000-10-03 | At&T Corporation | Module for constructing trainable modular network in which each module inputs and outputs data structured as a graph |
US20120072215A1 (en) * | 2010-09-21 | 2012-03-22 | Microsoft Corporation | Full-sequence training of deep structures for speech recognition |
US20140040748A1 (en) * | 2011-09-30 | 2014-02-06 | Apple Inc. | Interface for a Virtual Digital Assistant |
US20140257803A1 (en) * | 2013-03-06 | 2014-09-11 | Microsoft Corporation | Conservatively adapting a deep neural network in a recognition system |
US20140279771A1 (en) * | 2013-03-12 | 2014-09-18 | Oracle International Corporation | Novel Quadratic Regularization For Neural Network With Skip-Layer Connections |
US20160189058A1 (en) * | 2013-07-22 | 2016-06-30 | Aselsan Elektronik Sanayi Ve Ticaret Anonim Sirketi | Incremental learner via an adaptive mixture of weak learners distributed on a non-rigid binary tree |
US20150161995A1 (en) * | 2013-12-06 | 2015-06-11 | Nuance Communications, Inc. | Learning front-end speech recognition parameters within neural network training |
US20160071515A1 (en) * | 2014-09-09 | 2016-03-10 | Disney Enterprises, Inc. | Sectioned memory networks for online word-spotting in continuous speech |
Non-Patent Citations (2)
Title |
---|
ABU-MOSTAFA, Y., "Learning From Data: Lecture 9" from an online course <http://work.caltech.edu/telecourse.html#lectures> taught live (May 1 2012) 25 pp. * |
NOVOKHODKO, A. et al., "A parallel implementation of the batch backpropagation trainging of neural networks," Proc. 2001 IEEE Intl. Joint Conf. on Neural Networks, Vol. 3 (2001) pp. 1783-1786. * |
Cited By (36)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10304440B1 (en) * | 2015-07-10 | 2019-05-28 | Amazon Technologies, Inc. | Keyword spotting using multi-task configuration |
US11514901B2 (en) * | 2016-03-21 | 2022-11-29 | Amazon Technologies, Inc. | Anchored speech detection and speech recognition |
CN107622274A (en) * | 2016-07-15 | 2018-01-23 | 北京市商汤科技开发有限公司 | Neural network training method, device and computer equipment for image procossing |
CN107665706A (en) * | 2016-07-29 | 2018-02-06 | 科大讯飞股份有限公司 | Rapid Speech exchange method and system |
US11468901B2 (en) * | 2016-09-12 | 2022-10-11 | Pindrop Security, Inc. | End-to-end speaker recognition using deep neural network |
US11670304B2 (en) | 2016-09-19 | 2023-06-06 | Pindrop Security, Inc. | Speaker recognition in the call center |
US11657823B2 (en) | 2016-09-19 | 2023-05-23 | Pindrop Security, Inc. | Channel-compensated low-level features for speaker recognition |
WO2018099085A1 (en) * | 2016-11-29 | 2018-06-07 | 华为技术有限公司 | Neural network model training method and device, and chip |
CN106919918A (en) * | 2017-02-27 | 2017-07-04 | 腾讯科技（上海）有限公司 | A kind of face tracking method and device |
US10565983B2 (en) * | 2017-05-05 | 2020-02-18 | Baidu Online Network Technology (Beijing) Co., Ltd. | Artificial intelligence-based acoustic model training method and apparatus, device and storage medium |
US20180322865A1 (en) * | 2017-05-05 | 2018-11-08 | Baidu Online Network Technology (Beijing) Co., Ltd . | Artificial intelligence-based acoustic model training method and apparatus, device and storage medium |
US10388276B2 (en) * | 2017-05-16 | 2019-08-20 | Baidu Online Network Technology (Beijing) Co., Ltd. | Method and device for waking up via speech based on artificial intelligence and computer device |
US10522136B2 (en) * | 2017-06-16 | 2019-12-31 | Baidu Online Network Technology (Beijing) Co., Ltd. | Method and device for training acoustic model, computer device and storage medium |
US20180366107A1 (en) * | 2017-06-16 | 2018-12-20 | Baidu Online Network Technology (Beijing) Co., Ltd. | Method and device for training acoustic model, computer device and storage medium |
US11093816B2 (en) * | 2017-10-05 | 2021-08-17 | Salesforce.Com, Inc. | Convolutional neural network (CNN)-based anomaly detection |
US11308974B2 (en) * | 2017-10-23 | 2022-04-19 | Iflytek Co., Ltd. | Target voice detection method and apparatus |
US20190147855A1 (en) * | 2017-11-13 | 2019-05-16 | GM Global Technology Operations LLC | Neural network for use in speech recognition arbitration |
US11558392B2 (en) | 2017-12-07 | 2023-01-17 | Bank Of America Corporation | Automated event processing computing platform for handling and enriching blockchain data |
US11265326B2 (en) * | 2017-12-07 | 2022-03-01 | Bank Of America Corporation | Automated event processing computing platform for handling and enriching blockchain data |
US11729180B2 (en) | 2017-12-07 | 2023-08-15 | Bank Of America Corporation | Automated event processing computing platform for handling and enriching blockchain data |
US11188909B2 (en) | 2017-12-07 | 2021-11-30 | Bank Of America Corporation | Automated event processing computing platform for handling and enriching blockchain data |
US11196747B2 (en) | 2017-12-07 | 2021-12-07 | Bank Of America Corporation | Automated event processing computing platform for handling and enriching blockchain data |
US11734686B2 (en) | 2017-12-07 | 2023-08-22 | Bank Of America Corporation | Automated event processing computing platform for handling and enriching blockchain data |
CN108021537A (en) * | 2018-01-05 | 2018-05-11 | 南京大学 | A kind of softmax implementations based on hardware platform |
CN111602146A (en) * | 2018-01-16 | 2020-08-28 | 奥林巴斯株式会社 | Data processing system and data processing method |
CN113902921A (en) * | 2018-11-30 | 2022-01-07 | 腾讯科技（深圳）有限公司 | Image processing method, device, equipment and storage medium |
CN111444255A (en) * | 2018-12-29 | 2020-07-24 | 杭州海康存储科技有限公司 | Training method and device of data model |
US11870932B2 (en) | 2019-02-06 | 2024-01-09 | Pindrop Security, Inc. | Systems and methods of gateway detection in a telephone network |
CN111652378A (en) * | 2019-05-23 | 2020-09-11 | 谷歌有限责任公司 | Learning to select vocabulary of category features |
US11714857B2 (en) | 2019-05-23 | 2023-08-01 | Google Llc | Learning to select vocabularies for categorical features |
US20200387789A1 (en) * | 2019-06-06 | 2020-12-10 | Riskfuel Analytics Inc. | Neural network training |
CN110288089A (en) * | 2019-06-28 | 2019-09-27 | 北京百度网讯科技有限公司 | Method and apparatus for sending information |
CN110855485A (en) * | 2019-11-08 | 2020-02-28 | 西北工业大学青岛研究院 | Method and system for determining network flow of IP backbone network |
CN111027671A (en) * | 2019-11-12 | 2020-04-17 | 华中科技大学 | Distributed deep learning communication method and system based on model structure characteristics |
CN111144582A (en) * | 2019-12-31 | 2020-05-12 | 第四范式（北京）技术有限公司 | Method and corresponding device for training and updating machine learning model |
CN112288342A (en) * | 2020-12-29 | 2021-01-29 | 曜立科技(北京)有限公司 | Data processing method and system for improving multi-center cooperation quality control |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US20160180214A1 (en) | Sharp discrepancy learning | |
US10909456B2 (en) | Training multiple neural networks with different accuracy | |
US11854534B1 (en) | Asynchronous optimization for sequence training of neural networks | |
US11776531B2 (en) | Encoder-decoder models for sequence to sequence mapping | |
US9715660B2 (en) | Transfer learning for deep neural network based hotword detection | |
US11934956B2 (en) | Regularizing machine learning models | |
US9646634B2 (en) | Low-rank hidden input layer for speech recognition neural network | |
US11900915B2 (en) | Multi-dialect and multilingual speech recognition | |
US9754584B2 (en) | User specified keyword spotting using neural network feature extractor | |
US11934935B2 (en) | Feedforward generative neural networks | |
US10431206B2 (en) | Multi-accent speech recognition | |
US9443517B1 (en) | Generating sounds for detectability by neural networks | |
US20160035344A1 (en) | Identifying the language of a spoken utterance | |
US10762417B2 (en) | Efficient connectionist temporal classification for binary classification | |
US20200335108A1 (en) | Attentive adversarial domain-invariant training | |
US20240153508A1 (en) | End-to-End Speech Recognition Adapted for Multi-Speaker Applications |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:KANEVSKY, DIMITRI;MORENO, IGNACIO LOPEZ;ULIANOV, DMITRII VLADIMIROVICH;SIGNING DATES FROM 20141218 TO 20141219;REEL/FRAME:035303/0741 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044129/0001Effective date: 20170929 |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NON FINAL ACTION MAILED |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: RESPONSE TO NON-FINAL OFFICE ACTION ENTERED AND FORWARDED TO EXAMINER |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: FINAL REJECTION MAILED |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: RESPONSE AFTER FINAL ACTION FORWARDED TO EXAMINER |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: ADVISORY ACTION MAILED |
|
STCB | Information on status: application discontinuation |
Free format text: ABANDONED -- FAILURE TO RESPOND TO AN OFFICE ACTION |