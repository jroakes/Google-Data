US9418482B1 - Discovering visited travel destinations from a set of digital images - Google Patents
Discovering visited travel destinations from a set of digital images Download PDFInfo
- Publication number
- US9418482B1 US9418482B1 US14/288,902 US201414288902A US9418482B1 US 9418482 B1 US9418482 B1 US 9418482B1 US 201414288902 A US201414288902 A US 201414288902A US 9418482 B1 US9418482 B1 US 9418482B1
- Authority
- US
- United States
- Prior art keywords
- user
- geo
- location
- digital image
- social networking
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
- 230000006855 networking Effects 0.000 claims abstract description 107
- 238000000034 method Methods 0.000 claims description 46
- 230000009471 action Effects 0.000 claims description 14
- 238000009877 rendering Methods 0.000 description 21
- 238000012360 testing method Methods 0.000 description 19
- 238000010586 diagram Methods 0.000 description 10
- 230000008569 process Effects 0.000 description 6
- 238000001514 detection method Methods 0.000 description 3
- 238000002372 labelling Methods 0.000 description 3
- 238000012986 modification Methods 0.000 description 3
- 230000004048 modification Effects 0.000 description 3
- SNICXCGAKADSCV-UHFFFAOYSA-N nicotine Chemical compound CN1CCCC1C1=CC=CN=C1 SNICXCGAKADSCV-UHFFFAOYSA-N 0.000 description 3
- 230000003287 optical effect Effects 0.000 description 3
- 238000012545 processing Methods 0.000 description 3
- 238000012549 training Methods 0.000 description 3
- 238000004891 communication Methods 0.000 description 2
- 230000002860 competitive effect Effects 0.000 description 2
- 238000004590 computer program Methods 0.000 description 2
- 230000006870 function Effects 0.000 description 2
- 230000014509 gene expression Effects 0.000 description 2
- 230000002452 interceptive effect Effects 0.000 description 2
- 238000010422 painting Methods 0.000 description 2
- 238000009825 accumulation Methods 0.000 description 1
- 230000004888 barrier function Effects 0.000 description 1
- 230000008901 benefit Effects 0.000 description 1
- XIWFQDBQMCDYJT-UHFFFAOYSA-M benzyl-dimethyl-tridecylazanium;chloride Chemical compound [Cl-].CCCCCCCCCCCCC[N+](C)(C)CC1=CC=CC=C1 XIWFQDBQMCDYJT-UHFFFAOYSA-M 0.000 description 1
- 230000002457 bidirectional effect Effects 0.000 description 1
- 230000015572 biosynthetic process Effects 0.000 description 1
- 230000001419 dependent effect Effects 0.000 description 1
- 238000013461 design Methods 0.000 description 1
- 230000000694 effects Effects 0.000 description 1
- 238000003384 imaging method Methods 0.000 description 1
- 230000003993 interaction Effects 0.000 description 1
- 230000000670 limiting effect Effects 0.000 description 1
- 238000007726 management method Methods 0.000 description 1
- 238000013507 mapping Methods 0.000 description 1
- 230000008520 organization Effects 0.000 description 1
- 238000004091 panning Methods 0.000 description 1
- 238000003825 pressing Methods 0.000 description 1
- 238000001303 quality assessment method Methods 0.000 description 1
- 230000002829 reductive effect Effects 0.000 description 1
- 238000011160 research Methods 0.000 description 1
- 230000002441 reversible effect Effects 0.000 description 1
- 238000012552 review Methods 0.000 description 1
- 239000011435 rock Substances 0.000 description 1
- 230000000007 visual effect Effects 0.000 description 1
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/953—Querying, e.g. by the use of web search engines
- G06F16/9537—Spatial or temporal dependent retrieval, e.g. spatiotemporal queries
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T19/00—Manipulating 3D models or images for computer graphics
- G06T19/006—Mixed reality
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/58—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/58—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
- G06F16/583—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using metadata automatically derived from the content
-
- G—PHYSICS
- G01—MEASURING; TESTING
- G01C—MEASURING DISTANCES, LEVELS OR BEARINGS; SURVEYING; NAVIGATION; GYROSCOPIC INSTRUMENTS; PHOTOGRAMMETRY OR VIDEOGRAMMETRY
- G01C21/00—Navigation; Navigational instruments not provided for in groups G01C1/00 - G01C19/00
- G01C21/26—Navigation; Navigational instruments not provided for in groups G01C1/00 - G01C19/00 specially adapted for navigation in a road network
- G01C21/34—Route searching; Route guidance
- G01C21/36—Input/output arrangements for on-board computers
- G01C21/3679—Retrieval, searching and output of POI information, e.g. hotels, restaurants, shops, filling stations, parking facilities
- G01C21/3682—Retrieval, searching and output of POI information, e.g. hotels, restaurants, shops, filling stations, parking facilities output of POI information on a road map
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/40—Information retrieval; Database structures therefor; File system structures therefor of multimedia data, e.g. slideshows comprising image and additional audio data
- G06F16/48—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
- G06F16/487—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using geographical or spatial information, e.g. location
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/954—Navigation, e.g. using categorised browsing
-
- G06F17/30041—
-
- G06F17/30873—
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q50/00—Systems or methods specially adapted for specific business sectors, e.g. utilities or tourism
- G06Q50/01—Social networking
Definitions
- Still images, audio recordings, video sequences, and multimedia records are referred to collectively herein with the term “media assets,” and the term “image” refers both to an individual image, and to videos, which are simply a collection of images with accompanying audio. With very large numbers of media assets, organization can become difficult.
- TripAdvisor users indicate cities that they have visited by selecting cities from a list, or entering the names of cities.
- a personalized map having pushpins at the locations of visited cities can then be viewed, and the cities visited by others in the user's social networking system can also be viewed.
- this system relies on manual entry of the cities visited, and therefore many busy users do not enter this information.
- FIG. 1 is a block diagram illustrative of an embodiment of an environment for discovering visited travel destinations from digital images
- FIG. 2 is an illustration of possible connections between users within a social network.
- FIG. 3 is a block diagram illustrative of an embodiment of an environment for discovering visited travel destinations from digital images.
- FIG. 4A is a block diagram illustrative of an embodiment of the landmark registration engine.
- FIG. 4B is a diagram illustrative of an embodiment of a 3D point annotator for labelling points as confusing.
- FIG. 4C is a block diagram illustrative of an embodiment of the 3D point annotator for labelling points as confusing.
- FIG. 4D is a block diagram illustrative of an embodiment of the 3D point annotator for annotating 3D points from 3D models.
- FIG. 4E is a drawing illustrative of an embodiment of an image that has overlaid annotations for objects.
- FIG. 5 is a drawing illustrative of an embodiment of a map rendering with geo-registered images.
- FIG. 6 is a drawing illustrative of an embodiment of an image view that provides additional information related to a geo-located image.
- FIG. 7 is a drawing illustrative of an embodiment of a map that is overlaid with geo-registered images and information panes and controls for navigating the map.
- the present disclosure is directed towards providing a user of a social networking system with means for exploring images captured by the user's connections within the social networking system.
- the system includes analyzing the images to recognize landmark images for estimating the precise locations from which the images were captured, placing these geo-registered images onto a map, and/or providing means for the user to explore the images on this map in a number of intuitive ways.
- each user can receive a user travel score that further facilitates the user when searching and browsing the images from her connections in the social networking system.
- a computer program product can include one or more storage medium, for example; magnetic storage media such as magnetic disk (such as a floppy disk) or magnetic tape; optical storage media such as optical disk, optical tape, or machine readable bar code; solid-state electronic storage devices such as random access memory (RAM), or read-only memory (ROM); or any other physical device or media employed to store a computer program having instructions for controlling one or more computers to practice the method according to the present invention.
- magnetic storage media such as magnetic disk (such as a floppy disk) or magnetic tape
- optical storage media such as optical disk, optical tape, or machine readable bar code
- solid-state electronic storage devices such as random access memory (RAM), or read-only memory (ROM); or any other physical device or media employed to store a computer program having instructions for controlling one or more computers to practice the method according to the present invention.
- Digital images may be still (non-motion) images.
- Digital images may also be motion digital images, such as digital videos, which can include a plurality of digital image frames.
- Still and motion digital images are also referred to herein as digital media assets.
- the system can operate as part of, or in connection with, a multi-user online photo-management or social networking service.
- the method and system can also be applied to on-line social networking websites such as Facebook, Google+, Pinterest, Instagram, Twitter, and MySpace that allow users to upload and share collections of digital media assets with other users.
- Each individual user is associated with other individual users through connections called “friends”, “contacts”, “connections”, “circles”, “followers” or the like.
- friends typically, when users upload digital media assets to their respective internet sites, other users who are “friends” can view the digital media assets.
- a user can select privacy settings for the digital assets that they upload to the social networking system, for example, a user can share an item such as a digital image with a specific friend, a group (i.e., a subset) of friends, friends-of-friends, or publicly to all members of the social networking system, or publicly to everyone with Internet access.
- the users have the option to manually tag the digital media assets that include the identity of persons included in the digital media assets.
- the social networking system can include a personalize website, such as a blog, that is available to all users of the Internet and/or is limited to a select group of users.
- the system and methods described herein can provide ways for users to geographically explore the images they can access in the social networking system.
- the geographic location of an image is determined automatically through a process called geo-registration that includes comparing the appearance of the image with a database of 3D models of various landmarks on earth from photographs.
- geo-registration By applying geo-registration to the digital assets of a user on a social networking system, a travel score that indicates the amount of travel for each user can be produced.
- a plurality of users of the social networking system can be sorted or organized, and their images can be more easily explored.
- FIG. 1 is a block diagram illustrative of an embodiment of an environment for discovering visited travel destinations from digital images.
- the environment can include a social networking system 50 .
- the social networking system 50 includes at least one network server 135 , connected and accessible via a communications network such as the Internet 133 or a mobile phone network 137 .
- the server 135 can have a Uniform Resource Locator (URL) that allows it to be accessed by other computing devices.
- URL Uniform Resource Locator
- the social networking system 50 can exist without a central server, but instead as a peer-to-peer network.
- one or more user databases 141 collectively store the associations and connections between users who belong to the social networking system 50 .
- the user database 141 can include user access information such as a username and password, user identification number, and the user identification numbers of other users associated with a user.
- the user database 141 includes information and media assets that are posted to, or uploaded to, the social networking system 50 by the user, such as status updates, blog posts, and the like.
- the user database 141 further includes or has access to one or more image collection databases 143 for managing a plurality of digital images and videos, together with metadata associated with the digital images.
- each user can access the social networking system 50 by way of a user access device 99 such as a mobile computing device, a smartphone, a tablet, a personal computer (PC), a digital gaming console, and/or a television, etc.
- the user access device 99 can include a digital processor 105 (e.g., a central processing unit) for executing instructions and memory 119 for use by the digital processor 105 .
- the user access device can include an input device 123 such as a microphone 107 , a mouse, a keyboard, a touch screen, a remote control, a pointer device or the like, and a color display 121 , for example an LCD screen, or display output connection for outputting to an external display device.
- the user access device 99 can also optionally include an image capture unit 101 , such as a CMOS or CCD type image sensor array, for capturing digital images.
- an image capture unit 101 such as a CMOS or CCD type image sensor array
- the user access device 99 can include additional sensors or parts, such as a speaker 109 and microphone 107 to provide telephony capabilities, an accelerometer 111 , GPS sensor 113 , a gyroscope 115 , and possibly other sensors 117 to estimate the position of the user access device with respect to the earth's surface or to gather information about the environment (e.g., temperature or humidity) that can be useful for certain applications that are executed on the user access device.
- the environment e.g., temperature or humidity
- Each user can be provided a user account on the social networking system 50 having an associated user name and password.
- the user can be considered the owner of this account and can be provided with privileges to specify account settings for that account.
- the user can also be provided with access to information, such as the digital images associated with the accounts owned by other users with whom the user is connected within the social networking system 50 , as will be described in further detail below.
- the auto-mapper server 319 can access the social networking system 50 when an individual user provides access.
- the auto-mapper server 319 can analyze images from the image collection databases 143 that are owned by the individual user or connections of the individual user.
- the auto-mapper server 319 can perform geo-registration on the images, using computer vision methods to determine a geo-location, and possibly additional information such as tags, landmark names, relevant Internet links, and the like, for recognized images.
- This information can be used by the auto-mapper server 319 for a variety of tasks, such as displaying the recognized images on a map for presentation to the individual user, determining a user travel score for the individual user and for users connected to the individual user, using the user travel scores to sort, organize, rank, or award tangible or virtual prizes to a set of users of the social networking system, and producing maps indicating the travels of users of the social networking system.
- FIG. 2 is an illustration of possible connections between users within a social networking system 50 .
- connections between seven users 201 A to 201 G of the social networking system 50 are provided.
- the users 201 are connected with edges that represent the social connections 203 between the users of the social networking system 50 .
- Connections in a social networking system 50 can be established in a variety of ways: in some cases, one user issues a request to connect with another user, and, when confirmed by the second user, the connection is established and recorded in the user database 141 . Connections in a social networking system can be unidirectional, bidirectional, or based on membership to subgroups of the social networking system.
- connections can come in a variety of types such as friend, relative, co-worker, or additional social relationships.
- the system can operate within a social networking system where the connections of a user determine which digital assets that that user can access and which digital assets that the user shares, and with whom.
- user 201 F has four connections (to users 201 C 201 D 201 E and 201 G ), and he has access privilege to view the images posted to the social networking system that are owned by these four users.
- an image or video that is uploaded or published to the social networking system is owned by the user who uploads it.
- the owner can control which other users of the social networking system can view the image through privacy settings.
- other users who are “friends” can view the digital media assets.
- a user can select privacy settings for the digital assets that they upload to the social networking system, for example, to share the image with no users, with all friends, with friends-of-friends, or publicly (that is, with all users of the social networking system, or all users of the Internet).
- FIG. 3 is a block diagram illustrative of an embodiment of the environment for geo-registering images within a social networking system and displays the results on an interactive map for exploration by the user.
- the system can enable a user to quickly explore the travels of his or her connections in the social networking system.
- a user 201 with a user access device 99 can be a member of a social networking system 50 and can have a set of connections to other users within the social networking system 50 .
- the user 201 has access to an image collection 311 that includes images owned by the user's connections of the social networking system 50 that she has permission to access.
- the image collection 311 that the user 201 G has access to can include images owned by users 201 C , 201 D , and 201 F .
- the user 201 can provide access to her user account to the auto-mapper server 319 .
- This access can include a list of the connections between that individual user and other users of the social networking system 50 .
- the auto-mapper server can include a digital processor that receives and analyzes the images in an image collection 311 that includes some subset of images from the social networking system 50 that a particular user 201 has permission to view.
- the image collection 311 can be the images from among the user's 201 friends' images that the user 201 has permission to view, or the images from the user's friends' friends, or those images plus some subset of publicly viewable images.
- the auto-mapper server 319 can analyze images to geo-recognize the images, automatically determine the geographic coordinates of where recognized images were captured, and produce an auto-map rendering 323 of geo-recognized images placed on a map.
- the auto-mapper server 319 can be any digital processor that can access the images from the social networking system, and need not be distinct from the hardware associated with the social networking system 50 itself (e.g., server 135 ).
- the auto-mapper server 319 can control or include a landmark registration engine 325 that attempts to geo-recognize images 333 from the image collection 311 .
- the landmark registration engine 325 can perform geo-registration in a number of ways, such as, but not limited to the methods described further in FIG. 4A - FIG. 4E .
- the result can be stored in a database 327 that stores recognition results in association with each image 333 .
- the actual image pixel values of the image may or may not be stored in the database.
- a URL or image identification number can be stored.
- the geo-registration result 329 can be stored, indicating the position of the image on the globe, e.g., in latitude and longitude.
- auxiliary geo-information 331 such as the name and ID number of the landmark (e.g., Notre Dame, Louvre Museum, Statue of Liberty, Old Faithful geyser), city name, country name, altitude, links to one or more Wikipedia articles, and the like can be stored in association with the image 333 .
- Metadata 335 such as the focal length, image owner and identification number, camera distortion parameters, internal camera parameters, time and date of image capture, camera flash fire information, and possibly more can be stored in association with the image 333 in the database, and can optionally be stored in the image file itself (e.g., using the EXIF standard).
- the database 327 can store the results returned from the landmark registration engine 325 . Because of this, when an additional user enrolls by providing the auto-mapper server 319 with access to his account on the social networking system, the landmark registration engine 325 can, in some embodiments, omit geo-recognition of images that have already been processed. For example, suppose user 201 G in FIG. 2 provides access to the auto-mapper server 319 , and the auto-mapper server attempts to geo-recognize the images from user 201 G and her connections ( 201 F , 201 C , and 201 D ). The database 327 stores the results.
- user 201 F desires to see the images captured within his social networking system mapped, and provides access information to the auto-mapper server 319 to geo-recognize his images, and the images of his connections ( 201 E , 201 C , 201 D , and 201 G ).
- his own images, and the images from users ( 201 C , 201 D , and 201 G ) have already been processed, leaving only the images from user 201 E to be processed.
- the database 327 of results can conserve computing resources as the geo-registration and mapping application spreads throughout the social networking system 50 .
- the purpose of the landmark registration engine 325 can be to receive an image 333 , and find its location on the globe.
- the landmark registration engine 325 can determine the geo-location for an image in any of several ways.
- the landmark recognition engine 325 can check an image's header information (e.g., the header of an EXIF image) for embedded geo-position information, possibly recorded by a GPS sensor associated with a camera, as for example is common with a camera phone.
- the landmark recognition engine 325 can analyze the pixel values of an image to extract features that capture either local or global patterns of appearance to determine its geo-location.
- one method that can be employed by the landmark recognition engine 325 is presented by J. Hays and A. Efros, “im2gps: estimating geographic information from a single image,” CVPR, 2008, incorporated herein by reference in its entirety, where coarse patterns of color and edges are used to describe the scene, and are matched to a dataset of training images for estimating the geo-location of the image.
- interest feature points can be extracted from an image and matched (either ignoring or considering 2D or 3D geometric considerations) to interest feature points extracted from a training set of images having known geo-location, such as described by Y. Zheng, et al., “Tour the world: Building a web-scale landmark recognition engine,” CVPR, 2009, incorporated herein by reference in its entirety.
- the landmark recognition engine 325 can determine a geo-location for an image by comparing it to a set of 3D models in a geo-registration database 415 that includes a 3D model database 411 representing hundreds, thousands, or more landmarks across the globe, each of which can be associated with auxiliary information 413 , such as, but not limited to, keywords, Wikipedia, or other Internet links. From this comparison, the landmark recognition engine 325 can determine precise geo-coordinates of where the image was captured, and in some embodiments, do so relying solely on the clues from the appearance of the image. In certain embodiments, the landmark recognition engine 325 can determine precise geo-coordinates from external sensor information 425 . Furthermore, in some embodiments, the landmark recognition engine 325 can determine precise geo-coordinates using a combination of clues from the appearance of the image and/or the external sensor information 325 .
- the landmark recognition engine can output the geo-registration 329 and auxiliary geo-information 331 associated with the image.
- landmark recognition from an image can also be accomplished using 2D image techniques rather than the 3D model matching, and has been shown to perform more robustly.
- 2D matching is used in “Tour the World: building a web-scale landmark recognition engine” by Zheng et al, CVPR 2009, but this method lacks the means for producing highly accurate camera pose and position because geometry is ignored.
- Geo-registration of an image 333 can be performed by finding a plausible camera position from which the image could have been captured, given the arrangement of feature point positions in the image compared to the known positions of those points in the 3D world, as represented in a 3D model from the 3D model database 411 .
- a detailed description of an embodiment for producing geo-registration estimates from a set of landmark 3D models of points and an input image is described in “Worldwide Pose Estimation Using 3D Point Clouds,” Yunpeng Li, Arthur Snavely, Dan Huttenlocher, European Conference on Computer Vision (ECCV), Florence, Italy, October 2012, incorporated herein by reference.
- feature detector 401 can receive an image 333 for detecting and describing image features 403 from the image 333 .
- An embodiment of a feature detector is described in U.S. Pat. No. 6,711,293, incorporated herein by reference, which detects interest points by finding extrema in a difference-of-Gaussian pyramid, and describes each interest point as a histogram of gradient orientations in several (16) subregions about the interest point.
- Another embodiment of a interest point detection methods is described in M. Agrawal, K. Konolige, and M. Blas, “Censure: Center surround extremas for realtime feature detection and matching,” in ECCV, 2008, and T. Lindeberg, “Feature detection with automatic scale selection,” in Int. Journ. of Comp. Vision, 30:79-116, 1998, incorporated herein by reference.
- the image features 403 are input to a feature matcher 405 that finds matches between the image features 403 and points from the 3D model database 411 , based on the feature point descriptions of the points and the features. In some embodiments, matches are found by finding the point with the smallest Euclidean distance from a particular feature (or vice-versa), measuring distance in the feature point description space.
- the camera pose estimator 407 determines the position and rotation (6 degrees of freedom) for the camera that captured the image 333 , such as by minimizing the distance between rays emanating from the camera center through a random subset of selected image features and the corresponding matching points from a particular model from the 3D model database 411 , which in some embodiments, can be referred to as RANSAC and bundle adjustment.
- the 3D models in the 3D model database 411 can be built from sets of images, typically mined from the Internet, of a given landmark. For example, a set of 1000 photos of Mt. Rushmore, of which 452 are registered, can be used to produce a model including 133994 points, or 3D points.
- the term “landmark” can refer to any location on that reasonably has visual distinctness. Landmarks can be man-made (e.g., Eiffel Tower), naturally occurring in nature (e.g., the Grand Canyon), or a combination of the two (e.g., many areas of Niagara Falls). Landmarks can be popular tourist destinations, underwater locations (e.g., the Great Barrier Reef or the wreckage of the Titanic), a small venue such as a restaurant or hotel, a painting or artwork, or even a residential house or room within a home.
- sensor information 425 corresponding to the image 333 can be used by the feature matcher 405 and camera pose estimator 407 to improve the accuracy or speed of the landmark registration engine 325 .
- the feature matcher 405 can search for matches to the image features 403 and points from the 3D model database 411 only within a given radius (e.g., 5 km) from the initial geo-position.
- the landmark registration engine 325 can use a 3D model database 411 of 3D models that each include a set of points that have been registered so that each of the points has a computed geo-location associated with it.
- features from a test image can be extracted, and matched to points in the 3D models, and registration can be performed to calculate a camera geo-location position for the test image.
- the system can reduce false positive matches, and label specific points within a 3D model, which can then be used to render pixel-accurate annotations onto the image.
- a 3D model in the 3D model database 411 can include a representation of an object that occurs at many locations world-wide. Then, when a test image includes any instance of these objects, a false match can occur and an incorrect geo-location for the image is produced.
- FIG. 4B illustrates an example of this problem.
- On the left side of FIG. 4B is a rendering of many geo-registered points 431 from a 3D model that were learned from a set of images of Universal Studio's RiverWalk in Orlando, Fla., downloaded from the Internet.
- This 3D model happens to include a logo for the popular coffee company Starbucks, which has many thousands of locations worldwide.
- 3D points 437 in the circled region 435 belong to the 3D model, and are associated with the Starbucks logo.
- FIG. 4C is a block diagram illustrative of an embodiment of an 3D point annotator 445 for labelling points in 3D models from the 3D model database 411 to reduce the occurrence of incorrect false positive matches.
- the 3D point annotator 445 can determine points from 3D models of the 3D model database 411 that belong to objects, such as logos, street signs, text (e.g., “The,” “Office Hours,” etc.), posters, mass-produced products, etc., that have many instances across the globe.
- 3D points can be identified and annotated in the geo-recognition database 415 with a low uniqueness factor, or as having more than one instance or location, or as “confusing.”
- the 3D point annotator 445 can use several components from the landmark registration engine 325 .
- a logo image 451 such as the logo 429 shown in FIG. 4B
- the feature matcher 405 can match these image features 403 to the 3D model database 411 .
- the 3D points in the 3D model can be assigned a low uniqueness factor.
- the 3D points can be annotated as “confusing” or “ambiguous,” by the point annotator 431 , and that annotation can be stored in the geo-registration database 415 .
- the 3D point annotator 445 of FIG. 4C is illustrated as using a logo image 451 to identify the confusing 3D points, it will be understood that a similar process can be performed using images of other potentially confusing objects, such as street signs, text in signs, and other mass-produced items.
- a database of company logos, street signs, street lights, and/or other potentially confusing and/or mass-produced items, as well as items that are considered less confusing and/or items that are considered unique can be used to assign a uniqueness factors to 3D points in one or more of the 3D models in the 3D model database 411 .
- Relatively low uniqueness factors can be assigned to 3D points that are very common
- medium uniqueness factors can be assigned to 3D points that are somewhat common or somewhat unique
- high uniqueness factors can be assigned to 3D points that are very unique and/or not common
- Any combination of the above-referenced assignments can be made as desired.
- only low uniqueness factors can be assigned to 3D points that are considered common.
- the database can be based on items extracted from the images and/or uploaded images of the potentially confusing items.
- the 3D registration engine 325 from FIG. 4A can use this information to improve performance by reducing false positive matches. Specifically, in some embodiments, for an image to be declared to be a match to a certain 3D model in the 3D model database 411 , the 3D registration engine 325 can wait until a threshold number of matches between image features 403 extracted from the image and non-confusing 3D points (e.g., 3D points that have not been annotated as being confusing and/or 3D points with a high uniqueness factor) in the 3D model is satisfied. Once the threshold number of matches is satisfied, the camera pose estimator 407 can proceed as described before.
- a threshold number of matches between image features 403 extracted from the image and non-confusing 3D points (e.g., 3D points that have not been annotated as being confusing and/or 3D points with a high uniqueness factor) in the 3D model is satisfied.
- the 3D registration engine 325 can ignore, or give less weight to, 3D points in the 3D model that have been assigned a low uniqueness factor and/or annotated as “confusing” or “ambiguous.” By discounting the contribution of potentially “confusing” 3D points, the number of false positive matches can be substantially reduced.
- the threshold number of matches non-confusing 3D points can vary based on the uniqueness of the image features identified in the image and/or the number of 3D points in the 3D model that are assigned a low uniqueness factor. For example, if the image feature identified is the Eiffel Tower, the threshold can be one image feature. However, if the image feature is a silhouette of a large building, the threshold number of image features can be three, five, ten, etc. (which can be used to determine a particular city skyline, etc.).
- the 3D registration engine 325 can use a range or scale to annotate 3D points and/or image features.
- 3D points and/or image features that are ubiquitous such as STOP signs
- image features and/or 3D points that are still common, but less ubiquitous, such as a store logo can be annotated as “confusing”
- image features and/or 3D points that are relatively unique such as a statue, distinct building or skyline, rock formation, etc., can be annotated as “uncommon,” or “unique.”
- the 3D registration engine 325 can use the scale to determine how much weight is to be given to different image features and/or 3D points to determine whether to match an image with a 3D model. For example, the 3D registration engine 325 can give more weight to image features and/or 3D points that are less common and/or more unique, and less weight to image features and/or 3D points that are more common or confusing. In some embodiments, the 3D registration engine 325 can use the image features and/or 3D points annotated as less common and/or more unique to narrow down to a specific geographic location, and then use image features and/or 3D points that are more common to help further pinpoint the geographic location.
- the 3D registration engine 325 can use one or more combinations of image features and/or 3D points annotated as “confusing” to generate an image feature that is “less common,” or “unique.” For example, while a single store logo may be considered “confusing,” a combination of three or more store logos in the same image and/or 3D model may be considered “less common” or “unique.”
- the terms “confusing,” “very confusing,” “ubiquitous,” “uncommon,” or “unique,” are used as non-limiting examples, and that any number of methods can be used to annotate image features and/or 3D points.
- a numerical range or scale can be used.
- the 3D registration engine 325 can assign a ‘1’ for very ubiquitous image features and ‘10’ for unique image features, etc.
- the point annotator 439 can use additional annotations for 3D points, in addition to the annotation of “confusing”.
- the point annotator 439 can use an annotation of the company name of the logo image 451 . Consequently, when a test image including a logo is used as an input to the landmark registration engine 325 of FIG. 4A , there may be insufficient non-confusing matches for the test image to be geo-located. However, a set of features from the image can match to “confusing” points in a 3D model that have an additional annotation, such as “Starbucks”. Although geo-location was not possible, the test image can be annotated as a “Starbucks” image.
- the location of the Starbucks logo in the test image is known—for example, a rectangle is rendered on the test image so that it can include the set of image features that matched points in a 3D model that were previously annotated as confusing and as “Starbucks”. This rectangle can indicate a likely location of the Starbucks logo in the test image.
- additional information can be used to estimate the location of the image.
- the system can use GPS data and/or other geo-located images to estimate the location of the image.
- the system can refer to the additional information and/or a database storing all the locations of Starbucks to estimate the location of the user when the image was taken.
- the database can include known locations of multiple companies, stores, outlets, etc. to aid in identifying the location of a particular image.
- the system can estimate that the second image is likely near the first and third images.
- the system can indicate a likely or estimated location of the image.
- the system can assign a confidence level to the estimate location of the second image based on the geo-location of the first and third images. If the confidence level satisfies a threshold, the system can indicate the estimate position. If the confidence level does not satisfy a threshold, the system can indicate that the location is unknown.
- the system can estimate the location of the second image based on the amount of time that has elapsed and/or an average travel speed of the user (likely walking, riding, driving, etc.). In some embodiments, the slower the travel of the user and/or the less time that has passed between images can lead the system to place greater confidence in the estimated location of the second image. In certain embodiments, if a confidence threshold is satisfied, the system can indicate the estimated location to the image.
- the system can indicate that the location of the image is not known.
- the location of more than one image can be estimated based on the known geo-location of an image taken before or after the non-geo-located images, depending on the elapsed time between images and/or an average travel speed of the user.
- any combination of the above-referenced embodiments can be used to determine the location of an image.
- FIG. 4D illustrates an embodiment for annotating points in the 3D model database 411 using a reference image 471 and a reference annotation 475 .
- a reference image can include an object, such as a painting, building, or landmark
- the reference annotation 475 is a polygonal outline of the object in the reference image, and can include the name or title of the object.
- the reference annotation 475 can be an outline of the building (i.e., a set of 2D point coordinates in the reference image that form a polygonal outline of the Eiffel Tower) and the name “Eiffel Tower”.
- the reference annotation 475 can include a coarse outline, such as a rectangle, or a precise outline.
- the 3D point annotator 445 can be used to extract features from the reference image 471 , and match these features to a 3D model in the 3D model database 411 as previously described.
- the points in the 3D model that match points associated with, or included within, the object outline of the reference annotation 475 can be labelled with the reference annotation 475 in the geo-registration database 415 .
- the 3D positions of the points from the object outline can be estimated by geometric fitting, such as by fitting a 3D plane to the positions of the 3D points that match, and then calculating the intersection of the points on the object outline and the 3D plane. In this way, the object outline is transformed from a 2D shape in the coordinate system of the reference image 471 to a 3D shape (planar) having geo-located points.
- a test image When a test image is used as an input to the landmark registration engine 325 of FIG. 4A , it can include features that match to points that are annotated by the 3D point annotator 445 .
- the test image's camera geo-position and parameters can be recovered by the aforementioned process.
- Annotations associated with one or more 3D points that match features in the test image can be rendered onto the test image for display purposes.
- FIG. 4E shows an example test image 471 that includes renderings for four rendered annotations 481 , one for each of the Presidential busts that comprise Mount Rushmore.
- Annotated 3D points are also useful for defining regions within a test image that allow for user interaction with the test image.
- the convex hull of the 3D points associated with Thomas Jefferson in FIG. 4E when projected into the image coordinates of the test image, can be used to define a hot region in the image that serves as a link—when Jefferson's head is touched or clicked on, additional relevant information can be displayed.
- the auto-mapper server 319 can use a map renderer 321 to produce an auto-map rendering 323 of the recognized images from a user's connections within the social networking system that are stored in the database 327 .
- An example of the auto-map rendering 323 is shown in FIG. 5 , where thumbnail versions of geo-registered images are placed on the map at positions corresponding to their determined geo-locations.
- the map renderer 321 produces an auto-map rendering 323 by placing thumbnail images 501 produced from recognized images, onto a map 503 for user navigation, exploration, and control.
- the auto-map rendering 323 also includes user interface controls 505 so a user can navigate the map by zooming, panning, or searching for specific regions.
- the auto-mapper server 319 receives the selection, and the map renderer 321 produces an auto-map rendering 323 including an image view, a magnified view of the thumbnail image (e.g., in higher resolution) along with auxiliary information 331 , such as a link to the Wikipedia page, a link to the image on the social networking system, or a link to the owner of the image, as illustrated in FIG. 6 .
- auxiliary information 331 such as a link to the Wikipedia page, a link to the image on the social networking system, or a link to the owner of the image, as illustrated in FIG. 6 .
- the geo-registered location for the image 333 can be displayed with an inset map 601 and the recovered geo-coordinates 603 can be displayed in numerical form.
- the aforementioned auxiliary information 331 can be rendered to the auxiliary display 605 , and thumbnail images 607 of nearby images, found by computing the distances from the image 333 to other successfully geo-registered images, are displayed for the user to use for exploring more images from her social networking system.
- FIG. 5 shows only 4 geo-registered images
- the number of displayed thumbnail images can number in the hundreds or thousands. It is common for a user of a social networking system to have access to the photos of her friends on the social networking system, and the number of these images can be in the hundreds of thousands or millions. Of these, several percent are often captured at recognizable locations, resulting in thousands of geo-recognized images for a user to browse.
- no more than a fixed number of images on the map can be displayed, or the thumbnail images 501 can be displayed with different sizes depending on the quality, popularity, or absence or presence of other geo-recognized images at nearby map positions.
- the image scorer 343 is described in more detail herein below.
- action suggestions 609 can be placed in association with the geo-recognized image 333 . These action suggestions can provide a suggested action for the user: to plan travel with one or more partner sites (e.g., the fictitious TravelHelper or SeeUSA travel sites). Further, action suggestions can recommend a book or video that describes the depicted landmark that might be of interest to the user, or a link for the user to write an email to a friend from her social network that has traveled to the depicted landmark.
- partner sites e.g., the fictitious TravelHelper or SeeUSA travel sites
- the action suggestion can be a link to one or more partner sites, including travel, tourism, or review/rating websites, and can be provided to the user for the purpose of aiding the user to travel to the destination or venue depicted in the image.
- the partner sites can provide payment for appearing as an action suggestion for the user.
- the map renderer 321 from FIG. 4 can select action suggestions from the geo-registration database 415 , based on sets of advertisements or links that are associated with particular travel destinations or landmarks.
- Partner sites can bid against one another for the right to be featured in an action suggestion 609 corresponding to specific travel destinations. For example, the price for a partner site to be featured in an action suggestion for a popular or exotic destination (e.g., traveling to Disney World) will likely be more expensive than the price for a partner site to be featured at a more obscure, or less traveled location (e.g., the birthplace of U.S. President Martin Van Buren).
- the auto-mapper server 319 accesses a travel scorer 341 .
- the purpose of the travel scorer 341 is to produce user travel scores 347 that quantify the travel experience level achieved by different users of the social networking system 50 , including the user 201 , and other users that are connected to the user 201 with a link in the social networking system 50 .
- the travel scorer 341 can produce a user travel score 347 .
- the user travel score 347 can simply be the number of geo-recognized images owned by a particular user.
- the user travel score 347 can be based on the number of unique places or landmarks that a user has visited, rather than the number of geo-recognized images.
- a user traveled to the Statue of Liberty and captured 100 images.
- a second user traveled to the Grand Canyon, Mt. Rushmore, the Statue of Liberty, and Arches National Park, but captured only one image at each destination.
- the second user is more well-traveled than the first, since she visited 4 destinations versus 1 for the first, despite the fact that the second user captured only 4 images, and the first captured 100.
- the user's travel score 347 is determined by analyzing the auxiliary geo-information 331 for each geo-recognized image belonging to the user in the database 327 , and counting the number of unique landmark ID numbers included in that set.
- the user travel score 347 can be based on the physical distance between the geo-locations of recognized images.
- the physical distance between every pair of recognized images (or, between landmarks) owned by a particular user is computed using well-known methods for computing distances between points on the surface of the earth, such as the Vicenty formula or the Haversine formula.
- the minimum spanning tree is found, and the cost associated with this tree can be the user travel score 347 corresponding to the minimum distance traveled to connect the images owned by that particular owner.
- the time that each image is captured is considered, and the user travel score 347 can be the sum of the physical distances between consecutively geo-recognized images owned by that user.
- the user travel score 347 can correspond to points earned by the user for her travels.
- the travel scorer 341 can access one or more travel destination lists 345 .
- a travel destination list 345 can include the name, locations, or landmark ID numbers of interesting sets of destinations, a requirement for the number of those landmarks to be visited by the user, and the number of points awarded for completing the travel destination list.
- the travel scorer 341 can check whether a user's geo-recognized images from the database 327 satisfy the requirements associated with the list, and awards points, or tangible or virtual prizes accordingly when a travel destination list is completed.
- a travel destination list is said to be completed for a particular user when each the requirement list is fulfilled by geo-recognized images owned by that user.
- the user can be awarded 100 points for capturing a least one image on each of the seven continents.
- the user can be awarded 50 points for capturing images of at least 10 state capitol buildings.
- the user can be awarded 200 points for visiting at least 10 UNESCO World Heritage sites, and a user can be awarded 75 points for visiting 5 or more National Parks, etc.
- the user travel score 347 can depend not only on which images of the user are geo-recognized, but can be competitive or cooperative based on the other users of the social networking system.
- the travel scorer 341 can award 10 points to a user for being the first to visit a particular landmark from the subset of users including the user herself and users connected to her.
- a user can earn one point for each unique landmark that she has a corresponding geo-recognized image associated with, and another point if she is the most recent visitor from among the connections from her social networking system.
- a challenge can be issued (e.g., the first user to photograph all stadiums from the National Football League will receive 500 points) and the first user to capture the correct images after the challenge is issued received the reward.
- the user travel score that a user receives can be dependent upon the user's connections within the social networking system, which makes the score a fun and competitive travel experience.
- the user travel score 347 can be time-sensitive, that is, the score is the accumulation of points earned only within a recent time window, e.g., the past year.
- the user travel score 347 can depend on the popularity or the aesthetic quality of that user's image, in addition to the number of landmarks that have been visited. For example, in some social networking systems 50 , a user has the ability to express approval of an image that a friend or connection has posted by pressing “like,” upvote, or “+1”. Then, the user travel score 347 can be the sum of the number of times that this expression of approval has occurred with the geo-recognized images owned by the user.
- sensor information 425 can also be used to verify whether a user is physically at the landmark that is depicted in a captured image.
- the travel scorer 341 can produce a user travel score 347 for a user based on the images that the user owns. In some situations, a user may try to increase his or her score by capturing images of images, or by uploading images originally captured by another person. In some embodiments, the travel scorer 341 can ignore images that have sensor information 425 that indicates that the user is at a different location from the landmark that is recognized in the image.
- the travel scorer 341 may not award points to the user for that image.
- a likely explanation is that the user was in Buffalo, but captured the Great Wall of China image from a book or computer screen.
- FIG. 7 depicts an embodiment of the auto-map rendering 323 .
- the auto-map rendering 323 is viewed on a user access device 99 .
- One skilled in the art understands that certain adjustments can be made to the auto-map rendering 323 depending on the modality of the user access device 99 . For example, buttons on touch screen displays typically occupy a greater portion of the screen space because they are selected with a touch of a finger instead of a mouse click.
- the auto-map rendering 323 depicted in FIG. 7 primarily differs from the automap rendering 323 depicted in FIG. 5 by including a map navigation pane 711 and a travel news pane 701 . These panes provide a user 201 with several different methods for searching and browsing the images of the auto-map rendering 323 .
- the travel news pane 701 provides the user with a view of recently recognized images from the user's connections from the social networking system 50 .
- each thumbnail image 703 is accompanied with a headline 705 , informing the user of recent events of recognized images within the user's set of connections from the social networking system 50 .
- a headline can indicate that a friend's image was geo-recognized in a specific country or at a specific landmark: e.g., Bill was at Himeji 5 days ago.
- Headlines 705 can also capture collective events that summarize the travel history for a particular user of the social networking system 50 , or for a particular place or landmark.
- a headline can convey “Jen has visited 37 states” when a photo of hers from South Dakota is geo-recognized by the landmark registration engine 325 , and previously, she had images recognized in 36 other states.
- a headline for a particular place can be displayed in the travel news pane 701 , for example, “Mary and 3 friends were here” can be displayed when Mary's image of the Sydney Opera House is geo-recognized, and previously, three other friends of the user had geo-recognized images corresponding to the same location.
- the headlines 705 and thumbnail images 703 in the travel news pane 701 increase user engagement with the application; that is, the travel new pane 701 automatically displays newly geo-recognized images to the user, and provides insightful summarizations of the travel patterns of particular friends, or to particular places, from the users social networking system.
- the travel new pane 701 can be an interactive user interface element; when the user selects an image, the display responds by zooming in on the corresponding region of the map, or by enlarging the thumbnail image in an image view as illustrated in FIG. 6 .
- the system can link the name from a headline 705 to that person's account on the social networking system 50 . It will be understood that further variations and modifications are within the scope of the disclosure.
- the headlines 705 rendered to the map can also, or alternatively, be posted as an update, or status message, to the social networking system 50 .
- the headline description produced by the auto-mapper server 319 can be posted to a the user's personalized page on the accessible via the social networking system. For example, when Jim posts an image that is recognized as the Great Pyramid of Giza, the auto-mapper server 319 can generate a status update “Jim is at the Great Pyramid of Giza right now” along with the image.
- the auto-mapper server produces a status update “Jim has visited 25 countries!” that is posted along with the image he captured.
- Status updates are generated from the recognized image using one of several templates, two of which are included below for illustration.
- ⁇ Name> is replaced with the name of the user 201
- ⁇ Place> is the placename of the landmark in the image based on the recognized geo-location
- ⁇ ElapsedDays> is the number of days that have elapsed from the time the image was captured to the present.
- ⁇ CountryName> is the name of the country that the recognized landmark is located
- ⁇ CountryCount> is the number of countries that the user has captured images that have been recognized with the landmark recognition engine 325 .
- the map navigation pane 711 can provide a means for the user to navigate the geo-recognized images by various places, or by select individuals with whom the user is connected.
- the map navigation pane 711 can include user controls 713 , 715 for sorting elements on the map navigation pane 711 .
- One set of user controls 715 can allow the user to select whether to show information related to “me”, “people”, or “places”. As illustrated in FIG. 7 , “people” is selected. In this mode, the map navigation pane 711 shows icon faces 721 and corresponding user names 723 for individuals from the social networking system connected to the user. A second set of user controls 713 allows the user to sort these elements (friends from the social networking system, in the depicted case), alphabetically, by user travel score 347 , or by most recently geo-recognized photo.
- map navigation pane 711 there are many other ways of sorting the elements of the map navigation pane 711 , e.g., by age, or by length of time that the person has had a social network connection with the user, that are also within the scope of the disclosure. Further, when the user selects a particular icon face 721 from the map navigation pane 711 , an action is taken, such as highlighting that individual's images on the auto-map rendering 323 , or removing or deemphasizing the images belonging to other individuals.
- the map navigation pane 711 can display a user's friends' user travel scores 347 with a numeric representation, but other representations of the user travel scores are also within the scope of the disclosure.
- an icon or keyword is used to indicate a particular score range, such as the word “GlobeTrotter” for a user with a user travel score above 1000, the word “Tourist” for a user with a user travel score between 500 and 999, and the word “NonTourist” for a user with a user travel score under 500.
- the user travel score can be displayed pictorially in some embodiments, for example, the user travel score 347 is shown by displaying prize icons, or small images, that represent the travel accomplishments that a user has earned. For example, a user can earn prize icons or virtual trophies by completing one or more travel destination lists.
- the map navigation pane 711 can display a “global leaderboard” of users of the social networking system, that are not necessarily connected to the individual user.
- the individual user can view an indication of the user travel score of the user or users from the social networking system with the greatest (or least) user travel scores 347 .
- the map navigation pane can show a list of places, each having a corresponding icon image, in a similar manner to the icon faces 721 for representing people in the social networking system.
- the depicted places e.g., Golden Gate Bridge, Sydney Opera House, Himeji Castle and others
- the map 503 can zoom in to the corresponding region, or indicates the location of the place on the map 503 by placing an indicator such as an arrow or tack at the location.
- a particular place e.g., Niagara Falls
- a list of the user's connections who have visited that location can be displayed to the user. This list can serve as a set of experts who might have good advice when the user is planning to visit the selected place, because they have been to Niagara Falls in the past.
- a summary of the user's own travel can be displayed in the map navigation pane, including the user travel score 347 for the user and a list of places that the user has traveled to, and a map including thumbtacks or thumbnail images corresponding to places that she had traveled.
- the auto-mapper server 319 can access the image scorer 343 for providing scores related to priority, quality, iconicness, or popularity, for individual images.
- a given region of the map can have many geo-registered images from the user's connections within the social networking system. Instead of rendering all of these images on the map, where some would be overlapped by others, in some embodiments a subset of the images can be selected, such as the best images, most preferred images, and/or highest rated images.
- the map renderer 321 can use the scores from the image scorer 343 when producing the auto-map rendering 323 by placing images on a map, to ensure that images with high scores have a better chance of appearing on the auto-map rendering.
- the image scorer 343 can consider the image capture time (recent images have higher score), and image popularity (images with more expressions of approval, judged by number comments, “likes” upvotes,, “+1” s, and so on, have higher score). Further, images from other users of the social networking system with whom the user has a stronger relationship, for example, the user's mother or daughter, can be assigned a higher score. Also, the image scorer 343 can consider image quality, using methods for computing image quality such as described in “The Design of High-Level Features for Photo Quality Assessment,” Yan Ke, Xiaoou Tang, Feng Jing, in IEEE CVPR 2006, incorporated herein by reference in its entirety.
- a given image is an iconic or canonical view of the depicted landmark with methods that quantify how often the interest points in the query image match those from training images from which the 3D model of the landmark is produced.
- Methods for computing this type of score is described by Ian Simon, Arthur Snavely, and Steven M. Seitz. Scene Summarization for Online Image Collections, in ICCV, 2007, incorporated herein in its entirety.
- All of the processes described herein may be embodied in, and fully automated via, software code modules executed by one or more general purpose computers or processors.
- the code modules may be stored in any type of computer-readable medium or other computer storage device. Some or all the methods may alternatively be embodied in specialized computer hardware.
- the components referred to herein may be implemented in hardware, software, firmware or a combination thereof.
Abstract
Description
- 50 social networking system
- 99 user access device
- 101 image capture unit
- 105 digital processor
- 107 microphone
- 109 speaker
- 111 accelerometer
- 113 GPS sensor
- 115 gyroscope
- 117 other sensors
- 119 memory
- 121 color display
- 123 input device
- 133 Internet
- 135 server
- 137 mobile phone network
- 141 user database
- 143 image collection databases
- 201 user
- 203 social connection
- 319 auto-mapper server
- 321 map renderer
- 323 auto-map rendering
- 325 landmark registration engine
- 327 database
- 329 geo-registration
- 331 auxiliary geo-information
- 333 image
- 335 metadata
- 341 travel scorer
- 343 image scorer
- 345 travel destination lists
- 347 user travel score
- 401 feature detector
- 403 image features
- 405 feature matcher
- 407 camera pose estimator
- 411 3D model database
- 413 auxiliary database
- 415 geo-registration database
- 425 sensor info
- 429 logo
- 431 geo-registered points
- 435 circled region
- 437 3D points
- 439 point annotator
- 445 3D point annotator
- 451 logo image
- 471 reference image
- 475 reference annotation
- 481 rendered annotation
- 501 thumbnail image
- 503 map
- 505 interface controls
- 601 inset map
- 603 geo-coordinates
- 605 auxiliary display
- 607 thumbnail images
- 609 action suggestion
- 701 travel news pane
- 703 thumbnail image
- 705 headline
- 711 map navigation pane
- 713 user controls
- 715 user controls
- 721 icon faces
- 723 user name
Claims (20)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/288,902 US9418482B1 (en) | 2014-01-22 | 2014-05-28 | Discovering visited travel destinations from a set of digital images |
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201461930141P | 2014-01-22 | 2014-01-22 | |
US14/288,902 US9418482B1 (en) | 2014-01-22 | 2014-05-28 | Discovering visited travel destinations from a set of digital images |
Publications (1)
Publication Number | Publication Date |
---|---|
US9418482B1 true US9418482B1 (en) | 2016-08-16 |
Family
ID=56610754
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US14/288,902 Active 2034-10-03 US9418482B1 (en) | 2014-01-22 | 2014-05-28 | Discovering visited travel destinations from a set of digital images |
Country Status (1)
Country | Link |
---|---|
US (1) | US9418482B1 (en) |
Cited By (17)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20160092750A1 (en) * | 2014-09-30 | 2016-03-31 | Samsung Electronics Co., Ltd. | Method for recommending one or more images and electronic device thereof |
KR20170083892A (en) * | 2016-01-11 | 2017-07-19 | 한국전자통신연구원 | Server and Method for Providing City Street Search Service |
US20170301117A1 (en) * | 2016-04-17 | 2017-10-19 | Streetography, Inc. | Digitally-Generated Map Containing Defined Regions for Rendering with Photo Overlays |
US20170301104A1 (en) * | 2015-12-16 | 2017-10-19 | Objectvideo, Inc. | Profile matching of buildings and urban structures |
US20180121450A1 (en) * | 2015-05-05 | 2018-05-03 | Snap Inc. | Systems and methods for automated local story generation and curation |
JP2018106134A (en) * | 2016-12-28 | 2018-07-05 | ブラザー工業株式会社 | Terminal device |
WO2019051104A1 (en) * | 2017-09-07 | 2019-03-14 | Follow Me L.L.C. | Recording and sharing travel experiences |
US20190183451A1 (en) * | 2017-12-14 | 2019-06-20 | Siemens Healthcare Gmbh | Method for memorable image generation for anonymized three-dimensional medical image workflows |
US10380410B2 (en) * | 2014-04-07 | 2019-08-13 | Eyeways Systems Ltd. | Apparatus and method for image-based positioning, orientation and situational awareness |
US10527449B2 (en) * | 2017-04-10 | 2020-01-07 | Microsoft Technology Licensing, Llc | Using major route decision points to select traffic cameras for display |
US10650039B2 (en) * | 2016-02-25 | 2020-05-12 | Lionheart Legacy Uco | Customizable world map |
US10699459B2 (en) | 2016-04-17 | 2020-06-30 | Michael Lanza | Digitally generated set of regional shapes for presenting information on a display screen |
WO2020136633A1 (en) | 2018-12-26 | 2020-07-02 | Elbit Systems Land And C4I Ltd. | Methods and systems for camera 3d pose determination |
US20200302108A1 (en) * | 2014-04-01 | 2020-09-24 | Samsung Electronics Co., Ltd. | Method and apparatus for content management |
US10824667B2 (en) * | 2018-06-29 | 2020-11-03 | Rovi Guides, Inc. | Systems and methods for recommending media assets based on objects captured in visual assets |
US11379517B2 (en) * | 2018-01-20 | 2022-07-05 | Griffin Kelly | Photography searching system |
US11599741B1 (en) * | 2017-12-01 | 2023-03-07 | Snap Inc. | Generating data in a messaging system for a machine learning model |
Citations (12)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6711293B1 (en) | 1999-03-08 | 2004-03-23 | The University Of British Columbia | Method and apparatus for identifying scale invariant features in an image and use of same for locating an object in an image |
US20090254842A1 (en) * | 2008-04-05 | 2009-10-08 | Social Communication Company | Interfacing with a spatial virtual communication environment |
US20090290812A1 (en) * | 2008-05-23 | 2009-11-26 | Mor Naaman | System to Compile Landmark Image Search Results |
US20110074966A1 (en) * | 2009-09-25 | 2011-03-31 | Cerosaletti Cathleen D | Method for measuring photographer's aesthetic quality progress |
US20130191458A1 (en) * | 2008-09-04 | 2013-07-25 | Qualcomm Incorporated | Integrated display and management of data objects based on social, temporal and spatial parameters |
US20130275894A1 (en) * | 2011-12-19 | 2013-10-17 | Birds In The Hand, Llc | Method and system for sharing object information |
US20130303190A1 (en) * | 2012-03-01 | 2013-11-14 | Microsoft Corporation | Requesting a location of a user |
US20140137011A1 (en) * | 2012-11-14 | 2014-05-15 | Michael Matas | Photographs with Location or Time Information |
US20140280561A1 (en) * | 2013-03-15 | 2014-09-18 | Fujifilm North America Corporation | System and method of distributed event based digital image collection, organization and sharing |
US20140351717A1 (en) * | 2013-05-24 | 2014-11-27 | Facebook, Inc. | User-Based Interactive Elements For Content Sharing |
US20150031396A1 (en) * | 2013-07-26 | 2015-01-29 | Here Global B.V. | Familiarity Measure to Group Objects |
US20150046442A1 (en) * | 2013-08-12 | 2015-02-12 | Microsoft Corporation | Search result augmenting |
-
2014
- 2014-05-28 US US14/288,902 patent/US9418482B1/en active Active
Patent Citations (12)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6711293B1 (en) | 1999-03-08 | 2004-03-23 | The University Of British Columbia | Method and apparatus for identifying scale invariant features in an image and use of same for locating an object in an image |
US20090254842A1 (en) * | 2008-04-05 | 2009-10-08 | Social Communication Company | Interfacing with a spatial virtual communication environment |
US20090290812A1 (en) * | 2008-05-23 | 2009-11-26 | Mor Naaman | System to Compile Landmark Image Search Results |
US20130191458A1 (en) * | 2008-09-04 | 2013-07-25 | Qualcomm Incorporated | Integrated display and management of data objects based on social, temporal and spatial parameters |
US20110074966A1 (en) * | 2009-09-25 | 2011-03-31 | Cerosaletti Cathleen D | Method for measuring photographer's aesthetic quality progress |
US20130275894A1 (en) * | 2011-12-19 | 2013-10-17 | Birds In The Hand, Llc | Method and system for sharing object information |
US20130303190A1 (en) * | 2012-03-01 | 2013-11-14 | Microsoft Corporation | Requesting a location of a user |
US20140137011A1 (en) * | 2012-11-14 | 2014-05-15 | Michael Matas | Photographs with Location or Time Information |
US20140280561A1 (en) * | 2013-03-15 | 2014-09-18 | Fujifilm North America Corporation | System and method of distributed event based digital image collection, organization and sharing |
US20140351717A1 (en) * | 2013-05-24 | 2014-11-27 | Facebook, Inc. | User-Based Interactive Elements For Content Sharing |
US20150031396A1 (en) * | 2013-07-26 | 2015-01-29 | Here Global B.V. | Familiarity Measure to Group Objects |
US20150046442A1 (en) * | 2013-08-12 | 2015-02-12 | Microsoft Corporation | Search result augmenting |
Non-Patent Citations (8)
Title |
---|
Agrawal, et al., "CenSurE: Center Surround Extremas for Realtime Feature Detection and Matching", pp. 102-115, 2008. |
Hays, James et al., "IM2GPS: estimating geographic information from a single image" (2008) 8 pgs. |
Ke, Yan et al., "The Design of High-Level Features for Photo Quality Assessment" (2006) 8 pgs. |
Li, et al., "Worldwide Pose Estimation using 3D Point Clouds", pp. 1-14, 2012. |
Lindeberg, Tony, "Feature Detection with Automatic Scale Selection" (1998) 53 pgs. |
Simon, et al., "Scene Summarization for Online Image Collections", 2007. |
Snavely, et al., "Modeling the World from Internet Photo Collections", 2007. |
Zheng, Yan-Tao, et al., "Tour the World: building a web-scale landmark recognition engine" (2009) 8 pgs. |
Cited By (31)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20200302108A1 (en) * | 2014-04-01 | 2020-09-24 | Samsung Electronics Co., Ltd. | Method and apparatus for content management |
US10380410B2 (en) * | 2014-04-07 | 2019-08-13 | Eyeways Systems Ltd. | Apparatus and method for image-based positioning, orientation and situational awareness |
US20160092750A1 (en) * | 2014-09-30 | 2016-03-31 | Samsung Electronics Co., Ltd. | Method for recommending one or more images and electronic device thereof |
US9904864B2 (en) * | 2014-09-30 | 2018-02-27 | Samsung Electronics Co., Ltd | Method for recommending one or more images and electronic device thereof |
US10592574B2 (en) * | 2015-05-05 | 2020-03-17 | Snap Inc. | Systems and methods for automated local story generation and curation |
US20180121450A1 (en) * | 2015-05-05 | 2018-05-03 | Snap Inc. | Systems and methods for automated local story generation and curation |
US11449539B2 (en) | 2015-05-05 | 2022-09-20 | Snap Inc. | Automated local story generation and curation |
US11392633B2 (en) | 2015-05-05 | 2022-07-19 | Snap Inc. | Systems and methods for automated local story generation and curation |
US20170301104A1 (en) * | 2015-12-16 | 2017-10-19 | Objectvideo, Inc. | Profile matching of buildings and urban structures |
US10930005B1 (en) | 2015-12-16 | 2021-02-23 | Objectvideo Labs, Llc | Profile matching of buildings and urban structures |
US10127685B2 (en) * | 2015-12-16 | 2018-11-13 | Objectvideo Labs, Llc | Profile matching of buildings and urban structures |
US10430459B2 (en) * | 2016-01-11 | 2019-10-01 | Electronics And Telecommunications Research Institute | Server and method for providing city street search service |
KR20170083892A (en) * | 2016-01-11 | 2017-07-19 | 한국전자통신연구원 | Server and Method for Providing City Street Search Service |
US10650039B2 (en) * | 2016-02-25 | 2020-05-12 | Lionheart Legacy Uco | Customizable world map |
US10145704B2 (en) * | 2016-04-17 | 2018-12-04 | Streetography, Inc. | Digitally-generated map containing defined regions for rendering with photo overlays |
US20170301117A1 (en) * | 2016-04-17 | 2017-10-19 | Streetography, Inc. | Digitally-Generated Map Containing Defined Regions for Rendering with Photo Overlays |
US10699459B2 (en) | 2016-04-17 | 2020-06-30 | Michael Lanza | Digitally generated set of regional shapes for presenting information on a display screen |
JP2018106134A (en) * | 2016-12-28 | 2018-07-05 | ブラザー工業株式会社 | Terminal device |
US10527449B2 (en) * | 2017-04-10 | 2020-01-07 | Microsoft Technology Licensing, Llc | Using major route decision points to select traffic cameras for display |
US10489432B2 (en) | 2017-09-07 | 2019-11-26 | Follow Me L.L.C. | Recording and sharing travel experiences |
WO2019051104A1 (en) * | 2017-09-07 | 2019-03-14 | Follow Me L.L.C. | Recording and sharing travel experiences |
US11599741B1 (en) * | 2017-12-01 | 2023-03-07 | Snap Inc. | Generating data in a messaging system for a machine learning model |
US11886966B2 (en) * | 2017-12-01 | 2024-01-30 | Snap Inc. | Generating data in a messaging system for a machine learning model |
US10722210B2 (en) * | 2017-12-14 | 2020-07-28 | Siemens Healthcare Gmbh | Method for memorable image generation for anonymized three-dimensional medical image workflows |
US20190183451A1 (en) * | 2017-12-14 | 2019-06-20 | Siemens Healthcare Gmbh | Method for memorable image generation for anonymized three-dimensional medical image workflows |
US11379517B2 (en) * | 2018-01-20 | 2022-07-05 | Griffin Kelly | Photography searching system |
US10824667B2 (en) * | 2018-06-29 | 2020-11-03 | Rovi Guides, Inc. | Systems and methods for recommending media assets based on objects captured in visual assets |
WO2020136633A1 (en) | 2018-12-26 | 2020-07-02 | Elbit Systems Land And C4I Ltd. | Methods and systems for camera 3d pose determination |
EP3903285A4 (en) * | 2018-12-26 | 2022-10-12 | Elbit Systems Land and C4I Ltd. | Methods and systems for camera 3d pose determination |
EP4296943A2 (en) | 2018-12-26 | 2023-12-27 | Elbit Systems Land and C4I Ltd. | Methods and systems for camera 3d pose determination |
EP4296943A3 (en) * | 2018-12-26 | 2024-04-03 | Elbit Systems Land and C4I Ltd. | Methods and systems for camera 3d pose determination |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US9418482B1 (en) | Discovering visited travel destinations from a set of digital images | |
US10423656B2 (en) | Tag suggestions for images on online social networks | |
US9805065B2 (en) | Computer-vision-assisted location accuracy augmentation | |
US9805060B2 (en) | System and method for predicting a geographic origin of content and accuracy of geotags related to content obtained from social media and other content providers | |
US9269011B1 (en) | Graphical refinement for points of interest | |
US9830337B2 (en) | Computer-vision-assisted location check-in | |
US9342930B1 (en) | Information aggregation for recognized locations | |
US20150121477A1 (en) | Text suggestions for images | |
US10606824B1 (en) | Update service in a distributed environment | |
US9881084B1 (en) | Image match based video search | |
AU2014274171B2 (en) | Tag suggestions for images on online social networks | |
US20140317511A1 (en) | Systems and Methods for Generating Photographic Tours of Geographic Locations | |
WO2014090034A1 (en) | Method and device for achieving augmented reality application | |
CN103562911A (en) | Gesture-based visual search | |
KR20220112666A (en) | How to detect augmented-reality targets | |
US9600720B1 (en) | Using available data to assist in object recognition | |
CN115812217A (en) | Travel-based augmented reality content for reviews | |
US20140286624A1 (en) | Method and apparatus for personalized media editing | |
US11409788B2 (en) | Method for clustering at least two timestamped photographs | |
Hao et al. | Point of interest detection and visual distance estimation for sensor-rich video | |
US20210075754A1 (en) | Method for sharing a photograph | |
JP2020042752A (en) | Method and system for filtering image by using point of interest | |
Larson et al. | The benchmark as a research catalyst: Charting the progress of geo-prediction for social multimedia | |
US20210072869A1 (en) | Method for retrieving at least two captured photographs | |
JP5440197B2 (en) | Apparatus for constructing imaging target spot database, construction system, and construction method |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: TAGGPIC, INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:YANG, TSUNG-LIN;EVANS, BRYCE;SNAVELY, KEITH NOAH;AND OTHERS;SIGNING DATES FROM 20140122 TO 20140123;REEL/FRAME:032989/0032 |
|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:TAGGPIC, INC.;REEL/FRAME:032997/0541Effective date: 20140422 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044566/0657Effective date: 20170929 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 4TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1551); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 4 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 8TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1552); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 8 |