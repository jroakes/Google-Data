CN117223002A - Encrypted information retrieval - Google Patents
Encrypted information retrieval Download PDFInfo
- Publication number
- CN117223002A CN117223002A CN202280030960.5A CN202280030960A CN117223002A CN 117223002 A CN117223002 A CN 117223002A CN 202280030960 A CN202280030960 A CN 202280030960A CN 117223002 A CN117223002 A CN 117223002A
- Authority
- CN
- China
- Prior art keywords
- encrypted
- client
- server
- queries
- shard
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
- 238000012545 processing Methods 0.000 claims abstract description 37
- 238000000034 method Methods 0.000 claims description 84
- 230000008569 process Effects 0.000 claims description 37
- 230000004044 response Effects 0.000 claims description 6
- 238000000638 solvent extraction Methods 0.000 claims 2
- 238000003860 storage Methods 0.000 description 21
- 230000006870 function Effects 0.000 description 19
- 239000013598 vector Substances 0.000 description 19
- 239000012634 fragment Substances 0.000 description 16
- 238000004590 computer program Methods 0.000 description 12
- 238000010586 diagram Methods 0.000 description 8
- 238000004891 communication Methods 0.000 description 6
- 238000006243 chemical reaction Methods 0.000 description 5
- 238000013507 mapping Methods 0.000 description 5
- 238000010521 absorption reaction Methods 0.000 description 4
- 230000003993 interaction Effects 0.000 description 4
- 230000001413 cellular effect Effects 0.000 description 3
- 238000009795 derivation Methods 0.000 description 3
- 238000013549 information retrieval technique Methods 0.000 description 3
- 230000003287 optical effect Effects 0.000 description 3
- 230000000644 propagated effect Effects 0.000 description 3
- 150000003839 salts Chemical class 0.000 description 3
- 238000004422 calculation algorithm Methods 0.000 description 2
- 238000004364 calculation method Methods 0.000 description 2
- 238000009826 distribution Methods 0.000 description 2
- 238000010295 mobile communication Methods 0.000 description 2
- 238000005192 partition Methods 0.000 description 2
- 238000013515 script Methods 0.000 description 2
- 238000000926 separation method Methods 0.000 description 2
- 238000013459 approach Methods 0.000 description 1
- 238000010923 batch production Methods 0.000 description 1
- 230000005540 biological transmission Effects 0.000 description 1
- 230000006835 compression Effects 0.000 description 1
- 238000007906 compression Methods 0.000 description 1
- 238000013500 data storage Methods 0.000 description 1
- 239000004973 liquid crystal related substance Substances 0.000 description 1
- 238000007726 management method Methods 0.000 description 1
- 238000005457 optimization Methods 0.000 description 1
- 238000011946 reduction process Methods 0.000 description 1
- 239000004065 semiconductor Substances 0.000 description 1
- 230000001953 sensory effect Effects 0.000 description 1
- 239000000758 substrate Substances 0.000 description 1
- 238000012546 transfer Methods 0.000 description 1
- 230000007704 transition Effects 0.000 description 1
- 230000000007 visual effect Effects 0.000 description 1
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/60—Protecting data
- G06F21/62—Protecting access to data via a platform, e.g. using keys or access control rules
- G06F21/6218—Protecting access to data via a platform, e.g. using keys or access control rules to a system of files or objects, e.g. local or distributed file system or database
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/60—Protecting data
- G06F21/62—Protecting access to data via a platform, e.g. using keys or access control rules
- G06F21/6218—Protecting access to data via a platform, e.g. using keys or access control rules to a system of files or objects, e.g. local or distributed file system or database
- G06F21/6227—Protecting access to data via a platform, e.g. using keys or access control rules to a system of files or objects, e.g. local or distributed file system or database where protection concerns the structure of data, e.g. records, types, queries
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/60—Protecting data
- G06F21/62—Protecting access to data via a platform, e.g. using keys or access control rules
- G06F21/6218—Protecting access to data via a platform, e.g. using keys or access control rules to a system of files or objects, e.g. local or distributed file system or database
- G06F21/6245—Protecting personal data, e.g. for financial or medical purposes
Abstract
The encrypted information retrieval may include generating a database that is partitioned into shards each having a shard identifier, and the database entries in each shard are partitioned into buckets having bucket identifiers. A batch of client-encrypted queries is received. The batch of client-encrypted queries is processed using a set of server-encrypted data stored in a database. The processing includes grouping the client-encrypted queries according to their shard identifiers, executing a plurality of queries in the group of the fragmented client-encrypted queries together during the batch, and generating a plurality of server-encrypted results for the plurality of queries in the group of the client-encrypted queries. The results of the multiple server encryption per shard are sent to the client device.
Description
Background
The present description relates to data processing and information retrieval. In particular, the techniques and methods described in this specification describe techniques for enabling Private Information Retrieval (PIR) from a database.
User devices and content platforms, such as content distributors, may query content providers to retrieve information stored by the content providers. However, in some cases, any details that reveal to the content provider what information is being queried are not in the interest (interest) of the content platform. In other cases, any details that disclose to the content platform about other information stored on the content provider's computing system may not be in the content provider's interest (interest).
Disclosure of Invention
In general, one innovative aspect of the subject matter described in this specification can be embodied in methods that include the actions of: generating a partitioned database in which the database is partitioned into shards, each shard having a shard identifier that logically distinguishes each shard from other shards, and database entries in each shard being partitioned into buckets having bucket identifiers that logically distinguish each bucket in the shard from other buckets in the shard; receiving, by a server comprising one or more processors, a batch of client-encrypted queries from a client device, wherein the batch of client-encrypted queries comprises two or more queries, each of the two or more queries having been encrypted by the client device and specifying a shard identifier for the client-encrypted query; processing, by the server, the batch of client-encrypted queries using a set of server-encrypted data stored in a database, wherein each database entry is server-encrypted and decryptable by a corresponding decryption key, wherein the processing comprises: grouping, by the server, the client-encrypted queries according to their shard identifiers, wherein each client-encrypted query group comprises a plurality of queries; executing, by the server, for each shard, a plurality of queries in a group of client-encrypted queries of the shard together in a batch execution process; and generating, by the server, for each shard, a plurality of server-encrypted results of the plurality of queries in the set of client-encrypted queries, and transmitting, by the server, the plurality of server-encrypted results for each shard to the client device.
Other embodiments of this aspect include corresponding apparatuses, systems, and computer programs configured to perform aspects of the methods encoded on computer storage devices. These and other implementations can each optionally include one or more of the following features.
A method may include receiving a set of client encrypted entity identifiers; encrypting, by the server, the set of client-encrypted entity identifiers to create a server-client encrypted set of identifiers; and transmitting, by the server, the set of server-client encrypted identifiers to the client device.
The method may further include generating, by the client device, a set of queries using the set of server-client encrypted identifiers; generating, by the client device, a set of decryption keys using the set of server-client encrypted identifiers; the set of queries is encrypted by the client device to create a batch of client-encrypted queries.
The method may include encrypting, by the server, a set of data stored in a database, wherein for a plurality of entries in the database, each database entry is server-encrypted and decryptable by a corresponding decryption key, wherein generating the partitioned database includes assigning each server-encrypted database entry to a bucket.
The method may include applying, by the client device, a set of decryption keys generated by the client device using a set of server-client encrypted identifiers to the plurality of server-encrypted results to reveal unencrypted results to the client-encrypted query.
The method may include generating a partitioned database by dividing each bucket into small blocks.
The method may also include executing a plurality of queries by executing each query on each block of the bucket, which reduces CPU usage and response time by reducing search space for each query execution.
The subject matter described in this specification can be implemented in specific embodiments to realize one or more of the following advantages. The techniques and methods described in this specification describe techniques for retrieving data from a database while protecting client and server privacy. This allows the client to query the server without revealing any details about the data being queried to the server. Meanwhile, when the client is querying, the server does not reveal any details about the contents of the database that are not queried by the client. In contrast, the prior art of querying servers typically involves encrypting an entire server database and providing the encrypted database to clients for querying. This approach requires significantly more computing resources because the size of the database is typically large. Other methods of querying a server include providing an index of a database to a client, and receiving an index selection from the client that does not allow privacy of the server and the client.
The details of one or more embodiments of the subject matter described in this specification are set forth in the accompanying drawings and the description below. Other features, aspects, and advantages of the subject matter will become apparent from the description, the drawings, and the claims.
Drawings
FIG. 1 is a block diagram of an example environment in which content is distributed and presented to user devices.
FIG. 2 is a swim lane diagram of an example process of retrieving content from a server by a client.
FIG. 3 is a flow chart of an example process of generating a query from a server encrypted identifier.
FIG. 4 is a flow chart of an example process for processing a query by a server.
FIG. 5 is a block diagram of an example computer system.
Detailed Description
The present description relates to data processing and information retrieval. In particular, the techniques and methods described in this specification describe techniques for retrieving data from a database while protecting client and server privacy. For example, if a client queries a server database, the client does not reveal any details about the data being queried to the server (also referred to as client query privacy). At the same time, the server does not reveal to the client any details about the database content that the client has not queried (also referred to as server database privacy). These techniques enable batch processing of queries to provide a more efficient information retrieval system that also protects user privacy. For example, user privacy is protected by ensuring that the queried server is not aware of the information about the user that the client is querying the server, and also preventing the client from learning other information about the user that may be stored by the server.
FIG. 1 is a block diagram of an example environment 100 in which content is distributed and presented to user devices. The example environment 100 includes a network 102, such as a Local Area Network (LAN), wide Area Network (WAN), the Internet, or a combination thereof. Network 102 connects content platform 106 and content provider 110. The example environment 100 may include many different content providers 110, content platforms 106, and user devices 104.
The user device 104 is an electronic device capable of requesting and receiving content over the network 102. Example user devices 104 include personal computers, mobile communication devices, digital assistant devices, and other devices that can send and receive data over the network 102. The user device 104 typically includes an operating system 112, with the operating system 112 being primarily responsible for managing device hardware and software resources, such as applications. The user device 104 also includes a device memory 120 to temporarily or permanently store data based on the particular implementation, application, and use case. User device 104 typically includes user applications 116 and 117, such as web browsers or email clients, to facilitate the sending and receiving of data through network 102, although native applications executed by user device 104 may also facilitate the sending and receiving of content through network 102. Examples of content presented at the user device 104 include web pages, word processing documents, portable Document Format (PDF) documents, images, videos, and search results pages and digital advertisements.
Content platform 106 is a computing platform that enables distribution of content. Example content platforms 106 include search engines, social media platforms, news platforms, data aggregator platforms, or other content sharing platforms. Each content platform 106 may be operated by a content platform service provider. Content platform 106 may present content provided by one or more content providers 110. In the above examples, the news platform may present content created by different authors and provided by one or more content providers 110. As another example, the content platform 106 may be a data aggregator platform that does not publish any content of its own, but rather aggregates and presents news articles provided by different news websites (i.e., content providers 110).
In some implementations, the content platform 106 can distribute digital content to one or more users. For example, content platform 106 may have one or more users subscribe to content platform 106 and/or register with content platform 106. In response, the content platform 106 may retrieve digital content from the content provider 110 and provide the retrieved content to the user device 104 of the user. The content provider 110 includes a data storage device (also referred to as a database) that stores digital content in the form of key-value pairs. For example, the database of content provider 110 may include a plurality of keys and, for each key, a corresponding value retrieved by content platform 106.
In some implementations, the content platform 106 can assign an identifier to each user such that the content platform can distinguish users. In some implementations, the content platform 106 can use information provided by one or more users and/or user devices as a unique identifier. For example, the content platform 106 may use an electronic mail identifier (email id) provided by the user, a cellular telephone number provided by the user, or a Media Access Control (MAC) address of the user's user device 104 as the unique identifier. In some implementations, the content platform 106 can assign identifiers to groups of two or more users based on characteristics of the users in the group of users. For example, content platform 106 may assign a public identifier to a user based on similar interests in the context of digital content accessed by the user. In other examples, users may be assigned to groups and public identifiers may be assigned based on subscriptions with digital content. In some implementations, content platform 106 may assign multiple identifiers to a single user. For example, content platform 106 may assign an email identifier and a cellular telephone number as the user's identifier.
To retrieve digital content from content provider 110, content platform 106 and content provider 110 implement information retrieval techniques that ensure data privacy in a manner that content platform 106 does not reveal to content provider 110 any details about what information is being queried. The retrieval technique also ensures that the content provider 110 does not reveal any details to the content platform 106 about other information stored on the computing system of the content provider 110. Although the present description refers to content provider 110 and content platform 106, the information retrieval techniques discussed herein may be used by any two systems that want to exchange information in a privacy-preserving manner. The information retrieval technique is further explained with reference to fig. 2, and an entity that requests information from a database is referred to as a client, and an entity that maintains a database of information and returns information stored in the database is referred to as a server.
FIG. 2 is a swim lane diagram of an example process 200 for retrieving content from a server by a client. The operations of process 200 may be implemented, for example, by client 202 and server 204. The operations of process 200 may also be implemented as instructions stored on one or more computer-readable media, which may be non-transitory, and execution of the instructions by one or more data processing apparatus may cause the one or more data processing apparatus to perform the operations of process 200.
The server implements a database (also referred to as a server database) that stores digital content in the form of mappings between keys and values (referred to as key-value pairs). The key may be an identifier and/or pointer for a value that is digital content being queried by the client. The database may include a plurality of keys and, for each key, a corresponding value corresponding to that key. For example, the server may include a plurality of keys in the database, where each key may uniquely identify one or more users of the client for which the client is retrieving content from the server.
In some implementations, the keys of the key-value pairs of the server database are associated with identifiers assigned to users by the client. Upon querying the server, the client provides the query including the identifier to the server in a manner that does not disclose the details of the identifier to the server. As further explained in the document, the server may select content (e.g., any kind of data) from the server database based on the identifier, even if the identifier is masked from the server.
The client 202 obtains the unique identifier (212). For example, client 202 may provide digital content to one or more users. To uniquely identify one or more users, client 202 may assign an identifier to each of the one or more users. In some implementations, the client 202 can use information provided by one or more users and/or user devices 104 as identifiers for the one or more users and/or user devices 104. For example, the client 202 may use an email identifier (email-id or email address), a cellular telephone number, or a Media Access Control (MAC) address of the user device 104 as the unique identifier. A client may be any computing system that requests information from other systems (e.g., server systems) that store information or maintain databases.
The client 202 device encrypts the identifier (214). To prevent the server 204 from accessing the user's identifier in the clear, the client 202 encrypts the identifier using deterministic and exchangeable encryption techniques to generate an encrypted form of the identifier (referred to as a "client encrypted identifier"). In general, exchangeable encryption is an encryption that enables plaintext to be encrypted more than once using the public key of a different entity. In this system, decryption is not required prior to encryption/re-encryption processing. In addition, the resulting ciphertext (also referred to as encrypted text) may be decrypted by a specified decryption technique regardless of the order of the public keys used in the encryption/re-encryption process. In other words, the order of keys used in encryption and decryption does not affect the computation results, and allows one encryptor (e.g., client 202) to remove encryption of data encrypted by the first encryptor even after the other party (e.g., server) has applied further encryption thereto.
The client 202 sends the client encrypted identifier to the server 204 (216). For example, after encrypting the identifier, the client 202 sends the client encrypted identifier to the server 204 over the network 102.
Server 204 encrypts the client encrypted identifier (218). In some implementations, after receiving the client-encrypted identifier from the client 202, the server 204 re-encrypts (e.g., further encrypts) the client-encrypted identifier using an exchangeable encryption technique to generate an encrypted version of the client-encrypted identifier (referred to as the "server and client-encrypted identifier"). In other words, server 204 adds another layer of encryption over the client encrypted identifier. Note that the server 204 cannot access the identifier in plain text form because the identifier has been encrypted by the client 202 and the server 204 does not have a decryption key.
Server 204 sends the server and client encrypted identifiers back to client 202 (220). For example, after generating server and client encrypted identifiers, server 204 sends the server and client encrypted identifiers of one or more users to client 202 over network 102.
Client 202 removes the previous client encryption from the server and client encrypted identifiers (222). In some implementations, after receiving the server and client encrypted identifiers, the client 202 uses techniques to decrypt (or remove) the encryption performed by the client 202 in step 214 to generate a "server encrypted identifier" for each of the one or more users. Note that client 202 is able to remove client encryption because encryption techniques are exchangeable in nature. Note also that the server encrypted identifier generated after removal of the client encryption is an identifier encrypted by the server using exchangeable and deterministic encryption techniques. In other words, after the client 202 removes the original encryption applied to the identifier, the identifier remains encrypted by the server, and then is merely a server-encrypted version of the client identifier that is used by the client 202 to generate a query to be submitted to the server 204 to request information corresponding to the identifier.
In some implementations, steps 218-222 of process 200 may be implemented using an unintentional pseudo-random function (oblivious pseudo random function) (also referred to as an unintentional PRF or OPRF). An unintentional PRF is a protocol between a server holding a key to a Pseudo Random Function (PRF) and a client holding an input. At the end of the server-client interaction, the client knows the output of the OPRF on the input provided by the client, without other content. The server does not know about the client's input or OPRF output.
To facilitate the creation of the query, the client 202 generates a shard index and bucket identifier for each server encrypted identifier (224). In some implementations, the client 202 implements hashing techniques to generate queries that may include a shard index and a bucket identifier (also referred to as a bucket id). An example hash technique for generating a query is further explained with reference to fig. 3.
FIG. 3 is a flow diagram of an example process 300 for generating a query from a server encrypted identifier. The operations of process 300 may be implemented, for example, by a client 202, the client 202 including any entity that implements the techniques described in this document to retrieve content from other entities. The operations of process 300 may also be implemented as instructions stored on one or more computer-readable media, which may be non-transitory, and execution of the instructions by one or more data processing apparatus may cause the one or more data processing apparatus to perform the operations of process 300.
Fig. 3 illustrates a process 300 for generating a query using an example identifier 350 (john. Smith@sample. Com). After processing identifier 350 using steps 212 through 222 of process 200, server-encrypted identifier 360 of identifier 350 is represented as serv_enc { john. Smith@sample. Com } = adhf8f2g & 34-! d0sfgn2, where serv_enc is the server encryption of the server and client encrypted identifiers after client 202 removes the client encryption of step 214, and "adhf8f2g & 34-! d0sfgn2 "is the ciphertext of identifier 350.
Client 202 hashes the server encrypted identifier to generate an unsigned integer (310). In some implementations, the client 202 can implement a hash function configured to process the server encrypted identifier 360 to generate the unsigned integer 370. This may be expressed as hash_fn [ serv_enc { john. Smith@sample. Com } ] = 324423510001001110, where hash_fn is a HASH function implemented by the client 202 and "324423510001001110" is an unsigned integer. The hash function (also referred to as a cryptographic hash function) may be any one-way function that is virtually impossible to invert or reverse, and may be used to map any size of data to a fixed size value. Examples of such hash functions may include MD5 message digest algorithm, secure hash algorithms 1, 2, and 3.
The client 202 converts the unsigned integer into a converted number within the specified range (320). In some implementations, the client 202 may implement a conversion function configured to process the unsigned integer 370 to generate a converted number 380 within a specified range. Since the hash function and the conversion function are known to both the client 202 and the server 204, the range of converted numbers generated using the conversion function is predetermined. In this example, the converted number 380 is represented as CONV [ hash_fn [ serv_enc { john. Smith@sample. Com } ] ] = 324425, where CONV is the conversion function implemented by the client 202. As an example, one way to convert an unsigned integer to a number between 0 and 9999 is to use the remainder of the unsigned integer divided by 10000.
Client 202 divides the converted number into a fragment index and a bucket id (330). The tile index will be a number between 0 and P-1, where P is the number of tiles. Bucket id will range between 0 and n/P-1, where n is the transition generated in step 320The number 380 after the conversion may take the maximum value. In some implementations, the client 202 splits the converted number 380 generated in step 320 into two parts such that the first part is a fragment index and the second part is a bucket id. For example, if n is the maximum value that the converted number 380 can take, the number of bits needed to represent the number n is log 2 n bits. Log in this case 2 n, if P is a power of 2, where p=2k, then client 202 can use the first K bits as a fragment index, and the remaining log 2 n-K bits may be used as bucket id. In this example, client 202 splits converted number 380 into two parts as result 390 as depicted in fig. 3 such that the shard index is 32 and the bucket id is 4425. In other embodiments, if P represents the number of fragments, the fragment index may be calculated as the remainder of the converted number divided by P. In this case, when the converted number is divided by P, the bucket id may be calculated as an integer quotient. In this case, if p=100, the fragment index 25 and the bucket id 3244.
Returning to process 200, client 202 uses process 300 to generate a query for each of the server-encrypted identifiers for one or more users. For example, as described above, each query generated for each identifier will include a shard index and bucket id created using the server-encrypted identifier.
The client 202 generates a decryption key using the encrypted identifier for each server (226). In some implementations, the client 202 can generate a decryption key for each of the server-encrypted identifiers. For example, client 202 may implement an HMAC-based Extract-and-Expand Key Derivation Function (HKDF), which is a hash-based message authentication code (HMAC) encryption key derivation function (key derivation function, KDF) for expanding a key into one or more encrypted strong private keys (secret keys). For example, client 202 may process the server encrypted identifier using HKDF to generate a decryption key.
Client 202 generates and encrypts a query (228). In some implementations, client 202 uses bucket ids to generate an indicator vector of length n/P, where the element with index equal to the bucket id is 1 and the other elements are 0 (recall P is the number of fragments, n/P is the number of different bucket ids). In some implementations, the indicator vector may be compressed using well-known compression techniques. In some implementations, the client 202 can encrypt the indicator vectors corresponding to each of the server-encrypted identifiers using full homomorphic encryption (fully homomorphic encryption, FHE) techniques to generate corresponding FHE-encrypted bucket vectors. In general, homomorphic encryption is a form of encryption that allows a user to perform a calculation on its encrypted data without first decrypting it. These resulting calculations are preserved in encrypted form, which when decrypted, produce the same output as the result of performing the operation on the unencrypted data. The attributes of FHE may include addition, multiplication, and absorption (absorption). To illustrate, if { x } represents FHE for x, then adding { x } + { y } can result in { x+y } without revealing x, y, or x+y. Similarly, multiplying { x } { y } can produce { xy } without revealing x, y, or xy, and absorbing { x } { y can produce { xy } without revealing x. In some implementations, the attributes of the FHE may include the ability to convert the encrypted vector into a specified number of individually encrypted values (one for each item in the vector) without revealing any details about the items in the vector.
After encrypting the indicator vector, the client 202 can generate a query that includes the shard index and the corresponding FHE encrypted bucket vector. The QUERY may be represented as an FHE PIR QUERY, where the database represents a data store storing a mapping of keys and values, i.e. the database stores a plurality of keys and for each key a corresponding value.
The client 202 sends the query to the server 204 (230). For example, after generating a query for each of the server-encrypted identifiers, the client 202 sends the query to the server 204 over the network 102. In some implementations, multiple queries are sent to the server in batches, so that the server can process the queries simultaneously (e.g., in a batch process).
Server 204 encrypts the database (232). Server 204 may encrypt the database at any time prior to receiving the query. For example, when server 204 builds a database or adds information to a database, the server may encrypt data being stored in the database. In some implementations, the server 204 encrypts the server database using an encryption technique such as advanced encryption standard (Advanced Encryption Standard, AES). For example, the server 204 encrypts the value of each key-value pair of the server database using AES encryption techniques based on the AES key generated using the corresponding key of the key-value pair and HKDF. Each key in the key-value pair of the server database is further replaced by an integer (referred to as a record key) generated using a hash function (e.g., SHA 256) that maps keys to integers within the range 0, n, where n is an adjustable parameter known to both the server 204 and the client 202. This results in recording key-AES encrypted value pairs in place of each of the key-value pairs in the database.
The hash function may also utilize a cryptographic salt (cryptographic salt) that consists of random bits added to each key in the key-value pair prior to the hash operation. In some implementations, encryption salts are also known to the client 202, which may be used by the client 202 when encrypting the indicator vector using FHE techniques to generate a corresponding FHE encrypted bucket vector.
Server 204 processes the query (234). In some implementations, the server 204 can process queries using optimized batch processing, which reduces the resource consumption required to retrieve content from a database. This optimized processing may be implemented in a manner that facilitates concurrent processing by splitting the database into small blocks (referred to as shards and identified using shard indexes) and processing them in parallel on multiple computing systems, thereby reducing the computational resources required to retrieve content from the database. This will be further explained with reference to fig. 4.
FIG. 4 is a flow diagram of an example process 400 of processing a query. The operations of process 400 may be implemented, for example, by server 204, with server 204 including any entity implementing a database from which content is retrieved. The operations of process 400 may also be implemented as instructions stored on one or more computer-readable media, which may be non-transitory, and execution of the instructions by one or more data processing apparatus may cause the one or more data processing apparatus to perform the operations of process 400.
Server 204 divides the database into P shards (402). For example, the shard index is derived from the record key by using the same technique that the client uses to derive the shard index. Each shard may include a plurality of record key-AES encrypted value pairs.
Server 204 divides each shard into buckets (404). In some implementations, the server 204 partitions each shard into even smaller partitions called buckets by exporting the bucket id of each record key in the shard using the same technique used by the client. For example, when the converted number is divided by P, the fragment index and bucket id may be calculated as a remainder and integer quotient, respectively. This was observed to produce d chips up to n/P buckets.
After dividing each shard into a plurality of buckets, the AES encrypted values of the record key-AES encrypted value pairs are stored in each bucket such that the record key of the record key-AES encrypted value pairs indexes both the shard and the bucket within the shard. It should be noted that server 204 uses the same method as client 202 to derive the fragment number and bucket id from each key in the key-value pair in the server database.
The server 204 combines and serializes the encrypted values (406). In some implementations, the server 204 concatenates the AES encrypted value for each bucket into a byte string. For example, if a particular bucket includes 3 AES encrypted values, the 3 AES encrypted values are concatenated one after the other to generate a byte string. The server 204 recognizes the offset value (index position of byte string) of the AES-encrypted value, and encrypts the offset value using an encryption technique such as AES based on the corresponding record key. For example, if the byte string includes 3 AES encrypted values of uniform length, the server encrypts an offset value of each of the 3 AES encrypted values in the byte string using AES based on the corresponding record key of the record key-AES encrypted value pair. After generating the encrypted offset value, server 203 prepends the encrypted offset value to the byte string. The server 204 also prepends the number of AES-encrypted values to the byte string. In this example, server 204 prepends a value of 3 to the byte string. Server 204 further divides the byte string into blocks of c bytes each, where c is an integer known a priori to both the client and server. The c-byte chunks may be further indexed based on their relative positions in the byte string. For example, if c=1, bucket B may be represented as b= [ "p", "q", "r", "s" ], where "pqrs" may be a string of bytes divided into c-byte blocks "p", "q", "r", and "s" having indices 1-4, respectively, in the bucket. In another example, if c=2, bucket B may be represented as b= [ "pq", "rs", "tu", "v" ], where "pqrstuv" may be a string of bytes divided into c-byte blocks "pq", "rs", "tu" and "v" with indices 1-4, respectively, in the bucket.
For each query, server 204 uses the shard index of the query to identify shards (408). As mentioned above with reference to step 228 of process 200, each query includes a fragment index and a corresponding FHE encrypted bucket vector. After receiving the query, server 204 identifies the particular shard based on the shard index of the query. For example, if the shard index of the query is 32, the server identifies the 32 nd shard based on the shard index of the server database.
For each query, the server 204 queries each bucket in the shard and generates a list of FHE encrypted values (410). In some implementations, the server 204 uses the FHE-encrypted bucket vector from the query to query each bucket of a particular shard identified by the shard index. For example, if there are 32 buckets in the shards identified using the shard index from the query, server 204 will query each of the 32 buckets.
To query a bucket, the server 204 performs an inadvertent expansion operation on the FHE encrypted bucket vector from the query to obtain the FHE encrypted value for the particular bucket. It then performs a separate FHE absorbing operation between the value of the FHE encryption for the particular bucket and each c-byte block in the bucket. This can be logically explained with the following example.
Assume that there are 4 buckets in a particular fragment. Further assume that the first bucket has the following blocks [ "A", "B", "C", "D" ]. Similarly, the second, third, and fourth buckets have the following blocks [ "E", "F", "G" ], [ "H" ] and [ "I", "J", "K" ], respectively. Further assume that the indicator vector is [0,1, 0]. The absorb operation will generate FHE encrypted values with blocks of index 1 across all four buckets, which can be represented as [0, "E", 0]. Similarly, the FHE encrypted values for blocks with indices 2-4 across all four buckets are [0, "F," 0,0], [0, "G," 0,0] and [0, 0], respectively.
In some implementations, the server 204 can aggregate the bucket vector and the value of the FHE-encrypted value of the c-byte block using FHE addition operations across all buckets and generate a list of FHE-encrypted values. In other words, by summing the FHE values, all the entries in the set of triples previously described with the same query and block index are combined into one. For example, an aggregate operation on the bucket vector and the value of the FHE encrypted value for a c-byte block with a particular index (e.g., index 1) will select block E from all blocks with index 1 across all four buckets of the shard. Similarly, the aggregated values of the blocks at the second index, the third index, and the fourth index are "F", "G", and 0, respectively, across all buckets of the shard. After the server 204 selects a block from the bucket, the server 204 may generate a list of FHE encrypted values and send the list to the client 202. For example, the server may generate a list of values [ "E", "F", "G" ] encrypted using the FHE selected by the absorption operation and send the list to the client 202.
Although process 400 has been explained with reference to a single query, process 400 may be implemented in a manner that multiple queries may be processed in parallel on multiple computing systems. In some implementations, a mapping reduction process may be used that enables all queries to be processed as a batch of queries, which reduces the time required to generate a response to a query and saves processing resources relative to processing each query separately. For example, assume that a database is divided into n buckets by hashing a key, and the buckets are divided into fragments based on a preamble (bucket) k bits. In this example, the server may split the queries by fragments based on the provided fragment index submitted with each query. The server may then fan out each query to the FHE value of each (existing) bucket in its shard by decompressing the encrypted bucket selector. Within each fragment, each bucket is combined with the FHE value from the query for the bucket. For each bucket: FHE absorption is performed for each pair of Cartesian products of FHE values from the query and blocks of buckets. The output of this step is a multiple mapping from (query id, block index) pairs to FHE encrypted values. The values are aggregated using FHE addition as an aggregator. This has the same output format as the previous step except that it is not a multiple mapping-each key has exactly one FHE value. The list of encrypted values ordered by block index is aggregated and the output format is a mapping from the query to the list of FHE encrypted values. By providing the same number of queries per shard and doing the appropriate shard, computational costs can be reduced by having many shards without revealing any information about the distribution of the queries. Returning now to fig. 2.
The server 204 sends a list of FHE encrypted values to the client 202 (236). Server 204, after generating a list of FHE-encrypted values for the c-byte chunks and bucket vectors for each of the server-encrypted identifiers, sends one or more lists to client 202 over network 102.
The client 202 decrypts the FHE encryption (238). In some implementations, after receiving one or more lists of FHE-encrypted values for the bucket vector and c-byte chunks, the client 202 decrypts the FHE encryption from each of the lists using the decryption key generated in step 226 of process 200 to obtain the value (if any) of the key-value pairs that were queried and originally stored on the server database.
In some embodiments, the values of n and P may be adjusted for further optimization. For example, increasing the value of P saves computation time for the server 204, but at the same time increases the burden on the client 202 to generate more queries. To compensate for the additional queries of large values of P, the client 202 may generate a dummy query that does not select data from the server database.
In some cases, when a fake query presents a problem for a malicious client that uses additional queries to learn about other data stored in the server database, the server 204 may ensure that results are sent to the client 202 only per each real query, rather than a fake query. In some implementations, this may be accomplished by utilizing an additional PIR protocol over the results rather than sending the complete results to the client 202. In some implementations, this may be very efficient because even with a large number of false queries, the number of false queries is several orders of magnitude smaller than the server database.
In some implementations, it may be optimal to set the number of fragments equal to the number of queries. The number of pseudo-queries can be determined using techniques such as the relative Chernoff Bound (Chernoff Bound) and the Boolean inequality (Union Bound). For some implementations, for example, when there are about 10,000 queries, it may be optimal to have about 40-50 pseudo queries per real query.
FIG. 5 is a block diagram of an example computer system 500 that may be used to perform the operations described above. The system 500 includes a processor 510, a memory 520, a storage device 530, and an input/output device 540. Each of the components 510, 520, 530, and 540 may be interconnected, for example, using a system bus 550. Processor 510 is capable of processing instructions for execution within system 500. In some implementations, the processor 510 is a single-threaded processor. In other implementations, the processor 510 is a multi-threaded processor. The processor 510 is capable of processing instructions stored in the memory 520 or on the storage device 530.
Memory 520 stores information within system 500. In one implementation, the memory 520 is a computer-readable medium. In some implementations, the memory 520 is a volatile memory unit. In other implementations, the memory 520 is a non-volatile memory unit.
The storage device 530 is capable of providing mass storage for the system 500. In some implementations, the storage device 530 is a computer-readable medium. In various different implementations, storage device 530 may include, for example, a hard disk device, an optical disk device, a storage device shared by multiple computing devices over a network (e.g., a cloud storage device), or some other mass storage device.
Input/output device 540 provides input/output operations for system 500. In some implementations, the input/output device 540 may include one or more of a network interface device (e.g., an ethernet card), a serial communication device (e.g., an RS-232 port), and/or a wireless interface device (e.g., an 802.11 card). In other implementations, the input/output devices may include a driver device configured to receive input data and transmit output data to external devices 560, such as keyboards, printers, and display devices. However, other implementations may also be used, such as mobile computing devices, mobile communication devices, set-top box television client devices, and the like.
Although an example processing system has been described in FIG. 5, implementations of the subject matter and functional operations described in this specification can be implemented in other types of digital electronic circuitry, or in computer software, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them.
Embodiments of the subject matter and the operations described in this specification can be implemented in digital electronic circuitry, or in computer software, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them. Embodiments of the subject matter described in this specification can be implemented as one or more computer programs, i.e., one or more modules of computer program instructions, encoded on a computer storage medium (or media) for execution by, or to control the operation of, data processing apparatus. Alternatively or additionally, the program instructions may be encoded on a manually generated propagated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal, that is generated to encode information for transmission to suitable receiver apparatus for execution by data processing apparatus. The computer storage medium may be or be included in a computer readable storage device, a computer readable storage substrate, a random or serial access memory array or device, or a combination of one or more of them. Furthermore, although the computer storage medium is not a propagated signal, the computer storage medium may be a source or destination of computer program instructions encoded in an artificially generated propagated signal. Computer storage media may also be or be included in one or more separate physical components or media (e.g., multiple CDs, disks, or other storage devices).
The operations described in this specification may be implemented as operations performed by a data processing apparatus on data stored on one or more computer readable storage devices or received from other sources.
The term "data processing apparatus" encompasses all kinds of apparatus, devices, and machines for processing data, including by way of example programmable processors, computers, systems-on-a-chip, or multiple ones or combinations of the foregoing. The apparatus may comprise a dedicated logic circuit, such as a field programmable gate array (field programmable gate array, FPGA) or an application-specific integrated circuit (ASIC). In addition to hardware, an apparatus may include code that creates an execution environment for the computer program in question, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, a cross-platform runtime environment, a virtual machine, or a combination of one or more of them. The apparatus and execution environment may implement a variety of different computing model infrastructures, such as web services, distributed computing, and grid computing infrastructures.
A computer program (also known as a program, software application, script, or code) can be written in any form of programming language, including compiled or interpreted languages, declarative or procedural languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, object, or other unit suitable for use in a computing environment. The computer program may, but need not, correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data (e.g., one or more scripts stored in a markup language document), in a single file dedicated to the program in question, or in multiple coordinated files (e.g., files that store portions of one or more modules, sub-programs, or code). A computer program can be deployed to be executed on one computer or on multiple computers that are located on one site or distributed across multiple sites and interconnected by a communication network.
The processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform actions by operating on input data and generating output. The processes and logic flows can also be performed by, and apparatus can also be implemented as, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit).
Processors suitable for the execution of a computer program include, by way of example, both general and special purpose microprocessors. Generally, a processor will receive instructions and data from a read-only memory or a random access memory or both. The essential elements of a computer are a processor for performing actions in accordance with instructions and one or more memory devices for storing instructions and data. Typically, a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks. However, the computer need not have such a device. In addition, computers may be embedded in other devices such as mobile phones, personal Digital Assistants (PDAs), mobile audio or video players, game consoles, global positioning system (Global Positioning System, GPS) receivers, or portable storage devices (e.g., universal Serial Bus (USB) flash drives), to name a few. Devices suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, such as internal hard disks or removable disks; magneto-optical disk; CD-ROM and DVD-ROM discs. The processor and the memory can be supplemented by, or incorporated in, special purpose logic circuitry.
To provide for interaction with a user, embodiments of the subject matter described in this specification can be implemented on a computer having a display device (e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor) for displaying information to the user and a keyboard and a pointing device (e.g., a mouse or a trackball) by which the user can provide input to the computer. Other kinds of devices may also be used to provide for interaction with a user; for example, feedback provided to the user may be any form of sensory feedback, such as visual feedback, auditory feedback, or tactile feedback; and input from the user may be received in any form, including acoustic, speech, or tactile input. In addition, the computer may interact with the user by sending and receiving documents to and from the device used by the user; for example, by sending a web page to a web browser on a user's client device in response to a request received from the web browser.
Embodiments of the subject matter described in this specification can be implemented in a computing system that includes a back-end component (e.g., as a data server), or that includes a middleware component (e.g., an application server), or that includes a front-end component (e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the subject matter described in this specification), or any combination of one or more such back-end, middleware, or front-end components. The components of the system can be interconnected by any form or medium of digital data communication (e.g., a communication network). Examples of communication networks include local area networks ("LANs") and wide area networks ("WANs"), internetworks (e.g., the internet), and peer-to-peer networks (e.g., ad hoc peer-to-peer networks).
The computing system may include clients and servers. The client and server are typically remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other. In some embodiments, the server sends data (e.g., HTML pages) to the client device (e.g., for the purpose of displaying data to and receiving user input from a user interacting with the client device). Data generated at the client device (e.g., results of user interactions) may be received from the client device at the server.
While this specification contains many specifics of embodiments, these should not be construed as limitations on the scope of any invention or of what may be claimed, but rather as descriptions of features specific to particular embodiments of particular inventions. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. From another aspect, various features which are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Furthermore, although features may be described above as acting in certain combinations and even initially claimed as such, one or more features from a claimed combination can in some cases be excised from the combination, and the claimed combination may be directed to a subcombination or variation of a subcombination.
Similarly, although operations are depicted in the drawings in a particular order, this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order, or that all illustrated operations be performed, to achieve desirable results. In some cases, multitasking and parallel processing may be advantageous. Moreover, the separation of various system components in the embodiments described above should not be understood as requiring such separation in all embodiments, and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.
Thus, particular embodiments of the subject matter have been described. Other embodiments are within the scope of the following claims. In some cases, the actions recited in the claims can be performed in a different order and still achieve desirable results. Additionally, the processes depicted in the accompanying drawings do not necessarily require the particular order shown, or sequential order, to achieve desirable results. In some embodiments, multitasking and parallel processing may be advantageous.
Claims (15)
1. A method, comprising:
generating a partitioned database, wherein the database is partitioned into shards, each shard having a shard identifier that logically distinguishes each shard from other shards, and database entries in each shard are partitioned into buckets having bucket identifiers that logically distinguish each bucket in a shard from other buckets in the shard;
Receiving, by a server comprising one or more processors, a batch of client-encrypted queries from a client device, wherein the batch of client-encrypted queries comprises two or more queries, each of the two or more queries having been encrypted by the client device and specifying a shard identifier for the client-encrypted query;
processing, by a server, a batch of client-encrypted queries using a set of server-encrypted data stored in a database, wherein each database entry is server-encrypted and decryptable by a corresponding decryption key, wherein the processing comprises:
grouping, by the server, the client-encrypted queries according to their shard identifiers, wherein each client-encrypted query group comprises a plurality of queries;
executing, by the server and for each shard, the plurality of queries in the set of client-encrypted queries of the shard together in a batch execution process; and
generating, by the server and for each shard, a result of encrypting a plurality of servers of the plurality of queries in the set of client-encrypted queries; and
the result of the plurality of server encryptions for each shard is sent by the server to the client device.
2. The method of claim 1, further comprising:
receiving a set of client-encrypted entity identifiers from a client device;
encrypting, by the server, the client-encrypted set of entity identifiers to create a server-client encrypted set of identifiers;
the set of server-client encrypted identifiers is sent by the server to the client device.
3. The method of claim 2, further comprising:
generating, by the client device, a set of queries using the set of server-client encrypted identifiers;
generating, by the client device, a set of decryption keys using the set of server-client encrypted identifiers;
the set of queries is encrypted by the client device to create a batch of client-encrypted queries.
4. A method according to claim 3, further comprising:
encrypting, by the server, a set of data stored in the database, wherein for a plurality of entries in the database, each database entry is server-encrypted and decryptable by a corresponding decryption key, wherein generating the partitioned database comprises assigning each server-encrypted database entry to a bucket.
5. The method of claim 4, further comprising:
A set of decryption keys generated by the client device using the set of server-client encrypted identifiers is applied by the client device to the plurality of server-encrypted results to reveal unencrypted results to the client-encrypted query.
6. The method of claim 4, wherein generating a partitioned database further comprises partitioning each bucket into small blocks.
7. The method of claim 6, wherein executing the plurality of queries comprises executing each query on each block of a bucket, which reduces CPU usage and response time by reducing search space for each query execution.
8. A system, comprising:
a memory device; and
a server comprising one or more processors configured to execute instructions that cause the server to perform operations comprising:
generating a partitioned database in a memory device, wherein the database is partitioned into shards, each shard having a shard identifier that logically distinguishes each shard from other shards, and
the database entries in each shard are partitioned into buckets having bucket identifiers that logically distinguish each bucket in the shard from other buckets in the shard;
Receiving a batch of client-encrypted queries from a client device, wherein the batch of client-encrypted queries includes two or more queries, each of the two or more queries having been encrypted by the client device and specifying a shard identifier for the client-encrypted query;
processing a batch of client-encrypted queries using a set of server-encrypted data stored in a database, wherein each database entry is server-encrypted and decryptable by a corresponding decryption key, wherein the processing comprises:
grouping the client-encrypted queries according to their shard identifiers, wherein each client-encrypted query group includes a plurality of queries;
for each shard, executing the plurality of queries in the set of client-encrypted queries of the shard together in a batch execution process; and
generating, for each shard, a plurality of server encrypted results for the plurality of queries in the set of client encrypted queries; and
the result of the multiple server encryption of each shard is sent to the client device.
9. The system of claim 8, wherein the instructions cause a server to perform operations further comprising:
Receiving a set of client-encrypted entity identifiers from a client device;
encrypting the client-encrypted set of entity identifiers to create a server-client encrypted set of identifiers;
the set of server-client encrypted identifiers is sent to the client device.
10. The method of claim 9, wherein the instructions cause the server to perform operations further comprising:
generating, by the client device, a set of queries using the set of server-client encrypted identifiers;
generating, by the client device, a set of decryption keys using the set of server-client encrypted identifiers;
the set of queries is encrypted by the client device to create a batch of client-encrypted queries.
11. The system of claim 10, wherein the instructions cause a server to perform operations further comprising:
encrypting a set of data stored in a database, wherein for a plurality of entries in the database, each database entry is server encrypted and decryptable by a corresponding decryption key, wherein generating the partitioned database comprises assigning each server-encrypted database entry to a bucket.
12. The system of claim 11, wherein the instructions cause a server to perform operations further comprising:
A set of decryption keys generated by the client device using the set of server-client encrypted identifiers is applied by the client device to the plurality of server-encrypted results to reveal unencrypted results to the client-encrypted query.
13. The system of claim 11, wherein generating a partitioned database further comprises partitioning each bucket into small blocks.
14. The system of claim 13, wherein executing the plurality of queries comprises executing each query on each block of a bucket, which reduces CPU usage and response time by reducing search space for each query execution.
15. A non-transitory computer-readable medium storing instructions which, when executed by a server comprising one or more processors, cause the server to perform the operations recited by any of claims 1-7.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US202163210755P | 2021-06-15 | 2021-06-15 | |
US63/210,755 | 2021-06-15 | ||
PCT/US2022/033393 WO2022266071A1 (en) | 2021-06-15 | 2022-06-14 | Encrypted information retrieval |
Publications (1)
Publication Number | Publication Date |
---|---|
CN117223002A true CN117223002A (en) | 2023-12-12 |
Family
ID=82404016
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202280030960.5A Pending CN117223002A (en) | 2021-06-15 | 2022-06-14 | Encrypted information retrieval |
Country Status (4)
Country | Link |
---|---|
US (1) | US20240104234A1 (en) |
EP (1) | EP4315137A1 (en) |
CN (1) | CN117223002A (en) |
WO (1) | WO2022266071A1 (en) |
Families Citing this family (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
EP4283485A3 (en) * | 2021-10-19 | 2024-02-21 | Google LLC | Multi-key information retrieval |
CN115935429B (en) * | 2022-12-30 | 2023-08-22 | 上海零数众合信息科技有限公司 | Data processing method, device, medium and electronic equipment |
CN116150445B (en) * | 2023-04-04 | 2023-07-21 | 哈尔滨工业大学(深圳)(哈尔滨工业大学深圳科技创新研究院) | Batch information query method, electronic equipment and storage medium |
CN116257887B (en) * | 2023-05-16 | 2023-08-22 | 建信金融科技有限责任公司 | Data query method, device, system, equipment and storage medium |
Family Cites Families (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10229155B2 (en) * | 2014-09-05 | 2019-03-12 | Facebook, Inc. | Multi-tiered targeted querying |
US10467433B2 (en) * | 2017-03-17 | 2019-11-05 | Mediasift Limited | Event processing system |
US10586057B2 (en) * | 2017-11-16 | 2020-03-10 | Intuit Inc. | Processing data queries in a logically sharded data store |
-
2022
- 2022-06-14 EP EP22738229.8A patent/EP4315137A1/en active Pending
- 2022-06-14 US US18/008,554 patent/US20240104234A1/en active Pending
- 2022-06-14 WO PCT/US2022/033393 patent/WO2022266071A1/en active Application Filing
- 2022-06-14 CN CN202280030960.5A patent/CN117223002A/en active Pending
Also Published As
Publication number | Publication date |
---|---|
US20240104234A1 (en) | 2024-03-28 |
WO2022266071A1 (en) | 2022-12-22 |
EP4315137A1 (en) | 2024-02-07 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US10498706B2 (en) | Searchable encryption enabling encrypted search based on document type | |
EP3058678B1 (en) | System and method for dynamic, non-interactive, and parallelizable searchable symmetric encryption | |
Miao et al. | Hybrid keyword-field search with efficient key management for industrial internet of things | |
US20240104234A1 (en) | Encrypted information retrieval | |
Hoang et al. | A secure searchable encryption framework for privacy-critical cloud storage services | |
WO2016153602A1 (en) | Systems, methods, and apparatus to provide private information retrieval | |
EP4073673B1 (en) | Encrypted search with a public key | |
KR20120068524A (en) | Method and apparatus for providing data management | |
CN112685753B (en) | Method and equipment for storing encrypted data | |
He et al. | Secure encrypted data deduplication based on data popularity | |
US20190340391A1 (en) | Multiple message retrieval for secure electronic communication | |
US20230006813A1 (en) | Encrypted information retrieval | |
Yan et al. | Secure and efficient big data deduplication in fog computing | |
EP4193290B1 (en) | Multi-key information retrieval | |
US11310045B2 (en) | Compression and oblivious expansion of RLWE ciphertexts | |
Zhang et al. | Secure deduplication based on Rabin fingerprinting over wireless sensing data in cloud computing | |
Yin et al. | Attribute-Based Secure Keyword Search for Cloud Computing | |
Shruthishree et al. | Secure Conjunctive Keyword Ranked Search over Encrypted Cloud Data | |
Bharathi et al. | Secure Data Compression Scheme for Scalable Data in Dynamic Data Storage Environments | |
Priya et al. | Enabling Multi keyword Search on Secure Encrypted Data using Multi Cloud Approach | |
Shaikh et al. | Secure Data Storage over Cloud Using Content Features Processing |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |