DE202014010920U1 - Traffic design for large-scale data center networks - Google Patents
Traffic design for large-scale data center networks Download PDFInfo
- Publication number
- DE202014010920U1 DE202014010920U1 DE202014010920.6U DE202014010920U DE202014010920U1 DE 202014010920 U1 DE202014010920 U1 DE 202014010920U1 DE 202014010920 U DE202014010920 U DE 202014010920U DE 202014010920 U1 DE202014010920 U1 DE 202014010920U1
- Authority
- DE
- Germany
- Prior art keywords
- block
- source
- blocks
- fabric
- destination
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L49/00—Packet switching elements
- H04L49/35—Switches specially adapted for specific applications
- H04L49/356—Switches specially adapted for specific applications for storage area networks
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L47/00—Traffic control in data switching networks
- H04L47/10—Flow control; Congestion control
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L49/00—Packet switching elements
- H04L49/20—Support for services
- H04L49/205—Quality of Service based
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L45/00—Routing or path finding of packets in data switching networks
- H04L45/12—Shortest path evaluation
- H04L45/125—Shortest path evaluation based on throughput or bandwidth
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L47/00—Traffic control in data switching networks
- H04L47/10—Flow control; Congestion control
- H04L47/12—Avoiding congestion; Recovering from congestion
- H04L47/125—Avoiding congestion; Recovering from congestion by balancing the load, e.g. traffic engineering
Abstract
System, das einen oder mehrere Prozessoren umfasst, die für Folgendes konfiguriert sind: Identifizieren eines Quellen-Fabric-Blocks FBS unter mehreren Fabric-Blöcken, die in einem Computernetz miteinander kommunizieren; Beurteilen, der Reihe nach im Kreis, jedes Zielort-Fabric-Blocks der mehreren Fabric-Blöcke; Auswählen, der Reihe nach im Kreis, eines einzelnen Zielort-Mittelblocks MBd in einem ausgewählten Zielort-Fabric-Block FBd; Auswählen, der Reihe nach im Kreis, eines Quellen-Fabric-Blocks FBS; Identifizieren einer Teilmenge Μ von Quellen-Mittelblöcken unter allen Mittelblöcken in dem Quellen-Fabric-Block FBS, wobei die Teilmenge von Mittelblöcken als diejenige identifiziert wird, die eine kürzeste verfügbare Pfadlänge zu dem Zielort-Mittelblock MBd hat; und Auswählen, zur Verwendung in einem Netzwerkpfad, eines der Quellen-Mittelblöcke MBS in der Teilmenge Μ, der die folgende Bedingung maximiert: min (demand (MBS, FBd), spf_capacity (MBS, MBd)), wobei spf_capacity(MBS, MBd) eine kürzeste Pfadkapazität zwischen dem Quellen-Mittelblock MBS und dem Zielort-Mittelblock MBd, darstellt und demand(MBS, FBd) einen Bedarf zwischen dem Quellen-Mittelblock MBS und dem Zielort-Fabric-Block FBd darstellt.A system comprising one or more processors configured to: identify a source fabric block FBS among a plurality of fabric blocks that communicate with each other in a computer network; Judging, in order, in the circle, each destination fabric block of the plurality of fabric blocks; Selecting, in order in the circle, a single destination mid-block MBd in a selected destination fabric block FBd; Selecting, in order in the circle, a source fabric block FBS; Identifying a subset Μ of source mid-blocks among all middle blocks in the source fabric block FBS, the subset of middle blocks being identified as having a shortest available path length to the destination middle block MBd; and selecting, for use in a network path, one of the source middle blocks MBS in subset Μ that maximizes the following condition: min (demand (MBS, FBd), spf_capacity (MBS, MBd)), where spf_capacity (MBS, MBd) represents a shortest path capacity between the source middle block MBS and the destination middle block MBd, and demand (MBS, FBd) represents a demand between the source middle block MBS and the destination fabric block FBd.
Description
HINTERGRUND BACKGROUND
In Computerdatencentern werden viele verschiedene Hosts verwendet, um große Datenmengen zu verarbeiten, zu speichern und zu transferieren. Jeder Host kann einen oder mehrere Prozessoren, Speicher und Schnittstellen enthalten. Die Hosts, wie zum Beispiel Server, sind oft in Gestellen (Racks) angeordnet, wobei mehrere Server in einem Gestell untergebracht sind. Jedes Gestell kann einen Top-of-Rack(„TOR“)-Switch für die Kommunikation mit einer nächsten Switching-Schicht haben. Diese Switching-Schicht kann ein Cluster von Switches („Mittelblöcke“) enthalten, das einen bisektionalen volumenstarken lokalisierten Datenverkehr erlaubt. Mehrere Mittelblöcke wiederum können logisch zu größeren Clustern („Fabric-Blöcken“) gruppiert werden. Dadurch entsteht eine Switching-Anordnung mit mehreren Ebenen. Computer datacenters use many different hosts to process, store, and transfer large amounts of data. Each host can contain one or more processors, memory, and interfaces. The hosts, such as servers, are often arranged in racks, with multiple servers housed in a rack. Each rack can have a top-of-rack ("TOR") switch for communication with a next switching layer. This switching layer may contain a cluster of switches ("mid-blocks") that allow bisectional high volume localized traffic. In turn, several middle blocks can be grouped logically into larger clusters ("fabric blocks"). This creates a multilevel switching arrangement.
Fabric-Blöcke können im gesamten Datencenter verteilt werden, wobei ihre höchste Stufe von Switches unter Verwendung teurer Fasern und Optiken mit langer Reichweite miteinander verbunden werden. Für die Verbindungen zwischen Fabric-Blöcken kommt oft eine Direktverbindung anstelle der Verwendung einer CLOS-Topologie als Kompromiss zwischen bisektionaler Bandbreite und geringeren Kosten zum Einsatz. Es ist jedoch problematisch, ein System mit fairer Bandbreitenzuteilung zu erhalten, das obendrein verschiedene Klassen von Diensten respektiert und das effizient in der gesamten aus mehreren Ebenen bestehenden Switching-Umgebung arbeitet. Das kann besonders dann problematisch sein, wenn die Anzahl der Hosts und die Gesamtgröße des Datencenters zunehmen. Fabric blocks can be distributed throughout the datacenter, connecting their highest level of switches using expensive fibers and long-reach optics. Fabric block connections often use a direct connection instead of using a CLOS topology as a compromise between bidirectional bandwidth and lower cost. However, it is problematic to obtain a fair bandwidth allocation system which, moreover, respects different classes of services and operates efficiently throughout the multi-level switching environment. This can be particularly problematic as the number of hosts and the overall size of the datacenter increases.
KURZE ZUSAMMENFASSUNG SHORT SUMMARY
Ein Aspekt der vorliegende Offenbarung bestimmt die Bandbreitenzuteilung von Interblock-Datenverkehr in einem Datencenter-Netz über einen Satz von End-to-End-Pfaden hinweg auf der Basis einer Vielzahl verschiedener Informationen. Sie verwendet eine Anzahl von Optimierungszielen und eine heuristische Wasserfüllungsstrategie zum Vermeiden des Erzeugens unnötiger Pfade und zum Vermeiden des Bestimmens von Pfaden, die nicht verfügbar wären, wenn sie tatsächlich gebraucht werden. One aspect of the present disclosure determines the bandwidth allocation of inter-block traffic in a data center network over a set of end-to-end paths based on a variety of different information. It uses a number of optimization goals and a heuristic water-filling strategy to avoid creating unnecessary paths and avoiding the determination of paths that would be unavailable when they were actually needed.
Gemäß einem Aspekt der Offenbarung wird ein Verfahren zur Datenverkehrsgestaltung in einem Computernetz bereitgestellt. Das Computernetz hat mehrere Fabric-Blöcke, die miteinander kommunizieren, und einen oder mehrere Mittelblöcke in jedem Fabric-Block. Das Verfahren umfasst Folgendes: Identifizieren, durch einen oder mehrere Prozessoren, eines Quellen-Fabric-Blocks FBS unter den mehreren Fabric-Blöcken; Beurteilen, der Reihe nach im Kreis, jedes Zielort-Fabric-Blocks der mehreren Fabric-Blöcke; Auswählen, der Reihe nach im Kreis, durch den einen oder die mehreren Prozessoren, eines einzelnen Zielort-Mittelblocks MBd in einem ausgewählten Zielort-Fabric-Block FBd; Auswählen, der Reihe nach im Kreis, durch den einen oder die mehreren Prozessoren, eines Quellen-Fabric-Blocks FBS; Identifizieren, durch den einen oder die mehreren Prozessoren, einer Teilmenge Μ von Quellen-Mittelblöcken unter allen Mittelblöcken in dem Quellen-Fabric-Block FBS, wobei die Teilmenge von Mittelblöcken als diejenige identifiziert wird, die eine kürzeste verfügbare Pfadlänge zu dem Zielort-Mittelblock MBd hat; und Auswählen zur Verwendung in einem Netzwerkpfad, durch den einen oder die mehreren Prozessoren, eines der Quellen-Mittelblöcke MBS in der Teilmenge Μ, der die folgende Bedingung maximiert:
min (demand (MBS, FBd), spf_capacity (MBS, MBd)),
wobei spf_capacity(MBS, MBd) eine kürzeste Pfadkapazität zwischen dem Quellen-Mittelblock MBS und dem Zielort-Mittelblock MBd darstellt, und demand(MBS, FBd) einen Bedarf zwischen dem Quellen-Mittelblock MBS und dem Zielort-Fabric-Block FBd darstellt. According to one aspect of the disclosure, a method of traffic shaping in a computer network is provided. The computer network has multiple fabric blocks that communicate with each other and one or more center blocks in each fabric block. The method includes: identifying, by one or more processors, a source fabric block FB S among the plurality of fabric blocks; Judging, in order, in the circle, each destination fabric block of the plurality of fabric blocks; Selecting, in sequence, by the one or more processors, a single destination mid-block MB d in a selected destination fabric block FB d ; Selecting, in order in the circle, by the one or more processors, a source fabric block FB S ; Identifying, by the one or more processors, a subset Μ of source midblocks among all middle blocks in the source fabric block FB S , wherein the subset of middle blocks is identified as having the shortest available path length to the destination middle block MB d has; and selecting for use in a network path, by the one or more processors, one of the source middle blocks MB S in the subset Μ that maximizes the following condition:
min (demand (MB S , FB d ), spf_capacity (MB S , MB d )),
wherein spf_capacity (MB S , MB d ) represents a shortest path capacity between the source middle block MB S and the destination middle block MB d , and demand (MB S , FB d ) satisfies a need between the source middle block MB S and the destination Represents fabric block FB d .
In einer Alternative umfasst das Verfahren des Weiteren das Generieren eines Routenberechnungsgraphs, das eine Bandbreitenzuteilung durch iterative Auswahl von Quellen- und Zielort-Mittelblöcken, welche die Bedingung maximieren, erlaubt. In einer anderen Alternative umfasst das Verfahren des Weiteren, für jeden Quellen-Fabric-Block, das Aufteilen des Bedarfs zu einem Zielort-Fabric-Block gleichmäßig auf jeden nicht-fehlerhaften Mittelblock in dem Zielort-Fabric-Block. In an alternative, the method further comprises generating a route calculation graph that permits bandwidth allocation by iteratively selecting source and destination mid-blocks that maximize the condition. In another alternative, the method further comprises, for each source fabric block, dividing the demand to a destination fabric block equally to each non-defective middle block in the destination fabric block.
Das Verfahren kann des Weiteren Folgendes umfassen: Herausskalieren jedes Mittelblocks als einen einzelnen Knoten; Bestimmen aller Mittelblockebenen-Pfade für jeden Mittelblock; und Erstellen einer Tunneltabelle für jeden Mittelblockebenen-Pfad. In einem weiteren Beispiel, wenn nicht der gesamte Bedarf gedeckt ist, umfasst das Verfahren des Weiteren das Identifizieren einer eventuellen restlichen Interblock-Bandbreite. The method may further comprise: scaling down each middle block as a single node; Determining all middle block level paths for each middle block; and creating a tunnel table for each middle block level path. In another example, if not all of the demand is covered, the method further comprises identifying any remaining inter-block bandwidth.
In einer anderen Alternative wird das Verfahren iterativ für mehrere Prioritätsgruppen ausgeführt. Dies kann enthalten, das Verfahren für jede Klasse von Diensten innerhalb jeder der mehreren Prioritätsgruppen iterativ auszuführen. In diesem Fall kann das Verfahren des Weiteren das Anwenden einer Gewichtung auf jede Klasse von Diensten innerhalb der mehreren Prioritätsgruppen umfassen. In another alternative, the method is iteratively executed for multiple priority groups. This may include iteratively executing the method for each class of services within each of the plurality of priority groups. In this case, the method may further comprise applying a weight to each class of services within the plurality of priority groups.
In einer anderen Alternative umfasst das Verfahren des Weiteren das Aktualisieren der Auswahl des Quellen-Mittelblocks MBS auf der Basis eines Uplink-Ereignisses und/oder eines Downlink-Ereignisses. In another alternative, the method further comprises updating the selection of the source middle block MB S based on an uplink event and / or a downlink event.
Die oben angesprochene Verfahren kann durch einen oder mehrere Prozessoren ausgeführt werden, wie unten dargelegt wird. Ein Aufzeichnungsmedium, das Anweisungen zum Ausführen des Verfahrens speichert, wird ebenfalls bereitgestellt. The above-mentioned methods may be performed by one or more processors, as set forth below. A recording medium storing instructions for carrying out the method is also provided.
KURZBESCHREIBUNG DER ZEICHNUNGEN BRIEF DESCRIPTION OF THE DRAWINGS
AUSFÜHRLICHE BESCHREIBUNG DETAILED DESCRIPTION
Der Leser weiß Aspekte, Merkmale und Vorteile der Offenbarung zu würdigen, wenn er die folgende Beschreibung von Ausführungsformen und die beiliegenden Figuren studiert. Die gleichen Bezugszahlen in verschiedenen Zeichnungen können die gleichen oder ähnliche Elemente bezeichnen. Die gleichen Bezugszeichen in verschiedenen Zeichnungen können die gleichen oder ähnliche Elemente identifizieren. Ferner ist die folgende Beschreibung nicht einschränkend; der Umfang der vorliegenden Technologie wird durch die beigefügten Ansprüche und Äquivalente definiert. Während bestimmte Prozesse in Übereinstimmung mit Ausführungsbeispielen in den Figuren als in linearer Weise vorkommend dargestellt sind, ist dies nicht erforderlich, sofern nicht ausdrücklich hierin angegeben. Verschiedene Prozesse können in einer anderen Reihenfolge oder gleichzeitig durchgeführt werden. Schritte können auch hinzugefügt oder weggelassen werden, sofern nicht anders angegeben. The reader is to appreciate aspects, features, and advantages of the disclosure as he studies the following description of embodiments and the accompanying drawings. The same reference numerals in different drawings may denote the same or similar elements. The same reference numerals in different drawings may identify the same or similar elements. Furthermore, the following description is not limiting; The scope of the present technology is defined by the appended claims and equivalents. While certain processes in accordance with embodiments are shown as occurring in a linear fashion in the figures, this is not required unless expressly stated herein. Different processes can be performed in a different order or simultaneously. Steps may also be added or omitted, unless stated otherwise.
Die im vorliegenden Text beschriebene Technologie stellt eine Datenverkehrsgestaltungslösung für Datencenter-Netze bereit, einschließlich Netzwerken, die mit Direktverbindungstopologien arbeiten. Wie oben angemerkt, können groß angelegte Datencenter-Netze mehrere Stufen von Switches enthalten, die Kompromisse zwischen Kosten und Bandbreite darstellen. Ein Aspekt der Technologie verwendet eine Fairnessfunktion, die mehrere Optimierungsziele hat und verschiedene Zuteilungsstrategien verwendet, um bereitzustellen eine effiziente Datenroutung. The technology described herein provides a traffic design solution for data center networks, including networks that operate with direct connection topologies. As noted above, large-scale data center networks may include multiple stages of switches that represent cost-to-bandwidth tradeoffs. One aspect of the technology uses a fairness function that has multiple optimization goals and uses different allocation strategies to provide efficient data routing.
Viele Netzwerkzuteilungsalgorithmen berücksichtigen Fairness und Dienstklassen. Jedoch ist es in einem Netzwerk von Superswitches möglich, die Switching-Abstraktion synergistisch zu nutzen, anstatt einen Graph zu verwenden, der aus physischen Switching-Elementen auf niedriger Ebene zusammengesetzt ist. Diese Herangehensweise erzeugt einen viel kleineren Graph, was eine Beschleunigung der Zuteilung zur Folge hat. Außerdem können Bandbreitenzuteilungslösungen zwar einfache Vorstellungen von Fairness haben, wie zum Beispiel Max-Min-Fairness in Bezug auf verschiedene Datenströme in dem Netzwerk, wie im vorliegenden Text besprochen, doch die Gruppierung von Switches schafft neue Fairness-Anforderungen, wie zum Beispiel Fairness in Bezug auf Datenverkehr, der durch die verschiedenen Mittelblöcke eines Superblocks fließt. Zusätzliche Einschränkungen ergeben sich aus der begrenzten Anzahl von Tunneleingängen in Switches. Many network allocation algorithms consider fairness and classes of service. However, in a network of superswitches, it is possible to synergistically use the switching abstraction instead of using a graph composed of low-level physical switching elements. This approach produces a much smaller graph, resulting in acceleration of the allocation. In addition, while bandwidth allocation solutions may have simple notions of fairness, such as max-min fairness to different data streams in the network, as discussed herein, grouping of switches creates new fairness requirements, such as fairness traffic flowing through the various center blocks of a superblock. Additional constraints arise from the limited number of tunnel inputs in switches.
Nach bestimmten Aspekten, die unten noch ausführlich besprochen werden, umfasst eine Fairnessfunktion mehrere Optimierungsziele. Solche Ziele können in absteigender Bedeutung betrachtet werden und enthalten:
- 1. Aufrechterhaltung von Dienstklassen,
- 2. Max-Min-Fairness,
- 3. Intra-Superblock-Max-Min-Fairness,
- 4. Minimierung der Pfaddistanz,
- 5. Minimierung der Gesamtzahl von Pfaden, und
- 6. Minimierung der Anzahl von Pfaden, die zur Deckung eines gegebenen Bedarfs benötigt werden.
- 1. maintenance of service classes,
- 2. Max-Min-Fairness,
- 3. Intra-superblock-max-min-fairness,
- 4. minimize the path distance,
- 5. Minimize the total number of paths, and
- 6. Minimize the number of paths needed to meet a given need.
Mit Bezug auf das erste Ziel können Dienstklassen zu Prioritätsgruppen gruppiert werden. Über die verschiedenen Prioritätsgruppen hinweg, und bei der gewichteten Fairness innerhalb jeder Prioritätsgruppe, werden strenge Prioritäten gewahrt. Die Unterteilung von Dienstklassen in Prioritätsgruppen und die Gewichte verschiedener Dienstklassen werden als Eingabe in den Gesamtprozess vorgegeben. With respect to the first destination, service classes may be grouped into priority groups. Strict priorities are maintained across the different priority groups and the weighted fairness within each priority group. The subdivision of service classes into priority groups and the weights of different service classes are given as input to the overall process.
Aspekte der Technologie beinhalten die Erstellung eines Graphen aus Mittelblöcken, und nur, wenn kein Bedarf mehr gedeckt werden kann, das Zerlegen ausgewählter Mittelblöcke zu Switching-Chips, wodurch ein Graph von Switches verschiedener Abstraktionsgrade entsteht. Im Gegensatz zu Lösungen, die immer k-disjunkte kürzeste Pfade zwischen einer Quelle und einem Zielort erzeugen, werden Pfade nach Bedarf bestimmt. Eine solche Herangehensweise hat zwei wesentliche Vorteile. Erstens werden keine unnötigen Pfade erzeugt. Zweitens werden Pfade, die nicht verfügbar sind, wenn sie tatsächlich gebraucht werden, nicht berechnet. Wenn zum Beispiel der Prozess 10 Pfade im Voraus von einer ersten Quelle (src1) zu einem ersten Zielort (dst1) berechnet, so können diese Pfade Links mit denen von einer zweiten Quelle (src2) zu einem zweiten Zielort (dst2) gemeinsam nutzen. Wollte man also darauf bestehen, sie in vollem Umfang zu nutzen, um Bedarf von src1 zu dst1 zuzuteilen, so könnte dies die Fairness verletzen. Stattdessen wird nach einem Aspekt eine iterative Herangehensweise verwendet. Aspects of the technology include creating a graph of middle blocks, and only when no more needs can be met, disassembling selected mid-blocks into switching chips, creating a graph of switches of various levels of abstraction. Unlike solutions that always produce k-disjoint shortest paths between a source and a destination, paths are determined as needed. Such an approach has two major advantages. First, no unnecessary paths are created. Second, paths that are not available when they are actually needed are not calculated. For example, if the process calculates 10 paths in advance from a first source (src1) to a first destination (dst1), these paths may share links with those from a second source (src2) to a second destination (dst2). So, if you wanted to insist on using them fully to allocate needs from src1 to dst1, it could hurt fairness. Instead, one aspect uses an iterative approach.
Beispielsweise werden zunächst alle (nicht unbedingt disjunkten) Pfade von minimaler Länge zwischen jedem Paar Knoten berechnet, wo ein gewisser Bedarf zuzuteilen ist (im Gegensatz zu den oben beschriebenen k-kürzesten Pfaden werden nur Pfade von minimaler Länge berechnet, so dass alle Pfade, die bei diesem Schritt erzeugt werden, die gleiche Länge haben). Der Prozess verwendet dann ein mehrstufiges Wasserfüllungsverfahren, das die Optimierungsziele erfüllt. Erst wenn alle Pfade von minimaler Länge von einer Quelle zu einem Zielort erschöpft sind, werden die nächst-minimalen Pfade zwischen ihnen mit verfügbarer Kapazität berechnet. For example, first all (not necessarily disjoint) paths of minimum length between each pair of nodes are calculated where there is some need to allocate (in contrast to the k-shortest paths described above, only paths of minimum length are calculated so that all paths, the generated at this step, have the same length). The process then uses a multi-stage water filling process that meets the optimization goals. Only when all paths of minimum length from a source to a destination are exhausted are the next-minimum paths between them calculated with available capacity.
Der Prozess ist dafür konfiguriert, die Zuteilung bei einem Knoten- und Linkausfall inkrementell zu justieren, wobei nur die benötigten Mindestzuteilungsänderungen vorgenommen werden. Wenn der Bedarf zwischen Quelle und Zielort nicht gedeckt werden kann, so wird eine Zerlegungstechnik verwendet, um einen Mittelblock durch Switching-Chips in dem Netzwerk-Graph zu ersetzen, und dann versucht der Prozess, den restlichen Bedarf zuzuteilen. The process is configured to incrementally adjust the allocation in the event of node and link failure, with only the required minimum allocation changes being made. If the source-to-destination demand can not be met, a decomposition technique is used to replace a middle block with switching chips in the network graph, and then the process attempts to allocate the remaining demand.
Dies ist dahingehend vorteilhaft, als es eine zuverlässige Optimierungsfunktion bereitstellt, die reale Produktionserfordernisse erfasst, wie zum Beispiel Datenverkehrslastausgleich, Minimieren von Chip-Tabelleneinträgen und so weiter. Die iterative Zerlegung des Graphen nutzt vorteilhaft die Abstraktion von Switching-Elementen, die in Superclusters verwendet werden. Die verwendeten Techniken passen sich an Bedarfsänderungen und Ausfälle an und berücksichtigen Dienstqualitätsparameter. This is advantageous in that it provides a reliable optimization function that detects real production requirements, such as traffic load balancing, minimizing chip table entries, and so forth. The iterative decomposition of the graph advantageously exploits the abstraction of switching elements used in superclusters. The techniques used adapt to demand changes and failures and take into account quality of service parameters.
Jeder Mittelblock
Wie in
Die Datenverkehrsgestaltung für solche mehrstufigen Datencenter-Netze muss sich verschiedenen Problemen stellen, die man in herkömmlichen ISP-Netzen nicht findet. Zum Beispiel muss die Datenverkehrsgestaltung gut skalierbar sein, um effizient Routen für Datencenter-Netze berechnen zu können, die mehrere Größenordnungen größer sind als ein herkömmliches ISP-Netz, und muss außerdem die Routenkonvergenzzeit bei einem Ausfall minimieren. Sie muss sich auch der Topologieheterogenität in den Datencenter-Netzen widmen und Datenstaus von Datenverkehrsströmen von Ende zu Ende sowohl auf Intra- als auch auf Interblock-Links reduzieren. Des Weiteren muss die Datenverkehrsgestaltung auch begrenzte Weiterleitungstabelleneinträge in Netzwerk-Switches berücksichtigen. The traffic design for such multi-level data center networks must face various problems not found in traditional ISP networks. For example, the traffic design must be well scalable to efficiently compute routes for datacenter networks that are several orders of magnitude larger than a conventional ISP network, and also must minimize the route convergence time in the event of a failure. It also has to address topology heterogeneity in data center networks and reduce data traffic jams from end to end on both intra- and inter-block links. Furthermore, traffic design must also consider limited routing table entries in network switches.
Um solche Probleme zu lösen, nutzen Aspekte der Datenverkehrsgestaltungslösung eine Vielzahl verschiedener Informationen als Eingabe, um die Bandbreitenzuteilung von Interblock-Datenverkehr in einem Satz End-to-End-Pfade zu bestimmen. Die Eingabeinformationen berücksichtigen einige oder alle von Folgendem: Interblocktopologie, einen Satz Datenverkehrserfordernisse, die einen gewünschten Gesamtdurchsatz zwischen einem Paar Quellen- und Zielort-Fabric-Blöcken für eine gegebene Klasse von Diensten (Class of Service, CoS) beschreiben, Disponierungsrichtlinien (zum Beispiel Prioritätsgruppierungen) zwischen verschiedenen CoS, und die Kapazität von Mittelblöcken zum Bedienen von Interblock-Transitdatenverkehr. To solve such problems, aspects of the traffic design solution use a variety of different information as input to determine the bandwidth allocation of inter-block traffic in a set of end-to-end paths. The input information takes into account some or all of the following: interblock topology, a set of traffic requirements that describe a desired overall throughput between a pair of source and destination fabric blocks for a given class of service (CoS), scheduling policies (e.g., priority groupings ) between different CoS, and the capacity of middle blocks to service inter-block transit traffic.
Um dies zu erreichen, werden eine Anzahl von Optimierungszielen berücksichtigt. Ein Ziel ist die Fairness zwischen den Datenverkehrserfordernissen zwischen verschiedenen Quelle- und Zielort-Fabric-Blöcken. Ein anderes ist die Minimierung der Sprungzahl von Interblock-Datenverkehr zum Reduzieren der Latenz. Ein weiteres Ziel ist die Minimierung der Pfadanzahl von Interblock-Datenverkehr zum Reduzieren der Anzahl von Weiterleitungstabelleneinträgen. Ein weiteres Ziel ist die Minimierung von Datenstaus auf Inter- und Intrablock-Links. Ein weiteres Ziel ist die Minimierung der Laufzeitgeschwindigkeit des Datenverkehrsgestaltungsprozesses. Ein weiteres Ziel ist die Minimierung der Routenkonvergenzzeit, sollte es zu einem Ausfall kommen. Und ein weiteres Ziel ist die Berücksichtigung der Dienstqualität. Diese Ziele werden in der Weise erreicht, die unten ausführlich besprochen wird. To achieve this, a number of optimization goals are considered. One goal is fairness between the traffic requirements between different source and destination fabric blocks. Another is to minimize the hop count of interblock traffic to reduce latency. Another objective is to minimize the number of paths of interblock traffic to reduce the number of routing table entries. Another goal is to minimize congestion on inter- and intra-block links. Another goal is to minimize the runtime speed of the traffic design process. Another goal is to minimize the route convergence time should a failure occur. And another goal is the consideration of the quality of service. These goals are achieved in the way that will be discussed in detail below.
Ein Aspekt der im vorliegenden Text besprochenen Bandbreitenzuteilung beinhaltet eine „Wasserfüllungs“-Technik zum Erhöhen der Bandbreitenzuteilung für die Datenverkehrserfordernisse von verschiedenen Quellen- und Zielort-Fabric-Blockpaaren mit gleichem Tempo. Die Bandbreitenzuteilungen stoppen für Datenverkehrserfordernisse, die in vollem Umfang erfüllt sind, und nehmen weiter zu für jene, die unerfüllt bleiben. Dies geschieht in einem Fall, indem zunächst der kürzeste Pfad favorisiert wird, um die Sprungzahl und somit die Latenz von Interblock-Datenverkehr zu reduzieren. One aspect of the bandwidth allocation discussed herein includes a "water-filling" technique for increasing the bandwidth allocation for the traffic requirements of different source and destination fabric block pairs at the same rate. The bandwidth allocations stop for traffic requirements that are fully met and continue to increase for those who remain unfulfilled. This happens in one case by first favoring the shortest path to reduce the hop count and thus the latency of interblock traffic.
Wie mit Bezug auf die
In diesem Beispiel ist jeder Mittelblock
Zur Minimierung von Datenstaus an den Inter-Mittelblockkanten bestimmt ein Aspekt des Datenverkehrsgestaltungsprozesses die Kapazität eines Pfades als das Minimum zwischen (a) der Kapazität eines Engpass-Interblock-Links und (b) der Kapazität des Engpass-Mittelblocks zum Bedienen von Interblock-Transitdatenverkehr ohne Datenstaus. Jede Mittelblockkantenverbindung kann einen oder mehrere physische Kommunikationslinks umfassen. To minimize congestion at the inter-medial block edges, an aspect of the traffic shaping process determines the capacity of a path as the minimum between (a) the capacity of a bottleneck interblock link and (b) the capacity of the bottleneck mid-block for servicing inter-block transit traffic without congestion. Each middle block edge connection may include one or more physical communication links.
Zur Minimierung von Datenstaus auf TOR-Uplinks verwendet der Datenverkehrsgestaltungsprozess die unten besprochenen Strategien, um Inter- und Intrablock-„Max/Min“-Fairness sicherzustellen. Ein Flussdiagramm
Zuerst teilt der Prozess für jeden Fabric-Block einen Bandbreitenbedarf zu einem Zielort-Fabric-Block gleichmäßig zwischen den Mittelblöcken dieses Fabric-Blocks, wie in Block
Betrachten wir die Zielort-Fabric-Blöcke FBd der Reihe nach im Kreis, wie in Block
Unter den Mittelblöcken im Quellen-Fabric-Block FBS wird eine Teilmenge Μ mit der kürzesten verfügbaren Pfadlänge zum Zielort-Mittelblock MBd gesucht, wie in Block
min (demand (MBS, FBd), spf_capacity(MBS, MBd)),
wobei spf_capacity(MBS, MBd) die kürzeste Pfadkapazität zwischen Quellen-Mittelblock MBS und Zielort-Mittelblock MBd darstellt, und demand(MBS, FBd) den Bedarf zwischen Quellen-Mittelblock MBS zu Zielort-Fabric-Block FBd darstellt. In diesem Szenario skaliert der Datenverkehrsgestaltungsprozess – zum Zweck der Skalierbarkeit und Minimierung der Pfadanzahl – zuerst jeden Mittelblock als einen einzelnen Knoten heraus und berechnet alle Mittelblockebenen-Pfade. Der Prozess endet, wenn der gesamte Bedarf durch solche Pfade gedeckt werden kann, und richtet einen „Tunnel“ für jeden in den
min (demand (MB S , FB d ), spf_capacity (MB S , MB d )),
where spf_capacity (MB S , MB d ) represents the shortest path capacity between source middle block MB S and destination middle block MB d , and demand (MB S , FB d ) the demand between source middle block MB S to destination fabric block FB d represents. In this scenario, for purposes of scalability and path number minimization, the traffic shaping process first scales each center block as a single node and computes all middle block level paths. The process ends when all need can be covered by such paths and sets up a "tunnel" for everyone in the
Wenn nicht der gesamte Bedarf gedeckt ist, so wird der TE-Prozess fortgesetzt, um die restliche Interblock-Bandbreite zu identifizieren, die kein Bouncing innerhalb der Mittelblöcke erfordert. Nach einem Aspekt der Offenbarung generiert eine Herangehensweise Graphen mit abnehmenden Abstraktionsgraden, was iterativ in den
In solchen Graphen werden Mittelblöcke mit 0 Restkapazität in einen Satz getrennter s3-Switches zerlegt. Der Datenverkehrsgestaltungsprozess bestimmt neue Interblockpfade, die einen Satz Mittelblöcke mit einer Restkapazität ungleich null und s3-Switches in Mittelblöcken ohne Restkapazität durchqueren. Dies wiederholt sich, bis der Graph nur s3-Switches in Mittelblöcken enthält oder kein Bedarf gedeckt werden kann. In such graphs, zero-capacity middle blocks are decomposed into a set of separate s3 switches. The traffic shaping process determines new interblock paths traversing a set of non-zero residual capacity mid-blocks and s3 switches in mid-blocks without remaining capacity. This repeats until the graph contains only s3 switches in mid-blocks or no need can be met.
Ein Nutzeffekt des Beginnens mit einem Graphen, der von Mittelblöcken abgeleitet ist, und des Zerlegens in Switches nur dann, wenn kein Bedarf mehr gedeckt werden kann, ergibt sich aus der Beobachtung, dass es viel mehr Switchebenen-Pfade als Mittelblock-Ebenen-Pfade mit wahrscheinlich viel höherer Gesamtkapazität gibt. Dies wird unten ausführlich veranschaulicht. A benefit of starting with a graph derived from mid-blocks and breaking into switches only when no more need can be met results from the observation that there are many more switch planes paths than mid-block planar paths probably much higher total capacity. This is illustrated in detail below.
Nehmen wir beispielsweise an, dass jeder Mittelblock (MB) eines Fabric-Blocks (FB) acht S2- und acht S3-Switches umfasst. Ein Ein-Sprung-Mittelblockebenen-Pfad zwischen einem ersten Mittelblock MB1 und einem zweiten Mittelblock MB2 würde 3-Sprung-Switchebenen-Pfade ergeben: MB1.s2–MB1.s3–MB2.s3–MB2.s2. For example, assume that each middle block (MB) of a fabric block (FB) includes eight S2 and eight S3 switches. A one-hop mid-block path between a first middle block MB1 and a second middle block MB2 would yield 3-hop switch paths: MB1.s2-MB1.s3-MB2.s3-MB2.s2.
In diesem Fall kann, weil jeder Mittelblock acht S2-Ebenen-Switches hat, jeder dieser s2-Switches verwendet werden, um diesen Pfad in sowohl den Quellen- als auch den Zielort-Mittelblöcken zu durchqueren. Folglich gibt es insgesamt 64 verschiedene Switchebenen-Pfade, die jeweils durch eine eindeutige Kombination von MB1.s2 und MB2.s2 gekennzeichnet sind. Zum Beispiel könnten zwei verschiedene Switchebenen-Pfade sein:
MBl.s2 [0]—MB1.s3 [2]–MB2.s3 [4]–MB2.s2 [0]
MB1.s2 [0]–MB1.s3 [1]–MB2.s3 [3]–MB2.s2 [1] In this case, because each middle block has eight S2-level switches, each of these s2 switches can be used to traverse this path in both the source and destination mid-blocks. As a result, there are a total of 64 different switch level paths, each characterized by a unique combination of MB1.s2 and MB2.s2. For example, there could be two different switch levels paths:
MBl.s2 [0] -MB1.s3 [2] -MB2.s3 [4] -MB2.s2 [0]
MB1.s2 [0] -MB1.s3 [1] -MB2.s3 [3] -MB2.s2 [1]
Hier bezeichnen die Zahlen in Klammern, welche speziellen s2- und s3-Chips der Pfad durchquert. Here, the numbers in parentheses indicate which particular s2 and s3 chips the path traverses.
Es ist möglich, dass zwei Mittelblöcke durch mehrere S3-Links verbunden werden. In einem solchen Fall ist die Gesamtzahl von Pfaden in dem einen Sprung-Fall die Anzahl von Links zwischen den S3-Switches des ersten Mittelblocks MB1 und den S3-Switches des zweiten Mittelblocks MB2, multipliziert mit 64. Für einen Pfad der Länge k ist selbst dann, wenn es nur einen einzigen S3-Link gibt, der jedes MB-Paar auf dem Pfad verbindet, die Anzahl von Switchebenen-Pfaden gleich 8(k+1). Somit reduzieren das Wegabstrahieren von Switches und der anfängliche Blick auf Mittelblockebenen-Pfade den Graph beträchtlich und beschleunigen folglich den Routenberechnungsprozess. It is possible for two center blocks to be connected by multiple S3 links. In such a case, the total number of paths in the one hop case is the number of links between the S3 switches of the first middle block MB1 and the S3 switches of the second middle block MB2 multiplied by 64. For a path of length k is itself then, if there is only a single S3 link connecting each MB pair on the path, the number of switch planes paths equals 8 (k + 1) . Thus, the path abstraction of switches and the initial look at middle block level paths significantly reduce the graph and thus speed up the route calculation process.
Zur Minimierung der Routenkonvergenz bei Topologie-Ereignissen identifiziert ein Aspekt des Datenverkehrsgestaltungsprozesses den von den Ausfall-Ereignissen betroffenen Bedarf oder den restlichen Bedarf, der nicht vor Link/Switch-up-Ereignissen gedeckt wurde, und bestimmt einen Mindestsatz neuer Pfade, die für solche Erfordernisse zugeteilt werden sollen. Diese inkrementelle Aktualisierung wird anstelle einer erneuten Ausführung des Pfadbandbreitenzuteilungsalgorithmus, komplett von Anbeginn, ausgeführt. To minimize route convergence in topology events, one aspect of the traffic design process identifies the demand affected by the outage events or the remaining need that was not met prior to link / switch-up events and determines a minimum set of new paths that will support such requirements to be allocated. This incremental update is performed instead of rerunning the Path Bandwidth Allocation algorithm, completely from the beginning.
Durch den Datenverkehrsgestaltungsprozess werden verschiedene Dienstklassen (Classes of Service, CoS) unterstützt. Der Prozess handhabt einen Satz Erfordernisse, die jeweils als ein Tripel dargestellt werden können (CoS, Quellen-MB, Zielort-Fabric-Block). Die Dienstklassen werden in Prioritätsgruppen gruppiert. Wenn es zum Beispiel vier Dienstklassen gibt (CoS1, CoS2, CoS3 und CoS4), so kann eine mögliche Konfiguration das Gruppieren von CoS1 und CoS2 miteinander in einer ersten Prioritätsgruppe 1 und von CoS3 und CoS4 miteinander in einer zweiten Prioritätsgruppe 2 anweisen. Die Anordnung verschiedener Dienstklassen in Prioritätsgruppen dient als eine Eingabe in den Prozess. The traffic shaping process supports various classes of service (CoS). The process handles a set of requirements, each of which can be represented as a triple (CoS, Source MB, Destination Fabric Block). The service classes are grouped in priority groups. For example, if there are four classes of service (CoS1, CoS2, CoS3, and CoS4), one possible configuration may direct the grouping of CoS1 and CoS2 together in a first priority group 1 and CoS3 and CoS4 together in a
Der Prozess wendet zweckmäßigerweise eine strikte Priorität zwischen verschiedenen Prioritätsgruppen mit gewichteter fairer Zuteilung innerhalb einer Prioritätsgruppe an. So versucht der Prozess zuerst, alle Erfordernisse in der Prioritätsgruppe 1 zu erfüllen, und schreitet erst dann zu Prioritätsgruppe 2 voran. Bei der Zuteilung von Bandbreite für Gruppe 1 wird eine „gewichtete Wasserfüllung“ ausgeführt, wobei die Gewichte als eine Eingabe in den Prozess gegeben werden. Anstatt jedes Mal zu versuchen, den Bedarf um einen gewissen Betrag (delta) zu senken, wird er im Wesentlichen um diesen Betrag gesenkt, während eine Gewichtung der Dienstklasse gemäß delta*Gewicht (CoS) berücksichtigt wird. Somit kann der oben mit Bezug auf
Ein Beispiel für einen Pseudocode auf hoher Ebene eines Datenverkehrsgestaltungsprozesses („GraphConstruction“) nach Aspekten der Technologie ist unten dargestellt. Die GraphConstruction ()-Funktion erstellt einen Graph für eine Routenberechnung auf der Basis einer Interblocktopologie. Zunächst beginnt der Graph mit einem höchsten Abstraktionsgrad, wobei jeder Knoten einen Mittelblock darstellt, und reduziert allmählich den Abstraktionsgrad, um Pfade mit einem gemischten Abstraktionsgrad zu identifizieren, um den zusätzlichen Bedarf zu decken. Der Rest des Pseudocode implementiert die oben beschriebenen Zuteilungsstrategien. Repeat GraphConstruction ( ): An example of a high-level pseudo-code of a traffic design process ("GraphConstruction") in terms of technology is shown below. The GraphConstruction () function creates a graph for a route calculation based on an interblock topology. First begins the Graph with a highest level of abstraction, where each node represents a middle block, and gradually reduces the level of abstraction to identify paths with a mixed level of abstraction to meet the additional needs. The remainder of the pseudocode implements the allocation strategies described above. Repeat GraphConstruction ():
Der Datenverkehrsgestaltungsprozess verwendet zweckmäßigerweise einige oder alle der unten beschriebenen Bausteine für Pfadbestimmung und Bandbreitenzuteilungen. The traffic shaping process expediently uses some or all of the path determination and bandwidth allocation building blocks described below.
(I) Berechnung der kürzesten Pfade (I) Calculation of the shortest paths
Es ist möglich, eine Variation des Dijkstra-Algorithmus der kürzesten Pfade von einer einzelnen Quelle zum Berechnen der kürzesten Pfade zu implementieren. In der Variation zur Verwendung mit Aspekten der im vorliegenden Text besprochenen Technologie ist die Eingabe ein Quellen-MB (src) und der restliche Mittelblock-Graph. Der Algorithmus findet alle kürzesten Pfade von src zu jedem der anderen Knoten. Für jeden Knoten in dem Graph generiert er eine Liste von Vorgängern, die allen kürzesten Pfaden von src zu diesem Knoten entsprechen. It is possible to implement a variation of the shortest path Dijkstra algorithm from a single source for calculating the shortest paths. In the variation for use with aspects of the technology discussed herein, the input is a source MB (src) and the remainder of the mid-block graph. The algorithm finds all the shortest paths from src to each of the other nodes. For each node in the graph, it generates a list of predecessors that correspond to all the shortest paths of src to that node.
Eine Kante wird als funktionsfähig betrachtet, solange ihre Restkapazität größer als 0 ist und die Restkapazität ihrer Endpunktknoten größer als 0 ist. Der Algorithmus wird parallel aus einer gegebenen Liste von Quellenknoten abgearbeitet. Zunächst enthält diese Liste alle Knoten in dem Graph. Wenn alle kürzesten Pfade zwischen einigen Quellen- und Zielort-Knoten erschöpft sind, so wird die Kürzeste-Pfade-Suche aktiviert, wobei die Liste nur den relevanten Quellenknoten enthält (siehe unten). An edge is considered functional as long as its residual capacity is greater than 0 and the residual capacity of its endpoint nodes is greater than zero. The algorithm is processed in parallel from a given list of source nodes. First, this list contains all the nodes in the graph. When all the shortest paths between some source and destination nodes are exhausted, the shortest path search is activated, with the list containing only the relevant source node (see below).
(II) Finden des kürzesten Pfades mit der maximalen Kapazität (II) Find the shortest path with the maximum capacity
Eine rekursive Funktion kann verwendet werden, um den kürzesten Pfad mit der maximalen Kapazität von einem gegebenen Quellenknoten (src) zu einem gegebenen Zielort-Knoten (dst) zu finden. Zusätzlich zu src und dst nimmt die rekursive Funktion als Eingabe die Liste der Vorgänger von dst, die kürzesten Pfaden von src zu dst entsprechen. Die Funktion arbeitet die Vorgänger einen nach dem anderen ab und berechnet die Kapazität des letzten Sprungs gemäß einer Minimierungsfunktion:
last_hop_capacity = min (predecessor mb capacity, dst mb capacity, edge capacity between predecessor and dst). A recursive function can be used to find the shortest path with the maximum capacity from a given source node (src) to a given destination node (dst). In addition to src and dst, the recursive function takes as input the list of predecessors of dst, the shortest paths from src to dst. The function processes the predecessors one after the other and calculates the capacity of the last jump according to a minimization function:
last_hop_capacity = min (predecessor mb capacity, dst mb capacity, edge capacity between predecessor and dst).
Wenn last_hop_capacity kleiner ist als die bisher gesehene maximale Pfadkapazität, so gibt es keinen Grund, diesen Vorgänger weiter zu betrachten. Anderenfalls wird die Funktion rekursiv mit diesem Vorgänger aufgerufen, und die Gesamtpfadkapazität, die diesen Vorgänger verwendet, ist min (last_hop_capacity, max capacity path from src to predecessor). Wenn diese Pfadkapazität größer ist als das bisher gefundene Maximum, so wird das Maximum aktualisiert. Die Rekursion verwendet einen Cache, um zu vermeiden, Pfade mit maximaler Kapazität, die bereits gefunden wurden, neu berechnen zu müssen. If last_hop_capacity is less than the maximum path capacity seen so far, there is no reason to look at this predecessor further. Otherwise, the function is called recursively with this predecessor, and the total path capacity using this predecessor is min (last_hop_capacity, max capacity_path from src to predecessor). If this path capacity is greater than the previously found maximum, the maximum is updated. The recursion uses a cache to avoid having to recalculate paths with maximum capacity that have already been found.
(III) Erhalten des nächsten nutzbaren kürzesten Pfades zwischen zwei Mittelblöcken (III) Obtain the next usable shortest path between two middle blocks
Dieses Verfahren („get_path“) erhält einen Quellenknoten (MBS) und einen Zielort-Knoten (MBd) als Parameter und findet einen kürzesten Pfad mit nicht-leerer Kapazität zwischen diesen Knoten. Es eskaliert seine Suche nach dem Pfad gemäß den folgenden drei Schritten. Erstens: Wenn der letzte Pfad, der dafür verwendet wurde, Bandbreite zwischen dem Quellen- und dem Zielort zuzuteilen, immer noch etwas Kapazität hat, so wird dieser Pfad verwendet. Zu diesem Zweck erinnert sich das System immer an den letzten Pfad (speichert ihn zum Beispiel im Cache), der für die Zuteilung zwischen jedem Paar Knoten verwendet wurde. Zweitens: Der Prozess findet den kürzesten Pfad mit maximaler Kapazität unter den kürzesten Pfaden, die durch den jüngsten Aufruf des Algorithmus zur Berechnung der kürzesten Pfade gefunden wurden. Wenn der zurückgemeldete Pfad eine nicht-leere Kapazität hat, so wird dieser Pfad verwendet. Und drittens: Aufrufen des Algorithmus zur Berechnung der kürzesten Pfade, um nach neuen kürzesten Pfaden zu schauen, aber dieses Mal nur von der Quelle zu allen anderen Knoten in dem Graph. Dann wird der kürzeste Pfad mit maximaler Kapazität unter den kürzesten Pfaden gefunden. Hier wird, wenn der zurückgemeldete Pfad eine nicht-leere Kapazität hat, dieser Pfad verwendet. This method ("get_path") receives a source node (MB S ) and a destination node (MB d ) as parameters and finds a shortest path with non-empty capacity between these nodes. It escalates its search for the path according to the following three steps. First, if the last path used to allocate bandwidth between the source and the destination still has some capacity, that path will be used. For this purpose, the system always remembers the last path (for example, stores it in the cache) that was used for allocation between each pair of nodes. Second, the process finds the shortest path of maximum capacity among the shortest paths found by the most recent call of the algorithm for calculating the shortest paths. If the returned path has a non-empty capacity, this path will be used. And third, call the shortest path calculation algorithm to look for new shortest paths, but this time only from the source to all other nodes in the graph. Then the shortest path with maximum capacity is found among the shortest paths. Here, if the returned path has a non-empty capacity, this path is used.
(IV) Zuteilen von Bandbreite auf einem Pfad (IV) allocating bandwidth on a path
Dieses Verfahren („allocate_path“) erhält einen Pfad und den Bedarf als einen Parameter und teilt min(path capacity, demand) auf diesem Pfad zu. Die Restkapazität wird für jeden Link sowie jeden Knoten (Mittelblock) beibehalten. This method ("allocate_path") receives a path and the demand as a parameter and allocates min (path capacity, demand) on this path. The remaining capacity is retained for each link as well as each node (middle block).
(V) Invertierter Index von Pfaden (V) Inverted index of paths
Dieses Verfahren („index_path“) erhält einen Pfad als Parameter. Für jeden Knoten und Link in dem gegebenen Pfad wird der Pfadidentifikator zu der Liste von Pfaden hinzugefügt, die den Knoten/Link durchqueren, wodurch ein umgekehrter Index entsteht. Dies erlaubt es dem System, effizient auf Link- und Knotenausfälle zu reagieren, indem nur die relevanten Pfade für eine Neuzuteilung in Betracht gezogen werden. Wenn es zum Beispiel zwei Pfade p1 = (a, b, c) und p2 = (d, b, c, e) gibt, so hätte das System den folgenden Index für die Links (und in ähnlicher Weise einen Index für die Knoten):
(a, b): p1
(b, c): p1/p2
(d, b): p2
(c, e): p2 This method ("index_path") gets a path as a parameter. For each node and link in the given path, the path identifier is added to the list of paths traversing the node / link, creating a reverse index. This allows the system to efficiently respond to link and node failures by considering only the relevant paths for reallocation. For example, if there are two paths p1 = (a, b, c) and p2 = (d, b, c, e), then the system would have the following index for the links (and similarly an index for the nodes) :
(a, b): p1
(b, c): p1 / p2
(d, b): p2
(c, e): p2
Nach einem Aspekt der Technologie wird ein Pfad durch eine eindeutige Pfad-ID dargestellt. Die eindeutige Pfad-ID kann durch Hashing der Abfolge von Knoten-IDs in dem Pfad erzeugt werden. In one aspect of the technology, a path is represented by a unique path ID. The unique path ID can be generated by hashing the sequence of node IDs in the path.
(VI) Bandbreitenzuteilung: Breitester Pfad (VI) Bandwidth allocation: Widest path
Für diesen Prozess („widest_path“) gibt es Eingaben von einem Quellen-Fabric-Block FBS, eines Zielort-Mittelblocks MB und einem konstanten DELTA, das die Kapazität angibt. Das Ziel ist es, den „besten“ Mittelblock in dem Quellen-Fabric-Block FBS zu finden, DELTA auf dem nächsten nutzbaren Pfad zwischen diesem Quellen-Mittelblock und einem gegebenen Mittelblock MB zuzuteilen und den verwendeten Pfad zu indexieren. Dieser Prozess erbringt den „besten“ Quellen-Mittelblock oder null, wenn kein geeigneter Quellen-Mittelblock gefunden wird. For this process ("widest_path"), there are inputs from a source fabric block FB S , a destination middle block MB and a constant DELTA indicating the capacity. The goal is to find the "best" middle block in the source fabric block FB S , allocate DELTA on the next usable path between that source middle block and a given middle block MB, and index the path used. This process yields the "best" source middle block or zero if no appropriate source middle block is found.
Eine Annahme ist, dass die Kantenkapazität ein Mehrfaches von DELTA ist. Diese Annahme bedeutet, dass ein Pfad, der weniger als DELTA Kapazität hat, notwendigerweise keine Restkapazität hat. Wenn also get_path aufgerufen wird, so sucht der Prozess nach dem kürzesten Pfad zwischen den zwei Knoten, der mindestens DELTA Restkapazität hat. Wenn er keinen solchen Pfad findet, so wird bestimmt, dass es keine nutzbaren Pfade von irgendeiner Länge zwischen dem Quellen- und Zielort mehr gibt. One assumption is that the edge capacity is a multiple of DELTA. This assumption implies that a path having less than DELTA capacity does not necessarily have any remaining capacity. So, when get_path is called, the process looks for the shortest path between the two nodes, which has at least DELTA residual capacity. If it does not find such a path, it is determined that there are no usable paths of any length between the source and destination.
In diesem Prozess ist der „beste“ Quellen-Mittelblock im FBS einer, der (in dieser Reihenfolge):
- a) mindestens DELTA Kapazität auf dem nächsten nutzbaren Pfad zu MB hat und mindestens DELTA ungedeckten Bedarf zu dem Superblock hat, der MB umschließt;
- b) eine minimale Distanz zu MB hat; und
- c) einen maximalen ungedeckten Bedarf zu dem Fabric-Block hat, der MB umschließt.
- a) has at least DELTA capacity on the next usable path to MB and has at least DELTA unmet need for the superblock enclosing MB;
- b) has a minimum distance to MB; and
- c) has a maximum unmet need for the fabric block enclosing MB.
Der Prozess wählt einen solcher „besten“ Mittelblöcke nach Belieben und teilt DELTA auf dem nächsten kürzesten nutzbaren Pfad zwischen dem Mittelblock und dem gegebenen Mittelblock MB zu. Die Zuteilung selbst ist eine Abbildung von Quellen- und Zielort-Mittelblockpaaren auf eine Liste, wobei jedes Element einen anderen Pfad darstellt, und umfasst die eindeutige Pfad-ID und den zugeteilten Betrag auf diesem Pfad. The process chooses such "best" middle blocks at will and allocates DELTA on the next shortest usable path between the middle block and the given middle block MB. The grant itself is a mapping of source and destination mid-block pairs onto a list, each item representing a different path, and includes the unique path ID and the allocated amount on that path.
(VII) Bandbreitenzuteilung: Beurteilen möglicher Zielorte (VII) Bandwidth Allocation: Assess possible destinations
In diesem Prozess („allocate_bandwidth“) ist die Eingabe ein Bedarf von einem Mittelblock zu einem Fabric-Block, und die Ausgabe ist eine Zuteilung zwischen den Knoten in dem Graph, der mit ungedecktem Bedarf verknüpft ist. Der Prozess rotiert durch mögliche Zielort-Fabric-Blöcke. Für jeden Zielort-Fabric-Block behält der Prozess den momentanen Zielort-Mittelblock bei und rotiert jedes Mal durch die Mittelblöcke in diesem Zielort-Fabric-Block, wenn der Fabric-Block für eine Zuteilung in Betracht gezogen wird. Das System speichert auch eine Liste „verbrannter Ziel-Mittelblöcke“. Dies sind Zielort-Mittelblöcke, für die der Prozess keine Quelle finden konnte, so dass es keinen Grund gibt, sie in Zukunft noch einmal in Betracht zu ziehen. Der Prozess endet, wenn alle Mittelblöcke in dem Graph „verbrannter“ sind. In this process ("allocate_bandwidth"), the input is a requirement of a middle block to a fabric block, and the output is an allocation between the nodes in the graph associated with unmet need. The process rotates through possible destination fabric blocks. For each destination fabric block, the process retains the current destination midblock and rotates through the middle blocks in that destination fabric block each time the fabric block is considered for arbitration. The system also stores a list of "burnt target middle blocks". These are destination middle blocks for which the process could not find a source, so there is no reason to consider them again in the future. The process ends when all middle blocks in the graph are "burned".
Bei einem gegebenen Zielort-Mittelblock wählt der Prozess einen Quellen-Fabric-Block der Reihe nach im Kreis. Er aktiviert dann den widest_path-Bandbreitenzuteilungsprozess mit diesem Quellen-Fabric-Block und dem Zielort-Mittelblock als Parameter. Wenn der widest_path-Bandbreitenzuteilungsprozess erfolgreich eine Zuteilung von DELTA vornimmt, so kehrt der allocate_bandwidth-Prozess zum Anfang zurück, wobei er dieses Mal einen anderen Zielort-Mittelblock (der Reihe nach im Kreis) betrachtet. Anderenfalls wählt der allocate_bandwidth-Prozess einen anderen Quellen-Fabric-Block der Reihe nach im Kreis und aktiviert den widest_path-Bandbreitenzuteilungsprozess ab diesem Fabric-Block, und so weiter, bis entweder der widest_path-Bandbreitenzuteilungsprozess erfolgreich eine Zuteilung vornimmt oder der allocate_bandwidth-Prozess durch alle möglichen Quellen-Superblöcke rotiert ist. Im letzteren Fall „verbrennt“ der Prozess den Zielort-Mittelblock. For a given destination mid-block, the process circularly selects a source fabric block in turn. It then activates the widest_path bandwidth allocation process with this source fabric block and the destination middle block as parameters. If the widest_path bandwidth allocation process successfully allocates DELTA, then the allocate_bandwidth process returns to the beginning, this time looking at another destination middle block (in turn, in a circle). Otherwise, the allocate_bandwidth process sequentially selects another source fabric block and activates the widest_path bandwidth allocation process from this fabric block, and so on until either the widest_path bandwidth allocation process successfully arbitrates or the allocate_bandwidth process through all possible source super blocks are rotated. In the latter case, the process "burns" the destination middle block.
Wie oben angesprochen, ist jede „Zuteilung“ eine Liste von Pfaden zwischen einigen Quellen- und Zielort-Mittelblöcken, wobei jeder Pfad irgendeinen zugeteilten Betrag hat. Der letzte Schritt des allocate_bandwidth-Prozesses ist die Normalisierung dieser Beträge, um sie zu relativen „Gewichten“ zu machen, beispielsweise unter Verwendung des folgenden Prozesses. As mentioned above, each "allotment" is a list of paths between some source and destination middle blocks, each path having some amount allocated. The last step of the allocate_bandwidth process is to normalize these amounts to make them relative "weights" using, for example, the following process.
Eine Eingabe in den Prozess ist eine Liste von Zuteilungsbeträgen. Jeder Betrag entspricht einer Zuteilung auf einem anderen Pfad zwischen derselben Quelle und demselben Zielort. Die Ausgabe ist eine Liste relativer Gewichte, eines je Zuteilungsbetrag. Der Prozess führt die folgende Ermittlung durch. Finden des maximalen Zuteilungsbetrages in der Liste, als „max_allocation“ bezeichnet. Für jeden Zuteilungsbetrag, Generieren eines Gewichts (auf der Skala von 1 bis 10), als ceil(10 * allocation / max_allocation) berechnet. „ceil“ bedeutet hier „ceiling“, d. h. das Aufrunden auf die nächstgrößere ganze Zahl. Und dann Normalisieren der Gewichte unter Verwendung ihres größten gemeinsamen Nenners (Greatest Common Denominator, GCD). Zum Beispiel wird 9:6:3 zu 3:2:1. An entry in the process is a list of allocation amounts. Each amount corresponds to an allocation on a different path between the same source and the same destination. The output is a list of relative weights, one per allocation amount. The process performs the following determination. Find the maximum allocation amount in the list, called max_allocation. For each allocation amount, generate a weight (on the scale of 1 to 10), calculated as ceil (10 * allocation / max_allocation). "Ceil" here means "ceiling", d. H. rounding up to the next larger integer. And then normalizing the weights using their largest common denominator (GCD). For example, 9: 6: 3 becomes 3: 2: 1.
(VIII) Zuteilungsaufhebungsprozess (VIII) allotment process
Nach einem Aspekt der Offenbarung kann das System, wenn ein physischer Link ausfällt, die Zuteilung aller Pfade aufheben, die ihn durchqueren. In einem Graph ist ein physischer Link Teil einer Kante zwischen zwei Mittelblöcken, so dass ein Ausfall eines physischen Links eine Reduzierung der Kantenkapazität bedeutet. Darum muss die Zuteilung des richtigen Betrages aufgehoben werden, um diese neue Kapazität zu erfüllen. Die Zuteilungsaufhebung („deallocate_paths_through_link“) verwendet den umgekehrten Index von Pfaden, um die Pfade zu finden, die betroffen sein können. In one aspect of the disclosure, if a physical link fails, the system may override the allocation of all paths traversing it. In a graph, a physical link is part of an edge between two middle blocks, so a failure of a physical link means a reduction in edge capacity. Therefore, the allocation of the correct amount must be lifted to meet this new capacity. The deallocate_paths_through_link uses the inverted index of paths to find the paths that may be affected.
Die Eingabe in diesen Prozess ist eine Kante zwischen zwei Mittelblöcken und seine neue Kapazität. Wenn die neue Kapazität ausreicht, um die momentane Zuteilung durch den Link zu erfüllen, so wird der Prozess ausgeführt. Anderenfalls berechnet der Prozess den Betrag an Bandbreite, dessen Zuteilung aufzuheben ist. In einem Szenario hebt der Prozess die Zuteilung von gerade genug Bandbreite auf, um die neue Kapazität zu erfüllen, so dass die restliche Kantenkapazität nach der Zuteilungsaufhebung 0 ist. Alternativ ist es möglich, etwas mehr Zuteilung aufheben als notwendig, so dass die Restkapazität größer als 0 ist. Dies würde es dem System erlauben, ein paar weitere Ausfälle zu tolerieren, ohne jedem Mal die Zuteilung aufheben zu müssen (Überreagieren beim ersten Mal, aber dafür Einsparen von etwas Zeit später). The input to this process is an edge between two middle blocks and its new capacity. If the new capacity is sufficient to satisfy the current allocation by the link, then the process is executed. Otherwise, the process calculates the amount of bandwidth whose allocation is to be overridden. In one scenario, the process abolishes the allocation of just enough bandwidth to meet the new capacity so that the remaining edge capacity after arbitration cancellation is zero. Alternatively, it is possible to cancel a little more allocation than necessary, so that the residual capacity is greater than zero. This would allow the system to tolerate a few more failures without having to cancel the allocation each time (overreacting the first time, but saving some time later).
Alle Pfade, welche die betroffenen Kommunikationslink durchqueren, können – nach absteigendem Zuteilungsbetrag sortiert – betrachtet werden. Der Grund dafür ist, dass der Zuteilungsaufhebungsprozess so wenige Pfade wie möglich berühren sollte. Für jeden Pfad wird der zugeteilte Betrag aktualisiert, oder der Pfad wird vollständig aus der Zuteilung herausgenommen, wenn er gänzlich geleert wurde. Die restlichen Link- und Knotenkapazitäten entlang des Pfades werden aktualisiert, zusammen mit dem ungedeckten Bedarf zwischen Quellen- und Zielort-Knoten auf dem Pfad und dem umgekehrten Pfadindex. Der Prozess ist vollendet, wenn die Zuteilungsaufhebung die neue Kapazität des betroffenen Kommunikationslinks erfüllt. All paths traversing the affected communication link can be viewed sorted by decreasing allotment amount. The reason for this is that the allotment process should touch as few paths as possible. For each path, the allocated amount is updated, or the path is completely removed from the allotment when it has been completely emptied. The remaining link and node capacities along the path are updated, along with the unmet need between source and destination nodes on the path and the reverse path index. The process is completed when the allocation cancellation meets the new capacity of the affected communication link.
(IX) Kantenkapazitätenaktualisierungsprozess (IX) edge capacity updating process
Der Kantenkapazitätenaktualisierungsprozess („capacities_update_delta“) verwendet eine Liste von Paaren der Form (edge, capacity delta) als seine Eingabe. Der Prozess wertet die Liste aus. Für jede Kante in der Liste aktiviert der Prozess, wenn die Kapazität abnimmt, eine Zuteilungsaufhebung (deallocate_paths_through_link) und aktualisiert dann die Link-Kapazität. Nachdem die Liste verarbeitet wurde, überprüft das System, ob es ungedeckten Bedarf gibt. Wenn ja, so wird der allocate_bandwidth-Prozess aufgerufen, um eine inkrementelle Bandbreitenzuteilung zu versuchen. Es ist zu beachten, dass, wenn eine Link-Kapazität gleich bleibt oder zunimmt, der Prozess keine Zuteilung aufheben muss; jedoch kann das System möglicherweise einen gewissen früheren ungedeckten Bedarf decken, wenn eine Zuteilungsaufhebung ausgeführt wird. The edge capacity update process ("capacities_update_delta") uses a list of pairs of shapes (edge, capacity delta) as its input. The process evaluates the list. For each edge in the list, as capacity decreases, the process activates a deallocate_paths_through_link and then updates the link capacity. After the list has been processed, the system checks for any unmet needs. If so, the allocate_bandwidth process is called to try an incremental bandwidth allocation. Note that if a link capacity stays the same or increases, the process does not have to deallocate; however, the system may possibly cover some prior unmet need when performing arbitration.
(X) Handhabung von Knoten und Link-Up/Down-Ereignissen (X) handling of nodes and link up / down events
Hier wird die per Benachrichtigung empfangene Liste von Ereignissen als eine Eingabe in den Prozess behandelt. Die Ausgabe kann als wahr/falsch behandelt werden. Die Ausgabe ist wahr, wenn es Zuteilungsänderungen gibt, anderenfalls ist sie falsch. Hier ist die Annahme, dass die Liste der Änderungen nie dieselbe Entität (Link/Knoten) zweimal enthält. Die Reihenfolge der Verarbeitung von Ereignissen dürfte gleichgültig sein. Das System verwaltet eine Karte von einer Kante zur delta-Kapazität dieser Kante. Das System verwaltet außerdem einen Satz (P) von Links, für die es ein „Link up“-Ereignis oder ein Knoten up-Ereignis für einen seiner Endpunkt-Switches empfangen hat. Here, the list of events received by notification is treated as an input to the process. The output can be treated as true / false. The output is true if there are allotment changes, otherwise it is wrong. Here's the assumption that the list of changes never contains the same entity (link / node) twice. The order of processing events should be indifferent. The system manages a map from one edge to the delta capacity of that edge. The system also manages a set (P) of links for which it has received a "link up" event or a node up event for one of its endpoint switches.
Im Fall eines „Link down“-Ereignisses markiert das System den Link-Zustand als „down“ und merkt sich, dass die Kante, die den Link enthält, nun eine verringerte Kapazität haben sollte. In dieser Situation hat delta einen negativen Betrag der Einzellink-Kapazität. In the case of a "link down" event, the system marks the link state as "down" and notices that the edge containing the link should now have a reduced capacity. In this situation, delta has a negative amount of single link capacity.
Im Fall eines „Knoten down“(Switch down)-Ereignisses wird es für jeden Eintritts- oder Austrittslink, der den Knoten berührt, wenn der Link immer noch nutzbar, als ein Link down-Ereignis verarbeitet, wie oben besprochen. In the case of a "node down" event, for any ingress or egress link that touches the node, if the link is still usable, it will be processed as a link down event, as discussed above.
Im Fall eines „Link up“-Ereignisses fügt das System den Link zu dem Satz P hinzu. In the case of a "link up" event, the system adds the link to the set P.
Und im Fall eines „Knoten up“-Ereignisses fügt der Prozess für jeden Eintritts- oder Austrittslink, der den Knoten berührt, den Link zu dem Satz P hinzu. Nachdem alle Ereignisse verarbeitet wurden, wertet der Prozess den Satz P aus. Für jeden Link in P merkt sich der Prozess, wenn der Link nutzbar ist, dass die Kante, die den Link enthält, nun eine erhöhte Kapazität haben sollte, wobei delta einen positiven Betrag der Einzellink-Kapazität hat. And in the case of a "node up" event, for each entry or exit link that contacts the node, the process adds the link to the set P. After all events have been processed, the process evaluates the set P. For each link in P, if the link is usable, the process remembers that the edge containing the link should now have increased capacity, where delta has a positive amount of single-link capacity.
Der Grund für das Vorhandensein des Satzes Ρ ist, dass zum Beispiel ein „Knoten up“-Ereignis nicht unbedingt bedeutet, dass das System die Links, die diesen Knoten berühren, nutzen kann, weil der Link oder sein Switch am anderen End „down“ sein können. Mit dem oben beschriebenen Prozess erhöht das erste Ereignis, das den Link „nutzbar“ macht, die Kapazität der Kante. Mittels einer Liste von Kanten und ihren delta-Kapazitäten aktiviert das System den oben beschriebenen Kantenkapazitätenaktualisierungsprozess (capacities_update_delta). Wenn irgendeine Zuteilung geändert wurde, so gibt der Prozess die neue Zuteilungskarte aus. The reason for the existence of the sentence Ρ is that, for example, a "node up" event does not necessarily mean that the system can use the links that touch that node because the link or its switch "down" at the other end. could be. With the process described above, the first increases Event that makes the link "usable", the capacity of the edge. Using a list of edges and their delta capacities, the system activates the edge capacity update process described above (capacities_update_delta). If any allocation has been changed, the process issues the new allocation card.
Die oben beschriebenen Prozesse und Operationen können durch eine Verarbeitungsvorrichtung, wie zum Beispiel eine Vorrichtung
Die Anweisungen
Daten
Der eine oder die mehreren Prozessoren
Die obige Beschreibung der Ausführungsformen ist in einem veranschaulichenden Sinn zu verstehen, der die Offenbarung, die allein durch die Ansprüche definiert wird, nicht einschränkt. Es versteht sich des Weiteren, dass die Darstellung von Beispielen der Offenbarung (sowie Sätze, die Wendungen wie „wie zum Beispiel“, „beispielsweise“, „einschließlich“ und dergleichen enthalten) nicht in einem Sinne verstanden werden dürfen, der die Offenbarung auf die konkreten Beispiele beschränkt; vielmehr dienen die Beispiele lediglich zur Veranschaulichung einiger von vielen möglichen Ausführungsformen. The above description of the embodiments is to be taken in an illustrative sense that does not limit the disclosure, which is defined solely by the claims. It should also be understood that the illustration of examples of the disclosure (as well as phrases containing phrases such as "such as," "for example," "including," and the like) should not be construed in a sense that extends the disclosure to the limited to concrete examples; rather, the examples are merely illustrative of some of many possible embodiments.
Claims (11)
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/139,150 US9397957B2 (en) | 2013-12-23 | 2013-12-23 | Traffic engineering for large scale data center networks |
US14/139,150 | 2013-12-23 |
Publications (1)
Publication Number | Publication Date |
---|---|
DE202014010920U1 true DE202014010920U1 (en) | 2017-01-18 |
Family
ID=52355246
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
DE202014010920.6U Active DE202014010920U1 (en) | 2013-12-23 | 2014-12-22 | Traffic design for large-scale data center networks |
Country Status (8)
Country | Link |
---|---|
US (1) | US9397957B2 (en) |
EP (1) | EP3087721B1 (en) |
JP (1) | JP6275263B2 (en) |
CN (1) | CN106416158B (en) |
BR (1) | BR112016014908B1 (en) |
DE (1) | DE202014010920U1 (en) |
SG (1) | SG11201605073YA (en) |
WO (1) | WO2015100222A2 (en) |
Families Citing this family (8)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20160065449A1 (en) * | 2014-08-29 | 2016-03-03 | Cisco Technology, Inc. | Bandwidth-Weighted Equal Cost Multi-Path Routing |
JP6471066B2 (en) * | 2015-08-10 | 2019-02-13 | 日本電信電話株式会社 | Network management apparatus and address setting method |
US10374956B1 (en) * | 2015-09-25 | 2019-08-06 | Amazon Technologies, Inc. | Managing a hierarchical network |
US9961138B2 (en) * | 2016-02-16 | 2018-05-01 | Justin G. Lelacheur | Fiber-based distributed data center architecture |
CN108574594B (en) * | 2017-03-14 | 2020-04-03 | 华为技术有限公司 | Method and system for transmitting network service |
US20180343191A1 (en) * | 2017-05-25 | 2018-11-29 | Fang Hao | Hop constrained widest path for segment routing |
CN108023839B (en) * | 2017-12-13 | 2023-12-08 | 天津光电通信技术有限公司 | Signal switching equipment applied to Tb/s-level optical network and control system thereof |
CA3205104A1 (en) * | 2021-02-05 | 2022-08-11 | Mcmaster University | Method and system for determining design and segmentation for robust network access security |
Family Cites Families (17)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7499453B2 (en) * | 2000-05-19 | 2009-03-03 | Cisco Technology, Inc. | Apparatus and methods for incorporating bandwidth forecasting and dynamic bandwidth allocation into a broadband communication system |
US7586909B1 (en) * | 2002-03-06 | 2009-09-08 | Agere Systems Inc. | Striping algorithm for switching fabric |
US7483374B2 (en) | 2003-08-05 | 2009-01-27 | Scalent Systems, Inc. | Method and apparatus for achieving dynamic capacity and high availability in multi-stage data networks using adaptive flow-based routing |
US8199654B2 (en) * | 2005-06-21 | 2012-06-12 | Alcatel Lucent | Method and apparatus for providing end-to-end high quality services based on performance characterizations of network conditions |
JP4760628B2 (en) * | 2006-09-07 | 2011-08-31 | 富士通株式会社 | Transmission equipment |
JP4968117B2 (en) * | 2008-03-05 | 2012-07-04 | 富士通株式会社 | Route calculation apparatus and route calculation system |
AU2010328326B2 (en) | 2009-12-07 | 2016-12-01 | Robert Buffone | System and method for website performance optimization and internet traffic processing |
US8477610B2 (en) * | 2010-05-31 | 2013-07-02 | Microsoft Corporation | Applying policies to schedule network bandwidth among virtual machines |
US8553562B2 (en) * | 2010-09-08 | 2013-10-08 | Telefonaktiebolaget L M Ericsson (Publ) | Automated traffic engineering for multi-protocol label switching (MPLS) with link utilization as feedback into the tie-breaking mechanism |
CA2810660C (en) * | 2010-09-09 | 2016-04-26 | Nec Corporation | Computer system and communication method in computer system |
CN102710489B (en) * | 2011-03-28 | 2015-07-29 | 日电（中国）有限公司 | Dynamic shunt dispatching patcher and method |
US8559314B2 (en) * | 2011-08-11 | 2013-10-15 | Telefonaktiebolaget L M Ericsson (Publ) | Implementing OSPF in split-architecture networks |
US20150163148A1 (en) * | 2012-04-23 | 2015-06-11 | Telefonaktiebolaget L M Ericsson (Publ) | Packet Scheduling in a Communication Network |
CN102946443B (en) * | 2012-12-06 | 2015-02-18 | 北京邮电大学 | Multitask scheduling method for realizing large-scale data transmission |
US8982703B2 (en) * | 2012-12-18 | 2015-03-17 | Mellanox Technologies Ltd. | Routing support for lossless data traffic |
CN103036792B (en) * | 2013-01-07 | 2015-05-20 | 北京邮电大学 | Transmitting and scheduling method for maximizing minimal equity multiple data streams |
US20150109934A1 (en) * | 2013-10-23 | 2015-04-23 | Paramasiviah HARSHAVARDHA | Internet protocol routing mehtod and associated architectures |
-
2013
- 2013-12-23 US US14/139,150 patent/US9397957B2/en active Active
-
2014
- 2014-12-22 JP JP2016542157A patent/JP6275263B2/en active Active
- 2014-12-22 WO PCT/US2014/071857 patent/WO2015100222A2/en active Application Filing
- 2014-12-22 DE DE202014010920.6U patent/DE202014010920U1/en active Active
- 2014-12-22 BR BR112016014908-4A patent/BR112016014908B1/en active IP Right Grant
- 2014-12-22 CN CN201480070380.4A patent/CN106416158B/en active Active
- 2014-12-22 SG SG11201605073YA patent/SG11201605073YA/en unknown
- 2014-12-22 EP EP14827970.6A patent/EP3087721B1/en active Active
Also Published As
Publication number | Publication date |
---|---|
BR112016014908A2 (en) | 2017-08-08 |
JP6275263B2 (en) | 2018-02-07 |
BR112016014908B1 (en) | 2023-04-11 |
WO2015100222A3 (en) | 2015-10-15 |
US9397957B2 (en) | 2016-07-19 |
SG11201605073YA (en) | 2016-07-28 |
US20150180778A1 (en) | 2015-06-25 |
WO2015100222A2 (en) | 2015-07-02 |
JP2017500816A (en) | 2017-01-05 |
CN106416158A (en) | 2017-02-15 |
CN106416158B (en) | 2019-08-16 |
EP3087721A2 (en) | 2016-11-02 |
EP3087721B1 (en) | 2017-11-08 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
DE202014010920U1 (en) | Traffic design for large-scale data center networks | |
DE60016977T2 (en) | METHOD AND SYSTEM FOR DATA TRANSMISSION THROUGH AN OPTIMIZED DATA PATH IN A NETWORK | |
DE102012221059B4 (en) | Method and system of customizable network transmission optimization in large parallel computing systems | |
DE112012006642B4 (en) | Bandwidth guarantee and work preservation | |
DE112020002493T5 (en) | FAT-TREE ADAPTIVE ROUTING | |
DE102018214776A1 (en) | Technologies for the management of network statistics counters | |
DE102007011143A1 (en) | A method of optimizing the routing of requests in a network | |
DE102015102871B4 (en) | Distributed routing table lookup technologies | |
DE602004011890T2 (en) | Method for redistributing objects to arithmetic units | |
DE112017003703T5 (en) | Technologies for managing the allocation of accelerator resources | |
DE602004005785T2 (en) | Dynamic routing in a content-based distributed network | |
DE112013001426B4 (en) | Dynamic optimization of a multicast tree hierarchy for a distributed switch | |
DE202015009259U1 (en) | PREFIX-ORIENTED REDUCTION OF MULTIPATH GROUPS BY WEIGHTED COST | |
DE60302045T2 (en) | Method and system for the ordered dynamic distribution of packet flows between network processors | |
DE112013000752T5 (en) | Manage processing elements in a streaming data system | |
DE112012005030T5 (en) | Dynamically configurable placement engine | |
DE102009053578A1 (en) | Method and apparatus for performing parallel routing using a multithreaded routing procedure | |
DE102020110143A1 (en) | LOCATION-BASED VIRTUALIZATION WORKLOAD PLACEMENT | |
DE112017001800T5 (en) | TECHNOLOGIES FOR DYNAMIC WORKING QUALITY MANAGEMENT | |
DE102018204577A1 (en) | Techniques to meet quality of service requirements for a fabric point-to-point connection | |
DE60222233T2 (en) | Processor and method for maintaining the processing order of packets based on packet stream identifiers | |
DE112011100714T5 (en) | Computer system, procedure and program | |
DE112011101822T5 (en) | A switching connection unit for routing data, computer connection network and routing method with this unit | |
DE202015009265U1 (en) | UNIFORM API FOR PROGRAMMING BOTH SERVER AND FABRIC FOR FEIN OPTIMIZATION OF NETWORKS | |
DE112022000463T5 (en) | MANAGING A DISTRIBUTED CACHE |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
R207 | Utility model specification | ||
R150 | Utility model maintained after payment of first maintenance fee after three years | ||
R081 | Change of applicant/patentee |
Owner name: GOOGLE LLC (N.D.GES.D. STAATES DELAWARE), MOUN, USFree format text: FORMER OWNER: GOOGLE INC., MOUNTAIN VIEW, CALIF., US |
|
R082 | Change of representative |
Representative=s name: MAIKOWSKI & NINNEMANN PATENTANWAELTE PARTNERSC, DE |
|
R151 | Utility model maintained after payment of second maintenance fee after six years | ||
R152 | Utility model maintained after payment of third maintenance fee after eight years |