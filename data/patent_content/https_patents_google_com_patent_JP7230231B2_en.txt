JP7230231B2 - Robust model performance across heterogeneous subgroups within the same group - Google Patents
Robust model performance across heterogeneous subgroups within the same group Download PDFInfo
- Publication number
- JP7230231B2 JP7230231B2 JP2021553092A JP2021553092A JP7230231B2 JP 7230231 B2 JP7230231 B2 JP 7230231B2 JP 2021553092 A JP2021553092 A JP 2021553092A JP 2021553092 A JP2021553092 A JP 2021553092A JP 7230231 B2 JP7230231 B2 JP 7230231B2
- Authority
- JP
- Japan
- Prior art keywords
- term
- loss
- users
- loss function
- user
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
- 238000009826 distribution Methods 0.000 claims description 57
- 238000000034 method Methods 0.000 claims description 48
- 238000012549 training Methods 0.000 claims description 36
- 238000010606 normalization Methods 0.000 claims description 34
- 238000012545 processing Methods 0.000 claims description 19
- 230000001143 conditioned effect Effects 0.000 claims description 5
- 238000010801 machine learning Methods 0.000 description 66
- 230000006870 function Effects 0.000 description 56
- 230000008569 process Effects 0.000 description 23
- 230000004044 response Effects 0.000 description 14
- 238000004590 computer program Methods 0.000 description 13
- 238000010586 diagram Methods 0.000 description 8
- 238000013515 script Methods 0.000 description 8
- 239000002537 cosmetic Substances 0.000 description 7
- 230000009471 action Effects 0.000 description 6
- 238000004891 communication Methods 0.000 description 6
- 235000014510 cooky Nutrition 0.000 description 6
- 230000003993 interaction Effects 0.000 description 6
- 230000005540 biological transmission Effects 0.000 description 5
- 239000006071 cream Substances 0.000 description 4
- 230000000694 effects Effects 0.000 description 4
- 230000000007 visual effect Effects 0.000 description 4
- 230000003287 optical effect Effects 0.000 description 3
- 230000000644 propagated effect Effects 0.000 description 3
- 238000003491 array Methods 0.000 description 2
- 238000013528 artificial neural network Methods 0.000 description 2
- 230000008859 change Effects 0.000 description 2
- 230000001934 delay Effects 0.000 description 2
- 238000010295 mobile communication Methods 0.000 description 2
- 238000007637 random forest analysis Methods 0.000 description 2
- 238000000926 separation method Methods 0.000 description 2
- 238000012706 support-vector machine Methods 0.000 description 2
- 241000476256 Eleutherodactylus cooki Species 0.000 description 1
- 230000002411 adverse Effects 0.000 description 1
- 238000004458 analytical method Methods 0.000 description 1
- 230000006399 behavior Effects 0.000 description 1
- 230000015556 catabolic process Effects 0.000 description 1
- 239000002131 composite material Substances 0.000 description 1
- 230000001010 compromised effect Effects 0.000 description 1
- 238000007796 conventional method Methods 0.000 description 1
- 230000009193 crawling Effects 0.000 description 1
- 238000006731 degradation reaction Methods 0.000 description 1
- 238000011156 evaluation Methods 0.000 description 1
- 238000012854 evaluation process Methods 0.000 description 1
- 238000009472 formulation Methods 0.000 description 1
- 238000010413 gardening Methods 0.000 description 1
- 239000004973 liquid crystal related substance Substances 0.000 description 1
- 238000007726 management method Methods 0.000 description 1
- 239000011159 matrix material Substances 0.000 description 1
- 239000000203 mixture Substances 0.000 description 1
- 238000005457 optimization Methods 0.000 description 1
- 230000001737 promoting effect Effects 0.000 description 1
- 230000009467 reduction Effects 0.000 description 1
- 238000005070 sampling Methods 0.000 description 1
- 239000004065 semiconductor Substances 0.000 description 1
- 230000001953 sensory effect Effects 0.000 description 1
- 238000011524 similarity measure Methods 0.000 description 1
- 230000003068 static effect Effects 0.000 description 1
- 239000000758 substrate Substances 0.000 description 1
- 238000012546 transfer Methods 0.000 description 1
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/045—Combinations of networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/953—Querying, e.g. by the use of web search engines
- G06F16/9535—Search customisation based on user profiles and personalisation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/084—Backpropagation, e.g. using gradient descent
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q30/00—Commerce
- G06Q30/02—Marketing; Price estimation or determination; Fundraising
- G06Q30/0241—Advertisements
- G06Q30/0251—Targeted advertisements
- G06Q30/0269—Targeted advertisements based on user profile or attribute
Description
本明細書は、データ処理および機械学習モデルに関する。 This specification relates to data processing and machine learning models.
クライアントデバイスは、コンテンツプラットフォーム(たとえば、検索プラットフォーム、ソーシャルメディアプラットフォーム、またはコンテンツをホストする別のプラットフォーム)にアクセスするためにアプリケーション(たとえば、ウェブブラウザ、ネイティブアプリケーション)を使用することができる。コンテンツプラットフォームは、クライアントデバイス上で起動されたアプリケーション内で、1つまたは複数のコンテンツソース/コンテンツプラットフォームによって提供され得るデジタルコンポーネント(たとえば、ビデオクリップ、オーディオクリップ、マルチメディアクリップ、画像、テキスト、または別の単位のコンテンツなどの、個別単位のデジタルコンテンツまたはデジタル情報)を表示することができる。 A client device can use an application (eg, web browser, native application) to access a content platform (eg, a search platform, social media platform, or another platform that hosts content). A content platform is a digital component (e.g., video clip, audio clip, multimedia clip, image, text, or other Discrete units of digital content or digital information) can be displayed, such as units of content.
一般に、本明細書で説明される主題の1つの革新的な態様は、訓練されるべきモデルについて、モデルが訓練中に最適化しようとする性能の尺度を表す損失を生成する損失関数を識別する動作と、すべてが同じユーザグループ識別子によって表されるユーザの異なるサブグループ間での性能の尺度の差を低減する追加項を損失関数に追加することを含む、損失関数を変更する動作であって、ユーザの異なるサブグループの中の各ユーザサブグループが、ユーザの異なるサブグループの中の他のサブグループの特性とは異なる特性を有する、動作と、変更された損失関数を使用してモデルを訓練する動作と、デジタルコンポーネントを求める要求をクライアントデバイスから受信する動作であって、要求が、ユーザの異なるグループの中の特定のユーザグループのための所与のユーザグループ識別子を含む、動作と、訓練されたモデルを要求に含まれる情報に適用することによって、要求に含まれていない1つまたは複数のユーザ特性を生成する動作と、訓練されたモデルによって生成された1つまたは複数のユーザ特性に基づいて1つまたは複数のデジタルコンポーネントを選択する動作と、選択された1つまたは複数のデジタルコンポーネントをクライアントデバイスに伝送する動作とを含む方法において具現化され得る。 In general, one innovative aspect of the subject matter described herein identifies, for a model to be trained, a loss function that produces a loss representing a measure of performance that the model seeks to optimize during training. and adding additional terms to the loss function that reduce differences in performance measures between different subgroups of users all represented by the same user group identifier, , the behavior in which each user subgroup within a different subgroup of users has different properties from the properties of other subgroups within a different subgroup of users, and the model using a modified loss function an act of training and an act of receiving a request for the digital component from the client device, the request including a given user group identifier for a particular user group among different groups of users; The action of applying a trained model to information contained in a request to generate one or more user characteristics not contained in the request and one or more user characteristics generated by the trained model and transmitting the selected one or more digital components to a client device.
この態様の他の実装形態は、コンピュータ記憶デバイス上で符号化された方法の態様を実施するように構成された、対応する装置、システム、およびコンピュータプログラムを含む。これらの実装形態および他の実装形態はそれぞれ、以下の特徴のうちの1つまたは複数を任意選択で含むことができる。 Other implementations of this aspect include corresponding apparatus, systems, and computer programs configured to carry out aspects of the method encoded on computer storage devices. These and other implementations can each optionally include one or more of the following features.
いくつかの態様では、損失関数を変更することは、エラー正規化項を損失関数に追加することを含む。いくつかの態様では、損失関数を変更することは、ダイバージェンス最小化項を損失関数に追加することを含む。 In some aspects, modifying the loss function includes adding an error normalization term to the loss function. In some aspects, modifying the loss function includes adding a divergence minimization term to the loss function.
いくつかの態様では、エラー正規化項を損失関数に追加することは、損失変動項を損失関数に追加することを含み、損失変動項は、何らかの属性に基づいたユーザグループ内のモデルの平均損失とすべてのユーザ間でのモデルの平均損失との間の二乗差を特徴づけ、この差は、異なる属性に基づいてユーザ間で別々に計算され得る。 In some aspects, adding an error normalization term to the loss function includes adding a loss variation term to the loss function, the loss variation term being the average loss of the model within the user group based on some attribute. and the average loss of the model among all users, this difference can be calculated separately among users based on different attributes.
いくつかの態様では、エラー正規化項を損失関数に追加することは、最大加重損失誤差項を損失関数に追加することを含み、最大加重損失誤差項は、ユーザグループにおける損失とすべてのユーザの異なるグループ中のすべてのユーザにおける損失との間の最大加重差であり、方法は、各ユーザグループの重要性を定量化する関数を使用することをさらに含む。 In some aspects, adding the error normalization term to the loss function includes adding a maximum weighted loss error term to the loss function, where the maximum weighted loss error term is the sum of the loss in the user group and the sum of all users. The method further includes using a function that quantifies the importance of each user group.
いくつかの態様では、エラー正規化項を損失関数に追加することは、粗損失変動項を損失関数に追加することを含み、粗損失変動項は、別個のユーザ属性を条件とする、第1のユーザグループの損失と第2のユーザグループの損失との間の二乗差の平均である。 In some aspects, adding the error normalization term to the loss function includes adding a coarse loss variation term to the loss function, the coarse loss variation term being conditioned on a distinct user attribute, the first is the average of the squared differences between the loss of a user group of 1 and the loss of a second user group.
いくつかの態様では、エラー正規化項を損失関数に追加することは、HSIC正規化項を損失関数に追加することを含み、HSIC項は、ノンパラメトリックな方法での、ユーザの異なるグループ中のユーザの分布とは無関係の、ユーザの異なるグループ間での損失の差を特徴づける。 In some aspects, adding an error normalization term to the loss function includes adding an HSIC normalization term to the loss function, the HSIC term varying among different groups of users in a nonparametric manner. Characterize the difference in loss between different groups of users, independent of user distribution.
いくつかの態様では、ダイバージェンス最小化項を損失関数に追加することは、相互情報量項またはカルバック-ライブラーダイバージェンス項のうちの1つを損失関数に追加することを含み、相互情報量項は、ユーザの複数のグループ間でのモデル予測の分布の類似度を特徴づけ、カルバック-ライブラーダイバージェンス項は、ユーザの複数のグループ間でのモデル予測の分布の差を特徴づける。 In some aspects, adding the divergence minimizing term to the loss function includes adding one of a mutual information term or a Kullback-Leibler divergence term to the loss function, wherein the mutual information term is , characterizes the similarity of the distribution of model predictions among groups of users, and the Kullback-Leibler divergence term characterizes the difference in distributions of model predictions among groups of users.
本明細書で説明される主題の特定の実施形態は、以下の利点のうちの1つまたは複数を実現するために実装され得る。機械学習モデルは、ユーザから特定の情報を収集する代わりに、たとえば第三者クッキーを介してユーザ特性を予測するように訓練され得、それによって、ユーザのプライバシーに対する懸念に配慮する。しかしながら、そのような方法を実装することは、現実世界のユーザから獲得された不平衡なデータセットに対して機械学習モデルを訓練することを必要とし、その結果として、より低い頻度で観測されるサブグループと比較して、より高い頻度で観測されるサブグループがモデルのパラメータに対してより高い影響を与えることをもたらす。これは、サブグループ間でのモデル性能にかなりの変動をもたらす可能性がある。機械学習モデルの損失関数を変更することは、機械学習モデルが訓練データセットの複雑なパターンを学習し、それらのパターンを区別することを可能にし、それによって、ユーザ特性に関する予測におけるエラーを低減し、サブグループ間での機械学習モデルの予測精度の一貫性を高める。そのような実装形態は、予測されたユーザ特性に基づいて精細に選択されたデジタルコンポーネントをユーザに配信することを可能にし、それによって、ユーザエクスペリエンスを改善し、ユーザプライバシーを維持する。 Particular embodiments of the subject matter described herein may be implemented to achieve one or more of the following advantages. Machine learning models can be trained to predict user characteristics via, for example, third-party cookies instead of collecting specific information from users, thereby respecting user privacy concerns. However, implementing such methods requires training machine learning models on unbalanced datasets acquired from real-world users, resulting in less frequently observed Compared to subgroups, more frequently observed subgroups lead to a higher influence on the parameters of the model. This can lead to considerable variability in model performance between subgroups. Modifying the loss function of the machine learning model enables the machine learning model to learn complex patterns in the training dataset and distinguish between those patterns, thereby reducing errors in predictions about user characteristics. , to increase the consistency of prediction accuracy of machine learning models across subgroups. Such implementations enable delivery of finely-selected digital components to users based on predicted user characteristics, thereby improving user experience and maintaining user privacy.
本明細書で説明される主題の実施形態は、クライアントデバイスとネットワークの残りの部分との間で伝送される潜在的に機密性の高いデータの量を低減することができる。たとえば、ユーザのためのグループ識別子があまり観測されないサブグループを示す場合にクライアントデバイスがデジタルコンポーネントを求める要求を送信する場合、本明細書で説明される方法は、ユーザにサービスされるコンテンツを適切に調整するためにユーザについてのより多くの情報を送信する必要性を回避することができる。クライアントデバイスによって提供されるユーザについての追加のデータの低減は、あまり観測されないサブグループのユーザについての要求を送信するクライアントデバイスに対する帯域幅要件を低減する。そのような低減は、敏感な帯域幅要件と調和している要因(たとえば、ローカルネットワーク接続性が悪い場合、あまり観測されないサブグループはより頻繁に発見され得る)により、あまり観測されないサブグループにとってより重要であり得る。さらに、追加の情報の伝送を回避することによって、あまり観測されないサブグループが第三者による識別から保護され得る。 Embodiments of the subject matter described herein can reduce the amount of potentially sensitive data transmitted between the client device and the rest of the network. For example, if a client device sends a request for a digital component where the group identifier for the user indicates an under-observed subgroup, the methods described herein will appropriately distribute the content served to the user. It can avoid the need to send more information about the user for reconciliation. Reducing the additional data about users provided by the client device reduces the bandwidth requirements for client devices sending requests about less observed subgroups of users. Such a reduction may be higher for less-observed subgroups by factors that are consistent with sensitive bandwidth requirements (e.g., less-observed subgroups may be discovered more frequently if local network connectivity is poor). can be important. Furthermore, by avoiding the transmission of additional information, less observable subgroups can be protected from identification by third parties.
本明細書で説明される主題の1つまたは複数の実施形態の詳細は、添付の図面および以下の説明に記載される。主題の他の特徴、態様、および利点は、説明、図面、および特許請求の範囲から明らかとなろう。 The details of one or more embodiments of the subject matter described in this specification are set forth in the accompanying drawings and the description below. Other features, aspects, and advantages of the subject matter will be apparent from the description, drawings, and claims.
本文書は、機械学習モデルを変更して、同じユーザグループ内のユーザの異なるサブグループ間でのモデル性能ができるだけ変化しないことを保証するために使用される、方法、システム、装置、およびコンピュータ可読媒体を開示する。 This document describes methods, systems, apparatus, and computer readable methods used to modify machine learning models to ensure that model performance varies as little as possible between different subgroups of users within the same user group. Disclose the medium.
一般に、クライアントデバイスを介してインターネットに接続されるユーザには、デジタルコンポーネントが提供され得る。そのようなシナリオでは、デジタルコンポーネントプロバイダは、ユーザのオンラインアクティビティおよびユーザ閲覧履歴に基づいてデジタルコンポーネントを提供することを望むことがある。しかしながら、ますます多くのユーザは一定の情報が収集および使用されることを許可するのをやめるようになっており、第三者クッキーはいくつかのブラウザによってブロックおよび/または拒否されているので、デジタルコンポーネント選択は、第三者クッキー(すなわち、クッキーファイルのコンテンツにアクセスすることが許可されたウェブページのドメインとは異なるドメインからのクッキー)を使用せずに実施されなければならない。 Generally, digital components can be provided to users who are connected to the Internet via client devices. In such scenarios, digital component providers may wish to provide digital components based on the user's online activity and user browsing history. However, more and more users are opting out of allowing certain information to be collected and used, and third-party cookies are blocked and/or rejected by some browsers. Digital component selection must be performed without the use of third party cookies (i.e. cookies from a domain different from the domain of the web page authorized to access the contents of the cookie file).
ユーザが特定のリソースを訪問するかまたはリソースにおいて特定のアクションを実施する(たとえば、ウェブページ上で提示された特定のアイテムと対話するかまたはアイテムを仮想カートに追加する)ときにユーザをユーザグループに割り当てることによってデジタルコンポーネントをユーザに配信する新しい技法が出現している。これらのユーザグループは一般に、個々のユーザが識別され得ないように、各ユーザグループが十分な数のユーザを含むような方式で作成される。ユーザに関する人口統計学的情報は、たとえば、ユーザに関連する特定のデジタルコンポーネントを提供することによって、ユーザに個人化されたオンラインエクスペリエンスを提供するために、依然として重要である。しかしながら、そのような情報の利用不可能性のせいで、そのようなユーザ情報および/またはユーザ特性を予測することができる機械学習モデルが実装され得る。 A user group when a user visits a particular resource or performs a particular action on a resource (for example, interacting with a particular item presented on a web page or adding an item to a virtual cart). New techniques are emerging to deliver digital components to users by assigning them to . These user groups are generally created in such a way that each user group contains a sufficient number of users so that individual users cannot be identified. Demographic information about users remains important, for example, to provide users with a personalized online experience by providing them with specific digital components that are relevant to them. However, due to the unavailability of such information, machine learning models can be implemented that can predict such user information and/or user characteristics.
そのような技法および方法は最先端であるにもかかわらず、不平衡なデータセットのせいで機械学習モデルが非常に損なわれる可能性がある。(訓練データにわたる平均損失を最小化しようとする経験的リスク最小化などの)機械学習モデルを訓練するための標準的な技法は訓練データセットのクラス分布に関してアグノスティックであるので、そのようなデータセットからの学習はモデル性能の低下をもたらす。たとえば、ユーザ属性を予測することを目的とし、不平衡なデータセットに対して訓練された機械学習モデルは、うまく動作せず、ユーザの真の属性とモデルの予測との間の相当数の不一致をもたらすことがある。 Despite the state-of-the-art of such techniques and methods, machine learning models can be severely compromised due to unbalanced datasets. Such data Learning from a set leads to model performance degradation. For example, machine learning models aimed at predicting user attributes and trained on unbalanced datasets perform poorly, with significant discrepancies between the user's true attributes and the model's predictions. can result in
対照的に、本文書で説明される技法および方法は、ユーザ特性を予測する際に高精度を達成し、それによって、機械学習モデルの出力を使用してユーザのための関連するデジタルコンポーネントの選択を可能にする方法で損失関数を変更することによって、従来の技法よりも優れている。より具体的には、訓練されるべき機械学習モデルの損失関数は、ユーザの異なるサブグループの各々がユーザグループ内のユーザの異なるサブグループの中のユーザの他のサブグループの特性とは異なる特性を有するという事実にもかかわらず、すべてが同じユーザグループ識別子によって表される(すなわち、すべてがより大きい同じユーザのグループに含まれる)ユーザの異なるサブグループおよび/またはサブセット内のまたはそれらの間での性能の尺度の差を低減する追加項を含めるように変更される。この追加項は、ユーザの異なるサブグループ間でのモデルの性能のロバストネスを保証する。技法および方法は、図1～図4を参照しながらさらに説明される。 In contrast, the techniques and methods described in this document achieve high accuracy in predicting user characteristics, thereby using the output of machine learning models to select relevant digital components for users. It outperforms conventional techniques by modifying the loss function in a way that allows More specifically, the loss function of the machine learning model to be trained is such that each different subgroup of users has different characteristics from the characteristics of other subgroups of users within the different subgroups of users within the usergroup. within or among different subgroups and/or subsets of users all represented by the same user group identifier (i.e. all included in the same larger group of users), despite the fact that they have is modified to include an additional term that reduces the difference in the performance measures of This additional term ensures the robustness of the model's performance among different subgroups of users. The techniques and methods are further described with reference to FIGS. 1-4.
図1は、電子文書とともに提示するためにデジタルコンポーネントが配信される例示的な環境100のブロック図である。例示的な環境100は、ローカルエリアネットワーク(LAN)、ワイドエリアネットワーク(WAN)、インターネット、またはそれらの組合せなどの、ネットワーク102を含む。ネットワーク102は、コンテンツサーバ104、クライアントデバイス106、デジタルコンポーネントサーバ108、およびデジタルコンポーネント配信システム110(コンポーネント配信システム(CDS)とも呼ばれる)を接続する。
FIG. 1 is a block diagram of an
クライアントデバイス106は、ネットワーク102を介してリソースを要求および受信することが可能な電子デバイスである。例示的なクライアントデバイス106は、パーソナルコンピュータ、モバイル通信デバイス、ウェアラブルデバイス、携帯情報端末、およびネットワーク102を介してデータを送信および受信することができる他のデバイスを含む。クライアントデバイス106は、典型的には、ネットワーク102を介したデータの送信および受信を容易にするためにウェブブラウザなどのユーザアプリケーション107を含むが、クライアントデバイス106によって実行されるネイティブアプリケーションも、ネットワーク102を介したデータの送信および受信を容易にすることができる。クライアントデバイス106、具体的には、携帯情報端末は、クライアントデバイス106との音声対話を可能にするハードウェアおよび/またはソフトウェアを含むことができる。たとえば、クライアントデバイス106は、それを通じてユーザがコマンド、検索クエリ、閲覧命令、スマートホーム命令、および/または他の情報などのオーディオ(たとえば、音声)入力をサブミットすることができるマイクロフォンを含むことができる。加えて、クライアントデバイス106は、それを通じてユーザがオーディオ(たとえば、音声)出力を提供され得るスピーカを含むことができる。携帯情報端末は、例としては、ウェアラブル、スマートスピーカ、ホームアプライアンス、車、タブレットデバイス、または他のクライアントデバイス106を含む、任意のクライアントデバイス106において実装され得る。
電子文書は、クライアントデバイス106においてコンテンツのセットを提示するデータである。電子文書の例は、ウェブページ、ワード処理文書、ポータブルドキュメントフォーマット(PDF)文書、画像、ビデオ、検索結果ページ、およびフィードソースを含む。モバイル、タブレット、またはデスクトップコンピューティングデバイス上にインストールされたアプリケーションなどのネイティブアプリケーション(たとえば、「アプリ」)も、電子文書の例である。電子文書は、コンテンツサーバ104によってクライアントデバイス106に提供され得る。たとえば、コンテンツサーバ104は、発行者ウェブサイトをホストするサーバを含むことができる。この例では、クライアントデバイス106は、所与の発行者ウェブページを求める要求を開始することができ、所与の発行者ウェブページをホストするコンテンツサーバ104は、クライアントデバイス106において所与のウェブページの提示を開始する機械実行可能命令を送信することによって、その要求に応答することができる。
An electronic document is data that presents a set of content on
別の例では、コンテンツサーバ104は、そこからクライアントデバイス106がアプリをダウンロードすることができるアプリサーバを含むことができる。この例では、クライアントデバイス106は、クライアントデバイス106においてアプリをインストールするために必要とされるファイルをダウンロードし、次いで、ダウンロードされたアプリをローカルで実行することができる。ダウンロードされたアプリは、アプリケーション自体の一部であるネイティブコンテンツ、ならびに、アプリがクライアントデバイス106において実行されている間にデジタルコンポーネントサーバ108から取得され、アプリに挿入される1つまたは複数のデジタルコンポーネント(たとえば、第三者によって作成/配信されたコンテンツ)の組合せを提示するように構成され得る。
In another example,
電子文書は、様々なコンテンツを含むことができる。たとえば、電子文書は、電子文書自体内にあるおよび/または経時的に変化しない、静的なコンテンツ(たとえば、テキストまたは他の指定されたコンテンツ)を含むことができる。電子文書は、経時的にまたは要求に基づいて変化することがある動的なコンテンツも含むことができる。たとえば、所与の電子文書の発行者は、電子文書の部分をポピュレートするために使用されるデータソースを維持することができる。この例では、所与の電子文書は、所与の電子文書がクライアントデバイス106によって処理される(たとえば、レンダリングまたは実行される)ときにデータソースからのコンテンツを要求することをクライアントデバイス106に行わせるタグまたはスクリプトを含むことができる。クライアントデバイス106は、データソースから取得されたコンテンツを含む複合電子文書を作成するために、データソースから取得されたコンテンツを所与の電子文書に組み込む。
Electronic documents can contain a variety of content. For example, an electronic document can contain static content (eg, text or other specified content) that is within the electronic document itself and/or that does not change over time. Electronic documents can also contain dynamic content that can change over time or based on demand. For example, a publisher of a given electronic document may maintain data sources used to populate portions of the electronic document. In this example, a given electronic document instructs
いくつかの状況では、所与の電子文書は、デジタルコンポーネント配信システム110を参照するデジタルコンポーネントタグまたはデジタルコンポーネントスクリプトを含むことができる。これらの状況では、デジタルコンポーネントタグまたはデジタルコンポーネントスクリプトは、所与の電子文書がクライアントデバイス106によって処理されるときにクライアントデバイス106によって実行される。デジタルコンポーネントタグまたはデジタルコンポーネントスクリプトの実行は、ネットワーク102を介してデジタルコンポーネント配信システム110に伝送される、デジタルコンポーネントを求める要求112(「コンポーネント要求」と呼ばれる)を生成するようにクライアントデバイス106を構成する。たとえば、デジタルコンポーネントタグまたはデジタルコンポーネントスクリプトは、クライアントデバイス106がヘッダとペイロードデータとを含むパケット化されたデータ要求を生成することを可能にすることができる。デジタルコンポーネント要求112は、そこからメディアが要求されているサーバの名前(もしくはネットワークロケーション)、要求側デバイス(たとえば、クライアントデバイス106)の名前(もしくはネットワークロケーション)、および/または要求に応答して提供された1つもしくは複数のデジタルコンポーネントを選択するためにデジタルコンポーネント配信システム110が使用することができる情報などの特徴を指定するイベントデータを含むことができる。コンポーネント要求112は、クライアントデバイス106によって、ネットワーク102(たとえば、電気通信ネットワーク)を介してデジタルコンポーネント配信システム110のサーバに伝送される。
In some situations, a given electronic document may include a digital component tag or a digital component script that references the digital
デジタルコンポーネント要求112は、要求されている電子文書、およびデジタルコンポーネントが提示され得る電子文書のロケーションの特性などの、他のイベント特徴を指定するイベントデータを含むことができる。たとえば、デジタルコンポーネントが提示されることになる電子文書(たとえば、ウェブページもしくはアプリケーション)への参照(たとえば、ユニフォームリソースロケータ(URL))を指定するイベントデータ、デジタルコンポーネントを提示するために利用可能な電子文書の利用可能なロケーション、利用可能なロケーションのサイズ、および/またはロケーションにおいて提示するのに適格なメディアタイプが、デジタルコンポーネント配信システム110に提供され得る。同様に、電子文書に関連付けられたキーワード(「文書キーワード」)または電子文書によって参照されるエンティティ(たとえば、人、場所、もしくは物)を指定するイベントデータも、電子文書とともに提示するのに適格なデジタルコンポーネントの識別を容易にするために(たとえば、ペイロードデータとして)コンポーネント要求112に含まれ、デジタルコンポーネント配信システム110に提供され得る。イベントデータは、検索結果ページおよび/または検索結果を指定するデータおよび/または検索結果に含まれるテキストコンテンツ、可聴コンテンツ、もしくは他の視覚コンテンツを取得するためにクライアントデバイス106からサブミットされた検索クエリも含むことができる。
コンポーネント要求112は、クライアントデバイスのユーザが提供した情報、コンポーネント要求がサブミットされた州もしくは地域を示す地理的情報、またはデジタルコンポーネントが表示されることになる環境についてのコンテキストを提供する他の情報(たとえば、コンポーネント要求の時刻、コンポーネント要求の曜日、モバイルデバイスもしくはタブレットデバイスなどの、デジタルコンポーネントが表示されることになるデバイスのタイプ)などの、他の情報に関係するイベントデータも含むことができる。コンポーネント要求112は、たとえば、パケット化されたネットワークを介して伝送され得、コンポーネント要求112自体は、ヘッダとペイロードデータとを有するパケット化されたデータとしてフォーマット化され得る。ヘッダはパケットの宛先を指定することができ、ペイロードデータは上記で論じられた情報のうちのいずれかを含むことができる。
The
1つまたは複数のデジタルコンポーネント配信サーバを含むデジタルコンポーネント配信システム110は、コンポーネント要求112を受信したことおよび/またはコンポーネント要求112に含まれる情報を使用したことに応答して、所与の電子文書とともに提示されることになるデジタルコンポーネントを選ぶ。いくつかの実装形態では、デジタルコンポーネントは、デジタルコンポーネントの選択の遅延によって引き起こされる可能性があるエラーを回避するために1秒未満で選択される。たとえば、コンポーネント要求112に応答してデジタルコンポーネントを提供する際の遅延は、クライアントデバイス106におけるページロードエラーをもたらすか、または、電子文書の部分が、電子文書の他の部分がクライアントデバイス106において提示された後でもポピュレートされないままになる可能性がある。また、デジタルコンポーネントをクライアントデバイス106に提供する際の遅延が増加するにつれて、デジタルコンポーネントがクライアントデバイス106に配信されたときに電子文書がもはやクライアントデバイス106において提示されなくなる可能性が高くなり、それによって、電子文書に関するユーザのエクスペリエンスに悪影響を及ぼす。さらに、デジタルコンポーネントを提供する際の遅延は、たとえば、デジタルコンポーネントが提供されたときに電子文書がもはやクライアントデバイス106において提示されない場合、デジタルコンポーネントの配信の失敗をもたらす可能性がある。
Digital
電子文書の検索を容易にするために、環境100は、電子文書をクロールしインデックス付けする(たとえば、電子文書のクロールされたコンテンツに基づいてインデックス付けされる)ことによって電子文書を識別する検索システム150を含むことができる。電子文書についてのデータは、データが関連付けられる電子文書に基づいてインデックス付けされ得る。電子文書のインデックス付けされ、任意選択でキャッシュされたコピーは、検索インデックス152(たとえば、ハードウェアメモリデバイス)に記憶される。電子文書に関連付けられたデータは、電子文書に含まれるコンテンツを表すデータおよび/または電子文書についてのメタデータである。
To facilitate searching of electronic documents,
クライアントデバイス106は、検索クエリを検索システム150にネットワーク102を介してサブミットすることができる。それに応答して、検索システム150は、検索クエリに関連する電子文書を識別するために検索インデックス152にアクセスする。検索システム150は、検索結果の形態で電子文書を識別し、検索結果ページにおいて検索結果をクライアントデバイス106に返す。検索結果は、特定の検索クエリに応答する(たとえば、関連する)電子文書を識別する検索システム150によって生成されたデータであり、検索結果とのユーザ対話に応答して指定されたロケーションからのデータを要求することをクライアントデバイスに行わせるアクティブリンク(たとえば、ハイパーテキストリンク)を含む。例示的な検索結果は、ウェブページタイトル、ウェブページから抽出されたテキストのスニペットまたは画像の一部分、およびウェブページのURLを含むことができる。別の例示的な検索結果は、ダウンロード可能なアプリケーションのタイトル、ダウンロード可能なアプリケーションを記述するテキストのスニペット、ダウンロード可能なアプリケーションのユーザインターフェースを図示する画像、および/またはそこからアプリケーションがクライアントデバイス106にダウンロードされ得るロケーションへのURLを含むことができる。別の例示的な検索結果は、ストリーミングメディアのタイトル、ストリーミングメディアを記述するテキストのスニペット、ストリーミングメディアのコンテンツを図示する画像、および/またはそこからストリーミングメディアがクライアントデバイス106にダウンロードされ得るロケーションへのURLを含むことができる。他の電子文書と同様に、検索結果ページは、デジタルコンポーネント(たとえば、広告、ビデオクリップ、オーディオクリップ、画像、または他のデジタルコンポーネント)が提示され得る1つまたは複数のスロットを含むことができる。
いくつかの実装形態では、デジタルコンポーネント配信システム110は、たとえば、サーバと、相互接続され、コンポーネント要求112に応答してデジタルコンポーネントを識別および配信する複数のコンピューティングデバイスのセット114とを含む、分散コンピューティングシステムにおいて実装される。複数のコンピューティングデバイスのセット114は、電子文書において提示されるのに適格なデジタルコンポーネントのセットを場合によっては数百万の利用可能なデジタルコンポーネントのコーパスの中から識別するために一緒に動作する。
In some implementations, the digital
いくつかの実装形態では、デジタルコンポーネント配信システム110は、デジタルコンポーネントを選択および配信するための異なる技法を実装する。たとえば、デジタルコンポーネントは、対応するデジタルコンポーネントの選択/配信/伝送に寄与する(たとえば、条件付けるまたは制限する)対応する配信パラメータを含むことができる。たとえば、配信パラメータは、コンポーネント要求がデジタルコンポーネントの配信パラメータのうちの1つと(たとえば、正確にまたは何らかの事前指定されたレベルの類似度でのいずれかで)一致する少なくとも1つの基準を含むことを必要とすることによって、デジタルコンポーネントの伝送に寄与することができる。
In some implementations, digital
別の例では、特定のデジタルコンポーネントのための配信パラメータは、デジタルコンポーネントが提示に適格なものとなるために、(たとえば、電子文書、文書キーワード、またはコンポーネント要求112において指定される条項によって)一致させなければならない配信キーワードを含むことができる。配信パラメータは、コンポーネント要求112が特定の地理的領域(たとえば、国もしくは州)を指定する情報および/またはコンポーネントアイテムが提示に適格なものとなるためにコンポーネント要求112が特定のタイプのクライアントデバイス106(たとえば、モバイルデバイスもしくはタブレットデバイス)において発信したことを指定する情報を含むことを必要とすることもできる。配信パラメータは、以下でより詳細に論じられるように、(たとえば、他の利用可能なデジタルコンポーネントの中から)選択/配信/伝送のためのコンポーネントアイテムの適格性を評価するために使用される適格性値(たとえば、ランク、スコアまたは何らかの他の指定された値)を指定することもできる。いくつかの状況では、適格性値は、特定のイベントがデジタルコンポーネントアイテムに起因する(たとえば、デジタルコンポーネントの提示)ときにサブミットされることになる量に基づき得る。
In another example, delivery parameters for a particular digital component must be matched (e.g., by electronic document, document keywords, or terms specified in component request 112) in order for the digital component to be eligible for presentation. It can contain delivery keywords that must be allowed. The delivery parameters may include information specifying that the
適格なデジタルコンポーネントの識別は、複数のタスク117a～117cにセグメント化され得、次いで、複数のタスク117a～117cは、複数のコンピューティングデバイスのセット114内のコンピューティングデバイスの間で割り当てられる。たとえば、セット114の中の異なるコンピューティングデバイスはそれぞれ、コンポーネント要求112に含まれる情報と一致する配信パラメータを有する様々なデジタルコンポーネントを識別するために、異なるデジタルコンポーネントを分析することができる。いくつかの実装形態では、セット114の中の所与の各コンピューティングデバイスは、異なるデータ次元(または次元のセット)を分析し、分析の結果(Res 1～Res 3)118a～118cをデジタルコンポーネント配信システム110に戻す(たとえば、伝送する)ことができる。たとえば、セット114の中のコンピューティングデバイスの各々によって提供される結果118a～118cは、コンポーネント要求および/または一定の配信パラメータを有するデジタルコンポーネントのサブセットに応答して、配信に適格なデジタルコンポーネントアイテムのサブセットを識別し得る。デジタルコンポーネントのサブセットの識別は、たとえば、イベントデータを配信パラメータと比較すること、およびイベントデータの少なくともいくつかの特徴と一致する配信パラメータを有するデジタルコンポーネントのサブセットを識別することを含むことができる。
The identification of eligible digital components may be segmented into
デジタルコンポーネント配信システム110は、複数のコンピューティングデバイスのセット114から受信された結果118a～118cをアグリゲートし、アグリゲートされた結果に関連付けられた情報を使用して、コンポーネント要求112に応答して提供されることになる1つまたは複数のデジタルコンポーネントを選択する。たとえば、デジタルコンポーネント配信システム110は、1つまたは複数のデジタルコンポーネント評価プロセスの成果に基づいて勝利デジタルコンポーネントのセット(1つまたは複数のデジタルコンポーネント)を選択することができる。次に、デジタルコンポーネント配信システム110は、クライアントデバイス106が勝利デジタルコンポーネントのセットを所与の電子文書に組み込むことを可能にする応答データ120(たとえば、応答を表すデジタルデータ)を生成し、ネットワーク102を介して伝送することができ、その結果として、勝利デジタルコンポーネントのセットおよび電子文書のコンテンツがクライアントデバイス106のディスプレイにおいて一緒に提示される。
Digital
いくつかの実装形態では、クライアントデバイス106は応答データ120に含まれる命令を実行し、応答データ120はクライアントデバイス106を構成し、クライアントデバイス106が1つまたは複数のデジタルコンポーネントサーバ108から勝利デジタルコンポーネントのセットを取得することを可能にする。たとえば、応答データ120の中の命令は、ネットワークロケーション(たとえば、URL)と、デジタルコンポーネントサーバ108から所与の勝利デジタルコンポーネントを取得するためにサーバ要求(SR)121をデジタルコンポーネントサーバ108に伝送することをクライアントデバイス106に行わせるスクリプトとを含むことができる。サーバ要求121に応答して、デジタルコンポーネントサーバ108は、サーバ要求121において指定された所与の勝利デジタルコンポーネントを識別し、クライアントデバイス106において電子文書の中の所与の勝利デジタルコンポーネントを提示するデジタルコンポーネントデータ122(DIデータ)をクライアントデバイス106に伝送する。
In some implementations,
いくつかの実装形態では、デジタルコンポーネント配信のための配信パラメータは、人口統計学的情報、ユーザの興味、および/またはユーザのオンラインエクスペリエンスを個人化するために使用され得る他の情報などのユーザ特性を含み得る。いくつかの状況では、これらの特性および/またはクライアントデバイス106のユーザに関する情報は容易に利用可能である。たとえば、コンテンツサーバ104または検索システム150などのコンテンツプラットフォームは、ユーザがそのようなユーザ情報を提供することによってコンテンツプラットフォームに登録することを可能にし得る。別の例では、コンテンツプラットフォームは、クライアントデバイスを識別するためにクッキーを使用することができ、クッキーは、ユーザのオンラインアクティビティおよび/またはユーザ特性についての情報を記憶することができる。
In some implementations, delivery parameters for digital component delivery are user characteristics such as demographic information, user interests, and/or other information that can be used to personalize a user's online experience. can include In some situations, information about these characteristics and/or the user of
ユーザ特性を識別するこれらの方法および他の方法は、ユーザプライバシーを保護するために、あまり見られなくなりつつある。ユーザプライバシーを保護するために、ユーザは、単一の閲覧セッション中にユーザによってアクセスされたデジタルコンテンツに基づいて1つまたは複数のユーザグループに割り当てられ得る。たとえば、ユーザが特定のウェブサイトを訪問し、ウェブサイト上で提示された特定のアイテムと対話するか、またはアイテムを仮想カートに追加するとき、ユーザは、同じウェブサイトもしくはコンテキスト的に類似している他のウェブサイトを訪問したまたは同じアイテムに興味があるユーザのグループに割り当てられ得る。たとえば、クライアントデバイス106のユーザが靴を検索し、異なる靴メーカーの複数のウェブページを訪問する場合、ユーザは、靴に関係するウェブサイトを訪問したすべてのユーザのための識別子を含むことができるユーザグループ「靴」に割り当てられ得る。したがって、ユーザグループは、個々のユーザを識別することなしに、かつ任意の個々のユーザが識別されることを可能にすることなしに、アグリゲートの中のユーザの興味を表すことができる。たとえば、ユーザグループは、グループの中のあらゆるユーザのために使用されるユーザグループ識別子によって識別され得る。一例として、ユーザが靴をオンライン小売業者のショッピングカートに追加する場合、ユーザは特定の識別子を有する靴ユーザグループに追加され得、この識別子はそのグループの中のあらゆるユーザに割り当てられる。
These and other methods of identifying user characteristics are becoming less popular in order to protect user privacy. To protect user privacy, users may be assigned to one or more user groups based on the digital content accessed by the user during a single browsing session. For example, when a user visits a particular website, interacts with a particular item presented on the website, or adds an item to a virtual cart, the user may visit the same website or contextually similar can be assigned to a group of users who have visited other websites on the site or are interested in the same item. For example, if a user of
いくつかの実装形態では、ユーザのグループメンバーシップは、デジタルコンポーネントプロバイダによってもしくはコンテンツプラットフォームによって、または別の当事者によってではなく、たとえばブラウザベースのアプリケーションによって、ユーザのクライアントデバイス106において維持され得る。ユーザグループは、それぞれのユーザグループ識別子によって指定され得る。ユーザグループのためのユーザグループ識別子は、グループを記述するもの(たとえば、ガーデニンググループ)またはグループを表すコード(たとえば、記述的ではない英数字シーケンス)であり得る。
In some implementations, a user's group membership may be maintained on the user's
ユーザ特性(たとえば、グループ識別子以外)が利用可能ではない状況では、デジタルコンポーネント配信システム110は、利用可能な情報に基づいてユーザ特性を予測するユーザ評価装置170を含むことができる。いくつかの実装形態では、ユーザ評価装置170は、コンポーネント要求112に含まれる情報(たとえば、グループ識別子)に基づいて1つまたは複数のユーザ特性を予測する1つまたは複数の機械学習モデルを実装する。
In situations where user characteristics (eg, other than group identifiers) are not available, digital
たとえば、クライアントデバイス106のユーザが1つまたは複数のデジタルコンポーネントスロットを含むウェブサイトをロードするためにブラウザベースのアプリケーション107を使用する場合、ブラウザベースのアプリケーション107は、1つまたは複数のデジタルコンポーネントスロットの各々についてコンポーネント要求112を生成し、伝送することができる。コンポーネント要求112は、クライアントデバイス106のための識別子を含むユーザグループに対応するユーザグループ識別子、コンポーネント要求112がサブミットされた州もしくは地域を示す地理的情報などの他の情報、またはデジタルコンポーネントが表示されることになる環境についてのコンテキストを提供する他の情報(たとえば、コンポーネント要求の時刻、コンポーネント要求の曜日、モバイルデバイスもしくはタブレットデバイスなどの、デジタルコンポーネントが表示されることになるクライアントデバイス106のタイプ)を含む。
For example, if a user of
デジタルコンポーネント配信システム110は、コンポーネント要求112を受信した後、コンポーネント要求112に含まれる情報を入力として機械学習モデルに提供する。機械学習モデルは、入力を処理した後、コンポーネント要求112に含まれていなかった1つまたは複数のユーザ特性の予測を含む出力を生成する。これらの1つまたは複数のユーザ特性は、コンポーネント要求に含まれる他の情報とともに、デジタルコンポーネントサーバ108からデジタルコンポーネントをフェッチするために使用され得る。ユーザ特性の予測された出力を生成することは、図2を参照しながらさらに説明される。
After receiving the
図2は、ユーザ評価装置170内で実装される例示的な機械学習モデルのブロック図である。一般に、機械学習モデルは、複数の訓練可能なパラメータを含む、人工ニューラルネットワーク(ANN)、サポートベクターマシン(SVM)、ランダムフォレスト(RF)などの特定の実装形態に適切であると見なされる任意の技法であり得る。訓練プロセス中に、複数の訓練パラメータは、損失関数によって生成されたエラーの尺度に基づいて、訓練データセットの複数のサンプルにわたって繰り返す間に調整される(最適化と呼ばれるプロセス)。損失関数は、モデルが最小化するように訓練されるエラーメトリックを生成するために、機械学習モデルの予測された属性値を訓練セット中のサンプルの真の値と比較する。
FIG. 2 is a block diagram of an exemplary machine learning model implemented within
いくつかの実装形態では、機械学習モデルは、各サブ機械学習モデル(「サブモデル」とも呼ばれる)が特定のユーザ特性(たとえば、ユーザの人口統計学的特性、ユーザの興味、または何らかの他の特性)を予測するように、複数のサブモデルを含み得る。たとえば、ユーザ評価装置170は、3つのサブモデル、すなわち、(i)特性1モデル220、(ii)特性2モデル230、および(iii)特性3モデル240を含む。これらのサブモデルの各々は、ユーザが異なる特性(たとえば、人口統計学的特性またはユーザの興味)を有する尤度を予測する。他の実装形態は、システム(または管理者)が定義した数のユーザ特性を予測するために、より多くのまたはより少ない個々のサブモデルを含み得る。
In some implementations, the machine learning model is configured so that each sub-machine learning model (also called a "sub-model") identifies a particular user characteristic (e.g., user demographic characteristics, user interests, or some other characteristic). ) can include multiple sub-models. For example,
いくつかの実装形態では、機械学習モデルは、コンポーネント要求112に含まれる情報を入力として受け入れることができる。前に述べたように、コンポーネント要求112は、クライアントデバイス106を含むユーザグループに対応するユーザグループ識別子、および/またはコンポーネント要求112がサブミットされた州もしくは地域を示す地理的情報などの他の情報、またはデジタルコンポーネントが表示されることになる環境についてのコンテキストを提供する他の情報(たとえば、コンポーネント要求の時刻、コンポーネント要求の曜日、モバイルデバイスもしくはタブレットデバイスなどの、デジタルコンポーネントが表示されることになるクライアントデバイス106のタイプ)を含むことができる。たとえば、入力205は、コンポーネント要求112に含まれていた情報、すなわち、ユーザグループ識別子(ユーザグループID)202および他の情報204を含む。
In some implementations, the machine learning model can accept information contained in the
いくつかの実装形態では、ユーザ評価装置170内で実装される機械学習モデル(またはサブモデル)は、ユーザの現在のオンラインアクティビティに関係する追加の入力210を受け入れるようにさらに拡張され得る。たとえば、追加の入力は、現在のセッション中のユーザによって以前にアクセスされたウェブサイトのリスト、以前にアクセスされたウェブサイトにおいて提示されたデジタルコンポーネントとの以前の対話、または他のサブモデルの予測を含むことができる。追加の入力は、クライアントデバイス106のユーザがメンバーであるユーザグループに関係する情報も含み得る。たとえば、同じユーザグループ中のユーザによってアクセスされたウェブコンテンツの類似度尺度、同じグループに属するユーザのユーザ特性の平均予測、同じグループ中のユーザ間での属性の分布など。
In some implementations, the machine learning model (or sub-model) implemented within the
特定の実装形態に応じて、機械学習モデル(またはサブモデルの各々)は、1つまたは複数のユーザ特性の予測を含む出力を生成するために入力特徴のうちの1つまたは複数を使用することができる。たとえば、特性1モデル220は、クライアントデバイス106のユーザの予測された特性1 252(たとえば、予測された性別)を出力として予測し得る。同様に、特性2モデル230は、入力205および210を処理し、クライアントデバイス106のユーザの予測された特性2 254(たとえば、予測された年齢範囲)を出力として生成する回帰モデルであり得る。同様にして、特性3モデル240は、ユーザの予測された特性3 256を出力として生成する。
Depending on the particular implementation, the machine learning model (or each of the sub-models) uses one or more of the input features to generate an output containing predictions of one or more user characteristics. can be done. For example, the
これらの予測されたユーザ特性は、入力特徴205および210とともに、デジタルコンポーネントプロバイダおよび/またはデジタルコンポーネントサーバ108によって提供されたデジタルコンポーネントを選択するために使用される。しかしながら、ユーザ特性を予測するためにユーザ評価装置170によって機械学習モデル(またはサブモデルの各々)を実装することは、データクラス不均衡を被ることがある。データクラス不均衡は、訓練データセットにおけるクラスの不均等な分布があるときの予測分類の問題である。訓練データセットのサンプルは現実の世界から獲得されるので、訓練データセットにおけるサンプルの分布は、データを収集するために使用されるサンプリング手順に従ったクラスの分布を反映し、すべてのクラスを均等に表さないことがある。言い換えれば、単一のユーザグループ(たとえば、「靴」に興味があるユーザを含むユーザグループ)内には、異なる特性を有する、ユーザの異なるグループとも呼ばれるユーザのサブグループ(たとえば、靴に興味がある男性ユーザの1つのサブグループおよび靴に興味がある女性ユーザの第2のサブグループ)がある可能性があり、訓練サンプル中のサブグループの各々に異なる数のユーザが存在する(たとえば、男性よりも女性が多い、またはその逆)ときに不均衡が生じることがある。
These predicted user characteristics along with
そのような不均衡なデータ結果に対して機械学習モデルを訓練することは、機械学習モデルがクラスを差別しないので、大きい比率を占めるグループに対してモデルがより良い予測を達成する傾向をもたらす。たとえば、ユーザグループ「化粧品」に関連付けられた男性ユーザの数が同じユーザグループに関連付けられた女性ユーザの数よりも少ないと仮定する。別の例では、ユーザグループ「ビデオゲーム」に関連付けられた19～29歳の年齢グループ中のユーザの数が59～69歳の年齢グループ中のユーザの数よりもかなり多いと仮定する。そのようなシナリオでは、訓練サンプルの分布および/または比率を考慮しないユーザ特性を予測するように訓練されたユーザ評価装置170内で実装される機械学習モデルは、訓練データセット中の少数しか存在しないユーザグループに対するモデル性能の低下をもたらすことがある。言い換えれば、モデルによって出力される予測は、訓練データセット中の最も多くのメンバーを有するユーザのサブグループの特性に偏っていることがある。たとえば、ユーザグループ「化粧品」中の女性ユーザの真の数に対する同じユーザグループ中の男性ユーザの真の数が1/10である、すなわち、ユーザグループ「化粧品」中のユーザの10%が男性であると仮定する。真の比率と同じ男性対女性の分布を示す訓練データセットに対して訓練された機械学習モデルは、ユーザグループ中のすべてのユーザを女性として分類するが、90%の精度を達成することができる。
Training a machine learning model on such imbalanced data results tends to make the model achieve better predictions for large proportion groups, as the machine learning model does not discriminate between classes. For example, assume that the number of male users associated with the user group "cosmetics" is less than the number of female users associated with the same user group. In another example, assume that the number of users in the 19-29 age group associated with the user group "video games" is significantly greater than the number of users in the 59-69 age group. In such scenarios, machine learning models implemented within the
不均衡なデータに対して機械学習モデルを訓練することは、異なるユーザグループ間での性能の低下をもたらす可能性もある。たとえば、ユーザ評価装置170内で実装される機械学習モデルがユーザグループ1および2に属するユーザのユーザ特性を予測するように訓練されると仮定する。また、訓練サンプルの95%がユーザグループ1に関連付けられたユーザを表すと仮定する。そのようなシナリオでは、機械学習モデルは、ユーザグループ2に関連付けられたユーザについてのユーザ特性を予測しながら、ユーザグループ1に概ね共通しているユーザ特性への偏りを示す可能性がある。
Training machine learning models on imbalanced data can also result in poor performance across different user groups. For example, assume that a machine learning model implemented within
クラス不均衡の問題に対処するために、機械学習モデル(またはサブモデル)は、すべてが同じグループ識別子によって表されるユーザの異なるグループ間での性能の尺度の差を低減する追加項を損失関数に追加することによって変更された損失関数を最適化するように訓練される。言い換えれば、損失関数における追加項は、特定のユーザグループ内のユーザの任意のサブグループが少数しか存在しないことが原因でモデルによって出力されるフォールスポジティブおよび/またはフォールスネガティブの数を低減するのに役立つ。たとえば、変更された損失関数に追加された追加項は、訓練データセットが不均衡な数の男性ユーザおよび女性ユーザならびに/またはサンプルを有しているとしても、機械学習モデルがユーザグループ「化粧品」中の男性ユーザと女性ユーザを区別することができるような方法でその学習可能なパラメータを更新するために、訓練プロセス中にそのモデルにペナルティを科し、それによって、より正確な出力を提供する。異なるユーザグループ間での一貫した性能を提供するために追加項を追加することによって損失関数が変更されるシナリオでは、追加項は、各ユーザグループ内のモデル性能の変動性を測定し、それによって、モデルに各ユーザグループ内のより一貫した性能を達成させる。 To address the problem of class imbalance, a machine learning model (or sub-model) adds an additional term to the loss function that reduces differences in performance measures between different groups of users all represented by the same group identifier. is trained to optimize a modified loss function by adding In other words, the additional term in the loss function is used to reduce the number of false positives and/or false negatives output by the model due to the minority of any subgroup of users within a particular user group. Helpful. For example, an additional term added to the modified loss function indicates that even though the training dataset has a disproportionate number of male and female users and/or samples, the machine learning model may Penalize the model during the training process to update its learnable parameters in such a way that it can distinguish between male and female users in . In scenarios where the loss function is modified by adding additional terms to provide consistent performance across different user groups, the additional terms measure the variability of the model performance within each user group, thereby , causing the model to achieve more consistent performance within each user group.
いくつかの実装形態では、損失関数に追加される追加項は、機械学習モデルが訓練データセットの分布にわたって一般化するように、特定のユーザグループ内の複数のサブグループおよび/または複数のユーザグループ間での訓練プロセス中のエラーに従って機械学習モデルにペナルティを科すエラー正規化項である。他の実装形態では、損失関数に追加される追加項は、異なるグループ間での機械学習モデルの予測された出力の分布の間に差がある場合に機械学習モデルにペナルティを科すダイバージェンス最小化項である。エラー正規化項およびダイバージェンス最小化項は、以下でさらに説明される。 In some implementations, the additional terms added to the loss function are multiple subgroups within a particular usergroup and/or multiple usergroups so that the machine learning model generalizes across the distribution of the training dataset. is an error normalization term that penalizes the machine learning model according to errors during the training process between In other implementations, the additional term added to the loss function is a divergence minimizing term that penalizes the machine learning model when there are differences between the distributions of the machine learning model's predicted output across different groups. is. Error normalization terms and divergence minimization terms are further described below.
いくつかの実装形態では、損失関数に追加される追加項は、損失変動項である。いくつかの実装形態では、損失変動項は、第1のサブグループ中の第1のユーザの損失とユーザグループ内のすべてのサブグループ中のすべてのユーザの平均損失の二乗差である。たとえば、そのような実装形態は、「化粧品」および「靴」などの異なる興味グループ間での平均損失の変動を計算することになる。そのような例では、損失変動項は、異なる興味グループ、たとえば、「化粧品」および「靴」に対する損失の変動性を考慮する。この項は、異なる興味グループに対する変動が高いときにより高い値を取り、したがって、(より低い変動によって測定された)サブグループ間でのより均一な性能を促進することになる。損失変動項は、以下で提示される。
L(X)+Var(L)
ここで、
Var(L)=Ex～X((L(x)-E[L(x)])2)
ここで、L(X)はデータ分布X間での損失関数である。変動が各観測またはユーザ属性の真のラベルを条件とする場合、この損失変動の公式化の他の変形形態も可能である。
In some implementations, the additional term added to the loss function is the loss variation term. In some implementations, the loss variation term is the squared difference between the loss of the first user in the first subgroup and the average loss of all users in all subgroups in the user group. For example, such an implementation would compute the variation in average loss between different interest groups such as "cosmetics" and "shoes". In such an example, the loss volatility term considers the volatility of losses for different interest groups, eg, "Cosmetics" and "Shoes." This term will take higher values when the variability for different interest groups is high, thus promoting more uniform performance among subgroups (measured by lower variability). Loss variation terms are presented below.
L(X)+Var(L)
here,
Var(L)=Ex ～X ((L(x)-E[L(x)]) 2 )
where L(X) is the loss function between data distributions X. Other variations of this loss variability formulation are also possible if the variability is conditioned on the true label of each observation or user attribute.
いくつかの実装形態では、損失関数に追加される追加項は、最大加重損失誤差項である。いくつかの実装形態では、最大加重損失誤差項は、特定のユーザグループ内のあるサブグループ中のすべてのユーザの中のあるユーザの損失とその特定のユーザグループ内のすべてのサブグループ中のすべてのユーザの損失の最大加重差である。いくつかの実装形態では、サブグループは、ユーザグループ内の重要性に基づいて加重され得る。最大加重損失誤差項は、以下で提示される。
L(X)+w(g)|E[(g(x)=1)-E(L(x))]|
ここで、
g(x)は特定の要素がサブグループg中にあることを示す関数であり、w(g)はグループgの加重関数を示す。
In some implementations, the additional term added to the loss function is the maximum weighted loss error term. In some implementations, the maximum weighted loss error term is the loss of a user among all users in a subgroup within a particular user group and all users in all subgroups within that particular user group. is the maximum weighted difference between the losses of the users of In some implementations, subgroups may be weighted based on their importance within the user group. The maximum weighted loss error term is presented below.
L(X)+w(g)|E[(g(x)=1)-E(L(x))]|
here,
g(x) is a function indicating that a particular element is in subgroup g, and w(g) is a weighting function for group g.
いくつかの実装形態では、損失関数に追加される追加項は、粗損失変動項である。いくつかの実装形態では、粗損失変動項は、ユーザグループ内のサブグループの損失間の二乗差の平均である。粗損失変動項は、以下で提示される。
L(X)+Var(Ex～X[L(x)|A])
ここで、
Var(Ex～X[A])=Ex~X[(A)-E(L(x))2]
ここで、Aはユーザグループ内のサブグループである。
In some implementations, the additional term added to the loss function is the coarse loss variation term. In some implementations, the coarse loss variation term is the mean of the squared differences between the losses of subgroups within the user group. The coarse loss variation term is presented below.
L(X)+Var(Ex ～X [L(x)|A])
here,
Var(Ex ~X [A])=Ex ~X [(A)-E(L(x)) 2 ]
where A is a subgroup within the user group.
いくつかの実装形態では、損失関数に追加される追加項は、ヒルベルト-シュミット独立基準(HSIC:Hilbert-Schmidt independence criterion)正規化項である。いくつかの実装形態では、HSICは、ユーザ属性の予測の分布と何らかのグループ(たとえば、興味グループ、人口統計学的グループ)中の例のメンバーシップとの間の統計的独立性の程度を測定する。HSIC正規化項は、以下で提示される。
HSIC(pxy,F,G)=||Cxy||HS
2
ここで、FおよびGはジョイント尺度pxyを伴う再生核ヒルベルト空間であり、Cxyは相互共分散作用素であり、||・||HSはヒルベルト-シュミット行列ノルムである(この例では、XおよびYは、それぞれ、例のセットについてのモデル予測およびグループメンバーシップとなる)。
In some implementations, the additional term added to the loss function is a Hilbert-Schmidt independence criterion (HSIC) normalization term. In some implementations, HSIC measures the degree of statistical independence between the distribution of user attribute predictions and the membership of an example in some group (e.g., interest group, demographic group). . The HSIC normalization term is presented below.
HSIC(p xy ,F,G)=||C xy || HS 2
where F and G are the reproducing kernel Hilbert space with joint measure p xy , C xy is the cross-covariance operator, and ||·|| HS is the Hilbert-Schmidt matrix norm (in this example, X and Y are the model predictions and group memberships for the set of examples, respectively).
いくつかの実装形態では、損失関数に追加される追加項は、相互情報量(MI:mutual information)項である。いくつかの実装形態では、相互情報量項は、興味グループなどの異なるグループにわたるモデルの予測の分布の類似度の測定値である(たとえば、MI項は、靴および化粧品の興味グループ中のユーザについてのモデルの予測の全体的な分布間の類似度の程度を測定し得る)。相互情報量項は、以下で提示される。
L(X)+MI(logitsT,membershipT)
In some implementations, the additional term added to the loss function is a mutual information (MI) term. In some implementations, the mutual information term is a measure of the similarity of the distribution of the model's predictions across different groups, such as interest groups (e.g., the MI term is can measure the degree of similarity between the overall distributions of the model's predictions). The mutual information term is presented below.
L(X)+MI(logits T ,membership T )
いくつかの実装形態では、損失関数に追加される追加項は、カルバック-ライブラーダイバージェンス(Kullback-Leibler Divergence)項である。いくつかの実装形態では、カルバック-ライブラーダイバージェンス項は、同じユーザグループに属するユーザの複数のサブグループ間での機械学習モデル予測の分布の差の尺度である。いくつかの実装形態では、カルバック-ライブラーダイバージェンス項は、
L(X)+KL(logitsA||logitsB)
として提示され得る。ここで、関数KLは、ユーザグループ内の2つのサブグループAおよびBに対する連続的なカルバック-ライブラーダイバージェンスであり、2つの分布pおよびqに対する関数KLは、KL(p||q)=Σxp(x)log(p(x)/q(x))として書かれ得る。
In some implementations, the additional term added to the loss function is the Kullback-Leibler Divergence term. In some implementations, the Kullback-Leibler divergence term is a measure of the difference in the distribution of machine learning model predictions among multiple subgroups of users belonging to the same user group. In some implementations, the Kullback-Leibler divergence term is
L(X)+KL(logits A ||logits B )
can be presented as where the function KL is the continuous Kullback-Leibler divergence for the two subgroups A and B within the user group, and the function KL for the two distributions p and q is KL(p||q)=Σ x can be written as p(x)log(p(x)/q(x)).
サブモデル220、230および240の各々に対する損失関数を変更した後、訓練データセットに対してサブモデルが訓練される。特定の実装形態に応じて、サブ機械学習モデルの訓練プロセスは、教師あり、教師なし、または半教師ありとすることができ、モデルに関連付けられた複数のハイパーパラメータを調整すること(ハイパーパラメータチューニングと呼ばれるプロセス)も含み得る。 After changing the loss function for each of the sub-models 220, 230 and 240, the sub-models are trained on the training data set. Depending on the particular implementation, the process of training a sub-machine learning model can be supervised, unsupervised, or semi-supervised, and involves tuning multiple hyperparameters associated with the model (hyperparameter tuning). process).
機械学習モデル(またはサブモデル)が訓練されると、デジタルコンポーネント配信システム110は、ユーザ評価装置170(またはユーザ評価装置170内で実装される機械学習モデル)によって予測された1つまたは複数のユーザ特性に基づいてデジタルコンポーネントを選択することができる。たとえば、サブグループ「化粧品」に属する男性ユーザが、クライアントデバイス106を通じて検索クエリ「フェイスクリーム」を提供して、検索結果ページおよび/または検索結果を指定するデータおよび/または検索クエリに関係するテキストコンテンツ、可聴コンテンツ、もしくは他の視覚コンテンツを取得すると仮定する。検索結果ページは、検索結果ページを生成および提供するエンティティ以外のエンティティによって提供されたデジタルコンポーネント用のスロットを含むと仮定する。クライアントデバイス106上で実行されるブラウザベースのアプリケーション107は、デジタルコンポーネントスロットを求めるコンポーネント要求112を生成する。デジタルコンポーネント配信システム110は、コンポーネント要求112を受信した後、コンポーネント要求112に含まれる情報を入力として、ユーザ評価装置170によって実装された機械学習モデルに提供する。機械学習モデルは、入力を処理した後、1つまたは複数のユーザ特性の予測を出力として生成する。たとえば、サブ機械学習モデル220は、変更された損失関数に対して最適化することによって学習されたパラメータに基づいて、クライアントデバイス106のユーザを男性として正確に予測する。したがって、デジタルコンポーネント配信システム110は、男性への配信用に指定されたフェイスクリームに関係するデジタルコンポーネントを選択することができる。選択の後、選択されたデジタルコンポーネントは、検索結果ページにおいて検索結果とともに提示するためにクライアントデバイス106に伝送される。
Once the machine learning models (or sub-models) are trained, the digital
図3は、変更された損失関数に基づいてデジタルコンポーネントを配信する例示的なプロセス300の流れ図である。プロセス300の動作は、図1および図2で説明および図示されるシステムの構成要素によって実施されるものとして以下で説明される。プロセス300の動作は、単に例示の目的で以下で説明される。プロセス300の動作は、任意の適切なデバイスまたはシステム、たとえば、任意の適切なデータ処理装置によって実施され得る。プロセス300の動作はまた、非一時的であり得るコンピュータ可読媒体上に記憶された命令として実装され得る。命令の実行は、1つまたは複数のデータ処理装置にプロセス300の動作を実施させる。
FIG. 3 is a flow diagram of an
モデルが訓練中に最適化しようとする性能の尺度を表す損失を生成する損失関数が識別される(310)。いくつかの実装形態では、図1および図2を参照しながら説明したように、デジタルコンポーネント配信システム110は、コンポーネント要求112に含まれる情報に基づいてユーザ特性を予測するために機械学習モデル(またはサブ機械学習モデルと呼ばれる複数の機械学習モデル)を実装することができるユーザ評価装置170を含むことができる。たとえば、コンポーネント要求112は、コンポーネント要求112がサブミットされた国もしくは地域を示す地理的情報などの他の情報、またはデジタルコンポーネントが表示されることになる環境についてのコンテキストを提供する他の情報(たとえば、コンポーネント要求の時刻、コンポーネント要求の曜日、モバイルデバイスもしくはタブレットデバイスなどの、デジタルコンポーネントが表示されることになるクライアントデバイス106のタイプ)の他に、クライアントデバイス106が関連付けられるユーザグループに対応するユーザグループ識別子を含む。
A loss function is identified 310 that produces a loss representing a measure of performance that the model seeks to optimize during training. In some implementations, as described with reference to FIGS. 1 and 2, digital
損失関数が変更される(320)。いくつかの実装形態では、損失関数は、すべてが同じグループ識別子によって表されるユーザの異なるグループ間での性能の尺度の差を低減する追加項を損失関数に追加することによって変更される。クラス不均衡の問題に対処するために、機械学習モデル(またはサブ機械学習モデル)は、すべてが同じグループ識別子によって表されるユーザの異なるグループ間での性能の尺度の差を低減する追加項を損失関数に追加することによって変更された損失関数を最適化するように訓練される。2つの損失項(標準損失および追加項)間の相対加重は、乗数を一方または両方の項に別々に適用することによって調整され得る。 A loss function is modified (320). In some implementations, the loss function is modified by adding additional terms to the loss function that reduce differences in performance measures between different groups of users all represented by the same group identifier. To address the class imbalance problem, machine learning models (or sub-machine learning models) add additional terms that reduce differences in performance measures between different groups of users all represented by the same group identifier. It is trained to optimize the modified loss function by adding to the loss function. The relative weighting between the two loss terms (standard loss and additional term) can be adjusted by applying multipliers to one or both terms separately.
いくつかの実装形態では、損失関数に追加される追加項は、機械学習モデルが訓練データセットの分布にわたって一般化するように、特定のユーザグループ内の複数のサブグループ間での訓練プロセス中のあらゆる誤った予測について機械学習モデルにペナルティを科すエラー正規化項である。他の実装形態では、損失関数に追加される追加項は、機械学習モデルの予測された出力の分布とグランドトゥルースとの間に差がある場合に機械学習モデルにペナルティを科すダイバージェンス最小化項である。エラー正規化項およびダイバージェンス最小化項は、以下でさらに説明される。 In some implementations, additional terms added to the loss function are used during the training process across multiple subgroups within a particular user group so that the machine learning model generalizes across the distribution of the training dataset. An error normalization term that penalizes the machine learning model for any incorrect predictions. In other implementations, the additional term added to the loss function is a divergence minimizing term that penalizes the machine learning model when there is a difference between the distribution of the machine learning model's predicted output and the ground truth. be. Error normalization terms and divergence minimization terms are further described below.
たとえば、追加項は、第1のサブグループ中の第1のユーザの損失とユーザグループ内のすべてのサブグループ中のすべてのユーザの平均損失の二乗差である損失変動項であり得る。別の例では、追加項は、特定のユーザグループ内のあるサブグループ中のすべてのユーザの中のあるユーザの損失とその特定のユーザグループ内のすべてのサブグループ中のすべてのユーザの損失の最大加重差である最大加重損失誤差項であり得る。別の例では、追加項は、ユーザグループ内のサブグループの損失間の二乗差の平均である粗損失変動項であり得る。別の例では、追加項は、ノンパラメトリックな方法での、ユーザの異なるサブグループ中のユーザの分布とは無関係の、ユーザの異なるサブグループ間での損失の差である、HSIC正規化項であり得る。同様に、他の追加項は、相互情報量項、および同じユーザグループに属するユーザの複数のサブグループ間での機械学習モデル予測の分布の差の尺度であるカルバック-ライブラーダイバージェンス項であり得る。 For example, the additional term may be a loss variation term that is the squared difference between the loss of the first user in the first subgroup and the average loss of all users in all subgroups in the user group. In another example, the additional term is the loss of a user among all users in a subgroup within a particular user group and the loss of all users in all subgroups within that particular user group. It may be the maximum weighted loss error term, which is the maximum weighted difference. In another example, the additional term may be a coarse loss variation term that is the average of the squared differences between the losses of subgroups within the user group. In another example, the additional term is the HSIC normalization term, which is the difference in loss between different subgroups of users, independent of the distribution of users in different subgroups of users, in a nonparametric manner. could be. Similarly, other additional terms may be a mutual information term and a Kullback-Leibler divergence term, which is a measure of the difference in the distribution of machine learning model predictions among multiple subgroups of users belonging to the same user group. .
変更された損失関数を使用してモデルが訓練される(330)。たとえば、サブ機械学習モデル220、230および240の各々に対する損失関数を変更した後、訓練データセットに対してサブ機械学習モデルが訓練される。特定の実装形態に応じて、サブ機械学習モデルの訓練プロセスは、教師あり、教師なし、または半教師ありとすることができ、モデルに関連付けられた複数のハイパーパラメータを調整すること(ハイパーパラメータチューニングと呼ばれるプロセス)も含み得る。
A model is trained (330) using the modified loss function. For example, after changing the loss function for each of the
デジタルコンポーネントを求める要求が受信される(340)。いくつかの実装形態では、要求は、ユーザの異なるグループの中の特定のグループのための所与のグループ識別子を含む。たとえば、クライアントデバイス106のユーザが1つまたは複数のデジタルコンポーネントスロットを含むウェブサイトをロードするためにブラウザベースのアプリケーション107を使用する場合、ブラウザベースのアプリケーション107は、1つまたは複数のデジタルコンポーネントスロットの各々についてコンポーネント要求112を生成し、伝送することができ、コンポーネント要求112は、デジタルコンポーネント配信システム110によって受信され得る。
A request for a digital component is received (340). In some implementations, the request includes a given group identifier for a particular group among different groups of users. For example, if a user of
訓練されたモデルは、要求に含まれていない1つまたは複数のユーザ特性を生成するために、要求に含まれる情報に適用される(350)。たとえば、デジタルコンポーネント配信システム110は、コンポーネント要求112を受信した後、コンポーネント要求112に含まれる情報を入力として、ユーザ評価装置170によって実装された機械学習モデルに提供する。機械学習モデルは、入力を処理した後、1つまたは複数のユーザ特性の予測を出力として生成する。
A trained model is applied to the information included in the request to generate one or more user characteristics not included in the request (350). For example, after digital
訓練されたモデルによって生成された1つまたは複数のユーザ特性に基づいて1つまたは複数のデジタルコンポーネントが選択される(360)。たとえば、サブグループ「化粧品」に属する男性ユーザが、クライアントデバイス106を通じて検索クエリ「フェイスクリーム」を提供して、検索結果ページおよび/または検索結果を指定するデータおよび/または検索クエリに関係するテキストコンテンツ、可聴コンテンツ、もしくは他の視覚コンテンツを取得すると仮定する。検索結果ページがデジタルコンポーネント用のスロットを含むと仮定する。クライアントデバイス106上で実行されるブラウザベースのアプリケーション107は、デジタルコンポーネントスロットを求めるコンポーネント要求112を生成する。デジタルコンポーネント配信システム110は、コンポーネント要求112を受信した後、コンポーネント要求112に含まれる情報を入力として、ユーザ評価装置170によって実装された機械学習モデルに提供する。機械学習モデルは、入力を処理した後、1つまたは複数のユーザ特性の予測を出力として生成する。たとえば、サブ機械学習モデル220は、変更された損失関数に対して最適化することによって学習されたパラメータに基づいて、クライアントデバイス106のユーザを男性として正確に予測する。したがって、デジタルコンポーネント配信システム110は、デジタルコンポーネントが男性に配信されるべきであることを示す配信基準を有する、フェイスクリームに関係するデジタルコンポーネントを選択することができる。
One or more digital components are selected 360 based on one or more user characteristics generated by the trained model. For example, a male user belonging to the subgroup "cosmetics" provides the search query "face cream" through the
選択された1つまたは複数のデジタルコンポーネントがクライアントデバイスに伝送される(370)。たとえば、予測されたユーザ特性に基づいてデジタルコンポーネント配信システム110によってデジタルコンポーネントを選択した後、選択されたデジタルコンポーネントは提示のためにクライアントデバイス106に伝送される。
One or more selected digital components are transmitted (370) to the client device. For example, after selecting digital components by digital
上記の説明に加えて、ユーザには、本明細書で説明されるシステム、プログラム、または特徴がユーザ情報(たとえば、ユーザのソーシャルネットワーク、ソーシャルアクションもしくはアクティビティ、職業、ユーザの選好、またはユーザの現在のロケーションについての情報)の収集を可能にし得るかどうかおよびいつそれを可能にし得るかと、サーバからのコンテンツまたは通信がユーザに送信されるかどうかの両方に関しての選択をユーザが行うことを可能にする制御が与えられ得る。加えて、いくつかのデータは、個人を識別できる情報が削除されるように、記憶または使用される前に1つまたは複数の方法で扱われ得る。たとえば、ユーザのアイデンティティは、ユーザについて個人を識別できる情報が決定され得ないように、またはユーザの特定のロケーションが決定され得ないようにロケーション情報が取得される場合にユーザの地理的ロケーションが(都市レベル、ZIPコードレベル、または州のレベルなどに)一般化され得るように扱われ得る。したがって、ユーザは、ユーザについてのどの情報が収集されるか、その情報がどのように使用されるか、およびどの情報がユーザに提供されるかを制御することができる。 In addition to the above discussion, the user should be informed that the systems, programs, or features described herein are user information (e.g., the user's social networks, social actions or activities, occupation, user preferences, or the user's current allow the user to make choices regarding both whether and when the collection of data (information about the location of the control can be given. Additionally, some data may be treated in one or more ways before being stored or used such that personally identifiable information is removed. For example, a user's identity may be determined such that personally identifiable information about the user cannot be determined, or the user's geographic location (if location information is obtained such that the user's specific location cannot be determined). (to city level, ZIP code level, or state level, etc.). Thus, the user can control what information is collected about the user, how that information is used, and what information is provided to the user.
図4は、上記で説明された動作を実施するために使用され得る例示的なコンピュータシステム400のブロック図である。システム400は、プロセッサ410、メモリ420、記憶デバイス430、および入力/出力デバイス440を含む。構成要素410、420、430、および440の各々は、たとえば、システムバス450を使用して相互接続され得る。プロセッサ410は、システム400内での実行のために命令を処理することが可能である。一実装形態では、プロセッサ410はシングルスレッドプロセッサである。別の実装形態では、プロセッサ410はマルチスレッドプロセッサである。プロセッサ410は、メモリ420にまたは記憶デバイス430上に記憶された命令を処理することが可能である。
FIG. 4 is a block diagram of an
メモリ420はシステム400内に情報を記憶する。一実装形態では、メモリ420はコンピュータ可読媒体である。一実装形態では、メモリ420は揮発性メモリユニットである。別の実装形態では、メモリ420は不揮発性メモリユニットである。
記憶デバイス430は、システム400のための大容量記憶を提供することが可能である。一実装形態では、記憶デバイス430はコンピュータ可読媒体である。様々な異なる実装形態では、記憶デバイス430は、たとえば、ハードディスクデバイス、光ディスクデバイス、ネットワークを介して複数のコンピューティングデバイスによって共有される記憶デバイス(たとえば、クラウド記憶デバイス)、または何らかの他の大容量記憶デバイスを含むことができる。
入力/出力デバイス440は、システム400のための入力/出力動作を提供する。一実装形態では、入力/出力デバイス440は、ネットワークインターフェースデバイス、たとえば、イーサネットカード、シリアル通信デバイス、たとえば、RS-232ポート、および/またはワイヤレスインターフェースデバイス、たとえば、802.11カードのうちの1つまたは複数を含むことができる。別の実装形態では、入力/出力デバイスは、入力データを受信し、出力データを他の入力/出力デバイス、たとえば、キーボード、プリンタおよびディスプレイデバイス460に送信するように構成されたドライバデバイスを含むことができる。しかしながら、モバイルコンピューティングデバイス、モバイル通信デバイス、セットトップボックステレビジョンクライアントデバイスなどの他の実装形態も使用され得る。
Input/
例示的な処理システムが図4で説明されているが、主題の実装形態および本明細書で説明される機能的動作は、他のタイプのデジタル電子回路において、または本明細書で開示される構造およびその構造的等価物を含むコンピュータソフトウェア、ファームウェア、もしくはハードウェアにおいて、またはそれらのうちの1つもしくは複数の組合せにおいて実装され得る。 Although an exemplary processing system is illustrated in FIG. 4, the subject implementation and functional operations described herein may be implemented in other types of digital electronic circuits or structures disclosed herein. and structural equivalents thereof, or in any combination of one or more thereof.
電子文書(簡潔にするために単に文書と呼ばれる)は、必ずしもファイルに対応するとは限らない。文書は、他の文書を保持するファイルの一部分に、当該の文書専用の単一のファイルに、または複数の協調ファイルに記憶され得る。 An electronic document (referred to simply as a document for brevity) does not necessarily correspond to a file. A document may be stored in part of a file that holds other documents, in a single file dedicated to that document, or in multiple collaborative files.
主題の実施形態および本明細書で説明される動作は、デジタル電子回路において、または本明細書で開示される構造およびその構造的等価物を含むコンピュータソフトウェア、ファームウェア、もしくはハードウェアにおいて、またはそれらのうちの1つもしくは複数の組合せにおいて実装され得る。本明細書で説明される主題の実施形態は、1つまたは複数のコンピュータプログラム、すなわち、データ処理装置による実行のためにまたはデータ処理装置の動作を制御するために(1つまたは複数の)コンピュータ記憶媒体上で符号化された、コンピュータプログラム命令の1つまたは複数のモジュールとして実装され得る。代替または追加として、プログラム命令は、データ処理装置による実行のために、適切な受信機装置への伝送のために情報を符号化するために生成された、人工的に生成された伝搬信号、たとえば、機械で生成された電気信号、光信号、または電磁信号上で符号化され得る。コンピュータ記憶媒体は、コンピュータ可読記憶デバイス、コンピュータ可読記憶基板、ランダムもしくはシリアルアクセスメモリアレイもしくはデバイス、またはそれらのうちの1つもしくは複数の組合せであり得るか、またはそれらに含まれ得る。さらに、コンピュータ記憶媒体は伝搬信号ではないが、コンピュータ記憶媒体は、人工的に生成された伝搬信号において符号化されたコンピュータプログラム命令のソースまたは宛先であり得る。コンピュータ記憶媒体はまた、1つまたは複数の別個の物理構成要素または媒体(たとえば、複数のCD、ディスク、または他の記憶デバイス)であり得るか、またはそれらに含まれ得る。 The subject embodiments and operations described herein may be implemented in digital electronic circuitry, or in computer software, firmware, or hardware, including the structures disclosed herein and their structural equivalents. can be implemented in one or more combinations of Embodiments of the subject matter described herein comprise one or more computer programs, i.e., computer program(s), for execution by a data processing apparatus or for controlling operation of a data processing apparatus. It may be implemented as one or more modules of computer program instructions encoded on a storage medium. Alternatively or additionally, the program instructions may, for execution by a data processing device, be transferred to an artificially generated propagated signal, e.g., generated to encode information for transmission to an appropriate receiver device. , may be encoded on a machine-generated electrical, optical, or electromagnetic signal. A computer storage medium may be or be included in a computer readable storage device, a computer readable storage substrate, a random or serial access memory array or device, or a combination of one or more thereof. Moreover, although a computer storage medium is not a propagated signal, a computer storage medium can be a source or destination of computer program instructions encoded in an artificially generated propagated signal. A computer storage medium may also be or be contained within one or more separate physical components or media (eg, multiple CDs, discs, or other storage devices).
本明細書で説明される動作は、1つもしくは複数のコンピュータ可読記憶デバイス上に記憶されたまたは他のソースから受信されたデータに対してデータ処理装置によって実施される動作として実装され得る。 The operations described herein may be implemented as operations performed by a data processing apparatus on data stored on one or more computer-readable storage devices or received from other sources.
「データ処理装置」という用語は、例として、プログラマブルプロセッサ、コンピュータ、システムオンチップ、もしくは上記の複数のもの、または上記の組合せを含む、データを処理するためのすべての種類の装置、デバイス、および機械を包含する。装置は、専用論理回路、たとえば、FPGA(フィールドプログラマブルゲートアレイ)またはASIC(特定用途向け集積回路)を含むことができる。装置は、ハードウェアに加えて、当該のコンピュータプログラムのための実行環境を作成するコード、たとえば、プロセッサファームウェア、プロトコルスタック、データベース管理システム、オペレーティングシステム、クロスプラットフォームランタイム環境、仮想マシン、またはそれらのうちの1つもしくは複数の組合せを構成するコードも含むことができる。装置および実行環境は、ウェブサービス、分散コンピューティングインフラストラクチャおよびグリッドコンピューティングインフラストラクチャなどの様々な異なるコンピューティングモデルインフラストラクチャを実現することができる。 The term "data processing apparatus" includes, by way of example, all kinds of apparatus, devices and Including machinery. The device may include dedicated logic circuits, such as FPGAs (Field Programmable Gate Arrays) or ASICs (Application Specific Integrated Circuits). The apparatus includes, in addition to hardware, code that creates an execution environment for the computer program in question, such as processor firmware, protocol stacks, database management systems, operating systems, cross-platform runtime environments, virtual machines, or among them. can also include code that constitutes a combination of one or more of Devices and execution environments can implement a variety of different computing model infrastructures, such as web services, distributed computing infrastructures and grid computing infrastructures.
コンピュータプログラム(プログラム、ソフトウェア、ソフトウェアアプリケーション、スクリプト、またはコードとしても知られている)は、コンパイル型言語またはインタプリタ型言語、宣言型言語または手続き型言語を含む任意の形態のプログラミング言語で書かれ得、スタンドアロンプログラムとして、またはモジュール、構成要素、サブルーチン、オブジェクト、もしくはコンピューティング環境において使用するのに適した他のユニットとしてを含む任意の形態で展開され得る。コンピュータプログラムは、ファイルシステムにおけるファイルに対応し得るが、そうである必要はない。プログラムは、他のプログラムもしくはデータ(たとえば、マークアップ言語文書に記憶された1つもしくは複数のスクリプト)を保持するファイルの一部分に、当該のプログラム専用の単一のファイルに、または複数の協調ファイル(たとえば、1つもしくは複数のモジュール、サブプログラム、またはコードの部分を記憶するファイル)に記憶され得る。コンピュータプログラムは、1つのコンピュータ上で、または、1つのサイトに配置されるかもしくは複数のサイトにわたって分散され、通信ネットワークによって相互接続される複数のコンピュータ上で実行されるように展開され得る。 A computer program (also known as a program, software, software application, script, or code) can be written in any form of programming language, including compiled or interpreted languages, declarative or procedural languages. , may be deployed in any form, including as a stand-alone program, or as modules, components, subroutines, objects, or other units suitable for use in a computing environment. A computer program may, but need not, correspond to a file in a file system. A program may be part of a file holding other programs or data (e.g., one or more scripts stored in a markup language document), a single file dedicated to that program, or multiple cooperative files. (eg, a file that stores one or more modules, subprograms, or portions of code). A computer program can be deployed to be executed on one computer or on multiple computers located at one site or distributed across multiple sites and interconnected by a communication network.
本明細書で説明されるプロセスおよび論理フローは、入力データを操作し、出力を生成することによってアクションを実施するために、1つまたは複数のコンピュータプログラムを実行する1つまたは複数のプログラマブルプロセッサによって実施され得る。プロセスおよび論理フローは、専用論理回路、たとえば、FPGA(フィールドプログラマブルゲートアレイ)またはASIC(特定用途向け集積回路)によっても実施され得、装置は、それらとしても実装され得る。 The processes and logic flows described herein are performed by one or more programmable processors executing one or more computer programs to perform actions by manipulating input data and generating output. can be implemented. The processes and logic flows may also be implemented by dedicated logic circuits, such as FPGAs (Field Programmable Gate Arrays) or ASICs (Application Specific Integrated Circuits), and devices may be implemented as such.
コンピュータプログラムの実行に適したプロセッサは、例として、汎用マイクロプロセッサと専用マイクロプロセッサの両方を含む。一般に、プロセッサは、読取り専用メモリもしくはランダムアクセスメモリまたは両方から命令およびデータを受信する。コンピュータの必須要素は、命令に従ってアクションを実施するためのプロセッサ、ならびに命令およびデータを記憶するための1つまたは複数のメモリデバイスである。一般に、コンピュータは、データを記憶するための1つまたは複数の大容量記憶デバイス、たとえば、磁気ディスク、光磁気ディスク、または光ディスクも含むか、あるいは、それらからデータを受信することもしくはそれらにデータを転送することまたはその両方を行うために動作可能に結合される。しかしながら、コンピュータはそのようなデバイスを有する必要はない。さらに、コンピュータは、ほんの数例を挙げると、別のデバイス、たとえば、モバイル電話、携帯情報端末(PDA)、モバイルオーディオもしくはビデオプレーヤ、ゲームコンソール、全地球測位システム(GPS)受信機、またはポータブル記憶デバイス(たとえば、ユニバーサルシリアルバス(USB)フラッシュドライブ)に埋め込まれ得る。コンピュータプログラム命令およびデータを記憶するのに適したデバイスは、例として、半導体メモリデバイス、たとえば、EPROM、EEPROM、およびフラッシュメモリデバイス、磁気ディスク、たとえば、内部ハードディスクまたはリムーバブルディスク、光磁気ディスク、ならびにCD-ROMディスクおよびDVD-ROMディスクを含む、すべての形態の不揮発性メモリ、媒体およびメモリデバイスを含む。プロセッサおよびメモリは、専用論理回路によって補完され得るか、または専用論理回路に組み込まれ得る。 Processors suitable for the execution of a computer program include, by way of example, both general and special purpose microprocessors. Generally, a processor receives instructions and data from read-only memory or random-access memory or both. The essential elements of a computer are a processor for performing actions according to instructions, and one or more memory devices for storing instructions and data. Generally, a computer also includes, receives data from, or sends data to, one or more mass storage devices, such as magnetic, magneto-optical, or optical disks, for storing data. operably coupled to transfer or both. However, a computer need not have such devices. Additionally, a computer may be used in another device such as a mobile phone, personal digital assistant (PDA), mobile audio or video player, game console, global positioning system (GPS) receiver, or portable storage, to name just a few. It can be embedded in a device (eg, Universal Serial Bus (USB) flash drive). Suitable devices for storing computer program instructions and data include, by way of example, semiconductor memory devices such as EPROM, EEPROM and flash memory devices, magnetic disks such as internal or removable disks, magneto-optical disks and CDs. - Includes all forms of non-volatile memory, media and memory devices, including ROM discs and DVD-ROM discs. The processor and memory may be supplemented by, or incorporated in, dedicated logic circuitry.
ユーザとの対話を提供するために、本明細書で説明される主題の実施形態は、情報をユーザに表示するためのディスプレイデバイス、たとえば、CRT(陰極線管)またはLCD(液晶ディスプレイ)モニタと、それによってユーザが入力をコンピュータに提供することができるキーボードおよびポインティングデバイス、たとえば、マウスまたはトラックボールとを有するコンピュータ上で実装され得る。他の種類のデバイスも、ユーザとの対話を提供するために使用され得、たとえば、ユーザに提供されるフィードバックは、任意の形態の感覚フィードバック、たとえば、視覚フィードバック、聴覚フィードバック、または触覚フィードバックであり得、ユーザからの入力は、音響入力、音声入力、または触覚入力を含む任意の形態で受信され得る。加えて、コンピュータは、文書をユーザによって使用されるデバイスに送信し、文書をそのデバイスから受信することによって、たとえば、ユーザのクライアントデバイス上のウェブブラウザから受信された要求に応答してウェブページをそのウェブブラウザに送信することによって、ユーザと対話することができる。 To provide interaction with a user, embodiments of the subject matter described herein include a display device, such as a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to a user; It can be implemented on a computer having a keyboard and pointing device, such as a mouse or trackball, by which a user can provide input to the computer. Other types of devices may also be used to provide interaction with the user, e.g., the feedback provided to the user may be any form of sensory feedback, e.g., visual, auditory, or tactile feedback. Input from the user may be received in any form, including acoustic, speech, or tactile input. In addition, the computer can send documents to and receive documents from a device used by a user to, for example, render web pages in response to requests received from a web browser on the user's client device. You can interact with the user by sending to their web browser.
本明細書で説明される主題の実施形態は、バックエンド構成要素、たとえば、データサーバを含む、またはミドルウェア構成要素、たとえば、アプリケーションサーバを含む、またはフロントエンド構成要素、たとえば、それを通じてユーザが本明細書で説明される主題の一実装形態と対話することができるグラフィカルユーザインターフェースもしくはウェブブラウザを有するクライアントコンピュータを含む、または1つもしくは複数のそのようなバックエンド構成要素、ミドルウェア構成要素、もしくはフロントエンド構成要素の任意の組合せを含む、コンピューティングシステムにおいて実装され得る。システムの構成要素は、デジタルデータ通信の任意の形態の媒体、たとえば、通信ネットワークによって相互接続され得る。通信ネットワークの例は、ローカルエリアネットワーク(「LAN」)およびワイドエリアネットワーク(「WAN」)、インターネットワーク(たとえば、インターネット)、ならびにピアツーピアネットワーク(たとえば、アドホックピアツーピアネットワーク)を含む。 Embodiments of the subject matter described herein include back-end components, e.g., data servers, or include middleware components, e.g., application servers, or front-end components, e.g., through which users includes a client computer having a graphical user interface or web browser capable of interacting with one implementation of the subject matter described herein, or one or more such back-end components, middleware components, or front-end It can be implemented in a computing system containing any combination of end components. The components of the system can be interconnected by any form of medium for digital data communication, eg, a communication network. Examples of communication networks include local area networks (“LAN”) and wide area networks (“WAN”), internetworks (eg, the Internet), and peer-to-peer networks (eg, ad-hoc peer-to-peer networks).
コンピューティングシステムは、クライアントおよびサーバを含むことができる。クライアントおよびサーバは、一般に互いから離れており、典型的には通信ネットワークを通じて対話する。クライアントとサーバの関係は、それぞれのコンピュータ上で動作し、互いとのクライアント-サーバ関係を有するコンピュータプログラムから生じる。いくつかの実施形態では、サーバは、(たとえば、クライアントデバイスと対話するユーザにデータを受信し、そのユーザからユーザ入力を受信する目的で)データ(たとえば、HTMLページ)をクライアントデバイスに伝送する。クライアントデバイスにおいて生成されたデータ(たとえば、ユーザ対話の結果)は、サーバにおいてクライアントデバイスから受信され得る。 The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other. In some embodiments, the server transmits data (eg, HTML pages) to the client device (eg, for the purpose of receiving data to and receiving user input from a user interacting with the client device). Data generated at the client device (eg, results of user interactions) may be received from the client device at the server.
本明細書は多くの特定の実装形態の詳細を含んでいるが、これらは任意の発明の範囲または特許請求され得るものの範囲に対する限定として解釈されるべきではなく、むしろ特定の発明の特定の実施形態に特有の特徴の説明として解釈されるべきである。別個の実施形態の文脈において本明細書で説明されるいくつかの特徴はまた、単一の実施形態において組み合わせて実装され得る。逆に、単一の実施形態の文脈において説明される様々な特徴はまた、複数の実施形態において別々にまたは任意の適切な副組合せで実装され得る。さらに、特徴はいくつかの組合せにおいて働くものとして上記で説明され、そのようなものとして最初に特許請求されることさえあるが、特許請求される組合せからの1つまたは複数の特徴は、場合によっては、その組合せから削除される場合があり、特許請求される組合せは、副組合せまたは副組合せの変形形態を対象とし得る。 Although this specification contains many specific implementation details, these should not be construed as limitations on the scope of any invention or what may be claimed, but rather specific implementations of the particular invention. It should be construed as a description of features specific to the form. Some features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely, various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Further, although features are described above as working in some combination, and may even be originally claimed as such, one or more features from the claimed combination may optionally be may be deleted from the combination, and a claimed combination may cover subcombinations or variations of subcombinations.
同様に、動作は特定の順序で図面に図示されているが、これは、望ましい結果を達成するために、そのような動作が示されている特定の順序でまたは逐次的順序で実施されること、またはすべての例示された動作が実施されることを必要とするものとして理解されるべきではない。いくつかの状況では、マルチタスキングおよび並列処理が有利であり得る。さらに、上記で説明された実施形態における様々なシステム構成要素の分離は、すべての実施形態においてそのような分離を必要とするものとして理解されるべきではなく、説明されたプログラム構成要素およびシステムは一般に、単一のソフトウェア製品に一緒に組み込まれ得るか、または複数のソフトウェア製品にパッケージ化され得ることが理解されるべきである。 Similarly, although acts have been illustrated in the figures in a particular order, it is intended that such acts be performed in the specific order shown or in a sequential order to achieve desirable results. , or as requiring that all illustrated acts be performed. Multitasking and parallel processing may be advantageous in some situations. Furthermore, the separation of various system components in the above-described embodiments should not be understood as requiring such separation in all embodiments, and the described program components and systems In general, it should be understood that they may be incorporated together in a single software product or packaged in multiple software products.
このようにして、主題の特定の実施形態が説明されてきた。他の実施形態は、以下の特許請求の範囲の範囲内にある。場合によっては、特許請求の範囲において列挙されるアクションは、異なる順序で実施される場合があるが、依然として望ましい結果を達成することができる。加えて、添付の図において図示されるプロセスは、望ましい結果を達成するために、必ずしも示されている特定の順序または逐次的順序を必要とするとは限らない。いくつかの実装形態では、マルチタスキングおよび並列処理が有利であり得る。 Thus, specific embodiments of the subject matter have been described. Other embodiments are within the scope of the following claims. In some cases, the actions recited in the claims may be performed in a different order and still achieve desirable results. Additionally, the processes illustrated in the accompanying figures do not necessarily require the particular order shown or sequential order to achieve desirable results. Multitasking and parallel processing may be advantageous in some implementations.
100 環境
102 ネットワーク
104 コンテンツサーバ
106 クライアントデバイス
107 ユーザアプリケーション、ブラウザベースのアプリケーション
108 デジタルコンポーネントサーバ
110 デジタルコンポーネント配信システム
112 デジタルコンポーネントを求める要求、デジタルコンポーネント要求、コンポーネント要求
114 複数のコンピューティングデバイスのセット、セット
117a～117c タスク
118a～118c 結果(Res 1～Res 3)、結果
120 応答データ
121 サーバ要求(SR)、サーバ要求
122 デジタルコンポーネントデータ
150 検索システム
152 検索インデックス
170 ユーザ評価装置
202 ユーザグループ識別子(ユーザグループID)
204 他の情報
205 入力、入力特徴
210 入力、入力特徴
220 特性1モデル、サブモデル、サブ機械学習モデル
230 特性2モデル、サブモデル、サブ機械学習モデル
240 特性3モデル、サブモデル、サブ機械学習モデル
252 予測された特性1
254 予測された特性2
256 予測された特性3
300 プロセス
400 コンピュータシステム、システム
410 プロセッサ、構成要素
420 メモリ、構成要素
430 記憶デバイス、構成要素
440 入力/出力デバイス、構成要素
450 システムバス
460 キーボード、プリンタおよびディスプレイデバイス
100 environment
102 network
104 Content Server
106 client devices
107 User application, browser-based application
108 Digital Component Server
110 Digital Component Distribution System
112 Request for Digital Components, Digital Component Request, Component Request
114 sets of computing devices, sets
117a-117c tasks
118a-118c Result (Res 1-Res 3), Result
120 response data
121 Server Request (SR), Server Request
122 digital component data
150 search system
152 search index
170 User Evaluation Device
202 User Group Identifier (User Group ID)
204 Other information
205 input, input features
210 input, input features
220
230
240 trait 3 model, sub-model, sub-machine learning model
252
254
256 Predicted Trait 3
300 processes
400 computer system, system
410 processor, building blocks
420 memory, components
430 storage devices, components
440 Input/Output Devices, Components
450 system bus
460 keyboards, printers and display devices
Claims (24)
すべてが同じユーザグループ識別子によって表されるユーザの異なるサブグループ間での前記性能の尺度の差を低減する追加項を前記損失関数に追加することを含む、前記損失関数を変更するステップであって、前記ユーザの異なるサブグループの中の各ユーザサブグループが、前記ユーザの異なるサブグループの中の他のサブグループの特性とは異なる特性を有する、ステップと、
前記変更された損失関数を使用して前記モデルを訓練するステップと、
デジタルコンポーネントを求める要求をクライアントデバイスから受信するステップであって、前記要求が、ユーザの異なるグループの中の特定のユーザグループのための所与のユーザグループ識別子を含む、ステップと、
前記訓練されたモデルを前記要求に含まれる情報に適用することによって、前記要求に含まれていない1つまたは複数のユーザ特性を生成するステップと、
前記訓練されたモデルによって生成された前記1つまたは複数のユーザ特性に基づいて1つまたは複数のデジタルコンポーネントを選択するステップと、
前記選択された1つまたは複数のデジタルコンポーネントを前記クライアントデバイスに伝送するステップと
を含むコンピュータ実装方法。 identifying, for a model to be trained, a loss function that produces a loss representing a measure of performance that the model seeks to optimize during training;
modifying the loss function comprising adding additional terms to the loss function that reduce differences in the performance measure between different subgroups of users all represented by the same user group identifier; , each user subgroup in the different subgroups of users has characteristics that are different from the characteristics of other subgroups in the different subgroups of users;
training the model using the modified loss function;
receiving a request from a client device for a digital component, said request including a given user group identifier for a particular user group among different groups of users;
applying the trained model to information included in the request to generate one or more user characteristics not included in the request;
selecting one or more digital components based on the one or more user characteristics generated by the trained model;
and transmitting said selected one or more digital components to said client device.
すべてが同じユーザグループ識別子によって表されるユーザの異なるサブグループ間での前記性能の尺度の差を低減する追加項を前記損失関数に追加することを含む、前記損失関数を変更することであって、前記ユーザの異なるサブグループの中の各ユーザサブグループが、前記ユーザの異なるサブグループの中の他のサブグループの特性とは異なる特性を有する、変更することと、
前記変更された損失関数を使用して前記モデルを訓練することと、
デジタルコンポーネントを求める要求をクライアントデバイスから受信することであって、前記要求が、ユーザの異なるグループの中の特定のユーザグループのための所与のユーザグループ識別子を含む、受信することと、
前記訓練されたモデルを前記要求に含まれる情報に適用することによって、前記要求に含まれていない1つまたは複数のユーザ特性を生成することと、
前記訓練されたモデルによって生成された前記1つまたは複数のユーザ特性に基づいて1つまたは複数のデジタルコンポーネントを選択することと、
前記選択された1つまたは複数のデジタルコンポーネントを前記クライアントデバイスに伝送することと
を含むシステム。 identifying, for a model to be trained, a loss function that produces a loss representing a measure of performance that the model seeks to optimize during training;
modifying the loss function, comprising adding an additional term to the loss function that reduces differences in the performance measure between different subgroups of users all represented by the same user group identifier; , each user subgroup within the different subgroups of users has characteristics that are different from the characteristics of other subgroups within the different subgroups of users;
training the model using the modified loss function;
receiving a request from a client device for a digital component, the request including a given user group identifier for a particular user group among different groups of users;
applying the trained model to information included in the request to generate one or more user characteristics not included in the request;
selecting one or more digital components based on the one or more user characteristics generated by the trained model;
and transmitting the selected one or more digital components to the client device.
訓練されるべきモデルについて、前記モデルが訓練中に最適化しようとする性能の尺度を表す損失を生成する損失関数を識別することと、
すべてが同じユーザグループ識別子によって表されるユーザの異なるサブグループ間での前記性能の尺度の差を低減する追加項を前記損失関数に追加することを含む、前記損失関数を変更することであって、前記ユーザの異なるサブグループの中の各ユーザサブグループが、前記ユーザの異なるサブグループの中の他のサブグループの特性とは異なる特性を有する、変更することと、
前記変更された損失関数を使用して前記モデルを訓練することと、
デジタルコンポーネントを求める要求をクライアントデバイスから受信することであって、前記要求が、ユーザの異なるグループの中の特定のユーザグループのための所与のユーザグループ識別子を含む、受信することと、
前記訓練されたモデルを前記要求に含まれる情報に適用することによって、前記要求に含まれていない1つまたは複数のユーザ特性を生成することと、
前記訓練されたモデルによって生成された前記1つまたは複数のユーザ特性に基づいて1つまたは複数のデジタルコンポーネントを選択することと、
前記選択された1つまたは複数のデジタルコンポーネントを前記クライアントデバイスに伝送することと
を含む動作を実施させる、コンピュータ可読記憶媒体。 A computer-readable storage medium storing instructions which, when executed by the one or more data processing devices, causes the one or more data processing devices to:
identifying, for a model to be trained, a loss function that produces a loss representing a measure of performance that the model seeks to optimize during training;
modifying the loss function, comprising adding an additional term to the loss function that reduces differences in the performance measure between different subgroups of users all represented by the same user group identifier; , each user subgroup within the different subgroups of users has characteristics that are different from the characteristics of other subgroups within the different subgroups of users;
training the model using the modified loss function;
receiving a request from a client device for a digital component, the request including a given user group identifier for a particular user group among different groups of users;
applying the trained model to information included in the request to generate one or more user characteristics not included in the request;
selecting one or more digital components based on the one or more user characteristics generated by the trained model;
transmitting the selected one or more digital components to the client device.
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/US2020/053378 WO2022071929A1 (en) | 2020-09-30 | 2020-09-30 | Robust model performance across disparate sub-groups within a same group |
Publications (2)
Publication Number | Publication Date |
---|---|
JP2023500753A JP2023500753A (en) | 2023-01-11 |
JP7230231B2 true JP7230231B2 (en) | 2023-02-28 |
Family
ID=72964794
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2021553092A Active JP7230231B2 (en) | 2020-09-30 | 2020-09-30 | Robust model performance across heterogeneous subgroups within the same group |
Country Status (5)
Country | Link |
---|---|
US (1) | US20230222377A1 (en) |
EP (1) | EP3997624A1 (en) |
JP (1) | JP7230231B2 (en) |
CN (1) | CN114600125A (en) |
WO (1) | WO2022071929A1 (en) |
Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20160232575A1 (en) | 2015-02-06 | 2016-08-11 | Facebook, Inc. | Determining a number of cluster groups associated with content identifying users eligible to receive the content |
JP2018142294A (en) | 2017-02-28 | 2018-09-13 | 富士ゼロックス株式会社 | System and method that use deep learning to identify purchase stage from microblogging posting, program, and server device |
WO2020070834A1 (en) | 2018-10-03 | 2020-04-09 | 株式会社島津製作所 | Learned-model producing method, brightness adjusting method, and image processing device |
Family Cites Families (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN107679920A (en) * | 2017-10-20 | 2018-02-09 | 北京奇艺世纪科技有限公司 | The put-on method and device of a kind of advertisement |
-
2020
- 2020-09-30 EP EP20793856.4A patent/EP3997624A1/en active Pending
- 2020-09-30 CN CN202080019637.9A patent/CN114600125A/en active Pending
- 2020-09-30 WO PCT/US2020/053378 patent/WO2022071929A1/en unknown
- 2020-09-30 US US17/434,849 patent/US20230222377A1/en active Pending
- 2020-09-30 JP JP2021553092A patent/JP7230231B2/en active Active
Patent Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20160232575A1 (en) | 2015-02-06 | 2016-08-11 | Facebook, Inc. | Determining a number of cluster groups associated with content identifying users eligible to receive the content |
JP2018142294A (en) | 2017-02-28 | 2018-09-13 | 富士ゼロックス株式会社 | System and method that use deep learning to identify purchase stage from microblogging posting, program, and server device |
WO2020070834A1 (en) | 2018-10-03 | 2020-04-09 | 株式会社島津製作所 | Learned-model producing method, brightness adjusting method, and image processing device |
Also Published As
Publication number | Publication date |
---|---|
US20230222377A1 (en) | 2023-07-13 |
CN114600125A (en) | 2022-06-07 |
WO2022071929A1 (en) | 2022-04-07 |
EP3997624A1 (en) | 2022-05-18 |
JP2023500753A (en) | 2023-01-11 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US7739314B2 (en) | Scalable user clustering based on set similarity | |
US11276076B2 (en) | Method and system for generating a digital content recommendation | |
RU2731335C2 (en) | Method and system for generating recommendations of digital content | |
US11551281B2 (en) | Recommendation engine based on optimized combination of recommendation algorithms | |
AU2017301075B2 (en) | Optimized digital component analysis system | |
US11544767B2 (en) | Recommendation system with implicit feedback | |
US20240054392A1 (en) | Transfer machine learning for attribute prediction | |
JP7230231B2 (en) | Robust model performance across heterogeneous subgroups within the same group | |
US20220414247A1 (en) | Secured management of data distribution restrictions | |
JP7237194B2 (en) | Privacy-preserving machine learning predictions | |
US20140108591A1 (en) | Methods And Systems For Delivering Individualized Content | |
US20230259815A1 (en) | Machine learning techniques for user group based content distribution | |
JP7223164B2 (en) | Data integrity optimization | |
US20240160678A1 (en) | Distributing digital components based on predicted attributes | |
US20230177543A1 (en) | Privacy preserving machine learning expansion models | |
WO2024039474A1 (en) | Privacy sensitive estimation of digital resource access frequency | |
WO2023234938A1 (en) | Distributing digital components based on predicted attributes | |
WO2024086256A1 (en) | Privacy sensitive estimation of digital resource access frequency |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20210928 |
|
A621 | Written request for application examination |
Free format text: JAPANESE INTERMEDIATE CODE: A621Effective date: 20210928 |
|
TRDD | Decision of grant or rejection written | ||
A01 | Written decision to grant a patent or to grant a registration (utility model) |
Free format text: JAPANESE INTERMEDIATE CODE: A01Effective date: 20230116 |
|
A61 | First payment of annual fees (during grant procedure) |
Free format text: JAPANESE INTERMEDIATE CODE: A61Effective date: 20230215 |
|
R150 | Certificate of patent or registration of utility model |
Ref document number: 7230231Country of ref document: JPFree format text: JAPANESE INTERMEDIATE CODE: R150 |