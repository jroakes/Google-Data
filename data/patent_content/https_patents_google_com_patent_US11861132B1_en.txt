US11861132B1 - Identifying and rendering content relevant to a user's current mental state and context - Google Patents
Identifying and rendering content relevant to a user's current mental state and context Download PDFInfo
- Publication number
- US11861132B1 US11861132B1 US17/833,061 US202217833061A US11861132B1 US 11861132 B1 US11861132 B1 US 11861132B1 US 202217833061 A US202217833061 A US 202217833061A US 11861132 B1 US11861132 B1 US 11861132B1
- Authority
- US
- United States
- Prior art keywords
- user
- media
- current
- state
- context
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
- 238000009877 rendering Methods 0.000 title abstract description 33
- 230000006996 mental state Effects 0.000 title abstract description 30
- 238000000034 method Methods 0.000 claims abstract description 52
- 238000012545 processing Methods 0.000 claims description 8
- 238000010801 machine learning Methods 0.000 claims description 4
- 238000013500 data storage Methods 0.000 claims 2
- 230000036651 mood Effects 0.000 abstract description 52
- 238000003860 storage Methods 0.000 description 24
- 238000004891 communication Methods 0.000 description 14
- 230000033001 locomotion Effects 0.000 description 14
- 238000010586 diagram Methods 0.000 description 11
- 230000008569 process Effects 0.000 description 10
- 230000003993 interaction Effects 0.000 description 9
- 230000000694 effects Effects 0.000 description 8
- 239000002609 medium Substances 0.000 description 8
- 238000005516 engineering process Methods 0.000 description 7
- 230000007246 mechanism Effects 0.000 description 7
- 230000009471 action Effects 0.000 description 6
- 230000001413 cellular effect Effects 0.000 description 6
- 238000004458 analytical method Methods 0.000 description 5
- 235000021152 breakfast Nutrition 0.000 description 5
- 235000013410 fast food Nutrition 0.000 description 5
- 230000004044 response Effects 0.000 description 5
- 238000007792 addition Methods 0.000 description 4
- 230000006870 function Effects 0.000 description 4
- 238000007726 management method Methods 0.000 description 4
- 230000003252 repetitive effect Effects 0.000 description 4
- 238000012706 support-vector machine Methods 0.000 description 4
- 230000006399 behavior Effects 0.000 description 3
- 230000000977 initiatory effect Effects 0.000 description 3
- 238000004519 manufacturing process Methods 0.000 description 3
- 230000002040 relaxant effect Effects 0.000 description 3
- 230000008439 repair process Effects 0.000 description 3
- 238000012546 transfer Methods 0.000 description 3
- 238000013528 artificial neural network Methods 0.000 description 2
- 230000008901 benefit Effects 0.000 description 2
- 230000008859 change Effects 0.000 description 2
- 230000000875 corresponding effect Effects 0.000 description 2
- 238000013461 design Methods 0.000 description 2
- 238000009826 distribution Methods 0.000 description 2
- 230000005055 memory storage Effects 0.000 description 2
- 238000012986 modification Methods 0.000 description 2
- 230000004048 modification Effects 0.000 description 2
- 230000003287 optical effect Effects 0.000 description 2
- 230000002093 peripheral effect Effects 0.000 description 2
- 229920001690 polydopamine Polymers 0.000 description 2
- 230000003068 static effect Effects 0.000 description 2
- RYGMFSIKBFXOCR-UHFFFAOYSA-N Copper Chemical compound [Cu] RYGMFSIKBFXOCR-UHFFFAOYSA-N 0.000 description 1
- 230000004075 alteration Effects 0.000 description 1
- 238000013459 approach Methods 0.000 description 1
- 230000005540 biological transmission Effects 0.000 description 1
- 238000004422 calculation algorithm Methods 0.000 description 1
- 238000013145 classification model Methods 0.000 description 1
- 238000004140 cleaning Methods 0.000 description 1
- 230000000295 complement effect Effects 0.000 description 1
- 238000004590 computer program Methods 0.000 description 1
- 238000010276 construction Methods 0.000 description 1
- 230000001276 controlling effect Effects 0.000 description 1
- 229910052802 copper Inorganic materials 0.000 description 1
- 239000010949 copper Substances 0.000 description 1
- 230000002596 correlated effect Effects 0.000 description 1
- 230000001186 cumulative effect Effects 0.000 description 1
- 238000003066 decision tree Methods 0.000 description 1
- 230000009977 dual effect Effects 0.000 description 1
- 230000008451 emotion Effects 0.000 description 1
- 230000002996 emotional effect Effects 0.000 description 1
- 239000000835 fiber Substances 0.000 description 1
- 230000004927 fusion Effects 0.000 description 1
- 230000036541 health Effects 0.000 description 1
- 230000002045 lasting effect Effects 0.000 description 1
- 230000008450 motivation Effects 0.000 description 1
- 239000013307 optical fiber Substances 0.000 description 1
- 238000011160 research Methods 0.000 description 1
- 239000007787 solid Substances 0.000 description 1
- 235000015096 spirit Nutrition 0.000 description 1
- 230000001360 synchronised effect Effects 0.000 description 1
- 230000002123 temporal effect Effects 0.000 description 1
- 238000012360 testing method Methods 0.000 description 1
- 238000012549 training Methods 0.000 description 1
- 230000009466 transformation Effects 0.000 description 1
- 238000000844 transformation Methods 0.000 description 1
- 230000007704 transition Effects 0.000 description 1
- 230000007723 transport mechanism Effects 0.000 description 1
- 239000006163 transport media Substances 0.000 description 1
Images
Classifications
-
- G—PHYSICS
- G16—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR SPECIFIC APPLICATION FIELDS
- G16H—HEALTHCARE INFORMATICS, i.e. INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR THE HANDLING OR PROCESSING OF MEDICAL OR HEALTHCARE DATA
- G16H50/00—ICT specially adapted for medical diagnosis, medical simulation or medical data mining; ICT specially adapted for detecting, monitoring or modelling epidemics or pandemics
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
-
- A—HUMAN NECESSITIES
- A61—MEDICAL OR VETERINARY SCIENCE; HYGIENE
- A61B—DIAGNOSIS; SURGERY; IDENTIFICATION
- A61B5/00—Measuring for diagnostic purposes; Identification of persons
- A61B5/103—Detecting, measuring or recording devices for testing the shape, pattern, colour, size or movement of the body or parts thereof, for diagnostic purposes
- A61B5/11—Measuring movement of the entire body or parts thereof, e.g. head or hand tremor, mobility of a limb
-
- A—HUMAN NECESSITIES
- A61—MEDICAL OR VETERINARY SCIENCE; HYGIENE
- A61B—DIAGNOSIS; SURGERY; IDENTIFICATION
- A61B5/00—Measuring for diagnostic purposes; Identification of persons
- A61B5/16—Devices for psychotechnics; Testing reaction times ; Devices for evaluating the psychological state
- A61B5/165—Evaluating the state of mind, e.g. depression, anxiety
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0481—Interaction techniques based on graphical user interfaces [GUI] based on specific properties of the displayed interaction object or a metaphor-based environment, e.g. interaction with desktop elements like windows or icons, or assisted by a cursor's changing behaviour or appearance
-
- G—PHYSICS
- G16—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR SPECIFIC APPLICATION FIELDS
- G16H—HEALTHCARE INFORMATICS, i.e. INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR THE HANDLING OR PROCESSING OF MEDICAL OR HEALTHCARE DATA
- G16H10/00—ICT specially adapted for the handling or processing of patient-related medical or healthcare data
- G16H10/60—ICT specially adapted for the handling or processing of patient-related medical or healthcare data for patient-specific data, e.g. for electronic patient records
-
- A—HUMAN NECESSITIES
- A61—MEDICAL OR VETERINARY SCIENCE; HYGIENE
- A61B—DIAGNOSIS; SURGERY; IDENTIFICATION
- A61B5/00—Measuring for diagnostic purposes; Identification of persons
- A61B5/103—Detecting, measuring or recording devices for testing the shape, pattern, colour, size or movement of the body or parts thereof, for diagnostic purposes
- A61B5/11—Measuring movement of the entire body or parts thereof, e.g. head or hand tremor, mobility of a limb
- A61B5/1123—Discriminating type of movement, e.g. walking or running
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F13/00—Interconnection of, or transfer of information or other signals between, memories, input/output devices or central processing units
Definitions
- This application generally relates to systems and methods for identifying and rendering content relevant to a user's current mental state and context.
- Various content providers and advertisers often determine content to suggest to a user or advertisements to show to the user during a current session with the content provider based on historical analysis of the user's previous history with the content provider and/or other content providers. For example, when browsing the Internet, some advertisement systems will present the user with advertisements for content the user viewed/accessed in a previous browsing session or content similar to what they viewed or accessed in a previous session. These advertisement systems generally analyze various signals from the user's previous browsing sessions before the user begins a future browsing session to determine advertisement content to show the user in the user's future browsing session. However this advertisement content may not be relevant to the when the user begins the future browsing session for a variety of reasons.
- FIG. 1 illustrates an example system for identifying content relevant to a user's current mental state and context in accordance with various aspects and embodiments described herein;
- FIG. 2 presents an example system for identifying and rendering content relevant to a user's current mental state and context in accordance with various aspects and embodiments described herein;
- FIG. 3 presents another example system for identifying and rendering content relevant to a user's current mental state and context in accordance with various aspects and embodiments described herein;
- FIG. 4 presents another example system for identifying and rendering content relevant to a user's current mental state and context in accordance with various aspects and embodiments described herein;
- FIG. 5 presents another example system for identifying and rendering content relevant to a user's current mental state and context in accordance with various aspects and embodiments described herein;
- FIG. 6 illustrates an example flow diagram of an example method for identifying and rendering content relevant to a user's current mental state and context in accordance with various aspects and embodiments described herein;
- FIG. 7 illustrates another example flow diagram of an example method for identifying and rendering content relevant to a user's current mental state and context in accordance with various aspects and embodiments described herein;
- FIG. 8 illustrates another example flow diagram of an example method for identifying and rendering content relevant to a user's current mental state and context in accordance with various aspects and embodiments described herein;
- FIG. 9 is a schematic block diagram illustrating a suitable operating environment in accordance with various aspects and embodiments.
- FIG. 10 is a schematic block diagram of a sample-computing environment in accordance with various aspects and embodiments.
- the subject disclosure relates to dynamically determining or inferring content, provided by a content provider (e.g., via a network based platform such as a website or mobile application), that a user will be most receptive to at any given point during a current interaction session with the content provider based on the context and state of the user during the current session.
- a content provider e.g., via a network based platform such as a website or mobile application
- Various content providers and advertisers often determine content to suggest to a user or advertisements to show to the user during a current session with the content provider based on historical analysis of the user's previous history with the content provider and/or other content providers. For example, when browsing the Internet, some advertisement systems will present the user with advertisements for content they viewed/accessed in a previous session or content similar to what they viewed or accessed in a previous session.
- the subject disclosure employs a variety to signals received or extracted during a user's current session with a content provider to determine or infer a context of the current session and the user's mental state during the current session. These signals are then used to identify content that the user will be most receptive to at any given point during the current session.
- user research has shown that users are in different ‘modes’ according to various dynamic factors such as time of day, what device they are on, what brought them to a particular a particular content provider's website/application, where the user is located (e.g., home vs.
- the user's state of mind can also influence characteristics of content that the user will be most receptive to during a current session. For example, media content (e.g., images, video, music, etc.) can evict various user emotions. When a user's current frame of mind or mood can be discerned, media content can be identified and provided to the user the reflects or effects the user's mood. Accordingly, systems and mechanisms are provided that will take into account various factors related to a user's mental state and context during a current session of the user with a content provider to determine or infer a particular content item to render to the user during the current session.
- media content e.g., images, video, music, etc.
- the disclosed techniques are specifically tailored to determine or infer media content that a user will be most receptive to engage with during a current session with a streaming media provider that offers a wide array of different media content of various types and durations for access by the user.
- the specific media items that a user selects to view or listen to and the manner in which the user engages with media items selected by the user or pushed to the user can provide a strong indication of a user's mental state. For example, when a user is accessing and/or searching for short clips of funny videos, it can be inferred that the user is in a joyful, leisurely state of mind. This information coupled with information related to the context of the current session can provide even greater insight into the user's state of mind.
- the determination that the user is in a joyful and leisurely state of mind can be held with greater confidence when it is also determined that the user is at a party sharing the videos with friends.
- the specific content of the funny videos e.g., the plot, the characters, the script, the setting, etc.
- a user when a user is searching for videos related to information on a specific technical subject, it can be determined that the user's frame mind is focused, diligent, serious, etc.
- the user's frame of mind can further be discerned depending on the time of day, location of the user, the user's profession and the specific technical subject searched. For example, the user's intentions and concerns may vary if the technical subject is related to work aspects or personal aspects. Further, the user's navigational tactics can indicate the user's intention of the current session and the user's state of mind regarding fulfilling the intention.
- a method includes using a processor to execute computer executable instructions stored in a memory to perform various acts. These acts can include: determining user state attributes associated with a user's current state of mind during a current session of the user with a streaming media provider based on at least one of: navigation of the streaming media provider by the user during the current session, media items provided by the streaming media provider that are played during the current session, or a manner via which the user interacts with or reacts to the played media items, wherein the state of the user includes a mood of the user; selecting a media item provided by the streaming media provider based on the user state attributes; and rendering the media item to the user during the current session
- a tangible computer-readable storage medium comprising computer-readable instructions that, in response to execution, cause a computing system to perform various operations. These operations include determining mood attributes associated with a user's current mood during a session of the user with a streaming media provider and determining context attributes associated with a current context of the session based on at least one of: navigation of the streaming media provider by the user during the current session, media items provided by the streaming media provider that are played during the current session, or an environment of the user. The operations further include, selecting a media item provided by the streaming media provider based on the mood attributes and the context attributes, and rendering the media item to the user during the session.
- FIG. 1 presented is diagram of an example system 100 for identifying and rendering content relevant to a user's current mental state and context in accordance with various aspects and embodiments described herein.
- Aspects of systems, apparatuses or processes explained in this disclosure can constitute machine-executable components embodied within machine(s), e.g., embodied in one or more computer readable ediums (or media) associated with one or more machines. Such components, when executed by the one or more machines, e.g., computer(s), computing device(s), virtual machine(s), etc. can cause the machine(s) to perform the operations described.
- System 100 includes at least a content provider 102 and a client device 122 wherein the content provider is configured to provide content to a user of the client device 122 via one or more networks 120 using a network based platform (e.g., a website or mobile application).
- the content provider 102 can include dynamic content selection platform 104 to determine or infer characteristics of a user's current mental state and context during a session of the user with the content provider and to identify other content (e.g., an advertisement, a suggested content item, etc.) that is relevant to the user's current mental state and context.
- the dynamic content selection platform 104 can then facilitate rendering of the identified other content to the user by the content provider 102 during the current session. For example, when the other content is an advertisement, dynamic content selection platform 104 can direct content provider 102 to provide the advertisement to the user during the user's current session.
- the various components and devices of system 100 can be connected either directly or via one or more networks 120 .
- networks can include wired and wireless networks, including but not limited to, a cellular network, a wide area network (WAD, e.g., the Internet), a local area network (LAN), or a personal area network (PAN).
- client device 122 can communicate with content provider 102 (and vice versa) using virtually any desired wired or wireless technology, including, for example, cellular, WAN, wireless fidelity (Wi-Fi), Wi-Max, WLAN, and etc.
- one or more components of system 100 are configured to interact via disparate networks.
- dynamic content selection platform 104 is depicted as being internal to content provider 102 , one or more aspects of dynamic content selection platform 104 can be provided locally at client device 122 .
- content provider 102 can include an application service provider and client device 122 can employ a thin client application to interact with and receive various content and services provided by the content provider.
- the thin client application provided on the client device 122 can include one or more components (e.g., reception component 106 , state component 108 , context component 112 , etc.) of dynamic content selection platform 104 .
- Content provider 102 can include an entity configured to provide content and/or services to a user at a client device (e.g., client device 120 ) via a network (e.g., the Internet).
- content provider 102 can include a website or application service provider configured to provide videos, pictures, articles, blogs, messages, services, etc. or other types of content items to client devices via a network.
- the content provided by the web site or application can be configured for downloading, streaming or merely viewing at a client device 122 via the network.
- content provider 102 can include a information store that provides access to data included in the information store via a network.
- content provider 102 can include an online merchant that provides goods and services.
- a channel can include data content available from a common source or data content having a common topic or theme.
- a channel can be associated with a curator who can perform management actions on the channel. Management actions can include, for example, adding media items to the channel, removing media items from the channel, defining subscription requirements for the channel, defining presentation attributes for channel content, defining access attributes for channel content, etc.
- this curator constitutes the channel owner or channel creator and the channel itself can be considered a content or media item owned or created by the channel owner.
- channel content can include digital content uploaded to an Internet-based content platform that hosts the channel (e.g., content provider 102 ) by the channel curator and/or digital content selected by the channel curator from other content available on the Internet-based content platform.
- a channel curator can include a professional content provider (e.g., a professional content creator, a professional content distributor, a content rental service, a television (TV) service, etc.) or an amateur individual.
- Channel content can include professional content (e.g., movie clips, TV clips, music videos, educational videos) and/or amateur content (e.g., video blogging, short original videos, etc.).
- Users, other than the curator of the channel can subscribe to one or more channels in which they are interested. Users in addition to the channel curator can access content provided by a channel.
- content provider 102 includes a streaming media provider configured to provide streaming media and related services to client devices over a network.
- content provider 102 can include a media provider that has access to a voluminous quantity (and potentially an inexhaustible number) of shared media (e.g., video and/or audio) files.
- the media provider can further stream these media files to one or more users at respective client devices (e.g., clients 122 ) of the one or more users over a network.
- the media can be stored in memory associated with the media provider (e.g., memory 116 ) and/or at various servers and caches employed by media provider and accessed by client devices using a networked platform (e.g., a website platform, a mobile application) employed by the media provider.
- a networked platform e.g., a website platform, a mobile application
- the media provider can provide and present media content to a user via a website that can be accessed by a client device using a browser.
- the media provider can provide and present media to a user via a mobile/cellular application provided on a client device (e.g., where the client device is a smartphone or the like).
- Client device 122 can include presentation component 124 to generate a user interface (e.g., a graphical user interface or virtual interface) that displays media content provided by the media provider to a user of the client device.
- presentation component 124 can include an application (e.g., a web browser) for retrieving, presenting and traversing information resources on the World Wide Web.
- the media provider can provide and/or present media content to a client device 122 via a website that can be accessed using a browser of the client device 122 .
- the media provider can provide and/or present media content to a client device 122 via a mobile application platform.
- presentation component 124 can employ a client application version of the media provider that that can access the cellular application platform of the media provider.
- the media content can be presented and/or played at client device 122 using a video player associated with the media provider and/or the client device 122 .
- Client device 122 can include any suitable computing device associated with a user and configured to interact with content provider 102 via a network.
- client device 122 can include a desktop computer, a laptop computer, a television, an Internet enabled television, a mobile phone, a smartphone, a tablet personal computer (PC), a personal digital assistant PDA, or a wearable device.
- content consumer or “user” refer to a person, entity, system, or combination thereof that employs system 100 (or additional systems described in this disclosure) using a client device 122 .
- dynamic content selection platform 104 includes a streaming media provider (as described herein). Accordingly, dynamic contribution platform 104 is discussed in association with determining or inferring, in real-time or substantially real time, media content (e.g., media advertisement, video trailers, channel trailers, other videos provided by the media provider etc.) that is relevant to a user during the user's current session with the media provider.
- media content e.g., media advertisement, video trailers, channel trailers, other videos provided by the media provider etc.
- dynamic content selection platform 104 can be employed by a variety of content providers and systems to determine or infer content for provision to a user (e.g., advertisements, recommended content) that is relevant to the user's context and mental state at the time of rendering of the content.
- dynamic content selection platform 104 can include reception component 106 , state component 108 , context component 110 and selection component 112 .
- Reception component 106 is configured to receive and/or extract information in association with a user's current session with content provider 102 that can be employed to determine or infer attributes of the user's current mental state and context. For example, when a user conducts a session with a streaming media provider that includes navigating and consuming media content provided by the streaming media provider, reception component 106 can receive or extract information about the user's current session that relates to the user's state of mind and context. Based on this information, state component 108 is configured to determine a state of the user and context component 110 is configured to determine a context of the user and/or the current session. Selection component 112 can then determine or infer advertisements, video trailers, channel trailers, and/or other media that the user is likely to be most receptive to during the current session based on the user's state and context.
- reception component 106 can receive information regarding the manner in which the user navigates the media provider's content (e.g., searching via key word search, searching within a specific media category or channel, browsing, following recommendations, etc.), the specific content accessed and viewed by the user, and the manner in which the user interacts with the content selected by the user for viewing or pushed upon the user (e.g., watching or dismissing a video, controlling the playing of the video, commenting about the video, liking or disliking the video, sharing the video, having the video visible, having the volume of the video audible, interaction with the interface via which the video is included as based on cursor movement or touch screen interaction, etc.).
- Reception component 106 can also receive information regarding the watch history of the user during the current session, including durations of media items selected for watching or listening to by the user and respective amounts of the media items actually watched or listened to by the user.
- information regarding a user's navigation of a media provider, content accessed and viewed/watched, and the manner in which the user interacts with the content can be extracted in real-time as it is generated at the media provider during the user's session.
- signals regarding user interaction and engagement with the media provider during a current session can be collected at client device 122 via a signal collection component 126 and provided to reception component 106 during the course of the user's session (e.g., in real-time, in substantially real-time, or periodically).
- signal collection component 126 can receive signals regarding cursor movement, interaction by the user with a graphical user interface via which the media provider's content is accessed, interaction and control of a media player via which video and/or audio content provided by the media provider is played, visibility of media played during a current session at the client device 122 (e.g., whether the media player is minimized/maximized, whether the media player is behind another tab or window, etc.), and volume of media played during the current session.
- reception component 106 can receive information regarding a mechanism via which the current session was initiated (e.g., in response to a general request by the user to open the network based platform of the streaming media provider, or in response to selection of a link to media content, provided by the streaming media provider, at an external source 128 or received by the user in an electronic message).
- reception component 106 can receive information identifying the specific media item represented by a selected link, the referral source at which the link was located (e.g., an external source 128 ), and information about the referral source. This information can be provided by the referring source, the client device 122 and/or identified by reception component 106 via metadata associated with the selected link and/or the referral source.
- reception component 106 can receive information about the content of a web site or webpage at which the link was located. This information can provide insight into what mood the user was in at the time of selection of the link.
- Reception component 106 can also receive information related to the user's environment during a current session (e.g., including location, other people and things at the location, activities or events occurring at the location, etc.), what the user is doing in the environment in association with the current session, time of day of the current session, the type of device the user is employing to conduct the current session (e.g., mobile, stationary, tablet, phone, desktop, etc.).
- client device 122 and other clients 130 as well
- can determine its location e.g., via a global positioning system method, triangulation, or any other suitable locating technique) and provide this location information to reception component 106 over the course of the current session.
- an external source e.g., a cellular carrier system
- reception component 106 can look up information about the location (e.g., places and things associated with the location, events associated with the location, other clients 130 /users at the location, weather at the location, traffic at the location etc.).
- information regarding a user's environment can be captured and provided to reception component 106 via an auxiliary input device 132 .
- information regarding what a user is doing in association with a current session can be received by reception component 106 from a user's schedule (e.g., provided on client device 122 or at an external source 128 ).
- information regarding a user's movement and motion can be captured by various motion sensors employed by the user (e.g., worn by the user) and/or provided at client device (e.g., an accelerometer, gyroscope). This motion/movement information can facilitate determining (e.g., by reception component, dynamic content selection platform 104 and/or another system), what the user is doing (e.g., walking, running, sitting, driving a car, etc.) and where the user is going.
- dynamic content selection platform 104 and/or another system can learn user patterns and behaviors over time based on where the user goes, what the user does, who the user is with, the user's schedule, etc. to determine or infer what the user is doing during a current session.
- reception component 106 can also receive information related to what the user was doing before initiation of a current session (e.g., where the user was, an activity the user was performing, etc.), an amount of time the user has for conducting the current session (e.g., the user has a one hour lunch break during after which the user must return to work and end the current session), and what the user is likely to do or scheduled to do after the current session (e.g., return to work, attend an event, etc.), based on the user's schedule and/or learned user behaviors/patterns.
- information related to what the user was doing before initiation of a current session e.g., where the user was, an activity the user was performing, etc.
- an amount of time the user has for conducting the current session e.g., the user has a one hour lunch break during after which the user must return to work and end the current session
- what the user is likely to do or scheduled to do after the current session e.g., return to work, attend an event, etc.
- Reception component 106 can also receive information about other users activity with content provider 102 during a user's current session with the content provider, wherein the other users have some connection with the user (e.g., a social connection, a shared preference, a shared demographic feature, etc.). For example, media content that is being watched, liked, shared, etc., by a user's friends at a streaming media provider while the user is conducting a current session with the streaming media provider can influence what content the user may also be interested in during the user's current session. According to this example, when a bunch of the user's friends are conducting sessions with the streaming media provider at the same time as the user and watching a particular live sports video, it can be assumed that the user would likely be interested in watching the sports video as well. Accordingly the live sports video can be recommended to the user during the user's current session.
- a bunch of the user's friends are conducting sessions with the streaming media provider at the same time as the user and watching a particular live sports video, it can be assumed that the user would likely be interested
- State component 108 is configured to determine or infer state of mind attributes associated with a user's current state of mind during a session with a content provider 102 (e.g., a streaming media provider) based on information received by reception component 106 .
- a user's state of mind can include aspects related to what the user is thinking and/or feeling during a current session.
- state of mind attributes can correspond to aspects of a user's mood or attitude during a current session.
- a user's state of mind can also reflect a user's conscious or subconscious intention for performing or conducting a session with a streaming media provider.
- a user's mood can indicate whether the user wants to be entertained, whether the user is in an educational frame of mind, or whether the user is in a work frame of mind.
- a user's state of mind can include a level of engagement a user has with a particular content item such as a video or song (e.g., whether the user is actively attentive towards the content item or passively engaged with the content item).
- state component 108 can determine state attributes representative of a user's current state of mind during a session with a content provider 102 based on how the user navigates about content provided by the content provider 102 . For example, state component 108 can determine attributes about a user's state of mind based on how the user navigates about a media provider's website (e.g., what categories the user's selects, how the user moves from one interface to another, how the user influence what media items are presented on a particular interface, whether the user is searching or browsing, etc.).
- State component 108 can also determine state attributes based on media items, provided by the media provider, that are played for watching by the user during the current session (e.g., either in response to selection by the user or automatically played/pushed to the user), and a manner via which the user interacts with or reacts to the played media items.
- state attributes for the user could include ‘happy,’ ‘joyful,’ entertainment mode,’ ‘humorous content,’ and ‘light hearted.’
- state component 108 can determine the user is in a relaxed mood.
- state component 108 can determine whether the user is looking to be entertained and how or whether the user is looking for informational/instructional content. For instance, when a user is selecting videos that are short movies of a thriller genre, state component 108 can determine the user is looking to be entertained with media content that has a thriller theme. According state attributes for the user could include ‘entertainment mode,’ ‘movie,’ and ‘thriller.’ In another example, if a user is selecting exercise videos, state component 108 can determine that the user is in a mindset of working out.
- respective media items provided by a media provider at which a user conducts a current session can be associated with one or more different mood or state of mind attribute values.
- these mood or state of mind attributes can be associated with the respective media items as metadata associated with the respective media items.
- these mood or state attributes can be associated with the respective media items on a database correlating the respective media items to mood/state of mind attributes. For example, a funny video about puppies can be associated with mood values of corresponding to happy, joyful, sappy, sensitive, and humorous.
- workout videos can be associated with moods reflective of exercise, motivation, health and energy.
- classical music based content can be associated with relaxation mood values.
- attributes of media items provided by the media provider can be associated with respective mood values.
- state component 108 can analyze the various state or mood values associated with media items viewed (e.g., watched and/or listened to) by a user over the course of a current session to determine or infer one or more cumulative state attributes of the user's mood.
- information regarding a level of user interaction and engagement with the respective media items can further facilitate determining a user's mood. For example, where a user engages with and interacts more with media items having mood values of a, b, and c and less with media items having mood values x, y and z, state component 108 can place a greater weight on mood values a, b and c when determining the user's mood attributes.
- state component 108 can determine or infer a user's mood based on the manner in which a user navigates content provided by a media provider during the user's session with the media provider. For example, based on the user's navigational mechanisms, state component 108 can whether the user is in a state of haste or whether the user is not in a state of haste.
- state component 108 can determine or infer that a user is in a state of haste or not based on how quickly and frequently a user selects new media items for viewing and the durations of the media items selected for viewing being relatively short or long (e.g., with respect to a threshold duration) as well as the amounts of the durations watched/listened to by the user (e.g., watching more than X % of a video can indicate the user is not in a state of haste while watching less than X % of a video can indicate the user is in a state of haste).
- state component 108 can determining whether the user is in a leisurely mindset or has is focused on a specific agenda or task. According to this example, when a user's navigation mechanisms indicate the user is browsing the various media content provided by a media provider (e.g., via selecting recommended media items or items associated with different media item categories), state component 108 can consider the user in a leisurely mindset. On the other hand, when a user is performing a specific keywords search and looking for videos of a particular subject matter or title, the user can be considered to be in focused and structured mindset.
- state component 108 can determine or infer state attributes to associated with a user during a current session that include ‘state of haste or hurry,’ ‘browsing mindset,’ ‘focused searching mindset,’ ‘structure searching mindset,’ and similar attributes.
- state component 108 can determine or infer attributes associated with a user's state of mind based on the manner via which a user interacts with or reacts to the media items played during the user's current session. For example, if a user stops playing a certain media item or disengages from the media item as it plays, state component 108 can determine that mood values associated with the media item do not reflect the user's current mood. Similarly, where a user engages with a particular media item during a current session, shares the media item, comments on the item etc., state component 108 can determine or infer that mood values associated with the media item are more reflective of the user's current mood. Thus in an aspect, state component 108 can weight mood values associated with media items accessed/watched/listened to by a user based on the manner and level of engagement the user has with the respective media items.
- state component 108 can determine or infer attributes corresponding to a user's current state of mind based on comments provided by the user about the media item (“I love this song,” “this was so scary,” “this video made be bawl,” etc.).
- a user's state of mind can include a level of engagement of a user during a current session with a media provider and/or particular content played during the session.
- state component 108 can determine or infer state attributes that indicate whether the user is actively engaged, passively engaged or disengaged.
- state component 108 can discern a user's level of engagement during a current session based on explicit engagement signals (e.g., like/dislike, comment, subscribe, seek, etc.) and implicit engagement signals (e.g., continued playback, mouse/keyboard movement, device movement, touchscreen activity, etc.) received by reception component 106 .
- explicit engagement signals e.g., like/dislike, comment, subscribe, seek, etc.
- implicit engagement signals e.g., continued playback, mouse/keyboard movement, device movement, touchscreen activity, etc.
- state component 108 can determine a user's level of engagement during a current session based on visibility of the played media items via an interface presented to the user during the current session and volume of the played media items. For example, when a user has video content playing with the volume turned off or low, state component 108 can determine that the user is passively engaged in a ‘watching no volume mode.’ In another example, when a user has a video content playing with the volume turned up yet the video player minimized or provided behind another open window or tab, state component 108 can determine that the user is passively engaged in a ‘listening only mode.’ However where both the video player is not visible and the volume is turned off or down, state component 108 can determine that the user is disengaged.
- state component 108 can employ information regarding a user's movement/motion to determine or infer a user's state of mind. For example, if a user is moving or headed somewhere, state component 108 can determine that the user is in a state of ‘haste’ or ‘on the go.’ Similarly, if the user is stationary, state component 108 can determine that the user is relaxed and has time on his hands.
- Context component 110 is configured to determine context characteristics related to the context of a current session between a user and content provider 102 .
- Context refers to the circumstances that form the setting for an event, statement, or idea, and in terms of which it can be fully understood and assessed.
- context can include the circumstances that form the setting of the current session.
- context component 110 is configured to determine context characteristics associated with a current session between a user and a media provider based on information received by reception component 106 .
- these context characteristics can include but are not limited to: where the user is located or going during the current session (e.g., as determined by context component 110 based on received or determined location information for client device 122 during the current session and/or received user movement/motion information), when (e.g., time of day) the current session is occurring, and who the user is with (e.g., alone, with a group other users, with a friend etc.) during the current session (e.g., as determined by context component 110 based on received location information for other clients 130 when authorized by the other clients).
- content component 110 can further employ various external sources to look up current context characteristics about the location (e.g., persons, places, things, events, weather, traffic, etc. associated with the location). For example, context component 110 can determine that a user is located at a restaurant at a time when the restaurant that is throwing special event for alumni of a local college.
- context component 110 can determine that a user is located at a restaurant at a time when the restaurant that is throwing special event for alumni of a local college.
- context component 110 can determine or infer content characteristics that relate to what a user is doing aside from or in association with a current session with a content provider (e.g., walking, exercising, riding a train/bus, working, conducting a work meeting, attending a class, cleaning the house, attending a party with friends, etc.). Context component can also determine characteristics regarding what the user was doing before and/or will do after the current session. For example, context component 110 can determine or infer an activity performed by the user preceding initiation of the current session, a duration of time the user has available for the current session, or an activity for performance by the user at a known point in time after initiation of the current session.
- a content provider e.g., walking, exercising, riding a train/bus, working, conducting a work meeting, attending a class, cleaning the house, attending a party with friends, etc.
- Context component can also determine characteristics regarding what the user was doing before and/or will do after the current session. For example, context component 110 can determine or infer an activity performed
- Context component 110 can determine these content characteristics related to what a user is doing, was doing and will do in the near future based on analysis of a various received signals related to where the user is located, time of day, what device the user is on, and movement data for the user in view of the user's schedule and/or learned behavior for the user. For example, based on information indicating the user is located at her home around 6 am on a weekday morning, information indicating the user is moving about the house, information indicating the user is conducting a current media session on her Internet enabled television, and the user's work schedule, context component 110 can determine that the user is getting ready to go to work and will be leaving the house at about 7 am.
- Context component 110 can also determine content characteristics related to a user's purpose for a current session. For example, context component 110 can determine whether a current session with a media provider is for an entertainment purpose, an educational purpose, or a work related purpose. In an aspect, context component 110 can determine or infer a purpose of a current session with a media provider based on the media items provided by the media system that are played for watching by the user during the current session, and the manner via which the user interacts with or reacts to the played media items.
- context component 110 can determine whether a user is performing the current session to get information about a specific subject, to find a playlist for a party, to watch videos about a particular subject, to get the recent local news, to find a movie to watch, to browse for something entertaining to watch, to get instruction for performing a task, to find a yoga instruction video, etc.
- context component 110 can determine a purpose for a current session with a media provider based on how the current session was initiated.
- the purpose of a session could initially include a user's desire to view a media item represented by a selected link at another source.
- context component can determine 110 whether the user was directed to the media system from a referral source, a media item provided by the media provider represented by a link selected by the user at the referral source, and/or information about the referral source.
- context component 110 can determine or infer information related to sessions of other users, related to the user (e.g., friends of the user, users sharing similar preferences or demographics of the user, etc.), with the content provider that are being conducted during the current session of the user. For example, context information regarding content the user's friends are accessing and sharing while the user is also accessing the content provider can influence what the user may find interesting during the user's current session, such as what videos and channels the user's friends are watching during the user's current session with a media provider.
- state component 108 can determine or infer various attributes about a user's state of mind based on characteristics of a user's context as determined by context component 110 .
- a user's context can greatly influence the user's state of mind.
- a user's mood can vary depending on the time of day, the user's environment (e.g., where the user is located and current aspects associated with the location at the time of day and day of week, including other persons, things and events or activities), what the user is doing in association with the current session (e.g., driving, relaxing, at a party, etc.), what the user just did before the session and/or has to do after the session, what device the user is employing, or how the user initiated the session (e.g., in response to selection of a link to a specific video, to conduct a search, or to browse).
- state component 110 can analyze characteristics about a user's context to facilitate determining or inferring a user's current state of mind (e.g., mood, attitude, emotional state, energy level, etc.).
- state component 108 can employ various rule based classification schemes and/or machine learning techniques that relate different context attributes associated with a user's current context particular to state of mind attributes (e.g., mood values).
- Selection component 112 is configured to select a content item for provision to a user during the user's current session with a content provider 102 based on the various state attributes and context characteristics determined or inferred by state component 108 and context component 110 , respectively, during the user's current session.
- content provider 102 is a streaming media provider
- selection component 112 is configured to select a media item based on the user's state attributes and context characteristic.
- the media item can include a media advertisement or video trailer for another media item or channel provided by the media provider.
- the media advertisement or video trailer can be provided to the user (e.g., as an in-stream advertisement/trailer, as a banner advertisement, as an in-video advertisement, etc.) to the user in association with other media content accessed by the user during the current session.
- the media item can include another media item provided by the media provider.
- the media item can be provided to the user in a recommendation section or list of media items recommended to the user during the user's current session.
- selection component 112 can employ a media index 118 that associates a plurality of media items and media advertisements, provided by the media provider, with state attributes and context attributes.
- the state and context attributes associated with a particular media item can be selected based on a particular user a state of mind and user context under which the media item is considered to be well received.
- a video advertisement for a fast food breakfast restaurant could be associated with state attributes such as ‘hungry,’ ‘state of haste,’ ‘tired,’ or ‘on the go.’
- Context attributes associated with the advertisement could include ‘morning,’ ‘driving,’ and ‘location N’ (wherein location N can vary and include different locations where the fast food breakfast restaurant is located).
- media items in media index 118 can be associated with various mood attributes indicative of modes the media items evoke or compliment, such as mood attributes indicating whether the media item is suited for users in an entertainment related or a work related mode.
- media items that are relatively short in length can be associated with attributes that indicate they are suited for users who are in a state of haste/hurry or in distracted/passive state while media items that are longer in duration can be associated with attributes that indicate they are suited for users who are in leisurely, calm, time on their hands, attentive, etc., kind of state.
- a media advertisement can be associated with attributes that indicate whether it has audible branding or not (wherein a media advertisement without audible branding will be ineffective for a user who is passively engaged with a media content session based on failure to have a media player or interface visible to the user).
- a media advertisement can be associated with an attribute indicating it has no or low visible branding (wherein the media advertisement will be ineffective when the user is passively engaged do to no or low volume).
- selection component 112 can match or relate user state attributes and user context characteristics with state attributes and context characteristics associated with different media items provided in media index 118 to identify one or more media items that match or relate the user's current state of mind and context. For example, when a user is relaxing in the evening at home and selecting and watching relatively short videos with funny and light hearted content, selection component 112 can select a media item for provision to the user that is also relatively short and has an entertaining, funny and light hearted nature.
- a determination that a media item matches a user's current state and context can be based on a correspondence threshold (e.g., a percentage match threshold) between the user's current state and context attributes and the state and context attributes associated with the media item.
- a correspondence threshold e.g., a percentage match threshold
- the degree of contribution of certain state attributes and context characteristics to a match determination can also vary. For example, a location based context characteristic can provide a greater influence on a match determination over a context characteristic related to why a user's current session was initiated.
- selection component 112 can be configured to select media items that do not necessarily share the same state/context attributes as a user, but which are associated with state/context attributes that compliment those of the user.
- selection component can identify a media advertisement that is associated with attributes designed to lift the user's spirits. For example, a suitable advertisement could include one for a warm weather vacation.
- selection component 112 can employ various rule based classification schemes or machine based learning techniques to facilitate selecting a media item that a user will likely be receptive to and engage with during the user's current session with a media provider based on the user's current state of mind and context.
- selection component 112 can infer that although a user's state and context characteristics indicate the user is a relatively good match for the fast food breakfast restaurant advertisement, based on a single context characteristic that indicates the user has X amount of time before she has to be at work, the user will not be able to stop at the fast food breakfast restaurant on the way to work. Accordingly, selection component 112 can determine that provision of the fast food breakfast restaurant advertisement to the user during the user's current session would not cause the user to act on the advertisement, and thus select a different media advertisement for provision to the user.
- Scoring component 202 is configured to score and rank content items (e.g., media items) provided by content provider 102 (e.g., a streaming media provider based on relevance or suitability to a user in association with a current session between the user and the content provider 102 , wherein the determination of relevance or suitability is based at least in part on the user's current state of mind and context.
- content provider 102 e.g., a streaming media provider based on relevance or suitability to a user in association with a current session between the user and the content provider 102 , wherein the determination of relevance or suitability is based at least in part on the user's current state of mind and context.
- scoring component 202 can score media advertisements provided by a media provider based on relevance and suitability of the media advertisements for a user during the user's current session with the media provider based on the user's current state of mind and context.
- scoring component 202 can analyze a plurality of media advertisements based on correspondence and fixed relationships between the user's current user state and context attributes and state and context attributes respectively associated with the media advertisements to determine a score for the respective media advertisements representative of relevance and suitability of the respective media advertisements to the user.
- relevance and suitability can reflect a probability that the user will view the advertisement and/or the advertisement will have an impression upon the user.
- Selection component 112 can then select the media advertisement having the highest score (and/or a subset of the media advertisement having the highest scores) for provision to the user during the user's current media session.
- the weight vector W can be designed to account for a probability that the media advertisement will be viewed past a billable point and/or a probability that the media advertisement will have a lasting impression upon the user.
- W can be generated using historical data using a machine learning algorithm.
- scoring component 202 can score and rank trailers for channels provided by a media provider or trailers for other videos provided by the media provider based on relevance and suitability for a user during the user's current session with the media provider in view of the user's current state of mind and context.
- relevance and suitability can reflect a probability that the user will view the trailer and choose to select the channel or video represented by the trailer for watching, subscribing to, or otherwise showing an affinity for.
- selection component 112 can then select the trailer having the highest score (and/or a subset of the media advertisement having the highest scores) for provision to the user during the user's current media session.
- respective scores associated with trailers can change over the course of a user's media session based on changes to the user's mood or context. Accordingly, at any given time in a user's media session, selection component 112 can select the trailer having the highest score at that time.
- scoring component 202 can score other media items (e.g., videos, channels or playlists) provided by a media provider based on relevance and suitability for a user during the user's current session with the media provider based on the user's current state of mind and context. According to this example, relevance and suitability can reflect a probability that the user will view/play the media item or subscribe to the media item. Selection component 112 can then select a subset of media items having the highest scores for provision to the user in a recommendation section/list during the user's current media session.
- media items e.g., videos, channels or playlists
- Rendering component 204 is configured to effectuate the rendering of a content item (e.g., a media item) identified be selection component 112 to the user during the user's current session. For example, when the session includes a session with a streaming media provider, rendering component 204 can direct the streaming media provider to stream a selected video advertisement or trailer (e.g., an in-stream video advertisement) to the user in association with another media item accessed by the user. In another example, rendering component 204 can direct the streaming media provider to include a subset of media items identified by selection component 112 in a recommendation menu or list included in a portion of a user interface employed by the streaming media provider.
- a content item e.g., a media item identified be selection component 112
- rendering component 204 can direct the streaming media provider to stream a selected video advertisement or trailer (e.g., an in-stream video advertisement) to the user in association with another media item accessed by the user.
- rendering component 204 can direct the streaming media provider to include a subset of
- FIG. 3 presents another example system 300 for identifying and rendering content relevant to a user's current mental state and context in accordance with various aspects and embodiments described herein.
- System 300 includes same or similar features and functionalities as system 200 with the addition of inference component 302 to dynamic content selection platform 104 . Repetitive description of like elements employed in respective embodiments of systems described herein is omitted for sake of brevity.
- Inference component 302 is configured to provide for or aid in various inferences or determinations associated with aspects of dynamic content selection platform 104 .
- inference component 302 can aid state component 108 and context component 110 with inferring attributes about a user's current state of mind and context based on the various information received by reception component 106 discussed herein.
- inference component 302 can aid selection component 112 with identifying a content item (e.g., a media item) that is likely to be well received by a user during the user's current session based on the user's current state of mind and context.
- inference component 302 can facilitate scoring component 202 with inferring scores of suitability and relevance for content items based on a user's current state of mind and context and state and context attributes respectively associated with the content items.
- Such classification can employ a probabilistic and/or statistical-based analysis (e.g., factoring into the analysis utilities and costs) to prognose or infer an action that a user desires to be automatically performed.
- a support vector machine (SVM) is an example of a classifier that can be employed. The SVM operates by finding a hyper-surface in the space of possible inputs, where the hyper-surface attempts to split the triggering criteria from the non-triggering events. Intuitively, this makes the classification correct for testing data that is near, but not identical to training data.
- FIG. 4 presents another example system 400 for identifying and rendering content relevant to a user's current mental state and context in accordance with various aspects and embodiments described herein.
- System 400 includes same or similar features and functionalities as system 300 with the additions of trailer component 402 and recommendation component 404 to dynamic content selection platform 104 . Repetitive description of like elements employed in respective embodiments of systems described herein is omitted for sake of brevity.
- FIG. 5 presents another example system 500 for identifying and rendering content relevant to a user's current mental state and context in accordance with various aspects and embodiments described herein.
- System 500 includes same or similar features and functionalities as system 400 with the additions of advertisement component 502 and advertisement charging component 504 to dynamic content selection platform 104 . Repetitive description of like elements employed in respective embodiments of systems described herein is omitted for sake of brevity.
- Advertisement component 502 is configured to facilitate targeted advertising based on a user's current state of mind and context during a session with a content provider 102 .
- advertisement component 502 can identify video advertisements, banner advertisements, image advertisements, audio advertisements, etc. that are relevant to a user and likely to provide an impression upon the user based on the user's current state of mind and context as determined or inferred by state component 108 and context component 110 , respectively.
- advertisement component 502 can target users with tailored advertisements at the right time, increasing user happiness and advertiser return on investment.
- Advertisement charging component 504 can facilitate dynamically charging an advertiser for provision of an advertisement based on a degree to which the advertisement capitalizes on a user's current state of mind and context.
- scoring component is configured to dynamically score advertisements based on relevance and suitability of the advertisements for a user given various attributes associated with the user's state of mind and context, wherein relevance and suitability can reflect a probability that the user will view the advertisement and/or the advertisement will have an impression upon the user.
- Advertisement charging component 504 can factor in an advertisements score in association with charging provision of the advertisement.
- FIG. 6 illustrates a flow chart of an example method 600 for identifying and rendering content relevant to a user's current mental state and context in accordance with various aspects and embodiments described herein.
- user state attributes associated with a user's current state of mind during a current session of the user with a streaming media provider are determined based on at least one of: navigation of the streaming media provider by the user during the current session, media items provided by the streaming media provider that are played during the current session, or a manner via which the user interacts with or reacts to the played media items, wherein the state of the user includes a mood of the user (e.g., via state component 108 ).
- state component 108 can determine that the user is probably frustrated, annoyed, focused on finding a solution to a specific problem as opposed to looking for entertainment content and attentive to the current session.
- a media item provided by the streaming media provider is selected based on the user state attributes (e.g., via selection component 112 ). For example, selection component 112 can select a video trailer for a channel provided on by the streaming media provider that includes several short do it yourself repairs for different cell phone types and issues. In another example, selection component 112 can select a media advertisement for a service that repairs broken cell phones.
- the selected media item is then rendered to the user during the current session.
- FIG. 7 illustrates a flow chart of another example method 700 for identifying and rendering content relevant to a user's current mental state and context in accordance with various aspects and embodiments described herein.
- mood attributes associated with a user's current mood during a session of the user with a streaming media provider and context attributes associated with a current context of the session based are determined on at least one of: navigation of the streaming media provider by the user during the current session, media items provided by the streaming media provider that are played during the current session, or an environment of the user (e.g., via state component 108 and context component 110 ).
- selecting a media item provided by the streaming media provider based on the mood attributes and the context attributes e.g., via selection component 112 ).
- the media item is rendered to the user during the current session (e.g., via rendering component 204 ).
- FIG. 8 illustrates a flow chart of another example method 700 for identifying and rendering content relevant to a user's current mental state and context in accordance with various aspects and embodiments described herein.
- current mood attributes associated with a user's current mood during a session of the user with a streaming media provider and current context attributes associated with a current context of the session are determined based on at least one of: navigation of the streaming media provider by the user during the current session, media items provided by the streaming media provider that are played during the current session, or an environment of the user (e.g., via state component 108 and context component 110 ).
- a plurality of media advertisements provided by the streaming media provider are scored based on relevance and suitability for the user during the user's session, wherein the relevance and suitability is based on a correspondence between the current mood and current context attributes, and state and context attributes respectively associated with the plurality of media advertisements (e.g., via scoring component 202 ).
- one of the plurality of media advertisements associated with a score exceeding a threshold score is selected, wherein scores above the threshold score indicate a high degree of relevance and suitability for the user based on the user's current mood and the current context of the session (e.g., via selection component 112 ).
- streaming of the media advertisement to the user is effectuated during the user's current session (e.g., via rendering component 204 ).
- a suitable environment 1000 for implementing various aspects of the claimed subject matter includes a computer 1002 .
- the computer 1002 includes a processing unit 1004 , a system memory 1006 , a codec 1005 , and a system bus 1008 .
- the system bus 1008 couples system components including, but not limited to, the system memory 1006 to the processing unit 1004 .
- the processing unit 1004 can be any of various available processors. Dual microprocessors and other multiprocessor architectures also can be employed as the processing unit 1004 .
- the system bus 1008 can be any of several types of bus structure(s) including the memory bus or memory controller, a peripheral bus or external bus, and/or a local bus using any variety of available bus architectures including, but not limited to, Industrial Standard Architecture (ISA), Micro-Channel Architecture (MSA), Extended ISA (EISA), Intelligent Drive Electronics (IDE), VESA Local Bus (VLB), Peripheral Component Interconnect (PCI), Card Bus, Universal Serial Bus (USB), Advanced Graphics Port (AGP), Personal Computer Memory Card International Association bus (PCMCIA), Firewire (IEEE 13104), and Small Computer Systems Interface (SCSI).
- ISA Industrial Standard Architecture
- MSA Micro-Channel Architecture
- EISA Extended ISA
- IDE Intelligent Drive Electronics
- VLB VESA Local Bus
- PCI Peripheral Component Interconnect
- Card Bus Universal Serial Bus
- USB Universal Serial Bus
- AGP Advanced Graphics Port
- PCMCIA Personal Computer Memory Card International Association bus
- Firewire IEEE 13104
- SCSI Small Computer Systems Interface
- the system memory 1006 includes volatile memory 1010 and non-volatile memory 1012 .
- the basic input/output system (BIOS) containing the basic routines to transfer information between elements within the computer 1002 , such as during start-up, is stored in non-volatile memory 1012 .
- codec 1005 may include at least one of an encoder or decoder, wherein the at least one of an encoder or decoder may consist of hardware, a combination of hardware and software, or software. Although, codec 1005 is depicted as a separate component, codec 1005 may be contained within non-volatile memory 1012 .
- non-volatile memory 1012 can include read only memory (ROM), programmable ROM (PROM), electrically programmable ROM (EPROM), electrically erasable programmable ROM (EEPROM), or flash memory.
- Volatile memory 1010 includes random access memory (RAM), which acts as external cache memory. According to present aspects, the volatile memory may store the write operation retry logic (not shown in FIG. 10 ) and the like.
- RAM is available in many forms such as static RAM (SRAM), dynamic RAM (DRAM), synchronous DRAM (SDRAM), double data rate SDRAM (DDR SDRAM), and enhanced SDRAM (ESDRAM.
- Disk storage 1014 includes, but is not limited to, devices like a magnetic disk drive, solid state disk (SSD) floppy disk drive, tape drive, Jaz drive, Zip drive, LS-70 drive, flash memory card, or memory stick.
- disk storage 1014 can include storage medium separately or in combination with other storage medium including, but not limited to, an optical disk drive such as a compact disk ROM device (CD-ROM), CD recordable drive (CD-R Drive), CD rewritable drive (CD-RW Drive) or a digital versatile disk ROM drive (DVD-ROM).
- CD-ROM compact disk ROM
- CD-R Drive CD recordable drive
- CD-RW Drive CD rewritable drive
- DVD-ROM digital versatile disk ROM drive
- a removable or non-removable interface is typically used, such as interface 1016 .
- FIG. 10 describes software that acts as an intermediary between users and the basic computer resources described in the suitable operating environment 1000 .
- Such software includes an operating system 1018 .
- Operating system 1018 which can be stored on disk storage 1014 , acts to control and allocate resources of the computer system 1002 .
- Applications 1020 take advantage of the management of resources by operating system 1018 through program modules 1024 , and program data 1026 , such as the boot/shutdown transaction table and the like, stored either in system memory 1006 or on disk storage 1014 . It is to be appreciated that the claimed subject matter can be implemented with various operating systems or combinations of operating systems.
- Input devices 1028 include, but are not limited to, a pointing device such as a mouse, trackball, stylus, touch pad, keyboard, microphone, joystick, game pad, satellite dish, scanner, TV tuner card, digital camera, digital video camera, web camera, and the like.
- These and other input devices connect to the processing unit 1004 through the system bus 1008 via interface port(s) 1030 .
- Interface port(s) 1030 include, for example, a serial port, a parallel port, a game port, and a universal serial bus (USB).
- Output device(s) 1036 use some of the same type of ports as input device(s).
- a USB port may be used to provide input to computer 1002 , and to output information from computer 1002 to an output device 1036 .
- Output adapter 1034 is provided to illustrate that there are some output devices 1036 like monitors, speakers, and printers, among other output devices 1036 , which require special adapters.
- the output adapters 1034 include, by way of illustration and not limitation, video and sound cards that provide a means of connection between the output device 1036 and the system bus 1008 . It should be noted that other devices and/or systems of devices provide both input and output capabilities such as remote computer(s) 1038 .
- Computer 1002 can operate in a networked environment using logical connections to one or more remote computers, such as remote computer(s) 1038 .
- the remote computer(s) 1038 can be a personal computer, a server, a router, a network PC, a workstation, a microprocessor based appliance, a peer device, a smart phone, a tablet, or other network node, and typically includes many of the elements described relative to computer 1002 .
- only a memory storage device 1040 is illustrated with remote computer(s) 1038 .
- Remote computer(s) 1038 is logically connected to computer 1002 through a network interface 1042 and then connected via communication connection(s) 1044 .
- Network interface 1042 encompasses wire and/or wireless communication networks such as local-area networks (LAN) and wide-area networks (WAN) and cellular networks.
- LAN technologies include Fiber Distributed Data Interface (FDDI), Copper Distributed Data Interface (CDDI), Ethernet, Token Ring and the like.
- WAN technologies include, but are not limited to, point-to-point links, circuit switching networks like Integrated Services Digital Networks (ISDN) and variations thereon, packet switching networks, and Digital Subscriber Lines (DSL).
- ISDN Integrated Services Digital Networks
- DSL Digital Subscriber Lines
- Communication connection(s) 1044 refers to the hardware/software employed to connect the network interface 1042 to the bus 1008 . While communication connection 1044 is shown for illustrative clarity inside computer 1002 , it can also be external to computer 1002 .
- the hardware/software necessary for connection to the network interface 1042 includes, for exemplary purposes only, internal and external technologies such as, modems including regular telephone grade modems, cable modems and DSL modems, ISDN adapters, and wired and wireless Ethernet cards, hubs, and routers.
- the system 1100 includes one or more client(s) 1102 (e.g., laptops, smart phones, PDAs, media players, computers, portable electronic devices, tablets, and the like).
- the client(s) 1102 can be hardware and/or software (e.g., threads, processes, computing devices).
- the system 1100 also includes one or more server(s) 1104 .
- the server(s) 1104 can also be hardware or hardware in combination with software (e.g., threads, processes, computing devices).
- the servers 1104 can house threads to perform transformations by employing aspects of this disclosure, for example.
- One possible communication between a client 1102 and a server 1104 can be in the form of a data packet transmitted between two or more computer processes wherein the data packet may include video data.
- the data packet can include a metadata, e.g., associated contextual information, for example.
- the system 1100 includes a communication framework 1106 (e.g., a global communication network such as the Internet, or mobile network(s)) that can be employed to facilitate communications between the client(s) 1102 and the server(s) 1104 .
- a communication framework 1106 e.g., a global communication network such as the Internet, or mobile network(s)
- the client(s) 1102 include or are operatively connected to one or more client data store(s) 1108 that can be employed to store information local to the client(s) 1102 (e.g., associated contextual information).
- the server(s) 1104 are operatively include or are operatively connected to one or more server data store(s) 1110 that can be employed to store information local to the servers 1104 .
- a client 1102 can transfer an encoded file, in accordance with the disclosed subject matter, to server 1104 .
- Server 1104 can store the file, decode the file, or transmit the file to another client 1102 .
- a client 1102 can also transfer uncompressed file to a server 1104 and server 1104 can compress the file in accordance with the disclosed subject matter.
- server 1104 can encode video information and transmit the information via communication framework 1106 to one or more clients 1102 .
- the illustrated aspects of the disclosure may also be practiced in distributed computing environments where certain tasks are performed by remote processing devices that are linked through a communications network.
- program modules can be located in both local and remote memory storage devices.
- various components described in this description can include electrical circuit(s) that can include components and circuitry elements of suitable value in order to implement the embodiments of the subject innovation(s).
- many of the various components can be implemented on one or more integrated circuit (IC) chips.
- IC integrated circuit
- a set of components can be implemented in a single IC chip.
- one or more of respective components are fabricated or implemented on separate IC chips.
- the terms used to describe such components are intended to correspond, unless otherwise indicated, to any component which performs the specified function of the described component (e.g., a functional equivalent), even though not structurally equivalent to the disclosed structure, which performs the function in the disclosure illustrated exemplary aspects of the claimed subject matter.
- the innovation includes a system as well as a computer-readable storage medium having computer-executable instructions for performing the acts and/or events of the various methods of the claimed subject matter.
- a component may be, but is not limited to being, a process running on a processor (e.g., digital signal processor), a processor, an object, an executable, a thread of execution, a program, and/or a computer.
- a processor e.g., digital signal processor
- an application running on a controller and the controller can be a component.
- One or more components may reside within a process and/or thread of execution and a component may be localized on one computer and/or distributed between two or more computers.
- a “device” can come in the form of specially designed hardware; generalized hardware made specialized by the execution of software thereon that enables the hardware to perform specific function; software stored on a computer readable storage medium; software transmitted on a computer readable transmission medium; or a combination thereof.
- example or “exemplary” are used in this disclosure to mean serving as an example, instance, or illustration. Any aspect or design described in this disclosure as “exemplary” is not necessarily to be construed as preferred or advantageous over other aspects or designs. Rather, use of the words “example” or “exemplary” is intended to present concepts in a concrete fashion.
- the term “or” is intended to mean an inclusive “or” rather than an exclusive “or”. That is, unless specified otherwise, or clear from context, “X employs A or B” is intended to mean any of the natural inclusive permutations.
- Computer-readable storage media can be any available storage media that can be accessed by the computer, is typically of a non-transitory nature, and can include both volatile and nonvolatile media, removable and non-removable media.
- Computer-readable storage media can be implemented in connection with any method or technology for storage of information such as computer-readable instructions, program modules, structured data, or unstructured data.
- Computer-readable storage media can include, but are not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disk (DVD) or other optical disk storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or other tangible and/or non-transitory media which can be used to store desired information.
- Computer-readable storage media can be accessed by one or more local or remote computing devices, e.g., via access requests, queries or other data retrieval protocols, for a variety of operations with respect to the information stored by the medium.
- communications media typically embody computer-readable instructions, data structures, program modules or other structured or unstructured data in a data signal that can be transitory such as a modulated data signal, e.g., a carrier wave or other transport mechanism, and includes any information delivery or transport media.
- modulated data signal or signals refers to a signal that has one or more of its characteristics set or changed in such a manner as to encode information in one or more signals.
- communication media include wired media, such as a wired network or direct-wired connection, and wireless media such as acoustic, RF, infrared and other wireless media.
Abstract
Systems and methods are provided for identifying and rendering content relevant to a user's current mental state and context. In an aspect, a system includes a state component that determines a state of a user during a current session of the user with the media system based on navigation of the media system by the user during the current session, media items provided by the media system that are played for watching by the user during the current session, and a manner via which the user interacts with or reacts to the played media items. In an aspect, the state of the user includes a mood of the user. A selection component then selects a media item provided by the media provider based on the state of the user, and a rendering component effectuates rendering of the media item to the user during the current session.
Description
This application is a continuation of U.S. application Ser. No. 17/118,068, filed Dec. 10, 2020, which is a continuation of U.S. application Ser. No. 16/597,307, now U.S. Pat. No. 10,961,119, filed Oct. 9, 2019, which is a continuation of U.S. application Ser. No. 15/651,232, now U.S. Pat. No. 10,481,749, filed Jul. 17, 2017, which is a continuation-in-part of U.S. application Ser. No. 14/556,802, now U.S. Pat. No. 9,712,587, filed Dec. 1, 2014, the contents of which are hereby incorporated by reference.
This application generally relates to systems and methods for identifying and rendering content relevant to a user's current mental state and context.
Various content providers and advertisers often determine content to suggest to a user or advertisements to show to the user during a current session with the content provider based on historical analysis of the user's previous history with the content provider and/or other content providers. For example, when browsing the Internet, some advertisement systems will present the user with advertisements for content the user viewed/accessed in a previous browsing session or content similar to what they viewed or accessed in a previous session. These advertisement systems generally analyze various signals from the user's previous browsing sessions before the user begins a future browsing session to determine advertisement content to show the user in the user's future browsing session. However this advertisement content may not be relevant to the when the user begins the future browsing session for a variety of reasons.
Numerous aspects, embodiments, objects and advantages of the present invention will be apparent upon consideration of the following detailed description, taken in conjunction with the accompanying drawings, in which like reference characters refer to like parts throughout, and in which:
The innovation is described with reference to the drawings, wherein like reference numerals are used to refer to like elements throughout. In the following description, for purposes of explanation, numerous specific details are set forth in order to provide a thorough understanding of this innovation. It may be evident, however, that the innovation can be practiced without these specific details. In other instances, well-known structures and components are shown in block diagram form in order to facilitate describing the innovation.
By way of introduction, the subject disclosure relates to dynamically determining or inferring content, provided by a content provider (e.g., via a network based platform such as a website or mobile application), that a user will be most receptive to at any given point during a current interaction session with the content provider based on the context and state of the user during the current session. Various content providers and advertisers often determine content to suggest to a user or advertisements to show to the user during a current session with the content provider based on historical analysis of the user's previous history with the content provider and/or other content providers. For example, when browsing the Internet, some advertisement systems will present the user with advertisements for content they viewed/accessed in a previous session or content similar to what they viewed or accessed in a previous session.
However, this content may not be relevant to the user during the current session for a variety of reasons. For example, during a current session, a user may not be shopping online as the user was in a prior session but researching a technical subject for a work project. Accordingly, showing content to the user during the current session that includes advertisements for products previously viewed by the user will most likely disturb and distract the user. Similarly, where the user previously accessed content related to a technical subject for a work assignment and the user is now relaxing in the evening and browsing the Internet for entertainment and leisure based content, suggesting content to the user related to the technical work subject at this time will likely annoy the user and the user will likely discard the content.
In view of the above noted drawbacks with existing techniques for identifying content to suggest or target to users, the subject disclosure employs a variety to signals received or extracted during a user's current session with a content provider to determine or infer a context of the current session and the user's mental state during the current session. These signals are then used to identify content that the user will be most receptive to at any given point during the current session. In particular, user research has shown that users are in different ‘modes’ according to various dynamic factors such as time of day, what device they are on, what brought them to a particular a particular content provider's website/application, where the user is located (e.g., home vs. work), how much time the user has available to interact with the website/application, what the user is doing in association with access of the website/application. In addition, depending on the type of content provided by the content provider, the user's state of mind can also influence characteristics of content that the user will be most receptive to during a current session. For example, media content (e.g., images, video, music, etc.) can evict various user emotions. When a user's current frame of mind or mood can be discerned, media content can be identified and provided to the user the reflects or effects the user's mood. Accordingly, systems and mechanisms are provided that will take into account various factors related to a user's mental state and context during a current session of the user with a content provider to determine or infer a particular content item to render to the user during the current session.
In an exemplary embodiment, the disclosed techniques are specifically tailored to determine or infer media content that a user will be most receptive to engage with during a current session with a streaming media provider that offers a wide array of different media content of various types and durations for access by the user. The specific media items that a user selects to view or listen to and the manner in which the user engages with media items selected by the user or pushed to the user can provide a strong indication of a user's mental state. For example, when a user is accessing and/or searching for short clips of funny videos, it can be inferred that the user is in a joyful, leisurely state of mind. This information coupled with information related to the context of the current session can provide even greater insight into the user's state of mind. For example, the determination that the user is in a joyful and leisurely state of mind can be held with greater confidence when it is also determined that the user is at a party sharing the videos with friends. In addition the specific content of the funny videos (e.g., the plot, the characters, the script, the setting, etc.) can give an indication of the type of humor the user enjoys during the current session.
In another example, when a user is searching for videos related to information on a specific technical subject, it can be determined that the user's frame mind is focused, diligent, serious, etc. The user's frame of mind can further be discerned depending on the time of day, location of the user, the user's profession and the specific technical subject searched. For example, the user's intentions and concerns may vary if the technical subject is related to work aspects or personal aspects. Further, the user's navigational tactics can indicate the user's intention of the current session and the user's state of mind regarding fulfilling the intention. For instance, when a user selects videos related to a specific keyword search, watches a few seconds of some of the videos in the query result, then quickly dismisses the respective videos and modifies the keyword search, it can be determined that the user is frustrated, in a hurry, and honed in on a very specific task related to understanding the technical subject.
Based on various determined or inferred features related to a user's current mental state and context during a session with the streaming media provider, media content provided by the streaming media can be identified and rendered to the user that is relevant to the current user's mental state and context. In an aspect, this media content can include advertisements (e.g., video advertisements or static advertisements). For example, a video advertisement having a specific content type and duration can be identified based on characteristics of the user's mental state and context during a current session of the user with the media provider and rendered to the user during the current session at a point during the current session when the user will be most receptive to it. In another aspect, the media content identified for provision to the user can include a trailer for another video or channel offered by the media provider. Still in yet another aspect, the media content can include other videos, playlists and channels provided by the media provider and suggested to the user in a recommendation list for viewing during the current session.
In one or more aspects, a system is provided that includes a state component configured to determine a state of a user during a current session of the user with the media system based on at least one of: navigation of the media system by the user during the current session, media items provided by the media system that are played for watching by the user during the current session, or a manner via which the user interacts with or reacts to the played media items, wherein the state of the user includes a mood of the user. The system further includes a selection component configured to select a media item provided by the media provider based on the state of the user, and a rendering component configured to effectuate rendering of the media item to the user during the current session.
In another aspect, a method is disclosed that includes using a processor to execute computer executable instructions stored in a memory to perform various acts. These acts can include: determining user state attributes associated with a user's current state of mind during a current session of the user with a streaming media provider based on at least one of: navigation of the streaming media provider by the user during the current session, media items provided by the streaming media provider that are played during the current session, or a manner via which the user interacts with or reacts to the played media items, wherein the state of the user includes a mood of the user; selecting a media item provided by the streaming media provider based on the user state attributes; and rendering the media item to the user during the current session
Further provided is a tangible computer-readable storage medium comprising computer-readable instructions that, in response to execution, cause a computing system to perform various operations. These operations include determining mood attributes associated with a user's current mood during a session of the user with a streaming media provider and determining context attributes associated with a current context of the session based on at least one of: navigation of the streaming media provider by the user during the current session, media items provided by the streaming media provider that are played during the current session, or an environment of the user. The operations further include, selecting a media item provided by the streaming media provider based on the mood attributes and the context attributes, and rendering the media item to the user during the session.
Referring now to the drawings, with reference initially to FIG. 1 , presented is diagram of an example system 100 for identifying and rendering content relevant to a user's current mental state and context in accordance with various aspects and embodiments described herein. Aspects of systems, apparatuses or processes explained in this disclosure can constitute machine-executable components embodied within machine(s), e.g., embodied in one or more computer readable ediums (or media) associated with one or more machines. Such components, when executed by the one or more machines, e.g., computer(s), computing device(s), virtual machine(s), etc. can cause the machine(s) to perform the operations described.
In various aspects, system 100 can also include external sources 128, other client devices 130 and auxiliary input devices 132. Dynamic content selection platform 104 and/or content provider 102 can include memory 116 for storing computer executable components and instructions and processor 114 to facilitate operation of the instructions (e.g., computer executable components and instructions) by the dynamic content selection platform 104. Similarly, client device 122 can include memory for storing computer executable components and instructions and a processor to facilitate operation of the instructions (not shown).
The various components and devices of system 100 can be connected either directly or via one or more networks 120. Such networks can include wired and wireless networks, including but not limited to, a cellular network, a wide area network (WAD, e.g., the Internet), a local area network (LAN), or a personal area network (PAN). For example, client device 122 can communicate with content provider 102 (and vice versa) using virtually any desired wired or wireless technology, including, for example, cellular, WAN, wireless fidelity (Wi-Fi), Wi-Max, WLAN, and etc. In an aspect, one or more components of system 100 are configured to interact via disparate networks. In addition, although dynamic content selection platform 104 is depicted as being internal to content provider 102, one or more aspects of dynamic content selection platform 104 can be provided locally at client device 122. For example, content provider 102 can include an application service provider and client device 122 can employ a thin client application to interact with and receive various content and services provided by the content provider. The thin client application provided on the client device 122 can include one or more components (e.g., reception component 106, state component 108, context component 112, etc.) of dynamic content selection platform 104.
As used herein, the term content item refers to any suitable data object that can be accessed or otherwise shared via a network and includes but is not limited to: documents, articles, messages, webpages, programs, applications, data object and media items. The term media item or media content can include but is not limited to: video, live video, animations, video advertisements, music, music videos, sound files, pictures, and thumbnails. In an aspect, an owner of a media item is referred to herein as a content creator to indicate that the media item was created by the content creator (i.e., the content creator holds copyright authority to the media item). In some aspects, the term media item or media content refers to a collection of media items, such as a playlist or channel including several videos or songs.
A channel can include data content available from a common source or data content having a common topic or theme. A channel can be associated with a curator who can perform management actions on the channel. Management actions can include, for example, adding media items to the channel, removing media items from the channel, defining subscription requirements for the channel, defining presentation attributes for channel content, defining access attributes for channel content, etc. In an aspect, this curator constitutes the channel owner or channel creator and the channel itself can be considered a content or media item owned or created by the channel owner.
In an aspect, channel content can include digital content uploaded to an Internet-based content platform that hosts the channel (e.g., content provider 102) by the channel curator and/or digital content selected by the channel curator from other content available on the Internet-based content platform. A channel curator can include a professional content provider (e.g., a professional content creator, a professional content distributor, a content rental service, a television (TV) service, etc.) or an amateur individual. Channel content can include professional content (e.g., movie clips, TV clips, music videos, educational videos) and/or amateur content (e.g., video blogging, short original videos, etc.). Users, other than the curator of the channel, can subscribe to one or more channels in which they are interested. Users in addition to the channel curator can access content provided by a channel.
In an exemplary embodiment, content provider 102 includes a streaming media provider configured to provide streaming media and related services to client devices over a network. For example, content provider 102 can include a media provider that has access to a voluminous quantity (and potentially an inexhaustible number) of shared media (e.g., video and/or audio) files. The media provider can further stream these media files to one or more users at respective client devices (e.g., clients 122) of the one or more users over a network. The media can be stored in memory associated with the media provider (e.g., memory 116) and/or at various servers and caches employed by media provider and accessed by client devices using a networked platform (e.g., a website platform, a mobile application) employed by the media provider.
For example, the media provider can provide and present media content to a user via a website that can be accessed by a client device using a browser. In another example, the media provider can provide and present media to a user via a mobile/cellular application provided on a client device (e.g., where the client device is a smartphone or the like). Client device 122 can include presentation component 124 to generate a user interface (e.g., a graphical user interface or virtual interface) that displays media content provided by the media provider to a user of the client device. In an aspect, presentation component 124 can include an application (e.g., a web browser) for retrieving, presenting and traversing information resources on the World Wide Web. For example, the media provider can provide and/or present media content to a client device 122 via a website that can be accessed using a browser of the client device 122. In another example, the media provider can provide and/or present media content to a client device 122 via a mobile application platform. According to this application, presentation component 124 can employ a client application version of the media provider that that can access the cellular application platform of the media provider. In an aspect, the media content can be presented and/or played at client device 122 using a video player associated with the media provider and/or the client device 122.
The various features of dynamic content selection platform 104 are exemplified herein wherein content provider 102 includes a streaming media provider (as described herein). Accordingly, dynamic contribution platform 104 is discussed in association with determining or inferring, in real-time or substantially real time, media content (e.g., media advertisement, video trailers, channel trailers, other videos provided by the media provider etc.) that is relevant to a user during the user's current session with the media provider. However, it should be appreciated that dynamic content selection platform 104 can be employed by a variety of content providers and systems to determine or infer content for provision to a user (e.g., advertisements, recommended content) that is relevant to the user's context and mental state at the time of rendering of the content.
In accordance with an embodiment, dynamic content selection platform 104 can include reception component 106, state component 108, context component 110 and selection component 112. Reception component 106 is configured to receive and/or extract information in association with a user's current session with content provider 102 that can be employed to determine or infer attributes of the user's current mental state and context. For example, when a user conducts a session with a streaming media provider that includes navigating and consuming media content provided by the streaming media provider, reception component 106 can receive or extract information about the user's current session that relates to the user's state of mind and context. Based on this information, state component 108 is configured to determine a state of the user and context component 110 is configured to determine a context of the user and/or the current session. Selection component 112 can then determine or infer advertisements, video trailers, channel trailers, and/or other media that the user is likely to be most receptive to during the current session based on the user's state and context.
For example, reception component 106 can receive information regarding the manner in which the user navigates the media provider's content (e.g., searching via key word search, searching within a specific media category or channel, browsing, following recommendations, etc.), the specific content accessed and viewed by the user, and the manner in which the user interacts with the content selected by the user for viewing or pushed upon the user (e.g., watching or dismissing a video, controlling the playing of the video, commenting about the video, liking or disliking the video, sharing the video, having the video visible, having the volume of the video audible, interaction with the interface via which the video is included as based on cursor movement or touch screen interaction, etc.). Reception component 106 can also receive information regarding the watch history of the user during the current session, including durations of media items selected for watching or listening to by the user and respective amounts of the media items actually watched or listened to by the user.
In an aspect, information regarding a user's navigation of a media provider, content accessed and viewed/watched, and the manner in which the user interacts with the content can be extracted in real-time as it is generated at the media provider during the user's session. In another aspect, signals regarding user interaction and engagement with the media provider during a current session can be collected at client device 122 via a signal collection component 126 and provided to reception component 106 during the course of the user's session (e.g., in real-time, in substantially real-time, or periodically). For example, signal collection component 126 can receive signals regarding cursor movement, interaction by the user with a graphical user interface via which the media provider's content is accessed, interaction and control of a media player via which video and/or audio content provided by the media provider is played, visibility of media played during a current session at the client device 122 (e.g., whether the media player is minimized/maximized, whether the media player is behind another tab or window, etc.), and volume of media played during the current session.
In another example, reception component 106 can receive information regarding a mechanism via which the current session was initiated (e.g., in response to a general request by the user to open the network based platform of the streaming media provider, or in response to selection of a link to media content, provided by the streaming media provider, at an external source 128 or received by the user in an electronic message). According to this example, reception component 106 can receive information identifying the specific media item represented by a selected link, the referral source at which the link was located (e.g., an external source 128), and information about the referral source. This information can be provided by the referring source, the client device 122 and/or identified by reception component 106 via metadata associated with the selected link and/or the referral source. For example, reception component 106 can receive information about the content of a web site or webpage at which the link was located. This information can provide insight into what mood the user was in at the time of selection of the link.
In an aspect, information regarding what a user is doing in association with a current session can be received by reception component 106 from a user's schedule (e.g., provided on client device 122 or at an external source 128). In another aspect, information regarding a user's movement and motion can be captured by various motion sensors employed by the user (e.g., worn by the user) and/or provided at client device (e.g., an accelerometer, gyroscope). This motion/movement information can facilitate determining (e.g., by reception component, dynamic content selection platform 104 and/or another system), what the user is doing (e.g., walking, running, sitting, driving a car, etc.) and where the user is going. In other aspects, dynamic content selection platform 104 and/or another system can learn user patterns and behaviors over time based on where the user goes, what the user does, who the user is with, the user's schedule, etc. to determine or infer what the user is doing during a current session.
Similarly, reception component 106 can also receive information related to what the user was doing before initiation of a current session (e.g., where the user was, an activity the user was performing, etc.), an amount of time the user has for conducting the current session (e.g., the user has a one hour lunch break during after which the user must return to work and end the current session), and what the user is likely to do or scheduled to do after the current session (e.g., return to work, attend an event, etc.), based on the user's schedule and/or learned user behaviors/patterns.
A user's state of mind can also reflect a user's conscious or subconscious intention for performing or conducting a session with a streaming media provider. For example, a user's mood can indicate whether the user wants to be entertained, whether the user is in an educational frame of mind, or whether the user is in a work frame of mind. In another aspect, a user's state of mind can include a level of engagement a user has with a particular content item such as a video or song (e.g., whether the user is actively attentive towards the content item or passively engaged with the content item).
In an aspect, state component 108 can determine state attributes representative of a user's current state of mind during a session with a content provider 102 based on how the user navigates about content provided by the content provider 102. For example, state component 108 can determine attributes about a user's state of mind based on how the user navigates about a media provider's website (e.g., what categories the user's selects, how the user moves from one interface to another, how the user influence what media items are presented on a particular interface, whether the user is searching or browsing, etc.). State component 108 can also determine state attributes based on media items, provided by the media provider, that are played for watching by the user during the current session (e.g., either in response to selection by the user or automatically played/pushed to the user), and a manner via which the user interacts with or reacts to the played media items.
For instance, if a user is accessing funny videos about puppies, the user is likely in a happy mood. In addition, if the user is liking, sharing, and providing positive comments about the funny videos, it can be discerned that the content brings the user joy and entertainment. Accordingly, state attributes for the user could include ‘happy,’ ‘joyful,’ entertainment mode,’ ‘humorous content,’ and ‘light hearted.’ In another example, if a user is selecting or searching for music playlists with classical music, state component 108 can determine the user is in a relaxed mood. In another aspect, based on the type of media content a user selects for watching/listening to, state component 108 can determine whether the user is looking to be entertained and how or whether the user is looking for informational/instructional content. For instance, when a user is selecting videos that are short movies of a thriller genre, state component 108 can determine the user is looking to be entertained with media content that has a thriller theme. According state attributes for the user could include ‘entertainment mode,’ ‘movie,’ and ‘thriller.’ In another example, if a user is selecting exercise videos, state component 108 can determine that the user is in a mindset of working out.
In an aspect, respective media items provided by a media provider at which a user conducts a current session can be associated with one or more different mood or state of mind attribute values. In an aspect, these mood or state of mind attributes can be associated with the respective media items as metadata associated with the respective media items. In another aspect, these mood or state attributes can be associated with the respective media items on a database correlating the respective media items to mood/state of mind attributes. For example, a funny video about puppies can be associated with mood values of corresponding to happy, joyful, sappy, sensitive, and humorous. In another example, workout videos can be associated with moods reflective of exercise, motivation, health and energy. In another example, classical music based content can be associated with relaxation mood values. In yet another example, attributes of media items provided by the media provider (e.g. videos, channels, playlists, songs, etc.) related to a type of the media item (e.g., movie, sitcom, advertisement, music video), and a genre of the media item (e.g., comedy, drama, romance, thriller, reality, instructional, informational, etc.) can be associated with respective mood values. According to this aspect, state component 108 can analyze the various state or mood values associated with media items viewed (e.g., watched and/or listened to) by a user over the course of a current session to determine or infer one or more cumulative state attributes of the user's mood.
In addition, information regarding a level of user interaction and engagement with the respective media items can further facilitate determining a user's mood. For example, where a user engages with and interacts more with media items having mood values of a, b, and c and less with media items having mood values x, y and z, state component 108 can place a greater weight on mood values a, b and c when determining the user's mood attributes.
In another aspect, state component 108 can determine or infer a user's mood based on the manner in which a user navigates content provided by a media provider during the user's session with the media provider. For example, based on the user's navigational mechanisms, state component 108 can whether the user is in a state of haste or whether the user is not in a state of haste. According to this example, state component 108 can determine or infer that a user is in a state of haste or not based on how quickly and frequently a user selects new media items for viewing and the durations of the media items selected for viewing being relatively short or long (e.g., with respect to a threshold duration) as well as the amounts of the durations watched/listened to by the user (e.g., watching more than X % of a video can indicate the user is not in a state of haste while watching less than X % of a video can indicate the user is in a state of haste).
In another example, based on the user's navigational mechanisms, state component 108 can determining whether the user is in a leisurely mindset or has is focused on a specific agenda or task. According to this example, when a user's navigation mechanisms indicate the user is browsing the various media content provided by a media provider (e.g., via selecting recommended media items or items associated with different media item categories), state component 108 can consider the user in a leisurely mindset. On the other hand, when a user is performing a specific keywords search and looking for videos of a particular subject matter or title, the user can be considered to be in focused and structured mindset. Accordingly, based on a user's navigational mechanisms, state component 108 can determine or infer state attributes to associated with a user during a current session that include ‘state of haste or hurry,’ ‘browsing mindset,’ ‘focused searching mindset,’ ‘structure searching mindset,’ and similar attributes.
In another aspect, state component 108 can determine or infer attributes associated with a user's state of mind based on the manner via which a user interacts with or reacts to the media items played during the user's current session. For example, if a user stops playing a certain media item or disengages from the media item as it plays, state component 108 can determine that mood values associated with the media item do not reflect the user's current mood. Similarly, where a user engages with a particular media item during a current session, shares the media item, comments on the item etc., state component 108 can determine or infer that mood values associated with the media item are more reflective of the user's current mood. Thus in an aspect, state component 108 can weight mood values associated with media items accessed/watched/listened to by a user based on the manner and level of engagement the user has with the respective media items.
In another aspect, state component 108 can determine or infer attributes corresponding to a user's current state of mind based on comments provided by the user about the media item (“I love this song,” “this was so scary,” “this video made be bawl,” etc.).
In another aspect, a user's state of mind can include a level of engagement of a user during a current session with a media provider and/or particular content played during the session. For instance, state component 108 can determine or infer state attributes that indicate whether the user is actively engaged, passively engaged or disengaged. In an aspect, state component 108 can discern a user's level of engagement during a current session based on explicit engagement signals (e.g., like/dislike, comment, subscribe, seek, etc.) and implicit engagement signals (e.g., continued playback, mouse/keyboard movement, device movement, touchscreen activity, etc.) received by reception component 106. In an aspect, state component 108 can determine a user's level of engagement during a current session based on visibility of the played media items via an interface presented to the user during the current session and volume of the played media items. For example, when a user has video content playing with the volume turned off or low, state component 108 can determine that the user is passively engaged in a ‘watching no volume mode.’ In another example, when a user has a video content playing with the volume turned up yet the video player minimized or provided behind another open window or tab, state component 108 can determine that the user is passively engaged in a ‘listening only mode.’ However where both the video player is not visible and the volume is turned off or down, state component 108 can determine that the user is disengaged.
Further, state component 108 can employ information regarding a user's movement/motion to determine or infer a user's state of mind. For example, if a user is moving or headed somewhere, state component 108 can determine that the user is in a state of ‘haste’ or ‘on the go.’ Similarly, if the user is stationary, state component 108 can determine that the user is relaxed and has time on his hands.
In another aspect, context component 110 can determine or infer content characteristics that relate to what a user is doing aside from or in association with a current session with a content provider (e.g., walking, exercising, riding a train/bus, working, conducting a work meeting, attending a class, cleaning the house, attending a party with friends, etc.). Context component can also determine characteristics regarding what the user was doing before and/or will do after the current session. For example, context component 110 can determine or infer an activity performed by the user preceding initiation of the current session, a duration of time the user has available for the current session, or an activity for performance by the user at a known point in time after initiation of the current session. Context component 110 can determine these content characteristics related to what a user is doing, was doing and will do in the near future based on analysis of a various received signals related to where the user is located, time of day, what device the user is on, and movement data for the user in view of the user's schedule and/or learned behavior for the user. For example, based on information indicating the user is located at her home around 6 am on a weekday morning, information indicating the user is moving about the house, information indicating the user is conducting a current media session on her Internet enabled television, and the user's work schedule, context component 110 can determine that the user is getting ready to go to work and will be leaving the house at about 7 am.
In an aspect, context component 110 can determine a purpose for a current session with a media provider based on how the current session was initiated. For example, the purpose of a session could initially include a user's desire to view a media item represented by a selected link at another source. According to this example, context component can determine 110 whether the user was directed to the media system from a referral source, a media item provided by the media provider represented by a link selected by the user at the referral source, and/or information about the referral source.
Further, context component 110 can determine or infer information related to sessions of other users, related to the user (e.g., friends of the user, users sharing similar preferences or demographics of the user, etc.), with the content provider that are being conducted during the current session of the user. For example, context information regarding content the user's friends are accessing and sharing while the user is also accessing the content provider can influence what the user may find interesting during the user's current session, such as what videos and channels the user's friends are watching during the user's current session with a media provider.
In various aspects, state component 108 can determine or infer various attributes about a user's state of mind based on characteristics of a user's context as determined by context component 110. In particular, a user's context can greatly influence the user's state of mind. For example, a user's mood can vary depending on the time of day, the user's environment (e.g., where the user is located and current aspects associated with the location at the time of day and day of week, including other persons, things and events or activities), what the user is doing in association with the current session (e.g., driving, relaxing, at a party, etc.), what the user just did before the session and/or has to do after the session, what device the user is employing, or how the user initiated the session (e.g., in response to selection of a link to a specific video, to conduct a search, or to browse). In various aspects, state component 110 can analyze characteristics about a user's context to facilitate determining or inferring a user's current state of mind (e.g., mood, attitude, emotional state, energy level, etc.). For example, state component 108 can employ various rule based classification schemes and/or machine learning techniques that relate different context attributes associated with a user's current context particular to state of mind attributes (e.g., mood values).
In an aspect, selection component 112 can employ a media index 118 that associates a plurality of media items and media advertisements, provided by the media provider, with state attributes and context attributes. The state and context attributes associated with a particular media item can be selected based on a particular user a state of mind and user context under which the media item is considered to be well received. For example, a video advertisement for a fast food breakfast restaurant could be associated with state attributes such as ‘hungry,’ ‘state of haste,’ ‘tired,’ or ‘on the go.’ Context attributes associated with the advertisement could include ‘morning,’ ‘driving,’ and ‘location N’ (wherein location N can vary and include different locations where the fast food breakfast restaurant is located). In another example, media items in media index 118 can be associated with various mood attributes indicative of modes the media items evoke or compliment, such as mood attributes indicating whether the media item is suited for users in an entertainment related or a work related mode. In another example, media items that are relatively short in length (based on a threshold length) can be associated with attributes that indicate they are suited for users who are in a state of haste/hurry or in distracted/passive state while media items that are longer in duration can be associated with attributes that indicate they are suited for users who are in leisurely, calm, time on their hands, attentive, etc., kind of state. In yet another example, a media advertisement can be associated with attributes that indicate whether it has audible branding or not (wherein a media advertisement without audible branding will be ineffective for a user who is passively engaged with a media content session based on failure to have a media player or interface visible to the user). Similarly, a media advertisement can be associated with an attribute indicating it has no or low visible branding (wherein the media advertisement will be ineffective when the user is passively engaged do to no or low volume).
According to this aspect, selection component 112 can match or relate user state attributes and user context characteristics with state attributes and context characteristics associated with different media items provided in media index 118 to identify one or more media items that match or relate the user's current state of mind and context. For example, when a user is relaxing in the evening at home and selecting and watching relatively short videos with funny and light hearted content, selection component 112 can select a media item for provision to the user that is also relatively short and has an entertaining, funny and light hearted nature.
In an aspect, a determination that a media item matches a user's current state and context can be based on a correspondence threshold (e.g., a percentage match threshold) between the user's current state and context attributes and the state and context attributes associated with the media item. The degree of contribution of certain state attributes and context characteristics to a match determination can also vary. For example, a location based context characteristic can provide a greater influence on a match determination over a context characteristic related to why a user's current session was initiated. In another aspect, selection component 112 can be configured to select media items that do not necessarily share the same state/context attributes as a user, but which are associated with state/context attributes that compliment those of the user. For example, where a user is in a sad mood in association with a cold winter weather, rather that identifying a media advertisement that is reflective of sad and cold winter weather attributes, selection component can identify a media advertisement that is associated with attributes designed to lift the user's spirits. For example, a suitable advertisement could include one for a warm weather vacation.
In other aspects, selection component 112 can employ various rule based classification schemes or machine based learning techniques to facilitate selecting a media item that a user will likely be receptive to and engage with during the user's current session with a media provider based on the user's current state of mind and context. In furtherance to the above example, selection component 112 can infer that although a user's state and context characteristics indicate the user is a relatively good match for the fast food breakfast restaurant advertisement, based on a single context characteristic that indicates the user has X amount of time before she has to be at work, the user will not be able to stop at the fast food breakfast restaurant on the way to work. Accordingly, selection component 112 can determine that provision of the fast food breakfast restaurant advertisement to the user during the user's current session would not cause the user to act on the advertisement, and thus select a different media advertisement for provision to the user.
Referring now to FIG. 2 presented is another example system 200 for identifying and rendering content relevant to a user's current mental state and context in accordance with various aspects and embodiments described herein. System 200 includes same or similar features and functionalities as system 100 with the additions of scoring component 202 and rendering component 204 to dynamic content selection platform 104. Repetitive description of like elements employed in respective embodiments of systems described herein is omitted for sake of brevity.
Scoring component 202 is configured to score and rank content items (e.g., media items) provided by content provider 102 (e.g., a streaming media provider based on relevance or suitability to a user in association with a current session between the user and the content provider 102, wherein the determination of relevance or suitability is based at least in part on the user's current state of mind and context. For example, scoring component 202 can score media advertisements provided by a media provider based on relevance and suitability of the media advertisements for a user during the user's current session with the media provider based on the user's current state of mind and context. In an aspect, scoring component 202 can analyze a plurality of media advertisements based on correspondence and fixed relationships between the user's current user state and context attributes and state and context attributes respectively associated with the media advertisements to determine a score for the respective media advertisements representative of relevance and suitability of the respective media advertisements to the user. According to this example, relevance and suitability can reflect a probability that the user will view the advertisement and/or the advertisement will have an impression upon the user. Selection component 112 can then select the media advertisement having the highest score (and/or a subset of the media advertisement having the highest scores) for provision to the user during the user's current media session.
For example, scoring component 202 can evaluate each pairing between a user and a potential media advertisement by putting the advertisement state and context attributes and the user's current state and context attributes into a 1×N boolean feature vector:
F=<f 1 ,f 2 , . . . ,f N>
wherein each attribute or feature (e.g., user is active, user is A, user is B . . . , advertisement is X, advertisement is Y, . . . , user has mood X, advertisement has mood Y, etc.) is assigned a fixed position. Then scoringcomponent 202 can score a particular advertisement/user pairing by taking the dot product with a weight vector W
F·W=S
where S is the score. The weight vector W can be designed to account for a probability that the media advertisement will be viewed past a billable point and/or a probability that the media advertisement will have a lasting impression upon the user. In an aspect, W can be generated using historical data using a machine learning algorithm.
F=<f 1 ,f 2 , . . . ,f N>
wherein each attribute or feature (e.g., user is active, user is A, user is B . . . , advertisement is X, advertisement is Y, . . . , user has mood X, advertisement has mood Y, etc.) is assigned a fixed position. Then scoring
F·W=S
where S is the score. The weight vector W can be designed to account for a probability that the media advertisement will be viewed past a billable point and/or a probability that the media advertisement will have a lasting impression upon the user. In an aspect, W can be generated using historical data using a machine learning algorithm.
In addition, as attributes for a user's current state of mind and context change over the course of a user's session with a media provider, scoring component 202 can re-score the respective media advertisements based on the new user attribute values. Accordingly, over the course of the user's session, selection component 112 can dynamically select the most relevant and suitable media advertisement for provision to the user at a current point in the user's session based on the user's current mental state and context at that point.
In another example, scoring component 202 can score and rank trailers for channels provided by a media provider or trailers for other videos provided by the media provider based on relevance and suitability for a user during the user's current session with the media provider in view of the user's current state of mind and context. According to this example, relevance and suitability can reflect a probability that the user will view the trailer and choose to select the channel or video represented by the trailer for watching, subscribing to, or otherwise showing an affinity for. In an aspect, selection component 112 can then select the trailer having the highest score (and/or a subset of the media advertisement having the highest scores) for provision to the user during the user's current media session. It is to be appreciated that respective scores associated with trailers can change over the course of a user's media session based on changes to the user's mood or context. Accordingly, at any given time in a user's media session, selection component 112 can select the trailer having the highest score at that time.
In yet another example, scoring component 202 can score other media items (e.g., videos, channels or playlists) provided by a media provider based on relevance and suitability for a user during the user's current session with the media provider based on the user's current state of mind and context. According to this example, relevance and suitability can reflect a probability that the user will view/play the media item or subscribe to the media item. Selection component 112 can then select a subset of media items having the highest scores for provision to the user in a recommendation section/list during the user's current media session.
In order to provide for or aid in the numerous inferences described herein, inference component 302 can examine the entirety or a subset of the data to which it is granted access and can provide for reasoning about or infer states of the system, environment, etc. from a set of observations as captured via events and/or data. An inference can be employed to identify a specific context or action, or can generate a probability distribution over states, for example. The inference can be probabilistic—that is, the computation of a probability distribution over states of interest based on a consideration of data and events. An inference can also refer to techniques employed for composing higher-level events from a set of events and/or data.
Such an inference can result in the construction of new events or actions from a set of observed events and/or stored event data, whether or not the events are correlated in close temporal proximity, and whether the events and data come from one or several event and data sources. Various classification (explicitly and/or implicitly trained) schemes and/or systems (e.g., support vector machines, neural networks, expert systems, Bayesian belief networks, fuzzy logic, data fusion engines, etc.) can be employed in connection with performing automatic and/or inferred action in connection with the claimed subject matter.
A classifier can map an input attribute vector, x=(x1, x2, x3, x4, xn), to a confidence that the input belongs to a class, such as by f(x)=confidence(class). Such classification can employ a probabilistic and/or statistical-based analysis (e.g., factoring into the analysis utilities and costs) to prognose or infer an action that a user desires to be automatically performed. A support vector machine (SVM) is an example of a classifier that can be employed. The SVM operates by finding a hyper-surface in the space of possible inputs, where the hyper-surface attempts to split the triggering criteria from the non-triggering events. Intuitively, this makes the classification correct for testing data that is near, but not identical to training data. Other directed and undirected model classification approaches include, e.g., naïve Bayes, Bayesian networks, decision trees, neural networks, fuzzy logic models, and probabilistic classification models providing different patterns of independence can be employed. Classification as used herein also is inclusive of statistical regression that is utilized to develop models of priority.
As previously discussed, selection component 112 is configured to select a content item for provision to a user during the user's current session with a content provider 102 based on the user's current state of mind and context. The type of the content item selected can vary depending on the content provider 102. In an aspect, where content provider 102 is a streaming media provider, the content item can include a trailer for another media item provided by the streaming media provider. In video and film terminology a trailer is a series of short edited clips of selected scenes of a video that are put together into one montage. Trailers are often used as a way to advertise a video or film. Trailer for channels provided by the streaming media provider can include video content associated with the channel configured to provide a video advertisement for the channel.
In view of the example systems and/or devices described herein, example methods that can be implemented in accordance with the disclosed subject matter can be further appreciated with reference to flowcharts in FIGS. 6-8 . For purposes of simplicity of explanation, example methods disclosed herein are presented and described as a series of acts; however, it is to be understood and appreciated that the disclosed subject matter is not limited by the order of acts, as some acts may occur in different orders and/or concurrently with other acts from that shown and described herein. For example, a method disclosed herein could alternatively be represented as a series of interrelated states or events, such as in a state diagram. Moreover, interaction diagram(s) may represent methods in accordance with the disclosed subject matter when disparate entities enact disparate portions of the methods. Furthermore, not all illustrated acts may be required to implement a method in accordance with the subject specification. It should be further appreciated that the methods disclosed throughout the subject specification are capable of being stored on an article of manufacture to facilitate transporting and transferring such methods to computers for execution by a processor or for storage in a memory.
For example, when a user is employing a search mechanism to find and watch videos related to repair a broken cell phone and the user repeatedly watches the beginning on the found videos before starting a new one, state component 108 can determine that the user is probably frustrated, annoyed, focused on finding a solution to a specific problem as opposed to looking for entertainment content and attentive to the current session. At 604, a media item provided by the streaming media provider is selected based on the user state attributes (e.g., via selection component 112). For example, selection component 112 can select a video trailer for a channel provided on by the streaming media provider that includes several short do it yourself repairs for different cell phone types and issues. In another example, selection component 112 can select a media advertisement for a service that repairs broken cell phones. At 604, the selected media item is then rendered to the user during the current session.
The systems and processes described below can be embodied within hardware, such as a single integrated circuit (IC) chip, multiple ICs, an application specific integrated circuit (ASIC), or the like. Further, the order in which some or all of the process blocks appear in each process should not be deemed limiting. Rather, it should be understood that some of the process blocks can be executed in a variety of orders, not all of which may be explicitly illustrated in this disclosure.
With reference to FIG. 10 , a suitable environment 1000 for implementing various aspects of the claimed subject matter includes a computer 1002. The computer 1002 includes a processing unit 1004, a system memory 1006, a codec 1005, and a system bus 1008. The system bus 1008 couples system components including, but not limited to, the system memory 1006 to the processing unit 1004. The processing unit 1004 can be any of various available processors. Dual microprocessors and other multiprocessor architectures also can be employed as the processing unit 1004.
The system bus 1008 can be any of several types of bus structure(s) including the memory bus or memory controller, a peripheral bus or external bus, and/or a local bus using any variety of available bus architectures including, but not limited to, Industrial Standard Architecture (ISA), Micro-Channel Architecture (MSA), Extended ISA (EISA), Intelligent Drive Electronics (IDE), VESA Local Bus (VLB), Peripheral Component Interconnect (PCI), Card Bus, Universal Serial Bus (USB), Advanced Graphics Port (AGP), Personal Computer Memory Card International Association bus (PCMCIA), Firewire (IEEE 13104), and Small Computer Systems Interface (SCSI).
The system memory 1006 includes volatile memory 1010 and non-volatile memory 1012. The basic input/output system (BIOS), containing the basic routines to transfer information between elements within the computer 1002, such as during start-up, is stored in non-volatile memory 1012. In addition, according to present innovations, codec 1005 may include at least one of an encoder or decoder, wherein the at least one of an encoder or decoder may consist of hardware, a combination of hardware and software, or software. Although, codec 1005 is depicted as a separate component, codec 1005 may be contained within non-volatile memory 1012. By way of illustration, and not limitation, non-volatile memory 1012 can include read only memory (ROM), programmable ROM (PROM), electrically programmable ROM (EPROM), electrically erasable programmable ROM (EEPROM), or flash memory. Volatile memory 1010 includes random access memory (RAM), which acts as external cache memory. According to present aspects, the volatile memory may store the write operation retry logic (not shown in FIG. 10 ) and the like. By way of illustration and not limitation, RAM is available in many forms such as static RAM (SRAM), dynamic RAM (DRAM), synchronous DRAM (SDRAM), double data rate SDRAM (DDR SDRAM), and enhanced SDRAM (ESDRAM.
It is to be appreciated that FIG. 10 describes software that acts as an intermediary between users and the basic computer resources described in the suitable operating environment 1000. Such software includes an operating system 1018. Operating system 1018, which can be stored on disk storage 1014, acts to control and allocate resources of the computer system 1002. Applications 1020 take advantage of the management of resources by operating system 1018 through program modules 1024, and program data 1026, such as the boot/shutdown transaction table and the like, stored either in system memory 1006 or on disk storage 1014. It is to be appreciated that the claimed subject matter can be implemented with various operating systems or combinations of operating systems.
A user enters commands or information into the computer 1002 through input device(s) 1028. Input devices 1028 include, but are not limited to, a pointing device such as a mouse, trackball, stylus, touch pad, keyboard, microphone, joystick, game pad, satellite dish, scanner, TV tuner card, digital camera, digital video camera, web camera, and the like. These and other input devices connect to the processing unit 1004 through the system bus 1008 via interface port(s) 1030. Interface port(s) 1030 include, for example, a serial port, a parallel port, a game port, and a universal serial bus (USB). Output device(s) 1036 use some of the same type of ports as input device(s). Thus, for example, a USB port may be used to provide input to computer 1002, and to output information from computer 1002 to an output device 1036. Output adapter 1034 is provided to illustrate that there are some output devices 1036 like monitors, speakers, and printers, among other output devices 1036, which require special adapters. The output adapters 1034 include, by way of illustration and not limitation, video and sound cards that provide a means of connection between the output device 1036 and the system bus 1008. It should be noted that other devices and/or systems of devices provide both input and output capabilities such as remote computer(s) 1038.
Communication connection(s) 1044 refers to the hardware/software employed to connect the network interface 1042 to the bus 1008. While communication connection 1044 is shown for illustrative clarity inside computer 1002, it can also be external to computer 1002. The hardware/software necessary for connection to the network interface 1042 includes, for exemplary purposes only, internal and external technologies such as, modems including regular telephone grade modems, cable modems and DSL modems, ISDN adapters, and wired and wireless Ethernet cards, hubs, and routers.
Referring now to FIG. 11 , there is illustrated a schematic block diagram of a computing environment 1100 in accordance with this disclosure. The system 1100 includes one or more client(s) 1102 (e.g., laptops, smart phones, PDAs, media players, computers, portable electronic devices, tablets, and the like). The client(s) 1102 can be hardware and/or software (e.g., threads, processes, computing devices). The system 1100 also includes one or more server(s) 1104. The server(s) 1104 can also be hardware or hardware in combination with software (e.g., threads, processes, computing devices). The servers 1104 can house threads to perform transformations by employing aspects of this disclosure, for example. One possible communication between a client 1102 and a server 1104 can be in the form of a data packet transmitted between two or more computer processes wherein the data packet may include video data. The data packet can include a metadata, e.g., associated contextual information, for example. The system 1100 includes a communication framework 1106 (e.g., a global communication network such as the Internet, or mobile network(s)) that can be employed to facilitate communications between the client(s) 1102 and the server(s) 1104.
Communications can be facilitated via a wired (including optical fiber) and/or wireless technology. The client(s) 1102 include or are operatively connected to one or more client data store(s) 1108 that can be employed to store information local to the client(s) 1102 (e.g., associated contextual information). Similarly, the server(s) 1104 are operatively include or are operatively connected to one or more server data store(s) 1110 that can be employed to store information local to the servers 1104.
In one embodiment, a client 1102 can transfer an encoded file, in accordance with the disclosed subject matter, to server 1104. Server 1104 can store the file, decode the file, or transmit the file to another client 1102. It is to be appreciated, that a client 1102 can also transfer uncompressed file to a server 1104 and server 1104 can compress the file in accordance with the disclosed subject matter. Likewise, server 1104 can encode video information and transmit the information via communication framework 1106 to one or more clients 1102.
The illustrated aspects of the disclosure may also be practiced in distributed computing environments where certain tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment, program modules can be located in both local and remote memory storage devices.
Moreover, it is to be appreciated that various components described in this description can include electrical circuit(s) that can include components and circuitry elements of suitable value in order to implement the embodiments of the subject innovation(s). Furthermore, it can be appreciated that many of the various components can be implemented on one or more integrated circuit (IC) chips. For example, in one embodiment, a set of components can be implemented in a single IC chip. In other embodiments, one or more of respective components are fabricated or implemented on separate IC chips.
What has been described above includes examples of the embodiments of the present invention. It is, of course, not possible to describe every conceivable combination of components or methodologies for purposes of describing the claimed subject matter, but it is to be appreciated that many further combinations and permutations of the subject innovation are possible. Accordingly, the claimed subject matter is intended to embrace all such alterations, modifications, and variations that fall within the spirit and scope of the appended claims. Moreover, the above description of illustrated embodiments of the subject disclosure, including what is described in the Abstract, is not intended to be exhaustive or to limit the disclosed embodiments to the precise forms disclosed. While specific embodiments and examples are described in this disclosure for illustrative purposes, various modifications are possible that are considered within the scope of such embodiments and examples, as those skilled in the relevant art can recognize.
In particular and in regard to the various functions performed by the above described components, devices, circuits, systems and the like, the terms used to describe such components are intended to correspond, unless otherwise indicated, to any component which performs the specified function of the described component (e.g., a functional equivalent), even though not structurally equivalent to the disclosed structure, which performs the function in the disclosure illustrated exemplary aspects of the claimed subject matter. In this regard, it will also be recognized that the innovation includes a system as well as a computer-readable storage medium having computer-executable instructions for performing the acts and/or events of the various methods of the claimed subject matter.
The aforementioned systems/circuits/modules have been described with respect to interaction between several components/blocks. It can be appreciated that such systems/circuits and components/blocks can include those components or specified sub-components, some of the specified components or sub-components, and/or additional components, and according to various permutations and combinations of the foregoing. Sub-components can also be implemented as components communicatively coupled to other components rather than included within parent components (hierarchical). Additionally, it should be noted that one or more components may be combined into a single component providing aggregate functionality or divided into several separate sub-components, and any one or more middle layers, such as a management layer, may be provided to communicatively couple to such sub-components in order to provide integrated functionality. Any components described in this disclosure may also interact with one or more other components not specifically described in this disclosure but known by those of skill in the art.
In addition, while a particular feature of the subject innovation may have been disclosed with respect to only one of several implementations, such feature may be combined with one or more other features of the other implementations as may be desired and advantageous for any given or particular application. Furthermore, to the extent that the terms “includes,” “including,” “has,” “contains,” variants thereof, and other similar words are used in either the detailed description or the claims, these terms are intended to be inclusive in a manner similar to the term “comprising” as an open transition word without precluding any additional or other elements.
As used in this application, the terms “component,” “module,” “system,” or the like are generally intended to refer to a computer-related entity, either hardware (e.g., a circuit), a combination of hardware and software, software, or an entity related to an operational machine with one or more specific functionalities. For example, a component may be, but is not limited to being, a process running on a processor (e.g., digital signal processor), a processor, an object, an executable, a thread of execution, a program, and/or a computer. By way of illustration, both an application running on a controller and the controller can be a component. One or more components may reside within a process and/or thread of execution and a component may be localized on one computer and/or distributed between two or more computers. Further, a “device” can come in the form of specially designed hardware; generalized hardware made specialized by the execution of software thereon that enables the hardware to perform specific function; software stored on a computer readable storage medium; software transmitted on a computer readable transmission medium; or a combination thereof.
Moreover, the words “example” or “exemplary” are used in this disclosure to mean serving as an example, instance, or illustration. Any aspect or design described in this disclosure as “exemplary” is not necessarily to be construed as preferred or advantageous over other aspects or designs. Rather, use of the words “example” or “exemplary” is intended to present concepts in a concrete fashion. As used in this application, the term “or” is intended to mean an inclusive “or” rather than an exclusive “or”. That is, unless specified otherwise, or clear from context, “X employs A or B” is intended to mean any of the natural inclusive permutations. That is, if X employs A; X employs B; or X employs both A and B, then “X employs A or B” is satisfied under any of the foregoing instances. In addition, the articles “a” and “an” as used in this application and the appended claims should generally be construed to mean “one or more” unless specified otherwise or clear from context to be directed to a singular form.
Computing devices typically include a variety of media, which can include computer-readable storage media and/or communications media, in which these two terms are used in this description differently from one another as follows. Computer-readable storage media can be any available storage media that can be accessed by the computer, is typically of a non-transitory nature, and can include both volatile and nonvolatile media, removable and non-removable media. By way of example, and not limitation, computer-readable storage media can be implemented in connection with any method or technology for storage of information such as computer-readable instructions, program modules, structured data, or unstructured data. Computer-readable storage media can include, but are not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disk (DVD) or other optical disk storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or other tangible and/or non-transitory media which can be used to store desired information. Computer-readable storage media can be accessed by one or more local or remote computing devices, e.g., via access requests, queries or other data retrieval protocols, for a variety of operations with respect to the information stored by the medium.
On the other hand, communications media typically embody computer-readable instructions, data structures, program modules or other structured or unstructured data in a data signal that can be transitory such as a modulated data signal, e.g., a carrier wave or other transport mechanism, and includes any information delivery or transport media. The term “modulated data signal” or signals refers to a signal that has one or more of its characteristics set or changed in such a manner as to encode information in one or more signals. By way of example, and not limitation, communication media include wired media, such as a wired network or direct-wired connection, and wireless media such as acoustic, RF, infrared and other wireless media.
In view of the exemplary systems described above, methodologies that may be implemented in accordance with the described subject matter will be better appreciated with reference to the flowcharts of the various figures. For simplicity of explanation, the methodologies are depicted and described as a series of acts. However, acts in accordance with this disclosure can occur in various orders and/or concurrently, and with other acts not presented and described in this disclosure. Furthermore, not all illustrated acts may be required to implement the methodologies in accordance with certain aspects of this disclosure. In addition, those skilled in the art will understand and appreciate that the methodologies could alternatively be represented as a series of interrelated states via a state diagram or events. Additionally, it should be appreciated that the methodologies disclosed in this disclosure are capable of being stored on an article of manufacture to facilitate transporting and transferring such methodologies to computing devices. The term article of manufacture, as used in this disclosure, is intended to encompass a computer program accessible from any computer-readable device or storage media.
Claims (20)
1. A method, comprising:
obtaining characteristics of a current context of a user comprising obtaining information specifying a current location of the user and one or more media items viewed by the user during a current viewing session with a media player, wherein the characteristics of the current context of the user comprises characteristics of media items viewed by other users in the current location of the user;
determining a current state of mind of the user based on the current location and characteristics of the one or more media items; selecting a subsequent media item to provide through the media player based on the determined current state of mind of the user; and
effectuating playing of the subsequent media item to the user through the media player.
2. The method of claim 1 , wherein the characteristics of the current context of the user comprises a length of each media item viewed by the user during the current viewing session.
3. The method of claim 1 , wherein the state of mind of the user comprises one of an entertainment state or a work related state.
4. The method of claim 1 , wherein obtaining the information specifying the current location of the user comprises obtaining location information from a global positioning system.
5. The method of claim 1 , wherein the characteristics of the current context of the user comprises at least one of (i) events at the current location of the user, (ii) one or more other users at the current location of the user, (iii) weather at the current location of the user, or (iv) traffic at the current location of the user.
6. The method of claim 1 , further comprising:
determining that the user's level of engagement with the media player has become a passive engagement;
selecting a content item to display through the media player while the user is passively engaged with media content played by the media player; and
effectuating playing of the content item to the user through the media player.
7. The method of claim 1 , wherein the characteristics of the current context of the user comprises characteristics of media items viewed by other users that are connected to the user in a social graph.
8. The method of claim 1 , wherein determining the current state of mind of the user comprises:
processing context attribute data comprising data specifying the current location and characteristics of the one or more media items using a machine-learning model to generate an output that infers the current state of mind of the user.
9. The method of claim 1 , wherein selecting a subsequent media item to provide through the media player based on the determined current state of mind of the user comprises processing the determined current state of mind of the user using a machine learning model.
10. A system comprising:
a data storage device; and one or more processors configured to interact with the data storage device executing instructions that cause the one or more processors to perform operations comprising:
obtaining characteristics of a current context of a user comprising obtaining information specifying a current location of the user and one or more media items viewed by the user during a current viewing session with a media player, wherein the characteristics of the current context of the user comprises characteristics of media items viewed by other users in the current location of the user;
determining a current state of mind of the user based on the current location and characteristics of the one or more media items;
selecting a subsequent media item to provide through the media player based on the determined current state of mind of the user; and
effectuating playing of the subsequent media item to the user through the media player.
11. The system of claim 10 , wherein the characteristics of the current context of the user comprises a length of each media item viewed by the user during the current viewing session.
12. The system of claim 10 , wherein the state of mind of the user comprises one of an entertainment state or a work related state.
13. The system of claim 10 , wherein obtaining the information specifying the current location of the user comprises obtaining location information from a global positioning system.
14. The system of claim 10 , wherein the characteristics of the current context of the user comprises at least one of (i) events at the current location of the user, (ii) one or more other users at the current location of the user, (iii) weather at the current location of the user, or (iv) traffic at the current location of the user.
15. The system of claim 10 , wherein the operations comprise:
determining that the user's level of engagement with the media player has become a passive engagement;
selecting a content item to display through the media player while the user is passively engaged with media content played by the media player; and
effectuating playing of the content item to the user through the media player.
16. The system of claim 10 , wherein the characteristics of the current context of the user comprises characteristics of media items viewed by other users that are connected to the user in a social graph.
17. A non-transitory computer readable medium storing instructions that, upon execution, cause one or more processors to perform operations comprising:
obtaining characteristics of a current context of a user comprising obtaining information specifying a current location of the user and one or more media items viewed by the user during a current viewing session with a media player, wherein the characteristics of the current context of the user comprises characteristics of media items viewed by other users in the current location of the user;
determining a current state of mind of the user based on the current location and characteristics of the one or more media items;
selecting a subsequent media item to provide through the media player based on the determined current state of mind of the user; and effectuating playing of the subsequent media item to the user through the media player.
18. The non-transitory computer readable medium of claim 17 , wherein the characteristics of the current context of the user comprises a length of each media item viewed by the user during the current viewing session.
19. The non-transitory computer readable medium of claim 17 , wherein the state of mind of the user comprises one of an entertainment state or a work related state.
20. The non-transitory computer readable medium of claim 17 , wherein obtaining the information specifying the current location of the user comprises obtaining location information from a global positioning system.
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US17/833,061 US11861132B1 (en) | 2014-12-01 | 2022-06-06 | Identifying and rendering content relevant to a user's current mental state and context |
Applications Claiming Priority (5)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/556,802 US9712587B1 (en) | 2014-12-01 | 2014-12-01 | Identifying and rendering content relevant to a user's current mental state and context |
US15/651,232 US10481749B1 (en) | 2014-12-01 | 2017-07-17 | Identifying and rendering content relevant to a user's current mental state and context |
US16/597,307 US10963119B1 (en) | 2014-12-01 | 2019-10-09 | Identifying and rendering content relevant to a user's current mental state and context |
US17/118,068 US11372514B1 (en) | 2014-12-01 | 2020-12-10 | Identifying and rendering content relevant to a user's current mental state and context |
US17/833,061 US11861132B1 (en) | 2014-12-01 | 2022-06-06 | Identifying and rendering content relevant to a user's current mental state and context |
Related Parent Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US17/118,068 Continuation US11372514B1 (en) | 2014-12-01 | 2020-12-10 | Identifying and rendering content relevant to a user's current mental state and context |
Publications (1)
Publication Number | Publication Date |
---|---|
US11861132B1 true US11861132B1 (en) | 2024-01-02 |
Family
ID=68536353
Family Applications (4)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US15/651,232 Active 2035-05-01 US10481749B1 (en) | 2014-12-01 | 2017-07-17 | Identifying and rendering content relevant to a user's current mental state and context |
US16/597,307 Active US10963119B1 (en) | 2014-12-01 | 2019-10-09 | Identifying and rendering content relevant to a user's current mental state and context |
US17/118,068 Active US11372514B1 (en) | 2014-12-01 | 2020-12-10 | Identifying and rendering content relevant to a user's current mental state and context |
US17/833,061 Active US11861132B1 (en) | 2014-12-01 | 2022-06-06 | Identifying and rendering content relevant to a user's current mental state and context |
Family Applications Before (3)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US15/651,232 Active 2035-05-01 US10481749B1 (en) | 2014-12-01 | 2017-07-17 | Identifying and rendering content relevant to a user's current mental state and context |
US16/597,307 Active US10963119B1 (en) | 2014-12-01 | 2019-10-09 | Identifying and rendering content relevant to a user's current mental state and context |
US17/118,068 Active US11372514B1 (en) | 2014-12-01 | 2020-12-10 | Identifying and rendering content relevant to a user's current mental state and context |
Country Status (1)
Country | Link |
---|---|
US (4) | US10481749B1 (en) |
Families Citing this family (8)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10481749B1 (en) * | 2014-12-01 | 2019-11-19 | Google Llc | Identifying and rendering content relevant to a user's current mental state and context |
US11721090B2 (en) * | 2017-07-21 | 2023-08-08 | Samsung Electronics Co., Ltd. | Adversarial method and system for generating user preferred contents |
JP7134751B2 (en) * | 2018-07-04 | 2022-09-12 | シャープ株式会社 | Communication terminal, content server, content recommendation system, control device, and control method executed by communication terminal |
GB202007688D0 (en) | 2020-05-22 | 2020-07-08 | Psykhe Ltd | Matching users with visual items |
FR3111044A1 (en) * | 2020-05-29 | 2021-12-03 | Orange | Prediction of negative emotional situations in a connected habitat to promote services invoking positive emotions |
US11451870B1 (en) | 2021-08-19 | 2022-09-20 | Rovi Guides, Inc. | Methods and systems to dynamically adjust a playlist based on cumulative mood score |
US11895368B2 (en) * | 2022-03-04 | 2024-02-06 | Humane, Inc. | Generating, storing, and presenting content based on a memory metric |
US11949967B1 (en) * | 2022-09-28 | 2024-04-02 | International Business Machines Corporation | Automatic connotation for audio and visual content using IOT sensors |
Citations (43)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20030128871A1 (en) * | 2000-04-01 | 2003-07-10 | Rolf-Dieter Naske | Methods and systems for 2D/3D image conversion and optimization |
US20040191737A1 (en) * | 2003-03-25 | 2004-09-30 | Mark Doehner | Process for curing psychosis in humans |
US20080082613A1 (en) | 2006-09-28 | 2008-04-03 | Yahoo! Inc. | Communicating online presence and mood |
US20100011388A1 (en) | 2008-07-10 | 2010-01-14 | William Bull | System and method for creating playlists based on mood |
US20100122174A1 (en) | 2008-05-28 | 2010-05-13 | Snibbe Interactive, Inc. | System and method for interfacing interactive systems with social networks and media playback devices |
US20100211966A1 (en) | 2007-02-20 | 2010-08-19 | Panasonic Corporation | View quality judging device, view quality judging method, view quality judging program, and recording medium |
US20120304206A1 (en) | 2011-05-26 | 2012-11-29 | Verizon Patent And Licensing, Inc. | Methods and Systems for Presenting an Advertisement Associated with an Ambient Action of a User |
US20130081081A1 (en) | 2011-09-22 | 2013-03-28 | Tcl Lab (Us) Inc. | Least Click TV |
US20130080907A1 (en) | 2011-09-23 | 2013-03-28 | Richard Skelton | Method and system for a personalized content play list |
US20130243270A1 (en) * | 2012-03-16 | 2013-09-19 | Gila Kamhi | System and method for dynamic adaption of media based on implicit user input and behavior |
US20130290843A1 (en) | 2012-04-25 | 2013-10-31 | Nokia Corporation | Method and apparatus for generating personalized media streams |
US20130298044A1 (en) | 2004-12-30 | 2013-11-07 | Aol Inc. | Mood-based organization and display of co-user lists |
US20140052282A1 (en) | 2012-08-17 | 2014-02-20 | Be Labs, Llc | Music generator |
US20140114899A1 (en) | 2012-10-23 | 2014-04-24 | Empire Technology Development Llc | Filtering user actions based on user's mood |
US20140200463A1 (en) * | 2010-06-07 | 2014-07-17 | Affectiva, Inc. | Mental state well being monitoring |
US20140210640A1 (en) | 2011-06-10 | 2014-07-31 | Aliphcom | Data-capable band management in an integrated application and network communication data environment |
US20140337790A1 (en) * | 2013-05-10 | 2014-11-13 | Moonjung Kim | Mobile terminal and method for controlling the same |
US20150018660A1 (en) | 2013-07-11 | 2015-01-15 | Alivecor, Inc. | Apparatus for Coupling to Computing Devices and Measuring Physiological Data |
US20150032899A1 (en) | 2011-11-14 | 2015-01-29 | Telefonaktiebolaget L M Ericsson (Publ) | Media Streaming in Mobile Networks with Improved Efficiency |
US20150053066A1 (en) | 2013-08-20 | 2015-02-26 | Harman International Industries, Incorporated | Driver assistance system |
US20150067708A1 (en) | 2013-08-30 | 2015-03-05 | United Video Properties, Inc. | Systems and methods for generating media asset representations based on user emotional responses |
US20150153910A1 (en) | 2013-12-03 | 2015-06-04 | Google Inc. | Dyanmic thumbnail representation for a video playlist |
US20150200945A1 (en) * | 2014-01-10 | 2015-07-16 | Kuhoo Edson | Information organization, management, and processing system and methods |
US20150206523A1 (en) * | 2014-01-23 | 2015-07-23 | National Chiao Tung University | Method for selecting music based on face recognition, music selecting system and electronic apparatus |
US20150264431A1 (en) | 2014-03-14 | 2015-09-17 | Aliphcom | Presentation and recommendation of media content based on media content responses determined using sensor data |
US20150297109A1 (en) | 2014-04-22 | 2015-10-22 | Interaxon Inc. | System and method for associating music with brain-state data |
US20150318020A1 (en) | 2014-05-02 | 2015-11-05 | FreshTake Media, Inc. | Interactive real-time video editor and recorder |
US20150338917A1 (en) | 2012-12-26 | 2015-11-26 | Sia Technology Ltd. | Device, system, and method of controlling electronic devices via thought |
US20160065724A1 (en) | 2014-08-29 | 2016-03-03 | Samsung Electronics Co., Ltd. | Method for providing content and electronic device thereof |
US9399111B1 (en) * | 2013-03-15 | 2016-07-26 | Aic Innovations Group, Inc. | Method and apparatus for emotional behavior therapy |
US20160234369A1 (en) | 2015-02-06 | 2016-08-11 | Samsung Electronics Co., Ltd. | Multi-purpose device including mobile terminal and sensing device using radio-wave based sensor module |
US20160300102A1 (en) | 2013-11-20 | 2016-10-13 | Realeyes Ou | Method of benchmarking media content based on viewer behavior |
US20160308925A1 (en) | 2013-05-07 | 2016-10-20 | Nagravision S.A. | A media player for receiving media content from a remote server |
US20160335047A1 (en) | 2015-05-15 | 2016-11-17 | Spotify Ab | Methods and devices for adjustment of the energy level of a played audio stream |
US20170046496A1 (en) | 2015-08-10 | 2017-02-16 | Social Health Innovations, Inc. | Methods for tracking and responding to mental health changes in a user |
US9641488B2 (en) * | 2014-02-28 | 2017-05-02 | Dropbox, Inc. | Advanced security protocol for broadcasting and synchronizing shared folders over local area network |
US9652783B2 (en) | 2009-06-30 | 2017-05-16 | Verizon Patent And Licensing Inc. | Methods and systems for controlling presentation of media content based on user interaction |
US9788777B1 (en) * | 2013-08-12 | 2017-10-17 | The Neilsen Company (US), LLC | Methods and apparatus to identify a mood of media |
US10037339B1 (en) * | 2017-12-28 | 2018-07-31 | Dropbox, Inc. | Synchronized organization directory with team member folders |
US10264067B2 (en) * | 2013-03-10 | 2019-04-16 | Dropbox, Inc. | Content item sharing and synchronization system with team shared folders |
US10397319B2 (en) * | 2015-11-24 | 2019-08-27 | Dropbox, Inc. | Server-side selective synchronization |
US20200275875A1 (en) | 2019-02-28 | 2020-09-03 | Social Health Innovations, Inc. | Method for deriving and storing emotional conditions of humans |
US10805388B2 (en) * | 2012-08-10 | 2020-10-13 | Dropbox, Inc. | System, method, and computer program for enabling a user to access and edit via a virtual drive objects synchronized to a plurality of synchronization clients |
Family Cites Families (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20140298364A1 (en) * | 2013-03-26 | 2014-10-02 | Rawllin International Inc. | Recommendations for media content based on emotion |
WO2015020069A1 (en) * | 2013-08-08 | 2015-02-12 | 国立大学法人電気通信大学 | Data processing device, data processing method, program, recording medium, and data processing system |
US10481749B1 (en) * | 2014-12-01 | 2019-11-19 | Google Llc | Identifying and rendering content relevant to a user's current mental state and context |
-
2017
- 2017-07-17 US US15/651,232 patent/US10481749B1/en active Active
-
2019
- 2019-10-09 US US16/597,307 patent/US10963119B1/en active Active
-
2020
- 2020-12-10 US US17/118,068 patent/US11372514B1/en active Active
-
2022
- 2022-06-06 US US17/833,061 patent/US11861132B1/en active Active
Patent Citations (44)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20030128871A1 (en) * | 2000-04-01 | 2003-07-10 | Rolf-Dieter Naske | Methods and systems for 2D/3D image conversion and optimization |
US20040191737A1 (en) * | 2003-03-25 | 2004-09-30 | Mark Doehner | Process for curing psychosis in humans |
US20130298044A1 (en) | 2004-12-30 | 2013-11-07 | Aol Inc. | Mood-based organization and display of co-user lists |
US20080082613A1 (en) | 2006-09-28 | 2008-04-03 | Yahoo! Inc. | Communicating online presence and mood |
US20100211966A1 (en) | 2007-02-20 | 2010-08-19 | Panasonic Corporation | View quality judging device, view quality judging method, view quality judging program, and recording medium |
US20100122174A1 (en) | 2008-05-28 | 2010-05-13 | Snibbe Interactive, Inc. | System and method for interfacing interactive systems with social networks and media playback devices |
US20100011388A1 (en) | 2008-07-10 | 2010-01-14 | William Bull | System and method for creating playlists based on mood |
US9652783B2 (en) | 2009-06-30 | 2017-05-16 | Verizon Patent And Licensing Inc. | Methods and systems for controlling presentation of media content based on user interaction |
US20140200463A1 (en) * | 2010-06-07 | 2014-07-17 | Affectiva, Inc. | Mental state well being monitoring |
US20120304206A1 (en) | 2011-05-26 | 2012-11-29 | Verizon Patent And Licensing, Inc. | Methods and Systems for Presenting an Advertisement Associated with an Ambient Action of a User |
US20140210640A1 (en) | 2011-06-10 | 2014-07-31 | Aliphcom | Data-capable band management in an integrated application and network communication data environment |
US20130081081A1 (en) | 2011-09-22 | 2013-03-28 | Tcl Lab (Us) Inc. | Least Click TV |
US20130080907A1 (en) | 2011-09-23 | 2013-03-28 | Richard Skelton | Method and system for a personalized content play list |
US20150032899A1 (en) | 2011-11-14 | 2015-01-29 | Telefonaktiebolaget L M Ericsson (Publ) | Media Streaming in Mobile Networks with Improved Efficiency |
US20130243270A1 (en) * | 2012-03-16 | 2013-09-19 | Gila Kamhi | System and method for dynamic adaption of media based on implicit user input and behavior |
US20130290843A1 (en) | 2012-04-25 | 2013-10-31 | Nokia Corporation | Method and apparatus for generating personalized media streams |
US10805388B2 (en) * | 2012-08-10 | 2020-10-13 | Dropbox, Inc. | System, method, and computer program for enabling a user to access and edit via a virtual drive objects synchronized to a plurality of synchronization clients |
US20140052282A1 (en) | 2012-08-17 | 2014-02-20 | Be Labs, Llc | Music generator |
US20140114899A1 (en) | 2012-10-23 | 2014-04-24 | Empire Technology Development Llc | Filtering user actions based on user's mood |
US20150338917A1 (en) | 2012-12-26 | 2015-11-26 | Sia Technology Ltd. | Device, system, and method of controlling electronic devices via thought |
US10264067B2 (en) * | 2013-03-10 | 2019-04-16 | Dropbox, Inc. | Content item sharing and synchronization system with team shared folders |
US9399111B1 (en) * | 2013-03-15 | 2016-07-26 | Aic Innovations Group, Inc. | Method and apparatus for emotional behavior therapy |
US20160308925A1 (en) | 2013-05-07 | 2016-10-20 | Nagravision S.A. | A media player for receiving media content from a remote server |
US20140337790A1 (en) * | 2013-05-10 | 2014-11-13 | Moonjung Kim | Mobile terminal and method for controlling the same |
US20150018660A1 (en) | 2013-07-11 | 2015-01-15 | Alivecor, Inc. | Apparatus for Coupling to Computing Devices and Measuring Physiological Data |
US9788777B1 (en) * | 2013-08-12 | 2017-10-17 | The Neilsen Company (US), LLC | Methods and apparatus to identify a mood of media |
US20150053066A1 (en) | 2013-08-20 | 2015-02-26 | Harman International Industries, Incorporated | Driver assistance system |
US20150067708A1 (en) | 2013-08-30 | 2015-03-05 | United Video Properties, Inc. | Systems and methods for generating media asset representations based on user emotional responses |
US20160300102A1 (en) | 2013-11-20 | 2016-10-13 | Realeyes Ou | Method of benchmarking media content based on viewer behavior |
US20150153910A1 (en) | 2013-12-03 | 2015-06-04 | Google Inc. | Dyanmic thumbnail representation for a video playlist |
US9454289B2 (en) | 2013-12-03 | 2016-09-27 | Google Inc. | Dyanmic thumbnail representation for a video playlist |
US20150200945A1 (en) * | 2014-01-10 | 2015-07-16 | Kuhoo Edson | Information organization, management, and processing system and methods |
US20150206523A1 (en) * | 2014-01-23 | 2015-07-23 | National Chiao Tung University | Method for selecting music based on face recognition, music selecting system and electronic apparatus |
US9641488B2 (en) * | 2014-02-28 | 2017-05-02 | Dropbox, Inc. | Advanced security protocol for broadcasting and synchronizing shared folders over local area network |
US20150264431A1 (en) | 2014-03-14 | 2015-09-17 | Aliphcom | Presentation and recommendation of media content based on media content responses determined using sensor data |
US20150297109A1 (en) | 2014-04-22 | 2015-10-22 | Interaxon Inc. | System and method for associating music with brain-state data |
US20150318020A1 (en) | 2014-05-02 | 2015-11-05 | FreshTake Media, Inc. | Interactive real-time video editor and recorder |
US20160065724A1 (en) | 2014-08-29 | 2016-03-03 | Samsung Electronics Co., Ltd. | Method for providing content and electronic device thereof |
US20160234369A1 (en) | 2015-02-06 | 2016-08-11 | Samsung Electronics Co., Ltd. | Multi-purpose device including mobile terminal and sensing device using radio-wave based sensor module |
US20160335047A1 (en) | 2015-05-15 | 2016-11-17 | Spotify Ab | Methods and devices for adjustment of the energy level of a played audio stream |
US20170046496A1 (en) | 2015-08-10 | 2017-02-16 | Social Health Innovations, Inc. | Methods for tracking and responding to mental health changes in a user |
US10397319B2 (en) * | 2015-11-24 | 2019-08-27 | Dropbox, Inc. | Server-side selective synchronization |
US10037339B1 (en) * | 2017-12-28 | 2018-07-31 | Dropbox, Inc. | Synchronized organization directory with team member folders |
US20200275875A1 (en) | 2019-02-28 | 2020-09-03 | Social Health Innovations, Inc. | Method for deriving and storing emotional conditions of humans |
Non-Patent Citations (6)
Title |
---|
Cowie et al., "Emotion recognition in human-computer interaction." IEEE Signal processing magazine 18.1, Jan. 2001, 32-80. |
Jung et al., Product-Awareness Through Smart Audio Navigation in a Retail Environment, 2011, IEEE, 6 pages. (Year: 2011). * |
Lehtiniemi et al., "Evaluating MoodPic—A concept for collaborative mood music playlist creation." 2013 17th International Conference on Information Visualisation. IEEE, Jul. 2013, 10 pages. |
Lehtiniemi et al., Evaluating MoodPic—a Concept for Collaborative Mood Music Playlist Creation, 2013, IEEE, 6 pages. (Year: 2013 ). * |
Schatter et al., Product-Awareness Through Smart Audio Navigation in a Retail Environment, 2011, IEEE, 4 Page. (Year: 2011). * |
Yu et al., "Design of a mobile telephony system for social interaction." 2013 IEEE International Conference on Green Computing and Communications and IEEE Internet of Things and IEEE Cyber, Physical and Social Computing. IEEE, Aug. 2013, 7 pages. |
Also Published As
Publication number | Publication date |
---|---|
US10481749B1 (en) | 2019-11-19 |
US11372514B1 (en) | 2022-06-28 |
US10963119B1 (en) | 2021-03-30 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US9712587B1 (en) | Identifying and rendering content relevant to a user's current mental state and context | |
US11861132B1 (en) | Identifying and rendering content relevant to a user's current mental state and context | |
US11936610B2 (en) | Privacy aligned and personalized social media content sharing recommendations | |
US11974019B2 (en) | Identifying related videos based on relatedness of elements tagged in the videos | |
US9998796B1 (en) | Enhancing live video streams using themed experiences | |
US9055343B1 (en) | Recommending content based on probability that a user has interest in viewing the content again | |
US9967628B2 (en) | Rating videos based on parental feedback | |
US8255293B1 (en) | Product catalog dynamically tailored to user-selected media content | |
US11979465B2 (en) | Recommending media content to a user based on information associated with a referral source | |
US11683548B2 (en) | Conditional display of hyperlinks in a video | |
US9820004B1 (en) | Optimizing timing of display of a video overlay | |
US10783157B1 (en) | Delivering a continuous feed of content items to a client device | |
US20230089961A1 (en) | Optimizing content distribution using a model | |
US10620801B1 (en) | Generation and presentation of interactive information cards for a video | |
US20230401604A1 (en) | Systems and methods for composing a media feed for a target user by selecting media assets that share congruent objects with a secondary content item | |
Haugen | Mobile News: Design, User Experience and Recommendation | |
Lagger | User intent classification for video retrieval |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
FEPP | Fee payment procedure |
Free format text: ENTITY STATUS SET TO UNDISCOUNTED (ORIGINAL EVENT CODE: BIG.); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |