US10302499B2 - Adaptive threshold manipulation for movement detecting sensors - Google Patents
Adaptive threshold manipulation for movement detecting sensors Download PDFInfo
- Publication number
- US10302499B2 US10302499B2 US14/523,078 US201414523078A US10302499B2 US 10302499 B2 US10302499 B2 US 10302499B2 US 201414523078 A US201414523078 A US 201414523078A US 10302499 B2 US10302499 B2 US 10302499B2
- Authority
- US
- United States
- Prior art keywords
- sensor
- data
- processor
- smart
- threshold
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
- 230000033001 locomotion Effects 0.000 title description 33
- 230000003044 adaptive effect Effects 0.000 title 1
- 238000005259 measurement Methods 0.000 claims abstract description 70
- 241000282414 Homo sapiens Species 0.000 claims description 104
- 241001465754 Metazoa Species 0.000 claims description 16
- 230000004044 response Effects 0.000 claims description 9
- 238000000034 method Methods 0.000 abstract description 56
- 230000035945 sensitivity Effects 0.000 abstract description 22
- 230000006854 communication Effects 0.000 description 35
- 238000004891 communication Methods 0.000 description 35
- 238000001514 detection method Methods 0.000 description 31
- 230000000694 effects Effects 0.000 description 29
- 230000007613 environmental effect Effects 0.000 description 23
- 238000012545 processing Methods 0.000 description 21
- 239000000779 smoke Substances 0.000 description 19
- 230000003068 static effect Effects 0.000 description 18
- XLYOFNOQVPJJNP-UHFFFAOYSA-N water Substances O XLYOFNOQVPJJNP-UHFFFAOYSA-N 0.000 description 17
- 241000607479 Yersinia pestis Species 0.000 description 11
- 238000003032 molecular docking Methods 0.000 description 10
- 230000006870 function Effects 0.000 description 9
- 230000007958 sleep Effects 0.000 description 9
- UGFAIRIUMAVXCW-UHFFFAOYSA-N Carbon monoxide Chemical compound [O+]#[C-] UGFAIRIUMAVXCW-UHFFFAOYSA-N 0.000 description 7
- 229910002091 carbon monoxide Inorganic materials 0.000 description 7
- 230000001960 triggered effect Effects 0.000 description 7
- 238000013473 artificial intelligence Methods 0.000 description 6
- 238000005516 engineering process Methods 0.000 description 6
- 230000008569 process Effects 0.000 description 6
- 230000000007 visual effect Effects 0.000 description 6
- CURLTUGMZLYLDI-UHFFFAOYSA-N Carbon dioxide Chemical compound O=C=O CURLTUGMZLYLDI-UHFFFAOYSA-N 0.000 description 5
- 230000008859 change Effects 0.000 description 5
- 230000001276 controlling effect Effects 0.000 description 5
- 238000010586 diagram Methods 0.000 description 5
- 238000003973 irrigation Methods 0.000 description 5
- 230000002262 irrigation Effects 0.000 description 5
- 238000004519 manufacturing process Methods 0.000 description 5
- 238000012544 monitoring process Methods 0.000 description 5
- 241000282412 Homo Species 0.000 description 4
- 230000008901 benefit Effects 0.000 description 4
- 230000000875 corresponding effect Effects 0.000 description 4
- 238000004458 analytical method Methods 0.000 description 3
- 238000013459 approach Methods 0.000 description 3
- 230000009286 beneficial effect Effects 0.000 description 3
- 230000007175 bidirectional communication Effects 0.000 description 3
- 230000033228 biological regulation Effects 0.000 description 3
- 238000004422 calculation algorithm Methods 0.000 description 3
- 229910002092 carbon dioxide Inorganic materials 0.000 description 3
- 230000015556 catabolic process Effects 0.000 description 3
- 238000001914 filtration Methods 0.000 description 3
- 230000001965 increasing effect Effects 0.000 description 3
- 230000010354 integration Effects 0.000 description 3
- 238000013508 migration Methods 0.000 description 3
- 230000005012 migration Effects 0.000 description 3
- 230000003287 optical effect Effects 0.000 description 3
- 230000005855 radiation Effects 0.000 description 3
- 241000238631 Hexapoda Species 0.000 description 2
- 241000283984 Rodentia Species 0.000 description 2
- 230000009471 action Effects 0.000 description 2
- 239000001569 carbon dioxide Substances 0.000 description 2
- 238000010411 cooking Methods 0.000 description 2
- 230000002596 correlated effect Effects 0.000 description 2
- 230000001186 cumulative effect Effects 0.000 description 2
- 238000006731 degradation reaction Methods 0.000 description 2
- 238000013461 design Methods 0.000 description 2
- 238000011161 development Methods 0.000 description 2
- 230000018109 developmental process Effects 0.000 description 2
- 238000009826 distribution Methods 0.000 description 2
- 230000001815 facial effect Effects 0.000 description 2
- 231100001261 hazardous Toxicity 0.000 description 2
- 239000000383 hazardous chemical Substances 0.000 description 2
- 230000036541 health Effects 0.000 description 2
- 230000003993 interaction Effects 0.000 description 2
- 238000013507 mapping Methods 0.000 description 2
- 238000012986 modification Methods 0.000 description 2
- 230000004048 modification Effects 0.000 description 2
- 230000029058 respiratory gaseous exchange Effects 0.000 description 2
- 238000010408 sweeping Methods 0.000 description 2
- 238000012549 training Methods 0.000 description 2
- 238000012384 transportation and delivery Methods 0.000 description 2
- 238000002604 ultrasonography Methods 0.000 description 2
- 238000005406 washing Methods 0.000 description 2
- 208000024827 Alzheimer disease Diseases 0.000 description 1
- 241001674044 Blattodea Species 0.000 description 1
- 244000035744 Hura crepitans Species 0.000 description 1
- 241000256602 Isoptera Species 0.000 description 1
- 241000699670 Mus sp. Species 0.000 description 1
- 230000001133 acceleration Effects 0.000 description 1
- 230000002238 attenuated effect Effects 0.000 description 1
- 230000006399 behavior Effects 0.000 description 1
- 230000005540 biological transmission Effects 0.000 description 1
- 235000021152 breakfast Nutrition 0.000 description 1
- 238000004364 calculation method Methods 0.000 description 1
- 231100000357 carcinogen Toxicity 0.000 description 1
- 239000003183 carcinogenic agent Substances 0.000 description 1
- 230000001413 cellular effect Effects 0.000 description 1
- 230000008131 children development Effects 0.000 description 1
- 238000004590 computer program Methods 0.000 description 1
- 238000001816 cooling Methods 0.000 description 1
- 238000013500 data storage Methods 0.000 description 1
- 230000003111 delayed effect Effects 0.000 description 1
- 238000006073 displacement reaction Methods 0.000 description 1
- 239000003814 drug Substances 0.000 description 1
- 229940079593 drug Drugs 0.000 description 1
- 238000005265 energy consumption Methods 0.000 description 1
- 230000002708 enhancing effect Effects 0.000 description 1
- 231100000573 exposure to toxins Toxicity 0.000 description 1
- 230000008570 general process Effects 0.000 description 1
- 235000019580 granularity Nutrition 0.000 description 1
- 238000010438 heat treatment Methods 0.000 description 1
- 238000005286 illumination Methods 0.000 description 1
- 238000003384 imaging method Methods 0.000 description 1
- 230000002779 inactivation Effects 0.000 description 1
- 238000009434 installation Methods 0.000 description 1
- 238000012423 maintenance Methods 0.000 description 1
- 238000007620 mathematical function Methods 0.000 description 1
- 230000035764 nutrition Effects 0.000 description 1
- 235000016709 nutrition Nutrition 0.000 description 1
- 238000003909 pattern recognition Methods 0.000 description 1
- 238000002360 preparation method Methods 0.000 description 1
- 230000002265 prevention Effects 0.000 description 1
- 238000011160 research Methods 0.000 description 1
- 230000000630 rising effect Effects 0.000 description 1
- 239000002689 soil Substances 0.000 description 1
- 230000005236 sound signal Effects 0.000 description 1
- 239000000126 substance Substances 0.000 description 1
- 230000008685 targeting Effects 0.000 description 1
- 230000002123 temporal effect Effects 0.000 description 1
- 230000007704 transition Effects 0.000 description 1
- 238000010407 vacuum cleaning Methods 0.000 description 1
- 230000002618 waking effect Effects 0.000 description 1
Images
Classifications
-
- G01J5/32—
-
- G—PHYSICS
- G01—MEASURING; TESTING
- G01J—MEASUREMENT OF INTENSITY, VELOCITY, SPECTRAL CONTENT, POLARISATION, PHASE OR PULSE CHARACTERISTICS OF INFRARED, VISIBLE OR ULTRAVIOLET LIGHT; COLORIMETRY; RADIATION PYROMETRY
- G01J1/00—Photometry, e.g. photographic exposure meter
- G01J1/42—Photometry, e.g. photographic exposure meter using electric radiation detectors
- G01J1/44—Electric circuits
-
- G—PHYSICS
- G05—CONTROLLING; REGULATING
- G05B—CONTROL OR REGULATING SYSTEMS IN GENERAL; FUNCTIONAL ELEMENTS OF SUCH SYSTEMS; MONITORING OR TESTING ARRANGEMENTS FOR SUCH SYSTEMS OR ELEMENTS
- G05B15/00—Systems controlled by a computer
- G05B15/02—Systems controlled by a computer electric
-
- G—PHYSICS
- G08—SIGNALLING
- G08B—SIGNALLING OR CALLING SYSTEMS; ORDER TELEGRAPHS; ALARM SYSTEMS
- G08B13/00—Burglar, theft or intruder alarms
- G08B13/18—Actuation by interference with heat, light, or radiation of shorter wavelength; Actuation by intruding sources of heat, light, or radiation of shorter wavelength
- G08B13/189—Actuation by interference with heat, light, or radiation of shorter wavelength; Actuation by intruding sources of heat, light, or radiation of shorter wavelength using passive radiation detection systems
- G08B13/19—Actuation by interference with heat, light, or radiation of shorter wavelength; Actuation by intruding sources of heat, light, or radiation of shorter wavelength using passive radiation detection systems using infrared-radiation detection systems
- G08B13/191—Actuation by interference with heat, light, or radiation of shorter wavelength; Actuation by intruding sources of heat, light, or radiation of shorter wavelength using passive radiation detection systems using infrared-radiation detection systems using pyroelectric sensor means
-
- G—PHYSICS
- G08—SIGNALLING
- G08B—SIGNALLING OR CALLING SYSTEMS; ORDER TELEGRAPHS; ALARM SYSTEMS
- G08B29/00—Checking or monitoring of signalling or alarm systems; Prevention or correction of operating errors, e.g. preventing unauthorised operation
- G08B29/18—Prevention or correction of operating errors
- G08B29/20—Calibration, including self-calibrating arrangements
- G08B29/24—Self-calibration, e.g. compensating for environmental drift or ageing of components
- G08B29/26—Self-calibration, e.g. compensating for environmental drift or ageing of components by updating and storing reference thresholds
-
- H05B37/0218—
-
- H05B37/0227—
-
- H05B37/0272—
-
- H—ELECTRICITY
- H05—ELECTRIC TECHNIQUES NOT OTHERWISE PROVIDED FOR
- H05B—ELECTRIC HEATING; ELECTRIC LIGHT SOURCES NOT OTHERWISE PROVIDED FOR; CIRCUIT ARRANGEMENTS FOR ELECTRIC LIGHT SOURCES, IN GENERAL
- H05B47/00—Circuit arrangements for operating light sources in general, i.e. where the type of light source is not relevant
- H05B47/10—Controlling the light source
- H05B47/105—Controlling the light source in response to determined parameters
- H05B47/11—Controlling the light source in response to determined parameters by determining the brightness or colour temperature of ambient light
-
- H—ELECTRICITY
- H05—ELECTRIC TECHNIQUES NOT OTHERWISE PROVIDED FOR
- H05B—ELECTRIC HEATING; ELECTRIC LIGHT SOURCES NOT OTHERWISE PROVIDED FOR; CIRCUIT ARRANGEMENTS FOR ELECTRIC LIGHT SOURCES, IN GENERAL
- H05B47/00—Circuit arrangements for operating light sources in general, i.e. where the type of light source is not relevant
- H05B47/10—Controlling the light source
- H05B47/105—Controlling the light source in response to determined parameters
- H05B47/115—Controlling the light source in response to determined parameters by determining the presence or movement of objects or living beings
- H05B47/13—Controlling the light source in response to determined parameters by determining the presence or movement of objects or living beings by using passive infrared detectors
-
- H—ELECTRICITY
- H05—ELECTRIC TECHNIQUES NOT OTHERWISE PROVIDED FOR
- H05B—ELECTRIC HEATING; ELECTRIC LIGHT SOURCES NOT OTHERWISE PROVIDED FOR; CIRCUIT ARRANGEMENTS FOR ELECTRIC LIGHT SOURCES, IN GENERAL
- H05B47/00—Circuit arrangements for operating light sources in general, i.e. where the type of light source is not relevant
- H05B47/10—Controlling the light source
- H05B47/175—Controlling the light source by remote control
- H05B47/19—Controlling the light source by remote control via wireless transmission
-
- G—PHYSICS
- G05—CONTROLLING; REGULATING
- G05B—CONTROL OR REGULATING SYSTEMS IN GENERAL; FUNCTIONAL ELEMENTS OF SUCH SYSTEMS; MONITORING OR TESTING ARRANGEMENTS FOR SUCH SYSTEMS OR ELEMENTS
- G05B2219/00—Program-control systems
- G05B2219/20—Pc systems
- G05B2219/26—Pc applications
- G05B2219/2642—Domotique, domestic, home control, automation, smart house
-
- G—PHYSICS
- G08—SIGNALLING
- G08B—SIGNALLING OR CALLING SYSTEMS; ORDER TELEGRAPHS; ALARM SYSTEMS
- G08B19/00—Alarms responsive to two or more different undesired or abnormal conditions, e.g. burglary and fire, abnormal temperature and abnormal rate of flow
- G08B19/005—Alarms responsive to two or more different undesired or abnormal conditions, e.g. burglary and fire, abnormal temperature and abnormal rate of flow combined burglary and fire alarm systems
-
- H—ELECTRICITY
- H05—ELECTRIC TECHNIQUES NOT OTHERWISE PROVIDED FOR
- H05B—ELECTRIC HEATING; ELECTRIC LIGHT SOURCES NOT OTHERWISE PROVIDED FOR; CIRCUIT ARRANGEMENTS FOR ELECTRIC LIGHT SOURCES, IN GENERAL
- H05B47/00—Circuit arrangements for operating light sources in general, i.e. where the type of light source is not relevant
- H05B47/10—Controlling the light source
- H05B47/105—Controlling the light source in response to determined parameters
- H05B47/115—Controlling the light source in response to determined parameters by determining the presence or movement of objects or living beings
- H05B47/125—Controlling the light source in response to determined parameters by determining the presence or movement of objects or living beings by using cameras
-
- Y—GENERAL TAGGING OF NEW TECHNOLOGICAL DEVELOPMENTS; GENERAL TAGGING OF CROSS-SECTIONAL TECHNOLOGIES SPANNING OVER SEVERAL SECTIONS OF THE IPC; TECHNICAL SUBJECTS COVERED BY FORMER USPC CROSS-REFERENCE ART COLLECTIONS [XRACs] AND DIGESTS
- Y02—TECHNOLOGIES OR APPLICATIONS FOR MITIGATION OR ADAPTATION AGAINST CLIMATE CHANGE
- Y02B—CLIMATE CHANGE MITIGATION TECHNOLOGIES RELATED TO BUILDINGS, e.g. HOUSING, HOUSE APPLIANCES OR RELATED END-USER APPLICATIONS
- Y02B20/00—Energy efficient lighting technologies, e.g. halogen lamps or gas discharge lamps
- Y02B20/40—Control techniques providing energy savings, e.g. smart controller or presence detection
-
- Y02B20/44—
-
- Y02B20/46—
Definitions
- the present disclosure relates generally to detecting movement of objects to infer a presence of a living being. More specifically, the present disclosure relates to adaptively adjusting a threshold associated with sensor measurements used to detect a movement of objects to infer presence of a living being.
- Various types of smart electronic devices may control temperatures, detect hazardous environments, or perform other functions in a building such as a home or office. These electronic devices may vary their operation depending on whether a human being is occupying the building. For example, the electronic devices may save energy by efficiently controlling certain environmental properties, such as temperature, based on whether a human being is present in the building.
- an occupancy sensor e.g., a passive infrared (PIR) sensor
- PIR passive infrared
- each occupancy sensor may produce measurement signals that include some level of noise.
- the electronic devices may be programmed to use an occupancy threshold that is greater than the expected noise level of its occupancy sensor to avoid false positives due to noise.
- the actual amount of noise from any given occupancy sensor may vary substantially over the course of time due to, e.g., changing environmental conditions (i.e., temperature, humidity, etc.), sensor degradation, changes in battery level, etc.
- the amount of noise produced by different occupancy sensors may vary even in the same environmental conditions due to, e.g, manufacturing tolerance levels.
- the occupancy thresholds may be selected based on the noisiest occupancy sensors that may be found in the electronic devices. As a result of having unnecessarily high occupancy thresholds, many electronic devices may have an undesirably low occupancy detection sensitivity.
- Embodiments of the present disclosure relate to an electronic device, such as a thermostat or a hazard detector (e.g., smoke detector) that may be disposed in a building (e.g., home or office), such that the electronic device may detect the presence of a human being in the building.
- a hazard detector e.g., smoke detector
- each electronic device may use a sensor to sense the presence of the human when measurements acquired by the sensors are above a certain threshold.
- manufacturers of the electronic device may determine the value for the threshold and use the determined threshold for each of its electronic devices.
- the sensor used to detect human presence in each electronic device may have different sensitivity characteristics with respect to noise, different electronic devices may detect a presence of the same human being at different times. For example, sensors less sensitive to noise may detect the presence of the human later than sensors more sensitive to noise. Further, some electronic devices may falsely detect the presence of a human being when the sensors measurements correspond to the presence of an animal, such as a pet.
- the threshold used to denote the presence of a human being with respect to the sensor measurements may be adaptively adjusted for each individual electronic device according to the sensitivity characteristics of a respective sensor. That is, the threshold for human detection may be recalibrated, recalculated, or adjusted throughout the lifecycle of the electronic device.
- a processor may collect sensor measurements from a passive infrared (PIR) sensor when a respective building or a respective part of the respective building is expected to be unoccupied by a human. Using the sensor measurements collected during this time period, the processor may determine a threshold for detecting the presence of a human being based on the collected sensor measurements, which may be susceptible to various noise characteristics inherent in the respective sensor. As a result, each respective electronic device may more accurately detect the presence of a human regardless of the noise sensitivity levels of its respective sensor.
- PIR passive infrared
- FIG. 1 illustrates a block diagram of a general device that may control and/or monitor a building environment, in accordance with an embodiment
- FIG. 2 illustrates a block diagram of a smart-home environment in which the general device of FIG. 1 may communicate with other devices via a network layer protocol, in accordance with an embodiment
- FIG. 3 illustrates a network-level view of an extensible devices and services platform with which the smart-home environment of FIG. 2 can be integrated, in accordance with an embodiment
- FIG. 4 illustrates an abstracted functional view of the extensible devices and services platform of FIG. 3 , with reference to a processing engine as well as devices of the smart-home environment, in accordance with an embodiment
- FIG. 5 illustrates a graph of sensor measurements associated with PIR sensors and a threshold associated with detecting a presence of a human being, in accordance with an embodiment
- FIG. 6 illustrates a graph of sensor measurements associated with PIR sensors and a threshold associated with falsely detecting a presence of a human being, in accordance with an embodiment
- FIG. 7 illustrates a graph of sensor measurements associated with PIR sensors and a threshold associated with early detection of a presence of a human being, in accordance with an embodiment
- FIGS. 8 and 9 illustrate examples of when the general device of FIG. 1 may detect a presence of a human, in accordance with an embodiment
- FIG. 10 illustrates a graph of cumulative distributions of noise for different passive infrared (PIR) sensors that may be part of the general device of FIG. 1 , in accordance with an embodiment
- FIG. 11 illustrates a flow chart of a method for adjusting a threshold for detecting the presence of a human based on PIR sensor measurements, in accordance with an embodiment
- FIG. 12 illustrates a flow chart of a method that a low-power processor in the general device of FIG. 1 may employ when adjusting the threshold for detecting the presence of a human based on PIR sensor measurements, in accordance with an embodiment
- FIG. 13 illustrates a flow chart of a method that a high-power processor in the general device of FIG. 1 may employ when interacting with the low-power processor in the general device of FIG. 1 , in accordance with an embodiment
- FIG. 14 illustrates a flow chart of a method that a high-power processor in the general device of FIG. 1 may employ when adjusting the threshold for detecting the presence of a human based on PIR sensor measurements, in accordance with an embodiment
- FIG. 15 illustrates a flow chart of a method for determining statistics based on PIR sensor measurements, in accordance with an embodiment
- FIG. 16 illustrates a schematic diagram of sensor ranges for two types of general devices of FIG. 1 , in accordance with an embodiment
- FIG. 17 illustrates a flow chart of a method for adjusting the threshold for detecting the presence of a human when a pet is expected to be present based on PIR sensor measurements, in accordance with an embodiment
- FIG. 18 illustrates graphs of sensor measurements associated with PIR sensors and thresholds associated with a presence of a human being for the two general devices of FIG. 16 , in accordance with an embodiment.
- Embodiments of the present disclosure relate to an electronic device, such as a thermostat or a hazard detector (e.g., smoke detector) that may be disposed in a building (e.g., home or office), such that the electronic device may detect the presence of a human being in the building and distinguish between the presence of the human being and other objects/animals such as a pet.
- the electronic device may employ a sensor, such as a passive infrared (PIR) sensor, to detect the presence of a human being.
- PIR passive infrared
- each PIR sensor may be inherently sensitive to different levels of noise. By accounting for the different sensitivity levels of each PIR sensor, the electronic device may improve its detection of human beings and better distinguish between the presence of human beings and other objects/animals such as pets.
- the electronic device may include a low-power processor that may store the sensor measurements acquired by the PIR sensor during a time period when the electronic device does not expect a human in the building or portion of the building being monitored by electronic device.
- the low-power processor may send the stored sensor measurements to a high-power processor of the electronic device.
- the high-power processor may then calculate a threshold or adjust the previous threshold for determining a presence of a human based on the stored sensor measurements that correspond to the time period when a human being is likely not present in the building.
- the high-power processor may then send the newly calculated or the adjusted threshold to the low-power processor.
- the low-power processor may then use the newly calculated or the adjusted threshold to detect the presence of a human. Since the new threshold is calculated based on the sensor measurements from a particular PIR sensor of a particular electronic device, the new threshold may compensate for the inherent sensitivity characteristics of that particular PIR sensor. As a result, the electronic device may detect the presence of a human being more effectively and efficiently.
- FIG. 1 illustrates an example of a general electronic device 10 that may be disposed inside or outside of a structure.
- the device 10 may include one or more sensors 12 , a user-interface component 14 , a power supply 16 (e.g., including a power connection and/or battery), a network interface 18 , a high-power processor 20 , a low-power processor 22 , a passive infrared (PIR) sensor 24 , a light source 26 , and the like.
- a power supply 16 e.g., including a power connection and/or battery
- PIR passive infrared
- the sensors 12 may detect various properties such as acceleration, temperature, humidity, water, supplied power, proximity, external motion, device motion, sound signals, ultrasound signals, light signals, fire, smoke, carbon monoxide, global-positioning-satellite (GPS) signals, radio-frequency (RF), other electromagnetic signals or fields, or the like.
- various properties such as acceleration, temperature, humidity, water, supplied power, proximity, external motion, device motion, sound signals, ultrasound signals, light signals, fire, smoke, carbon monoxide, global-positioning-satellite (GPS) signals, radio-frequency (RF), other electromagnetic signals or fields, or the like.
- GPS global-positioning-satellite
- RF radio-frequency
- the sensors 12 may include temperature sensor(s), humidity sensor(s), hazard-related sensor(s) or other environmental sensor(s), accelerometer(s), microphone(s), optical sensors up to and including camera(s) (e.g., charged coupled-device or video cameras), active or passive radiation sensors, GPS receiver(s) or radiofrequency identification detector(s) infrared sensor(s), continuous wave radar sensor(s), ultrasonic sound wave sensor(s), microwave sensor(s), tomographic motion sensor(s), vibration sensor(s), a combination of the aforementioned sensors, and the like. While FIG. 1 illustrates an embodiment with a single sensor, many embodiments may include multiple sensors. In some instances, the device 10 may includes one or more primary sensors and one or more secondary sensors.
- the primary sensor(s) may sense data central to the core operation of the device (e.g., sensing a temperature in a thermostat or sensing smoke in a smoke detector), while the secondary sensor(s) may sense other types of data (e.g., motion, light or sound), which can be used for energy-efficiency objectives or smart-operation objectives.
- data e.g., sensing a temperature in a thermostat or sensing smoke in a smoke detector
- other types of data e.g., motion, light or sound
- One or more components of the user-interface 14 in the device 10 may receive input from the user and/or present information to the user. The received input may be used to determine a setting to configure operation of the device 10 .
- the user-interface components may include a mechanical or virtual component that responds to the user's motion. For example, the user can mechanically move a sliding component (e.g., along a vertical or horizontal track) or rotate a rotatable ring (e.g., along a circular track), or the user's motion along a touchpad may be detected.
- Such motions may correspond to a setting adjustment, which can be determined based on an absolute position of a component of the user-interface 14 or based on a displacement of a component of the user-interface 14 (e.g., adjusting a set point temperature by 1 degree F. for every 10° rotation of a rotatable-ring component).
- Physically and virtually movable user-interface components can allow a user to set a setting along a portion of an apparent continuum.
- the user may not be confined to choose between two discrete options (e.g., as would be the case if up and down buttons were used) but can quickly and intuitively define a setting along a range of possible setting values.
- a magnitude of a movement of a user-interface component may be associated with a magnitude of a setting adjustment, such that a user may dramatically alter a setting with a large movement or finely tune a setting with a small movement.
- the user-interface 14 may also or alternatively include one or more buttons (e.g., up and down buttons), a keypad, a number pad, a switch, a microphone, and/or a camera (e.g., to detect gestures).
- the user-interface 14 may include a click-and-rotate annular ring component that may enable the user to interact with the component by rotating the ring (e.g., to adjust a setting) and/or by clicking the ring inwards (e.g., to select an adjusted setting or to select an option).
- the user-interface 14 may include a camera that may detect gestures (e.g., to indicate that a power or alarm state of a device is to be changed).
- the device 10 may have one primary input component, which may be used to set a number of types of settings.
- the user-interface 14 may also be configured to present information to a user via, e.g., a visual display (e.g., a thin-film-transistor display or organic light-emitting-diode display) and/or an audio speaker.
- the power-supply 16 may include a power connection and/or a local battery.
- the power connection may connect the device 10 to a power source such as a line voltage source.
- a power source such as a line voltage source.
- an AC power source can be used to repeatedly charge a (e.g., rechargeable) local battery, such that the battery may be used later to supply power to the device 10 when the AC power source is not available.
- the network interface 18 may include a component that enables the device 10 to communicate between devices. As such, the network interface 18 may enable the device 10 to communicate with other devices 10 via a wired or wireless network.
- the network interface 18 may include a wireless card or some other transceiver connection to facilitate this communication.
- the high-power processor 20 and the low-power processor 22 may support one or more of a variety of different device functionalities.
- the high-power processor 20 and the low-power processor 22 may each include one or more processors configured and programmed to carry out and/or cause to be carried out one or more of the functionalities described herein.
- the high-power processor 20 and the low-power processor 22 may include general-purpose processors carrying out computer code stored in local memory (e.g., flash memory, hard drive, random access memory), special-purpose processors or application-specific integrated circuits, combinations thereof, and/or using other types of hardware/firmware/software processing platforms.
- the high-power processor 20 may execute computationally intensive operations such as operating the user-interface component 14 and the like.
- the low-power processor 22 may manage less complex processes such as detecting a hazard or temperature from the sensor 12 .
- the high-power processor 20 may have a higher operating power requirement than the low-power processor 22 .
- the low-power processor may wake or initialize the high-power processor for computationally intensive processes.
- the high-power processor 20 and the low-power processor 22 may detect when a location (e.g., a house or room) is occupied (i.e., includes a presence of a human), up to and including whether it is occupied by a specific person or is occupied by a specific number of people (e.g., relative to one or more thresholds). In one embodiment, this detection can occur, e.g., by analyzing microphone signals, detecting user movements (e.g., in front of a device), detecting openings and closings of doors or garage doors, detecting wireless signals, detecting an internet protocol (IP) address of a received signal, detecting operation of one or more devices within a time window, or the like.
- IP internet protocol
- the high-power processor 20 and the low-power processor 22 may include image recognition technology to identify particular occupants or objects.
- the high-power processor 20 and/or the low-power processor 22 may detect the presence of a human using the PIR sensor 24 .
- the PIR sensor 24 may be a passive infrared sensor that may measures infrared (IR) light radiating from objects in its field of view. As such, the PIR sensor 24 may detect the Infrared radiation emitted from an object.
- IR infrared
- the high-power processor 20 may determine desirable settings and/or implement those settings based sensor measurements from one or more sensors. For example, based on the presence detection, the high-power processor 20 may adjust device settings to, e.g., conserve power when nobody is home or in a particular room or to accord with user preferences (e.g., general at-home preferences or user-specific preferences).
- user preferences e.g., general at-home preferences or user-specific preferences.
- the high-power processor 20 may initiate an audio or visual indicator of where the person, animal or object is (either on the device itself or on a remote device via wired/wireless communication of information representative of where the person, animal or object is) or may initiate an alarm or security feature (either on the device itself or on the remote device) if an unrecognized person is detected under certain conditions (e.g., at night or when lights are off).
- devices may interact with each other such that events detected by a first device influences actions of a second device.
- a first device can detect that a user has entered into a garage (e.g., by detecting motion in the garage, detecting a change in light in the garage or detecting opening of the garage door).
- the first device can transmit this information to a second device via the network interface 18 , such that the second device can, e.g., adjust a home temperature setting, a light setting, a music setting, and/or a security-alarm setting.
- a first device can detect a user approaching a front door (e.g., by detecting motion or sudden light pattern changes).
- the first device may, e.g., cause a general audio or visual signal to be presented (e.g., such as sounding of a doorbell) or cause a location-specific audio or visual signal to be presented (e.g., to announce the visitor's presence within a room that a user is occupying) via a second device.
- a general audio or visual signal e.g., such as sounding of a doorbell
- a location-specific audio or visual signal e.g., to announce the visitor's presence within a room that a user is occupying
- the device 10 may include a light source 26 that may illuminate when a living being, such as a human, is detected as approaching.
- the light source 26 may include any type of light source, such as one or more light-emitting diodes, or the like.
- the light source 26 may be communicatively coupled to the high-power processor 20 and the low-power processor 22 , which may provide a signal to cause the light source 26 to illuminate.
- embodiments are not limited to the specific components or combination of components of device 10 as described with reference to FIG. 1 . Rather, embodiments include a variety of combinations as would be recognized by one skilled in the art in view of the current disclosure. For example, some embodiments may exclude the low power processor 22 , the sensors 12 , the light source 26 , and/or the network interface 18 . Further, in some embodiments the functionality of different components of device 10 as described with reference to FIG. 1 may be combined into new components or separated into multiple components. For example, in some embodiments the functionality described with reference to the low power processor 22 and high power processor 20 may be performed by a single processor.
- FIG. 2 illustrates an example of a smart-home environment 30 within which one or more of the devices 10 of FIG. 1 , methods, systems, services, and/or computer program products described further herein can be applicable.
- the depicted smart-home environment 30 includes a structure 32 , which can include, e.g., a house, office building, garage, or mobile home.
- a structure 32 can include, e.g., a house, office building, garage, or mobile home.
- devices can also be integrated into a smart-home environment 30 that does not include an entire structure 32 , such as an apartment, condominium, or office space.
- the smart home environment can control and/or be coupled to devices outside of the actual structure 32 . Indeed, several devices in the smart home environment need not physically be within the structure 32 at all. For example, a device controlling a pool heater or irrigation system can be located outside of the structure 32 .
- the depicted structure 32 includes a number of rooms 38 , separated at least partly from each other via walls 40 .
- the walls 40 can include interior walls or exterior walls.
- Each room can further include a floor 42 and a ceiling 44 .
- Devices can be mounted on, integrated with and/or supported by a wall 40 , floor 42 or ceiling 44 .
- the smart-home environment 30 of FIG. 2 includes a number of devices 10 , including intelligent, multi-sensing, network-connected devices, that can integrate seamlessly with each other and/or with a central server or a cloud-computing system to provide any of a variety of useful smart-home objectives.
- devices 10 including intelligent, multi-sensing, network-connected devices, that can integrate seamlessly with each other and/or with a central server or a cloud-computing system to provide any of a variety of useful smart-home objectives.
- the smart-home environment 30 may include one or more intelligent, multi-sensing, network-connected thermostats 46 (hereinafter referred to as “smart thermostats 46 ”), one or more intelligent, network-connected, multi-sensing hazard detection units 50 (hereinafter referred to as “smart hazard detectors 50 ”), and one or more intelligent, multi-sensing, network-connected entryway interface devices 52 (hereinafter referred to as “smart doorbells 52 ”).
- the smart thermostat 46 may include a Nest® Learning Thermostat—1st Generation T100577 or Nest® Learning Thermostat—2nd Generation T200577 by Nest Labs, Inc., among others.
- the smart thermostat 46 detects ambient climate characteristics (e.g., temperature and/or humidity) and controls a HVAC system 48 accordingly.
- the smart hazard detector 50 may detect the presence of a hazardous substance or a substance indicative of a hazardous substance (e.g., smoke, fire, or carbon monoxide).
- the smart hazard detector 50 may include a Nest® Protect that may include sensors 12 such as smoke sensors, carbon monoxide sensors, and the like. As such, the hazard detector 50 may determine when smoke, fire, and/or carbon monoxide may be present within the building.
- the smart doorbell 52 may detect a person's approach to or departure from a location (e.g., an outer door), control doorbell functionality, announce a person's approach or departure via audio or visual means, or control settings on a security system (e.g., to activate or deactivate the security system when occupants go and come).
- the smart doorbell 52 may interact with other devices 10 based on whether someone has approached or entered the smart-home environment 30 .
- the smart-home environment 30 further includes one or more intelligent, multi-sensing, network-connected wall switches 54 (hereinafter referred to as “smart wall switches 54 ”), along with one or more intelligent, multi-sensing, network-connected wall plug interfaces 56 (hereinafter referred to as “smart wall plugs 56 ”).
- the smart wall switches 54 may detect ambient lighting conditions, detect room-occupancy states, and control a power and/or dim state of one or more lights. In some instances, smart wall switches 54 may also control a power state or speed of a fan, such as a ceiling fan.
- the smart wall plugs 56 may detect occupancy of a room or enclosure and control supply of power to one or more wall plugs (e.g., such that power is not supplied to the plug if nobody is at home).
- the device 10 within the smart-home environment 30 may further includes a number of intelligent, multi-sensing, network-connected appliances 58 (hereinafter referred to as “smart appliances 58 ”), such as refrigerators, stoves and/or ovens, televisions, washers, dryers, lights, stereos, intercom systems, garage-door openers, floor fans, ceiling fans, wall air conditioners, pool heaters, irrigation systems, security systems, and so forth.
- the network-connected appliances 58 are made compatible with the smart-home environment by cooperating with the respective manufacturers of the appliances.
- the appliances can be space heaters, window AC units, motorized duct vents, etc.
- an appliance When plugged in, an appliance can announce itself to the smart-home network, such as by indicating what type of appliance it is, and it can automatically integrate with the controls of the smart-home. Such communication by the appliance to the smart home can be facilitated by any wired or wireless communication protocols known by those having ordinary skill in the art.
- the smart home also can include a variety of non-communicating legacy appliances 68 , such as old conventional washer/dryers, refrigerators, and the like which can be controlled, albeit coarsely (ON/OFF), by virtue of the smart wall plugs 56 .
- the smart-home environment 30 can further include a variety of partially communicating legacy appliances 70 , such as infrared (“IR”) controlled wall air conditioners or other IR-controlled devices, which can be controlled by IR signals provided by the smart hazard detectors 50 or the smart wall switches 54 .
- legacy appliances 70 such as infrared (“IR”) controlled wall air conditioners or other IR-controlled devices, which can be controlled by IR signals provided by the smart hazard detectors 50 or the smart wall switches 54 .
- the smart thermostats 46 , the smart hazard detectors 50 , the smart doorbells 52 , the smart wall switches 54 , the smart wall plugs 56 , and other devices of the smart-home environment 30 are modular and can be incorporated into older and new houses.
- the devices 10 may be designed around a modular platform consisting of two basic components: a head unit and a back plate, which is also referred to as a docking station. Multiple configurations of the docking station are provided so as to be compatible with any home, such as older and newer homes. However, all of the docking stations include a standard head-connection arrangement, such that any head unit can be removably attached to any docking station.
- the docking stations are interfaces that serve as physical connections to the structure and the voltage wiring of the homes, and the interchangeable head units contain all of the sensors 12 , processors 28 , user interfaces 14 , the power supply 16 , the network interface 18 , and other functional components of the devices described above.
- the head unit can ask the user (by 2D LCD display, 2D/3D holographic projection, voice interaction, etc.) a few simple questions such as, “Where am I” and the user can indicate “living room”, “kitchen” and so forth.
- the smart-home environment 30 may also include communication with devices outside of the physical home but within a proximate geographical range of the home.
- the smart-home environment 30 may include a pool heater monitor 34 that communicates a current pool temperature to other devices within the smart-home environment 30 or receives commands for controlling the pool temperature.
- the smart-home environment 30 may include an irrigation monitor 36 that communicates information regarding irrigation systems within the smart-home environment 30 and/or receives control information for controlling such irrigation systems.
- the device 10 may include a number of components or machines that could be implemented in environments outside of the smart-home environment 30 .
- the device 10 may also include a vehicle, a component (e.g., robot) in a vehicle (e.g., emergency services), a streetlight, and the like.
- an algorithm for considering the geographic location of the smart-home environment 30 , such as based on the zip code or geographic coordinates of the home.
- the geographic information is then used to obtain data helpful for determining optimal times for watering, such data may include sun location information, temperature, dewpoint, soil type of the land on which the home is located, etc.
- one or more of the smart-home devices of FIG. 2 can further allow a user to interact with the device even if the user is not proximate to the device.
- a user can communicate with a device using a computer (e.g., a desktop computer, laptop computer, or tablet) or other portable electronic device (e.g., a smartphone) 66 .
- a web page or app can be configured to receive communications from the user and control the device based on the communications and/or to present information about the device's operation to the user.
- the user can view a current setpoint temperature for a thermostat and adjust it using a computer.
- the user can be in the structure during this remote communication or outside the structure.
- users can control the smart thermostat and other smart devices in the smart-home environment 30 using a network-connected computer or portable electronic device 66 .
- some or all of the occupants e.g., individuals who live in the home
- Such registration can be made at a central server to authenticate the occupant and/or the device as being associated with the home and to give permission to the occupant to use the device to control the smart devices in the home.
- An occupant can use their registered device 66 to remotely control the smart devices of the home, such as when the occupant is at work or on vacation.
- the occupant may also use their registered device to control the smart devices when the occupant is actually located inside the home, such as when the occupant is sitting on a couch inside the home. It should be appreciated that instead of or in addition to registering devices 66 , the smart-home environment 30 makes inferences about which individuals live in the home and are therefore occupants and which devices 66 are associated with those individuals. As such, the smart-home environment “learns” who is an occupant and permits the devices 66 associated with those individuals to control the smart devices of the home.
- the smart-home environment may receive communication from an unregistered mobile device of an individual inside of the home, where said individual is not recognized as an occupant of the home. Further, for example, a smart-home environment may receive communication from a mobile device of an individual who is known to be or who is registered as a guest.
- a guest-layer of controls can be provided to guests of the smart-home environment 30 .
- the guest-layer of controls gives guests access to basic controls (e.g., a judicially selected subset of features of the smart devices), such as temperature adjustments, but it locks out other functionalities.
- the guest layer of controls can be thought of as a “safe sandbox” in which guests have limited controls, but they do not have access to more advanced controls that could fundamentally alter, undermine, damage, or otherwise impair the occupant-desired operation of the smart devices. For example, the guest layer of controls will not permit the guest to adjust the heat-pump lockout temperature.
- a use case example of this is when a guest is in a smart home, the guest could walk up to the thermostat and turn the dial manually, but the guest may not want to walk around the house “hunting” for the thermostat, especially at night while the home is dark and others are sleeping. Further, the guest may not want to go through the hassle of downloading the necessary application to their device for remotely controlling the thermostat. In fact, the guest may not have the home owner's login credentials, etc., and therefore cannot remotely control the thermostat via such an application. Accordingly, according to embodiments of the invention, the guest can open a mobile browser on their mobile device, type a keyword, such as “NEST” into the URL field and tap “Go” or “Search”, etc.
- the device presents the guest with a user interface which allows the guest to move the target temperature between a limited range, such as 65 and 80 degrees Fahrenheit.
- a user interface provides a guest layer of controls that are limited to basic functions. The guest cannot change the target humidity, modes, or view energy history.
- a local webserver is provided that is accessible in the local area network (LAN). It does not require a password, because physical presence inside the home is established reliably enough by the guest's presence on the LAN.
- the home owner is asked if they want to enable a Local Web App (LWA) on the smart device.
- LWA Local Web App
- Business owners will likely say no; home owners will likely say yes.
- the smart device broadcasts to the LAN that the above referenced keyword, such as “NEST”, is now a host alias for its local web server.
- a guest layer of controls may also be provided to users by means other than a device 66 .
- the smart device such as the smart thermostat, may be equipped with walkup-identification technology (e.g., face recognition, RFID, ultrasonic sensors) that “fingerprints” or creates a “signature” for the occupants of the home.
- the walkup-identification technology can be the same as or similar to the fingerprinting and signature creating techniques described in other sections of this application.
- the smart device provides the guest with the guest layer of controls, rather than full controls.
- the smart thermostat 46 and other smart devices “learn” by observing occupant behavior. For example, the smart thermostat learns occupants' preferred temperature set-points for mornings and evenings, and it learns when the occupants are asleep or awake, as well as when the occupants are typically away or at home, for example. According to embodiments, when a guest controls the smart devices, such as the smart thermostat, the smart devices do not “learn” from the guest. This prevents the guest's adjustments and controls from affecting the learned preferences of the occupants.
- a smart television remote control recognizes occupants by thumbprint, visual identification, RFID, etc., and it recognizes a user as a guest or as someone belonging to a particular class having limited control and access (e.g., child).
- the smart remote control Upon recognizing the user as a guest or someone belonging to a limited class, the smart remote control only permits that user to view a subset of channels and to make limited adjustments to the settings of the television and other devices. For example, a guest cannot adjust the digital video recorder (DVR) settings, and a child is limited to viewing child-appropriate programming.
- DVR digital video recorder
- sinks, bathtubs, and showers can be controlled by smart spigots that recognize users as guests or as children and therefore prevent water from exceeding a designated temperature that is considered safe.
- each of the devices 34 , 36 , 46 , 50 , 52 , 54 , 56 , and 58 is capable of data communications and information sharing with any other of the smart devices, as well as to any central server or cloud-computing system or any other device that is network-connected anywhere in the world.
- the required data communications can be carried out using any of a variety of custom or standard wireless protocols (Wi-Fi, ZigBee, 6LoWPAN, etc.) and/or any of a variety of custom or standard wired protocols (CAT6 Ethernet, HomePlug, etc.).
- all or some of the smart devices can serve as wireless or wired repeaters.
- a first one of the smart devices can communicate with a second one of the smart device via a wireless router 60 .
- the smart devices can further communicate with each other via a connection to a network, such as the Internet 62 .
- the smart devices can communicate with a central server or a cloud-computing system 64 .
- the central server or cloud-computing system 64 can be associated with a manufacturer, support entity, or service provider associated with the device.
- a user may be able to contact customer support using a device itself rather than needing to use other communication means such as a telephone or Internet-connected computer.
- software updates can be automatically sent from the central server or cloud-computing system 64 to devices (e.g., when available, when purchased, or at routine intervals).
- the smart devices combine to create a mesh network of spokesman and low-power nodes in the smart-home environment 30 , where some of the smart devices are “spokesman” nodes and others are “low-powered” nodes. Some of the smart devices in the smart-home environment 30 are battery powered, while others have a regular and reliable power source, such as by connecting to wiring (e.g., to 120V line voltage wires) behind the walls 40 of the smart-home environment.
- the smart devices that have a regular and reliable power source are referred to as “spokesman” nodes.
- nodes are equipped with the capability of using any wireless protocol or manner to facilitate bidirectional communication with any of a variety of other devices in the smart-home environment 30 as well as with the central server or cloud-computing system 64 .
- the devices that are battery powered are referred to as “low-power” nodes.
- These nodes tend to be smaller than spokesman nodes and can only communicate using wireless protocols that require very little power, such as Zigbee, 6LoWPAN, etc. Further, some, but not all, low-power nodes are incapable of bidirectional communication. These low-power nodes send messages, but they are unable to “listen”. Thus, other devices in the smart-home environment 30 , such as the spokesman nodes, cannot send information to these low-power nodes.
- the smart devices serve as low-power and spokesman nodes to create a mesh network in the smart-home environment 30 .
- Individual low-power nodes in the smart-home environment regularly send out messages regarding what they are sensing, and the other low-powered nodes in the smart-home environment—in addition to sending out their own messages—repeat the messages, thereby causing the messages to travel from node to node (i.e., device to device) throughout the smart-home environment 30 .
- the spokesman nodes in the smart-home environment 30 are able to “drop down” to low-powered communication protocols to receive these messages, translate the messages to other communication protocols, and send the translated messages to other spokesman nodes and/or the central server or cloud-computing system 64 .
- the low-powered nodes using low-power communication protocols are able send messages across the entire smart-home environment 30 as well as over the Internet 62 to the central server or cloud-computing system 64 .
- the mesh network enables the central server or cloud-computing system 64 to regularly receive data from all of the smart devices in the home, make inferences based on the data, and send commands back to one of the smart devices to accomplish some of the smart-home objectives described herein.
- the spokesman nodes and some of the low-powered nodes are capable of “listening”. Accordingly, users, other devices, and the central server or cloud-computing system 64 can communicate controls to the low-powered nodes.
- a user can use the portable electronic device (e.g., a smartphone) 66 to send commands over the Internet 62 to the central server or cloud-computing system 64 , which then relays the commands to the spokesman nodes in the smart-home environment 30 .
- the spokesman nodes drop down to a low-power protocol to communicate the commands to the low-power nodes throughout the smart-home environment, as well as to other spokesman nodes that did not receive the commands directly from the central server or cloud-computing system 64 .
- a low-power node is a smart night light 65 .
- the smart night light 65 houses an occupancy sensor, such as an ultrasonic or passive IR sensor, and an ambient light sensor, such as a photoresistor or a single-pixel sensor that measures light in the room.
- the smart night light 65 is configured to activate the light source when its ambient light sensor detects that the room is dark and when its occupancy sensor detects that someone is in the room. In other embodiments, the smart night light 65 is simply configured to activate the light source when its ambient light sensor detects that the room is dark.
- the smart night light 65 includes a low-power wireless communication chip (e.g., ZigBee chip) that regularly sends out messages regarding the occupancy of the room and the amount of light in the room, including instantaneous messages coincident with the occupancy sensor detecting the presence of a person in the room.
- these messages may be sent wirelessly, using the mesh network, from node to node (i.e., smart device to smart device) within the smart-home environment 30 as well as over the Internet 62 to the central server or cloud-computing system 64 .
- low-powered nodes include battery-operated versions of the smart hazard detectors 50 .
- These smart hazard detectors 50 are often located in an area without access to constant and reliable power and, as discussed in detail below, may include any number and type of sensors, such as smoke/fire/heat sensors, carbon monoxide/dioxide sensors, occupancy/motion sensors, ambient light sensors, temperature sensors, humidity sensors, and the like.
- smart hazard detectors 50 can send messages that correspond to each of the respective sensors to the other devices and the central server or cloud-computing system 64 , such as by using the mesh network as described above.
- spokesman nodes examples include smart thermostats 46 , smart doorbells 52 , smart wall switches 54 , and smart wall plugs 56 . These devices 46 , 52 , 54 , and 56 are often located near and connected to a reliable power source, and therefore can include more power-consuming components, such as one or more communication chips capable of bidirectional communication in any variety of protocols.
- these low-powered and spokesman nodes can function as “tripwires” for an alarm system in the smart-home environment. For example, in the event a perpetrator circumvents detection by alarm sensors located at windows, doors, and other entry points of the smart-home environment 30 , the alarm could be triggered upon receiving an occupancy, motion, heat, sound, etc. message from one or more of the low-powered and spokesman nodes in the mesh network.
- the central server or cloud-computing system 64 or some other device could trigger an alarm, provided the alarm is armed at the time of detection.
- the alarm system could be enhanced by various low-powered and spokesman nodes located throughout the smart-home environment 30 .
- a user could enhance the security of the smart-home environment 30 by buying and installing extra smart nightlights 65 .
- the devices 10 may be incapable of communicating with each other. Therefore, as discussed in detail below, the present techniques provide network communication jamming attack detection and notification solutions to such a problem.
- the mesh network can be used to automatically turn on and off lights as a person transitions from room to room.
- the low-powered and spokesman nodes detect the person's movement through the smart-home environment and communicate corresponding messages through the mesh network.
- the central server or cloud-computing system 64 or some other device activates and deactivates the smart wall switches 54 to automatically provide light as the person moves from room to room in the smart-home environment 30 .
- users may provide pre-configuration information that indicates which smart wall plugs 56 provide power to lamps and other light sources, such as the smart night light 65 .
- this mapping of light sources to wall plugs 56 can be done automatically (e.g., the smart wall plugs 56 detect when a light source is plugged into it, and it sends a corresponding message to the central server or cloud-computing system 64 ). Using this mapping information in combination with messages that indicate which rooms are occupied, the central server or cloud-computing system 64 or some other device activates and deactivates the smart wall plugs 56 that provide power to lamps and other light sources so as to track the person's movement and provide light as the person moves from room to room.
- the mesh network of low-powered and spokesman nodes can be used to provide exit lighting in the event of an emergency.
- users provide pre-configuration information that indicates exit routes in the smart-home environment 30 . For example, for each room in the house, the user provides a map of the best exit route.
- the central server or cloud-computing system 64 or some other device could automatically determine the routes using uploaded maps, diagrams, architectural drawings of the smart-home house, as well as using a map generated based on positional information obtained from the nodes of the mesh network (e.g., positional information from the devices is used to construct a map of the house).
- the central server or cloud-computing system 64 or some other device uses occupancy information obtained from the low-powered and spokesman nodes to determine which rooms are occupied and then turns on lights (e.g., nightlights 65 , wall switches 54 , wall plugs 56 that power lamps, etc.) along the exit routes from the occupied rooms so as to provide emergency exit lighting.
- lights e.g., nightlights 65 , wall switches 54 , wall plugs 56 that power lamps, etc.
- service robots 69 each configured to carry out, in an autonomous manner, any of a variety of household tasks.
- the service robots 69 can be respectively configured to perform floor sweeping, floor washing, etc. in a manner similar to that of known commercially available devices such as the ROOMBATM and SCOOBATM products sold by iRobot, Inc. of Bedford, Mass.
- Tasks such as floor sweeping and floor washing can be considered as “away” or “while-away” tasks for purposes of the instant description, as it is generally more desirable for these tasks to be performed when the occupants are not present.
- one or more of the service robots 69 are configured to perform tasks such as playing music for an occupant, serving as a localized thermostat for an occupant, serving as a localized air monitor/purifier for an occupant, serving as a localized baby monitor, serving as a localized hazard detector for an occupant, serving as a localized and mobile occupancy detection device, and so forth, it being generally more desirable for such tasks to be carried out in the immediate presence of the human occupant.
- such tasks can be considered as “human-facing” or “human-centric” tasks.
- a particular one of the service robots 69 can be considered to be facilitating what can be called a “personal comfort-area network” for the occupant, with the objective being to keep the occupant's immediate space at a comfortable temperature wherever that occupant may be located in the home.
- a personal comfort-area network for the occupant
- the localized-thermostat service robot 69 is configured to move itself into the immediate presence (e.g., within five feet) of a particular occupant who has settled into a particular location in the home (e.g. in the dining room to eat their breakfast and read the news).
- the localized-thermostat service robot 69 includes a temperature sensor, a processor, an occupancy detector, and wireless communication components configured such that control communications with the HVAC system, either directly or through a wall-mounted wirelessly communicating thermostat coupled to the HVAC system, are maintained and such that the temperature in the immediate vicinity of the occupant is maintained at their desired level. If the occupant then moves and settles into another location (e.g. to the living room couch to watch television), the localized-thermostat service robot 69 proceeds to move and park itself next to the couch and keep that particular immediate space at a comfortable temperature.
- the localized-thermostat service robot 69 can identify and locate the occupant whose personal-area space is to be kept at a comfortable temperature
- RFID sensing e.g., person having an RFID bracelet, RFID necklace, or RFID key fob
- a particular service robot 69 When serving as a localized air monitor/purifier for an occupant, a particular service robot 69 can be considered to be facilitating what can be called a “personal health-area network” for the occupant, with the objective being to keep the air quality in the occupant's immediate space at healthy levels.
- other health-related functions can be provided, such as monitoring the temperature or heart rate of the occupant (e.g., using finely remote sensors, near-field communication with on-person monitors, etc.).
- a particular service robot 69 When serving as a localized hazard detector for an occupant, a particular service robot 69 can be considered to be facilitating what can be called a “personal safety-area network” for the occupant, with the objective being to ensure there is no excessive carbon monoxide, smoke, fire, etc., in the immediate space of the occupant.
- Methods analogous to those described above for personal comfort-area networks in terms of occupant identifying and tracking are likewise applicable for personal health-area network and personal safety-area network embodiments.
- the above-referenced facilitation of personal comfort-area networks, personal health-area networks, personal safety-area networks, and/or other such human-facing functionalities of the service robots 69 are further enhanced by logical integration with other smart sensors in the home according to rules-based inferencing techniques or artificial intelligence techniques for achieving better performance of those human-facing functionalities and/or for achieving those goals in energy-conserving or other resource-conserving ways.
- the air monitor/purifier service robot 69 can be configured to detect whether a household pet is moving toward the currently settled location of the occupant (e.g., using on-board sensors and/or by data communications with other smart-home sensors along with rules-based inferencing/artificial intelligence techniques), and if so, the air purifying rate is immediately increased in preparation for the arrival of more airborne pet dander.
- the hazard detector service robot 69 can be advised by other smart-home sensors that the temperature and humidity levels are rising in the kitchen, which is nearby to the occupant's current dining room location, and responsive to this advisory the hazard detector service robot 69 will temporarily raise a hazard detection threshold, such as a smoke detection threshold, under an inference that any small increases in ambient smoke levels will most likely be due to cooking activity and not due to a genuinely hazardous condition.
- a hazard detection threshold such as a smoke detection threshold
- each service robot 69 includes wireless communication components that facilitate data communications with one or more of the other wirelessly communicating smart-home sensors of FIG. 2 and/or with one or more other service robots 69 (e.g., using Wi-Fi, Zigbee, Z-Wave, 6LoWPAN, etc.), and one or more of the smart-home devices 10 can be in communication with a remote server over the Internet.
- each service robot 69 can be configured to communicate directly with a remote server by virtue of cellular telephone communications, satellite communications, 3G/4G network data communications, or other direct communication method.
- inventions are systems and methods relating to the integration of the service robot(s) 69 with home security sensors and related functionalities of the smart home system.
- the embodiments are particularly applicable and advantageous when applied for those service robots 69 that perform “away” functionalities or that otherwise are desirable to be active when the home is unoccupied (hereinafter “away-service robots”).
- away-service robots Included in the embodiments are methods and systems for ensuring that home security systems, intrusion detection systems, and/or occupancy-sensitive environmental control systems (for example, occupancy-sensitive automated setback thermostats that enter into a lower-energy-using condition when the home is unoccupied) are not erroneously triggered by the away-service robots.
- a home automation and security system e.g., as shown in FIG. 2
- a monitoring service by virtue of automated systems (e.g., cloud-based servers or other central servers, hereinafter “central server”) that are in data communications with one or more network-connected elements of the home automation and security system.
- the away-service robots are configured to be in operative data communication with the central server, and are configured such that they remain in a non-away-service state (e.g., a dormant state at their docking station) unless permission is granted from the central server (e.g., by virtue of an “away-service-OK” message from the central server) to commence their away-service activities.
- An away-state determination made by the system which can be arrived at (i) exclusively by local on-premises smart device(s) based on occupancy sensor data, (ii) exclusively by the central server based on received occupancy sensor data and/or based on received proximity-related information such as GPS coordinates from user smartphones or automobiles, or (iii) any combination of (i) and (ii) can then trigger the granting of away-service permission to the away-service robots by the central server.
- the central server can readily filter signals from the occupancy sensing devices to distinguish between the away-service robot activity versus any unexpected intrusion activity, thereby avoiding a false intrusion alarm condition while also ensuring that the home is secure.
- the central server may provide filtering data (such as an expected occupancy-sensing profile triggered by the away-service robots) to the occupancy sensing nodes or associated processing nodes of the smart home, such that the filtering is performed at the local level.
- filtering data such as an expected occupancy-sensing profile triggered by the away-service robots
- the central server may temporarily disable the occupancy sensing equipment (including any occupancy sensing equipment located on the robot itself) for the duration of the away-service robot activity.
- functionality similar to that of the central server in the above example can be performed by an on-site computing device such as a dedicated server computer, a “master” home automation console or panel, or as an adjunct function of one or more of the smart-home devices of FIG. 2 .
- an on-site computing device such as a dedicated server computer, a “master” home automation console or panel, or as an adjunct function of one or more of the smart-home devices of FIG. 2 .
- the home security systems and/or occupancy-sensitive environmental controls that would be triggered by the motion, noise, vibrations, or other disturbances of the away-service robot activity are referenced simply as “activity sensing systems,” and when so triggered will yield a “disturbance-detected” outcome representative of the false trigger (for example, an alarm message to a security service, or an “arrival” determination for an automated setback thermostat that causes the home to be heated or cooled to a more comfortable “occupied” setpoint temperature).
- the away-service robots are configured to emit a standard ultrasonic sound throughout the course of their away-service activity
- the activity sensing systems are configured to detect that standard ultrasonic sound
- the activity sensing systems are further configured such that no disturbance-detected outcome will occur for as long as that standard ultrasonic sound is detected.
- the away-service robots are configured to emit a standard notification signal throughout the course of their away-service activity
- the activity sensing systems are configured to detect that standard notification signal
- the activity sensing systems are further configured such that no disturbance-detected outcome will occur for as long as that standard notification signal is detected
- the standard notification signal comprises one or more of: an optical notifying signal; an audible notifying signal; an infrared notifying signal; an infrasonic notifying signal; a wirelessly transmitted data notification signal (e.g., an IP broadcast, multicast, or unicast notification signal, or a notification message sent in an TCP/IP two-way communication session).
- the notification signals sent by the away-service robots to the activity sensing systems are authenticated and encrypted such that the notifications cannot be learned and replicated by a potential burglar.
- Any of a variety of known encryption/authentication schemes can be used to ensure such data security including, but not limited to, methods involving third party data security services or certificate authorities.
- a permission request-response model can be used, wherein any particular away-service robot requests permission from each activity sensing system in the home when it is ready to perform its away-service tasks, and does not initiate such activity until receiving a “yes” or “permission granted” message from each activity sensing system (or from a single activity sensing system serving as a “spokesman” for all of the activity sensing systems).
- One advantage of the described embodiments that do not require a central event orchestrator is that there can (optionally) be more of an arms-length relationship between the supplier(s) of the home security/environmental control equipment, on the one hand, and the supplier(s) of the away-service robot(s), on the other hand, as it is only required that there is the described standard one-way notification protocol or the described standard two-way request/permission protocol to be agreed upon by the respective suppliers.
- the activity sensing systems are configured to detect sounds, vibrations, RF emissions, or other detectable environmental signals or “signatures” that are intrinsically associated with the away-service activity of each away-service robot, and are further configured such that no disturbance-detected outcome will occur for as long as that particular detectable signal or environmental “signature” is detected.
- a particular kind of vacuum-cleaning away-service robot may emit a specific sound or RF signature.
- the away-service environmental signatures for each of a number of known away-service robots are stored in the memory of the activity sensing systems based on empirically collected data, the environmental signatures being supplied with the activity sensing systems and periodically updated by a remote update server.
- the activity sensing systems can be placed into a “training mode” for the particular home in which they are installed, wherein they “listen” and “learn” the particular environmental signatures of the away-service robots for that home during that training session, and thereafter will suppress disturbance-detected outcomes for intervals in which those environmental signatures are heard.
- the activity sensing system is configured to automatically learn the environmental signatures for the away-service robots by virtue of automatically performing correlations over time between detected environmental signatures and detected occupancy activity.
- an intelligent automated nonoccupancy-triggered setback thermostat such as the Nest Learning Thermostat can be configured to constantly monitor for audible and RF activity as well as to perform infrared-based occupancy detection.
- the environmental signature of the away-service robot will remain relatively constant from event to event, and in view of the fact that the away-service events will likely either (a) themselves be triggered by some sort of nonoccupancy condition as measured by the away-service robots themselves, or (b) occur at regular times of day, there will be patterns in the collected data by which the events themselves will become apparent and for which the environmental signatures can be readily learned.
- the environmental signatures of the away-service robots are automatically learned without requiring user interaction, it is more preferable that a certain number of false triggers be tolerable over the course of the learning process.
- this automatic-learning embodiment is more preferable for application in occupancy-sensitive environmental control equipment (such as an automated setback thermostat) rather than home security systems for the reason that a few false occupancy determinations may cause a few instances of unnecessary heating or cooling, but will not otherwise have any serious consequences, whereas false home security alarms may have more serious consequences.
- occupancy-sensitive environmental control equipment such as an automated setback thermostat
- technologies including the sensors of the smart devices located in the mesh network of the smart-home environment in combination with rules-based inference engines or artificial intelligence provided at the central server or cloud-computing system 64 are used to provide a personal “smart alarm clock” for individual occupants of the home.
- user-occupants can communicate with the central server or cloud-computing system 64 via their mobile devices 66 to access an interface for the smart alarm clock.
- occupants can turn on their “smart alarm clock” and input a wake time for the next day and/or for additional days.
- the occupant may have the option of setting a specific wake time for each day of the week, as well as the option of setting some or all of the inputted wake times to “repeat”.
- Artificial intelligence will be used to consider the occupant's response to these alarms when they go off and make inferences about the user's preferred sleep patterns over time.
- the smart device in the smart-home environment 30 that happens to be closest to the occupant when the occupant falls asleep will be the device that transmits messages regarding when the occupant stopped moving, from which the central server or cloud-computing system 64 will make inferences about where and when the occupant prefers to sleep.
- This closest smart device will as be the device that sounds the alarm to wake the occupant.
- the “smart alarm clock” will follow the occupant throughout the house, by tracking the individual occupants based on their “unique signature”, which is determined based on data obtained from sensors located in the smart devices.
- the sensors include ultrasonic sensors, passive IR sensors, and the like.
- the unique signature is based on a combination of walking gate, patterns of movement, voice, height, size, etc. It should be appreciated that facial recognition may also be used.
- the wake times associated with the “smart alarm clock” are used by the smart thermostat 46 to control the HVAC in an efficient manner so as to pre-heat or cool the house to the occupant's desired “sleeping” and “awake” temperature settings.
- the preferred settings can be learned over time, such as by observing which temperature the occupant sets the thermostat to before going to sleep and which temperature the occupant sets the thermostat to upon waking up.
- a device is positioned proximate to the occupant's bed, such as on an adjacent nightstand, and collects data as the occupant sleeps using noise sensors, motion sensors (e.g., ultrasonic, IR, and optical), etc.
- Data may be obtained by the other smart devices in the room as well.
- Such data may include the occupant's breathing patterns, heart rate, movement, etc. Inferences are made based on this data in combination with data that indicates when the occupant actually wakes up. For example, if—on a regular basis—the occupant's heart rate, breathing, and moving all increase by 5% to 10%, twenty to thirty minutes before the occupant wakes up each morning, then predictions can be made regarding when the occupant is going to wake.
- predictions to provide other smart-home objectives such as adjusting the smart thermostat 46 so as to pre-heat or cool the home to the occupant's desired setting before the occupant wakes up. Further, these predictions can be used to set the “smart alarm clock” for the occupant, to turn on lights, etc.
- technologies including the sensors of the smart devices located throughout the smart-home environment in combination with rules-based inference engines or artificial intelligence provided at the central server or cloud-computing system 64 are used to detect or monitor the progress of Alzheimer's Disease.
- the unique signatures of the occupants are used to track the individual occupants' movement throughout the smart-home environment 30 .
- This data can be aggregated and analyzed to identify patterns indicative of Alzheimer's.
- individuals with Alzheimer's have distinctive patterns of migration in their homes. For example, a person will walk to the kitchen and stand there for a while, then to the living room and stand there for a while, and then back to the kitchen. This pattern will take about thirty minutes, and then the person will repeat the pattern.
- the remote servers or cloud computing architectures 64 analyze the person's migration data collected by the mesh network of the smart-home environment to identify such patterns.
- FIG. 3 illustrates an embodiment of an extensible devices and services platform 80 that can be concentrated at a single server or distributed among several different computing entities without limitation with respect to the smart-home environment 30 .
- the extensible devices and services platform 80 may include a processing engine 86 , which may include engines that receive data from devices of smart-home environments (e.g., via the Internet or a hubbed network), to index the data, to analyze the data and/or to generate statistics based on the analysis or as part of the analysis.
- the analyzed data can be stored as derived home data 88 .
- Results of the analysis or statistics can thereafter be transmitted back to the device that provided home data used to derive the results, to other devices, to a server providing a web page to a user of the device, or to other non-device entities.
- use statistics, use statistics relative to use of other devices, use patterns, and/or statistics summarizing sensor readings can be generated by the processing engine 86 and transmitted.
- the results or statistics can be provided via the Internet 62 .
- the processing engine 86 can be configured and programmed to derive a variety of useful information from the home data 82 .
- a single server can include one or more engines.
- the derived data can be highly beneficial at a variety of different granularities for a variety of useful purposes, ranging from explicit programmed control of the devices on a per-home, per-neighborhood, or per-region basis (for example, demand-response programs for electrical utilities), to the generation of inferential abstractions that can assist on a per-home basis (for example, an inference can be drawn that the homeowner has left for vacation and so security detection equipment can be put on heightened sensitivity), to the generation of statistics and associated inferential abstractions that can be used for government or charitable purposes.
- processing engine 86 can generate statistics about device usage across a population of devices and send the statistics to device users, service providers or other entities (e.g., that have requested or may have provided monetary compensation for the statistics).
- the home data 82 , the derived home data 88 , and/or another data can be used to create “automated neighborhood safety networks.” For example, in the event the central server or cloud-computing architecture 64 receives data indicating that a particular home has been broken into, is experiencing a fire, or some other type of emergency event, an alarm is sent to other smart homes in the “neighborhood.” In some instances, the central server or cloud-computing architecture 64 automatically identifies smart homes within a radius of the home experiencing the emergency and sends an alarm to the identified homes.
- the other homes in the “neighborhood” do not have to sign up for or register to be a part of a safety network, but instead are notified of an emergency based on their proximity to the location of the emergency.
- this can be an opt-in service and that, in addition to or instead of the central server or cloud-computing architecture 64 selecting which homes to send alerts to, individuals can subscribe to participate in such networks and individuals can specify which homes they want to receive alerts from. This can include, for example, the homes of family members who live in different cities, such that individuals can receive alerts when their loved ones in other locations are experiencing an emergency.
- sound, vibration, and/or motion sensing components of the smart devices are used to detect sound, vibration, and/or motion created by running water. Based on the detected sound, vibration, and/or motion, the central server or cloud-computing architecture 64 makes inferences about water usage in the home and provides related services. For example, the central server or cloud-computing architecture 64 can run programs/algorithms that recognize what water sounds like and when it is running in the home.
- the central server or cloud-computing architecture 64 to map the various water sources of the home, upon detecting running water, the central server or cloud-computing architecture 64 sends a message an occupant's mobile device asking if water is currently running or if water has been recently run in the home and, if so, which room and which water-consumption appliance (e.g., sink, shower, toilet, etc.) was the source of the water. This enables the central server or cloud-computing architecture 64 to determine the “signature” or “fingerprint” of each water source in the home. This is sometimes referred to herein as “audio fingerprinting water usage.”
- the central server or cloud-computing architecture 64 creates a signature for the toilet in the master bathroom, and whenever that toilet is flushed, the central server or cloud-computing architecture 64 will know that the water usage at that time is associated with that toilet. Thus, the central server or cloud-computing architecture 64 can track the water usage of that toilet as well as each water-consumption application in the home. This information can be correlated to water bills or smart water meters so as to provide users with a breakdown of their water usage.
- sound, vibration, and/or motion sensing components of the smart devices are used to detect sound, vibration, and/or motion created by mice and other rodents as well as by termites, cockroaches, and other insects (collectively referred to as “pests”).
- the central server or cloud-computing architecture 64 Based on the detected sound, vibration, and/or motion, the central server or cloud-computing architecture 64 makes inferences about pest-detection in the home and provides related services.
- the central server or cloud-computing architecture 64 can run programs/algorithms that recognize what certain pests sound like, how they move, and/or the vibration they create, individually and/or collectively.
- the central server or cloud-computing architecture 64 can determine the “signatures” of particular types of pests.
- the central server or cloud-computing architecture 64 detects sounds that may be associated with pests, it notifies the occupants of such sounds and suggests hiring a pest control company. If it is confirmed that pests are indeed present, the occupants input to the central server or cloud-computing architecture 64 confirms that its detection was correct, along with details regarding the identified pests, such as name, type, description, location, quantity, etc. This enables the central server or cloud-computing architecture 64 to “tune” itself for better detection and create “signatures” or “fingerprints” for specific types of pests.
- the central server or cloud-computing architecture 64 can use the tuning as well as the signatures and fingerprints to detect pests in other homes, such as nearby homes that may be experiencing problems with the same pests. Further, for example, in the event that two or more homes in a “neighborhood” are experiencing problems with the same or similar types of pests, the central server or cloud-computing architecture 64 can make inferences that nearby homes may also have such problems or may be susceptible to having such problems, and it can send warning messages to those homes to help facilitate early detection and prevention.
- the devices and services platform 80 expose a range of application programming interfaces (APIs) 90 to third parties, such as charities 94 , governmental entities 96 (e.g., the Food and Drug Administration or the Environmental Protection Agency), academic institutions 98 (e.g., university researchers), businesses 100 (e.g., providing device warranties or service to related equipment, targeting advertisements based on home data), utility companies 102 , and other third parties.
- the APIs 90 are coupled to and permit third-party systems to communicate with the central server or the cloud-computing system 64 , including the services 84 , the processing engine 86 , the home data 82 , and the derived home data 88 .
- the APIs 90 allow applications executed by the third parties to initiate specific data processing tasks that are executed by the central server or the cloud-computing system 64 , as well as to receive dynamic updates to the home data 82 and the derived home data 88 .
- third parties can develop programs and/or applications, such as web or mobile apps, that integrate with the central server or the cloud-computing system 64 to provide services and information to users.
- programs and application may be, for example, designed to help users reduce energy consumption, to preemptively service faulty equipment, to prepare for high service demands, to track past service performance, etc., or to perform any of a variety of beneficial functions or tasks now known or hereinafter developed.
- third-party applications make inferences from the home data 82 and the derived home data 88 , such inferences may include when are occupants home, when are they sleeping, when are they cooking, when are they in the den watching television, and when do they shower.
- the answers to these questions may help third-parties benefit consumers by providing them with interesting information, products and services as well as with providing them with targeted advertisements.
- a shipping company creates an application that makes inferences regarding when people are at home.
- the application uses the inferences to schedule deliveries for times when people will most likely be at home.
- the application can also build delivery routes around these scheduled times. This reduces the number of instances where the shipping company has to make multiple attempts to deliver packages, and it reduces the number of times consumers have to pick up their packages from the shipping company.
- FIG. 4 describes an abstracted functional view 110 of the extensible devices and services platform 80 of FIG. 3 , with particular reference to the processing engine 86 as well as devices, such as those of the smart-home environment 30 of FIG. 2 .
- devices situated in smart-home environments will have an endless variety of different individual capabilities and limitations, they can all be thought of as sharing common characteristics in that each of them is a data consumer 112 (DC), a data source 114 (DS), a services consumer 116 (SC), and a services source 118 (SS).
- DC data consumer 112
- DS data source 114
- SC services consumer 116
- SS services source 118
- the extensible devices and services platform 80 can also be configured to harness the large amount of data that is flowing out of these devices.
- the extensible devices and services platform 80 can be directed to “repurposing” that data in a variety of automated, extensible, flexible, and/or scalable ways to achieve a variety of useful objectives. These objectives may be predefined or adaptively identified based on, e.g., usage patterns, device efficiency, and/or user input (e.g., requesting specific functionality).
- FIG. 4 shows processing engine 86 as including a number of paradigms 120 .
- Processing engine 86 can include a managed services paradigm 120 a that monitors and manages primary or secondary device functions.
- the device functions can include ensuring proper operation of a device given user inputs, estimating that (e.g., and responding to an instance in which) an intruder is or is attempting to be in a dwelling, detecting a failure of equipment coupled to the device (e.g., a light bulb having burned out), implementing or otherwise responding to energy demand response events, or alerting a user of a current or predicted future event or characteristic.
- Processing engine 86 can further include an advertising/communication paradigm 120 b that estimates characteristics (e.g., demographic information), desires and/or products of interest of a user based on device usage. Services, promotions, products or upgrades can then be offered or automatically provided to the user. Processing engine 86 can further include a social paradigm 120 c that uses information from a social network, provides information to a social network (for example, based on device usage), and/or processes data associated with user and/or device interactions with the social network platform. For example, a user's status as reported to their trusted contacts on the social network could be updated to indicate when they are home based on light detection, security system inactivation or device usage detectors. As another example, a user may be able to share device-usage statistics with other users. In yet another example, a user may share HVAC settings that result in low power bills and other users may download the HVAC settings to their smart thermostat 46 to reduce their power bills.
- characteristics e.g., demographic information
- Services, promotions, products or upgrades can then be offered or automatically provided to the user
- the processing engine 86 can include a challenges/rules/compliance/rewards paradigm 120 d that informs a user of challenges, competitions, rules, compliance regulations and/or rewards and/or that uses operation data to determine whether a challenge has been met, a rule or regulation has been complied with and/or a reward has been earned.
- the challenges, rules or regulations can relate to efforts to conserve energy, to live safely (e.g., reducing exposure to toxins or carcinogens), to conserve money and/or equipment life, to improve health, etc.
- one challenge may involve participants turning down their thermostat by one degree for one week. Those that successfully complete the challenge are rewarded, such as by coupons, virtual currency, status, etc.
- compliance an example involves a rental-property owner making a rule that no renters are permitted to access certain owner's rooms. The devices in the room having occupancy sensors could send updates to the owner when the room is accessed.
- the processing engine 86 can integrate or otherwise utilize extrinsic information 122 from extrinsic sources to improve the functioning of one or more processing paradigms.
- Extrinsic information 122 can be used to interpret data received from a device, to determine a characteristic of the environment near the device (e.g., outside a structure that the device is enclosed in), to determine services or products available to the user, to identify a social network or social-network information, to determine contact information of entities (e.g., public-service entities such as an emergency-response team, the police or a hospital) near the device, etc., to identify statistical or environmental conditions, trends or other information associated with a home or neighborhood, and so forth.
- entities e.g., public-service entities such as an emergency-response team, the police or a hospital
- each bedroom of the smart-home environment 30 can be provided with a smart wall switch 54 , a smart wall plug 56 , and/or smart hazard detectors 50 , all or some of which include an occupancy sensor, wherein the occupancy sensor is also capable of inferring (e.g., by virtue of motion detection, facial recognition, audible sound patterns, etc.) whether the occupant is asleep or awake.
- the remote security/monitoring service or fire department is advised of how many occupants there are in each bedroom, and whether those occupants are still asleep (or immobile) or whether they have properly evacuated the bedroom. While this is, of course, a very advantageous capability accommodated by the described extensible devices and services platform 80 , there can be substantially more “profound” examples that can truly illustrate the potential of a larger “intelligence” that can be made available. By way of perhaps a more “profound” example, the same bedroom occupancy data that is being used for fire safety can also be “repurposed” by the processing engine 86 in the context of a social paradigm of neighborhood child development and education.
- the same bedroom occupancy and motion data discussed in the “ordinary” example can be collected and made available (properly anonymized) for processing in which the sleep patterns of schoolchildren in a particular ZIP code can be identified and tracked.
- Localized variations in the sleeping patterns of the schoolchildren may be identified and correlated, for example, to different nutrition programs in local schools.
- the device 10 may use the PIR sensor 24 to detect the presence of a living being, such as a human or any other being (e.g., animal, insect, etc.).
- a living being such as a human or any other being (e.g., animal, insect, etc.).
- FIG. 5 illustrates a graph 140 of sensor measurements 142 associated with one PIR sensor 24 and a static PIR sensor threshold 144 that is used to indicate whether a monitored space is occupied or unoccupied.
- the low power processor 22 may monitor the sensor measurements 142 with respect to the static PIR sensor threshold 144 over a certain period of time (e.g., 15 minutes).
- the low power processor 22 may designate the space being monitored as “occupied” or having the presence of a living being. If, however, the low power processor 22 detects a measurement below the static PIR sensor threshold 144 for the entire duration of the period of time, the low power processor 22 may designate the space being monitored as “unoccupied” or not having a living being.
- the measurements 142 above the static PIR sensor threshold 144 may be associated with the presence of a living being. However, during the unoccupied period of time (i.e., 9 to 19 hours), the measurements 142 do not exceed the static PIR threshold 144 for an extended period of time. In certain embodiments, every individual PIR sensor 24 that may be part of one or more devices 10 may use the same static PIR sensor threshold 144 to detect the presence of a human being. Although the static PIR sensor threshold 144 may work well for detecting the presence of a being for one particular PIR sensor 24 , the same threshold 144 may be less optimal for detecting the presence via another PIR sensor 24 .
- the individual noise profile for each PIR sensor 24 may cause certain PIR sensors 24 (e.g., those sensors that output relatively high sensor values) to trigger an occupied state in response to the presence of an animal (e.g., pet) or other noise source that may cause the output sensor value to exceed the static PIR threshold 144 , thereby falsely detecting the presence of a human, while causing other PIR sensors 24 (e.g., those sensors that output relatively low sensor values) to suboptimally delay triggering of an occupied state in response to the presence of a human.
- certain PIR sensors 24 e.g., those sensors that output relatively high sensor values
- an animal e.g., pet
- other noise source may cause the output sensor value to exceed the static PIR threshold 144 , thereby falsely detecting the presence of a human
- other PIR sensors 24 e.g., those sensors that output relatively low sensor values
- FIG. 6 illustrates measurements 142 that exceed the static PIR sensor threshold 144 by a small margin. Since these measurements exceed the static PIR sensor threshold 144 , the low power processor 22 may assume that the space being monitored includes the presence of a living being. However, these measurements that barely exceed the static PIR sensor threshold 144 are likely false detections of living beings. That is, the presence of a living being may typically correspond to measurements that are well over the static PIR sensor threshold 144 .
- the measurements that just exceed the static PIR sensor threshold 144 may also cause the low power processor 22 to detect the presence of the living being too early.
- FIG. 7 illustrates one measurement 145 that just exceeds these measurements exceed the static PIR sensor threshold 144 .
- This one measurement 145 may cause the low power processor 22 to detect the presence of the living too early, thereby causing the low power processor 22 to take action (e.g., illuminate the light source 26 ) before the living being is positioned at a desired location.
- the device 10 may use the PIR sensor 24 to determine when to illuminate a light source 26 .
- FIG. 8 depicts an example 150 of when the device 10 detects the presence of a human 152 when the human is directly inline with the device 10 .
- the device 10 may detect the presence of the human 152 before the human 152 is directly inline with the device 10 .
- the device 10 may detect the presence of the human 152 approaching the device 10 when the human 152 is up to four feet away from being directly inline with the PIR sensor 24 or up to one second before the human is directly inline with the PIR sensor 24 , as shown in example 160 of FIG. 9 .
- the light source 26 may illuminate a path for the human 152 as the human 152 approaches the device 10 , thereby assisting the human 152 journey through the dark corridors of the smart home environment 30 during late hours in the night.
- PIR sensors 24 may experience the delayed illumination of the light source depicted in FIG. 9 . Rather, certain PIR sensors 24 that are less susceptible to noise may not receive an indication or measurement above the static PIR sensor threshold 144 until the living being is closer to the respective PIR sensor 24 as compared to other PIR sensors 24 that may be more susceptible to noise. Moreover, any PIR sensor 24 may become more or less sensitive to noise over a relatively short period of time due to temperature variations and over longer periods of time due to issues such as sensor degradation, changes in battery voltage, etc.
- each individual PIR sensor 24 may inherently be sensitive to different types and levels of noise. That is, the peak noise detections by each individual PIR sensor 24 (with respect to multiple PIR sensors within a single device and/or individual PIR sensors distributed across multiple devices) may vary significantly for each PIR sensor 24 due to manufacturing tolerances, ambient conditions, etc.
- FIG. 10 illustrates a graph 130 of cumulative distributions of noise for different PIR sensors 24 that may be part of a device(s) 10 .
- different PIR sensors may differ in noise sensitivity by a relatively large amount. For instance, measurements from a first PIR sensor 132 may reach a peak PIR sensor value of 10 for noise while measurements from a second PIR sensor 134 may reach a peak PIR sensor value of 40 for noise.
- each individual PIR sensor 24 may have different noise sensitivity profiles, in some devices 10 , one common PIR sensor threshold value may be used across the devices 10 for evaluating whether a space lacks the presence of a human (i.e., “unoccupied”) or includes the presence of a human (i.e., “occupied”). Accordingly, since each individual PIR sensor 24 may have different noise sensitivity profiles, and since each PIR sensor 24 may be affected by temperature variations and other factors that may influence its noise sensitivity levels, it may be beneficial to dynamically adapt or adjust the PIR sensor threshold 144 for each individual PIR sensor 24 using techniques described herein.
- the device 10 may employ a method 170 for adjusting a threshold associated with detecting the presence of a human based on PIR sensor measurements.
- a method 170 for adjusting a threshold associated with detecting the presence of a human based on PIR sensor measurements may be employed using data from any type of sensor 12 that may be part of the device 10 .
- the techniques described herein may be used to detect the presence of other objects such as animals in the wild for migration pattern studies, rodents in grocery aisles, and the like.
- the method 170 may describe the general process employed by the device 10 to adjust thresholds associated with various measurements acquired by various sensors.
- a processor in the device 10 may receive data from the sensor 12 .
- the data may be acquired by any type of sensor 12 that may be part of the device 10 .
- the processor may compare the data to a threshold associated with the data. If the data exceeds the threshold, at block 176 , the processor may communicate information indicating that the data exceeds the threshold to another processor within the same device, to another device 10 , a data storage unit, or the like via a wired or wireless transmission.
- the processor may receive an adjusted threshold to compare the data received at block 172 .
- the adjusted threshold may be determined by first determining a noise floor level of the measurements acquired by the sensor 12 when a space being monitored by the sensor 12 is determined to be unoccupied. The noise floor level may be determined based on the mean of the measurements. Next, a standard or absolute deviation of the measurements acquired by the sensor 12 may be determined. The updated threshold may then be determined as being a number (e.g., 8) of standard or absolute deviations away from the noise floor or mean of the measurements.
- the process described in the method 170 may be distributed between the low-power processor 22 and the high-power processor 20 . That is, the low-power processor 22 may be used to monitor certain conditions regarding a physical space and the high-power processor 20 may be used to perform various calculations (e.g., threshold adjustments) that may involve more energy as compared to the monitoring operations performed by the low-power processor 22 . In this way, the device 10 may use its available energy more efficiently.
- FIG. 12 illustrates a method 180 that the low-power processor 22 may employ when monitoring a physical space.
- the low-power processor 22 may receive infrared light data from the PIR sensor 24 .
- the infrared light data may include raw measurements from the PIR sensor 24 .
- the raw measurements may represent a change in an infrared radiation detected in a space within a sensing range of the PIP, sensor 24 .
- the low-power processor 22 may store the infrared light data acquired by the PIR sensor 24 in a buffer.
- the buffer may be a first-in-first-out (FIFO) buffer.
- the buffer may include a limited amount of memory that may be sufficient to store the infrared light data over some period of time (e.g., 30 minutes).
- the low-power processor 22 may compare the infrared light data (e.g., PIR sensor measurements) to an initial threshold and determine whether the infrared light data exceeds an initial threshold over a certain period of time in which the monitored space is designated as a unoccupied.
- the initial threshold may be determined based on the type of PIR sensor 24 being used, various expected noise conditions associated with the smart home environment 30 (e.g., if noise is regularly expected due to the presence of a train near the house), and the like.
- the initial threshold may be programmed into the device 10 at the time of manufacturing.
- the device 10 may perform a learning operation that monitors its environment, receives input from a user verifying unoccupied versus occupied periods of time, and determine the initial threshold using similar techniques described herein.
- the low-power processor 22 may determine whether a condition (e.g., wake condition) has been detected that may cause the low-power processor 22 to wake the high-power processor 20 , which may be operating in a sleep or low power mode. For instance, when the infrared light data exceeds the initial threshold during a period of time identified as be unoccupied, low-power processor 22 may determine that the physical space within the sensing range of the PIR sensor 24 may include the presence of a human. In one embodiment, the detection of the presence of the human during the unoccupied period may be a wake condition. In another embodiment, the wake condition may correspond to when the buffer of the low-power processor 22 is full. Wake conditions may also correspond to when a hazard (e.g., smoke, fire, carbon monoxide) is detected.
- a hazard e.g., smoke, fire, carbon monoxide
- the low-power processor 22 may return to block 182 . If, however, the wake condition exists, the low-power processor 22 may proceed to block 190 . At block 190 , the low-power processor 22 may send a wake command to the high-power processor 20 .
- the wake command may cause the high-power processor 20 to exit from operating in its sleep or low power mode and begin performing various operations that may be computationally more complex or may use more energy as compared to the operations of the low-power processor 22 .
- the low-power processor 22 may send the buffer data that includes the stored infrared light data received at block 182 .
- the high-power processor 20 may use the buffer data to adjust the initial threshold as will be described in greater detail below.
- the low-power processor 22 may send a reason that the wake condition exists at block 188 . That is, the low-power processor 22 may send data related to the condition that caused the low-power processor 22 to determine that the wake condition was present. For instance, the low-power processor 22 may send data related to a smoke alarm detected that may include a time at which the smoke was detected, a location or device 10 that detected the smoke, and the like.
- the low-power processor 22 may, at block 196 , clear the buffer that stores the infrared light data and return to block 182 . As such, the low-power processor 22 may continue operating to monitor the corresponding physical space for wake conditions and continue receiving the infrared light data to determine whether a human is present in the space.
- FIG. 13 illustrates a method 200 that the high-power processor 20 may employ upon receiving the wake command from the low-power processor 22 , as described above in the method 180 .
- the high-power processor 20 may operate in a sleep or low-power mode. As such, the high-power processor 20 may perform few tasks to preserve energy.
- the high-power processor 20 may determine whether it received a wake command. In one embodiment, the high-power processor 20 may periodically exit its sleep mode to determine whether a wake condition exists or whether the low-power processor 22 attempted to wake the high-power processor 20 .
- the high-power processor 20 may determine the purpose of the wake command.
- the low-power processor 22 may send a reason or data regarding a reason that the wake command was sent.
- the wake command may correspond to the detection of smoke by a hazard detector device.
- the high-power processor 20 may, at block 208 , perform various operations based on the purpose of the wake command received at block 206 .
- the high-power processor 20 may send a notification to an alarm company, a fire department, or the like indicating the detected presence of smoke by the hazard detector.
- the high-power processor 20 may adjust the initial threshold that corresponds to the detection of the presence of a human during unoccupied periods of time. As such, block 210 may be performed at every instance that the wake command has been received. Alternatively, block 210 may be performed each time the buffer for storing the infrared light data is received. In yet another embodiment, block 210 may be performed at regular intervals during the day, week, month, or year, at regular intervals during known unoccupied periods of time, or the like. Moreover, block 210 may be performed based on a command received from the high-power processor 20 , a user of the device 10 , a predetermined time schedule, or the like.
- FIG. 14 illustrates a method 220 that the high-power processor 20 may employ when determining the adjusted threshold for detecting human presence at block 210 .
- the high-power processor 20 may receive the current or initial threshold being used by the low-power processor 22 to detect the presence of a human during periods of time that are designated as being unoccupied.
- the high-power processor 20 may receive the buffer data that includes the measurements acquired by the PIR sensors 24 from the low-power processor 22 .
- the high-power processor 20 may then, at block 226 , determine various statistics associated with the measurements recording in the buffer data.
- the high-power processor 20 is configured to receive a second set of data acquired by the PIR sensors 24 , and send a second signal to the low-power processor 22 to store the first set of data when none of one or more measurements of the second set of data exceeds an initial threshold over a period of time.
- the high-power processor 20 may remove outlier values from the data stored in the buffer and compute a mean and standard deviation of the remaining data.
- the mean of the remaining data may represent a noise floor of the measurements associated with the respective PIR sensor 24 .
- the standard deviation may be used to set the new threshold for detecting human presence using the low-power processor 22 .
- the high-power processor 20 may calculate a mean absolute deviation of the remaining data to conserve the processing power used by the high-power processor 20 . That is, the mean absolute deviation may include calculating absolute differences between each value of the data stored in the buffer and then determining the mean of the absolute differences (i.e., mean absolute deviation). Like the standard deviation mentioned above, the mean absolute deviation may be used to set the new threshold for detecting human presence using the low-power processor 22 . By determining the absolute mean differences, the high-power processor 20 may determine an approximate deviation from the mean of the data in the buffer without using complex mathematical functions (e.g., square root). As a result, the high-power processor 20 may determine a deviation amount from the mean of the data in the buffer more using less processing power than what may be used when calculating the standard deviation of the data in the buffer.
- complex mathematical functions e.g., square root
- the high-power processor 20 may update the threshold for detecting the presence of a human using the standard deviation or the mean absolute deviation mentioned above. That is, the high-power processor 20 may set the threshold for detecting the presence of a human a number of standard deviations (e.g, 8) from the mean. Alternatively, the high-power processor 20 may set the threshold for detecting the presence of a human a number of mean absolute deviations (e.g, 10) from the mean of the remaining data.
- the high-power processor may, at block 230 , send the new threshold to the low-power processor 22 .
- the low-power processor 22 may then use the new threshold to detect the presence of a human, as mentioned above with reference to FIG. 12 .
- each device 10 may better predict when a human is present in a respective space by accounting for the noise sensitivity characteristics of the respective PIR sensor 24 .
- the low-power processor 22 may detect the presence of a human sooner (e.g., up to one second earlier) using the new threshold. As a result, the light source 26 may be illuminated earlier or before the human is directly inline with the device 10 . In some cases, the low-power processor 24 may detect the presence of the human up to four feet before the human is inline with the device 10 .
- the low-power processor 22 may set the threshold it uses to detect the presence of a human to the new threshold. Since the new threshold is determined based on the infrared light data acquired by the PIR sensor 24 when a human was unlikely in the presence of the PIR sensor 24 , the new threshold may account for the noise sensitivity characteristics of the respective PIR sensor 24 .
- the high-power processor 20 may adjust the initial threshold based on the noise sensitivity characteristics of the respective PIR sensor 24 receiving the infrared light data. That is, when a human is not present in the space monitored by the PIR sensor 24 , the infrared light data received by the PIR sensor 24 may more likely be affected by noise since a large object, such as a human, is not drastically changing the levels of the infrared light detected by the PIR sensor 24 . Rather, the sensitivity characteristics of the PIR sensor 24 may be represented better during the time period when a human does not occupy the space associated with the respective PIR sensor 24 .
- the noise sensitivity characteristics or the amount of noise received by a particular PIR sensor 24 is not static. Instead, the noise sensitivity characteristics for each respective PIR sensor 24 change gradually over time. In some instances, the noise sensitivity characteristics for each respective PIR sensor 24 may be related to temperature. For example, the data received by the PIR sensor 24 is inversely proportional to temperature. As such, the threshold for a respective PIR sensor 24 should decrease when the respective PIR sensor 24 is in an environment where the temperature increases. In any case, by continuously determining a new threshold for detecting the presence of a human, the high-power processor 20 may improve its accuracy in detecting the presence of a human and may improve its rate at which it detects the presences of a human.
- the high-power processor 20 may determine the statistics regarding the measurements in the buffer data using the method 240 of FIG. 15 .
- the method 240 describes one embodiment in which the statistics regarding the measurement data may be determined, it should be understood that the statistics may be determined in a number of different manners and that FIG. 15 merely provides an example of one embodiment.
- the high-power processor 20 may receive a value N from the buffer data. That is, the high-power processor 20 may receive one value from the buffer data provided to the high-power processor 20 by the low-power processor 22 .
- the high-power processor 20 may determine whether the value N is within a range of acceptable values.
- the high-power processor 20 may proceed to block 246 and increment a value counter by one. As such, the high-power processor 20 may skip or ignore the value N and prevent the value N from being used in its statistics regarding the buffer data. As such, the high-power processor 20 may remove outliers or extreme values that may be part of the buffer data from being calculated as part of the statistics of the buffer data.
- the high-power processor 20 may proceed to block 248 .
- the high-power processor 20 may update a mean, a standard deviation, and/or an absolute mean deviation based on the value N. Initially, the high-power processor 20 may determine the mean, the standard deviation, or the absolute mean deviation based on just the value N. As the process of the method 240 continues, however, the mean, the standard deviation, and/or the absolute mean deviation may be determine based on multiple sample values from the buffer data.
- updated mean, standard deviation, and/or absolute mean deviation is described as being determined using the equations described above, it should be understood that any temporal filter may be applied when determining the statistics associated with the buffer data.
- the high-power processor 20 may proceed to block 250 .
- the high-power processor 20 may determine whether additional values are present in the buffer data. If additional values are present in the buffer data, the high-power processor 20 may proceed to block 246 and increment a value counter by one as described above. The high-power processor 20 may then return to block 242 and receive the next (N+1) value from the buffer data. The high-power processor 20 may then perform blocks 242 - 248 continuously until no other values are remaining in the buffer data. As such, the high-power processor 20 may output the mean, the standard deviation, and/or the absolute mean deviation determined at block 248 . The high-power processor 20 may then use the mean, the standard deviation, and/or the absolute mean deviation output at block 254 may update the threshold as described above with reference to block 228 of FIG. 14 .
- the high-power processor 20 may receive additional information via the sensors 12 of the device 10 to assist in the determination of the threshold. For instance, the threshold may be adjusted further based on certain ambient conditions such as temperature, time of day, carbon dioxide, rain, ultrasonic waves, ambient light, or the like. Upon receiving this information, the high-power processor 20 may further adjust the threshold. For example, during the day or when a ambient light sensor detects an amount of ambient light that corresponds to daylight, the PIR sensor 24 may be more susceptible to noise. As such, the high-power processor 20 may further increase the threshold by some amount when the ambient light sensor receives measurements that are greater than some value (i.e., some value that corresponds to daylight).
- the high-power processor 20 may decrease the threshold by some amount. In another example, the high-power processor 20 may increase the threshold when the temperature of a space being monitored is above some value, when an amount of carbon dioxide is present in the space, if rain is occurring outside, and the like.
- FIG. 16 illustrates a schematic diagram 270 of sensor ranges for two types of devices 10 that may be disposed in the smart home environment 30 .
- one device 10 may be placed on the ceiling 272 and another device 10 may be placed on a wall 274 .
- each device 10 may use different thresholds to detect the presence of a human.
- each device 10 may have different sensing ranges 276 , 278 .
- the device 10 on the ceiling 272 may detect the presence of an animal, while the device 10 on the wall 274 does not detect the same animal.
- using a different threshold for detecting the presence of a human in each device 10 may enable the device 10 to better predict the presence of a human.
- the infrared light data associated with an animal may be falsely interpreted by the device 10 as indicating the presence of a human.
- the threshold established by the high-power processor 20 may be too low since it may not be accounting for the presence of an animal.
- the user of the device 10 may provide an input indicating that the smart home environment 30 may include an animal, such as a pet.
- indication of the presence of a pet may be used to adjust the threshold for all of the devices 10 in or otherwise associate with an enclosure. In other embodiments, indication of the presence of a pet may be used to adjust the threshold for only a subset of the devices 10 .
- the threshold may be adjusted for only those devices which may have sensor ranges which may detect a pet. This may be based on a mounting arrangement (e.g., a device 10 mounted on a ceiling versus a device mounted on a wall), and/or based on a mounting location (e.g., in a room which a pet is expected to occupy at some point in time, such as a living room, vs a room which a pet is not expected to occupy, such as a bedroom).
- a mounting arrangement e.g., a device 10 mounted on a ceiling versus a device mounted on a wall
- a mounting location e.g., in a room which a pet is expected to occupy at some point in time, such as a living room, vs a room which a pet is not expected to occupy, such as a bedroom.
- FIG. 17 illustrates a flow chart of a method 280 for adjusting the threshold for detecting the presence of a human when a pet is expected to be present.
- the method 260 may be performed in addition to or in conjunction with the methods described above.
- the method 280 may begin after the high-power processor 20 determines the new threshold value at block 210 of the method 200 .
- the high-power processor 20 may determine whether a pet is expected to be present in the smart home environment 30 .
- a user of the device 10 may specify to the device 10 that the user has a pet. The user may specify this information to the device 10 when the device 10 is first installed, when prompted by the device 10 , or at any other time.
- the high-power processor 20 may proceed to block 284 .
- the high-power processor 20 may add some additional amount to the new threshold calculated at block 210 . The additional amount may be determined to be sufficient to prevent infrared light data to be interpreted as being associated with a human when it actually corresponds to a pet, while still accurately detecting the presence of a human.
- the high-power processor 20 may proceed to block 286 and send the pet-conscious threshold value to the low-power processor 22 .
- the low-power processor 22 may then use the pet-conscious threshold value to detect the presence of a human.
- the pet-conscious threshold value may be used for certain devices 10 but not all of the devices 10 .
- the device 10 on the wall 274 may not use the pet-conscious threshold value because the presence of the pet may not be misinterpreted as the presence of a human.
- the device 10 on the ceiling 272 may use the pet-conscious threshold value because its corresponding sensing range 278 may be influenced by the presence of a pet. In this manner, each device 10 may be specifically calibrated to accurately detect the presence of a human.
- FIG. 18 illustrates graphs 290 of sensor measurements associated with a first PIR sensor 24 acquired by the device 10 on the wall 274 and a second PIR sensor 24 acquired by the device 10 on the ceiling 272 .
- the thresholds used to detect the presence of a human are different for the device 10 on the wall 274 and the device 10 on the ceiling 272 .
- the device 10 on the wall 274 may use increase its occupancy threshold from threshold 144 by X amount (e.g., X millivolts) to threshold 292 during the unoccupied period of time when humans are not expected to be present.
- X amount e.g., X millivolts
- the device 10 on the ceiling 272 may increase its threshold 144 by Y amount (e.g., Y millivolts) to threshold 294 during the unoccupied period of time when humans are not expected to be present.
- Y amount e.g., Y millivolts
- each respective device 10 may account for the presence of a pet during the unoccupied period of time. As such, each respective device 10 may more accurately detect the presence of a human during the unoccupied period of time, as opposed to falsely detecting the presence of a human when instead a pet is present.
- the likelihood of one device 10 detecting the presence of a human when a second device 10 in the same vicinity does not detect the human presence reduces, thereby improving the cohesiveness between the operations of both devices 10 .
- each PIR sensor 24 may use a different a PIR sensor threshold when the presence of a human is expected (i.e., occupied) and when the presence of a human is not expected (i.e., unoccupied).
- FIG. 14 illustrates how the respective PIR sensor threshold 144 may increase during unoccupied periods of time for each PIR sensor 24 .
Abstract
Description
new value=(previous value x)+(new sample value)×(1−)
Keeping this in mind, the updated mean may be calculated according to:
updated mean=(previously calculated mean x)+(new sample value)×(1−)
Although the updated mean, standard deviation, and/or absolute mean deviation is described as being determined using the equations described above, it should be understood that any temporal filter may be applied when determining the statistics associated with the buffer data.
Claims (10)
Priority Applications (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/523,078 US10302499B2 (en) | 2014-10-24 | 2014-10-24 | Adaptive threshold manipulation for movement detecting sensors |
PCT/US2015/054001 WO2016064562A2 (en) | 2014-10-24 | 2015-10-05 | Adaptive threshold manipulation for movement detecting sensors |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/523,078 US10302499B2 (en) | 2014-10-24 | 2014-10-24 | Adaptive threshold manipulation for movement detecting sensors |
Publications (2)
Publication Number | Publication Date |
---|---|
US20160116343A1 US20160116343A1 (en) | 2016-04-28 |
US10302499B2 true US10302499B2 (en) | 2019-05-28 |
Family
ID=54347834
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US14/523,078 Active 2036-04-17 US10302499B2 (en) | 2014-10-24 | 2014-10-24 | Adaptive threshold manipulation for movement detecting sensors |
Country Status (2)
Country | Link |
---|---|
US (1) | US10302499B2 (en) |
WO (1) | WO2016064562A2 (en) |
Cited By (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20180109582A1 (en) * | 2016-10-18 | 2018-04-19 | Beijing Xiaomi Mobile Software Co., Ltd. | Operating mehtod, apparatus and computer readable storage medium |
US11162848B2 (en) | 2020-01-31 | 2021-11-02 | Enlighted, Inc. | Motion detection system and method of a building automation system |
US20210396867A1 (en) * | 2020-06-17 | 2021-12-23 | Google Llc | Multi-Radar System |
Families Citing this family (47)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP6413622B2 (en) * | 2014-10-22 | 2018-10-31 | 株式会社Ｓｏｋｅｎ | Ultrasonic object detection device |
US9619985B2 (en) * | 2015-04-08 | 2017-04-11 | Vivint, Inc. | Home automation communication system |
US10147290B2 (en) * | 2015-05-05 | 2018-12-04 | Andre Green | Tent alarm system |
US9817957B1 (en) * | 2015-06-04 | 2017-11-14 | EMC IP Holding Company LLC | Access management based on active environment comprising dynamically reconfigurable sets of smart objects |
DE112016003831T5 (en) * | 2015-08-24 | 2018-05-24 | Iee International Electronics & Engineering S.A. | Adaptive signal threshold for triggering a kicker detection |
US11533584B2 (en) * | 2015-09-16 | 2022-12-20 | Ivani, LLC | Blockchain systems and methods for confirming presence |
US20170339343A1 (en) * | 2016-05-17 | 2017-11-23 | Tijee Corporation | Multi-functional camera |
EP3264384B1 (en) * | 2016-06-29 | 2023-12-13 | 9Solutions Oy | Detecting exit of a person from a room |
IT201600074818A1 (en) * | 2016-07-18 | 2018-01-18 | Cefla Soc Cooperativa | METHOD AND APPARATUS FOR SETTING ENVIRONMENTAL CONDITIONS OF ENVIRONMENTS |
US10204498B2 (en) | 2016-10-02 | 2019-02-12 | Marquette Trishaun | System for monitoring state of user and related methods |
IT201600114194A1 (en) * | 2016-11-11 | 2018-05-11 | Tera Srl | Intelligent system for monitoring a reference environment suitable for multi-sensory interaction with the user. |
JP7019700B2 (en) * | 2016-12-21 | 2022-02-15 | アキュセラ インコーポレイテッド | Optical coherence tomography (OCT) system for measuring retina thickness |
US10712204B2 (en) | 2017-02-10 | 2020-07-14 | Google Llc | Method, apparatus and system for passive infrared sensor framework |
US10395124B2 (en) | 2017-03-31 | 2019-08-27 | Osram Sylvania Inc. | Thermal image occupant detection |
US10380863B2 (en) * | 2017-04-03 | 2019-08-13 | Oneevent Technologies, Inc. | System and method for monitoring a building |
US10984640B2 (en) * | 2017-04-20 | 2021-04-20 | Amazon Technologies, Inc. | Automatic adjusting of day-night sensitivity for motion detection in audio/video recording and communication devices |
US10026283B1 (en) | 2017-06-20 | 2018-07-17 | International Business Machines Corporation | Multi-sensor intrusion detection system |
US10942196B2 (en) * | 2017-08-14 | 2021-03-09 | Google Llc | Systems and methods of motion detection using dynamic thresholds and data filtering |
US11026315B2 (en) * | 2017-08-22 | 2021-06-01 | Signify Holding B.V. | Device, system, and method for determining occupancy for automated lighting operations |
US10613619B2 (en) | 2017-12-15 | 2020-04-07 | Google Llc | Ultra-low power mode for a low-cost force-sensing device |
US20210055011A1 (en) * | 2018-03-23 | 2021-02-25 | Carrier Corporation | User Profiles for Optimized Smart Buildings |
US11147146B2 (en) * | 2018-03-27 | 2021-10-12 | Signify Holding B.V. | Sensor-based lighting system with integrated wireless signal repeater |
EP3777254A1 (en) | 2018-04-09 | 2021-02-17 | Carrier Corporation | Satisfaction measurement for smart buildings |
US10634380B2 (en) * | 2018-04-10 | 2020-04-28 | Osram Sylvania Inc. | System for monitoring occupancy and activity in a space |
US11847241B1 (en) * | 2018-04-20 | 2023-12-19 | Amazon Technologies, Inc. | Management of service permissions |
US11037418B2 (en) * | 2018-05-05 | 2021-06-15 | Current Lighting Solutions, Llc | Distributed occupancy detection system and method |
CN108615340B (en) * | 2018-05-07 | 2019-04-02 | 山东科技大学 | A kind of method and system of dynamic alert threshold design and alarm elimination |
CN110501035B (en) * | 2018-05-18 | 2022-03-15 | 好庆科技企业股份有限公司 | Sensor and automatic correction method thereof |
US11125907B2 (en) * | 2018-05-18 | 2021-09-21 | Steelcase Inc. | Occupancy sensing systems and methods |
CN108917936A (en) * | 2018-07-05 | 2018-11-30 | 佛山正能光电有限公司 | A kind of motion detection module and starter |
JP6988020B2 (en) | 2018-07-26 | 2022-01-05 | シグニファイ ホールディング ビー ヴィSignify Holding B.V. | Methods for configuring the tracking system, tracking system, lighting system and computer program incorporating the tracking system |
EP3874478A1 (en) * | 2018-10-31 | 2021-09-08 | Assa Abloy Ab | Controlling operational state of a sensor device for break-in detection |
CN113168140A (en) * | 2018-11-20 | 2021-07-23 | 华为技术有限公司 | Self-learning home system and autonomous home operation framework |
SE544484C2 (en) * | 2019-02-18 | 2022-06-14 | Jondetech Sensors Ab Publ | Method and system for detecting presence of a person |
US11113952B2 (en) * | 2019-04-29 | 2021-09-07 | Alarm.Com Incorporated | Machine learning motion sensing with auxiliary sensors |
US11676429B2 (en) | 2019-09-04 | 2023-06-13 | Ford Global Technologies, Llc | Vehicle wheel impact detection and response |
CN112899969B (en) * | 2019-11-19 | 2023-09-19 | 青岛海尔智能技术研发有限公司 | Control method and device for washing machine and direct current motor washing machine |
CA3174558A1 (en) | 2020-03-09 | 2021-09-16 | Royal Caribbean Cruises Ltd. | Contact tracing systems and methods for tracking of shipboard pathogen transmission |
IT202000007942A1 (en) * | 2020-04-15 | 2021-10-15 | St Microelectronics Srl | PRESENCE DETECTION DEVICE AND METHOD, IN PARTICULAR FOR ANTI-INTRUSION SYSTEMS |
CN111857154B (en) * | 2020-08-02 | 2022-03-04 | 珠海一微半导体股份有限公司 | Robot calibration detection method, chip and robot |
JP2022098225A (en) * | 2020-12-21 | 2022-07-01 | 三菱重工サーマルシステムズ株式会社 | Temperature measurement value processing device, heating element detection device, temperature measurement value processing method, and program |
US11503433B2 (en) * | 2021-02-24 | 2022-11-15 | Building Robotics, Inc. | System and method for managing sensors |
CN113727019A (en) * | 2021-07-15 | 2021-11-30 | 天津华来科技股份有限公司 | Automatic awakening method and system for intelligent network camera |
AU2022314733A1 (en) * | 2021-07-19 | 2024-02-01 | Johnson Controls Tyco IP Holdings LLP | Sensitivity adjustment using integrated passive infrared sensors |
FR3131017B1 (en) * | 2021-12-21 | 2023-12-08 | Legrand France | Home automation control method and device with detection of presence and proximity events |
US20230223785A1 (en) * | 2022-01-07 | 2023-07-13 | Leviton Manufacturing Co., Inc. | Controlling power to a load based on sensed environmental conditions |
CN116699714A (en) * | 2023-04-28 | 2023-09-05 | 武汉领普科技有限公司 | Detection device, method and system |
Citations (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6384414B1 (en) | 1997-11-25 | 2002-05-07 | Board Of Regents, The University Of Texas System | Method and apparatus for detecting the presence of an object |
US20130204442A1 (en) * | 2010-11-19 | 2013-08-08 | Nest Labs, Inc. | Hvac controller configurations that compensate for heating caused by direct sunlight |
-
2014
- 2014-10-24 US US14/523,078 patent/US10302499B2/en active Active
-
2015
- 2015-10-05 WO PCT/US2015/054001 patent/WO2016064562A2/en active Application Filing
Patent Citations (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6384414B1 (en) | 1997-11-25 | 2002-05-07 | Board Of Regents, The University Of Texas System | Method and apparatus for detecting the presence of an object |
US20130204442A1 (en) * | 2010-11-19 | 2013-08-08 | Nest Labs, Inc. | Hvac controller configurations that compensate for heating caused by direct sunlight |
Non-Patent Citations (2)
Title |
---|
Partial International Search Report for PCT Application No. PCT/US2015/054001 dated Mar. 21, 2016, 5 pgs. |
Sang Gi Hong et al.; "Reduction of False Alarm Signals for PIR Sensor in Realistic Outdoor Surveillance", ETRI Journal, Feb. 2013, pp. 80-88. |
Cited By (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20180109582A1 (en) * | 2016-10-18 | 2018-04-19 | Beijing Xiaomi Mobile Software Co., Ltd. | Operating mehtod, apparatus and computer readable storage medium |
US10826961B2 (en) * | 2016-10-18 | 2020-11-03 | Beijing Xiaomi Mobile Software Co., Ltd. | Multimedia player device automatically performs an operation triggered by a portable electronic device |
US11162848B2 (en) | 2020-01-31 | 2021-11-02 | Enlighted, Inc. | Motion detection system and method of a building automation system |
US20210396867A1 (en) * | 2020-06-17 | 2021-12-23 | Google Llc | Multi-Radar System |
Also Published As
Publication number | Publication date |
---|---|
US20160116343A1 (en) | 2016-04-28 |
WO2016064562A2 (en) | 2016-04-28 |
WO2016064562A3 (en) | 2016-07-21 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US10302499B2 (en) | Adaptive threshold manipulation for movement detecting sensors | |
US11627133B2 (en) | Selectively restricting communications from third party applications/devices to electronic devices | |
US20190208390A1 (en) | Methods And Apparatus For Exploiting Interfaces Smart Environment Device Application Program Interfaces | |
US10375150B2 (en) | Crowd-based device trust establishment in a connected environment | |
US10411827B2 (en) | Systems and methods for detecting wireless communication jamming in a network | |
US10691196B2 (en) | System and methods for efficiently communicating between low-power devices | |
US11322316B2 (en) | Home monitoring and control system | |
US9660948B2 (en) | Rule-based rate limiting | |
US9869484B2 (en) | Predictively controlling an environmental control system | |
US9933177B2 (en) | Enhanced automated environmental control system scheduling using a preference function | |
US9772116B2 (en) | Enhanced automated control scheduling | |
US9857238B2 (en) | Thermodynamic model generation and implementation using observed HVAC and/or enclosure characteristics | |
US10453098B2 (en) | Privacy-aware personalized content for the smart home | |
US20160201933A1 (en) | Predictively controlling an environmental control system | |
WO2016073312A1 (en) | Enhanced automated control scheduling |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:DIXON, MICHAEL;GOLDENSON, ANDREW;SIGNING DATES FROM 20141022 TO 20141023;REEL/FRAME:034038/0800 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044695/0115Effective date: 20170929 |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NOTICE OF ALLOWANCE MAILED -- APPLICATION RECEIVED IN OFFICE OF PUBLICATIONS |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: PUBLICATIONS -- ISSUE FEE PAYMENT RECEIVED |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: PUBLICATIONS -- ISSUE FEE PAYMENT VERIFIED |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 4TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1551); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 4 |