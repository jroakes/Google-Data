CN115699149A - Dynamic power converter switching for displays based on predicted power usage - Google Patents
Dynamic power converter switching for displays based on predicted power usage Download PDFInfo
- Publication number
- CN115699149A CN115699149A CN202080102053.8A CN202080102053A CN115699149A CN 115699149 A CN115699149 A CN 115699149A CN 202080102053 A CN202080102053 A CN 202080102053A CN 115699149 A CN115699149 A CN 115699149A
- Authority
- CN
- China
- Prior art keywords
- power
- display
- amount
- machine
- model
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Images
Classifications
-
- G—PHYSICS
- G09—EDUCATION; CRYPTOGRAPHY; DISPLAY; ADVERTISING; SEALS
- G09G—ARRANGEMENTS OR CIRCUITS FOR CONTROL OF INDICATING DEVICES USING STATIC MEANS TO PRESENT VARIABLE INFORMATION
- G09G3/00—Control arrangements or circuits, of interest only in connection with visual indicators other than cathode-ray tubes
- G09G3/20—Control arrangements or circuits, of interest only in connection with visual indicators other than cathode-ray tubes for presentation of an assembly of a number of characters, e.g. a page, by composing the assembly by combination of individual elements arranged in a matrix no fixed position being assigned to or needed to be assigned to the individual characters or partial characters
- G09G3/34—Control arrangements or circuits, of interest only in connection with visual indicators other than cathode-ray tubes for presentation of an assembly of a number of characters, e.g. a page, by composing the assembly by combination of individual elements arranged in a matrix no fixed position being assigned to or needed to be assigned to the individual characters or partial characters by control of light from an independent source
- G09G3/3406—Control of illumination source
- G09G3/342—Control of illumination source using several illumination sources separately controlled corresponding to different display panel areas, e.g. along one dimension such as lines
-
- G—PHYSICS
- G09—EDUCATION; CRYPTOGRAPHY; DISPLAY; ADVERTISING; SEALS
- G09G—ARRANGEMENTS OR CIRCUITS FOR CONTROL OF INDICATING DEVICES USING STATIC MEANS TO PRESENT VARIABLE INFORMATION
- G09G3/00—Control arrangements or circuits, of interest only in connection with visual indicators other than cathode-ray tubes
- G09G3/20—Control arrangements or circuits, of interest only in connection with visual indicators other than cathode-ray tubes for presentation of an assembly of a number of characters, e.g. a page, by composing the assembly by combination of individual elements arranged in a matrix no fixed position being assigned to or needed to be assigned to the individual characters or partial characters
- G09G3/22—Control arrangements or circuits, of interest only in connection with visual indicators other than cathode-ray tubes for presentation of an assembly of a number of characters, e.g. a page, by composing the assembly by combination of individual elements arranged in a matrix no fixed position being assigned to or needed to be assigned to the individual characters or partial characters using controlled light sources
- G09G3/30—Control arrangements or circuits, of interest only in connection with visual indicators other than cathode-ray tubes for presentation of an assembly of a number of characters, e.g. a page, by composing the assembly by combination of individual elements arranged in a matrix no fixed position being assigned to or needed to be assigned to the individual characters or partial characters using controlled light sources using electroluminescent panels
- G09G3/32—Control arrangements or circuits, of interest only in connection with visual indicators other than cathode-ray tubes for presentation of an assembly of a number of characters, e.g. a page, by composing the assembly by combination of individual elements arranged in a matrix no fixed position being assigned to or needed to be assigned to the individual characters or partial characters using controlled light sources using electroluminescent panels semiconductive, e.g. using light-emitting diodes [LED]
- G09G3/3208—Control arrangements or circuits, of interest only in connection with visual indicators other than cathode-ray tubes for presentation of an assembly of a number of characters, e.g. a page, by composing the assembly by combination of individual elements arranged in a matrix no fixed position being assigned to or needed to be assigned to the individual characters or partial characters using controlled light sources using electroluminescent panels semiconductive, e.g. using light-emitting diodes [LED] organic, e.g. using organic light-emitting diodes [OLED]
- G09G3/3225—Control arrangements or circuits, of interest only in connection with visual indicators other than cathode-ray tubes for presentation of an assembly of a number of characters, e.g. a page, by composing the assembly by combination of individual elements arranged in a matrix no fixed position being assigned to or needed to be assigned to the individual characters or partial characters using controlled light sources using electroluminescent panels semiconductive, e.g. using light-emitting diodes [LED] organic, e.g. using organic light-emitting diodes [OLED] using an active matrix
- G09G3/3233—Control arrangements or circuits, of interest only in connection with visual indicators other than cathode-ray tubes for presentation of an assembly of a number of characters, e.g. a page, by composing the assembly by combination of individual elements arranged in a matrix no fixed position being assigned to or needed to be assigned to the individual characters or partial characters using controlled light sources using electroluminescent panels semiconductive, e.g. using light-emitting diodes [LED] organic, e.g. using organic light-emitting diodes [OLED] using an active matrix with pixel circuitry controlling the current through the light-emitting element
-
- G—PHYSICS
- G09—EDUCATION; CRYPTOGRAPHY; DISPLAY; ADVERTISING; SEALS
- G09G—ARRANGEMENTS OR CIRCUITS FOR CONTROL OF INDICATING DEVICES USING STATIC MEANS TO PRESENT VARIABLE INFORMATION
- G09G3/00—Control arrangements or circuits, of interest only in connection with visual indicators other than cathode-ray tubes
- G09G3/20—Control arrangements or circuits, of interest only in connection with visual indicators other than cathode-ray tubes for presentation of an assembly of a number of characters, e.g. a page, by composing the assembly by combination of individual elements arranged in a matrix no fixed position being assigned to or needed to be assigned to the individual characters or partial characters
- G09G3/22—Control arrangements or circuits, of interest only in connection with visual indicators other than cathode-ray tubes for presentation of an assembly of a number of characters, e.g. a page, by composing the assembly by combination of individual elements arranged in a matrix no fixed position being assigned to or needed to be assigned to the individual characters or partial characters using controlled light sources
- G09G3/30—Control arrangements or circuits, of interest only in connection with visual indicators other than cathode-ray tubes for presentation of an assembly of a number of characters, e.g. a page, by composing the assembly by combination of individual elements arranged in a matrix no fixed position being assigned to or needed to be assigned to the individual characters or partial characters using controlled light sources using electroluminescent panels
- G09G3/32—Control arrangements or circuits, of interest only in connection with visual indicators other than cathode-ray tubes for presentation of an assembly of a number of characters, e.g. a page, by composing the assembly by combination of individual elements arranged in a matrix no fixed position being assigned to or needed to be assigned to the individual characters or partial characters using controlled light sources using electroluminescent panels semiconductive, e.g. using light-emitting diodes [LED]
- G09G3/3208—Control arrangements or circuits, of interest only in connection with visual indicators other than cathode-ray tubes for presentation of an assembly of a number of characters, e.g. a page, by composing the assembly by combination of individual elements arranged in a matrix no fixed position being assigned to or needed to be assigned to the individual characters or partial characters using controlled light sources using electroluminescent panels semiconductive, e.g. using light-emitting diodes [LED] organic, e.g. using organic light-emitting diodes [OLED]
- G09G3/3225—Control arrangements or circuits, of interest only in connection with visual indicators other than cathode-ray tubes for presentation of an assembly of a number of characters, e.g. a page, by composing the assembly by combination of individual elements arranged in a matrix no fixed position being assigned to or needed to be assigned to the individual characters or partial characters using controlled light sources using electroluminescent panels semiconductive, e.g. using light-emitting diodes [LED] organic, e.g. using organic light-emitting diodes [OLED] using an active matrix
- G09G3/3258—Control arrangements or circuits, of interest only in connection with visual indicators other than cathode-ray tubes for presentation of an assembly of a number of characters, e.g. a page, by composing the assembly by combination of individual elements arranged in a matrix no fixed position being assigned to or needed to be assigned to the individual characters or partial characters using controlled light sources using electroluminescent panels semiconductive, e.g. using light-emitting diodes [LED] organic, e.g. using organic light-emitting diodes [OLED] using an active matrix with pixel circuitry controlling the voltage across the light-emitting element
-
- G—PHYSICS
- G09—EDUCATION; CRYPTOGRAPHY; DISPLAY; ADVERTISING; SEALS
- G09G—ARRANGEMENTS OR CIRCUITS FOR CONTROL OF INDICATING DEVICES USING STATIC MEANS TO PRESENT VARIABLE INFORMATION
- G09G2300/00—Aspects of the constitution of display devices
- G09G2300/04—Structural and physical details of display devices
- G09G2300/0439—Pixel structures
- G09G2300/0452—Details of colour pixel setup, e.g. pixel composed of a red, a blue and two green components
-
- G—PHYSICS
- G09—EDUCATION; CRYPTOGRAPHY; DISPLAY; ADVERTISING; SEALS
- G09G—ARRANGEMENTS OR CIRCUITS FOR CONTROL OF INDICATING DEVICES USING STATIC MEANS TO PRESENT VARIABLE INFORMATION
- G09G2320/00—Control of display operating conditions
- G09G2320/02—Improving the quality of display appearance
- G09G2320/0247—Flicker reduction other than flicker reduction circuits used for single beam cathode-ray tubes
-
- G—PHYSICS
- G09—EDUCATION; CRYPTOGRAPHY; DISPLAY; ADVERTISING; SEALS
- G09G—ARRANGEMENTS OR CIRCUITS FOR CONTROL OF INDICATING DEVICES USING STATIC MEANS TO PRESENT VARIABLE INFORMATION
- G09G2330/00—Aspects of power supply; Aspects of display protection and defect management
- G09G2330/02—Details of power systems and of start or stop of display operation
- G09G2330/021—Power management, e.g. power saving
-
- G—PHYSICS
- G09—EDUCATION; CRYPTOGRAPHY; DISPLAY; ADVERTISING; SEALS
- G09G—ARRANGEMENTS OR CIRCUITS FOR CONTROL OF INDICATING DEVICES USING STATIC MEANS TO PRESENT VARIABLE INFORMATION
- G09G2330/00—Aspects of power supply; Aspects of display protection and defect management
- G09G2330/02—Details of power systems and of start or stop of display operation
- G09G2330/028—Generation of voltages supplied to electrode drivers in a matrix display other than LCD
-
- G—PHYSICS
- G09—EDUCATION; CRYPTOGRAPHY; DISPLAY; ADVERTISING; SEALS
- G09G—ARRANGEMENTS OR CIRCUITS FOR CONTROL OF INDICATING DEVICES USING STATIC MEANS TO PRESENT VARIABLE INFORMATION
- G09G2370/00—Aspects of data communication
- G09G2370/02—Networking aspects
- G09G2370/022—Centralised management of display operation, e.g. in a server instead of locally
Abstract
An example method includes: estimating an amount of power to be used by a display at a future time based on content to be displayed at the display of the mobile computing device at the future time; selecting a power converter of a plurality of power converters of the mobile computing device based on the estimated power level, each power converter of the plurality of power converters optimized for a different output power range; and causing the electrical power from the selected power converter to be supplied to the display at a future time.
Description
Background
The display device may include a light emitting element that generates light using electric energy. For example, an Organic Light Emitting Diode (OLED) display device may include a matrix of OLEDs, each OLED generating light using electrical energy. The amount of electrical energy consumed by the light emitting elements may be related to what is being displayed by the display. For example, an OLED display may consume more power when displaying a brighter image than when displaying a darker image.
Disclosure of Invention
In general, aspects of the disclosure are directed to systems that include a power converter that supplies electrical power to a display (e.g., to light emitting elements of the display). The display may consume different amounts of power based on the content being displayed (e.g., based on the brightness of the content being displayed). Power converters may be designed to operate efficiently within certain ranges (e.g., output power versus input power). For example, a particular power converter may be optimized to supply a load current in the range from 60 milliamps (mA) to 300 mA. When the display supplied by that particular power converter draws an amount of current that is outside of the optimized range, that particular power converter may still supply the required power, but with reduced efficiency. The system may include a plurality of power converters configured to supply electrical power to the display, each power converter optimized for a different output load current range. A controller of the system may select one of the plurality of power converters to supply power to the display. However, it may not be desirable to select a power converter based on the amount of power currently used by the display. For example, if the selected power converter is not the optimal power converter for the amount of power currently being used by the display, the controller may switch to the optimal power converter. However, such switching in frames may introduce flicker, which may be undesirable. As such, the controller may need to choose between using a non-optimal power converter and an undesirable option of introducing flicker.
In accordance with one or more techniques of this disclosure, a controller of a device may select a power converter from a plurality of power converters to supply power to a display based on an amount of power predicted to be used by the display at a future time. For example, a controller of the device may estimate an amount of power to be used by a display of the device to output frame N at a future time based on the content of frame N. The controller may select a power converter that matches the estimated amount of power and cause electrical power from the selected power converter to be supplied to the display at a future time (i.e., while the display is outputting frame N). In this way, the power converter of the plurality of power converters that can most efficiently supply the amount of power used by the display will be used dynamically without introducing flicker. In this manner, the techniques of this disclosure enable a reduction in the amount of power used to drive the display.
In one example, a method comprises: estimating an amount of power to be used by a display at a future time based on content to be displayed at the future time at the display of the mobile computing device; selecting, based on the estimated power level, a power converter of a plurality of power converters of the mobile computing device, each power converter of the plurality of power converters optimized for a different output power range; and causing electrical power from the selected power converter to be supplied to the display at the future time.
In another example, a device includes a display; a plurality of power converters configured to supply electrical power to a display, each power converter optimized for a different output power range; and circuitry configured to: estimating an amount of power to be used by a display at a future time based on content to be displayed at the future time; selecting a power converter of the plurality of power converters based on the estimated power level; and causing electrical power from the selected power converter to be supplied to the display at the future time.
In another example, a device includes a plurality of power converters configured to supply electrical power to a display, each power converter optimized for a different output load current range, wherein each power converter of the plurality of power converters includes a respective set of ELVDD and ELVSS power converters; means for estimating an amount of power to be used by a display at a future time based on content to be displayed at the future time at a display of a device; means for selecting a power converter of the plurality of power converters based on the estimated power level; and means for causing electrical power from the selected power converter to be supplied to the display at the future time.
The details of one or more examples are set forth in the accompanying drawings and the description below. Other features, objects, and advantages of the disclosure will be apparent from the description and drawings, and from the claims.
Drawings
Fig. 1 is a block diagram illustrating an apparatus including a plurality of power converters configured to supply electrical power to a display, according to one or more aspects of the present disclosure.
Fig. 2 is a graph illustrating example efficiencies across an output load current of various power converters of a power converter according to one or more aspects of the present disclosure.
Fig. 3 is a block diagram illustrating details of another example of the apparatus of fig. 1 in accordance with one or more aspects of the present disclosure.
Fig. 4A and 4B are conceptual diagrams illustrating simulated data power according to one or more aspects of the present disclosure.
Fig. 5 is a conceptual diagram illustrating components of a display according to one or more aspects of the present disclosure.
Fig. 6 is a conceptual diagram illustrating a machine learning model that predicts the transmit power of a display in accordance with one or more aspects of the present disclosure.
Fig. 7A to 7E are conceptual diagrams illustrating aspects of an example machine learned model according to example embodiments of the present disclosure.
Fig. 8 is a flow diagram illustrating example operations of an example controller configured to dynamically select a power converter from a plurality of power converters in accordance with one or more aspects of the present disclosure.
Detailed Description
Fig. 1 is a block diagram illustrating an apparatus including a plurality of power converters configured to supply electrical power to a display, according to one or more aspects of the present disclosure. As shown in fig. 1, the device 2 includes a power supply 4, a power manager 6, a multiplexer 8, a controller 10, and a display 12.
In the example of fig. 1, device 2 may be any device that includes a display. Examples of device 2 include, but are not limited to, a mobile phone, a camera device, a tablet computer, a smart display, a laptop computer, a desktop computer, a gaming system, a media player, an e-book reader, a television platform, a vehicle infotainment system, or a vehicle host (head unit), or a wearable computing device (e.g., a computerized watch, a head mounted device such as a VR/AR headset, computerized glasses, computerized gloves).
The power source 4 may be any component that can supply electrical power to other components of the device 2. Examples of the power source 4 include, but are not limited to, a battery pack (primary battery, secondary battery, or a combination thereof), a photovoltaic panel, a mechanical generator, a fuel cell, or any other device capable of providing electrical power.
The power manager 6 may include one or more components capable of processing and supplying electrical power for use by other components of the device 2, such as the display 12. In some examples, power manager 6 may be a plurality of components that are separately attached to a board (e.g., a printed circuit board) of device 2. In some examples, one or more components of power manager 6 may be included in an integrated circuit, which may be referred to as a Power Management Integrated Circuit (PMIC). The power manager 6 may be capable of supplying at least two power signals concurrently (e.g., for use by the display 12). For example, where the display 12 is an Organic Light Emitting Diode (OLED) display, the power manager 6 may include a power converter configured to supply an ELVDD power signal and an ELVSS power signal. In some examples, the power manager 6 may be capable of having five power signals. Such power signals may include ELVDD power signals, ELVSS power signals, AVDD power signals (e.g., analog power signals for pixel data drivers and timing controllers), VDDI, and VCI power signals (e.g., digital power for peripheral blocks).
The display 12 may be capable of presenting data as an image viewable by a user of the device 2. For example, the display 12 may include a matrix of individually controllable pixels. Examples of the display 12 include, but are not limited to, a Liquid Crystal Display (LCD), a Light Emitting Diode (LED) display, an Organic Light Emitting Diode (OLED) display (including, for example, active Matrix Organic Light Emitting Diodes (AMOLEDs)), a micro LED display, or similar monochrome or color display capable of outputting visible information to a user of the device 2.
The display 12 may include one or more light emitting elements, which may be controlled via in-plane Gates (GIPs) 24A and 24B along with a driver IC 22. The light emitting elements may form a backlight of the display or may form pixels of the display. As one example, where the display 12 is an LCD display, the display 12 may include one or more light emitting elements arranged as a backlight. As another example, where the display 12 is an OLED display or a micro led display, the display 12 may include a plurality of light emitting elements that individually operate as pixels.
An example circuit for a single light emitting element of display 12 is shown in box 14 of fig. 1. For simplicity, only a single light emitting element is shown. However, it should be understood that the display 12 includes a plurality of circuits that perform operations similar to the example circuit shown in block 14. As shown in block 14, a light emitting element 16 (e.g., a Light Emitting Diode (LED)) may be coupled to the ELVSS node and a current source 18. The ELVSS node and ELVDD node may be supplied by ELVSS and ELVDD power supply signals, respectively, generated by the power manager 6. The state of the current source 18 may control the amount of current flowing through the light emitting element 16. The amount of light emitted by the light emitting element 16 is an inherent factor (e.g., eta or eta) of the light emitting element 16 and the amount of current (e.g., I) flowing through the light emitting element 16 OLED ) As a function of (c). For example, the amount of light emitted by the light emitting element 16 may be represented by the following equation L = η I OLED Where L is the amount of light emitted by the light emitting element 16. Thus, the amount of current I provided by the current source 18 OLED Is a function of several parameters such as display brightness settings (e.g., display Brightness Value (DBV)) and content to be displayed (e.g., red, green, and blue (RGB) values). In other words, I OLED ～f(DBV，R，G，B)。
As can be seen from the above, the amount of power consumed by the light emitting elements of the display 12 may vary based on the image formed by the display 12. For example, the light emitting elements of display 12 may consume more power (e.g., a higher current level) when display 12 is displaying a brighter image than when display 12 is displaying a darker image.
The total amount of power used by the display 12 may be a function of the transmit power, the data power, and the gate drive power. The transmission power may be power actually used by the light emitting element. As discussed above, the power used by the light emitting elements may be a function of the Display Brightness Value (DBV) and the content to be displayed. The ELVDD and ELVSS power rails (e.g., provided by power manager 6) may be used to generate transmit power. The analog data power may be a power for adjusting an output of the light emitting element (e.g., used by the driver IC 22). As discussed in further detail below, the analog data power may be a function of data line capacitance, DBV, frame rate, and content to be displayed. The analog data power may be generated using an AVDD power rail (e.g., provided by power manager 6). The gate drive power may be the power used to drive the various gates of the display 12, such as the gates of Gate In Panel (GIP) modules 24A and 24B. The gate drive power may be generated using an AVDD power rail (e.g., provided by power manager 6). As discussed in further detail below, the gate drive power may be a function of the data line capacitance, DBV, frame rate, and content to be displayed.
As discussed above, the power manager 6 may include a power converter configured to supply power signals (e.g., AVDD, ELVDD, and ELVSS) that may be used to drive light emitting elements of the display 12 or other components of the display 12 (e.g., the driver IC 22, the GIP 24A, and the GIP 24B). Examples of such power converters include DC/DC converters, such as buck (buck), boost (boost), buck-boost (buck-boost), buck-boost (Cuk) (also known as dual-inductor inverter converters), flyback (flyback), or any other type of DC/DC converter. In one particular example, power manager 6 may include a boost converter configured to generate an ELVDD power signal and a buck-boost converter configured to generate an ELVSS power signal. By its nature, power converters have different efficiencies (e.g., efficiency may be a function of output current) under different operating conditions. In general, efficiency may be considered to be the amount of power provided by the power converter relative to the amount of power consumed by the power converter. For example, a power converter that consumes 10 watts (W) of power while outputting 9W of power may be considered to be 90% efficient. The values of the components of the power converter may affect the efficiency of the power converter and may therefore be selected to achieve certain efficiency goals. For example, the values of the inductor and capacitor of the power converter of power manager 6 may be selected to provide optimal efficiency at the normal operating current levels of display 12.
However, in some examples, a display such as display 12 may be operated such that there is not any one normal operating current level. For example, in addition to a normal mode in which images are displayed at normal brightness and the display 12 consumes normal operating current levels (e.g., between about 50mA and 200 mA), the device 2/display 12 may operate in: a dark mode in which the image is changed to appear darker (e.g., having a lower brightness than the normal mode) and the display 12 consumes a reduced operating current level (e.g., between about 10mA and 50 mA); a locked mode in which limited information (e.g., only time, date, etc.) is displayed; and/or any other mode in which the operating current level of display 12 is different from the normal operating current level.
To reduce the total amount of power consumed to display an image, power manager 6 may include a plurality of power converters 20A-20N (collectively, "power converters 20"), each optimized for a different output load current range. For example, rather than including only a single set of ELVDD/ELVSS power converters, the power converters 20 may each include a respective set of ELVDD/ELVSS power converters optimized to supply electrical power to the display 12 at different current ranges.
In operation, the controller 10 may dynamically switch which of the power converters 20 is supplying electrical power to the display 12. For example, the controller 10 may measure an amount of power currently being used by the display 12 (e.g., an amount of current used by the display 12), select a power converter of the power converters 20 based on the measured power level, and cause electrical power from the selected power converter of the power converters 20 to be supplied to the display 12. However, switching the power converter based on the amount of power currently being used by display 12 may present one or more drawbacks. For example, mid-frame power converter switching may introduce flicker. The amount of power used by the display 12 is a function of the content being displayed at the display 12. Different content frames may be disparate and thus require disparate amounts of power. In this way, if the selected one of the power converters 20 is not the optimal power converter for the amount of power currently being used by the display 12, the controller 10 may switch to the optimal power converter of the power converters 20. Such switching in frames may introduce flicker, which may be undesirable.
In accordance with one or more techniques of this disclosure, controller 10 may select a power converter from power converters 20 to supply power to display 12 based on an amount of power predicted to be used by display 12 at a future time. For example, the controller 10 may estimate the amount of power used by the display 12 to output frame N at a future time based on the content of frame N. The controller 10 may select one of the power converters 20 that matches the estimated amount of power, and cause the electrical power from the selected power converter to be supplied to the display 12 at a future time. For example, rather than switching to the selected power converter halfway through the output of frame N, the controller 10 may cause the selected power converter to supply power to the display 12 while the display is outputting frame N. In this way, the power converters in the power converter 20 that can most efficiently supply the amount of power used by the display 12 can be used dynamically without introducing flicker. In this manner, the techniques of this disclosure enable a reduction in the amount of power used to drive the display 12.
The controller 10 may be any controller or processor capable of performing the operations described herein. Examples of controller 10 include, but are not limited to, one or more Digital Signal Processors (DSPs), general purpose microprocessors, application Specific Integrated Circuits (ASICs), field programmable logic arrays (FPGAs), system-on-a-chip (socs), or other equivalent integrated or discrete logic circuitry.
Fig. 2 is a graph illustrating example efficiencies across an output load current of various power converters of power converter 20 according to one or more aspects of the present disclosure. As shown in fig. 2, graph 200 includes a horizontal axis representing an output load current of the power converter, a vertical axis representing an efficiency of the power converter, and curves 202A and 202B representing example relationships between the efficiency and the output load current of the various power converters. For example, curve 202A may represent the relationship between the efficiency and the output load current of power converter 20A of fig. 1, and curve 202B may represent the relationship between the efficiency and the output load current of power converter 20B of fig. 1.
As can be seen from curves 202A and 202B in fig. 2, power converters 20A and 20B may be optimized for efficient operation over different load current ranges. For example, as can be seen from curve 202A, power converter 20A may be optimized for efficient operation from about 10mA to about 50 mA. Similarly, as can be seen from curve 202B, power converter 20B can be optimized for efficient operation from about 50mA to about 250 mA.
In operation, multiplexer 8 and/or controller 10 may enable dynamic switching between power converters 20. For example, the controller 10 may estimate a current level used by the display 12 at a future time. As discussed in further detail below, the controller 10 may estimate the current level based on one or more of a variety of factors, such as the display brightness setting and the content to be displayed by the display 12. The controller 10 may select a power converter of the power converter 20 based on the estimated current level. For example, the controller 10 may select a power converter of the power converter 20 that is optimized to supply electrical power at the estimated current level. The controller 10 may cause electrical power from the selected power converter to be supplied to the display 12 at a future time. As one example, where the device 2 includes a multiplexer 8, the controller 10 may cause the multiplexer 8 to route the ELVDD and ELVSS power signals from the selected power converter to the display 12. As another example (e.g., where the multiplexer 8 is omitted and the outputs of all power converters 20 are connected to a common ELVSS and ELVSS node, such as shown in fig. 3), the controller 10 may cause selected ones of the power converters 20 to output power signals and cause other ones of the power converters to refrain from outputting the power signals.
Fig. 3 is a block diagram illustrating details of another example of the apparatus of fig. 1 in accordance with one or more aspects of the present disclosure. As shown in example fig. 3, which is the inverse of fig. 1, the device 2 may omit the multiplexer 8, and the output of the power converter 20 may be connected to a common node (e.g., ELVDD node and ELVSS node) that supplies power to the display 12. As discussed above, in such examples, the controller 10 may dynamically control which of the power converters 20 supplies power by operating only the desired power converter and shutting down the other power converters.
As discussed above, the controller 10 may enable dynamic switching between the power converters 20. For example, controller 10 may estimate a current level to be used by display 12 at a future time, select a power converter of power converters 20 based on the estimated current level, and cause electrical power from the selected power converter to be supplied to display 12 at the future time.
As shown in fig. 3, the controller 10 may include a data path 30, a transmit power (EM) calculator 32, a data power calculator 34, a gate power calculator 36, and a power selector 38. The controller 10 may receive data from one or more other components of the device 2. For example, the controller 10 may receive content, frame rate, and/or brightness settings from a Central Processing Unit (CPU) of the device 2. The content may represent content to be displayed by the display 12. For example, the content may include pixel values (e.g., RGB values) that collectively form an image to be displayed by the display 12. The brightness setting may indicate a general brightness level for operation of the display 12. The brightness setting may be controlled by a user (e.g., via a slider or some other user interface element) and/or may be automatically controlled by the device 2 (e.g., based on ambient light sensed via a light sensor).
The data path 30 may perform one or more actions to process the content before it is provided to the display 12. For example, data path 30 may include one or more frame buffers that store frames of image data to be displayed at display 12.
The EM power calculator 32 may predict the amount of power used by the light emitting elements of the display 12 when outputting a particular frame. The EM power calculator 32 may predict or estimate EM power using any combination of theoretical, analytical, and machine learning techniques or models. To utilize a theoretical or analytical model, the EM power calculator 32 may calculate the transmit power using the following equation:
in other words, the EM power calculator 32 may sum the RGB values to be displayed at each pixel across all pixels of the display 12 by a function of the voltage difference between ELVDD and ELVSS. Assuming that the same DBV is used for all pixels, the EM power calculator 32 may multiply the sum by a function of the Display Brightness Value (DBV). The theoretical and analytical techniques may differ in their method of determining f (DBV) and f (R, G, B). To determine f (DBV) and/or f (R, G, B) using theoretical techniques, EM power calculator 32 may use a model based on theoretical parameters of display 12. As one example, the EM power calculator 32 may determine a function of the display brightness values using the following theoretical equation:
wherein L is MAX_NORM Is the image of the display 12 in the normal modeMaximum brightness level of pixel, and L MAX_HBM Is the maximum brightness level of the pixel of display 12 in High Brightness (HB) mode.
As another example, the EM power calculator 32 may determine a function of the content to be displayed using the following theoretical equation:
f(R，G，B)＝GAMMA2.2
wherein GAMMA2.2 is GAMMA value determined based on R, G, and B values.
To determine f (DBV) and/or f (R, G, B) using analytical techniques, EM power calculator 32 may use a model based on measured parameters of display 12. As one example, the EM power calculator 32 may determine a function of the display brightness values using the following analytical equation:
as another example, the EM power calculator 32 may determine a function of the content to be displayed using the following analytical equation:
f(R，G，B)＝0.6957e -9 R 3 +0.5471e -6 R 2 -0.3260e -5 R+0.5748e -3
+2.147e -10 G 3 +0.4471e -6 G 2 -0.2260e -5 G+0.7348e -4
+1.4957e -10 B 3 +1.3471e -6 B 2 -0.2220e -5 B+1.1748e -4
where R is a gray code of a red value of the content to be displayed at the pixel, G is a gray code of a green value of the content, and B is a gray code of a blue value of the content.
The EM power calculator 32 may use machine learning to determine the transmit power by several techniques. Machine learning techniques may assist the EM power calculator 32 in considering more complex aspects of the display 12, such as panel load resistance. In particular, the panel load resistance may be such that the combined sum of the transmit power of each color component is not equal to the total transmit power (e.g., P) R +P G +P B ≠P RGB ). In one example, the EM power calculator 32 may use a Machine Learning (ML) model to determine a new gray code for the color component to account for this panel resistance. For example, the EM power calculator 32 may utilize the ML model to calculate the new gray codes (R ', G ', B ') such that P R’ +P G’ +P B’ ＝P R’G’B’ . The ML model may be trained based on past behavior of the display 12. The EM power calculator 32 may use the ML-derived new gray code to determine the transmit power. For example, the EM power calculator 32 may use the ML-derived new gray code to determine the transmit power using the analytical or theoretical techniques discussed above. Additional or alternative techniques for determining transmit power using machine learning are discussed below with reference to fig. 6.
The data power calculator 34 may predict the use of analog data (i.e., P), such as by the driver IC 22 Data ) The amount of power of. The data power calculator 34 may be based on the inclusion of data line capacitance (C) line ) Display Brightness Value (DBV), frame rate, and several parameters of content (e.g., RGB data) to predict P Data . Further details of one example of the data power calculator 34 are discussed below with reference to fig. 4.
FIGS. 4A and 4B are diagrams illustrating one or more embodiments according to the present disclosureConceptual diagram of simulated data power of the aspects. Fig. 4A illustrates an example arrangement of sub-pixels in rows and columns. In particular, fig. 4A illustrates a so-called RGBG arrangement, in which each pixel is composed of one red sub-pixel, two green sub-pixels, and one blue sub-pixel. The blue and red sub-pixels are arranged on a common column (e.g., an odd column), while the green sub-pixels are arranged on their own column (e.g., an even column). Due to the various characteristics of the subpixels, the voltages required to achieve a particular gray code may be different for different colors. For example, the voltage required to implement the blue gray code 255 may be different from (e.g., greater than) the voltage required to implement the red gray code 255. The amount of power consumed when programming the sub-pixel output levels may be a function of the difference between the voltages of adjacent pixels. The voltage difference between one sub-pixel and the next sub-pixel may be referred to as the swing voltage or V Swing . A worst case scenario (maximum power usage) may be that all red subpixels are off (e.g., with a gray code of 0) and all blue subpixels are fully on (e.g., with a gray code of 255). Thus, the amount of analog data power (e.g., P) Data ) May be based on the content displayed.
FIG. 4B illustrates an example timing diagram for pixel programming. As shown in fig. 4B, the output data frame may include a pixel programming period and an optional blanking period. During the pixel programming period, the driver IC 22 may output a voltage level that causes each sub-pixel to emit light at a particular level.
Based on the above, the data power calculator 34 may calculate the data line power using the following theoretical equation:
wherein, C line Is the capacitance of the sub-pixel line (e.g. C of FIG. 4A) LINE )，V swing Is the swing voltage between adjacent sub-pixels, F toggle Is the frame rate, T prog Is the length of the programming period, and T frame Is the length of the entire frame (e.g., T) prog Plus T blank )。
Based on this theoretical equation, the data power calculator 34 may calculate P using the following analytical equation Data :
Wherein, C line Is the capacitance of the sub-pixel line (e.g., C of FIG. 4A) LINE ) AVDD is the voltage level, V, of the AVDD rail (e.g., generated by the power converter in power converter 20 of FIG. 1) i,j Is the voltage required to program the sub-pixel at location i, j, and relu [ deg. ]]Is a linear unit function of rectification (e.g., since no power is consumed from a higher programming voltage swing to a lower programming voltage, and power is consumed from a low programming voltage swing to a high programming voltage).
For completeness, it is again noted that the programming voltage of a subpixel is a function of both the gray code and the display luminance value of the subpixel. As such, the data power calculator 34 may determine P based on one or more of the following Data : content to be displayed, display brightness value, frame rate, and data line capacitance.
Fig. 5 is a conceptual diagram illustrating components of a display according to one or more aspects of the present disclosure. As discussed above, the panel load resistance may have an effect on the amount of current used to drive the light emitting elements (e.g., on I OLED Has an effect). The panel load resistance, also referred to as the Internal Resistance (IR), may be formed by the common resistance of the components inside the display 12. For example, as shown in FIG. 5, each additional row of pixels may introduce an additional resistance. The cumulative resistance may be relatively small near the driver IC 22 (e.g., in a row near the "bottom", such as y = 1), but may be relatively large far from the driver IC 22 (e.g., in a row near the "top", such as y = M). The result of these changes in IR may be that the amount of current used to drive the light emitting elements is a function of the distance (e.g., the number of rows or y-coordinate in fig. 5) from the driver IC 22. For example, I OLED Can be Display Brightness Value (DBV), red grayA function of the code R, the green gray code G, the blue gray code B, and the position y (e.g., I OLED F (DBV, R, G, B, y)). In some examples, y may represent the distance (e.g., in number of pixels) of a particular row from driver IC 22.
This dependence on the position y may render the above-mentioned analytical equation for the transmission power false. In accordance with one or more techniques of this disclosure, EM power calculator 32 may use a machine learning model to predict the transmit power of display 12. For example, the EM power calculator 32 may use a machine learning model that may be trained based on previous transmit power consumption of the display 12 while displaying various patterns at various locations to predict I OLED . In this way, the machine learning model may take into account the panel load resistance.
Fig. 6 is a conceptual diagram illustrating a machine learning model that predicts the transmit power of a display in accordance with one or more aspects of the present disclosure. As discussed above, the EM power calculator 32 may use a machine learning model to predict the transmit power of the display 12. In some examples, the machine learning model may be a deep neural network, such as a Convolutional Neural Network (CNN), to predict the transmit power. Using CNN to predict transmit power may present one or more advantages. For example, the CNN may hold location information (e.g., row information or "y" from fig. 5).
As shown in fig. 6, the EM power calculator 32 may receive content 602, which is content displayed at the display 12 at a future time. The content 602 may be in the form of an RGB matrix, referred to as an input RGB matrix. The EM power calculator 32 may execute the ML model 604 to process the content 602 to determine the predicted amount of transmit power. For example, the EM power calculator 32 may determine I using the ML model 604 and based on the content 602 OLED 。
The EM power calculator 32 may determine the I based on OLED The total transmit power is determined. For example, the EM power calculator 32 may determine the transmit power using the following analytical equation.
Wherein, I OLED [i，j]～f(DBV，R，G，B，y)。
Referring back to fig. 3, power selector 38 may be configured to select a power converter of power converters 20 based on one or more estimated power levels. For example, the power selector 38 may be based on the estimated amount of transmit power P EM Estimated amount of data power P Data And/or estimated amount of gate drive power P GIP To estimate the total amount of power to be used by the display 12. The total amount of power may be expressed as a current level (e.g., assuming a uniform voltage) or a watt level.
In some examples, power selector 38 may include a look-up table (LUT) that maps between current levels and power converters. An example LUT is shown below in table 1.
TABLE 1
Current range | Power converter | |
10mA- | Power converter | 20A |
51mA- | Power converter | 20B |
As shown above in table 1, power selector 38 may select power converter 20A if the estimated power level is between 10mA and 50 mA. Similarly, power selector 38 may select power converter 20B if the estimated power level is between 51mA and 250 mA.
In some examples, power selector 38 may select a group of power converters from power converters 20. For example, where power converter 20 includes a first set of power converters (e.g., a set of EVLDD and EVLSS converters) configured to supply a first power rail and a second set of power converters (e.g., a set of AVDD converters) configured to supply a second power rail, power selector 38 may select a power converter from the first set and a power converter from the second set. As one example, the power selector 38 may select an ELVDD/ELVSS converter from a set of ELVDD/ELVSS converters based on the transmission power and an AVDD converter from a set of AVDD converters based on the gate driving power amount and the data power amount. The selection of power converters may be separate or may be joint. For example, in a joint selection, the power selector 38 may always select the same AVDD converter for a particular ELVDD/ELVSS converter. In a separate option, the power selector 38 may choose to be optimized to output P DaTa +P GIP And the selection is optimized to output P EM ELVDD/ELVSS.
The power selector 38 may cause the electrical power from the selected power converter to be supplied to the display at a future time. As one example, as shown in the example of fig. 3, power selector 38 may cause selected ones of power converters 20 to supply electrical power to display 12 while causing other ones of power converters 20 to not supply electrical power to display 12. As another example, as shown in the example of fig. 1, the power selector 38 may output a signal to the multiplexer 8 that causes power from the selected one of the power converters 20 to be routed to the display 12 (while similarly not operating the other ones of the power converters 20).
The controller 10 may be configured to periodically update the selection of power converters from the power converters 20. For example, the controller 10 may be configured to update the selection of power converters from the power converters 20 based on the occurrence of an event. Example events include, but are not limited to, display 12 displaying a particular number of frames (e.g., 1,5,10,20,30,60,120, etc.), display 12 passing a particular amount of time (e.g., 1 second, 2 seconds, 5 seconds, 10 seconds, 30 seconds, 1 minute, etc.), and so forth. As one example, controller 10 may determine that an event has occurred in response to determining that a particular number of frames have been displayed by display 12 (e.g., based on monitoring of a frame buffer of display 12 or used by display 12). As another example, the controller 10 may determine that an event has occurred in response to determining that a particular amount of time has elapsed.
Fig. 7A through 7E are conceptual diagrams illustrating aspects of an example machine-learned model according to example embodiments of the present disclosure. Fig. 7A through 7E are described below in the context of model 604 of fig. 6. For example, in some instances, machine-learned model 300 may be an example of any of models 604, as referenced below.
Fig. 7A depicts a conceptual diagram of an example machine-learned model according to an example embodiment of the present disclosure. As shown in fig. 7A, in some embodiments, the machine-learned model 300 is trained to receive one or more types of input data and, in response, provide one or more types of output data. Thus, fig. 7A illustrates a model 300 of machine learning that performs inference.
The input data may include one or more characteristics associated with the instance or example. In some implementations, the one or more features associated with an instance or example may be organized into a feature vector (e.g., an RGB matrix). In some embodiments, the output data may include one or more predictions. Prediction may also be referred to as inference. Thus, given the features associated with a particular instance, the machine-learned model 300 may output a prediction for that instance based on the features.
The machine-learned model 300 may be or include one or more of a variety of different types of machine-learned models. In particular, in some embodiments, the machine-learned model 300 may perform classification, regression, clustering, anomaly detection, recommendation generation, and/or other tasks.
In some implementations, the machine-learned model 300 can perform various types of classification based on input data. For example, the machine-learned model 300 may perform binary classification or multi-class classification. In binary classification, outputting data may include classifying input data into one of two different classes. In a multi-class classification, outputting data may include classifying input data into one (or more) of two or more classes. The classification may be single-label or multi-label. The machine-learned model 300 may perform discrete class classification, where the input data is simply classified into one or more classes or classes.
In some implementations, the machine-learned model 300 can perform classification, wherein the machine-learned model 300 provides a numerical value for each of one or more classes that describes the extent to which it believes that the input data should be classified into the respective class. In some instances, the numerical values provided by the machine-learned model 300 may be referred to as "confidence scores," which indicate respective confidences associated with classifying the input into respective classes. In some implementations, the confidence score can be compared to one or more thresholds to give discrete class predictions. In some implementations, only a certain number (e.g., one) of classes with relatively largest confidence scores may be selected to give discrete class predictions.
The machine-learned model 300 may output a probabilistic classification. For example, the machine-learned model 300 may predict a probability distribution over a set of classes given sample input. Thus, rather than outputting only the most likely class to which a sample input should belong, the machine-learned model 300 outputs, for each class, the probability that the sample input belongs to such class. In some embodiments, the probability distributions over all possible classes may be summed to one. In some implementations, a Softmax function or other type of function or layer may be used to compress the set of real values respectively associated with the possible classes into a set of real values in a range of (0, 1) that sums to one.
In some examples, the probabilities provided by the probability distributions may be compared to one or more thresholds to give discrete class predictions. In some implementations, only a certain number (e.g., one) of classes with relatively maximum prediction probabilities may be selected to give discrete class predictions.
In cases where the machine-learned model 300 performs classification, the machine-learned model 300 may be trained using supervised learning techniques. For example, the machine-learned model 300 may be trained on a training data set that includes training examples labeled as belonging to (or not belonging to) one or more classes. Further details regarding supervised training techniques are provided below in the description of fig. 7B-7E.
In some embodiments, the machine-learned model 300 may perform regression to provide output data in the form of continuous values. Consecutive numerical values may correspond to numbers including any of various metrics or numerical representations, such as monetary values, scores, or other numerical representations. As an example, the machine-learned model 300 may perform a linear regression, a polynomial regression, or a nonlinear regression. As an example, the machine-learned model 300 may perform a simple regression or a multiple regression. As described above, in some embodiments, a Softmax function or other function or layer may be used to compress the set of real values respectively associated with two or more possible classes into a set of real values in the range of (0, 1) summed to one.
The machine-learned model 300 may perform various types of clustering. For example, the machine-learned model 300 may identify one or more previously defined clusters to which the input data most likely corresponds. The machine-learned model 300 may identify one or more clusters within the input data. That is, in instances in which the input data includes multiple objects, documents, or other entities, the machine-learned model 300 may classify the multiple entities included in the input data into multiple clusters. In some embodiments where the machine-learned model 300 performs clustering, the machine-learned model 300 may be trained using unsupervised learning techniques.
The machine-learned model 300 may perform anomaly detection or outlier detection. For example, the machine-learned model 300 may identify input data that does not conform to expected patterns or other features (e.g., as previously observed from previous input data). As an example, anomaly detection may be used for fraud detection or system failure detection.
In some implementations, the machine-learned model 300 can provide output data in the form of one or more recommendations. For example, the machine-learned model 300 may be included in a recommendation system or engine. As an example, given input data describing previous results of certain entities (e.g., scores, rankings, or ratings indicative of an amount of success or enjoyment), the machine-learned model 300 may output suggestions or recommendations of one or more additional entities that are expected to have a desired result based on the previous results (e.g., eliciting a score, ranking, or rating indicative of success or enjoyment). As one example, given input data describing content to be output at a display of a computing device, such as device 2 of fig. 1, a controller, such as controller 10 of fig. 1, may predict an amount of power to be used to output the content.
In some cases, the machine-learned model 300 may act as a proxy within the environment. For example, the machine-learned model 300 may be trained using reinforcement learning, which will be discussed in further detail below.
In some embodiments, the machine-learned model 300 may be a parametric model, while in other embodiments, the machine-learned model 300 may be a non-parametric model. In some embodiments, the machine-learned model 300 may be a linear model, while in other embodiments, the machine-learned model 300 may be a non-linear model.
As described above, the machine-learned model 300 may be or include one or more of a variety of different types of machine-learned models. Examples of such different types of machine learning models are provided below for illustration. One or more example models described below may be used (e.g., combined) to provide output data in response to input data. Additional models may be used in addition to the example models provided below.
In some implementations, the machine-learned model 300 can be or include one or more classifier models, such as, for example, a linear classification model, a quadratic classification model, or the like. The machine-learned model 300 may be or include one or more regression models, such as, for example, a simple linear regression model, a multiple linear regression model, a logistic regression model, a stepwise regression model, a multivariate adaptive regression spline, a locally estimated scatter-smoothing model, and the like.
In some examples, the machine-learned model 300 may be or include one or more decision tree-based models such as, for example, classification and/or regression trees, iterative dichotomy 3 decision trees, C4.5 decision trees, chi-square automatic interaction detection decision trees, decision stumps, conditional decision trees, and so forth.
The machine-learned model 300 may be or include one or more kernel machines. In some implementations, the machine-learned model 300 can be or include one or more support vector machines. The machine-learned model 300 may be or include one or more instance-based learning models, such as, for example, a learning vector quantization model, a self-organizing map model, a local weighted learning model, and so forth. In some implementations, the machine-learned model 300 can be or include one or more nearest neighbor models, such as, for example, a k-nearest neighbor classification model, a k-nearest neighbor regression model, or the like. The machine-learned model 300 may be or include one or more bayesian models, such as, for example, a na iotave bayes model, a gaussian na iotave bayes model, a polynomial na iotave bayes model, an average single dependency estimator, a bayesian network, a bayesian belief network, a hidden Markov (Markov) model, or the like.
In some embodiments, the machine-learned model 300 may be or include one or more artificial neural networks (also referred to simply as neural networks). A neural network may include a set of connected nodes, which may also be referred to as neurons or perceptrons. The neural network may be organized into one or more layers. Neural networks comprising multiple layers may be referred to as "deep" networks. The deep network may include an input layer, an output layer, and one or more hidden layers located between the input layer and the output layer (e.g., as shown in fig. 6). The nodes of the neural network may or may not be fully connected.
The machine-learned model 300 may be or include one or more feed-forward neural networks. In a feed forward network, the connections between nodes do not form loops. For example, each connection may connect a node from an earlier layer to a node from a later layer.
In some examples, the machine-learned model 300 may be or include one or more recurrent neural networks. In some instances, at least some nodes of the recurrent neural network may form a cycle. Recurrent neural networks are particularly useful for processing input data that is sequential in nature. In particular, in some instances, the recurrent neural network may pass or retain information from a previous portion of the input data sequence to a subsequent portion of the input data sequence by using recurrent or directed recurrent node connections.
In some examples, the sequential input data may include time series data (e.g., sensor data versus time or imaging captured at different times). For example, the recurrent neural network may analyze sensor data versus time to detect or predict sliding directions, to perform handwriting recognition, and so forth. The sequential input data may include words in a sentence (e.g., for natural language processing, speech detection or processing, etc.), notes in a musical composition, sequential actions taken by a user (e.g., application usage in a detected or predicted sequence), sequential object states, and so forth.
Example recurrent neural networks include Long Short Term (LSTM) recurrent neural networks, gated recurrent units, bidirectional recurrent neural networks, continuous time recurrent neural networks, neural history compressors, echo state networks, elman (Elman) networks, jordan (Jordan) networks, recurrent neural networks, hopfield (Hopfield) networks, full-cycle networks, sequence-to-sequence configurations, and the like.
In some embodiments, the machine-learned model 300 may be or include one or more convolutional neural networks. In some examples, a convolutional neural network may include one or more convolutional layers that perform convolution on input data using a learned filter.
The filter may also be referred to as a kernel. Convolutional neural networks may be particularly useful for visual problems, such as when the input data includes imaging such as still images or video. However, convolutional neural networks may also be applied to natural language processing.
In some examples, the machine-learned model 300 may be or include one or more generating networks, such as, for example, generating an antagonistic network. The generation network may be used to generate new data, such as new images or other content.
The machine-learned model 300 may be or include an auto-encoder. In some instances, the purpose of the auto-encoder is to learn a representation for a data set (e.g., a lower-dimensional encoding), typically for the purpose of dimension reduction. For example, in some instances, an auto-encoder may attempt to encode input data and provide output data that reconstructs the input data from the encoding. Recently, the concept of an auto-encoder has been more widely used for learning a generative model of data. In some examples, the auto-encoder can include additional losses beyond reconstructing the input data.
The machine-learned model 300 may be or include one or more other forms of artificial neural networks, such as a deep boltzmann machine, a deep belief network, a stacked autoencoder, and so forth. Any of the neural networks described herein may be combined (e.g., stacked) to form a more complex network.
One or more neural networks may be used to provide the embedding based on the input data. For example, the embedding may be a representation of knowledge abstracted from the input data into one or more learned dimensions. In some instances, embedding may be a useful source to identify related entities. In some instances, the embedding may be extracted from the output of the network, while in other instances, the embedding may be extracted from any hidden node or layer of the network (e.g., near but not at the final layer of the network). Embedding is useful for performing auto-suggest next videos, product suggestions, entity or object recognition, and the like. In some instances, the embedding is a useful input to the downstream model. For example, embedding input data (e.g., search queries) that can be used to generalize downstream models or processing systems.
The machine-learned model 300 may include one or more clustering models, such as, for example, a k-means clustering model, an expectation-maximization model, a hierarchical clustering model, and so forth.
In some embodiments, the machine-learned model 300 may perform one or more dimension reduction techniques such as, for example, principal component analysis, kernel principal component analysis, graph-based kernel principal component analysis, principal component regression, partial least squares regression, sammon mapping, multidimensional scaling, projection pursuit, linear discriminant analysis, hybrid discriminant analysis, quadratic discriminant analysis, generalized discriminant analysis, flexible discriminant analysis, auto-coding, and the like.
In some implementations, the machine-learned model 300 may perform or be subject to one or more reinforcement learning techniques, such as markov decision processes, dynamic programming, Q-function or Q-learning, value function methods, deep Q-networks, microneuropathies, asynchronous dominant actor-critics (actor-critics), deterministic policy gradients, and so forth.
In some embodiments, the machine-learned model 300 may be an autoregressive model. In some instances, the autoregressive model may specify that the output data is linearly dependent on its own prior values and on a random term. In some examples, the autoregressive model may take the form of a random difference equation. An example of an autoregressive model is WaveNet, which is a generative model of the original audio.
In some embodiments, the machine-learned model 300 may include or form part of a multi-model integration. As one example, guided focusing (bagging), which may also be referred to as "bagging," may be performed. In guided focusing, a training data set is divided into a plurality of subsets (e.g., by randomly sampling with substitution), and a plurality of models are trained on the plurality of subsets, respectively. At inference time, the respective outputs of the multiple models may be combined (e.g., by averaging, voting, or other techniques) and used as an integrated output.
One example integration is a random forest, which may also be referred to as a random decision forest. Random forests are an integrated learning method for classification, regression, and other tasks. A random forest is generated by producing a plurality of decision trees when trained. In some instances, classes that are individual trees (classes) or average prediction (regression) patterns may be used as the output of a forest when reasoning. The random decision forest can correct the trend that the decision tree is over-adapted to the training set.
Another example integration technique is stacking, which in some instances may be referred to as stacking generalization. Stacking includes training the combiner model to fuse or combine predictions of several other machine-learned models. Accordingly, multiple machine-learned models (e.g., of the same or different types) may be trained based on training data. In addition, the combiner model may be trained to take predictions from other machine-learned models as input, and in response, produce a final inference or prediction. In some instances, a single-layer logistic regression model may be used as the combiner model.
Another example of an integration technique is Boosting. Boosting may include incrementally building the ensemble by iteratively training weak models, and then adding to the final strong model. For example, in some instances, each new model may be trained to emphasize training examples where previous models were misinterpreted (e.g., misclassified). For example, the weight associated with each such misinterpreted example may be increased. One common implementation of Boosting is AdaBoost, which may also be referred to as adaptive Boosting. Other example Boosting techniques include LPBoost, totalBoost, brownBoost, xgboost, madaBoost, logitBoost, gradient Boosting, and the like. Further, any of the models described above (e.g., regression models and artificial neural networks) may be combined to form an integration. As an example, the integration may include a highest level machine-learned model or heuristic function to combine and/or weight the outputs of the models that form the integration.
In some implementations, multiple machine-learned models (e.g., models that form an ensemble may be linked and jointly trained (e.g., sequentially through model integrations through back propagation of errors) — however, in some implementations, only a subset (e.g., one) of the jointly trained models is used for reasoning.
In some embodiments, the machine-learned model 300 may be used to pre-process input data for subsequent input into another model. For example, the machine-learned model 300 may perform dimension reduction techniques and embedding (e.g., matrix factorization, principal component analysis, singular value decomposition, word2vec/GLOVE, and/or related methods), clustering, and even classification and regression of downstream consumption. Many of these techniques have been discussed above and are discussed further below.
As discussed above, the machine-learned model 300 may be trained or otherwise configured to receive input data and, in response, provide output data. The input data may include different types, forms or variations of input data. As an example, in various embodiments, the input data may include features that describe content (or portions of content) that the user initially selected, e.g., content of a document or image that the user selected, a link to the user selection, a link within the user selection that relates to other files available on the device or cloud, metadata of the user selection, and so forth. Additionally, with user permission, the input data includes a context of use of the user obtained from the application itself or from other sources. Examples of usage contexts include the breadth of sharing (public sharing, or sharing with a large group, or sharing privately, or sharing with a particular person), the context of sharing, and so forth. Additional input data, when allowed by the user, may include the state of the device, e.g., the location of the device, applications running on the device, etc.
In some implementations, the machine-learned model 300 can receive and use the input data in its raw form. In some embodiments, the raw input data may be preprocessed. Thus, additionally or alternatively to raw input data, the machine-learned model 300 may receive and use pre-processed input data.
In some implementations, preprocessing the input data may include extracting one or more additional features from the raw input data. For example, feature extraction techniques may be applied to the input data to generate one or more new additional features. Example feature extraction techniques include edge detection, corner detection, blob detection, ridge detection, scale-invariant feature transforms, motion detection, optical flow, hough (Hough) transforms, and the like.
In some implementations, the extracted features may include or be derived from transformations of the input data into other domains and/or dimensions. As an example, the extracted features may comprise or be derived from a transformation of the input data into the frequency domain. For example, a wavelet transform and/or a fast fourier transform may be performed on the input data to generate additional features.
In some implementations, the extracted features can include statistics calculated from the input data or certain portions or dimensions of the input data. Example statistics include patterns, means, maxima, minima, or other measures of the input data or portions thereof.
In some embodiments, the input data may be sequential in nature, as described above. In some instances, the sequential input data may be generated by sampling or segmenting the input data stream. As one example, frames may be extracted from a video. In some embodiments, the sequential data may be made non-sequential data by aggregation.
As another example preprocessing technique, portions of the input data may be interpolated. For example, additional synthesized input data may be generated by interpolation and/or extrapolation.
As another example pre-processing technique, some or all of the input data may be scaled, normalized, generalized, and/or regularized. Examples of regularization techniques include ridge regression, least Absolute Shrinkage and Selection Operator (LASSO), elastic networks, least angle regression, cross validation, L1 regularization, L2 regularization, and the like. As one example, some or all of the input data may be normalized by subtracting the mean of the feature values for a given dimension from each individual feature value, and then dividing by the standard deviation or other metric.
As another example pre-processing technique, some or all of the input data may be quantized or discretized. In some cases, qualitative features or variables contained in the input data may be converted into quantitative features or variables. For example, a thermal encoding may be performed.
In some examples, dimension reduction techniques may be applied to the input data prior to input to the machine-learned model 300. Several examples of dimension reduction techniques are provided above, including, for example, principal component analysis, kernel principal component analysis, graph-based kernel principal component analysis, principal component regression, partial least squares regression, sammon mapping, multidimensional scaling, projection pursuit, linear discriminant analysis, hybrid discriminant analysis, quadratic discriminant analysis, generalized discriminant analysis, flexible discriminant analysis, auto-coding, and the like.
In some embodiments, during training, the input data may be intentionally deformed in any number of ways to increase model robustness, generalization, or other quality. Example techniques for distorting the input data include adding noise, altering color or shading or hue, magnification, segmentation, magnification, and the like.
In response to receiving the input data, the machine-learned model 300 may provide output data. The output data may include different types, forms, or variations of output data. As an example, in various embodiments, the output data may include content stored locally on the user device or stored in the cloud that is correlatively shared with the initial content selection.
As discussed above, in some embodiments, the output data may include various types of classification data (e.g., binary classification, multi-class classification, single-label, multi-label, discrete classification, regression classification, probabilistic classification, etc.), or may include various types of regression data (e.g., linear regression, polynomial regression, non-linear regression, simple regression, multiple regression, etc.). In other examples, the output data may include clustering data, anomaly detection data, recommendation data, or any other form of output data discussed above.
In some embodiments, the output data may affect downstream processes or decision making. As one example, in some embodiments, the output data may be interpreted and/or acted upon by a rule-based regulator.
The present disclosure provides systems and methods that include or otherwise leverage one or more machine-learned models to suggest content stored locally on a using device or stored in the cloud that is correlatively shared with an initial content selection based on characteristics of the initial content selection. Any of the different types or forms of input data described above may be combined with any of the different types or forms of machine-learned models described above to provide any of the different types or forms of output data described above.
The systems and methods of the present disclosure may be implemented by or otherwise executed on one or more computing devices. Example computing devices include user computing devices (e.g., laptop computers, desktop computers, and mobile computing devices such as tablets, smart phones, wearable computing devices, and the like), embedded computing devices (e.g., devices embedded in vehicles, cameras, image sensors, industrial machines, satellites, gaming consoles or controllers, or embedded in home appliances such as refrigerators, thermostats, power meters, home energy managers, smart home assistants, and the like), server computing devices (e.g., database servers, parameter servers, file servers, mail servers, print servers, web servers, game servers, application servers, and the like), dedicated professional model processing or training devices, virtual computing devices, other computing devices or computing infrastructures, or combinations thereof.
Fig. 7B illustrates a conceptual diagram of a computing device 310, the computing device 310 being an example of device 2 of fig. 1. The computing device 310 includes a processing component 302, a memory component 304, and a machine-learned model 300. The computing device 310 may store and implement the machine-learned model 300 locally (i.e., on the device). Thus, in some implementations, the machine-learned model 300 can be stored at and/or implemented locally by an embedded device or a user computing device, such as a mobile device. The output data obtained through the local implementation of the machine-learned model 300 at the embedded device or the user computing device may be used to improve the performance of the embedded device or the user computing device (e.g., an application implemented by the embedded device or the user computing device).
Fig. 7C illustrates a conceptual diagram of an example client computing device that may communicate over a network with an example server computing system that includes a machine-learned model. Fig. 7C includes client device 310A in communication with server device 360 over network 330. Client device 310A is an example of device 2 of fig. 1. Server device 360 stores and implements machine-learned model 300. In some instances, output data obtained by the machine-learned model 300 at the server device 360 may be used to improve other server tasks, or may be used by other non-user devices to improve services performed by or for such other non-user devices. For example, the output data may improve other downstream processing performed by the server device 360 for the user's computing device or embedded computing device. In other instances, the output data obtained by implementing the machine-learned model 300 at the server device 360 may be sent to and used by a user computing device, such as the client device 310A, an embedded computing device, or some other client device. For example, server device 360 may say that machine learning is performed as a service.
In other implementations, different respective portions of the machine-learned model 300 may be stored at and/or implemented by some combination of user computing devices, embedded computing devices, server computing devices, and the like. In other words, portions of machine-learned model 300 may be distributed in whole or in part among client device 310A and server device 360.
Devices 310A and 360 may perform graphics processing techniques or other machine learning techniques using one or more machine learning platforms, frameworks, and/or libraries, such as, for example, tensorFlow, caffe/Caffe2, thano, torch/PyTorch, mxnet, CNTK, and the like. Devices 310A and 360 may be distributed at different physical sites and connected via one or more networks, including network 330. If configured as a distributed computing device, devices 310A and 360 may operate according to a sequential computing architecture, a parallel computing architecture, or a combination thereof. In one example, the distributed computing devices may be controlled or directed through the use of a parameter server.
In some embodiments, multiple instances of the machine-learned model 300 may be parallelized to provide increased processing throughput. For example, multiple instances of the machine-learned model 300 may be parallelized on a single processing device or computing device, or across multiple processing devices or computing devices.
Each computing device implementing the machine-learned model 300 or other aspects of the disclosure may include a plurality of hardware components that enable the techniques described herein to be performed. For example, each computing device may include one or more storage devices that store some or all of the machine-learned model 300. For example, the machine-learned model 300 may be a structured numerical representation stored in memory. The one or more storage devices may also include instructions for implementing the model 300 for machine learning or for performing other operations. Example storage devices include RAM, ROM, EEPROM, EPROM, flash memory devices, disks, etc., and combinations thereof.
Each computing device may also include one or more processing devices that implement some or all of the machine-learned model 300 and/or perform other related operations. Example processing devices include one or more of the following: a Central Processing Unit (CPU), a Visual Processing Unit (VPU), a Graphics Processing Unit (GPU), a Tensor Processing Unit (TPU), a Neural Processing Unit (NPU), a neural processing engine, a core of a CPU, VPU, GPU, TPU, NPU or other processing device, an Application Specific Integrated Circuit (ASIC), a Field Programmable Gate Array (FPGA), a coprocessor, a controller, or a combination of the above processing devices. The processing device may be embedded within other hardware components, such as image sensors, accelerometers, and the like.
Hardware components (e.g., storage devices and/or processing devices) may be distributed across multiple physically distributed computing devices and/or virtually distributed computing systems.
FIG. 7D illustrates a conceptual diagram of an example computing device in communication with an example training computing system that includes a model trainer. Fig. 7D includes client device 310B in communication with training device 370 via network 330. Client device 310B is an example of device 2 of fig. 1. The machine-learned model 300 described herein may be trained at a training computing system, such as training device 370, and then provided for storage and/or implementation at one or more computing devices, such as client device 310B. For example, model trainer 372 executes locally at training device 370. However, in some examples, training device 370 including model trainer 372 may be included in or separate from client device 310B or any other computing device implementing machine-learned model 300.
In some embodiments, the machine-learned model 300 may be trained in an offline manner or an online manner. In offline training (also referred to as batch learning), the machine-learned model 300 is trained on the entire set of static training data. In online learning, the machine-learned model 300 is continuously trained (or retrained) as new training data becomes available (e.g., when the model is used to perform reasoning).
The model trainer 372 may perform centralized training of the machine-learned model 300 (e.g., based on a centrally stored data set). In other implementations, decentralized training techniques, such as distributed training, joint learning, and the like, may be used to train, update, or personalize the machine-learned model 300.
The machine-learned model 300 described herein may be trained according to one or more of a variety of different training types or techniques. For example, in some implementations, the machine-learned model 300 may be trained by the model trainer 372 using supervised learning, where the machine-learned model 300 is trained on a training dataset that includes instances or examples with labels. The tags may be applied manually by experts, generated by crowd sourcing, or provided by other techniques (e.g., physical or complex mathematical based models). In some implementations, the training examples may be provided by the user computing device if the user has provided permission. In some embodiments, this process may be referred to as personalizing the model.
Fig. 7E illustrates a conceptual diagram of a training process 390 as an example training process in which a machine-learned model 300 is trained on training data 391 that includes sample input data 392 with labels 393. The training process 390 is an example training process; other training procedures may also be used.
The training data 391 used by the training process 390 may include: when a user permits use of such data for training, anonymous usage records of the shared stream, e.g., content items shared together, bundled content segments that have been identified as belonging together, e.g., from entities in a knowledge graph, etc. In some implementations, training data 391 may include an example of input data 392 that has been assigned a label 393 corresponding to output data 394.
In some implementations, the machine-learned model 300 can be trained by optimizing an objective function, such as the objective function 395. For example, in some implementations, the objective function 395 may be or include a loss function that compares (e.g., determines a difference between) output data generated by the model from the training data and a label associated with the training data (e.g., a true value label). For example, the loss function may evaluate the sum or mean of the squared differences between the output data and the labels. In some examples, objective function 395 may be or include a cost function that describes the cost of a particular result or output data. Other examples of the objective function 395 may include marginally based techniques such as, for example, triple loss or maximum marginal training.
One or more of a variety of optimization techniques may be performed to optimize the objective function 395. For example, the optimization technique may minimize or maximize the objective function 395. Example optimization techniques include Hessian-based techniques and gradient-based techniques such as, for example, coordinate descent, gradient descent (e.g., random gradient descent), sub-gradient methods, and the like. Other optimization techniques include black box optimization techniques and heuristics.
In some implementations, the back propagation of errors can be used in conjunction with optimization techniques (e.g., gradient-based techniques) to train the machine-learned model 300 (e.g., when the machine-learned model is a multi-layer model such as an artificial neural network). For example, an iterative loop of propagation and model parameter (e.g., weight) updates may be performed to train the machine-learned model 300. Exemplary backpropagation techniques include backpropagation by time truncation, levenberg-Marquardt backpropagation, and the like.
In some embodiments, the machine-learned model 300 described herein may be trained using unsupervised learning techniques. Unsupervised learning can include reasoning about functions describing hidden structures from unlabeled data. For example, the classification or categorization may not be included in the data. Unsupervised learning techniques may be used to generate machine-learned models capable of performing clustering, anomaly detection, learning latent variable models, or other tasks.
The machine-learned model 300 may be trained using semi-supervised techniques that combine aspects of supervised learning and unsupervised learning. The machine-learned model 300 may be trained or generated by evolutionary techniques or genetic algorithms. In some implementations, the machine-learned model 300 described herein can be trained using reinforcement learning. In reinforcement learning, an agent (e.g., a model) may take action in the environment and learn to maximize rewards and/or minimize penalties resulting from such actions. Reinforcement learning differs from the supervised learning problem in that the correct input/output pair is not provided, nor is suboptimal action explicitly corrected.
In some implementations, one or more generalization techniques may be performed during training to improve the generalization of the machine-learned model 300. Generalization techniques may help reduce overfitting of the machine-learned model 300 to training data. Example generalization techniques include dropout techniques, weight decay techniques, batch normalization, early stop methods, subset selection, step-by-step selection, and the like.
In some embodiments, the machine-learned model 300 described herein may include or be affected by a number of hyper-parameters, such as, for example, a learning rate, a number of layers, a number of nodes in each layer, a number of leaves in a tree, a number of clusters, and the like. The hyper-parameters can affect the model performance. The hyper-parameters may be selected manually or may be selected automatically through application of techniques such as, for example, grid search, black-box optimization techniques (e.g., bayesian optimization, random search, etc.), gradient-based optimization, etc. Example techniques and/or tools for performing automated hyper-parameter optimization include Hyperopt, auto-WEKA, spearmint, metric Optimization Engine (MOE), and the like.
In some embodiments, various techniques may be used to optimize and/or adjust the learning rate when the model is trained. Example techniques and/or tools for performing learning rate optimization or adjustment include Adagrad, adaptive moment estimation (ADAM), adapelta, RMSprop, and the like.
In some embodiments, the migration learning technique may be used to provide an initial model from which to train the machine-learned model 300 described herein.
In some implementations, the machine-learned model 300 described herein can be included in different portions of computer readable code on a computing device. In one example, the machine-learned model 300 may be included in and used (e.g., exclusively used) by a particular application or program. Thus, in one example, a computing device may include multiple applications, and one or more of the applications may contain its own respective machine learning library and machine learned model.
In another example, the machine-learned model 300 described herein may be included in an operating system of a computing device (e.g., in a central intelligence layer of the operating system) and may be invoked or otherwise used by one or more applications interacting with the operating system. In some implementations, each application can communicate with the central smart tier (and the models stored therein) using an Application Programming Interface (API) (e.g., a common public API that is generic across all applications).
In some embodiments, a central smart inlay may communicate with a central device data inlay. The central device data layer may be a centralized repository of data for the computing devices. The central device data layer may communicate with many other components of the computing device, such as, for example, one or more sensors, a context manager, a device state component, and/or additional components. In some implementations, the central device data layer can communicate with each device component using an API (e.g., a private API).
The techniques discussed herein make reference to servers, databases, software applications, and other computer-based systems, as well as actions taken and information sent to and from such systems. The inherent flexibility of computer-based systems allows for a wide variety of possible configurations, combinations, and divisions of tasks and functionality between and among components. For example, the processes discussed herein may be implemented using a single device or component or multiple devices or components operating in combination.
Databases and applications may be implemented on a single system or may be distributed across multiple systems. The distributed components may operate sequentially or in parallel.
Additionally, the machine learning techniques described herein are readily interchangeable and combinable. While certain example techniques have been described, many other techniques exist and may be used in connection with aspects of the present disclosure.
The present disclosure has provided a brief overview of example machine-learned models and associated techniques. For additional details, the reader should look at the following references: machine Learning AProbabilistic Perspectral (Murphy); rules of Machine Learning Best Practices for ML Engineering (Zinkevich); deep Learning (Goodfellow); reinforcement Learning: an Introduction (Sutton); and artifiacial Intelligence: a model Approach (Norvig).
In addition to the above, the user may be provided with controls that allow the user to make selections as to whether and when the systems, programs, or features described herein may enable gathering user information (e.g., information about the user's social network, social actions or activities, profession, the user's preferences, or the user's current location), and whether to send content or communications from the server to the user. In addition, certain data may be processed in one or more ways before being stored or used, thereby removing personally identifiable information. For example, the identity of the user or the content to be displayed may be processed such that no personally identifiable information can be determined for the user, or the geographic location of the user may be generalized where location information is obtained (such as city, zip code, or state level), such that the user's particular location cannot be determined. Thus, the user may have control over which information about the user is collected, how the information is used, and which information is provided to the user.
Fig. 8 is a flow diagram illustrating example operations of an example controller configured to dynamically select a power converter from a plurality of power converters in accordance with one or more aspects of the present disclosure. The operation of the controller 10 is described in the context of the device 2 of fig. 1 and 3.
The controller 10 may estimate the current level of the display of the device (802). For example, the controller 10 may estimate the amount of current that will be used by the display 12 at a future time. As discussed above, controller 10 may estimate the current level based on any number of factors including one or both of the brightness setting of display 12 and the content to be displayed by display 12.
The controller 10 may select a power converter from a plurality of power converters based on the estimated current level (804). For example, controller 10 may select the power converter of power converter 20 that operates most efficiently (e.g., as compared to other power converters of power converter 20) at the estimated current level.
The controller 10 may cause electrical power from the selected power converter to be supplied to the display (806). For example, where power converter 20 is a switched-mode power converter, controller 10 may operate the selected power converter and not the other power converters of power converter 20. In examples where the device 2 includes a multiplexer (e.g., the multiplexer 8 of fig. 1), the controller 10 may output a signal that causes the multiplexer to route power from the selected power converter to the display 12.
In some examples, the controller 10 may perform one or more actions to verify the power estimate. For example, the controller 10 may determine an actual amount of power used by the display at a future time and compare the actual amount of power to the estimated amount of power. The difference between the actual amount of power used and the estimated amount of power may be referred to as an error (e.g., P error ＝P actual -P estinated ). Based on the comparison, the controller 10 may determine whether to update the model of the display. For example, if the error satisfies a threshold (e.g., if the error is greater than 10% of the estimated amount of power), the controller 10 may determine to update the model used to generate the estimated amount of power. As one example, the controller 10 may retrain the machine learning model (e.g., the ML model 604). As another example, the controller 10 may update coefficients of an analysis model such as an analysis model for predicting transmission power. In this way, the controller 10 may use feedback to improve power prediction.
The techniques described in this disclosure may be implemented at least in part in hardware, software, firmware, or any combination thereof. For example, various aspects of the described techniques may be implemented within one or more processors, including one or more microprocessors, digital Signal Processors (DSPs), application Specific Integrated Circuits (ASICs), field Programmable Gate Arrays (FPGAs), or any other equivalent integrated or discrete logic circuitry, as well as any combinations of such components. The term "processor" or "processing circuitry" may generally refer to any of the foregoing logic circuitry, alone or in combination with other logic circuitry or any other equivalent circuitry. A control unit comprising hardware may also perform one or more of the techniques of this disclosure.
Such hardware, software, and firmware may be implemented within a system device or within separate devices to support the various techniques described in this disclosure. Additionally, any of the described units, modules or components may be implemented together or separately as discrete but interoperable logic devices. The description of different features as modules or units is intended to highlight different functional aspects and does not necessarily imply that such modules or units must be implemented by separate hardware, firmware, or software components. Rather, functionality associated with one or more modules or units may be performed by separate hardware, firmware, or software components, or integrated within common or separate hardware, firmware, or software components.
The techniques described in this disclosure may also be embodied or encoded in an article of manufacture that includes a computer-readable storage medium encoded with instructions. Instructions embedded or encoded in an article of manufacture that includes an encoded computer-readable storage medium may cause one or more programmable processors or other processors to implement one or more of the techniques described herein, such as when the instructions included or encoded in the computer-readable storage medium are executed by the one or more processors. The computer-readable storage medium may include Random Access Memory (RAM), read-only memory (ROM), programmable read-only memory (PROM), erasable programmable read-only memory (EPROM), electrically erasable programmable read-only memory (EEPROM), flash memory, hard disk, compact disk ROM (CD-ROM), floppy disk, magnetic tape, magnetic media, optical media, or other computer-readable medium. In some examples, an article of manufacture may include one or more computer-readable storage media.
In some examples, the computer-readable storage medium may include a non-transitory medium. The term "non-transitory" may indicate that the storage medium is not embodied in a carrier wave or propagated signal. In some examples, a non-transitory storage medium may store data that can change over time (e.g., in RAM or cache).
Various aspects have been described in this disclosure. These and other aspects are within the scope of the appended claims.
Claims (11)
1. A method, comprising:
estimating, based on content to be displayed at a future time at a display of a mobile computing device, an amount of power to be used by the display at the future time;
selecting a power converter of a plurality of power converters of the mobile computing device based on the estimated power level, each power converter of the plurality of power converters optimized for a different output power range; and
causing electrical power from the selected power converter to be supplied to the display at the future time.
2. The method of claim 1, wherein estimating the amount of power further comprises estimating the amount of power based on a brightness setting of the display.
3. The method of claim 1 or claim 2, wherein estimating the amount of power comprises:
estimating an amount of transmit power;
estimating the amount of data power;
estimating the amount of gate drive power; and
estimating an amount of power to be used by the display at the future time based on the amount of transmit power, the amount of data power, and the amount of gate drive power.
4. The method of any of claims 1-3, wherein estimating the amount of power comprises estimating the amount of transmit power using a machine learning model.
5. The method of any of claims 1-4, wherein estimating the amount of power comprises estimating the amount of transmit power using an analytical model.
6. The method of any of claims 1-5, wherein each of the plurality of power converters is optimized for a different output power range, and wherein selecting the power converter comprises: identifying which of the plurality of power converters has an output power range that matches the estimated amount of power.
7. The method of any of claims 1 to 6, wherein estimating the amount of power comprises estimating the amount of power based on a model of the display, the method further comprising:
determining an actual amount of power to be used by the display at the future time;
comparing the actual power amount to the estimated power amount; and
determining whether to update the model of the display based on the comparison.
8. The device of any of claims 1-7, wherein the display comprises an Organic Light Emitting Diode (OLED) display.
9. An apparatus, comprising:
a display;
a plurality of power converters configured to supply electrical power to the display, each power converter optimized for a different output power range; and
circuitry configured to perform the method of any of claims 1-7.
10. A computer-readable storage medium storing instructions that, when executed, cause one or more processors of a device comprising a plurality of power converters to perform the method of any one of claims 1-7.
11. An apparatus, comprising:
a plurality of power converters configured to supply electrical power to a display, each power converter optimized for a different output load current range, wherein each of the plurality of power converters comprises a respective set of ELVDD and ELVSS power converters;
apparatus for performing the method of any one of claims 1 to 7.
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/US2020/041613 WO2022010490A1 (en) | 2020-07-10 | 2020-07-10 | Dynamic power converter switching for displays based on predicted power usage |
Publications (1)
Publication Number | Publication Date |
---|---|
CN115699149A true CN115699149A (en) | 2023-02-03 |
Family
ID=71995057
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202080102053.8A Pending CN115699149A (en) | 2020-07-10 | 2020-07-10 | Dynamic power converter switching for displays based on predicted power usage |
Country Status (4)
Country | Link |
---|---|
US (1) | US11955076B2 (en) |
EP (1) | EP4147225A1 (en) |
CN (1) | CN115699149A (en) |
WO (1) | WO2022010490A1 (en) |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN117728583A (en) * | 2023-12-27 | 2024-03-19 | 中节能甘肃武威太阳能发电有限公司 | Distributed photovoltaic cluster energy control monitoring system based on transfer learning |
Families Citing this family (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
KR20230019352A (en) * | 2021-07-30 | 2023-02-08 | 삼성디스플레이 주식회사 | Display apparatus |
Family Cites Families (8)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
KR100894606B1 (en) * | 2007-10-29 | 2009-04-24 | 삼성모바일디스플레이주식회사 | Organic lighting emitting display and supply power method thereof |
US9824615B2 (en) * | 2015-06-07 | 2017-11-21 | Apple Inc. | Load adaptive power management for a display panel |
US10234926B2 (en) | 2015-06-16 | 2019-03-19 | Dell Products, Lp | Method and apparatus for customized energy policy based on energy demand estimation for client systems |
KR102298224B1 (en) | 2015-07-16 | 2021-09-08 | 삼성디스플레이 주식회사 | Backlight unit and display apparatus having the same |
KR102455054B1 (en) | 2015-12-17 | 2022-10-13 | 엘지디스플레이 주식회사 | Gate driving circuit and display device using the same |
US11924290B2 (en) * | 2018-10-26 | 2024-03-05 | Dell Products, Lp | Aggregated stochastic method for predictive system response |
US11183150B2 (en) * | 2019-01-04 | 2021-11-23 | Ati Technologies Ulc | Foveated illumination control at display device |
US11127357B2 (en) * | 2019-04-19 | 2021-09-21 | Apple Inc. | Display pixel luminance stabilization systems and methods |
-
2020
- 2020-07-10 EP EP20753515.4A patent/EP4147225A1/en active Pending
- 2020-07-10 US US17/756,319 patent/US11955076B2/en active Active
- 2020-07-10 CN CN202080102053.8A patent/CN115699149A/en active Pending
- 2020-07-10 WO PCT/US2020/041613 patent/WO2022010490A1/en unknown
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN117728583A (en) * | 2023-12-27 | 2024-03-19 | 中节能甘肃武威太阳能发电有限公司 | Distributed photovoltaic cluster energy control monitoring system based on transfer learning |
Also Published As
Publication number | Publication date |
---|---|
WO2022010490A1 (en) | 2022-01-13 |
US11955076B2 (en) | 2024-04-09 |
US20220415256A1 (en) | 2022-12-29 |
EP4147225A1 (en) | 2023-03-15 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN111680721A (en) | Accurate and interpretable classification with hard attention | |
US11955076B2 (en) | Dynamic power converter switching for displays based on predicted power usage | |
Raman et al. | Predicting Delivery Time of Components in a Supply Chain | |
Yessou | Analysis of deep learning loss functions for multi-label remote sensing image classification | |
Price et al. | Configuring Alarm Setting Using Machine Learning | |
Chai et al. | Item recommendations for cache and synchronization of application stores | |
Salazar | Legal Precedent Mining with Machine Learning | |
Price et al. | Machine Learning to Select Screen Brightness Level | |
Armstrong | Using Imagery of Property Improvements to Direct Marketing | |
Liu et al. | Allocating System Resources in Display of Advertisements | |
Feuz et al. | Ranking and automatic selection of machine learning models Abstract | |
Membrives | Machine-Learned Caching of Datasets | |
Price et al. | Machine Learning to Disable Applications from Using Background Resources Except at Appropriate Times | |
Gibson et al. | Anticipatory Product Development Using Design Suggestions | |
Price et al. | Machine Learning to Automatically Lock Device Screen at Opportune Time | |
Luo et al. | Training High Quality Spam-detection Models Using Weak Labels | |
Armstrong | Discovering Employment Listings from Imagery | |
Garrett | Machine Learning to Predict Advertisement Targeting Solutions | |
Wang et al. | Intelligent Ordering of Repeated Fields | |
Price | Predicting Computing Prices Dynamically Using Machine Learning | |
Hong | Generating Icons for Applications in an Applications Marketplace | |
Schpok | Stylizing Map Based on Examples of Representative Styling | |
Felker | Planning Group Meals Based on Preferences of Attendees | |
Dhillon et al. | Determining Priority Value of Processes Based on Usage History | |
Armstrong | Using Imagery of Vegetation and Rooftops to Predict Solar Roof Candidacy |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |