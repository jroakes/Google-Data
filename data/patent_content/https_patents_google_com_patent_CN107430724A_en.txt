CN107430724A - Activity-triggered - Google Patents
Activity-triggered Download PDFInfo
- Publication number
- CN107430724A CN107430724A CN201680018932.6A CN201680018932A CN107430724A CN 107430724 A CN107430724 A CN 107430724A CN 201680018932 A CN201680018932 A CN 201680018932A CN 107430724 A CN107430724 A CN 107430724A
- Authority
- CN
- China
- Prior art keywords
- user
- activity
- action
- condition
- triggered
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q10/00—Administration; Management
- G06Q10/10—Office automation; Time management
- G06Q10/109—Time management, e.g. calendars, reminders, meetings or time accounting
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0484—Interaction techniques based on graphical user interfaces [GUI] for the control of specific functions or operations, e.g. selecting or manipulating an object, an image or a displayed text element, setting a parameter value or selecting a range
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0481—Interaction techniques based on graphical user interfaces [GUI] based on specific properties of the displayed interaction object or a metaphor-based environment, e.g. interaction with desktop elements like windows or icons, or assisted by a cursor's changing behaviour or appearance
- G06F3/0482—Interaction with lists of selectable items, e.g. menus
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0484—Interaction techniques based on graphical user interfaces [GUI] for the control of specific functions or operations, e.g. selecting or manipulating an object, an image or a displayed text element, setting a parameter value or selecting a range
- G06F3/04842—Selection of displayed objects or displayed text elements
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/16—Sound input; Sound output
- G06F3/167—Audio in a user interface, e.g. using voice commands for navigating, audio feedback
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/44—Arrangements for executing specific programs
- G06F9/445—Program loading or initiating
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/46—Multiprogramming arrangements
- G06F9/54—Interprogram communication
- G06F9/542—Event management; Broadcasting; Multicasting; Notifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04M—TELEPHONIC COMMUNICATION
- H04M2250/00—Details of telephonic subscriber devices
- H04M2250/12—Details of telephonic subscriber devices including a sensor for measuring a physical value, e.g. temperature or motion
Abstract
Method, system and the equipment of action and triggered activity are defined for action item, user, is included in the computer program encoded on computer-readable storage medium.In an aspect, a kind of method includes：The input of action is defined in user device reception user, user's definition action includes multiple lexical items；The selection that triggered activity is defined to user is received by the user's set, the triggered activity indicates to define the movable user behavior of action for triggering this to be presented user；Determine at least one environmental condition for the environment that the user's set is located at；The movable user behavior indicated by the triggered activity is determined based on user profile and at least one environmental condition；And the notice that the user defines action is presented to the user's set of the user by the user's set.
Description
Technical field
The present invention relates to data processing and delivery of notifications, and specifically but not exclusively relate to processing with action item, use
Family, which defines, acts the data related to triggered activity.
Background technology
Expand significantly between service, search engine and the decade of appearing in over of other services and media based on cloud
The practicality of user's set is opened up.Many user's sets of especially mobile device and smart phone there is presently provided except voice and
Service and application outside data access.In addition, with the nearest progress in terms of processing system, many users now want to utilize
Its user's set smoothness and intuitively Consumer's Experience.
These many application services that can be widely-available for users are instantiated by using order input.Clothes as one
Business is the setting of action (for example, prompting).For example, user can say input [reminding me to buy milk tonight] (or key entry)
Into smart mobile phone, and the smart mobile phone (or alternatively, is led to using command analysis application with command analysis service
Letter) it will call the action process of additional information can be implored from user.Such information can it is expected when specific in user
Between be alerted in the case of include the time, and/or wrapped in the case of being alerted when user it is expected in user in-position
Include position.Although the setting of such action is highly useful and is relatively smooth Consumer's Experience, user usually forgets
The thing that they feel like doing is done, because they can not need inside to set can complete the scene of task on hand based on them
Put prompting.
The content of the invention
In general, a novel aspects of the theme described in this manual can be carried out with a kind of method,
This method includes following action：The input of action is defined in user device reception user, user's definition action includes multiple
Lexical item；The selection that triggered activity is defined to user is received by the user's set, the triggered activity indicates that being used for triggering will be presented
The user define the movable user behavior of action；Determine at least one environment bar for the environment that the user's set is located at
Part；The movable user's row indicated by the triggered activity is determined based on user profile and at least one environmental condition
For；And the notice that the user defines action is presented to the user's set of the user by the user's set.This respect its
Its embodiment includes corresponding system, equipment and computer program, and the computer program is configured to perform being somebody's turn to do for this method
Action, is coded on Computer Memory Unit.
The particular implementation of the theme described in this specification can be realized, so as to realize one in advantages below or
It is multiple.
The data for specifying the prompting for performing particular task can be inputted in an efficient way according to straightforward format, so as to
Express daily routines rather than require to specify the complex process of series of parameters, this facilitate the configuration of prompting.Therefore this can
Reducing user must be with its device, equipment or system interaction, the time reminded so as to configuration provides.This can reduce the dress of user
The display put is the total time of activity, and therefore, it is possible to reduce electricity usage.In the scene of mobile device, this can be with
Save battery electric power and can help to reduce the frequency that battery needs to charge.In addition to reducing electricity usage, retouch herein
The method, apparatus and system stated reduce the workload on the user interface components of device, and are also used as reducing user
Cognitive load.
What situation may also is that, i.e., because the routine work of user changes, preassigned time or position
It may become unsuitable for reminding, and so can be by avoiding the storage of potential redundant data, and even if the routine work
Change, also store and specify the data for probably maintaining the triggering related to the routine work of user to increase the effective of the present invention
Property.Such benefit improves flexibility and the reliability of alert notification.The inevitable benefit so done is, it is possible to reduce to configuration
And store multiple promptings and be used as the needs of safeguard measure in the case of loss to be reminded first due to specifying parameter inappropriate.
By determining the behavior of activity based on environmental condition, the movable behavior can be identified exactly, this is also improved
The reliability of alert notification.
The embodiment for the theme being described below allows directly perceived when establishment acts and is notified action (for example, prompting)
And more accurately Consumer's Experience.They are wanted by user when being provided with user's definition action (seeming to remind) to them
The selection of the one or more activity of execution allows user more likely to have time, resource or other means at them
Complete during user definition action customized task and to their reminding tasks.
For example, if user selects user's definition of [buying fruit juice] to act when they [drive], user be
In their vehicle, produced in their vehicle when they can go out at them and arrive shop stroke.In most cases
This will make user from being necessary for specifying special time or search ad-hoc location for activity-triggered.Which reduce necessary use
Family will keep specific schedule, and can the presence of system determination activity cause they will more likely have the time,
When resource or other means define the user behavior of action to complete user, flexibly complete to carry to user at reasonable time again
Acted for user's definition.
The one or more embodiments of the detail of the theme described in this specification are elaborated in the following drawings and description.
The further feature, aspect and advantage of this theme will become apparent according to this specification, drawings and claims.
Brief description of the drawings
Fig. 1 is that the block diagram for acting the example context that order input is handled with activity-triggered is wherein defined for user.
Fig. 2 is the stream for defining the instantiation procedure of action for creating and being notified user when it is determined that to perform triggered activity
Cheng Tu.
Fig. 3 A are in user device, wherein create the diagram that user defines the user interface of action.
Fig. 3 B are to create the user device of action limitation by being selected in the region of action limitation in wherein user
User interface diagram.
Fig. 3 C are the diagrams of the user interface for the user device for providing triggered activity list wherein.
Fig. 3 D are the diagrams of the user interface for the user device that triggered activity is presented in the case where user defines action wherein.
Fig. 4 A are the diagrams of the user interface of the user device of the condition of establishment activity wherein.
Fig. 4 B be wherein activity condition be added to action item user device user interface diagram.
Fig. 5 is the diagram of the user interface for the user device for providing the list that user defines action wherein.
Fig. 6 is the stream for determining the instantiation procedure of at least one environmental condition based on the environment at different time sections
Cheng Tu.
Fig. 7 has been used to determine the user behavior of triggered activity and has used confidence score and confidence score threshold value
The flow chart of instantiation procedure.
Fig. 8 is the block diagram of example mobile computing device.
Identical reference and label instruction identical element in various figures.
Embodiment
Processing system is acted to promote to create user's definition action and triggered activity.In operation, the action processing system from
User receives the input for the set for describing the lexical item that user defines action.User can select one or more triggered activities, should
One or more triggered activity instructions will trigger the activity that the user to be presented to user defines action from user behavior.It is additional
Ground, user can select one or more activity conditions, and one or more activity condition instructions will be it is determined that user's executed
The condition met in the activity indicated by triggered activity.For example, user can be in the triggered activity feelings of " walking (Walking) "
User's definition action of " phoning Larry (Call Larry) " is selected under condition.User's definition action will not be triggered
To be presented on a user device to user, until the action processing system determines user at " walking (Walking) ".In addition,
In some embodiments, activity-triggered can be included to trigger the additional contextual information that user defines action.For example, it is based on
Exemplified earlier, activity-triggered may include walking to locality (for example, walking home or walk to grocery store).Based under
Environmental condition, user's history and the user situation that face further describes, the action processing system are able to determine whether existing work
The user behavior of dynamic triggering.
Additionally, based on above exemplified earlier, user can create the activity for also needing to meet in addition to satisfaction activity
Condition.Example activities condition is probably the period of " Saturday afternoon (Saturday afternoon) ".Therefore, based on including
Activity condition, user's definition action will not be triggered to be presented to user, until action processing system determines user in " star
Afternoon phase six (Saturday afternoon) " " walking (Walking) ".
In order to determine whether there is the user behavior of triggered activity, action processing system being capable of such as user based on user
Device assesses at least one environmental condition of user.The environmental condition can be by related to user's set or action processing system
The sensor of connection is analyzed, and can include such as sensor to monitor mobile and speed, wind speed, light and light variability, temperature
Degree, humidity, height, noise level and noise change etc..
Additionally, the action processing system can analyze user profile to determine the user behavior of triggered activity.As herein
Used in, user profile is used in conjunction with the environmental data of sensing to determine the user behavior of triggered activity
Information.User profile is the information collected or received from the source in addition to the sensor of generation sensing data.For example, user
Information can include the user's history for including past user data.For example, user's history can include it is related to user's set
Prior actions, activity and the position of the user of connection.
In addition, user profile can include the user situation of instruction current-user data, the current-user data can be with
The calendar on user's set and/or another device of user of position and user including weather and user's set.For example,
If the weather data instruction temperature of the weather service from the position for user's set is 50 degree of Fahrenheit and is used to determine
The sensor instruction temperature of environmental condition around user's set is 72 degrees Fahrenheits, then this user can be used by acting processing system
Information and sensing data are come to determine the user's set 106 of user be indoors.
The action processing system can be implemented in user's set or in the computer system separated with user's set
In (such as server system).In the latter case, server system receives input and to user's set from user's set
Data are sent, with processing and set action item.These features and supplementary features are further described in more detail below.
Fig. 1 be wherein for action item, user define action and triggered activity handle order input environment 100 frame
Figure.Computer network 102 (such as internet) or its combination provide the data being used between electronic installation and system and communicated.Calculate
Machine network 102 can also include one or more wireless networks 103, or by means of one or more gateways and one or more
Wireless network 103 enters row data communication.
User's set 106 be under control of the user and can ask and receive by network 102 resource, with other use
Family device establishes communication channel (for example, voice communication) and can also perform the electronic installation of other actions.Example user fills
Putting 106 includes that the personal computer of data, mobile communications device and other devices can be sent and received by network 102.
In the example of fig. 1, user's set 106 is smart phone.Example smart phone is described below with reference to Fig. 8.User
Device 106 can communicate by means of the wired and wireless connection with network 102 and 103, by network 102 and 103.Such as reference chart
Described by 8, user's set can be able to be the set of various programs and ability and performs device action.
User's set 106 and user account (such as by the account for the trustship of cloud service provider 112 for providing multiple services)
It is associated.These services can include web mails, social networks, messaging, document storage and editor, electronic assistant service
Deng.Account data 114 can store the data of the account specific to user's set 106.In addition, although it illustrate only in Fig. 1
One user's set 106, but multiple user's sets 106 can be included.
Action processing system 120 receives the order from user's set and inputs and handle the input, to determine those
(if yes) action will be taken in response to the input.Although processing system 120 is acted in Fig. 1 by as single
Entity and show, but can in cloud service provider 112 or even in user's set 106 realization act processing system
120。
Input can call the various actions such as determined by action processing system 120.For example, input can be interpreted to search
Rope querying command, in the case search inquiry be sent to search service.Similarly, input can be interpreted to initiate phone
The order of calling, in the case user's set 106 attempt to establish voice communication by network 103.Similarly, input can be by
User's definition action is construed to, the action item that action is defined with user can be generated in the case.It is dynamic to generating below
Make item, user's definition acts and handles this category and is described in more detail.
In some embodiments, each input is handled by input resolver 122, and the input resolver 122 is programmed
To be parsed to the lexical item inputted and it is determined that taking what action (if yes).In some embodiments,
Input resolver 122 can with access language model with determine to take those order or action.This class language model can be base
In statistics, for example, model can include being assigned to being confirmed as the certain words semantically related with particular command and phrase
Weight, it is or rule-based, such as describe the grammer of the sentence structure for particular command.It can use various other
Language and text input processing system.
As described above, user can input order on user's set 106, and act the processing order of processing system 120
Input to determine whether order input is decomposed into the user's set action that user's set is configured to perform.For this document
Remainder, the input of processed example will be decomposed into the input based on operation.Therefore, omit for other order input classes
The description of other command process features of type.
In some embodiments, acting processing system 120 includes handling with the action that input resolver 122 is communicated
Device 124.Action processor 124 also accesses action data 126 and user profile data 128.Action processor 124 can receive
User on user's set 106, being set by the user defines user's input of action.User's definition action can be for example will be
The prompting presented on user's set to user or the action that can be completed.User's definition action can include multiple lexical items, and
Can be such as " phoning Larry (Call Larry) ", " carwash (Wash Car) ", " housecleaner (Clean the
) " or any other action House.Action processor 124 will be directed to specific remind and user's definition action is stored in into action number
In 126.Can be stored with action data 126 multiple action item AI1, AI2 ... AIn, and the multiple action item
In can each have the one or more user's definition defined for the action item act A1, A2 ....
Additionally, can each have the one or more triggerings associated with the action item in the multiple action item
Movable TA1, TA2 ... TAn.Triggered activity can indicate to define movable user's row of action for triggering the user to be presented
For.The user that the user behavior of activity can include prediction user's set 106 will perform triggered activity, user's set 106
User is carrying out triggered activity, and/or the user of user's set 106 has performed triggered activity.As being discussed below
It is that user's history and user situation can be used in determining and analyze when the user behavior that action be present (includes the row in future
For).
Triggered activity can be body movement or situation activity.Body movement is can be directly from environmental sensor data
The activity of (including position data, voice data, accelerometer data) sensing.Additionally, activity can be based on being handled by action
The reasoning that system 120 generates, the action processing system 120 can be incorporated by the information that environmental sensor data senses,
The activity performed with reasoning by the user of user's set 106.Example includes walking, drives, rides a bicycle, running, swimming.Feelings
Border activity is other data reasonings that can be from environmental sensor data and when it is instruction activity to be combined with environmental data
Activity.Example includes reading, sees TV, culinary art, sleep etc..In some embodiments, more than one activity can be selected.Make
For example, user can select triggered activity as " reading (reading) " and " sleep (in bed) ".If however, user
More than one activity can be selected, then action processor 124 can prevent two or more that user's selection can not be done simultaneously
Individual activity (for example, " swimming (Swimming) " and " culinary art (cooking) ")；However, such configure what is be not required, and
In some embodiments, user can provide the sequence for the triggered activity to be performed before providing user and defining action.
In some embodiments, triggered activity can be selected from the list for be supplied to user.
Additionally, in some embodiments, user can provide one or more triggered activities with each action item
With user define the associated activity condition Ac1, Ac2 of action ... Acn.Can be that one or more action items set multiple classes
The activity condition of type.Activity condition is also specified in addition to the activity will be it is determined that the movable user indicated by triggered activity
The condition met in behavior.Connect for example, activity condition can be one or more period conditions, band of position condition or people
Nearly condition etc..Period condition can be date, date range, moment or moment scope etc..For example, AI1 can include " beating
Phone gives Larry (Call Larry) " user's definition action (A1) and " walking (Walking) " triggered activity (TA1), and
And user can also include the activity condition (Ac1) of " Saturday afternoon (Saturday afternoon) ", its can be on
Specific Saturday (for example, next Saturday), each Saturday, selected Saturday or Saturday pattern (for example,
First Saturday monthly) acquiescence or user setting time range (for example, 1PM-5PM).Based on this of action item AI1
Example, unless determine such as by activity condition Ac1 define in " Saturday afternoon (Saturday afternoon) " " walking
(Walking) user behavior of triggered activity (TA1) ", it otherwise will not trigger user's definition action and " phone Larry
(Call Larry)”(A1).Additionally, be as previously described, activity-triggered relative to activity can be particularly, and
Activity-triggered can include the scene (for example, being walked home from workplace) of the more type multiple-situation for the activity.
Band of position condition can be region around ad-hoc location (for example, house address) or user's set for will
The type (for example, grocery store, airport, hospital) of position close to or within being in for the activity condition of satisfaction.For example, position
It can be " near grocery store (Near Grocery Store) " to put area condition, and it can be defined as specific grocery store or appoint
What grocery store.Additionally, " near (Near) " can be by different travel pattern (for example, by automobile, public transport,
Walking) specific range (for example, foot or mile) or time quantum that are left from the position identified.Therefore, if user defines
Action is set to " buying groceries (Buy Groceries) " and triggered activity is set to " driving (Driving) ", then user
The additional conditions in " near grocery store (Near Grocery Store) " can be selected.If when user near grocery store (
Present exemplary includes user and driven near grocery store) when action processor 124 determine triggered activity be triggered and meet
Activity condition, then user's set then will inform the user user's definition action " buying groceries (Buy Groceries) ".Phase
Instead, if user runs away and is near grocery store, user will not be reminded to buy groceries, because user very will may be used
The remainder that can be run for user is not desired to carry groceries.
Additionally, activity condition can be people close to condition.If the user's set 106 of user is from particular person or colony
The user's set of mark can then meet people close to condition in certain distance.In some embodiments, user's set 106
It can be provided or user can adjust the distance by action processor 124 from a distance from the user's set of mark.Separately
Outside, in some embodiments, to allow action processor 124 to identify particular person or the user's set of colony, user's set 106 can
Can need, which includes the particular person or colony, identifies the people or colony as contact person or otherwise.However, in other realities
Apply in mode, action processor 124 can be identified for that the particular person around user's set 106 and the user's set of colony.For example, with
Family can create user's definition action including " discussing vacation (Discuss vacation) ", " have supper (eating
Dinner the action item of triggered activity) " and the people of " David (David) " close to condition.When action processor 124 determines to use
Family " culinary art (cooking) " and user's set 106 and then is notifying user " to beg for when together with " David (David) "
By vacation (Discuss vacation) ".Additionally, user can also include period condition and/or band of position condition.
User's set 106 can determine the environmental condition of the wherein environment that user's set is located at, and according to being sensed
Data, can determine whether some activities are being performed.In some embodiments, user's set 106 can include can
Assess the sensor 108 of surrounding environment.For example, sensor 108 can monitor mobile and speed (for example, using accelerometer), wind
Fast, light and light variability, temperature, humidity, height, noise level and noise change etc..Sensor 108 can be in user's set
In 106 inside and/or on the outside of user's set 106, and sensor 108 will can be sensed by sensor 108
Data are sent to user's set 106 and/or action processor 124.Sensor 108 can constantly or periodically monitor user
The surrounding environment of device 106.
It can be carried out based on the individual data detection carried out by sensor 108 and/or by sensor 108 in different time
Data Detection assess surrounding environment.For example, if sensor 108 detects the situation that and temperature bright in illumination is 70 degree
Under with the movement of the user's set 106 of 7 miles per hour travelings, then sensor 108 can provide user's set 106 and/or dynamic
The data that device 124 detects are dealt with, to assess the environmental condition of the user associated with the user's set.For provided above
Environmental condition, user's set 106 and action processor 124 can use this information to and user profile, with determine for example with
The associated user of user's set 106 just runs out of doors.In some embodiments, environmental condition can be by action processing system
The component of system 120 can detect environmental condition and be communicated with action processing system 120 or user's set 106 any other
Device or component determine.For example, in some embodiments, sensor 108, which can be included in, can sense and determine to use
In the information at family and the different components of activity.
Additionally, as previously mentioned, simultaneously detection data of the combination sensor 108 at different time can be used, with
Determine the environmental condition of user's set 106.For example, at the very first time, sensor 108 can detect the user's dress not moved
Put 106, high-caliber artificial light and low noise level.At the second time (for example, after the first time ten minutes) place,
Sensor 108 can detect the user's set 106 not moved, low-level artificial light and high noise levels.It will can come from
This sensing data of different time is supplied to user's set 106 and/or action processor 124, to determine and user's set 106
The environmental condition of associated user.Based on above example, user's set 106 and/or action processor 124 can be determined
The environmental condition of the user's set of between one time and the second time including fixed user's set 106, and in artificial illumination
With variability in noise level be present.For environmental condition provided above, user's set 106 and/or the energy of action processor 124
Enough use this information to and user profile, TV is seen with the user for determining for example associated with user's set 106.
Can be according to the user profile data 128 associated with user, user's set 106 or can also be with user profile number
The other information (for example, position, weather, calendar) being included according to 128 and/or user's set 106 determines and user's set
The user profile of 106 associated users.User profile can be determined according to user's history and user situation.
For example, user's history can include the prior actions for the description user associated with user's set 106, activity
With the data of position.User history information can be used by action processor 124, associated with user's set 106 to determine
Interest, preference, schedule and the pattern of user.If for example, user after many occasions are waken up in about 30 minutes with
The walking of user's set 106, then action processor 124 can its triggered activity analysis in use the pattern information.Therefore, if
Triggered activity be, for example, " walking (Walking) " and analysis time be that in the morning, then action processor 124 can be user's mould
Whether formula contributes to as factor determines user at that time just with the analysis of the walking of user's set 106.User's history may be used also
With the action that has been performed on user's set 106 including user and/or the movable level applied for user's set 106 and
The time of application is used on user's set 106.Additionally, other information can be obtained from user's history and be included in use
In the history of family.
User situation includes current-user data, and the current-user data can include the position of weather and user's set 106
Put, and the calendar on user's set 106 and/or another device of user of user.If for example, user's set 106
Weather instruction temperature in position is 50 degree of Fahrenheit and the sensor for determining the environmental condition around user's set 106
108 instruction temperature are 72 degrees Fahrenheits, then action processor 124 can use the information, to determine that the user's set 106 of user exists
It is indoor.Additionally, user situation can include user just user's set 106 and/or on user's set 106 open or just
The action using upper execution used.
User situation can include the data of the content (for example, recipe) in such as browser of instruction user device 106,
Or user situation can indicate that reading is applied and is opened in user's set 106.Furthermore, it is possible to it is determined that using currently with
Made a distinction when in the viewport of family device 106 or in the backstage of the viewport of user's set 106 in terms of user situation.Example
Such as, if user situation includes user's set 106 and opens webpage, user situation in the viewport of user's set 106 with recipe
This user profile can be supplied to action processor 124, to perform triggered activity analysis.Based on exemplified earlier, if triggering
Activity is " culinary art (cooking) ", then action processor 124 can include being used to determine the use associated with user's set 106
Whether family has triggered the user profile and environmental condition of triggered activity.In addition, user's history and user situation can be used for really
Surely it whether there is the user behavior of triggered activity, and can be based on the current user action and use detected by sensor 108
The past activity of family scene and user's history makes inferences with action.
In addition, in some embodiments, in order to determine whether or not there have been the user behavior of triggered activity, it may be determined that put
Confidence score, to indicate confidence level that triggered activity has been performed.For example, when user situation include user's set 106 with
" it can be cooked by action processor 124 when opening (or positive opening) webpage in the viewport of family device 106 with recipe
(cooking) triggered activity " determines confidence score.If user's calendar instruction such as user on user's set 106 exists
It is arranged to share a supper with " Larry " at this special time, then can determines higher confidence score.If in addition, with
" Larry " related people is included in action item close to condition, and action processor 124 determines user's dress of " Larry "
Put in the user's set 106 associated with user close in scope, then may determine the confidence score of even more high.Separately
Outside, in some embodiments, in order to determine the user behavior of triggered activity, threshold value can be defined by action processor 124 and put
Confidence score, the threshold confidence scoring can be adjusted or changed by the user of action processor 124 or user's set.
Fig. 2 is the example for defining action for creating and being notified user when the user behavior of triggered activity has occurred and that
The flow chart of process 200.Process 200 can be realized for example by user's set 106 and/or action processor 124.In some realities
To apply in mode, the operation of instantiation procedure 200 can be implemented as the instruction stored in non-transitory computer-readable medium, its
Middle instruction makes the operation of data processing equipment execution example process 200.
The input (202) that user defines action is received at user's set 106.Action processor 124 can receive with
The user being set by the user on family device 106 defines user's input of action.It is user in triggered activity that user, which defines action,
The thing for being alerted or performing is wanted when user behavior is determined.User's definition action can be reminded and can include more
Individual lexical item, and can be that such as user wants to be alerted or performs " phoning Larry (Call Larry) ", " washes
Car (Wash Car) ", " housecleaner (Clean the House) ", or any other task.Action processor 124 will
User's definition action is stored in action data 126 for specific action item.
The selection (204) that triggered activity is defined to user is received at user's set 106.Triggered activity instruction will be by user
It is performing, to trigger the activity that user defines action.Triggered activity can be body movement or situation activity.In some embodiment party
In formula, more than one activity can be selected.
In some embodiments, can at user's set 106 selection activity condition (206).The instruction of activity condition will
It is determined that user has performed the condition that meets in the activity indicated by triggered activity.For example, activity condition is as described previously
As can be one or more period conditions, band of position condition or people close to condition.
It is determined that the wherein environmental condition (208) for the environment that user's set is located at.In some embodiments, user's set
106 can include that the sensor 108 of surrounding environment can be assessed.For example, sensor 108 can monitor mobile and speed (for example,
Use accelerometer), wind speed, light and light variability, temperature, humidity, height, noise level and noise change etc..Can be based on by
Individual data detection that sensor 108 is carried out and/or the Data Detection that is carried out by sensor 108 at different time assess week
Collarette border.In some embodiments, environmental condition can be supplied to action processor 124.
Next, this method determines whether or not there have been what is indicated by triggered activity based on user profile and environmental condition
The user behavior (210) of activity.It is determined that in the analysis whether triggered activity has been performed, user profile can be included, it is described
User profile can be from the user profile data 128 associated with user, user's set 106 or acceptable and user profile
The other information (for example, position, weather, calendar) that data 128 and/or user's set 106 are included obtains.Being capable of basis
User's history and user situation determine user profile.Additionally, movable user behavior can include prediction user's set 106
User will perform triggered activity, the user of user's set 106 is carrying out the user of triggered activity, and/or user's set 106
Triggered activity is performed.
User's history can include past user data.For example, user's history can include it is related to user's set 106
Connection for the prior actions of user, activity and position.User history information can be used by action processor 124, to determine
Interest, preference, schedule and the pattern of the user associated with user's set 106.Additionally, can be obtained simultaneously from user's history
Include other information in user's history.
In addition, user situation can be included in user profile.User situation includes current-user data, the current use
User data can include the position of weather and user's set 106, and user in the another of user's set 106 and/or user
Calendar on device.Additionally, user situation can include user just on user's set 106 and/or on user's set 106
The action using upper execution opened or be being used.User situation can include browsing for such as instruction user device 106
The data of content (for example, recipe) in device, or user situation can indicate that reading is applied and be beaten in user's set 106
Open.
It is determined that after the user behavior of triggered activity, user can be defined into action to user's as described below
User's set 106 is presented (212).User, which defines action, can also have the alarm associated with notice.Additionally, in some realities
Apply in mode, user's set 106 or action processing system 120 can perform user's definition action.For example, if user's definition is dynamic
Work is " open air-conditioning (Turn on air conditioner) " and triggered activity is that " drive (driving that goes home
home)”.When the user behavior of " drive go home (driving home) " is determined, user's set 106 or action processing system
120 can perform the action for opening air-conditioning.User's definition can be acted and be presented to user, for selecting with triggered activity
User's definition action is completed when user behavior is determined, or in other embodiments, user's definition can be automatically carried out
Action.Additionally, user's history is determined for the temperature for being set to air-conditioning.
If user's definition action is performed by user's set 106 or action processing system 120, can be to user's set
106 user presentation user defines the notice that action has been performed.However, if triggered activity is not yet performed, process can
To continue executing with step 210.In addition, in some embodiments, the presentation that user can be defined to action is supplied to except user
Device beyond device 106.For example, can by present be supplied to be confirmed as close to user device or user will be appreciated that or
The device that person is just seeing.For example, if the user's set 106 of user is currently invisible to user, but user check it is another
Device, then acting processing system 120 can determine to define user into the device for acting and being presented to user and checking.
Process 200 can be confirmed by user, and be also described in Fig. 3 A-3D scene.Especially, Fig. 3 A are
The diagram that user defines the user interface 302a of action is created at user's set 300.Input field 304 is acted in user's definition
Place, user can key in user's definition action that the user when the user behavior of triggered activity is determined wants to be presented with.
In Fig. 3 A, user's definition action is during being input into user's definition action input field 304.In current subscriber device
On 300, user can use the touch-screen of user's set 300, define the lexical item and character of action for user with typing.So
And what such configuration was not required, and other methods and subscriber device type can be used for inputting character and lexical item.
In figure 3b, there is provided user interface 302b, wherein have input use in user's definition acts input field
Family definition action, and user can create action limitation by being selected in the region 306 of action limitation.Limited in action
After being selected in the region 306 of system, user is presented with limited option, when the limited option includes in the present embodiment
Between section condition 306a, band of position condition 306b, people close to condition 306c, triggered activity 306d and World Affairs option 306e.
However, what such limited option was not required, and different and/or more or less limited options can be provided.
In addition, in fig. 3 c, there is provided user interface 302c, can be with wherein after user selects triggered activity 306d
Triggered activity list 308d is provided.In the present embodiment, triggered activity list 308d includes the figure for each activity
Represent and indicate the movable text.For example, triggered activity list 308d includes " driving (Driving) ", " cycling
(Biking) ", " walking (Walking) ", " seeing TV (Watching TV) " activity, and can be as user is in user
Scroll down through in triggered activity list 308d on device 300 and other activities are provided.However, such triggered activity list
What 308d was not required, and the different types of list for including different movable and different tabular layouts can be provided.
In fig. 3d, there is provided user interface 302d, wherein have selected the triggered activity of " walking (Walking) " in user
Afterwards, action limitation 306 be included in user define action input field 304 in user's definition action " phone Larry
The triggered activities " walking (Walking) " of (Call Larry) " below.Additionally, user such as can will limit 306 by acting
In addition action limited option 309 see additional move limitation be added to " adding another (Add another) ".User
Can for example, by selection save options 310 come indicate action item be complete, or can provide other options be used for complete
Action item.
As seen in Fig. 4 A, there is provided user interface 402a, if wherein user selects addition action limited option 309
(seeing in fig. 3d), then as similarly seen and describing in Fig. 3 B, user can be presented with limited option.Such as in mistake
It is seeing in journey 200 in optional step 206 and it is described above be that Fig. 4 A and Fig. 4 B provides addition activity condition and retouched
State.If the period condition 306a of user's selectional restriction option, user can select internally perform triggered activity
So that the user presentation user triggered to user's set defines the period of action.The period can be for example the moment (for example,
Morning, afternoon, evening), the time range (for example, 2PM-5PM) in daytime, particular day is (for example, Saturday or March 1 in 2015
Day), circulation time section, the scope (for example, first Saturday monthly) or the scope on date on date or date (for example,
On April 15,1 day to 2015 March in 2015) etc..
As in Fig. 4 B it is seen that, there is provided user interface 402b, wherein user chosen one day, " Saturday
" and a period " morning (Morning) " (Saturday).Therefore, in present exemplary, user must be in period condition
Triggered activity " walking (Walking) " is performed during " saturday morning (Saturday Morning) ", to be filled to user
The user presentation user definition action " phoning Larry (Call Larry) " put.Additionally, as described in Fig. 3 D,
User can be limited by selecting addition to act limited option 309 to add additional move.
Fig. 5 is the diagram of the user interface 502 for the list that action item is wherein provided at user's set 300.It can be based on
Filter 504 carrys out the list of filter action item.In the present embodiment, filter 504 includes " all (ALL) ", " time
" and " position (LOCATION) " (TIME).However, in other embodiments, can provide different filters and it is more or
Less filter.In addition, action item 506,508,510 and 512 is provided in the present embodiment.Action item 506 includes
User's definition action, triggered activity and the activity condition for creating and defining in Fig. 3 A-4B.Additionally, can be added by selection
Action option 514 is added to create action item from user interface 502.In some embodiments, by selecting to add Action option
514, the user interface 302 that will can be provided in user guiding Fig. 3 A.
Fig. 6 is the ring for determining the wherein environment that user's set is located at based on the environmental condition at different time sections
The flow chart of the instantiation procedure 600 of border condition.Process 600 can for example by user's set 106 and/or action processor 124
Realize.In some embodiments, the operation of instantiation procedure 600 can be implemented as depositing on nonvolatile computer-readable medium
The instruction of storage, wherein these instructions make the operation of data processing equipment execution instantiation procedure 600.
At the very first time, the environmental condition (602) that user's set 106 is located therein is determined.It is as discussed above,
Simultaneously detection data of the combination sensor 108 at different time can be used, to determine the environmental condition of user's set 106.Example
Such as, in the very first time, sensor 108 can detect the user's set 106 not moved, high-caliber artificial light and low noise
It is horizontal.
At the second time (for example, after the first time five minutes), the ring that user's set 106 is located therein is determined
Border condition (604).For example, at the second time, sensor 108 can detect the user's set 106, low-level not moved
Artificial light and high noise levels.Environmental condition based on the very first time and the second time, it may be determined that user's set 106 is located at
The environmental condition (606) of environment therein.From the sensor that can be the different time for being more than the very first time and the second time
Data can detect change and the variability of the environmental condition of the user associated with user's set 106, and this can aid in really
Determine the activity of user.For example, being based on above sensing data, user's set 106 and/or action processor 124 can determine
The environmental condition of the user's set of between the very first time and the second time including fixed user's set 106 and artificial illumination
With the variability of noise level.For environmental condition provided above, user's set 106 and/or action processor 124 can make
With the information and user profile, TV is seen with the user for determining for example associated with user's set 106.
Fig. 7 is still used to use confidence score and confidence score threshold value to determine the user behavior of triggered activity
Instantiation procedure 700 flow chart.Process 700 can be realized for example by user's set 106 and/or action processor 124.
In some embodiments, the operation of instantiation procedure 700 can be implemented as the storage in non-transitory computer-readable medium
Instruction, wherein these instructions make the operation of data processing equipment execution instantiation procedure 700.
In instantiation procedure 700, in order to determine the user behavior of triggered activity, it may be determined that confidence score, for referring to
Show the confidence level (702) of the user behavior of triggered activity.For example, when user situation includes user's set 106 in user's set
When opening webpage in 106 viewport with recipe, it can determine that confidence level is commented by action processor 124 for the triggered activity of " culinary art "
Point.If user's calendar instruction such as user on user's set 106 is arranged at this special time altogether to enter with " Larry " late
Meal, then can determine higher confidence score.In addition, if the people related to " Larry " is included in action close to condition
Xiang Zhong, and action processor 124 determines the user's set of " Larry " in the close of the user's set 106 associated with user
In the range of, then it may determine the confidence score of even more high.
In order to determine the user behavior of triggered activity, can make on whether confidence score meets confidence score threshold
The determination (704) of value.If confidence score meets confidence score threshold value, action processor 124 and/or user's set
106 can determine the user behavior (706) of triggered activity.However, if confidence score is unsatisfactory for confidence score threshold value,
The determination (708) for the user behavior that there is no triggered activity here can be made.It that case, action processor 124
And/or user's set 106 can continue to monitor user profile and environmental condition, to determine whether to exist by user's set
The user behavior for the triggered activity that 106 user is carried out.
Wherein systematic collection described herein on user personal information or can utilize personal information feelings
Under shape, user can be provided with for whether control program or feature to collect user profile (for example, the social network on user
The information of the current location of network, social action or activity, the professional, preference of user or user), or use can be provided with
In control whether and/or how from content server receive may be more relevant with user content chance.In addition, some data
It can be processed before it is by storage or use in a manner of one or more so that the information that can corporally identify is gone
Remove.For example, the identity of user can be processed so that the personal information that can be identified is not confirmable for the user, or
Person can make the geographical position vague generalization of user (such as be generalized to city, postal volume in the case where obtaining positional information
Code or state rank) so that the ad-hoc location of user can not be determined.Therefore, user can be in information how on user's quilt
Collect and there is control using upper by content server.
Fig. 8 is the block diagram of example mobile computing device.In this diagram, mobile computing device 810 is depicted as hand-held
Mobile phone (for example, smart phone or application phone), it is included for user's presentation content to mobile computing device 810 simultaneously
And receive the touch panel display device 812 of user's input based on touch.As a variety of input modules can be provided, also
Other visions, tactile and sense of hearing output block can be provided (for example, LED, the vibrating mechanism for tactile output or being used for
There is provided tone, speech production or record output loudspeaker).
Example visual output mechanism in the form of display device 812 can be taken with resistance or capacitance touch ability
The form of display.Display device can be used to show video, figure, image and text, and be to be used to touch user
Input position and the position co-ordination of the information of display so that device 810 can make the user contact in the opening position of display items
It is associated with this.Mobile computing device 810 can also take alternative form, and it includes as laptop computer, put down
Plate or slate tablet computer, personal digital assistant, embedded system (for example, auto-navigation system), desktop PC or
Computerized work station.
Mobile computing device 810 may be able to determine that with touch panel display device 812 be physically contacted position (for example, by
Finger or the position of input pen contact).Using touch-screen 812, various " virtual " input mechanisms can be produced, wherein user passes through
Contact pattern user interface element interacts with the graphical user-interface element described on touch-screen 512." virtual " input mechanism
Example be " software keyboard ", wherein keyboard is shown on the touchscreen and user is mutually corresponding with each key by pressing
Selection key is carried out in the region of touch-screen 812.
Mobile computing device 810 can include machinery or touch-sensitive button 818a-d.Additionally, mobile computing device can wrap
The button for adjusting the volume exported by one or more loudspeakers 820 is included, and for opening or closing mobile computing dress
The button put.Microphone 822 allows mobile computing device 810 that sub-audible sound is converted into electric signal, and the electric signal can be by
Digital coding is simultaneously stored in computer-readable memory, or sends it to another computing device.Mobile computing device 810
Digital compass, accelerometer, proximity transducer and ambient light sensor can also be included.
Operating system can provide the hardware of mobile computing device (for example, input/output mechanism and execution can from computer
The processor of instruction for reading to retrieve in medium) interface between software.Operating system can be to promote computing device and user
Between interaction application program execution provide platform.
Mobile computing device 810 can utilize touch-screen 812 that graphic user interface is presented.Graphic user interface be one or
The intersection of multiple Basic Elements of Graphic User Interface and can be static (for example, display seems to keep not in certain period of time
Become), or can be dynamically (for example, graphic user interface includes the figure of animation in the absence of user input
Interface element).
Basic Elements of Graphic User Interface can be text, line, shape, image or its combination.For example, Basic Elements of Graphic User Interface can be
The icon and the associated text of the icon being shown on desktop.In some instances, Basic Elements of Graphic User Interface can utilize user to input
To select.For example, user can select to scheme by pressing the region of the touch-screen corresponding with the display of Basic Elements of Graphic User Interface
Shape interface element.In some instances, user can manipulate trace ball so that it is with focus that single Basic Elements of Graphic User Interface, which protrudes,.
User's selection to Basic Elements of Graphic User Interface can be called predefined action by mobile computing device.Can be with to the user of button selection
Call predefined action.
Mobile computing device 810 can include other application, computing subsystem and hardware.Speech-recognition services 872 can be with
The voice communication data that is received by the microphone 822 of mobile computing device is received, and voice communication is translated into corresponding
Text data or perform speech recognition.Speech data through processing can be input to and be deposited in bidding model data 122
The bidding model of storage, whether called as described above for application-specific with the phonetic entry for determining to be used to generate speech data
Specific action.One or more of following application, service and unit can have the phase called by such voice command
Respective action.
Call processing unit can receive the instruction of incoming call and provide a user the incoming phone to response
The ability of calling.Media player can allow user to listen to music or play being locally stored in mobile computing device 810
Stored film in device.Mobile device 810 can include digital camera sensor, and corresponding image and video capture
And software for editing.Internet-browser can be allowed the user to by keying in the address corresponding with web page or choosing
The chain of the web page, which fetches, checks the content from web page.
Network 850 can be connected to so that mobile by mobile computing device 810 by operating the ISP of the network of base station
Computing device 810 can communicate between other computing systems with providing service 860.Although different network (examples can be passed through
Such as, the internal network of ISP, public switched telephone network and internet) service 860 is provided, but network 850 is illustrated
For single network.ISP can operate server system 852, and the server system 852 route mobile computing device
810 and service 860 associated computing systems between information block and speech data.
Mobile computing device 810 can be connected to public switched telephone network (PSTN) 862 by network 850, so as in movement
Voice or facsimile are established between computing device 810 and another computing device.For example, service provider server's system 852
The instruction of the incoming call for mobile computing device 810 can be received from PSTN 862.On the contrary, mobile computing device 810
It can send and communicate to service provider server's system 852, thereby using the device phase with that can be accessed by PSTN 862
The telephone number of association initiates call.
Mobile computing device 810 can be connected by network 850 with voice-over ip phone (VoIP) service 864, described
VoIP service 864 is communicated by IP network routing voice, is completely contradicted with PSTN.For example, the user of mobile computing device 810 can
To call VoIP applications and initiate to call using the program.Service provider server's system 852 can will come from calling
Speech data be forwarded to VoIP service, the VoIP service can potentially use the PSTN of the final stage for connecting,
Corresponding computing device is routed the call to by internet.
Can be provided using shop 866 to the user of mobile computing device 810 can be by network 850 for browsing user
The ability of the list of the application program for the long-range storage downloaded and be installed on mobile computing device 810.Using shop 866
It may be used as the repository of application developed by third-party application developer.It is installed in answering on mobile computing device 810
With program can by network 850 with to be communicated using the server system specified by journey.For example, can be from using shop
866 download VoIP application programs, so that user can communicate with VoIP service 864.
Mobile computing device 810 can access the content on internet 868 by network 850.For example, mobile computing device
810 user can call the web from the addressable remote computing device request data at specified universal resource location clear
Look at device application.In various examples, some in these services 860 can pass through internet access.
Mobile computing device can be communicated with personal computer 870.For example, personal computer 870 can be mobile
The home computer of the user of computing device 810.Therefore, user can transmit matchmaker as a stream from his personal computer 870
Body.User can also look at the file structure of his personal computer 870, and selection is sent between computerized device
Document.
Mobile computing device 810 can be communicated with social networks 874.Social networks can include many members, its
In some have agreed to be associated as acquaintance.Application program on mobile computing device 810 can access social networks 874 with
Retrieve the information of the acquaintance of the user based on mobile computing device.For example, " address book " application program can retrieve the ripe of user
The telephone number of people., can the social activity based on other members in the social network diagram from user to member in various examples
Network distance and annexation deliver the content to mobile computing device 810.For example, can be based on by " close " in user into
Member (for example, as " friend " or the member of " friends of friends ") to select for user with the level interacted that such content is carried out
Advertisement and news article content.
Mobile computing device 810 can access the set 876 of personal contact person by network 850.Each contact person can be with
Mark is individual and including the information (for example, telephone number, e-mail address and birthday) individual on that.Because connection
Be people set by remote hosting to mobile computing device 810, if so user can by cross over equipment for drying contact person 876 make
Access and safeguard for the set of public contact person.
Mobile computing device 810 can access the application program 878 based on cloud.Cloud computing is provided from mobile computing device
The application program (for example, word processor or e-mail program) of 810 remote hostings, and web can be used by device 810
Browser or dedicated program access.
Map Services 880 can be provided with street map, route planning information and satellite mapping to mobile computing device 810
Picture.Map Services 880 can also receive inquiry and home position particular result.For example, mobile computing device 810 can be to map
Service 880 sends the estimated location of mobile computing device and looked into for " pizza place (pizza place) " user's typing
Ask.Map Services 880 can return to the street map with " mark (marker) " being superimposed on the map, " mark
(marker) " the geographical position of " pizza place (the pizza place) " near mark.
Pavement branch sections service 882 can be provided with the pavement branch sections road of the destination of user's supply to mobile computing device 810
Line guides.For example, pavement branch sections service 882 can to device 810 transmit as a stream the device estimated locations street level view with
And for providing the data by the voice command of the user guiding of device 810 to destination and superposition arrow.
Various forms of Streaming Medias 884 can be asked by mobile computing device 810.For example, computing device 810 can ask
Seek the stream for pre-recorded video file, live television programming or live radio programming.
The user that microblogging service 886 can receive the recipient for not identifying issue (post) from mobile computing device 810 is defeated
Enter issue.The issue can be distributed to the other members for the microblogging service 886 for agreeing to subscribe to the user by microblogging service 886.
Search engine 888 can receive text the or oral inquiry of user's typing from mobile computing device 810, so as to
It is determined that the set of the addressable document in internet in response to the inquiry, and provide information to device 810 and be used to be somebody's turn to do to show
Respond the list of the search result of document.In wherein the example of interview is received, speech-recognition services 872 can be by institute
The audio translation received is into the text query for being sent to search engine.
These and other service can be realized in server system 890.Server system can be to provide service or clothes
The combination of the hardware and software of the set of business.For example, the set for the computerized device for being physically separated and networking can be together
Operate as logical server system unit, operated necessary to providing service to hundreds of computing devices with processing.Service
Device system is also known as computing system herein.
In various embodiments, if formerly operation is unsuccessful (if for example, being not carried out determining), do not perform
" in response to " another operation (for example, determine or mark) or " as " another operation " result " and the operation performed.By " automatic
The operation that ground " performs is the operation of execution in the case of no user intervention (for example, intervention user input).In this document
The middle feature described with conditional statement can describe optional embodiment.In some instances, from first device " transmission " to
Second device is placed data into network including first device to be used to be received by second device, but can not include second device
Receive the data.On the contrary, can include receiving data from network from first device " reception ", but first device can not be included
Send the data.
By computing system " it is determined that " computing system can be included ask another device perform this determining and by the result
It is supplied to computing system.In addition, it can be sent by computing system " display " or " presentation " including the computing system another for making
One device shows or presented the data of cited information.
The embodiment available digital electronic circuit of the theme that describes in this manual and operation or with computer software,
Firmware or hardware (including structure and its equivalent structures disclosed in this specification) use one or more of which
Combination realized.The embodiment of the theme described in this manual can be used as on computer-readable storage medium encode with
For (that is, being calculated by one or more computer programs of data processing equipment execution or the operation of control data processing equipment
One or more modules of machine programmed instruction) it is implemented.Alternatively or furthermore it is possible to programmed instruction is encoded manually generated
Transmitting signal electricity, optics or the electromagnetic signal of generation (for example, machine) on, the transmitting signal is generated to carry out information
Encode to be transferred to suitable receiver apparatus for being performed by data processing equipment.Computer-readable storage medium can be or
It is included in computer readable storage means, computer-readable memory substrate, random or serial access memory array or device
Or in the combination of one or more of which.In addition, when computer-readable storage medium is not transmitting signal, computer storage is situated between
Matter can be the source or destination of computer program instructions of the coding in manually generated transmitting signal.Computer-readable storage medium
One or more individually physical assemblies or media be can also be or be included in (for example, multiple CD, disk or other storages
Device) in.
The operation described in this manual can be used as by data processing equipment to being stored in one or more computers
The operation that the data received in readable storage devices or from other sources perform is implemented.
Term " data processing equipment " includes the unit and machine of all kinds for processing data, as showing
Example include programmable processor, computer, on-chip system or it is above-mentioned in it is multiple or combination.The equipment can include special logic
Circuit, for example, FPGA (field programmable gate array) or ASIC (application specific integrated circuit).The equipment is gone back in addition to including hardware
The code that performing environment is created for the computer program can be included, for example, forming processor firmware, protocol stack, database
Management system, operating system, cross-platform runtime environment, virtual machine or one or more of which combination code.Should
Equipment and performing environment can realize a variety of computation model infrastructure, such as web services, Distributed Calculation and grid
Computing basic facility.
Computer program (being also known as program, software, software application, script or code) can use any type of programming language
Speech (including compiling or interpretative code, illustrative or procedural language) is write, and it can be disposed in any form, including is made
For stand-alone program or as module, component, subroutine, object or the other lists for being suitable for using in a computing environment
Member.Computer program can with but the file that may not correspond in file system.Other programs or data (example can kept
Such as, be stored in one or more of marking language document script) file a part in, be exclusively used in the list of described program
In individual file or multiple coordination files (for example, storing the file of the part of one or more modules, subprogram or code)
Middle storage program.Computer program can be deployed on a computer either at a website or cross over it is more
Performed on multiple computers that individual website is distributed and passes through interconnection of telecommunication network.
The process and logic flow described in this manual can perform one by one or more programmable processors
Individual or multiple computer programs by the way that output is operated and generated to input data to perform action to perform.Process and patrol
Collecting flow can also be performed by dedicated logic circuit, and equipment can also be implemented as dedicated logic circuit, described special
It is, for example, FPGA (field programmable gate array) or ASIC (application specific integrated circuit) with logic circuit.
As an example, being adapted for carrying out the processor of computer program includes not only general but also special microprocessor and any
Any one or more processors of the digital computer of species.Generally, processor will be deposited from read-only storage or arbitrary access
Reservoir or both receives instruction and data.The necessary element of computer is for the processor and use according to instruction execution action
In one or more storage arrangements of store instruction and data.Generally, computer will also include or operationally couple with
From for data storage one or more high-capacity storages (for example, disk, magneto-optic disk or CD) receive data or to
One or more high-capacity storages for data storage shift data or both.However, computer need not have such dress
Put.In addition, computer can be embedded in another device, another device such as mobile phone, personal digital assistant
(PDA), Mobile audio frequency or video player, game console, global positioning system (GPS) receiver or portable memory
(for example, USB (USB) flash drive) etc..Being suitable for the device of storage computer program instructions and data includes
Nonvolatile memory, medium and the memory device of form of ownership, include semiconductor storage unit as example, such as EPROM,
EEPROM and flash memory device；Disk, such as internal hard drive or removable disk；Magneto-optic disk；And CD ROM and DVD-ROM
Disk.Processor and memory can be supplemented by dedicated logic circuit, or be incorporated to dedicated logic circuit.
Interacted to provide with user, can realize the embodiment of the theme described in this specification on computers,
The computer, which has, is used for the display device to user's display information (for example, CRT (cathode-ray tube) or LCD (liquid crystals
Show) monitor) and user can be used to provide the keyboard and pointing device of input, such as mouse or trace ball to computer.Its
The device of its species can also be used to provide and be interacted with user；For example, the feedback for being supplied to user can be any type of
Sense feedback, such as visual feedback, audio feedback or touch feedback；And can according to any form (including sound, voice or touch
Feel input) receive the input from user.In addition, computer can by as used in user device send document and
From used in user device receive document with user mutual；For example, by being asked in response to what is received from web browser
Ask and send web page to the web browser on the user's set of user.
The embodiment of the theme described in this specification can be realized in computing systems, and the computing system includes rear end
Component (for example, as data server), either including middleware component (for example, application server) or including front group
Part, for example, with user can be used for the graphic user interface that is interacted with the embodiment of the theme described in this specification or
The subscriber computer of Web browser, or any combinations of one or more such rear ends, middleware or front end assemblies.This is
The component of system can be interconnected by any form or the digital data communications of medium (for example, communication network).Communication network
Example include between LAN (" LAN ") and wide area network (" WAN "), network (for example, internet) and peer-to-peer network (for example, oneself
Organize peer-to-peer network).
The computing system can include user and server.User and server be generally remote from each other and typically via
Communication network interacts.The relation of user and server on corresponding computer by means of running and having user-clothes each other
Be engaged in device relation computer program and produce.In certain embodiments, server sends data (for example, HTML to user's set
The page) (for example, being used to receive to the user's display data interacted with user's set and from the user interacted with user's set
The purpose of family input).The data in user device generation can be received (for example, user hands over from user's set at server
Mutual result).
Although this specification includes many particular implementation details, these are not construed as to any invention
Or the scope of thing that can be claimed be construed as limiting, but be conversely interpreted the particular implementation specific to specific invention
The description of the feature of example.It can also be realized in combination in this manual in the feelings of single embodiment in single embodiment
Some features described in scape.On the contrary, can also be individually real in various embodiments or in any suitable sub-portfolio
Various features described in the scene of present single embodiment.In addition, although feature can be described above as according to some
Combination action and therefore even initially claimed protection, but can be deleted in some cases from combination from claimed
Combination one or more features, and combination claimed can be directed to the change of sub-portfolio or sub-portfolio.
Similarly, operated although being described in the accompanying drawings with certain order, this is not construed as requiring with shown
Certain order either performs this generic operation or performs the operations of all diagrams to realize desired result in sequential order.
In some cases, multitasking and parallel processing can be favourable.In addition, the various system components in above-described embodiment
Separation be not construed as requiring such separation in all embodiments, and should be understood that described journey
Sequence component and system usually can be integrated together in single software product or be encapsulated into multiple software product.
Therefore, the specific embodiment of theme is described.Scope of the other embodiments in following claims
It is interior.In some cases, action described in claim can in different order be performed and still realized desired
Result.In addition, to not necessarily require shown certain order or sequential order desired to realize for the process described in accompanying drawing
As a result.In some embodiments, multitasking and parallel processing can be favourable.
Claims (20)
1. a kind of method, including：
The input of action is defined in user device reception user, user's definition action includes multiple lexical items；
The selection that triggered activity is defined to user is received by the user's set, the triggered activity indicates that being used for triggering will be in
The existing user defines the movable user behavior of action；
Determine at least one environmental condition for the environment that the user's set is located at；
It is described movable to determine to indicate by the triggered activity based on user profile and at least one environmental condition
User behavior；And
The notice of action is defined to the user's set presentation user of the user by the user's set.
2. according to the method for claim 1, wherein, user's definition action is reminding task, and the triggering is lived
Dynamic is at least one in body movement and situation activity.
3. method according to claim 1 or 2, further comprise at least one activity condition, wherein it is determined that by described
The movable user behavior of triggered activity instruction further comprises：
Selection at least one activity condition is received by the user's set, at least one activity condition instruction will be
It is determined that the condition met in the movable user behavior indicated by the triggered activity；
At least one activity condition is determined by the user's set；
Determine to have met at least one activity condition by the user's set；And
It is described movable to determine to indicate by the triggered activity based on user profile and at least one environmental condition
User behavior.
4. according to the method for claim 3, wherein, at least one activity condition is period condition, the band of position
Condition and people are close at least one in condition.
5. the method according to any one of preceding claims, wherein it is determined that the environment that the user's set is located at
At least one environmental condition further comprise：
The user's set is determined by one or more sensors associated with the user's set and in the very first time
The environment being located at；
By the one or more of sensors associated with the user's set and determine the user in the second time
The environment that device is located at；And
The use is determined based on the environment of at least described very first time and second time by the user's set
At least one environmental condition for the environment that family device is located at.
6. the method according to any one of preceding claims, wherein, presented to the user's set of the user
The notice that the user defines action further comprises：
User's definition is performed by the user's set to act；And
The user is presented to the user's set of the user by the user's set and defines what action had been carried out
Notice.
7. the method according to any one of preceding claims, wherein, based on user profile and at least one ring
Border condition determines that the movable user behavior indicated by the triggered activity further comprises：
It is determined that the confidence score of the confidence level for the movable user behavior that instruction is indicated by the triggered activity；
Determine that the confidence score meets confidence score threshold value.
8. a kind of system, including：
Processor；And
Computer-readable medium, the computer-readable medium are coupled to the processor and with the fingers stored thereon
Order, by operating the computing device during computing device, the operation includes for the instruction：
The input that user defines action is received, user's definition action includes multiple lexical items；
The selection that triggered activity is defined to user is received, the triggered activity is indicated for triggering the user to be presented definition
The movable user behavior of action；
Determine at least one environmental condition for the environment that user's set is located at；
It is described movable to determine to indicate by the triggered activity based on user profile and at least one environmental condition
User behavior；And
The notice of action is defined to the user's set presentation user of the user.
9. system according to claim 8, wherein, user's definition action is reminding task, and the triggering is lived
Dynamic is at least one in body movement and situation activity.
10. system according to claim 8 or claim 9, further comprise at least one activity condition, wherein it is determined that passing through institute
The movable user behavior for stating triggered activity instruction further comprises：
The selection at least one activity condition is received, at least one activity condition instruction will be it is determined that pass through the triggering
The condition met in the movable user behavior of activity instruction；
Determine at least one activity condition；
It is determined that at least one activity condition is met；And
It is described movable to determine to indicate by the triggered activity based on user profile and at least one environmental condition
User behavior.
11. system according to claim 10, wherein, at least one activity condition is period condition, position area
Domain condition and people are close at least one in condition.
12. the system according to any one of claim 8 to 11, wherein it is determined that the ring that the user's set is located at
At least one environmental condition in border further comprises：
The user's set is determined by one or more sensors associated with the user's set and in the very first time
The environment being located at；
By the one or more of sensors associated with the user's set and determine the user in the second time
The environment that device is located at；And
The use is determined based on the environment of at least described very first time and second time by the user's set
At least one environmental condition for the environment that family device is located at.
13. the system according to any one of claim 8 to 12, wherein, it is in the user's set of the user
The notice that the existing user defines action further comprises：
Perform user's definition action；And
The notice for acting and having been carried out is defined to the user's set presentation user of the user.
14. the system according to any one of claim 8 to 13, wherein, based on user profile and described at least one
Environmental condition determines that the movable user behavior indicated by the triggered activity further comprises：
It is determined that the confidence score of the confidence level for the movable user behavior that instruction is indicated by the triggered activity；
Determine that the confidence score meets confidence score threshold value.
15. a kind of computer-readable medium with the instruction stored thereon, the instruction is described by making during computing device
Computing device operates, and the operation includes：
The input that user defines action is received, user's definition action includes multiple lexical items；
The selection that triggered activity is defined to user is received, the triggered activity is indicated for triggering the user to be presented definition
The movable user behavior of action；
Determine at least one environmental condition for the environment that the user's set is located at；
It is described movable to determine to indicate by the triggered activity based on user profile and at least one environmental condition
User behavior；And
The notice of action is defined to the user's set presentation user of the user.
16. computer-readable medium according to claim 15, further comprise at least one activity condition, wherein, really
Surely the movable user behavior indicated by the triggered activity further comprises：
The selection at least one activity condition is received, at least one activity condition instruction will be it is determined that pass through the triggering
The condition met in the movable user behavior of activity instruction；
Determine at least one activity condition；
It is determined that at least one activity condition is met；And
It is described movable to determine to indicate by the triggered activity based on user profile and at least one environmental condition
User behavior.
17. the computer-readable medium according to claim 15 or 16, wherein it is determined that the ring that the user's set is located at
The environmental condition in border further comprises：
The user's set is determined by one or more sensors associated with the user's set and in the very first time
The environment being located at；
By the one or more of sensors associated with the user's set and determine the user in the second time
The environment that device is located at；And
The use is determined based on the environment of at least described very first time and second time by the user's set
At least one environmental condition for the environment that family device is located at.
18. the computer-readable medium according to any one of claim 15 to 17, wherein, to described in the user
User's set is presented the notice that the user defines action and further comprised：
Perform user's definition action；And
The notice for acting and having been carried out is defined to the user's set presentation user of the user.
19. the computer-readable medium according to any one of claim 15 to 18, wherein, based on user profile and institute
Environmental condition is stated to determine that the movable user behavior indicated by the triggered activity further comprises：
It is determined that the confidence score of the confidence level for the movable user behavior that instruction is indicated by the triggered activity；
Determine that the confidence score meets confidence score threshold value.
20. a kind of method, including：
The input of action is defined by data processing equipment reception user, user's definition action includes multiple lexical items；
The selection that triggered activity is defined to user is received by the data processing equipment, the triggered activity indicates to be used to trigger
The user to be presented defines the movable user behavior of action；
At least one environmental condition for the environment that user is located at is determined by the data processing equipment；
It is described movable to determine to indicate by the triggered activity based on user profile and at least one environmental condition
User behavior；And
The user notice for defining action is provided by the data processing equipment.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/708,642 | 2015-05-11 | ||
US14/708,642 US20160335139A1 (en) | 2015-05-11 | 2015-05-11 | Activity triggers |
PCT/US2016/028819 WO2016182712A1 (en) | 2015-05-11 | 2016-04-22 | Activity triggers |
Publications (1)
Publication Number | Publication Date |
---|---|
CN107430724A true CN107430724A (en) | 2017-12-01 |
Family
ID=55949102
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201680018932.6A Pending CN107430724A (en) | 2015-05-11 | 2016-04-22 | Activity-triggered |
Country Status (4)
Country | Link |
---|---|
US (2) | US20160335139A1 (en) |
EP (1) | EP3295393A1 (en) |
CN (1) | CN107430724A (en) |
WO (1) | WO2016182712A1 (en) |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN115550304A (en) * | 2018-08-22 | 2022-12-30 | 谷歌有限责任公司 | Method, apparatus, and storage medium for determining a set of activity instances for a group of users |
Families Citing this family (39)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8977255B2 (en) | 2007-04-03 | 2015-03-10 | Apple Inc. | Method and system for operating a multi-function portable electronic device using voice-activation |
US8676904B2 (en) | 2008-10-02 | 2014-03-18 | Apple Inc. | Electronic devices with voice command and contextual data processing capabilities |
CN104969289B (en) | 2013-02-07 | 2021-05-28 | 苹果公司 | Voice trigger of digital assistant |
US9715875B2 (en) | 2014-05-30 | 2017-07-25 | Apple Inc. | Reducing the need for manual start/end-pointing and trigger phrases |
US10170123B2 (en) | 2014-05-30 | 2019-01-01 | Apple Inc. | Intelligent assistant for home automation |
US9338493B2 (en) | 2014-06-30 | 2016-05-10 | Apple Inc. | Intelligent automated assistant for TV user interactions |
US10133443B2 (en) | 2015-06-14 | 2018-11-20 | Google Llc | Systems and methods for smart home automation using a multifunction status and entry point icon |
US9361011B1 (en) | 2015-06-14 | 2016-06-07 | Google Inc. | Methods and systems for presenting multiple live video feeds in a user interface |
USD803241S1 (en) | 2015-06-14 | 2017-11-21 | Google Inc. | Display screen with animated graphical user interface for an alert screen |
USD812076S1 (en) | 2015-06-14 | 2018-03-06 | Google Llc | Display screen with graphical user interface for monitoring remote video camera |
US10747498B2 (en) | 2015-09-08 | 2020-08-18 | Apple Inc. | Zero latency digital assistant |
US10691473B2 (en) | 2015-11-06 | 2020-06-23 | Apple Inc. | Intelligent automated assistant in a messaging environment |
DK201670540A1 (en) | 2016-06-11 | 2018-01-08 | Apple Inc | Application integration with a digital assistant |
US10263802B2 (en) | 2016-07-12 | 2019-04-16 | Google Llc | Methods and devices for establishing connections with remote cameras |
USD882583S1 (en) * | 2016-07-12 | 2020-04-28 | Google Llc | Display screen with graphical user interface |
USD843398S1 (en) | 2016-10-26 | 2019-03-19 | Google Llc | Display screen with graphical user interface for a timeline-video relationship presentation for alert events |
US11238290B2 (en) | 2016-10-26 | 2022-02-01 | Google Llc | Timeline-video relationship processing for alert events |
US10386999B2 (en) | 2016-10-26 | 2019-08-20 | Google Llc | Timeline-video relationship presentation for alert events |
DK180048B1 (en) | 2017-05-11 | 2020-02-04 | Apple Inc. | MAINTAINING THE DATA PROTECTION OF PERSONAL INFORMATION |
DK201770427A1 (en) | 2017-05-12 | 2018-12-20 | Apple Inc. | Low-latency intelligent automated assistant |
DK179496B1 (en) | 2017-05-12 | 2019-01-15 | Apple Inc. | USER-SPECIFIC Acoustic Models |
USD878402S1 (en) * | 2017-05-22 | 2020-03-17 | Subsplash Ip, Llc | Display screen or portion thereof with transitional graphical user interface |
US10819921B2 (en) | 2017-05-25 | 2020-10-27 | Google Llc | Camera assembly having a single-piece cover element |
US10683962B2 (en) | 2017-05-25 | 2020-06-16 | Google Llc | Thermal management for a compact electronic device |
US10972685B2 (en) | 2017-05-25 | 2021-04-06 | Google Llc | Video camera assembly having an IR reflector |
US11493359B2 (en) * | 2018-01-24 | 2022-11-08 | Sony Corporation | Control device, control method, and mobile object |
US10928918B2 (en) | 2018-05-07 | 2021-02-23 | Apple Inc. | Raise to speak |
US11145294B2 (en) | 2018-05-07 | 2021-10-12 | Apple Inc. | Intelligent automated assistant for delivering content from user experiences |
DK180639B1 (en) | 2018-06-01 | 2021-11-04 | Apple Inc | DISABILITY OF ATTENTION-ATTENTIVE VIRTUAL ASSISTANT |
US11462215B2 (en) | 2018-09-28 | 2022-10-04 | Apple Inc. | Multi-modal inputs for voice commands |
JP7241499B2 (en) * | 2018-10-10 | 2023-03-17 | パナソニック インテレクチュアル プロパティ コーポレーション オブ アメリカ | Information processing method, information processing apparatus, and information processing program |
US11348573B2 (en) | 2019-03-18 | 2022-05-31 | Apple Inc. | Multimodality in digital assistant systems |
US11307752B2 (en) | 2019-05-06 | 2022-04-19 | Apple Inc. | User configurable task triggers |
DK201970509A1 (en) | 2019-05-06 | 2021-01-15 | Apple Inc | Spoken notifications |
US11140099B2 (en) | 2019-05-21 | 2021-10-05 | Apple Inc. | Providing message response suggestions |
US11227599B2 (en) | 2019-06-01 | 2022-01-18 | Apple Inc. | Methods and user interfaces for voice-based control of electronic devices |
US11061543B1 (en) | 2020-05-11 | 2021-07-13 | Apple Inc. | Providing relevant data items based on context |
US11490204B2 (en) | 2020-07-20 | 2022-11-01 | Apple Inc. | Multi-device audio adjustment coordination |
US11438683B2 (en) | 2020-07-21 | 2022-09-06 | Apple Inc. | User identification using headphones |
Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20040019603A1 (en) * | 2002-05-29 | 2004-01-29 | Honeywell International Inc. | System and method for automatically generating condition-based activity prompts |
CN102413231A (en) * | 2011-10-10 | 2012-04-11 | 宇龙计算机通信科技(深圳)有限公司 | Mobile terminal and schedule reminding method |
CN103221948A (en) * | 2010-08-16 | 2013-07-24 | 诺基亚公司 | Method and apparatus for executing device actions based on context awareness |
CN103856635A (en) * | 2014-03-12 | 2014-06-11 | 宇龙计算机通信科技(深圳)有限公司 | Terminal device and processing method for agenda items of terminal device |
CN104506707A (en) * | 2014-11-21 | 2015-04-08 | 惠州Tcl移动通信有限公司 | Control method and control system for context awareness mode |
CN104519203A (en) * | 2014-09-02 | 2015-04-15 | 冯林 | Alarm clock setting prompting method and system |
Family Cites Families (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20090157672A1 (en) * | 2006-11-15 | 2009-06-18 | Sunil Vemuri | Method and system for memory augmentation |
US20090320047A1 (en) * | 2008-06-23 | 2009-12-24 | Ingboo Inc. | Event Bundling |
US10057736B2 (en) * | 2011-06-03 | 2018-08-21 | Apple Inc. | Active transport based notifications |
US9167388B2 (en) * | 2013-01-18 | 2015-10-20 | Apple Inc. | Method and apparatus for automatically adjusting the operation of reminders based on device event history |
-
2015
- 2015-05-11 US US14/708,642 patent/US20160335139A1/en not_active Abandoned
-
2016
- 2016-04-22 EP EP16721311.5A patent/EP3295393A1/en not_active Ceased
- 2016-04-22 WO PCT/US2016/028819 patent/WO2016182712A1/en active Application Filing
- 2016-04-22 CN CN201680018932.6A patent/CN107430724A/en active Pending
-
2017
- 2017-05-23 US US15/603,030 patent/US20170357395A1/en not_active Abandoned
Patent Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20040019603A1 (en) * | 2002-05-29 | 2004-01-29 | Honeywell International Inc. | System and method for automatically generating condition-based activity prompts |
CN103221948A (en) * | 2010-08-16 | 2013-07-24 | 诺基亚公司 | Method and apparatus for executing device actions based on context awareness |
CN102413231A (en) * | 2011-10-10 | 2012-04-11 | 宇龙计算机通信科技(深圳)有限公司 | Mobile terminal and schedule reminding method |
CN103856635A (en) * | 2014-03-12 | 2014-06-11 | 宇龙计算机通信科技(深圳)有限公司 | Terminal device and processing method for agenda items of terminal device |
CN104519203A (en) * | 2014-09-02 | 2015-04-15 | 冯林 | Alarm clock setting prompting method and system |
CN104506707A (en) * | 2014-11-21 | 2015-04-08 | 惠州Tcl移动通信有限公司 | Control method and control system for context awareness mode |
Cited By (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN115550304A (en) * | 2018-08-22 | 2022-12-30 | 谷歌有限责任公司 | Method, apparatus, and storage medium for determining a set of activity instances for a group of users |
CN115550304B (en) * | 2018-08-22 | 2023-10-10 | 谷歌有限责任公司 | Method, apparatus and storage medium for determining a set of active instances for a group of users |
US11843655B2 (en) | 2018-08-22 | 2023-12-12 | Google Llc | Automatically resolving, with reduced user inputs, a set of activity instances for a group of users |
Also Published As
Publication number | Publication date |
---|---|
US20160335139A1 (en) | 2016-11-17 |
EP3295393A1 (en) | 2018-03-21 |
US20170357395A1 (en) | 2017-12-14 |
WO2016182712A1 (en) | 2016-11-17 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN107430724A (en) | Activity-triggered | |
US11562005B2 (en) | List accumulation and reminder triggering | |
CN105025173B (en) | Know profile switching on mobile computing device | |
CN106845644B (en) | Heterogeneous network for learning user and mobile application contact through mutual relation | |
CN102792320B (en) | The individualized vocabulary of digital assistants | |
CN105229575B (en) | Text prediction based on multiple language models | |
JP6791569B2 (en) | User profile generation method and terminal | |
CN103282957B (en) | Automatically speech input is monitored based on context | |
US10917485B2 (en) | Implicit contacts in an online social network | |
US20130024456A1 (en) | Method and apparatus for category based navigation | |
WO2013012211A2 (en) | Situation-aware user sentiment social interest models | |
EP3283950A2 (en) | Systems and methods for proactively identifying and surfacing relevant content on a touch-sensitive device | |
CN105683847A (en) | Physical environment profiling through internet of things integration platform | |
CN105830065A (en) | Generating recommended search queries on online social networks | |
CN102265649A (en) | User-adaptive recommended mobile content | |
US9754016B1 (en) | Dynamic content discoverability | |
EP2817738B1 (en) | Predictive service access | |
CN105637448A (en) | Contextualizing sensor, service and device data with mobile devices | |
CN107969167A (en) | Physical awareness action triggers | |
AU2012283928B2 (en) | Method and apparatus for category based navigation | |
Coppola et al. | AI techniques in a context-aware ubiquitous environment | |
KR20230132588A (en) | User-oriented actions based on audio dialogue | |
KR102184691B1 (en) | Method for recording life log diary based on context aware, apparatus and terminal thereof | |
Patil et al. | On Feature Models of Home Automation Systems towards Smart Sensing | |
Lovett | Sensing and interactive intelligence in mobile context aware systems |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
CB02 | Change of applicant information |
Address after: American CaliforniaApplicant after: Google limited liability companyAddress before: American CaliforniaApplicant before: Google Inc. |
|
CB02 | Change of applicant information | ||
WD01 | Invention patent application deemed withdrawn after publication |
Application publication date: 20171201 |
|
WD01 | Invention patent application deemed withdrawn after publication |