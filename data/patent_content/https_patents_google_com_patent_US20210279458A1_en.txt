US20210279458A1 - Interactive editing of electronic text - Google Patents
Interactive editing of electronic text Download PDFInfo
- Publication number
- US20210279458A1 US20210279458A1 US17/327,034 US202117327034A US2021279458A1 US 20210279458 A1 US20210279458 A1 US 20210279458A1 US 202117327034 A US202117327034 A US 202117327034A US 2021279458 A1 US2021279458 A1 US 2021279458A1
- Authority
- US
- United States
- Prior art keywords
- representation
- handwriting
- electronic handwriting
- electronic
- content
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
- 230000002452 interceptive effect Effects 0.000 title description 3
- 230000008859 change Effects 0.000 claims abstract description 11
- 238000000034 method Methods 0.000 claims description 42
- 230000009471 action Effects 0.000 claims description 19
- 230000000007 visual effect Effects 0.000 claims description 13
- 238000003780 insertion Methods 0.000 claims description 9
- 230000037431 insertion Effects 0.000 claims description 9
- 230000005055 memory storage Effects 0.000 claims 3
- 238000005516 engineering process Methods 0.000 description 34
- 230000008569 process Effects 0.000 description 22
- 238000004891 communication Methods 0.000 description 13
- 238000012545 processing Methods 0.000 description 12
- 238000004590 computer program Methods 0.000 description 9
- 230000003993 interaction Effects 0.000 description 7
- 238000004422 calculation algorithm Methods 0.000 description 6
- 238000013461 design Methods 0.000 description 4
- 230000004048 modification Effects 0.000 description 4
- 238000012986 modification Methods 0.000 description 4
- 230000003287 optical effect Effects 0.000 description 4
- 238000010586 diagram Methods 0.000 description 3
- 230000006870 function Effects 0.000 description 3
- 230000004044 response Effects 0.000 description 3
- 230000003190 augmentative effect Effects 0.000 description 2
- 230000008901 benefit Effects 0.000 description 2
- 230000015572 biosynthetic process Effects 0.000 description 2
- 230000001413 cellular effect Effects 0.000 description 2
- 239000004973 liquid crystal related substance Substances 0.000 description 2
- 230000007246 mechanism Effects 0.000 description 2
- 230000002093 peripheral effect Effects 0.000 description 2
- 230000009467 reduction Effects 0.000 description 2
- 238000013515 script Methods 0.000 description 2
- 230000003068 static effect Effects 0.000 description 2
- 238000003786 synthesis reaction Methods 0.000 description 2
- 238000004458 analytical method Methods 0.000 description 1
- 238000013459 approach Methods 0.000 description 1
- 238000003491 array Methods 0.000 description 1
- 239000002355 dual-layer Substances 0.000 description 1
- 230000000694 effects Effects 0.000 description 1
- 239000011521 glass Substances 0.000 description 1
- 230000000977 initiatory effect Effects 0.000 description 1
- 239000000463 material Substances 0.000 description 1
- 239000000203 mixture Substances 0.000 description 1
- 230000007935 neutral effect Effects 0.000 description 1
- 230000003362 replicative effect Effects 0.000 description 1
- 230000001953 sensory effect Effects 0.000 description 1
- 239000007787 solid Substances 0.000 description 1
- 238000012800 visualization Methods 0.000 description 1
Images
Classifications
-
- G06K9/00422—
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/10—Text processing
- G06F40/166—Editing, e.g. inserting or deleting
- G06F40/171—Editing, e.g. inserting or deleting by use of digital ink
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V30/00—Character recognition; Recognising digital ink; Document-oriented image-based pattern recognition
- G06V30/10—Character recognition
- G06V30/32—Digital ink
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/03—Arrangements for converting the position or the displacement of a member into a coded form
- G06F3/033—Pointing devices displaced or positioned by the user, e.g. mice, trackballs, pens or joysticks; Accessories therefor
- G06F3/0354—Pointing devices displaced or positioned by the user, e.g. mice, trackballs, pens or joysticks; Accessories therefor with detection of 2D relative movements between the device, or an operating part thereof, and a plane or surface, e.g. 2D mice, trackballs, pens or pucks
- G06F3/03545—Pens or stylus
-
- G06K9/00416—
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V30/00—Character recognition; Recognising digital ink; Document-oriented image-based pattern recognition
- G06V30/10—Character recognition
- G06V30/14—Image acquisition
- G06V30/148—Segmentation of character regions
- G06V30/153—Segmentation of character regions using recognition of characters or words
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V30/00—Character recognition; Recognising digital ink; Document-oriented image-based pattern recognition
- G06V30/10—Character recognition
- G06V30/32—Digital ink
- G06V30/333—Preprocessing; Feature extraction
- G06V30/347—Sampling; Contour coding; Stroke extraction
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V30/00—Character recognition; Recognising digital ink; Document-oriented image-based pattern recognition
- G06V30/10—Character recognition
- G06V30/32—Digital ink
- G06V30/36—Matching; Classification
Definitions
- aspects of the subject technology provide systems and methods for providing interactive editing of electronic text using electronic handwriting.
- a goal of the electronic handwriting is to encourage creativity and freeform mixed layouts where drawings, figures, and text may be placed anywhere in the document.
- the subject technology provide a computer-implemented method that includes receiving a new segment of electronic handwriting for display at a user designated position within or adjacent to existing electronic content displayed on a display device, providing the received new segment to a handwriting recognition module to obtain a plurality of textual interpretations of the new segment, generating respective electronic handwriting representations for the plurality of textual interpretations obtained from the handwriting recognition module, scoring the plurality of textual interpretations obtained from the handwriting recognition module based on how each respective electronic handwriting representation would change the display of the existing electronic content when the respective electronic handwriting representation is displayed substantially at the user designated position within or adjacent to the existing electronic content, selecting, based on the scoring, an electronic handwriting representation corresponding to a respective textual interpretation of the plurality of textual interpretations, and modifying, for display on
- FIG. 1 illustrates an exemplary system for editing electronic text, according to aspects of the subject technology.
- FIGS. 2A and 2B depict an example handwriting recognition interface displayed on the touch display, according to aspects of the subject technology.
- FIG. 3 is an example reflow of characters input into a display, according to aspects of the subject technology.
- FIG. 5 depicts an example process for editing electronic handwriting, according to aspects of the subject technology.
- FIG. 6 is a conceptual diagram illustrating an example electronic system 600 for the recognition and editing of electronic handwriting, according to aspects of the subject technology.
- the subject technology provides a software application in which a user may interact with a structured document that includes existing electronic content made up of a string of electronic characters and/or user-generated electronic handwriting (e.g., one or more lines of text or paragraphs, or drawings or symbols).
- the electronic content may be broken down as multiple segments or blocks for dynamic editing of the content.
- Each segment or block may be the smallest definable unit of text, such as a character or word, or may encompass a series of handwriting strokes or one or more continuous strokes.
- a segment may include characters, partial characters, strikeouts, lines, scribbles, underlines, insertion carets, border shapes, and the like. Accordingly, all strokes within a document are automatically clustered into blocks as the user writes. The grouping may consider the physical proximity of the strokes, the time they were created, etc.
- a textual interpretation may include or take into consideration segments that include characters, partial characters, strikeouts, lines, scribbles, underlines, insertion carets, border shapes, and the like. Often, the handwriting recognition module 141 generates multiple textual interpretations.
- the identified portion of the existing electronic content may be delineated according to a number of nodes along a given branch. For example, a first node in a branch may identify a paragraph to which the newly received segment may be assigned, and a second node along the branch may then identify a line within the paragraph to which the received segment may be assigned. Accordingly, an algorithm automatically traverses the tree along respective paths from a root node of the tree to respective leaf nodes of the tree to identify candidate portions of the existing electronic content to provide to the handwriting recognition module 141 with the new segment. Each determined candidate portion is then provided with the newly received segment of electronic handwriting to the recognition to obtain the plurality of textual interpretations of the new segment.
- the textual interpretations generated by the handwriting recognition module 141 may then be utilized by a handwriting synthesizer that, based on an analysis of existing electronic handwriting in the document, generates respective handwriting representations for each of the plurality of textual interpretations obtained from the handwriting recognition module 141 .
- Each of these electronic handwriting representations may include one or more computer-replicated glyphs substantially in a handwriting style of the existing electronic content (e.g., replicating the textual interpretation(s)).
- These handwriting representations are then applied to the content of the existing document in a hidden background process and scored based on how each respective electronic handwriting representation would change the display of the existing electronic content when displayed substantially at the position within or adjacent to the existing electronic content that was designated by the user.
- a score for a handwriting interpretation may be based on, for example, a comparison of the visualized document, including the original electronic handwriting as annotated by the user, with a visualization of the document after the interpreted handwriting representation has been applied to the document (e.g., inserted into the electronic content).
- the score may decrease, for example, if the addition of the interpreted handwriting representation causes additional lines in a paragraph or causes an additional paragraph to be added.
- the score may remain the same or increase if the boundaries of the paragraph or line into which the interpreted handwriting representation remain substantially the same.
- the system selects the best interpretation based on the ranking and updates the document accordingly.
- the existing electronic content is then modified to include the selected electronic handwriting representation located substantially at the user designated position, and displayed on the display device. Reflow of the document and updates to spacing occur in real time as the user is writing. Additionally or in the alternative, the user may delay updating of the document until editing is complete, and then manually cause the document to update by selection of an update control.
- the system After receiving a segment of electronic handwriting and updating the document as described above, the system begins to monitor for additional feedback from the user to determine whether the insertion of a selected electronic handwriting representation can be considered accepted or rejected by the user. Acceptance may be indicated by the user taking no further action with regard to the newly inserted handwriting representation. Rejection, however, may be indicated by a user modification of the representation or an undo action. If a rejection is determined, the system may select a second electronic handwriting representation corresponding to one of the textual interpretations previously provided by the handwriting recognition module 141 . For example, the system may select the interpretation corresponding to the next highest score.
- the textual interpretations obtained from the handwriting recognition module 141 may be rescored based on user input associated with the indication that the selected electronic handwriting representation was rejected. For example, the user may only cross out part of the newly annotated handwriting segment, or add to it.
- the updated handwriting segment may then be passed back through the handwriting recognition module 141 (along with selected portions of the existing electronic content, as described above), and then new scores generated based on updated newly generated handwriting representations being inserted into the document.
- the system may visually solicit feedback from the user. After scoring a textual interpretation, the system may determine that the score does not satisfy a predetermined confidence level, and then visually identify a portion of the modified electronic content corresponding to the textual interpretation as not satisfying the predetermined confidence level. For example, a portion of the electronic handwriting representation applied to the document may be highlighted. Additionally or in the alternative, before the existing electronic content is modified, the system may visually identify a position within or adjacent to the existing electronic content where the handwriting representation will be placed, and then prompt for user acceptance or rejection of the designated location.
- the system simultaneously maintains electronic content as electronic handwriting and a character-based textual representation of existing electronic content.
- the character-based textual representation is also updated to include the corresponding textual interpretation.
- the system may also include an option to display electronic handwriting simultaneously with a character-based textual representation, such that each word of the character-based textual representation is provided for display adjacent to or directly underneath a corresponding displayed word segment of the electronic handwriting.
- the subject technology enables a user to update a document simultaneously in both computer-generated text as well as electronic handwriting, without having to be concerned with the particular mode in which the document should be edited for an optimal result.
- FIG. 1 illustrates an exemplary system 100 for editing electronic text, according to aspects of the subject technology.
- System 100 includes computing device 101 , touch device 178 , network 170 , and application server 180 .
- Computing device 101 and/or touch device 178 may be coupled to application server 180 over network 170 .
- a user desiring to hand write text with touch device 178 and computing device 101 may, for example, access an application storefront supported by application server 180 to download and install touch-enabled editor application 140 onto computing device 101 .
- computing device 101 may utilize communications module 123 , for example an Ethernet adapter, wireless card or cellular modem, to communicate with application server 180 over network 170 .
- touch-enabled editor application 140 may be provided on installable media, for example on an optical disc, flash memory card, or other device.
- touch-enabled editor application 140 may be preinstalled onto computing device 101 , or touch-enabled editor application 140 may be integrated as part of an operating system of computing device 101 .
- Touch device 178 may interact with touch-enabled editor application 140 via display device 122 (e.g., by actively transmitting communications to electrodes or other receiving components in the display device, or by passively causing detectable changes such as capacitive or resistive changes in electrodes or other receiving components in the display device) and/or may interact with touch-enabled editor application 140 by receiving and transmitting signals via communications module 123 .
- One example function that may be performed by the computing device 101 is recognition of handwritten text that is input to the computing device 101 .
- a user can input handwriting to the computing device 101 for recognition using touch device 178 , including a finger or stylus, a mouse, a trackball, a pen, or the like.
- Handwritten input generally includes one or more strokes, e.g., single points or continuous lines, which individually or collectively represent one or more characters in a writing system.
- a “stroke” can form a portion of a character, one or more full characters, a word or a portion of a word, a multi-word phrase, or even a complete sentence.
- a handwriting recognition module 141 such as handwriting recognition module 141 , parses handwritten input into individual handwritten characters. The handwriting recognition module 141 determines text characters based on the handwritten characters, respectively. The determined text characters are displayed to the user.
- the recognition may be a single character at a time, multiple characters at a time, one or more words at a time, or the recognition of less than (a portion of) a single character.
- character is intended to include a single character, multiple characters (including a word, multiple words, phrases, sentences, etc.) and a portion of a single character.
- the handwritten input recognition can be performed locally (at the computing device 101 via display device 122 ), in the cloud (at a server connected to the computing device 101 via a network), or at a combination thereof. It should be appreciated that the techniques described herein as being performed at “a server” can be performed at more than one server in a distributed or parallel server arrangement. Thus, the term server as used herein is meant to include a single server and a plurality of servers working in conjunction.
- the computing device 101 may display the possible stems to a user of the device. As will be described further, the recognition module 141 may automatically select one or more stems based on a scoring algorithm and wait for further input from the user to confirm or rejects the selection. In some implementations, the computing device 101 may display a possible word indicator with a possible stem when one or more possible whole words have been identified for the possible stem. The user can then select a possible stem that is displayed with a possible word indicator. When a possible stem is selected, the computing device 101 displays possible words identified for the possible stem. The user can select one of the possible words or one of the possible stems before the recognition of the handwritten input is complete.
- the computing device 101 may alter the size of the first handwritten input that is passed to the handwriting recognition module 141 and/or is currently being recognized, for example, when the handwritten input(s) have not yet been recognized.
- computing device 101 may also display a recognition pending indicator for the user when a handwritten input is currently being recognized and/or there are one or more additional handwritten inputs to be recognized.
- FIGS. 2A and 2B depict an example handwriting recognition interface displayed on the touch display 122 , according to various implementations.
- Editor application 140 displays a handwriting interface 202 on the touch display 122 for the user to input handwriting to the computing device 101 for recognition.
- Handwriting interface 202 includes a handwriting display portion 204
- the handwriting interface 200 may also include a whole or partial keyboard, such as a QWERTY based keyboard, a T9 based keyboard, or another suitable type of interface from which the user can input spaces, returns, punctuation marks, symbols, and the like.
- the handwriting recognition interface is displayed on the touch display without an interface from which the user 108 can input spaces, returns, punctuation marks, symbols, and the like.
- the computing device 101 may generate two display portions on the touch display 122 : a first display portion 204 and optionally a second display portion 206 .
- the computing device 101 displays a handwritten input that is currently being recognized and any additional handwritten inputs that have not yet been recognized.
- the computing device 101 may display text corresponding to handwritten words and/or handwritten characters that have previously been recognized.
- a character-based textual representation of the existing electronic content displayed on a display device is maintained in memory 130 and updated with a textual interpretations of handwriting representations selected by editor application 140 .
- the character-based textual representation may be displayed in second display portion 206 , or hidden from view.
- the user may input handwriting for recognition anywhere within handwriting display portion 204 or, in some embodiments, anywhere upon the touch display 122 .
- the editor application 140 may display the handwriting input as it is input by the user in real time, during recognition of handwriting, or both. It should be understood that real time may include an acceptable amount of delay between input and display.
- the display of the text characters as the handwriting input is recognized may provide a visual indication of the progress of the recognition to the user.
- the user handwriting interface 200 may display the handwritten input within the handwriting display portion 204 .
- the user can provide handwritten input using cursive or print (also referred to as block letter). While handwriting in the English language is discussed and shown, the recognition and display techniques disclosed herein are also applicable to handwritten input in other languages.
- the updated character-based textual representation may be provided for display with the modified version of the existing electronic content on the display device in a space adjacent and/or below the inputted handwriting.
- the updated character-based textual representation including a plurality of words, each word may be provided for display adjacent to or directly underneath a corresponding displayed word segment of the modified version of the existing electronic content.
- the corresponding character-based textual representation is displayed below the handwritten characters as they are input and updated in real time.
- handwriting recognition module 141 may parse handwritten input into handwritten characters using data stored in a recognition datastore 150 .
- the editor application 140 may update what is displayed to display a representation of the handwritten input using the one or more handwritten characters.
- the handwriting recognition module 141 can recognize the handwritten characters of the handwritten input one by one. In other words, the handwriting recognition module 141 may determine text characters for the handwritten characters one handwritten character at a time. In some implementations, the handwriting recognition module 141 may recognize multiple handwritten characters of a handwritten input at a time. The order that the handwriting recognition module 141 recognizes the handwritten characters may be a logical order of reading, such as left to right for recognition of English language.
- the handwriting recognition module 141 may parse the handwritten input into various portions, such as one or more handwritten characters. For example, the handwriting recognition module 141 can parse the handwritten input “hello” into four handwritten characters that form the handwritten input. In various languages, a character may correspond to a word.
- FIG. 3 is an example reflow of characters input into display 122 , according to one or more implementations of the subject technology.
- Editor application 140 displays the text characters within the text display portion 204 as they are determined, reflowing existing content to incorporate new strokes and newly generated handwritten content.
- the user inputs the characters “butnot” via touch display 122 .
- the characters are passed to handwriting recognition module 141 , which parses the handwritten input into various portions.
- handwriting recognition module 141 determines that the inputted characters include two words “but” and “not” and return two different versions of the phrase with different space inserted between the words. Each of the versions in analyzed together with existing electronic content displayed in handwriting interface 202 and scored.
- the recognition of handwriting input may be performed wholly or in part by a remote server 180 .
- the editor application 140 may capture a digital representation of a handwritten input that is input to the touch display 122 .
- the communication module 123 may transmit the digital representation to the server 180 via a network 170 .
- the network 170 may be, for example, a cellular network, a satellite network, or another suitable type of network.
- the server 180 may include a communication module, a handwriting recognition module 141 , and a recognition datastore 150 .
- the server 500 may include additional computing components such as one or more processors, memory, a power supply, and other suitable computing components.
- the server 180 may receive the digital representation via the communication module 123 .
- the recognition module 141 may parse the digital representation into handwritten characters.
- the recognition module 141 may parse the handwritten input into handwritten characters, for example, using data stored in the recognition datastore 150 .
- the server 180 may transmit one or more representations of the handwritten characters back to computing device 101 for computing device 101 to display the handwritten characters to a user (e.g., on display device 122 ).
- the recognition module 141 may determine the text characters for the handwritten characters one by one or more than one at a time. For example, the recognition module 141 may determine the text characters for the handwritten characters using data stored in the recognition datastore 512 .
- the server 180 can transmit indicators of the text characters for the handwritten characters to the computing device 101 as the text characters are determined.
- the computing device 101 determines the text characters based on the indicators and displays the text characters to the user via the touch display 122 .
- the digital representation that the editor application 140 captures is embodied in a request context that is sent to recognition engine 142 .
- the request context may include electronic handwriting strokes currently inputted into the editor application 140 via the handwriting interface 202 , as well as a set of already recognized characters before the strokes.
- the request context may also include a set of previously recognized characters after the strokes.
- the editor application may detect that the user is attempting to insert characters between words or other characters.
- FIG. 4 depicts an example tree of content actions for recognizing electronic handwriting, according to one or more implementations of the subject technology.
- Recognition engine 142 includes a parser that generates a tree of content actions 400 for the current request context. Tree may be implemented as a data structure resident within memory 130 .
- a parent node 402 is generated for one or more strokes.
- each lower node 404 that branches from a higher level node in the tree is representative of one of a plurality of content actions that can be performed with respect to the existing electronic content to identify a portion of the existing electronic content for association with at least a portion of the new segment.
- a content action may include identifying an existing paragraph or a line of existing text, to which the new segment may be assigned. Each line, paragraph, word, or character may be selected using a nearest neighbor algorithm and/or search based on the inputted stroke(s).
- the identified portion of the existing electronic content may be delineated according to a number of nodes along a given branch.
- a first node in a branch identifies an existing paragraph to which the newly received segment may be assigned
- a second node along the branch e.g., child of the first node
- a third node identifies that the new stroke(s) likely belong to a new paragraph, and assign a new line to the stroke(s).
- an algorithm automatically traverses the tree along respective paths from a root node of the tree to respective leaf nodes of the tree to identify candidate portions of the existing electronic content to provide to the handwriting recognition module 141 with the new segment.
- Each determined candidate portion is then provided with the newly received segment of electronic handwriting to the recognition to obtain the plurality of textual interpretations of the new segment.
- handwriting recognition module 141 may generate the tree and perform this task.
- FIG. 5 depicts an example process for editing electronic handwriting, according to aspects of the subject technology.
- the various blocks of example process 500 are described herein with reference to FIGS. 1-4 , and the components and/or processes described herein.
- the one or more of the blocks of process 500 may be implemented, for example, by computing device 101 , including a processor and other components utilized by device 101 .
- one or more of the blocks may be implemented apart from other blocks, and by one or more different processors or devices.
- the blocks of example process 500 are described as occurring in serial, or linearly. However, multiple blocks of example process 500 may occur in parallel.
- the blocks of example process 500 need not be performed in the order shown and/or one or more of the blocks of example process 500 need not be performed.
- a new segment of electronic handwriting is received by editor application 140 for display at a user designated position within or adjacent to existing electronic content displayed on display device 122 ( 502 ). For example, a user may electronically draw one or more strokes within handwriting display portion 204 of handwriting interface 200 .
- editor application 140 provides the received new segment to handwriting recognition module 141 to obtain a plurality of textual interpretations of the new segment ( 504 ).
- Handwriting recognition module 141 generates the textual interpretations and passes them back to editor application 140 .
- editor application 140 may generate a tree of content actions for the new segment. As described previously, a root node may first be created for the new segment, and each lower node that branches from a higher level node (e.g., starting at the root node) may be representative of one of a plurality of content actions that can be performed with respect to the existing electronic content to identify a portion of the existing electronic content for association with at least a portion of the new segment. Using this mechanism, editor application 140 may determine, automatically, without user intervention, candidate portions of the existing electronic content to provide to the handwriting recognition module 141 with the new segment.
- the candidate portions are generated based on automatically traversing the tree along respective paths from a root node of the tree to respective leaf nodes of the tree and identifying the portions of the existing electronic content associated with the content actions represented by nodes along the path.
- the new segment is then provided with each determined candidate portion of the existing electronic content to the handwriting recognition module to obtain the plurality of textual interpretations of the new segment.
- the new segment of electronic handwriting received at display 122 may modify an existing segment of electronic handwriting of the existing electronic content.
- the existing segment of electronic handwriting may be provided with the new segment to the handwriting recognition module to obtain the plurality of textual interpretations.
- Editor application 140 then generates respective electronic handwriting representations for the plurality of textual interpretations obtained from the handwriting recognition module 141 ( 506 ).
- the electronic handwriting representations may be generated using handwriting synthesis, such that the electronic handwriting representations include one or more computer-replicated glyphs substantially in a handwriting style of the existing electronic content.
- the artificial handwriting generated by editor application 140 may be based on the user's own handwriting samples already input into editor application 140 .
- Editor application 140 may match the style, font size, and stroke characteristics of the user.
- the generation of electronic handwriting representations by editor application 140 includes editor application 140 forwarding the textual interpretations to a handwriting synthesis engine (not shown).
- the generated handwriting representations may not be (e.g., immediately) displayed to the user.
- editor application 140 passes the handwriting representations, along with at least a portion of the existing electronic content, to scoring module 142 .
- Editor application 140 in connection with scoring module 142 , assigns scores to the textual interpretations obtained from handwriting recognition module 141 .
- Each textual interpretation obtained from the handwriting recognition module 141 is scored based on how its corresponding electronic handwriting representation would change the display of the existing electronic content when the electronic handwriting representation is displayed substantially at the user designated position within or adjacent to the existing electronic content ( 508 ).
- the scoring module 142 may, without display, analyze the existing content with a selected handwriting representation inserted to determine how the existing content changes with the insertion.
- a score is calculated based on predetermined factors such as changes to: word spacing, baseline alignment, character kerning, character morphing, number of lines on a current page, word or line or paragraph reflow, and the like. For example, an increase or reduction in word spacing or kerning may negatively impact the score proportional to the increase or reduction amount. Scores may be represented as a value having a range, for example, from 0 to 1, or from ⁇ 1 to 1 with 0 being a neutral or status quo value.
- Editor application 140 selects, based on the scoring, an electronic handwriting representation corresponding to a respective textual interpretation of the plurality of textual interpretations ( 510 ).
- Editor application 140 modifies, for display on display device 122 , the existing electronic content to include the selected electronic handwriting representation located substantially at the user designated position ( 512 ).
- the existing electronic content is modified to accommodate the selected electronic handwriting representation by way of a dynamic reflow of at least a portion of the existing electronic content.
- editor application 140 displays one or more visual indicators of the progress of the recognition of the handwritten input.
- computing device 101 may receive a handwriting (or character) representation corresponding to a first handwritten input, and display the handwriting (or character) representation in addition to updating the one or more visual indicators of the progress.
- Editor application 140 may receive a handwriting (or character) representation corresponding to the second handwritten input.
- Editor application 140 displays the handwriting (or character) representation corresponding to the second handwritten input and updates visual indicator(s) of the progress of the recognition.
- Editor application 140 may continue to receive handwriting (or character) representation, if any, (e.g., from handwriting recognition module 141 or server 180 ) display the determined text characters, and update visual indicator(s) displayed as they are received.
- editor application 140 may receive an indicator from recognition module 141 (or server 180 ) that the recognition of the handwritten input is complete.
- a visual indicator is elevated to a different color or otherwise highlighted to signal that the predetermined confidence level (e.g., a threshold score) was not met.
- a score assigned to a selected handwriting representation may be determined to have not met a predetermined confidence level (e.g., if only one representation was returned).
- Editor application 140 may then visually identify the portion of the modified electronic content corresponding to the selected electronic handwriting representation as not satisfying the predetermined confidence level.
- editor application 140 incorporates a feedback loop that adjusts scoring and selection of handwriting representations based on input (or lack of input) from the user.
- Editor application 140 may visually designate, before modifying the existing electronic content, a computer designated position within or adjacent to the existing electronic content corresponding to an insertion point of the selected electronic handwriting.
- Editor application 140 monitors for an indication of user acceptance or rejection of the selected electronic handwriting representation.
- editor application 140 selects, as the selected electronic handwriting representation, a second electronic handwriting representation corresponding to a second textural interpretation of the plurality of textual interpretations.
- editor application 140 may select the representation having the next highest score. In some implementations, editor application 140 may rescore the representations as described above based on a new set of factors and select the highest representation. On an indication of rejection by the user, the current representation is replaced with the new representation. Editor application 140 may consider the absence of an indication of rejection as acceptance of the representation, for example, after a predetermined period of time (e.g., 1 or 2 s).
- editor application 140 may select, a second electronic handwriting representation corresponding to a second textural interpretation of the plurality of textual interpretations, and modify, for display on the display device, the existing electronic content to include the second electronic handwriting representation located substantially at the user designated position.
- editor application 140 may rescore the textual interpretations obtained using the handwriting recognition module 141 based on user input associated with the indication that the selected electronic handwriting representation was rejected and based on how each respective electronic handwriting representation would change the display of the existing electronic content when the respective electronic handwriting representation is displayed substantially at the user designated position within or adjacent to the existing electronic content.
- the second electronic handwriting representation may then be selected based on the rescoring.
- example 500 may also be implemented as software processes that are specified as a set of instructions recorded on a computer readable storage medium (also referred to as computer readable medium), and may be executed automatically (e.g., without user intervention).
- a computer readable storage medium also referred to as computer readable medium
- these instructions are executed by one or more processing unit(s) (e.g., one or more processors, cores of processors, or other processing units), they cause the processing unit(s) to perform the actions indicated in the instructions.
- processing unit(s) e.g., one or more processors, cores of processors, or other processing units
- Examples of computer readable media include, but are not limited to, CD-ROMs, flash drives, RAM chips, hard drives, EPROMs, etc.
- the computer readable media does not include carrier waves and electronic signals passing wirelessly or over wired connections.
- the term “software” is meant to include, where appropriate, firmware residing in read-only memory or applications stored in magnetic storage, which can be read into memory for processing by a processor. Also, in some implementations, multiple software aspects of the subject disclosure can be implemented as sub-parts of a larger program while remaining distinct software aspects of the subject disclosure. In some implementations, multiple software aspects can also be implemented as separate programs. Finally, any combination of separate programs that together implement a software aspect described here is within the scope of the subject disclosure. In some implementations, the software programs, when installed to operate on one or more electronic systems, define one or more specific machine implementations that execute and perform the operations of the software programs.
- a computer program (also known as a program, software, software application, script, or code) can be written in any form of programming language, including compiled or interpreted languages, declarative or procedural languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, object, or other unit suitable for use in a computing environment.
- a computer program may, but need not, correspond to a file in a file system.
- a program can be stored in a portion of a file that holds other programs or data (e.g., one or more scripts stored in a markup language document), in a single file dedicated to the program in question, or in multiple coordinated files (e.g., files that store one or more modules, sub programs, or portions of code).
- a computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.
- Electronic system 600 may include various types of computer readable media and interfaces for various other types of computer readable media.
- electronic system 600 includes a bus 608 , processing unit(s) 612 , a system memory 604 , a read-only memory (ROM) 610 , a permanent storage device 602 , an input device interface 614 , an output device interface 606 , and one or more network interfaces 616 .
- processing unit(s) 612 includes a bus 608 , processing unit(s) 612 , a system memory 604 , a read-only memory (ROM) 610 , a permanent storage device 602 , an input device interface 614 , an output device interface 606 , and one or more network interfaces 616 .
- ROM read-only memory
- permanent storage device 602 an input device interface 614
- an output device interface 606 an output device interface 606
- network interfaces 616 may include or be integrated with other computing devices or circuitry for operation of the various components and processes previously described.
- Bus 608 collectively represents all system, peripheral, and chipset buses that communicatively connect the numerous internal devices of electronic system 600 .
- bus 608 communicatively connects processing unit(s) 612 with ROM 610 , system memory 604 , and permanent storage device 602 .
- processing unit(s) 612 retrieves instructions to execute and data to process in order to execute the processes of the subject disclosure.
- the processing unit(s) can be a single processor or a multi-core processor in different implementations.
- ROM 610 stores static data and instructions that are needed by processing unit(s) 612 and other modules of the electronic system.
- Permanent storage device 602 is a read-and-write memory device. This device is a non-volatile memory unit that stores instructions and data even when electronic system 600 is off. Some implementations of the subject disclosure use a mass-storage device (such as a magnetic or optical disk and its corresponding disk drive) as permanent storage device 602 .
- system memory 604 is a read-and-write memory device. However, unlike storage device 602 , system memory 604 is a volatile read-and-write memory, such a random access memory. System memory 604 stores some of the instructions and data that the processor needs at runtime. In some implementations, the processes of the subject disclosure are stored in system memory 604 , permanent storage device 602 , and/or ROM 610 . From these various memory units, processing unit(s) 612 retrieves instructions to execute and data to process in order to execute the processes of some implementations.
- Bus 608 also connects to input and output device interfaces 614 and 606 .
- Input device interface 614 enables the user to communicate information and select commands to the electronic system.
- Input devices used with input device interface 614 include, e.g., alphanumeric keyboards and pointing devices (also called “cursor control devices”).
- Output device interfaces 606 enables, e.g., the display of images generated by the electronic system 600 .
- Output devices used with output device interface 606 include, e.g., printers and display devices, such as cathode ray tubes (CRT) or liquid crystal displays (LCD). Some implementations include devices such as a touchscreen that functions as both input and output devices.
- CTR cathode ray tubes
- LCD liquid crystal displays
- bus 608 also couples electronic system 600 to a network (not shown) through network interfaces 616 .
- Network interfaces 616 may include, e.g., a wireless access point (e.g., Bluetooth or WiFi) or radio circuitry for connecting to a wireless access point.
- Network interfaces 616 may also include hardware (e.g., Ethernet hardware) for connecting the computer to a part of a network of computers such as a local area network (“LAN”), a wide area network (“WAN”), wireless LAN, or an Intranet, or a network of networks, such as the Internet.
- LAN local area network
- WAN wide area network
- Internet Intranet
- Some implementations include electronic components, such as microprocessors, storage and memory that store computer program instructions in a machine-readable or computer-readable medium (alternatively referred to as computer-readable storage media, machine-readable media, or machine-readable storage media).
- computer-readable media include RAM, ROM, read-only compact discs (CD-ROM), recordable compact discs (CD-R), rewritable compact discs (CD-RW), read-only digital versatile discs (e.g., DVD-ROM, dual-layer DVD-ROM), a variety of recordable/rewritable DVDs (e.g., DVD-RAM, DVD-RW, DVD+RW, etc.), flash memory (e.g., SD cards, mini-SD cards, micro-SD cards, etc.), magnetic and/or solid state hard drives, read-only and recordable Blu-Ray® discs, ultra density optical discs, any other optical or magnetic media, and floppy disks.
- CD-ROM compact discs
- CD-R recordable compact discs
- ASICs application specific integrated circuits
- FPGAs field programmable gate arrays
- implementations of the subject matter described in this specification can be implemented on a computer having a display device, e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to the user and a keyboard and a pointing device, e.g., a mouse or a trackball, by which the user can provide input to the computer.
- a display device e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor
- a keyboard and a pointing device e.g., a mouse or a trackball
- Other kinds of devices can be used to provide for interaction with a user as well; e.g., feedback provided to the user can be any form of sensory feedback, e.g., visual feedback, auditory feedback, or tactile feedback; and input from the user can be received in any form, including acoustic, speech, or tactile input.
- a computer can interact with a user by sending documents to and receiving documents from
- Embodiments of the subject matter described in this specification can be implemented in a computing system that includes a back end component, e.g., as a data server, or that includes a middleware component, e.g., an application server, or that includes a front end component, e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the subject matter described in this specification, or any combination of one or more such back end, middleware, or front end components.
- the components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network.
- Examples of communication networks include a local area network (“LAN”) and a wide area network (“WAN”), an inter-network (e.g., the Internet), and peer-to-peer networks (e.g., ad hoc peer-to-peer networks).
- LAN local area network
- WAN wide area network
- inter-network e.g., the Internet
- peer-to-peer networks e.g., ad hoc peer-to-peer networks.
- the computing system can include clients and servers.
- a client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other.
- a server transmits data (e.g., an HTML, page) to a client device (e.g., for purposes of displaying data to and receiving user input from a user interacting with the client device).
- client device e.g., for purposes of displaying data to and receiving user input from a user interacting with the client device.
- Data generated at the client device e.g., a result of the user interaction
- the term website may include any aspect of a website, including one or more web pages, one or more servers used to host or store web related content, etc. Accordingly, the term website may be used interchangeably with the terms web page and server.
- the predicate words “configured to”, “operable to”, and “programmed to” do not imply any particular tangible or intangible modification of a subject, but, rather, are intended to be used interchangeably.
- a processor configured to monitor and control an operation or a component may also mean the processor being programmed to monitor and control the operation or the processor being operable to monitor and control the operation.
- a processor configured to execute code can be construed as a processor programmed to execute code or operable to execute code.
- automatic may include performance by a computer or machine without user intervention; for example, by instructions responsive to a predicate action by the computer or machine or other initiation mechanism.
- the word “example” is used herein to mean “serving as an example or illustration.” Any aspect or design described herein as “example” is not necessarily to be construed as preferred or advantageous over other aspects or designs.
- a phrase such as an “aspect” does not imply that such aspect is essential to the subject technology or that such aspect applies to all configurations of the subject technology.
- a disclosure relating to an aspect may apply to all configurations, or one or more configurations.
- An aspect may provide one or more examples.
- a phrase such as an aspect may refer to one or more aspects and vice versa.
- a phrase such as an “embodiment” does not imply that such embodiment is essential to the subject technology or that such embodiment applies to all configurations of the subject technology.
- a disclosure relating to an embodiment may apply to all embodiments, or one or more embodiments.
- An embodiment may provide one or more examples.
- a phrase such as an “embodiment” may refer to one or more embodiments and vice versa.
- a phrase such as a “configuration” does not imply that such configuration is essential to the subject technology or that such configuration applies to all configurations of the subject technology.
- a disclosure relating to a configuration may apply to all configurations, or one or more configurations.
- a configuration may provide one or more examples.
- a phrase such as a “configuration” may refer to one or more configurations and vice versa.
Abstract
Description
- This application is a continuation of International Application No. PCT/US2019/051333, filed Sep. 19, 2019 which claims benefit of U.S. application Ser. No. 16/273,014, filed Feb. 11, 2019, the entire contents of each of which are hereby incorporated by reference.
- The editing of existing electronic documents is traditionally done by way of a traditional keyboard and mouse input. For example, a user may select a portion of the document to be edited and provide input via the keyboard to erase, add to, or modify content within the document. Certain software applications allow use of a stylus to add handwritten notes to documents. However, in these applications, electronic handwriting applied to a document is generally static. Either the input is permanently displayed as electronic handwriting, or the electronic handwriting is converted in its entirety to character-based content. If a mistake is made, the user must undo the last action and redraw the notes in the document. In other words, editing of a document is accomplished after the entire document is converted to computer-based text form, and all of the user-generated content is ultimately displayed in text form.
- Aspects of the subject technology provide systems and methods for providing interactive editing of electronic text using electronic handwriting. A goal of the electronic handwriting is to encourage creativity and freeform mixed layouts where drawings, figures, and text may be placed anywhere in the document. To that end, the subject technology provide a computer-implemented method that includes receiving a new segment of electronic handwriting for display at a user designated position within or adjacent to existing electronic content displayed on a display device, providing the received new segment to a handwriting recognition module to obtain a plurality of textual interpretations of the new segment, generating respective electronic handwriting representations for the plurality of textual interpretations obtained from the handwriting recognition module, scoring the plurality of textual interpretations obtained from the handwriting recognition module based on how each respective electronic handwriting representation would change the display of the existing electronic content when the respective electronic handwriting representation is displayed substantially at the user designated position within or adjacent to the existing electronic content, selecting, based on the scoring, an electronic handwriting representation corresponding to a respective textual interpretation of the plurality of textual interpretations, and modifying, for display on the display device, the existing electronic content to include the selected electronic handwriting representation located substantially at the user designated position. Other aspects include corresponding systems, apparatuses, and computer program products for implementation of the computer-implemented method.
- Further aspects of the subject technology, features, and advantages, as well as the structure and operation of various aspects of the subject technology are described in detail below with reference to accompanying drawings.
- Aspects of the subject technology are described with reference to the accompanying drawings. In the drawings, like reference numbers may indicate identical or functionally similar elements.
-
FIG. 1 illustrates an exemplary system for editing electronic text, according to aspects of the subject technology. -
FIGS. 2A and 2B depict an example handwriting recognition interface displayed on the touch display, according to aspects of the subject technology. -
FIG. 3 is an example reflow of characters input into a display, according to aspects of the subject technology. -
FIG. 4 depicts an example tree of content actions for recognizing electronic handwriting, according to aspects of the subject technology. -
FIG. 5 depicts an example process for editing electronic handwriting, according to aspects of the subject technology. -
FIG. 6 is a conceptual diagram illustrating an exampleelectronic system 600 for the recognition and editing of electronic handwriting, according to aspects of the subject technology. - While aspects of the subject technology are described herein with reference to illustrative examples for particular applications, it should be understood that the subject technology is not limited to those particular applications. Those skilled in the art with access to the teachings provided herein will recognize additional modifications, applications, and aspects within the scope thereof and additional fields in which the subject technology would be of significant utility.
- There is a need to keep user-generated content in handwriting and to allow the interactive editing of the electronic handwriting content. There is also a need to have a user interface that allows interaction between computer-based text and handwriting, all while maintaining a natural flow of a written document.
- The subject technology provides a software application in which a user may interact with a structured document that includes existing electronic content made up of a string of electronic characters and/or user-generated electronic handwriting (e.g., one or more lines of text or paragraphs, or drawings or symbols). The electronic content may be broken down as multiple segments or blocks for dynamic editing of the content. Each segment or block may be the smallest definable unit of text, such as a character or word, or may encompass a series of handwriting strokes or one or more continuous strokes. A segment may include characters, partial characters, strikeouts, lines, scribbles, underlines, insertion carets, border shapes, and the like. Accordingly, all strokes within a document are automatically clustered into blocks as the user writes. The grouping may consider the physical proximity of the strokes, the time they were created, etc.
- Using a pointing device such as a stylus or other touch device, a user may add a series of strokes to represent a word or some other electronic handwriting annotation to the document at a user-designated positon. The word or stroke may modify or add to existing electronic content. The system responds to the new handwriting interaction by generating all possible document interpretations of the interaction, and ranks the document interpretations. In this regard, when new segments of electronic handwriting are received, they are provided to a
handwriting recognition module 141. Thehandwriting recognition module 141 analyzes each segment and generates a textual interpretation of the segment. In this regard, a textual interpretation may include or take into consideration segments that include characters, partial characters, strikeouts, lines, scribbles, underlines, insertion carets, border shapes, and the like. Often, thehandwriting recognition module 141 generates multiple textual interpretations. - To generate the interpretations, a parser dynamically generates a tree of content actions for the newly received segment of electronic handwriting. Each lower node that branches from a higher level node in the tree is representative of one of a plurality of content actions that can be performed with respect to the existing electronic content to identify a portion of the existing electronic content for association with at least a portion of the new segment. For example, a content action may include identifying an existing paragraph or a line of existing text, to which the new segment may be assigned.
- The identified portion of the existing electronic content may be delineated according to a number of nodes along a given branch. For example, a first node in a branch may identify a paragraph to which the newly received segment may be assigned, and a second node along the branch may then identify a line within the paragraph to which the received segment may be assigned. Accordingly, an algorithm automatically traverses the tree along respective paths from a root node of the tree to respective leaf nodes of the tree to identify candidate portions of the existing electronic content to provide to the
handwriting recognition module 141 with the new segment. Each determined candidate portion is then provided with the newly received segment of electronic handwriting to the recognition to obtain the plurality of textual interpretations of the new segment. - The textual interpretations generated by the
handwriting recognition module 141 may then be utilized by a handwriting synthesizer that, based on an analysis of existing electronic handwriting in the document, generates respective handwriting representations for each of the plurality of textual interpretations obtained from thehandwriting recognition module 141. Each of these electronic handwriting representations may include one or more computer-replicated glyphs substantially in a handwriting style of the existing electronic content (e.g., replicating the textual interpretation(s)). These handwriting representations are then applied to the content of the existing document in a hidden background process and scored based on how each respective electronic handwriting representation would change the display of the existing electronic content when displayed substantially at the position within or adjacent to the existing electronic content that was designated by the user. - A score for a handwriting interpretation may be based on, for example, a comparison of the visualized document, including the original electronic handwriting as annotated by the user, with a visualization of the document after the interpreted handwriting representation has been applied to the document (e.g., inserted into the electronic content). The score may decrease, for example, if the addition of the interpreted handwriting representation causes additional lines in a paragraph or causes an additional paragraph to be added. The score may remain the same or increase if the boundaries of the paragraph or line into which the interpreted handwriting representation remain substantially the same.
- The system then selects the best interpretation based on the ranking and updates the document accordingly. The existing electronic content is then modified to include the selected electronic handwriting representation located substantially at the user designated position, and displayed on the display device. Reflow of the document and updates to spacing occur in real time as the user is writing. Additionally or in the alternative, the user may delay updating of the document until editing is complete, and then manually cause the document to update by selection of an update control.
- In some implementations, electronic handwriting representations may not be generated (or desired), and scoring may be undertaken based on the plurality of textual interpretations obtained from the
handwriting recognition module 141. In this regard, the system may convert the electronic handwriting received from the user, convert the handwriting to electronic text, and dynamically insert the newly converted electronic text into the existing electronic content after the scored textual interpretation is selected. - Feedback Loop
- After receiving a segment of electronic handwriting and updating the document as described above, the system begins to monitor for additional feedback from the user to determine whether the insertion of a selected electronic handwriting representation can be considered accepted or rejected by the user. Acceptance may be indicated by the user taking no further action with regard to the newly inserted handwriting representation. Rejection, however, may be indicated by a user modification of the representation or an undo action. If a rejection is determined, the system may select a second electronic handwriting representation corresponding to one of the textual interpretations previously provided by the
handwriting recognition module 141. For example, the system may select the interpretation corresponding to the next highest score. In some implementations, the textual interpretations obtained from thehandwriting recognition module 141 may be rescored based on user input associated with the indication that the selected electronic handwriting representation was rejected. For example, the user may only cross out part of the newly annotated handwriting segment, or add to it. The updated handwriting segment may then be passed back through the handwriting recognition module 141 (along with selected portions of the existing electronic content, as described above), and then new scores generated based on updated newly generated handwriting representations being inserted into the document. - If the system is unable to obtain a certain confidence level for new handwriting input, the system may visually solicit feedback from the user. After scoring a textual interpretation, the system may determine that the score does not satisfy a predetermined confidence level, and then visually identify a portion of the modified electronic content corresponding to the textual interpretation as not satisfying the predetermined confidence level. For example, a portion of the electronic handwriting representation applied to the document may be highlighted. Additionally or in the alternative, before the existing electronic content is modified, the system may visually identify a position within or adjacent to the existing electronic content where the handwriting representation will be placed, and then prompt for user acceptance or rejection of the designated location.
- Additional Features
- The system simultaneously maintains electronic content as electronic handwriting and a character-based textual representation of existing electronic content. When an electronic handwriting representation is added to the document, the character-based textual representation is also updated to include the corresponding textual interpretation. The system may also include an option to display electronic handwriting simultaneously with a character-based textual representation, such that each word of the character-based textual representation is provided for display adjacent to or directly underneath a corresponding displayed word segment of the electronic handwriting.
- The foregoing features, which are described further below, provide the technical effect of enabling interaction between computer-based text and handwriting, all while maintaining a natural flow of a written document. In this regard, the subject technology enables a user to update a document simultaneously in both computer-generated text as well as electronic handwriting, without having to be concerned with the particular mode in which the document should be edited for an optimal result.
-
FIG. 1 illustrates anexemplary system 100 for editing electronic text, according to aspects of the subject technology.System 100 includescomputing device 101,touch device 178,network 170, andapplication server 180.Computing device 101 and/ortouch device 178 may be coupled toapplication server 180 overnetwork 170. -
Computing device 101 includes processor 121, one or more input/output components such asdisplay device 122, communications module 123, andmemory 130.Memory 130 includes touch-enablededitor application 140, which may include ahandwriting recognition module 141 and ascoring module 142. - In aspects of the subject technology,
computing device 101 is a touch-enabled device that may receive touch input from a finger or other instrument viadisplay device 122. For example,computing device 101 may be a desktop all-in-one computer, tablet or convertible computer, laptop computer, smart phone, portable gaming console, or other device having adisplay device 122 supporting electronic pen input. - In one example, touch input is used to refer generally to input from a
touch device 178, which may be implemented as a finger, or an electronic pen or a stylus that can interface withdisplay device 122 ofcomputing device 101. For example,touch device 178 may be an active device that includes processing circuitry, memory, and/or one or more applications stored in the pen device memory, or may be a passive device having a material composition configured to be detectable by circuitry withindisplay device 122. For example, a passive pen device may interface with capacitive or resistive touchscreens, display digitizers, peripheral tablet devices, or other input devices coupled to or integrated withdisplay device 122. In some aspects of the subject technology,display device 122 may correspond to a display projector or augmented reality eyewear, in whichcase touch device 178 be implemented as an air pen that provides pen input without contacting a physical surface. - A user desiring to hand write text with
touch device 178 andcomputing device 101 may, for example, access an application storefront supported byapplication server 180 to download and install touch-enablededitor application 140 ontocomputing device 101. Thus,computing device 101 may utilize communications module 123, for example an Ethernet adapter, wireless card or cellular modem, to communicate withapplication server 180 overnetwork 170. In aspects of the subject technology, touch-enablededitor application 140 may be provided on installable media, for example on an optical disc, flash memory card, or other device. In other aspects of the subject technology, touch-enablededitor application 140 may be preinstalled ontocomputing device 101, or touch-enablededitor application 140 may be integrated as part of an operating system ofcomputing device 101. -
Touch device 178 may interact with touch-enablededitor application 140 via display device 122 (e.g., by actively transmitting communications to electrodes or other receiving components in the display device, or by passively causing detectable changes such as capacitive or resistive changes in electrodes or other receiving components in the display device) and/or may interact with touch-enablededitor application 140 by receiving and transmitting signals via communications module 123. - Scoring
module 142, may be included with touch-enablededitor application 140 or may be operably connected toapplication 140, for example, as a local plug-in or a web-application located at a server and accessible via a web-based API. Touch-enablededitor application 140 may provide a user with the ability to enter handwritten text and/or drawings along with an option to digitize and/or clean up the handwritten input after entry. Touch-enablededitor application 140 may also provide a user with other types of input options, such as options to input content from a keyboard and/or options for insertion of objects such as images, videos, or other figures, via a file browser or drag-and-drop operation. - One example function that may be performed by the
computing device 101 is recognition of handwritten text that is input to thecomputing device 101. A user can input handwriting to thecomputing device 101 for recognition usingtouch device 178, including a finger or stylus, a mouse, a trackball, a pen, or the like. - Handwritten input generally includes one or more strokes, e.g., single points or continuous lines, which individually or collectively represent one or more characters in a writing system. A “stroke” can form a portion of a character, one or more full characters, a word or a portion of a word, a multi-word phrase, or even a complete sentence. A
handwriting recognition module 141, such ashandwriting recognition module 141, parses handwritten input into individual handwritten characters. Thehandwriting recognition module 141 determines text characters based on the handwritten characters, respectively. The determined text characters are displayed to the user. The recognition may be a single character at a time, multiple characters at a time, one or more words at a time, or the recognition of less than (a portion of) a single character. Thus, when the description herein discusses the recognition of handwritten input to determine a “character” it should be understood that the term “character” is intended to include a single character, multiple characters (including a word, multiple words, phrases, sentences, etc.) and a portion of a single character. - The handwritten input recognition can be performed locally (at the
computing device 101 via display device 122), in the cloud (at a server connected to thecomputing device 101 via a network), or at a combination thereof. It should be appreciated that the techniques described herein as being performed at “a server” can be performed at more than one server in a distributed or parallel server arrangement. Thus, the term server as used herein is meant to include a single server and a plurality of servers working in conjunction. - In one or more implementations, while a handwritten input is being recognized, possible stems of a handwritten word represented by the handwritten input and possible whole words for one or more possible stems can be identified. The
computing device 101 may display the possible stems to a user of the device. As will be described further, therecognition module 141 may automatically select one or more stems based on a scoring algorithm and wait for further input from the user to confirm or rejects the selection. In some implementations, thecomputing device 101 may display a possible word indicator with a possible stem when one or more possible whole words have been identified for the possible stem. The user can then select a possible stem that is displayed with a possible word indicator. When a possible stem is selected, thecomputing device 101 displays possible words identified for the possible stem. The user can select one of the possible words or one of the possible stems before the recognition of the handwritten input is complete. - If the user begins inputting another handwritten input while a handwritten input is being recognized, the
computing device 101 may alter the size of the first handwritten input that is passed to thehandwriting recognition module 141 and/or is currently being recognized, for example, when the handwritten input(s) have not yet been recognized. In some implementations,computing device 101 may also display a recognition pending indicator for the user when a handwritten input is currently being recognized and/or there are one or more additional handwritten inputs to be recognized. -
FIGS. 2A and 2B depict an example handwriting recognition interface displayed on thetouch display 122, according to various implementations.Editor application 140 displays ahandwriting interface 202 on thetouch display 122 for the user to input handwriting to thecomputing device 101 for recognition.Handwriting interface 202 includes ahandwriting display portion 204, thehandwriting interface 200 may also include a whole or partial keyboard, such as a QWERTY based keyboard, a T9 based keyboard, or another suitable type of interface from which the user can input spaces, returns, punctuation marks, symbols, and the like. In one example, the handwriting recognition interface is displayed on the touch display without an interface from which the user 108 can input spaces, returns, punctuation marks, symbols, and the like. - As depicted in
FIG. 2A , in some implementations, thecomputing device 101 may generate two display portions on the touch display 122: afirst display portion 204 and optionally asecond display portion 206. In the first display portion, thecomputing device 101 displays a handwritten input that is currently being recognized and any additional handwritten inputs that have not yet been recognized. In the second display portion, thecomputing device 101 may display text corresponding to handwritten words and/or handwritten characters that have previously been recognized. In this regard, a character-based textual representation of the existing electronic content displayed on a display device is maintained inmemory 130 and updated with a textual interpretations of handwriting representations selected byeditor application 140. The character-based textual representation may be displayed insecond display portion 206, or hidden from view. - The user may input handwriting for recognition anywhere within
handwriting display portion 204 or, in some embodiments, anywhere upon thetouch display 122. Theeditor application 140 may display the handwriting input as it is input by the user in real time, during recognition of handwriting, or both. It should be understood that real time may include an acceptable amount of delay between input and display. The display of the text characters as the handwriting input is recognized may provide a visual indication of the progress of the recognition to the user. - Once the user provides a handwritten input, the
user handwriting interface 200 may display the handwritten input within thehandwriting display portion 204. The user can provide handwritten input using cursive or print (also referred to as block letter). While handwriting in the English language is discussed and shown, the recognition and display techniques disclosed herein are also applicable to handwritten input in other languages. - In some implementations, the updated character-based textual representation may be provided for display with the modified version of the existing electronic content on the display device in a space adjacent and/or below the inputted handwriting. As depicted in
FIG. 2B , the updated character-based textual representation including a plurality of words, each word may be provided for display adjacent to or directly underneath a corresponding displayed word segment of the modified version of the existing electronic content. As new strokes are recognized the corresponding character-based textual representation is displayed below the handwritten characters as they are input and updated in real time. - With further reference to
FIG. 1 ,handwriting recognition module 141 may parse handwritten input into handwritten characters using data stored in arecognition datastore 150. Theeditor application 140 may update what is displayed to display a representation of the handwritten input using the one or more handwritten characters. - Based on data stored in the
recognition datastore 150, thehandwriting recognition module 141 can recognize the handwritten characters of the handwritten input one by one. In other words, thehandwriting recognition module 141 may determine text characters for the handwritten characters one handwritten character at a time. In some implementations, thehandwriting recognition module 141 may recognize multiple handwritten characters of a handwritten input at a time. The order that thehandwriting recognition module 141 recognizes the handwritten characters may be a logical order of reading, such as left to right for recognition of English language. - The
handwriting recognition module 141 may parse the handwritten input into various portions, such as one or more handwritten characters. For example, thehandwriting recognition module 141 can parse the handwritten input “hello” into four handwritten characters that form the handwritten input. In various languages, a character may correspond to a word. -
FIG. 3 is an example reflow of characters input intodisplay 122, according to one or more implementations of the subject technology.Editor application 140 displays the text characters within thetext display portion 204 as they are determined, reflowing existing content to incorporate new strokes and newly generated handwritten content. In the depicted example, the user inputs the characters “butnot” viatouch display 122. The characters are passed tohandwriting recognition module 141, which parses the handwritten input into various portions. Here,handwriting recognition module 141 determines that the inputted characters include two words “but” and “not” and return two different versions of the phrase with different space inserted between the words. Each of the versions in analyzed together with existing electronic content displayed inhandwriting interface 202 and scored. - With reference to
FIG. 1 , the recognition of handwriting input may be performed wholly or in part by aremote server 180. Theeditor application 140 may capture a digital representation of a handwritten input that is input to thetouch display 122. The communication module 123 may transmit the digital representation to theserver 180 via anetwork 170. Thenetwork 170 may be, for example, a cellular network, a satellite network, or another suitable type of network. Theserver 180 may include a communication module, ahandwriting recognition module 141, and arecognition datastore 150. It should be appreciated that theserver 500 may include additional computing components such as one or more processors, memory, a power supply, and other suitable computing components. - The
server 180 may receive the digital representation via the communication module 123. Therecognition module 141 may parse the digital representation into handwritten characters. Therecognition module 141 may parse the handwritten input into handwritten characters, for example, using data stored in therecognition datastore 150. Theserver 180 may transmit one or more representations of the handwritten characters back tocomputing device 101 forcomputing device 101 to display the handwritten characters to a user (e.g., on display device 122). - The
recognition module 141 may determine the text characters for the handwritten characters one by one or more than one at a time. For example, therecognition module 141 may determine the text characters for the handwritten characters using data stored in therecognition datastore 512. Theserver 180 can transmit indicators of the text characters for the handwritten characters to thecomputing device 101 as the text characters are determined. Thecomputing device 101 determines the text characters based on the indicators and displays the text characters to the user via thetouch display 122. - The digital representation that the
editor application 140 captures is embodied in a request context that is sent torecognition engine 142. In this regard, the request context may include electronic handwriting strokes currently inputted into theeditor application 140 via thehandwriting interface 202, as well as a set of already recognized characters before the strokes. The request context may also include a set of previously recognized characters after the strokes. For example, the editor application may detect that the user is attempting to insert characters between words or other characters. -
FIG. 4 depicts an example tree of content actions for recognizing electronic handwriting, according to one or more implementations of the subject technology.Recognition engine 142 includes a parser that generates a tree ofcontent actions 400 for the current request context. Tree may be implemented as a data structure resident withinmemory 130. Aparent node 402 is generated for one or more strokes. As described previously, eachlower node 404 that branches from a higher level node in the tree is representative of one of a plurality of content actions that can be performed with respect to the existing electronic content to identify a portion of the existing electronic content for association with at least a portion of the new segment. For example, a content action may include identifying an existing paragraph or a line of existing text, to which the new segment may be assigned. Each line, paragraph, word, or character may be selected using a nearest neighbor algorithm and/or search based on the inputted stroke(s). - The identified portion of the existing electronic content may be delineated according to a number of nodes along a given branch. In the depicted example, a first node in a branch identifies an existing paragraph to which the newly received segment may be assigned, and a second node along the branch (e.g., child of the first node) identifies a line within the paragraph to which the received segment may be assigned. A third node (child of the parent) identifies that the new stroke(s) likely belong to a new paragraph, and assign a new line to the stroke(s). Accordingly, an algorithm automatically traverses the tree along respective paths from a root node of the tree to respective leaf nodes of the tree to identify candidate portions of the existing electronic content to provide to the
handwriting recognition module 141 with the new segment. Each determined candidate portion is then provided with the newly received segment of electronic handwriting to the recognition to obtain the plurality of textual interpretations of the new segment. In one or more implementations,handwriting recognition module 141 may generate the tree and perform this task. -
FIG. 5 depicts an example process for editing electronic handwriting, according to aspects of the subject technology. For explanatory purposes, the various blocks ofexample process 500 are described herein with reference toFIGS. 1-4 , and the components and/or processes described herein. The one or more of the blocks ofprocess 500 may be implemented, for example, by computingdevice 101, including a processor and other components utilized bydevice 101. In some implementations, one or more of the blocks may be implemented apart from other blocks, and by one or more different processors or devices. Further for explanatory purposes, the blocks ofexample process 500 are described as occurring in serial, or linearly. However, multiple blocks ofexample process 500 may occur in parallel. In addition, the blocks ofexample process 500 need not be performed in the order shown and/or one or more of the blocks ofexample process 500 need not be performed. - In the depicted example flow diagram, a new segment of electronic handwriting is received by
editor application 140 for display at a user designated position within or adjacent to existing electronic content displayed on display device 122 (502). For example, a user may electronically draw one or more strokes withinhandwriting display portion 204 ofhandwriting interface 200. - In response,
editor application 140 provides the received new segment tohandwriting recognition module 141 to obtain a plurality of textual interpretations of the new segment (504).Handwriting recognition module 141 generates the textual interpretations and passes them back toeditor application 140. - Prior to passing the received new segment to
handwriting recognition module 141,editor application 140 may generate a tree of content actions for the new segment. As described previously, a root node may first be created for the new segment, and each lower node that branches from a higher level node (e.g., starting at the root node) may be representative of one of a plurality of content actions that can be performed with respect to the existing electronic content to identify a portion of the existing electronic content for association with at least a portion of the new segment. Using this mechanism,editor application 140 may determine, automatically, without user intervention, candidate portions of the existing electronic content to provide to thehandwriting recognition module 141 with the new segment. The candidate portions are generated based on automatically traversing the tree along respective paths from a root node of the tree to respective leaf nodes of the tree and identifying the portions of the existing electronic content associated with the content actions represented by nodes along the path. The new segment is then provided with each determined candidate portion of the existing electronic content to the handwriting recognition module to obtain the plurality of textual interpretations of the new segment. - It is notable that, in some examples, the new segment of electronic handwriting received at
display 122 may modify an existing segment of electronic handwriting of the existing electronic content. In this case, the existing segment of electronic handwriting may be provided with the new segment to the handwriting recognition module to obtain the plurality of textual interpretations. -
Editor application 140 then generates respective electronic handwriting representations for the plurality of textual interpretations obtained from the handwriting recognition module 141 (506). The electronic handwriting representations may be generated using handwriting synthesis, such that the electronic handwriting representations include one or more computer-replicated glyphs substantially in a handwriting style of the existing electronic content. The artificial handwriting generated byeditor application 140 may be based on the user's own handwriting samples already input intoeditor application 140.Editor application 140 may match the style, font size, and stroke characteristics of the user. In some implementations, the generation of electronic handwriting representations byeditor application 140 includeseditor application 140 forwarding the textual interpretations to a handwriting synthesis engine (not shown). - The generated handwriting representations may not be (e.g., immediately) displayed to the user. In one or more implementations,
editor application 140 passes the handwriting representations, along with at least a portion of the existing electronic content, to scoringmodule 142.Editor application 140, in connection with scoringmodule 142, assigns scores to the textual interpretations obtained fromhandwriting recognition module 141. Each textual interpretation obtained from thehandwriting recognition module 141 is scored based on how its corresponding electronic handwriting representation would change the display of the existing electronic content when the electronic handwriting representation is displayed substantially at the user designated position within or adjacent to the existing electronic content (508). In this regard, thescoring module 142 may, without display, analyze the existing content with a selected handwriting representation inserted to determine how the existing content changes with the insertion. A score is calculated based on predetermined factors such as changes to: word spacing, baseline alignment, character kerning, character morphing, number of lines on a current page, word or line or paragraph reflow, and the like. For example, an increase or reduction in word spacing or kerning may negatively impact the score proportional to the increase or reduction amount. Scores may be represented as a value having a range, for example, from 0 to 1, or from −1 to 1 with 0 being a neutral or status quo value. -
Editor application 140 then selects, based on the scoring, an electronic handwriting representation corresponding to a respective textual interpretation of the plurality of textual interpretations (510).Editor application 140 modifies, for display ondisplay device 122, the existing electronic content to include the selected electronic handwriting representation located substantially at the user designated position (512). In this regard, the existing electronic content is modified to accommodate the selected electronic handwriting representation by way of a dynamic reflow of at least a portion of the existing electronic content. - In some implementations,
editor application 140 displays one or more visual indicators of the progress of the recognition of the handwritten input. For example,computing device 101 may receive a handwriting (or character) representation corresponding to a first handwritten input, and display the handwriting (or character) representation in addition to updating the one or more visual indicators of the progress.Editor application 140 may receive a handwriting (or character) representation corresponding to the second handwritten input.Editor application 140 displays the handwriting (or character) representation corresponding to the second handwritten input and updates visual indicator(s) of the progress of the recognition.Editor application 140 may continue to receive handwriting (or character) representation, if any, (e.g., fromhandwriting recognition module 141 or server 180) display the determined text characters, and update visual indicator(s) displayed as they are received. Once all of the handwritten characters have been recognized,editor application 140 may receive an indicator from recognition module 141 (or server 180) that the recognition of the handwritten input is complete. - In some implementations, a visual indicator is elevated to a different color or otherwise highlighted to signal that the predetermined confidence level (e.g., a threshold score) was not met. A score assigned to a selected handwriting representation may be determined to have not met a predetermined confidence level (e.g., if only one representation was returned).
Editor application 140 may then visually identify the portion of the modified electronic content corresponding to the selected electronic handwriting representation as not satisfying the predetermined confidence level. - In one or more implementations,
editor application 140 incorporates a feedback loop that adjusts scoring and selection of handwriting representations based on input (or lack of input) from the user.Editor application 140 may visually designate, before modifying the existing electronic content, a computer designated position within or adjacent to the existing electronic content corresponding to an insertion point of the selected electronic handwriting.Editor application 140 monitors for an indication of user acceptance or rejection of the selected electronic handwriting representation. On receiving an indication of user rejection of the selected electronic handwriting representation,editor application 140 selects, as the selected electronic handwriting representation, a second electronic handwriting representation corresponding to a second textural interpretation of the plurality of textual interpretations. If the representation being rejected was the highest scored representation of representations that were assigned scores based on data from scoringmodule 142 theneditor application 140 may select the representation having the next highest score. In some implementations,editor application 140 may rescore the representations as described above based on a new set of factors and select the highest representation. On an indication of rejection by the user, the current representation is replaced with the new representation.Editor application 140 may consider the absence of an indication of rejection as acceptance of the representation, for example, after a predetermined period of time (e.g., 1 or 2 s). - For example, an indication that the selected electronic handwriting representation was rejected by a user may be received. In response,
editor application 140 may select, a second electronic handwriting representation corresponding to a second textural interpretation of the plurality of textual interpretations, and modify, for display on the display device, the existing electronic content to include the second electronic handwriting representation located substantially at the user designated position. Before selection of the second representation,editor application 140 may rescore the textual interpretations obtained using thehandwriting recognition module 141 based on user input associated with the indication that the selected electronic handwriting representation was rejected and based on how each respective electronic handwriting representation would change the display of the existing electronic content when the respective electronic handwriting representation is displayed substantially at the user designated position within or adjacent to the existing electronic content. The second electronic handwriting representation may then be selected based on the rescoring. - Many of the above-described example 500, and related features and applications, may also be implemented as software processes that are specified as a set of instructions recorded on a computer readable storage medium (also referred to as computer readable medium), and may be executed automatically (e.g., without user intervention). When these instructions are executed by one or more processing unit(s) (e.g., one or more processors, cores of processors, or other processing units), they cause the processing unit(s) to perform the actions indicated in the instructions. Examples of computer readable media include, but are not limited to, CD-ROMs, flash drives, RAM chips, hard drives, EPROMs, etc. The computer readable media does not include carrier waves and electronic signals passing wirelessly or over wired connections.
- The term “software” is meant to include, where appropriate, firmware residing in read-only memory or applications stored in magnetic storage, which can be read into memory for processing by a processor. Also, in some implementations, multiple software aspects of the subject disclosure can be implemented as sub-parts of a larger program while remaining distinct software aspects of the subject disclosure. In some implementations, multiple software aspects can also be implemented as separate programs. Finally, any combination of separate programs that together implement a software aspect described here is within the scope of the subject disclosure. In some implementations, the software programs, when installed to operate on one or more electronic systems, define one or more specific machine implementations that execute and perform the operations of the software programs.
- A computer program (also known as a program, software, software application, script, or code) can be written in any form of programming language, including compiled or interpreted languages, declarative or procedural languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, object, or other unit suitable for use in a computing environment. A computer program may, but need not, correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data (e.g., one or more scripts stored in a markup language document), in a single file dedicated to the program in question, or in multiple coordinated files (e.g., files that store one or more modules, sub programs, or portions of code). A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.
-
FIG. 6 is a conceptual diagram illustrating an exampleelectronic system 600 for the recognition and editing of electronic handwriting, according to aspects of the subject technology.Electronic system 600 may be a computing device for execution of software associated with one or more portions or steps ofprocess 500, or components and processes provided byFIGS. 1-4 .Electronic system 600 may be representative, in combination with the disclosure regardingFIGS. 1-5 , ofcomputing device 101. In this regard,electronic system 600 orcomputing device 101 may be a personal computer or a mobile device such as a smartphone, tablet computer, laptop, PDA, an augmented reality device, a wearable such as a watch or band or glasses, or combination thereof, or other touch screen or television with one or more processors embedded therein or coupled thereto, or any other sort of computer-related electronic device having network connectivity. -
Electronic system 600 may include various types of computer readable media and interfaces for various other types of computer readable media. In the depicted example,electronic system 600 includes abus 608, processing unit(s) 612, asystem memory 604, a read-only memory (ROM) 610, apermanent storage device 602, aninput device interface 614, anoutput device interface 606, and one or more network interfaces 616. In some implementations,electronic system 600 may include or be integrated with other computing devices or circuitry for operation of the various components and processes previously described. -
Bus 608 collectively represents all system, peripheral, and chipset buses that communicatively connect the numerous internal devices ofelectronic system 600. For instance,bus 608 communicatively connects processing unit(s) 612 withROM 610,system memory 604, andpermanent storage device 602. - From these various memory units, processing unit(s) 612 retrieves instructions to execute and data to process in order to execute the processes of the subject disclosure. The processing unit(s) can be a single processor or a multi-core processor in different implementations.
-
ROM 610 stores static data and instructions that are needed by processing unit(s) 612 and other modules of the electronic system.Permanent storage device 602, on the other hand, is a read-and-write memory device. This device is a non-volatile memory unit that stores instructions and data even whenelectronic system 600 is off. Some implementations of the subject disclosure use a mass-storage device (such as a magnetic or optical disk and its corresponding disk drive) aspermanent storage device 602. - Other implementations use a removable storage device (such as a floppy disk, flash drive, and its corresponding disk drive) as
permanent storage device 602. Likepermanent storage device 602,system memory 604 is a read-and-write memory device. However, unlikestorage device 602,system memory 604 is a volatile read-and-write memory, such a random access memory.System memory 604 stores some of the instructions and data that the processor needs at runtime. In some implementations, the processes of the subject disclosure are stored insystem memory 604,permanent storage device 602, and/orROM 610. From these various memory units, processing unit(s) 612 retrieves instructions to execute and data to process in order to execute the processes of some implementations. -
Bus 608 also connects to input and output device interfaces 614 and 606.Input device interface 614 enables the user to communicate information and select commands to the electronic system. Input devices used withinput device interface 614 include, e.g., alphanumeric keyboards and pointing devices (also called “cursor control devices”). Output device interfaces 606 enables, e.g., the display of images generated by theelectronic system 600. Output devices used withoutput device interface 606 include, e.g., printers and display devices, such as cathode ray tubes (CRT) or liquid crystal displays (LCD). Some implementations include devices such as a touchscreen that functions as both input and output devices. - Also, as shown in
FIG. 6 ,bus 608 also coupleselectronic system 600 to a network (not shown) through network interfaces 616. Network interfaces 616 may include, e.g., a wireless access point (e.g., Bluetooth or WiFi) or radio circuitry for connecting to a wireless access point. Network interfaces 616 may also include hardware (e.g., Ethernet hardware) for connecting the computer to a part of a network of computers such as a local area network (“LAN”), a wide area network (“WAN”), wireless LAN, or an Intranet, or a network of networks, such as the Internet. Any or all components ofelectronic system 600 can be used in conjunction with the subject disclosure. - These functions described above can be implemented in computer software, firmware or hardware. The techniques can be implemented using one or more computer program products. Programmable processors and computers can be included in or packaged as mobile devices. The processes and logic flows can be performed by one or more programmable processors and by one or more programmable logic circuitry. General and special purpose computing devices and storage devices can be interconnected through communication networks.
- Some implementations include electronic components, such as microprocessors, storage and memory that store computer program instructions in a machine-readable or computer-readable medium (alternatively referred to as computer-readable storage media, machine-readable media, or machine-readable storage media). Some examples of such computer-readable media include RAM, ROM, read-only compact discs (CD-ROM), recordable compact discs (CD-R), rewritable compact discs (CD-RW), read-only digital versatile discs (e.g., DVD-ROM, dual-layer DVD-ROM), a variety of recordable/rewritable DVDs (e.g., DVD-RAM, DVD-RW, DVD+RW, etc.), flash memory (e.g., SD cards, mini-SD cards, micro-SD cards, etc.), magnetic and/or solid state hard drives, read-only and recordable Blu-Ray® discs, ultra density optical discs, any other optical or magnetic media, and floppy disks. The computer-readable media can store a computer program that is executable by at least one processing unit and includes sets of instructions for performing various operations. Examples of computer programs or computer code include machine code, such as is produced by a compiler, and files including higher-level code that are executed by a computer, an electronic component, or a microprocessor using an interpreter.
- While the above discussion primarily refers to microprocessor or multi-core processors that execute software, some implementations are performed by one or more integrated circuits, such as application specific integrated circuits (ASICs) or field programmable gate arrays (FPGAs). In some implementations, such integrated circuits execute instructions that are stored on the circuit itself
- As used in this specification and any claims of this application, the terms “computer”, “server”, “processor”, and “memory” all refer to electronic or other technological devices. These terms exclude people or groups of people. For the purposes of the specification, the terms display or displaying means displaying on an electronic device. As used in this specification and any claims of this application, the terms “computer readable medium” and “computer readable media” are entirely restricted to tangible, physical objects that store information in a form that is readable by a computer. These terms exclude any wireless signals, wired download signals, and any other ephemeral signals.
- To provide for interaction with a user, implementations of the subject matter described in this specification can be implemented on a computer having a display device, e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to the user and a keyboard and a pointing device, e.g., a mouse or a trackball, by which the user can provide input to the computer. Other kinds of devices can be used to provide for interaction with a user as well; e.g., feedback provided to the user can be any form of sensory feedback, e.g., visual feedback, auditory feedback, or tactile feedback; and input from the user can be received in any form, including acoustic, speech, or tactile input. In addition, a computer can interact with a user by sending documents to and receiving documents from a device that is used by the user; e.g., by sending web pages to a web browser on a user's client device in response to requests received from the web browser.
- Embodiments of the subject matter described in this specification can be implemented in a computing system that includes a back end component, e.g., as a data server, or that includes a middleware component, e.g., an application server, or that includes a front end component, e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the subject matter described in this specification, or any combination of one or more such back end, middleware, or front end components. The components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include a local area network (“LAN”) and a wide area network (“WAN”), an inter-network (e.g., the Internet), and peer-to-peer networks (e.g., ad hoc peer-to-peer networks).
- The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other. In some embodiments, a server transmits data (e.g., an HTML, page) to a client device (e.g., for purposes of displaying data to and receiving user input from a user interacting with the client device). Data generated at the client device (e.g., a result of the user interaction) can be received from the client device at the server.
- Those of skill in the art would appreciate that the various illustrative blocks, modules, elements, components, methods, and algorithms described herein may be implemented as electronic hardware, computer software, or combinations of both. To illustrate this interchangeability of hardware and software, various illustrative blocks, modules, elements, components, methods, and algorithms have been described above generally in terms of their functionality. Whether such functionality is implemented as hardware or software depends upon the particular application and design constraints imposed on the overall system. Skilled artisans may implement the described functionality in varying ways for each particular application. Various components and blocks may be arranged differently (e.g., arranged in a different order, or partitioned in a different way) all without departing from the scope of the subject technology.
- It is understood that the specific order or hierarchy of steps in the processes disclosed is an illustration of example approaches. Based upon design preferences, it is understood that the specific order or hierarchy of steps in the processes may be rearranged. Some of the steps may be performed simultaneously. The accompanying method claims present elements of the various steps in a sample order, and are not meant to be limited to the specific order or hierarchy presented.
- The previous description is provided to enable any person skilled in the art to practice the various aspects described herein. The previous description provides various examples of the subject technology, and the subject technology is not limited to these examples. Various modifications to these aspects will be readily apparent to those skilled in the art, and the generic principles defined herein may be applied to other aspects. Thus, the claims are not intended to be limited to the aspects shown herein, but is to be accorded the full scope consistent with the language claims, wherein reference to an element in the singular is not intended to mean “one and only one” unless specifically so stated, but rather “one or more.” Unless specifically stated otherwise, the term “some” refers to one or more. Pronouns in the masculine (e.g., his) include the feminine and neuter gender (e.g., her and its) and vice versa. Headings and subheadings, if any, are used for convenience only and do not limit the invention.
- The term website, as used herein, may include any aspect of a website, including one or more web pages, one or more servers used to host or store web related content, etc. Accordingly, the term website may be used interchangeably with the terms web page and server. The predicate words “configured to”, “operable to”, and “programmed to” do not imply any particular tangible or intangible modification of a subject, but, rather, are intended to be used interchangeably. For example, a processor configured to monitor and control an operation or a component may also mean the processor being programmed to monitor and control the operation or the processor being operable to monitor and control the operation. Likewise, a processor configured to execute code can be construed as a processor programmed to execute code or operable to execute code.
- The term automatic, as used herein, may include performance by a computer or machine without user intervention; for example, by instructions responsive to a predicate action by the computer or machine or other initiation mechanism. The word “example” is used herein to mean “serving as an example or illustration.” Any aspect or design described herein as “example” is not necessarily to be construed as preferred or advantageous over other aspects or designs.
- A phrase such as an “aspect” does not imply that such aspect is essential to the subject technology or that such aspect applies to all configurations of the subject technology. A disclosure relating to an aspect may apply to all configurations, or one or more configurations. An aspect may provide one or more examples. A phrase such as an aspect may refer to one or more aspects and vice versa. A phrase such as an “embodiment” does not imply that such embodiment is essential to the subject technology or that such embodiment applies to all configurations of the subject technology. A disclosure relating to an embodiment may apply to all embodiments, or one or more embodiments. An embodiment may provide one or more examples. A phrase such as an “embodiment” may refer to one or more embodiments and vice versa. A phrase such as a “configuration” does not imply that such configuration is essential to the subject technology or that such configuration applies to all configurations of the subject technology. A disclosure relating to a configuration may apply to all configurations, or one or more configurations. A configuration may provide one or more examples. A phrase such as a “configuration” may refer to one or more configurations and vice versa.
- All structural and functional equivalents to the elements of the various aspects described throughout this disclosure that are known or later come to be known to those of ordinary skill in the art are expressly incorporated herein by reference and are intended to be encompassed by the claims. Moreover, nothing disclosed herein is intended to be dedicated to the public regardless of whether such disclosure is explicitly recited in the claims. No claim element is to be construed under the provisions of 35 U.S.C. § 112, sixth paragraph, unless the element is expressly recited using the phrase “means for” or, in the case of a method claim, the element is recited using the phrase “step for.” Furthermore, to the extent that the term “include,” “have,” or the like is used in the description or the claims, such term is intended to be inclusive in a manner similar to the term “comprise” as “comprise” is interpreted when employed as a transitional word in a claim.
Claims (21)
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US16/273,014 US10769424B2 (en) | 2019-02-11 | 2019-02-11 | Interactive editing of electronic text |
PCT/US2019/051333 WO2020167342A1 (en) | 2019-02-11 | 2019-09-16 | Interactive editing of electronic text |
Related Parent Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
PCT/US2019/051333 Continuation WO2020167342A1 (en) | 2019-02-11 | 2019-09-16 | Interactive editing of electronic text |
Publications (2)
Publication Number | Publication Date |
---|---|
US20210279458A1 true US20210279458A1 (en) | 2021-09-09 |
US11983945B2 US11983945B2 (en) | 2024-05-14 |
Family
ID=
Also Published As
Publication number | Publication date |
---|---|
CN113228048A (en) | 2021-08-06 |
US20200257898A1 (en) | 2020-08-13 |
WO2020167342A1 (en) | 2020-08-20 |
US10769424B2 (en) | 2020-09-08 |
EP3874398A1 (en) | 2021-09-08 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
KR102257248B1 (en) | Ink to text representation conversion | |
KR102381801B1 (en) | Systems and methods for guiding handwriting input | |
JP6840132B2 (en) | Digital note-taking systems and methods | |
US9965175B2 (en) | System and method of digital note taking | |
KR102413461B1 (en) | Apparatus and method for taking notes by gestures | |
US10769424B2 (en) | Interactive editing of electronic text | |
CN110692060B (en) | Electronic text pen system and method | |
WO2022132427A1 (en) | System for analyzing and prescribing content changes to achieve target readability level | |
US11983945B2 (en) | Interactive editing of electronic text | |
US9229911B1 (en) | Detecting continuation of flow of a page | |
Herbig | Multi-modal post-editing of machine translation |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:CIRIMELE, MARIA;BUCKLEY, THOMAS WILLIAM;MICKLE, ROBERT KY;AND OTHERS;SIGNING DATES FROM 20190214 TO 20190319;REEL/FRAME:056315/0501 |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: DOCKETED NEW CASE - READY FOR EXAMINATION |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NON FINAL ACTION MAILED |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NOTICE OF ALLOWANCE MAILED -- APPLICATION RECEIVED IN OFFICE OF PUBLICATIONS |
|
ZAAB | Notice of allowance mailed |
Free format text: ORIGINAL CODE: MN/=. |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: PUBLICATIONS -- ISSUE FEE PAYMENT RECEIVED |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: PUBLICATIONS -- ISSUE FEE PAYMENT VERIFIED |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |