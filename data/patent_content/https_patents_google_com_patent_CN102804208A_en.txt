CN102804208A - Automatically mining person models of celebrities for visual search applications - Google Patents
Automatically mining person models of celebrities for visual search applications Download PDFInfo
- Publication number
- CN102804208A CN102804208A CN2010800612031A CN201080061203A CN102804208A CN 102804208 A CN102804208 A CN 102804208A CN 2010800612031 A CN2010800612031 A CN 2010800612031A CN 201080061203 A CN201080061203 A CN 201080061203A CN 102804208 A CN102804208 A CN 102804208A
- Authority
- CN
- China
- Prior art keywords
- image
- face
- names
- list
- model
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
- 238000005065 mining Methods 0.000 title description 6
- 230000000007 visual effect Effects 0.000 title description 3
- 238000000034 method Methods 0.000 claims abstract description 43
- 238000004458 analytical method Methods 0.000 claims abstract description 32
- 239000013598 vector Substances 0.000 claims abstract description 24
- 238000010183 spectrum analysis Methods 0.000 claims abstract description 14
- 230000001815 facial effect Effects 0.000 claims description 81
- 238000001514 detection method Methods 0.000 claims description 22
- 238000004590 computer program Methods 0.000 claims description 12
- 238000001228 spectrum Methods 0.000 claims description 11
- 239000011159 matrix material Substances 0.000 claims description 8
- 230000003287 optical effect Effects 0.000 claims description 6
- 244000188472 Ilex paraguariensis Species 0.000 claims description 5
- 230000008878 coupling Effects 0.000 claims description 3
- 238000010168 coupling process Methods 0.000 claims description 3
- 238000005859 coupling reaction Methods 0.000 claims description 3
- 230000008676 import Effects 0.000 claims description 2
- 238000004364 calculation method Methods 0.000 claims 1
- 238000012360 testing method Methods 0.000 description 34
- 238000012549 training Methods 0.000 description 31
- 238000004891 communication Methods 0.000 description 20
- 230000006870 function Effects 0.000 description 10
- 238000010586 diagram Methods 0.000 description 8
- 230000008569 process Effects 0.000 description 7
- 238000012986 modification Methods 0.000 description 6
- 230000004048 modification Effects 0.000 description 6
- 238000012545 processing Methods 0.000 description 4
- 239000000654 additive Substances 0.000 description 3
- 230000000996 additive effect Effects 0.000 description 3
- 230000008901 benefit Effects 0.000 description 3
- 238000005516 engineering process Methods 0.000 description 3
- 239000000284 extract Substances 0.000 description 3
- 239000000463 material Substances 0.000 description 3
- 238000005259 measurement Methods 0.000 description 3
- 238000000513 principal component analysis Methods 0.000 description 3
- 238000007670 refining Methods 0.000 description 3
- 230000008859 change Effects 0.000 description 2
- 230000000977 initiatory effect Effects 0.000 description 2
- 238000007689 inspection Methods 0.000 description 2
- 230000000717 retained effect Effects 0.000 description 2
- 101000746134 Homo sapiens DNA endonuclease RBBP8 Proteins 0.000 description 1
- 101000969031 Homo sapiens Nuclear protein 1 Proteins 0.000 description 1
- 102100021133 Nuclear protein 1 Human genes 0.000 description 1
- 241000405217 Viola <butterfly> Species 0.000 description 1
- 238000009825 accumulation Methods 0.000 description 1
- 238000013459 approach Methods 0.000 description 1
- 238000000429 assembly Methods 0.000 description 1
- 230000000712 assembly Effects 0.000 description 1
- 230000005540 biological transmission Effects 0.000 description 1
- 230000001413 cellular effect Effects 0.000 description 1
- 238000013480 data collection Methods 0.000 description 1
- 230000005611 electricity Effects 0.000 description 1
- 238000002474 experimental method Methods 0.000 description 1
- 238000000605 extraction Methods 0.000 description 1
- 239000004744 fabric Substances 0.000 description 1
- 239000012530 fluid Substances 0.000 description 1
- 230000037308 hair color Effects 0.000 description 1
- 238000013095 identification testing Methods 0.000 description 1
- 238000005286 illumination Methods 0.000 description 1
- 210000000088 lip Anatomy 0.000 description 1
- 230000007774 longterm Effects 0.000 description 1
- 238000013507 mapping Methods 0.000 description 1
- 230000007246 mechanism Effects 0.000 description 1
- 238000010295 mobile communication Methods 0.000 description 1
- 239000013307 optical fiber Substances 0.000 description 1
- 238000009877 rendering Methods 0.000 description 1
- 238000005070 sampling Methods 0.000 description 1
- 239000004065 semiconductor Substances 0.000 description 1
- 230000003068 static effect Effects 0.000 description 1
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V40/00—Recognition of biometric, human-related or animal-related patterns in image or video data
- G06V40/10—Human or animal bodies, e.g. vehicle occupants or pedestrians; Body parts, e.g. hands
- G06V40/16—Human faces, e.g. facial parts, sketches or expressions
- G06V40/172—Classification, e.g. identification
- G06V40/173—Classification, e.g. identification face re-identification, e.g. recognising unknown faces across different face tracks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F18/00—Pattern recognition
- G06F18/20—Analysing
- G06F18/23—Clustering techniques
- G06F18/232—Non-hierarchical techniques
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/70—Arrangements for image or video recognition or understanding using pattern recognition or machine learning
- G06V10/762—Arrangements for image or video recognition or understanding using pattern recognition or machine learning using clustering, e.g. of similar faces in social networks
- G06V10/763—Non-hierarchical techniques, e.g. based on statistics of modelling distributions
Abstract
Methods and systems for automated identification of celebrity face images are provided that generate a name list of prominent celebrities, obtain a set of images and corresponding feature vectors for each name, detect faces within the set of images, and remove non-face images. An analysis of the images is performed using an intra-model analysis, an inter-model analysis, and a spectral analysis to return highly accurate biometric models for each of the individuals present in the name list. Recognition is then performed based on precision and recall to identify the face images as belonging to a celebrity or indicate that the face is unknown.
Description
Technical field
Embodiments of the invention relate to the people in the identification vision content.
Background technology
Trustship a large amount of dissimilar contents in the Internet comprise text, image and video.Utilize this content request content be can search for and by being organized.Image is generally searched for based on the identifier of user's manual allocation and is organized.
Particularly, when image was people's the image of face, although the bigger variation on appearance, light and expression is arranged, the people can accomplish with high accuracy the identification of face.On the other hand, computer vision system has difficulty carrying out with the mankind's level of accuracy in the identification.Although facial identification is the medium-term and long-term problem that exists of computer vision and other field always, yet the principal focal point of the sector is with the identification of quite little data set to the face in the controlled environment always.Along with the data set increase becomes thousands of, because illumination, posture and expression, each has the appearance variation, so lack the task of good authentication and identification always.
Because the personality has become available than small data set, the famous person's in the identification news effort has also appearred.Developed the algorithm that is used for face recognition, checking and identification, it typically comprises the data set that is restricted to usually news picture high-quality, that in controlled environment and with controlled posture, take.By contrast, the interested people's in uncontrolled environment general pattern lacks by the ability of automatic identification and checking.
Therefore, needed is to use the method and system of automatic mining famous person's individual model for visual search.
Summary of the invention
In one embodiment, a kind of computer implemented method that is used for identification name human face image is provided, this method: the list of names that generates famous famous person; For each name obtains image set and characteristic of correspondence vector; The face of detection in image set; And remove non-face-image.Use a model between inner analysis, model and to analyze and the analysis to image is carried out in spectral analysis, each return altitude of thinking the individual philtrum that exists in the list of names is living model accurately.Then, carry out identification based on precision ratio (precision) and recall ratio (recall), with face-image is identified as belong to the famous person or identification face be unknown.
In another embodiment, the system of the face that is used to discern the famous person is provided, it comprises: the list of names maker, and it produces famous famous person's name; Facial signature detection device, it obtains the interior face of image set and characteristic of correspondence vector, detected image collection and removes non-face-image for each name.The individual model learning system uses a model between inner analysis, model and to analyze and the analysis to image is carried out in spectral analysis, thinks each face-image return altitude living model accurately.Then, carry out identification based on precision ratio and recall ratio, with face-image is identified as belong to the famous person or the indication face be unknown.
Be described in detail with reference to the attached drawings further characteristic of the present invention and advantage below, with and structure and the operation of each embodiment.Be noted that the specific embodiment that the invention is not restricted to describe in this article.Only for illustration purposes, such embodiment is provided in this article.Based on the instruction that comprises in this article, additional embodiments will be conspicuous to various equivalent modifications.
Description of drawings
Will be with reference to embodiments of the invention, its example can illustrate in the accompanying drawings.It is illustrative and nonrestrictive that these accompanying drawings are intended to.Although generally under the sight of these embodiment, described the present invention, yet, should be understood that it also is not intended to scope of the present invention is limited in these specific embodiments.
Fig. 1 illustrates according to an embodiment of the invention two similar legends in pairs.
Fig. 2 illustrates according to an embodiment of the invention the diagram in the identification performance in interstage.
Fig. 3 illustrates according to an embodiment of the invention the diagram about the identification performance of specific set of data.
Fig. 4 is a system view according to an embodiment of the invention.
Fig. 5 illustrates the assembly of list of names maker according to an embodiment of the invention.
Fig. 6 illustrates the assembly of facial according to an embodiment of the invention signature detection device.
Fig. 7 illustrates the assembly of individual model learning system according to an embodiment of the invention.
Fig. 8 illustrates the method for the individual model that is used for the automatic mining famous person according to an embodiment of the invention.
Fig. 9 diagram is carried out the computer system to the automatic mining of famous person's individual model according to an embodiment of the invention.
Embodiment
Though described the present invention with reference to the illustrative example that is used for application-specific in this article, should be understood that the present invention is not limited to this.Those skilled in the art will recognize that through using instruction in this article other modification, application and embodiment and the present invention in its scope will be the other field that great function is arranged therein.
The propagation that relies on the content that wide usability encouraged of image-capturing apparatus, and the connectedness that the Internet provided, it is available that increasing image collection is just becoming.Through the use to interconnection network and shared image collection, at any time, unique user can be visited the big properties collection about various themes that the people created that spreads all over the world.The system that can discern automatically with the face of the thousands of individual of identification in being included in physical environment data centralization is very useful.The method and system of describing in this article uses and for example comes auto-associating famous person's name and face at a large amount of articles available on the Internet and image corpus.In an embodiment of the present invention, system can get and learns living model and identification is facial from the image of face and its note through web is climbed.Such image can obtain from the picture material of any kind, comprises rest image, video, hologram and other medium types or rendering method.Utilize the framework of cloud computing, can obtain query image with mobile device, wherein the name with the face of being inquired about in the image turns back to this equipment.
The training data set
List of names on Web and image
In an embodiment of the present invention, the facial identification system of non-supervised is used at the training set that does not have to generate under the situation of man-machine interactively and is generated.Unique input to system is the list of names that the famous famous person of identification attempts in system.Such list of names can be obtained from multiple source, and such as in the Internet, for example wikipedia is gone up available article, wherein article is filtered only to keep those articles of mentioning name.Then, use any available service, Google's picture search (GIS) of making such as the Google in mountain scene city, California, can with each name with through the Internet can with image carry out related.Use such service, can retrieve face-image and carry out related with the list of names that in article, finds it.The quantity of the face-image that can return for each name based on picture search then, comes the name in tabulating is carried out rank.
In such embodiment, in case list of names is defined, first step is exactly to collect image set and characteristic of correspondence vector for each name in the tabulation.This can be through with the completion of getting off: to initiate inquiry such as the available internet images search system of Google's picture search and be recorded as the image that each inquiry returns number of thresholds, detect facial and extract proper vector and putatively mark this each proper vector with the inquiry of obtaining each proper vector from image.Consider wrong possibility intrinsic in the picture search based on the Internet, can mark the subclass of initial characteristics vector set improperly.In an embodiment, further train attempt to improve the quality of training data through the clauses and subclauses of discerning and abandon incorrect mark.In another embodiment, if for returning image more than a celebrity name inquiry, then a plurality of copies of consequent proper vector can be stored in and mark the inquiry that produces it with each copy.In a similar manner, if image comprises two or more faces, then all facial putatively marks have query name.Yet, under two kinds of situation, solve which face and be actually in question famous person and will be processed in later phases.
Detect
In an embodiment of the present invention, for fear of the obvious outside sgency that picture search is returned, use face detector to come to remove non-face-image from initial results.Detecting device for example uses the quick moving window method in the scope of window size.In an embodiment, detecting device utilizes the linear combination of mixed features detecting device collection, and it is based on the characteristic family of the complicacy that changes; Comprise (1) characteristic simply but fast; Such as the position characteristic, and (2) more expensive characteristic of information but more, such as the Gabor small echo.Utilize the objective function of logic loss item and L1 regularization to train detecting device through minimizing.Output can be the score value of distributing to each window in scope [0,1].When all yardsticks have been carried out processing, according to the score value of residue window with stride yardstick overlapping the residue window filtered and merges.Detector parameters can comprise inclination (gradient) angle that is set to threshold level, such as ± 30 degree and minimum boxsize (frame size), such as 40 pixels.In another embodiment, the facial score value that detects that can come further to refine through boundary mark device (landmarker) subsystem that interpolation is accurately positioned in the facial features location in the facial bounding box.Then, can use the characteristic of extracting in those positions to obtain the score value of refining of the facial probability that exists of indication.Embodiment uses the detection algorithm that belongs to such as the big nation of the moving window detecting device of far-reaching Viola and Jones detecting device.Can reduce dimension through using principal component analysis (PCA) (PCA), further handle the proper vector of being extracted, and can use the dot product of weighting to measure the similarity between two proper vectors.
Those skilled in the art will recognize that, can come constructed embodiment based on any detecting device of high precision ratio and recall ratio.
Individual model study
According to embodiments of the invention, this part has been described total fluid line, and it is got the original image Search Results and imports, and is the thousands of individual return altitude that in list of names, exists living model accurately.
The model inner analysis
In an embodiment of the present invention, can use such as the collection that has 30,000 names, Q=30 for example, 000, big list of names generate training data.In one embodiment, for q ∈ [1, Q], variable M
qBe the collection of 1000 images at the most that picture search is returned, wherein from M
qRemove the training example of incorrect mark, for example
In an embodiment, for by
Represented M
qIn each image I
i, through the neighbours' in the counting group the quantity and the quantity of near-duplicate article, can carry out nearest-neighbors and divide into groups, wherein neighbours are defined as and have
Then, can be from M
qRemove and have the image that is less than k nearest-neighbors.In order to reduce redundancy, can remove by I
iAll near-duplicate article of the image of expression.Then, can be according to the descending of near-duplicate article countings to M
qElement sort.Each face in the sorted lists if it has the previous near-duplicate image that occurs in tabulation, then can be dropped; Otherwise it can be retained.Can be noted that so local outside sgency removes method, and can to help for reducing false negative be important high recall ratio.Through this process, can discern initial sets with the face of the given corresponding mark of mask.
Analyze between model
In an embodiment of the present invention, this stage is with the face of remaining mark after model inner analysis set beginning, and attempt is through to for example comparing the clauses and subclauses that further remove incorrect mark with the face from different models of different name notes.If set comprises two near-duplicate faces with different labels, then almost for certain in the label or both be incorrect, and this face can not to be used to mark reliably the inquiry of entering facial.The target of analysis phase is between model, solves the near-duplicate face through all faces in considering to gather with paired mode.For each to
Spectral analysis
In an embodiment of the present invention, the spectral analysis stage, individual facial with therein, for example near-duplicate article and nearest-neighbors, it is different to add up between the model inner analysis that is considered and model the analysis phase, and the target in this stage is to assess the global statistics of individual model.In the spectral analysis stage, each collection M of facial characteristics vector
qOnly be included in those elements that also are not dropped during analyzing between model inner analysis or model.
For each model M
q, set of eigenvectors
So, this L of pula, Tula only is used for confirming model order k.Sort according to the eigenwert of descending, wherein λ to L
1=1, and the remainder of eigenwert reduces to zero.The distribution of eigenwert is as the distortion of model M or the estimation of pollution.If the residue character value is fallen too fast, then suppose M
qBe not have contaminatedly, and all its members have powerful support among its neighbours.Yet, if some eigenwerts are very big really, for example>T, k is confirmed by the quantity greater than the eigenwert of T.
In an embodiment, rely on suitable model order k, use the cohesion cluster to come M
qIn clauses and subclauses carry out cluster.Can on the cluster of k road, select iteration scale-of-two cluster, because be not noisy only in raw data, and selected k=k
TrueThe time, multichannel is just carried out better.Because data possibility quilt is mark by error, in this case, iteration scale-of-two cluster is more suitable.Can use the hierarchical clustering that has average link to come at M
qIn face carry out cluster, the similarity function below using:
In an embodiment, substitute and only to use paired similarity S
Ij, can use the more similarity measurement of the overall situation, it is considered
In case M
qBe divided into cluster C
1... C
k, just select outside sgency's cluster.The outside sgency selects can be through with completions of getting off: the statistics of cluster, for example cluster size, entropy, on average cluster diagram is counted as rank or the average duplicate that calculates in the stage formerly, or and model M
q' compare, wherein q ≠ q '.In most cases, with M
q' the most similar cluster, φ (C
i, M
q') is considered to outside sgency's cluster, and is dropped.Note φ (C
i, M
q') only is at cluster C
iAnd model M
q' between average similarity in pairs.Then, the comparison of the proprietary set in completion and the list of names.With face and the M in the residue cluster
qAnd M
q' in clauses and subclauses compare respectively.From M
qRemove and M
q' have those of higher average similarity.Possible is, with M
qCompare with the model of its most similar with it only lesser amt, rather than with M
qEach that remains in the model with Q-1 compares, and causes q (Q-1)/2 in pairs relatively.For example, can be with M
qOnly before the model inner analysis, share maximum single model M of occuring simultaneously with it with it
q' compare.As an alternative, exist || M
q‖<before 2, can be with M
qWith other model M
q' compare.
Presentation graphics
In an embodiment of the present invention, select individual's presentation graphics automatically.Individual's presentation graphics is defined by the similarity feature set from above-mentioned image set and characteristic of correspondence vector, for example, and facial signature, clothes, sunglasses, hair color, background etc.
Select presentation graphics to accomplish based on facial characteristics through at first interested individual's face-image being carried out cluster based on facial similarity.As is known to the person skilled in the art, can use any algorithm in some clustering algorithms, for example, any paired or central method is created cluster.As an example, as the center, can use the average drifting cluster to come at first to create cluster in the face each.Add all faces that have with facial at least for example 90% the threshold value similarity in center to this cluster.Such process can cause same face in a plurality of clusters, to exist.Can remove from less cluster and duplicate face, and comprise that the cluster of the face of the quantity that for example surpasses 10 minimum threshold can be called as " well " cluster.At the U.S. Patent application No.12/172 that is entitled as " Method And System For Automated Annotation Of Persons In Video Content "; Described the further argumentation of clustering technique among 939 (Atty.Dkt.No.2525.1390000) in more detail, it is incorporated herein through the mode of quoting in full.
Then, can with image recognition presentation graphics from maximum cluster or any good cluster.Under the situation that does not have good cluster, can select presentation graphics from maximum cluster.
In an embodiment, presentation graphics is configured to only comprise the talking head image, for example is not whole body image or picture group picture.To the selection of talking head presentation graphics based on scoring algorithm.For example, when cutting of image was not allowed to or is impossible, the part based on the face of describing interested individual of image gave each image normalized talking head score value.Therefore, the group photograph will have the score value littler than the score value of portrait photograph.In addition, if specific image the ratio of width to height expect, then with the expansion of selected image in the dimension to be fit to the depth-width ratio of expectation., uses the talking head score value image expanding size in calculating.Select representative talking head image based on score image, wherein optimal selection is the image that from good cluster, obtains.Yet,, select score image from all images if there is not good cluster to use.If have some images, then select image from maximum cluster with same highest score.
Identification
According to embodiments of the invention, the process of using the identification of the living model that makes up has been described in this part.In an embodiment, selection can be almost the sorting technique through whole training dataset in real time.Because postponing is the problem of large data collection, can carry out identification with the variant of nearest neighbor classifiers.
In an embodiment, given query image I
Query, with proper vector
Wherein
Identification to the face in wilderness (wild) is the open set problem inherently, the famous person who wherein in query image, describes maybe be not do not know in identification system those among.In order to solve this, in an embodiment, introduce identification possibility threshold value T
TIf do not surpass this threshold value, sim (I with the similarity of the name human model that matees most
Query, q)<t
T, then the identification of system refusal is should inquiry facial, and alternatively will inquire about face and be reported as " the unknown ".
Test findings
In test, in order to assess the performance of identifier, selected the query graph image set of manual annotations, and used identifier to come to propose celebrity name or " the unknown " for each image corresponding to exemplary embodiment.Can use two numerals to come measurement performance: precision ratio (being the mark of the name of correct proposal) and recall ratio (being subordinated to the mark of the correct name of proposing among the known famous person's of identifier all images).Precision ratio and recall ratio change with the selection of identification possibility threshold value, and for example, higher threshold value produces higher precision ratio, but lower recall ratio.Therefore, to threshold range, assessment precision ratio and recall ratio.In Fig. 2 and 3, recall ratio figure has been summed up the result with precision ratio.
The target of test is that the use normal image comprises those with low resolution and relatively poor image-forming condition, comes identification people's face.Therefore, on the data set of three differences and nature, accomplished test.As the described herein; The mobile device that use has 1,000,000 pixel camera duplicates the actual life user experience; And the identification result in each stage of report exemplary embodiment and additive method, the use test image set compares the performance and the state-of-the-art method of exemplary embodiment.Also with the performance of exemplary embodiment with via Berg, Berg, Edwards, Maire, Teh, Learned-Miller and Forsyth people such as (" ") Berg, the comparing of name and facial related work and test data in submission.
30,000 personalities' identification
According to embodiments of the invention, scalability and feasibility performance for the algorithm that appears above confirming have made up the tabulation that is similar to 30,000 names.In order to test, to have selected above 1000 names from tabulation, and obtained face-image for each corresponding name.On purpose, with light and the posture acquisition image that changes, the facial feature of scope on from the journal surface to the TV screen.All images all uses the mobile phone with 1,000,000 pixel camera to take.In test, the performance of this method pipeline each in stage the place by relatively, and be that the original output of the picture system of Google's picture search (GIS) compares with coming in comfortable this test.Particularly, relatively use 20 and 50 results from GIS, wherein facial filtrator is opened (GIS, preceding 20/50 face), the model of structure; Only use the phase one of pipeline, the model that nearest-neighbors grouping (in the model) makes up; Use comprises that duplicate removes the model that preceding two stages of the pipeline of (between model) make up; And the final mask that uses whole pipeline (spectrum) to make up.In addition; To same data set, algorithm (In Automatic Faced and Gesture Recognition, the 2008.FGR 2008.8th Int.Conf.on of people's exploitations such as use Zhao; 2008) come the comparison performance, this algorithm is incorporated herein through the mode of quoting in full.Precision ratio/recall ratio curve has been shown, its center line 201 indication GIS, preceding 20 faces in Fig. 2; Line 203 indication GIS, preceding 50 faces; Line 205 indication consistance; The consistance of line 207 indications and neardupes; Between line 209 indication models; Line 211 indication spectrum; And in the line 213 indication models.
In an embodiment, each proposal stage that Fig. 2 illustrates pipeline provides clear and definite contribution, and has improved the overall performance of system.For all algorithms, at high recall ratio (> 0.5) the low precision ratio trend located is visible.The high recall ratio zone of these curves is corresponding to the people's who in GIS, has considerably less image identification.Therefore, for can the such people of identification, for example, increase recall ratio in order to reduce false negative, the quantity of the false positive that is allowed must increase, and causes low precision ratio.
Compare with the original output of GIS, be apparent that, the size (20 or 50) that changes GIS output does not cause a large amount of inputs.In fact, increase GIS output and only reduced signal to noise ratio (S/N ratio), and caused still less living model and misidentification accurately.Yet, use the pipeline that is appeared, extract image as much as possible from GIS, wherein the upper limit is 1000, uses each stage of pipeline to remove the wrong image that marks.
Except that the contribution in each stage of pipeline and identification accuracy are compared, also consider the consequent model size that required time in each stage of training and each stage submit.Working time and size have been provided in the following Table 1.The study of people's such as Zhao consistance have and the model of pipeline between the complicacy O (n of stage same order
2), wherein n is facial quantity.Yet, because it can be O (1000*n
2) Sampling Strategies, wherein 1000 is the quantity of random sample, is O (1*n and analyze between model
2).More importantly, different with consistance study scheme, it is deterministic analyzing between model.In practice; Consistance study; The unique additive method that is used for large-scale facial identification, (in the built-up pattern, between model and the spectrum) method that is slower than in this exemplary embodiment surpasses 3 times, and causes surpassing 11% even worse discrimination power (raising of measuring at F-).
Table 1: the performance statistics of various algorithms and pipeline stage
The identification of " name and face "
For the performance of the method in the exemplary embodiment and additive method and test set are compared, repeat people's such as Berg identification test.The headline that people such as Berg have selected 1000 random images and have been associated from its data set.The language model that use is coupled in facial identifier will be chosen as the label that is used for given face from the name of title.In order to simulate this experiment, require all Real Names in the test data to be present in and be used for training in the list of names.Two different editions of training data have been used: general and specific.General training has comprised the list of names of approximate 30,000 names, and having no the corresponding living model of training under the situation of supervision, and specific training has only comprised the name that in test set, exists, in the standard of computer vision community.For test data, two versions have also been created: test 1 and test 2.The part that is used for the label of the test pattern that people such as Berg provide is with form " christian palestinian (Christian Pakistani) " and " young afghan (young Afghan) ".These labels are not distinctive names, and if with the inquiry of doing GIS, then can not produce deterministic result set significantly.Therefore, removed a little test pattern that has such label from testing 1 test data.In test 2, removed equally and had the image that in GIS, does not produce remarkable responding tags.Fig. 3 illustrates the ROC curve, and the performance of above-mentioned two training and testing collection is shown, and its center line 301 illustrates the only training test 1 of Berg; Line 303 illustrates the only training test 2 of Berg; Line 305 diagram general training tests 1; And line 307 diagram general training tests 2.Be shown in the following Table 2 the summary of performance statistics.
Table 2: the performance statistics of various algorithms and pipeline stage
| Rank | 1 identification |
Specific training: |
77% | |
Specific training: test 2 | 90% | |
General training: |
55% | |
General training: test 2 | 69% | |
People such as Berg: |
78% |
Yet,, and guarantee that training set accurately comprises the classification that is present in the test if revert to the conventional exercises scheme; (specific training; Test 1), then people such as exemplary embodiment and Berg carries out well equally, has solved the more general problem that does not receive headline and language model restriction simultaneously.At last, if require to have the training data that is used for all category of tests, fair requirement, then the definition test 2.In this case, exemplary embodiment has significantly surpassed people such as Berg, and has produced identification system, and its precision ratio spreads all over whole recall ratio territory and only reduced by 10%.
The failure case
Because the statistical property of the algorithm that appeared, and to the dependence of the faulty annotated figure image source of for example GIS, exist wrongly through its a plurality of approach that can get into the name human model of instant training, therefore produced incorrect identification result.
In these primarily is that more obscure famous person's model becomes and pollutes their problem of the more famous famous person's of close association face with it with modal.For example, be clean though Sa draws Perrin's model, comprising does not have 78 wrong images, and her more unpowerful and more influential daughter's Bristol Perrin's model comprises 7 images of her mother.As a result, Sa draws some query image of Perrin to be recognized as Bristol improperly, is not because Sa draws Perrin's model to have any problem, but because another model has mistake.Can be with this question attribution in the following fact: in this example, more unpowerful and more influential people's GIS result be intrinsic more noisy.Enjoyably, but two extremely famous famous persons' that are associated strongly model, and special and Angelina Zhu Li does not show this problem such as cloth rad skin, possibly be because the high s/n ratio in its people GIS result.
Second problem is to the use of canonical name when initiating the GIS inquiry.For example, " Wales prince Henry " return relatively seldom, noisy result, produce the model that only comprises single face, and more spoken " prince Henry " will return set significantly widely.As the result of this poverty model, analyzing between model can not be from his love object, and the model of Chelsea Dai Wei removes prince's face.This problem can be by being each the collection GIS result in famous person's the another name and selecting best model or assemble the result to cause.
Other classifications that possibly go wrong comprise the fashion designer, and its GIS result is preponderated by other people photograph of dressing its creation, and the famous person who wears sunglasses, and it can be obscured by facial similarity function once in a while.
System component
Fig. 4 illustrates system 400 according to an embodiment of the invention, and it can discern celebrity name automatically, and identification, identification face-image and carry out related with the celebrity name of being discerned face-image.Facial identification detecting device 412 is coupled to system interface 410 through connecting 411.System interface 410 can be user interface or API or the remote user interface that for example is positioned on the computing platform identical with facial identification detecting device 412, such as the web client.Therefore, connect 411 and can use method of attachment, such as communication bus, Ethernet or wireless communication standard or other communication protocol.
Facial identification detecting device 412 may reside on the server, and can comprise the web server, such as from Google's Web server of Google, from the Apache Web server of Apache foundation, from the internet information service of Microsoft etc.Facial identification detecting device 412 can provide the visit of this locality being stored or being stored in the web content on the memory device (not shown) that couples.Facial identification detecting device 412 typically comprises at least one server computer that is connected to network.Exemplary server computer includes but not limited to computing machine, workstation, distributed computing system, computer cluster, embedded system, independent electronics, networked devices, mobile device (for example, mobile phone or mobile computing device), rack server, STB or has the computer system of the other types of at least one processor, storer and network interface.
Facial identification detecting device 412 can also access images/video corpus 432 and article corpus 434.In the corpus 432 and 434 can be addressable through network 430 partly or entirely, and said network 430 is such as as the wide area network (WAN) of the Internet or Local Area Network or can local be positioned in user's oneself the system.Corpus 432 and 434 each can comprise and be positioned at same place or by one or more memory devices of being distributed.In certain embodiments, corpus 432 and 434 can partly or entirely be positioned at same place.Facial identification detecting device 412 can be coupled to network 430 through any connection 431, and said connection 431 comprises such as but not limited to communication bus, Ethernet and wireless communication standard.Image/video corpus 432 can comprise the image with any picture format, said picture format such as JPEG, Exif, TIFF, RAW, PNG, GIF, BMP, PPM, CGM, SVG, PNS, JPS and MPO.Image/video corpus 432 comprises people's image.Article corpus 434 comprises the filing of article for example, based on the service of web and local and/or through the addressable storage vault in the Internet.Available article filing can comprise such as but not limited to ASCII text, PDF text and other forms of text.
Facial identification detecting device 412 also is coupled to database of names 440 and image data base 450 through connecting 441 and 451 respectively.Database of names 440 comprises that facial identification detecting device 412 is based on the name of discerning in the article available in the article corpus 434 at least and discerns the also famous person's of rank list of names.Below, will further describe such generation of list of names with reference to figure 5.Image data base 450 be included in the database of names 440 people in famous person's the list of names of expression, from the face-image of the picture material of any kind that comprises rest image and video image.Face-image in the image data base 450 generates and discerns according to the image that in image/video corpus 432, finds at least.As employed in the disclosure, " database " is meant any set of data element, and storage that is associated and access mechanism.Connect 142 and can use one or more methods of attachment, such as communication bus, Ethernet, and wireless communication standard.
Facial identification detecting device 412 can comprise some assemblies, comprises list of names maker 422, facial signature detection device 424 and individual model learning system 426.Partly or entirely can realize in facial identification detecting device 412 and subsystem 422,424 and 426 with software, hardware or its any combination.For example, facial identification detecting device 412 may be implemented as the executable code on central processor unit (not shown among Fig. 4).In another embodiment, facial identification detecting device 412 can be realized with the nextport hardware component NextPort such as field programmable gate array.It will be appreciated by those skilled in the art that facial identification detecting device 412 can realize in one or more platforms.
List of names maker 422 generation systems will be attempted the famous famous person's of identification list of names.The tabulation of name, or list of names generates based on the article from article corpus 434.422 pairs of articles from article corpus 434 of list of names maker filter those articles of describing the people only to comprise.Below list of names maker 422 is based in greater detail the quantity of the face-image that returns of picture search the name in the list of names is carried out rank.
Facial signature detection device 424 removes " non-face " image from the initial pictures that list of names generation detecting device 422 is generated, and is described in more detail below.
The face-image that individual model learning system 426 is produced facial signature detection device 424 is got and is imported, and generates the living model of pin-point accuracy for the individual who in list of names, discerns.Individual model learning system 426 uses a series of analyzing subsystems name that further refines related with image, and it is final to generate the name that is associated with the face of inquiring about or indicate the face of inquiring about is " the unknown ".
Fig. 5 illustrates the assembly of list of names maker 422 according to an embodiment of the invention.List of names maker 422 comprises list of names maker subsystem 502, image collector 504 and name rank device 506.
List of names maker subsystem 502 is based on the article that finds in the article corpus 434 and generates list of names.Article in the list of names maker subsystem 502 identification article corpus 434, only select and filter those articles that comprise name.In case obtain list of names, image collector 504 is with regard to the image set of the picture material of any kind of collect for each name for example static certainly and/or video, and the characteristic of correspondence vector.This for example accomplishes through initiating picture search to image/video corpus 432.In an embodiment, image collector 504 is included as the threshold value of the quantity of the image that each inquiry returns, and the quantity of said image can not surpass this threshold value.Face in each image of image collector 504 Detection and Extraction proper vectors, and with each proper vector from the quilt inquiry of obtaining putatively mark each proper vector.The quantity of the face-image that name rank device 506 is discerned based on image collector 504 then comes the name in the list of names is carried out rank.
Fig. 6 illustrates the assembly of facial according to an embodiment of the invention signature detection device 424.Facial signature detection device 424 comprises feature detection subsystem 602, boundary mark device subsystem 604, facial probability subsystem 606 and facial detection subsystem 608.
As previously mentioned, feature detection subsystem 602 for example uses the quick moving window method in the scope of window size, and it utilizes the linear combination of mixed features detecting device collection.In an embodiment, can use boundary mark device subsystem 604 through being accurately positioned in facial features location in the facial bounding box facial detection of further refining.Facial probability subsystem 606 extracts characteristic in the position that boundary mark device subsystem 604 is discerned then, to obtain the score value of refining of the facial probability that exists of indication.Facial detection subsystem 608 confirms that based on detected characteristic and the facial probability that exists face is detected really then at least.
Fig. 7 illustrates the assembly of individual model learning system 426 according to an embodiment of the invention.Individual model learning system 426 comprises analyzer subsystem 704, optical spectrum analyser subsystem 706 and identifier subsystem 708 between model inner analysis device subsystem 702, model.
Model inner analysis device subsystem 702 realizes removing from facial signature detection device 424 phase one of the face signature of incorrect mark.Which face all face-images that model inner analysis device subsystem 702 inspection is associated with single name in the list of names under the situation of the face of not considering to belong to other names, determine be dropped.The task of model inner analysis device subsystem 702 is to remove tangible outside sgency, wherein removes and the very dissimilar face of other faces of great majority that is associated with specific name.
It is each facial neighbours' quantity and quantity of near-duplicate article of counting in group that given all marks have the facial signature group of same celebrity name, model inner analysis device subsystem 702.In an embodiment, neighbours are defined as the face that has less than the distance of for example 0.2 value, and the near-duplicate article have the distance less than for example 0.01 second value, and wherein distance range from minimum 0.0 to maximum 1.0.Model inner analysis device abandons all faces that have less than for example 10 the 3rd value neighbour then.At last, model inner analysis device subsystem 702 sorts to face according to descending through the quantity of the near-duplicate article that in group, have based on face, removes the near-duplicate article from group.For each face in the sorted lists, if facial near-duplicate article with previous appearance in tabulation then make abandoning decision; Otherwise it is retained.
If list of names comprises two near-duplicate faces that have different labels, then almost for certain in the label or both be incorrect, and this face can not to be used to mark reliably the inquiry of entering facial.Analyzer subsystem 704 in the target in this stage is between model, solves the near-duplicate face through all faces in considering to gather with paired mode.Right for each, if the facial distance that has less than for example 0.01 value, and the celebrity name of mark is inconsistent, then has like the minimum near calculated by model inner analysis device subsystem 702 face like the duplicate counting to be labeled for removing after a while.In case considered that all facial signatures are right, just abandoned the face that mark is used to remove from set.Yet this formula compares each other face in each face and the set.Therefore, possible is that single facial signature " is lost " between some comparable periods or is labeled and is used to remove and " win " other comparison.If facial signature " was lost " between any comparable period, then analyzer 704 abandons facial signature from set between model.
Optical spectrum analyser subsystem 706 realizes analyzing and using the final stage of two components.First component is relatively interior based on the individual, and second component based on the individual human world relatively.Relatively be respectively everyone in the optical spectrum analyser 706 use individuals and consider image collection.Optical spectrum analyser 706 makes up the paired relation between all images that distance matrixs are described in a people.Distance matrix is transformed into this matrix of pula, Tula, and its spectrum is analyzed.If this second eigenwert of pula, Tula is not then carried out the cluster of set less than the feature pitch that for example is set to 0.4.Otherwise, if second eigenwert greater than feature pitch, then uses average cohesion cluster that set is divided into two clusters.One in two clusters is abandoned as the outside sgency.Cluster is selected through with completions of getting off: the statistics of cluster (for example, the cluster size or type in the average image rank or formerly the average duplicate that calculates of stage count) or compare with other people image collection.Carry out to use and have the embodiment of " simple and easy " version of such comparison of the overlapping individual's of higher identifier image collection with current individual.Note, before the comparison of carrying out cluster, in current set with have between the overlapping set of the highest identifier and can set up advantage.Advantage can be through calculating this spectrum analysis of the pula, Tula of each set.Set with higher second eigenwert is considered to dominant.In another embodiment, use " complete " version, the comparison of the proprietary set in completion and the list of names.
It is identification or unknown relevant final decision that identification subsystem 708 is carried out with the face of inquiry.In an embodiment, as previously mentioned, identification subsystem 708 uses identification possibility threshold value.If do not surpass this threshold value with the similarity of the face-image of coupling, the then face of identification subsystem 708 refusal identifications inquiries, and the face that will inquire about is reported as the unknown.Otherwise identification subsystem 708 is showed the face of those identifications with the corresponding name that is associated.
Fig. 8 is the process flow diagram of method 800 of describing to be used for according to an embodiment of the invention automatic mining famous person's individual model.In step 802, identification is also collected famous person's name.In step 804, the image that identification, collection and rank are associated with the famous person's who in step 802, collects name.In step 806, the execution model inner analysis is to remove the image of incorrect mark based on the image that is associated with specific famous person.In step 808, analyze between execution model, to compare the image that further removes incorrect mark through the face that note is had different celebrity name.In step 810, carry out spectral analysis, to use further the refine image of incorrect mark of distance matrix.In step 812, make definite that whether specific image is associated with specific celebrity name.
Example computer system realizes
Aspect of the present invention shown in Fig. 1-8 or its any part or function; The tangible computer-readable medium or its that can use hardware, software module, firmware, store instruction on it make up to be realized, and can in one or more computer systems or other disposal systems, realize.
Fig. 9 is shown in the example computer system 900 that embodiments of the invention wherein or its part may be implemented as computer-readable code.For example, system 400 can use hardware, software, firmware in computer system 900, store instruction on it tangible computer-readable medium or its make up to be realized, and can in one or more computer systems or other disposal systems, realize.Hardware, software or so any combination can make in the assembly among Fig. 1-8 any one specialize.
If the use FPGA, then such logic can be carried out on commercial processing platform or specialized equipment.It will be understood by those skilled in the art that; The embodiment of disclosed theme can be with the practice of various computer system configurations, comprises multinuclear multicomputer system, small-size computer, mainframe computer, with distributed function link or the computing machine of trooping and can be embedded in the general or microcomputer in almost any equipment.
For example, can use at least one processor device and storer to realize the foregoing description.Processor device can be single processor, a plurality of processor or its combination.Processor device can have one or more processors " nuclear ".
According to this example computer system 900 various embodiment of the present invention has been described.Read should describe after, will become to various equivalent modifications that it is obvious that, use other computer systems and/or Computer Architecture how to realize the present invention.Although operation can be described to sequential process, yet in fact the part in the operation can walk abreast, simultaneously and/or in distributed environment, be performed, and program code by the Local or Remote storage for single or a plurality of processor machine access.In addition, in certain embodiments, under the situation of the spirit that does not deviate from disclosed theme, can rearrange the order of operation.
Computer system 900 (alternatively) comprises that (it can comprise input and output device to display interface 902; Such as keyboard, mouse etc.); It passes on picture, text and other data from the communications infrastructure 906 (or from frame buffer, not shown) on display unit 930, showing.
In realizing for choosing, supplementary storage 910 can comprise and is used for allowing computer program or other instructions to be loaded into other similar devices of computer system 900.Such device can comprise for example removable memory module 922 and interface 920.The example of such device can comprise program tape drum and tape drum interface (such as what in video game device, find), removable memory chip (such as EPROM or PROM) and the slot that is associated and allow software and data to be sent to other removable memory modules 922 and the interface 920 of computer system 900 from removable memory module 922.
In this document, term " computer program medium " and " computer usable medium " are commonly used to refer to such as removable memory module 918, removable memory module 922 and are installed in the medium of the hard disk in the hard disk drive 912.Computer program medium and computer usable medium can also be meant storer, and such as primary memory 908 and supplementary storage 910, it can be memory semiconductor (for example, DRAM etc.).
Computer program (being also referred to as computer control logic) is stored in primary memory 908 and/or the supplementary storage 910.Computer program can also receive via communication interface 924.Such computer program makes computer system 900 can realize the present invention who discusses as in this article when being performed.Particularly, computer program makes processor device 904 can realize process of the present invention when being performed, such as the stage in the process flow diagram 800 illustrated methods of above-mentioned Fig. 8.Therefore, such computer program is represented the controller of computer system 900.Use software to realize that under the situation of the present invention, software can be stored in the computer program, and using removable memory driver 914, interface 920 and hard disk drive 912 or communication interface 924 to be loaded in the computer system 900.
Embodiments of the invention can also be to comprising the computer program that is stored in the software on any computer usable medium.Such software impels the operation of data processing equipment as describing in this article when in one or more data processing equipments, carrying out.The embodiment of the invention utilizes any computing machine can use or computer-readable recording medium.The example of computer usable medium includes but not limited to that main storage device (for example; The RAS of any kind), auxiliary storage device (for example, hard disk drive, floppy disk, CD ROM, ZIP dish, band, magnetic storage apparatus and light storage device, MEMS, nanometer technology memory device etc.).
Conclusion
Should be understood that, be intended to use embodiment part but not summary of the invention and summary partly come the construe requirement.Summary of the invention can be illustrated of the present invention one or more but not all exemplary embodiments of inventor's expection with summary part, so summary of the invention and summary are partly and be not intended to and limit the present invention and appended claim by any way.
By means of the functional configuration piece of the realization of function and the relation thereof of explanation appointment the present invention has been described in the above.For the ease of describing, at random define the border of these functional configuration pieces in this article.Can limit for selecting the border, as long as the function of said appointment and relation thereof are suitably carried out.
The aforementioned description of specific embodiment has disclosed general aspects of the present invention so fully; Make that other people can be under the situation that does not deviate from universal of the present invention; Through the knowledge in the technology that is applied in this area is that various application are easily revised and/or adjusted such specific embodiment, and need not carry out undo experimentation.Therefore, based on instruction that provides in this article and guidance, such adjustment and modification are intended in the implication and scope of the equivalent of the disclosed embodiments.Should be understood that word in this article or term are used to describe and unrestricted purpose, so the term of this instructions or word should be by the technician according to said instructions with instruct and explain.
Width of the present invention and scope should be by any one restrictions of above-mentioned exemplary embodiment, but should only limit according to accompanying claims and equivalent thereof.
Claims (22)
1. the computer implemented method of an automatic facial identification comprises:
(a) generate one or more names based on one or more articles;
(b) obtain one or more images of claiming corresponding to said one or more names;
(c) select one or more face-images from said one or more images;
(d) said one or more face-images are associated with said one or more names; And
(e) use a model between inner analysis, model to analyze and remove incorrect related face-image with spectral analysis.
2. computer implemented method according to claim 1 further comprises: confirm the name that matees most with face-image.
3. computer implemented method according to claim 1 further comprises: the presentation graphics of confirming the individual.
4. computer implemented method according to claim 1, wherein said one or more articles are filtered, only to keep the article that comprises name.
5. computer implemented method according to claim 1, wherein said spectral analysis is based on iteration scale-of-two cluster.
6. computer implemented method according to claim 1 further comprises: when not surpassing identification possibility threshold value, be not sure of the name that matees most with face-image.
7. computer implemented method according to claim 1, wherein said spectral analysis are performed after between said model, analyzing, and analysis is performed after said model inner analysis between said model.
8. computer implemented method according to claim 1 further comprises: come name is carried out rank based on the quantity of the face-image that is associated.
9. computer implemented method according to claim 1 further comprises: be said one or more facial image detection proper vectors.
10. computer implemented method according to claim 8, wherein said detection are identified in the facial features location in said one or more face-image.
11. a system comprises:
(a) face image data storehouse;
(b) database of names; And
(c) the facial identification system of computer based comprises:
(i) list of names maker, it is configured to generate the one or more names in the list of names based on article, and one or more images of being associated with said one or more names of retrieval;
(ii) facial signature detection device, its be configured to detect and be associated in said list of names in the corresponding said one or more images of said one or more names in face-image;
(iii) model inner analysis device, its be configured to based on said list of names in the face-image that is associated of single name remove incorrect related face-image;
(iv) analyzer between model, its be configured to based on said list of names in the face-image that is associated of different names remove incorrect related face-image; And
(v) optical spectrum analyser, it is configured to remove based on similarity matrix the face-image of incorrect association.
12. system according to claim 11 further comprises: identifier, its be configured to confirm specific image whether with said list of names in specific name be associated.
13. system according to claim 11, wherein said list of names maker further comprises: name rank device, it is configured to come the said one or more names in the said list of names are carried out rank based on the quantity of the face-image that is associated.
14. system according to claim 11, wherein said facial signature detection device comprises the property detector that detects face-image based on the Gabor small echo.
15. system according to claim 11, wherein said facial signature detection device comprises that the facial features location that is based in said one or more face-image detects the property detector of face-image.
16. system according to claim 12, wherein said identifier confirms not exist the name of the coupling that is associated with face-image.
17. system according to claim 11, wherein said model inner analysis device uses in the individual based on the said face-image that is associated of all the said names in the said list of names and compares.
18. system according to claim 11, analyzer uses based on the RECURSIVE SIMILARITY property individual human world relatively relatively between wherein said model.
19. computer program; Comprise nonvolatile property computer-readable recording medium; Said nonvolatile property computer-readable recording medium includes above that and is used for realizing automatic facial identification calculation of Matching machine readable program code, and said computer control logic comprises:
First computer readable program code, it is used for impelling said computer based to generate one or more names of list of names in article, and one or more images of being associated with said one or more names of retrieval;
Second computer readable program code, its be used for impelling said COMPUTER DETECTION and be associated in the corresponding said one or more images of said one or more names of said list of names in face-image;
The 3rd computer readable program code, it is used for impelling said computer based in removing incorrect related face-image with the corresponding face-image of single name of said list of names;
The 4th computer readable program code, it is used to impel between said computing machine execution model analyzes, with based on said list of names in the face-image that is associated of different names remove incorrect related face-image;
The 5th computer readable program code, it is used to impel said computing machine to carry out spectral analysis, to remove the face-image of incorrect association based on distance matrix; And
The 6th computer readable program code, it is used for impelling said computing machine to confirm whether specific image is associated with the specific name of said list of names.
20. computer program according to claim 19 further comprises: further the 7th computer readable program code, it is used to impel said computing machine to confirm not exist the name of the coupling that is associated with face-image.
21. one kind be used for the inner analysis that uses a model, model between analyze with spectral analysis and confirm the equipment that automatic facial identification system that whether specific image is associated with the specific name of list of names is communicated by letter, comprising:
Client-based interface, it is configured to one or more names are input to the said list of names of said automatic facial identification system; And
Client-based interface, its be configured to from said automatic facial identification system receive with said list of names the specific image that is associated of specific name.
22. the method for an automatic facial identification, it comprises: generate one or more names based on one or more articles; Obtain one or more images of claiming corresponding to said one or more names; Select one or more face-images from said one or more images; Said one or more face-images are associated with said one or more names; And analyze between the inner analysis that uses a model, model and remove incorrect related face-image with spectral analysis; Definite face-image that matees most with specific name comprises:
Import one or more names; And
Receive the face-image that said and said specific name matees most.
Applications Claiming Priority (5)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US27291209P | 2009-11-18 | 2009-11-18 | |
US61/272,912 | 2009-11-18 | ||
US12/859,721 US8605956B2 (en) | 2009-11-18 | 2010-08-19 | Automatically mining person models of celebrities for visual search applications |
US12/859,721 | 2010-08-19 | ||
PCT/US2010/056869 WO2011062911A1 (en) | 2009-11-18 | 2010-11-16 | Automatically mining person models of celebrities for visual search applications |
Publications (2)
Publication Number | Publication Date |
---|---|
CN102804208A true CN102804208A (en) | 2012-11-28 |
CN102804208B CN102804208B (en) | 2016-08-17 |
Family
ID=44011321
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201080061203.1A Active CN102804208B (en) | 2009-11-18 | 2010-11-16 | Individual model for visual search application automatic mining famous person |
Country Status (7)
Country | Link |
---|---|
US (1) | US8605956B2 (en) |
EP (1) | EP2502185A1 (en) |
KR (1) | KR101967410B1 (en) |
CN (1) | CN102804208B (en) |
AU (1) | AU2010322173B2 (en) |
CA (1) | CA2781105A1 (en) |
WO (1) | WO2011062911A1 (en) |
Cited By (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN106375817A (en) * | 2015-07-21 | 2017-02-01 | 三星电子株式会社 | Electronic device and method for providing broadcast program |
CN109086697A (en) * | 2018-07-20 | 2018-12-25 | 腾讯科技（深圳）有限公司 | A kind of human face data processing method, device and storage medium |
CN111971686A (en) * | 2018-12-12 | 2020-11-20 | 微软技术许可有限责任公司 | Automatic generation of training data sets for object recognition |
CN113127712A (en) * | 2019-12-31 | 2021-07-16 | 深圳云天励飞技术有限公司 | Archiving method and device |
Families Citing this family (52)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7801864B2 (en) | 2005-11-28 | 2010-09-21 | Commvault Systems, Inc. | Systems and methods for using metadata to enhance data identification operations |
US20200257596A1 (en) | 2005-12-19 | 2020-08-13 | Commvault Systems, Inc. | Systems and methods of unified reconstruction in storage systems |
US20150015576A1 (en) * | 2009-08-07 | 2015-01-15 | Cherif Atia Algreatly | Object recognition and visualization |
US8121618B2 (en) | 2009-10-28 | 2012-02-21 | Digimarc Corporation | Intuitive computing methods and systems |
US8903798B2 (en) | 2010-05-28 | 2014-12-02 | Microsoft Corporation | Real-time annotation and enrichment of captured video |
US9311395B2 (en) | 2010-06-10 | 2016-04-12 | Aol Inc. | Systems and methods for manipulating electronic content based on speech recognition |
US8601076B2 (en) | 2010-06-10 | 2013-12-03 | Aol Inc. | Systems and methods for identifying and notifying users of electronic content based on biometric recognition |
BR112013006018A2 (en) * | 2010-09-14 | 2016-06-07 | Dynamic Digital Depth Reseach Pty Ltd | method for improving depth maps |
US8559682B2 (en) * | 2010-11-09 | 2013-10-15 | Microsoft Corporation | Building a person profile database |
US8645230B2 (en) * | 2011-03-18 | 2014-02-04 | Microsoft Corporation | Virtual closet for storing and accessing virtual representations of items |
US9036925B2 (en) * | 2011-04-14 | 2015-05-19 | Qualcomm Incorporated | Robust feature matching for visual search |
US9678992B2 (en) | 2011-05-18 | 2017-06-13 | Microsoft Technology Licensing, Llc | Text to image translation |
US8811726B2 (en) * | 2011-06-02 | 2014-08-19 | Kriegman-Belhumeur Vision Technologies, Llc | Method and system for localizing parts of an object in an image for computer vision applications |
US8948518B2 (en) * | 2011-07-14 | 2015-02-03 | Futurewei Technologies, Inc. | Scalable query for visual search |
US9087273B2 (en) * | 2011-11-15 | 2015-07-21 | Facebook, Inc. | Facial recognition using social networking information |
US8971591B2 (en) * | 2011-12-09 | 2015-03-03 | Google Technology Holdings LLC | 3D image estimation for 2D image recognition |
EP2766850B1 (en) * | 2011-12-09 | 2021-08-25 | Google Technology Holdings LLC | Faceprint generation for image recognition |
US8892523B2 (en) | 2012-06-08 | 2014-11-18 | Commvault Systems, Inc. | Auto summarization of content |
US9336302B1 (en) | 2012-07-20 | 2016-05-10 | Zuci Realty Llc | Insight and algorithmic clustering for automated synthesis |
KR101993241B1 (en) * | 2012-08-06 | 2019-06-26 | 삼성전자주식회사 | Method and system for tagging and searching additional information about image, apparatus and computer readable recording medium thereof |
EP2915062A4 (en) * | 2012-11-01 | 2016-06-29 | Google Inc | Image comparison process |
US9137314B2 (en) | 2012-11-06 | 2015-09-15 | At&T Intellectual Property I, L.P. | Methods, systems, and products for personalized feedback |
US9690980B2 (en) | 2012-11-09 | 2017-06-27 | Google Inc. | Automatic curation of digital images |
US10509963B2 (en) * | 2012-12-20 | 2019-12-17 | Microsoft Technology Licensing, Llc | Discovering authoritative images of people entities |
US9235782B1 (en) * | 2012-12-24 | 2016-01-12 | Google Inc. | Searching images and identifying images with similar facial features |
US9098552B2 (en) | 2013-02-05 | 2015-08-04 | Google Inc. | Scoring images related to entities |
US9311640B2 (en) | 2014-02-11 | 2016-04-12 | Digimarc Corporation | Methods and arrangements for smartphone payments and transactions |
US9530072B2 (en) | 2013-03-15 | 2016-12-27 | Dropbox, Inc. | Duplicate/near duplicate detection and image registration |
US20150100289A1 (en) * | 2013-10-09 | 2015-04-09 | Technion Research & Development Foundation Limited | Method and system for shapewise comparison |
US9569656B2 (en) | 2013-12-06 | 2017-02-14 | Google Inc. | Local real-time facial recognition |
US9268793B2 (en) | 2014-03-12 | 2016-02-23 | Google Inc. | Adjustment of facial image search results |
US9875301B2 (en) | 2014-04-30 | 2018-01-23 | Microsoft Technology Licensing, Llc | Learning multimedia semantics from large-scale unstructured data |
US9934423B2 (en) | 2014-07-29 | 2018-04-03 | Microsoft Technology Licensing, Llc | Computerized prominent character recognition in videos |
US9646227B2 (en) | 2014-07-29 | 2017-05-09 | Microsoft Technology Licensing, Llc | Computerized machine learning of interesting video sections |
US10013637B2 (en) | 2015-01-22 | 2018-07-03 | Microsoft Technology Licensing, Llc | Optimizing multi-class image classification using patch features |
US9785866B2 (en) | 2015-01-22 | 2017-10-10 | Microsoft Technology Licensing, Llc | Optimizing multi-class multimedia data classification using negative data |
US9507996B2 (en) * | 2015-03-02 | 2016-11-29 | International Business Machines Corporation | Ensuring a desired distribution of images in a multimedia document utilizing facial signatures |
US10121056B2 (en) | 2015-03-02 | 2018-11-06 | International Business Machines Corporation | Ensuring a desired distribution of content in a multimedia document for different demographic groups utilizing demographic information |
US10482091B2 (en) * | 2016-03-18 | 2019-11-19 | Oath Inc. | Computerized system and method for high-quality and high-ranking digital content discovery |
US10535371B2 (en) | 2016-09-13 | 2020-01-14 | Intel Corporation | Speaker segmentation and clustering for video summarization |
US10540516B2 (en) | 2016-10-13 | 2020-01-21 | Commvault Systems, Inc. | Data protection within an unsecured storage environment |
CN106548162B (en) * | 2016-11-24 | 2019-03-29 | 中译语通科技股份有限公司 | A method of automatically extracting band name human face data from news pages |
US11205103B2 (en) | 2016-12-09 | 2021-12-21 | The Research Foundation for the State University | Semisupervised autoencoder for sentiment analysis |
CN107180093B (en) * | 2017-05-15 | 2020-05-19 | 北京奇艺世纪科技有限公司 | Information searching method and device and timeliness query word identification method and device |
US10025950B1 (en) * | 2017-09-17 | 2018-07-17 | Everalbum, Inc | Systems and methods for image recognition |
US11605017B1 (en) * | 2017-12-26 | 2023-03-14 | Meta Platforms, Inc. | Machine-learning based detection of policy-violating information in content |
US10642886B2 (en) * | 2018-02-14 | 2020-05-05 | Commvault Systems, Inc. | Targeted search of backup data using facial recognition |
US11074434B2 (en) * | 2018-04-27 | 2021-07-27 | Microsoft Technology Licensing, Llc | Detection of near-duplicate images in profiles for detection of fake-profile accounts |
US10963677B2 (en) | 2018-07-23 | 2021-03-30 | The Mitre Corporation | Name and face matching |
CN111259918B (en) * | 2018-11-30 | 2023-06-20 | 重庆小雨点小额贷款有限公司 | Method and device for labeling intention labels, server and storage medium |
AU2020329148A1 (en) * | 2019-08-09 | 2022-03-17 | Clearview Ai, Inc. | Methods for providing information about a person based on facial recognition |
WO2023114758A1 (en) * | 2021-12-14 | 2023-06-22 | Canon U.S.A., Inc. | Apparatus and method for issuance of meeting invitations |
Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20030210808A1 (en) * | 2002-05-10 | 2003-11-13 | Eastman Kodak Company | Method and apparatus for organizing and retrieving images containing human faces |
US20070258646A1 (en) * | 2002-12-06 | 2007-11-08 | Samsung Electronics Co., Ltd. | Human detection method and apparatus |
CN101295352A (en) * | 2007-04-13 | 2008-10-29 | 兴瑞科技有限公司 | Human face recognition and user interface system for digital camera and video camera |
Family Cites Families (8)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7298412B2 (en) * | 2001-09-18 | 2007-11-20 | Ricoh Company, Limited | Image pickup device, automatic focusing method, automatic exposure method, electronic flash control method and computer program |
US8064650B2 (en) * | 2002-07-10 | 2011-11-22 | Hewlett-Packard Development Company, L.P. | File management of digital images using the names of people identified in the images |
US7274822B2 (en) * | 2003-06-30 | 2007-09-25 | Microsoft Corporation | Face annotation for photo management |
KR100858087B1 (en) * | 2007-02-14 | 2008-09-10 | 삼성전자주식회사 | Object Pose Normalization Method and Apparatus and Object Recognition Method |
CN101398832A (en) * | 2007-09-30 | 2009-04-01 | 国际商业机器公司 | Image searching method and system by utilizing human face detection |
US8213689B2 (en) * | 2008-07-14 | 2012-07-03 | Google Inc. | Method and system for automated annotation of persons in video content |
KR20120035292A (en) * | 2010-10-05 | 2012-04-16 | 엘지전자 주식회사 | Electronic device and operating method thereof |
US8559682B2 (en) * | 2010-11-09 | 2013-10-15 | Microsoft Corporation | Building a person profile database |
-
2010
- 2010-08-19 US US12/859,721 patent/US8605956B2/en active Active
- 2010-11-16 CA CA2781105A patent/CA2781105A1/en not_active Abandoned
- 2010-11-16 CN CN201080061203.1A patent/CN102804208B/en active Active
- 2010-11-16 KR KR1020127015598A patent/KR101967410B1/en active IP Right Grant
- 2010-11-16 WO PCT/US2010/056869 patent/WO2011062911A1/en active Application Filing
- 2010-11-16 AU AU2010322173A patent/AU2010322173B2/en not_active Ceased
- 2010-11-16 EP EP10782762A patent/EP2502185A1/en not_active Ceased
Patent Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20030210808A1 (en) * | 2002-05-10 | 2003-11-13 | Eastman Kodak Company | Method and apparatus for organizing and retrieving images containing human faces |
US20070258646A1 (en) * | 2002-12-06 | 2007-11-08 | Samsung Electronics Co., Ltd. | Human detection method and apparatus |
CN101295352A (en) * | 2007-04-13 | 2008-10-29 | 兴瑞科技有限公司 | Human face recognition and user interface system for digital camera and video camera |
Non-Patent Citations (1)
Title |
---|
TAMARA L.BERG: "Names and Faces in the News", 《IEEE CVPR》 * |
Cited By (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN106375817A (en) * | 2015-07-21 | 2017-02-01 | 三星电子株式会社 | Electronic device and method for providing broadcast program |
CN109086697A (en) * | 2018-07-20 | 2018-12-25 | 腾讯科技（深圳）有限公司 | A kind of human face data processing method, device and storage medium |
CN111971686A (en) * | 2018-12-12 | 2020-11-20 | 微软技术许可有限责任公司 | Automatic generation of training data sets for object recognition |
CN113127712A (en) * | 2019-12-31 | 2021-07-16 | 深圳云天励飞技术有限公司 | Archiving method and device |
Also Published As
Publication number | Publication date |
---|---|
AU2010322173A1 (en) | 2012-06-07 |
KR101967410B1 (en) | 2019-04-10 |
EP2502185A1 (en) | 2012-09-26 |
CA2781105A1 (en) | 2011-05-26 |
US8605956B2 (en) | 2013-12-10 |
AU2010322173B2 (en) | 2014-07-17 |
WO2011062911A1 (en) | 2011-05-26 |
KR20120086728A (en) | 2012-08-03 |
CN102804208B (en) | 2016-08-17 |
US20110116690A1 (en) | 2011-05-19 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN102804208A (en) | Automatically mining person models of celebrities for visual search applications | |
US11182640B2 (en) | Analyzing content of digital images | |
US20240028571A1 (en) | Automatic entity resolution with rules detection and generation system | |
Whitelam et al. | Iarpa janus benchmark-b face dataset | |
Tran et al. | Rich image captioning in the wild | |
JP6397144B2 (en) | Business discovery from images | |
US10140575B2 (en) | Sports formation retrieval | |
CN105027162B (en) | Image analysis apparatus, image analysis system, method for analyzing image | |
US9278255B2 (en) | System and method for activity recognition | |
CN105843850B (en) | Search optimization method and device | |
CN108960124B (en) | Image processing method and device for pedestrian re-identification | |
CN111325115A (en) | Countermeasures cross-modal pedestrian re-identification method and system with triple constraint loss | |
CN106663196A (en) | Computerized prominent person recognition in videos | |
CN107220663B (en) | Automatic image annotation method based on semantic scene classification | |
L'Heureux et al. | A gamification framework for sensor data analytics | |
CN111931616A (en) | Emotion recognition method and system based on mobile intelligent terminal sensor equipment | |
CN110751027A (en) | Pedestrian re-identification method based on deep multi-instance learning | |
CN108875448B (en) | Pedestrian re-identification method and device | |
Dewi et al. | Combination of resnet and spatial pyramid pooling for musical instrument identification | |
CN103443772A (en) | System and method for demographic analytics based on multimodal information | |
CN110472057B (en) | Topic label generation method and device | |
CN111723628B (en) | Person re-identification method, person re-identification system and image screening method | |
Dong et al. | Scene-oriented hierarchical classification of blurry and noisy images | |
Sowmyayani et al. | STHARNet: Spatio-temporal human action recognition network in content based video retrieval | |
Xu et al. | Estimating similarity of rich internet pages using visual information |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
C06 | Publication | ||
PB01 | Publication | ||
C10 | Entry into substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
C14 | Grant of patent or utility model | ||
GR01 | Patent grant | ||
CP01 | Change in the name or title of a patent holder |
Address after: American CaliforniaPatentee after: Google limited liability companyAddress before: American CaliforniaPatentee before: Google Inc. |
|
CP01 | Change in the name or title of a patent holder |