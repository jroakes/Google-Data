CN103109260A - Parallel processing of data - Google Patents
Parallel processing of data Download PDFInfo
- Publication number
- CN103109260A CN103109260A CN2011800327395A CN201180032739A CN103109260A CN 103109260 A CN103109260 A CN 103109260A CN 2011800327395 A CN2011800327395 A CN 2011800327395A CN 201180032739 A CN201180032739 A CN 201180032739A CN 103109260 A CN103109260 A CN 103109260A
- Authority
- CN
- China
- Prior art keywords
- parallel
- delays
- data
- mapping
- carry out
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
- 238000012545 processing Methods 0.000 title claims abstract description 106
- 230000009466 transformation Effects 0.000 claims abstract description 20
- 238000013507 mapping Methods 0.000 claims description 335
- 230000001934 delay Effects 0.000 claims description 221
- 230000006870 function Effects 0.000 claims description 215
- 238000000034 method Methods 0.000 claims description 147
- 230000008569 process Effects 0.000 claims description 111
- 238000012937 correction Methods 0.000 claims description 19
- 238000004891 communication Methods 0.000 claims description 10
- 241001269238 Data Species 0.000 claims description 5
- 238000012550 audit Methods 0.000 claims description 3
- 238000000844 transformation Methods 0.000 abstract 1
- 238000012384 transportation and delivery Methods 0.000 description 44
- 238000010586 diagram Methods 0.000 description 16
- 239000012634 fragment Substances 0.000 description 16
- 238000006243 chemical reaction Methods 0.000 description 13
- 238000003860 storage Methods 0.000 description 12
- 230000004927 fusion Effects 0.000 description 11
- 244000035744 Hura crepitans Species 0.000 description 9
- 238000011156 evaluation Methods 0.000 description 8
- 238000005516 engineering process Methods 0.000 description 7
- 238000005457 optimization Methods 0.000 description 6
- 230000003111 delayed effect Effects 0.000 description 5
- 230000007246 mechanism Effects 0.000 description 5
- 238000009795 derivation Methods 0.000 description 4
- 239000000284 extract Substances 0.000 description 4
- 230000003993 interaction Effects 0.000 description 4
- 230000009471 action Effects 0.000 description 3
- 239000002131 composite material Substances 0.000 description 3
- 238000013461 design Methods 0.000 description 3
- 238000006062 fragmentation reaction Methods 0.000 description 3
- 230000007704 transition Effects 0.000 description 3
- 238000004364 calculation method Methods 0.000 description 2
- 230000008859 change Effects 0.000 description 2
- 238000013500 data storage Methods 0.000 description 2
- 238000009826 distribution Methods 0.000 description 2
- 230000007613 environmental effect Effects 0.000 description 2
- 238000007726 management method Methods 0.000 description 2
- 230000001360 synchronised effect Effects 0.000 description 2
- 238000012360 testing method Methods 0.000 description 2
- 235000017060 Arachis glabrata Nutrition 0.000 description 1
- 244000105624 Arachis hypogaea Species 0.000 description 1
- 235000010777 Arachis hypogaea Nutrition 0.000 description 1
- 235000018262 Arachis monticola Nutrition 0.000 description 1
- 239000004183 Monensin A Substances 0.000 description 1
- 238000004458 analytical method Methods 0.000 description 1
- 230000004888 barrier function Effects 0.000 description 1
- 230000033228 biological regulation Effects 0.000 description 1
- 230000005540 biological transmission Effects 0.000 description 1
- 238000004140 cleaning Methods 0.000 description 1
- 238000004590 computer program Methods 0.000 description 1
- 238000007796 conventional method Methods 0.000 description 1
- 230000007423 decrease Effects 0.000 description 1
- 238000012217 deletion Methods 0.000 description 1
- 230000037430 deletion Effects 0.000 description 1
- 238000011161 development Methods 0.000 description 1
- 230000000694 effects Effects 0.000 description 1
- 230000008570 general process Effects 0.000 description 1
- 238000011835 investigation Methods 0.000 description 1
- 238000012423 maintenance Methods 0.000 description 1
- 230000014759 maintenance of location Effects 0.000 description 1
- 238000012986 modification Methods 0.000 description 1
- 230000004048 modification Effects 0.000 description 1
- 230000003287 optical effect Effects 0.000 description 1
- 235000020232 peanut Nutrition 0.000 description 1
- 239000012466 permeate Substances 0.000 description 1
- 238000013439 planning Methods 0.000 description 1
- 238000006116 polymerization reaction Methods 0.000 description 1
- 239000000047 product Substances 0.000 description 1
- 238000007670 refining Methods 0.000 description 1
- 230000008439 repair process Effects 0.000 description 1
- 238000012552 review Methods 0.000 description 1
- 230000035807 sensation Effects 0.000 description 1
- 235000019615 sensations Nutrition 0.000 description 1
- 238000012163 sequencing technique Methods 0.000 description 1
- 238000009331 sowing Methods 0.000 description 1
- 238000010561 standard procedure Methods 0.000 description 1
- 238000011079 streamline operation Methods 0.000 description 1
- 235000019640 taste Nutrition 0.000 description 1
- 230000001052 transient effect Effects 0.000 description 1
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/50—Monitoring users, programs or devices to maintain the integrity of platforms, e.g. of processors, firmware or operating systems
- G06F21/57—Certifying or maintaining trusted computer platforms, e.g. secure boots or power-downs, version controls, system software checks, secure updates or assessing vulnerabilities
- G06F21/577—Assessing vulnerabilities and evaluating computer system security
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/60—Protecting data
- G06F21/62—Protecting access to data via a platform, e.g. using keys or access control rules
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/60—Protecting data
- G06F21/62—Protecting access to data via a platform, e.g. using keys or access control rules
- G06F21/6218—Protecting access to data via a platform, e.g. using keys or access control rules to a system of files or objects, e.g. local or distributed file system or database
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F8/00—Arrangements for software engineering
- G06F8/30—Creation or generation of source code
- G06F8/31—Programming languages or programming paradigms
- G06F8/314—Parallel programming languages
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F8/00—Arrangements for software engineering
- G06F8/30—Creation or generation of source code
- G06F8/34—Graphical or visual programming
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F8/00—Arrangements for software engineering
- G06F8/40—Transformation of program code
- G06F8/41—Compilation
- G06F8/43—Checking; Contextual analysis
- G06F8/433—Dependency analysis; Data or control flow analysis
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/30—Arrangements for executing machine instructions, e.g. instruction decode
- G06F9/38—Concurrent instruction execution, e.g. pipeline, look ahead
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/30—Arrangements for executing machine instructions, e.g. instruction decode
- G06F9/38—Concurrent instruction execution, e.g. pipeline, look ahead
- G06F9/3836—Instruction issuing, e.g. dynamic instruction scheduling or out of order instruction execution
- G06F9/3851—Instruction issuing, e.g. dynamic instruction scheduling or out of order instruction execution from multiple instruction streams, e.g. multistreaming
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/30—Arrangements for executing machine instructions, e.g. instruction decode
- G06F9/38—Concurrent instruction execution, e.g. pipeline, look ahead
- G06F9/3885—Concurrent instruction execution, e.g. pipeline, look ahead using a plurality of independent parallel functional units
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/44—Arrangements for executing specific programs
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/44—Arrangements for executing specific programs
- G06F9/445—Program loading or initiating
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/44—Arrangements for executing specific programs
- G06F9/455—Emulation; Interpretation; Software simulation, e.g. virtualisation or emulation of application or operating system execution engines
- G06F9/45504—Abstract machines for programme code execution, e.g. Java virtual machine [JVM], interpreters, emulators
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/44—Arrangements for executing specific programs
- G06F9/455—Emulation; Interpretation; Software simulation, e.g. virtualisation or emulation of application or operating system execution engines
- G06F9/45533—Hypervisors; Virtual machine monitors
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/46—Multiprogramming arrangements
- G06F9/48—Program initiating; Program switching, e.g. by interrupt
- G06F9/4806—Task transfer initiation or dispatching
- G06F9/4843—Task transfer initiation or dispatching by program, e.g. task dispatcher, supervisor, operating system
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/24—Querying
- G06F16/245—Query processing
- G06F16/2453—Query optimisation
- G06F16/24532—Query optimisation of parallel queries
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/24—Querying
- G06F16/245—Query processing
- G06F16/2453—Query optimisation
- G06F16/24534—Query rewriting; Transformation
- G06F16/24547—Optimisations to support specific applications; Extensibility of optimisers
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F2221/00—Indexing scheme relating to security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F2221/03—Indexing scheme relating to G06F21/50, monitoring users, programs or devices to maintain the integrity of platforms
- G06F2221/034—Test or assess a computer or a system
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/30—Arrangements for executing machine instructions, e.g. instruction decode
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/44—Arrangements for executing specific programs
- G06F9/448—Execution paradigms, e.g. implementations of programming paradigms
- G06F9/4494—Execution paradigms, e.g. implementations of programming paradigms data driven
Abstract
An untrusted application is received at a data center including one or more processing modules and providing a native processing environment. The untrusted application includes a data parallel pipeline. Secured processing environments are used to execute the untrusted application. A data parallel pipeline may specify multiple parallel data objects and parallel operations. Based on the data parallel pipeline, a dataflow graph of deferred parallel data objects and deferred parallel operations may be generated and one or more graph transformations may be applied to the dataflow graph to generate a revised dataflow graph that includes one or more of the deferred parallel data objects and deferred, combined parallel data operations. The deferred, combined parallel operations may be executed to produce materialized parallel data objects corresponding to the deferred parallel data objects.
Description
Priority request
The application require to be incorporated into by reference and all this, on May 4th, 2010 submit to the 61/331st, No. 148 U.S. Patent applications, on June 4th, 2010 submit to the 12/794th, the right of priority of No. 348 U.S. Patent applications and the 12/959th, No. 022 U.S. Patent application submitting on Dec 2nd, 2010.
Technical field
Present disclosure relates to the parallel processing of data.
Background technology
Large-scale data is processed can comprise parallel processing, and parallel processing relates generally to carries out a certain operation to each element of large data sets.Various operations can link together to create the efficient mechanism for the treatment of data set in data parallel pipeline.
Summary of the invention
In one aspect, comprising one or more processing module and providing the data center of the machine processing environment to receive the non-letter application of putting.The non-letter of putting is used and to be comprised data parallel pipeline.Data parallel pipeline is specified a plurality of parallel data objects that comprise a plurality of elements and a plurality of parallel work-flows that are associated with the non-confidence function that element is operated.Instantiation the first secure computing environment on one or more processing module in the machine processing environment and in processing module.Carrying out the non-letter of putting in the first secure computing environment uses.Carry out the data stream figure of using the parallel work-flow that generates the parallel data object that delay corresponding with data parallel pipeline and delay.Pass on the information of representative data stream graphics beyond the first secure computing environment.Beyond the first secure computing environment and in the machine processing environment, the information that one or more graph transformation is applied to the representative data stream graphics to be generating the data stream figure of revising, the data stream figure of correction comprise with non-confidence function in that be associated, the parallel data object that delay of one or more non-confidence function and one or more the parallel data object that delays in the combination parallel data operation that delays and the combination parallel data operation that delays.What execution delayed is combined line operate to produce the parallel data object specialized corresponding with the parallel data object that delays.The line operate that is combined that execution delays comprises: one or more second secure computing environment of instantiation on one or more processing module in the machine processing environment and in processing module; And carry out and the non-confidence function that line operate is associated that is combined that delays in one or more second secure computing environment.
Implementation can comprise one or more feature in following characteristics.For example, the first secure computing environment can comprise the first virtual machine, and one or more second secure computing environment can comprise the second virtual machine.The first virtual machine and one or more second virtual machine can be hardware virtual machines.Carry out in one or more second secure computing environment with delay be combined the non-confidence function that line operate is associated and can comprise:, input batch processor log and comprise a plurality of indivedual input records to pass on the input batch processor log export-oriented the second secure computing environment from the second secure computing environment; Each record in the individual record of input in batch processing is carried out with at least one the non-confidence function that is combined in the non-confidence function that line operate is associated that delays exported record to generate; To export record and accumulate the output batch processing; And pass on the output batch processing beyond the second secure computing environment.
Non-output of putting the letter application can be sent to data center and send the non-client that letter is used of putting.Pass on the information of representative data stream graphics can comprise to the information of the execution figure service communication representative data stream graphics beyond the first secure computing environment beyond the first secure computing environment.
The combination parallel data operation that delays can comprise that the mapping of at least one broad sense simplifies operation.Broad sense mapping simplify operation can comprise a plurality of parallel map operations and a plurality of parallel simplify operation and can be translated into single mapping simplify operation, single mapping is simplified operation and is comprised be used to the single mapping function of implementing a plurality of parallel map operations and be used for implementing a plurality of parallel single functions of simplifying of simplifying operation.Single mapping function and the single function of simplifying can comprise one or more non-confidence function in non-confidence function.
Execution delays is combined line operate and can comprises that combinatorial mapping is simplified operation to be translated into single mapping and to simplify operation.Carry out in one or more second secure computing environment with delay be combined the non-confidence function that line operate is associated and can be included in the single mapping function of execution and the single function of simplifying in one or more second secure computing environment.
Carrying out the non-letter of putting in secure computing environment uses and carries out the non-letter of putting in the virtual machine that can be included in the first secure computing environment and use.Carry out in one or more secure computing environment with being combined of the delaying non-confidence function that line operate is associated and to be included in execution and the non-confidence function that line operate is associated that is combined that delays in virtual machine in one or more second secure computing environment.
Passing in addition the information of representative data stream graphics to comprise at the first secure computing environment uses remote procedure call to pass on the information of representative data stream graphics beyond the first secure computing environment.Can examine remote procedure call.
In another aspect, a kind of system comprises: one or more processing module is configured to provide the machine processing environment and is implemented in the first secure computing environment in the machine processing environment, is arranged in beyond the first secure computing environment and in the service of the machine processing environment and at one or more second secure computing environment of the machine processing environment.
The first secure computing environment is configured to carry out the non-letter of putting that comprises data parallel pipeline and uses.Data parallel pipeline is specified a plurality of parallel data objects that comprise a plurality of elements and a plurality of parallel work-flows that are associated with the non-confidence function that element is operated.Carry out the data stream figure of using the parallel work-flow that generates the parallel data object that delay corresponding with data parallel pipeline and delay.The first secure computing environment also is configured to pass on the information of representative data stream graphics beyond the first secure computing environment
Service is configured to: the information that receives the representative data stream graphics from the first secure computing environment; The information that one or more graph transformation is applied to the representative data stream graphics to be generating the data stream figure of revising, the data stream figure of correction comprise with non-confidence function in that be associated, the parallel data object that delay of one or more non-confidence function and one or more the parallel data object that delays in the combination parallel data operation that delays and the combination parallel data operation that delays; And cause carry out delay be combined line operate to produce the specific parallel data object corresponding with the parallel data object that delays.
One or more second secure computing environment is configured to carry out with the non-confidence function that line operate is associated that is combined that delays carries out to cause the line operate that is combined that delays.
Implementation can comprise one or more feature in following characteristics.For example, the first secure computing environment can comprise the first virtual machine, and one or more second secure computing environment can comprise the second virtual machine.The first virtual machine and one or more second virtual machine can be hardware virtual machines.
One or more treatment facility can be configured to the implementation device, and working device is configured to from the second secure computing environment to pass on the input batch processor log export-oriented the second secure computing environment.The input batch processor log can comprise a plurality of indivedual input records.In order to carry out and the non-confidence function that line operate is associated that is combined that delays, one or more second secure computing environment can be configured to: each record in the individual record of input in batch processing is carried out with at least one the non-confidence function that is combined in the non-confidence function that line operate is associated that delays exported record to generate; To export record and accumulate the output batch processing; And pass on the output batch processing to working device.
This system can comprise and is configured to receive non-client of putting the output that letter uses.The combination parallel data operation that delays can comprise that the mapping of at least one broad sense simplifies operation.Broad sense mapping simplify operation can comprise a plurality of parallel map operations and a plurality of parallel simplify operation and can be translated into single mapping simplify operation, single mapping is simplified operation and is comprised be used to the single mapping function of implementing a plurality of parallel map operations and be used for implementing a plurality of parallel single functions of simplifying of simplifying operation.Single mapping function and the single function of simplifying can comprise one or more non-confidence function in non-confidence function.
Service can be configured to that combinatorial mapping is simplified operation and be translated into single mapping and simplify operation.One or more second secure computing environment can be configured to carry out single mapping function and the single function of simplifying in one or more the second secure computing environment.
The first secure computing environment can be configured to carry out in virtual machine in the first secure computing environment the non-letter of putting and use.Can be configured in one or more second secure computing environment carry out and the non-confidence function that line operate is associated that is combined that delays in the virtual machine in one or more the second secure computing environment.
In another aspect, access represents the information of the data stream figure of the parallel data object that delays and the parallel work-flow that delays.The parallel data object that delays and the parallel work-flow that delays are corresponding to putting by non-parallel data object and the parallel work-flow that letter is used the data parallel pipeline appointment that comprises.The parallel data object comprises a plurality of elements, and parallel work-flow is associated with the non-confidence function that element is operated.The information that one or more graph transformation is applied to the representative data stream graphics to be generating the data stream figure of revising, the data stream figure of correction comprise with non-confidence function in that be associated, the parallel data object that delay of one or more non-confidence function and one or more the parallel data object that delays in the combination parallel data operation that delays and the combination parallel data operation that delays.What execution delayed is combined line operate to produce the parallel data object specialized corresponding with the parallel data object that delays.The line operate that is combined that execution delays comprises: one or more secure computing environment of instantiation; And carry out and the non-confidence function that line operate is associated that is combined that delays in one or more secure computing environment.
Can receive the non-letter of putting that comprises data parallel pipeline and use, and can instantiation initial safe processing environment.Can carry out the non-letter of putting in the initial safe processing environment uses.Carry out and use the data stream figure that can generate the parallel data object that delays and the parallel work-flow that delays.Can pass on the information of representative data stream graphics beyond the initial safe processing environment, thereby make graph transformation be applied to the information of representative data stream graphics beyond the initial safe processing environment.One or more secure computing environment can comprise virtual machine.
In another aspect, a kind of system comprises one or more treatment facility and one or more memory device.Memory device, stores practices when being carried out by one or more treatment facility, the instruction of evaluator, optimizer and actuator.Application comprises data parallel pipeline.Data parallel pipeline is specified a plurality of parallel data objects comprise a plurality of elements and to a plurality of parallel work-flows of parallel data Object Operations.Evaluator based on data parallel pipeline is configured to generate the data stream figure of the parallel data object that delay corresponding with data parallel pipeline and the parallel work-flow that delays.
The parallel data object that delays can be for example the data structure that comprises pointer, and pointed is to the parallel data object rather than to the parallel data operation of the element stored in parallel data object operation.The parallel work-flow that delays can be for example data structure, this data structure comprises the pointer that points to the parallel data object, the pointer that points to the Parallel Object that delays and the function that (but not yet) carried out input object, parallel data to as if to the input of the parallel work-flow that delays, the Parallel Object that delays is the output of the parallel work-flow that delays.
Optimizer is configured to one or more graph transformation is applied to the data stream figure to generate the data stream figure of revising, and the data stream figure of correction comprises one or more the parallel data object that delays in the parallel data object that delays and the combination parallel data operation that delays and the combination parallel data operation that delays.Actuator be configured to carry out delay be combined line operate to produce the specific parallel data object corresponding with the parallel data object that delays.The parallel data object of specializing can be for example to comprise the data of parallel data object or the data structure of element.
This implementation on the one hand can comprise one or more feature in following characteristics.For example, the combination parallel data operation that delays can comprise that the mapping of at least one broad sense simplifies operation.Broad sense mapping simplify operation can comprise a plurality of parallel map operations and a plurality of parallel simplify operation and can be translated into single mapping simplify operation, single mapping is simplified operation and is comprised be used to the single mapping function of implementing a plurality of parallel map operations and be used for implementing a plurality of parallel single functions of simplifying of simplifying operation.Simplify operation in order to carry out broad sense mapping, actuator can be configured to that combinatorial mapping is simplified operation and be translated into single mapping and simplify operation and carry out single mapping and simplify operation.Simplify operation in order to carry out single mapping, actuator can be configured to determine whether to carry out single mapping and simplify operation as local sequential operation or long-range parallel work-flow.Be translated into single mapping and simplify operation for broad sense mapping being simplified operation, actuator can be configured to generate the mapping function that comprises a plurality of map operations and comprise a plurality of simplify the device operation simplify the device function.
The first kind object that a plurality of parallel data objects can be the main frame programming languages.
Streamline can also comprise the individual data object, and the individual data object comprises individual element, and the data stream figure comprises the corresponding individual data object that delays.At least one parallel work-flow in a plurality of parallel work-flows in streamline can be to a parallel data Object Operations in individual data object and a plurality of parallel data object, and the data stream figure can comprise the parallel work-flow that delays to the correspondence of the individual data object that delays and the parallel data Object Operations that delays.
Actuator can be configured to high-speed cache to be carried out one or more result that is combined line operate delay and uses to be used for carrying out in the future of data parallel pipeline.
In another aspect, a kind of method comprises that execution comprises the application of data parallel pipeline.Data parallel pipeline is specified a plurality of parallel data objects comprise a plurality of elements and to a plurality of parallel work-flows of parallel data Object Operations.The method comprises that also the based on data parallel pipeline generates the data stream figure of the parallel data object that delay corresponding with data parallel pipeline and the parallel work-flow that delays.The parallel data object that delays can be for example the data structure that comprises pointer, and this pointed is to the parallel data object rather than to the parallel data operation of the element stored in parallel data object operation.The parallel work-flow that delays can be for example data structure, this data structure comprises the pointer that points to the parallel data object, the pointer that points to the Parallel Object that delays and the function that (but not yet) carried out input object, parallel data to as if to the input of the parallel work-flow that delays, the Parallel Object that delays is the output of the parallel work-flow that delays.
The method also comprises one or more graph transformation is applied to the data stream figure of data stream figure generate to revise, and the data stream figure of correction comprises one or more the parallel data object that delays in the parallel data object that delays and the combination parallel data operation that delays and the combination parallel data operation that delays.In addition, the method also comprise carry out delay be combined line operate to produce the specific parallel data object corresponding with the parallel data object that delays.The parallel data object of specializing can be for example to comprise the data of parallel data object or the data structure of element.
This implementation on the one hand can comprise one or more feature in following characteristics.For example, the combination parallel data operation that delays can comprise that the mapping of at least one broad sense simplifies operation.Broad sense mapping simplify operation can comprise a plurality of parallel map operations and a plurality of parallel simplify operation and can be translated into single mapping simplify operation, single mapping is simplified operation and is comprised be used to the single mapping function of implementing a plurality of parallel map operations and be used for implementing a plurality of parallel single functions of simplifying of simplifying operation.Carrying out the broad sense mapping simplifies operation and can comprise that combinatorial mapping is simplified operation to be translated into single mapping and to simplify operation and carry out single mapping and simplify operation.Carry out single mapping simplify operation can comprise determine whether to carry out single mapping simplify the operation as local sequential operation or long-range parallel work-flow.With broad sense mapping simplify operation be translated into single mapping simplify operation can comprise generate the mapping function that comprises a plurality of map operations and comprise a plurality of simplify the device operation simplify the device function.
The first kind object that a plurality of parallel data objects can be the main frame programming languages.
Streamline can also comprise the individual data object, and the individual data object comprises individual element, and the data stream figure comprises the corresponding individual data object that delays.At least one parallel work-flow in a plurality of parallel work-flows in streamline can be to a parallel data Object Operations in individual data object and a plurality of parallel data object, and the data stream figure can comprise the parallel work-flow that delays to the correspondence of the individual data object that delays and the parallel data Object Operations that delays.
The method can comprise that high-speed cache carries out one or more result that is combined line operate delay and use to be used for carrying out in the future of data parallel pipeline.
In another aspect, a kind of system comprises one or more treatment facility and one or more memory device.Memory device, stores is implemented the instruction of actuator when being carried out by one or more treatment facility.Actuator is configured to access the data stream figure that comprises the parallel data object that delays and the combination parallel data operation that delays.The parallel data object that delays can be for example the data structure that comprises pointer, and this pointed is to the parallel data object rather than to the parallel data operation of the element stored in parallel data object operation.The parallel work-flow that delays can be for example data structure, this data structure comprises the pointer that points to the parallel data object, the pointer that points to the Parallel Object that delays and the function that (but not yet) carried out input object, parallel data to as if to the input of the parallel work-flow that delays, the Parallel Object that delays is the output of the parallel work-flow that delays.
Actuator be configured to carry out delay be combined line operate to produce the specific parallel data object corresponding with the parallel data object that delays.The parallel data object of specializing can be for example to comprise the data of parallel data object or the data structure of element.For the line operate that is combined that at least one in line operate delay that is combined that delays, actuator is configured to carry out by following operation the line operate that is combined that at least one delays: determine the size with at least one estimation that is combined the data that line operate is associated that delays; Determine whether the size of estimating surpasses threshold size; If what the size of estimating below threshold size, carried out that at least one delays is combined line operate as local sequential operation; And if the size of estimating surpasses threshold size, that carries out that at least one delays is combined line operate as long-range parallel work-flow.
This implementation on the one hand can comprise one or more feature in following characteristics.For example, can comprise at least one input data that are combined line operate that delay, by at least one being combined of delaying intermediate data that line operate produces or by at least one one or more data that are combined the output data that line operate produces that delay with at least one being combined of delaying data that line operate is associated.The combination parallel data operation that at least one delays can be that operation is simplified in the broad sense mapping.Broad sense mapping simplify operation can comprise a plurality of parallel map operations and a plurality of parallel simplify operation and can be translated into single mapping simplify operation, single mapping is simplified operation and is comprised be used to the single mapping function of implementing a plurality of parallel map operations and be used for implementing a plurality of parallel single functions of simplifying of simplifying operation.Simplify operation in order to carry out broad sense mapping, actuator can be configured to that combinatorial mapping is simplified operation and be translated into single mapping and simplify operation and carry out single mapping and simplify operation.Simplify operation as long-range parallel work-flow in order to carry out single mapping, actuator can be configured to that single mapping is simplified and operate in be replicated and carry out on a plurality of different disposal modules in data center.Be translated into single mapping and simplify operation for broad sense mapping being simplified operation, actuator can be configured to generate the mapping function that comprises a plurality of map operations and comprise a plurality of simplify the device operation simplify the device function.For the size of determine estimating, actuator can be configured to the note in the visit data stream graphics, the estimation of note reflection and at least one size that is combined the data that line operate is associated that delays.
In another aspect, a kind of method comprises that access comprises the data stream figure of the parallel data object that delays and the combination parallel data operation that delays.The parallel data object that delays can be for example the data structure that comprises pointer, and this pointed is to the parallel data object rather than to the parallel data operation of the element stored in parallel data object operation.The parallel work-flow that delays can be for example data structure, this data structure comprises the pointer that points to the parallel data object, the pointer that points to the Parallel Object that delays and the function that (but not yet) carried out input object, parallel data to as if to the input of the parallel work-flow that delays, the Parallel Object that delays is the output of the parallel work-flow that delays.
The method also comprise carry out delay be combined line operate to produce the specific parallel data object corresponding with the parallel data object that delays.The parallel data object of specializing can be for example to comprise the data of parallel data object or the data structure of element.For the line operate that is combined that at least one in line operate delay that is combined that delays, carry out at least one line operate that is combined that delays and comprise: determine the size with at least one estimation that is combined the data that line operate is associated that delays; Determine whether the size of estimating surpasses threshold size; If what the size of estimating below threshold size, carried out that at least one delays is combined line operate as local sequential operation; And if the size of estimating surpasses threshold size, that carries out that at least one delays is combined line operate as long-range parallel work-flow.
This implementation on the one hand can comprise one or more feature in following characteristics.For example, can comprise at least one input data that are combined line operate that delay, by at least one being combined of delaying intermediate data that line operate produces or by at least one one or more data that are combined the output data that line operate produces that delay with at least one being combined of delaying data that line operate is associated.The combination parallel data operation that at least one delays can be that operation is simplified in the broad sense mapping.Broad sense mapping simplify operation can comprise a plurality of parallel map operations and a plurality of parallel simplify operation and can be translated into single mapping simplify operation, this single mapping is simplified operation and is comprised be used to the single mapping function of implementing a plurality of parallel map operations and be used for implementing a plurality of parallel single functions of simplifying of simplifying operation.Carrying out the broad sense mapping simplifies operation and can comprise that combinatorial mapping is simplified operation to be translated into single mapping and to simplify operation and carry out single mapping and simplify operation.Carrying out single mapping simplifies operation and can comprise on a plurality of different disposal modules that single mapping simplified operate in data center as long-range parallel work-flow and be replicated and carry out.With broad sense mapping simplify operation be translated into single mapping simplify operation can comprise generate the mapping function that comprises a plurality of map operations and comprise a plurality of simplify the device operation simplify the device function.The size of determine estimating can comprise the note in the visit data stream graphics, the estimation of this note reflection and at least one size that is combined the data that line operate is associated that delays.
In one aspect, a kind of system comprises one or more treatment facility and one or more memory device.Memory device, stores is implemented the instruction of actuator when being carried out by one or more treatment facility.Actuator is configured to the visit data stream graphics, and this data stream figure comprises the parallel data object that delays and the combination parallel data operation that delays.The parallel data object that delays can be for example the data structure that comprises pointer, and this pointed is to the parallel data object rather than to the parallel data operation of the element stored in parallel data object operation.The parallel work-flow that delays can be for example data structure, this data structure comprises the pointer that points to the parallel data object, the pointer that points to the Parallel Object that delays and the function that (but not yet) carried out input object, parallel data to as if to the input of the parallel work-flow that delays, the Parallel Object that delays is the output of the parallel work-flow that delays.
At least one combination parallel data operation that delays in the combination parallel data operation that delays is that operation is simplified in the broad sense mapping.Broad sense mapping simplify operation comprise a plurality of parallel map operations and a plurality of parallel simplify operation and can be translated into single mapping simplify operation, this single mapping is simplified operation and is comprised be used to the single mapping function of implementing a plurality of parallel map operations and be used for implementing a plurality of parallel single functions of simplifying of simplifying operation.
Actuator also be configured to carry out delay be combined line operate to produce the specific parallel data object corresponding with the parallel data object that delays.The parallel data object of specializing can be for example to comprise the data of parallel data object or the data structure of element.Simplify operation in order to carry out broad sense mapping, actuator is configured to that combinatorial mapping is simplified operation and is translated into single mapping and simplifies operation and carry out single mapping and simplify operation.
This implementation on the one hand can comprise one or more feature in following characteristics.For example, be translated into single mapping and simplify operation for broad sense mapping being simplified operation, actuator can be configured to generate the mapping function that comprises a plurality of map operations and comprise a plurality of functions of simplifying of simplifying operation.
Actuator can be configured to carry out single mapping and simplify operation as long-range parallel work-flow.Simplify operation as long-range parallel work-flow in order to carry out single mapping, actuator can be configured to make single mapping to simplify operation by a plurality of working device processes execution on a plurality of different disposal modules.Carried out by a plurality of working device processes in order to make single mapping simplify operation, actuator can be configured to cause for each map operation in map operation quotes a plurality of mappings work device processes, wherein each the mappings work device course allocation index number in a plurality of mappings work device processes.Each mappings work device process in mappings work device process can be configured to: receive to implement the mapping function of a plurality of map operations, one or more input that is associated with a map operation in map operation and the index that is associated of mappings work device process; The map operation that is associated with input based on the index selection that is associated of mappings work device process; And one or more input is quoted the map operation of selection.
Carried out by a plurality of working device processes in order to make single mapping simplify operation, actuator can be configured to make for simplifying each in operation simplifies operation and quotes a plurality of working device processes of simplifying, and wherein simplifies working device course allocation index number to a plurality of each of simplifying in the working device process.A plurality of each of simplifying in the working device process are simplified the working device process and can be configured to: receive to implement a plurality of simplify operation simplify function, with simplify operation in one simplify and operate one or more input that is associated and the index that is associated of simplifying the working device process; Simplify operation based on what the index selection that is associated of working device process was associated with input; And one or more input is quoted the operation of simplifying of selection.
In another aspect, a kind of method comprises the visit data stream graphics, and this data stream figure comprises the parallel data object that delays and the combination parallel data operation that delays.The parallel data object that delays can be for example the data structure that comprises pointer, and this pointed is to the parallel data object rather than to the parallel data operation of the element stored in parallel data object operation.The parallel work-flow that delays can be for example data structure, this data structure comprises the pointer that points to the parallel data object, the pointer that points to the Parallel Object that delays and the function that (but not yet) carried out input object, parallel data to as if to the input of the parallel work-flow that delays, the Parallel Object that delays is the output of the parallel work-flow that delays.
At least one combination parallel data operation that delays in the combination parallel data operation that delays is that operation is simplified in the broad sense mapping.Broad sense mapping simplify operation comprise a plurality of parallel map operations and a plurality of parallel simplify operation and can be translated into single mapping simplify operation, this single mapping is simplified operation and is comprised be used to the single mapping function of implementing a plurality of parallel map operations and be used for implementing a plurality of parallel single functions of simplifying of simplifying operation; And
The method also comprise carry out delay be combined line operate to produce the specific parallel data object corresponding with the parallel data object that delays.The parallel data object of specializing can be for example to comprise the data of parallel data object or the data structure of element.Carrying out the broad sense mapping simplifies operation and comprises that combinatorial mapping is simplified operation to be translated into single mapping and to simplify operation and carry out single mapping and simplify operation.
This implementation on the one hand can comprise one or more feature in following characteristics.For example, broad sense mapping being simplified operation is translated into single mapping and simplifies operation and can comprise and generate the mapping function that comprises a plurality of map operations and comprise a plurality of functions of simplifying of simplifying operation.Carrying out single mapping simplifies operation and can comprise that carrying out single mapping simplifies operation as long-range parallel work-flow.Carrying out single mapping simplifies operation and can comprise that as long-range parallel work-flow making single mapping simplify operation is carried out by a plurality of working device processes on a plurality of different disposal modules.
Make single mapping simplify operation and carried out by a plurality of working device processes and can comprise and cause for each map operation in map operation and quote a plurality of mappings work device processes, wherein each the mappings work device course allocation index number in a plurality of mappings work device processes.Each mappings work device process in mappings work device process can be configured to: receive to implement the mapping function of a plurality of map operations, one or more input that is associated with a map operation in map operation and the index that is associated of mappings work device process; The map operation that is associated with input based on the index selection that is associated of mappings work device process; And one or more input is quoted the map operation of selection.
Make single mapping simplify operation and carried out by a plurality of working device processes and can comprise making for simplifying each in operation and simplify operation and quote a plurality of working device processes of simplifying, wherein simplify working device course allocation index number to a plurality of each of simplifying in the working device process.A plurality of each of simplifying in the working device process are simplified the working device process and can be configured to: receive to implement a plurality of simplify operation simplify function, with simplify operation in one simplify and operate one or more input that is associated and the index that is associated of simplifying the working device process; Simplify operation based on what the index selection that is associated of working device process was associated with input; And one or more input is quoted the operation of simplifying of selection.
The implementation of the technology of describing can comprise hardware, system, method or process or the computer software on computer accessible.
Set forth in the accompanying drawings and the description below the details of one or more implementation.Further feature will and become obvious from description and accompanying drawing from claim.
Description of drawings
Fig. 1 is the block diagram that illustrates the example of data center.
Fig. 2 is the block diagram of the example of processing module.
Fig. 3 is the block diagram that illustrates the example in streamline storehouse.
Fig. 4 A is the process flow diagram that illustrates the example of the process that can be carried out by the evaluator of streamline, optimizer and actuator.
Fig. 4 B is the process flow diagram that illustrates the example of the process that can be carried out by the actuator in streamline storehouse.
Fig. 5 A and Fig. 5 B show the example data flow graph transformation, and this data flow diagram fractal transform illustrates the ParallelDo producer-consumer and merges the fusion with the compatriot.
Fig. 6 A and Fig. 6 B show the example data flow graph transformation, and this data flow diagram fractal transform illustrates MSCR and merges.
Fig. 7 A to Fig. 7 E shows the example of the data flow diagram fractal transform of carrying out in order to generate the final data stream graphics.
Fig. 8 illustrates the example of the MSCR operation with 3 input channels.
Fig. 9 illustrates and can be used for implementing the streamline storehouse as the example of the system of service.
Figure 10 illustrates the non-process flow diagram of putting the example of the process that letter uses that comprises data parallel pipeline for execution.
Embodiment
Generally speaking, the technology of describing in the literature can be applied to large-scale data and process and be applied to especially the large-scale data parallel pipeline.Can carry out so extensive processing in distributed data processing system (such as the network of data center or data center).For example, extensive Internet service and support the large-scale parallel computation foundation structure of such service can use the computing system of the warehouse size that is formed by thousands of or ten hundreds of computing nodes.
Fig. 1 is the block diagram that illustrates the example of data center 100.Data center 100 is used for storing data, carries out calculation task and for example uses the network that is connected to data center to data center's other system transmissions data in addition.Particularly, data center 100 can carry out the large-scale data processing to mass data.
In some implementations, processing module 104 can be born the role as master control or subordinate separately.Master control module controls they itself and subordinate between scheduling and data distribution task.Frame can comprise the reservoir that the reservoir (for example, one or more network attachment dish) shared by one or more processing module 104 and/or each processing module 104 can comprise it.Additionally or alternatively, can there be the remote storage device that is connected to frame by network.
Fig. 2 is can be for the treatment of the block diagram of the example of the processing module 200 of one or more processing module in module 104.Processing module 200 comprises storer 202, one or more processing unit (CPU) 204 and one or more network or other communication interface 206.These parts are by one or more communication bus interconnection.In some implementations, processing module 200 can comprise I/O (I/O) interface that processing module is connected to input and output device (such as display and keyboard).Storer 202 can comprise high-speed random access memory and also can comprise nonvolatile memory, such as one or more disk storage device.Storer 202 can comprise the long-range mass storage that is positioned at CPU 204.
Generally speaking, the mapping reduced model is provided for how considering their calculating abstract to application developer.Application developer can be according to abstract calculating of formulating them, and this can simplify the structure to the program that is used for the processing of execution large-scale parallel data.Application developer can be used the mapping reduced model, and this mapping reduced model uses or do not use mapping to simplify storehouse 202b.Yet storehouse 202b is simplified in mapping can manage many tasks in different rudimentary tasks.Rudimentary task like this can for example comprise select suitable concurrent working device machine, to they distribute program to be moved, management intermediate data between this three phases interim storage and flow, the overall sequencing of synchronous phase and the transient fault of reply machine, network and software.
The mapping reduced model relates generally to calculating is resolved into and comprises that single map operation and single mapping of simplifying operation simplify operation.Map operation to each the logical record executable operations in input to calculate the right set of middle key/value.Simplify operation to the value executable operations of sharing same keys with according to a certain mode combined value.Shuffling operation (shuffle operation) is implicit expression in this model, and this operation relates to having all values grouping of same keys.
Mapping is simplified storehouse 202b and can be implemented mapping stage, the stage of shuffling and simplify the calculating of stage to support to formulate according to the mapping reduced model.In some implementations, simplify storehouse 202b in order to use mapping, user program (perhaps another storehouse (such as streamline storehouse 202c)) calls mapping and simplifies storehouse 202b, thereby the information of designated identification input file, the output file that be used for to receive the output data is identified or information and the map operation symbol of appointment and simplify these two of operational characters and use exclusive data processing operations symbol.Generally speaking, map operation symbol designated treatment is inputted data with the mapping function of generation intermediate data, and simplifies operational character and specify the function of simplifying that merges or otherwise make up intermediate data value.Mapping is simplified storehouse 202b and is then used this information to implement this mapping stage, the stage of shuffling and to simplify the stage.
The mapping stage by from input source (such as text, towards file or the MySql database of binary recording) read value or key/value right collect to come.Large data sets can be represented by a plurality of, even thousands of file (can be called as fragment), and can read a plurality of file fragmentations as single logic input source.The mapping stage is independent to each element of parallel quote user-defined function, mapping function or mapper then.For each input element, user-defined function sends zero or more key/value is right, and these key/values are to being the output in mapping stage.
The stage of shuffling obtain key/value of being sent by mapper to and all key/values that will have a same keys to being grouped in together.The stage of shuffling then exports each different key and has the stream of all values of this key to this next stage in the stage of simplifying.
The stage of simplifying is obtained the key integrated data of being sent by the stage of shuffling and each different key and value group is independently quoted user-defined function, simplifies function or simplified device with parallel.Simplify device to each and quote and transmit key and to the iterator of all values that is associated with this key, and each is simplified device and sends for the zero that is associated with enter key or more replacement value.Simplify device and usually all values with given key is carried out certain polymerization.For certain operations, simplify device and only be identity function.Then, write to output place (for example, shared file or database) and simplify device from all to call key/value of sending right.
In order to implement these stages, storehouse 202b is simplified in mapping can (for example be divided into M fragment with the input fragment, the file of 64 megabyte (MB) sizes) and at a plurality of copies of the upper start-up routine of machine cluster (such as a plurality of processing modules in processing module 104), this program is used storehouse 202b.A copy in copy can be master copy, and all the other copies can be the working device copies that is shared out the work by master control.Master control is selected the vacant working device and to each vacant working device allocation map task or simplify task.There is M mapping task (each input fragment has a mapping task).Use mapper input is carried out map operation to produce the intermediate result that for example is divided into R set to mapping task assignment device.When middle result is divided into R set, exist the individual task of simplifying of R to be allocated.Use and to simplify device and simplify operation to produce output so that intermediate value is carried out to simplifying task assignment device.Simplify task in case completed all mapping tasks with all, master control is just returned to the user program or the storehouse that use mapping to simplify storehouse 202b.As a result of, the enforcement mapping is simplified to be operating as and is crossed over the parallel work-flow set that treatment facility is trooped.
For first make up the device of simplifying of all values with given key with related swap operation, can specify individual consumer's combinations of definitions device function to carry out the part combination to the value that is associated with given key during the mapping stage.Each mappings work device can keep the right high-speed cache of key/value that sent from mapper, and uses the combiner function to make up carrying out as much as possible before this locality in the key/value that sends combination to the stage of shuffling.Simplify device and can complete combination step from the value of different mappings working device by combination.
By default, but the working device machine of simplifying that the stage of shuffling can be selected to the ground of determinacy at random send each key and value group, and wherein this selection determines which output file fragment will keep the result of this key.Alternatively, can designated user the fragment device function of definition, which this fragment device function selects simplify the working device machine should receive group for given key.User-defined fragment device can be used for the auxiliary burden balance.User-defined fragment device also can be used for run-out key is categorized into and simplify in " bucket ", wherein i all keys of simplifying working device be ordered in i+1 simplify all keys of working device before.Simplify with each the fact that working device processes key according to lexicographic order and contact, this a kind of fragment device can be used for producing classification output.
Generally speaking, application software 202a can use one or two storehouses in storehouse 202b or storehouse 202c.Application developer can Application and Development software, and this application software is used mapping to simplify storehouse 202b and is formulated the calculating of simplifying operation as mapping take execution.
Alternatively or additionally, application developer can be used streamline storehouse 202c when exploitation comprises that the data parallel pipeline of operation is simplified in a plurality of mappings.Such as discussed further below, the machine programming language that streamline storehouse 202c can allow the developer to use wherein to implement streamline storehouse 202c, and is not considered to simplify in mapping the orderly figure that the operating aspect design logic calculated or built operation to calculation code with natural way more.Streamline storehouse 202c can simplify operating aspect in a plurality of mappings and formulate logical calculated before carrying out, and then shine upon to simplify operation itself or simplify storehouse 202b with mapping by enforcements and dock to implement to shine upon to simplify to operate and carry out calculating.
Fig. 3 is the block diagram that illustrates the example in the streamline storehouse 300 that can be used for implementing streamline storehouse 200c.Streamline storehouse 300 comprises that one or more parallel data collects class 302, one or more parallel work-flow 304, evaluator 306, optimizer 308 and actuator 310.Generally speaking, parallel data is collected class 302 and is used for instantiation parallel data object, and these parallel data objects keep data to collect, and parallel work-flow 304 is used for the data that kept by the parallel data object are carried out parallel work-flow.Can form parallel work-flow 304 with implementation data parallel computation and whole streamline or even a plurality of streamline, can collect class 302 and parallel work-flow 304 is implemented in parallel work-flow 304 with parallel.
Parallel data is collected class 302 and parallel work-flow 304 and is presented many different pieces of informations are represented and abstract to the simple senior unification of different implementation strategies.Parallel data is collected class 302 and is taken out the details that how data is represented, these details comprise data structure, one or more file or the exterior storage service that whether data is expressed as in storer.Similarly, parallel work-flow 304 takes out their implementation strategy, such as whether, operation is embodied as mapping and simplifies this locality of storehouse 202b, circulation successively, long-rangely parallelly quotes, is embodied as the inquiry of database or be embodied as flowmeter and calculate.
Evaluator 306 delays to estimate them to the evaluation of parallel work-flow rather than when the executing data parallel pipeline along with the traversal parallel work-flow.Replace, evaluator 306 structures comprise the inside executive plan data stream figure of operation and argument thereof.In case constructed the executive plan data stream figure that is used for whole logical calculated, for example chain with parallel work-flow merges optimizer 308 together or the graph transformation that is combined into the more combination operation of peanut is revised executive plan by using.The executive plan of revising can comprise that the broad sense mapping simplifies operation, the mapping of this broad sense is simplified operation and is comprised a plurality of parallel map operations and a plurality ofly parallelly (for example simplify operation, the MapShuffleCombineReduce that hereinafter further describes operation), but can be translated into single mapping and simplify operation with single mapping function and the single function of simplifying, this single mapping function is used for implementing a plurality of map operations, and this single function of simplifying is used for implementing a plurality of operations of simplifying.Actuator 310 uses lower floor's primitive (for example, MapReduce operation) to carry out the operation of correction.When operation during executive plan, the size that actuator 310 can at least part of data based on processing comes which strategy of choice for use to implement each operation (for example, this locality recycle ratio to long-range parallel MapReduce) successively.Actuator 310 also can be placed in remote computation near their data to its operation, and can the executed in parallel independent operation.Actuator 310 also can be managed establishment and the cleaning to calculating interior required any intermediate file.
Can implement streamline storehouse 300 with any programming language in multiple programming language.The example of the aspect of an implementation using Java (R) programming language is hereinafter described.
Can read in data set by the representative of a plurality of file fragmentations as single logic PCollection.For example:
PCollection<String>lines＝readTextFileCollection(″/gfs/data/shakes/hamlet.txt″)；
PCollection<DocInfo>docInfos＝readRecordFileCollection(″/gfs/webdocinfo/part-*″，recordsOf(DocInfo.class))；
In this example, recordsOf (...) to specify be wherein the ad hoc fashion of binary recording with the DocInfo example code.Other predefine coding indicator can comprise for the text encoded strings () of UTF-8-, be used for 32 integers variable length code ints () and be used for pairsOf (e1, e2) according to the right coding that the coding of component is derived.Some implementations can allow the user to specify themselves customization coding.
It is PTable＜K that the second parallel data is collected class 302, V 〉, this parallel data is collected (immutable) many mappings that class representative has the value of the key of type K and type V.PTable＜K, V〉can be only right out-of-sequence packet.Some parallel work-flows in parallel work-flow 304 can be only applicable to right PCollection, and in Java (R), PTable＜K, V〉may be implemented as PCollection＜Pair＜K, V subclass abstract to catch this.In another language, PTable＜K, V〉can be defined as PCollection＜Pair＜K, V the type synonym.
Parallel data object (such as PCollection) may be implemented as the first kind object of the native language of wherein implementing storehouse 300.When being this situation, object can be as other in native language to controlling that way.For example, PCollection can transmit and return from these methods in the conventional method in language, and can be stored in other data structure of language (being stored in other PCollection but some implementations may prevent PCollection).The conventional control flow of native language is constructed and also can be used for defining the calculating that relates to object, and these objects comprise function, conditional clause and circulation.For example, if Java (R) is native language:
The developer implements the parallel data object and can simplify as the first kind object in the native language in storehouse 300 program development of using the storehouse, because can will use according to he or she the identical mode of mode of other object to use the parallel data object.
Except parallel data was collected class, streamline storehouse 300 can comprise that also individual data collects class PObject＜T 〉, these data are collected class and are used for being supported in the ability that checks the content of PCollection during execution pipeline.With the PCollection contrast that keeps a plurality of elements, PObject＜T〉for the single object of type T (for example be, single the machine object of type T (for example, Java (R) object)) container, and any method that is associated of design PObject is to operate individual element.As PCollection, can delay or specialize (as described further below such) PObject, thereby allowing to calculate them as the result of the operation that delays in streamline.In case the operation streamline can use getValue () to extract the content of the PObject that specializes now.
For example, in an implementation using Java (R), asSequentialCollection () operation can be applied to PCollection＜T〉to produce PObject＜Collection＜T 〉, in case streamline operation can check PObject＜Collection＜T〉〉 with all elements of the PCollection that reads calculating as the Collection in conventional Java (R) storer:
As another example, to T to PCollection＜T and composite function the combine () operation (hereinafter describing) of using produce the PObject＜T that represents the complete combination result.Can calculate like this overall situation summation and maximal value.
The content of PObject also can for example use the operate () primitive that is provided by streamline storehouse 300 to be examined in the execution of streamline.The list of PObject and argument OperateFn (operation that this argument definition will be carried out each PObject) obtained in operate () primitive, and return to the list of PObject.When being evaluated, operate () extracts the content of the argument PObject that specializes now and transmit them in argument OperateFn.OperateFn returns to the list of the machine object (such as Java (R) object), and operate () these the machine objects of reeling in the PObject that as a result of returns.Use this primitive, can be embedded in and carry out any calculating according to the mode of delaying at streamline.In other words, can comprise the operation except ParallelDo operation (hereinafter describing) that the PCollection that comprises a plurality of elements is operated at streamline.For example, consider to embed reading and the calling of the external service of writing in files:
This example is used for the operation of changing between the PObject of PCollection and include file name.Be applied to the PObject＜String of title that viewAsFile () that PCollection and file layout select produces the following interim fragment file of selected form 〉, can find the content of PCollection during execution pipeline in this fragment file.File read operation (such as readRecordFileCollection ()) can be overloaded to allow to read title and is contained in file in PObj ect.
According to very identical mode, also can check them as the pair input is next in DoFn (hereinafter describing) by the content of transmitting PObject in parallelDo ().Usually, DoFn each element executable operations to PCollection, and only receive PCollection as input.In some cases, can relate to value or other data of storing to the operation of each PCollection in PObject.In this case, DoFn can input as pair as input and reception PObject by reception PCollection as usual.When moving streamline and finally estimate parallelDo () operation, extract and provide any PObject that specializes now content of secondary input to user's DoFn, and then each element of input PCollection being quoted DoFn so that use from the data of PObject and element is carried out the operation of definition.For example:
Described above such, (such as PCollection) quotes data parallel operations 304 to the parallel data object.Streamline storehouse 300 some primitive data parallel operations of definition are wherein being implemented other operation aspect these primitive.One of data parallel primitive is parallelDo (), and this data parallel primitive is supported input PCollection＜T〉element one by one (elementwise) calculate to produce new output PCollection＜S.This operation obtains functional expression object DoFn＜T, S〉as its main transformer unit, how this object definition will input PCollection＜T in each value be mapped to will be at output PCollection＜S in the zero or more value of appearance.This operation also obtains the PCollection that will as a result of produce or the indication of PTable kind.For example:
In this code, collectionOf (strings ()) specifies parallelDo () operation should produce unordered PCollection, and the String element of this PCollection should be encoded with UTF-8.Other option can comprise for the sequenceOf (elemEncoding) of orderly PCollection and be used for the tableOf (keyEncoding, valueEncoding) of PTable.EmitFN be to the user process (...) call back function that method is transmitted, this call back function should be for quoting emitFn.emit (outElem) to each outElem that output PCollection adds.Can comprise that the subclass (such as MapFn (implementing mapping) and FilterFn (enforcement filtrator)) of DoFn is to provide in some cases simpler interface.
Operation parallelDo () can be used for expressing the mapping of MapReduce operation and simplifying part both.Storehouse 300 also can comprise the following version of parallelDo (), and this version allows to produce simultaneously a plurality of output PCollection according to the single ergodic of input PCollection.
If can long-distance distribution and parallel running DoFn function, can prevent any overall variableness of DoFn function access package program (enclosing program).The DoFn object can be kept local example variableness, but can have parallel work-flow and there is no a plurality of DoFn duplicates of shared state.
The second primitive groupByKey () is with type PTable＜K, V〉many mappings (it is right that these many mappings can have many key/values, these key/values are to having same keys) convert type PTable＜K to, Collection＜V〉〉 single mapping, wherein each key is mapped to the unordered of all values with this key and collects.For example, hereinafter be calculated as follows table, this table is mapped to document with URL and collects, and these document links arrive these URL:
Operation groupByKey () is corresponding to the step of shuffling of MapReduce.Also can have following variant, this variant allows to specify the classified order that collects of the value that is used for each key.
The 3rd primitive combineValues () obtains input PTable＜K, Collection＜V〉〉 with to the composite function that is associated of V, and return to PTable＜K, V 〉, each input of its intermediate value collects and is combined into single output valve.For example:
Operation combineValues () is the special circumstances of parallelDo () semantically, but the relevance of composite function allows to simplify device (being used for completing combination) by combination MapReduce combiner (part as each mapper is moved) and MapReduce comes implementation and operation, and this can be more efficient than complete all combinations in simplifying device.
The 4th primitive flatten () obtains PCollection＜T〉list and return to the single PCollection＜T that comprises all elements of inputting PCollection.Not actual copy input of operation flatten (), but be only that a logic PCollection is to be entered as input.
Streamline finishes to write the operation of final gained PCollection to external storage usually.For example:
wordCounts.writeToRecordFileTable(″/gfs/data/shakes/hamlet-counts.records″)；
PTable<String，Integer>wordCounts＝words.count()；
Another operation join () is to sharing two or more PTable enforcement joint of common key type.When being applied to many mapping PTable＜K, V1〉and many mapping PTable＜K, V2〉time, join () returns to single mapping PTable＜K, Pair＜Collection＜V1 〉, Collection＜V2〉〉 〉, the mapping of this list with each key in the arbitrary input table in input table be mapped to all values with this key in first table collect with second table in the collecting of all values with this key.Can further process this gained table calculating in tradition or outer engagement, but directly the value of controlling collect and do not calculate their cross product can be more efficient.
Can implementation and operation join () as follows:
1. parallelDo () is applied to each the input PTable＜K, Vi〉it is converted to type PTable＜K, TaggedUnion＜V1, V2 common format.
2. use flatten () to come combination table.
3. groupByKey () is applied to the table of planarization to produce PTable＜K, Collection＜TaggedUnion＜V1, V2〉〉 〉.
4. parallelDo () is applied to the key grouping sheet, thereby convert each Collection＜TaggedUnion＜V1, V2 to a pair of Collection＜V1 and Collection＜V2.
The operation of another derivation is top (), and this operation obtains comparison function and counting N and returns to maximum N the element of its receiver pc ollection according to comparison function.This operation can be implemented on parallelDo (), groupByKey () and above combineValues ().
Mentioned above is also the operation of deriving be used to reading the operation of a plurality of file fragmentations as single PCollection, and these operations are used flatten () and monofile to read primitive and implemented.
Described above like that, parallel work-flow is carried out in the evaluation that streamline storehouse 300 use delay idly.For this reason, evaluator 306 delays the evaluation to parallel work-flow, and replaces the inside executive plan data stream figure that structure comprises the argument of operation and operation.Each parallel data object of internal representation in delaying (not yet calculating) or (the calculating) state of specializing is such as PCollection.The parallel data object that delays for example keeps pointing to the pointer of the following operation that delays, and the parallel data object is calculated in the operation that this delays.The operation that delays then can keep quoting parallel data object and the parallel data object that delays, these parallel datas to as if the argument of the operation that delays (these operations itself can be delayed or specialize), these parallel datas that delay to as if the result of operation.When calling the storehouse operation as ParallelDo (), the operand that storehouse 300 establishment ParallelDo delay and the new PCollection that delays that returns to point operation.In other words, when the executing data parallel pipeline, evaluator 306 converts parallel data object and parallel work-flow to the object that delays (estimating) and the directed acyclic graph shape of operation.This figure can be called as executive plan or executive plan data stream figure.
The operation that optimizer 308 is fused into lesser number with chain or the spirte of the parallel work-flow in the data stream figure (certain operations in these operations can be the operation of combination), actuator 310 can be carried out these operations with lower floor's primitive or other logic then.Can for example write optimizer 308 as a series of independent drawing conversion.In an implementation, 308 pairs of original execution plans of optimizer are carried out and are reduced overall operation and organize a series of of number of operations and pass through, and wherein are operating as general objective to produce minimum MapShuffleCombineReduce (MSCR).
The MSCR operation comprises the combination of ParallelDo, GroupByKey, CombineValues and Flatten operation.The MSCR operation can be mapped to single mapping and simplifies operation and simplify operation as this single mapping and move.The MSCR operation has M input channel (each input channel is carried out map operation) and R delivery channel (each delivery channel is carried out and shuffled, makes up and simplify).Each input channel m obtains PCollection＜T
mCarry out R-output ParallelDo " mapping " operation to produce type PTable＜K as input and to this input
r, V
rR the output of s.Its M input of each delivery channel R planarization, and then (a) carry out that GroupByKey " shuffles ", optional CombineValues " combination " and O
r-output ParallelDo " simplifies " (this is defaulted as identity operation), and then to O
rIndividual output PCollection write result or (b) write direct the input as output.Front a kind of delivery channel can be called as " grouping " channel, and then a kind of delivery channel can be called as " leading directly to " channel.It is the result of MSCR operation that direct channel can allow the output of mapper.
Fig. 8 illustrates the example of the MSCR operation 800 with 3 input channel 802a, 802b and 802c.The first input channel 802a carries out ParallelDo M1804a.The second input channel 802b carries out ParallelDo M2 804b.The 3rd input channel 802c carries out ParallelDo M3 804c.The MSCR operation comprises two grouping delivery channel 806a and 806b.The first grouping delivery channel 806a comprises GroupByKey GBK1 808a, CombineValues CV1 810a and simplifies ParallelDo R1 812a.Similarly, the second grouping delivery channel comprises GroupByKey GBK2 808b, CombineValues CV2810b and simplifies ParallelDo R2 812b.MSCR operation 800 also comprises a straight-through delivery channel 814.
MSCR is by allowing a plurality of mappers and a plurality ofly simplifying device and combiner, simplify by allowing each that device produces a plurality of outputs, simplifying device by removal must be with same keys as simplifying that the device input produces the such requirement of output and by allowing straight-through output to conclude the mapping reduced model.Therefore, any given MSCR can comprise separately to a plurality of parallel map operation of different input operations with to the output function of map operation and a plurality ofly simplifies operation with what produce a plurality of different outputs.Although each MSCR operation have it obviously larger expressivity, but still can simplify operation with single mapping and implement, this mapping simplify operation comprise for to difference input implement the single mapping function of map operation and be used for implementing to simplify operation to produce the single function of simplifying of a plurality of outputs.
In case optimizer 308 has been revised executive plan, actuator 310 is just carried out the executive plan data stream figure of revising.In an implementation, streamline storehouse 300 execution batch processings are carried out.In other words, the operation in the executive plan that actuator 310 is revised according to the traversal of topological order forward, and carry out in turn each operation.Independent operation can be performed simultaneously.Alternatively, can implement increasing progressively or carrying out continuously of streamline, the input that wherein increases progressively interpolation causes output is increased progressively renewal fast.In addition, can cross over the streamline execution optimization to corporate data source operation by a plurality of users.
In some implementations, actuator 310 first adjudicate mapping simplify operation whether should be by local and operation or simplify operation (for example use to shine upon and simplify storehouse 202b) as long-range parallel mapping and move successively.Due to the expense that exists when starting (launch) long-range concurrent job, so local evaluation can be used for the input of modest size, wherein Start-up costs surpasses the gain from parallel processing.The data set of modest size can share during development﹠ testing.This locality evaluation is used for these data sets therefore can helps to use conventional IDE, debugger, profile device and relevant instrument, thereby make exploitation comprise that the task of the program of data parallel becomes easy.
If input data set shows as greatly (for example, being greater than or equal to 64 megabyte), actuator 310 can choice for use mapping simplify storehouse 2202b and start long-range parallel mapping and simplify operation.Actuator 310 can use the observation of input size of data and export the estimation of size of data with the concurrent working device machine of automatic selection reasonable number.The user can for example assist estimation output size of data by expanding with the following method DoFn, and the method is based on returning to output size of data and the expectation ratio of inputting size of data by the calculating of this DoFn representative.Can be by the estimation of refining of the output size of data of dynamic surveillance and feedback observation.Can distribute relative more multiple parallel working device with the operation of the ratio of I/O to having higher CPU.
Generally speaking, streamline storehouse 300 can be designed to make build and operation streamline sensation similar as far as possible with the conventional program that moves native language, the streamline storehouse is designed for this native language.When native language was Java (R), the input that this locality is estimated successively for modest size was a kind of mode of doing like this.Another way is that always self-corresponding long-range mapping is simplified in the user DoFn (such as debug print) of working device any output of System.out or System.err to the output stream automatic seeking route of master routine.What abandon in the DoFn that moves on working device is simplified in long-range mapping similarly, anyly extremely is hunted down, sends and again abandoned to master routine.
The high-speed cache execution pattern can be supported in storehouse 300.In this pattern, if the result from previous operation of operation is stored in (inside or user are as seen) file, and if actuator 310 determines that the result of operation not yet changes, actuator 310 tastes test mass with it rather than recomputates this operation.If the input that (a) operates not yet changes and the code that (b) operates and the state of catching not yet change, the result of operation can be regarded as constant.Actuator 310 can be carried out conservative analysis automatically and when guarantee to reuse previous safety as a result with sign.Even high-speed cache is for usually needing the streamline that a few hours are moved still can cause quick editor-compiling-operation-debugging circulation.This can reduce in order to find the mistake, repair procedure in the later stage pipeline stages and (scratch) re-executes the streamline of correction and the time quantum that needs from the working area then.
Fig. 4 A is the process flow diagram that illustrates the example of the process 400 that can be carried out by evaluator 306, optimizer 308 and actuator 310.Based on comprising a plurality of parallel data objects and to the data parallel pipeline of a plurality of parallel data operations of Object Operations, evaluator 306 generates the parallel data object that delay corresponding with data parallel pipeline and the data stream figure (402) of the parallel work-flow that delays.Described above like that, the parallel data that delays to as if the parallel data object that not yet calculates, and the parallel work-flow that delays is still unenforced parallel work-flow.For example, when running into the parallel data object in data parallel pipeline, evaluator 306 can generate the data structure that keeps pointer, the parallel data operation of this pointed to the parallel data Object Operations.Similarly, when running into parallel data operation, evaluator 306 can the generated data structure, the pointer that this data structure keeps pointing to the pointer of parallel data object and points to the Parallel Object that delays, this parallel data to as if to the input of the parallel work-flow that delays, this Parallel Object that delays is the output of the parallel work-flow that delays.
In case evaluator 306 has generated the data stream figure, optimizer 308 just is applied to one or more graph transformation the data stream figure to generate the data stream figure of revising, and the data stream figure of this correction comprises the parallel data object (perhaps subset) that delays and the combination parallel data operation (404) that delays.The combination parallel data operation that delays can comprise that the mapping of one or more broad sense (for example simplifies operation, MSCR), the mapping of this broad sense is simplified operation and is comprised a plurality of map operations and a plurality ofly simplify operation, but can be translated into single mapping and simplify operation, this single mapping is simplified operation and is comprised for the single mapping function of implementing map operation and be used for the single function of simplifying that operation is simplified in enforcement.
In an implementation, 308 pairs of data stream graphics of optimizer are carried out a series of passing through, thereby use following graph transformation or note in the following order: (1) place planarization; (2) remove (lift) CombineValues operation; (3) insert the fusion piece; (4) merge ParallelDo; And (5) merge MSCR.
Place planarization conversion relates to by consuming the ParallelDo operation and push away the Flatten operation under coming copying ParallelDo before each input of planarization.In other words, h (f (a)+g (b)) is equivalent to h (f (a))+h (g (b)).This conversion creates and is used for the chance that ParallelDo merges (hereinafter describing).
Removing CombineValues operation note relates to some CombineValues of mark and operates ParallelDo to be used for being regarded as merging for ParallelDo.If the GroupByKey operation is followed in the CombineValues operation immediately, GroupByKey records this fact.Original CombineValues stays suitable place and after this is regarded as normal ParallelDo operation and is subject to ParallelDo merging.
Insert fusion piece note and relate to the ParallelDo that mark connects two GroupByKey operations.If two GroupByKey operations are connected by the chain that one or more ParallelDo operates, which ParallelDo optimizer 308 selects should upwards be fused in the delivery channel of GroupByKey more early, and which should be fused to downwards in the input channel of more late GroupByKey.Optimizer is estimated along the size of the middle-of-chain PCollection of ParallelDo, is identified the Pcollection with minimum expected size, and this centre of mark Pcollection is as the border (that is to say, the ParallelDo on the either side of PCollection is labeled as is not subject to mutual fusion) that stops ParallelDo to merge.
Fusion ParallelDo conversion relates to ParallelDo is merged.The ParallelDo fusion of the type that optimizer 306 can be carried out is called as the producer-consumer and merges.If function f is carried out in ParallelDo operation, and result is by another ParallelDo operation consumption of carrying out function g, and two ParallelDo operations can be replaced by and calculate f and g ο f single ParallelDo both.If other operation in figure need not the result of f ParallelDo, merge that it is become is nonessential, and can remove for generation of its code as stopping using.
The ParallelDo fusion of another type is called as the compatriot and merges.Can use the ParallelDo compatriot when two or more ParallelDo read identical input PCollection merges.The ParallelDo operation can be fused into the single ParallelDo of output operation more, and this many output ParallelDo operation is for inputting in the result of single by the operation of middle all fusions of calculating.The producer-consumer and compatriot are merged any tree that both can be applied to many output ParallelDo operation.
As more early mentioning, the CombineValues operation is the special circumstances that can repeatedly be applied to the ParallelDo of some numerical results operation.Like this, the ParallelDo fusion also can be applied to the CombineValues operation.
Merge the MSCR conversion and relate to establishment MSCR operation.The MSCR operation is from the set of relevant GroupByKey operation.If the GroupByKey operation consumes one or more identical input that (may operate via Flatten) created by identical ParallelDo operation, operation can be regarded as relevant.Input and output channel according to relevant GroupByKey operation and the adjacent operation derivation MSCR in executive plan.Have each ParallelDo operation that consumes at least one output of (may operate via Flatten) by one of GroupByKey operation and be fused in MSCR, thereby form new input channel.Any other input to GroupByKey also forms the new input channel with identical mapping device.Each relevant GroupByKey operation start delivery channel.If the result of GroupByKey is only consumed by the CombineValues operation, this operation is fused in corresponding delivery channel.Similarly, if GroupByKey's or the CombineValues's that merges result is only consumed by the ParallelDo operation, if this operation it can not be fused in the input channel of different MS CR also be fused in delivery channel.ParallelDo, the GroupByKey that merges and CombineValues operation inner all PCollection present tense, is nonessential and can be deleted.At last, each output of mapper ParallelDo generates its straight-through delivery channel, and this each output stream is to the operation except one of relevant GroupByKey or output.
After all GroupByKey operations had been transformed into the MSCR operation, any residue ParallelDo operation also was transformed into ordinary MSCR operation, and these ordinary MSCR operations have single input channel and the identical delivery channel that comprises ParallelDo.The final optimization pass executive plan only comprises MSCR, Flatten and Operate operation.
In case generated the data stream figure of revising, actuator 310 is combined line operate to produce the specific parallel data object (406) corresponding with the parallel data object that delays with regard to what execution delayed.Carrying out the broad sense mapping simplifies operation and (for example, MSCR) can comprise that operation is simplified in the broad sense mapping to be translated into single mapping and to simplify and operate and carry out single mapping and simplify operation.Carrying out before single mapping simplifies operation, actuator 310 can be adjudicated and whether be carried out single mapping and simplify operation as local sequential operation or long-range parallel work-flow, and then correspondingly carries out single mapping and simplify.For example, actuator 310 can described abovely be adjudicated based on the size of input data set like that.
Fig. 4 B is the process flow diagram that illustrates the example of the process 450 that can be carried out for the data stream figure of carrying out correction by the actuator 310 of streamline storehouse 202c.The data stream figure (452) that actuator 310 access is revised and beginning for example begin ergodic data stream graphics (454) in topological mode forward.Described above such, in other implementation, actuator 310 can be supported increasing progressively of streamline or carry out continuously.
When actuator 310 runs into non-MSCR operation (456), actuator 310 use are come those operations of local execution (458) in the logic that streamline storehouse 202c comprises.On the other hand, when actuator 310 runs into the MSCR operation (456), actuator 310 determines whether that simplifying storehouse 202b with mapping carries out MSCR as local sequential operation or replace as long-range parallel work-flow (406).For example, actuator 310 can determine the data that are associated with MSCR estimation size and determine whether the size of estimating surpasses threshold value.If estimate size below threshold size, actuator 310 can be carried out MSCR as local sequential operation (462).On the contrary, if the size of estimating equals or exceeds threshold size, actuator 310 can be simplified operation and simplify storehouse 202c with mapping and carry out this mapping and simplify operation and carry out MSCR as long-range parallel work-flow and operate as long-range parallel work-flow (464) by MSCR being translated into single mapping
For example, in an implementation, actuator is estimated for the size of the input data of each input channel of MSCR, is estimated the size by the intermediate data of each input channel generation, and estimates the size from the output data of each delivery channel.If any size estimation in these size estimation equals or exceeds 64 megabyte (MB), simplify storehouse 202b with mapping and carry out MSCR as long-range parallel work-flow (464).
When carrying out MSCR as local sequential operation, actuator 310 can be carried out proper handling to data with mode successively.For example, for circulation that can implement in storer of actuator is carried out proper handling with visit data and to data.
When simplifying storehouse 202b and carry out MSCR as long-range parallel work-flow with mapping, actuator 310 can be estimated the number of mappings work device process and reduce the working device process that needs in order to carry out the processing that is associated based on the configuration of the input and output of MSCR.For example, actuator can be for example based on the estimation of the input data that are used for each input channel or known dimensions estimate number for the mappings work device process of each input channel, and similarly can be for example based on the estimation of the data that will be processed by each delivery channel or dose known amounts estimate to simplify the number of working device process.Actuator 310 then can add up to the number of mappings work device process and simplify the number of working device process and make these working device processes simplify storehouse 202b with mapping and quote.
Simplify working device to each mappings work device and each and give index number.For example, if MSCR comprises two input channels, one has 4 mappings work device processes and another has 5 mappings work device processes, can give from 1 to 9 index number to 9 working devices.This can occur for simplifying the working device process equally.These index number are used to respectively related given mappings work device process or simplify the working device process and specific input or delivery channel.Continue precedent, index number 1-4 can be associated with the first input channel, and index number 5-9 can be associated with the second input channel.
Therefore, when storehouse 202b is simplified in mapping to mappings work device course allocation mapping task, transmit in mapping function together with the sign of the index that is associated of working device and file to be worked in.Index number regulation mapping function is then quoted which map operation (parallelDo) to the element in file, and indicates thus working device to implement which input channel.
Similarly, simplifying function uses the index of simplifying the working device process to select as being used for which is simplified operational applications in the basis of the input of simplifying the working device process.Distributing when simplifying task to simplifying the working device function, the index that is associated of working device transmits to simplifying in function together with file the to be worked in sign of (this document comprises the single planarization of key grouping input and flows).Index number is then stipulated to simplify function and which the element in file quoted is simplified operation, and stipulates thus which delivery channel working device implements.Implement the grouping delivery channel if simplify the working device process, simplify the working device process and carry out CombineValues " combination " operation (if existence), and then carry out ParallelDo and " simplify " operation.Implement straight-through delivery channel if simplify the working device process, thus simplify the working device process carry out run-out key/value on the cancellation division operation cancel and shine upon the impact that the implicit expression of simplifying the storehouse is shuffled.
It is right that each input channel in the input channel of MSCR operation can send key/value to any delivery channel in its R delivery channel.For example, input channel 2 sends an output and sends another output and do not send output to delivery channel 2 to delivery channel 3 to delivery channel 1.
Mapping is simplified storehouse 202b and is processed the shuffling of data output by mappings work device process, and then will export to correctly simplify the pathfinding of device working device by.It is right that each input channel in the input channel of MSCR operation can send key/value to any delivery channel in its R delivery channel.For example, input channel 2 sends an output and sends another output and do not send output to delivery channel 2 to delivery channel 3 to delivery channel 1.This is for example shone upon the emitToShard (key that simplifies in the 202b of storehouse by use by streamline storehouse 202c, value, shardNum) primitive is processed, and this primitive allows streamline storehouse 202c to indicate to which and simplifies the given output that the working device process sends mappings work device process.When sending output from given mappings work device process to specific delivery channel, streamline storehouse 202c can calculate the scope of simplifying working device index corresponding with this delivery channel, with the determinacy function select they one of, and use the emitToShard function to send output to the selected device working device of simplifying.The determinacy function can comprise the hash to the key that is associated with output valve, and wherein which of the working device process of simplifying that determine to select be used in the scope of index of output of the result of hash simplified working device.This can guarantee to send to the identical working device process of simplifying all data that are associated with particular key.
In an implementation, mapping is simplified storehouse 202b and is only directly supported writing to single output.In addition, simplify in the implementation of storehouse 202b in mapping, estimate that key/value is right if simplify the output of function, the key that writes to this output must be with identical to simplifying the key that transmits in function.In contrast, in an implementation, each MSCR delivery channel can to zero, one or some output write and to key without constraint.Export more flexibly in order to implement these, simplify function and can write direct to output, thereby avoid the normal output mechanism that the storehouse is simplified in mapping.If the restriction that the output in storehouse is simplified in mapping is satisfied in any output in the output of MSCR, can replace with shining upon the normal mechanism of simplifying the storehouse and implement this output.
When estimating each parallel work-flow, the object that actuator 310 use proper datas fillings delay is to specialize object (466), until complete all operations, at this moment actuator 310 back returns to control (468) to using 202a.
Fig. 5 shows example executive plan conversion, and this executive plan conversion illustrates the ParallelDo producer-consumer and merges the fusion with the compatriot.Figure 502 illustrates the original figure that comprises ParallelDo operation A 504, B 506, C 508 and D 510.As shown in the figure, ParallelDo operation A 504, B 506, C 508 and D 510 are fused into single ParallelDo A+B+C+D 512 to form figure 550.New ParallelDo in figure 550 creates all leaves outputs and output A.1 514 according to original figure 502, because a certain other operation Op 518 needs output A.1 514.No longer need and merge in figure 550 in the middle of output A.0 516.
Fig. 6 A and Fig. 6 B show example executive plan conversion 600, and this executive plan conversion illustrates MSCR and merges.Figure 601 illustrates the original figure that comprises three GroupByKey operation GBK1 602, GBK2 604 and GBK3 606.In this example, all three GroupByKey operations 602,604 and 606 are relevant, and the therefore single MSCR operation 652 of sowing as shown in the figure 650 of revising.With reference to figure 601, GBK1 602 is relevant with GBK2 604, because they all consume the output of ParallelDo M2 608.GBK2604 is relevant with GBK3 606, because they all consume ParallelDo M4.0 612.As being indicated by asterisk, the rear action need ParallelDoM2.0 except GBK1 602.Similarly, the rear action need ParallelDo M4.1 except those operations that form the MSCR operation.
With reference to figure 650, incorporate ParallelDo M2 608, M3 614 and M4 612 into as MSCR input channel 616.Each operation in GroupByKey 602,604,606 operations becomes grouping delivery channel 620.The delivery channel of GBK2 is incorporated CV2CombineValues operation 622 and R2 ParallelDo operation 624 into.R3 ParallelDo 626 operations also are fused in delivery channel.For the input from non-ParallelDo Op1 to GBK1 creates additional identical input channel.For M2.0 and the M4.1PCollection that uses after the MSCR operation creates two additional straight-through delivery channels (being depicted as the limit from mapper to output).Gained MSCR operation 650a has 4 input channels 616 and 5 delivery channels 620.
Fig. 7 A to Fig. 7 E for example illustrates the example of the data flow diagram fractal transform of being carried out by optimizer 306.
Fig. 7 A illustrates initial parallel data streamline 700.In order to simplify, not shown parallel data object.This streamline is obtained four different input sources and is write two outputs.Input1 is processed by ParallelDo () A 702.Input2 is processed by ParallelDo () B 704, and Input3 is processed by ParallelDo () C 706.The result of these two operations is presented by flatten () 708 and in ParallelDo () D 710 together.Use the operation 712count () that derives to the Input4 counting, and result is further processed by ParallelDo () E 714.The operation join () 716 that use to derive is bonded together ParallelDo () A, D and E 702,710,714 result.The result of join () 716 is further processed by ParallelDo () F 718.At last, write out the result of ParallelDo () A and F 702 and 718 to external file.
Fig. 7 B illustrates by the primary data stream graphics 720 of constructing of calling to primitive (such as ParallelDo () and flatten ()) and the operation (such as count () and join ()) of deriving, and the operation of these derivations itself is implemented by calling that even lower level is operated.In this example, count () invoke extensions becomes ParallelDo C:Map 722, GroupByKeyC:GBK 724 and CombineValues C:CV 726, and join () invoke extensions becomes ParallelDo operation J:tag1 726, J:Tag2 728 and J:Tag3 730 to collect with result with each input that N input of sign collects in Flatten J:Fltn 732, GroupByKey J:GBK 734 and ParallelDoJ:Untag 736.
Fig. 7 C shows by place planarization conversion being applied to the data stream figure 738 of the correction that figure 720 produces.Push away Flatten operation Fltn 708 under ParallelDo operation D 710 and JTag:2 728 by consuming.
Fig. 7 D shows the data stream figure 740 that is applied to the correction that figure 738 produces by ParallelDo being merged conversion.The producer-consumer and synchronous fusion both are applied to adjacent ParallelDo operate to produce ParallelDo operation 760,762,764,766 and 768.
Fig. 7 E shows by MSCR being merged conversion and is applied to the final correction data stream figure 748 that figure 740 produces.GroupByKey operation C:GBK 724 and ParallelDo operation (C:Map 722 and C:CV 726) on every side are fused into a MSCR operation 750.GroupByKey operation J:GBK 734 becomes the core operation of the 2nd MSCR operation 752 and is included in the grouping delivery channel.The 2nd MSCR operation 752 also comprises residue ParallelDo operation 770,762,764 and 766 and straight-through delivery channel 744 at corresponding input channel.Original executive plan has 16 data parallel work-flows (ParallelDo, GroupByKey and CombineValues).Last minute planning has two MSCR operations.
Be implemented as the storehouse although be described as, the function of streamline storehouse 202c additionally or alternatively can also be implemented as service, and this service allows client by network (such as the Internet) access function.For example, the function of streamline storehouse 202c can be embodied as Web service on server system, and this Web service has the correspondence set of Web service application programming interface (API).Web service API can for example be implemented as based on the HTTP interface of expression state transitions (REST) or based on the interface of Simple Object Access Protocol (SOAP).Alternatively or additionally, can provide interface (such as webpage) to pass through network access service.
Use API or interface, the user can send from client to service the program by User Exploitation.Program for example can comprise collects the data parallel pipeline that class 302 and parallel work-flow 304 are implemented with walking abreast.Use API or interface, the user can indicate and send the message that is used for executive routine for the data of streamline and to service.Message can comprise the required any argument of program alternatively.In case received message, service with regard to the function of executive routine and implementation evaluation device 306, optimizer 308 and actuator 310 with the implementation data parallel pipeline.Service then can be to any output of client feedback process.Alternatively or additionally, user program can be carried out on client and program is come the implementation data parallel pipeline with API with the function of using evaluator 306, optimizer 308 and the actuator 310 implemented by service.
Fig. 9 illustrates and can be used for implementing streamline storehouse 202c as the example of the system 900 of service (being called in addition the pipeline processes service).Generally speaking, the framework that is used in system 900 implementing the pipeline processes service provides security context, and this security context allows non-confidential code safe operation in being used for implementing the data center of pipeline processes service of the program of external developer.This entity that can for example be used in the service data center makes the pipeline processes service can be used for not used by entity or during the third party developer that otherwise do not control with the entity associating or by entity.
As described in hereinafter complete, in the implementation shown in Fig. 9, the non-letter data parallel processing code of putting is resolved into two logic segments, and isolate each fragment with operation in secure computing environment (" sandbox " or " prison (jail) ").Fragment is the executable code of the data parallel (building the data stream figure according to this data parallel) that limits the user, and another fragment is the executable code that comprises the function of data operation.
For example, each fragment of non-confidential code can operation in moving client operating system and analog network and being connected the hardware virtual machine (VM) that connects.Hardware VM can prevent that non-confidential code from directly accessing main frame or the machine environment, and only can provide by concrete review mechanism communication beyond virtual machine is provided.Hardware VM can prevent the details how user's code Internet access data are stored and send in data center.
This framework can allow non-confidential code to move on data center's foundation structure of the machine processing environment is provided.Being used in data center the file system of storage and Mobile data and interconnection network can full speed running and move in safe sandbox for the non-confidential code of consumption data, and this may slow down non-confidential code.In some cases, Mobile data takies the most time in the time that spends in the executing data parallel computation.In this case, the execution of code compares with direct operation in the machine processing environment that is provided by data center's foundation structure the appropriateness decline that can only experience the overall execution time.Only non-confidential code being placed in safe sandbox can be placed in sandbox more efficient than code and implementation with file system and network with interior in some instances.Only non-confidential code is placed in and also can makes overall system be easier to protection in sandbox, be used for non-confidential code and the limited channel of putting the letter main-machine communication because exist with much wide communication channel contrast that can be used in sandbox supporting whole file system and network.
System 900 comprises client 902 and data center 904 that can be similar to data center 100.Client 902 can intercom by network 906 (such as the Internet) mutually with data center 904.Client 902 is stored user programs or uses 908, this user program or application for example comprise with above-described parallel data and collect the data parallel pipeline that class 302 and one or more parallel work-flow 304 are implemented, and these parallel datas are collected the pipeline processes service support that class and parallel work-flow are provided by data center 904.As described further below such, the user uses 908 and can upload and be carried out by data center 904 to data center 904.
The user program 908 that virtual machine 922 master controls (and carry out) are uploaded and executive plan storehouse 924.When carrying out user program 908, executive plan storehouse 924 builds the data stream figure based on parallel data object and parallel work-flow, and these parallel data objects and parallel work-flow form the streamline in user program 906.For this reason, executive plan storehouse 924 implementation evaluation devices 926, this evaluator and evaluator 306 are similarly constructed the inside executive plan data stream figure with the object that delays corresponding to data parallel pipeline and the operation that delays.Except implementation evaluation device 926, executive plan storehouse 924 can also be implemented for other function to the expression of executive plan service 920 communicating data stream graphics.For example, in an implementation, executive plan storehouse 924 comprises for using remote procedure call (RPC) to cross over the virtual machine border to the functions of executive plan service 920 communications.Can monitor that these call to guarantee suitably to call.For example, executive plan service 920 can check the validity of an argument of supplying with given function, and checks function call according to the white list of the function call that is allowed to.Can carry out audit for example to detect not being allowed to by the service of non-confidential code access or the request (investigation) of other data center's resource (for example, file or other service based on RPC).
In some implementations, can configuring virtual machine 922 be for the code in virtual machine and the outer environmental interaction of virtual machine 922 mode only to be arranged so that these RPC call.Executive plan storehouse 926 also can implement just to receive the function of the information of specializing (expression of the version of the object of for example, specializing itself or specific object) that realizes object from executive plan service 920 in a single day having optimized and having carried out the data stream figure.Executive plan storehouse 922 can use this information with the data object in specific internal data stream graphics then, thus the object that makes user program 906 can use these to specialize.
Optimization and the execution to the 924 data stream figures that send from the executive plan storehouse processed in executive plan service 920.In an implementation, executive plan service 920 is the letter processes of putting, and this is put the letter process and does not carry out any non-credit household's of putting code and have complete access right to data centers foundation structure.Executive plan service 920 is accepted to represent and is non-ly put the information of letter executive plan and graphic structure is come into force.Executive plan service 920 then process to figure optimization (that is to say, use graph transformation described above) and to the execution of the figure optimized.
In order to process optimization, optimizer 928 is implemented in executive plan service 920.As optimizer 308, optimizer 928 Graphics Application conversion (such as above-described graph transformation) are to generate the data stream figure of revising, this data stream figure comprises the parallel data object (perhaps subset) that delays and the combination parallel data operation that delays, and these parallel data operations can comprise MSCR.In an implementation, as optimizer 308, the 928 pairs of original execution plans of optimizer carry out reduce overall operation and group number of operations a series of by and be operating as general objective to produce minimum MSCR.
For the data stream figure of processing execution correction, actuator 930 is implemented in executive plan service 920.If the data stream figure of revising comprise in the data stream figure be not MSCR operation (for example, the PObject handling function), actuator 930 can communicate by letter with virtual machine (such as virtual machine 922) to implement the non-letter operation of putting in the JVM in virtual machine.
For MSCR, as actuator 310, actuator 930 is translated into single mapping with the given MSCR in figure and simplifies operation.For example, in order to do like this for given MSCR, actuator 930 is created in the input channel of MSCR and implements single mapping function of a plurality of map operations and implement a plurality of single functions of simplifying of simplifying operation in the delivery channel of MSCR.Actuator 930 is then carried out single mapping and is simplified operation as long-range parallel work-flow.For example, similar to the example that reference Fig. 4 B describes, actuator 930 can make a plurality of mappings work devices and simplify working device and come reason with the index number that is associated, and this index number is controlled the data that receive separately and separately data carried out mapping or simplify which operation in operation.
As virtual machine 922, virtual machine 934 can be hardware virtual machine and can implement with the KVM technology.In other implementation, virtual machine 934 may be implemented as the process virtual machine.The virtual machine that other processing module can be implemented other concurrent working device and be associated.
Except master control (and execution) user function 936, virtual machine 934 is master control and execution solution batch processor/batch processor process 938 also, and this process is used for processing the input and output data for user function 936.Generally speaking, transmit the input and output data as batch processor log between working device 932 and virtual machine 934.For example, working device 932 access (for example, being stored in reservoir 916) input data, extract batch processor log and for example use RPC to send the input batch processor logs rather than transmit each to virtual machine 934 and record and send to user function being used for to the solution batch processor/batch processor 938 virtual machine 934 from input.In one example, working device 932 is configured to extract the record of 64MB and sends those records to separating batch processor/batch processor 938.
Separate batch processor/batch processor 938 be configured to batch processing resolve into individual record, quote user function 936 and to user function 936 transmit individual record with for the treatment of.Separating batch processor/batch processor 938 also is configured to the output of user function 938 is accumulated the output batch processor log, and pass on the output batch processings to working device 932, one or more output file that other parts that this working device can be arranged to allow result be written to for example executive plan service 920 or system 900 then can be accessed.Executive plan service 920 can be responsible for passing on back result by executive plan storehouse 922 to user program 908.The batch delivery input and output can reduce the impact of the processing expenditure (expense that for example, needs in order to implement RPC) that needs in order to cross the virtual machine border between working device and virtual machine 934.
With the same with RPC between executive plan storehouse 926 in executive plan service 920, can monitor that the RPC between working device 932 and solution batch processor/batch processor 938 calls to guarantee suitably to call.In some implementations, can configuring virtual machine 934 be for the code in virtual machine and the outer environmental interaction of virtual machine 934 mode only to be arranged so that these RPC call.
Although shown in implementation comprise solution batch processor/batch processor 938 and cross over virtual machine border batch processing and send record and result, other implementation can not carried out batch processing to cross over virtual machine border communication.
Can configuring external accessible repositories 916 as the addressable master control stores service of client 902, thereby make client can store data (such as the input data that are used for user program 908) and/or fetch the output data from user program 908 in reservoir 916.For example, can implement reservoir 916 as the Web service with corresponding Web service API set.Can implement Web service API for example as based on the HTTP interface of expression state transitions (REST) or based on the interface of Simple Object Access Protocol (SOAP).In the interface based on REST, data object is visited as the resource with the next unique name of URI, and the expression of the incompatible exchange resource state of operation set of client 908 and reservoir 916 use definition.For example, the action of request can be represented as verb, such as being represented by HTTP GET, PUT, POST, HEAD and DELETE verb.Although be shown as the part of data center 904, reservoir 916 can be implemented by independent data center or other facility.
In an implementation, in the file of the result store of user program 908 in reservoir 916.The filename of file can be served 920 by executive plan and be indicated or designated in user program 908.In case user program 908 has been completed execution and result is stored in reservoir 916, the indication of successful execution can be sent back to client 902 and can comprise alternatively filename (for example, if filename is generated by executive plan service 920 or be not otherwise known to client 902).Client 902 can use filename and API to fetch result then.
Figure 10 illustrates be used to carrying out the non-process flow diagram of putting the example of the process 1000 that letter uses, and this is non-puts letter and use and comprise data parallel pipeline.Hereinafter describe process 1000 in the context of system 900, but other system or system configuration can implementation processes 900.In addition, hereinafter be described below example, this example is used Java (R) to become language to conciliate batch processor/batch processor 938 to implement user program 908 (comprising user function 936), executive plan storehouse 924.Generally speaking, Java (R) program runs in virtual machine so that compatible with various processing hardware.Use virtual machine can provide added layer of security by non-confidential code is run in the multilayer of virtual machine as the non-credit household's of putting code take operation Java (R) syllabified code.The innermost layer virtual machine is Java (R) VM that moves Java (R) syllabified code.Next virtual machine is operation client operating system and analog network and the hardware virtual machine that is connected connection.
As beginning, receive the non-letter of putting in data center 904 and use (1002).For example, the non-credit household of putting for example uses the API or the interface that provide to upload user program 908 (being expressed as Java (R) .jar file) to service interface 918.Also use API or interface, user's notification service interface 910 then starts user programs 908 operations and some arguments are controlled this operation.For example, argument can indicate the concrete input file in reservoir 916.
Instantiation the first virtual machine (1004).For example, service interface 910 for example comes instantiation subordinate hardware virtual machine 922 with the KVM technology.Service interface 910 use Java (R) when operation (comprising Java (R) VM), user's .jar file (user program 908), executive plan storehouse .jar file and being used for implemented any other standard .jar file in user program 908 and executive plan storehouse 926 and (virtual) this domain that other data file is filled virtual machine.
Then, carry out the non-letter of putting in the first virtual machine and use (1006).For example, service interface 918 can start Java (R) VM and carry out user's the non-letter program 906 of putting in Java (R) VM (this Java (R) VM is at virtual machine 922).User non-put the letter program and quotes executive plan storehouse 924, thereby make evaluator 926 build the data stream figure based on parallel data object and parallel work-flow in the storer of virtual machine 922, these parallel data objects and parallel work-flow form the streamline in user program 908.
Pass on the information (1008) of representative of data flow figure outside the first virtual machine.For example, executive plan storehouse 924 builds the expression of data stream figures, and uses RPC to call to executive plan service 920 and pass on expression.
Outside the first virtual machine, one or more graph transformation is applied to the information of representative data stream graphics to generate the data stream figure of revising, the data stream figure of this correction comprises one or more the parallel data object that delays in the parallel data object that delays and the combination parallel data operation that delays and the combination parallel data operation (1010) that delays.For example, executive plan service 920 is accepted the expression of data stream figure and graphic structure is come into force.Optimizer 928 is carried out the data stream figure that the optimization of figure is revised with generation, and the data stream figure of this correction comprises the parallel data object (perhaps subset) that delays and the combination parallel data operation that delays, and these data manipulations can comprise MSCR.
What then, execution delayed is combined line operate to produce the parallel data object (1012) specialized corresponding with the parallel data object that delays.For this reason, for example, actuator 930 is translated into single mapping with the MSCR in figure and simplifies operation, and this mapping is simplified operation and comprised the single mapping function of implementing a plurality of map operations and implement a plurality of single functions of simplifying of simplifying operation.Actuator 930 is then carried out single mapping and is simplified operation as long-range parallel work-flow, and this long-range parallel work-flow causes quotes and to single mapping or simplify a plurality of parallel mappings work devices of function passes and simplify working device 932 and the suitably indication of input file.Indicate work its one of as master control, the activity of other working device is coordinated in this master control.
Then, for non-one or more second virtual machine of credit household's function instantiation of putting.For example, the given working device of quoting 932 instantiation subordinate hardware virtual machines 934 and when moving with Java (R) (comprising Java (R) VM), single mapping or simplify function copy, separate batch processor/batch processor code and conciliate batch processor/batch processor 938 and any other standard .jar file of needs and this domain of other data file filling virtual machine in order to implement user function 936.Working device 932 starts Java (R) VM and operation solution batch processor/batch processor 938 in Java (R) VM in virtual machine 934.Separate the quoting user function 936 that batch processor/batch processor 938 is controlled in Java (R) VM.
In case instantiation virtual machine 934 and separate 938 operations of batch processor/batch processor, working device 932 just access from the input file of reservoir 916.Working device extracts batch processor log and uses RPC to send the input batch processor log to the solution batch processor/batch processor 938 in VM 934 from input file.Separate that batch processor/batch processor 938 will input that individual record is resolved in batch processing, the function of quoting the user to be processing in turn each record, will export record and accumulate the output batch processing, and feeding back out batch processing to working device 932 reception and registration in the answer of RPC at last.
In case working device 932 receives the output batch processings, working device 932 is just arranged can be by one or more output file of other parts access of executive plan storehouse 922 or system 900 to allow result for example be written to.Based on output file, executive plan service 920 generates the information of specializing that realizes object, such as the expression of the specific version of object or specific object.Executive plan service 920 922 is passed on these information to the executive plan storehouse then.The data object in the specific internal data stream graphics of this information is used in executive plan storehouse 922, thus the object that makes user program 906 can use those to specialize.
In an implementation, in case user program 906 is completed operation, pass on output or the result of user program 906 to service interface 918.Service interface 918 is directly passed on output to client then.
Alternatively or additionally, in can the file in reservoir 916, storage output or result be in order to make them addressable by client 902.For example, in this case, the filename of file can be served 920 by executive plan and indicated and offer client 902 together with the indication of user program 908 successful execution.Client 902 can use filename to fetch result then.In another example, user program 908 can the specified document name, and can send the indication of successful execution of user programs 908 and Transmit message name not to client 902.Yet, because filename is indicated by user program 908, so client 902 can the Internet access filename and can be fetched result.
Use virtual machine can provide isomery " deeply defence " strategy to implement the non-credit household's of putting code.In order to jeopardize data center of lower floor, illegal non-confidential code must permeate the barrier of some audits.For example, when using hardware virtual machine, non-confidential code must jeopardize the standard procedure model of being implemented by the client operating system on hardware virtual machine, and obtains " root " access in the client.Non-confidential code must jeopardize the sandbox that the simulator by virtual machine provides then.In addition, when using programming language (this programming language also applies to the runtime with virtual machine), non-confidential code must first jeopardize the innermost layer virtual machine.
Although shown in framework user program is isolated in sandbox zone in data center, can use other processing environment that has the controlled access of data centers foundation structure.For example, in other implementation, user program can be carried out on client 908.Similar to executive plan storehouse 924, the storehouse on client 908 can the generated data stream graphics and directly or by the expression of service interface 918 to executive plan service 920 communicating data stream graphics.Executive plan service 920 can described abovely make the data stream figure come into force, create the figure of revising then like that, and carry out the figure of revising, and still carry out user function to prevent that user function is to the direct access of data center of lower floor foundation structure in virtual machine 934 or other sandbox.
Above-described technology is not limited to any specific hardware or software configuration.In fact, can implement them with hardware, software or combination both.Described Method and Process may be implemented as the computer program of carrying out on the programmable calculator that comprises at least one processor and at least one data-storage system.Can use the high-level programming language implementation procedure, also can be with collecting or other even lower level language implementation procedure and if wish.
Any such program will be stored on computer-usable storage medium or equipment (for example CD-Rom, RAM or disk) usually.When in the processor that reads computing machine and when carrying out, the instruction of program makes programmable calculator realize above-described various operation.
A plurality of implementations have been described.Yet, will understand, can there be various modifications.Thereby other implementation is in the scope of following claim.
Claims (51)
1. method comprises:
A plurality of parallel work-flows that wherein said data parallel pipeline is specified a plurality of parallel data objects of comprising a plurality of elements and is associated with non-confidence function to described element operation are provided comprising one or more processing module and provide the data center of the machine processing environment to receive the non-letter of putting comprise data parallel pipeline;
Instantiation the first secure computing environment on one or more processing module in described the machine processing environment and in described processing module;
Carry out the described non-letter of putting and use in described the first secure computing environment, wherein carry out the data stream figure that described application generates the parallel data object that delay corresponding with described data parallel pipeline and the parallel work-flow that delays;
Pass on the information that represents described data stream figure beyond described the first secure computing environment;
Beyond described the first secure computing environment and the described information that one or more graph transformation is applied to represent described data stream figure in described the machine processing environment generating the data stream figure of revising, the data stream figure of described correction comprise be associated with one or more non-confidence function in described non-confidence function, one or more the parallel data object that delays in the described parallel data object that delays and the combination parallel data operation that delays and the combination parallel data operation that delays; And
Carry out described delay be combined line operate to produce the specific parallel data object corresponding with the described parallel data object that delays, wherein carry out the described line operate that is combined that delays and comprise:
One or more second secure computing environment of instantiation on one or more processing module in described the machine processing environment and in described processing module;
Carry out in described one or more second secure computing environment with described delay be combined the described non-confidence function that line operate is associated.
2. method according to claim 1, wherein said the first secure computing environment comprises the first virtual machine, and described one or more second secure computing environment comprises the second virtual machine.
3. method according to claim 2, wherein said the first virtual machine and described one or more second virtual machine are hardware virtual machines.
4. method according to claim 1, wherein carry out in described one or more second secure computing environment with the described described non-confidence function that line operate is associated that is combined that delays and comprise:
To pass on the input batch processor log described the second secure computing environment of extroversion, described input batch processor log comprises a plurality of indivedual input records from described the second secure computing environment; And
Each record in described individual record in described input batch processing is carried out with described at least one non-confidence function that is combined in the described non-confidence function that line operate is associated that delays exported record to generate;
Described output record is accumulated the output batch processing; And
Pass on described output batch processing beyond described the second secure computing environment.
5. method according to claim 1, also comprise described non-output of putting the letter application is sent to described data center sending the described non-client that letter is used of putting.
6. method according to claim 1, wherein pass on the described information that represents described data stream figure to comprise the described information that represents described data stream figure to the execution figure service communication beyond described the first secure computing environment beyond described the first secure computing environment.
7. method according to claim 1, wherein:
The described combination parallel data operation that delays comprises that the mapping of at least one broad sense simplifies operation, the mapping of described broad sense simplify operation comprise a plurality of parallel map operations and a plurality of parallel simplify operation and can be translated into single mapping simplify operation, described single mapping is simplified operation and is comprised be used to the single mapping function of implementing described a plurality of parallel map operations and be used for implementing described a plurality of parallel single function of simplifying of simplifying operation, and described single mapping function and the described single function of simplifying comprise one or more non-confidence function in described non-confidence function.
8. method according to claim 7, wherein:
Carry out the described line operate that is combined that delays and comprise that described combinatorial mapping is simplified operation to be translated into described single mapping and to simplify operation; And
Carry out in described one or more second secure computing environment with the described described non-confidence function that line operate is associated that is combined that delays and be included in the described single mapping function of execution and the described single function of simplifying in described one or more second secure computing environment.
9. method according to claim 1, wherein:
Carry out the described non-letter of putting and use the described non-letter application of putting of execution in the virtual machine that is included in described the first secure computing environment in described secure computing environment; And
Carry out in described one or more secure computing environment with described delay be combined described non-confidence function that line operate is associated be included in execution in virtual machine in described one or more second secure computing environment with described delay be combined the described non-confidence function that line operate is associated.
10. method according to claim 1, wherein pass on the information that represents described data stream figure to comprise beyond described the first secure computing environment and use remote procedure call to pass on the information that represents described data stream figure beyond described the first secure computing environment.
11. method according to claim 10 also comprises the described remote procedure call of audit.
12. a system comprises:
One or more processing module is configured to provide the machine processing environment and implements following secure computing environment and service:
The first secure computing environment in described the machine processing environment, described the first secure computing environment is configured to:
The non-letter of putting that execution comprises data parallel pipeline is used, a plurality of parallel work-flows that described data parallel pipeline is specified a plurality of parallel data objects of comprising a plurality of elements and is associated with non-confidence function to described element operation; Wherein carry out the data stream figure that described application generates the parallel data object that delay corresponding with described data parallel pipeline and the parallel work-flow that delays;
Pass on the information that represents described data stream figure beyond described the first secure computing environment;
Be arranged in beyond described the first secure computing environment and in the service of described the machine processing environment, described service is configured to:
Receive from described the first secure computing environment the described information that represents described data stream figure;
The described information that one or more graph transformation is applied to represent described data stream figure to be generating the data stream figure of revising, and the data stream figure of described correction comprises one or more parallel data object that delays that be associated with one or more non-confidence function in described non-confidence function, in the described parallel data object that delays and the combination parallel data operation that delays and the combination parallel data operation that delays;
Cause carry out described delay be combined line operate to produce the specific parallel data object corresponding with the described parallel data object that delays; And
One or more second secure computing environment in described the machine processing environment, described one or more second secure computing environment be configured to carry out with described delay be combined described non-confidence function that line operate is associated with cause carry out described delay be combined line operate.
13. system according to claim 12, wherein said the first secure computing environment comprises the first virtual machine, and described one or more second secure computing environment comprises the second virtual machine.
14. system according to claim 13, wherein said the first virtual machine and described one or more second virtual machine are hardware virtual machines.
15. system according to claim 12, wherein:
Described one or more treatment facility is configured to the implementation device, described working device is configured to input batch processor log from described the second secure computing environment to pass on described the second secure computing environment of extroversion, and described input batch processor log comprises a plurality of indivedual input records; And
For carry out with described delay be combined the described non-confidence function that line operate is associated, described one or more second secure computing environment is configured to:
Each record in described individual record in described input batch processing is carried out with described at least one non-confidence function that is combined in the described non-confidence function that line operate is associated that delays exported record to generate;
Described output record is accumulated the output batch processing; And
Pass on described output batch processing to described working device.
16. system according to claim 12 also comprises being configured to receive described non-client of putting the output of letter application.
17. system according to claim 12, wherein:
The described combination parallel data operation that delays comprises that the mapping of at least one broad sense simplifies operation, the mapping of described broad sense simplify operation comprise a plurality of parallel map operations and a plurality of parallel simplify operation and can be translated into single mapping simplify operation, described single mapping is simplified operation and is comprised be used to the single mapping function of implementing described a plurality of parallel map operations and be used for implementing described a plurality of parallel single function of simplifying of simplifying operation, and described single mapping function and the described single function of simplifying comprise one or more non-confidence function in described non-confidence function.
18. system according to claim 17, wherein:
Described service is configured to that described combinatorial mapping is simplified operation and is translated into described single mapping and simplifies operation; And
Described one or more second secure computing environment is configured to carry out described single mapping function and the described single function of simplifying in described one or more second secure computing environment.
19. system according to claim 12, wherein:
Described the first secure computing environment is configured to carry out in virtual machine in described the first secure computing environment the described non-letter of putting and uses; And
Be configured in described one or more second secure computing environment in the virtual machine in described one or more second secure computing environment to carry out with described delay be combined the described non-confidence function that line operate is associated.
20. a computer-readable medium of storing instruction, described instruction makes described one or more treatment facility when being carried out by one or more treatment facility:
The information of the data stream figure of the parallel data object that the access representative delays and the parallel work-flow that delays, the described parallel data object that delays and the parallel work-flow that delays are corresponding to by putting non-parallel data object and the parallel work-flow that letter is used the data parallel pipeline appointment that comprises, wherein said parallel data object comprises a plurality of elements, and described parallel work-flow is associated with the non-confidence function that described element is operated;
The described information that one or more graph transformation is applied to represent described data stream figure to be generating the data stream figure of revising, and the data stream figure of described correction comprises one or more parallel data object that delays that be associated with one or more non-confidence function in described non-confidence function, in the described parallel data object that delays and the combination parallel data operation that delays and the combination parallel data operation that delays; And
Carry out described delay be combined line operate to produce the specific parallel data object corresponding with the described parallel data object that delays, wherein, for carry out described delay be combined line operate, described instruction comprises makes described one or more treatment facility carry out the instruction of following operation:
One or more secure computing environment of instantiation;
Carry out in described one or more secure computing environment with described delay be combined the described non-confidence function that line operate is associated.
21. medium according to claim 22, wherein in order to access the information of the described data stream figure that represents the parallel data object that delays and the parallel work-flow that delays, described instruction is included in when being carried out by described one or more treatment facility and makes described one or more treatment facility carry out the following instruction that operates:
The described non-letter of putting that reception comprises described data parallel pipeline is used;
Instantiation initial safe processing environment;
Carry out the described non-letter of putting and use in described initial safe processing environment, wherein carry out the described data stream figure that described application generates the parallel data object that delays and the parallel work-flow that delays; And
Pass on beyond described initial safe processing environment and represent the described information of described data stream figure, thereby make described graph transformation be applied to represent the described information of described data stream figure beyond described initial safe processing environment.
22. medium according to claim 21, wherein said one or more secure computing environment comprises virtual machine.
23. a system comprises:
One or more treatment facility;
One or more memory device, described memory device, stores are implemented the instruction of the following when being carried out by described one or more treatment facility:
Comprise the application of data parallel pipeline, wherein said data parallel pipeline is specified a plurality of parallel data objects of comprising a plurality of elements and to a plurality of parallel work-flows of described parallel data Object Operations;
Evaluator is configured to generate the parallel data object that delay corresponding with described data parallel pipeline and the data stream figure of the parallel work-flow that delays based on described data parallel pipeline;
Optimizer, be configured to one or more graph transformation is applied to the data stream figure of described data stream figure generate to revise, the data stream figure of described correction comprise the described parallel data object that delays and the combination parallel data operation that delays in one or more parallel data object that delays and the combination parallel data operation that delays; And
Actuator, be configured to carry out described delay be combined line operate to produce the specific parallel data object corresponding with the described parallel data object that delays.
24. system according to claim 23, wherein:
The described combination parallel data operation that delays comprises that the mapping of at least one broad sense simplifies operation, the mapping of described broad sense simplify operation comprise a plurality of parallel map operations and a plurality of parallel simplify operation and can be translated into single mapping simplify operation, described single mapping is simplified operation and is comprised be used to the single mapping function of implementing described a plurality of parallel map operations and be used for implementing described a plurality of parallel single function of simplifying of simplifying operation.
25. system according to claim 24 wherein simplifies operation in order to carry out the mapping of described broad sense, described actuator is configured to that described combinatorial mapping is simplified operation and is translated into described single mapping and simplifies operation and carry out described single mapping and simplify operation.
26. system according to claim 25 wherein simplifies operation in order to carry out described single mapping, described actuator is configured to determine whether to carry out described single mapping and simplifies operation as local sequential operation or long-range parallel work-flow.
27. system according to claim 25, wherein be translated into described single mapping and simplify operation for the mapping of described broad sense being simplified operation, described actuator be configured to generate the mapping function that comprises described a plurality of map operations and comprise described a plurality of simplify the device operation simplify the device function.
28. system according to claim 23, wherein each parallel data object that delays comprises pointer, and described pointed produces the parallel data operation of described parallel data object.
29. system according to claim 23, wherein each parallel work-flow that delays comprises the pointer that points to the parallel data object and the pointer that points to the Parallel Object that delays, described parallel data is to liking the input to the described parallel work-flow that delays, and the described Parallel Object that delays is the output of the described parallel work-flow that delays.
30. system according to claim 23, wherein each object of specializing comprises the data that are contained in described object.
31. system according to claim 23, wherein said a plurality of parallel datas are to liking the first kind object of main frame programming language.
32. system according to claim 23, wherein said streamline also comprises the individual data object, and described individual data object comprises individual element, and described data stream figure comprises the corresponding individual data object that delays.
33. system according to claim 32, at least one parallel work-flow in described a plurality of parallel work-flows in wherein said streamline is to a parallel data Object Operations in described individual data object and described a plurality of parallel data object, and described data stream figure comprises the parallel work-flow that delays to the correspondence of the individual data object that delays and the parallel data Object Operations that delays.
34. system according to claim 23, wherein said actuator is configured to high-speed cache and carries out described one or more result that is combined line operate that delays to be used for carrying out use in the future of described data parallel pipeline.
35. a system comprises:
One or more treatment facility;
One or more memory device, described memory device, stores are implemented the instruction of the following when being carried out by described one or more treatment facility:
Actuator is configured to:
Visit data stream graphics, described data stream figure comprise the parallel data object that delays and the combination parallel data operation that delays; And
Carry out described delay be combined line operate to produce the specific parallel data object corresponding with the described parallel data object that delays;
Wherein, for described delay be combined the line operate that is combined that at least one in line operate delay, described actuator be configured to by following operation carry out described at least one delay be combined line operate:
Determine and the size of described at least one estimation that is combined the data that line operate is associated that delays;
Whether the size of determining described estimation surpasses threshold size;
If the size of described estimation below threshold size, carry out described at least one delay be combined line operate as local sequential operation; And
If the size of described estimation surpasses threshold size, carry out described at least one delay be combined line operate as long-range parallel work-flow.
36. system according to claim 35 wherein comprises for described at least one input data that are combined line operate that delay, by described at least one being combined of delaying intermediate data that line operate produces or by described at least one one or more data that are combined the output data that line operate produces that delay with described at least one being combined of delaying described data that line operate is associated.
37. system according to claim 35, wherein:
Described at least one combination parallel data operation that delays is that operation is simplified in the broad sense mapping, the mapping of described broad sense simplify operation comprise a plurality of parallel map operations and a plurality of parallel simplify operation and can be translated into single mapping simplify operation, described single mapping is simplified operation and is comprised be used to the single mapping function of implementing described a plurality of parallel map operations and be used for implementing described a plurality of parallel single function of simplifying of simplifying operation; And
Simplify operation in order to carry out the mapping of described broad sense, described actuator is configured to that described combinatorial mapping is simplified operation and is translated into described single mapping and simplifies operation and carry out described single mapping and simplify operation.
38. described system according to claim 37, wherein, simplify operation as long-range parallel work-flow in order to carry out described single mapping, described actuator is configured to that described single mapping is simplified and operates in be replicated and carry out on a plurality of different disposal modules in data center.
39. described system according to claim 37, wherein, be translated into described single mapping and simplify operation for the mapping of described broad sense being simplified operation, described actuator be configured to generate the mapping function that comprises described a plurality of map operations and comprise described a plurality of simplify the device operation simplify the device function.
40. system according to claim 35, wherein, in order to determine the size of described estimation, described actuator is configured to access the note in described data stream figure, the estimation of described note reflection and described at least one size that is combined the described data that line operate is associated that delays.
41. system according to claim 35, wherein each parallel data object that delays comprises pointer, and described pointed produces the parallel data operation of described parallel data object.
42. system according to claim 35, wherein each parallel work-flow that delays comprises the pointer that points to the parallel data object and the pointer that points to the Parallel Object that delays, described parallel data is to liking the input to the described parallel work-flow that delays, and the described Parallel Object that delays is the output of the described parallel work-flow that delays.
43. system according to claim 35, wherein each object of specializing comprises the data that are contained in described object.
44. a system comprises:
One or more treatment facility;
One or more memory device, described memory device, stores are implemented the instruction of the following when being carried out by described one or more treatment facility:
Actuator is configured to:
the visit data stream graphics, described data stream figure comprises the parallel data object that delays and the combination parallel data operation that delays, at least one combination parallel data operation that delays in the wherein said combination parallel data operation that delays is that operation is simplified in the broad sense mapping, the mapping of described broad sense simplify operation comprise a plurality of parallel map operations and a plurality of parallel simplify operation and can be translated into single mapping simplify operation, described single mapping is simplified operation and is comprised be used to the single mapping function of implementing described a plurality of parallel map operations and be used for implementing described a plurality of parallel single function of simplifying of simplifying operation, and
Carry out described delay be combined line operate to produce the specific parallel data object corresponding with the described parallel data object that delays;
Wherein, simplify operation in order to carry out the mapping of described broad sense, described actuator is configured to that described combinatorial mapping is simplified operation and is translated into described single mapping and simplifies operation and carry out described single mapping and simplify operation.
45. described system according to claim 44, wherein, be translated into described single mapping and simplify operation for the mapping of described broad sense being simplified operation, described actuator is configured to generate the mapping function that comprises described a plurality of map operations and comprises described a plurality of function of simplifying of simplifying operation.
46. described system according to claim 45, wherein said actuator is configured to carry out described single mapping and simplifies operation as long-range parallel work-flow.
47. described system according to claim 46, wherein, simplify operation as long-range parallel work-flow in order to carry out described single mapping, described actuator is configured to make described single mapping to simplify operation by a plurality of working device processes execution on a plurality of different disposal modules.
48. described system according to claim 46, wherein, carried out by a plurality of working device processes in order to make described single mapping simplify operation, described actuator is configured to cause for each map operation in described map operation quotes a plurality of mappings work device processes, wherein each the mappings work device course allocation index number in described a plurality of mappings work device processes.
49. described system according to claim 48, each the mappings work device process in wherein said mappings work device process is configured to: receive the described mapping function of implementing described a plurality of map operations, one or more input that is associated with a map operation in described map operation and the index that is associated of described mappings work device process; The described map operation that is associated with described input based on the index selection that is associated of described mappings work device process; And selected map operation is quoted in described one or more input.
50. described system according to claim 46, wherein, carried out by a plurality of working device processes in order to make described single mapping simplify operation, described actuator is configured to make simplify to operate for described each of simplifying in operation quotes a plurality of working device processes of simplifying, and wherein simplifies working device course allocation index number to described a plurality of each of simplifying in the working device process.
51. described system according to claim 50, wherein said a plurality of each of simplifying in the working device process are simplified the working device process and are configured to: receive and implement described a plurality of simplify operation described and simplify function, simplify with described of simplifying in operation and operate one or more input and the described index that is associated of simplifying the working device process that is associated; Describedly simplify operation based on what the index selection that is associated of described working device process was associated with described input; And the selected operation of simplifying is quoted in described one or more input.
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
CN201510772809.0A CN105279022B (en) | 2010-05-04 | 2011-05-04 | The parallel processing of data |
Applications Claiming Priority (7)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US33114810P | 2010-05-04 | 2010-05-04 | |
US61/331,148 | 2010-05-04 | ||
US12/794,348 US8555265B2 (en) | 2010-05-04 | 2010-06-04 | Parallel processing of data |
US12/794,348 | 2010-06-04 | ||
US12/959,022 | 2010-12-02 | ||
US12/959,022 US8887156B2 (en) | 2010-05-04 | 2010-12-02 | Parallel processing of data |
PCT/US2011/035159 WO2011140201A1 (en) | 2010-05-04 | 2011-05-04 | Parallel processing of data |
Related Child Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201510772809.0A Division CN105279022B (en) | 2010-05-04 | 2011-05-04 | The parallel processing of data |
Publications (2)
Publication Number | Publication Date |
---|---|
CN103109260A true CN103109260A (en) | 2013-05-15 |
CN103109260B CN103109260B (en) | 2015-12-02 |
Family
ID=44902741
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201180032739.5A Active CN103109260B (en) | 2010-05-04 | 2011-05-04 | The parallel processing of data |
CN201510772809.0A Active CN105279022B (en) | 2010-05-04 | 2011-05-04 | The parallel processing of data |
Family Applications After (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201510772809.0A Active CN105279022B (en) | 2010-05-04 | 2011-05-04 | The parallel processing of data |
Country Status (7)
Country | Link |
---|---|
US (13) | US8555265B2 (en) |
EP (1) | EP2567313B1 (en) |
KR (3) | KR101904526B1 (en) |
CN (2) | CN103109260B (en) |
CA (2) | CA2798266C (en) |
DE (1) | DE202011110864U1 (en) |
WO (1) | WO2011140201A1 (en) |
Cited By (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN103678235A (en) * | 2013-12-09 | 2014-03-26 | 无锡市同威科技有限公司 | Network data processing device and method based on parallel flow lines |
CN106687921A (en) * | 2014-09-02 | 2017-05-17 | 起元科技有限公司 | Specifying components in graph-based programs |
CN107688493A (en) * | 2016-08-05 | 2018-02-13 | 阿里巴巴集团控股有限公司 | Train the method, apparatus and system of deep neural network |
CN107832144A (en) * | 2017-10-20 | 2018-03-23 | 南方电网科学研究院有限责任公司 | Distributed Parallel Computing method and apparatus |
CN111158693A (en) * | 2014-04-01 | 2020-05-15 | 谷歌有限责任公司 | Incremental parallel processing of data |
US10885003B2 (en) | 2014-09-02 | 2021-01-05 | Ab Initio Technology Llc | Compiling graph-based program specifications |
CN114579190A (en) * | 2022-02-17 | 2022-06-03 | 中国科学院计算机网络信息中心 | Cross-center cooperative computing arrangement method and system based on pipeline mechanism |
Families Citing this family (150)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
WO2009102765A2 (en) | 2008-02-11 | 2009-08-20 | Nuix North America Inc. | Parallelization of electronic discovery document indexing |
US9785700B2 (en) | 2008-02-11 | 2017-10-10 | Nuix Pty Ltd | Systems and methods for load-balancing by secondary processors in parallelized indexing |
US9928260B2 (en) | 2008-02-11 | 2018-03-27 | Nuix Pty Ltd | Systems and methods for scalable delocalized information governance |
US11048765B1 (en) | 2008-06-25 | 2021-06-29 | Richard Paiz | Search engine optimizer |
EP2370892B1 (en) | 2008-12-02 | 2020-11-04 | Ab Initio Technology LLC | Mapping instances of a dataset within a data management system |
US9665620B2 (en) | 2010-01-15 | 2017-05-30 | Ab Initio Technology Llc | Managing data queries |
US8918388B1 (en) * | 2010-02-26 | 2014-12-23 | Turn Inc. | Custom data warehouse on top of mapreduce |
US8555265B2 (en) | 2010-05-04 | 2013-10-08 | Google Inc. | Parallel processing of data |
US9495427B2 (en) | 2010-06-04 | 2016-11-15 | Yale University | Processing of data using a database system in communication with a data processing framework |
US9336263B2 (en) | 2010-06-04 | 2016-05-10 | Yale University | Data loading systems and methods |
US8935232B2 (en) * | 2010-06-04 | 2015-01-13 | Yale University | Query execution systems and methods |
US8782434B1 (en) | 2010-07-15 | 2014-07-15 | The Research Foundation For The State University Of New York | System and method for validating program execution at run-time |
US9489183B2 (en) * | 2010-10-12 | 2016-11-08 | Microsoft Technology Licensing, Llc | Tile communication operator |
JP5902185B2 (en) * | 2010-10-25 | 2016-04-13 | アビニシオ テクノロジー エルエルシー | Management of dataset objects in data flow graphs representing computer programs |
US9430204B2 (en) | 2010-11-19 | 2016-08-30 | Microsoft Technology Licensing, Llc | Read-only communication operator |
US9507568B2 (en) | 2010-12-09 | 2016-11-29 | Microsoft Technology Licensing, Llc | Nested communication operator |
US9395957B2 (en) | 2010-12-22 | 2016-07-19 | Microsoft Technology Licensing, Llc | Agile communication operator |
US8713039B2 (en) * | 2010-12-23 | 2014-04-29 | Microsoft Corporation | Co-map communication operator |
JP6138701B2 (en) * | 2011-03-04 | 2017-05-31 | 富士通株式会社 | Distributed calculation method and distributed calculation system |
US9116955B2 (en) | 2011-05-02 | 2015-08-25 | Ab Initio Technology Llc | Managing data queries |
US8954967B2 (en) * | 2011-05-31 | 2015-02-10 | International Business Machines Corporation | Adaptive parallel data processing |
WO2012166106A1 (en) | 2011-05-31 | 2012-12-06 | Hewlett-Packard Development Company, L.P. | Estimating a performance parameter of a job having map and reduce tasks after a failure |
WO2013009503A2 (en) | 2011-07-08 | 2013-01-17 | Yale University | Query execution systems and methods |
US9747128B1 (en) * | 2011-12-21 | 2017-08-29 | EMC IP Holding Company LLC | Worldwide distributed file system model |
US9361079B2 (en) * | 2012-01-30 | 2016-06-07 | Nvidia Corporation | Method for compiling a parallel thread execution program for general execution |
US20130219394A1 (en) * | 2012-02-17 | 2013-08-22 | Kenneth Jerome GOLDMAN | System and method for a map flow worker |
US8949175B2 (en) * | 2012-04-17 | 2015-02-03 | Turn Inc. | Meta-data driven data ingestion using MapReduce framework |
US10346375B2 (en) | 2012-04-26 | 2019-07-09 | Entit Software Llc | In-database parallel analytics |
CN103379114B (en) | 2012-04-28 | 2016-12-14 | 国际商业机器公司 | For the method and apparatus protecting private data in Map Reduce system |
US9165035B2 (en) * | 2012-05-10 | 2015-10-20 | Microsoft Technology Licensing, Llc | Differential dataflow |
US8972986B2 (en) * | 2012-05-25 | 2015-03-03 | International Business Machines Corporation | Locality-aware resource allocation for cloud computing |
US8984515B2 (en) | 2012-05-31 | 2015-03-17 | International Business Machines Corporation | System and method for shared execution of mixed data flows |
US9542462B1 (en) * | 2012-06-14 | 2017-01-10 | Google Inc. | Scaling high-level statistical languages to large, distributed datasets |
US9235446B2 (en) * | 2012-06-22 | 2016-01-12 | Microsoft Technology Licensing, Llc | Parallel computing execution plan optimization |
WO2014020735A1 (en) * | 2012-08-02 | 2014-02-06 | 富士通株式会社 | Data processing method, information processing device, and program |
US20140059552A1 (en) * | 2012-08-24 | 2014-02-27 | International Business Machines Corporation | Transparent efficiency for in-memory execution of map reduce job sequences |
US9122873B2 (en) | 2012-09-14 | 2015-09-01 | The Research Foundation For The State University Of New York | Continuous run-time validation of program execution: a practical approach |
EP2898638B1 (en) * | 2012-09-21 | 2020-10-28 | NYSE Group, Inc. | High performance data streaming |
US9471651B2 (en) | 2012-10-08 | 2016-10-18 | Hewlett Packard Enterprise Development Lp | Adjustment of map reduce execution |
US10489360B2 (en) | 2012-10-17 | 2019-11-26 | Ab Initio Technology Llc | Specifying and applying rules to data |
US9146830B2 (en) * | 2012-10-26 | 2015-09-29 | Jsmapreduce Corporation | Hybrid local/remote infrastructure for data processing with lightweight setup, powerful debuggability, controllability, integration, and productivity features |
US9832068B2 (en) | 2012-12-17 | 2017-11-28 | Microsoft Technology Licensing, Llc | Reachability-based coordination for cyclic dataflow |
US9536016B2 (en) * | 2013-01-16 | 2017-01-03 | Google Inc. | On-disk multimap |
US20140215471A1 (en) * | 2013-01-28 | 2014-07-31 | Hewlett-Packard Development Company, L.P. | Creating a model relating to execution of a job on platforms |
US11741090B1 (en) | 2013-02-26 | 2023-08-29 | Richard Paiz | Site rank codex search patterns |
US11809506B1 (en) | 2013-02-26 | 2023-11-07 | Richard Paiz | Multivariant analyzing replicating intelligent ambience evolving system |
US9336058B2 (en) | 2013-03-14 | 2016-05-10 | International Business Machines Corporation | Automated scheduling management of MapReduce flow-graph applications |
CN105164634A (en) * | 2013-03-29 | 2015-12-16 | 惠普发展公司，有限责任合伙企业 | Batching tuples |
US9116953B2 (en) | 2013-05-17 | 2015-08-25 | Sap Se | Calculation engine with dynamic partitioning of intermediate results |
US9537931B2 (en) | 2013-07-29 | 2017-01-03 | Red Hat, Inc. | Dynamic object oriented remote instantiation |
WO2015030717A1 (en) * | 2013-08-27 | 2015-03-05 | Empire Technology Development Llc | Consolidating operations associated with a plurality of host devices |
KR20150033453A (en) * | 2013-09-24 | 2015-04-01 | 주식회사 엘지씨엔에스 | Method of big data processing, apparatus performing the same and storage media storing the same |
US20150149745A1 (en) * | 2013-11-25 | 2015-05-28 | Markus Eble | Parallelization with controlled data sharing |
US10776325B2 (en) | 2013-11-26 | 2020-09-15 | Ab Initio Technology Llc | Parallel access to data in a distributed file system |
KR102186050B1 (en) * | 2013-12-06 | 2020-12-03 | 아브 이니티오 테크놀로지 엘엘시 | Source code translation |
US9489225B2 (en) * | 2014-01-15 | 2016-11-08 | Cisco Technology, Inc. | Allocating resources for multi-phase, distributed computing jobs |
US9514171B2 (en) * | 2014-02-11 | 2016-12-06 | International Business Machines Corporation | Managing database clustering indices |
US9563697B1 (en) | 2014-02-24 | 2017-02-07 | Amazon Technologies, Inc. | Calculating differences between datasets having differing numbers of partitions |
US9424290B2 (en) | 2014-03-11 | 2016-08-23 | Wipro Limited | System and method for data validation |
US9367366B2 (en) * | 2014-03-27 | 2016-06-14 | Nec Corporation | System and methods for collaborative query processing for large scale data processing with software defined networking |
US9607073B2 (en) | 2014-04-17 | 2017-03-28 | Ab Initio Technology Llc | Processing data from multiple sources |
US9483310B2 (en) | 2014-04-29 | 2016-11-01 | Bluedata Software, Inc. | Associating cache memory with a work process |
US11169993B2 (en) * | 2014-06-06 | 2021-11-09 | The Mathworks, Inc. | Datastore mechanism for managing out-of-memory data |
JP2016004328A (en) * | 2014-06-13 | 2016-01-12 | 富士通株式会社 | Task assignment program, task assignment method, and task assignment device |
US11099841B2 (en) * | 2014-06-26 | 2021-08-24 | Sap Se | Annotations for parallelization of user-defined functions with flexible partitioning |
US10248688B2 (en) * | 2014-06-26 | 2019-04-02 | Sap Se | Annotations for parallelization of user-defined functions with flexible partitioning |
US9298590B2 (en) * | 2014-06-26 | 2016-03-29 | Google Inc. | Methods and apparatuses for automated testing of streaming applications using mapreduce-like middleware |
US9286044B2 (en) | 2014-06-27 | 2016-03-15 | International Business Machines Corporation | Hybrid parallelization strategies for machine learning programs on top of MapReduce |
US9613127B1 (en) * | 2014-06-30 | 2017-04-04 | Quantcast Corporation | Automated load-balancing of partitions in arbitrarily imbalanced distributed mapreduce computations |
SG11201700381XA (en) | 2014-07-18 | 2017-02-27 | Ab Initio Technology Llc | Managing lineage information |
US10826930B2 (en) | 2014-07-22 | 2020-11-03 | Nuix Pty Ltd | Systems and methods for parallelized custom data-processing and search |
CN105302536A (en) * | 2014-07-31 | 2016-02-03 | 国际商业机器公司 | Configuration method and apparatus for related parameters of MapReduce application |
US9760406B2 (en) | 2014-09-02 | 2017-09-12 | Ab Initio Technology Llc | Controlling data processing tasks |
US9933918B2 (en) * | 2014-09-02 | 2018-04-03 | Ab Initio Technology Llc | Specifying control and data connections in graph-based programs |
US9626393B2 (en) | 2014-09-10 | 2017-04-18 | Ab Initio Technology Llc | Conditional validation rules |
GB2530052A (en) | 2014-09-10 | 2016-03-16 | Ibm | Outputting map-reduce jobs to an archive file |
US10095654B2 (en) * | 2014-09-30 | 2018-10-09 | International Business Machines Corporation | Mapping and reducing |
US10353912B2 (en) | 2014-10-10 | 2019-07-16 | Salesforce.Com, Inc. | Navigation of a data extraction graph of data and metadata from a data repository |
US9747089B2 (en) * | 2014-10-21 | 2017-08-29 | International Business Machines Corporation | Automatic conversion of sequential array-based programs to parallel map-reduce programs |
US10437819B2 (en) | 2014-11-14 | 2019-10-08 | Ab Initio Technology Llc | Processing queries containing a union-type operation |
US9639566B2 (en) * | 2014-12-18 | 2017-05-02 | Here Global B.V. | Method, apparatus and computer program product for improved storage of key-value pairs |
US10185730B2 (en) * | 2014-12-31 | 2019-01-22 | Nexenta Systems, Inc. | Methods and systems for key-value-tuple-encoded storage |
CN105897805B (en) * | 2015-01-04 | 2019-12-27 | 伊姆西公司 | Method and device for cross-layer scheduling of resources of data center with multi-layer architecture |
US10417281B2 (en) | 2015-02-18 | 2019-09-17 | Ab Initio Technology Llc | Querying a data source on a network |
US10397313B2 (en) * | 2015-03-18 | 2019-08-27 | Nokia Of America Corporation | Data stream load balancing utilizing multiple sets of servers |
US10162617B2 (en) * | 2015-04-10 | 2018-12-25 | Google Llc | Binary translation into native client |
US11200249B2 (en) | 2015-04-16 | 2021-12-14 | Nuix Limited | Systems and methods for data indexing with user-side scripting |
WO2016172015A1 (en) * | 2015-04-20 | 2016-10-27 | 3M Innovative Properties Company | Durable low emissivity window film constructions |
US10133827B2 (en) | 2015-05-12 | 2018-11-20 | Oracle International Corporation | Automatic generation of multi-source breadth-first search from high-level graph language |
US9684526B2 (en) * | 2015-05-15 | 2017-06-20 | Ab Initio Technology Llc | Techniques for configuring a generic program using controls |
US10614126B2 (en) | 2015-05-21 | 2020-04-07 | Oracle International Corporation | Textual query editor for graph databases that performs semantic analysis using extracted information |
US9575736B2 (en) * | 2015-07-22 | 2017-02-21 | Oracle International Corporation | Advanced interactive command-line front-end for graph analysis systems |
US10127025B2 (en) | 2015-07-22 | 2018-11-13 | Oracle International Corporation | Optimization techniques for high-level graph language compilers |
US10810257B2 (en) | 2015-08-27 | 2020-10-20 | Oracle International Corporation | Fast processing of path-finding queries in large graph databases |
US10530892B2 (en) * | 2015-09-28 | 2020-01-07 | Microsoft Technology Licensing, Llc | Processing request for multi-versioned service |
US9367425B1 (en) | 2015-09-30 | 2016-06-14 | Semmle Limited | Disjoint-or trees for caching aggregated dependencies |
US9971570B2 (en) | 2015-12-15 | 2018-05-15 | Oracle International Corporation | Automated generation of memory consumption aware code |
US9715373B2 (en) * | 2015-12-18 | 2017-07-25 | International Business Machines Corporation | Dynamic recompilation techniques for machine learning programs |
US10684781B1 (en) * | 2015-12-23 | 2020-06-16 | The Mathworks, Inc. | Big data read-write reduction |
CA3009817A1 (en) * | 2015-12-29 | 2017-07-06 | Tao Tao | Systems and methods for caching task execution |
US10216926B2 (en) * | 2016-01-29 | 2019-02-26 | Cisco Technology, Inc. | Isolation of untrusted code in operating system without isolation capability |
KR102592611B1 (en) * | 2016-02-18 | 2023-10-23 | 한국전자통신연구원 | Map reduce apparatus, controller for map reduce and method thereof |
US9977725B2 (en) | 2016-08-26 | 2018-05-22 | Cisco Technology, Inc. | Automatic classification and parallel processing of untested code in a protected runtime environment |
US10025566B1 (en) * | 2016-10-07 | 2018-07-17 | The Mathworks, Inc. | Scheduling technique to transform dataflow graph into efficient schedule |
US10613897B1 (en) * | 2016-12-21 | 2020-04-07 | Ca, Inc. | Systems and methods for creating program-specific execution environments |
US10769180B2 (en) | 2017-02-02 | 2020-09-08 | International Business Machines Corporation | Efficient dataflow processing for objects |
US10168705B2 (en) * | 2017-04-06 | 2019-01-01 | Uber Technologies, Inc. | Automatic tuning of autonomous vehicle cost functions based on human driving data |
US10540398B2 (en) | 2017-04-24 | 2020-01-21 | Oracle International Corporation | Multi-source breadth-first search (MS-BFS) technique and graph processing system that applies it |
CN107256363B (en) * | 2017-06-13 | 2020-03-06 | 杭州华澜微电子股份有限公司 | High-speed encryption and decryption device composed of encryption and decryption module array |
US10585945B2 (en) | 2017-08-01 | 2020-03-10 | Oracle International Corporation | Methods of graph-type specialization and optimization in graph algorithm DSL compilation |
US10887235B2 (en) * | 2017-08-24 | 2021-01-05 | Google Llc | Method of executing a tuple graph program across a network |
US10599482B2 (en) | 2017-08-24 | 2020-03-24 | Google Llc | Method for intra-subgraph optimization in tuple graph programs |
US10642582B2 (en) | 2017-08-24 | 2020-05-05 | Google Llc | System of type inference for tuple graph programs method of executing a tuple graph program across a network |
US11294943B2 (en) * | 2017-12-08 | 2022-04-05 | International Business Machines Corporation | Distributed match and association of entity key-value attribute pairs |
CN108197246A (en) * | 2017-12-29 | 2018-06-22 | 安徽迈普德康信息科技有限公司 | A kind of underground utilities electronic map management system |
US11556710B2 (en) | 2018-05-11 | 2023-01-17 | International Business Machines Corporation | Processing entity groups to generate analytics |
US11036471B2 (en) * | 2018-06-06 | 2021-06-15 | Sap Se | Data grouping for efficient parallel processing |
US11277455B2 (en) | 2018-06-07 | 2022-03-15 | Mellanox Technologies, Ltd. | Streaming system |
US10949219B2 (en) | 2018-06-15 | 2021-03-16 | Sap Se | Containerized runtime environments |
US11275485B2 (en) | 2018-06-15 | 2022-03-15 | Sap Se | Data processing pipeline engine |
US10747506B2 (en) * | 2018-06-15 | 2020-08-18 | Sap Se | Customizing operator nodes for graphical representations of data processing pipelines |
US10866831B2 (en) | 2018-06-15 | 2020-12-15 | Sap Se | Distributed execution of data processing pipelines |
US10733034B2 (en) | 2018-06-15 | 2020-08-04 | Sap Se | Trace messaging for distributed execution of data processing pipelines |
CN109189477B (en) * | 2018-06-27 | 2021-09-28 | 北京中科睿芯科技集团有限公司 | Instruction emission control method oriented to multi-context coarse-grained data stream structure |
US11003686B2 (en) | 2018-07-26 | 2021-05-11 | Roblox Corporation | Addressing data skew using map-reduce |
JP2022500755A (en) * | 2018-09-11 | 2022-01-04 | ホアウェイ・テクノロジーズ・カンパニー・リミテッド | Heterogeneous scheduling for sequential DAG |
US20200106828A1 (en) * | 2018-10-02 | 2020-04-02 | Mellanox Technologies, Ltd. | Parallel Computation Network Device |
US10795672B2 (en) | 2018-10-31 | 2020-10-06 | Oracle International Corporation | Automatic generation of multi-source breadth-first search from high-level graph language for distributed graph processing systems |
US10565038B1 (en) * | 2018-11-27 | 2020-02-18 | Massachusetts Institute Of Technology | Method and apparatus for graph-based computing |
US11379308B2 (en) | 2018-12-10 | 2022-07-05 | Zoox, Inc. | Data processing pipeline failure recovery |
US11625393B2 (en) | 2019-02-19 | 2023-04-11 | Mellanox Technologies, Ltd. | High performance computing system |
EP3699770A1 (en) | 2019-02-25 | 2020-08-26 | Mellanox Technologies TLV Ltd. | Collective communication system and methods |
US10956212B1 (en) * | 2019-03-08 | 2021-03-23 | The Mathworks, Inc. | Scheduler for tall-gathering algorithms that include control flow statements |
US11093223B2 (en) | 2019-07-18 | 2021-08-17 | Ab Initio Technology Llc | Automatically converting a program written in a procedural programming language into a dataflow graph and related systems and methods |
US10826801B1 (en) | 2019-07-31 | 2020-11-03 | Bank Of America Corporation | Multi-level data channel and inspection architectures |
US11115310B2 (en) | 2019-08-06 | 2021-09-07 | Bank Of America Corporation | Multi-level data channel and inspection architectures having data pipes in parallel connections |
US11470046B2 (en) | 2019-08-26 | 2022-10-11 | Bank Of America Corporation | Multi-level data channel and inspection architecture including security-level-based filters for diverting network traffic |
US11461135B2 (en) | 2019-10-25 | 2022-10-04 | International Business Machines Corporation | Dynamically modifying the parallelism of a task in a pipeline |
WO2021137669A1 (en) * | 2019-12-30 | 2021-07-08 | 매니코어소프트주식회사 | Method for generating program for accelerator for deep learning |
CN113126958B (en) * | 2019-12-31 | 2022-07-08 | 思必驰科技股份有限公司 | Decision scheduling customization method and system based on information flow |
US11750699B2 (en) | 2020-01-15 | 2023-09-05 | Mellanox Technologies, Ltd. | Small message aggregation |
US11252027B2 (en) | 2020-01-23 | 2022-02-15 | Mellanox Technologies, Ltd. | Network element supporting flexible data reduction operations |
CN111488888B (en) * | 2020-04-10 | 2022-12-02 | 腾讯科技（深圳）有限公司 | Image feature extraction method and human face feature generation device |
US11876885B2 (en) | 2020-07-02 | 2024-01-16 | Mellanox Technologies, Ltd. | Clock queue with arming and/or self-arming features |
US11848980B2 (en) * | 2020-07-09 | 2023-12-19 | Boray Data Technology Co. Ltd. | Distributed pipeline configuration in a distributed computing system |
US11513991B2 (en) * | 2020-10-01 | 2022-11-29 | Qualcomm Incorporated | Batch operation across an interface |
US11556378B2 (en) | 2020-12-14 | 2023-01-17 | Mellanox Technologies, Ltd. | Offloading execution of a multi-task parameter-dependent operation to a network device |
DE112022000886T5 (en) | 2021-01-31 | 2023-12-21 | Ab Initio Technology Llc | DATA PROCESSING SYSTEM WITH MANIPULATION OF LOGICAL DATA RECORD GROUPS |
US11556452B2 (en) | 2021-03-31 | 2023-01-17 | Bank Of America Corporation | System for software compiler integrity verification |
US11922237B1 (en) | 2022-09-12 | 2024-03-05 | Mellanox Technologies, Ltd. | Single-step collective operations |
Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20080098375A1 (en) * | 2006-09-29 | 2008-04-24 | Microsoft Corporation | Runtime optimization of distributed execution graph |
CN101568900A (en) * | 2006-12-22 | 2009-10-28 | 日本电气株式会社 | Parallel sort device, method, and program |
US20100005080A1 (en) * | 2004-06-18 | 2010-01-07 | Pike Robert C | System and method for analyzing data records |
Family Cites Families (50)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6128642A (en) * | 1997-07-22 | 2000-10-03 | At&T Corporation | Load balancing based on queue length, in a network of processor stations |
US7164422B1 (en) * | 2000-07-28 | 2007-01-16 | Ab Initio Software Corporation | Parameterized graphs with conditional components |
US20070083730A1 (en) | 2003-06-17 | 2007-04-12 | Martin Vorbach | Data processing device and method |
US20080052687A1 (en) * | 2003-11-03 | 2008-02-28 | Agustin Gonzales-Tuchmann | Development environment for data transformation applications |
US7389510B2 (en) * | 2003-11-06 | 2008-06-17 | International Business Machines Corporation | Load balancing of servers in a cluster |
US7650331B1 (en) | 2004-06-18 | 2010-01-19 | Google Inc. | System and method for efficient large-scale data processing |
US7756919B1 (en) * | 2004-06-18 | 2010-07-13 | Google Inc. | Large-scale data processing in a distributed and parallel processing enviornment |
JP4275013B2 (en) * | 2004-06-21 | 2009-06-10 | 三洋電機株式会社 | Data flow graph processing device, processing device, reconfigurable circuit. |
EP1811387A4 (en) | 2004-08-25 | 2016-04-13 | Nec Corp | Information communication device, and program execution environment control method |
US7941794B2 (en) * | 2004-08-30 | 2011-05-10 | Sanyo Electric Co., Ltd. | Data flow graph processing method and processing apparatus provided with reconfigurable circuit |
US20090217020A1 (en) * | 2004-11-22 | 2009-08-27 | Yourst Matt T | Commit Groups for Strand-Based Computing |
WO2006134691A1 (en) | 2005-06-17 | 2006-12-21 | Nec Corporation | Information processing device, restoration device, program and restoration method |
US7716630B2 (en) * | 2005-06-27 | 2010-05-11 | Ab Initio Technology Llc | Managing parameters for graph-based computations |
US7739314B2 (en) | 2005-08-15 | 2010-06-15 | Google Inc. | Scalable user clustering based on set similarity |
GB0517304D0 (en) * | 2005-08-23 | 2005-10-05 | Netronome Systems Inc | A system and method for processing and forwarding transmitted information |
US20070083735A1 (en) * | 2005-08-29 | 2007-04-12 | Glew Andrew F | Hierarchical processor |
US8429630B2 (en) * | 2005-09-15 | 2013-04-23 | Ca, Inc. | Globally distributed utility computing cloud |
US7870556B2 (en) * | 2006-05-16 | 2011-01-11 | Ab Initio Technology Llc | Managing computing resources in graph-based computations |
JP4770657B2 (en) * | 2006-09-13 | 2011-09-14 | 日本電気株式会社 | Pipeline synthesis system, method and program |
US8190610B2 (en) * | 2006-10-05 | 2012-05-29 | Yahoo! Inc. | MapReduce for distributed database processing |
US7921416B2 (en) * | 2006-10-20 | 2011-04-05 | Yahoo! Inc. | Formal language and translator for parallel processing of data |
US20080250227A1 (en) | 2007-04-04 | 2008-10-09 | Linderman Michael D | General Purpose Multiprocessor Programming Apparatus And Method |
US8296743B2 (en) * | 2007-12-17 | 2012-10-23 | Intel Corporation | Compiler and runtime for heterogeneous multiprocessor systems |
US8537160B2 (en) | 2008-03-05 | 2013-09-17 | Microsoft Corporation | Generating distributed dataflow graphs |
US9058483B2 (en) | 2008-05-08 | 2015-06-16 | Google Inc. | Method for validating an untrusted native code module |
JP5056644B2 (en) | 2008-07-18 | 2012-10-24 | 富士通セミコンダクター株式会社 | Data conversion apparatus, data conversion method and program |
JP4635082B2 (en) * | 2008-09-30 | 2011-02-16 | 株式会社東芝 | Multiprocessor system and grouping method |
US7917463B2 (en) * | 2008-10-10 | 2011-03-29 | Business.Com, Inc. | System and method for data warehousing and analytics on a distributed file system |
US20100162230A1 (en) | 2008-12-24 | 2010-06-24 | Yahoo! Inc. | Distributed computing system for large-scale data handling |
US20100175049A1 (en) | 2009-01-07 | 2010-07-08 | Microsoft Corporation | Scope: a structured computations optimized for parallel execution script language |
US8225277B2 (en) * | 2009-01-31 | 2012-07-17 | Ted J. Biggerstaff | Non-localized constraints for automated program generation |
US9110706B2 (en) * | 2009-02-09 | 2015-08-18 | Microsoft Technology Licensing, Llc | General purpose distributed data parallel computing using a high level language |
US8239847B2 (en) * | 2009-03-18 | 2012-08-07 | Microsoft Corporation | General distributed reduction for data parallel computing |
US8209664B2 (en) * | 2009-03-18 | 2012-06-26 | Microsoft Corporation | High level programming extensions for distributed data parallel processing |
US20100281078A1 (en) | 2009-04-30 | 2010-11-04 | Microsoft Corporation | Distributed data reorganization for parallel execution engines |
US9733914B2 (en) * | 2009-06-01 | 2017-08-15 | National Instruments Corporation | Loop parallelization analyzer for data flow programs |
US8478967B2 (en) * | 2009-06-01 | 2013-07-02 | National Instruments Corporation | Automatically creating parallel iterative program code in a data flow program |
US8365142B2 (en) * | 2009-06-15 | 2013-01-29 | Microsoft Corporation | Hypergraph implementation |
US9268815B2 (en) * | 2009-08-20 | 2016-02-23 | Hewlett Packard Enterprise Development Lp | Map-reduce and parallel processing in databases |
US8572575B2 (en) * | 2009-09-14 | 2013-10-29 | Myspace Llc | Debugging a map reduce application on a cluster |
US8555265B2 (en) | 2010-05-04 | 2013-10-08 | Google Inc. | Parallel processing of data |
US8583757B2 (en) * | 2010-05-31 | 2013-11-12 | Hitachi, Ltd. | Data processing method and computer system |
US8381015B2 (en) * | 2010-06-30 | 2013-02-19 | International Business Machines Corporation | Fault tolerance for map/reduce computing |
US8510284B2 (en) * | 2010-12-20 | 2013-08-13 | Microsoft Corporation | Large-scale event evaluation using realtime processors |
US8751639B2 (en) * | 2011-04-27 | 2014-06-10 | Rackspace Us, Inc. | Event queuing and distribution system |
US9450873B2 (en) * | 2011-06-28 | 2016-09-20 | Microsoft Technology Licensing, Llc | Performance isolation for clouds |
US9542462B1 (en) * | 2012-06-14 | 2017-01-10 | Google Inc. | Scaling high-level statistical languages to large, distributed datasets |
US9454571B2 (en) * | 2014-06-26 | 2016-09-27 | Sap Se | Optimization of parallelization of user-defined functions with flexible partitioning |
US9350384B2 (en) * | 2014-09-30 | 2016-05-24 | International Business Machines Corporation | Hierarchical data compression and computation |
US10417239B2 (en) * | 2017-01-13 | 2019-09-17 | International Business Machines Corporation | Reducing flow delays in a data streaming application caused by lookup operations |
-
2010
- 2010-06-04 US US12/794,348 patent/US8555265B2/en active Active
- 2010-12-02 US US12/959,022 patent/US8887156B2/en active Active
-
2011
- 2011-05-04 WO PCT/US2011/035159 patent/WO2011140201A1/en active Application Filing
- 2011-05-04 KR KR1020187018715A patent/KR101904526B1/en active IP Right Grant
- 2011-05-04 DE DE202011110864.7U patent/DE202011110864U1/en not_active Expired - Lifetime
- 2011-05-04 KR KR1020127031681A patent/KR101870320B1/en active IP Right Grant
- 2011-05-04 CA CA2798266A patent/CA2798266C/en active Active
- 2011-05-04 CN CN201180032739.5A patent/CN103109260B/en active Active
- 2011-05-04 CA CA3014814A patent/CA3014814C/en active Active
- 2011-05-04 KR KR1020177020753A patent/KR101875178B1/en active IP Right Grant
- 2011-05-04 EP EP11778249.0A patent/EP2567313B1/en active Active
- 2011-05-04 CN CN201510772809.0A patent/CN105279022B/en active Active
-
2013
- 2013-09-20 US US14/033,145 patent/US8959499B2/en active Active
-
2014
- 2014-10-30 US US14/528,908 patent/US9477502B2/en active Active
-
2015
- 2015-02-13 US US14/622,556 patent/US9626202B2/en active Active
-
2016
- 2016-09-28 US US15/278,392 patent/US9678770B2/en active Active
-
2017
- 2017-04-10 US US15/483,044 patent/US10133592B2/en active Active
- 2017-05-17 US US15/597,564 patent/US9898313B2/en active Active
-
2018
- 2018-10-31 US US16/175,925 patent/US10338942B2/en active Active
-
2019
- 2019-06-24 US US16/449,987 patent/US10795705B2/en active Active
-
2020
- 2020-09-01 US US17/009,420 patent/US11392398B2/en active Active
-
2022
- 2022-06-07 US US17/834,256 patent/US11755351B2/en active Active
-
2023
- 2023-08-02 US US18/229,450 patent/US20230376332A1/en active Pending
Patent Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20100005080A1 (en) * | 2004-06-18 | 2010-01-07 | Pike Robert C | System and method for analyzing data records |
US20080098375A1 (en) * | 2006-09-29 | 2008-04-24 | Microsoft Corporation | Runtime optimization of distributed execution graph |
CN101568900A (en) * | 2006-12-22 | 2009-10-28 | 日本电气株式会社 | Parallel sort device, method, and program |
Cited By (14)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN103678235B (en) * | 2013-12-09 | 2016-06-08 | 无锡市同威科技有限公司 | Based on parallel pipeline network data processing device and method |
CN103678235A (en) * | 2013-12-09 | 2014-03-26 | 无锡市同威科技有限公司 | Network data processing device and method based on parallel flow lines |
CN111158693B (en) * | 2014-04-01 | 2023-11-14 | 谷歌有限责任公司 | Incremental parallel processing of data |
CN111158693A (en) * | 2014-04-01 | 2020-05-15 | 谷歌有限责任公司 | Incremental parallel processing of data |
CN106687921B (en) * | 2014-09-02 | 2021-02-02 | 起元科技有限公司 | Specifying components in graph-based programs |
CN106687921A (en) * | 2014-09-02 | 2017-05-17 | 起元科技有限公司 | Specifying components in graph-based programs |
US11301445B2 (en) | 2014-09-02 | 2022-04-12 | Ab Initio Technology Llc | Compiling graph-based program specifications |
US10885003B2 (en) | 2014-09-02 | 2021-01-05 | Ab Initio Technology Llc | Compiling graph-based program specifications |
US10896025B2 (en) | 2014-09-02 | 2021-01-19 | Ab Initio Technology Llc | Specifying components in graph-based programs |
CN107688493A (en) * | 2016-08-05 | 2018-02-13 | 阿里巴巴集团控股有限公司 | Train the method, apparatus and system of deep neural network |
CN107832144B (en) * | 2017-10-20 | 2020-07-28 | 南方电网科学研究院有限责任公司 | Distributed parallel computing method and device |
CN107832144A (en) * | 2017-10-20 | 2018-03-23 | 南方电网科学研究院有限责任公司 | Distributed Parallel Computing method and apparatus |
CN114579190A (en) * | 2022-02-17 | 2022-06-03 | 中国科学院计算机网络信息中心 | Cross-center cooperative computing arrangement method and system based on pipeline mechanism |
CN114579190B (en) * | 2022-02-17 | 2022-10-14 | 中国科学院计算机网络信息中心 | Cross-center cooperative computing arrangement method and system based on pipeline mechanism |
Also Published As
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN103109260B (en) | The parallel processing of data | |
Zhou et al. | An agent composition framework for the J-Park Simulator-A knowledge graph for the process industry | |
Colomer-Cugat et al. | Membrane system-based models for specifying Dynamical Population systems | |
Cople et al. | A simulation framework for technical systems life cycle cost analysis | |
Liles | On the characterization and analysis of system of systems architectures | |
Dossou et al. | The use of Multi-agent Systems for Improving a Logistic Platform in a GRAI Environment | |
Kukla | Interoperability of heterogeneous large-scale scientific workflows and data resources | |
Uchibayashi et al. | Towards a validation framework for sub-ontology extraction workflows in a semantic grid |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
C06 | Publication | ||
PB01 | Publication | ||
C10 | Entry into substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
C14 | Grant of patent or utility model | ||
GR01 | Patent grant | ||
CP01 | Change in the name or title of a patent holder | ||
CP01 | Change in the name or title of a patent holder |
Address after: American CaliforniaPatentee after: Google limited liability companyAddress before: American CaliforniaPatentee before: Google Inc. |