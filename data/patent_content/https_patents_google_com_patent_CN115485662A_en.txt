CN115485662A - Quota request resolution on a computing platform - Google Patents
Quota request resolution on a computing platform Download PDFInfo
- Publication number
- CN115485662A CN115485662A CN202180028013.8A CN202180028013A CN115485662A CN 115485662 A CN115485662 A CN 115485662A CN 202180028013 A CN202180028013 A CN 202180028013A CN 115485662 A CN115485662 A CN 115485662A
- Authority
- CN
- China
- Prior art keywords
- user
- platform
- score
- quota
- computing resources
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/46—Multiprogramming arrangements
- G06F9/50—Allocation of resources, e.g. of the central processing unit [CPU]
- G06F9/5005—Allocation of resources, e.g. of the central processing unit [CPU] to service a request
- G06F9/5011—Allocation of resources, e.g. of the central processing unit [CPU] to service a request the resources being hardware resources other than CPUs, Servers and Terminals
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/46—Multiprogramming arrangements
- G06F9/50—Allocation of resources, e.g. of the central processing unit [CPU]
- G06F9/5005—Allocation of resources, e.g. of the central processing unit [CPU] to service a request
- G06F9/5027—Allocation of resources, e.g. of the central processing unit [CPU] to service a request the resource being a machine, e.g. CPUs, Servers, Terminals
Abstract
Systems, methods, and apparatuses, including non-transitory computer-readable media, for performing quota resolution on a cloud computing platform are disclosed. A system can receive user account data from one or more user accounts representing a first user. The system can generate, from the user account data, a plurality of features characterizing interaction between the first user and the computing platform. In accordance with at least a number of features, the system can generate a score that represents, at least in part, a predicted likelihood that the additional computing resources allocated to the first user account will be used in violation of one or more predetermined abusive usage parameters during a predetermined future time period.
Description
Cross Reference to Related Applications
This application is a continuation of U.S. patent application Ser. No.17/382,973, filed on 22/7/2021, which claims benefit of the filing date of U.S. provisional patent application Ser. No.63/106,177, filed on 27/10/2020, the disclosure of which is incorporated herein by reference.
Background
A cloud computing platform is a computer system maintained by a host computer for providing computing resources and services to one or more users. The platform can allocate different amounts of computing resources to users, who can then use the allocated resources for performing tasks, such as hosting their own services and software applications on the allocated resources.
The platform can provide its own suite of services to assist users in their own application or service development, sometimes at a monetary cost. Cloud computing platforms can provide computing resources that may otherwise be prohibitively expensive for users to purchase and directly maintain. The platform is capable of providing a series of abstractions between the hardware of the platform and the platform users. The abstraction of the users of the platform can come in different forms, such as in the form of Infrastructure As A Service (IAAS), platform As A Service (PAAS) or Software As A Service (SAAS) paradigms.
To facilitate fair and proportional allocation of available computing resources, cloud computing platforms can implement quota resolution systems for setting, enforcing, and adjusting quotas for users of the platform. The quota can represent an upper limit on the amount of computing resources a user can request and use from the platform at a given time.
The quota resolving system can include one or more processes for receiving requests from users who wish to increase their quota, thereby allowing users to increase their allocation of computing resources on the platform. One problem that may occur is that a user may request a computing resource (either as an initial request or a request for additional allocation) and then use the computing resource in a manner that violates agreed conditions on resource usage between the user and the platform.
For users with little history of interacting with the platform, it may be difficult to automate the quota resolving system to accurately approve or deny requests for quota increases. Moreover, false positives (i.e., rejecting quota requests to users that would otherwise use additional resources in a compliant and efficient manner) are particularly detrimental to the user experience and efficient utilization of computing resources. For example, more accurate quota resolution has the following effects: the services that cause doxxing, perform denial of service attacks, or infect computers with malware will be prevented from allocating additional resources, thus making the operation of the platform and other computing systems in the network more secure. In this way, the accessibility of the platform can be maintained for users that are not running such services, and will be prevented from being taken up by services that cause doxxing, perform denial of service attacks, or infect computers with malware. In contrast, manual inspection of quota requests by human operators can result in fewer false positives, but manual approaches are not feasible for large platforms that may serve tens of thousands of users concurrently.
Furthermore, heuristic or rule-based methods for quota request resolution (e.g., scorecard methods) also do not accurately resolve quota requests. At least because these methods typically rely on a small set of (typically) manually tuned parameters obtained from user account data.
Disclosure of Invention
The present application relates to a quota resolution system for resolving quota requests for computing resources on a cloud computing platform. According to some aspects of the present disclosure, the quota resolving system is able to accurately predict future behavior of users whose interactions with the platform are represented by one or more user accounts. The quota resolving system is able to predict a likelihood that a user will abuse a computing resource by performing activities prohibited on the platform for a future period of time given the additional computing resource. In response, the quota resolving system can resolve the quota request from the user by granting or denying. In some implementations, the quota resolving system can allocate additional computing resources that the quota resolving system predicts will be needed by the user but not yet requested. In this way, the provisioning of resources for the user can be accelerated. By resolving quota requests as described herein, a platform can operate more efficiently in providing infrastructure, software support, or other services to its users. The prohibited platform activities can include any activity that reduces the computing resources of the platform that would otherwise be available to users to service their requests and/or extend their operations on the platform as needed.
The quota resolving system is capable of obtaining data from a wide variety of sources for the cloud computing platform and designing features that are believed to be most relevant to determining the likelihood that a platform user will abuse the additional computing resources allocated to the platform user. The designed features can characterize platform user interactions with the platform across multiple user accounts. A single platform user may be represented by multiple accounts because the platform provides many specialized services. The quota resolution system is capable of handling different features from different accounts representing platform user's activities, such as financial transactions, virtual machine usage, and project management of projects hosted on the platform.
The quota resolving system can implement one or more machine learning models trained to predict the likelihood of future abuse of additional computing resources by platform users. The system is further capable of offsetting the likelihood based on one or more other indicators found to be relevant to the final prediction of abuse.
The quota resolving system is capable of training and retraining a quota score that is trained to generate a model that represents a likelihood that a platform user will abuse additional computing resources. The system can automatically generate new training data from the platform to further train the system to detect abusive behavior even if the behavior pattern transitions over time. The system can evaluate its own performance in terms of various different metrics and retrain itself to more accurately predict abuse by focusing on common characteristics of different sub-populations of the cloud platform user base.
The quota resolving system can use data that is critical to the misuse of the platform's users in conjunction with many other signals. In other words, the quota resolving system does not merely leverage existing systems within the platform to monitor and penalize users that are found to have abused the system.
In general, one innovative aspect of the subject matter described in this specification provides a system that includes a computing platform including multiple processors and one or more storage devices storing instructions that are operable, when executed by the multiple processors, to cause the multiple processors to perform operations. The operations include allocating up to a first quota of computing resources to a first user account of one or more user accounts representing a first user of the computing platform, wherein the first quota is an upper limit of computing resources allocated to the first user account. The operations include receiving user account data from one or more user accounts representing a first user. The operation comprises the following steps: generating a plurality of features from the user account data, wherein each feature is a measurable representation of an interaction between one or more user accounts and the computing platform; and generating a score at least partially representing a predicted likelihood that the additional computing resources allocated to the first user account will be used in violation of the one or more predetermined abusive usage parameters during the predetermined future time period based at least on the plurality of features.
Generating the score can include: generating a higher score in response to a lower predicted likelihood that the predetermined abusive use parameter will be violated using the additional computing resources; and generating a lower score in response to a higher predicted likelihood that the predetermined abusive use parameter will be violated to use the additional computing resources.
The operations can further include: determining that the generated score does meet a predetermined threshold representing a minimum score for allocating additional computing resources that exceed the respective quota of the user account; and in response to determining that the generated score satisfies a predetermined threshold, allocating additional computing resources to the first user account and updating the first quota.
Generating the score can include generating the score using one or more machine learning models trained to generate the score from the plurality of features. The operations can further include: determining, by the system, that the score does not satisfy a plurality of evaluation criteria; and in response to determining that the score does not satisfy the plurality of evaluation criteria, retraining the one or more machine learning models trained to generate the score according to the plurality of features.
The user account data can be first user account data received at a first time and the generated score is a first score. The operations can further include generating labeled user account data and retraining one or more machine learning models on the labeled user account data. Generating the marked user account data can include: receiving second user account data generated at a second time that is prior to the first time and that is separated by a length of time that is equal to or greater than the length of the predetermined future time period, and tagging the second user account data with a second score generated using the second account data after expiration of the future time period relative to the second time.
Generating the plurality of features can include: generating a graph representing one or more user accounts; and generating a first feature of the plurality of features from one or more other features of the plurality of features of the one or more user accounts in the graph.
The user account data can include data characterizing computing resource usage on the computing platform by the first user through one or more user accounts. The operations can include determining that the first user requires additional computing resources. Determining can include processing data characterizing computing resource usage of the first user by one or more machine learning models trained to receive data characterizing computing resource usage and to predict a measure of additional computing resources needed to exceed the first quota during the predetermined future time period.
Allocating the additional computing resources to the first user can include: the method includes predicting a first time at which the first user will require additional computing usage and allocating additional computing resources prior to the first time.
The operations can further include determining a quantitative metric of additional computing resources to allocate to the first user based on the data characterizing the computing resource usage.
The predicted likelihood can be a predicted abuse likelihood, and the operations can further include maintaining a resource allocation service for allocating additional computing resources of the computing platform in response to the user request and payment. Generating the score can include: the method also includes generating a predicted revenue likelihood that the computing platform will receive a first request to allocate additional computing resources and a first payment from one of the one or more user accounts within a predetermined future time period, and generating the score as a function that includes the predicted revenue likelihood and the predicted abuse likelihood.
Generating the score can include generating the score according to: f (x) T ，a T )＝act(x T )+a T *(act(x T ) -1), wherein T is a predetermined future time period, x T Is a prediction of revenue probability, a T Is the predicted abuse potential, and act (-) is a non-linear function ranging between-1 to 1. The non-linear function can be one of a logistic function, a hyperbolic tangent function, and a modified linear unit function.
Generating the predicted likelihood can include generating the predicted likelihood in response to a request for additional computing resources from the first user account.
The operations can further include executing, by the computing platform, a plurality of applications hosted on one or more of the plurality of computers. The one or more user accounts can include one or more of: an application account including data corresponding to a first user for interacting with one or more applications of the plurality of applications, and a billing account including data corresponding to billing activity between the first user and the one or more applications of the plurality of applications.
The computing resources allocated to the first user can include computing resources configured to execute one or more virtual machines. The one or more user accounts can include a virtual machine entity that includes data corresponding to virtual machine creation and use on the computing platform by the first user.
The operations can further include one or more software items hosted on the computing platform by the computing platform. The one or more user accounts can include a project entity that includes data corresponding to one or more projects authored or co-authored by the first user.
The first quota can represent one or both of: an upper limit on computing resources to be allocated to the first user, and an upper limit on a number of concurrent projects hosted on the computing platform and authored or co-authored by the first user.
The operations can include sending, to a first user device associated with a first user, an indication that additional computing resources have been allocated to the first user.
Other embodiments of the foregoing aspects can include a computer-implemented method, apparatus, and computer program recorded on one or more computer-readable storage media, for execution on a computing device.
Drawings
Fig. 1 is a diagram of a quota resolution system implemented on a cloud computing platform.
FIG. 2 is a diagram illustrating an example embodiment of a quota resolving system.
FIG. 3 is a diagram representing an example mapping of user accounts for different platform users.
FIG. 4 is a flow diagram illustrating an example process for resolving a quota request using a quota resolving system.
FIG. 5 is a flow diagram illustrating an example process for allocating additional computing resources prior to receiving a quota request from a first user.
Like reference symbols in the various drawings indicate like elements.
Detailed Description
Fig. 1 is a diagram of a quota resolving system 100 implemented on a cloud computing platform 110. The cloud computing platform 110 can include one or more server computing devices 115, one or more storage devices 150, and one or more user computing devices 120. For ease of description, processes and systems according to some aspects of the present disclosure will be described as if implemented on a single server computing device 115 or user computing device 120, but some or all of the components of system 100 can be implemented across different computing devices in one or more physical locations.
The server computing device 115 can include one or more processors 112 and memory 114. The memory 114 can include instructions 116 and data 118. The instructions are one or more instructions written in a computer programming language that, when executed by the server computing device 115, cause the server computing device 115 to perform one or more actions. The data 118 can include data retrieved, processed, or generated by the server computing device 115 as part of one or more actions performed by the server computing device 115 when executing the instructions 116. Separately or as part of the instructions 116, the memory 114 can include instructions and data structures that, when executed by the server computing device 115, cause the server computing device 115 to implement the quota resolving system 100 according to some aspects of the present disclosure.
The user computing device 120 can also include one or more processors 113, memory 131 storing instructions 117 and data 119. The user computing device 120 can additionally include a display 122 and user inputs 124, such as a touch screen or keyboard and mouse. The processors of the devices 115, 120 can be a combination of any type of processor, such as a central processing unit ("CPU"), a graphics processing unit ("GPU"), or an application specific integrated circuit ("ASIC"). The memory of the devices 115, 120 can also be any combination of types (e.g., volatile or non-volatile, including RAM, solid state memory, or hard disk).
The server computing device 115 and the user computing device 120 can communicate over the network 160 according to any communication protocol. The network 160 can be a local area network or a wide area network, or the internet itself. The devices 115, 120 may be capable of communicating according to any communication protocol, such as SHH, HTTP (S), or FTP. The cloud computing platform 110 can also include one or more storage devices 150 communicatively coupled to the devices 115, 120 over a network 160. The storage device(s) 150 are capable of storing data generated by user activity on the platform 110.
The cloud computing platform 110 can perform various functions corresponding to any number of services that can be generally grouped according to different paradigms (e.g., iaaS, saaS, and PaaS). The platform 110 can host and maintain a variety of different services that perform tasks on computing resources (e.g., the server computing device(s) 115 and the storage device 150).
Computing resources refer to processors, storage devices, and applications running on them as part of computing platform 110. Computing resources can also refer to the number and/or quality of network connections to and from server computing device 115 and user computing device 120 over network 160. The computing resources can be quantified in different manners, such as by some selected number of clock cycles of the processor, a period of time to use the processor and/or storage of the platform, or generally unrestricted access to the computing resources at a throttled processing/bandwidth rate.
The platform 110 can host dedicated hardware, e.g., an ASIC such as a tensor processing unit ("TPU"), and can receive data and processing parameters from the user computing device 120 to process the received data on the dedicated hardware according to the processing parameters. The platform 110 is capable of hosting at least a portion of the storage capacity of the storage device 150 for the platform user to store data thereon. Similarly, the platform 110 can establish one or more virtual machines or other forms of abstraction between the user computing device 120 and the server computing device 115 to allow a user of the user computing device 120 to access and use the computing resources of the platform 110 through the virtual machines.
The platform 110 can also facilitate one or more services for allowing users of the user computing devices 120 to run and maintain their own services. For example, a platform user of the user computing device 120 may run their own services for one or more secondary users (i.e., users of the platform user's services). The secondary users can include platform users of the platform 110. The services can be hosted on computing resources allocated to platform users, and secondary users can interact with the services hosted on the cloud computing platform 110.
The platform 110 can also host one or more projects authored or co-authored by platform users. The items can be software programming items having source code that can be stored and executed by the platform 110. The user computing device 120 can display an interface through which a platform user can write source code that is automatically saved and executed by the platform 110 using the user input 124. The platform 110 can provide a plurality of application programming interfaces ("APIs") that can define interfaces for the user computing devices 120 to communicate with services hosted by the server computing devices 115. For example, the platform may host APIs related to training and processing machine learning models using data stored on the platform 110. The platform user can invoke one or more function calls defined in the corresponding API using source code provided to the platform 110 by the user computing device 120. Further, when executing user source code, the platform 110 can automatically execute services invoked through one or more function calls according to different parameter values specified in the call.
The platform 110 can be maintained by an individual or organization (e.g., an organization or one or more individuals distinct from the platform users of the platform 110). The platform user can also be one or more individuals or an organization of individuals, such as a software development company. A platform user can also be software or hardware that automatically interacts with the platform 110 through one or more user accounts. The platform 110 is configured to provide services to platform users for free or a fee. The platform 110 may provide a wider range of services relative to monetary costs. Platform users can pay the platform 110 for these services, which can include greater storage capacity, access to increased processing power, or additional features for basic services that are available at no charge on the platform 110.
The platform users are represented on the platform 110 as one or more user accounts. A user account is a data structure representing data collected by a platform relating to one or more platform users. The represented data can be or can include data entities generated by the platform 110, the platform 110 being implemented in hardware or software and storing information related to interactions between platform users and the platform 110. In some implementations, the accounts and entities are different in that the user account can additionally maintain profile settings and preferences that can be modified by the platform user, for example, through a user interface to the platform 110. In contrast, an entity can be a data structure internal to the platform 110 and representing one or more platform users, but not modified directly by the platform users through the user interface.
The platform user interacts with the platform 110 through one or more interfaces, for example using the user computing device 120, and the platform 110 updates the user account in response to different actions performed by the platform user. The platform 110 can also track other data related to the platform user, such as metadata indicating when and where the platform user last accessed the platform or related applications or services. The server computing device 115 can perform an account creation process in which a platform user enters information such as an email address and password through the user computing device 120. In response to receiving the requested information, the platform 110 can establish one or more user accounts to represent the platform users.
The platform 110 is capable of establishing multiple user accounts representing platform users depending on the manner in which the platform users interact with the platform 110. One reason the platform 110 is able to establish multiple user accounts is because different users can be represented by the same account.
One example of one type of user account is a platform account. The platform account typically represents a single user and can represent general information such as the time of account creation, the time period since the platform user last logged into the platform 110, or the location (e.g., network address) from which the platform user logged into the platform 110. In some implementations, the platform 110 creates the platform account when the account is created by the platform user, and then later creates and associates other types of accounts with the platform account when needed. For example, if a platform user creates a platform account for the first time and then creates a new software project to run on the platform 110, the platform 110 can create a new project account that represents the platform user's activities with respect to project management.
A platform account can include project entities that represent different projects authored or coauthored by a platform user represented by the account and hosted on the platform 110. In this manner, a platform user can manage projects mapped to a particular project entity in conjunction with other platform users. The project entity can be a data structure implemented in software or hardware and includes data representing different aspects of an authored or coauthored project. In some implementations, the platform user (and potentially other platform users) are additionally represented by a project account that maintains project entities related to projects authored or co-authored by the platform user and potentially one or more other users. The project account can represent metadata corresponding to different projects, as well as track changes to the project, such as creation, modification, or deletion of the project.
The platform account can include a virtual machine entity that represents information about virtual machines running on the platform 110 that are accessible to platform users. The virtual machine entity can be a data structure implemented in software or hardware and represents one or more virtual machines and platform users that have permission to use or modify the virtual machines. The virtual machine entity can also track usage data related to the represented virtual machines, such as the number of virtual machines, the virtualized computing resources, and the usage to idle time ratio. In some embodiments, the virtual machine entity is represented at least in part by an item entity, e.g., as a sub-entity.
In some embodiments, a platform user (and potentially other platform users) is represented by a virtual machine account that maintains data related to virtual machines that the platform user has access to. The virtual machine account can represent metadata corresponding to different virtual machines, as well as track changes to the virtual machines, such as changes to resource allocations or user settings of various virtual machines.
Another example of an account type is a billing account. The billing account generally represents financial transactions and billing activities between the platform user and the platform 110. The billing account can maintain data corresponding to the platform user's available monetary funds represented by the billing account on the platform 110. For example, the platform 110 can run a subscription service for a suite of different applications hosted on the platform 110. A platform user can subscribe to one or more applications. Billing and financial transactions between the platform user and the platform 110 for the subscription application can be represented by corresponding billing accounts. As in the project entity or virtual machine entity described above, the billing account may be shared by multiple platform users. In some embodiments, the platform 110 maintains billing information for billing accounts as described above, but as an entity that represents billing activity of one or more platform users through the respective platform account.
Another example of a user account type is an application account. The application accounts can represent information related to platform user interactions with available services or applications of the platform 110. For example, a platform user can submit a request to process data to an existing application that is run and hosted by the platform 110. One example of such an application is a machine learning application that receives data from the user computing device 120 as submitted by a platform user, and generates analytics and insights from the data for viewing by the platform user. The analysis can include ways to improve the industrial process represented by the input data, such as improving supply chain management, protecting customer data, or deploying telecommunication infrastructure. The application account can include data representing the nature or status of these requests, as well as the results of data processed from previous requests. In some embodiments, the data represented by the application accounts can be stored on the platform 110 as entities representing application activities of one or more platform users through respective platform accounts, as described above with reference to the project and billing entities.
From the perspective of the platform user, the platform user is able to log into the platform 110 and interact with the platform 110 using a single account (e.g., a platform account). The interface between the server computing device 115 and the user computing device 120 is capable of handling individual account updates when the platform user switches activity during a session with the platform 110. For example, a platform user can perform actions related to logging in, managing billing activities, and managing items without having to switch user accounts.
In some implementations, the platform 110 maintains a combination of different user accounts to facilitate organization of the platform 110 and different services provided. In some implementations, platform users are represented by a single platform account, and the platform accounts represent different entities corresponding to a service, such as applications, billing, projects, and virtual machines. In some embodiments, different entities are managed as different accounts or sub-accounts that are managed directly or indirectly by platform users through platform accounts. As described above, the platform 110 may manage different entities in this manner to facilitate organization, but also as a technique for managing entities representing interactions between the platform 110 and multiple platform users.
In some implementations, the platform 110 can manage user authentication as a service that requires user credentials corresponding to a platform account of a platform user. After successful authentication, the platform 110 can automatically and in response to user activity switch between accounts without additional authentication. However, in some implementations, the platform 110 may require additional authentication to perform certain actions in response to user input, for example, when a platform user requests funds available for use of a representative billing account.
Because many (e.g., thousands or tens of thousands) of platform users can request and use the computing resources of platform 110 at the same time, platform 110 maintains quotas associated with one or more user accounts that represent platform users on platform 110. Quotas represent an upper limit on the amount of computing resources or services available to platform users. The platform 110 may enforce quotas on different platform users to maintain platform accessibility and prevent resource occupation of a relatively small percentage of the user pool.
Quotas can represent upper limits in various ways. For example, the quota can be a rate quota, representing the number of API requests that a platform user can make to platform 110 in a given day, or the total amount of data that can be requested through an API call. Additionally or alternatively, the quota can be an allocated quota that limits the number of virtual machines or load balancers that a service or item authored or coauthored by a platform user can use concurrently or over a period of time. Additionally or alternatively, the quota can be a storage quota that limits the amount of data storage that a platform user can access. The quota can also be an upper limit on the amount of one or more particular types of hardware that can be allocated to a platform user account, e.g., the total number of CPUs or GPUs.
At account creation time, platform 110 can set the quota of the platform user to a predetermined value, e.g., 1 terabyte storage quota, 100 API requests per day, etc. Although the quota represents an upper limit, platform users may not use or have the allocated computing resources to satisfy the quota. For example, a platform user may have a storage quota of 1 terabyte of data storage, but only 500 gigabytes of storage have been allocated.
As the computing demands of platform users increase over time, the platform users may wish to request additional allocations of computing resources. Typically, platform users can request additional allocations up to their quota from the platform 110, e.g., through a platform account and an interface displayed on the user computing device 120. In the previous example, a platform user whose allocation of data storage is 500 gigabytes can request to increase its allocation to its quota of 1 terabyte. In some implementations, the platform 110 automatically matches the computing resource allocations of platform users to their quotas.
The platform 110 can receive a request for additional computing resources beyond the quota set for the requesting platform user, for example, through a request sent by the platform account of the platform user. As described in more detail below with reference to fig. 2, the quota resolving system 100 is configured to receive requests and user account data for one or more user accounts representing platform users on the platform 110, and to automatically resolve the requests. Resolving the quota request means processing the quota request from a platform user account or on behalf of a platform user and making a decision as to whether to approve the request.
If the request is granted, the platform 110 can allocate additional computing resources to the platform user according to the request and can increase the quota. If the system 100 denies the request, the platform 110 is configured to send an indication to the platform user, for example, by displaying a notification on the display 122 of the user computing device 120 that the request was denied.
As described below with reference to fig. 2, the quota resolving system 100 is configured to resolve requests by predicting the likelihood that a platform user will abuse additional computing resources given the additional computing resources. Abuse in this specification refers to a platform user violating one or more abusive usage parameters of the cloud computing platform 110. The abuse usage parameter represents a prohibited and restricted manner of usage of the computing platform 110 by a platform user. The abuse usage parameters are predetermined and can vary depending on the implementation. The abuse usage parameter can define a limit or illegal activity that prohibits the platform user from performing using the allocated computing resources. When a prohibited or limited activity is performed as defined by an abusive use parameter, the platform user is said to violate the abusive use parameter.
For example, the abuse usage parameter can specify that a platform user cannot use the allocated computing resources to host copyrighted material. Other examples of platform abuse include using the platform to conduct or facilitate illegal activities, such as hosting services for doxxing, performing denial of service attacks, or infecting a computer with malware. The abuse usage parameter can also specify prohibited activities that may not be illegal per se but are prohibited from operating on the platform 110 for one reason or another (e.g., data capture or cryptographic currency mining).
Abuse usage parameters can also limit the platform 110 from being used for mass-hosting (hosting) or other forms of automation that disrupt other services or websites, such as selling at a greatly expanded price by purchasing a large number of salvaged products at release. The abuse usage parameters can also include parameters for specifying efficient use of allocated computing resources, e.g., virtual machines allocated to platform users are not allowed to remain idle for more than a predetermined period of time. In some implementations, the platform user can receive abuse usage parameters through terms and conditional agreements sent by the platform 110 to the platform user during account creation.
In these and other examples of platform abuse, computing resources are typically reduced or made inaccessible, which would otherwise be available to users on the platform 110. For example, a user requesting an increased quota allocation to extend their operations on platform 110 may be prevented or limited in doing so because existing computing resources are allocated to other users that violate abusive usage parameters of platform 110. If the requesting user is hosting an application on the platform 110 that cannot be expanded to meet the demand, the quality of the application degrades, for example, because it cannot service or timely service queries or requests from computing devices in communication with the application.
Fig. 2 is a diagram illustrating an example implementation of quota resolving system 100. The quota resolving system 100 can include a data orchestration module 205, a data tagging module 210, a feature design module 215, a score-service model 220, a training module 240, an output module 250, and an evaluation module 260. In some implementations, the quota resolving system 100 also includes an allocation prediction module 270.
In general, the quota parsing system 100 is configured to receive a quota request and raw input data from the platform 110 and generate a set of design features having values obtained from the raw input data. System 100 processes the design features through a score-service model 220. The score-service model 220 generates a quota score that represents a likelihood that a platform user requesting additional computing resources will abuse those resources according to one or more abusive usage parameters. Score-service model 220 communicates the quota score to output module 250, and output module 250 is configured to process the quota score and parse the quota request according to the quota score and optionally one or more other criteria.
The quota resolving system 100 can also include a training module 240 for training or retraining the score-service model 220 with updated training data from the platform 110. The quota resolution system 100 can also include an evaluation module 260 configured to evaluate performance of the score-service model 220 relative to a plurality of evaluation criteria and to trigger retraining of the training module 240 in response to the performance not satisfying the plurality of evaluation criteria.
The following description includes a description of an example data stream as it is received by the data orchestration module 205, processed by one or more other components of the quota resolving system 100, and used to generate output by the output module 250 to resolve quota requests. The various components can be implemented on one or more server computing devices in one or more physical locations. In some embodiments, the flow of data from input to output can be different from the flow described according to aspects of the present disclosure. In some embodiments, some components are omitted and other components not shown in fig. 2 are added.
The data orchestration module 205 is configured to obtain and process raw data to be processed by the quota resolving system 100. The data orchestration module 205 obtains user account data, and in some embodiments computing resource data, and pre-processes the data into a standardized format for consumption by the feature design module 215 and the data tagging module 210. Because the platform 110 can be complex and store user account data across multiple different sources, the data orchestration module 205 can be adapted to process different types of data. Instead of updating each module implemented on system 100 as the original data on platform 100 changes, data orchestration module 205 can instead be updated, for example, by one or more other modules of platform 110.
The feature design module 215 is configured to generate features from the user account data obtained from the data orchestration module 205. In this description, a feature is a measurable characteristic of some portion of the user's activity on the platform 110. The feature design module 215 is configured to generate both simple features and composite features from the data obtained by the data orchestration module 205. The output of the feature design module 215 can be a numerical multidimensional array of numerical values and/or classification values.
Simple features are features that are mapped directly from data that measures some aspect of user activity by a platform user through one or more user accounts on the platform 110. A simple feature can be an account age representing a platform account of a platform user. The feature design module 215 is configured to set a value of the signal (e.g., six months old for the created account) and map the value to a feature of the account age of the platform account. The feature design module 215 can query one or more data tables obtained from the data orchestration module 205 according to the table fields corresponding to the values of the different features. For example, the obtained data may include a field of platform account age, and the feature design module 215 is configured to query the value at this field and map it to a simple feature of platform account age.
The feature design module 215 is also configured to process at least a portion of the obtained data to generate a composite feature. A composite feature is the product of processing one or more other features or data obtained from data orchestration module 205. For example, if the obtained data includes a table with fields for daily RAM usage assigned to a virtual machine of a platform user, the feature design module 215 can generate a value representing a composite feature for the daily RAM usage. One composite characteristic can be average RAM usage over thirty days. Another composite characteristic can be a ratio between RAM usage for the first thirty days and RAM usage for a time period earlier than the first thirty days.
The feature design module 215 is capable of generating composite features and using the composite features to further characterize user activities in a manner that simple features alone cannot. The diversity of the feature representations allows the quota resolving system 100 to access different insights into user activities that can have strong or weak relevance to the final determination of whether the platform is likely to abuse the additionally allocated computing resources. In addition, the feature design module 215 generates features from a platform with which a platform user interacts in various ways through various different user accounts. The task of identifying features corresponding to the behavior of a particular platform user is made important by the interrelationships between different platform users of various types of billing, applications, projects, and virtual machine accounts or entities. This is at least because excessive reliance on certain features can skew the determination of the system 100 as to whether a particular platform user will abuse the allocated computing resources.
The features can be classified according to the account type from the feature design module 215, and the feature design module 215 generates values according to, for example, platform account level features, billing account level features, and the like. Within each account level, there are one or more sub-categories, e.g., the history of reported abuse of a platform user can be under the "abuse" sub-category within different account level features. Examples of different features that the feature design module 215 can generate are as follows.
Platform account level features are typically features related to how a platform user accesses the platform 110 and how the platform 110 identifies and authenticates the platform user. Examples of platform account level features can include: an age of the platform account and a characteristic of an email address corresponding to the platform account. The characteristics of the email address can include the presence or percentage of certain patterns of letters and numbers or strings of characters within the email (such as the presence of the current year, or strings of letters concentrated in certain portions of the QWERTY keyboard). Other examples include the type of domain of the email address, e.g.,. Com,. Org,. Edu, and whether the domain is free or requires payment for use.
The platform-level account features can also include features that characterize information about the platform account of the platform user. If this type of platform-level account feature is used, the feature design module 215 can be configured to process an encrypted version of the characterization information and design the feature according to the encrypted version.
The platform account level features can also include features that characterize the location of the platform user when accessing the platform. The location of the platform user can include a country or region associated with the user computing device 120. The location of the platform user can be identified based on selections made by the user when accessing the platform 110, utilizing the network address of the user computing device 120, and other known methods. When appropriate rights exist with respect to the user computing device 120, the location of the user computing device 120 can be included as a platform account level feature. In some implementations, the feature design module 215 can generate features characterizing the location of a platform user when accessing the platform from an encrypted version of the location data. For example, the feature design module 215 can generate location features without specific knowledge of a country or region, and the scoring-service model 220 can instead rely on differences and similarities between location features between platform accounts to predict whether particular platform users sharing certain location feature values are likely to abuse the platform. Further, the platform 110 can include features related to the identified location, such as whether the location has been predetermined as a source of abuse for the platform 110.
The platform account level features can also include similarities between a platform account and another platform account that has declined quota requests. For example, the feature can represent a distance between a platform account email address and an email address of a known abuser.
Another type of platform account level feature relates to cross-product usage by platform users of different services or applications hosted by the platform 110. This type of feature can include usage data corresponding to the use of different products by the platform user, as well as data representing the frequency with which certain applications or service groups are used together by the platform user.
Another type of platform account level feature relates to terms and conditions that are either explicitly or implicitly agreed upon by the platform user at the time of platform account creation. The terms and conditions can describe some or all of the abusive use parameters that specify abusive activity on the platform. If the platform 110 is accessible by platform users in different countries or states, the terms and conditions may vary, for example, according to local laws and regulations. Thus, the platform account level features can include features corresponding to the language of the terms and conditions as requested or agreed upon by the platform user, and physical areas/locations corresponding to the version of the terms and conditions requested or agreed upon by the platform user.
Another type of platform account level feature relates to hibernation of a platform account, i.e., data related to the number of logins through the platform account, the time between logins, and the time since the last login. The characteristics of the class can also include the time between different activities of the platform account, e.g., the time between the last request for additional computing resources.
Another type of platform account level feature relates to the nature of a platform user's current or previous request to increase allocation of computing resources. Example features include the type of quota request, e.g., quota request for additional CPU/GPU/ASIC resources or additional items, the ratio between successful and denied requests, the number of quota requests and how much additional computing resources are requested in each quota request, and whether quota increase is related to usage of paid services on platform 110.
Another type of platform account level feature relates to console behavior of platform users when interacting with the platform 110. For example, this type of feature can include data collected by the platform 110 related to the input, as well as the time spent by the platform user on the interface between the server computing device 115 and the user computing device 120 when the platform user interacts with the platform 110.
The platform user can also be represented by one or more project entities that can be managed by one or more platform user accounts. As described above with reference to FIG. 1, in some embodiments, the project entity is managed by a project account. The project account can represent one or more platform users. Project entity-level features include metadata of the project hosted on the cloud platform, such as the creation date, the project type, or the programming language in which the project was written (if applicable). Project entity level features can also include API usage, such as tracking which projects use which APIs, and the frequency with which calls are made.
One type of project entity-level feature relates to reported project abuse. The item abuse type feature can include a ratio of the abuse item (i.e., violating the abuse usage parameters) to all items in the past thirty days, and a percentage of the abuse item among all items represented by the item entity. The rate or amount of abusive items can be counteracted according to a predetermined false positive rate. The abusive items can be reported and verified manually or detected automatically by the platform 110.
The platform user can also be represented by one or more billing accounts. A billing account representing a platform user can include data corresponding to a number of different characteristics characterizing the billing behavior of the platform user on the platform 110. Examples include the number of billing accounts representing the platform user, the age of each billing account, reported fraudulent activity related to bills paid for subscription services, the rolling balance of each billing account, and the payment (or non-payment history) of the platform user. Similar to the platform account, the billing account representing the platform user can also represent when the billing account was created, and the frequency with which the platform user was active on the platform 110 when performing billing-related activities.
The billing account level features can also include the rate or relative contribution of platform users to the activities of the billing account. The billing account can be shared by multiple platform accounts through which the multiple platform accounts individually interact with the platform 110. For example, the billing account feature can represent how many subscriptions/purchases the platform user performed with respect to another user, or a ratio between items authored by the platform user that use subscription services paid through the billing account and items that also use paid services but are not authored by the platform user.
Platform users can also be represented by one or more virtual machine accounts. The virtual machine account includes data representing a virtual machine managed by a platform user and hosted on the platform 110. Virtual machine account-level features generally include features related to the use of any virtual machine associated with one or more virtual machine accounts. For example, these characteristics can include resource allocation and usage, request history, activities performed using the virtual machine, network traffic, and statistics of uptime/downtime of the virtual machine.
Reputation is a general type of feature that can be made available across user accounts representing platform users. In some implementations, the platform 110 is configured to maintain reputation metrics that measure the platform user's interactions with different applications and services provided by the platform 110. Platform 110 can generate these reputation metrics separately from quota resolving system 100, and those metrics can be used for various purposes, e.g., for comparing platform users according to the metrics, or for reporting off platform 110. For example, one reputation metric for a platform user's billing account can measure the timeliness of making payments to the platform 110. The feature design module 215 is configured to use the reputation metrics as additional features for generating a designed feature set, either alone or in combination with other features.
Risk features are another type of feature that can be available across each user account representing a platform user. The value of the risk profile measures the abuse risk of the platform user that is in compliance with the particular profile. For example, the feature design module 215 can generate abuse risk features among accounts created during a particular time period. The feature design module 215 is capable of generating risk features and performing discriminant analysis to distinguish platform users who are compliant with a given feature profile who are likely to abuse the computing platform 110 from platform users who are compliant with the given profile but are not likely to abuse the platform 110. The quota resolution system 100 can implement any of a variety of discriminant analysis techniques on a given profile of a platform user.
The risk features are different from the quota scores generated by score-service model 220 at least because model 220 is able to use the values of the risk features as part of generating the quota scores. Another reason for the difference in risk characteristics is because quota scores are an overall prediction of the likelihood of abuse by platform users, whereas risk characteristics only represent platform users within a profile. Despite this difference, the risk features can help improve the accuracy of quota resolving system 100 in resolving quota requests, as the features can represent the potential risk of abuse from a sub-population of user pools of platform 110 with additional nuances.
Complaint metrics are another type of feature that can be made available across each user account representing a platform user. The complaint metrics measure complaints by platform users to the platform 110. For example, the platform 110 can provide a service in which a platform user can make a complaint about a decision to remove an item by the platform 110. If the platform 110 detects that the project is violating abusive usage parameters of the platform 110, the platform 110 may automatically remove the project authored by the platform user. In response, the platform 110 may receive a complaint from the platform user that gives a reason why the removal was incorrect. The platform 110 may automatically review the complaint or pass the complaint to an entity hosting the platform 110 for further review. As an example, the complaint metrics can measure the frequency and type of complaints provided to the platform 110 by the platform user.
Because the platform users can be represented by different user accounts, the feature design module 215 can aggregate any of the above-described features to represent an aggregated feature across all user accounts representing the platform users. The feature design module 215 can receive as input a mapping of identifiers for each user account representing a platform user and how each account is related to each other. For example, if a platform user is represented by several billing accounts, the feature design module 215 can aggregate the payment history across each account, creating an aggregated payment history feature. As an example, in this case, the value of the feature can be the average payment history across the platform user's billing accounts. Fig. 3 below shows an example of mapping.
FIG. 3 is a diagram of an example mapping 300 representing user accounts for different platform users. Mapping 300 illustrates the relationship between platform accounts 305A-F, billing accounts 310A-B, and projects 315A-E hosted on platform 110. The connection between the account and the project as shown in fig. 3 indicates a relationship on the platform 110, e.g., represented by a relationship in the case of a platform account and a billing account, and authored/coauthored by a relationship in the case of a platform account and a project. For ease of description, various relationships of platform account A305A are referenced (represented by solid lines), while other relationships between other platform accounts 305B-G are represented by dashed lines. Also in this example, platform accounts 305A-F are connected with various items 315A-E. In some implementations and as described above with reference to fig. 1, the platform account of the platform user can directly represent the data of the project entity.
As shown in FIG. 3, platform account A305A is represented by billing account A310A. Billing account A310A represents data for the billing activity of project A315A and project B315B. Projects 315A, 315B are coauthored by platform account B305B and platform account C305C. This example highlights various different relationships between items and user accounts on the platform 110. Platform accounts A-C305A-C are related to project A, B A-B, but in a different manner. For the thousands of accounts and services available on the platform 110, the connections between user accounts and projects can be large and largely separate between individual accounts.
Also in FIG. 3, platform account A305A is directly linked to item E315E, without an intermediate billing account. This example further illustrates how a platform account can directly or indirectly interface to any other type of user account or entity of a computing platform. For example, the platform account can be the author of the project, and not associated with the billing account for the project.
The feature design module 215 can leverage rich interconnections between user accounts to generate additional features for the score-service model 220 process. For example, one type of feature can relate to a graph or sub-graph created by the relationship between user accounts and items on the platform 110. The feature design module 215 can generate a connection component between different accounts that can represent each account or project connecting different accounts. The connected component can include some or all of the data corresponding to individual or aggregate characteristics of the different accounts represented by the connected component. The feature design module 215 can filter the generated subgraphs according to different criteria to generate other more specialized features. One example of such a feature is a connection graph representing user accounts of platform users that are active over a given period of time.
The feature design module 215 is configured to perform any of a variety of different graph processing techniques to generate different graph attributes corresponding to a graph or sub-graph between a user account and an entity. The graph attributes can directly or indirectly form values for the features designed by the feature design module 215. For example, the feature design module 215 can calculate the degree of separation from different platform user accounts that share different characteristics.
In some implementations, the platform 110 may not have a clear mapping between user accounts representing platform users. The platform 110 is configured to cluster the similar accounts according to a similarity metric and generate a cluster score representing the similarity according to the metric. As described above, the feature design module 215 can use these generated cluster scores to determine which user accounts to aggregate.
The feature design module 215 is configured to perform various statistical operations on aggregated data representing user accounts of platform users. For example, the feature design module 215 can calculate an average, find a distribution, or perform a more specialized analysis, such as calculating a kurtosis "or a tailrace" of a distribution. The results of these statistical processes can form values for more complex features that form part of the designed feature set.
The feature design module 215 can aggregate data from different platform accounts according to the similarity or likelihood that the platform accounts are operated by platform users from the same larger organization (e.g., company or research institute). Feature design module 215 can identify whether a platform account is associated with a particular domain or physical region. This type of data may be relevant to quota resolution, for example, because the scoring-service model 220 may learn a correlation or inverse correlation between the size of the original organization and the likelihood that a platform user from that organization will abuse the computing resources.
In some implementations, the feature design module 215 uses data across multiple time steps corresponding to a platform user to determine statistical trends. For example, the feature design module 215 can generate values for features that represent trends in resource consumption by platform users over a period of time. This and other features can then be processed by the score-service model to predict future behavior, i.e., the likelihood of abuse by the platform user given the additional resources. In some implementations, the feature design module 215 uses data across multiple different platform users to generate trends or baselines that are compared to the feature data.
The feature design module 215 can include one or more machine learning models trained to receive data from the data orchestration module 205 and to generate values for one or more features from the received data. In this manner, the feature design module 215 can further extract potential candidates for the designed feature set using the data-rich nature of the platform 110.
One example of a learned feature can be API usage. As described above, the feature design module 215 is capable of generating features corresponding to API usage of items associated with platform users. API usage can be high dimensional, meaning that there can be many data fields from which features can be generated. However, in some cases, the feature design module 215 may generate representative features from API usage data that is still relevant to model performance, but less computationally intensive. The feature design module 215 can implement a machine learning model, such as a neural network, that is trained to receive the API usage data and generate a relatively low-dimensional data structure that represents the API usage data. The feature design module 215 can include one or more other machine learning models configured to reduce other forms of high dimensional data.
As part of generating a low-dimensional data structure from relatively higher-dimensional data, the feature design module 215 can process the obtained classification data, represented as text or non-numeric, using, for example, one or more machine learning models. The feature design module 215 can then process the classified data into numerical equivalents using any of a variety of different techniques. In this manner, the quota resolving system 100 can process quota requests more quickly, at least because the feature design module 215 is configured to automatically convert classification data to numerical data.
Returning to FIG. 2, the feature design module 215 is configured to generate a set of simple and composite features to be subsequently processed by the quota resolving system 100. As policies or behavioral patterns related to resource abuse can change over time. Accordingly, the feature design module 215 is configured to periodically re-evaluate the designed features according to different metrics. In some embodiments, the feature design module 215 generates a pool of candidate features and ranks the features by importance.
The importance of a feature can be related to the goal of the model that processes the feature. For the quota resolving system 100, the score-service model 220 is configured to receive the designed features and generate a score that represents, at least in part, a predicted abuse likelihood that the violating platform abuse usage parameters will use additional computing resources allocated to the first user. Importance can be measured in various ways, for example as a statistical correlation. The feature design module 215 is configured to perform feature significance analysis according to various techniques, for example, using random forest methods, neural networks, or regression analysis techniques (such as LASSO).
The feature design module 215 can generate a top subset of the significant features as features to be passed for training or inference by the quota resolving system 100. In some implementations, the feature design module 215 processes the pool of candidate features by permuting the pool of candidate features to determine the effective size or order of the features. In addition to the model objectives of the score-service model 220, the feature design module 215 can generate feature sets from other objectives. For example, the feature design module 215 can also consider the size of the feature set being designed, e.g., to prefer simpler or fewer features when possible, while not substantially sacrificing model performance.
Additionally or alternatively, the feature design module 215 can consider the resulting complexity of the score-service model 220 necessary to process the designed feature set, for example, by processing features that are preferably less computationally complex. The feature design module 215 can also generate a designed list of features based at least in part on the received manual tuning parameters that manually assign relative importance to different features.
However, the feature design module 215 is configured to perform significance analysis when generating the designed feature set, and the feature design module 215 is configured to perform significance analysis periodically or in response to triggering events when user activity (both abusive and non-abusive) transitions on the platform 110. For example, the feature design module 215 is configured to rerun the importance analysis once a month to allow for changes in the designed feature set. Because platform users often use computing resources on the platform 110 to implement their own industrial/business problem solutions, the variety of data obtained by the data orchestration module 205 can vary greatly in response to emerging business practices. Abusive activity can also lead to paradigm shift processing on the platform 110. For example, in response to a requirement to mine different currencies, the rise in cryptocurrency mining has resulted in a substantial increase in CPU, GPU and/or ASIC usage. Thus, periodic re-evaluation of the designed feature set can account for potentially unpredictable commercial or technical trends.
The feature design module 215 is also capable of re-evaluating the designed feature set in response to events recorded by the platform 110. An event can be anything that represents a deviation from normal activity of the platform 110 within a margin of error. The feature design module 215 can be configured as a separate module of the listening platform 110 that is configured to record and track activity on the platform 110 according to different metrics. For example, increased GPU usage over normal demand can prompt the feature design module 215 to re-evaluate the designed feature set. Returning to the cryptocurrency example, the increased GPU usage can be a metric of cryptocurrency mining, which may or may not be an allowed activity on the platform 110. By triggering feature design module 215 to re-evaluate, quota resolving system 100 can more quickly adapt to changes in the way that platform users can potentially abuse platform 110.
The feature design module 215 can be configured to estimate missing values as necessary. In some cases, the data from the data orchestration module 205 may not include data for a particular feature of the designed feature set. In these cases, feature design module 215 can add predetermined values for some or all of the missing features. In some implementations, the feature design module 215 can generate a replacement value for the missing feature from one or more other features whose values are known.
The quota resolving system 100 includes a score-service model 220 configured to receive the designed feature set as input and generate quota scores as output. The quota score is a numerical representation of a predicted likelihood that the additional computing resources allocated to the user will be used (i.e., will not be abused) according to the abuse usage parameters for a given future time period generated by the quota resolving system. Score-service model 220 can generate quota scores for each platform user in response to a request and/or automatically (e.g., on an hourly, daily, or weekly schedule).
The range of quota scores can be, for example, an integer within the range [0,1000], where a quota score towards one end of the range corresponds to a lower likelihood of abuse and a quota score at the other end of the range corresponds to a higher likelihood of abuse. In some embodiments, score-service model 220 generates and performs further processing on the quota score for the platform user according to a probability distribution within the range [0,1], where 0 corresponds to a predicted 0% chance of the platform user abusing the additional computing resource and 1 corresponds to a predicted 100% chance of the platform user abusing the additional computing resource. Score-service model 220 is capable of generating a predicted abuse potential anywhere within this range.
Score-service model 220 can directly generate the likelihood as a quota score, or quota resolving system can map quota scores according to a probability distribution (e.g., [0,1] or [ -1,1 ]). As described below, the output module 250 can map probability distributions over a wide range of intervals (e.g., 1001 intervals of quota scores within the range [0,1000 ]), which can provide more granularity in comparing abuse potential between similar or dissimilar platform users.
The future time period is a predicted time window during which the scoring-service model 220 focuses on potential abuse by the platform user. The future time period can be predetermined, for example, 30 or 60 days from the time the quota resolving system 100 generates the quota score.
The quota score as generated by score-service model 220 is at least one or more learning model parameter values (including abuse index a) T ) As a function of (c). The abuse index is a computational parameter of the score-service model 220 that represents a predicted likelihood that the platform user will abuse additional computational resources within a future time period T. In some embodiments, the quota score is a function of the abuse-only index. In other embodiments, the quota score can be expressed as a target objective function that includes the abuse metric and additional parameters.
An example of an objective function can be:
f(x T ，a T ，k)＝act(k*x T )+a T *(act(k*x T )-1)
wherein x is T Is a revenue indicator learned in the future time period T, a T Is a learned abuse indicator, k is an optional tuning parameter, and act (-) is a nonlinear activation function. Example functions of act (·) can include tanh, sigmoid, and ReLU. Each parameter is described in turn.
The score-service model 220 is trained to process the designed feature set from the feature design module 215 to generate the abuse index a T . For example, if the score-service model 220 is a deep neural network with multiple layers, the input layers of the model 220 can receive features. One or more hidden layers between the input layer and the output layer can process the features to generate an intermediate output. Each hidden layer can include one or more activation functions for processing features or intermediate outputs from another hidden layer according to the set of weights for that layer. The scoring-service model 220 learns the weight values for the weights of each hidden layer through training, which can be performed by the training module 240, as described below.
After processing through one or more hidden layers, score-service model 220 can process the intermediate output generated by the last hidden layer through the output layer. The output layer can be configured to generate abuse metrics and other metrics based on the value of the intermediate output from the last hidden layer. The output layer can process the abuse index a according to a model objective function (e.g., the objective function described above) T And any other processed metrics.
Prediction revenue index x T Indicating a predicted probability that the platform 110 will generate revenue from platform users that meets the target threshold over a future time period. Scoring-service model 220 can use the designed feature set to predict learned revenue index x T And a T The value of (c). The optional tuning parameter k can be predetermined or learned and introduced for adjusting the revenue index x T A variable of relative contribution to quota score.
In some embodiments, the break-even point for x is selected based on the predicted cost/goal of the potential abuser T Optional tuning parameter k. For example, in the case of cryptocurrency mining, if abuse by a platform user is likely to generate more revenue than the predictive contribution of the platform 110, the prediction revenue index x T Can be less important for predicting abuse. Quota resolving system 100 can receive expected or predicted revenue for platform users when mining using cryptocurrency, for example, from platform 110 or another source external to platform 110. In this example, the expected or predicted revenue can be a function of at least current market trends for different cryptocurrencies. Thus, score-service model 220 is able to set an optional tuning parameter k to reduce revenue index x T An overall contribution to the model target quota score.
Despite the prediction revenue index x T Is an abuse index a in an objective model called a "counteraction" score-service model 220 T But one or more other cancellation indicators may be used. For example, if the metrics generated by score-service model 220 from the subset of designed features are found to be inversely related to the abuse metrics, score-service model 220 can be configured to generate quota scores from the abuse metrics and one or more additional cancellation metrics. In some embodiments, the score-service model 220 takes into account one or more cancellation parameters when generating the abuse metrics, i.e., the model objectives of the model 220 do not always include cancellation metrics, as the contribution of the metrics has been implicitly represented by the value of the abuse metrics. Each cancellation index i can pass through a different parameter k i To tune to further allow the model 220 to adjust the relative contribution of each cancellation metric to the abuse score.
The scoring-service model 220 itself can be implemented according to a variety of different machine learning techniques. For example, the score-service model 220 can be a deep neural network. As described below, the model 220 can be trained by the training module 240 according to any of a variety of supervised training techniques. Other example architectures for score-service model 220, instead of deep neural networks, include random forest models and decision trees. In some implementations, the score-service model 220 is a collection of multiple machine learning models having the same or different architectures and/or model parameter values or hyper-parameter values. As a decision tree, model 220 can be a gradient boosting decision tree.
Although described as being generated using the score-service model 220 implemented as a machine learning model, in some implementations, the score-service model 220 generates various metrics according to any of a variety of different bayesian statistical techniques. For example, the scoring-service model 220 can be configured to generate a plurality of likelihoods, each likelihood representing a likelihood that the platform user will abuse additional computing resources within a future time period, given some conditions that can be represented by values of one or more features. In these embodiments, score-service model 220 can generate abuse index a based on multiple likelihoods T Or any other cancellation indicator.
As previously described with reference to fig. 1, the quota resolving system 100 can be configured to automatically determine whether the quota of a platform user should be increased even before a request from the platform user is received. In some embodiments, where the quota resolving system 100 is configured to determine whether to increase a quota without a request from a platform user, the quota resolving system 100 can implement the allocation prediction module 270. The allocation prediction module 270 is not present in some embodiments and is indicated in dashed lines, for example, because in some embodiments the system does not receive a request for increased allocated computing resources as in step 410 of the process 400 of FIG. 4. In those embodiments, the system may in some examples, in which process 400 is not implemented by the system, the system instead performs process 500, including predicting an expected computing resource demand of the first user during a predetermined future time period, according to block 515.
The allocation prediction module 270 is configured to predict whether a platform user will need additional computing resources that exceed their quota within a future time period T. The allocation prediction module 270 can include one or more machine learning models trained to receive inputs representing patterns of usage and growth over time of platform user usage of currently allocated computing resources. The allocation prediction module 270 is able to predict whether the platform user will request additional resources within the time period T. In some embodiments, allocation prediction module 270 is capable of receiving raw data from data orchestration module 205 and processing the data into a plurality of features. Additionally or alternatively, the allocation prediction module 270 is configured to receive some or all of the designed feature set from the feature design module 215. In some embodiments, allocation prediction module 270 is configured to receive data from elsewhere on platform 110.
The one or more machine learning models of the assignment prediction module 270 can have a variety of different architectures trained according to a variety of different supervised learning techniques. For example, if one or more machine learning models are neural networks, the models can be trained using labeled training data. Each example of data can include usage patterns and growing data for computing resource usage by a platform user over a period of time, and is tagged with a time indicating when the platform user made a request for additional resources and the amount of resources requested. In some implementations, allocation prediction module 270 can generate a number representing the amount of computing resources, where a value of 0 is interpreted as module 270 predicting that the platform user will not make a request for additional computing resources within the time period T. In some implementations, the allocation prediction module 270 predicts individual additional quota usage by the type of quota (e.g., an item quota or a resource quota).
One or more machine learning models can be trained to predict whether the requested time falls within a future time period relative to a set current time, and how much additional resources are requested. A model trainer training one or more machine learning models can compute the loss between the predictions and the ground truth and update the weights of the models according to the error, e.g., using back propagation with a gradient descent. The model trainer can be a module of the computing platform 110, such as the training module 240, or another module separate from the platform 110 but communicatively coupled with the platform 110 and configured to train one or more machine learning models.
Returning to the score-service model 220, the model 220 can receive output predicting whether a platform user will send a request for additional computing resources. The model 220 can process this output with the designed feature set from the feature design module 215 to generate a quota score. An example model objective function is:
wherein, w T Is the range of the current time [ current time, current time + T ] as the output generated by score-service model 220]A future time period of the time window in. q is a quota type, such as an item quota or a resource quota.allocation prediction module 270 that indicates whether the platform user will require additional resources in a future time period. I (-) is an indicator function that returns 1 if the input is true, and 0 otherwise. Finally, Q (w) T Q | I) is the time window w that the platform user will generate at the one or more models of the allocation prediction module 270 T A prediction of an amount of computational resources requested within.
For example, on day 1, scoring-service model 220 receives the request and processes features corresponding to the platform user to generate an abuse score that predicts that the platform user will not abuse the additionally allocated resources within 60 days (time period T). Between 2-60 days, however, the platform user does abuse the allocated resources. On day 60, the data tagging module 210 tags the feature set processed on day 1 with the correct tags, i.e., the platform user abused the computing resources during this time period T. As described in more detail below, the data tagging module 210 can also tag output from the output module 250 that can be processed by the evaluation module 260.
The training module 240 is able to train and retrain the score-service model 220 using the labeling data from the data labeling module 210. For example, the training module 240 can calculate the error between the predicted output of the score-service model 220 and the expected output defined on the processed features of the training examples by the labels of the data labeling module 210. Any technique for measuring error can be used, such as mean square error, and the training module can perform a technique such as back propagation to compute the gradient of the loss function with respect to the weights of the score-service model 220. The weights for score-service model 220 can then be updated after the gradient calculations, and the process can be repeated, for example, for a period of time or until a target accuracy threshold is reached.
Thus, the score-service model 220 can more easily adapt to different trends and abuse patterns, which can reduce staleness of the model 220 and potentially increase accuracy over time. This can be particularly important because platform abusers can change behavior quickly, for example, over weeks or months. Because the platform 110 can be highly complex and varied in terms of services available to platform users, the training module 240 allows other aspects of the platform 110 to grow in the clear by considering how the platform 110 manages quota resolving.
In some embodiments, training module 240 is configured to periodically retrain score-service model 220 according to different hyper-parameters (e.g., learning rate or small batch size). The training module 240 can perform the hyper-parametric optimization according to various different techniques (e.g., random search). Training module 240 can train score-service model 220 according to various learning rates (e.g., 0.0001-0.01). In some embodiments where the training module 240 performs back propagation as part of training the score-service model 220, the corresponding gradients can also be normalized according to different factors (e.g., 0.01-100). The training module 240 can be suitably configured to train other models implemented by the quota resolving system 100, such as one or more machine learning models implemented as part of the allocation prediction module 270.
The output module 250 is generally responsible for post-processing, storage, and reporting of quota scores generated by the score-service model 220 as a determination by the platform 110 of an allocation of increased computing resources to platform users. Post-processing can include mapping raw scores from the score-service model 220 onto different ranges, which can in some cases facilitate score interpretation. The output module 250 can apply an order-preserving transform to transform, for example, the range [ -1,1]Quota score within calibrated to the range [0,1000]A fixed distribution within. From the original value (e.g., [ -1,1)]) To a fixed distribution [0,1000]Can be based on a threshold value (t) 0 ，t 1 ，...，t 999 ) Wherein the raw score is less than or equal to t 0 Mapping to 0; t is t i < original score ≦ t i+1 Mapping to i, i ∈ {1.. 999}; and t 999 <The raw scores are mapped to 1000. The set of thresholds can be selected to act as a q-quantile of the historical score data set.
Maintaining a fixed distribution can be valuable in maintaining consistency in the output of the scoring-service model 220, at least because the designed feature set from the feature design module 215 can change over time or in response to a triggering event, as described above. In this manner, the interpretation of the output scores is consistent even if the model inputs vary, and downstream modules of platform 110, e.g., output module 250, do not have to be recalibrated or adjusted.
The export module 250 can use the quota score to generate an approval or denial of the request from the platform user. Depending on the response, the output module 250 can send a message to the platform user via the user computing device 120 indicating that their request has been approved or denied. In some implementations, the output module 250 can include one or more reasons for the allowance or denial of content that is processed as the most important feature based on, for example, the feature design module 215.
The output module 250 can generate an approval or a denial based on a determination that the quota score satisfies a predetermined threshold. The predetermined threshold can represent a minimum score set by the platform 110 for allocating computing resources that exceed the quota assigned to the platform user. An evaluation module 260 on the quota resolving system 100 can generate a threshold based on an evaluation of the accuracy of the quota resolving system 100 when resolving quota requests. The threshold can be adjusted to balance the accessibility of platform users who have approved their requests, with some tolerance to false positives caused by the quota resolving system 100 rejecting platform users who are not actually abused.
The output module 250 can also adjust the predetermined threshold based on other factors. For example, the output module 250 can adjust the threshold based on the number of requests from requesting platform accounts over a set period of time. The predetermined threshold can also vary depending on the type of quota request. For example, the threshold may be higher for requests for additional hardware resources that exceed the quota than for requests for additional quantities of items that the platform user account can concurrently author or coauthor on the platform.
The output module 250 is also capable of adjusting the predetermined threshold based on the available computing resources. For example, the output module 250 can set the threshold higher when the total amount of available computing resources on the platform 110 is low. At different points in time, the output module 250 can set the threshold lower as computing resources on the platform 110 become more available.
The evaluation module 260 is configured to monitor the performance of the scoring service model 220 according to a plurality of evaluation criteria. The evaluation module 260 is further configured to trigger retraining by the training module 240 in response to a determination that the model performance does not satisfy the plurality of evaluation criteria. The evaluation module 260 is capable of evaluating the output from the output module 250 tagged by the data tagging module 210. The data tagging module 210 can tag the output, i.e., the resolution of the quota request given the designed feature set generated in the past, with the actual results of platform abuse by the platform user. In other words, through the data tagging module 210 and the evaluation module 260, the system 100 can double check the performance of the score-service model 220 against actual results, which in turn can allow the system 100 to improve how quota resolution is performed.
One example of an evaluation criterion is accuracy. The evaluation module 260 can determine whether the model performance over a period of time is accurate within a threshold (e.g., 95% over a two month period). If the model performance does not meet the criteria, the evaluation module 260 triggers retraining of the model 220 by the training module 240.
While overall accuracy is an important metric for determining model performance, the evaluation criteria can include correlation criteria, such as false positive rate, that the evaluation module 260 can use to evaluate different aspects of model performance accuracy. The evaluation module 260 can evaluate the number of false positives of the quota resolving system 100, i.e., the number of times the system 100 rejects a platform user's request when the platform user does not ultimately abuse the computing resources. Similarly, the evaluation module 260 can evaluate model performance based on a false negative rate (i.e., the number of platform users whose quota requests are granted but who later abuse additional computing resources).
In some embodiments in which the quota resolving system 100 is configured to predict and increase a quota for a platform user prior to receiving a quota request, the evaluation criteria can also include criteria for evaluating the use of additional computing resources by the platform user. The evaluation module 260 can check whether the platform user actually uses the additional resources. If the model performance is below a threshold for the criteria, the evaluation module 260 can trigger retraining by the training module 240. This form of evaluation can help the system 100 more accurately preempt additional resource needs from non-abusive platform users, which can reduce wasted resources that would otherwise be allocated but not used by the platform users.
The evaluation module 260 can evaluate the quota score at different thresholds. Because the output module 250 can map the quota score to a fixed distribution, e.g., [0,1000], the evaluation module 260 can evaluate the quota score relative to the evaluation criteria at different cutoff points. In some implementations, the evaluation module 260 sets each value [0,1000] to a threshold and filters the quota score generated by the output module 250 according to each threshold. The evaluation module 260 can then evaluate the quota score against the evaluation criteria at each threshold. In this manner, the evaluation module 260 can more specifically identify whether quota scores of different thresholds fall below expected model performance.
For example, after setting a threshold for the quota score and evaluating the quota score against a plurality of evaluation criteria, the evaluation module 260 can determine that the model performance falls below a minimum threshold for quota scores below 500. In other words, the score-service model 220 may generate quota scores that more accurately predict whether a platform user is likely to abuse additional computing resources when the resulting score is above 500, but may be less accurate for platform users with scores less than 500.
In response, evaluation module 260 can trigger retraining by training module 240. In some implementations, the training module 240 can customize the input training data to more broadly cover a particular score threshold. For example, the training module 240 can receive more training examples labeled with quota scores below 500 to focus model improvement. In some implementations, the evaluation module 260 identifies common values for some features shared between platform users scored at particular thresholds where reduced model performance is identified. In response, the training module 240 can receive more training examples that have those common feature values.
FIG. 4 is a flow diagram illustrating an example process 400 for resolving a quota request using a quota resolving system. Process 400 is described as being performed by a cloud computing platform having one or more server computing devices and one or more user computing devices located in one or more physical locations and programmed according to aspects of the present disclosure. For example, a suitably programmed cloud computing platform 110 implementing quota resolving system 100 can perform process 400. The steps of process 400 can be performed in a different order with additional steps added or some of the steps shown in process 400 removed.
The computing platform allocates 405 up to a first quota of computing resources to a first user account representing a first user. As described above with reference to fig. 1, the platform is able to do so as part of account creation. The first user account can be a platform account. In some implementations, the quota resolving system 100 processes the initial allocation or the additional allocation, while in other implementations, the quota resolving system is configured to cause one or more other modules to allocate computing resources.
According to block 410, the system receives a request for increased allocated computing resources for the first user account that exceed the first quota. In some implementations, and as described below with reference to FIG. 5, the platform does not receive the request, but rather automatically determines whether the first quota should be updated and whether additional computing resources should be allocated.
According to block 415, the platform receives user account data from one or more user accounts representing the first user. Referring to FIG. 2, the platform can receive user account data from different portions of the platform and using the data orchestration module 205 of the quota resolving system 100. User account data can be processed such that it can be consumed by modules downstream from the data orchestration module 205 (e.g., the feature design module 215).
According to block 420, the platform generates, based at least in part on the user account data, a plurality of features characterizing the interaction between the first user and the computing platform. Interaction refers to user activity across platforms and using one or more user accounts (e.g., platforms, virtual machines, projects, applications, and billing accounts) representing the platforms. As described above with reference to FIG. 2, the feature design module 215 is configured to generate features directly or indirectly from data obtained from the data orchestration module 210. The obtained data can include user account data.
According to block 425, the platform generates a score that represents, at least in part, a predicted likelihood that the additional computing resources allocated to the first user will be used in violation of the predetermined abusive usage parameter during the predetermined future time period. For example, the score-service model 220, as described above with reference to FIG. 2, can be trained to generate scores according to the designed feature set of the feature design module 215.
According to diamond 430, the platform determines whether the score satisfies a threshold. If not ("NO"), the process ends and the platform can report to the first user, e.g., via the user computing device, that the quota request from the first user is denied. As described above with reference to fig. 2, the output module 250 can compare the quota score to a threshold to determine how the quota request should be parsed. The threshold can be a composite of various different criteria, or in some embodiments can be a predetermined score threshold, such as 700. Based on the generated score, meeting a threshold can indicate a minimum confidence level of the platform for the platform user.
If the platform determines 430 that the score satisfies the threshold, the quota resolution system can cause the computing platform to update 435 the first quota. The quota resolving system can update the first quota itself, or the system can cause another component of the platform to update the first quota. The amount increased by the quota can be a function of the request itself, or can be based on the amount of increase indicated in the request. The platform can then allocate 440 additional resources in response to the request.
FIG. 5 is a flow diagram illustrating an example process 500 for allocating additional computing resources prior to receiving a quota request from a platform user. Process 500 is described as being performed by a cloud computing platform having one or more server computing devices and one or more user computing devices located in one or more physical locations and programmed according to aspects of the present disclosure. For example, a suitably programmed cloud computing platform 110 implementing quota resolving system 100 can perform process 500. The steps of process 500 can be performed in a different order with additional steps added or some of the steps shown in process 500 removed.
According to block 505, the platform allocates up to a first quota of computing resources to the first user account. According to block 510, the platform receives user account data from one or more user accounts representing the first user. The first user account can be a platform account of the first user.
According to block 515, the platform predicts a computing resource demand of the first user during a predetermined future time period. As described above with reference to fig. 2, the quota resolving system 100 can include an allocation prediction module 270 configured to predict an increase in computing resource demand of a platform user over a future time period.
According to diamond 520, the platform determines whether the predicted expected demand exceeds the first quota. If not ("NO"), the platform ends the process 500. If the platform determines that the expected demand exceeds the first quota ("yes"), the platform can continue as in process 400, i.e., generate a plurality of features characterizing the interaction between the first user and the platform; determining whether the score satisfies a threshold; and updating the first quota; and allocating additional computing resources for the first user, according to blocks 420-440.
Aspects of the disclosure can be implemented to realize one or more of the following advantages. Quota request resolution can be performed more accurately and in an automated manner. A quota resolving system implemented consistent with aspects of the present disclosure can generate a likelihood of future abuse by a user of a cloud computing platform, even if the platform user is represented by a user account with little characterizing data and no past history of abuse. By facilitating more accurate resolution of quota requests by platform users who are less likely to abuse additional computing resources, the platform can mitigate the risk of under-stock (stockout), a situation where all available computing resources on the platform are exhausted and the platform does not have sufficient available resources to address future quota requests.
The system is able to accurately predict that a new platform user will not abuse additional computing resources despite some past history of abuse. The quota resolving system can utilize a wide variety and feature-rich signals unique to cloud computing platforms, which can better utilize available data than previous rule-based approaches that rely on a small set of manual tuning parameters. More accurate quota request resolution can improve overall resource usage of the platform because the allocated computing resources are more likely to be used in a manner consistent with abusive usage parameters that do not violate the platform.
Computing resources can also be allocated more judiciously to prevent computing resources from being allocated but not used. By proactively allocating additional computing resources to only non-abusing users, the quotas of different users can be automatically and more confidently increased based on the user's prediction of the need for additional resources. Improved automation of the quota request resolution process can also reduce the number of requests to the platform and the turnaround time between the time the user sends the request and the time the quota resolution system resolves the request. Reduced turnaround time without sacrificing accuracy can improve the user experience when interacting with the platform, at least because any delay caused by waiting for increased resource quotas is reduced, allowing for sustained and increased productivity. The system is also able to reduce the amount of interaction between the platform and the requesting user at least because the system is able to operate on the data available to the platform 110 and is less likely to subsequently request additional information from the user.
Based on the system's predictions, the anticipated and existing users of the computing platform can be the target of proactive bids and advertisements for computing resource quota increases. For example, based on system predictions, new users of the platform can be provided with varying amounts of quotas during new user boot so that users can quickly begin using the platform without prematurely encountering resource allocation issues. Instead, as described herein, the platform can analyze the signals of platform users across multiple sources to predict users who have a low risk of abusing the additionally allocated resources even before the user's initial quota request.
Aspects of the disclosure can be implemented in digital circuitry, a computer readable storage medium, as one or more computer programs, or a combination of one or more of the foregoing. The computer-readable storage medium can be non-transitory, for example, as one or more instructions executable by a cloud computing platform and stored on a tangible storage device.
A computer program can be written in any type of programming language and according to any programming paradigm, such as declarative, procedural, assembly, object-oriented, data-oriented, functional, or imperative. Computer programs can be written to perform one or more of a variety of functions and operate within a computing environment (e.g., on a physical device, a virtual machine, or across multiple devices). The computer programs can also implement the functions described in this specification as performed by the system, engine, module, or model.
In this specification, the phrase "configured to" is used in different contexts in relation to computer systems, hardware, or portions of computer programs, modules, or engines. When a system is referred to as being configured to perform one or more operations, this means that the system has the appropriate software, firmware, and/or hardware installed on the system that, when operated, causes the system to perform the one or more operations. When some hardware is referred to as being configured to perform one or more operations, this means that the hardware includes one or more circuits that, when operated, receive input and generate output in accordance with the input and corresponding to the one or more operations. When a computer program, module, or engine is referred to as being configured to perform one or more operations, this means that the computer program comprises one or more program instructions that, when executed by one or more computers, cause the one or more computers to perform the one or more operations.
Unless otherwise specified, the foregoing alternative examples are not mutually exclusive, but may be implemented in various combinations to achieve unique advantages. As these and other variations and combinations of the features discussed above can be utilized without departing from the subject matter defined by the claims, the foregoing description of the embodiments should be taken by way of illustration rather than by way of limitation of the subject matter defined by the claims. In addition, the provision of examples described herein, as well as terms such as "such as," "including," and the like, should not be construed to limit claimed subject matter to particular examples; rather, these examples are intended to illustrate only one of many possible embodiments. Further, the same reference numbers in different drawings can identify the same or similar elements.
Claims (21)
1. A system, comprising:
a computing platform comprising a plurality of processors and one or more storage devices storing instructions that are operable when executed by the plurality of processors to cause the plurality of processors to perform operations comprising:
allocating up to a first quota of computing resources to a first user account of one or more user accounts representing a first user of the computing platform, wherein the first quota is an upper limit on computing resources allocated to the first user account;
receiving user account data from the one or more user accounts representing the first user;
generating a plurality of features from the user account data, wherein each feature is a measurable representation of an interaction between the one or more user accounts and the computing platform; and
generating, based at least on the plurality of features, a score that represents, at least in part, a predicted likelihood that the additional computing resources allocated to the first user account will be used in violation of one or more predetermined abusive usage parameters during a predetermined future time period.
2. The system of claim 1, wherein generating the score comprises:
generating a higher score in response to a lower predicted likelihood that the additional computing resource will be used in violation of the predetermined abusive usage parameter; and
generating a lower score in response to a higher predicted likelihood that the additional computing resource will be used in violation of the predetermined abusive use parameter.
3. The system of claim 2, wherein the operations further comprise:
determining that the generated score does meet a predetermined threshold, the predetermined threshold representing a minimum score for allocating additional computing resources beyond a respective quota of the user account; and
in response to determining that the generated score satisfies the predetermined threshold, allocating additional computing resources to the first user account and updating the first quota.
4. The system of claim 3, wherein the first and second sensors are arranged in a single unit,
wherein the one or more processors are further configured to receive a request for increased allocated computing resources allocated to the first user account that exceed the first quota; and
wherein, in response to determining that the generated score does not satisfy the predetermined threshold, the received request for increased allocation of computing resources is denied and no additional computing resources are allocated to the first user account.
5. The system of claim 3, wherein allocating the additional computing resources to the first user comprises:
predicting a first time that the first user will require additional computational usage, an
Allocating the additional computing resources prior to the first time.
6. The system of claim 1, wherein the first and second sensors are disposed in a common housing,
wherein generating the score comprises generating the score using one or more machine learning models trained to generate the score from the plurality of features; and
wherein the operations further comprise:
determining, by the system, that the score does not satisfy a plurality of evaluation criteria; and
in response to determining that the score does not satisfy the plurality of evaluation criteria, retraining the one or more machine learning models trained to generate the score from the plurality of features.
7. The system of claim 6, wherein the first and second sensors are arranged in a single package,
wherein the user account data is first user account data received at a first time and the generated score is a first score,
wherein the operations further comprise:
generating flagged user account data comprising:
receiving second user account data generated at a second time that is prior to the first time and that is separated by a length of time that is equal to or greater than the length of the predetermined future time period, and
flagging the second user account data with a second score generated using the second account data after expiration of the future time period relative to the second time; and
retraining the one or more machine learning models on the labeled user account data.
8. The system of claim 1, wherein generating the plurality of features comprises:
generating a graph representing the one or more user accounts; and
generating a first feature of the plurality of features from one or more other features of the plurality of features of the one or more user accounts in the graph.
9. The system of claim 1, wherein the first and second sensors are disposed in a common housing,
wherein the user account data comprises data characterizing the usage of computing resources by the first user on the computing platform by the one or more user accounts, an
Wherein the operations further comprise determining that the first user requires additional computing resources, including processing the data characterizing computing resource usage by the first user through one or more machine learning models trained to receive the data characterizing computing resource usage and to predict a metric of additional computing resources required to exceed the first quota during the predetermined future time period.
10. The system of claim 9, wherein the operations further comprise determining a quantitative measure of additional computing resources to allocate to the first user from the data characterizing computing resource usage.
11. The system as set forth in claim 1, wherein,
wherein the predicted likelihood is a predicted abuse likelihood,
wherein the operations further comprise maintaining a resource allocation service for allocating additional computing resources of the computing platform in response to user requests and payments; and
wherein generating the score comprises:
generating a predicted revenue likelihood that the computing platform will receive a first request to allocate additional computing resources and a first payment from one of the one or more user accounts within the predetermined future time period, and
generating the score as a function comprising the predicted likelihood of revenue and the predicted likelihood of abuse.
12. The system as set forth in claim 11, wherein,
wherein generating the score further comprises generating the score according to:
f(x r ，a T )＝act(x T )+a T *(act(x T )-1)
wherein T is the predetermined future time period, x T Is the predicted revenue probability, a T Is the predicted abuse potential, and act () is a non-linear function ranging between-1 and 1.
13. The system of claim 12, wherein the non-linear function is one of a logistic function, a hyperbolic tangent function, and a modified linear unit function.
14. The system of claim 1, wherein generating the predicted likelihood comprises generating the predicted likelihood in response to a request for the additional computing resource from the first user account.
15. The system of claim 1, wherein the first and second sensors are disposed in a common housing,
wherein the operations further comprise executing, by the computing platform, a plurality of applications hosted on one or more of the plurality of computers, an
Wherein the one or more user accounts include one or more of:
an application account including data corresponding to the first user for interacting with one or more of the plurality of applications, an
A billing account comprising data corresponding to billing activity between the first user and one or more of the plurality of applications.
16. The system as set forth in claim 1, wherein,
wherein the computing resources allocated to the first user comprise computing resources configured to execute one or more virtual machines, an
Wherein the one or more user accounts include a virtual machine entity that includes data corresponding to virtual machine creation and use on the computing platform by the first user.
17. The system of claim 1, wherein the first and second sensors are disposed in a common housing,
wherein the operations further comprise one or more software items hosted on the computing platform by the computing platform, an
Wherein the one or more user accounts include a project entity that includes data corresponding to one or more projects authored or co-authored by the first user.
18. The system of claim 1, wherein the first quota represents one or both of:
an upper limit on computing resources to be allocated to the first user, an
An upper limit on a number of concurrent projects hosted on the computing platform and authored or coauthored by the first user.
19. The system of claim 1, wherein the operations further comprise sending, to a first user device associated with the first user, an indication that the additional computing resource has been allocated to the first user.
20. A computer-implemented method performed by a computing platform, comprising:
allocating up to a first quota of computing resources to a first user account of one or more user accounts representing a first user of the computing platform, wherein the first quota is an upper limit of computing resources allocated to the first user account;
receiving user account data from the one or more user accounts representing the first user;
generating a plurality of features from the user account data, wherein each feature is a measurable characterization of an interaction between the one or more user accounts and the computing platform; and
generating, based at least on the plurality of features, a score that represents, at least in part, a predicted likelihood that the additional computing resources allocated to the first user account will be used in violation of one or more predetermined abusive usage parameters during a predetermined future time period.
21. One or more computer-readable storage media storing instructions that are operable, when executed by a computing platform comprising one or more processors, to cause the one or more processors to perform operations comprising:
allocating up to a first quota of computing resources to a first user account of one or more user accounts representing a first user of the computing platform, wherein the first quota is an upper limit on computing resources allocated to the first user account;
receiving user account data from the one or more user accounts representing the first user;
generating a plurality of features from the user account data, wherein each feature is a measurable representation of an interaction between the one or more user accounts and the computing platform; and
generating, based at least on the plurality of features, a score that represents, at least in part, a predicted likelihood that the additional computing resources allocated to the first user account will be used in violation of one or more predetermined abusive usage parameters during a predetermined future time period.
Applications Claiming Priority (5)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US202063106177P | 2020-10-27 | 2020-10-27 | |
US63/106,177 | 2020-10-27 | ||
US17/382,973 US20220129318A1 (en) | 2020-10-27 | 2021-07-22 | Quota Request Resolution On Computing Platform |
US17/382,973 | 2021-07-22 | ||
PCT/US2021/046873 WO2022093370A1 (en) | 2020-10-27 | 2021-08-20 | Quota request resolution on computing platform |
Publications (1)
Publication Number | Publication Date |
---|---|
CN115485662A true CN115485662A (en) | 2022-12-16 |
Family
ID=81258388
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202180028013.8A Pending CN115485662A (en) | 2020-10-27 | 2021-08-20 | Quota request resolution on a computing platform |
Country Status (4)
Country | Link |
---|---|
US (1) | US20220129318A1 (en) |
EP (1) | EP4237944A1 (en) |
CN (1) | CN115485662A (en) |
WO (1) | WO2022093370A1 (en) |
Families Citing this family (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20230155902A1 (en) * | 2021-11-18 | 2023-05-18 | Zscaler, Inc. | Network traffic identification using machine learning |
Family Cites Families (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11106560B2 (en) * | 2018-06-22 | 2021-08-31 | EMC IP Holding Company LLC | Adaptive thresholds for containers |
US10868732B2 (en) * | 2019-04-02 | 2020-12-15 | Sap Se | Cloud resource scaling using programmable-network traffic statistics |
EP4028920A1 (en) * | 2019-09-13 | 2022-07-20 | Equifax, Inc. | Secure resource management to prevent resource abuse |
-
2021
- 2021-07-22 US US17/382,973 patent/US20220129318A1/en active Pending
- 2021-08-20 WO PCT/US2021/046873 patent/WO2022093370A1/en unknown
- 2021-08-20 CN CN202180028013.8A patent/CN115485662A/en active Pending
- 2021-08-20 EP EP21769300.1A patent/EP4237944A1/en active Pending
Also Published As
Publication number | Publication date |
---|---|
US20220129318A1 (en) | 2022-04-28 |
EP4237944A1 (en) | 2023-09-06 |
WO2022093370A1 (en) | 2022-05-05 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US20230316076A1 (en) | Unsupervised Machine Learning System to Automate Functions On a Graph Structure | |
US11720962B2 (en) | Systems and methods for generating gradient-boosted models with improved fairness | |
US20190378050A1 (en) | Machine learning system to identify and optimize features based on historical data, known patterns, or emerging patterns | |
US20190378049A1 (en) | Ensemble of machine learning engines coupled to a graph structure that spreads heat | |
US20190378051A1 (en) | Machine learning system coupled to a graph structure detecting outlier patterns using graph scanning | |
US20190377819A1 (en) | Machine learning system to detect, label, and spread heat in a graph structure | |
Fahrenkrog-Petersen et al. | Fire now, fire later: alarm-based systems for prescriptive process monitoring | |
US20170323216A1 (en) | Determining retraining of predictive models | |
US20180253728A1 (en) | Optimizing fraud analytics selection | |
US20190180290A1 (en) | Procurement fraud detection system | |
US11295328B2 (en) | Intelligent prospect assessment | |
US11860905B2 (en) | Scanning for information according to scan objectives | |
US11640470B1 (en) | System and methods for reducing an organization's cybersecurity risk by determining the function and seniority of employees | |
US20230087026A1 (en) | Performing an action based on predicted information | |
Fazzinga et al. | Online and offline classification of traces of event logs on the basis of security risks | |
Wang et al. | An unsupervised strategy for defending against multifarious reputation attacks | |
CN111598360A (en) | Service policy determination method and device and electronic equipment | |
US20220129318A1 (en) | Quota Request Resolution On Computing Platform | |
CN102214348A (en) | Data management for top-down risk-based auditing approach | |
Tasgetiren et al. | On the distributed software architecture of a data analysis workflow: A case study | |
US11625626B2 (en) | Performance improvement recommendations for machine learning models | |
CN112950359A (en) | User identification method and device | |
US20230169054A1 (en) | End-to-end identification of erroneous data using machine learning and similarity analysis | |
CN115965464A (en) | Empty shell enterprise identification method and device, storage medium and electronic device | |
Tziakouris et al. | Market‐inspired framework for securing assets in cloud computing environments |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |