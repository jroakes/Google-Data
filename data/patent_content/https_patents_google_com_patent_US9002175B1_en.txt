US9002175B1 - Automated video trailer creation - Google Patents
Automated video trailer creation Download PDFInfo
- Publication number
- US9002175B1 US9002175B1 US13/799,751 US201313799751A US9002175B1 US 9002175 B1 US9002175 B1 US 9002175B1 US 201313799751 A US201313799751 A US 201313799751A US 9002175 B1 US9002175 B1 US 9002175B1
- Authority
- US
- United States
- Prior art keywords
- video
- audience
- trailer
- videos
- segments
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N9/00—Details of colour television systems
- H04N9/79—Processing of colour television signals in connection with recording
- H04N9/87—Regeneration of colour television signals
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N5/00—Details of television systems
- H04N5/76—Television signal recording
-
- G—PHYSICS
- G11—INFORMATION STORAGE
- G11B—INFORMATION STORAGE BASED ON RELATIVE MOVEMENT BETWEEN RECORD CARRIER AND TRANSDUCER
- G11B27/00—Editing; Indexing; Addressing; Timing or synchronising; Monitoring; Measuring tape travel
-
- G—PHYSICS
- G11—INFORMATION STORAGE
- G11B—INFORMATION STORAGE BASED ON RELATIVE MOVEMENT BETWEEN RECORD CARRIER AND TRANSDUCER
- G11B27/00—Editing; Indexing; Addressing; Timing or synchronising; Monitoring; Measuring tape travel
- G11B27/02—Editing, e.g. varying the order of information signals recorded on, or reproduced from, record carriers
- G11B27/031—Electronic editing of digitised analogue information signals, e.g. audio or video signals
-
- G—PHYSICS
- G11—INFORMATION STORAGE
- G11B—INFORMATION STORAGE BASED ON RELATIVE MOVEMENT BETWEEN RECORD CARRIER AND TRANSDUCER
- G11B27/00—Editing; Indexing; Addressing; Timing or synchronising; Monitoring; Measuring tape travel
- G11B27/10—Indexing; Addressing; Timing or synchronising; Measuring tape travel
- G11B27/19—Indexing; Addressing; Timing or synchronising; Measuring tape travel by using information detectable on the record carrier
- G11B27/28—Indexing; Addressing; Timing or synchronising; Measuring tape travel by using information detectable on the record carrier by using information signals recorded by the same method as the main recording
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/43—Processing of content or additional data, e.g. demultiplexing additional data from a digital video stream; Elementary client operations, e.g. monitoring of home network or synchronising decoder's clock; Client middleware
- H04N21/442—Monitoring of processes or resources, e.g. detecting the failure of a recording device, monitoring the downstream bandwidth, the number of times a movie has been viewed, the storage space available from the internal hard disk
- H04N21/44213—Monitoring of end-user related data
- H04N21/44218—Detecting physical presence or behaviour of the user, e.g. using sensors to detect if the user is leaving the room or changes his face expression during a TV program
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/47—End-user applications
- H04N21/475—End-user interface for inputting end-user data, e.g. personal identification number [PIN], preference data
- H04N21/4756—End-user interface for inputting end-user data, e.g. personal identification number [PIN], preference data for rating content, e.g. scoring a recommended movie
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/80—Generation or processing of content or additional data by content creator independently of the distribution process; Content per se
- H04N21/83—Generation or processing of protective or descriptive data associated with content; Content structuring
- H04N21/845—Structuring of content, e.g. decomposing content into time segments
- H04N21/8456—Structuring of content, e.g. decomposing content into time segments by decomposing the content in the time domain, e.g. in time segments
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/80—Generation or processing of content or additional data by content creator independently of the distribution process; Content per se
- H04N21/85—Assembly of content; Generation of multimedia applications
- H04N21/854—Content authoring
- H04N21/8549—Creating video summaries, e.g. movie trailer
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N5/00—Details of television systems
- H04N5/76—Television signal recording
- H04N5/765—Interface circuits between an apparatus for recording and another apparatus
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N9/00—Details of colour television systems
- H04N9/79—Processing of colour television signals in connection with recording
- H04N9/80—Transformation of the television signal for recording, e.g. modulation, frequency changing; Inverse transformation for playback
- H04N9/82—Transformation of the television signal for recording, e.g. modulation, frequency changing; Inverse transformation for playback the individual colour picture signal components being recorded simultaneously only
- H04N9/8205—Transformation of the television signal for recording, e.g. modulation, frequency changing; Inverse transformation for playback the individual colour picture signal components being recorded simultaneously only involving the multiplexing of an additional signal and the colour video signal
Definitions
- the field generally relates to video content and, more particularly, to generating samples of video content.
- a video channel is a collection or grouping of videos that may be associated with, for example, a particular user, subject, or theme.
- a user may promote a video channel to generate interest, subscribers, and views from others.
- users do not typically promote online video channels with video trailers because the process of creating a trailer is manual, complex, and time-consuming. Further, video trailer creation requires video editing software, editing skills, and is costly to produce.
- Embodiments generally relate to the automated generation of video trailers.
- a processor computes blended audience retention for video segments based on audience retention rates for each of the video segments across corresponding points in time.
- the processor analyzes the blended audience retention for the video segments across corresponding points in time.
- the processor identifies one or more audience engagement peaks for the video segments based on the analyzing, selects one or more video clips from the video segments based on the identified audience engagement peaks, and generates a video trailer using the selected video clips into a new video.
- a system including a memory and a processing device coupled with the memory is configured to compute blended audience retention for video segments based on audience retention rates for each of the video segments across corresponding points in time.
- the system is also configured to analyze the blended audience retention for the video segments across corresponding points in time.
- the system identifies one or more audience engagement peaks for the video segments based on the analyzing, selects one or more video clips from the video segments based on the identified audience engagement peaks, and generates a video trailer using the selected video clips into a new video.
- a computer-readable medium has instructions stored thereon that when executed by a processor, cause the processor to perform operations.
- the instructions include computer-readable program code configured to cause the processor to compute blended audience retention for video segments based on audience retention rates for each of the video segments across corresponding points in time, analyze the blended audience retention for the video segments across corresponding points in time, identify one or more audience engagement peaks for the video segments based on the analyzing, select one or more video clips from the video segments based on the identified audience engagement peaks, and generate a video trailer using the selected video clips into a new video.
- FIG. 1 illustrates an exemplary system architecture, in accordance with various embodiments of the present disclosure.
- FIG. 2 is a block diagram of an automated video trailer generation system, in accordance with an embodiment.
- FIG. 3 is a flow diagram illustrating automated video trailer generation, according to an embodiment.
- FIG. 4A is a diagram generally illustrating audience retention for a video, according to an embodiment.
- FIG. 4B is a diagram illustrating relative audience retention for a video as compared to average retention computed for a collection of videos, according to an embodiment.
- FIG. 5 is a flow diagram illustrating additional aspects of automated video trailer generation, according to an embodiment.
- FIG. 6 is a diagram illustrating determination of audience engagement peaks in a video, according to an embodiment.
- FIG. 7 is a block diagram of an exemplary computer system that may perform one or more of the operations described herein.
- Video trailers are not typically used to promote online videos because of the associated complexity and expense. For example, creating a video trailer is a manual and time-consuming process, which usually requires video editing software and editing skills. Further, it is costly to outsource video trailer creation and new content is typically added to channels on a regular basis. Therefore, most users choose to promote their online videos by other means or not at all.
- Embodiments of the present disclosure allow a user to automatically generate a video trailer from a collection of videos. For example, a user may submit a request to generate a promotional video trailer advertisement for one or more video channels on a video sharing website or via an application running on a user device (e.g., a mobile phone or a tablet).
- a user device e.g., a mobile phone or a tablet.
- the video sharing website may receive the user request and select one or more interesting or popular videos from the channels to consider.
- the video sharing website may analyze video segments from the selected videos by comparing audience retention throughout a video segment to the average audience retention computed for a group of video segments.
- the video sharing website may identify audience engagement peaks within the video segments based on the analysis and select video clips corresponding to the identified audience engagement peaks.
- the video sharing website then may generate a video trailer by combining the video clips into a new video.
- the generated video trailer may be provided to a user for consideration and approval. Once approved, the generated video trailer may be used to promote the online video channels to other users.
- aspects of the present disclosure allow users to create appealing and informative video trailers for channels with minimal effort.
- channel administrators will be more likely to promote channels using video trailers, and other users will be more likely to discover content of interest by viewing the video trailers.
- FIG. 1 illustrates exemplary system architecture 100 in which embodiments can be implemented.
- the system architecture 100 includes a server machine 110 , a data store 140 and client machines 102 A- 102 N connected to a network 104 .
- Network 104 may be a public network (e.g., the Internet), a private network (e.g., a local area network (LAN) or wide area network (WAN)), or a combination thereof.
- LAN local area network
- WAN wide area network
- Data store 140 is persistent storage that is capable of storing various types of data, such as video and image content.
- data store 140 might be a network-attached file server, while in other embodiments data store 140 might be some other type of persistent storage such as an object-oriented database, a relational database, and so forth.
- Data store 140 may include user generated content (e.g., user generated videos) that is uploaded by client machines 102 A- 102 N. The data may additionally or alternatively include content provided by one or more other parties.
- Video content may be added to the data store 140 as discrete files (e.g., motion picture experts group (MPEG) files, windows media video (WMV) files, joint photographic experts group (JPEG) files, graphics interchange format (GIF) files, portable network graphics (PNG) files, etc.) or as components of a single compressed file (e.g., a zip file).
- MPEG motion picture experts group
- WMV windows media video
- JPEG joint photographic experts group
- GIF graphics interchange format
- PNG portable network graphics
- the client machines 102 A- 102 N may be personal computers (PC), laptops, mobile phones, tablet computers, or any other computing device.
- the client machines 102 A- 102 N may run an operating system (OS) that manages hardware and software of the client machines 102 A- 102 N.
- OS operating system
- a browser (not shown) may run on the client machines (e.g., on the OS of the client machines).
- the browser may be a web browser that can access content served by a web server.
- the browser may display video content and other visual media provided by a web server and may allow editing of videos and other visual media.
- Server machine 110 may be a rackmount server, a router computer, a personal computer, a portable digital assistant, a mobile phone, a laptop computer, a tablet computer, a camera, a video camera, a netbook, a desktop computer, a media center, or any combination of the above.
- Server machine 110 may include a web server 120 and a video trailer generation system 130 .
- the web server 120 and video trailer generation system 130 may run on one or more different machines.
- Web server 120 may serve video content from data store 140 to clients 102 A- 102 N. Clients 102 A- 102 N may locate, access and view video content from web server 120 using a web browser. Web server 120 also may receive video content from clients 102 A- 102 N that is saved in data store 140 for purposes that may include preservation and distribution.
- Web server 120 may receive queries for video content and perform searches for video content using data store 140 to locate video data satisfying the search queries. Web server 120 may then send to a client 102 A- 102 N video data results matching the search query.
- web server 120 provides an application configured to allow clients 102 A- 102 N to upload, preview, edit, display, generate, publish, and promote video content.
- Such functionality may be provided, for example, as one or more different web applications, standalone applications, systems, plugins, web browser extensions, and application programming interfaces (APIs).
- some clients 102 A- 102 N can include applications that are associated with a service provided by server 110 . Examples of client machines that may use such applications (“apps”) include mobile phones, “smart” televisions, tablet computers, and so forth.
- the applications or apps may access content provided by server 110 , issue commands to server 110 , receive content from server 110 , and so on, without visiting web pages of server 110 .
- functions described in one embodiment as being performed by server 110 or web server 120 can also be performed on the client machines 102 A- 102 N in other embodiments if appropriate.
- the functionality attributed to a particular component can be performed by different or multiple components operating together.
- the server 110 can also be accessed as a service provided to other systems or devices through appropriate application programming interfaces, and thus is not limited to use in websites.
- a video is a set of sequential image frames representing a scene in motion. For example, a series of sequential images may be captured continuously or later reconstructed to produce animation.
- Video content may be presented in various formats including, but not limited to, analog, digital, two-dimensional and three-dimensional video. Further, video content may include movies, video clips, or any set of animated images to be displayed in sequence.
- Video trailer generation system 130 may automatically generate one or more video trailers from a collection of videos.
- a video trailer may be, for example, a short video advertisement used to promote one or more other videos.
- a video trailer may highlight one or more interesting scenes or exchanges within the other videos as a way of generating interest, views, and followers.
- video trailer generation system 130 may select one or more interesting or popular videos from a collection of videos that have been uploaded by one or more clients 102 A- 102 N. Video trailer generation system 130 then may analyze portions of the selected videos to identify popular video clips based on previous viewings. Video trailer generation system 130 then may generate a video trailer automatically using the selected video clips.
- web server 120 provides an application to clients 102 A- 102 N.
- the application may include a graphical user interface configured to allow users to upload, display, manage, generate, publish, and promote video content.
- the application also may include or utilize a video trailer generation system 130 .
- video trailer generation system 130 may receive a request to generate a video trailer from a collection of one or more videos.
- the request for example, may be initiated by a user in real-time, or may be a previously or regularly scheduled request.
- a request to generate a video trailer also may be received in response to a corresponding suggestion provided to a user.
- a user may initiate a request to generate a video trailer, for example, by using one or more commands (e.g., voice, text, motion) or by performing one or more actions/interactions with the graphical user interface (e.g., button click, keyboard shortcut).
- video trailer generation may occur based on one or more of a system setting, user preference, user request, or default.
- a graphical user interface is configured to allow a user to initiate generation of a video trailer, to preview one or more generated video trailers, to rate one or more generated video trailers, to approve one or more generated video trailers, and to store one or more generated video trailers.
- the graphical user interface also may be configured to allow a user to publish and/or promote a generated video trailer as part of an advertising campaign.
- a video trailer may be generated using one or more different types of content available for a channel or group of channels.
- a channel generally describes data or content available from a common source or having a common subject or theme.
- a channel may contain information in the form of audio clips, movie clips, TV clips, and music videos, as well as content such as blogs, social media pages, short original videos, pictures, photos, articles, avatars, software programs, games, etc.
- FIG. 2 is a block diagram of an automated video trailer generation system 130 , in accordance with an embodiment.
- the automated video trailer generation system 130 includes a request receiving module 202 , a video selection module 204 , a video analysis module 206 , a video trailer generation module 208 , and a video trailer delivery module 210 .
- functionality associated with one or more of request receiving module 202 , a video selection module 204 , a video analysis module 206 , a video trailer generation module 208 , and a video trailer delivery module 210 may be combined, divided and organized in various arrangements.
- automated video trailer generation system 130 is coupled to data store 140 and working data store 240 .
- Data store 140 includes video data 220 .
- Working data store 240 includes temporary video data 250 .
- Video data 220 generally refers to any type of moving image, which includes, but is not limited to movie films, videos, digital videos and other forms of animated drawings or display.
- video data 220 may include digital videos having a sequence of static image frames that also may be stored as image data.
- each image frame may represent a snapshot of a scene that has been captured according to a time interval.
- Video data 220 may include computer animations, including two-dimensional and three-dimensional graphics. Video data 220 also may include any sequence of images, including graphical drawings that create an illusion of movement.
- automated video trailer generation system 130 utilizes working data store 240 as a temporary storage space to perform calculations, analyze video data 220 , and generate video trailers.
- Working data store 240 may include, for example, any type or combination of volatile and non-volatile storage (e.g., disk, memory).
- working data store 240 contains temporary video data 250 .
- temporary video data 250 may include one or more copies of video data 220 , such as an original version, a modified version, or a generated video trailer.
- Working data store 240 also may include temporary data and results produced by video trailer generation system 130 .
- working data store 240 may include one or more selected videos, one or more of video segments from the selected videos, one or more video clips identified from the video segments, one or more adjusted video clips, and one or more video trailers generated from the video clips.
- video trailer generation system 130 may use working data store 240 , for example, to perform calculations, to persist intermediate processing results, and to provide generated video trailers to users for review, approval, and/or distribution.
- Request receiving module 202 receives requests from users to generate video trailers. For example, a user managing a collection of one or more videos on website may request automatic generation of one or more video trailers. Request receiving module 202 may receive the user request and initiate video trailer generation processing for the collection of videos.
- request receiving module 202 receives a system request to generate a video trailer for a collection of one or more videos.
- one or more video trailers may be generated automatically for a video collection without user input. The generated video trailers then may be provided to user automatically for review and consideration.
- Video selection module 204 determines which videos from a collection will be considered as part of the video trailer generation process. In an embodiment, video selection module 204 selects one or more videos to analyze from a video collection.
- Video selection module 204 may analyze and compare one or more attributes of videos to determine which videos will be considered in the video trailer generation process.
- Video analysis module 206 analyzes video segments from selected videos and identifies audience engagement peaks occurring in the video segments. In an embodiment, video analysis module 206 determines one or more video segments to analyze from each of the selected videos. In an example, video segments may be determined based on a uniform or near-uniform length to facilitate comparison of the video segments that otherwise might be of unequal lengths.
- video analysis module 206 computes blended audience retention for a set of video segments. For example, video analysis module 206 may average the computed audience retention rate throughout each of a plurality of equal length or near equal length video segments. Blended audience retention generally refers to averaging audience retention rates (e.g., a percentage of retained viewers) across a number of video segments. In one example, blended audience retention for a set of video segments may reflect an average audience retention rate as measured at a plurality of different time intervals (e.g., every second) or continuously throughout the duration of the video segments.
- video analysis module 206 analyzes the video segments by comparing audience retention computed in each of the video segments to the blended audience retention computed for the group of video segments. For example, video analysis module 206 may compare audience retention of a video segment to the blended audience retention at corresponding time intervals to compute a relative retention ratio. For example, a video segment with an audience retention rate of 80% at a point in time (e.g., 80 out of 100 viewers continued to watch the video at a point in time) could be compared to blended audience retention of 40% for all of the video segments at a corresponding point in time. Thus, the video segment may be said to have an audience retention ratio of 2.0 (i.e., two times the average rate) as compared to the blended audience retention.
- video analysis module 206 identifies one or more audience engagement peaks for the video segments. In one example, video analysis module 206 determines audience engagement peaks in a video segment based on one or more of the largest audience retention ratio values computed for a video segment.
- video analysis module 206 selects one or more video clips from the video segments based on identified audience engagement peaks. For example, video analysis module 206 may identify one or more audience engagement peaks in a video segment based on the highest computed relative retention ratios.
- video analysis module 206 may identify an audience engagement peak within one or more video segments based on the highest relative retention ratios computed for each of the video segments. Video analysis module 206 also may identify a plurality of audience engagement peaks in one or more video segments, for example, by choosing one or more of the highest, distributed relative retention ratios computed for each of the video segments.
- video analysis module 206 selects one or more video clips from the video segments based on the identified audience engagement peaks. In one example video analysis module 206 selects a video clip from a video segment by capturing a portion of the video segment around an identified audience engagement peak. (e.g., 10 seconds before and 5 seconds after each identified audience engagement peak).
- Video trailer generation module 208 generates video trailers by assembling and adjusting selected video clips into a new video.
- video trailer generation module 208 receives a set of selected video clips from video analysis module 206 .
- Video trailer generation module 208 then may adjust the selected video clips by arranging a sequence, shortening video clip length, providing visual transitions, providing audio transitions, removing audio, applying a new soundtrack, and/or applying textual description related to an associated video channel.
- Video trailer delivery module 210 provides a generated video trailer to a user.
- video trailer delivery module 210 may receive a generated video trailer from video trailer generation module 208 .
- Video trailer delivery module 210 then may provide the generated video trailer to a requesting user (e.g., video channel administrator) for review and approval.
- a requesting user e.g., video channel administrator
- video trailer delivery module 210 also may provide the generated video trailer as an advertisement presented to other users.
- the generated video trailer may be displayed in an advertising space on a website or before playing another online video to promote a video channel associated with the generated video trailer.
- FIG. 3 is a flow diagram illustrating automatic creation of a video trailer, according to an embodiment.
- the method 300 is performed by processing logic that may comprise hardware (circuitry, dedicated logic, etc.), software (such as is run on a general purpose computer system or a dedicated machine), or a combination of both.
- the method 300 is performed by the server machine 110 of FIG. 1 .
- the method 300 may be performed by video trailer generation system 130 running on server machine 110 or one or more other computing devices.
- Method 300 begins at stage 302 , when blended audience retention is computed across a set of video segments.
- a set of one or more video segments from one or more videos are provided.
- Each of the video segments may be the same length, may be nearly the same length, or may be of different lengths. Further, each of the video segments may be associated audience retention data.
- a video may have an audience retention rate from 0-100% at any point in time throughout the video's duration.
- the audience retention rate may be determined by comparing a number of viewers who continue to watch a video at a point in time to the total number of users that have viewed the video. For example, if 100 users have viewed a video and 75 of the users continued to watch the video at the two-minute mark, then the audience retention rate would be 75% at that point in time.
- Audience retention data for a video may be provided with the video as pre-collected information or may be collected and compiled from one or more other sources.
- FIG. 4A generally illustrates audience retention for a video, according to an embodiment.
- Diagram 400 includes general audience retention ranges 402 , video time scale 404 , a point in time within the video 406 , measured audience retention throughout the video 408 (i.e., audience retention curve), and an audience retention rate measured at a specific point in time 410 .
- video analysis module 206 uses audience retention data to compute blended audience retention for a group of video segments. For example, video analysis module 206 may average audience retention rates across a set of equal length or near equal length video segments.
- the audience retention rates used to compute blended audience retention for a set of video segments may be weighted equally. For example, audience retention at a single point in time for three different videos may be (1) 80%, (2) 70%, and (3) 30%. Thus, blended audience retention for the single point in time would be 60% (i.e., 180/3).
- the audience retention rates used to compute blended audience retention may be weighted based on one or more factors.
- blended audience retention may be computed based on a number of user views (not straight percentages as computed above). Thus, a video with a higher number of views would have greater influence, and a video with fewer views would have less influence in blended audience retention computations.
- Stage 302 may be performed by, for example, video analysis module 206 .
- each of the video segments is analyzed by comparing audience retention in a video segment to the blended audience retention.
- each of the video segments is analyzed by comparing audience retention rates in a segment to the blended audience retention for all of the video segments. For example, relative retention ratios may be computed by comparing video segment audience retention rates to blended audience retention for the video segments at corresponding points in time.
- a video segment with an audience retention rate of 90% at a point in time would have a relative retention ratio of 2.0 as compared to a blended audience retention of 45% at the same point in time.
- an relative retention ratio of 1.0 would mean that the audience retention rate of the video segment is equivalent to the blended audience retention rate at the same point in time.
- a relative retention ratio less than 1.0 indicates that the video segment lags behind the average audience retention for the video segments at a particular point in time.
- Stage 304 may be performed by, for example, video analysis module 206 .
- FIG. 4B is a diagram that generally illustrates relative audience retention for a video compared to blended audience retention computed for a collection of videos, according to an embodiment.
- Diagram 420 includes audience retention ranges 422 based on computed audience retention ratios.
- Diagram 420 also includes video time scale 424 , a point in time within the video 426 , a first audience engagement peak 428 , a second audience engagement peak 430 , and a discarded audience engagement peak 432 .
- an audience engagement peak may be discarded, for example, if the peak occurs within a specific portion of the video, such as the first 1, 2, 5, 10 or 15 seconds, which may be considered too early for an accurate indication.
- one or more audience engagement peaks are identified for the video segments.
- identification of audience engagement peaks may be based on relative retention ratios calculated for a video segment.
- one or more of the highest relative retention ratios occurring at different ranges of time in a video segment may be identified as audience engagement peaks for the video segment (e.g., the top one, two, or three relative retention ratios that do not coincide within a 15-second range of time).
- audience engagement peaks also may be contingent on other criteria, such as a minimum audience retention ratio, a maximum number of audience engagement peaks for a video segment, when an audience engagement peak occurs in a video segment, duration, and/or slope(s).
- Audience engagement peaks also may be identified across video segments. For example, audience engagement peaks may be defined as the top three audience retention ratio values as measured within fifteen second intervals across six different video segments.
- Stage 306 may be performed by, for example, video analysis module 206 .
- one or more video clips are selected from the video segments based on the identified audience engagement peaks.
- a portion of a video associated with an identified audience engagement peak is selected as a video clip.
- four identified engagement peaks may be used to generate a 60 second video trailer.
- four video clips that begin 10 seconds before and ends 5 seconds after each of the identified audience retention peaks may be selected to produce the 60 seconds of content for the video trailer.
- the duration of selected video clips may be based on one or more user defined or system parameters.
- one or more parameters may specify an amount of video content to select before and/or after an identified engagement peak, for example, to provide viewers with context.
- Duration of selected video clips also may be non-uniform and may be based on, for example, a duration of an audience retention peak.
- Stage 308 may be performed by, for example, video analysis module 206 .
- a video trailer is generated by combining the selected video clips into a new video.
- selected video clips are assembled to generate a video trailer.
- one or more visual effects may be used to transition between video clips.
- no visual effects are used when transitioning between video clips.
- audio associated with one or more of the selected video clips may be modified.
- audio of a first video clip may gradually decrease as a scene is transitioned or cut over to a second video clip.
- audio of the second video clip may gradually increase until presented at a normal volume.
- the audio transition between the first video clip and the second video clip may or may not be performed proportionally.
- audio associated with a selected video clip may be erased and replaced by different audio, such as a soundtrack, a voice-over or other sound.
- a summarized version of information associated with a video channel is presented in the video trailer.
- a summarized version of information associated with a video channel is displayed with video trailer content near the end of a trailer.
- the video trailer may be reduced to a portion of the display (e.g., half of the top, bottom, left or right side of the display), and a summarized version of information associated with a video channel may be presented alongside the video trailer on the other portion of the display.
- the summarized information associated with the video channel may include, for example, a number of subscribers, user comments received for the channel, user comments received for videos associated with the channel, and comments from a user that manages the channel.
- the summarized information is automatically generated and incorporated into the video trailer.
- the summarized information is linked to the video trailer and dynamically updated on a regular or periodic basis.
- one or more aspects of the summarized information may be selected and/or provided by a user that manages the video channel.
- one or more actionable prompts may be included in one or more locations throughout a generated video trailer.
- selectable text overlays, speech bubbles, notes, titles, hyperlinks, spotlights, images, labels, or any combination thereof may allow a viewer to access a full version of a highlighted video, to subscribe to a channel, to visit a related website, and/or to perform one or more other actions.
- one or more actionable prompts may be generated automatically as part of generating a video trailer.
- actionable prompts may be generated with a video trailer based on one or more pre-defined templates and/or one or more sets of stored instructions.
- one or more actionable prompts may be added to a video trailer after the video trailer has been generated.
- actionable prompts may be defined in an editor and inserted into or linked to a portion of a generated video trailer.
- An editor also may allow modification and removal of actionable prompts that already have been packaged or associated with a generated video trailer.
- actionable prompts may be integrated directly into a generated video trailer and/or may be linked to and updated independently from the generated video trailer.
- Stage 310 may be performed by, for example, video trailer generation module 208 .
- FIG. 5 is a flow diagram illustrating additional aspects of automated video trailer generation, according to an embodiment.
- the method 500 is performed by processing logic that may comprise hardware (circuitry, dedicated logic, etc.), software (such as is run on a general purpose computer system or a dedicated machine), or a combination of both.
- the method 500 is performed by the server machine 110 of FIG. 1 .
- the method 500 may be performed by video trailer generation system 130 running on server machine 110 or one or more other computing devices.
- Method 500 begins at stage 502 , when a request to generate a video trailer for a collection of one or more videos is received.
- request receiving module 202 receives a user request to generate a video trailer for one or more videos associated with one or more online video channels.
- a user may request generation of a video trailer for a single video channel.
- a user may request generation of a video trailer for a plurality of video channels.
- a user may request generation of a video trailer for an entire category of related video channels, such as cooking, sports, or comedy.
- Stage 502 may be performed by, for example, request receiving module 202 .
- one or more videos are selected from the collection of videos for consideration based on the user request.
- one or more videos are selected from a collection of videos based on one or more video attributes.
- video selection may be based on one or more of how many times a video has been viewed (e.g., by distinct users or total views), how many “likes” a video has received, how many times users have commented about a video, the words users have used to describe a video, how many times users have shared a video with others, how many times users have recommended a video, an average rating given to a video by users, video length, and/or how many follow-on views (e.g., sum or average) a video has generated for a channel.
- follow-on views generally refer to a number of times that videos in a channel have been viewed after a user views their first video in the channel.
- one or more video attributes may be weighted and/or combined to produce a video score. Videos may be ranked based on the score and selected, for example, based on a ranking or for meeting/exceeding one or more thresholds. Videos also may be excluded from selection, for example, when not meeting or exceeding one or more thresholds. Stage 504 may be performed by, for example, video selection module 204 .
- one or more video segments are determined for analysis from each of the selected videos.
- video segments are unmodified versions of the selected videos. For example, selected videos of uniform length or near uniform length may be compared without any further modification.
- video segments are modified versions of the selected videos.
- an early portion of each video is disregarded to normalize audience retention statistics across a set of videos.
- one or more portions of a video are trimmed to produce a video segment of a standard duration for comparison with other videos of or near the standard duration.
- Stage 506 may be performed by, for example, video analysis module 206 .
- blended audience retention is computed for the video segments.
- blended audience retention is computed by averaging audience retention rates of the video segments across the duration of the video segments.
- Stage 508 may be performed by, for example, video analysis module 206 .
- the video segments are analyzed by comparing audience retention in each of the video segments to the blended audience retention computed for the video segments.
- relative retention ratio is computed throughout a video segment by comparing a video segment's audience retention rate at various points in time to blended audience retention computed for the video segments at corresponding points in time.
- Stage 510 may be performed by, for example, video analysis module 206 .
- one or more audience engagement peaks are identified in each of the video segments.
- a defined time interval is used to continuously compute audience retention across an entire video segment based on relative audience retention.
- relative audience retention for a video segment is determined by computing an integral of relative audience retention (i.e., the area under the relative retention ratio curve) across a video segment in sets of continuous 15-second time intervals.
- Time intervals having the highest computed relative retention include audience engagement peaks in the video segment.
- the time interval, number of audience engagement peaks to identify, and spacing between audience engagement peaks may be defined as one or more of a system default, system setting, or user preference.
- Stage 512 may be performed by, for example, video analysis module 206 .
- FIG. 6 is a diagram illustrating determination of audience engagement peaks in a video, according to an embodiment.
- Diagram 600 includes relative retention ranges 602 based on relative audience retention computed for a video segment and video time scale 604 .
- Diagram 600 also includes time intervals 610 and 620 , and audience engagement peaks 612 and 622 .
- Aggregate audience retention for a time interval may be calculated by computing the area under the relative audience retention curve 626 .
- Areas 614 and 624 each represent aggregate audience retention respectively for time intervals 610 and 620 .
- one or more of the video clips are selected based on the identified audience engagement peaks. According to an embodiment, one or more video clips may be selected based on a level of determined audience engagement. In another embodiment, one or more video clips may be selected to provide additional content variety in a generated video trailer. Stage 514 may be performed by, for example, video analysis module 206 .
- one or more of the selected video clips are adjusted.
- duration of one or more selected video clips is adjusted.
- length of a selected video clip may be extended to provide additional video content for a video trailer.
- length of a selected video clip may be reduced.
- a selected video clip may be further analyzed using shot boundary detection analysis to determine whether a camera shot transition occurs in the selected video clip. When a camera shot transition is detected then the selected video clip may be adjusted, for example, by removing the portion of the video before or after the detected event. In one example, selected video clips determined to have a camera shot transition may be excluded from the video trailer. Stage 516 may be performed by, for example, video analysis module 206 .
- a video trailer is generated by combining the selected video clips into a new video.
- one or more video trailers are generated from the selected video clips based on a ranking of the selected video clips according to relative audience retention.
- a minimum number of video clips are selected from one or more of the video segments to provide variety.
- selected video clips from one or more different videos may be used to assemble different combinations video clips, and thus generate multiple video trailers for consideration.
- Stage 518 may be performed by, for example, video trailer generation model 208 .
- the generated video trailer is provided to a user.
- the generated video trailer may be provided to a user for approval.
- an approved video trailer may be provided to other users to promote one or more online video channels associated with the video trailer.
- Stage 520 may be performed by, for example, video trailer delivery module 210 .
- FIG. 7 illustrates a diagram of a machine in the exemplary form of a computer system 700 within which a set of instructions, for causing the machine to perform any one or more of the methodologies discussed herein, may be executed.
- the machine may be connected (e.g., networked) to other machines in a LAN, an intranet, an extranet, or the Internet.
- the machine may operate in the capacity of a server or a client machine in client-server network environment, or as a peer machine in a peer-to-peer (or distributed) network environment.
- the machine may be a personal computer (PC), a tablet PC, a set-top box (STB), a Personal Digital Assistant (PDA), a cellular telephone, a web appliance, a server, a network router, switch or bridge, or any machine capable of executing a set of instructions (sequential or otherwise) that specify actions to be taken by that machine.
- PC personal computer
- PDA Personal Digital Assistant
- STB set-top box
- WPA Personal Digital Assistant
- a cellular telephone a web appliance
- server a server
- network router switch or bridge
- the exemplary computer system 700 includes a processing device (processor) 702 , a main memory 704 (e.g., read-only memory (ROM), flash memory, dynamic random access memory (DRAM) such as synchronous DRAM (SDRAM), double data rate (DDR SDRAM), or DRAM (RDRAM), etc.), a static memory 706 (e.g., flash memory, static random access memory (SRAM), etc.), and a data storage device 718 , which communicate with each other via a bus 730 .
- a processing device e.g., a main memory 704
- main memory 704 e.g., read-only memory (ROM), flash memory, dynamic random access memory (DRAM) such as synchronous DRAM (SDRAM), double data rate (DDR SDRAM), or DRAM (RDRAM), etc.
- DRAM dynamic random access memory
- SDRAM synchronous DRAM
- DDR SDRAM double data rate
- RDRAM DRAM
- static memory 706 e.g., flash memory, static random access memory
- Processor 702 represents one or more general-purpose processing devices such as a microprocessor, central processing unit, or the like. More particularly, the processor 702 may be a complex instruction set computing (CISC) microprocessor, reduced instruction set computing (RISC) microprocessor, very long instruction word (VLIW) microprocessor, or a processor implementing other instruction sets or processors implementing a combination of instruction sets.
- the processor 702 may also be one or more special-purpose processing devices such as an application specific integrated circuit (ASIC), a field programmable gate array (FPGA), a digital signal processor (DSP), network processor, or the like.
- the processor 702 is configured to execute instructions 722 for performing the operations and steps discussed herein.
- the computer system 700 may further include a network interface device 708 .
- the computer system 700 also may include a video display unit 710 (e.g., a liquid crystal display (LCD) or a cathode ray tube (CRT)), an alphanumeric input device 712 (e.g., a keyboard), a cursor control device 714 (e.g., a mouse), and a signal generation device 716 (e.g., a speaker).
- a video display unit 710 e.g., a liquid crystal display (LCD) or a cathode ray tube (CRT)
- an alphanumeric input device 712 e.g., a keyboard
- a cursor control device 714 e.g., a mouse
- a signal generation device 716 e.g., a speaker
- the data storage device 718 may include a computer-readable storage medium 728 on which is stored one or more sets of instructions 722 (e.g., software) embodying any one or more of the methodologies or functions described herein.
- the instructions 722 may also reside, completely or at least partially, within the main memory 704 and/or within the processor 702 during execution thereof by the computer system 700 , the main memory 704 and the processor 702 also constituting computer-readable storage media.
- the instructions 722 may further be transmitted or received over a network 720 via the network interface device 708 .
- the instructions 722 include instructions for a video trailer generation system (e.g., video trailer generation system 130 of FIG. 1 ) and/or a software library containing methods that call a video trailer generation system.
- a video trailer generation system e.g., video trailer generation system 130 of FIG. 1
- a software library containing methods that call a video trailer generation system.
- the computer-readable storage medium 728 (machine-readable storage medium) is shown in an exemplary embodiment to be a single medium, the term “computer-readable storage medium” should be taken to include a single medium or multiple media (e.g., a centralized or distributed database, and/or associated caches and servers) that store the one or more sets of instructions.
- computer-readable storage medium shall also be taken to include any medium that is capable of storing, encoding or carrying a set of instructions for execution by the machine and that cause the machine to perform any one or more of the methodologies of the present disclosure.
- computer-readable storage medium shall accordingly be taken to include, but not be limited to, solid-state memories, optical media, and magnetic media.
- inventions of the present disclosure also relate to an apparatus for performing the operations herein.
- This apparatus may be constructed for the intended purposes, or it may comprise a general-purpose computer selectively activated or reconfigured by a computer program stored in the computer.
- a computer program may be stored in a computer readable storage medium, such as, but not limited to, any type of disk including floppy disks, optical disks, CD-ROMs, and magnetic-optical disks, read-only memories (ROMs), random access memories (RAMs), EPROMs, EEPROMs, magnetic or optical cards, or any type of media suitable for storing electronic instructions.
Abstract
Description
Claims (20)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US13/799,751 US9002175B1 (en) | 2013-03-13 | 2013-03-13 | Automated video trailer creation |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US13/799,751 US9002175B1 (en) | 2013-03-13 | 2013-03-13 | Automated video trailer creation |
Publications (1)
Publication Number | Publication Date |
---|---|
US9002175B1 true US9002175B1 (en) | 2015-04-07 |
Family
ID=52745208
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US13/799,751 Active 2033-05-29 US9002175B1 (en) | 2013-03-13 | 2013-03-13 | Automated video trailer creation |
Country Status (1)
Country | Link |
---|---|
US (1) | US9002175B1 (en) |
Cited By (17)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN106231399A (en) * | 2016-08-01 | 2016-12-14 | 乐视控股（北京）有限公司 | Methods of video segmentation, equipment and system |
US9635337B1 (en) * | 2015-03-27 | 2017-04-25 | Amazon Technologies, Inc. | Dynamically generated media trailers |
CN108307229A (en) * | 2018-02-02 | 2018-07-20 | 新华智云科技有限公司 | A kind of processing method and equipment of video-audio data |
CN109831678A (en) * | 2019-02-26 | 2019-05-31 | 中国联合网络通信集团有限公司 | Short method for processing video frequency and system |
US10334326B2 (en) | 2017-11-08 | 2019-06-25 | Roku, Inc. | Enhanced playback bar |
US10390077B2 (en) | 2017-03-15 | 2019-08-20 | The Directv Group, Inc. | Collective determination of interesting portions of a media presentation, media tagging and jump playback |
US10455266B2 (en) | 2013-01-02 | 2019-10-22 | Amazon Technologies, Inc. | Personalized smart-list video channels |
US20190387287A1 (en) * | 2017-11-08 | 2019-12-19 | Roku, Inc. | Automatically and programmatically generating crowdsourced trailers |
US10636449B2 (en) | 2017-11-06 | 2020-04-28 | International Business Machines Corporation | Dynamic generation of videos based on emotion and sentiment recognition |
US10694222B2 (en) | 2016-01-07 | 2020-06-23 | Microsoft Technology Licensing, Llc | Generating video content items using object assets |
US10917702B2 (en) | 2018-12-13 | 2021-02-09 | At&T Intellectual Property I, L.P. | Creating customized short-form content from long-form content |
CN113286179A (en) * | 2021-04-21 | 2021-08-20 | 北京爱奇艺科技有限公司 | Processing method and device for jumping-out curve, electronic equipment and storage medium |
US11169767B2 (en) * | 2017-09-29 | 2021-11-09 | Spotify Ab | Automatically generated media preview |
US11388488B2 (en) * | 2017-11-27 | 2022-07-12 | Rovi Guides, Inc. | Systems and methods for dynamically extending or shortening segments in a playlist |
US11509962B2 (en) | 2020-12-14 | 2022-11-22 | Disney Enterprises, Inc. | Curating narrative experiences through automated content compilation |
US20220382442A1 (en) * | 2020-09-25 | 2022-12-01 | Beijing Zitiao Network Technology Co., Ltd. | Method and apparatus for user guide, device and storage medium |
US11770572B1 (en) * | 2023-01-23 | 2023-09-26 | Adrennial Inc. | Content distribution platform for uploading and linking content to products and services |
Citations (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20040158865A1 (en) * | 2001-05-24 | 2004-08-12 | Kubler Kenneth M. | System and method for managing in-theater display advertisements |
US8745647B1 (en) * | 2006-12-26 | 2014-06-03 | Visible Measures Corp. | Method and system for internet video and rich media behavioral measurement |
-
2013
- 2013-03-13 US US13/799,751 patent/US9002175B1/en active Active
Patent Citations (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20040158865A1 (en) * | 2001-05-24 | 2004-08-12 | Kubler Kenneth M. | System and method for managing in-theater display advertisements |
US8745647B1 (en) * | 2006-12-26 | 2014-06-03 | Visible Measures Corp. | Method and system for internet video and rich media behavioral measurement |
Cited By (25)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10455266B2 (en) | 2013-01-02 | 2019-10-22 | Amazon Technologies, Inc. | Personalized smart-list video channels |
US9635337B1 (en) * | 2015-03-27 | 2017-04-25 | Amazon Technologies, Inc. | Dynamically generated media trailers |
US10694222B2 (en) | 2016-01-07 | 2020-06-23 | Microsoft Technology Licensing, Llc | Generating video content items using object assets |
CN106231399A (en) * | 2016-08-01 | 2016-12-14 | 乐视控股（北京）有限公司 | Methods of video segmentation, equipment and system |
US10390077B2 (en) | 2017-03-15 | 2019-08-20 | The Directv Group, Inc. | Collective determination of interesting portions of a media presentation, media tagging and jump playback |
US11169767B2 (en) * | 2017-09-29 | 2021-11-09 | Spotify Ab | Automatically generated media preview |
US10636449B2 (en) | 2017-11-06 | 2020-04-28 | International Business Machines Corporation | Dynamic generation of videos based on emotion and sentiment recognition |
US11315600B2 (en) | 2017-11-06 | 2022-04-26 | International Business Machines Corporation | Dynamic generation of videos based on emotion and sentiment recognition |
US11356750B2 (en) * | 2017-11-08 | 2022-06-07 | Roku, Inc. | Automatically and programmatically generating crowdsourced trailers |
US20190387287A1 (en) * | 2017-11-08 | 2019-12-19 | Roku, Inc. | Automatically and programmatically generating crowdsourced trailers |
US10972812B2 (en) * | 2017-11-08 | 2021-04-06 | Roku, Inc. | Automatically and programmatically generating crowdsourced trailers |
US10334326B2 (en) | 2017-11-08 | 2019-06-25 | Roku, Inc. | Enhanced playback bar |
US11838604B2 (en) * | 2017-11-08 | 2023-12-05 | Roku, Inc. | Generating crowdsourced trailers based on forward or rewind commands |
US20220256254A1 (en) * | 2017-11-08 | 2022-08-11 | Roku, Inc. | Generating crowdsourced trailers based on forward or rewind commands |
US11388488B2 (en) * | 2017-11-27 | 2022-07-12 | Rovi Guides, Inc. | Systems and methods for dynamically extending or shortening segments in a playlist |
CN108307229B (en) * | 2018-02-02 | 2023-12-22 | 新华智云科技有限公司 | Video and audio data processing method and device |
CN108307229A (en) * | 2018-02-02 | 2018-07-20 | 新华智云科技有限公司 | A kind of processing method and equipment of video-audio data |
US10917702B2 (en) | 2018-12-13 | 2021-02-09 | At&T Intellectual Property I, L.P. | Creating customized short-form content from long-form content |
CN109831678A (en) * | 2019-02-26 | 2019-05-31 | 中国联合网络通信集团有限公司 | Short method for processing video frequency and system |
US20220382442A1 (en) * | 2020-09-25 | 2022-12-01 | Beijing Zitiao Network Technology Co., Ltd. | Method and apparatus for user guide, device and storage medium |
US11733849B2 (en) * | 2020-09-25 | 2023-08-22 | Beijing Zitiao Network Technology Co., Ltd. | Method and apparatus for user guide, device and storage medium |
US11509962B2 (en) | 2020-12-14 | 2022-11-22 | Disney Enterprises, Inc. | Curating narrative experiences through automated content compilation |
CN113286179A (en) * | 2021-04-21 | 2021-08-20 | 北京爱奇艺科技有限公司 | Processing method and device for jumping-out curve, electronic equipment and storage medium |
US11770567B1 (en) * | 2023-01-23 | 2023-09-26 | Adrennial Inc. | Content distribution platform for upload and linking content to products and services |
US11770572B1 (en) * | 2023-01-23 | 2023-09-26 | Adrennial Inc. | Content distribution platform for uploading and linking content to products and services |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US9002175B1 (en) | Automated video trailer creation | |
US9715731B2 (en) | Selecting a high valence representative image | |
CN112383566B (en) | Streaming media presentation system | |
US11856254B2 (en) | Dynamically adjustable electronic program guide | |
KR102054548B1 (en) | Multi-view audio and video interactive playback | |
US10777229B2 (en) | Generating moving thumbnails for videos | |
US11974013B2 (en) | Modifying digital video content | |
US9224156B2 (en) | Personalizing video content for Internet video streaming | |
US9854285B1 (en) | Popular media items data set with exponential decay | |
US20140245334A1 (en) | Personal videos aggregation | |
US11206441B2 (en) | Automated media production pipeline for generating personalized media content | |
US20230409582A1 (en) | Precision of content matching systems at a platform | |
US20230419997A1 (en) | Automatic Non-Linear Editing Style Transfer | |
US11553219B2 (en) | Event progress detection in media items | |
WO2021107957A1 (en) | System and method for modelling access requests to multi-channel content sharing platforms | |
US20230379556A1 (en) | Crowd source-based time marking of media items at a platform | |
US11948172B2 (en) | Rendering a dynamic endemic banner on streaming platforms using content recommendation systems and content affinity modeling | |
US20230379520A1 (en) | Time marking of media items at a platform using machine learning |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:RAJ, ANOSH;REEL/FRAME:030056/0814Effective date: 20130312 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044334/0466Effective date: 20170929 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 4TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1551); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 4 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 8TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1552); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 8 |