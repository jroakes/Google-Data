TW201842431A - Tracking of position and orientation of objects in virtual reality systems - Google Patents
Tracking of position and orientation of objects in virtual reality systems Download PDFInfo
- Publication number
- TW201842431A TW201842431A TW107114622A TW107114622A TW201842431A TW 201842431 A TW201842431 A TW 201842431A TW 107114622 A TW107114622 A TW 107114622A TW 107114622 A TW107114622 A TW 107114622A TW 201842431 A TW201842431 A TW 201842431A
- Authority
- TW
- Taiwan
- Prior art keywords
- signal
- radiation
- hmd
- handheld controller
- lut
- Prior art date
Links
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/03—Arrangements for converting the position or the displacement of a member into a coded form
- G06F3/033—Pointing devices displaced or positioned by the user, e.g. mice, trackballs, pens or joysticks; Accessories therefor
- G06F3/0346—Pointing devices displaced or positioned by the user, e.g. mice, trackballs, pens or joysticks; Accessories therefor with detection of the device orientation or free movement in a 3D space, e.g. 3D mice, 6-DOF [six degrees of freedom] pointers using gyroscopes, accelerometers or tilt-sensors
-
- G—PHYSICS
- G02—OPTICS
- G02B—OPTICAL ELEMENTS, SYSTEMS OR APPARATUS
- G02B27/00—Optical systems or apparatus not provided for by any of the groups G02B1/00 - G02B26/00, G02B30/00
- G02B27/01—Head-up displays
- G02B27/017—Head mounted
-
- G—PHYSICS
- G02—OPTICS
- G02B—OPTICAL ELEMENTS, SYSTEMS OR APPARATUS
- G02B27/00—Optical systems or apparatus not provided for by any of the groups G02B1/00 - G02B26/00, G02B30/00
- G02B27/01—Head-up displays
- G02B27/017—Head mounted
- G02B27/0172—Head mounted characterised by optical features
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/011—Arrangements for interaction with the human body, e.g. for user immersion in virtual reality
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/017—Gesture based interaction, e.g. based on a set of recognized hand gestures
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/03—Arrangements for converting the position or the displacement of a member into a coded form
- G06F3/0304—Detection arrangements using opto-electronic means
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/03—Arrangements for converting the position or the displacement of a member into a coded form
- G06F3/0304—Detection arrangements using opto-electronic means
- G06F3/0325—Detection arrangements using opto-electronic means using a plurality of light emitters or reflectors or a plurality of detectors forming a reference frame from which to derive the orientation of the object, e.g. by triangulation or on the basis of reference deformation in the picked up image
-
- H—ELECTRICITY
- H03—ELECTRONIC CIRCUITRY
- H03K—PULSE TECHNIQUE
- H03K19/00—Logic circuits, i.e. having at least two inputs acting on one output; Inverting circuits
- H03K19/02—Logic circuits, i.e. having at least two inputs acting on one output; Inverting circuits using specified components
- H03K19/173—Logic circuits, i.e. having at least two inputs acting on one output; Inverting circuits using specified components using elementary logic circuits as components
- H03K19/177—Logic circuits, i.e. having at least two inputs acting on one output; Inverting circuits using specified components using elementary logic circuits as components arranged in matrix form
- H03K19/17724—Structural details of logic blocks
- H03K19/17728—Reconfigurable logic blocks, e.g. lookup tables
-
- G—PHYSICS
- G02—OPTICS
- G02B—OPTICAL ELEMENTS, SYSTEMS OR APPARATUS
- G02B27/00—Optical systems or apparatus not provided for by any of the groups G02B1/00 - G02B26/00, G02B30/00
- G02B27/01—Head-up displays
- G02B27/0101—Head-up displays characterised by optical features
- G02B2027/0132—Head-up displays characterised by optical features comprising binocular systems
-
- G—PHYSICS
- G02—OPTICS
- G02B—OPTICAL ELEMENTS, SYSTEMS OR APPARATUS
- G02B27/00—Optical systems or apparatus not provided for by any of the groups G02B1/00 - G02B26/00, G02B30/00
- G02B27/01—Head-up displays
- G02B27/0101—Head-up displays characterised by optical features
- G02B2027/0138—Head-up displays characterised by optical features comprising image capture systems, e.g. camera
-
- G—PHYSICS
- G02—OPTICS
- G02B—OPTICAL ELEMENTS, SYSTEMS OR APPARATUS
- G02B27/00—Optical systems or apparatus not provided for by any of the groups G02B1/00 - G02B26/00, G02B30/00
- G02B27/01—Head-up displays
- G02B27/0101—Head-up displays characterised by optical features
- G02B2027/014—Head-up displays characterised by optical features comprising information/image processing systems
-
- G—PHYSICS
- G02—OPTICS
- G02B—OPTICAL ELEMENTS, SYSTEMS OR APPARATUS
- G02B27/00—Optical systems or apparatus not provided for by any of the groups G02B1/00 - G02B26/00, G02B30/00
- G02B27/01—Head-up displays
- G02B27/0179—Display position adjusting means not related to the information to be displayed
- G02B2027/0187—Display position adjusting means not related to the information to be displayed slaved to motion of at least a part of the body of the user, e.g. head, eye
-
- G—PHYSICS
- G08—SIGNALLING
- G08C—TRANSMISSION SYSTEMS FOR MEASURED VALUES, CONTROL OR SIMILAR SIGNALS
- G08C2201/00—Transmission systems of control signals via wireless link
- G08C2201/30—User interface
- G08C2201/32—Remote control based on movements, attitude of remote control device
Abstract
Description
本發明係關於追蹤三維位置及用於虛擬實境(VR)系統中之真實物體之定位。The present invention relates to tracking three-dimensional positions and positioning of real objects used in virtual reality (VR) systems.
在一些VR系統中，一使用者使用一頭戴顯示器(HMD)及一對手持控制器與虛擬一虛擬環境中之任何數目個虛擬物體互動。在此等VR系統中，當VR系統使用手持控制器追蹤控制器之位置及定向時，使用者使用HMD看見及聽到物體。接著，VR系統將控制器之六個自由度(6DOF)(即三維位置及定向)回饋至HMD以更新虛擬環境內之使用者之視野。In some VR systems, a user uses a head mounted display (HMD) and a pair of handheld controllers to interact with any number of virtual objects in a virtual environment. In these VR systems, when the VR system uses a handheld controller to track the position and orientation of the controller, the user uses the HMD to see and hear objects. Then, the VR system returns the six degrees of freedom (6DOF) (ie, three-dimensional position and orientation) of the controller to the HMD to update the user's field of vision in the virtual environment.
在一一般態樣中，一VR系統可包含一手持控制器及一HMD。在此VR系統中，一方法可包含由處理電路自放置於HMD中之複數個輻射發射器接收漫射電磁輻射之一脈衝。該方法亦可包含由該處理電路自該漫射電磁輻射產生一數位信號。該方法可進一步包含由該處理電路獲得基於該數位信號之該手持控制器之一位置及一定向。 下文之附圖及描述中闡述一或多個實施方案之細節。將自此描述及圖式及自申請專利範圍明白其他特徵。In a general aspect, a VR system may include a handheld controller and an HMD. In this VR system, a method may include receiving a pulse of diffused electromagnetic radiation from a plurality of radiation transmitters placed in the HMD by a processing circuit. The method may also include generating a digital signal from the diffused electromagnetic radiation by the processing circuit. The method may further include obtaining a position and orientation of the handheld controller based on the digital signal by the processing circuit. The details of one or more embodiments are set forth in the accompanying drawings and description below. Other features will be apparent from the description and drawings and from the scope of the patent application.
相關申請案之交叉參考 本申請案主張名稱為「TRACKING OF POSITION AND ORIENTATION OF OBJECTS IN VIRTUAL REALITY SYSTEMS」之2017年5月1日申請之美國專利申請案第62/492,801號之優先權，該案之全部內容以引用的方式併入本文中。 習知VR系統需要一外部系統以提供諸如一手持控制器之一物體之追蹤資料。此一外部系統之一實例呈放置於(例如)一房間之相對角中之一對固定發射器(「基站」)之形式。此等發射器使用準直近紅外線(NIR)雷射或LED照明以使用一旋轉馬達組態光柵掃描一場景。在本文所描述之實施方案中，一物體可不經由收集聚焦照明資料及自照明資料產生物體位置及定向之高頻寬感測器來追蹤。在本文所描述之實施方案中，可不需要一大空間(即一整個房間)之固定發射器及用於準直照明之昂貴光學器件。此外，在本文所描述之實施方案中，可消除可引入之對光學雜訊之不需要的敏感度之高頻寬感測器。 根據本文所描述之實施方案，追蹤一VR系統中之一手持控制器之改良技術涉及手持控制器中之光電二極體偵測由HMD中之漫射LED產生之漫射輻射之圖案。裝置及方法亦可包含比較經偵測之圖案與先前離線模擬且在一查找表(LUT)中表示之圖案。藉由在LUT中查找經偵測之圖案，VR系統可判定具有亞毫米準確度之手持控制器之位置及/或定向。改良技術之一些優點可在於組件之簡單性及/或低成本而無需犧牲導出手持控制器之位置及定向之準確度。需要專用於用於改良式VR系統之一大空間。產生漫射輻射之光學元件及手持控制器中之光電二極體不如準直所需之光學元件及光電二極體昂貴。此外，應用於光電二極體之新穎電路提供改良式VR系統對外部光之低敏感度。 圖1A繪示包含一HMD 105及一手持控制器103之一實例性VR系統100。HMD 105適配於一使用者之頭部及使用展示為使用者前面之投射之一顯示器204涵蓋其眼睛。HMD 105內部之顯示器204展示一虛擬環境115至使用者。在此特定使用者環境115中，存在一虛擬物體120。使用者可使用手持控制器103操縱虛擬物體120。 VR系統100使用手持控制器103來追蹤使用者之移動及因此判定虛擬環境115中顯示之內容。特定言之，VR系統100經組態以追蹤手持控制器103之位置及(在一些情況中)手持控制器103之定向。因此，重要的係VR系統能夠使用足夠準確度(通常在一毫米內)追蹤手持控制器103之位置及定向。 根據改良技術，VR系統100使用由HMD 105中之輻射源130 (例如LED)產生之漫射電磁輻射(例如近紅外線輻射)追蹤手持控制器103。此等輻射源130可配置於頭盔內(例如HMD 105之一外殼內)之一陣列中。 作為手持控制器之此追蹤之部分，手持控制器103包含一輻射偵測器140。在諸如本文所描述之一些實施方案中，輻射偵測器包含光電二極體。在一些實施方案中，輻射偵測器可包含光電倍增管、電荷耦合器件及其類似者。 如圖1A中所繪示，HMD亦包含處理電路132。處理電路132經組態以偵測由輻射偵測器140回應於接收所發射之輻射而在手持控制器103中產生之信號及基於經偵測之信號而判定手持控制器103之位置及/或定向。在一些配置中，處理電路132亦耦合至儲存一LUT 138之一記憶體136。在此等配置中，處理電路132經組態以對經偵測之信號及記憶體136中之LUT 138執行一比較操作。 如本文中將描述，VR系統100經組態以經由處理器132處理輻射源130及輻射偵測器140之模擬以及由偵測器中之電路產生之信號以構建LUT 138。 在一些配置中，處理電路132及記憶體136位於(例如)手持控制器103中之HMD外部或手持控制器103及HMD 105外部之一電腦外部。 圖1B繪示可包含於諸如HMD 105 (圖1A)之一HMD中之實例性LED發射器。在圖1B中，存在十二個配置於嵌入一HMD中之一曲面上之LED。LED之各者焊接於一印刷電路板上且自HMD汲取電力。在一些實施方案中，LED依一近紅外線(NIR)波長(例如介於700 nm與1000 nm之間)發射電磁輻射。在一些實施方案中，LED依光學波長、近紅外線波長、遠紅外線波長及微波波長發射此輻射。 如本文所論述，有利的係模擬由HMD 105中之輻射源發射之輻射圖案使得當在手持控制器103處偵測室時，實際輻射圖案可判定手持控制器103之位置及定向。據此而言，各輻射源130根據一已知亮度輪廓發射輻射，且此一輪廓可用於判定手持控制器103處接收之亮度。因為手持控制器103包含一輻射偵測器140 (例如將輻射能量轉換為電能之光電二極體)，所以手持控制器103之位置及定向將支配偵測器140處接收之輻射輪廓。偵測器140處之電路產生基於亦可模擬之所接收之輪廓之一電氣信號。其係由記錄於記憶體136中之LUT 138中之此電路產生之信號。在包含本文所討論之一些實施方案中，手持控制器103中可存在多個輻射偵測器。 圖1C及圖1D係繪示具有NIR波長之圖1B中所繪示之LED之特徵之一對實例性輻射亮度圖的一圖。此一亮度輪廓可用於本文所描述之實施方案中以模擬由手持控制器103接收之輻射信號。在各圖中係一對圖：左邊係一極座標圖而右邊係一直角座標圖。極座標圖繪示其中亮度係極角相對於一LED之一垂直軸線之一函數之一輻射輪廓之一半。直角座標圖繪示相同圖但繪示亮度之小值之一更詳細檢查。 如圖1C中所展示，圖展示一相對窄亮度輪廓(即亮度在遠離LED之一垂直軸線處相對較快減少)。然而，直角座標圖展示亮度朝向LED之一水平軸線更慢減少。相比而言，圖1D中之圖展示一相對寬輪廓(即亮度在遠離LED之一垂直軸線處相對較慢減少)。然而，直角座標圖展示亮度朝向LED之一水平軸線更快減少。 圖2係在各LED輻射發射器之手持控制器103中之一光電二極體處接收之模擬輻射之圖之一陣列的一圖。模擬使用圖1B中所展示之十二個LED之位置及定向連同亮度資料(亮度資料之實例在圖1C及圖1D中展示)。圖之各者係其中明亮表示最高接收強度之區域而黑暗表示最低接收強度之區域之一平面熱圖。各圖之水平及垂直軸線表示沿手持控制器之一接收區域之位置(例如一光電二極體正上方)。 圖3A係繪示一毫秒時間尺度內之實例性模擬輻射脈衝列之一圖的一圖。圖3A中之圖表示源自自LED接收且入射於一光電二極體上且接著經受一類比-數位轉換(ADC)之漫射電磁輻射之一脈衝之一脈衝列之一整體強度(光電二極體之一區域上)。數位脈衝之週期係略大於0.1 ms。 源自漫射輻射之脈衝信號之時間態樣隱含LUT中之圖案應係時間相依。因此，如本文將論述，比較一實際信號與LUT中之一圖案之程序涉及將該實際信號同步至LUT以判定該圖案之校正相位。 俯視圖中之脈衝列之頻率分量可包含居中於大約1000 Hz (1/列之週期)上之大量頻率，但亦具有小量低頻率(與信號之DC部分相關聯)及較小量高頻率。低頻率分量及高頻率分量兩者可與非所要之各種雜訊比重相關聯且可引起導出手持控制器103之位置及定向之不準確度。因此，在一些實施方案中，VR系統100可包含一帶通濾波器。俯視圖中展示應用於實例性脈衝列之一實例性帶通濾波器之結果。 圖3B係展示以伏特為單位之一濾波信號電壓對以毫米為單位之時間之一圖。濾波脈衝列之週期相同於非濾波脈衝列，但振幅及相位已改變。其係判定LUT 138中之圖案之相位之此帶通濾波脈衝列。 如上文所討論，需要手持控制器處之輻射之模擬來構建用於回應於自HMD 105中之源130接收輻射之手持控制器103而判定手持控制器之位置及定向之LUT 138。上述討論繪示手持控制器103處所接收之輻射的空間及時間性質。另外，亦可需要接收器之性質以準確模擬由VR系統100接收之實際電氣信號。 圖4A繪示一手持控制器103中之一組實例性光電二極體輻射偵測器140 (參閱圖1A)。光電二極體以一預指定圖案沿手持控制器103之表面配置且而光電二極體回應於入射於其表面上之輻射而產生其自身之信號。 圖4B係手持控制器中之一光電二極體之一實例性傳遞函數之一圖。在此圖中，傳遞函數具有一帶通濾波器之特徵，其係低於一高頻率fH及一低頻率fL之零。圖進一步繪示其中預期1/f雜訊低於一臨界頻率fc ＜ fH及一DC雜訊高於臨界頻率fc之光電二極體之一雜訊輪廓。 圖4C係光電二極體及帶通濾波器之一示意性電路圖。電路圖展示兩個操作放大器：用於放大由漫射輻射之入射脈衝產生之信號之一第一操作放大器及用於消除由周圍光產生之電流之一第二操作放大器。此一配置使得用於手持控制器中之光電二極體在周圍光之面中及其他DC雜訊中較為穩健。 一旦VR系統100判定經由手持控制器103接收及處理之信號，則VR系統100接著判定手持控制器103之位置。通常，存在歸因於VR系統之組態(例如手持控制器至VR系統之連接等等)而受約束之手持主控器之一組可能位置。 圖5係繪示手持控制器位置之一實例性限制空間之一圖。圖5中之限制空間呈三維座標空間中之一固體物體之形式。形狀類似一倒置型錐體之固體物體表示可由手持控制器占據之空間中之該組所有可能位置。就此固體物體中之各點而言，存在其中手持控制器可針對該點固持之一組所有可能位置。就離散取樣而言，各可能離散位置表示為一立體像素或體積像素(即一三維像素)。 在圖4A中，據回顧，一手持控制器103中通常存在多個光電二極體。各光電二極體針對VR系統產生其自身之脈衝列信號。LUT最終可單獨表示各信號。LUT 138可(例如)藉由平均化而將信號組合成一單一信號。 圖6係繪示在自HMD 105中之LED接收脈衝、漫射輻射之後由手持控制器103中之光電二極體輸出之實例性脈衝列之一圖。在此實例中，存在九個光電二極體。在此實例中，各光電二極體自圖1B中所繪示之十二個LED之各者產生各自不同信號。因為各光電二極體具有相對於LED之一不同視角，所以各光電二極體產生不同信號列。 圖7係繪示一實例性LUT 138之一圖。如圖7中所展示之LUT 138表現為一彩色圖但實際上係由立體像素指數及時間索引之一組離散圖案。一立體像素指數係手持控制器可呈現之可能離散位置及定向之一整數函數。例如，立體像素指數可為三個位置座標(X、Y、Z)及三個角座標(俯仰、偏航、翻滾)之各者之一圓形、加權線性組合。此等三個位置座標及三個角座標應自一立體像素指數唯一判定。 圖7中之LUT 138之各離散元件係一組九個圖案，各光電二極體之一圖案配置於手持控制器中。沿此等線，自ADC及帶通濾波器輸出之信號分成兩片：一第一短片用於判定圖案之時間或相位，而一第二較長片用於判定最佳立體像素指數。就圖7中所繪示之LUT 138而言，基於使圖案之第一片匹配一特定行中之圖案之各者而判定最佳列。在一些配置中，藉由藉由(例如)平均化行上之圖案而發現在一個以上行內尋找最佳列來判定時間。接著，藉由透過最佳列搜尋而發現最佳立體像素指數。 圖8係繪示判定手持控制器103所採取之最可能位置之一實例性程序之一圖。如圖8中所展示，光電二極體之一配置回應於接收漫射輻射之一脈衝而各輸出一信號至一各自ADC。各ADC繼而輸出輸入至一數位信號處理器中之一數位信號以減輕雜訊及偵測對其他信號之任何干擾。接著，偵測最終數位信號且將其輸入至LUT 138之一相關操作中。該相關操作之輸出係圖5中所展示之立體像素上之一熱圖。 立體像素上之三維熱圖係將立體像素指數逆映射至薩內物體中之位置之一結果。接著，此三維熱圖表示位於由一立體像素表示之位置中之手持控制器之可能性。在圖8中所展示之實例中，明亮區域表示最可能由手持控制器採取之位置而黑暗區域表示最不可能由手持控制器採取之位置。 在一些實施方案中，相關操作藉由差分化由各光電二極體產生之一信號與在LUT中表示之一信號且平均化差值之平方或絕對值以產生一度量而產生熱圖。接著，熱圖之色彩可基於度量之值。 自最可能之位置，一第二三維熱圖可基於立體像素指數而依類似於定向之一方式產生且手持控制器之最可能定向可自此第二熱圖導出。 一旦一最可能姿勢自3D熱圖導出，則將存在進一步追蹤及濾波以移除由立體像素及外部信號引起之任何雜訊。接著，此濾波結果輸入至VR系統100作為一特定時刻之手持控制器之姿勢。 圖9A係繪示用於自光電二極體電路之一跨阻抗放大器(TIA)部分減去DC雜訊電流之一組實例性電路拓撲之一圖。在圖中所繪示之第一拓撲(「拓撲1」)中，不存在用於減去此DC電流之額外電路且電路之增益輪廓具有可表示對周圍光之敏感度之非常大及不需要的低頻分量。在圖中所繪示之第二拓撲(「拓撲2」)中，電路已經更改以將兩個電阻器放置於一分壓器之任一側上。此一分壓器可用於自TIA輸出汲取低頻電流。結果係低頻處之電路之增益減少，改良第一拓撲。 第三拓撲(「拓撲3」)具有連接至TIA之輸出及回饋至TIA之一伺服迴路。結果係低於一臨限頻率之零增益以指示低頻及DC電流已視需要消除TIA。圖9b中展示伺服迴路之進一步細節。 圖9B係繪示消除TIA中之低頻及DC電流之圖9a中之伺服迴路之一圖。伺服迴路包含連接至TIA輸出之一第二操作放大器及連接至操作放大器之輸出及輸入回TIA之一低通濾波器。低頻電流接收於操作放大器處，低頻電流在誤差放大器處產生一低頻電壓。回應於接收低頻電流，操作放大器產生與低頻電壓與一參考電壓之間之一差值成比例之一控制電壓。接著，控制電壓輸入至低通濾波器中，其接著自控制電壓產生一負電流，負電流比僅一分壓器更有效自TIA汲取低頻電流。 本文所揭示之元件及介面之一或多者可複製、並行實施、以單數實施、組合實施、分開實施、重新配置、忽略、消除及/或以任何其他方式實施。此外，所揭示之元件及介面之任何者可由一處理器、一電腦及/或諸如下文連同圖10討論之實例性處理器平台P00及P50之具有一處理器之一機器實施。實例性處理器包含(但不限於)一電路、一可程式化處理器、保險絲、一應用特定積體電路(ASIC)、一可程式化邏輯器件(PLD)、一場可程式化邏輯器件(FPLD)、一場可程式化閘陣列(FPGA)、一數位信號處理器(DSP)、一圖形處理單元(GPU)、一中央處理單元(CPU)、一微控制器、一控制器等等。本文所揭示之元件及介面之任何者可(例如)實施為由一處理器、一電腦及/或具有一處理器之一機器之一或多者執行之指令、程式碼、機器可讀指令等等。一處理器、一電腦及/或具有一處理器之一機器可被使用、經組態及/或經程式化以執行及/或實施本文所揭示之實例。例如，實例之任何者可體現在儲存於可由一處理器、一電腦及/或諸如下文連同圖10討論之實例性處理器平台P00及P50之具有一處理器之其他機器存取之一有形及/或非暫時性電腦可讀媒體上之指令、程式碼、機器可讀指令等等中。機器可讀指令包含(例如)引起一處理器、一電腦及/或具有一處理器之一機器執行一或多個特定程序或方法之指令。當閱讀併入圖10之元件之一或多者之本專利之一請求項以涵蓋一純軟體及/或韌體實施方案時，圖10之元件之至少一者特此明確地界定以包含諸如儲存機器可讀指令之一有形機器可讀媒體(諸如韌體及/或軟體)之一有形製品。 本文所揭示之實例性方法可(例如)實施為由一處理器、一電腦及/或具有一處理器之其他機器執行之指令、程式碼、機器可讀指令。一處理器、一控制器及/或諸如圖10中所展示之任何其他適合處理器件可被使用、經組態及/或經程式化以執行及/或實施實例性方法。例如，處理器、控制器及/或任何適合處理器件體現在儲存於可由一處理器、一電腦及/或諸如下文連同圖10討論之具有一處理器之其他機器存取之一有形及/或非暫時性電腦可讀媒體上之指令、程式碼及/或機器可讀指令中。可採用實施實例性方法之許多其他方法。例如，可改變執行之順序及/或可改變、消除、再分或組合所描述之區塊及/或互動之一或多者。另外，可依序執行及/或由(例如)單獨處理執行緒、處理器、器件、離散邏輯、電路等等並行執行任何或整個實例性方法。 如本文所使用，術語「電腦可讀媒體」及「機器可讀媒體」明確地排除傳播信號。實例性電腦可讀或機器可讀媒體包含(但不限於)一揮發性及/或非揮發性記憶體、一揮發性及/或非揮發性記憶體器件、一光碟(CD)、一數位化多功能光碟(DVD)、一唯讀記憶體(ROM)、一隨機存取記憶體(RAM)、一快閃驅動器、一軟碟、一同步動態隨機存取記憶體(SDRAM)、一動態隨機存取記憶體((DRAM)、一RAMBUS動態隨機存取記憶體((RDRAM)、一可程式化ROM (PROM)、一電子可程式化ROM (EPROM)、一電子可擦除PROM (EEPROM)、一固態(SS)記憶體、一固態磁碟(SSD)、一光學儲存磁碟、一光學儲存器件、一磁性儲存磁碟、一網路附接儲存器(NAS)器件、一磁性儲存器件、一快取及/或其中資訊儲存達任何持續時間(例如達延伸時間週期、永久、簡短時刻、用於暫時緩衝及/或用於資訊之快取)且可由一處理器、一電腦及/或具有一處理器之其他機器存取之其他儲存媒體之一者或任何組合。 圖10展示可與此處所描述之技術一起使用之一一般電腦器件P00及一一般行動電腦器件P50之一實例。計算器件P00意欲表示諸如膝上型電腦、桌上型電腦、平板電腦、工作站、個人數位助理、電視機、伺服器、刀鋒型伺服器、主機及其他適當計算器件各種形式之數位電腦。計算器件P50意欲表示諸如個人數位助理、蜂巢式電話、智慧型電話及其他類似計算器件之各種形式之行動器件。此處所展示之組件、組件之連接及關係及組件之功能意謂僅係例示性，且不意謂限制本文件中所描述及/或主張之本發明之實施方案。 計算器件P00包含一處理器P02、記憶體P04、一儲存器件P06、連接至記憶體P04及高度擴充埠P10之一高速介面P08及連接至低速匯流排P14及儲存器件P06之一低速介面P12。處理器P02可為一基於半導體之處理器。記憶體P04可為一基於半導體之記憶體。組件P02、P04、P06、P08、P10及P12之各者使用各種匯流排互連且可安裝於一共同主機板上或視情況依其他方式安裝。處理器P02可處理用於在計算器件P00內執行之指令，包含儲存於記憶體P04中或儲存器件P06上以將一GUI之圖形資訊顯示在諸如耦合至高速介面P08之顯示器P16之一外部輸入/輸出器件上之指令。在其他實施方案中，可視情況使用多個處理器及/或多個匯流排以及多個記憶體或多個類型之記憶體。另外，可連接多個計算器件P00，其中各器件提供必要操作之部分(例如作為一伺服器組、一組刀鋒型伺服器或一多處理器系統)。 記憶體P04將資訊儲存於計算器件P00內。在一實施方案中，記憶體P04係一揮發性記憶體單元或若干揮發性記憶體單元。在另一實施方案中，記憶體P04係一非揮發性記憶體單元或若干揮發性記憶體單元。記憶體P04亦可為諸如一磁碟或光碟之另一形式之電腦可讀媒體。 儲存器件P06能夠針對計算器件P00提供大量儲存。在一實施方案中，儲存器件P06可為或含有諸如一軟碟器件、一硬碟器件、一光碟器件或一磁帶器件、一快閃記憶體或其他類似固態記憶體器件或一器件(包含一儲存區域網路或其他組態中之器件)陣列之一電腦可讀媒體。一電腦程式產品可有形地體現在一資訊載體中。電腦程式產品亦可含有指令，當執行時，指令執行諸如上文所描述之一或多個方法。資訊載體係諸如記憶體P04、儲存器件P06或處理器P02上之記憶體之一電腦或機器可讀媒體。 高速控制器P08管理計算器件P00之頻寬密集操作，而低速控制器P12管理較低頻寬密集操作。功能之此分配僅係例示性。在一實施方案中，高速控制器P08耦合至記憶體P04、顯示器P16 (例如透過一圖形處理器或加速器)及耦合至可接受各種擴充卡(圖中未展示)高度擴充埠P10。在實施方案中，低速控制器P12耦合至儲存器件P06及低速擴充埠P14。可包含各種通信埠(例如USB、藍芽、乙太網路、無線乙太網路)之低速擴充埠可(例如)透過一網路配接器耦合至諸如一鍵盤、一指向器件、一掃描器或諸如一開關或路由器之一網路器件)一或多個輸入/輸出器件。 計算器件P00可以如圖中所展示之若干不同形式實施。例如，其可實施為一標準伺服器P20或在在一組此等伺服器中多次實施。其亦可實施為一機架伺服器系統P24之部分。另外，其可在諸如一膝上型電腦P22之一個人電腦中實施。替代地，來自計算器件P00之組件可與諸如器件P50之一行動器件(圖中未展示)中之其他組件組合。此等器件之各者可含有計算器件P00、P50之一或多者且整個系統可由彼此通信之多個計算器件P00、P50組成。 除其他組件之外，計算器件P50包含一處理器P52、記憶體P64、諸如一顯示器P54之一輸入/輸出器件、一通信介面P66及一收發器P68。計算器件P50亦可具有諸如一微驅動器或其他器件之一儲存器件以提供額外儲存。組件 P50、P52、P64、P54、P66及P68之各者使用各種匯流排互連，且若干組件可安裝於一共同主機板上或視情況依其他方式安裝。 處理器P52可執行計算器件P50內之指令，包含儲存於記憶體P64中之指令。處理器可實施為一晶片組或包含單獨或多個類比及數位處理器之晶片。處理器可提供(例如)器件P50之其他組件之協調(諸如使用者介面之控制、由器件P50運行之應用程式及藉由器件P50之無線通信)。 處理器P52可透過控制介面P58及耦合至一顯示器P54之顯示介面P56與一使用者通信。顯示器P54可為(例如)一TFT LCD (薄膜電晶體液晶顯示器)或一OLED (有機發光二極體)顯示器或其他適當顯示技術。顯示介面P56可包括用於驅動顯示器P54呈現圖形及其他資訊至一使用者之適當電路。控制介面P58可自一使用者接收命令及轉換命令以提交至處理器P52。另外，可提供與處理器P52通信之一外部介面P62以達成器件P50與其他器件之近區域通信。在一些實施方案中，外部介面P62可提供(例如)有線通信或在其他實施方案中，透過無線通信，且亦可使用多個介面。 記憶體P64將資訊儲存於計算器件P50內。記憶體P64可實施為一電腦可讀媒體或若干電腦可讀媒體、一揮發性記憶體單元或若干揮發性記憶體單元或一非揮發性記憶體單元或若干非揮發性記憶體單元之一或多者。亦可提供擴充記憶體P74且透過可包含(例如)一SIMM (單直插記憶體模組)卡介面之擴充介面P72將其連接至器件P50。此擴充記憶體P74可提供器件P50之額外儲存空間，或亦可儲存器件P50之應用或其他資訊。具體而言，擴充記憶體P74可包含用於實施或補充上述程序之指令，且亦可包含安全資訊。例如，因此，擴充記憶體P74可提供為器件P50之一完全模組，且可使用允許安全使用器件P50之指令程式化。另外，可經由SIMM卡提供安全應用以及額外資訊(諸如依一非可破解方式將識別資訊放置於SIMM卡上)。 記憶體可包含(例如)如下文所討論之快閃記憶體及/或NVRAM記憶體。在一實施方案中，一電腦程式產品有形地體現在一資訊載體中。電腦程式產品含有指令，當執行時，指令執行諸如上文所描述之一或多個方法。資訊載體係諸如記憶體P64、擴充記憶體P74或可(例如)經由收發器P68或外部介面P62接收之處理器P52上之記憶體之一電腦或機器可讀媒體。 器件P50可透過可在必要處包含數位信號處理電路之通信介面P66無線通信。通信介面P66可在諸如(尤其) GSM語音呼叫、SMS、EMS或MMS傳訊、CDMA、TDMA、PDC、WCDMA、CDMA2000或GPRS之各種模式或協定下提供通信。此通信可(例如)透過射頻收發器P68發生。另外，可諸如使用一藍芽、Wi-Fi或其他此等收發器(圖中未展示)發生短程通信。另外，全球定位系統(GPS)接收器模組P70可提供額外導航及位置相關無線資料至器件P50，額外導航及位置相關無線資料可視情況由運行於器件P50上之應用程式使用。 器件P50亦可使用可自一使用者接收口說資訊且將其轉換為可用數位資訊之音訊編解碼器P60可聽地通信。同樣地，音訊編解碼器P60可(諸如)透過一揚聲器(例如在器件P50之一手機中)產生一使用者之可聽聲音。此聲音可包含來自語音電話呼叫之聲音、可包含記錄聲音(例如語音訊息、音樂檔案等等)且亦可包含由在器件P50上操作之應用產生之聲音。 計算器件P50可以圖中所展示之若干不同形式實施。例如，其可實施為一蜂巢式電話P80。其亦可實施為一智慧型電話P82、個人數位助理或其他類似行動器件之部分。 圖11繪示諸如圖1A中所展示之一頭戴顯示器之一實例性實施方案。在圖11中，佩戴一HMD 700之一使用者固持一可攜式手持電子器件702。手持電子器件702可為(例如)一智慧型電話、一控制器、一操縱桿或可與HMD 700配對及與HMD 700通信以在由HMD 700產生之沉浸式虛擬環境中互動之另一(若干)可攜式手持電子器件。手持電子器件702可經由(例如)一有線連接或諸如(例如)一WiFi或藍芽連接之一無線連接操作地與HMD 700耦合或配對。手持電子器件702及HMD 700之此配對或可操作耦合可在手持電子器件702與HMD 700之間提供通信及手持電子器件702與HMD 700之間之資料之交換。此可允許手持電子器件702充當與HMD 700通信以在由HMD 700產生之沉浸式虛擬環境中互動之一控制器。即，手持電子器件702之一操縱(諸如(例如)由手持電子器件702發射且引導至用於選擇之一虛擬物體或特徵之一光束或射線及/或接收於手持電子器件702之一觸控表面上之一輸入及/或手持電子器件702之一移動)可轉換為由HMD 700產生之沉浸式虛擬環境中之一對應選擇或移動或其他類型之互動。例如，HMD 700可與手持電子器件702一起產生如上文所描述之一虛擬環境，且手持電子器件702可經操縱以實現使用者相對於如上文所描述之虛擬環境中之虛擬特徵之比例或視角的改變。 圖12A及圖12B係諸如(例如)由圖11中之使用者佩戴之HMD 700之一實例性HMD之透視圖，且圖12C繪示諸如(例如)圖11中所展示之手持電子器件702之一實例性手持電子器件。 手持電子器件802可包含其中接收器件802之內部組件之一外殼803，及可供使用者取得之位於外殼803之一外部上之一使用者介面804。使用者介面804可包含經組態以接收使用者觸控輸入之一觸敏表面806。使用者介面804亦可包含諸如(例如)致動按鈕、旋鈕、操縱桿及其類似者之用於由使用者操縱之其他組件。在一些實施方案中，使用者介面804之至少一部分可組態為一觸控螢幕，其中使用者介面804之該部分經組態以顯示使用者介面項目至使用者，且亦在觸敏表面806上自使用者接收觸控輸入。手持電子器件802亦可包含經組態以(例如)回應於在使用者介面804處接收之一使用者輸入而透過外殼803中之一埠選擇性地發射光(例如一光束或射線)之一光源808。 HMD 800可包含耦合至一框架820之一外殼810，其中包含(例如)安裝於頭戴耳機中之揚聲器之一音訊輸出器件830亦耦合至框架820。在圖8B中，外殼810之一前部分810a旋轉遠離外殼810之一基座部分810b使得接收於外殼810中之一些組件可見。一顯示器840可安裝於外殼810之前部分810a之一面向內部側上。當前部分810a位於抵靠外殼810之基座部分810b之閉合位置中時，透鏡850可安裝於外殼810中，介於使用者之眼與顯示器840之間。在一些實施方案中，HMD 800可包含具有各種感測器之一感測系統860及具有一處理器890之一控制系統870及各種控制系統器件以促進HMD 800之操作。 在一些實施方案中，HMD 800可包含一攝影機880以擷取靜止及移動影像。由攝影機880擷取之影像可用於助於追蹤真實世界中之使用者及/或手持電子器件802之一實體位置，或相對於虛擬環境之實體環境及/或可以一通過模式顯示至顯示器840上之使用者以允許使用者暫時留下虛擬環境且在無需移動HMD 800或以其他方式改變HMD 800之組態之情況下返回至實體環境以將外殼810移出使用者之視線。 在一些實施方案中，HMD 800可包含一視線追蹤器件865以偵測及追蹤使用者之一眼部視線。視線追蹤器件865可包含(例如)一影像感測器865A或多個影像感測器865A以擷取使用者之眼(例如使用者之眼之一特定部分，諸如(例如)瞳孔)之影像以偵測及追蹤使用者之視線之方向及移動。在一些實施方案中，HMD 800可經組態使得經偵測之視線處理為待轉換為沉浸式虛擬體驗中之一對應互動之一使用者輸入。 此處所描述之系統及技術之各種實施方案可在數位電子電路、積體電路、經特殊設計之ASIC (應用特定積體電路)、電腦硬體、韌體、軟體及/或其等之組合中實現。此等各種實施方案可包含可在包含至少一可程式化處理器之一可程式化系統上執行及/或解譯之一或多個電腦程式中之實施方案，該至少一可程式化處理器可係專用或通用、耦合以自一儲存系統、至少一輸入器件及至少一輸出器件接收資料及指令及將資料及指令傳輸至一儲存系統、至少一輸入器件及至少一輸出器件。 此等電腦程式(亦稱為程式、軟體、軟體應用程式或碼)包含一可程式化處理器之機器指令，且可依一高階程序及/或物體導向程式設計語言及/或依組合/機器語言實施。如本文所使用，術語「機器可讀媒體」、「電腦可讀媒體」係指用於提供機器指令及/或資料至一可程式化處理器之任何電腦程式產品、裝置及/或器件(例如磁碟、光碟、記憶體、可程式化邏輯器件(PLD))，包含接收機器指令作為一機器可讀信號之一機器可讀媒體。術語「機器可讀信號」係指用於提供機器指令及/或資料至一可程式化處理器之任何信號。 為提供與一使用者之互動，此處所描述之系統及技術可在具有用於顯示資訊至使用者之一顯示器件(例如一CRT (陰極射線管)或LCD (液晶顯示器)監視器)及使用者可藉此提供輸入至電腦之一鍵盤及一指向器件(例如一滑鼠或一軌跡球)之一電腦上實施。其他種類之器件亦可用於提供與一使用者之互動；例如，提供至使用者之回饋可為任何形式之感覺回饋(例如視覺回饋、聽覺回饋或觸覺回饋)；且來自使用者之輸入可以任何形式接收，包含聽覺、語音或觸覺輸入。 此處所描述之系統及技術可在包含一後端組件(例如作為一資料伺服器)、包含一中間軟體組件(例如一應用伺服器)或包含一前端組件(例如具有一圖形使用者介面或一使用者可透過其與此處所描述之系統及技術之一實施方案互動之一網頁瀏覽器之一客戶端電腦)或此等後端、中間軟體或前端組件之任何組合之一計算系統中實施。系統之組件可由任何形式之數位資料通信或數位資料通信之媒體(例如一通信網路)互連。通信網路之實例包含一區域網路(「LAN」)、一廣域網路(「WAN」)及網際網路。 計算系統可包含客戶端及伺服器。一客戶端及伺服器一般彼此遠離且通常透過一通信網路互動。客戶端與伺服器之關係憑藉在各自電腦上運行且彼此具有一客戶端-伺服器關係之電腦程式發生。 已描述若干實施例。然而，應理解可在不背離說明書之精神及範疇之情況下進行各種修改。 亦應理解當一元件指稱位於另一元件上、連接至另一元件、電連接至另一元件、耦合至另一元件或電耦合至另一元件時，其可直接位於另一元件上、連接或耦合至另一元件或可存在一或多個居間元件。相比而言，當一元件指稱直接位於另一元件上、直接連接至或直接耦合至另一元件時，不存在居間元件。儘管術語直接位於…上、直接連接至或直接耦合至可不在[實施方式]中使用，但展示為直接位於…上、直接連接或直接耦合之元件可指稱如此。可修訂本申請案之請求項以詳述說明書中所描述或圖中所展示之例示性關係。 儘管已如本文所描述繪示所描述之實施方案之某些特徵，但熟習技術者現將想起許多修改、替代、改變及等效物。因此，應理解隨附申請專利範圍意欲涵蓋如落入實施方案之範疇內之所有此等修改及改變。應理解此等修改及改變以實例而非限制之方式呈現，且可對形式及細節進行各種改變。除互斥組合之外，本文所描述之裝置及/或方法之任何部分可以任何組合組合。本文所描述之實施方案可包含所描述之不同實施方案之功能、組件及/或特徵之各種組合及/或子組合。 另外，圖中所描繪之邏輯流程不需要所展示之特定順序或順序次序以達成期望結果。另外，可提供其他步驟，或步驟可自所描述之流程消除，且其他組件可添加至所描述之系統或自所描述之系統移除。因此，其他實施例在以下申請專利範圍之範疇內。儘管本文已描述某些實例性方法、裝置及製品，但本專利之涵蓋範圍之範疇不限制於此。應理解本文所採用之術語係為了描述特定態樣，且不意欲具限制性。相反，本專利適當地涵蓋落入本專利之申請專利範圍之範疇內之所有方法、裝置及製品。 較佳實施例： 實施例1：在包含一手持控制器及一頭戴顯示器(HMD)之一虛擬實境(NR)系統中，一種追蹤該手持控制器之一位置及定向之方法，該方法包括： 由處理電路自放置於該HMD中之複數個輻射發射器接收漫射電磁輻射之一脈衝； 由該處理電路自該漫射電磁輻射產生一數位信號；及 由該處理電路獲得基於該數位信號之該手持控制器之一位置及一定向。 實施例2：如實施例1之方法，其中獲得基於該數位信號之該手持控制器之該位置及定向包含： 比較該數位信號與一查找表(LUT)之複數個信號表示，該複數個信號表示之各者對應於該手持控制器之一各自位置及定向。 實施例3：如實施例1或2之方法，其中該LUT之該複數個信號表示之各預定信號表示包含放置於該HMD中之該複數個輻射發射器之各者之一各自信號部分。 實施例4：如實施例2或3之方法，其中該LUT之該複數個信號表示之各預定信號表示對應於漫射輻射之該脈衝自該HMD中之該複數個漫射輻射發射器發射之一時間。 實施例5：如實施例4之方法，其中該數位信號包含一第一部分及一第二部分； 其中比較該數位信號與該LUT之該複數個信號表示之該預定信號表示包含： 基於該數位信號之該第一部分而產生漫射輻射之該脈衝自該HMD中之該複數個漫射輻射發射器發射之該時間；及 基於該信號之該第二部分及漫射輻射之該脈衝自該HMD中之該複數個漫射輻射發射器發射之該時間而產生該手持控制器之該位置及定向。 實施例6：如實施例2至5之任一者之方法，其中該複數個漫射輻射發射器配置於該HMD內之一指定角圖案中。 實施例7：如實施例2至6之任一者之方法，其中該處理電路包含一光電二極體， 其中該方法進一步包括產生藉由執行該光電二極體對於自該HMD中之該等漫射輻射發射器之各者之照明之一回應之一模擬而離線產生該LUT，該光電二極體回應具有含一雜訊輪廓及一信號輪廓之一傳遞函數，該信號輪廓係具有一上頻率及一下頻率之一指定頻帶外部之零，該雜訊輪廓包含低於一臨界頻率之1/f雜訊，該臨界頻率低於該信號輪廓之該頻帶之該下頻率。 實施例8：如實施例2至7之任一者之方法，其中比較該數位信號與該LUT之該複數個信號表示包含： 產生指示該LUT中之一信號表示與經偵測之漫射輻射之圖案之緊密度之一熱圖，該熱圖包含其中信號表示對應於經偵測之漫射輻射之圖案之一熱區域及其中信號表示不對應於經偵測之漫射輻射之圖案之一冷卻區域；及 選擇該熱圖中之該熱區域中之一信號表示。 實施例9：如實施例8之方法，其中該熱圖繪製於三維位置空間中，且 其中選擇該LUT之該熱區域中之該信號表示包含將該手持控制器之一位置識別為該熱圖之該熱區域中之一座標三元組。 實施例10：如實施例9之方法，其中選擇該LUT之該熱區域中之該信號表示進一步包含： 產生識別為該手持控制器之該位置之該熱圖之該熱區域中之該座標三元組處之一第二熱圖，該第二熱圖繪製於一三維俯仰-偏航-翻滾角空間，該第二熱圖包含其中信號表示對應於經偵測之漫射輻射之圖案之一熱區域及其中信號表示不對應於經偵測之漫射輻射之圖案之一冷卻區域；及 選擇該第二熱圖之該熱區域中之一信號表示。 實施例11：如實施例2至10之任一者之方法，其中該手持控制器包含：(i)一跨阻抗放大器(TIA)，其經組態以自漫射電磁輻射之該脈衝產生一第一電流及自自放置於該HMD中之該複數個輻射發射器外部之輻射源接收之外部輻射產生一第二電流；及(ii)一誤差放大器，其經組態以消除該第二電流； 其中該方法進一步包括： 接收該誤差放大器處之該第二電流，該第二電流在該誤差放大器處產生一第二電壓； 回應於接收該第二電流，產生與該第二電壓與一參考電壓之間之一差值成比例之一控制電壓；及 自該控制電壓產生一負電流，該負電流自該TIA抽離該第二電流。 實施例12：一種電腦程式產品，其包括一非暫時性儲存媒體，該電腦程式產品包含碼，當由亦包含一頭戴顯示器(HMD)之一虛擬實境(VR)系統之一手持控制器之處理電路執行時，碼引起該處理電路執行一方法，該方法包括： 自放置於該HMD中之複數個輻射發射器接收漫射電磁輻射之一脈衝； 自該漫射電磁輻射產生一數位信號；及 獲得基於該數位信號之該手持控制器之一位置及一定向。 實施例13：如實施例12之電腦程式產品，其中獲得基於該數位信號之該手持控制器之該位置及定向包含： 比較該數位信號與一查找表(LUT)之複數個信號表示，該複數個信號表示之各者對應於該手持控制器之一各自位置及定向。 實施例14：如實施例13之電腦程式產品，其中該LUT之該複數個信號表示之各預定信號表示包含放置於該HMD中之該複數個輻射發射器之各者之一各自信號部分。 實施例15：一種虛擬實境(VR)系統，其包括一頭戴顯示器(HMD)及一手持控制器，該VR系統包含： 記憶體；及 控制電路，其耦合至該記憶體，該控制電路經組態以： 自放置於該HMD中之複數個輻射發射器接收漫射電磁輻射之一脈衝； 自該漫射電磁輻射產生一數位信號；及 獲得基於該數位信號之該手持控制器之一位置及一定向。Cross Reference to Related Applications This application claims the priority of US Patent Application No. 62 / 492,801 filed on May 1, 2017, entitled "TRACKING OF POSITION AND ORIENTATION OF OBJECTS IN VIRTUAL REALITY SYSTEMS". The entire contents are incorporated herein by reference. Conventional VR systems require an external system to provide tracking data for an object such as a handheld controller. An example of such an external system is in the form of a pair of fixed transmitters ("base stations") placed at, for example, opposite corners of a room. These transmitters use collimated near-infrared (NIR) lasers or LED lighting to rasterize a scene using a rotary motor configuration. In the embodiments described herein, an object can be tracked without a high-frequency sensor that collects focused illumination data and generates object position and orientation from the illumination data. In the embodiments described herein, a large space (ie, an entire room) of fixed emitters and expensive optics for collimated illumination may not be required. In addition, in the embodiments described herein, a high-bandwidth sensor that can introduce unwanted sensitivity to optical noise can be eliminated. According to the implementation described herein, an improved technique for tracking a handheld controller in a VR system involves a photodiode in the handheld controller detecting a pattern of diffuse radiation generated by a diffuse LED in an HMD. The apparatus and method may also include comparing the detected pattern to a pattern previously simulated offline and represented in a look-up table (LUT). By finding the detected pattern in the LUT, the VR system can determine the position and / or orientation of the handheld controller with sub-millimeter accuracy. Some advantages of the improved technology may lie in the simplicity and / or low cost of the components without sacrificing the accuracy of the position and orientation of the derived handheld controller. A large space dedicated to one of the improved VR systems is needed. Optical elements that generate diffuse radiation and photodiodes in handheld controllers are not as expensive as the optical elements and photodiodes required for collimation. In addition, a novel circuit applied to a photodiode provides an improved VR system with low sensitivity to external light. FIG. 1A illustrates an exemplary VR system 100 including an HMD 105 and a handheld controller 103. The HMD 105 is adapted to a user's head and uses a display 204 that is displayed as a projection in front of the user to cover his eyes. The display 204 inside the HMD 105 shows a virtual environment 115 to the user. In this specific user environment 115, a virtual object 120 exists. The user can use the handheld controller 103 to manipulate the virtual object 120. The VR system 100 uses the handheld controller 103 to track the user's movement and therefore determine what is displayed in the virtual environment 115. In particular, the VR system 100 is configured to track the position and (in some cases) the orientation of the handheld controller 103. Therefore, important VR systems can track the position and orientation of the handheld controller 103 with sufficient accuracy (usually within one millimeter). According to an improved technology, the VR system 100 uses the diffused electromagnetic radiation (such as near-infrared radiation) generated by a radiation source 130 (such as an LED) in the HMD 105 to track the handheld controller 103. These radiation sources 130 may be disposed in an array within a helmet (eg, within a housing of the HMD 105). As part of this tracking of the handheld controller, the handheld controller 103 includes a radiation detector 140. In some embodiments such as described herein, the radiation detector comprises a photodiode. In some embodiments, the radiation detector may include a photomultiplier tube, a charge coupled device, and the like. As shown in FIG. 1A, the HMD also includes a processing circuit 132. The processing circuit 132 is configured to detect signals generated by the radiation detector 140 in the handheld controller 103 in response to receiving the emitted radiation and to determine the position of the handheld controller 103 based on the detected signals and / or Directional. In some configurations, the processing circuit 132 is also coupled to a memory 136 that stores a LUT 138. In these configurations, the processing circuit 132 is configured to perform a comparison operation on the detected signal and the LUT 138 in the memory 136. As will be described herein, the VR system 100 is configured to process the simulation of the radiation source 130 and the radiation detector 140 and the signals generated by the circuitry in the detector via the processor 132 to construct the LUT 138. In some configurations, the processing circuit 132 and the memory 136 are, for example, external to the HMD in the handheld controller 103 or external to one of the computers of the handheld controller 103 and the HMD 105. FIG. 1B illustrates an exemplary LED emitter that can be included in an HMD such as HMD 105 (FIG. 1A). In FIG. 1B, there are twelve LEDs arranged on a curved surface embedded in an HMD. Each of the LEDs is soldered to a printed circuit board and draws power from the HMD. In some embodiments, the LED emits electromagnetic radiation at a near infrared (NIR) wavelength (eg, between 700 nm and 1000 nm). In some embodiments, the LED emits this radiation at an optical wavelength, near infrared wavelength, far infrared wavelength, and microwave wavelength. As discussed herein, it is advantageous to simulate a radiation pattern emitted by a radiation source in the HMD 105 so that when a room is detected at the handheld controller 103, the actual radiation pattern can determine the position and orientation of the handheld controller 103. According to this, each radiation source 130 emits radiation according to a known brightness profile, and this profile can be used to determine the brightness received at the handheld controller 103. Because the handheld controller 103 includes a radiation detector 140 (eg, a photodiode that converts radiant energy into electrical energy), the position and orientation of the handheld controller 103 will govern the radiation profile received at the detector 140. The circuit at the detector 140 generates an electrical signal based on a received profile that can also be simulated. It is a signal generated by this circuit recorded in LUT 138 in memory 136. In some embodiments including those discussed herein, multiple radiation detectors may be present in the handheld controller 103. FIGS. 1C and 1D are diagrams showing an exemplary radiance map of one of the characteristics of the LED shown in FIG. 1B with a NIR wavelength. This luminance profile can be used in the embodiments described herein to simulate the radiation signal received by the handheld controller 103. In each figure is a pair of diagrams: the left is a polar coordinate diagram and the right is a rectangular coordinate diagram. The polar plot shows one-half of a radiation profile in which the polar angle of the brightness is a function of a vertical axis of an LED. The rectangular coordinate plot shows the same plot but shows one of the small values of brightness for more detailed inspection. As shown in Figure 1C, the graph shows a relatively narrow brightness profile (ie, the brightness decreases relatively quickly at a vertical axis away from the LED). However, the right-angled graph shows that the brightness decreases more slowly toward one of the horizontal axes of the LED. In contrast, the graph in FIG. 1D shows a relatively wide profile (ie, the brightness decreases relatively slowly at a vertical axis away from the LED). However, the right-angled graph shows that the brightness decreases faster toward one of the horizontal axes of the LED. FIG. 2 is a diagram of an array of simulated radiation received at a photodiode in a handheld controller 103 of each LED radiation transmitter. The simulation uses the position and orientation of the twelve LEDs shown in FIG. 1B together with the luminance data (examples of the luminance data are shown in FIG. 1C and FIG. 1D). Each of the figures is a flat heat map of a region in which light indicates the highest receiving intensity and dark indicates the region of the lowest receiving intensity. The horizontal and vertical axes of each figure represent positions along one of the receiving areas of the handheld controller (such as directly above a photodiode). FIG. 3A is a diagram illustrating a diagram of an exemplary simulated radiation pulse train over a millisecond time scale. The graph in FIG. 3A represents the overall intensity of a pulse train and a pulse train derived from diffuse electromagnetic radiation received from an LED and incident on a photodiode and then subjected to an analog-to-digital conversion (ADC). On one of the polar bodies). The period of the digital pulse is slightly greater than 0. 1 ms. The time pattern of the impulse signal from the diffuse radiation implies that the pattern in the LUT should be time dependent. therefore, As this article will discuss, The procedure of comparing an actual signal with a pattern in the LUT involves synchronizing the actual signal to the LUT to determine the correction phase of the pattern. The frequency component of the pulse train in the top view may include a large number of frequencies centered at about 1000 Hz (period of 1 / row). But it also has a small amount of low frequency (associated with the DC portion of the signal) and a small amount of high frequency. Both low frequency components and high frequency components can be associated with various unwanted noise weights and can cause inaccuracy in deriving the position and orientation of the handheld controller 103. therefore, In some embodiments, The VR system 100 may include a band-pass filter. The top view shows the results of an example bandpass filter applied to an example pulse train. FIG. 3B is a graph showing a filtered signal voltage versus time in millimeters in volts. The period of the filtered pulse train is the same as the unfiltered pulse train. But the amplitude and phase have changed. It is this band-pass filtered pulse train that determines the phase of the pattern in LUT 138. As discussed above, A simulation of the radiation at the handheld controller is needed to construct a LUT 138 for determining the position and orientation of the handheld controller in response to the handheld controller 103 receiving radiation from the source 130 in the HMD 105. The above discussion illustrates the spatial and temporal nature of the radiation received at the handheld controller 103. In addition, The nature of the receiver may also be required to accurately simulate the actual electrical signals received by the VR system 100. FIG. 4A illustrates an exemplary group of photodiode radiation detectors 140 in a handheld controller 103 (see FIG. 1A). The photodiode is arranged along the surface of the handheld controller 103 in a pre-designated pattern, and the photodiode generates its own signal in response to the radiation incident on its surface. FIG. 4B is a diagram of an exemplary transfer function of a photodiode in a handheld controller. In this figure, The transfer function has the characteristics of a band-pass filter, It is below zero for a high frequency fH and a low frequency fL. The figure further illustrates a noise profile of a photodiode in which 1 / f noise is expected to be lower than a critical frequency fc <fH and a DC noise is higher than the critical frequency fc. FIG. 4C is a schematic circuit diagram of one of a photodiode and a band-pass filter. The circuit diagram shows two operational amplifiers: A first operational amplifier for amplifying a signal generated by an incident pulse of diffuse radiation and a second operational amplifier for canceling a current generated by ambient light. This configuration makes the photodiode used in the handheld controller more robust in the surrounding light surface and in other DC noise. Once the VR system 100 determines the signals received and processed by the handheld controller 103, The VR system 100 then determines the position of the handheld controller 103. usually, There is a set of possible locations for a handheld master that is constrained due to the configuration of the VR system (such as the connection of the handheld controller to the VR system, etc.). FIG. 5 is a diagram illustrating an example restricted space for a position of a handheld controller. The restricted space in FIG. 5 is in the form of a solid object in a three-dimensional coordinate space. A solid object shaped like an inverted cone represents all possible positions of the group in the space that can be occupied by a handheld controller. As far as the points in this solid object are concerned, There is a set of all possible positions where the handheld controller can hold for that point. For discrete sampling, Each possible discrete position is represented as a three-dimensional pixel or a volume pixel (ie, a three-dimensional pixel). In FIG. 4A, According to the review, There are usually multiple photodiodes in a handheld controller 103. Each photodiode generates its own pulse train signal for the VR system. The LUT can ultimately represent each signal individually. The LUT 138 may, for example, combine the signals into a single signal by averaging. Figure 6 shows the LED receiving pulses from the HMD 105, A diagram of an exemplary pulse train output by a photodiode in the handheld controller 103 after diffuse radiation. In this example, There are nine photodiodes. In this example, Each photodiode generates a different signal from each of the twelve LEDs shown in FIG. 1B. Because each photodiode has a different viewing angle relative to one of the LEDs, So each photodiode produces a different signal train. FIG. 7 illustrates a diagram of an exemplary LUT 138. FIG. The LUT 138 as shown in FIG. 7 appears as a color map but is actually a discrete pattern of a set of stereo pixel index and time index. A stereo pixel index is an integer function of the possible discrete positions and orientations that a handheld controller can present. E.g, The stereo pixel index can be three position coordinates (X, Y, Z) and three angular coordinates (pitch, yaw, One of the tumbling) Weighted linear combination. These three position coordinates and three angular coordinates should be uniquely determined from a stereo pixel index. Each discrete element of LUT 138 in FIG. 7 is a set of nine patterns. One pattern of each photodiode is arranged in the handheld controller. Along these lines, The signal output from the ADC and the band-pass filter is divided into two pieces: A first movie to determine the time or phase of the pattern, A second longer film is used to determine the best stereo pixel index. As far as the LUT 138 shown in FIG. 7 is concerned, The best column is determined based on matching the first piece of the pattern to each of the patterns in a particular row. In some configurations, Time is determined by finding the best column in more than one row by, for example, averaging the patterns on the rows. then, Find the best stereo pixel index by searching through the best rows. FIG. 8 is a diagram showing an example procedure for determining one of the most probable positions taken by the handheld controller 103. As shown in Figure 8, One of the photodiodes is configured to output a signal to a respective ADC in response to receiving a pulse of diffuse radiation. Each ADC then outputs a digital signal to a digital signal processor to reduce noise and detect any interference with other signals. then, The final digital signal is detected and input into one of the related operations of the LUT 138. The output of this related operation is a heat map on the stereo pixel shown in FIG. 5. The three-dimensional heat map on the three-dimensional pixel is a result of inverse mapping of the three-dimensional pixel index to the position in the object in the Sane. then, This three-dimensional heat map represents the possibility of a handheld controller in a position represented by a three-dimensional pixel. In the example shown in Figure 8, The bright area indicates the location most likely to be taken by the handheld controller and the dark area indicates the location most likely to be taken by the handheld controller. In some embodiments, The related operation generates a heat map by differentiating a signal generated by each photodiode and a signal expressed in the LUT and averaging the square or absolute value of the difference to generate a metric. then, The color of the heat map can be based on the value of the metric. From the most likely position, A second three-dimensional heat map can be generated based on the stereo pixel index in a manner similar to one of the orientations and the most likely orientation of the handheld controller can be derived from this second heat map. Once a most probable pose is derived from the 3D heat map, Then there will be further tracking and filtering to remove any noise caused by stereo pixels and external signals. then, This filtering result is input to the VR system 100 as a gesture of the handheld controller at a specific time. FIG. 9A is a diagram illustrating an exemplary circuit topology for subtracting DC noise current from a transimpedance amplifier (TIA) portion of a photodiode circuit. In the first topology shown in the figure ("Topology 1"), There is no additional circuit for subtracting this DC current and the gain profile of the circuit has very large and unwanted low frequency components that can represent sensitivity to ambient light. In the second topology shown in the figure ("Topology 2"), The circuit has been changed to place two resistors on either side of a voltage divider. This voltage divider can be used to draw low frequency current from the TIA output. The result is that the gain of the circuit at low frequencies is reduced, Improve the first topology. The third topology ("Topology 3") has an output connected to the TIA and a servo loop that feeds back to the TIA. The result is a zero gain below a threshold frequency to indicate that low frequency and DC current have eliminated TIA as needed. Further details of the servo loop are shown in Figure 9b. FIG. 9B is a diagram showing the servo loop in FIG. 9a which eliminates the low frequency and DC current in the TIA. The servo loop includes a second operational amplifier connected to the output of the TIA and a low-pass filter connected to the output of the operational amplifier and input back to the TIA. Low frequency current is received at the operational amplifier, The low-frequency current generates a low-frequency voltage at the error amplifier. In response to receiving low-frequency current, The operational amplifier generates a control voltage proportional to a difference between a low frequency voltage and a reference voltage. then, The control voltage is input into a low-pass filter, It then generates a negative current from the control voltage, Negative current draws low frequency current from the TIA more efficiently than just a voltage divider. One or more of the components and interfaces disclosed herein may be reproduced, Implemented in parallel, Implement in singular, Combined implementation, Separate implementation, Reconfigure, ignore, Eliminate and / or implement in any other way. In addition, Any of the disclosed components and interfaces may be implemented by a processor, A computer and / or a machine with a processor such as the example processor platforms P00 and P50 discussed below in connection with FIG. 10 is implemented. An example processor includes, but is not limited to, a circuit, A programmable processor, fuse, An application specific integrated circuit (ASIC), A programmable logic device (PLD), A programmable logic device (FPLD), A field programmable gate array (FPGA), A digital signal processor (DSP), A graphics processing unit (GPU), A central processing unit (CPU), A microcontroller, A controller and so on. Any of the components and interfaces disclosed herein may be implemented, for example, by a processor, A computer and / or instructions executed by one or more of a machine with a processor, Code, Machine-readable instructions and more. A processor, A computer and / or a machine with a processor can be used, Configured and / or programmed to perform and / or implement the examples disclosed herein. E.g, Any of the examples may be embodied in a file stored by a processor, A computer and / or other machines with a processor such as the example processor platforms P00 and P50 discussed below in connection with FIG. 10 access a tangible and / or non-transitory computer-readable medium, Code, Machine-readable instructions, etc. Machine-readable instructions include, for example, causing a processor, A computer and / or a machine with a processor executes instructions for one or more specific programs or methods. When reading one of the claims of this patent incorporating one or more of the elements of FIG. 10 to cover a pure software and / or firmware implementation, At least one of the elements of FIG. 10 is hereby clearly defined to include a tangible article such as a tangible machine-readable medium, such as firmware and / or software, that stores machine-readable instructions. The exemplary methods disclosed herein may be implemented, for example, by a processor, Instructions executed by a computer and / or other machine with a processor, Code, Machine-readable instructions. A processor, A controller and / or any other suitable processing device such as that shown in FIG. 10 may be used, Configured and / or programmed to perform and / or implement example methods. E.g, processor, The controller and / or any suitable processing device is embodied in a memory which can be stored by a processor, A computer and / or other machine with a processor such as discussed below in conjunction with FIG. 10 accesses instructions on a tangible and / or non-transitory computer-readable medium, Code and / or machine-readable instructions. Many other methods of implementing the example methods can be employed. E.g, May change the order of execution and / or may change, eliminate, Subdivide or combine one or more of the described blocks and / or interactions. In addition, May be executed sequentially and / or by, for example, separate processing of threads, processor, Device, Discrete logic, Circuitry, etc., executes any or the entire example method in parallel. As used in this article, The terms "computer-readable medium" and "machine-readable medium" specifically exclude the transmission of signals. Example computer-readable or machine-readable media includes, but is not limited to, a volatile and / or non-volatile memory, A volatile and / or non-volatile memory device, A compact disc (CD), A digital versatile disc (DVD), One read-only memory (ROM), A random access memory (RAM), A flash drive, A floppy disk, A synchronous dynamic random access memory (SDRAM), A dynamic random access memory ((DRAM), A RAMBUS dynamic random access memory ((RDRAM), -Programmable ROM (PROM), An electronically programmable ROM (EPROM), An electronically erasable PROM (EEPROM), A solid state (SS) memory, A solid state disk (SSD), An optical storage disk, An optical storage device, A magnetic storage disk, A network attached storage (NAS) device, A magnetic storage device, A cache and / or where the information is stored for any duration (e.g., for extended time periods, permanent, Brief moments, For temporary buffering and / or caching of information) and can be processed by a processor, One or any combination of other storage media accessed by a computer and / or other machine with a processor. FIG. 10 shows an example of a general computer device P00 and a general mobile computer device P50 that can be used with the technology described herein. The computing device P00 is intended to represent a device such as a laptop, Desktop, tablet, workstation, Personal digital assistant, TV set, server, Blade server, Digital computers in various forms of mainframe and other appropriate computing devices. The computing device P50 is intended to represent such things as a personal digital assistant, Cellular phone, Various forms of mobile devices for smart phones and other similar computing devices. Components shown here, The connection and relationship of the components and the function of the components are meant to be illustrative only. It is not intended to limit the embodiments of the invention described and / or claimed in this document. The computing device P00 includes a processor P02, Memory P04, A storage device P06, Connected to one of the high-speed interface P08 of the memory P04 and the high expansion port P10 and one of the low-speed interface P12 of the low-speed bus P14 and the storage device P06. The processor P02 may be a semiconductor-based processor. The memory P04 may be a semiconductor-based memory. Component P02, P04, P06, P08, Each of P10 and P12 is interconnected using various buses and can be installed on a common motherboard or in other ways as appropriate. The processor P02 can process instructions for execution in the computing device P00, Contains instructions stored in the memory P04 or on the storage device P06 to display graphical information of a GUI on an external input / output device such as a display P16 coupled to the high-speed interface P08. In other embodiments, Optionally, multiple processors and / or multiple buses and multiple memories or types of memory are used. In addition, Can connect multiple computing devices P00, Where each device provides the necessary operation (e.g. as a server bank, A blade server or a multi-processor system). The memory P04 stores the information in the computing device P00. In one embodiment, The memory P04 is a volatile memory unit or a plurality of volatile memory units. In another embodiment, The memory P04 is a non-volatile memory unit or a plurality of volatile memory units. The memory P04 may also be another form of computer-readable medium such as a magnetic disk or an optical disk. The storage device P06 can provide a large amount of storage for the computing device P00. In one embodiment, The storage device P06 may be or contain a device such as a floppy disk, A hard disk device, A disc device or a tape device, A computer-readable medium of a flash memory or other similar solid-state memory device or an array of devices (including a storage area network or other device in a configuration). A computer program product can be tangibly embodied in an information carrier. Computer program products can also contain instructions. When executed, The instructions execute one or more methods such as those described above. Information carriers such as memory P04, A computer or machine-readable medium that stores one of the memories on the device P06 or the processor P02. The high-speed controller P08 manages the bandwidth-intensive operation of the computing device P00, The low-speed controller P12 manages lower bandwidth-intensive operations. This assignment of functions is exemplary only. In one embodiment, High-speed controller P08 is coupled to memory P04, The display P16 (for example, through a graphics processor or accelerator) and a high expansion port P10 coupled to a variety of expansion cards (not shown). In an embodiment, The low-speed controller P12 is coupled to the storage device P06 and the low-speed expansion port P14. Can include various communication ports (e.g. USB, Bluetooth, Ethernet, (Wireless Ethernet) low-speed expansion ports can be coupled to, for example, a network adapter, such as a keyboard, A pointing device, A scanner or a network device such as a switch or router) one or more input / output devices. The computing device P00 can be implemented in several different forms as shown in the figure. E.g, It can be implemented as a standard server P20 or multiple times in a group of these servers. It can also be implemented as part of a rack server system P24. In addition, It can be implemented in a personal computer such as a laptop computer P22. Instead, The components from the computing device P00 may be combined with other components such as a mobile device (not shown in the figure), such as the device P50. Each of these devices may contain a computing device P00, One or more of P50 and the whole system can be composed of multiple computing devices P00, Composition of P50. Among other components, The computing device P50 includes a processor P52, Memory P64, An input / output device such as a display P54, A communication interface P66 and a transceiver P68. The computing device P50 may also have a storage device such as a micro-driver or other device to provide additional storage. Component P50, P52, P64, P54, Each of P66 and P68 is interconnected using various buses, And several components can be installed on a common motherboard or other methods as appropriate. The processor P52 can execute instructions in the computing device P50, Contains instructions stored in memory P64. The processor may be implemented as a chipset or a chip containing separate or multiple analog and digital processors. The processor can provide, for example, coordination of other components of the device P50 (such as user interface control, Applications run by device P50 and wireless communication through device P50). The processor P52 can communicate with a user through a control interface P58 and a display interface P56 coupled to a display P54. The display P54 may be, for example, a TFT LCD (thin film transistor liquid crystal display) or an OLED (organic light emitting diode) display or other suitable display technology. The display interface P56 may include appropriate circuits for driving the display P54 to present graphics and other information to a user. The control interface P58 can receive commands and conversion commands from a user for submission to the processor P52. In addition, An external interface P62 can be provided to communicate with the processor P52 to achieve near-area communication between the device P50 and other devices. In some embodiments, The external interface P62 may provide, for example, wired communication or in other embodiments, Through wireless communication, And multiple interfaces can also be used. The memory P64 stores the information in the computing device P50. The memory P64 may be implemented as a computer-readable medium or several computer-readable media, One or more of a volatile memory unit or a plurality of volatile memory units or a non-volatile memory unit or a plurality of non-volatile memory units. An expansion memory P74 can also be provided and connected to the device P50 through an expansion interface P72 that can include, for example, a SIMM (single in-line memory module) card interface. This expansion memory P74 can provide additional storage space for device P50. Or it can store the application or other information of the device P50. in particular, Expansion memory P74 may contain instructions for implementing or supplementing the above procedures, It can also include safety information. E.g, therefore, Expansion memory P74 can be provided as a complete module of device P50, It can also be programmed with instructions that allow the safe use of device P50. In addition, Security applications and additional information can be provided via the SIMM card (such as placing identification information on the SIMM card in a non-decipherable manner). The memory may include, for example, flash memory and / or NVRAM memory as discussed below. In one embodiment, A computer program product is tangibly embodied in an information carrier. Computer program products contain instructions. When executed, The instructions execute one or more methods such as those described above. Information carriers such as memory P64, The extended memory P74 may be, for example, a computer or machine-readable medium on the processor P52 that can be received via the transceiver P68 or the external interface P62. The device P50 can communicate wirelessly through a communication interface P66 which can include a digital signal processing circuit where necessary. The communication interface P66 can be used in, for example, (especially) GSM voice calls, SMS, EMS or MMS messaging, CDMA, TDMA, PDC, WCDMA, Communication is provided under various modes or protocols of CDMA2000 or GPRS. This communication can occur, for example, via radio frequency transceiver P68. In addition, Such as using a Bluetooth, Wi-Fi or other such transceivers (not shown) have short-range communications. In addition, Global Positioning System (GPS) receiver module P70 can provide additional navigation and position related wireless data to device P50, Additional navigation and location-related wireless data may be used by applications running on device P50, as appropriate. The device P50 can also audibly communicate using an audio codec P60 that can receive spoken information from a user and convert it into usable digital information. Similarly, The audio codec P60 may, for example, generate a user's audible sound through a speaker (for example in a mobile phone of the device P50). This sound can include sound from a voice phone call, May include recorded sounds (e.g. voice messages, Music files, etc.) and may also include sounds generated by applications operating on the device P50. The computing device P50 can be implemented in several different forms as shown in the figure. E.g, It can be implemented as a cellular phone P80. It can also be implemented as a smart phone P82, Personal digital assistants or other similar mobile devices. FIG. 11 illustrates an exemplary embodiment of a head mounted display such as that shown in FIG. 1A. In Figure 11, A user wearing an HMD 700 holds a portable handheld electronic device 702. The handheld electronic device 702 may be, for example, a smart phone, 一 Controller, A joystick may be paired with the HMD 700 and communicate with the HMD 700 to interact with another (several) portable handheld electronic devices in the immersive virtual environment created by the HMD 700. The handheld electronic device 702 may be operatively coupled or paired with the HMD 700 via, for example, a wired connection or a wireless connection such as, for example, a WiFi or Bluetooth connection. This pairing or operative coupling of the handheld electronic device 702 and the HMD 700 can provide communication between the handheld electronic device 702 and the HMD 700 and the exchange of data between the handheld electronic device 702 and the HMD 700. This may allow the handheld electronics 702 to act as a controller that communicates with the HMD 700 to interact in an immersive virtual environment created by the HMD 700. which is, One of the handheld electronics 702 is manipulated (such as, for example, emitted by the handheld electronics 702 and directed to a light beam or ray for selecting a virtual object or feature and / or received on a touch surface of the handheld electronics 702 One of the inputs and / or one of the handheld electronic devices 702 can be converted into a corresponding selection or movement or other type of interaction in an immersive virtual environment generated by the HMD 700. E.g, HMD 700 can be used with handheld electronics 702 to generate a virtual environment as described above, And the handheld electronic device 702 can be manipulated to change the proportion or perspective of the user relative to the virtual features in the virtual environment as described above. 12A and 12B are perspective views of an exemplary HMD such as, for example, the HMD 700 worn by the user in FIG. 11, And FIG. 12C illustrates an example handheld electronic device such as, for example, the handheld electronic device 702 shown in FIG. 11. The handheld electronic device 802 may include a housing 803, one of the internal components of the receiving device 802, And a user interface 804 that is available on the outside of one of the housings 803. The user interface 804 may include a touch-sensitive surface 806 configured to receive user touch input. The user interface 804 may also include, for example, actuation buttons, Knob, Other components of joysticks and the like for manipulation by a user. In some embodiments, At least a part of the user interface 804 can be configured as a touch screen, The part of the user interface 804 is configured to display the user interface items to the user, A touch input is also received from the user on the touch-sensitive surface 806. The handheld electronic device 802 may also include one configured to selectively emit light (e.g., a light beam or ray) through a port in the housing 803 in response to receiving a user input at the user interface 804 Light source 808. HMD 800 may include a housing 810 coupled to a frame 820, An audio output device 830, which includes, for example, a speaker installed in the headset, is also coupled to the frame 820. In FIG. 8B, A front portion 810a of the housing 810 is rotated away from a base portion 810b of the housing 810 to make some components received in the housing 810 visible. A display 840 may be mounted on one of the front portions 810a of the housing 810 facing the inner side. When the front portion 810a is in a closed position against the base portion 810b of the housing 810, The lens 850 can be installed in the housing 810, Between the eyes of the user and the display 840. In some embodiments, The HMD 800 may include a sensing system 860 with various sensors, a control system 870 with a processor 890, and various control system devices to facilitate the operation of the HMD 800. In some embodiments, HMD 800 may include a camera 880 to capture still and moving images. The images captured by the camera 880 can be used to help track the physical location of a user and / or a physical location of one of the handheld electronic devices 802, Or a physical environment relative to the virtual environment and / or a user that can be displayed on the display 840 in a pass mode to allow the user to temporarily leave the virtual environment and without having to move the HMD 800 or otherwise change the configuration of the HMD 800 Return to the physical environment to move the housing 810 out of the user's sight. In some embodiments, The HMD 800 may include a gaze tracking device 865 to detect and track the eyes of one of the users. The gaze tracking device 865 may include, for example, an image sensor 865A or multiple image sensors 865A to capture a user's eye (for example, a specific part of the user's eye, Images such as (for example, the pupil) to detect and track the direction and movement of the user's line of sight. In some embodiments, HMD 800 can be configured so that the detected sight is processed as a user input to be converted into a corresponding interaction in an immersive virtual experience. Various implementations of the systems and technologies described herein can be implemented in digital electronic circuits, Integrated circuit, Specially designed ASIC (application specific integrated circuit), Computer hardware, firmware, Software and / or combinations thereof. These various implementations may include implementations in one or more computer programs executable and / or interpretable on a programmable system including at least one programmable processor, The at least one programmable processor may be dedicated or general purpose, Coupled to a storage system, At least one input device and at least one output device receive data and instructions and transmit the data and instructions to a storage system, At least one input device and at least one output device. These computer programs (also known as programs, software, Software application or code) contains machine instructions for a programmable processor, It can be implemented according to a high-level procedure and / or object-oriented programming language and / or combined / machine language. As used in this article, The term "machine-readable medium", "Computer-readable medium" means any computer program product used to provide machine instructions and / or data to a programmable processor, Devices and / or devices (e.g. disks, Disc, Memory, Programmable Logic Device (PLD)), A machine-readable medium containing receiver machine instructions as a machine-readable signal. The term "machine-readable signal" refers to any signal used to provide machine instructions and / or information to a programmable processor. To provide interaction with a user, The systems and technologies described herein can be implemented by having a display device (such as a CRT (cathode ray tube) or LCD (liquid crystal display) monitor) for displaying information to the user and by which the user can provide input to a computer A keyboard and a pointing device (such as a mouse or a trackball) are implemented on a computer. Other types of devices can also be used to provide interaction with a user; E.g, The feedback provided to the user can be any form of sensory feedback (e.g. visual feedback, Auditory feedback or tactile feedback); And input from the user can be received in any form, Including hearing, Voice or tactile input. The systems and technologies described herein can include a back-end component (e.g., as a data server), Contains an intermediate software component (such as an application server) or a front-end component (such as having a graphical user interface or a web browser through which a user can interact with one of the systems and technologies described herein One client computer) or these backends, Intermediate software or any combination of front-end components implemented in a computing system. The components of the system may be interconnected by any form of digital data communication or digital data communication medium (eg, a communication network). Examples of communication networks include a local area network (`` LAN ''), A wide area network ("WAN") and the Internet. The computing system may include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship between the client and the server occurs by computer programs running on the respective computers and having a client-server relationship with each other. Several embodiments have been described. however, It should be understood that various modifications can be made without departing from the spirit and scope of the description. It should also be understood that when an element is referred to as being on another element, Connected to another component, Electrically connected to another component, When coupled to or electrically coupled to another element, It can be located directly on another element, Connected or coupled to another element or there may be one or more intervening elements. in comparison, When an element is referred to as being directly on another element, When directly connected to or directly coupled to another component, There are no intervening elements. Although the term is directly on, Directly connected to or directly coupled to may not be used in [Embodiment], But displayed directly on, Directly connected or directly coupled elements may be referred to as such. The claims of this application may be amended to detail the exemplary relationships described in the specification or shown in the drawings. Although certain features of the described embodiments have been illustrated as described herein, But those skilled in technology will now remember many modifications, Instead, Changes and equivalents. therefore, It should be understood that the scope of the accompanying patent application is intended to cover all such modifications and changes as fall within the scope of the embodiments. It should be understood that such modifications and changes are presented by way of example rather than limitation, Various changes can be made to the form and details. In addition to mutually exclusive combinations, Any part of the devices and / or methods described herein may be combined in any combination. The embodiments described herein may include the functionality of different embodiments described, Various combinations and / or sub-combinations of components and / or features. In addition, The logic flow depicted in the figure does not require the particular order or sequence shown to achieve the desired result. In addition, Additional steps are available. Or steps can be eliminated from the described process, And other components can be added to or removed from the described systems. therefore, Other embodiments are within the scope of the following patent applications. Although some example methods have been described herein, Devices and products, However, the scope of coverage of this patent is not limited thereto. It should be understood that the terminology used herein is to describe a particular aspect, It is not intended to be limiting. in contrast, This patent properly covers all methods falling within the scope of the patent application of this patent, Devices and products. Preferred embodiment: Example 1: In a virtual reality (NR) system including a handheld controller and a head mounted display (HMD), A method for tracking the position and orientation of one of the handheld controllers, The method includes: A processing circuit receives a pulse of diffused electromagnetic radiation from a plurality of radiation transmitters placed in the HMD; A digital signal is generated by the processing circuit from the diffused electromagnetic radiation; And obtaining a position and a certain direction of the handheld controller based on the digital signal by the processing circuit. Example 2: As in the method of Example 1, Wherein obtaining the position and orientation of the handheld controller based on the digital signal includes: Comparing the digital signal with a plurality of signal representations of a lookup table (LUT), Each of the plurality of signals corresponds to a respective position and orientation of one of the handheld controllers. Example 3: As in the method of embodiment 1 or 2, Each of the predetermined signals represented by the plurality of signals of the LUT represents a respective signal portion including one of each of the plurality of radiation emitters placed in the HMD. Example 4: As in the method of embodiment 2 or 3, Each of the predetermined signals represented by the plurality of signals of the LUT represents a time when the pulse corresponding to the diffuse radiation is emitted from the plurality of diffuse radiation emitters in the HMD. Example 5: As in the method of Example 4, The digital signal includes a first part and a second part; Wherein comparing the digital signal with the predetermined signal representation represented by the plurality of signals of the LUT includes: The time at which the pulse that generates diffuse radiation based on the first portion of the digital signal is emitted from the plurality of diffuse radiation emitters in the HMD; And generating the position and orientation of the handheld controller based on the time that the second portion of the signal and the pulse of diffuse radiation were emitted from the plurality of diffuse radiation emitters in the HMD. Example 6: The method as in any one of embodiments 2 to 5, The plurality of diffuse radiation emitters are arranged in a designated corner pattern in the HMD. Example 7: The method as in any one of embodiments 2 to 6, The processing circuit includes a photodiode, The method further includes generating the LUT offline by performing a simulation of the photodiode in response to one of the illumination from each of the diffuse radiation emitters in the HMD, The photodiode response has a transfer function containing a noise profile and a signal profile. The signal profile has zeros outside a specified frequency band of one of the upper and lower frequencies, The noise profile contains 1 / f noise below a critical frequency, The critical frequency is lower than the lower frequency of the frequency band of the signal profile. Example 8: The method as in any one of Examples 2 to 7, The comparison between the digital signal and the plurality of signals of the LUT includes: Generating a heat map indicating the closeness of a signal in the LUT to the pattern of detected diffuse radiation, The heat map includes a hot area where the signal represents a pattern corresponding to the detected diffuse radiation and a cooling area where the signal represents a pattern which does not correspond to the detected diffuse radiation; And Select one of the signal representations in the hot zone in the heat map. Example 9: As in the method of Example 8, The heat map is drawn in a three-dimensional position space. And the signal in the hot area where the LUT is selected indicates that it includes identifying a position of the handheld controller as a coordinate triple in the heat area of the heat map. Example 10: As in the method of Example 9, The selection of the signal in the hot zone of the LUT further includes: Generating a second heat map at the coordinate triplet in the heat region of the heat map identified as the location of the handheld controller, The second heat map is drawn in a three-dimensional pitch-yaw-roll angle space, The second heat map includes a thermal area where the signal represents a pattern corresponding to the detected diffuse radiation and a cooling area where the signal represents a pattern that does not correspond to the detected diffuse radiation; And Select one of the signal representations in the hot zone of the second heat map. Example 11: The method as in any one of embodiments 2 to 10, The handheld controller includes: (i) a transimpedance amplifier (TIA), It is configured to generate a first current from the pulse of diffused electromagnetic radiation and a second current from external radiation received from a radiation source external to the plurality of radiation emitters placed in the HMD; And (ii) an error amplifier, It is configured to eliminate the second current; The method further includes: Receiving the second current at the error amplifier, The second current generates a second voltage at the error amplifier; In response to receiving the second current, Generating a control voltage proportional to a difference between the second voltage and a reference voltage; And a negative current is generated from the control voltage, The negative current is drawn from the TIA by the second current. Example 12: A computer program product, It includes a non-transitory storage medium, The computer program product contains code. When executed by a processing circuit of a handheld controller that also includes a head mounted display (HMD), a virtual reality (VR) system, The code causes the processing circuit to execute a method, The method includes: Receiving a pulse of diffused electromagnetic radiation from a plurality of radiation emitters placed in the HMD; Generating a digital signal from the diffused electromagnetic radiation; And obtaining a position and orientation of the handheld controller based on the digital signal. Example 13: As the computer program product of Embodiment 12, Wherein obtaining the position and orientation of the handheld controller based on the digital signal includes: Comparing the digital signal with a plurality of signal representations of a lookup table (LUT), Each of the plurality of signals corresponds to a respective position and orientation of one of the handheld controllers. Example 14: As the computer program product of Embodiment 13, Each of the predetermined signals represented by the plurality of signals of the LUT represents a respective signal portion including one of each of the plurality of radiation emitters placed in the HMD. Example 15: A virtual reality (VR) system, It includes a head-mounted display (HMD) and a handheld controller, The VR system contains: Memory; And control circuits, Which is coupled to that memory, The control circuit is configured to: Receiving a pulse of diffused electromagnetic radiation from a plurality of radiation emitters placed in the HMD; Generating a digital signal from the diffused electromagnetic radiation; And obtaining a position and orientation of the handheld controller based on the digital signal.
100‧‧‧虛擬實境(VR)系統100‧‧‧ Virtual Reality (VR) System
103‧‧‧手持控制器103‧‧‧Handheld Controller
105‧‧‧頭戴顯示器(HMD)105‧‧‧ Head Mounted Display (HMD)
115‧‧‧虛擬環境/使用者環境115‧‧‧Virtual Environment / User Environment
120‧‧‧虛擬物體120‧‧‧ Virtual Object
130‧‧‧輻射源130‧‧‧ radiation source
132‧‧‧處理電路/處理器132‧‧‧Processing Circuit / Processor
136‧‧‧記憶體136‧‧‧Memory
138‧‧‧查找表(LTU)138‧‧‧ Lookup Table (LTU)
140‧‧‧輻射偵測器140‧‧‧ radiation detector
204‧‧‧顯示器204‧‧‧ Display
700‧‧‧頭戴顯示器(HMD)700‧‧‧ Head Mounted Display (HMD)
702‧‧‧手持電子器件702‧‧‧Handheld electronics
800‧‧‧頭戴顯示器(HMD)800‧‧‧ Head Mounted Display (HMD)
802‧‧‧手持電子器件802‧‧‧Handheld electronic device
803‧‧‧外殼803‧‧‧shell
804‧‧‧使用者介面804‧‧‧user interface
806‧‧‧觸敏表面806‧‧‧ touch-sensitive surface
808‧‧‧光源808‧‧‧light source
810‧‧‧外殼810‧‧‧shell
810a‧‧‧前部分810a‧‧‧front
810b‧‧‧基座部分810b‧‧‧base part
820‧‧‧框架820‧‧‧Frame
830‧‧‧音訊輸出器件830‧‧‧Audio output device
840‧‧‧顯示器840‧‧‧ Display
850‧‧‧透鏡850‧‧‧ lens
860‧‧‧感測系統860‧‧‧sensing system
865‧‧‧視線追蹤器件865‧‧‧Gaze Tracking Device
865A‧‧‧影像感測器865A‧‧‧Image Sensor
870‧‧‧控制系統870‧‧‧control system
880‧‧‧攝影機880‧‧‧Camera
890‧‧‧處理器890‧‧‧ processor
P00‧‧‧處理器平台/一般電腦器件/計算器件P00‧‧‧Processor Platform / General Computer Device / Computing Device
P02‧‧‧處理器P02‧‧‧Processor
P04‧‧‧記憶體P04‧‧‧Memory
P06‧‧‧儲存器件P06‧‧‧Storage Device
P08‧‧‧高速介面/高速控制器P08‧‧‧High-speed interface / high-speed controller
P10‧‧‧高度擴充埠P10‧‧‧ Height expansion port
P12‧‧‧低速介面/低速控制器P12‧‧‧Low-speed interface / low-speed controller
P14‧‧‧低速匯流排/低速擴充埠P14‧‧‧Low-speed bus / low-speed expansion port
P16‧‧‧顯示器P16‧‧‧Display
P20‧‧‧標準伺服器P20‧‧‧Standard Server
P22‧‧‧膝上型電腦P22‧‧‧laptop
P24‧‧‧機架伺服器系統P24‧‧‧ Rack Server System
P50‧‧‧處理器平台/一般行動電腦器件/計算器件P50‧‧‧Processor Platform / General Mobile Computer Device / Computing Device
P52‧‧‧處理器P52‧‧‧Processor
P54‧‧‧顯示器P54‧‧‧Display
P56‧‧‧顯示介面P56‧‧‧display interface
P58‧‧‧控制介面P58‧‧‧Control Interface
P60‧‧‧音訊編解碼器P60‧‧‧Audio Codec
P62‧‧‧外部介面P62‧‧‧External interface
P64‧‧‧記憶體P64‧‧‧Memory
P66‧‧‧通信介面P66‧‧‧communication interface
P68‧‧‧收發器P68‧‧‧Transceiver
P70‧‧‧全球定位系統(GPS)接收器模組P70‧‧‧Global Positioning System (GPS) Receiver Module
P72‧‧‧擴充介面P72‧‧‧Expansion interface
P74‧‧‧擴充記憶體P74‧‧‧Expand Memory
P80‧‧‧蜂巢式電話P80‧‧‧Hive Phone
P82‧‧‧智慧型電話P82‧‧‧Smart Phone
圖1A係繪示一VR系統中之一實例性HMD及手持控制器之一圖。 圖1B係繪示包含於一HMD中之實例性LED發射器之一圖。 圖1C係繪示典型LED之實例性亮度輪廓之一圖。 圖1D係繪示LED之另一實例性亮度輪廓之一圖。 圖2係給定圖1B中所展示之亮度輪廓之LED之實例性模擬圖之一圖。 圖3A及圖3B係繪示在帶通濾波之前及帶通濾波之後自圖1中所展示之LED發射之脈衝輻射之實例性時間輪廓之圖。 圖4A至圖4C係位於一手持控制器中之一組實例性光電二極體之圖、手持控制器中之一典型光電二極體之一實例性回應之一圖及提供手持控制器中之典型光電二極體之帶通濾波之一實例性電路之一圖。 圖5A、圖5B、圖5C及圖5D係手持控制器可在空間中占據之一組實例性可能三維座標之圖。 圖6係繪示源自自HMD中之LED接收漫射輻射之一實例性信號之一圖。 圖7係手持控制器之位置及定向可自其導出之一實例性查找表(LUT)之一圖。 圖8係繪示用於回應於自LED接收漫射光而自LUT導出一熱圖及由光電二極體產生之信號之一實例性程序之一流程圖。 圖9A係繪示用於自外源拒斥DC光之實例性電路拓撲之一圖。 圖9B係繪示用於自外源拒斥DC光之一實例性電路之一圖。 圖10繪示可與此處所描述之電路一起使用之一電腦器件及一行動電腦器件之一實例。 圖11係描繪一實例性VR頭戴顯示器(HMD)之一圖。 圖12A、圖12B及圖12C係描繪實例性VR HMD及控制器之圖。FIG. 1A is a diagram illustrating an exemplary HMD and a handheld controller in a VR system. FIG. 1B is a diagram showing an exemplary LED emitter included in an HMD. FIG. 1C is a diagram illustrating an exemplary brightness profile of a typical LED. FIG. 1D is a diagram illustrating another exemplary brightness profile of an LED. FIG. 2 is a diagram of an exemplary simulation of an LED given the luminance profile shown in FIG. 1B. 3A and 3B are diagrams illustrating exemplary time profiles of pulsed radiation emitted from the LED shown in FIG. 1 before and after band-pass filtering. 4A to 4C are diagrams of a group of example photodiodes located in a handheld controller, a diagram of an example response of a typical photodiode in a handheld controller, and providing a A diagram of an example circuit of a typical photodiode's bandpass filtering. 5A, 5B, 5C, and 5D are diagrams of an exemplary set of possible three-dimensional coordinates that a handheld controller can occupy in space. FIG. 6 is a diagram showing an exemplary signal derived from receiving diffused radiation from an LED in an HMD. FIG. 7 is a diagram of an exemplary lookup table (LUT) from which the position and orientation of the handheld controller can be derived. 8 is a flowchart illustrating an exemplary procedure for deriving a heat map from a LUT and a signal generated by a photodiode in response to receiving diffused light from an LED. FIG. 9A is a diagram illustrating an exemplary circuit topology for rejecting DC light from an external source. FIG. 9B is a diagram illustrating an exemplary circuit for rejecting DC light from an external source. FIG. 10 illustrates an example of a computer device and a mobile computer device that can be used with the circuits described herein. 11 is a diagram depicting an exemplary VR head-mounted display (HMD). 12A, 12B, and 12C are diagrams depicting exemplary VR HMDs and controllers.
Claims (15)
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201762492801P | 2017-05-01 | 2017-05-01 | |
US62/492,801 | 2017-05-01 |
Publications (2)
Publication Number | Publication Date |
---|---|
TW201842431A true TW201842431A (en) | 2018-12-01 |
TWI706291B TWI706291B (en) | 2020-10-01 |
Family
ID=63916572
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
TW107114622A TWI706291B (en) | 2017-05-01 | 2018-04-30 | Method and computer program product for tracking of position and orientation of objects in virtual reality systems |
Country Status (7)
Country | Link |
---|---|
US (1) | US10444865B2 (en) |
EP (1) | EP3619596B1 (en) |
JP (1) | JP7049364B2 (en) |
KR (1) | KR102335908B1 (en) |
CN (1) | CN110494827B (en) |
TW (1) | TWI706291B (en) |
WO (1) | WO2018204219A1 (en) |
Cited By (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11392218B2 (en) | 2020-08-26 | 2022-07-19 | Institute For Information Industry | Data filtering device and data filtering method |
US11506901B2 (en) | 2020-07-08 | 2022-11-22 | Industrial Technology Research Institute | Method and system for simultaneously tracking 6 DoF poses of movable object and movable camera |
US11836302B2 (en) | 2022-03-03 | 2023-12-05 | Htc Corporation | Motion computing system and method for virtual reality |
Families Citing this family (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10908680B1 (en) | 2017-07-12 | 2021-02-02 | Magic Leap, Inc. | Pose estimation using electromagnetic tracking |
US10386938B2 (en) * | 2017-09-18 | 2019-08-20 | Google Llc | Tracking of location and orientation of a virtual controller in a virtual reality system |
US20190385372A1 (en) * | 2018-06-15 | 2019-12-19 | Microsoft Technology Licensing, Llc | Positioning a virtual reality passthrough region at a known distance |
KR102433082B1 (en) * | 2020-06-25 | 2022-08-17 | 주식회사 리얼리티매직 | In-game event-based lighting production method for virtual reality game and virtual reality system for performing the same |
US20230398433A1 (en) * | 2022-06-10 | 2023-12-14 | Sony Interactive Entertainment Inc. | Hybrid pixel dynamic vision sensor tracking using ir and ambient light (or depth sensor) |
US20230398432A1 (en) * | 2022-06-10 | 2023-12-14 | Sony Interactive Entertainment Inc. | Asynchronous dynamic vision sensor led ai tracking system and method |
CN115694670B (en) * | 2022-09-28 | 2023-11-28 | 中国电子科技集团公司第十四研究所 | Radio frequency domain virtual reality method and device based on microwave photon technology |
Family Cites Families (28)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
EP0852732A1 (en) * | 1995-09-21 | 1998-07-15 | Omniplanar, Inc. | Method and apparatus for determining position and orientation |
AU2001233019A1 (en) * | 2000-01-28 | 2001-08-07 | Intersense, Inc. | Self-referenced tracking |
US20070159455A1 (en) * | 2006-01-06 | 2007-07-12 | Ronmee Industrial Corporation | Image-sensing game-controlling device |
US7368999B2 (en) | 2006-07-10 | 2008-05-06 | Jds Uniphase Corporation | DC offset cancellation for a trans-impedance amplifier |
WO2008010024A1 (en) * | 2006-07-16 | 2008-01-24 | Cherradi I | Free fingers typing technology |
WO2009147904A1 (en) * | 2008-06-04 | 2009-12-10 | 国立大学法人筑波大学 | Finger shape estimating device, and finger shape estimating method and program |
SE533704C2 (en) * | 2008-12-05 | 2010-12-07 | Flatfrog Lab Ab | Touch sensitive apparatus and method for operating the same |
US8179604B1 (en) * | 2011-07-13 | 2012-05-15 | Google Inc. | Wearable marker for passive interaction |
JP2015519687A (en) * | 2012-04-20 | 2015-07-09 | レンセレイアー ポリテクニック インスティテュート | Sensing lighting system and method for characterizing an illumination space |
US9329678B2 (en) * | 2012-08-14 | 2016-05-03 | Microsoft Technology Licensing, Llc | Augmented reality overlay for control devices |
JP6155448B2 (en) * | 2012-11-01 | 2017-07-05 | アイカム エルエルシー | Wireless wrist computing and controlling device and method for 3D imaging, mapping, networking and interfacing |
US20140362110A1 (en) | 2013-06-08 | 2014-12-11 | Sony Computer Entertainment Inc. | Systems and methods for customizing optical representation of views provided by a head mounted display based on optical prescription of a user |
US20150062086A1 (en) * | 2013-08-29 | 2015-03-05 | Rohildev Nattukallingal | Method and system of a wearable ring device for management of another computing device |
CN110308561A (en) * | 2014-03-14 | 2019-10-08 | 索尼互动娱乐股份有限公司 | Method and system for head-mounted display (HMD) |
US9649558B2 (en) * | 2014-03-14 | 2017-05-16 | Sony Interactive Entertainment Inc. | Gaming device with rotatably placed cameras |
US9551873B2 (en) * | 2014-05-30 | 2017-01-24 | Sony Interactive Entertainment America Llc | Head mounted device (HMD) system having interface with mobile computing device for rendering virtual reality content |
US20160117081A1 (en) * | 2014-10-27 | 2016-04-28 | Thales Avionics, Inc. | Controlling entertainment system using combination of inputs from proximity sensor and touch sensor of remote controller |
US10338186B2 (en) * | 2014-11-10 | 2019-07-02 | Valve Corporation | Positional tracking systems and methods |
US10043282B2 (en) * | 2015-04-13 | 2018-08-07 | Gerard Dirk Smits | Machine vision for ego-motion, segmenting, and classifying objects |
US10532277B2 (en) * | 2015-06-11 | 2020-01-14 | Facebook Technologies, Llc | Hand-held controllers with light-emitting diodes synchronized to an external camera |
US10007116B2 (en) | 2015-06-15 | 2018-06-26 | Oculus Vr, Llc | Recessed light-emitting diodes in virtual-reality systems |
US10083544B2 (en) | 2015-07-07 | 2018-09-25 | Google Llc | System for tracking a handheld device in virtual reality |
US10095024B2 (en) | 2015-08-07 | 2018-10-09 | Sony Interactive Entertainment Inc. | Systems and methods for using a MEMS projector to determine an orientation of a photosensor of an HMD or another controller |
US10146334B2 (en) * | 2016-06-09 | 2018-12-04 | Microsoft Technology Licensing, Llc | Passive optical and inertial tracking in slim form-factor |
US10146335B2 (en) * | 2016-06-09 | 2018-12-04 | Microsoft Technology Licensing, Llc | Modular extension of inertial controller for six DOF mixed reality input |
US9961236B2 (en) * | 2016-06-13 | 2018-05-01 | Gopro, Inc. | 3D color mapping and tuning in an image processing pipeline |
US10440240B2 (en) * | 2016-09-30 | 2019-10-08 | Sony Interactive Entertainment Inc. | Systems and methods for reducing an effect of occlusion of a tracker by people |
US9983665B2 (en) * | 2016-10-25 | 2018-05-29 | Oculus Vr, Llc | Position tracking system that exploits arbitrary configurations to determine loop closure |
-
2018
- 2018-04-27 US US15/964,499 patent/US10444865B2/en active Active
- 2018-04-30 TW TW107114622A patent/TWI706291B/en active
- 2018-04-30 CN CN201880024528.9A patent/CN110494827B/en active Active
- 2018-04-30 KR KR1020197032510A patent/KR102335908B1/en active IP Right Grant
- 2018-04-30 WO PCT/US2018/030095 patent/WO2018204219A1/en unknown
- 2018-04-30 JP JP2019559776A patent/JP7049364B2/en active Active
- 2018-04-30 EP EP18725090.7A patent/EP3619596B1/en active Active
Cited By (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11506901B2 (en) | 2020-07-08 | 2022-11-22 | Industrial Technology Research Institute | Method and system for simultaneously tracking 6 DoF poses of movable object and movable camera |
US11392218B2 (en) | 2020-08-26 | 2022-07-19 | Institute For Information Industry | Data filtering device and data filtering method |
TWI784305B (en) * | 2020-08-26 | 2022-11-21 | 財團法人資訊工業策進會 | Device and method for filtering data through analyzing tracks in a six-degrees-of-freedom virtual space |
US11836302B2 (en) | 2022-03-03 | 2023-12-05 | Htc Corporation | Motion computing system and method for virtual reality |
Also Published As
Publication number | Publication date |
---|---|
EP3619596A1 (en) | 2020-03-11 |
TWI706291B (en) | 2020-10-01 |
CN110494827A (en) | 2019-11-22 |
WO2018204219A1 (en) | 2018-11-08 |
KR20190136057A (en) | 2019-12-09 |
EP3619596B1 (en) | 2021-09-01 |
JP7049364B2 (en) | 2022-04-06 |
US20180314346A1 (en) | 2018-11-01 |
JP2020518808A (en) | 2020-06-25 |
CN110494827B (en) | 2023-09-22 |
US10444865B2 (en) | 2019-10-15 |
KR102335908B1 (en) | 2021-12-06 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
TWI706291B (en) | Method and computer program product for tracking of position and orientation of objects in virtual reality systems | |
US20220375174A1 (en) | Beacons for localization and content delivery to wearable devices | |
US11277597B1 (en) | Marker-based guided AR experience | |
US11520399B2 (en) | Interactive augmented reality experiences using positional tracking | |
US20170277259A1 (en) | Eye tracking via transparent near eye lens | |
KR20160024986A (en) | Eye tracking via depth camera | |
US20210306791A1 (en) | Immersive augmented reality experiences using spatial audio | |
US11582409B2 (en) | Visual-inertial tracking using rolling shutter cameras | |
US11740313B2 (en) | Augmented reality precision tracking and display | |
US20230359037A1 (en) | Head-Mounted Display With Low Light Operation | |
US10679376B2 (en) | Determining a pose of a handheld object | |
KR20240008359A (en) | Audio Enhanced Augmented Reality | |
US20240004197A1 (en) | Dynamic sensor selection for visual inertial odometry systems | |
US20230258756A1 (en) | Augmented reality precision tracking and display | |
US11803234B2 (en) | Augmented reality with eyewear triggered IoT | |
US11863963B2 (en) | Augmented reality spatial audio experience | |
US20240077934A1 (en) | Virtual ar interfaces for controlling iot devices using mobile device orientation sensors | |
US20240077935A1 (en) | Virtual interfaces for controlling iot devices |