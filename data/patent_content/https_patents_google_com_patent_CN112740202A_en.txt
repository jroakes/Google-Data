CN112740202A - Performing image search using content tags - Google Patents
Performing image search using content tags Download PDFInfo
- Publication number
- CN112740202A CN112740202A CN201980062450.4A CN201980062450A CN112740202A CN 112740202 A CN112740202 A CN 112740202A CN 201980062450 A CN201980062450 A CN 201980062450A CN 112740202 A CN112740202 A CN 112740202A
- Authority
- CN
- China
- Prior art keywords
- search
- search query
- image
- content
- candidate
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/58—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
- G06F16/583—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using metadata automatically derived from the content
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/24—Querying
- G06F16/245—Query processing
- G06F16/2457—Query processing with adaptation to user needs
- G06F16/24578—Query processing with adaptation to user needs using ranking
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/53—Querying
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/58—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
- G06F16/5866—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using information manually generated, e.g. tags, keywords, comments, manually generated location and time information
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V20/00—Scenes; Scene-specific elements
- G06V20/30—Scenes; Scene-specific elements in albums, collections or shared content, e.g. social network photos or video
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V2201/00—Indexing scheme relating to image or video recognition or understanding
- G06V2201/10—Recognition assisted with metadata
Abstract
Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for performing image searches. In one aspect, the system receives a request for an image responsive to a provided search query including one or more search terms. The system obtains a content tag for the provided search query, the content tag representing an entity depicted in an image identified by search results that were previously generated by the search system by processing a search query that includes search terms included in the provided search query. The system determines a relevance score for each of the plurality of candidate images using the content tags of the provided search query. The system determines a ranking of the candidate images based in part on the relevance scores of the candidate images.
Description
Cross Reference to Related Applications
This application claims the benefit of U.S. application No. 16/264,218 filed on 31.1.2019 and U.S. patent application No. 62/770,478 entitled "PERFORMING IMAGE SEARCH USE CONTENT LABELS" filed on 21.11.2018. The disclosure of the aforementioned application is hereby incorporated by reference in its entirety for all purposes.
Background
This specification relates to information retrieval.
The internet provides access to a wide variety of electronic documents, such as image files, audio files, video files, and web pages. The search system may identify (identity) electronic documents that are responsive to the search query. The search query may include one or more search terms (search term), images, audio data, or a combination thereof. Searching for images presents particular challenges.
Disclosure of Invention
This specification describes a search system implemented as a computer program on one or more computers at one or more locations. The search system may perform an image search by processing a search query that includes one or more search terms to generate search results that identify images responsive to the search query.
According to a first aspect, there is provided a method performed by one or more data processing apparatus, the method comprising: a request is received for an image responsive to a provided search query, the provided search query including one or more search terms. Obtaining a content tag of a provided search query, wherein the content tag of the provided search query represents an entity depicted in an image identified by search results that were previously generated by a search system by processing a search query that includes search terms included in the provided search query. For each of a plurality of candidate images, a content tag of the candidate image is obtained, wherein each content tag of the candidate image represents an entity depicted by the candidate image. Determining a relevance score for a candidate image based on a similarity measure (similarity measure) that measures similarity of: (i) a content tag of the provided search query, and (ii) a content tag of the candidate image. A ranking of the candidate images is determined based in part on the relevance scores of the candidate images. In response to the request, search results are provided that identify one or more candidate images based on the ranking of the candidate images.
In some implementations, the content tags of the provided search query include terms that represent entities depicted in the image identified by search results that were previously generated by the search system by processing the provided search query.
In some implementations, the content tags of the provided search query include terms that represent entities depicted in an image identified by search results that were previously generated by a search system by processing a search query defined by a sequence of one or more search terms included in the provided search query.
In some implementations, the content tags of the provided search query include terms that represent entities depicted in an image identified by search results that were previously generated by a search system by processing the search query, the search query including a sequence of one or more search terms that are also included in the provided search query.
In some implementations, the content tags of the provided search query are determined based on respective user selection rates (selection rates) of search results generated by the search system by processing the search query that include search terms included in the provided search query.
In some embodiments, the content tag of the candidate image is generated by processing the candidate image using an entity detection model to generate data defining an entity depicted by the candidate image; and the content tags of the provided search query are generated by processing images identified by search results that were previously generated by the search system by processing a search query that includes search terms included in the provided search query using the entity detection model.
In some embodiments, the entity detection model includes an object detection neural network.
In some implementations, obtaining the content tag of the candidate image includes: one or more content tags are obtained, each content tag representing a respective object depicted by a candidate image.
In some implementations, obtaining the content tags for the provided search query includes: one or more content tags are obtained, each content tag representing a respective object depicted in an image identified by a search result that was previously generated by a search system by processing a search query that includes search terms included in the provided search query.
In some implementations, the relevance score of the candidate image is determined based on a similarity metric that measures similarity of: (i) a content tag of the provided search query, and (ii) a content tag of the candidate image, including determining a cosine similarity measure between: (i) a digital representation of the content tag of the provided search query, and (ii) a digital representation of the content tag of the candidate image.
In some embodiments, the similarity measure is based on a respective likelihood (likelihood) of each of: (i) a content tag of the provided search query, and (ii) a content tag of the candidate image.
In some implementations, providing, in response to the request, data identifying one or more candidate images based on a ranking of the plurality of candidate images includes: in response to the request, data is provided that identifies one or more highest ranked candidate images.
According to a second aspect, there is provided a system comprising one or more computers and one or more storage devices storing instructions that, when executed by the one or more computers, cause the one or more computers to perform operations comprising the operations of the foregoing method.
According to a third aspect, one or more non-transitory computer storage media storing instructions that, when executed by one or more computers, cause the one or more computers to perform operations comprising the operations of the foregoing methods are provided.
Particular embodiments of the subject matter described in this specification can be implemented to realize one or more of the following advantages.
The search system described in this specification can identify images that are responsive to a search query. The search system identifies images using sets of content tags (a sets of content labels) obtained for search queries, and can efficiently determine sets of content tags for any search query using pre-computed data, thereby reducing any latency in providing images responsive to the search query. More specifically, for each of a large number (e.g., millions) of search queries, the search system may pre-compute (i.e., by identifying and storing) content tags representing entities depicted in images identified by search results that were pre-generated by the search system through processing of the search queries.
The search system may obtain a set of content tags for a given search query by aggregating (aggregate) pre-computed content tags from images corresponding to one or more of: (i) a given search query, (ii) a "sub-query" of the search query, and (iii) a search query that is "relevant" to the given search query. The sub-queries of a given search query are defined by a sequence of one or more search terms included in the given search query. Two search queries are said to be "related" if they both contain the same sub-queries. In this manner, the search system may use the pre-computed data to determine the content tags for a given search query even if the content tags from the images corresponding to the given search query are not pre-computed. More specifically, the system may determine the content tags for a given search query by aggregating pre-computed content tags from images corresponding to sub-queries and related search queries for the given search query, even if the content tags from the images corresponding to the given search query are not pre-computed. This is a technological advance in the field of information retrieval and image search.
The search system described in this specification can use criteria that are well understood and interpreted to determine a relevance score that characterizes the relevance of (charcterize) images to a search query. In particular, the search system determines a relevance score based on: (i) a content tag set of the search query, and (ii) a content tag set of the image. The search query and the corresponding content tag set of the image can be easily understood and interpreted by a person, which may facilitate efficient calibration and commissioning (debug) of the (factitioate) search system. In contrast, other scores that characterize the relevance of an image to a search query may be based on complex and unexplained criteria (e.g., the output of a neural network), which may significantly increase the difficulty of calibrating and debugging the search system. This is yet another technical improvement in the fields of information retrieval and image search.
By determining search results for a search query based on relevance scores computed using content tags, the search system described in this specification can generate improved image search results in response to the search query. In this manner, the search system may reduce computational resource consumption (e.g., memory, computing power, or both) by reducing the number of search queries sent by the user to retrieve relevant data. For example, experiments have shown that manual search query refinement when a search system determines search results based on relevance scores computed using content tags
The details of one or more embodiments of the subject matter of this specification are set forth in the accompanying drawings and the description below. Other features, aspects, and advantages of the subject matter will become apparent from the description, the drawings, and the claims.
Drawings
FIG. 1 illustrates an example search system.
FIG. 2 illustrates an example ranking engine.
FIG. 3 is a flow diagram of an example process for providing image search results in response to a search query that includes one or more search terms.
FIG. 4 is a flow diagram of an example process for obtaining content tags for a given search query that includes one or more search terms.
Like reference numbers and designations in the various drawings indicate like elements.
Detailed Description
This specification describes search systems that may perform image searches by processing search queries that include one or more search terms to generate search results that identify images that are responsive to the search queries. The search system is configured to process the search query to determine a respective relevance score for each of the one or more candidate images, wherein the relevance score for a candidate image characterizes the relevance of the candidate image to the search query. The search system determines a ranking of the candidate images based (at least in part) on the relevance scores of the candidate images, and may generate search results that identify one or more highest ranked candidate images.
To generate a relevance score for a candidate image, the search system determines: (i) the content tag sets of the search query, and (ii) the content tag sets of the candidate images, and a similarity measure between the respective content tag sets is calculated. The content tags of a search query are terms that represent entities (e.g., objects) depicted in an image identified by search results that were previously generated by a search system for one or more of: (i) a search query, (ii) a "sub-query" of the search query, and (iii) a "related" search query. The content tag of the candidate image represents an entity (e.g., an object) depicted by the candidate image. The search system may determine the entities depicted in the image by processing the image using an entity detection model (e.g., which may include an object detection neural network).
These and other features will be described in more detail below.
FIG. 1 illustrates an example search system 100. The search system 100 is an example of a system implemented as a computer program on one or more computers at one or more locations in which the systems, components, and techniques described below are implemented.
The search system 100 is configured to receive a search query 102 from a user device 104, process the search query 102 to determine one or more search results 106 responsive to the search query 102, and provide the search results 106 to the user device 104. The search query 102 may include search terms expressed in natural language (e.g., english), images, audio data, or any other suitable form of data. The search results 106 identify electronic documents 108 from the website 110 that are responsive to the search query 102 and include links to the electronic documents 108. The electronic document 108 may include, for example, images, HTML web pages, word processing documents, Portable Document Format (PDF) documents, and videos. The electronic document 108 may include content, such as words, phrases, images, and audio data, and may include embedded information (e.g., meta information and hyperlinks) and embedded instructions (e.g., scripts). The website 110 is a collection (collection) of one or more electronic documents 108 associated with a domain name and hosted (host) by one or more servers. For example, the website 110 may be a collection of web pages formatted in hypertext markup language (HTML) that may contain text, images, multimedia content, and programming elements (e.g., scripts).
In a particular example, the search query 102 can include the search term "Apollodeny", and the search system 100 can be configured to perform an image search, i.e., provide search results 106 that identify respective images that are responsive to the search query 102. In particular, the search system 100 may provide search results 106, each search result 106 including: (i) a title of the web page, (ii) a representation of the image extracted from the web page, and (iii) a hypertext link (e.g., specifying a Uniform Resource Locator (URL)) to the web page or to the image itself. In this example, the search system 100 may provide search results 106, the search results 106 including: (i) the title "apolegaentry month" of the web page, (ii) a reduced representation (i.e., thumbnail) of the image of the apolegamic spacecraft included in the web page, and (iii) a hypertext link to the image.
A computer network 112, such as a Local Area Network (LAN), Wide Area Network (WAN), the internet, a mobile telephone network, or a combination thereof, connects the website 110, the user device 104, and the search system 100 (i.e., enables them to send and receive data over the network 112). In general, the network 112 may connect the search system 100 to thousands of websites 110 and user devices 104.
The user device 104 is an electronic device that is controlled by a user and is capable of sending and receiving data (including electronic documents 108) over the network 112. Example user devices 104 include personal computers, mobile communication devices, and other devices capable of sending and receiving data over the network 112. The user device 104 typically includes a user application (e.g., a web browser) that facilitates the sending and receiving of data over the network 112. In particular, a user application included in the user device 104 enables the user device 104 to send search queries 102 to the search system 100 over the network 112 and receive search results 106 provided by the search system 100 in response to the search queries 102.
A user application included in the user device 104 may present the search results 106 received from the search system 100 to a user of the user device (e.g., by rendering a search results page that displays an ordered list of the search results 106). The user may select one of the search results 106 presented by the user device 104 (e.g., by clicking on a hypertext link included in the search results 106), which may cause the user device 104 to generate a request for the electronic document 108 identified by the search results 106. A request for an electronic document 108 identified by the search results 106 is sent over a network 112 to a website 110 hosting the electronic document 108. In response to receiving a request for the electronic document 108, the website 110 hosting the electronic document 108 may send the electronic document 108 to the user device 104.
The search system 100 processes the search query 102 using the ranking engine 114 to determine search results 106 responsive to the search query 102. As will be described in greater detail below, the ranking engine 114 uses the search index 116 and the historical query log 118 to determine the search results 106 that are responsive to the search query 102.
The search system 100 uses the index engine 120 to generate and maintain a search index 116 by "crawling" (i.e., systematically browsing) electronic documents 108 of the web site 110. For each of a large number (e.g., millions) of electronic documents 108, the search index 116 indexes the electronic documents by maintaining the following data: (i) data that identifies the electronic document 108 (e.g., via a link to the electronic document 108), and (ii) data that characterizes the electronic document 108. The data characterizing the electronic documents maintained by the search index 116 may include, for example, data specifying the type of electronic document (e.g., image, video, PDF document, etc.), the quality of the electronic document (e.g., the resolution of the electronic document when it is an image or video), keywords associated with the electronic document, cached copies of the electronic document, or combinations thereof.
The search system 100 may store the search index 116 in a data store (data store), which may include thousands of data storage devices. The index engine 120 may maintain the search index 116 by continually updating the search index 116, for example, by indexing new electronic documents 108 and removing electronic documents 108 that are no longer available from the search index 116.
The search system 100 uses a query log engine 122 to generate and maintain historical query logs 118. For each of a large number (e.g., millions) of search queries previously processed by the search system 100, the historical query log 118 indexes previous search queries by maintaining data specifying: (i) a previous search query, (ii) search results provided by the search system 100 in response to the previous search query, and (iii) user selection data specifying one or more search results selected by a user of the user device that sent the previous search query. As previously described, a user may select a search result by, for example, clicking on a hypertext link included in the search result to generate a request for an electronic document identified by the search result. More generally, user-selected data may be understood as any data characterizing a degree of "interest" (level) of a user in search results sent in response to a search query. For example, the user selection data may be based on "hover data" (hover data) that characterizes how long the user hovers their cursor over the search results. Hovering the cursor over the search results may cause more information related to the search results to be displayed. For example, if the search result is an image, hovering the cursor over the search result may cause an enlarged version of the image to be displayed.
The search system 100 may store the historical query log 118 in a data store, which may include thousands of data storage devices. The query log engine 122 may maintain the historical query logs 118 by continuously updating the historical query logs 118 (e.g., by indexing new search queries as they are processed by the search system 100).
The ranking engine 114 determines the search results 106 responsive to the search query 102 by scoring (scoping) the electronic documents 108 indexed by the search index 116. Ranking engine 114 may score electronic documents 108 based in part on data accessed from historical query logs 118. The score determined by the ranking engine 114 for the electronic document 108 characterizes the degree to which the electronic document is responsive (e.g., relevant) to the search query 102. Ranking engine 114 determines a ranking of electronic documents 108 indexed by search index 116 based on their respective scores and determines search results based on the ranking. For example, the ranking engine 114 may generate the search results 106, the search results 106 identifying the highest ranked electronic documents 108 indexed by the search index 116.
Fig. 2 illustrates an example ranking engine 114. Ranking engine 114 is an example of an engine implemented as a computer program on one or more computers at one or more locations in which the systems, components, and techniques described below are implemented. As described with reference to FIG. 1, the ranking engine 114 of the search system 100 may process search queries in any suitable format to generate search results that identify electronic documents in any suitable format. For example, the search query processed by the ranking engine may include, for example, search terms, images, audio data, or a combination thereof, and the electronic documents identified by the search results may include, for example, images, HTML web pages, word processing documents, Portable Document Format (PDF) documents, and videos. FIG. 2 depicts certain components of a ranking engine 114 that may be used to perform an image search by processing a search query 102 that includes one or more search terms to generate search results 106 that identify images that are responsive to the search query 102.
The ranking engine 114 generates the search results 106 by determining a respective relevance score 202 for each of a plurality of images indexed by the search index 116, and determining a ranking 204 of the images based at least in part on the relevance scores 202. The ranking engine 114 determines a relevance score 202 for an image based on a similarity measure between: (i) a content tag set 206 of images, and (ii) a content tag set 208 of the search query 102, which will be described in more detail below.
The ranking engine 114 processes each of a plurality of "candidate" images 218 indexed by the search index 116 using an image content annotation (annotation) engine 212 to generate a respective set of content tags 206 for each of the candidate images 218. In some cases, the candidate images 218 may include each image indexed by the search index 116, while in other cases, the candidate images 218 may include only a proper subset of the images indexed by the search index 116. In a particular example, the ranking engine 114 can determine an initial ranking of images indexed by the search index 116 using a "fast" ranking method that can be performed quickly and consumes less computing resources. The initial ranking of images indexed by the search index 116 may rank the images approximately (i.e., coarsely) based on the degree to which the images respond to the search query 102 (how responsive). After determining the initial ranking of the images indexed by the search index 116, the ranking engine 114 may determine a set of highest ranked images as candidate images 218 according to an initial ranking method
The image content annotation engine 212 is configured to generate a content tag 206 for an image, the content tag 206 for the image representing an "entity" depicted by the image. The entity depicted by the image may be, for example: (i) an object depicted by the image, (ii) a feature of the object depicted by the image, or (iii) a global feature of the image. The object depicted by the image may be a high-level object (e.g., a vehicle), or a specific object (e.g., a Ford horse). The characteristic of the object depicted by the image may be, for example, the color of the object depicted in the image (e.g., green), the emotion expressed by the person depicted in the image (e.g., happy), or the action performed by the person depicted in the image (e.g., running). Global features of an image refer to data characterizing the image as a whole rather than a particular object in the image, such as weather conditions depicted in the image (e.g., sunny, cloudy, or rainy days), or a location where the image is captured (e.g., paris). The image content annotation engine 212 may pre-compute the content tags 206 for each image indexed by the search index 116 to reduce any latency in generating the search results 106.
The ranking engine 114 processes the search query 102 using an image mapping engine 210, the image mapping engine 210 mapping the search query 102 to a set of historical images 220. The historical images 220 are images identified by search results that were previously generated by the search system 100 for one or more of: (i) search query 102, (ii) a "sub-query" of search query 102, and (iii) a search query "related" to search query 102. The sub-queries of the search query 102 are defined by a sequence of one or more search terms included in the search query 102. For example, "deny moon" is a sub-query of the search query "Apollodeny moon". Two search queries are said to be "related" if they both contain the same sub-queries. For example, the search query "Apollodenyum" is related to the search query "American Denyum" (i.e., because they both include the sub-query "Denyum"). The image mapping engine 210 uses the historical query log 118 to determine search results that the search system 100 previously generated for the search query. The image mapping engine 210 may map the search query 102 to the historical images 220 based on a user selection rate of previous search queries. For example, the image mapping engine 210 may be more likely to map the search query 102 to historical images 220 identified by search results that are more frequently selected by the user when provided in response to the search query 102. In general, the historical images 220 may be images included in the search index 116.
The ranking engine 114 generates the content tags 208 for the search query 102 by processing the historical images 220 using the image content annotation engine 212. In a particular example, for the search query "Apollodenyule," the ranking engine 114 may determine the content tags 208 for the search query, including: "space", "astronaut", "emblem", "vehicle", "symbol", "spacecraft", "badge", "circle", "logo", "rocket" and "aerospace engineering". An example process for generating content tags for a search query is described in more detail with reference to FIG. 4.
The ranking engine 114 uses the similarity metric engine 214 to process: (i) a content tag 208 of the search query 102, and (ii) a respective content tag 206 of each candidate image to generate a respective relevance score 202 for each candidate image. The relevance score 202 for a candidate image is a numerical value that characterizes the relevance of the candidate image to the search query 102. Alternatively, the ranking engine 114 may calculate one or more additional scores for each candidate image and determine a respective overall score 214 for each candidate image based on: (i) a relevance score 202 for the candidate image, and (ii) an additional score 216 for the candidate image. For example, the ranking engine 114 may determine the overall score 214 of the candidate image as a weighted sum of the relevance score 202 of the candidate image and the additional score 216 of the candidate image. An example of the additional score 216 is further described with reference to fig. 3.
The ranking engine 114 determines a ranking 204 of the candidate images 218 based on the overall score 214 (or, if there are no additional scores 216, the relevance scores 202), and generates the search results 106 based on the ranking 204. For example, the ranking engine 114 may generate the search results 106 identifying the highest ranked candidate image 218.
FIG. 3 is a flow diagram of an example process 300 for providing image search results in response to a search query that includes one or more search terms. For convenience, process 300 will be described as being performed by a system of one or more computers located at one or more locations. For example, a search system suitably programmed in accordance with the subject specification, such as search system 100 of FIG. 1, may perform process 300.
A search system receives a search query that includes one or more search terms (302). As described with reference to FIG. 1, a search query may be sent by a user device of a user to a search system over a computer network. Examples of search queries that include one or more search terms are: "Apollodenyule".
The search system obtains a content tag for the search query (304). The content tags of a search query are terms that represent entities depicted by an image that is identified by a search system for pre-generated search results for one or more of: (i) a search query, (ii) a "sub-query" of the search query, and (iii) a "related" search query. An example process for obtaining content tags for a search query is described with reference to FIG. 4.
For each of a plurality of candidate images indexed by the search index, the search system obtains a respective content tag (306) of the candidate image representing the entity depicted by the candidate image. As described with reference to fig. 2, the entities depicted by the images may be, for example: (i) an object depicted by the image, (ii) a feature of the object depicted by the image, or (iii) a global feature of the image. The search system may generate a content tag for the image by processing the image using the entity detection model. For example, the entity detection model may be an entity detection neural network system that includes an object detection neural network. In this example, the object detection neural network may be configured to process the image to generate object detection data comprising data defining object classes of objects depicted in the image. The system may determine an object class of an object depicted in the image as a content tag of the image. In some cases, the system determines a predetermined number of content tags for each candidate image, while in other cases, the system determines a variable number of content tags for each candidate image. For example, the system may determine a variable number of content tags per candidate image by determining that the content tags of the candidate image include an object class of objects detected in the candidate image by an object detection network having at least a threshold "confidence" (e.g., 90%). The system may pre-compute the content tags for each image indexed by the search index to reduce any latency in generating search results in response to the search query. Other suitable processes and systems for generating content tags may also be used.
In some cases, the candidate images include each image indexed by the search index, while in other cases, the candidate images include an appropriate subset of the images indexed by the search index. For example, the candidate image may be a set of highest ranked images according to an initial ranking of images indexed by the search index by a fast ranking method (as described with reference to FIG. 2).
The system determines a respective relevance score for each of the candidate images (308). The relevance score for a candidate image is a numerical value that characterizes the relevance of the candidate image to the search query. The system determines a relevance score for the candidate image based on a similarity metric that measures similarity of: (i) a content tag of the candidate image, and (ii) a content tag of the search query. For example, the system may determine vector representations of content tags of the candidate images and vector representations of content tags of the search query, and thereafter determine a similarity metric based on a cosine similarity metric or a Euclidean (Euclidean) distance between the respective vector representations. The system may determine the vector representation of the content tag set in any of a variety of ways. For example, a vector representation of a given content tag set may have respective components of each "possible" content tag, where those components of the vector corresponding to the content tags in the given content tag set have a value of 1 and all other components have a value of 0. The possible content tags refer to content tags included in a predetermined set of possible content tags.
In some cases, the system determines a similarity metric based on the respective "likelihood" of different content tags. Likelihood of content tags characterizes the frequency (how often) the system associates content tags with search queries and images. For example, a content tag such as "vehicle" may have a higher likelihood than a more specific content tag such as "ford wildhorse". In particular, content tags having a low likelihood of being common to both the search query and the candidate image may affect the similarity metric more than content tags having a high likelihood of being common to both the search query and the candidate image. In one example, the system may determine the similarity metric based on respective likelihoods of different content tags by using a weighted cosine similarity metric, where a function of the likelihoods of each content tag is used as a weight in the cosine similarity metric.
Optionally, the system determines one or more additional scores for each candidate image (310). In some cases, the system may have determined some or all of the additional scores for the candidate images while generating an initial ranking for the images indexed by the search index using a fast ranking method (as described previously). In one example, the system may determine an additional score for the candidate image based on the visual quality of the candidate image (e.g., the image resolution of the candidate image). As another example, the system may determine an additional score for a candidate image based on how many search terms of the search query are included in the metadata tags associated with the candidate image. As another example, the system may determine additional scores for candidate images based on the frequency with which a user has selected candidate images when the system has provided search results identifying candidate images in response to a search query (e.g., based on a historical data log).
The system determines a ranking of the candidate images based on the relevance score of each candidate image (312). For example, the system may determine a total score for each candidate image that characterizes the extent to which the candidate image is responsive to the search query based on: (i) a relevance score for the candidate image, and (ii) any additional scores for the candidate image. In a particular example, the system may determine the overall score of the candidate image as a weighted sum of the relevance score of the candidate image and any additional scores of the candidate image. The ranking of the candidate images may define an ordering of the candidate images from the candidate image with the highest overall score to the candidate image with the lowest overall score.
The system generates search results responsive to the search query based on the ranking of the candidate images (314). For example, the system may generate search results that identify a predetermined number of the highest ranked candidate images according to the rank of the candidate images determined based on the relevance scores. After generating the search results, the system may provide the search results for presentation on the user device that generated the search query.
FIG. 4 is a flow diagram of an example process 400 for obtaining content tags for a given search query that includes one or more search terms. For convenience, process 400 will be described as being performed by a system of one or more computers located at one or more locations. For example, a search system suitably programmed in accordance with the subject specification, such as search system 100 of FIG. 1, may perform process 400.
The system identifies content tags representing entities depicted in images identified by search results generated by the search system by processing a given search query (402). More specifically, the system may use the historical data log to obtain data specifying: (i) images identified by search results previously generated by the search system by processing the given search query, and (ii) a user-selection rate of search results generated by processing the given search query. The user selection rate for a given search result may specify the frequency (i.e., relative to other search results) that the user selects the given search result when the search system provides the given search result in response to a given search query. For example, the user selection rate may specify that a given search result is selected by the user 22% of the time provided by the search system in response to a given search query. More generally, the user selection data for a given search result may describe a level of interest (a level of interest) of the user in the given search result when the search system provides the given search result in response to a given search query. For example, user selection data for a given search result may be based in part on "hover data" that characterizes how long the user hovers a cursor over the given search result when the given search result is provided in response to a given search query. The system may be more likely to identify content tags from images identified by search results having a higher user selection rate (e.g., indicating a higher degree of user interest). As previously described, the system may identify content tags representing entities depicted in an image by processing the image using an entity detection model.
In some implementations, the system may have previously identified (i.e., "pre-computed") content tags for images corresponding to a given search query and stored the content tags in a data store. The system may access pre-computed content tags for images corresponding to a given search query from a data store to reduce any latency in determining the content tags for the search query. If the system does not pre-calculate the content tags for the images corresponding to the given search query, the system may refrain (refain) from obtaining the content tags for the images corresponding to the given search query and proceed to step 404.
The system identifies content tags representing entities depicted in images identified by search results generated by the search system by processing sub-queries of a given search query (404). In some cases, a sub-query may include every possible sub-query of a given search query, while in other cases, a sub-query may include a predetermined number of sub-queries of a given search query. For example, the sub-queries may include a predetermined number of randomly selected sub-queries for a given search query, or a predetermined number of most frequently searched sub-queries for a given search query. As previously described, the system may identify content tags representing entities depicted in an image by processing the image using an entity detection model.
In some implementations, the system can have pre-computed content tags for images corresponding to sub-queries of a given search query and store the content tags in a data store. The system may access pre-computed content tags for images corresponding to sub-queries of a given search query from a data store to reduce any latency in determining the content tags for the search query. If the system does not pre-compute the content tags of images corresponding to a particular sub-query of a given search query, the system may refrain from obtaining content tags of images corresponding to the particular sub-query.
The system identifies content tags representing entities depicted in images identified by search results generated by the search system by processing search queries related to a given search query (406). The related search queries may include, for example, a predetermined number of most frequently searched related search queries, or a predetermined number of randomly selected related search queries. As previously described, the system may identify content tags representing entities depicted in an image by processing the image using an entity detection model. In some implementations, the system can have pre-computed content tags for images corresponding to related search queries and store the content tags in a data store. The system can access pre-computed content tags of images corresponding to related search queries from a data store to reduce any latency in determining the content tags of the search queries. If the system does not pre-calculate the content tags of the images corresponding to a particular related search query, the system may refrain from obtaining the content tags of the images corresponding to the particular related search query.
The system determines the content tags for a given search query based on the content tags identified as described in reference 402, 404, and 406 (408). For example, the system may determine the content tags as a set of all content tags identified for images corresponding to a given search query, sub-queries of the given search query, and search queries related to the given search query. Any other suitable method for combining the identified content tags described with reference to 402, 404, and 406 may be used.
The term "configured" is used herein in connection with system and computer program components. For a system of one or more computers configured to perform particular operations or actions, it is meant that the system has installed thereon software, firmware, hardware, or a combination thereof that in operation causes the system to perform the operations or actions. For one or more computer programs configured to perform certain operations or actions, it is meant that the one or more programs include instructions that, when executed by a data processing apparatus, cause the apparatus to perform the operations or actions.
Embodiments of the subject matter and the functional operations described in this specification can be implemented in digital electronic circuitry, in tangibly embodied computer software or firmware, in computer hardware including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them. Embodiments of the subject matter described in this specification can be implemented as one or more computer programs, i.e., one or more modules of computer program instructions encoded on a tangible, non-transitory computer storage medium for execution by, or to control the operation of, data processing apparatus. The computer storage medium may be a machine-readable storage device, a machine-readable storage substrate, a random or serial access memory device, or a combination of one or more of them. Alternatively or additionally, the program instructions can be encoded on an artificially generated propagated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal that is generated to encode information for transmission to suitable receiver apparatus for execution by a data processing apparatus.
The term "data processing apparatus" refers to data processing hardware and encompasses all kinds of apparatus, devices, and machines for processing data, including by way of example a programmable processor, a computer, or multiple processors or computers. The apparatus can also be or further comprise special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit). The apparatus can optionally include, in addition to hardware, code that creates a runtime environment for the computer program, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, or a combination of one or more of them.
A computer program may also be referred to or described as a program, software, a software application, an application, a module, a software module, a script, or code in any form of programming language, including compiled or interpreted languages, or declarative or procedural languages, and it may be deployed in any form, including as a stand-alone program or as a module, component, subroutine, or other unit suitable for use in a computing environment. A program may, but need not, correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data, e.g., one or more scripts stored in a markup language document, in a single file dedicated to the program in question, or in multiple coordinated files such as files that store one or more modules, sub programs, or portions of code. A computer program can be deployed to be run on one computer or on multiple computers at one site or distributed across multiple sites and interconnected by a data communication network.
In this specification, the term "engine" is used broadly to refer to a software-based system, subsystem, or process that is programmed to perform one or more particular functions. Typically, the engine will be implemented as one or more software modules or components installed on one or more computers in one or more locations. In some cases, one or more computers will be dedicated to a particular engine; in other cases, multiple engines may be installed and run on the same computer or computers.
The processes and logic flows described in this specification can be performed by one or more programmable computers executing one or more computer programs to perform functions by operating on input data and generating output. The processes and logic flows can also be performed by, and in combination with, special purpose logic circuitry, e.g., an FPGA or an ASIC.
A computer suitable for the execution of a computer program can be based on a general-purpose or special-purpose microprocessor or both, or any other kind of central processing unit. Generally, a central processing unit will receive instructions and data from a read-only memory or a random access memory or both. The essential elements of a computer are a central processing unit for executing or executing instructions and one or more memory devices for storing instructions and data. The central processing unit and the memory can be supplemented by, or incorporated in, special purpose logic circuitry. Generally, a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks. However, a computer need not have such a device. Moreover, the computer can be embedded in another device, e.g., a mobile telephone, a Personal Digital Assistant (PDA), a mobile audio or video player, a game console, a Global Positioning System (GPS) receiver, or a portable storage device such as a Universal Serial Bus (USB) flash drive, to name a few.
Computer-readable media suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, such as internal hard disks or removable disks; magneto-optical disks; and CD-ROM and DVD-ROM disks.
To provide for interaction with a user, embodiments of the subject matter described in this specification can be implemented on a computer having a display device, e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to the user and a keyboard and a pointing device, e.g., a mouse or a trackball, by which the user can provide input to the computer. Other kinds of devices can also be used to provide for interaction with a user; for example, feedback provided to the user can be any form of sensory feedback, e.g., visual feedback, auditory feedback, or tactile feedback; and input from the user can be received in any form including acoustic, speech, or tactile input. Further, the computer is able to interact with the user by sending and receiving documents to and from the device used by the user; for example, by sending a web page to a web browser on the user's device in response to a request received from the web browser. In addition, the computer may interact with the user by sending a text message or other form of message to a personal device (e.g., a smartphone running a messaging application) and in return receiving a response message from the user.
The data processing apparatus for implementing the machine learning model may also comprise, for example, a dedicated hardware accelerator unit for processing common and computationally intensive parts of the machine learning training or production, i.e. reasoning, workload.
The machine learning model may be implemented and deployed using a machine learning framework, such as a TensorFlow framework, a Microsoft cognitive toolkit framework, an Apache Singa framework, or an Apache MXNet framework.
Embodiments of the subject matter described in this specification can be implemented in a computing system that includes a back-end component, e.g., as a data server, or that includes a middleware component, e.g., an application server, or that includes a front-end component, e.g., a client computer having a graphical user interface, a web browser or an application through which a user can interact with an implementation of the subject matter described is this specification, or any combination of one or more such back-end, middleware, or front-end components. The components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include a Local Area Network (LAN) and a Wide Area Network (WAN), e.g., the internet.
The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other. In some embodiments, the server sends data (e.g., HTML pages) to the user device, for example, to display data to and receive user input from a user interacting with the device acting as a client. Data generated at the user device, such as results of user interaction, may be received at the server from the device.
While this specification contains many specific implementation details, these should not be construed as limitations on the scope of any invention or of what may be claimed, but rather as descriptions of features that may be specific to particular embodiments of particular inventions. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely, various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Moreover, although features may be described above as occurring in certain combinations and even initially claimed as such, one or more features from a claimed combination can in some cases be excised from the combination, and the claimed combination may be directed to a subcombination or variation of a subcombination.
Similarly, while operations are depicted in the drawings and described in the claims in a particular order, this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order, or that all illustrated operations be performed, to achieve desirable results. In some cases, multitasking and parallel processing may be advantageous. Moreover, the separation of various system modules and components in the embodiments described above should not be understood as requiring such separation in all embodiments, and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.
Particular embodiments of the subject matter have been described. Other embodiments are within the scope of the following claims. For example, the actions recited in the claims can be performed in a different order and still achieve desirable results. As one example, the processes depicted in the accompanying figures do not necessarily require the particular order shown, or sequential order, to achieve desirable results. In some cases, multitasking and parallel processing may be advantageous.
Claims (20)
1. A method performed by one or more data processing apparatus, the method comprising:
receiving a request for an image responsive to a provided search query comprising one or more search terms;
obtaining a content tag of the provided search query, wherein the content tag of the provided search query represents an entity depicted in an image identified by search results that were previously generated by a search system by processing a search query that includes search terms included in the provided search query;
for each of a plurality of candidate images:
obtaining content tags for candidate images, wherein each content tag of the candidate images represents an entity depicted by a candidate image; and
determining a relevance score for the candidate image based on a similarity metric that measures similarity of: (i) a content tag of the provided search query, and (ii) a content tag of the candidate image;
determining a ranking of the candidate images based in part on the relevance scores of the candidate images; and
in response to the request, search results are provided that identify one or more candidate images based on the ranking of the candidate images.
2. The method of claim 1, wherein the content tags of the provided search query include terms representing entities depicted in an image identified by search results that were previously generated by a search system by processing the provided search query.
3. The method of claim 1, wherein the content tags of the provided search query include terms representing entities depicted in an image identified by search results that were previously generated by a search system by processing a search query defined by a sequence of one or more search terms included in the provided search query.
4. The method of claim 1, wherein the content tags of the provided search query include terms representing entities depicted in an image identified by search results that were previously generated by a search system by processing a search query that includes a sequence of one or more search terms that are also included in the provided search query.
5. The method of claim 1, wherein the content tags of the provided search query are determined based on respective user selection rates of search results generated by a search system by processing a search query including search terms included in the provided search query.
6. The method of claim 1, wherein:
the content tag of the candidate image is generated by processing the candidate image using an entity detection model to generate data defining an entity depicted by the candidate image; and
the content tags of the provided search query are generated by processing images identified by search results that were previously generated by a search system by processing a search query that includes search terms included in the provided search query using an entity detection model.
7. The method of claim 6, wherein the entity detection model comprises an object detection neural network.
8. The method of claim 1, wherein:
obtaining the content tag of the candidate image comprises: obtaining one or more content tags, each content tag representing a respective object depicted by a candidate image; and
obtaining the content tags for the provided search query includes: one or more content tags are obtained, each content tag representing a respective object depicted in an image identified by a search result that was previously generated by a search system by processing a search query that includes search terms included in the provided search query.
9. The method of claim 1, wherein the relevance score for a candidate image is determined based on a similarity metric that measures similarity of: (i) a content tag of the provided search query, and (ii) a content tag of the candidate image, comprising:
determining a cosine similarity measure between: (i) a digital representation of the content tag of the provided search query, and (ii) a digital representation of the content tag of the candidate image.
10. The method of claim 1, wherein the similarity metric is based on a respective likelihood of each of: (i) a content tag of the provided search query, and (ii) a content tag of the candidate image.
11. The method of claim 1, wherein providing, in response to the request, data identifying one or more candidate images based on a ranking of a plurality of candidate images comprises:
in response to the request, data is provided that identifies one or more highest ranked candidate images.
12. A system comprising one or more computers and one or more storage devices storing instructions that, when executed by the one or more computers, cause the one or more computers to perform operations comprising:
receiving a request for an image responsive to a provided search query comprising one or more search terms;
obtaining a content tag of the provided search query, wherein the content tag of the provided search query represents an entity depicted in an image identified by search results that were previously generated by a search system by processing a search query that includes search terms included in the provided search query;
for each of a plurality of candidate images:
obtaining content tags for candidate images, wherein each content tag of the candidate images represents an entity depicted by a candidate image; and
determining a relevance score for the candidate image based on a similarity metric that measures similarity of: (i) a content tag of the provided search query, and (ii) a content tag of the candidate image;
determining a ranking of the candidate images based in part on the relevance scores of the candidate images; and
in response to the request, search results are provided that identify one or more candidate images based on the ranking of the candidate images.
13. The system of claim 12, wherein the content tags of the provided search query include terms representing entities depicted in the image identified by search results that were previously generated by the search system by processing the provided search query.
14. The system of claim 12, wherein the content tags of the provided search query include terms representing entities depicted in the image identified by search results that were previously generated by the search system by processing a search query defined by a sequence of one or more search terms included in the provided search query.
15. The system of claim 12, wherein the content tags of the provided search query include terms representing entities depicted in the image identified by search results that were previously generated by the search system by processing the search query, the search query including a sequence of one or more search terms that are also included in the provided search query.
16. The system of claim 12, wherein the content tags of the provided search query are determined based on respective user selection rates of search results generated by the search system by processing the search query including search terms included in the provided search query.
17. One or more non-transitory computer storage media storing instructions that, when executed by one or more computers, cause the one or more computers to perform operations comprising:
receiving a request for an image responsive to a provided search query comprising one or more search terms;
obtaining a content tag of the provided search query, wherein the content tag of the provided search query represents an entity depicted in an image identified by search results that were previously generated by a search system by processing a search query that includes search terms included in the provided search query;
for each of a plurality of candidate images:
obtaining content tags for candidate images, wherein each content tag of the candidate images represents an entity depicted by a candidate image; and
determining a relevance score for the candidate image based on a similarity metric that measures similarity of: (i) a content tag of the provided search query, and (ii) a content tag of the candidate image;
determining a ranking of the candidate images based in part on the relevance scores of the candidate images; and
in response to the request, search results are provided that identify one or more candidate images based on the ranking of the candidate images.
18. The non-transitory computer storage medium of claim 17, wherein the content tags of the provided search query include terms representing entities depicted in an image identified by search results that were previously generated by a search system by processing the provided search query.
19. The non-transitory computer storage medium of claim 17, wherein the content tags of the provided search query include terms representing entities depicted in the image identified by search results that were previously generated by the search system by processing a search query defined by a sequence of one or more search terms included in the provided search query.
20. The non-transitory computer storage medium of claim 17, wherein the content tags of the provided search query include terms representing entities depicted in an image identified by search results that were previously generated by a search system by processing a search query that includes a sequence of one or more search terms that are also included in the provided search query.
Applications Claiming Priority (5)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201862770478P | 2018-11-21 | 2018-11-21 | |
US62/770,478 | 2018-11-21 | ||
US16/264,218 US20200159765A1 (en) | 2018-11-21 | 2019-01-31 | Performing image search using content labels |
US16/264,218 | 2019-01-31 | ||
PCT/US2019/046690 WO2020106341A1 (en) | 2018-11-21 | 2019-08-15 | Performing image search using content labels |
Publications (1)
Publication Number | Publication Date |
---|---|
CN112740202A true CN112740202A (en) | 2021-04-30 |
Family
ID=70726360
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201980062450.4A Pending CN112740202A (en) | 2018-11-21 | 2019-08-15 | Performing image search using content tags |
Country Status (4)
Country | Link |
---|---|
US (1) | US20200159765A1 (en) |
EP (1) | EP3682309A1 (en) |
CN (1) | CN112740202A (en) |
WO (1) | WO2020106341A1 (en) |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN113220922A (en) * | 2021-06-04 | 2021-08-06 | 北京有竹居网络技术有限公司 | Image searching method and device and electronic equipment |
Families Citing this family (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11675787B2 (en) * | 2019-03-15 | 2023-06-13 | International Business Machines Corporation | Multiple search collections based on relevancy value |
CN112464006A (en) * | 2020-06-14 | 2021-03-09 | 黄雨勤 | Data analysis method and system based on artificial intelligence and Internet |
US20240126807A1 (en) * | 2022-10-18 | 2024-04-18 | Google Llc | Visual Search Determination for Text-To-Image Replacement |
CN116628251B (en) * | 2023-06-19 | 2023-11-03 | 北京控制工程研究所 | Method, device, equipment and medium for searching moon surface safety area |
Family Cites Families (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11222044B2 (en) * | 2014-05-16 | 2022-01-11 | Microsoft Technology Licensing, Llc | Natural language image search |
-
2019
- 2019-01-31 US US16/264,218 patent/US20200159765A1/en not_active Abandoned
- 2019-08-15 WO PCT/US2019/046690 patent/WO2020106341A1/en unknown
- 2019-08-15 EP EP19759856.8A patent/EP3682309A1/en not_active Withdrawn
- 2019-08-15 CN CN201980062450.4A patent/CN112740202A/en active Pending
Cited By (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN113220922A (en) * | 2021-06-04 | 2021-08-06 | 北京有竹居网络技术有限公司 | Image searching method and device and electronic equipment |
CN113220922B (en) * | 2021-06-04 | 2024-02-02 | 北京有竹居网络技术有限公司 | Image searching method and device and electronic equipment |
Also Published As
Publication number | Publication date |
---|---|
WO2020106341A1 (en) | 2020-05-28 |
EP3682309A1 (en) | 2020-07-22 |
US20200159765A1 (en) | 2020-05-21 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US20240078258A1 (en) | Training Image and Text Embedding Models | |
US8429173B1 (en) | Method, system, and computer readable medium for identifying result images based on an image query | |
JP6266080B2 (en) | Method and system for evaluating matching between content item and image based on similarity score | |
JP5436665B2 (en) | Classification of simultaneously selected images | |
US8762326B1 (en) | Personalized hot topics | |
US20180081880A1 (en) | Method And Apparatus For Ranking Electronic Information By Similarity Association | |
US20200159765A1 (en) | Performing image search using content labels | |
US11586927B2 (en) | Training image and text embedding models | |
US8527564B2 (en) | Image object retrieval based on aggregation of visual annotations | |
CN108763244B (en) | Searching and annotating within images | |
US20100010982A1 (en) | Web content characterization based on semantic folksonomies associated with user generated content | |
US9218366B1 (en) | Query image model | |
US9507805B1 (en) | Drawing based search queries | |
US10339191B2 (en) | Method of and a system for processing a search query | |
CN109952571B (en) | Context-based image search results | |
US20140280086A1 (en) | Method and apparatus for document representation enhancement via social information integration in information retrieval systems | |
US11379527B2 (en) | Sibling search queries | |
US20150088859A1 (en) | Click magnet images | |
CN107423298B (en) | Searching method and device | |
US20140081944A1 (en) | Web searching method, system, and apparatus | |
Geetha et al. | Diversifying Image search results |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |