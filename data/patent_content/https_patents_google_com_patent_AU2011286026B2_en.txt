AU2011286026B2 - Input to locked computing device - Google Patents
Input to locked computing device Download PDFInfo
- Publication number
- AU2011286026B2 AU2011286026B2 AU2011286026A AU2011286026A AU2011286026B2 AU 2011286026 B2 AU2011286026 B2 AU 2011286026B2 AU 2011286026 A AU2011286026 A AU 2011286026A AU 2011286026 A AU2011286026 A AU 2011286026A AU 2011286026 B2 AU2011286026 B2 AU 2011286026B2
- Authority
- AU
- Australia
- Prior art keywords
- computing device
- command
- user inputs
- user
- computer
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/60—Protecting data
- G06F21/62—Protecting access to data via a platform, e.g. using keys or access control rules
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/30—Authentication, i.e. establishing the identity or authorisation of security principals
- G06F21/31—User authentication
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/30—Authentication, i.e. establishing the identity or authorisation of security principals
- G06F21/31—User authentication
- G06F21/36—User authentication by graphic or iconic representation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/30—Authentication, i.e. establishing the identity or authorisation of security principals
- G06F21/45—Structures or tools for the administration of authentication
- G06F21/46—Structures or tools for the administration of authentication by designing passwords or checking the strength of passwords
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/60—Protecting data
- G06F21/62—Protecting access to data via a platform, e.g. using keys or access control rules
- G06F21/629—Protecting access to data via a platform, e.g. using keys or access control rules to features or functions of an application
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/70—Protecting specific internal or peripheral components, in which the protection of a component leads to protection of the entire computer
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/017—Gesture based interaction, e.g. based on a set of recognized hand gestures
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0481—Interaction techniques based on graphical user interfaces [GUI] based on specific properties of the displayed interaction object or a metaphor-based environment, e.g. interaction with desktop elements like windows or icons, or assisted by a cursor's changing behaviour or appearance
- G06F3/04817—Interaction techniques based on graphical user interfaces [GUI] based on specific properties of the displayed interaction object or a metaphor-based environment, e.g. interaction with desktop elements like windows or icons, or assisted by a cursor's changing behaviour or appearance using icons
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0484—Interaction techniques based on graphical user interfaces [GUI] for the control of specific functions or operations, e.g. selecting or manipulating an object, an image or a displayed text element, setting a parameter value or selecting a range
- G06F3/0486—Drag-and-drop
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0487—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser
- G06F3/0488—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser using a touch-screen or digitiser, e.g. input of commands through traced gestures
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0487—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser
- G06F3/0488—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser using a touch-screen or digitiser, e.g. input of commands through traced gestures
- G06F3/04883—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser using a touch-screen or digitiser, e.g. input of commands through traced gestures for inputting data by handwriting, e.g. gesture or text
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/16—Sound input; Sound output
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/16—Sound input; Sound output
- G06F3/167—Audio in a user interface, e.g. using voice commands for navigating, audio feedback
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/22—Procedures used during a speech recognition process, e.g. man-machine dialogue
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/26—Speech to text systems
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F2221/00—Indexing scheme relating to security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F2221/03—Indexing scheme relating to G06F21/50, monitoring users, programs or devices to maintain the integrity of platforms
- G06F2221/032—Protect output to user by software means
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F2221/00—Indexing scheme relating to security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F2221/21—Indexing scheme relating to G06F21/00 and subgroups addressing additional information or applications relating to security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F2221/2105—Dual mode as a secondary aspect
Abstract
The subject matter of this specification can be embodied in, among other things, a method that includes receiving at a computing device that is in a locked state, one or more user inputs to unlock the device and to execute at least one command that is different from a command for unlocking the device. The method further includes executing in response to the user inputs to unlock the device an unlocking operation by the device to convert the device from a locked state to an unlocked state. The method further includes executing the at least one command in response to receiving the user inputs to execute the at least one command. The at least one command executes so that results of executing the at least one command are first displayed on the device to a user automatically after the device changes from the locked state to the unlocked state.
Description
Input to Locked Computing Device
CROSS-REFERENCE TO RELATED APPLICATION
[0001] This application claims priority to U.S. Application Serial No. 12/851,739, filed on August 6, 2010, entitled INPUT TO LOCKED COMPUTING DEVICE, the disclosure of which is incorporated herein by reference.
BACKGROUND
[0002] Computing devices, such as smartphones or desktop computers, often have a security measure that prevents accidental and/or unauthorized access. The locking of a device may simply be aimed at preventing casual contact with the device from leading to a dialed number or similar input, or it may be aimed at preventing a user other than the owner of the device from accessing the full functionality of the device (partial functionality like a clock and access to dialing 911 may be permitted even when the device is locked). For example, a user of a smartphone may enter a number of alphanumeric characters to gain access to the full functionality of the smartphone, or a smartphone may have a touchscreen on which a simple pattern can be drawn by a user to unlock the device. A more complex pattern can be used to prevent access by unauthorized users. Larger computers, such as desktop computers, also often require a person to enter a username and password to unlock or gain access to the device.
SUMMARY
[0003] In general, this document describes systems and techniques by which a locked computing device may respond to inputs from a user of the device who is preferably an authorized user of the device. In particular examples discussed below, the input is a request to perform a particular operation beyond simply unlocking the device. For example, icons for a number of commands may be displayed on a touchscreen, though a user will not be able to invoke those commands when the device is locked simply by tapping them in a normal manner, as the user could if the device were unlocked. Instead, the user may be required to perform a more complex action that is unlikely to be performed accidentally or by an unintended action such as contact with the touchscreen when the device is in a user’s pocket. Such action may involve, for example, dragging from one of the command-related icons to an unlock icon at a different location on the touchscreen and releasing over that other icon. The device may then respond by executing at least part of the requested command while the unlocking operation is still being performed, such as launching an application to which the first icon is directed. In this two-icon dragging example, the motion may also be reversed, with the user starting at an unlock icon and dragging to a command-related icon.
[0004] In one aspect, a computer-implemented method for making an input to a locked device includes receiving at a computing device that is in a locked state, one or more user inputs to unlock the computing device and to execute at least one command that is different from a command for unlocking the computing device. The method further includes executing in response to the user inputs to unlock the computing device an unlocking operation by the computing device to convert the computing device from a locked state to an unlocked state. The method further includes executing the at least one command in response to receiving the user inputs to execute the at least one command. The method further includes wherein the at least one command executes so that results of executing the at least one [0005] Implementations can include any, all, or none of the following features. Executing the at least one command begins before the user inputs to unlock the computing device are fully received. The method includes comparing the user inputs to unlock the computing device to one or more passcodes, and executing the unlock operation only if the user inputs to unlock the computing device match the one or more passcodes. Receiving the user inputs to unlock the computing device and to execute the at least one command, includes receiving a touch input on a device touchscreen to unlock the computing device and a spoken input to execute the at least one command. Receiving the user inputs to unlock the computing device and to execute the at least one command, includes receiving a dragging motion between an icon that corresponds to a function corresponding to the at least one command, and an icon that corresponds to an unlocking function for the computing device. Executing the at least one command includes making a network request to a server system that is remote from the computing device so as to accelerate availability of content from the server system as soon as the computing device is unlocked. The method includes storing results from the server system without displaying the results while the computing device is locked, and displaying the stored results when the computing device is unlocked.
[0006] In one aspect, a computer program product, encoded on a computer-readable medium, operable to cause one or more processors to perform operations for making an input to a locked device including receiving at a computing device that is in a locked state, one or more user inputs to unlock the computing device and to execute at least one command that is different from a command for unlocking the computing device. The operations further include executing in response to the user inputs to unlock the computing device an unlocking operation by the computing device to convert the computing device from a locked state to an unlocked state.
The operations further include executing the at least one command in response to receiving the user inputs to execute the at least one command. The operations further include wherein the at least one command executes so that results of executing the at least one command are first displayed on the computing device to a user automatically after the computing device changes from the locked state to the unlocked state.
[0007] In one aspect, a computer-implemented system for making an input to a locked device includes a computing device that includes a user interface that receives, while the computing device is in a locked state, one or more user inputs to unlock the computing device and to execute at least one command that is different from a command for unlocking the computing device; a processor that executes, in response to the user inputs to unlock the computing device, an unlocking operation to convert the computing device from a locked state to an unlocked state and executes the at least one command in response to receiving the user inputs to execute the at least one command; and a display device that first displays results of executing the at least one command on the computing device to a user automatically after the computing device changes from the locked state to the unlocked state.
[0008] Implementations can include any, all, or none of the following features.
The computer device further includes a microphone that receives audio, and executing the at least one command includes processing the received audio. The system includes a server system, and processing the received audio includes sending the received audio to the server system and receiving the results from the server system. The computing device further includes a memory that stores the results received from the server system without displaying the results while the computing device is locked, and displaying the stored results when the computing device is unlocked.
[0009] The systems and techniques described here may provide one or more of the following advantages. First, a user of a computer-implemented system can access resources on the system in less time and with less effort than they would if they had to unlock the device and then select an action to perform with the device. Second, a system can perform in parallel an unlocking operation and a user-requested operation, such as launching an application or making the application the focus of the system. Third, a system can receive a voice input that requests an operation while an unlocking operation is performed. Fourth, results of an operation that was requested while a computing device is locked can be presented audibly while the computing device is being unlocked.
[0010] The details of one or more implementations are set forth in the accompanying drawings and the description below. Other features and advantages will be apparent from the description and drawings, and from the claims.
DESCRIPTION OF DRAWINGS
[0011] FIG. 1 is a schematic diagram that shows an example of a system for initiating an action while unlocking a device.
[0012] FIG. 2 shows an example of a user interface for initiating an action while unlocking a device.
[0013] FIG. ЗА shows an example of a graphical user interface and icons for initiating an action while unlocking a device.
[0014] FIG. 3B shows an example of a graphical user interface and icons for initiating a modified action while unlocking a device.
[0015] FIG. 4 shows an example of a graphical user interface and a radial menu for initiating an action while unlocking a device.
[0016] FIG. 5 is a flow chart that shows an example of a process for initiating an action while unlocking a device.
[0017] FIG. 6 is a sequence diagram that shows an example of a process for initiating an action while unlocking a device.
[0018] FIG. 7 shows an example of a computing device and a mobile computing device that can be used in connection with computer-implemented methods and systems described in this document.
DETAILED DESCRIPTION
[0019] This document describes systems and techniques for inputting a command while unlocking a mobile device. The command, which is distinct from a command to unlock the device, can be executed while the mobile device is being unlocked. For example, a user can command a dialer to call a particular contact, such as the user’s wife, with a single input action. In another example, a user can command an email client to request new emails from a mail server while a mobile telephone is being unlocked. In some implementations, this can provide greater efficiency than a command entered after unlocking by allowing a mobile device to at least begin performing an action that is complex, lengthy, or delayed by network communication while a user makes an input to unlock the telephone. In some implementations, a system can provide efficient input commands by accepting a single input that initiates multiple actions, such as an unlocking operation and another operation or an email operation and an email recipient selection.
[0020] FIG. 1 is a schematic diagram that shows an example of a system 100 for initiating an action at a mobile device 102 while unlocking the mobile device 102.
The mobile device 102 is an electronic device that performs one or more actions, such as a smartphone or a tablet computer. The mobile device 102 includes a user interface that can be locked and unlocked by a user, and typically will implement the interface as a touchscreen display in a familiar manner. For example, a cellular telephone or other computing device can be locked to prevent accidental or unauthorized access. Such locking may be instigated manually by a user (such as by the user placing the device into a sleep state by pressing a power button) or automatically such as by a predetermined period of inactivity for the device passing. During an unlocking operation performed by the user, a portion of the user input triggers an action that is performed concurrently with the unlocking operation. For example, the mobile device 102 can send a search query to a search server 104.
[0021] The search server 104 is a computer system that accepts search queries and in return provides search results. In some implementations, the search queries can be provided in text, audio, or other data formats. For example, a search query “buffalo wings” sent to the search server 104 can return a list of links to content servers, including a content server 106. The content servers include content related to buffalo wings recipes, local restaurants that serve buffalo wings, buffalo anatomy, media labeled “buffalo wings”, and small airports in the Nantucket area that serve buffalo wings. The results for certain queries that are determined to be location-based in character, such as queries that refer to foods served in restaurants, may be “local” results, such as links to web sites for restaurants and telephone numbers for the restaurants near that serve buffalo wings near the user’s current location (as [0022] The content server 106 is a computer system that serves content, such as web pages, video, audio, or other media over a computer network 108 to client devices, such as the mobile device 102. For example, the content server 106 can serve web page from the search results that lists reviews of a restaurant that serves buffalo wings.
[0023] The computer network 108 is a network that provides for communication between the mobile device 102, the search server 104, and the content server 106. The computer network 108 can include, for example, the Internet, a local intranet, cellular data networks such as the Enhanced Data rates for Global System for Mobile Evolution (EDGE) and/or other wired or wireless data networks.
[0024] The components of the system 100 may interact with each other in response to commands and other inputs provided by a user of the mobile device 102, and such actions are shown using numbered arrows superimposed over the components in the figure. In this example, the mobile device 102 initially receives an input 110 from the user while the mobile device 102 is in a locked state. The input 110 includes a request to unlock the mobile device 102 and a request to perform an action that is different from unlocking the device. For example, the request to perform an action can include a voice command to perform a search using one or more search terms in the voice the command. In another example, the request to perform the action can include a selection or moving of an icon or area that represents the action. The request to unlock the mobile device 102 can include, for example, a text-based or pattern-based (e.g., finger-traced) password or passcode.
[0025] The mobile device 102 then receives the two-part input 110 from the user. From the input 110, the mobile device 102 detects the request to perform the action and, in this example, subsequently the request to unlock the mobile device 102. Where the request to unlock is expected to take a relatively long time, such as when it involves entering a password or passcode as opposed to simply sliding an unlock mechanism (i.e., when the telephone is locked so as to avoid accidental input rather than to provide security) the selection of the other action may occur first, so that the device may begin performing the other action while the user performs the relatively time consuming action of entering the password or passcode. When the unlocking action can be performed quickly, it may more readily be implemented so that it is performed first by the user - in such a situation, the process does not really save time by starting the other action early, but it does save input effort for the user, because the user can, for instance, provide a single movement that combines unlocking and selection of an action.
[0026] In response to detecting the request to perform the action as an initial user input, the mobile device 102 begins performing the action prior to detecting the request to unlock the mobile device 102. For example, the mobile device 102 can detect a voice command to search for “buffalo wings” and can send a voice search request 112 to the search server 104. The voice search request 112 can include an audio file recording of the voice command, a text transcription of the voice command, and/or other corresponding content.
[0027] After or while the mobile device 102 is sending the voice search request 112 to the search server 104, it can detect from the user’s input 110, a request to unlock 114 the mobile device 102. In response, the mobile device 102 determines if the request to unlock 114 the mobile device 102 includes a valid request, such as a correct password or unlock pattern. If the request to unlock 114 the mobile device 102 is valid, then the mobile device 102 unlocks itself. Otherwise, the mobile device 102 remains in the locked state and can prompt the user to reenter the unlocking information. As long as the user has not entered an appropriate credential (password or passcode), the device 102 maintains a typical locked state in which it accepts only very limited inputs, such as dialing of emergency numbers, and provides only limited, non-secure information such as the date and time. This is true even though the mobile device 102 may be performing activities relating to the initial user action or request, but is not making the results of the actions visible to or otherwise accessible to the user of the mobile device 102.
[0028] In response to receiving the search request, the search server 104 sends one or more search results 116 back to the mobile device 102. The search results 116 can include, for example, a list of links that include titles and associated uniform resource identifiers (URIs). The search results 116 can arrive at the mobile device 102 before, during, or after unlocking of the device 102 is complete. In the case in which the search results 116 arrive before the end of unlocking, the search results 116 can be temporarily stored by the mobile device 102 without displaying them. If the mobile device 102 is not successfully unlocked within a certain amount of time, the search results 116 can be discarded. After the mobile device 102 is successfully unlocked, the mobile device 102 displays the search results 116. The user can then select one of the search results 116, and the mobile device 102 can send a request to the content server 106 or another server (e.g., a content server for a company that is a subject of the selected result and/or an advertising server in order to register the user’s selection of an advertising result so that the advertiser may be billed for a user click) using the URI associated with the title.
[0029] Thus, by the system and process shown here, a computing device can begin processing a command for a user while the user is still in the process of unlocking the device, so that the results for the command can be presenting immediately, or at least more quickly than would otherwise be possible, to the user. Also, the user may combine an input for unlocking a device with an input of a command so that the user can save effort in performing the two distinct operations via one common and continuous input (i.e., the user need not pause to wait for a response from the device, such as when a user must first make an input to unlock a device, wait for the full unlocked display of the device to be shown, and then execute a command such as by selecting an icon on the display).
[0030] FIG. 2 shows an example of a mobile computing device 200 that allows a user to initiate an action while unlocking the mobile computing device 200. In general, the device contains memory and processors for executing code from the memory so that a user can substantially simultaneously perform an action (such as an action instigated by a touch or voice input) and unlock the device 200. In this example, the device is shown in the middle of being unlocked by a user, and may be performing background activities that have been previously started by an input from the user.
[0031] The mobile computing device 200 includes a screen 202 that presents to the user various user interface elements, such as a search icon 204 and a password field 206. The mobile computing device also includes a keyboard 208. The keyboard 208 can include hard keys or virtual, soft keys (e.g., a touchscreen keyboard within the screen 202). The user can select the search icon 204 to begin speaking a search command to the mobile computing device 200. While speaking the search command or while waiting for a response to the search command, the user can make an input in the password field 206 using the keyboard 208. The processing of the password input and the search query can occur concurrently. If the password input is successful, the mobile computing device 200 can subsequently present the search results to the user in the screen 202, after the device has changed from its prior locked mode or status to an unlocked mode or status.
[0032] The screen 202 is a touchscreen, such as a capacitive or resistive screen for user input and output. The search icon 204 is a graphical user interface (GUI) object and the device 102 can detect when a user presses over the top of the icon, so that the element acts as a software button. The password field 206 is also a GUI object. The password field 206 displays asterisks (*) for each character that is entered into the password field 206 using the keyboard 208.
[0033] For example, before a user completes a password entry input, the user can press the search icon 204, speak a voice command to the mobile computing device 200, and subsequently complete the password entry input using the keyboard 208. In another example, the user can input the password or other unlocking information in another way, such as by speaking the password or drawing an unlocking pattern on the screen 202. When the user correctly enters the password or other unlocking information, the mobile computing device 200 can present results of the voice command. In some implementations, some results can be presented to the user before their device completes the unlocking operation. For example, a summary of search results can be displayed. In some implementations, the summary of the search results cannot be selected or acted on by the user until the device has successfully completed the unlocking operation.
[0034] In different contexts, different amounts of information may be shown to the user or different levels of input may be allowed from the user, before the device has completed its unlocking. Generally, information and actions that are associated with security for the device (i.e., that would allow an interloper to send a message masquerading as the real user, that would let an interloper run up a bill for the real user, or that would let an interloper see personal information of the user such as contact records or other data files on the device) will be withheld from a user of the device until after the device is unlocked. Information that is shown before the device is unlocked is traditionally time information, perhaps local weather, and controls for unlocking and making emergency (e.g., 911) telephone calls. Limited additional functionality might also be permitted, such as the ability to use a web browser at limited URLs, the ability to review a news reader, and the like. In any such situations, however, the accessibility of an unlocked device is effectively unlimited, while the accessibility of a locked device is noticeably and extensively more limited.
[0035] As one example of input functionality that may be available (though with limited output) for a locked device using the techniques described here, which would not generally be available on a locked computing device, a user can press the search icon 204, speak the voice command “search raspberry jam,” and enter the password “12345” using the keyboard 208. In this example, the mobile computing device 200 can begin parsing and executing the voice command while the password is being entered with the keyboard 208. If the mobile computing device 200 finishes parsing and executing the voice command before the entire password is entered, the results of the execution can be stored and held without displaying them, and then be displayed upon successful unlocking of the device 200. If the mobile computing device 200 is successfully unlocked before it finishes parsing and executing the voice command, it can display a GUI object that indicates that the voice command is being processed. Alternatively, if the mobile computing device 200 is successfully unlocked after the it finishes parsing and executing the voice command, it can unlock normally and notify the user when the results of executing the voice command are ready to be displayed.
[0036] FIG. ЗА shows an example of a mobile computing device 300 that allows a user to initiate an action while unlocking the mobile computing device 300. In general, the device provides for convenience-based unlocking rather than the security-based unlocking just described. In particular, convenience-based unlocking is directed to requiring a user to perform an action on a touchscreen that would not easily be performing accidentally or by inanimate objects that might come in contact with the screen, such as in the user’s pocket. In the example described in more detail below, such as action involves dragging from an icon that corresponds to a command, to an unlocking icons that is located far enough away from the first icon on a display that the dragging input would not frequently occur accidentally or coincidentally.
[0037] The mobile computing device 300 in this example includes a touchscreen 302 for displaying outputs to, and receiving inputs from, the user. While the mobile computing device 300 is in a locked state, the touchscreen 302 displays one or more action icons 304a-c and an unlock icon 306.
[0038] The action icons 304a-c represent shortcuts for requesting that a particular action be performed. The action icons 304a-c include a the action icon 304b that represents an action for placing a telephone call to a contact named Emily. The user can make an input on the touchscreen 302 that drags the action icon 304b to the unlock icon 306. The mobile computing device 300 can then in response initiate a telephone call to the contact named Emily as soon as the mobile computing device 300 unlocks, and automatically without further input from the user.
[0039] In one example, the mobile computing device 300 can begin initiating the action when the action icon 304b has been pulled a threshold distance toward the unlock icon 306, such as to a particular line or location on the touchscreen before reaching the unlock icon 306 or otherwise completing the unlocking operation. In some implementations, preparation for an action can begin before the unlocking operation is completed by the device. For example, an antenna for wireless communication can be activated or a data connection can be established (or such action can at least begin) without performing a final step for the requested action (e.g., completing the telephone call to the selected contact). Once the mobile computing device 300 receives a successful unlock command, then the mobile computing device 300 can perform the final step for the requested action.
[0040] In some implementations, the mobile computing device 300 can display an authentication screen in response to a user dragging the action icon 304b to the unlock icon 306. For example, the mobile computing device 300 can present a password entry field. In some implementations, the unlocking information can include a more complex pattern than selecting or dragging an icon to the unlock icon 306. For example, after the user selects or drags the action icon 304b as described above, the unlocking pattern may involve selecting and/or dragging a pattern across a series of multiple unlock icons.
[0041] The mobile computing device 300 can also allow the user to scroll through the action icons 304a-c. For example, the user can make a sideways dragging or flicking motion to scroll left to the action icon 304a or right to the action icon 304c. In some implementations, more than one action icon can be displayed in the touchscreen 302 at the same time. For example, the next contact name alphabetically in the mobile computing device 300 may be a contact named
Elizabeth. Accordingly, the action icon 304c can be a command to initiate a telephone call to the contact named Elizabeth. Flicking the action icon 304c to the left can scroll the action icon 304c to the center of the screen of the mobile computing device 300, into the location in which the action icon 304b is currently shown. Subsequently, the user can drag the action icon 304c to the unlock icon 306 to initiate a call to the contact named Elizabeth.
[0042] FIG. 3B is an example of a mobile computing device 350 that allows a user to initiate an action while unlocking the mobile computing device 350. The device 350 is similar to the device 300 in FIG. ЗА, but in this example, two different actions may be specified before the user chooses to unlock the device (i.e., by dragging through two icons).
[0043] The mobile computing device 350 includes a touchscreen 352 for displaying outputs to and receiving inputs from the user. While the mobile computing device 350 is in a locked state, the touchscreen 352 displays one or more action icons 354a-c, an unlock icon 356, and one or more value icons 358a-b.
[0044] The action icons 354a-c relate to a particular category or application. For example, the action icon 354a relates to placing telephone calls, the action icon 354b relates to accessing documents or files, and the action icon 354c relates to accessing email. The mobile computing device 350 can present other action icons as well, such as an action icon for a web browser or social network. The value icons 358a-b relate to values, events, settings, or other data that can modify or be acted on by one or more of the action icons 354a-c.
[0045] As a user drags an action icon toward the unlock icon 356, the action icon can be dragged through one of the value icons 358a-b, which can modify the category or application associated with the action icon. For example, the action icon 354a for placing a telephone call can be dragged through the value icon 358a for favorites and then dragged into the unlock icon 356. In this example, the mobile computing device 350 will prepare a list of favorite contacts to be displayed for calling as soon as, and automatically as, the mobile computing device 350 unlocks. In another example, the action icon 354a can be dragged through the value icon 358b for a dial-pad and dragged into the unlock icon 356. In such an example, the mobile computing device 350 prepares a dial-pad application for outgoing telephone calls as the mobile computing device 350 unlocks. In some implementations, an empty space 360 is left to allow an action icon to reach the unlock icon 356 without being dragged through any of the value icons 358a-b.
[0046] In some implementations, the value icons 358a-b can be displayed above the action icons 354a-c. In such a case, the value icons 358a-b can be dragged through an action icon and to the unlock icon 356 to perform an action while the mobile computing device 350 unlocks. For example, a value icon related to a contact named Emily can be dragged through the action icons 354a-c. In particular, the value icon for the contact named Emily can be dragged through an action icon that relates to tasks or applications, such as an instant messaging application, a social network site or application, or the telephone application. In such an example, dragging the value icon related to the contact named Emily through the action icon 354a and to the unlock icon 356 causes the mobile computing device 350 to initiate a telephone call to Emily while the mobile computing device 350 unlocks.
[0047] In another implementation, the value icons 358a-b contain values for a particular one of the action icons 354a-c that the user selects. For example, if the action icon 354a for placing a telephone call is selected and/or dragged, then the value icons 358a-b can relate to contacts that can be called using the telephone application, such as the value icon 358a for favorite contacts or individual contacts (e.g., Emily and Elizabeth). Dragging the action icon 354a through a value icon that relates to a contact named Emily can cause the mobile computing device 350 to initiate a telephone call to Emily while the device unlocks.
[0048] In some implementations, the value icons 358a-b change depending on the action icon that the user selects. For example, when the user drags one of the action icons 354a-c out of the top of the touchscreen 352, then one or more of the value icons 358a-b can change based on the selected action icon. In some implementations, a user can trigger or initiate the change in the value icons 358a-b by dragging an action item across a line 362. The line 362 can be either shown to or hidden from the user. Some of the value icons 358a-b can be general to multiple ones of the action icons 354a-c. For example, the value icon 358a for favorites can modify any of the action icons 354a-c. The value icon 358a indicates a most often accessed or bookmarked data. In another example, the value icon 358b for the dial-pad can modify only the action icon 354a for the telephone application, because it may not be appropriate for other ones of the action icons 354b-c, such as recent files, email, and others.
[0049] In another example, the mobile computing device 350 can receive a selection of the action icon 354c for the email application. In response to crossing the line 362, the mobile computing device 350 can update the value icons 358a-b to include a list of tasks that can be performed by the email application, such as a value icon for reading email or composing an email. In another example, the mobile computing device 350 can update the value icons 358a-b to include icons representing unread or new emails. While the unlocking operation is performed, the mobile computing device 350 can refresh the email inbox of the user and/or retrieve a specific email for presentation to the user in the touchscreen 352. In some implementations, the mobile computing device 350 can present a third set of icons. For example, the user can select and/or drag the action icon 354c for the email application, a value icon for composing an email, and then one or more of a third set of contact icons to select recipients for the email.
[0050] In some implementations, features described with respect to FIG. 3 allow for efficient use of limited display real estate. For example, scrolling action icons can allow easy access to many actions while providing each action with a large icon that can easily be controlled on a touchscreen. Separate screens for command input and authentication can allow larger GUI objects and locations used for user input. Combining action icons and modifying values can provide more options than the number of GUI objects shown.
[0051] FIG. 4 shows an example of a mobile computing device 400 that allows a user to initiate an action while unlocking the mobile computing device 400. In this example, the inputs that a user provides to the device 400 when unlocking the device 400 are providing by using a radial menu interface element.
[0052] The mobile computing device 400 includes a touchscreen 402 for displaying outputs to, and receiving inputs from, the user. While the mobile computing device 400 is in a locked state, the touchscreen 402 displays one or more action icons 404a-c and an unlock icon 406. The touchscreen 402 can be, for example, a capacitive or resistive screen for user input and output. The mobile computing device 400 detects a user selection and/or dragging of the unlock icon 406 that requests initiation of an action and an unlocking of the mobile computing device 400.
[0053] In particular, the mobile computing device 400 receives an input from the user that drags the unlock icon 406 to the action icon 404c, then to the action icon 404b, and finally back to the action icon 404c. In this example, the first selection of the action icon 404c indicates a request from the user to open the email application upon completion of the unlocking operation. Subsequently, the user drags an unlock pattern through the action icons 404b-c (i.e., drag one action clockwise to the action icon 404b and then one action counter-clockwise back to the action icon 404c). After the first selection of the action icon 404c for the email application, the mobile computing device 400 begins initiating the email application, such as by refreshing the inbox, retrieving content for messages, and/or retrieving contact information.
Once the mobile computing device 400 receives the remainder of the user input including a successful unlocking pattern, then the mobile computing device 400 presents the user interface for the requested email application.
[0054] Similarly, the user can drag the unlock icon 406 to the action icon 404b, then to the action icon 404a, and finally back to the action icon 404b. Upon the first selection of the action icon 404b, the mobile computing device 400 begins preparing the documents application. After receiving the successful unlocking pattern, the mobile computing device 400 presents the user interface for the documents application to the user in the touchscreen 402. In some implementations, some features of the GUI can enlarge, shrink, move, disappear, appear, or otherwise alter their appearance and/or location, for example, to facilitate input and/or provide feedback to the user regarding icons recognized as selected by the mobile computing device 400. The tracing through multiple action icons and an unlock icon can also result in actions corresponding to each and every one of the action icons being carried out generally concurrently with the device being unlocked. For [0055] In another example, the user can hold the mobile computing device 400 to the user’s ear or mouth, speak a voice command, and subsequently unlock the mobile computing device 400 by inputting the unlock pattern. The mobile computing device 400 detects raising of the mobile computing device 400 to the user’s ear (or proximity of a large object - a head - in front of the device’s screen) and, in response, enables speech input using a microphone in the mobile computing device 400. Alternatively, the mobile computing device 400 can enable speech input in response to selection of an action icon on the touchscreen 402. The mobile computing device 400 begins processing the voice command while the user inputs the unlocking information (which can be provided by touch or verbally). For example, the mobile computing device 400 can retrieve search results in response to a search command or refresh an email inbox in response to an email command.
[0056] In another implementation, a user can select the action icon to be executed separately from the input for the unlocking information. For example, the user can double tap or long press a particular action icon to be executed and then separately select and/or drag an unlocking pattern or password using on screen controls. Again, the mobile computing device 400 begins preparing the selected operation upon the initial selection of the action icon. Subsequently, the mobile computing device 400 receives the unlocking information and, in response, presents the user interface for the selected operation.
[0057] FIG. 5 is a flow chart that shows an example of a process 500 for initiating an action while unlocking a device. In general, the process involves recognizing a user’s input on a touchscreen of an unlocking input and a second input that is separate from the unlocking input, both before the device is switched from a locked to an unlocked mode, and performing actions that correspond to the second input and automatically presenting the result of the performed actions when the device becomes unlocked.
[0058] The process 500 may be performed, for example, by a system such as the system 100 and the mobile computing devices 200, 300, 350, and 400. For clarity of presentation, the description that follows uses the system 100 and the mobile computing devices 200, 300, 350, and 400 examples for describing the process 500. However, other systems, or combination of systems, may be used to perform the process 500.
[0059] The process 500 includes receiving (502) an input from a user to a device that is locked. For example, the mobile device 102 can be one of mobile telephones, personal data assistants, music players, and other such devices that include input features which can be locked when the device is not in use.
[0060] The process 500 then determines (504) if the input includes a touchscreen input. For example, the mobile device 102 can include a touchscreen for selecting icons or keys. Alternatively, the mobile device 102 can include a microphone for inputting voice commands.
[0061] If the input includes a touchscreen input, then the process 500 includes recognizing (506) a fist portion of the input on the touchscreen. For example, the mobile device 102 can include an icon, graphic, location, or button that can be pressed, dragged, or otherwise activated. In one example, a user can place a finger over an icon on a screen of the mobile device 102 and drag their finger across the screen indicating a direction of travel for the icon. In another example, a blank area [0062] If the input includes a voice input, then the process 500 includes recognizing (508) the voice input. For example, the mobile device 102 can include a microphone that receives audio commands from the user. The microphone can be activated in response to, for example, an accelerometer reading or an explicit request from the user, such as by selecting a microphone icon. The voice input can be recognized, or translated to text and otherwise processed ,either at the device itself or by sending a sound file to a server system and receiving corresponding text of the spoken words and other meta data.
[0063] When the portion of the input has been received, the process 500 initiates (510) an action based on the first portion or the voice input. For example, the first portion of the touchscreen input and/or the voice input may indicate an application, script, program, or other action to be performed by the mobile device 102. The mobile device 102 begins performing the requested action prior to receiving unlocking information.
[0064] The process 500 determines (512) if a touchscreen input is present. For example, the mobile device 102 can include a touchscreen for inputting an unlock pattern. If no touchscreen is present or not being used for the unlocking information, the a keyboard input or anther type of input can be retrieved.
[0065] If the touchscreen is being used, then the process 500 recognizes (514) a second portion of the input on the touchscreen. For example, the icon or location of the previous steps can be dragged to a location or icon before the user removes a finger from the touchscreen of the mobile device 102, such as in the case of an unlock pattern.
[0066] If the touchscreen is not being used, then the process 500 recognizes (516) a keyboard or other input. For example, a user can select individual keys on a keyboard.
[0067] If the second portion of the input and/or the keyboard input include proper unlock information, then the process 500 includes unlocking (518) the device. For example, the mobile device 102 can be unlocked after recognizing (516) the unlock pattern or the keyboard input. Upon unlocking, the mobile device 102 presents results of the selected action to the user, such as in a user interface of an application for the selected action.
[0068] FIG. 6 is a sequence diagram that shows an example of a process 620 for initiating an action while unlocking a mobile device 616. A user 600 operates the mobile device 616 or a client software application in communication with the mobile device 616, or other system able to send messages to the mobile device 616. The mobile device 616 is an electronic device that performs one or more actions and that is lockable to prevent accidental or unauthorized input. For example, a cellular telephone locks to prevent accidental input when the cellular telephone is in a pocket. A computer locks to prevent accidental or unauthorized input.
[0069] Once unlocked, the mobile device 616 can perform actions in response to user input commands. For example, the mobile device 616 can send search queries to a search system 618. The search system 618 is a computer system that accepts search queries and, in response, provides search results. For example, the search system 618 can be a search engine, database, or other system. The search system 618 can be included in the mobile device 616 or separate from the mobile device 616, such as a remote web server.
[0070] The mobile device 616 receives (602) a first input portion from the user 600. For example, the user can drag an icon or area of a touchscreen, enter input through a keyboard and/or speak a voice command into a microphone. The mobile device 616 processes the first input portion. For example, the mobile device 616 can indentify the first input portion as including a search query. The mobile device 616 sends (604) a search request to the search system 618. In some implementations, the search request can include data from the first input portion and/or the mobile device 616. The search system 618 performs (606) a search based on the search request. For example, the search system 618 can compare terms in the search request to terms in a search index to indentify one or more search results. The search system 618 sends (608) the search results to the mobile device 616.
[0071] The mobile device 616 receives (610) a second input portion from the user 600. For example, the second input portion can complete a password or pattern for unlocking the mobile device 616. The mobile device 616 unlocks (612) in response to the second input portion. After successfully unlocking, the mobile device 616 presents (614) the search results.
[0072] In one example, a user can speak a voice command “Pumpkinseed Street” as the first input portion. The mobile device 616 can parse the voice command and detect that the voice command is likely related to a location search. The mobile device 616 can transmit the voice command, in audio, text, or other format, along with global positioning system (GPS) information about the mobile device 616 to the search system 618 as the search request. The search system 618 can perform a search such as compiling a map of Pumpkinseed Street, collecting weather information (“sunny all day”), and/or traffic conditions (“all routes OK”). The map, weather information, and/or traffic conditions can be returned to the mobile device 616. The user 600 can enter an unlocking command, such as drawing a pattern on the touchscreen of the mobile device 616. The mobile device 616 unlocks itself in response to receiving a successful unlocking pattern. Once unlocked, the mobile device 616 displays the map of Pumpkinseed street, the “sunny all day” weather condition, and/or “all routes OK” traffic information.
[0073] In another example, the user 600 may enter a search request “Who was crowned king last Friday?” as the first input portion. The mobile device 616 sends the search request to the search system 618 without parsing, analyzing, or editing the first input portion. The search system 618 performs the action of searching for an answer to the query in the search request. In this example, no king was crowned last Friday, and the search system 618 spends a longer time performing the search than in some other examples. In this example, the user can input the second input portion before the search results are returned (not shown). In this example, the mobile device 616 can unlock the mobile device 616 and display a screen indicating that the mobile device 616 is waiting on search results (not shown).
[0074] FIG. 7 shows an example of a computing device 700 and a mobile computing device that can be used to implement the techniques described here.
The computing device 700 is intended to represent various forms of digital computers, such as laptops, desktops, workstations, personal digital assistants, servers, blade servers, mainframes, and other appropriate computers. The mobile computing device is intended to represent various forms of mobile devices, such as personal digital assistants, cellular telephones, smart-phones, and other similar computing devices. The components shown here, their connections and relationships, and their functions, are meant to be exemplary only, and are not meant to limit implementations of the inventions described and/or claimed in this document.
[0075] The computing device 700 includes a processor 702, a memory 704, a storage device 706, a high-speed interface 708 connecting to the memory 704 and multiple high-speed expansion ports 710, and a low-speed interface 712 connecting to a low-speed expansion port 714 and the storage device 706. Each of the processor 702, the memory 704, the storage device 706, the high-speed interface 708, the high-speed expansion ports 710, and the low-speed interface 712, are interconnected using various busses, and may be mounted on a common motherboard or in other manners as appropriate. The processor 702 can process instructions for execution within the computing device 700, including instructions stored in the memory 704 or on the storage device 706 to display graphical information for a GUI on an external input/output device, such as a display 716 coupled to the high-speed interface 708. In other implementations, multiple processors and/or multiple buses may be used, as appropriate, along with multiple memories and types of memory. Also, multiple computing devices may be connected, with each device providing portions of the necessary operations (e.g., as a server bank, a group of blade servers, or a multi-processor system).
[0076] The memory 704 stores information within the computing device 700. In some implementations, the memory 704 is a volatile memory unit or units. In some implementations, the memory 704 is a non-volatile memory unit or units. The memory 704 may also be another form of computer-readable medium, such as a magnetic or optical disk.
[0077] The storage device 706 is capable of providing mass storage for the computing device 700. In some implementations, the storage device 706 may be or contain a computer-readable medium, such as a floppy disk device, a hard disk device, an optical disk device, or a tape device, a flash memory or other similar solid state memory device, or an array of devices, including devices in a storage area network or other configurations. A computer program product can be tangibly embodied in an information carrier. The computer program product may also contain instructions that, when executed, perform one or more methods, such as those described above. The computer program product can also be tangibly embodied in a computer- or machine-readable medium, such as the memory 704, the storage device 706, or memory on the processor 702.
[0078] The high-speed interface 708 manages bandwidth-intensive operations for the computing device 700, while the low-speed interface 712 manages lower bandwidth-intensive operations. Such allocation of functions is exemplary only. In some implementations, the high-speed interface 708 is coupled to the memory 704, the display 716 (e.g., through a graphics processor or accelerator), and to the highspeed expansion ports 710, which may accept various expansion cards (not shown). In the implementation, the low-speed interface 712 is coupled to the storage device 706 and the low-speed expansion port 714. The low-speed expansion port 714, which may include various communication ports (e.g., USB, Bluetooth, Ethernet, wireless Ethernet) may be coupled to one or more input/output devices, such as a keyboard, a pointing device, a scanner, or a networking device such as a switch or router, e.g., through a network adapter.
[0079] The computing device 700 may be implemented in a number of different forms, as shown in the figure. For example, it may be implemented as a standard server 720, or multiple times in a group of such servers. In addition, it may be implemented in a personal computer such as a laptop computer 722. It may also be implemented as part of a rack server system 724. Alternatively, components from the computing device 700 may be combined with other components in a mobile device (not shown), such as a mobile computing device 750. Each of such devices may contain one or more of the computing device 700 and the mobile computing device 750, and an entire system may be made up of multiple computing devices communicating with each other.
[0080] The mobile computing device 750 includes a processor 752, a memory 764, an input/output device such as a display 754, a communication interface 766, and a transceiver 768, among other components. The mobile computing device 750 may also be provided with a storage device, such as a micro-drive or other device, to provide additional storage. Each of the processor 752, the memory 764, the display 754, the communication interface 766, and the transceiver 768, are interconnected using various buses, and several of the components may be mounted on a common motherboard or in other manners as appropriate.
[0081] The processor 752 can execute instructions within the mobile computing device 750, including instructions stored in the memory 764. The processor 752 may be implemented as a chipset of chips that include separate and multiple analog and digital processors. The processor 752 may provide, for example, for coordination of the other components of the mobile computing device 750, such as control of user interfaces, applications run by the mobile computing device 750, and wireless communication by the mobile computing device 750.
[0082] The processor 752 may communicate with a user through a control interface 758 and a display interface 756 coupled to the display 754. The display 754 may be, for example, a TFT (Thin-Film-Transistor Liquid Crystal Display) display or an OLED (Organic Light Emitting Diode) display, or other appropriate display technology. The display interface 756 may comprise appropriate circuitry for driving the display 754 to present graphical and other information to a user. The control interface 758 may receive commands from a user and convert them for submission to the processor 752. In addition, an external interface 762 may provide communication with the processor 752, so as to enable near area communication of the mobile computing device 750 with other devices. The external interface 762 may provide, for example, for wired communication in some implementations, or for wireless communication in other implementations, and multiple interfaces may also be used.
[0083] The memory 764 stores information within the mobile computing device 750. The memory 764 can be implemented as one or more of a computer-readable medium or media, a volatile memory unit or units, or a non-volatile memory unit or units. An expansion memory 774 may also be provided and connected to the mobile computing device 750 through an expansion interface 772, which may include, for example, a SIMM (Single In Line Memory Module) card interface. The expansion memory 774 may provide extra storage space for the mobile computing device 750, or may also store applications or other information for the mobile computing device 750. Specifically, the expansion memory 774 may include instructions to carry out or supplement the processes described above, and may include secure information also. Thus, for example, the expansion memory 774 may be provide as a security module for the mobile computing device 750, and may be programmed with instructions that permit secure use of the mobile computing device 750. In addition, secure applications may be provided via the SIMM cards, along with additional information, such as placing identifying information on the SIMM card in a non-hackable manner.
[0084] The memory may include, for example, flash memory and/or NVRAM memory (non-volatile random access memory), as discussed below. In some implementations, a computer program product is tangibly embodied in an information carrier. The computer program product contains instructions that, when executed, perform one or more methods, such as those described above. The computer program product can be a computer- or machine-readable medium, such as the memory 764, the expansion memory 774, or memory on the processor 752. In some implementations, the computer program product can be received in a propagated signal, for example, over the transceiver 768 or the external interface 762.
[0085] The mobile computing device 750 may communicate wirelessly through the communication interface 766, which may include digital signal processing circuitry where necessary. The communication interface 766 may provide for communications under various modes or protocols, such as GSM voice calls (Global System for Mobile communications), SMS (Short Message Service), EMS (Enhanced Messaging Service), or MMS messaging (Multimedia Messaging Service), CDMA (code division multiple access), TDMA (time division multiple access), PDC (Personal Digital Cellular), WCDMA (Wideband Code Division Multiple Access), CDMA2000, or GPRS (General Packet Radio Service), among others.
Such communication may occur, for example, through the transceiver 768 using a radio-frequency. In addition, short-range communication may occur, such as using a Bluetooth, WiFi, or other such transceiver (not shown). In addition, a GPS (Global Positioning System) receiver module 770 may provide additional navigation- and location-related wireless data to the mobile computing device 750, which may be used as appropriate by applications running on the mobile computing device 750.
[0086] The mobile computing device 750 may also communicate audibly using an audio codec 760, which may receive spoken information from a user and convert it to usable digital information. The audio codec 760 may likewise generate audible sound for a user, such as through a speaker, e.g., in a handset of the mobile computing device 750. Such sound may include sound from voice telephone calls, may include recorded sound (e.g., voice messages, music files, etc.) and may also include sound generated by applications operating on the mobile computing device 750.
[0087] The mobile computing device 750 may be implemented in a number of different forms, as shown in the figure. For example, it may be implemented as a cellular telephone 780. It may also be implemented as part of a smart-phone 782, personal digital assistant, or other similar mobile device.
[0088] Various implementations of the systems and techniques described here can be realized in digital electronic circuitry, integrated circuitry, specially designed ASICs (application specific integrated circuits), computer hardware, firmware, software, and/or combinations thereof. These various implementations can include implementation in one or more computer programs that are executable and/or interpretable on a programmable system including at least one programmable processor, which may be special or general purpose, coupled to receive data and instructions from, and to transmit data and instructions to, a storage system, at least one input device, and at least one output device.
[0089] These computer programs (also known as programs, software, software applications or code) include machine instructions for a programmable processor, and can be implemented in a high-level procedural and/or object-oriented programming language, and/or in assembly/machine language. As used herein, the terms machine-readable medium and computer-readable medium refer to any computer program product, apparatus and/or device (e.g., magnetic discs, optical disks, memory, Programmable Logic Devices (PLDs)) used to provide machine instructions and/or data to a programmable processor, including a machine-readable medium that receives machine instructions as a machine-readable signal. The term machine-readable signal refers to any signal used to provide machine instructions and/or data to a programmable processor.
[0090] To provide for interaction with a user, the systems and techniques described here can be implemented on a computer having a display device (e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor) for displaying information to the user and a keyboard and a pointing device (e.g., a mouse or a trackball) by which the user can provide input to the computer. Other kinds of devices can be used to provide for interaction with a user as well; for example, feedback provided to the user can be any form of sensory feedback (e.g., visual feedback, auditory feedback, or tactile feedback); and input from the user can be received in any form, including acoustic, speech, or tactile input.
[0091] The systems and techniques described here can be implemented in a computing system that includes a back end component (e.g., as a data server), or that includes a middleware component (e.g., an application server), or that includes a front end component (e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the systems and techniques described here), or any combination of such back end, middleware, or front end components. The components of the system can be interconnected by any form or medium of digital data communication (e.g., a communication network). Examples of communication networks include a local area network (LAN), a wide area network (WAN), and the Internet.
[0092] The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other.
[0093] Although a few implementations have been described in detail above, other modifications are possible. For example, the cellular telephone 780 and or smart-phone 782 can include a capacitive or resistive screen for user input and output.
[0094] In addition, the logic flows depicted in the figures do not require the particular order shown, or sequential order, to achieve desirable results. In addition, other steps may be provided, or steps may be eliminated, from the described flows, and other components may be added to, or removed from, the described systems. Accordingly, other implementations are within the scope of the following claims.
Claims (39)
1. A computer-implemented method, comprising: receiving, at a computing device that is in a locked state, one or more user inputs to unlock the computing device and to execute at least one command that is different from a command for unlocking the computing device; executing, in response to the one or more user inputs to unlock the computing device, an unlocking operation by the computing device to convert the computing device from the locked state to an unlocked state; executing the at least one command in response to receiving the one or more user inputs to execute the at least one command; wherein the at least one command executes so that results of executing the at least one command are first displayed on the computing device to a user automatically after the computing device changes from the locked state to the unlocked state, wherein executing the at least one command comprises sending a network request to a server system that is remote from the computing device so as to accelerate availability of content from the server system as soon as the computing device enters the unlocked state; storing results from the server system without displaying the results while the computing device is locked; and displaying the stored results in response to the computing device entering the unlocked state.
2. The method of claim 1, wherein executing the at least one command begins before the one or more user inputs to unlock the computing device are fully received.
3. The method of claim 1, further comprising comparing the one or more user inputs to unlock the computing device to one or more passcodes, and executing the unlocking operation only if the one or more user inputs to unlock the computing device match the one or more passcodes.
4. The method of claim 1, wherein receiving the one or more user inputs to unlock the computing device and to execute the at least one command comprises receiving a touch input on a device touchscreen to unlock the computing device and a spoken input to execute the at least one command.
5. The method of claim 1, wherein receiving the one or more user inputs to unlock the computing device and to execute the at least one command comprises receiving a dragging motion between an icon that corresponds to a function corresponding to the at least one command, and an icon that corresponds to an unlocking function for the computing device.
6. A computer program product, encoded on a non-transitory computer-readable medium, operable to cause one or more processors to perform operations, comprising: receiving, at a computing device that is in a locked state, one or more user inputs to unlock the computing device and to execute at least one command that is different from a command for unlocking the computing device; executing, in response to the one or more user inputs to unlock the computing device, an unlocking operation by the computing device to convert the computing device from a locked state to an unlocked state; executing the at least one command in response to receiving the one or more user inputs to execute the at least one command; wherein the at least one command executes so that results of executing the at least one command are first displayed on the computing device to a user automatically after the computing device changes from the locked state to the unlocked state, wherein executing the at least one command comprises sending a network request to a server system that is remote from the computing device so as to accelerate availability of content from the server system as soon as the computing device enters the unlocked state; storing results from the server system without displaying the results while the computing device is locked; and displaying the stored results in response to the computing device entering the unlocked state.
7. A computer-implemented system, comprising: a computing device comprising: a user interface that receives, while the computing device is in a locked state, one or more user inputs to unlock the computing device and to execute at least one command that is different from a command for unlocking the computing device; a processor that executes, in response to the one or more user inputs to unlock the computing device, an unlocking operation to convert the computing device from a locked state to an unlocked state, and that executes the at least one command in response to receiving the one or more user inputs to execute the at least one command; a display device that first displays results of executing the at least one command on the computing device to a user automatically after the computing device changes from the locked state to the unlocked state; a microphone that receives audio, wherein executing the at least one command includes processing the received audio, wherein processing the received audio includes sending the received audio to a server system and receiving the results from the server system; and a memory that stores the results received from the server system without displaying the results while the computing device is locked, and wherein the computing device displays the stored results in response to the computing device entering the unlocked state.
8. A computer-implemented method, comprising: receiving, by a computing device that is in a locked state, one or more user inputs to execute at least one command and execute an unlocking operation, execution of the at least one command being different from execution of the unlocking operation; executing, by the computing device and in response to at least some of the one or more user inputs, the at least one command by sending a network request to a server system while the computing device is in the locked state; receiving, by the computing device and as having been sent by the server system, information that identifies a result of the network request, and storing the information in computer memory without the computing device presenting the result while the computing device is in the locked state; executing, by the computing device and in response to at least some of the one or more user inputs, the unlocking operation so as to convert the computing device from the locked state to an unlocked state; and presenting, by the computing device and in response to the one or more user inputs, the result in response to the computing device entering the unlocked state.
9. The computer-implemented method of claim 8, wherein the one or more user inputs is a single user input that initiates the executing of the at least one command and the executing of the unlocking operation.
10. The computer-implemented method of claim 8, wherein the one or more user inputs include a first one or more user inputs to execute the at least one command and a second one or more user inputs to enter a correct password, passcode, or unlock pattern that causes execution of the unlocking operation, wherein the information is received by the computing device and as having been sent by the server system after receiving the first one or more user inputs but before completion of the second one or more user inputs.
11. The computer-implemented method of claim 8, wherein the computing device is configured to receive a different one or more user inputs while in the locked state that causes the computing device to execute the unlocking operation without executing the one or more commands.
12. The computer-implemented method of claim 8, wherein receiving the one or more user inputs includes identifying contact with a touchscreen of the computing device that moves a display of an icon across the touchscreen.
13. The computer-implemented method of claim 8, wherein: the at least one command includes a command to activate an email application program for display by the computing device; and the network request includes a request to retrieve email messages.
14. The computer-implemented method of claim 8, further comprising converting the computing device from the unlocked state to the locked state in response to user selection of a power button or passage of a predetermined period of user inactivity with the computing device.
15. The computer-implemented method of claim 8, wherein the network request is sent over the internet.
16. The computer-implemented method of claim 8, wherein: the one or more user inputs include a voice command; and the network request includes a recording of the voice command.
17. The computer-implemented method of claim 16, wherein the received information includes a text transcription of at least part of the recording.
18. The computer-implemented method of claim 17, wherein the voice command includes a request for a map, and the result that is presented includes a display of the map that was requested.
19. The computer-implemented method of claim 17, wherein the voice command includes a request for weather information, and the result that was presented includes a display of the weather information that was requested.
20. The computer-implemented method of claim 17, wherein the voice command includes a search query, and the request that was presented includes a display of multiple search results.
21. The computer-implemented method of claim 17, wherein receiving the one or more user inputs includes receiving user input of a password, a passcode, or an unlock pattern while the computing device waits for the text transcription as a response to the network request.
22. The computer-implemented method of claim 21, wherein the voice command is recorded with a microphone of the computing device and the user input of the password, the passcode, or the unlock pattern is received with a keyboard of the computing device.
23. The computer-implemented method of claim 21, wherein the computing device is configured to only execute the unlocking operation as a result of a determination that the password, the passcode, or the unlock pattern that was user input matches a correct password, a correct passcode, or a correct unlock pattern for which the computing device authorizes performance of the unlocking operation.
24. A computer program product, encoded on a non-transitory computer-readable medium, operable to cause one or more processors to perform operations, comprising: receiving, by a computing device that is in a locked state, one or more user inputs to execute at least one command and execute an unlocking operation, execution of the at least one command being different from execution of the unlocking operation; executing, by the computing device and in response to at least some of the one or more user inputs, the at least one command by sending a network request to a server system while the computing device is in the locked state; receiving, by the computing device and as having been sent by the server system, information that identifies a result of the network request, and storing the information in computer memory without the computing device presenting the result while the computing device is in the locked state; executing, by the computing device and in response to at least some of the one or more user inputs, the unlocking operation so as to convert the computing device from the locked state to an unlocked state; and presenting, by the computing device and in response to the one or more user inputs, the result in response to the computing device entering the unlocked state.
25. The computer program product of claim 24, wherein the one or more user inputs is a single user input that initiates the executing of the at least one command and the executing of the unlocking operation.
26. The computer program product of claim 24, wherein the one or more user inputs include a first one or more user inputs to execute the at least one command and a second one or more user inputs to enter a correct password, passcode, or unlock pattern that causes execution of the unlocking operation, wherein the information is received by the computing device and as having been sent by the server system after receiving the first one or more user inputs but before completion of the second one or more user inputs.
27. The computer program product of claim 24, wherein the computing device is configured to receive a different one or more user inputs while in the locked state that causes the computing device to execute the unlocking operation without executing the one or more commands.
28. The computer program product of claim 24, wherein receiving the one or more user inputs includes identifying contact with a touchscreen of the computing device that moves a display of an icon across the touchscreen.
29. The computer program product of claim 24, wherein: the at least one command includes a command to activate an email application program for display by the computing device; and the network request includes a request to retrieve email messages.
30. The computer program product of claim 24, wherein the operations further comprise converting the computing device from the unlocked state to the locked state in response to user selection of a power button or passage of a predetermined period of user inactivity with the computing device.
31. The computer program product of claim 24, wherein the network request is sent over the internet.
32. The computer program product of claim 24, wherein: the one or more user inputs include a voice command; and the network request includes a recording of the voice command.
33. The computer program product of claim 32, wherein the received information includes a text transcription of at least part of the recording.
34. The computer program product of claim 33, wherein the voice command includes a request for a map, and the result that is presented includes a display of the map that was requested.
35. The computer program product of claim 33, wherein the voice command includes a request for weather information, and the result that was presented includes a display of the weather information that was requested.
36. The computer program product of claim 33, wherein the voice command includes a search query, and the request that was presented includes a display of multiple search results.
37. The computer program product of claim 33, wherein receiving the one or more user inputs includes receiving user input of a password, a passcode, or an unlock pattern while the computing device waits for the text transcription as a response to the network request.
38. The computer program product of claim 37, wherein the voice command is recorded with a microphone of the computing device and the user input of the password, the passcode, or the unlock pattern is received with a keyboard of the computing device.
39. The computer program product of claim 37, wherein the computing device is configured to only execute the unlocking operation as a result of a determination that the password, the passcode, or the unlock pattern that was user input matches a correct password, a correct passcode, or a correct unlock pattern for which the computing device authorizes performance of the unlocking operation.
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
AU2013200503A AU2013200503B2 (en) | 2010-08-06 | 2013-01-31 | Input to locked computing device |
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US12/851,739 US8402533B2 (en) | 2010-08-06 | 2010-08-06 | Input to locked computing device |
US12/851,739 | 2010-08-06 | ||
PCT/US2011/045928 WO2012018689A1 (en) | 2010-08-06 | 2011-07-29 | Input to locked computing device |
Related Child Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
AU2013200503A Division AU2013200503B2 (en) | 2010-08-06 | 2013-01-31 | Input to locked computing device |
Publications (2)
Publication Number | Publication Date |
---|---|
AU2011286026A1 AU2011286026A1 (en) | 2013-02-21 |
AU2011286026B2 true AU2011286026B2 (en) | 2016-08-25 |
Family
ID=45557065
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
AU2011286026A Active AU2011286026B2 (en) | 2010-08-06 | 2011-07-29 | Input to locked computing device |
Country Status (7)
Country | Link |
---|---|
US (6) | US8402533B2 (en) |
EP (2) | EP2601571B1 (en) |
KR (2) | KR101838971B1 (en) |
AU (1) | AU2011286026B2 (en) |
DE (1) | DE112011102650T5 (en) |
GB (2) | GB2497231B (en) |
WO (1) | WO2012018689A1 (en) |
Families Citing this family (369)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8645137B2 (en) | 2000-03-16 | 2014-02-04 | Apple Inc. | Fast, language-independent method for user authentication by voice |
US8677377B2 (en) | 2005-09-08 | 2014-03-18 | Apple Inc. | Method and apparatus for building an intelligent automated assistant |
US9318108B2 (en) | 2010-01-18 | 2016-04-19 | Apple Inc. | Intelligent automated assistant |
US8977255B2 (en) | 2007-04-03 | 2015-03-10 | Apple Inc. | Method and system for operating a multi-function portable electronic device using voice-activation |
US8127254B2 (en) | 2007-06-29 | 2012-02-28 | Nokia Corporation | Unlocking a touch screen device |
DE102008051756A1 (en) * | 2007-11-12 | 2009-05-14 | Volkswagen Ag | Multimodal user interface of a driver assistance system for entering and presenting information |
US10002189B2 (en) | 2007-12-20 | 2018-06-19 | Apple Inc. | Method and apparatus for searching using an active ontology |
US9330720B2 (en) | 2008-01-03 | 2016-05-03 | Apple Inc. | Methods and apparatus for altering audio output signals |
US8996376B2 (en) | 2008-04-05 | 2015-03-31 | Apple Inc. | Intelligent text-to-speech conversion |
US10496753B2 (en) | 2010-01-18 | 2019-12-03 | Apple Inc. | Automatically adapting user interfaces for hands-free interaction |
US9082117B2 (en) | 2008-05-17 | 2015-07-14 | David H. Chin | Gesture based authentication for wireless payment by a mobile electronic device |
US9024890B2 (en) * | 2008-05-17 | 2015-05-05 | David H. Chin | Comparison of an applied gesture on a touch screen of a mobile device with a remotely stored security gesture |
US20100030549A1 (en) | 2008-07-31 | 2010-02-04 | Lee Michael M | Mobile device having human language translation capability with positional feedback |
US8676904B2 (en) | 2008-10-02 | 2014-03-18 | Apple Inc. | Electronic devices with voice command and contextual data processing capabilities |
US9858925B2 (en) | 2009-06-05 | 2018-01-02 | Apple Inc. | Using context information to facilitate processing of commands in a virtual assistant |
US10241644B2 (en) | 2011-06-03 | 2019-03-26 | Apple Inc. | Actionable reminder entries |
US10241752B2 (en) | 2011-09-30 | 2019-03-26 | Apple Inc. | Interface for a virtual digital assistant |
US10706373B2 (en) | 2011-06-03 | 2020-07-07 | Apple Inc. | Performing actions associated with task items that represent tasks to perform |
US9431006B2 (en) | 2009-07-02 | 2016-08-30 | Apple Inc. | Methods and apparatuses for automatic speech recognition |
US20120256959A1 (en) * | 2009-12-30 | 2012-10-11 | Cywee Group Limited | Method of controlling mobile device with touch-sensitive display and motion sensor, and mobile device |
US10276170B2 (en) | 2010-01-18 | 2019-04-30 | Apple Inc. | Intelligent automated assistant |
US10705794B2 (en) | 2010-01-18 | 2020-07-07 | Apple Inc. | Automatically adapting user interfaces for hands-free interaction |
US10553209B2 (en) | 2010-01-18 | 2020-02-04 | Apple Inc. | Systems and methods for hands-free notification summaries |
US10679605B2 (en) | 2010-01-18 | 2020-06-09 | Apple Inc. | Hands-free list-reading by intelligent automated assistant |
US8682667B2 (en) | 2010-02-25 | 2014-03-25 | Apple Inc. | User profiling for selecting user specific voice input processing information |
US8402533B2 (en) | 2010-08-06 | 2013-03-19 | Google Inc. | Input to locked computing device |
US8854318B2 (en) | 2010-09-01 | 2014-10-07 | Nokia Corporation | Mode switching |
US20120060123A1 (en) * | 2010-09-03 | 2012-03-08 | Hugh Smith | Systems and methods for deterministic control of instant-on mobile devices with touch screens |
US20190158535A1 (en) * | 2017-11-21 | 2019-05-23 | Biocatch Ltd. | Device, System, and Method of Detecting Vishing Attacks |
US10069837B2 (en) | 2015-07-09 | 2018-09-04 | Biocatch Ltd. | Detection of proxy server |
US11210674B2 (en) | 2010-11-29 | 2021-12-28 | Biocatch Ltd. | Method, device, and system of detecting mule accounts and accounts used for money laundering |
US20120133484A1 (en) * | 2010-11-29 | 2012-05-31 | Research In Motion Limited | Multiple-input device lock and unlock |
US10834590B2 (en) | 2010-11-29 | 2020-11-10 | Biocatch Ltd. | Method, device, and system of differentiating between a cyber-attacker and a legitimate user |
US11223619B2 (en) * | 2010-11-29 | 2022-01-11 | Biocatch Ltd. | Device, system, and method of user authentication based on user-specific characteristics of task performance |
US10917431B2 (en) | 2010-11-29 | 2021-02-09 | Biocatch Ltd. | System, method, and device of authenticating a user based on selfie image or selfie video |
KR101740436B1 (en) * | 2010-12-08 | 2017-05-26 | 엘지전자 주식회사 | Mobile terminal and method for controlling thereof |
KR20120067445A (en) * | 2010-12-16 | 2012-06-26 | 엘지전자 주식회사 | Mobile terminal and operation control method thereof |
US10620794B2 (en) * | 2010-12-23 | 2020-04-14 | Apple Inc. | Device, method, and graphical user interface for switching between two user interfaces |
TW201227393A (en) * | 2010-12-31 | 2012-07-01 | Acer Inc | Method for unlocking screen and executing application program |
TWI546700B (en) * | 2011-01-13 | 2016-08-21 | 宏達國際電子股份有限公司 | Portable electronic device, and control method and computer program product of the same |
GB201101135D0 (en) * | 2011-01-21 | 2011-03-09 | Inq Entpr Ltd | Electronic device and method with efficient data capture |
JP5651494B2 (en) | 2011-02-09 | 2015-01-14 | 日立マクセル株式会社 | Information processing device |
CN102087585A (en) * | 2011-02-12 | 2011-06-08 | 华为终端有限公司 | Touch screen terminal and unlocking method thereof |
US10146415B2 (en) * | 2011-03-02 | 2018-12-04 | Lenovo (Beijing) Limited | Method and terminal device for controlling a terminal device in a locked and unlocked state |
JP5693305B2 (en) * | 2011-03-11 | 2015-04-01 | 京セラ株式会社 | Mobile terminal device |
US9262612B2 (en) | 2011-03-21 | 2016-02-16 | Apple Inc. | Device access using voice authentication |
JP6089384B2 (en) * | 2011-04-11 | 2017-03-08 | ソニー株式会社 | Information processing apparatus, information processing method, and program |
US9122862B2 (en) * | 2011-04-13 | 2015-09-01 | Lenovo (Singapore) Pte. Ltd. | Password input method using visual object |
US9606643B2 (en) * | 2011-05-02 | 2017-03-28 | Microsoft Technology Licensing, Llc | Extended above the lock-screen experience |
US10222974B2 (en) * | 2011-05-03 | 2019-03-05 | Nokia Technologies Oy | Method and apparatus for providing quick access to device functionality |
US20160132119A1 (en) * | 2014-11-12 | 2016-05-12 | Will John Temple | Multidirectional button, key, and keyboard |
US10275153B2 (en) * | 2011-05-19 | 2019-04-30 | Will John Temple | Multidirectional button, key, and keyboard |
US10057736B2 (en) | 2011-06-03 | 2018-08-21 | Apple Inc. | Active transport based notifications |
KR20130008424A (en) * | 2011-07-12 | 2013-01-22 | 삼성전자주식회사 | Apparatus and method for executing a shortcut function in a portable terminal |
US9417754B2 (en) | 2011-08-05 | 2016-08-16 | P4tents1, LLC | User interface system, method, and computer program product |
US8994660B2 (en) | 2011-08-29 | 2015-03-31 | Apple Inc. | Text correction processing |
KR20130027774A (en) * | 2011-09-08 | 2013-03-18 | 삼성전자주식회사 | Method and apparatus for providing user interface to control lock state |
KR101563150B1 (en) * | 2011-09-09 | 2015-10-28 | 주식회사 팬택 | Method for providing shortcut in lock screen and portable device employing the same |
US9002322B2 (en) | 2011-09-29 | 2015-04-07 | Apple Inc. | Authentication with secondary approver |
US8769624B2 (en) | 2011-09-29 | 2014-07-01 | Apple Inc. | Access control utilizing indirect authentication |
KR101853856B1 (en) * | 2011-10-04 | 2018-05-04 | 엘지전자 주식회사 | Mobile terminal and control method for the same |
US9830049B2 (en) | 2011-12-12 | 2017-11-28 | Nokia Technologies Oy | Apparatus and method for providing a visual transition between screens |
US20140012677A1 (en) * | 2011-12-21 | 2014-01-09 | Paul F. Wagner | Mobile Device Application for Dynamic Delivery of Advertising-Based Content |
US8806383B2 (en) * | 2012-02-06 | 2014-08-12 | Motorola Mobility Llc | Initiation of actions by a portable computing device from a locked state |
US10134385B2 (en) | 2012-03-02 | 2018-11-20 | Apple Inc. | Systems and methods for name pronunciation |
US9483461B2 (en) | 2012-03-06 | 2016-11-01 | Apple Inc. | Handling speech synthesis of content for multiple languages |
WO2013133007A1 (en) * | 2012-03-06 | 2013-09-12 | Ｎｅｃカシオモバイルコミュニケーションズ株式会社 | Information processing device, information processing method, and information processing program |
TWI545495B (en) * | 2012-03-07 | 2016-08-11 | 群邁通訊股份有限公司 | System and method for operating touch screens |
US8504842B1 (en) | 2012-03-23 | 2013-08-06 | Google Inc. | Alternative unlocking patterns |
CN103365578B (en) * | 2012-03-29 | 2016-12-14 | 百度在线网络技术（北京）有限公司 | The unlocking method of a kind of mobile terminal and mobile terminal |
CN102646047B (en) * | 2012-04-20 | 2016-03-30 | 华为终端有限公司 | A kind ofly start the method for application program and there is the terminal device of touch display screen |
KR101413286B1 (en) * | 2012-05-02 | 2014-07-01 | 주식회사 팬택 | Electronic device and apparatus and method for unlocking the electronic device |
WO2013169865A2 (en) | 2012-05-09 | 2013-11-14 | Yknots Industries Llc | Device, method, and graphical user interface for moving a user interface object based on an intensity of a press input |
WO2013169845A1 (en) | 2012-05-09 | 2013-11-14 | Yknots Industries Llc | Device, method, and graphical user interface for scrolling nested regions |
JP6182207B2 (en) | 2012-05-09 | 2017-08-16 | アップル インコーポレイテッド | Device, method, and graphical user interface for providing feedback for changing an activation state of a user interface object |
WO2013169849A2 (en) | 2012-05-09 | 2013-11-14 | Industries Llc Yknots | Device, method, and graphical user interface for displaying user interface objects corresponding to an application |
EP3264252B1 (en) | 2012-05-09 | 2019-11-27 | Apple Inc. | Device, method, and graphical user interface for performing an operation in accordance with a selected mode of operation |
WO2013169843A1 (en) | 2012-05-09 | 2013-11-14 | Yknots Industries Llc | Device, method, and graphical user interface for manipulating framed graphical objects |
JP6002836B2 (en) | 2012-05-09 | 2016-10-05 | アップル インコーポレイテッド | Device, method, and graphical user interface for transitioning between display states in response to a gesture |
WO2013169875A2 (en) | 2012-05-09 | 2013-11-14 | Yknots Industries Llc | Device, method, and graphical user interface for displaying content associated with a corresponding affordance |
WO2013169842A2 (en) | 2012-05-09 | 2013-11-14 | Yknots Industries Llc | Device, method, and graphical user interface for selecting object within a group of objects |
WO2013169851A2 (en) | 2012-05-09 | 2013-11-14 | Yknots Industries Llc | Device, method, and graphical user interface for facilitating user interaction with controls in a user interface |
WO2013169853A1 (en) | 2012-05-09 | 2013-11-14 | Industries Llc Yknots | Device, method, and graphical user interface for providing tactile feedback for operations performed in a user interface |
CN105260049B (en) | 2012-05-09 | 2018-10-23 | 苹果公司 | For contacting the equipment for carrying out display additional information, method and graphic user interface in response to user |
CN106201316B (en) | 2012-05-09 | 2020-09-29 | 苹果公司 | Apparatus, method and graphical user interface for selecting user interface objects |
US9280610B2 (en) | 2012-05-14 | 2016-03-08 | Apple Inc. | Crowd sourcing information to fulfill user requests |
US10417037B2 (en) | 2012-05-15 | 2019-09-17 | Apple Inc. | Systems and methods for integrating third party services with a digital assistant |
WO2013170383A1 (en) | 2012-05-16 | 2013-11-21 | Xtreme Interactions Inc. | System, device and method for processing interlaced multimodal user input |
US8339377B1 (en) | 2012-05-18 | 2012-12-25 | Google Inc. | Method and apparatus for LED transition from physical to virtual space |
KR20130133629A (en) * | 2012-05-29 | 2013-12-09 | 삼성전자주식회사 | Method and apparatus for executing voice command in electronic device |
US20130321400A1 (en) | 2012-06-05 | 2013-12-05 | Apple Inc. | 3D Map Views for 3D Maps |
US10176633B2 (en) | 2012-06-05 | 2019-01-08 | Apple Inc. | Integrated mapping and navigation application |
US9052197B2 (en) | 2012-06-05 | 2015-06-09 | Apple Inc. | Providing navigation instructions while device is in locked mode |
US9997069B2 (en) | 2012-06-05 | 2018-06-12 | Apple Inc. | Context-aware voice guidance |
US9482296B2 (en) | 2012-06-05 | 2016-11-01 | Apple Inc. | Rendering road signs during navigation |
US9418672B2 (en) | 2012-06-05 | 2016-08-16 | Apple Inc. | Navigation application with adaptive instruction text |
US9886794B2 (en) | 2012-06-05 | 2018-02-06 | Apple Inc. | Problem reporting in maps |
US9230556B2 (en) * | 2012-06-05 | 2016-01-05 | Apple Inc. | Voice instructions during navigation |
US9721563B2 (en) | 2012-06-08 | 2017-08-01 | Apple Inc. | Name recognition system |
CN102750093B (en) * | 2012-06-11 | 2016-03-30 | 惠州Tcl移动通信有限公司 | A kind of method of unlocking screen, system and touch screen terminal |
US9495129B2 (en) | 2012-06-29 | 2016-11-15 | Apple Inc. | Device, method, and user interface for voice-activated navigation and browsing of a document |
CN102819387A (en) * | 2012-07-02 | 2012-12-12 | 北京小米科技有限责任公司 | Terminal unlocking method and device |
CN103544426A (en) * | 2012-07-13 | 2014-01-29 | 深圳市腾讯计算机系统有限公司 | Method and device for authentication of touch screen and equipment |
US9607313B2 (en) * | 2012-08-13 | 2017-03-28 | Blackberry Limited | Targeted content streaming banners |
KR101705472B1 (en) * | 2012-08-29 | 2017-02-09 | 알까뗄 루슨트 | Pluggable authentication mechanism for mobile device applications |
US9047651B2 (en) * | 2012-09-14 | 2015-06-02 | Location Labs, Inc. | Contact management system |
US9547647B2 (en) | 2012-09-19 | 2017-01-17 | Apple Inc. | Voice-based media searching |
CN102929525B (en) * | 2012-09-24 | 2016-03-30 | 惠州Tcl移动通信有限公司 | Unlocking screen unit and screen unlock method thereof and mobile communication equipment |
CN102902464B (en) * | 2012-09-25 | 2015-08-05 | 百度在线网络技术（北京）有限公司 | A kind of unlock method of mobile terminal and device |
CN102929480A (en) * | 2012-09-28 | 2013-02-13 | 百度在线网络技术（北京）有限公司 | Method and device for unlocking mobile terminal |
KR20140042280A (en) * | 2012-09-28 | 2014-04-07 | 엘지전자 주식회사 | Portable device and controlling method thereof |
KR20140051487A (en) * | 2012-10-08 | 2014-05-02 | 삼성전자주식회사 | Device and method for protecting data in terminal |
WO2014060129A1 (en) | 2012-10-19 | 2014-04-24 | Telefonica Digital España, S.L.U. | Method and device for improved electronic device unlocking |
WO2014060128A1 (en) | 2012-10-19 | 2014-04-24 | Telefonica Digital España, S.L.U. | Method and device for improved unlocking of an electronic device |
CN103777879A (en) * | 2012-10-22 | 2014-05-07 | 纬创资通股份有限公司 | Electronic device and method for removing lock status of screen |
US9632574B2 (en) * | 2012-10-31 | 2017-04-25 | Sony Corporation | Device and method for authenticating a user |
CN104798077A (en) * | 2012-11-22 | 2015-07-22 | Nec卡西欧移动通信株式会社 | Electronic device, unlocking method, and program |
WO2014089763A1 (en) * | 2012-12-12 | 2014-06-19 | Intel Corporation | Single- gesture device unlock and application launch |
JP6314834B2 (en) * | 2012-12-14 | 2018-04-25 | 日本電気株式会社 | Information terminal device, information terminal control method, and program |
KR102001332B1 (en) | 2012-12-29 | 2019-07-17 | 애플 인크. | Device, method, and graphical user interface for determining whether to scroll or select contents |
WO2014105275A1 (en) | 2012-12-29 | 2014-07-03 | Yknots Industries Llc | Device, method, and graphical user interface for forgoing generation of tactile output for a multi-contact gesture |
KR102000253B1 (en) | 2012-12-29 | 2019-07-16 | 애플 인크. | Device, method, and graphical user interface for navigating user interface hierachies |
WO2014105279A1 (en) | 2012-12-29 | 2014-07-03 | Yknots Industries Llc | Device, method, and graphical user interface for switching between user interfaces |
EP3435220B1 (en) | 2012-12-29 | 2020-09-16 | Apple Inc. | Device, method and graphical user interface for transitioning between touch input to display output relationships |
US20140189855A1 (en) * | 2012-12-31 | 2014-07-03 | Conduit, Ltd. | Gestures for Unlocking a Mobile Device |
GB201300031D0 (en) | 2013-01-02 | 2013-02-13 | Canonical Ltd | Ubuntu UX innovations |
US20140195979A1 (en) * | 2013-01-10 | 2014-07-10 | Appsense Limited | Interactive user interface |
US9135427B2 (en) | 2013-01-30 | 2015-09-15 | Arris Technology, Inc. | Authentication using a subset of a user-known code sequence |
CN104969289B (en) | 2013-02-07 | 2021-05-28 | 苹果公司 | Voice trigger of digital assistant |
CN104020946B (en) * | 2013-02-28 | 2018-06-12 | 富泰华工业（深圳）有限公司 | Unlocking system and method |
US10652394B2 (en) | 2013-03-14 | 2020-05-12 | Apple Inc. | System and method for processing voicemail |
WO2014143776A2 (en) | 2013-03-15 | 2014-09-18 | Bodhi Technology Ventures Llc | Providing remote interactions with host device using a wireless device |
US10748529B1 (en) | 2013-03-15 | 2020-08-18 | Apple Inc. | Voice activated device for use with a voice-based digital assistant |
US9336779B1 (en) * | 2013-04-10 | 2016-05-10 | Google Inc. | Dynamic image-based voice entry of unlock sequence |
CN104111788A (en) * | 2013-04-19 | 2014-10-22 | 联想(北京)有限公司 | Unlocking method and electronic equipment |
CN108108147A (en) * | 2013-05-07 | 2018-06-01 | 北京三星通信技术研究有限公司 | The unlocking method and terminal of a kind of terminal |
US9199609B2 (en) * | 2013-05-16 | 2015-12-01 | GM Global Technology Operations LLC | Start system for a motor vehicle |
KR102124476B1 (en) * | 2013-06-03 | 2020-06-19 | 엘지전자 주식회사 | Mobile terminal and method for controlling the same |
WO2014197336A1 (en) | 2013-06-07 | 2014-12-11 | Apple Inc. | System and method for detecting errors in interactions with a voice-based digital assistant |
WO2014197334A2 (en) | 2013-06-07 | 2014-12-11 | Apple Inc. | System and method for user-specified pronunciation of words for speech synthesis and recognition |
US9582608B2 (en) | 2013-06-07 | 2017-02-28 | Apple Inc. | Unified ranking with entropy-weighted information for phrase-based semantic auto-completion |
KR20140143599A (en) * | 2013-06-07 | 2014-12-17 | 주식회사 엘지씨엔에스 | Method and apparatus for unlocking a locking mode of terminal |
WO2014197335A1 (en) | 2013-06-08 | 2014-12-11 | Apple Inc. | Interpreting and acting upon commands that involve sharing information with remote devices |
US10176167B2 (en) | 2013-06-09 | 2019-01-08 | Apple Inc. | System and method for inferring user intent from speech inputs |
KR101959188B1 (en) | 2013-06-09 | 2019-07-02 | 애플 인크. | Device, method, and graphical user interface for enabling conversation persistence across two or more instances of a digital assistant |
US10025378B2 (en) * | 2013-06-25 | 2018-07-17 | Microsoft Technology Licensing, Llc | Selecting user interface elements via position signal |
US8938612B1 (en) | 2013-07-31 | 2015-01-20 | Google Inc. | Limited-access state for inadvertent inputs |
US9898642B2 (en) | 2013-09-09 | 2018-02-20 | Apple Inc. | Device, method, and graphical user interface for manipulating user interfaces based on fingerprint sensor inputs |
KR20150031010A (en) * | 2013-09-13 | 2015-03-23 | 삼성전자주식회사 | Apparatus and method for providing lock screen |
CN103685231B (en) * | 2013-11-06 | 2018-05-01 | 百度在线网络技术（北京）有限公司 | Location-based operation demonstration method and server, client |
US9111076B2 (en) | 2013-11-20 | 2015-08-18 | Lg Electronics Inc. | Mobile terminal and control method thereof |
US10296160B2 (en) | 2013-12-06 | 2019-05-21 | Apple Inc. | Method for extracting salient dialog usage from live data |
US10339288B2 (en) * | 2013-12-12 | 2019-07-02 | Mcafee, Llc | User authentication for mobile devices using behavioral analysis |
US9449165B2 (en) | 2014-02-06 | 2016-09-20 | Untethered Labs, Inc. | System and method for wireless proximity-based access to a computing device |
CN108469937B (en) * | 2014-03-26 | 2020-11-20 | 联想(北京)有限公司 | Information processing method and electronic equipment |
US20170094065A1 (en) * | 2014-04-18 | 2017-03-30 | Huawei Technologies Co., Ltd. | Information reminding method and apparatus, and electronic terminal |
WO2015178715A1 (en) * | 2014-05-23 | 2015-11-26 | Samsung Electronics Co., Ltd. | System and method of providing voice-message call service |
US9324067B2 (en) | 2014-05-29 | 2016-04-26 | Apple Inc. | User interface for payments |
US9966065B2 (en) | 2014-05-30 | 2018-05-08 | Apple Inc. | Multi-command single utterance input method |
JP6328797B2 (en) | 2014-05-30 | 2018-05-23 | アップル インコーポレイテッド | Transition from using one device to using another device |
US10170123B2 (en) | 2014-05-30 | 2019-01-01 | Apple Inc. | Intelligent assistant for home automation |
US9760559B2 (en) | 2014-05-30 | 2017-09-12 | Apple Inc. | Predictive text input |
US10078631B2 (en) | 2014-05-30 | 2018-09-18 | Apple Inc. | Entropy-guided text prediction using combined word and character n-gram language models |
US9842101B2 (en) | 2014-05-30 | 2017-12-12 | Apple Inc. | Predictive conversion of language input |
US9785630B2 (en) | 2014-05-30 | 2017-10-10 | Apple Inc. | Text prediction using combined word N-gram and unigram language models |
US9967401B2 (en) | 2014-05-30 | 2018-05-08 | Apple Inc. | User interface for phone call routing among devices |
US9633004B2 (en) | 2014-05-30 | 2017-04-25 | Apple Inc. | Better resolution when referencing to concepts |
US9430463B2 (en) | 2014-05-30 | 2016-08-30 | Apple Inc. | Exemplar-based natural language processing |
US9715875B2 (en) | 2014-05-30 | 2017-07-25 | Apple Inc. | Reducing the need for manual start/end-pointing and trigger phrases |
US10423769B2 (en) | 2014-06-12 | 2019-09-24 | Maxell, Ltd. | Information processing device, application software start-up system, and application software start-up method |
WO2015193545A1 (en) * | 2014-06-18 | 2015-12-23 | Lss-Long Special Services Ltd Oy | Techniques for exception calls from a mobile terminal |
US20160378967A1 (en) * | 2014-06-25 | 2016-12-29 | Chian Chiu Li | System and Method for Accessing Application Program |
US9338493B2 (en) | 2014-06-30 | 2016-05-10 | Apple Inc. | Intelligent automated assistant for TV user interactions |
US10659851B2 (en) | 2014-06-30 | 2020-05-19 | Apple Inc. | Real-time digital assistant knowledge updates |
WO2016022318A1 (en) * | 2014-08-04 | 2016-02-11 | Hafeman Carolyn W | Communication apparatus, system and method |
US10339293B2 (en) * | 2014-08-15 | 2019-07-02 | Apple Inc. | Authenticated device used to unlock another device |
US9461946B2 (en) * | 2014-08-18 | 2016-10-04 | Stephen B. Zutphen | Synchronized single-action graphical user interfaces for assisting an individual to uniformly manage computer-implemented activities utilizing distinct software and distinct types of electronic data, and computer-implemented methods and computer-based systems utilizing such synchronized single-action graphical user interfaces |
US10446141B2 (en) | 2014-08-28 | 2019-10-15 | Apple Inc. | Automatic speech recognition based on user feedback |
USD766267S1 (en) * | 2014-09-02 | 2016-09-13 | Samsung Electronics Co., Ltd. | Display screen or portion thereof with graphical user interface |
USD763871S1 (en) * | 2014-09-02 | 2016-08-16 | Samsung Electronics Co., Ltd. | Display screen of portion thereof with transitional graphical user interface |
US10066959B2 (en) | 2014-09-02 | 2018-09-04 | Apple Inc. | User interactions for a mapping application |
WO2016036603A1 (en) | 2014-09-02 | 2016-03-10 | Apple Inc. | Reduced size configuration interface |
US9818400B2 (en) | 2014-09-11 | 2017-11-14 | Apple Inc. | Method and apparatus for discovering trending terms in speech requests |
US10789041B2 (en) | 2014-09-12 | 2020-09-29 | Apple Inc. | Dynamic thresholds for always listening speech trigger |
US10127911B2 (en) | 2014-09-30 | 2018-11-13 | Apple Inc. | Speaker identification and unsupervised speaker adaptation techniques |
US9886432B2 (en) | 2014-09-30 | 2018-02-06 | Apple Inc. | Parsimonious handling of word inflection via categorical stem + suffix N-gram language models |
US9668121B2 (en) | 2014-09-30 | 2017-05-30 | Apple Inc. | Social reminders |
US10074360B2 (en) | 2014-09-30 | 2018-09-11 | Apple Inc. | Providing an indication of the suitability of speech recognition |
US9646609B2 (en) | 2014-09-30 | 2017-05-09 | Apple Inc. | Caching apparatus for serving phonetic pronunciations |
USD763884S1 (en) * | 2014-10-02 | 2016-08-16 | Samsung Electronics Co., Ltd. | Display screen or portion thereof with graphical user interface |
US20160103987A1 (en) * | 2014-10-14 | 2016-04-14 | Hong Fu Jin Precision Industry (Wuhan) Co., Ltd. | Electronic device and an unlocking password setting method |
US10552013B2 (en) | 2014-12-02 | 2020-02-04 | Apple Inc. | Data detection |
KR102307349B1 (en) * | 2014-12-03 | 2021-09-30 | 삼성전자주식회사 | Apparatus and method for search |
US20160196419A1 (en) * | 2015-01-06 | 2016-07-07 | Google Inc. | Multi-action lock screen |
US9574896B2 (en) | 2015-02-13 | 2017-02-21 | Apple Inc. | Navigation user interface |
US9865280B2 (en) | 2015-03-06 | 2018-01-09 | Apple Inc. | Structured dictation using intelligent automated assistants |
US10152299B2 (en) | 2015-03-06 | 2018-12-11 | Apple Inc. | Reducing response latency of intelligent automated assistants |
US9886953B2 (en) | 2015-03-08 | 2018-02-06 | Apple Inc. | Virtual assistant activation |
US9721566B2 (en) | 2015-03-08 | 2017-08-01 | Apple Inc. | Competing devices responding to voice triggers |
US10567477B2 (en) | 2015-03-08 | 2020-02-18 | Apple Inc. | Virtual assistant continuity |
US9645732B2 (en) | 2015-03-08 | 2017-05-09 | Apple Inc. | Devices, methods, and graphical user interfaces for displaying and using menus |
US9990107B2 (en) | 2015-03-08 | 2018-06-05 | Apple Inc. | Devices, methods, and graphical user interfaces for displaying and using menus |
US10216351B2 (en) | 2015-03-08 | 2019-02-26 | Apple Inc. | Device configuration user interface |
US10048757B2 (en) | 2015-03-08 | 2018-08-14 | Apple Inc. | Devices and methods for controlling media presentation |
US9632664B2 (en) | 2015-03-08 | 2017-04-25 | Apple Inc. | Devices, methods, and graphical user interfaces for manipulating user interface objects with visual and/or haptic feedback |
US10095396B2 (en) | 2015-03-08 | 2018-10-09 | Apple Inc. | Devices, methods, and graphical user interfaces for interacting with a control object while dragging another object |
US9899019B2 (en) | 2015-03-18 | 2018-02-20 | Apple Inc. | Systems and methods for structured stem and suffix language models |
US9639184B2 (en) | 2015-03-19 | 2017-05-02 | Apple Inc. | Touch input cursor manipulation |
US9785305B2 (en) | 2015-03-19 | 2017-10-10 | Apple Inc. | Touch input cursor manipulation |
US10067653B2 (en) | 2015-04-01 | 2018-09-04 | Apple Inc. | Devices and methods for processing touch inputs based on their intensities |
US20170045981A1 (en) | 2015-08-10 | 2017-02-16 | Apple Inc. | Devices and Methods for Processing Touch Inputs Based on Their Intensities |
US9842105B2 (en) | 2015-04-16 | 2017-12-12 | Apple Inc. | Parsimonious continuous-space phrase representations for natural language processing |
CN106155297B (en) * | 2015-04-20 | 2019-06-21 | 阿里巴巴集团控股有限公司 | A kind of unlocking method and equipment of mobile terminal |
EP3091422B1 (en) * | 2015-05-08 | 2020-06-24 | Nokia Technologies Oy | Method, apparatus and computer program product for entering operational states based on an input type |
DE102015005933A1 (en) * | 2015-05-12 | 2016-11-17 | Coramaze Technologies Gmbh | Implantable device for improving or eliminating heart valve insufficiency |
US10460227B2 (en) | 2015-05-15 | 2019-10-29 | Apple Inc. | Virtual assistant in a communication session |
US10627987B2 (en) * | 2015-05-19 | 2020-04-21 | Samsung Electronics Co., Ltd. | Method for launching a second application using a first application icon in an electronic device |
US10200824B2 (en) | 2015-05-27 | 2019-02-05 | Apple Inc. | Systems and methods for proactively identifying and surfacing relevant content on a touch-sensitive device |
US10083688B2 (en) | 2015-05-27 | 2018-09-25 | Apple Inc. | Device voice control for selecting a displayed affordance |
US10127220B2 (en) | 2015-06-04 | 2018-11-13 | Apple Inc. | Language identification from short strings |
US9578173B2 (en) | 2015-06-05 | 2017-02-21 | Apple Inc. | Virtual assistant aided communication with 3rd party service in a communication session |
US20160358133A1 (en) | 2015-06-05 | 2016-12-08 | Apple Inc. | User interface for loyalty accounts and private label accounts for a wearable device |
US10101822B2 (en) | 2015-06-05 | 2018-10-16 | Apple Inc. | Language input correction |
US10255907B2 (en) | 2015-06-07 | 2019-04-09 | Apple Inc. | Automatic accent detection using acoustic models |
US9891811B2 (en) | 2015-06-07 | 2018-02-13 | Apple Inc. | Devices and methods for navigating between user interfaces |
US9860451B2 (en) | 2015-06-07 | 2018-01-02 | Apple Inc. | Devices and methods for capturing and interacting with enhanced digital images |
US9830048B2 (en) | 2015-06-07 | 2017-11-28 | Apple Inc. | Devices and methods for processing touch inputs with instructions in a web page |
US10186254B2 (en) | 2015-06-07 | 2019-01-22 | Apple Inc. | Context-based endpoint detection |
US10346030B2 (en) | 2015-06-07 | 2019-07-09 | Apple Inc. | Devices and methods for navigating between user interfaces |
US10200598B2 (en) | 2015-06-07 | 2019-02-05 | Apple Inc. | Devices and methods for capturing and interacting with enhanced digital images |
US11025565B2 (en) | 2015-06-07 | 2021-06-01 | Apple Inc. | Personalized prediction of responses for instant messaging |
USD797756S1 (en) * | 2015-06-24 | 2017-09-19 | Tomtom International B.V. | Display panel with a changeable graphical user interface for an electronic personal training device |
US20160378747A1 (en) | 2015-06-29 | 2016-12-29 | Apple Inc. | Virtual assistant for media playback |
US10509476B2 (en) * | 2015-07-02 | 2019-12-17 | Verizon Patent And Licensing Inc. | Enhanced device authentication using magnetic declination |
USD789957S1 (en) * | 2015-07-10 | 2017-06-20 | Capital One Services, Llc | Display screen with graphical user interface |
US10248308B2 (en) | 2015-08-10 | 2019-04-02 | Apple Inc. | Devices, methods, and graphical user interfaces for manipulating user interfaces with physical gestures |
US9880735B2 (en) | 2015-08-10 | 2018-01-30 | Apple Inc. | Devices, methods, and graphical user interfaces for manipulating user interface objects with visual and/or haptic feedback |
US10235035B2 (en) | 2015-08-10 | 2019-03-19 | Apple Inc. | Devices, methods, and graphical user interfaces for content navigation and manipulation |
US10416800B2 (en) | 2015-08-10 | 2019-09-17 | Apple Inc. | Devices, methods, and graphical user interfaces for adjusting user interface objects |
USD777784S1 (en) * | 2015-08-26 | 2017-01-31 | Google Inc. | Display screen with icon |
USD784387S1 (en) * | 2015-09-02 | 2017-04-18 | Samsung Electronics Co., Ltd | Display screen or portion thereof with graphical user interface |
US10331312B2 (en) | 2015-09-08 | 2019-06-25 | Apple Inc. | Intelligent automated assistant in a media environment |
US10740384B2 (en) | 2015-09-08 | 2020-08-11 | Apple Inc. | Intelligent automated assistant for media search and playback |
US10671428B2 (en) | 2015-09-08 | 2020-06-02 | Apple Inc. | Distributed personal assistant |
US10747498B2 (en) | 2015-09-08 | 2020-08-18 | Apple Inc. | Zero latency digital assistant |
US9697820B2 (en) | 2015-09-24 | 2017-07-04 | Apple Inc. | Unit-selection text-to-speech synthesis using concatenation-sensitive neural networks |
US10366158B2 (en) | 2015-09-29 | 2019-07-30 | Apple Inc. | Efficient word encoding for recurrent neural network language models |
US11010550B2 (en) | 2015-09-29 | 2021-05-18 | Apple Inc. | Unified language modeling framework for word prediction, auto-completion and auto-correction |
US11587559B2 (en) | 2015-09-30 | 2023-02-21 | Apple Inc. | Intelligent device identification |
US9928840B2 (en) | 2015-10-16 | 2018-03-27 | Google Llc | Hotword recognition |
US9747926B2 (en) * | 2015-10-16 | 2017-08-29 | Google Inc. | Hotword recognition |
JP6463710B2 (en) | 2015-10-16 | 2019-02-06 | グーグル エルエルシー | Hot word recognition |
CN114675771A (en) | 2015-10-29 | 2022-06-28 | 创新先进技术有限公司 | Service calling method and device |
US10691473B2 (en) | 2015-11-06 | 2020-06-23 | Apple Inc. | Intelligent automated assistant in a messaging environment |
US10956666B2 (en) | 2015-11-09 | 2021-03-23 | Apple Inc. | Unconventional virtual assistant interactions |
CN105488374B (en) * | 2015-11-28 | 2018-06-12 | 小米科技有限责任公司 | unlocking method and device |
US10049668B2 (en) | 2015-12-02 | 2018-08-14 | Apple Inc. | Applying neural network language models to weighted finite state transducers for automatic speech recognition |
US10223066B2 (en) | 2015-12-23 | 2019-03-05 | Apple Inc. | Proactive assistance based on dialog communication between devices |
CN105718773B (en) * | 2016-01-20 | 2019-02-01 | Oppo广东移动通信有限公司 | A kind of terminal unlock method and device |
US10530762B2 (en) | 2016-03-09 | 2020-01-07 | Google Llc | Electing whether to unify passcodes |
US10446143B2 (en) | 2016-03-14 | 2019-10-15 | Apple Inc. | Identification of voice inputs providing credentials |
DK179186B1 (en) | 2016-05-19 | 2018-01-15 | Apple Inc | REMOTE AUTHORIZATION TO CONTINUE WITH AN ACTION |
US9934775B2 (en) | 2016-05-26 | 2018-04-03 | Apple Inc. | Unit-selection text-to-speech synthesis based on predicted concatenation parameters |
US9972304B2 (en) | 2016-06-03 | 2018-05-15 | Apple Inc. | Privacy preserving distributed evaluation framework for embedded personalized systems |
US10249300B2 (en) | 2016-06-06 | 2019-04-02 | Apple Inc. | Intelligent list reading |
US11227589B2 (en) | 2016-06-06 | 2022-01-18 | Apple Inc. | Intelligent list reading |
KR20170138279A (en) * | 2016-06-07 | 2017-12-15 | 엘지전자 주식회사 | Mobile terminal and method for controlling the same |
US10049663B2 (en) | 2016-06-08 | 2018-08-14 | Apple, Inc. | Intelligent automated assistant for media exploration |
DK179309B1 (en) | 2016-06-09 | 2018-04-23 | Apple Inc | Intelligent automated assistant in a home environment |
US10586535B2 (en) | 2016-06-10 | 2020-03-10 | Apple Inc. | Intelligent digital assistant in a multi-tasking environment |
US10490187B2 (en) | 2016-06-10 | 2019-11-26 | Apple Inc. | Digital assistant providing automated status report |
US10509862B2 (en) | 2016-06-10 | 2019-12-17 | Apple Inc. | Dynamic phrase expansion of language input |
US10067938B2 (en) | 2016-06-10 | 2018-09-04 | Apple Inc. | Multilingual word prediction |
US10706175B2 (en) * | 2016-06-10 | 2020-07-07 | Nirvon Shoa | Method and apparatus for hiding private browsing data |
US10192552B2 (en) | 2016-06-10 | 2019-01-29 | Apple Inc. | Digital assistant providing whispered speech |
DK201670540A1 (en) | 2016-06-11 | 2018-01-08 | Apple Inc | Application integration with a digital assistant |
DK179049B1 (en) | 2016-06-11 | 2017-09-18 | Apple Inc | Data driven natural language event detection and classification |
DK179343B1 (en) | 2016-06-11 | 2018-05-14 | Apple Inc | Intelligent task discovery |
DK179415B1 (en) | 2016-06-11 | 2018-06-14 | Apple Inc | Intelligent device arbitration and control |
DK201670622A1 (en) | 2016-06-12 | 2018-02-12 | Apple Inc | User interfaces for transactions |
US10474753B2 (en) | 2016-09-07 | 2019-11-12 | Apple Inc. | Language identification using recurrent neural networks |
US10466891B2 (en) * | 2016-09-12 | 2019-11-05 | Apple Inc. | Special lock mode user interface |
US10043516B2 (en) | 2016-09-23 | 2018-08-07 | Apple Inc. | Intelligent automated assistant |
US10237268B2 (en) * | 2016-11-02 | 2019-03-19 | Google Llc | Secure passcode processing device |
KR102521333B1 (en) * | 2016-11-09 | 2023-04-14 | 삼성전자주식회사 | Method for displaying user interface related to user authentication and electronic device for the same |
US11281993B2 (en) | 2016-12-05 | 2022-03-22 | Apple Inc. | Model and ensemble compression for metric learning |
US10593346B2 (en) | 2016-12-22 | 2020-03-17 | Apple Inc. | Rank-reduced token representation for automatic speech recognition |
US11204787B2 (en) | 2017-01-09 | 2021-12-21 | Apple Inc. | Application integration with a digital assistant |
US11314898B2 (en) * | 2017-02-28 | 2022-04-26 | Samsung Electronics Co., Ltd. | Operating method of electronic device for function execution based on voice command in locked state and electronic device supporting the same |
US10992795B2 (en) | 2017-05-16 | 2021-04-27 | Apple Inc. | Methods and interfaces for home media control |
US11431836B2 (en) | 2017-05-02 | 2022-08-30 | Apple Inc. | Methods and interfaces for initiating media playback |
DK201770383A1 (en) | 2017-05-09 | 2018-12-14 | Apple Inc. | User interface for correcting recognition errors |
US10417266B2 (en) | 2017-05-09 | 2019-09-17 | Apple Inc. | Context-aware ranking of intelligent response suggestions |
DK201770439A1 (en) | 2017-05-11 | 2018-12-13 | Apple Inc. | Offline personal assistant |
US10395654B2 (en) | 2017-05-11 | 2019-08-27 | Apple Inc. | Text normalization based on a data-driven learning network |
DK180048B1 (en) | 2017-05-11 | 2020-02-04 | Apple Inc. | MAINTAINING THE DATA PROTECTION OF PERSONAL INFORMATION |
US10726832B2 (en) | 2017-05-11 | 2020-07-28 | Apple Inc. | Maintaining privacy of personal information |
US11301477B2 (en) | 2017-05-12 | 2022-04-12 | Apple Inc. | Feedback analysis of a digital assistant |
DK201770427A1 (en) | 2017-05-12 | 2018-12-20 | Apple Inc. | Low-latency intelligent automated assistant |
DK179496B1 (en) | 2017-05-12 | 2019-01-15 | Apple Inc. | USER-SPECIFIC Acoustic Models |
DK179745B1 (en) | 2017-05-12 | 2019-05-01 | Apple Inc. | SYNCHRONIZATION AND TASK DELEGATION OF A DIGITAL ASSISTANT |
DK201770431A1 (en) | 2017-05-15 | 2018-12-20 | Apple Inc. | Optimizing dialogue policy decisions for digital assistants using implicit feedback |
DK201770432A1 (en) | 2017-05-15 | 2018-12-21 | Apple Inc. | Hierarchical belief states for digital assistants |
US10303715B2 (en) | 2017-05-16 | 2019-05-28 | Apple Inc. | Intelligent automated assistant for media exploration |
DK179560B1 (en) | 2017-05-16 | 2019-02-18 | Apple Inc. | Far-field extension for digital assistant services |
US20180336892A1 (en) | 2017-05-16 | 2018-11-22 | Apple Inc. | Detecting a trigger of a digital assistant |
US10403278B2 (en) | 2017-05-16 | 2019-09-03 | Apple Inc. | Methods and systems for phonetic matching in digital assistant services |
US10311144B2 (en) | 2017-05-16 | 2019-06-04 | Apple Inc. | Emoji word sense disambiguation |
CN111343060B (en) | 2017-05-16 | 2022-02-11 | 苹果公司 | Method and interface for home media control |
US20220279063A1 (en) | 2017-05-16 | 2022-09-01 | Apple Inc. | Methods and interfaces for home media control |
US10657328B2 (en) | 2017-06-02 | 2020-05-19 | Apple Inc. | Multi-task recurrent neural network architecture for efficient morphology handling in neural language modeling |
US10283117B2 (en) * | 2017-06-19 | 2019-05-07 | Lenovo (Singapore) Pte. Ltd. | Systems and methods for identification of response cue at peripheral device |
KR102353486B1 (en) * | 2017-07-18 | 2022-01-20 | 엘지전자 주식회사 | Mobile terminal and method for controlling the same |
US10445429B2 (en) | 2017-09-21 | 2019-10-15 | Apple Inc. | Natural language understanding using vocabularies with compressed serialized tries |
US10755051B2 (en) | 2017-09-29 | 2020-08-25 | Apple Inc. | Rule-based natural language processing |
US10636424B2 (en) | 2017-11-30 | 2020-04-28 | Apple Inc. | Multi-turn canned dialog |
USD870142S1 (en) * | 2017-12-29 | 2019-12-17 | Leica Biosystems Imaging, Inc. | Digital pathology apparatus display screen with graphical user interface |
US10733982B2 (en) | 2018-01-08 | 2020-08-04 | Apple Inc. | Multi-directional dialog |
WO2019143492A1 (en) | 2018-01-22 | 2019-07-25 | Apple Inc. | Secure login with authentication based on a visual representation of data |
US10733375B2 (en) | 2018-01-31 | 2020-08-04 | Apple Inc. | Knowledge-based framework for improving natural language understanding |
USD916861S1 (en) * | 2018-02-27 | 2021-04-20 | Rockport Networks Inc. | Display screen with a graphical user interface |
US10789959B2 (en) | 2018-03-02 | 2020-09-29 | Apple Inc. | Training speaker recognition models for digital assistants |
US10592604B2 (en) | 2018-03-12 | 2020-03-17 | Apple Inc. | Inverse text normalization for automatic speech recognition |
TWI664553B (en) * | 2018-03-16 | 2019-07-01 | 義守大學 | How to unlock your phone |
US10818288B2 (en) | 2018-03-26 | 2020-10-27 | Apple Inc. | Natural assistant interaction |
US10909331B2 (en) | 2018-03-30 | 2021-02-02 | Apple Inc. | Implicit identification of translation payload with neural machine translation |
US11145294B2 (en) | 2018-05-07 | 2021-10-12 | Apple Inc. | Intelligent automated assistant for delivering content from user experiences |
US10928918B2 (en) | 2018-05-07 | 2021-02-23 | Apple Inc. | Raise to speak |
US10984780B2 (en) | 2018-05-21 | 2021-04-20 | Apple Inc. | Global semantic word embeddings using bi-directional recurrent neural networks |
US10991373B1 (en) * | 2018-05-29 | 2021-04-27 | Amazon Technologies, Inc. | Voice command processing for locked devices |
DK179822B1 (en) | 2018-06-01 | 2019-07-12 | Apple Inc. | Voice interaction at a primary device to access call functionality of a companion device |
DK180639B1 (en) | 2018-06-01 | 2021-11-04 | Apple Inc | DISABILITY OF ATTENTION-ATTENTIVE VIRTUAL ASSISTANT |
US10892996B2 (en) | 2018-06-01 | 2021-01-12 | Apple Inc. | Variable latency device coordination |
US11386266B2 (en) | 2018-06-01 | 2022-07-12 | Apple Inc. | Text correction |
DK201870355A1 (en) | 2018-06-01 | 2019-12-16 | Apple Inc. | Virtual assistant operation in multi-device environments |
US10496705B1 (en) | 2018-06-03 | 2019-12-03 | Apple Inc. | Accelerated task performance |
KR20200002610A (en) | 2018-06-29 | 2020-01-08 | 캐논 가부시끼가이샤 | Electronic device, control method for electronic device, and computer readable medium |
US11010561B2 (en) | 2018-09-27 | 2021-05-18 | Apple Inc. | Sentiment prediction from textual data |
US10839159B2 (en) | 2018-09-28 | 2020-11-17 | Apple Inc. | Named entity normalization in a spoken dialog system |
US11170166B2 (en) | 2018-09-28 | 2021-11-09 | Apple Inc. | Neural typographical error modeling via generative adversarial networks |
US11462215B2 (en) | 2018-09-28 | 2022-10-04 | Apple Inc. | Multi-modal inputs for voice commands |
US11475898B2 (en) | 2018-10-26 | 2022-10-18 | Apple Inc. | Low-latency multi-speaker speech recognition |
USD936665S1 (en) * | 2018-11-21 | 2021-11-23 | Biosense Webster (Israel) Ltd. | Portion of a computer screen with a graphical user interface |
US11638059B2 (en) | 2019-01-04 | 2023-04-25 | Apple Inc. | Content playback on multiple devices |
US11348573B2 (en) | 2019-03-18 | 2022-05-31 | Apple Inc. | Multimodality in digital assistant systems |
DK201970509A1 (en) | 2019-05-06 | 2021-01-15 | Apple Inc | Spoken notifications |
US11423908B2 (en) | 2019-05-06 | 2022-08-23 | Apple Inc. | Interpreting spoken requests |
US11475884B2 (en) | 2019-05-06 | 2022-10-18 | Apple Inc. | Reducing digital assistant latency when a language is incorrectly determined |
US11307752B2 (en) | 2019-05-06 | 2022-04-19 | Apple Inc. | User configurable task triggers |
US11140099B2 (en) | 2019-05-21 | 2021-10-05 | Apple Inc. | Providing message response suggestions |
US11289073B2 (en) | 2019-05-31 | 2022-03-29 | Apple Inc. | Device text to speech |
KR20240049648A (en) | 2019-05-31 | 2024-04-16 | 애플 인크. | User interfaces for audio media control |
DK201970510A1 (en) | 2019-05-31 | 2021-02-11 | Apple Inc | Voice identification in digital assistant systems |
US11496600B2 (en) | 2019-05-31 | 2022-11-08 | Apple Inc. | Remote execution of machine-learned models |
DK180129B1 (en) | 2019-05-31 | 2020-06-02 | Apple Inc. | User activity shortcut suggestions |
US11010121B2 (en) | 2019-05-31 | 2021-05-18 | Apple Inc. | User interfaces for audio media control |
US11360641B2 (en) | 2019-06-01 | 2022-06-14 | Apple Inc. | Increasing the relevance of new available information |
US11227599B2 (en) * | 2019-06-01 | 2022-01-18 | Apple Inc. | Methods and user interfaces for voice-based control of electronic devices |
US11488406B2 (en) | 2019-09-25 | 2022-11-01 | Apple Inc. | Text detection using global geometry estimators |
US11418713B2 (en) * | 2020-04-02 | 2022-08-16 | Qualcomm Incorporated | Input based launch sequences for a camera application |
US11043220B1 (en) | 2020-05-11 | 2021-06-22 | Apple Inc. | Digital assistant hardware abstraction |
US11061543B1 (en) | 2020-05-11 | 2021-07-13 | Apple Inc. | Providing relevant data items based on context |
US11755276B2 (en) | 2020-05-12 | 2023-09-12 | Apple Inc. | Reducing description length based on confidence |
US11490204B2 (en) | 2020-07-20 | 2022-11-01 | Apple Inc. | Multi-device audio adjustment coordination |
US11438683B2 (en) | 2020-07-21 | 2022-09-06 | Apple Inc. | User identification using headphones |
US11392291B2 (en) | 2020-09-25 | 2022-07-19 | Apple Inc. | Methods and interfaces for media control with dynamic feedback |
US11847378B2 (en) | 2021-06-06 | 2023-12-19 | Apple Inc. | User interfaces for audio routing |
WO2022261628A1 (en) | 2021-06-08 | 2022-12-15 | Mewt LLC | Wireless kill switch |
US11606353B2 (en) | 2021-07-22 | 2023-03-14 | Biocatch Ltd. | System, device, and method of generating and utilizing one-time passwords |
Citations (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
WO2010040670A2 (en) * | 2008-10-06 | 2010-04-15 | Tat The Astonishing Tribe Ab | Method for application launch and system function invocation |
US20100146437A1 (en) * | 2008-12-04 | 2010-06-10 | Microsoft Corporation | Glanceable animated notifications on a locked device |
Family Cites Families (29)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5870083A (en) | 1996-10-04 | 1999-02-09 | International Business Machines Corporation | Breakaway touchscreen pointing device |
US6216230B1 (en) | 1998-02-11 | 2001-04-10 | Durango Corporation | Notebook security system (NBS) |
US6189099B1 (en) | 1998-02-11 | 2001-02-13 | Durango Corporation | Notebook security system (NBS) |
KR100312954B1 (en) * | 1998-12-26 | 2001-11-03 | 윤종용 | Method for locking origination call and releasing lock of it in portable telephone |
FI20021655A (en) | 2002-06-19 | 2003-12-20 | Nokia Corp | Method of deactivating locking and a portable electronic device |
US7099684B2 (en) | 2002-12-30 | 2006-08-29 | Motorola, Inc. | Method and apparatus for protecting against an inadvertent keystroke |
US20050212760A1 (en) | 2004-03-23 | 2005-09-29 | Marvit David L | Gesture based user interface supporting preexisting symbols |
US7657849B2 (en) | 2005-12-23 | 2010-02-02 | Apple Inc. | Unlocking a device by performing gestures on an unlock image |
US20070226778A1 (en) * | 2006-03-22 | 2007-09-27 | Jorg Pietruszka | Bluetooth theft protection |
US20080191905A1 (en) | 2007-02-14 | 2008-08-14 | Research In Motion Limited | Method and apparatus for preventing action responsive to accidental keystroke |
US20080250509A1 (en) * | 2007-04-04 | 2008-10-09 | Nokia Corporation | Write Protection For Memory Devices |
US8218734B2 (en) | 2007-06-12 | 2012-07-10 | Microsoft Corporation | Messaging with a locked communication device |
EP2060970A1 (en) | 2007-11-12 | 2009-05-20 | Research In Motion Limited | User interface for touchscreen device |
KR101442169B1 (en) * | 2007-11-27 | 2014-11-03 | 삼성전자주식회사 | A Public Key Infrastructure-based Bluetooth Smart-Key System and Operating Method Thereof |
US20090164467A1 (en) | 2007-12-20 | 2009-06-25 | Nokia Corporation | Ice recognition function to override mobile device lock code |
TWI353545B (en) * | 2008-04-17 | 2011-12-01 | Htc Corp | Method for unlocking screen, mobile electronic dev |
CN101587398A (en) * | 2008-05-23 | 2009-11-25 | 鸿富锦精密工业（深圳）有限公司 | Password protection method |
KR101517967B1 (en) * | 2008-07-07 | 2015-05-06 | 엘지전자 주식회사 | Controlling a Mobile Terminal |
US20100079380A1 (en) * | 2008-09-30 | 2010-04-01 | Nokia Corporation | Intelligent input device lock |
US9197738B2 (en) * | 2008-12-04 | 2015-11-24 | Microsoft Technology Licensing, Llc | Providing selected data through a locked display |
US8331992B2 (en) * | 2008-12-19 | 2012-12-11 | Verizon Patent And Licensing Inc. | Interactive locked state mobile communication device |
KR101565768B1 (en) * | 2008-12-23 | 2015-11-06 | 삼성전자주식회사 | Apparatus and method for unlocking a locking mode of portable terminal |
WO2010075623A1 (en) * | 2008-12-31 | 2010-07-08 | Bce Inc. | System and method for unlocking a device |
US8539382B2 (en) * | 2009-04-03 | 2013-09-17 | Palm, Inc. | Preventing unintentional activation and/or input in an electronic device |
US8528072B2 (en) * | 2010-07-23 | 2013-09-03 | Apple Inc. | Method, apparatus and system for access mode control of a device |
US8402533B2 (en) | 2010-08-06 | 2013-03-19 | Google Inc. | Input to locked computing device |
KR20130039586A (en) * | 2011-10-12 | 2013-04-22 | 삼성전자주식회사 | Method and apparatus for providing lock function of touch device |
CN102393805A (en) * | 2011-10-24 | 2012-03-28 | 中兴通讯股份有限公司 | Operating method of terminal screen lock interface, and device and terminal |
US8543397B1 (en) * | 2012-10-11 | 2013-09-24 | Google Inc. | Mobile device voice activation |
-
2010
- 2010-08-06 US US12/851,739 patent/US8402533B2/en active Active
-
2011
- 2011-07-29 GB GB1303938.3A patent/GB2497231B/en active Active
- 2011-07-29 EP EP11815115.8A patent/EP2601571B1/en active Active
- 2011-07-29 WO PCT/US2011/045928 patent/WO2012018689A1/en active Application Filing
- 2011-07-29 KR KR1020137005770A patent/KR101838971B1/en active IP Right Grant
- 2011-07-29 AU AU2011286026A patent/AU2011286026B2/en active Active
- 2011-07-29 KR KR1020187006390A patent/KR101889054B1/en active IP Right Grant
- 2011-07-29 GB GB1604236.8A patent/GB2535341B/en active Active
- 2011-07-29 EP EP18204185.5A patent/EP3457256B1/en active Active
- 2011-07-29 DE DE112011102650T patent/DE112011102650T5/en not_active Withdrawn
- 2011-09-30 US US13/251,112 patent/US8667562B2/en active Active
-
2013
- 2013-03-19 US US13/847,301 patent/US8839413B2/en active Active
-
2014
- 2014-09-15 US US14/486,188 patent/US9245151B2/en active Active
-
2015
- 2015-12-17 US US14/972,911 patent/US10565387B2/en active Active
-
2020
- 2020-02-14 US US16/790,926 patent/US11263330B2/en active Active
Patent Citations (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
WO2010040670A2 (en) * | 2008-10-06 | 2010-04-15 | Tat The Astonishing Tribe Ab | Method for application launch and system function invocation |
US20100146437A1 (en) * | 2008-12-04 | 2010-06-10 | Microsoft Corporation | Glanceable animated notifications on a locked device |
Also Published As
Publication number | Publication date |
---|---|
KR101838971B1 (en) | 2018-04-26 |
US8839413B2 (en) | 2014-09-16 |
EP3457256A1 (en) | 2019-03-20 |
US9245151B2 (en) | 2016-01-26 |
EP2601571A4 (en) | 2016-04-06 |
GB2497231A (en) | 2013-06-05 |
WO2012018689A1 (en) | 2012-02-09 |
GB201303938D0 (en) | 2013-04-17 |
US8402533B2 (en) | 2013-03-19 |
US20130219346A1 (en) | 2013-08-22 |
KR101889054B1 (en) | 2018-09-20 |
US20120036556A1 (en) | 2012-02-09 |
US11263330B2 (en) | 2022-03-01 |
GB2535341B (en) | 2017-04-05 |
EP2601571A1 (en) | 2013-06-12 |
DE112011102650T5 (en) | 2013-05-16 |
KR20130130697A (en) | 2013-12-02 |
US10565387B2 (en) | 2020-02-18 |
EP3457256B1 (en) | 2021-03-10 |
AU2011286026A1 (en) | 2013-02-21 |
US8667562B2 (en) | 2014-03-04 |
US20200202019A1 (en) | 2020-06-25 |
GB2535341A (en) | 2016-08-17 |
EP2601571B1 (en) | 2018-11-07 |
US20150007354A1 (en) | 2015-01-01 |
GB2497231B (en) | 2017-06-28 |
US20120124644A1 (en) | 2012-05-17 |
US20160104001A1 (en) | 2016-04-14 |
GB201604236D0 (en) | 2016-04-27 |
KR20180029090A (en) | 2018-03-19 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11263330B2 (en) | Input to locked computing device | |
US20200249813A1 (en) | Method and system for enabling the sharing of information between applications on a computing device | |
US11429402B2 (en) | Multi-user configuration | |
US20170090565A1 (en) | User interfaces and associated processes for information resources | |
US9098695B2 (en) | Secure note system for computing device lock screen | |
JP2015503149A (en) | Adaptive input language switching | |
US10788981B2 (en) | Method and apparatus for processing new message associated with application | |
JP2021521565A (en) | Devices, methods, and graphical user interfaces for managing authentication credentials for user accounts | |
US11960615B2 (en) | Methods and user interfaces for voice-based user profile management | |
AU2013200503B2 (en) | Input to locked computing device | |
EP3939217A1 (en) | Initiating a business messaging session |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
FGA | Letters patent sealed or granted (standard patent) | ||
HB | Alteration of name in register |
Owner name: GOOGLE LLCFree format text: FORMER NAME(S): GOOGLE, INC. |