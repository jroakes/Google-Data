CA2631151A1 - Social and interactive applications for mass media - Google Patents
Social and interactive applications for mass media Download PDFInfo
- Publication number
- CA2631151A1 CA2631151A1 CA002631151A CA2631151A CA2631151A1 CA 2631151 A1 CA2631151 A1 CA 2631151A1 CA 002631151 A CA002631151 A CA 002631151A CA 2631151 A CA2631151 A CA 2631151A CA 2631151 A1 CA2631151 A1 CA 2631151A1
- Authority
- CA
- Canada
- Prior art keywords
- descriptors
- rating
- determining
- media broadcast
- descriptor
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/43—Processing of content or additional data, e.g. demultiplexing additional data from a digital video stream; Elementary client operations, e.g. monitoring of home network or synchronising decoder's clock; Client middleware
- H04N21/435—Processing of additional data, e.g. decrypting of additional data, reconstructing software from modules extracted from the transport stream
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/43—Processing of content or additional data, e.g. demultiplexing additional data from a digital video stream; Elementary client operations, e.g. monitoring of home network or synchronising decoder's clock; Client middleware
- H04N21/442—Monitoring of processes or resources, e.g. detecting the failure of a recording device, monitoring the downstream bandwidth, the number of times a movie has been viewed, the storage space available from the internal hard disk
- H04N21/44213—Monitoring of end-user related data
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/60—Information retrieval; Database structures therefor; File system structures therefor of audio data
- G06F16/63—Querying
- G06F16/635—Filtering based on additional data, e.g. user or group profiles
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/60—Information retrieval; Database structures therefor; File system structures therefor of audio data
- G06F16/68—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
- G06F16/683—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using metadata automatically derived from the content
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q30/00—Commerce
- G06Q30/02—Marketing; Price estimation or determination; Fundraising
-
- G—PHYSICS
- G11—INFORMATION STORAGE
- G11B—INFORMATION STORAGE BASED ON RELATIVE MOVEMENT BETWEEN RECORD CARRIER AND TRANSDUCER
- G11B27/00—Editing; Indexing; Addressing; Timing or synchronising; Monitoring; Measuring tape travel
- G11B27/02—Editing, e.g. varying the order of information signals recorded on, or reproduced from, record carriers
- G11B27/031—Electronic editing of digitised analogue information signals, e.g. audio or video signals
- G11B27/034—Electronic editing of digitised analogue information signals, e.g. audio or video signals on discs
-
- G—PHYSICS
- G11—INFORMATION STORAGE
- G11B—INFORMATION STORAGE BASED ON RELATIVE MOVEMENT BETWEEN RECORD CARRIER AND TRANSDUCER
- G11B27/00—Editing; Indexing; Addressing; Timing or synchronising; Monitoring; Measuring tape travel
- G11B27/10—Indexing; Addressing; Timing or synchronising; Measuring tape travel
- G11B27/19—Indexing; Addressing; Timing or synchronising; Measuring tape travel by using information detectable on the record carrier
- G11B27/28—Indexing; Addressing; Timing or synchronising; Measuring tape travel by using information detectable on the record carrier by using information signals recorded by the same method as the main recording
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04H—BROADCAST COMMUNICATION
- H04H60/00—Arrangements for broadcast applications with a direct linking to broadcast information or broadcast space-time; Broadcast-related systems
- H04H60/35—Arrangements for identifying or recognising characteristics with a direct linkage to broadcast information or to broadcast space-time, e.g. for identifying broadcast stations or for identifying users
- H04H60/37—Arrangements for identifying or recognising characteristics with a direct linkage to broadcast information or to broadcast space-time, e.g. for identifying broadcast stations or for identifying users for identifying segments of broadcast information, e.g. scenes or extracting programme ID
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04H—BROADCAST COMMUNICATION
- H04H60/00—Arrangements for broadcast applications with a direct linking to broadcast information or broadcast space-time; Broadcast-related systems
- H04H60/35—Arrangements for identifying or recognising characteristics with a direct linkage to broadcast information or to broadcast space-time, e.g. for identifying broadcast stations or for identifying users
- H04H60/37—Arrangements for identifying or recognising characteristics with a direct linkage to broadcast information or to broadcast space-time, e.g. for identifying broadcast stations or for identifying users for identifying segments of broadcast information, e.g. scenes or extracting programme ID
- H04H60/372—Programme
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04H—BROADCAST COMMUNICATION
- H04H60/00—Arrangements for broadcast applications with a direct linking to broadcast information or broadcast space-time; Broadcast-related systems
- H04H60/35—Arrangements for identifying or recognising characteristics with a direct linkage to broadcast information or to broadcast space-time, e.g. for identifying broadcast stations or for identifying users
- H04H60/37—Arrangements for identifying or recognising characteristics with a direct linkage to broadcast information or to broadcast space-time, e.g. for identifying broadcast stations or for identifying users for identifying segments of broadcast information, e.g. scenes or extracting programme ID
- H04H60/375—Commercial
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04H—BROADCAST COMMUNICATION
- H04H60/00—Arrangements for broadcast applications with a direct linking to broadcast information or broadcast space-time; Broadcast-related systems
- H04H60/56—Arrangements characterised by components specially adapted for monitoring, identification or recognition covered by groups H04H60/29-H04H60/54
- H04H60/58—Arrangements characterised by components specially adapted for monitoring, identification or recognition covered by groups H04H60/29-H04H60/54 of audio
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04H—BROADCAST COMMUNICATION
- H04H60/00—Arrangements for broadcast applications with a direct linking to broadcast information or broadcast space-time; Broadcast-related systems
- H04H60/56—Arrangements characterised by components specially adapted for monitoring, identification or recognition covered by groups H04H60/29-H04H60/54
- H04H60/59—Arrangements characterised by components specially adapted for monitoring, identification or recognition covered by groups H04H60/29-H04H60/54 of video
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04H—BROADCAST COMMUNICATION
- H04H60/00—Arrangements for broadcast applications with a direct linking to broadcast information or broadcast space-time; Broadcast-related systems
- H04H60/61—Arrangements for services using the result of monitoring, identification or recognition covered by groups H04H60/29-H04H60/54
- H04H60/64—Arrangements for services using the result of monitoring, identification or recognition covered by groups H04H60/29-H04H60/54 for providing detail information
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/20—Servers specifically adapted for the distribution of content, e.g. VOD servers; Operations thereof
- H04N21/25—Management operations performed by the server for facilitating the content distribution or administrating data related to end-users or client devices, e.g. end-user or client device authentication, learning user preferences for recommending movies
- H04N21/251—Learning process for intelligent management, e.g. learning user preferences for recommending movies
- H04N21/252—Processing of multiple end-users' preferences to derive collaborative data
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/20—Servers specifically adapted for the distribution of content, e.g. VOD servers; Operations thereof
- H04N21/25—Management operations performed by the server for facilitating the content distribution or administrating data related to end-users or client devices, e.g. end-user or client device authentication, learning user preferences for recommending movies
- H04N21/266—Channel or content management, e.g. generation and management of keys and entitlement messages in a conditional access system, merging a VOD unicast channel into a multicast channel
- H04N21/26603—Channel or content management, e.g. generation and management of keys and entitlement messages in a conditional access system, merging a VOD unicast channel into a multicast channel for automatically generating descriptors from content, e.g. when it is not made available by its provider, using content analysis techniques
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/41—Structure of client; Structure of client peripherals
- H04N21/414—Specialised client platforms, e.g. receiver in car or embedded in a mobile appliance
- H04N21/41407—Specialised client platforms, e.g. receiver in car or embedded in a mobile appliance embedded in a portable device, e.g. video client on a mobile phone, PDA, laptop
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/41—Structure of client; Structure of client peripherals
- H04N21/414—Specialised client platforms, e.g. receiver in car or embedded in a mobile appliance
- H04N21/4143—Specialised client platforms, e.g. receiver in car or embedded in a mobile appliance embedded in a Personal Computer [PC]
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/41—Structure of client; Structure of client peripherals
- H04N21/422—Input-only peripherals, i.e. input devices connected to specially adapted client devices, e.g. global positioning system [GPS]
- H04N21/42203—Input-only peripherals, i.e. input devices connected to specially adapted client devices, e.g. global positioning system [GPS] sound input device, e.g. microphone
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/43—Processing of content or additional data, e.g. demultiplexing additional data from a digital video stream; Elementary client operations, e.g. monitoring of home network or synchronising decoder's clock; Client middleware
- H04N21/439—Processing of audio elementary streams
- H04N21/4394—Processing of audio elementary streams involving operations for analysing the audio stream, e.g. detecting features or characteristics in audio streams
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/43—Processing of content or additional data, e.g. demultiplexing additional data from a digital video stream; Elementary client operations, e.g. monitoring of home network or synchronising decoder's clock; Client middleware
- H04N21/44—Processing of video elementary streams, e.g. splicing a video clip retrieved from local storage with an incoming video stream, rendering scenes according to MPEG-4 scene graphs
- H04N21/44016—Processing of video elementary streams, e.g. splicing a video clip retrieved from local storage with an incoming video stream, rendering scenes according to MPEG-4 scene graphs involving splicing one content stream with another content stream, e.g. for substituting a video clip
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/43—Processing of content or additional data, e.g. demultiplexing additional data from a digital video stream; Elementary client operations, e.g. monitoring of home network or synchronising decoder's clock; Client middleware
- H04N21/44—Processing of video elementary streams, e.g. splicing a video clip retrieved from local storage with an incoming video stream, rendering scenes according to MPEG-4 scene graphs
- H04N21/4402—Processing of video elementary streams, e.g. splicing a video clip retrieved from local storage with an incoming video stream, rendering scenes according to MPEG-4 scene graphs involving reformatting operations of video signals for household redistribution, storage or real-time display
- H04N21/440236—Processing of video elementary streams, e.g. splicing a video clip retrieved from local storage with an incoming video stream, rendering scenes according to MPEG-4 scene graphs involving reformatting operations of video signals for household redistribution, storage or real-time display by media transcoding, e.g. video is transformed into a slideshow of still pictures, audio is converted into text
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/45—Management operations performed by the client for facilitating the reception of or the interaction with the content or administrating data related to the end-user or to the client device itself, e.g. learning user preferences for recommending movies, resolving scheduling conflicts
- H04N21/454—Content or additional data filtering, e.g. blocking advertisements
- H04N21/4542—Blocking scenes or portions of the received content, e.g. censoring scenes
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/47—End-user applications
- H04N21/472—End-user interface for requesting content, additional data or services; End-user interface for interacting with content, e.g. for content reservation or setting reminders, for requesting event notification, for manipulating displayed content
- H04N21/4722—End-user interface for requesting content, additional data or services; End-user interface for interacting with content, e.g. for content reservation or setting reminders, for requesting event notification, for manipulating displayed content for requesting additional data associated with the content
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/47—End-user applications
- H04N21/475—End-user interface for inputting end-user data, e.g. personal identification number [PIN], preference data
- H04N21/4756—End-user interface for inputting end-user data, e.g. personal identification number [PIN], preference data for rating content, e.g. scoring a recommended movie
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/47—End-user applications
- H04N21/478—Supplemental services, e.g. displaying phone caller identification, shopping application
- H04N21/4782—Web browsing, e.g. WebTV
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/47—End-user applications
- H04N21/478—Supplemental services, e.g. displaying phone caller identification, shopping application
- H04N21/4788—Supplemental services, e.g. displaying phone caller identification, shopping application communicating with other users, e.g. chatting
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/47—End-user applications
- H04N21/482—End-user interface for program selection
- H04N21/4828—End-user interface for program selection for searching program descriptors
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/80—Generation or processing of content or additional data by content creator independently of the distribution process; Content per se
- H04N21/81—Monomedia components thereof
- H04N21/8106—Monomedia components thereof involving special audio data, e.g. different tracks for different languages
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/80—Generation or processing of content or additional data by content creator independently of the distribution process; Content per se
- H04N21/81—Monomedia components thereof
- H04N21/812—Monomedia components thereof involving advertisement data
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/80—Generation or processing of content or additional data by content creator independently of the distribution process; Content per se
- H04N21/81—Monomedia components thereof
- H04N21/8126—Monomedia components thereof involving additional data, e.g. news, sports, stocks, weather forecasts
- H04N21/8133—Monomedia components thereof involving additional data, e.g. news, sports, stocks, weather forecasts specifically related to the content, e.g. biography of the actors in a movie, detailed information about an article seen in a video program
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/80—Generation or processing of content or additional data by content creator independently of the distribution process; Content per se
- H04N21/85—Assembly of content; Generation of multimedia applications
- H04N21/858—Linking data to content, e.g. by linking an URL to a video object, by creating a hotspot
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N5/00—Details of television systems
- H04N5/44—Receiver circuitry for the reception of television signals according to analogue transmission standards
- H04N5/445—Receiver circuitry for the reception of television signals according to analogue transmission standards for displaying additional information
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N7/00—Television systems
- H04N7/16—Analogue secrecy systems; Analogue subscription systems
- H04N7/173—Analogue secrecy systems; Analogue subscription systems with two-way working, e.g. subscriber sending a programme selection signal
- H04N7/17309—Transmission or handling of upstream communications
- H04N7/17318—Direct or substantially direct transmission and handling of requests
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N7/00—Television systems
- H04N7/16—Analogue secrecy systems; Analogue subscription systems
- H04N7/173—Analogue secrecy systems; Analogue subscription systems with two-way working, e.g. subscriber sending a programme selection signal
- H04N7/17309—Transmission or handling of upstream communications
- H04N7/17336—Handling of requests in head-ends
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04H—BROADCAST COMMUNICATION
- H04H20/00—Arrangements for broadcast or for distribution combined with broadcast
- H04H20/12—Arrangements for observation, testing or troubleshooting
- H04H20/14—Arrangements for observation, testing or troubleshooting for monitoring programmes
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04H—BROADCAST COMMUNICATION
- H04H2201/00—Aspects of broadcast communication
- H04H2201/90—Aspects of broadcast communication characterised by the use of signatures
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04H—BROADCAST COMMUNICATION
- H04H60/00—Arrangements for broadcast applications with a direct linking to broadcast information or broadcast space-time; Broadcast-related systems
- H04H60/02—Arrangements for generating broadcast information; Arrangements for generating broadcast-related information with a direct linking to broadcast information or to broadcast space-time; Arrangements for simultaneous generation of broadcast information and broadcast-related information
- H04H60/06—Arrangements for scheduling broadcast services or broadcast-related services
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04H—BROADCAST COMMUNICATION
- H04H60/00—Arrangements for broadcast applications with a direct linking to broadcast information or broadcast space-time; Broadcast-related systems
- H04H60/35—Arrangements for identifying or recognising characteristics with a direct linkage to broadcast information or to broadcast space-time, e.g. for identifying broadcast stations or for identifying users
- H04H60/45—Arrangements for identifying or recognising characteristics with a direct linkage to broadcast information or to broadcast space-time, e.g. for identifying broadcast stations or for identifying users for identifying users
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04H—BROADCAST COMMUNICATION
- H04H60/00—Arrangements for broadcast applications with a direct linking to broadcast information or broadcast space-time; Broadcast-related systems
- H04H60/61—Arrangements for services using the result of monitoring, identification or recognition covered by groups H04H60/29-H04H60/54
- H04H60/65—Arrangements for services using the result of monitoring, identification or recognition covered by groups H04H60/29-H04H60/54 for using the result on users' side
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04H—BROADCAST COMMUNICATION
- H04H60/00—Arrangements for broadcast applications with a direct linking to broadcast information or broadcast space-time; Broadcast-related systems
- H04H60/61—Arrangements for services using the result of monitoring, identification or recognition covered by groups H04H60/29-H04H60/54
- H04H60/66—Arrangements for services using the result of monitoring, identification or recognition covered by groups H04H60/29-H04H60/54 for using the result on distributors' side
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04H—BROADCAST COMMUNICATION
- H04H60/00—Arrangements for broadcast applications with a direct linking to broadcast information or broadcast space-time; Broadcast-related systems
- H04H60/76—Arrangements characterised by transmission systems other than for broadcast, e.g. the Internet
- H04H60/78—Arrangements characterised by transmission systems other than for broadcast, e.g. the Internet characterised by source locations or destination locations
- H04H60/80—Arrangements characterised by transmission systems other than for broadcast, e.g. the Internet characterised by source locations or destination locations characterised by transmission among terminal devices
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04H—BROADCAST COMMUNICATION
- H04H60/00—Arrangements for broadcast applications with a direct linking to broadcast information or broadcast space-time; Broadcast-related systems
- H04H60/76—Arrangements characterised by transmission systems other than for broadcast, e.g. the Internet
- H04H60/81—Arrangements characterised by transmission systems other than for broadcast, e.g. the Internet characterised by the transmission system itself
- H04H60/82—Arrangements characterised by transmission systems other than for broadcast, e.g. the Internet characterised by the transmission system itself the transmission system being the Internet
- H04H60/87—Arrangements characterised by transmission systems other than for broadcast, e.g. the Internet characterised by the transmission system itself the transmission system being the Internet accessed over computer networks
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/45—Management operations performed by the client for facilitating the reception of or the interaction with the content or administrating data related to the end-user or to the client device itself, e.g. learning user preferences for recommending movies, resolving scheduling conflicts
- H04N21/462—Content or additional data management, e.g. creating a master electronic program guide from data received from the Internet and a Head-end, controlling the complexity of a video stream by scaling the resolution or bit-rate based on the client capabilities
- H04N21/4622—Retrieving content or additional data from different sources, e.g. from a broadcast channel and the Internet
Abstract
Systems, methods, apparatuses, user interfaces and computer program products provide social and interactive applications for mass media based on real-time ambient-audio and/or video identification. In some implementations, a method includes: receiving descriptors identifying ambient audio associated with a media broadcast; comparing the descriptors to one or more reference descriptors; and determining a rating for the media broadcast based at least in part on the results of the comparison.
Description
Social and Interactive Applications For Mass Media RELATED APPLICATIONS
[0001] This application claims the benefit of priority from U.S. Provisional Patent Application No. 60/ 740,760, for "Enviroruueii.t-Based Referrals, filed November 29, 2005, which application is incorporated by reference herein its entirety.
[0001] This application claims the benefit of priority from U.S. Provisional Patent Application No. 60/ 740,760, for "Enviroruueii.t-Based Referrals, filed November 29, 2005, which application is incorporated by reference herein its entirety.
[0002] This application claims the benefit of priority from U.S. Provisional Patent Application No. 60/823,881, for "Audio Identification Based on Signatures,"
filed August 29, 2006, which application is incorporated by reference herein its entirety.
TECHNICAL FIELD
filed August 29, 2006, which application is incorporated by reference herein its entirety.
TECHNICAL FIELD
[0003] The disclosed implementations are related to social and interactive applications for mass media.
BACKGROUND
BACKGROUND
[0004] Mass media charuzels (e.g., television and radio broadcasts) typically provide limited colitent to a large audience. By contrast, the World Wide Web provides vast amounts of information that may only interest a few individuals.
Conventional interactive television attempts to bridge these two communication mediums by providing a means for viewers to interact with their televisions and to receive content and/or services related to television broadcasts.
Conventional interactive television attempts to bridge these two communication mediums by providing a means for viewers to interact with their televisions and to receive content and/or services related to television broadcasts.
[0005] Conventional interactive television is typically onl.y available to viewers tluough cable or satellite networks for a subscription fee. To receive . . .. ....... ....:.. ...~.. .~.~:
interactive television service the viewer has to rent or buy a set-top box and have it installed by a teclu-iician. The viewer's television is connected to the set-top box, which enables the viewer to interact with the television using a remote control or other input device, and to receive informatiori, entertairunent and services (e.g., advertisements, oi-dine shopping, forms and surveys, games and activities, etc.).
interactive television service the viewer has to rent or buy a set-top box and have it installed by a teclu-iician. The viewer's television is connected to the set-top box, which enables the viewer to interact with the television using a remote control or other input device, and to receive informatiori, entertairunent and services (e.g., advertisements, oi-dine shopping, forms and surveys, games and activities, etc.).
[0006] While conventional interactive television can improve the viewer's television experience, there remains a need for social and interactive applications for mass media that do not rely on slgnlflcant additional hardware or physical coiu-tections between the television or radio and a set-top box or computer.
[0007] One social and interactive television application that is lacking with coliventional and interactive television systems is the ability to provide complementary irtformation to the mass media chaiulel in an effortless manner.
With conventional systems, a user would have to log-on to a computer and query for such information which would diminish the passive experience offered by mass media. Moreover, conventional television systems cannot provide complementary information in real-time while the user is watching a broadcast.
With conventional systems, a user would have to log-on to a computer and query for such information which would diminish the passive experience offered by mass media. Moreover, conventional television systems cannot provide complementary information in real-time while the user is watching a broadcast.
[0008] Another social and interactive television application that is lacking with conventional interactive television systems is the ability to dynamically link a viewer with an ad hoc social peer comxnunity (e.g., a discussion group, chat room, etc.) in real-time. Imagine that you are watching the latest episode of "Friends" on television and discover that the character "Monica" is pregnant. You want to chat, comment or read other viewers' responses to the scene in real-time. One option would be to log on your computer, type in the name of "Friends" or other related terms into a search engine, and perform a search to find a discussion group on "Friends." Such required action by the viewer, however, would diminish the passive experience offered by mass media and would not enable the viewer to dynamically interact (e.g., conunent, chat, etc.) with other viewers who are watching the program at the same time.
[0009] Another deficiency in conventional television systems and interactive television systems is a simple method to assess the popularity of broadcasting events. The popularity ratings of broadcasting events are of high interest to users, broadcasters and advertisers. These needs are partially resolved by measurement systems like the Nielsen ratings. These ratings, however, require dedicated hardware installation and cooperation from participating viewers.
SUMMARY
SUMMARY
[0010] The deficiencies described above are addressed by the disclosed systems, methods, apparatuses, user interfaces and computer program products for providing social and interactive applications based on real-time ambient-audio and J or video identification.
[0011] In some implementations, a method includes: receiving a descriptor identifying ainbient audio associated with a media broadcast; comparing the descriptor to reference descriptors associated with the media broadcast; and aggregating personalized information related to the media broadcast based on the result of the comparison.
[0012] In some implementations, a method includes: receiving a first descriptor identifying ainbient audio associated with a first media broadcast;
receiving a secoa-id descriptor identifying alnbient audio associated with a second media broadcast; coinparing the first and second descriptors to determine if the first and second media broadcasts are the same; and aggregating personalized inforination based on the result of the comparison.
receiving a secoa-id descriptor identifying alnbient audio associated with a second media broadcast; coinparing the first and second descriptors to determine if the first and second media broadcasts are the same; and aggregating personalized inforination based on the result of the comparison.
[0013] In some implementations, a method irtcludes: detecting ambient audio associated with a media broadcast; generating descriptors identifying the media broadcast; transmitting the descriptors to a network resource; and receiving aggregated personalized information from the network resource based on the descriptors.
[0014] In some implementations, a system includes a database of reference descriptors. A database server is operatively coupled to the database and to a client system. The database server is configurable to receive a descriptor from the client system for identifying ambient audio associated with a media broadcast, comparing the received descriptor with one or more referertce descriptors, and aggregating personalized information related to the media broadcast based on the result of the comparison.
[0015] In some implementations, a system includes an audio detector configurable for sampling ambient audio. A client interface is operatively coupled to the audio detector and cortfigurable to generate descriptors identifying a media broadcast. The client interface is configurable for transmitting the descriptors to a network resource, and for receiving aggregated personalized information from the network resource based on the descriptors.
[0016] In some implementations, a method includes: receiving descriptors identifying ainbient audio associated with a media broadcast; comparing the descriptors to one or more reference descriptors; and determining a rating for the media broadcast based at least in part on the results of the coinparison.
[0017] In some implementations, a method includes: generating descriptors identifying ambient audio associated with a media broadcast; providing the descriptors to a ratings provider for determining a rating for the media broadcast based on the descriptors; receiving the rating from the ratings provider; and displaying the rating on a display device.
[0018] In some implementations, a method includes: recording ambient audio snippets from a media broadcast; generating a descriptor from the ambient audio snippets; and providing the descriptor to a ratings provider.
[0019] In some implementations, a system includes a database of reference descriptors. A server is operatively coupled to the database and to a client system.
The server is configurable to receive a descriptor from the client system for identifying ambient audio associated with a media broadcast, comparing the received descriptor with one or more reference descriptors, and determining a rating for the media broadcast based at least in part on the results of the comparison.
The server is configurable to receive a descriptor from the client system for identifying ambient audio associated with a media broadcast, comparing the received descriptor with one or more reference descriptors, and determining a rating for the media broadcast based at least in part on the results of the comparison.
[0020] In some impleinentations, a system includes an audio detector configurable for sampling ambient audio. A client interface is operatively coupled to the audio detector and configurable to generate descriptors identifying a media broadcast. The client interface is configurable for transmitting the descriptors to a network resource, and for receiving rating information from the network resource based on the descriptors.
[0021] Other iinplementations are directed to systems, methods, apparatuses, user interfaces, and computer program products.
DESCRIPTION OF DRAWINGS
DESCRIPTION OF DRAWINGS
[0022] FIG. 1 is a block diagram of one embodiment of a mass personalization system.
[0023] FIG. 2 illustrates one embodiment of an ambient-audio identification system, including the client-side interface shown in FIG. 1.
[0024] ' FIG. 3 is a flow diagram of one embodiment of a process for providing mass-personalization applications.
[0025] FIG. 4 is a flow diagram of one embodiinent of an audio fingerprinting process.
[0026] FIG. 5 is a flow diagram of one embodiment of a user interface for interacting with mass personalization applications.
[0027] FIG. 6 is a block diagram of one embodiment of hardware architecture for a client system for implementing the client-side interface shown in FIG.
1.
1.
[0028] FIG. 7 is a flow diagram of one embodiment of a repetition detection process.
DETAILED DESCRIPTION
Mass Personalization Applications [0029] Mass personalization applications provide personalized and interactive inforination related to inass media broadcasts (e.g., television, radio, movies, Internet broadcasts, etc.). Such applications include but are not limited to:
personalized information layers, ad hoc social peer communities, real-time popularity ratings and video (or audio) bookmarks, etc. Although some of the mass media examples disclosed herein are in the context of television broadcasts, the disclosed implementations are equally applicable to radio and/or music broadcasts.
DETAILED DESCRIPTION
Mass Personalization Applications [0029] Mass personalization applications provide personalized and interactive inforination related to inass media broadcasts (e.g., television, radio, movies, Internet broadcasts, etc.). Such applications include but are not limited to:
personalized information layers, ad hoc social peer communities, real-time popularity ratings and video (or audio) bookmarks, etc. Although some of the mass media examples disclosed herein are in the context of television broadcasts, the disclosed implementations are equally applicable to radio and/or music broadcasts.
[0030] Personalized iriformation layers provide complementary information to the mass media channel. Examples of personalized information layers include but are not liinited to: fashion, politics, business, health, traveling, etc.
For exainple, while watching a news segment on a celebrity, a fasl-Lion layer is presented to the viewer on a television screen or a computer display device, which provides information and/or images related to the clothes and accessories the celebrity is wearing in the news segment. Additiolially, personalized layers may include advertisements promoting products or services related to the news segment, such as a link to a clothing store that is selling clothes that the celebrity is, wearing.
For exainple, while watching a news segment on a celebrity, a fasl-Lion layer is presented to the viewer on a television screen or a computer display device, which provides information and/or images related to the clothes and accessories the celebrity is wearing in the news segment. Additiolially, personalized layers may include advertisements promoting products or services related to the news segment, such as a link to a clothing store that is selling clothes that the celebrity is, wearing.
[0031] Ad hoc social peer communities provide a venue for commentary between users who are watching the same show on television or listening to the same radio station. For example, a user who is watching the latest CNN
headlines can be provided with a cominenting medium (e.g., a chat room, inessage board, wiki page, video link, etc.) that allows the user to chat, comment on or read other viewers responses to the ongoing mass media broadcast.
headlines can be provided with a cominenting medium (e.g., a chat room, inessage board, wiki page, video link, etc.) that allows the user to chat, comment on or read other viewers responses to the ongoing mass media broadcast.
[0032] Real-time popularity ratings provide content providers and users with ratings information (similar to Nielsen ratings). For example, a user can instantaneously be provided with real-time popularity ratings of television charu.lels or radio stations being watched or listened to by the user's social network and/or by people with similar demographics.
[0033] Video or audio bookmarks provide users with low effort ways of creating personalized libraries of their favorite broadcast content. For example, a user can siinply press a button on a computer or a remote control device and a snippet of ainbient audio and/ or video of the broadcast content is recorded, processed and saved. The snippet can be used as a bookmark to refer to the program, or portions of the program, for later viewing. The bookmark can be shared with friends or saved for future personal reference.
Mttss Personrtlizatio3z Netznorlc [0034] FIG. 1 is a block diagram of a mass personalization system 100 for providing mass personalization applications. The system 100 includes one or more client-side interfaces 102, an audio database server 104 and a social application server 106, all of which communicate over a network 108 (e.g., the Internet, an irttranet, LAN, wireless network, etc.).
Mttss Personrtlizatio3z Netznorlc [0034] FIG. 1 is a block diagram of a mass personalization system 100 for providing mass personalization applications. The system 100 includes one or more client-side interfaces 102, an audio database server 104 and a social application server 106, all of which communicate over a network 108 (e.g., the Internet, an irttranet, LAN, wireless network, etc.).
[0035] A client interface 102 can be any device that allows a user to enter and receive ii-.formation, and which is capable of presenting a user interface on a display s device, including but not limited to: a desktop or portable computer; an electronic device; a telephone; a mobile phone; a display system; a television; a computer monitor; a navigation system; a portable lnedia player jrecorder; a personal digital assistant (PDA); a game console; a handheld electronic device; and an embedded electronic device or appliance. The client interface 102 is described more fully with respect to FIG. 2.
[0036] In some implementations, the client-interface 102 includes an ambient audio detector (e.g., a microphone) for monitoring and recording the ambient audio of a mass media broadcast in a broadcast environlnent (e.g., a user's living room).
One or more ambient audio segments or "snippets" are converted into distinctive and robust statistical summaries, referred to as "audio fingerprints" or "descriptors." In some implementations, the descriptors are compressed files COnta1111ng one or more audio signature components that can be compared with a database of previously generated reference descriptors or statistics associated with the mass media broadcast.
One or more ambient audio segments or "snippets" are converted into distinctive and robust statistical summaries, referred to as "audio fingerprints" or "descriptors." In some implementations, the descriptors are compressed files COnta1111ng one or more audio signature components that can be compared with a database of previously generated reference descriptors or statistics associated with the mass media broadcast.
[0037] A technique for generating audio fingerprints for music identification is described in Ke, Y., Hoiem, D., Sukthankar, R. (2005), Computer Vision for Music Identification, In Proc. Coinputer Vision and Pattern Recognition, which is incorporated herein by reference in its entirety. In some implementations, the music identification approach proposed by (hereinafter "Ke et al.") is adapted to generate descriptors for television audio data and queries, as described with respect to FIG. 4.
- , - . -[0038] A techn.ique for generating audio descriptors using wavelets is described in U.S. Provisional Patent Application No. 60/823,881, for "Audio Identification Based on Signatures." That application describes a teclulique that uses a combination of computer-vision techniques and large-scale-data-stream processing algorithms to create compact descriptors/fingerprints of audio snippets that can be efficiently matched. The tecl-u-tique uses wavelets, which is a known mathematical tool for hierarchically decomposing functions.
- , - . -[0038] A techn.ique for generating audio descriptors using wavelets is described in U.S. Provisional Patent Application No. 60/823,881, for "Audio Identification Based on Signatures." That application describes a teclulique that uses a combination of computer-vision techniques and large-scale-data-stream processing algorithms to create compact descriptors/fingerprints of audio snippets that can be efficiently matched. The tecl-u-tique uses wavelets, which is a known mathematical tool for hierarchically decomposing functions.
[0039] In "Audio Identification Based on Signatures," an implementation of a retrieval process includes the following steps: 1) given the audio spectra of an audio snippet, extract spectral images of, for example, 11.6*w ms duration, with randoin spacing averaging d-ms apart. For each spectral image: 2) coznpute wavelets on the spectral image; 3) extract the top-t wavelets; 4) create a binary representation of the top-t wavelets; 5) use min-hash to create a sub-fingerprint of the top-t wavelets; 6) use LSH with b bins and 1 hash tables to find sub-fingerprint segments that are close inatches; 7) discard sub-fingerprints with less than v matches; 8) compute a Hamming distance from the remaining candidate sub-fingerprints to the query sub-fingerprint; and 9) use dynamic programming to combined the matches across time.
[0040] In some iinplementations, the descriptors and an associated user identifier ("user id") for identifying the client-side interface 102 are sent to the audio database server 104 via network 108. The audio database server 104 compares the descriptor to a plurality of reference descriptors, which were previously determined and stored in an audio database 110 coupled to the audio database server 104.
In some iinplementations, tl-te audio database server 104 continuously updates the reference descriptors stored in the audio database 110 from recent mass media broadcasts.
[0041] The audio database server 104 determines the best matches between the received descriptors and the reference descriptors and sends best-match ir-.formation to the social application server 106. The matching process is described more fully with respect to FIG. 4.
In some iinplementations, tl-te audio database server 104 continuously updates the reference descriptors stored in the audio database 110 from recent mass media broadcasts.
[0041] The audio database server 104 determines the best matches between the received descriptors and the reference descriptors and sends best-match ir-.formation to the social application server 106. The matching process is described more fully with respect to FIG. 4.
[0042] In some, impleinentations, the social application server 106 accepts web-browser coin-tections associated with the client-side interface 102. Using the best-match information, the social application server 106 aggregates personalized information for the user and sends the personalized information to the client-side interface 102. The personalized information can include but is not limited to:
advertisements, personalized information layers, popularity ratings, and in.formation associated with a commenting medium (e.g., ad hoc social peer communities, forums, discussion groups, video conferences, etc.).
advertisements, personalized information layers, popularity ratings, and in.formation associated with a commenting medium (e.g., ad hoc social peer communities, forums, discussion groups, video conferences, etc.).
[0043] In some implementations, the personalized information can be used to create a chat room for viewers without knowing the show that the viewers are watching in real time. The chat rooms can be created by directly comparing descriptors in the data streams transmitted by client systems to determine matches.
That is, chat rooms can be created around viewers having matching descriptors.
In such an implementation, there is no need to compare the descriptors received from viewers against reference descriptors.
That is, chat rooms can be created around viewers having matching descriptors.
In such an implementation, there is no need to compare the descriptors received from viewers against reference descriptors.
[0044] Iiz some iinplementations, the social application server 106 serves a web page to the client-side interface 102, which is received and displayed by a web browser (e.g., Microsoft Internet ExplorerTM) running at the client-side interface 102.
The social application server 106 also receives the user id from the client-side interface 102 and/or audio database server 104 to assist in aggregating personalized content and serving web pages to the client-side interface 102.
The social application server 106 also receives the user id from the client-side interface 102 and/or audio database server 104 to assist in aggregating personalized content and serving web pages to the client-side interface 102.
[0045] It should be apparent that other implementations of the system 100 are possible. For example, the system 100 can include multiple audio databases 110, audio database servers 104 and/or social application servers 106.
Alternatively, the audio database server 104 and the social application server 106 can be a single server or system, or part of a network resource and/ or service. Also, the network 108 can include multiple networks and links operatively coupled together in various topologies and arrangements using a variety of network devices (e.g., hubs, routers, etc.) and mediums (e.g., copper, optical fiber, radio frequencies, etc.).
Client-server ..
architectures are described lherein only as an example. Other computer architectures are possible.
Ambient Audio Identification System [0046] FIG. 2 illustrates an ainbient audio identification system 200, including a client-side interface 102 as shown in FIG. 1. The system 200 includes a mass media system 202 (e.g., a television set, radio, computer, electronic device, mobile phone, gaine console, network appliance, etc.), an ambient audio detector 204, a client-side interface 102 (e.g., a desktop or laptop computer, etc.) and a iletwork access device 206. In some iinplementations, the clierit-side interface 102 includes a display device 210 for presenting a user interface (UI) 208 for enabling a user to interact with a mass personalization application, as described with respect to FIG. 5.
Alternatively, the audio database server 104 and the social application server 106 can be a single server or system, or part of a network resource and/ or service. Also, the network 108 can include multiple networks and links operatively coupled together in various topologies and arrangements using a variety of network devices (e.g., hubs, routers, etc.) and mediums (e.g., copper, optical fiber, radio frequencies, etc.).
Client-server ..
architectures are described lherein only as an example. Other computer architectures are possible.
Ambient Audio Identification System [0046] FIG. 2 illustrates an ainbient audio identification system 200, including a client-side interface 102 as shown in FIG. 1. The system 200 includes a mass media system 202 (e.g., a television set, radio, computer, electronic device, mobile phone, gaine console, network appliance, etc.), an ambient audio detector 204, a client-side interface 102 (e.g., a desktop or laptop computer, etc.) and a iletwork access device 206. In some iinplementations, the clierit-side interface 102 includes a display device 210 for presenting a user interface (UI) 208 for enabling a user to interact with a mass personalization application, as described with respect to FIG. 5.
[0047] In operation, the mass media system 202 generates ainbient audio of a mass media broadcast (e.g., television audio), which is detected by the ambient audio detector 204. The ambient audio detector 204 can be any device that can detect ambient audio, including a freestanding microphone and a microphone that is integrated with the client-side interface 102. The detected ambient audio is encoded by the client-side interface 102 to provide descriptors identifying the ambient audio.
The descriptors are transmitted to the audio database server 104 by way of the network access device 206 and the network 108.
The descriptors are transmitted to the audio database server 104 by way of the network access device 206 and the network 108.
[0048] In some implementations, client software running at the client-side interface 102 continually monitors and records n-second (e.g., 5 second) audio files ("snippets") of ambient audio. The snippets are then converted into iiz-frams (e.g., 415 frames) of k-bit encoded descriptors (e.g., 32-bit), according to a process described with respect to FIG. 4. In some implementations, the monitoring and recording is event based. For example, the monitoring and recording can be automatically initiated on a specified date and at a specified tiine (e.g., Monday, 8:00 P.M.) and for a specified time duration (e.g., between 8:00-9:00 P.M.).
Alternatively, the monitoring and recording can be initiated in response to user input (e.g., a mouse click, function key or key combination) from a control device (e.g., a remote _--control, etc.). In some implementations, the ambient audio is encoded using a streaming variation of the 32-bit/frame discriminative features described in Ke et al.
Alternatively, the monitoring and recording can be initiated in response to user input (e.g., a mouse click, function key or key combination) from a control device (e.g., a remote _--control, etc.). In some implementations, the ambient audio is encoded using a streaming variation of the 32-bit/frame discriminative features described in Ke et al.
[0049] In some implementations, the client software runs as a "side bar" or other user interface element. That way, when the client-side interface 102 is booted up, the ambient audio sampling can start immediately and run in the "background"
with results (optionally) being displayed in the side bar without invoking a full web-browser session.
with results (optionally) being displayed in the side bar without invoking a full web-browser session.
[0050] In some implementations, the alnbient audio sampling can begin when the client-side interface 102 is booted or when the viewer logs into a service or application (e.g., email, etc.) [0051] The descriptors are sent to the audio database server 104. In some implementations, the descriptors are compressed statistical summaries of the alnbient audio, a described in Ke et al. By sending statistical sulninaries, the user's acoustic privacy is maintained because the statistical summaries are not reversible, i.e., the original audio caru.lot be recovered from the descriptor. Thus, any conversations by the user or other individuals monitored and recorded in the broadcast environment cannot be reproduced from the descriptor. In some implementations, the descriptors can be encrypted for extra privacy and security using one or more known encryption techniques (e.g., asymmetric or symmetric key encryption, elliptic encryption, etc.).
[0052] In some implementations, the descriptors are sent to the audio database server 104 as a query submission (also referred to as a query descriptor) in response to a trigger event detected by the monitoring process at the client-side interface 102. For example, a trigger event could be the opening theme of a television program (e.g., opening tune of "Seinfeld") or dialogue spoken by the actors. In some implementations, the query descriptors can be sent to the audio database server 104 as part of a continuous streaming process. In some implementations, the query descriptors can be transmitted to the audio database server 104 in response to user input (e.g., via remote control, mouse clicks, etc.).
Mass PeYsoiialization Process [0053] FIG. 3 is a flow diagram a mass personalization process 300. The steps of process 300 do not have to be completed in any particular order and at least some steps can be performed at the same time in a multi-threading or parallel processing environment.
Mass PeYsoiialization Process [0053] FIG. 3 is a flow diagram a mass personalization process 300. The steps of process 300 do not have to be completed in any particular order and at least some steps can be performed at the same time in a multi-threading or parallel processing environment.
[0054] The process 300 begins when a client-side interface (e.g., client-side interface 102) monitors and records snippets of ambient audio of a mass media broadcast in a broadcast environm.ent (302). The recorded ainbient audio snippets are encoded into descriptors (e.g., compressed statistical summaries), which can be sent to an audio database server (304) as queries. The audio database server compares the queries against a database of reference descriptors computed from mass media broadcast statistics to determine candidate descriptors that best match the query (308). The candidate descriptors are sent to a social application server or other network resource, which uses the candidate descriptors to aggregate personalized information for the user (310). For example, if the user is watching the television show "Seiilfeld," then query descriptors generated from the show's ambient audio will be matched with reference descriptors derived from previous "Seinfeld" broadcasts. Thus, the best matching candidate descriptors are used to aggregate personalized information relating to "Seinfeld" (e.g., news stories, discussion groups, links to ad laoc social peer communities or chat rooms, advertisements, etc.). In some implementations, the matching procedure is efficiently performed using hashing techniques (e.g., direct hashing or locality sensitive hashing (LSH)) to achieve a short list of candidate descriptors, as described with respect to FIG. 4. The candidate descriptors are then processed in a validation procedure, such as described in Ke et al.
[0055] In some implementations, query descriptors from different viewers are directly matched rather than matching each query with a database of reference descriptors. Such an embodiment would enable the creation of ad hoc social peer coinmunities on subject matter for which a database of reference descriptors is not available. Such an einbodiinent could match in real-time viewers who are in the same public form (e.g., stadiuin, bar, etc.) using portable electronic devices (e.g., mobile phones, PDAs, etc.).
Popularity Ratiugs [0056] In some implementations, real-time and aggregate statistics are inferred from a list of viewers currently watching the broadcast (e.g., show, advertisement, etc.). These statistics can be gathered in the background while viewers are using other applications. Statistics can include but are i-tot limited to: 1) the average number of viewers watching the broadcast; 2) the average number of times viewers watched the broadcast; 3) other shows the viewers watched; 4) the miniinuin and peak number of viewers; 5) what viewers most often switched to when they left a broadcast; 6) how long viewers watch a broadcast; 7) how many times viewers flip a charuZel; 8) which advertisements were watched by viewers; and 9) what viewers most often switched from when they entered a broadcast, etc.
From these statistics, one or more popularity ratings can be determined.
Popularity Ratiugs [0056] In some implementations, real-time and aggregate statistics are inferred from a list of viewers currently watching the broadcast (e.g., show, advertisement, etc.). These statistics can be gathered in the background while viewers are using other applications. Statistics can include but are i-tot limited to: 1) the average number of viewers watching the broadcast; 2) the average number of times viewers watched the broadcast; 3) other shows the viewers watched; 4) the miniinuin and peak number of viewers; 5) what viewers most often switched to when they left a broadcast; 6) how long viewers watch a broadcast; 7) how many times viewers flip a charuZel; 8) which advertisements were watched by viewers; and 9) what viewers most often switched from when they entered a broadcast, etc.
From these statistics, one or more popularity ratings can be determined.
[0057] The statistics used to generate popularity ratings can be generated using a counter for each broadcast channel being monitored. In some implementations, the counters can be intersected with demographic group data or geographic group data. The popularity ratings can be used by viewers to "see what's hot" while the broadcast is ongoing (e.g., by noticing an increased rating during the 2004 Super Bowl half-time performance). Advertisers and content providers can also use popularity ratings to dynamically adjust the material shown in response to ratings. This is especially true for advertisements, since the short unit length and numerous versions of advertisements generated by advertising campaigns are easily exchanged to adjust to viewer rating levels. Other examples of statistics include but are not limited to: popularity of a television broadcast versus a radio broadcast by demographics or time, the popularity of times of day, i.e., peak watching/listening times, the number of households in a given area, the amount of charulel surfing during particular shows (genre of shows, particular times of day), the volume of the broadcast, etc.
[0058] The personalized information is sent to the client-side interface (312).
The popularity ratings can also be stored in a database for use by other processes (318), such as the dynamic adjustment of advertisements described above. The personalized information is received at the client-side interface (314) where it is formatted and presented in a user interface (316). The personalized information can be associated with a coinmenting medium (e.g., text inessages in a chat room) that is presented to the user in a user interface. In some implementations, a chat room can include one or more subgroups. For exainple, a discussion group for "Seinfeld"
might include a subgroup called "Seinfeld Experts," or a subgroup may be associated with a particular demographic, such as women between the ages of 20-who watch "Seinfeld," etc.
The popularity ratings can also be stored in a database for use by other processes (318), such as the dynamic adjustment of advertisements described above. The personalized information is received at the client-side interface (314) where it is formatted and presented in a user interface (316). The personalized information can be associated with a coinmenting medium (e.g., text inessages in a chat room) that is presented to the user in a user interface. In some implementations, a chat room can include one or more subgroups. For exainple, a discussion group for "Seinfeld"
might include a subgroup called "Seinfeld Experts," or a subgroup may be associated with a particular demographic, such as women between the ages of 20-who watch "Seinfeld," etc.
[0059] In some implementations, the raw information (e.g., counter values) used to generate statistics for popularity ratings is collected and stored at the client-side interface rather than at the social application server. The raw information can be transferred to the broadcaster whenever the user is online and/ or invokes a mass personalization application.
[0060] In some implementations, a broadcast measurement box (BMB) is installed at the client-side interface. The BMB can be a simple hardware device that is similar to a set-top box but does not connect to the broadcast device.
Unlike the Neilsen rating system, which requires hardware to be installed in the television, the BMB can be installed near the mass media system or within the range of the television signal. In some implementations, the BMB autoinatically records audio snippets and generates descriptors, which are stored in memory (e.g., flash media).
In some implementations, the BMB can optionally include one or more hardware buttons which can be pressed by a user to indicate which broadcast they are watching (similar to Neilsen ratings). The BMB device can be picked-up by the ratings provider from time to time to collect the stored descriptors, or the BMB can broadcast the stored descriptors to one or more interested parties over a network connection (e.g., telephone, Internet, wireless radio, such as SMS/ carriers radio, etc.) from time to time.
Unlike the Neilsen rating system, which requires hardware to be installed in the television, the BMB can be installed near the mass media system or within the range of the television signal. In some implementations, the BMB autoinatically records audio snippets and generates descriptors, which are stored in memory (e.g., flash media).
In some implementations, the BMB can optionally include one or more hardware buttons which can be pressed by a user to indicate which broadcast they are watching (similar to Neilsen ratings). The BMB device can be picked-up by the ratings provider from time to time to collect the stored descriptors, or the BMB can broadcast the stored descriptors to one or more interested parties over a network connection (e.g., telephone, Internet, wireless radio, such as SMS/ carriers radio, etc.) from time to time.
[0061] In some impleinentations, advertiseinertts can be monitored to determine t1-te ad's effectiveness, which can be reported back to advertisers.
For example, which ads were watched, skipped, volume level of the ads, etc.
For example, which ads were watched, skipped, volume level of the ads, etc.
[0062] In some implementations, an image capture device (e.g., digital camera, video recorder, etc.) can be used to measure how many viewers are watching or listening to a broadcast. For exalnple, various known pattern-matching algoritluns can be applied to an image or a sequence of images to determine the rtumber of viewers present in a broadcast environment during a particular broadcast. The images and or data derived from the images can be used in combination with audio descriptors to gather personalized information for a user, compute popularity ratings, or for any other purpose.
Audio Fingey-printing Process [0063] FIG. 4 is a flow diagram of audio fingerprinting process 400. The steps of process 400 do not have to be completed in any particular order and at least soYne steps can be performed at the same time in a multi-tlueading or parallel processing environment. The process 400 matches query descriptors generated at a client-side interface (e.g., client-side interface 102) to reference descriptors stored in one or more databases in real-time and with low latency. The process 400 adapts a technique proposed by Ke et al. to handle ambient audio data (e.g., from a television broadcast) and queries.
Audio Fingey-printing Process [0063] FIG. 4 is a flow diagram of audio fingerprinting process 400. The steps of process 400 do not have to be completed in any particular order and at least soYne steps can be performed at the same time in a multi-tlueading or parallel processing environment. The process 400 matches query descriptors generated at a client-side interface (e.g., client-side interface 102) to reference descriptors stored in one or more databases in real-time and with low latency. The process 400 adapts a technique proposed by Ke et al. to handle ambient audio data (e.g., from a television broadcast) and queries.
[0064] The process 400 begins at a client-side interface by decomposing ambient audio snippets (e.g., 5-6 seconds of audio) of a mass media broadcast captured by an ambient audio detector (e.g., microphone) into overlapping frames (402). In some impleinentations, the frames are spaced apart by several milliseconds (e.g., 12 ms apart). Each frame is converted into a descriptor (e.g., a 32-bit descriptor) that is trained to overcome audio noise and distortion (404), as described in Ke et al. In some implementations, each descriptor represents an identifying statistical summary of the audio snippet.
[0065] In some implementations, the descriptors can be sent as query snippets (also referred to as query descriptors) to an audio database server where they are matched to a database of reference descriptors identifying statistical summaries of previously recorded audio snippets of the mass media broadcast (406). A list of candidate descriptors having best matches can be determined (408). The candidate descriptors can be scored, such that candidate descriptors that are temporally consistent with, the query descriptor are scored higher than candidate descriptors that are less temporally consistent with the query descriptor (410). The candidate descriptors with the highest scores (e.g., score exceeds a sufficiently high tlireshold value) are transmitted or otherwise provided to a social application server (412) where they can be used to aggregate personalized information related to the media broadcast. Using a tl-u eshold ensures that descriptors are sufficiently matched before the descriptors are transmitted or otherwise provided to the social application server (412).
[0066] In some implementations, the database of reference descriptors can be generated from broadcasts given by various media companies, which can be indexed and used to generate the descriptors. In other implementations, reference descriptors can also be generated using television guides or other metadata and/or iriformation embedded in the broadcast signal.
[0067] In some implementations, speech recognition tecl-u-tology can be used to help identify which program is being watched. Such technology could help users discuss news events instead of just television shows. For exainple, a user could be watching a Shuttle launch on a different channel than another viewer and, therefore, possibly getting a different audio signal (e.g., due to a different newscaster). Speech recognition tecl-uzology could be used to recognize keywords (e.g., Shuttle, launch, etc.), which can be used to link the user with a commenting medium.
Hashing Descriptoi-s [0068] Ke et al. uses computer vision techniques to find higl-dy discriminative, compact statistics for audio. Their procedure trained on labeled pairs of positive examples (where x and x' are noisy versions of the same audio) and negative examples (where x and x' are from different audio). During this training phase, machine-learning technique based on boosting uses the labeled pairs to select a coinbination of 32 filters and thresholds that joiiitly create a higl-lly discriminative statistic. The filters localize changes in the spectrogram magnitude, using first and secol-id order differences across time and frequency. One benefit of using these simple difference filters is that they can be calculated efficiently using a integral image technique described in Viola, P. artd Jones, M. (2002), Robust Real-Time Object Detection, International Journal of Cornputer Vision, which is incorporated by reference herein in its entirety.
Hashing Descriptoi-s [0068] Ke et al. uses computer vision techniques to find higl-dy discriminative, compact statistics for audio. Their procedure trained on labeled pairs of positive examples (where x and x' are noisy versions of the same audio) and negative examples (where x and x' are from different audio). During this training phase, machine-learning technique based on boosting uses the labeled pairs to select a coinbination of 32 filters and thresholds that joiiitly create a higl-lly discriminative statistic. The filters localize changes in the spectrogram magnitude, using first and secol-id order differences across time and frequency. One benefit of using these simple difference filters is that they can be calculated efficiently using a integral image technique described in Viola, P. artd Jones, M. (2002), Robust Real-Time Object Detection, International Journal of Cornputer Vision, which is incorporated by reference herein in its entirety.
[0069] In some implementations, the outputs of these 32 filters are tluesholds, giving a single bit per filter at each audio frame. These 32 threshold results form only transmitted descriptors 'of that frame of audio. This sparsity in encoding ensures tl-ie privacy of the user to unauthorized eavesdropping. Further, these 32-bit descriptors are robust to the audio distortions in the training data, so that positive exaxnples (e.g., matching frames) have small Hanu.ning distances (i.e., distance measuring differing number of bits) and negative examples (e.g., mismatched frames) have large Hamming distances. It should be noted that more or fewer filters can be used and more than one bit per filter can be used at each audio frame (e.g., more bits using multiple tlueshold tests).
[0070] In some implementations, the 32-bit descriptor itself used as a hash key for direct hashing. The descriptor is a well-balanced hash function.
Retrieval rates are further improved by querying not oidy the query descriptor, but also a small set of similar descriptors (up to a Hainming distance of 2 from the original query descriptor).
Witlzin-Query Tenaporal Consistency [0071] Once the query descriptors are matched to the audio database using the hashing procedure described above, the matches are validated to determine which of the database return hits are accurate matches. Otherwise, a candidate descriptor might have many frames matched to the query descriptor but with the wrong temporal structure.
Retrieval rates are further improved by querying not oidy the query descriptor, but also a small set of similar descriptors (up to a Hainming distance of 2 from the original query descriptor).
Witlzin-Query Tenaporal Consistency [0071] Once the query descriptors are matched to the audio database using the hashing procedure described above, the matches are validated to determine which of the database return hits are accurate matches. Otherwise, a candidate descriptor might have many frames matched to the query descriptor but with the wrong temporal structure.
[0072] In some implementations, validation is achieved by viewing each database hit as support for a match at a specific query-database offset. For example, if the eight descriptor ( q8 ) in a 5-second, 415-frame-long "Seinfeld" query snippet, q, hits the 10MI1 database descriptor ( x1008 ), this supports a candidate match between the 5-second query and frames 1001 tltrough 1415 in the audio database.
Other matches between qõ and x,000+,, (1 ~n ~ 415) would support this same candidate match.
Other matches between qõ and x,000+,, (1 ~n ~ 415) would support this same candidate match.
[0073] In addition to temporal cortsistency, we need to account for frames when conversations temporarily drown out the ambient audio. This can be modeled as an exclusive switch between ambient audio and interfering sounds. For each query frame i, there is a hidden variable, yi: if y;=0, the it'1 frame of the query is modeled as interference only; if y;=1, the i~'i frame is modeled as from clean ambient audio. Taking an extreme view (pure ambient or pure interference) is justified by the extremely low precision with which each audio frame is represented (32 bits) and softened by providing additional bit-flop probabilities for each of the 32 positions of the frame vector under each of the two hypotheses (yi=O and y;=1).
Finally, we model the between-frame transitions between ainbient-only and interference-only states as a hidden first-order Markov process, with transition probabilities derived from training data. For example, we can re-use the 66-parameter probability model given by Ke et al., CVPR 2005.
Finally, we model the between-frame transitions between ainbient-only and interference-only states as a hidden first-order Markov process, with transition probabilities derived from training data. For example, we can re-use the 66-parameter probability model given by Ke et al., CVPR 2005.
[0074] The final model of the match probability between a query vector, q, and an ambient-database vector at an offset of N frames, xN, is:
N 415 (y t ~) l P(q I x ) = ~õc1 P(< 11I , ~N Fõ >I ll /I )~(J õ I /'~/!-1 ) (~) where < qõ , x,,, > denotes the bit differences between the 32-bit frame vectors q,, and x,,,. This model incorporates both the temporal consistency constraint and the ambient/interference hidden Markov model.
Post-Matcli Consistency Filtering [0075] People often talk with others while watching television, resulting in sporadic but strong acoustic interference, especially when using laptop-based microphones for sampling the ambient audio. Given that most conversational utterances are two or three seconds in duratiort, a simple con-ununication exchange between viewers could render a 5-second query unrecognizable.
N 415 (y t ~) l P(q I x ) = ~õc1 P(< 11I , ~N Fõ >I ll /I )~(J õ I /'~/!-1 ) (~) where < qõ , x,,, > denotes the bit differences between the 32-bit frame vectors q,, and x,,,. This model incorporates both the temporal consistency constraint and the ambient/interference hidden Markov model.
Post-Matcli Consistency Filtering [0075] People often talk with others while watching television, resulting in sporadic but strong acoustic interference, especially when using laptop-based microphones for sampling the ambient audio. Given that most conversational utterances are two or three seconds in duratiort, a simple con-ununication exchange between viewers could render a 5-second query unrecognizable.
[0076] In some implementations, post-match filtering is used to handle tl-tese intermittent low-confidence mismatches. For example, we can use a continuous-time hidden Markov model of chaiuzel switching with an expected dwell time (i.e., time between charulel changes) of L seconds. The social application server 106 indicates the highest-confidence match witl-iin the recent past (along with its "discounted" confidence) as part of state irLforination associated with each client session. Using this information, the server 106 selects either the content-index match from the recent past or the current index match, base on whichever has the higher con.fidence.
[0077] We use Mi, and Ci, to refer to the best match for the previous time step (5 seconds ago) and its log-likelihood confidence score. If we simply apply the Markov model to this previous best match, without taking another observation, then our expectation is that the best match for the current time is that same program sequence, just 5 seconds further along, and our confidence in this expectation is Ci,-l/L, where 1 =5 seconds is the query time step. This discount of l/L in the log-likelihood corresponds to the Markov model probability, e-'IL, of not switching channels during the l-length time step.
[0078] An alternative hypothesis is generated by the audio match for the current query. We use Mo to refer to the best match for the current audio snippet:
that is, the match that is generated by the audio fingerprinting process 400.
Co is the log-likelihood confidence score given by the audio fingerprinting process 400.
that is, the match that is generated by the audio fingerprinting process 400.
Co is the log-likelihood confidence score given by the audio fingerprinting process 400.
[0079] If tl-tese two matches (the updated historical expectation and the current snippet observation) give different matches, we select the hypothesis with the higher confidence score:
f{ItIIJZCI, -l /L} if C,, -Z/L > C
{M ' C ' (2) M , C } otherwise where Mo is the match that is used by the social application server 106 for selecting related content and Mo and Co are carried forward on the next time step as Mi, and CG,.
User Inteiface [0080] FIG. 5 is a flow diagram of one embodiment of a user interface 208 for interacting with mass personalization applications. The user interface 208 includes a personalized layer display area 502, a commenting medium display area 504, a sponsored lirl<s display area 506 and a content display area 508. The personalized layer display area 502 provides complementary information and/or images related to the video content shown in the content display area 508. The personalized layers can be navigated using a navigation bar 510 and an input device (e.g., a mouse or remote control). Each layer has an associated label in the navigation bar 510.
For example, if the user selects the "Fashion" label, then the fashion layer, which includes fashion related content associated with "Seinfeld;" will be presented in the display area 502.
f{ItIIJZCI, -l /L} if C,, -Z/L > C
{M ' C ' (2) M , C } otherwise where Mo is the match that is used by the social application server 106 for selecting related content and Mo and Co are carried forward on the next time step as Mi, and CG,.
User Inteiface [0080] FIG. 5 is a flow diagram of one embodiment of a user interface 208 for interacting with mass personalization applications. The user interface 208 includes a personalized layer display area 502, a commenting medium display area 504, a sponsored lirl<s display area 506 and a content display area 508. The personalized layer display area 502 provides complementary information and/or images related to the video content shown in the content display area 508. The personalized layers can be navigated using a navigation bar 510 and an input device (e.g., a mouse or remote control). Each layer has an associated label in the navigation bar 510.
For example, if the user selects the "Fashion" label, then the fashion layer, which includes fashion related content associated with "Seinfeld;" will be presented in the display area 502.
[0081] In some ilnpleinentations, the client-side interface 102 includes a display device 210 capable of presenting the user interface 208. In some iinplementations, the user interface 208 is an interactive web page served by the social application server 106 and presented in a browser window on the screen of the display device 210. In some implementations, the user interface 208 is persistent and will be available for interaction after the broadcast audio used in the content match process has shifted in time. In some implementations, the user interface is dynainically updated over time or in response to a trigger event (e.g., a new person enters the chat room, a coiTunercial begins, etc.). For example, each time a commercial is broadcast, the sponsored linlcs display area 506 can be updated with fresh links 518 related to the subject matter of the commercial.
[0082] In some implementations, the personalized information and sponsored links can be emailed to the viewer or shown on a side bar at a later time.
[0083] In some impleYnentations, the client-side interface 102 receives personalized information from the social application server 106. This iriformation can include a web page, email, a message board, links, instant message, a chat room, or an invitation to join an ongoing discussion group, eRoom, video conference or netmeeting, voice call (e.g., Skype ), etc. In some implementations, the user interface 208 provides access to comments and/or links to comments from previously seen broadcasts or movies. For example, if user is currently watching a DVD of "Shrek" he may want to see what people said about the movie in the past.
[0084] In some implementations, the display area 502 includes a rating region 512, which is used to display popularity ratings related to a broadcast. For example, the display area 512 may show how many viewers are currently watching "Seinfeld"
compared to another television show that is broadcast at the same time.
compared to another television show that is broadcast at the same time.
[0085] In some implementations, the commenting medium display area 504 presents a chat room type envirorunent where multiple users can conunent about broadcasts. In some implementations, the display area 504 includes a text box for inputting comments that are sent to the chat room using the input mechanism 516 (e.g., a button).
[0086] The sponsored links display area 506 includes information, images and/or links related to advertising that is associated with the broadcast. For example, one of the links 518 may take the user to a web site that is selling "Seinfeld" merchandise.
[0087] The content display area 508 is where the broadcast content is displayed. For example, a scene from the current broadcast can be displayed with other relevant informatioaz (e.g., episode number, title, timestamp, etc.). In some implementations, the display area 508 includes controls 520 (e.g., scroll buttons) for navigating tYuough the displayed content.
Video Booknaarlcs [0088] In some implementations, a button 522 is included in the content display area that can be used to bookmark video. For example, by clicking the button 522, the "Seinfeld" episode shown in the display area 508 is added to the user's favorites video library, which can then be viewed on-demand through a web-based streaming application or other access methods. According to the policy set by the content owner, this streaming service can provide free single-viewing playback, collect payments as the agent for the content owners, or insert advertisements that would provide payment to the content owners.
Client-Side Interface Hardzmre Architectttre [0089] FIG. 6 is block diagram of hardware architecture 600 for the client-side interface 102 shown in FIG.1. Although the hardware architecture 600 is typical of a computing device (e.g., a personal computer), the disclosed implementations can be realized in any device capable of presenting a user interface on a display device, including but not limited to: desktop or portable computers; electronic devices;
telephones; mobile phones; display systems; televisions; monitors; navigation systems; portable media players/recorders; personal digital assistants; game systems; handheld electronic devices; and embedded electronic devices or appliances.
Video Booknaarlcs [0088] In some implementations, a button 522 is included in the content display area that can be used to bookmark video. For example, by clicking the button 522, the "Seinfeld" episode shown in the display area 508 is added to the user's favorites video library, which can then be viewed on-demand through a web-based streaming application or other access methods. According to the policy set by the content owner, this streaming service can provide free single-viewing playback, collect payments as the agent for the content owners, or insert advertisements that would provide payment to the content owners.
Client-Side Interface Hardzmre Architectttre [0089] FIG. 6 is block diagram of hardware architecture 600 for the client-side interface 102 shown in FIG.1. Although the hardware architecture 600 is typical of a computing device (e.g., a personal computer), the disclosed implementations can be realized in any device capable of presenting a user interface on a display device, including but not limited to: desktop or portable computers; electronic devices;
telephones; mobile phones; display systems; televisions; monitors; navigation systems; portable media players/recorders; personal digital assistants; game systems; handheld electronic devices; and embedded electronic devices or appliances.
[0090] In some implementations, the system 600 includes one or more processors 602 (e.g., CPU), optionally one or more display devices 604 (e.g., CRT, LCD, etc.), a microphone interface 606, one or more network interfaces 608 (e.g., USB, Ethernet, FireWire ports, etc.), optionally one or more input devices 610 (e.g., mouse, keyboard, etc.) and one or more computer-readable mediums 612. Each of these components is operatively coupled to one or more buses 614 (e.g., EISA, PCI, USB, FireWire , NuBus, PDS, etc.).
[0091] In some implementations, there are no display devices or input devices and the system 600 just performs sampling and encoding (e.g., generating descriptors, etc.) in the background without user input.
[0092] The term "computer-readable medium" refers to arty medium that participates in providing instructions to a processor 602 for execution, including without limitation, non-volatile media (e.g., optical or magnetic disks), volatile media (e.g., memory) and transmission media. Transmission inedia includes, without limitation, coaxial cables, copper wire and fiber optics. Transmission media can also take the form of acoustic, light or radio frequency waves.
[0093] The computer-readable medium(s) 612 further includes an operating system 616 (e.g., Mac OSO, Windows0, Unix, Linux, etc.), a network communications module 618, client software 620 and one or more applications 622.
The operating system 616 can be multi-user, inultiprocessing, multitasking, multithreading, real-time and the like. The operating system 616 performs basic tasks, including but not limited to: recognizing input from input devices 610;
sending output to display devices 604; keeping track of files and directories on storage devices 612; controlling peripheral devices (e.g., disk drives, printers, image capture device, etc.); and managing traffic on the one or more buses 614.
The operating system 616 can be multi-user, inultiprocessing, multitasking, multithreading, real-time and the like. The operating system 616 performs basic tasks, including but not limited to: recognizing input from input devices 610;
sending output to display devices 604; keeping track of files and directories on storage devices 612; controlling peripheral devices (e.g., disk drives, printers, image capture device, etc.); and managing traffic on the one or more buses 614.
[0094] The network corrunurdcations module 618 includes various comporients lor establishing and maintaining network connections (e.g., software for impletnex-tting cominunication protocols, such as TCP/IP, HTTP, Ethernet, USB, FireWire(D, etc.).
[0095] The client software 620 provides various software components for implementing the client-side of the mass personalization applications and for performing the various client-side functions described with respect to FIGS. 1-5 (e.g., ambient audio identification). In some implementations, some or all of the processes performed by the client software 620 can be integrated into the operating system 616. In some implementations, the processes can be at least partially implemented in digital electronic circuitry, or in computer hardware, firmware, software, or in any combination thereof.
[0096] Other applications 624 can include any other software application, including but not limited to: word processors, browsers, email, Instant Messaging, media players, telephony software, etc.
Detecting Avertisenzents and Rebroadcasts Repetition Detection [0097] When preparing a database for search, it helps to be able to pre-flag repeated material using the descriptors previously described. Repeating material can include but is not limited to repeating shows, advertisements, sub-segments (e.g., stock footage in news shows), etc. Using these flags, repeated material can be presented in a way that does not push all other material beyond the attention span of a user conducting a search (e.g., beyond the first 10-20 hits). The process described below provides a way to detect those duplicates prior to any search queries on the database.
Video Ad Removal [0098] One of the complaints that broadcasters have had about allowing material to be searched and played back is the rebroadcast of embedded advertising.
From the point of view of the broadcasters, this rebroadcast is counterproductive: it lowers the value of the broadcasts that the advertiser pays for directly, since it provides that advertiser with free advertising. Ui-tless old advertisements are removed and new advertisements are put in place in a way that returris some review to the original broadcasters, they do not profit from the replay of their previously broadcast material. The process 700 described below provides a way of detecting embedded advertisement by looking for repetitions, possibly in conjunction with other criteria (e.g., duration, volume, visual activity, bracketing blanl<
frames, etc.).
Video Summarization [0099] If a"summary"' (i.e., shorter version) of non-repeated program material is needed, one way to get that is to remove the advertisements (as detected by repeated material) and to take segments from the material just preceding and just following the advertisemertt location. On broadcast television, these positions in the program typically contain "teasers" (before the ads) and "recaps" (just after the ads).
If a summary is to be made of a news program that includes a mix of non-repeated and repeated non-advertisement material, typically the repeated non-advertisement material corresponds to a sound bite. These segments generally contribute less information than the anchorperson's narration of the news story and are good candidates for removal. If a suinmary is to be made of a narrative program (e.g. a movie or a serial installment), repeated audio tracks typically correspond to theme sounds, mood music, or silence. Again, these are typically good segments to remove from a summary video. The process 700 described below provides a way of detecting these repeated audio tracks so they can be removed from the summary video.
Repetition Detectiozz Process [00100] FIG. 7 is a flow diagram of one embodiment of a repetition detection process 700 in accordance. The steps of process 700 do not have to be completed in any particular order and at least some steps can be performed at the same time in a multi-tlu-eading or parallel processing environment.
Detecting Avertisenzents and Rebroadcasts Repetition Detection [0097] When preparing a database for search, it helps to be able to pre-flag repeated material using the descriptors previously described. Repeating material can include but is not limited to repeating shows, advertisements, sub-segments (e.g., stock footage in news shows), etc. Using these flags, repeated material can be presented in a way that does not push all other material beyond the attention span of a user conducting a search (e.g., beyond the first 10-20 hits). The process described below provides a way to detect those duplicates prior to any search queries on the database.
Video Ad Removal [0098] One of the complaints that broadcasters have had about allowing material to be searched and played back is the rebroadcast of embedded advertising.
From the point of view of the broadcasters, this rebroadcast is counterproductive: it lowers the value of the broadcasts that the advertiser pays for directly, since it provides that advertiser with free advertising. Ui-tless old advertisements are removed and new advertisements are put in place in a way that returris some review to the original broadcasters, they do not profit from the replay of their previously broadcast material. The process 700 described below provides a way of detecting embedded advertisement by looking for repetitions, possibly in conjunction with other criteria (e.g., duration, volume, visual activity, bracketing blanl<
frames, etc.).
Video Summarization [0099] If a"summary"' (i.e., shorter version) of non-repeated program material is needed, one way to get that is to remove the advertisements (as detected by repeated material) and to take segments from the material just preceding and just following the advertisemertt location. On broadcast television, these positions in the program typically contain "teasers" (before the ads) and "recaps" (just after the ads).
If a summary is to be made of a news program that includes a mix of non-repeated and repeated non-advertisement material, typically the repeated non-advertisement material corresponds to a sound bite. These segments generally contribute less information than the anchorperson's narration of the news story and are good candidates for removal. If a suinmary is to be made of a narrative program (e.g. a movie or a serial installment), repeated audio tracks typically correspond to theme sounds, mood music, or silence. Again, these are typically good segments to remove from a summary video. The process 700 described below provides a way of detecting these repeated audio tracks so they can be removed from the summary video.
Repetition Detectiozz Process [00100] FIG. 7 is a flow diagram of one embodiment of a repetition detection process 700 in accordance. The steps of process 700 do not have to be completed in any particular order and at least some steps can be performed at the same time in a multi-tlu-eading or parallel processing environment.
[00101] The process 700 begins by creating a database of audio statistics from a set of content such as television feeds, video uploads, etc. (702). For example, the database could contain 32-bit/frame descriptors, as described in I<e et al.
Queries are taken from the database and run against the database to see where repetitions occur (704). In some implementations, a short segment of audio statistics is taken as a query and run checked for non-identity matches (matches that are not identical) using hashing techniques (e.g. direct hashing or locality sensitive hashing (LSH)) to achieve a short list of possible auditory matches. These candidate matches are then processed in a validation procedure, for example, as described in Ke, et al.
Content corresponding to a validated candidate match can be identified as repeating content (706).
Queries are taken from the database and run against the database to see where repetitions occur (704). In some implementations, a short segment of audio statistics is taken as a query and run checked for non-identity matches (matches that are not identical) using hashing techniques (e.g. direct hashing or locality sensitive hashing (LSH)) to achieve a short list of possible auditory matches. These candidate matches are then processed in a validation procedure, for example, as described in Ke, et al.
Content corresponding to a validated candidate match can be identified as repeating content (706).
[00102] The non-identity matches that are strongest are "grown" forwards and backwards in time, to find the begiruling and ending points of the repeated material (708). In some implementations, this can be done using known dynamic programming tecl-uliques (e.g., Viterbi decoding). In extending the match forward in time, the last time slice in the strong "seed" match is set as "matching"
and the last time slice of the first below-believable-strength match for the same database -- -offset between the query and the match is set as "not matching." In some implementations, match scores for individual frames in between these two fixed points are used as observations and a first-order Markov model allowing within state transitions plus a single transition from "matching" to "not-matching"
states is used. The transition probability from matching to not matching to 1/L can be set somewhat arbitrarily, where L is the number of frames between these two fixed pouits, corresponding to the least knowledge of the transition location within the allowed range. Another possibility for selecting transition probabilities would use the match strength profiles to bias this estimate to an earlier or later transition. But this would increase the complexity of the dynamic programining model and is not likely to improve the results, since the match strengths are already used as observations within this period. The same process is used to grow the segment matches backwards in time (e.g., just switch past/future and run the same algorithrn).
and the last time slice of the first below-believable-strength match for the same database -- -offset between the query and the match is set as "not matching." In some implementations, match scores for individual frames in between these two fixed points are used as observations and a first-order Markov model allowing within state transitions plus a single transition from "matching" to "not-matching"
states is used. The transition probability from matching to not matching to 1/L can be set somewhat arbitrarily, where L is the number of frames between these two fixed pouits, corresponding to the least knowledge of the transition location within the allowed range. Another possibility for selecting transition probabilities would use the match strength profiles to bias this estimate to an earlier or later transition. But this would increase the complexity of the dynamic programining model and is not likely to improve the results, since the match strengths are already used as observations within this period. The same process is used to grow the segment matches backwards in time (e.g., just switch past/future and run the same algorithrn).
[00103] In some implementations the audio cues are combined with non-auditory information (e.g., visual cues) to obtain higher matching accuracies.
For example, the matches that are found with audio matching can then be verified (or checked a second time) by using simple visual similarity inetrics (710). These metrics can include but are not limited to: color histograms (e.g., frequencies of similar colors in two images), statistics on nuYnber and distribution of edges, etc.
These need not be computed only over the entire image, but can be computed for sub-regions of the images as well, and coinpared to the corresponding sub-regions in the target image.
For example, the matches that are found with audio matching can then be verified (or checked a second time) by using simple visual similarity inetrics (710). These metrics can include but are not limited to: color histograms (e.g., frequencies of similar colors in two images), statistics on nuYnber and distribution of edges, etc.
These need not be computed only over the entire image, but can be computed for sub-regions of the images as well, and coinpared to the corresponding sub-regions in the target image.
[00104] For those applications that are looking for advertisements (in contrast with all types of repeated material), the results of repeated-material detection can be coinbined with metrics aimed at distinguishing advertisements from non-advertisements (712). These distinguishing characteristics can rely on advertising conventions, such as durations (e.g., 10/15/30-second spots are common), on volume (e.g., advertisements tend to be louder than surrounding program material, so if the repeated material is louder than the material on either side, it is more likely to be an advertisement), on visual activity (e.g., advertisements tend to have more rapid transitions between shots and more within-shot motion, so if the repeated material has larger frame differences than the material on either side, it is more likely to be an advertisement), and on bracketing blank frames (locally inserted advertisements typically do not completely fill the slot that is left for it by the national feed, resulting in black frames and silence at a spacing that is a multiple of 30 seconds).
[00105] Once advertisements are identified, material surrounding the advertisements can be analyzed and statistics can be generated. For example, statistics can be generated about how many times a particular product is advertised using a particular creative (e.g., images, text), or how many times a particular seginent is aired, etc. In some implementations, one or more old advertisements can be removed or replaced with new advertisements. Additional techniques for advertisement detection and replaceYnent are described in Covell, M., Baluja, S., Fiiik, M., Advertisement Detection and Replacement Using Acoustic and Visual Repetition, IEEE Signal Processing Society, MMSP 2006 International Workshop on Multimedia Signal Processing, October 3-6, 2006, BC Canada, which article is incorporated by reference herein in its entirety.
[00106] In some implementations, information from content owners about the detailed structure of the content (e.g., where ad material was inserted, where programs were repeated) could be used to augment the process 700 and increase matching accuracies. In some implementations, video statistics can be used to determine repetition instead of audio. In other implementations, a combination of video and audio statistics can be used.
Audio Snippet Auctions [00107] In some implementations, advertisers can participate in auctions related to the presence of ambient audio that is related to the product or service that the advertiser want to sell. For example, multiple advertisers could bid in an auction for the right to associate its products or services with an audio snippet or descriptor associated with "Seinfeld." The winner of the auction could then put some related information in front of the viewer (e.g., the sponsored links) whenever the subject ambient audio is present. In some implementations, advertisers could bid on ambient audio snippets having a meta-level description. For example, advertisers could bid on audio that is associated with a television ad (e.g., this is the audio associated with a Ford Explorer TV ad), on closed captioning (e.g., the captioning says "Yankees baseball"), on program seg.tnent location (e.g., this audio will occur 15 min into the "Seinfeld" and will occur 3 minutes after the previous coinmercial break and 1 min before the next cominercial break), or on low-level acoustic or visual properties (e.g., "background music," "conversational voices,"
"explosive-like", etc.) [00108] In some implementations, one or more mass personalization applications can be run in the background while the user performs other tasks such as browsing another web site (e.g., a sponsored Iirik). Material that is related to a media broadcast (e.g., television contei-it) can participate in the same sponsored link auctions as material that is related to another content source (e.g., web site content).
For example, TV related ads can be mixed with ads that correspond to the content of a current web page.
Audio Snippet Auctions [00107] In some implementations, advertisers can participate in auctions related to the presence of ambient audio that is related to the product or service that the advertiser want to sell. For example, multiple advertisers could bid in an auction for the right to associate its products or services with an audio snippet or descriptor associated with "Seinfeld." The winner of the auction could then put some related information in front of the viewer (e.g., the sponsored links) whenever the subject ambient audio is present. In some implementations, advertisers could bid on ambient audio snippets having a meta-level description. For example, advertisers could bid on audio that is associated with a television ad (e.g., this is the audio associated with a Ford Explorer TV ad), on closed captioning (e.g., the captioning says "Yankees baseball"), on program seg.tnent location (e.g., this audio will occur 15 min into the "Seinfeld" and will occur 3 minutes after the previous coinmercial break and 1 min before the next cominercial break), or on low-level acoustic or visual properties (e.g., "background music," "conversational voices,"
"explosive-like", etc.) [00108] In some implementations, one or more mass personalization applications can be run in the background while the user performs other tasks such as browsing another web site (e.g., a sponsored Iirik). Material that is related to a media broadcast (e.g., television contei-it) can participate in the same sponsored link auctions as material that is related to another content source (e.g., web site content).
For example, TV related ads can be mixed with ads that correspond to the content of a current web page.
[00109] Various modifications may be made to the disclosed implementations and still be within the scope of the following claims.
Claims (60)
1. A method comprising:
receiving a descriptor identifying ambient audio associated with a media broadcast;
comparing the descriptor to reference descriptors associated with the media broadcast; and aggregating personalized information related to the media broadcast based on the result of the comparison.
receiving a descriptor identifying ambient audio associated with a media broadcast;
comparing the descriptor to reference descriptors associated with the media broadcast; and aggregating personalized information related to the media broadcast based on the result of the comparison.
2. The method of claim 1, where comparing the descriptor to reference descriptors further comprises:
querying a database of reference descriptors using the received descriptor;
and determining one or more reference descriptors that match the received descriptor based on matching criteria.
querying a database of reference descriptors using the received descriptor;
and determining one or more reference descriptors that match the received descriptor based on matching criteria.
3. The method of claim 2, where determining one or more reference descriptors further comprises:
determining a set of candidate reference descriptors based on the matching criteria; and validating the set of candidate references descriptors using a validation procedure.
determining a set of candidate reference descriptors based on the matching criteria; and validating the set of candidate references descriptors using a validation procedure.
4. The method of claim 3, where determining a set of candidate reference descriptors further comprises:
scoring the reference descriptors based on temporal consistency with the received descriptor; and determining the set of candidate reference descriptors from the scores.
scoring the reference descriptors based on temporal consistency with the received descriptor; and determining the set of candidate reference descriptors from the scores.
5. The method of claim 1, where receiving the reference descriptors from a database of reference descriptors.
6. The method of claim 1, where aggregating personalized information further comprises:
providing a communication link with a commenting medium.
providing a communication link with a commenting medium.
7. A method comprising:
receiving a first descriptor identifying ambient audio associated with a first media broadcast;
receiving a second descriptor identifying ambient audio associated with a second media broadcast;
comparing the first and second descriptors to determine if the first and second media broadcasts are the same; and aggregating personalized information based on the result of the comparison.
receiving a first descriptor identifying ambient audio associated with a first media broadcast;
receiving a second descriptor identifying ambient audio associated with a second media broadcast;
comparing the first and second descriptors to determine if the first and second media broadcasts are the same; and aggregating personalized information based on the result of the comparison.
8. A method comprising:
detecting ambient audio associated with a media broadcast;
generating descriptors identifying the media broadcast;
transmitting the descriptors to a network resource; and receiving aggregated personalized information from the network resource application server based on the descriptors.
detecting ambient audio associated with a media broadcast;
generating descriptors identifying the media broadcast;
transmitting the descriptors to a network resource; and receiving aggregated personalized information from the network resource application server based on the descriptors.
9. The method of claim 8, where generating descriptors further comprises:
recording snippets of ambient audio;
decomposing the ambient audio snippets into overlapping frames; and converting the frames into descriptors identifying statistical summaries of the ambient audio snippets.
recording snippets of ambient audio;
decomposing the ambient audio snippets into overlapping frames; and converting the frames into descriptors identifying statistical summaries of the ambient audio snippets.
10. The method of claim 8, further comprising:
training the descriptors to overcome noise.
training the descriptors to overcome noise.
11. A system comprising:
a database of reference descriptors; and a server operatively coupled to the database and to a client system, the database server configurable to receive a descriptor from the client system for identifying ambient audio associated with a media broadcast, comparing the received descriptor with one or more reference descriptors, and aggregating personalized information related to the media broadcast based on the result of the comparison.
a database of reference descriptors; and a server operatively coupled to the database and to a client system, the database server configurable to receive a descriptor from the client system for identifying ambient audio associated with a media broadcast, comparing the received descriptor with one or more reference descriptors, and aggregating personalized information related to the media broadcast based on the result of the comparison.
12. The system of claim 11, where the received descriptor is generated from ambient audio samples.
13. The system of claim 11, where the received descriptor is a compressed file containing one or more audio signature components.
14. The system of claim 11, where the database server receives a client system identifier from the client system for identifying the client system.
15. The system of claim 11, where the personalized information includes information associated with a commenting medium.
16. The system of claim 11, where the personalized information includes information associated with advertising.
17. The system of claim 11, where the reference descriptors are periodically updated from recent media broadcasts.
18. The system of claim 11, where the personalized information is served to the client system in a web page.
19. The system of claim 11, where the client system includes a display device for enabling a user to interact with a mass personalization application.
20. The system of claim 11 , where the client system monitors and records ambient audio at selectable periods of time.
21. The system of claim 11, where the received descriptor is encoded so that the ambient audio signal cannot be recovered.
22. The system of claim 11, where the received descriptor is encrypted.
23. The system of claim 11, where the received descriptor is sent to the database server as a query submission in response to a trigger event at the client system.
24. The system of claim 11, where the received descriptor is sent to the audio database server as part of a streaming process.
25. The system of claim 11, where the reference descriptors are generated by one or more client systems.
26. The system of claim 11, where the personalized information includes information for establishing a communication link between users in the same geographic location.
27. The system of claim 11, where the match is determined using locality sensitive hashing.
28. The system of claim 11, where the received descriptor represents an identifying statistical summary of an audio sample.
29. The system of claim 11, where the match is determined using reference descriptors that are temporally consistent with the descriptor generated by the client system.
30. A method comprising:
receiving descriptors from multiple client systems, the descriptors identifying ambient audio associated with a real time media broadcast;
comparing the descriptors with reference descriptors to determine positive matches, where positive matches are determined based at least in part on temporal consistency between the received descriptors and the reference descriptors;
creating a social community based on the positive matches; and transmitting information relating to the social community to the client systems.
receiving descriptors from multiple client systems, the descriptors identifying ambient audio associated with a real time media broadcast;
comparing the descriptors with reference descriptors to determine positive matches, where positive matches are determined based at least in part on temporal consistency between the received descriptors and the reference descriptors;
creating a social community based on the positive matches; and transmitting information relating to the social community to the client systems.
31. The method of claim 30, where the transmitted information includes a communication link for providing a communication channel between the client systems and the social community.
32. The method of claim 30, where the descriptors are generated using wavelets.
33. A method, comprising:
receiving descriptors identifying ambient audio associated with a media broadcast;
comparing the descriptors to one or more reference descriptors; and determining a rating for the media broadcast based at least in part on the results of the comparison.
receiving descriptors identifying ambient audio associated with a media broadcast;
comparing the descriptors to one or more reference descriptors; and determining a rating for the media broadcast based at least in part on the results of the comparison.
34. The method of claim 33, where determining a rating further comprises:
determining a count of matches generated by comparing the received descriptors with the reference descriptors; and determining a rating based at least in part on the count.
determining a count of matches generated by comparing the received descriptors with the reference descriptors; and determining a rating based at least in part on the count.
35. The method of claim 33, further comprising:
providing information to a device based on the rating.
providing information to a device based on the rating.
36. The method of claim 35, further comprising:
determining a change in the rating;
modifying the information in response to the change in the rating; and providing the modified information to the device.
determining a change in the rating;
modifying the information in response to the change in the rating; and providing the modified information to the device.
37. The method of claim 33, further comprising:
providing the rating to a device.
providing the rating to a device.
38. The method of claim 33, where determining the rating further comprises:
receiving information from a device related to the media broadcast;
determining statistics using the information; and determining the rating from the statistics.
receiving information from a device related to the media broadcast;
determining statistics using the information; and determining the rating from the statistics.
39. The method of claim 33, where determining a rating further comprises:
determining the average number of users receiving the media broadcast.
determining the average number of users receiving the media broadcast.
40. The method of claim 33, where determining a rating further comprises:
determining the average number of times users received the media broadcast.
determining the average number of times users received the media broadcast.
41. The method of claim 33, where determining a rating further comprises:
determining the maximum number of users receiving the media broadcast.
determining the maximum number of users receiving the media broadcast.
42. The method of claim 33, where determining a rating further comprises:
determining the minimum number of users receiving the media broadcast.
determining the minimum number of users receiving the media broadcast.
43. The method of claim 33, further comprising:
associating the rating with demographic group data; and providing the rating to a device associated with the demographic group.
associating the rating with demographic group data; and providing the rating to a device associated with the demographic group.
44. The method of claim 33, further comprising:
associating the rating with geographic group data; and providing the rating to a device associated with the geographic group.
associating the rating with geographic group data; and providing the rating to a device associated with the geographic group.
45. A method, comprising:
generating descriptors identifying ambient audio associated with a media broadcast;
providing the descriptors to a ratings provider for determining a rating for the media broadcast based on the descriptors;
receiving the rating from the ratings provider; and displaying the rating on a display.
generating descriptors identifying ambient audio associated with a media broadcast;
providing the descriptors to a ratings provider for determining a rating for the media broadcast based on the descriptors;
receiving the rating from the ratings provider; and displaying the rating on a display.
46. The method of claim 45, further comprising:
receiving information from the ratings provider, where the information is associated with the media broadcast; and displaying the information on a display.
receiving information from the ratings provider, where the information is associated with the media broadcast; and displaying the information on a display.
47. The method of claim 45, where determining the rating further comprises:
collecting information related to the media broadcast;
providing the information to a rating system;
receiving a rating from the rating system, where the rating is based at least in part on the collected information; and displaying the rating on a display.
collecting information related to the media broadcast;
providing the information to a rating system;
receiving a rating from the rating system, where the rating is based at least in part on the collected information; and displaying the rating on a display.
48. The method of claim 45, where determining a rating further comprises:
determining the average number of users receiving the media broadcast.
determining the average number of users receiving the media broadcast.
49. The method of claim 45, where determining a rating further comprises:
determining the average number of times users received the media broadcast.
determining the average number of times users received the media broadcast.
50. The method of claim 45, where determining a rating further comprises:
determining the maximum number of users receiving the media broadcast.
determining the maximum number of users receiving the media broadcast.
51. The method of claim 45, where determining a rating further comprises:
determining the minimum number of users receiving the media broadcast.
determining the minimum number of users receiving the media broadcast.
52. The method of claim 45, further comprising:
receiving from the ratings provider information associated with a demographic group.
receiving from the ratings provider information associated with a demographic group.
53. The method of claim 45, further comprising:
receiving from the ratings provider information associated with geographic group data.
receiving from the ratings provider information associated with geographic group data.
54. A method, comprising:
recording ambient audio snippets from a media broadcast;
generating a descriptor from the ambient audio snippets; and providing the descriptor to a ratings provider.
recording ambient audio snippets from a media broadcast;
generating a descriptor from the ambient audio snippets; and providing the descriptor to a ratings provider.
55. The method of claim 54, comprising:
associating a product or service with the descriptor; and providing information to one or more users that is related to the product or service.
associating a product or service with the descriptor; and providing information to one or more users that is related to the product or service.
56. The method of claim 54, further comprising:
receiving user input confirming receipt of the media broadcast; and determining the rating based on the user input.
receiving user input confirming receipt of the media broadcast; and determining the rating based on the user input.
57. The method of claim 54, further comprising:
capturing a digital image of users receiving the media broadcast; and determining the rating at least in part on the digital image.
capturing a digital image of users receiving the media broadcast; and determining the rating at least in part on the digital image.
58. A system, comprising:
a database of reference descriptors; and a server operatively coupled to the database and to a client system, the server configurable to receive a descriptor from the client system for identifying ambient audio associated with a media broadcast, comparing the received descriptor with one or more reference descriptors, and determining a rating for the media broadcast based at least in part on the results of the comparison.
a database of reference descriptors; and a server operatively coupled to the database and to a client system, the server configurable to receive a descriptor from the client system for identifying ambient audio associated with a media broadcast, comparing the received descriptor with one or more reference descriptors, and determining a rating for the media broadcast based at least in part on the results of the comparison.
59. A method comprising:
receiving descriptors from multiple client systems, the descriptors identifying ambient audio associated with a real time media broadcast;
comparing the descriptors with reference descriptors to determine positive matches, where positive matches are determined based at least in part on temporal consistency between the received descriptors and the reference descriptors;
generating ratings based on the positive matches; and transmitting the ratings to the client systems.
receiving descriptors from multiple client systems, the descriptors identifying ambient audio associated with a real time media broadcast;
comparing the descriptors with reference descriptors to determine positive matches, where positive matches are determined based at least in part on temporal consistency between the received descriptors and the reference descriptors;
generating ratings based on the positive matches; and transmitting the ratings to the client systems.
60. The method of claim 59, further comprising:
using the descriptors to detect an advertisement in the media broadcast;
generating statistics on the advertisement; and transmitting the statistics to an advertiser associated with the advertisement.
using the descriptors to detect an advertisement in the media broadcast;
generating statistics on the advertisement; and transmitting the statistics to an advertiser associated with the advertisement.
Applications Claiming Priority (5)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US74076005P | 2005-11-29 | 2005-11-29 | |
US60/740,760 | 2005-11-29 | ||
US82388106P | 2006-08-29 | 2006-08-29 | |
US60/823,881 | 2006-08-29 | ||
PCT/US2006/045551 WO2007064641A2 (en) | 2005-11-29 | 2006-11-27 | Social and interactive applications for mass media |
Publications (2)
Publication Number | Publication Date |
---|---|
CA2631151A1 true CA2631151A1 (en) | 2007-06-07 |
CA2631151C CA2631151C (en) | 2015-10-13 |
Family
ID=38092724
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CA2631151A Expired - Fee Related CA2631151C (en) | 2005-11-29 | 2006-11-27 | Social and interactive applications for mass media |
CA002631270A Abandoned CA2631270A1 (en) | 2005-11-29 | 2006-11-27 | Detecting repeating content in broadcast media |
Family Applications After (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CA002631270A Abandoned CA2631270A1 (en) | 2005-11-29 | 2006-11-27 | Detecting repeating content in broadcast media |
Country Status (10)
Country | Link |
---|---|
US (6) | US8442125B2 (en) |
EP (3) | EP1986145A1 (en) |
JP (3) | JP2009524273A (en) |
KR (2) | KR101371574B1 (en) |
AU (2) | AU2006320692A1 (en) |
BR (2) | BRPI0619388A2 (en) |
CA (2) | CA2631151C (en) |
ES (1) | ES2386977T3 (en) |
IL (1) | IL191814A0 (en) |
WO (2) | WO2007064641A2 (en) |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
WO2009140759A1 (en) * | 2008-05-22 | 2009-11-26 | Unify4Life Corporation | Interactive event guide with enhanced features |
Families Citing this family (433)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6834308B1 (en) * | 2000-02-17 | 2004-12-21 | Audible Magic Corporation | Method and apparatus for identifying media content presented on a media playing device |
US8205237B2 (en) | 2000-09-14 | 2012-06-19 | Cox Ingemar J | Identifying works, using a sub-linear time search, such as an approximate nearest neighbor search, for initiating a work-based action, such as an action on the internet |
US8117281B2 (en) * | 2006-11-02 | 2012-02-14 | Addnclick, Inc. | Using internet content as a means to establish live social networks by linking internet users to each other who are simultaneously engaged in the same and/or similar content |
US7239981B2 (en) | 2002-07-26 | 2007-07-03 | Arbitron Inc. | Systems and methods for gathering audience measurement data |
US8959016B2 (en) | 2002-09-27 | 2015-02-17 | The Nielsen Company (Us), Llc | Activating functions in processing devices using start codes embedded in audio |
US9711153B2 (en) | 2002-09-27 | 2017-07-18 | The Nielsen Company (Us), Llc | Activating functions in processing devices using encoded audio and detecting audio signatures |
US9055239B2 (en) | 2003-10-08 | 2015-06-09 | Verance Corporation | Signal continuity assessment using embedded watermarks |
US10387920B2 (en) | 2003-12-23 | 2019-08-20 | Roku, Inc. | System and method for offering and billing advertisement opportunities |
US10032192B2 (en) * | 2003-12-23 | 2018-07-24 | Roku, Inc. | Automatic localization of advertisements |
US9865017B2 (en) | 2003-12-23 | 2018-01-09 | Opentv, Inc. | System and method for providing interactive advertisement |
US7623823B2 (en) * | 2004-08-31 | 2009-11-24 | Integrated Media Measurement, Inc. | Detecting and measuring exposure to media content items |
US20060224798A1 (en) * | 2005-02-22 | 2006-10-05 | Klein Mark D | Personal music preference determination based on listening behavior |
US20070016918A1 (en) * | 2005-05-20 | 2007-01-18 | Alcorn Allan E | Detecting and tracking advertisements |
US20070118455A1 (en) * | 2005-11-18 | 2007-05-24 | Albert William J | System and method for directed request for quote |
JP2009524273A (en) | 2005-11-29 | 2009-06-25 | グーグル・インコーポレーテッド | Repetitive content detection in broadcast media |
US8132103B1 (en) * | 2006-07-19 | 2012-03-06 | Aol Inc. | Audio and/or video scene detection and retrieval |
US8751502B2 (en) * | 2005-11-29 | 2014-06-10 | Aol Inc. | Visually-represented results to search queries in rich media content |
US20070136741A1 (en) * | 2005-12-09 | 2007-06-14 | Keith Stattenfield | Methods and systems for processing content |
US20070162761A1 (en) * | 2005-12-23 | 2007-07-12 | Davis Bruce L | Methods and Systems to Help Detect Identity Fraud |
US20150082342A1 (en) * | 2006-06-15 | 2015-03-19 | Social Commenting, Llc | System and method for viewers to comment on television content for display on remote websites using a web browser |
US8019162B2 (en) * | 2006-06-20 | 2011-09-13 | The Nielsen Company (Us), Llc | Methods and apparatus for detecting on-screen media sources |
US7831531B1 (en) | 2006-06-22 | 2010-11-09 | Google Inc. | Approximate hashing functions for finding similar content |
US8732019B2 (en) | 2006-07-21 | 2014-05-20 | Say Media, Inc. | Non-expanding interactive advertisement |
EP2050057A4 (en) * | 2006-07-21 | 2011-06-29 | Videoegg Inc | Systems and methods for interaction prompt initiated video advertising |
US20090018920A1 (en) | 2006-07-21 | 2009-01-15 | Videoegg, Inc. | Interaction Prompt for Interactive Advertising |
US9208500B2 (en) | 2006-07-21 | 2015-12-08 | Microsoft Technology Licensing, Llc | Fixed position multi-state interactive advertisement |
US8707459B2 (en) | 2007-01-19 | 2014-04-22 | Digimarc Corporation | Determination of originality of content |
US9654447B2 (en) | 2006-08-29 | 2017-05-16 | Digimarc Corporation | Customized handling of copied content based on owner-specified similarity thresholds |
US8010511B2 (en) | 2006-08-29 | 2011-08-30 | Attributor Corporation | Content monitoring and compliance enforcement |
US8411977B1 (en) | 2006-08-29 | 2013-04-02 | Google Inc. | Audio identification using wavelet-based signatures |
US8738749B2 (en) | 2006-08-29 | 2014-05-27 | Digimarc Corporation | Content monitoring and host compliance evaluation |
US8615778B1 (en) | 2006-09-28 | 2013-12-24 | Qurio Holdings, Inc. | Personalized broadcast system |
US7895275B1 (en) | 2006-09-28 | 2011-02-22 | Qurio Holdings, Inc. | System and method providing quality based peer review and distribution of digital content |
AU2007316477A1 (en) * | 2006-11-03 | 2008-05-15 | Google Inc. | Content management system |
US7707224B2 (en) | 2006-11-03 | 2010-04-27 | Google Inc. | Blocking of unlicensed audio content in video files on a video hosting website |
US8296195B2 (en) * | 2006-11-13 | 2012-10-23 | Joseph Harb | Broadcast programming data capture |
US8718538B2 (en) * | 2006-11-13 | 2014-05-06 | Joseph Harb | Real-time remote purchase-list capture system |
US8391155B2 (en) * | 2006-11-13 | 2013-03-05 | Joseph Harb | Digital content download associated with corresponding radio broadcast items |
US8462645B1 (en) | 2006-11-13 | 2013-06-11 | Joseph Harb | Interactive advertising system, business methods and software |
US8310985B2 (en) * | 2006-11-13 | 2012-11-13 | Joseph Harb | Interactive radio advertising and social networking |
US9456250B2 (en) * | 2006-12-15 | 2016-09-27 | At&T Intellectual Property I, L.P. | Automatic rating optimization |
US10242415B2 (en) | 2006-12-20 | 2019-03-26 | Digimarc Corporation | Method and system for determining content treatment |
US9179200B2 (en) | 2007-03-14 | 2015-11-03 | Digimarc Corporation | Method and system for determining content treatment |
US8356039B2 (en) * | 2006-12-21 | 2013-01-15 | Yahoo! Inc. | Providing multiple media items to a consumer via a simplified consumer interaction |
US7890874B2 (en) | 2007-02-23 | 2011-02-15 | Dkcm, Inc. | Systems and methods for interactively displaying user images |
JP4281819B2 (en) * | 2007-04-02 | 2009-06-17 | ソニー株式会社 | Captured image data processing device, viewing information generation device, viewing information generation system, captured image data processing method, viewing information generation method |
US10489795B2 (en) | 2007-04-23 | 2019-11-26 | The Nielsen Company (Us), Llc | Determining relative effectiveness of media content items |
US20080265631A1 (en) * | 2007-04-30 | 2008-10-30 | Foremost Groups, Inc. | Folding ottoman |
US9911127B1 (en) * | 2007-05-02 | 2018-03-06 | Google Llc | Ratable video advertisements |
CA2685870A1 (en) * | 2007-05-03 | 2008-11-13 | Google Inc. | Monetization of original digital content contributions |
US8094872B1 (en) * | 2007-05-09 | 2012-01-10 | Google Inc. | Three-dimensional wavelet based video fingerprinting |
JP5090523B2 (en) * | 2007-06-06 | 2012-12-05 | ドルビー ラボラトリーズ ライセンシング コーポレイション | Method and apparatus for improving audio / video fingerprint search accuracy using a combination of multiple searches |
US7840502B2 (en) * | 2007-06-13 | 2010-11-23 | Microsoft Corporation | Classification of images as advertisement images or non-advertisement images of web pages |
US8611422B1 (en) | 2007-06-19 | 2013-12-17 | Google Inc. | Endpoint based video fingerprinting |
US20090021474A1 (en) * | 2007-07-17 | 2009-01-22 | Motorola, Inc. | System and method for displaying status information of a multimedia broadcast receiver on an ambient device |
US8620878B2 (en) * | 2007-07-19 | 2013-12-31 | Ustream, Inc. | System and method of distributing multimedia content |
EP2193420A4 (en) | 2007-07-27 | 2010-10-06 | Synergy Sports Technology Llc | System and method for using a website containing video playlists as input to a download manager |
US8238669B2 (en) * | 2007-08-22 | 2012-08-07 | Google Inc. | Detection and classification of matches between time-based media |
US8447032B1 (en) | 2007-08-22 | 2013-05-21 | Google Inc. | Generation of min-hash signatures |
US9633505B2 (en) * | 2007-09-07 | 2017-04-25 | Veritone, Inc. | System and method for on-demand delivery of audio content for use with entertainment creatives |
US20090089326A1 (en) * | 2007-09-28 | 2009-04-02 | Yahoo!, Inc. | Method and apparatus for providing multimedia content optimization |
US8332883B2 (en) | 2007-10-02 | 2012-12-11 | The Nielsen Company (Us), Llc | Providing actionable insights based on physiological responses from viewers of media |
US8521766B1 (en) | 2007-11-12 | 2013-08-27 | W Leo Hoarty | Systems and methods for providing information discovery and retrieval |
WO2009073634A1 (en) * | 2007-11-30 | 2009-06-11 | Emsense Corporation | Correlating media instance information with physiological responses from participating subjects |
US8938747B2 (en) * | 2007-12-06 | 2015-01-20 | At&T Intellectual Property I, L.P. | Rating multimedia programs accessed from a provider network |
WO2009082711A1 (en) * | 2007-12-20 | 2009-07-02 | G-Snap!, Inc. | Apparatus and method for providing real-time event updates |
US20090164590A1 (en) * | 2007-12-20 | 2009-06-25 | G-Snap!, Inc. | Apparatus and method for providing real-time event updates |
US8806021B2 (en) * | 2008-01-28 | 2014-08-12 | Sony Corporation | Methods, portable electronic devices, systems and computer program products for automatically creating social networking services (SNS) |
US8874076B2 (en) * | 2008-02-15 | 2014-10-28 | Alcatel Lucent | Method to allow community-identity based communications using mobile phones |
US8184953B1 (en) * | 2008-02-22 | 2012-05-22 | Google Inc. | Selection of hash lookup keys for efficient retrieval |
US9043483B2 (en) * | 2008-03-17 | 2015-05-26 | International Business Machines Corporation | View selection in a vehicle-to-vehicle network |
WO2009116856A2 (en) * | 2008-03-18 | 2009-09-24 | Civolution B.V. | Generating statistics of popular content |
US20090259519A1 (en) * | 2008-04-14 | 2009-10-15 | Microsoft Corporation | Advertisements Targeted to Social Groups that Establish Program Popularity |
US8650094B2 (en) * | 2008-05-07 | 2014-02-11 | Microsoft Corporation | Music recommendation using emotional allocation modeling |
US8344233B2 (en) | 2008-05-07 | 2013-01-01 | Microsoft Corporation | Scalable music recommendation by search |
WO2009149063A1 (en) * | 2008-06-02 | 2009-12-10 | Azuki Systems, Inc. | Media mashup system |
US20090307084A1 (en) * | 2008-06-10 | 2009-12-10 | Integrated Media Measurement, Inc. | Measuring Exposure To Media Across Multiple Media Delivery Mechanisms |
US20090307061A1 (en) * | 2008-06-10 | 2009-12-10 | Integrated Media Measurement, Inc. | Measuring Exposure To Media |
US20090319571A1 (en) * | 2008-06-23 | 2009-12-24 | Itel Llc | Video indexing |
US8380564B2 (en) | 2008-07-30 | 2013-02-19 | At&T Intellectual Property I, Lp | System and method for internet protocol television product placement data |
US20150026707A1 (en) * | 2008-08-12 | 2015-01-22 | Iheartmedia Management Services, Inc. | Audience response determination to digital-media content |
US20100043021A1 (en) * | 2008-08-12 | 2010-02-18 | Clear Channel Management Services, Inc. | Determining audience response to broadcast content |
US20170034586A1 (en) * | 2008-10-08 | 2017-02-02 | Wakingapp Ltd. | System for content matching and triggering for reality-virtuality continuum-based environment and methods thereof |
US8121830B2 (en) | 2008-10-24 | 2012-02-21 | The Nielsen Company (Us), Llc | Methods and apparatus to extract data encoded in media content |
US9667365B2 (en) | 2008-10-24 | 2017-05-30 | The Nielsen Company (Us), Llc | Methods and apparatus to perform audio watermarking and watermark detection and extraction |
US8359205B2 (en) | 2008-10-24 | 2013-01-22 | The Nielsen Company (Us), Llc | Methods and apparatus to perform audio watermarking and watermark detection and extraction |
US9788043B2 (en) * | 2008-11-07 | 2017-10-10 | Digimarc Corporation | Content interaction methods and systems employing portable devices |
US8516533B2 (en) | 2008-11-07 | 2013-08-20 | Digimarc Corporation | Second screen methods and arrangements |
US20100205628A1 (en) * | 2009-02-12 | 2010-08-12 | Davis Bruce L | Media processing methods and arrangements |
US9355554B2 (en) * | 2008-11-21 | 2016-05-31 | Lenovo (Singapore) Pte. Ltd. | System and method for identifying media and providing additional media content |
US10880340B2 (en) | 2008-11-26 | 2020-12-29 | Free Stream Media Corp. | Relevancy improvement through targeting of information based on data gathered from a networked device associated with a security sandbox of a client device |
US8180891B1 (en) | 2008-11-26 | 2012-05-15 | Free Stream Media Corp. | Discovery, access control, and communication with networked services from within a security sandbox |
US10334324B2 (en) | 2008-11-26 | 2019-06-25 | Free Stream Media Corp. | Relevant advertisement generation based on a user operating a client device communicatively coupled with a networked media device |
US9154942B2 (en) | 2008-11-26 | 2015-10-06 | Free Stream Media Corp. | Zero configuration communication between a browser and a networked media device |
US10567823B2 (en) | 2008-11-26 | 2020-02-18 | Free Stream Media Corp. | Relevant advertisement generation based on a user operating a client device communicatively coupled with a networked media device |
US9961388B2 (en) | 2008-11-26 | 2018-05-01 | David Harrison | Exposure of public internet protocol addresses in an advertising exchange server to improve relevancy of advertisements |
US10419541B2 (en) | 2008-11-26 | 2019-09-17 | Free Stream Media Corp. | Remotely control devices over a network without authentication or registration |
US10631068B2 (en) | 2008-11-26 | 2020-04-21 | Free Stream Media Corp. | Content exposure attribution based on renderings of related content across multiple devices |
US10977693B2 (en) | 2008-11-26 | 2021-04-13 | Free Stream Media Corp. | Association of content identifier of audio-visual data with additional data through capture infrastructure |
US9986279B2 (en) | 2008-11-26 | 2018-05-29 | Free Stream Media Corp. | Discovery, access control, and communication with networked services |
US9519772B2 (en) | 2008-11-26 | 2016-12-13 | Free Stream Media Corp. | Relevancy improvement through targeting of information based on data gathered from a networked device associated with a security sandbox of a client device |
JP4887348B2 (en) * | 2008-11-27 | 2012-02-29 | ヤフー株式会社 | Event information providing apparatus and event information providing method |
JP4775671B2 (en) * | 2008-12-26 | 2011-09-21 | ソニー株式会社 | Information processing apparatus and method, and program |
US20100226526A1 (en) * | 2008-12-31 | 2010-09-09 | Modro Sierra K | Mobile media, devices, and signaling |
US8929719B2 (en) * | 2009-01-02 | 2015-01-06 | Harris Technology, Llc | Frame correlating content determination |
US9742849B2 (en) * | 2009-01-30 | 2017-08-22 | Hewlett-Packard Development Company, L.P. | Methods and systems for establishing collaborative communications between devices using ambient audio |
US8918333B2 (en) | 2009-02-23 | 2014-12-23 | Joseph Harb | Method, system and apparatus for interactive radio advertising |
US9015757B2 (en) * | 2009-03-25 | 2015-04-21 | Eloy Technology, Llc | Merged program guide |
US20100251279A1 (en) * | 2009-03-26 | 2010-09-30 | Clear Channel Management Services, Inc. | Delivering content related to a commercial media program |
CN102365871A (en) * | 2009-04-03 | 2012-02-29 | 日本电气株式会社 | Distribution system and method, conversion device, and program |
DE102009017315B3 (en) * | 2009-04-16 | 2010-10-28 | Freie Universität Berlin | Method for providing data on mobile terminals and mobile terminal for carrying out the method |
US8666528B2 (en) | 2009-05-01 | 2014-03-04 | The Nielsen Company (Us), Llc | Methods, apparatus and articles of manufacture to provide secondary content in association with primary broadcast media content |
WO2010132806A2 (en) * | 2009-05-14 | 2010-11-18 | Brand Affinity Technologies, Inc. | System and method for on-demand delivery of audio content for use with entertainment creatives |
US20100319015A1 (en) * | 2009-06-15 | 2010-12-16 | Richard Anthony Remington | Method and system for removing advertising content from television or radio content |
WO2011004370A1 (en) * | 2009-07-09 | 2011-01-13 | Carfosget Holdings, Ltd. | Method and apparatus for interactive audio |
US8407287B2 (en) | 2009-07-14 | 2013-03-26 | Radvision Ltd. | Systems, methods, and media for identifying and associating user devices with media cues |
CA3149767A1 (en) | 2009-07-16 | 2011-01-20 | Bluefin Labs, Inc. | Estimating and displaying social interest in time-based media |
US8229219B1 (en) * | 2009-08-06 | 2012-07-24 | Google Inc. | Full-length video fingerprinting |
NZ581850A (en) * | 2009-08-27 | 2011-12-22 | Eyemagnet Ltd | Informational content scheduling system and method |
US20110066942A1 (en) * | 2009-09-14 | 2011-03-17 | Barton James M | Multifunction Multimedia Device |
US8290918B1 (en) | 2009-09-29 | 2012-10-16 | Google Inc. | Robust hashing of digital media data |
US8161071B2 (en) | 2009-09-30 | 2012-04-17 | United Video Properties, Inc. | Systems and methods for audio asset storage and management |
US8677400B2 (en) | 2009-09-30 | 2014-03-18 | United Video Properties, Inc. | Systems and methods for identifying audio content using an interactive media guidance application |
US8245249B2 (en) * | 2009-10-09 | 2012-08-14 | The Nielson Company (Us), Llc | Methods and apparatus to adjust signature matching results for audience measurement |
US20110085781A1 (en) * | 2009-10-13 | 2011-04-14 | Rovi Technologies Corporation | Content recorder timing alignment |
US8428955B2 (en) * | 2009-10-13 | 2013-04-23 | Rovi Technologies Corporation | Adjusting recorder timing |
US8533760B1 (en) * | 2009-10-20 | 2013-09-10 | Arris Enterprises, Inc. | Reduced latency channel switching for IPTV |
US8121618B2 (en) | 2009-10-28 | 2012-02-21 | Digimarc Corporation | Intuitive computing methods and systems |
US8175617B2 (en) | 2009-10-28 | 2012-05-08 | Digimarc Corporation | Sensor-based mobile search, related methods and systems |
US9218530B2 (en) | 2010-11-04 | 2015-12-22 | Digimarc Corporation | Smartphone-based methods and systems |
US9830605B2 (en) * | 2009-10-30 | 2017-11-28 | At&T Intellectual Property I, L.P. | Apparatus and method for product marketing |
EP2497267B1 (en) * | 2009-11-03 | 2014-08-27 | Telefonaktiebolaget LM Ericsson (publ) | Streaming with optional broadcast delivery of data segments |
US8566876B2 (en) | 2009-11-04 | 2013-10-22 | At&T Intellectual Property I, Lp | System and method for interacting with social networking in an internet protocol television system |
US20110137976A1 (en) * | 2009-12-04 | 2011-06-09 | Bob Poniatowski | Multifunction Multimedia Device |
US8682145B2 (en) * | 2009-12-04 | 2014-03-25 | Tivo Inc. | Recording system based on multimedia content fingerprints |
US8625033B1 (en) | 2010-02-01 | 2014-01-07 | Google Inc. | Large-scale matching of audio and video |
US8355910B2 (en) | 2010-03-30 | 2013-01-15 | The Nielsen Company (Us), Llc | Methods and apparatus for audio watermarking a substantially silent media content presentation |
US9264785B2 (en) | 2010-04-01 | 2016-02-16 | Sony Computer Entertainment Inc. | Media fingerprinting for content determination and retrieval |
US8560583B2 (en) | 2010-04-01 | 2013-10-15 | Sony Computer Entertainment Inc. | Media fingerprinting for social networking |
US9185458B2 (en) * | 2010-04-02 | 2015-11-10 | Yahoo! Inc. | Signal-driven interactive television |
US20110251971A1 (en) * | 2010-04-08 | 2011-10-13 | International Business Machines Corporation | System and method for facilitating real-time collaboration in a customer support environment |
US20110251885A1 (en) * | 2010-04-09 | 2011-10-13 | Alcatel-Lucent Canada | Differentiated experience for user generated content (UGC) based on popularity |
US8265928B2 (en) * | 2010-04-14 | 2012-09-11 | Google Inc. | Geotagged environmental audio for enhanced speech recognition accuracy |
AU2011239567A1 (en) * | 2010-04-14 | 2012-12-06 | Sven Riethmueller | Platform-independent interactivity with media broadcasts |
US9729344B2 (en) * | 2010-04-30 | 2017-08-08 | Mitel Networks Corporation | Integrating a trigger button module into a mass audio notification system |
US20110276882A1 (en) * | 2010-05-04 | 2011-11-10 | Kai Buehler | Automatic grouping for users experiencing a specific broadcast media |
US9634855B2 (en) | 2010-05-13 | 2017-04-25 | Alexander Poltorak | Electronic personal interactive device that determines topics of interest using a conversational agent |
US8819714B2 (en) * | 2010-05-19 | 2014-08-26 | Cisco Technology, Inc. | Ratings and quality measurements for digital broadcast viewers |
US8649573B1 (en) * | 2010-06-14 | 2014-02-11 | Adobe Systems Incorporated | Method and apparatus for summarizing video data |
US9814977B2 (en) | 2010-07-13 | 2017-11-14 | Sony Interactive Entertainment Inc. | Supplemental video content on a mobile device |
US9159165B2 (en) | 2010-07-13 | 2015-10-13 | Sony Computer Entertainment Inc. | Position-dependent gaming, 3-D controller, and handheld as a remote |
US9143699B2 (en) | 2010-07-13 | 2015-09-22 | Sony Computer Entertainment Inc. | Overlay non-video content on a mobile device |
US9832441B2 (en) | 2010-07-13 | 2017-11-28 | Sony Interactive Entertainment Inc. | Supplemental content on a mobile device |
US8730354B2 (en) | 2010-07-13 | 2014-05-20 | Sony Computer Entertainment Inc | Overlay video content on a mobile device |
US20120020647A1 (en) * | 2010-07-21 | 2012-01-26 | Rovi Technologies Corporation | Filtering repeated content |
EA201001465A1 (en) * | 2010-07-29 | 2012-02-28 | Виктор Никифорович БОРЩОВ | FUNCTIONAL MODEL OF ASSISTANCE IN THE SOLUTION OF STATE PROBLEMS ON THE BASIS OF INFORMATION TECHNOLOGIES |
US8744860B2 (en) | 2010-08-02 | 2014-06-03 | At&T Intellectual Property I, L.P. | Apparatus and method for providing messages in a social network |
US8732697B2 (en) | 2010-08-04 | 2014-05-20 | Premkumar Jonnala | System, method and apparatus for managing applications on a device |
GB2483370B (en) | 2010-09-05 | 2015-03-25 | Mobile Res Labs Ltd | A system and method for engaging a person in the presence of ambient audio |
US8494851B2 (en) * | 2010-09-13 | 2013-07-23 | International Business Machines Corporation | System and method for contextual social network communications during phone conversation |
KR20120034378A (en) * | 2010-10-01 | 2012-04-12 | 엔에이치엔(주) | Advertisement information providing system through recognition of sound and method thereof |
US8606293B2 (en) | 2010-10-05 | 2013-12-10 | Qualcomm Incorporated | Mobile device location estimation using environmental information |
JP5987227B2 (en) * | 2010-10-25 | 2016-09-07 | サムスン エレクトロニクス カンパニー リミテッド | Social network-based TV broadcast content sharing method, TV broadcast content sharing server, method for receiving social network-based TV broadcast content sharing service, and TV device |
US10034034B2 (en) | 2011-07-06 | 2018-07-24 | Symphony Advanced Media | Mobile remote media control platform methods |
US20120136466A1 (en) * | 2010-11-28 | 2012-05-31 | Aron Weiss | System and method for identifying a broadcast source of ambient audio |
US8483725B2 (en) | 2010-12-03 | 2013-07-09 | Qualcomm Incorporated | Method and apparatus for determining location of mobile device |
US9542203B2 (en) | 2010-12-06 | 2017-01-10 | Microsoft Technology Licensing, Llc | Universal dock for context sensitive computing device |
US8923770B2 (en) | 2010-12-09 | 2014-12-30 | Microsoft Corporation | Cognitive use of multiple regulatory domains |
US8792429B2 (en) * | 2010-12-14 | 2014-07-29 | Microsoft Corporation | Direct connection with side channel control |
US8948382B2 (en) | 2010-12-16 | 2015-02-03 | Microsoft Corporation | Secure protocol for peer-to-peer network |
US9294545B2 (en) | 2010-12-16 | 2016-03-22 | Microsoft Technology Licensing, Llc | Fast join of peer to peer group with power saving mode |
US8971841B2 (en) | 2010-12-17 | 2015-03-03 | Microsoft Corporation | Operating system supporting cost aware applications |
US10089592B2 (en) | 2010-12-29 | 2018-10-02 | Comcast Cable Communications, Llc | Measuring video asset viewing |
US10945011B2 (en) | 2010-12-29 | 2021-03-09 | Comcast Cable Communications, Llc | Measuring video viewing |
WO2012091938A1 (en) | 2010-12-30 | 2012-07-05 | Dolby Laboratories Licensing Corporation | Ranking representative segments in media data |
US20120189140A1 (en) * | 2011-01-21 | 2012-07-26 | Apple Inc. | Audio-sharing network |
US10440402B2 (en) | 2011-01-26 | 2019-10-08 | Afterlive.tv Inc | Method and system for generating highlights from scored data streams |
US10382509B2 (en) * | 2011-01-28 | 2019-08-13 | Amazon Technologies, Inc. | Audio-based application architecture |
US20120200667A1 (en) * | 2011-02-08 | 2012-08-09 | Gay Michael F | Systems and methods to facilitate interactions with virtual content |
US9325953B2 (en) * | 2011-02-14 | 2016-04-26 | Disney Enterprises, Inc. | System and method for synchronizing on-air commercial programming with interactive applications |
US8543454B2 (en) | 2011-02-18 | 2013-09-24 | Bluefin Labs, Inc. | Generating audience response metrics and ratings from social interest in time-based media |
KR101069090B1 (en) * | 2011-03-03 | 2011-09-30 | 송석명 | Rice wreath for family |
US20120224711A1 (en) * | 2011-03-04 | 2012-09-06 | Qualcomm Incorporated | Method and apparatus for grouping client devices based on context similarity |
US9143571B2 (en) | 2011-03-04 | 2015-09-22 | Qualcomm Incorporated | Method and apparatus for identifying mobile devices in similar sound environment |
US20140026157A1 (en) * | 2011-04-11 | 2014-01-23 | Tao Wang | Face recognition control and social networking |
KR101799443B1 (en) * | 2011-05-02 | 2017-11-20 | 삼성전자주식회사 | Method for surveying watching of video content, Broadcasting receiving apparatus and Server thereof |
US8917823B1 (en) | 2011-05-26 | 2014-12-23 | Google Inc. | Transcribing and navigating a response system |
WO2012174301A1 (en) | 2011-06-14 | 2012-12-20 | Related Content Database, Inc. | System and method for presenting content with time based metadata |
US9160837B2 (en) | 2011-06-29 | 2015-10-13 | Gracenote, Inc. | Interactive streaming content apparatus, systems and methods |
US8732739B2 (en) | 2011-07-18 | 2014-05-20 | Viggle Inc. | System and method for tracking and rewarding media and entertainment usage including substantially real time rewards |
KR101786974B1 (en) * | 2011-07-29 | 2017-10-18 | 네이버 주식회사 | Apparatus and method for providing social network service using sound |
US8861937B2 (en) | 2011-08-31 | 2014-10-14 | The Nielsen Company (Us), Llc | Methods and apparatus to access media |
US9443518B1 (en) * | 2011-08-31 | 2016-09-13 | Google Inc. | Text transcript generation from a communication session |
US8689255B1 (en) * | 2011-09-07 | 2014-04-01 | Imdb.Com, Inc. | Synchronizing video content with extrinsic data |
WO2013040533A1 (en) * | 2011-09-16 | 2013-03-21 | Umami Co. | Second screen interactive platform |
CN102611921A (en) * | 2011-09-16 | 2012-07-25 | 李世平 | Viewing data acquisition method and system |
US9113202B1 (en) | 2011-09-21 | 2015-08-18 | Google Inc. | Inverted client-side fingerprinting and matching |
US8824645B2 (en) * | 2011-09-30 | 2014-09-02 | Verizon Patent And Licensing Inc. | Video messaging systems and methods |
US9223893B2 (en) | 2011-10-14 | 2015-12-29 | Digimarc Corporation | Updating social graph data using physical objects identified from images captured by smartphone |
US9402099B2 (en) | 2011-10-14 | 2016-07-26 | Digimarc Corporation | Arrangements employing content identification and/or distribution identification data |
US20130254159A1 (en) * | 2011-10-25 | 2013-09-26 | Clip Interactive, Llc | Apparatus, system, and method for digital audio services |
US11599915B1 (en) | 2011-10-25 | 2023-03-07 | Auddia Inc. | Apparatus, system, and method for audio based browser cookies |
US8966525B2 (en) * | 2011-11-08 | 2015-02-24 | Verizon Patent And Licensing Inc. | Contextual information between television and user device |
KR20130055748A (en) * | 2011-11-21 | 2013-05-29 | 한국전자통신연구원 | System and method for recommending of contents |
US8745403B2 (en) | 2011-11-23 | 2014-06-03 | Verance Corporation | Enhanced content management based on watermark extraction records |
US8806528B1 (en) * | 2011-12-02 | 2014-08-12 | Adobe Systems Incorporated | Mediating digital program insertion for linear streaming media |
US10645433B1 (en) | 2013-08-29 | 2020-05-05 | Comcast Cable Communications, Llc | Measuring video-content viewing |
US10440428B2 (en) | 2013-01-13 | 2019-10-08 | Comcast Cable Communications, Llc | Measuring video-program-viewing activity |
US9143742B1 (en) * | 2012-01-30 | 2015-09-22 | Google Inc. | Automated aggregation of related media content |
US8645485B1 (en) * | 2012-01-30 | 2014-02-04 | Google Inc. | Social based aggregation of related media content |
US8510770B1 (en) * | 2012-02-03 | 2013-08-13 | Google Inc. | Predicting live programs |
US20160014466A1 (en) * | 2012-02-09 | 2016-01-14 | Ipxtend Ab | Search for media material |
US9684715B1 (en) * | 2012-03-08 | 2017-06-20 | Google Inc. | Audio identification using ordinal transformation |
US8838609B1 (en) | 2012-10-10 | 2014-09-16 | Google Inc. | IDF weighting of LSH bands for live reference ingestion |
EP2642484A1 (en) * | 2012-03-23 | 2013-09-25 | Thomson Licensing | Method for setting a watching level for an audiovisual content |
US9301016B2 (en) | 2012-04-05 | 2016-03-29 | Facebook, Inc. | Sharing television and video programming through social networking |
US9516360B2 (en) * | 2012-04-12 | 2016-12-06 | Qualcomm Incorporated | Estimating demographic statistics of media viewership via context aware mobile devices |
US10292022B2 (en) * | 2012-04-24 | 2019-05-14 | Ascension Intellectual Properties Llc | Media echoing and social networking device and method |
US8904446B2 (en) * | 2012-05-30 | 2014-12-02 | Verizon Patent And Licensing Inc. | Method and apparatus for indexing content within a media stream |
US11023520B1 (en) | 2012-06-01 | 2021-06-01 | Google Llc | Background audio identification for query disambiguation |
KR20130139675A (en) * | 2012-06-13 | 2013-12-23 | 삼성전자주식회사 | Server-based profile generation method, management method, system thereof and apparatus therefor |
US9251406B2 (en) * | 2012-06-20 | 2016-02-02 | Yahoo! Inc. | Method and system for detecting users' emotions when experiencing a media program |
US8843952B2 (en) * | 2012-06-28 | 2014-09-23 | Google Inc. | Determining TV program information based on analysis of audio fingerprints |
US9113203B2 (en) | 2012-06-28 | 2015-08-18 | Google Inc. | Generating a sequence of audio fingerprints at a set top box |
US8689250B2 (en) * | 2012-06-29 | 2014-04-01 | International Business Machines Corporation | Crowd sourced, content aware smarter television systems |
US20140013342A1 (en) * | 2012-07-05 | 2014-01-09 | Comcast Cable Communications, Llc | Media Content Redirection |
CN102831894B (en) * | 2012-08-09 | 2014-07-09 | 华为终端有限公司 | Command processing method, command processing device and command processing system |
GB201214842D0 (en) * | 2012-08-21 | 2012-10-03 | Omnifone Ltd | Content tracker |
US9699485B2 (en) | 2012-08-31 | 2017-07-04 | Facebook, Inc. | Sharing television and video programming through social networking |
JP6102124B2 (en) * | 2012-08-24 | 2017-03-29 | ソニー株式会社 | Information processing apparatus, information processing method, and program |
US8843951B1 (en) * | 2012-08-27 | 2014-09-23 | Google Inc. | User behavior indicator |
US9571606B2 (en) * | 2012-08-31 | 2017-02-14 | Verance Corporation | Social media viewing system |
US9113128B1 (en) | 2012-08-31 | 2015-08-18 | Amazon Technologies, Inc. | Timeline interface for video content |
US8726304B2 (en) | 2012-09-13 | 2014-05-13 | Verance Corporation | Time varying evaluation of multimedia content |
US9661361B2 (en) | 2012-09-19 | 2017-05-23 | Google Inc. | Systems and methods for live media content matching |
US20140089815A1 (en) * | 2012-09-21 | 2014-03-27 | Google Inc. | Sharing Content-Synchronized Ratings |
US9081778B2 (en) | 2012-09-25 | 2015-07-14 | Audible Magic Corporation | Using digital fingerprints to associate data with a work |
US8826316B2 (en) | 2012-10-22 | 2014-09-02 | The Nielsen Company (Us), Llc | Systems and methods for configuring media devices utilizing audio codes or signatures |
US9027048B2 (en) * | 2012-11-14 | 2015-05-05 | Bank Of America Corporation | Automatic deal or promotion offering based on audio cues |
US9265458B2 (en) | 2012-12-04 | 2016-02-23 | Sync-Think, Inc. | Application of smooth pursuit cognitive testing paradigms to clinical drug development |
US9389745B1 (en) | 2012-12-10 | 2016-07-12 | Amazon Technologies, Inc. | Providing content via multiple display devices |
WO2014099272A1 (en) * | 2012-12-17 | 2014-06-26 | Thismoment, Inc. | Systems and methods for interactive advertisements with distributed engagement channels |
US9529907B2 (en) | 2012-12-31 | 2016-12-27 | Google Inc. | Hold back and real time ranking of results in a streaming matching system |
KR101369475B1 (en) | 2013-01-23 | 2014-03-06 | (주)엔써즈 | System and method for surveying broadcasting audience rating |
US9256269B2 (en) * | 2013-02-20 | 2016-02-09 | Sony Computer Entertainment Inc. | Speech recognition system for performing analysis to a non-tactile inputs and generating confidence scores and based on the confidence scores transitioning the system from a first power state to a second power state |
US9311640B2 (en) | 2014-02-11 | 2016-04-12 | Digimarc Corporation | Methods and arrangements for smartphone payments and transactions |
US9344759B2 (en) | 2013-03-05 | 2016-05-17 | Google Inc. | Associating audio tracks of an album with video content |
KR101277523B1 (en) * | 2013-03-08 | 2013-06-21 | (주) 에이노드 | Local interactive platform system, and local interactive service providing method using the same, and computer-readable recording medium for the same |
US9307337B2 (en) | 2013-03-11 | 2016-04-05 | Arris Enterprises, Inc. | Systems and methods for interactive broadcast content |
US20140258373A1 (en) | 2013-03-11 | 2014-09-11 | Say Media, Inc. | Systems and Methods for Managing and Publishing Managed Content |
US9301070B2 (en) | 2013-03-11 | 2016-03-29 | Arris Enterprises, Inc. | Signature matching of corrupted audio signal |
US9380976B2 (en) | 2013-03-11 | 2016-07-05 | Sync-Think, Inc. | Optical neuroinformatics |
US9258597B1 (en) | 2013-03-13 | 2016-02-09 | Google Inc. | System and method for obtaining information relating to video images |
US9247309B2 (en) | 2013-03-14 | 2016-01-26 | Google Inc. | Methods, systems, and media for presenting mobile content corresponding to media content |
US9268880B2 (en) * | 2013-03-14 | 2016-02-23 | Google Inc. | Using recent media consumption to select query suggestions |
US9262793B2 (en) | 2013-03-14 | 2016-02-16 | Verance Corporation | Transactional video marking system |
US9588675B2 (en) | 2013-03-15 | 2017-03-07 | Google Inc. | Document scale and position optimization |
US9705728B2 (en) | 2013-03-15 | 2017-07-11 | Google Inc. | Methods, systems, and media for media transmission and management |
WO2014158193A1 (en) * | 2013-03-29 | 2014-10-02 | Hewlett-Packard Development Company, L.P. | Silence signatures of audio signals |
US9210119B2 (en) | 2013-03-29 | 2015-12-08 | Garret J. LoPorto | Automated triggering of a broadcast |
US9123330B1 (en) * | 2013-05-01 | 2015-09-01 | Google Inc. | Large-scale speaker identification |
US9460201B2 (en) * | 2013-05-06 | 2016-10-04 | Iheartmedia Management Services, Inc. | Unordered matching of audio fingerprints |
US9817911B2 (en) * | 2013-05-10 | 2017-11-14 | Excalibur Ip, Llc | Method and system for displaying content relating to a subject matter of a displayed media program |
US9871606B1 (en) | 2013-05-13 | 2018-01-16 | Twitter, Inc. | Identification of concurrently broadcast time-based media |
FR3006525B1 (en) * | 2013-06-04 | 2016-10-14 | Visiware | SYNCHRONIZATION OF MULTIMEDIA CONTENT ON SECOND SCREEN |
US9485089B2 (en) | 2013-06-20 | 2016-11-01 | Verance Corporation | Stego key management |
US11019300B1 (en) | 2013-06-26 | 2021-05-25 | Amazon Technologies, Inc. | Providing soundtrack information during playback of video content |
US9251549B2 (en) | 2013-07-23 | 2016-02-02 | Verance Corporation | Watermark extractor enhancements based on payload ranking |
US10063450B2 (en) | 2013-07-26 | 2018-08-28 | Opentv, Inc. | Measuring response trends in a digital television network |
US20150039321A1 (en) | 2013-07-31 | 2015-02-05 | Arbitron Inc. | Apparatus, System and Method for Reading Codes From Digital Audio on a Processing Device |
US9711152B2 (en) | 2013-07-31 | 2017-07-18 | The Nielsen Company (Us), Llc | Systems apparatus and methods for encoding/decoding persistent universal media codes to encoded audio |
US9542488B2 (en) | 2013-08-02 | 2017-01-10 | Google Inc. | Associating audio tracks with video content |
CN103618953B (en) * | 2013-08-15 | 2016-09-14 | 北京中视广信科技有限公司 | Broadcast TV program based on audio frequency characteristics mark and the method and system identified |
BR112016006860B8 (en) * | 2013-09-13 | 2023-01-10 | Arris Entpr Inc | APPARATUS AND METHOD FOR CREATING A SINGLE DATA STREAM OF COMBINED INFORMATION FOR RENDERING ON A CUSTOMER COMPUTING DEVICE |
US10506305B1 (en) * | 2013-09-18 | 2019-12-10 | Cox Communications, Inc. | Updating content URL for non-linear video content |
KR102095888B1 (en) | 2013-10-07 | 2020-04-01 | 삼성전자주식회사 | User terminal apparatus and server providing broadcast viewing pattern information and method for providing broadcast viewing pattern information |
US9292174B1 (en) * | 2013-10-30 | 2016-03-22 | Cox Communications, Inc. | Content check-in |
EP2876890A1 (en) * | 2013-11-21 | 2015-05-27 | Thomson Licensing | Method and apparatus for frame accurate synchronization of video streams |
US9438967B2 (en) * | 2013-11-25 | 2016-09-06 | Samsung Electronics Co., Ltd. | Display apparatus and control method thereof |
US9491522B1 (en) | 2013-12-31 | 2016-11-08 | Google Inc. | Methods, systems, and media for presenting supplemental content relating to media content on a content interface based on state information that indicates a subsequent visit to the content interface |
US9426525B2 (en) | 2013-12-31 | 2016-08-23 | The Nielsen Company (Us), Llc. | Methods and apparatus to count people in an audience |
US9456237B2 (en) | 2013-12-31 | 2016-09-27 | Google Inc. | Methods, systems, and media for presenting supplemental information corresponding to on-demand media content |
US10002191B2 (en) | 2013-12-31 | 2018-06-19 | Google Llc | Methods, systems, and media for generating search results based on contextual information |
IN2014MU00140A (en) | 2014-01-15 | 2015-08-28 | Whats On India Media Private Ltd | |
FR3016720B1 (en) * | 2014-01-20 | 2016-02-05 | Tdf | METHOD AND SYSTEM FOR DELIVERING COUPONS FOR REDUCTION AND MANAGEMENT OF SUCH COUPONS. |
WO2015123201A1 (en) * | 2014-02-11 | 2015-08-20 | The Nielsen Company (Us), Llc | Methods and apparatus to calculate video-on-demand and dynamically inserted advertisement viewing probability |
US10504200B2 (en) | 2014-03-13 | 2019-12-10 | Verance Corporation | Metadata acquisition using embedded watermarks |
WO2015138798A1 (en) | 2014-03-13 | 2015-09-17 | Verance Corporation | Interactive content acquisition using embedded codes |
US9900656B2 (en) * | 2014-04-02 | 2018-02-20 | Whats On India Media Private Limited | Method and system for customer management |
US9438940B2 (en) * | 2014-04-07 | 2016-09-06 | The Nielsen Company (Us), Llc | Methods and apparatus to identify media using hash keys |
JP6599864B2 (en) | 2014-04-27 | 2019-11-06 | エルジー エレクトロニクス インコーポレイティド | Broadcast signal transmitting apparatus, broadcast signal receiving apparatus, broadcast signal transmitting method, and broadcast signal receiving method |
CN104093079B (en) | 2014-05-29 | 2015-10-07 | 腾讯科技（深圳）有限公司 | Based on the exchange method of multimedia programming, terminal, server and system |
US9838759B2 (en) | 2014-06-20 | 2017-12-05 | Google Inc. | Displaying information related to content playing on a device |
US10206014B2 (en) | 2014-06-20 | 2019-02-12 | Google Llc | Clarifying audible verbal information in video content |
US9946769B2 (en) | 2014-06-20 | 2018-04-17 | Google Llc | Displaying information related to spoken dialogue in content playing on a device |
US9805125B2 (en) | 2014-06-20 | 2017-10-31 | Google Inc. | Displaying a summary of media content items |
US9858922B2 (en) | 2014-06-23 | 2018-01-02 | Google Inc. | Caching speech recognition scores |
US9805434B2 (en) | 2014-08-20 | 2017-10-31 | Verance Corporation | Content management based on dither-like watermark embedding |
US10325591B1 (en) * | 2014-09-05 | 2019-06-18 | Amazon Technologies, Inc. | Identifying and suppressing interfering audio content |
US20160073148A1 (en) * | 2014-09-09 | 2016-03-10 | Verance Corporation | Media customization based on environmental sensing |
US9736503B1 (en) * | 2014-09-12 | 2017-08-15 | Google Inc. | Optimizing timing of display of a mid-roll video advertisement based on viewer retention data |
US10602236B2 (en) | 2014-09-17 | 2020-03-24 | Ispot.Tv, Inc. | Unique content sequence identification method and apparatus |
US9402111B2 (en) | 2014-09-17 | 2016-07-26 | Ispot.Tv, Inc. | Television audience measurement method and apparatus |
US9497505B2 (en) | 2014-09-30 | 2016-11-15 | The Nielsen Company (Us), Llc | Systems and methods to verify and/or correct media lineup information |
US9299347B1 (en) | 2014-10-22 | 2016-03-29 | Google Inc. | Speech recognition using associative mapping |
US9942602B2 (en) | 2014-11-25 | 2018-04-10 | Verance Corporation | Watermark detection and metadata delivery associated with a primary content |
WO2016086047A1 (en) | 2014-11-25 | 2016-06-02 | Verance Corporation | Enhanced metadata and content delivery using watermarks |
CN104394436B (en) * | 2014-11-28 | 2018-06-26 | 北京国双科技有限公司 | The monitoring method and device of the audience ratings of Internet TV live television channel |
FR3030177B1 (en) * | 2014-12-16 | 2016-12-30 | Stmicroelectronics Rousset | ELECTRONIC DEVICE COMPRISING A WAKE MODULE OF AN ELECTRONIC APPARATUS DISTINCT FROM A PROCESSING HEART |
US9602891B2 (en) | 2014-12-18 | 2017-03-21 | Verance Corporation | Service signaling recovery for multimedia content using embedded watermarks |
CA3057090C (en) * | 2015-01-30 | 2023-01-03 | Sharp Kabushiki Kaisha | System for service usage reporting |
US10219039B2 (en) | 2015-03-09 | 2019-02-26 | The Nielsen Company (Us), Llc | Methods and apparatus to assign viewers to media meter data |
US10015541B2 (en) | 2015-03-25 | 2018-07-03 | Cisco Technology, Inc. | Storing and retrieval heuristics |
US9578394B2 (en) | 2015-03-25 | 2017-02-21 | Cisco Technology, Inc. | Video signature creation and matching |
US9705936B2 (en) | 2015-04-24 | 2017-07-11 | Mersive Technologies, Inc. | System and method for interactive and real-time visualization of distributed media |
US10257567B2 (en) | 2015-04-30 | 2019-04-09 | Verance Corporation | Watermark based content recognition improvements |
WO2016190662A1 (en) * | 2015-05-26 | 2016-12-01 | 엘지전자 주식회사 | Broadcasting signal transmitting apparatus, broadcasting signal receiving apparatus, broadcasting signal transmitting method, and broadcasting signal receiving method |
EP3298789A1 (en) * | 2015-06-15 | 2018-03-28 | Piksel, Inc. | Synchronisation of streamed content |
CN104936035B (en) * | 2015-06-19 | 2018-04-17 | 腾讯科技（北京）有限公司 | A kind of barrage processing method and system |
US11481652B2 (en) * | 2015-06-23 | 2022-10-25 | Gregory Knox | System and method for recommendations in ubiquituous computing environments |
US9786270B2 (en) | 2015-07-09 | 2017-10-10 | Google Inc. | Generating acoustic models |
US10477285B2 (en) | 2015-07-20 | 2019-11-12 | Verance Corporation | Watermark-based data recovery for content with multiple alternative components |
US9699504B2 (en) * | 2015-09-28 | 2017-07-04 | Rovi Guides, Inc. | Systems and methods for identifying a source of media content based on a log of content identifiers |
US9854304B2 (en) | 2015-09-28 | 2017-12-26 | Rovi Guides, Inc. | Systems and methods for identifying a source of media content based on a log of fingerprints |
CA3001480C (en) * | 2015-10-16 | 2019-06-18 | Tribune Broadcasting Company, Llc | Video-production system with dve feature |
US20170140795A1 (en) * | 2015-11-18 | 2017-05-18 | International Business Machines Corporation | Intelligent segment marking in recordings |
US10349141B2 (en) | 2015-11-19 | 2019-07-09 | Google Llc | Reminders of media content referenced in other media content |
US10229672B1 (en) | 2015-12-31 | 2019-03-12 | Google Llc | Training acoustic models using connectionist temporal classification |
KR102102453B1 (en) * | 2016-01-08 | 2020-04-20 | 주식회사 아이플래테아 | Viewer rating calculation server, viewer rating calculation method, and viewer rating calculation remote device |
US20170214954A1 (en) * | 2016-01-25 | 2017-07-27 | Google Inc. | Media Program Moments Guide |
US10034053B1 (en) | 2016-01-25 | 2018-07-24 | Google Llc | Polls for media program moments |
KR102468763B1 (en) * | 2016-02-05 | 2022-11-18 | 삼성전자 주식회사 | Image processing apparatus and control method thereof |
US10776823B2 (en) | 2016-02-09 | 2020-09-15 | Comcast Cable Communications, Llc | Collection analysis and use of viewer behavior |
US10433026B2 (en) * | 2016-02-29 | 2019-10-01 | MyTeamsCalls LLC | Systems and methods for customized live-streaming commentary |
US10063918B2 (en) | 2016-02-29 | 2018-08-28 | Gracenote, Inc. | Media channel identification with multi-match detection and disambiguation based on single-match |
US9924222B2 (en) | 2016-02-29 | 2018-03-20 | Gracenote, Inc. | Media channel identification with multi-match detection and disambiguation based on location |
US9930406B2 (en) | 2016-02-29 | 2018-03-27 | Gracenote, Inc. | Media channel identification with video multi-match detection and disambiguation based on audio fingerprint |
CN105657326A (en) * | 2016-03-02 | 2016-06-08 | 掌赢信息科技（上海）有限公司 | Group video call method, device and system |
US10318813B1 (en) | 2016-03-11 | 2019-06-11 | Gracenote, Inc. | Digital video fingerprinting using motion segmentation |
US9918128B2 (en) * | 2016-04-08 | 2018-03-13 | Orange | Content categorization using facial expression recognition, with improved detection of moments of interest |
WO2017184648A1 (en) | 2016-04-18 | 2017-10-26 | Verance Corporation | System and method for signaling security and database population |
CN106170104B (en) * | 2016-07-01 | 2019-03-08 | 广州华多网络科技有限公司 | The determination method, apparatus and server of video highlight segment |
US20180018973A1 (en) | 2016-07-15 | 2018-01-18 | Google Inc. | Speaker verification |
GB2556023B (en) | 2016-08-15 | 2022-02-09 | Intrasonics Sarl | Audio matching |
US10171879B2 (en) * | 2016-10-04 | 2019-01-01 | International Business Machines Corporation | Contextual alerting for broadcast content |
US10108718B2 (en) | 2016-11-02 | 2018-10-23 | Alphonso Inc. | System and method for detecting repeating content, including commercials, in a video data stream |
US10419141B2 (en) | 2016-12-09 | 2019-09-17 | The Nielsen Company (Us), Llc | Estimating volume of switching among television programs for an audience measurement panel |
US10075767B2 (en) * | 2016-12-12 | 2018-09-11 | Facebook, Inc. | Broadcast content view analysis based on ambient audio recording |
US10791355B2 (en) | 2016-12-20 | 2020-09-29 | The Nielsen Company (Us), Llc | Methods and apparatus to determine probabilistic media viewing metrics |
US10405012B2 (en) * | 2016-12-25 | 2019-09-03 | Synamedia Limited | Cloud DVR Optimization |
US11044520B2 (en) * | 2016-12-29 | 2021-06-22 | Telefonaktiebolaget Lm Ericsson (Publ) | Handling of video segments in a video stream |
WO2018125590A1 (en) * | 2016-12-30 | 2018-07-05 | Tivo Solutions Inc. | Advanced trick-play modes for streaming video |
US10462514B2 (en) | 2017-03-29 | 2019-10-29 | The Nielsen Company (Us), Llc | Interactive overlays to determine viewer data |
WO2018237191A1 (en) | 2017-06-21 | 2018-12-27 | Verance Corporation | Watermark-based metadata acquisition and processing |
US9980004B1 (en) * | 2017-06-30 | 2018-05-22 | Paypal, Inc. | Display level content blocker |
US10440413B2 (en) * | 2017-07-31 | 2019-10-08 | The Nielsen Company (Us), Llc | Methods and apparatus to perform media device asset qualification |
US10706840B2 (en) | 2017-08-18 | 2020-07-07 | Google Llc | Encoder-decoder models for sequence to sequence mapping |
US10764639B2 (en) * | 2017-09-09 | 2020-09-01 | Telegenic, Inc. | Overlaying aggregated media content with additional services based on a context |
EP3682414B1 (en) * | 2017-09-12 | 2022-11-09 | Irdeto B.V. | Device and method for gpu-based watermarking |
US10264297B1 (en) * | 2017-09-13 | 2019-04-16 | Perfect Sense, Inc. | Time-based content synchronization |
US10621256B2 (en) * | 2017-09-29 | 2020-04-14 | Facebook, Inc. | Determining a rate for sampling information describing presentation of content based on previously received information describing presentation of content |
WO2019089028A1 (en) * | 2017-11-02 | 2019-05-09 | Bretherton Peter | Method and system for real-time broadcast audience engagement |
US11140450B2 (en) * | 2017-11-28 | 2021-10-05 | Rovi Guides, Inc. | Methods and systems for recommending content in context of a conversation |
US10715860B1 (en) * | 2017-11-29 | 2020-07-14 | Twitch Interactive, Inc. | Video stream with additional content areas |
US11146845B2 (en) | 2017-12-05 | 2021-10-12 | Relola Inc. | Systems and methods for unified presentation of synchronized on-demand, live, social or market content |
US10783573B2 (en) | 2017-12-05 | 2020-09-22 | Silicon Beach Media II, LLC | Systems and methods for unified presentation and sharing of on-demand, live, or social activity monitoring content |
US10631035B2 (en) | 2017-12-05 | 2020-04-21 | Silicon Beach Media II, LLC | Systems and methods for unified compensation, presentation, and sharing of on-demand, live, social or market content |
US10817855B2 (en) | 2017-12-05 | 2020-10-27 | Silicon Beach Media II, LLC | Systems and methods for unified presentation and sharing of on-demand, live, social or market content |
US10924809B2 (en) | 2017-12-05 | 2021-02-16 | Silicon Beach Media II, Inc. | Systems and methods for unified presentation of on-demand, live, social or market content |
US10567828B2 (en) * | 2017-12-05 | 2020-02-18 | Silicon Beach Media II, LLC | Systems and methods for unified presentation of a smart bar on interfaces including on-demand, live, social or market content |
US10412442B1 (en) | 2017-12-11 | 2019-09-10 | Amazon Technologies, Inc. | Embedded content input and timing |
US10531165B1 (en) | 2017-12-11 | 2020-01-07 | Amazon Technologies, Inc. | Embedded content synchronization |
US10715855B1 (en) * | 2017-12-20 | 2020-07-14 | Groupon, Inc. | Method, system, and apparatus for programmatically generating a channel incrementality ratio |
US10848792B2 (en) * | 2018-03-05 | 2020-11-24 | Maestro Interactive, Inc. | System and method for providing audience-targeted content triggered by events during program |
US10346474B1 (en) * | 2018-03-30 | 2019-07-09 | Alphonso Inc. | System and method for detecting repeating content, including commercials, in a video data stream using audio-based and video-based automated content recognition |
US11463747B2 (en) | 2018-04-05 | 2022-10-04 | Tvu Networks Corporation | Systems and methods for real time control of a remote video production with multiple streams |
US10966001B2 (en) * | 2018-04-05 | 2021-03-30 | Tvu Networks Corporation | Remote cloud-based video production system in an environment where there is network delay |
US11212431B2 (en) | 2018-04-06 | 2021-12-28 | Tvu Networks Corporation | Methods and apparatus for remotely controlling a camera in an environment with communication latency |
US11468149B2 (en) | 2018-04-17 | 2022-10-11 | Verance Corporation | Device authentication in collaborative content screening |
US20200007934A1 (en) * | 2018-06-29 | 2020-01-02 | Advocates, Inc. | Machine-learning based systems and methods for analyzing and distributing multimedia content |
US10771828B2 (en) * | 2018-09-18 | 2020-09-08 | Free Stream Media Corp. | Content consensus management |
US10929878B2 (en) * | 2018-10-19 | 2021-02-23 | International Business Machines Corporation | Targeted content identification and tracing |
WO2020095767A1 (en) * | 2018-11-08 | 2020-05-14 | 日本電信電話株式会社 | Distribution design assistance method, distribution design assistance device, and program |
US10868620B2 (en) * | 2018-12-26 | 2020-12-15 | The Nielsen Company (Us), Llc | Methods and apparatus for optimizing station reference fingerprint loading using reference watermarks |
US10848836B2 (en) * | 2018-12-28 | 2020-11-24 | Dish Network L.L.C. | Wager information based prioritized live event display system |
US11151609B2 (en) | 2019-01-07 | 2021-10-19 | Alphonso Inc. | Closed loop attribution |
US10803480B2 (en) | 2019-01-07 | 2020-10-13 | Alphonso Inc. | Bidding agent with optimized reach limitation |
US10873785B2 (en) * | 2019-01-07 | 2020-12-22 | Alphonso Inc. | Content recommendation system and method-based implicit ratings |
US11037205B2 (en) | 2019-01-07 | 2021-06-15 | Alphonso Inc. | Bidding agent using ad opportunity source to limit ad reach |
CN109547843B (en) * | 2019-02-01 | 2022-05-17 | 腾讯音乐娱乐科技（深圳）有限公司 | Method and device for processing audio and video |
US10856041B2 (en) * | 2019-03-18 | 2020-12-01 | Disney Enterprises, Inc. | Content promotion using a conversational agent |
US11259058B2 (en) * | 2019-03-25 | 2022-02-22 | Apple Inc. | Use of rendered media to assess delays in media distribution systems |
US11785194B2 (en) | 2019-04-19 | 2023-10-10 | Microsoft Technology Licensing, Llc | Contextually-aware control of a user interface displaying a video and related user text |
US11026000B2 (en) * | 2019-04-19 | 2021-06-01 | Microsoft Technology Licensing, Llc | Previewing video content referenced by typed hyperlinks in comments |
US11678031B2 (en) | 2019-04-19 | 2023-06-13 | Microsoft Technology Licensing, Llc | Authoring comments including typed hyperlinks that reference video content |
US11212560B2 (en) * | 2019-06-24 | 2021-12-28 | The Nielsen Company (Us), Llc | Use of steganographically-encoded time information as basis to establish a time offset, to facilitate taking content-related action |
US11234049B2 (en) * | 2019-06-24 | 2022-01-25 | The Nielsen Company (Us), Llc | Use of steganographically-encoded time information as basis to control implementation of dynamic content modification |
US10834466B1 (en) * | 2019-08-02 | 2020-11-10 | International Business Machines Corporation | Virtual interactivity for a broadcast content-delivery medium |
US11627361B2 (en) * | 2019-10-14 | 2023-04-11 | Meta Platforms, Inc. | Method to acoustically detect a state of an external media device using an identification signal |
CN112995759A (en) * | 2019-12-13 | 2021-06-18 | 腾讯科技（北京）有限公司 | Interactive service processing method, system, device, equipment and storage medium |
US11356720B2 (en) | 2020-01-30 | 2022-06-07 | Snap Inc. | Video generation system to render frames on demand |
EP4096798A1 (en) | 2020-01-30 | 2022-12-07 | Snap Inc. | System for generating media content items on demand |
US11036781B1 (en) | 2020-01-30 | 2021-06-15 | Snap Inc. | Video generation system to render frames on demand using a fleet of servers |
US11284144B2 (en) * | 2020-01-30 | 2022-03-22 | Snap Inc. | Video generation system to render frames on demand using a fleet of GPUs |
CN113711617B (en) | 2020-03-13 | 2024-04-02 | 谷歌有限责任公司 | Method and device for projecting media content in networking television device |
GB2597334A (en) | 2020-07-17 | 2022-01-26 | Playrcart Ltd | A media player |
US11284139B1 (en) * | 2020-09-10 | 2022-03-22 | Hulu, LLC | Stateless re-discovery of identity using watermarking of a video stream |
US11974024B2 (en) * | 2020-09-11 | 2024-04-30 | Sling TV L.L.C. | Automated program promotion detection in a video streaming system |
US11922967B2 (en) | 2020-10-08 | 2024-03-05 | Gracenote, Inc. | System and method for podcast repetitive content detection |
US11317128B1 (en) * | 2020-10-23 | 2022-04-26 | Synamedia Limited | Systems, methods, and devices for media content tamper protection and detection |
US11445042B2 (en) | 2020-12-02 | 2022-09-13 | International Business Machines Corporation | Correlating multiple media sources for personalized media content |
US10998006B1 (en) * | 2020-12-08 | 2021-05-04 | Turku University of Applied Sciences Ltd | Method and system for producing binaural immersive audio for audio-visual content |
US20220210488A1 (en) * | 2020-12-30 | 2022-06-30 | Comcast Cable Communications, Llc | Method and system for detecting and managing similar content |
US11722741B2 (en) | 2021-02-08 | 2023-08-08 | Verance Corporation | System and method for tracking content timeline in the presence of playback rate changes |
US11809481B2 (en) | 2021-02-17 | 2023-11-07 | International Business Machines Corporation | Content generation based on multi-source content analysis |
US11589100B1 (en) * | 2021-03-31 | 2023-02-21 | Amazon Technologies, Inc. | On-demand issuance private keys for encrypted video transmission |
US11580982B1 (en) | 2021-05-25 | 2023-02-14 | Amazon Technologies, Inc. | Receiving voice samples from listeners of media programs |
US11586344B1 (en) | 2021-06-07 | 2023-02-21 | Amazon Technologies, Inc. | Synchronizing media content streams for live broadcasts and listener interactivity |
US11792143B1 (en) | 2021-06-21 | 2023-10-17 | Amazon Technologies, Inc. | Presenting relevant chat messages to listeners of media programs |
US11792467B1 (en) | 2021-06-22 | 2023-10-17 | Amazon Technologies, Inc. | Selecting media to complement group communication experiences |
US11683558B2 (en) * | 2021-06-29 | 2023-06-20 | The Nielsen Company (Us), Llc | Methods and apparatus to determine the speed-up of media programs using speech recognition |
US11470130B1 (en) | 2021-06-30 | 2022-10-11 | Amazon Technologies, Inc. | Creating media content streams from listener interactions |
US11496776B1 (en) * | 2021-07-19 | 2022-11-08 | Intrado Corporation | Database layer caching for video communications |
CN114286169B (en) * | 2021-08-31 | 2023-06-20 | 腾讯科技（深圳）有限公司 | Video generation method, device, terminal, server and storage medium |
US11687576B1 (en) | 2021-09-03 | 2023-06-27 | Amazon Technologies, Inc. | Summarizing content of live media programs |
US11463772B1 (en) | 2021-09-30 | 2022-10-04 | Amazon Technologies, Inc. | Selecting advertisements for media programs by matching brands to creators |
US11785299B1 (en) | 2021-09-30 | 2023-10-10 | Amazon Technologies, Inc. | Selecting advertisements for media programs and establishing favorable conditions for advertisements |
US11831943B2 (en) * | 2021-10-26 | 2023-11-28 | Apple Inc. | Synchronized playback of media content |
US11785272B1 (en) | 2021-12-03 | 2023-10-10 | Amazon Technologies, Inc. | Selecting times or durations of advertisements during episodes of media programs |
US11916981B1 (en) | 2021-12-08 | 2024-02-27 | Amazon Technologies, Inc. | Evaluating listeners who request to join a media program |
US11791920B1 (en) | 2021-12-10 | 2023-10-17 | Amazon Technologies, Inc. | Recommending media to listeners based on patterns of activity |
US11785278B1 (en) * | 2022-03-18 | 2023-10-10 | Comcast Cable Communications, Llc | Methods and systems for synchronization of closed captions with content output |
US11910044B1 (en) * | 2022-06-30 | 2024-02-20 | Amazon Technologies, Inc. | Systems and methods for switching the processing of a live content stream to another datacenter |
Family Cites Families (81)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4811399A (en) | 1984-12-31 | 1989-03-07 | Itt Defense Communications, A Division Of Itt Corporation | Apparatus and method for automatic speech recognition |
EP0384689B1 (en) | 1989-02-20 | 1997-12-29 | Fujitsu Limited | A learning system and learning method for a data processing apparatus |
US5436653A (en) * | 1992-04-30 | 1995-07-25 | The Arbitron Company | Method and system for recognition of broadcast segments |
US6044365A (en) * | 1993-09-01 | 2000-03-28 | Onkor, Ltd. | System for indexing and retrieving graphic and sound data |
JPH11506575A (en) | 1995-03-07 | 1999-06-08 | インターバル リサーチ コーポレイション | Information selective storage system and method |
US5706364A (en) | 1995-04-28 | 1998-01-06 | Xerox Corporation | Method of producing character templates using unsegmented samples |
US7562392B1 (en) | 1999-05-19 | 2009-07-14 | Digimarc Corporation | Methods of interacting with audio and ambient music |
US20030093790A1 (en) | 2000-03-28 | 2003-05-15 | Logan James D. | Audio and video program recording, editing and playback systems using metadata |
DK128796A (en) | 1996-11-14 | 1998-05-15 | Jan Meyrowitsch | Method of objectifying subjective classifications |
US7802276B2 (en) * | 1997-01-06 | 2010-09-21 | At&T Intellectual Property I, L.P. | Systems, methods and products for assessing subscriber content access |
US7587323B2 (en) | 2001-12-14 | 2009-09-08 | At&T Intellectual Property I, L.P. | System and method for developing tailored content |
US6157746A (en) | 1997-02-12 | 2000-12-05 | Sarnoff Corporation | Apparatus and method for encoding wavelet trees generated by a wavelet-based coding method |
US5870744A (en) * | 1997-06-30 | 1999-02-09 | Intel Corporation | Virtual people networking |
US6553404B2 (en) | 1997-08-08 | 2003-04-22 | Prn Corporation | Digital system |
ES2296585T3 (en) * | 1998-05-12 | 2008-05-01 | Nielsen Media Research, Inc. | AUDIENCE MEASUREMENT SYSTEM FOR DIGITAL TELEVISION. |
US6182186B1 (en) * | 1998-06-30 | 2001-01-30 | Sun Microsystems, Inc. | Method and apparatus that utilizes lock states to lock resources |
US6529526B1 (en) | 1998-07-13 | 2003-03-04 | Thomson Licensing S.A. | System for processing programs and program content rating information derived from multiple broadcast sources |
US6471521B1 (en) | 1998-07-31 | 2002-10-29 | Athenium, L.L.C. | System for implementing collaborative training and online learning over a computer network and related techniques |
US7178106B2 (en) * | 1999-04-21 | 2007-02-13 | Sonic Solutions, A California Corporation | Presentation of media content from multiple media sources |
US6604239B1 (en) * | 1999-06-25 | 2003-08-05 | Eyescene Inc. | System and method for virtual television program rating |
US6895514B1 (en) | 1999-06-25 | 2005-05-17 | Lucent Technologies Inc. | Method and apparatus for achieving secure password access |
US7120871B1 (en) * | 1999-09-15 | 2006-10-10 | Actv, Inc. | Enhanced video programming system and method utilizing a web page staging area |
US7174293B2 (en) * | 1999-09-21 | 2007-02-06 | Iceberg Industries Llc | Audio identification system and method |
KR100353798B1 (en) | 1999-12-01 | 2002-09-26 | 주식회사 코난테크놀로지 | Method for extracting shape descriptor of image object and content-based image retrieval system and method using it |
DE19962281A1 (en) | 1999-12-23 | 2001-06-28 | Philips Corp Intellectual Pty | X-ray examination device |
US6892191B1 (en) | 2000-02-07 | 2005-05-10 | Koninklijke Philips Electronics N.V. | Multi-feature combination generation and classification effectiveness evaluation using genetic algorithms |
US6879967B1 (en) | 2000-03-24 | 2005-04-12 | Ricoh Co., Ltd. | Method and apparatus for open data collection |
JP3994682B2 (en) | 2000-04-14 | 2007-10-24 | 日本電信電話株式会社 | Broadcast information transmission / reception system |
US6636848B1 (en) * | 2000-05-31 | 2003-10-21 | International Business Machines Corporation | Information search using knowledge agents |
US6763339B2 (en) | 2000-06-26 | 2004-07-13 | The Regents Of The University Of California | Biologically-based signal processing system applied to noise removal for signal extraction |
US6751601B2 (en) | 2000-07-21 | 2004-06-15 | Pablo Zegers | Method and a system for solving dynamic problems using the dynamical system architecture |
EP1303819A1 (en) * | 2000-07-22 | 2003-04-23 | ABB Research Ltd. | System and method for generating an xml-based error model |
US7853664B1 (en) * | 2000-07-31 | 2010-12-14 | Landmark Digital Services Llc | Method and system for purchasing pre-recorded music |
IL139368A (en) | 2000-10-30 | 2006-12-10 | Nova Measuring Instr Ltd | Process control for microlithography |
US7375304B2 (en) | 2001-01-25 | 2008-05-20 | Lincoln Global, Inc. | System and method providing automated welding notification |
US7330717B2 (en) * | 2001-02-23 | 2008-02-12 | Lucent Technologies Inc. | Rule-based system and method for managing the provisioning of user applications on limited-resource and/or wireless devices |
US20020133499A1 (en) | 2001-03-13 | 2002-09-19 | Sean Ward | System and method for acoustic fingerprinting |
JP4340398B2 (en) * | 2001-05-15 | 2009-10-07 | 日本放送協会 | Interactive broadcast viewing system |
US20020194585A1 (en) * | 2001-06-15 | 2002-12-19 | Connelly Jay H. | Methods and apparatus for providing ranking feedback for content in a broadcast system |
EP1421521A2 (en) * | 2001-07-31 | 2004-05-26 | Gracenote, Inc. | Multiple step identification of recordings |
JP4165685B2 (en) | 2001-08-09 | 2008-10-15 | ヤマハ株式会社 | Content sales server and program |
FR2831981B1 (en) | 2001-11-08 | 2005-07-08 | Cit Alcatel | METHOD AND DEVICE FOR ANALYZING ALARMS FROM A COMMUNICATION NETWORK |
JP2003150529A (en) * | 2001-11-19 | 2003-05-23 | Hitachi Ltd | Information exchange method, information exchange terminal unit, information exchange server device and program |
JP2003163911A (en) * | 2001-11-22 | 2003-06-06 | Nippon Telegr & Teleph Corp <Ntt> | Image reproducing method based on favorable public image information, image reproduction control system, server apparatus, client apparatus, image reproduction control program and its recording medium |
US7065544B2 (en) | 2001-11-29 | 2006-06-20 | Hewlett-Packard Development Company, L.P. | System and method for detecting repetitions in a multimedia stream |
JP3872980B2 (en) * | 2001-12-12 | 2007-01-24 | 松下電器産業株式会社 | Information playback device |
US6585521B1 (en) | 2001-12-21 | 2003-07-01 | Hewlett-Packard Development Company, L.P. | Video indexing based on viewers' behavior and emotion feedback |
US7038619B2 (en) | 2001-12-31 | 2006-05-02 | Rdp Associates, Incorporated | Satellite positioning system enabled media measurement system and method |
US7987491B2 (en) | 2002-05-10 | 2011-07-26 | Richard Reisman | Method and apparatus for browsing using alternative linkbases |
US7665035B2 (en) * | 2002-05-20 | 2010-02-16 | Gateway, Inc. | Content selection apparatus, system, and method |
JP2003345729A (en) * | 2002-05-24 | 2003-12-05 | Matsushita Electric Ind Co Ltd | System, terminal device and server for television chat, and method and program for providing television chat service |
US20030225833A1 (en) * | 2002-05-31 | 2003-12-04 | Paul Pilat | Establishing multiparty communications based on common attributes |
US6766523B2 (en) * | 2002-05-31 | 2004-07-20 | Microsoft Corporation | System and method for identifying and segmenting repeating media objects embedded in a stream |
WO2003102728A2 (en) | 2002-05-31 | 2003-12-11 | Predictive Media Corporation | Method and system for the storage, viewing management, and delivery of targeted advertising |
JP2004015087A (en) * | 2002-06-03 | 2004-01-15 | Matsushita Electric Ind Co Ltd | Viewer participating type two-way communication service system |
US7107207B2 (en) | 2002-06-19 | 2006-09-12 | Microsoft Corporation | Training machine learning by sequential conditional generalized iterative scaling |
CN100426861C (en) * | 2002-07-01 | 2008-10-15 | 微软公司 | A system and method for providing user control over repeating objects embedded in a stream |
JP2004037721A (en) * | 2002-07-02 | 2004-02-05 | Pioneer Electronic Corp | System and program for voice response and storage medium therefor |
JP2004049438A (en) | 2002-07-18 | 2004-02-19 | Olympia:Kk | Game machine with medal apportioning mechanism, method for medal apportioning, memory medium and program |
JP2004159192A (en) * | 2002-11-07 | 2004-06-03 | Nippon Telegr & Teleph Corp <Ntt> | Video image summarizing method, program, and storage medium for storing video image summarizing program |
US7930716B2 (en) * | 2002-12-31 | 2011-04-19 | Actv Inc. | Techniques for reinsertion of local market advertising in digital video from a bypass source |
JP2004213570A (en) * | 2003-01-08 | 2004-07-29 | Sony Corp | Information providing method |
JP2004235694A (en) * | 2003-01-28 | 2004-08-19 | Mitsubishi Electric Corp | Server apparatus and broadcast receiver |
US7913279B2 (en) * | 2003-01-31 | 2011-03-22 | Microsoft Corporation | Global listings format (GLF) for multimedia programming content and electronic program guide (EPG) information |
US20050009620A1 (en) | 2003-02-14 | 2005-01-13 | Hodgetts George W. | Golf club shaft with adjustable flex |
US20040216041A1 (en) * | 2003-04-24 | 2004-10-28 | Amir Ajizadeh | System and methods in interactive television and radio ratings through the internet and the telephone |
JP2005107529A (en) * | 2003-09-25 | 2005-04-21 | Ricoh Co Ltd | Printing possible expression for time base media |
US7788696B2 (en) * | 2003-10-15 | 2010-08-31 | Microsoft Corporation | Inferring information about media stream objects |
JP2005167349A (en) * | 2003-11-28 | 2005-06-23 | Matsushita Electric Ind Co Ltd | Program contents transmitting apparatus |
JP4466055B2 (en) * | 2003-11-28 | 2010-05-26 | ソニー株式会社 | COMMUNICATION SYSTEM, COMMUNICATION METHOD, TERMINAL DEVICE, INFORMATION PRESENTATION METHOD, MESSAGE EXCHANGE DEVICE, AND MESSAGE EXCHANGE METHOD |
US7281219B2 (en) | 2003-12-05 | 2007-10-09 | International Business Machines Corporation | Blended learning experience tool and method |
US20050147256A1 (en) * | 2003-12-30 | 2005-07-07 | Peters Geoffrey W. | Automated presentation of entertainment content in response to received ambient audio |
US20050193016A1 (en) * | 2004-02-17 | 2005-09-01 | Nicholas Seet | Generation of a media content database by correlating repeating media content in media streams |
US7197502B2 (en) * | 2004-02-18 | 2007-03-27 | Friendly Polynomials, Inc. | Machine-implemented activity management system using asynchronously shared activity data objects and journal data items |
US8229751B2 (en) * | 2004-02-26 | 2012-07-24 | Mediaguide, Inc. | Method and apparatus for automatic detection and identification of unidentified Broadcast audio or video signals |
US7546086B2 (en) * | 2004-05-07 | 2009-06-09 | Telefonaktiebolaget L M Ericsson (Publ) | Ad-hoc messaging between wireless devices |
US20060080356A1 (en) | 2004-10-13 | 2006-04-13 | Microsoft Corporation | System and method for inferring similarities between media objects |
US7472096B2 (en) | 2005-07-18 | 2008-12-30 | Microsoft Corporation | Training a learning system with arbitrary cost functions |
JP2009524273A (en) | 2005-11-29 | 2009-06-25 | グーグル・インコーポレーテッド | Repetitive content detection in broadcast media |
US7617164B2 (en) | 2006-03-17 | 2009-11-10 | Microsoft Corporation | Efficiency of training for ranking systems based on pairwise training with aggregated gradients |
US7831531B1 (en) | 2006-06-22 | 2010-11-09 | Google Inc. | Approximate hashing functions for finding similar content |
-
2006
- 2006-11-27 JP JP2008543390A patent/JP2009524273A/en active Pending
- 2006-11-27 KR KR1020087015739A patent/KR101371574B1/en active IP Right Grant
- 2006-11-27 ES ES06838488T patent/ES2386977T3/en active Active
- 2006-11-27 EP EP08153719A patent/EP1986145A1/en not_active Ceased
- 2006-11-27 US US11/563,653 patent/US8442125B2/en active Active
- 2006-11-27 CA CA2631151A patent/CA2631151C/en not_active Expired - Fee Related
- 2006-11-27 AU AU2006320692A patent/AU2006320692A1/en not_active Abandoned
- 2006-11-27 BR BRPI0619388-9A patent/BRPI0619388A2/en active Search and Examination
- 2006-11-27 EP EP06838488A patent/EP1955458B1/en active Active
- 2006-11-27 US US11/563,661 patent/US8479225B2/en active Active
- 2006-11-27 US US11/563,665 patent/US7991770B2/en active Active
- 2006-11-27 JP JP2008543391A patent/JP2009518884A/en active Pending
- 2006-11-27 WO PCT/US2006/045551 patent/WO2007064641A2/en active Application Filing
- 2006-11-27 AU AU2006320693A patent/AU2006320693B2/en not_active Ceased
- 2006-11-27 CA CA002631270A patent/CA2631270A1/en not_active Abandoned
- 2006-11-27 BR BRPI0619197-5A patent/BRPI0619197A2/en not_active IP Right Cessation
- 2006-11-27 WO PCT/US2006/045549 patent/WO2007064640A2/en active Application Filing
- 2006-11-27 EP EP06838486A patent/EP1958362A4/en not_active Withdrawn
- 2006-11-27 KR KR1020087015779A patent/KR20080073357A/en not_active Application Discontinuation
-
2008
- 2008-05-29 IL IL191814A patent/IL191814A0/en unknown
-
2011
- 2011-08-01 US US13/195,330 patent/US8700641B2/en active Active
-
2012
- 2012-10-05 JP JP2012223077A patent/JP6161249B2/en active Active
-
2013
- 2013-03-15 US US13/842,471 patent/US20150156542A1/en not_active Abandoned
-
2017
- 2017-08-11 US US15/675,586 patent/US20170366847A1/en not_active Abandoned
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
WO2009140759A1 (en) * | 2008-05-22 | 2009-11-26 | Unify4Life Corporation | Interactive event guide with enhanced features |
Also Published As
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US20170366847A1 (en) | Determining Popularity Ratings Using Social and Interactive Applications for Mass Media | |
CN101517550B (en) | Social and interactive applications for mass media | |
US8805865B2 (en) | Efficient matching of data | |
US8732745B2 (en) | Method and system for inserting an advertisement in a media stream | |
US20050086682A1 (en) | Inferring information about media stream objects | |
EP2149117A1 (en) | Characterizing content for identification of advertising | |
Fink et al. | Social-and interactive-television applications based on real-time ambient-audio identification | |
US20190005129A1 (en) | Method and device for presenting content | |
US20140106708A1 (en) | Continuous monitoring of data exposure and providing service related thereto | |
Fink et al. | Mass personalization: social and interactive applications using sound-track identification |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
EEER | Examination request | ||
MKLA | Lapsed |
Effective date: 20171127 |