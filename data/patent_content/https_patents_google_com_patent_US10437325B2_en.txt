US10437325B2 - Retinal see through display power level determination method and apparatus - Google Patents
Retinal see through display power level determination method and apparatus Download PDFInfo
- Publication number
- US10437325B2 US10437325B2 US15/242,341 US201615242341A US10437325B2 US 10437325 B2 US10437325 B2 US 10437325B2 US 201615242341 A US201615242341 A US 201615242341A US 10437325 B2 US10437325 B2 US 10437325B2
- Authority
- US
- United States
- Prior art keywords
- pupil size
- display
- light
- luminance
- ambient light
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/011—Arrangements for interaction with the human body, e.g. for user immersion in virtual reality
- G06F3/013—Eye tracking input arrangements
-
- G—PHYSICS
- G02—OPTICS
- G02B—OPTICAL ELEMENTS, SYSTEMS OR APPARATUS
- G02B27/00—Optical systems or apparatus not provided for by any of the groups G02B1/00 - G02B26/00, G02B30/00
- G02B27/0093—Optical systems or apparatus not provided for by any of the groups G02B1/00 - G02B26/00, G02B30/00 with means for monitoring data relating to the user, e.g. head-tracking, eye-tracking
-
- G—PHYSICS
- G02—OPTICS
- G02B—OPTICAL ELEMENTS, SYSTEMS OR APPARATUS
- G02B27/00—Optical systems or apparatus not provided for by any of the groups G02B1/00 - G02B26/00, G02B30/00
- G02B27/01—Head-up displays
- G02B27/017—Head mounted
- G02B27/0172—Head mounted characterised by optical features
-
- G06K9/0061—
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T11/00—2D [Two Dimensional] image generation
- G06T11/60—Editing figures and text; Combining figures or text
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V40/00—Recognition of biometric, human-related or animal-related patterns in image or video data
- G06V40/10—Human or animal bodies, e.g. vehicle occupants or pedestrians; Body parts, e.g. hands
- G06V40/18—Eye characteristics, e.g. of the iris
- G06V40/193—Preprocessing; Feature extraction
-
- G—PHYSICS
- G02—OPTICS
- G02B—OPTICAL ELEMENTS, SYSTEMS OR APPARATUS
- G02B27/00—Optical systems or apparatus not provided for by any of the groups G02B1/00 - G02B26/00, G02B30/00
- G02B27/01—Head-up displays
- G02B27/0101—Head-up displays characterised by optical features
- G02B2027/014—Head-up displays characterised by optical features comprising information/image processing systems
Definitions
- the present disclosure relates to the field of display technology. More particularly, the present disclosure relates to retinal see through display power level determination method and apparatus.
- Natural response of the human eye to a change in ambient brightness includes adaptation of the eye pupil diameter through action of the iris, yielding a change in retinal illumination.
- the mechanism provided by nature would no longer work as the retinal illumination is no longer dependent on the eye pupil diameter.
- FIG. 1 illustrates the retinal see through display power determination technology of the present disclosure, according to various embodiments.
- FIG. 2 illustrates the retinal see through display power determination technology of the present disclosure, according to various other embodiments.
- FIG. 3 illustrates determination of display luminance, according to various embodiments.
- FIG. 4 illustrates a component view of a wearable device having the retinal see through display power determination technology of the present disclosure, according to various embodiments.
- FIG. 5 illustrates an example process for determining power of a retinal see through display, according to various embodiments.
- FIG. 6 illustrates a storage medium having instructions for practicing methods described with references to FIGS. 1-3 , according to various embodiments.
- an apparatus may comprise a body wearable by a user, a retinal see through display disposed in the body; a target luminance calculator disposed in the body to determine a required luminance level; and a display power controller communicatively coupled with the target light calculator and the retinal see through display, and disposed in the body, to determine a power level for the retinal see through display, based at least in part on a pupil size of the user and the determined required luminance level.
- the apparatus may further comprises sensors disposed in the body to sense local luminance level for a local area behind a virtual image, and the target luminance calculator may be communicatively coupled with the sensors to sense local luminance level, and determine a required luminance level based at least in part on the sensed local luminance level.
- the required luminance level may be determined based at least in part on the sensed local luminance level, using a required luminance model that models required luminance for various local luminance conditions.
- the pupil size of the user may be estimated or detected.
- the apparatus may further comprises sensors disposed in the body to sense ambient light level, and a pupil size calculator communicatively coupled with the sensors to sense ambient light level, and disposed in the body, to estimate the pupil size based at least in part on the sensed ambient light level.
- the pupil size may be estimated based at least in part on the sensed ambient light level using a model that models the pupil size for various ambient light conditions.
- phrase “A and/or B” means (A), (B), or (A and B).
- phrase “A, B, and/or C” means (A), (B), (C), (A and B), (A and C), (B and C), or (A, B and C).
- module may refer to, be part of, or include an Application Specific Integrated Circuit (ASIC), an electronic circuit, a processor (shared, dedicated, or group) and/or memory (shared, dedicated, or group) that execute one or more software or firmware programs having machine instructions (generated from assembler instructions or compiled from higher level language instructions), a combinational logic circuit, and/or other suitable components that provide the described functionality.
- ASIC Application Specific Integrated Circuit
- processor shared, dedicated, or group
- memory shared, dedicated, or group
- machine instructions generated from assembler instructions or compiled from higher level language instructions
- combinational logic circuit and/or other suitable components that provide the described functionality.
- wearable device 100 may include retinal see through display (not shown in FIG. 1 , see e.g., 406 in FIG. 4 ) having an exit pupil smaller than actual eye pupil size or within possible eye pupil size range (2-7 mm).
- Wearable device 100 may include further display power controller 114 configured to adaptively determine an appropriate power for the retinal see through display output light beams 116 of appropriate display luminance level to display images to user's eye 118 .
- the power level may be determined to be the power level that provides for the display luminance level to approximate or equal the required luminance level, for a pupil size, as described more fully below.
- wearable device 100 may further include local light sensor 104 and target light calculator 112 communicatively coupled with each other, and with display power controller 114 as shown.
- Local light sensor 104 may be configured to sense and output local luminance level of a local area behind a displayed virtual image (see e.g., virtual image 304 displayed on the user's field of view 302 illustrated on the right hand side of FIG. 3 ).
- local light sensor 104 may be any one of a number of suitable light sensors known in the art configurable to be coupled to a light pipe designed to have an acceptance angle consistent (e.g., matching) the displayed image of view.
- An example of such light sensors may include, but is not limited to, the Light To Digital Converters available from AMS TAOS of Premstaetten, Austria.
- target luminance calculator 112 may be configured to determine the required luminance level (L required ), based at least in part on the sensed local luminance level (L local ). In embodiments, target luminance calculator 112 may determine the required luminance level, using a required luminance level model 108 that models required luminance level for various local luminance levels.
- L required may be determined using an empirical model represented by the following formula:
- L local_eye would be 18% of the sensed local luminance level.
- the determined L required provides for virtual image contrast on top of the field of view background.
- display power controller 114 may be configured to select a power level for retinal see through display, such that the display luminance level approximates or equals the required luminance level, for a pupil size.
- the exit pupil of the retinal see through display is smaller than the user's eye pupil, thus technology of the present disclosure adapt the display luminance depending on the size of the eye pupil of the user.
- the optimum power P opt of the retinal see through display to provide the display luminance to approximate or equal the required luminance may be determined using the following formulas (see left hand side 310 of FIG. 3 ):
- a lookup table of P opt to provide various display luminance for various pupil size may be pre-computed and pre-provided to display power controller 114 , using the above formulas, e.g., at manufacturing time, at initial set up time, or during power on initialization.
- P opt may be computed in real time.
- wearable device 100 may further include ambient light sensor 102 and pupil size calculator 110 communicatively coupled with each other, and with display power controller 114 as shown.
- ambient light sensor 102 may be configured to sense and output ambient light level.
- ambient light sensor 102 may be any one of a number of suitable light sensors known in the art.
- pupil size calculator 110 may be configured to estimate the pupil size of the user, based at least in part on the sensed ambient light level. In embodiments, pupil size calculator 110 may estimate the user's pupil size, using a pupil size model 106 that models pupil sizes for various ambient light levels.
- pupil size model 106 may be represented by the following formula:
- Ambient luminance L is the parameter detected by ambient light sensors 102 .
- the field area is the user's FOV (field of view), in square degrees. A typical value may be between 60° ⁇ 2700 square degrees. Monocular effect means either one eye, or two eyes.
- the age of the user may be provided by the user. In embodiments, a reference or defaulted value, e.g., 30 years old, may be used instead.
- the result (D u ) is the corresponding user pupil size in mm. See A unified formula for light - adapted pupil size by Watson and Yellott, Journal of Vision (2012), 12(10); 12, 1-16 for further information.
- wearable device 200 may include retinal see through display (not shown in FIG. 2 , see e.g., 406 in FIG. 4 ) having an exit pupil smaller than actual eye pupil size or within possible eye pupil size range (2-7 mm). Further, like wearable device 100 , wearable device 200 may include display power controller 114 , local light sensors 104 and target light calculator 112 . Display power controller 114 , local light sensors 104 and target light calculator 112 may be similarly constituted and perform the same functions, as earlier described.
- wearable device 200 include pupil size detector 202 , in lieu of ambient light sensor 102 and pupil size calculator 110 .
- Pupil size detector 202 may be configured to detect (measure) the user's pupil size directly.
- Pupil size detector 202 may be any one of a number of suitable detectors known in the art.
- wearable device 400 may include wearable body 410 hosting hardware 401 , i.e., hardware 401 are disposed on or within wearable body 410 .
- Hardware 401 in turn may host software 403 .
- hardware 401 may include one or more processors 402 , memory 404 , retinal optical display 406 , sensors 407 and other I/O devices 408 .
- Software 403 may include operating system (OS) 412 and application 414 .
- the wearable body 410 may be a pair of eyeglasses or goggles.
- Processor(s) 402 may be any one of a number of processors known in the art, having one or more processor cores.
- Memory 404 may be any volatile or non-volatile memory known in the art, suitable for storing instructions and/or data, e.g., instructions and/or data of OS 412 and/or applications 414 .
- retinal optical display 406 may otherwise be any one of a number of retinal optical display known in the art.
- Sensors 407 may be sensors 102 and 104 and/or pupil size detector 202 of FIGS. 1 and 2 . As described earlier, they may be any one of a number of known sensors suitable for sensing ambient and local lights, and/or detecting pupil size of a user.
- I/O devices 408 may include e.g., but are not limited to, Global Positioning System (GPS), gyroscope, accelerometer, compass, or communication or networking interfaces, such as WiFi, 3G/4G, Bluetooth®, Near Field Communication, Universal Serial Bus (USB) and so forth.
- GPS Global Positioning System
- gyroscope gyroscope
- accelerometer e.g., but are not limited to, GPS, GPS, gyroscope, accelerometer, compass, or communication or networking interfaces, such as WiFi, 3G/4G, Bluetooth®, Near Field Communication, Universal Serial Bus (USB) and so forth.
- USB Universal Serial Bus
- OS 412 may include a number of services and utilities 420 , in particular, optical display driver 422 , incorporated with the teachings of the present disclosure, e.g., pupil size calculator 110 , target light calculator 112 and display power controller 114 of FIGS. 1 and 2 . Except for optical display driver 422 , OS 112 may be any one of a number of OS known in the art, e.g., the Windows OS from Microsoft® Corporation. Applications 114 may likewise be any one of a number of applications known in the art.
- process 500 for determining optimal power for a retinal see through optical display may include operations performed at blocks 502 - 512 .
- the operations may be performed e.g., by the earlier described optical device driver 422 of FIG. 4 (having pupil size calculator 110 , target light calculator 112 an/or display power controller 114 ).
- FIG. 5 also depicts the algorithmic structure of optical device driver 422 and its components.
- process 500 may start at block 502 , 506 or 508 .
- sensed ambient light data may be received.
- detected pupil size of a user may be received.
- sense local light data 510 may be received.
- process 500 may proceed to block 504 .
- the pupil size of the user may be calculated/estimated.
- the pupil size of the user may be calculated/estimated using a pupil size model that models pupil sizes for various ambient light conditions.
- the pupil size model may be represented by the earlier described equation (6).
- process 500 may proceed to block 510 .
- the required luminance level may be calculated/estimated.
- the required luminance level may be calculated/estimated using a required luminance model that models required luminance level for various local luminance levels.
- the required luminance model may be represented by the earlier described equation (1).
- process 500 may proceed to block 512 .
- the optimal power of retinal see through display may be determined.
- the optimal power may be the power that provides a display luminance level that approximates/equals the required luminance level for the user's pupil size.
- the determination may be performed by retrieving the optimal power from a lookup table pre-calculated in accordance with equations 5.
- the calculations may be performed in real time (e.g., by a photodiode embedded in one of sensors 407 in FIG. 4 ).
- aspects of the present disclosure may be embodied as methods or computer program products. Accordingly, aspects of the present disclosure, in addition to being embodied in hardware as earlier described, may take the form of an entirely software embodiment (including firmware, resident software, micro-code, etc.) or an embodiment combining software and hardware aspects that may all generally be referred to as a “circuit,” “module” or “system.” Furthermore, aspects of the present disclosure may take the form of a computer program product embodied in any tangible or non-transitory medium of expression having computer-usable program code embodied in the medium.
- FIG. 6 illustrates an example computer-readable non-transitory storage medium that may be suitable for use to store instructions that cause an apparatus, in response to execution of the instructions by the apparatus, to practice selected aspects of the present disclosure.
- non-transitory computer-readable storage medium 602 may include a number of programming instructions 604 .
- Programming instructions 604 may be configured to enable a wearable device, e.g., wearable device 500 , in response to execution of the programming instructions, to implement (aspects of) OS 412 , such as optical display driver 422 .
- OS 412 such as optical display driver 422
- programming instructions 604 may be disposed on multiple computer-readable non-transitory storage media 602 instead.
- programming instructions 604 may be disposed on computer-readable transitory storage media 602 , such as, signals.
- the computer-usable or computer-readable medium may be, for example but not limited to, an electronic, magnetic, optical, electromagnetic, infrared, or semiconductor system, apparatus, device, or propagation medium.
- the computer-readable medium would include the following: an electrical connection having one or more wires, a portable computer diskette, a hard disk, a random access memory (RAM), a read-only memory (ROM), an erasable programmable read-only memory (EPROM or Flash memory), an optical fiber, a portable compact disc read-only memory (CD-ROM), an optical storage device, a transmission media such as those supporting the Internet or an intranet, or a magnetic storage device.
- RAM random access memory
- ROM read-only memory
- EPROM or Flash memory erasable programmable read-only memory
- CD-ROM compact disc read-only memory
- CD-ROM compact disc read-only memory
- a transmission media such as those supporting the Internet or an intranet, or a magnetic storage device.
- a computer-usable or computer-readable medium could even be paper or another suitable medium upon which the program is printed, as the program can be electronically captured, via, for instance, optical scanning of the paper or other medium, then compiled, interpreted, or otherwise processed in a suitable manner, if necessary, and then stored in a computer memory.
- a computer-usable or computer-readable medium may be any medium that can contain, store, communicate, propagate, or transport the program for use by or in connection with the instruction execution system, apparatus, or device.
- the computer-usable medium may include a propagated data signal with the computer-usable program code embodied therewith, either in baseband or as part of a carrier wave.
- the computer usable program code may be transmitted using any appropriate medium, including but not limited to wireless, wireline, optical fiber cable, RF, etc.
- Computer program code for carrying out operations of the present disclosure may be written in any combination of one or more programming languages, including an object oriented programming language such as Java, Smalltalk, C++ or the like and conventional procedural programming languages, such as the “C” programming language or similar programming languages.
- the program code may execute entirely on the user's wearable device, partly on the user's wearable device, as a stand-alone software package, partly on the user's wearable device and partly on a remote computer or entirely on the remote computer or server.
- the remote computer may be connected to the user's wearable device through any type of network, including a local area network (LAN) or a wide area network (WAN), or the connection may be made to an external computer (for example, through the Internet using an Internet Service Provider).
- LAN local area network
- WAN wide area network
- Internet Service Provider for example, AT&T, MCI, Sprint, EarthLink, MSN, GTE, etc.
- each block in the flowchart or block diagrams may represent a module, segment, or portion of code, which comprises one or more executable instructions for implementing the specified logical function(s).
- the functions noted in the block may occur out of the order noted in the figures. For example, two blocks shown in succession may, in fact, be executed substantially concurrently, or the blocks may sometimes be executed in the reverse order, depending upon the functionality involved.
- At least one of processors 402 may be packaged together with memory having aspects of optical display driver 422 .
- at least one of processors 402 may be packaged together with memory having aspects of optical display driver 422 , to form a System in Package (SiP).
- SiP System in Package
- at least one of processors 402 may be integrated on the same die with memory having aspects of optical display driver 422 .
- at least one of processors 402 may be packaged together with memory having aspects of optical display driver 422 , to form a System on Chip (SoC).
- SoC System on Chip
- Example 1 may be an apparatus for displaying images, comprising: a body wearable by a user; a retinal see through display disposed in the body; a target light calculator disposed in the body to determine a required luminance level; and a display power controller communicatively coupled with the target light calculator and the retinal see through display, and disposed in the body, to determine a power level for the retinal see through display to display images, based at least in part on a pupil size of the user and the determined required luminance level.
- Example 2 may be example 1, further comprising one or more ambient light sensors disposed in the body to sense ambient light and output sensed ambient light data, and a pupil size calculator coupled to the one or more ambient light sensors, and disposed in the body, to estimate the pupil size of the user; wherein the pupil size calculator may estimate the pupil size based at least in part on the sensed ambient light data.
- Example 3 may be example 2, wherein the pupil size calculator may estimate the pupil size based at least in part on the sensed ambient light data, using a pupil size model that models pupil sizes for various ambient light conditions.
- Example 4 may be example 1, further comprising a pupil size detector disposed in the body to detect and output the pupil size of the user.
- Example 5 may be example 1, further comprising one or more local light sensors disposed in the body to sense local light and output sensed local light data associated with a local area behind a displayed virtual image; wherein the target light calculator may determine the required luminance level, based at least in part on the sensed local light data associated with the local area behind the displayed virtual image.
- Example 6 may be example 5, wherein the target light calculator may determine the required luminance level, based at least in part on the sensed local light data, using a required light model that models required light for various local light conditions.
- Example 7 may be any one of examples 1-6; wherein the display power controller may determine the power level of the retinal see through display, such that a display luminance level approximates the determined required luminance level, for the pupil size of the user.
- Example 8 may be example 7, further comprising a processor disposed in the body, wherein the target light calculator may be a software target light calculator operated by the processor, and the display power controller may be a software display power controller operated by the processor.
- Example 9 may be example 8, wherein the target light calculator and the display power controller may be part of an optical display driver.
- Example 10 may be example 7, wherein the display power controller includes or may have access to a lookup table of pre-calculated powers to provide various display luminance levels for various pupil sizes.
- Example 11 may be a method for displaying images, comprising: determining, by a wearable device, a required luminance level; and determining, by the wearable device, a power level of a retinal see through display of the wearable device to display images, based at least in part on a pupil size of a user and the determined required luminance level.
- Example 12 may be example 11, further comprising sensing ambient light and outputting sensed ambient light data with one or more ambient light sensors disposed in a body of the wearable device, and estimating the pupil size of the user, based at least in part on the sensed ambient light data.
- Example 13 may be example 12, wherein estimating may comprise estimating the pupil size based at least in part on the sensed ambient light data, using a pupil size model that models pupil sizes for various ambient light conditions.
- Example 14 may be example 11, further comprising detecting and outputting the pupil size of the user using a pupil size detector disposed in a body of the wearable device.
- Example 15 may be example 11, further comprising sensing local light and outputting sensed local light data associated with a local area behind a displayed virtual image, using one or more local light sensors disposed in a body of the wearable device; wherein determining a required luminance level may comprise determining the required luminance level, based at least in part on the sensed local light data associated with the local area behind the displayed virtual image.
- Example 16 may be example 15, wherein determining the required luminance level may comprise determining the required luminance level, based at least in part on the sensed local light data, using a required light model that models required light for various local light conditions.
- Example 17 may be any one of examples 11-16; wherein determining a power level may comprise determining a power level of the retinal see through display, such that a display luminance level approximates the determined required luminance level, for the pupil size of the user.
- Example 18 may be example 17, wherein determining a power level may comprise accessing a lookup table of pre-calculated powers to provide various display luminance levels for various pupil sizes, to retrieve the power level.
- Example 19 may be one or more computer-readable media comprising instructions that cause a wearable device, in response to execution of the instructions by the wearable device, to: determine a required luminance level; and determine a power level of a retinal see through display of the wearable device to display images, based at least in part on a pupil size of a user and the determined required luminance level.
- Example 20 may be example 19, wherein the wearable device may comprise one or more ambient light sensors disposed in a body of the wearable device to sense ambient light and output sensed ambient light data; and wherein the wearable device may be further caused to estimate the pupil size of the user, based at least in part on the sensed ambient light data.
- Example 21 may be example 20, wherein the wearable device may be further caused to estimate the pupil size based at least in part on the sensed ambient light data, using a pupil size model that models pupil sizes for various ambient light conditions.
- Example 22 may be example 19, wherein the wearable device may comprise a pupil size detector disposed in a body of the wearable device to detect and output the pupil size of the user.
- Example 23 may be example 19, wherein the wearable device may comprise one or more local light sensors disposed in the body to sense local light and output sensed local light data associated with a local area behind a displayed virtual image; wherein the wearable device may be further caused to determine the required luminance level, based at least in part on the sensed local light data associated with the local area behind the displayed virtual image.
- Example 24 may be example 23, wherein the wearable device may be further caused to determine the required luminance level, based at least in part on the sensed local light data, using a required light model that models required light for various local light conditions.
- Example 25 may be any one of examples 19-24; wherein the wearable device may be further caused to determine the power level of the retinal see through display, such that a display luminance level approximates the determined required luminance level, for the pupil size of the user.
- Example 26 may be example 25, further comprising a lookup table of pre-calculated powers to provide various display luminance levels for various pupil sizes.
- Example 27 may be an apparatus for displaying images, comprising: means for determining a required luminance level; and means for determining a power level of a retinal see through display of the apparatus, based at least in part on a pupil size of a user and the determined required luminance level.
- Example 28 may be example 27, further comprising means for sensing ambient light and outputting sensed ambient light data with one or more ambient light sensors disposed in a body of the wearable device, and means for estimating the pupil size of the user, based at least in part on the sensed ambient light data.
- Example 29 may be example 28, wherein means for estimating may comprise means for estimating the pupil size based at least in part on the sensed ambient light data, using a pupil size model that models pupil sizes for various ambient light conditions.
- Example 30 may be example 27, further comprising means for detecting and outputting the pupil size of the user using a pupil size detector disposed in a body of the wearable device.
- Example 31 may be example 27, further comprising means for sensing local light and outputting sensed local light data associated with a local area behind a displayed virtual image, using one or more local light sensors disposed in a body of the wearable device; wherein means for determining a required luminance level may comprise means for determining the required luminance level, based at least in part on the sensed local light data associated with the local area behind the displayed virtual image.
- Example 32 may be example 31, wherein means for determining the required luminance level may comprise means for determining the required luminance level, based at least in part on the sensed local light data, using a required light model that models required light for various local light conditions.
- Example 33 may be any one of examples 27-32; wherein means for determining a power level may comprise means for determining a power level of the retinal see through display, such that a display luminance level approximates the determined required luminance level, for the pupil size of the user.
- Example 34 may be example 33, wherein means for determining a power level may comprise means for accessing a lookup table of pre-calculated powers to provide various display luminance levels for various pupil sizes, to retrieve the power level.
Abstract
Description
-
- where w is the virtual image solid angle in steradian,
- p is an index which depends on the position of the virtual image in the user's field of view (FOV), and
- Llocal_eye may be the local luminance level perceived by user's
eye 118, which may be a percentage of the sensed local luminance level.
-
- where L is the display luminance level;
- Popt(λ) is a spectral distribution of optical power incident onto the eye pupil;
- KM is a factor which is equal to 683.002 lm/W and is the maximal photopic spectral luminous efficacy, corresponding to lambda=555 nm;
- Virtual image surface: A
- Solid angle defined by eye pupil: Ω
- Photopic Spectral Luminous efficiency: V(λ)
- Eye pupil diameter: d
- Vert. (hor.) FOV: θv (θh)
-
- where Du is the diameter of the pupil size, F is the effective corneal flux density, and f is F elevated to the power of 0.41.
Claims (25)
Priority Applications (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US15/242,341 US10437325B2 (en) | 2016-08-19 | 2016-08-19 | Retinal see through display power level determination method and apparatus |
PCT/US2017/042900 WO2018034783A2 (en) | 2016-08-19 | 2017-07-19 | Retinal see through display power level determination method and apparatus |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US15/242,341 US10437325B2 (en) | 2016-08-19 | 2016-08-19 | Retinal see through display power level determination method and apparatus |
Publications (2)
Publication Number | Publication Date |
---|---|
US20180052513A1 US20180052513A1 (en) | 2018-02-22 |
US10437325B2 true US10437325B2 (en) | 2019-10-08 |
Family
ID=61191643
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US15/242,341 Active 2037-01-21 US10437325B2 (en) | 2016-08-19 | 2016-08-19 | Retinal see through display power level determination method and apparatus |
Country Status (2)
Country | Link |
---|---|
US (1) | US10437325B2 (en) |
WO (1) | WO2018034783A2 (en) |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20180365875A1 (en) * | 2017-06-14 | 2018-12-20 | Dell Products, L.P. | Headset display control based upon a user's pupil state |
Families Citing this family (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20170132466A1 (en) | 2014-09-30 | 2017-05-11 | Qualcomm Incorporated | Low-power iris scan initialization |
US10515284B2 (en) | 2014-09-30 | 2019-12-24 | Qualcomm Incorporated | Single-processor computer vision hardware control and application execution |
US10984235B2 (en) | 2016-12-16 | 2021-04-20 | Qualcomm Incorporated | Low power data generation for iris-related detection and authentication |
US10614332B2 (en) * | 2016-12-16 | 2020-04-07 | Qualcomm Incorportaed | Light source modulation for iris size adjustment |
US10983349B2 (en) * | 2018-06-14 | 2021-04-20 | Google Llc | Method of dynamically adjusting display luminance flux in wearable heads-up displays |
Citations (8)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20070058261A1 (en) | 2004-05-17 | 2007-03-15 | Olympus Corporation | Head mount type image display system |
US20110057863A1 (en) | 2009-09-10 | 2011-03-10 | Ryohei Sugihara | Spectacles-type image display device |
US20130333266A1 (en) | 2012-06-16 | 2013-12-19 | Bradley H. Gose | Augmented Sight and Sensing System |
US8681073B1 (en) | 2011-09-29 | 2014-03-25 | Rockwell Collins, Inc. | System for and method of controlling contrast or color contrast in see-through displays |
US20150035744A1 (en) | 2013-07-30 | 2015-02-05 | Steve Robbins | Near-eye optic positioning in display devices |
US9030383B2 (en) | 2008-09-29 | 2015-05-12 | Carl Zeiss Ag | Display device and display method |
US20150187330A1 (en) | 2014-01-02 | 2015-07-02 | Quanta Computer Inc. | Head mounted display apparatus and backlight adjustment method thereof |
US20160231573A1 (en) * | 2015-02-10 | 2016-08-11 | Daqri, Llc | Dynamic lighting for head mounted device |
-
2016
- 2016-08-19 US US15/242,341 patent/US10437325B2/en active Active
-
2017
- 2017-07-19 WO PCT/US2017/042900 patent/WO2018034783A2/en active Application Filing
Patent Citations (8)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20070058261A1 (en) | 2004-05-17 | 2007-03-15 | Olympus Corporation | Head mount type image display system |
US9030383B2 (en) | 2008-09-29 | 2015-05-12 | Carl Zeiss Ag | Display device and display method |
US20110057863A1 (en) | 2009-09-10 | 2011-03-10 | Ryohei Sugihara | Spectacles-type image display device |
US8681073B1 (en) | 2011-09-29 | 2014-03-25 | Rockwell Collins, Inc. | System for and method of controlling contrast or color contrast in see-through displays |
US20130333266A1 (en) | 2012-06-16 | 2013-12-19 | Bradley H. Gose | Augmented Sight and Sensing System |
US20150035744A1 (en) | 2013-07-30 | 2015-02-05 | Steve Robbins | Near-eye optic positioning in display devices |
US20150187330A1 (en) | 2014-01-02 | 2015-07-02 | Quanta Computer Inc. | Head mounted display apparatus and backlight adjustment method thereof |
US20160231573A1 (en) * | 2015-02-10 | 2016-08-11 | Daqri, Llc | Dynamic lighting for head mounted device |
Non-Patent Citations (4)
Title |
---|
Cakmakci et al., "A Compact Optical See-through Head-Worn Display with Occlusion Support", International Symposium on Mixed and Augmented Reality, (2004), 10 pages. |
International Search Report and Written Opinion dated Oct. 20, 2017 for International Application No. PCT/US2017/042900, 12 pages. |
Watson et al., "A unified formula for light-adapted pupil size", Journal of Vision, Sep. 25, 2012, vol. 12, 16 pages. |
Wearable Technology | The Next Megatrend, [online] Aug. 23, 2014 [Retrieved Nov. 30, 2016], http://plasticplus.ca/wp-content/uploads/2014/08/Wearable-Technology.pdf, 6 pages. |
Cited By (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20180365875A1 (en) * | 2017-06-14 | 2018-12-20 | Dell Products, L.P. | Headset display control based upon a user's pupil state |
US10810773B2 (en) * | 2017-06-14 | 2020-10-20 | Dell Products, L.P. | Headset display control based upon a user's pupil state |
Also Published As
Publication number | Publication date |
---|---|
WO2018034783A2 (en) | 2018-02-22 |
WO2018034783A3 (en) | 2018-07-26 |
US20180052513A1 (en) | 2018-02-22 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US10437325B2 (en) | Retinal see through display power level determination method and apparatus | |
JP5420793B1 (en) | Head-mounted display with adjustable image viewing distance | |
EP3671313B1 (en) | Gaze tracking using mapping of pupil center position | |
US20160180692A1 (en) | Reminding method and reminding device | |
US9811095B2 (en) | Glasses with fluid-fillable membrane for adjusting focal length of one or more lenses of the glasses | |
US20160041615A1 (en) | Information processing apparatus, focus detection method, and information processing system | |
BR112017018416A8 (en) | METHOD IMPLEMENTED BY COMPUTER MEANS FOR DETERMINING AN OPHTHALMIC LENS HAVING UNDESIRED ASTIGMATISM, METHOD FOR DETERMINING FOCAL PLANE IMAGE, OPHTHALMIC LENS SET AND SYSTEM FOR DETERMINING AN OPHTHALMIC LENS HAVING UNDESIRED ASTIGMATISM | |
JP6794353B2 (en) | Methods and Devices for Making Eye Judgments Under Ambient Illumination Conditions | |
JP2018151754A5 (en) | ||
US11301969B1 (en) | Context aware dynamic distortion correction | |
US10062353B2 (en) | System to compensate for visual impairment | |
US10983349B2 (en) | Method of dynamically adjusting display luminance flux in wearable heads-up displays | |
JP2015529856A (en) | Method for adapting the optical function of an adaptive ophthalmic lens system | |
US20190369719A1 (en) | Robust convergence signal | |
US11579683B2 (en) | Wearable device and control method therefor | |
JP2014223192A5 (en) | Eye characteristic measuring device, eye characteristic measuring method, computer program | |
KR20210100690A (en) | Dynamic convergence adjustment of augmented reality headsets | |
CN109716204B (en) | Method for managing the display of images to a user of an optical system | |
WO2014062299A1 (en) | Method and apparatus for determining depth of focus of an eye optical system | |
US20160139432A1 (en) | Using google glass to project a red overlay that enhances night vision | |
EP3669753B1 (en) | Gaze tracking via tracing of light paths | |
CN111752383A (en) | Updating a corneal model | |
JP5200518B2 (en) | Intraocular substance measurement device | |
KR101527295B1 (en) | Vision correction apparatus | |
JP7334155B2 (en) | Display method and display device |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: INTEL CORPORATION, CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:LE GROS, CHRISTOPHE;COSENDEY, GATIEN;REEL/FRAME:039764/0001Effective date: 20160623 |
|
AS | Assignment |
Owner name: NORTH INC., CANADAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:INTEL CORPORATION;REEL/FRAME:048044/0034Effective date: 20181105 |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NOTICE OF ALLOWANCE MAILED -- APPLICATION RECEIVED IN OFFICE OF PUBLICATIONS |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: PUBLICATIONS -- ISSUE FEE PAYMENT RECEIVED |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: PUBLICATIONS -- ISSUE FEE PAYMENT VERIFIED |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:NORTH INC.;REEL/FRAME:054113/0814Effective date: 20200916 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 4TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1551); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 4 |