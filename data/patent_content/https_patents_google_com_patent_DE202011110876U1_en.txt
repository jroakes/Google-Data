DE202011110876U1 - Identifying plants in images - Google Patents
Identifying plants in images Download PDFInfo
- Publication number
- DE202011110876U1 DE202011110876U1 DE202011110876.0U DE202011110876U DE202011110876U1 DE 202011110876 U1 DE202011110876 U1 DE 202011110876U1 DE 202011110876 U DE202011110876 U DE 202011110876U DE 202011110876 U1 DE202011110876 U1 DE 202011110876U1
- Authority
- DE
- Germany
- Prior art keywords
- geo
- image
- match
- tagged
- geographic location
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Expired - Lifetime
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/29—Geographical information databases
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/10—Text processing
- G06F40/166—Editing, e.g. inserting or deleting
- G06F40/169—Annotation, e.g. comment data or footnotes
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/20—Natural language analysis
- G06F40/205—Parsing
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V20/00—Scenes; Scene-specific elements
- G06V20/10—Terrestrial scenes
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V30/00—Character recognition; Recognising digital ink; Document-oriented image-based pattern recognition
- G06V30/10—Character recognition
- G06V30/26—Techniques for post-processing, e.g. correcting the recognition result
- G06V30/262—Techniques for post-processing, e.g. correcting the recognition result using context analysis, e.g. lexical, syntactic or semantic context
- G06V30/268—Lexical context
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V30/00—Character recognition; Recognising digital ink; Document-oriented image-based pattern recognition
- G06V30/10—Character recognition
Abstract
Computersystem zum Identifizieren eines Betriebs in einem geogetaggten Bild, Folgendes umfassend: ein nicht-flüchtiges computerlesbares Speichermedium, das einen ausführbaren Computerprogrammcode für Folgendes umfasst: das Erkennen einer Textfolge im geogetaggten Bild, das Identifizieren eines Betriebs in der Nähe eines geografischen Orts, der durch ein Geotag des Bildes spezifiziert ist, das Entnehmen eines Satzes aus Informationen, die mit dem Betrieb in der Nähe des geografischen Ortes verknüpft sind, das Vergleichen der Textfolgen mit dem Satz, um eine Übereinstimmung abzuleiten, und Identifizieren des Betriebs in der Nähe des geografischen Orts als den Betrieb im geogetaggten Bild, basierend auf der Übereinstimmung; und ein Prozessor zum Ausführen eines ausführbaren Codes für das Computerprogramm.A computer system for identifying an operation in a geo-tagged image, comprising: a non-transitory computer-readable storage medium comprising executable computer program code for: detecting a text string in the geo-tagged image, identifying an operation proximate to a geographic location specified by Geotag the image is specified, the extraction of a set of information associated with the operation in the vicinity of the geographical location, comparing the text strings with the sentence to derive a match, and identifying the operation in the vicinity of the geographical location as the operation in the geo-tagged image based on the match; and a processor for executing an executable code for the computer program.
Description
HINTERGRUNDBACKGROUND
GEBIET DER OFFENBARUNGAREA OF REVELATION
Die Offenbarung bezieht sich im Allgemeinen auf den Bereich der Computervision, insbesondere auf die Bilderkennung. Unter Schutz gestellt werden und Gegenstand des Gebrauchsmusters sind dabei, entsprechend den Vorschriften des Gebrauchsmustergesetzes, lediglich Vorrichtungen wie in den beigefügten Schutzansprüchen definiert, jedoch keine Verfahren. Soweit nachfolgend in der Beschreibung gegebenenfalls auf Verfahren Bezug genommen wird, dienen diese Bezugnahmen lediglich der beispielhaften Erläuterung der in den beigefügten Schutzansprüchen unter Schutz gestellten Vorrichtung oder Vorrichtungen.The disclosure generally relates to the field of computer vision, and more particularly to image recognition. Be provided under protection and subject of the utility model are, according to the provisions of the utility model law, only devices as defined in the appended claims, but no method. Wherever in the description, if appropriate, reference is made to methods, these references are merely illustrative of the device or devices set forth in the appended claims.
BESCHREIBUNG DES VERWANDTEN GEBIETESDESCRIPTION OF THE RELATED AREA
Es gibt heutzutage, dank der Beliebtheit von digitalen Kameras und Positionierungsgeräten viele geogetaggte Bilder in der Welt. Viele der geogetaggten Bilder zeigen oder verweisen auf einen oder mehrere Betriebe (z. B. eine Geschäftsfassade, ein Firmenschild). Derzeit gibt es keine effiziente Technik für einen Computer, um zu identifizieren, welche Betriebe gezeigt oder auf welche Betriebe in einem geogetaggten Bild verwiesen wird.Today, thanks to the popularity of digital cameras and positioning devices, there are many geo-tagged images in the world. Many of the geo-tagged images show or refer to one or more businesses (eg a business façade, a company sign). Currently, there is no efficient technique for a computer to identify which operations are shown or which operations are referenced in a geo-tagged image.
ZUSAMMENFASSUNGSUMMARY
Ausführungsformen der vorliegenden Offenbarungen beinhalten ein computerimplemetiertes Verfahren (und ein entsprechendes Computersystem und nicht-flüchtiges computerlesbares Medium) zum Identifizieren eines Betriebs in einem geogetaggten Bild. Das Verfahren umfasst das Erkennen von Textfolgen im geogetaggten Bild und identifiziert einen Betrieb in der Nähe eines geografischen Orts, der durch ein Geotag des geogetaggten Bildes spezifiziert ist. Das Verfahren umfasst das Entnehmen eines Satzes aus Informationen, die mit dem Betrieb in der Nähe des geografischen Orts verbunden sind und vergleicht die Textfolgen mit dem Satz, um eine Übereinstimmung abzuleiten. Das Verfahren umfasst auch die Identifizierung des Betriebs in der Nähe des geografischen Orts als einen Betrieb im geogetaggten Bild, basierend auf der Übereinstimmung.Embodiments of the present disclosures include a computer-implemented method (and computer system and non-transitory computer-readable medium) for identifying operation in a geo-tagged image. The method includes detecting text strings in the geotagged image and identifying an operation near a geographic location specified by geotagging the geo-tagged image. The method includes extracting a set of information associated with operation proximate to the geographic location and comparing the text strings to the sentence to derive a match. The method also includes identifying the operation near the geographic location as an operation in the geotagged image based on the match.
Ausführungsformen der vorliegenden Offenbarung beinhalten auch ein computerimplementiertes Verfahren (und ein entsprechendes Computersystem und nicht-flüchtiges computerlesbares Speichermedium) zum Identifizierens eines Betriebs in einem geogetaggten Bild. Das Verfahren umfasst das Erkennen von zumindest einer Textfolge im geogetaggten Bild und das Identifizieren von zumindest einem Betrieb in der Nähe eines geografischen Orts, der durch ein Geotag des geogetaggten Bildes spezifiziert wurde. Das Verfahren umfasst auch das Entnehmen von zumindest einem Ngramm aus Information, die mit dem zumindest einen Betrieb in der Nähe des geografischen Orts verbunden sind, der die zumindest eine Textfolge mit dem zumindest einen Ngramm vergleicht, um einen oder mehrere Übereinstimmungen abzuleiten, und der einer Übereinstimmung eine Gewichtung zuweist, die auf einem oder mehreren Faktoren basiert. Die Faktoren beinhalten: ein Informationsfeld, aus dem ein Ngramm entnommen wird, das mit der Übereinstimmung verbunden ist, eine Konfidenz, die eine Genauigkeit einer Textfolge misst, die mit einer Übereinstimmung verbunden ist, eine Prävalenz des Ngramms, das mit der Übereinstimmung in einer Sprache verbunden ist, die mit dem Ngramm verknüpft ist, und eine Prävalenz des Ngramms, das mit der Übereinstimmung in einem geografischen Bereich verbunden ist, welches mit dem geogetaggten Bild verknüpft ist. Das Verfahren umfasst zusätzlich das Erzeugen einer Wertung für einen Betrieb, der in der Nähe des geografischen Orts liegt, basierend auf einem oder mehreren der folgenden Faktoren: eine Anzahl von Übereinstimmungen, die mit Ngrammen verbunden sind, welche aus Informationen entnommen wurden, die mit dem Betrieb verbunden sind, einer Gewichtung für eine Übereinstimmung, die einem Ngramm verbunden ist, das aus Informationen entnommen wurde, die mit dem Betrieb verbunden sind, und einer Entfernung zwischen dem geografischen Ort, der durch das Geotag des geogetaggten Bildes und einem Betriebsort spezifiziert wurde. Das Verfahren umfasst außerdem das Identifizieren eines Betriebs in der Nähe des geografischen Orts als Betrieb in dem geogetaggten Bild basierend auf der Wertung.Embodiments of the present disclosure also include a computer implemented method (and corresponding computer system and non-transitory computer readable storage medium) for identifying an operation in a geo-tagged image. The method includes detecting at least one text string in the geotagged image and identifying at least one operation near a geographic location specified by geotagging the geo-tagged image. The method also includes extracting at least one gram of information associated with the at least one operation near the geographic location that compares the at least one text string to the at least one gram to derive one or more matches, and the one Match a weighting based on one or more factors. The factors include: an informational field from which a ngram associated with the match is extracted, a confidence value that measures an accuracy of a text string associated with a match, a prevalence of the nugget that matches the match in a language and a prevalence of the ngramm associated with the match in a geographic area associated with the geo-tagged image. The method additionally includes generating a score for an operation that is proximate to the geographic location based on one or more of the following factors: a number of matches associated with programs derived from information associated with the Operation, a weighting for a match associated with a gram taken from information associated with the operation, and a distance between the geographic location specified by the Geotag of the geo-tagged image and an operation location. The method also includes identifying an operation near the geographic location as an operation in the geo-tagged image based on the score.
Die Funktionen und Vorteile, die in der Spezifikation beschrieben werden, sind nicht alle miteinbeziehend, und viele zusätzlichen Funktionen und Vorteile werden insbesondere einem Fachmann hinsichtlich der Zeichnungen, Spezifikation und Ansprüche offensichtlich werden. Schlussendlich sollte darauf hingewiesen werden, dass die in der Spezifikation verwendete Sprache prinzipiell zu Lesbarkeit- und Anweisungszwecken ausgewählt wurde, und möglicherweise nicht ausgewählt wurde, um die offenbarte Thematik zu schildern oder zu umschreiben.The functions and advantages described in the specification are not all inclusive, and many additional functions and advantages will become apparent to one of ordinary skill in the art in view of the drawings, specification, and claims. Finally, it should be noted that the language used in the specification has been principally selected for readability and instruction purposes, and may not have been selected to delineate or rewrite the disclosed subject matter.
KURZBESCHREIBUNG DER ZEICHNUNGENBRIEF DESCRIPTION OF THE DRAWINGS
AUSFÜHRLICHE BESCHREIBUNGDETAILED DESCRIPTION
Die Figuren (FIGS.) und die nachfolgende Beschreibung bezieht sich nur zu Illustrationszwecken auf bestimmte Ausführungsformen. Fachleute werden anhand der nachfolgenden Diskussion leicht erkennen, dass alternative Ausführungsformen der hierin dargestellten Strukturen und Verfahren verwendet werden können, ohne von den Prinzipien der hierin dargestellten Erfindung abzuweichen. Nun wird im Detail auf mehrere Ausführungsformen Bezug genommen, von denen Beispiele in den begleitenden Figuren veranschaulicht sind. Es wird angemerkt, dass soweit dies praktisch möglich ist, ähnliche oder gleiche Referenzziffern in den Figuren verwendet werden können, die auf ähnliche oder gleiche Funktionalität hinweisen.The figures (FIGS. 1) and the following description refer to specific embodiments only for illustrative purposes. Those skilled in the art will readily recognize from the discussion below that alternative embodiments of the structures and methods presented herein may be used without departing from the principles of the invention set forth herein. Reference will now be made in detail to several embodiments, examples of which are illustrated in the accompanying drawings. It should be noted that, as far as practicable, similar or like reference numerals may be used in the figures, which indicate similar or identical functionality.
Wie angezeigt beinhaltet die Computerumgebung
Der Client
Die geogetaggten Bilder können durch den Client
Der Bildserver
Das Betrieb-Bilderkennungsmodul
Das Netzwerk
Die angezeigten Einheiten in
Ein Arbeitsspeicher
Das Speichergerät
Der Computer
Die Computerarten
Das Bildverarbeitungsmodul
Das Erkennungsmodul für den Textbereich
Das OCR Modul
Die resultierenden OCR-ten Textfolgen werden zusammen „Text-Pool” genannt. Der Text-Pool kann OCR-ten Textfolgen beinhalten, die in einem einzelnen Bild (z. B. für einzelne Bildszenarien) oder in mehreren Bilder (z. B. für Bild Korpus Szenarien) erkannt werden.The resulting OCR-th text strings are collectively called "text pool". The text pool may contain OCR-th text strings that are recognized in a single image (eg, for individual image scenarios) or in multiple images (eg, for image corpus scenarios).
Das Betriebsverarbeitungsmodul
Das nahe Betrieb-Identifikationsmodul
Das Satz-Erzeugungsmodul
Das Bild zum Betrieb eines Erkennungsmoduls
Das annähernde Übereinstimmungsmodul
Das Auswertungs- und Auswahlmodul für einen Betrieb
Für das einzelne Bildszenario erzeugt das Auswertungs- und Auswahlmodul
Das Datengeschäft
Zuerst erhält der Bildserver
Der Bildserver
Zuerst erhält
Der Bildserver
In einer Ausführungsform kann der Bildserver
In einer Ausführungsform kann der Bildserver
Zusätzlich zum Anpassen des erkannten OCR-ten Texts passt der Bildserver
Der Bildserver
Einige Teile der obigen Beschreibung beschreiben die Ausführungsformen als algorithmische Prozesse oder Operationen. Diese algorithmischen Beschreibungen und Darstellungen werden normalerweise von Fachleuten im Bereich der Datenverarbeitung verwendet, um die Essenz ihrer Arbeit anderen Fachleuten auf effektive Weise mitzuteilen. Diese Operationen, obwohl sie funktional, rechnerisch oder logisch beschrieben wurden, werden selbstverständlich von Computerprogrammen implementiert, die Anweisungen zur Ausführung eines Prozessors oder gleichwertigen elektrischen Schaltungseinrichtungen, Mikrocode oder Ähnlichem umfassen. Weiterhin hat es sich zuweilen als zweckmäßig erwiesen, diese Arbeitsabläufe von funktionalen Operationen als Module zu bezeichnen, ohne Einschränkung der Allgemeingültigkeit. Die beschriebenen Operationen und die ihnen zugeordneten Module können in Software Firmware, Hardware oder in jeder beliebigen Kombination daraus ausgeführt werden.Some portions of the above description describe the embodiments as algorithmic processes or operations. These algorithmic descriptions and representations are commonly used by data processing professionals to effectively communicate the essence of their work to other professionals. Of course, these operations, although functionally, computationally or logically described, are implemented by computer programs that include instructions for executing a processor or equivalent electrical circuitry, microcode, or the like. Furthermore, it has sometimes proved convenient to call these functional operations workflows as modules, without limitation of generality. The described operations and their associated modules may be executed in software firmware, hardware, or any combination thereof.
Wie hierin verwendet, bedeuten Verweise auf „eine Ausführungsform” (one embodiment) oder „eine Ausführungsform” (an embodiment), dass ein bestimmtes Element, Merkmal, eine Struktur oder eine Eigenschaft, das/die in Verbindung mit der Ausführungsform beschrieben wird, zumindest in einer Ausführungsform enthalten ist. Das Erscheinen der Formulierung „in einer Ausführungsform” an verschiedenen Orten in der Spezifikation bezieht sich nicht notwendigerweise immer auf dieselbe Ausführungsform.As used herein, references to "one embodiment" or "an embodiment" mean that a particular element, feature, structure, or characteristic described in connection with the embodiment, at least in one embodiment. The appearance of the phrase "in one embodiment" at various locations in the specification does not necessarily always refer to the same embodiment.
Einige Ausführungsformen können mithilfe des Ausdrucks „gekoppelt” und „verbunden” zusammen mit deren Ableitungen beschrieben werden. Es sollte verstanden werden, dass diese Begriffe nicht als Synonyme füreinander gedacht sind. Zum Beispiel können einige Ausführungsformen mithilfe des Begriffs „gekoppelt” beschrieben werden, um anzugeben, dass ein oder mehrere Elemente im direkten physischen oder elektrischen Kontakt sind. Zum Beispiel können einige Ausführungsformen mithilfe des Begriffs „gekoppelt” beschrieben werden, um anzugeben, dass ein oder mehrere Elemente im direkten physischen oder elektrischen Kontakt sind. Der Begriff „gekoppelt” kann jedoch auch bedeuten, dass eines oder mehrere Elemente nicht im direkten Kontakt miteinander sind, aber trotzdem noch miteinander zusammenarbeiten oder interagieren. Die Ausführungsformen sind in diesem Kontext nicht beschränkt.Some embodiments may be described by the term "coupled" and "connected" together with their derivatives. It should be understood that these terms are not intended to be synonymous with each other. For example, some embodiments may be described by the term "coupled" to indicate that one or more elements are in direct physical or electrical contact. For example, some embodiments may be described by the term "coupled" to indicate that one or more elements are in direct physical or electrical contact. However, the term "coupled" may also mean that one or more elements are not in direct contact with each other but still co-operate or interact with each other. The embodiments are not limited in this context.
Wie hierin verwendet, sollen die Begriffe „umfasst”, „umfassend”, „beinhaltet”, „enthält”, „hat”, „haben” und andere Varianten davon eine nicht ausschließliche Einbeziehung abdecken. Zum Beispiel ist ein Prozess, ein Verfahren, ein Artikel oder eine Vorrichtung, der/die eine Liste von Elementen umfasst, nicht notwendigerweise nur auf diese Elemente beschränkt, sondern kann andere Elemente beinhalten, die nicht ausdrücklich aufgelistet oder bei einem solchen Prozess, einem solchen Verfahren, einem solchen Artikel oder einer solchen Vorrichtung inhärent sind. Des Weiteren bezieht sich, sofern nichts Gegenteiliges angegeben, „oder” auf ein einschließendes und nicht auf ein ausschließendes Oder. Zum Beispiel ist eine Bedingung A oder B durch eines der folgenden erfüllt: A ist wahr (oder vorhanden) und B ist falsch (oder nicht vorhanden), A ist falsch (oder nicht vorhanden) und B ist wahr (oder vorhanden) und sowohl A als auch B sind wahr (oder vorhanden).As used herein, the terms "comprising," "comprising," "including," "containing," "having," "having" and other variants thereof are intended to cover a non-exclusive inclusion. For example, a process, method, article, or device that includes a list of elements is not necessarily limited to only these elements, but may include other elements that are not expressly listed or included in any such process Method, such an article or such a device are inherent. Furthermore, unless otherwise specified, "or" refers to an inclusive and not an exclusive or. For example, an A or B condition is satisfied by one of the following: A is true (or exists) and B is false (or absent), A is false (or absent), and B is true (or exists) and both are A as well as B are true (or present).
Außerdem wird „ein” (one), oder „ein” (an) verwendet, um Elemente und Komponenten der Ausführungsformen hierin zu beschreiben. Das erfolgt lediglich aus praktischen Gründen und um eine allgemeine Vorstellung der Offenbarung zu vermitteln. Die Beschreibung sollte so gelesen werden, dass sie eines oder mindestens eines enthält, und der Singular umfasst auch den Plural, außer es ist offensichtlich anders gedacht.In addition, "a", or "on" is used to describe elements and components of the embodiments herein. This is for practical reasons only and to give a general idea of the disclosure. The description should be read to include one or at least one, and the singular also includes the plural, unless it is obviously different.
Nach dem Lesen dieser Offenbarung werden Fachleute durch die hier offenbarten Prinzipien noch zusätzliche alternative Struktur- und Funktionsdesigns für ein System und ein Verfahren für die Identifizierung von Betrieben erkennen. Während bestimmte Ausführungsformen und Anwendungen dargestellt und beschrieben wurden, sollte deshalb verstanden werden, dass das beschriebene Thema nicht auf die hierin genaue Konstruktion und veröffentlichten Komponenten begrenzt ist und dass verschiedene Änderungen, Wechsel und Variationen, die von Fachleuten erkannt werden in der Regelung der Operation und den Details des Verfahrens und dem hierin veröffentlichten Apparats gemacht werden können.After reading this disclosure, those skilled in the art will recognize additional alternative structural and functional designs for a system and method for identifying factories through the principles disclosed herein. Therefore, while particular embodiments and applications have been illustrated and described, it should be understood that the subject matter described is not limited to the precise construction and components disclosed herein and that various changes, alternations, and variations will occur to those skilled in the art the details of the method and apparatus disclosed herein.
Claims (27)
Applications Claiming Priority (6)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US35634210P | 2010-06-18 | 2010-06-18 | |
US61/356,342 | 2010-06-18 | ||
US13/105,853 | 2011-05-11 | ||
US13/105,842 US8385593B2 (en) | 2010-06-18 | 2011-05-11 | Selecting representative images for establishments |
US13/105,842 | 2011-05-11 | ||
US13/105,853 US8379912B2 (en) | 2010-06-18 | 2011-05-11 | Identifying establishments in images |
Publications (1)
Publication Number | Publication Date |
---|---|
DE202011110876U1 true DE202011110876U1 (en) | 2017-01-18 |
Family
ID=45328727
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
DE202011110876.0U Expired - Lifetime DE202011110876U1 (en) | 2010-06-18 | 2011-05-31 | Identifying plants in images |
Country Status (4)
Country | Link |
---|---|
US (5) | US8385593B2 (en) |
EP (1) | EP2583201B1 (en) |
DE (1) | DE202011110876U1 (en) |
WO (1) | WO2011159460A2 (en) |
Families Citing this family (54)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
EP2629211A1 (en) * | 2009-08-21 | 2013-08-21 | Mikko Kalervo Väänänen | Method and means for data searching and language translation |
US8611592B2 (en) * | 2009-08-26 | 2013-12-17 | Apple Inc. | Landmark identification using metadata |
JP2011055250A (en) * | 2009-09-02 | 2011-03-17 | Sony Corp | Information providing method and apparatus, information display method and mobile terminal, program, and information providing system |
US8385593B2 (en) * | 2010-06-18 | 2013-02-26 | Google Inc. | Selecting representative images for establishments |
US8670618B2 (en) * | 2010-08-18 | 2014-03-11 | Youwho, Inc. | Systems and methods for extracting pedigree and family relationship information from documents |
US9846688B1 (en) | 2010-12-28 | 2017-12-19 | Amazon Technologies, Inc. | Book version mapping |
US8798366B1 (en) * | 2010-12-28 | 2014-08-05 | Amazon Technologies, Inc. | Electronic book pagination |
US9069767B1 (en) | 2010-12-28 | 2015-06-30 | Amazon Technologies, Inc. | Aligning content items to identify differences |
US9881009B1 (en) | 2011-03-15 | 2018-01-30 | Amazon Technologies, Inc. | Identifying book title sets |
US8749580B1 (en) * | 2011-08-12 | 2014-06-10 | Google Inc. | System and method of texturing a 3D model from video |
US20130061147A1 (en) * | 2011-09-07 | 2013-03-07 | Nokia Corporation | Method and apparatus for determining directions and navigating to geo-referenced places within images and videos |
WO2013085409A1 (en) * | 2011-12-08 | 2013-06-13 | Общество С Ограниченной Ответственностью Базелевс-Инновации | Method for animating sms messages |
US9165206B2 (en) * | 2011-12-12 | 2015-10-20 | Google Inc. | Updating point of interest data based on an image |
US8489585B2 (en) * | 2011-12-20 | 2013-07-16 | Xerox Corporation | Efficient document processing system and method |
US9430876B1 (en) * | 2012-05-10 | 2016-08-30 | Aurasma Limited | Intelligent method of determining trigger items in augmented reality environments |
US9020278B2 (en) * | 2012-06-08 | 2015-04-28 | Samsung Electronics Co., Ltd. | Conversion of camera settings to reference picture |
US20140019867A1 (en) * | 2012-07-12 | 2014-01-16 | Nokia Corporation | Method and apparatus for sharing and recommending content |
US8843493B1 (en) * | 2012-09-18 | 2014-09-23 | Narus, Inc. | Document fingerprint |
US9071785B2 (en) | 2013-02-15 | 2015-06-30 | Gradeable, Inc. | Adjusting perspective distortion of an image |
US10176500B1 (en) * | 2013-05-29 | 2019-01-08 | A9.Com, Inc. | Content classification based on data recognition |
US9262438B2 (en) * | 2013-08-06 | 2016-02-16 | International Business Machines Corporation | Geotagging unstructured text |
US9069794B1 (en) * | 2013-10-11 | 2015-06-30 | Google Inc. | Determining location information for images using landmark, caption, and metadata location data |
US9734168B1 (en) * | 2013-12-08 | 2017-08-15 | Jennifer Shin | Method and system for organizing digital files |
US9466009B2 (en) | 2013-12-09 | 2016-10-11 | Nant Holdings Ip. Llc | Feature density object classification, systems and methods |
US9652442B1 (en) * | 2014-01-24 | 2017-05-16 | Google Inc. | Virtual photo wall |
US9361317B2 (en) * | 2014-03-04 | 2016-06-07 | Qbase, LLC | Method for entity enrichment of digital content to enable advanced search functionality in content management systems |
US9794229B2 (en) * | 2015-04-03 | 2017-10-17 | Infoblox Inc. | Behavior analysis based DNS tunneling detection and classification framework for network security |
US10210580B1 (en) * | 2015-07-22 | 2019-02-19 | Intuit Inc. | System and method to augment electronic documents with externally produced metadata to improve processing |
US10467284B2 (en) * | 2015-08-03 | 2019-11-05 | Google Llc | Establishment anchoring with geolocated imagery |
US9870351B2 (en) * | 2015-09-24 | 2018-01-16 | International Business Machines Corporation | Annotating embedded tables |
US20180300341A1 (en) * | 2017-04-18 | 2018-10-18 | International Business Machines Corporation | Systems and methods for identification of establishments captured in street-level images |
US20190251138A1 (en) | 2018-02-09 | 2019-08-15 | Banjo, Inc. | Detecting events from features derived from multiple ingested signals |
US10324948B1 (en) | 2018-04-27 | 2019-06-18 | Banjo, Inc. | Normalizing ingested signals |
US10257058B1 (en) | 2018-04-27 | 2019-04-09 | Banjo, Inc. | Ingesting streaming signals |
US10581945B2 (en) | 2017-08-28 | 2020-03-03 | Banjo, Inc. | Detecting an event from signal data |
US10313413B2 (en) | 2017-08-28 | 2019-06-04 | Banjo, Inc. | Detecting events from ingested communication signals |
US11025693B2 (en) | 2017-08-28 | 2021-06-01 | Banjo, Inc. | Event detection from signal data removing private information |
US10585724B2 (en) | 2018-04-13 | 2020-03-10 | Banjo, Inc. | Notifying entities of relevant events |
US10324935B1 (en) | 2018-02-09 | 2019-06-18 | Banjo, Inc. | Presenting event intelligence and trends tailored per geographic area granularity |
US10313865B1 (en) | 2018-04-27 | 2019-06-04 | Banjo, Inc. | Validating and supplementing emergency call information |
US10261846B1 (en) | 2018-02-09 | 2019-04-16 | Banjo, Inc. | Storing and verifying the integrity of event related data |
US10970184B2 (en) | 2018-02-09 | 2021-04-06 | Banjo, Inc. | Event detection removing private information |
JP6874729B2 (en) * | 2018-04-02 | 2021-05-19 | 日本電気株式会社 | Image processing equipment, image processing methods and programs |
US10353934B1 (en) * | 2018-04-27 | 2019-07-16 | Banjo, Inc. | Detecting an event from signals in a listening area |
US10904720B2 (en) | 2018-04-27 | 2021-01-26 | safeXai, Inc. | Deriving signal location information and removing private information from it |
US10327116B1 (en) | 2018-04-27 | 2019-06-18 | Banjo, Inc. | Deriving signal location from signal content |
US11386636B2 (en) | 2019-04-04 | 2022-07-12 | Datalogic Usa, Inc. | Image preprocessing for optical character recognition |
US10582343B1 (en) | 2019-07-29 | 2020-03-03 | Banjo, Inc. | Validating and supplementing emergency call information |
US11521400B2 (en) | 2019-12-06 | 2022-12-06 | Synamedia Limited | Systems and methods for detecting logos in a video stream |
US11232135B2 (en) * | 2020-04-02 | 2022-01-25 | Shantanu Bhattacharyya | Methods and system of using N-gram analysis to discover points of interest in a given geographic region |
US11916942B2 (en) | 2020-12-04 | 2024-02-27 | Infoblox Inc. | Automated identification of false positives in DNS tunneling detectors |
US20230044871A1 (en) * | 2020-12-29 | 2023-02-09 | Google Llc | Search Results With Result-Relevant Highlighting |
US11756447B1 (en) | 2021-09-13 | 2023-09-12 | Christine Hoffman | System for teaching music notation and associated method of use |
CN114116616B (en) * | 2022-01-26 | 2022-05-17 | 上海朝阳永续信息技术股份有限公司 | Method, apparatus and medium for mining PDF files |
Family Cites Families (21)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6161131A (en) | 1998-10-02 | 2000-12-12 | Garfinkle; Jeffrey | Digital real time postcards including information such as geographic location or landmark |
US6608930B1 (en) | 1999-08-09 | 2003-08-19 | Koninklijke Philips Electronics N.V. | Method and system for analyzing video content using detected text in video frames |
US6937766B1 (en) | 1999-04-15 | 2005-08-30 | MATE—Media Access Technologies Ltd. | Method of indexing and searching images of text in video |
US20060002590A1 (en) | 2004-06-30 | 2006-01-05 | Borak Jason M | Method of collecting information for a geographic database for use with a navigation system |
US9451219B2 (en) * | 2004-12-31 | 2016-09-20 | Nokia Technologies Oy | Provision of target specific information |
US7917286B2 (en) * | 2005-12-16 | 2011-03-29 | Google Inc. | Database assisted OCR for street scenes and other images |
US8098934B2 (en) | 2006-06-29 | 2012-01-17 | Google Inc. | Using extracted image text |
US7953295B2 (en) | 2006-06-29 | 2011-05-31 | Google Inc. | Enhancing text in images |
KR101421704B1 (en) | 2006-06-29 | 2014-07-22 | 구글 인코포레이티드 | Recognizing text in images |
US8031940B2 (en) | 2006-06-29 | 2011-10-04 | Google Inc. | Recognizing text in images using ranging data |
KR100775123B1 (en) * | 2006-09-15 | 2007-11-08 | 삼성전자주식회사 | Method of indexing image object and image object indexing system using the same |
US7698336B2 (en) | 2006-10-26 | 2010-04-13 | Microsoft Corporation | Associating geographic-related information with objects |
WO2009075689A2 (en) | 2006-12-21 | 2009-06-18 | Metacarta, Inc. | Methods of systems of using geographic meta-metadata in information retrieval and document displays |
US20080243906A1 (en) | 2007-03-31 | 2008-10-02 | Keith Peters | Online system and method for providing geographic presentations of localities that are pertinent to a text item |
US20080268876A1 (en) * | 2007-04-24 | 2008-10-30 | Natasha Gelfand | Method, Device, Mobile Terminal, and Computer Program Product for a Point of Interest Based Scheme for Improving Mobile Visual Searching Functionalities |
US8676001B2 (en) * | 2008-05-12 | 2014-03-18 | Google Inc. | Automatic discovery of popular landmarks |
US10210179B2 (en) | 2008-11-18 | 2019-02-19 | Excalibur Ip, Llc | Dynamic feature weighting |
US8396287B2 (en) * | 2009-05-15 | 2013-03-12 | Google Inc. | Landmarks from digital photo collections |
US9477667B2 (en) | 2010-01-14 | 2016-10-25 | Mobdub, Llc | Crowdsourced multi-media data relationships |
US8385593B2 (en) * | 2010-06-18 | 2013-02-26 | Google Inc. | Selecting representative images for establishments |
US20120084323A1 (en) * | 2010-10-02 | 2012-04-05 | Microsoft Corporation | Geographic text search using image-mined data |
-
2011
- 2011-05-11 US US13/105,842 patent/US8385593B2/en active Active
- 2011-05-11 US US13/105,853 patent/US8379912B2/en active Active
- 2011-05-31 DE DE202011110876.0U patent/DE202011110876U1/en not_active Expired - Lifetime
- 2011-05-31 EP EP11796149.0A patent/EP2583201B1/en active Active
- 2011-05-31 WO PCT/US2011/038568 patent/WO2011159460A2/en active Application Filing
- 2011-09-27 US US13/246,809 patent/US8532333B2/en not_active Expired - Fee Related
- 2011-09-27 US US13/246,812 patent/US8265400B2/en active Active
-
2013
- 2013-09-06 US US14/019,670 patent/US8811656B2/en active Active
Also Published As
Publication number | Publication date |
---|---|
EP2583201A4 (en) | 2017-04-26 |
US20120020578A1 (en) | 2012-01-26 |
US20120121195A1 (en) | 2012-05-17 |
US20140003650A1 (en) | 2014-01-02 |
WO2011159460A2 (en) | 2011-12-22 |
EP2583201A2 (en) | 2013-04-24 |
WO2011159460A3 (en) | 2012-04-05 |
US20110311140A1 (en) | 2011-12-22 |
US8532333B2 (en) | 2013-09-10 |
EP2583201B1 (en) | 2023-07-12 |
US8385593B2 (en) | 2013-02-26 |
US20120020565A1 (en) | 2012-01-26 |
US8379912B2 (en) | 2013-02-19 |
US8811656B2 (en) | 2014-08-19 |
US8265400B2 (en) | 2012-09-11 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
DE202011110876U1 (en) | Identifying plants in images | |
US9454714B1 (en) | Sequence transcription with deep neural networks | |
US9317777B2 (en) | Analyzing font similarity for presentation | |
EP3117369B1 (en) | Detecting and extracting image document components to create flow document | |
US10043231B2 (en) | Methods and systems for detecting and recognizing text from images | |
DE112015006255T5 (en) | Object recognition device, object recognition method, and program | |
DE112016001830T5 (en) | Discovering companies from images | |
CN111191695A (en) | Website picture tampering detection method based on deep learning | |
US11227153B2 (en) | Automated systems and methods for identifying fields and regions of interest within a document image | |
CN105608454A (en) | Text structure part detection neural network based text detection method and system | |
US20180173681A1 (en) | System and method for generating content pertaining to real property assets | |
CN110059539A (en) | A kind of natural scene text position detection method based on image segmentation | |
CN112966685B (en) | Attack network training method and device for scene text recognition and related equipment | |
CN111353491A (en) | Character direction determining method, device, equipment and storage medium | |
CN106127042A (en) | Webpage visual similarity recognition method | |
US9122943B1 (en) | Identifying rendering differences between label rendering engines | |
US11210507B2 (en) | Automated systems and methods for identifying fields and regions of interest within a document image | |
DE202016007840U1 (en) | Anchoring facilities with geolocalized imagery | |
CN112396060B (en) | Identification card recognition method based on identification card segmentation model and related equipment thereof | |
EP3564833B1 (en) | Method and device for identifying main picture in web page | |
CN111881900B (en) | Corpus generation method, corpus translation model training method, corpus translation model translation method, corpus translation device, corpus translation equipment and corpus translation medium | |
CN111222000B (en) | Image classification method and system based on graph convolution neural network | |
US10043070B2 (en) | Image-based quality control | |
JP2011238057A (en) | Image ranking method, program, and storage medium and image display system | |
Qiao et al. | Spatial relationship-assisted classification from high-resolution remote sensing imagery |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
R207 | Utility model specification | ||
R150 | Utility model maintained after payment of first maintenance fee after three years | ||
R151 | Utility model maintained after payment of second maintenance fee after six years | ||
R081 | Change of applicant/patentee |
Owner name: GOOGLE LLC (N.D.GES.D. STAATES DELAWARE), MOUN, USFree format text: FORMER OWNER: GOOGLE INC., MOUNTAIN VIEW, CALIF., US |
|
R082 | Change of representative |
Representative=s name: BETTEN & RESCH PATENT- UND RECHTSANWAELTE PART, DE |
|
R081 | Change of applicant/patentee |
Owner name: GOOGLE LLC (N.D.GES.D. STAATES DELAWARE), MOUN, USFree format text: FORMER OWNER: GOOGLE LLC (N.D.GES.D. STAATES DELAWARE), MOUNTAIN VIEW, CALIF., US |
|
R082 | Change of representative |
Representative=s name: BETTEN & RESCH PATENT- UND RECHTSANWAELTE PART, DE |
|
R152 | Utility model maintained after payment of third maintenance fee after eight years | ||
R079 | Amendment of ipc main class |
Free format text: PREVIOUS MAIN CLASS: G06F0017300000Ipc: G06F0016000000 |
|
R071 | Expiry of right |