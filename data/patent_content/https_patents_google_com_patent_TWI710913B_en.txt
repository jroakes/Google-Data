TWI710913B - Method of executing a tuple graph program across a network - Google Patents
Method of executing a tuple graph program across a network Download PDFInfo
- Publication number
- TWI710913B TWI710913B TW107116380A TW107116380A TWI710913B TW I710913 B TWI710913 B TW I710913B TW 107116380 A TW107116380 A TW 107116380A TW 107116380 A TW107116380 A TW 107116380A TW I710913 B TWI710913 B TW I710913B
- Authority
- TW
- Taiwan
- Prior art keywords
- partitions
- partition
- program
- operations
- graph
- Prior art date
Links
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L47/00—Traffic control in data switching networks
- H04L47/10—Flow control; Congestion control
- H04L47/12—Avoiding congestion; Recovering from congestion
- H04L47/125—Avoiding congestion; Recovering from congestion by balancing the load, e.g. traffic engineering
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/46—Multiprogramming arrangements
- G06F9/50—Allocation of resources, e.g. of the central processing unit [CPU]
- G06F9/5005—Allocation of resources, e.g. of the central processing unit [CPU] to service a request
- G06F9/5027—Allocation of resources, e.g. of the central processing unit [CPU] to service a request the resource being a machine, e.g. CPUs, Servers, Terminals
- G06F9/5038—Allocation of resources, e.g. of the central processing unit [CPU] to service a request the resource being a machine, e.g. CPUs, Servers, Terminals considering the execution order of a plurality of tasks, e.g. taking priority or time dependency constraints into consideration
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/44—Arrangements for executing specific programs
- G06F9/448—Execution paradigms, e.g. implementations of programming paradigms
- G06F9/4494—Execution paradigms, e.g. implementations of programming paradigms data driven
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/46—Multiprogramming arrangements
- G06F9/50—Allocation of resources, e.g. of the central processing unit [CPU]
- G06F9/5061—Partitioning or combining of resources
- G06F9/5066—Algorithms for mapping a plurality of inter-dependent sub-tasks onto a plurality of physical CPUs
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L41/00—Arrangements for maintenance, administration or management of data switching networks, e.g. of packet switching networks
- H04L41/12—Discovery or management of network topologies
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L67/00—Network arrangements or protocols for supporting network services or applications
- H04L67/01—Protocols
- H04L67/10—Protocols in which an application is distributed across nodes in the network
Abstract
Description
雲計算允許使用者具有用以使用共用可組態資源集區來儲存及處理資料以實現成本及計算效率之各種計算能力。用於雲計算之當前程式化模型包含MapReduce、Dryad及整體同步並行(Bulk Synchronous Parallel)雲處理。面對分散式計算之問題中之一者係效能。一分散式計算中之效能與資料至計算單元之一近接及計算單元之間的資料傳送成本有關。 Cloud computing allows users to have various computing capabilities to use shared configurable resource pools to store and process data to achieve cost and computing efficiency. The current programming models for cloud computing include MapReduce, Dryad, and Bulk Synchronous Parallel cloud processing. One of the problems facing decentralized computing is performance. The performance of a distributed calculation is related to the cost of data transmission to one of the computing units and the data transfer between the computing units.
本發明闡述用於雲計算之一新程式化模型。該新程式化模型可用於寫入分散式低延時非批程式。一應用程式根據該模型而建構一程式，且然後提交該程式以用於執行。該程式由運算子之一有向非循環圖形組成。值串流沿著圖形中之邊緣自一個運算子流動至另一運算子。透過一串流而發送之每一值係一元組。同一程式中之不同運算子可在不同機器上運行。程式化模型協調此等運算子在不同機器上之執行且將資料自一個運算子傳播至另一運算子。 The present invention describes a new stylized model for cloud computing. The new programming model can be used to write distributed low-latency non-batch programs. An application program constructs a program according to the model, and then submits the program for execution. The program consists of a directed acyclic graph of one of the operators. The value stream flows from one operator to another along the edges in the graph. Each value sent through a stream is a tuple. Different operators in the same program can be run on different machines. The stylized model coordinates the execution of these operators on different machines and propagates data from one operator to another.
程式化模型之一項態樣提供一種用於在一分散式架構中執 行一程式之方法，該方法包括：由該分散式架構之一或多個第一分區(shards)執行一或多個操作；自該一或多個第一分區將元組發送至至少一個第二分區，該等元組係一串流之一部分且基於該一或多個操作；當該串流中之該等元組之該發送完成時，自該一或多個第一分區中之每一者將一符記值發送至該至少一個第二分區。該方法進一步包含：由該第二分區判定該等符記值之一總數是否匹配該一或多個第一分區之一數目；及回應於判定該等符記值之該總數匹配該一或多個第一分區之該數目而採取一第一動作。該第一動作可包含將該串流標記為已完成及/或產生指示該串流已完成之一訊息。 One aspect of the stylized model provides a way to execute in a distributed architecture A method of executing a program, the method includes: executing one or more operations by one or more first partitions (shards) of the distributed architecture; sending tuples from the one or more first partitions to at least one first partition Two partitions, the tuples are part of a stream and based on the one or more operations; when the sending of the tuples in the stream is completed, from each of the one or more first partitions One sends a token value to the at least one second partition. The method further includes: determining, by the second partition, whether a total of the symbol values matches the number of the one or more first partitions; and responding to determining that the total of the symbol values matches the one or more Take a first action for the number of first partitions. The first action may include marking the stream as completed and/or generating a message indicating that the stream is completed.
該至少一個第二分區係該一或多個第一分區中之一者之一接收分區。該方法可進一步包含：由該一或多個第一分區中之該一者產生該一或多個第一分區與其進行通信之該等接收分區之一清單；及由該一或多個第一分區中之該一者將該清單傳輸至一控制器。另外，該控制器可追蹤已起始處理之所有接收分區；判定該等接收分區中之已起始處理之一或多者是否不存在於該清單中；及針對已起始處理且不存在於該清單中之每一接收分區，將代表該一或多個第一分區中之該一者之一符記值發送至該接收分區。在某些實例中，該方法可進一步包含：由一控制器判定是否有任何分區未起始處理；由該控制器判定未開始處理之該等分區是否被該程式之設計故意跳過；及由該控制器代表未開始處理之任何被故意跳過之分區將一符記值發送至該第二分區。 The at least one second partition is a receiving partition of one of the one or more first partitions. The method may further include: generating from the one of the one or more first partitions a list of the receiving partitions with which the one or more first partitions communicate; and generating from the one or more first partitions The one of the partitions transmits the list to a controller. In addition, the controller can track all the receiving partitions that have started processing; determine whether one or more of the started processing in the receiving partitions does not exist in the list; and for the started processing and does not exist in the list Each receiving partition in the list sends a token value representing the one of the one or more first partitions to the receiving partition. In some instances, the method may further include: determining by a controller whether there are any partitions that have not been processed; determining by the controller whether the partitions that have not been processed are deliberately skipped by the design of the program; and The controller sends a token value to the second partition on behalf of any deliberately skipped partition that has not yet started processing.
本發明之另一態樣提供一種系統，該系統包括：一分散式計算環境中之一或多個第一分區；及該分散式計算環境中之至少一個第二分區，該至少一個第二分區遠離該一或多個第一分區。該一或多個第一分 區經組態以：執行一或多個操作；將元組發送至至少一個第二分區，該等元組係一串流之一部分且基於該一或多個操作；及當該串流中之該等元組之該發送完成時，將一符記值發送至該至少一個第二分區。該至少一個第二分區經組態以：判定該等符記值之一總數是否匹配該一或多個第一分區之一數目；及回應於判定該等符記值之該總數匹配該一或多個第一分區之該數目而採取一第一動作。 Another aspect of the present invention provides a system that includes: one or more first partitions in a distributed computing environment; and at least one second partition in the distributed computing environment, the at least one second partition Away from the one or more first partitions. The one or more first points The area is configured to: perform one or more operations; send tuples to at least one second partition, the tuples being part of a stream and based on the one or more operations; and when the stream is When the sending of the tuples is completed, a token value is sent to the at least one second partition. The at least one second partition is configured to: determine whether a total of the token values matches the number of the one or more first partitions; and in response to determining that the total of the token values matches the one or Take a first action for the number of first partitions.
該系統可進一步包含與該一或多個第一分區、該至少一個第二分區或控制器中之至少一者進行通信之一用戶端裝置。該用戶端裝置可經組態以：建構一圖形，其中該圖形之每一節點表示一分區；及基於該圖形而驗證是否將跨分散式架構準確地執行程式。該用戶端裝置可進一步經組態以在執行該程式時動態地構建該圖形之啟動。 The system may further include a client device in communication with at least one of the one or more first partitions, the at least one second partition, or the controller. The client device can be configured to: construct a graph in which each node of the graph represents a partition; and verify based on the graph whether the program will be executed accurately across the distributed architecture. The client device can be further configured to dynamically construct the activation of the graph when the program is executed.
在某些實例中，在分散式架構中之一計算裝置上執行之一動態發送操作。該動態發送操作將一資料輸入串流發送至一目的地圖形之所有啟動；且自該控制器接收新元組，該等新元組係在偵測到該目的地圖形之額外啟動時被接收。 In some instances, a dynamic sending operation is performed on a computing device in a distributed architecture. The dynamic sending operation sends a data input stream to all activations of a destination graphic; and receives new tuples from the controller, which are received when additional activations of the destination graphic are detected .
110:用戶端 110: client
120:處理器 120: processor
130:記憶體 130: memory
132:指令 132: Instruction
134:資料 134: Information
136:應用程式 136: Application
150:網路 150: Network
160:資料中心 160: Data Center
162:計算裝置 162: Computing Device
164:計算裝置 164: Computing Device
170:資料中心 170: Data Center
172:計算裝置 172: Computing Device
180:資料中心 180: Data Center
181:計算裝置 181: Computing Device
182:計算裝置 182: Computing Device
183:計算裝置 183: Computing Device
184:計算裝置 184: Computing Device
185:計算裝置 185: computing device
186:計算裝置 186: Computing Device
190:控制器 190: Controller
192:記憶體 192: Memory
194:資料 194: Information
196:指令 196: Instruction
198:處理器 198: Processor
210:輸入操作 210: input operation
215:串流 215: Streaming
220:ListImages操作/ListImages 220: ListImages operation/ListImages
225:串流 225: Streaming
226:快取記憶體中查找操作 226: Search operation in cache
227:串流 227: Streaming
228:串流 228: Streaming
230:查找運算子/查找 230: search operator/search
235:串流 235: Streaming
240:縮圖操作 240: Thumbnail operation
245:所產生縮圖 245: generated thumbnail
250:輸出 250: output
500:類型推論方法 500: Type inference method
510:方塊 510: Block
520:方塊 520: Block
530:方塊 530: Block
540:方塊 540: Block
550:方塊 550: Block
560:方塊 560: Block
610:引數 610: Argument
620:查找 620: find
630:濾波器 630: filter
640:結果 640: result
710:引數 710: Argument
720:查找 720: Find
730:濾波器 730: filter
740:結果 740: result
815:邊緣 815: edge
825:邊緣 825: edge
835:邊緣 835: edge
920:查找 920: Find
930:處理 930: processing
940:查找 940: Find
1020:查找 1020: find
1030:查找 1030: find
1110:第一輸入引數 1110: the first input argument
1115:邊緣 1115: edge
1125:邊緣 1125: Edge
1130:第一查找操作/查找操作 1130: First search operation/search operation
1135:邊緣 1135: Edge
1140:第二查找操作/查找操作 1140: Second search operation/search operation
1145:邊緣 1145: Edge
1150:ZipAny操作/ZipAny 1150: ZipAny operation/ZipAny
1155:邊緣 1155: Edge
1160:選擇操作/選擇 1160: Select operation/selection
1165:邊緣 1165: edge
1170:結果 1170: result
1211:邊緣 1211: Edge
1212:邊緣 1212: Edge
1213:邊緣 1213: Edge
1214:邊緣 1214: Edge
1215:邊緣 1215: Edge
1216:邊緣 1216: Edge
1217:邊緣 1217: Edge
1218:邊緣 1218: Edge
1219:邊緣 1219: Edge
1220:邊緣 1220: Edge
1221:邊緣 1221: Edge
1222:邊緣 1222: Edge
1310:子圖 1310: subgraph
1312:子圖 1312: subgraph
1313:子圖 1313: subgraph
1315:子圖 1315: subgraph
1316:子圖 1316: subgraph
1317:子圖 1317: subgraph
1318:子圖 1318: subgraph
1320:子圖 1320: subgraph
1322:新子圖 1322: new subgraph
1413:子圖 1413: subgraph
1432:No-op操作 1432: No-op operation
1434:No-op操作 1434: No-op operation
1450:合併圖形 1450: merge graphics
1452:子圖 1452: subgraph
1453:子圖 1453: subgraph
1454:子圖 1454: subgraph
1455:子圖 1455: subgraph
1456:子圖 1456: subgraph
1458:子圖 1458: subgraph
1600:方法 1600: method
1610:方塊 1610: block
1620:方塊 1620: block
1630:方塊 1630: block
1640:方塊 1640: Block
1650:方塊 1650: block
1700:方法 1700: method
1710:方塊 1710: Block
1720:方塊 1720: Block
1730:方塊 1730: Block
1740:方塊 1740: Block
1800:方法 1800: method
1810:方塊 1810: block
1820:方塊 1820: block
1830:方塊 1830: block
1840:方塊 1840: Block
2500:方法 2500: method
2510:方塊 2510: block
2520:方塊 2520: Block
2530:方塊 2530: block
2540:方塊 2540: Block
2550:方塊 2550: block
A:節點 A: Node
B:節點/操作/封鎖操作 B: Node/operation/blocking operation
B0:節點/下游節點 B0: node/downstream node
B1:節點/下游節點/分區 B1: node/downstream node/partition
B2:節點/下游節點 B2: node/downstream node
B3:節點 B3: Node
C:目的地節點/節點/位置/控制器/操作 C: Destination node/node/location/controller/operation
C0:分區 C0: partition
C1:分區/節點 C1: partition/node
C2:節點 C2: Node
D:節點/操作 D: node/operation
D’:新操作/節點 D’: New operation/node
E:節點/目的地節點 E: node/destination node
F:節點 F: Node
G:節點/非唯一圖形/目的地圖形 G: node/non-unique graph/destination graph
G’:新操作/節點 G’: New operation/node
G0:單獨圖形/圖形 G0: separate graph/graph
G1:單獨圖形/圖形 G1: separate graph/graph
G2:單獨圖形 G2: separate graphics
G3:單獨圖形 G3: separate graphics
H:節點 H: node
I:節點 I: Node
J:節點 J: Node
K:節點 K: node
L:位置 L: location
R1:分區 R1: partition
S1:串流/發送者 S1: Streamer/Sender
S2:串流/動態發送操作 S2: Streaming/dynamic sending operation
SL:位置/經分區位置 SL: location/zoned location
X:常規輸入 X: regular input
Y:輸入 Y: input
圖1係根據本發明之態樣之一實例性系統之一方塊圖。 Figure 1 is a block diagram of an exemplary system according to an aspect of the present invention.
圖2A至圖2B圖解說明根據本發明之態樣之使用程式化模型建立之一程式的一實例。 2A to 2B illustrate an example of creating a program using a stylized model according to aspects of the present invention.
圖3係根據本發明之態樣之列示程式化模型之內建操作之實例的一圖表。 3 is a diagram showing an example of the built-in operation of the stylized model according to the aspect of the present invention.
圖4係根據本發明之態樣之列示針對操作之輸出類型注釋之實例的一圖表。 FIG. 4 is a diagram showing examples of output type annotations for operations according to aspects of the present invention.
圖5提供圖解說明根據本發明之態樣之一實例性類型推論方法之一流程圖。 Figure 5 provides a flowchart illustrating an exemplary type inference method according to an aspect of the present invention.
圖6A至圖6C圖解說明根據本發明之態樣之在程式建立期間之位置指派的一實例。 6A to 6C illustrate an example of location assignment during program creation according to aspects of the present invention.
圖7A至圖7B圖解說明根據本發明之態樣之在圖形建立期間之自動位置指派的一實例。 7A to 7B illustrate an example of automatic position assignment during graph creation according to aspects of the present invention.
圖8A至圖8C圖解說明根據本發明之態樣之分割一圖形以使子圖之一數目最小化的一實例。 8A to 8C illustrate an example of dividing a pattern to minimize the number of sub-pictures according to aspects of the present invention.
圖9A至圖9D提供根據本發明之態樣之針對經分區位置之圖形分割的一實例。 9A to 9D provide an example of graph segmentation for the partitioned position according to aspects of the present invention.
圖10A至圖10B提供根據本發明之態樣之共同位置之一實例。 10A to 10B provide an example of a common position according to aspects of the present invention.
圖11A至圖11C圖解說明根據本發明之態樣之具有多個輸入操作之一程式的一實例。 11A to 11C illustrate an example of a program with multiple input operations according to aspects of the present invention.
圖12圖解說明根據本發明之態樣之一實例性程式。 Figure 12 illustrates an example program according to aspects of the present invention.
圖13A至圖13F闡述根據本發明之態樣之圖12之程式之主要分割的一實例。 13A to 13F illustrate an example of the main division of the program of FIG. 12 according to aspects of the present invention.
圖14A至圖14E闡述根據本發明之態樣之圖12之程式之本端分割的一實例。 14A to 14E illustrate an example of the local division of the program of FIG. 12 according to aspects of the present invention.
圖15圖解說明根據本發明之態樣之在執行主要分割及本端分割之後的圖12之程式。 FIG. 15 illustrates the program of FIG. 12 after performing the main partition and the local partition according to aspects of the present invention.
圖16提供圖解說明根據本發明之態樣之圖形建立及分割之一實例性方法的一流程圖。 Figure 16 provides a flow chart illustrating an exemplary method of graph creation and segmentation according to aspects of the present invention.
圖17提供圖解說明主要圖形分割之一方法之一流程圖。 Figure 17 provides a flow chart illustrating one method of main image segmentation.
圖18提供圖解說明本端分割之一實例性方法之一流程圖。 Figure 18 provides a flowchart illustrating an example method of local segmentation.
圖19係根據本發明之態樣之一唯一圖形之一實例的一圖形圖解說明。 Figure 19 is a graphical illustration of an example of a unique figure according to aspects of the present invention.
圖20係根據本發明之態樣之一實例性非唯一圖形之一圖形圖解說明。 Fig. 20 is a graphical illustration of an exemplary non-unique figure according to an aspect of the present invention.
圖21圖解說明根據本發明之態樣之發送符記值從而用信號通知一串流之完成的一實例。 Figure 21 illustrates an example of sending token values to signal the completion of a stream according to aspects of the present invention.
圖22圖解說明其中一發送節點僅將串流發送至該發送節點所連接至的接收節點之一子集之一實例。 Figure 22 illustrates an example in which a sending node only sends a stream to a subset of the receiving nodes to which the sending node is connected.
圖23圖解說明在存在未經起始發送節點時判定一串流之完成之一實例。 FIG. 23 illustrates an example of determining the completion of a stream when there is an uninitialized sending node.
圖24圖解說明在存在一圖形之多個啟動時判定一串流之完成之一實例。 FIG. 24 illustrates an example of determining the completion of a stream when there are multiple activations of a pattern.
圖25提供圖解說明用於經由一分散式網路而執行一程式之一實例性方法2500之一流程圖。
Figure 25 provides a flowchart illustrating an
一新程式化模型可用於寫入分散式低延時非批程式。一應用程式根據該新模型而建構一程式，且然後提交該程式以用於執行。該程式由運算子之一有向非循環圖形組成。值串流沿著圖形中之邊緣流動。透過一串流而發送之每一值係一元組。同一程式中之不同運算子可在不同機器上運行。程式化模型協調此等運算子在不同機器上之執行且將資料自一 個運算子傳播至另一運算子。 A new programming model can be used to write distributed low-latency non-batch programs. An application program constructs a program based on the new model, and then submits the program for execution. The program consists of a directed acyclic graph of one of the operators. The value stream flows along the edges in the graph. Each value sent through a stream is a tuple. Different operators in the same program can be run on different machines. The programmatic model coordinates the execution of these operators on different machines and integrates the data One operator propagates to another operator.
建構程式包含定義形成圖形之節點之操作。操作接收值串流來作為輸入且發送值串流來作為輸出。每一串流具有一元組類型，且流動穿過串流之所有元組必須匹配彼類型。元組類型由包含一名稱識別符及一欄位類型識別符之欄位定義。在定義操作時，類型推論用於提供使操作彼此交互之一標準化方式。舉例而言，作為其定義之一部分，一操作可係指其輸入及輸出且對該等輸入及輸出設定多種約束。此一約束之一項實例係一輸出類型可被約束為包含輸入之每個欄位。 The construction program includes operations that define the nodes that form the graph. The operation receives a stream of values as input and sends a stream of values as output. Each stream has a tuple type, and all tuples flowing through the stream must match that type. The tuple type is defined by a field containing a name identifier and a field type identifier. When defining operations, type inference is used to provide a standardized way for operations to interact with each other. For example, as part of its definition, an operation can refer to its inputs and outputs and set various constraints on those inputs and outputs. An example of this constraint is that an output type can be constrained to include every field of input.
可在分散式架構中之各種位置處執行圖形中之操作。儘管可在一程式化階段中定義某些運算子位置，但可並不定義其他運算子位置，且可在圖形建立及分割期間將運算子自動指派至其他位置。就此而言，以減少總體網路訊務之一方式自動指派位置。 Operations in graphics can be performed at various locations in the distributed architecture. Although some operator positions can be defined in a programming stage, other operator positions may not be defined, and operators can be automatically assigned to other positions during graph creation and segmentation. In this regard, the location is automatically assigned in a way that reduces overall network traffic.
基於在程式化階段中所定義之操作而建立圖形。可在兩個階段(包含一主要階段及一本端階段)中執行圖形之分割。根據一組約束而執行每一階段。針對主要分割之一第一組約束可不同於針對本端分割之一第二組約束。 Create graphics based on the operations defined in the programming phase. The division of graphics can be performed in two stages (including a main stage and a local stage). Each stage is executed according to a set of constraints. The first set of constraints for one of the main divisions may be different from the second set of constraints for one of the local divisions.
在主要階段中，一第一步驟根據第一組約束而合併子圖，從而使程式中之子圖之一總數目最小化。然後藉由將相鄰未經指派節點併入至某些子圖中而使該等子圖擴大。候選操作首先經檢查以判定其是否已被標記為可分裂的，意指其可在不改變操作之功能性之情況下被分裂成單獨操作。若否，則不將該等候選操作併入至相鄰子圖中。若該等候選操作係可分裂的，則將彼等候選者放置至相鄰子圖中受約束限制。藉由將來自經指派節點之位置複製至其相鄰者而將位置指派至所有未經指派操作。將 在相同位置處運行之可能之未經分區子圖對合併以使子圖之總數目最小化。在某一時刻，進一步合併將係不可能的。 In the main stage, a first step merges subgraphs according to the first set of constraints, thereby minimizing the total number of subgraphs in the formula. Then by merging adjacent unassigned nodes into some subgraphs, the subgraphs are enlarged. The candidate operation is first checked to determine whether it has been marked as splittable, which means that it can be split into individual operations without changing the functionality of the operation. If not, then these candidate operations are not incorporated into adjacent subgraphs. If these candidate operations are splittable, placing them in adjacent subgraphs is subject to constraints. Assign the location to all unassigned operations by copying the location from the assigned node to its neighbors. will The possible unpartitioned pairs of subgraphs running at the same location are merged to minimize the total number of subgraphs. At some point, further mergers will be impossible.
在本端分割階段中，識別需要被分裂(舉例而言，以防止執行中之低效率)之子圖。此等子圖可僅係含有封鎖操作之子圖，該等封鎖操作可在執行I/O之同時遵循一執行緒，從而防止其他操作能夠運行。使圖形準備好進行分裂。此可包含修改子圖以強加本端分割約束。構建一合併圖形，其中每一操作在其自身之一子圖中結束。然後將此等子圖重複地合併在一起。具體而言，將具有外部傳入邊緣之所有操作一起合併至相同子圖中。此外，合併具有非封鎖操作之所有可能之子圖對。 In the local segmentation stage, identify subgraphs that need to be split (for example, to prevent inefficiency in execution). These subgraphs can only be subgraphs that contain blocking operations, and these blocking operations can follow a thread while performing I/O, thereby preventing other operations from being able to run. Prepare the graph for splitting. This can include modifying the subgraph to impose local segmentation constraints. Construct a merged graph, where each operation ends in one of its own subgraphs. Then merge these subgraphs together repeatedly. Specifically, all operations with external incoming edges are merged together into the same subgraph. In addition, merge all possible sub-picture pairs with non-blocking operations.
若針對一經分區服務實施一運算子，則新程式化模型藉由多次例示子圖而對計算進行自動分區。分區提供一延時益處(此乃因並行執行分區)以及一資料效率益處。作為資料效率益處之一實例，放置於一經分區運算子之後的運算子可通常在相同經分區執行個體上運行，從而對最終輸出進行濾波且減少該最終輸出，因此使網路訊務最小化。 If an operator is implemented for a partitioned service, the new stylized model automatically partitions the calculation by instantiating the subgraph multiple times. Partitioning provides a delay benefit (this is due to parallel execution of the partition) and a data efficiency benefit. As an example of data efficiency benefits, operators placed after a partitioned operator can generally run on the same partitioned instance, thereby filtering and reducing the final output, thereby minimizing network traffic.
一旦經分割，圖形便可被執行。在子圖之各別位置處執行該等子圖中之每一者，且在一各別單個執行緒中執行每一子圖。沿著一子圖內之邊緣進行之資料傳送基於其在一單執行緒環境中之執行而被最佳化。 Once split, the graphics can be executed. Each of the sub-graphs is executed at a separate position of the sub-graph, and each sub-graph is executed in a separate single thread. The data transfer along the edges within a sub-picture is optimized based on its execution in a single-threaded environment.
程式化模型之各種態樣允許對程式之高效執行。此等態樣包含(以實例方式而非限制方式)管線化(pipelining)及上文所闡述之分區。管線化提供極低延時。舉例而言，針對由各自花費10ms但涉及數十萬獨立值之一系列5個操作組成之一計算，一個接一個地處理操作將花費50ms。然而，一恰當管線化解決方案可在低至10ms內完成。為了實現此， 在執行期間在運算子之間流式傳輸元組，此導致跨整個程式之較佳管線化。此元組流式傳輸格式跨網路期限提供高效串列化/解串列化。為了使管線在早期起始但達成較高通量，新程式化模型使用動態緩衝區擴大。舉例而言，小訊息在計算中之早期被發送但稍後擴大，此乃因較大訊息係較高效的。 The various aspects of the programming model allow efficient execution of the program. These aspects include (by way of example and not limitation) pipelining and the partitioning described above. Pipelining provides extremely low latency. For example, for one calculation consisting of a series of 5 operations each taking 10ms but involving hundreds of thousands of independent values, it would take 50ms to process the operations one after another. However, a proper pipelined solution can be completed in as little as 10ms. To achieve this, Streaming tuples between operators during execution, which results in better pipelined across the entire program. This tuple streaming format provides efficient serialization/deserialization across network deadlines. In order to start the pipeline early but achieve higher throughput, the new stylized model uses dynamic buffer expansion. For example, small messages are sent early in the calculation but expanded later, because larger messages are more efficient.
新程式化模型亦(舉例而言)藉由在網路節點之間實行流控制而提供低緩衝。舉例而言，發送節點判定一接收者是否係忙碌的，且若如此，則阻止傳輸。在一子圖內，新程式化模型能夠經由本端程序呼叫而在操作之間高效地遞送資料。新程式化模型高效地判定一計算何時完成，且藉由較快地判定完成而提供較低延時。 The new stylized model also (for example) provides low buffering by implementing flow control between network nodes. For example, the sending node determines whether a receiver is busy, and if so, blocks the transmission. Within a sub-picture, the new stylized model can efficiently deliver data between operations via local program calls. The new stylized model efficiently determines when a calculation is completed, and provides lower latency by quickly determining completion.
圖1圖解說明包含一分散式計算環境之一實例性系統。複數個資料中心160、170、180可(舉例而言)經由一網路150而以通信方式耦合。資料中心160、170、180可經由網路150而進一步與一或多個用戶端裝置(諸如用戶端110)進行通信。因此，舉例而言，用戶端110可在「雲」中執行操作。在某些實例中，資料中心160、170、180可進一步與一控制器190進行通信。
Figure 1 illustrates an exemplary system that includes a distributed computing environment. A plurality of data centers 160, 170, and 180 can be communicatively coupled via a
用戶端110可執行一或多個應用程式以用於使用新程式化模型來建立程式。每一用戶端110可為意欲供由一人使用之一個人電腦，其具有通常存在於一個人電腦中之所有內部組件，諸如一中央處理單元(CPU)、CD-ROM、硬碟機及一顯示裝置(舉例而言，具有一螢幕之一監視器、一投影機、一觸控螢幕、一小LCD螢幕、一電視或另一裝置，諸如可操作以顯示由處理器120處理之資訊之一電裝置)、揚聲器、一數據機及 /或網路介面裝置、使用者輸入(諸如一滑鼠、鍵盤、觸控螢幕或麥克風)，且所有該等組件用於使此等元件彼此連接。此外，根據本文中所闡述之系統及方法之電腦可包含能夠處理指令且向人類及其他電腦並自人類及其他電腦傳輸資料之裝置，包含一般用途電腦、PDA、平板電腦、行動電話、智慧型手錶、缺乏本端儲存能力之網路電腦、用於電視之機上盒及其他網路裝置。 The client 110 can execute one or more application programs for creating programs using the new programming model. Each client 110 may be a personal computer intended for use by one person, which has all the internal components normally present in a personal computer, such as a central processing unit (CPU), CD-ROM, hard disk drive and a display device ( For example, a monitor with a screen, a projector, a touch screen, a small LCD screen, a TV or another device, such as an electrical device operable to display information processed by the processor 120) , Speakers, a modem and /Or network interface device, user input (such as a mouse, keyboard, touch screen or microphone), and all these components are used to connect these components to each other. In addition, computers based on the systems and methods described in this article may include devices capable of processing commands and transmitting data to and from humans and other computers, including general-purpose computers, PDAs, tablets, mobile phones, and smart devices. Watches, network computers that lack local storage capabilities, set-top boxes for TVs, and other network devices.
用戶端110可含有通常存在於一般用途電腦中之一處理器120、記憶體130及其他組件。記憶體130可儲存可由處理器120存取之資訊，包含可由處理器120執行之指令132。記憶體亦可包含可由處理器120擷取、操縱或儲存之資料134。記憶體130可為能夠儲存可由處理器120存取之資訊之一種類型之非暫時性電腦可讀媒體，諸如一硬碟機、固態磁碟機、磁帶機、光學儲存裝置、記憶體卡、ROM、RAM、DVD、CD-ROM、具有寫入能力之記憶體及唯讀記憶體。處理器120可為一眾所周知之處理器或其他較罕為人知類型之處理器。另一選擇係，處理器120可為一專用控制器，諸如一ASIC。 The client 110 may include a processor 120, a memory 130, and other components that are commonly found in general-purpose computers. The memory 130 can store information that can be accessed by the processor 120, including instructions 132 that can be executed by the processor 120. The memory may also include data 134 that can be retrieved, manipulated, or stored by the processor 120. The memory 130 may be a type of non-transitory computer-readable medium capable of storing information that can be accessed by the processor 120, such as a hard disk drive, solid state drive, tape drive, optical storage device, memory card, ROM , RAM, DVD, CD-ROM, memory with write capability and read-only memory. The processor 120 may be a well-known processor or other less-known types of processors. Alternatively, the processor 120 may be a dedicated controller, such as an ASIC.
指令132可為由處理器120直接執行(諸如機器碼)或間接執行(諸如描述性語言(script))之一組指令。就此而已，術語「指令」、「步驟」及「程式」可在本文中互換地使用。指令132可以目標碼格式(以用於由處理器120直接處理)或其他類型之電腦語言(包含指令碼或者按需求進行解譯或提前進行編譯之獨立原始程式碼模組之集合)儲存。 The instructions 132 may be a set of instructions executed directly (such as machine code) or indirectly executed (such as a script) by the processor 120. For this reason, the terms "command", "step" and "program" can be used interchangeably in this article. The instruction 132 can be stored in an object code format (for direct processing by the processor 120) or other types of computer languages (including instruction codes or a collection of independent source code modules that are interpreted or compiled in advance).
資料134可由處理器120根據指令132而擷取、儲存或修改。舉例而言，雖然系統及方法不受一特定資料結構限制，但資料134可儲存於電腦暫存器中、儲存於一相關資料庫中作為具有複數個不同欄位及 記錄之表或XML文件。資料134亦可以一電腦可讀格式(諸如但不限於二進位值、ASCII或Unicode)進行格式化。此外，資料134可包含足以識別相關資訊(諸如數目、說明性文字、專屬程式碼、指標、對儲存於其他記憶體(包含其他網路位置)中之資料之參考或由一功能使用以計算相關資料之資訊)之資訊。 The data 134 can be retrieved, stored or modified by the processor 120 according to the instruction 132. For example, although the system and method are not restricted by a specific data structure, the data 134 can be stored in a computer register or in a related database as having a plurality of different fields and Record table or XML file. The data 134 can also be formatted in a computer-readable format (such as but not limited to binary values, ASCII, or Unicode). In addition, the data 134 may contain enough to identify relevant information (such as numbers, descriptive text, exclusive code, indicators, references to data stored in other memories (including other network locations) or used by a function to calculate correlation Data information).
應用程式136可用於根據新程式化模式而建構程式。舉例而言，應用程式136可被下載、可自指令132執行或被遠端存取。在某些實例中，應用程式可被遠端執行。舉例而言，用戶端110可編譯一程式且將該程式發送至雲以用於執行。應用程式136可執行不同功能，諸如類型推論、圖形建立、圖形分割等。舉例而言，一個應用程式可執行多種不同功能，或各種應用程式可各自執行一或多個不同功能。 The application program 136 can be used to construct a program according to the new programming model. For example, the application program 136 can be downloaded, executed from the command 132, or accessed remotely. In some instances, the application can be executed remotely. For example, the client 110 can compile a program and send the program to the cloud for execution. The application program 136 can perform different functions, such as type inference, graph creation, graph segmentation, and so on. For example, one application can perform multiple different functions, or various applications can each perform one or more different functions.
針對類型推論功能，應用程式可經組態以接收資訊，該資訊藉由欄位名稱及類型區分符而定義一操作之屬性。應用程式可進一步接收資訊，該資訊關於該等屬性而定義操作之一行為。基於屬性及行為而判定針對操作之約束。定義操作之一輸入之資訊亦可被接收且連同該等約束一起使用以判定操作之一輸出之一類型。所判定輸出類型可與操作之輸出相關聯。 For the type inference function, the application can be configured to receive information, which defines the attribute of an operation by the field name and type identifier. The application can further receive information, which defines a behavior of the operation regarding these attributes. Determine the constraints for operations based on attributes and behaviors. The information that defines the input of an operation can also be received and used together with the constraints to determine the type of output of an operation. The determined output type can be associated with the output of the operation.
針對圖形建立，可產生複數個節點，其中每一節點對應於程式之一操作。該等節點由邊緣或頂點連接，該等邊緣或頂點表示在該等節點之間發送之串流。舉例而言，可基於計算裝置之程式要求及能力而自動地或藉由程式設計員選擇而手動地將位置指派至特定節點。 For graph creation, multiple nodes can be generated, and each node corresponds to an operation of the program. The nodes are connected by edges or vertices, which represent streams sent between the nodes. For example, the location can be assigned to a specific node automatically or manually by the programmer's choice based on the program requirements and capabilities of the computing device.
針對圖形分割，圖形經最佳化以減少總體網路訊務。舉例而言，在可能之情況下，自動地一起指派用於執行一或多個操作之位置。 如此一來，根據一定數目個預定義約束而合併及分裂節點。可在一本端層級處進一步執行分割，(舉例而言)以使操作在一經分區位置處執行。可根據一組第二單獨約束而執行此本端分割。當編譯程式時，可執行主要分割及本端分割兩者。作為分割之一結果，程式準備好由一或多個資料中心160、170、180中之計算裝置執行，且可被發送以用於執行。 For graphics segmentation, graphics are optimized to reduce overall network traffic. For example, where possible, locations for performing one or more operations are automatically assigned together. In this way, the nodes are merged and split according to a certain number of predefined constraints. The segmentation can be further performed at a local level, (for example) so that the operation is performed at a partitioned location. This local split can be performed based on a set of second individual constraints. When compiling the program, both main partition and local partition can be performed. As a result of the division, the program is ready to be executed by computing devices in one or more data centers 160, 170, 180, and can be sent for execution.
雖然圖1在功能上將處理器120及記憶體130圖解說明為在同一區塊內，但處理器120及記憶體130可實際上包含可或可不儲存於同一實體殼體內之多個處理器及記憶體。舉例而言，指令132及資料134中之某些指令及資料可儲存於一可抽換式CD-ROM上且其他指令及資料儲存於一唯讀電腦晶片內。指令及資料中之某些或全部指令及資料可儲存於實體上遠離處理器120但仍可由處理器120存取之一位置中。類似地，處理器120可實際上包含可或可不並行操作之處理器之一集合。 Although FIG. 1 functionally illustrates the processor 120 and the memory 130 as being in the same block, the processor 120 and the memory 130 may actually include multiple processors that may or may not be stored in the same physical housing. Memory. For example, some commands and data in the commands 132 and data 134 can be stored on a removable CD-ROM and other commands and data can be stored in a read-only computer chip. Some or all of the instructions and data can be stored in a location physically remote from the processor 120 but still accessible by the processor 120. Similarly, the processor 120 may actually include a set of processors that may or may not operate in parallel.
資料中心160至180可定位於距彼此一相當大距離處。舉例而言，資料中心可定位於全世界各個國家中。每一資料中心160、170、180可包含一或多個計算裝置，諸如處理器、伺服器、分區或諸如此類。舉例而言，如圖1中所展示，資料中心160包含計算裝置162、164，資料中心170包含計算裝置172，且資料中心180包含計算裝置181至186。舉例而言，可跨此等計算裝置執行程式，使得某些操作由一第一資料中心之一或多個計算裝置執行而其他操作由一第二資料中心之一或多個計算裝置執行。在某些實例中，各種資料中心中之計算裝置可具有不同能力。舉例而言，不同計算裝置可具有不同處理速度、工作負載等。儘管僅展示此等計算裝置中之幾個計算裝置，但應理解，每一資料中心160、170、180可包含任何數目個計算裝置，且一第一資料中心中之計算裝置之數目可不同於
一第二資料中心中之計算裝置之一數目。此外，應理解，每一資料中心160至180中之計算裝置之數目可隨時間(舉例而言，在硬體被移除、替換、升級或擴展時)變化。
The data centers 160 to 180 can be located at a considerable distance from each other. For example, data centers can be located in various countries around the world. Each data center 160, 170, 180 may include one or more computing devices, such as processors, servers, partitions, or the like. For example, as shown in FIG. 1, the data center 160 includes
在某些實例中，每一資料中心160至180亦可包含一定數目個儲存裝置(未展示)，諸如硬碟機、隨機存取記憶體、磁碟、磁碟陣列、磁帶機或任何其他類型之儲存裝置。資料中心160、170、180可實施包含但不限於以下各項之一定數目個架構及技術中之任一者：直接附加儲存(DAS)、網路附加儲存(NAS)、儲存區域網路(SAN)、光纖通道(FC)、乙太網路光纖通道(FCoE)、混合架構網路或諸如此類。除了儲存裝置之外，資料中心亦可包含一定數目個其他裝置，諸如佈纜、路由器等。此外，在某些實例中，資料中心160至180可為虛擬化環境。此外，儘管僅展示幾個資料中心160至180，但可經由網路150及/或額外網路而耦合眾多資料中心。
In some examples, each data center 160 to 180 may also include a certain number of storage devices (not shown), such as hard drives, random access memory, magnetic disks, disk arrays, tape drives, or any other type The storage device. The data centers 160, 170, and 180 can implement any of a certain number of architectures and technologies including but not limited to the following: direct attached storage (DAS), network attached storage (NAS), storage area network (SAN) ), Fibre Channel (FC), Fibre Channel over Ethernet (FCoE), hybrid architecture network or the like. In addition to storage devices, the data center may also contain a certain number of other devices, such as cabling, routers, etc. In addition, in some instances, the data centers 160 to 180 may be virtualized environments. In addition, although only a few data centers 160 to 180 are shown, many data centers can be coupled via the
在某些實例中，控制器190可與資料中心160至180中之計算裝置進行通信，且可促進程式之執行。舉例而言，控制器190可追蹤每一計算裝置之能力、狀態、工作負載或其他資訊，且使用此資訊來指派任務。控制器190亦可幫助判定是否已完成經由網路而發送串流。舉例而言，在某些情形中，控制器190可發送代表經分區運算子之符記，該等符記由下游節點使用以判定串流已完成。控制器190可包含一處理器198及記憶體192(其包含資料194及指令196)，類似於上文所闡述之用戶端110。 In some instances, the controller 190 can communicate with computing devices in the data centers 160 to 180, and can facilitate the execution of programs. For example, the controller 190 can track the capabilities, status, workload, or other information of each computing device, and use this information to assign tasks. The controller 190 can also help determine whether the stream has been sent via the network. For example, in some situations, the controller 190 may send tokens representing partitioned operators, which tokens are used by downstream nodes to determine that the streaming is complete. The controller 190 may include a processor 198 and a memory 192 (which includes data 194 and instructions 196), similar to the client 110 described above.
用戶端110、資料中心160至180及控制器190可能夠進行直接及間接通信(諸如經由網路150)。舉例而言，使用一網際網路套接口，一
用戶端110可透過一網際網路協定套組而連接至在遠端伺服器上操作之一服務。伺服器可創建監聽套接口，該等監聽套接口可接受一起始連接以用於發送及接收資訊。網路150及介入節點可包含各種組態及協定，包含網際網路、全球資訊網、內部網路、虛擬私人網路、廣域網路、區域網路、使用一或多個公司專屬之通信協定之私人網路、乙太網路、WiFi(例如，702.71、702.71b、g、n或其他此等標準)及HTTP以及前述各項之各種組合。此通信可藉由能夠向其他電腦及自該等其他電腦傳輸資料之一裝置(諸如數據機(例如，撥號、電纜或光纖)及無線介面)而促進。
The client 110, the data centers 160 to 180, and the controller 190 may be capable of direct and indirect communication (such as via the network 150). For example, using an Internet socket, a
The client 110 can connect to a service operating on a remote server through an Internet protocol suite. The server can create listening sockets, which can accept an initial connection for sending and receiving information. The
圖2A至圖2B圖解說明使用程式化模型建立之一程式之一實例。在此程式中，一目標係提取一相簿中之所有影像且針對每一影像產生一縮圖。在程式碼中，可將此目標表示為： 2A to 2B illustrate an example of a program created by using a stylized model. In this program, a goal is to extract all images in an album and generate a thumbnail for each image. In the code, this goal can be expressed as:
然而，若相簿資料儲存於一不同伺服器上，則影像(album_name)呼叫需要一遠端存取。應與一經分區服務並行地發送查找呼叫，該經分區服務傳回給出一影像名稱之影像資料。應與一單獨縮圖伺服器組並行地發送縮圖呼叫。根據本文中所闡述之程式化模型建構及執行之一程式以如下方式達成此分散式執行： However, if the album data is stored on a different server, the image (album_name) call requires a remote access. The search call should be sent in parallel with a partitioned service that returns image data giving an image name. The thumbnail call should be sent in parallel with a single thumbnail server group. According to the programming model described in this article, a program is constructed and executed in the following way to achieve this distributed execution:
此程式建構產生圖2A之圖形。如所展示，輸入操作210產生一串流215，該串流將一相簿名稱饋送至ListImages操作220。ListImages 220具有相關聯後設資料，該相關聯後設資料告知程式化模型其必須在一不同伺服器(或許基於相簿名稱之一特定分區)上運行。程式化模型在內部建立對於此服務之適當分區之一遠端程序呼叫(RPC)且向該適當分區發送相簿名稱。ListImages 220產生影像名稱之一串流225。程式化模型再次找到針對每一影像名稱之查找服務之適當分區且將名稱發送至此等分區。查找運算子230產生影像之一串流235。此等影像繼而被傳遞至又一服務-產生縮圖之縮圖操作240。程式化模型找到針對每一影像之縮圖服務之適當分區，且將每一影像發送至適當分區。所產生縮圖245作為程式之輸出250而保存。雖然計算觸及三種不同經分區服務中之伺服器，但應用程式碼不必起始或管理任何遠端通信。
This program is constructed to produce the graph in Figure 2A. As shown, the
圖2B表示一經更新圖形，其中程式經微調以添加由影像名稱加索引鍵之縮圖之一快取記憶體。因此，展示快取記憶體中查找操作226。經由串流228而將在快取記憶體中命中之影像縮圖直接傳遞至輸出。如之前但經由串流227而將未命中之影像名稱發送至查找230。應用程式對於快取記憶體之一位置或實施方案係不可知的。只要快取記憶體根
據程式化模型(其知曉快取記憶體之位置)而實施一查找運算子，圖2B之程式便滿足要求。
Figure 2B shows an updated graphic in which the program has been fine-tuned to add one of the caches of thumbnails with the image name plus the index key. Therefore, the
根據某些實例，程式化模型可提供一組內建運算子。在圖3之圖表中提供此等內建運算子之實例。每一運算子結合一對應功能來闡述。儘管僅展示幾個運算子，但應理解，可將任何數目個運算子構建至程式化模型中。另外，可建立其他運算子。可藉由(舉例而言)根據以下程式碼將運算子與串流一起寫入而構建程式： According to some examples, the stylized model can provide a set of built-in operators. Examples of these built-in operators are provided in the diagram in Figure 3. Each operator is described with a corresponding function. Although only a few operators are shown, it should be understood that any number of operators can be built into the stylized model. In addition, other operators can be created. The program can be constructed by (for example) writing the operator and the stream together according to the following code:
此程式將兩個常數組合至一單個串流中。藉由呼叫運算子特定建構函數(常數與交錯)而將運算子添加至圖形。每個運算子具有傳回一或多個串流之此一建構函數。此等串流可用作稍後運算子建構函數之引數。 This program combines two constants into a single stream. Add operators to the graph by calling operator specific constructors (constant and interlace). Each operator has this constructor that returns one or more streams. These streams can be used as arguments for later operator construction functions.
在建立程式時，運算子可由包含一名稱及一類型區分符之欄位定義。名稱可由程式設計員選擇。選擇一唯一名稱可提供最有幫助之輸出，但此並非必需的。 When creating a program, the operator can be defined by a field containing a name and a type identifier. The name can be selected by the programmer. Choosing a unique name provides the most helpful output, but it is not required.
一旦將運算子連線在一起，便可藉由建構一程式物件並編譯該程式物件而構建程式。另外，建構一編譯器物件，將內建運算子庫添加至該編譯器物件。可建構一繫結(Binding)物件以在稍後階段中向程式供應引數及結果。 Once the operators are connected together, the program can be constructed by constructing a program object and compiling the program object. In addition, a compiler object is constructed, and the built-in operator library is added to the compiler object. A Binding object can be constructed to supply arguments and results to the program at a later stage.
可藉由添加結果及引數而達成將輸入提供至程式及自程式接收輸出。可利用一輸入串流及結果之一名稱來添加一結果，且然後使結果之名稱與一實際執行個體相關聯。此分離允許一程式與不同輸出一起再使用。可藉由一類似程序添加引數，利用一名稱來添加引數，且使該名稱與一執行個體相關聯，從而允許程式與不同輸入資料一起使用。 It can be achieved by adding results and arguments to provide input to the program and receive output from the program. An input stream and a name of the result can be used to add a result, and then the name of the result can be associated with an actual instance. This separation allows a program to be reused with different outputs. Arguments can be added by a similar procedure, a name can be used to add an argument, and the name can be associated with an instance, allowing the program to be used with different input data.
透過一串流發送之每一值係一元組。每一串流具有一元組類型且在彼串流中流動之所有元組必需匹配彼類型。一元組類型由具有形式<name：field type>之一組固定欄位定義。一元組類型之一實例係結構<city string,population int64>。此元組具有兩個欄位：保持一字串之一城市欄位，及保持一數目(64位元整數)之一人口欄位。匹配此類型之某些值係{city：'Tokyo',population：13350000}及{city：'Ithaca',population：30515}。一元組中可支援之欄位類型之實例包含但不限於：布林值(bool)、位元組、字串(必需係有效UTF-8之位元組)、雙精度浮點數(double)、單精度浮點數(float)、int32、uint32、int64及uint64。 Each value sent through a stream is a tuple. Each stream has a tuple type and all tuples flowing in that stream must match that type. The type of a tuple is defined by a fixed field of the form <name:field type>. An instance of a tuple type is the structure <city string, population int64>. This tuple has two fields: a city field for holding a string, and a population field for holding a number (64-bit integer). Some values that match this type are {city:'Tokyo', population: 13350000} and {city:'Ithaca', population: 30515}. Examples of field types that can be supported in a tuple include, but are not limited to: Boolean value (bool), byte, string (must be a valid UTF-8 byte), double-precision floating-point number (double) , Single-precision floating-point numbers (float), int32, uint32, int64 and uint64.
為允許以可跨各種平臺及程式設計語言適用之一方式實施操作，一推論演算法允許去往操作之輸入改變或參數化欄位名稱、欄位類型或結構形狀。為允許分散式圖形執行，類型推論規則及約束之規範與運算子之實際實施方案分離。如此，透過操作而表達類型流，而無需判定特 定實施方案。 In order to allow operations to be implemented in a manner applicable across various platforms and programming languages, an inference algorithm allows input changes to operations or parameterized field names, field types, or structure shapes. To allow distributed graphics execution, the specification of type inference rules and constraints are separated from the actual implementation of operators. In this way, the type flow is expressed through operations without the need to determine special Determine the implementation plan.
作為其定義之一部分，一操作可係指其輸入及輸出且對該等輸入及輸出設定多種約束。可依據輸入而約束一輸出。舉例而言，一輸出類型可被約束為包含輸入之每個欄位。除了輸入之每個欄位之外，該輸出類型亦可被約束為包含一或多個額外欄位。作為另一實例，輸出類型可僅被約束為包含一或多個特定欄位。 As part of its definition, an operation can refer to its inputs and outputs and set multiple constraints on those inputs and outputs. An output can be restricted based on the input. For example, an output type can be constrained to include every field of input. In addition to each input field, the output type can also be constrained to include one or more additional fields. As another example, the output type may only be restricted to include one or more specific fields.
一實例性操作係如下： An example operation system is as follows:
在此實例中，藉由由欄位名稱key_field、fp_field及val_field定義之屬性而參數化該操作。當建立操作時，一程式設計員可指定此等欄位名稱，且參考此等欄位名稱而組態操作之行為。彼行為判定類型約束。舉例而言，類型約束可指定去往操作之一輸入應含有欄位<key：bytes>(名稱：索引鍵，類型：位元組)及<fp：uint64>，且輸出值應含有欄位<val：bytes>。 In this example, the operation is parameterized by the attributes defined by the field names key_field, fp_field, and val_field. When creating an operation, a programmer can specify these field names, and refer to these field names to configure the behavior of the operation. That behavior determines type constraints. For example, the type constraint can specify that one of the input to the operation should contain the field <key: bytes> (name: index key, type: byte) and <fp: uint64>, and the output value should contain the field < val: bytes>.
實例性操作亦可指定其他性質，諸如輸入串流之一數目、輸出串流之一數目、應如何實施分區等。舉例而言，以上實例中之操作亦指定fp_field係用於分區目的。僅以實例方式，操作可跨100個複製品而擴 展，且若均勻地分散，則每一複製品將接收輸入之1%。fp_field經查閱以便經由模組化算術而判定哪一分區應接收輸入資料。 The example operation may also specify other properties, such as the number of input streams, the number of output streams, and how partitioning should be implemented. For example, the operation in the above example also specifies that fp_field is used for partitioning purposes. By way of example only, the operation can be expanded across 100 copies If spread evenly, each copy will receive 1% of the input. The fp_field is consulted to determine which partition should receive the input data through modular arithmetic.
該操作定義其接收稱為In之一單個輸入串流，且建立稱為Hits及Misses之兩個輸出串流。Misses被定義為具有與輸入相同之類型，而Hits被約束為由輸入類型與<val_field bytes>之一串接組成之一新類型。操作可具有並非用於類型推論目的但對於圖形執行目的係重要之其他性質。以上實例性操作中之此等其他性質之實例包含end_when_outputs_done及skip_on_empty_inputs。 This operation defines that it receives a single input stream called In, and establishes two output streams called Hits and Misses. Misses are defined as having the same type as the input, and Hits are constrained to be a new type consisting of the input type and one of the <val_field bytes> concatenated. Operations may have other properties that are not used for type inference purposes but are important for graphics execution purposes. Examples of these other properties in the above example operations include end_when_outputs_done and skip_on_empty_inputs.
在編譯時間判定所有操作之類型並檢查其正確性。舉例而言，在編譯時間判定一個操作之輸出是否與另一操作之輸入匹配。系統執行類型推論以使類型約束轉變為具體類型。此可作為一正向傳遞而實施。 Determine the type of all operations at compile time and check their correctness. For example, it is determined at compile time whether the output of one operation matches the input of another operation. The system performs type inference to transform type constraints into concrete types. This can be implemented as a forward pass.
上文所提及之運算子建構函數傳回一串流物件。舉例而言：Stream s=ZipConst(input,{"label",100})；運算子建構函數用於將類型相關資訊添加至與該運算子建構函數傳回之串流相關聯之一陳述式(statement)。在以上實例之後，ZipConst可添加類型相關資訊，諸如+<label：int64>。在此實例性注釋中，「+」指示應將輸入類型中之所有欄位添加至輸出類型。「<label：int64>」指示亦應將稱為「標籤(label)」之一64整數欄位添加至輸出類型。「<label：int64>」可稱作類型區分符，其可較一般地指定一系列欄位名稱、欄位類型對。程式化模型之類型推論程式碼解釋此等注釋且產生一輸出類型。在某些例項中，(諸如)若一程式設計員嘗試定義與約束不一致之一輸出，則推論可產生一錯誤。舉例而言，若輸入類型已含有稱 為「標籤」之一欄位，則類型推論將失敗，此乃因每一欄位名稱可在一有效類型中出現一次。當此一錯誤發生時，可拒絕所嘗試之輸出定義，且可提示程式設計員輸入與約束一致之一不同定義。在其他實例中，可藉由程式化模型而對產生錯誤之所嘗試輸出定義自動地加旗標以由程式設計員進行進一步再檢測。 The operator constructor mentioned above returns a stream of objects. For example: Stream s=ZipConst(input,{"label",100}); the operator constructor is used to add type-related information to a statement associated with the stream returned by the operator constructor ( statement). After the above example, ZipConst can add type-related information, such as +<label:int64>. In this example note, "+" indicates that all fields in the input type should be added to the output type. "<label:int64>" indicates that a 64 integer field called "label" should also be added to the output type. "<label:int64>" can be called a type distinguisher, which can specify a series of field names and field type pairs more generally. The type inference code of the stylized model interprets these annotations and produces an output type. In some cases, (such as) if a programmer tries to define an output that is inconsistent with the constraint, the inference can produce an error. For example, if the input type already contains If it is a field of "label", the type inference will fail because each field name can appear once in a valid type. When this error occurs, the attempted output definition can be rejected, and the programmer can be prompted to enter a different definition consistent with the constraint. In other examples, the attempted output definition that produced the error can be automatically flagged by the stylized model for further re-examination by the programmer.
圖4提供列示針對現有運算子之輸出類型注釋之實例之一圖表。應理解，該圖表並非詳盡的，且亦可在程式化模型中使用其他實例性輸出類型注釋。 Figure 4 provides a diagram showing an example of output type annotations for existing operators. It should be understood that the chart is not exhaustive, and other example output type annotations can also be used in the stylized model.
將某些運算子(諸如接收(Receive)及交錯(Interleave))標記為「特殊」。類型推論對此等運算子提供特殊處理。舉例而言，對於接收，輸出類型與針對相關聯於注釋之一發送節點之輸入類型相同。對於交錯，所有輸入類型係相同的，且輸出類型與輸入類型相同。儘管此可抑制寫入進行極複雜之類型處理之運算子，但該等運算子係有益的，此乃因其提供運算子當中之較大一致性。此外，若類型推論程式碼不需要運行任何運算子特定程式碼，則該類型推論程式碼可在運算子實施方案不可用之一地點中運行。舉例而言，在一分散式設定中，可在無需使所有運算子連結至控制器之情況下在該控制器處執行類型推論。類型推論可作為一正向傳遞而執行。 Mark certain operators (such as Receive and Interleave) as "special". Type inference provides special handling for these operators. For example, for receiving, the output type is the same as the input type for the sending node associated with one of the annotations. For interleaving, all input types are the same, and the output type is the same as the input type. Although this can inhibit the writing of operators that perform extremely complex types of processing, these operators are beneficial because they provide greater consistency among the operators. In addition, if the type inference code does not need to run any operator specific code, the type inference code can be run in a location where the operator implementation is not available. For example, in a distributed setting, type inference can be performed at the controller without linking all operators to the controller. Type inference can be performed as a forward pass.
程式化模型可進一步提供類型檢查。運算子建構函數可將一注釋添加至一陳述式，其中該注釋用於去往運算子之類型檢查輸入。舉例而言，運算子總和(Sum)要求一輸入含有一數字欄位，且此將跟隨之輸入類型注釋放置於其陳述式上：<n：int64>。程式化模型將驗證被饋送至此運算子中之任何輸入皆含有所指定欄位之一超集合。 The stylized model can further provide type checking. The operator constructor can add a comment to a statement, where the comment is used for type check input to the operator. For example, the operator sum (Sum) requires an input to contain a numeric field, and this puts the following input type comment on its statement: <n:int64>. The stylized model will verify that any input fed to this operator contains a superset of the specified fields.
圖5提供圖解說明一實例性類型推論方法500之一流程圖。舉例而言，方法可由一用戶端計算裝置、控制器或其他網路計算裝置執行。儘管下文以一特定次序闡述方法，但應理解，可以一不同次序或同時地執行子部分。此外，可添加或移除子部分。
FIG. 5 provides a flowchart illustrating an exemplary
在方塊510中，接收藉由欄位名稱及欄位類型識別符而定義屬性之資訊。舉例而言，參考以上程式碼中所產生之實例性操作，定義屬性{key_field,bytes}、{val_field,bytes}及{fp_field,bytes}。此資訊用於定義操作之輸入及輸出串流之類型。
In
在方塊520中，接收關於該等屬性而定義一操作之行為之資訊。舉例而言，參考以上實例，輸入、輸出及分區欄位判定操作將如何表現。
In
在方塊530中，基於屬性及行為而判定針對操作之約束。在某些實例中，可藉由程式化模型而自動地判定該等約束。在其他實例中，可由一使用者定義該等約束。
In
在方塊540中，接收定義操作之一輸入之資訊。該輸入可包含(舉例而言)一欄位，該欄位包含一名稱及一類型。此資訊亦可稱作類型資訊且針對操作之一或多個輸入串流而提供。類型推論方法基於與一或多個輸入串流相關聯之類型資訊及與一運算子相關聯之一輸出注釋而判定該運算子之一或多個輸出串流之類型資訊。類型資訊可包含限制包含於串流(該類型資訊與其相關聯)中之元組之約束。類型應與在屬性中所定義之一類型對應。
In
在方塊550中，基於約束及所定義輸入而判定一輸出類型。舉例而言，輸出類型可被限制為在約束中所指定之一類型，且可對應
於定義輸入之所接收資訊。此判定可在穿過圖形之一正向傳遞中執行，而無需進行回溯。
In
在方塊560中，使輸出類型與操作之一輸出相關聯。舉例而言，當使用者正定義操作之一輸出時，可自動地填充輸出類型欄位。在其他實例中，可阻止使用者進行輸入一不同輸出類型之嘗試。
In
儘管前述實例闡述基於一輸入類型及所定義運算子而判定一輸出類型，但類型推論亦可在逆向中使用。舉例而言，可接收輸出類型作為輸入，且可基於所定義輸出類型及其他資訊而判定輸入類型。 Although the foregoing example illustrates determining an output type based on an input type and defined operators, type inference can also be used in the reverse direction. For example, the output type can be received as input, and the input type can be determined based on the defined output type and other information.
如上文所闡述之類型推論及約束驗證確保準確且快速查詢執行。亦可以一極泛用方式實施操作。推論允許去往操作之輸入(諸如屬性)改變或參數化欄位名稱、欄位類型或甚至結構之形狀。為允許分散式圖形執行，類型推論規則及約束之規範與運算子之實際實施方案分離。結果係一格式，該格式係完全自任何特定實施方案抽象而成，同時透過操作而表達類型流。類型推論及約束驗證係查詢執行之一關鍵路徑之一部分，從而產生快速執行之要求。在不進行回溯之情況下之一單個遍次推論及驗證演算法進一步提供快速執行。 The type inference and constraint verification described above ensure accurate and fast query execution. The operation can also be implemented in a very general way. Inference allows the input to the operation (such as attributes) to change or parameterize the field name, field type or even the shape of the structure. To allow distributed graphics execution, the specification of type inference rules and constraints are separated from the actual implementation of operators. The result is a format that is completely abstracted from any specific implementation, and at the same time expresses the type flow through operations. Type inference and constraint verification are part of a critical path of query execution, which leads to requirements for fast execution. In the case of no backtracking, a single pass inference and verification algorithm further provides fast execution.
位置指派在程式建構期間發生。一圖形中之操作可具有指示可執行操作之一或多個位置之一位置限制。位置限制可由一使用者定義，或可基於分散式系統中之計算裝置之能力而判定。舉例而言，若待由一查找操作擷取之資料儲存於一特定資料中心中，則查找操作被限制為在特定資料中心處執行。 Location assignment occurs during program construction. An operation in a graph may have a position limit indicating one or more positions of the executable operation. The location limit can be defined by a user, or can be determined based on the capabilities of the computing device in the distributed system. For example, if the data to be retrieved by a search operation is stored in a specific data center, the search operation is restricted to be executed at the specific data center.
針對不具有一位置限制之操作，程式化模型將一位置指派 至該操作。此等位置可經選擇而以某一方式最佳化計算。舉例而言，一個節點可產生大量資料，但然後該節點後續接著一濾波器節點，該濾波器節點濾除資料之99%。在此情形中，使濾波器節點定位於資料產生節點之相同位置處係尤其有利的。位置指派可發生而作為下文進一步論述之圖形建立及分割之一部分。 For operations that do not have a location restriction, the stylized model assigns a location To this operation. These positions can be selected to optimize the calculation in a certain way. For example, a node can generate a large amount of data, but then the node is followed by a filter node, which filters out 99% of the data. In this case, it is particularly advantageous to locate the filter node at the same position as the data generating node. Location assignment can occur as part of the graph creation and segmentation discussed further below.
圖6A至圖6C圖解說明在程式建構期間之位置指派之一實例。圖6A提供一實例性圖形，該實例性圖形具有表示操作之節點及介於該等節點之間的連接一源操作與一目的地操作之邊緣，其中一源操作之輸出係目的地操作之輸入。在此程式中，將引數610(諸如索引鍵)發送至執行一查找620之一遠端位置。將查找結果發送通過一濾波器630，該濾波器移除某些結果且將該等結果輸出至結果操作640中。
6A to 6C illustrate an example of location assignment during program construction. Figure 6A provides an example graph with nodes representing operations and edges connecting a source operation and a destination operation between the nodes, where the output of a source operation is the input of the destination operation . In this program, an argument 610 (such as an index key) is sent to a remote location where a
圖6B圖解說明針對操作中之每一者之使用者指派位置之一實例。將引數610自位置C發送至位置L以進行查找620。然後將查找620之結果往回發送至位置C以進行濾波且輸出結果。此導致將大量資料自位置L發送至位置C，僅使彼資料中之諸多資料藉由濾波操作630而被濾波。圖6C圖解說明可能之使用者指派位置之一較高效實例，其中查找及濾波皆在相同位置L處執行。此指派最佳化執行時間且減少網路訊務。然而，依賴於使用者來預見位置指派中之潛在低效率並適應該等低效率會給使用者帶來一顯著負擔。
Figure 6B illustrates one example of user assignment locations for each of the operations. The
圖7A至圖7B圖解說明在圖形建立期間之自動位置指派之一實例。當建構程式時，操作引數710、查找720及結果740伴隨預指派位置而發生。可由程式化模型(舉例而言)基於用於執行操作之計算裝置之能
力、與操作定義相關聯之限制或任何其他資訊而自動地預指派此等位置。濾波器操作730不伴隨任何位置指派而發生。因此，當建立圖形時，可如圖7A中所展示而顯現。當提交程式以用於執行時，程式化模型將辨識出濾波器730係一資料減少操作，且將該濾波器730指派至位置L。因此，程式將如圖7B中而顯現。
Figures 7A-7B illustrate an example of automatic location assignment during graph creation. When the program is constructed,
由於位置指派係自動化的，因此將程式分割至保留位置約束之圖形中亦應係自動化的。以使效能最大化之一方式完成此分割。 Since the location assignment is automated, the division of the program into the graphics that retain the location constraints should also be automated. This segmentation is done in a way that maximizes performance.
圖8A至圖8C圖解說明分割一圖形以使子圖之一數目最小化同時遵循約束之一實例。舉例而言，圖形必須保持為非循環的。如圖8A中所展示，每個操作在一單獨圖形G0、G1、G2、G3中運行。如此，需要在每個邊緣815、825、835上串列化及解串列化資料。針對橫跨兩個位置C及L之邊緣815及835，網路傳送需要此資料串列化。然而，邊緣825不需要資料串列化。然而，使圖形分割之數目最小化將產生圖8B之圖形，該圖形在圖形G0至G1及G1至G0之間引入一循環。此可導致死結(deadlock)，且因此應加以避免。使圖形之數目最小化同時阻止循環會產生圖8C之圖形，該圖形係針對程式之最佳分割。
8A to 8C illustrate an example of dividing a graph to minimize the number of one of the subgraphs while observing constraints. For example, the graph must remain acyclic. As shown in Figure 8A, each operation runs in a separate graph G0, G1, G2, G3. In this way, data needs to be serialized and deserialized on each
經分區位置呈現針對圖形分割之額外考量因素。圖9A至圖9D提供針對經分區位置之圖形分割之一實例。經分區位置可包含具有用於執行操作之多個計算分區之任何位置。如圖9A中所展示，兩個查找操作920、940被放置於相同位置上、藉由欄位「索引鍵」而被分區。將處理操作930指派至相同經分區位置會產生圖9B之圖形，該圖形可能如圖9C中所展示而被分割。然而，此分割係不正確的。若處理操作930以任何方式修改索引鍵欄位，則在未對輸入進行重新分區之情況下，不應將該處理
操作之輸出直接傳遞至第二查找操作940。為防止此發生，將所有經分區位置視為唯一的。舉例而言，即使將查找操作920、940兩者指派至相同位置，亦將該等查找操作視為不同位置。因此，如圖9D中所展示，將處理操作930指派至唯一查找位置中之一者。
The partitioned position presents additional considerations for the graphics segmentation. Figures 9A to 9D provide an example of graph segmentation for partitioned locations. A partitioned location can include any location that has multiple computational partitions for performing operations. As shown in FIG. 9A, two
如由經分區位置之以上實例所演示，將相同位置指派至兩個操作並不保證該兩個操作將在相同圖形中一起運行。保證被指派至相同經分區位置之兩個操作不在相同圖形中運行。儘管此行為不影響程式之正確性，但其可影響其效能。因此，程式化模型提供使得使用者將一組操作一起共同定位於一特定位置處之一方式。然後保證彼等操作在彼位置處之相同圖形中結束，其中其他操作可能被添加至該圖形。每當將操作指定為共同定位的，便不會對在該等操作之間發送之資料進行重新分區。 As demonstrated by the above example of partitioned locations, assigning the same location to two operations does not guarantee that the two operations will run together in the same graph. Ensure that the two operations assigned to the same partitioned position do not run in the same graph. Although this behavior does not affect the correctness of the program, it can affect its performance. Therefore, the stylized model provides a way for the user to co-locate a set of operations together at a specific location. Then make sure that their operations end in the same graph at that location, where other operations may be added to the graph. Whenever an operation is designated as co-located, the data sent between these operations will not be repartitioned.
圖10A至圖10B提供共同位置之一實例。在圖10A之程式中，使用者已指定查找操作1020、1030將在一給定位置處一起運行。在位置指派及圖形建立之後，程式將如圖10B中所展示而被分割。
Figures 10A to 10B provide an example of a common location. In the program of FIG. 10A, the user has specified that the
總結上文所闡述之自動位置指派及圖形分割，位置係一操作而非一圖形之一性質。某些操作將伴隨指派位置或位置約束而發生，某些操作將使其位置由使用者指派，且某些操作將不伴隨任何經指派位置而發生。使用者利用一單個操作圖形寫入一程式，而無需擔心子圖。每一操作向程式化模型提供提示。舉例而言，針對每一輸出邊緣，操作報告將在彼輸出邊緣上流動之總輸入資料之百分比。此提示幫助程式化模型判定將什麼位置指派至運算子。在其他實例中，可在較早運行期間針對一給定程式而自動地計算此資訊。程式化模型將位置自動地指派至操作，且將程式自動地分割至最小數目個圖形中同時保留圖形之間無循環之性質。 To summarize the automatic position assignment and pattern segmentation described above, position is an operation rather than a characteristic of a pattern. Certain operations will occur with assigned locations or location constraints, certain operations will have their locations assigned by the user, and certain operations will occur without any assigned locations. The user writes a program with a single operation graph without worrying about sub-pictures. Each operation provides hints to the stylized model. For example, for each output edge, the operation reports the percentage of total input data that will flow on that output edge. This hint helps the stylized model determine what position to assign to the operator. In other examples, this information can be calculated automatically for a given program during an earlier run. The program model automatically assigns positions to operations, and automatically divides the program into a minimum number of graphics while retaining the nature of no loops between graphics.
根據一項實例，在操作中指定之輸出提示或自先前圖形運行收集之資料可用於利用將在程式圖形之每一邊緣上流動之預期數目個元組而增大彼邊緣。可因此以使在位置之間流動之元組總數目最小化之一方式將該等位置指派至圖形節點。可藉由以元組計數遞減次序對程式中之所有邊緣進行分類且以經分類次序對邊緣進行反覆而執行此位置指派。針對每一邊緣，識別源運算子及目的地運算子且若源運算子及目的地運算子兩者皆不具有指派至其之一位置，則藉由將該源運算子與該目的地運算子分群在一起而對其指派有相同位置。若一個運算子具有經指派之一位置，則將相同位置指派至另一運算子及可已與該運算子分群在一起之所有其他運算子。此演算法自總元組計數移除最昂貴邊緣、然後移除次昂貴邊緣，以此類推。 According to one example, the output prompt specified in the operation or the data collected from the previous graph run can be used to increase the number of tuples that will flow on each edge of the program graph by using that edge. The locations can therefore be assigned to graph nodes in a way that minimizes the total number of tuples flowing between locations. This position assignment can be performed by sorting all edges in the program in descending order of tuple count and iterating the edges in the sorted order. For each edge, identify the source operator and the destination operator, and if both the source operator and the destination operator do not have a position assigned to one of them, then by the source operator and the destination operator Grouped together and assigned the same position. If an operator has an assigned position, then the same position is assigned to another operator and all other operators that may have been grouped with that operator. This algorithm removes the most expensive edge from the total tuple count, then removes the second most expensive edge, and so on.
圖11A至圖11C圖解說明具有多個輸入操作之一程式之一實例。如圖11A中所展示，程式包含經由邊緣1115而輸入至一第一查找操作1130之一第一輸入引數1110。程式亦包含經由邊緣1125而將輸入提供至一第二查找操作1140之一第二輸入引數1120。查找操作1130、1140分別經由邊緣1135、1145而將串流提供至ZipAny操作1150，且ZipAny操作1150經由邊緣1155而將串流提供至選擇操作1160。經由邊緣1165而將一輸出提供至結果1170。邊緣權重表示沿著邊緣流動之元組之所估計數目。舉例而言，邊緣1115、1135及1155具有邊緣權重1M。邊緣1125及1145具有邊緣權重1，且邊緣1165具有一權重3。對位置SL進行分區，而未對位置L進行經分區。
11A to 11C illustrate an example of a program having multiple input operations. As shown in FIG. 11A, the program includes a
此程式之自動分割可產生圖11B之圖形，其中ZipAny 1150及選擇1160皆被指派至位置SL。此位置指派將起作用，前提係在位
置L處運行之第二查找操作1140將其元組廣播至ZipAny 1150之所有經分區執行個體。
The automatic segmentation of this program can generate the graph in Figure 11B, in which
如圖11C中所展示，用一交錯操作1180替換ZipAny操作。程式將起作用，前提係在位置L處運行之第二查找操作1140將其元組僅發送至交錯之經分區執行個體中之一者。儘管此解決方案係操作特定的，但亦可較一般地解決問題。舉例而言，可將所有多個輸入操作標記為不可分裂的。若一操作可被分裂成單獨操作而不改變操作之功能性，則該操作可為可分裂的。舉例而言，若存在饋送至一操作OP之三個串流S1、S2、S3，則若OP(UNION(S1,S2,S3))==UNION(OP(S1),OP(S2),OP(S3))，則操作OP係可分裂的。一可分裂操作之一實例係圖4中所提及之使每個輸入值加倍之運算子雙精度浮點數。然而，此可導致效能降級。一種一般解決方案之另一實例係要求程式寫入者明確指定如何對多個輸入操作進行分區。然而，此將給程式寫入者帶來一負擔，且將消除動態最佳化程式之可能性。又一實例性一般解決方案係提供使一操作寫入者定製多個輸入操作之分裂之一方式。在以上實例中，ZipAny將總是想要使其其他輸入被廣播，而交錯將總是想要使其其他輸入僅被發送至一個位置。儘管此給操作寫入者帶來一額外負擔，但此與對程式寫入者之潛在負擔相比較不顯著且以經最佳化效能保留程式之正確性。
As shown in Figure 11C, replace the ZipAny operation with an
除了位置指派之外，新程式化模型亦以經最佳化以減少總體網路訊務且增加執行程式之速度及效能之一方式執行圖形之自動分割。圖形中之操作被分割至複數個子圖中。一子圖中之每個操作必須被指派至相同位置。在執行分割時，偵測到在候選子圖當中建立一循環之一可能 性，且藉由進一步分割候選子圖中之一者而消除該循環。 In addition to location assignment, the new programming model also performs automatic graphics segmentation in a way that is optimized to reduce overall network traffic and increase the speed and performance of program execution. The operations in the graph are divided into multiple subgraphs. Each operation in a subgraph must be assigned to the same location. When performing segmentation, a possibility of creating a loop in the candidate subgraph is detected And eliminate the loop by further dividing one of the candidate subgraphs.
圖形分割藉由將具有經指派位置之所有操作放置至其自身之一子圖中而開始。舉例而言，可基於與操作相關聯之位置限制而指派位置。舉例而言，某些操作可具有特定要求，其中在分散式架構中之特定位置處之僅某些計算裝置能夠根據彼等限制執行操作。此等限制及能力可由程式化模型辨識，該程式化模型可因此將一位置自動地指派至操作。分割可包含減少具有被指派至一特定位置之操作之子圖之一數目。 Graph segmentation begins by placing all operations with assigned positions into one of its own subgraphs. For example, the location can be assigned based on location restrictions associated with the operation. For example, certain operations may have specific requirements, where only certain computing devices at specific locations in the distributed architecture can perform operations according to their restrictions. These limitations and capabilities can be identified by a stylized model, which can therefore automatically assign a position to the operation. Segmentation can include reducing the number of subgraphs that have operations assigned to a specific location.
在分割演算法之進程內，將未經指派操作放置至經位置指派之子圖中，且儘可能將該等子圖合併在一起。在執行演算法時，施加一定數目個主要約束，其中該等約束確保最終圖形及對於操作之位置指派使得當執行由圖形表示之程式時，圖形中之操作當中之通信係高效的。特定而言，必須將所有操作放置至一子圖中，演算法必須將一位置指派至每一子圖，具有一程式設計員指派之位置之一操作必須保持彼指派，且若一未經指派操作具有一可分裂性質，則可僅將該未經指派操作放置至一經分區位置中。此外，若一位置被分區，則其目的地操作被指派至彼位置的程式中之所有邊緣在整個演算法中保持不改變。此外，圖形必須係非循環的。 In the process of the segmentation algorithm, unassigned operations are placed in the position-assigned subgraphs, and the subgraphs are merged together as much as possible. When the algorithm is executed, a certain number of main constraints are imposed, where these constraints ensure that the final graphics and the assignment of positions for the operations make the communication between the operations in the graphics efficient when the program represented by the graphics is executed. Specifically, all operations must be placed in a subgraph, the algorithm must assign a position to each subgraph, and an operation with a position assigned by a programmer must remain assigned, and if an unassigned The operation has a splittable property, and the unassigned operation can only be placed in a partitioned location. In addition, if a location is partitioned, all edges in the program whose destination operations are assigned to that location remain unchanged throughout the algorithm. In addition, the graphics must be acyclic.
可在兩個階段中執行圖形分割。在一第一階段中，執行主要分割，而在一第二階段中，執行本端分割。第一階段之一個目的係判定圖形中之節點至位置之一指派，使得當執行由圖形表示之程式時，使位置當中之通信最小化。本端分割之一個目的係改良及最佳化一程式及被分配至相同位置之操作之實施方案。主要分割可包含合併經分區子圖、擴大經分區子圖、指派未經分區位置及合併未經分區子圖。若將所有節點指派至相同經分區位置，則一子圖被分區。作為主要分割之一結果，每一子圖被 指派有一經分區位置或未經分區位置且相同子圖中之所有節點具有與子圖相同之位置。本端分割可包含識別需要被分裂之子圖、使圖形準備好進行分裂、構建合併圖形、利用外部傳入邊緣合併子圖及利用非封鎖操作合併子圖。 The graph segmentation can be performed in two stages. In a first stage, the main segmentation is performed, and in a second stage, the local segmentation is performed. One goal of the first stage is to determine the assignment of nodes to positions in the graph, so that when the program represented by the graph is executed, the communication in the position is minimized. One purpose of local partitioning is to improve and optimize a program and the implementation of operations that are assigned to the same location. The main division may include merging partitioned submaps, expanding partitioned submaps, assigning unpartitioned locations, and merging unpartitioned submaps. If all nodes are assigned to the same partitioned position, a subgraph is partitioned. As a result of one of the main divisions, each subgraph is Assign a partitioned position or an unpartitioned position and all nodes in the same subgraph have the same position as the subgraph. Local segmentation can include identifying subgraphs that need to be split, preparing the graph for splitting, constructing a merged graph, merging subgraphs using external incoming edges, and merging subgraphs using non-blocking operations.
在主要分割之第一階段中，一第一步驟合併儘可能多之經分區子圖。因此，使程式中之子圖之一總數目最小化。下一步驟係藉由將相鄰未經指派節點摺疊至經分區子圖中而擴大該等經分區子圖。候選操作首先經檢查以判定其是否已被標記為可分裂的。若否，則不摺疊候選操作。若該等候選操作係可分裂的，則將彼等候選者放置至相鄰子圖中受主要分割約束限制。在指派未經分區位置之一下一步驟中，藉由將來自經指派節點之位置複製至其相鄰者而將位置指派至所有未經指派操作。一下一步驟包含合併未經分區子圖，藉由合併在相同位置處運行之所有可能之未經分區子圖對而嘗試使子圖之總數目最小化。在某一時刻，進一步合併將係不可能的。舉例而言，當將每個操作指派至一子圖且使子圖之數目最小化時，任何進一步合併將向圖形中引入一循環或打破約束中之一者。此時，封鎖操作可被分裂至其自身之一子圖中，從而建立在相同機器上執行之本端圖形。封鎖操作係可必須進行輸入/輸出之操作，且因此可在執行I/O之同時保留一執行緒，從而防止其他操作能夠運行。 In the first stage of the main segmentation, a first step merges as many partitioned subgraphs as possible. Therefore, minimize the total number of one of the subgraphs in the program. The next step is to expand the partitioned subgraphs by folding adjacent unassigned nodes into the partitioned subgraphs. The candidate operation is first checked to determine whether it has been marked as splittable. If not, the candidate operations are not collapsed. If these candidate operations are splittable, placing them in adjacent subgraphs is restricted by the main division constraint. In the next step of assigning unpartitioned locations, the locations are assigned to all unassigned operations by copying the location from the assigned node to its neighbors. The next step involves merging the unpartitioned subgraphs, trying to minimize the total number of subgraphs by merging all possible pairs of unpartitioned subgraphs running at the same location. At some point, further mergers will be impossible. For example, when each operation is assigned to a subgraph and the number of subgraphs is minimized, any further merging will introduce a loop into the graph or break one of constraints. At this time, the blocking operation can be split into one of its own subgraphs, thereby establishing a local graph executed on the same machine. The blocking operation system may have to perform input/output operations, and therefore may retain a thread while performing I/O, thereby preventing other operations from running.
在本端分割之第二階段中，已指派位置。此外，經分區位置可正如未經分區位置一樣分裂。舉例而言，若一位置包含多個分區，則該位置可被分區。然而，分裂成多個本端子圖必須滿足一組本端約束，此要求每一封鎖操作必須在其自身之一子圖中結束，分裂可利用外部(非本端)輸入產生僅一個子圖，且子圖及子圖之間的邊緣必須係非循環的。要 求該分裂利用外部輸入產生僅一個子圖確保外部圖形與一單個本端圖形進行通信，此達成較多發送/接收最佳化且簡化協定。 In the second stage of the local split, the location has been assigned. In addition, partitioned locations can be split just as unpartitioned locations. For example, if a location includes multiple partitions, the location can be partitioned. However, splitting into multiple current terminal diagrams must meet a set of local constraints. This requires that each blockade operation must end in one of its own sub-maps. Splitting can use external (non-local) input to generate only one sub-map. And the edge between the subgraph and the subgraph must be acyclic. want It is required that the split use external input to generate only one sub-picture to ensure that the external picture communicates with a single local picture, which achieves more transmit/receive optimization and simplify the agreement.
本端分割之一第一步驟係識別需要被分裂之子圖。此等子圖可僅係含有封鎖操作之子圖。在一下一步驟中，使圖形準備好進行分裂。此可包含修改子圖以強加本端分割約束。舉例而言，該修改可在每一封鎖操作之前及之後插入空操作(no-op)。在封鎖操作之前插入空操作確保在子程式中不存在具有外部輸入之封鎖操作。在封鎖操作之後插入空操作確保在子程式中不存在具有外部輸出之封鎖操作。 The first step of the local segmentation is to identify the subgraphs that need to be split. These sub-pictures may only contain the sub-pictures of the blocking operation. In the next step, prepare the graph for splitting. This can include modifying the subgraph to impose local segmentation constraints. For example, the modification can insert a no-op before and after each lockout operation. Insert a dummy operation before the block operation to ensure that there is no block operation with external input in the subroutine. Insert a dummy operation after the lockout operation to ensure that there is no lockout operation with external output in the subroutine.
在本端分割之一下一步驟中，構建一合併圖形，其中每一操作在其自身之一子圖中結束。然後將此等子圖重複地合併在一起。具體而言，將具有外部傳入邊緣之所有操作一起合併至相同子圖中。此外，合併具有非封鎖操作之所有可能之子圖對。 In the next step of the local segmentation, a merged graph is constructed, where each operation ends in one of its own subgraphs. Then merge these subgraphs together repeatedly. Specifically, all operations with external incoming edges are merged together into the same subgraph. In addition, merge all possible sub-picture pairs with non-blocking operations.
一旦經分割，圖形便可被執行。在子圖之各別位置處執行該等子圖中之每一者，且在一各別單個執行緒中執行每一子圖。沿著一子圖內之邊緣進行之資料傳送基於其在一單執行緒環境中之執行而被最佳化。 Once split, the graphics can be executed. Each of the sub-graphs is executed at a separate position of the sub-graph, and each sub-graph is executed in a separate single thread. The data transfer along the edges within a sub-picture is optimized based on its execution in a single-threaded environment.
圖12圖解說明一實例性程式。圖13A至圖13F闡述程式之主要分割，而圖14A至圖14E闡述本端分割之一實例。在圖15中展示所得程式。 Figure 12 illustrates an example program. FIGS. 13A to 13F illustrate the main division of the program, and FIGS. 14A to 14E illustrate an example of the local division. The resulting formula is shown in Figure 15.
如圖12中所展示，建立程式之一初始圖形。該圖形包含表示各種操作之複數個節點A至K，其中邊緣1211至1222表示在該等節點之間流動之資料串流。節點中之某些節點具有預定義位置。舉例而言，將節點A之操作指派至位置C，而將節點I之操作指派至位置L。將節點B、C、
E及F中之每一者之操作指派至經分區位置SL。在分割期間，將位置自動地指派至其餘節點D、J、G、H及K。
As shown in Figure 12, create an initial graph of the program. The graph includes a plurality of nodes A to K representing various operations, where
在圖13A中，將具有一預定義位置之每一節點放置至其自身之子圖中。舉例而言，將節點A放置於子圖1310中、將節點B放置於子圖1312中、將節點C放置於子圖1314中、將節點E放置於子圖1316中、將節點F放置於子圖1318中且將節點I放置於子圖1320中。在分割期間，將具有未經指派位置之節點放置至此等子圖1310至1320中，且儘可能地合併子圖。此根據上文所提及之主要分割約束而執行。
In FIG. 13A, each node with a predefined position is placed in its own subgraph. For example, place node A in
舉例而言，藉由儘可能地合併經分區子圖同時遵循主要分割約束而將圖13A變換為圖13B。用於合併之候選者包含節點B、C、E及F。節點A及I並非候選者，此乃因該等節點並非被指派至經分區位置。節點B及節點C兩者皆不可與節點E或F合併，此乃因其將向圖形中引入一循環。亦無法將子圖1316與1318合併在一起，此乃因若一經分區位置中之一發送節點之目的地節點亦處於一經分區位置中，則無法將該發送節點與其目的地合併在一起。可將節點B與C合併，且合併至相同子圖1313中。
For example, FIG. 13A is transformed into FIG. 13B by merging the partitioned sub-graphs as much as possible while observing the main segmentation constraints. Candidates for merging include nodes B, C, E, and F. Nodes A and I are not candidates, because they are not assigned to the partitioned locations. Neither node B nor node C can be merged with node E or F, because they will introduce a cycle into the graph. It is also impossible to merge the
舉例而言，藉由擴大經分區子圖而將圖13B變換為圖13C。此擴大包含將具有未經指派位置之相鄰節點添加至經分區子圖中。節點D及G係待被摺疊至經分區子圖中之候選者，此乃因該等節點具有未經指派位置且亦具有耦合至經分區子圖內之節點之邊緣。判定節點D及G是否已被標記為可分裂的。若否，則將該等節點捨棄作為候選者。若該等節點被標記為可分裂的，則將該等節點放置至相鄰子圖中。無法將操作D放置至具有節點E之子圖1316中，此乃因以下約束：目的地操作被指派至一經分區位置之一組邊緣必須保持不改變。將操作D添加至子圖1313。若
節點B及C先前未被合併至相同子圖中，則此將係不可能的，此乃因其將不遵守主要分割約束。
For example, FIG. 13B is transformed into FIG. 13C by expanding the partitioned subgraph. This expansion includes adding adjacent nodes with unassigned positions to the partitioned subgraph. Nodes D and G are candidates to be collapsed into the partitioned subgraph because they have unassigned positions and also have edges coupled to nodes in the partitioned subgraph. Determine whether nodes D and G have been marked as splittable. If not, then discard these nodes as candidates. If these nodes are marked as splittable, they are placed in adjacent subgraphs. The operation D cannot be placed in the
藉由將節點D添加至子圖1313中，有效地對節點D之操作進行分區。因此，將新操作D’添加至圖形以合併來自D之經分區執行個體之結果。類似地，將節點G之操作放置至具有節點F之子圖1318中，且將新操作G’添加至圖形。新操作D’及G’係不可分裂的。在圖13C中不存在可被放置至經分區位置中之其他操作。
By adding the node D to the
圖13D圖解說明將位置指派至所有未經指派位置。此可藉由將來自經指派節點之位置複製至其相鄰者而執行。舉例而言，節點D’、J、G’、H及K在圖13C中具有未經指派位置。節點G’、H及K係包含節點I之子圖1320之相鄰者。因此，被指派至節點I之位置L亦被指派至節點G’、H及K。節點D’及J不具有任何相鄰未經分區子圖，且因此節點D’及J被指派至控制器C。
Figure 13D illustrates the assignment of locations to all unassigned locations. This can be performed by copying the location from the assigned node to its neighbors. For example, nodes D', J, G', H, and K have unassigned positions in Figure 13C. Nodes G', H, and K are the neighbors of the
圖13E至圖13F圖解說明合併未經分區子圖之一實例。藉由將在相同位置處運行之可能之未經分區子圖對合併在一起而使子圖之總數目最小化。存在被指派至位置C之三個子圖(1310、1315、1317)。而且，節點G’、H、I及K之子圖全部被指派至位置L。可在不引入一循環之情況下將被指派至位置L之所有子圖合併至新子圖1322中。無法在不引入一循環之情況下將包含節點A之子圖1310與子圖1315或1317合併。然而，可合併包含節點D’之子圖1315與包含節點J之子圖1317。在圖13F中圖解說明一所得圖形。無法進一步合併此圖形。已將每一操作指派至一子圖，且已使子圖之數目最小化。任何進一步合併將打破主要分割約束中之一者。
Figures 13E to 13F illustrate an example of merging unpartitioned subgraphs. Minimize the total number of subgraphs by merging together possible pairs of unpartitioned subgraphs running at the same location. There are three subgraphs (1310, 1315, 1317) assigned to position C. Moreover, the subgraphs of nodes G', H, I, and K are all assigned to position L. All the sub-pictures assigned to the position L can be merged into the new sub-picture 1322 without introducing a loop. It is not possible to merge the
封鎖操作可被分裂至其自身之一子圖中，從而建立在相同 機器上本端地執行之本端圖形。在本端分割期間，已指派位置。此外，不需要針對經分區位置進行特殊考量，該等經分區位置可在本端分割階段期間被分裂。本端分割必須遵循上文所提及之本端分割約束。此等本端分割約束要求每一封鎖操作在其自身之一子圖中結束，分裂子圖可利用外部/非本端輸入僅產生一個子圖，且圖形必須保持為非循環的。確保分裂利用外部輸入產生僅一個子圖達成較多發送及接收最佳化，且簡化程式化協定。在圖形中，一外部/非本端輸入由介於已被指派有不同位置之節點之間的一邊緣表示。在程式之執行期間，一外部邊緣導致節點之間的可能通信。 The blocking operation can be split into one of its own subgraphs, thereby establishing the same Local graphics executed locally on the machine. During the local split, the location has been assigned. In addition, no special consideration is required for the partitioned locations, which can be split during the local segmentation stage. The local partition must follow the local partition constraints mentioned above. These local segmentation constraints require each blockade operation to end in one of its own subgraphs. The split subgraph can use external/non-local input to generate only one subgraph, and the graph must remain acyclic. Ensure that splitting uses external input to generate only one sub-picture to achieve more sending and receiving optimizations, and simplify the programming protocol. In the graph, an external/non-local input is represented by an edge between nodes that have been assigned different positions. During the execution of the program, an external edge leads to possible communication between nodes.
在圖14A中，識別含有封鎖操作之子圖。在此實例中，操作B及D係程式中之僅有封鎖操作。因此，將對包含節點B、C及D之子圖1413進行分裂。
In Fig. 14A, the sub-picture containing the lockout operation is identified. In this example, the only block operation in operation B and D is the program. Therefore, the
在圖14B至圖14C中，圖14A之子圖1413經修改以便強加本端分割約束。圖14B中所展示之一第一修改確保在子圖中不存在具有外部輸入之封鎖操作。具有外部輸入之多個封鎖操作將使得難以或不可能強加本端分割約束，該等本端分割約束要求每一封鎖操作在其自身之一子圖中結束，且圖形保持為非肺循環的。第一修改僅在封鎖操作之前插入空操作。一空操作或「no-op」係在被插入於兩個操作之間的情況下不改變程式語義之一操作。一空操作之一實例係交錯。交錯將資料自其之前的一節點傳遞至其之後的一節點。由於封鎖操作B具有來自節點A之一外部輸入，因此將一No-op操作1432插入於節點A與B之間。
In FIGS. 14B to 14C, the
圖14C中所展示之一第二修改確保在子圖中不存在具有外部輸出之封鎖操作。此使子圖準備好進行一最終分割步驟，其中沿著彼等
輸出而插入發送及接收操作，且確保發送操作不在與封鎖操作相同之子圖中結束。因此，第二修改將另一No-op操作1434插入於節點D與D’之間。
One of the second modifications shown in Figure 14C ensures that there is no blocking operation with external output in the sub-figure. This prepares the subgraphs for a final segmentation step, where along their
Insert sending and receiving operations for output, and make sure that the sending operation does not end in the same subgraph as the blocking operation. Therefore, the second modification inserts another No-
圖14D圖解說明構建一合併圖形，其中每一操作在其自身之一子圖中結束。如所展示，合併圖形1450包含子圖1452、1453、1454、1456及1458，該等子圖各自包含一個操作。
Figure 14D illustrates the construction of a merged graph, where each operation ends in one of its own subgraphs. As shown, the
在圖14E中，識別具有外部傳入邊緣之操作並將其一起合併至相同子圖中。由於節點C及第一No-op操作皆具有自合併圖形1450外部之節點A傳入之外部邊緣，因此將圖14D之子圖1452與1454一起合併至圖14E之子圖1455中。
In Figure 14E, operations with external incoming edges are identified and merged together into the same subgraph. Since both the node C and the first No-op operation have the outer edges passed in from the node A outside the
儘可能地合併具有非封鎖操作之子圖。在圖14E中，存在含有Noop操作之兩個子圖1455、1458。然而，合併彼兩個子圖1455、1458將引入一循環，且因此係不准許的。由於包含節點B之子圖1453及包含節點D之子圖1456具有無法與任何其他子圖合併之封鎖操作，因此本端分割完成。
As much as possible, merge subgraphs with non-blocking operations. In Figure 14E, there are two
圖15圖解說明在主要分割及本端分割之後的最終程式。已以使跨網路自一個位置發送至另一位置之訊務最小化之此一方式將若干位置指派至每一位置。此外，已採取預防措施以(舉例而言)藉由防止節點之間的循環且最佳化節點之間的發送及接收而確保效率。 Figure 15 illustrates the final program after the main partition and the local partition. Several locations have been assigned to each location in such a way as to minimize the traffic sent from one location to another across the network. In addition, precautions have been taken to ensure efficiency, for example, by preventing loops between nodes and optimizing transmission and reception between nodes.
圖16提供圖解說明針對一所建立程式之圖形建立及分割之一實例性方法1600之一流程圖。結合圖17至圖18而進一步詳細地闡述方法1600之某些部分。本文中所闡述之方法中之每一者包含可以一不同次序或同時執行之部分，且可包含額外部分，其中可省略其他部分。
FIG. 16 provides a flowchart illustrating an
在方塊1610中，建立一有向非循環圖形，其包含表示程式
之操作之節點。圖形中之節點藉由邊緣而接合，該等邊緣表示自一個操作流動至另一操作之資料串流。操作中之某些操作可具有預定義位置。舉例而言，可藉由操作之性質、分散式環境中之計算裝置之能力、程式設計員指派或任何其他資訊而判定此等位置。
In
在方塊1620中，將位置指派至不具有一預定義位置之任何操作。可基於一第一組約束(諸如上文所闡述之主要分割約束)而指派位置。在某些實例中，第一組約束要求將所有操作放置至一子圖中、將一位置指派至每一子圖、具有一程式設計員指派之位置之一操作必須保持彼指派且若一未經指派操作具有一可分裂性質，則可僅將該未經指派操作放置至一經分區位置中。此外，若一位置被分區，則其目的地操作被指派至彼位置的程式中之所有邊緣在整個演算法中保持不改變。此外，圖形必須係非循環的。舉例而言，可基於相鄰節點而指派位置。舉例而言，可根據約束而將具有未經指派位置之操作添加至毗鄰經分區子圖中。可向具有未經指派位置之任何其他操作指派匹配相鄰未經分區節點之位置。位置指派可為圖形分割之一部分。
In
在方塊1630中，將圖形分割成複數個子圖，其中將一子圖中之操作指派至相同位置。結合圖17而進一步詳細地闡述方塊1630之分割。
In
在方塊1640中，基於一第二組約束(諸如上文所論述之本端分割約束)而針對個別子圖執行本端分割。結合圖18而進一步闡述本端分割。
In
在方塊1650中，在每一子圖之各別位置處執行該每一子圖。在一單個各別執行緒中執行個別子圖。在下一章節IV中較全面地論述
程式執行。
In
圖17提供圖解說明主要圖形分割之一方法1700之一流程圖。在方塊1710中，儘可能地合併經分區子圖，同時遵循主要分割約束。上文結合圖13B而論述一實例。
FIG. 17 provides a flowchart illustrating a
在方塊1720中，儘可能地將具有未經指派位置之節點添加至相鄰經分區子圖中，同時遵循主要分割約束。上文結合圖13C而論述一實例。在某些例項中，此可包含建立一額外操作。舉例而言，在將具有一未經指派位置之一節點添加至相鄰經分區子圖時對該節點有效地進行分區之情況下，將一新操作添加至子圖外部之圖形以合併來自經分區操作之結果。
In
在方塊1730中，將位置指派至具有未經指派位置之任何其餘節點。可基於先前被指派至相鄰節點之位置同時遵循主要分割約束而指派位置。上文結合圖13D而論述一實例。
In
在方塊1740中，合併在相同位置處運行之可能之未經分區子圖對。上文結合圖13E至圖13F而論述一實例。
In
圖18提供圖解說明本端分割之一實例性方法1800之一流程圖。在方塊1810中，識別需要被分裂之子圖。舉例而言，若子圖含有一或多個封鎖操作，則可將要分裂該等子圖。
Figure 18 provides a flow chart illustrating an
在方塊1820中，使所識別子圖準備好進行分裂。舉例而言，準備可包含進行修改以確保不存在具有去往子圖之外部輸入之封鎖操作，且在子圖中不存在具有外部輸出之封鎖操作。此等修改可包含將操作添加至子圖，諸如上文結合圖14B至圖14C所論述。
In
在方塊1830中，構建一合併圖形，其中每一操作在一單獨
子圖中結束。上文結合圖14D而論述一實例。
In
在方塊1840中，在不打破本端分割約束中之一者之情況下重複地合併單獨子圖直至無進一步合併可執行為止。可針對圖形中之每一相關子圖而重複此方法。
In
一旦經分割，圖形便可被執行。在子圖之各別位置處執行該等子圖中之每一者，且在一各別單個執行緒中執行每一子圖。沿著一子圖內之邊緣進行之資料傳送基於其在一單執行緒環境中之執行而被最佳化。 Once split, the graphics can be executed. Each of the sub-graphs is executed at a separate position of the sub-graph, and each sub-graph is executed in a separate single thread. The data transfer along the edges within a sub-picture is optimized based on its execution in a single-threaded environment.
在執行程式時，判定經由圖形而發送之一串流是否已完成。為進行此判定，一端節點自將元組發送至該端節點之每一其他節點接收一符記，該符記指示其他節點已完成提供輸入。該其他節點可(舉例而言)為一經分區節點，或簡稱為分區。端節點將符記加在一起，且當符記之一總和等於提供輸入之其他節點之數目時，端節點判定串流已完成。 When the program is executed, it is determined whether a stream sent via graphics has been completed. To make this determination, one end node receives a token from every other node that sent the tuple to the end node, which indicates that the other node has finished providing input. The other node can be, for example, a partitioned node, or simply a partition. The end node adds the tokens together, and when the sum of one of the tokens is equal to the number of other nodes that provide input, the end node determines that the stream is complete.
當提交程式以用於執行時，建立每一圖形之一或多個啟動。針對一唯一圖形存在一個啟動。一唯一圖形包含各自恰好運行一次之複數個節點。在圖19中提供一唯一圖形之一實例。在此實例中，節點A、B*、C*、D中之每一者運行一次，其中將來自A之串流輸入至B*，將該串流輸入至C*，將該串流輸入至D。 When submitting the program for execution, create one or more activations for each graphic. There is one activation for a unique graphic. A unique graph contains multiple nodes that each run exactly once. An example of a unique figure is provided in Figure 19. In this example, each of nodes A, B*, C*, and D runs once, where the stream from A is input to B*, the stream is input to C*, and the stream is input to D.
一非唯一圖形可使任意數目個啟動複本執行，使得輸入將被分裂並發送至此等執行中之任一者且輸出被合併在一起。在圖20中提供一非唯一圖形之一實例。存在操作B及C之多個複本，其中來自節點A之輸入在節點B之複本當中進行分裂等。舉例而言，節點B1、B2及B3係相同 操作B之啟動。類似地，節點C1及C2係相同操作C之啟動。 A non-unique graphic can allow any number of startup copies to execute, so that the input will be split and sent to any of these executions and the output will be merged together. An example of a non-unique figure is provided in Figure 20. There are multiple copies of operations B and C, where the input from node A is split among the copies of node B, etc. For example, nodes B1, B2, and B3 are the same Start operation B. Similarly, nodes C1 and C2 are the start of the same operation C.
當初始化啟動時，每一節點本端地追蹤其所連接至的一定數目個上游(發送節點)及下游節點(接收節點)。初始發送節點與最終接收節點之間的節點可用作發送節點及接收節點兩者，從而自一或多個節點接收資訊、執行一操作及將資訊傳輸至一或多個其他節點。透過一串流而發送之每一值係一元組。同一程式中之不同操作可在不同機器上運行。程式化模型協調此等運算子在不同機器上之執行且將資料自一個運算子傳播至另一運算子。 When the initialization starts, each node locally tracks a certain number of upstream (transmitting nodes) and downstream nodes (receiving nodes) it is connected to. The node between the initial sending node and the final receiving node can be used as both a sending node and a receiving node to receive information from one or more nodes, perform an operation, and transmit information to one or more other nodes. Each value sent through a stream is a tuple. Different operations in the same program can be run on different machines. The stylized model coordinates the execution of these operators on different machines and propagates data from one operator to another.
由於運算子在不同機器上且因此在圖形之不同節點處運行，因此程式之部分並行地運行。為判定一特定串流是否完成，目的地節點對自分區之上游運算子接收之符記值之一數目求總和。舉例而言，當去往一發送節點之輸入結束時，發送節點將一符記值(例如，1)傳輸至該發送節點已向其傳輸資訊之每個節點。當目的地節點接收到總數達其所連接至的發送節點之一數目之符記值時，目的地節點判定串流已結束。因此，目的地節點可採取一動作，諸如產生一結束信號或將串流標記為已完成。在一項實例中，目的地節點將一完成符記發送至其他下游節點。 Since the operators run on different machines and therefore at different nodes of the graph, parts of the program run in parallel. To determine whether a particular stream is complete, the destination node sums one of the number of token values received from the upstream operator of the partition. For example, when the input to a sending node ends, the sending node transmits a token value (for example, 1) to each node to which the sending node has transmitted information. When the destination node receives a total of token values up to the number of one of the sending nodes it is connected to, the destination node determines that the stream has ended. Therefore, the destination node can take an action, such as generating an end signal or marking the stream as completed. In one example, the destination node sends a completion token to other downstream nodes.
圖21圖解說明發送符記值從而用信號通知一串流之完成之一實例。節點B0、B1及B2中之每一者自一個節點A接收輸入。當節點A已完成發送串流時，該節點A將一符記值(諸如1)發送至所連接下游節點B0、B1、B2中之每一者。節點B0、B1、B2將等待接收等於發送者數目之符記值(在此情形中，1)。節點B0、B1、B2中之每一者繼而將串流發送至一單個目的地節點C。目的地節點C知曉其自三個不同節點B0、B1、B2接收輸入，且因此該目的地節點C等待接收等於3之符記值。當節點B0、 B1、B2完成發送串流時，該等節點將一符記值發送至所連接下游節點，即，目的地節點C。目的地節點C對所接收之符記值求總和且比較該總和與該目的地節點C自其接收輸入之節點之數目。當數目相等時，節點C將其自身標記為已完成。 Figure 21 illustrates an example of sending a token value to signal the completion of a stream. Each of nodes B0, B1, and B2 receives input from a node A. When the node A has finished sending the stream, the node A sends a token value (such as 1) to each of the connected downstream nodes B0, B1, and B2. Nodes B0, B1, B2 will wait to receive a token value equal to the number of senders (in this case, 1). Each of the nodes B0, B1, B2 then sends the stream to a single destination node C. The destination node C knows that it receives input from three different nodes B0, B1, B2, and therefore the destination node C is waiting to receive a token value equal to 3. When node B0, When B1 and B2 finish sending the stream, these nodes send a token value to the connected downstream node, that is, the destination node C. The destination node C sums the received token values and compares the sum with the number of nodes from which the destination node C receives input. When the numbers are equal, node C marks itself as completed.
圖22圖解說明其中一發送節點僅將串流發送至該發送節點所連接至的接收節點之一子集之一實例。舉例而言，節點B及C被分區，但分區對中之僅某些分區對進行通信。B0可僅接觸分區C0而不接觸分區C1，而分區B1僅接觸分區C1而不接觸分區C0。在此情景中，發送節點可產生其已進行通信之所有接收分區之一清單，且可將此清單進一步提供至一控制器2250。舉例而言，該清單可包含於一訊息中，該訊息指示發送分區已完成其對串流之傳輸。控制器追蹤已開始處理之所有接收分區。若一特定分區已起始但不存在於清單中，則控制器對彼特定分區承擔責任且向該特定分區發送代表發送分區之一符記值。
Figure 22 illustrates an example in which a sending node only sends a stream to a subset of the receiving nodes to which the sending node is connected. For example, nodes B and C are partitioned, but only certain partition pairs in the partition pair communicate. B0 may only contact the partition C0 but not the partition C1, and the partition B1 may only contact the partition C1 but not the partition C0. In this scenario, the sending node can generate a list of all receiving partitions that it has communicated with, and can further provide this list to a
圖23圖解說明其中某些發送節點可未開始處理之一實例。舉例而言，節點C及D可被節點B跳過，且將元組自在所跳過節點之前的一發送節點直接提供至目的地節點E。另一可能性係節點B、C及D全部被節點A跳過，節點A將元組直接提供至目的地節點E。在任一情形中，控制器接管將符記自圖形之所有分區進行遞送之責任。控制器模擬所跳過節點B、C及D之執行，且將符記值遞送至代表此等未經起始發送節點之下游接收者(節點E)。下游接收者可對符記值求總和以判定串流是否已完成。 FIG. 23 illustrates an example in which some sending nodes may not start processing. For example, nodes C and D can be skipped by node B, and the tuple is directly provided to the destination node E from a sending node before the skipped node. Another possibility is that nodes B, C, and D are all skipped by node A, and node A provides the tuple directly to the destination node E. In either case, the controller takes over the responsibility of delivering the symbol from all the partitions of the graph. The controller simulates the execution of skipped nodes B, C, and D, and delivers the token value to downstream receivers (node E) that represent these uninitiated sending nodes. The downstream receiver can sum the token values to determine whether the stream has been completed.
如上文所提及，用於程式之圖形可為唯一或非唯一的，其中一唯一圖形之一分區運行一次且一非唯一圖形可使任意數目個複本針對一或多個分區而執行。舉例而言，在一非唯一圖形中，輸入在複本當中被 分裂，且輸出被合併在一起。在其中每一發送節點並非唯一地與一個接收節點配對之圖形中，接收節點可本端地追蹤一定數目個發送節點，且當該接收節點接收到等於發送節點數目之一符記數目時，該接收節點判定一串流已完成。 As mentioned above, the graphics used in the program can be unique or non-unique. One of the unique graphics can be executed once for one partition and a non-unique graphics can allow any number of copies to be executed for one or more partitions. For example, in a non-unique graphic, the input is Split, and the output is merged together. In a graph in which each sending node is not uniquely paired with a receiving node, the receiving node can track a certain number of sending nodes locally, and when the receiving node receives a token number equal to the number of sending nodes, the The receiving node determines that a stream has been completed.
每一發送操作分區可具有其自身之非唯一接收者。在此例項中，發送者僅發送一個1且對應非唯一接收者在接收到1時完成。可引入跨多個發送者共用一非唯一接收者之相同執行之一最佳化。然後，該一定數目發送者由接收者本端地追蹤，且非唯一接收者在已接收到等於發送者數目之符記時完成。 Each transmission operation partition may have its own non-unique receiver. In this example, the sender only sends a 1 and the corresponding non-unique receiver completes when the 1 is received. It is possible to introduce an optimization that shares a non-unique receiver across multiple senders. Then, the certain number of senders are tracked locally by the receivers, and the non-unique receivers complete when they have received tokens equal to the number of senders.
在其他實例中，一非唯一發送者可將串流發送至一唯一接收者。每一非唯一發送者將一符記值1發送至唯一接收者且唯一接收者等待等於非唯一發送者數目之一符記值總數。當非唯一發送者完成時，其發送接收分區(該非唯一發送者已向其發送符記)之清單且控制器負責將其餘符記遞送至每一分區。在其他實例中，控制器可將針對非唯一發送者之所有符記遞送至每一接收分區。 In other examples, a non-unique sender may send the stream to a unique receiver. Each non-unique sender sends a token value of 1 to the only receiver and the only receiver waits for the total token value equal to one of the number of non-unique senders. When the non-unique sender completes, it sends and receives the list of partitions to which the non-unique sender has sent tokens and the controller is responsible for delivering the remaining tokens to each partition. In other examples, the controller may deliver all tokens for non-unique senders to each receiving partition.
在某些實例中，可將某些串流廣播至一圖形之所有啟動。然而，在建構程式之一時間處並不知曉啟動集合，且該集合係隨著程式執行繼續進行而逐步構建。圖24圖解說明其中一非唯一圖形G在分區R1上接收可導致G之多個啟動之一常規輸入X之一實例。舉例而言，G可被分區(包含分區R1及R2)，或發送者S1至R1可具有到達G之不同複本之多個啟動。應將另一輸入Y廣播至G之每個複本。針對每個此廣播，引入一動態發送操作S2。動態發送操作S2具有兩個輸入串流一來自Y之一資料輸入串流及來自控制器之一啟動輸入串流。資料輸入串流係應被發送至目的地圖 形G之所有啟動之一正常元組串流。當偵測到目的地圖形之新啟動時，啟動輸入串流包含元組到達其上之啟動。舉例而言，當執行一特定圖形之一複本時，將一識別符發送至控制器，該控制器將啟動路由至適當動態發送操作。動態發送操作維持經暫存啟動之一集合，且亦維持所接收之所有輸入資料之一緩衝區。當資料輸入結束時，將一結束信號自動態發送操作發送至所有經暫存啟動及新啟動，且亦發送至隨後到達之新啟動。當啟動輸入結束時，可丟棄輸入資料之緩衝區。 In some instances, certain streams can be broadcast to all activations of a graphic. However, the activation set is not known at a time when the program is constructed, and the set is gradually constructed as the program execution continues. FIG. 24 illustrates an example in which a non-unique graphic G receives a regular input X on the partition R1 that can cause multiple activations of G. For example, G may be partitioned (including partitions R1 and R2), or senders S1 to R1 may have multiple activations reaching different copies of G. The other input Y should be broadcast to each copy of G. For each broadcast, a dynamic sending operation S2 is introduced. The dynamic sending operation S2 has two input streams, one data input stream from Y and one start input stream from the controller. The data input stream should be sent to the destination map One of all activations of the shape G is a normal tuple stream. When a new activation of the destination graphic is detected, the activation input stream contains the activation where the tuple reaches it. For example, when a copy of a particular pattern is executed, an identifier is sent to the controller, which will initiate routing to the appropriate dynamic sending operation. The dynamic sending operation maintains a set activated by temporary storage, and also maintains a buffer of all input data received. When the data input ends, an end signal is sent from the dynamic sending operation to all temporarily stored startups and new startups, and also sent to the new startups that arrive later. When the start input ends, the input data buffer can be discarded.
圖25提供圖解說明用於經由一分散式網路而執行一程式之一實例性方法2500之一流程圖，該程式由一圖形表示，該圖形包含表示操作之複數個節點，其中邊緣表示將該等節點互連之資料串流。如在以上實例中，方法2500之子部分可被重新排序、被補充或被減少。
Figure 25 provides a flowchart illustrating an
在方塊2510中，由一或多個第一分區執行操作。舉例而言，第一分區可為一圖形中之發送分區。
In
在方塊2520中，將基於所執行操作之元組自一或多個第一分區發送至至少一個第二分區，諸如一接收分區。
In
在方塊2530中，當一或多個第一分區已完成發送元組時，一或多個第一分區中之每一者將一符記值發送至至少一個第二分區。舉例而言，該符記值可為1。一或多個第一分區可進一步本端地註記元組之傳輸完成。
In
在方塊2540中，至少一個第二分區對所接收符記值求總和，且判定該總和是否匹配一或多個第一分區之一數目。舉例而言，至少一個第二分區可知曉其自三個發送分區接收輸入。因此，至少一個第二分區在其認為串流完成之前進行等待直至其接收到一總數3個符記為止。
In
在方塊2550中，至少一個第二分區回應於判定符記值之總和匹配一或多個第一分區之數目而採取一動作。該動作可為(舉例而言)進行一本端註記、將一訊息及/或符記值發送至另一下游節點等。 In block 2550, at least one second partition takes an action in response to the sum of the determinator values matching the number of one or more first partitions. This action can be, for example, performing a local annotation, sending a message and/or token value to another downstream node, etc.
上文所闡述技術提供快速且高效之程式執行。此外，所闡述之技術可適應於各種類型之經分區及經管線化程式。更進一步地，該等技術可在一程式之寫入期間應用，且因此動態地適應於程式中之改變。新程式化模型支援無限數目個分區，每一分區跨資料庫將元組傳輸至其他分區。儘管僅分區之某些子集可實際上針對一特定程式而運行，但控制器對並未運行之分區進行補償，而不會給控制器帶來顯著負擔。 The technologies described above provide fast and efficient program execution. In addition, the techniques described can be adapted to various types of partitioned and pipelined programs. Furthermore, these techniques can be applied during the writing of a program, and therefore dynamically adapt to changes in the program. The new programming model supports an unlimited number of partitions, and each partition transfers tuples across databases to other partitions. Although only certain subsets of the partitions can actually be run for a specific program, the controller compensates for the partitions that are not running without placing a significant burden on the controller.
除非另外陳述，否則前述替代實例並非相互排斥的，而是可以各種組合來實施以達成獨特優點。由於可在不背離由申請專利範圍界定之標的物之情況下利用上文所論述之特徵之此等及其他變化及組合，因此應藉由圖解說明方式而非藉由限制由申請專利範圍界定之標的物之方式理解實施例之前述說明。另外，對本文中所闡述之實例以及措辭為「諸如」、「包含」及諸如此類之從句之提供不應被解釋為將申請專利範圍之標的物限制於特定實例；而是，該等實例意欲圖解說明諸多可能實施例中之僅一者。此外，不同圖式中之相同元件符號可識別相同或類似元件。 Unless stated otherwise, the foregoing alternative examples are not mutually exclusive, but can be implemented in various combinations to achieve unique advantages. Since these and other changes and combinations of the features discussed above can be used without departing from the subject matter defined by the scope of the patent application, it should be illustrated by way of illustration rather than by limiting the scope defined by the patent application The manner of the subject matter understands the foregoing description of the embodiment. In addition, the provision of the examples set forth herein and clauses such as "such as", "including" and the like should not be construed as limiting the subject matter of the patent application to specific examples; rather, these examples are intended Illustrates only one of many possible embodiments. In addition, the same component symbols in different drawings can identify the same or similar components.
A‧‧‧節點 A‧‧‧node
B0‧‧‧節點/下游節點 B0‧‧‧Node/Downstream Node
B1‧‧‧節點/下游節點 B1‧‧‧Node/Downstream Node
B2‧‧‧節點/下游節點 B2‧‧‧Node/Downstream Node
C‧‧‧目的地節點/節點 C‧‧‧Destination Node/Node
Claims (20)
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US15/685,022 US10887235B2 (en) | 2017-08-24 | 2017-08-24 | Method of executing a tuple graph program across a network |
US15/685,022 | 2017-08-24 |
Publications (2)
Publication Number | Publication Date |
---|---|
TW201913404A TW201913404A (en) | 2019-04-01 |
TWI710913B true TWI710913B (en) | 2020-11-21 |
Family
ID=62567816
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
TW107116380A TWI710913B (en) | 2017-08-24 | 2018-05-15 | Method of executing a tuple graph program across a network |
Country Status (5)
Country | Link |
---|---|
US (1) | US10887235B2 (en) |
EP (1) | EP3673369A1 (en) |
CN (1) | CN110945481B (en) |
TW (1) | TWI710913B (en) |
WO (1) | WO2019040139A1 (en) |
Families Citing this family (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11843656B2 (en) * | 2017-09-27 | 2023-12-12 | Iguazio Systems Ltd. | Dynamic application mobilization |
KR20200083048A (en) * | 2018-12-31 | 2020-07-08 | 삼성전자주식회사 | Neural network system predicting polling time and neural network model processing method using the same |
US11256546B2 (en) | 2019-07-02 | 2022-02-22 | Nokia Technologies Oy | Methods, apparatuses and computer readable mediums for network based media processing |
TWI714390B (en) * | 2019-12-13 | 2020-12-21 | 中華電信股份有限公司 | Method for controlling operation flow |
US11550554B2 (en) * | 2021-01-07 | 2023-01-10 | Microsoft Technology Licensing, Llc | Merged machine-level intermediate representation optimizations |
Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
TW200506646A (en) * | 2003-06-30 | 2005-02-16 | Microsoft Corp | Network load balancing with host status information |
TW200813738A (en) * | 2006-04-06 | 2008-03-16 | Ibm | Process restart on a computer node |
TW200947225A (en) * | 2007-11-08 | 2009-11-16 | Genetic Finance Holdings Ltd | Distributed network for performing complex algorithms |
TW201237639A (en) * | 2010-12-10 | 2012-09-16 | Microsoft Corp | Back-end constrained delegation model |
Family Cites Families (77)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
EP0390563A3 (en) | 1989-03-31 | 1992-12-02 | Matsushita Electric Industrial Co., Ltd. | Fuzzy multi-stage inference apparatus |
US5748966A (en) | 1994-12-30 | 1998-05-05 | The Trustees Of The University Of Pennsylvania | Type error checker for type-free or polymorphic computer language |
US5630051A (en) | 1995-03-06 | 1997-05-13 | Motorola Inc. | Method and apparatus for merging hierarchical test subsequence and finite state machine (FSM) model graphs |
JPH08278890A (en) | 1995-04-05 | 1996-10-22 | Sharp Corp | Evolution adaptive type inference knowledge extracting device and analyzing device for point-of sales data using the same |
US6202202B1 (en) | 1996-09-24 | 2001-03-13 | Microsoft Corporation | Pointer analysis by type inference for programs with structured memory objects and potentially inconsistent memory object accesses |
US6014518A (en) | 1997-06-26 | 2000-01-11 | Microsoft Corporation | Terminating polymorphic type inference program analysis |
US6018628A (en) | 1998-06-16 | 2000-01-25 | Sun Microsystems, Inc. | Method of implementing parameterized types to be compatible with existing unparameterized libraries |
US6292938B1 (en) | 1998-12-02 | 2001-09-18 | International Business Machines Corporation | Retargeting optimized code by matching tree patterns in directed acyclic graphs |
CA2288614C (en) | 1999-11-08 | 2004-05-11 | Robert J. Blainey | Loop allocation for optimizing compilers |
WO2002013002A2 (en) | 2000-08-04 | 2002-02-14 | Intrinsic Graphics, Inc. | Development of graphics hardware and software |
US7010789B1 (en) | 2000-09-29 | 2006-03-07 | International Business Machines Corporation | Independent net task identification for efficient partition and distribution |
US7120902B2 (en) | 2000-12-04 | 2006-10-10 | Hewlett-Packard Development Company, L.P. | Method and apparatus for automatically inferring annotations |
TW200408955A (en) | 2002-09-30 | 2004-06-01 | Advent Networks Inc | Implementing request/reply programming semantics using publish/subscribe middleware |
US7496892B2 (en) | 2003-05-06 | 2009-02-24 | Andrew Nuss | Polymorphic regular expressions |
US7567504B2 (en) | 2003-06-30 | 2009-07-28 | Microsoft Corporation | Network load balancing with traffic routing |
US20050177578A1 (en) | 2004-02-10 | 2005-08-11 | Chen Yao-Ching S. | Efficient type annontation of XML schema-validated XML documents without schema validation |
GB2416048A (en) | 2004-07-10 | 2006-01-11 | Hewlett Packard Development Co | Inferring data type in a multi stage process |
US7970730B2 (en) | 2005-01-27 | 2011-06-28 | Microsoft Corporation | Efficient data access via runtime type inference |
US10002325B2 (en) | 2005-03-30 | 2018-06-19 | Primal Fusion Inc. | Knowledge representation systems and methods incorporating inference rules |
US7426503B2 (en) | 2005-04-25 | 2008-09-16 | Microsoft Corporation | System and method for an improved type inference |
US8473971B2 (en) | 2005-09-06 | 2013-06-25 | Microsoft Corporation | Type inference and type-directed late binding |
US7958493B2 (en) | 2006-01-20 | 2011-06-07 | Kevin Edward Lindsey | Type inference system and method |
US7720779B1 (en) | 2006-01-23 | 2010-05-18 | Quantum Leap Research, Inc. | Extensible bayesian network editor with inferencing capabilities |
EP1933507A1 (en) * | 2006-12-15 | 2008-06-18 | Ubiwave | Low-power multi-hop networks |
US8396827B2 (en) | 2006-12-29 | 2013-03-12 | Sap Ag | Relation-based hierarchy evaluation of recursive nodes |
US8752032B2 (en) | 2007-02-23 | 2014-06-10 | Irdeto Canada Corporation | System and method of interlocking to protect software-mediated program and device behaviours |
US7856246B2 (en) | 2007-03-21 | 2010-12-21 | Nokia Corporation | Multi-cell data processor |
US8332385B2 (en) | 2008-03-11 | 2012-12-11 | Semmle Limited | Approximating query results by relations over types for error detection and optimization |
WO2010107327A1 (en) | 2009-03-20 | 2010-09-23 | Syl Research Limited | Natural language processing method and system |
US8555265B2 (en) * | 2010-05-04 | 2013-10-08 | Google Inc. | Parallel processing of data |
US8549502B2 (en) | 2010-06-21 | 2013-10-01 | Microsoft Corporation | Compiler with user-defined type inference rules |
US8438364B2 (en) * | 2010-12-30 | 2013-05-07 | Facebook Inc. | Distributed cache for graph data |
US20130139164A1 (en) | 2011-11-28 | 2013-05-30 | Sap Ag | Business Process Optimization |
US8965921B2 (en) * | 2012-06-06 | 2015-02-24 | Rackspace Us, Inc. | Data management and indexing across a distributed database |
US20140058913A1 (en) * | 2012-08-24 | 2014-02-27 | International Business Machines Corporation | Graph partitioning for dynamic securitization |
US8843887B2 (en) | 2012-08-31 | 2014-09-23 | Oracle International Corporation | Fast dispatch predicate for overloaded functions with generic type hierarchies that lack contravariance |
US9411558B2 (en) * | 2012-10-20 | 2016-08-09 | Luke Hutchison | Systems and methods for parallelization of program code, interactive data visualization, and graphically-augmented code editing |
US9229983B2 (en) * | 2012-11-30 | 2016-01-05 | Amazon Technologies, Inc. | System-wide query optimization |
CN106896524B (en) * | 2012-12-06 | 2021-01-01 | E-视觉有限公司 | System, apparatus, and/or method for providing images |
US9832068B2 (en) * | 2012-12-17 | 2017-11-28 | Microsoft Technology Licensing, Llc | Reachability-based coordination for cyclic dataflow |
US9311149B2 (en) | 2012-12-21 | 2016-04-12 | International Business Machines Corporation | Processor provisioning by a middleware processing system |
US9696974B2 (en) | 2013-03-13 | 2017-07-04 | Microsoft Technology Licensing, Llc. | Graph-based model for type systems |
US10055396B2 (en) | 2013-04-12 | 2018-08-21 | Microsoft Technology Licensing, Llc | Binding of data source to compound control |
US9147010B2 (en) * | 2013-04-17 | 2015-09-29 | International Business Machines Corporation | Reconfiguring an operator graph based on attribute usage |
US9182952B2 (en) | 2013-06-04 | 2015-11-10 | Qualcomm Incorporated | Automated graph-based programming |
US9459986B2 (en) | 2013-08-28 | 2016-10-04 | International Business Machines Corporation | Automatic generation of analysis-equivalent application constructs |
EP3051773B1 (en) * | 2013-10-25 | 2020-09-16 | Huawei Technologies Co., Ltd. | Multi-path auxiliary stream control method, control device, node and system |
US9723054B2 (en) * | 2013-12-30 | 2017-08-01 | Microsoft Technology Licensing, Llc | Hierarchical organization for scale-out cluster |
US9313110B2 (en) * | 2014-01-22 | 2016-04-12 | International Business Machines Corporation | Managing processing branches in an operator graph |
US9189212B2 (en) * | 2014-03-31 | 2015-11-17 | International Business Machines Corporation | Predicted outputs in a streaming environment |
US10402453B2 (en) | 2014-06-27 | 2019-09-03 | Nuance Communications, Inc. | Utilizing large-scale knowledge graphs to support inference at scale and explanation generation |
US10025571B1 (en) | 2014-07-17 | 2018-07-17 | Google Llc | Optimized execution of dynamic languages |
US10437843B2 (en) * | 2014-07-29 | 2019-10-08 | Microsoft Technology Licensing, Llc | Optimization of database queries via transformations of computation graph |
US20160065498A1 (en) * | 2014-08-26 | 2016-03-03 | rift.IO, Inc. | Distributed transaction subsystem |
US10303796B2 (en) * | 2015-01-09 | 2019-05-28 | Ariba, Inc. | Updating distributed shards without compromising on consistency |
US9886441B2 (en) * | 2015-04-06 | 2018-02-06 | Sap Se | Shard aware near real time indexing |
US9864779B2 (en) * | 2015-06-15 | 2018-01-09 | International Business Machines Corporation | Suppressing stream functionality to expedite preferred data |
US9823982B1 (en) * | 2015-06-19 | 2017-11-21 | Amazon Technologies, Inc. | Archiving and restoration of distributed database log records |
US10037389B2 (en) * | 2015-07-21 | 2018-07-31 | International Business Machines Corporation | Dynamic window adjustments in a streaming environment |
US10339116B2 (en) * | 2015-10-07 | 2019-07-02 | Oracle International Corporation | Composite sharding |
KR102433254B1 (en) | 2015-10-28 | 2022-08-18 | 구글 엘엘씨 | Processing computational graphs |
US11151446B2 (en) | 2015-10-28 | 2021-10-19 | Google Llc | Stream-based accelerator processing of computational graphs |
US10664249B2 (en) | 2015-11-20 | 2020-05-26 | Microsoft Technology Licensing, Llc | Verified compilation of reversible circuits |
US20170193041A1 (en) | 2016-01-05 | 2017-07-06 | Sqrrl Data, Inc. | Document-partitioned secondary indexes in a sorted, distributed key/value data store |
US9928046B2 (en) * | 2016-02-12 | 2018-03-27 | International Business Machines Corporation | System and method for dynamic runtime merging of real time streaming operator environments |
US10896178B2 (en) * | 2016-03-30 | 2021-01-19 | Microsoft Technology Licensing, Llc | High performance query processing and data analytics |
US10303505B2 (en) * | 2016-05-19 | 2019-05-28 | International Business Machines Corporation | Adjusting a computing environment for processing a data stream with dummy tuples |
US10311158B2 (en) * | 2016-06-06 | 2019-06-04 | International Business Machines Corporation | Streamlining tuple processing by delivering tuple attributes to associated operators |
US10380188B2 (en) * | 2016-08-05 | 2019-08-13 | International Business Machines Corporation | Distributed graph databases that facilitate streaming data insertion and queries by reducing number of messages required to add a new edge by employing asynchronous communication |
US10552450B2 (en) * | 2016-08-05 | 2020-02-04 | International Business Machines Corporation | Distributed graph databases that facilitate streaming data insertion and low latency graph queries |
US10394891B2 (en) * | 2016-08-05 | 2019-08-27 | International Business Machines Corporation | Distributed graph databases that facilitate streaming data insertion and queries by efficient throughput edge addition |
US10417239B2 (en) * | 2017-01-13 | 2019-09-17 | International Business Machines Corporation | Reducing flow delays in a data streaming application caused by lookup operations |
US10706102B2 (en) * | 2017-03-06 | 2020-07-07 | International Business Machines Corporation | Operation efficiency management with respect to application run-time |
US10425313B2 (en) * | 2017-04-05 | 2019-09-24 | International Business Machines Corporation | Tuple traffic management |
US10628492B2 (en) * | 2017-07-20 | 2020-04-21 | Microsoft Technology Licensing, Llc | Distributed graph database writes |
US10599482B2 (en) * | 2017-08-24 | 2020-03-24 | Google Llc | Method for intra-subgraph optimization in tuple graph programs |
US10642582B2 (en) * | 2017-08-24 | 2020-05-05 | Google Llc | System of type inference for tuple graph programs method of executing a tuple graph program across a network |
-
2017
- 2017-08-24 US US15/685,022 patent/US10887235B2/en active Active
-
2018
- 2018-05-15 TW TW107116380A patent/TWI710913B/en active
- 2018-05-17 EP EP18730559.4A patent/EP3673369A1/en active Pending
- 2018-05-17 CN CN201880035919.0A patent/CN110945481B/en active Active
- 2018-05-17 WO PCT/US2018/033112 patent/WO2019040139A1/en unknown
Patent Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
TW200506646A (en) * | 2003-06-30 | 2005-02-16 | Microsoft Corp | Network load balancing with host status information |
TW200813738A (en) * | 2006-04-06 | 2008-03-16 | Ibm | Process restart on a computer node |
TW200947225A (en) * | 2007-11-08 | 2009-11-16 | Genetic Finance Holdings Ltd | Distributed network for performing complex algorithms |
TW201237639A (en) * | 2010-12-10 | 2012-09-16 | Microsoft Corp | Back-end constrained delegation model |
Also Published As
Publication number | Publication date |
---|---|
WO2019040139A1 (en) | 2019-02-28 |
CN110945481A (en) | 2020-03-31 |
US20190068504A1 (en) | 2019-02-28 |
EP3673369A1 (en) | 2020-07-01 |
US10887235B2 (en) | 2021-01-05 |
TW201913404A (en) | 2019-04-01 |
CN110945481B (en) | 2023-08-08 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
TWI710913B (en) | Method of executing a tuple graph program across a network | |
TWI692692B (en) | Method for intra-subgraph optimization in tuple graph programs | |
CN106663010B (en) | Executing graph-based program specification | |
CN107077364B (en) | Compilation of graph-based program specifications using automatic clustering of graph components based on identification of specific data port connections | |
CN106687920B (en) | Management task invocation | |
CN106687919B (en) | Method, system, and computer-readable medium for controlling execution of a plurality of components | |
CN106605209B (en) | Controlling data processing tasks | |
CA3055071C (en) | Writing composite objects to a data store | |
US11429355B2 (en) | System of type inference for tuple graph programs | |
CN115729648A (en) | Operator scheduling method, device and system based on directed acyclic graph | |
DARROUS | A Programming and Data Model for In-Situ frameworks | |
Gava et al. | Two formal semantics of a subset of the paderborn university bsplib | |
Mantha et al. | FutureGrid 2012 Project Challenge: Project 45 Building Scalable, Dynamic and Distributed Applications Using SAGA |