US10242080B1 - Clustering applications using visual metadata - Google Patents
Clustering applications using visual metadata Download PDFInfo
- Publication number
- US10242080B1 US10242080B1 US14/084,816 US201314084816A US10242080B1 US 10242080 B1 US10242080 B1 US 10242080B1 US 201314084816 A US201314084816 A US 201314084816A US 10242080 B1 US10242080 B1 US 10242080B1
- Authority
- US
- United States
- Prior art keywords
- application
- cluster
- screen shots
- clusters
- applications
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/26—Visual data mining; Browsing structured data
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/55—Clustering; Classification
-
- G06F17/30572—
Definitions
- the present disclosure a dynamical system and method for identifying visual metadata from screenshots of a software application, analyzing the identified visual metadata, and categorizing the software application based on the analysis.
- the software application is then presented to a user on a display in a cluster of other similar software applications.
- the present disclosure provides a system and method for recognition of applications visual metadata and a clustering of the applications based on the recognized visual metadata.
- clustering includes grouping software applications based on a commonly identified visual metadata. Accordingly, software applications are classified in a more desirable fashion.
- FIG. 1 is a flow chart illustrating the method of automatic clustering and recognition of applications using metadata
- FIG. 2 illustrates various modules used for the feature selection and extraction steps in the flow chart of FIG. 1 ;
- FIG. 3 illustrates elements used for the clustering analysis step in the flow chart of FIG. 1 ;
- FIG. 4 is a graphic illustration of how different software applications may be clustered together.
- FIG. 5 is a block diagram of a system for automatic recognition and clustering applications.
- FIGS. 1 through 5 illustrate a system and method for automatic clustering of applications using metadata.
- the system 600 preferably includes a computer (or computers) 500 including a microprocessor 501 , a feature selection and extraction module 502 and a clustering module 504 and memory 503 .
- the system further includes a user interface (UI) 506 that connects with the computer 500 via I/O 505 to allow a user 508 connected via the internet Y to interact with the computer 500 .
- UI user interface
- a data warehouse comprising a database 510 is also connected to the computer 500 .
- a user 508 may access the UI 506 using a variety of devices, including but not limited to a mobile phone, a tablet, a personal computer (PC), or other computing device.
- a user 508 is able to interact with the computer 500 .
- the feature selection and extraction module 502 performs several functions, illustrated in FIGS. 1 and 2 . First, it selects and extracts features from software applications (step 100 ). Once features are extracted, the features are assigned a classification (step 200 ), whereby the classification may be numerical, a set of characters, or some combination of the two. A cluster analysis is then performed on the classifications (step 300 ). A variety of methods for cluster analysis may be used and will be discussed in further detail. As a result of the cluster analysis 300 , at least one cluster assignment is delegated to each software application (step 400 ). Each cluster designation places the software application in a category with other software applications that have similar extracted features.
- a feed of information may be required in order to perform the feature selection and extraction.
- This information may be obtained through screen shots provided by the software developer 10 when the developer submits his or her software application to a digital multimedia content service provider.
- the digital multimedia content service provider may run the software application in an emulated mode to obtain screen shots 20 .
- the screen shots are stored in the database 510 .
- the screen shots are then processed during feature selection and extraction step 100 (via the feature extraction and selection module 502 ).
- feature selection and extraction step 100 a variety of methods and techniques to select and extract features may be used using specific modules, such as image segmentation analysis 102 , interest point-based analysis 104 , object recognition 106 , histogram-based analysis 108 , application information analysis 110 , and maturity level analysis 112 .
- image segmentation analysis 102 images (screen shots) are segmented so that each segment may be parsed and examined for pixel color, pattern recognition, and other elements. Segmentation analysis 102 may be used to locate objects and boundaries in the screen shots.
- interest point-based analysis 104 determines points in an image that are rich in information content. These points may be determined using techniques such as blob detection, edge detection, corner detection, and ridge detection. Interest point-based analysis 104 may be used to determine the presence of certain objects within the image. Furthermore, an interest point-based analysis may be utilized to understand the texture of the image.
- Object recognition 106 may be used in conjunction with data from a database 510 which contains information on objects that may repeat in screen shots of similar applications.
- video player software applications tend to have a control panel with a play button and a status bar. This information may be stored as image object data in a database 510 and during object recognition 106 , the video player object information may be compared to screen shots of software applications in order to detect specific software applications.
- the object recognition module 106 may be designed to recognize software applications that contain a play button and a status bar. These applications may then be assigned a category reference indicating that they contain media player objects.
- object recognition 106 may recognize gaming applications with similar character graphics or scenery graphics. Thus, object recognition 106 may recognize gaming applications all having images of farms, animals, etc. that may be categorized as certain type roll playing games.
- key features are extracted from software application screen shots. These key features are then compared with entries in a database 501 and information about what objects may have created these features are retrieved. Position, orientation, and scale may also be accounted for in object recognition by using a variety of features stored in the database 501 .
- Histogram-based analysis 108 includes the analysis of pixels of digital images. Preferably, an image is partitioned and each partition is analyzed with respect to pixel color information. A color histogram is then produced to represent the distribution of colors within the image or partition by providing the number of pixels that have colors in each of a fixed color range. The set of fixed color ranges span the image's color space.
- This analysis may provide object information, such as scenery information and the like, so that software applications with similar color histograms and patterns may be grouped together.
- Application information analysis 110 receives all developer-produced data including, but not limited to, software application title and description, developer-created metadata associated with the software application, a maturity rating pre-associated with the software application, developer data, and all text-based data associated with the application provided by the developer or from other sources.
- the feature selection and extraction step 100 may utilize any of the tools to detect and tag mature content to assign a maturity rating to the software application. For example, where applications contain violent content, such as weapons and the like, image segmentation analysis 102 , interest point-based analysis, object recognition 106 , or histogram-based analysis 108 may pick up those graphics and mark the software application as containing mature content.
- the selected and extracted features are assigned a classification in step 200 .
- This classification may be a numerical classification, or text-based classification, or some combination of the two.
- a cluster analysis step 300 is then performed on the classified features to determine patterns in the features and group the features by resemblance and the software applications are then arranged into different cluster, each cluster having some predetermined feature that is common to all the software applications within the cluster.
- FIGS. 3 and 4 illustrate some illustrative clustering criteria.
- clustering occurs where there are a set of data items, X ⁇ R m ⁇ n representing a set of m points x i in R n , a Euclidean n dimensional space.
- Clustering aims to accomplish the objective of partitioning X into K groups C k such that a data item belonging to a group is more similar to other data items in that group than data items in other groups.
- Each of the K groups is called a cluster.
- FIG. 4 illustrates three cluster groups, 410 , 420 , and 430 .
- Each data item, denoted i through N is compared against all other data items, such that a “distance” between data items is computed.
- Data items similarly “distanced” from one another are grouped together in a cluster.
- the cluster groups may be exclusive such that every data item belongs in only one group (exclusive clustering 302 ).
- the cluster groups may be overlapping, meaning that at least one software application may belong to several cluster groups (overlapping clustering 304 ).
- the cluster groups can be hierarchical, whereby each data item is assigned its own cluster and then clusters are merged as similarities are computed until all clusters are contained in one cluster called the root node (hierarchical clustering 306 ).
- the cluster groups may be probabilistic and each data item is assigned to a cluster group depending on an assigned probability (probability based clustering 308 ).
- these cluster analyses seek either to minimize a cost function (or optimize a certain measurement which associates a cost to each data item and cluster assignment) or to perform a number of iterations, analyzing the data items and/or clusters in each iteration to differentiate data items based on dissimilarities between the data items and/or clusters.
- a common visual feature will be selected and extracted, such as video playback controls.
- a machine learning system may be used to extract and correlate the presence of these shapes as features which represent a cluster. The system can then look for other metadata, such as listing details or feedback, and find that video is a strongly correlated with these visual features.
- these clusters can be used as new navigational categories, or as a source of related software applications when viewing one software application within a cluster.
- these clusters can be used as seeds to populate metadata when a publisher is listing a software application in a digital multimedia content service.
- visual features that are extracted may be used to distinguish quality of the software application which can be correlated with ratings of the software application (user ratings, digital multimedia content service ratings, maturity level ratings, etc.) in order to predict likely quality of the software application or influence a ranking for new software applications which have not received any user or digital multimedia content service feedback.
- the assignment may be automatically linked to the software application.
- the cluster assignment may be sent to the software developer for verification that the software application is properly classified. The software developer may then affirm classification or may request that another assignment be generated.
Abstract
The present disclosure provides a system and method for automatic clustering and recognition of software applications using metadata. The system selects and extracts visual features from software applications which are then classified, analyzed using a cluster analysis, and then used to assign the software application to a cluster group.
Description
The present disclosure a dynamical system and method for identifying visual metadata from screenshots of a software application, analyzing the identified visual metadata, and categorizing the software application based on the analysis. The software application is then presented to a user on a display in a cluster of other similar software applications.
With recent developments in mobile technology, numerous software developers are concentrating on producing software applications (typically “apps”) that perform various functions. Because of the increase in the number and variety of such software applications, finding a desired application can be challenging, especially where the categorization of a software application is inaccurate or imprecise. Thus, there is a need for an improved system and method for recognition of applications and for presenting them to a user in a coherent fashion, for example by clustering them.
The present disclosure provides a system and method for recognition of applications visual metadata and a clustering of the applications based on the recognized visual metadata.
It is a feature of the disclosed subject matter to recognize visual metadata by inputting screenshot images of an application to a machine learning system to extract visual features from those images to build clusters.
It is further a feature of the disclosed subject matter to perform both feature extraction and clustering, wherein clustering includes grouping software applications based on a commonly identified visual metadata. Accordingly, software applications are classified in a more desirable fashion.
It is a still further feature of the disclosed subject matter to provide a method for clustering applications based on visual metadata by identifying metadata as at least one visual feature of an application; assigning a classification to each application based on the at least one identified visual feature; performing a cluster analysis based on the assigned classification; and selecting a cluster assignment to the application based on the cluster analysis.
The above-described and other advantages and features of the present disclosure will be appreciated and understood by those skilled in the art from the following detailed description and drawings.
A user 508 may access the UI 506 using a variety of devices, including but not limited to a mobile phone, a tablet, a personal computer (PC), or other computing device. By connecting to the Internet Y, a user 508 is able to interact with the computer 500.
The feature selection and extraction module 502 performs several functions, illustrated in FIGS. 1 and 2 . First, it selects and extracts features from software applications (step 100). Once features are extracted, the features are assigned a classification (step 200), whereby the classification may be numerical, a set of characters, or some combination of the two. A cluster analysis is then performed on the classifications (step 300). A variety of methods for cluster analysis may be used and will be discussed in further detail. As a result of the cluster analysis 300, at least one cluster assignment is delegated to each software application (step 400). Each cluster designation places the software application in a category with other software applications that have similar extracted features.
As illustrated in FIG. 2 , prior to features selection and extraction 100, a feed of information may be required in order to perform the feature selection and extraction. This information may be obtained through screen shots provided by the software developer 10 when the developer submits his or her software application to a digital multimedia content service provider. Alternatively, the digital multimedia content service provider may run the software application in an emulated mode to obtain screen shots 20. Once the screen shots are obtained, they are stored in the database 510. The screen shots are then processed during feature selection and extraction step 100 (via the feature extraction and selection module 502).
In feature selection and extraction step 100 a variety of methods and techniques to select and extract features may be used using specific modules, such as image segmentation analysis 102, interest point-based analysis 104, object recognition 106, histogram-based analysis 108, application information analysis 110, and maturity level analysis 112.
In image segmentation analysis 102, images (screen shots) are segmented so that each segment may be parsed and examined for pixel color, pattern recognition, and other elements. Segmentation analysis 102 may be used to locate objects and boundaries in the screen shots.
In interest point-based analysis 104, the feature selection and extraction step 100 determines points in an image that are rich in information content. These points may be determined using techniques such as blob detection, edge detection, corner detection, and ridge detection. Interest point-based analysis 104 may be used to determine the presence of certain objects within the image. Furthermore, an interest point-based analysis may be utilized to understand the texture of the image.
Thus, key features are extracted from software application screen shots. These key features are then compared with entries in a database 501 and information about what objects may have created these features are retrieved. Position, orientation, and scale may also be accounted for in object recognition by using a variety of features stored in the database 501.
Histogram-based analysis 108 includes the analysis of pixels of digital images. Preferably, an image is partitioned and each partition is analyzed with respect to pixel color information. A color histogram is then produced to represent the distribution of colors within the image or partition by providing the number of pixels that have colors in each of a fixed color range. The set of fixed color ranges span the image's color space. This analysis may provide object information, such as scenery information and the like, so that software applications with similar color histograms and patterns may be grouped together.
In an alternative embodiment, where a software application does not contain maturity level information, the feature selection and extraction step 100 may utilize any of the tools to detect and tag mature content to assign a maturity rating to the software application. For example, where applications contain violent content, such as weapons and the like, image segmentation analysis 102, interest point-based analysis, object recognition 106, or histogram-based analysis 108 may pick up those graphics and mark the software application as containing mature content.
As previously mentioned, once the software application features are selected and extracted in step 100, the selected and extracted features are assigned a classification in step 200. This classification may be a numerical classification, or text-based classification, or some combination of the two. A cluster analysis step 300 is then performed on the classified features to determine patterns in the features and group the features by resemblance and the software applications are then arranged into different cluster, each cluster having some predetermined feature that is common to all the software applications within the cluster.
By way of example, FIG. 4 illustrates three cluster groups, 410, 420, and 430. Each data item, denoted i through N is compared against all other data items, such that a “distance” between data items is computed. Data items similarly “distanced” from one another are grouped together in a cluster.
Various types of clustering criteria are shown in FIG. 3 . In one embodiment, the cluster groups may be exclusive such that every data item belongs in only one group (exclusive clustering 302). In an alternative embodiment, the cluster groups may be overlapping, meaning that at least one software application may belong to several cluster groups (overlapping clustering 304). In yet another embodiment, the cluster groups can be hierarchical, whereby each data item is assigned its own cluster and then clusters are merged as similarities are computed until all clusters are contained in one cluster called the root node (hierarchical clustering 306). In another embodiment, the cluster groups may be probabilistic and each data item is assigned to a cluster group depending on an assigned probability (probability based clustering 308).
In general, these cluster analyses seek either to minimize a cost function (or optimize a certain measurement which associates a cost to each data item and cluster assignment) or to perform a number of iterations, analyzing the data items and/or clusters in each iteration to differentiate data items based on dissimilarities between the data items and/or clusters.
In a simple implementation, a common visual feature will be selected and extracted, such as video playback controls. A machine learning system may be used to extract and correlate the presence of these shapes as features which represent a cluster. The system can then look for other metadata, such as listing details or feedback, and find that video is a strongly correlated with these visual features.
Thereafter these clusters can be used as new navigational categories, or as a source of related software applications when viewing one software application within a cluster. Alternatively, these clusters can be used as seeds to populate metadata when a publisher is listing a software application in a digital multimedia content service.
In an alternative embodiment, visual features that are extracted may be used to distinguish quality of the software application which can be correlated with ratings of the software application (user ratings, digital multimedia content service ratings, maturity level ratings, etc.) in order to predict likely quality of the software application or influence a ranking for new software applications which have not received any user or digital multimedia content service feedback.
Once a cluster assignment is generated, the assignment may be automatically linked to the software application. Alternatively, the cluster assignment may be sent to the software developer for verification that the software application is properly classified. The software developer may then affirm classification or may request that another assignment be generated.
The accompanying drawings illustrate a system and method for recognition of applications visual metadata and a clustering of the applications based on the recognized visual metadata, its constituent parts, and method of use. However, other types and styles are possible, and the drawings are not intended to be limiting in that regard. For example logos, images or videos may be included along with metadata. Thus, although the description above and accompanying drawings contains much specificity, the details provided should not be construed as limiting the scope of the embodiment(s) but merely as providing illustrations of some of the presently preferred embodiment(s). The drawings and the description are not to be taken as restrictive on the scope of the embodiment(s) and are understood as broad and general teachings in accordance with the present invention. While the present embodiment(s) of the invention have been described using specific terms, such description is for present illustrative purposes only, and it is to be understood that modifications and variations to such embodiments, including but not limited to the substitutions of equivalent features, materials, or parts, and the reversal of various features thereof, may be practiced by those of ordinary skill in the art without departing from the spirit and scope of the invention.
Claims (12)
1. A method, comprising:
executing, by a computing system, an application in an emulation mode;
obtaining, by the computing system and while executing the application in the emulation mode, a plurality of screen shots;
extracting, by the computing system, at least one visual feature from one or more screen shots from the plurality of screen shots using a machine learning system;
assigning, by the computing system and based on the at least one visual feature and one or more other visual features extracted from screen shots of other applications, the application to an application cluster, wherein each application included in the application cluster is more similar to each other than to applications included in other application clusters;
determining, by the computing system and based on the at least one visual feature, whether any of the plurality of screen shots includes violent content;
responsive to determining that at least one of the plurality of screen shots includes violent content, determining, by the computing system and based on respective maturity level ratings of other applications included in the application cluster, a maturity level rating for the application; and
presenting, by the computing system and for display, information about the application and information about at least one other application included in the application cluster, the information including at least the maturity level rating.
2. The method of claim 1 , wherein extracting at least one visual feature from the one or more screen shots comprises applying one or more of: image segmentation analysis, interest point-based analysis, object recognition algorithms, or histogram-based analysis to the one or more screen shots.
3. The method of claim 1 , wherein assigning the application to the application cluster comprises:
assigning the application to a unique application cluster that only includes the application, wherein the unique application cluster is included in a plurality of unique application clusters; and
merging, based on one or more similarities between each of the plurality of unique application clusters, each of the plurality of unique application clusters into a hierarchical tree to form the application cluster.
4. The method of claim 1 , wherein the application is included in more than one application cluster of a plurality of application clusters.
5. The method of claim 1 , wherein the application is included in only one application cluster from a plurality of application clusters.
6. The method of claim 1 , further comprising:
analyzing a respective set of visual features, a respective classification, and a respective cluster assignment for each of a plurality of software applications; and
storing associations between the software applications, the respective sets of visual features and the respective cluster assignments in a database.
7. A system comprising:
a microprocessor; and
a memory that stores a database, the database storing visual metadata including visual features associated with said software application,
wherein the microprocessor is configured to:
execute an application in an emulation mode;
obtain, while executing the application in the emulation mode, a plurality of screen shots;
extract at least one visual feature from one or more screen shots from the plurality of screen shots using a machine learning system;
assign, based on the at least one visual feature and one or more other visual features extracted from screen shots of other applications, the application to an application cluster, wherein each application included in the application cluster is more similar to each other than to applications included in other application clusters;
determine, based on the at least one visual features, whether any of the plurality of screen shots includes violent content;
responsive to determining that at least one of the plurality of screen shots includes violent content, determine, based on respective maturity level ratings of other applications included in the application cluster, a maturity level rating for the application; and
present, for display, information about the software application and information about the at least one other application included in the application cluster, the information including at least the maturity level rating.
8. The system of claim 7 , wherein the microprocessor is configured to:
extract the at least one visual feature from the one or more screen shots by applying one or more of image segmentation analysis, interest point-based analysis, object recognition, or histogram-based analysis to the one or more screen shots.
9. The system of claim 7 , wherein the microprocessor is configured to:
assign the application to a unique application cluster that only includes the application, wherein the unique application cluster is included in a plurality of unique application clusters; and
merge, based on one or more similarities between each of the plurality of unique application clusters, each of the plurality of unique application clusters into a hierarchical tree to form the application cluster.
10. The system of claim 7 , wherein the application is included in more than one application cluster of a plurality of application clusters.
11. The system of claim 7 , wherein the application is included in only one application cluster from a plurality of application clusters.
12. The system of claim 7 , wherein the microprocessor is further configured to:
analyze a respective set of visual features, a respective classification, and a respective cluster assignment for each of a plurality of software applications; and
store associations between the software applications, the respective sets of visual features and the respective cluster assignments in the database.
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/084,816 US10242080B1 (en) | 2013-11-20 | 2013-11-20 | Clustering applications using visual metadata |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/084,816 US10242080B1 (en) | 2013-11-20 | 2013-11-20 | Clustering applications using visual metadata |
Publications (1)
Publication Number | Publication Date |
---|---|
US10242080B1 true US10242080B1 (en) | 2019-03-26 |
Family
ID=65811753
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US14/084,816 Active 2034-08-08 US10242080B1 (en) | 2013-11-20 | 2013-11-20 | Clustering applications using visual metadata |
Country Status (1)
Country | Link |
---|---|
US (1) | US10242080B1 (en) |
Cited By (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10643074B1 (en) * | 2018-06-08 | 2020-05-05 | Amazon Technologies, Inc. | Automated video ratings |
US10897649B1 (en) | 2018-09-26 | 2021-01-19 | Amazon Technologies, Inc. | Mature themes prediction for online content |
US11153655B1 (en) | 2018-09-26 | 2021-10-19 | Amazon Technologies, Inc. | Content appeal prediction using machine learning |
Citations (38)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20020042793A1 (en) * | 2000-08-23 | 2002-04-11 | Jun-Hyeog Choi | Method of order-ranking document clusters using entropy data and bayesian self-organizing feature maps |
US20030217052A1 (en) | 2000-08-24 | 2003-11-20 | Celebros Ltd. | Search engine method and apparatus |
US20050268338A1 (en) | 2000-07-14 | 2005-12-01 | Internet Security Systems, Inc. | Computer immune system and method for detecting unwanted code in a computer system |
US20060056707A1 (en) * | 2004-09-13 | 2006-03-16 | Nokia Corporation | Methods, devices and computer program products for capture and display of visually encoded data and an image |
US7185001B1 (en) | 2000-10-04 | 2007-02-27 | Torch Concepts | Systems and methods for document searching and organizing |
US20070112754A1 (en) | 2005-11-15 | 2007-05-17 | Honeywell International Inc. | Method and apparatus for identifying data of interest in a database |
US20070226324A1 (en) | 2006-03-23 | 2007-09-27 | International Business Machines Corporation | Apparatus and method for high-availability identification and application installation |
US20070297641A1 (en) * | 2006-06-27 | 2007-12-27 | Microsoft Corporation | Controlling content suitability by selectively obscuring |
US20080033922A1 (en) | 2006-08-04 | 2008-02-07 | Pavel Cisler | Searching a backup archive |
US20080086775A1 (en) | 2006-10-04 | 2008-04-10 | Rolf Repasi | Detecting an audio/visual threat |
US20080201466A1 (en) | 2007-02-21 | 2008-08-21 | The Go Daddy Group, Inc. | Web hosting community |
US20090279794A1 (en) * | 2008-05-12 | 2009-11-12 | Google Inc. | Automatic Discovery of Popular Landmarks |
US20100138775A1 (en) | 2008-11-28 | 2010-06-03 | Sharon Kohen | Method, device and system, for extracting dynamic content from a running computer application |
US20100205274A1 (en) | 2009-02-09 | 2010-08-12 | Sam Gharabally | Intelligent Download of Application Programs |
US20100218091A1 (en) | 2009-02-23 | 2010-08-26 | Samsung Electronics Co., Ltd. | Apparatus and method for extracting thumbnail of contents in electronic device |
US20110041078A1 (en) | 2009-07-31 | 2011-02-17 | Samsung Electronic Co., Ltd. | Method and device for creation of integrated user interface |
US20110082868A1 (en) * | 2009-10-02 | 2011-04-07 | Aravind Musuluri | System and method for block segmenting, identifying and indexing visual elements, and searching documents |
US20110123120A1 (en) * | 2008-06-03 | 2011-05-26 | Eth Zurich | Method and system for generating a pictorial reference database using geographical information |
US20110208801A1 (en) | 2010-02-19 | 2011-08-25 | Nokia Corporation | Method and apparatus for suggesting alternate actions to access service content |
US20110313843A1 (en) | 2010-06-17 | 2011-12-22 | Microsoft Corporation | Search advertisement targeting |
US20120095979A1 (en) | 2010-10-15 | 2012-04-19 | Microsoft Corporation | Providing information to users based on context |
US8200025B2 (en) | 2007-12-07 | 2012-06-12 | University Of Ottawa | Image classification and search |
US20120233163A1 (en) * | 2011-03-08 | 2012-09-13 | Google Inc. | Detecting application similarity |
US20120260232A1 (en) | 2011-04-06 | 2012-10-11 | Media Direct, Inc. | Systems and methods for a mobile application development and deployment platform |
US20120290583A1 (en) * | 2011-05-09 | 2012-11-15 | Google Inc. | Using Application Metadata To Identify Applications Of Interest |
US20130014146A1 (en) | 2011-07-06 | 2013-01-10 | Manish Bhatia | Mobile content tracking platform apparatuses and systems |
US20130014040A1 (en) | 2011-07-07 | 2013-01-10 | Qualcomm Incorporated | Application relevance determination based on social context |
US20130055211A1 (en) * | 2011-08-26 | 2013-02-28 | Apple Inc. | Client-side policy enforcement of developer api use |
US20130124449A1 (en) | 2011-07-12 | 2013-05-16 | Ebay Inc. | Recommendations in a computing advice facility |
KR20130082848A (en) | 2011-12-20 | 2013-07-22 | 주식회사 케이티 | Method and apparatus for application recommendation |
US8521679B2 (en) | 2010-12-20 | 2013-08-27 | Yahoo! Inc. | Classification recommendation based on social actions |
US20130275431A1 (en) * | 2012-04-12 | 2013-10-17 | Nainesh Rathod | Visual clustering method |
US8682819B2 (en) | 2008-06-19 | 2014-03-25 | Microsoft Corporation | Machine-based learning for automatically categorizing data on per-user basis |
US8787683B1 (en) | 2009-07-17 | 2014-07-22 | Google Inc. | Image classification |
US20140280131A1 (en) | 2013-03-13 | 2014-09-18 | Motorola Mobility Llc | Recommendations for Applications Based on Device Context |
US20150055854A1 (en) * | 2013-08-20 | 2015-02-26 | Xerox Corporation | Learning beautiful and ugly visual attributes |
US20150200815A1 (en) * | 2009-05-08 | 2015-07-16 | The Nielsen Company (Us), Llc | Systems and methods for behavioural and contextual data analytics |
US9639694B2 (en) * | 2013-06-17 | 2017-05-02 | Appthority, Inc. | Automated classification of applications for mobile devices |
-
2013
- 2013-11-20 US US14/084,816 patent/US10242080B1/en active Active
Patent Citations (43)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20050268338A1 (en) | 2000-07-14 | 2005-12-01 | Internet Security Systems, Inc. | Computer immune system and method for detecting unwanted code in a computer system |
US20020042793A1 (en) * | 2000-08-23 | 2002-04-11 | Jun-Hyeog Choi | Method of order-ranking document clusters using entropy data and bayesian self-organizing feature maps |
US20030217052A1 (en) | 2000-08-24 | 2003-11-20 | Celebros Ltd. | Search engine method and apparatus |
US7185001B1 (en) | 2000-10-04 | 2007-02-27 | Torch Concepts | Systems and methods for document searching and organizing |
US20060056707A1 (en) * | 2004-09-13 | 2006-03-16 | Nokia Corporation | Methods, devices and computer program products for capture and display of visually encoded data and an image |
US20070112754A1 (en) | 2005-11-15 | 2007-05-17 | Honeywell International Inc. | Method and apparatus for identifying data of interest in a database |
US20070226324A1 (en) | 2006-03-23 | 2007-09-27 | International Business Machines Corporation | Apparatus and method for high-availability identification and application installation |
US20070297641A1 (en) * | 2006-06-27 | 2007-12-27 | Microsoft Corporation | Controlling content suitability by selectively obscuring |
US20080033922A1 (en) | 2006-08-04 | 2008-02-07 | Pavel Cisler | Searching a backup archive |
US20080086775A1 (en) | 2006-10-04 | 2008-04-10 | Rolf Repasi | Detecting an audio/visual threat |
US20080201466A1 (en) | 2007-02-21 | 2008-08-21 | The Go Daddy Group, Inc. | Web hosting community |
US8200025B2 (en) | 2007-12-07 | 2012-06-12 | University Of Ottawa | Image classification and search |
US20090279794A1 (en) * | 2008-05-12 | 2009-11-12 | Google Inc. | Automatic Discovery of Popular Landmarks |
US20110123120A1 (en) * | 2008-06-03 | 2011-05-26 | Eth Zurich | Method and system for generating a pictorial reference database using geographical information |
US8682819B2 (en) | 2008-06-19 | 2014-03-25 | Microsoft Corporation | Machine-based learning for automatically categorizing data on per-user basis |
US20100138775A1 (en) | 2008-11-28 | 2010-06-03 | Sharon Kohen | Method, device and system, for extracting dynamic content from a running computer application |
EP2224336A1 (en) | 2009-02-09 | 2010-09-01 | Apple Inc. | Intelligent download of application programs |
US20100205274A1 (en) | 2009-02-09 | 2010-08-12 | Sam Gharabally | Intelligent Download of Application Programs |
KR20100095777A (en) | 2009-02-23 | 2010-09-01 | 삼성전자주식회사 | Apparatus and method for extracting thumbnail of contents in electronic device |
US20100218091A1 (en) | 2009-02-23 | 2010-08-26 | Samsung Electronics Co., Ltd. | Apparatus and method for extracting thumbnail of contents in electronic device |
US20150200815A1 (en) * | 2009-05-08 | 2015-07-16 | The Nielsen Company (Us), Llc | Systems and methods for behavioural and contextual data analytics |
US8787683B1 (en) | 2009-07-17 | 2014-07-22 | Google Inc. | Image classification |
US20110041078A1 (en) | 2009-07-31 | 2011-02-17 | Samsung Electronic Co., Ltd. | Method and device for creation of integrated user interface |
US20110082868A1 (en) * | 2009-10-02 | 2011-04-07 | Aravind Musuluri | System and method for block segmenting, identifying and indexing visual elements, and searching documents |
US20110208801A1 (en) | 2010-02-19 | 2011-08-25 | Nokia Corporation | Method and apparatus for suggesting alternate actions to access service content |
US20110313843A1 (en) | 2010-06-17 | 2011-12-22 | Microsoft Corporation | Search advertisement targeting |
US20120095979A1 (en) | 2010-10-15 | 2012-04-19 | Microsoft Corporation | Providing information to users based on context |
US8521679B2 (en) | 2010-12-20 | 2013-08-27 | Yahoo! Inc. | Classification recommendation based on social actions |
US20120233165A1 (en) | 2011-03-08 | 2012-09-13 | Google Inc. | Detecting application similarity |
US20120233163A1 (en) * | 2011-03-08 | 2012-09-13 | Google Inc. | Detecting application similarity |
KR20140018329A (en) | 2011-04-06 | 2014-02-12 | 미디어 다이렉트, 인크. | Systems and methods for a mobile application development and deployment platform |
US20120260232A1 (en) | 2011-04-06 | 2012-10-11 | Media Direct, Inc. | Systems and methods for a mobile application development and deployment platform |
US20120290583A1 (en) * | 2011-05-09 | 2012-11-15 | Google Inc. | Using Application Metadata To Identify Applications Of Interest |
US20130014146A1 (en) | 2011-07-06 | 2013-01-10 | Manish Bhatia | Mobile content tracking platform apparatuses and systems |
US20130014040A1 (en) | 2011-07-07 | 2013-01-10 | Qualcomm Incorporated | Application relevance determination based on social context |
KR20140045549A (en) | 2011-07-07 | 2014-04-16 | 퀄컴 인코포레이티드 | Application relevance determination based on social context |
US20130124449A1 (en) | 2011-07-12 | 2013-05-16 | Ebay Inc. | Recommendations in a computing advice facility |
US20130055211A1 (en) * | 2011-08-26 | 2013-02-28 | Apple Inc. | Client-side policy enforcement of developer api use |
KR20130082848A (en) | 2011-12-20 | 2013-07-22 | 주식회사 케이티 | Method and apparatus for application recommendation |
US20130275431A1 (en) * | 2012-04-12 | 2013-10-17 | Nainesh Rathod | Visual clustering method |
US20140280131A1 (en) | 2013-03-13 | 2014-09-18 | Motorola Mobility Llc | Recommendations for Applications Based on Device Context |
US9639694B2 (en) * | 2013-06-17 | 2017-05-02 | Appthority, Inc. | Automated classification of applications for mobile devices |
US20150055854A1 (en) * | 2013-08-20 | 2015-02-26 | Xerox Corporation | Learning beautiful and ugly visual attributes |
Non-Patent Citations (7)
Title |
---|
"Amazon.com: What are Statistically Improbable Phrases?" Accessed from http://www.amazon.com/gp/search-inside/sipshelp.html on Mar. 8. 2011, 1 pp. |
Almohammad et al.: Face and Gait Fusion Methods: A Survey, International Journal of Computer Science and Telecommunications, vol. 4, Issue 4, Apr. 2013, pp. 19-28. |
Collin McMillan et al.; "Categorizing Software Applications for Maintenance", in Proc. of 27th IEEE International Conference on Software Maintenance (ICSM '11), Williamsburg, VA, Sep. 25-30, 2011. |
Gallestey, "Cluster Analysis," Encyclopaedia Britannica, last modified Nov. 23, 2017, accessed from https://www.britannica.com/topic/cluster-analysis on Mar. 15, 2017, 3 pp. |
Prosecution History from U.S. Appl. No. 13/043,214, dated Jan. 19, 2012 through Apr. 7, 2017, 184 pp. |
Prosecution History from U.S. Appl. No. 13/250,592, dated Dec. 2, 2011 through Feb. 22, 2017 206 pp. |
Wikipedia, the free encyclopedia, "Statistically Improbable Phrases, from Wikipedia, the free encyclopedia," Last modified on Jan. 26, 2011 Retrieved from http://en.wikipedia.org/wiki/Statistically_Improbable_Phrases 2 pp. |
Cited By (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10643074B1 (en) * | 2018-06-08 | 2020-05-05 | Amazon Technologies, Inc. | Automated video ratings |
US10897649B1 (en) | 2018-09-26 | 2021-01-19 | Amazon Technologies, Inc. | Mature themes prediction for online content |
US11153655B1 (en) | 2018-09-26 | 2021-10-19 | Amazon Technologies, Inc. | Content appeal prediction using machine learning |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11556743B2 (en) | Learning highlights using event detection | |
US10642892B2 (en) | Video search method and apparatus | |
US10921957B1 (en) | User interface for context labeling of multimedia items | |
US11423076B2 (en) | Image similarity-based group browsing | |
US10140575B2 (en) | Sports formation retrieval | |
CN110245259B (en) | Video labeling method and device based on knowledge graph and computer readable medium | |
US9886669B2 (en) | Interactive visualization of machine-learning performance | |
Pritch et al. | Clustered synopsis of surveillance video | |
US9330341B2 (en) | Image index generation based on similarities of image features | |
JP5134628B2 (en) | Media material analysis of consecutive articles | |
US20130101209A1 (en) | Method and system for extraction and association of object of interest in video | |
US10963700B2 (en) | Character recognition | |
US20150199567A1 (en) | Document classification assisting apparatus, method and program | |
CN106537387B (en) | Retrieval/storage image associated with event | |
CN113963303A (en) | Image processing method, video recognition method, device, equipment and storage medium | |
US10872114B2 (en) | Image processing device, image retrieval interface display device, and method for displaying image retrieval interface | |
US10242080B1 (en) | Clustering applications using visual metadata | |
KR100876214B1 (en) | Apparatus and method for context aware advertising and computer readable medium processing the method | |
JP5226651B2 (en) | Similar image retrieval device, similar image retrieval method, and similar image retrieval program | |
JP2019109924A (en) | Information processing system, information processing method, and program | |
CN113657087A (en) | Information matching method and device | |
Feng et al. | Multiple style exploration for story unit segmentation of broadcast news video | |
CN111198957A (en) | Push method and device, electronic equipment and storage medium | |
JP4995770B2 (en) | Image dictionary generation device, image dictionary generation method, and image dictionary generation program | |
JP5292247B2 (en) | Content tag collection method, content tag collection program, content tag collection system, and content search system |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 4TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1551); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 4 |