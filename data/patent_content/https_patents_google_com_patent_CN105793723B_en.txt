CN105793723B - It is self-positioning using the microphone of moving sound - Google Patents
It is self-positioning using the microphone of moving sound Download PDFInfo
- Publication number
- CN105793723B CN105793723B CN201480065555.2A CN201480065555A CN105793723B CN 105793723 B CN105793723 B CN 105793723B CN 201480065555 A CN201480065555 A CN 201480065555A CN 105793723 B CN105793723 B CN 105793723B
- Authority
- CN
- China
- Prior art keywords
- sensor
- acoustic events
- time
- microphone
- group
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
Classifications
-
- G—PHYSICS
- G01—MEASURING; TESTING
- G01S—RADIO DIRECTION-FINDING; RADIO NAVIGATION; DETERMINING DISTANCE OR VELOCITY BY USE OF RADIO WAVES; LOCATING OR PRESENCE-DETECTING BY USE OF THE REFLECTION OR RERADIATION OF RADIO WAVES; ANALOGOUS ARRANGEMENTS USING OTHER WAVES
- G01S5/00—Position-fixing by co-ordinating two or more direction or position line determinations; Position-fixing by co-ordinating two or more distance determinations
- G01S5/18—Position-fixing by co-ordinating two or more direction or position line determinations; Position-fixing by co-ordinating two or more distance determinations using ultrasonic, sonic, or infrasonic waves
-
- G—PHYSICS
- G01—MEASURING; TESTING
- G01S—RADIO DIRECTION-FINDING; RADIO NAVIGATION; DETERMINING DISTANCE OR VELOCITY BY USE OF RADIO WAVES; LOCATING OR PRESENCE-DETECTING BY USE OF THE REFLECTION OR RERADIATION OF RADIO WAVES; ANALOGOUS ARRANGEMENTS USING OTHER WAVES
- G01S5/00—Position-fixing by co-ordinating two or more direction or position line determinations; Position-fixing by co-ordinating two or more distance determinations
- G01S5/18—Position-fixing by co-ordinating two or more direction or position line determinations; Position-fixing by co-ordinating two or more distance determinations using ultrasonic, sonic, or infrasonic waves
- G01S5/30—Determining absolute distances from a plurality of spaced points of known location
Abstract
Flight time (TOF) measured value for providing the acoustic events for using multiple spatial distributions at sensor carrys out the method and system of calibrating distributed sensor (such as microphone) array.The calibration includes positioning and the gain balance of sensor.The precise measurements of TOF are obtained from the acoustic events of spatial distribution using the controlled signal emitted by known spacings by moving sound.The portable user that audio can be played be used to generate multiple acoustic events (such as click sound), equipment of the position based on just spatially being moved by user while generating acoustic events by known interval and in different and arbitrary position.It is designed specifically for providing the robustness for noise and reverberation by the calibration signal of source emission.
Description
Background technology
In order to make (for example, installing on the portable user of such as cellular phone) microphone can determine its from
Body position (such as relative to another sound source and relative to one or more sound sources), it is necessary to which there are acoustic events
Group.In the self-positioning method of existing microphone, acoustic events are independent of equipment and create, for example, being clapped hands by user.
Such method introduces four unknown quantitys (three space coordinates of event and time) to each acoustic events.Due to calculating this
The problem of a little unknown quantitys is nonlinearity, it is difficult to handle all these additional unknown quantitys.Specifically, acoustic events are not
County magistrate's part time-lag convergence of existing self-positioning algorithm.
Invention content
The content of present invention describes the selection of concept in simplified form, in order to provide the base of some aspects to the disclosure
This understanding.The content of present invention is not the exhaustive overview to the disclosure, and is not intended to the key or important element of the mark disclosure,
It is not intended to description the scope of the present disclosure.The content of present invention only presents only some concepts of the disclosure, using as presented below
Specific implementation mode preamble.
Present disclose relates generally to the method and systems for signal processing.More specifically, being related to making in terms of the disclosure
With the measured value of the arrival time of the acoustic events of spatial distribution come calibrating distributed sensor.
One embodiment of the disclosure is related to computer implemented method, and the method includes measuring at sensor group
The arrival time of acoustic events group, wherein generating the acoustic events by being spaced known to the sensor；And it is based on
The arrival time of the record of the acoustic events at the sensor estimates the internal latency of the sensor.
In another embodiment, the method further includes based on the acoustic events at the sensor
The arrival time of record and the event generated time of the acoustic events reach the sensor to calculate the acoustic events
Flight time；And the flight time of the sensor is reached to determine the position of the sensor using the acoustic events
It sets.
In another embodiment, the method further includes selecting the first generated acoustic events as based on
Calculate the fiducial time that the acoustic events reach the flight time of the sensor.
In another embodiment, the method further includes using the position of the sensor of calculating and described
The arrival time of the record of the event at sensor to determine relative gain to each in the sensor.
Another embodiment of the disclosure is related to a kind of method comprising：Note based on the acoustic events at sensor
The arrival time of record and the event generated time of the acoustic events reach the sensor group to calculate the acoustic events group
Flight time, wherein generating the acoustic events by time interval known to the sensor；Use the acoustic events
The flight time of the sensor is reached to calculate the position of the sensor；And use the sensor calculated
The arrival time of the record of position and the event at the sensor to determine phase to each in the sensor
To gain.
In another embodiment, the method further includes measuring the acoustic events at the sensor group
The arrival time of group；And the biography is estimated based on the arrival time of the record of the acoustic events at the sensor
The internal latency of sensor.
In another embodiment, the method further includes selecting the first generated acoustic events as based on
Calculate the fiducial time that the acoustic events reach the flight time of the sensor.
In one or more other embodiments, method described herein and system optionally include following supplementary features
One or more of：It is iteratively performed and calculates the flight time that the acoustic events reach the sensor, to refine
The flight time；Each in the acoustic events is the calibration signal as Gaussian modulation sinusoidal impulse；The acoustics
Each in event is the calibration signal of time domain extension pulse；Each in the acoustic events is as unit pulse
Calibration signal；The sensor group is microphone group；The event group is by the equipment with loud speaker from relative to the sensing
Multiple and different positions of device generate；One or more of described sensor is the microphone on mobile phone；And/or
Person determines relative gain based on the estimation of the signal-to-noise ratio (SNR) at the sensor to each in the sensor.
The further range that the disclosure is applicable in will become apparent from following specific implementation modes.However, should manage
Solution, due to falling into the various variants and modifications in spirit and scope of the present disclosure for a person skilled in the art from specific
Embodiment will become obvious, so while indicating preferred embodiment, but only be to provide this in an illustrative manner specifically
Embodiment and specific example.
Description of the drawings
These and other targets, the features and characteristics of the disclosure, to below in conjunction with appended claims and attached drawing
Specific implementation mode research in, will become obvious for a person skilled in the art, wherein specific embodiment party
Formula, claim and attached drawing form the part of this specification.In the accompanying drawings：
Fig. 1 is illustrate according to one or more embodiments as described herein in signaling environment sensor self-positioning
Sample application schematic diagram；
Fig. 2 is to illustrate to be sent out by known spacings according to the example moving sound of one or more embodiments as described herein
The exemplary schematic diagram of calibration signal；
Fig. 3 is to illustrate to be used for using flight time measurement value come school according to one or more embodiments as described herein
The flow chart of the exemplary method of quasi-distributed sensor array；
Fig. 4 is the multiple units illustrated according to the extraction of one or more embodiments as described herein at sensor group
The graphical representation of the example evaluated error result of the flight time measurement value of pulse matching signal；
Fig. 5 is the multiple Gausses illustrated according to the extraction of one or more embodiments as described herein at sensor group
Modulate the graphical representation of the example evaluated error result of the flight time measurement value of sinusoidal impulse (GMSP) calibration signal；
Fig. 6 is the multiple time domains illustrated according to the extraction of one or more embodiments as described herein at sensor group
Extend the graphical representation of the example evaluated error result of the flight time measurement value of pulse (TSP) calibration signal；
Fig. 7 is to illustrate according to one or more embodiments as described herein for the flight time measurement using estimation
Value determines the graphical representation of the example results of the relative gain of sensor group；
Fig. 8 is to illustrate according to one or more embodiments as described herein for based on multiple schools at sensor group
The measurements of arrival time value of calibration signal determines the graphical representation of the example results of the position of sensor group；
Fig. 9 is to illustrate according to one or more embodiments as described herein for based on multiple schools at sensor group
The measurements of arrival time value of calibration signal determines the example results of the position of the particular type of sensor group in specific environment
Graphical representation；
Figure 10 is to illustrate to be surveyed according to the arrival time that is arranged to use of one or more embodiments as described herein
Magnitude carrys out the block diagram of the Example Computing Device of calibrating distributed sensor array.
For the sake of headings provided herein is merely for convenience, and do not have to disclosure range claimed or meaning
Inevitable influence.
In attached drawing, for ease of understanding with for the sake of convenience, identical drawing reference numeral and any abbreviation are identified with phase
The element of same or similar structure or function or behavior.Attached drawing will be described in detail in the following detailed description.
Specific implementation mode
It summarizes
Various examples and embodiment will now be described.Following description provides these exemplary descriptions for comprehensive understanding simultaneously
And facilitate the detail of these exemplary descriptions.However, those skilled in the relevant art it is understood that one as described herein or
Multiple embodiments can be implemented in the case of these no many details.Equally, those skilled in the relevant art can also manage
Solution, one or more other embodiments of the present disclosure can include many other obvious characteristics not being described in detail herein.In addition, hereafter
Some well known structure or functions may not be shown or described in detail, so that avoiding unnecessarily obscuring associated description.
Embodiment of the disclosure is related to for using at sensor (for example, audio input device of such as microphone)
Flight time (TOF) measured value of the acoustic events of multiple spatial distributions carrys out the method for calibrating distributed sensor array and is
System.According to one or more embodiments, the calibration may include positioning and the gain balance of sensor.The sensor of generation
Positioning and gain balance information can be used for such as near field beam forming, and the near field beam forming allows in different talkers
Between selected and reduced the acoustic noise of environment.The sample application of method described herein and system includes from group (ad-
Hoc) conference call, group's Video chat etc..
The accurate estimation of TOF is important element for the successful calibration of distributed sensor array.Therefore, the disclosure carries
A kind of method is supplied, the method uses the acoustics thing of the controlled signal that is sent out by known spacings by moving sound from spatial distribution
Practice and accurate measurement are carried out to TOF in part.As will be described in further detail herein, the signal can be designed specifically for providing
To the robustness of noise and reverberation.In addition, it is the accurate of 1-3cm that the disclosure, which will demonstrate that measured TOF can be used for precision,
True sensor positioning, and description is also subjected to the new method of gain balance based on measured TOF.Using described herein
The example of method will illustrate, accurate sensor positioning and gain are realized there are noise and reverberation
It is balanced.
One or more embodiment as described herein can utilize the moving sound that calibration signal is sent out by known spacings.Example
Such as, can play the portable user (such as mobile phone, smart mobile phone etc.) of audio can be used for by known time
It is spaced (such as every 0.5 second, every 1 second etc.) and generates multiple acoustic events (such as click sound in different and arbitrary position
Sound), the position is based on just spatially (for example, by user or operator of equipment) movement while generating acoustic events
Equipment.Therefore, the time that acoustic events generate is known and is spatially different.It will be described in further detail Ru following
, the TOF of these calibration signals sent out at microphone group and the signal observed at these microphones, in addition to
It is used to carry out other than microphone positioning, may be utilized for estimating the gain inequality between microphone.
Fig. 1 illustrates according to one or more embodiments as described herein in signaling environment sensor it is self-positioning
Sample application.Multiple signal sources 105 (such as talker, loud speaker etc.) can be located at multiple sensors 120 (such as microphone or its
His audio input device) between.
Microphone array is easy to use extensive voice and the algorithm of audio frequency process.In order to make these many algorithms correctly grasp
Make, to microphone array, there are two requirements：(i) relative position of microphone must be known；(ii) microphone must be carried out
Calibration, so that the deviation of its gain having the same and reduction and ideal (such as flat) transmission function.These can pass through
Microphone is selected with caution and makes the known priori defined by microphone arrangement of relative distance to realize.However, such
Method has the shortcomings that several：Fixed array needs special hardware really, and microphone characteristics can change over time, and depend on
It may also change in the position of the structure of array, microphone.Therefore, it will be useful to automatically configure scheme.Such automatic example
Journey can also be easy to use more flexible group microphone array certainly, and such as mobile phone, tablet electricity is deployed in the microphone array
The equipment containing microphone of brain or laptop computer.
Present disclose provides use mobile controlled sound (such as sound) source to solve microphone positioning and calibrate the two to ask
The method of topic.As will be described in further detail below, the method forms complete microphone arrays to configure system.
Microphone array can be used for capturing voice and audio signal in unfavorable acoustic enviroment.It is originated to focus
Inhibit the signal from every other position simultaneously relative to the signal of the specific position of microphone, can handle and combines Mike
Wind number.Such technology leads to the noise reduced compared with untreated single microphone is observed and reverberation.
The conventional method of microphone array column processing is beam forming.Despite the presence of several existing beam forming techniques, it is
Making these technology correct operations, usually there are two custom requirements：(i) relative position of microphone must be known；(ii) necessary
Microphone is calibrated.A kind of direct scheme is the distance between manual measurement microphone and selects and calibrate Mike with caution
Wind.However, such method may be infeasible in the case where being for example related to from group microphone array.In such scene,
Automatic Routine can be preferred.
Although depending on the measurement of TOF for microphone and some existing methods of auditory localization, or equally, depend on
From the measurement of the arrival time (TOA) of the acoustic events of spatial distribution at sensor, but other replacements are also explored
Property method, these methods are relevant including such as reaching time-difference (TDOA), signal energy and diffusion noise field.Also show that gain
Calibration is important several beamforming algorithms, and some algorithms for automatic gain calibration have been proposed.
Despite the presence of the localization method based on TOF, however it remains relatively small number of how to obtain accurate TOF in practice
The discussion of measured value, and the error in such measurement is usually modeled as additional measurement noise.However, as below will be more detailed
Description, disclosed method and system are designed to considered below accurate to obtain including other business by taking into account
TOF measured values.First, need correctly to identify all microphones (such as from the loud speaker of such as portable user
What sound source generated) specific acoustic events sign in (RTOA).According to embodiment as described herein, RTOA can be considered as
Signal reaches the temporal summation of sensor and the equipment internal latency caused by for example buffering and/or handling.Second, it needs
Identify the onset time (such as acoustic source starts to transmit the time of sound) of acoustic events.Third needs to identify each microphone
Internal latency (for example, from sound reach microphone time it is received by the user equipment of installation microphone to the sound when
The time recorded).As will be described in more detail, for given microphone, from the RTOA identified for microphone
The onset time of the internal latency and acoustic events that subtract microphone gives the TOF for microphone.If should be noted that
Internal latency associated with acoustic events is constant, can not take into account such delay among above-mentioned calculating.
The existing method proposition of microphone positioning is identified using chirp (chirp) or maximal-length sequence (MLS)
Acoustic events.In such method, assuming that each microphone is associated with the acoustic events occurred in its vicinity and simultaneously
In the case of manual measurement internal latency, to estimate onset time.
As long as following discloses illustrate that can obtain accurate TOF measured values realizes distributing audio acquisition system
Calibration completely.According at least one embodiment, portable user (such as mobile phone, smart mobile phone etc.) can be used for
Transmitting calibration signal can obtain TOF measured values from the calibration signal.Calibration signal can be sent by known interval, it should
Known interval can determine source onset time.Fig. 2 is illustrated according to one or more embodiments as described herein in this way
Moving sound 250 press known spacings transmitting calibration signal 215 example.Sound source 250 may include that output equipment (such as is raised one's voice
Device) 255, which is configured as just being moved relative to multiple sensors 220 (such as microphone or other sounds
Frequency input equipment) different location while generate and output calibration signal 215.It should be appreciated that in addition to example side shown in Fig. 2
Other than formula or replace way of example shown in Fig. 2, it can also any one of in various ways, and/or with relative to biography
The sound source 250 for generating calibration signal 215 is moved in any one of direction of sensor 220.
As will be described in more detail, algorithm is derived to estimate the internal latency of microphone.Also show, it is such
Controlled source is convenient for the design for the calibration signal for having robustness to noise and reverberation.The TOF of measurement can be used for positioning microphone,
And it can further be used to estimate that the relative gain between microphone is poor in conjunction with the calibration signal observed.Therefore, originally
Method described in text provides the complete calibration of distributed microphone array.
Fig. 3 is illustrated according to one or more embodiments as described herein using flight time measurement value come calibration distribution
The instantiation procedure of formula sensor array.At block 305, can measure at multiple sensors (such as from such as portable user
What the sound source of the loud speaker of equipment generated) RTOA of specific sound events, and the RTOA measured is used as acoustic events and reaches to pass
The initial TOF measured values of sensor.At block 310, the initial TOF measured values determined at block 305 can be used to be updated
Acoustic events reach sensor TOF measured values.
At block 315, it may be determined that for each sensor, initial TOF measured values from block 305 at block 310
Calculate newer TOF measured values between variation it is whether sufficiently small (for example, for source positioning purpose, initial TOF measured values
Whether the variation between newer TOF measured values is sufficiently small so that newer TOF measured values can be considered to be accurately
).The initial TOF measured values of each sensor (such as from block 305) and newer TOF are surveyed if determined at block 315
Variation between magnitude (such as from block 310) is all sufficiently small, then for the newer TOF measured values of sensor at block 325
The position of sensor and source can be used to calculate.On the other hand, if determined at block 315 initial for each sensor
Deficient change between TOF measured values (such as from block 305) and newer TOF measured values (such as from block 310) is enough small, then
It can be determined at block 320：Whether have reached the predetermined limit of the iterations of execution.
If being determined at block 320 and having reached iteration limit, process can return to block 310, can be used at this
At block 305 determine initial TOF measured values come obtain acoustic events reach sensor further newer (such as perfect)
TOF measured values.However, having reached iteration limit if determined at block 320 on the contrary, process can move to block 325, at this
Place can be used to calculate the position of sensor and source as described previously for the newer TOF measured values of sensor.
At block 330, the calibration signal that can be observed using the sensing station calculated at block 325 and at sensor is come
Determine that the relative gain between sensor is poor.
Each block of composition instantiation procedure 300 will be described in further detail in following paragraph.
Problem formulation
Consider, such as three dimensions, wherein from different and unknown position sj=[sX, j sY, j sZ, j]TJ calibration letter
Number sj(n) (such as acoustic events) are in unknown position ri=[rX, i rY, i rZ, i]TPlace is obtained by I microphones.From source j to microphone
The signal of i can be designated as：
xij(n)=Gi(hij(n)*sj(n)+vij(n)) (1)
Wherein hij(n) it is that ping responds (AIR) and vij(n) the * expression convolution for additional measurement noise.Each wheat
Gram wind has associated unknown gain Gi。
It according at least one embodiment as described herein, provides a method, to from the signal x observedij(n) smart
The TOF for each calibration signal and each microphone really is extracted, the relative position r of microphone is calculated using the TOFi,
And use the TOF and the signal x observedij(n) estimate microphone gain Gi。
RTOA measured values
It is critically important that accurate STOA measured values, which are obtained, for many microphone location algorithms.It can be from the letter of observation
Number xij(n) stop completely to obtain STOA measured values.In microphone riThe acoustic events s at placejThe RTOA of measurement can be true
It is set to：
tij=c-1||ri-sj||+τj+δi+∈ij (2)
Wherein c is velocity of sound, | | | | indicate Euclidean norms, ∈ijFor measurement noise, δiFor the inside of the i-th microphone
Delay, and τjIndicate the onset time of jth acoustic events.In addition, c-1||ri-sj||+τjFor STOA.As it is used herein,
" internal latency " was referred to from the time of sound (such as acoustic events) arrival audio capturing equipment (such as microphone) to the sound
The time recorded when received by capture device.Accurate positioning depends on TOFc-1||ri-sj| |, and therefore cope with source
Onset time and internal latency compensate, and measurement error should be maintained to minimum.As will be further described below, originally
Disclosed one or more embodiment presents Robust Method used for positioning, this method by using from moving source by
Control signal realizes these targets.
Pumping signal
It, can be by the portable user that can perform audio playback according at least one embodiment as described herein
(such as mobile phone, smart mobile phone etc.) generates acoustic events, which can be considered as that " audio-source is set
It is standby ".It can be assumed that have mounted on the microphone being related in the other users equipment of voice communication session (such as audio conferencing) and arrive
The straight line view of audio source device.Audio source device can be used to play (such as generation, generation etc.) signal τj, which can
To be identical play signal, each of which is played with unique onset time.The total output signal of audio source device
Can be individual signals sj(n) summation, i.e. sj(n)=∑jsj(n), wherein the summation covers the pumping signals of all broadcasts.
At least in this example, it can be assumed that with TpThe fixed cycle of second (s) detaches signal s in timej(n).In this case,
sj(n)=s0(n-jTp).Such set time detaches so that total output signal s (n) is during calibration signal generating process
Periodically, the total output signal s (n) indicates signal sj(n) summation.
It should be noted, however, that above-mentioned hypothesis regular time separation is not the necessary item of embodiment as described herein
Part.On the contrary, according to one or more embodiments, in the calibration signal s of transmittingj(n) time interval between can be not fixed
, and/or the signal of transmitting may not necessarily be identical.However according to any such embodiment, the signal of the transmitting should
It is known.
As described above, while broadcasting pumping signal by audio source device, which can be (for example, by the behaviour of equipment
Author) it is moved in the way of undulatory motion, and can just be used at the applicable microphone of each of communication session
The generated audio of capture.If pumping signal sj(n) duration of each in is relative to Mobile audio frequency source device
Shorter for speed, then each signal can be considered as with onset time τj=τ0+jTPDifferent acoustic events sj(n)。
By by the τ in formula above (2)jReplace with τ0+jTP, realize can be by subtracting known jT from the RTOA observedP
Carry out calibration source onset time.Further, the onset time of the first acoustic events is set to timeorigin τ0=0, then it obtains
Following formula：
tij=c-1||ri+sj||+δi+vij (3)
It should be noted that application and any internal latency at transmission device (such as audio source device) of above-mentioned logic without
It closes.
All controlled signals as described above have several characteristics for the precision for improving microphone and source positioning.For example, making
Unknown sound source onset time is eliminated with such signal, allows to generate a large amount of acoustic events in a short time, and can
Select pumping signal sj(n) in order to which accurate RTOA is measured.
According at least one embodiment, can based on measure to noise and reverberation should the standard with robustness come select can
To be used for sj(n) signal, and the signal (for example, compared to speed of sound source) should be short duration.Example
Such as, three kinds of candidate signals can be considered as possible situation below：(i) unit pulse；(ii) time domain extension pulse (TSP), one
It is used to measure AIR in a little existing methods and the desired feature of AIR length can be significantly shorter than with pulse；And
(iii) Gaussian modulation sinusoidal impulse (GMSP) is understood by the person skilled in the art as according to the measurement side usually utilized
Method has the optimum balance between time domain and frequency localization.One exemplary advantages of the localization frequency of GMSP are that pulse can be with
It concentrates on that microphone properties can be assumed to be to advantageous spectrum area.According at least one embodiment, pumping signal sj(n) it can be selected
For pulse signal so that RTOA can be measured based on its peak value.
Matched filter h can be usedMf, j(n) received signal is post-processed, which is pumping signal
Time reversal version hMf, j(n)=sj(- n), and peak picking algorithm can be used to extract RTOAtij.For example, according at least
One embodiment, peak picking algorithm may include in TPNon-overlapping frame in processing input signal xij(n) and can will have
There is the peak value of each frame of highest energy to be selected as candidate RTOA.Then it can select that there is highest energy from the candidate identified
J peak values.
In the case of TSP, matched filter, which is equivalent to the inverse filter of sequence and its, leads to and (leaves AIR's) arteries and veins
Punching.For GMSP and unit pulse, which leads to the peak value at the maximal correlation between two signals.In general, matching
Filter can also effectively inhibit incoherent additional noise；The amount of noise suppressed with sample frequency and filter length increasing
Add and increases.Therefore, the filter does not interfere with unit pulse.
Internal latency is estimated
The RTOA that manner described above obtains can be considered as the accurate estimation of TOF, the accurate estimation of the TOF depending on
The associated internal latency of each equipment.As mentioned above it solves by using controlled audio-source and works with unknown source
Time correlation join the problem of, so only need estimate equipment internal latency (can be optionally by the first onset time of generation
Zero).This has drawn the simplification algorithm being discussed in greater detail as follows.
In order to without loss of generality, it will be assumed that c=1 and RTOA is correctly extracted and (depended on internal latency) thus
∈ij=0.The both sides of formula (3) are squared, the equation when formula takes i=1 is subtracted, then subtract the equation when formula takes j=1,
Obtain following formula：
Wherein i=2 ..., I, j=2 ..., J.Further formula (4) can be expressed as：
WhereinIt is microphone relative to r1Location matrix (I -1) x3,It is acoustic events relative to s1Location matrix
(J -1) x3,Vec { A (δ) }=W δ, δ=[δ1 δ2...δI]T, and W is
By (tij-ti1) and (t1j-t11) item composition matrix.It should be noted that vec { X } is defined matrix column being stacked into column vector
Operator.
From formula (5) above it can be seen that matrixOrder be up to 3.Therefore, it is possible to use two-stage iterative algorithm comes
Estimate internal latency δ, thusOrder be 3.According at least one embodiment, can make in first order iteration
With δ, δnCurrent estimation.It keeps this estimation to immobilize, can be determined according to following optimization problemEstimation.
Meet rank (6)
WhereinForBest (according to Frobenius norms) order 3 approach, and
Thus it isBest approach.Such as Eckhart-Young-Mirsky low-ranks approximation theorem can be used to obtain formula (6)
Solution.Consider for exampleSingular value decomposition (SVD)It can be written as：
Wherein Σ1Containing the U there are three maximum singular value1And V1For corresponding left singular vector and right singular vector.It can be with
Obtain according to the best order 3 of Frobenius norms approach for：
In second of iteration, the estimation of internal latency can be updated to：
WhereinAnd W+For the pseudoinverse of W.It is introduced to force to make solution that there is rational length of delay
Additional bound termIt accelerates initial convergence speed.However, according to some criterion for allowing algorithm Complete Convergence,
λ should be set as zero when solution has become reasonable.According at least one embodiment, this can pass through monitoringAnd λ=0 is set when iterating to next variation less than threshold value for one to complete.It should be noted that
The exact value of the threshold value only influences convergence rate, and can be by noticing that Frobenius norms are selected with first power
The reasonable value of the threshold value.Therefore, can set a threshold to compared to the flight time square smaller value.For example, according to
According at least one embodiment, threshold value can be selected as 0.01ms2。
Similarly, it can be monitored when iterating to next variation less than threshold value for one
And algorithm can be stopped.Can again by the threshold value be set as compared to the flight time square smaller value.For example, can be by threshold
Value is set to sufficiently small so that its value can not influence the precision of algorithm output.According at least one implementation as described herein
Example, the threshold value can also be selected as 0.01ms2。
According at least one embodiment, this algorithm can restrain λ=0 according to Frobenius norms.It should note
It anticipates and arrives, be different from some existing methods, the algorithm above does not include any step for needing nonlinear optimization.Therefore, this paper institutes
Other existing methods of the convergence ratio for the Double Step algorithm stated more improve.
Microphone positions
As described above, giving the accurate estimation of the internal latency of microphone, the correction matrix of relevant TOAIt can be by
Position for estimating source and microphone.It is possible, firstly, to willBe converted to squared-distance matrixWherein c=343m/
S, and wherein formula (5) is writeSVD is carried out to D and obtains D=U Σ VT, and due toIt is the matrix of order 3, class
It is similar to formula above (7), it is thus only necessary to consider three maximum singular values in Σ.Residual value in Σ should be zero or near zero.Cause
This, is given below：
Wherein C is 3x3 invertible matrix (to be estimated).Rotation or translation of the minimal solution of positioning for source-microphone arrangement
It is constant.Therefore, can be origin r by the coordinates restriction of the first microphone1=[0 0 0]T, and about by the coordinate in the first source
Beam is in x-axis：s1=[sx,1 0 0]T.Then can be come using non-linear least square (LS) Optimality Criteria estimated matrix C and
sx,1, as follows：
Wherein dij=c (tij-δi).Can pass through byAnd sx,1It is substituted into source and the microphone that estimation is determined in formula (10)
Position.Such method results in the quantity independently of acoustic events and microphone, estimates 10 parameters.Known increasing
Acoustic events or number of microphone are added to improve the precision of estimation.According at least one embodiment, the parameter of all estimations can
To be used as improving the initial value estimated using non-linear LS criterion come final based on formula (3).
Microphone gain calculates
According to one or more embodiments as described herein, the TOF of estimation can together with the calibration signal of reception by with
Unknown gain G at each microphone of determinationi.It is contemplated that free field AIR and may be assumed that noise is uncorrelated to pumping signal.
It can be written as according to the energy of the i-th microphone caused by jth acoustic events of formula (1), including microphone gain：
WhereinFor the signal energy at the sound source of jth position,For the energy and d of measurement noiseij=| |
ri-sj| |=ctijFor the distance between jth sound source and the i-th microphone.It should be noted that source-wheat of TOF measured values or estimation
Gram wind position can be used for distance estimations.
In view of the above, arbitrary reference microphone, such as the first I=1 may be selected, drawn relative to reference to wheat
The following formula of the microphone gain of gram wind：
WhereinFor the signal-to-noise ratio (SNR) for the jth source at the i-th microphone.From formula (16) presented below, it can manage
Deviation will be increased to the relative gain of the estimation for microphone by solving observation noise, and this deviation is by the SNR dependent on observation.
In the case of noise for spatially spreading or the microphone for being arranged with tight spacing, wherein can it is expected to cross over Mike
Wind SNR is identical, and noise will have smaller influence.However, for other scenes, if estimated the SNR at microphone
Then recoverable deviation.It, can be by making excitation interval Tp make more than the reverberation time in practice although not taking explicitly into account reverberation
The influence of reverberation minimizes.
Opposite microphone gain can be determined that：
The priori of the calibration signal duration of the TOF and transmitting that wherein measure can be used to evaluate signal energy
Amount.It should be noted that according to various embodiments described herein, the estimation of TOF is independently of the gain inequality between microphone.
Example calculations
Following present some additional examples to further illustrate microphone array calibration method as described herein.Below
In the example provided, RTOA is evaluated using different calibration signals.In second and third example, the TOF quilts of measurement
For microphone positioning and gain calibration.Each in these detailed further below instantiation procedures.
All following example are all based on identical primary condition and setting.As described above, being observed by being generated according to formula (1)
Signal start setting up.Source images method known to those skilled in the art can be used to simulate acoustic enviroment.It is illustrative
Example is for the room with following example size：6m (rice) × 5m × 4m.Reverberation time T60With the step-length of 0.15s in 0s
(such as free field) changes between 0.6s.2m × 2m that the microphone of I=8 is randomly placed at room center × 1m rectangles are empty
In, and the source of J=30 is randomly dispersed in one cubic metre of (1m of the random position in room3) space in.Then it gives birth to
At ten kinds of different source-microphone arrangements.Pass through AIR hij(n) it defines each source point and simulates the instantaneous of moving sound
Position.Used calibration signal sj(n) can be with TpThe pulse of the playing interval of=0.1s, the TSP of 1.3ms or
The GMSP of 1ms.
It can be for vij(n) assume additive gaussian white noise.As expected SNR is adjusted with reference to free field unit pulse
The noise level is saved, and the noise level keeps constant other pumping signals.Between this example consideration -25dB and -5dB
SNR (it was found that for unaffected higher than the SNR performances of -5dB).In addition, the stochastic gain factor changed between 0.5 and 1
GiAnd the random internal delay between 0 and 1 is applied to each microphone.Sample rate is arranged to fs=48kHz.
Example 1
It in the first example, can be to being used for the different calibration signals according to above-mentioned (such as in 3.1 sections) method extraction TOF
It is evaluated.In this example, assume that internal latency is known for the purpose of evaluation.For each case, ± 1 can be calculated
The percentage of the TOF correctly identified in interior sample.Fig. 4-6 illustrates the example knot that different calibration signals are executed with this calculating
Fruit, wherein used sample rate is 48kHz.Fig. 4 is the example evaluated error shown for unit pulse as calibration signal
The graphical representation 400 of (ratio of the sample in correct TOF and ± 1 indicated with %).Fig. 5 is to show that GMSP, which is used as calibration, to be believed
Number example evaluated error graphical representation 500.In addition, Fig. 6 is the example evaluated error for showing TSP being used as calibration signal
Graphical representation 600.Can be seen that compared with other two kinds of calibration signal types from example results shown in Fig. 4-6, TSP to noise and
Reverberation has maximum tolerance, and all TOF are accurately extracted.
Example 2
The TOF estimated in another example can be used for according to the above method (such as in the calibration of-microphone gain "
In) find out the gain about microphone i=1.Fig. 7 be illustrate it is other for different noise levels and different reverberation levels
The graphical representation 700 of example results.
Example 3
In another example, it can be looked for using newer TOF according to the above method (such as in the positioning of-microphone " in)
Go out the position in microphone and source.Fig. 8 be illustrate using exactly known internal latency 830, estimation internal latency 820 and
The graphical representation 800 of the example results of internal latency 810 is not considered.
Example 4
In another example, it can use and RME is connected to by RME Octamic II microphone preamplifiers
The AKG C417 clip-on microphones of Fireface 800 are come all processes before executing described in example.In such example
In, microphone can be on the table of 0.75m × 1.5m by the size being randomly placed in the room of quiet, slight reverberation.Mobile electricity
Words are used as sound source and can be by the phones while it is mobile just in a manner of undulatory motion (such as by user)
Generation is divided into T between havingpThe pulse train of 50 pulses of=0.1s.Additional random delay between 0 and 100ms can be added
Enter each microphone signal to simulate different internal latencies.Fig. 9 is the figure table for the example results for illustrating microphone positioning
Show 900.Can microphone be navigated to the precision of 2.9cm, and only result in the root-mean-square error of 1.4cm using centralized clock
(RMSE)。
Figure 10 be according to one or more embodiments as described herein be arranged to calibrating distributed sensor (such as
Microphone) array illustrative computer (1000) high-level block diagram, wherein the calibrating distributed sensor array is to make
The TOF measured values of the acoustic events of multiple spatial distributions at sensor carry out.In very basic configuration (1001)
In, computing device (1000) generally includes one or more processors (1010) and system storage (1020).Memory bus
(1030) it can be used for the communication between processor (1010) and system storage (1020).
Depending on desired configuration, processor (1010) can be any types, including but not limited to：Microprocessor (μ
P), microcontroller (μ C), digital signal processor (DSP) or any combination thereof.Processor (1010) may include one all
As layer 1 caches multilayer caching, processor core (1013) and the register (1014) of (1011) and the caching of layer 2 (1012).The processing
Device core (1013) may include arithmetic logic unit (ALU), floating point unit (FPU), Digital Signal Processing core (DSP core) or its
Any combinations.Memory Controller (1016) can also rise with processor (1010)-and use, or in some embodiments,
Memory Controller (1015) can be the interior section of processor (1010).
Depending on desired configuration, system storage (1020) can be any types, including but not limited to：Volatibility
Memory (RAM), nonvolatile memory (ROM, flash memory etc.) or any combination thereof.System storage (1020)
Generally include operating system (1021), one or more application (1022) and program data (1024).It can be with using (1022)
Include for the acoustic events according to one or more embodiments as described herein using multiple spatial distributions at sensor
TOF measured values calibrate positioning and the gain calibration algorithm (1023) of multiple sensors.Program data (1024) may include
Storage instruction, when executing storage instruction by one or more processing equipments, which is used for according to herein
One or more embodiments are calibrated using the TOF measured values of the acoustic events of multiple spatial distributions at sensor
The method of distributed sensor (such as microphone) array.
In addition, according at least one embodiment, program data (1024) may include calibration signal data (1025), the signal
Data (1025) may include data related with the characteristic of signal specific and/or characteristic, which is used as from audio
Source device transmitting to improve microphone and source positioning precision pumping signal (for example, " pumping signal " section such as above
Pumping signal s described in fallingj(n)).For example, calibration signal data (1025) may include smart about being selected for being convenient for
The various characteristics data of any one of the following example signal that true RTOA is measured：(i) unit pulse；(ii) time domain extends
Pulse (TSP)；And (iii) Gaussian modulation sinusoidal impulse (GMSP).In some embodiments, it can be arranged using (1022)
To be operated with program data (1024) in operating system (1021).
Computing device (1000) can have the function of bells and whistles or, and convenient for basic configuration (1001) with it is any required
The additional interface of communication between equipment and interface.
System storage (1020) is the example of computer storage media.Computer storage media include but not limited to RAM,
ROM, EEPROM, flash or other storage technology, CD-ROM, digital versatile disc (DVD) or other optical memory, cassette,
Tape, disk storage or other magnetic storage apparatus or it can be used in storing desired information and can be set by calculating
The standby 1000 any other media accessed.Any such computer storage media can be one of computing device (1000)
Point.
Computing device (1000) can be implemented as a part for small portable (or mobile) electronic equipment, such as, bee
Cellular telephone, personal digital assistant (PDA), personal media player device, tablet computer (tablet), wireless network are watched and are set
Standby, personal ear speaker device, special equipment or the mixing apparatus for including any of above function.Computing device (1000) can also be by
Be embodied as include laptop computer and non-laptop computer configuration both personal computer.
Via using block diagram, flow chart and/or example, each of equipment and/or processing has been elaborated in aforementioned detailed description
Kind embodiment.In the range of such block diagram, flow chart and/or example include one or more functions and/or operation, ability
Domain the skilled person will understand that, can by extensive hardware, software, firmware or actually any combination thereof individually and/or altogether
Each function and/or the operation in such block diagram, flow chart or example are realized together.It in one embodiment, can be via
Application-specific integrated circuit (ASIC), field programmable gate array (FPGA), digital signal processor (DSP) or other integrated shapes
If formula realizes the stem portion of subject matter described herein.However, those skilled in the art will recognize that, it is disclosed herein
The some aspects of embodiment can be in whole or in part as one or more meters run on one or more computers
Calculation machine program, as one or more programs run on one or more processors, as firmware or as reality
Any combination thereof on border, equally to realize in integrated circuits, and according to the disclosure, for software or firmware design circuit
And/or write code will be within the technical ability of complete those skilled in the art.
In addition, it will be appreciated by those skilled in the art that the mechanism of theme as described herein can divide in a variety of manners
Cloth is in program product, also, the application of the illustrative embodiment of theme as described herein executes the non-of distribution with for practical
The specific type of instantaneity signal bearing medium is unrelated.The example of non-transient signal bearing medium includes but not limited to following：
Floppy disk, hard disk drive, CD (CD), digital versatile disc (DVD), digital magnetic tape, computer storage etc. can record
Type medium；And such as number and/or analogue communication medium are (for example, optical cable, waveguide, wired communications links, wireless communication link
Deng) transmission type media.
For relatively more any plural number and/or singular references used herein, as long as it is suitable for context and/or answers
With then those skilled in the art can convert plural number to odd number and/or convert odd number to plural number.For clarity, originally
Civilization really elaborates the transformation of various singular/plurals.
Therefore, it has been described that the specific embodiment of this theme.Other embodiment falls into the range of following claims
It is interior.In some cases, the action quoted in claims can be executed in a different order and can still obtain required
Result.In addition, the process described in attached drawing may not require shown in particular order or successively sequence, to obtain desired knot
Fruit.In some embodiments, multitask and parallel processing can be advantageous.
Claims (20)
1. a kind of computer implemented method for calibrating distributed sensor, including：
The arrival time of the record of the acoustic events group at sensor group is determined, wherein coming by time interval known to sensor
Generate acoustic events；
When the arrival time of record based on the acoustic events at the sensor, the event of the acoustic events generate
Between and the internal latency of estimation of the sensor calculate the flight time that the acoustic events reach the sensor；And
The calculated flight time is used to determine the position of the sensor.
2. according to the method described in claim 1, wherein, for each sensor, by from the record for the sensor
The event generated time for the internal latency and the acoustic events that the time subtracts the sensor on earth calculates the acoustic events
Reach the flight time of the sensor.
3. according to the method described in claim 1, wherein, being iteratively performed the calculating acoustic events and reaching the sensor
The flight time, with the flight time of refining.
4. according to the method described in claim 1, further comprising selecting the first acoustic events in the acoustic events group, institute
It states the first acoustic events and is generated as the benchmark for reaching the flight time of the sensor for calculating the acoustic events
Time.
5. according to the method described in claim 1, further comprising using the position of the determining sensor and in the biography
The arrival time of the record of the acoustic events at sensor to determine relative gain to each in the sensor.
6. according to the method described in claim 1, wherein, each in the acoustic events is as the positive taut pulse of Gaussian modulation
The calibration signal of punching.
7. according to the method described in claim 1, wherein, each in the acoustic events is to extend pulse as time domain
Calibration signal.
8. according to the method described in claim 1, wherein, each in the acoustic events is the calibration as unit pulse
Signal.
9. according to the method described in claim 1, wherein, the sensor group is microphone group.
10. according to the method described in claim 1, wherein, the acoustic events group by the equipment with loud speaker from relative to
Multiple and different positions of the sensor generate.
11. according to the method described in claim 1, wherein, one or more of described sensor is on mobile phone
Microphone.
12. a kind of computer implemented method for calibrating distributed sensor, including：
The arrival time of record based on the acoustic events at sensor, event generated time of the acoustic events and described
The internal latency of the estimation of sensor calculates the flight time that (310) acoustic events group reaches sensor group, wherein by described
Time interval known to sensor generates the acoustic events；
The flight time of the sensor is reached using the acoustic events to calculate the position of (325) sensor；
And
Use the arrival time of the position of the sensor of calculating and the record of the acoustic events at the sensor
To determine (330) relative gain to each in the sensor.
13. according to the method for claim 12, further comprising：
Measure the arrival time of the acoustic events group of (305) at the sensor group；And
Estimate that the inside of the sensor is prolonged based on the arrival time of the record of the acoustic events at the sensor
Late.
14. according to the method for claim 12, wherein be iteratively performed and calculate the acoustic events arrival sensor
The flight time, with the flight time of refining.
15. according to the method for claim 12, further comprise selecting the first acoustic events in the acoustic events group,
First acoustic events are generated as the base for reaching the flight time of the sensor for calculating the acoustic events
Between punctual.
16. according to the method for claim 12, wherein the estimation based on the signal-to-noise ratio (SNR) at the sensor come pair
Each in the sensor determines relative gain.
17. according to the method for claim 12, wherein each in the acoustic events is as Gaussian modulation sine
The calibration signal of pulse.
18. according to the method for claim 12, wherein each in the acoustic events is to extend pulse as time domain
Calibration signal.
19. according to the method for claim 12, wherein each in the acoustic events is the school as unit pulse
Calibration signal.
20. according to the method for claim 12, wherein the sensor group is microphone group (220) and the acoustics
Event group (215) is by the equipment (250) with loud speaker (255) from multiple and different positions generation relative to the sensor.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/145,196 | 2013-12-31 | ||
US14/145,196 US9488716B2 (en) | 2013-12-31 | 2013-12-31 | Microphone autolocalization using moving acoustic source |
PCT/US2014/070554 WO2015102883A1 (en) | 2013-12-31 | 2014-12-16 | Microphone autolocalization using moving acoustic source |
Publications (2)
Publication Number | Publication Date |
---|---|
CN105793723A CN105793723A (en) | 2016-07-20 |
CN105793723B true CN105793723B (en) | 2018-10-19 |
Family
ID=52350323
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201480065555.2A Active CN105793723B (en) | 2013-12-31 | 2014-12-16 | It is self-positioning using the microphone of moving sound |
Country Status (4)
Country | Link |
---|---|
US (1) | US9488716B2 (en) |
EP (1) | EP3090275B1 (en) |
CN (1) | CN105793723B (en) |
WO (1) | WO2015102883A1 (en) |
Families Citing this family (21)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9948415B2 (en) * | 2015-03-27 | 2018-04-17 | Intel IP Corporation | Method of processing a plurality of signals and signal processing device |
WO2018064410A1 (en) * | 2016-09-29 | 2018-04-05 | Dolby Laboratories Licensing Corporation | Automatic discovery and localization of speaker locations in surround sound systems |
CN106340305B (en) * | 2016-11-04 | 2024-03-19 | 北京声智科技有限公司 | Self-calibration far-field voice interaction device and far-field voice self-calibration method |
CN107219512B (en) * | 2017-03-29 | 2020-05-22 | 北京大学 | Sound source positioning method based on sound transfer function |
US11482308B2 (en) | 2017-08-10 | 2022-10-25 | Nuance Communications, Inc. | Automated clinical documentation system and method |
US11316865B2 (en) | 2017-08-10 | 2022-04-26 | Nuance Communications, Inc. | Ambient cooperative intelligence system and method |
CN109935237A (en) * | 2017-12-19 | 2019-06-25 | 展讯通信（上海）有限公司 | MIC array method for self-calibrating, device and the server of multi-mobile-terminal |
US10825440B2 (en) * | 2018-02-01 | 2020-11-03 | Cirrus Logic International Semiconductor Ltd. | System and method for calibrating and testing an active noise cancellation (ANC) system |
US11250382B2 (en) | 2018-03-05 | 2022-02-15 | Nuance Communications, Inc. | Automated clinical documentation system and method |
WO2019173333A1 (en) | 2018-03-05 | 2019-09-12 | Nuance Communications, Inc. | Automated clinical documentation system and method |
US20190272895A1 (en) | 2018-03-05 | 2019-09-05 | Nuance Communications, Inc. | System and method for review of automated clinical documentation |
EP3777234B1 (en) * | 2018-04-06 | 2022-03-30 | LEONARDO S.p.A. | Acoustic system for detecting and locating low intensity and low frequency sound sources and related locating method |
CN108989947A (en) * | 2018-08-02 | 2018-12-11 | 广东工业大学 | A kind of acquisition methods and system of moving sound |
US11216480B2 (en) | 2019-06-14 | 2022-01-04 | Nuance Communications, Inc. | System and method for querying data points from graph data structures |
US11043207B2 (en) | 2019-06-14 | 2021-06-22 | Nuance Communications, Inc. | System and method for array data simulation and customized acoustic modeling for ambient ASR |
US11227679B2 (en) | 2019-06-14 | 2022-01-18 | Nuance Communications, Inc. | Ambient clinical intelligence system and method |
US11531807B2 (en) | 2019-06-28 | 2022-12-20 | Nuance Communications, Inc. | System and method for customized text macros |
US11670408B2 (en) | 2019-09-30 | 2023-06-06 | Nuance Communications, Inc. | System and method for review of automated clinical documentation |
US11670298B2 (en) * | 2020-05-08 | 2023-06-06 | Nuance Communications, Inc. | System and method for data augmentation for multi-microphone signal processing |
US11222103B1 (en) | 2020-10-29 | 2022-01-11 | Nuance Communications, Inc. | Ambient cooperative intelligence system and method |
US20230283949A1 (en) * | 2022-03-03 | 2023-09-07 | Nureva, Inc. | System for dynamically determining the location of and calibration of spatially placed transducers for the purpose of forming a single physical microphone array |
Family Cites Families (8)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4909064A (en) * | 1988-07-22 | 1990-03-20 | The United States Of America As Represented By The Secretary Of The Air Force | Impulse calibration of mechanical to electrical transducers |
US5247489A (en) * | 1992-10-02 | 1993-09-21 | The United States Of America As Represented By The Secretary Of The Navy | Digital range measurement system |
EP1464985B1 (en) * | 2003-04-03 | 2008-07-16 | Mitsubishi Electric Information Technology Centre Europe B.V. | Time delay measurement |
EP4174448A3 (en) * | 2009-05-27 | 2023-07-26 | Silixa Ltd. | Method and apparatus for optical sensing |
US8421479B2 (en) * | 2009-06-30 | 2013-04-16 | Navisense | Pulsed echo propagation device and method for measuring a parameter |
ITTO20110464A1 (en) * | 2011-05-27 | 2012-11-28 | Fond Istituto Italiano Di Tecnologia | SELF-CALIBRATION PROCEDURE OF A SET OF SENSORS, IN PARTICULAR MICROPHONES, AND ITS SYSTEM |
US9025416B2 (en) * | 2011-12-22 | 2015-05-05 | Pelco, Inc. | Sonar system for automatically detecting location of devices |
CN102944613B (en) * | 2012-11-16 | 2015-04-01 | 中国科学院半导体研究所 | Detecting and positioning system for optical fiber acoustic emission |
-
2013
- 2013-12-31 US US14/145,196 patent/US9488716B2/en active Active
-
2014
- 2014-12-16 CN CN201480065555.2A patent/CN105793723B/en active Active
- 2014-12-16 EP EP14827623.1A patent/EP3090275B1/en active Active
- 2014-12-16 WO PCT/US2014/070554 patent/WO2015102883A1/en active Application Filing
Also Published As
Publication number | Publication date |
---|---|
WO2015102883A1 (en) | 2015-07-09 |
EP3090275A1 (en) | 2016-11-09 |
US9488716B2 (en) | 2016-11-08 |
CN105793723A (en) | 2016-07-20 |
US20150185312A1 (en) | 2015-07-02 |
EP3090275B1 (en) | 2021-03-17 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN105793723B (en) | It is self-positioning using the microphone of moving sound | |
US10939225B2 (en) | Calibrating listening devices | |
US10334357B2 (en) | Machine learning based sound field analysis | |
US9689959B2 (en) | Method, apparatus and computer program product for determining the location of a plurality of speech sources | |
US10063965B2 (en) | Sound source estimation using neural networks | |
CN106537501B (en) | Reverberation estimator | |
TWI530201B (en) | Sound acquisition via the extraction of geometrical information from direction of arrival estimates | |
JP5814476B2 (en) | Microphone positioning apparatus and method based on spatial power density | |
Nielsen et al. | The single-and multichannel audio recordings database (SMARD) | |
Dorfan et al. | Tree-based recursive expectation-maximization algorithm for localization of acoustic sources | |
BR112019013548A2 (en) | AUDIO CAPTURE EQUIPMENT, OPERATING METHOD FOR CAPTURING AUDIO, AND COMPUTER PROGRAM PRODUCT | |
JP2013148576A (en) | Portable device performing position specification using modulated background sound, computer program, and method | |
Salvati et al. | Sound source and microphone localization from acoustic impulse responses | |
CN107079219A (en) | The Audio Signal Processing of user oriented experience | |
Gaubitch et al. | Calibration of distributed sound acquisition systems using TOA measurements from a moving acoustic source | |
Yadav et al. | A system for simulating room acoustical environments for one’s own voice | |
Yousefian et al. | A hybrid coherence model for noise reduction in reverberant environments | |
Coleman et al. | Audio object separation using microphone array beamforming | |
US11830471B1 (en) | Surface augmented ray-based acoustic modeling | |
KR20090090693A (en) | Embodiment method of generating virtual sound using distance measurement devices and computer-readable medium thereof | |
Hur et al. | Techniques for synthetic reconfiguration of microphone arrays | |
Schlienger et al. | Immersive Spatial Interactivity in Sonic Arts: The Acoustic Localization Positioning System | |
Lee et al. | Sonicstrument: A Musical Interface with Stereotypical Acoustic Transducers. | |
US9589550B2 (en) | Methods and systems for measuring and reporting an energy level of a sound component within a sound mix | |
Shi et al. | Spatial Calibration of Surround Sound Systems including Listener Position Estimation |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
C06 | Publication | ||
PB01 | Publication | ||
C10 | Entry into substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
CB02 | Change of applicant information |
Address after: American CaliforniaApplicant after: Google limited liability companyAddress before: American CaliforniaApplicant before: Google Inc. |
|
CB02 | Change of applicant information | ||
GR01 | Patent grant | ||
GR01 | Patent grant |