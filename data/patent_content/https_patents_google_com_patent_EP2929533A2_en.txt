EP2929533A2 - Keyboard typing detection and suppression - Google Patents
Keyboard typing detection and suppressionInfo
- Publication number
- EP2929533A2 EP2929533A2 EP14708368.7A EP14708368A EP2929533A2 EP 2929533 A2 EP2929533 A2 EP 2929533A2 EP 14708368 A EP14708368 A EP 14708368A EP 2929533 A2 EP2929533 A2 EP 2929533A2
- Authority
- EP
- European Patent Office
- Prior art keywords
- audio signal
- residual part
- signal
- voiced parts
- noise
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Withdrawn
Links
Classifications
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L25/00—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00
- G10L25/48—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00 specially adapted for particular use
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L21/00—Processing of the speech or voice signal to produce another audible or non-audible signal, e.g. visual or tactile, in order to modify its quality or its intelligibility
- G10L21/02—Speech enhancement, e.g. noise reduction or echo cancellation
- G10L21/0208—Noise filtering
- G10L21/0216—Noise filtering characterised by the method used for estimating noise
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L25/00—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00
- G10L25/93—Discriminating between voiced and unvoiced parts of speech signals
- G10L2025/935—Mixed voiced class; Transitions
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L21/00—Processing of the speech or voice signal to produce another audible or non-audible signal, e.g. visual or tactile, in order to modify its quality or its intelligibility
- G10L21/02—Speech enhancement, e.g. noise reduction or echo cancellation
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L21/00—Processing of the speech or voice signal to produce another audible or non-audible signal, e.g. visual or tactile, in order to modify its quality or its intelligibility
- G10L21/02—Speech enhancement, e.g. noise reduction or echo cancellation
- G10L21/0208—Noise filtering
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L25/00—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00
- G10L25/78—Detection of presence or absence of voice signals
- G10L25/84—Detection of presence or absence of voice signals for discriminating voice from noise
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L25/00—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00
- G10L25/93—Discriminating between voiced and unvoiced parts of speech signals
Definitions
- the present disclosure generally relates to methods, systems, and apparatus for signal processing. More specifically, aspects of the present disclosure relate to detecting transient noise events in an audio stream using the incoming audio data.
- the noise pulses produced by keystrokes can vary greatly with factors such as keystroke speed and length, microphone placement and response, laptop frame or base, keyboard or trackpad type, and even the surface on which the computer is placed. It is also noted that in many scenarios the microphone and the noise source might not even be mechanically linked, and in some cases the keyboard strokes could originate from an entirely different device, making any attempt at incorporating software cues futile.
- a second approach proposes relying on a median filter to identify outlying noise events and then restoring audio based on the median filter data. This second approach is primarily designed for much faster corruption events with only a few corrupted samples.
- a third approach is similar to the second approach described above, but with wavelets used as the basis. While this third approach increases the temporal resolution of detection, the approach considers the scales independently, which might give rise to false detections based on the more transient voiced speech components.
- a fourth approach to resolving the nuisance of button-clicking noise proposes an algorithm relying on no auxiliary data.
- detection is based on the Short Time Fourier Transform and detections are identified by spectral flatness and increasing rate of high-frequency components, which can falsely detect voiced segments with a sudden onset.
- the algorithm proposed in this fourth approach is meant for post-processing, and a computationally-efficient real-time implementation of this algorithm would lose temporal resolution. It is also not clear that this fourth approach would work well for the range of transient noise seen in real life applications. A probabilistic interpretation of the detection state could yield a more adaptable and dependable basis for detection.
- This fourth approach also proposes restoration based on scaled frequency components which, coupled with the low temporal resolution, could be overly invasive and unsettling to the listener.
- One embodiment of the present disclosure relates to a method for detecting presence of a transient noise in an audio signal, the method comprising: identifying one or more voiced parts of the audio signal; extracting the one or more identified voiced parts from the audio signal, wherein the extraction of the one or more voiced parts yields a residual part of the audio signal; estimating an initial probability of one or more detection states for the residual part of the signal; calculating a transition probability between each of the one or more detection states; and determining a probable detection state for the residual part of the signal based on the initial probabilities of the one or more detection states and the transition probabilities between the one or more detection states.
- the method for detecting presence of a transient noise further comprises preprocessing the audio signal by recursively subtracting tonal components.
- the step of preprocessing the audio signal includes decomposing the audio signal into a set of coefficients.
- the method for detecting presence of a transient noise further comprises performing a time-frequency analysis on the residual part of the audio signal to generate a predictive model of the residual part of the audio signal.
- the method for detecting presence of a transient noise further comprises recombining the residual part of the audio signal with the one or more extracted voiced parts.
- the method for detecting presence of a transient noise further comprises determining, based on the residual part of the audio signal, that additional voiced parts remain in the residual part of the audio signal, and extracting one or more of the additional voiced parts from the residual part of the audio signal.
- the method for detecting presence of a transient noise further comprises, prior to recombining the residual part and the one or more extracted voiced parts, determining that the one or more extracted voiced parts include low-frequency components of the transient noise, and filtering out the low-frequency components of the transient noise from the one or more extracted voiced parts.
- the method for detecting presence of a transient noise further comprises modeling additive noise in the residual part of the signal as a zero-mean Gaussian process.
- the method for detecting presence of a transient noise further comprises modeling additive noise in the residual part of the signal as an autoregressive (AR) process with estimated coefficients.
- AR autoregressive
- the method for detecting presence of a transient noise further comprises identifying corrupted samples of the audio signal based on the estimated detection state, and restoring the corrupted samples in the audio signal;
- the step of restoring the corrupted samples includes removing the corrupted samples from the audio signal.
- the methods presented herein may optionally include one or more of the following additional features: the time-frequency analysis is a discrete wavelet transform; the time-frequency analysis is a wavelet packet transform; the one or more voiced parts of the audio signal are identified by detecting spectral peaks in the frequency domain; the spectral peaks are detected by thresholding a median filter output, and/or the one or more additional voiced parts are identified by detecting spectral peaks in the frequency domain for the residual part of the audio signal.
- Figure 1 is a block diagram illustrating an example system for detecting the presence of a transient noise event in an audio stream using the incoming audio data according to one or more embodiments described herein.
- Figure 2 is a graphical representation illustrating an example output of voiced signal extraction according to one or more embodiments described herein.
- Figure 3 is a flowchart illustrating an example method for detecting the presence of a transient noise event in an audio stream using the incoming audio data according to one or more embodiments described herein.
- Figure 4 is a graphical representation illustrating an example performance of transient noise detection according to one or more embodiments described herein.
- Figure 5 is a block diagram illustrating an example computing device arranged for detecting the presence of a transient noise event in an audio stream using the incoming audio data according to one or more embodiments described herein.
- Embodiments of the present disclosure relate to methods and systems for detecting the presence of a transient noise event in an audio stream using primarily or exclusively the incoming audio data. Such an approach provides improved temporal resolution and is computationally efficient.
- the methods and systems presented herein utilize some time-frequency representation (e.g., discrete wavelet transform (DWT), wavelet packet transform (WPT), etc.) of an audio signal as the basis in a predictive model in an attempt to find outlying transient noise events.
- DWT discrete wavelet transform
- WPT wavelet packet transform
- the methods of the present disclosure interpret the true detection state as a Hidden Markov Model (HMM) to model temporal and frequency cohesion common amongst transient noise events.
- HMM Hidden Markov Model
- the algorithm proposed uses a preprocessing stage to decompose an audio signal into a sparse set of coefficients relating to the noise pulses.
- the audio data may be preprocessed by subtracting tonal components recursively, as system resources allow. While this approach detects and restores transient noise events primarily based on a single audio stream, various parameters can be tuned if positive detections can be confirmed via operating system (OS) information or otherwise.
- OS operating system
- FIG. 1 illustrates an example system for detecting the presence of a transient noise event in an audio stream using the incoming audio data according to one or more embodiments described herein.
- the detection system 100 may include a voice extraction component 110, a time-frequency detector 120, and interpolation components 130 and 160 for the residual and voiced signals, respectively. Additionally, the detection system 100 may perform an algorithm similar to the algorithm illustrated in FIG. 3, which is described in greater detail below.
- An audio signal 105 input into the detection system 100 may undergo voice extraction 110, resulting in a voiced signal part 150 and a residual signal part 140.
- the residual signal part 140 may undergo time-frequency analysis (via the time-frequency detector 120) providing information for the possible restoration step (via the interpolation component 130).
- the voiced signal 150 may require restoration based on the time-frequency detector 120 findings, which may be performed by the interpolation component 160 for the voiced signal 150.
- the interpolated voice signal 150 and residual signal 140 may then be recombined to form the output signal.
- the detection system 100 may perform the detection algorithm in an iterative manner. For example, once the interpolated voice signal 150 and residual signal 140 are recombined following any necessary restoration processing (e.g., by interpolation components 130 and 160), a determination may be made as to whether further restoration of the signal is needed. If it is found that further restoration is needed, then the recombined signal may be processed again through the various components of the detection system 100. Having removed some of the transient components from the signal during the initial iteration, a subsequent iteration may affect the audio separation and lead to better overall results. [0041] FIG.
- the output of voice extraction on an input signal 205 may include a voiced signal part 250 and a residual signal part 240, (e.g., the voiced signal part 150 and the residual signal part 140 in the example system shown in FIG. 1).
- FIG. 3 illustrates an example process for detecting the presence of a transient noise event in an audio stream using the incoming audio data.
- the process illustrated may be performed, for example, by the voice extraction component 110, the time-frequency detector 120, and the interpolation components 130, 160 of the detection system 100 shown in FIG. 1 and described above.
- voiced parts of the signal can be extracted (e.g., via the voice extraction 110 of the example detection system shown in FIG. 1).
- the voiced parts of the signal may be identified and then extracted at blocks 300 and 305, respectively, of the process illustrated in FIG. 3.
- the voiced parts of the signal may be identified by detecting acoustic resonances, or spectral peaks, in a frequency domain.
- the voiced parts may then be extracted prior to the detection procedure. Peaks in the spectral domain can be identified, for example, by thresholding a median filter output or by some other peak-detection method.
- a determination may be made as to whether further extraction e.g., voice extraction
- further extraction e.g., voice extraction
- the process may return to blocks 300 and 305. By repeating the identification and extraction (e.g., at blocks 300 and 305) multiple times for different frame sizes and thresholds, additional voiced parts of the signal may be extracted.
- the process may move to estimating the initial probability for the detection state (block 315), calculating the transition probability between states (block 320), determining the most likely detection state based on the probabilities of each state (block 325), and interpolating the corrupted audio samples (block 330).
- the operations shown in blocks 315 through 330 will be described in greater detail below.
- the process may move to block 335 where the voiced parts of the signal may be reintroduced (e.g., following voice extraction 110, time-frequency analysis 120, and interpolation 130, the residual signal part 140 may be recombined with the extracted voiced signal part 150 (e.g., following interpolation 160) as illustrated in FIG. 1).
- the voiced parts of the signal may be reintroduced (e.g., following voice extraction 110, time-frequency analysis 120, and interpolation 130, the residual signal part 140 may be recombined with the extracted voiced signal part 150 (e.g., following interpolation 160) as illustrated in FIG. 1).
- c i are the coefficients for the voiced parts of the signal and ⁇ is a basis function which could be based on standard Fourier, Cepstrum or Gabor analysis, or Voice Speech filters.
- Wj (t) are the coefficients of the residual part, where j is an integer relating to some translation and/or dilation of some basis function ⁇ .
- WPD Wavelet Packet Decomposition
- win will be used to denote a vector of all coefficients at a given time index n. It may be assumed that the coefficients for each terminal node j can be modeled as some switched additive noise process such that:
- the transient signal ⁇ ⁇ j is thus a switched noise burst corrupted by additive noise v n
- the grouping of the transient noise bursts may depend on the statistics of i n j .
- Corresponding values of i n j at different scales j and with consecutive time indexes n may be modeled as a Markov chain, which will describe some degree of cohesion between frequency and time.
- the transient noise pulses will typically have a similar index of onset and will likely stay active for a length of time proportional with wavelet scale j.
- the model may now be expressed in terms of the additive noise and a matrix of coefficients:
- ⁇ ⁇ + ⁇ , (3)
- w [w 1 , w 2 , ... , w J ]
- Wj [w l ⁇ , w 2 ⁇ , ... , w N . ] r for the j ' th set of coefficients.
- ⁇ denotes the corresponding switched noise burst J by N matrix containing elements i n j 0 n j and v is the random additive noise describing, for example, the effect of speech on the coefficients.
- the i values across different scales may differ from one another, and would be statistically linked together via a hidden Markov tree or similar construction.
- both the noise burst ⁇ and the background noise (e.g., speech) v can be modeled as zero mean Gaussian distributions gives the following: ⁇ ⁇ ⁇ ⁇ ⁇ (0, ⁇ ) , (4) where A is a covariance matrix.
- the diagonal elements of A may simply be [ ⁇ ⁇ , ⁇ 2 ,..., ⁇ ] ] .
- the diagonal elements of A could also represent more complex variance cohesion. Rather than keeping the variance constant for the duration of the noise pulse, a changing variance model based on some envelope of the changing variance may provide a more accurate match for transients of interest.
- the background noise may similarly be modeled as a zero-mean Gaussian process, such that: v star ⁇ N Vn (0, C v ) , (5) where C v is a covariance matrix.
- the diagonal components of C v may simply be [ ⁇ ⁇ 1 , ⁇ ⁇ 2 , ... , ⁇ ⁇ 7 ] .
- a more computationally-intensive implementation could model v as an autoregressive (AR) process with estimated coefficients or with a simple averaging coefficient set.
- AR autoregressive
- each coefficient can be estimated by the M preceding (and possibly succeeding) coefficients in addition to some noise. Treating each scale as independent, the combined likelihood may be calculated by the product of the likelihood from each scale. In such an implementation, transient noise events could be detected by thresholding the combined likelihood. Additional algorithmic details of such an implementation are provided below in "Example Implementation.”
- the probability of i conditional upon the observed (and corrupted) data w and other prior information available may be determined.
- Prior information regarding detections may include, for example, information from the operation system (OS), inferred likely detection timings based on recent detection, inferred likely detection timings based on learned information from the user, and the like.
- this posterior probability p(i I w) may be expressed using Bayes' rule so that p(w ⁇ i)p(i)
- pii I ) (6) p(w) where the likelihood p(w I i) may be considered the primary part of the calculation.
- ⁇ denotes the switched random noise process.
- each set of wavelet coefficients may be expressed as w l (n) , such as the following:
- the knowledge that detections usually come in blocks of detections may be incorporated into the model.
- the state vector i considering the state vector i as a HMM, specific knowledge about the nature of expected detections may be incorporated into the model.
- the Viterbi algorithm may be used to calculate the most likely evolution of i or sequence of i n .
- the most likely detection state given a sequence of data may be expressed as:
- MLE arg p(icuit I i n _,)p(w(n) I i . ( io)
- Equation (10) p(i 0 ) is the starting probability, p(i n I i ⁇ ) is the transition probability from one state to the next, and p(w(n) I i n ) is the emission probability or the observation probability.
- an extension to the algorithm described above and illustrated in FIG. 3 may include running the entire algorithm in an iterative manner.
- the process may move from block 335, where the voiced parts of the signal may be reintroduced and combined with the residual signal part (e.g., following voice extraction 110, time-frequency analysis 120, and interpolation 130, the residual signal part 140 may be recombined with the extracted voiced signal part 150, as illustrated in FIG. 1), to block 340 where it is determined whether further restoration of the signal is needed (represented by broken lines in FIG. 3). If it is determined at block 340 that further restoration is needed, the process may return to block 300 and repeat.
- the process may move from block 335, where the voiced parts of the signal may be reintroduced and combined with the residual signal part (e.g., following voice extraction 110, time-frequency analysis 120, and interpolation 130, the residual signal part 140 may be recombined with the extracted voiced signal part 150, as illustrated in FIG. 1), to block 340 where it is determined
- FIG. 4 illustrates an example performance of transient noise detection in accordance with one or more of the embodiments described herein.
- the step function 405 indicates detections
- a detection is found at the high value and no detection at the low value.
- the detections 405 are also an indication of possible areas for interpolation with components 130 and 160 as illustrated in FIG. 1.
- the detected state agrees with the ground truth for the example and the transients are picked up despite the surrounding voiced signal.
- the step function 405 indicates a range of corrupted samples and not just a single detection at each transient noise event. This is because the algorithm, in this case, correctly determines an appropriate number of corrupted samples.
- the benefit of using a decomposition with good temporal resolution is that the detection onset and duration can be more accurately determined and corrupted frames can be dealt with in a less intrusive manner.
- a Bayesian approach may proceed by estimating p(v n I w n ,i n ) ⁇
- p(w n ⁇ v n , i n l) ⁇ N(w n , A)
- p(v n ⁇ i n ) p(v n ) ⁇ N(0, C v ) .
- a more straightforward restoration approach may entirely remove the offending coefficients while a more complex approach may attempt to fill-in the corrupted coefficients with an AR process trained on preceding and succeeding coefficients.
- the voiced speech e.g., voiced signal part 150 as shown in FIG. 1.
- the algorithm may proceed by recombining the processed residual signal part (e.g., with the keystrokes removed) and the dictionary of tonal components from equation (1).
- each coefficient can be estimated by the M preceding (and possibly succeeding) coefficients in addition to some noise (where "M" is an arbitrary number). Treating each scale as independent, the combined likelihood may be calculated by the product of the likelihood from each scale. In such an implementation, transient noise events could be detected by thresholding the combined likelihood. Additional algorithmic details of such an implementation are provided below.
- the terminal node coefficients of a WPD, or some other time-frequency analysis coefficients, of an incoming audio sequence x(n) of length N may be defined as X(j,t), where j is thej ' th terminal node (scale or frequency), j e ⁇ 1,...,/ ⁇ , and t is the time index related to n.
- X(t) may be used to denote a vector of all coefficients at a given time index t. Additionally, it may be assumed that the coefficients for each terminal node j follow the linear predictive model
- v(j,t) Gaussian noise with zero mean so that v(j,t) ⁇ N v (0, ⁇ ).
- the marginal probability may be expressed as assuming that the conditional probabilities for each set of coefficients are independent.
- FIG. 5 is a block diagram illustrating an example computing device 500 that is arranged for detecting the presence of a transient noise event in an audio stream using the incoming audio data in accordance with one or more embodiments of the present disclosure.
- computing device 500 may be configured to utilize a time-frequency representation of an incoming audio signal as the basis in a predictive model in an attempt to find outlying transient noise events, as described above.
- the computing device 500 may further be configured to interpret the true detection state as a Hidden Markov Model (HMM) to model temporal and frequency cohesion common amongst transient noise events.
- HMM Hidden Markov Model
- computing device 500 typically includes one or more processors 510 and system memory 520.
- a memory bus 530 may be used for communicating between the processor 510 and the system memory 520.
- processor 510 can be of any type including but not limited to a microprocessor ( ⁇ ), a microcontroller ( ⁇ ( ⁇ ), a digital signal processor (DSP), or any combination thereof.
- Processor 510 may include one or more levels of caching, such as a level one cache 51 1 and a level two cache 512, a processor core 513, and registers 514.
- the processor core 513 may include an arithmetic logic unit (ALU), a floating point unit (FPU), a digital signal processing core (DSP Core), or any combination thereof.
- a memory controller 515 can also be used with the processor 510, or in some embodiments the memory controller 515 can be an internal part of the processor 510.
- system memory 520 can be of any type including but not limited to volatile memory (e.g., RAM), non-volatile memory (e.g., ROM, flash memory, etc.) or any combination thereof.
- System memory 520 typically includes an operating system 521 , one or more applications 522, and program data 524.
- application 522 may include a detection algorithm 523 that is configured to detect the presence of a transient noise event in an audio stream (e.g., input signal 105 as shown in the example system of FIG. 1) using primarily or exclusively the incoming audio data.
- the detection algorithm 523 may be configured to perform preprocessing on an incoming audio signal to decompose the signal into a sparse set of coefficients relating to the noise pulses and then perform time- frequency analysis on the decomposed signal to determine a likely detection state.
- the detection algorithm 523 may be further configured to perform voice extraction on the input audio signal to extract the voiced signal parts (e.g., via the voice extraction component 110 of the example detection system shown in FIG. 1).
- Program Data 524 may include audio signal data 525 that is useful for detecting the presence of transient noise in an incoming audio stream.
- application 522 can be arranged to operate with program data 524 on an operating system 521 such that the detection algorithm 523 uses the audio signal data 525 to perform voice extraction, time-frequency analysis, and interpolation (e.g., voice extraction 110, time- frequency detector 120, and interpolation 130 in the example detection system 100 shown in FIG. 1).
- Computing device 500 can have additional features and/or functionality, and additional interfaces to facilitate communications between the basic configuration 501 and any required devices and interfaces.
- a bus/interface controller 540 can be used to facilitate communications between the basic configuration 501 and one or more data storage devices 550 via a storage interface bus 541.
- the data storage devices 550 can be removable storage devices 551, non-removable storage devices 552, or any combination thereof.
- removable storage and non-removable storage devices include magnetic disk devices such as flexible disk drives and hard-disk drives (HDD), optical disk drives such as compact disk (CD) drives or digital versatile disk (DVD) drives, solid state drives (SSD), tape drives and the like.
- Example computer storage media can include volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information, such as computer readable instructions, data structures, program modules, and/or other data.
- System memory 520, removable storage 551 and non-removable storage 552 are all examples of computer storage media.
- Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by computing device 500. Any such computer storage media can be part of computing device 500.
- Computing device 500 can also include an interface bus 542 for facilitating communication from various interface devices (e.g., output interfaces, peripheral interfaces, communication interfaces, etc.) to the basic configuration 501 via the bus/interface controller 540.
- Example output devices 560 include a graphics processing unit 561 and an audio processing unit 562, either or both of which can be configured to communicate to various external devices such as a display or speakers via one or more A/V ports 563.
- Example peripheral interfaces 570 include a serial interface controller 571 or a parallel interface controller 572, which can be configured to communicate with external devices such as input devices (e.g., keyboard, mouse, pen, voice input device, touch input device, etc.) or other peripheral devices (e.g., printer, scanner, etc.) via one or more I/O ports 573.
- input devices e.g., keyboard, mouse, pen, voice input device, touch input device, etc.
- other peripheral devices e.g., printer, scanner, etc.
- An example communication device 580 includes a network controller 581, which can be arranged to facilitate communications with one or more other computing devices 590 over a network communication (not shown) via one or more communication ports 582.
- the communication connection is one example of a communication media.
- Communication media may typically be embodied by computer readable instructions, data structures, program modules, or other data in a modulated data signal, such as a carrier wave or other transport mechanism, and includes any information delivery media.
- a "modulated data signal" can be a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal.
- communication media can include wired media such as a wired network or direct-wired connection, and wireless media such as acoustic, radio frequency (RF), infrared (IR) and other wireless media.
- RF radio frequency
- IR infrared
- computer readable media can include both storage media and communication media.
- Computing device 500 can be implemented as a portion of a small-form factor portable (or mobile) electronic device such as a cell phone, a personal data assistant (PDA), a personal media player device, a wireless web-watch device, a personal headset device, an application specific device, or a hybrid device that include any of the above functions.
- a small-form factor portable (or mobile) electronic device such as a cell phone, a personal data assistant (PDA), a personal media player device, a wireless web-watch device, a personal headset device, an application specific device, or a hybrid device that include any of the above functions.
- PDA personal data assistant
- Computing device 500 can also be implemented as a personal computer including both laptop computer and non-laptop computer configurations.
- ASICs Application Specific Integrated Circuits
- FPGAs Field Programmable Gate Arrays
- DSPs digital signal processors
- ASICs Application Specific Integrated Circuits
- FPGAs Field Programmable Gate Arrays
- DSPs digital signal processors
- some aspects of the embodiments described herein, in whole or in part, can be equivalently implemented in integrated circuits, as one or more computer programs running on one or more computers (e.g., as one or more programs running on one or more computer systems), as one or more programs running on one or more processors (e.g., as one or more programs running on one or more microprocessors), as firmware, or as virtually any combination thereof.
- processors e.g., as one or more programs running on one or more microprocessors
- firmware e.g., as one or more programs running on one or more microprocessors
- designing the circuitry and/or writing the code for the software and/or firmware would be well within the skill of one of skilled in the art in light of the present disclosure.
- Examples of a signal-bearing medium include, but are not limited to, the following: a recordable-type medium such as a floppy disk, a hard disk drive, a Compact Disc (CD), a Digital Video Disk (DVD), a digital tape, a computer memory, etc.; and a transmission-type medium such as a digital and/or an analog communication medium (e.g., a fiber optic cable, a waveguide, a wired communications link, a wireless communication link, etc.)
- a recordable-type medium such as a floppy disk, a hard disk drive, a Compact Disc (CD), a Digital Video Disk (DVD), a digital tape, a computer memory, etc.
- a transmission-type medium such as a digital and/or an analog communication medium (e.g., a fiber optic cable, a waveguide, a wired communications link, a wireless communication link, etc.)
- a typical data processing system generally includes one or more of a system unit housing, a video display device, a memory such as volatile and non-volatile memory, processors such as microprocessors and digital signal processors, computational entities such as operating systems, drivers, graphical user interfaces, and applications programs, one or more interaction devices, such as a touch pad or screen, and/or control systems including feedback loops and control motors (e.g., feedback for sensing position and/or velocity; control motors for moving and/or adjusting components and/or quantities).
- a typical data processing system may be implemented utilizing any suitable commercially available components, such as those typically found in data computing/communication and/or network computing/communication systems.
Abstract
Provided are methods and systems for detecting the presence of a transient noise event in an audio stream using primarily or exclusively the incoming audio data. Such an approach offers improved temporal resolution and is computationally efficient. The methods and systems presented utilize some time-frequency representation of an audio signal as the basis in a predictive model in an attempt to find outlying transient noise events and interpret the true detection state as a Hidden Markov Model (HMM) to model temporal and frequency cohesion common amongst transient noise events.
Description
KEYBOARD TYPING DETECTION AND SUPPRESSION TECHNICAL FIELD
[0001] The present disclosure generally relates to methods, systems, and apparatus for signal processing. More specifically, aspects of the present disclosure relate to detecting transient noise events in an audio stream using the incoming audio data.
BACKGROUND
[0002] The ubiquitous nature of high speed internet connections has made personal computers a popular basis for teleconferencing applications. While embedded microphones, loudspeakers, and webcams in laptop computers have made conference calls very easy to set up, these features have also introduced specific noise nuisances such as feedback, fan noise, and button-clicking noise. Button-clicking noise has been a particularly persistent problem, and is generally due to the mechanical impulses caused by keystrokes. In the context of laptop computers, button-clicking noise can be a significant nuisance due to the mechanical connection between the microphone within the laptop case and the keyboard.
[0003] The noise pulses produced by keystrokes can vary greatly with factors such as keystroke speed and length, microphone placement and response, laptop frame or base, keyboard or trackpad type, and even the surface on which the computer is placed. It is also noted that in many scenarios the microphone and the noise source might not even be mechanically linked, and in some cases the keyboard strokes could originate from an entirely different device, making any attempt at incorporating software cues futile.
[Θ0Θ ] There are a handful of approaches that attempt to address the problem described above. However, none of these proposed solutions attempt to tackle the issue in real-time, and none are based purely on the audio stream. For example, a first approach utilizes a linear predictive model on frequency bins in an area around the audio frame in question. While this first approach has the advantage of dealing with speech segments with sharp attacks, the required look-ahead is between 20-30 milliseconds (ms), which will delay any detection by at least this much. Such an approach has been suggested only as an aid where the final detection decision requires confirmation from the hardware keyboard.
[0005] It should be noted that with frame lengths of 20 ms and overlaps of 10 ms, the exact localization of the transient is lost. Exact localization of the transient is of interest when the transient is to be removed from the audio stream. It is also worth noting that many transient noises might not be detectable as a hardware input through the keyboard and a more general approach will provide a more consistent noise reduction performance on transient noise.
[0006] A second approach proposes relying on a median filter to identify outlying noise events and then restoring audio based on the median filter data. This second approach is primarily designed for much faster corruption events with only a few corrupted samples.
[0007] A third approach is similar to the second approach described above, but with wavelets used as the basis. While this third approach increases the temporal resolution of detection, the approach considers the scales independently, which might give rise to false detections based on the more transient voiced speech components.
[0008] A fourth approach to resolving the nuisance of button-clicking noise proposes an algorithm relying on no auxiliary data. In this fourth approach, detection is based on the Short Time Fourier Transform and detections are identified by spectral flatness and increasing rate of high-frequency components, which can falsely detect voiced segments with a sudden onset. The algorithm proposed in this fourth approach is meant for post-processing, and a computationally-efficient real-time implementation of this algorithm would lose temporal resolution. It is also not clear that this fourth approach would work well for the range of transient noise seen in real life applications. A probabilistic interpretation of the detection state could yield a more adaptable and dependable basis for detection. This fourth approach also proposes restoration based on scaled frequency components which, coupled with the low temporal resolution, could be overly invasive and unsettling to the listener.
SUMMARY
[0009] This Summary introduces a selection of concepts in a simplified form in order to provide a basic understanding of some aspects of the present disclosure. This Summary is not an extensive overview of the disclosure, and is not intended to identify key or critical elements of the disclosure or to delineate the scope of the disclosure. This Summary merely
presents some of the concepts of the disclosure as a prelude to the Detailed Description provided below.
[0010] One embodiment of the present disclosure relates to a method for detecting presence of a transient noise in an audio signal, the method comprising: identifying one or more voiced parts of the audio signal; extracting the one or more identified voiced parts from the audio signal, wherein the extraction of the one or more voiced parts yields a residual part of the audio signal; estimating an initial probability of one or more detection states for the residual part of the signal; calculating a transition probability between each of the one or more detection states; and determining a probable detection state for the residual part of the signal based on the initial probabilities of the one or more detection states and the transition probabilities between the one or more detection states.
[0011] In another embodiment, the method for detecting presence of a transient noise further comprises preprocessing the audio signal by recursively subtracting tonal components.
[0012] In another embodiment of the method for detecting presence of a transient noise, the step of preprocessing the audio signal includes decomposing the audio signal into a set of coefficients.
[0013] In another embodiment, the method for detecting presence of a transient noise further comprises performing a time-frequency analysis on the residual part of the audio signal to generate a predictive model of the residual part of the audio signal.
[0014] In another embodiment, the method for detecting presence of a transient noise further comprises recombining the residual part of the audio signal with the one or more extracted voiced parts.
[0015] In another embodiment, the method for detecting presence of a transient noise further comprises determining, based on the residual part of the audio signal, that additional voiced parts remain in the residual part of the audio signal, and extracting one or more of the additional voiced parts from the residual part of the audio signal.
[0016] In yet another embodiment, the method for detecting presence of a transient noise further comprises, prior to recombining the residual part and the one or more extracted voiced parts, determining that the one or more extracted voiced parts include low-frequency
components of the transient noise, and filtering out the low-frequency components of the transient noise from the one or more extracted voiced parts.
[0017] In still another embodiment, the method for detecting presence of a transient noise further comprises modeling additive noise in the residual part of the signal as a zero-mean Gaussian process.
[0018] In another embodiment, the method for detecting presence of a transient noise further comprises modeling additive noise in the residual part of the signal as an autoregressive (AR) process with estimated coefficients.
[0019] In yet another embodiment, the method for detecting presence of a transient noise further comprises identifying corrupted samples of the audio signal based on the estimated detection state, and restoring the corrupted samples in the audio signal;
[0020] In another embodiment of the method for detecting presence of a transient noise, the step of restoring the corrupted samples includes removing the corrupted samples from the audio signal.
[0021] In one or more other embodiments, the methods presented herein may optionally include one or more of the following additional features: the time-frequency analysis is a discrete wavelet transform; the time-frequency analysis is a wavelet packet transform; the one or more voiced parts of the audio signal are identified by detecting spectral peaks in the frequency domain; the spectral peaks are detected by thresholding a median filter output, and/or the one or more additional voiced parts are identified by detecting spectral peaks in the frequency domain for the residual part of the audio signal.
[0022] Further scope of applicability of the present disclosure will become apparent from the Detailed Description given below. However, it should be understood that the Detailed Description and specific examples, while indicating preferred embodiments, are given by way of illustration only, since various changes and modifications within the spirit and scope of the disclosure will become apparent to those skilled in the art from this Detailed Description.
BRIEF DESCRIPTION OF DRAWINGS
[0023] These and other objects, features and characteristics of the present disclosure will become more apparent to those skilled in the art from a study of the following Detailed
Description in conjunction with the appended claims and drawings, all of which form a part of this specification. In the drawings:
[0024] Figure 1 is a block diagram illustrating an example system for detecting the presence of a transient noise event in an audio stream using the incoming audio data according to one or more embodiments described herein.
[0025] Figure 2 is a graphical representation illustrating an example output of voiced signal extraction according to one or more embodiments described herein.
[0026] Figure 3 is a flowchart illustrating an example method for detecting the presence of a transient noise event in an audio stream using the incoming audio data according to one or more embodiments described herein.
[0027] Figure 4 is a graphical representation illustrating an example performance of transient noise detection according to one or more embodiments described herein.
[0028] Figure 5 is a block diagram illustrating an example computing device arranged for detecting the presence of a transient noise event in an audio stream using the incoming audio data according to one or more embodiments described herein.
[0029] The headings provided herein are for convenience only and do not necessarily affect the scope or meaning of what is claimed in the present disclosure.
[0030] In the drawings, the same reference numerals and any acronyms identify elements or acts with the same or similar structure or functionality for ease of understanding and convenience. The drawings will be described in detail in the course of the following Detailed Description.
DETAILED DESCRIPTION
[0031] Various examples and embodiments will now be described. The following description provides specific details for a thorough understanding and enabling description of these examples. One skilled in the relevant art will understand, however, that one or more embodiments described herein may be practiced without many of these details. Likewise, one skilled in the relevant art will also understand that one or more embodiments of the present disclosure can include many other obvious features not described in detail herein.
Additionally, some well-known structures or functions may not be shown or described in detail below, so as to avoid unnecessarily obscuring the relevant description.
[0032] 1. Overview
[0033] Embodiments of the present disclosure relate to methods and systems for detecting the presence of a transient noise event in an audio stream using primarily or exclusively the incoming audio data. Such an approach provides improved temporal resolution and is computationally efficient. As will be described in greater detail below, the methods and systems presented herein utilize some time-frequency representation (e.g., discrete wavelet transform (DWT), wavelet packet transform (WPT), etc.) of an audio signal as the basis in a predictive model in an attempt to find outlying transient noise events. Furthermore, the methods of the present disclosure interpret the true detection state as a Hidden Markov Model (HMM) to model temporal and frequency cohesion common amongst transient noise events.
[0034] As will be further described herein, the algorithm proposed uses a preprocessing stage to decompose an audio signal into a sparse set of coefficients relating to the noise pulses. To minimize false detections, the audio data may be preprocessed by subtracting tonal components recursively, as system resources allow. While this approach detects and restores transient noise events primarily based on a single audio stream, various parameters can be tuned if positive detections can be confirmed via operating system (OS) information or otherwise.
[Θ035] The algorithm presented below exploits the contrast in spectral and temporal characteristics seen between transient noise pulses and speech signals. While switched noise processes are used in a handful of offline applications for detection of noise pulses, some with a sparse basis, these other approaches are batch processing implementations, none of which are suitable for real-time implementation. Additionally, the processing requirements of these existing approaches are not trivial, and thus they cannot feasibly be implemented as part of a real-time communication system.
[0036] Other systems have utilized Markov Chain Monte Carlo (MCMC) methods for modeling temporal and spectral cohesion in two-state detection systems. However, these systems are also considered batch processing implementations with significant computational
requirements. Although the Bayesian restoration step proposed in one or more embodiments of the present disclosure has similarities to other restoration approaches, the Gaussian impulse and background model utilized in the present disclosure dramatically simplifies the restoration to a computationally-efficient implementation, as will be further described herein.
[0037] 2. Detection
[0038] FIG. 1 illustrates an example system for detecting the presence of a transient noise event in an audio stream using the incoming audio data according to one or more embodiments described herein. In at least one embodiment, the detection system 100 may include a voice extraction component 110, a time-frequency detector 120, and interpolation components 130 and 160 for the residual and voiced signals, respectively. Additionally, the detection system 100 may perform an algorithm similar to the algorithm illustrated in FIG. 3, which is described in greater detail below.
[0039] An audio signal 105 input into the detection system 100 may undergo voice extraction 110, resulting in a voiced signal part 150 and a residual signal part 140. Following voice extraction 110, the residual signal part 140 may undergo time-frequency analysis (via the time-frequency detector 120) providing information for the possible restoration step (via the interpolation component 130). The voiced signal 150 may require restoration based on the time-frequency detector 120 findings, which may be performed by the interpolation component 160 for the voiced signal 150. The interpolated voice signal 150 and residual signal 140 may then be recombined to form the output signal. Each of the voice extraction 110, the time-frequency detector 120, and the interpolations 130, 160 will be described in greater detail in the sections that follow.
[0040] It should be noted that, in accordance with at least one embodiment described herein, the detection system 100 may perform the detection algorithm in an iterative manner. For example, once the interpolated voice signal 150 and residual signal 140 are recombined following any necessary restoration processing (e.g., by interpolation components 130 and 160), a determination may be made as to whether further restoration of the signal is needed. If it is found that further restoration is needed, then the recombined signal may be processed again through the various components of the detection system 100. Having removed some of the transient components from the signal during the initial iteration, a subsequent iteration may affect the audio separation and lead to better overall results.
[0041] FIG. 2 illustrates an example output of voiced signal extraction according to one or more embodiments described herein. For example, the output of voice extraction on an input signal 205 (e.g., by the voice extraction component 110 on the input signal 105 in the example system shown in FIG. 1) may include a voiced signal part 250 and a residual signal part 240, (e.g., the voiced signal part 150 and the residual signal part 140 in the example system shown in FIG. 1).
[0042] In the following sections reference may be made to FIG. 3, which illustrates an example process for detecting the presence of a transient noise event in an audio stream using the incoming audio data. In at least one embodiment, the process illustrated may be performed, for example, by the voice extraction component 110, the time-frequency detector 120, and the interpolation components 130, 160 of the detection system 100 shown in FIG. 1 and described above.
[0043] 2.1 Tonal Extractor
[0044] To reduce the rate of false detections, voiced parts of the signal can be extracted (e.g., via the voice extraction 110 of the example detection system shown in FIG. 1). The voiced parts of the signal may be identified and then extracted at blocks 300 and 305, respectively, of the process illustrated in FIG. 3. For example, the voiced parts of the signal may be identified by detecting acoustic resonances, or spectral peaks, in a frequency domain. The voiced parts may then be extracted prior to the detection procedure. Peaks in the spectral domain can be identified, for example, by thresholding a median filter output or by some other peak-detection method.
[0045] At block 310, a determination may be made as to whether further extraction (e.g., voice extraction) is needed. If further extraction is needed, then the process may return to blocks 300 and 305. By repeating the identification and extraction (e.g., at blocks 300 and 305) multiple times for different frame sizes and thresholds, additional voiced parts of the signal may be extracted. If no further extraction is needed at block 310, the process may move to estimating the initial probability for the detection state (block 315), calculating the transition probability between states (block 320), determining the most likely detection state based on the probabilities of each state (block 325), and interpolating the corrupted audio samples (block 330). The operations shown in blocks 315 through 330 will be described in greater detail below.
[0046] In at least one embodiment, after the detection state has been estimated the process may move to block 335 where the voiced parts of the signal may be reintroduced (e.g., following voice extraction 110, time-frequency analysis 120, and interpolation 130, the residual signal part 140 may be recombined with the extracted voiced signal part 150 (e.g., following interpolation 160) as illustrated in FIG. 1).
[0047] The audio signal can now be expressed in the following way: χ( =∑ .Φ,.( +∑^ (ί)Ψ ( (1)
■ J
where ci are the coefficients for the voiced parts of the signal and Φ is a basis function which could be based on standard Fourier, Cepstrum or Gabor analysis, or Voice Speech filters. Also, Wj (t) are the coefficients of the residual part, where j is an integer relating to some translation and/or dilation of some basis function Ψ .
[0048] 2.2 Time-Frequency Analysis of the Residual
[0049] The coefficients Wj (t) from equation (1), above, may be interpreted as wavelet coefficients from a Wavelet Packet Decomposition (WPD) such that j denotes the jth terminal node or scale, j e {1,..., /} , where J = L2 for a level L decomposition. In the following description, n will replace t as the time index in the wavelet coefficients due to the scaling caused by decimation, but for the case of an undecimated transform t = n. Further, win) will be used to denote a vector of all coefficients at a given time index n. It may be assumed that the coefficients for each terminal node j can be modeled as some switched additive noise process such that:
where in . is the binary (1/0) switching variable denoting the presence of θη j for in j = l , and otherwise in j = 0 . The transient signal θη j is thus a switched noise burst corrupted by additive noise vn It should be noted that the grouping of the transient noise bursts may depend on the statistics of in j . Corresponding values of in j at different scales j and with consecutive time indexes n may be modeled as a Markov chain, which will describe some degree of cohesion between frequency and time. For example, the transient noise pulses will
typically have a similar index of onset and will likely stay active for a length of time proportional with wavelet scale j.
[0050] The model may now be expressed in terms of the additive noise and a matrix of coefficients:
\ν = θ + ν , (3) where w = [w1, w2, ... , wJ ] and where Wj = [wl■ , w2■ , ... , wN . ]r for the j'th set of coefficients. Also in equation (3), Θ denotes the corresponding switched noise burst J by N matrix containing elements in j0n j and v is the random additive noise describing, for example, the effect of speech on the coefficients. For simplicity, in j may be considered constant across scales j so the discrete vector i = [i{ ,i2,... ,iN] can take any one of 2N values. Accordingly, the detection task now becomes the estimation of the true state of i from the observed sequence w. In more sophisticated realizations, the i values across different scales may differ from one another, and would be statistically linked together via a hidden Markov tree or similar construction.
[0051] Assuming that both the noise burst Θ and the background noise (e.g., speech) v can be modeled as zero mean Gaussian distributions gives the following: θη ~ Νθπ (0,Α) , (4) where A is a covariance matrix. In one example, the diagonal elements of A may simply be [λί,λ2,...,λ] ] . However, in another example, the diagonal elements of A could also represent more complex variance cohesion. Rather than keeping the variance constant for the duration of the noise pulse, a changing variance model based on some envelope of the changing variance may provide a more accurate match for transients of interest.
[0052] The background noise may similarly be modeled as a zero-mean Gaussian process, such that: v„ ~ NVn (0, Cv ) , (5) where Cv is a covariance matrix. In one example, the diagonal components of Cv may simply be [σν 1 , σν 2 , ... , σν 7 ] . A more computationally-intensive implementation could model v as
an autoregressive (AR) process with estimated coefficients or with a simple averaging coefficient set.
[0053] A straightforward implementation based on AR background noise may assume that each coefficient can be estimated by the M preceding (and possibly succeeding) coefficients in addition to some noise. Treating each scale as independent, the combined likelihood may be calculated by the product of the likelihood from each scale. In such an implementation, transient noise events could be detected by thresholding the combined likelihood. Additional algorithmic details of such an implementation are provided below in "Example Implementation."
[0054] Treating the detection state i as a discrete random vector, the probability of i conditional upon the observed (and corrupted) data w and other prior information available may be determined. Prior information regarding detections may include, for example, information from the operation system (OS), inferred likely detection timings based on recent detection, inferred likely detection timings based on learned information from the user, and the like. In accordance with at least one embodiment, this posterior probability p(i I w) may be expressed using Bayes' rule so that p(w \ i)p(i)
pii I ) = (6) p(w) where the likelihood p(w I i) may be considered the primary part of the calculation.
[0055] As described above, Θ denotes the switched random noise process. The amplitude of this switched random noise process may be defined by the noise burst amplitude p.d.f. ρθ , which is the joint distribution for the burst amplitudes where i„ = l .
[0056] Since both functions pv (v) and ρθ (θ) are zero-mean Gaussians, each set of wavelet coefficients may be expressed as w l (n) , such as the following:
and the likelihood function p(w I i) becomes
J N
P(w \ i) = YlYlN(0, aV ] + in }) . (8) [0057] The Maximum a posteriori (MAP) estimate for in may now be calculated as in MLE = arg m (a0,x1) f[ N(0, σν> . + i } ) . (9)
[0058] In accordance with one or more embodiments of the disclosure, the knowledge that detections usually come in blocks of detections may be incorporated into the model. For example, considering the state vector i as a HMM, specific knowledge about the nature of expected detections may be incorporated into the model. In at least one embodiment, the Viterbi algorithm may be used to calculate the most likely evolution of i or sequence of in. The most likely detection state given a sequence of data may be expressed as:
!MLE = arg p(i„ I in_,)p(w(n) I i . (io)
In equation (10), p(i0) is the starting probability, p(in I i^) is the transition probability from one state to the next, and p(w(n) I in) is the emission probability or the observation probability.
[0059] In accordance with at least one embodiment of the disclosure, an extension to the algorithm described above and illustrated in FIG. 3 may include running the entire algorithm in an iterative manner. For example, the process may move from block 335, where the voiced parts of the signal may be reintroduced and combined with the residual signal part (e.g., following voice extraction 110, time-frequency analysis 120, and interpolation 130, the residual signal part 140 may be recombined with the extracted voiced signal part 150, as illustrated in FIG. 1), to block 340 where it is determined whether further restoration of the signal is needed (represented by broken lines in FIG. 3). If it is determined at block 340 that further restoration is needed, the process may return to block 300 and repeat. Having removed some of the transient components from the signal during the previous iteration, this next iteration may affect the audio separation and lead to better overall results. If it is determined at block 340 that no further restoration is needed, the process may end.
[0060] FIG. 4 illustrates an example performance of transient noise detection in accordance with one or more of the embodiments described herein. In the example graphical representation, where the step function 405 indicates detections, a detection is found at the high value and no detection at the low value. The detections 405 are also an indication of possible areas for interpolation with components 130 and 160 as illustrated in FIG. 1.
[0061] In the example case shown in FIG. 4, the detected state agrees with the ground truth for the example and the transients are picked up despite the surrounding voiced signal. The step function 405 indicates a range of corrupted samples and not just a single detection at each transient noise event. This is because the algorithm, in this case, correctly determines an appropriate number of corrupted samples. The benefit of using a decomposition with good temporal resolution is that the detection onset and duration can be more accurately determined and corrupted frames can be dealt with in a less intrusive manner.
[0062] 3. Interpolation
[0063] Having estimated the most likely state of i, as described in the previous sections above, it is now possible to interpolate corrupted samples (e.g., values of w(n) at time n for which in = 1) using one or more of a variety of methods.
[0064] In at least one embodiment, a Bayesian approach may proceed by estimating p(vn I wn,in)■ For example, using Bayes' rule gives the following: p n 1 w n > ) ~ P 1 vn > )p( n ι *„ ) , a i) where p(wn \ vn, in = l) ~ N(wn, A) , (12) and p(vn \ in) = p(vn) ~ N(0, Cv) . (13)
[0065] Substituting equations (12) and (13) into equation (11) where the product is proportional to a third Gaussian gives the following: p(vn I wn, in = l) oc N((CV + A)-1 vw„, (C 1 + Λ"1)-1) . (14)
In this case, where both the background noise vn and the noise burst θη are Gaussian, estimating the mean of the conditional distribution equates to simply scaling corrupted samples by a factor of (Cv + A)~1 CV in a Wiener-style wavelet shrinkage. The simple form of such estimation should be noted in the above case with diagonal covariance matrices.
[0066] In one or more other embodiments, a more straightforward restoration approach may entirely remove the offending coefficients while a more complex approach may attempt to fill-in the corrupted coefficients with an AR process trained on preceding and succeeding coefficients.
[0067] In accordance with at least one embodiment of the disclosure, having estimated the most likely state of in , it may further be necessary to filter out any low-frequency (e.g., below a predetermined threshold frequency) components of the transient noise that were removed/extracted with the voiced speech (e.g., voiced signal part 150 as shown in FIG. 1).
[0068] Following the restoration process, the algorithm may proceed by recombining the processed residual signal part (e.g., with the keystrokes removed) and the dictionary of tonal components from equation (1).
[0069] 4. Example Implementation
[0070] The following describes an example implementation for detecting transient noise events in accordance with at least one embodiment of the present disclosure. It should be noted that this example implementation is of a simplified embodiment that has had the Bayesian/HMM components removed and replaced with a traditional AR model-based detector for the transient noise. As such, the following is provided merely for purposes of illustration, and is not in any way intended to limit the scope of the present disclosure.
[0071] The present example is based on AR background noise and assumes that each coefficient can be estimated by the M preceding (and possibly succeeding) coefficients in addition to some noise (where "M" is an arbitrary number). Treating each scale as independent, the combined likelihood may be calculated by the product of the likelihood from each scale. In such an implementation, transient noise events could be detected by thresholding the combined likelihood. Additional algorithmic details of such an implementation are provided below.
[0072] The terminal node coefficients of a WPD, or some other time-frequency analysis coefficients, of an incoming audio sequence x(n) of length N may be defined as X(j,t), where j is thej'th terminal node (scale or frequency), j e {1,...,/} , and t is the time index related to n. A level L WPD gives J = 2L terminal nodes. In the following, X(t) may be used to denote a vector of all coefficients at a given time index t. Additionally, it may be assumed that the coefficients for each terminal node j follow the linear predictive model
M
= , aj,mXU, t-m) + v(j, t) , (15) m=l where am is the mth weight applied to the j'th terminal node so that = {a^1,...,a^M}, is the size of the buffer used, and v(j,t) is Gaussian noise with zero mean so that v(j,t)~Nv(0,^). (16)
[0073] The probability of X(j,t) conditional on prior values of X may now be expressed as p(X(j,t)\X(j,t-l),...,X(j,t-M)) = Nx {j,t-mXo)t
and the marginal probability may be expressed as
assuming that the conditional probabilities for each set of coefficients are independent.
[0074] The log-likelihood log L = log p(X(t)) for the current coefficient X(t) may be calculated as logL = log^ \p(X(j,t)\X(j,t-l),...,X(j,t-M))^ (i9)
=∑logL = log{p(XO-,i)|xa,i-l),...,XO",i- ))}
where C^t is a constant. The value log L is now a measure of how well X(t) can be predicted by its previous values.
[0075] FIG. 5 is a block diagram illustrating an example computing device 500 that is arranged for detecting the presence of a transient noise event in an audio stream using the incoming audio data in accordance with one or more embodiments of the present disclosure. For example, computing device 500 may be configured to utilize a time-frequency representation of an incoming audio signal as the basis in a predictive model in an attempt to find outlying transient noise events, as described above. In accordance with at least one embodiment, the computing device 500 may further be configured to interpret the true detection state as a Hidden Markov Model (HMM) to model temporal and frequency cohesion common amongst transient noise events. In a very basic configuration 501 , computing device 500 typically includes one or more processors 510 and system memory 520. A memory bus 530 may be used for communicating between the processor 510 and the system memory 520.
[0076] Depending on the desired configuration, processor 510 can be of any type including but not limited to a microprocessor (μΡ), a microcontroller (μ(ϋ), a digital signal processor (DSP), or any combination thereof. Processor 510 may include one or more levels of caching, such as a level one cache 51 1 and a level two cache 512, a processor core 513, and registers 514. The processor core 513 may include an arithmetic logic unit (ALU), a floating point unit (FPU), a digital signal processing core (DSP Core), or any combination thereof. A memory controller 515 can also be used with the processor 510, or in some embodiments the memory controller 515 can be an internal part of the processor 510.
[0077] Depending on the desired configuration, the system memory 520 can be of any type including but not limited to volatile memory (e.g., RAM), non-volatile memory (e.g., ROM, flash memory, etc.) or any combination thereof. System memory 520 typically includes an operating system 521 , one or more applications 522, and program data 524. In one or more embodiments, application 522 may include a detection algorithm 523 that is configured to detect the presence of a transient noise event in an audio stream (e.g., input
signal 105 as shown in the example system of FIG. 1) using primarily or exclusively the incoming audio data. For example, in one or more embodiments the detection algorithm 523 may be configured to perform preprocessing on an incoming audio signal to decompose the signal into a sparse set of coefficients relating to the noise pulses and then perform time- frequency analysis on the decomposed signal to determine a likely detection state. As part of the preprocessing, the detection algorithm 523 may be further configured to perform voice extraction on the input audio signal to extract the voiced signal parts (e.g., via the voice extraction component 110 of the example detection system shown in FIG. 1).
[0078] Program Data 524 may include audio signal data 525 that is useful for detecting the presence of transient noise in an incoming audio stream. In some embodiments, application 522 can be arranged to operate with program data 524 on an operating system 521 such that the detection algorithm 523 uses the audio signal data 525 to perform voice extraction, time-frequency analysis, and interpolation (e.g., voice extraction 110, time- frequency detector 120, and interpolation 130 in the example detection system 100 shown in FIG. 1).
[0079] Computing device 500 can have additional features and/or functionality, and additional interfaces to facilitate communications between the basic configuration 501 and any required devices and interfaces. For example, a bus/interface controller 540 can be used to facilitate communications between the basic configuration 501 and one or more data storage devices 550 via a storage interface bus 541. The data storage devices 550 can be removable storage devices 551, non-removable storage devices 552, or any combination thereof. Examples of removable storage and non-removable storage devices include magnetic disk devices such as flexible disk drives and hard-disk drives (HDD), optical disk drives such as compact disk (CD) drives or digital versatile disk (DVD) drives, solid state drives (SSD), tape drives and the like. Example computer storage media can include volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information, such as computer readable instructions, data structures, program modules, and/or other data.
[0080] System memory 520, removable storage 551 and non-removable storage 552 are all examples of computer storage media. Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital
versatile disks (DVD) or other optical storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by computing device 500. Any such computer storage media can be part of computing device 500.
[0081] Computing device 500 can also include an interface bus 542 for facilitating communication from various interface devices (e.g., output interfaces, peripheral interfaces, communication interfaces, etc.) to the basic configuration 501 via the bus/interface controller 540. Example output devices 560 include a graphics processing unit 561 and an audio processing unit 562, either or both of which can be configured to communicate to various external devices such as a display or speakers via one or more A/V ports 563. Example peripheral interfaces 570 include a serial interface controller 571 or a parallel interface controller 572, which can be configured to communicate with external devices such as input devices (e.g., keyboard, mouse, pen, voice input device, touch input device, etc.) or other peripheral devices (e.g., printer, scanner, etc.) via one or more I/O ports 573.
[0082] An example communication device 580 includes a network controller 581, which can be arranged to facilitate communications with one or more other computing devices 590 over a network communication (not shown) via one or more communication ports 582. The communication connection is one example of a communication media. Communication media may typically be embodied by computer readable instructions, data structures, program modules, or other data in a modulated data signal, such as a carrier wave or other transport mechanism, and includes any information delivery media. A "modulated data signal" can be a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example, and not limitation, communication media can include wired media such as a wired network or direct-wired connection, and wireless media such as acoustic, radio frequency (RF), infrared (IR) and other wireless media. The term computer readable media as used herein can include both storage media and communication media.
[0083] Computing device 500 can be implemented as a portion of a small-form factor portable (or mobile) electronic device such as a cell phone, a personal data assistant (PDA), a personal media player device, a wireless web-watch device, a personal headset device, an application specific device, or a hybrid device that include any of the above functions.
Computing device 500 can also be implemented as a personal computer including both laptop computer and non-laptop computer configurations.
[0084] There is little distinction left between hardware and software implementations of aspects of systems; the use of hardware or software is generally (but not always, in that in certain contexts the choice between hardware and software can become significant) a design choice representing cost versus efficiency trade-offs. There are various vehicles by which processes and/or systems and/or other technologies described herein can be effected (e.g., hardware, software, and/or firmware), and the preferred vehicle will vary with the context in which the processes and/or systems and/or other technologies are deployed. For example, if an implementer determines that speed and accuracy are paramount, the implementer may opt for a mainly hardware and/or firmware vehicle; if flexibility is paramount, the implementer may opt for a mainly software implementation. In one or more other scenarios, the implementer may opt for some combination of hardware, software, and/or firmware.
[0085] The foregoing detailed description has set forth various embodiments of the devices and/or processes via the use of block diagrams, flowcharts, and/or examples. Insofar as such block diagrams, flowcharts, and/or examples contain one or more functions and/or operations, it will be understood by those skilled within the art that each function and/or operation within such block diagrams, flowcharts, or examples can be implemented, individually and/or collectively, by a wide range of hardware, software, firmware, or virtually any combination thereof.
[0086] In one or more embodiments, several portions of the subject matter described herein may be implemented via Application Specific Integrated Circuits (ASICs), Field Programmable Gate Arrays (FPGAs), digital signal processors (DSPs), or other integrated formats. However, those skilled in the art will recognize that some aspects of the embodiments described herein, in whole or in part, can be equivalently implemented in integrated circuits, as one or more computer programs running on one or more computers (e.g., as one or more programs running on one or more computer systems), as one or more programs running on one or more processors (e.g., as one or more programs running on one or more microprocessors), as firmware, or as virtually any combination thereof. Those skilled in the art will further recognize that designing the circuitry and/or writing the code for
the software and/or firmware would be well within the skill of one of skilled in the art in light of the present disclosure.
[0087] Additionally, those skilled in the art will appreciate that the mechanisms of the subject matter described herein are capable of being distributed as a program product in a variety of forms, and that an illustrative embodiment of the subject matter described herein applies regardless of the particular type of signal-bearing medium used to actually carry out the distribution. Examples of a signal-bearing medium include, but are not limited to, the following: a recordable-type medium such as a floppy disk, a hard disk drive, a Compact Disc (CD), a Digital Video Disk (DVD), a digital tape, a computer memory, etc.; and a transmission-type medium such as a digital and/or an analog communication medium (e.g., a fiber optic cable, a waveguide, a wired communications link, a wireless communication link, etc.)
[0088] Those skilled in the art will also recognize that it is common within the art to describe devices and/or processes in the fashion set forth herein, and thereafter use engineering practices to integrate such described devices and/or processes into data processing systems. That is, at least a portion of the devices and/or processes described herein can be integrated into a data processing system via a reasonable amount of experimentation. Those having skill in the art will recognize that a typical data processing system generally includes one or more of a system unit housing, a video display device, a memory such as volatile and non-volatile memory, processors such as microprocessors and digital signal processors, computational entities such as operating systems, drivers, graphical user interfaces, and applications programs, one or more interaction devices, such as a touch pad or screen, and/or control systems including feedback loops and control motors (e.g., feedback for sensing position and/or velocity; control motors for moving and/or adjusting components and/or quantities). A typical data processing system may be implemented utilizing any suitable commercially available components, such as those typically found in data computing/communication and/or network computing/communication systems.
[0089] With respect to the use of substantially any plural and/or singular terms herein, those having skill in the art can translate from the plural to the singular and/or from the singular to the plural as is appropriate to the context and/or application. The various singular/plural permutations may be expressly set forth herein for sake of clarity.
[0090] While various aspects and embodiments have been disclosed herein, other aspects and embodiments will be apparent to those skilled in the art. The various aspects and embodiments disclosed herein are for purposes of illustration and are not intended to be limiting, with the true scope and spirit being indicated by the following claims.
Claims
1. A method for detecting presence of a transient noise in an audio signal, the method comprising:
identifying (300) one or more voiced parts of the audio signal;
extracting (305) the one or more identified voiced parts from the audio signal, wherein the extraction of the one or more voiced parts yields a residual part of the audio signal;
estimating (315) an initial probability of one or more detection states for the residual part of the signal;
calculating (320) a transition probability between each of the one or more detection states; and
determining (325) a probable detection state for the residual part of the signal based on the initial probabilities of the one or more detection states and the transition probabilities between the one or more detection states.
2. The method of claim 1, further comprising preprocessing the audio signal by recursively subtracting tonal components.
3. The method of claim 2, wherein preprocessing the audio signal includes decomposing the audio signal into a set of coefficients.
4. The method of claim 1 , further comprising performing a time-frequency analysis on the residual part of the audio signal to generate a predictive model of the residual part of the audio signal.
5. The method of claim 4, wherein the time-frequency analysis is a discrete wavelet transform.
6. The method of claim 4, wherein the time-frequency analysis is a wavelet packet transform.
7. The method of claim 1, further comprising recombining (335) the residual part of the audio signal with the one or more extracted voiced parts.
8. The method of claim 7, further comprising determining (340), based on the recombined residual part with the one or more extracted voiced parts, whether to perform further restoration of the audio signal.
9. The method of claim 7, further comprising, prior to recombining the residual part and the one or more extracted voiced parts:
determining that the one or more extracted voiced parts include low-frequency components of the transient noise; and
filtering out the low-frequency components of the transient noise from the one or more extracted voiced parts.
10. The method of claim 1, wherein the one or more voiced parts of the audio signal are identified by detecting spectral peaks in the frequency domain.
11. The method of claim 10, wherein the spectral peaks are detected by thresholding a median filter output.
12. The method of claim 1, further comprising modeling additive noise in the residual part of the signal as a zero-mean Gaussian process.
13. The method of claim 1, further comprising modeling additive noise in the residual part of the signal as an autoregressive (AR) process with estimated coefficients.
14. The method of claim 1, further comprising:
identifying corrupted samples of the audio signal based on the estimated detection state; and
restoring (330) the corrupted samples in the audio signal;
15. The method of claim 14, wherein restoring the corrupted samples includes removing the corrupted samples from the audio signal.
16. The method of claim 1, further comprising:
determining, based on the residual part of the audio signal, that additional voiced parts remain in the residual part of the audio signal; and
extracting one or more of the additional voiced parts from the residual part of the audio signal.
17. The method of claim 16, wherein the one or more additional voiced parts are identified by detecting spectral peaks in the frequency domain for the residual part of the audio signal.
18. The method of claim 17, wherein the spectral peaks are detected by thresholding a median filter output.
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US13/781,262 US9520141B2 (en) | 2013-02-28 | 2013-02-28 | Keyboard typing detection and suppression |
PCT/US2014/015999 WO2014133759A2 (en) | 2013-02-28 | 2014-02-12 | Keyboard typing detection and suppression |
Publications (1)
Publication Number | Publication Date |
---|---|
EP2929533A2 true EP2929533A2 (en) | 2015-10-14 |
Family
ID=50236268
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
EP14708368.7A Withdrawn EP2929533A2 (en) | 2013-02-28 | 2014-02-12 | Keyboard typing detection and suppression |
Country Status (6)
Country | Link |
---|---|
US (1) | US9520141B2 (en) |
EP (1) | EP2929533A2 (en) |
JP (1) | JP6147873B2 (en) |
KR (1) | KR101729634B1 (en) |
CN (1) | CN105190751B (en) |
WO (1) | WO2014133759A2 (en) |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN111444382A (en) * | 2020-03-30 | 2020-07-24 | 腾讯科技（深圳）有限公司 | Audio processing method and device, computer equipment and storage medium |
Families Citing this family (10)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9721580B2 (en) * | 2014-03-31 | 2017-08-01 | Google Inc. | Situation dependent transient suppression |
US10755726B2 (en) * | 2015-01-07 | 2020-08-25 | Google Llc | Detection and suppression of keyboard transient noise in audio streams with auxiliary keybed microphone |
EP3059656B1 (en) | 2015-07-13 | 2017-04-26 | Advanced Digital Broadcast S.A. | System and method for managing display-related resources |
EP3059655B1 (en) | 2015-07-13 | 2017-04-26 | Advanced Digital Broadcast S.A. | Method for managing display-related resources |
CN108470220B (en) * | 2018-01-31 | 2021-11-30 | 天津大学 | Hybrid energy storage system energy management optimization method considering power change rate limitation |
US10812562B1 (en) * | 2018-06-21 | 2020-10-20 | Architecture Technology Corporation | Bandwidth dependent media stream compression |
US10862938B1 (en) | 2018-06-21 | 2020-12-08 | Architecture Technology Corporation | Bandwidth-dependent media stream compression |
CN110838299B (en) * | 2019-11-13 | 2022-03-25 | 腾讯音乐娱乐科技（深圳）有限公司 | Transient noise detection method, device and equipment |
TWI723741B (en) * | 2020-01-14 | 2021-04-01 | 酷碁科技股份有限公司 | Button device and button voice suppression method |
CN111370033B (en) * | 2020-03-13 | 2023-09-22 | 北京字节跳动网络技术有限公司 | Keyboard sound processing method and device, terminal equipment and storage medium |
Family Cites Families (26)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
IL84948A0 (en) * | 1987-12-25 | 1988-06-30 | D S P Group Israel Ltd | Noise reduction system |
US5680508A (en) * | 1991-05-03 | 1997-10-21 | Itt Corporation | Enhancement of speech coding in background noise for low-rate speech coder |
TW384434B (en) * | 1997-03-31 | 2000-03-11 | Sony Corp | Encoding method, device therefor, decoding method, device therefor and recording medium |
CN1188830C (en) * | 2002-06-28 | 2005-02-09 | 清华大学 | An impact and noise resistance process of limiting observation probability minimum value in a speech recognition system |
US7424423B2 (en) * | 2003-04-01 | 2008-09-09 | Microsoft Corporation | Method and apparatus for formant tracking using a residual model |
US7389230B1 (en) * | 2003-04-22 | 2008-06-17 | International Business Machines Corporation | System and method for classification of voice signals |
US7454336B2 (en) * | 2003-06-20 | 2008-11-18 | Microsoft Corporation | Variational inference and learning for segmental switching state space models of hidden speech dynamics |
US7353169B1 (en) | 2003-06-24 | 2008-04-01 | Creative Technology Ltd. | Transient detection and modification in audio signals |
US7643989B2 (en) * | 2003-08-29 | 2010-01-05 | Microsoft Corporation | Method and apparatus for vocal tract resonance tracking using nonlinear predictor and target-guided temporal restraint |
US8170875B2 (en) * | 2005-06-15 | 2012-05-01 | Qnx Software Systems Limited | Speech end-pointer |
US7664643B2 (en) * | 2006-08-25 | 2010-02-16 | International Business Machines Corporation | System and method for speech separation and multi-talker speech recognition |
US8019089B2 (en) | 2006-11-20 | 2011-09-13 | Microsoft Corporation | Removal of noise, corresponding to user input devices from an audio signal |
PL2118889T3 (en) | 2007-03-05 | 2013-03-29 | Ericsson Telefon Ab L M | Method and controller for smoothing stationary background noise |
US20080219466A1 (en) * | 2007-03-09 | 2008-09-11 | Her Majesty the Queen in Right of Canada, as represented by the Minister of Industry, through | Low bit-rate universal audio coder |
US8654950B2 (en) | 2007-05-08 | 2014-02-18 | Polycom, Inc. | Method and apparatus for automatically suppressing computer keyboard noises in audio telecommunication session |
US8121311B2 (en) * | 2007-11-05 | 2012-02-21 | Qnx Software Systems Co. | Mixer with adaptive post-filtering |
US8213635B2 (en) | 2008-12-05 | 2012-07-03 | Microsoft Corporation | Keystroke sound suppression |
US8908882B2 (en) | 2009-06-29 | 2014-12-09 | Audience, Inc. | Reparation of corrupted audio signals |
GB0919672D0 (en) | 2009-11-10 | 2009-12-23 | Skype Ltd | Noise suppression |
JP5538918B2 (en) | 2010-01-19 | 2014-07-02 | キヤノン株式会社 | Audio signal processing apparatus and audio signal processing system |
US9628517B2 (en) | 2010-03-30 | 2017-04-18 | Lenovo (Singapore) Pte. Ltd. | Noise reduction during voice over IP sessions |
US8411874B2 (en) | 2010-06-30 | 2013-04-02 | Google Inc. | Removing noise from audio |
JP5328744B2 (en) | 2010-10-15 | 2013-10-30 | 本田技研工業株式会社 | Speech recognition apparatus and speech recognition method |
US9111526B2 (en) * | 2010-10-25 | 2015-08-18 | Qualcomm Incorporated | Systems, method, apparatus, and computer-readable media for decomposition of a multichannel music signal |
US8239196B1 (en) * | 2011-07-28 | 2012-08-07 | Google Inc. | System and method for multi-channel multi-feature speech/noise classification for noise suppression |
US20140114650A1 (en) * | 2012-10-22 | 2014-04-24 | Mitsubishi Electric Research Labs, Inc. | Method for Transforming Non-Stationary Signals Using a Dynamic Model |
-
2013
- 2013-02-28 US US13/781,262 patent/US9520141B2/en active Active
-
2014
- 2014-02-12 CN CN201480005008.5A patent/CN105190751B/en active Active
- 2014-02-12 JP JP2015557216A patent/JP6147873B2/en active Active
- 2014-02-12 KR KR1020157023964A patent/KR101729634B1/en active IP Right Grant
- 2014-02-12 EP EP14708368.7A patent/EP2929533A2/en not_active Withdrawn
- 2014-02-12 WO PCT/US2014/015999 patent/WO2014133759A2/en active Application Filing
Non-Patent Citations (1)
Title |
---|
See references of WO2014133759A2 * |
Cited By (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN111444382A (en) * | 2020-03-30 | 2020-07-24 | 腾讯科技（深圳）有限公司 | Audio processing method and device, computer equipment and storage medium |
CN111444382B (en) * | 2020-03-30 | 2021-08-17 | 腾讯科技（深圳）有限公司 | Audio processing method and device, computer equipment and storage medium |
Also Published As
Publication number | Publication date |
---|---|
KR101729634B1 (en) | 2017-04-24 |
US20140244247A1 (en) | 2014-08-28 |
KR20150115885A (en) | 2015-10-14 |
WO2014133759A2 (en) | 2014-09-04 |
JP6147873B2 (en) | 2017-06-14 |
CN105190751A (en) | 2015-12-23 |
US9520141B2 (en) | 2016-12-13 |
CN105190751B (en) | 2019-06-04 |
WO2014133759A3 (en) | 2014-11-06 |
JP2016510436A (en) | 2016-04-07 |
WO2014133759A4 (en) | 2015-01-15 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US9520141B2 (en) | Keyboard typing detection and suppression | |
CN110634497B (en) | Noise reduction method and device, terminal equipment and storage medium | |
CN108615535B (en) | Voice enhancement method and device, intelligent voice equipment and computer equipment | |
US8019089B2 (en) | Removal of noise, corresponding to user input devices from an audio signal | |
CN110767223B (en) | Voice keyword real-time detection method of single sound track robustness | |
CN107113521B (en) | Keyboard transient noise detection and suppression in audio streams with auxiliary keybed microphones | |
US20140067388A1 (en) | Robust voice activity detection in adverse environments | |
CN107086043B (en) | Method and apparatus for detecting audio signal | |
Awad | Impulse noise reduction in audio signal through multi-stage technique | |
Harvilla et al. | Least squares signal declipping for robust speech recognition | |
Khaldi et al. | Voiced/unvoiced speech classification‐based adaptive filtering of decomposed empirical modes for speech enhancement | |
US11610601B2 (en) | Method and apparatus for determining speech presence probability and electronic device | |
KR20120056661A (en) | Apparatus and method for preprocessing of speech signal | |
JP4891805B2 (en) | Reverberation removal apparatus, dereverberation method, dereverberation program, recording medium | |
Harvilla et al. | Efficient audio declipping using regularized least squares | |
US8275612B2 (en) | Method and apparatus for detecting noise | |
KR20180041072A (en) | Device and method for audio frame processing | |
CN107919136B (en) | Digital voice sampling frequency estimation method based on Gaussian mixture model | |
JP7152112B2 (en) | Signal processing device, signal processing method and signal processing program | |
Indumathi et al. | An efficient speaker recognition system by employing BWT and ELM | |
Badiezadegan et al. | A wavelet-based data imputation approach to spectrogram reconstruction for robust speech recognition | |
JPWO2015093025A1 (en) | Audio processing apparatus, audio processing method, and audio processing program | |
CN111951791B (en) | Voiceprint recognition model training method, electronic equipment and storage medium | |
Luo et al. | Adaptive Noise Reduction Algorithm Based on SPP and NMF for Environmental Sound Event Recognition under Low-SNR Conditions | |
Jancovic et al. | On the mask modeling and feature representation in the missing-feature ASR: evaluation on the Consonant Challenge. |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PUAI | Public reference made under article 153(3) epc to a published international application that has entered the european phase |
Free format text: ORIGINAL CODE: 0009012 |
|
17P | Request for examination filed |
Effective date: 20150709 |
|
AK | Designated contracting states |
Kind code of ref document: A2Designated state(s): AL AT BE BG CH CY CZ DE DK EE ES FI FR GB GR HR HU IE IS IT LI LT LU LV MC MK MT NL NO PL PT RO RS SE SI SK SM TR |
|
AX | Request for extension of the european patent |
Extension state: BA ME |
|
DAX | Request for extension of the european patent (deleted) | ||
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: THE APPLICATION IS DEEMED TO BE WITHDRAWN |
|
18D | Application deemed to be withdrawn |
Effective date: 20160901 |
|
P01 | Opt-out of the competence of the unified patent court (upc) registered |
Effective date: 20230519 |