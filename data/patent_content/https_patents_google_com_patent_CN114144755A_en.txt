CN114144755A - Autofocus detection with relative threshold aware cell visibility for scrolling sets of cells - Google Patents
Autofocus detection with relative threshold aware cell visibility for scrolling sets of cells Download PDFInfo
- Publication number
- CN114144755A CN114144755A CN202080048036.0A CN202080048036A CN114144755A CN 114144755 A CN114144755 A CN 114144755A CN 202080048036 A CN202080048036 A CN 202080048036A CN 114144755 A CN114144755 A CN 114144755A
- Authority
- CN
- China
- Prior art keywords
- visual
- cells
- cell
- gui
- reference frame
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0484—Interaction techniques based on graphical user interfaces [GUI] for the control of specific functions or operations, e.g. selecting or manipulating an object, an image or a displayed text element, setting a parameter value or selecting a range
- G06F3/0485—Scrolling or panning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0481—Interaction techniques based on graphical user interfaces [GUI] based on specific properties of the displayed interaction object or a metaphor-based environment, e.g. interaction with desktop elements like windows or icons, or assisted by a cursor's changing behaviour or appearance
- G06F3/04812—Interaction techniques based on cursor appearance or behaviour, e.g. being affected by the presence of displayed objects
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0484—Interaction techniques based on graphical user interfaces [GUI] for the control of specific functions or operations, e.g. selecting or manipulating an object, an image or a displayed text element, setting a parameter value or selecting a range
- G06F3/0485—Scrolling or panning
- G06F3/04855—Interaction with scrollbars
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0484—Interaction techniques based on graphical user interfaces [GUI] for the control of specific functions or operations, e.g. selecting or manipulating an object, an image or a displayed text element, setting a parameter value or selecting a range
- G06F3/04842—Selection of displayed objects or displayed text elements
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0487—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser
- G06F3/0488—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser using a touch-screen or digitiser, e.g. input of commands through traced gestures
- G06F3/04886—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser using a touch-screen or digitiser, e.g. input of commands through traced gestures by partitioning the display area of the touch-screen or the surface of the digitising tablet into independently controllable areas, e.g. virtual keyboards or menus
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/10—Text processing
- G06F40/166—Editing, e.g. inserting or deleting
- G06F40/177—Editing, e.g. inserting or deleting of tables; using ruled lines
- G06F40/18—Editing, e.g. inserting or deleting of tables; using ruled lines of spreadsheets
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F2203/00—Indexing scheme relating to G06F3/00 - G06F3/048
- G06F2203/048—Indexing scheme relating to G06F3/048
- G06F2203/04804—Transparency, e.g. transparent or translucent windows
Abstract
A system and method for autofocus detection with relative threshold aware cell visibility of a rolling set of cells is disclosed. The method includes identifying a visual cell of a plurality of cells of a reference frame, the visual cell rendered in a Graphical User Interface (GUI) displaying at least a portion of the reference frame, determining, by a processing device rendering the GUI and for each visual cell of the visual cells, a distance value indicating a distance to a focus threshold in the reference frame that the visual cell has traveled since the visual cell became visible in the GUI, and modifying behavior of the visual cell in the GUI based on the distance value of each visual cell.
Description
Technical Field
Aspects and embodiments of the present disclosure relate to display processing, and more particularly, to auto-focus detection with relative threshold aware cell visibility of a scrolling set of cells.
Background
The media viewer application enables a user to view content, such as images, videos, web pages, documents, and the like. For example, the media viewer may be a web browser capable of accessing, retrieving, rendering, and/or navigating content (e.g., web pages such as hypertext markup language (HTML) pages, digital media items or content items, etc.) provided by a web server. The media viewer may render, display, and/or present content (e.g., web pages, documents) to the user. The media viewer may also display an embedded media player (e.g.,
The media viewer may provide a Graphical User Interface (GUI) to display received content (e.g., documents, pages, etc.). The size of the content may exceed the available space for display on the GUI. In this case, the GUI displays only a part of the content. The content itself can be divided into one or more cells that can scroll vertically or horizontally for display in the GUI. The cells may be rectangular arrays of pixel values within the content rendered in the GUI. The cells can represent different logical portions and/or graphical elements of the content being rendered. For example, a cell may represent an item in a video player portion of content being rendered, an advertisement portion of content, a feed or activity portion of content, and so forth.
Disclosure of Invention
The following presents a simplified summary of various aspects of the disclosure in order to provide a basic understanding of such aspects. This summary is not an extensive overview of all contemplated aspects, and is intended to neither identify key or critical elements nor delineate the scope of such aspects. Its purpose is to present some concepts of the disclosure in a simplified form as a prelude to the more detailed description that is presented later.
In one aspect of the disclosure, a system and method of autofocus detection with relative threshold aware cell visibility of a rolling set of cells is disclosed. In one embodiment, a method includes identifying a visual cell of a plurality of cells of a reference frame, displaying at least a portion of the reference frame in a visual cell rendered in a Graphical User Interface (GUI), determining, by a processing device rendering the GUI, a distance value for each visual cell of the visual cells, the distance value indicating a distance to a focus threshold in the reference frame that the visual cell has traveled since the visual cell became visible in the GUI, and modifying behavior of the visual cells in the GUI based on the distance value for each visual cell.
In one embodiment, the focus threshold indicates a location where a visual cell in the reference frame becomes a focused cell in the GUI. In some implementations, the distance value includes a relative threshold visibility percentage. Further, determining the relative threshold visibility percentage may include identifying unselected ones of the visual cells in the visual window of the reference frame, determining a threshold cutoff point for the unselected visual cells, determining a first distance between a window edge of the visual window and the threshold cutoff point, determining a second distance between a cell edge of the unselected visual cells and the threshold cutoff point, and determining the relative threshold visibility percentage for the unselected visual cells based on the first distance and the second distance.
In one embodiment, the focused cells include visual cells that are most likely to be focused on in the GUI, and in response to being identified as one of the focused cells, a different cell behavior is applied to the visual cell. Additionally, the visual cells may include one or more cells of a reference frame having at least one pixel rendered in the GUI. In some implementations, the GUI corresponds to a visual window within a scrolling container of the reference frame, wherein the scrolling container includes a plurality of sets of cells that are capable of at least one of scrolling horizontally or vertically within the scrolling container, and wherein at least a portion of the visual cells are in the visual window.
In some implementations, the plurality of cells each include a rectangular array of pixels of the reference frame that correspond to logically separate portions of the reference frame. Additionally, the method may further include identifying visual cells having an absolute visibility percentage that exceeds a threshold visibility percentage, selecting a determined number of the identified visual cells as focused cells based on a number of focused cells specified for the GUI, sorting the identified visual cells into sorted visual cells according to a priority sorting order, selecting a determined number of the highest sorted visual cells as focused cells; and returning the recognition result of the focused cell and the distance value of each visual cell. In one embodiment, the prioritization order is based on at least one of a top-to-bottom direction, a bottom-to-top direction, a left-to-right direction, or a right-to-left direction.
In some embodiments, the modifying act includes applying the distance value to the visual cell to provide a color blending effect in the visual cell according to a particular value of the distance value. Further, the modifying act may include performing data pre-extraction of the visual cells based on the distance values of the visual cells. In one embodiment, the distance value is provided to the server device for data records corresponding to the visual cell.
Further, computing devices for performing the operations of the above-described methods and various embodiments described herein are disclosed. Also disclosed are computer-readable media storing instructions for performing operations associated with the above-described methods and various embodiments described herein.
Drawings
Aspects and embodiments of the present disclosure will be understood more fully from the detailed description given below and from the accompanying drawings of various aspects and embodiments of the disclosure, which, however, should not be taken to limit the disclosure to the specific aspects or embodiments, but are for explanation and understanding only.
FIG. 1 depicts an illustrative computer system architecture in accordance with one or more aspects of the present disclosure.
Fig. 2 is an example reference frame depicting a vertically scrolling container for determining relative threshold perceptual visibility of cells of the reference frame, in accordance with an embodiment of the present disclosure.
Fig. 3 depicts a flow diagram of one example of a method for determining a distance value corresponding to a visual cell in a reference frame of a Graphical User Interface (GUI) according to one or more aspects of the present disclosure.
Fig. 4 depicts a flowchart of one example of a method for determining a relative threshold visibility percentage of cells of a reference frame in accordance with one or more aspects of the present disclosure.
Fig. 5 depicts a flowchart of one example of a method for applying a relative threshold visibility percentage to a cell behavior modification of a cell in a reference frame in accordance with one or more aspects of the present disclosure.
Fig. 6 depicts a block diagram of an illustrative computer system operating in accordance with one or more aspects of the present disclosure.
Detailed Description
The media viewer application enables a user to view content, such as images, videos, web pages, documents, and the like. For example, the media viewer may be a web browser capable of accessing, retrieving, rendering, and/or navigating content (e.g., web pages such as hypertext markup language (HTML) pages, digital media items or content items, etc.) provided by a web server. The media viewer may render, display, and/or present content (e.g., web pages, documents) to the user. The media viewer may also display an embedded media player (e.g.,
The media viewer may provide a Graphical User Interface (GUI) to display received content (e.g., documents, pages (e.g., hypertext markup language (HTML) pages), etc.). The size of the content may exceed the available space for display on the GUI. When the content exceeds the space available for display, the GUI displays a portion (or subset) of the content at any given point in time. The content can be represented as a reference frame. The reference frame may be a data set representing the received content to be rendered. The content portion displayed in the GUI can be represented as a visual window that scrolls horizontally or vertically within the reference frame.
The reference frame can be divided into one or more cells that can scroll vertically or horizontally for display in the GUI. The cell may be a rectangular array of pixels in the content. The cells can represent different logical portions of content and/or graphical elements. For example, a cell may represent an item in a video player portion of content being rendered, an advertisement portion of content, a feed or activity portion of content, and so forth.
In conventional systems, the media viewer may provide specific or specialized processing (e.g., automatic playback of video, color processing, etc.) to the cells in the GUI based on the cells' visibility. A cell may be considered a visible cell when at least one pixel corresponding to the cell is rendered in the GUI. One or more visual cells in the GUI may be selected as focused cells. The focused cell is the visual cell that is most likely to be focused on (e.g., by the user) in the GUI. However, conventional systems that select focused cells typically do not provide information about other visual cells in the GUI that are not selected as focused cells ("unselected visual cells"). In conventional systems, no information is provided about the unselected visual cells, which indicates how close the cells are to becoming the focused cells.
Embodiments of the present disclosure propose to determine a distance value of a visual cell in a reference frame corresponding to content to be rendered. The distance value may be a relative threshold visibility percentage that can be used as an objective index to determine how close the unselected visible cells are to becoming the focused cells. In embodiments of the present disclosure, the relative threshold visibility percentage refers to the proportion of the distance the visual cell (in the reference frame) has traveled to the focus threshold since the visual cell became visible in the visual window (e.g., GUI) of the reference frame. In one embodiment, the focus threshold refers to the location in the reference frame where the visual cell is to be selected as the focused cell in the GUI.
The relative threshold visibility percentages provided by embodiments of the present disclosure allow for better control and/or monitoring of the non-selected visual cells. For example, data regarding the relative threshold visibility percentage of unselected visual cells may support features including, but not limited to: visibility threshold aware animation (e.g., color blending application based on relative threshold visibility percentages of cells), data pre-extraction (e.g., initiating a pre-extraction mechanism based on relative threshold visibility percentages of cells), or improving attention logging on cells at a server device (e.g., relative threshold visibility percentages provide information about how close a cell is to a focused cell).
Accordingly, aspects of the present disclosure provide a mechanism by which additional focus-based information is determined for all visual cells of a reference frame of content being rendered in a GUI. In particular, aspects of the present disclosure propose determining a relative threshold visibility percentage of visible cells in a reference frame. As described above, this mechanism allows for better control and monitoring of unselected visual cells in the reference frame. An advantage of embodiments of the present disclosure is improved support for features that affect the behavior of unselected visual cells, such as visibility threshold perception animation, data pre-extraction, and improved detailed record data about the visual cells. This improved support can then be used to optimize the user experience with respect to the GUI provided in embodiments of the present disclosure.
Fig. 1 illustrates an illustrative system architecture 100 according to one embodiment of the disclosure. The system architecture 100 includes one or more server machines (e.g., depicting an example server machine 120), a content repository 110, and a client machine (e.g., depicting an example client device 102) connected to a network 104. The network 104 may be a public network (e.g., the internet), a private network (e.g., a Local Area Network (LAN) or a Wide Area Network (WAN)), or a combination thereof.
The client device 102 may be a Personal Computer (PC), notebook computer, mobile phone, tablet computer, set-top box, television, video game console, digital assistant, or any other computing device. The client device 102 may run an Operating System (OS) that manages the hardware and software of the client device 102. In one implementation, the client device 102 may upload the video to a network server (such as the media server 125 discussed below) for storage and/or processing.
The server machine 120 may be a rack-mounted server, a router computer, a personal computer, a portable digital assistant, a mobile phone, a notebook computer, a tablet computer, a camera, a camcorder, a netbook, a desktop computer, a media center, or any combination of the above. The server machine 120 includes a media server 125 that is capable of receiving and providing content (e.g., videos, audio clips, images, etc.) uploaded by client machines, such as the client device 102 (e.g., via web pages, via applications, etc.).
The content items stored in the content repository 110 may include user-generated media items uploaded by client machines, as well as media items from service providers such as news agencies, publishers, libraries, and the like. In some implementations, the content repository 110 may be provided by a third party service, while in some other implementations, the content repository 110 may be maintained by the same entity that maintains the server machine 120. In some examples, content repository 110 and server 120 may be part of a content sharing platform that allows users to upload, consume, search, approve ("like"), dislike, and/or comment on media items.
The content sharing platform may include a plurality of channels. The channels can be data content available from a common source or data content having a common topic, theme, or theme. The data content can be user-selected digital content, user-provided digital content, user-uploaded digital content, content provider-selected digital content, broadcaster-selected digital content, and the like. A channel can be associated with an owner, who is a user who can perform an operation on the channel. Based on the owner's actions, different activities can be associated with the channel, such as the owner making digital content available on the channel, the owner selecting (e.g., liking) digital content associated with another channel, the owner commenting on digital content associated with another channel, and so forth. The activity associated with a channel can be collected into an activity feed for the channel. Users other than the channel owner can subscribe to one or more channels of interest to them. The concept of "subscribe" may also be referred to as "like", "focus", "buddy", and the like.
Each channel may include one or more media items. Examples of media items can include, but are not limited to, digital videos, digital movies, digital photos, digital music, website content, social media updates, electronic books (ebooks), electronic magazines, digital newspapers, digital audiobooks, electronic periodicals, web blogs, Really Simple Syndication (RSS) feeds, electronic caricatures, software applications, and so forth. In some implementations, the media items are also referred to as video content items.
The media items may be consumed via a media viewer 105 executing on the client device 102. In one implementation, the media viewer 105 may be an application that allows a user to view content such as images, videos (e.g., video content items), web pages, documents, and so forth. For example, the media viewer 105 may be a web browser capable of accessing, retrieving, rendering, and/or navigating content (e.g., web pages such as hypertext markup language (HTML) pages, digital media items or content items, etc.) provided by a web server. The media viewer 105 may render, display, and/or present content (e.g., web pages, media viewers) to a user. The media viewer 105 may also display an embedded media player (e.g.,
The media viewer 105 may be provided to the client device 102 by the server 120 and/or the content sharing platform. For example, the media viewer 105 may be an embedded media player embedded in a web page provided by the content sharing platform. In another example, media viewer 105 may be an application that communicates with server 120 and/or a content sharing platform.
Embodiments of the present disclosure provide for autofocus detection with relative threshold aware cell visibility of a scrolling set of cells. In one embodiment, the media viewer 105 includes a visibility component 107 for providing autofocus detection with relative threshold aware cell visibility of a scrolling set of cells. As described above, the media viewer 105 may provide a GUI to display received content, such as a document or page to be rendered in the GUI. In one implementation, the received content may include one or more content items from the media server 125.
In some implementations, the size of the received content to be rendered at the client device 102 may exceed the available space for display on the client-provided GUI. In this case, the GUI displays a portion of the content at any given time. The received content for rendering by the GUI may be represented as a reference frame. The reference frame can be divided into one or more cells that can be scrolled vertically or horizontally for display in the GUI (i.e., a scrolling set of cells (SCC)). Each cell may be a rectangular array of pixel values within the content being rendered in the GUI. The cell sizes in the reference frames can be different or may not be uniform. As described above, the cells can represent different logical portions and/or graphical elements of the content being rendered. For example, a cell may represent an item in a video player portion of content being rendered, an advertisement portion of content, a feed or activity portion of content, and so forth.
The content displayed in the GUI provided by the media viewer 105 at a particular point in time may correspond to a visual window within a scrolling container of reference frames. The rolling container includes a plurality of sets of cells of a reference frame that can be rolled horizontally or vertically within the rolling container. A cell of the plurality of cells visible in the visible window is referred to as a visible cell. The visual cells in the visual window include any cells of a reference frame having at least one pixel rendered in a GUI (e.g., the visual window). For purposes of discussion herein, the terms GUI and visual window may be used interchangeably.
In some implementations, the media viewer 105 can apply specialized processing (e.g., automatic playback of video, color processing, etc.) to cells in the reference frame based on the visibility of the cells in the visual window rendered in the GUI. In particular, one or more visual cells in the GUI may be considered focused cells. A focused cell may refer to a visual cell in the GUI that is most likely to be focused on (e.g., by the user). However, as previously described, conventional systems for selecting a focused cell do not provide information about cells in the visual window that are not selected as focused cells (referred to herein as unselected visual cells). For example, in conventional systems, no information is provided regarding unselected visual cells indicating how close the cells are to becoming focused cells.
Embodiments of the present disclosure provide for the determination of a distance value (e.g., relative threshold visibility percentage) of a visible cell in a reference frame. The distance value (e.g., relative threshold visibility percentage) is used as an objective index to determine how close the unselected visual cells are to becoming the focused cells. In one implementation, visibility component 107 of media viewer 105 of client device 102 determines a relative threshold visibility percentage. In some implementations, visibility component 107 can determine a relative threshold visibility at each frame refresh of the GUI (e.g., according to a frame refresh rate of the GUI). Visibility component 107 may determine a relative threshold visibility percentage at other time intervals in accordance with an embodiment of the present disclosure.
The relative threshold visibility percentage provided by embodiments of the present disclosure allows for better control and/or monitoring of unselected visual cell behavior. For example, data regarding the relative threshold visibility percentage of unselected visual cells may support the following features: including, but not limited to, visibility threshold aware animation (e.g., color blending application to unselected visual cells), data pre-fetching (e.g., initiating a pre-fetch mechanism using a relative threshold visibility percentage of unselected visual cells), or improving attention recording of unselected visual cells at the server device. In one embodiment, the cell behavior component 109 of the media viewer 105 may receive relative threshold visibility percentage data for visual cells of a reference frame (rendered in the GUI of the media viewer 105) and cause particular cell behavior characteristics (e.g., color blending, data prefetching, etc.) to be applied to unselected visual cells according to the particular associated relative threshold visibility percentage of the cells.
Specifically, in one example of a color blending application, the cell behavior component 109 applies red to the focused cell while applying yellow to the unselected visual cells in the reference frame. The particular intensity value of yellow applied to the unselected visual cells may be determined by the cell behavior component 109 using a relative threshold visibility percentage of the unselected visual cells, where the yellow blends with an increasing hue of the red as the relative threshold visibility percentage approaches 100%. In this way, the relative threshold visibility percentage of the unselected visual cells may be used by the cell behavior component 109 to calculate a particular intensity value for yellow and/or red applied to the unselected visual cells.
In another example of a data pre-extraction usage for a relative threshold visibility percentage, the cell behavior component 109 can initiate data pre-extraction of content in the unselected visual cells in response to the relative threshold visibility percentage of the unselected visual cells exceeding a determined threshold. Similarly, the cell behavior component 109 can perform data pre-extraction of content in the unselected visual cells according to the relative threshold visibility percentage of the unselected visual cells, such that if the relative threshold visibility percentage of the cells is 10%, the amount of pre-extracted content for the cells is also 10%, and so on.
In embodiments of the present disclosure, the relative threshold visibility percentage refers to the proportion of the distance the visual cell has traveled to the focus threshold since the visual cell became visible in the GUI. In one embodiment, the focus threshold indicates a location in the reference frame where the visible cell will become the focused cell in the GUI.
The following discussion provides further explanation of the visibility component 107 of the media viewer 105 determining the relative threshold visibility percentage of cells in a reference frame. In one embodiment, the content received at the media viewer 105 may be represented as a scrolling cell Set (SCC). An SCC is a rectangular container with a limited or unlimited number of consecutive rectangular cells (C0, C1, C2..) that can roll horizontally or vertically within the SCC. WSCC and HSCC are the width and height of the SCC, respectively. The SCC is also characterized by the rectangular area (visible window) it encloses. WSCC _ Visible _ Window and HSCC _ Visible _ Window are the width and height of the SCC visual Window, respectively. If the SCC scrolls vertically, WSCC _ Visible _ Window >0 and HSCC > -HSCC _ Visible _ Window > 0. If the SCC scrolls horizontally, HSCC _ Visable _ Window >0 and WSCC > -WSCC _ Visable _ Window > 0. At any given time, because the SCC has a scrolling mechanism, a subset of its cells can be fully or partially visible within the visible window, and are referred to as visible cells.
Each of these visible cells may have absolute vertical and horizontal visibility percentages, which represent the percentage of their width and height that are visible within the visible window. Each cell contained in the SCC has vertical and horizontal visibility threshold percentages that can be arbitrarily, subjectively, or objectively set (e.g., by an interface designer). The threshold vertical and horizontal visibility percentages represent the minimum limit of cells that are considered to be fully visible in the viewable window. In one embodiment, a cell is considered to be partially visible when at least one pixel of the cell is rendered in a visible window. The cell may remain partially visible until its absolute visibility percentage exceeds the threshold visibility percentage for the cell.
Given an SCC cell Cx, Absolute _ Visibility _ Percentage _ Vertical _ Cx and Absolute _ Visibility _ Percentage _ Horizontal _ Cx are the Absolute Vertical and Horizontal Visibility percentages calculated for the cell Cx, respectively. Further, Threshold _ Visibility _ Percentage _ Vertical _ Cx and Threshold _ Visibility _ Percentage _ Horizontal _ Cx are given Threshold Vertical and Horizontal Visibility percentages, respectively, of the cell Cx. Finally, Relative _ Threshold _ Visibility _ percent and Relative _ Threshold _ Visibility _ percent _ Horizontal _ Cx are the Vertical and Horizontal Relative Threshold Visibility percentages, respectively, of the cell Cx calculated according to the disclosed embodiments described herein. The discussion below with respect to fig. 2 further discusses a process for determining a relative threshold visibility percentage.
Embodiments of the present disclosure may perform a selection process that determines which cell should be the focused cell (also referred to as "focused" or "selected") within the viewable window. Criteria for making a focused cell determination for a cell include, at a given time:
1.SCC
SCC visual window;
SCC visual cells;
i. for each one, (arbitrarily) given:
Threshold_Visibility_Percentage_Vertical_Cx，
Threshold_Visibility_Percentage_horizontal_Cx；
for each, calculating:
Absolute_Visibility_Percentage_Vertical_Cx，
Absolute_Visibility_Percentage_horizontal_Cx；
4. a prioritized order (also referred to as a sort order) (i.e., from top to bottom or bottom to top (for vertically scrolling SCCs), from leftmost to rightmost, or from rightmost to leftmost (for horizontally scrolling SCCs)); and
5. the maximum number of visible cells is selected as the focus cell (max _ number _ selection), and can be arbitrarily set (max _ number _ selection > 1).
Given the above input criteria, embodiments of the present disclosure may perform the following processes: for each visual cell, Relative _ Threshold _ visual _ persistence _ Vertical _ Cx and Relative _ Threshold _ visual _ persistence _ horizontal _ Cx are determined. For a vertically scrolling SCC, embodiments of the present disclosure may select the cell of which Absolute _ Visivity _ Perceptivity _ Verticai _ Cx > Threshold _ Visivity _ Perceptivity _ Verticai _ Cx among the visual cells. Similarly, for a SCC that scrolls horizontally, embodiments of the present disclosure may select its Absolute _ visual _ persistence _ horizontal _ Cx > Threshold _ visual _ persistence _ horizontal _ Cx in the visual cell.
Subsequently, from the cells selected above, embodiments of the present disclosure may select the top max _ number _ selection visual cells according to the sort order. As described above, the sort order (also referred to herein as a priority sort order) is based on at least one of a top-to-bottom direction, a bottom-to-top direction, a left-to-right direction, or a right-to-left direction. In one embodiment, this sort order may be based on a typical reading direction of the set of users (e.g., a typical reading direction from left to right or a typical reading direction from left to right). Embodiments of the present disclosure may output "selected" or "focused cells," as well as a relative threshold visibility percentage determined for each visible cell.
Accordingly, embodiments of the present disclosure can facilitate visibility percentage aware scrolling processing through, for example, the cell behavior component 109. For example, animation (collection view on any device with a screen) within the software SCC may be supported, where cells can adjust their behavior based not only on whether the cell has been selected as a focused cell but also on the relative threshold visibility percentage of cells. Embodiments of the present disclosure may also be used in such a way that the "focus" or "select" criteria can be personalized for a given viewer of the SCC.
Generally, the functions described in one embodiment as being performed by the content item sharing platform and server machine 120 may also be performed on the client device 102 in other embodiments, if appropriate. In addition, the functionality attributed to a particular component can be performed by different or multiple components operating together. The content sharing platform and/or server 120 can also be accessed as a service provided to other systems or devices through an appropriate application programming interface and is therefore not limited to use in a website.
In addition to the above, a user may be provided with controls that allow the user to select whether and when the systems, programs, or features described herein are capable of collecting user information (e.g., information about the user's social network, social actions or activities, profession, user preferences, or the user's current location), and whether to send content or communications from a server to the user. In addition, some data may be processed in one or more ways before being stored or used, such that personally identifiable information is removed. For example, the user's identity may be processed such that no personal identity information can be determined for the user, or the user's geographic location may be generalized to the place where the location information is obtained (e.g., city, zip code, or state level) such that no particular location of the user can be determined. Thus, the user may have control over what information is collected about the user, how the information is used, and what information is provided to the user.
Fig. 2 illustrates an example reference frame 200 depicting a vertically scrolling container located in a reference frame for determining relative threshold perceptual visibility of cells of the reference frame, according to an embodiment of the present disclosure. The reference frame 200 may correspond to content received from a server to be rendered on a client device, such as content received by the client device 102 from the media server 125 described with reference to fig. 1. For example, the reference frame 200 may correspond to pixels of a document or page to be rendered on a display of a client machine, such as the client device 102.
Reference frame 200 shows a vertically scrolling container 201 located in reference frame 200. As shown in reference frame 200, the scrolling container 201 includes a plurality of cells including cell 1202 a, cell 0202 b, cell n-1202 c, and cell n202d, which are disposed in one or more viewable area 240 and/or non-viewable area 245 of the scrolling container 201. The visible region 240 may be referred to herein as a "visual window" and is a portion of the reference frame 200 rendered in the GUI. For purposes of explanation, the reference frame 200 is depicted as having an input for determining a relative threshold visibility percentage for the cell n202 d. In one embodiment, visibility component 107, described with reference to FIG. 1, may determine a relative threshold visibility percentage for cell n202 d.
In the example of fig. 2, assume that the inputs to the process of determining the relative threshold visibility percentage are such that: ScrollView ═ scroll container 201, numSelected ═ 2 (e.g., the number of selected focus cells), and sortPriority ═ top-to-bottom (e.g., prioritized order). The reference frame 200 may also include the following values, as shown in fig. 2. The Scroll Content Offset (SCO) (dy)210 indicates how far the viewable area 240 of the scroll container 201 has scrolled (i.e., from the top of the reference frame 200). Cell 0202 b is determined to be the leading "selected" cell or the furthest selected cell from cell n202 d. In one embodiment, cell 0202 b can be determined by: ScrollView. getCellAtIndex (MAX (0, Cell _ n. vertical index-numSelected)).
The visible height of cell n202d is shown as vhtn 205d and may be determined as follows: VisibleHeight _ Cell _ n (vis _ height _ cn) ═ Cell _ n.height ═ Cell _ n.visibilitythreshold. The visible height of cell 0202 b, shown as vht 0205 b, may be determined as follows: VisibleHeight _ Cell _0(vis _ height _ c0) ═ Cell0.height Cell0. visibilitythreshold.
The minimum unfocused distance of cell n202d is shown as mdn 206d and may be determined as follows: min _ unfocus _ distance _ Cell _ n (Min _ udcn) ═ Cell _ n. In one embodiment, if cell n202d is the topmost visible cell, this is the minimum distance (top to bottom) that cell n202d becomes unfocused (or deselected). The minimum unfocused distance of cell 0202 b is shown as mud 0206 b and may be determined as follows: min _ unfocus _ distance _ Cell _0(Min _ udc0) ═ Cell0.height-vis _ height _ c 0. If cell 0202 b is the uppermost visible cell, this is the minimum distance (bottom to top) that cell 0202 b becomes unfocused (or deselected).
The minimum focus distance for cell n202d is shown as dtc 260 and may be determined as follows: min _ focused _ distance _ cell _ n (Min _ fdcn) ═ MAX (Min _ udcn, Min _ udc 0). dtc 260 is the distance (bottom to top) that cell n202d must travel in order to be selected.
The bottom cut-off threshold 280 is the bottom cut-off point at which cell n202d becomes in focus or selected if scrolled from the bottom of the reference frame 200 to the top of the reference frame 200. In some embodiments, the bottom cutoff threshold 280 is the same as the focus threshold discussed above. In embodiments of the present disclosure, the bottom cutoff threshold 280 may also be referred to as a threshold cutoff point. The distance of cell n202d from the bottom cutoff threshold 280 is referred to as dbcn 207 and may be determined as follows: b _ cutOff _ n ═ dy + (Cell _ n.y-Cell 0.y) -min _ fdcn. The top cut-off threshold 290 is the top cut-off point at which cell n202d becomes focused or selected if scrolled from the top of the reference frame 200 to the bottom of the reference frame 200. In some embodiments, the top cutoff threshold 290 is the same as the focus threshold discussed above. In an embodiment of the present disclosure, the top cutoff threshold 290 may also be referred to as a threshold cutoff point. The distance of cell n202d to the top cutoff threshold 290 may be determined as follows: t _ cutOff _ n is dy-min _ udcn.
In one embodiment, an example process (pseudo-code) to determine the vertical relative threshold visibility percentage for cell n202d may be as follows:
float verticalRelativeVisibilityRatio；
float distanceToEdge；
float distanceToCutoff；
if(Cell_n.y>＝b_cutOff_n){//cell is below b_cutOff_n
distanceToEdge＝b_cutOff_n-dy；
distanceToCutoff＝b_cutOff_n-Cell_n.yt_origin.y；
verticalRelativeVisibilityRatio＝ABS(distanceToEdge-
distanceToCutoff)/distanceToEdge；
}else if(Cell_n.y<＝t_cutOff_n){//cell is above t_cutOff_n
distanceToEdge＝dy；
distanceToCutoff＝Cell_n.y-t_cutOff_n；
verticalRelativeVisibilityRatio＝ABS(distanceToEdge-
distanceToCutoff)/distanceToEdge；
}else{//cell is in selection range
verticalRelativeVisibilityRatio＝1.0；
}
return verticalRelativeVisibilityRatio*100；
fig. 3 depicts a flowchart of one example of a method 300 for determining a distance value corresponding to a visual cell in a reference frame of a GUI, in accordance with one or more aspects of the present disclosure. The method is performed by processing logic that may comprise hardware (circuitry, dedicated logic, etc.), software (such as is run on a general purpose computer system or a dedicated machine), or a combination of both. In one embodiment, the method is performed by computer system 100 of FIG. 1, while in some other embodiments, one or more blocks of FIG. 3 may be performed by one or more other machines not shown in the figures. In some aspects, one or more blocks of fig. 3 may be performed by visibility component 107 and/or cell behavior component 109 of client device 102 of fig. 1.
For simplicity of explanation, the methodologies are depicted and described as a series of acts. However, acts in accordance with the present disclosure can occur in various orders and/or concurrently, and with other acts not presented and described herein. Moreover, not all illustrated acts may be required to implement a methodology in accordance with the disclosed subject matter. In addition, those skilled in the art will understand and appreciate that the methodologies could alternatively be represented as a series of interrelated states via a state diagram or events. Moreover, it should be appreciated that the methodologies disclosed herein are capable of being stored on an article of manufacture to facilitate transporting and transferring such methodologies to computing devices. The term article of manufacture, as used herein, is intended to encompass a computer program accessible from any computer-readable device or storage media.
The method 300 begins at block 301, where a visual cell of a plurality of cells of a reference frame is identified, the visual cell rendered in the GUI displaying at least a portion of the reference frame. The GUI may render a visual window corresponding to a reference frame of the received content. In one embodiment, a visual cell refers to one or more cells of a reference frame having at least one pixel rendered in the GUI.
At block 302, for each of the visual cells, a distance value is determined. In one embodiment, the distance value is a relative threshold visibility percentage as discussed herein. The distance value can indicate the distance that the visual cell has traveled to the focus threshold in the reference frame since the visual cell became visible in the GUI. In one embodiment, the focus threshold indicates a location in the reference frame where the visible cell will become the focused cell in the GUI.
At block 303, the behavior of the visual cells in the GUI is modified based on the distance value for each visual cell. In one embodiment, the behavioral modification of the visual cells may include, but is not limited to, visibility threshold aware animation (e.g., color blending application to the visual cells), data pre-extraction (e.g., initiating a pre-extraction mechanism using a relative threshold visibility percentage of the visual cells), or improving the attention recording of the visual cells at the server device. In one embodiment, the distance values of the visual cells of the reference frame (rendered in the GUI) are used to cause a particular cell behavior feature (e.g., color blending, data pre-extraction, etc.) to be applied to the visual cells according to the particular associated distance values of the cells.
Fig. 4 depicts a flow diagram of one example of a method 400 for determining a relative threshold visibility percentage of cells of a reference frame in accordance with one or more aspects of the present disclosure. The method is performed by processing logic that may comprise hardware (circuitry, dedicated logic, etc.), software (such as is run on a general purpose computer system or a dedicated machine), or a combination of both. In one embodiment, the method is performed by computer system 100 of FIG. 1, while in some other embodiments, one or more blocks of FIG. 4 may be performed by one or more other machines not depicted in the figure. In some aspects, one or more blocks of fig. 4 may be performed by visibility component 107 of client device 102 of fig. 1.
The method 400 begins at block 401, where unselected visual cells are identified in a visual window that scrolls relative to a reference frame. In one example, the visual window is the visual area 240 discussed with respect to fig. 2. An unselected visual cell may refer to a visual cell in the reference frame that is not selected as a focused cell. In one embodiment, the unselected visual cells are the same as cell n202d described with respect to FIG. 2.
At block 402, a threshold cutoff point is determined for the unselected visual cells. In some embodiments, the threshold cutoff point may be the same as the focus threshold discussed above, and may also refer to the bottom cutoff threshold 280 or the top cutoff threshold 290 discussed with reference to fig. 2. In one embodiment, the threshold cut-off point is a point in the reference frame that, when reached by an unselected visual cell, becomes a focused cell.
At block 403, a first distance between a window edge of the visual window and a threshold cutoff point is determined. In one embodiment, the first distance is the same as dte 270 described with respect to fig. 2. At block 404, a second distance between a cell edge of the unselected visual cell and the threshold cutoff point is determined. In one embodiment, the second distance is the same as dtc 260 described with reference to fig. 2.
At block 405, a relative threshold visibility percentage of the unselected visual cells is determined based on the first distance and the second distance. In one embodiment, the relative threshold visibility percentage may be a ratio of the value of the first distance minus the second distance relative to the first distance (e.g., (first distance-second distance)/first distance). In various embodiments of the present disclosure, other combinations of first and second distances may be utilized to determine the relative threshold visibility percentage.
Fig. 5 depicts a flowchart of one example of a method 500 for applying a relative threshold visibility percentage to a cell behavior modification of a cell in a reference frame, in accordance with one or more aspects of the present disclosure. The method is performed by processing logic that may comprise hardware (circuitry, dedicated logic, etc.), software (such as is run on a general purpose computer system or a dedicated machine), or a combination of both. In one embodiment, the method is performed using visibility component 107 and/or cell behavior component 109 of client device 102 of FIG. 1.
The method 500 begins at block 501 where a focused cell of a visual window of a reference frame is identified. In one embodiment, a focused cell may refer to a visual cell that is most likely to be focused on (e.g., focused on by a user) in a GUI rendering a portion of a reference frame that includes multiple cells.
At block 502, a relative threshold visibility percentage is determined for each visual cell in the visual window. The relative threshold visibility percentage may refer to the proportion of the distance the visual cell has traveled to the focus threshold in the reference frame since the visual cell became visible in the visual window. In one embodiment, the focus threshold indicates a location in the reference frame where the visible cell will become the focused cell in the GUI.
At block 503, cell behavior modification is applied to the focused cell and other visible cells based on the relative threshold visibility percentage. In one embodiment, cell behavior modification may include visibility threshold perception animation (e.g., color blending application to unselected visual cells), data pre-extraction (e.g., initiating a pre-extraction mechanism using a relative threshold visibility percentage), or improving attention records regarding cells.
Finally, at block 504, a visual window is provided for rendering in the GUI. In one embodiment, the visual cell depicts the cell behavior modification applied at block 503.
Fig. 6 depicts a block diagram of an illustrative computer system 600 operating in accordance with one or more aspects of the present disclosure. In various illustrative examples, computer system 600 may correspond to a computing device within system architecture 100 of fig. 1. In some embodiments, computer system 600 may be connected (e.g., via a network 630, such as a Local Area Network (LAN), intranet, extranet, or the internet) to other computer systems. The computer system 600 may operate in the capacity of a server or a client computer in a client-server environment, or as a peer computer in a peer-to-peer or distributed network environment. Computer system 600 may be provided by a Personal Computer (PC), a tablet PC, a set-top box (STB), a Personal Digital Assistant (PDA), a cellular telephone, a network appliance, a server, a network router, switch or bridge, or any device capable of executing a set of instructions (sequential or otherwise) that specify actions to be taken by that device. Furthermore, the term "computer" shall include any collection of computers that individually or jointly execute a set (or multiple sets) of instructions to perform any one or more of the methodologies discussed herein.
In another aspect, computer system 600 may include a processing device 602, volatile memory 604 (e.g., Random Access Memory (RAM)), non-volatile memory 606 (e.g., read-only memory (ROM) or electrically erasable programmable ROM (eeprom)), and a data storage device 616, which may communicate with each other via a bus 608.
The processing device 602 may be provided by one or more processors, such as a general-purpose processor (e.g., a Complex Instruction Set Computing (CISC) microprocessor, a Reduced Instruction Set Computing (RISC) microprocessor, a Very Long Instruction Word (VLIW) microprocessor, a microprocessor implementing other types of instruction sets, or a microprocessor implementing a combination of multiple types of instruction sets) or a special-purpose processor (e.g., an Application Specific Integrated Circuit (ASIC), a Field Programmable Gate Array (FPGA), a Digital Signal Processor (DSP), or a network processor).
The computer system 600 may also include a network interface device 622. Computer system 600 may also include a video display unit 610 (e.g., an LCD), an alphanumeric input device 612 (e.g., a keyboard), a cursor control device 614 (e.g., a mouse), and a signal generation device 620.
The data storage device 616 may include a non-transitory computer-readable storage medium 624 on which instructions 626 encoding any one or more of the methods or functions described herein may be stored, including instructions for implementing the methods 300-500 of fig. 3-5, respectively.
The instructions 626 may also reside, completely or partially, within the volatile memory 604 and/or within the processing device 602 during execution thereof by the computer system 600, and thus the volatile memory 604 and the processing device 602 may also constitute machine-readable storage media.
While the computer-readable storage medium 624 is shown in an illustrative example to be a single medium, the term "computer-readable storage medium" should be taken to include a single medium or multiple media (e.g., a centralized or distributed database, and/or associated caches and servers) that store the one or more sets of executable instructions. The term "computer-readable storage medium" shall also be taken to include any tangible medium that is capable of storing or encoding a set of instructions for execution by the computer and that cause the computer to perform any one or more of the methodologies described herein. The term "computer readable storage medium" shall include, but not be limited to, solid-state memories, optical media, and magnetic media.
The methods, components and features described herein may be implemented by discrete hardware components or may be integrated in the functionality of other hardware components such as ASICs, FPGAs, DSPs or similar devices. Additionally, the methods, components and features may be implemented by component modules or functional circuits within a hardware device. Furthermore, the methods, components and features may be implemented in any combination of hardware devices and computer program components, or in a computer program.
Unless specifically stated otherwise, terms such as "generating," "providing," "training," or the like, refer to the action and processes performed or effected by a computer system that manipulates and transforms data represented as physical (electronic) quantities within the computer system's registers and memories into other data similarly represented as physical quantities within the computer system memories or registers or other such information storage, transmission or display devices. Furthermore, the terms "first," "second," "third," "fourth," and the like, as used herein, refer to labels used to distinguish between different elements, and may not have an ordinal meaning according to their numerical designation.
Examples described herein also relate to an apparatus for performing the methods described herein. The apparatus may be specially constructed for carrying out the methods described herein, or it may comprise a general purpose computer system selectively programmed by a computer program stored in the computer system. Such a computer program may be stored in a computer readable tangible storage medium.
The methods and illustrative examples described herein are not inherently related to any particular computer or other apparatus. Various general purpose systems may be used with the teachings described herein, or it may prove convenient to construct a more specialized apparatus to perform the methods 300-500 and/or their respective functions, routines, subroutines, or operations. Examples of the structure of various of these systems are set forth in the description above.
The above description is intended to be illustrative, and not restrictive. While the present disclosure has been described with reference to specific illustrative examples and embodiments, it will be appreciated that the present disclosure is not limited to the described examples and embodiments. The scope of the disclosure should be determined with reference to the appended claims, along with the full scope of equivalents to which such claims are entitled.
Claims (20)
1. A method, comprising:
identifying a visual cell of a plurality of cells of a reference frame, the visual cell rendered in a Graphical User Interface (GUI) displaying at least a portion of the reference frame;
determining, by a processing device rendering the GUI, a distance value for each of the visual cells, the distance value indicating a distance that the visual cell has traveled to a focus threshold in the reference frame since the visual cell became visible in the GUI; and
modifying behavior of visual cells in the GUI based on the distance value for each of the visual cells.
2. The method of claim 1, wherein the focus threshold indicates a location in the reference frame where the visual cell becomes a focused cell in the GUI.
3. The method of claim 2, wherein the distance value comprises a relative threshold visibility percentage, and wherein determining the relative threshold visibility percentage comprises:
identifying unselected ones of the visual cells in a visual window of the reference frame;
determining a threshold cutoff point for the unselected visual cells;
determining a first distance between a window edge of the visual window and the threshold cutoff point;
determining a second distance between a cell edge of the unselected visible cell and the threshold cutoff point; and
determining the relative threshold visibility percentage of the unselected visible cells based on the first distance and the second distance.
4. The method of claim 2, wherein the focused cells include visual cells that are most likely to be focused on in the GUI, and wherein, in response to identifying one of the focused cells, a different cell behavior is applied to the visual cells.
5. The method of claim 1, wherein the visual cells comprise one or more cells of the reference frame having at least one pixel rendered in the GUI.
6. The method of claim 1, wherein the GUI corresponds to a visual window within a scrolling container of the reference frame, wherein the scrolling container comprises a set of multiple cells that are at least one of horizontally or vertically scrollable within the scrolling container, and wherein at least a portion of the visual cells are in the visual window.
7. The method of claim 1, wherein the plurality of cells each comprise a rectangular array of pixels of the reference frame corresponding to a logically separate portion of the reference frame.
8. The method of claim 1, further comprising:
identifying visible cells having an absolute visibility percentage that exceeds a threshold visibility percentage;
selecting a determined number of the identified visual cells as focused cells based on the number of focused cells specified for the GUI;
sorting the identified visual cells into ordered visual cells according to a priority sorting order;
selecting the determined number of ordered visual cells that are highest ranked as the focused cell; and
returning the identification of the focused cell and the distance value for each of the visible cells,
wherein the prioritization order is based on at least one of a top-to-bottom direction, a bottom-to-top direction, a left-to-right direction, or a right-to-left direction.
9. The method of claim 1, wherein modifying the behavior comprises applying the distance value to the visual cell to provide a color blending effect in the visual cell according to a particular value of the distance value.
10. The method of claim 1, wherein modifying the behavior comprises performing data pre-extraction of the visual cell based on the distance value of the visual cell.
11. The method of claim 1, wherein the distance value is provided to a server device for a data record corresponding to the visual cell.
12. An apparatus, comprising:
a memory;
a display device for rendering a graphical user interface, GUI; and
a processing device operatively coupled to the memory and the display device to:
rendering the GUI;
identifying a visual cell of a plurality of cells of a reference frame, the visual cell rendered in a Graphical User Interface (GUI) displaying at least a portion of the reference frame;
determining, for each of the visual cells, a distance value indicative of a distance that the visual cell has traveled to a focus threshold in the reference frame since the visual cell became visible in the GUI; and
modifying behavior of visual cells in the GUI based on the distance value for each of the visual cells.
13. The apparatus of claim 12, wherein the focus threshold indicates a location in the reference frame where the visual cell becomes a focused cell in the GUI.
14. The apparatus of claim 13, wherein the distance value comprises a relative threshold visibility percentage, and wherein determining the relative threshold visibility percentage comprises the processing device:
identifying unselected ones of the visual cells in a visual window of the reference frame;
determining a threshold cutoff point for the unselected visual cells;
determining a first distance between a window edge of the visual window and the threshold cutoff point;
determining a second distance between a cell edge of the unselected visible cell and the threshold cutoff point; and
determining the relative threshold visibility percentage of the unselected visible cells based on the first distance and the second distance.
15. The apparatus of claim 12, wherein the GUI corresponds to a visual window within a scrolling container of the reference frame, wherein the scrolling container comprises the set of the plurality of cells that can be scrolled at least one of horizontally or vertically within the scrolling container, and wherein at least a portion of the visual cells are in the visual window.
16. The apparatus of claim 12, wherein the plurality of cells each comprise a rectangular array of pixels of the reference frame corresponding to a logically separate portion of the reference frame.
17. The apparatus of claim 12, wherein the processing device to modify the behavior comprises the processing device to perform at least one of: applying the distance value to the visual cell to provide a color blending effect in the visual cell, applying the distance value to the visual cell to perform data pre-extraction of the visual cell, or providing the distance value to a server device for a data record corresponding to the visual cell.
18. A non-transitory machine-readable storage medium storing instructions that, when executed, cause a processing device to perform operations comprising:
identifying a visual cell of a plurality of cells of a reference frame, the visual cell rendered in a Graphical User Interface (GUI) displaying at least a portion of the reference frame;
determining, by the processing device rendering the GUI, a distance value for each of the visual cells, the distance value indicating a distance that the visual cell has traveled into the reference frame since the visual cell became visible in the GUI; and
modifying behavior of the visual cells in the GUI based on the distance value for each of the visual cells.
19. The non-transitory machine-readable storage medium of claim 18, wherein the focus threshold indicates a location in the reference frame where the visual cell becomes a focused cell in the GUI.
20. The non-transitory machine-readable storage medium of claim 18, wherein modifying the behavior comprises performing at least one of: applying the distance value to the visual cell to provide a color blending effect in the visual cell, applying the distance value to the visual cell to perform data pre-extraction of the visual cell, or providing the distance value to a server device for a data record corresponding to the visual cell.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US16/732,024 | 2019-12-31 | ||
US16/732,024 US11269479B2 (en) | 2019-12-31 | 2019-12-31 | Automatic focus detection with relative threshold-aware cell visibility for a scrolling cell collection |
PCT/US2020/053647 WO2021137908A1 (en) | 2019-12-31 | 2020-09-30 | Automatic focus detection with relative threshold-aware cell visibility for a scrolling cell collection |
Publications (2)
Publication Number | Publication Date |
---|---|
CN114144755A true CN114144755A (en) | 2022-03-04 |
CN114144755B CN114144755B (en) | 2023-08-18 |
Family
ID=72896165
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202080048036.0A Active CN114144755B (en) | 2019-12-31 | 2020-09-30 | Autofocus detection with relative threshold-aware cell visibility of a scrolling set of cells |
Country Status (4)
Country | Link |
---|---|
US (2) | US11269479B2 (en) |
EP (1) | EP3973377A1 (en) |
CN (1) | CN114144755B (en) |
WO (1) | WO2021137908A1 (en) |
Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20180300032A1 (en) * | 2017-04-12 | 2018-10-18 | Microsoft Technology Licensing, Llc | Continued Selection During Scrolling |
US20190377487A1 (en) * | 2018-06-07 | 2019-12-12 | Magic Leap, Inc. | Augmented reality scrollbar |
CN110583012A (en) * | 2017-06-19 | 2019-12-17 | 谷歌有限责任公司 | Dynamically adjustable electronic program guide |
Family Cites Families (30)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7028264B2 (en) * | 1999-10-29 | 2006-04-11 | Surfcast, Inc. | System and method for simultaneous display of multiple information sources |
US6857128B1 (en) | 2000-02-14 | 2005-02-15 | Sharp Laboratories Of America | Electronic programming guide browsing system |
FR2846115A1 (en) * | 2002-10-16 | 2004-04-23 | Canal Plus Technologies | Hypertext markup-language document displaying process for digital television, involves recopying contents of pixel map of buffer memory when document is displayed or flashed, where memory is created for visible part of document |
US8046705B2 (en) * | 2003-05-08 | 2011-10-25 | Hillcrest Laboratories, Inc. | Systems and methods for resolution consistent semantic zooming |
CN103398718B (en) * | 2004-03-23 | 2017-04-12 | 咕果公司 | Digital mapping system |
US7571146B2 (en) * | 2005-04-04 | 2009-08-04 | Spadac, Inc. | Event, threat and result change detection system and method |
US20100125804A1 (en) * | 2008-11-18 | 2010-05-20 | International Business Machines Corporation | Object positioning in a graphical user interface |
US8356247B2 (en) * | 2008-12-16 | 2013-01-15 | Rich Media Worldwide, Llc | Content rendering control system and method |
US9529866B2 (en) * | 2010-12-20 | 2016-12-27 | Sybase, Inc. | Efficiently handling large data sets on mobile devices |
EP2761419A1 (en) * | 2011-09-30 | 2014-08-06 | Van Der Westhuizen, Willem Morkel | Method for human-computer interaction on a graphical user interface (gui) |
CA2792895C (en) * | 2011-10-18 | 2020-04-28 | Research In Motion Limited | Method of rendering a user interface |
US20130125066A1 (en) * | 2011-11-14 | 2013-05-16 | Microsoft Corporation | Adaptive Area Cursor |
US8963962B2 (en) * | 2012-03-06 | 2015-02-24 | Apple Inc. | Display of multiple images |
AU2013363975A1 (en) * | 2012-12-19 | 2015-07-23 | Willem Morkel Van Der Westhuizen | User control of the trade-off between rate of navigation and ease of acquisition in a graphical user interface |
US9874991B2 (en) * | 2013-01-15 | 2018-01-23 | Apple Inc. | Progressive tiling |
WO2014124417A1 (en) * | 2013-02-11 | 2014-08-14 | Vindico Llc | Comprehensive measurement of the opportunity to see online advertisements |
WO2015107670A1 (en) | 2014-01-17 | 2015-07-23 | 楽天株式会社 | Information processing device, display control method, program, and storage medium |
US9886179B2 (en) | 2014-08-27 | 2018-02-06 | Apple Inc. | Anchored approach to scrolling |
US20160321230A1 (en) * | 2015-04-29 | 2016-11-03 | Facebook, Inc. | Generating a data table |
US10706119B1 (en) * | 2015-04-30 | 2020-07-07 | Tensera Networks Ltd. | Content prefetching to user devices based on rendering characteristics |
US9658736B2 (en) * | 2015-06-04 | 2017-05-23 | Microsoft Technology Licensing, Llc | Contrast-oriented cursor presentation |
US10783548B1 (en) * | 2015-07-31 | 2020-09-22 | Amazon Technologies, Inc. | Content viewability detection |
US10346019B2 (en) * | 2016-01-09 | 2019-07-09 | Apple Inc. | Graphical user interface for providing video in a document reader application |
DK201670728A1 (en) | 2016-09-06 | 2018-03-19 | Apple Inc | Devices, Methods, and Graphical User Interfaces for Providing Feedback During Interaction with an Intensity-Sensitive Button |
US10782852B1 (en) * | 2016-12-11 | 2020-09-22 | Snap Inc. | Contextual action mechanisms in chat user interfaces |
KR20180068219A (en) * | 2016-12-13 | 2018-06-21 | 삼성전자주식회사 | Display apparatus for providing ui and controlling method thereof |
JP6915387B2 (en) * | 2017-06-02 | 2021-08-04 | コニカミノルタ株式会社 | Medical image display device, touch operation control program and touch operation control method |
CN110582012B (en) | 2018-06-11 | 2021-07-30 | 腾讯科技（深圳）有限公司 | Video switching method, video processing device and storage medium |
EP4062313A1 (en) * | 2019-11-18 | 2022-09-28 | Monday.com Ltd. | Collaborative networking systems, methods, and devices |
US20210150135A1 (en) * | 2019-11-18 | 2021-05-20 | Monday.Com | Digital processing systems and methods for integrated graphs in cells of collaborative work system tables |
-
2019
- 2019-12-31 US US16/732,024 patent/US11269479B2/en active Active
-
2020
- 2020-09-30 EP EP20792884.7A patent/EP3973377A1/en active Pending
- 2020-09-30 WO PCT/US2020/053647 patent/WO2021137908A1/en unknown
- 2020-09-30 CN CN202080048036.0A patent/CN114144755B/en active Active
-
2022
- 2022-03-07 US US17/688,773 patent/US11762526B2/en active Active
Patent Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20180300032A1 (en) * | 2017-04-12 | 2018-10-18 | Microsoft Technology Licensing, Llc | Continued Selection During Scrolling |
CN110583012A (en) * | 2017-06-19 | 2019-12-17 | 谷歌有限责任公司 | Dynamically adjustable electronic program guide |
US20190377487A1 (en) * | 2018-06-07 | 2019-12-12 | Magic Leap, Inc. | Augmented reality scrollbar |
Also Published As
Publication number | Publication date |
---|---|
US20220187980A1 (en) | 2022-06-16 |
US11269479B2 (en) | 2022-03-08 |
US11762526B2 (en) | 2023-09-19 |
US20210200419A1 (en) | 2021-07-01 |
WO2021137908A1 (en) | 2021-07-08 |
CN114144755B (en) | 2023-08-18 |
EP3973377A1 (en) | 2022-03-30 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US20240094872A1 (en) | Navigating through documents in a document viewing application | |
US10203845B1 (en) | Controlling the rendering of supplemental content related to electronic books | |
KR101850264B1 (en) | Touch screen user interface to present media | |
JP5923611B2 (en) | User interface with media content prediction | |
CN107223241B (en) | Contextual scaling | |
US20140149936A1 (en) | System and method for providing a tapestry interface with location services | |
CN112153454B9 (en) | Method, device and equipment for providing multimedia content | |
US9268858B1 (en) | Previewing content based on detected customer activities | |
CN108780654B (en) | Generating mobile thumbnails for video | |
US20140149932A1 (en) | System and method for providing a tapestry presentation | |
CN110709835B (en) | Video preview providing search results | |
US20150213018A1 (en) | Method for recommending videos to add to a playlist | |
US20190394514A1 (en) | Touch gesture control of video playback | |
KR20160104067A (en) | Generating a news timeline and recommended news editions | |
US20140149885A1 (en) | System and method for providing a tapestry interface with interactive commenting | |
CN114144755B (en) | Autofocus detection with relative threshold-aware cell visibility of a scrolling set of cells | |
US10599319B2 (en) | Drag and drop insertion control object | |
US10372317B1 (en) | Method for highly accurate selection of items on an axis with a quadrilateral control surface | |
US11727046B2 (en) | Media item matching using search query analysis |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
GR01 | Patent grant | ||
GR01 | Patent grant |