CN115280314A - Pattern-based classification - Google Patents
Pattern-based classification Download PDFInfo
- Publication number
- CN115280314A CN115280314A CN202180019880.5A CN202180019880A CN115280314A CN 115280314 A CN115280314 A CN 115280314A CN 202180019880 A CN202180019880 A CN 202180019880A CN 115280314 A CN115280314 A CN 115280314A
- Authority
- CN
- China
- Prior art keywords
- interaction
- content
- encoded
- given
- entity
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
- 230000003993 interaction Effects 0.000 claims abstract description 225
- 238000009826 distribution Methods 0.000 claims abstract description 57
- 238000000034 method Methods 0.000 claims abstract description 57
- 238000012545 processing Methods 0.000 claims abstract description 21
- 230000004044 response Effects 0.000 claims abstract description 16
- 238000003860 storage Methods 0.000 claims description 28
- 230000015654 memory Effects 0.000 claims description 26
- 238000013528 artificial neural network Methods 0.000 claims description 13
- 230000002776 aggregation Effects 0.000 claims description 7
- 238000004220 aggregation Methods 0.000 claims description 7
- 230000000306 recurrent effect Effects 0.000 claims description 6
- 230000006403 short-term memory Effects 0.000 claims description 6
- 238000013145 classification model Methods 0.000 description 53
- 238000012549 training Methods 0.000 description 47
- 230000000694 effects Effects 0.000 description 43
- 230000008569 process Effects 0.000 description 23
- 238000004590 computer program Methods 0.000 description 12
- 230000006870 function Effects 0.000 description 9
- 238000004891 communication Methods 0.000 description 8
- 230000002452 interceptive effect Effects 0.000 description 7
- 238000013515 script Methods 0.000 description 7
- 238000010586 diagram Methods 0.000 description 6
- 230000006399 behavior Effects 0.000 description 4
- 230000008901 benefit Effects 0.000 description 4
- 238000011156 evaluation Methods 0.000 description 4
- 238000009877 rendering Methods 0.000 description 4
- 230000004931 aggregating effect Effects 0.000 description 3
- 238000013459 approach Methods 0.000 description 3
- 230000008859 change Effects 0.000 description 3
- 238000010801 machine learning Methods 0.000 description 3
- 239000000203 mixture Substances 0.000 description 3
- 230000003287 optical effect Effects 0.000 description 3
- 230000000644 propagated effect Effects 0.000 description 3
- 230000003542 behavioural effect Effects 0.000 description 2
- 230000005540 biological transmission Effects 0.000 description 2
- 235000014510 cooky Nutrition 0.000 description 2
- 230000009021 linear effect Effects 0.000 description 2
- 238000013507 mapping Methods 0.000 description 2
- 238000010295 mobile communication Methods 0.000 description 2
- 238000000926 separation method Methods 0.000 description 2
- 230000000007 visual effect Effects 0.000 description 2
- 239000002699 waste material Substances 0.000 description 2
- 238000013473 artificial intelligence Methods 0.000 description 1
- 239000002131 composite material Substances 0.000 description 1
- 238000013461 design Methods 0.000 description 1
- 238000011161 development Methods 0.000 description 1
- 238000005516 engineering process Methods 0.000 description 1
- 239000004973 liquid crystal related substance Substances 0.000 description 1
- 238000003058 natural language processing Methods 0.000 description 1
- 230000009022 nonlinear effect Effects 0.000 description 1
- 238000005457 optimization Methods 0.000 description 1
- 239000004065 semiconductor Substances 0.000 description 1
- 230000001953 sensory effect Effects 0.000 description 1
- 230000011273 social behavior Effects 0.000 description 1
- 230000005477 standard model Effects 0.000 description 1
- 230000003068 static effect Effects 0.000 description 1
- 239000000758 substrate Substances 0.000 description 1
- 238000012546 transfer Methods 0.000 description 1
- 230000007704 transition Effects 0.000 description 1
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/10—Protecting distributed programs or content, e.g. vending or licensing of copyrighted material ; Digital rights management [DRM]
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/50—Monitoring users, programs or devices to maintain the integrity of platforms, e.g. of processors, firmware or operating systems
- G06F21/55—Detecting local intrusion or implementing counter-measures
- G06F21/552—Detecting local intrusion or implementing counter-measures involving long-term monitoring or reporting
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/28—Databases characterised by their database models, e.g. relational or object models
- G06F16/284—Relational databases
- G06F16/285—Clustering or classification
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/044—Recurrent networks, e.g. Hopfield networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
Abstract
A method includes receiving interaction data indicating, for each given interaction of a plurality of interactions occurring at a client device, (i) an event type and (ii) a delay period specifying an amount of time between the given event and a previous event occurring prior to the given event, encoding each given interaction as an encoded interaction having a standardized format, the format being a combination of (i) the event type and (ii) the delay period, generating an interaction signature comprising the encoded interaction sequence, processing the encoded interaction sequence using a trained model to mark a user interaction sequence as valid or invalid, including marking the encoded interaction sequence as invalid using the model, and preventing distribution of a set of content to an entity executing the encoded interaction sequence in response to a subsequently identified request to provide content to the entity.
Description
Background
This document relates to data processing and pattern-based classification of interactive data sequences.
Disclosure of Invention
In general, one innovative aspect of the subject matter described in this specification can be embodied in a method for classifying a sequence of interaction data that includes receiving interaction data indicating, for each given interaction of a plurality of interactions that occur at a client device, (i) an event type and (ii) a delay period that specifies an amount of time between the given event and a previous event that occurred before the given event, encoding each given interaction as an encoded interaction having a standardized format that is a combination of (i) the event type of the given interaction and (ii) the delay period specified by the interaction data of the given interaction, generating an interaction signature that includes the encoded interaction sequence, processing the encoded interaction sequence using a trained model to classify a user interaction sequence as valid or invalid, including classifying the encoded interaction sequence as invalid using the model, and preventing a set of content from being distributed to an entity that performs the encoded interaction sequence in response to subsequently identified requests to provide content to the entity.
These and other embodiments may each optionally include one or more of the following features.
In some implementations, the recurrent neural network is a Long Short Term Memory (LSTM) network.
In some implementations, preventing distribution of the set of content includes refraining from providing the specified type of content to the entity.
In some implementations, preventing distribution of the set of content includes temporarily preventing distribution of the content to one or more devices corresponding to the entity.
In some implementations, the method includes identifying a result entry of the content distribution log corresponding to the encoded interaction sequence classified as invalid and invalidating the result entry corresponding to the encoded interaction sequence classified as invalid.
In some implementations, invalidating the result entry corresponding to the encoded interaction sequence includes deleting the result entry from memory.
In some implementations, receiving the interaction data includes collecting, for a given entity, sets of interaction data corresponding to interactions with multiple different portions of content, generating an interaction signature includes generating a separate interaction signature for each set of interaction data corresponding to interactions with each different portion of content, and the method includes classifying the given entity as an actual user or an automated bot based on a label assigned to each set of interaction data or an aggregate label assigned to the sets of interaction data in the aggregate, wherein preventing distribution of the set of content includes preventing distribution of the set of content when the given entity is classified as the automated bot.
Other embodiments of this aspect may include corresponding systems, apparatus, and computer programs configured to perform the actions of the methods encoded on computer storage devices.
Particular embodiments of the subject matter described in this document can be implemented to realize one or more of the following advantages. The evaluation and/or classification of online activity may be performed based on an entity behavior pattern within a sequence of events. Entities include, for example, users, organizations, content providers, content publishers, and companies. Generally, online activity classification methods use probabilistic rules to model state transitions, but are linear and limited to analyzing short-term effects. For example, existing methods may classify sequence information using a model based on a markov chain, but the markov chain is typically limited by the number of back-off steps that may be considered. Furthermore, markov chains do not address the non-linear effects of interactions between links in a chain.
The methods described herein provide an improved activity classification method using sequence information and context information, thereby avoiding the disadvantages of prior methods that are not applicable to sequences of different lengths or having complex interactions within the sequence. In particular, the method uses a model that classifies a particular sequence of activity events related to an entity as valid or invalid, and uses the classification to inform whether or how to adjust the distribution of content to the entity based on the classification. For example, a series of activity events may be invalid if the events are performed by or under the influence of malware or malicious third parties. In another example, a series of activity events may be invalid if the behavior does not conform to the characteristics of the user or user type, or if the sequence is unlikely to be performed by a human (e.g., the type of interactions performed occur too quickly for the human executing them). By reducing or completely eliminating distribution of content to entities identified as performing or associated with invalid sequences, the method reduces the amount of resources expended to distribute content to entities susceptible to invalid interactions and more efficiently provides content across a network-the method prevents distribution of content to entities that do not actually view the content. In other words, computing resources such as network bandwidth, processor cycles, and/or allocated memory are not wasted by using these resources to distribute content to entities that do not actually view the content.
Further, the described method may include retroactively invalidating entries within the content distribution log in response to the coded interaction sequence being marked as invalid. These invalid entries may then be deleted from memory, thereby reducing the amount of memory used by the content distribution system.
For example, the described methods may provide an enhanced spam filter that captures advertisements or view counts from high risk accesses; evaluating the flow quality by using the prediction scores in the aggregation, and improving the flow quality scores; entity risk scores are improved by aggregating prediction scores at the entity level and using the prediction scores to filter and alter distribution parameters among other applications.
The described method combines the advantages of a model that uses only event-level features of interaction sequences related to entities and aggregate features of interaction sequences related to entities. The context information is used by inputting interaction data into the sequence model using a deep neural network. For simplicity of explanation, the following description is provided with respect to a Recurrent Neural Network (RNN), which is a deep neural network often used for applications such as natural language processing. However, various other types of sequence models are contemplated that use deep neural networks, including transform neural networks and bi-directional encoder representations from transform (BERT). By processing the user's behavior in the visit or encoding a sequence of events, the method allows context information to be obtained within and among the events in the sequence to inform the classification of the sequence. RNNs, among other things, provide flexibility for the method to be used with sequences of varying length and can share features learned at different positions of the sequence, which are not available using standard neural networks.
The following discussion also details several techniques that optimize standard model training techniques to train the pattern-based online activity classification system. As described below, these techniques include online activity coding (e.g., using standardized formats), deep neural networks, and weak oversight to improve the ability to train models based on user behavior patterns, relieve the burden of obtaining manually labeled data sets, and allow the models to be customized for a particular entity without incurring the cost of having a human expert label the training data set for each model.
In addition to improving the quality of the training model, these techniques also reduce the amount of data to be transmitted across the communication channel, e.g., avoid transmitting digital components to the entity's client device if the entity performs an invalid sequence. This reduces the amount of resources spent on entities that are unlikely to be legitimate consumers of content. Further, the model may be applied to real-time online traffic (e.g., to predict the results of transmitting a particular digital component to a particular entity).
The details of one or more embodiments of the subject matter described in this specification are set forth in the accompanying drawings and the description below. Other features, aspects, and advantages of the subject matter will become apparent from the description, the drawings, and the claims.
Drawings
FIG. 1 is a block diagram of an example environment for pattern-based activity classification.
Fig. 2 depicts a data flow for a pattern-based approach to classifying an activity sequence.
Fig. 3 depicts an encoding process of an active sequence.
FIG. 4 is a flow diagram of an example process for pattern-based activity classification.
FIG. 5 is a block diagram of an example computing system.
Like reference numbers and designations in the various drawings indicate like elements.
Detailed Description
This document describes methods, systems, and apparatus that improve the classification of active sequences as valid or invalid and optimize the transmission of digital components to entities based on the classification.
The schema-based digital component transport optimization leverages the schema of the online activity to adjust how the digital component is provided to the client device. In some implementations, the evaluation of the online activity requires that the online activity be encoded as an encoded sequence of interaction events that can be used to train an RNN model (e.g., a predictive model or a model that provides an after-the-fact quality estimate) under weak supervision. Note that much of the discussion below is directed to predictive analysis, but the techniques described below are also applicable to post-hoc determination of quality.
As described in detail below, the model is trained using deep neural networks and using weak supervision. The model classifies the encoded sequence of events as valid or invalid. The classification of the model may be used for various purposes, such as adjusting distribution criteria of the digital component based on the classification of the session in which the digital component is transmitted to the client device, determining whether a particular digital component should be transmitted to the client device in response to a particular query submitted by the client device, and adjusting result entries corresponding to logs of past interactions, among other applications.
FIG. 1 is a block diagram of an example environment 100 for efficient, dynamic video editing and rendering. The example environment 100 includes a network 102, such as a Local Area Network (LAN), a Wide Area Network (WAN), the Internet, or a combination thereof. The network 102 connects an electronic document server 104 ("electronic document server"), user devices 106, and a digital component distribution system 110 (also referred to as a DCDS 110). The example environment 100 may include many different electronic document servers 104 and user devices 106.
The user device 106 is an electronic device capable of requesting and receiving resources (e.g., electronic documents) over the network 102. Example user devices 106 include personal computers, wearable devices, smart speakers, tablet devices, mobile communication devices (e.g., smart phones), smart appliances, and other devices that can send and receive data over the network 102. In some implementations, the user device can include a speaker that outputs audible information to the user and a microphone that accepts audible input (e.g., spoken input) from the user. The user device may also include a digital assistant that provides an interactive voice interface for submitting input and/or receiving output provided in response to the input. The user device may also include a display for presenting visual information (e.g., text, images, and/or video). The user device 106 typically includes a user application, such as a web browser, to facilitate sending and receiving data over the network 102, although a native application executed by the user device 106 may also facilitate sending and receiving data over the network 102.
The one or more third parties 130 include content providers, product designers, product manufacturers, and others involved in the design, development, marketing, or distribution of videos, products, and/or services.
An electronic document is data that presents a set of content at a user device 106. Examples of electronic documents include web pages, word processing documents, portable Document Format (PDF) documents, images, videos, search result pages, and feed sources. Native applications (e.g., "application programs"), such as applications installed on mobile, tablet, or desktop computing devices, are also examples of electronic documents. An electronic document 105 ("electronic document") may be provided by the electronic document server 104 to the user device 106. For example, the electronic document server 104 may include a server hosting publisher's web pages. In this example, the user device 106 may initiate a request for a given publisher web page, and the electronic document server 104 hosting the given publisher web page may respond to the request by sending machine hypertext markup language (HTML) code that initiates presentation of the given web page at the user device 106.
The electronic document may include a variety of content. For example, the electronic document 105 may include static content (e.g., text or other specified content) that is within the electronic document itself and/or that does not change over time. The electronic document may also include dynamic content that may change over time or upon each request. For example, a publisher of a given electronic document may maintain a data source for populating portions of the electronic document. In this example, a given electronic document may include a tag or script that causes the user device 106 to request content from a data source when the given electronic document is processed (e.g., rendered or executed) by the user device 106. The user device 106 integrates content obtained from the data source into the presentation of the given electronic document to create a composite electronic document that includes the content obtained from the data source.
In some cases, a given electronic document may include a digital content tag or digital content script that references the DCDS 110. In these cases, the digital content tag or digital content script is executed by the user device 106 when a given electronic document is processed by the user device 106. Execution of the digital content tag or digital content script configures the user device 106 to generate a request 108 for digital content that is transmitted over the network 102 to the DCDS 110. For example, a digital content tag or digital content script may enable the user device 106 to generate a packet data request including a header and payload data. The request 108 may include information such as the name (or network location) of the server from which the digital content was requested, the name (or network location) of the requesting device (e.g., user device 106), and/or the DCDS110 may be used to select the digital content to provide in response to the request. The request 108 is transmitted by the user device 106 to a server of the DCDS110 over the network 102 (e.g., a telecommunications network).
The request 108 may include data specifying characteristics of the electronic document and the location where the digital content may be presented. For example, data specifying a reference (e.g., a URL) to an electronic document (e.g., a web page) in which digital content is to be rendered, available locations of the electronic document (e.g., a digital content slot) available for rendering the digital content, sizes of the available locations, locations of the available locations within the rendering of the electronic document, and/or media types that are eligible for rendering in those locations may be provided to the DCDS 110. Similarly, data specifying selected keywords for an electronic document ("document keywords") or an entity referenced by the electronic document (e.g., a person, place, or thing) may also be included in the request 108 (e.g., as payload data) and provided to the DCDS110 in order to identify digital content items that are eligible for presentation with the electronic document.
The request 108 may also include data related to other information, such as user-provided information, geographic information indicating the state or region in which the request was submitted, or other information that provides context of the environment in which the digital content is to be displayed (e.g., the type of device, such as a mobile device or tablet device, on which the digital content is to be displayed). The user-provided information may include demographic data of the user device 106. For example, demographic information may include age, gender, geographic location, education level, marital status, household income, occupation, hobbies, social media data, and whether the user owns a particular project, among other characteristics.
For the cases where the systems discussed herein collect personal information about a user or potentially utilize personal information, the user may be provided with an opportunity to control whether programs or features collect personal information (e.g., information about the user's social network, social behavior or activity, profession, user preferences, or the user's current location), or whether and/or how to receive content from a content server that may be more relevant to the user. In addition, some data may be anonymized in one or more ways prior to storage or use, thereby deleting personally identifiable information. For example, the identity of the user may be anonymous, and thus unable to determine the user's personal identity information, or the user's geographic location may be summarized where location information is obtained (e.g., at a city, zip code, or state level), and thus unable to determine the user's particular location. Thus, the user may control how information about him or her is collected and used by the content server.
Data specifying characteristics of the user device 106 may also be provided in the request 108, such as information identifying a model of the user device 106, a configuration of the user device 106, or a size (e.g., a physical size or resolution) of an electronic display (e.g., a touchscreen or desktop display) on which the electronic document is presented. The request 108 may be transmitted over a packet network, for example, and the request 108 itself may be formatted as packet data having a header and payload data. The header may specify the destination of the packet and the payload data may include any of the information discussed above.
The DCDS110 selects digital content to be presented with a given electronic document in response to receiving the request 108 and/or using information included in the request 108. In some implementations, the DCDS110 is implemented in a distributed computing system (or environment) including, for example, a server and a set of multiple computing devices interconnected and responsive to the request 108 to identify and distribute digital content. The set of multiple computing devices operate together to identify a set of digital content that is eligible for presentation in electronic documents in a corpus of millions or more of available digital content. For example, millions or more of available digital content may be indexed in the digital component database 112. Each digital content index entry may reference corresponding digital content and/or include distribution parameters (e.g., selection criteria) that regulate distribution of the corresponding digital content.
In some implementations, the digital components from the digital component database 112 may include content provided by third parties 130. For example, the digital component database 112 can receive photographs of public intersections from third parties 130 that use machine learning and/or artificial intelligence to navigate public streets.
The identification of eligible digital content may be segmented into a plurality of tasks, which are then distributed among the computing devices within the set of multiple computing devices. For example, different computing devices may each analyze different portions of the digital component database 112 to identify various digital content having distribution parameters that match the information included in the request 108.
The DCDS110 aggregates the results received from the set of multiple computing devices and uses information associated with the aggregated results to select one or more instances of digital content to be provided in response to the request 108. The DCDS110 may then generate and transmit reply data 114 (e.g., digital data representing a reply) over the network 102, the reply data 114 enabling the user device 106 to integrate the selected set of digital content into a given electronic document such that the selected set of digital content is presented on a display of the user device 106 along with the content of the electronic document.
The encoder 120 receives interaction or event data and encodes the data into a standardized format. The encoded interaction data is provided to the classification model 124. The encoder 130 may receive the interaction data from a variety of sources, including the user device 106, the third party 130, and the DCDS110 itself.
The training module 122 trains one or more classification models 116 using machine learning techniques including RNNs and weak supervision to generate training data.
The classification model 124 receives the encoded interaction data and outputs a classification of whether the sequence of events represented by the encoded interaction data is valid or invalid.
For ease of explanation, the encoder 120, the training module 122, and the classification model 124 are shown in FIG. 1 as separate components of the DCDS 110. The DCDS110 may be implemented as a single system on a non-transitory computer readable medium. In some implementations, one or more of the encoder 120, training module 122, and classification model 124 can be implemented as integrated components of a single system. The DCDS110, its components, the encoder 120, the training module 122, and the classification model 124, as well as their respective functions and outputs, are described in further detail below with reference to pattern-based classification of activity sequences.
FIG. 2 illustrates an example data flow 200 for a pattern-based approach to classifying activity sequences in the example environment of FIG. 1. The operations of data flow 200 are performed by various components of system 100. For example, the operations of the data stream 200 may be performed by the encoder 120, the training module 122, and the classification model 124 of the DCDS110 in communication with the user equipment 106.
The flow begins at step a where the encoder 120 receives interactive data. The encoder 120 may receive the interaction data from a variety of sources, including the user equipment 106 and the DCDS110 itself. The interaction data indicates an activity performed by a particular entity. For example, a user on the smartphone 106 may click on a video to play the video. In some implementations, the entity may be malware or a malicious third party disguised as a user of the smartphone 106. The encoder 120 will receive interaction data from the smartphone 106 indicating that the user clicked on the video. The interaction data provides detailed information of the event, including the type of interaction and the time at which the interaction occurred. For example, the interaction data may include a timestamp, an event type, and an entity that performed the event. The interaction data may include other features, including data provided by the web browser or the entity itself. For example, the user may allow the smartphone 106 to provide user profile information. In another example, the user's browser or website the user is visiting may provide information including an IP address, cookie ID, and other browser or cookie related information.
The flow continues to step B where the encoder 120 encodes the interactive data. The encoder 120 outputs the encoded interactive data in a standardized format. Details of this encoding process are provided below with respect to fig. 3.
The encoder 120 may encode the interaction data into an interaction sequence for each visit or session. An access is a set of interactions performed by a single entity. The session may be time-limited and/or may end based on the occurrence of one or more conditions. For example, a session may end based on detecting interactions of the same entity on different devices, the absence of any interactions or activities for a threshold period of time, and a loss of network connection or a change in network state, among other conditions. A session may include activity across different browsers or devices. A session may involve multiple accesses. For example, the same user may use their smart phone, notebook computer, or networked television to access a website, each resulting in a different access, but may also be part of the same session. The encoder 120 may encode each individual event as a "word" and each visit as a sequence of encoded events (e.g., words) to form a "sentence". In the context of this specification, a "word" represents a coded interaction, and a "sentence" or sequence of coded events represents an interaction signature. By grouping events in sentences together, the encoder 120 allows the classification model 124 to classify data using relationships and similarities between events within the same visit.
Further, by grouping events by visit, the classification model 124 can detect activities performed by different entities within a single session. For example, a single user session may be a mix of natural access and malware-driven or hijacked access. Because events are grouped by access, the classification model 124 may treat hidden browse windows controlled by malware as different accesses having a different classification than other accesses performed by a particular user.
In some implementations, the encoder 120 includes multiple encoders, each of which maintains a sequence of events for a particular entity. In some implementations, the encoder 120 may maintain multiple separate threads such that the encoder 120 receives interaction data for various entities. The encoder 120 may then encode the interaction data into an interaction sequence within the same visit.
The flow continues to step C where the encoder 120 provides the encoded interaction data to the classification model 124 and the training module 122. The encoder 120 outputs the encoded interaction data in a standardized format to the classification model 124 and the training module 122. In some implementations, the encoder 120 provides the encoded interaction data word-by-word to the classification model 124, identifying the visits in which each encoded interaction event occurred. In some implementations, the encoder 120 provides the encoded interaction data to the classification model 124 in the form of sentences.
The training module 122 uses the encoded data to generate training data that is used to train a model, such as the classification model 124. For various examples, such as invalid visits, ground truth training labels may not exist or may be sparse. In some implementations, the DCDS110 trains the model using weak supervised techniques, even with limited ground truth training labels. The DCDS110 may use a set of tag functions created by, for example, a human expert; inferring an accuracy of a label function for each label; the labels generated by the plurality of label functions are then combined into a probabilistic label for each data point to use as a training label.
In some implementations, the user may specify a composition of sufficient training data. For example, the user may specify a minimum number of encoded interactions, a minimum number of different entities performing the interactions, a number of manually generated ground truth training tags, and other training data parameters. For example, the user may specify that, for a particular system, a sufficient composition of training data includes a minimum of 100 encoded interactions, a minimum of 5 different entities performing these encoded interactions, and a minimum of 20 ground truth training labels.
In some implementations, training module 122 may automatically determine and adjust each training data parameter based on information including the expected amount of available data. In some implementations, the interaction of the entity and the code must be chosen randomly. In some implementations, the entity and the encoded interaction may be extracted from the interaction and/or a training set of entities.
The training labels may be provided as an example to the training module 210 as an input instead of the ground truth example to train the RNN-based classification model 124 in this particular example. The classification model 124 is a long short term memory model (LSTM) and is applicable to sequences of varying length. Because the classification model 124 is an LSTM model, it can also account for non-linear interactions between in-visit events. Examples may be positive examples, or negative examples. The training module 122 may use the training labels to validate the model output of the classification model 124 and continue training the model to improve the accuracy with which the model classifies the sequence of activity events.
The training module 122 performs inference using the inference input data, generating a prediction score for each visit in addition to the classification. The prediction score is semantically a risk score that indicates a probability of access invalidation. The training module 122 maintains a log of visits for which the risk score is above a threshold. In some implementations, the threshold is selected based on model evaluation statistics that are available to the classification model at runtime. For example, the threshold may be 90%. In some implementations, the threshold is selected as the maximum accuracy available in the evaluation statistics used.
The training module 122 trains the classification using a loss function. The loss function computes the model error, and the training module 122 trains the classification model 124 using the loss function and the examples labeled with the training labels to see which variables are important to the model. The training module 122 allows the classification model 124 to learn by changing the weights applied to different variables to emphasize or de-emphasize the importance of the variables within the model. Changing the weights applied to the variables allows the classification model 124 to know which types of information should be weighted more heavily to produce a more accurate classification. For example, training module 122 uses a loss function that penalizes deviations from tags with higher confidence more than those with lower confidence, thereby providing a "suspect benefit" to the model for tags with lower confidence. Using this weakly supervised approach, the classification model 124 is able to better reconcile the noise data.
In some implementations, training module 122 uses the probabilistically labeled data as training data and data that has not been labeled as input to classification model 124, such that data used as input to classification model 124 is not used during model training until after the input data has been classified.
The classification model 124 uses the encoded interaction data as input data and generates a classification of whether the activity represented by the interaction data is valid or invalid.
The flow continues to step D where the classification model 124 classifies the activity represented by the encoded interaction data as valid or invalid.
The classification model 124 may be, for example, a "shoe size" model that is personalized to some extent. For example, the DCDS110 may use a generic profile for people of a particular age group, new York people, people who like videos rather than text articles, and the like. Furthermore, each model may be personalized. For example, each model may be created from a generic model by varying the model parameters based on characteristics of each user determined from the collected data. Each model may be different for a long period of time and a short period of time for a particular user. For example, the DCDS110 may determine a behavioral profile of an entity associated with a particular visit and adjust the classification model based on the behavioral profile of the entity. In some implementations, each model may also be created from models that have been personalized using a generic profile and further changed for each user. For example, the model may be created by varying model parameters based on characteristics of each user determined from the collected data.
In some implementations, the model may be personalized without using a base model. For example, user response data may be input to model generator 126 and provided to a product designer, manufacturer, or design program to be mapped to a product configuration without adjustment. In one example, the model generator 126 allows a user to immediately purchase a particular item or set an alert when a particular item is available.
The flow continues to step E where the classification model 124 outputs a determination to the DCDS110 as to whether the activity is valid or invalid.
The classification model 124 provides an output to the DCDS110 whether the activity is valid or invalid. The DCDS110 uses the classification to adjust the frequency of content distribution to the entity performing the sequence. For example, the DCDS110 may prevent distribution of a set of content to an entity performing a coded interaction sequence in response to a subsequently identified request to provide the content to the entity. In some implementations, the DCDS110 can reduce the frequency of content distribution to entities. In some implementations, the DCDS110 may refrain from providing the specified type of content to the entity. For example, the DCDS110 may refrain from providing video content to users who are unlikely to actually view video, thereby reducing wasted bandwidth, processor cycles, memory usage, and/or display driver capacity by not providing video that will not actually be viewed.
In some implementations, the DCDS110 may refrain from distributing the content to devices corresponding to the entity. For example, the DCDS110 may refrain from distributing content to the user's smartphone based on a sequence of activities performed on the smartphone that are determined to be performed by malware, but may continue to distribute content to the user's notebook computer. This type of distribution limitation may reduce wasted computing resources that would otherwise be used to distribute content to the user's smart phone while still being able to distribute content to the user's notebook computer. Limiting the distribution of content in this manner prevents a waste of resources, as described above, while still being able to provide content to a particular type of device that is more likely to be actually viewed by the user.
In another example, the DCDS110 may refrain from distributing content to computers of companies at particular locations based on a sequence of activities performed on one of the computers at the location determined to be invalid. In some implementations, the DCDS110 may conserve memory resources by analyzing the result entries of the content distribution log, invalidating the result entries corresponding to the activity sequences classified as invalid, and removing the invalid result entries from memory. The DCDS110 frees resources (e.g., memory) by removing invalid result entries and may help maintain accurate records. These records may be, for example, records used to maintain the content distribution system and to compensate the content provider or host.
The flow continues with step F where the DCDS110 receives a request for content including entity information from the user equipment 106. For example, the DCDS110 may receive the request 108 from a user of the user device 106.
The flow ends with step G where the DCDS110 determines to refrain from distributing the content to the user of the user equipment 106 based on a determination that the activity sequence associated with the user of the user equipment 106 is invalid. In some implementations, the DCDS110 prevents distribution of digital components included in the content requested in the request 108. In some implementations, the DCDS110 prevents distribution of both the content and the digital components requested in the request 108.
Fig. 3 depicts an encoding process 300 of an active sequence. In some implementations, the process 300 may be performed by one or more systems. For example, the process 300 may be implemented by the encoder 120, the training module 122, the classification model 124, the DCDS110, and/or the user equipment 106 of fig. 1-2. In some implementations, the process 300 may be implemented as instructions stored on a non-transitory computer-readable medium, and when the instructions are executed by one or more servers, the instructions may cause the one or more servers to perform the operations of the process 300.
The encoder 120 receives interaction information 302 associated with an entity. For example, the interaction information may be interaction information as described above with respect to fig. 1-2. In this particular example, the interaction information 302 indicates the time at which the event 304 occurred and the event type of the event 304. Event types may include, for example, content video playback, digital component start event, search, skip-or alternate-digital component playback, new visit, click on digital component, skip-or non-alternate-digital component playback, engagement with content (e.g., likes, dislikes, or comments, and other types of engagement activities), new visit to start with a search, new embedded visit or new visit to start with an engagement activity, click on search result link, click on suggestion, and other event types. For example, a user may search on a search engine and click on a link will be directed to a web page or application; these event types may be classified as click search results or launching a new application, respectively.
Each event 304 occurs at a particular time indicated by the timestamp of that event 304. The encoder 120 may determine a time delay from a previous event in the access based on the timestamp of the particular event. Encoder 120 assigns a time delay value of 0 for the first event in the access.
The encoder 120 formats the information into a standardized format to generate an encoded "word" 306. In this particular example, the format is a vector in the form of event type, time delay. The format may include other features as described above with respect to fig. 1-2. For example, the event-generated encoding word 306 that the user started playing the favorite puppy video on the website 2.4 seconds after the user clicked on the website is encoded as [ watch, 2.4]. The encoder 120 may generate an encoded event sequence or interaction signature 307 based on the interaction data. For example, for a user clicking on one web site, the sequence of events for watching a favorite puppy video after 2.4 seconds, and then clicking on the link of another video after 2 minutes and 13 seconds, is encoded as an interactive signature in the form of [ navigation, 0] [ watch, 2.4] [ watch, 2.
In this particular example, the encoder 120 generates encoded words 306, which are [ PB,0], [ WP,1 ], [ CV, 0. The encoder 120 performs the encoding by mapping the online activity to a short format code and combining the short format code with the calculated time delay. Each event is assigned a timestamp, and the encoder 120 can calculate the delay period between a particular event and a previous event by calculating the difference between two consecutive timestamps of two consecutive events corresponding to the particular event and the previous event, e.g., using the timestamp data.
In this particular example, the encoder 120 generates a cross-signature 307, which is [ PB,0] [ WP,1 ] [ 43] [ CV, 0] [ PB, 0.
The classification model 124 uses the encoded word 306 to classify the visit represented by the encoded word 306 and outputs a classification 308 of the visit. The classification model 124 classifies the access as valid or invalid based on features and characteristics included in the coded word 306. For example, as described above, the classification model 124 may use buckets to distinguish valid values from invalid values.
The classification model 124 uses the time delay between events 306 to classify an access as valid or invalid. For example, the classification model 124 may be determined based on whether a particular time delay may be reasonably performed by a human, whether it is a typical user or type of user, or indicating actual engagement with content rather than just a click through. In one example, a time delay of 0.002 seconds between a click interaction on a video presented in a news article and a video beginning to watch the video is physically impossible for a human user to perform, so the classification model 124 may classify the access as invalid. In another example, a 30 second time delay between a link to a similar style garment presented in a page for a particular garment and a click interaction on the link may be a typical user type accessing a fashion advice website, and thus the classification model 124 may classify the access as valid. In another example, a 1 minute time delay between starting to play a 45 second video and scrolling through actions in a social media feed may indicate that a human user has actually engaged in the video (e.g., watched most of the content of the video) rather than simply scrolling through without watching the video, so the classification model 124 may classify the access as valid.
In some implementations, for a given entity, the DCDS110 may receive multiple sets of interaction data corresponding to interactions with multiple different portions of content. For example, the DCDS110 may receive interaction data for a particular user that corresponds to interactions with multiple types of content from multiple different content providers. The classification model 124 may generate individual interaction signatures for each set of interaction data by classifying a given entity as an actual user or an automated robot based on tags assigned to each set of interaction data or aggregated tags assigned to sets of interaction data in an aggregation. For example, the classification model 124 may generate a separate interaction signature for each visit associated with a particular user. The classification model 124 may independently classify each visit as an actual user, a user who actually participates in the content, or an automated bot. Based on the classification of a particular visit by the classification model 124, the DCDS110 may prevent distribution of a set of content when a given entity is classified as an automated bot.
FIG. 4 is a flow diagram of an example process 400 for efficiently and dynamically changing and presenting videos. In some implementations, process 400 may be performed by one or more systems. For example, the process 400 may be implemented by the encoder 120, the training module 122, the classification model 124, the DCDS110, and/or the user equipment 106 of fig. 1-3. In some implementations, the process 400 may be implemented as instructions stored on a non-transitory computer-readable medium, and when the instructions are executed by one or more servers, the instructions may cause the one or more servers to perform the operations of the process 400.
In some implementations, receiving the interaction data includes collecting, for a particular entity, multiple sets of interaction data corresponding to interactions with multiple different portions of the content. For example, the DCDS110 may collect multiple sets of interaction data for multiple accesses by a particular user.
The process 400 continues with generating an interaction signature that includes the encoded interaction sequence (406). For example, the encoder 120 may generate an interaction signature or sentence of the encoded interaction. In some implementations, the encoder 120 may generate the interaction signature by aggregating interaction data for a set of events that are part of a single access by a particular user prior to encoding the word. In some implementations, the encoder 120 can generate the interaction signature after encoding the word by aggregating encoded interactions of a set of events that are part of a single visit by a particular user.
In some implementations, generating the interaction signature includes generating a separate interaction signature for each set of interaction data corresponding to interactions with each different portion of the content. For example, generating the interaction signature may include generating a separate interaction signature for each access in a set of accesses.
The process 400 continues with processing the encoded interaction sequence using a model trained to classify the user interaction sequence as valid or invalid, including classifying the encoded interaction sequence as invalid using the model (408). For example, the classification model 124 may process the encoded interaction sequence using a model, such as the classification model 124, trained to classify the user interaction sequence as valid or invalid. The classification model 124 may, for example, classify an activity sequence represented by a sentence of a coded word as a valid activity sequence or an invalid activity sequence. In this particular example, the classification model 124 may classify the sequence of activities as an invalid sequence of activities because the sequence indicates, for example, that the sequence of activities was performed under the influence of malware, hijacking, or an uninteresting user who did not actually participate in the content.
In some implementations, the classification of a given entity as an actual user or an automated robot is based on tags assigned to each set of interaction data or aggregated tags assigned to sets of interaction data in an aggregation. For example, the classification model 124 may classify a particular entity as an actual user or robot based on the classifications accessed by each group or the aggregate classifications assigned to the group.
In some implementations, preventing the distribution of the set of content includes refraining from providing the specified type of content to the entity. For example, the DCDS110 may refrain from providing textual content to users who are unlikely to actually view reading articles, thereby reducing wasted bandwidth, processor cycles, memory usage, and/or display driver capabilities by not providing content that will not actually be read.
In some implementations, the DCDS110 may refrain from distributing the content to devices corresponding to the entity. For example, the DCDS110 may refrain from distributing content to the user's notebook computer based on a sequence of activities performed on the notebook computer that are determined to be performed by a malicious third party, but may continue to distribute content to the user's smartphone. In some implementations, the DCDS110 may generate an alert indicating the activity to the user. This type of distribution limitation may reduce wasted computing resources that would otherwise be used to distribute content to the user's smartphone, while still being able to distribute content to the user's notebook computer. Limiting the distribution of content in this manner prevents a waste of resources, as described above, while still being able to provide content to a particular type of device that is more likely to be actually viewed by the user.
In some implementations, preventing the distribution of the set of content includes preventing the distribution of the set of content when the given entity is classified as an automated bot. For example, the DCDS110 may prevent distribution of a set of content when the entity identified in the request is classified as an automation bot.
In some implementations, the process 400 can continue by identifying a result entry of the content distribution log corresponding to the encoded interaction sequence classified as invalid and then invalidating the result entry corresponding to the encoded interaction sequence classified as invalid. For example, the DCDS110 may identify a particular result entry within the content distribution log that corresponds to an interaction signature classified as invalid (e.g., indicating whether a particular interaction completed successfully or a set of conditions was met). The DCDS110 may then invalidate the result entries in the log. In some implementations, the DCDS110 may remove invalid entries, thereby freeing up resources, such as memory.
By using a suitably trained machine learning model, such as a Recurrent Neural Network (RNN) (e.g., a Long Short Term Memory (LSTM) network), in conjunction with encoded interactions in a standard format (e.g., the previously described vector format), the present technology is able to determine whether content should be distributed to the entity based on a sequence of encoded interactions previously performed by the entity in a computationally reliable and efficient manner. Furthermore, because the content is not distributed to entities if the encoded interaction sequence is classified as invalid, the processing and bandwidth resources required to distribute the content may be reduced while ensuring that the content is still distributed to legitimate entities.
FIG. 5 is a block diagram of an example computer system 500 that may be used to perform the operations described above. System 400 includes processor 510, memory 520, storage 530, and input/output device 540. Each of the components 510, 520, 530, and 540 may be interconnected, for example, using a system bus 550. Processor 510 is capable of processing instructions for execution within system 500. In one implementation, the processor 510 is a single-threaded processor. In another implementation, the processor 510 is a multi-threaded processor. The processor 510 is capable of processing instructions stored in the memory 520 or on the storage device 530.
The storage device 530 is capable of providing mass storage for the system 500. In one implementation, the storage device 530 is a computer-readable medium. In various different implementations, the storage device 530 may include, for example, a hard disk device, an optical disk device, a storage device shared by multiple computing devices over a network (e.g., a cloud storage device), or some other mass storage device.
The input/output device 540 provides input/output operations for the system 500. In one implementation, the input/output device 540 may include one or more network interface devices, such as an Ethernet card, a serial communication device, such as an RS-232 port, and/or a wireless interface device, such as an 802.11 card. In another implementation, the input/output devices may include driver devices configured to receive input data and send output data to other input/output devices, such as a keyboard, a printer, and a display device 460. However, other implementations may also be used, such as mobile computing devices, mobile communication devices, set-top box television client devices, and so forth.
Although an example processing system has been described in fig. 5, implementations of the subject matter and the functional operations described in this specification can be implemented in other types of digital electronic circuitry, or in computer software, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them.
An electronic document (which will be simply referred to as a document for brevity) does not necessarily correspond to a file. A document may be stored in a portion of a file that contains other documents, in a single file dedicated to the document in question, or in multiple coordinated files.
Embodiments of the subject matter and the operations described in this specification can be implemented in digital electronic circuitry, or in computer software, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them. Embodiments of the subject matter described in this specification can be implemented as one or more computer programs, i.e., one or more modules of computer program instructions, encoded on a computer storage medium (or media) for performing operations of, or controlling the operation of, data processing apparatus. Alternatively or in addition, the program instructions may be encoded on an artificially generated propagated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal, that is generated to encode information for transmission to suitable receiver apparatus for execution by the data processing apparatus. The computer storage medium may be or be embodied in a computer-readable storage device, a computer-readable storage substrate, a random or serial access memory array or device, or a combination of one or more of them. Further, while a computer storage medium is not a propagated signal, a computer storage medium can be a source or destination of computer program instructions encoded in an artificially generated propagated signal. The computer storage medium may also be or be included in one or more separate physical components or media (e.g., multiple CDs, disks, or other storage devices).
The operations described in this specification can be implemented as operations performed by data processing apparatus on data stored on one or more computer-readable storage devices or received from other sources.
The term "data processing apparatus" encompasses all kinds of apparatus, devices, and machines for processing data, including by way of example a programmable processor, a computer, a system on a chip, or a plurality or combination of the foregoing. The apparatus can comprise special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit). The apparatus can include, in addition to hardware, code that creates an execution environment for the computer program in question, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, a cross-platform runtime environment, a virtual machine, or a combination of one or more of them. The apparatus and execution environment may implement a variety of different computing model infrastructures, such as Web services, distributed computing and grid computing infrastructures.
A computer program (also known as a program, software application, script, or code) can be written in any form of programming language, including compiled or interpreted languages, declarative or procedural languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, object, or other unit suitable for use in a computing environment. A computer program may, but need not, correspond to a file in a file system. A program can be stored in a portion of a file that contains other programs or data (e.g., one or more scripts stored in a markup language document), in a single file dedicated to the program in question, or in multiple coordinated files (e.g., files that store one or more modules, sub programs, or portions of code). A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.
The processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform actions by operating on input data and generating output. The processes and logic flows can also be performed by, and apparatus can also be implemented as, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit).
Processors suitable for the execution of a computer program include, by way of example, both general and special purpose microprocessors. Generally, a processor will receive instructions and data from a read-only memory or a random access memory or both. The essential elements of a computer are a processor for performing actions in accordance with the instructions and one or more memory devices for storing instructions and data. Generally, a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks. However, a computer need not have such a device. Further, the computer may be embedded in another device, e.g., a mobile telephone, a Personal Digital Assistant (PDA), a mobile audio or video player, a game console, a Global Positioning System (GPS) receiver, or a portable storage device (e.g., a Universal Serial Bus (USB) flash drive), to name a few. Devices suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, such as internal hard disks or removable disks; magneto-optical disks; and CD ROM and DVD-ROM disks. The processor and the memory can be supplemented by, or incorporated in, special purpose logic circuitry.
To provide for interaction with a user, embodiments of the subject matter described in this specification can be implemented on a computer having a display device, e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to the user and a keyboard and a pointing device, e.g., a mouse or a trackball, by which the user can provide input to the computer. Other types of devices may also be used to provide for interaction with a user; for example, feedback provided to the user can be any form of sensory feedback, such as visual feedback, auditory feedback, or tactile feedback; input from the user may be received in any form, including acoustic, speech, or tactile input. Further, the computer may transmit and receive documents to and from the device used by the user; for example, a user is interacted with by sending a web page to a web browser on the user's client device in response to a request received from the web browser.
Embodiments of the subject matter described in this specification can be implemented in a computing system that includes a back end component, e.g., as a data server, or that includes a middleware component, e.g., an application server, or that includes a front end component, e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the subject matter described is this specification, or any combination of one or more such back end, middleware, or front end components. The components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include a local area network ("LAN") and a wide area network ("WAN"), the internet (e.g., the internet), and peer-to-peer networks (e.g., ad hoc peer-to-peer networks).
The computing system may include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other. In some embodiments, the server transmits data (e.g., HTML pages) to the client device (e.g., for displaying data to a user interacting with the client device and receiving user input from the user). Data generated at the client device (e.g., a result of the user interaction) may be received at the server from the client device.
While this specification contains many specific implementation details, these should not be construed as limitations on the scope of any invention or of what may be claimed, but rather as descriptions of features specific to particular embodiments of particular inventions. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely, various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Moreover, although features may be described as acting in certain combinations and even initially claimed as such, one or more features from a claimed combination can in some cases be excised from the combination, and the claimed combination may be directed to a subcombination or variation of a subcombination.
Similarly, while operations are depicted in the drawings in a particular order, this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order, or that all illustrated operations be performed, to achieve desirable results. In some cases, multitasking and parallel processing may be advantageous. Moreover, the separation of various system components in the embodiments described above should not be understood as requiring such separation in all embodiments, and it should be understood that the described program components and systems can generally be integrated within a single software product or packaged into multiple software products.
Thus, particular embodiments of the present subject matter have been described. Other embodiments are within the scope of the following claims. In some cases, the actions recited in the claims can be performed in a different order and still achieve desirable results. Moreover, the processes depicted in the accompanying figures do not necessarily require the particular order shown, or sequential order, to achieve desirable results. In some implementations, multitasking and parallel processing may be advantageous.
Claims (20)
1. A method performed by one or more data processing apparatus, comprising:
receiving interaction data indicating, for each given interaction of a plurality of interactions occurring at a client device, (i) an event type and (ii) a delay period specifying an amount of time between the given event and a previous event occurring prior to the given event;
encoding each given interaction as an encoded interaction having a standardized format that is a combination of (i) an event type of the given interaction and (ii) a delay period specified by interaction data of the given interaction;
generating an interaction signature comprising the encoded interaction sequence;
processing the encoded interaction sequence using a trained model to classify a user interaction sequence as valid or invalid, comprising:
classifying the encoded interaction sequence as invalid using the model; and
preventing distribution of a set of content to an entity performing the coded interaction sequence in response to a subsequently identified request to provide content to the entity.
2. The method of claim 1, wherein the model is a recurrent neural network, optionally a Long Short Term Memory (LSTM) network.
3. The method of claim 1 or 2, wherein preventing distribution of a set of content comprises refraining from providing a specified type of content to the entity.
4. The method of any of the preceding claims, wherein preventing distribution of a set of content comprises temporarily preventing distribution of the content to one or more devices corresponding to the entity.
5. The method of any of the preceding claims, further comprising:
identifying a result entry of the content distribution log corresponding to the encoded interaction sequence classified as invalid; and
invalidating the result entry corresponding to the encoded interaction sequence classified as invalid.
6. The method of claim 5, wherein invalidating a result entry corresponding to the encoded interaction sequence comprises deleting the result entry from memory.
7. The method of any one of the preceding claims, wherein:
receiving the interaction data comprises collecting, for a given entity, sets of interaction data corresponding to interactions with a plurality of different portions of content;
generating the interaction signature comprises generating a separate interaction signature for each set of interaction data corresponding to interactions with each different portion of the content, the method further comprising:
classifying the given entity as an actual user or an automation bot based on a label assigned to each set of interaction data or an aggregation label assigned to a plurality of sets of interaction data in an aggregation, wherein preventing distribution of the set of content comprises preventing distribution of the set of content when the given entity is classified as the automation bot.
8. A system, comprising:
one or more processors; and
one or more memory elements comprising instructions that when executed cause the one or more processors to perform operations comprising:
receiving interaction data indicating, for each given interaction of a plurality of interactions that occur at a client device, (i) an event type and (ii) a delay period that specifies an amount of time between the given event and a previous event that occurred prior to the given event;
encoding each given interaction as an encoded interaction having a standardized format that is a combination of (i) an event type of the given interaction and (ii) a delay period specified by interaction data of the given interaction;
generating an interaction signature comprising the encoded interaction sequence;
processing the encoded interaction sequence using a trained model to classify a user interaction sequence as valid or invalid, comprising:
classifying the coded interaction sequence as invalid using the model; and
preventing distribution of a set of content to an entity that performs the coded interaction sequence in response to a subsequently identified request to provide content to the entity.
9. The system of claim 8, wherein the model is a recurrent neural network, optionally a Long Short Term Memory (LSTM) network.
10. The system of claim 8 or 9, wherein preventing distribution of a set of content comprises refraining from providing a specified type of content to the entity.
11. The system of any of claims 8 to 10, wherein preventing distribution of a set of content comprises temporarily preventing distribution of the content to one or more devices corresponding to the entity.
12. The system of any of claims 8 to 11, the operations further comprising:
identifying a result entry of the content distribution log corresponding to the encoded interaction sequence classified as invalid; and
invalidating the result entry corresponding to the encoded interaction sequence classified as invalid.
13. The system of claim 12, wherein invalidating a result entry corresponding to the encoded interaction sequence comprises deleting the result entry from memory.
14. The system of any of claims 8 to 13, wherein:
receiving the interaction data comprises collecting, for a given entity, sets of interaction data corresponding to interactions with a plurality of different portions of content;
generating the interaction signature includes generating a separate interaction signature for each set of interaction data corresponding to interactions with each different portion of the content, the operations further comprising:
classifying the given entity as an actual user or an automation bot based on a label assigned to each set of interaction data or an aggregation label assigned to a plurality of sets of interaction data in an aggregation, wherein preventing distribution of the set of content comprises preventing distribution of the set of content when the given entity is classified as the automation bot.
15. A non-transitory computer storage medium encoded with instructions that, when executed by a distributed computing system, cause the distributed computing system to perform operations comprising:
receiving interaction data indicating, for each given interaction of a plurality of interactions occurring at a client device, (i) an event type and (ii) a delay period specifying an amount of time between the given event and a previous event occurring prior to the given event;
encoding each given interaction as an encoded interaction having a standardized format that is a combination of (i) an event type of the given interaction and (ii) a delay period specified by interaction data of the given interaction;
generating an interaction signature comprising the encoded interaction sequence;
processing the encoded interaction sequence using a trained model to classify a user interaction sequence as valid or invalid, comprising:
classifying the encoded interaction sequence as invalid using the model; and
preventing distribution of a set of content to an entity performing the coded interaction sequence in response to a subsequently identified request to provide content to the entity.
16. The non-transitory computer storage medium of claim 15, wherein the model is a recurrent neural network, optionally a Long Short Term Memory (LSTM) network.
17. The non-transitory computer storage medium of claim 15 or 16, wherein preventing distribution of a set of content comprises refraining from providing a specified type of content to the entity.
18. The non-transitory computer storage medium of any of claims 15 to 17, wherein preventing distribution of a set of content comprises temporarily preventing distribution of the content to one or more devices corresponding to the entity.
19. The non-transitory computer storage medium of any one of claims 15 to 18, the operations further comprising:
identifying a result entry of the content distribution log corresponding to the encoded interaction sequence classified as invalid; and
invalidating the result entry corresponding to the encoded interaction sequence classified as invalid.
20. The non-transitory computer storage medium of claim 19, wherein invalidating a result entry corresponding to the encoded interaction sequence comprises deleting the result entry from memory.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US16/912,009 | 2020-06-25 | ||
US16/912,009 US11704560B2 (en) | 2020-06-25 | 2020-06-25 | Pattern-based classification |
PCT/US2021/029693 WO2021262316A1 (en) | 2020-06-25 | 2021-04-28 | Pattern-based classification |
Publications (1)
Publication Number | Publication Date |
---|---|
CN115280314A true CN115280314A (en) | 2022-11-01 |
Family
ID=75954303
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202180019880.5A Pending CN115280314A (en) | 2020-06-25 | 2021-04-28 | Pattern-based classification |
Country Status (6)
Country | Link |
---|---|
US (2) | US11704560B2 (en) |
JP (1) | JP2023524362A (en) |
KR (1) | KR20220137943A (en) |
CN (1) | CN115280314A (en) |
CA (1) | CA3175105A1 (en) |
WO (1) | WO2021262316A1 (en) |
Families Citing this family (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11636361B2 (en) * | 2020-07-14 | 2023-04-25 | Yahoo Assets Llc | Content recommendations based upon historical future data |
BR112023005820A2 (en) * | 2020-10-02 | 2023-05-02 | Lenovo Singapore Pte Ltd | EXPIRY NOTIFICATION FOR A MACHINE LEARNING MODEL |
Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20180191837A1 (en) * | 2016-12-30 | 2018-07-05 | Google Inc. | Pattern based optimization of digital component transmission |
US20180300609A1 (en) * | 2017-04-13 | 2018-10-18 | Adobe Systems Incorporated | Facilitating machine-learning and data analysis by computing user-session representation vectors |
CN109074263A (en) * | 2017-02-17 | 2018-12-21 | 谷歌有限责任公司 | mobile application activity detector |
CN110795624A (en) * | 2019-01-11 | 2020-02-14 | 谷歌有限责任公司 | Analyzing a personalization framework |
Family Cites Families (10)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7769811B2 (en) * | 2003-03-03 | 2010-08-03 | Aol Llc | Instant messaging sound control |
US8910188B1 (en) * | 2011-07-14 | 2014-12-09 | Google Inc. | Deterministic data processing |
US10121157B2 (en) * | 2015-04-17 | 2018-11-06 | GoodData Corporation | Recommending user actions based on collective intelligence for a multi-tenant data analysis system |
WO2017037444A1 (en) | 2015-08-28 | 2017-03-09 | Statustoday Ltd | Malicious activity detection on a computer network and network metadata normalisation |
WO2018204399A1 (en) * | 2017-05-05 | 2018-11-08 | Microchip Technology Incorporated | Devices and methods for transmission of events with a uniform latency on serial communication links |
US11171937B2 (en) * | 2018-05-25 | 2021-11-09 | Target Brands, Inc. | Continuous guest re-authentication system |
US11539716B2 (en) | 2018-07-31 | 2022-12-27 | DataVisor, Inc. | Online user behavior analysis service backed by deep learning models trained on shared digital information |
KR20200086143A (en) * | 2019-01-08 | 2020-07-16 | 삼성전자주식회사 | Storage device and data processing method thereof |
US11869033B2 (en) * | 2019-12-09 | 2024-01-09 | Yahoo Ad Tech Llc | Content item selection and measurement determination |
US11561704B2 (en) * | 2019-12-27 | 2023-01-24 | Seagate Technology Llc | Artificial intelligence (AI) assisted anomaly detection of intrusion in storage systems |
-
2020
- 2020-06-25 US US16/912,009 patent/US11704560B2/en active Active
-
2021
- 2021-04-28 CN CN202180019880.5A patent/CN115280314A/en active Pending
- 2021-04-28 KR KR1020227030602A patent/KR20220137943A/en unknown
- 2021-04-28 CA CA3175105A patent/CA3175105A1/en active Pending
- 2021-04-28 WO PCT/US2021/029693 patent/WO2021262316A1/en active Application Filing
- 2021-04-28 JP JP2022554665A patent/JP2023524362A/en active Pending
-
2023
- 2023-05-31 US US18/326,475 patent/US20230306263A1/en active Pending
Patent Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20180191837A1 (en) * | 2016-12-30 | 2018-07-05 | Google Inc. | Pattern based optimization of digital component transmission |
CN109074263A (en) * | 2017-02-17 | 2018-12-21 | 谷歌有限责任公司 | mobile application activity detector |
US20180300609A1 (en) * | 2017-04-13 | 2018-10-18 | Adobe Systems Incorporated | Facilitating machine-learning and data analysis by computing user-session representation vectors |
CN110795624A (en) * | 2019-01-11 | 2020-02-14 | 谷歌有限责任公司 | Analyzing a personalization framework |
Also Published As
Publication number | Publication date |
---|---|
WO2021262316A1 (en) | 2021-12-30 |
US20210406670A1 (en) | 2021-12-30 |
US11704560B2 (en) | 2023-07-18 |
US20230306263A1 (en) | 2023-09-28 |
CA3175105A1 (en) | 2021-12-30 |
KR20220137943A (en) | 2022-10-12 |
JP2023524362A (en) | 2023-06-12 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11868375B2 (en) | Method, medium, and system for personalized content delivery | |
US10599774B1 (en) | Evaluating content items based upon semantic similarity of text | |
TWI636416B (en) | Method and system for multi-phase ranking for content personalization | |
US8788442B1 (en) | Compliance model training to classify landing page content that violates content item distribution guidelines | |
CN112395489B (en) | Recommendation method, recommendation device, recommendation equipment and computer storage medium | |
US10218599B2 (en) | Identifying referral pages based on recorded URL requests | |
US10445753B1 (en) | Determining popular and trending content characteristics | |
US20230306263A1 (en) | Pattern-based classification | |
US10691664B1 (en) | User interface structural clustering and analysis | |
EP4091106B1 (en) | Systems and methods for protecting against exposure to content violating a content policy | |
US10334057B2 (en) | Pattern based optimization of digital component transmission | |
EP3857406A1 (en) | Multi-tier scalable media analysis | |
US10922624B2 (en) | Identifying users of shared devices based on user interactions and identity graph | |
WO2023191811A1 (en) | Transfer machine learning for attribute prediction | |
CN112269942B (en) | Method, device and system for recommending object and electronic equipment | |
US11403324B2 (en) | Method for real-time cohort creation based on entity attributes derived from partially observable location data | |
CN112561578A (en) | Advertisement audience user behavior analysis method and system | |
US20230205754A1 (en) | Data integrity optimization | |
US9251171B2 (en) | Propagating image signals to images | |
Fuxman et al. | Enabling direct interest-aware audience selection | |
US20240160678A1 (en) | Distributing digital components based on predicted attributes | |
US20190171955A1 (en) | System and method for inferring anonymized publishers | |
CN113892085A (en) | Limiting provision and display of redundant digital components on a client device | |
WO2023234938A1 (en) | Distributing digital components based on predicted attributes | |
WO2023107479A1 (en) | Privacy preserving machine learning expansion models |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |