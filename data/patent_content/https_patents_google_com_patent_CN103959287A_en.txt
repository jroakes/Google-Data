CN103959287A - Gesture-based search - Google Patents
Gesture-based search Download PDFInfo
- Publication number
- CN103959287A CN103959287A CN201280052322.XA CN201280052322A CN103959287A CN 103959287 A CN103959287 A CN 103959287A CN 201280052322 A CN201280052322 A CN 201280052322A CN 103959287 A CN103959287 A CN 103959287A
- Authority
- CN
- China
- Prior art keywords
- search
- character
- display
- characters
- user
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0487—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser
- G06F3/0488—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser using a touch-screen or digitiser, e.g. input of commands through traced gestures
- G06F3/04883—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser using a touch-screen or digitiser, e.g. input of commands through traced gestures for inputting data by handwriting, e.g. gesture or text
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/33—Querying
- G06F16/332—Query formulation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/903—Querying
- G06F16/9032—Query formulation
Abstract
In general, a subject matter described in the specification can be embodied in methods, systems, and program products for performing searches with gesture-based input. A search system receives gesture data corresponding to one or more characters that have been drawn on a display of a client device. The search system recognizes the one or more characters that correspond to the gesture data. The search system formulates a search that includes the one or more characters as a query term. The search system communicates to the client device one or more search results for the search, and data identifying the one or more characters.
Description
the cross reference of related application
The application's requirement was submitted on October 25th, 2011, name is called the right of priority of the U. S. application sequence number 13/280,582 of " GESTURE-BASED SEARCH ", by reference its disclosure is incorporated at this.
Background technology
This instructions relates to search engine, and a specific implementation relevant with the search of using the input execution receiving by subscriber equipment display.
An example of search is the instant search based on web, and it returns to Search Results when user's entry information, for example search immediately.The Search Results of instant search upgrades conventionally when user's typing additional information.
Summary of the invention
The disclosure has been described such system and technology, utilizes this system and technology, can be between subscriber equipment and search system, by network exchange information, to promote search.In one implementation, for example, while drawing a design (, corresponding to the pattern of the letter of language, font, character) on the display of user at subscriber equipment, will initiate search.Subscriber equipment is collected the relevant gesture data of pattern of drawing with this user, and this gesture data is sent to search system together with the character of identifying before forming search terms any.
This search system is identified fresh character based on gesture data, and by the character of newly identification is flocked together and upgrades search terms with the character of identifying before.This search system then search terms based on upgrading generates the Search Results of renewal.This search system is returned to the search terms of renewal and the Search Results of renewal to subscriber equipment, and this subscriber equipment presents the search terms of renewal and the Search Results of renewal on its display.
Conventionally, the one side of the theme of the present invention of describing in this instructions can realize in computer implemented method, and it comprises: search system receives the gesture data corresponding with one or more characters of having drawn on the display of client device.This search system identification one or more characters corresponding with gesture data.This search system is formulated such search, and it comprises that one or more characters are as query term.Search system is passed on the one or more Search Results for this search to client device, and the data that identify these one or more characters.
Other embodiments in this respect comprise corresponding system and computer program.This system comprises client device and one or more computing machine, and it can be used to mutual with client device and carries out action listed above.
These embodiments and other embodiments can comprise one or more in following characteristics alternatively.Gesture data can initiate the user of client device to be received before search.This search system can be before receiving the gesture data corresponding with one or more characters, receive the data that identify one or more other characters of identifying before this search system.This search system can be passed on the data of one or more other characters of sign.Gesture data can comprise a map, and it identifies the point on the display that one or more characters draw thereon, and the sequence of drawing thereon of the point in designated display.This search can be instant search or picture search.
Conventionally, this theme of describing in this instructions can be realized on the other hand in computer implemented method, and it comprises that client device generates the gesture data corresponding with one or more characters of having drawn on client device display.This client device transmits gesture data to search system.This client device receives the Search Results that is used the search identification that comprises one or more characters by search system, and identifies the data of these one or more characters.This client device display of search results.
These embodiments and other embodiments can comprise following one or more feature alternatively.Client device can determine that controlling object no longer contacts with the display of client device.Can be in response to determining that controlling object no longer contacts the display of client device and generate gesture data.Client device can identify the data of one or more characters and show search terms based on having received.Client device can detect this user and initiate search, and determines that this user has drawn pattern on the display of client device.
Described in this instructions, the details of the one or more aspects of theme of the present invention provides in specific descriptions below and accompanying drawing.Other features, aspect and the advantage of this subject matter will be easy to understand from description, accompanying drawing and claim.
Accompanying drawing explanation
Fig. 1 shows the system that the pattern of drawing on the display of subscriber equipment based on user is carried out search.
Fig. 2 is the process flow diagram illustrating for the process example of the pattern based on drawing on the display of subscriber equipment, execution search.
Fig. 3 shows the example that presents the system of Search Results on the display of subscriber equipment for detection of the pattern of drawing and the pattern based on detecting.
Fig. 4 A to Fig. 4 C shows a series of screenshotss of illustrative user device 400, and it presents corresponding search terms and the association search result of pattern of drawing with user on the display of subscriber equipment 400.
Fig. 5 shows can be for the example system of the pattern based on drawing on the display of subscriber equipment, generation pixel map.
Fig. 6 A to Fig. 6 F shows can be for carrying out the exemplary system of search, and wherein image returns as the Search Results based on drawing a design on subscriber equipment display.
Fig. 7 A to Fig. 7 H shows can be for carrying out the exemplary system of search, and wherein search terms and the Search Results pattern based on drawing on subscriber equipment display upgrades.
Fig. 8 A to Fig. 8 D shows exemplary system, wherein can search for icon on application interface by selection and enable or forbid for carrying out the gesture on the subscriber equipment display of search.
In various accompanying drawings, like reference numerals refers to analogous element.
Embodiment
Fig. 1 shows system 100, and the pattern that it is drawn on the display of subscriber equipment 110 based on user is carried out search.System 100 is to realize therein the example of the information retrieval system of following system, parts and technology.Fig. 1 also show state (A) to during state (H), the data stream of the system of flowing through 100 parts.State (A) to state (H) can according to shown in sequence occur, or occur with the sequence of sequence shown in being different from.
System 100 comprises subscriber equipment 110, and it is coupled to search system 140 by network 130.Conventionally, subscriber equipment 110 is passed on search data 120 by network 130 to search system 140.Search system 140 is processed search data 120, and to subscriber equipment 110, returns results data 160 by network 130.Sign user's equipment 110 of result data 160 is shown to user.System 100 for example can be used for carrying out instant search, wherein when user's typing one or more character corresponding with query term, generate Search Results and be presented on the display of subscriber equipment 110, and in user's typing during for the additional character of query term, can upgrade this Search Results.
Subscriber equipment 110 can be for example smart phone, flat computer, notebook, laptop computer, E-book reader, music player, desk-top computer or any other suitable portable or state type computing equipment.Subscriber equipment 110 can comprise one or more processors, be configured for carry out by computer-readable medium stores, for carry out various client operations (such as, I/O, communication, data processing etc.) instruction.For example, subscriber equipment 110 can comprise display 112 or communication with it, and can present the information being associated with search to user.Display apparatus 112 can be implemented as adjacency sensitive display (for example, touch screen), makes user to control object (for example, finger or stylus) and entry information by touching or hovering on display 112.
In order to carry out search, user can start search application, and it provides interface via display 112 to user.By user's typing the information utilization search application interface processed by system 100, be presented on display 112, and can comprise search terms 116 and the Search Results 118 corresponding with search terms 116.User can be by drawing a design typing for the additional information of search terms on display 112.Subscriber equipment 110 can present the sign 119 of the pattern of being drawn by user on display 112, for example, and digital ink.This interface can be used the browser triggering on subscriber equipment 110 and be presented on display 112, or this interface for example can be, for searching for the special purpose interface of application (, local search application).
The pattern that user draws can be corresponding to alphabetic(al) letter, or the character of non-alphabetic language.In some applications, user can draw with rapid style of writing one or more characters of language.In other application, pattern can be corresponding to the font of any language character not necessarily, but can be explained and for triggering useful search, for example, smiling face, heart, or star-like.
The search data 120 sending to search system 140 by network 130 from subscriber equipment 110 can comprise the character 122 of identification before search system 140, and with user from the last time search of carrying out starts, the pattern of drafting is corresponding gesture data 124.In some implementations, drawing by before characterizing the pattern shown in 119, search data 120 can comprise the gesture data corresponding with one or more patterns of drawing before user.In alternative realization, search data 120 can only comprise the gesture data corresponding with the pattern of new drafting 124.In other are realized, search data can comprise the gesture data corresponding with the pattern of a plurality of new draftings.For example, when search system 140 is configured for support once during the identification of a plurality of characters, be this situation.
Network 130 can comprise Circuit Switching Data Network network, packet data network, maybe can carry any other network (for example, the network of internet protocol-based (IP) or the network based on asynchronous transfer mode (ATM), comprise wired network or wireless network) of data.Network 130 can be configured for processes web business, such as HTML (Hypertext Markup Language) (HTTP) business and HTML (Hypertext Markup Language) (HTML) business.Network 130 can comprise the Internet, wide area network (WAN), LAN (Local Area Network) (LAN), wired and the wireless network of analog or digital (for example, IEEE802.11 network, PSTN (PSTN), integrated services digital network network (ISDN) and digital subscriber line (xDSL)), the third generation (3G) mobile telecom network or the 4th generation (4G) mobile telecom network, wired ethernet network, privately-owned network (such as, in-house network, radio, TV, cable, satellite, and/or any other is for carrying sending or tunnel transmission mechanism of data), or this network is any appropriately combined.
Search system 140 can be implemented as and is arranged on each other for example, by the computer program on the one or more network equipments in one or more positions of network (, network 130) coupling.Search system 140 can comprise one or more servers, for example, cloud computing server, server farm or another allocate servers (comprise be configured for carry out by computer-readable medium stores, for carrying out one or more processors of the instruction of various server operations).In an example implementation, search system 140 can be the server farm of being responsible for by server engine supplier.Search system 140 comprises the front end 145 that is connected to gesture engine 150 and search engine 155.Front end 145 can be to be configured for to process all gateway servers of communicating by letter that carry out with the outer entity of server farm.Front end 145 can also be configured for the operation of coordinating gesture engine 150 and search engine 155, determine search terms, and the search terms based on definite returns to Search Results with the gesture data based on receiving.
Gesture engine 150 can be realized on the server of the one or more software process of master control, and these software process are configured for processes gesture data 147, and identifies the character 152 mating with this gesture data.The sign of character 152 can occur by closely spending coupling between one or more characters at gesture data 147 with in being included in the character database that can be used for gesture engine 150.Degree coupling can for example be used statistical distance measurement (for example, having the character of minimum statistics distance apart from gesture data 147 by sign) to be determined closely.Gesture data 147 can be with similar together with the gesture data 124 of search data 120 transmission.The character 152 of sign, together with the character 122 of identifying before, can form search terms 154.In some implementations, gesture engine 150 can be configured for and once identify a plurality of characters 152, thus gesture data corresponding to the single pattern that coupling is drawn with user or a plurality of pattern.
Search engine 155 can be realized on the server of the one or more software process of master control, these software process are configured for processes search terms 154, and by match search item 154 or comprise that one or more web pages of search terms 154 are designated Search Results 157.Search engine generally includes index engine, and it for example, by Literacy Internet Resources (, web page, image or new article) produce index; And sequence engine, for the resource having identified is sorted.The index of resource and sequence can be used conventional art to carry out.In this example, search engine 155 can be web server, is configured for and returns to the Search Results corresponding with search terms 157.Search Results 157 can comprise the link of going to web page, and these web pages comprise search terms or mate with search terms based on certain specific tolerance.Alternatively, Search Results 157 can comprise the link of going to image or video file or audio file, or its any combination, and these links are based on certain specific tolerance and associated with search terms.
The result data 160 that search system 140 is returned to subscriber equipment 110 can comprise message unit, it is applicable to format with transmission on network 130, or for example, for be shown to user's (, shown in the web browser on subscriber equipment 110) on subscriber equipment 110.For example, Search Results 157 (for example can be included in marking language document, HTML (Hypertext Markup Language) (HTML) document or extend markup language (XML) document), it is as being included in payload in Internet Protocol (IP) grouping, sending on network 130.Result data 160 can comprise the character 162 of identification and use the character 162 of identification as the Search Results 164 of search terms generation.In alternative realization, result data 160 can only comprise Search Results 164.The character 162 of identification can comprise the character 122 sending together with search data 120, identify before, and the character 152 of the new identification corresponding with gesture data 124.Search Results 164 can be identical with Search Results 157.Alternatively, Search Results 164 can comprise and the similar information of Search Results 157, but can from for transmitting and carry out different formattings to subscriber equipment 110 on network 130.
The interface (for example, via web browser) that subscriber equipment 110 for example uses search application to provide presents result data 160, and presents Search Results 164 with display 112.The character 162 of identification shows as the search terms 172 in query frame or " search box ", shows in the resultant field 174 of Search Results 164 below the search terms 172 showing simultaneously.
Reference example data stream, at state (A) before, on subscriber equipment 110, the search of operation application has received the character (for example, " B ") of identification from search system 140 via network 130.The character of identification is presented on display 112 as search terms 116.Subscriber equipment 110 also receives the Search Results corresponding with the character of identification via network 130 from search system 140, and these results are shown as result of page searching 118.That search terms 116 has been drawn corresponding to user with associated result of page searching 118 on display 112, as the pattern of the search part for " banana pie recipe ".
During state (a), for more than typing search terms, user carries out gesture indication by draw new pattern on display 112, searches for application interface simultaneously and is presented on display 112.User for example, by (touching, use the part such as finger, stylus, user's hand or arm, or the control object of another suitable input mechanism) display 112 and describe character and draw a design on display 112 by contacting mobile input mechanism with display.Although Fig. 1 has described user, use finger on display, to describe character, can use other suitable input mechanisms.In addition, term " drafting gesture ", " track drafting ", " drawing a design ", " describing gesture " and " describing character " can be exchanged use, and wherein each relates to the similar action of user's entry information on subscriber equipment.
Along with user draws a design on display 112, the sign 119 that presents this pattern on display 112, simultaneously the data associated with this pattern (for example, display 112 pixel coordinates corresponding with the position of user institute touch display 112) are caught as gesture data by subscriber equipment 110.
Search application determines that user has completed gesture typing.For example, search application can the contact of user's finger from display 112 remove and when scheduled time slot does not contact display 112 again, determine that user has completed gesture typing.Scheduled time slot may be very short, for example, and 1 second, or can be some seconds.
In some implementations, subscriber equipment 110 may not have the processing power of the identification character corresponding with the pattern of user on display 112.During state (B), search application via network 130 send the gesture data 124 corresponding with user's pattern on display 112 to search system 140 to process.In some implementations, gesture data 124 can adopt the form of pixel map, and in alternative realization, gesture data 124 can transmit to be different from certain other form of pixel map.For example, search application can send [x, y] coordinate of the display sampled point corresponding with this gesture.
In some implementations, pixel map is the array of the pixel coordinate of the display 112 that touches of representative of consumer.Each element in array can comprise the coordinate of the single pixel of display 112.The order that element in array can draw a design based on user on display 112 and being arranged in sequence, can be promoted by the element of analyzing in array element sequence of living in user trajectory reconstruct.The example of pixel map is presented in Fig. 5.
Except gesture data 124, the character 122 (" B " in the accompanying drawings) of identification before search application also sends to search system 140.Search application sends the character 122 of identification before together with gesture data 124, so that the sign of auxiliary 140 pairs of Search Results of search system, or the aid identification character corresponding with gesture data 124.
In some implementations, the gesture data 124 that search application sends can comprise the gesture data corresponding with the character 122 of identification before.This can assist search system 140 to utilize the character of identification before to correct mistakes (for example, for the original character of poor identification), and it is what on earth that character below can be used for revising original character.
The character 122 of identification forms the search data 120 sending to search system 140 by network 130 together with gesture data 124 before.Search data 120 also can comprise auxiliary search system 140 signs or resolve the character 122 of identification before and the instruction of gesture data 124.These instructions also auxiliary search system 140 are identified new character by processing gesture data 120.In addition, these instructions can assist search system 140 that identification character is treated to search terms, for searching Search Results.Search data 120 can send with suitable transformat on network 130, for example, and as the data that are included in one or more IP groupings.
Search data 120 is received by front end 145 at search system 140 places.Character 122 (for example " B ") and gesture data 147 that front end 145 is processed search data 120 and extracted identification before.Gesture data 147 can be with identical as the gesture data 124 of search data 120 part transmission.Alternatively, gesture data 147 can comprise and the similar information of gesture data 124, but get rid of except some form that may be added for transmission on network 130 by search application.
Based on institute's Extracting Information (comprising the instruction that can be included together with search data 120) is checked, the definite gesture data 147 of front end 145 is treated to be processed by gesture engine 150.Therefore,, during state (C), front end sends gesture data 147 to gesture engine 150.
Gesture engine 150 is processed gesture data 147 and is identified the one or more characters that mate with gesture data 147.Gesture engine 150 can for example have the character of the highest gesture recognition confidence value by selection, select specific character (in the accompanying drawings, " a "), to pass on back front end 145.
During state (D), gesture engine 150 forward end 145 are returned to the character 152 (for example, " a ") of new identification.In some implementations, in order to preserve computational resource, gesture engine 150 can not be stored the character 152 of gesture data 147 or new identification in local storage.On the contrary, once the character 152 of newly identification is transferred to front end 145, can abandon the character 152 of gesture data 147 or new identification.
In some implementations, front end 145 can send to gesture engine 150 character 122 (for example, " B ") and the gesture data 147 of identification before.In some implementations, the character 122 of identification can provide contextual information to gesture engine 150 before, to promote the identification of the character corresponding with gesture data 147.For example, before gesture engine 150 can use, the character combination occurring without in the language-specific of being everlasting eliminated in the character " B " of identification, for example, and the combination in English " Bx ".On the contrary, gesture engine 150 can be with the character 122 of identification before by chracter search space constraint during to character 122 pairing with identification before, be formed with the character that implication combines.
Front end 145 receives the character 152 of new identification from gesture engine 150.Front end can be for example instruction based on together with may being included in search data 120 determine before the character 122 of identification and the character 152 of new identification will be for carrying out search.Therefore, front end 145 can be combined the character 152 of the character of identification before 122 and new identification, for example, to form the search terms 154 (, " Ba ") of renewal.During state (E), front end 145 is to search engine 155 transmission search termses 154.
Search engine 155 use search termses 154 are carried out search, and during state (F), forward end 145 is returned to corresponding the linking of web page with search terms 154 couplings, as Search Results 157.Search Results 157 can send to quote the form of the search results pages of Search Results or the part of search results pages.In some implementations, in order to preserve computational resource, search engine 155 may not be in local storage memory search item 154 or Search Results 157.On the contrary, once forward end 145 has been transmitted Search Results 157, search terms 154 or Search Results 157 can be dropped.Therefore, front end 154 can, by providing for each search example, to search engine 150 the renewal search terms 154 that comprises the character 122 of identification before and the character 152 of new identification, promote search engine 155 to return to the accurate Search Results corresponding with search terms 154.
After search engine 155 has received Search Results 157, the character 122 of identification and the character 152 of the new identification word territory 162 of filling character before front end 145 utilizes.Front end 145 is also included in Search Results 157 in Search Results territory 164.During state (G), front end 145 sends result data 160 by network 130 to subscriber equipment 110.
In some implementations, front end 145 may not stored character, gesture data or the Search Results of identification in local storage.On the contrary, once to user device transmissions identification character and Search Results, the character of identification, gesture data or Search Results can be dropped.Therefore, in order to promote front end 145 to provide correct search terms for each search example to search engine 155, search on subscriber equipment 110 application can be when sending search data 120 to search system 140, the character 122 of identification before search data 120 comprises.
During state (H), subscriber equipment 110 reception result data 160, and pass on result data 160 to the search application of operation on subscriber equipment 110.Search application result data 160, to extract from character field 162 and Search Results 164 character of identifying.Search is applied in the character that presents identification on display 112, usings as the search terms 172 in search application interface search box.
Search application also presents Search Results 164 in the resultant field 174 below shown search terms 172 for example.As shown in state (H), search terms 172 is " Ba ", resultant field 174 comprises with phrase " Bank of Example ", the Search Results of " Banana Pie Recipe " and " Bank of Alaska " (each mates with search terms " Ba ").Due to Search Results comprise go to user's information needed (for example, " Banana Pie Recipe ") link of corresponding web page, user may be for example by patting the part directly over corresponding with " Banana Pie Recipe " link on display 112, the web page that this is corresponding is checked in selection, and this web page may present and the selected web page being associated that links subsequently on display 112.
On the other hand, user may want to continue search and therefore input the more multiword symbol corresponding with search terms (for example, by describe in the manner described above character on display 112, or passing through certain other proper method).For each character of typing thus, said process can repeat, comprise: the character that sends gesture data and identify before to search system 140 by network 130, by the gesture engine 150 identification character corresponding with gesture data, by search engine 155, determine the Search Results corresponding with search terms, and by network 130, to subscriber equipment 110, return to character and the Search Results of identification.Therefore, the search terms 172 presenting in query frame or search box and the corresponding Search Results in resultant field 174 can, along with user's typing multiword symbol and upgrading more, provide the search experience strengthening thus., when the search of carrying out is while immediately searching for, can be for example like this.
In a word, character 122 and gesture data 124 that the search application on subscriber equipment 110 is identified before to search system 140 transmission, to promote determining of 155 pairs of Search Results of search engine.Front end 145 sends character 162 and the nearest Search Results 164 of identification to subscriber equipment 110, make the character of identification present to user as search terms 172, and Search Results is presented in resultant field 174.Therefore, the explanation that system 100 provides this user to draw a design to user, and the context that shown Search Results can also be provided.
Fig. 2 carries out the process flow diagram of process 200 examples of search for the pattern based on drawing on subscriber equipment display.For example, this process 200 can be used for carrying out instant search, wherein Search Results is presented on subscriber equipment display when user's typing one or more character corresponding with query term, and Search Results along with user's typing for the additional character of query term and upgrade.Process 200 can be realized by the one or more computer programs that are arranged on one or more computing machines.The process 200 of being carried out by the parts of system 100 has below been described.Yet this process 200 can be carried out by other system or system configuration.
This process 200 starts (202) when system receives information with execution search.For example, user can be by starting search application and describing character and initiate search on display 112 on subscriber equipment 110.
This system detects user's gesture (206).For example, display 112 can be touch-sensitive display, and subscriber equipment 110 can be configured for when user draws a design on display 112, the touch of detection user finger.Along with user draws a design on display 112, subscriber equipment 110 can be caught the data that are associated with this pattern, and coordinate or the screen area of display 112 pixels that the part of the display 112 for example touching with user is corresponding, using as gesture data.Subscriber equipment 110 can be stored the gesture data of catching.In some implementations, gesture data can be stored by the form of pixel map.Yet in some alternative realization, gesture data can be to be different from certain other form storage of pixel map.
This system transmission gesture data is to process (206).In some implementations, except gesture data, the character that this system is identified before also transmitting, and during other are realized at some, only transmit gesture data.For example, search system in local storage for given search sessions high-speed cache before during some of identification character realize, can be this situation.Yet, during at some, other are realized, search system may not can in local storage the character of identification before storage, and the search application on subscriber equipment sends the character of identification before together with gesture data thus, so that auxiliary search system sign Search Results, as previously mentioned.
In addition, the search system identification character corresponding with gesture data can be assisted in the character of identification before, as described above.For example, the application of the search on subscriber equipment 110 can be transmitted gesture data to search system via network.In addition, search application also can send the character of identification before to search system.
This system receives any character and the gesture data (208) of identification before of transmission.For example, this search system can receive the search data by the search application transport on subscriber equipment at front end.Character and the gesture data of identification before search data can comprise.In some implementations, search system can only receive gesture data.
The data identification character (210) of this system based on receiving.For example, the front-end processing search data of search system, and extraction and the similar gesture data of gesture data 124 and the character of identification before.Front end sends gesture data to gesture engine 150, and this gesture engine 150 is processed gesture data and determined the recognizable character mating with this gesture data.After this, gesture engine 150 forward end 145 are returned to the character 152 of new identification.
Search (212) formulated in the character of this system based on identification.For example, after having received the character 152 of new identification from gesture engine 150, the character 122 that front end 145 is identified before can determining and the character 152 of new identification are for carrying out search.Therefore, front end 145 can form new search terms 154 by the character 122 of identification before combination and the character 152 of new identification, and to search engine 155 transmission search termses 154.
This system generates Search Results (214).For example, after front end 145 has received search terms 154, search engine 155 can be carried out search with search terms 154.The result of search operation can be used as Search Results 157 and is back to front end 145.The web page form linking that search engine 155 can be gone to comprise the web page mating with search terms 154 sends Search Results 157.
The identification character that this systematic collection is corresponding with received gesture data and Search Results.Subsequently, the character (216) of this system transmission Search Results and identification.In some implementations, the character of identification and the character of new identification before this system transmission, and in some implementations, this system is only transmitted the character of new identification.For example, the front end 145 of search system 140 generates the result data 160 that comprises character field 162 and Search Results territory 164.Front end 145 is put into character field 162 by the character 152 of the character of identification before 122 and new identification, and Search Results 157 is included in Search Results territory 164.Front end 145 sends result data 160 by network 130 to subscriber equipment 110 then.
This system receives the character (218) of Search Results and identification.For example, subscriber equipment 110 is from search system 140 reception result data 160, and forwards it to the search application operating on subscriber equipment 110.
After having received the character of Search Results and identification, this system display of search results (220).For example, operate in the search application result data 160 on subscriber equipment 110, to extract character 162 and the Search Results 164 of identification.This search is applied on display 112, in the search box of search application interface, presents the character 162 of identification, as the search terms upgrading.This search application also in the resultant field 174 of search application interface (being usually located under the search terms 172 of demonstration) present Search Results 164.
After having shown Search Results, whether this systems inspection detects another gesture (222).If this system is determined, another gesture detected, this system repetitive process 200, carrys out display of search results (220) from detecting gesture (204) to more new search corresponding to the gesture based on new detection.Yet, if gesture do not detected, this system closure process 200 (224).
User can accord with by the more multiword of describing character or input for search terms by certain other proper method on display 112.For each character of typing thus, operate in search application on subscriber equipment 110 can to search system 140, send by network 130 before character and the gesture data of identification; System 140 engine 150 that can make to use gesture is identified the character corresponding with gesture data, search terms formulated in the character of the character with front end 145 based on identification before and new identification, with search engine 155, determine the Search Results corresponding with search terms, and by network 130, to subscriber equipment 110, return to character and the Search Results of identification, to present to user.
Fig. 3 shows the example that presents the system 300 of Search Results on subscriber equipment display for detection of the gesture of drawing and the gesture based on detecting.This system 300 for example can utilize the subscriber equipment 110 in system 100 to realize.System 300 for example can be for carrying out instant search, wherein when user's typing one or more character corresponding with query term, can on the display of subscriber equipment 110, present Search Results, wherein Search Results is along with user's typing is upgraded for the additional character of query term.
System 300 comprises search application 302, and it is coupled to touch-sensitive display 304, network interface 306 and high-speed cache 308.Network interface 308 is also coupled to antenna 310.Search application 302 has some parts, comprise the display interface device 312 that search application is coupled to touch-sensitive display 304, touch disambiguation device 314, pixel map maker 316, search application 302 is coupled to the cache interface 318 of high-speed cache 308, inquire about formulator 320, search application 302 is coupled to the identification character resolver 322 of network interface, and user interface maker 324.High-speed cache 308 comprises the character 326 of identification and the pixel 328 touching.
In some implementations, search application 302 can be the software application (for example, executable software code) for example residing in, in the upper local storage of computing equipment (, subscriber equipment 110).During at some, other are realized, this search application 302 can be hardware adaptations, and for example, wherein programming has field programmable gate array (FPGA) or the microchip of search functionality, for example, other hardware in itself and computing equipment (, subscriber equipment 110) are coupled.
Search application 302 can be configured for character recognition corresponding to pattern that promotion is drawn on computing equipment display with user, and uses the search terms based on institute's identification character to return to Search Results.Search application 302 can be by user for example by patting to start this computing equipment on shown icon in computing equipment main screen.Alternatively, search application 302 more or less continuous service on computing equipment.
For example, interface on search application 302 displays (, the display 112 of subscriber equipment 110) that can be configured for by being presented at computing equipment presents search terms and association search result to user.In some implementations, search application interface can be provided by the web browser operating on subscriber equipment.During at some, other are realized, interface can be to apply the interface 302 web browsers of using except specializing in search.
Search application 302 for example can be configured for, with search system (, search system 140) communicates by letter.Search application 302 can forward the gesture data corresponding with the pattern of drawing on computing equipment display to search system.As response, search application 302 can receive back from long-range search system the character of Search Results and identification.Search application 302 can present via interface search terms and the association search result corresponding with the character of identification on the display of computing equipment.
System 300 has to be configured for for example accepts user, by the touch-sensitive display 304 (, touch screen) of touch display 304 entry informations.Touch-sensitive display 304 is also configured for to user and shows various information, corresponding search terms and the association search result of pattern of for example drawing on the surface of display 304 with user.Touch-sensitive display 304 can be for example the display 112 of subscriber equipment 110.In some implementations, touch-sensitive display 304 can be also proximity sensitive display, that is, display 304 can be configured for the physics proximity that detects user, and the one or more configuration parameters that therefore regulate display, to promote user's comfortable reading.
System 300 has network interface 306, and it is for example configured for back-up system 300, via one or more networks (, network 130) and remote system and devices communicating.Network interface can be a hardware, for example ether port or IEEE802.11 chip, or a software, for example, and software radio, or hardware and software is any appropriately combined.By search application 302, by the information of transmitting with communicating by letter of search system or receiving, by the network interface 306 of the point of the entrance as system 300 and/or outlet, processed.
System 300 has antenna 310, and it can be a hardware of the information that is configured for transmission and reception and remote system and devices exchange (as electromagnetic wave, for example, radio frequency (RF) electric wave or infrared (IR) electric wave).Antenna 310 receives data waiting for transmission from being coupled to the network interface 306 of antenna 306, and these data are broadcasted as electromagnetic wave.Antenna 310 also receives as electromagnetic data from remote system and equipment, and the data that forward reception to network interface 306 are to process.System 300 can have an antenna 310 or a plurality of antenna 310.
System 300 has high-speed cache 308, and it can be realized in local storage with storage information.For example, high-speed cache 308 can be realized in the random access storage device (RAM) providing in subscriber equipment 110.High-speed cache 308 can be configured for quick storage and fetch the data of being used by search application 302.Search application 302 can be stored in the character of identification 326 in high-speed cache 308.The character 326 of identification can comprise the character that draws a design on the surface based at touch-sensitive display 304 and identify.For example, the character 326 of identification can comprise the before character of identification corresponding with search terms 116, or the character of the before identification corresponding with search terms 172 and the newly combination of the character of identification.
Search application 302 also can be stored in the pixel of touch 328 in high-speed cache 308.The pixel 308 touching comprises about touch-sensitive display 304 pixel coordinate or the screen position corresponding with user institute touch display 304 parts.Display 112 pixel coordinates corresponding to part of the display 112 for example, touching when, the pixel 308 of touch can be included in user and draws a design on display 112, with this user.The pixel 328 touching also can comprise the pattern of for example drawing with user gesture data (for example, pixel map) that be associated, by subscriber equipment 110 to remote system 140 transmission.In addition, the pixel 328 of touch can comprise the gesture data being associated with the gesture of typing before, and corresponding character may be identified and be stored in the character 326 of identification with it.System 300 can be used the information associated with the pixel 328 touching, for example, when drawing a design (, being presented on the track 119 on display 112) on the surface at display user, provide visible track to characterize on touch-sensitive display 304.System 300 can also be used the information associated with the pixel 328 touching, and generates gesture data (for example, pixel map) corresponding to pattern of drawing on touch-sensitive display 304 with user.
System 300 has the display interface device 312 with touch-sensitive display 304 couplings by search application 302.In some implementations, display interface device 312 can be provided as the module of search application 302, and during at some, other are realized, display interface device 312 at the computing equipment of run search application 302 (for example can be provided as, subscriber equipment 110) common application on, it shares (comprising search application 302) by different application.Display interface device 312 can be graphical user interface (GUI), or can be text based interface or it is any appropriately combined.In some implementations, display interface device 312 can be provided by the web browser being included in system 300.During at some, other are realized, display interface device 312 can be to apply the interface 302 web browsers of using except specializing in search.Display interface device 312 can be configured for and on touch-sensitive display 304, present search terms and the association search result drawing a design based on user on touch-sensitive display 304.
System 300 comprises touch disambiguation device 314.In some implementations, the touch qi device 314 that disappears can be provided as the module of search application 302, and in other are realized, the touch qi device 314 that disappears (for example can be provided as on the computing equipment of run search application 302, subscriber equipment 110) common application, it is shared by different application (comprising search application 302).The touch qi device 314 that disappears is configured between the various touch action of carrying out on the surface of touch-sensitive display 304 user and distinguishes.For example, the touch qi device 314 that disappears can be configured for following two actions are distinguished: relate to user temporarily from removing the action of its point to point with the finger or gesticulate " i " with contacting of touch-sensitive display 304, and relate to user from removing from contacting of touch-sensitive display 304 the different actions that its finger finishes with indicator diagram.
The touch qi device 314 that disappears also can be responsible for the order that the system of translating 300 provides.This order (for example can come from touch-sensitive display 304, the display 112 associated with subscriber equipment 110), or other these provenances that come from the system of being coupled to 300 ((for example comprise dedicated button or soft key, its function can change in time, with and function may be displayed on the region or position of closing on specific button on touch-sensitive display 304)).The touch qi device 314 that disappears can be interpreted as common form by the input motion on touch-sensitive display 304, and the motion of these explanations (for example, short pressing, long pressing, tip-tap and straight line pull) is passed to search application 302.In addition, touch the qi device 314 that disappears and for example can determine and receive order in which region or the position of display 304, and determine thus these orders for, the application that illustrates on display.The touch qi device 314 that disappears can also be reported this input to task manager (not shown), and this task manager is then to suitable module or these inputs of application report.
System 300 comprises pixel map maker 316.In some implementations, pixel map maker 316 can be provided as the module of search application 302, and during at some, other are realized, the computing equipment that pixel map maker 316 can be provided as run search application 302 (for example, subscriber equipment 110) common application on, it shares between different application (comprising search application 302).Pixel map maker 316 is configured for the pattern of drawing on the surface of touch-sensitive display 304 based on user and generates pixel map.For example, pixel map maker can be communicated by letter with high-speed cache 308, to fetch the pixel 328 of touch, and uses the information being associated with the pixel 328 touching to create pixel map.Pixel map can be by search application 302 as for example, being sent to search system with user's corresponding gesture data that draws a design (, gesture data 124) on the surface of touch-sensitive display 304.
System 300 comprises cache interface 318.In some implementations, cache interface 318 can be provided as the module of search application 302, and during at some, other are realized, the computing equipment that cache interface 318 can be provided as run search application 302 (for example, subscriber equipment 110) common application on, it shares in different application (comprising search application 302).Cache interface 318 is configured for supports search application 302 (the different parts that comprise search application 302) to communicate by letter with high-speed cache 308.Cache interface 318 promote the characters 326 of identification and the pixel 328 that touches by the various component stores of system 300 in high-speed cache 308.Cache interface 318 also promotes the character 326 of identification in high-speed cache 308 and the pixel 328 of touch to be fetched by the various parts (for example,, by pixel map maker 316 and inquiry formulator 320) of system 300.
In some implementations, system 300 can comprise the inquiry formulator 320 of the parts that are provided as search application 302.For example, during character corresponding to the pattern that has processing power sign to draw on touch-sensitive display 304 with user when system 300, can be this situation.In this realization, inquiry formulator 320 can be configured for fresh character corresponding to pattern that identification is drawn on touch-sensitive display 304 with user.Inquiry formulator 320 can be communicated by letter with high-speed cache 308, to store the character of new identification.The character 326 that inquiry formulator 320 is identified before can also obtaining from high-speed cache 308, and itself and the character of new identification are combined, thereby search terms formulated.Inquiry formulator 320 is coupled to network interface 306, and it can be sent to search system (for example, search system 140) by network interface 306 by the search terms of formulation.
During at some, other are realized, character corresponding to pattern that system 300 may not have processing power sign to draw on touch-sensitive display 304 with user.In this realization, can not there is not inquiry formulator 320.
System 300 comprises the identification character resolver 322 of the parts that are provided as search application 302.Identification character resolver 322 is coupled to network interface 306, and from search system, receives information by network interface 306.For example, identification character resolver 322 can be from search system 140 reception result data 160.Identification character resolver 322 is configured for resolves the information (for example, result data 160) receiving and character (for example, the character 162 of identification) and the Search Results (for example, Search Results 164) that extracts identification.Identification character resolver 322 sends to user interface maker 324 character and the Search Results extracting.In addition, identification character resolver 322 is coupled to cache interface 318, with and to the character that high-speed cache 308 sends identification, using and store as the character 326 of identification.
System 300 comprises the user interface maker 324 that is provided as search application 302 parts.User interface maker 324 receives character and the Search Results of identification from the character resolver 322 of identification, and its form of layout is to used display interface device 312 to be presented on touch-sensitive display 304.For example, the part that user interface maker 324 can be used as on subscriber equipment 110 search application is included.In this case, user interface maker 324 can layout the form of character 162 of identification, using and present as being presented at query frame or the search terms in search box 172 of searching for application interface on display 112.User interface maker 324 also can be rendered as the link of going to web page by Search Results 164 in the resultant field 174 (being usually located under the search terms 172 of demonstration) in being included in shown search application interface.
Fig. 4 A to Fig. 4 C shows a series of screenshotss of illustrative user device 400, and it presents search terms and the association search result corresponding with the pattern of being drawn by user on subscriber equipment 400 displays.Subscriber equipment 400 can be subscriber equipment 110 for example, or it can be certain other the suitable equipment that comprises touch-sensitive display.
Fig. 4 A shows the display 402 that presents the subscriber equipment 400 of searching for application interface 404 thereon.Search application interface 404 comprises search box 406 and Search Results territory 408.The pattern that user draws on the surface of display 402 is indicated by track 410.
Display 402 can be the touch-sensitive display 112 being for example associated with subscriber equipment 110.Fig. 4 A shows when for example display 402 not when initiating search, while generating Search Results.This is by empty search box 406 and 408 indications of empty Search Results territory.Search application interface 404 can be worked as user and for example by patting the icon being presented in subscriber equipment 400 main screens, be initiated when search is applied to be presented on display 402 on subscriber equipment 400.Alternatively, search application can operate on subscriber equipment 400 continuously, and interface 404 is always presented on display 402.
User can be by drawing a design typing search terms on display 402.Subscriber equipment 400 can be configured for the track that pattern on display 402 is provided.For example, user may draw pattern " b " on display 402, and the track 410 that therefore shows indicator diagram " b " in the prospect of display 402, and search application interface 404 is visible in background.The pattern that can draw based on user is identified one or more characters, and uses by search system 140 Search Results that for example one or more identification characters return as query term.Fig. 4 B shows when the display 402 when identifying the character corresponding with the pattern of describing with reference to figure 4A.For example, the character of identification can be " b ", and it is as search terms, to generate the Search Results returning to subscriber equipment 400.The character of identification is presented on search application interface 404 as the search terms 412 in search box 406.Search Results 414 is presented in the Search Results territory 408 of search application interface 404.For example, as shown in Figure 4 B, search terms 412 is " b ", and corresponding Search Results 414 comprises going to and comprises phrase " Bank of Example ", the link of the web page of " Bozo The Clown " and " Bill the Builder ", each phrase mates with search terms " b ".
Although shown search terms 412 and association search result 414, user for example can be by drawing new pattern or utilizing certain other proper method to input the additional character corresponding with search terms on display 402.Subscriber equipment 400 can be configured for the sign that new pattern on display 402 is provided, and it is superimposed upon on search application interface 404.For example, as shown in Figure 4 B, user can draw a design " a " on display 402, and therefore the sign 416 of indicator diagram " a " is presented in the prospect of display 402, and search interface 404 is visible in background.Characterize 416 some part that may block Search Results 414, for example, with the link of phrase " Bozo The Clown ".
Can the user based on new draw a design to identify one or more characters, and search terms is updated to and comprises the character of identification before and the character of new identification.Therefore, the search terms based on upgrading generates new Search Results, and returns to this Search Results to subscriber equipment 400.
Fig. 4 C shows the display 402 when identifying the fresh character corresponding with pattern with reference to the description of figure 4B, and has upgraded search terms to comprise fresh character, and the new search result based on upgrading search terms is back to subscriber equipment 400.Together with the character of the character of identification and new identification, as the search terms in search box 406, be presented on search application interface 404 before.New search result is presented in the Search Results territory 408 of search application interface 404.For example, as shown in Figure 4 C, the search terms 418 of renewal is " ba ", and corresponding Search Results 420 comprises going to and comprises phrase " Bank of Example ", the link of the web page of " Baby " and " Banana Recipe ", each phrase and search terms " ba " match.The link of going to the web page that comprises phrase " Bozo The Clown " and " Bill The Builder " (it is included in Search Results 414) is not included in Search Results 420, because they do not mate with the search terms " ba " upgrading.
If Search Results 420 comprises the Search Results of match user expectation search, this user for example can select to visit corresponding web page by patting the part directly over corresponding with matching result link on display 402, and this web page may present subsequently with selected and links associated web page on display 402.On the other hand, this user can be for example by describing the lip-deep character of display 402 or with certain other proper method, continuing the input more multiword symbol corresponding with search terms in mode mentioned above.For example, as shown in Figure 4 C, user can draw new pattern " n " on display 402, and therefore the track 422 of indicator diagram " n " may be displayed in the prospect of display 402, and search terms 418 and Search Results 420 are visible in background.This system can identify the fresh character into " n " subsequently, search terms is updated to " ban ", and generates the Search Results mating with the search terms upgrading.
Fig. 5 shows the example system 500 that the pattern that can be used for based on drawing on subscriber equipment display becomes pixel map next life.This system 500 can be realized by the one or more computer programs that are arranged on one or more computing machines.Below system 500 is described as being realized by search application 302.Yet system 500 can be realized by other application, system or system configuration.
System 500 comprises display 502, and it is included in subscriber equipment or coupling with it, and user can draw the pattern by 504 representatives thereon.Display 502 can map to the pel array with row 506 and row 508.This system 500 can generate the pixel map corresponding with the pattern of 504 representatives 510.
Display 502 can be to be configured for the touch-sensitive display (for example, touch screen) of accepting user's information of typing by touch display 502.Touch-sensitive display 502 can be the display 304 being for example included in system 300.Touch-sensitive display 502 can be configured for to user and show the track by user's information of typing by touching this display 502, for example, and the pattern trace of being drawn on the surface of display 502 by user.For example, user can utilize finger or certain other suitable input method draw a design on the surface of display 502 " g ".This system 500 will be processed user's pattern, and the track 504 that presents pattern " g " on display 502.
Pixel corresponding to the point on the display 502 that system 500 storages touch with this user or position.This for example can be by touch any appropriately combined execution of qi device 314 or pixel map maker 316 or its that disappear.System 500 is based on row 506 and row 508 and display 502 is mapped to pel array.Each pixel in array is identified by its corresponding row and column, and for example, elements A 1 as shown in Figure 5 and element B 2 represent two different pixels.Generate the array of pixel, each position that makes display 502 is characterized by the element of array.
When user draws a design on display 502, system 500 detects each position of the display 502 being touched by user, and identification represents the pixel of detected position.For example, along with user draws the pattern being represented by track 504 on display 502, user can come according to the sequence of the numbering in Fig. 5 (1)-(22) indication the position of touch display.The position that this system 500 touches sequence detection, and the sign pixel corresponding with touched position.The element of system 500 using the pixel of sign as array stored, and for example, system 500 is stored respectively the coordinate D2 corresponding with the pixel that is associated with touch position (1)-(22), C2, B2, B3, B4, C4, D4, D3, D2, D4, D5, D6, D7, C7, B7, B6, B5, C5, D5, D4, E4.Aforesaid operations can be carried out by disappear qi device 314 of touch, its in high-speed cache 308 by pixel coordinate D2, C2, B2, B3, B4, C4, D4, D3, D2, D4, D5, D6, D7, C7, B7, B6, B5, C5, D5, D4, E4 stores as the pixel 328 touching.
When system 500 is based on definite user touch display 502 predetermined amount of time and while determining that user has completed the character rendering on display 502, system 500 is fetched the pixel of storage and generated pixel map not.For example, pixel map maker 316 is fetched the pixel 328 of touch from high-speed cache 308, and the generation pixel map 510 corresponding with track 504, is { D2, C2, B2, B3, B4, C4, D4, D3, D2, D4, D5, D6, D7, C7, B7, B6, B5, C5, D5, D4, E4}.Subsequently, system 500 can for example, send pixel map 510 to search system (, search system 140), and for identifying the character corresponding with pixel map, and the character based on identification generates Search Results.
Fig. 6 A to Fig. 6 F shows system 600 examples that can be used for carrying out search, and wherein, image is returned as the Search Results based on drawing a design on subscriber equipment display 602.Display 602 can be for example the display of subscriber equipment 110, and it has presented the search application interface that search terms and association search result are shown on display 602 to user.As shown in Fig. 6 A to Fig. 6 F, user can draw a design on display 602, with typing search terms.The system 600 identification character corresponding with the pattern of user's typing, and the search terms 604 that can advise comprising institute's identification character.User can select one of search terms of suggestion, mate, or user can ignore advised search terms, and continue by drawing a design typing for the character of search terms on display if it determines search inquiry with user's meaning.Search application can provide the selection by selecting icon 608 to forbid advised search terms to user.
Utilization draws a design and is identified as the character of search terms based on user, and system 600 is returned to the thumbnail of image 606, as Search Results.Along with user draws more pattern, the more character of system 600 identification, the search terms that renewal is advised is to comprise the character of new identification, and the renewal Search Results that returns to the thumbnail that comprises the image 610 mating with the search terms upgrading.The thumbnail of image and search terms is presented by the search application interface on display 602.
Fig. 7 A to Fig. 7 H shows system 700 examples that can be used for carrying out search, and wherein the pattern based on drawing on subscriber equipment display 702 upgrades search terms and Search Results.Display 702 can be for example the display of subscriber equipment 110, and it is presented on the search application interface that search terms and association search result are shown on display 602 to user.As shown in Fig. 7 A to Fig. 7 H, user can draw a design with typing search terms on display 702.The system 700 identification character corresponding with user's typing pattern, and the search terms 704 that can advise comprising institute's identification character.User can select one of search terms of suggestion, mate, or user can ignore advised search terms, and continue by drawing a design typing for the character of search terms on display if it determines search inquiry with user's meaning.
The character that the pattern identification that use is drawn based on user is search terms, system 700 is returned to Search Results.Along with user draws more pattern, the more character of system 700 identification, upgrades the search terms of advising to comprise the character of new identification, and returns to renewal Search Results.As shown in Fig. 7 H, Search Results can comprise the thumbnail of the image 708 mating with search terms, and go to the web page that mates with search terms based on word, link 706.The thumbnail of the links and images based on word is presented by the search application interface on display 702 together.
Fig. 8 A to Fig. 8 D shows the example of system 800, wherein can search for icon on application interface by selection and enable or forbid for carrying out the gesture on the display 802 of subscriber equipment of search.Display 802 can be for example the display of subscriber equipment 110, and it is presented on the search application interface that search terms and association search result are shown on display 802 to user.As shown in Fig. 8 A and Fig. 8 C, search application can provide the icon 804 in search box 806, to indicate the search by gesture to be activated.Search application can provide and select 808 search based on gesture with forbidding to user.If user selects the search of forbidding based on gesture, icon 804 disappears from search box 806, as shown in Fig. 8 D.Yet search application can provide instruction 812 on interface, its indication how by modifications search for apply arrange to reactivate the search by gesture.
In some implementations, search application also can provide about how to carry out the demonstration 810 of searching for by gesture, as shown in Figure 8 B.This demonstration 810 can understand how to make to use gesture (for example,, by drawing a design and the typing character corresponding with search terms) execution search on display 802 by assisted user.
The various realizations of system described herein and technology can realize with digital circuit, integrated circuit, special designs ASIC (special IC), computer hardware, firmware, software and/or its combination.These various realizations can be included in the realization in one or more computer programs, these programs can comprise that (it can be special use or general at least one programmable processor, coupling is to receive data and instruction with stocking system, at least one input equipment and at least one output device, and transmission data and instruction) programmable system on carry out and/or explain.
These computer programs (being also known as program, software, software application or code) comprise the machine instruction for programmable processor, and can realize at level process and/or OO programming language, and/or in compilation/machine language.As used herein, term " machine readable media " or " computer-readable medium " (for example relate to any computer program, device and/or equipment, disk, CD, storer, programmable logic device (PLD) (PLD)), it comprises for providing machine instruction and/or data to programmable processor the machine readable media receiving as the machine instruction of machine-readable signal.Term " machine-readable signal " relates to for any signal of machine instruction and/or data is provided to programmable processor.
For mutual with user is provided, system described herein and technology can realize on computers, it (for example has display apparatus for show from information to user, CRT (cathode-ray tube (CRT)) or LCD (liquid crystal display) monitor), can utilize it that pointing apparatus (for example, mouse or trace ball) of input is provided to computing machine with user.Other kind of equipment also can be used for providing mutual with user; For example, the feedback providing to user can be any sensory feedback form (for example, visible feedback, can listen feedback or traceable feedback); And from user's input in any form (for example, sound, voice or traceable input) receive.
System described herein and technology can realize in computing system, it comprises that back-end component (for example, data server), or comprise that middleware component (for example, or comprise the front end component (client device for example, with graphical user interface or web browser application server),, user can be undertaken by the realization of itself and system described herein and technology alternately), or any combination of this back-end component, middleware or front end component.The parts of system can be for example, by any form or the medium (, communication network) of digital data communication interconnected.The example of communication network comprises local network (" LAN "), wide area network (" WAN ") and the Internet.
Computing system can comprise client and server.Client and server conventionally away from each other, and conventionally by communication network mutual.The relation of client and server realizes by means of the computer program that operates on each computing machine and have each other a client-server relation.
The character from English alphabet is used in above-mentioned exemplary realization.In other are realized, character can be the character from non-English alphabet or non-letter character.
A plurality of embodiments have been described.Yet, will understand, can, without departing from the spirit and scope of the present invention, make various modifications.For example, the major part of this document has been described in Reference News's transmitting-receiving and mapping application, but also can realize other forms of graphical application, such as interactive program guiding, web page navigation and convergent-divergent, and other this application.
In addition, the logic flow of describing in accompanying drawing not need to according to shown in particular order or sequence order, realize the result of expectation.In addition, can provide other steps from the flow process of describing, or can removal process, and can remove miscellaneous part or add miscellaneous part to it from institute's descriptive system.Therefore, other embodiments also fall in the scope of following claim.
Claims (15)
1. a computer implemented method, comprising:
By search system, received: (i) pixel map corresponding with one or more characters of having drawn on client device display, and (ii) by described search system, used the data of one or more other characters of one or more other pixel maps identifications before sign;
The described one or more characters corresponding with described pixel map identified in pixel map by described search system based on described reception and described one or more other characters;
By described search system, formulate and comprise that described one or more character and described one or more other characters are as the search of query term; And
By described search system, to described client device, passed on: (i) for one or more Search Results of described search, (ii) identify the data of the described one or more characters corresponding with the pixel map of described reception, and (iii) sign is used the data of described one or more other characters of described one or more other pixel maps identifications before by described search system.
2. method as claimed in claim 1, wherein said pixel map is received before the user of described client device initiates described search.
3. method as claimed in claim 1, wherein said pixel map (i) identifies the point on the described display that described one or more character draws thereon, and (ii) specifies the drawn sequence of point on described display.
4. method as claimed in claim 1, wherein said search comprises instant search.
5. method as claimed in claim 1, wherein said search comprises picture search.
6. a system, comprising:
One or more computing machines and one or more storage facilities, described one or more storage facilitiess storage when by described one or more computing machines execution, can operate to cause that described one or more computing machine carries out the instruction of following operation, comprising:
By search system, received: (i) pixel map corresponding with one or more characters of having drawn on client device display, and (ii) by described search system, used the data of one or more other characters of one or more other pixel maps identifications before sign;
The described one or more characters corresponding with described pixel map identified in pixel map by described search system based on described reception and described one or more other characters;
By described search system, formulate and comprise that described one or more character and described one or more other characters are as the search of query term; And
By described search system, to described client device, passed on: (i) for one or more Search Results of described search, (ii) identify the data of the described one or more characters corresponding with the pixel map of described reception, and (iii) sign is used the data of described one or more other characters of described one or more other pixel maps identifications before by described search system.
7. system as claimed in claim 6, wherein said pixel map is received before the user of described client device initiates described search.
8. system as claimed in claim 6, wherein said pixel map (i) identifies the point on the described display that described one or more character draws thereon, and (ii) specifies the drawn sequence of point on described display.
9. system as claimed in claim 6, wherein said search comprises instant search.
10. system as claimed in claim 6, wherein said search comprises picture search.
11. 1 kinds of non-transient computer-readable mediums, storage comprises the software of the instruction that can be carried out by one or more computing machines, when carrying out, can cause described one or more computing machine executable operations, comprising:
By search system, received: (i) pixel map corresponding with one or more characters of having drawn on client device display, and (ii) by described search system, used the data of one or more other characters of one or more other pixel maps identifications before sign;
The described one or more characters corresponding with described pixel map identified in pixel map by described search system based on described reception and described one or more other characters;
By described search system, formulate and comprise that described one or more character and described one or more other characters are as the search of query term; And
By described search system, to described client device, passed on: (i) for one or more Search Results of described search, (ii) identify the data of the described one or more characters corresponding with the pixel map of described reception, and (iii) sign is used the data of described one or more other characters of described one or more other pixel maps identifications before by described search system.
12. as the computer-readable medium of claim 11, and wherein said pixel map is received before the user of described client device initiates described search.
13. as the computer-readable medium of claim 11, and wherein said pixel map (i) identifies the point on the described display that described one or more character draws thereon, and (ii) specifies the drawn sequence of point on described display.
14. as the computer-readable medium of claim 11, and wherein said search comprises instant search.
15. as the computer-readable medium of claim 11, and wherein said search comprises picture search.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US13/280,582 | 2011-10-25 | ||
US13/280,582 US8478777B2 (en) | 2011-10-25 | 2011-10-25 | Gesture-based search |
PCT/US2012/061258 WO2013062883A1 (en) | 2011-10-25 | 2012-10-22 | Gesture-based search |
Publications (2)
Publication Number | Publication Date |
---|---|
CN103959287A true CN103959287A (en) | 2014-07-30 |
CN103959287B CN103959287B (en) | 2018-01-09 |
Family
ID=47076457
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201280052322.XA Active CN103959287B (en) | 2011-10-25 | 2012-10-22 | Search based on gesture |
Country Status (6)
Country | Link |
---|---|
US (1) | US8478777B2 (en) |
EP (1) | EP2771816B1 (en) |
JP (1) | JP6400477B2 (en) |
KR (1) | KR20140089550A (en) |
CN (1) | CN103959287B (en) |
WO (1) | WO2013062883A1 (en) |
Cited By (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN105373552A (en) * | 2014-08-25 | 2016-03-02 | 中兴通讯股份有限公司 | Display terminal based data processing method |
WO2016062191A1 (en) * | 2014-10-21 | 2016-04-28 | 中兴通讯股份有限公司 | Information publication method, information receiving method and apparatus, and information sharing system |
CN106125937A (en) * | 2016-06-30 | 2016-11-16 | 联想(北京)有限公司 | A kind of information processing method and processor |
CN107209756A (en) * | 2015-02-10 | 2017-09-26 | 微软技术许可有限责任公司 | Digital ink is supported in marking language document |
CN109213333A (en) * | 2017-07-07 | 2019-01-15 | 联想（新加坡）私人有限公司 | For converting speech into text and using the device and method of posture insertion character |
Families Citing this family (33)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7974962B2 (en) | 2005-01-06 | 2011-07-05 | Aptiv Digital, Inc. | Search engine for a video recorder |
WO2012142323A1 (en) | 2011-04-12 | 2012-10-18 | Captimo, Inc. | Method and system for gesture based searching |
US20110158605A1 (en) * | 2009-12-18 | 2011-06-30 | Bliss John Stuart | Method and system for associating an object to a moment in time in a digital video |
US20110176788A1 (en) * | 2009-12-18 | 2011-07-21 | Bliss John Stuart | Method and System for Associating an Object to a Moment in Time in a Digital Video |
CN102436477A (en) * | 2011-10-11 | 2012-05-02 | 鸿富锦精密工业（深圳）有限公司 | Device with related content search function and method |
JP5694234B2 (en) * | 2012-05-11 | 2015-04-01 | 株式会社東芝 | Electronic device, handwritten document display method, and display program |
KR101395480B1 (en) * | 2012-06-01 | 2014-05-14 | 주식회사 팬택 | Method for activating application based on handwriting input and terminal thereof |
US8868598B2 (en) * | 2012-08-15 | 2014-10-21 | Microsoft Corporation | Smart user-centric information aggregation |
US9483518B2 (en) | 2012-12-18 | 2016-11-01 | Microsoft Technology Licensing, Llc | Queryless search based on context |
US8943092B2 (en) * | 2013-03-04 | 2015-01-27 | Microsoft Corporation | Digital ink based contextual search |
KR102203885B1 (en) * | 2013-04-26 | 2021-01-15 | 삼성전자주식회사 | User terminal device and control method thereof |
JP5898141B2 (en) * | 2013-07-24 | 2016-04-06 | 京セラドキュメントソリューションズ株式会社 | Search program and search device |
EP2829962A3 (en) | 2013-07-24 | 2015-05-27 | Kyocera Document Solutions Inc. | Retrieval device for retrieving data specific information used for identifying data of data group |
US10445417B2 (en) | 2013-08-01 | 2019-10-15 | Oracle International Corporation | Entry of values into multiple fields of a form using touch screens |
KR102063103B1 (en) * | 2013-08-23 | 2020-01-07 | 엘지전자 주식회사 | Mobile terminal |
US9672287B2 (en) * | 2013-12-26 | 2017-06-06 | Thomson Licensing | Method and apparatus for gesture-based searching |
US10628848B2 (en) * | 2014-05-15 | 2020-04-21 | Oath Inc. | Entity sponsorship within a modular search object framework |
KR102152819B1 (en) * | 2014-07-08 | 2020-09-07 | 엘지전자 주식회사 | Mobile terminal and method for controlling the same |
CN104408099B (en) * | 2014-11-18 | 2019-03-12 | 百度在线网络技术（北京）有限公司 | Searching method and device |
US20160154555A1 (en) * | 2014-12-02 | 2016-06-02 | Lenovo (Singapore) Pte. Ltd. | Initiating application and performing function based on input |
US20160259488A1 (en) * | 2015-03-06 | 2016-09-08 | Alibaba Group Holding Limited | Navigation user interface for compact mobile devices |
WO2017019028A1 (en) * | 2015-07-28 | 2017-02-02 | Hewlett Packard Enterprise Development Lp | Application launch state determination |
US10228775B2 (en) * | 2016-01-22 | 2019-03-12 | Microsoft Technology Licensing, Llc | Cross application digital ink repository |
CN108153801B (en) * | 2016-12-06 | 2023-05-23 | 松下知识产权经营株式会社 | Information processing method, information processing apparatus, and recording medium |
US20190155958A1 (en) * | 2017-11-20 | 2019-05-23 | Microsoft Technology Licensing, Llc | Optimized search result placement based on gestures with intent |
JP7270876B2 (en) * | 2018-11-19 | 2023-05-11 | 治 寺田 | program |
KR20200119378A (en) * | 2019-03-25 | 2020-10-20 | 현대자동차주식회사 | Apparatus and method for mode control of vehicle, and vehicle system |
US11429879B2 (en) * | 2020-05-12 | 2022-08-30 | Ubs Business Solutions Ag | Methods and systems for identifying dynamic thematic relationships as a function of time |
US11875543B2 (en) | 2021-03-16 | 2024-01-16 | Microsoft Technology Licensing, Llc | Duplicating and aggregating digital ink instances |
US11361153B1 (en) | 2021-03-16 | 2022-06-14 | Microsoft Technology Licensing, Llc | Linking digital ink instances using connecting lines |
US11435893B1 (en) * | 2021-03-16 | 2022-09-06 | Microsoft Technology Licensing, Llc | Submitting questions using digital ink |
US11372486B1 (en) | 2021-03-16 | 2022-06-28 | Microsoft Technology Licensing, Llc | Setting digital pen input mode using tilt angle |
US11526659B2 (en) | 2021-03-16 | 2022-12-13 | Microsoft Technology Licensing, Llc | Converting text to digital ink |
Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5105468A (en) * | 1991-04-03 | 1992-04-14 | At&T Bell Laboratories | Time delay neural network for printed and cursive handwritten character recognition |
US5420943A (en) * | 1992-04-13 | 1995-05-30 | Mak; Stephen M. | Universal computer input device |
KR100633231B1 (en) * | 2005-04-18 | 2006-10-12 | 엘지전자 주식회사 | Portable terminal with a information search function based on gesture recognition and implementating method thereof |
US20080104020A1 (en) * | 2006-10-27 | 2008-05-01 | Microsoft Corporation | Handwritten Query Builder |
US20100271315A1 (en) * | 2009-04-28 | 2010-10-28 | Microsoft Corporation | Encoding and decoding adaptive input device inputs |
Family Cites Families (34)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4972496A (en) * | 1986-07-25 | 1990-11-20 | Grid Systems Corporation | Handwritten keyboardless entry computer system |
US4988981B1 (en) * | 1987-03-17 | 1999-05-18 | Vpl Newco Inc | Computer data entry and manipulation apparatus and method |
US5252951A (en) * | 1989-04-28 | 1993-10-12 | International Business Machines Corporation | Graphical user interface with gesture recognition in a multiapplication environment |
US5428692A (en) * | 1991-11-18 | 1995-06-27 | Kuehl; Eberhard | Character recognition system |
US5500937A (en) * | 1993-09-08 | 1996-03-19 | Apple Computer, Inc. | Method and apparatus for editing an inked object while simultaneously displaying its recognized object |
WO1996001453A1 (en) * | 1994-07-01 | 1996-01-18 | Palm Computing, Inc. | Multiple pen stroke character set and handwriting recognition system |
JP2845149B2 (en) * | 1994-12-28 | 1999-01-13 | 日本電気株式会社 | Handwritten character input device and handwritten character input method |
US5864635A (en) * | 1996-06-14 | 1999-01-26 | International Business Machines Corporation | Distinguishing gestures from handwriting in a pen based computer by stroke analysis |
US6057845A (en) * | 1997-11-14 | 2000-05-02 | Sensiva, Inc. | System, method, and apparatus for generation and recognizing universal commands |
US7840912B2 (en) * | 2006-01-30 | 2010-11-23 | Apple Inc. | Multi-touch gesture dictionary |
US6573883B1 (en) * | 1998-06-24 | 2003-06-03 | Hewlett Packard Development Company, L.P. | Method and apparatus for controlling a computing device with gestures |
US6407679B1 (en) * | 1998-07-31 | 2002-06-18 | The Research Foundation Of The State University Of New York | System and method for entering text in a virtual environment |
US7293231B1 (en) * | 1999-03-18 | 2007-11-06 | British Columbia Ltd. | Data entry for personal computing devices |
US6791537B1 (en) * | 2001-07-06 | 2004-09-14 | Mobigence, Inc. | Display of ink for hand entered characters |
US6938222B2 (en) * | 2002-02-08 | 2005-08-30 | Microsoft Corporation | Ink gestures |
US7079713B2 (en) * | 2002-06-28 | 2006-07-18 | Microsoft Corporation | Method and system for displaying and linking ink objects with recognized text and objects |
US7002560B2 (en) * | 2002-10-04 | 2006-02-21 | Human Interface Technologies Inc. | Method of combining data entry of handwritten symbols with displayed character data |
JP2005267292A (en) * | 2004-03-19 | 2005-09-29 | Citizen Watch Co Ltd | Handwritten character input device and method thereof |
US9008447B2 (en) * | 2004-04-01 | 2015-04-14 | Google Inc. | Method and system for character recognition |
US7372993B2 (en) * | 2004-07-21 | 2008-05-13 | Hewlett-Packard Development Company, L.P. | Gesture recognition |
US7719523B2 (en) * | 2004-08-06 | 2010-05-18 | Touchtable, Inc. | Bounding box gesture recognition on a touch detecting interactive display |
US20060095504A1 (en) | 2004-08-24 | 2006-05-04 | Gelsey Jonathan I | System and method for optical character information retrieval (OCR) via a thin-client user interface |
US20070273674A1 (en) * | 2005-03-18 | 2007-11-29 | Searete Llc, A Limited Liability Corporation | Machine-differentiatable identifiers having a commonly accepted meaning |
JP2007034871A (en) * | 2005-07-29 | 2007-02-08 | Sanyo Electric Co Ltd | Character input apparatus and character input apparatus program |
US7747639B2 (en) * | 2005-08-24 | 2010-06-29 | Yahoo! Inc. | Alternative search query prediction |
JP2007188410A (en) * | 2006-01-16 | 2007-07-26 | Sharp Corp | Electronic dictionary device, electronic dictionary search method, and electronic dictionary program |
US8094939B2 (en) * | 2007-06-26 | 2012-01-10 | Microsoft Corporation | Digital ink-based search |
US7949157B2 (en) * | 2007-08-10 | 2011-05-24 | Nitin Afzulpurkar | Interpreting sign language gestures |
US20090058820A1 (en) * | 2007-09-04 | 2009-03-05 | Microsoft Corporation | Flick-based in situ search from ink, text, or an empty selection region |
US20100097322A1 (en) * | 2008-10-16 | 2010-04-22 | Motorola, Inc. | Apparatus and method for switching touch screen operation |
RU2011134935A (en) * | 2009-02-04 | 2013-03-10 | Кейлесс Системз Лтд. | DATA INPUT SYSTEM |
US8819597B2 (en) | 2009-04-10 | 2014-08-26 | Google Inc. | Glyph entry on computing device |
US20100318696A1 (en) * | 2009-06-15 | 2010-12-16 | Nokia Corporation | Input for keyboards in devices |
US8341558B2 (en) * | 2009-09-16 | 2012-12-25 | Google Inc. | Gesture recognition on computing device correlating input to a template |
-
2011
- 2011-10-25 US US13/280,582 patent/US8478777B2/en active Active
-
2012
- 2012-10-22 WO PCT/US2012/061258 patent/WO2013062883A1/en active Application Filing
- 2012-10-22 EP EP12778589.7A patent/EP2771816B1/en active Active
- 2012-10-22 JP JP2014538854A patent/JP6400477B2/en active Active
- 2012-10-22 KR KR1020147013702A patent/KR20140089550A/en active Search and Examination
- 2012-10-22 CN CN201280052322.XA patent/CN103959287B/en active Active
Patent Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5105468A (en) * | 1991-04-03 | 1992-04-14 | At&T Bell Laboratories | Time delay neural network for printed and cursive handwritten character recognition |
US5420943A (en) * | 1992-04-13 | 1995-05-30 | Mak; Stephen M. | Universal computer input device |
KR100633231B1 (en) * | 2005-04-18 | 2006-10-12 | 엘지전자 주식회사 | Portable terminal with a information search function based on gesture recognition and implementating method thereof |
US20080104020A1 (en) * | 2006-10-27 | 2008-05-01 | Microsoft Corporation | Handwritten Query Builder |
US20100271315A1 (en) * | 2009-04-28 | 2010-10-28 | Microsoft Corporation | Encoding and decoding adaptive input device inputs |
Non-Patent Citations (1)
Title |
---|
J.R.RAPHAEL: ""Google’s Android Gesture search A fingers-on tour "", 《PC WORD》 * |
Cited By (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN105373552A (en) * | 2014-08-25 | 2016-03-02 | 中兴通讯股份有限公司 | Display terminal based data processing method |
WO2016062191A1 (en) * | 2014-10-21 | 2016-04-28 | 中兴通讯股份有限公司 | Information publication method, information receiving method and apparatus, and information sharing system |
CN107209756A (en) * | 2015-02-10 | 2017-09-26 | 微软技术许可有限责任公司 | Digital ink is supported in marking language document |
CN106125937A (en) * | 2016-06-30 | 2016-11-16 | 联想(北京)有限公司 | A kind of information processing method and processor |
CN106125937B (en) * | 2016-06-30 | 2019-05-31 | 联想(北京)有限公司 | A kind of information processing method and processor |
CN109213333A (en) * | 2017-07-07 | 2019-01-15 | 联想（新加坡）私人有限公司 | For converting speech into text and using the device and method of posture insertion character |
CN109213333B (en) * | 2017-07-07 | 2023-02-28 | 联想（新加坡）私人有限公司 | Apparatus and method for converting speech into text and inserting characters using gestures |
Also Published As
Publication number | Publication date |
---|---|
EP2771816A1 (en) | 2014-09-03 |
JP2014535110A (en) | 2014-12-25 |
JP6400477B2 (en) | 2018-10-03 |
CN103959287B (en) | 2018-01-09 |
EP2771816B1 (en) | 2019-08-07 |
WO2013062883A1 (en) | 2013-05-02 |
KR20140089550A (en) | 2014-07-15 |
US8478777B2 (en) | 2013-07-02 |
US20130103712A1 (en) | 2013-04-25 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN103959287A (en) | Gesture-based search | |
CN101334790B (en) | Method and system for controlling browser by using image | |
US9507519B2 (en) | Methods and apparatus for dynamically adapting a virtual keyboard | |
US9268987B2 (en) | Method of recognizing QR code in image data and apparatus and method for converting QR code in content data into touchable object | |
EP2954692B1 (en) | Telestration system for command processing | |
US20140258838A1 (en) | Expense input utilities, systems, and methods | |
US10789474B2 (en) | System, method and apparatus for displaying information | |
CN103814351A (en) | Collaborative gesture-based input language | |
CN102141889A (en) | Typing assistance for editing | |
CN103176690A (en) | Display control apparatus, display control method, and program | |
CN109086834B (en) | Character recognition method, character recognition device, electronic equipment and storage medium | |
US10175883B2 (en) | Techniques for predicting user input on touch screen devices | |
CN102165404A (en) | Object detection and user settings | |
WO2019218688A1 (en) | Method and device for displaying information and searching information | |
WO2021168304A1 (en) | Proactive learning of network software problems | |
CN111787154A (en) | Information processing method and electronic equipment | |
WO2022268023A1 (en) | Fingerprint recognition method and apparatus, and electronic device and readable storage medium | |
KR20040019036A (en) | System and Method For Collaborative Handwriting Input | |
CN111967304A (en) | Method and device for acquiring article information based on edge calculation and settlement table | |
EP3910496A1 (en) | Search method and device | |
CN109391836B (en) | Supplementing a media stream with additional information | |
CN113869063A (en) | Data recommendation method and device, electronic equipment and storage medium | |
KR100963976B1 (en) | Method, apparatus, system and computer-readable recording medium for arithmetical operation based on image information | |
WO2017205160A1 (en) | Sequential two-handed touch typing on a mobile device | |
TWI519997B (en) | Server, user apparatus and terminal device |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
C06 | Publication | ||
PB01 | Publication | ||
C10 | Entry into substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
GR01 | Patent grant | ||
GR01 | Patent grant | ||
CP01 | Change in the name or title of a patent holder |
Address after: American CaliforniaPatentee after: Google limited liability companyAddress before: American CaliforniaPatentee before: Google Inc. |
|
CP01 | Change in the name or title of a patent holder |