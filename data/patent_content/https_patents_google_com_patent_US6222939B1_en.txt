US6222939B1 - Labeled bunch graphs for image analysis - Google Patents
Labeled bunch graphs for image analysis Download PDFInfo
- Publication number
- US6222939B1 US6222939B1 US08/882,223 US88222397A US6222939B1 US 6222939 B1 US6222939 B1 US 6222939B1 US 88222397 A US88222397 A US 88222397A US 6222939 B1 US6222939 B1 US 6222939B1
- Authority
- US
- United States
- Prior art keywords
- graph
- image
- model
- bunch
- graphs
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Expired - Lifetime
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V40/00—Recognition of biometric, human-related or animal-related patterns in image or video data
- G06V40/10—Human or animal bodies, e.g. vehicle occupants or pedestrians; Body parts, e.g. hands
- G06V40/16—Human faces, e.g. facial parts, sketches or expressions
- G06V40/168—Feature extraction; Face representation
- G06V40/171—Local features and components; Facial parts ; Occluding parts, e.g. glasses; Geometrical relationships
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/40—Extraction of image or video features
- G06V10/42—Global feature extraction by analysis of the whole pattern, e.g. using frequency domain transformations or autocorrelation
- G06V10/422—Global feature extraction by analysis of the whole pattern, e.g. using frequency domain transformations or autocorrelation for representing the structure of the pattern or shape of an object therefor
- G06V10/426—Graphical representations
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/40—Extraction of image or video features
- G06V10/44—Local feature extraction by analysis of parts of the pattern, e.g. by detecting edges, contours, loops, corners, strokes or intersections; Connectivity analysis, e.g. of connected components
- G06V10/443—Local feature extraction by analysis of parts of the pattern, e.g. by detecting edges, contours, loops, corners, strokes or intersections; Connectivity analysis, e.g. of connected components by matching or filtering
- G06V10/449—Biologically inspired filters, e.g. difference of Gaussians [DoG] or Gabor filters
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V30/00—Character recognition; Recognising digital ink; Document-oriented image-based pattern recognition
- G06V30/10—Character recognition
- G06V30/19—Recognition using electronic means
- G06V30/196—Recognition using electronic means using sequential comparisons of the image signals with a plurality of references
- G06V30/1983—Syntactic or structural pattern recognition, e.g. symbolic string recognition
- G06V30/1988—Graph matching
Definitions
- the present invention relates to technology for recognizing and analyzing objects that are shown in camera or video images.
- the present invention relates to technology which compensates for variability of images for different objects of the same type, or for images of the same object (due to differences in position, scale, orientation, pose, illumination, deformation, noise etc.).
- the present invention provides a process for image analysis.
- ⁇ ij is a distance vector between nodes i and j in model graph m.
- a number M of jets is associated with each node of the associated bunch graph, and at least one jet is labeled with an attribute characteristic of one of the number of images.
- the model bunch graph may be manually prepared by associating a standard grid of points over an image, correcting node positions to fall over designated sites characteristic of the image, and extracting jets at the nodes.
- FIG. 1 shows a data format for image representation.
- FIG. 2 shows graphs as placed over objects.
- FIG. 3 shows graphs as placed over objects, emphasizing an irregular, object-type adapted graph structure.
- FIG. 4 shows a bunch graph and image graph.
- the process of the invention is based on a technique of representing images by wavelets and of comparing different images by elastic graph matching.
- An application of the present invention is the extraction of a fixed, sparse image representation (called “image graph”) from each image in the gallery and of each new image to be recognized.
- An image graph sparsely summarizes an image in terms of those data that are important for recognition or analysis. Comparison of two image graphs is computationally very cheap, and recognition from large galleries thus becomes feasible.
- the extraction of the relevant data (that is, of the image graph) from an image is achieved with reference to a small collection (the “bunch graph”) of sample images in which the relevant data have been identified manually.
- the different sample images in the bunch graph are selected to cover a large range of variants of the type of objects to be recognized or analyzed.
- the bunch graph thus covers a virtually infinite range of variants.
- Graphs G with an underlying two-dimensional topography are used.
- Each node denotes a jet J n and each edge denotes a distance vector ⁇ x e .
- the graph has the form of a rectangular grid with constant vertical and constant horizontal spacing between nodes.
- the kernels are corrected for their DC value, i.e., the sum ⁇ x ⁇ j (x) vanishes. All kernels are similar in the sense that they can be generated from one kernel simply by dilation and rotation.
- kernel size index ⁇ 0, . . . , 4 ⁇ , and orientation index ⁇ 0, . . . , 7 ⁇ , for simplicity labeled with one index j ⁇ +8 ⁇ .
- the full wavelet transform provides 40 complex coefficients at each pixel (5 frequencies and 8 orientations). This array of coefficients at one pixel will be referred to as the jet J(x), see FIG. 1 .
- jets play the role of local feature vectors. Images are compared in terms of jets (and not in terms of pixel values), as described below.
- This similarity function S a has the advantage of varying smoothly with shifts of the image.
- the term d•k j with the estimated displacement vector d compensates for rapid phase shifts due to small variation in the positions x or x′ of the two jets being compared.
- a set “grid” of pixel positions (“nodes”, see 23 in FIG. 2) is selected in the image.
- the grid can be exactly rectangular (as in 21 a , FIG. 2) or can be deformed (as in 21 b , FIG. 2) or of a different arrangement, such as in FIG. 3 .
- Nodes can be selected by hand, or they can be selected by the automatic procedure described below. Pairs of neighboring nodes can be connected by “edges,” see FIG. 2 or 3 . For each node, after it is positioned within the image, the jet computed at that pixel location is recorded.
- a distance vector is recorded (the distance vector is a pair of pixel distances in the x and y directions).
- This data structure (jets and distance vectors) is called an “image graph”. It can be incorporated in a “model domain”, by storing it in an appropriate file. In this case, the graph is called a “model graph”.
- model graph two types of model domains will be described, called “gallery” and “bunch graph”, as described below.
- Elastic Graph Matching is the process by which a stored model graph G M is matched to a new image.
- the model graph have N nodes, labeled with jets J n , and E edges, labeled with distance vectors ⁇ x e .
- an image graph G I is selected from the new image.
- This image graph has the same structure as G M (same number of nodes, same pairs of nodes connected by edges).
- node points are selected in the image, jets are extracted from the image, distance vectors are computed, and the resulting structure, a “tentative image graph”, is compared to the model graph G M .
- the second term on the right-hand-side is the “edge similarity,” computed as the average squared difference between pairs of corresponding edges. (The second term is also called the “distortion term”).
- the system parameter ⁇ controls the relative importance of node similarity and edge similarity.
- the graph similarity ( 6 ) between the image graph and the model graph is optimized by varying the node positions of the tentative image graph appropriately, with the jet for each node being determined anew after the position of the node is varied. After each modification, the new graph similarity is computed. If it is higher, the new tentative image graph is selected; if it is lower, the old tentative image graph is retained.
- a simple procedure for optimizing the tentative image graph is as follows.
- the first tentative image graph is formed as an exact replica of the relative node positions of the model graph, placed in the middle of the image. Then, the position of the tentative image graph is modified (without distortion) in random steps of plus or minus 5 pixels in x or y direction, until a (local) optimum is reached, using the magnitude similarity, equation 4.
- phase Randomly chosen nodes are visited and displacements d are chosen (up to a maximum of 1 pixel distance) to optimize the phase similarity, equation 5. Each node is visited just once.
- the optimal graph resulting at the end of this elastic matching procedure is called the “image graph.” For an example see 21 b in FIG. 2 or 31 - 34 in FIG. 3 .
- M model graphs are assembled into a gallery.
- These M model graphs are all of the same qualitative structure, that is, they have the same number N of nodes (which are numbered 1 to N), and each pair of nodes (identified by a pair of numbers) is either connected in all of the M model graphs or not connected in all model graphs.
- the model graphs in the gallery differ in the jets that are affixed to the nodes and in the distance vectors affixed to the edges.
- the model graphs as stacked up on each other, see FIG. 4, with nodes bearing the same number aligned with each other.
- This gallery of model graphs is then mapped into a different graph structure, called a “bunch graph”, constructed in the following way.
- Let the distance vector between nodes i and j in model graph m be designated as ⁇ i m j . Then the average ⁇ ij of that distance vector over all model graphs is computed, ⁇ ij 1 M ⁇ ⁇ m ⁇ ⁇ ij m . ( 7 )
- the associated bunch graph has N nodes, but differs from the image graphs and model graphs in that there are now M jets for each node of the bunch graph.
- Each jet in the bunch graph is designated by the number of the model graph in the associated gallery which contains that specific jet.
- Each jet of this collection of models in the associated gallery and thus each corresponding jet in the bunch graph may be labeled with one or several attributes characterizing the object that is represented by the model.
- attributes For example, if the models represent human faces, an attribute could be the gender of the person, or the presence or absence of attributes like eyeglasses or beard or a particular type of hair style.
- the collection of jets of this kind plus the attribute labels attached to each jet, plus the average edge vectors, may be called a “model stacks” or “generalized object knowledge” or “labeled bunch graph,” which latter term is the name adopted herein.
- the name derives from the view that the labeled bunch graph consists of a single graph with N nodes, each of which has M different jets, which are labeled by attributes in addition to being designated by a sequence number.
- the bunch graph idea was developed for applications involving objects which are qualitatively of the same structure.
- Examplary object types are different individuals of a given animal species (man, dog, horse, . . . ), or different types of the same kind of technical implement (automobiles, motorcycles, airplanes, computer terminals . . . ), or corresponding parts of a kind of animal or implement (human face, human hand, front of automobile, tail of airplane . . . ).
- the general structure of the model grid (for instance, the aspect ratio length/width of the graphs, or the local density of nodes) is adapted to the general type of object or part to be handled, see FIG. 3 for examples.
- jets attached to the same node of the bunch graph encode the same qualitative region of the object (for instance, the left eye of all stored faces, if the application is concerned with faces).
- each node n of the tentative image graph G I when compared to node n of the bunch graph, selects the jet with maximal similarity.
- the bunch-similarity function contains no term sensitive to deformations.
- the tentative image graph is modified to optimize its similarity to the bunch graph, this time using the similarity of equation 8, however. Optimization is done according to the same schedule as the elastic graph matching procedure described previously. After each move of a node of the tentative image graph, the node is free to pick the best-matching jet attached to the corresponding node of the bunch graph, see FIG. 4 . Again, variation in size and orientation of the object in the image can be accommodated by allowing for changes, in size and orientation of the tentative image graph (especially in the early global move stage of the match), along with proper transformation of the jet components.
- a bunch graph can be prepared by a “manual” method.
- a collection of representative images of that class of objects is acquired (typically of the order of 50 to 100).
- a suitable graph structure that is, an arrangement of node points plus a set of edges connecting them) is selected. For examples see FIGS. 2 and 3.
- the graph structure can be regular, as in FIG. 2, or it can be adapted to the object type, see FIG. 3 .
- the qualitative graph is then placed on individual images, such that node points occupy appropriately fixed positions. This is done by first placing a standard grid of points (depending on the object) over the object in the image, and by then correcting individual node positions such that they fall over appropriately designated sites characteristic of the object (e.g., in facial images, the centers of the eyes, the comers of the mouth, etc.). For this process it is convenient to use a graphical interface which allows the user to move node points around with the help of a computer mouse.
- jets are extracted at those node points and are assembled into the bunch graph structure described previously.
- Individual jets or groups of jets in the bunch graph can be manually labeled with attribute information (such as gender of a person, breed of animal, make of car, etc.).
- Image graph generation can take place in two steps.
- a bunch graph is used that is optimized for reliably finding instances of the object type in images and to estimate the size and the orientation of the object.
- an appropriate region of the image can be cut out and normalized as to size.
- the final image graph can be identified by matching to a second bunch graph, one that is designed to extract the data important for the final purpose (such as object recognition). For example of grids adapted to these two stages see FIG. 3 . Image graphs thus created are stored in a gallery for later use.
- an image graph is extracted from an image (or video frame) that is presented to the system.
- This image graph can then be compared efficiently to a gallery of stored image graphs of the same pose or type.
- This image graph comparison is done in terms of a simple graph similarity as in equation 6, with or without the distortion term (the relative importance of which is proportional to the user-controlled parameter ⁇ in that equation). The computation is efficient since no graph adaptation steps are necessary.
- This graph comparison gives a similarity value for each model graph stored in the gallery.
- the graph with the best similarity value can be taken as identifying the object or person recognized.
- a confidence measure can be derived from the distribution of similarity values, by using, for example, a threshold on the distance between the best match and the second best or on the mean of all other matches.
- wavelets of the form of equation 1 can be used.
- the wavelet transform can be implemented directly as a convolution, as in equation 2, or with the help of a Fast Fourier Transform.
- the wavelet transform can be speeded by using a pyramid-type scheme (according to which the lower frequency levels are computed by first low-pass filtering and then down-sampling the image).
- bunch graphs that are constructed for different poses of the object can be used side-by-side. During the matching process, each bunch graph is matched individually to the image, and the one with the best similarity is selected along with the image graph it created. The identity of the best-matching bunch graph determines the pose. For graph structures adapted to different head poses, see FIG. 3 .
- bunch graph matching can be used to determine those instances and parameters. Consequently, windows of appropriate location, size, and orientation can be cut out from the image and can be resized to a normal format. Instances of different pose can be labeled and sorted according to pose. It is thus possible to automatically create large collections of standardized portraits (for instance, of persons taken from (group-) photographs, of animals of a particular species or kind, of vehicles of the same type but different make or individuality, etc.)
- Statistical methods can be used to select entries in the bunch graph. An important criterion could be recognition success and (small) number of entries in the bunch graph.
- clustering methods can be used to find subsets of similar jets. These can then be replaced by just one representative (a statistical mean or a jet near the center of a cluster).
- a matrix of pair-wise similarities can be prepared, using the graph similarity of equation 6, with or without the distortion term. This matrix can be used and evaluated for several purposes. Clusters of graphs with large mutual similarity can be determined. These clusters can be used to identify sub-types of the object class that is being examined. The clusters can be used to create new bunch graphs to cover the sub-types or distinctions thus identified.
- each node of the final image graph is identified with the best-matching jet in the corresponding node of the bunch graph. If an attribute label (for example, gender of a person, or the presence of a beard or glasses or type of hair-style, or a particular breed of a given animal species, or a particular make of a vehicle type) is attached to the identified jet, that attribute can be attached to the node of the image graph.
- an attribute label for example, gender of a person, or the presence of a beard or glasses or type of hair-style, or a particular breed of a given animal species, or a particular make of a vehicle type
- a classification of the object in the image in terms of type can be achieved by letting the attribute labels vote, a clear majority determining the type, or with the help of Bayesian estimation methods.
- the type of an object part hair-style or beard of person, expression of mouth or eyes, type of attachment on vehicle or machine etc.
- the bunch graph can be determined with the help of attributes that are attached to individual nodes or to groups of nodes of models in the bunch graph.
- the bunch graph method can be used to automatically classify and label all image graphs in a gallery according to a number of attributes (e.g., age, gender, subspecies, peculiar features like scar or birth mark). During a recognition task, these attributes can be exploited to make the search more efficient (e.g., by concentrating the search on only those gallery graphs with the right attributes) or more reliable (by using the attributes as additional support for a particular identification).
- attributes e.g., age, gender, subspecies, peculiar features like scar or birth mark.
- search methods can be devised that are more efficient than exhaustive search of all gallery image graphs.
- the information as to which jet of the bunch graph was most similar to the image jet is available for each node of the image graph.
- This information can be used to construct a “composite image” that is based entirely on data derived from the sample images that went into the bunch graph (or from the jets in the bunch graph).
- a simple way to construct the composite is as follows. Assume all sample images of the bunch graph have the same format (same width and height, measured in pixels). Subdivide this region into tiles such that each tile contains exactly one node of the bunch graph. Assume that for node n the jet of sample image m has been selected during the bunch graph match. Then, cut tile n out of image m.
- unusual features can be detected, that is, features that were not contained in the sample images used to prepare the bunch graph (for instance, abnormalities of body shape for different individuals of an animal species).
- FIG. 1 shows a data format for image representation.
- An image 1 is selected to be analyzed.
- the image 1 is in the form of a pixel array (typically 512 ⁇ 512 or 128 ⁇ 128 pixels). Each pixel is a fixed point represented as a number, typically in the range 0-256. Pixels are indexed by their horizontal (x-) and vertical (y-) position.
- a general image may contain one or several pictured objects (for instance, human faces).
- One of the kernels 2 a described in equation 1 is also shown.
- the kernel is centered on the middle of the square. The value zero is represented by the average gray, whereas positive values are lighter and negative values are darker.
- This kernel 2 a is of low frequency-(short k-vector), and the k-vector points at 2 o'clock.
- Another kernel 2 b has a higher frequency and a k-vector pointing to 4:30 o'clock.
- the image 1 convolved with the kernel 2 a is shown as 3 a .
- the imaginary component that is, the sine component
- the magnitude 4 a , a j (x) of the convolution of the image 1 with the kernel 2 a is used in the similarity functions equations 4 and 5.
- the magnitude 4 b of the convolution of the image 1 with the kernel 2 b is also shown.
- the jet is shown in FIG. 1 in schematic representation 5 .
- the resulting image or model graph 6 is composed of a grid and of labels.
- the grid is a set of nodes and a set of edges (pairs of neighboring nodes).
- Edge labels are distance vectors between node positions (measured in pixels in the x- and y-directions).
- Node labels are jets that are extracted from an image by positioning the grid over the image and extracting the jets computed at the node positions.
- FIG. 2 shows graphs as placed over objects.
- An image 21 a is selected here to derive a model graph.
- Another image 21 b is shown in which an image graph has been formed by graph matching with the graph of the model graph derived from the image 21 a .
- the model graph 22 is formed by placing a regular grid over the object and extracting jets at the node points of the grid.
- the node points 23 of the grid are shown, as are the edges 24 of the grid.
- An image graph 25 is formed in image 21 b . It is the graph that best matches the model graph shown for image 21 a , formed by the matching procedure described previously.
- FIG. 3 shows graphs as placed over objects for an irregular, object type-adapted graph structure.
- a frontal image with image graph 31 is selected.
- the qualitative image graph structure is adapted to the task of finding a frontal face in an image, a large proportion of the number of nodes lying on the outline and relatively few nodes in the face region.
- the actual image graph (that is, the precise node positions) has been created by matching to a bunch graph as described previously.
- Another frontal image with image graph 32 is shown.
- the qualitative image graph structure is adapted to the task of face recognition, a large proportion of the number of nodes lying over facial features (eyes, nose, mouth) that are characteristic for a person and are not likely to change (as does the outline with changing hairstyle).
- An image of a person in half-profile 33 is shown.
- the graph structure is adapted for face finding.
- An image of a person in half-profile 34 is also shown.
- the graph structure is adapted for recognition. Image graph nodes 35 and image graph edges 36
- FIG. 4 shows a bunch graph and an image graph. Part of an image 41 containing a face is selected. An image graph is placed over the image, utilizing bunch graph matching (only the nodes 42 are shown, not the edges). The image shown has been cut out of a larger image, the position of the frame being centered on the image graph. The qualitative structure of the image graph is a rectangular grid in this case. A schematic depiction of the image graph 43 is shown in its relation to the bunch graph 44 .
- the bunch graph 44 is a collection of model graphs (typically 50 - 100 ) derived from images of the type of object and pose of concern (frontal faces in this example). Individual model graphs 45 are shown in the bunch graph which are derived from sample images.
- All model graphs have the same qualitative graph structure and identically-numbered nodes.
- the nodes carrying the same number in different model graphs refer to the same qualitative part of the sample objects (for instance, left eye of a face).
- a jet is stored that was derived from the node position in the corresponding sample image.
- the stored distance vectors for a given pair of nodes are identical for all model graphs, and are computed as an average, equation 7.
- Pointers 46 are directed from the nodes of the image graph to the best-matching nodes of the bunch graph.
- an image node When an image node is repositioned during the bunch graph matching process, it extracts the jet from the image that is centered at the new position, compares it to all the jets attached to the corresponding nodes in the bunch graph, and selects the one with the highest similarity. In this way, the bunch graph can optimize its total similarity, equation 8, making use of all possible combinations of stored jets (restricted only by the requirement that bunch graph jets have to be selected from the correct node). Attributes 47 are attached to the model graphs (for instance, gender, age and happiness/sadness of the person represented by the model graph).
Abstract
Description
Claims (8)
Priority Applications (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US08/882,223 US6222939B1 (en) | 1996-06-25 | 1997-06-25 | Labeled bunch graphs for image analysis |
US09/760,685 US6356659B1 (en) | 1996-06-25 | 2001-01-16 | Labeled bunch graphs for image analysis |
US10/029,691 US6563950B1 (en) | 1996-06-25 | 2001-12-21 | Labeled bunch graphs for image analysis |
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US2081096P | 1996-06-25 | 1996-06-25 | |
US08/882,223 US6222939B1 (en) | 1996-06-25 | 1997-06-25 | Labeled bunch graphs for image analysis |
Related Child Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US09/760,685 Continuation US6356659B1 (en) | 1996-06-25 | 2001-01-16 | Labeled bunch graphs for image analysis |
Publications (1)
Publication Number | Publication Date |
---|---|
US6222939B1 true US6222939B1 (en) | 2001-04-24 |
Family
ID=26693903
Family Applications (3)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US08/882,223 Expired - Lifetime US6222939B1 (en) | 1996-06-25 | 1997-06-25 | Labeled bunch graphs for image analysis |
US09/760,685 Expired - Lifetime US6356659B1 (en) | 1996-06-25 | 2001-01-16 | Labeled bunch graphs for image analysis |
US10/029,691 Expired - Lifetime US6563950B1 (en) | 1996-06-25 | 2001-12-21 | Labeled bunch graphs for image analysis |
Family Applications After (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US09/760,685 Expired - Lifetime US6356659B1 (en) | 1996-06-25 | 2001-01-16 | Labeled bunch graphs for image analysis |
US10/029,691 Expired - Lifetime US6563950B1 (en) | 1996-06-25 | 2001-12-21 | Labeled bunch graphs for image analysis |
Country Status (1)
Country | Link |
---|---|
US (3) | US6222939B1 (en) |
Cited By (48)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6466695B1 (en) * | 1999-08-04 | 2002-10-15 | Eyematic Interfaces, Inc. | Procedure for automatic analysis of images and image sequences based on two-dimensional shape primitives |
US20030044070A1 (en) * | 2001-09-03 | 2003-03-06 | Manfred Fuersich | Method for the automatic detection of red-eye defects in photographic image data |
US20030063778A1 (en) * | 2001-09-28 | 2003-04-03 | Canon Kabushiki Kaisha | Method and apparatus for generating models of individuals |
US20030086593A1 (en) * | 2001-05-31 | 2003-05-08 | Chengjun Liu | Feature based classification |
US20030152147A1 (en) * | 2002-01-09 | 2003-08-14 | Hiroshi Akimoto | Enhanced aperture problem solving method using displaced center quadtree adaptive partitioning |
US6714661B2 (en) * | 1998-11-06 | 2004-03-30 | Nevengineering, Inc. | Method and system for customizing facial feature tracking using precise landmark finding on a neutral face image |
US6798898B1 (en) * | 1998-02-26 | 2004-09-28 | Eastman Kodak Company | Management of physiological and psychological state of an individual using images therapeutic imaging classification system |
US20050002571A1 (en) * | 2000-05-24 | 2005-01-06 | Masaki Hiraga | Object shape exploration using topology matching |
US20060119572A1 (en) * | 2004-10-25 | 2006-06-08 | Jaron Lanier | Movable audio/video communication interface system |
US20060184066A1 (en) * | 2005-02-15 | 2006-08-17 | Baylor College Of Medicine | Method for aiding stent-assisted coiling of intracranial aneurysms by virtual parent artery reconstruction |
US20070214461A1 (en) * | 2005-06-08 | 2007-09-13 | Logitech Europe S.A. | System and method for transparently processing multimedia data |
US20070269111A1 (en) * | 2006-05-16 | 2007-11-22 | Eastman Kodak Company | Shape detection using coherent appearance modeling |
US20080208828A1 (en) * | 2005-03-21 | 2008-08-28 | Oren Boiman | Detecting Irregularities |
US20080232681A1 (en) * | 2007-03-20 | 2008-09-25 | Feris Rogerio S | Object detection system based on a pool of adaptive features |
US20080263040A1 (en) * | 2007-04-02 | 2008-10-23 | Nikhilesh Talreja | System and method for making a face call |
US20090034805A1 (en) * | 2006-05-10 | 2009-02-05 | Aol Llc | Using Relevance Feedback In Face Recognition |
US20100039533A1 (en) * | 2001-03-27 | 2010-02-18 | Hemisphere Ii Investment Lp | Method and Apparatus for Sharing Information Using a Handheld Device |
US20100194782A1 (en) * | 2009-02-04 | 2010-08-05 | Motorola, Inc. | Method and apparatus for creating virtual graffiti in a mobile virtual and augmented reality system |
US20100194756A1 (en) * | 2006-08-07 | 2010-08-05 | Max-Planck-Gesellschaft Zur Forderung Der Wissenschaften E.V., A Corporation Of Germany | Method for producing scaleable image matrices |
US20100214111A1 (en) * | 2007-12-21 | 2010-08-26 | Motorola, Inc. | Mobile virtual and augmented reality system |
US7907755B1 (en) | 2006-05-10 | 2011-03-15 | Aol Inc. | Detecting facial similarity based on human perception of facial similarity |
US20110135207A1 (en) * | 2009-12-07 | 2011-06-09 | Google Inc. | Matching An Approximately Located Query Image Against A Reference Image Set |
US7974714B2 (en) | 1999-10-05 | 2011-07-05 | Steven Mark Hoffberg | Intelligent electronic appliance system and method |
US8046313B2 (en) | 1991-12-23 | 2011-10-25 | Hoffberg Steven M | Ergonomic man-machine interface incorporating adaptive pattern recognition based control system |
US20110270853A1 (en) * | 2010-05-03 | 2011-11-03 | International Business Machines Corporation | Dynamic Storage and Retrieval of Process Graphs |
WO2012015919A1 (en) | 2010-07-27 | 2012-02-02 | Google Inc. | Automatic media sharing via shutter click |
US20120057011A1 (en) * | 2010-09-03 | 2012-03-08 | Shi-Jinn Horng | Finger vein recognition system and method |
US8235725B1 (en) | 2005-02-20 | 2012-08-07 | Sensory Logic, Inc. | Computerized method of assessing consumer reaction to a business stimulus employing facial coding |
US8238671B1 (en) | 2009-12-07 | 2012-08-07 | Google Inc. | Scene classification for place recognition |
EP2618289A2 (en) | 2008-04-02 | 2013-07-24 | Google Inc. | Method and apparatus to incorporate automatic face recognition in digital image collections |
US8509525B1 (en) | 2011-04-06 | 2013-08-13 | Google Inc. | Clustering of forms from large-scale scanned-document collection |
US8538458B2 (en) | 2005-04-04 | 2013-09-17 | X One, Inc. | Location sharing and tracking using mobile phones or other wireless devices |
US8774527B1 (en) | 2009-12-07 | 2014-07-08 | Google Inc. | Matching an approximately located query image against a reference image set using cellular base station and wireless access point information |
US8849020B2 (en) | 2008-07-22 | 2014-09-30 | Jeong-tae Kim | Search system using images |
US20140365310A1 (en) * | 2013-06-05 | 2014-12-11 | Machine Perception Technologies, Inc. | Presentation of materials based on low level feature analysis |
US20160070972A1 (en) * | 2014-09-10 | 2016-03-10 | VISAGE The Global Pet Recognition Company Inc. | System and method for determining a pet breed from an image |
US9330301B1 (en) | 2012-11-21 | 2016-05-03 | Ozog Media, LLC | System, method, and computer program product for performing processing based on object recognition |
US9336435B1 (en) | 2012-11-21 | 2016-05-10 | Ozog Media, LLC | System, method, and computer program product for performing processing based on object recognition |
USRE46310E1 (en) | 1991-12-23 | 2017-02-14 | Blanding Hovenweep, Llc | Ergonomic man-machine interface incorporating adaptive pattern recognition based control system |
US9652875B2 (en) | 2012-10-29 | 2017-05-16 | Yahoo! Inc. | Systems and methods for generating a dense graph |
US10270824B2 (en) | 2012-06-27 | 2019-04-23 | Google Llc | System and method for event content stream |
US10361802B1 (en) | 1999-02-01 | 2019-07-23 | Blanding Hovenweep, Llc | Adaptive pattern recognition based control system and method |
US10402629B1 (en) * | 2014-12-30 | 2019-09-03 | Morphotrust Usa, Llc | Facial recognition using fractal features |
US10432728B2 (en) | 2017-05-17 | 2019-10-01 | Google Llc | Automatic image sharing with designated users over a communication network |
USRE47908E1 (en) | 1991-12-23 | 2020-03-17 | Blanding Hovenweep, Llc | Ergonomic man-machine interface incorporating adaptive pattern recognition based control system |
USRE48056E1 (en) | 1991-12-23 | 2020-06-16 | Blanding Hovenweep, Llc | Ergonomic man-machine interface incorporating adaptive pattern recognition based control system |
US11146520B2 (en) | 2015-09-28 | 2021-10-12 | Google Llc | Sharing images and image albums over a communication network |
US11263492B2 (en) | 2011-02-18 | 2022-03-01 | Google Llc | Automatic event recognition and cross-user photo clustering |
Families Citing this family (62)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
DE19837004C1 (en) * | 1998-08-14 | 2000-03-09 | Christian Eckes | Process for recognizing objects in digitized images |
US6665440B1 (en) * | 2000-05-30 | 2003-12-16 | Microsoft Corporation | System and method for performing corner guided curve matching of multiple images representing a scene |
AU2001291175A1 (en) * | 2000-09-21 | 2002-04-02 | Md Online Inc. | Medical image processing systems |
US7329621B2 (en) * | 2002-12-26 | 2008-02-12 | Kimberly-Clark Worldwide, Inc. | Stretchable film laminates and methods and apparatus for making stretchable film laminates |
WO2004075105A2 (en) * | 2003-02-20 | 2004-09-02 | Intelligent Mechatronic Systems Inc. | Adaptive visual occupant detection and classification system |
US7912299B2 (en) * | 2004-10-08 | 2011-03-22 | Microsoft Corporation | System and method for efficiently encoding data |
US7930434B2 (en) * | 2003-03-05 | 2011-04-19 | Microsoft Corporation | System and method for managing communication and/or storage of image data |
US7075535B2 (en) * | 2003-03-05 | 2006-07-11 | Sand Codex | System and method for exact rendering in a zooming user interface |
US7133054B2 (en) * | 2004-03-17 | 2006-11-07 | Seadragon Software, Inc. | Methods and apparatus for navigating an image |
US7042455B2 (en) * | 2003-05-30 | 2006-05-09 | Sand Codex Llc | System and method for multiple node display |
US7254271B2 (en) * | 2003-03-05 | 2007-08-07 | Seadragon Software, Inc. | Method for encoding and serving geospatial or other vector data as images |
US7546419B2 (en) * | 2004-06-01 | 2009-06-09 | Aguera Y Arcas Blaise | Efficient data cache |
EP1602063A1 (en) * | 2003-03-13 | 2005-12-07 | Intelligent Mechatronic Systems, Inc. | Automotive occupant detection and classification method and system |
GB2402535B (en) * | 2003-06-05 | 2006-06-21 | Canon Kk | Image processing |
EP2955662B1 (en) * | 2003-07-18 | 2018-04-04 | Canon Kabushiki Kaisha | Image processing device, imaging device, image processing method |
JP4217664B2 (en) * | 2004-06-28 | 2009-02-04 | キヤノン株式会社 | Image processing method and image processing apparatus |
US20060020630A1 (en) * | 2004-07-23 | 2006-01-26 | Stager Reed R | Facial database methods and systems |
US7970625B2 (en) | 2004-11-04 | 2011-06-28 | Dr Systems, Inc. | Systems and methods for retrieval of medical data |
US7787672B2 (en) * | 2004-11-04 | 2010-08-31 | Dr Systems, Inc. | Systems and methods for matching, naming, and displaying medical images |
US7660488B2 (en) | 2004-11-04 | 2010-02-09 | Dr Systems, Inc. | Systems and methods for viewing medical images |
US7885440B2 (en) * | 2004-11-04 | 2011-02-08 | Dr Systems, Inc. | Systems and methods for interleaving series of medical images |
US7920152B2 (en) * | 2004-11-04 | 2011-04-05 | Dr Systems, Inc. | Systems and methods for viewing medical 3D imaging volumes |
US20060235941A1 (en) * | 2005-03-29 | 2006-10-19 | Microsoft Corporation | System and method for transferring web page data |
US20070162761A1 (en) * | 2005-12-23 | 2007-07-12 | Davis Bruce L | Methods and Systems to Help Detect Identity Fraud |
US7720773B2 (en) * | 2005-12-29 | 2010-05-18 | Microsoft Corporation | Partitioning data elements of a visual display of a tree using weights obtained during the training state and a maximum a posteriori solution for optimum labeling and probability |
US20080086311A1 (en) * | 2006-04-11 | 2008-04-10 | Conwell William Y | Speech Recognition, and Related Systems |
US7917514B2 (en) * | 2006-06-28 | 2011-03-29 | Microsoft Corporation | Visual and multi-dimensional search |
US7751599B2 (en) * | 2006-08-09 | 2010-07-06 | Arcsoft, Inc. | Method for driving virtual facial expressions by automatically detecting facial expressions of a face image |
US8707459B2 (en) | 2007-01-19 | 2014-04-22 | Digimarc Corporation | Determination of originality of content |
US8010511B2 (en) | 2006-08-29 | 2011-08-30 | Attributor Corporation | Content monitoring and compliance enforcement |
US8738749B2 (en) | 2006-08-29 | 2014-05-27 | Digimarc Corporation | Content monitoring and host compliance evaluation |
JP2008059197A (en) * | 2006-08-30 | 2008-03-13 | Canon Inc | Apparatus, method, computer program and storage medium for collating image |
US7953614B1 (en) | 2006-11-22 | 2011-05-31 | Dr Systems, Inc. | Smart placement rules |
US8356035B1 (en) | 2007-04-10 | 2013-01-15 | Google Inc. | Association of terms with images using image similarity |
US7904461B2 (en) * | 2007-05-01 | 2011-03-08 | Google Inc. | Advertiser and user association |
US8055664B2 (en) | 2007-05-01 | 2011-11-08 | Google Inc. | Inferring user interests |
CN101334780A (en) * | 2007-06-25 | 2008-12-31 | 英特维数位科技股份有限公司 | Figure image searching method, system and recording media for storing image metadata |
US7853622B1 (en) | 2007-11-01 | 2010-12-14 | Google Inc. | Video-related recommendations using link structure |
US8041082B1 (en) | 2007-11-02 | 2011-10-18 | Google Inc. | Inferring the gender of a face in an image |
WO2009124139A1 (en) * | 2008-04-01 | 2009-10-08 | The Government Of The United States Of America, As Represented By The Secretaty Of The Navy | Methods and systems of comparing face models for recognition |
US8369625B2 (en) * | 2008-06-30 | 2013-02-05 | Korea Institute Of Oriental Medicine | Method for grouping 3D models to classify constitution |
US7961986B1 (en) | 2008-06-30 | 2011-06-14 | Google Inc. | Ranking of images and image labels |
DE102008055884A1 (en) | 2008-11-03 | 2010-05-06 | Cross Match Technologies Gmbh | Method for detecting two-dimensional representation of face of person for generating identification document, involves generating signal for displaying representation when intensity is greater than multiple of algorithm and black value |
US8380533B2 (en) | 2008-11-19 | 2013-02-19 | DR Systems Inc. | System and method of providing dynamic and customizable medical examination forms |
US8346800B2 (en) * | 2009-04-02 | 2013-01-01 | Microsoft Corporation | Content-based information retrieval |
IL199657A0 (en) * | 2009-07-02 | 2011-08-01 | Carmel Haifa University Economic Corp Ltd | Face representation systems for privacy aware applications and methods useful in conjunction therewith |
US8712120B1 (en) | 2009-09-28 | 2014-04-29 | Dr Systems, Inc. | Rules-based approach to transferring and/or viewing medical images |
US8306922B1 (en) | 2009-10-01 | 2012-11-06 | Google Inc. | Detecting content on a social network using links |
US8311950B1 (en) | 2009-10-01 | 2012-11-13 | Google Inc. | Detecting content on a social network using browsing patterns |
US8866845B2 (en) * | 2010-03-10 | 2014-10-21 | Empire Technology Development Llc | Robust object recognition by dynamic modeling in augmented reality |
JP5672307B2 (en) * | 2010-11-09 | 2015-02-18 | 日本電気株式会社 | Information processing device |
US8488011B2 (en) | 2011-02-08 | 2013-07-16 | Longsand Limited | System to augment a visual data stream based on a combination of geographical and visual information |
US9075899B1 (en) | 2011-08-11 | 2015-07-07 | D.R. Systems, Inc. | Automated display settings for categories of items |
US20130251201A1 (en) * | 2012-03-22 | 2013-09-26 | Samsung Electronics Co., Ltd. | System and method for recommending buddies in social network |
US9064326B1 (en) | 2012-05-10 | 2015-06-23 | Longsand Limited | Local cache of augmented reality content in a mobile computing device |
US9430876B1 (en) | 2012-05-10 | 2016-08-30 | Aurasma Limited | Intelligent method of determining trigger items in augmented reality environments |
US9495604B1 (en) | 2013-01-09 | 2016-11-15 | D.R. Systems, Inc. | Intelligent management of computerized advanced processing |
US9036044B1 (en) * | 2013-07-22 | 2015-05-19 | Google Inc. | Adjusting camera parameters associated with a plurality of images |
CN106233322A (en) * | 2014-03-03 | 2016-12-14 | 赛曼提克姆德公司 | Patient's searching system based on individualized content |
US20170046483A1 (en) | 2015-04-30 | 2017-02-16 | D.R. Systems, Inc. | Database systems and interactive user interfaces for dynamic interaction with, and comparison of, digital medical image data |
US11386143B2 (en) | 2019-08-30 | 2022-07-12 | International Business Machines Corporation | Searching for analogue subsurface structures based on topological knowledge representation (TKR) |
US11164039B2 (en) * | 2019-10-23 | 2021-11-02 | International Business Machines Corporation | Framework for few-shot temporal action localization |
Citations (25)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4725824A (en) | 1983-06-15 | 1988-02-16 | Mitsubishi Denki Kabushiki Kaisha | Doze prevention system |
US4805224A (en) * | 1983-06-08 | 1989-02-14 | Fujitsu Limited | Pattern matching method and apparatus |
US4827413A (en) | 1987-06-16 | 1989-05-02 | Kabushiki Kaisha Toshiba | Modified back-to-front three dimensional reconstruction algorithm |
US5168529A (en) * | 1988-08-29 | 1992-12-01 | Rayethon Company | Confirmed boundary pattern matching |
US5187574A (en) | 1990-08-24 | 1993-02-16 | Kanda Tsushin Kogyo Co., Ltd. | Method for automatically adjusting field of view of television monitor system and apparatus for carrying out the same |
US5220441A (en) | 1990-09-28 | 1993-06-15 | Eastman Kodak Company | Mechanism for determining parallax between digital images |
US5333165A (en) | 1992-02-27 | 1994-07-26 | John K. Grady | Method and apparatus for three-dimensional video signals |
US5383013A (en) | 1992-09-18 | 1995-01-17 | Nec Research Institute, Inc. | Stereoscopic computer vision system |
DE4406020C1 (en) | 1994-02-24 | 1995-06-29 | Zentrum Fuer Neuroinformatik G | Automatic digital image recognition system |
US5430809A (en) | 1992-07-10 | 1995-07-04 | Sony Corporation | Human face tracking system |
US5432712A (en) | 1990-05-29 | 1995-07-11 | Axiom Innovation Limited | Machine vision stereo matching |
US5511153A (en) | 1994-01-18 | 1996-04-23 | Massachusetts Institute Of Technology | Method and apparatus for three-dimensional, textured models from plural video images |
US5533177A (en) | 1990-10-24 | 1996-07-02 | Siemens Aktiengesellschaft | Method for detecting and estimating the spatial position of objects from a two-dimensional image |
US5588033A (en) | 1995-06-06 | 1996-12-24 | St. Jude Children's Research Hospital | Method and apparatus for three dimensional image reconstruction from multiple stereotactic or isocentric backprojections |
US5625717A (en) * | 1992-06-24 | 1997-04-29 | Mitsubishi Denki Kabushiki Kaisha | Image processing device for processing grey level images |
US5680487A (en) | 1991-12-23 | 1997-10-21 | Texas Instruments Incorporated | System and method for determining optical flow |
US5699449A (en) | 1994-11-14 | 1997-12-16 | The University Of Connecticut | Method and apparatus for implementation of neural networks for face recognition |
US5715325A (en) * | 1995-08-30 | 1998-02-03 | Siemens Corporate Research, Inc. | Apparatus and method for detecting a face in a video image |
US5714997A (en) | 1995-01-06 | 1998-02-03 | Anderson; David P. | Virtual reality television system |
US5719954A (en) | 1994-06-07 | 1998-02-17 | Matsushita Electric Industrial Co., Ltd. | Stereo matching method and disparity measuring method |
US5736982A (en) | 1994-08-03 | 1998-04-07 | Nippon Telegraph And Telephone Corporation | Virtual space apparatus with avatars and speech |
US5764803A (en) | 1996-04-03 | 1998-06-09 | Lucent Technologies Inc. | Motion-adaptive modelling of scene content for very low bit rate model-assisted coding of video sequences |
US5774591A (en) | 1995-12-15 | 1998-06-30 | Xerox Corporation | Apparatus and method for recognizing facial expressions and facial gestures in a sequence of images |
US5809171A (en) * | 1996-01-05 | 1998-09-15 | Mcdonnell Douglas Corporation | Image processing method and apparatus for correlating a test image with a template |
US5828769A (en) * | 1996-10-23 | 1998-10-27 | Autodesk, Inc. | Method and apparatus for recognition of objects via position and orientation consensus of local image encoding |
-
1997
- 1997-06-25 US US08/882,223 patent/US6222939B1/en not_active Expired - Lifetime
-
2001
- 2001-01-16 US US09/760,685 patent/US6356659B1/en not_active Expired - Lifetime
- 2001-12-21 US US10/029,691 patent/US6563950B1/en not_active Expired - Lifetime
Patent Citations (25)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4805224A (en) * | 1983-06-08 | 1989-02-14 | Fujitsu Limited | Pattern matching method and apparatus |
US4725824A (en) | 1983-06-15 | 1988-02-16 | Mitsubishi Denki Kabushiki Kaisha | Doze prevention system |
US4827413A (en) | 1987-06-16 | 1989-05-02 | Kabushiki Kaisha Toshiba | Modified back-to-front three dimensional reconstruction algorithm |
US5168529A (en) * | 1988-08-29 | 1992-12-01 | Rayethon Company | Confirmed boundary pattern matching |
US5432712A (en) | 1990-05-29 | 1995-07-11 | Axiom Innovation Limited | Machine vision stereo matching |
US5187574A (en) | 1990-08-24 | 1993-02-16 | Kanda Tsushin Kogyo Co., Ltd. | Method for automatically adjusting field of view of television monitor system and apparatus for carrying out the same |
US5220441A (en) | 1990-09-28 | 1993-06-15 | Eastman Kodak Company | Mechanism for determining parallax between digital images |
US5533177A (en) | 1990-10-24 | 1996-07-02 | Siemens Aktiengesellschaft | Method for detecting and estimating the spatial position of objects from a two-dimensional image |
US5680487A (en) | 1991-12-23 | 1997-10-21 | Texas Instruments Incorporated | System and method for determining optical flow |
US5333165A (en) | 1992-02-27 | 1994-07-26 | John K. Grady | Method and apparatus for three-dimensional video signals |
US5625717A (en) * | 1992-06-24 | 1997-04-29 | Mitsubishi Denki Kabushiki Kaisha | Image processing device for processing grey level images |
US5430809A (en) | 1992-07-10 | 1995-07-04 | Sony Corporation | Human face tracking system |
US5383013A (en) | 1992-09-18 | 1995-01-17 | Nec Research Institute, Inc. | Stereoscopic computer vision system |
US5511153A (en) | 1994-01-18 | 1996-04-23 | Massachusetts Institute Of Technology | Method and apparatus for three-dimensional, textured models from plural video images |
DE4406020C1 (en) | 1994-02-24 | 1995-06-29 | Zentrum Fuer Neuroinformatik G | Automatic digital image recognition system |
US5719954A (en) | 1994-06-07 | 1998-02-17 | Matsushita Electric Industrial Co., Ltd. | Stereo matching method and disparity measuring method |
US5736982A (en) | 1994-08-03 | 1998-04-07 | Nippon Telegraph And Telephone Corporation | Virtual space apparatus with avatars and speech |
US5699449A (en) | 1994-11-14 | 1997-12-16 | The University Of Connecticut | Method and apparatus for implementation of neural networks for face recognition |
US5714997A (en) | 1995-01-06 | 1998-02-03 | Anderson; David P. | Virtual reality television system |
US5588033A (en) | 1995-06-06 | 1996-12-24 | St. Jude Children's Research Hospital | Method and apparatus for three dimensional image reconstruction from multiple stereotactic or isocentric backprojections |
US5715325A (en) * | 1995-08-30 | 1998-02-03 | Siemens Corporate Research, Inc. | Apparatus and method for detecting a face in a video image |
US5774591A (en) | 1995-12-15 | 1998-06-30 | Xerox Corporation | Apparatus and method for recognizing facial expressions and facial gestures in a sequence of images |
US5809171A (en) * | 1996-01-05 | 1998-09-15 | Mcdonnell Douglas Corporation | Image processing method and apparatus for correlating a test image with a template |
US5764803A (en) | 1996-04-03 | 1998-06-09 | Lucent Technologies Inc. | Motion-adaptive modelling of scene content for very low bit rate model-assisted coding of video sequences |
US5828769A (en) * | 1996-10-23 | 1998-10-27 | Autodesk, Inc. | Method and apparatus for recognition of objects via position and orientation consensus of local image encoding |
Non-Patent Citations (53)
Title |
---|
Akimoto, T., et al, "Automatic Creation of 3-D Facial Models", IEEE Computer Graphics & Applications., pp. 16-22, Sep. 1993. |
Ayache, N., et al, "Rectification of Images for Binocular and Trinocular Stereovision", In IEEE Proceedings of 9th International Conference on Pattern Recognition, pp. 11-16, 1988, Italy. |
Belhumeur, P., "A Bayesian Approach to Binocular Stereopsis", International Journal of Computer Vision, 19 (3), 1996, pp. 237-260. |
Beymer, D.J.: "Face Recognition Under Varying Pose", MIT Al, Lab Memo #1461, Dec. 1993. |
Beymer, D.J.: "Face Recognition Under Varying Pose", Proc. IEEE Computer Vision and Pattern Recognition, pp. 756-761, Seattle, WA, Jun. 1994. |
Buhmann, et al "distortion invariant object recognition by matching hierarchically labeled graphs", pp. 155-159, Jun. 1989.* |
DeCarlo, D., et al, "The Integration of Optical Flow and Deformable Models with Applications to Human Face Shape and Motion Estimation", pp. 1-15, in Proceedings, CVPR '96, pp. 231-238. |
Devernay, F., et al, "Computing Differential Properties of 3-D Shapes from Stereoscopic Images without 3-D Models", INRIA, RR-2304, 1994, pp. 1-28. |
Dhond, U., et al, "Structure from Stereo-A Review", IEEE Transactions on Systems, Man, and Cybernetics, vol. 19, No.6, pp. 1489-1510, Nov./Dec. 1989. |
Fleet, D. J., et al, "Computation of Component Image Velocity from Local Phase Information", International Journal of Computer Vision, vol. 5, No. 1, 1990, pp. 77-104. |
Fleet, D.J., et al, "Measurement of Image Velocity", Kluwer International Series in Engineering and Computer Science, Kluwer Academic Publishers, Boston, 1992, No. 169, pp. 1-203. |
Hall "computer image processing and recognition", academic press, pp. 467-484, 1979.* |
Hong, H., et al, "Online Facial Recognition Based on Personalized Gallery", Proceedings of International Conference on Automatic Face and Gesture Recognition, pp. 1-6, Japan, Apr. 1997. |
Kolocsai, P., et al, Statistical Analysis of Gabor-Filter Representation, Proceedings of International Conference on Automatic Face and Gesture Recognition, 1997, 4 pp. |
Kruger, N., "Visual Learning with a priori Constraints", Shaker Verlag, Aachen, Germany, 1998, pp. 1-131. |
Kruger, N., et al, "Autonomous Learning of Object Representation Utilizing Self-Controlled Movements", 1998, Proceedings of NN98, 5 pp. |
Kruger, N., et al, "Object Recognition with a Sparse and Autonomously Learned Representation Based on Banana Wavelets", Internal Report 96-11, Institut fur Neuroinformatik, Dec. 96, pp. 1-24. |
Kruger, N., et al, "Object Recognition with Banana Wavelets", European Symposium on Artificial Neural Networks (ESANN97), 1997, 6 pp. |
Kruger, N., et al, "Principles of Cortical Processing Applied to and Motivated by Artificial Object Recognition", Institut fur Neuroinformatik, Internal Report 97-17, Oct. 97, pp. 1-12. |
Kruger, N: "An Algorithm for the Learning Weights in Discrimination Functions Using a Priori Constraints", Mustererkennung, G. Sagerer et al., Ed. Spring Verlag, Sep. 13, 1995. |
Lades, M., et al, "Distortion Invarient Object Recognition in the Dynamic Link Architecture", IEEE Transactions on Computers, vol. 42, No. 3, 1993, 11 pp. |
Luong, Q. T., et al, "The Fundamentals Matrix, Theory, Algorithm, and Stability Analysis", INRIA, 1993, pp. 1-46. |
Manjunath "a feature based approach to face recognition", IEEE, pp. 373-378, Mar. 1992.* |
Mauer, T., et al, "Tracking and Learning Graphs and Pose on Image Sequences of Faces", Proceedings of 2nd International Conference on Automatic Face and Gesture Recognition, Oct. 14-16, 1996, pp. 176-181. |
Maurer, T., von der Malsburg, C.: "Learning Feature Transformations to Recognize Faces Rotated in Depth", in Proceedings of the International Conference on Artificial Neural Networks, vol. 1, p. 353-358, Paris, France, Oct. 9-13, 1995. |
Maurer, T., von der Malsburg, C.: "Single-View Based Recognition of Faces Rotated in Depth", in Proceedings of the International Workshop on Automatic Face-and Gesture-Recognition, pp. 248-253. Zurich, CH, Jun. 26, 1995. |
Maybank, S. J., et al, "A Theory of Self-Calibration of a Moving Camera", International Journal of Computer Vision, 8(2), pp. 123-151, 1992. |
McKenna, S.J., et al, Tracking Facial Feature Points With Gabor Wavelets and Shape Models, (publication & date unknown). |
Okada, K., et al, "The Bochum/USC Face Recognition System", 19 pp. (publication & date unknown). |
Okutomi, M., et al, "A Multiple-Baseline Stereo", IEEE Trans. on Pattern Analysis and Machine Intelligence, vol. 15, No. 4, pp. 353-363, Apr. 1993. |
Peters, G., et al, "Learning Object Representations by Clustering Banana Wavelet Responses", Tech. Report IR-INI 96-09, Institut fur Neuroinformatik, Ruhr Universitat, Bochum, 1996, 6 pp. |
Phillips, P. J., et al, "The Face Recognition Technology (FERET) Program", Proceedings of Office of National Drug Control Policy, CTAC International Technology Symposium, Aug. 18-22, 1997, 10 pages. |
Pighin, F, et al, "Synthesizing Realistic Facial Expressions from Photographs", In SIGGRAPH 98 Conference Proceedings, pp. 75-84, Jul. 1998. |
Roy, S., et al, "A Maximum Flow Formulation of the N-Camera Stereo Correspondence Problem", IEEE, Proceedings of International Conference on Computer Vision, Bombay, India, Jan. 1998, pp. 1-6. |
Sara, R., et al, "3-D Data Acquisition and Interpretation for Virtual Reality and Telepresence"Proceedings of IEEE Workshop Computer Vision for Virtual Reality Based Human Communications, Bombay, India, Jan. 1998, 7 pp. |
Sara, R., et al, "Fish-Scales: Representing Fuzzy Manifolds", Proceedings of International Conference on Computer Vision, Bombay, India, Narosa Publishing House, 1998. |
Sara, R., et al, "On Occluding Contour Artifacts in Stereo Vision", IEEE, Proceedings of International Conference Computer Vision and Pattern Recognition, Puerto Rico, 1997, 6 pp. |
Steffens, J., et al, "PersonSpotter-Fast and Robust System for Human Detection, Tracking, and Recognition", Proceedings of International Conference on Automatic Face and Gesture Recognition, 6 pp., Japan-Apr. 1998. |
Theimer, W. M., et al, "Phase-Based Binocular Vergence Control and Depth Reconstruction using Active Vision", CVGIP: Image Understanding, vol. 60, No. 3, Nov. 1994, pp. 343-358. |
Tomasi, C., et al., "Stereo Without Search", Proceedings of European Conference on Computer Vision, Cambridge, UK, 1996, 14 pp. (7 sheets). |
Triesch, J., et al, "Robust Classification of Hand Postures Against Complex Backgrounds", Proceedings of the Second International Conference on Automatic Face and Gesture Recognition, Killington, VT, Oct. 1996, 6 pp. |
Turk, M., et al, "Eigenfaces for Recognition", Journal of Cognitive Neuroscience, vol. 3, No. 1, pp. 71-86, 1991. |
Wiskott, L. (1996): "Phantom Faces for Face Analysis". Proc. of the 3rd Joint Symposium on Neural Computation, Pasadena, CA. 6:46-52, Publ. Univ. of California, San Diego. Jun. 1, 1996. |
Wiskott, L., "Phanton Faces for Face Analysis". Pattern Recognition, vol. 30, No. 6, pp. 837-846,Jun. 1997. |
Wiskott, L., et al, "Face Recognition by Elastic Bunch Graph Matching", IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 19, No. 7, Jul. 1, 1997, pp. 775-779. |
Wiskott, L., Fellous, J.M., Kruger, N., and von der Malsburg, C.: "Face Recognition and Gender Determination", Proc. of the Int. Workshop on Automatic Face-and Gesture-Recognition, Ed. Martin, Bischel, pp. 92-97, Zurich CH, Jun. 26, 1995. |
Wiskott, L., Fellous, J.M., Kruger, N., and von der Malsburg, C.: "Face Recognition by Elastic Bunch Graph Matching", Internal report, IR-INI 96-08, Institut fur Neuroinformatik, Ruhr-Universitat, Bochum, 44780 Bochum, Germany, 21 Pages, Apr. 1996. |
Wiskott, L.: "Labeled Graphs and Dynamic Link Matching for Face Recognition and Scene Analysis", Verlag Harri Deutsch. Thun-Frankfurt am Main. Reihe Physik 53 (PhD thesis), 110 Pages. Dec., 1995. |
Wiskott, L.: "Phantom Faces for Face Analysis". Internal Report, IR-INI 96-06, Institut fur Neuroinformatik, Ruhr-Universitat, Bochum, 44780 Bochum, Germany, 12 Pages, Mar. 1996. |
Wong, et al "pc-based human face recognition system", IEEE, pp. 641-644, 1992.* |
Wurtz, R., "Object Recognition Robust Under Translations, Deformations, and Changes in Background", IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 19, No. 7, Jul. 1, 1997, pp. 769-775. |
Wurtz, R., et al, "Corner Detection in Color Images by Multiscale Combination of End-stopped Cortical Cells", Artificial Neural Networks-ICANN '97, Lecture Notes in Computer Science, vol. 1327, pp. 901-906, Springer-Verlag, 1997. |
Yao, Y., et al, "Tracking a Dynamic Set of Feature Points", IEEE Transactions on Image Processing, vol. 4, No. 10, Oct., 1995, pp. 1382-1394. |
Cited By (115)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
USRE49387E1 (en) | 1991-12-23 | 2023-01-24 | Blanding Hovenweep, Llc | Ergonomic man-machine interface incorporating adaptive pattern recognition based control system |
US8046313B2 (en) | 1991-12-23 | 2011-10-25 | Hoffberg Steven M | Ergonomic man-machine interface incorporating adaptive pattern recognition based control system |
USRE46310E1 (en) | 1991-12-23 | 2017-02-14 | Blanding Hovenweep, Llc | Ergonomic man-machine interface incorporating adaptive pattern recognition based control system |
USRE47908E1 (en) | 1991-12-23 | 2020-03-17 | Blanding Hovenweep, Llc | Ergonomic man-machine interface incorporating adaptive pattern recognition based control system |
USRE48056E1 (en) | 1991-12-23 | 2020-06-16 | Blanding Hovenweep, Llc | Ergonomic man-machine interface incorporating adaptive pattern recognition based control system |
US6798898B1 (en) * | 1998-02-26 | 2004-09-28 | Eastman Kodak Company | Management of physiological and psychological state of an individual using images therapeutic imaging classification system |
US6714661B2 (en) * | 1998-11-06 | 2004-03-30 | Nevengineering, Inc. | Method and system for customizing facial feature tracking using precise landmark finding on a neutral face image |
US10361802B1 (en) | 1999-02-01 | 2019-07-23 | Blanding Hovenweep, Llc | Adaptive pattern recognition based control system and method |
US6466695B1 (en) * | 1999-08-04 | 2002-10-15 | Eyematic Interfaces, Inc. | Procedure for automatic analysis of images and image sequences based on two-dimensional shape primitives |
US7974714B2 (en) | 1999-10-05 | 2011-07-05 | Steven Mark Hoffberg | Intelligent electronic appliance system and method |
US20050002571A1 (en) * | 2000-05-24 | 2005-01-06 | Masaki Hiraga | Object shape exploration using topology matching |
US20100039533A1 (en) * | 2001-03-27 | 2010-02-18 | Hemisphere Ii Investment Lp | Method and Apparatus for Sharing Information Using a Handheld Device |
US8285791B2 (en) | 2001-03-27 | 2012-10-09 | Wireless Recognition Technologies Llc | Method and apparatus for sharing information using a handheld device |
US6826300B2 (en) * | 2001-05-31 | 2004-11-30 | George Mason University | Feature based classification |
US20030086593A1 (en) * | 2001-05-31 | 2003-05-08 | Chengjun Liu | Feature based classification |
US20030044070A1 (en) * | 2001-09-03 | 2003-03-06 | Manfred Fuersich | Method for the automatic detection of red-eye defects in photographic image data |
US7257239B2 (en) * | 2001-09-28 | 2007-08-14 | Canon Kabushiki Kaisha | Method and apparatus for generating models of individuals |
US20030063778A1 (en) * | 2001-09-28 | 2003-04-03 | Canon Kabushiki Kaisha | Method and apparatus for generating models of individuals |
US6925125B2 (en) | 2002-01-09 | 2005-08-02 | Hiroshi Akimoto | Enhanced aperture problem solving method using displaced center quadtree adaptive partitioning |
US20030152147A1 (en) * | 2002-01-09 | 2003-08-14 | Hiroshi Akimoto | Enhanced aperture problem solving method using displaced center quadtree adaptive partitioning |
US20060119572A1 (en) * | 2004-10-25 | 2006-06-08 | Jaron Lanier | Movable audio/video communication interface system |
US20100039380A1 (en) * | 2004-10-25 | 2010-02-18 | Graphics Properties Holdings, Inc. | Movable Audio/Video Communication Interface System |
US7626569B2 (en) | 2004-10-25 | 2009-12-01 | Graphics Properties Holdings, Inc. | Movable audio/video communication interface system |
US20060184066A1 (en) * | 2005-02-15 | 2006-08-17 | Baylor College Of Medicine | Method for aiding stent-assisted coiling of intracranial aneurysms by virtual parent artery reconstruction |
US8235725B1 (en) | 2005-02-20 | 2012-08-07 | Sensory Logic, Inc. | Computerized method of assessing consumer reaction to a business stimulus employing facial coding |
US8363959B2 (en) * | 2005-03-21 | 2013-01-29 | Yeda Research & Development Co. Ltd. | Detecting irregularities |
US20080208828A1 (en) * | 2005-03-21 | 2008-08-28 | Oren Boiman | Detecting Irregularities |
US9854402B1 (en) | 2005-04-04 | 2017-12-26 | X One, Inc. | Formation of wireless device location sharing group |
US10165059B2 (en) | 2005-04-04 | 2018-12-25 | X One, Inc. | Methods, systems and apparatuses for the formation and tracking of location sharing groups |
US11778415B2 (en) | 2005-04-04 | 2023-10-03 | Xone, Inc. | Location sharing application in association with services provision |
US11356799B2 (en) | 2005-04-04 | 2022-06-07 | X One, Inc. | Fleet location sharing application in association with services provision |
US10856099B2 (en) | 2005-04-04 | 2020-12-01 | X One, Inc. | Application-based two-way tracking and mapping function with selected individuals |
US10791414B2 (en) | 2005-04-04 | 2020-09-29 | X One, Inc. | Location sharing for commercial and proprietary content applications |
US10750309B2 (en) | 2005-04-04 | 2020-08-18 | X One, Inc. | Ad hoc location sharing group establishment for wireless devices with designated meeting point |
US10750310B2 (en) | 2005-04-04 | 2020-08-18 | X One, Inc. | Temporary location sharing group with event based termination |
US10750311B2 (en) | 2005-04-04 | 2020-08-18 | X One, Inc. | Application-based tracking and mapping function in connection with vehicle-based services provision |
US10341809B2 (en) | 2005-04-04 | 2019-07-02 | X One, Inc. | Location sharing with facilitated meeting point definition |
US10341808B2 (en) | 2005-04-04 | 2019-07-02 | X One, Inc. | Location sharing for commercial and proprietary content applications |
US10313826B2 (en) | 2005-04-04 | 2019-06-04 | X One, Inc. | Location sharing and map support in connection with services request |
US10299071B2 (en) | 2005-04-04 | 2019-05-21 | X One, Inc. | Server-implemented methods and systems for sharing location amongst web-enabled cell phones |
US10200811B1 (en) | 2005-04-04 | 2019-02-05 | X One, Inc. | Map presentation on cellular device showing positions of multiple other wireless device users |
US10149092B1 (en) | 2005-04-04 | 2018-12-04 | X One, Inc. | Location sharing service between GPS-enabled wireless devices, with shared target location exchange |
US9967704B1 (en) | 2005-04-04 | 2018-05-08 | X One, Inc. | Location sharing group map management |
US9955298B1 (en) | 2005-04-04 | 2018-04-24 | X One, Inc. | Methods, systems and apparatuses for the formation and tracking of location sharing groups |
US9942705B1 (en) | 2005-04-04 | 2018-04-10 | X One, Inc. | Location sharing group for services provision |
US9883360B1 (en) | 2005-04-04 | 2018-01-30 | X One, Inc. | Rendez vous management using mobile phones or other mobile devices |
US9854394B1 (en) | 2005-04-04 | 2017-12-26 | X One, Inc. | Ad hoc location sharing group between first and second cellular wireless devices |
US9749790B1 (en) | 2005-04-04 | 2017-08-29 | X One, Inc. | Rendez vous management using mobile phones or other mobile devices |
US9736618B1 (en) | 2005-04-04 | 2017-08-15 | X One, Inc. | Techniques for sharing relative position between mobile devices |
US9654921B1 (en) | 2005-04-04 | 2017-05-16 | X One, Inc. | Techniques for sharing position data between first and second devices |
US9615204B1 (en) | 2005-04-04 | 2017-04-04 | X One, Inc. | Techniques for communication within closed groups of mobile devices |
US8538458B2 (en) | 2005-04-04 | 2013-09-17 | X One, Inc. | Location sharing and tracking using mobile phones or other wireless devices |
US9584960B1 (en) | 2005-04-04 | 2017-02-28 | X One, Inc. | Rendez vous management using mobile phones or other mobile devices |
US9467832B2 (en) | 2005-04-04 | 2016-10-11 | X One, Inc. | Methods and systems for temporarily sharing position data between mobile-device users |
US9253616B1 (en) | 2005-04-04 | 2016-02-02 | X One, Inc. | Apparatus and method for obtaining content on a cellular wireless device based on proximity |
US9185522B1 (en) | 2005-04-04 | 2015-11-10 | X One, Inc. | Apparatus and method to transmit content to a cellular wireless device based on proximity to other wireless devices |
US8712441B2 (en) | 2005-04-04 | 2014-04-29 | Xone, Inc. | Methods and systems for temporarily sharing position data between mobile-device users |
US8750898B2 (en) | 2005-04-04 | 2014-06-10 | X One, Inc. | Methods and systems for annotating target locations |
US9167558B2 (en) | 2005-04-04 | 2015-10-20 | X One, Inc. | Methods and systems for sharing position data between subscribers involving multiple wireless providers |
US9031581B1 (en) | 2005-04-04 | 2015-05-12 | X One, Inc. | Apparatus and method for obtaining content on a cellular wireless device based on proximity to other wireless devices |
US8798647B1 (en) | 2005-04-04 | 2014-08-05 | X One, Inc. | Tracking proximity of services provider to services consumer |
US8798645B2 (en) | 2005-04-04 | 2014-08-05 | X One, Inc. | Methods and systems for sharing position data and tracing paths between mobile-device users |
US8831635B2 (en) | 2005-04-04 | 2014-09-09 | X One, Inc. | Methods and apparatuses for transmission of an alert to multiple devices |
US8798593B2 (en) | 2005-04-04 | 2014-08-05 | X One, Inc. | Location sharing and tracking using mobile phones or other wireless devices |
US20070214461A1 (en) * | 2005-06-08 | 2007-09-13 | Logitech Europe S.A. | System and method for transparently processing multimedia data |
US8606950B2 (en) | 2005-06-08 | 2013-12-10 | Logitech Europe S.A. | System and method for transparently processing multimedia data |
US8542888B2 (en) | 2006-05-10 | 2013-09-24 | Aol Inc. | Detecting facial similarity based on human perception of facial similarity |
US20110085710A1 (en) * | 2006-05-10 | 2011-04-14 | Aol Inc. | Using relevance feedback in face recognition |
US20110129145A1 (en) * | 2006-05-10 | 2011-06-02 | Aol Inc | Detecting facial similarity based on human perception of facial similarity |
US9141878B2 (en) | 2006-05-10 | 2015-09-22 | Aol Inc. | Detecting facial similarity based on human perception of facial similarity |
US7907755B1 (en) | 2006-05-10 | 2011-03-15 | Aol Inc. | Detecting facial similarity based on human perception of facial similarity |
US7783085B2 (en) * | 2006-05-10 | 2010-08-24 | Aol Inc. | Using relevance feedback in face recognition |
US20090034805A1 (en) * | 2006-05-10 | 2009-02-05 | Aol Llc | Using Relevance Feedback In Face Recognition |
US9773160B2 (en) | 2006-05-10 | 2017-09-26 | Aol Inc. | Using relevance feedback in face recognition |
US8233679B2 (en) | 2006-05-10 | 2012-07-31 | Aol Inc. | Detecting facial similarity based on human perception of facial similarity |
US8194939B2 (en) | 2006-05-10 | 2012-06-05 | Aol Inc. | Using relevance feedback in face recognition |
US20070269111A1 (en) * | 2006-05-16 | 2007-11-22 | Eastman Kodak Company | Shape detection using coherent appearance modeling |
US7672482B2 (en) | 2006-05-16 | 2010-03-02 | Eastman Kodak Company | Shape detection using coherent appearance modeling |
US20100194756A1 (en) * | 2006-08-07 | 2010-08-05 | Max-Planck-Gesellschaft Zur Forderung Der Wissenschaften E.V., A Corporation Of Germany | Method for producing scaleable image matrices |
US8170276B2 (en) * | 2007-03-20 | 2012-05-01 | International Business Machines Corporation | Object detection system based on a pool of adaptive features |
US20080232681A1 (en) * | 2007-03-20 | 2008-09-25 | Feris Rogerio S | Object detection system based on a pool of adaptive features |
US8655018B2 (en) | 2007-03-20 | 2014-02-18 | International Business Machines Corporation | Object detection system based on a pool of adaptive features |
US20080263040A1 (en) * | 2007-04-02 | 2008-10-23 | Nikhilesh Talreja | System and method for making a face call |
US20100214111A1 (en) * | 2007-12-21 | 2010-08-26 | Motorola, Inc. | Mobile virtual and augmented reality system |
EP2618289A2 (en) | 2008-04-02 | 2013-07-24 | Google Inc. | Method and apparatus to incorporate automatic face recognition in digital image collections |
EP2618290A2 (en) | 2008-04-02 | 2013-07-24 | Google Inc. | Method and apparatus to incorporate automatic face recognition in digital image collections |
US8849020B2 (en) | 2008-07-22 | 2014-09-30 | Jeong-tae Kim | Search system using images |
US20100194782A1 (en) * | 2009-02-04 | 2010-08-05 | Motorola, Inc. | Method and apparatus for creating virtual graffiti in a mobile virtual and augmented reality system |
US8350871B2 (en) * | 2009-02-04 | 2013-01-08 | Motorola Mobility Llc | Method and apparatus for creating virtual graffiti in a mobile virtual and augmented reality system |
US8238671B1 (en) | 2009-12-07 | 2012-08-07 | Google Inc. | Scene classification for place recognition |
US8768107B2 (en) | 2009-12-07 | 2014-07-01 | Google Inc. | Matching an approximately located query image against a reference image set |
US8798378B1 (en) | 2009-12-07 | 2014-08-05 | Google Inc. | Scene classification for place recognition |
US8774527B1 (en) | 2009-12-07 | 2014-07-08 | Google Inc. | Matching an approximately located query image against a reference image set using cellular base station and wireless access point information |
US20110135207A1 (en) * | 2009-12-07 | 2011-06-09 | Google Inc. | Matching An Approximately Located Query Image Against A Reference Image Set |
US8532400B1 (en) | 2009-12-07 | 2013-09-10 | Google Inc. | Scene classification for place recognition |
US8189964B2 (en) | 2009-12-07 | 2012-05-29 | Google Inc. | Matching an approximately located query image against a reference image set |
US20110270853A1 (en) * | 2010-05-03 | 2011-11-03 | International Business Machines Corporation | Dynamic Storage and Retrieval of Process Graphs |
US8676818B2 (en) * | 2010-05-03 | 2014-03-18 | International Business Machines Corporation | Dynamic storage and retrieval of process graphs representative of business processes and extraction of formal process models therefrom |
US8194940B1 (en) | 2010-07-27 | 2012-06-05 | Google, Inc. | Automatic media sharing via shutter click |
US8270684B2 (en) | 2010-07-27 | 2012-09-18 | Google Inc. | Automatic media sharing via shutter click |
WO2012015919A1 (en) | 2010-07-27 | 2012-02-02 | Google Inc. | Automatic media sharing via shutter click |
US20120057011A1 (en) * | 2010-09-03 | 2012-03-08 | Shi-Jinn Horng | Finger vein recognition system and method |
US11263492B2 (en) | 2011-02-18 | 2022-03-01 | Google Llc | Automatic event recognition and cross-user photo clustering |
US8509525B1 (en) | 2011-04-06 | 2013-08-13 | Google Inc. | Clustering of forms from large-scale scanned-document collection |
US10270824B2 (en) | 2012-06-27 | 2019-04-23 | Google Llc | System and method for event content stream |
US9652875B2 (en) | 2012-10-29 | 2017-05-16 | Yahoo! Inc. | Systems and methods for generating a dense graph |
US9330301B1 (en) | 2012-11-21 | 2016-05-03 | Ozog Media, LLC | System, method, and computer program product for performing processing based on object recognition |
US9336435B1 (en) | 2012-11-21 | 2016-05-10 | Ozog Media, LLC | System, method, and computer program product for performing processing based on object recognition |
US20140365310A1 (en) * | 2013-06-05 | 2014-12-11 | Machine Perception Technologies, Inc. | Presentation of materials based on low level feature analysis |
US20160070972A1 (en) * | 2014-09-10 | 2016-03-10 | VISAGE The Global Pet Recognition Company Inc. | System and method for determining a pet breed from an image |
US10402629B1 (en) * | 2014-12-30 | 2019-09-03 | Morphotrust Usa, Llc | Facial recognition using fractal features |
US11146520B2 (en) | 2015-09-28 | 2021-10-12 | Google Llc | Sharing images and image albums over a communication network |
US11212348B2 (en) | 2017-05-17 | 2021-12-28 | Google Llc | Automatic image sharing with designated users over a communication network |
US10432728B2 (en) | 2017-05-17 | 2019-10-01 | Google Llc | Automatic image sharing with designated users over a communication network |
US11778028B2 (en) | 2017-05-17 | 2023-10-03 | Google Llc | Automatic image sharing with designated users over a communication network |
Also Published As
Publication number | Publication date |
---|---|
US6356659B1 (en) | 2002-03-12 |
US6563950B1 (en) | 2003-05-13 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US6222939B1 (en) | Labeled bunch graphs for image analysis | |
US8452108B2 (en) | Systems and methods for image recognition using graph-based pattern matching | |
US10891511B1 (en) | Human hairstyle generation method based on multi-feature retrieval and deformation | |
Srivastava et al. | Statistical shape analysis: Clustering, learning, and testing | |
Felzenszwalb et al. | Visual object detection with deformable part models | |
US20080285862A1 (en) | Probabilistic Boosting Tree Framework For Learning Discriminative Models | |
Abiyev et al. | Personal iris recognition using neural network | |
US20070242858A1 (en) | Method and apparatus for person identification | |
CN110674685B (en) | Human body analysis segmentation model and method based on edge information enhancement | |
Othman et al. | A novel approach for occluded ear recognition based on shape context | |
Suresh et al. | Optimization and Deep Learning–Based Content Retrieval, Indexing, and Metric Learning Approach for Medical Images | |
Perronnin et al. | A probabilistic model of face mapping with local transformations and its application to person recognition | |
Arathi et al. | An efficient offline signature verification system | |
Monzo et al. | Hog-ebgm vs. gabor-ebgm | |
Le Borgne et al. | Classification of images: ICA filters vs human perception | |
Salah et al. | Hidden Markov Model-based face recognition using selective attention | |
CN102385704A (en) | Negative sample selection method in biometrics identification and apparatus thereof | |
Nayef | Geometric-based symbol spotting and retrieval in technical line drawings | |
Bachoo et al. | A segmentation method to improve iris-based person identification | |
Ayodele et al. | Development of a modified local Binary Pattern-Gabor Wavelet transform aging invariant face recognition system | |
Salih | A Suggested System for Palmprint Recognition Using Curvelet Transform and Co-Occurrence Matrix | |
MAHURKAR et al. | Novel Outline Tracing Techniques for Leaf Species Identification from Shrouded Leaves | |
Jayaraman et al. | An efficient technique for indexing multimodal biometric databases | |
Mazumdar et al. | Evolutionary-rough feature selection for face recognition | |
Zhelezniakov | Automatic image-based identification of saimaa ringed seals |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: EYEMATIC INTERFACES, INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:WISKOTT, LAURENZ;REEL/FRAME:009266/0796Effective date: 19980603Owner name: EYEMATIC INTERFACES, INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:MALSBURG, CHRISTOPH VON DER;REEL/FRAME:009272/0461Effective date: 19980528 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
AS | Assignment |
Owner name: EYEMATIC INTERFACES, INC., CALIFORNIAFree format text: SECURITY AGREEMENT;ASSIGNOR:NEVENGINEERING, INC.;REEL/FRAME:014532/0427Effective date: 20030702 |
|
AS | Assignment |
Owner name: NEVENGINEERING, INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:EYEMATIC INTERFACES, INC.;REEL/FRAME:015008/0717Effective date: 20031003 |
|
FPAY | Fee payment |
Year of fee payment: 4 |
|
AS | Assignment |
Owner name: GOOGLE INC.,CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:NEVENGINEERING, INC.;REEL/FRAME:018616/0814Effective date: 20061206Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:NEVENGINEERING, INC.;REEL/FRAME:018616/0814Effective date: 20061206 |
|
FPAY | Fee payment |
Year of fee payment: 8 |
|
FPAY | Fee payment |
Year of fee payment: 12 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044127/0735Effective date: 20170929 |