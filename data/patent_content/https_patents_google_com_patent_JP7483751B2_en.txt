JP7483751B2 - Training machine learning models using unsupervised data augmentation - Google Patents
Training machine learning models using unsupervised data augmentation Download PDFInfo
- Publication number
- JP7483751B2 JP7483751B2 JP2021563340A JP2021563340A JP7483751B2 JP 7483751 B2 JP7483751 B2 JP 7483751B2 JP 2021563340 A JP2021563340 A JP 2021563340A JP 2021563340 A JP2021563340 A JP 2021563340A JP 7483751 B2 JP7483751 B2 JP 7483751B2
- Authority
- JP
- Japan
- Prior art keywords
- training
- model
- machine learning
- input
- data
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
- 238000012549 training Methods 0.000 title claims description 209
- 238000010801 machine learning Methods 0.000 title claims description 95
- 238000013434 data augmentation Methods 0.000 title claims description 14
- 238000000034 method Methods 0.000 claims description 72
- 230000003190 augmentative effect Effects 0.000 claims description 35
- 238000009826 distribution Methods 0.000 claims description 21
- 238000003860 storage Methods 0.000 claims description 9
- 230000036541 health Effects 0.000 claims description 6
- 230000000007 visual effect Effects 0.000 claims description 2
- 230000008569 process Effects 0.000 description 20
- 238000012545 processing Methods 0.000 description 18
- 238000013528 artificial neural network Methods 0.000 description 14
- 230000003416 augmentation Effects 0.000 description 13
- 238000004590 computer program Methods 0.000 description 13
- 230000015654 memory Effects 0.000 description 7
- 230000000306 recurrent effect Effects 0.000 description 6
- 230000009471 action Effects 0.000 description 5
- 238000004891 communication Methods 0.000 description 5
- 238000010586 diagram Methods 0.000 description 4
- 239000002131 composite material Substances 0.000 description 3
- 230000001419 dependent effect Effects 0.000 description 3
- 230000006870 function Effects 0.000 description 3
- 230000003993 interaction Effects 0.000 description 3
- 230000004044 response Effects 0.000 description 3
- 230000008901 benefit Effects 0.000 description 2
- 230000003287 optical effect Effects 0.000 description 2
- 238000013515 script Methods 0.000 description 2
- 238000000926 separation method Methods 0.000 description 2
- 230000026676 system process Effects 0.000 description 2
- 230000009466 transformation Effects 0.000 description 2
- 238000013519 translation Methods 0.000 description 2
- ORILYTVJVMAKLC-UHFFFAOYSA-N Adamantane Natural products C1C(C2)CC3CC1CC2C3 ORILYTVJVMAKLC-UHFFFAOYSA-N 0.000 description 1
- 238000012935 Averaging Methods 0.000 description 1
- 241000009334 Singa Species 0.000 description 1
- 240000001949 Taraxacum officinale Species 0.000 description 1
- 235000005187 Taraxacum officinale ssp. officinale Nutrition 0.000 description 1
- 230000004913 activation Effects 0.000 description 1
- 230000005540 biological transmission Effects 0.000 description 1
- 238000004422 calculation algorithm Methods 0.000 description 1
- 230000008859 change Effects 0.000 description 1
- 230000001149 cognitive effect Effects 0.000 description 1
- 230000002860 competitive effect Effects 0.000 description 1
- 238000013527 convolutional neural network Methods 0.000 description 1
- 239000004973 liquid crystal related substance Substances 0.000 description 1
- 238000004519 manufacturing process Methods 0.000 description 1
- 239000000203 mixture Substances 0.000 description 1
- 238000005457 optimization Methods 0.000 description 1
- 230000000644 propagated effect Effects 0.000 description 1
- 239000004065 semiconductor Substances 0.000 description 1
- 230000001953 sensory effect Effects 0.000 description 1
- 230000006403 short-term memory Effects 0.000 description 1
- 239000000758 substrate Substances 0.000 description 1
- 238000012546 transfer Methods 0.000 description 1
- 238000000844 transformation Methods 0.000 description 1
Images
Description
関連出願の相互参照
本出願は、その全体が参照により本明細書に組み込まれている、2019年4月25日に出願した米国特許出願第62/838,932号の優先権を主張するものである。
CROSS-REFERENCE TO RELATED APPLICATIONS This application claims priority to U.S. Patent Application No. 62/838,932, filed April 25, 2019, which is incorporated by reference in its entirety.
本明細書は、機械学習モデルのトレーニングに関する。詳細には、限定されないが、本明細書は、知覚タスク(例えば視覚または音声に関係するタスク)のための機械学習モデルのトレーニングに関する。 This specification relates to training machine learning models. In particular, but not by way of limitation, this specification relates to training machine learning models for perceptual tasks (e.g., tasks related to vision or speech).
機械学習モデルは、入力を受領し、受領した入力とモデルのパラメータの値とに基づいて、出力、例えば予測された出力を生成する。 A machine learning model receives input and generates an output, e.g., a predicted output, based on the received input and the values of the parameters of the model.
ニューラルネットワークは、非線形ユニットの1つまたは複数の層を用いて、受領した入力についての出力を予測する、機械学習モデルである。一部のニューラルネットワークは、出力層に加えて、1つまたは複数の隠れ層を含む。各隠れ層の出力は、ネットワーク内の次の層、すなわち次の隠れ層または出力層への入力として使用される。ネットワークの各層は、受領した入力から、それぞれに対応するパラメータ集合の現在値に従って出力を生成する。 A neural network is a machine learning model that uses one or more layers of nonlinear units to predict an output for a given input. Some neural networks contain one or more hidden layers in addition to an output layer. The output of each hidden layer is used as the input for the next layer in the network, either the next hidden layer or the output layer. Each layer of the network generates an output from the input it receives according to the current values of its corresponding set of parameters.
一部のニューラルネットワークは、再帰型ニューラルネットワークである。再帰型ニューラルネットワークは、入力系列を受領し、その入力系列から出力系列を生成する、ニューラルネットワークである。具体的には、再帰型ニューラルネットワークは、以前の時間ステップからのネットワークの内部状態の一部または全てを、現在の時間ステップにおける出力を計算する際に使用することができる。再帰型ニューラルネットワークの一例が、長短期(LSTM)ニューラルネットワークであり、これは、1つまたは複数のLSTMメモリブロックを含む。各LSTMメモリブロックは、1つまたは複数のセルを含むことができ、セルはそれぞれ、入力ゲート、忘却ゲート、および出力ゲートを含み、これらのゲートにより、セルは、例えば現在の活性化を生じさせる際に使用するかまたはLSTMニューラルネットワークの他のコンポーネントに提供される、そのセルの以前の状態を記憶することが可能になっている。 Some neural networks are recurrent neural networks. A recurrent neural network is a neural network that receives an input sequence and generates an output sequence from the input sequence. Specifically, a recurrent neural network can use some or all of the internal state of the network from a previous time step in computing the output at the current time step. One example of a recurrent neural network is a long short-term (LSTM) neural network, which includes one or more LSTM memory blocks. Each LSTM memory block can include one or more cells, each of which includes an input gate, a forget gate, and an output gate that enable the cell to remember its previous state, for example for use in generating the current activation or for provision to other components of the LSTM neural network.
本明細書では、機械学習モデルを、半教師あり学習を通じて、すなわちラベルなしトレーニング入力およびラベルありトレーニング入力を含むトレーニングデータに対して機械学習モデルをトレーニングすることによって、ある機械学習タスクを実行するようにトレーニングする、1つまたは複数の位置にある1つまたは複数のコンピュータ上のコンピュータプログラムとして実装されるシステムについて説明する。ラベルありトレーニング入力は、それについてグラウンドトゥルース出力、すなわち機械学習モデルがラベルありトレーニング入力に対して特定の機械学習タスクを実行することにより生成すべき出力が利用可能な、入力である。ラベルなしトレーニング入力は、それについてグラウンドトゥルース出力が利用不可能なトレーニング入力である。 Described herein is a system, implemented as a computer program on one or more computers at one or more locations, that trains a machine learning model to perform a certain machine learning task through semi-supervised learning, i.e., by training the machine learning model on training data that includes unlabeled training inputs and labeled training inputs. A labeled training input is an input for which a ground truth output is available, i.e., the output that the machine learning model should generate by performing the particular machine learning task on the labeled training input. An unlabeled training input is a training input for which a ground truth output is not available.
システムは、トレーニングデータから拡張トレーニングデータを生成し、次いで、拡張トレーニングデータに対して機械学習をトレーニングすることによって、機械学習モデルをトレーニングする。拡張トレーニングデータを生成することは、複数のラベルなしトレーニング入力のそれぞれについて、ラベルなしトレーニング入力にデータ拡張技法を適用することによって、それぞれに対応する拡張トレーニング入力を生成することを含む。 The system trains the machine learning model by generating augmented training data from the training data and then training the machine learning model on the augmented training data. Generating the augmented training data includes, for each of a plurality of unlabeled training inputs, generating a corresponding augmented training input by applying a data augmentation technique to the unlabeled training input.
本明細書において説明する本主題の特定の実施形態は、以下の利点のうちの1つまたは複数を実現するように実装することができる。本明細書において説明するように機械学習モデルをトレーニングすることによって、機械学習モデルを、正確なモデル出力を生成するようにトレーニングすることが可能である。具体的には、本明細書において説明するように機械学習モデルをトレーニングすることによって、ラベルなしトレーニングデータをトレーニングに効果的に組み込むことができ、それによって、機械学習モデルの性能が向上する。すなわち、追加のラベルありトレーニングデータを必要とせずに、トレーニング済みモデルの性能を向上させることができる。ラベルなしトレーニングデータは一般に、ラベルありトレーニングデータよりも容易に入手できるので、追加のトレーニングデータを取得または生成する時間および計算コストを大幅に増大させずに、トレーニングの効果を向上させることができる。より具体的には、拡張技法、例えばラベルありトレーニングデータに従来適用されてきた技法を、ラベルなしデータに効果的に適用して、ラベルありまたはラベルなしの追加のトレーニングデータを必要とせずに、機械学習モデルのトレーニングを向上させることができる。加えて、ラベルありトレーニングデータを比較的少量しか入手できないとしても、容易に入手できるラベルなしトレーニングデータを、本明細書において説明するようにトレーニングに効果的に組み込むことによって、機械学習モデルを効果的にトレーニングすることができる。したがって、正確なモデル出力を生成するためのモデルのトレーニングは、正確なラベルありトレーニングデータの入手可能性にそれほど依存しないようになる。結果として、モデルを効果的に、かつ完全な教師あり集合に対してトレーニングされたモデルと比べてはるかに少ないラベルあり例を用いて、トレーニングすることが可能である。 Certain embodiments of the subject matter described herein may be implemented to achieve one or more of the following advantages. By training a machine learning model as described herein, it is possible to train the machine learning model to generate accurate model outputs. Specifically, by training a machine learning model as described herein, unlabeled training data can be effectively incorporated into the training, thereby improving the performance of the machine learning model. That is, the performance of the trained model can be improved without requiring additional labeled training data. Because unlabeled training data is generally more readily available than labeled training data, the effectiveness of training can be improved without significantly increasing the time and computational cost of obtaining or generating additional training data. More specifically, augmentation techniques, such as techniques traditionally applied to labeled training data, can be effectively applied to unlabeled data to improve the training of the machine learning model without requiring additional training data, labeled or unlabeled. In addition, even if only a relatively small amount of labeled training data is available, the machine learning model can be effectively trained by effectively incorporating readily available unlabeled training data into the training as described herein. Thus, training a model to generate accurate model outputs becomes less dependent on the availability of accurate labeled training data. As a result, models can be trained efficiently and with many fewer labeled examples than models trained on a fully supervised set.
本明細書において説明する本主題の1つまたは複数の実施形態の詳細は、添付の図面および下の説明中に記載されている。本主題の他の特徴、態様、および利点が、説明、図面、および特許請求の範囲から明らかとなろう。 The details of one or more embodiments of the subject matter described herein are set forth in the accompanying drawings and the description below. Other features, aspects, and advantages of the subject matter will become apparent from the description, drawings, and claims.
さまざまな図面中の同様の参照番号および名称は、同様の要素を示す。 Like reference numbers and designations in the various drawings indicate like elements.
図1は、例示的な機械学習モデルトレーニングシステム100を示す。機械学習モデルトレーニングシステム100は、1つまたは複数の位置にある1つまたは複数のコンピュータ上のコンピュータプログラムとして実装されるシステムの一例であり、下で説明するシステム、コンポーネント、および技法はこのシステム内に実装することができる。 Figure 1 illustrates an exemplary machine learning model training system 100. Machine learning model training system 100 is an example of a system implemented as a computer program on one or more computers at one or more locations within which the systems, components, and techniques described below may be implemented.
機械学習モデルトレーニングシステム100は、本明細書ではモデルパラメータと呼ばれる機械学習モデル110のパラメータのトレーニング済みの値を、モデルパラメータの初期値から決定するように、ラベルありトレーニングデータ140およびラベルなしトレーニングデータ150を含むトレーニングデータに対して機械学習モデル110をトレーニングする、システムである。
The machine learning model training system 100 is a system that trains the machine learning model 110 on training data including labeled
機械学習モデル110は、モデル入力102を受領するように構成され、またモデルパラメータに従って特定の機械学習タスクを実行するためにモデル入力102をモデル出力112にマッピングするように、モデル入力を処理するように構成された、機械学習モデルである。
The machine learning model 110 is a machine learning model configured to receive
機械学習モデル110は、多様な機械学習タスクのいずれかを実行するように、すなわち、入力として任意の種類のデジタルデータ入力を受領し、その入力からモデル出力を生成するように、構成することができる。一般に、モデル出力は、可能なクラスの集合に関する確率分布である。 The machine learning model 110 can be configured to perform any of a variety of machine learning tasks, i.e., to receive as input any type of digital data input and generate a model output from the input. Typically, the model output is a probability distribution over a set of possible classes.
例えば、タスクがコンピュータビジョンタスク、例えば画像分類である場合、モデル110への入力は画像であり、所与の画像についてのモデル出力は、物体カテゴリの集合のそれぞれについての確率とすることができ、各確率は、画像がそのカテゴリに属する物体の画像を含む推定尤度を表す。 For example, if the task is a computer vision task, e.g., image classification, the input to model 110 is an image, and the model output for a given image can be a probability for each of a set of object categories, each probability representing an estimated likelihood that the image contains an image of an object belonging to that category.
別の例として、機械学習タスクがドキュメント分類である場合、機械学習モデル110への入力は、インターネットリソース(例えばウェブページ)またはドキュメントからのテキストであり、所与のインターネットリソース、ドキュメント、またはドキュメントの一部分についてのモデル出力は、トピックの集合のそれぞれについてのスコアとすることができ、各スコアは、インターネットリソース、ドキュメント、またはドキュメントの一部分がそのトピックについてのものである推定尤度を表す。 As another example, if the machine learning task is document classification, the input to the machine learning model 110 is text from an Internet resource (e.g., a web page) or document, and the model output for a given Internet resource, document, or portion of a document can be a score for each of a set of topics, with each score representing an estimated likelihood that the Internet resource, document, or portion of a document is about that topic.
別の例として、タスクが自然言語理解タスクである場合、機械学習モデル110への入力は、テキスト系列であり、所与のテキスト系列についてのモデル出力は、自然言語理解タスクに適した確率分布、例えば言語容認性カテゴリ、言語感情(language sentiment)カテゴリ、言語言い換え(language paraphrasing)カテゴリ、文章類似性カテゴリ、テキスト含意(textual entailment)カテゴリ、質問応答カテゴリなどにわたる分布とすることができる。 As another example, if the task is a natural language understanding task, the input to the machine learning model 110 is a text sequence, and the model output for a given text sequence can be a probability distribution appropriate for natural language understanding tasks, such as a distribution over language acceptability categories, language sentiment categories, language paraphrasing categories, sentence similarity categories, textual entailment categories, question answering categories, etc.
別の例として、タスクが健康予測タスクである場合、機械学習モデル110への入力は、患者の電子健康記録データであり、所与の系列についてのモデル出力は、患者の健康関連カテゴリ、例えば患者にとってあり得る診断、患者に関連する起こり得る将来的な健康現象などに関する確率分布とすることができる。 As another example, if the task is a health prediction task, the input to the machine learning model 110 can be the patient's electronic health record data, and the model output for a given sequence can be a probability distribution over the patient's health-related categories, such as likely diagnoses for the patient, possible future health events associated with the patient, etc.
別の例として、タスクが音声処理タスクである場合、機械学習モデル110への入力は、口頭による発話(spoken utterance)を表すオーディオデータ、例えば生のオーディオ特徴または音響特徴とすることができ、モデル出力は、音声分類カテゴリの集合に関する確率分布、例えば可能な言語に関する確率分布、可能なホットワードの集合に関する確率分布などとすることができる。 As another example, if the task is a speech processing task, the input to the machine learning model 110 can be audio data representing spoken utterances, e.g., raw audio or acoustic features, and the model output can be a probability distribution over a set of speech classification categories, e.g., a probability distribution over possible languages, a probability distribution over a set of possible hot words, etc.
機械学習モデル110は、機械学習モデル110によって処理されるモデル入力のタイプに適した任意のアーキテクチャを有することができる。例えば、モデル入力が画像であるとき、機械学習モデル110は、畳み込みニューラルネットワークとすることができる。モデル入力がテキスト系列、または他の特徴、例えば電子健康記録特徴の系列であるとき、機械学習モデル110は、セルフアテンションベースのニューラルネットワーク、例えばTransformer、または再帰型ニューラルネットワーク、例えば長短期メモリ(LSTM)ニューラルネットワークとすることができる。モデル入力が、複数のモダリティ、例えば画像とテキストの両方、からなる入力を含むとき、モデル110は、異なるタイプのニューラルネットワーク、例えば畳み込み層とセルフアテンション層または再帰層の両方を含むことができる。 The machine learning model 110 can have any architecture suitable for the type of model input processed by the machine learning model 110. For example, when the model input is an image, the machine learning model 110 can be a convolutional neural network. When the model input is a text sequence, or a sequence of other features, e.g., electronic health record features, the machine learning model 110 can be a self-attention based neural network, e.g., a Transformer, or a recurrent neural network, e.g., a long short-term memory (LSTM) neural network. When the model input includes inputs of multiple modalities, e.g., both images and text, the model 110 can include different types of neural networks, e.g., both convolutional layers and self-attention or recurrent layers.
システム100によって機械学習モデル110をトレーニングするために使用されるラベルありトレーニングデータ140は、ラベルありトレーニング入力の複数のバッチを含む。このトレーニング入力が「ラベルあり」トレーニング入力と呼ばれるのは、ラベルありトレーニングデータ140が、各ラベルありトレーニング入力についてグラウンドトゥルース出力、すなわち機械学習モデルがラベルありトレーニング入力に対して特定の機械学習タスクを実行することにより生成すべき出力も含むためである。換言すれば、グラウンドトゥルース出力は、機械学習タスクの、対応するラベルありトレーニング入力に対して実行されるときの実際の出力である。
The labeled
システム100によって機械学習モデル110をトレーニングするために使用されるラベルなしトレーニングデータ150は、ラベルなしトレーニング入力の複数のバッチを含む。このトレーニング入力が「ラベルなし」トレーニング入力と呼ばれるのは、ラベルなしトレーニング入力についてのグラウンドトゥルース出力が利用不可能なためであり、すなわちシステム100が、モデル110のトレーニングのために、ラベルなしトレーニング入力のいずれかについてのいかなるグラウンドトゥルース出力にもアクセスすることができないか、または他の何らかの理由でラベルなしトレーニング入力のいずれかについてのグラウンドトゥルース出力を使用することができないためである。
The
一般に、ラベルなしトレーニング入力のバッチは、ラベルありトレーニング入力のバッチと同じ数のトレーニング入力を含むこともあり、ラベルありトレーニング入力のバッチとは異なる数のトレーニング入力を含むこともある。例えば、ラベルありトレーニングアイテムよりもさらに多くのラベルなしトレーニングアイテムが利用可能な、よくあるケースでは、ラベルなしトレーニングアイテムのバッチは、ラベルありトレーニングアイテムのバッチよりも多くのトレーニングアイテムを含むことがある。 In general, a batch of unlabeled training inputs may contain the same number of training inputs as a batch of labeled training inputs, or it may contain a different number of training inputs than a batch of labeled training inputs. For example, a batch of unlabeled training items may contain more training items than a batch of labeled training items, which is often the case when many more unlabeled training items are available than labeled training items.
一般に、システム100は、トレーニングデータから拡張トレーニングデータを生成し、次いで、拡張トレーニングデータに対して機械学習モデル110をトレーニングすることによって、機械学習モデル110をトレーニングする。拡張トレーニングデータを生成するために、システム100は、複数のラベルなしトレーニング入力のそれぞれについて、ラベルなしトレーニング入力にデータ拡張技法を適用することによって、それぞれに対応する拡張トレーニング入力を生成する。 In general, the system 100 trains the machine learning model 110 by generating augmented training data from the training data and then training the machine learning model 110 on the augmented training data. To generate the augmented training data, the system 100 generates, for each of a plurality of unlabeled training inputs, a corresponding augmented training input by applying a data augmentation technique to the unlabeled training input.
拡張トレーニングデータを生成し、拡張トレーニングデータに対して機械学習モデル110をトレーニングすることについては、下で図2および図3を参照してより詳細に説明する。 Generating augmented training data and training the machine learning model 110 on the augmented training data is described in more detail below with reference to Figures 2 and 3.
モデル110がトレーニングされた後、システム100は、新たなネットワーク入力を処理する際に使用するトレーニング済みモデルを指定したデータを提供することができる。すなわち、システム100は、モデルパラメータのトレーニング済みの値を、後にそのトレーニング済みモデルを使用して入力を処理する際に使用できるように、例えばユーザデバイスに出力することによって、またはシステム100にとってアクセス可能なメモリ内に記憶することによって、出力することができる。 After model 110 has been trained, system 100 can provide data specifying the trained model to use when processing new network inputs. That is, system 100 can output the trained values of the model parameters, for example by outputting them to a user device or by storing them in memory accessible to system 100, for later use in processing inputs using the trained model.
トレーニング済み機械学習モデルデータを出力する代わりにまたはそれに加えて、システム100は、モデルパラメータのトレーニング済みの値を有する機械学習モデルのインスタンスをインスタンス化し、処理すべき入力を、例えばシステムによって提供されるアプリケーションプログラミングインターフェース(API)を通じて受領し、受領した入力を、トレーニング済みモデルを使用して処理して、モデル出力を生成し、次いで、受領した入力に応答して、生成されたモデル出力、分類出力、または両方を提供することもできる。 Instead of or in addition to outputting trained machine learning model data, the system 100 may also instantiate an instance of a machine learning model having trained values for model parameters, receive inputs to be processed, for example through an application programming interface (API) provided by the system, process the received inputs using the trained model to generate model outputs, and then provide the generated model outputs, classification outputs, or both, in response to the received inputs.
図2は、ラベルなしトレーニング入力およびラベルありトレーニング入力を含むトレーニングデータに対して機械学習モデルをトレーニングするための例示的なプロセス200のフロー図である。便宜上、プロセス200については、1つまたは複数の位置にある1つまたは複数のコンピュータからなるシステムによって実行されるものとして説明する。例えば、適切にプログラムされた、機械学習モデルトレーニングシステム、例えば図1の機械学習モデルトレーニングシステム100が、プロセス200を実行することができる。
FIG. 2 is a flow diagram of an
システムは、特定の機械学習タスクを実行するためにモデル入力をモデル出力にマッピングするように機械学習モデルをトレーニングするための、トレーニングデータを受領する(ステップ202)。上述したように、トレーニングデータは、ラベルなしトレーニング入力とラベルありトレーニング入力の両方を含む。各ラベルありトレーニング入力について、トレーニングデータは、機械学習モデルがラベルありトレーニング入力に対して特定の機械学習タスクを実行することにより生成すべきグラウンドトゥルース出力も含む。 The system receives training data (step 202) for training the machine learning model to map model inputs to model outputs to perform a particular machine learning task. As described above, the training data includes both unlabeled training inputs and labeled training inputs. For each labeled training input, the training data also includes a ground truth output that the machine learning model should generate by performing the particular machine learning task on the labeled training input.
システムは、トレーニングデータから拡張トレーニングデータを生成する(ステップ204)。具体的には、システムは、複数のラベルなしトレーニング入力のそれぞれについて、ラベルなしトレーニング入力にデータ拡張技法を適用することによって、それぞれに対応する拡張ラベルなしトレーニング入力を生成する。 The system generates augmented training data from the training data (step 204). Specifically, for each of a plurality of unlabeled training inputs, the system generates a corresponding augmented unlabeled training input by applying a data augmentation technique to the unlabeled training input.
用いられるデータ拡張技法は、機械学習モデルがどのようなタイプの入力に作用するかに応じて決まる。 The data augmentation technique used depends on what type of input the machine learning model will operate on.
例えば、モデル入力が画像であるとき、データ拡張技法は、学習された、データ依存の技法、例えばAutoAugment手法を使用して学習された技法とすることができる。換言すれば、システムは、データ依存のAutoAugment手法を使用して、ラベルあり入力にわたって、画像処理変換の集合からラベルなし入力のための拡張技法として使用すべき画像処理変換の学習された組合せを探索することができる。AutoAugmentについては、Ekin D Cubuk、Barret Zoph、Dandelion Mane、Vijay Vasudevan、およびQuoc V Le. Autoaugment: Learning augmentation policies from data. arXivプレプリント arXiv:1805.09501、2018年に、より詳細に記載されている。 For example, when the model input is an image, the data augmentation technique can be a learned, data-dependent technique, such as a technique learned using the AutoAugment technique. In other words, the system can use the data-dependent AutoAugment technique to search across the labeled inputs for a learned combination of image processing transforms from a collection of image processing transforms to use as an augmentation technique for the unlabeled input. AutoAugment is described in more detail in Ekin D Cubuk, Barret Zoph, Dandelion Mane, Vijay Vasudevan, and Quoc V Le. Autoaugment: Learning augmentation policies from data. arXiv preprint arXiv:1805.09501, 2018.
別の例として、モデル入力が画像であるとき、データ拡張技法は、ハイパーパラメータ探索を通じて、すなわちモデルのトレーニング前に、決定される技法とすることができる。例えば、データ拡張技法はRandAugment技法とすることができ、これは、グリッドサーチまたは他のハイパーパラメータ最適化技法を利用して、拡張方策を定めるハイパーパラメータ、例えば各画像に適用される変換の回数を定めるハイパーパラメータ、および適用される各変換の強度(magnitude)を定めるハイパーパラメータの値を特定するものである。RandAugmentについては、Ekin D Cubuk、Barret Zoph、Jonathon Shlens、およびQuoc V Le. Randaugment: Practical data augmentation with no separate search. arXivプレプリント、2019年に、より詳細に記載されている。 As another example, when the model input is an image, the data augmentation technique can be a technique that is determined through hyperparameter search, i.e., before training the model. For example, the data augmentation technique can be the RandAugment technique, which utilizes grid search or other hyperparameter optimization techniques to identify values for hyperparameters that define the augmentation strategy, such as the number of transformations to be applied to each image and the magnitude of each transformation applied. RandAugment is described in more detail in Ekin D Cubuk, Barret Zoph, Jonathon Shlens, and Quoc V Le. Randaugment: Practical data augmentation with no separate search. arXiv preprint, 2019.
別の例として、モデル入力が自然言語テキストであるとき、データ拡張技法は逆翻訳技法とすることができる。逆翻訳は、言語Aの既存の例を別の言語Bに翻訳し、次いでそれをAに翻訳し戻して拡張例を取得する手順を指す。例えば、システムは、モデル入力内の1つまたは複数の語をランダムに選択し、そのランダムに選択された語を逆翻訳して、拡張ラベルなし入力を生成することができる。 As another example, when the model input is natural language text, the data augmentation technique can be a back-translation technique. Back-translation refers to the procedure of translating existing examples in language A into another language B and then translating it back into A to obtain augmented examples. For example, the system can randomly select one or more words in the model input and back-translate the randomly selected words to generate the augmented unlabeled input.
さらに別の例として、モデル入力が自然言語テキストであるとき、データ拡張技法はTF-IDFベースの語置換技法とすることができる。TF-IDFベースの語置換技法は、高いTF-IDF値をもつ非情報的語を維持しながら低いTF-IDFスコアをもつ非情報的語を置換するという技法である。例えば、システムは、入力内の各語にその語のTF-IDF値に基づく確率を割り当てることができ、高いTF-IDF値をもつ語のほうが高い確率を有する。次いで、システムは、設定された個数の語を、割り当てられた確率に従ってサンプリングし、サンプリングされた各語を、例えば入力語の可能な語彙からサンプリングされた語と置換することができる。 As yet another example, when the model input is natural language text, the data augmentation technique can be a TF-IDF based word replacement technique that replaces uninformative words with low TF-IDF scores while preserving uninformative words with high TF-IDF values. For example, the system can assign each word in the input a probability based on its TF-IDF value, with words with high TF-IDF values having a higher probability. The system can then sample a set number of words according to the assigned probabilities and replace each sampled word with a word sampled, for example, from the possible vocabulary of the input words.
したがって、拡張トレーニングデータは、(i)ラベルありトレーニング入力、(ii)ラベルなしトレーニング入力、および(iii)拡張ラベルなしトレーニング入力を含み、各ラベルなしトレーニング入力は、ラベルなしトレーニング入力のうちの1つに対応する。 The augmented training data thus includes (i) labeled training inputs, (ii) unlabeled training inputs, and (iii) augmented unlabeled training inputs, where each unlabeled training input corresponds to one of the unlabeled training inputs.
(i)および(ii)については、本明細書では、拡張されていないトレーニング入力として説明しているが、場合によっては、システムは、入力が画像であるときに(i)および(ii)内のトレーニング例に単純な拡張、例えばクロッピングや反転を適用して、トレーニングプロセスのロバスト性を向上させることができる。これらの単純な拡張は一般に、(ii)から(iii)を生成するために使用される拡張方策とは異なり、すなわち、この拡張方策は一般に、単純な拡張よりもはるかに複雑である。換言すれば、場合によっては、拡張トレーニングデータ内のラベルありトレーニング入力およびラベルなしトレーニング入力には、別の拡張方策を使用する単純な拡張が適用されている。 Although (i) and (ii) are described herein as unaugmented training inputs, in some cases, the system may apply simple augmentations, such as cropping or flipping, to the training examples in (i) and (ii) when the inputs are images to improve the robustness of the training process. These simple augmentations are typically different from the augmentation strategy used to generate (iii) from (ii), i.e., the augmentation strategy is typically much more complex than the simple augmentations. In other words, in some cases, the labeled and unlabeled training inputs in the augmented training data have had simple augmentations applied to them that use different augmentation strategies.
次いで、システムは、拡張トレーニングデータに対して機械学習モデルをトレーニングする(ステップ206)。具体的には、システムは、教師なし目的(unsupervised objective)と教師あり目的(supervised objective)との組合せ、例えば和、平均、または加重和である目的を最適化するように、例えば損失を最小限に抑えるように、モデルをトレーニングする。 The system then trains a machine learning model on the augmented training data (step 206). Specifically, the system trains the model to optimize an objective that is a combination of an unsupervised objective and a supervised objective, e.g., a sum, average, or weighted sum, e.g., to minimize a loss.
教師なし目的は、所与のラベルなしトレーニング入力について、(i)その所与のラベルなしトレーニング入力について機械学習モデルによって生成されたモデル出力と、(ii)対応する拡張教師なしトレーニング入力、すなわちそのラベルなしトレーニング入力から生成された拡張トレーニング入力について機械学習モデルによって生成されたモデル出力との間の差異の尺度となる。 The unsupervised objective is, for a given unlabeled training input, a measure of the difference between (i) the model output generated by the machine learning model for that given unlabeled training input and (ii) the model output generated by the machine learning model for the corresponding augmented unsupervised training input, i.e., the augmented training input generated from that unlabeled training input.
一具体例として、教師なし目的は、(i)所与のラベルなしトレーニング入力について機械学習モデルによって生成されたモデル出力と、(ii)対応する拡張教師なしトレーニング入力について機械学習モデルによって生成されたモデル出力との間の、カルバック-ライブラー(K-L)ダイバージェンスに基づくことができる。この例では、教師なし目的は、 As one specific example, the unsupervised objective can be based on the Kullback-Leibler (K-L) divergence between (i) the model output generated by the machine learning model for a given unlabeled training input and (ii) the model output generated by the machine learning model for the corresponding augmented unsupervised training input. In this example, the unsupervised objective is
を満足させることができ、上式で、λは正の定数値、例えば1.5、1、または.5であり、Eは期待値演算子であり、xは、ラベルなしトレーニングデータUからのラベルなしトレーニング入力であり、 where λ is a positive constant value, e.g., 1.5, 1, or .5, E is the expectation operator, x is an unlabeled training input from the unlabeled training data U,
は、拡張方策qを適用することによってxから生成された、対応する拡張ラベルなしトレーニング入力であり、 is the corresponding augmented unlabeled training input generated from x by applying the augmentation strategy q,
は、(i)ラベルなしトレーニング入力xについて機械学習モデルpによって生成されたモデル出力と、(ii)拡張トレーニング入力 is (i) the model output generated by a machine learning model p for an unlabeled training input x, and (ii) the augmented training input
について機械学習モデルによって生成されたモデル出力との間のK-Lダイバージェンスであり、 is the K-L divergence between the model output generated by the machine learning model,
はモデルパラメータを表し、 represents the model parameters,
は現在のモデルパラメータθの固定のコピーを表し、したがって、モデルパラメータ更新データを計算するときに represents a fixed copy of the current model parameters θ, and therefore, when computing model parameter update data,
を通じて勾配が伝搬しないことを意味する。 This means that gradients do not propagate through
教師あり目的は、所与のラベルありトレーニング入力について、(i)その所与のラベルありトレーニング入力について機械学習モデルによって生成されたモデル出力と、(ii)その所与のラベルありトレーニング入力についてのグラウンドトゥルース出力との間の差異の尺度となる。一具体例として、教師あり目的は、所与のラベルありトレーニング入力について生成された確率分布による所与のグラウンドトゥルース出力の負の対数尤度に基づくことができる。換言すれば、教師あり目的は、 The supervised objective is a measure of the difference between (i) the model output generated by the machine learning model for the given labeled training input and (ii) the ground truth output for the given labeled training input. As one specific example, the supervised objective can be based on the negative log-likelihood of the given ground truth output from the probability distribution generated for the given labeled training input. In other words, the supervised objective is
を満足させることができ、上式で、xは、ラベルありトレーニングデータLからのラベルありトレーニング入力であり、y*は、xについてのグラウンドトゥルース出力である。 where x is the labeled training input from the labeled training data L, and y * is the ground truth output for x.
いくつかの実装形態では、機械学習モデルのトレーニングに利用可能なラベルなしデータ量とラベルありデータ量との間に大きな差異がある場合があり、すなわち、利用可能なトレーニングデータ内に、ラベルありデータよりもはるかに大量のラベルなしデータがある場合がある。これにより、モデルが、ラベルなしデータに対して未学習でありながら、限られた量のラベルありデータに対して早急に過学習する結果となることがある。この困難を軽減するために、いくつかの実装形態では、システムは、トレーニングが進行するにつれてラベルあり例の「トレーニング信号」を徐々にリリースする技法を使用する。 In some implementations, there may be a large disparity between the amount of unlabeled and labeled data available for training a machine learning model; that is, there may be a much larger amount of unlabeled data in the available training data than labeled data. This may result in the model quickly overfitting to a limited amount of labeled data while under-learning to the unlabeled data. To mitigate this difficulty, in some implementations, the system uses techniques to gradually release a "training signal" of labeled examples as training progresses.
大まかに言うと、システムはこの技法を用いて、ラベルあり例に対するモデルの確信度が、トレーニングの間にスケジュールに従って増大する予め定められたしきい値未満である場合にのみ、その例を利用する。 Roughly speaking, using this technique, the system uses a labeled example only if the model's confidence in that example is below a predefined threshold that increases according to a schedule during training.
より具体的には、システムは、上述したように教師あり目的として負の対数尤度を使用する代わりに、修正された教師あり目的を使用する。 More specifically, instead of using negative log-likelihood as the supervised objective as described above, the system uses a modified supervised objective.
上述した目的と同様に、修正された教師あり目的は、所与のラベルありトレーニング入力について生成された確率分布による所与のグラウンドトゥルース出力の負の対数尤度に、ただし確率分布によって所与のグラウンドトゥルース出力に割り当てられた確率が確信度しきい値未満であるときにのみ、基づく。 Similar to the objective described above, the modified supervised objective is based on the negative log-likelihood of a given ground truth output from a generated probability distribution for a given labeled training input, but only when the probability assigned to the given ground truth output by the probability distribution is below a confidence threshold.
確率分布によって所与のグラウンドトゥルース出力に割り当てられた確率が確信度しきい値以上であるとき、システムは、その所与のトレーニング入力を損失関数から除去する。この除去は、確率分布によって所与のグラウンドトゥルース出力に割り当てられた確率が確信度しきい値以上であるときに、教師あり目的をゼロに等しくなるように設定することによって、達成することが可能である。 When the probability assigned to a given ground truth output by the probability distribution is greater than or equal to the confidence threshold, the system removes the given training input from the loss function. This removal can be achieved by setting the supervised objective equal to zero when the probability assigned to a given ground truth output by the probability distribution is greater than or equal to the confidence threshold.
一般に、システムは、トレーニングが進行するにつれてこの確信度しきい値を増大させる。例えば、確率分布がそれにわたって生成されるカテゴリ数がKに等しい場合、システムは、トレーニングが進行するにつれて確信度しきい値を1/Kから1まで徐々に増大させることができる。一具体例として、システムは、各トレーニングステップ後に、すなわち下で説明する、実行されるプロセス300を反復するたびにその後で、確信度しきい値を増大させることができる。 In general, the system increases this confidence threshold as training progresses. For example, if the number of categories over which a probability distribution is generated is equal to K, the system may gradually increase the confidence threshold from 1/K to 1 as training progresses. As one specific example, the system may increase the confidence threshold after each training step, i.e., after each iteration of process 300 performed, described below.
システムは、多様なスケジュールのいずれかに従って確信度しきい値を増大させることができる。 The system can increase the confidence threshold according to any of a variety of schedules.
例えば、システムは、対数関数的スケジュール(logarithmic schedule)に従ってスケジュールを増大させることができる。この例では、トレーニングステップtにおけるしきい値の値は、 For example, the system can increase the schedule according to a logarithmic schedule. In this example, the value of the threshold at training step t is:
を満足させ、上式で、 and satisfy the above equation,
であり、Tはトレーニングステップの合計数である。 where T is the total number of training steps.
別の例として、システムは、線形スケジュール(linear schedule)に従ってスケジュールを増大させることができる。この例では、 As another example, the system can ramp up according to a linear schedule. In this example,
である。 It is.
別の例として、システムは、指数関数的スケジュール(exponential schedule)に従ってスケジュールを増大させることができる。この例では、 As another example, the system can increase the schedule according to an exponential schedule. In this example,
である。 It is.
直観的に、モデルが過学習する傾向のあるとき、例えば、タスクが比較的容易であるか、またはラベルあり例の数が非常に限られているときは、指数関数的スケジュールが最も適しており、というのも、トレーニングの終わりに教師あり信号が大部分リリースされるためである。対照的に、モデルがそれほど過学習しない可能性があるとき(例えばラベルあり例が豊富にあるとき、またはモデルが効果的な正則化を用いているとき)は、対数関数的スケジュールを使用することができる。 Intuitively, when the model is prone to overfitting, e.g., when the task is relatively easy or the number of labeled examples is very limited, an exponential schedule is most appropriate since the supervised signal is largely released at the end of training. In contrast, when the model is unlikely to overfit much (e.g., when labeled examples are abundant or the model uses effective regularization), a logarithmic schedule can be used.
具体的には、トレーニングの間、システムは機械学習モデルを、機械学習トレーニング手順の複数回の反復を実行することによってトレーニングし、手順の各反復は、ラベルありトレーニング入力のバッチとラベルなしトレーニング入力のバッチの両方に対して実行される。各反復の間、システムは、教師あり目的および教師なし目的に基づいて、その反復時点でのモデルパラメータの現在値に対する更新データを決定し、その更新データを現在値に適用して、モデルパラメータの更新値を生成する。 Specifically, during training, the system trains the machine learning model by performing multiple iterations of a machine learning training procedure, where each iteration of the procedure is performed on both batches of labeled and unlabeled training inputs. During each iteration, the system determines updates to the current values of the model parameters at the time of that iteration based on the supervised and unsupervised objectives, and applies the updates to the current values to generate updates to the model parameters.
図3は、ラベルなしトレーニング入力のバッチおよびラベルありトレーニング入力のバッチに対して機械学習モデルをトレーニングするための例示的なプロセス300のフロー図である。便宜上、プロセス300については、1つまたは複数の位置にある1つまたは複数のコンピュータからなるシステムによって実行されるものとして説明する。例えば、適切にプログラムされた、機械学習モデルトレーニングシステム、例えば図1の機械学習モデルトレーニングシステム100が、プロセス300を実行することができる。 FIG. 3 is a flow diagram of an exemplary process 300 for training a machine learning model on batches of unlabeled training inputs and batches of labeled training inputs. For convenience, process 300 is described as being performed by a system of one or more computers at one or more locations. For example, a suitably programmed machine learning model training system, such as machine learning model training system 100 of FIG. 1, may perform process 300.
システムは、モデルパラメータのトレーニング済みの値をモデルパラメータの初期値から決定するために、ラベルありバッチ-ラベルなしバッチの複数の異なる組合せについて、プロセス300を複数回実行することができる。例えば、システムは、指定の反復回数にわたって、指定の時間量にわたって、またはパラメータの値の変化がしきい値を下回るまで、プロセス300の実行を継続することができる。 The system can run process 300 multiple times for multiple different combinations of labeled and unlabeled batches to determine trained values for the model parameters from the initial values of the model parameters. For example, the system can continue to run process 300 for a specified number of iterations, for a specified amount of time, or until the change in the value of the parameter falls below a threshold.
システムは、ラベルありトレーニング入力のバッチを取得する(ステップ302)。 The system obtains a batch of labeled training inputs (step 302).
システムは、各ラベルありトレーニング入力を、機械学習モデルを使用して、モデルパラメータの現在値に従って処理して、ラベルありトレーニング入力のそれぞれについて、それぞれに対応するモデル出力を生成する(ステップ304)。 The system processes each labeled training input using the machine learning model according to the current values of the model parameters to generate a corresponding model output for each labeled training input (step 304).
システムは、ラベルなしトレーニング入力のラベルなしバッチ、およびラベルなしバッチ内の各ラベルなしトレーニング入力についての拡張ラベルなしトレーニング入力を取得する(ステップ306)。 The system obtains an unlabeled batch of unlabeled training inputs and an augmented unlabeled training input for each unlabeled training input in the unlabeled batch (step 306).
システムは、各ラベルなしトレーニング入力、および各拡張ラベルなしトレーニング入力を、機械学習モデルを使用して、モデルパラメータの現在値に従って処理して、ラベルなしトレーニング入力のそれぞれについて、それぞれに対応するモデル出力を生成する(ステップ308)。 The system processes each unlabeled training input and each augmented unlabeled training input using the machine learning model according to the current values of the model parameters to generate a corresponding model output for each unlabeled training input (step 308).
システムは、ラベルありトレーニング入力、ラベルなしトレーニング入力、およびラベルなしトレーニング入力についてのモデル出力に基づいて、モデルパラメータの現在値を更新する(ステップ310)。 The system updates the current values of the model parameters based on the labeled training inputs, the unlabeled training inputs, and the model output for the unlabeled training inputs (step 310).
具体的には、システムは、ラベルありトレーニング入力のそれぞれについて、教師あり目的のモデルパラメータに関するそれぞれに対応する勾配を決定し、ラベルなしトレーニング入力のそれぞれについて、教師なし目的のモデルパラメータに関するそれぞれに対応する勾配を決定する。 Specifically, for each labeled training input, the system determines a corresponding gradient with respect to the model parameters of the supervised objective, and for each unlabeled training input, the system determines a corresponding gradient with respect to the model parameters of the unsupervised objective.
次いで、システムは、例えばそれぞれに対応する勾配を平均または加算することによって、それぞれに対応する勾配を複合して複合勾配を生成し、次いで、複合勾配を使用して、例えば複合勾配に更新ルール、例えば学習率、Adamオプティマイザ更新ルール、またはrmsProp更新ルールを適用して更新データを生成し、次いで更新データを現在値に適用、すなわち減算または加算することによって、モデルパラメータの現在値を更新する。 The system then combines the corresponding gradients to generate a composite gradient, e.g., by averaging or adding the corresponding gradients, and then uses the composite gradient to generate update data, e.g., by applying an update rule, e.g., a learning rate, Adam optimizer update rule, or an rmsProp update rule, to the composite gradient, and then updates the current values of the model parameters by applying, i.e., subtracting or adding, the update data to the current values.
図4は、説明した技法の性能を、他の半教師あり学習技法と比べた様子を示す。 Figure 4 shows how the performance of the described technique compares with other semi-supervised learning techniques.
具体的には、図4は、説明した技法(「RandAugment」拡張方策を用いた「UDA」)を、大いに競争力のある2つのベースライン(1)入力に対して敵対的ガウス雑音を生成するアルゴリズムであるVirtual adversarial training (VAT) (Miyatoら、2018年)、および(2)半教師あり学習におけるこれまでの進展を融合させた技法であるMixMatch ((Berthelotら、2019年))と比較した様子を示す。 Specifically, Figure 4 shows how the described technique (UDA with the RandAugment augmentation strategy) compares with two highly competitive baselines: (1) Virtual adversarial training (VAT) (Miyato et al., 2018), an algorithm that generates adversarial Gaussian noise for the input, and (2) MixMatch (Berthelot et al., 2019), a technique that blends previous advances in semi-supervised learning.
図4から分かるように、説明した技法を使用してトレーニングされたトレーニング済みモデルの誤り率は、さまざまなサイズのラベルありデータにおいて、2つのベースラインよりも一貫して低く、すなわち良好であり、すなわち、説明した技法は、さまざまなサイズのラベルありデータが与えられたとき、明確なマージンを伴って2つのベースラインよりも一貫して性能が優れている。 As can be seen from Figure 4, the error rates of trained models trained using the described technique are consistently lower, i.e., better, than the two baselines on labeled data of various sizes, i.e., the described technique consistently outperforms the two baselines by a clear margin when given labeled data of various sizes.
したがって、他の半教師あり学習技法、すなわちラベルありデータとラベルなしデータの両方を使用する他の技法と比べても、説明した技法は、より効果的なモデルトレーニングをもたらす。 Thus, compared to other semi-supervised learning techniques, i.e., other techniques that use both labeled and unlabeled data, the described technique results in more effective model training.
本明細書では、システムおよびコンピュータプログラムコンポーネントに関連して、「構成される」という用語を使用している。1つまたは複数のコンピュータからなるシステムが、特定の動作またはアクションを実行するように構成されるとは、システムが、動作の際にそのシステムにその動作またはアクションを実行させるソフトウェア、ファームウェア、ハードウェア、またはそれらの組合せを、システム上にインストールされる、ということを意味する。1つまたは複数のコンピュータプログラムが、特定の動作またはアクションを実行するように構成されるとは、データ処理装置によって実行されるとその装置にその動作またはアクションを実行させる命令を、その1つまたは複数のプログラムが含む、ということを意味する。 The term "configured" is used herein in connection with systems and computer program components. A system of one or more computers is configured to perform a particular operation or action means that the system has installed thereon software, firmware, hardware, or a combination thereof that, when in operation, causes the system to perform the operation or action. One or more computer programs are configured to perform a particular operation or action means that the one or more programs contain instructions that, when executed by a data processing device, cause the device to perform the operation or action.
本明細書において説明した本主題および機能的動作の実施形態は、デジタル電子回路として、有形に具現化されたコンピュータソフトウェアもしくはコンピュータファームウェアとして、本明細書において開示した構造およびそれらの構造的等価物を含むコンピュータハードウェアとして、またはそれらのうちの1つもしくは複数のものの組合せとして、実装することができる。本明細書において説明した本主題の実施形態は、1つまたは複数のコンピュータプログラムとして、すなわちデータ処理装置によって実行できるように、またはデータ処理装置の動作を制御するために、有形の非一時的記憶媒体上に符号化されたコンピュータプログラム命令の1つまたは複数のモジュールとして、実装することができる。コンピュータ記憶媒体は、機械可読記憶デバイス、機械可読記憶基板、ランダムアクセスもしくはシリアルアクセスのメモリデバイス、またはそれらのうちの1つもしくは複数のものの組合せとすることができる。その代わりにまたはそれに加えて、プログラム命令は、情報をデータ処理装置によって実行する目的で適切なレシーバ装置に送信できるように符号化するために生成される、人工的に生成された伝搬信号、例えば機械により生成された電気信号、光信号、または電磁信号上に、符号化することもできる。 Embodiments of the subject matter and functional operations described herein may be implemented as digital electronic circuitry, as tangibly embodied computer software or firmware, as computer hardware including the structures disclosed herein and their structural equivalents, or as a combination of one or more of them. Embodiments of the subject matter described herein may be implemented as one or more computer programs, i.e., as one or more modules of computer program instructions encoded on a tangible, non-transitory storage medium for execution by or for controlling the operation of a data processing apparatus. The computer storage medium may be a machine-readable storage device, a machine-readable storage substrate, a random-access or serial-access memory device, or a combination of one or more of them. Alternatively or additionally, the program instructions may be encoded on an artificially generated propagated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal, that is generated to encode information for transmission to a suitable receiver device for execution by the data processing apparatus.
「データ処理装置」という用語は、データ処理ハードウェアを指し、例として1つのプログラマブルプロセッサ、1つのコンピュータ、または複数のプロセッサもしくはコンピュータを含む、データを処理するためのあらゆる種類の装置、デバイス、および機械を包含するものである。装置は、専用論理回路、例えばFPGA(フィールドプログラマブルゲートアレイ)またはASIC(特定用途向け集積回路)とすることもでき、あるいはそれをさらに含むこともできる。装置はオプションで、ハードウェアに加えて、コンピュータプログラムのための実行環境を作り出すコード、例えば、プロセッサファームウェア、プロトコルスタック、データベース管理システム、オペレーティングシステム、またはそれらのうちの1つもしくは複数のものの組合せを構成するコードを含むこともできる。 The term "data processing apparatus" refers to data processing hardware and encompasses any kind of apparatus, device, and machine for processing data, including, by way of example, a programmable processor, a computer, or multiple processors or computers. An apparatus may also be or include special purpose logic circuitry, such as an FPGA (field programmable gate array) or an ASIC (application specific integrated circuit). An apparatus may optionally include, in addition to hardware, code that creates an execution environment for computer programs, such as code constituting processor firmware, a protocol stack, a database management system, an operating system, or a combination of one or more of these.
プログラム、ソフトウェア、ソフトウェアアプリケーション、アプリ、モジュール、ソフトウェアモジュール、スクリプト、またはコードとも呼ばれるかまたは記載されることのあるコンピュータプログラムは、コンパイル型言語もしくはインタープリタ型言語、または宣言型言語もしくは手続き型言語を含む、任意の形態のプログラミング言語で記述することができ、またコンピュータプログラムは、スタンドアロンプログラムとして、またはモジュール、コンポーネント、サブルーチン、もしくはコンピューティング環境において使用するのに適した他のユニットとして、を含む、任意の形態でデプロイすることができる。プログラムは、その必要はないが、ファイルシステム内のファイルに対応してよい。プログラムは、他のプログラムもしくはデータを保持するファイルの一部分、例えばマークアップ言語ドキュメント内に格納された1つもしくは複数のスクリプト内に、当該のプログラムに専用の単一のファイル内に、または複数の連係されたファイル、例えばコードの1つもしくは複数のモジュール、サブプログラム、もしくは一部分を格納したファイル内に、格納することができる。コンピュータプログラムは、1つのコンピュータ上で、または1つのサイトに位置するかもしくは複数のサイトにわたって分散され、データ通信ネットワークによって相互接続された複数のコンピュータ上で実行されるように、デプロイすることができる。 A computer program, which may also be referred to or described as a program, software, software application, app, module, software module, script, or code, may be written in any form of programming language, including compiled or interpreted languages, or declarative or procedural languages, and may be deployed in any form, including as a stand-alone program or as a module, component, subroutine, or other unit suitable for use in a computing environment. A program may, but need not, correspond to a file in a file system. A program may be stored as part of a file that holds other programs or data, for example in one or more scripts stored in a markup language document, in a single file dedicated to the program, or in multiple linked files, for example files that store one or more modules, subprograms, or portions of code. A computer program may be deployed to be executed on one computer, or on multiple computers located at one site or distributed across multiple sites and interconnected by a data communications network.
本明細書では、「データベース」という用語は、データの任意の集まりを指すために広義に使用され、データは、任意の特定の様式で構造化されている必要も、全く構造化されている必要もなく、1つまたは複数の位置にある記憶デバイス上に記憶させることができる。したがって、例えば、インデックスデータベースは、そのそれぞれが別様に編成およびアクセスされることの可能な、データの複数の集まりを含むことができる。 The term "database" is used broadly herein to refer to any collection of data, which need not be structured in any particular manner, or even structured at all, and which may be stored on storage devices in one or more locations. Thus, for example, an index database may contain multiple collections of data, each of which may be organized and accessed differently.
同様に、本明細書では、「エンジン」という用語は、1つまたは複数の特定の機能を実施するようにプログラムされる、ソフトウェアベースのシステム、サブシステム、またはプロセスを指すために広義に使用される。一般に、エンジンは、1つまたは複数の位置にある1つまたは複数のコンピュータ上にインストールされた、1つまたは複数のソフトウェアモジュールまたはソフトウェアコンポーネントとして実装される。いくつかの場合には、1つまたは複数のコンピュータが、特定のエンジンに専用であり、他の場合には、複数のエンジンが、同じ1つまたは複数のコンピュータ上にインストールされ、その上で実行されることが可能である。 Similarly, the term "engine" is used broadly herein to refer to a software-based system, subsystem, or process that is programmed to perform one or more specific functions. Generally, an engine is implemented as one or more software modules or components installed on one or more computers in one or more locations. In some cases, one or more computers are dedicated to a particular engine, and in other cases, multiple engines can be installed and executed on the same computer or computers.
本明細書において説明したプロセスおよび論理フローは、入力データに作用し出力を生成することによって機能を実施するための1つまたは複数のコンピュータプログラムを実行する、1つまたは複数のプログラマブルコンピュータによって実施されることが可能である。プロセスおよび論理フローは、専用論理回路、例えばFPGAもしくはASICによって、または専用論理回路とプログラムされた1つもしくは複数のコンピュータとの組合せによって、実施されることも可能である。 The processes and logic flows described herein may be implemented by one or more programmable computers executing one or more computer programs to perform functions by operating on input data and generating output. The processes and logic flows may also be implemented by special purpose logic circuitry, e.g., an FPGA or an ASIC, or by a combination of special purpose logic circuitry and one or more programmed computers.
コンピュータプログラムの実行に適したコンピュータは、汎用マイクロプロセッサもしくは専用マイクロプロセッサもしくはその両方、または他の任意の種類の中央処理装置に基づくことができる。一般に、中央処理装置は、読出し専用メモリまたはランダムアクセスメモリまたはその両方から、命令およびデータを受領する。コンピュータの不可欠な要素が、命令を実施または実行するための中央処理装置、ならびに命令およびデータを記憶するための1つまたは複数のメモリデバイスである。中央処理装置およびメモリは、専用論理回路によって補完されるかまたは専用論理回路に組み込むことが可能である。一般に、コンピュータはまた、データを記憶するための1つまたは複数の大容量記憶デバイス、例えば磁気ディスク、光磁気ディスク、または光ディスクを含むか、またはそこからデータを受領するように、もしくはそこにデータを転送するように動作可能に結合されるか、またはその両方である。しかし、コンピュータはそのようなデバイスを有している必要はない。さらに、コンピュータは別のデバイスに、例えばほんの数例を挙げると、モバイル電話、パーソナルデジタルアシスタント(PDA)、モバイルオーディオプレーヤもしくはモバイルビデオプレーヤ、ゲーム機、グローバルポジショニングシステム(GPS)レシーバ、またはポータブル記憶デバイス、例えばユニバーサルシリアルバス(USB)フラッシュドライブに、埋め込むことができる。 A computer suitable for executing a computer program may be based on a general-purpose or special-purpose microprocessor or both, or on any other type of central processing unit. Typically, the central processing unit receives instructions and data from a read-only memory or a random-access memory or both. The essential elements of a computer are a central processing unit for implementing or executing instructions, and one or more memory devices for storing instructions and data. The central processing unit and memory may be supplemented by or incorporated in special-purpose logic circuitry. Typically, a computer also includes one or more mass storage devices, such as magnetic, magneto-optical, or optical disks, for storing data, or is operatively coupled to receive data therefrom or to transfer data thereto, or both. However, a computer need not have such devices. Furthermore, a computer may be embedded in another device, such as a mobile phone, a personal digital assistant (PDA), a mobile audio or video player, a gaming console, a global positioning system (GPS) receiver, or a portable storage device, such as a universal serial bus (USB) flash drive, to name just a few.
コンピュータプログラム命令およびデータを記憶するのに適したコンピュータ可読媒体としては、例として半導体メモリデバイス、例えばEPROM、EEPROM、およびフラッシュメモリデバイス;磁気ディスク、例えば内蔵ハードディスクまたはリムーバブルディスク;光磁気ディスク;ならびにCD ROMディスクおよびDVD-ROMディスクを含む、あらゆる形態の不揮発性のメモリ、媒体、およびメモリデバイスがある。 Computer-readable media suitable for storing computer program instructions and data include all forms of non-volatile memory, media, and memory devices, including, by way of example, semiconductor memory devices, such as EPROM, EEPROM, and flash memory devices; magnetic disks, such as internal hard disks or removable disks; magneto-optical disks; and CD ROM disks and DVD-ROM disks.
ユーザとの対話を可能にするために、本明細書において説明した本主題の実施形態は、ユーザに情報を表示するためのディスプレイデバイス、例えばCRT(陰極線管)またはLCD(液晶ディスプレイ)モニタと、ユーザがそれによってコンピュータに入力することのできるキーボードおよびポインティングデバイス、例えばマウスまたはトラックボールとを有するコンピュータ上に実装することができる。他の種類のデバイスを使用して、ユーザとの対話を可能にすることもでき、例えば、ユーザに提供されるフィードバックは、任意の形態の感覚フィードバック、例えば視覚フィードバック、聴覚フィードバック、または触覚フィードバックとすることができ、ユーザからの入力は、音響入力、音声入力、または触覚入力を含む、任意の形態で受領されることが可能である。加えて、コンピュータはユーザと、ユーザによって使用されているデバイスにドキュメントを送り、そこからドキュメントを受信することによって、例えば、ユーザのデバイス上のウェブブラウザに、そのウェブブラウザから受信した要求に応答してウェブページを送ることによって、対話することができる。また、コンピュータはユーザと、パーソナルデバイス、例えばメッセージングアプリケーションを実行しているスマートフォンに、テキストメッセージまたは他の形態のメッセージを送り、ユーザから返信として応答メッセージを受信することによって、対話することができる。 To enable interaction with a user, the embodiments of the subject matter described herein can be implemented on a computer having a display device, such as a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to the user, and a keyboard and pointing device, such as a mouse or trackball, by which the user can provide input to the computer. Other types of devices can also be used to enable interaction with the user, for example, feedback provided to the user can be any form of sensory feedback, such as visual feedback, auditory feedback, or tactile feedback, and input from the user can be received in any form, including acoustic input, speech input, or tactile input. In addition, the computer can interact with the user by sending documents to and receiving documents from a device being used by the user, for example, by sending a web page to a web browser on the user's device in response to a request received from the web browser. The computer can also interact with the user by sending text messages or other forms of messages to a personal device, such as a smartphone running a messaging application, and receiving a response message in return from the user.
機械学習モデルを実装するためのデータ処理装置は、例えば、機械学習のトレーニングまたはプロダクションの共通の計算集約的部分、すなわち推論、作業負荷を処理するための、専用ハードウェアアクセラレータユニットを含むこともできる。 Data processing devices for implementing machine learning models may also include dedicated hardware accelerator units, for example, to handle common computationally intensive parts of machine learning training or production, i.e., inference, workloads.
機械学習モデルは、機械学習フレームワーク、例えばTensorFlowフレームワーク、Microsoft Cognitive Toolkitフレームワーク、Apache Singaフレームワーク、またはApache MXNetフレームワークを使用して実装し、デプロイすることができる。 Machine learning models can be implemented and deployed using machine learning frameworks, such as the TensorFlow framework, the Microsoft Cognitive Toolkit framework, the Apache Singa framework, or the Apache MXNet framework.
本明細書において説明した本主題の実施形態は、例えばデータサーバとしてのバックエンドコンポーネントを含むコンピューティングシステム内、またはミドルウェアコンポーネント、例えばアプリケーションサーバを含むコンピューティングシステム内、またはフロントエンドコンポーネント、例えば本明細書において説明した本主題の一実装形態とユーザがそれを通じて対話することのできるグラフィカルユーザインターフェース、ウェブブラウザ、もしくはアプリを有するクライアントコンピュータを含むコンピューティングシステム内、または1つもしくは複数のそのようなバックエンドコンポーネント、ミドルウェアコンポーネント、もしくはフロントエンドコンポーネントの任意の組合せを含むコンピューティングシステム内に、実装することができる。システムのこれらのコンポーネント同士は、任意の形態または媒体のデジタルデータ通信、例えば通信ネットワークによって、相互接続することができる。通信ネットワークの例としては、ローカルエリアネットワーク(LAN)、および広域ネットワーク(WAN)、例えばインターネットがある。 Embodiments of the subject matter described herein may be implemented in a computing system that includes a back-end component, e.g., a data server, or a middleware component, e.g., an application server, or a front-end component, e.g., a client computer having a graphical user interface, web browser, or app through which a user may interact with an implementation of the subject matter described herein, or any combination of one or more such back-end, middleware, or front-end components. The components of the system may be interconnected by any form or medium of digital data communication, e.g., a communications network. Examples of communications networks include local area networks (LANs) and wide area networks (WANs), e.g., the Internet.
コンピューティングシステムは、クライアントとサーバを含むことができる。クライアントとサーバは、一般に互いに遠隔にあり、典型的には通信ネットワークを通じて対話する。クライアントとサーバの関係は、それぞれのコンピュータ上で実行され、互いにクライアント-サーバ関係を有する、コンピュータプログラムによって生じる。いくつかの実施形態では、サーバはデータ、例えばHTMLページをユーザデバイスに、例えばクライアントとしての役割を果たすデバイスと対話しているユーザにデータを表示し、そのユーザからユーザ入力を受領する目的で送信する。ユーザデバイスにおいて生成されたデータ、例えばユーザ対話の結果は、デバイスからサーバにおいて受信されることが可能である。 A computing system may include clients and servers. Clients and servers are generally remote from each other and typically interact through a communications network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other. In some embodiments, a server transmits data, e.g., HTML pages, to a user device, e.g., for the purpose of displaying the data to a user interacting with the device acting as a client and receiving user input from the user. Data generated at the user device, e.g., results of user interaction, can be received from the device at the server.
本明細書は、実装形態の多くの具体的詳細を含んでいるが、これらは、任意の発明の範囲に対する、または特許請求され得るものの範囲に対する限定と解釈するのではなく、特定の発明の特定の実施形態に特有であり得る特徴についての説明と解釈されたい。本明細書において別々の実施形態の文脈の中で説明されるいくつかの特徴は、単一の実施形態において組み合わせて実装することもできる。反対に、単一の実施形態の文脈の中で説明されるさまざまな特徴は、複数の実施形態において別々に、または任意の適切な部分組合せで、実装することもできる。さらに、特徴については上で、ある特定の組合せで作用するものと説明されていることがあり、さらにはそのようなものとして最初に特許請求されていることすらあるが、特許請求された組合せからの1つまたは複数の特徴を、場合によっては、その組合せから削除することができ、特許請求された組合せが、部分組合せまたは部分組合せの変形を対象としてよい。 While this specification contains many specific details of implementations, these should not be construed as limitations on the scope of any invention or on the scope of what may be claimed, but rather as descriptions of features that may be specific to particular embodiments of a particular invention. Some features described in the context of separate embodiments herein may also be implemented in combination in a single embodiment. Conversely, various features described in the context of a single embodiment may also be implemented in multiple embodiments separately or in any suitable subcombination. Furthermore, although features may be described above as working in a particular combination, and even initially claimed as such, one or more features from a claimed combination may, in some cases, be deleted from the combination, and the claimed combination may be directed to a subcombination or a variation of the subcombination.
同様に、動作については、特定の順序で図面に描かれ特許請求の範囲に記載されているが、これは、望ましい結果を得るために、そのような動作が図示の特定の順序で、もしくは順番に実施されること、または図示の全ての動作が実施されることを要求するものと理解すべきではない。ある特定の状況下では、マルチタスキングおよび並列処理が有利となることがある。さらに、上述した実施形態におけるさまざまなシステムモジュールおよびシステムコンポーネントの分離は、全ての実施形態においてそのような分離を要求するものと理解すべきではなく、説明したプログラムコンポーネントとシステムは一般に、単一のソフトウェア製品に一緒に統合するか、または複数のソフトウェア製品にパッケージ化できることを理解されたい。 Similarly, although operations are depicted in the figures and recited in the claims in a particular order, this should not be understood as requiring that such operations be performed in the particular order or sequence illustrated, or that all of the illustrated operations be performed, to achieve desirable results. In certain circumstances, multitasking and parallel processing may be advantageous. Furthermore, the separation of various system modules and system components in the above-described embodiments should not be understood as requiring such separation in all embodiments, and it should be understood that the program components and systems described may generally be integrated together in a single software product or packaged in multiple software products.
以上、本主題の特定の実施形態について説明してきた。他の実施形態が、添付の特許請求の範囲に記載の範囲に含まれる。例えば、特許請求の範囲に記載されたアクションは、異なる順序で実施してもなお、望ましい結果を得ることができる。一例として、添付の図中に描かれたプロセスは、望ましい結果を得るために、図示の特定の順序、または順番を必ずしも必要とするとは限らない。場合によっては、マルチタスキングおよび並列処理が有利となることがある。 Specific embodiments of the present subject matter have been described above. Other embodiments are within the scope of the following claims. For example, the actions recited in the claims can be performed in a different order and still achieve desirable results. By way of example, the processes depicted in the accompanying figures do not necessarily require the particular order shown, or sequence, to achieve desirable results. In some cases, multitasking and parallel processing may be advantageous.
100 機械学習モデルトレーニングシステム
102 モデル入力
110 機械学習モデル
112 モデル出力
140 ラベルありトレーニングデータ
150 ラベルなしトレーニングデータ
200 プロセス
300 プロセス
100 Machine Learning Model Training System
102 Model Input
110 Machine Learning Models
112 Model Output
140 labeled training data
150 unlabeled training data
200 processes
300 processes
Claims (13)
複数のラベルなしトレーニング入力、ならびに
複数のラベルありトレーニング入力、および各ラベルありトレーニング入力について、前記機械学習モデルが前記ラベルありトレーニング入力に対して前記特定の機械学習タスクを実行することにより生成すべきグラウンドトゥルース出力
を含む、ステップと、
拡張トレーニングデータを生成するステップであって、前記複数のラベルなしトレーニング入力のそれぞれについて、前記ラベルなしトレーニング入力にデータ拡張技法を適用することによって、それぞれに対応する拡張トレーニング入力を生成するステップを含む、ステップと、
前記拡張トレーニングデータに対して前記機械学習モデルをトレーニングするステップであって、
前記ラベルなしトレーニング入力および前記拡張トレーニング入力に対して、(i)所与のラベルなしトレーニング入力について前記機械学習モデルによって生成されたモデル出力と、(ii)前記ラベルなしトレーニング入力から生成された前記拡張トレーニング入力について前記機械学習モデルによって生成されたモデル出力との間の差異の尺度となる教師なし目的を最適化するように、前記機械学習モデルをトレーニングするステップ、ならびに
前記ラベルありトレーニング入力に対して、(i)所与のラベルありトレーニング入力について前記機械学習モデルによって生成されたモデル出力と、(ii)前記所与のラベルありトレーニング入力についての前記グラウンドトゥルース出力との間の差異の尺度となる教師あり目的を最適化するように、前記機械学習モデルをトレーニングするステップ
を含む、ステップと
を含む、コンピュータ実装方法。 Receiving training data for training a machine learning model to map model inputs to model outputs to perform a particular machine learning task, the training data comprising:
a plurality of unlabeled training inputs; and a plurality of labeled training inputs, and for each labeled training input, a ground truth output to be generated by the machine learning model by performing the particular machine learning task on the labeled training inputs;
generating augmented training data, the augmented training data including, for each of the plurality of unlabeled training inputs, generating a corresponding augmented training input by applying a data augmentation technique to the unlabeled training input;
training the machine learning model on the augmented training data,
training the machine learning model to optimize, for the unlabeled training inputs and the augmented training inputs, an unsupervised objective that measures the difference between (i) a model output generated by the machine learning model for a given unlabeled training input and (ii) a model output generated by the machine learning model for the augmented training input generated from the unlabeled training input; and training the machine learning model to optimize, for the labeled training inputs, a supervised objective that measures the difference between (i) a model output generated by the machine learning model for a given labeled training input and (ii) the ground truth output for the given labeled training input.
前記教師なし目的が、(i)前記所与のラベルなしトレーニング入力について前記機械学習モデルによって生成された前記モデル出力と、(ii)前記ラベルなしトレーニング入力から生成された前記拡張トレーニング入力について前記機械学習モデルによって生成された前記モデル出力との間のK-Lダイバージェンスに基づく、請求項1に記載の方法。 the model output is a probability distribution;
2. The method of claim 1 , wherein the unsupervised objective is based on a KL divergence between (i) the model output generated by the machine learning model for the given unlabeled training input and (ii) the model output generated by the machine learning model for the augmented training input generated from the unlabeled training input.
前記教師あり目的が、前記所与のラベルありトレーニング入力について生成された前記確率分布による前記所与のグラウンドトゥルース出力の負の対数尤度に基づく、請求項1から2のいずれか一項に記載の方法。 the model output is a probability distribution;
3. The method of claim 1, wherein the supervised objective is based on the negative log-likelihood of the given ground truth output from the probability distribution generated for the given labeled training input.
前記教師あり目的が、
前記確率分布によって前記所与のグラウンドトゥルース出力に割り当てられた確率が確信度しきい値未満であるときに、前記所与のラベルありトレーニング入力について生成された確率分布による前記所与のグラウンドトゥルース出力の負の対数尤度に基づき、
前記確率分布によって前記所与のグラウンドトゥルース出力に割り当てられた前記確率が前記確信度しきい値以上であるときに、ゼロに等しい、
請求項1から4のいずれか一項に記載の方法。 the model output is a probability distribution;
The supervised objective is:
based on a negative log-likelihood of the given ground truth output from a probability distribution generated for the given labeled training input when the probability assigned to the given ground truth output by the probability distribution is less than a confidence threshold;
equal to zero when the probability assigned to the given ground truth output by the probability distribution is greater than or equal to the confidence threshold;
5. The method according to any one of claims 1 to 4.
トレーニングが進行するにつれて前記確信度しきい値を増大させるステップ
を含む、請求項5に記載の方法。 said step of training comprising:
The method of claim 5 , comprising increasing the confidence threshold as training progresses.
前記モデル入力が画像であり、
所与の画像についての前記モデル出力が、物体カテゴリの集合のそれぞれについての確率であり、
各確率が、前記画像が前記物体カテゴリに属する物体を含む推定尤度を表す、請求項1から8のいずれか一項に記載の方法。 the machine learning task is image classification;
the model input is an image;
the model output for a given image is a probability for each of a set of object categories;
The method of claim 1 , wherein each probability represents an estimated likelihood that the image contains an object belonging to the object category.
前記対応するモデル出力が、前記患者にとってあり得る診断の確率分布を含む、請求項1から7のいずれか一項に記載の方法。 the model input includes patient electronic health record data;
8. The method of claim 1, wherein the corresponding model output comprises a probability distribution of possible diagnoses for the patient.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201962838932P | 2019-04-25 | 2019-04-25 | |
US62/838,932 | 2019-04-25 | ||
PCT/US2020/029945 WO2020219971A1 (en) | 2019-04-25 | 2020-04-24 | Training machine learning models using unsupervised data augmentation |
Publications (2)
Publication Number | Publication Date |
---|---|
JP2022530127A JP2022530127A (en) | 2022-06-27 |
JP7483751B2 true JP7483751B2 (en) | 2024-05-15 |
Family
ID=
Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2017037588A (en) | 2015-08-14 | 2017-02-16 | 富士ゼロックス株式会社 | Information processor and information processing program |
US20180285771A1 (en) | 2017-03-31 | 2018-10-04 | Drvision Technologies Llc | Efficient machine learning method |
JP2018205920A (en) | 2017-05-31 | 2018-12-27 | 富士通株式会社 | Learning program, learning method and object detecting apparatus |
Patent Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2017037588A (en) | 2015-08-14 | 2017-02-16 | 富士ゼロックス株式会社 | Information processor and information processing program |
US20180285771A1 (en) | 2017-03-31 | 2018-10-04 | Drvision Technologies Llc | Efficient machine learning method |
JP2018205920A (en) | 2017-05-31 | 2018-12-27 | 富士通株式会社 | Learning program, learning method and object detecting apparatus |
Non-Patent Citations (1)
Title |
---|
SAJJADI, Mehdi et al.，Regularization With Stochastic Transformations and Perturbations for Deep Semi-Supervised Learning，arXiv.org，Cornell University，2016年06月14日，pp. 1-9，[検索日 2024.03.25], インターネット <URL: https://doi.org/10.48550/arXiv.1606.04586> |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11568207B2 (en) | Learning observation representations by predicting the future in latent space | |
CN110520871B (en) | Training machine learning models using learning progress measurements | |
US11875262B2 (en) | Learning neural network structure | |
US20220215209A1 (en) | Training machine learning models using unsupervised data augmentation | |
EP3711000B1 (en) | Regularized neural network architecture search | |
US11227581B2 (en) | Systems and methods for generating a response based on task-independent conversational responses or task-specific responses | |
US20220092416A1 (en) | Neural architecture search through a graph search space | |
US20240127058A1 (en) | Training neural networks using priority queues | |
US11922281B2 (en) | Training machine learning models using teacher annealing | |
US10824946B2 (en) | Training neural networks using posterior sharpening | |
US20220230065A1 (en) | Semi-supervised training of machine learning models using label guessing | |
US20200104707A1 (en) | Sampling from a generator neural network using a discriminator neural network | |
CN111832699A (en) | Computationally efficient expressive output layer for neural networks | |
JP7483751B2 (en) | Training machine learning models using unsupervised data augmentation | |
CN115398446A (en) | Machine learning algorithm search using symbolic programming | |
CN114730380A (en) | Deep parallel training of neural networks | |
US20240152809A1 (en) | Efficient machine learning model architecture selection | |
US20230376755A1 (en) | Training neural network systems to perform multiple machine learning tasks |