CN115244547A - Automatically and intelligently exploring design spaces - Google Patents
Automatically and intelligently exploring design spaces Download PDFInfo
- Publication number
- CN115244547A CN115244547A CN202180019805.9A CN202180019805A CN115244547A CN 115244547 A CN115244547 A CN 115244547A CN 202180019805 A CN202180019805 A CN 202180019805A CN 115244547 A CN115244547 A CN 115244547A
- Authority
- CN
- China
- Prior art keywords
- user
- design
- user device
- data
- information
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F30/00—Computer-aided design [CAD]
- G06F30/10—Geometric CAD
- G06F30/12—Geometric CAD characterised by design entry means specially adapted for CAD, e.g. graphical user interfaces [GUI] specially adapted for CAD
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F30/00—Computer-aided design [CAD]
- G06F30/20—Design optimisation, verification or simulation
- G06F30/27—Design optimisation, verification or simulation using machine learning, e.g. artificial intelligence, neural networks, support vector machines [SVM] or training a model
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/045—Combinations of networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/088—Non-supervised learning, e.g. competitive learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F2119/00—Details relating to the type or aim of the analysis or the optimisation
- G06F2119/12—Timing analysis or timing optimisation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/004—Artificial life, i.e. computing arrangements simulating life
- G06N3/006—Artificial life, i.e. computing arrangements simulating life based on simulated virtual individual or collective life forms, e.g. social simulations or particle swarm optimisation [PSO]
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/047—Probabilistic or stochastic networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/12—Computing arrangements based on biological models using genetic models
- G06N3/126—Evolutionary algorithms, e.g. genetic algorithms or genetic programming
Abstract
Methods, systems, and computer-readable media include receiving a request for digital components from a user device, receiving a dataset of user-provided information about a particular product design, generating a visual representation that maps design factors to potential product design geometries based on the dataset, segmenting the visual representation based on design factor values, selecting a segment that contains less than a threshold number of data points, selecting a digital component, dynamically changing presentation of the digital component that solicits information about the segment to a user based on the selected segment, distributing the dynamically changing digital component for presentation at the user device, obtaining feedback information from the user device about the segment that contains less than the threshold number of data points through a feedback mechanism, and modifying the design factors for the particular product design based at least in part on the feedback information.
Description
Cross Reference to Related Applications
This application claims benefit of U.S. application No.16/943,126, filed on 30/7/2020 and U.S. provisional application No.63/010,438, filed on 15/4/2020, the contents of which are incorporated herein by reference.
Technical Field
This document relates to providing a data collection and model generation process that continuously reduces the bias introduced by using data points from non-uniformly distributed or non-representative populations and explores the design space.
Disclosure of Invention
In general, one innovative aspect of the subject matter described in this specification can be embodied in methods for generating a new product design that include receiving a request from a user device for digital components presented on the user device, receiving a data set of user-provided information about a particular product design, generating a visual representation that maps design factors to continuous shapes representing potential product design geometries based on the data set of user-provided information, segmenting the visual representation into a plurality of segments based on design factor values, selecting segments of the visual representation that contain less than a threshold number of data points, selecting digital components that solicit information from a user, dynamically changing presentation of digital components that solicit information from the user about segments of the visual representation that contain less than the threshold number of data points based on the selected segments of the visual representation, distributing the dynamically changing digital components for presentation at the user device, obtaining feedback information from the user device and through a feedback mechanism about segments of the visual representation that contain less than the threshold number of data points, modifying the design factors of the particular product design based at least in part on the feedback information obtained from the user to create a modified product design factor for the particular product design.
These and other embodiments can each optionally include one or more of the following features.
In some implementations, the method includes selecting a format of the solicitation information for a particular content item soliciting information from the user, and verifying the information solicited from the particular content item of the user soliciting information based on the selected segment of the visual representation. In some embodiments, selecting the format of the solicitation information includes selecting a particular feedback mechanism provided with the dynamically changing numeric components.
In some implementations, the method includes determining that a user of the user device is in the first user group based on a request for digital components presented at the user device, wherein the request for digital components presented at the user device indicates user demographic information of the user device. The method can include receiving, from a second user device, a request for a digital component for presentation at the second user device indicating user demographic information of a user of the second user device, determining, based on the request for the digital component for presentation at the second user device, that the user of the second user device is in a same first user group as the user of the user device, and providing, in response to determining that the user of the second user device is in the same first user group as the user of the user device, a modified product design instead of the particular product design.
In some implementations, segmenting the visual representation into a plurality of segments based on the design factor value includes dividing the visual representation into a plurality of segments based on the design factor value such that each segment of the visual representation shares a design factor value within a defined range of values.
The user interface elements can be elements such as images of a product or brand, audio or video representations, feedback mechanisms, the subject of a task, and/or the wording of a task. For example, the data quality processor 120 can determine that the user of the user device 106 is in a group of users interested in product design for a handbag, and identify the visual theme of the task to be changed. In some implementations, the data processor 120 can change the user element by replacing the user element. In some embodiments, the data processor 120 can change the user element by modifying the element. For example, the data quality processor 120 can change the visual theme of the task by adding elements specific to the particular product design that the user has determined is of interest, including logos for particular brands of handbags, color schemes reminiscent of particular brands of handbags, audio tracks used by particular brands of handbags, and other elements.
In some implementations, dynamically changing presentation of the digital component includes determining that a user of the user device is in a first user group based on a request for the digital component for presentation at the user device, wherein the request for the digital component for presentation at the user device contains information indicative of one or more attributes of the user, identifying a user interface element of the digital component based on determining that the user of the user device is in the first user group, and changing the presented user interface element of the digital component.
In some implementations, mapping the design factor to the visual representation of the continuous shape representing the potential product design geometry is reversible such that generating the visual representation of the design factor mapped to the continuous shape representing the potential product design geometry based on the dataset of user-provided information includes generating the visual representation by mapping the potential product design geometry to the design factor.
In some embodiments, the method includes identifying a closest existing product design from a plurality of existing product designs based on the modified product design and having a plurality of design factor values in common with the modified product design.
In some embodiments, the method includes providing the modified product design to the integrated manufacturing system.
In some embodiments, the method includes constructing a behavioral model that predicts acceptance of the potential product design geometry by the user based on the feedback information, wherein modifying the design factor for the particular product design is based at least in part on the behavioral model.
In some embodiments, the particular product design is a user interface design of a software application.
In some implementations, dynamically changing the presentation of the content item includes using machine learning or artificial intelligence techniques to specify the information requested by the digital component.
Other embodiments of this aspect include corresponding systems, apparatus, and computer programs, configured to perform the actions of the methods, and encoded on computer storage devices.
Particular embodiments of the subject matter described in this document can be implemented to realize one or more of the following advantages. In certain circumstances, there has been no previous way to automatically and systematically reduce bias in data sets that are not representative of a population or are determined to lack data in a particular segment, and this shortcoming is addressed by the techniques, devices, and systems discussed herein.
In some embodiments of the new system, segments of the population for which data is collected that are not adequately represented are identified and tasks are generated for distribution to users in those segments. These tasks solicit responses from the user regarding a particular topic or domain, such that these responses supplement the existing data set. For example, the system can determine that the response from a user within a particular age range for a preferred selection between two products is less than a threshold amount, and then generate a task to distribute to users within that age range that asks the user to select between the two products. These responses are received and processed by the system as a supplement to the existing data set, thereby improving data quality. The system continuously monitors the data set, providing a solution that automatically maintains data quality even as the data set is updated.
The new system has access to a complex data processing infrastructure that cleans up, processes and maintains a comprehensive set of tagged searchable data that can be used in many different situations to improve the results of the model, while no previous solution has automatically improved data quality and maintained data quality as more data is collected. If the model uses an incomplete or unrepresentative data set, the model can produce results that are not representative of the actual behavior of the population: the new system automatically supplements the data set from which the model is extracted, thereby improving the robustness of the data and the accuracy of the model results. By automatically identifying population segments that are under-or not representative of the data, the system reduces bias in the data sets used as inputs to the various models. These more robust data sets in turn improve the reliability and accuracy of the results of the model that relies on these data. The improved data sets can be tagged and used by different aspects, including content providers and product manufacturers who may not have a system-maintained infrastructure of tagging and searchable data sets or access to these data sets.
In addition to improving the data set, the system can automatically explore the design space. The design space is a conceptual representation of design values and can be referred to as a continuous shape. The design space can be associated with a particular product or service and can be multidimensional, representing possible design values for a parameter of interest. In some implementations, the design space can be expanded to map design parameters to semantic values. For example, the system can create a model using a mapping of semantic attributes and geometric features of the product; these models exist in a single continuous shape space that represents a range of possible attribute values. The design can be based on one or more sensory characteristics. For example, the design can be visual, auditory, tactile, odor-based, or taste-based. For example, the design of a car seat may include visual and tactile features.
The new system is able to automatically explore a design space by identifying skews in the design space where little or no data exists and generating tasks for the identified segments to be distributed to users. By collecting data for these segments, the system allows previously unexplored designs to be taken into account. For example, the system can automatically generate a design with parameter values that have not been presented to the user for feedback. Based on the received feedback, the system can continually update existing designs and generate new designs that the user is solicited for feedback prior to the prototyping, manufacturing, and distribution stages. The feedback can be provided as input to an output such as a model of user preference prediction. The system is capable of determining directions to guide product design based on data analysis and the output of behavioral models, and allows content providers, product designers, and manufacturers to focus on designs that are most likely to be accepted by a target consumer group. In other words, the improved update process can reduce the number of feedback cycles required to complete a product design, thereby reducing the computational resources required for the entire design cycle from initial data collection to complete the design.
Utilizing this method allows for rapid design development of products to more accurately and reliably meet consumer needs and expectations of different populations. In addition, the improved update process provides for high efficiency in designing the system by improving data quality and reducing the number of feedback cycles required to collect user data for input to the behavioral model. The present system provides product designers, developers, and manufacturers with a way to quickly receive a variety of feedback on a global basis and determine user preferences from demographic data prior to the manufacturing and shipping stages, which requires significant resource investment. The method may allow personalized design and manufacture for an individual or group of users. For example, a manufacturer can use this method to review personal preferences to measure acceptance statistics for a larger market.
The techniques described in this document enable a system to generate high quality data related to a particular product or service using fewer resources and performing fewer operations. By automatically detecting and reducing deviations in the data set, the system enables models using the data to provide more accurate and reliable results. Furthermore, the system reduces the amount of resources required to complete a new product or new service design by allowing targeted exploration of design space and continued improvement in data quality.
The details of one or more embodiments of the subject matter described in this specification are set forth in the accompanying drawings and the description below. Other features, aspects, and advantages of the subject matter will become apparent from the description, the drawings, and the claims.
Drawings
FIG. 1 is a block diagram of an example environment for data quality improvement and design space exploration.
Fig. 2A illustrates an example data flow for a data quality improvement process.
Fig. 2B and 2C depict the model training process.
Fig. 3 shows an example data flow of a data quality improvement process.
FIG. 4 illustrates design space exploration example data flow of a process.
Fig. 5A and 5B depict data flows for a specific example, where the system generates tasks for a user using a behavior model.
Fig. 6A and 6B depict data flows for a specific example of a system integrating user feedback into a design cycle.
Fig. 7A and 7B depict data flows for a specific example, where the system implements user feedback to customize existing designs and products.
Fig. 7C-7F depict specific examples of the system implementing user feedback into a design cycle.
Fig. 8 is a flow diagram of an example process for data quality improvement.
FIG. 9 is a flow diagram of an example process for automated design space exploration.
FIG. 10 is a block diagram of an example computing system.
Like reference numbers and designations in the various drawings indicate like elements.
Detailed Description
Methods, systems, and devices are described herein that improve data quality, reduce inherent biases, and allow for automatic, intelligent design space exploration. The accuracy and representativeness of the population of the model depends on the input data provided to the model. The proposed system improves the quality of data that can be provided to various systems for modeling and product development. User feedback data and behavioral data can be collected in various ways.
In some embodiments, the system generates tasks for distribution to users. Each task can be a question, task, or other form of user input solicitation. The user's input can be tagged and used as part of a comprehensive database that can be used in different contexts. For example, a user can be presented with a task to be completed in which the user must select a single logo design from a plurality of logo designs that appears most appealing. The user's selections can then be tagged with the user's demographic information and stored as part of a tagged searchable database. The system can determine that data from a particular user demographic or about a particular product segment is missing, deficient, or not representative of a known population based on an analysis of the labeled data set, and automatically generate tasks or questions to collect more data and reduce inherent bias in the non-representative data set. The supplemented tagged data set can be provided as input to various models. For example, the labeled data sets can be provided to a behavioral model to predict whether a particular design will appeal to a particular user population. Various models can be used to predict a user's reaction to and acceptance of, for example, a particular design.
The system also allows for the automatic and intelligent exploration of a particular design space. For example, based on analysis of the labeled data set, the system can determine that data about a particular region of the design space is missing, insufficient, not representative of a known population, and automatically generate tasks or questions to collect more data. The system is capable of exploring a design space by generating a product design based on unexplored regions of the design space using artificial intelligence and machine learning models. These manually generated designs can then be presented to the user along with the task of soliciting feedback.
FIG. 1 is a block diagram of an example environment 100 for data quality improvement and design space exploration. The example environment 100 includes a network 102, such as a Local Area Network (LAN), a Wide Area Network (WAN), the Internet, or a combination thereof. Network 102 connects electronic document server 104 ("electronic document server"), user devices 106, and digital component distribution system 110 (also referred to as DCDS 110). The example environment 100 may include many different electronic document servers 104 and user devices 106.
The user device 106 is an electronic device capable of requesting and receiving resources (e.g., electronic documents) over the network 102. Example user devices 106 include personal computers, mobile communication devices, and other devices capable of sending and receiving data over the network 102. The user device 106 typically includes a user application, such as a web browser, to facilitate sending and receiving data over the network 102, although a native application executed by the user device 106 can also facilitate sending and receiving data over the network 102.
One or more third parties 140 include content providers, product designers, product manufacturers, and other parties involved in the design, development, manufacture, marketing, or distribution of a product or service.
An electronic document is data that presents a set of content at a user device 106. Examples of electronic documents include web pages, word processing documents, portable Document Format (PDF) documents, images, videos, search result pages, and feed sources. Native applications (e.g., "applications"), such as applications installed on mobile, tablet, or desktop computing devices, are also examples of electronic documents. Electronic documents 105 ("electronic documents") can be provided by the electronic document server 104 to the user devices 106. For example, the electronic document server 104 can include a server hosting a publisher's website. In this example, the user device 106 can initiate a request for a given publisher web page, and the electronic document server 104 hosting the given publisher web page can respond to the request by sending machine hypertext markup language (HTML) code that initiates presentation of the given web page at the user device 106.
The electronic document can include various contents. For example, the electronic document 105 can include static content (e.g., text or other specified content) within the electronic document itself and/or that does not change over time. The electronic document can also include dynamic content that can change over time or on a per-request basis. For example, a publisher of a given electronic document can maintain a data source for populating portions of the electronic document. In this example, the given electronic document can include a tag or script that causes the user device 106 to request content from the data source when the user device 106 processes (e.g., renders or executes) the given electronic document. The user device 106 integrates content obtained from the data sources into the presentation of a given electronic document to create a composite electronic document that includes the content obtained from the data sources.
In some cases, a given electronic document can include a digital content tag or digital content script that references the DCDS 110. In these cases, the user device 106 executes the digital content tag or digital content script when the user device 106 processes a given electronic document. Execution of the digital content tag or digital content script configures the user device 106 to generate a request 108 for digital content, the request 108 being transmitted over the network 102 to the DCDS 110. For example, a digital content tag or digital content script can enable the user device 106 to generate a packetized data request including a header and payload data. The request 108 can include data such as the name (or network location) of the server from which the digital content is requested, the name (or network location) of the requesting device (e.g., user device 106), and/or information that the DCDS110 can use to select the digital content to provide in response to the request. The user equipment 106 transmits the request 108 to a server of the DCDS110 over the network 102 (e.g., a telecommunications network).
The request 108 can include data specifying characteristics of the electronic document and the location where the digital content can be rendered. For example, data specifying a reference (e.g., a URL) to an electronic document (e.g., a web page) that will present the digital content, available locations of the electronic document (e.g., a digital content slot) that are available for presenting the digital content, sizes of the available locations, locations of the available locations in the presentation of the electronic document, and/or media types that are eligible for presentation in those locations can be provided to the DCDS 110. Similarly, data specifying keywords designated as keywords for selecting an electronic document ("document keywords") or entities referenced by the electronic document (e.g., people, places, or things) can also be included in the request 108 (e.g., as payload data) and provided to the DCDS110 to facilitate identifying digital content items that are eligible for presentation with the electronic document.
The request 108 can also include data related to other information, such as information that the user has provided, geographic information indicating the state or region in which the request was submitted, or other information that provides context for the environment in which the digital content is to be displayed (e.g., the type of device, such as a mobile device or tablet device, on which the digital content is to be displayed). The user-provided information can include demographic data of the user device 106. For example, demographic information can include characteristics of age, gender, geographic location, education level, marital status, household income, occupation, hobbies, social media data, and whether a user owns a particular project.
For the case where the system discussed herein collects or may make use of personal information about a user, the user may be provided with an opportunity to control whether programs or features collect personal information (e.g., information about the user's social network, social actions or activities, profession, the user's preferences, or the user's current location), or whether and/or how to receive content from a content server that may be more relevant to the user. In addition, certain data may be anonymized in one or more ways before it is stored or used, thereby removing personally identifiable information. For example, the identity of the user may be anonymized such that identity information of the user cannot be determined, or the geographic location of the user may be generalized (e.g., at a city, zip code, or state level) such that a particular location of the user cannot be determined in the case where location information is obtained. Thus, the user can control how the content server collects and uses information about him or her.
Data specifying characteristics of the user device 106 can also be provided in the request 108, such as information identifying a model of the user device 106, a configuration of the user device 106, or a size (e.g., a physical size or resolution) of an electronic display (e.g., a touchscreen or desktop monitor) presenting the electronic document. The request 108 can be transmitted over a packet network, for example, and the request 108 itself can be formatted as packet data having a header and payload data. The header can specify the destination of the packet and the payload data can include any of the information discussed above.
In response to receiving the request 108 and/or using information included in the request 108, the DCDS110 selects digital content to be presented with the given electronic document. In some implementations, the DCDS110 is implemented in a distributed computing system (or environment) that includes, for example, a server and a set of multiple computing devices that are interconnected and that identify and distribute digital content in response to requests 108. The set of multiple computing devices operate together to identify a set of digital content that is eligible for presentation in an electronic document from a corpus of millions or more of available digital content. For example, millions or more of available digital content can be indexed in the digital component database 112. Each digital content index entry can reference corresponding digital content and/or include distribution parameters (e.g., selection criteria) that regulate distribution of the corresponding digital content.
In some implementations, the digital components from the digital component database 112 can include content provided by a third party 140. For example, the digital component database 112 can receive photographs of public intersections from third parties 140 that use machine learning and/or artificial intelligence to navigate public streets. In another example, the digital component parts database 112 can receive specific questions from third parties 140 that provide services to the cyclist that the third parties 140 wish the user to respond to.
The identification of eligible digital content can be segmented into a plurality of tasks, which are then distributed among the computing devices in the set of multiple computing devices. For example, different computing devices of the set of multiple computing devices can each analyze different portions of the digital component database 112 to identify various digital content having distribution parameters that match the information included in the request 108.
The DCDS110 aggregates the results received from the set of multiple computing devices and uses information associated with the aggregated results to select one or more instances of digital content to be provided in response to the request 108. In turn, the DCDS110 can generate and transmit reply data 114 (e.g., digital data representing a reply) over the network 102, the reply data 114 enabling the user device 106 to integrate the selected set of digital content into a given electronic document such that the selected set of digital content is presented on the display of the user device 106 along with the content of the electronic document. The digital content distributed by the DCDS110 and represented by the reply data 114 can include, for example, digital content solicited for user input. The input can be analyzed, tagged, and stored as part of an integrated database, such as tag database 130. The tag database 130 stores tag data that has been analyzed and classified. The tag database 130 can be searched and can store data related to the user, including user demographic information, user response data, and other user characteristics. For example, the tagging database 130 can store anonymous demographic information for a user and associate it with the user's response to questions previously presented to the user. Input from the user is transmitted from the user device 106 to the data quality processor 120 as response data 116.
The data quality processor 120 generates digital content that solicits user input, receives and processes user input data, and generates and modifies design space and designs. The data quality processor 120 includes a task processor 122, a data processor 124, and a model generator 126. The task processor 122 generates tasks to be distributed to users. The data processor 124 analyzes and labels the input received in response to the task. Model generator 126 generates and modifies design spaces and designs based on markup data and input from third parties, such as content providers, product designers, and manufacturers. For ease of explanation, the task processor 122, the data processor 124, and the model generator 126 are shown in fig. 1 as separate components of the data quality processor 120. Data quality processor 120 can be implemented as a single system on a computer-readable medium, which may be non-transitory. In some embodiments, one or more of the task processor 122, the data processor 124, and the model generator 126 may be implemented as integrated components of a single system.
The task processor 122 creates digital content that solicits input from the user or task. The task processor 122 communicates with the DCDS110, the electronic document server 104, and the third party 140. The data quality processor 120 can collect data from tasks published directly by the task processor 122 or from tasks published by a third party, such as third party 140, which provides the data quality processor 120 with access to its data sources. Tasks can include content requiring different levels of interaction, from activities requiring the user to draw a picture, to questions requiring the user to select only answers, to single-click activities requiring the user to grant the system access to the user's data. In some implementations, the task can include requesting the user to answer an input question. For example, the task presented to the user can include the question "do you like chocolate or vanilla ice cream? "and the user can input their answers or select from pre-selected answers. In some implementations, the tasks can include activities that require more participation by the user. For example, a task presented to a user can ask the user to select one or more portions of an image of a traffic intersection that includes a bicycle, and the user can click on or otherwise indicate the appropriate portion. In some implementations, the task can include an authentication protocol challenge, such as a CAPTCHA or a reactcha.
In addition to generating tasks for presentation to the user, the task processor 122 can also modify the tasks. For example, the task processor 122 can modify a task that has been previously provided to one or more users, and modify the task to collect different data, ask more targeted questions, or otherwise change the direction of the task. The task processor 122 and its output will be described in further detail below.
The data processor 124 receives and processes the data to identify missing, inaccurate, underrepresented, or unrepresentative data, and automatically determines a data quality improvement solution. The data processor 124 analyzes a particular data set and determines whether existing data meets a quality threshold based on design guidelines and other inputs. The data processor 124 can process response data received from the user equipment and existing response data. For example, the data processor 124 can determine whether the existing user response data stored in the signature database 130 for a particular camping backpack design includes a representative number of responses from consumers of that age by determining the ratio of responses received from consumers of 45 to 54 years of age to responses received from consumers of other ages and comparing the existing ratio to an expected or actual ratio for the target market for the camping backpack. The data processor 124 can also determine whether design values within the design space have been explored, or whether there is sufficient data about those values. For example, the data processor 124 can determine whether a trackpad of a particular size on a laptop has received a sufficient number of user responses by comparing an existing number of user responses to a threshold number of user responses.
The data processor 124 is also capable of receiving and extracting data collected from the digital content distribution process. For example, the data analyzer 124 can receive the request data 108 and the reply data 114 to determine the population and characteristics of the users represented by the cookies indicated in the request data 108 and the reply data 114. The data analyzer 124 can store demographic and other characteristic data in a database, such as the signature database 130. In some implementations, the data analyzer 124 can retrieve data from the tag database 130 that has been analyzed and tagged by other systems. The data analyzer 124 can, for example, retrieve data from the tag database 130 that indicates demographic data of the user providing the request data 108 and receiving the reply data 114. The data processor 124 can segment the data, for example, based on user demographic information. The data processor 124 and its output will be described in further detail below.
In addition to the above, a user may be provided with controls that allow the user to select whether and when the systems, programs, or features described herein are capable of collecting user information (e.g., information about the user's social network, social actions or activities, profession, the user's preferences, or the user's current location), and whether to send content or communications to the user from a server. In addition, some data may be processed in one or more ways to remove personal identity information before it is stored or used. For example, the identity of the user may be processed such that no personal identity information of the user can be determined, or the geographic location of the user (e.g., city, zip code, or state level) may be summarized where location information is obtained such that no particular location of the user can be determined. Thus, the user may have control over what information is collected about the user, how the information is used, and what information is provided to the user.
The output of such a model can range from a particular design to a predicted user response to the particular design. The model generator 126 and its output will be described in further detail below.
The techniques described below enable the system to continuously and automatically improve data quality and explore design space.
Fig. 2A illustrates an example data flow 200 of a data quality improvement process in the example environment of fig. 1. The operations of data flow 200 are performed by various components of system 100. For example, the operations of the data flow 200 can be performed by the data quality processor 120 in communication with the DCDS110, the user equipment 106, the third party 140, and the indicia database 130.
The flow begins at step a where the data processor 124 of the data quality processor 120 analyzes and segments the data set associated with the user population. In some embodiments, the data set is existing data retrieved from the tag database 130. For example, the data set can include a set of user inputs in response to a reachctcha that requires a user to select all squares from a photographic grid that show a portion of a type of vehicle, such as a bicycle. In another example, the data set can include a set of user inputs in response to questions asking the user how much they spend on dog food, typically monthly. The user input can be associated with user characteristic data of a user providing the input. For example, user characteristic data can include demographic data and browsing history, as well as other data that the system 100 has access to and that the system 100 has usage rights. In another example, the data set can include a set of user inputs that are responsive to a question asking users to rate their likelihood of purchasing a particular handbag product design within a range of handbag designs mapped to subjective descriptors such as "utility" or "fashion".
The data processor 124 segments the data based on various parameters including user characteristic data. For example, the data processor 124 can divide the data set into segments based on the user's age, user location, and/or user interests, as well as other user characteristic data that the system 100 has access to and that the system 100 has usage rights. In another example, the data processor 124 can segment the data based on characteristics of the data itself. For example, the data processor 124 can partition the data set based on the values of certain subjective factors of the product design, such as how "fashion" the handbag product design is perceived based on feedback provided by the user.
Flow continues to step B where the data processor 124 identifies deficient segments of the data set based on one or more metrics. In some embodiments, the metrics are provided by a third party 140, such as a product designer. For example, the metric can be the number of user responses and target demographic information of the responding users. In some embodiments, the metric is automatically determined. For example, the metric can be a threshold difference in population proportion of responding users, where a data set with a population proportion difference greater than the threshold difference may be deemed not to represent an actual population soliciting a response. In one example, the data processor 124 can identify bicycle detection segments in the vehicle detection set as being undersized.
The flow continues to step C where the task processor 122 dynamically changes the task to be presented to the user based on the identified segment. In some implementations, the task processor 122 dynamically changes existing tasks that have been previously generated and/or presented to the user. In some implementations, the task processor 122 generates entirely new tasks to present to the user. The task processor 122 can perform this change in real-time in response to identifying the segment. For example, the data quality processor 120 can continuously monitor the quality of the data set and update its metrics based on the new and updated information received.
In one example, the task processor 122 automatically changes one aspect of the previously distributed task that requires the user to select all squares that contain a portion of a bicycle by modifying the grid system to use smaller squares to provide better resolution. In step B, the data processor 124 automatically determines that greater granularity is needed and, using this information, the task processor 122 can divide the intersection photograph with the bicycle into smaller squares.
The data quality processor 120 automatically modifies or generates new tasks based on analysis of existing data sets and performs additional operations that facilitate generating tasks. For example, the data quality processor 120 can determine that the modified task includes providing the user with photo data of an intersection with a bicycle in the field of view. The data processor 122 can receive specific photo data for an intersection from the third party 140. The data processor 122 is also capable of automatically retrieving data to be provided as part of a task. For example, the data processor 122 can retrieve photo data for a public intersection marked as having at least one bicycle in view from, for example, the marking database 130. The data processor 122 can then perform data cleansing operations, including erasing the data of the personal identity information, cleansing the data, and adjusting the data so that the data is available, among other operations. For example, the data processor 122 can adjust the live photo stream from a street camera aimed at a public intersection by filtering out images that do not include bicycles in the field of view, adjusting the lighting, and creating a larger dynamic range in the images. The data processor 122 is capable of performing complex data processing operations including removing objects that obstruct another object and enhancing the focus of a particular object, among other operations.
The task processor 122 can also determine, based on the identified segments, one or more distribution parameters that must be met before distributing the task. The distribution parameters can include user characteristics that the user must have in order to accept the task. For example, the distribution parameters can include specific demographic information for women living between 18 and 24 years of age on the west coast of the united states.
The task processor 122 can change the task to sample an existing or new region of space for an image, video or audio object within the tag database 130, for example. The task processor 122 can also test the removal or addition of brand information to assess, for example, a user's reaction to a brand or a user bias.
The flow continues to step D where the task processor 122 transmits the dynamically changed or generated task to the DCDS110 for distribution to the user. For example, the task processor 122 can transmit task data that indicates tasks to be presented to the user and content to be presented to the user as part of the tasks. The task processor 122 can include distribution parameters that must be satisfied in order to distribute the task to a particular user. For example, the task processor 122 can include demographic data of the target user to whom the task can be presented.
The flow continues to step E where the DCDS110 receives a request 108 for content from the user device 106. When the client device interacts with the digital content, the request 108 is transmitted by the user device 106 to the DCDS 110. For example, if the user of the user device 106 clicks on a link to download a shopping application, the link can cause the user device 106 to transmit the request 108 to the DCDS 110. The request 108 can include interaction tracking data from the client device 106. For example, the request 108 can include tracking data, such as an indication of the interaction, the digital content with which the user device 106 interacted, and an identifier that uniquely identifies the user device 106. In some implementations, the request 108 includes an indication of the digital content provider and the location of the destination server hosting the requested resource.
The flow continues to step F where the DCDS110 transmits reply data 114 to the user equipment 106. As described above, reply data 114 can indicate tasks to be distributed to users that satisfy particular distribution parameters in addition to the requested electronic document. In response to the DCDS110 receiving the request 108 and determining that the distribution parameters are satisfied based on the received distribution parameters and the user data indicated in the request 108, the DCDS110 transmits reply data 114 to the user equipment 106. For example, the DCDS110 can determine, based on the received request data 108, that the user of the user device 106 is a 22 year old female living in oregon, and thus satisfies the distribution parameters. The DCDS110 can then transmit the requested electronic document and the dynamically changing task to the user device 106 in the form of reply data 114.
The flow continues to step G where the DCDS110 receives response data 116 from the user equipment 106. In response to the user of the user device 106 completing the task provided in the reply data 114, the user device 106 transmits the response data 116 to the DCDS 110. The response data 116 includes user information, such as demographic data, device data, information about user responses, and includes user input in response to tasks provided in the reply data 114. For example, the response data 116 can include a user's selection of a square containing a portion of a bicycle, the amount of time the user spends making the selection, her mouse movement pattern, and her anonymous demographic data, device data, and browsing history, all of which she is allowed to access by the system 100. The response data can include semantic descriptors provided by the user regarding the task, product, or design. The semantic descriptors can include any descriptors that provide semantic information about an object, such as a product or design. Semantic descriptors can be generated by human or artificial intelligence and can take the form of words (e.g., keywords or key phrases), sentences, symbols, or other descriptors that convey semantic information. In addition, semantic descriptors can be assigned to objects based on other actions, such as interacting with presented information (e.g., photos or icons), interacting with rating elements (e.g., product rating tools), or submitting free-form textual feedback about the objects. The DCDS110 can then provide the data to the data processor 124 for analysis and tagging.
The flow continues to step H where the data processor 124 analyzes the response data 116 from the user device 106. The data processor 124 can analyze the response data 116 to classify the data and tag the data with information of the user so that the data becomes searchable. For example, the data processor 124 can label the square selected by the user with the user's demographic information, the amount of time she spent making the selection, and the accuracy of her selection (as compared to the set of true values for the square).
The flow continues to step I where the data quality processor 120 provides the analyzed data to the signature database 130. The data processor 124 can provide the tag data for storage in the tag database 130 so that the data is searchable.
The system 100 can continuously perform the process 200 such that the data quality processor 120 automatically and continuously monitors the quality of the data included in a particular data set. Thus, the system 100 maintains and improves the quality of the data in the integrated database 130, such that the accuracy and completeness of the model output results continues to increase. Because the system 100 continuously updates the tag database 130, the system provides a searchable database from which the system 100 can retrieve content, such as images, audio or video instances, based on user response information (such as results of tasks) and user information.
The system reduces bias in user feedback distribution by selectively soliciting additional feedback from user demographic information that is not represented at all or is not represented at all.
Fig. 2B and 2C depict the model training process. Server 250 maintains a baseline model 252 and a task repository 254. The baseline model 252 is a model that serves as a baseline behavior model and can be updated. Task repository 254 maintains a set of tasks that can be distributed to users.
Each of devices A260 a, B260B, \8230, and N260N (collectively referred to as devices 260) includes models A, B, \8230, N262 a, 262B, \8230, 262N (collectively referred to as models 262), respectively. Each of the locally maintained models 262 can be updated and refined based on the tasks and model updates provided by the server 250.
Each device 260n receives input from, displays information to, and is controllable by a user 270a, 270b, \8230; 270n (collectively referred to as users 270). For example, the device 260 can provide tasks as described above to each user 270. Tasks can be provided from, for example, task repository 254. In response to the task, each user 270 can provide semantic mappings 272a, 272b, \8230; 272n (collectively semantic mappings 272) to device 260. Based on the response provided by the user 270, the device 260 can update the model 262.
In fig. 2C, model training module 256 can generate an updated baseline model 258 based on information from the response provided by user 270 and provide updated baseline model 258 to server 250 to replace or update baseline model 252.
Fig. 3 illustrates an example design space 300. The design space 300 is a visual representation of the conceptual world of possible design values. The design space 300 can be generated by a system, such as the system 100 shown in FIG. 1. For example, model generator 126 of data quality processor 120 can generate design space 300 based on user response data from indicia database 130.
The design space 300 can be multi-dimensional. In this particular example, design space 300 includes two dimensions and is generated as a result of data submitted by a user in response to questions asking the user to rate various package designs. In other examples, the design space 300 can include more than two dimensions and can be represented as a three-dimensional or multi-dimensional model. The dimensions include design features such as shape, color, texture, size, or relative distance from another object.
By automatically generating and modifying the design space 300, the new system reduces the amount of time and resources used to arrive at the final design. The system can focus design exploration in areas that are most likely to be productive according to metrics specified by interested third parties. For example, the data quality processor 120 can automatically focus the design exploration of the package design on areas that consumers (third party package designers and targeted populations of manufacturers 140) are most likely to purchase between the ages of 25 and 34. The data quality processor 120 is able to focus the request for user response data on the package design indicated as being of most interest to the surveyed user in the age range of 25-34 by automatically generating package shapes and designs that fall within the design space 300 that is most likely to be of interest to the user.
In this particular example, the design space 300 maps semantic attributes to geometric features of the design that fall within the space. For example, the design space 300 maps semantic attributes "utility" and "fashion" to specific shapes and forms of package designs, including package designs 302 and 304. These semantic attributes are subjective factors that represent specific qualitative design goals and demographic information. Based on the user response data 306 and 308 from the tag database 130, the data quality processor 120 has determined that the user is most interested in packages that mix "practical" and "fashion" factors. In this particular example, the data processor 124 of the data quality processor 120 has analyzed the user response data from the signature database 130 and determined that there is a great interest in packages that are more "practical" and at least somewhat "fashionable". Using this determination, model generator 126 can limit design space 300 to "practical" bag designs that focus on "fashion" exceeding some threshold amount and some other threshold amount. In some implementations, model generator 126 can automatically generate a design that satisfies these design criteria without further input from the designer. In some embodiments, model generator 126 is capable of generating a package design that meets "fashion" and "utility" thresholds that have not been previously generated. For example, the model generator 126 can generate package designs 312 and 314 without input from the third party package designer 140, and the designs 312 and 314 can be new, previously unknown package designs.
In some implementations, a probabilistic model can be used that defines a probabilistic ranking of attributes for a given product design or shape, or a probabilistic ranking of product designs or shapes given one or more attributes.
In some implementations, the model generator 126 can use machine learning to determine an objective function for a particular user based on subjective feedback from the user. The objective function can be simple and implement general modifications to the product design. As the system 100 collects user response data, the system 100 anonymizes the data and provides the data to a central database that stores and analyzes the collected data to improve the general behavioral model and allow the system 100 to provide more personalized policies for each user 102.
For example, the system 100 can utilize a general profile of a user of a particular age, location, interest, and the like. The system 100 can summarize support configurations across users predicted to have similar interests. In some implementations, the system 100 accepts input from the user's profile information, such as the user's age, location, and interests, among other parameters.
The system 100 can utilize, for example, a "shoe size" model that is personalized to some degree. For example, the system 110 can use general profiles of people of a particular age group, people in new york, people who like motorcycles, and so forth. For example, if multiple users indicate similar preferences, the system 100 can determine if there are matching products. If a matching product exists, the system 100 can return the product to the user. If a matching product does not exist, the system 100 can modify an existing product design or generate a new design. In some embodiments, the system 100 can perform aggregated personalization or clustering by mapping particular users to existing user groups or user segments or forming new user groups or user segments. The system 100 can also be used to identify products or purchasing trends in a particular user. In some implementations, the system 100 can perform aggregated configuration clustering by mapping users to existing customer segments or products or mapping user preferences to existing feature sets.
Furthermore, each model may be personalized. For example, each model can be created from a generic model by varying the model parameters based on the characteristics of each user determined from the collected data. Each model can change over long and short periods of time for a particular user. For example, the system 100 can track how interesting a user is with respect to a particular design element and adjust the behavioral model when it is determined that the user has lost interest. In some embodiments, each model can also be created from models that have been personalized using a generic profile and further changed for each user. For example, a model can be created by changing the model parameters based on the characteristics of each user determined from the collected data.
In some embodiments, the model can be personalized without using a base model. For example, user response data can be input to model generator 126 and provided to a product designer, manufacturer, or design program to map to a product configuration that is not adjusted. In one example, model generator 126 allows a user to immediately purchase a particular item, or set an alert when a particular item is available.
FIG. 4 illustrates an example data flow 400 for a design space exploration process in the example environment of FIG. 1. The operations of data flow 400 are performed by various components of system 100. For example, the operations of the data flow 400 can be performed by the data quality processor 120 in communication with the DCDS110, the user device 106, the third party 140, and the indicia database 130.
The flow begins at step a, where the data processor 124 of the data quality processor 120 analyzes and segments the data set associated with the user population. In some embodiments, the data set is existing data retrieved from the tag database 130. For example, the data set can include a response of a group of users to a question that requires the user to rate two different package designs in a sliding scale relative to two semantic descriptors. The user input can be associated with user characteristic data of the user providing the input. For example, user characteristic data can include demographic data and browsing history, as well as other data that the system 100 can access and have rights to.
Flow continues to step B where the data processor 124 identifies an insufficient segment of the data set based on one or more metrics. Details of this step can be found in the description of fig. 2A above with respect to step B.
The flow continues to step C where model generator 126 generates a design space. As described above with respect to fig. 3, the design space is a visual representation of the universe of possible designs. In some embodiments, model generator 126 simply updates the existing design space provided by third party 140. For example, the model generator 126 can receive the design space from the third party package designer 140 and update the design space based on the data set.
The flow continues to step D where the data processor 124 determines one or more target segments of the design space using the behavioral model. For example, the data processor 124 uses the output of the behavioral model generated by the model generator 126 in step C to determine that a very "fashionable" but also very "practical" design has no threshold number of users' reactions to the design, or that no such design has been generated.
The flow continues to step E where the task processor 122 dynamically changes the task to be presented to the user based on the determined one or more segments. As described above with reference to FIG. 2A, the task processor 122 can change an existing task that has been previously generated and/or presented to the user, or generate an entirely new task to be presented to the user. For example, the task processor 122 can generate a new package design that is very "fashion" and very "practical" to present to the user for feedback.
In some embodiments, model generator 126 can display two or more product designs to allow a user to visualize differences or distortions between two or more product instances produced by a model.
In some embodiments, the model generator 126 can be integrated with a computer-aided design program, and the design of a product or service package can be improved, modified, or changed through the integrated program.
The flow continues to step F where the task processor 122 transmits the dynamically changed or generated task to the DCDS110 for distribution to the user. Details of this step can be found in the description of fig. 2A above with respect to step D.
The flow continues to step G where the DCDS110 receives a request 108 for content from the user equipment 106. Details of this step can be found in the description of fig. 2A above with respect to step E.
The flow continues to step H where the DCDS110 transmits reply data 114 to the user equipment 106. Details of this step can be found in the description of fig. 2A above with respect to step F.
The flow continues to step I where the DCDS110 receives response data 116 from the user equipment 106. Details of this step can be found in the description of fig. 2A above with respect to step G.
The flow continues to step J where the data processor 124 analyzes the response data 116 from the user device 106. Details of this step can be found in the description of fig. 2A above with respect to step H.
The flow continues to step K where the model generator 126 updates the design space and/or the behavioral model based on the analyzed response data from the user device 106. Model generator 126 can narrow or enlarge the design space based on feedback from the user. For example, model generator 126 can discard a portion of the design space that has been determined to have a threshold number or percentage of user responses and to have less than a threshold number of positive responses. The model generator 126 can update the behavioral model to reflect the updated data set. For example, model generator 126 can input the analyzed response data as input to train a behavioral model that predicts the user's acceptance of a particular package design.
The data quality processor 120 can also provide the analyzed data to the signature database 130. Model and design space updates can be performed concurrently with the data quality processor 120 transmitting the analyzed data to the signature database 130. In some embodiments, these portions of step K can be performed asynchronously.
The system described above with reference to fig. 1 and 3-4 automatically changes tasks to provide data quality improvements. In some implementations, the data quality processor 120 can alter tasks based on data that indicates particular characteristics, e.g., segments of the data itself, such as lack of consistent response to one or more types of designs, to different image locations, or to images having particular characteristics, among other factors. In some implementations, the data quality processor 120 can change tasks based on data that indicates, for example, particular characteristics in a user group, such as a particular user group spending an unusually short amount of time completing a task, or a lack of consistent response from a user group, among other factors. The system 100 automatically creates product designs based on consumer feedback and obtains further feedback regarding those designs, allowing innovative designs that meet consumer preferences and needs without the need to design and maintain a focal group. With more representative data, design improvements can be made at a faster rate. Furthermore, additional feedback can be used as input to, for example, a network that trains the behavior model to improve the classification of what constitutes a positive or negative example by the model.
Fig. 5A and 5B depict data flows in which the system uses a behavioral model to generate tasks for a user.
FIG. 5A depicts a data flow 500 in which the system has a user consent to personalize the tasks that the user receives in the example environment of FIG. 1. The operations of data flow 500 are performed by various components of system 100. For example, the operations of the data flow 400 can be performed by the data quality processor 120 in communication with the DCDS110, the user device 106, the third party 140, and the indicia database 130.
The flow 500 begins with an individual uploading one or more design primitives and/or semantic descriptors, such as keywords or ways of expressing user preferences, e.g., user clicks or text input (502). The uploaded data may provide information that allows humans to express preferences, semantic descriptions, or ratings, which may be mapped to a given design or more using visual or auditory elements or features of the product or service being designed. For example, a market researcher can provide the system 100 with the product design of a backpack and a set of keywords associated with the backpack, such as "sports," functionality, "" utility, "and" specialty. Design primitives can be used for a product or service and can include the design of physical products and digital products. In another example, a task can present a design, description, or feature to determine a value or price of a product or service. These designs and/or keywords can be stored in a database of product designs and keywords, for example. The person may also upload experimental plans that determine which design classes or instances should be displayed with which semantic descriptions. The experimental plan may also include statistical measures or other guiding criteria for how, when, or where a given design type and semantic description is displayed. In some embodiments, the designs and/or keywords can be stored in the numeric component database 112 and/or the tagging database 130.
The flow 500 continues with the system selecting a format of content to be provided to the user (504). For example, the DCDS110 of the system 100 can select a layout of content to be provided to the user. The layout can include, for example, the types of user interface elements available and the types of information provided. In one example, the DCDS110 can select a layout for the content that includes sliders and radio buttons for tasks to be provided to the user at the time of distribution. In another example, the format layout may include a reward that is provided to the user upon response by the user.
The flow 500 continues with the system preprocessing the data and verifying the correctness of the task to be provided to the user (506). For example, the task processor 122 and the data processor 124 of the data quality processor 120 can pre-process the data and verify the correctness of the task to be provided to the user based on the layout determined from (504).
The flow 500 continues with storing the pre-processed data and verified tasks to be provided to the user (508). In flow 500, the system 100 has user consent to provide personalized content, so the pre-processing data and verified tasks can be modified and/or personalized based on user information.
The flow 500 continues with the user of the website or application interacting with the content of the service (510). For example, the DCDS110 can select pre-processed data and validated tasks to be provided to a particular user of a website or application, as described above with respect to fig. 1, and receive user input from the user's interaction with the content of the service.
The process 500 continues with storing the user's response (512). For example, the DCDS110 can receive a response from the user that includes user information, such as user demographic data after the response data has been analyzed and processed by the data processor 124 of the data quality processor 120. The analyzed response data can be tagged by the data processor 124 and stored in the tag database 130.
The flow 500 continues with building one or more behavioral models based on the user response data (514). Examples of behavioral models include mapping a design, design features, design deformation, or graphic-based design representation to semantic descriptions or ratings using linear or non-linear function approximations (e.g., deep learning enabled convolutional neural networks). A reversible model may be used that allows mapping from input to output and vice versa, or multiple models can be used to map inputs to outputs and vice versa. The behavioral model may also include user demographic information stored with the given user's responses. For example, a model is created using task data that allows viewing of apparel design feedback for women living in london between the ages of 20 and 30. For example, the behavioral model may take user demographic information as input, or be probabilistic in nature, allowing the computer to adjust the model response for a given set of demographic parameters. For example, the model generator 126 of the data quality processor 120 can generate a behavioral model based on the user response data, as described above with respect to fig. 1-4. The model or model-based analysis may also include information or input from other sources, such as online surveys, pricing and conversion data, sales attribution models, topic clinics, and focal group feedback. The model or model-based analysis may also use pricing information obtained from the task feedback.
The flow 500 continues by analyzing and identifying new ideas and/or concepts based on one or more behavioral models (516). For example, the model generator 126 of the data quality processor 120 can analyze and identify new design ideas and/or new design concepts based on the output of the behavioral model.
The flow 500 continues with exploring and/or optimizing the design to generate new designs and/or keywords or semantic descriptors or preferences (518). For example, the model generator 126 of the data quality processor 120 can use the design space to explore and/or optimize a design to generate a new design or to modify an existing design. Model generator 126 can also generate new keywords associated with the design. For example, the model generator 126 can generate new keywords that are trending or popular in the current marketing material based on the generated behavioral model and have been displayed as popular with the user. The model can be used to generate a design from a semantic description or rating, and can be used to generate a semantic description or rating from a given design. The model can be used to explore or optimize the model space to identify new designs or semantic descriptions and include them in future tasks. An example can be seen in fig. 3, where the model space is shown as having a design positioned with respect to two axes associated with keywords (fashion and utility). In this example, a design 312 may be selected that optimizes a cost function of 60% utility and 40% fashion. One example includes the use of behavioral models, which include pricing feedback, derived safely from tasks where optimization can take into account design tradeoffs, cost, and pricing. These new designs and/or keywords are provided to a database of product designs and keywords referenced in (502). In some embodiments, the designs and/or keywords can be stored in the numeric component database 112 and/or the tagging database 130.
FIG. 5B depicts a data flow 550 in which the system has no user consent to personalize the tasks that the user receives in the example environment of FIG. 1. The operations of data flow 550 are performed by various components of system 100. For example, the operations of data flow 550 can be performed by data quality processor 120 in communication with DCDS110, user device 106, third party 140, and indicia database 130.
The process 550 follows the process 500. The process 550 begins with the customer uploading one or more design primitives and/or keywords (552). Details of this step can be found in the description of fig. 5A above with respect to (502).
The flow 550 continues with the system preprocessing the data and verifying the correctness of the task to be provided to the user (556). Details of this step can be found in the description of FIG. 5A above with respect to (506).
The process 550 continues by storing the pre-processed data and verified tasks to be provided to the user (558). In flow 550, the system 100 does not have user consent to provide personalized content, and thus neither the pre-processing data nor the verified task is modified or personalized based on the user information.
The flow 550 continues with the user of the website or application interacting with the content of the service (560). Details of this step can be found in the description of fig. 5A above with respect to (510).
The flow 550 continues with storing the user's response (562). For example, the DCDS110 can receive a user's response, which may include user information, such as user demographic data after the response data has been analyzed and processed by the data processor 124 of the data quality processor 120. If the user information is included, the DCDS110 can remove the user information. In some implementations, the user information is not provided because the system 100 does not have user consent to access the user information. The analyzed response data can be tagged by the data processor 124 and stored in the tagging database 130.
The flow 550 continues with building one or more behavioral models based on the user response data (564). Details of this step can be found in the description of fig. 5A above with respect to (514).
The flow 550 continues by analyzing and identifying new ideas and/or concepts based on one or more behavioral models (566). Details of this step can be found in the description of FIG. 5A above with respect to (516).
The flow 550 continues by exploring and/or optimizing the design to generate new designs and/or semantic descriptors (568). Details of this step can be found in the description of fig. 5A above with respect to (518).
Fig. 6A and 6B depict data flows in which the system integrates user feedback into the design cycle. Fig. 6A and 6B are built on the data flow shown in fig. 5A and 5B. In some implementations, the system 100 has user consent to personalize the content. In some implementations, the system 100 does not have the user consent to personalize the content.
FIG. 6A depicts a data flow 600 in which a system integrates user feedback into a design cycle, subject to designer input in the example environment of FIG. 1. The operations of data flow 600 are performed by various components of system 100. For example, the operations of the data flow 600 can be performed by the data quality processor 120 in communication with the DCDS110, the user device 106, the third party 140, and the indicia database 130.
The process 600 follows the process 500 or 550. Flow 600 begins with an individual selecting a task format and uploading design primitives and semantic descriptors (602). Details of this step can be found in the description of fig. 5A above with respect to (502) or fig. 5B with respect to (552). For example, a user can upload design drawing primitives or design shapes and associated keywords to a database. The database stores the initial product design shapes and keywords, as well as any updates based on the user's responses to the viewing tasks. For example, the database can store the updates based on step 618.
The flow 600 continues with the system selecting a format of content to be provided to the user (604). Details of this step can be found in the description above with respect to fig. 5A of (504) or fig. 5B of (554). The format of the primitives and semantic descriptors in the store is selected by a person or can be automatically configured by the system.
The flow 600 continues with the system preprocessing the data and verifying the correctness of the task to be provided to the user (606). Details of this step can be found in the description of fig. 5A above with respect to (506) or fig. 5B with respect to (556). The data may be preprocessed, for example, to identify a set of keywords that are available for a particular design shape. Further, the appropriateness or correctness of the data can be verified for a given format or the user's desired audience. In some embodiments, the tasks may be related to a particular country, geography, or demographic. For example, interpreting a French language description may not be a relevant task for illegal language users in the United states and most parts of Europe. These tasks can be stored and provided with content distributed via the internet or applications.
The flow 600 continues by storing the pre-processed data and verified tasks to be provided to the user (608). Details of this step can be found in the description of fig. 5A above with respect to (508) or fig. 5B with respect to (558).
The flow 600 continues with the user of the website or application interacting with the content of the service (610). Details of this step can be found in the description of fig. 5A above with respect to (510) or fig. 5B with respect to (560). For example, a user interacts with content and issues task requests. The user can then interact with the task to provide a response. For example, the user may select the most appropriate keyword or tag for a photograph or image of a product design.
The flow 600 continues by storing the user's response (612). Details of this step can be found in the description of fig. 5A above with respect to (512) or fig. 5B with respect to (562). In some embodiments, only responses are recorded. In some implementations, responses and user demographics may be stored.
The flow 600 continues by building one or more behavioral models based on the user response data (614). Details of this step can be found in the description of fig. 5A above with respect to (514) or fig. 5B with respect to (564). For example, the model can map keywords and semantic descriptors to specific design shapes or geometries. In another example, the model maps product features to preferred sets of other features, or maps products to preferred sets of other products. These models can also map design features or decisions to customer preferences and values.
The flow 600 continues by analyzing and identifying new ideas and/or concepts based on one or more behavioral models (616). Details of this step can be found in the description of FIG. 5A above with respect to (516) or FIG. 5B with respect to (566). For example, the model is analyzed and identified to generate data and results that can be used to help determine new tasks.
The flow 600 continues by exploring and/or optimizing the design to generate new designs and/or keywords (618). Details of this step can be found in the description of fig. 5A above with respect to (518) or fig. 5B with respect to (568). For example, in response to the analysis, the system can use the data to explore and optimize or modify task content, formats, or messaging. Any learning, modification and updating related to models, analysis, design decisions and optimization are stored in the database.
The flow 600 continues with the generation of a modified design shape (622). For example, the model generator 126 can use the behavioral model and the design space of the product to produce a modified design shape. In some embodiments, the model can map keyword descriptions to actual 3D product designs, and the designer can use the keyword descriptions and user feedback to generate new or modified designs. The design can be represented as an explicit shape, a data structure representing the shape or deformation of a given shape, or as a shape diagram. In one example, a designer uses a model to create or modify a design based on other products, which may be sold or bundled. This cycle may repeat until product requirements or release criteria are met. If they are met, the design is provided as a specification, manufacturing direction, recipe, or method to guide or direct the manufacturing process. The resulting product can be sent to the original user who provided the feedback, or provided to a warehouse or store for distribution to customers. In some embodiments, the method can be provided manually, wherein information is provided to the person making the decision. In some embodiments, the method can be used to automatically modify a design according to constraints, specifications, or cost functions that direct the design toward better states. In some embodiments, such methods can use a hybrid approach, where some steps are performed manually and some are performed automatically.
The flow 600 can optionally include manufacturing and transporting a product having the modified design shape (626). For example, a design flow can be integrated with a manufacturing and distribution workflow of a product. In some implementations, products can be distributed to warehouses, stores, and directly to users with similar preferences as the user providing the initial response, such as other users within the same group, cluster, location, or user group in other shared groupings.
FIG. 6B depicts a data flow 650 in which the system integrates user feedback into the design cycle to automatically generate a new design in the example environment of FIG. 1. The operations of data flow 650 are performed by various components of system 100. For example, the operations of data flow 650 can be performed by data quality processor 120 in communication with DCDS110, user device 106, third party 140, and indicia database 130.
A key feature of the flow 650 is that the generative design can be used to enhance the field of view of the human designer, and in some embodiments, can completely replace the human designer based on the desired results.
The process 650 follows the process 500, 550 or 600. Flow 650 begins with the customer uploading one or more design primitives and/or keywords (652). Details of this step can be found in the description above with respect to fig. 5A of (502), fig. 5B with respect to (552), or fig. 6A with respect to (602).
The flow 650 continues with the system preprocessing the data and verifying the correctness of the task to be provided to the user (656). Details of this step can be found in the description above with respect to fig. 5A of (506), fig. 5B with respect to (556), or fig. 6A with respect to (606).
The flow 650 continues with the user of the website or application interacting with the content of the service (660). Details of this step can be found in the description above with respect to fig. 5A of (510), fig. 5B with respect to (560), or fig. 6A with respect to (610).
The flow 650 continues by storing the user's response (662). Details of this step can be found in the description above with respect to fig. 5A of (512), fig. 5B with respect to (562), or fig. 6A with respect to (612).
The process 650 continues with building 664 one or more behavioral models based on the user response data. Details of this step can be found in the description above with respect to fig. 5A of (514), fig. 5B with respect to (564), or fig. 6A with respect to (614).
The flow 650 continues by analyzing and identifying new ideas and/or concepts based on the one or more behavioral models (666). Details of this step can be found in the description above with respect to fig. 5A at (516), fig. 5B at (566), or fig. 6A at (616).
The flow 650 continues by exploring and/or optimizing the design to generate new design and/or semantic descriptors (668). Details of this step can be found in the description above with respect to fig. 5A of (518), fig. 5B with respect to (568), or fig. 6A with respect to (618).
The flow 650 continues with the generation of a modified design shape (672). Details of this step can be found in the description of fig. 6A above with respect to (622).
The process 650 can optionally include manufacturing and transporting the product having the modified design shape (676). Details of this step can be found in the description of FIG. 6A above with respect to (626).
In one example, a task can include presenting two different products, such as shoes, to a user and asking the user which shoe pairs better match the presented apparel. For example, the garment can be a suit. The garment can comprise multiple different garments and require the user to select a set.
In one example, tasks can include ways in which a user configures or modifies a design and solicits feedback on how to create new products or improve existing products. The improved product can then be provided to the user in a new task, and the user can iteratively improve the product design.
In one example, a task can include displaying two different product designs to a user, such as an automobile design, and providing the user with a feedback mechanism, such as a slider or button, to provide the user with a rating of the user's level of confidence in a given attribute, such as a subjective product design descriptor (or adjective) "compact" describing each design.
A computer aided design process can be automatically driven to generate and modify a design in accordance with criteria and specifications. The cost function may be used to weigh design criteria or factors within constraints and specifications. The behavioral model may be used with a cost function to maximize user preferences within constraints, specifications, or manufacturing rules. For example, a generative design method can be used to iterate across the design space under the direction of a behavioral model and a cost function or decision criterion. The use of generative designs includes the use of AI and reinforcement learning to iterate across many design decisions that are allowed or within specifications or constraints, but may represent different customer preferences, such as body style of an automobile or color combinations of running shoes. The generation algorithm method comprises one or more of an evolutionary algorithm, a variational automatic encoder and a generation countermeasure network. These methods can utilize cloud computing to iterate through a large number of design iterations to optimize a single customer, a customer base, or multiple customer bases. Examples of algorithms that may be used include evolutionary algorithms, which include genetic algorithms that evolve a given design or create a mixture of multiple designs. In some embodiments, the system is able to use multiple existing designs of inputs to create a generative countermeasure network of a completely new design. These methods can iteratively generate new designs, the task presenting the new designs to the user to provide relevant feedback. The entire process can be automatically iterated and optimized to produce a new design. In some embodiments, the system can be integrated into an automated manufacturing flow using robotics or 3D printing. In some embodiments, the system can be used to personalize products for users or groups of users based on their provided preferences.
The variational autoencoder and associated generative countermeasure network can be used with the task-generated behavioral model to develop a new design, which is then fed into the system for additional user feedback. The system iterates and is scored until a stop criterion defined by the cost function is reached.
The variational auto-encoder can be used with a library of designs represented as images, shapes, shape-related data structures, shape-related graphs, or polygon data. A variational auto-encoder may be used to create a set of latent factors that effectively represent a reduced set of features that describe a given design. Once the variational auto-encoder is trained, the design is encoded into its latent form and then decoded into its reconstructed design. In one example, an existing library of design representations can be used to build the initial mapping to speed up convergence. Behavioral models developed using task-based feedback can be used to map a given reconstructed design representation to user features or classifications. In some implementations, the user classification can be a good (preferred) versus a bad (non-preferred) score. The user/person-based characterization can be used with a cost function to create a mathematical representation or score that the optimizer can use to create or refine a design. The output of the optimizer is the design type associated with the latent factor description. Optimization may even use gene mutations or crossover to create new potential factors. New latent factors can be generated by the decoder/generator to produce a new design representation that can be inserted into a new task. The designs, the latent factors, and the keywords all form a space for designs and distance metrics that can be used to associate or cluster one design with another design when creating a new task for presentation to a user. The system can automatically iterate around the design space until the cost-based score converges very little, with the resulting latent factors satisfying a stopping criterion or modification. At this point, the design is considered complete and ready for production.
In another embodiment, creating or optimizing a design can include creating a mathematical representation of a design space, where each car or garment design is represented by design features defined by each dimension of the space. The N-dimensional feature space is represented in N space. In many cases, this space can be converted to a lower dimensional space. In other cases, the distance metric can be used to cluster or segment the design instances into classes. The distance from each design instance or class to another instance or class can be calculated and stored. The behavior model represents a mapping between a design instance and a set of keywords or semantic descriptions of the task evaluator/user. This mapping can be explored to find designs similar to the most promising designs evaluated to date (optimization) or dissimilar to those designs (exploration), to discover and explore new portions of the design space. The system can be used with distance-based clustering methods, such as K-nearest neighbor or collaborative filtering, to define design instances of future tasks that are displayed to the user.
Fig. 7A and 7B depict data flows in which the system implements user feedback to customize existing designs and products.
FIG. 7A depicts a data flow 700 in which a system implements user feedback to modify existing designs and products in the example environment of FIG. 1. The operations of data flow 700 are performed by various components of system 100. For example, the operations of data flow 700 can be performed by data quality processor 120 in communication with DCDS110, user device 106, third party 140, and indicia database 130.
The data stream 700 can be integrated with various manufacturing processes, including 3D printing or automated manufacturing.
Flow 700 immediately follows flow 500, 550, 600, or 650. Flow 700 begins with a customer uploading one or more design primitives and/or keywords (702). Details of this step can be found in the description of fig. 5A with respect to (502), fig. 5B with respect to (552), fig. 6A with respect to (602), or fig. 6B with respect to (652) above.
The flow 700 continues with the system preprocessing the data and verifying the correctness of the task to be provided to the user (706). Details of this step can be found in the description of fig. 5A with respect to (506), fig. 5B with respect to (556), fig. 6A with respect to (606), or fig. 6B with respect to (656), above.
The process 700 continues by storing the pre-processed data and verified tasks to be provided to the user (708). Details of this step can be found in the description of fig. 5A with respect to (508), fig. 5B with respect to (558), fig. 6A with respect to (608), or fig. 6B with respect to (658) above.
The flow 700 continues with the user of the website or application interacting with the content of the service (710). Details of this step can be found in the description of fig. 5A with respect to (510), fig. 5B with respect to (560), fig. 6A with respect to (610), or fig. 6B with respect to (660) above.
The flow 700 continues with storing the user's response (712). Details of this step can be found in the description of fig. 5A with respect to (512), fig. 5B with respect to (562), fig. 6A with respect to (612), or fig. 6B with respect to (662), above.
The flow 700 continues with building one or more behavioral models based on the user response data (714). Details of this step can be found in the description of fig. 5A with respect to (514), fig. 5B with respect to (564), fig. 6A with respect to (614), or fig. 6B with respect to (664) above.
The flow 700 continues by analyzing and identifying new ideas and/or concepts based on one or more behavioral models (716). Details of this step can be found in the description of fig. 5A with respect to (516), fig. 5B with respect to (566), fig. 6A with respect to (616), or fig. 6B with respect to (666) above.
The flow 700 continues with exploring and/or optimizing the design to generate new design and/or semantic descriptors (718). Details of this step can be found in the description of fig. 5A with respect to (518), fig. 5B with respect to (568), fig. 6A with respect to (618), or fig. 6B with respect to (668) above.
The process 700 includes using the behavioral model to identify an existing product or set of products having characteristics closest to the design identified by the behavioral model (720). In some embodiments, model generator 126 can access a database or other searchable structure that stores existing product designs and features with or without pre-existing keyword descriptions.
The process 700 can optionally include manufacturing and shipping a product having the modified design shape (726). Details of this step can be found in the description of fig. 6A with respect to (626) or fig. 6B with respect to (676) above.
In one example, a task includes displaying a set of product designs. For example, a kit of product designs can include different product designs for different item types, such as interior furniture (e.g., designs for chairs, tables, beds, accessories, artwork, etc.), and require a user to select different product designs and different item types which the user thinks together look visually appealing. In some implementations, the user feedback can be used in subsequent tasks to test existing and form new marketing strategies, such as cross-sell and up-sell strategies.
In another example, tasks include ways for users to design or configure products (such as shoes or automobiles), and ways for users to receive products or for manufacturers to manufacture products and ship them to users. For example, a user can provide input through a feedback mechanism to indicate a new design or a design configured using a set of predetermined feature values.
In another example, the task includes the user modifying an existing product design and having the manufacturer provide the user with a way to customize the product (e.g., using a 3D printer). For example, a user can provide input through a feedback mechanism to indicate a modification to an existing design.
FIG. 7B depicts a data flow 750 in which a system implements user feedback to customize software designs and products in the example environment of FIG. 1. The operations of data flow 750 are performed by various components of system 100. For example, the operations of data flow 750 can be performed by data quality processor 120 in communication with DCDS110, user device 106, third party 140, and indicia database 130.
The data flow 750 uses a semantic behavior model to configure the software product to suit, for example, a particular user, group or group of users, and so forth. In one example, data stream 750 is used to create a mini-game with characters, weapons, environments, and/or situations, and other characteristics selected or customized based on user information.
The flow 750 may be followed by flows 500, 550, 600, 650, or 700. Flow 750 begins with the customer uploading one or more design primitives and/or semantic descriptors (752). Details of this step can be found in the description of fig. 5A with respect to (502), fig. 5B with respect to (552), fig. 6A with respect to (602), fig. 6B with respect to (652), or fig. 7A with respect to (702) above.
The flow 750 continues with the system selecting a format of content to be provided to the user (754). Details of this step can be found in the description of fig. 5A with respect to (504), fig. 5B with respect to (554), fig. 6A with respect to (604), fig. 6B with respect to (654), or fig. 7A with respect to (704) above.
The flow 750 continues with the system preprocessing the data and verifying the correctness of the task to be provided to the user (756). Details of this step can be found in the description of fig. 5A with respect to (506), fig. 5B with respect to (556), fig. 6A with respect to (606), fig. 6B with respect to (656), or fig. 7A with respect to (706) above.
The flow 750 continues with the user of the website or application interacting with the content of the service (760). Details of this step can be found in the description of fig. 5A with respect to (510), fig. 5B with respect to (560), fig. 6A with respect to (610), fig. 6B with respect to (660), or fig. 7A with respect to (710) above.
The flow 750 continues with storing the user's response (762). Details of this step can be found in the description of fig. 5A with respect to (512), fig. 5B with respect to (562), fig. 6A with respect to (612), fig. 6B with respect to (662), or fig. 7A with respect to (712) above.
The flow 750 continues with building one or more behavioral models based on the user response data (764). Details of this step can be found in the description of fig. 5A with respect to (514), fig. 5B with respect to (564), fig. 6A with respect to (614), fig. 6B with respect to (664), or fig. 7A with respect to (714) above.
The flow 750 continues by analyzing and identifying new ideas and/or concepts based on the one or more behavioral models (766). Details of this step can be found in the description of fig. 5A with respect to (516), fig. 5B with respect to (566), fig. 6A with respect to (616), fig. 6B with respect to (666), or fig. 7A with respect to (716) above.
The flow 750 continues by exploring and/or optimizing the design to generate new design and/or semantic descriptors (768). Details of this step can be found in the description of fig. 5A with respect to (518), fig. 5B with respect to (568), fig. 6A with respect to (618), fig. 6B with respect to (668), or fig. 7A with respect to (718) above.
For example, if the user information indicates that a particular user likes the "star wars" franchise and the software product is a mini-game, the data quality processor 120, and in particular the model generator 126, can modify the mini-game to include characters, audio, items, etc. of the star wars series under the approval of the user and the Lucas movie industry.
In another example, a game developer takes an existing or new game that may have many levels, characters, weapons, and allows a user to select through tasks portions that can be configured using user feedback to allow a small portion to be played through an online or downloadable form.
The flow 750 can optionally include distributing or providing download options with the modified game design to users interacting with the system, and providing feedback (774) and actual delivery of the modified game design to other users (775). Details of this step can be found in the description of fig. 6A with respect to (626), fig. 6B with respect to (676), or fig. 7A with respect to (726) above.
In one example, the task includes displaying to the user two different software game characters or attributes related to the game application, such as window size, and asking the user which is more interesting. In some examples, the method can further include providing for the user to download software that is preconfigured with the selected persona or attribute. In another example, the method can include providing software for a user playing the game online that is preconfigured with the selected character or attribute. In another example, a behavioral model is created through task feedback from one or more users to design new software, such as an application or game, that may have multiple forms of characters, settings, backgrounds customized to one or more user demographics. In another example, multiple users can use tasks to cooperatively design game features that are inserted into a multiplayer gaming environment that the users have access to.
Flow 750 can optionally include distributing or providing download options with the modified game design to users other than the user interacting with the system, and providing feedback (776) and the actual delivery of the modified game design to other users (777). The implementation details are the same as (774).
Fig. 7C is a specific example where the system implements user feedback into the design cycle, as described with respect to fig. 7B. The system can receive a product (780), such as a software title. For example, the system can receive a game or application. The system can identify attributes and assets of the product. For example, the system can determine attributes of the game, including characters, weapons, scenes, environments, keywords, and the like. The system is capable of identifying assets of a game, including thumbnails, presentation versions, multiple configurations, use/game videos, comments, descriptions, keywords, superliberal versions, and the like. Attributes of the game can be presented to the user (782). For example, character a, character B, weapon a, and weapon B can be presented to the user. The user can make their selection and choose to play the game. Assets of the game can be presented to the user (783). For example, thumbnail 1 and thumbnail 2 can be presented to the user along with two sliders that require user input. The first slider asks "which game this tag is: ' role-playing ', ' the user can drag the slider to the side representing their answer. The second slider asks "which game this tag is: 'jigsaw puzzle'.
Fig. 7D is a specific example where the system implements user feedback into the design cycle, as described with respect to fig. 7B. The user can interact with the task to select settings or configuration preferences (784). The user can be presented with task-related UI elements (785). The games or applications can be configured using the flow outlined in (786) - (788). For example, the flow can include settings, configuration, or game state descriptions, such as character/skin, inventory/load, settings/environment, tasks (786). These settings and configurations may be encrypted to control usage and limit permissions for the sub-game. The engine can then take the input and use the settings, configuration, or game state description to generate a usable and viable environment (787). The game or application can then be a configured/personalized experience (788). The configured game or application can be provided to the user through the task-related UI element (789). The user can then receive or download the configured game or application (790). The user can be the same user that interacted with the task in (784) or a different user.
Fig. 7E is a specific example where the system implements user feedback into the design cycle, as described with respect to fig. 7B. The user can interact with the task to select settings or configuration preferences (791). Task related UI elements can be presented to the user (792). The game or application can be configured using the flow outlined in (793) - (795). For example, the flow can include settings, configuration, or game state descriptions, such as character/skin, inventory/load, settings/environment, tasks (793). These settings and configurations may be encrypted to control usage and limit licensing to sub-games. The engine can then map the user settings, configurations, or game state preferences to a preconfigured or pre-compiled game/application from the library (794). The game or application can then be a configured/personalized experience (795). The configured game or application can be provided to the user through the task-related UI element (796). The user can then receive or download the configured game or application (797). The user can be the same user that interacted with the task in (791) or a different user.
FIG. 7F is a specific example where the system uses an auto-encoder to implement user feedback into design feedback. As described above, an auto-encoder can be used with a library of designs and used to create a set of latent factors that effectively represent a reduced set of features that describe a given design. The system has access to a library of design representations, including shapes, images, charts, data structures, and the like (a). The system can then generate a reconstructed design (B) using a set of latent factors that effectively represent a set of features that describe the design. The system is capable of automatically creating an automobile design (C) from raw data or from evolving latency or improved design features. The system can receive results (D) from behavioral models created through user-defined tasks. The system can use a behavioral model as well as user classification (e.g., sports, family, compact) of the automobile design in a semantic representation (E). The system automatically creates a design object (G) using a cost function based scoring method (F) and performing an optimization to create a new feature vector. If the optimization converges to a particular set of criteria, the method ends (H).
Fig. 8 is a flow diagram of an example process 800 for data quality improvement. In some implementations, the process 800 can be performed by one or more systems. For example, the process 800 can be implemented by the data quality processor 120, the DCDS110, the user device 106, and the third party 140 of fig. 1-2 and 4. In some implementations, the process 800 can be implemented as instructions stored on a computer-readable medium, which may be non-transitory, and which, when executed by one or more servers, can cause the one or more servers to perform the operations of the process 800.
The process 800 continues by identifying a behavioral model corresponding to one or more attributes of the user (806). For example, the model generator 126 can identify a behavior model that predicts the behavior of the user based on one or more attributes of the user. In one example, the model generator 126 can identify behavioral models of males over age 65.
The process 800 continues by dynamically changing the presentation of the item depicted by the digital component based on the identified behavioral model corresponding to the one or more attributes of the user (808). For example, the task processor 122 and/or the data processor 124 can dynamically modify the presentation of an item depicted by a digital component, such as a task question, based on an identified behavioral model corresponding to one or more attributes of the user. In one example, the task processor 122 can modify the task questions regarding the mug design depicted in the task based on a behavioral model of a male older than 65 years of age.
In some implementations, the task processor 122 selects the format of the solicited feedback for the numeric components soliciting feedback from the user regarding the item. For example, the task processor 122 selects a form of the user's reaction to a particular mug design.
In some implementations, the data quality processor 120 dynamically changes the presentation of the item depicted by the digital components based on the identified behavioral model corresponding to the one or more attributes of the user, including using machine learning or artificial intelligence techniques to identify feedback about the item to be solicited from the user. For example, the data quality processor 120 can use the output of the model generator 126 to identify feedback to be solicited from the user regarding the mug design.
In some implementations, the task processor 122 validates the information solicited by the numerical components based on specific attributes corresponding to portions of the user population that are not adequately represented. For example, the task processor 122 verifies that the information solicited by the task is to be distributed based on the user age attribute.
The process 800 continues by determining that the user has particular attributes corresponding to insufficiently represented portions of the user population in the database containing information about the item (810). For example, the data processor 124 can determine that a male user portion older than 65 years of age is an underrepresented portion based on a threshold number of responses. In some implementations, the data processor 124 uses statistical analysis to identify portions of the user population that are not adequately represented. The data processor 124 can then determine that the user of the user device 106 has an age attribute corresponding to a portion of the user population in the database that is not adequately represented containing information about the mug design.
The process 800 continues by, in response to determining that the user has a particular attribute corresponding to a portion of the user population that is not adequately represented, generating a numeric component that includes a dynamically changing presentation of the item in response to the request, soliciting feedback from the user regarding the item, and including a feedback mechanism that enables the user to submit feedback regarding the item (812). For example, the task processor 122 can generate a changed presentation or changed task of the project that solicits feedback from the user of the user device 106 regarding the mug design and includes a feedback mechanism, such as a voting feature, that enables the user to submit feedback regarding the project. In some embodiments, DCDS110 generates digital components or selects digital components to distribute to user devices 106, as described above with respect to fig. 1-7.
In some implementations, in response to receiving feedback from users having particular attributes corresponding to portions of the user population that are not adequately represented, the data quality processor 120 tags the feedback information using one or more attributes of the users and stores the tagged feedback information in a tagged, searchable database, such as the tag database 130.
In some implementations, the data quality processor 120 can modify the presentation of the item as it is distributed to other users having one or more attributes of the user by selecting a particular feedback mechanism included with the digital composition.
FIG. 9 is a flow diagram of an example process 900 for automated design space exploration. In some implementations, the process 900 can be performed by one or more systems. For example, the process 900 can be implemented by the data quality processor 120, the DCDS110, the user equipment 106, and the third party 140 of fig. 1-2 and 4. In some implementations, the process 600 can be implemented as instructions stored on a computer-readable medium, which may be non-transitory, and which, when executed by one or more servers, can cause the one or more servers to perform the operations of the process 900.
The process 900 continues by receiving a data set of user-provided information about a particular product design (904). For example, the data quality processor 120 can receive a user-provided response regarding a particular product design, such as a handbag design. In some embodiments, the product design is product specific. The product design can be a service or a software product. For example, the particular product design can be a user interface design of a software application.
The process 900 continues by generating a visual representation that maps the design factors to continuous shapes representing potential product design geometries based on the data set of user-provided information (906). As described above with respect to fig. 3-4, model generator 126 can generate a design space that maps subjective factors to continuous shapes representing potential product designs. For example, model generator 126 can generate a design space that maps semantic factors, such as descriptors, to a continuous shape representing the universe of possible designs.
The design space can be reversible such that generating a visual representation that maps the design factors to continuous shapes representing potential product design geometries based on the dataset of user-provided information includes generating the visual representation by mapping the potential product design geometries to the design factors.
The process 900 continues by segmenting the visual representation into a plurality of segments based on the design factor values (908). As described above with respect to fig. 3-4, the model generator 126 can partition the design space into groups based on the values of the subjective factors.
In some implementations, segmenting the visual representation into a plurality of segments based on the design factor value includes dividing the visual representation into a plurality of segments based on the design factor value such that each segment of the visual representation shares the design factor value within a defined range of values. For example, the data processor 124 can partition the design space into segments based on a range of design factor values, such as a subjective rating of how comfortable the handbag design is perceived.
The process 900 continues by selecting a segment of the visual representation that contains less than a threshold number of data points (910). As described above with respect to fig. 3-4, the data processor 124 can identify the data segments according to a metric, such as a threshold number of data points. For example, the data processor 124 can identify segments of very "fashion" and very "utility" packages as segments having less than a threshold number of data points or failing to reach other metrics.
The process 900 continues by selecting the numeric component for soliciting information from the user (912). For example, the task processor 122 or the DCDS110 can select a numeric component that solicits information from the user. The task processor 122 can select or generate a task for the user that solicits information from the user.
In some implementations, the task processor 122 selects the format in which feedback has been solicited for the numeric components that solicit information from the user. For example, the task processor 122 selects a format of the user's reaction to the handbag design.
In some embodiments, selecting the format of the solicitation information includes selecting a particular feedback mechanism to provide with the dynamically changing numeric component.
In some implementations, the task processor 122 validates the information solicited by the numerical components based on specific attributes corresponding to portions of the user population that are not adequately represented. For example, the task processor 122 verifies that the information solicited by the task is to be distributed based on the user age attribute.
The process 900 continues by dynamically changing the presentation of the numerical components soliciting information from the user regarding segments of the visual representation that contain less than a threshold number of data points based on the selected segments of the visual representation (914). For example, as described above with respect to fig. 3-4, the task processor 122 can dynamically change an existing task or generate a new task. In one example, task processor 122 can change existing tasks to present a user with new product designs that have not been previously generated or presented to the user.
In some implementations, dynamically changing the presentation of the content item includes using machine learning or artificial intelligence techniques to specify the information requested by the digital component. For example, the data quality processor 120 can use the machine learning model generated by the model generator 126 to determine and specify information for the task request.
In some implementations, dynamically changing presentation of the digital composition includes determining that a user of the user device is in a first user cluster interested in a particular product design based on a request for the digital composition for presentation at the user device, and identifying user interface elements of the digital composition and changing the presented user interface elements of the digital composition based on determining that the user of the user device is in the first user cluster interested in the particular product design. For example, the data processor 124 can determine that the user of the user device 106 is in a cluster of interested users, identify user interface elements for the tasks, and change the user interface elements to customize the tasks for the users who have been interested in designing the handbag.
In some implementations, dynamically changing presentation of the digital components includes determining that a user of the user device is in a first user cluster interested in the particular product design based on a request for the digital components for presentation at the user device, wherein the request for the digital components for presentation at the user device indicates one or more attributes of the user based on information provided by the user, identifying user interface elements of the digital components based on determining that the user of the user device is in the first user cluster interested in the particular product design, and changing the presented user interface elements of the digital components.
In some implementations, the process 900 includes building a behavioral model that predicts user acceptance of potential product design geometries based on the feedback information. For example, the model generator 126 can generate a behavioral model that predicts the user's acceptance of a handbag product design. The modification of the design factors for a particular product design is based at least in part on the behavioral model.
The process 900 continues with distributing the dynamically changing digital components for presentation at the user device (916). For example, DCDS110 may be capable of distributing tasks and any requested content to user devices 106 as replies 114.
The process 900 continues with obtaining feedback information from the user device and through a feedback mechanism regarding segments of the visual representation that contain less than a threshold number of data points (918). For example, the DCDS110 can receive the response data 116 from the user equipment 106 and provide it to the data processor 124. As described above with respect to fig. 3-4, the data quality processor 120 can receive feedback information from the user regarding a particular segment of the visual representation. For example, the data processor 124 and the DCDS110 can receive feedback information from the user equipment 106 regarding design space segments having less than a threshold number of data points.
In some implementations, the request for the digital components for presentation at the user device indicates user demographic information of a user of the user device. Process 900 can also include determining that a user of the user device is in a first user group, such as a group of female users in california, based on the request for the digital composition for presentation at the user device.
In some implementations, the process 900 can also include receiving, from the second user device, a request for the digital components for presentation at the second user device, the request indicating user demographic information of a user of the second user device. The system 100 (e.g., the data processor 124) can then determine that the user of the second user device is in the same first user group as the user of the user device based on the request for the digital component for presentation at the second user device. For example, system 100 (e.g., data processor 124) can determine that the user of the second device is a woman in california. In response to determining that the user of the second user device is in the same first user group as the user of the user device, the system 100 can provide the modified product design instead of the particular product design. For example, due to similarities between the user of the first user device and the user of the second user device, the task processor 122 can provide the user of the second user device with a modified handbag design instead of the original handbag design.
As described above with respect to fig. 3-4, the model generator 126 can update the design space and/or the behavioral model. For example, the model generator 126 can update the data set by providing feedback information as input to a training system of a behavioral model or design generator.
In some implementations, the process 900 includes identifying, based on the modified product design and from among a plurality of existing product designs, a closest existing product design having a plurality or maximum number of common design factor values with the modified product design. For example, the data quality processor 120 can identify the existing product that is closest to the modified design. For example, rather than creating an entirely new product, the system 100 can modify an existing product and its method of manufacture. In some embodiments, the system 100 can provide the modified product design to the integrated manufacturing system. For example, the data quality processor 120 can provide the modified product design to a 3D printing system or an automated manufacturing system for immediate production.
FIG. 10 is a block diagram of an example computer system 1000 that can be used to perform the operations described above. The system 1000 includes a processor 1010, a memory 1020, a storage device 1030, and an input/output device 1040. Each of the components 1010, 1020, 1030, and 1040 can be interconnected, for example, using a system bus 1050. Processor 1010 is capable of processing instructions for execution within system 1000. In one implementation, the processor 1010 is a single-threaded processor. In another implementation, the processor 1010 is a multi-threaded processor. The processor 1010 is capable of processing instructions stored in the memory 1020 or the storage 1030.
The storage device 1030 is capable of providing mass storage for the system 1000. In one implementation, the storage device 1030 is a computer-readable medium. In various different implementations, the storage 1030 can include, for example, a hard disk device, an optical disk device, a storage device shared by multiple computing devices over a network (e.g., a cloud storage device), or some other mass storage device.
Input/output device 1040 provides input/output operations for system 1000. In one embodiment, input/output device 1040 can include one or more network interface devices, such as an Ethernet card, a serial communication device (e.g., an RS-232 port), and/or a wireless interface device (e.g., an 802.11 card). In another embodiment, the input/output devices can include driver devices configured to receive input data and send output data to other input/output devices (e.g., keyboard, printer, and display devices 1060). However, other implementations can also be used, such as mobile computing devices, mobile communication devices, set-top box television client devices, and so forth.
Although an example processing system is depicted in FIG. 10, implementations of the subject matter and the functional operations described in this specification can be implemented in other types of digital electronic circuitry, or in computer software, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them.
An electronic document (simply referred to as a document for brevity) does not necessarily correspond to a file. A document may be stored in a portion of a file that holds other documents, in a single file dedicated to the document in question, or in multiple coordinated files.
Embodiments of the subject matter and the operations described in this specification can be implemented in digital electronic circuitry, or in computer software, firmware, or hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them. Embodiments of the subject matter described in this specification can be implemented as one or more computer programs, i.e., one or more modules of computer program instructions, encoded on a computer storage medium (or multiple media) for execution by, or to control the operation of, data processing apparatus. Alternatively or additionally, the program instructions can be encoded on an artificially generated propagated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal, that is generated to encode information for transmission to suitable receiver apparatus for execution by the data processing apparatus. The computer storage medium can be or be included in a computer-readable storage device, a computer-readable storage substrate, a random or serial access memory array or device, or a combination of one or more of them. Further, although the computer storage medium is not a propagated signal, the computer storage medium can be a source or destination of computer program instructions encoded in an artificially generated propagated signal. The computer storage medium can also be or be included in one or more separate physical components or media (e.g., multiple CDs, disks, or other storage devices).
The operations described in this specification can be implemented as operations performed by data processing apparatus on data stored on one or more computer-readable storage devices or received from other sources.
The term "data processing apparatus" encompasses all kinds of apparatus, devices, and machines for processing data, including by way of example a programmable processor, a computer, a system on a chip, or a plurality or combination of the foregoing. The apparatus can comprise special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit). The apparatus can include, in addition to hardware, code that creates an execution environment for the computer program in question, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, a cross-platform runtime environment, a virtual machine, or a combination of one or more of them. The apparatus and execution environment are capable of implementing a variety of different computing model infrastructures, such as web services, distributed computing and grid computing infrastructures.
A computer program (also known as a program, software application, script, or code) can be written in any form of programming language, including compiled or interpreted languages, declarative or procedural languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, object, or other unit suitable for use in a computing environment. A computer program may, but need not, correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data (e.g., one or more scripts stored in a markup language document), in a single file dedicated to the program in question, or in multiple coordinated files (e.g., files that store one or more modules, sub programs, or portions of code). A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.
The processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform actions by operating on input data and generating output. The processes and logic flows can also be performed by, and apparatus can also be implemented as, special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit).
Processors suitable for the execution of a computer program include, by way of example, both general and special purpose microprocessors. Generally, a processor will receive instructions and data from a read-only memory or a random access memory or both. The essential elements of a computer are a processor for performing actions in accordance with the instructions and one or more memory devices for storing instructions and data. Generally, a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks. However, a computer need not have such a device. Further, the computer can be embedded in another device, e.g., a mobile telephone, a Personal Digital Assistant (PDA), a mobile audio or video player, a game console, a Global Positioning System (GPS) receiver, or a portable storage device (e.g., a Universal Serial Bus (USB) flash drive), to name a few. Devices suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, e.g., internal hard disks or removable disks; a magneto-optical disk; and CD ROM and DVD-ROM disks. The processor and the memory can be supplemented by, or incorporated in, special purpose logic circuitry.
To provide for interaction with a user, embodiments of the subject matter described in this specification can be implemented on a computer having a display device, e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to the user and a keyboard and a pointing device, e.g., a mouse or a trackball, by which the user can provide input to the computer. Other types of devices can also be used to provide for interaction with a user; for example, feedback provided to the user can be any form of sensory feedback, such as visual feedback, auditory feedback, or tactile feedback; and input from the user can be received in any form, including acoustic, speech, or tactile input. Further, the computer is able to interact with the user by sending and receiving documents to and from the device used by the user; for example, by sending a web page to a web browser on the user's client device in response to a request received from the web browser.
Embodiments of the subject matter described in this specification can be implemented in a computing system that includes a back-end component, e.g., as a data server, or that includes a middleware component, e.g., an application server, or that includes a front-end component, e.g., a client computer having a graphical user interface or a web browser through which a user can interact with an implementation of the subject matter described is this specification, or any combination of one or more such back-end, middleware, or front-end components. The components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include local area networks ("LANs") and wide area networks ("WANs"), the internet (e.g., the internet), and peer-to-peer networks (e.g., ad hoc peer-to-peer networks).
The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other. In some embodiments, the server transmits data (e.g., HTML pages) to the client device (e.g., for displaying data to and receiving user input from a user interacting with the client device). Data generated at the client device (e.g., a result of the user interaction) can be received at the server from the client device.
While this specification contains many specific implementation details, these should not be construed as limitations on the scope of any invention or of what may be claimed, but rather as descriptions of features specific to particular embodiments of particular inventions. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely, various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Moreover, although features may be described above as acting in certain combinations and even initially claimed as such, one or more features from a claimed combination can in some cases be excised from the combination, and the claimed combination may be directed to a subcombination or variation of a subcombination.
Similarly, while operations are depicted in the drawings in a particular order, this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order, or that all illustrated operations be performed, to achieve desirable results. In some cases, multitasking and parallel processing may be advantageous. Moreover, the separation of various system components in the embodiments described above should not be understood as requiring such separation in all embodiments, and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.
Thus, particular embodiments of the subject matter have been described. Other embodiments are within the scope of the following claims. In some cases, the actions recited in the claims can be performed in a different order and still achieve desirable results. Moreover, the processes depicted in the accompanying figures do not necessarily require the particular order shown, or sequential order, to achieve desirable results. In some embodiments, multitasking and parallel processing may be advantageous.
Claims (21)
1. A method for generating a new product design, comprising:
receiving a request from a user device for a digital component for display at the user device;
receiving a data set of user-provided information about a particular product design;
generating a visual representation that maps design factors to continuous shapes representing potential product design geometries based on the data set of user-provided information;
segmenting the visual representation into a plurality of segments based on design factor values;
selecting a segment of the visual representation that contains less than a threshold number of data points;
selecting a numeric component for soliciting information from a user;
dynamically changing, based on the selected segment of the visual representation, the providing of the numerical component that solicits the user for information about the segment of the visual representation that contains less than the threshold number of data points;
distributing the dynamically changing digital components for display at the user device;
obtaining, from the user device and through a feedback mechanism, feedback information about the segment of the visual representation containing less than the threshold number of data points; and
modifying design factors of the particular product design based at least in part on the feedback information obtained from the user to create a modified product design.
2. The method of claim 1, further comprising:
selecting a format in which to solicit information for the particular numeric component that solicits the information from the user; and
verifying the information solicited from the user for the particular numerical component of information based on the selected segment of the visual representation.
3. The method of claim 2, wherein selecting a format for soliciting the information comprises selecting a particular feedback mechanism provided with the dynamically changing numeric component.
4. The method of any preceding claim, further comprising:
determining that the user of the user device is in a first user group based on the request for the digital components for display at the user device,
wherein the request for the digital components for display at the user device indicates user demographic information for the user of the user device.
5. The method of claim 4, further comprising:
receiving, from a second user device, a request for a digital composition for display at the second user device, the request indicating user demographic information for a user of the second user device;
determining, based on the request for the digital composition for display at the second user device, that the user of the second user device is in the same first user group as the user of the user device; and
providing the modified product design instead of the particular product design in response to determining that the user of the second user device is in the same first user group as the user of the user device.
6. The method of any preceding claim, wherein segmenting the visual representation into a plurality of segments based on the design factor values comprises:
based on the design factor values, the visual representation is divided into a plurality of segments such that each segment of the visual representation shares a design factor value within a defined range of values.
7. The method of any preceding claim, wherein dynamically changing the provision of the digital components comprises:
determining, based on the request for the digital part for display at the user device, that the user of the user device is in a first cluster of users interested in the particular product design, wherein the request for the digital part for display at the user device indicates one or more attributes of the user based on information provided by the user;
identifying a user interface element for the digital component based on determining that the user of the user device is in the first user cluster of interest in the particular product design; and
changing the provided user interface element of the digital component.
8. The method of claim 7, wherein the user interface element of the digital component is a visual theme of the digital component, and
wherein changing the user interface element comprises modifying the visual theme of the digital component by modifying a color scheme and a brand logo provided in the digital component.
9. The method of any preceding claim, wherein dynamically changing the presentation of the digital components comprises:
determining that the user of the user device is in a first user group based on the request for the digital components for display at the user device, wherein the request for the digital components for display at the user device includes information indicative of one or more attributes of the user;
identifying a user interface element of the digital component based on determining that the user of the user device is in the first user group; and
changing the provided user interface element of the digital component.
10. The method of any preceding claim, wherein mapping design factors to the visual representation of continuous shapes representing potential product design geometries is reversible such that generating the visual representation of mapping design factors to continuous shapes representing potential product design geometries based on the dataset of user-provided information comprises generating the visual representation by mapping potential product design geometries to design factors.
11. The method of any preceding claim, further comprising:
identifying a closest existing product design from a plurality of existing product designs based on the modified product design and having a plurality of design factor values in common with the modified product design.
12. The method of any preceding claim, further comprising providing the modified product design to an integrated manufacturing system.
13. The method of any preceding claim, further comprising:
constructing a behavior model predicting acceptance of potential product design geometries by a user based on the feedback information; and
wherein modifying design factors of the particular product design is based at least in part on the behavioral model.
14. The method of any preceding claim, wherein the particular product design is a user interface design of a software application.
15. The method of any preceding claim, wherein dynamically changing the providing of the digital components comprises using machine learning or artificial intelligence techniques to specify information to be requested by the digital components.
16. A system, comprising:
one or more processors; and
one or more memory elements comprising instructions that when executed cause the one or more processors to perform operations comprising:
receiving a request from a user device for a digital component for display at the user device;
receiving a data set of user-provided information about a particular product design;
generating a visual representation that maps design factors to continuous shapes representing potential product design geometries based on the data set of user-provided information;
segmenting the visual representation into a plurality of segments based on design factor values;
selecting a segment of the visual representation that contains less than a threshold number of data points;
selecting a numeric component for soliciting information from a user;
dynamically changing, based on the selected segment of the visual representation, the solicitation to the user of the numerical components for information about the segment of the visual representation that contains less than the threshold number of data points;
distributing the dynamically changing digital components for display at the user device;
obtaining, from the user device and through a feedback mechanism, feedback information about the segment of the visual representation containing less than the threshold number of data points; and
modifying design factors of the particular product design based at least in part on the feedback information obtained from the user to create a modified product design.
17. The system of claim 16, the operations further comprising:
determining that the user of the user device is in a first user group based on the request for the digital component for display at the user device;
wherein the request for the digital component for display at the user device indicates user demographic information for the user of the user device.
18. The system of claim 17, the operations further comprising:
receiving, from a second user device, a request for a digital component for display at the second user device, the request indicating user demographic information for a user of the second user device;
determining, based on the request for the digital composition for display at the second user device, that the user of the second user device is in the same first user group as the user of the user device; and
providing the modified product design instead of the particular product design in response to determining that the user of the second user device is in the same first user group as the user of the user device.
19. A computer storage medium encoded with instructions that, when executed by a distributed computing system, cause the distributed computing system to perform operations comprising:
receiving, from a user device, a request for a digital composition for display at the user device;
receiving a data set of user-provided information about a particular product design;
generating a visual representation that maps design factors to continuous shapes representing potential product design geometries based on the data set of user-provided information;
segmenting the visual representation into a plurality of segments based on design factor values;
selecting a segment of the visual representation that contains less than a threshold number of data points;
selecting a numeric component for soliciting information from a user;
dynamically changing, based on the selected segment of the visual representation, the providing of the numerical component that solicits the user for information about the segment of the visual representation that contains less than the threshold number of data points;
distributing the dynamically changing digital components for display at the user device;
obtaining, from the user device and through a feedback mechanism, feedback information about the segment of the visual representation containing less than the threshold number of data points; and
modifying design factors of the particular product design based at least in part on the feedback information obtained from the user to create a modified product design.
20. The computer storage medium of claim 19, the operations further comprising:
receiving, from a second user device, a request for a digital component for display at the second user device, the request indicating user demographic information for a user of the second user device;
determining, based on the request for the digital composition for display at the second user device, that the user of the second user device is in the same first user group as the user of the user device; and
providing the modified product design instead of the particular product design in response to determining that the user of the second user device is in the same first user group as the user of the user device.
21. The computer storage medium of claim 19, the operations further comprising the method of any of claims 2 to 15.
Applications Claiming Priority (5)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US202063010438P | 2020-04-15 | 2020-04-15 | |
US63/010,438 | 2020-04-15 | ||
US16/943,126 | 2020-07-30 | ||
US16/943,126 US20210326494A1 (en) | 2020-04-15 | 2020-07-30 | Automatically and intelligently exploring design spaces |
PCT/US2021/026853 WO2021211437A1 (en) | 2020-04-15 | 2021-04-12 | Automatically and intelligently exploring design spaces |
Publications (1)
Publication Number | Publication Date |
---|---|
CN115244547A true CN115244547A (en) | 2022-10-25 |
Family
ID=78081926
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202180019805.9A Pending CN115244547A (en) | 2020-04-15 | 2021-04-12 | Automatically and intelligently exploring design spaces |
Country Status (6)
Country | Link |
---|---|
US (1) | US20210326494A1 (en) |
JP (1) | JP7361942B2 (en) |
KR (1) | KR20220139942A (en) |
CN (1) | CN115244547A (en) |
CA (1) | CA3175045A1 (en) |
WO (1) | WO2021211437A1 (en) |
Families Citing this family (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10140392B1 (en) | 2017-06-29 | 2018-11-27 | Best Apps, Llc | Computer aided systems and methods for creating custom products |
US20210326494A1 (en) * | 2020-04-15 | 2021-10-21 | Google Llc | Automatically and intelligently exploring design spaces |
US11514203B2 (en) | 2020-05-18 | 2022-11-29 | Best Apps, Llc | Computer aided systems and methods for creating custom products |
US11900052B2 (en) * | 2020-11-11 | 2024-02-13 | Microsoft Technology Licensing, Llc | Automatic generation of transformations of formatted templates using deep learning modeling |
CN115480679A (en) * | 2021-05-28 | 2022-12-16 | 北京字节跳动网络技术有限公司 | Display method, device, client, server and medium of virtual live broadcast room |
Family Cites Families (23)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
EP2631856A3 (en) | 2000-11-10 | 2013-10-30 | Affinnova, Inc. | Method and apparatus for for dynamic, real-time market segmentation |
JP2003141180A (en) | 2001-11-05 | 2003-05-16 | Mitsui Home Co Ltd | Life style image simulation system, method and program |
US20100169313A1 (en) * | 2008-12-30 | 2010-07-01 | Expanse Networks, Inc. | Pangenetic Web Item Feedback System |
US8296183B2 (en) * | 2009-11-23 | 2012-10-23 | Ecomsystems, Inc. | System and method for dynamic layout intelligence |
US20120303559A1 (en) * | 2011-05-27 | 2012-11-29 | Ctc Tech Corp. | Creation, use and training of computer-based discovery avatars |
US8255293B1 (en) * | 2011-10-10 | 2012-08-28 | Google Inc. | Product catalog dynamically tailored to user-selected media content |
US8965897B2 (en) * | 2012-02-29 | 2015-02-24 | International Business Machines Corporation | Intelligent product feedback analytics tool |
US10185917B2 (en) * | 2013-01-31 | 2019-01-22 | Lf Technology Development Corporation Limited | Computer-aided decision systems |
US9799041B2 (en) * | 2013-03-15 | 2017-10-24 | The Nielsen Company (Us), Llc | Method and apparatus for interactive evolutionary optimization of concepts |
US20150213164A1 (en) * | 2014-01-27 | 2015-07-30 | GM Global Technology Operations LLC | Product design reliability with consideration of material property changes during service |
US20150228002A1 (en) * | 2014-02-10 | 2015-08-13 | Kelly Berger | Apparatus and method for online search, imaging, modeling, and fulfillment for interior design applications |
JP6167942B2 (en) | 2014-03-04 | 2017-07-26 | 富士ゼロックス株式会社 | Design editing apparatus and program |
US9881332B2 (en) * | 2014-05-22 | 2018-01-30 | LogoMix, Inc. | Systems and methods for customizing search results and recommendations |
US20160267684A1 (en) * | 2015-03-11 | 2016-09-15 | International Business Machines Corporation | Creative Color Design |
US11106760B2 (en) * | 2015-05-01 | 2021-08-31 | Einstein Industries, Inc. | Enhanced metadata collection and output |
JP7015514B2 (en) | 2016-09-06 | 2022-02-03 | 公紀 岩中 | Virtual clothing output system and virtual clothing output method |
US11226831B2 (en) * | 2016-12-05 | 2022-01-18 | Facebook, Inc. | Customizing content based on predicted user preferences |
US20180196895A1 (en) * | 2017-01-11 | 2018-07-12 | Benjamin James Joseph Soppitt | Reusable product design model |
EP3514707A1 (en) * | 2018-01-17 | 2019-07-24 | PDM Software ApS | Designing assemblies of digital models utilizing information derived from earlier design processes |
CN112262363A (en) * | 2018-02-27 | 2021-01-22 | 利惠商业有限公司 | Laser arrangement design tool |
US20210326494A1 (en) * | 2020-04-15 | 2021-10-21 | Google Llc | Automatically and intelligently exploring design spaces |
US11531655B2 (en) * | 2020-04-15 | 2022-12-20 | Google Llc | Automatically improving data quality |
US10957086B1 (en) * | 2020-06-25 | 2021-03-23 | Accenture Global Solutions Limited | Visual and digital content optimization |
-
2020
- 2020-07-30 US US16/943,126 patent/US20210326494A1/en active Pending
-
2021
- 2021-04-12 WO PCT/US2021/026853 patent/WO2021211437A1/en active Application Filing
- 2021-04-12 KR KR1020227030971A patent/KR20220139942A/en unknown
- 2021-04-12 JP JP2022554664A patent/JP7361942B2/en active Active
- 2021-04-12 CA CA3175045A patent/CA3175045A1/en active Pending
- 2021-04-12 CN CN202180019805.9A patent/CN115244547A/en active Pending
Also Published As
Publication number | Publication date |
---|---|
JP2023521558A (en) | 2023-05-25 |
KR20220139942A (en) | 2022-10-17 |
CA3175045A1 (en) | 2021-10-21 |
JP7361942B2 (en) | 2023-10-16 |
WO2021211437A1 (en) | 2021-10-21 |
US20210326494A1 (en) | 2021-10-21 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
Adomavicius et al. | Multi-criteria recommender systems | |
JP7361942B2 (en) | Automatic and intelligent exploration of design space | |
JP7464741B2 (en) | Automatically improving data quality | |
CN112313697A (en) | System and method for generating interpretable description-based recommendations describing angle augmentation | |
De Mauro et al. | Machine learning and artificial intelligence use in marketing: a general taxonomy | |
Pan et al. | Learning adaptive trust strength with user roles of truster and trustee for trust-aware recommender systems | |
CN115917535A (en) | Recommendation model training method, recommendation device and computer readable medium | |
Taghavi et al. | New insights towards developing recommender systems | |
Da Costa et al. | Exploiting multimodal interactions in recommender systems with ensemble algorithms | |
Yan et al. | Implementation of a product-recommender system in an IoT-based smart shopping using fuzzy logic and apriori algorithm | |
Jung et al. | Discovery of automotive design paradigm using relevance feedback | |
Kang et al. | A personalized point-of-interest recommendation system for O2O commerce | |
Yıldız et al. | A Hyper-Personalized Product Recommendation System Focused on Customer Segmentation: An Application in the Fashion Retail Industry | |
Zhang et al. | Recommendation system in social networks with topical attention and probabilistic matrix factorization | |
Elahi et al. | Recommender systems: Challenges and opportunities in the age of big data and artificial intelligence | |
Fareed et al. | A collaborative filtering recommendation framework utilizing social networks | |
Wen et al. | Visual background recommendation for dance performances using deep matrix factorization | |
Lim et al. | No. 3. Hybrid-based Recommender System for Online Shopping: A Review: Manuscript Received: 8 February 2023, Accepted: 21 February 2023, Published: 15 March 2023, ORCiD: 0000-0002-7190-0837 | |
Tsafarakis et al. | Applications of MCDA in Marketing and e-Commerce | |
Liao et al. | An integrated model based on deep multimodal and rank learning for point-of-interest recommendation | |
Salman et al. | Product recommendation system using deep learning techniques: CNN and NLP | |
McIlwraith | Algorithms of the intelligent web | |
Da Costa et al. | Improving personalized ranking in recommender systems with multimodal interactions | |
Nasir et al. | A Survey and Taxonomy of Sequential Recommender Systems for E-commerce Product Recommendation | |
CN114298118B (en) | Data processing method based on deep learning, related equipment and storage medium |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |