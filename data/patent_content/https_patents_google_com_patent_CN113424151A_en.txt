CN113424151A - Automated assistant suggestion for third party vehicle computing devices with restricted architecture - Google Patents
Automated assistant suggestion for third party vehicle computing devices with restricted architecture Download PDFInfo
- Publication number
- CN113424151A CN113424151A CN201980091586.8A CN201980091586A CN113424151A CN 113424151 A CN113424151 A CN 113424151A CN 201980091586 A CN201980091586 A CN 201980091586A CN 113424151 A CN113424151 A CN 113424151A
- Authority
- CN
- China
- Prior art keywords
- data
- vehicle
- application
- automated assistant
- content
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/16—Sound input; Sound output
- G06F3/167—Audio in a user interface, e.g. using voice commands for navigating, audio feedback
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0481—Interaction techniques based on graphical user interfaces [GUI] based on specific properties of the displayed interaction object or a metaphor-based environment, e.g. interaction with desktop elements like windows or icons, or assisted by a cursor's changing behaviour or appearance
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/46—Multiprogramming arrangements
- G06F9/48—Program initiating; Program switching, e.g. by interrupt
- G06F9/4806—Task transfer initiation or dispatching
- G06F9/4843—Task transfer initiation or dispatching by program, e.g. task dispatcher, supervisor, operating system
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/46—Multiprogramming arrangements
- G06F9/54—Interprogram communication
-
- Y—GENERAL TAGGING OF NEW TECHNOLOGICAL DEVELOPMENTS; GENERAL TAGGING OF CROSS-SECTIONAL TECHNOLOGIES SPANNING OVER SEVERAL SECTIONS OF THE IPC; TECHNICAL SUBJECTS COVERED BY FORMER USPC CROSS-REFERENCE ART COLLECTIONS [XRACs] AND DIGESTS
- Y02—TECHNOLOGIES OR APPLICATIONS FOR MITIGATION OR ADAPTATION AGAINST CLIMATE CHANGE
- Y02D—CLIMATE CHANGE MITIGATION TECHNOLOGIES IN INFORMATION AND COMMUNICATION TECHNOLOGIES [ICT], I.E. INFORMATION AND COMMUNICATION TECHNOLOGIES AIMING AT THE REDUCTION OF THEIR OWN ENERGY USE
- Y02D10/00—Energy efficient computing, e.g. low power processors, power management or thermal management
Abstract
Implementations set forth herein relate to an automated assistant that provides suggested elements at an OEM application and/or a third party application accessible via an OEM vehicle computing device that employs restrictions on communication between native applications. The automated assistant may render the suggestions via the OEM vehicle application and/or third party application and initialize the actions for execution via the OEM vehicle application and/or third party application, although there are limitations. The suggestions may be rendered at a graphical user interface of the vehicle and include content that, when spoken by the user, causes the automated assistant to initiate such actions. The actions suggested by the automated assistant may be performed by a third-party application that is different from the third-party application that is rendering the suggestions. In this way, a common automated assistant may be indiscriminately available via a variety of vehicle computing devices despite differences in communication limitations between vehicle applications.
Description
Background
Computing devices and their corresponding applications often provide robust functionality to assist users in performing various tasks. Providers of a particular application or device may not expect a user to employ all of the functionality during initial use, but rather learn the functionality of the application or device over time. When a particular device provides access to the automated assistant, the automated assistant can be used to familiarize the user with various functions using suggestions that direct the user to control one or more actions of the particular device and/or application. However, in some instances, such as at a vehicle computing device or other OEM computing device, the automated assistant may be accessible through the vehicle computing device, but is limited in the type of data that may be collected from the operation of the vehicle computing device. As a result, any suggestions made by the automated assistant may not be appropriately adjusted to accommodate the vehicle computing device and/or may enable more efficient and/or effective use of the functionality of the vehicle and/or other applications of the vehicle computing device.
Furthermore, such limitations may prevent a user from more quickly learning about the safety functions of the vehicle computing device. In other words, because the vehicle computing device may provide too many safety features that the user cannot reasonably expect to immediately confirm, any delay in learning these features may limit the safety and/or utility of the vehicle. In addition, because users may spend a significant amount of their time controlling the vehicle in order to navigate rather than learn features, the users will not receive benefits such as reduced power consumption and increased efficiency. This may be particularly evident when the vehicle computing device is not specifically actively suggesting functionality to the user, as such benefits are typically realized when the user outsources various tasks to the computing device.
Disclosure of Invention
Implementations set forth herein relate to a hierarchy of vehicle applications provided at a vehicle computing device that also includes an automated assistant that can render suggestions via the vehicle applications and initiate actions via the vehicle applications. The vehicle applications may be loaded onto a vehicle computing device of the vehicle and may provide various functionality related to navigation, communications, media, and/or any other type of service capable of being provided by the computing device. The vehicle computing device may operate in accordance with an operating system loaded onto the vehicle computing device and including one or more Original Equipment Manufacturer (OEM) applications. The OEM application may be provided by an entity or source that also provides the vehicle. Further, the vehicle computing device may also include one or more vehicle applications provided by third-party sources (i.e., third-party applications rather than native vehicle applications), and automated assistants provided by sources separate from the third-party sources. Communication between the automated assistant and other applications may be limited to communication occurring via the vehicle computing device, which may improve reliability of the vehicle system. The automated assistant may be remote from the vehicle computing device. The one or more actions suggested by the automated assistant may be performed by a local vehicle application (whether a local OEM application or a third party application), which may improve reliability of vehicle performance, particularly where the vehicle is expected to maintain full control of its systems, such as in an autonomous vehicle environment. One or more actions may be performed by the remote automated assistant that may protect user data and information associated with the automated assistant (assistant data), and thus improve user privacy and data security by preventing the native vehicle application from accessing the user data.
In some implementations, the OEM vehicle application and/or automated assistant can render a graphical user interface that includes a variety of different content based on data from one or more other vehicle applications while the user is in the vehicle. For example, the graphical user interface may include a first region for rendering navigation-related content, a second region for rendering communication-related content, and/or a third region for rendering automated assistant content. In order for the user to learn various functions of the vehicle computing device and/or vehicle applications, the automated assistant may provide suggestions and/or cause suggestions to be rendered at each region of the graphical user interface. As a result, while the automated assistant is accessible via a variety of different vehicles using data from one or more other vehicle applications provided at the vehicle computing device, the automated assistant will still be able to provide suggestions to the user regardless of the vehicle in which the automated assistant is operating.
In some implementations, while the graphical user interface is displaying at least the first region and the second region, the OEM vehicle application may generate data characterizing what is provided at the user interface and provide such generated data to the automated assistant. As used herein, data may characterize or indicate some or all of the content provided at the graphical user interface in order to provide a context that the automated assistant may use to generate suggestions. For example, when the first region is displaying navigation directions to a destination and the second region is displaying a notification regarding an incoming phone call, the OEM vehicle application may generate data characterizing (or indicating) the status of the incoming phone call and the status of the navigation to the destination. In some implementations, the automated assistant can use the data to generate one or more suggestions or actions to be performed by the automated assistant and/or any other application accessible via the vehicle computing device.
For example, the automated assistant may provide a suggestion element at the graphical user interface to invoke the messaging application to provide an estimated time of arrival to the person who is the source of the incoming call. The automated assistant can cause the suggestion element to be provided at the second region of the graphical user interface because the suggestion is related to the communication. The suggestion elements may include natural language content that characterizes (or indicates) any action that the assistant may take, such as "Send Megan my estimated time of arrival to the root of the plum". The natural language content may be text provided at the suggestion element, may be an example utterance used to invoke the automated assistant to perform an action associated with the suggestion element, and/or may otherwise characterize a spoken utterance used to invoke the automated assistant. For example, to invoke the automated Assistant to cause a message to be sent, the user may tap the display panel at a location where the suggestion element is being rendered, and/or provide a spoken input that includes at least a portion of the spoken utterance rendered at the graphical user interface (e.g., "Assistant, send a message to the Meigen indicating My ETA").
In some implementations, the OEM vehicle application may provide various data to the automated assistant over time in response to at least a change in content rendered at a display panel of the vehicle computing device. When the automated assistant receives subsequent data from the OEM vehicle application, the automated assistant may generate further suggestions, and/or rank the suggestions according to various different attributes. In some cases, the suggested elements provided by the automated assistant may be ranked according to the strength of the correlation between the assistant data and the vehicle application data provided by the OEM vehicle application. For example, vehicle application data that characterizes a destination displayed at the display panel may have a stronger correlation with assistant data that also identifies the destination, and such "stronger" correlation may be relative to when the vehicle application data does not identify a destination that is also identified by the assistant data.
A set of suggested elements may be generated for each region of the graphical user interface associated with a particular type of application and/or activity. For each set of suggested elements, a rank may be assigned to each suggested element in the set of suggested elements. In this manner, when a suggestion element is to be rendered at a particular region of the graphical user interface, the suggestion element selected to be rendered may be the highest ranked suggestion element from the set of suggestion elements corresponding to the particular region. In some implementations, the ranking of a particular suggested element may be based on the content of the entire graphical user interface, previous interactions between the user and the automated assistant, third party application data available to the automated assistant if permitted from the user, vehicle data characterizing one or more operations of the vehicle, and/or any other information on which the ranking of the suggestion may be based.
In some implementations, the automated assistant can provide suggestions for rendering by third party vehicle applications, and these suggestions can be generated based on information from the OEM vehicle application. For example, a plurality of different third party applications may be accessible via the vehicle computing device and may communicate with the OEM vehicle application in order to send and/or receive data. In some implementations, the OEM vehicle application may restrict communication between other applications on the vehicle computing device. Thus, the third-party application may not be able to communicate locally with the automated assistant, but only via the vehicle computing device, rather the automated assistant may thus know that the third-party application is performing operations using data provided by the OEM vehicle application rather than by direct communication with the third-party application.
For example, when a third-party application is rendering content at a display panel of a vehicle computing device, the OEM vehicle application may generate data characterizing the content and provide the data to an automated assistant. Alternatively or additionally, the third party application may communicate with a remote computing device, such as a server, to provide data to the automated assistant (e.g., using an automated assistant Application Programming Interface (API)). The recommendation data can then be generated via an automated assistant and then shared with the OEM vehicle application and/or a remote device associated with the third party application. One or more suggestion elements may then be presented at a graphical user interface of the third-party application based on the suggestion data. In this manner, while the OEM vehicle application limits communication between the native applications to only that occurring via the vehicle computing device, the automated assistant may still provide suggestions to the user for various actions that the user may not be aware of at least the vehicle computing device and/or the vehicle.
In some implementations, the automated assistant can bypass providing suggestions related to actions that have recently been performed under the direction of the user via third party applications and/or OEM vehicle applications. For example, when the third-party application corresponds to a vehicle maintenance application and the vehicle maintenance application provides a notification indicating that a portion of the vehicle requires attention, the automated assistant may be notified of the notification via the OEM vehicle application. For example, when the vehicle maintenance application indicates that the vehicle requires gasoline and/or charging, the vehicle maintenance application may provide a notification of a nearby location to refuel the vehicle. The OEM vehicle application may generate data based on the notification and/or content rendered at the graphical user interface of the third-party application and provide the generated data to the automated assistant. The automated assistant can use the data to generate suggestions that can be ranked and/or filtered according to content that has been presented to the user.
For example, when the generated suggestion corresponds to a nearby location that refuels the vehicle, the generated suggestion may be ranked (i.e., prioritized) lower than a separate suggestion that does not correspond to a nearby location that refuels the vehicle. As a result, other suggestions regarding, for example, spoken utterances (e.g., "what is my high way people per gallon Location information. In one example, data from the OEM vehicle application may be compared with the assistant data to determine that the notification from the third party application is associated with an operating characteristic of the vehicle. Based on the determination, the automated assistant can determine when the user has previously engaged in a conversation session with the automated assistant regarding the operating characteristics of the vehicle.
For example, the user may have queried an automated assistant to find out what the appropriate tire pressure is for their vehicle. Thus, in response to receiving data from the OEM vehicle application, the automated Assistant may generate suggestions that characterize spoken utterances (such as "what is the tire pressure of my vehicle.
Other implementations may include a computer program or non-transitory computer-readable storage medium storing instructions executable by one or more processors (e.g., a Central Processing Unit (CPU), a Graphics Processing Unit (GPU), and/or a Tensor Processing Unit (TPU)) to perform a method, such as one or more of the methods described above and/or elsewhere herein. Still other implementations may include one or more computers and/or one or more robotic systems comprising one or more processors operable to execute stored instructions to perform methods such as one or more of the methods described above and/or elsewhere herein.
It should be understood that all combinations of the foregoing concepts and additional concepts described in greater detail herein are contemplated as being part of the subject matter disclosed herein. For example, all combinations of claimed subject matter appearing at the end of this disclosure are considered part of the subject matter disclosed herein.
Drawings
Fig. 1A, 1B, and 1C illustrate views of a vehicle including an OEM vehicle computing device that provides access to an automated assistant.
Fig. 2A, 2B, and 2C illustrate one or more implementations of an automated assistant that provides suggested elements at an OEM application and/or a third party application accessible via an OEM vehicle computing device that employs restrictions on communication between native applications.
Fig. 3 illustrates a system that provides an OEM vehicle computing device that includes a vehicle automation assistant that can render recommendations via an OEM vehicle application and/or a third party application and initialize actions via the OEM vehicle application and/or the third party application.
Fig. 4 illustrates a method for providing one or more suggested elements at a graphical user interface of a third party vehicle computing device and/or a third party application operating at the third party vehicle computing device.
FIG. 5 is a block diagram of an example computer system.
Detailed Description
Fig. 1A, 1B, and 1C illustrate a view 100, a view 130, and a view 140 of a vehicle 108 including an OEM vehicle computing device 104 that provides access to an automation assistant 128 that may cause suggestions to be rendered at the graphical user interface 106 of the OEM vehicle application 124 and/or third party application 126. Specifically, fig. 1A shows that the OEM vehicle computing device 104 provides a view 100 of a graphical user interface 106, one or more of which correspond at different areas to different applications and/or content that may be presented at the graphical user interface 106. The OEM vehicle computing device 104 may include one or more OEM vehicle applications 124, one or more third party applications 126, and/or an automation assistant 128. While the user 102 is seated in the vehicle 108, one or more applications accessible via the OEM vehicle computing device 104 may communicate with the particular OEM vehicle application 124 to cause certain content to be rendered at the graphical user interface 106.
For example, the OEM vehicle computing device 104 may include an OEM vehicle application 124, such as a navigation application, which may cause content to be rendered at the first region 110 of the graphical user interface 106. Alternatively or additionally, the OEM vehicle computing device 104 may include a third party application 126, such as a messaging application, which may cause other content to be rendered at the second region 114 of the graphical user interface 106. Each application providing data for rendering content at the graphical user interface 106 may communicate with a particular OEM vehicle application 124. The particular OEM vehicle application may communicate with other OEM vehicle applications 124, third party applications 126, and automation assistant 128. For example, the navigation application may provide data characterizing the upcoming navigation instruction, which may be rendered as a first graphical element 112 in the first region 110 of the graphical user interface 106. Further, the messaging application may provide other data characterizing (or indicating the content of) the incoming message, as well as other dates that may be rendered by the particular OEM vehicle application 124 as the second graphical element 116 at the graphical user interface 106.
In some implementations, a particular OEM vehicle application 124 may mediate communications between applications by generating data characterizing content provided by one or more applications of the OEM vehicle computing device 104 and providing the generated data to the automation assistant 128. For example, the generated data may characterize natural language content provided in the first graphical element 112 and other natural language content provided in the second graphical element 116. The particular OEM vehicle application 124 may provide the data so generated to the automation assistant 128, and the automation assistant 128 may use the generated data to provide additional suggestions for each respective region of the graphical user interface 106.
Fig. 1B shows a view 130 of the graphical user interface 106 that provides room for suggested elements for each region of the graphical user interface 106 based on data provided by the automated assistant 128, and the suggested elements are generated based on data from the particular OEM vehicle application 124 and based on data from the OEM vehicle application 124 that is associated with the assistant data. The vehicle application data and the assistant data can be associated or related if the vehicle application data corresponds at least in part to data associated with an interaction between the user and the automated assistant. For example, the vehicle application data may correspond to the content of a previous interaction or conversation session between the user and the automated assistant, relate to a previous action performed by the automated assistant, indicate an action associated with a location or contact linked to the user, or otherwise correspond to the assistant data. In particular, the particular OEM vehicle application 124 may provide the automation assistant 128 with data characterizing the content of the first graphical element 112. The automation assistant 128 may receive data from the OEM vehicle application 124 and generate suggested data based on the received data. In some implementations, the received data can be compared to one or more actions that can be performed by the automated assistant 128, and based on the comparison, suggested data can be generated. Additionally or alternatively, the OEM vehicle application 124 may provide other data characterizing the content of the second graphical element 116 to the automation assistant 128. The automated assistant 128 may additionally receive data to be processed for determining a correlation between other received data and one or more actions capable of being performed by the automated assistant 128. Based on the comparison, other recommendation data may be generated and provided to the OEM vehicle application 124.
In response to the OEM vehicle application 124 receiving the recommendation data from the automation assistant 128, the OEM vehicle application 124 may cause the recommendation element to be rendered at the graphical user interface 106. For example, the OEM vehicle applications 124 may include a launcher application that renders contacts characterizing the operational state of one or more applications and also initializes one or more actions of the one or more applications according to data received from the automation assistant 128. For example, the automated assistant 128 can provide suggestion data that characterizes a first suggestion element 132 that can characterize a spoken utterance that, when spoken by the user and/or another user, causes the automated assistant to initialize or perform a particular action. For example, the vehicle application may provide an indication of the selection to the automated assistant, and the automated assistant may cause another application of the vehicle computing device to perform the action. The other application may be one of a third party application (i.e., from a different source than the automated assistant and the vehicle OEM application) or an OEM vehicle application. Further, the automated assistant 128 can provide another suggestion data that characterizes the second suggestion elements 134 that can characterize a different spoken utterance that, when spoken by the user and/or another user, causes the automated assistant 128 to initialize or perform a different particular action. For example, the first suggestion element 132 may characterize a spoken utterance, such as "Assistant, what is my ETA? (assistant, what is my ETA)?
In response to the user tapping the suggestion element at the display panel 120 or providing a verbal input that includes at least a certain amount of the content of the suggestion element 132, the automated assistant can communicate the estimated time of arrival at the destination to the user. Further, the second suggestion element 134 may characterize a spoken utterance, such as "Assistant, reply to Jane". In response to the user tapping the second suggestion element 134 at the display panel 120 and/or providing verbal input that includes at least a certain amount of the content of the second suggestion element 134, the automated assistant 128 can prompt the user to provide additional content for a message to be communicated to a contact named Jane. In this manner, users may be notified that they may employ automated assistants to initialize actions of the OEM vehicle application 124 and/or third party application 126 and/or otherwise perform actions based on information provided by the vehicle application 124 and/or third party application 126.
Fig. 1C shows that the automation assistant 128 causes the launcher OEM vehicle application 124 to provide a view 140 of suggested elements based on content presented at the graphical user interface 106 for a plurality of different applications. In particular, the third suggestion element 142 may be generated by the automation assistant 128 using vehicle application data provided by the launcher OEM vehicle application 124. The launcher OEM vehicle application 124 may receive data from a plurality of different third party applications and/or other OEM vehicle applications 124 for rendering at the graphical user interface 106. The launcher OEM vehicle application 124 may generate data characterizing the content presented at the graphical user interface 106 and provide the generated data to the automation assistant 128. The automation assistant 128 may use the data received from the launcher OEM vehicle application 124 to generate recommendation data, which may be rendered in the third region 118 of the graphical user interface 106.
The suggestion data can be generated via the automated assistant 128 to provide suggestions to the user regarding a plurality of different sources of content being presented at the graphical user interface 106. In some implementations, the data generated from the launcher OEM vehicle application 124 may characterize ongoing actions being performed by the individual OEM vehicle application, as well as recently performed actions or recently presented notifications provided by the individual third party application 126. To generate a suitable suggestion for the user 102, the automated assistant 128 may determine whether any of the generated data (that characterizes or indicates content presented at the graphical user interface 106) carries any relationships with assistant data accessible to the automated assistant 128. For example, because the automation assistant 128 may be linked to the account of the user 102, the automation assistant 128 may be notified of incoming messages from a contact of the user called "Jane" to be a third party application. Based on this association or relationship between the content of the second graphical element 116 and the assistant data that also indicates the incoming message, the automated assistant 128 may generate a blank message to reply to Jane. In addition, the automated assistant 128 may also determine a relationship between the content of the first graphical element 112 and the assistant data. For example, the assistant data can characterize one or more actions that can be performed or initiated by the automated assistant 128.
The suggestion data can be generated via the automated assistant 128 to provide suggestions to the user regarding a plurality of different sources of content being presented at the graphical user interface 106. In some implementations, the data generated from the launcher OEM vehicle application 124 may characterize ongoing actions being performed by the individual OEM vehicle application, as well as recently performed actions or recently presented notifications provided by the individual third party application 126. To generate a suitable suggestion for the user 102, the automated assistant 128 may determine whether any of the generated data carries any relationships with assistant data accessible to the automated assistant 128. For example, because the automated assistant 128 may be linked to the account of the user 102, the automated assistant 128 may be notified of incoming messages from the user's known contact "Jane" that are to be third party applications. Based on this relationship between the content of the second graphical element 116 and the assistant data that also indicates the incoming message, the automated assistant 128 may generate a blank message to reply to Jane. In addition, the automated assistant 128 may also determine a relationship between the content of the first graphical element 112 and the assistant data. For example, the assistant data can characterize one or more actions that can be performed or initiated by the automated assistant 128.
Fig. 2A, 2B, and 2C illustrate one or more implementations of an automated assistant 228 that provides suggested elements at an OEM application and/or third party application accessible via the OEM vehicle computing device 204 that employs restrictions on communication between native applications. For example, as provided in the view 200 of fig. 2A, the OEM vehicle computing device 204 may include an OEM vehicle application 224, a third party application 226, and/or an automation assistant 228. The OEM vehicle computing device 204 may enforce access restrictions on the automation assistant 228, thereby limiting access of the automation assistant 228 to locally stored data of the OEM vehicle application 224 and locally stored data of the third party application 226. However, one or more of the OEM vehicle applications 224 may provide to the automated assistant 228 an amount of data regarding the operation of the vehicle 208, the OEM vehicle computing device 204, the OEM vehicle applications 224, the third party applications 226, and/or any other information that may be associated with the vehicle 208.
For example, the launcher OEM vehicle application may generate content data characterizing the content of the graphical user interface 206 rendered at the display panel 220 of the OEM vehicle computing device 204. The content data may characterize natural language content presented in the first region 210 of the graphical user interface 206. The first region 210 may include a first graphical element 212 associated with a third party application, such as a navigation application. The content data may also characterize natural language content presented in the second region 214 of the graphical user interface 206. The second region 214 may include a second graphical element 216 associated with a third party application, such as a messaging application.
To familiarize the user 202 with functionality that allows the automated assistant at 228 to initialize OEM vehicle applications 224 and/or third party applications 226, the automated assistant 228 may provide suggested elements related to such functionality. In other words, the automation assistant 228 may use the content data from the OEM vehicle application 224 to generate suggestions of spoken utterances that may be provided by the user 202 for invoking the automation assistant 228 to initiate performance of actions by another OEM vehicle application 224 and/or the third party application 226.
For example, the automated assistant 228 may use the content data to generate suggestion data corresponding to suggestions by the user to provide commands related to both the content of the first graphical element 212 and the content of the second graphical element 216. In this manner, the automated assistant 228 acts within the boundaries of the limitations implemented by the OEM vehicle computing device 204 while still providing useful advice to facilitate use of all of the functionality of the OEM vehicle computing device 204. For example, the recommendation data may characterize a spoken utterance, such as "Assistant, where is the nearest grocery store? (assistant, where the nearest grocery store. This is a suggestion that the spoken utterance may be based on the navigation application making an ongoing action that directs the user to a particular destination and that the user 202 receives a message about taking coffee during their driving of the vehicle 208. The suggestion data may be provided to a launcher OEM vehicle application, which may process the suggestion data and cause a third graphical element 214 to be presented within a third region 222 of the graphical user interface 206. As a result, the user 202 is presented with suggestions without the automated assistant 228 violating any access restrictions set forth by the OEM vehicle computing device 204, thereby allowing other instances of the automated assistant to operate on other vehicles with similar restrictions. Additionally or alternatively, the automated assistant 228 may use the content data to generate suggestion data corresponding to suggestions that the user provided commands related to only one of the content of the first graphical element 212 or the content of the second graphical element 216.
In some implementations, the automated assistant 228 can be invoked in response to the user tapping the third graphical element 216 and/or providing the identified spoken utterance to the OEM vehicle computing device 204. Further, in response to the spoken utterance, the automated assistant at 228 can initiate performance of one or more corresponding actions by the navigation application. For example, in response to the automated Assistant 228 receiving a spoken utterance, "is the nearest grocery store? (where the assistant is closest to the grocery store. The command data may characterize one or more commands generated according to an API corresponding to the navigation application. When the initiator OEM application and/or server device receives the command data, the initiator OEM application and/or server device may initiate execution of one or more commands via the navigation application and/or any other third party application 226.
In response to execution of the one or more commands being initialized, the navigation application may cause a third party application interface 242 to be provided at the graphical user interface 206, as illustrated by view 240 of FIG. 2B. Thus, although the starter OEM vehicle application sets forth the limitations, the user may provide spoken utterances to the automation assistant 228 in order to invoke the third-party application to perform one or more actions at the OEM vehicle computing device 204. To further the foregoing example, the third-party application 226 may provide content to a launcher OEM vehicle application for providing the third-party application interface 242. Further, the content may characterize the location of nearby grocery stores, details about the route currently taken by the user, and details about when the user 202 will reach the destination.
In some implementations, the launcher OEM vehicle application may generate data characterizing the content provided at the graphical user interface 206. Such generated data may be provided to the automated assistant 228, which may generate further suggestions based on recent changes to the graphical user interface 206. In particular, the generated data may characterize content provided at the third-party application interface 242, and the automation assistant 228 may use the generated data to generate other suggested data for the automation assistant 228 to initialize performance of one or more actions by the OEM vehicle application 224 and/or the third-party application 226. Further, the suggestion data may characterize one or more actions related to the content provided at the graphical user interface 206, although the one or more actions are performed by an application that is different from the navigation application and/or other applications that provide the content presented at the graphical user interface 206.
As provided in view 260 of fig. 2C, the automated assistant may cause the launcher OEM vehicle application to provide one or more suggestions 262 for invoking separate applications to perform one or more actions using different applications. The automated assistant 228 may use data characterizing previously rendered content at the graphical user interface 206 and currently rendered content at the graphical user interface 206 to generate appropriate suggestions for the user 202. For example, because the messaging application is indicated in fig. 2A as having a new message from Jane, and an ETA from the navigation application is provided at fig. 2C, the automated assistant can suggest to the user to invoke the automated assistant to send the new ETA to Jane. In particular, the suggestion data generated by the automated Assistant 228 may characterize a spoken utterance, such as "Assistant, send my new ETA to Jane (Assistant, send my new ETA to short)". The suggestion data can be provided from the automation assistant 228 to a launcher OEM vehicle application and/or server device associated with the navigation application to cause one or more suggestions 262 to be presented at the graphical user interface 206 in accordance with the suggestion data.
Fig. 3 illustrates a system 300 that provides an OEM vehicle computing device 318 that includes a vehicle automation assistant 322 that may render recommendations via an OEM vehicle application 320 and/or a third party application 332 and initiate actions via the OEM vehicle application 320 and/or the third party application 332. The system 300 may include an automated assistant 304, which may operate as part of an assistant application provided at one or more computing devices (e.g., the OEM vehicle computing device 318 and/or the server device 302). The user may interact with the automated assistant 304 via an assistant interface, which may be a microphone, a camera, a touch screen display, a user interface, and/or any other device capable of providing an interface between the user and an application.
For example, a user may initialize the automated assistant 304 by providing verbal, textual, and/or graphical input to an assistant interface (e.g., an assistant interface of the OEM vehicle computing device 318 and/or an assistant interface of any other client device) to cause the automated assistant 304 to perform a function (e.g., provide data, control peripherals, access agents, generate input and/or output, etc.). The OEM vehicle computing device 318 may include a display device, which may be a display panel that includes a touch interface for receiving touch input and/or gestures to allow a user to control applications of the OEM vehicle computing device 318 via the touch interface. In some implementations, the OEM vehicle computing device 318 may lack a display device, providing audible user interface output, rather than graphical user interface output; in such an arrangement, the vehicle computing device 318 may be coupled or connected to an external display device to render the graphical user interface described herein. Further, the OEM vehicle computing device 318 may provide a user interface, such as a microphone, for receiving spoken natural language input from the user. In some implementations, the OEM vehicle computing device 318 may include a touch interface and may be without a camera or include a camera, but may optionally include one or more other sensors.
The OEM vehicle computing device 318 and/or other third party server device 350 may communicate with the server device 302 over a network 340, such as the internet. Additionally, the OEM vehicle computing device 318 and other client devices may communicate with each other over a Local Area Network (LAN), such as a Wi-Fi network. The automation assistant 322 may offload computing tasks to the server device 302 in order to conserve computing resources at the OEM vehicle computing device 318. For example, the server device 302 may host the automated assistant 304, and the OEM vehicle computing device 318 may communicate input received at one or more assistant interfaces to the server device 302. However, in some implementations, the automation assistant 304 may be hosted at the OEM vehicle computing device 318 as a client automation assistant 322.
In various implementations, all or less than all aspects of automated assistant 304 may be implemented on OEM vehicle computing device 318. In some of those implementations, aspects of the automated assistant 304 are implemented via a client automated assistant 322 of the OEM vehicle computing device 318 and may interface with the server device 302, which may implement other aspects of the automated assistant 304. The server device 302 can optionally serve multiple users and their associated assistant applications via multiple threads. In implementations in which all or less than all aspects of the automation assistant 304 are implemented via the client automation assistant 322 at the OEM vehicle computing device 318, the client automation assistant 322 may be an application separate from the operating system of the OEM vehicle computing device 318 (e.g., installed "on top of" the operating system) or may alternatively be implemented directly by the operating system of the OEM vehicle computing device 318 (e.g., an application considered to be the operating system, but integrated with the operating system).
In some implementations, the automation assistant 304 and/or the client automation assistant 322 may include an input processing engine 306 that may employ a number of different modules to process input and/or output of the OEM vehicle computing device 318 and/or the server device 302. For example, the input processing engine 306 can include a speech processing engine 308 that can process audio data received at the assistant interface to identify text contained in the audio data. The audio data may be transmitted from, for example, the OEM vehicle computing device 318 to the server device 302 in order to conserve computing resources at the OEM vehicle computing device 318.
The process for converting audio data to text may include a speech recognition algorithm that may employ a neural network and/or a statistical model to identify sets of audio data corresponding to words or phrases. The text converted from the audio data may be parsed by the data parsing engine 310 and made available to the automated assistant as text data that may be used to generate and/or identify command phrases, intents, actions, slot values, and/or any other content specified by the user. In some implementations, the output data provided by the data parsing engine 310 may be provided to the parameters module 312 to determine whether the user provided input corresponding to a particular intent, action, and/or routine that can be performed by the automated assistant 304 and/or an application or agent that can be accessed via the automated assistant 304. For example, the assistant data 316 may be stored as vehicle data 324 at the server device 302 and/or the OEM vehicle computing device 318, and may include data defining one or more actions capable of being performed by the automated assistant 304 and/or the client automated assistant 322, as well as parameters necessary to perform the actions.
In some implementations, the automation assistant 304 may be accessible via the OEM vehicle computing device 318, which may limit local communications between applications accessible at the OEM vehicle computing device 318. The automation assistant 304 may be operable to provide recommendations for invoking the automation assistant 304 to initialize the OEM vehicle application 320, the third party application 332, and/or the client device to perform one or more actions. The automated assistant 304 may be accessible via an OEM vehicle computing device 318, which OEM vehicle computing device 318 may provide access to an instance of the automated assistant 322 in communication with the server device 302. Additionally or alternatively, the automated assistant 304 may be provided at the OEM vehicle computing device 318.
The vehicle computing device 318 may operate the application interaction engine 334 to limit data transfer between the automated assistant 322 and the third-party application 332 and/or between the automated assistant 322 and the OEM vehicle application 320. The application interaction engine 334 can send and/or receive data from various applications at the OEM vehicle computing device 318 and determine when and/or how much data to share with other applications at the OEM vehicle computing device 318. For example, the third-party application 332 may be available at the OEM vehicle computing device 318, and the third-party application 332 may communicate with the third-party server device 350. The third party server device 350 can process requests provided via the OEM vehicle computing device 318 using the incoming request engine 354 and can respond to the requests using the command engine 356.
In some implementations, the application state engine 352 of the third party server device 350 can generate server data 358, which can characterize the state of one or more third party applications 332. Further, because the third-party application 332 may be associated with the user's account, and the account may also be associated with the automated assistant 304 (with the user's previous permissions), data may be shared between the third-party server device 350 and the server device 302. For example, changes in application state determined by the application state engine 352 and/or operations performed by one or more applications may be communicated to the automated assistant 304 in order to bring the automated assistant 304 into the attention of one or more actions performed by the third-party application 332. The third-party interaction engine 326 may receive data from the third-party server device 350, the OEM vehicle computing device 318, the client device, and/or any other device or apparatus to provide contextual data for the automated assistant 304.
The suggestion engine 328 of the automated assistant 304 can use the context data to generate suggestions regarding related actions that can be initiated by the automated assistant 304. Further, suggestion data characterizing suggestions may be stored as assistant data 316 and processed by suggestion ranking engine 336. Suggestion ranking engine 336 may rank suggestions based at least in part on context data. Further, in some implementations, suggestion ranking engine 336 may be ranked using context data to prevent suggestions of actions that have been recently performed by the application and/or are currently being performed by the application.
In some implementations, suggestions can be ranked and/or presented according to contextual data, which can include details of the user's route. For example, the context data may indicate whether the user is currently driving on a portion of a route that lasts X minutes and/or Y miles. In some implementations, when the portion of the route satisfies the time and/or distance threshold, the suggestion engine 328 can cause one or more suggestion elements to be presented at a graphical user interface of the OEM vehicle computing device 318. However, when the portion of the route does not satisfy the time and/or distance threshold, suggestion engine 328 may bypass causing the graphical user interface to present one or more suggestion elements.
Fig. 4 illustrates a method 400 for providing one or more suggested elements at a graphical user interface of a third party vehicle computing device and/or a third party application operating at the third party vehicle computing device. Method 400 may be performed by one or more computing devices, applications, and/or any other apparatus or module capable of providing suggestions at a user interface. The method 400 may include an operation 402 including receiving vehicle application data characterizing content rendered at a display panel of a vehicle computing device. The vehicle computing device may operate according to restrictions that limit local communication between applications accessible via the vehicle computing device.
For example, the vehicle computing device may include an OEM third party vehicle application, one or more other third party applications, and/or an automated assistant. The automated assistant may be remote from the vehicle computing device. Thus, the vehicle computing device may limit communication between the automated assistant and one or more other third-party applications. For example, when the vehicle computing device includes a third-party navigation application and/or a third-party messaging application, the applications may be limited to communicating directly with the automated assistant and instead limited to communicating optionally through the vehicle application only via the vehicle computing device. However, the OEM vehicle application may generate vehicle application data that may characterize or indicate content being rendered at the display panel of the vehicle computing device. Alternatively or additionally, the OEM vehicle application may generate vehicle application data that characterizes one or more operations performed by one or more other third party applications, the vehicle, and/or any other devices or modules that may be associated with the vehicle and/or the vehicle computing device. Limiting direct communication access between automated assistants and other third party applications may help maintain the integrity of vehicle systems, which may be important for vehicle safety and reliability.
The method 400 may also include an operation 404 of determining a relationship between the received vehicle application data and assistant data associated with the automated assistant. For example, operation 404 may include determining whether the vehicle application data characterizes any information that is already the subject of one or more conversation sessions between the user and the automated assistant. Alternatively or additionally, operation 404 may include determining whether the vehicle application data characterizes any information that the user has accessed using one or more computing devices that provide access to the automated assistant. Access to such information may be provided with permission from the user in order to protect information that the user does not wish to be accessed by other devices and/or people. Alternatively or additionally, operation 404 may further include determining whether the vehicle application data and the assistant data characterize information that may be associated with data types and/or subjective information. For example, a relationship between the vehicle application data and the assistant data may be identified when the vehicle application data indicates that an incoming call was received at the vehicle computing device from a particular person and the automated assistant data indicates that the user has previously invoked the automated assistant to answer the call from the same particular person.
The method 400 may also include an optional operation 406 of determining whether the (vehicle) application data characterizes a past action. The past action may be an action that has been performed within a period of time before the vehicle application data was received (e.g., providing a notification, sending data, accessing data, generating data, etc.). In some implementations, the time period can be a threshold time period that is static or dynamic in accordance with characteristics of the user's interaction with the vehicle computing device and/or the user with the automated assistant. As an example, a third party application available at the vehicle computing device may provide a notification indicating that a fluid sensor of the vehicle is in an alert state. The notification may be considered a past action because the notification is provided at a graphical user interface rendered at the display panel within a threshold period of time of receiving the vehicle application data. In some implementations, the time at which the notification is presented can be determined based on time information characterized by the vehicle application data. The automated assistant may access an application for tracking certain attributes of the vehicle, and thus may also know the information characterized by the notification about the fluid sensor. However, depending on when the notification is presented at the display panel of the vehicle computing device, the automated assistant may or may not bypass causing the notification regarding the fluid sensor to appear at the display panel.
When the application data characterizes the past action at operation 406, the method 400 may proceed to operation 408, which may include generating another suggestion data that avoids suggesting the past action. As an example, when a third party application provides a notification related to a fluid sensor, another recommendation data may avoid recommending obtaining information about the state of the fluid sensor by providing one or more recommendations that do not include information requesting a specification of the state of the fluid sensor. Rather, the automated assistant can generate recommendation data characterizing the spoken utterance for requesting information regarding purchasing of a fluid corresponding to the fluid sensor, sending a message including information detailing a state of the fluid sensor, placing a call to a business performing maintenance associated with the fluid sensor, and/or any other request different from the request detailing the information of the state of the fluid sensor.
When it is determined at operation 406 that the application data does not characterize the past action, the method 400 may proceed to operation 410. Operation 410 may include generating recommendation data based on a relationship between the vehicle application data and the assistant data. For example, when the graphical user interface at the third-party application includes content characterizing a route to a particular destination and the automated assistant has not provided a notification related to the fluid sensor within a threshold period of time, the automated assistant can provide suggested data corresponding to the notification for the fluid sensor. The recommendation data may characterize natural language content, such as a spoken utterance, that, when spoken by a user, causes the automated assistant to provide information related to a state of the fluid sensor. For example, the spoken utterance may be "Assistant, what is the status of the fluid sensor? (assistant, what is the state of the fluid sensor)?
From operation 410 and/or operation 408, the method 400 may advance to operation 412, which may include determining a priority of the suggested data and/or the other suggested data based on a relationship between the vehicle application data and the assistant data. In some implementations, operation 412 may be an optional operation. In some implementations, the strength of correlation between the beautiful vehicle application data and the assistant data can be used to determine a priority of the recommendation data. For example, a correlation of vehicle application data characterizing natural language content explicitly included in a dialog session between an automated assistant and a user may be characterized as having a stronger correlation than another correlation between the vehicle application data and assistant data when a past dialog session between the user and the automated assistant results in an action characterized by the natural language content.
From operation 412, the method 400 may advance to operation 414, which may include causing the congestion suggestion element to be rendered by the third party application based on the suggestion data. Optionally, the suggested elements may be rendered by a vehicle application. Causing the suggested element to be rendered by the vehicle application may include providing the action data from the automated assistant to the vehicle application. The action data may indicate an action to be performed by the vehicle application when selecting the suggested element, and may include, for example, parameters for performance of the action associated with the suggested element. The suggestion element may be a selectable element that may be selected by a user tapping the display panel at a location where the suggestion element is presented and/or by a user providing a spoken utterance that includes at least a certain amount of natural language content included in the suggestion element. When a suggestion element is rendered at the display panel, the method 400 may proceed to optional operation 416 where it is determined whether the rendered suggestion element has been selected within a particular time period. In some embodiments, the action associated with the suggested element may be performed by one of the OEM vehicle application or a third party application based on the action data. In situations where third party applications are not expected to access critical vehicle systems, for example, in an autonomous vehicle, access to the sensor system or navigation system may be limited to the vehicle's native application, such that the native OEM vehicle application performing the action may improve security. In other embodiments, the action data may include a unique ID number provided by the automated assistant; the selection of the suggestion element by the user may cause the vehicle application to cause the automated assistant to perform an action associated with the unique ID number of the action data of the suggestion element. Causing the automated assistant to execute the application may improve the privacy of the user because third party applications or vehicle-local OEM applications cannot access information about the user or about actions performed by the automated assistant based on the correlation or association between the vehicle application data and the assistant data. Accordingly, security can be improved for the user.
From operation 416, the method may proceed to optional operation 418 when the rendered suggested element is selected within a particular time period. Optional operation 418 may include assigning a priority to the suggested data according to the suggested selection. However, if the user does not select a suggestion within a certain period of time, the method may proceed from operation 416 to operation 420. Operation 420 may include assigning a priority to the suggested data based on the non-selection of the suggested element. In some implementations, the priority of the suggested data may be increased in response to the user selecting the suggested element and/or the priority of the suggested data may be decreased in response to the user not selecting the suggested element within a particular time period. In this way, when the user interacts with the vehicle computing device, the suggestions may be ranked according to their relevance to the user and whether the user has confirmed content corresponding to the suggestion data. The method 400 may cycle according to new vehicle application data rendered by third party vehicle applications in order to facilitate various functions at the vehicle and/or vehicle computing device, thereby also facilitating more efficient use of the vehicle and/or vehicle computing device.
Fig. 5 is a block diagram of an example computer system 510. Computer system 510 typically includes at least one processor 514 that communicates with a number of peripheral devices via a bus subsystem 512. These peripheral devices may include a storage subsystem 524 (including, for example, memory 525 and file storage subsystem 526), a user interface output device 520, a user interface input device 522, and a network interface subsystem 516. The input and output devices allow a user to interact with computer system 510. Network interface subsystem 516 provides an interface to external networks and is coupled to corresponding interface devices in other computer systems.
The user interface input devices 522 may include a keyboard, a pointing device such as a mouse, trackball, touchpad, or tablet, a scanner, a touch screen incorporated into a display, an audio input device such as a voice recognition system, a microphone, and/or other types of input devices. In general, use of the term "input device" is intended to include all possible types of devices and ways to input information into computer system 510 or onto a communication network.
User interface output devices 520 may include a display subsystem, a printer, a facsimile machine, or a non-visual display such as an audio output device. The display subsystem may include a Cathode Ray Tube (CRT), a flat panel device such as a Liquid Crystal Display (LCD), a projection device, or some other mechanism for creating a visible image. The display subsystem may also provide non-visual displays, such as via audio output devices. In general, use of the term "output device" is intended to include all possible types of devices and ways to output information from computer system 510 to a user or to another machine or computer system.
These software modules are typically executed by processor 514 alone or in combination with other processors. Memory 525 used in storage subsystem 524 may include a number of memories, including a main Random Access Memory (RAM)530 for storing instructions and data during program execution and a Read Only Memory (ROM)532 in which fixed instructions are stored. File storage subsystem 526 may provide permanent storage for program and data files, and may include a hard disk drive, a floppy disk drive along with associated removable media, a CD-ROM drive, an optical disk drive, or removable media cartridges. Modules implementing the functionality of certain implementations may be stored by file storage subsystem 526 in storage subsystem 524, or in other machines accessible by processor 514.
Where the systems described herein collect or make available personal information about a user (or often referred to herein as a "participant"), the user may be provided with an opportunity to control whether programs or features collect user information (e.g., information about the user's social network, social actions or activities, profession, the user's preferences, or the user's current geographic location) or whether and/or how to receive content from a content server that may be more relevant to the user. Also, certain data may be processed in one or more ways before being stored or used, thereby removing personally identifiable information. For example, the identity of the user may be processed such that personally identifiable information cannot be determined for the user, or the geographic location of the user may be summarized where geographic location information is obtained (such as to a city, zip code, or state level) such that a particular geographic location of the user cannot be determined. Thus, the user may control how information is collected and/or used with respect to the user.
While several implementations have been described and illustrated herein, various other means and/or structures for performing the functions described herein and/or obtaining the results and/or one or more advantages described herein may be utilized, and each of such variations and/or modifications is considered to be within the scope of the implementations described herein. More generally, all parameters, dimensions, materials, and configurations described herein are meant to be exemplary, and the actual parameters, dimensions, materials, and/or configurations will depend upon the specific application or applications for which the present teachings is/are used. Those skilled in the art will recognize, or be able to ascertain using no more than routine experimentation, many equivalents to the specific implementations described herein. It is, therefore, to be understood that the foregoing implementations are presented by way of example only and that, within the scope of the appended claims and equivalents thereto, implementations may be practiced otherwise than as specifically described and claimed. Implementations of the present disclosure are directed to each individual feature, system, article, material, kit, and/or method described herein. In addition, any combination of two or more such features, systems, articles, materials, kits, and/or methods, if such features, systems, articles, materials, kits, and/or methods are not mutually inconsistent, is included within the scope of the present disclosure.
In some implementations, a method implemented by one or more processors is set forth as including operations such as receiving, via a vehicle application operating while a user is in a vehicle, vehicle application data corresponding to content rendered at a graphical user interface of the vehicle application, wherein the graphical user interface is displayed at a display panel in communication with a vehicle computing device of the vehicle. The method may also include, in response to receiving the vehicle application data, determining that the vehicle application data is associated with assistant data available via an automated assistant, wherein the automated assistant is accessible via the vehicle computing device. The method may also generate suggestion data in response to determining that the vehicle application data is associated with the assistant data, wherein the suggestion data identifies an action associated with the assistant data and the vehicle application data, and the suggestion data characterizes natural language content that is different from content being rendered at the display panel. The method may also include determining a priority of the suggestion data relative to priority data associated with previously generated suggestion data based on the suggestion data, wherein the previously generated suggestion data corresponds to one or more suggestion elements previously rendered at a graphical user interface of the vehicle application. The method may further comprise, when the priority of the suggested data relative to the priority data indicates that the suggested data takes precedence over other suggested data: causing a particular suggestion element to be rendered at a graphical user interface of the vehicle application based on the suggestion data and while the user is in the vehicle, wherein the particular suggestion element includes the natural language content.
In some implementations, the priority data is based on one or more prior instances in which the user and/or one or more other users selected the one or more suggested elements while the user and/or the one or more other users were riding the vehicle. In some implementations, the method may further include determining an estimated time of arrival of the user to a destination location, wherein determining the priority of the suggested data relative to priority data associated with other suggested data is based at least in part on the estimated time of arrival of the user to the destination location. In some implementations, the method may further include, when the priority of the suggested data relative to the priority data indicates that the suggested data takes precedence over other suggested data: after causing the particular suggestion element to be rendered at a graphical user interface of the vehicle application, determining that the particular suggestion element is selected, and in response to determining that the particular suggestion element is selected, causing a priority of the suggestion data to be modified.
In some implementations, the graphical user interface of the vehicle application includes a first region that includes the content and a second region that includes other content, and wherein causing the particular suggested element to be rendered at the graphical user interface of the vehicle application includes: causing the particular suggested element to be rendered at a first region of the graphical user interface and other suggested elements to be rendered at a second region of the graphical user interface, wherein the other suggested elements are based at least in part on the other content. In some implementations, the vehicle application data also corresponds to the other content, and generating the recommendation data includes identifying other actions associated with the other content. In some implementations, the method may further include generating additional suggestion data based on the content provided in the first region of the graphical user interface and based on other content provided in the second region of the graphical user interface, wherein the additional suggestion data identifies additional actions associated with the assistant data and the vehicle application data, and the suggestion data characterizes other natural language content that is different from the content and the other content.
In some implementations, the graphical user interface of the vehicle application includes a third region corresponding to the automated assistant, and the method further includes: causing a separate suggestion element to be rendered at a third region of a graphical user interface of the vehicle application based on the additional suggestion data and while the user is in the vehicle, wherein the separate suggestion element includes the other natural language content. In some implementations, causing the particular suggestion element to be rendered at a graphical user interface of the vehicle application based on the suggestion data includes providing action data from the automated assistant to the vehicle application. In some implementations, the particular suggestion element is rendered by the vehicle application, and natural language content of the suggestion element characterizes a spoken utterance that, when spoken by the user to the vehicle computing device, causes the action to be initiated via the automated assistant. In some implementations, the method may further include, when the priority of the suggested data relative to the priority data indicates that the suggested data takes precedence over other suggested data: determining that the user has provided a verbal input corresponding to natural language content of the suggested element, and in response to determining that the user has provided the verbal input, causing the automated assistant to initialize the action, wherein the action is performed by a separate vehicle application in response to the automated assistant initializing the action.
In some implementations, the automated assistant is provided by a source that generates the priority data, the vehicle application data is generated by a third party source that is different from the source, and the separate vehicle application is provided by a source that is separate from the source and the third party source. In some implementations, the vehicle application is a navigation application provided by the source, and the separate vehicle application is a communication and/or media application provided by the separate source. In some implementations, the automated assistant is provided by a source that generated the priority data, and the vehicle application data is generated by a third party source that is different from the source. In some implementations, the automated assistant is remote from a vehicle computing device of the vehicle.
In other implementations, a method implemented by one or more processors is set forth as including operations such as determining, by a vehicle application of a vehicle computing device, that a third party application is providing content via a graphical user interface rendered at a display panel of the vehicle computing device, wherein the vehicle application is accessible by a user via the vehicle computing device and the vehicle computing device is part of a vehicle that navigates the user to a destination. In some implementations, the method can further include generating vehicle application data characterizing at least a portion of the content provided by the third-party application based on a determination that the graphical user interface includes the content. In some implementations, the method may further include providing, by a vehicle application of the vehicle computing device, the vehicle application data to an automated assistant, wherein the automated assistant is also accessible by the user via the vehicle computing device. In some implementations, the method may further include, based on providing the vehicle application data to the automated assistant, causing the automated assistant to provide suggestion data generated based on a correspondence between assistant data and the vehicle application data, wherein the assistant data is associated with an account of the user. In some implementations, the method may further include receiving, by the vehicle application, the suggestion data from the automated assistant, wherein the suggestion data characterizes natural language content that, when spoken by the user to the vehicle computing device, causes the automated assistant to initiate performance of an action by the third-party application. In some implementations, the method may further include, in response to receiving the suggestion data from the automated assistant, causing the third-party application to render the natural language content at a graphical user interface of the third-party application, wherein the natural language content is rendered at the graphical user interface while the content is rendered at the graphical user interface and the vehicle navigates the user to the destination.
In some implementations, the method may further include, after the natural language content is rendered at the graphical user interface: determining that the user and/or another user has provided a spoken utterance that includes at least some of the natural language content rendered at the graphical user interface, and in response to determining that the user and/or the other user has provided the spoken utterance, causing the automated assistant to initiate performance of an action by the third-party application. In some implementations, the method may further include determining, in response to receiving the suggestion data, an amount of time remaining and/or a distance remaining for the vehicle to navigate the user to the destination; and determining whether an amount of time remaining for the vehicle to navigate the user to the destination and/or the distance remaining satisfies a threshold, wherein when the amount of time remaining and/or the distance remaining satisfies the threshold, execution causes the third-party application to render the natural language content at a graphical user interface of the third-party application. In some implementations, the method can further include providing updated content data characterizing the additional data being presented at the graphical user interface.
In other implementations, a method implemented by one or more processors is set forth as including operations such as providing, from a third party application to a vehicle application, content data characterizing content to be rendered at a display panel of a vehicle computing device included in a vehicle in which a user is driving to a destination. The method may also include causing the vehicle application to provide at least a portion of the content data to an automated assistant based on providing the content data to the vehicle application, wherein the automated assistant is accessible by the user via one or more interfaces of the vehicle computing device, and wherein the vehicle computing device limits accessibility of the content data to the automated assistant. The method may also include receiving suggestion data from the vehicle application, the suggestion data generated based at least in part on the automated assistant receiving at least the portion of the content data, wherein the suggestion data characterizes natural language content that, when included in a spoken utterance from the user to the automated assistant, causes the automated assistant to initialize performance of one or more actions by the third-party application, the vehicle application, and/or another third-party application. The method may cause a display panel of the vehicle to calculate to render the natural language content at a graphical user interface in response to receiving the suggestion data from the vehicle application. The method may further include, when the user provides the spoken utterance to the automated assistant via an interface of the vehicle computing device: causing the automated assistant to initiate performance of the one or more actions by the third-party application, the vehicle application, and/or another third-party application.
In some implementations, at least the portion of the content data is selected for provision to the automated assistant based on rendered data displayed at a display panel of the vehicle computing device. In some implementations, the method can further include, when the user provides the spoken utterance to the automated assistant via an interface of the vehicle computing device: providing, via a server device in communication with the third-party application, the operational state of the one or more actions to another computing device separate from the vehicle computing device.
Claims (25)
1. A method implemented by one or more processors, the method comprising:
receiving, via a vehicle application operating while a user is in a vehicle, vehicle application data corresponding to content rendered at a graphical user interface of the vehicle application, wherein the graphical user interface is displayed at a display panel in communication with a vehicle computing device of the vehicle;
in response to receiving the vehicle application data, determining that the vehicle application data is associated with assistant data available via an automated assistant, wherein the automated assistant is accessible via the vehicle computing device;
generate advisory data in response to determining that the vehicle application data is associated with the assistant data,
wherein the suggestion data identifies an action associated with the assistant data and the vehicle application data, and the suggestion data characterizes natural language content that is different from content being rendered at the display panel;
determining a priority of the suggested data relative to priority data associated with previously generated suggested data based on the suggested data,
wherein the previously generated suggestion data corresponds to one or more suggestion elements previously rendered at a graphical user interface of the vehicle application; and
when the priority of the suggested data relative to the priority data indicates that the suggested data is prioritized over other suggested data:
causing a particular suggestion element to be rendered at a graphical user interface of the vehicle application based on the suggestion data and while the user is in the vehicle, wherein the particular suggestion element includes the natural language content.
2. A method according to claim 1, wherein the priority data is based on one or more previous instances in which the user and/or one or more other users selected the one or more suggested elements while the user and/or the one or more other users were riding the vehicle.
3. The method of any preceding claim, further comprising:
determining an estimated time of arrival of the user to a destination location, wherein determining a priority of the suggested data relative to priority data associated with other suggested data is based at least in part on the estimated time of arrival of the user to the destination location.
4. The method of any preceding claim, further comprising:
when the priority of the suggested data relative to the priority data indicates that the suggested data is prioritized over the other suggested data:
after causing the particular suggestion element to be rendered at a graphical user interface of the vehicle application, determining that the particular suggestion element is selected, an
Causing the priority of the suggested data to be modified in response to determining that the particular suggested element is selected.
5. The method according to any one of the preceding claims,
wherein the graphical user interface of the vehicle application comprises a first region containing the content and a second region containing other content, an
Wherein causing the particular suggested element to be rendered at a graphical user interface of the vehicle application comprises:
causing the particular suggestion element to be rendered at a first region of the graphical user interface and another suggestion element to be rendered at a second region of the graphical user interface, wherein the other suggestion element is based at least in part on the other content.
6. The method of claim 5, wherein the first and second light sources are selected from the group consisting of,
wherein the vehicle application data further corresponds to the other content, an
Wherein generating the suggestion data comprises identifying another action associated with the other content.
7. The method of claim 5 or 6, further comprising:
generating additional suggestion data based on the content provided in the first region of the graphical user interface and based on other content provided in the second region of the graphical user interface,
wherein the additional suggestion data identifies additional actions associated with the assistant data and the vehicle application data, and the suggestion data characterizes other natural language content that is different from the content and the other content.
8. The method of claim 7, wherein the graphical user interface of the vehicle application includes a third region corresponding to the automated assistant, and the method further comprises:
causing a separate suggestion element to be rendered at a third region of a graphical user interface of the vehicle application based on the additional suggestion data and while the user is in the vehicle, wherein the separate suggestion element includes the other natural language content.
9. The method of any of the preceding claims, wherein causing the particular suggestion element to be rendered at a graphical user interface of the vehicle application based on the suggestion data comprises providing action data from the automated assistant to the vehicle application.
10. The method of any of the preceding claims, wherein the particular suggestion element is rendered by the vehicle application and natural language content of the suggestion element characterizes a spoken utterance that, when spoken by the user to the vehicle computing device, causes the action to be initiated via the automated assistant.
11. The method of claim 10, further comprising:
when the priority of the suggested data relative to the priority data indicates that the suggested data is prioritized over the other suggested data:
determining that the user has provided spoken input corresponding to natural language content of the suggested element, an
In response to determining that the user has provided the verbal input, causing the automated assistant to initialize the action, wherein the action is performed by a separate vehicle application in response to the automated assistant initializing the action.
12. The method of claim 11, wherein the automated assistant is provided by a source that generates the priority data, the vehicle application data is generated by a third party source different from the source, and the separate vehicle application is provided by a source separate from the source and the third party source.
13. The method of claim 12, wherein the vehicle application is a navigation application provided by the source and the separate vehicle application is a communication and/or media application provided by the separate source.
14. The method of any preceding claim, wherein the automated assistant is provided by a source that generated the priority data, and the vehicle application data is generated by a third party source different from the source.
15. The method of any preceding claim, wherein the automated assistant is remote from a vehicle computing device of the vehicle.
16. A method implemented by one or more processors, the method comprising:
determining, by a vehicle application of a vehicle computing device, that a third party application is providing content via a graphical user interface rendered at a display panel of the vehicle computing device,
wherein the vehicle application is accessible by a user via the vehicle computing device and the vehicle computing device is part of a vehicle that navigates the user to a destination;
based on determining that the graphical user interface includes the content, generating vehicle application data that characterizes at least a portion of the content provided by the third-party application;
providing, by a vehicle application of the vehicle computing device, the vehicle application data to an automated assistant, wherein the automated assistant is also accessible by the user via the vehicle computing device;
based on providing the vehicle application data to the automated assistant, causing the automated assistant to provide suggestion data generated based on a correspondence between assistant data and the vehicle application data, wherein the assistant data is associated with an account of the user;
receiving, by the vehicle application, the suggestion data from the automated assistant, wherein the suggestion data characterizes natural language content that, when spoken by the user to the vehicle computing device, causes the automated assistant to initiate performance of an action by the third-party application;
in response to receiving the suggestion data from the automated assistant, cause the third-party application to render the natural language content at a graphical user interface of the third-party application,
wherein the natural language content is rendered at the graphical user interface while the content is rendered at the graphical user interface and the vehicle navigates the user to the destination.
17. The method of claim 16, further comprising:
after the natural language content is rendered at the graphical user interface:
determining that the user and/or another user has provided a spoken utterance including at least some of the natural language content rendered at the graphical user interface, an
In response to determining that the user and/or the other user has provided the spoken utterance, cause the automated assistant to initiate performance of an action by the third-party application.
18. The method of claim 16 or 17, further comprising:
in response to receiving the suggestion data, determining an amount of time remaining and/or a distance remaining for the vehicle to navigate the user to the destination; and
determining whether the amount of time remaining and/or the distance remaining for the vehicle to navigate the user to the destination satisfies a threshold,
wherein when the amount of time remaining and/or the distance remaining satisfies the threshold, execution causes the third-party application to render the natural language content at a graphical user interface of the third-party application.
19. The method of any of claims 16 to 18, further comprising:
providing updated content data characterizing the additional data being presented at the graphical user interface.
20. A method implemented by one or more processors, the method comprising:
providing, from a third-party application to a vehicle application, content data characterizing content to be rendered at a display panel of a vehicle computing device, wherein the vehicle computing device is included in a vehicle in which a user is driving to a destination;
based on providing the content data to the vehicle application, cause the vehicle application to provide at least a portion of the content data to an automated assistant,
wherein the automated assistant is accessible by the user via one or more interfaces of the vehicle computing device, an
Wherein the vehicle computing device limits accessibility of the content data to the automated assistant;
receiving suggestion data from the vehicle application, the suggestion data generated based at least in part on the automated assistant receiving at least the portion of the content data,
wherein the suggestion data characterizes natural language content that, when included in a spoken utterance from the user to the automated assistant, causes the automated assistant to initiate performance of one or more actions by the third-party application, the vehicle application, and/or another third-party application;
in response to receiving the suggestion data from the vehicle application, causing a display panel of the vehicle computing to render the natural language content at a graphical user interface; and
when the user provides the spoken utterance to the automated assistant via an interface of the vehicle computing device:
causing the automated assistant to initiate performance of the one or more actions by the third-party application, the vehicle application, and/or another third-party application.
21. The method of claim 18, wherein at least the portion of the content data is selected for provision to the automated assistant based on rendered data displayed at a display panel of the vehicle computing device.
22. The method of claim 20 or 21, further comprising:
when the user provides the spoken utterance to the automated assistant via an interface of the vehicle computing device:
providing, via a server device in communication with the third-party application, the operational state of the one or more actions to another computing device separate from the vehicle computing device.
23. A computer program product comprising instructions which, when executed by one or more processors, cause the one or more processors to carry out the method according to any one of the preceding claims.
24. A computer-readable storage medium comprising instructions that, when executed by one or more processors, cause the one or more processors to perform the method of any one of claims 1-22.
25. A system comprising one or more processors configured to perform the method of any one of claims 1-22.
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/US2019/031498 WO2020226650A1 (en) | 2019-05-09 | 2019-05-09 | Automated assistant suggestions for third-party vehicle computing devices with restricted architecture |
Publications (1)
Publication Number | Publication Date |
---|---|
CN113424151A true CN113424151A (en) | 2021-09-21 |
Family
ID=66625397
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201980091586.8A Pending CN113424151A (en) | 2019-05-09 | 2019-05-09 | Automated assistant suggestion for third party vehicle computing devices with restricted architecture |
Country Status (7)
Country | Link |
---|---|
US (2) | US10996925B2 (en) |
EP (1) | EP3752892A1 (en) |
JP (1) | JP7341243B2 (en) |
KR (1) | KR20210145283A (en) |
CN (1) | CN113424151A (en) |
AU (2) | AU2019444479A1 (en) |
WO (1) | WO2020226650A1 (en) |
Families Citing this family (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP6939376B2 (en) * | 2017-10-10 | 2021-09-22 | トヨタ自動車株式会社 | Autonomous driving system |
US11788851B2 (en) * | 2020-06-11 | 2023-10-17 | Apple Inc. | User interfaces for customized navigation routes |
US11959764B2 (en) * | 2021-04-02 | 2024-04-16 | Google Llc | Automated assistant that detects and supplements various vehicle computing device capabilities |
US11967321B2 (en) * | 2021-10-06 | 2024-04-23 | Google Llc | Automated assistant control of non-assistant applications via identification of synonymous term and/or speech processing biasing |
Family Cites Families (20)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7702731B2 (en) * | 2006-08-17 | 2010-04-20 | International Business Machines Corporation | System, method and program for facilitating an electronic chat session |
US20080082257A1 (en) * | 2006-09-05 | 2008-04-03 | Garmin Ltd. | Personal navigational device and method with automatic call-ahead |
US8548509B2 (en) * | 2008-12-12 | 2013-10-01 | Qualcomm Incorporated | System and method of automatically generating and sending text messages |
US9317834B2 (en) | 2011-06-30 | 2016-04-19 | Microsoft Technology Licensing, Llc | User computing device with personal agent program for recommending meeting a friend at a service location based on current location, travel direction, and calendar activity |
US9652556B2 (en) | 2011-10-05 | 2017-05-16 | Google Inc. | Search suggestions based on viewport content |
WO2014172369A2 (en) * | 2013-04-15 | 2014-10-23 | Flextronics Ap, Llc | Intelligent vehicle for assisting vehicle occupants and incorporating vehicle crate for blade processors |
US20140108307A1 (en) * | 2012-10-12 | 2014-04-17 | Wipro Limited | Methods and systems for providing personalized and context-aware suggestions |
US9798799B2 (en) * | 2012-11-15 | 2017-10-24 | Sri International | Vehicle personal assistant that interprets spoken natural language input based upon vehicle context |
KR20150122561A (en) * | 2014-04-23 | 2015-11-02 | 삼성전자주식회사 | Devices and Methods of processing an incoming call in the devices |
US10116748B2 (en) * | 2014-11-20 | 2018-10-30 | Microsoft Technology Licensing, Llc | Vehicle-based multi-modal interface |
US10104023B2 (en) * | 2015-04-16 | 2018-10-16 | Oath Inc. | Location sharing |
US10504509B2 (en) | 2015-05-27 | 2019-12-10 | Google Llc | Providing suggested voice-based action queries |
US20170329790A1 (en) * | 2015-09-28 | 2017-11-16 | Developing Software LLC | Location based push notification and multi-user class social introduction |
KR102393928B1 (en) * | 2015-11-10 | 2022-05-04 | 삼성전자주식회사 | User terminal apparatus for recommanding a reply message and method thereof |
US10169794B2 (en) | 2016-06-07 | 2019-01-01 | Microsoft Technology Licensing, Llc | Digital assistant for vehicle related activities |
US10521107B2 (en) * | 2016-09-24 | 2019-12-31 | Apple Inc. | Devices, methods, and graphical user interfaces for selecting and interacting with different device modes |
US10153938B2 (en) * | 2016-10-13 | 2018-12-11 | Airwatch, Llc | Detecting driving and modifying access to a user device |
KR102426704B1 (en) * | 2017-08-28 | 2022-07-29 | 삼성전자주식회사 | Method for operating speech recognition service and electronic device supporting the same |
US10680978B2 (en) * | 2017-10-23 | 2020-06-09 | Microsoft Technology Licensing, Llc | Generating recommended responses based on historical message data |
US10198877B1 (en) * | 2018-05-23 | 2019-02-05 | Google Llc | Providing a communications channel between instances of automated assistants |
-
2019
- 2019-05-09 WO PCT/US2019/031498 patent/WO2020226650A1/en unknown
- 2019-05-09 US US16/613,668 patent/US10996925B2/en active Active
- 2019-05-09 CN CN201980091586.8A patent/CN113424151A/en active Pending
- 2019-05-09 AU AU2019444479A patent/AU2019444479A1/en not_active Abandoned
- 2019-05-09 JP JP2021543211A patent/JP7341243B2/en active Active
- 2019-05-09 EP EP19725590.4A patent/EP3752892A1/en not_active Ceased
- 2019-05-09 KR KR1020217036951A patent/KR20210145283A/en not_active Application Discontinuation
-
2021
- 2021-05-03 US US17/306,443 patent/US20210255828A1/en active Pending
-
2023
- 2023-04-27 AU AU2023202550A patent/AU2023202550A1/en active Pending
Also Published As
Publication number | Publication date |
---|---|
JP2022528218A (en) | 2022-06-09 |
US10996925B2 (en) | 2021-05-04 |
AU2019444479A1 (en) | 2021-08-05 |
KR20210145283A (en) | 2021-12-01 |
JP7341243B2 (en) | 2023-09-08 |
US20200356339A1 (en) | 2020-11-12 |
AU2023202550A1 (en) | 2023-05-11 |
US20210255828A1 (en) | 2021-08-19 |
WO2020226650A1 (en) | 2020-11-12 |
EP3752892A1 (en) | 2020-12-23 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
KR102505136B1 (en) | Dynamically adapting provision of notification output to reduce user distraction and/or mitigate usage of computational resources | |
US11030515B2 (en) | Determining semantically diverse responses for providing as suggestions for inclusion in electronic communications | |
US10996925B2 (en) | Automated assistant suggestions for third-party vehicle computing devices with restricted architecture | |
US11823676B2 (en) | Systems, methods, and apparatuses for managing incomplete automated assistant actions | |
US11238242B2 (en) | Generating output for presentation in response to user interface input, where the input and/or the output include chatspeak | |
CN117908735A (en) | Systems, methods, and apparatus for restoring dialog sessions via an automated assistant | |
US20230125662A1 (en) | Dynamically delaying execution of automated assistant actions and/or background application requests | |
US20220391772A1 (en) | Automatic generation and transmission of a status of a user and/or predicted duration of the status | |
US11900944B2 (en) | Initializing non-assistant background actions, via an automated assistant, while accessing a non-assistant application | |
US20230412538A1 (en) | Automated assistant architecture for preserving privacy of application content | |
US20230336521A1 (en) | Sending messages from smart speakers and smart displays via smartphones | |
US20220215179A1 (en) | Rendering content using a content agent and/or stored content parameter(s) | |
US11885632B2 (en) | Conditional preparation for automated assistant input from a user in a vehicle | |
US20220147775A1 (en) | Generating a selectable suggestion using a provisional machine learning model when use of a default suggestion model is inconsequential | |
US20240061694A1 (en) | Interactive application widgets rendered with assistant content |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |