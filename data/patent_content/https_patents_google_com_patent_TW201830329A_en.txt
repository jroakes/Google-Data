TW201830329A - Compiler managed memory for image processor - Google Patents
Compiler managed memory for image processor Download PDFInfo
- Publication number
- TW201830329A TW201830329A TW107117967A TW107117967A TW201830329A TW 201830329 A TW201830329 A TW 201830329A TW 107117967 A TW107117967 A TW 107117967A TW 107117967 A TW107117967 A TW 107117967A TW 201830329 A TW201830329 A TW 201830329A
- Authority
- TW
- Taiwan
- Prior art keywords
- image data
- shift register
- processor
- array
- slice
- Prior art date
Links
- 238000000034 method Methods 0.000 claims abstract description 46
- 238000011068 loading method Methods 0.000 claims abstract description 37
- 125000001475 halogen functional group Chemical group 0.000 claims description 71
- 238000012545 processing Methods 0.000 claims description 64
- 230000006870 function Effects 0.000 claims description 28
- 238000006073 displacement reaction Methods 0.000 claims description 15
- 238000004590 computer program Methods 0.000 claims description 11
- 238000003860 storage Methods 0.000 claims description 10
- 230000008569 process Effects 0.000 description 15
- 238000004422 calculation algorithm Methods 0.000 description 12
- 238000004364 calculation method Methods 0.000 description 8
- 238000013461 design Methods 0.000 description 8
- 238000007726 management method Methods 0.000 description 8
- 230000000694 effects Effects 0.000 description 5
- 238000004891 communication Methods 0.000 description 4
- 238000003491 array Methods 0.000 description 3
- 238000004519 manufacturing process Methods 0.000 description 3
- 238000005070 sampling Methods 0.000 description 3
- 238000009825 accumulation Methods 0.000 description 2
- 230000005574 cross-species transmission Effects 0.000 description 2
- 238000013500 data storage Methods 0.000 description 2
- 238000005516 engineering process Methods 0.000 description 2
- 230000003287 optical effect Effects 0.000 description 2
- 239000004065 semiconductor Substances 0.000 description 2
- 239000007787 solid Substances 0.000 description 2
- 230000006399 behavior Effects 0.000 description 1
- 230000008901 benefit Effects 0.000 description 1
- 230000001413 cellular effect Effects 0.000 description 1
- 125000004122 cyclic group Chemical group 0.000 description 1
- 230000003247 decreasing effect Effects 0.000 description 1
- 239000000284 extract Substances 0.000 description 1
- 239000012634 fragment Substances 0.000 description 1
- 230000008570 general process Effects 0.000 description 1
- LNEPOXFFQSENCJ-UHFFFAOYSA-N haloperidol Chemical compound C1CC(O)(C=2C=CC(Cl)=CC=2)CCN1CCCC(=O)C1=CC=C(F)C=C1 LNEPOXFFQSENCJ-UHFFFAOYSA-N 0.000 description 1
- 238000010801 machine learning Methods 0.000 description 1
- 238000007620 mathematical function Methods 0.000 description 1
- 238000012986 modification Methods 0.000 description 1
- 230000004048 modification Effects 0.000 description 1
- 230000002093 peripheral effect Effects 0.000 description 1
- 238000003672 processing method Methods 0.000 description 1
- 230000007480 spreading Effects 0.000 description 1
- 238000003892 spreading Methods 0.000 description 1
- 238000012546 transfer Methods 0.000 description 1
- 230000000007 visual effect Effects 0.000 description 1
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T1/00—General purpose image data processing
- G06T1/20—Processor architectures; Processor configuration, e.g. pipelining
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/30—Arrangements for executing machine instructions, e.g. instruction decode
- G06F9/30003—Arrangements for executing specific machine instructions
- G06F9/30007—Arrangements for executing specific machine instructions to perform operations on data operands
- G06F9/30032—Movement instructions, e.g. MOVE, SHIFT, ROTATE, SHUFFLE
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/30—Arrangements for executing machine instructions, e.g. instruction decode
- G06F9/30003—Arrangements for executing specific machine instructions
- G06F9/30007—Arrangements for executing specific machine instructions to perform operations on data operands
- G06F9/30036—Instructions to perform operations on packed data, e.g. vector, tile or matrix operations
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/30—Arrangements for executing machine instructions, e.g. instruction decode
- G06F9/30003—Arrangements for executing specific machine instructions
- G06F9/3004—Arrangements for executing specific machine instructions to perform operations on memory
- G06F9/30043—LOAD or STORE instructions; Clear instruction
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/30—Arrangements for executing machine instructions, e.g. instruction decode
- G06F9/30098—Register arrangements
- G06F9/3012—Organisation of register space, e.g. banked or distributed register file
- G06F9/30134—Register stacks; shift registers
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/30—Arrangements for executing machine instructions, e.g. instruction decode
- G06F9/30098—Register arrangements
- G06F9/3012—Organisation of register space, e.g. banked or distributed register file
- G06F9/30138—Extension of register space, e.g. register cache
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/30—Arrangements for executing machine instructions, e.g. instruction decode
- G06F9/38—Concurrent instruction execution, e.g. pipeline, look ahead
- G06F9/3885—Concurrent instruction execution, e.g. pipeline, look ahead using a plurality of independent parallel functional units
- G06F9/3887—Concurrent instruction execution, e.g. pipeline, look ahead using a plurality of independent parallel functional units controlled by a single instruction for multiple data lanes [SIMD]
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T1/00—General purpose image data processing
- G06T1/60—Memory management
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N25/00—Circuitry of solid-state image sensors [SSIS]; Control thereof
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N3/00—Scanning details of television systems; Combination thereof with generation of supply voltages
- H04N3/10—Scanning details of television systems; Combination thereof with generation of supply voltages by means not exclusively optical-mechanical
- H04N3/14—Scanning details of television systems; Combination thereof with generation of supply voltages by means not exclusively optical-mechanical by means of electrically scanned solid-state devices
- H04N3/15—Scanning details of television systems; Combination thereof with generation of supply voltages by means not exclusively optical-mechanical by means of electrically scanned solid-state devices for picture signal generation
- H04N3/1575—Picture signal readout register, e.g. shift registers, interline shift registers
Abstract
Description
發明領域大體而言係關於影像處理，且具體而言係關於用於一影像處理器之一編譯器管理記憶體。FIELD OF THE INVENTION This invention relates generally to image processing, and more specifically to a compiler management memory for an image processor.
影像處理通常涉及對組織成一陣列之像素值之處理。本文中，一空間組織式二維陣列擷取影像之二維性質(額外維度可包含時間(例如，一個二維影像序列)及資料類型(例如，色彩))。在一典型情境中，由已產生一靜止影像或一圖框序列之一相機提供陣列式像素值以擷取運動影像。傳統影像處理器通常會遭遇兩個極端之任一方面。 一第一極端係以在一個一般目的處理器或類一般目的之處理器(例如，具有向量指令增強之一個一般目的處理器)上執行之軟體程式形式來執行影像處理任務。儘管該第一極端通常提供一高度多功能應用軟體開發平台，但與相關聯附加項(例如，指令提取及解碼、晶片上資料及晶片外資料之處置、推測性執行)結合地使用較精細粒度之資料結構最終會導致在程式碼之執行期間每資料單元消耗更大量能量。 一第二相反極端係將固定功能硬連線電路應用於較大資料區塊。直接施加至定製設計電路之較大(與較精細粒度相對)資料區塊之使用極大地減少每資料單元之功率消耗。然而，定製設計之固定功能電路通常導致處理器能夠執行之任務集合係有限的。如此，在第二極端中，缺少功能廣泛之程式化環境(其第一極端相關聯)。 既提供高度多功能應用軟體開發機會又與每資料單元之經改良效率相結合之一技術平台仍係一期望但缺失之解決方案。Image processing usually involves processing pixel values organized into an array. In this paper, a two-dimensional array of spatially organized images captures the two-dimensional nature (extra dimensions may include time (for example, a two-dimensional image sequence) and data type (for example, color)). In a typical scenario, an array of pixel values is provided by a camera that has generated a still image or a frame sequence to capture a moving image. Traditional image processors often encounter one of two extremes. A first extreme is to perform image processing tasks in the form of a software program executed on a general-purpose processor or a general-purpose-like processor (for example, a general-purpose processor with vector instruction enhancement). Although this first extreme usually provides a highly versatile application software development platform, it uses finer granularity in combination with associated add-ons (e.g., instruction fetch and decode, processing of on-chip and off-chip data, speculative execution) The data structure ultimately results in a greater amount of energy being consumed per data unit during the execution of the code. A second opposite terminal applies a fixed-function hard-wired circuit to a larger data block. The use of larger (as opposed to finer-grained) data blocks applied directly to custom-designed circuits greatly reduces power consumption per data unit. However, custom-designed fixed-function circuits often result in a limited set of tasks that a processor can perform. As such, in the second extreme, a stylized environment with extensive functions (its first extreme is associated) is lacking. A technology platform that offers both highly versatile application software development opportunities and the improved efficiency of each data unit is still a desired but missing solution.
闡述一種方法。該方法包含將下一影像資料片區自一記憶體之一第一部位反覆地載入至一個二維移位暫存器陣列中。該記憶體在本端耦合至該二維移位暫存器陣列及一執行通道陣列，該執行通道陣列沿著至少一個陣列軸具有比該二維移位暫存器陣列小之一尺寸。該所載入下一影像資料片區保持於該二維移位暫存器陣列之一影像區域內。該方法亦包含透過沿著該執行通道陣列之各別通道執行程式碼指令而反覆地判定該下一影像資料片區之輸出值，其中在判定該等輸出值時所使用之一樣板(stencil)大小僅囊括駐存於該二維移位暫存器陣列內之像素。該方法亦包含將欲完全載入至該二維移位暫存器陣列中之下一影像資料片區遠離該記憶體之一第二部位而反覆地移動至該記憶體之該第一部位。Explain a method. The method includes repeatedly loading the next image data area from a first part of a memory into a two-dimensional shift register array. The memory is locally coupled to the two-dimensional shift register array and an execution channel array, and the execution channel array has a size smaller than the two-dimensional shift register array along at least one array axis. The loaded next image data area is kept in an image area of the two-dimensional shift register array. The method also includes repeatedly determining the output value of the next image data slice by executing code instructions along the respective channels of the execution channel array, wherein a stencil size is used in determining the output values. Only the pixels residing in the two-dimensional shift register array are included. The method also includes moving the next image data area to be completely loaded into the two-dimensional shift register array away from a second part of the memory and repeatedly moving to the first part of the memory.
本申請案主張2016年2月26日提出申請之美國臨時申請案第62/300,671號「COMPILER MANAGED MEMORY FOR IMAGE PROCESSOR」之權益，該申請案之全部內容以引用方式併入。 a. 影像處理器硬體架構及操作 圖1展示以硬體實施之一影像處理器之一架構100之一實施例。舉例而言，該影像處理器可作為一編譯器之目標，該編譯器將在一模擬環境內針對一虛擬處理器撰寫之程式碼轉換成實際上由硬體處理器執行之程式碼。如在圖1中所見，架構100包含透過一網路104 (例如，包含一晶片交換網路、一晶片環狀網路或其他種類之網路之一晶片網路(NOC))互連至複數個樣板處理器單元102_1至102_N及對應片區產生器單元103_1至103_N之複數個線緩衝器單元101_1至101_M。在一實施例中，任何線緩衝器單元可透過網路104連接至任何片區產生器及對應樣板處理器。 在一實施例中，程式碼經編譯且被載入至一對應樣板處理器102上以執行先前由一軟體開發者定義之影像處理操作(程式碼亦可被載入至樣板處理器之相關聯片區產生器103，例如，取決於設計及實施方案)。在至少某些例項中，可藉由將針對一第一管線級之一第一內核程式載入至一第一樣板處理器102_1中、將針對一第二管線級之一第二內核程式載入至一第二樣板處理器102_2中等來實現一影像處理管線，其中第一內核執行管線之第一級之功能，第二內核執行管線之第二級之功能等，且設置額外控制流程方法以將輸出影像資料自管線之一個級傳遞至管線之另一級。 在其他組態中，可將影像處理器實現為具有對相同內核程式碼進行操作之兩個或多於兩個樣板處理器102_1、102_2之一並行機器。舉例而言，可藉由跨越每一者執行相同功能之多個樣板處理器散佈圖框來處理一高度密集且具有高資料速率流之影像資料。 在其他組態中，在DAG設計中基本上任何內核DAG可藉由以下方式被載入至硬體處理器上：將各別樣板處理器組態有其各自程式碼內核且將適當控制流程勾點組態至硬體中以將輸出影像自一個內核引導至下一內核之輸入。 作為一個一般流程，影像資料圖框由一大型I/O單元105接收並在逐個圖框基礎上被傳遞至線緩衝器單元101中之一或多者。一特定線緩衝器單元將其影像資料圖框剖析成一較小影像資料區(被稱為一「線群」)，且然後將線群透過網路104傳遞至一特定片區產生器。一完整或「全」單數個線群可(舉例而言)由一圖框之多個連續完整列或行(為簡單起見，本說明書將主要係指連續列)之資料組成。片區產生器將影像資料線群進一步剖析成一較小影像資料區(被稱為一「片區」)，並將片區呈遞至其對應樣板處理器。 在一影像處理管線或一DAG流程具有一單個輸入之情形中，通常將輸入圖框引導至同一線緩衝器單元101_1，線緩衝器單元101_1將影像資料剖析成線群且將線群引導至片區產生器103_1，片區產生器103_1之對應樣板處理器102_1執行管線/DAG中之第一內核之碼。在樣板處理器102_1完成對其處理之線群之操作之後，片區產生器103_1旋即將輸出線群發送至一「下游」線緩衝器單元101_2 (在某些使用情形中，可將輸出線群發送回至先前已發送了輸入線群之同一線緩衝器單元101_1)。 然後在「消費者」內核各自其他片區產生器及樣板處理器(例如，片區產生器103_2及樣板處理器102_2)上執行的表示管線/DAG中之下一級/操作之該一或多個消費者內核自下游線緩衝器單元101_2接收由第一樣板處理器102_1產生之影像資料。以此方式，在一第一樣板處理器上操作之一「生產者」內核將其輸出資料轉送至在一第二樣板處理器上操作之一「消費者」內核，其中消費者內核在生產者內核與總體管線或DAG之設計相一致之後執行下一任務集合。 一樣板處理器102經設計以同時對在多個重疊影像資料樣板進行操作。該多個重疊樣板及樣板處理器之內部硬體處理容量有效判定一片區之大小。本文中，在一樣板處理器102內，執行通道陣列一致地操作以同時處理被多個重疊樣板覆蓋之影像資料表面區域。 如下文將更詳細地闡述，在各種實施例中，影像資料片區被載入至樣板處理器102內之一個二維暫存器陣列結構中。據信，片區及二維暫存器陣列結構之使用因在(例如)一單個載入操作時將大量資料移動至大量暫存器空間中而有效提供功率消耗改良，其中此後立即藉由一執行通道陣列直接對資料執行處理任務。另外，一執行通道陣列及對應暫存器陣列之使用提供可輕易程式化/可輕易組態之不同樣板大小。 圖2a至圖2e在一高水平上圖解說明一線緩衝器單元101之剖析活動、一片區產生器單元103之較精細粒度之剖析活動以及耦合至片區產生器單元103之樣板處理器102之樣板處理活動三者的實施例。 圖2a繪示影像資料201之一輸入訊框之一實施例。圖2a亦繪示三個重疊樣板202 (各自具有3個像素x 3個像素之一尺寸)之一輪廓，一樣板處理器經設計以對該等樣板進行操作。以實心黑區醒目提示每一樣板針對其分別產生輸出影像資料之輸出像素。為簡單起見，三個重疊樣板202被繪示為僅在垂直方向上重疊。應瞭解，實際上一樣板處理器可經設計以在垂直方向及水平方向兩個方向上皆具有重疊樣板。 如圖2a中所見，由於樣板處理器內之垂直重疊樣板202，在圖框內存在一單個樣板處理器可操作之一寬頻影像資料。如下文將更詳細地闡述，在一實施例中，樣板處理器跨越影像資料以一左至右方式處理其重疊樣板內之資料(且然後以頂部至底部次序針對下一線集合重複)。因此，隨著樣板處理器繼續其操作，實心黑區輸出像素區塊之數目將水平向右增長。如上文所論述，一線緩衝器單元101負責剖析來自一傳入圖框之輸入影像資料之一線群，該傳入圖框足夠由樣板處理器在擴展數目個即將到來之循環內進行操作。對一線群之一例示性繪示被圖解說明為一陰影區203。在一實施例中，線緩衝器單元101可瞭解不同動態：自一片區產生器接收一線群或將一線群發送至一片區產生器。舉例而言，根據被稱為「全群」之一種模式，影像資料之完整全寬度線係在一線緩衝器單元與一片區產生器之間被傳遞。根據被稱為「虛擬高」之一第二模式，一線群最初係以全寬度列之一子集被傳遞。然後其餘列以較小片段(小於全寬度)被依序傳遞。 在輸入影像資料之線群203已由線緩衝器單元界定且被傳遞至片區產生器單元之情況下，片區產生器單元將線群進一步剖析成更精確地符合樣板處理器之硬體限制之較精細片區。更具體而言，如下文將更詳細地闡述，在一實施例中，每一樣板處理器由一個二維移位暫存器陣列組成。該二維移位暫存器陣列將影像資料基本上移位於一執行通道陣列「下方」，其中移位型樣致使每一執行通道對其各自樣板內之資料進行操作(亦即，每一執行通道在其自身之資訊樣板上處理以針對彼樣板產生一輸出)。在一實施例中，片區係「填充」或者被載入至二維移位暫存器陣列中之輸入影像資料之表面區域。 如下文將更詳細地闡述，在各種實施例中，實際上在任何循環上皆存在可被移位之多層二維暫存器資料。為方便起見，本說明之大部分將僅使用術語「二維移位暫存器」及諸如此類來指代具有可被移位之一或多個此等層之二維暫存器資料之結構。 因此，如圖2b中所見，片區產生器剖析來自線群203之一初始片區204且將其提供至樣板處理器(本文中，資料片區對應於通常由元件符號204識別之陰影區)。如在圖2c及圖2d中所見，樣板處理器藉由在片區上方以一左至右方式有效地移動重疊樣板202而對輸入影像資料片區進行操作。直至圖2d，可依據片區內之資料計算一輸出值之像素之數目被耗盡(無其他像素位置可具有依據片區內之資訊所判定之一輸出值)。為簡單起見，已忽略影像之邊界區。 如在圖2e中所見，然後片區產生器為樣板處理器提供下一片區205以繼續操作。注意，在樣板開始對下一片區進行操作時，該等樣板之最初位置係自第一片區上之耗盡點至右側之下一進展(如先前在圖2d中所繪示)。在具有新片區205之情況下，當樣板處理器以與對第一片區之處理相同之方式對新片區進行操作時，樣板將僅繼續移動至右側。 注意，第一片區204之資料與第二片區205之資料之間因環繞一輸出像素部位之樣板之邊界區而存在某些重疊。可僅藉由片區產生器再次傳輸重疊資料兩次來處置該重疊。在替代實施方案中，為了將下一片區饋送至樣板處理器，片區產生器可繼續僅將新資料發送至樣板處理器且樣板處理器再次使用來自先前片區之重疊資料。 b. 樣板處理器設計及操作 圖3a展示一樣板處理器架構300之一實施例。如在圖3a中所見，樣板處理器包含一資料運算單元301、一純量處理器302及相關聯記憶體303以及一I/O單元304。資料運算單元301包含一執行通道陣列305、一個二維移位陣列結構306及與陣列之特定列或行相關聯之單獨隨機存取記憶體307。 I/O單元304負責將自片區產生器接收之「輸入」資料片區載入至資料運算單元301中且將來自樣板處理器之「輸出」資料片區儲存至片區產生器中。在一實施例中，將片區資料載入至資料運算單元301中需要將一所接收片區剖析成影像資料列/影像資料行並將影像資料列/影像資料行載入至二維移位暫存器結構306或執行通道陣列之列/行之各別隨機存取記憶體307中(下文更詳細地闡述)。若片區最初被載入至記憶體307中，則然後執行通道陣列305內之個別執行通道可在適當時候將片區資料自隨機存取記憶體307載入至二維移位暫存器結構306中(例如，當恰在對片區資料進行操作之前存在一載入指令時)。在將一資料片區(直接自一片區產生器或自記憶體307)載入至暫存器結構306中完成之後，執行通道陣列305之執行通道旋即對資料進行操作並最終將已完成資料以一片區形式直接「寫回」至片區產生器或寫回至隨機存取記憶體307中。若將已完成資料寫回至隨機存取記憶體307中，則I/O單元304自隨機存取記憶體307提取資料以形成一輸出片區，然後該輸出片區被轉送至片區產生器。 純量處理器302包含一程式控制器309，程式控制器309自純量記憶體303讀取樣板處理器程式碼之指令且將指令發佈至執行通道陣列305中之執行通道。在一實施例中，一單個相同指令自資料運算單元301被廣播至陣列305內之所有執行通道以達成一類SIMD行為。在一實施例中，自純量記憶體303讀取並發佈至執行通道陣列305之執行通道之指令之指令格式包含一極長指令字(VLIW)類型之格式，該極長指令字類型之格式包含一個以上運算碼/指令。在另一實施例中，VLIW格式包含兩個運算碼：一ALU運算碼，其引導由每一執行通道之ALU (如下文所闡述，在一實施例中，其可規定一個以上傳統ALU運算)執行之一數學函數；及一記憶體運算碼，其引導一特定執行通道或執行通道集合之一記憶體運算。 術語「執行通道」係指能夠執行一指令之一或多個執行單元(例如，可執行一指令之邏輯電路)之一集合。然而，在各種實施例中，一執行通道可包含超出執行單元的較多如同處理器之功能性。舉例而言，除了一或多個執行單元之外，一執行通道亦可包含將一所接收指令解碼之邏輯電路或在較多如同MIMD之設計之情形中包含提取一指令並將該指令解碼之邏輯電路。關於如同MIMD之方法，儘管本文中已在很大程度上闡述了一集中式程式控制方法，但可在各種替代實施例中實施一較分散方法(例如，在陣列305之每一執行通道內皆包含程式碼及一程式控制器)。 一執行通道陣列305、程式控制器309及二維移位暫存器結構306之組合為一寬廣範圍之可程式化功能提供一廣泛可調適/可組態硬體平台。舉例而言，應用程式軟體開發者能夠將具有一寬廣範圍之不同功能性能力及尺寸(例如，樣板大小)之內核程式化，前提係執行通道能夠執行各種功能且能夠輕易存取靠近於輸出陣列部位之輸入影像資料。 除了用作由執行通道陣列305操作之影像資料之一資料儲存裝置之外，隨機存取記憶體307亦可保存一或多個查找表。在各種實施例中，一或多個純量查找表亦可被具現化於純量記憶體303內。 一純量查找涉及將相同資料值自相同查找表之相同索引傳遞至執行通道陣列305內之執行通道中之每一者。在各種實施例中，上文所闡述之VLIW指令格式經擴展以亦包含將由純量處理器執行之一查找操作引導至一純量查找表中的一純量運算碼。經規定與運算碼一起使用之索引可係一立即運算元或可自某些其他資料儲存部位提取。無論如何，在一實施例中，依據純量記憶體內之一純量查找表之一查找基本上涉及在相同時脈循環期間將相同資料值廣播至執行通道陣列305內之所有執行通道。下文進一步提供關於查找表之使用及操作之額外細節。 圖3b概述上文所論述之VLIW指令字實施例。如在圖3b中所見，VLIW指令字格式包含用於以下三個單獨指令之欄位：1)一純量指令351，其由純量處理器執行；2)一ALU指令352，其由執行通道陣列內之各別ALU以SIMD方式廣播及執行；及3)一記憶體指令353，其以一部分SIMD方式被廣播及執行(例如，若沿著執行通道陣列中之同一列之執行通道共用同一隨機存取記憶體，則來自不同列之每一者之一個執行通道實際上執行該指令(記憶體指令353之格式可包含識別來自每一列之哪一執行通道執行該指令的一運算元)。 亦包含用於一或多個立即運算元之一欄位354。指令351、指令352、指令353中之哪一者使用哪些立即運算元資訊可在指令格式中被識別。指令351、指令352、指令353中之每一者亦包含其各自輸入運算元及所得資訊(例如，用於ALU運算之本端暫存器以及用於記憶體存取指令之一本端暫存器及一記憶體位址)。在一實施例中，純量處理器在執行通道陣列內之執行通道執行另外指令352、353中之任一者之前執行純量指令351。亦即，對VLIW字之執行包含一第一循環，純量指令351在該第一循環上被執行；後續接著一第二循環，其他指令352、353可在該第二循環上被執行(注意，在各種實施例中，指令352及353可被並行執行)。 在一實施例中，由純量處理器執行之純量指令包含命令，該等命令經發佈至片區產生器以自資料運算單元之記憶體或2D移位暫存器載入片區/將片區儲存至資料運算單元之記憶體或2D移位暫存器中。本文中，片區產生器之操作可取決於線緩衝器單元之操作或阻止片區產生器將花費來完成由純量處理器發佈之任何命令之循環數目之前執行階段瞭解的其他變數。如此，在一實施例中，其純量指令351對應於片區產生器或者致使一命令被發佈至片區產生器之任何VLIW字亦包含其他兩個指令欄位352、353中之無操作(NOOP)指令。然後程式碼進入指令欄位352、353之NOOP指令之一迴圈直至片區產生器完成其自資料運算單元之載入/至資料運算單元之儲存為止。本文中，在將一命令發佈至片區產生器之後，純量處理器旋即可設定一互鎖暫存器之一位元，片區產生器在完成命令之後旋即重設該位元。在NOOP迴圈期間，純量處理器監視互鎖位元之位元。當純量處理器偵測到片區產生器已完成其命令時，再次開始常規執行。 圖4展示一資料計算組件401之一實施例。如圖4中所見，資料計算組件401包含邏輯上定位於一個二維移位暫存器陣列結構406「上方」之一執行通道陣列405。如上文所論述，在各種實施例中，由一片區產生器提供之一影像資料片區被載入至二維移位暫存器406中。然後執行通道自暫存器結構406對片區資料進行操作。 執行通道陣列405與移位暫存器結構406相對於彼此而被固定於適當位置。然而，移位暫存器陣列406內之資料以一策略方式及座標方式移位亦致使執行通道陣列中之每一執行通道處理資料內之一不同樣板。如此，每一執行通道判定所產生輸出片區中之一不同像素之輸出影像值。依據圖4之架構應明瞭，重疊樣板不僅垂直地配置而且亦水平地配置，此乃因執行通道陣列405包含垂直毗鄰之執行通道以及水平毗鄰之執行通道。 資料運算單元401之某些明顯架構特徵包含移位暫存器結構406具有比執行通道陣列405寬之尺寸。亦即，在執行通道陣列405外側存在暫存器409之一「暈輪」。儘管暈輪409經展示為存在於執行通道陣列之兩側上，但取決於實施方案，暈輪可存在於執行通道陣列405之少於(一)或多於(三或四)側上。當資料移位於執行通道405「下方」時，暈輪409用於為溢出於執行通道陣列405之界限外之資料提供「外溢」空間。作為一簡單實例，當處理樣板之最左側像素時，以執行通道陣列405之右邊緣為中心之一5x5樣板將需要進一步向右之四個暈輪暫存器部位。為了繪示簡單，圖4將暈輪右側之暫存器展示為僅具有水平移位連接且將暈輪底側之暫存器展示為僅具有垂直移位連接，而在一標稱實施例中，任一側(右側、底側)上之暫存器將具有水平及垂直連接兩者。 耦合至陣列中之每一列及/或每一行之隨機存取記憶體407或其若干部分提供額外外溢空間(例如，一隨機存取記憶體可被指派至按列橫跨4個執行通道及按行橫跨2個執行通道之執行通道陣列之一「區」)。為簡單起見，本申請案之其餘部分將主要係指基於列及/或行之分配方案)。本文中，若一執行通道之內核操作需要該執行通道處理二維移位暫存器陣列406外部之像素值(某些影像處理常式可需要該二維移位暫存器陣列)，則影像資料之平面能夠(例如)自暈輪區409進一步外溢至隨機存取記憶體407中。舉例而言，可考慮一6X6樣板，其中該硬體在執行通道陣列之右邊緣上之一執行通道右側包含僅四個儲存元件之一暈輪區。在此情形中，將需要將資料在暈輪409之右邊緣處進一步向右移位以完全處理該樣板。然後移位於暈輪區409外部之資料將外溢至隨機存取記憶體407。下文進一步提供隨機存取記憶體407及圖3之樣板處理器之其他應用。 圖5a至圖5k證明將影像資料移位於如上文所提及之執行通道陣列「下方」之二維移位暫存器陣列內之方式之一工作實例。如在圖5a中所見，以一第一陣列507繪示二維移位陣列之資料內容且藉由一圖框505繪示執行通道陣列。此外，亦簡單繪示執行通道陣列內之兩個鄰近執行通道510。在此簡單繪示510中，每一執行通道包含可自移位暫存器接受資料、自一ALU輸出(例如，跨越循環用作一加速器)接受資料或將輸出資料寫入至一輸出目的地的一暫存器R1。 每一執行通道亦可在一本端暫存器R2中獲得二維移位陣列中在該執行通道「下面」之內容。因此，R1係執行通道之一實體暫存器而R2係二維移位暫存器陣列之一實體暫存器。執行通道包含可對由R1及/或R2提供之運算元進行運算之一ALU。如下文將更詳細地闡述，在一實施例中，移位暫存器實際上實施有多個(一定「深度」之)儲存/暫存元件/陣列部位，但移位活動被限制於一個儲存元件平面(例如，僅一個儲存元件平面可移位/循環)。圖5a至圖5k繪示用於儲存來自各別執行通道之結果X之此等較深暫存器部位中之一者。為了易於圖解說明，在對應暫存器R2旁邊而非其下方繪製較深所得暫存器。 圖5a至圖5k集中於對兩個樣板之計算，該兩個樣板之中心位置與執行通道陣列內所繪示之執行通道位置對511對準。為了易於圖解說明，執行通道對510經繪製為水平鄰近者，而事實上根據以下實例，其等係垂直鄰近者。 如最初在圖5a中所見，執行通道以其中心樣板部位為中心。圖5b展示由兩個執行通道執行之目的碼。如圖5b中所見，兩個執行通道之程式碼致使移位暫存器陣列內之資料向下移位一個位置且向右移位一個位置。此使兩個執行通道對準其各別樣板之左上角。然後，程式碼致使位於(R2中)其各別部位中之資料被載入至R1中。 如圖5c中所見，接下來程式碼致使執行通道對將移位暫存器陣列內之資料向左移位一個單位，此致使每一執行通道之各別位置之右側之值被移位至每一執行通道之位置中。然後R1中之值(先前值)與已被移位至執行通道之位置中(R2中)之新值相加。將結果寫入至R1中。如圖5d中所見，重複與上文針對圖5c所闡述相同之程序，此致使所得R1現在包含上部執行通道中之值A+B+C及下部執行通道中之F+G+H。在此時，兩個執行通道已處理其各別樣板之上部列。注意至執行通道陣列之左側上之一暈輪區(若在左手側上存在一暈輪區)中之外溢，或若執行通道陣列之左手側上不存在一暈輪區則注意至隨機存取記憶體中之外溢。 如圖5e中所見，接下來程式碼致使移位暫存器陣列內之資料向上移位一個單位，此致使兩個執行通道與其各別樣板之中間列之右邊緣對準。兩個執行通道之暫存器R1當前包含樣板之頂部列與中間列的最右側值之總和。圖5f及圖5g證明跨越兩個執行通道之樣板之中間列向左移動之後續進展。累加繼續，致使在圖5g之處理最後兩個執行通道包含其各別樣板之頂部列及中間列之值的總和。 圖5h展示用以使每一執行通道與其對應樣板之最低列對準之另一移位。圖5i及圖5j展示用以在兩個執行通道之樣板之過程內完成處理之後續移位。圖5k展示用以使每一執行通道與其在資料陣列中之正確位置對準之額外移位且將結果寫入至資料陣列中。 在圖5a至圖5k之實例中，注意，用於移位操作之目的碼可包含一指令格式，該指令格式識別以(X、Y)座標表達之移位之方向及量值。舉例而言，用於向上一個部位之一移位之目的碼可以如移位0，+1之目的碼來表達。作為另一實例，向右一個部位之一移位可以如移位+1，0之目的碼來表達。在各種實施例中，較大量值之移位亦可以目的碼(例如，移位0，+2)來規定。本文中，若2D移位暫存器硬體僅支援移位一個部位/循環，則機器可將指令解譯為需要多個循環執行，或2D移位暫存器硬體可經設計以支援移位一個以上部位/循環。下文更詳細地闡述後者之實施例。 圖6展示陣列執行通道及移位暫存器結構之單位單元之另一更詳細繪示(暈輪區中之暫存器不包含一對應執行通道)。在一實施例中，執行通道及與執行通道陣列中之每一部位相關聯之暫存器空間係藉由將在圖6中所見的在執行通道陣列之每一節點處之電路具現化來實施。如圖6中所見，單位單元包含耦合至由四個暫存器R2至R5組成之一暫存器檔案602之一執行通道601。在任何循環期間，執行通道601可自暫存器R1至R5中之任一者進行讀取或對暫存器R1至R5中之任一者進行寫入。對於需要兩個輸入運算元之指令而言，執行通道可自R1至R5中之任一者擷取該兩個運算元。 在一實施例中，二維移位暫存器結構係藉由以下操作實施：在一單個循環期間，准許透過輸出多工器603將暫存器R2至R4中之(僅)任一者之內容移「出」至其鄰近者之暫存器檔案中之一者，且以透過輸入多工器604自其鄰近者中之一對應暫存器移「進」之內容來替換暫存器R2至R4中之(僅)一者之內容，致使鄰近者之間的移位在同一方向上(例如，所有執行通道向左移位，所有執行通道向右移位等)。儘管在同一循環內通常將同一暫存器之內容移出且以移進之內容替換，但在同一循環期間多工器配置603、604准許不同移位源及同一暫存器檔案內之移位目標暫存器。 如圖6a中所繪示，注意，在一移位序列期間，一執行通道將把內容自其暫存器檔案602移出至其左側鄰近者、右側鄰近者、頂部鄰近者及底部鄰近者中之每一者。與同一移位序列相結合，執行通道亦將把內容自其左側鄰近者、右側鄰近者、頂部鄰近者及底部鄰近者中之一特定鄰近者移位至其暫存器檔案。此外，對於所有執行通道而言，移出目標及移進源應與同一移位方向相一致(例如，若向右側鄰近者移出，則應自左側鄰近者移進)。 儘管在一項實施例中，准許每循環每執行通道移位僅一個暫存器之內容，但其他實施例可准許移進/移出一個以上暫存器之內容。舉例而言，若將圖6a中所見之多工器電路603、604之一第二例項併入至圖6a之設計中，則在同一循環期間可移出/移進兩個暫存器之內容。當然，在其中准許每循環移位僅一個暫存器之內容之實施例中，可藉由在數學運算之間為移位耗用更多移位時脈循環而在數學運算之間進行自多個暫存器之移位(例如，可藉由在數學運算之間耗用兩個移位操作而在數學運算之間移位兩個暫存器之內容)。 若在一移位序列期間並非一執行通道之暫存器檔案之所有內容皆被移出，則注意，每一執行通道之暫存器之未移出內容仍在適當位置(不移位)。如此，未被移進內容替換之任何未移位內容跨越移位循環存留於執行通道本端。在每一執行通道中所見之記憶體單元(「M」)用於自與執行通道陣列內之執行通道之列及/或行相關聯之隨機存取記憶體空間載入資料/將資料儲存至該隨機存取記憶體空間。本文中，M單元用作一標準M單元，此乃因其通常用於載入/儲存可自執行通道自身之暫存器空間載入/儲存至執行通道自身之暫存器空間之資料。在各種實施例中，M單元之主要操作係將資料自一本端暫存器寫入至記憶體中，且自記憶體讀取資料並將其寫入至一本端暫存器中。 關於由硬體執行通道601之ALU單元支援之ISA運算碼，在各種實施例中，由硬體ALU支援之數學運算碼與由一虛擬執行通道(例如，ADD、SUB、MOV、MUL、MAD、ABS、DIV、SHL、SHR、MIN/MAX、SEL、AND、OR、XOR、NOT)支援之數學運算碼連結(例如，實質上相同)。如上文所闡述，記憶體存取指令可由執行通道601執行以自其相關聯隨機存取記憶體提取資料/將資料儲存至其相關聯隨機存取記憶體。另外，硬體執行通道601支援移位操作指令(右、左、上、下)以移位二維移位暫存器結構內之資料。如上文所闡述，程式控制指令主要由樣板處理器之純量處理執行器。 c. 編譯器管理樣板處理器記憶體 返回參考圖4，可知暫存器409之一暈輪區之存在，在圖4之特定實施例中，該暈輪區駐存於執行通道陣列405之右側邊緣及下部邊緣周圍(其他實施例可在執行通道陣列之更多側或更少側上包含暈輪暫存器)。在先前論述中，一「片區」被理解為耗用具有執行通道陣列405之尺寸之內部移位暫存器空間之一影像資訊陣列。本文中，在各種實施例中，409中之暫存器部位不包含用於對影像資料執行影像處理指令之相關聯ALU單元–而是–存在暈輪409區是為了例如累積在執行通道陣列區域因移位活動而得到之「外溢」資料。如此，可被處理之影像資料之區域對應於區域405且一「片區」被理解為與區域405共存。將一片區載入至暫存器陣列406中包含將影像資料載入至區域405中。 一編譯器負責將指令插入至程式碼中，該程式碼控制資訊片區自片區產生器至一樣板處理器之資料運算單元401之內部RAM 407之載入/自一樣板處理器之資料運算單元401之內部RAM 407至片區產生器之載入。如此，在各種實施例中，編譯器負責判定哪些片區自片區產生器被載入至RAM 407中且此等片區何時被載入。另外，編譯器亦負責判定樣板處理器RAM 407中之哪些片區被載入至二維移位陣列406中。注意，RAM 407可被分解成單獨庫，其中每一庫關於移位暫存器陣列而被指派一特定影像區(例如，RAM庫407_1保存移位暫存器陣列之第一列之影像資料，RAM庫407_2保存移位暫存器陣列之第二列之影像資料等)。 本文中，在可能情況下應避免將相同資料片區自片區產生器「重新載入」至RAM 407中及/或將相同資料片區自RAM 407重新載入至二維移位暫存器406中，以便(例如)將影像處理器之功率消耗最小化。如下文立即做出之更詳細闡釋，若編譯器意識到暈輪區409之存在，則即使影像資料之基本單元被理解為對應於執行通道陣列405之較小區域之資料片區，仍可避免低效率。特定而言在影像處理演算法處理執行通道陣列405內延伸於暈輪外部的任何輸出像素之資料之情況下，宣告避免了低效率。 圖7a至圖7d展示一基本實例。如在圖7a中所見，一輸入影像資料片區對應於一較大輸入影像之區701。為簡單起見，圖7a至圖7d假定輸入片區具有與執行通道陣列相同之尺寸。儘管此一配置可通常係方便的，但並無必要。舉例而言，在其中輸入表面之解析度不同於輸出表面(例如，由於增加取樣或減少取樣)之情形中，片區可具有與執行通道陣列不同之尺寸。舉例而言，在具有一16x16執行通道陣列之一處理器中，2x經減少取樣輸入片區可具有尺寸32x32而2x經增加取樣輸入片區可具有尺寸8x8。 若輸入影像被理解為不僅包含片區701而且包含可納入至暈輪區中之周圍影像資料，則輸入影像資料之總量將耗用陰影區720。在判定片區701內之像素之輸出像素值時，至少可設計某些演算法以處理暈輪區外部(諸如更大區730)之輸入影像資料。 舉例而言，若執行通道陣列405之尺寸係16個像素部位乘以16個像素部位且暈輪區之大小係沿著X軸之一額外4個像素部位及沿著Y軸之4個像素部位，則片區701將具有16個像素部位乘以16個像素部位之尺寸且區720將具有20個像素部位乘以20個像素部位之尺寸。若判定片區701內之像素之輸出像素值之演算法處理具有18個像素乘以18個像素之尺寸之樣板，則將需要被處理的片區701之表面區域將自區720向外延伸以包含邊限730內之區域。本文中，舉例而言，為了適應對片區701之右下角處之像素部位之處理，將在由邊限730限界之區之右下角中需要一像素。因此，對片區701之處理需要來自片區702、703及704之大量資料。 在一實施例中，編譯器經設計以瞭解一輸入影像內之多個片區之佈局、執行通道陣列之尺寸、暈輪之尺寸及執行通道陣列區域內之一特定輸出像素之待處理樣板之大小。然後，編譯器繼續將記憶體載入指令插入於程式碼中之適宜部位處，該等指令將下一資訊片區自片區產生器載入至資料運算單元RAM 407中。 另外，如下文將更詳細地闡述，編譯器亦插入資料移動指令以移動資料運算單元之隨機存取記憶體407內之資料片區，以便增強其再次使用且藉此減少同一資料片區自片區產生器至隨機存取記憶體407中之重複載入。 圖7b展示由編譯器建構之指令740之一序列，該指令致使片區產生器最初將充分數目個片區載入於隨機存取記憶體407以針對第一片區部位701之像素部位中之每一者充分執行演算法。如在圖7b中所見，來自四個片區701至704之資料被載入且被指派邏輯片區識別符(Lsheet_0、Lsheet_1、LSheet_2、LSheet_3)。本文中，若考慮到包含暈輪區409之整個移位暫存器陣列406，則經載入片區之數目對應於影像處理演算法達到之片區數目。自圖3a及圖3b之論述可知，在各種實施例中與純量處理器302相關聯之程式控制器309執行對應於至片區產生器之命令之指令以自資料運算單元301載入資料片區/將資料片區儲存至資料運算單元301。如此，可由純量處理器302執行指令740。 編譯器亦建構後續指令750、760以將來自剛剛被載入至RAM中之四個片區之內容載入移位暫存器陣列406 (MEM LOAD)。指令750以LSheet_0之內容(影像區701之內容)來填充與執行通道陣列405共存之移位暫存器區。同樣地，與上文之論述相一致，純量處理器302可亦執行指令750、760。 指令760填充暈輪區。亦即，指令760執行以下操作：1)將片區702 (Lsheet_1)之左手側(LHS)載入至駐存於執行通道陣列405之右側邊緣處之暈輪409之區中；2)將片區704 (Lsheet_3)之上部區(UPR)載入至駐存於執行通道陣列405之下部邊緣正下方之暈輪409之區中；3)將片區705之左上角(Lsheet_4)載入至執行通道陣列405之右下角處之暈輪區中。在此等載入被執行之後，包含暈輪區(圖7a中之區720)之整個移位暫存器陣列之內容載有經適當定位輸入影像資料。 本文中，參考圖4，注意，每一執行通道陣列部位含有用於執行一記憶體載入指令(MEM LOAD)以自隨機存取記憶體407提取影像資料之一記憶體存取單元(M)。儘管圖4中未展示，但在各種實施例中，暈輪區409中之部位中之每一者亦包含一記憶體存取單元，致使影像資料值可自隨機存取記憶體407被載入至暈輪區409中。然而，此外，在各種實施例中暈輪區部位不含有一ALU單元，致使實際影像處理限於執行通道陣列405內之影像資料。因此，指令750對應於在每一執行通道陣列部位處被個別地執行但基於其在陣列中之部位而具有不同輸入運算元資料(其定義待載入影像資料)的一記憶體載入指令，而同樣地，MEM LOAD指令760對應於在暈輪區409內之特定部位處被執行但基於其在執行通道陣列周圍之部位而具有不同輸入運算元資料(其定義待載入影像資料)的一記憶體載入指令。下文更詳細地闡述用於規定此等指令之位址之技術。 編譯器亦建構指令770之一以下集合以執行針對Lsheet_0部位內之像素部位而判定輸出像素值之影像處理演算法。與上文之論述相一致，計算包含針對藉由移位二維移位暫存器陣列內之內容而產生之每一像素部位而對一樣板區進行操作。因此，編譯器建構不僅用於執行對樣板之數學計算而且用於執行對應暫存器移位指令之若干指令。 在目前正在論述之實例中，可知LSheet_0內之任何像素部位之待處理樣板之尺寸係18 x 18。如此，將有影像資料自執行通道陣列405之上側及左手側處「外溢」至隨機存取記憶體407中。亦即，資料向左移位將致使來自在由邊限720限界之區內但在由邊限701限界之區外部之片區702 (LSheet_1)及片區703 (LSheet_2)之資料被載入至暈輪區409之右側邊緣中。將資料載入至暈輪區409之右側邊緣中將有效地將「外溢」資料自執行通道陣列之左側邊緣及駐存於執行通道陣列405正下方之暈輪區409之左側邊緣推擠出移位暫存器。已外溢/已推擠出之資料被寫入至隨機存取記憶體407中。 同樣地，資料「向上」移位將致使來自在由邊限720限界之區內但在執行通道區域外部之片區704 (LSheet_3)及片區703 (LSheet_2)之資料被載入至暈輪區409之下部邊緣中。將資料載入至暈輪區409之下部邊緣中將有效地將「外溢」資料自執行通道陣列405之頂部邊緣及駐存於執行通道陣列405右側之暈輪區之頂部邊緣推擠出移位暫存器。已外溢/已推擠出之資料亦被寫入至隨機存取記憶體407中。此外，為了達成移位，編譯器為新資料自RAM 407至移位暫存器中之所有載入及經推擠出資料自移位暫存器至RAM 407中之寫回建構程式碼。 在對片區701 (LSheet_0)執行所有移位及計算770之後，處理將以一光柵狀形式繼續掃描至右側(區701之一輸出片區亦可被寫入至隨機存取記憶體407中以用於轉送至片區產生器)。為了實現演算法之一光柵狀掃描，僅需要重新指派邏輯片區，在此之後可再次執行相同程式碼以處理下一片區之像素之輸出值。如此，以一掃描式方式對影像執行演算法可由編譯器以一軟體迴圈方式建構。本文中，迴圈程式內之內部指標可以迴圈之每一新反覆來更新。具體而言，當核心常式意識到其已到達針對本遞迴而欲載入資料之最「右側」時，其同樣意識到下一遞迴即將到來。 本文中，如在圖7c中所見，編譯器建構使機器準備以柵格掃描來對下一片區處理演算法之指令780之一額外集合。指令包含將LSheet_1之內容移動(MOV)至LSheet_0中且將LSheet_2之內容移動至LSheet_3中。另外，指令780包含用以將下一LSheet_1 (片區705)及下一LSheet_2 (片區706)自片區產生器載入至RAM 407中之指令。在執行了此等指令780之後，機器之脈絡與在執行指令770之前的圖7b中之機器之脈絡已無不同，惟除待處理片區之部位向右了一個片區除外(亦即，片區702而非片區701)。重要的是，已載入至RAM 407中之片區(亦即，片區702及片區703)不會自片區產生器被重新載入至RAM 407中。如此，避免了在片區702及703被重新載入至RAM 407中之情況下將出現之任何低效率。 注意，在已將Sheet_1及Sheet_2之較早內容分別移動至LSheet_0及LSheet_3中之後，如由指令780內之SG指令所指示，可(例如)在操作770期間執行LSheet_1 (片區705)及LSheet_2 (片區706)自片區產生器至RAM 407中之載入且隨後將此等片區於RAM內移動至Sheet_1部位及Sheet_2部位。如此，實際上指令780之SG LOAD指令在RAM 407內可被實施為額外MOV指令。在一實施例中，指令780之移動(MOV)指令實際上係將資料實體移動於RAM 407內。如此，程式碼內所規定之LSheet_0至LSheet_3之位址係固定位址。 儘管上文關於圖7a至圖7c所概述之方法係針對其中片區701內之像素的待處理樣板大小足夠大以包含駐存於暈輪區外部之像素的一實例，但據信該方法對於其中片區701內(亦即，執行通道陣列內)之像素的待處理樣板大小足夠小致使所有待處理像素駐存於暈輪區內(亦即，在邊限720外部且在邊限730內之像素或者不需要超出部分)之應用係最佳的。在此情形中，避免將額外影像資料載入至二維移位暫存器(例如，沿著暈輪區之右側邊緣)中。 圖8繪示上文所闡述之一方法。該方法包含：反覆地801執行以下操作。將下一影像資料片區自一記憶體之一第一部位載入至一個二維移位暫存器陣列802中。該記憶體在本端耦合至二維移位暫存器陣列及一執行通道陣列，該執行通道陣列沿著至少一個陣列軸具有比二維移位暫存器陣列小之一尺寸。所載入之下一影像資料片區保持在二維移位暫存器陣列之一影像區域內。透過沿著執行通道陣列之各別通道執行程式碼指令而判定下一影像資料片區之輸出值，其中在判定該等輸出值時所使用之一樣板大小僅囊括駐存於二維移位暫存器陣列803內之像素。將欲完全載入至該二維移位暫存器陣列中之下一影像資料片區遠離該記憶體之一第二部位而移動至該記憶體804之該第一部位。 自先前論述可知，在指令750、760及770之執行期間，可將影像資料自RAM 407載入至二維移位暫存器406中。本文中，假定二維移位暫存器406 (包含暈輪區)中之每一個別部位包含一記憶體存取單元以用於在本端執行一記憶體載入指令，致使可將資料自RAM 407個別地載入至其本端暫存器空間中。在一實施例中，編譯器在RAM 407中固定一基本位址分量以用於LSheet_0且由編譯器分辨以執行迴圈之額外邏輯片區(例如，LSheet_1、LSheet_2及LSheet_3)之位址具有相對於基本位址分量之位移。舉例而言，若RAM 407中用於LSheet_0之位址係[base]，則用於LSheet_1之位址係[base]+1、用於LSheet_2之位址係[base]+2且用於LSheet_3之位址係[base]+3。 為了支援一廣泛可程式化環境，執行通道陣列中及暈輪區中之執行單元之指令集架構支援產生特定移位暫存器陣列部位之正確位移之一指令。然後該位移可隨後用於(例如)產生正確位址。本文中，在片區尺寸與執行通道陣列尺寸相同之意義上而言，指出圖7a至圖7c之實例過於簡單係中肯的。亦即，片區及執行通道陣列兩者皆具有16個像素部位x 16個像素部位之一尺寸。 其他實施例可選擇具有(例如)沿著任一維度或兩個維度大於或小於執行通道陣列之一片區大小。在前者情形中，(例如) LSheet_0將延伸至暈輪區中，而在後者之情形中(例如) LSheet_1及/或LSheet_3最初將載入於執行通道陣列405之尺寸內。為簡單起見，圖9a及圖9b之論述將係指其中片區尺寸與執行通道陣列尺寸相同之簡單情形。然而，將更清楚指令之一般操作可用於其中尺寸不同之實施例。 圖9a基本上展示圖7a之繪示之一推攝，其中二維移位暫存器陣列(包含其暈輪區)之完整大小被觀察為一陰影區。圖9b展示在每一陣列部位處執行之一特殊指令(QUADRANT)之結果。本文中，當將內容自RAM 407載入至特定移位陣列部位中時，QUADRANT針對每一移位暫存器陣列部位指令而計算正確位移並將其與基本記憶體位址相加。 在圖9b之特定實例中，在片區尺寸與執行通道陣列尺寸相同之情況下，與執行通道陣列區域相關聯之所有陣列部位將載入具有一位移0之LSheet_0。相比而言，緊靠執行通道陣列右側之暈輪區中之陣列部位將自具有一位移+1之LSheet_1載入，緊靠執行通道陣列下方之暈輪區中之陣列部位將自具有一位移+3之LSheet_3載入且執行通道陣列之隅角處之暈輪區中之陣列部位將自具有一位移+2之LSheet_2載入。 在一實施例中，指令接受片區之X及Y尺寸(Xs、Ys)以及規定陣列部位之位置之X及Y座標(Xa、Ya)兩者來作為輸入參數。QUADRANT指令可利用此等值將位移計算為： 位移= 0 if (Xa＜ Xs) AND (Ya＜ Ys) = TRUE 1 if (Xa ＞ Xs) AND (Ya＜ Ys) = TRUE 2 if (Xa ＞ Xs) AND (Ya ＞ Ys) = TRUE 3 if (Xa＜ Xs) AND (Ya ＞ Ys) = TRUE 在各種實施例中，編譯器產生具有Xa、Ya座標對之陣列，Xa、Ya座標對基本上識別將讀取座標對且規定Xs及Ys以作為立即運算元之陣列部位，此乃因其等跨越QUADRANT指令之所有執行而係常數。在執行指令之前，將Xa及Ya座標對載入至各別陣列部位中以作為輸入運算元資訊。在另一實施例中，指令另外接受[base]位址值以作為一輸入運算元，致使完整位址值[base]+位移可作為QUADRANT指令之結果而提供。可將[base]運算元規定為一立即運算元或可建構程式碼以動態地判定[base]值且將[base]值廣播至陣列部位以作為一額外輸入運算元。 注意，QUADRANT指令係針對其中判定輸出像素值之演算法將對跨越四個片區之像素值進行運算之一操作環境。對於(例如)其中演算法將對九個片區進行運算之操作環境而言，可將計算九個不同位移中之哪些位移用於任何特定陣列部位之另一指令HECTANT建立至指令集架構中。 圖10展示上文關於圖7a至圖7c所闡述之網格掃描處理方法之一替代實施例之一繪示。在圖10之方法中，若掃描係向右的，則暈輪區之右側最初未被載入。而是，僅在執行通道正下方之暈輪之部分被載入。在演算法運算期間，在需要來自LSheet_1之新值以(例如)達成一向左移位之程度上，該等值係沿著執行通道陣列之右側邊緣而非沿著暈輪之右側邊緣被載入。在其中演算法不在暈輪區外部運算且將有效地產生具有較少載入指令之程式碼之情形中，圖10之方法係特別有用的。 d. 實施方案實施例 中肯地指出，上文所闡述之各種影像處理器架構特徵未必限制於傳統意義上之影像處理且因此可應用於可(可不)致使影像處理器被重新特性化之其他應用。舉例而言，對比於用於實際相機影像之處理，若將上文所闡述之各種影像處理器架構特徵中之任一者用於動畫之創作及/或產生及/或呈現，則影像處理器可被特性化為一圖形處理單元。另外，上文所闡述之影像處理器架構特徵可應用於其他技術應用，諸如視訊處理、視覺處理、影像辨識及/或機器學習。在以此方式應用之情況下，影像處理器可與一更一般目的處理器(例如，其係運算系統之一CPU或運算系統之一CPU之一部分)整合(例如，作為一更一般目的處理器之一副處理器)，或者可係一運算系統內之一獨立處理器。 上文所論述之硬體設計實施例可體現於一半導體晶片內及/或可作為最終面向一半導體製造程序之一電路設計之一說明。在後者之情形中，此等電路說明可採取一(例如，VHDL或Verilog)暫存器轉移層次(RTL)電路說明形式、一閘級電路說明、一電晶體級電路說明或遮罩說明或上述各項之各種組合。電路說明通常體現於一電腦可讀儲存媒體上(諸如一CD-ROM或其他類型之儲存技術)。 自以上章節中肯地意識到，如上文所闡述之一影像處理器可以硬體形式體現於一電腦系統上(例如，作為處理來自手持式裝置之相機之資料之一手持式裝置之系統單晶片(SOC)之一部分)。在其中影像處理器體現為一硬體電路之情形中，注意，由影像處理器處理之影像資料可直接自一相機接收。本文中，影像處理器可係一離散相機之一部分，或係具有一整合式相機之一運算系統之一部分。在後者之情形中，影像資料可直接自相機接收或自運算系統之系統記憶體接收(例如，相機將其影像資料發送至系統記憶體而非影像處理器)。亦注意，以上章節中所闡述之諸多特徵可適用於一圖形處理單元(其呈現動畫)。 圖11提供對一運算系統之一例示性繪示。下文所闡述之運算系統之諸多組件適用於具有一整合式相機及相關聯影像處理器(例如，諸如一智慧型電話或平板電腦等一手持式裝置)之一運算系統。熟習技術者將能夠輕易地在該兩者之間進行區分。 如在圖11所見，基本運算系統可包含一中央處理單元1101 (其可包含(例如)複數個一般目的處理核心1115_1至1115_N及安置於一多核心處理器或應用處理器上之一主記憶體控制器1117)、系統記憶體1102、一顯示器1103 (例如，觸控螢幕、平板)、一本端有線點對點鏈路(例如，USB)介面1104、各種網路I/O功能1105 (諸如一乙太網路介面及/或蜂巢式數據機子系統)、一無線區域網路(例如，WiFi)介面1106，一無線點對點鏈路(例如，藍芽)介面1107及一全球定位系統介面1108、各種感測器1109_1至1109_N、一或多個相機1110、一電池1111、一功率管理控制單元1112、一揚聲器及麥克風1113以及一音訊編碼器/解碼器1114。 一應用處理器或多核心處理器1150可包含在其CPU 1101內之一或多個一般目的處理核心1115/一或多個圖形處理單元1116、一記憶體管理功能1117 (例如，一記憶體控制器)、一I/O控制功能1118及一影像處理單元1119。一般目的處理核心1115通常執行運算系統之作業系統及應用程式軟體。圖形處理單元1116通常執行圖形密集型功能以(例如)產生在顯示器1103呈現之圖形資訊。記憶體控制功能1117與系統記憶體1102介接以將資料寫入至系統記憶體1102/自系統記憶體1102讀取資料。功率管理控制單元1112通常控制系統1100之功率消耗。 影像處理單元1119可根據上文在以上章節中所詳盡闡述之影像處理單元實施例中之任一者來實施。另一選擇係或以組合方式，IPU 1119可耦合至GPU 1116及CPU 1101中之任一者或兩者以作為一副處理器。另外，在各種實施例中，GPU 1116可實施有上文所詳盡闡述之影像處理器特徵中之任一者。 相對於(在適當情況下)亦包含一整合式周邊裝置(例如，一或多個相機1110)之總體運算系統，觸控螢幕顯示器1103、通信介面1104至1107、GPS介面1108、感測器1109、相機1110及揚聲器/麥克風1113、編解碼器1114中之每一者全部皆可被視為各種形式之I/O (輸入及/或輸出)。取決於實施方案，此等I/O組件中之各個組件可被整合於應用處理器/多核心處理器1150上或者可位於晶粒處或應用處理器/多核心處理器1150之封裝外部。 在一實施例中，一或多個相機1110包含能夠量測相機與在其視域中之一物件之間的深度之一深度相機。在一應用處理器或其他處理器之一個一般目的CPU核心(或具有一指令執行管線以執行程式碼之其他功能區塊)上執行之應用程式軟體、作業系統軟體、裝置驅動程式軟體及/或韌體執行可執行上文所闡述功能中之任一者。 本發明之實施例可包含如上文陳述之各種程序。該等程序可體現為機器可執行指令。該等指令可用於致使一個一般目的或專用處理器執行特定程序。另一選擇係，可由含有用於執行程序之硬連線邏輯之特定硬體組件執行或由經程式化電腦組件及定製硬體組件之任何組合執行此等程序。 本發明之元件亦可提供為用於儲存機器可執行指令之一機器可讀媒體。機器可讀媒體可包含(但不限於)軟式磁片、光碟、CD-ROM及磁光碟、FLASH記憶體、ROM、RAM、EPROM、EEPROM、磁性或光學卡、傳播媒體或適合於儲存電子指令之其他類型媒體/機器可讀媒體。舉例而言，本發明可下載為一電腦程式，該電腦程式可藉助體現於一載波或其他傳播媒體中之資料信號而經由一通信鏈路(例如，一數據機或網路連接)自一遠端電腦(例如，一伺服器)被傳送至一請求電腦(例如，一用戶端)。 在前述說明書中，已參考其特定例示性實施例闡述了本發明。然而，顯而易見，可在不背離如隨附專利申請範圍中所陳述的本發明之較廣義精神及範疇之情況下對本發明做出各種修改及改變。因此，應將說明書及圖式視為一說明性意義而非一限制性意義。This application claims the benefit of US Provisional Application No. 62 / 300,671 "COMPILER MANAGED MEMORY FOR IMAGE PROCESSOR" filed on February 26, 2016, the entire contents of which are incorporated by reference. a. Image processor hardware architecture and operation FIG. 1 shows an embodiment of an architecture 100 of an image processor implemented in hardware. For example, the image processor may be the target of a compiler that converts code written for a virtual processor in a simulated environment into code that is actually executed by a hardware processor. As seen in FIG. 1, the architecture 100 includes interconnecting to a plurality through a network 104 (eg, a chip network (NOC) including a chip switching network, a chip ring network, or other kind of network). A plurality of sample processor units 102_1 to 102_N and a plurality of line buffer units 101_1 to 101_M corresponding to the slice generator units 103_1 to 103_N. In one embodiment, any line buffer unit can be connected to any slice generator and corresponding prototype processor through the network 104. In one embodiment, the code is compiled and loaded onto a corresponding template processor 102 to perform an image processing operation previously defined by a software developer (the code can also be loaded into the associated model processor). The tile generator 103 depends, for example, on design and implementation). In at least some instances, a first kernel program for a first pipeline stage can be loaded into a first board processor 102_1, and a second kernel program for a second pipeline stage can be loaded. Load into a second model processor 102_2 and so on to implement an image processing pipeline, where the first kernel performs the functions of the first stage of the pipeline, the second kernel performs the functions of the second stage of the pipeline, etc., and sets additional control flow methods To pass the output image data from one stage of the pipeline to another stage of the pipeline. In other configurations, the image processor can be implemented as a parallel machine with two or more than two sample processors 102_1, 102_2 operating on the same kernel code. For example, a highly dense and high data rate stream of image data can be processed by spreading the frames across multiple model processors that perform the same function across each. In other configurations, in the DAG design, basically any core DAG can be loaded onto the hardware processor by configuring each model processor with its own code core and checking the appropriate control flow. Point configuration into hardware to direct the output image from one core to the input of the next core. As a general process, the image data frame is received by a large I / O unit 105 and is transferred to one or more of the line buffer units 101 on a frame-by-frame basis. A specific line buffer unit parses its image data frame into a smaller image data area (referred to as a "line group"), and then passes the line group to a specific area generator through the network 104. A complete or "full" singular line group may (for example) consist of multiple consecutive complete columns or rows of a frame (for simplicity, this description will mainly refer to consecutive columns). The slice generator further analyzes the image data line group into a smaller image data zone (referred to as a "slice zone") and presents the slice to its corresponding model processor. In the case where an image processing pipeline or a DAG process has a single input, the input frame is usually guided to the same line buffer unit 101_1, and the line buffer unit 101_1 analyzes the image data into line groups and leads the line group to the area The generator 103_1 and the corresponding template processor 102_1 of the slice generator 103_1 execute the code of the first kernel in the pipeline / DAG. After the model processor 102_1 completes the operation of its processing line group, the slice generator 103_1 sends the output line group to a "downstream" line buffer unit 101_2 (in some use cases, the output line group can be sent Go back to the same line buffer unit 101_1) that had previously sent the input line group. The one or more consumers representing the next level / operation in the pipeline / DAG executed on the other consumer generators and template processors (e.g., tile generator 103_2 and template processor 102_2) of the "consumer" kernel The kernel receives the image data generated by the first plate processor 102_1 from the downstream buffer unit 101_2. In this way, one of the "producer" cores operating on a first prototype processor forwards its output data to one of the "consumer" kernels operating on a second prototype processor, where the consumer kernel is in production After the kernel is consistent with the design of the overall pipeline or DAG, the next task set is executed. The template processor 102 is designed to operate on multiple overlapping image data templates simultaneously. The internal hardware processing capacity of the multiple overlapping templates and the template processor effectively determines the size of an area. Herein, within the same plate processor 102, the channel array is uniformly operated to simultaneously process the image data surface area covered by multiple overlapping templates. As will be explained in more detail below, in various embodiments, the image data area is loaded into a two-dimensional register array structure in the template processor 102. It is believed that the use of tile and two-dimensional register array structures effectively provides power consumption improvements by, for example, moving a large amount of data into a large number of register spaces during a single load operation, with immediate implementation by a Channel arrays perform processing tasks directly on the data. In addition, the use of an execution channel array and corresponding register array provides different board sizes that can be easily programmed / configured. 2a to 2e illustrate, at a high level, the profiling activity of a line buffer unit 101, the finer-grained profiling activity of a slice generator unit 103, and the template processing of the prototype processor 102 coupled to the slice generator unit 103. Examples of activities three. FIG. 2 a illustrates an embodiment of an input frame of the image data 201. FIG. 2a also shows an outline of three overlapping templates 202 (each having a size of 3 pixels x 3 pixels). The template processor is designed to operate the templates. The solid black area highlights each output pixel for which each plate generates output image data. For simplicity, three overlapping templates 202 are shown as overlapping only in the vertical direction. It should be understood that the same board processor may be designed to have overlapping templates in both the vertical and horizontal directions. As seen in FIG. 2a, due to the vertically overlapping template 202 in the template processor, a single template processor can operate one of the broadband image data stored in the frame. As explained in more detail below, in one embodiment, the template processor processes the data within its overlapping templates in a left-to-right manner across the image data (and then repeats for the next line set in top-to-bottom order). Therefore, as the model processor continues its operation, the number of solid black zone output pixel blocks will increase horizontally to the right. As discussed above, the line buffer unit 101 is responsible for analyzing a line group of input image data from an incoming frame, which is sufficient for the model processor to operate within an extended number of upcoming cycles. An exemplary drawing of a line group is illustrated as a shaded area 203. In one embodiment, the line buffer unit 101 can learn different dynamics: receive a line group from a slice generator or send a line group to a slice generator. For example, according to a mode called "full cluster", the full-width line of image data is transferred between a line buffer unit and a region generator. According to a second pattern known as "virtual height", a line group is initially delivered as a subset of a full width column. The remaining columns are then passed sequentially in smaller fragments (less than full width). In the case where the line group 203 of the input image data has been defined by the line buffer unit and passed to the slice generator unit, the slice generator unit further analyzes the line group into a comparison that more accurately meets the hardware constraints of the model processor Fine area. More specifically, as will be explained in more detail below, in one embodiment, each board processor is composed of a two-dimensional shift register array. The two-dimensional shift register array basically moves the image data "below" an array of execution channels, where the shift pattern causes each execution channel to operate on the data in its respective template (i.e., each The execution channel processes on its own information template to produce an output for that template). In one embodiment, the slice area is "filled" or the surface area of the input image data loaded into the two-dimensional shift register array. As will be explained in more detail below, in various embodiments, there are actually two layers of two-dimensional register data that can be shifted on any cycle. For convenience, most of this description will only use the term "two-dimensional shift register" and the like to refer to the structure of two-dimensional register data with one or more of these layers that can be shifted . Therefore, as seen in FIG. 2b, the tile generator dissects an initial tile 204 from one of the clusters 203 and provides it to the template processor (herein, the tile zone corresponds to the shaded zone that is generally identified by the component symbol 204). As seen in FIG. 2c and FIG. 2d, the template processor operates the input image data region by effectively moving the overlapping template 202 in a left-to-right manner above the region. Until Figure 2d, the number of pixels that can calculate an output value based on the data in the slice area is exhausted (no other pixel position may have an output value determined based on the information in the slice area). For simplicity, the border area of the image has been ignored. As seen in Figure 2e, the tile generator then provides the next slice of zone 205 to the prototype processor to continue operation. Note that when the template starts to operate on the next area, the initial position of these templates is a progress from the depletion point on the first area to the lower right side (as previously shown in Figure 2d). With the new section 205, when the template processor operates on the new section in the same manner as the first section, the template will continue to move to the right only. Note that there is some overlap between the data of the first area 204 and the data of the second area 205 due to the boundary area of the template surrounding an output pixel portion. The overlap can only be handled by the tile generator transmitting the overlapping data again twice. In an alternative embodiment, in order to feed the next slice to the template processor, the slice generator may continue to send only new data to the template processor and the template processor reuses the overlapping data from the previous slice. b. Model processor design and operation FIG. 3a shows an embodiment of the on-board processor architecture 300. As seen in FIG. 3a, the model processor includes a data operation unit 301, a scalar processor 302 and associated memory 303, and an I / O unit 304. The data operation unit 301 includes an execution channel array 305, a two-dimensional shift array structure 306, and a separate random access memory 307 associated with a specific column or row of the array. The I / O unit 304 is responsible for loading the "input" data slice received from the slice generator into the data operation unit 301 and storing the "output" data slice from the model processor into the slice generator. In an embodiment, loading slice data into the data calculation unit 301 requires parsing a received slice into an image data row / image data row and loading the image data row / image data row into a two-dimensional shift temporary storage. The respective random access memory 307 of the row / row of the processor structure 306 or the execution channel array (explained in more detail below). If the slice is initially loaded into the memory 307, then the individual execution channels in the execution channel array 305 can load the slice data from the random access memory 307 into the two-dimensional shift register structure 306 at an appropriate time. (For example, when there is a load instruction just before operation on the piece of data). After loading a piece of data area (directly from a piece of area generator or self-memory 307) into the register structure 306, the execution channel of the execution channel array 305 immediately operates the data and finally completes the completed data into a piece The region form is "written back" directly to the slice generator or written back to the random access memory 307. If the completed data is written back to the random access memory 307, the I / O unit 304 extracts data from the random access memory 307 to form an output slice, and then the output slice is transferred to the slice generator. The scalar processor 302 includes a program controller 309. The program controller 309 reads the instructions of the model processor code from the scalar memory 303 and issues the instructions to the execution channels in the execution channel array 305. In one embodiment, a single same instruction is broadcast from the data operation unit 301 to all execution channels in the array 305 to achieve a type of SIMD behavior. In an embodiment, the instruction format of the instruction read from the scalar memory 303 and issued to the execution channel of the execution channel array 305 includes a very long instruction word (VLIW) type format, and the very long instruction word type format Contain more than one opcode / instruction. In another embodiment, the VLIW format includes two operation codes: an ALU operation code, which guides the ALU of each execution channel (as explained below, in one embodiment, it can specify more than one traditional ALU operation) Performing a mathematical function; and a memory operation code that directs a specific execution channel or a memory operation of a set of execution channels. The term "execution channel" refers to a set of one or more execution units capable of executing an instruction (e.g., a logic circuit that can execute an instruction). However, in various embodiments, an execution channel may include more processor-like functionality beyond the execution unit. For example, in addition to one or more execution units, an execution channel may include a logic circuit that decodes a received instruction or, in more cases like MIMD's design, includes fetching an instruction and decoding the instruction. Logic circuit. Regarding MIMD-like methods, although a centralized program control method has been described to a large extent in this article, a more decentralized method may be implemented in various alternative embodiments (for example, in each execution channel of array 305) Including code and a program controller). The combination of an execution channel array 305, a program controller 309, and a two-dimensional shift register structure 306 provides a widely adjustable / configurable hardware platform for a wide range of programmable functions. For example, application software developers can program a kernel with a wide range of different functional capabilities and sizes (for example, template size), provided that the execution channel can perform various functions and can easily access the output array. Input image data of parts. In addition to being used as a data storage device for image data operated by the execution channel array 305, the random access memory 307 can also store one or more lookup tables. In various embodiments, one or more scalar lookup tables can also be embodied in the scalar memory 303. A scalar lookup involves passing the same data value from the same index of the same lookup table to each of the execution channels in the execution channel array 305. In various embodiments, the VLIW instruction format described above is extended to also include a scalar opcode that directs a lookup operation performed by a scalar processor to a scalar lookup table. An index specified for use with an opcode may be an immediate operand or may be retrieved from some other data storage location. However, in one embodiment, the lookup according to one of the scalar lookup tables in the scalar memory basically involves broadcasting the same data value to all execution channels in the execution channel array 305 during the same clock cycle. Additional details on the use and operation of lookup tables are provided below. Figure 3b summarizes the VLIW instruction word embodiment discussed above. As seen in Figure 3b, the VLIW instruction word format contains fields for three separate instructions: 1) a scalar instruction 351, which is executed by a scalar processor; 2) an ALU instruction 352, which is executed by an execution channel Individual ALUs in the array are broadcast and executed in SIMD mode; and 3) a memory instruction 353 is broadcast and executed in a part of SIMD mode (for example, if the execution channels along the same row in the execution channel array share the same random When accessing memory, an execution channel from each of the different rows actually executes the instruction (the format of the memory instruction 353 may include an operand identifying which execution channel from each row executes the instruction). Contains a field 354 for one of one or more immediate operands. Which immediate operand information is used by which of instruction 351, instruction 352, instruction 353 can be identified in the instruction format. Instruction 351, instruction 352, instruction Each of 353 also contains its own input operand and the resulting information (e.g., a local register for ALU operations and a local register and a memory address for memory access instructions) .Yi Shi In the example, the scalar processor executes the scalar instruction 351 before the execution channel in the execution channel array executes any of the other instructions 352, 353. That is, the execution of the VLIW word includes a first loop, the scalar instruction 351 is executed on the first cycle; subsequent to a second cycle, other instructions 352, 353 may be executed on the second cycle (note that in various embodiments, instructions 352 and 353 may be executed in parallel). In one embodiment, the scalar instructions executed by the scalar processor include commands, which are issued to the slice generator to load / store the slice from the memory of the data operation unit or the 2D shift register. To the data operation unit's memory or 2D shift register. In this article, the operation of the slice generator can depend on the operation of the line buffer unit or prevent the slice generator from spending to complete any of the issues issued by the scalar processor. Other variables known to the execution stage before the number of loops of the command. Thus, in one embodiment, its scalar instruction 351 corresponds to the slice generator or any VLIW word that causes a command to be issued to the slice generator. It also contains the NOOP instructions in the other two instruction fields 352 and 353. Then the code enters one of the NOOP instructions in the instruction fields 352 and 353 and loops until the slice generator finishes loading its data operation unit. / Until the storage of the data operation unit. In this article, after issuing a command to the slice generator, the scalar processor can set a bit of an interlock register, and the slice generator will immediately repeat after completing the command. Set this bit. During the NOOP loop, the scalar processor monitors the bits of the interlocked bit. When the scalar processor detects that the slice generator has completed its command, it resumes normal execution again. Figure 4 shows a An embodiment of the data calculation component 401. As seen in FIG. 4, the data calculation component 401 includes an execution channel array 405 that is logically positioned on top of a two-dimensional shift register array structure 406. As discussed above, in various embodiments, a slice of image data provided by a slice generator is loaded into the two-dimensional shift register 406. Then execute the channel self-register structure 406 to operate the slice data. The execution channel array 405 and the shift register structure 406 are fixed in place relative to each other. However, shifting the data in the shift register array 406 in a strategic and coordinate manner also causes each of the execution channels in the execution channel array to process a different plate. In this way, each execution channel determines the output image value of a different pixel in the output slice generated. The structure according to FIG. 4 should be understood that the overlapping templates are not only arranged vertically but also horizontally, because the execution channel array 405 includes vertically adjacent execution channels and horizontally adjacent execution channels. Some obvious architectural features of the data operation unit 401 include that the shift register structure 406 has a wider size than the execution channel array 405. That is, there is a “halo” of a register 409 outside the execution channel array 405. Although the halo 409 is shown as being present on both sides of the array of execution channels, depending on the implementation, the halo may be present on fewer than (one) or more than (three or four) sides of the array of execution channels 405. When the data is moved "below" the execution channel 405, the halo 409 is used to provide "overflow" space for the data that overflows the boundary of the execution channel array 405. As a simple example, when processing the leftmost pixel of the template, one 5x5 template centered on the right edge of the execution channel array 405 will require four further halo register locations to the right. For simplicity, FIG. 4 shows the register on the right side of the halo as only having a horizontal shift connection and the register on the bottom side of the halo as only having a vertical shift connection. In a nominal embodiment, The registers on either side (right side, bottom side) will have both horizontal and vertical connections. Random access memory 407 or portions thereof coupled to each row and / or each row in the array provides additional spillover space (e.g., a random access memory can be assigned to each row across 4 execution channels and The row spans one of the execution channel arrays of the two execution channels ("zone"). For the sake of simplicity, the rest of this application will primarily refer to a column and / or row based allocation scheme). In this article, if the kernel operation of an execution channel requires the execution channel to process pixel values outside the two-dimensional shift register array 406 (some image processing routines may require the two-dimensional shift register array), then the image The plane of data can, for example, further overflow from the halo area 409 into the random access memory 407. For example, consider a 6X6 template, in which the hardware includes one halo area on the right side of the execution channel array on the right side of the execution channel and only one of the four storage elements. In this case, the data will need to be shifted further to the right at the right edge of halo 409 to fully process the template. The data moved outside the halo area 409 will then overflow to the random access memory 407. The following further provides other applications of the random access memory 407 and the model processor of FIG. 3. 5a to 5k demonstrate a working example of a method for moving image data into a two-dimensional shift register array "below" the execution channel array as mentioned above. As seen in FIG. 5 a, the data content of the two-dimensional shift array is shown by a first array 507 and the execution channel array is shown by a frame 505. In addition, two adjacent execution channels 510 in the execution channel array are also shown briefly. In this simple illustration 510, each execution channel includes a self-shifting register to accept data, receive data from an ALU output (e.g., use as an accelerator across a loop), or write output data to an output destination. A register R1. Each execution channel can also obtain the content “under” the execution channel in the two-dimensional shift array in a local register R2. Therefore, R1 is a physical register of the execution channel and R2 is a physical register of the two-dimensional shift register array. The execution channel includes one of the ALUs that can perform operations on the operands provided by R1 and / or R2. As will be explained in more detail below, in one embodiment, the shift register is actually implemented with multiple (certain "depth") storage / temporary components / array locations, but the shifting activity is limited to one storage Element plane (for example, only one storage element plane can be shifted / rotated). Figures 5a to 5k show one of these deeper register locations for storing results X from respective execution channels. For ease of illustration, the deeper register is drawn next to the corresponding register R2 instead of below. Figures 5a to 5k focus on the calculation of two templates whose center positions are aligned with the execution channel position pair 511 shown in the execution channel array. For ease of illustration, the pair of execution channels 510 are plotted as horizontal neighbors, but in fact, they are vertical neighbors according to the following example. As initially seen in Figure 5a, the execution channel is centered on its central template site. Figure 5b shows the destination code executed by the two execution channels. As seen in FIG. 5b, the code of the two execution channels causes the data in the shift register array to be shifted down by one position and shifted to the right by one position. This aligns the two execution channels to the upper left corners of their respective templates. The code then causes the data located in (R2) its respective parts to be loaded into R1. As seen in Figure 5c, the next code causes the execution channel pair to shift the data in the shift register array one unit to the left, which causes the value on the right side of each position of each execution channel to be shifted to each In the position of an execution channel. The value in R1 (previous value) is then added to the new value in the position (in R2) that has been shifted to the execution channel. Write the result to R1. As seen in FIG. 5d, the same procedure as described above for FIG. 5c is repeated, so that the resulting R1 now includes the value A + B + C in the upper execution channel and F + G + H in the lower execution channel. At this point, the two execution channels have processed the upper columns of their respective templates. Note the overflow in one halo area on the left side of the execution channel array (if there is a halo area on the left-hand side), or if there is no halo area on the left-hand side of the execution channel array, pay attention to random access Memory overflow. As seen in Figure 5e, the next code causes the data in the shift register array to be shifted up by one unit, which causes the two execution channels to align with the right edge of the middle column of their respective templates. The register R1 of the two execution channels currently contains the sum of the rightmost values of the top column and the middle column of the template. Figures 5f and 5g demonstrate the subsequent progress of moving the middle column of the template across the two execution channels to the left. The accumulation continues, so that the last two execution channels of the process of FIG. 5g include the sum of the values in the top and middle columns of their respective templates. Figure 5h shows another shift to align each execution channel with the lowest column of its corresponding template. Figures 5i and 5j show subsequent shifts to complete processing within the process of a template of two execution channels. Figure 5k shows an additional shift to align each execution channel with its correct position in the data array and write the results to the data array. In the example of FIGS. 5a to 5k, it is noted that the purpose code for the shift operation may include an instruction format that identifies the direction and magnitude of the shift expressed in the (X, Y) coordinates. For example, the purpose code for shifting to one of the previous parts can be expressed as the purpose code of shifting 0, +1. As another example, shifting to one of the right parts can be expressed as the purpose code of shifting +1,0. In various embodiments, a larger magnitude shift may also be specified by a destination code (for example, a shift of 0, +2). In this article, if the 2D shift register hardware only supports shifting one part / cycle, the machine can interpret the instructions as requiring multiple cycles to execute, or the 2D shift register hardware can be designed to support shifting Bit more than one site / cycle. The latter embodiment is explained in more detail below. Figure 6 shows another more detailed illustration of the unit of the array execution channel and the shift register structure (the register in the halo area does not include a corresponding execution channel). In one embodiment, the execution channel and the register space associated with each part of the execution channel array are implemented by realizing the circuit at each node of the execution channel array as seen in FIG. 6 . As seen in FIG. 6, the unit cell includes an execution channel 601 coupled to a register file 602 composed of four registers R2 to R5. During any cycle, the execution channel 601 can read from any of the registers R1 to R5 or write to any of the registers R1 to R5. For instructions that require two input operands, the execution channel can retrieve the two operands from any of R1 to R5. In an embodiment, the two-dimensional shift register structure is implemented by the following operations: during a single cycle, one of (only) any one of the registers R2 to R4 is permitted to be output through the output multiplexer 603 The content is moved "out" to one of its neighbor's register files, and the register R2 is replaced by the content of the corresponding register moved from one of its neighbors by the input multiplexer 604 The content of (only) one to R4 causes the shifts between neighbors in the same direction (for example, all execution channels are shifted to the left, all execution channels are shifted to the right, etc.). Although the contents of the same register are usually moved out and replaced with the contents moved in during the same cycle, the multiplexer configuration 603, 604 allows different shift sources and shift targets in the same register file during the same cycle Register. As shown in FIG. 6a, note that during a shift sequence, an execution channel will move content from its register file 602 to one of its left neighbor, right neighbor, top neighbor, and bottom neighbor. Each. In combination with the same shift sequence, the execution channel will also shift content from one of its left, right, top, and bottom neighbors to its register file. In addition, for all execution channels, the moving target and moving source should be consistent with the same moving direction (for example, if moving to the right neighbor, it should move in from the left neighbor). Although in one embodiment, the contents of only one register are permitted to be shifted per execution channel per cycle, other embodiments may allow the contents of more than one register to be moved in / out. For example, if the second example of one of the multiplexer circuits 603, 604 seen in FIG. 6a is incorporated into the design of FIG. 6a, the contents of the two registers can be moved in / out during the same cycle . Of course, in an embodiment in which the contents of only one register are allowed to be shifted per cyclic, it is possible to multiply between mathematical operations by consuming more shift clock cycles between the mathematical operations for the shift. A register (for example, the contents of two registers can be shifted between mathematical operations by spending two shift operations between mathematical operations). If all the contents of the register file that is not an execution channel are removed during a shift sequence, then note that the unremoved contents of the register of each execution channel are still in place (not shifted). In this way, any unshifted content that has not been replaced by the shifted content persists across the shift loop at the local end of the execution channel. The memory unit (`` M '') seen in each execution channel is used to load / store data from the random access memory space associated with the rows and / or rows of execution channels in the execution channel array The random access memory space. In this paper, the M unit is used as a standard M unit because it is usually used to load / store data that can be loaded / stored from the register space of the execution channel itself. In various embodiments, the main operation of the M unit is to write data from a local register into the memory, and read data from the memory and write it into a local register. Regarding the ISA operation code supported by the ALU unit of the hardware execution channel 601, in various embodiments, the mathematical operation code supported by the hardware ALU and the virtual execution channel (for example, ADD, SUB, MOV, MUL, MAD, ABS, DIV, SHL, SHR, MIN / MAX, SEL, AND, OR, XOR, NOT) supported mathematical operation code links (for example, substantially the same). As explained above, the memory access instruction may be executed by the execution channel 601 to fetch data from its associated random access memory / store data to its associated random access memory. In addition, the hardware execution channel 601 supports shift operation instructions (right, left, up, down) to shift the data in the two-dimensional shift register structure. As explained above, the program control instructions are mainly executed by the scalar of the model processor. c. Compiler Management Model Processor Memory Referring back to FIG. 4, it can be seen that a halo area of the register 409 exists. In the specific embodiment of FIG. 4, the halo area resides around the right edge and the lower edge of the execution channel array 405 (other embodiments may Halo registers are included on more or fewer sides of the execution channel array). In the previous discussion, a “slice area” is understood as an image information array that consumes an internal shift register space having the size of the execution channel array 405. Herein, in various embodiments, the register portion in 409 does not include an associated ALU unit for executing image processing instructions on the image data—but—the halo area 409 exists, for example, for accumulation in the execution channel array area "Spillover" data from shift activities. In this way, the area of the image data that can be processed corresponds to area 405 and a "slice area" is understood to coexist with area 405. Loading a region into the register array 406 includes loading image data into the region 405. A compiler is responsible for inserting instructions into the code. The code controls the loading of the information area from the area generator to the data operation unit 401 of the same board processor. The internal RAM 407 is loaded / loaded from the data operation unit 401 of the same board processor. The internal RAM 407 is loaded into the slice generator. As such, in various embodiments, the compiler is responsible for determining which extents are loaded into RAM 407 from the extent generator and when such extents are loaded. In addition, the compiler is also responsible for determining which sections of the sample processor RAM 407 are loaded into the two-dimensional shift array 406. Note that the RAM 407 can be decomposed into separate banks, where each bank is assigned a specific image area with respect to the shift register array (for example, the RAM bank 407_1 holds image data of the first row of the shift register array, The RAM library 407_2 stores image data of the second row of the shift register array, etc.). In this article, where possible, avoid reloading the same data slice from the slice generator into RAM 407 and / or reload the same data slice from RAM 407 into the two-dimensional shift register 406. In order to, for example, minimize the power consumption of the image processor. As explained in more detail immediately below, if the compiler is aware of the presence of halo area 409, even if the basic unit of image data is understood as a data area corresponding to a smaller area of the execution channel array 405, the low effectiveness. In particular, in the case where the image processing algorithm processes data of any output pixels extending outside the halo in the execution channel array 405, it is declared to avoid low efficiency. Figures 7a to 7d show a basic example. As seen in FIG. 7a, an input image data slice corresponds to a region 701 of a larger input image. For simplicity, Figures 7a to 7d assume that the input tiles have the same size as the array of execution channels. Although this configuration can often be convenient, it is not necessary. For example, in situations where the resolution of the input surface is different from the output surface (e.g., due to increased or decreased sampling), the tiles may have a different size from the array of execution channels. For example, in a processor with a 16x16 execution channel array, a 2x reduced sampling input slice may have a size of 32x32 and a 2x increased sampling input slice may have a size of 8x8. If the input image is understood to include not only the area 701 but also surrounding image data that can be included in the halo area, the total amount of input image data will consume the shadow area 720. When determining the output pixel values of the pixels in the area 701, at least some algorithms can be designed to process the input image data outside the halo area (such as the larger area 730). For example, if the size of the execution channel array 405 is 16 pixel parts multiplied by 16 pixel parts and the size of the halo area is an additional 4 pixel parts along one of the X axis and 4 pixel parts along the Y axis Then, the area 701 will have the size of 16 pixel parts by 16 pixel parts and the area 720 will have the size of 20 pixel parts by 20 pixel parts. If the algorithm for determining the output pixel value of the pixels in the area 701 processes a template having a size of 18 pixels by 18 pixels, the surface area of the area 701 to be processed will extend outward from the area 720 to include edges Limited to 730 areas. In this article, for example, in order to adapt to the processing of the pixel portion at the lower right corner of the area 701, a pixel will be needed in the lower right corner of the area bounded by the margin 730. Therefore, processing of region 701 requires a large amount of data from regions 702, 703, and 704. In one embodiment, the compiler is designed to understand the layout of multiple regions in an input image, the size of the execution channel array, the size of the halo, and the size of the template to be processed for a specific output pixel in the execution channel array area. . Then, the compiler continues to insert memory load instructions at appropriate locations in the code, and these instructions load the next information slice from the slice generator into the data operation unit RAM 407. In addition, as will be explained in more detail below, the compiler also inserts data movement instructions to move data slices in the random access memory 407 of the data operation unit in order to enhance its reuse and thereby reduce the same data slice from the slice generator. Repeated loading to random access memory 407. FIG. 7b shows a sequence of instructions 740 constructed by the compiler, which cause the tile generator to initially load a sufficient number of tiles into the random access memory 407 to target each of the pixel portions of the first slice portion 701 Perform the algorithm fully. As seen in Figure 7b, data from four slices 701 to 704 is loaded and assigned logical slice identifiers (Lsheet_0, Lsheet_1, LSheet_2, LSheet_3). In this paper, if the entire shift register array 406 including the halo region 409 is considered, the number of loaded regions corresponds to the number of regions reached by the image processing algorithm. As can be seen from the discussion of FIG. 3a and FIG. 3b, in various embodiments, the program controller 309 associated with the scalar processor 302 executes a command corresponding to a command to the slice generator to load the data slice from the data operation unit 301 / The data area is stored in the data operation unit 301. As such, the instruction 740 can be executed by the scalar processor 302. The compiler also constructs subsequent instructions 750, 760 to load the contents of the four registers just loaded into the RAM into the shift register array 406 (MEM LOAD). The instruction 750 fills the shift register area coexisting with the execution channel array 405 with the content of LSheet_0 (the content of the image area 701). Similarly, consistent with the discussion above, the scalar processor 302 may also execute instructions 750, 760. Instruction 760 fills the halo area. That is, the instruction 760 performs the following operations: 1) loads the left-hand side (LHS) of the region 702 (Lsheet_1) into the region of the halo 409 residing at the right edge of the execution channel array 405; 2) loads the region 704 (Lsheet_3) Load the upper part (UPR) into the area of halo 409 that resides directly below the lower edge of the execution channel array 405; 3) Load the upper left corner (Lsheet_4) of the area 705 into the execution channel array 405 In the halo area at the bottom right corner. After these loadings are performed, the contents of the entire shift register array containing the halo area (area 720 in Fig. 7a) contains the input image data that has been appropriately positioned. Herein, referring to FIG. 4, note that each execution channel array portion includes a memory access unit (M) for executing a memory load instruction (MEM LOAD) to extract image data from the random access memory 407. . Although not shown in FIG. 4, in various embodiments, each of the positions in the halo region 409 also includes a memory access unit, so that image data values can be loaded from the random access memory 407 To the halo zone 409. However, in addition, in various embodiments, the halo area does not include an ALU unit, so that the actual image processing is limited to the image data in the execution channel array 405. Therefore, the instruction 750 corresponds to a memory loading instruction that is executed individually at each execution channel array location but has different input operation metadata (which defines image data to be loaded) based on its location in the array, Similarly, the MEM LOAD instruction 760 corresponds to a command executed at a specific position in the halo area 409 but having different input operation metadata (which defines image data to be loaded) based on its position around the execution channel array. Memory load command. The techniques used to specify the addresses of these instructions are explained in more detail below. The compiler also constructs one or more sets of instructions 770 to execute an image processing algorithm that determines the output pixel value for the pixel portion in the Lsheet_0 portion. Consistent with the above discussion, the calculation includes operating the same plate area for each pixel portion generated by shifting the contents in the two-dimensional shift register array. Therefore, the compiler constructs not only for performing mathematical calculations on the template but also for executing several instructions corresponding to the register shift instructions. In the example currently being discussed, it can be known that the size of the template to be processed at any pixel portion in LSheet_0 is 18 x 18. In this way, some image data will "overflow" from the upper side and the left-hand side of the execution channel array 405 into the random access memory 407. That is, shifting the data to the left will cause data from the area 702 (LSheet_1) and area 703 (LSheet_2) within the area bounded by margin 720 but outside the area bounded by margin 701 to be loaded into the halo. Area 409 is in the right edge. Loading data into the right edge of the halo area 409 will effectively push the "overflow" data from the left edge of the execution channel array and the left edge of the halo area 409 that resides directly below the execution channel array 405. Bit register. The overflowed / pushed data is written into the random access memory 407. Similarly, the "upward" shift of data will cause the data from area 704 (LSheet_3) and area 703 (LSheet_2) in the area bounded by margin 720 but outside the execution channel area to be loaded into the halo area 409. In the lower edge. Loading data into the lower edge of the halo area 409 will effectively push out the "overflow" data from the top edge of the execution channel array 405 and the top edge of the halo area residing on the right side of the execution channel array 405. Register. The overflowed / pushed data is also written into the random access memory 407. In addition, in order to achieve the shift, the compiler constructs the code for all the new data loaded from RAM 407 to the shift register and the pushed back data from the shift register to RAM 407. After performing all shifts and calculations on slice 701 (LSheet_0) 770, the process will continue to scan to the right in a raster-like form (one of the output slices of zone 701 can also be written to random access memory 407 for use in Forwarded to the slice generator). In order to implement a raster scan of the algorithm, it is only necessary to reassign the logical slice. After that, the same code can be executed again to process the pixel output value of the next slice. In this way, the algorithm for performing the scan on the image can be constructed by the compiler in a software loop. In this article, the internal indicators in the loop program can be updated with each new iteration of the loop. Specifically, when the core routine realizes that it has reached the "right side" of the data to be loaded for this recursion, it also realizes that the next recursion is coming. In this paper, as seen in Figure 7c, the compiler constructs an additional set of instructions 780 that prepares the machine to use raster scans to process the algorithm for the next slice. The instructions include moving (MOV) the contents of LSheet_1 to LSheet_0 and moving the contents of LSheet_2 to LSheet_3. In addition, the instruction 780 includes an instruction to load the next LSheet_1 (the slice 705) and the next LSheet_2 (the slice 706) from the slice generator into the RAM 407. After the execution of these instructions 780, the context of the machine is no different from the context of the machine in FIG. 7b before executing instruction 770, except that the area to be processed is one block to the right (that is, the area 702 and Non-sector 701). It is important that the regions (ie, regions 702 and 703) already loaded into the RAM 407 are not reloaded into the RAM 407 from the region generator. In this way, any inefficiency that would occur if the regions 702 and 703 were reloaded into the RAM 407 is avoided. Note that after the earlier contents of Sheet_1 and Sheet_2 have been moved to LSheet_0 and LSheet_3, respectively, as indicated by the SG instruction in instruction 780, LSheet_1 (segment 705) and LSheet_2 (segment) can be executed, for example, during operation 770 706) Load from the slice generator to the RAM 407 and then move these slices to the Sheet_1 and Sheet_2 locations in the RAM. As such, the SG LOAD instruction of instruction 780 may actually be implemented as an additional MOV instruction in RAM 407. In one embodiment, the move (MOV) instruction of instruction 780 actually moves the data entity into RAM 407. In this way, the addresses of LSheet_0 to LSheet_3 specified in the code are fixed addresses. Although the method outlined above with respect to Figs. 7a to 7c is an example of the size of the template to be processed for the pixels within the area 701 which is large enough to include pixels residing outside the halo area, it is believed that the method The size of the template to be processed for the pixels in area 701 (i.e., in the execution channel array) is small enough that all pixels to be processed reside in the halo area (i.e., pixels outside boundary 720 and within boundary 730) Or you don't need to go beyond the best). In this case, avoid loading extra image data into the two-dimensional shift register (for example, along the right edge of the halo area). FIG. 8 illustrates one of the methods described above. The method includes: 801 repeatedly performing the following operations. The next image data area is loaded from a first part of a memory into a two-dimensional shift register array 802. The memory is locally coupled to the two-dimensional shift register array and an execution channel array. The execution channel array has a size smaller than the two-dimensional shift register array along at least one array axis. The next loaded image data area is kept in an image area of the two-dimensional shift register array. The output value of the next image data slice is determined by executing code instructions along the respective channels of the execution channel array, wherein the same plate size used in determining these output values includes only the two-dimensional shift temporary storage Pixels in the filter array 803. The next image data area to be completely loaded into the two-dimensional shift register array is moved away from a second part of the memory to the first part of the memory 804. It can be known from the previous discussion that during the execution of the instructions 750, 760, and 770, image data can be loaded from the RAM 407 into the two-dimensional shift register 406. In this article, it is assumed that each individual part of the two-dimensional shift register 406 (including the halo region) includes a memory access unit for executing a memory load command at the local end, so that data can be transferred from The RAM 407 is individually loaded into its local register space. In an embodiment, the compiler fixes a basic address component in RAM 407 for LSheet_0 and the additional logical slices (for example, LSheet_1, LSheet_2, and LSheet_3) that are resolved by the compiler to perform loops have relative addresses The displacement of the base address component. For example, if the address used for LSheet_0 in RAM 407 is [base], the address used for LSheet_1 is [base] +1, the address used for LSheet_2 is [base] +2 and used for LSheet_3 The address is [base] +3. In order to support a broadly programmable environment, the instruction set architecture of the execution units in the execution channel array and in the halo area supports one instruction that generates the correct displacement of a specific shift register array location. This displacement can then be used, for example, to generate the correct address. In this paper, it is pointed out that the examples of FIG. 7a to FIG. 7c are too simple in the sense that the area size is the same as the execution channel array size. That is, both the tile area and the execution channel array have a size of 16 pixel parts x 16 pixel parts. Other embodiments may choose to have a tile size larger or smaller than one of the execution channel arrays, for example, along either or both dimensions. In the former case, for example, LSheet_0 will extend into the halo area, while in the latter case, for example, LSheet_1 and / or LSheet_3 will initially be loaded within the size of the execution channel array 405. For simplicity, the discussion of FIGS. 9a and 9b will refer to a simple case where the size of the slice area is the same as the size of the execution channel array. However, it will be clearer that the general operation of the instructions can be used for embodiments in which the sizes differ. FIG. 9a basically shows one of the drawings shown in FIG. 7a, in which the full size of the two-dimensional shift register array (including its halo region) is observed as a shaded region. Figure 9b shows the result of executing a special instruction (QUADRANT) at each array location. Here, when loading content from RAM 407 into a specific shift array location, QUADRANT calculates the correct shift for each shift register array location instruction and adds it to the base memory address. In the specific example of FIG. 9b, in the case where the tile size is the same as the execution channel array size, all array locations associated with the execution channel array area will be loaded with LSheet_0 with a displacement of zero. In contrast, the array part in the halo area immediately to the right of the execution channel array will be loaded from LSheet_1 with a displacement of +1, and the array part in the halo area immediately below the execution channel array will have a displacement of its own. LSheet_3 of +3 is loaded and the array part in the halo area at the corners of the execution channel array is loaded from LSheet_2 with a displacement of +2. In an embodiment, both the X and Y dimensions (Xs, Ys) of the instruction receiving area and the X and Y coordinates (Xa, Ya) of the positions of the specified array site are used as input parameters. The QUADRANT instruction can use these values to calculate the displacement as: displacement = 0 if (Xa< Xs) AND (Ya< Ys) = TRUE 1 if (Xa ＞ Xs) AND (Ya< Ys) = TRUE 2 if (Xa ＞ Xs) AND (Ya ＞ Ys) = TRUE 3 if (Xa< Xs) AND (Ya> Ys) = TRUE In various embodiments, the compiler generates an array with Xa, Ya coordinate pairs. The Xa, Ya coordinate pairs basically recognize that the coordinate pairs will be read and Xs and Ys are specified for immediate operation. The array part of the element is constant because it spans all executions of the QUADRANT instruction. Before executing the instruction, the Xa and Ya coordinate pairs are loaded into the respective array parts as input operand information. In another embodiment, the instruction additionally accepts the [base] address value as an input operand, so that the full address value [base] + shift can be provided as a result of the QUADRANT instruction. The [base] operand can be specified as an immediate operand or the code can be constructed to dynamically determine the [base] value and broadcast the [base] value to the array location as an additional input operand. Note that the QUADRANT instruction is one of the operating environments for algorithms in which the output pixel value is determined to operate on pixel values that span four slices. For an operating environment where, for example, the algorithm will operate on nine tiles, another instruction, HECTANT, which calculates which of the nine different displacements is used for any particular array location, is built into the instruction set architecture. FIG. 10 is a drawing showing an alternative embodiment of the grid scanning processing method described above with reference to FIGS. 7a to 7c. In the method of FIG. 10, if the scanning system is to the right, the right side of the halo area is not initially loaded. Instead, only the part of the halo just below the execution channel is loaded. During algorithmic operations, to the extent that new values from LSheet_1 are needed to achieve, for example, a leftward shift, these values are loaded along the right edge of the execution channel array rather than along the right edge of the halo . The method of FIG. 10 is particularly useful in situations where the algorithm does not operate outside the halo region and will effectively generate code with fewer load instructions. d. 实施 例 例 Implementation Examples It is fair to point out that the various image processor architecture features described above are not necessarily limited to traditional image processing and can therefore be applied to other applications that may (or may not) cause the image processor to be re-characterized. For example, compared to processing for actual camera images, if any of the various image processor architecture features described above are used for the creation and / or production and / or presentation of animation, the image processor Can be characterized as a graphics processing unit. In addition, the image processor architecture features described above can be applied to other technical applications, such as video processing, visual processing, image recognition, and / or machine learning. When applied in this manner, the image processor may be integrated with a more general purpose processor (for example, it is a CPU of a computing system or a part of a CPU of a computing system) (for example, as a more general purpose processor A sub-processor), or an independent processor within a computing system. The hardware design embodiments discussed above may be embodied in a semiconductor wafer and / or may be used as an illustration of a circuit design that ultimately faces a semiconductor manufacturing process. In the latter case, these circuit descriptions can take the form of a (for example, VHDL or Verilog) register transfer level (RTL) circuit description, a gate-level circuit description, a transistor-level circuit description or mask description, or the above Various combinations of various items. The circuit description is usually embodied on a computer-readable storage medium (such as a CD-ROM or other type of storage technology). From the above chapters it is readily realized that an image processor as described above may be embodied in hardware on a computer system (e.g., a system-on-chip of a handheld device as one of the processing data from a camera of a handheld device ( SOC). In the case where the image processor is embodied as a hardware circuit, note that the image data processed by the image processor can be received directly from a camera. Herein, the image processor may be part of a discrete camera or part of a computing system with an integrated camera. In the latter case, the image data may be received directly from the camera or from the system memory of the computing system (eg, the camera sends its image data to the system memory instead of the image processor). It is also noted that many of the features described in the above section can be applied to a graphics processing unit (which presents animation). FIG. 11 provides an exemplary drawing of a computing system. Many of the components of the computing system described below are applicable to a computing system having an integrated camera and associated image processor (eg, a handheld device such as a smart phone or tablet). Those skilled in the art will be able to easily distinguish between the two. As seen in FIG. 11, the basic computing system may include a central processing unit 1101 (which may include, for example, a plurality of general-purpose processing cores 1115_1 to 1115_N and a main memory disposed on a multi-core processor or application processor Controller 1117), system memory 1102, a display 1103 (e.g., touch screen, tablet), a local wired point-to-point link (e.g., USB) interface 1104, various network I / O functions 1105 (e.g., one Ethernet interface and / or cellular modem subsystem), a wireless local area network (e.g., WiFi) interface 1106, a wireless point-to-point link (e.g., Bluetooth) interface 1107, and a global positioning system interface 1108, various The sensors 1109_1 to 1109_N, one or more cameras 1110, a battery 1111, a power management control unit 1112, a speaker and microphone 1113, and an audio encoder / decoder 1114. An application processor or multi-core processor 1150 may include one or more general-purpose processing cores 1115 / one or more graphics processing units 1116, a memory management function 1117 (e.g., a memory control Device), an I / O control function 1118, and an image processing unit 1119. The general purpose processing core 1115 usually executes the operating system and application software of a computing system. The graphics processing unit 1116 typically performs graphics-intensive functions to, for example, generate graphics information presented on the display 1103. The memory control function 1117 interfaces with the system memory 1102 to write data to the system memory 1102 / to read data from the system memory 1102. The power management control unit 1112 generally controls the power consumption of the system 1100. The image processing unit 1119 may be implemented according to any one of the image processing unit embodiments detailed above in the above sections. Alternatively, or in combination, the IPU 1119 may be coupled to either or both of the GPU 1116 and the CPU 1101 as a secondary processor. In addition, in various embodiments, the GPU 1116 may implement any of the image processor features detailed above. As opposed to (if appropriate) an overall computing system that also includes an integrated peripheral device (eg, one or more cameras 1110), a touch screen display 1103, a communication interface 1104 to 1107, a GPS interface 1108, and a sensor 1109 Each of the camera 1110, speaker / microphone 1113, and codec 1114 can be considered as various forms of I / O (input and / or output). Depending on the implementation, each of these I / O components may be integrated on the application processor / multi-core processor 1150 or may be located at the die or outside the package of the application processor / multi-core processor 1150. In one embodiment, the one or more cameras 1110 include a depth camera capable of measuring the depth between the camera and an object in its field of view. Application software, operating system software, device driver software, and / or software running on a general-purpose CPU core (or an instruction execution pipeline to execute other functional blocks of code) of an application processor or other processor The firmware execution may perform any of the functions described above. Embodiments of the invention may include various procedures as stated above. Such programs may be embodied as machine-executable instructions. These instructions can be used to cause a general purpose or special purpose processor to execute a particular program. Alternatively, these procedures may be performed by specific hardware components containing hard-wired logic for executing the procedures or by any combination of programmed computer components and custom hardware components. Elements of the present invention may also be provided as a machine-readable medium for storing machine-executable instructions. Machine-readable media may include, but is not limited to, floppy disks, optical disks, CD-ROMs and magneto-optical disks, flash memory, ROM, RAM, EPROM, EEPROM, magnetic or optical cards, propagation media, or media suitable for storing electronic instructions Other types of media / machine-readable media. For example, the present invention can be downloaded as a computer program which can be transmitted from a remote site via a communication link (for example, a modem or a network connection) by means of a data signal embodied in a carrier wave or other propagation medium. A client computer (e.g., a server) is transmitted to a requesting computer (e.g., a client). In the foregoing specification, the invention has been described with reference to specific exemplary embodiments thereof. However, it will be apparent that various modifications and changes can be made to the present invention without departing from the broader spirit and scope of the invention as set forth in the scope of the attached patent application. Therefore, the description and drawings should be regarded as an illustrative rather than a restrictive one.
101_1‧‧‧線緩衝器單元101_1‧‧‧line buffer unit
101_2‧‧‧線緩衝器單元/下游線緩衝器單元101_2‧‧‧line buffer unit / downstream line buffer unit
101_M‧‧‧線緩衝器單元101_M‧‧‧line buffer unit
102_1‧‧‧樣板處理器單元/第一樣板處理器/樣板處理器102_1‧‧‧model processor unit / first model processor / model processor
102_2‧‧‧第二樣板處理器/樣板處理器102_2‧‧‧Second model processor / model processor
102_N‧‧‧樣板處理器單元102_N‧‧‧Model processor unit
103_1‧‧‧片區產生器單元/片區產生器103_1‧‧‧Slice generator unit / slice generator
103_2‧‧‧片區產生器103_2‧‧‧ area generator
103_N‧‧‧片區產生器單元103_N‧‧‧ Zone generator unit
104‧‧‧網路104‧‧‧Internet
105‧‧‧大型輸入/輸出單元105‧‧‧large input / output unit
201‧‧‧影像資料201‧‧‧Image data
202‧‧‧重疊樣板/垂直重疊樣板202‧‧‧ Overlapping Template / Vertical Overlapping Template
203‧‧‧陰影區/線群203‧‧‧Shaded area / line group
204‧‧‧初始片區/第一片區204‧‧‧Initial Area / First Area
205‧‧‧下一片區/新片區/第二片區205‧‧‧Next Area / New Area / Second Area
300‧‧‧樣板處理器架構300‧‧‧ Model Processor Architecture
301‧‧‧資料運算單元301‧‧‧Data Operation Unit
302‧‧‧純量處理器302‧‧‧ scalar processor
303‧‧‧相關聯記憶體/純量記憶體303‧‧‧associative memory / scalar memory
304‧‧‧輸入/輸出單元304‧‧‧Input / Output Unit
305‧‧‧執行通道陣列/陣列305‧‧‧execution channel array / array
306‧‧‧二維移位陣列結構/暫存器結構306‧‧‧Two-dimensional shift array structure / register structure
309‧‧‧程式控制器309‧‧‧Program Controller
351‧‧‧純量指令/指令351‧‧‧scalar instruction / instruction
352‧‧‧ALU指令/指令/另外指令/其他指令/指令欄位352‧‧‧ALU instruction / instruction / other instruction / other instruction / instruction field
353‧‧‧記憶體指令/指令/另外指令/其他指令/指令欄位353‧‧‧Memory Command / Command / Additional Command / Other Command / Command Field
354‧‧‧欄位354‧‧‧field
401‧‧‧資料計算組件/資料運算單元401‧‧‧data computing unit / data computing unit
405‧‧‧執行通道陣列/執行通道/區域405‧‧‧Execution Channel Array / Execution Channel / Area
406‧‧‧二維移位暫存器陣列結構/二維移位暫存器/暫存器結構/移位暫存器結構/移位暫存器陣列/二維移位暫存器陣列/暫存器陣列/二維移位陣列406‧‧‧Two-dimensional shift register array structure / two-dimensional shift register / register structure / shift register structure / shift register array / two-dimensional shift register array / Register array / two-dimensional shift array
407‧‧‧隨機存取記憶體/內部隨機存取記憶體/樣板處理器隨機存取記憶體407‧‧‧RAM / internal random access memory / template processor random access memory
407_1‧‧‧隨機存取記憶體庫407_1‧‧‧ random access memory bank
407_2‧‧‧隨機存取記憶體庫407_2‧‧‧ Random Access Memory Bank
409‧‧‧暫存器/暈輪/暈輪區409‧‧‧Register / Halo / Halo area
505‧‧‧圖框505‧‧‧Frame
507‧‧‧第一陣列507‧‧‧first array
510‧‧‧鄰近執行通道/簡單繪示/執行通道對510‧‧‧adjacent execution channel / simple drawing / execution channel pair
511‧‧‧執行通道位置對511‧‧‧ execution channel position pair
601‧‧‧執行通道/硬體執行通道601‧‧‧execution channel / hardware execution channel
602‧‧‧暫存器檔案602‧‧‧Register file
603‧‧‧輸出多工器/多工器配置/多工器電路603‧‧‧Output Multiplexer / Multiplexer Configuration / Multiplexer Circuit
604‧‧‧輸入多工器/多工器配置/多工器電路604‧‧‧Input Multiplexer / Multiplexer Configuration / Multiplexer Circuit
701‧‧‧區/片區/第一片區部位/影像區/邊限701‧‧‧area / area / part of the first area / image area / margin
702‧‧‧片區702‧‧‧ area
703‧‧‧片區703‧‧‧area
704‧‧‧片區Area 704‧‧‧
705‧‧‧片區Area 705‧‧‧
706‧‧‧片區Area 706‧‧‧
720‧‧‧陰影區/區/邊限720‧‧‧Shadow area / area / margin
730‧‧‧更大區/邊限730‧‧‧larger area / margin
740‧‧‧指令740‧‧‧Instruction
750‧‧‧後續指令/指令750‧‧‧ follow-up instructions / instructions
760‧‧‧後續指令/指令760‧‧‧Following instructions / instructions
770‧‧‧指令/計算/操作770‧‧‧Instructions / Calculations / Operations
780‧‧‧指令780‧‧‧Instruction
1100‧‧‧控制系統1100‧‧‧control system
1101‧‧‧中央處理單元1101‧‧‧Central Processing Unit
1102‧‧‧系統記憶體1102‧‧‧System Memory
1103‧‧‧顯示器/觸控螢幕顯示器1103‧‧‧Display / Touch Screen Display
1104‧‧‧本端有線點對點鏈路介面/通信介面1104‧‧‧Local wired point-to-point link interface / communication interface
1105‧‧‧網路輸入/輸出功能1105‧‧‧Network input / output function
1106‧‧‧無線區域網路介面1106‧‧‧Wireless LAN Interface
1107‧‧‧無線點對點鏈路介面/通信介面1107‧‧‧Wireless point-to-point link interface / communication interface
1108‧‧‧全球定位系統介面1108‧‧‧Global Positioning System Interface
1109_1至1109_N‧‧‧感測器1109_1 to 1109_N‧‧‧ Sensor
1110‧‧‧相機1110‧‧‧ Camera
1111‧‧‧電池1111‧‧‧ Battery
1112‧‧‧功率管理控制單元1112‧‧‧Power Management Control Unit
1113‧‧‧揚聲器及麥克風1113‧‧‧Speaker and microphone
1114‧‧‧音訊編碼器/解碼器/編解碼器1114‧‧‧Audio encoder / decoder / codec
1115_1至1115_N‧‧‧一般目的處理核心1115_1 to 1115_N‧‧‧ General purpose processing core
1116‧‧‧圖形處理單元1116‧‧‧Graphics Processing Unit
1117‧‧‧主記憶體控制器/記憶體管理功能/記憶體控制功能1117‧‧‧Main memory controller / memory management function / memory control function
1118‧‧‧輸入/輸出控制功能1118‧‧‧ input / output control function
1119‧‧‧影像處理單元1119‧‧‧Image Processing Unit
1150‧‧‧應用處理器或多核心處理器1150‧‧‧Application processor or multi-core processor
Lsheet_0‧‧‧邏輯片區識別符/片區Lsheet_0‧‧‧Logical slice identifier / slice
Lsheet_1‧‧‧邏輯片區識別符/片區/額外邏輯片區Lsheet_1‧‧‧Logical slice identifier / slice / extra logical slice
Lsheet_2‧‧‧邏輯片區識別符/片區/額外邏輯片區Lsheet_2‧‧‧Logical slice identifier / slice / extra logical slice
Lsheet_3‧‧‧邏輯片區識別符/片區/額外邏輯片區Lsheet_3‧‧‧Logical slice identifier / slice / extra logical slice
M‧‧‧記憶體單元/記憶體存取單元M‧‧‧Memory Unit / Memory Access Unit
R1‧‧‧暫存器R1‧‧‧Register
R2‧‧‧本端暫存器/暫存器R2‧‧‧Local register / register
R3‧‧‧暫存器R3‧‧‧Register
R4‧‧‧暫存器R4‧‧‧Register
R5‧‧‧暫存器R5‧‧‧Register
X‧‧‧結果 X‧‧‧ Results
以下說明及附圖用於圖解說明本發明之實施例。在圖式中： 圖1展示一影像處理器硬體架構之一實施例； 圖2a、圖2b、圖2c、圖2d及圖2e繪示將影像資料剖析成一線群、將一線群剖析成一片區及對具有重疊樣板之一片區執行之操作； 圖3a展示一樣板處理器之一實施例； 圖3b展示樣板處理器之一指令字之一實施例；圖4展示一樣板處理器內之一資料運算單元之一實施例； 圖5a、圖5b、圖5c、圖5d、圖5e、圖5f、圖5g、圖5h、圖5i、圖5j及圖5k繪示使用一個二維移位陣列及一執行通道陣列來判定具有重疊樣板之一對鄰近輸出像素值的一實例； 圖6展示一整合式執行通道陣列與二維移位陣列之一單位單元(unit cell)之一實施例； 圖7a至圖7c係關於針對一影像處理器資料運算單元之一編譯器管理記憶體存取方法； 圖8展示針對一影像處理器之一記憶體存取方法； 圖9a及圖9b係關於用於產生一記憶體位址之一指令； 圖10係關於另一編譯器管理記憶體存取方法； 圖11展示一運算系統之一實施例。The following description and accompanying drawings are used to illustrate embodiments of the present invention. In the drawings: FIG. 1 shows an embodiment of an image processor hardware architecture; FIG. 2a, FIG. 2b, FIG. 2c, FIG. 2d, and FIG. 2e illustrate parsing image data into a line group and a line group into a slice Figure 3a shows an embodiment of a template processor; Figure 3b shows an example of an instruction word of a template processor; Figure 4 shows one of the instructions in a template processor; An embodiment of a data operation unit; Figures 5a, 5b, 5c, 5d, 5e, 5f, 5g, 5h, 5i, 5j and 5k illustrate the use of a two-dimensional shift array and An example of an execution channel array to determine a pair of adjacent output pixel values with overlapping templates; FIG. 6 shows an embodiment of an integrated execution channel array and a unit cell of a two-dimensional shift array; FIG. 7a FIG. 7c is about a memory management method for a compiler of an image processor data operation unit; FIG. 8 shows a memory access method for an image processor; FIG. 9a and FIG. 9b are about generating memory access method An instruction at a memory address; FIG. 10 shows another method for managing memory access by a compiler; FIG. 11 shows an embodiment of a computing system.
Claims (20)
Applications Claiming Priority (4)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201662300671P | 2016-02-26 | 2016-02-26 | |
US62/300,671 | 2016-02-26 | ||
US15/427,374 US10204396B2 (en) | 2016-02-26 | 2017-02-08 | Compiler managed memory for image processor |
US15/427,374 | 2017-02-08 |
Publications (2)
Publication Number | Publication Date |
---|---|
TW201830329A true TW201830329A (en) | 2018-08-16 |
TWI698832B TWI698832B (en) | 2020-07-11 |
Family
ID=58228574
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
TW107117967A TWI698832B (en) | 2016-02-26 | 2017-02-24 | Compiler managed memory for image processor |
TW106106319A TWI628618B (en) | 2016-02-26 | 2017-02-24 | Compiler managed memory for image processor |
Family Applications After (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
TW106106319A TWI628618B (en) | 2016-02-26 | 2017-02-24 | Compiler managed memory for image processor |
Country Status (9)
Country | Link |
---|---|
US (3) | US10204396B2 (en) |
EP (1) | EP3420528B1 (en) |
JP (1) | JP6726752B2 (en) |
KR (1) | KR102050899B1 (en) |
CN (1) | CN107133908B (en) |
DE (2) | DE202017101012U1 (en) |
GB (3) | GB2576117B (en) |
TW (2) | TWI698832B (en) |
WO (1) | WO2017147020A1 (en) |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10853908B2 (en) | 2019-02-12 | 2020-12-01 | Google Llc | Image processor complex transfer functions |
Families Citing this family (13)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP6815926B2 (en) * | 2017-04-27 | 2021-01-20 | キヤノン株式会社 | Imaging device, imaging system, mobile body, chip |
US10503689B2 (en) * | 2017-05-15 | 2019-12-10 | Google Llc | Image processor I/O unit |
US10489878B2 (en) * | 2017-05-15 | 2019-11-26 | Google Llc | Configurable and programmable image processor unit |
US10460416B1 (en) | 2017-10-17 | 2019-10-29 | Xilinx, Inc. | Inline image preprocessing for convolution operations using a matrix multiplier on an integrated circuit |
US11386644B2 (en) * | 2017-10-17 | 2022-07-12 | Xilinx, Inc. | Image preprocessing for generalized image processing |
CN107633477B (en) * | 2017-10-20 | 2021-04-20 | 上海兆芯集成电路有限公司 | Image processing method and device |
CN108230229B (en) * | 2018-01-04 | 2021-07-06 | 格兰菲智能科技有限公司 | Image processing apparatus and image processing method |
CN112005213A (en) * | 2018-02-27 | 2020-11-27 | 谷歌有限责任公司 | Large lookup tables for image processors |
US10983583B2 (en) * | 2018-08-23 | 2021-04-20 | Apple Inc. | Electronic display reduced blanking duration systems and methods |
US11848980B2 (en) * | 2020-07-09 | 2023-12-19 | Boray Data Technology Co. Ltd. | Distributed pipeline configuration in a distributed computing system |
CN112184536B (en) * | 2020-09-24 | 2022-09-30 | 成都海光集成电路设计有限公司 | Method, apparatus, device and medium for processing image data based on GEMM |
TWI771921B (en) * | 2021-02-22 | 2022-07-21 | 瑞鼎科技股份有限公司 | Display driving system |
WO2023172660A1 (en) * | 2022-03-10 | 2023-09-14 | Ascenium, Inc. | Highly parallel processing architecture with out-of-order resolution |
Family Cites Families (83)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4445177A (en) | 1981-05-22 | 1984-04-24 | Data General Corporation | Digital data processing system utilizing a unique arithmetic logic unit for handling uniquely identifiable addresses for operands and instructions |
DE3851005T2 (en) | 1987-06-01 | 1995-04-20 | Applied Intelligent Syst Inc | Parallel neighboring processing system and method. |
US4935894A (en) | 1987-08-31 | 1990-06-19 | Motorola, Inc. | Multi-processor, multi-bus system with bus interface comprising FIFO register stocks for receiving and transmitting data and control information |
US5253308A (en) | 1989-06-21 | 1993-10-12 | Amber Engineering, Inc. | Massively parallel digital image data processor using pixel-mapped input/output and relative indexed addressing |
US6948050B1 (en) | 1989-11-17 | 2005-09-20 | Texas Instruments Incorporated | Single integrated circuit embodying a dual heterogenous processors with separate instruction handling hardware |
WO1994009595A1 (en) | 1991-09-20 | 1994-04-28 | Shaw Venson M | Method and apparatus including system architecture for multimedia communications |
JP3482660B2 (en) | 1993-09-08 | 2003-12-22 | ソニー株式会社 | Image data processing apparatus and image data processing method |
US5612693A (en) | 1994-12-14 | 1997-03-18 | International Business Machines Corporation | Sliding window data compression using a toroidal bit shift register |
JP3573755B2 (en) | 1996-01-15 | 2004-10-06 | シーメンス アクチエンゲゼルシヤフト | Image processing processor |
US5892962A (en) | 1996-11-12 | 1999-04-06 | Lucent Technologies Inc. | FPGA-based processor |
US6366289B1 (en) | 1998-07-17 | 2002-04-02 | Microsoft Corporation | Method and system for managing a display image in compressed and uncompressed blocks |
US6587158B1 (en) | 1998-07-23 | 2003-07-01 | Dvdo, Inc. | Method and apparatus for reducing on-chip memory in vertical video processing |
US7010177B1 (en) | 1998-08-27 | 2006-03-07 | Intel Corporation | Portability of digital images |
EP1164544B1 (en) | 1999-03-16 | 2011-11-02 | Hamamatsu Photonics K.K. | High-speed vision sensor |
JP3922859B2 (en) | 1999-12-28 | 2007-05-30 | 株式会社リコー | Image processing apparatus, image processing method, and computer-readable recording medium storing program for causing computer to execute the method |
US6745319B1 (en) | 2000-02-18 | 2004-06-01 | Texas Instruments Incorporated | Microprocessor with instructions for shuffling and dealing data |
US6728862B1 (en) | 2000-05-22 | 2004-04-27 | Gazelle Technology Corporation | Processor array and parallel data processing methods |
US6728722B1 (en) | 2000-08-28 | 2004-04-27 | Sun Microsystems, Inc. | General data structure for describing logical data spaces |
US7286717B2 (en) | 2001-10-31 | 2007-10-23 | Ricoh Company, Ltd. | Image data processing device processing a plurality of series of data items simultaneously in parallel |
JP4146654B2 (en) | 2002-02-28 | 2008-09-10 | 株式会社リコー | Image processing circuit, composite image processing circuit, and image forming apparatus |
US9170812B2 (en) | 2002-03-21 | 2015-10-27 | Pact Xpp Technologies Ag | Data processing system having integrated pipelined array data processor |
WO2003088033A1 (en) | 2002-04-09 | 2003-10-23 | University Of Rochester | Multiplier-based processor-in-memory architectures for image and graphics processing |
US7084929B2 (en) * | 2002-07-29 | 2006-08-01 | Koninklijke Philips Electronics N.V. | Video data filtering arrangement and method |
AU2003286131A1 (en) | 2002-08-07 | 2004-03-19 | Pact Xpp Technologies Ag | Method and device for processing data |
US20060044576A1 (en) | 2004-07-30 | 2006-03-02 | Kabushiki Kaisha Toshiba | Apparatus for image processing |
US7667764B2 (en) | 2004-06-04 | 2010-02-23 | Konica Minolta Holdings, Inc. | Image sensing apparatus |
US8424012B1 (en) | 2004-11-15 | 2013-04-16 | Nvidia Corporation | Context switching on a video processor having a scalar execution unit and a vector execution unit |
JP4219887B2 (en) | 2004-12-28 | 2009-02-04 | 富士通マイクロエレクトロニクス株式会社 | Image processing apparatus and image processing method |
ATE504043T1 (en) | 2005-04-28 | 2011-04-15 | Univ Edinburgh | RECONFIGURABLE INSTRUCTION CELL ARRAY |
US7882339B2 (en) | 2005-06-23 | 2011-02-01 | Intel Corporation | Primitives to enhance thread-level speculation |
JP2007067917A (en) | 2005-08-31 | 2007-03-15 | Matsushita Electric Ind Co Ltd | Image data processing apparatus |
US7602974B2 (en) | 2005-10-21 | 2009-10-13 | Mobilic Technology (Cayman) Corp. | Universal fixed-pixel-size ISP scheme |
FR2895103B1 (en) | 2005-12-19 | 2008-02-22 | Dxo Labs Sa | METHOD AND SYSTEM FOR PROCESSING DIGITAL DATA |
US7802073B1 (en) | 2006-03-29 | 2010-09-21 | Oracle America, Inc. | Virtual core management |
US7834873B2 (en) * | 2006-08-25 | 2010-11-16 | Intel Corporation | Display processing line buffers incorporating pipeline overlap |
CN100409259C (en) * | 2006-08-29 | 2008-08-06 | 中国航天时代电子公司第七七一研究所 | Scaleable large-scale 2D convolution circuit |
US20080111823A1 (en) | 2006-11-13 | 2008-05-15 | Faraday Technology Corp. | Graphics processing system |
EP1927949A1 (en) * | 2006-12-01 | 2008-06-04 | Thomson Licensing | Array of processing elements with local registers |
US8321849B2 (en) | 2007-01-26 | 2012-11-27 | Nvidia Corporation | Virtual architecture and instruction set for parallel thread computing |
US20080244222A1 (en) | 2007-03-30 | 2008-10-02 | Intel Corporation | Many-core processing using virtual processors |
JP4389976B2 (en) | 2007-06-29 | 2009-12-24 | ブラザー工業株式会社 | Image processing apparatus and image processing program |
JP4844853B2 (en) | 2007-09-05 | 2011-12-28 | 国立大学法人東北大学 | Solid-state imaging device and driving method thereof |
CN102047241B (en) | 2008-05-30 | 2014-03-12 | 先进微装置公司 | Local and global data share |
JP4999791B2 (en) | 2008-06-30 | 2012-08-15 | キヤノン株式会社 | Information processing apparatus, control method thereof, and program |
US8456480B2 (en) | 2009-01-14 | 2013-06-04 | Calos Fund Limited Liability Company | Method for chaining image-processing functions on a SIMD processor |
KR101572879B1 (en) | 2009-04-29 | 2015-12-01 | 삼성전자주식회사 | Dynamic parallel system and method for parallel application program |
US20110055495A1 (en) | 2009-08-28 | 2011-03-03 | Qualcomm Incorporated | Memory Controller Page Management Devices, Systems, and Methods |
CN101697486A (en) * | 2009-09-27 | 2010-04-21 | 华中科技大学 | Two-dimensional wavelet transformation integrated circuit structure |
US8976195B1 (en) | 2009-10-14 | 2015-03-10 | Nvidia Corporation | Generating clip state for a batch of vertices |
US8436857B2 (en) | 2009-10-20 | 2013-05-07 | Oracle America, Inc. | System and method for applying level of detail schemes |
US8595428B2 (en) | 2009-12-22 | 2013-11-26 | Intel Corporation | Memory controller functionalities to support data swizzling |
TWI424372B (en) * | 2010-03-24 | 2014-01-21 | Altek Corp | Selectable image line path means |
US8749667B2 (en) | 2010-08-02 | 2014-06-10 | Texas Instruments Incorporated | System and method for maintaining maximum input rate while up-scaling an image vertically |
US8508612B2 (en) | 2010-09-30 | 2013-08-13 | Apple Inc. | Image signal processor line buffer configuration for processing ram image data |
US8797323B2 (en) | 2011-01-18 | 2014-08-05 | Intel Corporation | Shadowing dynamic volumetric media |
WO2012105174A1 (en) | 2011-01-31 | 2012-08-09 | パナソニック株式会社 | Program generation device, program generation method, processor device, and multiprocessor system |
US9092267B2 (en) | 2011-06-20 | 2015-07-28 | Qualcomm Incorporated | Memory sharing in graphics processing unit |
US20130027416A1 (en) | 2011-07-25 | 2013-01-31 | Karthikeyan Vaithianathan | Gather method and apparatus for media processing accelerators |
US9183614B2 (en) | 2011-09-03 | 2015-11-10 | Mireplica Technology, Llc | Processor, system, and method for efficient, high-throughput processing of two-dimensional, interrelated data sets |
JP5742651B2 (en) | 2011-10-15 | 2015-07-01 | コニカミノルタ株式会社 | Image processing apparatus, linkage method, and linkage program |
US20140089634A1 (en) | 2011-12-23 | 2014-03-27 | Victor W. Lee | Apparatus and method for detecting identical elements within a vector register |
JP5746100B2 (en) | 2011-12-27 | 2015-07-08 | 京セラドキュメントソリューションズ株式会社 | Image forming apparatus |
US8823736B2 (en) | 2012-01-20 | 2014-09-02 | Intel Corporation | Graphics tiling architecture with bounding volume hierarchies |
US10244246B2 (en) | 2012-02-02 | 2019-03-26 | Texas Instruments Incorporated | Sub-pictures for pixel rate balancing on multi-core platforms |
US9235769B2 (en) | 2012-03-15 | 2016-01-12 | Herta Security, S.L. | Parallel object detection method for heterogeneous multithreaded microarchitectures |
CN102665049B (en) * | 2012-03-29 | 2014-09-17 | 中国科学院半导体研究所 | Programmable visual chip-based visual image processing system |
TWI520598B (en) | 2012-05-23 | 2016-02-01 | 晨星半導體股份有限公司 | Image processing apparatus and image processing method |
US9232139B2 (en) | 2012-07-24 | 2016-01-05 | Apple Inc. | Image stabilization using striped output transformation unit |
US9378181B2 (en) | 2012-11-09 | 2016-06-28 | Intel Corporation | Scalable computing array |
CN103019656B (en) * | 2012-12-04 | 2016-04-27 | 中国科学院半导体研究所 | The multistage parallel single instruction multiple data array processing system of dynamic reconstruct |
CN103020890B (en) * | 2012-12-17 | 2015-11-04 | 中国科学院半导体研究所 | Based on the visual processing apparatus of multi-level parallel processing |
US8954992B2 (en) | 2013-03-15 | 2015-02-10 | Lenovo Enterprise Solutions (Singapore) Pte. Ltd. | Distributed and scaled-out network switch and packet processing |
US9165337B2 (en) | 2013-05-31 | 2015-10-20 | Qualcomm Incorporated | Command instruction management |
US9477999B2 (en) * | 2013-09-20 | 2016-10-25 | The Board Of Trustees Of The Leland Stanford Junior University | Low power programmable image processor |
US9749548B2 (en) | 2015-01-22 | 2017-08-29 | Google Inc. | Virtual linebuffers for image signal processors |
US9769356B2 (en) | 2015-04-23 | 2017-09-19 | Google Inc. | Two dimensional shift array for image processor |
US10095479B2 (en) | 2015-04-23 | 2018-10-09 | Google Llc | Virtual image processor instruction set architecture (ISA) and memory model and exemplary target hardware having a two-dimensional shift array structure |
US9772852B2 (en) * | 2015-04-23 | 2017-09-26 | Google Inc. | Energy efficient processor core architecture for image processor |
US9965824B2 (en) | 2015-04-23 | 2018-05-08 | Google Llc | Architecture for high performance, power efficient, programmable image processing |
US10291813B2 (en) | 2015-04-23 | 2019-05-14 | Google Llc | Sheet generator for image processor |
US9785423B2 (en) | 2015-04-23 | 2017-10-10 | Google Inc. | Compiler for translating between a virtual image processor instruction set architecture (ISA) and target hardware having a two-dimensional shift array structure |
US9756268B2 (en) | 2015-04-23 | 2017-09-05 | Google Inc. | Line buffer unit for image processor |
US10387988B2 (en) * | 2016-02-26 | 2019-08-20 | Google Llc | Compiler techniques for mapping program code to a high performance, power efficient, programmable image processing hardware platform |
-
2017
- 2017-02-08 US US15/427,374 patent/US10204396B2/en active Active
- 2017-02-17 EP EP17708937.2A patent/EP3420528B1/en active Active
- 2017-02-17 KR KR1020187022164A patent/KR102050899B1/en active IP Right Grant
- 2017-02-17 JP JP2018539834A patent/JP6726752B2/en active Active
- 2017-02-17 WO PCT/US2017/018444 patent/WO2017147020A1/en active Application Filing
- 2017-02-23 GB GB1912713.3A patent/GB2576117B/en active Active
- 2017-02-23 DE DE202017101012.0U patent/DE202017101012U1/en active Active
- 2017-02-23 GB GB1820155.8A patent/GB2567757B/en active Active
- 2017-02-23 DE DE102017103764.0A patent/DE102017103764A1/en active Pending
- 2017-02-23 GB GB1702925.7A patent/GB2549578B/en active Active
- 2017-02-24 TW TW107117967A patent/TWI698832B/en active
- 2017-02-24 TW TW106106319A patent/TWI628618B/en active
- 2017-02-27 CN CN201710107518.9A patent/CN107133908B/en active Active
- 2017-06-16 US US15/625,972 patent/US10304156B2/en active Active
-
2019
- 2019-02-11 US US16/272,819 patent/US10685422B2/en active Active
Cited By (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10853908B2 (en) | 2019-02-12 | 2020-12-01 | Google Llc | Image processor complex transfer functions |
TWI722684B (en) * | 2019-02-12 | 2021-03-21 | 美商谷歌有限責任公司 | Computer-implemented methods and non-transitory computer storage media related to image processor complex transfer functions and computing devices employing an image processor |
Also Published As
Publication number | Publication date |
---|---|
US10304156B2 (en) | 2019-05-28 |
TWI698832B (en) | 2020-07-11 |
US10685422B2 (en) | 2020-06-16 |
US20190188824A1 (en) | 2019-06-20 |
CN107133908A (en) | 2017-09-05 |
TW201737201A (en) | 2017-10-16 |
JP6726752B2 (en) | 2020-07-22 |
GB2549578A (en) | 2017-10-25 |
GB2549578B (en) | 2019-01-30 |
KR20180100374A (en) | 2018-09-10 |
US10204396B2 (en) | 2019-02-12 |
GB201912713D0 (en) | 2019-10-16 |
JP2019507922A (en) | 2019-03-22 |
GB2576117A (en) | 2020-02-05 |
US20170249717A1 (en) | 2017-08-31 |
GB201702925D0 (en) | 2017-04-12 |
US20170287105A1 (en) | 2017-10-05 |
DE102017103764A1 (en) | 2017-08-31 |
EP3420528A1 (en) | 2019-01-02 |
GB2567757B (en) | 2019-10-23 |
KR102050899B1 (en) | 2019-12-02 |
GB201820155D0 (en) | 2019-01-23 |
TWI628618B (en) | 2018-07-01 |
CN107133908B (en) | 2021-01-12 |
DE202017101012U1 (en) | 2017-05-29 |
GB2576117B (en) | 2020-08-12 |
GB2567757A (en) | 2019-04-24 |
EP3420528B1 (en) | 2022-06-15 |
WO2017147020A1 (en) | 2017-08-31 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
TWI628618B (en) | Compiler managed memory for image processor | |
JP7202987B2 (en) | Architecture for High Performance, Power Efficient, Programmable Image Processing | |
TWI690858B (en) | Method, machine readable storage medium, and apparatus for convolutional neural network on programmable two dimensional image processor | |
TWI614689B (en) | Compiler techniques for mapping program code to a high performance, power efficient, programmable image processing hardware platform | |
JP6793228B2 (en) | Sheet generator for image processor | |
CN107408041B (en) | Energy efficient processor core architecture for image processors | |
CN107430760B (en) | Two-dimensional shift array for image processor | |
CN107533750B (en) | Virtual image processor, and method and system for processing image data thereon | |
TWI736880B (en) | Processor, computer program product and method performed by a processor | |
US10685423B2 (en) | Determination of per line buffer unit memory allocation | |
CN110300944B (en) | Image processor with configurable number of active cores and supporting internal network | |
TWI752343B (en) | Execution unit circuits, image processors, and methods for performing a sum of absolute difference computation | |
JP6820428B2 (en) | Configuring application software on a multi-core image processor |