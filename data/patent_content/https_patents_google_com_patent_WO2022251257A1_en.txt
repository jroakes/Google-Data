WO2022251257A1 - Overlaying an image of a conference call participant with a shared document - Google Patents
Overlaying an image of a conference call participant with a shared document Download PDFInfo
- Publication number
- WO2022251257A1 WO2022251257A1 PCT/US2022/030779 US2022030779W WO2022251257A1 WO 2022251257 A1 WO2022251257 A1 WO 2022251257A1 US 2022030779 W US2022030779 W US 2022030779W WO 2022251257 A1 WO2022251257 A1 WO 2022251257A1
- Authority
- WO
- WIPO (PCT)
- Prior art keywords
- document
- participant
- image
- conference call
- conference
- Prior art date
Links
- 238000000034 method Methods 0.000 claims abstract description 28
- 238000012545 processing Methods 0.000 claims description 28
- 238000012986 modification Methods 0.000 claims 2
- 230000004048 modification Effects 0.000 claims 2
- 238000007726 management method Methods 0.000 description 76
- 238000012549 training Methods 0.000 description 57
- 238000000605 extraction Methods 0.000 description 52
- 230000004044 response Effects 0.000 description 47
- 238000009877 rendering Methods 0.000 description 16
- 238000010801 machine learning Methods 0.000 description 13
- 238000001514 detection method Methods 0.000 description 12
- 230000015654 memory Effects 0.000 description 12
- 238000010586 diagram Methods 0.000 description 10
- 230000006870 function Effects 0.000 description 6
- 238000013528 artificial neural network Methods 0.000 description 4
- 230000000694 effects Effects 0.000 description 4
- 238000013461 design Methods 0.000 description 3
- 230000008569 process Effects 0.000 description 3
- 230000001413 cellular effect Effects 0.000 description 2
- 238000004891 communication Methods 0.000 description 2
- 238000013480 data collection Methods 0.000 description 2
- 238000013500 data storage Methods 0.000 description 2
- 230000003247 decreasing effect Effects 0.000 description 2
- 230000005291 magnetic effect Effects 0.000 description 2
- 230000007246 mechanism Effects 0.000 description 2
- 230000003287 optical effect Effects 0.000 description 2
- 230000002085 persistent effect Effects 0.000 description 2
- 230000005236 sound signal Effects 0.000 description 2
- 230000003068 static effect Effects 0.000 description 2
- 238000004458 analytical method Methods 0.000 description 1
- 230000007812 deficiency Effects 0.000 description 1
- 238000005516 engineering process Methods 0.000 description 1
- 230000037406 food intake Effects 0.000 description 1
- 230000007274 generation of a signal involved in cell-cell signaling Effects 0.000 description 1
- 239000004973 liquid crystal related substance Substances 0.000 description 1
- 230000007774 longterm Effects 0.000 description 1
- 238000012706 support-vector machine Methods 0.000 description 1
- 230000001360 synchronised effect Effects 0.000 description 1
- 238000012360 testing method Methods 0.000 description 1
- 230000007704 transition Effects 0.000 description 1
- 230000000007 visual effect Effects 0.000 description 1
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N7/00—Television systems
- H04N7/14—Systems for two-way working
- H04N7/15—Conference systems
- H04N7/152—Multipoint control units therefor
Definitions
- Video or audio-based conference call discussions can take place between multiple participants via a conference platform.
- a conference platform includes tools that allow multiple client devices to be connected over a network and share each other’s audio data (e.g., voice of a user recorded via a microphone of a client device) and/or video data (e.g., a video captured by a camera of a client device, or video captured from a screen image of the client device) for efficient communication.
- a conference platform can also include tools to allow a participant of a conference call to share a document displayed via user interface (UI) on a client device associated with the participant with other participants of the conference call.
- UI user interface
- a system and method are disclosed for overlaying an image of a conference call participant with a shared document.
- a request is received to initiate a document sharing operation to share a document displayed via a first graphical user interface (GUI) on a first client device associated with a first participant of a conference call with a second participant of the conference call via a second GUI on a second client device.
- GUI graphical user interface
- Image data corresponding to a view of the first participant in a surrounding environment is also received.
- An image depicting the first participant is obtained based on the received image data.
- One or more regions of the document that satisfy one or more image placement criteria are identified.
- the document and the image depicting the first participant are provided for presentation via the second GUI on the second client device.
- the image depicting the first participant is presented at a region of the identified one of more regions of the document.
- GUI graphical user interface
- a request is received to display an image depicting the first participant of the conference call with the document shared with the second participant via the second GUI.
- Image data corresponding to a view of the first participant in a surrounding environment is received.
- An image depicting the first participant is obtained based on the received image data.
- At least one of a formatting or an orientation of one or more content items of the shared document is modified in view of the image depicting the first participant.
- the image depicting the first participant with the modified document is provided for presentation via the second GUI on the second client device.
- FIG. 1 illustrates an example system architecture, in accordance with implementations of the present disclosure.
- FIG. 2 is a block diagram illustrating an example conference platform and an example background extraction engine, in accordance with implementations of the present disclosure.
- FIG. 3 is a block diagram illustrating an example conference platform and an example image overlay engine, in accordance with implementations of the present disclosure.
- FIG. 4 depicts a flow diagram of an example method for overlaying an image of a conference call participant with a shared document, in accordance with implementations of the present disclosure.
- FIGs. 5A-5C illustrate an example of overlaying an image of a conference call participant with a shared document for presentation via a GUI, in accordance with implementations of the present disclosure.
- FIGs. 6A-6C illustrate another example of overlaying an image of a conference call participant with a shared document for presentation via a GUI, in accordance with implementations of the present disclosure.
- FIG. 7 depicts a flow diagram of another example method for overlaying an image of a conference call participant with a shared document, in accordance with implementations of the present disclosure.
- FIGs. 8A-8B illustrate another example of overlaying an image of a conference call participant with a shared document for presentation via a GUI, in accordance with implementations of the present disclosure.
- FIGs. 9A-9B illustrate an example of overlaying an image of multiple conference call participants with a shared document for presentation via a GUI, in accordance with implementations of the present disclosure.
- FIG. 10 is a block diagram illustrating an exemplary computer system, in accordance with implementations of the present disclosure.
- a conference platform can enable video or audio-based conference call discussions between multiple participants via respective client devices that are connected over a network and share each other’s audio data (e.g., voice of a user recorded via a microphone of a client device) and/or video data (e.g., a video captured by a camera of a client device) during a conference call.
- audio data e.g., voice of a user recorded via a microphone of a client device
- video data e.g., a video captured by a camera of a client device
- a conference platform can enable a significant number of client devices (e.g., up to one hundred or more client devices) to be connected via the conference call.
- a participant of a live conference call e.g., a video conference call
- a shared document e.g., a slide presentation document, a word processing document, a webpage document, etc.
- a presenter of a conference call can prepare a document including content that the presenter plans to discuss during the conference call.
- Existing conference platforms enable the presenter to share the document displayed via a GUI of a client device associated with the presenter with the other participants of the call via a conference platform GUI on respective client devices while the presenter discusses content included in the shared document.
- conference platforms do not effectively display the content of the shared document while simultaneously displaying an image depicting the presenter via the conference platform GUI on the client devices associated with the other participants.
- some existing conference platforms may not provide the image depicting the conference call presenter with the document shared via the conference platform GUI, which prevents the presenter from effectively engaging with the participants via a video feature of the conference platform.
- the attention of the conference call participants is not captured for long (or at all) and the presentation of the shared document during the conference call can come across as being impersonal or mechanical.
- Other existing conference platforms may display the content of the shared document via a first portion of the conference platform GUI and an image depicting the presenter via a second portion of the conference platform GUI.
- participant may not be able to simultaneously focus on or concurrently observe the visual cues or gestures provided by the presenter while consuming the content provided by the shared document.
- Hardware constraints associated with different client devices connected to the conference call platform may prevent a conference platform GUI from displaying both the content of the shared document and the image of the presenter concurrently or effectively.
- Existing conference platforms do not provide mechanisms that can modify a display of a conference platform GUI on a client device associated with a participant of a conference call in view of one or more hardware constraints associated with the client device.
- a client device associated with a presenter of a conference call can include a large display screen.
- Client devices associated with some participants of the conference call can include a large display screen, while client devices associated with other participants of the call can include a small display screen.
- Existing conference platforms can provide the same document for presentation via the conference platform GUI at each client device regardless of the size of the display screen at the respective client device. Accordingly, participants accessing the conference call via client devices that include small display screens may not easily be able to consume all of the content of the document shared by the presenter. As a result, the presenter may not be able to effectively engage with these participants during the conference call.
- a client device associated with a presenter of a conference call can transmit a request to a conference platform to initiate a document sharing operation to share a document displayed via a GUI for the client device with participants of the conference call via GUIs on client devices associated with participants of the conference call.
- the conference platform can receive image data (e.g., pixel data, etc.) from the client device associated with the conference call presenter.
- the image data can correspond to a view of the first participant in a surrounding environment (e.g., a background environment).
- the conference platform can obtain an image depicting the presenter based on the received image data.
- the received image data can include a first set of pixels associated with the presenter and a second set of pixels associated with the surrounding environment.
- the conference platform can extract the identified first set of pixels from the received image data and generate the image depicting the first participant based on the extracted first set of pixels.
- the conference platform can identify one or more regions of the document that satisfy one or more image placement criteria.
- a region of the document can satisfy the image placement criterion if the region of the document does not include any content or does not include content that is relevant to the presentation (e.g., the region includes a company logo, etc.).
- the conference platform can modify a formatting or an orientation of one or more content items of the shared document in order to accommodate the image depicting the presenter.
- the conference platform can reduce the size of the title or can move a portion of the title to another region of the slide in order to accommodate the image depicting the presenter.
- the conference platform can provide the document and the image depicting the presenter for presentation via the conference GUI on the client devices associated with the conference participants.
- the image depicting the presenter can be displayed at a region that was previously identified (or modified) to satisfy one or more image placement criteria.
- a technical solution to the above identified technical problems of the conventional technology may include overlaying an image of a conference call presenter with a document shared via a conference platform GUI on client devices associated with participants of the conference call.
- the conference platform may identify one or more regions of a document that satisfy one or more placement criteria (e.g., the one or more regions do not include content, etc.) for presentation of an image depicting the presenter of the conference call.
- the conference platform may modify one or more content items of the document to accommodate the image depicting the conference call presenter.
- the image depicting the conference call presenter is presented in a region of the shared document that does not interfere (or minimally interferes) with existing content of the document.
- Another technical solution to the above identified technical problems is to modify the presentation of the document and the image depicting the presenter via the conference platform GUI on a particular client device in view of one of more hardware constraints associated with a client device.
- the conference platform can obtain data indicating one or more hardware constraints (e.g., an image resolution constraint, a screen size, etc.) associated with a client device associated with a conference call participant. If the one or more hardware constraints satisfy a hardware constraint criterion (e.g., fall below a threshold image resolution, a threshold screen size, etc.), the conference platform can modify the presentation of the document and the image depicting the presenter in view of the one or more hardware constraints.
- a hardware constraint criterion e.g., fall below a threshold image resolution, a threshold screen size, etc.
- the conference platform can present a first portion of content included in the document with the image depicting the presenter via the conference platform GUI.
- the conference platform can update the conference platform GUI at the client device to display the second portion of content included in the document with the image depicting the platform.
- the technical effect may include improving the presentation of an image of a conference call presenter and a document shared with participants of the conference call.
- By providing mechanisms to present an image of the conference call presenter in a region that does not interfere (or minimally interferes) with existing content of a shared document all important information is presented to the participants of the conference call in an unobstructed and convenient manner, while imitating an in-person meeting experience which enables the presenter to effectively engage with the participants of the conference call.
- FIG. 1 illustrates an example system architecture 100, in accordance with implementations of the present disclosure.
- the system architecture 100 (also referred to as “system” herein) includes client devices 102A-N, a data store 110 and a conference platform 120, each connected to a network 108.
- system 100 can additionally include a predictive system 112.
- Predictive system 112 can include one or more server machines 130-150 each connected to network 108.
- network 108 can include a public network (e.g., the Internet), a private network (e.g., a local area network (LAN) or wide area network (WAN)), a wired network (e.g., Ethernet network), a wireless network (e.g., an 802.11 network or a Wi-Fi network), a cellular network (e.g., a Long Term Evolution (LTE) network), routers, hubs, switches, server computers, and/or a combination thereof.
- a public network e.g., the Internet
- a private network e.g., a local area network (LAN) or wide area network (WAN)
- a wired network e.g., Ethernet network
- a wireless network e.g., an 802.11 network or a Wi-Fi network
- a cellular network e.g., a Long Term Evolution (LTE) network
- data store 110 is a persistent storage that is capable of storing data as well as data structures to tag, organize, and index the data.
- a data item can include audio data and/or image data, in accordance with embodiments described herein.
- a data item can correspond to a document displayed via a graphical user interface (GUI) on a client device 102, in accordance with embodiments described herein.
- GUI graphical user interface
- Data store 110 can be hosted by one or more storage devices, such as main memory, magnetic or optical storage based disks, tapes or hard drives, NAS, SAN, and so forth.
- data store 110 can be a network-attached file server, while in other embodiments data store 110 can be some other type of persistent storage such as an object- oriented database, a relational database, and so forth, that may be hosted by conference platform 120 or one or more different machines coupled to the conference platform 120 via network 108.
- data store 110 can be some other type of persistent storage such as an object- oriented database, a relational database, and so forth, that may be hosted by conference platform 120 or one or more different machines coupled to the conference platform 120 via network 108.
- Conference platform 120 can enable users of client devices 102A-N to connect with each other via a conference call, such as a video conference call or an audio conference call.
- a conference call refers to an audio-based call and/or a video-based call in which participants of the call can connect with multiple additional participants.
- Conference platform 120 can allow a user to join and participate in a video conference call and/or an audio conference call with other users of the platform.
- embodiments of the present disclosure refer to multiple participants (e.g., 3 or more) connecting via a conference call, it should be noted that embodiments of the present disclosure can be implemented with any number of participants connecting via the conference call (e.g., 2 or more).
- the client devices 102A-N can each include computing devices such as personal computers (PCs), laptops, mobile phones, smart phones, tablet computers, netbook computers, network-connected televisions, etc. In some implementations, client devices 102A-N may also be referred to as “user devices.” Each client device 102A-N can include a web browser and/or a client application (e.g., a mobile application or a desktop application). In some implementations, the web browser and/or the client application can display a user interface (UI), provided by conference platform 120, for users to access conference platform 120. For example, a user can join and participate in a video conference call or an audio conference call via a UI provided by conference platform 120 and presented by the web browser or client application.
- UI user interface
- Each client device 102A-N can include one or more audiovisual components that can generate audio and/or image data to be streamed to conference platform 120.
- an audiovisual component can include a device (e.g., a camera) that is configured to capture images and generate image data associated with the captured images.
- a camera for a client device 102 can capture images of a participant of a conference call in a surrounding environment (e.g., a background) during the conference call.
- an audiovisual component can include a device (e.g., a microphone) to capture an audio signal representing speech of a user and generate audio data (e.g., an audio file) based on the captured audio signal.
- the audiovisual component can include another device (e.g., a speaker) to output audio data to a user associated with a particular client device 102A-N.
- conference platform 120 can include a conference management component 122.
- Conference management component 122 is configured to manage a conference call between multiple users of conference platform 120.
- conference management component 122 can provide a GUI to each client device (referred to as conference platform GUI herein) to enable users to watch and listen to each other during a conference call.
- conference management component 122 can also enable users to share documents (e.g., a slide presentation document, a word processing document, a webpage document, etc.) displayed via a GUI on an associated client device with other users.
- conference management component 122 can receive a request to share a document displayed via a GUI on a first client device associated with a first participant of the conference call with other participants of the conference call.
- Conference management platform 122 can modify the conference platform GUI at the client devices 102 associated with the other conference call participants to display at least a portion of the shared document, in some embodiments.
- conference management component 122 can overlay an image depicting a participant of a conference call with a document shared by the participant and present the shared document with the overlayed image to other participants via a conference platform GUI on client devices associated with the other participants.
- a participant of a conference call can prepare a document (e.g., a slide presentation document) to present to other participants of the conference call.
- a presenter e.g., a presenter
- Conference management component 122 can receive a request from a client device 102 associated with the presenter to share the document with the other conference call participants via the conference platform GUI on respective client devices 102 associated with the other conference call participants.
- conference management component 122 can also receive an additional request to overlay an image depicting the presenter with the shared document.
- conference management component 122 can obtain an image depicting the presenter.
- an audiovisual component of each client device 102A-N can capture images and generate image data associated with the captured images.
- a camera for the client device 102 associated with the presenter can capture images of the presenter in a surrounding environment and generate image data associated with the captured images.
- conference management component 122 can receive the image data generated by the client device 102 associated with the presenter and can obtain the image depicting the presenter from the received image data.
- conference management component 122 can provide the image data received from the client device 102 associated with the presenter to a background extraction engine 124.
- background extraction engine 124 can be configured to parse through image data and identify a portion of the image data that corresponds to a participant of a conference call and a portion of the image data that corresponds to an environment surrounding the participant.
- the image data received from the client device 102 associated with the presenter can include a first set of pixels associated with the presenter and a second set of pixels associated with the surrounding environment.
- Background extraction engine 124 can parse through the received image data to identify the first set of pixels associated with the presenter and can extract the first set of pixels from the image data.
- background extraction engine 124 can be configured to identify a portion of the image data that corresponds to the conference call participant based on one or more outputs of a machine learning model, in accordance with embodiments described below. Conference management component 122 and/or background extraction engine 124 can generate the image depicting the presenter based on the extracted first set of pixels. Further details regarding background extraction engine 124 are provided below and with respect to
- Conference platform 120 can also include an image overlay engine 126 that is configured to overlay the image depicting the presenter with the document shared with the participants of the conference call.
- image overlay engine 126 can identify one or more regions of the document that satisfy one or more image placement criteria and can cause the image depicting the presenter to be presented at one of the identified regions. For example, a region of the document can satisfy an image placement criteria if the region does not include any content (e.g., is a blank space).
- Image overlay engine 126 can identify one or more regions that do not include any content and can select one of the identified one or more regions to include the image depicting the presenter. In another example, image overlay engine 126 may not identify any regions of the document that satisfy an image placement criteria.
- image overlay engine 126 can modify a size, a shape, and/or a transparency of the image depicting the presenter and can cause the modified image depicting the presenter to be overlayed with the document, in accordance with embodiment described herein. Further details regarding image overlay engine 126 are provided with respect to FIG. 3.
- conference management component 122 can provide the document and the image depicting the presenter for presentation via a conference platform GUI on client devices associated with the other participants of the call.
- the image depicting the presenter can be included at the region of the document identified by the image overlay engine 126.
- conference management component 122 can receive a request from the client device 102 associated with the presenter to move the image depicting the presenter from the identified region to another region of the document.
- conference management component 122 can move the image depicting the presenter to another region of the document, in accordance with the request.
- the requested region of the document can include one or more content items.
- Conference management platform 122 can modify the image depicting the presenter and/or a formatting or orientation of the one or more content items in view of the image, in some embodiments. Further details regarding conference management component 122 modifying the image depicting the presenter and/or the content items of the document are provided herein.
- system architecture can include a predictive system 112 that includes one or more server machines 130-150.
- background extraction engine 124 described above, can be part of predictive system 112.
- predictive system 112 can be configured to train an image extraction model that can be used by background extraction engine 124 to identify a portion of an image that corresponds to a conference call participant and a portion of the image that corresponds to an environment surrounding the conference call participant.
- predictive system 112 can include a gesture detection engine 151.
- predictive system 112 can be configured to train a gesture detection model that can be used by gesture detection engine 151 to detect a gesture made by a conference call participant during a conference call and generate a GUI element that corresponds to the detected gesture for presentation at the conference platform GUI at the client devices 102 associated with other participants of the conference call. Further details regarding the image extraction model and the gesture detection model are provided herein.
- Predictive system 112 can include at least a training set generator 131, a training engine 141 and one or more machine learning models 160A-N. In some embodiments, predictive system 112 can also include background extraction engine 124 and/or gesture detection engine 151, as described above.
- Server machine 130 can include a training set generator 131 that is capable of generating training data (e.g., a set of training inputs and a set of target outputs) to train ML models 160A-N. For the image extraction model, training data can be generated based on images that have been previously captured by audiovisual components of client devices associated with participants of prior conference calls hosted by conference platform 120.
- an audiovisual component e.g., a camera of a client device associated with a conference call participant can generate an image depicting the conference call participant and the environment surrounding the conference call participant.
- the conference call participant can provide an indication (e.g., via the conference platform GUI at the client device) of a portion of the image that depicts the conference call participant and/or an indication of the portion of the image that depicts the environment surrounding the conference call participant.
- the client device can transmit the generated image as well as the one or more indications provided by the conference call participant to conference platform 120 (e.g., via network 108).
- conference management component 122 (or another component of conference platform 120) can store the received image and indications at data store 110 as training data.
- the conference call participant may not provide the indication of the portion of the image that depicts the conference call participant and/or the indication of the portion of the image that depicts the environment surrounding the conference call participant.
- the client device 102 associated with the conference call participant can transmit the generated image to conference platform and conference management component 122 (or another component of conference platform 120) can store the generated image at data store 110.
- a client device 102 associated with another user can obtain the generated image from data store 110.
- the other user can provide an indication of the portion of the image that depicts the conference call participant and/or an indication of the portion of the image that depicts the environment surrounding the conference call participant.
- the client device 102 associated with the other user can transmit the one or more indications to conference platform 120, in accordance with previously described embodiments.
- Conference management component 122 can store the one or more provided indications with the image as training data at data store 110, as described above.
- the image generated by the client device 102 associated with a conference call participant can depict an image of the participant during a prior conference call hosted by conference platform 120, in some embodiments.
- the image generated by the client device 102 can depict an image of the participant just before a conference call that is going to be hosted by conference platform 120.
- the conference call participant can be a presenter for the conference call and can prepare one or more documents that are to be shared during the conference call, in accordance with embodiments described herein.
- the conference call presenter can cause an audiovisual component (e.g., a camera) of the client device associated with the presenter to generate one or more images depicting the presenter before the conference call.
- an audiovisual component e.g., a camera
- the one or more generated images can depict conditions associated with the presenter and/or the environment surrounding the presenter that are expected to be captured by the audiovisual component of the client device during the conference call.
- the generated images can depict an expected positioning or orientation of the presenter during the conference call, an expected attire of the presenter during the conference call, an expected positioning of one or more objects included in the environment surrounding the presenter during the conference call, an expected lighting condition associated with the presenter and/or the environment surrounding the presenter during the conference call, and so forth.
- the client device 102 associated with the presenter can transmit the generated images to conference platform 120, as previously described.
- the presenter can provide an indication of a portion of each of the one or more generated images that depicts the presenter and/or an indication of a portion of the one or more generated images that depicts the environment surrounding the presenter via a GUI of the client device, as previously described.
- the client device 102 associated with the presenter can transmit the one or more generated images and the one or more provided indications to conference platform 120, as previously described.
- the one or more generated images and the one or more indications can be stored to data store 110 as training data, as described above.
- Training set generator 131 of server machine 130 can obtain the training data from data store 110 and can generate a training set based on the obtained training data.
- the training set can include a subset of training inputs and target outputs based on the retrieved training data.
- the subset of training inputs can include image data associated with an image depicting a conference call participant (i.e., generated during prior conference calls or before a conference call), as described above.
- Training set generator 131 can generate one or more target outputs for each of the subset of training inputs.
- training set generator 131 can determine, based on the one or more indications associated with each image of the training data, a set of pixels that correspond to the conference call participant and a set of pixels that correspond to the environment surrounding the conference call participant.
- a target output for a respective training input of the training set can correspond to at least an indication of the set of pixels that associated with the conference call participant.
- Server machine 140 can include a training engine 141.
- Training engine 141 can train a machine learning model 160A-N using the training data from training set generator 131.
- the machine learning model 160A-N can refer to the model artifact that is created by the training engine 141 using the training data that includes training inputs and corresponding target outputs (correct answers for respective training inputs).
- the training engine 141 can find patterns in the training data that map the training input to the target output (the answer to be predicted), and provide the machine learning model 160A-N that captures these patterns.
- the machine learning model 160A-N can be composed of, e.g., a single level of linear or non-linear operations (e.g., a support vector machine (SVM or may be a deep network, i.e., a machine learning model that is composed of multiple levels of non-linear operations).
- SVM support vector machine
- An example of a deep network is a neural network with one or more hidden layers, and such a machine learning model can be trained by, for example, adjusting weights of a neural network in accordance with a backpropagation learning algorithm or the like.
- the remainder of this disclosure will refer to the implementation as a neural network, even though some implementations might employ an SVM or other type of learning machine instead of, or in addition to, a neural network.
- the training set is obtained by training set generator 131 hosted by server machine 130.
- Background extraction engine 124 of server 150 can provide image data associated with one or more images generated by an audiovisual component (e.g., a camera) of a client device 102 associated with a participant (e.g., a presenter) of a current conference call as input to the trained machine learning model 160 to obtain one or more outputs.
- the provided image data can be associated with images that depict the conference call presenter in the same or similar conditions as associated with one or more images that were used to train machine learning model 160, as described above.
- the model 160 can be used to determine a likelihood that each pixel of the provided image data corresponds to the participant of the current conference call or an environment surrounding the conference call participant.
- the one or more outputs of the model 160 can include data indicating a level of confidence that one or more pixels of the image data corresponds to the conference call participant (or the environment surrounding the conference call participant).
- background extraction engine 124 can determine that the one or more pixels correspond to a view of the conference call participant and can extract the image depicting the conference call participant from the provided image data, in accordance with embodiments provided herein (e.g., with respect to FIG. 2).
- predictive system 112 can be configured to train a gesture detection model that is used by gesture detection engine 151 to detect a gesture made by a conference call participant during a conference call hosted by conference platform 120.
- training set generator 131 can be capable of generating training data to train the gesture detection model based on image and/or video data that have been previously captured by audiovisual components of client devices associated with participants of prior conference calls hosted by conference platform 120.
- an audiovisual component e.g., a camera of a client device 102 associated with a conference call participant can generate a video depicting the conference call participant providing a gesture (e.g., with his or her hands, with an object such as a pen or a laser pointer, etc.).
- the conference call participant can provide (e.g., during or after the conference call) an indication of whether the gesture was directed to one or more content items displayed in a document presented via a conference platform GUI of the client device 102.
- the conference call participant can provide another indication of the one or more content items of the presented document that were the focus of the provided gesture.
- the conference call participant can provide the one or more indications associated with the gesture and/or the content items of the presented document via the conference platform GUI at the client device 102, in some embodiments. Responsive to receiving the one or more indications via the conference platform GUI, the client device 102 can transmit video data associated with the generated video and the one or more indications to conference platform 120, in accordance with previously described embodiments. In some embodiments, client device 102 can also transmit one or more portions of the document was presented via the conference platform GUI at the time the video depicting the gesture was captured. Conference management component 122 (or another component of conference platform 120) can store the received video data, the one or more indications, and or the document as training data at data store 110, as described above.
- Training set generator 131 of server machine 130 can obtain the training data from data store 110 and can generate a training set based on the obtained training data, as described above.
- the training set can include a subset of training inputs and target outputs based on the obtained training data.
- the subset of training inputs can include video data associated with a video depicting a gesture provided by a conference call participant.
- the subset of training inputs can also include the document that was presented via the conference platform GUI at the time the video depicting the gesture was captured.
- Training set generator 131 can generate one or more target outputs for each of the subset of training inputs.
- training set generator 131 can determine, based on the one or more indications associated with a respective video data of the training data, whether a gesture depicted in a video captured by a client device 102 was made towards one or more content items of a document presented via the conference platform GUI of the client device 102 and can generate a target output based on this determination.
- training set generator 131 can determine one or more content items of the document that were the subject of the gesture based on the one or more indications associated with the respective video. Training set generator 131 can generate an additional target output indicating the determined one or more content items.
- Training engine 141 can train a machine learning model 160A-N using the training data from training set generator 131, in accordance with previously described embodiments.
- Gesture detection engine 151 can provide video data associated with one or more videos generated by an audiovisual component (e.g., a camera) of a client device associated with a participant (e.g., a presenter) of a current conference call as input to the trained machine learning model 160 to obtain one or more outputs.
- the model 160 can determine a likelihood that a gesture depicted in the video associated with the video data is directed to one or more content items of a document currently displayed via a conference platform GUI of client devices associated with one or more participants of the current conference call.
- the one or more outputs of the model 160 can provide a level of confidence that a gesture depicted in the video is directed to a respective content item included in the document. Responsive to determining that the level of confidence exceeds a threshold level of confidence, gesture detection engine 151 can determine that the participant of the conference call was likely gesturing to the respective content item. Gesture detection engine 151 can generate a GUI element (or transmit an instruction to client devices associated with the one or more participants of the conference call to generate the GUI element) that highlights the respective content item that is gestured to by the conference call participant. The gesture detection engine 151 can update the conference platform GUI at each client device associated with a conference platform participant to include the generated GUI element.
- conference platform 120 and/or server machines 130-150 can operate on one or more computing devices (such as a rackmount server, a router computer, a server computer, a personal computer, a mainframe computer, a laptop computer, a tablet computer, a desktop computer, etc.), data stores (e.g., hard disks, memories, databases), networks, software components, and/or hardware components that may be used to enable a user to connect with other users via a conference call.
- the functions of conference platform 120 may be provided by a more than one machine.
- the functions of conference management component 122, background extraction engine 124, and image overlay engine 126 may be provided by two or more separate server machines.
- Conference platform 120 may also include a website (e.g., a webpage) or application back-end software that may be used to enable a user to connect with other users via the conference call.
- server machines 130, 140, and 150 or conference platform 120 can be provided by a fewer number of machines.
- server machines 130 and 140 can be integrated into a single machine, while in other implementations server machines 130, 140, and 150 can be integrated into multiple machines.
- one or more of server machines 130, 140, and 150 can be integrated into conference platform 120.
- functions described in implementations as being performed by conference platform 120 can also be performed on the client devices 102A-N in other implementations, if appropriate.
- the functionality attributed to a particular component can be performed by different or multiple components operating together.
- Conference platform 120 can also be accessed as a service provided to other systems or devices through appropriate application programming interfaces, and thus is not limited to use in websites.
- implementations of the disclosure are discussed in terms of conference platform 120 and users of conference platform 120 participating in a video and/or audio conference call, implementations can also be generally applied to any type of telephone call or conference call between users. Implementations of the disclosure are not limited to content sharing platforms that provide conference call tools to users.
- a “user” can be represented as a single individual.
- other implementations of the disclosure encompass a “user” being an entity controlled by a set of users and/or an automated source.
- a set of individual users federated as a community in a social network can be considered a “user.”
- an automated consumer can be an automated ingestion pipeline, such as a topic channel, of the conference platform 120.
- a user may be provided with controls allowing the user to make an election as to both if and when systems, programs, or features described herein may enable collection of user information (e.g., information about a user’s social network, social actions, or activities, profession, a user’s preferences, or a user’s current location), and if the user is sent content or communications from a server.
- user information e.g., information about a user’s social network, social actions, or activities, profession, a user’s preferences, or a user’s current location
- certain data can be treated in one or more ways before it is stored or used, so that personally identifiable information is removed.
- a user’s identity can be treated so that no personally identifiable information can be determined for the user, or a user’s geographic location can be generalized where location information is obtained (such as to a city, ZIP code, or state level), so that a particular location of a user cannot be determined.
- location information such as to a city, ZIP code, or state level
- the user can have control over what information is collected about the user, how that information is used, and what information is provided to the user.
- FIG. 2 is a block diagram illustrating a conference platform 120 and a background extraction engine 124 for the conference platform 120, in accordance with implementations of the present disclosure.
- conference platform 120 can provide tools to users of a client device 102 to join and participate in a video and/or audio conference call.
- Conference platform 120 can include a conference management component 122.
- background extraction engine 124 can be configured to extract an image depicting a participant (e.g., a presenter) of a conference call from an image corresponding to a view of the participant in a surrounding environment.
- background extraction engine 124 can be included as a component of conference platform 120.
- background extraction engine can be separate from conference platform 120, as illustrated in FIG. 2.
- background extraction engine 124 can reside on one or more server machines that are separate from one or more server machines associated with conference platform 120.
- background extraction engine 124 can be communicatively coupled to multiple platforms (e.g., conference platform 120, a content sharing platform, a document sharing platform etc.) via one or more networks.
- background extraction engine 124 can be configured to extract images of users such platforms from image data, in accordance with embodiments described herein.
- Background extraction engine 124 can include at least an extraction component 220 and an image generation component 222, in some embodiments.
- an audiovisual component of a client device 102 can capture images and generate image data 210 associated with the captured images.
- the generated image data 210 can include two or more sets of pixels that each correspond to different portions of a view depicted in the captured images. For example, a first set of pixels can correspond to a portion of the view depicted in the captured images associated with a participant of a conference call hosted by conference platform 120. A second set of pixels can correspond to a portion of the view associated with an environment surrounding the participant, also referred to as a background of the participant.
- Client device 102 can transmit the generated image data 210 associated with the captured images to conference platform 120 (e.g., during a conference call with one or more additional users of conference platform 120). Responsive to receiving the image data from client device 102, conference platform 120 can provide the received image data 210 to background extraction engine 124. Background extraction engine 124 can store the received image data 210 at a memory (e.g., data store 110) associated with background extraction engine 124 and/or conference platform 120, in some embodiments.
- a memory e.g., data store 110
- Extraction component 220 of background extraction engine 124 can be configured to obtain an image depicting a participant of a conference call (referred to as participant image 212 herein) from image data 210 generated by client device 102.
- image data can include a first set of pixels that correspond to a view of the participant of the conference call and a second set of pixels that correspond to a view of an environment surrounding the participant.
- extraction component 220 can parse through image data 210 to identify the first set of pixels and the second set of pixels.
- the participant of the conference call can provide an indication of a first portion of a generated image that corresponds to the participant and a second portion of the generated image that corresponds to the surrounding environment (e.g., by drawing an outline of a silhouette of the participant using an element of the conference platform GUI).
- Extraction component 220 can identify, in view of the indication provided by the conference call participant, the first set of pixels that are associated with the first portion of the generated image and the second set of pixels that are associated with the second portion of the generated image.
- the pixels of image data 210 that correspond to the environment surrounding the conference call participant can be associated with a distinct color that is different from any color associated with the pixels of image data 210 that correspond to the conference call participant (e.g., if the conference call participant is sitting or standing in front of a green screen).
- Extraction component 220 can determine that each pixel of image data 210 that is associated with the distinct color is included in the second set of pixels corresponding to the surrounding environment and each pixel of image data 210 that is not associated with the distinct color is included in the first set of pixels corresponding to the conference call participant.
- extraction component 220 can identify the first set of pixels and the second set of pixels of image data 210 based on an output of a trained image extraction model 234.
- trained image extraction model 234 can be a machine learning model that is trained to determine a likelihood that each pixel of image data 210 corresponds to the conference call participant or an environment surrounding the conference call participant.
- trained image extraction model 234 can be trained by predictive system 112, in accordance with embodiments described with respect to FIG. 1.
- Extraction component 220 can provide the image data 210 generated by client device 102 as input to the trained image extraction model 234 and obtain one or more outputs of the trained image extraction model 234.
- the one or more obtained outputs can include data indicating a level of confidence that one or more pixels of image data 210 correspond to the conference call participant (or the environment surrounding the conference call participant).
- extraction component 220 can determine that the one or more pixels are included in the first set of pixels corresponding to the view of the conference call participant.
- extraction component 220 can determine that the one or more pixels are included in the second set of pixels corresponding to the view of the environment surrounding the conference call participant.
- extraction component 220 can extract the first set of pixels and store the extracted pixels 232 at data store 110.
- Image generation component 222 of background extraction engine 124 can generate the participant image 212 based on the extracted pixels 232, in some embodiments.
- background extraction engine 124 can transmit the generated participant image 212 to conference management component 122 to be overlaid with the shared document, in accordance with embodiments described herein.
- FIG. 3 is a block diagram illustrating an example conference platform 120 and an example image overlay engine 126 for the conference platform 120, in accordance with implementations of the present disclosure.
- conference management component 122 can enable a conference call participant to share a document displayed via a GUI on a client device associated with the conference call participant with other participants of the conference call.
- a presenter for a conference call can prepare a slide presentation document to share with the participants during the conference call.
- a conference platform GUI provided to the client device 102 associated with the presenter can include one or more GUI elements that enable the presenter to initiate a document sharing operation to share the document with the conference platform participants.
- Client device 102 can transmit a request to initiate the document sharing operation to conference platform 120 in response to detecting that the presenter has engaged (e.g., clicked on) the one or more GUI elements.
- Conference management component 122 of conference platform 120 can receive the request to initiate the document sharing operation from client device 102.
- conference management component 122 can also receive an image depicting the document 310 (or a portion of the document) that is to be shared with the other participants of the conference call.
- conference management component 122 can receive an identifier for a document 310 that is stored in a data store associated with a document sharing platform that is communicatively coupled to the conference platform 120.
- conference management component 122 can retrieve the document 310 from the data store (e.g., in response to determining that the presenter is permitted to access the document 310 from the data store).
- conference management component 122 can also receive image data 210 generated by client device 102. Conference management 122 can obtain the image depicting the presenter based on the received image data 210 (e.g., by providing the image data 210 to background extraction engine 124), in accordance with embodiments described with respect to FIG. 2.
- conference management component 122 can provide the participant image 212 and shared document 310 to image overlay engine 126.
- image overlay engine 126 can be configured to overlay participant image 212 with shared document 310.
- image overlay engine 126 can be included as a component of conference platform 120.
- image overlay engine 126 can be separate from conference platform 120, as illustrated in FIG. 2.
- image overlay engine 126 can reside on one or more server machines that are separate from one or more server machines associated with conference platform 120.
- Image overlay engine 126 can include at least a document region identifier component 320, a GUI layout component 322, and an overlay component 324.
- document region identifier component 320 can identify one or more regions of shared document 310 that satisfy one or more image placement criteria associated with shared document 310.
- the one or more image placement criteria correspond to a set of characteristics associated with a target region of shared document 310 for image placement.
- a region of shared document 310 can satisfy an image placement criterion if the region does not include any content (e.g., is a blank space). Such region is referred to as a blank region of document 310, in some embodiments.
- a region of shared document 310 can satisfy another image placement criterion if the region includes one or more content items that can be modified in order to accommodate presenter image 212.
- the set of characteristics associated with the target region of shared document 310 can be defined by the participant that has requested to share document 310 with other participants of the conference call (i.e., the conference call presenter).
- the set of characteristics can be determined by conference platform 120 in view of testing and/or run-time data collected for one or more conference calls at one or more client devices 102 connected to conference platform 120. Further details associated with the one or more image placement criteria are provided herein.
- document region identifier component 320 can identify one or more regions that satisfy the one or more image placement criteria based on metadata 332 associated with the document and/or metadata 334 associated with participant image 212.
- Document metadata 332 can include data associated with characteristics of one or more regions of shared document 310.
- client device 102 can transmit an image depicting the shared document 310 with the request to share document 310 with other participants of the conference call.
- Client device 102 can also include document metadata 332, which includes pixel data associated with one or more regions of shared document 310.
- the pixel data can indicate a color associated with one or more pixels of the image depicting shared document 310.
- image metadata 334 can include data associated with characteristics of one or more portions of participant image 212.
- image metadata 334 can include data associated with a size of participant image 212, a shape of participant image 212, and/or pixel data associated with the one or more portions of participant image 212.
- Document region identifier component 320 can identify a region that satisfies the one or more image placement criteria in view of document metadata 332 and/or image metadata 334. In some embodiments, document region identifier component 320 can determine the size of participant image 212 and/or the shape of participant image 212 based on image metadata 334. Document region identifier component 320 can also determine an image boundary associated with participant 212 in view of the determined size and/or shape of participant image 212. In some embodiments, the determined image boundary can correspond to a maximum and/or minimum size associated with participant image 212 at a region of shared document 310. The determined image boundary can also correspond to a target shape associated with participant image 212 at a region of shared document 310. For example, document region identifier component 320 can determine, in view of the determined size and/or shape of participant image 212, that a target shape associated with participant image 212 corresponds to a square shape.
- document region identifier component 320 can parse through pixel data included in document metadata 332 to identify a region of shared document 310 that does not include any content. For example, document region identifier 320 can determine, based on document metadata 332, that pixels corresponding to text content items of shared document 310 are associated with the color black and pixels corresponding to a background of shared document 310 are associated with the color white. Document region identifier 320 can parse through pixel data included in document metadata 332 to determine regions of shared document 310 that include pixels that are associated with the color white (i.e., regions that do not include any text content items).
- document region identifier component 320 can determine whether a size and/or shape of each respective region corresponds to the size and/or shape associated with participant image 212. For example, document region identifier component 320 can determine whether the size of a respective region is the same as or is larger than the size associated with participant image 212. In response to determining that the size of a respective region of shared document 310 corresponds to the size and/or shape associated with participant image 212, document region identifier can determine that the respective region satisfies the one or more image placement criteria.
- document region identifier component 320 can determine whether a region of shared document 310 satisfies the one or more image placement criteria in view of the pixel data associated with participant image 212.
- the pixel data associated with participant image 212 can include an indication of a color associated with one or more pixels of participant image 212.
- document region identifier component 320 can determine whether a color associated with the pixels for the identified region corresponds to a color associated with pixels for participant image 212.
- document region identifier component 320 can determine that the one or more image placement criteria are satisfied. In response to determining that the color associated with the pixels for participant image 212 correspond to a color associated with pixels for participant image 212, document region identifier component 320 can determine that the one or more image placement criteria are not satisfied.
- document region identifier component 320 can identify multiple regions of shared document 310 that satisfy the one or more image placement criteria. In such embodiments, document region identifier component 320 can determine a region for presentation of participant image 212 image placement conditions associated with shared document 310.
- An image placement condition can be a pre-defmed set of conditions associated with presenting participant image 212 with shared document 310.
- the image placement conditions can be defined by the participant that is requesting to share document 310 with other participants of the conference call. For example, before or during the conference call, the participant can provide (i.e., via a GUI of a client device associated with the participant) an indication of a target image region for each document shared with other conference call participants.
- document region identifier component 320 can select the target image region for placement of participant image 212.
- document region identifier component 320 can determine that no region of shared document 310 satisfies the one or more image placement criteria. For example, document region identifier component 320 can determine that no blank region of shared document 310 corresponds to a size and/or shape associated with participant image 212. In such example, document region identifier component 320 can determine whether a size and/or shape of participant image 212 can be modified for presentation with shared document 310.
- document region identifier component 320 can determine whether a size and/or shape of participant image 212 can be modified to fit within a blank region of shared document 310, in view of the maximum and/or minimum size associated with participant image 212. In response to determining that the size and/or the shape can be modified (e.g., the size of participant image 212 can be made smaller) to fit within a blank region of shared document 310, document region identifier component 320 can modify the size and/or shape of shared document 310 select region of shared document 310 for placement of modified participant image 212.
- document region identifier component 320 can determine that a size of participant image 212 cannot be modified to fit within a blank region of shared document 310. In such embodiments, document region identifier component 320 can determine whether participant image 212 can be placed over top of content at any region of shared document 310.
- a respective region of shared document 310 can include a logo of a company or an entity associated with one or more participants of the conference call.
- document region identifier component 320 can select the respective region for placement of participant image 212.
- document region identifier component 320 can determine that no pixels for any blank region of shared document 310 are associated with a color that is different from a color associated with pixels for participant image 212. In such example, document region identifier component 320 can determine whether one or more pixels for participant image 212 can be modified to be associated with a different color than the pixels for the blank region of shared document 310. For example, document region identifier component 320 can determine that a color temperature associated with the one or more pixels for participant image 212 can be modified (e.g., increased or decreased) such to cause the pixels for participant image 212 to be associated with a different color.
- the color associated with the one or more pixels for participant image 212 can be different from the color associated with the pixels for the blank region of shared documents 310.
- document region identifier component 320 can select the blank region of shared document 310 for placement of modified participant image 212.
- document region identifier component 320 can determine that the size, shape, and/or color associated with pixels of participant image 212 cannot be modified to fit within a blank region of shared document 310.
- document region identifier component 320 can identify a region of shared document 310 that corresponds to the image boundary for participant image 212 and includes the smallest number of content items than other regions of shared document 310.
- document region identifier component 320 can additionally modify a transparency of participant image 212 such that the content items at the identified region are detectable by the other participants of the conference call while participant image 212 is presented at the identified region.
- the request to initiate the document sharing operation can include an identifier for a document 310 that is stored in a data store associated with a document sharing platform that is communicatively coupled to conference platform 120.
- document region identifier component 320 can identify a region based on metadata 332 associated with the stored document and/or image metadata 334, as described above.
- document metadata 332 can include metadata associated with one or more content items included in document 310.
- the metadata associated with one or more content items can include an indication of a style associated with the one or more content items (e.g., a bold style, an italic style, an underlined style, etc.), a formatting associated with the one or more content items (e.g., a size of the content item), and/or an orientation of the one or more content items within the document 310 (i.e., a positioning of the content items relative to one or more other content items of the document 310).
- Document region identifier component 320 can determine whether any regions of document 310 correspond to the size and/or shape associated with participant image 212, in accordance with previously described embodiments.
- document region identifier component 320 can determine whether any region of document 310 includes one or more content items that can be modified in order to accommodate participant image 212.
- a content item of document 310 can correspond to a title associated with a slide of a slide presentation document.
- Document region identifier component 320 can obtain a style, a formatting and/or an orientation associated with the title based on document metadata 332.
- document region identifier component 320 can determine whether the size, formatting, and/or orientation associated with the title can be modified to accommodate participant image 212.
- document region identifier can modify the title to accommodate participant image 212 and can select the region associated with the modified title for presentation of participant image 212.
- overlay component 322 can overlay participant image 212 for presentation at the identified region.
- overlay component 322 can generate a rendering of participant image 212 at the identified region of shared document 310 and can transmit the rendering to conference platform 120.
- conference management component 122 can transmit the rendering to each client device 102 associated with a participant of the conference call, in accordance with embodiments described herein.
- overlay component 322 can generate one or more instructions for rendering participant image 212 at the identified region of document 310 and can transmit the generated instructions to conference platform 120.
- conference management component 122 can execute the received instructions to generate the rendering of participant image 212 at the identified region of document 310.
- conference management component 122 can transmit the received instructions (with or without participant image 212 and/or shared document 310) to each client device 102 associated with a participant of conference call and client device 102 can execute the instructions to generate the rendering of participant image 212 at the identified region of document 310.
- image overlay engine 126 can also include a GUI layout component 322.
- GUI layout component 324 can be configured to modify the presentation of shared document 310 at a respective client device 102 in view of one or more hardware constraints associated with the client device 102.
- a presenter of a conference call can be associated with client device 102 A and a participant of the conference call can be associated with client device 102B.
- Client device 102A can include a larger display screen than a display screen of a client device 102B.
- client device 102A can be a desktop computing device and client device 102B can be a mobile computing device.
- one or more hardware constraints associated with displaying the shared document 310 with participant image 212 at the client device 102B can be different from hardware constraints of the client device associated with client device 102 A.
- GUI layout component 324 can obtain one or more hardware constraints associated with displaying the shared document 310 with participant image 212 at client device 102B (e.g., by requesting the hardware constraints from client device 102B, in a request from client device 102B to join a conference call hosted by conference platform 120, etc.), and can store the obtained hardware constraints as hardware constraint data 336 at data store 110. In response to determining that the one or more hardware constraints satisfy a hardware constraint criterion, GUI layout component 324 can determine to modify the presentation of shared document 310 at client device 102B.
- GUI layout component 324 can determine that a hardware constraint for client device 102B satisfies a hardware constraint criterion in response to determining that a display screen size associated with client device 102B falls below a threshold screen size. In other or similar embodiments, GUI layout component 324 can determine that a hardware constraint for client device 102B satisfies a hardware constraint criterion in response to determining that a display resolution associated with client device 102B falls below a threshold display resolution.
- GUI layout component 324 can modify the presentation of shared document 310 at client device 102B by identifying two or more distinct portions of content at shared document 310. For example, GUI layout component 324 can determine that shared document 310 includes a first portion of content that includes one or more text content items and a second portion of content that includes one or more image content items. In some embodiments, in response to identifying the first and second portions of content at shared document 310, GUI layout component 324 can transmit an instruction to overlay component 322 to display participant image 212 over top of the second portion of content while also displaying the first portion of content at another region of document 310.
- GUI layout component 324 can detect that the presenter of the conference call has shifted focus from the first portion of content to the second portion of content (i.e., which is blocked by participant image 212). For example, GUI layout component 324 can detect that the presenter has moved a GUI element (e.g., a mouse, a cursor, etc.) of the conference platform GUI to highlight one or more content items at the first portion of content of document 310. In response to detecting that the presenter has shifted focus to the second portion of content, GUI layout component 324 can update the conference platform GUI to display participant image 212 at the region of document 310 that includes the first portion of content while displaying the second portion of content of document 310. In some embodiments, GUI layout component 324 can update the conference platform GUI by generating an instruction that causes overlay component 324 to display participant image 212 over the first portion of content, in accordance with embodiments described herein.
- GUI layout component 324 can update the conference platform GUI by generating an instruction that causes overlay component 324 to display participant image 212 over the first portion
- GUI layout component 324 can generate a new document 338 that includes one or more of the identified distinct portions of content at shared document 310. For example, GUI layout component 324 can select a region including the first portion of content to display with participant image 212. GUI layout component 324 can also generate document 338, which includes one or more similar design characteristics (e.g., style, format, orientation, background, etc.) as shared document 310. Document 338 can further include the second portion of content that is included in shared document 310. In some embodiments, document 338 can also include a blank space (e.g., that corresponds to the region including the first portion of content at shared document 310).
- a blank space e.g., that corresponds to the region including the first portion of content at shared document 310.
- overlay component 324 can present participant image 212 at the region of shared document 310 that corresponds to the second portion of content. Responsive to GUI layout component 324 detecting that the presenter has shifted focus to the second portion of content, GUI layout component 324 can update the conference platform GUI to display generated document 338, which includes the second portion of content. Overlay component 324 can also present participant image 212 at the region of generated document 338 that includes the blank space (e.g., that corresponds to the region including the first portion of content at shared document 310). Further details and examples regarding the generation of document 338 are provided with respect to FIGs. 6A-6C.
- FIG. 4 depicts a flow diagram of an example method 400 for providing a shared document and an image of a conference call participant for presentation via a GUI, in accordance with implementations of the present disclosure.
- Method 400 can be performed by processing logic that can include hardware (circuitry, dedicated logic, etc.), software (e.g., instructions run on a processing device), or a combination thereof. In one implementation, some or all the operations of method 400 can be performed by one or more components of system 100 of FIG. 1.
- processing logic can receive a request to share a document associated with a first participant of a conference call with one or more second participants.
- processing logic can receive the request to share the document from a client device associated with a first participant of a conference call.
- FIG. 5A depicts an example GUI 500 on a client device associated with a first participant (e.g., a presenter) of a conference call, in accordance with implementations of the present disclosure.
- GUI 500 can include at least a first portion 510 and a second portion 530.
- the first portion 510 of GUI 500 can include one or more GUI elements that enable one or more users of conference platform 120 (e.g., the presenter, participants A-N, etc.) to join and participate in the conference call.
- the second portion 530 of GUI 500 can display a document 532 (e.g., a slide presentation document, a word document, a webpage document, etc.) that is to be shared by a presenter of the conference call with one or more participants of the conference call (e.g., participants A- N).
- one or more elements of the first portion 510 of GUI 500 correspond to GUI elements of a conference platform GUI provided by conference management component 122, as described above.
- elements of both the first portion 510 and second portion 530 of GUI 500 correspond to elements of the conference platform GUI.
- the first portion 510 of GUI 500 can include a first section 512 and a second section 518 that are both configured to output video data captured at client devices 102 associated with each participant of the conference call.
- first section 512 can display image data captured by a client device associated with a presenter of a video conference call.
- Second section 518 can display image data captured by client devices associated with participants of the call.
- first portion 510 can include one or more sections that are configured to display image data associated with users of conference platform 120 in other orientations than depicted in FIG. 5A.
- portion 510 can include a single section that displays image data captured by client devices of the presenter of the conference call and does not display video data captured by client devices of other participants of the conference call.
- the image data displayed at the first section 512 and/or the second section 518 of first portion 510 can correspond to a view of a user (e.g., the presenter, participant A-N) in a surrounding environment.
- first section 512 of portion 510 can display image data corresponding to a view of presenter 514 in a surrounding environment 516.
- second section 512 of portion 510 can also display image data corresponding to a view of participants A-N in respective surrounding environments (not shown).
- the first portion 510 of GUI 500 can also include one or more GUI elements that enable the presenter of the conference call to share document 522 displayed at the second portion 530 with the participants of the conference call.
- first portion 510 can include a button 520 that enables the presenter to share document 522 displayed at second portion 530 with participants A-N.
- the presenter can initiate an operation to share document 522 with participants A-N by engaging (e.g., clicking) with button 520.
- the client device associated with the presenter can detect that an operation to share document 532 with participants A-N is to be initiated.
- the client device can transmit the request to initiate the document sharing operation to conference management component 122, in accordance with previously described embodiments.
- the presenter can initiate the operation to share document 522 with participants A-N according to other techniques.
- a setting for the client device associated with the presenter can cause the operation to share document 522 to be initiated in response to detecting that document 522 has been retrieved from local memory of the client device and displayed at the second portion 530 of GUI 500.
- processing logic can receive image data corresponding to a view of the first participant (e.g., the presenter) in a surrounding environment.
- an audiovisual component of the client device associated with the first participant can be configured to capture images of the first participant and generate image data associated with the captured images.
- the generated image data can be displayed at the first section 512 of the first portion 510 of GUI 500, in according to some embodiments.
- the client device associated with the first participant can transmit the generated image data displayed at the first section 512 of the first portion 510 of GUI 500 to conference management component 122.
- the client device associated with the first participant can transmit the generated image data with or separate from the request to initiate the document sharing operation.
- processing logic can obtain an image depicting the first participant based on the received image data.
- conference management component 122 can provide the received image data to background extraction engine 124, in some embodiments.
- background extraction engine 124 can obtain the image depicting the conference call presenter by extracting a set of pixels that corresponds to the conference call presenter and generating the image depicting the conference call presenter based on the extracted set of pixels.
- background extraction engine 124 can identify the set of pixels that corresponds to the conference call presenter based on an output of a trained image extraction model, in accordance with previously described embodiments.
- processing logic can identify one or more regions of the document (e.g., document 522) that satisfy one or more image placement criteria.
- conference management component 122 can receive an image of document 522 to be shared with participants A-N of the conference call from the client device associated with the conference call presenter, in some embodiments.
- document 522 can be stored in a data store associated with a document sharing platform that is communicatively coupled to conference platform 120.
- conference management component 122 can receive an identifier for document 522 at the data store associated with a document sharing platform.
- Conference management component 122 can retrieve document 522 (or a portion of document 522) from the data store associated with the document sharing platform, in accordance with previously described embodiments.
- conference management component 122 can provide document 522 to image overlay engine 126, as previously described.
- Image overlay engine 126 can identify one or more regions of document 522 that satisfy one or more image placement criteria, as described above. For example, image overlay engine 126 can identify one or more blank regions of document 522 that correspond to an image boundary associated with the image of the conference call presenter. In another example, image overlay engine 126 can identify one or more regions of document 522 that include content items that can be modified to accommodate the image of conference call presenter.
- processing logic can provide the document and the image depicting the first participant for presentation via a GUI on a client device associated with the second participant.
- image overlay engine 126 can overlay the image of the conference call presenter at one of the identified regions, as described above.
- image overlay engine 126 can generate a rendering of the image depicting the conference call presenter and the document 522 and provide the generated rendering to conference management component 122.
- Conference management component 122 can provide the generated rendering to the client devices associated with one or more users of conference platform 120 (e.g., the presenter, participant A-N), in accordance with previously described embodiments.
- a client device associated with a respective participant of the conference call can update a GUI to display the rendering of the image depicting the conference call presenter and the document 522.
- image overlay engine 126 can generate instructions to render the image depicting the conference call presenter and document 522.
- Conference management component 122 and/or the client device associated with the respective participant of the conference call can execute the instructions to generate the rendering, in accordance with previously described embodiments.
- FIG 5B depicts an example GUI 550 displaying the rendering of the image depicting the conference call presenter and document 522, in accordance with implementations of the present disclosure.
- GUI 550 can be displayed via a client device associated with a participant of the conference call (e.g., participant A).
- GUI 550 can be displayed via a client device associated with the presenter of the conference call.
- GUI 550 depicts the document 532 and an image 552 depicting the conference call presenter at a region 554 of document 532.
- image overlay engine 126 can select region 554 to include image 552 in response to determining that region 554 satisfies one or more image placement criteria (e.g., includes a blank space that corresponds to an image boundary associated with image 552).
- the presenter of the conference call can engage with participants A-N by emphasizing one or more content items of document 532 (e.g., by physically pointing to the one or more content items) while image 552 is presented at region 554.
- GUI 550 can additionally display image data captured by one or more client devices associated with participants (e.g., participants A-N) of the conference call, as described above.
- GUI 550 can be displayed via a client device associated with the presenter of the conference call.
- the conference call presenter can engage with one or more elements of GUI 550 to modify the presentation of image 552 and document 532, in some embodiments.
- the conference call presenter can request move image 552 from region 554 of document 532 to another region of document 532 (e.g., by clicking image 552 and dragging image 552 to another region of document 532, by pushing one or more buttons on a keyboard connected to the client device).
- conference management component 122 can update GUI 550 at each client device associated with the presenter and each participant of the conference call, in accordance with the received request.
- FIG. 5C depicts an example updated GUI 550, in accordance with implementations of the present disclosure.
- image 552 depicting the conference call presenter has been moved from region 554 of GUI 550 to region 556 of GUI 550.
- region 556 can be associated with different characteristics than region 554.
- a size of region 556 can be smaller than the size of region 554.
- conference management component 122 (or image overlay engine 126) can modify a size and/or shape of image 552 to fit within region 556 (e.g., in view of the image boundary associated with image 552).
- conference management component 122 cannot modify a size and/or shape of image 552 to fit within region 556 in view of the image boundary associated with image 552. In such embodiments, conference management component 122 can move image 552 to region 556 in accordance with the request from the conference call presenter. However, in some embodiments, at least a portion of the image 552 can overlap with one or more content items of document 532. In such instance, conference management component 122 can modify a transparency of image 552 such that participants A-N of the conference call can detect the content items of document 532 that overlap with image 552. [0086] FIGs.
- FIG. 6A-6C illustrate another example of overlaying an image of a conference call participant with a shared document for presentation via a GUI, in accordance with implementations of the present disclosure.
- FIG. 6A depicts another example GUI 600 on a client device associated with a first participant (e.g., a presenter) of a conference call.
- GUI 600 can correspond to GUI 500 described with respect to FIG. 5A, except that the document 632 displayed at the second portion 630 of GUI 600 can include one or more additional content items than included in document 532 displayed at the second portion 530 of GUI 500.
- the conference call presenter can initiate the operation to share document 632 with participants A-N of the conference call (e.g., by engaging with button 620) as described previously.
- conference management component 122 can transmit the image data generated by the client device associated with the conference call presenter and/or document 632 (or a portion of document 632) to image overlay engine 126.
- a client device associated with a participant of the conference call e.g., participant A
- image overlay engine 126 can determine to modify the presentation of document 632 and the image depicting the conference call presenter, e.g., in response to determining that the hardware constraints of the client device associated with participant A satisfy a hardware constraint condition.
- image overlay engine 126 can determine to display a first portion of content of document 632 (e.g., the one or more text content items associated with data points 1-5 of document 632) and the image depicting the conference call presenter at a region including the second portion of content of document 632 (e.g., the one image content item of document 632).
- image overlay engine 126 can generate an additional document that includes the second portion of content of document 632, as described previously.
- image overlay engine 126 can determine to display the first portion of content of document 632 with the image depicting the conference call presenter at the region associated with the second portion of content of document 632.
- FIG. 6B depicts an example GUI 650 displaying the rendering of the image depicting the conference call presenter and document 632, in accordance with implementations of the present disclosure.
- GUI 650 can be displayed via a client device associated with a participant of the conference call (e.g., participant A).
- GUI 650 can be displayed via a client device associated with the presenter of the conference call.
- GUI 650 displays the content included in the first portion of document 632 in a first region 654 of document 632 and an image 652 depicting the conference call presenter at a second region 656 of document 632.
- region 654 is associated with a second portion of content (e.g., the graph included in document 632 illustrated in FIG. 6A) included in document 632.
- GUI 650 can display image 652 at region 656 associated with the graphic content item, in accordance with previously described embodiments.
- conference management component 122 (or image overlay engine 126) can detect that the conference call presenter has shifted focus to the second portion of content included in document 632. For example, conference management component 122 can detect that the conference call presenter has moved a GUI element (e.g., a mouse) at the GUI on the client device associated with the presenter from region 654 of document 632 including the first portion of content to region 656 including the second portion of content. In such embodiments, conference management component 122 (or image overlay engine 126) can update GUI 650 to display the second portion of content of document 632.
- GUI element e.g., a mouse
- FIG. 6C depicts an example updated GUI 650, in accordance with implementations of the present disclosure.
- updated GUI 650 displays document 632 with image 622 at region 656.
- updated GUI 650 displays the document generated by image overlay engine 126 that includes the second portion of content included in document 632.
- updated GUI 650 can display image 622 at region 654 of document 632, in accordance with previously described embodiments.
- FIG. 7 depicts a flow diagram of another example method 700 for providing a shared document and an image of a conference call participant for presentation via a GUI, in accordance with implementations of the present disclosure.
- Method 400 can be performed by processing logic that can include hardware (circuitry, dedicated logic, etc.), software (e.g., instructions run on a processing device), or a combination thereof. In one implementation, some or all the operations of method 700 can be performed by one or more components of system 100 of FIG. 1.
- processing logic can share a document displayed via a first GUI on a first client device associated with a first participant (e.g., a presenter) of a conference call with a second participant of the conference call via a second GUI on a second client device.
- FIG. 8A depicts an example GUI 800 displaying a document 812 shared with one or more participants (e.g., Participant A-N) of a conference call, in accordance with implementations of the present disclosure.
- GUI 800 can be displayed via a client device associated with a participant of the conference call (e.g., participant A).
- GUI 800 can be displayed via a client device associated with the presenter of the conference call.
- the presenter of the conference call can share document 812 with the participants of the conference call by engaging with a GUI element (e.g., button 820), in accordance with previously described embodiments.
- document 812 can be stored at a data store associated with a document sharing platform communicatively coupled to conference platform 120.
- processing logic can receive a request to display an image depicting the first participant with the document shared with the second participant.
- processing logic can receive the request in response to the conference call presenter engaging with a particular GUI element (not shown) of GUI element 800.
- processing logic can receive image data corresponding to a view of the first participant in a surrounding environment.
- the client device associated with the conference call presenter can generate image data corresponding to the view of the presenter in the surrounding environment, in accordance with previously described embodiments.
- Conference management component 122 can receive the generated image data from the client device associated with the conference call presenter, in accordance with previously described embodiments.
- processing logic can obtain an image depicting the first participant based on the received image data.
- conference management component 122 can provide the received image data to background extraction engine 124.
- Background extraction engine 124 can generate the image depicting the first participant, in accordance with previously described embodiments.
- processing logic can modify a formatting and/or an orientation of one or more content items of the shared document in view of the image depicting the first participant.
- document 812 can be stored at a data store associated with a document sharing platform communicatively coupled to conference platform 120.
- Content management component 122 can retrieve document 812 from the data store, as previously described.
- image overlay engine 126 can identify a region of document 812 that includes one or more content items that can be modified in view of the image depicting the conference call presenter. For example, image overlay engine 126 can identify region 814 of document 812 that includes a title content item. Image overlay engine 126 can determine that a formatting and/or an orientation of the title content item of region 814 can be modified (e.g., in view of metadata associated with document 812) to accommodate the image depicting the conference call presenter. In other example, image overlay engine 126 can determine that a formatting and/or an orientation of one or more text content items can additionally or alternatively be modified to accommodate the image depicting the conference call presenter.
- processing logic can provide the image depicting the first participant with the modified document for presentation via the second GUI on the second client device.
- FIG. 8B depicts an updated GUI 800, in accordance with implementations of the present disclosure.
- image overlay engine 126 can modify the formatting and/or orientation of the one or more content items at region 814 and/or region 816, in accordance with previously described embodiments.
- Conference management component 122 can present the modified document 812 via the updated GUI 800, in accordance with previously described embodiments.
- a formatting of the title content item in region 814 of document 812 is modified from an alignment in a center portion of document 812 to an alignment at a left-hand portion of document 812.
- a size of the one or more text items in region 816 of document 812 has been decreased and an orientation of the one or more text items in region 814 has been modified to accommodate image 822 depicting the conference presenter.
- FIGs. 9A-9B illustrate an example of overlaying an image of multiple conference call participants with a shared document for presentation via a GUI 900, in accordance with implementations of the present disclosure.
- an image 910 depicting a conference call presenter can be displayed at particular region 912 of a document via a conference platform GUI, in accordance with previously described embodiments.
- the conference call presenter can invite an additional participant of the conference call to present a shared document (or a portion of the document) with the conference call presenter.
- the client device associated with the conference call presenter can transmit a request to the client device associated with the additional participant to present the shared document with the conference call presenter.
- conference management component 122 can initiate a process to display a rendering of an image depicting the additional participant of the conference call with the image depicting the presenter of the conference call.
- conference management component 122 can receive image data generated by an audiovisual component (e.g., a camera) of a client device associated with the additional participant. Conference management component 122 can obtain an image depicting the additional participant, in accordance with previously described embodiments. In some embodiments, conference management component 122 can identify a region of a shared document that satisfies one or more image placement criteria. In some embodiments, conference management component 122 can identify a region that satisfies one or more image placement criteria with respect to the image depicting the additional participant. In other or similar embodiments, conference management component 122 can identify a region that satisfies the one or more image placement criteria with respect to both the image depicting the conference call presenter and the additional participant.
- an audiovisual component e.g., a camera
- conference management component 122 can update a GUI 900 on client devices for each participant of the conference call to display the additional participant (and/or the conference call presenter) at the identified region.
- region 916 can be identified as a region that satisfies one or more image placement criteria.
- the image 914 depicting the additional participant can be displayed at region 916.
- conference management component 122 may not identify a region of the shared document that satisfies the image placement criteria with respect to image 910 depicting the conference call presenter and/or the image 914 depicting the additional participant.
- conference management component 122 can modify a format and/or an orientation of one or more content items of the shared document to accommodate the image depicting the conference call presenter and the image depicting the additional participant, in accordance with embodiments described above.
- the conference call presenter and/or the additional participant can invite another conference call participant to present the shared document (or a portion of the shared document) in place of the conference call presenter.
- conference management component 122 can obtain an image depicting the other conference call participant, as described above.
- conference management component 122 can remove the image 910 depicting the conference call presenter from GUI 900 and replace the removed image 910 with the image depicting the other conference call participant, as illustrated in FIG. 9B.
- conference management component 122 can identify another region of the shared document that satisfies the one or more image placement criteria and display the image 918 depicting the other conference call participant at the identified region, in accordance with previously described embodiments.
- conference management component 122 can modify a format and/or an orientation of one or more content items of the shared document to accommodate image 914 and/or image 918, as previously described.
- FIG. 10 is a block diagram illustrating an exemplary computer system 1000, in accordance with implementations of the present disclosure.
- the computer system 1000 can correspond to conference platform 120 and/or client devices 102A-N, described with respect to FIG. 1.
- Computer system 1000 can operate in the capacity of a server or an endpoint machine in endpoint-server network environment, or as a peer machine in a peer-to-peer (or distributed) network environment.
- the machine can be a television, a personal computer (PC), a tablet PC, a set-top box (STB), a Personal Digital Assistant (PDA), a cellular telephone, a web appliance, a server, a network router, switch or bridge, or any machine capable of executing a set of instructions (sequential or otherwise) that specify actions to be taken by that machine.
- PC personal computer
- PDA Personal Digital Assistant
- STB set-top box
- a cellular telephone a web appliance
- server a server
- network router switch or bridge
- the example computer system 1000 includes a processing device (processor) 1002, a main memory 1004 (e.g., read-only memory (ROM), flash memory, dynamic random access memory (DRAM) such as synchronous DRAM (SDRAM), double data rate (DDR SDRAM), or DRAM (RDRAM), etc.), a static memory 1006 (e.g., flash memory, static random access memory (SRAM), etc.), and a data storage device 1018, which communicate with each other via a bus 1040.
- processor (processing device) 1002 represents one or more general-purpose processing devices such as a microprocessor, central processing unit, or the like.
- the processor 1002 can be a complex instruction set computing (CISC) microprocessor, reduced instruction set computing (RISC) microprocessor, very long instruction word (VLIW) microprocessor, or a processor implementing other instruction sets or processors implementing a combination of instruction sets.
- the processor 1002 can also be one or more special-purpose processing devices such as an application specific integrated circuit (ASIC), a field programmable gate array (FPGA), a digital signal processor (DSP), network processor, or the like.
- the processor 1002 is configured to execute instructions 1005 (e.g., for predicting channel lineup viewership) for performing the operations discussed herein.
- the computer system 1000 can further include a network interface device 1008.
- the computer system 1000 also can include a video display unit 1010 (e.g., a liquid crystal display (LCD) or a cathode ray tube (CRT)), an input device 1012 (e.g., a keyboard, and alphanumeric keyboard, a motion sensing input device, touch screen), a cursor control device 1014 (e.g., a mouse), and a signal generation device 1020 (e.g., a speaker).
- a video display unit 1010 e.g., a liquid crystal display (LCD) or a cathode ray tube (CRT)
- an input device 1012 e.g., a keyboard, and alphanumeric keyboard, a motion sensing input device, touch screen
- a cursor control device 1014 e.g., a mouse
- signal generation device 1020 e.g., a speaker
- the data storage device 1018 can include a non-transitory machine-readable storage medium 1024 (also computer-readable storage medium) on which is stored one or more sets of instructions 1005 (e.g., for overlaying an image depicting a conference call presenter with a shared document) embodying any one or more of the methodologies or functions described herein.
- the instructions can also reside, completely or at least partially, within the main memory 1004 and/or within the processor 1002 during execution thereof by the computer system 1000, the main memory 1004 and the processor 1002 also constituting machine- readable storage media.
- the instructions can further be transmitted or received over a network 1030 via the network interface device 1008.
- the instructions 1005 include instructions for overlaying an image depicting a conference call participant with a shared document.
- the computer- readable storage medium 1024 (machine-readable storage medium) is shown in an exemplary implementation to be a single medium, the terms “computer-readable storage medium” and “machine-readable storage medium” should be taken to include a single medium or multiple media (e.g., a centralized or distributed database, and/or associated caches and servers) that store the one or more sets of instructions.
- computer-readable storage medium and “machine-readable storage medium” shall also be taken to include any medium that is capable of storing, encoding or carrying a set of instructions for execution by the machine and that cause the machine to perform any one or more of the methodologies of the present disclosure.
- references throughout this specification to “one implementation,” “one embodiment,” “an implementation,” or “an embodiment,” means that a particular feature, structure, or characteristic described in connection with the implementation and/or embodiment is included in at least one implementation and/or embodiment.
- the appearances of the phrase “in one implementation,” or “in an implementation,” in various places throughout this specification can, but are not necessarily, referring to the same implementation, depending on the circumstances.
- the particular features, structures, or characteristics can be combined in any suitable manner in one or more implementations.
- a component can be, but is not limited to being, a process running on a processor (e.g., digital signal processor), a processor, an object, an executable, a thread of execution, a program, and/or a computer.
- a processor e.g., digital signal processor
- an application running on a controller and the controller can be a component.
- One or more components can reside within a process and/or thread of execution and a component can be localized on one computer and/or distributed between two or more computers.
- a “device” can come in the form of specially designed hardware; generalized hardware made specialized by the execution of software thereon that enables hardware to perform specific functions (e.g., generating interest points and/or descriptors); software on a computer readable medium; or a combination thereof.
- one or more components can be combined into a single component providing aggregate functionality or divided into several separate sub-components, and any one or more middle layers, such as a management layer, can be provided to communicatively couple to such sub-components in order to provide integrated functionality.
- middle layers such as a management layer
- Any components described herein can also interact with one or more other components not specifically described herein but known by those of skill in the art.
- example or “exemplary” are used herein to mean serving as an example, instance, or illustration. Any aspect or design described herein as “exemplary” is not necessarily to be construed as preferred or advantageous over other aspects or designs. Rather, use of the words “example” or “exemplary” is intended to present concepts in a concrete fashion.
- the term “or” is intended to mean an inclusive “or” rather than an exclusive “or.” That is, unless specified otherwise, or clear from context, “X employs A or B” is intended to mean any of the natural inclusive permutations.
- implementations described herein include collection of data describing a user and/or activities of a user.
- data is only collected upon the user providing consent to the collection of this data.
- a user is prompted to explicitly allow data collection.
- the user can opt-in or opt-out of participating in such data collection activities.
- the collect data is anonymized prior to performing any analysis to obtain any statistical patterns so that the identity of the user cannot be determined from the collected data.
Abstract
Description
Claims
Priority Applications (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
CN202280008982.1A CN116762333A (en) | 2021-05-24 | 2022-05-24 | Superimposing images of conference call participants and shared documents |
EP22738098.7A EP4320856A1 (en) | 2021-05-24 | 2022-05-24 | Overlaying an image of a conference call participant with a shared document |
Applications Claiming Priority (4)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US202163192509P | 2021-05-24 | 2021-05-24 | |
US63/192,509 | 2021-05-24 | ||
US17/549,708 | 2021-12-13 | ||
US17/549,708 US20220374190A1 (en) | 2021-05-24 | 2021-12-13 | Overlaying an image of a conference call participant with a shared document |
Publications (1)
Publication Number | Publication Date |
---|---|
WO2022251257A1 true WO2022251257A1 (en) | 2022-12-01 |
Family
ID=82403842
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
PCT/US2022/030779 WO2022251257A1 (en) | 2021-05-24 | 2022-05-24 | Overlaying an image of a conference call participant with a shared document |
Country Status (2)
Country | Link |
---|---|
EP (1) | EP4320856A1 (en) |
WO (1) | WO2022251257A1 (en) |
Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20130314421A1 (en) * | 2011-02-14 | 2013-11-28 | Young Dae Kim | Lecture method and device in virtual lecture room |
US20150186744A1 (en) * | 2013-12-31 | 2015-07-02 | Personify, Inc. | Transmitting video and sharing content via a network |
US20170039867A1 (en) * | 2013-03-15 | 2017-02-09 | Study Social, Inc. | Mobile video presentation, digital compositing, and streaming techniques implemented via a computer network |
US20210076105A1 (en) * | 2019-09-11 | 2021-03-11 | Educational Vision Technologies, Inc. | Automatic Data Extraction and Conversion of Video/Images/Sound Information from a Slide presentation into an Editable Notetaking Resource with Optional Overlay of the Presenter |
-
2022
- 2022-05-24 EP EP22738098.7A patent/EP4320856A1/en active Pending
- 2022-05-24 WO PCT/US2022/030779 patent/WO2022251257A1/en active Application Filing
Patent Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20130314421A1 (en) * | 2011-02-14 | 2013-11-28 | Young Dae Kim | Lecture method and device in virtual lecture room |
US20170039867A1 (en) * | 2013-03-15 | 2017-02-09 | Study Social, Inc. | Mobile video presentation, digital compositing, and streaming techniques implemented via a computer network |
US20150186744A1 (en) * | 2013-12-31 | 2015-07-02 | Personify, Inc. | Transmitting video and sharing content via a network |
US20210076105A1 (en) * | 2019-09-11 | 2021-03-11 | Educational Vision Technologies, Inc. | Automatic Data Extraction and Conversion of Video/Images/Sound Information from a Slide presentation into an Editable Notetaking Resource with Optional Overlay of the Presenter |
Also Published As
Publication number | Publication date |
---|---|
EP4320856A1 (en) | 2024-02-14 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US10423656B2 (en) | Tag suggestions for images on online social networks | |
US10152773B2 (en) | Creating a blurred area for an image to reuse for minimizing blur operations | |
AU2014274171B2 (en) | Tag suggestions for images on online social networks | |
US20190339820A1 (en) | Displaying a subset of menu items based on a prediction of the next user-actions | |
US11463748B2 (en) | Identifying relevance of a video | |
US20230208894A1 (en) | Integrating a video feed with shared documents during a conference call discussion | |
US20170109339A1 (en) | Application program activation method, user terminal, and server | |
US20220374190A1 (en) | Overlaying an image of a conference call participant with a shared document | |
US11875029B2 (en) | Video display method and apparatus, computer-readable medium, and electronic device | |
US11838448B2 (en) | Audio-based polling during a conference call discussion | |
EP4320856A1 (en) | Overlaying an image of a conference call participant with a shared document | |
US11675492B2 (en) | Determining user engagement in content based on scrolling events | |
CN116762333A (en) | Superimposing images of conference call participants and shared documents | |
US20230334240A1 (en) | Providing fine-grained version histories of electronic documents at a platform | |
US20230222281A1 (en) | Modifying the presentation of drawing objects based on associated content objects in an electronic document | |
US11755181B2 (en) | Populating answers to polling questions based on initial responses | |
US20230379520A1 (en) | Time marking of media items at a platform using machine learning | |
US11972200B1 (en) | Tracking approvals for an electronic document managed by an electronic document platform | |
US20230379556A1 (en) | Crowd source-based time marking of media items at a platform | |
US20240098184A1 (en) | Audio-based polling during a conference call discussion | |
US20230023973A1 (en) | System and methods for changing a size of a group of users to be presented with a media item | |
CN116992113A (en) | Information searching method and device, electronic equipment and storage medium |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
121 | Ep: the epo has been informed by wipo that ep was designated in this application |
Ref document number: 22738098Country of ref document: EPKind code of ref document: A1 |
|
WWE | Wipo information: entry into national phase |
Ref document number: 202280008982.1Country of ref document: CN |
|
WWE | Wipo information: entry into national phase |
Ref document number: 2022738098Country of ref document: EP |
|
ENP | Entry into the national phase |
Ref document number: 2022738098Country of ref document: EPEffective date: 20231110 |
|
NENP | Non-entry into the national phase |
Ref country code: DE |