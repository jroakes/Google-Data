KR20200003132A - Generate query variants using a trained generation model - Google Patents
Generate query variants using a trained generation model Download PDFInfo
- Publication number
- KR20200003132A KR20200003132A KR1020197035500A KR20197035500A KR20200003132A KR 20200003132 A KR20200003132 A KR 20200003132A KR 1020197035500 A KR1020197035500 A KR 1020197035500A KR 20197035500 A KR20197035500 A KR 20197035500A KR 20200003132 A KR20200003132 A KR 20200003132A
- Authority
- KR
- South Korea
- Prior art keywords
- query
- generation model
- processors
- trained
- response
- Prior art date
Links
- 238000000034 method Methods 0.000 claims abstract description 125
- 230000004044 response Effects 0.000 claims description 179
- 238000012549 training Methods 0.000 claims description 121
- 238000012986 modification Methods 0.000 claims description 57
- 230000004048 modification Effects 0.000 claims description 57
- 230000009466 transformation Effects 0.000 claims description 36
- 238000004891 communication Methods 0.000 claims description 12
- 230000015654 memory Effects 0.000 claims description 12
- 230000002787 reinforcement Effects 0.000 claims description 11
- 238000003062 neural network model Methods 0.000 claims description 7
- 238000013519 translation Methods 0.000 claims description 7
- 230000003993 interaction Effects 0.000 claims description 6
- 238000013528 artificial neural network Methods 0.000 claims description 5
- 238000002372 labelling Methods 0.000 claims description 3
- 238000004590 computer program Methods 0.000 claims 1
- 230000009471 action Effects 0.000 description 14
- 238000010586 diagram Methods 0.000 description 8
- 230000006870 function Effects 0.000 description 8
- 238000012545 processing Methods 0.000 description 7
- 229920002803 thermoplastic polyurethane Polymers 0.000 description 7
- 230000002123 temporal effect Effects 0.000 description 6
- 241000282326 Felis catus Species 0.000 description 3
- 238000013459 approach Methods 0.000 description 3
- 238000005516 engineering process Methods 0.000 description 3
- 230000006399 behavior Effects 0.000 description 2
- 230000007246 mechanism Effects 0.000 description 2
- 230000002093 peripheral effect Effects 0.000 description 2
- 230000000644 propagated effect Effects 0.000 description 2
- 238000000844 transformation Methods 0.000 description 2
- 230000000007 visual effect Effects 0.000 description 2
- 241000288105 Grus Species 0.000 description 1
- OAICVXFJPJFONN-UHFFFAOYSA-N Phosphorus Chemical group [P] OAICVXFJPJFONN-UHFFFAOYSA-N 0.000 description 1
- 230000008859 change Effects 0.000 description 1
- 238000007596 consolidation process Methods 0.000 description 1
- 238000010411 cooking Methods 0.000 description 1
- 230000000694 effects Effects 0.000 description 1
- 238000013549 information retrieval technique Methods 0.000 description 1
- 239000004973 liquid crystal related substance Substances 0.000 description 1
- 230000007787 long-term memory Effects 0.000 description 1
- 238000005259 measurement Methods 0.000 description 1
- 230000001537 neural effect Effects 0.000 description 1
- 230000003287 optical effect Effects 0.000 description 1
- 229910052698 phosphorus Inorganic materials 0.000 description 1
- 239000011574 phosphorus Substances 0.000 description 1
- 230000008439 repair process Effects 0.000 description 1
- 230000001850 reproductive effect Effects 0.000 description 1
- 238000000926 separation method Methods 0.000 description 1
- 238000012546 transfer Methods 0.000 description 1
- 238000011144 upstream manufacturing Methods 0.000 description 1
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/33—Querying
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/33—Querying
- G06F16/3331—Query processing
- G06F16/3332—Query translation
- G06F16/3338—Query expansion
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/24—Querying
- G06F16/242—Query formulation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/044—Recurrent networks, e.g. Hopfield networks
- G06N3/0442—Recurrent networks, e.g. Hopfield networks characterised by memory or gating, e.g. long short-term memory [LSTM] or gated recurrent units [GRU]
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/047—Probabilistic or stochastic networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/0475—Generative networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/044—Recurrent networks, e.g. Hopfield networks
Abstract
제출된 질의에 대한 질의 변형들을 생성하는 것과 관련된 시스템들, 방법들 및 컴퓨터 판독 가능 매체가 개시된다. 많은 구현들에서, 질의 변형들은 생성 모델을 이용하여 생성된다. 생성 모델은 생성된 모델에 대한 질의의 토큰들의 적용에 기초하고 선택적으로 생성 모델에 추가 입력 피처들의 적용에 기초하여 질의의 변형을 능동적으로 생성하는데 이용될 수 있다는 점에서 생산적이다.Systems, methods, and computer readable media related to generating query variants for a submitted query are disclosed. In many implementations, query variants are generated using a generation model. The generation model is productive in that it can be used to actively generate variations of the query based on the application of tokens of the query to the generated model and optionally based on the application of additional input features to the generation model.
Description
본 발명은 훈련된 생성 모델을 사용하여 질의 변형들을 생성하는 것에 관한 것이다.The present invention is directed to generating query variants using a trained generation model.
검색 질의들의 규칙 기반 다시 쓰기들은 검색 시스템들의 질의 처리 컴포넌트들에 사용되었다. 예를 들어, 일부의 규칙 기반 다시 쓰기들은 "the", "a" 등과 같은 특정 중지 단어를 쿼리에서 제거하여 질의의 다시 쓰기를 생성할 수 있다. 이후 다시 쓰여진 질의는 검색 시스템에 제출될 수 있고 그리고 다시 쓰여진 질의에 응답하는 검색 결과들이 리턴될 수 있다. Rule-based rewrites of search queries have been used in query processing components of search systems. For example, some rule-based rewrites can generate a rewrite of a query by removing certain stop words from the query, such as "the", "a", and so on. The rewritten query can then be submitted to the search system and the search results responsive to the rewritten query can be returned.
또한, 유사한 질의들의 모음들은, 예를 들어, 제출된 질의와 관련된 추가 질의들(예를 들어, "사람들은 또한 X를 검색한다")를 추천하기 위해 검색 시스템에서 이용되었다. 주어진 질의와 유사한 질의들은 종종 탐색 클러스터링에 의해 결정된다. 예를 들어, 질의 "재미있는 고양이 사진들"에 대해,"자막들이 있는 재미있는 고양이 사진들"의 유사한 질의는 "재미있는 고양이 사진들"을 제출한 후 사용자들이 자주 제출하는 유사한 질의에 기초하여 결정될 수 있다. 따라서, 특정 질의에 대한 유사한 질의들은 종종 미리정의된다. In addition, collections of similar queries have been used in the search system to recommend additional queries (eg, "people also search for X") associated with the submitted query, for example. Queries similar to a given query are often determined by search clustering. For example, for the query "funny cat pictures", a similar query of "funny cat pictures with subtitles" may be determined based on similar queries that users frequently submit after submitting "funny cat pictures". . Thus, similar queries for a particular query are often predefined.
본 명세서의 구현들은 제출된 질의에 대한 질의 변형들을 생성하는 것과 관련된 시스템들, 방법들 및 컴퓨터 판독 가능 매체에 관한 것이다. 많은 구현들에서, 질의 변형들은 훈련된 생성 모델을 이용하여 런타임에 생성된다. 생성 모델은 생성된 모델에 대한 질의의 토큰들의 적용에 기초하고, 그리고 선택적으로 생성 모델에 추가 입력 피처들의 적용에 기초하여 질의의 변형을 능동적으로 생성하는데 이용될 수 있다는 점에서 생산적이다. 이러한 방식으로, 생성 모델이 질의에 기초하여 훈련되지 않더라도, 생성 모델은 임의의 질의의 변형(들)을 생성하기 위해 이용될 수 있다. 따라서, 생성 모델은 신규 질의들 및 소위 "꼬리(tail)" 질의 (즉, 제출 빈도 및/또는 제출 수량이 임계값 미만인 질의들)에 대한 변형들을 생성하는 데 이용될 수 있다. 결과적으로, 풍부한 질의 입력으로 관련 결과들을 보다 효율적으로 식별할 수 있으므로 질의들을 보다 효과적으로 처리할 수 있다. 예를 들어, 낮은 제출 빈도 및/또는 제출 수량으로 인해 질의들이 단순히 제외되지 않는다. 초기 질의가 관련 결과들을 생성하지 않는 경우 사용자가 수정된 질의를 다시 제출할 필요가 없기 때문에 관련 결과를 얻을 수 있는 속도에 개선된 효율이 존재할 수 있다. 개시된 구현들은 복수의 질의 변형들이 자동적으로 테스트될 수 있게 한다. 변형들을 생성하는데 사용되는 모델의 훈련을 통해 결과들의 수렴 또한 보장될 수 있고, 따라서 다수의 질의들을 동시에 처리하는 것이 아니라 대상 질의 변형 생성을 통해 효율성이 향상된다. 개시된 방법들을 구현하는 프로세서들의 처리 전력 및 전력 소비를 포함하여 질의 처리에 필요한 기술 리소스들의 사용은, 따라서, 본 발명의 구현들을 통해 최적화된다. Implementations herein relate to systems, methods, and computer readable media related to generating query variants for a submitted query. In many implementations, query variants are generated at run time using a trained generation model. The generation model is productive in that it can be used to actively generate variations of the query based on the application of tokens of the query to the generated model, and optionally based on the application of additional input features to the generation model. In this way, even if the generation model is not trained based on the query, the generation model can be used to generate variant (s) of any query. Thus, the generation model can be used to generate new queries and variants for so-called "tail" queries (ie, queries whose submission frequency and / or submission quantity are below a threshold). As a result, rich query input makes it possible to more efficiently identify relevant results, thus making queries more efficient. For example, queries are not simply excluded due to low submission frequency and / or submission quantity. If the initial query does not produce relevant results, there may be an improved efficiency in the speed at which the relevant results can be obtained since the user does not have to resubmit the modified query. The disclosed implementations allow multiple query variants to be tested automatically. Convergence of the results can also be ensured through the training of the model used to generate the variations, thus improving efficiency through the generation of target query variants rather than processing multiple queries simultaneously. The use of technical resources required for query processing, including processing power and power consumption of processors implementing the disclosed methods, is therefore optimized through implementations of the present invention.
일부 구현들에서, 생성 모델은 하나 이상의 "메모리 계층"을 갖는 신경망 모델과 같은 신경망 모델이다. 메모리 계층은 긴 단기 메모리("LSTM") 유닛 및/또는 게이트형 반복 유닛("GRU")과 같은 하나 이상의 반복 신경망(RNN) 유닛을 포함한다.In some implementations, the generation model is a neural network model, such as a neural network model with one or more "memory hierarchies". The memory hierarchy includes one or more repeating neural network (RNN) units, such as long term memory (“LSTM”) units and / or gated repeat units (“GRUs”).
생성 모델이 메모리 계층들을 갖는 신경망 모델인 일부 구현들에서, 생성 모델은 시퀀스 대 시퀀스 모델이다. 예를 들어, 시퀀스 대 시퀀스 모델은, 질의의 토큰들이 (예를 들어, 토큰 대 토큰 기반으로 또는 결합 기반으로) 모델에 입력으로 적용될 수 있고, 그리고 토큰들의 인코딩이 네트워크의 계층들에 걸쳐 생성될 수 있다. 또한, 생성된 인코딩은 네트워크의 추가 계층들을 통해 디코딩될 수 있으며, 결과적인 디코딩은 질의의 변형을 (직접 또는 간접적으로) 지시한다. 예를 들어, 결과적인 디코딩은 질의의 변형을 생성하기 위해 네트워크의 소프트맥스 계층(들)에 적용될 수 있다. 이러한 구현들의 일부 버전들에서는, 생성 모델은 시퀀스 대 시퀀스 신경 기계 번역 모델과 동일한 또는 유사한 구조를 가지며, 질의 변형 특정 훈련 데이터를 이용하여 훈련된다. 검색어 변형 특정 훈련 데이터는, 예를 들어, 동일한 문서들에 "클릭"들을 각각 갖는 질의 쌍들(예를 들어, 동등한 질의 변형 생성을 위해 훈련하는 것); 연속적으로 제출된 질의 쌍들(예를 들어, 후속 질의 변형 생성을 위해 훈련하는 것); 및/또는 원래의 표준 질의 쌍들(예를 들어, 표준 질의 변형 생성을 위해 훈련하는 것)에 기초할 수 있다. 이러한 모델은 번역 훈련 데이터를 기반으로 선택적으로 사전 훈련될 수 있다.In some implementations where the generation model is a neural network model with memory layers, the generation model is a sequence-to-sequence model. For example, a sequence-to-sequence model may allow the tokens of a query to be applied as input to the model (eg, token-to-token-based or combination-based), and encoding of tokens may be generated across the layers of the network. Can be. In addition, the generated encoding can be decoded through additional layers of the network, with the resulting decoding indicating (directly or indirectly) modification of the query. For example, the resulting decoding can be applied to the softmax layer (s) of the network to generate a modification of the query. In some versions of these implementations, the generation model has the same or similar structure as the sequence-to-sequence neural machine translation model and is trained using query variant specific training data. The query variant specific training data may be, for example, query pairs each having "clicks" in the same documents (eg, training for generating equivalent query variants); Consecutively submitted query pairs (eg, training to generate subsequent query variants); And / or original standard query pairs (eg, training to generate standard query variants). Such a model can be optionally pre-trained based on translation training data.
일부 구현들에서, 생성 모델은, 다중 유형들의 질의 변형들 중 임의의 하나의 질의 변형을 생성할 수 있도록 훈련된다는 점에서, "다중 태스크" 모델로서 훈련된다. 이러한 구현들 중 일부에서, 생성 모델의 특정 패스에 대해 생성될 질의 변형의 유형은 특정 패스에서 모델에 적용된 유형 값 입력에 기초하여 표시될 수 있다. 질의 변형들의 유형들은, 예를 들어, 등가 질의, 후속 질의, 일반화 질의, 정규화 질의, 언어 번역 질의, 연루 질의, 사양 질의, 및/또는 설명 질의(즉, 사용자에게 출력을 제공하여 설명을 촉구하는 질의)를 포함할 수 있다. 더 크거나 작은 세분성을 포함하여 추가 및/또는 대체 유형이 정의될 수 있다. 생식 모델의 훈련에서, 다양한 유형들의 훈련 데이터를 활용할 수 있고, 여기서 훈련 데이터의 각 인스턴스는, 그 인스턴스에 대한 질의 변형의 유형을 나타내고 그리고 훈련 동안 훈련 인스턴스 입력으로서 이용될 수 있는 유형 값 입력을 포함한다. 이러한 구현들 중 일부에서, 이러한 방식으로 멀티 태스킹 모델을 훈련시키는 것은, 다양한 유형들의 훈련 데이터에 걸쳐 정보 공유를 이용할 수 있으며, 이는 훈련된 멀티 태스킹 모델의 보다 강력한 성능으로 이어질 수 있다.In some implementations, the generation model is trained as a “multitask” model in that it is trained to produce a query variant of any one of multiple types of query variants. In some of these implementations, the type of query variant to be generated for a particular pass of the generation model may be indicated based on the type value input applied to the model in that particular pass. Types of query variants are, for example, an equivalent query, subsequent query, generalized query, normalized query, language translation query, implicit query, specification query, and / or explanatory query (i.e., providing output to the user to prompt explanation). Query). Additional and / or alternative types may be defined, including greater or smaller granularity. In the training of the reproductive model, various types of training data can be utilized, where each instance of the training data includes a type value input that indicates the type of query variant for that instance and can be used as a training instance input during training. do. In some of these implementations, training a multitasking model in this manner can utilize information sharing across various types of training data, which can lead to more powerful performance of the trained multitasking model.
일단 훈련되면, 멀티태스크 모델은, (예를 들어, 입력으로서 제1 유형 값을 적용하는 것에 기초하여) 제1 패스에서의 질의에 대해 제1 유형의 변형을 생성하고, 그리고 (예를 들어, 입력으로서 제2 유형 값을 적용하는 것에 기초하여) 제2 패스에서의 질의에 대해 제2 유형의 변형을 생성하기 위해 사용될 수 있다. 추가 패스들에서 추가 유형들의 추가 변형들이 생성될 수 있다. 여기에서 서술된 바와 같이, 멀티 태스킹 모델을 이용하여 생성된 추가 패스들의 양은 질의마다 다를 수 있다. 예를 들어, 추가 패스들의 양은, 예를 들어, 패스(들)에서 생성된 변형(들) 및/또는 그러한 변형(들)에 대한 응답(들)에 기초하여 애드혹 방식으로 제어될 수 있다. 또한, 후속 패스는 이전 패스에서 생성된 이전 변형과 동일한 타입의 변형을 생성할 수 있다. 이러한 상황들 중 일부에서, 본 명세서에 기술된 바와 같이, 후속 패스는 이전 변형(예를 들어, 이전 변형 자체 및/또는 이전 변형에 대한 응답(들)) 및/또는 다른 이전 변형들에 기초한 정보를 이용할 수 있고, 이는 후속 패스의 변형이 이전 변형과 상이할 수 있다.Once trained, the multitask model generates a first type of variation for the query in the first pass (eg, based on applying the first type value as input), and (eg, Based on applying the second type value as input) may be used to generate a second type of variation for the query in the second pass. Further types of further variants may be created in further passes. As described herein, the amount of additional passes generated using the multitasking model may vary from query to query. For example, the amount of additional passes may be controlled in an ad hoc manner, for example, based on the deformation (s) generated in the path (s) and / or response (s) to such modification (s). In addition, subsequent passes may produce variations of the same type as previous variants created in previous passes. In some of these situations, as described herein, the subsequent pass may be based on previous modifications (eg, the previous variation itself and / or response (s) to the previous variation) and / or other previous variations. Can be used, where the deformation of the subsequent pass can be different than the previous deformation.
일부 구현들에서, 원래 질의의 다수의 변형들이 생성 모델을 이용하여 생성되고, 다수의 변형들 각각은 검색 시스템에 제출되고, 그리고 대응하는 응답(들)은 다수의 변형들 각각에 대해 수신된다. 출력은 하나 이상의 응답에 기초하여 생성될 수 있고, 그리고 상기 출력은 원래의 질의에 응답하여 제공된다. 예를 들어, 출력에는 "최상의" 응답(예를 들어, 검색 시스템에서 제공한 응답 점수들로 표시됨), 다수의 "최상의" 응답들 및/또는 변형 및 대응하는 응답(들)(예를 들어, 변형이 후속 유형인 경우)을 포함할 수 있다. 이러한 방식 및 다른 방식으로, 원래 질의의 변형(들)에 대한 응답(들)은 원래 질의에 응답하여 출력을 제공하기 위해 이용될 수 있고, 출력은 원래 질의에 직접 답변한다. 또한, 원래 질의의 변형(들)에 대한 응답(들)은 원래 질의에 대한 응답(들) 및/또는 다른 변형(들)에 대한 응답(들)을 입증/확증하는데 이용될 수 있다. 예를 들어, 원래 질의에 대한 "답변"의 정확성은 원래 질의의 변형들에 대해 긍정적인 답변들이 제공되는지에 따라 결정될 수 있다. 예를 들어, 원래 질의에 대한 "답변"의 정확성은, 후속 유형의 변형(들)에 대해 다른 긍정적인 답변들이 제공되는지에 따라 그리고/또는 긍정적인 유사한 답변들(원래 질의 답변과 유사)이 동등, 일반화 및/또는 언어 번역 유형(들)의 변형들에 대해 이용가능한지에 따라 결정될 수 있다. 이러한 방식 및 다른 방식으로, 입증되지 않은/보증되지 않은 응답(들)은 제공된 출력에서 결정되어 이용되지 않을 수 있고 그리고/또는 제공된 출력에서 사용될 경우(예를 들어, "잠재적으로 가짜"로 표시됨) 확증되지 않은 것으로 플래그될 수 있다.In some implementations, multiple variants of the original query are generated using a generation model, each of the multiple variants is submitted to a search system, and the corresponding response (s) are received for each of the multiple variants. The output can be generated based on one or more responses, and the output is provided in response to the original query. For example, the output may include a "best" response (eg, indicated by response scores provided by a search system), a number of "best" responses and / or variations and corresponding response (s) (eg, If the variant is of a subsequent type). In this and other ways, the response (s) for the modification (s) of the original query can be used to provide an output in response to the original query, which output directly answers the original query. In addition, the response (s) to the modification (s) of the original query may be used to verify / confirm the response (s) to the original query and / or the response (s) to other modification (s). For example, the accuracy of the "answer" to the original query may be determined depending on whether positive answers are provided for variations of the original query. For example, the accuracy of the "answer" to the original query is equivalent, depending on whether other positive answers are provided for subsequent types of variation (s) and / or positive similar answers (similar to the original query answer). , Generalization and / or language translation type (s) may be determined according to availability. In this and other ways, the unproven / unguaranteed response (s) may be determined and not used at the provided output and / or used when provided at the provided output (eg, marked "potentially fake"). Can be flagged as unconfirmed.
일부 구현들 및/또는 상황들에서, 다수의 응답들이 변형에 응답하여 검색 시스템에 의해 리턴된다. 일부 다른 구현들 및/또는 상황들에서, 검색 시스템은 변형에 응답하여 단일 응답을 제공한다. 이러한 구현들 중 일부에서, 단일 응답은 "답변" (예를 들어, 검색 시스템이 간주한 응답은 변형에 대한 답변임)을 포함하거나 또는 답변이 알려지지 않았다는 표시를 포함한다. 다른 구현들에서, 답변이 알려지지 않았다는 표시는 검색 시스템에 의한 응답의 부족일 수 있다. 검색 시스템은 다수의 도메인들에 걸쳐 동작하거나, 또는 하나 이상의 특정 도메인(예를 들어, 온라인 쇼핑 도메인)에 특화된 검색 시스템일 수 있다. 검색 시스템에서 리턴된 응답은, 예를 들어, 검색 결과(예를 들어, 문서로부터의 콘텐츠 스니펫 및 문서로의 링크), 답변(예를 들어, 검색 시스템에 의해 정식 답변으로 간주되는 콘텐츠), 이미지, 비디오 또는 지식 그래프 엔티티, "널" 응답(예를 들어, "답변 없음" 응답)일 수 있다. 일부 상황들에서, 생성된 변형은 추가로 또는 대안적으로 설명을 촉구하기 위해 사용자에게 (원래 질의를 제출한) 출력으로 제공될 수 있으며, 그리고 촉구에 응답하여 사용자에 의해 제공된 사용자 인터페이스 입력을 명확화하는 것은 변형에 대한 "응답"으로서 이용될 수 있다. 이러한 사용자 제공 응답은 추가 변형 생성에 영향을 주기 위해 이용될 수 있다. 예를 들어, 이러한 사용자 제공 응답은 변형을 생성하는 추가 반복에서 생성 모델로 전달되는 콘텍스트 벡터를 생성하는데 이용될 수 있다.In some implementations and / or situations, multiple responses are returned by the search system in response to the modification. In some other implementations and / or situations, the search system provides a single response in response to the modification. In some of these implementations, the single response includes an “answer” (eg, the response considered by the search system is the answer to the variant) or an indication that the answer is unknown. In other implementations, an indication that the answer is unknown can be a lack of a response by the search system. The search system may be a search system that operates across multiple domains or is specialized for one or more specific domains (eg, an online shopping domain). The response returned from the search system may include, for example, search results (e.g., content snippets from the document and links to the document), answers (e.g., content deemed a formal answer by the search system), It can be an image, video or knowledge graph entity, a "null" response (eg, a "no answer" response). In some situations, the generated variant may additionally or alternatively be provided to the user as an output (submitted to the original query) to prompt the explanation, and clarify the user interface input provided by the user in response to the prompt. Can be used as a "response" to the transformation. This user-provided response can be used to influence the generation of further variations. For example, such user-provided response can be used to generate a context vector that is passed to the generation model in further iterations of generating the transformation.
일부 구현들에서, 다수의 생성 모델들이 생성될 수 있고, 각각의 생성 모델들은 고유한 사용자들의 그룹의 과거 질의 제출에 기초한 훈련 데이터에 기초하여 훈련된다. 예를 들어, 제1 생성 모델은 속성들 A 및 B를 갖는 사용자들의 과거 질의 제출들에 기초한 훈련 데이터에 기초하여 생성될 수 있다. 속성들 B 및 C를 갖는 사용자들의 과거 질의 제출들에 기초한 훈련 데이터에 기초하여 제2 생성 모델이 생성될 수 있다. 속성들 B와 C(A는 아님)를 가진 사용자의 제출된 질의의 경우, 사용자 속성들 B 및 C가 제2 생성 모델을 훈련 시키는데 사용된 것과 일치하기 때문에, 제2 생성 모델은 사용자에 대한 변형들을 생성할 때 (제1 생성 모델을 선택하지 않고) 사용하기 위해 선택될 수 있다. 이러한 방식으로, 선택된 생성 모델이 사용자의 속성들에 맞춰지도록 복수의 이용 가능한 생성 모델들로부터 생성 모델이 선택될 수 있다. 이로 인해, 선택된 생성 모델을 사용하여 사용자에게 더 적합한 질의 변형들이 생성될 수 있다. 예를 들어, 프리랜서 작가와 비교하여 과학 연구원에 대해 매우 상이한 변형들이 생성될 수 있다.In some implementations, multiple generation models can be generated, each generation model being trained based on training data based on past query submission of a group of unique users. For example, the first generation model may be generated based on training data based on past query submissions of users with attributes A and B. A second generation model may be generated based on training data based on past query submissions of users with attributes B and C. For a user's submitted query with attributes B and C (but not A), the second generation model is transformed to the user because user attributes B and C match those used to train the second generation model. Can be selected for use in generating them (without selecting the first generation model). In this way, a generation model can be selected from a plurality of available generation models so that the selected generation model is tailored to the user's attributes. As a result, query variants more suitable to the user may be generated using the selected generation model. For example, very different variations can be created for a scientific researcher compared to a freelance writer.
일부 구현들에서, 여러 생성 모델들이 생성될 수 있고, 각 생성 모델은 사용자의 특정 속성들, 특정 시간 속성들 및/또는 다른 속성들과 같은 특정 속성들과 관련된 과거 질의 제출들에 기초한 훈련 데이터에 기반하여 훈련된다. 예를 들어, 제1 생성 모델은 온라인 쇼핑 태스크와 관련된 과거 질의 제출들에 기초한 훈련 데이터에 기초하여 생성될 수 있다. 예를 들어, 과거 질의 제출들은, 온라인 쇼핑 검색 시스템에 제출된 것을 기초로, 제출된 것들과 관련하여 쇼핑 컨텐츠(예를 들어, 특정 광고들)를 선택하는 사용자들을 기초로, 쇼핑 중심인 검색 결과들에 기초로, 제출 이후의 거래를 완료한 사용자들을 기초로 식별될 수 있다. 제2 생성 모델은 상이한 특정 속성들과 관련된 과거 질의 제출들에 기초한 훈련 데이터에 기초하여 생성될 수 있다. 예를 들어, 제2 생성 모델은 위치 태스크(예를 들어, 임의의 위치, 임의의 레스토랑 위치, 회의 위치 등)로의 여행과 관련된 과거 질의 제출들에 기초한 훈련 데이터에 기초하여 생성될 수 있다. 예를 들어, 과거 질의 제출들은 예정된 캘린더 엔트리에 일시적으로 근접하여 제출되는 것에 기초하여, 위치로의 여행 전 및/또는 여행 중에 제출된 것에 기초하여 식별될 수 있다. 사용자의 제출 된 질의에 대해, 사용자의 태스크가 예측될 수 있고, 제출된 질의에 대한 변형들을 생성하기 위해 선택된 예측된 태스크에 대응하는 생성 모델이 제공될 수 있다. 예를 들어, 사용자의 캘린더 엔트리 및/또는 전자 통신이 사용자가 위치로 여행 중이거나 곧 위치로 여행할 것임을 나타내는 경우, 앞의 예에서 제2 생성 모델은 위치 태스크로의 여행과 관련된 모델에 기초하여 선택될 수 있다. 이러한 방식으로, 생성된 모델은 복수의 이용 가능한 생성 모델들로부터 선택될 수 있어서, 선택된 생성 모델은 예측된 작업이 관여되거나 관여될 것과 같은 사용자의 태스크에 맞춰진다. 이로 인해, 선택된 생성 모델을 사용하여 사용자의 현재 태스크에 더 적합한 질의 변형들이 생성될 수 있다. 위에서 그리고 본 명세서의 다른 곳에서 설명된 바와 같이, 다양한 구현들에서, 생성 모델은 멀티태스킹 모델일 수 있고 다양한 이종 유형들의 질의 변형들을 생성할 수 있다. 이러한 다양한 구현들 중 일부는 생성 모델을 사용하여 사용자 질의를 확장하고 질의를 확장하는 다수의 경로들을 탐색할 수 있는 변형들을 생성할 수 있다. 이러한 변형들은 사용자가 질의를 확장하기 위한 다양한 경로들을 탐색할 수 있도록 사용자에게 제시하기 위해 (예를 들어, 선택적으로 그러한 변형들에 기초하여 먼저 질의를 발행하지 않고) 제공될 수 있다. 추가로 또는 대안적으로, 이러한 변형들에 대한 응답은 검색 시스템으로부터 얻어질 수 있고, 사용자가 질의에 대한 확장들에 대한 다양한 응답들을 탐색할 수 있도록 사용자에게 제시하기 위해 제공된 응답이다.In some implementations, several generation models can be generated, each generation model being based on training data based on past query submissions related to particular attributes, such as the user's specific attributes, specific temporal attributes, and / or other attributes. Trained on the basis of For example, the first generation model may be generated based on training data based on past query submissions related to the online shopping task. For example, past query submissions are shopping-centric search results based on users who select shopping content (eg, specific advertisements) with respect to those submitted based on submissions to an online shopping search system. Can be identified based on the users who completed the transaction after submission. The second generation model may be generated based on training data based on past query submissions associated with different specific attributes. For example, a second generation model may be generated based on training data based on past query submissions related to a trip to a location task (eg, any location, any restaurant location, meeting location, etc.). For example, past query submissions may be identified based on those submitted before and / or during the trip to the location, based on being submitted in proximity to the scheduled calendar entry. For a user's submitted query, the user's task can be predicted, and a generation model corresponding to the selected predicted task can be provided to generate variants for the submitted query. For example, if a user's calendar entry and / or electronic communication indicates that the user is traveling to or will soon be traveling to a location, the second generation model in the previous example is based on the model associated with the trip to the location task. Can be selected. In this way, the generated model can be selected from a plurality of available generation models, such that the selected generation model is tailored to the user's task such that the predicted task will or will be involved. This allows query variants that are more suitable for the user's current task using the selected generation model. As described above and elsewhere herein, in various implementations, the generation model may be a multitasking model and may generate various heterogeneous types of query variants. Some of these various implementations can use the generation model to generate variants that can expand the user query and explore multiple paths that extend the query. Such variations may be provided for presentation to the user (eg, optionally without first issuing a query based on those variations) to allow the user to explore various paths to expand the query. Additionally or alternatively, the response to these variations may be obtained from a search system and provided to present to the user so that the user may explore the various responses to extensions to the query.
본 명세서에 서술된 일부 구현들은 (예를 들어, 물리적 손상으로 인해) 질의들을 공식화하는데 어려움이 있을 수 있는 사용자들에 의해 제출된 질의들의 변형들을 생성하는데 이용될 수 있다. 예를 들어, 질의는 시선 안내(또는 다른 낮은 노력) 사용자 인터페이스 입력을 이용하는 사용자 및 본 명세서에 서술된 기술들에 따라 생성된 질의 변형들에 의해 공식화될 수 있다.Some implementations described herein can be used to generate variations of queries submitted by users that may have difficulty formulating queries (eg, due to physical damage). For example, a query can be formulated by a user using a gaze guidance (or other low effort) user interface input and query variants created in accordance with the techniques described herein.
본 명세서에 기술된 바와 같이, 생성 모델은 질의의 토큰들을 생성 모델에 적용하는 것에 기초하여 그리고 선택적으로 추가 입력 피처들을 생성 모델에 적용하는 것에 기초하여 질의의 변형을 능동적으로 생성하는데 이용될 수 있다. 이러한 구현들 중 일부에서, 추가 입력 피처들은 질의를 제출한 사용자와 연관된 속성들, 온도 속성들 및/또는 다른 피처들을 포함할 수 있다. 사용자와 연관된 속성들은, 예를 들어, 사용자의 위치(예를 들어, KY 루이스 빌; "레스토랑"; 남동부 미국), 사용자와 관련된 태스크(예를 들어, 요리, 자동차 수리, 여행 계획), 및/또는 사용자의 위치에서의 날씨를 포함할 수 있다. 사용자와 관련된 태스크는, 현재 사용자에 의해 관여되거나 사용자에 의해 관여될 태스크일 수 있다. 일부 구현들에서, 태스크는, 예를 들어, 사용자의 저장된 캘린더 엔트리, 사용자의 전자 통신(예를 들어, 채팅 메시지들 또는 사용자로 또는 사용자에 의해 전송된 다른 통신), 사용자에 의해 제출된 과거 질의들 등과 같은 다양한 신호들에 기초하여 예측된다. 시간 속성들은, 예를 들어, 현재 시간, 현재 요일 및/또는 현재 날짜를 포함할 수 있다. 이러한 방식으로, 생성 모델을 이용하는 질의 변형 생성은 생성 모델에 추가적인 입력 피처들의 적용에 기초하여 사용자 및/또는 현재 콘텍스트에 개인화될 수 있다.As described herein, a generation model may be used to actively generate variations of a query based on applying tokens of the query to the generation model and optionally based on applying additional input features to the generation model. . In some of these implementations, additional input features may include attributes, temperature attributes, and / or other features associated with the user who submitted the query. Attributes associated with a user may include, for example, the user's location (eg, KY Lewisville; "restaurant"; southeastern United States), tasks associated with the user (eg, cooking, car repairs, travel planning), and / Or weather at the user's location. The task associated with the user may be a task that will be engaged by the current user or by the user. In some implementations, the task may include, for example, the user's stored calendar entry, the user's electronic communication (eg, chat messages or other communication sent to or by the user), a past query submitted by the user. Prediction based on various signals such as Time attributes may include, for example, current time, current day of week, and / or current date. In this way, query variant generation using the generation model may be personalized to the user and / or current context based on the application of additional input features to the generation model.
일부 구현들에서, 생성 모델은 질의의 변형들, 및 하나 이상의 변형에 할당된 이러한 컨텐츠에 기초하여, 질의를 생성한 클라이언트 디바이스에 제공된 광고 또는 다른 컨텐츠를 생성하기 위해 이용될 수 있다. 이들 구현들 중 일부에서, 생성 모델에 의해 생성된 변형들은 본 명세서에 기술된 것과 같은 기술들을 이용하여 클라이언트 디바이스 및/또는 클라이언트 디바이스의 사용자에 맞춰질 수 있다. 예를 들어, 생성 모델은 사용자의 속성(들)에 기초하여 선택될 수 있고 그리고/또는 사용자와 연관된 속성들은 생성 모델에 대한 입력으로서 제공될 수 있고 그리고 변형들을 생성하는데 이용될 수 있다.In some implementations, the generation model can be used to generate advertisements or other content provided to the client device that generated the query, based on variations of the query and such content assigned to one or more variations. In some of these implementations, the variations generated by the generation model can be tailored to the client device and / or user of the client device using techniques such as those described herein. For example, the generation model may be selected based on the user's attribute (s) and / or the attributes associated with the user may be provided as input to the generation model and used to generate variations.
일부 구현들에서, 생성 모델은 다수의 시간 단계들 각각에서 원래 질의의 변형(및/또는 변형의 토큰)을 생성하는데 이용된다. 이러한 구현들 중 일부에서, 특정 시간 단계에서, 변형이 생성되는지 및/또는 어떤 변형이 생성되는지는 현재 상태 피처(들)에 기초할 수 있다. 현재 상태 피처(들)은, 예를 들어, 원래 질의에 대한 검색 시스템 응답(들); 이전 시간 단계(들)에서 생성된 원래 질의의 변형(들)에 대한 검색 시스템 응답(들); 이전 시간 단계(들)에서 생성된 원래 질의의 변형(들); 원래 질의의 변형(들)에 대한 사용자 응답(들)(예를 들어, 사용자에게 촉구로서 제공된 설명 변형); 및/또는 원래 질의에 기초한 피처들을 포함할 수 있다. 이러한 방식으로, 세션 동안 질의에 대한 변형의 생성은 세션 동안 이전에 생성된 질의의 변형(들), 이전에 생성된 변형(들)에 대한 응답(들) 및/또는 원래 질의에 기초하여 동적으로 영향을 받을 수 있다. 예를 들어, 일부 구현들에서, 이러한 현재 상태 피처들 중 하나 이상은, 추가 변형이 생성되어야 하는지를 결정하기 위해 이용될 수 있고, 대안으로, 추가 변형을 발생시키지 않고 원래의 질의에 대한 응답으로 이전 변형(들)(및/또는 원래의 질의)에 대한 응답(들)이 대신 제공되어야하는지 결정하기 위해 이용될 수 있다. 또한, 예를 들어, 일부 추가 또는 대안의 구현들에서, 이러한 현재 상태 피처들 중 하나 이상이 시간 단계에서 변형 생성에 영향을 주기 위해 생성 모델에 대한 입력으로서 (직접적으로 또는 간접적으로) 적용될 수 있다. 예를 들어, 현재 상태 피처들의 벡터 요약이 생성될 수 있고, 생성된 변형에 영향을 주기 위해 생성 모델에 대한 입력으로서 적용될 수 있다.In some implementations, the generation model is used to generate a variant (and / or token of a variant) of the original query in each of the plurality of time steps. In some of these implementations, at a particular time step, whether a variation is generated and / or which variation is generated may be based on the current state feature (s). The current state feature (s) can be, for example, search system response (s) for the original query; Search system response (s) for the modification (s) of the original query generated in the previous time step (s); Modification (s) of the original query generated in the previous time step (s); User response (s) to the modification (s) of the original query (eg, an explanatory variant provided as a prompt to the user); And / or features based on the original query. In this way, the generation of a variant for a query during the session is dynamically based on the variant (s) of the query previously generated during the session, the response (s) for the previously generated variant (s) and / or the original query. May be affected. For example, in some implementations, one or more of these current state features can be used to determine if additional variations should be generated, and, alternatively, transfer in response to the original query without generating additional variations. It may be used to determine if the response (s) to the variant (s) (and / or original query) should be provided instead. Further, for example, in some additional or alternative implementations, one or more of these current state features may be applied (directly or indirectly) as input to the generation model to affect the generation of deformations in a time step. . For example, a vector summary of the current state features can be generated and applied as input to the generation model to affect the generated transformation.
일부 구현들에서, 훈련된 제어 모델은, 복수의 시간 단계들 각각에서, 변형이 생성되는지를 결정하고 그리고/또는 시간 단계에서 변형 생성에 영향을 주기 위해 생성 모델에 입력으로서 제공될 피처들을 결정하기 위해 이용된다. 예를 들어, 훈련된 제어 모델은 피드포워드 신경망 모델 또는 반복 신경망(RNN) 모델일 수 있다. 현재 상태 피처들은 훈련된 제어 모델에 대한 입력으로 적용될 수 있고, 상기 모델을 통해, 추가 변형이 생성되는지 그리고/또는 변형 생성(추가적인 변형이 생성되는 경우)에 영향을 주기 위해 생성 모델에 제공될 피처(들)(예를 들어, 현재 상태 피처들 및/또는 보상 신호의 백터 요약)을 나타내는 값(들)을 생성할 수 있다. 이러한 방식으로, 제어 모델은 "비평가"로서 행동할 수 있고, 그리고 생성 모델은 행위자 비평 환경에서 "행위자"로서 작용한다. 따라서, 훈련된 제어 모델은 관찰된 현재 상태 피처(들)에 기초하여, 추가적인 변형들이 생성되는지 그리고/또는 그러한 생성에 영향을 미치는 피처(들)을 결정하는데 이용될 수 있다. 이러한 방식으로, 훈련된 제어 모델은 특정 질의에 대해 생성된 추가 변형들의 수량을 제어할 수 있다. 이러한 제어로 인해 생성된 변형들의 양이 질의마다 다를 수 있고, 예를 들어, 제어 모델은 주어진 질의에 대한 이전 반복들에서 생성된 변형(들) 및/또는 그러한 변형(들)에 대한 응답에 기초하여 특정 질의에 대한 변형 생성의 반복들의 양을 동적으로 결정하기 때문이다. 이러한 동적 제어는 종종 비교적 많은 양 (예를 들어, 5개 초과, 10개 초과, 또는 15개 초과)의 변형들이 생성되도록 하고 그리고/또는 이러한 변형들에 대한 상대적으로 많은 양의 반응이 고려되는 것으로 이해된다.In some implementations, the trained control model determines, in each of the plurality of time steps, whether a deformation is generated and / or to determine features to be provided as input to the generation model to influence the deformation generation in the time step. To be used. For example, the trained control model can be a feedforward neural network model or an iterative neural network (RNN) model. Current state features can be applied as input to a trained control model, through which the features to be provided to the generation model to affect whether additional deformations are generated and / or deformation generation (if additional deformations are generated). Generate value (s) indicative of the (s) (eg, a vector summary of current state features and / or compensation signal). In this way, the control model can act as a "criteria" and the generation model acts as an "acter" in the actor critique environment. Thus, a trained control model can be used to determine whether additional variations are generated and / or affect feature (s) affecting such generation based on the observed current state feature (s). In this way, the trained control model can control the quantity of additional variations created for a particular query. The amount of variants generated by this control may vary from query to query, for example, the control model is based on the variant (s) generated in previous iterations for a given query and / or the response to such variant (s). This is because it dynamically determines the amount of iterations of variant generation for a particular query. Such dynamic control often results in relatively large amounts (e.g., more than 5, more than 10, or more than 15) of modifications being generated and / or relatively large amounts of response to such variations being considered. I understand.
일부 구현들에서, 제어 모델 및/또는 생성 모델은 적어도 부분적으로 강화 학습에 기초하여 훈련될 수 있다. 이러한 구현들 중 일부에서 제어 모델과 생성 모델은 개별적으로 훈련되지만 서로 조합되어 훈련된다. 강화 학습에 기반한 제어 모델 및/또는 생성 모델을 훈련할 때, 생성된 변형들은 검색 시스템에 제출될 수 있고, 검색 시스템으로부터의 응답들(및 선택적으로 응답들이 없음)은 보상을 나타낼 수 있다. 예를 들어, 질의 변형에 대한 응답인 '답변' 응답에 대해, (예를 들어, "답변" 응답에 대해, 검색 시스템에 의해 제공되는 응답 스코어 의해 표시되는 바와 같이) 답변 응답의 품질에 비례하여 (또는 다른 방식으로) 보상이 할당될 수 있다. 일부 예들에서, 질의 변형에 대한 응답에서 어떤 응답도 제공되지 않고 그리고/또는 응답이 (예를 들어, 검색 시스템으로부터의 출력에 기초하여) "답변" 응답이 아닌 것으로 간주될 때, 어떤 보상도 할당되지 않을 것이다. 다시 말해, 마지막 "답변" 응답만이 보상될 것이고, 이러한 보상에 기초하여 중간 행동들이 업데이트된다(예를 들어, 몬테-카를로 Q 학습 방식). 이러한 방식으로, Q 기능 학습 또는 다른 강화 기능 학습은, 강화 학습 동안 상호 작용하는 검색 시스템에 의해 제공되는 응답들에 기초한 보상들에 기반하여 발생할 수 있다. 본원에 서술된 강화 학습의 구현들에서, 특정 시간 단계에서의 상태는 하나 이상의 상태 피처들(예를 들어, 전술한 것들)에 의해 표시되고, 그리고 행동은 질의 변형(즉, 추가 질의 변형을 생성)이거나 "답변" 응답을 제공할 수 있다. 행동 공간의 각 행동은 해당 질문 또는 "답변" 응답을 정의하는 스트링과 쌍을 이룰 수 있다.In some implementations, the control model and / or generation model can be trained based at least in part on reinforcement learning. In some of these implementations, the control and generation models are trained separately but in combination with each other. When training a control model and / or a generation model based on reinforcement learning, the generated modifications may be submitted to a search system, and responses from the search system (and optionally no responses) may represent a reward. For example, for a 'response' response that is a response to a query variant, relative to the quality of the response response (eg, as indicated by the response score provided by the search system for a "answer" response) Rewards may be assigned (or otherwise). In some examples, no reward is provided in response to a query variant and / or when no response is considered to be a "answer" response (eg, based on output from a search system), assign any reward Will not be. In other words, only the last "answer" response will be rewarded, and the intermediate actions are updated based on this reward (eg Monte-Carlo Q learning style). In this way, Q function learning or other reinforcement learning may occur based on rewards based on the responses provided by the search system interacting during the reinforcement learning. In implementations of reinforcement learning described herein, a state at a particular time step is represented by one or more state features (eg, those described above), and the behavior is a query variant (ie, creates additional query variants). ) Or provide a "answer" response. Each action in the action space can be paired with a string that defines the corresponding question or "answer" response.
일부 구현들에서, 클라이언트 디바이스를 통한 사용자의 사용자 인터페이스 입력에 기초하여 생성된 원래 질의를 수신하는 단계를 포함하는 하나 이상의 프로세서에 의해 구현되는 방법이 제공된다. 방법은 훈련된 생성 모델에 대한 입력으로서, 원래 질의의 토큰들, 및 사용자와 관련된 하나 이상의 속성을 적용하는 단계를 더 포함한다. 훈련된 생성 모델은 하나 이상의 메모리 계층을 갖는 시퀀스 대 시퀀스 심층 신경망 모델이다. 이 방법은 토큰들의 적용 및 훈련된 생성 모델에 대한 하나 이상의 속성에 기초하여 원래 질의의 적어도 하나의 변형을 생성하는 단계를 더 포함한다. 이 방법은 적어도 하나의 변형, 및 적어도 하나의 변형에 대한 적어도 하나의 검색 시스템 응답 중 적어도 하나에 기초하여 출력을 생성하는 단계를 더 포함한다. 방법은 원래의 질의에 응답하여 클라이언트 디바이스를 통해 표현하기 위해 출력을 제공하는 단계를 더 포함한다.In some implementations, a method is provided that is implemented by one or more processors that includes receiving an original query generated based on a user interface input of a user through a client device. The method further includes applying as inputs to the trained generation model, tokens of the original query, and one or more attributes associated with the user. The trained generation model is a sequence-to-sequence deep neural network model with one or more memory layers. The method further includes generating at least one variant of the original query based on the application of the tokens and one or more attributes for the trained generation model. The method further includes generating an output based on at least one of at least one variant and at least one search system response to the at least one variant. The method further includes providing an output for presentation via the client device in response to the original query.
일부 구현들에서, 하나 이상의 프로세서에 의해 구현되는 방법은, 원래 질의를 수신하는 단계; 훈련된 생성 모델에 입력으로서 원래 질의의 토큰들을 적용하는 단계; 및 상기 훈련된 생성 모델에 대한 원래 질의의 토큰들의 적용에 기초하여 원래 질의의 다수의 변형들을 생성하는 단계를 포함한다. 원래 질의는 클라이언트 디바이스를 통한 사용자의 사용자 인터페이스 입력에 기초하여 생성될 수 있다. 생성 된 변형들 각각은 원래 질의와 상이하며 그리고 변형들을 생성하는 것은 훈련된 생성 모델의 학습된 파라미터들을 기반으로 변형들을 생성하는 것을 포함한다. 훈련된 생성 모델은 여러 유형들의 쿼리 변형들을 생성할 수 있도록 훈련되고, 그리고 생성된 변형들은 질의 변형들의 다수의 유형들 중 제1 유형인 제1 변형 및 질의 변형들의 다수의 유형들 중 제2 유형인 제2 변형을 포함한다. 이 방법은: 다수의 변형들 중 적어도 하나 및/또는 다수의 변형들 중 적어도 하나에 대한 적어도 하나의 검색 시스템 응답에 기초하여 출력을 생성하는 단계; 및 상기 원래 질의에 응답하여, 상기 클라이언트 디바이스를 통해 표현을 위한 출력을 제공하는 단계를 포함한다. In some implementations, a method implemented by one or more processors can include receiving an original query; Applying tokens of the original query as input to the trained generation model; And generating a plurality of variations of the original query based on the application of tokens of the original query to the trained generation model. The original query may be generated based on the user interface input of the user through the client device. Each of the generated variants is different from the original query and creating the variants involves creating the variants based on the learned parameters of the trained generation model. The trained generation model is trained to produce several types of query variants, and the generated variants are the first of the many types of query variants and the second type of the many types of query variants A second variant that is phosphorus. The method comprises: generating an output based on at least one search system response for at least one of the plurality of variants and / or at least one of the plurality of variations; And in response to the original query, providing an output for presentation via the client device.
일부 구현들에서, 하나 이상의 프로세서에 의해 구현되는 방법은, 클라이언트 디바이스 통한 사용자의 사용자 인터페이스 입력에 기초하여 생성된 원래 질의를 수신하는 단계를 포함한다. 이 방법은, 사용자와 공통인 하나 이상의 속성을 갖는 사용자들의 그룹의 과거 질의 제출들에 기초하여 훈련되는 상기 훈련된 생성 모델에 기초하여, 복수의 훈련된 생성 모델들로부터 훈련된 생성 모델을 선택하는 단계를 더 포함한다. 이 방법은, 선택된 훈련된 생성 모델에 입력으로서 원래 질의의 토큰들을 적용하는 단계; 훈련된 생성 모델에 원래 질의의 토큰들의 적용에 기초하여 원래 질의의 적어도 하나의 변형을 생성하는 단계; 및 적어도 하나의 변형 및/또는 적어도 하나의 변형에 대한 적어도 하나의 검색 시스템 응답에 기초하여 출력을 생성하는 단계를 더 포함한다. 이 방법은 원래의 질의에 응답하여 클라이언트 디바이스를 통해 표현하기 위한 출력을 제공하는 단계를 더 포함한다.In some implementations, a method implemented by one or more processors includes receiving an original query generated based on a user interface input of a user through a client device. The method selects a trained generation model from a plurality of trained generation models based on the trained generation model trained based on past query submissions of a group of users with one or more attributes in common with the user. It further comprises a step. The method includes applying tokens of the original query as input to the selected trained generation model; Generating at least one variant of the original query based on the application of tokens of the original query to the trained generation model; And generating an output based on at least one variant and / or at least one search system response for the at least one variant. The method further includes providing an output for presentation via the client device in response to the original query.
일부 구현들에서, 하나 이상의 프로세서에 의해 구현되는 방법은, 원래 질의를 수신하는 단계; 훈련된 생성 모델에 입력으로서 원래 질의의 토큰들을 적용하는 단계; 및 입력에 기초하여 훈련된 생성 모델에 대한 원래 질의의 변형을 생성하는 단계를 포함한다. 원래 질의는 클라이언트 디바이스를 통한 사용자의 사용자 인터페이스 입력에 기초하여 생성될 수 있다. 훈련된 생성 모델에 걸쳐 생성된 변형은, 원래의 질의와 상이하고, 그리고 질의의 변형을 생성하는 것은 훈련된 생성 모델의 학습된 파라미터들에 기초하여 변형을 생성하는 것을 포함한다. 상기 방법은, 상기 질의의 변형을 검색 시스템에 제출하는 것에 기초하여 상기 질의의 변형에 대한 변형 응답을 결정하는 단계; 훈련된 생성 모델에 추가 입력을 적용하는 단계; 및 추가 입력에 기초하여 훈련된 생성 모델에 대한 원래 질의의 추가 변형을 생성하는 단계를 포함한다. 훈련된 생성 모델에 적용되는 추가 입력은 원래 질의의 토큰들 및 원래 질의의 변형의 변형 토큰들 중 적어도 하나를 포함한다. 생성된 추가 변형은, 변형 및 원래 질의와 상이하고, 원래 질의의 추가 변형을 생성하는 것은 훈련된 생성 모델의 학습된 파라미터들에 기초하여 추가 변형을 생성하는 것을 포함한다. 이 방법은 검색 시스템에 원래 질의의 추가 변형을 제출하는 것에 기초하여 원래 질의의 추가 변형에 대한 추가 변형 응답을 결정하는 단계를 더 포함한다. 이 방법은 변형 응답 및/또는 추가 변형 응답에 기초하여 출력을 생성하는 단계; 및 상기 원래 질의에 응답하여, 상기 클라이언트 디바이스를 통해 표현을 위한 출력을 제공하는 단계를 더 포함한다. In some implementations, a method implemented by one or more processors can include receiving an original query; Applying tokens of the original query as input to the trained generation model; And generating a variant of the original query for the trained generation model based on the input. The original query may be generated based on the user interface input of the user through the client device. Variations generated over a trained generation model are different from the original query, and generating a variant of the query includes generating a variant based on learned parameters of the trained generation model. The method includes determining a modification response to a modification of the query based on submitting a modification of the query to a search system; Applying additional input to the trained generation model; And generating further modifications of the original query to the trained generation model based on the further input. The additional input applied to the trained generation model includes at least one of tokens of the original query and variant tokens of the modification of the original query. The generated further variant is different from the variant and the original query, and generating further variant of the original query includes generating further variant based on the learned parameters of the trained generation model. The method further includes determining an additional modification response to the further modification of the original query based on submitting further modifications of the original query to the search system. The method includes generating an output based on a modification response and / or a further modification response; And in response to the original query, providing an output for presentation via the client device.
일부 구현들에서, 하나 이상의 프로세서에 의해 구현되는 방법은, 클라이언트 디바이스를 통해 사용자의 사용자 인터페이스 입력에 기초하여 생성된 원래 질의를 수신하는 단계를 포함한다. 이 방법은 사용자에 대한 예측된 태스크를 결정하는 단계; 및 훈련된 생성 모델에 대한 입력으로서, 원래 질의의 토큰들 및 사용자에 대한 예측된 태스크의 하나 이상의 태스크 속성을 적용하는 단계를 더 포함한다. 이 방법은 토큰들 및 하나 이상의 태스크 속성을 훈련된 생성 모델에 적용하는 것에 기초하여 원래 질의의 적어도 하나의 변형을 생성하는 단계를 더 포함한다. 이 방법은: 적어도 하나의 변형 및/또는 적어도 하나의 변형에 대한 적어도 하나의 검색 시스템 응답에 기초하여 출력을 생성하는 단계; 및 상기 원래 질의에 응답하여, 상기 클라이언트 디바이스를 통해 표현하기 위한 출력을 제공하는 단계를 포함한다. In some implementations, a method implemented by one or more processors includes receiving an original query generated based on a user interface input of a user via a client device. The method includes determining a predicted task for a user; And applying, as input to the trained generation model, one or more task attributes of the original task's tokens and the predicted task for the user. The method further includes generating at least one variant of the original query based on applying the tokens and one or more task attributes to the trained generation model. The method comprises: generating an output based on at least one variant and / or at least one search system response for at least one variant; And in response to the original query, providing an output for presentation via the client device.
하나 이상의 프로세서에 의해 구현되는 방법은, 클라이언트 디바이스를 통해 사용자의 사용자 인터페이스 입력에 기초하여 생성된 원래 질의를 수신하는 단계를 포함한다. 방법은 사용자에 대한 예측된 태스크를 결정하는 단계를 더 포함한다. 이 방법은 예측된 태스크와 관련된 과거 질의 제출들에 기초하여 훈련되는 훈련된 생성 모델에 기초하여, 복수의 훈련된 생성 모델들로부터 훈련된 생성 모델을 선택하는 단계를 더 포함한다. 이 방법은, 선택된 훈련된 생성 모델에 입력으로서 원래 질의의 토큰들을 적용하는 단계; 훈련된 생성 모델에 원래 질의의 토큰들의 적용에 기초하여 원래 질의의 적어도 하나의 변형을 생성하는 단계; 및 적어도 하나의 변형 및/또는 적어도 하나의 변형에 대한 적어도 하나의 검색 시스템 응답에 기초하여 출력을 생성하는 단계를 더 포함한다. 이 방법은 원래 질의에 응답하여 출력을 제공하는 단계를 더 포함한다.A method implemented by one or more processors includes receiving, via a client device, an original query generated based on a user interface input of a user. The method further includes determining a predicted task for the user. The method further includes selecting a trained generation model from the plurality of trained generation models based on the trained generation model trained based on past query submissions associated with the predicted task. The method includes applying tokens of the original query as input to the selected trained generation model; Generating at least one variant of the original query based on the application of tokens of the original query to the trained generation model; And generating an output based on at least one variant and / or at least one search system response for the at least one variant. The method further includes providing an output in response to the original query.
본 명세서에 개시된 다양한 구현들은 프로세서는, 본 명세서에 서술된 하나 이상의 방법과 같은 방법을 수행하기 위해 프로세서(예를 들어, 중앙 처리 장치(CPU), 그래픽 처리 장치(GPU) 및/또는 TPU(Tensor Processing Unit))에 의해 실행 가능한 명령어들을 저장하는 하나 이상의 비 일시적 컴퓨터 판독 가능 저장 매체를 포함할 수 있다. 또 다른 다양한 구현들은 본 명세서에 기술된 하나 이상의 방법과 같은 방법을 수행하기 위해 저장된 명령어들을 실행하도록 동작 가능한 하나 이상의 프로세서를 포함하는 하나 이상의 컴퓨터의 시스템을 포함할 수 있다.Various implementations disclosed herein may be embodied by a processor (eg, central processing unit (CPU), graphics processing unit (GPU), and / or TPU (Tensor) to perform a method such as one or more methods described herein. One or more non-transitory computer readable storage media storing instructions executable by the unit. Still other various implementations can include a system of one or more computers that include one or more processors operable to execute stored instructions to perform a method such as one or more methods described herein.
전술한 개념과 본 명세서에 더 상세히 설명된 추가 개념의 조합은 본 명세서에 개시된 주제의 일부인 것으로 고려됨을 이해해야 한다. 예를 들어, 본 발명의 끝에 나타나는 청구된 주제의 모든 조합들은 본 명세서에 개시된 주제의 일부인 것으로 고려된다.It is to be understood that the combination of the foregoing concepts and additional concepts described in more detail herein are considered to be part of the subject matter disclosed herein. For example, all combinations of claimed subject matter appearing at the end of the present invention are considered to be part of the subject matter disclosed herein.
도 1은 본 명세서에 개시된 구현들이 구현될 수 있는 예시적인 환경의 블록도이다.
도 2는 본 명세서에 개시된 구현들에 따라 생성 모델을 훈련시키는 예를 도시한다.
도 3은 질의의 하나 이상의 변형을 생성하기 위해 생성 모델을 이용하는 예를 도시한다.
도 4는 질의의 하나 이상의 변형을 생성하기 위해 생성 모델을 이용하는 다른 예를 도시하며, 제어 모델은 변형들의 생성을 제어하기 위해 이용된다.
도 5는 여기에 개시된 구현들에 따라 생성 모델을 훈련시키는 방법을 예시하는 흐름도이다.
도 6은 질의의 하나 이상의 변형을 생성하기 위해 생성 모델을 이용하는 방법을 나타내는 흐름도이다.
도 7은 생성의 모델을 이용하여 질의의 하나 이상의 변형을 생성하는 방법을 나타내는 흐름도이며, 제어 모델은 변형들의 생성을 제어하는데 이용된다.
도 8a 및 도 8b는 각각 여기에 개시된 구현들에 따라 생성된 변형(들)에 기초한 출력을 제공하기 위한 예시적인 그래픽 사용자 인터페이스를 도시한다.
도 9는 컴퓨팅 디바이스의 예시적인 아키텍처를 도시한다.1 is a block diagram of an example environment in which implementations disclosed herein may be implemented.
2 illustrates an example of training a generation model in accordance with implementations disclosed herein.
3 illustrates an example of using a generation model to generate one or more variations of a query.
4 shows another example of using a generation model to generate one or more variants of a query, wherein a control model is used to control the generation of variants.
5 is a flow diagram illustrating a method of training a generation model in accordance with implementations disclosed herein.
6 is a flow diagram illustrating a method of using a generation model to generate one or more variations of a query.
7 is a flow diagram illustrating a method of generating one or more variations of a query using a model of generation, wherein a control model is used to control the generation of variations.
8A and 8B each show an example graphical user interface for providing output based on variant (s) generated in accordance with implementations disclosed herein.
9 illustrates an example architecture of a computing device.
도 1은 여기에 개시된 구현들이 구현될 수 있는 예시적인 환경을 도시한다. 도 1의 예시적인 환경은 클라이언트 디바이스(106), 질의 시스템(110), 검색 시스템(140), 생성 모델 훈련 엔진(120) 및 훈련 인스턴스 엔진(122)을 포함한다. 이러한 시스템들 및 엔진들은 각각, 예를 들어, 통신 네트워크를 통해 통신하는 하나 이상의 컴퓨팅 디바이스들에서 구현될 수 있다. 통신 네트워크는 인터넷, 하나 이상의 인트라넷 및/또는 하나 이상의 버스 서브 시스템과 같은 WAN(Wide Area Network)을 포함할 수 있다. 통신 네트워크는 선택적으로 하나 이상의 표준 통신 기술, 프로토콜 및/또는 프로세스 간 통신 기술을 이용할 수 있다.1 illustrates an example environment in which implementations disclosed herein may be implemented. The example environment of FIG. 1 includes
질의 시스템(110), 검색 시스템(140), 생성 모델 훈련 엔진(120) 및 훈련 인스턴스 엔진(122)은 여기에 서술된 기술들이 구현될 수 있는 그리고/또는 여기에 서술된 시스템들, 컴포넌트들 및 기술들이 인터페이스할 수 있는 예시적인 컴포넌트들이다. 도 1의 하나 이상의 시스템들(110, 140) 및 엔진들(120, 122)에 의해 수행되는 동작들은 각각 여러 다수의 컴퓨터 시스템들에 걸쳐 분산될 수 있다. 일부 구현들에서, 시스템들(110, 140) 및 엔진들(120, 122)의 하나 이상의 양태들은 단일 시스템에서 결합될 수 있고 그리고/또는 하나 이상의 양태들은 클라이언트 디바이스(106)에서 구현될 수 있다. 예를 들어, 이들 구현들 중 일부에서, 질의 시스템 (110)의 양태들은 검색 시스템(140)의 양태들과 결합될 수 있다.The
클라이언트 디바이스(106)의 사용자는 클라이언트 디바이스(106)의 하나 이상의 사용자 인터페이스 입력 디바이스들을 통해 사용자 인터페이스 입력을 제공함으로써 클라이언트 디바이스(106)를 통한 질의를 공식화할 수 있다. 클라이언트 디바이스(106)는 질의를 질의 시스템(110)에 제출한다. 일부 상황들에서, 질의는 텍스트 형태이다. 다른 상황들에서, 질의는 오디오 및/또는 다른 형태로 제출될 수 있고, 질의 시스템(110)(또는 다른 컴포넌트)에 의해 텍스트 형태로 변환될 수 있다.A user of
수신된 질의에 대해, 질의 시스템(110)은 수신된 질의의 하나 이상의 변형을 생성하고, 그리고 출력이 클라이언트 디바이스(106)에 제공되게 하고, 출력은 하나 이상의 변형에 기초한다. 일부 구현들에서, 출력은 사용자에 의해 고려하기 위해 제안된 대안의 변형들로서 제공될 하나 이상의 변형을 포함한다. 일부 구현들에서, 출력은 검색 시스템(140)으로부터의 하나 이상의 응답에 기초한 콘텐츠를 추가로 또는 대안적으로 포함하며, 여기서 응답(들)은 하나 이상의 변형을 검색 시스템 (140)에 제출하는 것에 기초한다. 검색 시스템(140)은 하나 이상의 리소스(166)의 액세스에 기초하여 응답들을 결정할 수 있고, 전통적인 정보 검색 기술들과 같은 다양한 기술들을 이용할 수 있다. 응답(들)에 기초한 컨텐츠는, 예를 들어, 그래픽적인 그리고/또는 청취가능한 "답변들" 또는 응답에 기초한(예를 들어, 동일한) 다른 검색 결과일 수 있다. 응답(들)에 기초한 컨텐츠가 제공되는 경우, 질의 시스템(110)은 컨텐츠를 클라이언트 디바이스(106)에 직접 제공할 수 있거나, 또는 검색 시스템(140)이 컨텐츠를 클라이언트 디바이스(106)에 제공하도록 할 수 있다. 일부 구현들에서, 질의 시스템(110) 및 검색 시스템(140)은 선택적으로 동일한 당사자에 의해 제어되고 그리고/또는 서로 협력하여 동작할 수 있다. 하나 이상의 데이터베이스에서 생성된 변형에 할당된 광고와 같은 생성된 변형들을 기반으로 추가 및/또는 대체 출력이 제공될 수 있다.For the received query, the
도 1에서, 질의 시스템(110)은 변형 엔진(112) 및 제어기 엔진(114)을 포함한다. 일부 구현들에서, 변형 엔진(112) 및 제어기 엔진(114)의 하나 이상의 양상들은 클라이언트 디바이스(106)와 같은 질의 시스템(110)과 분리된 컴포넌트에서 결합 및/또는 구현될 수 있다. 일부 구현들에서, 제어기 엔진(114)은 생략될 수 있다.In FIG. 1,
변형 엔진(112)은 제출된 질의에 대한 하나 이상의 질의 변형을 생성하기 위해 하나 이상의 훈련된 생성 모델들(152)을 이용한다. 일부 구현들에서, 변형 엔진(112)은 훈련된 생성 모델들(152)을 통해 동작하는 하나 이상의 CPU, GPU 및/또는 TPU를 포함한다. 변형 엔진(112)은 생성 모델들(152) 중 하나에 입력으로서 질의의 토큰들을 적용하고, 그리고 입력에 기초하여 생성 모델에 대한 변형을 생성함으로써 제출된 질의에 대한 변형을 생성한다. 많은 구현들에서, 변형을 생성할 때, 변형 엔진(112)은 추가 입력 피처들을 생성 모델에 대한 입력으로서 추가로 적용하고 그리고 추가 입력 피처들에 기초하여 변형을 생성한다.
일부 구현들에서, 추가 입력 피처들은 질의를 제출한 사용자와 연관된 속성들, 시간적 속성들 및/또는 다른 피처들을 포함할 수 있다. 예를 들어, 원래 질의에 대한 변형을 생성할 때, 변형 엔진(112)은, 생성 모델들(152) 중 하나에 대한 입력으로서, 원래 질의의 토큰들, 질의를 제출한 사용자의 속성들(예를 들어, 사용자의 위치, 사용자가 참여한 작업) 및 시간적 속성들(예를 들어, 현재 요일, 현재 시간)을 적용할 수 있고, 그리고 적용된 입력을 기반으로 생성 모델에 대한 변형을 생성한다.In some implementations, additional input features can include attributes, temporal attributes, and / or other features associated with the user who submitted the query. For example, when generating a variation on the original query, the
일부 구현들에서, 원래 질의에 대한 변형을 생성하는 특정 반복에서 적용되는 추가 입력 피처들은, 부가적으로 또는 대안적으로, 이전 반복(들)에서 생성된 원래 질의의 변형(들) 및/또는 그러한 변형(들)에 대한 검색 시스템 응답(들)에 기초한 피처들을 포함한다. 예를 들어, 원래 질의에 대한 변형을 생성할 때, 변형 엔진(112)은 다수의 시간 단계들 각각에서 변형을 생성할 수 있다. 특정 시간 단계에서, 변형 엔진(112)은, 생성 모델들(152) 중 하나에 대한 입력으로서, 원래 질의에 대한 검색 시스템 응답(들); 이전 시간 단계(들)에서 생성된 원래 질의의 변형(들)에 대한 검색 시스템 응답(들); 이전 시간 단계(들)에서 생성된 원래 질의의 변형(들); 및/또는 원래 질의에 기초한 피처들을 적용할 수 있다. 이러한 방식으로, 특정 시간 단계의 변형 생성은 이전에 생성된 변형(들), 이전에 생성된 변형(들)에 대한 응답(들) 및/또는 원래 질의에 의해 영향을 받을 수 있다.In some implementations, additional input features that are applied in a particular iteration that produces a variation on the original query may, additionally or alternatively, modify (s) and / or the original query generated in the previous iteration (s). Include features based on the search system response (s) for the variation (s). For example, when generating a variation on the original query, the
일부 구현들에서, 원래 질의에 대한 변형을 생성하는 특정 반복에서 적용되는 추가 입력 피처들은 유형 값을 추가로 또는 대안적으로 포함할 수 있다. 예를 들어, 일부 구현들에서, 생성 모델들(152) 중 하나는 "멀티태스크(multitask)" 모델일 수 있고, 이는, 다중 유형들의 질의 변형들 중 어느 하나의 생성을 가능하게 하도록 훈련된다. 이들 구현들 중 일부에서, 변형 엔진(112)은, 생성 모델들(152) 중 하나에 입력으로서, 생성될 질의 변형의 유형을 나타내는 유형 값을 적용할 수 있다. 질의 변형들 유형들은, 예를 들어, 동등한 질의, 후속 질의, 일반화 질의, 정규화 질의, 언어 번역 질의 및/또는 함의 질의를 포함할 수 있다. 일부 구현들에서, 변형 엔진(112)은 변형을 생성하는 복수의 반복들 각각에서 상이한 유형 값을 선택함으로써 동일한 생성 모델을 이용하여 개별 유형들의 다수의 변형들을 생성한다.In some implementations, additional input features applied in a particular iteration that produces a variation on the original query can additionally or alternatively include a type value. For example, in some implementations, one of the
일부 구현들에서, 다수의 생성 모델들(152)은 변형 엔진(112)에 액세스가능하고, 그리고 변형 엔진(112)은 하나 이상의 파라미터에 기초하여 제출된 질의에 대한 변형(들)을 생성하기 위해 하나 이상의 다수의 생성 모델들(152)의 서브 세트를 선택한다. 예를 들어, 다수의 생성 모델들(152)이 제공될 수 있으며, 각각의 생성 모델은 고유한 사용자들의 그룹의 과거 질의 제출에 기초한 훈련 데이터에 기초하여 훈련된다. 예를 들어, 제1 생성 모델은 속성 A 및 B를 갖는 사용자들의 과거 질의 제출들에 기초한 훈련 데이터에 기초하여 생성될 수 있다. 제2 생성 모델은, 속성 B 및 C를 갖는 사용자들의 과거 질의 제출들에 기초한 훈련 데이터에 기초하여 생성될 수 있다. 속성 B와 C(A는 아님)를 가진 사용자의 제출된 질의의 경우, 변형 엔진(112)은, 사용자 속성 B 및 C가 제2 생성 모델을 훈련시키는 데 이용된 것과 일치하기 때문에, 그 질의에 대한 변형들을 생성함에 있어서(제1 생성 모델을 선택하지 않고) 제2 생성 모델을 선택할 수 있다.In some implementations,
생성 모델 훈련 엔진(120) 및 훈련 인스턴스 엔진(122)이 도 1에 또한 도시된다. 훈련 인스턴스 엔진(122)은 훈련 인스턴스를 생성하고 그리고 훈련 인스턴tm데이터베이스(164)에 훈련 인스턴스들을 저장한다. 예를 들어, 훈련 인스턴스 엔진(122)은, 다수의 사용자들의 과거 질의 제출들을 저장하는 제출된 질의 데이터베이스(162)에 기초하여 복수의 훈련 인스턴스들을 생성할 수 있다. 생성 모델 훈련 엔진(120)은, 데이터베이스(164)의 저장된 훈련 인스턴스들에 기초하여 생성 모델들(152)을 훈련시킨다. 여기에 서술된 것처럼, 일부 구현들에서, 하나 이상의 생성 모델들(152)은 선택적으로 훈련 인스턴스 데이터베이스(164)의 훈련 인스턴스들에 의존하지 않는 강화 학습 기술들을 이용하여 추가로 훈련될 수 있다. 엔진들(120, 122) 및 데이터베이스들(162 및 164)의 구현에 대한 추가 서술은 도 2와 관련된 서술에서 아래에 제공된다.The generation
제어기 엔진(114)은, 제공될 때, 변형 엔진(112)과 함께 작동하고, 변형 엔진(112)이 변형을 생성하는지를 제어하고; 그리고/또는 변형 생성에 영향을 주는 파라미터들을 생성하고 그리고 변형 엔진(112)에 제공한다. 제어기 엔진(114)은, 변형 엔진(112)이 변형을 생성하는지를 제어하는데 그리고/또는 변형 생성에 영향을 주는 파라미터들을 생성하는데 하나 이상의 훈련된 제어 모델들(154)을 선택적으로 이용한다. 일부 구현들에서, 변형 엔진(112)은 훈련된 제어 모델들(154)을 통해 동작하는 하나 이상의 CPU들, GPU들 및/또는 TPU들을 포함한다.The controller engine 114, when provided, operates in conjunction with the
일부 구현들에서, 제어기 엔진(114)은 제출된 질의에 대해, 제출된 질의에 대한 변형 엔진(112)에 의해 임의의 변형들이 생성될지를 결정한다. 예를 들어, 제어기 엔진(114)은 제출된 질의 자체에 기초하여 그리고/또는 제출된 질의에 대한 검색 시스템(140)으로부터의 응답(들)(있는 경우)에 기초하여 그와 같은 결정을 할 수 있다. 예를 들어, 제어기 엔진(114)은, 응답이 검색 시스템(140)에 의해 리턴되지 않거나 또는 리턴된 응답의 품질이 불충분한 경우(예를 들어, 검색 시스템이 스코어를 제공하여 임계 값을 만족시키지 못하는 경우)에만 변형들을 생성하도록 결정할 수 있다. 이러한 구현들 중 일부에서, 제어기 엔진(114)은 제출된 질의의 토큰들 및/또는 제어 모델들(154) 중 하나에 대한 제출된 질의에 응답(들)의 피처들을 적용하고, 그리고 변형들이 생성될지를 나타내는 제어 모델들(154)에 대한 출력을 생성한다. 일부 추가 또는 대안의 구현들에서, 제어기 엔진(114)은 제출된 질의의 토큰들 및/또는 응답(들)의 피처들을 제어 모델들(154) 중 하나에 적용하고, 그리고 변형을 생성할 때 (그 결과 변형 생성에 영향을 미침) 생성 모델에 대한 입력으로서 적용하기 위해 변형 엔진(112)에 제공되는 제어 모델들(154)에 대한 출력을 생성한다.In some implementations, the controller engine 114 determines, for a submitted query, whether any variations will be generated by the
여기에서 서술된 바와 같이, 일부 구현들에서, 변형 엔진(112)은 다수의 시간 단계들 각각에서 제출된 질의의 변형을 생성한다. 이러한 구현들 중 일부에서, 제어기 엔진(114)은 변형 생성이 중단되어야 하는 시기를 결정한다. 즉, 변형 엔진(112)이 특정 시간 단계에서 변형을 생성하는지는, 제어기 엔진(114)으로부터의 인증에 따라 결정될 수 있다. 또한, 제어기 엔진(114)은, 각각의 시간 단계마다, 시간 단계에서 변형 생성에 영향을 미치는 피처들을 제공할 수 있다. 변형 생성의 중단 여부를 결정할 때 그리고/또는 변형 생성에 영향을 주는 피처들을 생성할 때, 제어기 엔진(114)은 하나 이상의 제어 모델들(154) 중 적어도 하나를 이용할 수 있다. As described herein, in some implementations, the
일 예로서, 제어기 엔진(114)은, 제어 모델들(154) 중 하나에 대한 입력으로서, 원래 질의에 대한 검색 시스템 응답들; 이전 시간 단계(들)에서 변형 엔진(112)에 의해 생성된 원래 질의의 변형(들)에 대한 검색 시스템 응답(들); 이전 시간 단계(들)에서 변형 엔진에 의해 생성된 원래 질의의 변형(들); 및/또는 원래 질의에 기초한 피처들을 적용할 수 있다. 제어기 엔진(114)은 적용된 입력에 기초하여 제어 모델에 대한 출력을 생성할 수 있고, 그리고 출력을 이용하여 변형 엔진 (112)에게 추가 변형을 생성하도록 지시할지 아니면 변형 생성을 중단할지를 결정한다. 변형 생성이 중단되면, 제어기 엔진(114)은 제출된 질의에 대한 응답인 출력으로서 이전에 생성된 변형 및/또는 이전에 생성된 변형에 대한 응답을 대신 제공할 수 있다. 이러한 방식으로, 제어기 엔진(114)은 "평론자"로서 작용할 수 있고, 그리고 변형 엔진(112)은 행위자-비평적 환경에서 "행위자"로서 작용할 수 있다. 제어기 엔진(114), 제어 모델(들)(154) 중 하나, 및 제어기 엔진(114)과 변형 엔진 (112)과의 상호 작용들의 구현에 대한 추가 서술은 도 4와 관련하여 아래에서 서술된다.As one example, the controller engine 114 may include, as input to one of the
도 2를 참조하면, 생성 모델들(152) 중 생성 모델(152A)을 훈련시키는 예가 도시되어 있다. 훈련 인스턴스(164A)는 훈련 인스턴스들 데이터베이스(164)로부터 검색된다. 훈련 인스턴스(164A)는, 예를 들어, 사용자에 의해 사전에 제출되고 그리고 제출된 질의 데이터베이스(162)(도 1)에 저장된 한 쌍의 질의들에 기초하여 훈련 인스턴스 엔진(122)(도 1)에 의해 생성될 수 있다. 일 예로서, 한 쌍의 질의들은, "로저 무어가 퍼세이더들에서 애스턴 마틴을 몰았는가"라는 사용자의 초기 질의 및 "로저 무어가 퍼세이더들에서 어떤 차를 몰았는가"(이 질의는 초기 질의에 대해 동등한 유형임)라는 사용자의 후속 질의(즉, 초기 질의 직후)를 포함할 수 있다. 다른 예로서, 한 쌍의 질의들은, "레오나르도 다빈치가 모나리자를 그렸는가"라는 사용자의 초기 질의 및 "누가 레오나르도 다빈치에게 모나리자를 그려달라고 의뢰했는가"라는 사용자의 후속 질의(초기 질의에 관련된 후속 유형)을 포함할 수 있다.Referring to FIG. 2, an example of training the generation model 152A among the
훈련 인스턴스(164A)는 질의(예를 들어, 한 쌍의 초기에 제출된 질의), 속성들 및 유형을 포함하는 훈련 인스턴스 입력을 포함한다. 속성들은, 예를 들어, 질의를 제출한 사용자의 속성, 질의의 시간적 속성들(예를 들어, 제출 요일), 질의에 대한 검색 시스템 응답(들)의 피처들을 포함할 수 있다. 유형은 훈련 인스턴스 출력에 포함된 변형 유형을 나타내는 유형 값일 수 있다. 일부 구현들에서, 유형은 인간 라벨링에 의해 할당될 수 있거나 또는 훈련 인스턴스(164A)를 생성하기 위해이용된 질의 쌍의 특성들에 기초하여(예를 들어, 질의 쌍의 질의들의 제출의 시간적 분리의 크기, 질의 쌍의 질의들에 대한 검색 시스템 응답들의 비교에 기초하여), 훈련 인스턴스 엔진(122)에 의해 추론될 수 있다. 훈련 인스턴스(164A)는 또한 변형(예를 들어, 상기 한 쌍의 제출된 시간 후)을 포함하는 훈련 인스턴스 출력을 포함한다.
생성 모델 훈련 엔진(120)은 훈련 인스턴스의 훈련 인스턴스 입력을 생성 모델(152A)에 대한 입력으로서 적용한다. 생성 모델 훈련 엔진(120)은 생성 모델(152A)의 적용된 입력 및 현재 학습된 파라미터에 기초하여 생성 모델(152A)에 대한 출력을 추가로 생성한다. 생성 모델 훈련 엔진(120)은 또한 생성된 출력과 훈련 인스턴스(164A)의 훈련 인스턴스 출력의 비교에 기초하여 기울기를 더 생성하고, 그리고 기울기에 기초하여 생성 모델(152A)을 업데이트한다(예를 들어, 전체 생성 모델(152A)에 대한 기울기를 역전파한다).The generation
적용된 입력에 기초하여 출력을 생성할 때, 생성 모델 훈련 엔진(120)은 입력의 전부 또는 일부를 생성 모델(152A)의 인코더 계층들(153A)에 적용할 수 있고 그리고 인코더 계층들(153A)에 대한 인코딩을 생성할 수 있다. 예를 들어, 입력의 원래 질의의 토큰들이 인코더 계층들(153A)에 적용될 수 있다. 엔진(120)은, 추가로, 생성 모델(152A)의 디코더 계층들(154A)에 인코딩을 적용할 수 있고 그리고 디코더 계층들(154A)에 대한 인코딩의 디코딩을 생성할 수 있다. 이후, 엔진(120)은 생성된 인코딩을 소프트맥스 계층들(155A)에 적용할 수 있고 그리고 생성된 인코딩의 적용에 기초하여 소프트맥스 계층들(155A)을 통해 출력을 생성할 수 있다. 일부 구현들에서, 엔진(120)은 입력의 속성들 및/또는 유형을 다른 층들에 적용하고 그리고/또는 "측면 입력"으로서 인코더 층들(153A), 디코더 층들(154A) 및/또는 소프트맥스 층들(155A) 중 하나에 적용한다. 이러한 구현들 중 일부에서, 엔진(120)은 속성들 및/또는 유형을 인코더 층들(153A)의 다운스트림에 있지만, 디코더 층들(154A)의 업스트림에 있는 다른 층들에 적용한다.When generating an output based on the applied input, the generation
도 2는 단일 훈련 인스턴스(164A) 만을 도시하지만, 많은 추가 훈련 인스턴스들이 훈련 생성 모델(152A)에서 이용될 것으로 이해된다. 일부 구현들에서, 단일 훈련 인스턴스(164A) 및 추가 훈련 인스턴스들은 생성 모델(152A)이 특정 속성들에 구체적으로 적응되기 위해 트레이닝되도록 선택되는 것이 주목된다. 예를 들어, 생성 모델(152A)은 특정 속성(들)을 갖는 사용자들의 과거 제출들에 기초하여 생성되는 훈련 인스턴스들 만을 선택하여 (또는 훈련 인스턴스들을 향해 편향하여) 훈련될 수 있다. 예를 들어, 훈련 인스턴스들의 훈련 인스턴스 입력들에 명시적으로 포함된 사용자들의 속성들이 그러한 선택에 이용될 수 있다. 또한, 예를 들어, 생성 모델(152A)은 특정 작업 속성들과 관련된 훈련 인스턴스들 만을 선택하여 (또는 훈련 인스턴스들을 향해 편향하여) 훈련될 수 있다. 예를 들어, 선택은 참여된 (또는 참여될) 특정 작업(들)과 관련하여 제출된 질의들에 편향될 수 있다. 일부 구현들에서, 생성 모델(152A)은 훈련 인스턴스 입력에서 복수의 상이한 "유형들(types)"을 포함하는 훈련 인스턴스들을 이용하여 훈련된다는 것이 또한 주목된다. 본 명세서에 기술된 바와 같이, 이것은, 다중 이종 유형들의 변형을 생성할 수 있고, 그리고 런타임에서, 대응하는 유형 값을 입력으로서 적용함으로써 특정 유형을 향해 편향될 수 있는 멀티 태스크 모델의 생성을 가능하게 한다.2 shows only a
도 3은 질의의 하나 이상의 변형을 생성하기 위해 생성 모델을 이용하는 예를 도시한다. 도 3에서, 사용자의 원래 질의 및 속성들은 클라이언트 디바이스(106)로부터 변형 엔진(112)으로 전송된다. 일부 다른 구현들에서, 속성들 중 하나 이상(예를 들어, 모두)은 질의와 함께 클라이언트 디바이스(106)에 의해 전송되지 않을 수 있거나, 심지어 클라이언트 디바이스(106)에 의해 전혀 전송되지 않을 수 있다. 예를 들어, 사용자의 속성들은 클라이언트 디바이스로부터 원격으로 저장될 수 있다. 예를 들어, 속성들은, 원격으로 저장될 수 있고 그리고 (예를 들어, 다른 클라이언트 디바이스들을 통해) 사용자의 과거 상호 작용들에 기초될 수 있으며, 그리고 원격 저장 장치로부터 변형 엔진(112)에 의해 액세스될 수 있다.3 illustrates an example of using a generation model to generate one or more variations of a query. In FIG. 3, the user's original queries and attributes are sent from the
변형 엔진(112)은 원래 질의의 하나 이상의 변형을 생성하기 위해 생성 모델들(152) 중 적어도 하나를 이용한다. 변형(들)을 생성함에 있어서, 변형 엔진(112)은 생성 모델들(152) 중 하나를 선택하는데 속성들을 이용할 수 있고 그리고/또는 생성 모델들 중 하나에 대한 입력으로서 하나 이상의 속성을 적용할 수 있다. 변형 엔진(112)은 원래 질의의 토큰들을 생성 모델 및/또는 다른 피처들(예를 들어, 다수의 변형들이 반복적인 방식으로 생성되는 과거에 생성된 변형들)에 추가로 적용할 수 있다.The
일부 구현들에서, 변형 엔진(112)은 원래 질의에 기초하여 제공될 출력으로서 변형들을 클라이언트 디바이스(106)에 전송한다. 일부 구현들에서, 변형 엔진(112)은 부가적으로 또는 대안적으로 하나 이상의 변형을 검색 시스템(140)(이 검색 시스템(140)은 변형(들)에 대한 하나 이상의 응답(들)(예를 들어, 단일 답변 검색 결과 또는 여러 검색 결과들)을 결정함)에 제공하고, 그리고 원래 질의에 기초하여 제공될 출력으로서 응답을 클라이언트 장치에 전송한다.In some implementations, the
도 4는 질의의 하나 이상의 변형을 생성하기 위해 생성 모델을 이용하는 다른 예를 도시한다. 특히, 도 4는 변형들의 생성을 제어하기 위해 제어 모델이 사용되는 일례를 도시한다.4 illustrates another example of using a generation model to generate one or more variations of a query. In particular, FIG. 4 shows an example in which a control model is used to control the generation of variants.
도 4에서, 사용자의 원래 질의 및 속성들이 클라이언트 디바이스(106)로부터 제어기 엔진(114)으로 전송된다. 도 3에서와 같이, 다른 구현들에서는, 하나 이상의 속성들(예를 들어, 속성들 전부)은 질의와 함께 클라이언트 디바이스(106)에 의해 전송되지 않을 수 있거나, 또는 심지어 클라이언트 디바이스(106)에 의해 전혀 전송되지 않을 수 있다.In FIG. 4, the user's original queries and attributes are sent from the
일부 구현들에서, 제어기 엔진(114)은 원래 질의의 변형을 생성할지 결정하기 위해 하나 이상의 제어 모델(154)을 이용한다. 예를 들어, 제어기 엔진(114)은, 변형을 생성할지를 결정하기 위해 원래 질의의 토큰들, 원래 질의에 대한 검색 시스템 응답(들) 및/또는 사용자의 속성들을 제어 모델들(154) 중 하나에 적용할 수 있다. 일부 다른 구현들에서, 제어기 엔진(114)은 기본적으로 적어도 하나의 변형 또는 원래의 질의가 생성되어야 한다고 결정할 수 있다.In some implementations, the controller engine 114 uses one or
제어기 엔진(114)은 하나 이상의 제어 모델(154)을 통한 출력에 기초하여 결정된 보상 신호를 변형 엔진(112)에 제공하고, 또한 현재 상태를 제공한다. 현재 상태는, 예를 들어, 원래 질의, 사용자의 속성들, 및/또는 하나 또는 둘 모두에 기초한 특징 벡터를 포함할 수 있으며, 여기서, 특징 벡터는 하나 이상의 제어 모델 (154)을 통한 출력에 기초한다.The controller engine 114 provides the
변형 엔진은 적어도 하나의 생성 모델(152)을 이용하여 원래 질의의 하나 이상의 변형을 생성한다. 변형(들)을 생성함에 있어서, 변형 엔진(112)은 제공된 상태 및 선택적으로 보상 신호를 이용할 수 있다. 예를 들어, 변형 엔진(112)은 질의 변형을 생성할 때 보상을 결정하기 위해 보상 신호를 학습된 보상 기능에 적용할 수 있다. 변형 엔진(112)은 변형(들)을 검색 시스템(140)에 제공한다. 이에 응답하여, 검색 시스템(140)은 하나 이상의 응답(들)을 생성하고 그리고 응답(들)을 제어기 엔진(114)에 제공한다.The transformation engine uses at least one
제어기 엔진(114)은 지금까지 생성된 변형(들) 및/또는 그들의 대응하는 응답(들)을 이용하여 추가 변형들이 변형 엔진(112)에 의해 생성되어야 하는지 여부를 결정한다. 예를 들어, 제어기 엔진(114)은, 지금까지 생성된 변형(들) 및/또는 대응하는 응답(들)의 피처들의 토큰들을 제어 모델들(154) 중 하나에 입력으로서 적용할 수 있고, 상기 입력을 기반으로 제어 모델을 통해 출력을 생성할 수 있고, 그리고 추가 변형들을 생성하는지를 결정하기 위해 출력을 이용할 수 있다. 일부 구현들에서, 제어기 엔진(114)은 입력의 일부로서, 원래 질의의 토큰들, 원래 질의에 대한 검색 시스템 응답(들), 및/또는 사용자의 속성들에 추가로 적용한다.The controller engine 114 uses the variant (s) created so far and / or their corresponding response (s) to determine whether further variants should be generated by the
추가 변형들이 생성되어야 한다고 제어기 엔진(114)이 결정하면, 업데이트된 보상 신호 및 업데이트된 현재 상태(예를 들어, 지금까지 생성된 변형(들) 및/또는 대응하는 변형 응답(들)에 기초하여 업데이트됨)를 제공할 수 있다. 변형 엔진(112)은 하나 이상의 추가 변형들을 생성할 수 있고, 변형(들)을 검색 시스템 (140)에 제공할 수 있고, 대응하는 응답(들)을 다시 제공할 수 있다. 제어기 엔진(114)은 추가 변형(들) 및 대응하는 응답(들)에 기초하여, 추가 변수들이 생성되어야 하는지를 다시 결정할 수 있다.If the controller engine 114 determines that additional variants should be generated, based on the updated compensation signal and the updated current state (eg, the variant (s) generated so far and / or the corresponding variant response (s)). Updated). The
주어진 반복에서, 제어기 엔진(114)이 추가 변형들이 생성되지 않아야 한다고 결정하면, 제어기 엔진(114)은 원래의 질의에 기초하여 제공될 출력으로서 하나 이상의 검색 시스템 응답(들) 및/또는 하나 이상의 생성된 변형을 클라이언트 장치 (106)에 전송한다. 예를 들어, 제어기 엔진(114)은 모든 제공된 응답(들)을 저장하고, 응답(들) 중 하나만을 응답성 출력(예를 들어, 최고 품질 응답 또는 다른 응답들에 의해 확인된 최고 품질 응답)으로서 제공할 수 있다. 다른 예로서, 제어기 엔진(114)은 다수의 응답들(예를 들어, N개의 최고의 응답, 응답들의 다양한 세트)을 제공할 수 있다.At a given iteration, if the controller engine 114 determines that no additional variations should be generated, the controller engine 114 generates one or more search system response (s) and / or one or more outputs as output to be provided based on the original query. The modified variant to the
일부 구현들에서, 제어 모델(들)(154), 생성 모델(들)(152), 제어기 엔진(114) 및/또는 변형 엔진(112)은 강화 학습을 이용하여 훈련될 수 있다. 이러한 구현들 중 일부에서, 제어 모델(들)(154) 및/또는 생성 모델(들)(152)은 다른 기술들을 이용하여 초기에 훈련될 수 있고, 강화 학습을 통해 개선될 수 있다. 예를 들어, 생성 모델(들)(152)은 도 2와 관련하여 서술된 바와 같이 초기에 훈련될 수 있고, 그리고 강화 학습을 통해 더 훈련될 수 있다. In some implementations, control model (s) 154, generation model (s) 152, controller engine 114, and / or
이러한 구현들 중 일부에서, 제어기 엔진(114) 및 제어 모델(들)(154)은 행위자-비평가 알고리즘에서 "비평가"로 볼 수 있고, 그리고 변형 엔진(112) 및 생성 모델(들)(152)은 "행위자"로 볼 수 있다. 일반적으로, 행위자는 변형들을 생성하고, 그리고 변형들을 사용하여 환경을 조사한다. 환경은, 예를 들어, 검색 시스템(140)일 수 있다. 일반적으로, 비평가는 환경에서 오는 증거(예를 들어, 답변 스트링들 또는 해당 순위 목록들 같은 응답들)를 축적하여, 전체 행동들/결정들 d를 생성하고, 전체 상태들을 유지하며, 그리고 행위자에 보상 신호 r 및 콘텍스트 c를 제공한다.In some of these implementations, controller engine 114 and control model (s) 154 may be viewed as “critical” in the actor-critical algorithm, and
행위자 및 비평가의 행동은 두 가지 상이한 시간 스케일들에서 강화에 의해 추진될 수 있다. 행위자는 더 미세한 시간 스케일(t'로 색인)로 실행할 수 있다. 각 단계에서 행위자는 컨텍스트에 따라 다음 변형을 생성한다. 비평가는 환경에서 전체 상태들로 증거를 축적한다. 일부 상황들에서, 어떤 상황에서, 상태는 최소한 원래의 질의, 생성된 변형들 및 관찰들(예를 들어, 생성된 변형들에 대한 검색 시스템 응답)과 네트워크를 공급하는 데 사용되는 벡터 요약 h를 포함하며, s=({qt,ot}1..T,ht). 전체 상태를 감안할 때, 비평가는 각 단계마다 전체 결정을 내린다. 즉, 응답을 내거나, 변형 생성 및 더 많은 증거의 축적 사이클을 계속한다. 비평가는 또한 변형 생성 및 보상 신호를 조정하기 위해 행위자에 컨텍스트를 제공한다. 비평가는 상태-행동 쌍 "Q- 함수" Q(st, dt)의 값을 직접 모델링한다. Q 함수의 이 값은 보상 신호로 행위자에 전달된다. Q 함수는 응답(들)(예를 들어, 원래 질의에 대한 응답(들)) 및 결정들 d의 시퀀스에 정의된 전체 보상을 사용하여 훈련된다. 시간 스케일들을 분리하면 변형 생성과 전체 의사 결정의 두 가지 작업들을 개별적으로 모델링할 수 있지만 엔드 투 엔드 성능을 최적화하기 위해 결합하여 교육할 수 있다.The actions of the actor and the critic can be driven by consolidation on two different time scales. An actor can run on a finer time scale (indexed by t '). At each stage, the actor creates the next variant, depending on the context. Critics accumulate evidence as a whole state in the environment. In some situations, in some situations, the state may contain at least the original query, generated variants, and observations (eg, a retrieval system response to the generated variants) and a vector summary h used to supply the network. S = ({q t , o t } 1..T , h t ). Given the overall condition, the critic makes a full decision at each stage. That is, to respond or continue the cycle of generating strain and more evidence. The critic also provides context to the actor to coordinate the variant generation and compensation signals. The critic directly models the value of the state-behavior pair "Q-function" Q (s t , d t ). This value of the Q function is passed to the actor as a reward signal. The Q function is trained using the response (s) (eg, response (s) to the original query) and the overall compensation defined in the sequence of decisions d. By separating the time scales, you can separately model the two tasks of creating transformations and making overall decisions, but you can combine and train them to optimize end-to-end performance.
변형 생성 및 더 많은 증거의 주기를 계속하는 대신 비평가가 응답을 했을 때 최종 상태에 도달된다. 행위자의 행동 공간은, A := {(a, <w>) : a ∈ {질문, 답변}, <w> ∈ 스트링들}로서 정의될 수 있고, 여기서, a는 변형을 사용하여 환경을 조사하거나 또는 응답할 수 있다. 행동은 변형 또는 답변(응답)을 정의하는 스트링 <w>와 쌍을 이룬다. 일부 구현들에서, "변형으로 환경을 조사" 행동들을 보상을 받지 않으며, 그리고 "응답 행동들의 방출"은 답변의 품질에 비례하여 보상을 받는다. 비평가는 행동들 (a, <w>)을 현재 상태에서 예상 리턴 E [Gs]로 매핑하는 Q 함수를 학습할 수 있다. "응답 행동들의 방출"만 보상되는 경우, 예상 리턴은 Instead of continuing to generate variants and cycles of more evidence, the final state is reached when the critic responds. The actor's space of action can be defined as A: = {(a, <w>): a ∈ {question, answer}, <w> ∈ strings}, where a uses a variant to examine the environment Can respond or respond. An action is paired with a string <w> that defines a variant or an answer. In some implementations, the “investigate the environment with deformation” actions are not compensated, and the “release of response actions” is rewarded in proportion to the quality of the answer. The critic can learn a Q function that maps actions (a, <w>) from the current state to the expected return E [Gs]. If only "release of response actions" is compensated, the expected return is
Q 함수 훈련은 몬테-카를로 Q-러닝 접근법을 사용하여 달성될 수 있다. 변형들은 최종 보상이 도달될 때까지 샘플링될 수 있고, 보상이 결정될 수 있으며, 그리고 Q 함수의 모든 중간 예측들은 Q function training can be accomplished using the Monte-Carlo Q-learning approach. The variants can be sampled until the final compensation is reached, the compensation can be determined, and all intermediate predictions of the Q function
이제 도 5를 참조하면, 여기에 개시된 다양한 구현들에 따라 생성 모델을 훈련시키는 방법(500)을 나타내는 흐름도가 제공된다. 편의상, 흐름도의 동작들은 동작들을 수행하는 시스템을 참조하여 서술된다. 이러한 시스템은 하나 이상의 프로세서(예를 들어, CPU(들), GPU(들) 및/또는 TPU(들))와 같은 하나 이상의 컴퍼넌트들을 포함할 수 있다. 방법(500)의 동작이 특정 순서로 도시되어 있지만, 이는 제한적인 것은 아니다. 하나 이상의 동작은 재정렬, 생략 또는 추가될 수 있다.Referring now to FIG. 5, a flow diagram illustrating a
블록 552에서, 시스템은 훈련 인스턴스들의 그룹을 선택한다. 예를 들어, 생성 모델이 방법(500)에서 멀티태스크 모델이 되도록 훈련될 때, 시스템은 그룹이 다수 유형들의 변형 생성을 나타내는 훈련 인스턴스들을 포함하도록 그룹을 선택할 수 있다. 또한, 예를 들어, 생성 모델이 추가로 또는 대안적으로 특정 사용자들 그룹(들)에 특화되도록 훈련되는 경우, 시스템은, 훈련 시스턴스들이 특정 그룹(들)을 준수하는 사용자들에 의한 질의들의 과거 제출들을 기반으로 하는 훈련 인스턴스들 만을 포함하거나 또는 상기 훈련 인스턴스들의 상당량(예를 들어, 절반 초과, 70% 초과)을 포함하도록 그룹을 선택할 수 있다. 또한, 예를 들어, 생성 모델이 추가로 또는 대안적으로 특정 태스크(들)에 특화되도록 훈련되는 경우, 시스템은 트레이닝 인스턴스들이 특정 태스크(들)과 관련하여 질의들의 과거 제출들을 기초로하는 훈련 인스턴스들 만을 포함하거나 또는 상기 훈련 인스턴스들의 상당량(예를 들어, 전반 초과, 70% 초과)을 포함하도록 그룹을 선택할 수 있다.At block 552, the system selects a group of training instances. For example, when a generation model is trained to be a multitasking model in
블록 554에서, 시스템은 그룹의 훈련 인스턴스를 선택한다.At block 554, the system selects a training instance of the group.
블록 556에서, 시스템은 생성 모델에 대한 입력으로서 훈련 인스턴스의 훈련 인스턴스 입력을 적용한다. 훈련 인스턴스 입력은, 예를 들어, 원래 질의의 용어들, 속성들(예를 들어, 원래 질의를 제출한 사용자의 속성들) 및 유형 값(원래 질의의 변형 유형을 나타냄)을 포함할 수 있다.At block 556, the system applies the training instance input of the training instance as input to the generation model. The training instance input may include, for example, terms of the original query, attributes (eg, attributes of the user who submitted the original query), and type value (indicating the variant type of the original query).
블록 558에서, 시스템은 적용된 훈련 인스턴스 입력에 기초하여 생성 모델에 대한 변형을 생성한다.At
블록 560에서, 시스템은 생성된 변형과 훈련 인스턴스 출력(즉, 훈련 인스턴스 출력에 표시된 변형)의 비교에 기초하여 훈련 인스턴스에 대한 에러를 결정한다.At block 560, the system determines an error for the training instance based on the comparison of the generated modification with the training instance output (ie, the variation indicated in the training instance output).
블록 562에서, 시스템은 에러에 기초하여 생성 모델을 업데이트한다. 예를 들어, 에러는 생성 모델을 업데이트하기 위해 생성 모델에 대해 역 전파되는 그라디언트일 수 있다.At block 562, the system updates the generation model based on the error. For example, the error may be a gradient that is propagated back to the generation model to update the generation model.
블록 564에서, 시스템은 그룹에 추가의 미처리 훈련 인스턴스들이 있는지를 결정한다. 그렇다면, 시스템은 블록 554으로 진행하여 추가 훈련 인스턴스를 선택한다. 이후, 시스템은 추가 훈련 인스턴스에 기초하여 블록들 556, 558, 560 및 562를 수행한다.At block 564, the system determines if there are additional raw training instances in the group. If so, the system proceeds to block 554 to select additional training instances. The system then performs
블록 564의 반복에서, 시스템이 그룹 내에 추가의 미처리 훈련 인스턴스들이 존재하지 않는다고 (또는 다른 훈련 기준이 충족되었다고) 결정하면, 시스템은 트레이닝이 종료되는 블록 566으로 진행한다.In an iteration of block 564, if the system determines that there are no further training instances in the group (or other training criteria have been met), the system proceeds to block 566 where the training ends.
도 5는 특정 비-뱃치(non-batch) 훈련 접근법을 도시하지만, 뱃치 훈련(예를 들어, 훈련 인스턴스들의 뱃치에 기초하여 에러가 결정되고 그리고 역전파되는 경우)이 훈련에서 추가로 또는 대안적으로 이용될 수 있는 것으로 이해된다. 또한, 다양한 구현들에서, 방법(500)에 기초하여 훈련된 생성 모델은 여기에 개시된 기술들에 따라 추가로 훈련될 수 있다는 것이 이해된다. 예를 들어, 생성 모델은 강화 학습 기술들을 사용하여 추가로 훈련될 수 있고, 그리고 별도의 제어 모델과는 별도로, 그러나 별도의 제어 모델과 함께 추가로 훈련될 수 있다. 또한, 다수의 생성 모델이 생성되는 경우, 블록 552에서 상이한 선택 기준으로 방법(500)이 반복되어 추가 모델(들)을 생성할 수 있다.5 illustrates a particular non-batch training approach, but batch training (eg when an error is determined and back propagated based on a batch of training instances) is additional or alternative in training. It is understood that it can be used as. In addition, it is understood that in various implementations, a generation model trained based on the
도 6을 참조하면, 여기에 개시된 다양한 구현들에 따라 생성 모델을 이용하여 질의의 하나 이상의 변형을 생성하는 방법(600)을 도시하는 흐름도가 제공된다. 편의상, 흐름도의 동작들은 동작들을 수행하는 시스템을 참조하여 서술된다. 이 시스템은 하나 이상의 프로세서(예를 들어, CPU(들), GPU(들) 및/또는 TPU(들))와 같은 하나 이상의 컴포넌트를 포함할 수 있다. 방법(600)의 동작들이 특정 순서로 도시되어 있지만, 이것은 제한적이지 않다. 하나 이상의 동작이 재정렬, 생략 또는 추가될 수 있다.Referring to FIG. 6, a flow diagram illustrating a
블록 652에서, 시스템은 질의를 수신한다.At block 652, the system receives a query.
블록 654에서, 시스템은 복수의 후보 생성 모델들로부터 생성 모델을 선택한다. 일부 구현들에서, 시스템은 블록 652의 질의를 제출한 사용자의 하나 이상의 속성에 기초하여 생성 모델을 선택한다. 예를 들어, 시스템은 사용자의 하나 이상의 속성과 일치하는 속성과 관련하여 저장되는 모델에 기초하여 생성 모델을 선택할 수 있다. 예를 들어, 해당 속성들을 가진 사용자들의 과거 질의 제출들을 기초로하는 훈련 인스턴스들을 기초로 훈련된 것을 기반으로 하여 이러한 속성들과 관련하여 저장할 수 있다. 일부 구현들에서, 블록 654은 생략될 수 있다(예를 들어, 단일 생성 모델 만이 이용될 수 있다).At block 654, the system selects a generation model from the plurality of candidate generation models. In some implementations, the system selects a generation model based on one or more attributes of the user who submitted the query of block 652. For example, the system may select a generation model based on a model stored in association with an attribute that matches one or more attributes of a user. For example, one may store in association with these attributes based on what is trained based on training instances based on past query submissions of users with those attributes. In some implementations, block 654 can be omitted (eg, only a single generation model can be used).
블록 656에서, 시스템은 질의의 토큰들 및 추가 값들을 생성 모델에 입력으로서 적용한다. 질의를 제출한 사용자의 속성들, 시간 속성들 및/또는 수신된 질의에 대한 검색 시스템 응답(들)에 대한 속성들과 같은 다양한 추가 값들이 적용될 수 있다. 하나의 특정 예로서, 추가 값들은 질의를 제출한 사용자의 예측된 태스크 속성을 포함할 수 있다. 예측된 태스크 속성은, 예를 들어, 사용자에 의해 컴퓨팅 디바이스에서 최근에 본 콘텐츠, 사용자의 저장된 캘린더 엔트리 및/또는 사용자의 전자 통신(들)에 기초하여 예측될 수 있다.At
블록 658에서, 시스템은 적용된 입력에 기초하여 생성 모델에 대한 하나 이상의 변형을 생성한다.At
블록 660에서, 시스템은 추가 변형들을 생성할지를 결정한다. 일부 구현들에서, 시스템은 지금까지 생성된 변형들의 속성들 및/또는 지금까지 생성된 변형들에 대한 검색 시스템으로부터의 응답(들)에 기초하여 추가 변형들을 생성할지를 결정한다. 예를 들어, 시스템은 지금까지 생성된 변형(들)에 대한 응답(들)이 검색 시스템에 의해 발견되었는지 여부 및/또는 응답(들)의 품질 척도(들)에 기초하여 추가 변수를 생성할지 여부를 결정할 수 있다. 예를 들어, 시스템은 응답들이 없거나 그리고/또는 품질 측정(들)이 하나 이상의 품질 기준을 만족시키지 못하는 경우에 추가의 변형들을 생성할 수 있다.At block 660, the system determines whether to generate additional variations. In some implementations, the system determines whether to generate additional variants based on the properties of the variants created so far and / or the response (s) from the search system for the variants created so far. For example, the system may generate additional variables based on whether the response (s) for the variation (s) generated so far have been found by the search system and / or the quality measure (s) of the response (s). Can be determined. For example, the system may generate additional variations if there are no responses and / or if the quality measurement (s) do not meet one or more quality criteria.
블록 660의 반복에서, 시스템이 추가 변형들을 생성하기로 결정하면, 시스템은 블록 662으로 진행하여 블록 656의 후속 반복에서 생성 모델에 입력으로서 적용될 하나 이상의 추가 값을 업데이트한다. 예를 들어, 시스템은, 블록 658의 가장 최근 반복에서 생성된 변형(들)을 반영하기 위해, 변형(들)에 대한 응답(들)을 반영하기 위해, 그리고 블록 658의 다음 반복에 대한 유형 값을 변경하기 위해 추가 값들을 업데이트할 수 있다. 그 후, 시스템은 업데이트된 추가 값들을 사용하여 블록 656의 다른 반복을 수행한 다음, 블록들 658 및 660로 진행한다.At an iteration of block 660, if the system determines to generate additional variations, the system proceeds to block 662 to update one or more additional values to be applied as inputs to the generation model at a subsequent iteration of
블록 660의 반복에서, 시스템이 추가 변형들을 생성하지 않기로 결정하면, 시스템은 블록 664으로 진행하여 하나 이상의 생성된 변형에 기초한 출력을 제공한다. 출력은 하나 이상의 변형(들) 및/또는 하나 이상의 변형(들)에 대한 검색 시스템 응답(들)을 포함할 수 있다.At an iteration of block 660, if the system determines not to generate additional variations, the system proceeds to block 664 to provide an output based on one or more generated variations. The output may include one or more variant (s) and / or search system response (s) for one or more variant (s).
도 7은 생성 모델을 이용하여 질의의 하나 이상의 변형을 생성하는 방법 (700)을 나타내는 흐름도이며, 제어 모델은 변형들의 생성을 제어하는데 이용된다. 편의상, 흐름도의 동작들은 동작들을 수행하는 시스템을 참조하여 서술된다. 이 시스템은 하나 이상의 프로세서(예를 들어, CPU(들), GPU(들) 및/또는 TPU(들))와 같은 하나 이상의 컴포넌트들을 포함할 수 있다. 방법(700)의 동작들이 특정 순서로 도시되어 있지만, 이는 제한적인 것으로 의도되지 않는다. 하나 이상의 동작들이 재정렬, 생략 또는 추가될 수 있다.7 is a flow diagram illustrating a
블록 752에서, 시스템은 질의를 수신한다.In block 752, the system receives a query.
블록 754에서, 시스템은 현재 상태에 기초하여 제어 모델을 통해 제어 출력을 생성한다. 예를 들어, 현재 상태는 현재 질의의 토큰들, 현재 질의에 대한 검색 시스템 응답들 및/또는 기타 피처들을 기초로 할 수 있다.At block 754, the system generates a control output via the control model based on the current state. For example, the current state may be based on tokens of the current query, search system responses to the current query, and / or other features.
블록 756에서, 시스템은, 제어 출력에 기초하여, 수신된 질의의 변형을 생성할지 여부를 결정한다. 일부 구현들에서, 블록 754, 및 블록 756의 초기 반복은 생략될 수 있다. 다시 말해서, 이러한 구현들에서, 시스템은 (예를 들어, 수신된 질의에 대한 검색 시스템 응답의 유효성을 검사하기 위해) 항상 변형을 생성하기로 결정할 수 있다.At block 756, the system determines whether to generate a variation of the received query based on the control output. In some implementations, initial iteration of block 754 and block 756 can be omitted. In other words, in such implementations, the system may decide to always generate a variant (eg, to validate a search system response to a received query).
블록 756의 반복에서, 시스템이 변형을 생성하지 않기로 결정하면, 시스템은 블록 766으로 진행하여 현재 검색 시스템 응답(들) 및/또는 생성된 변형(들)에 기초한 출력을 제공한다.At an iteration of block 756, if the system determines not to generate a variant, the system proceeds to block 766 to provide an output based on the current search system response (s) and / or generated variant (s).
블록 756의 반복에서, 시스템이 변형을 생성하기로 결정하면, 시스템은 블 758으로 진행한다.At an iteration of block 756, if the system determines to generate a variant, the system proceeds to block 758.
블록 758에서, 시스템은 블록 754의 가장 최근 반복에서 생성된 제어 출력에 기초하여 보상 신호 및/또는 컨텍스트를 결정한다. 보상 신호는 여기에 기술된 바와 같이 학습된 Q-함수에 기초할 수 있고, 그리고 컨텍스트는, 예를 들어, 현재 상태 및/또는 현재 상태의 벡터 요약을 포함할 수 있다.At
블록 760에서, 시스템은 수신된 질의 및 블록 758의 보상 신호 및/또는 컨텍스트에 기초하여 생성 모델에 대한 변형을 생성한다.At block 760, the system generates a variation on the generation model based on the received query and the compensation signal and / or context of
블록 762에서, 시스템은 블록 760에서 생성된 변형에 대한 응답(들)을 결정한다. 예를 들어, 시스템은 변형을 검색 시스템에 제출하고 그리고 변형에 응답하는 검색 시스템으로부터 응답(들)을 수신할 수 있다. 어떤 상황들에서는, 검색 시스템이 응답을 리턴하지 않거나 그리고/또는 "널(null)"을 생성하는데, 각각은 어떤 응답(예를 들어, 답변)도 이용가능하지 않음을 나타낸다. At block 762, the system determines the response (s) for the transformation generated at block 760. For example, the system can submit a variant to the search system and receive response (s) from the search system responsive to the variant. In some situations, the search system does not return a response and / or generates a "null", each indicating that no response (eg, answer) is available.
블록 764에서, 시스템은 변형에 기초한 현재 상태 및 변형에 대한 응답(들)을 업데이트한다. 그 후, 시스템은 블록 754으로 진행하여 블록 764의 업데이트를 포함하는 현재 상태에 기초하여 제어 모델에 대한 제어 출력을 생성한다. 이러한 방식으로, 블록 764의 후속 반복들에서, 이전에 생성된 (즉, 블록들 760 및 762의 이전 반복에서 생성된) 변형(들) 및 응답(들)은 다음 블록(754)의 반복에서 고려될 수 있다. 그 후, 시스템은 블록 756으로 되돌아가서, 제어 출력에 기초하여 수신된 질의의 다른 변형을 생성할지 여부를 결정한다. 시스템이 다른 변형을 생성하기로 결정하면, 블록 758의 다음 반복에서 제공되는 보상 신호 및 컨텍스트는 마찬가지로 이전에 생성된 (즉, 블록들 760 및 762의 이전 반복에서 생성된) 변형(들) 및 응답(들)에 따라 조절될 수 있음이 주목된다. 이러한 방식으로, 블록 760의 다음 반복의 변형 생성은 결과적으로 이전에 생성된 변형(들) 및 응답(들)에 의해 영향을 받는다.At block 764, the system updates the current state and response (s) for the variant based on the variant. The system then proceeds to block 754 to generate a control output for the control model based on the current state including the update of block 764. In this way, in subsequent iterations of block 764, the modification (s) and response (s) previously generated (ie, generated in the previous iterations of blocks 760 and 762) are considered in the iteration of the next block 754. Can be. The system then returns to block 756 to determine whether to generate another variant of the received query based on the control output. If the system decides to generate another variant, the compensation signal and context provided in the next iteration of
도 8a 및 도 8b를 참조하면, 예시적인 그래픽 사용자 인터페이스들(800a 및 800b)은 여기에 개시된 구현들에 따라 생성된 변형(들)에 기초하여 출력을 제공하기 위해 도시된다. 그래픽 사용자 인터페이스들(800A 및 800B)은, 클라이언트 디바이스(106)에서 (예를 들어, 클라이언트 디바이스(106)에서 실행되는 브라우저 및/또는 클라이언트 디바이스(106)에서 실행되는 다른 애플리케이션에서) 제공될 수 있다.8A and 8B, example graphical user interfaces 800a and 800b are shown to provide an output based on variant (s) generated in accordance with implementations disclosed herein.
도 8a에서, 사용자는 "다빈치가 모나리자를 그렸나"라는 질의(891A)를 제공했다. 이에 응답하여, 응답(892A)을 포함하고 그리고 또한 2개의 변형들(893A)을 포함하는 출력이 제공된다. 2개의 변형들(893A)은 여기에 개시된 구현들에 따라 생성될 수 있다. 일부 구현들에서, 각각의 변형들이 선택 가능하고, 그리고 선택에 응답하여, 대응하는 변형이 새로운 질의로서 제출되게 한다. 일부 구현들에서, 응답(892A)은 또한 여기에 개시된 구현들에 따라 생성된 변형(들)에 기초한다. 예를 들어, 일부 상황들에서, 응답(892A)은 질의(891A)의 변형(변형들(893A)과 상이한 변형)에 대한 응답일 수 있고 그리고/또는 응답(892A)은 질의(891A)에 대한 것일 수 있지만, 질의의 변형(들)에 대한 응답(들)에 기초하여 (예를 들어, 이들 변형의 더 생성된 긍정적인 응답들을 보장함으로써) 검증된다.In FIG. 8A, the user provided a
도 8b에서, 사용자는 "미켈란젤로가 모나리자를 그렸나"라는 질의(891B)를 제공했다. 이에 응답하여, "아니오"라는 응답(892B)을 포함하는 출력이 제공된다. 도 8b의 박스(895B)는 선택적으로 디스플레이를 위해 제공되지 않을 수 있지만, "아니오"라는 응답(892B)을 생성하기 위해 여기에 서술된 기술들에 따라 생성될 수 있는 변형들의 예로서 제시된다. 박스 895B는 원래 질의("O"로 표시됨)를 디스플레이하고 그리고 원래 질의에 대한 응답으로 검색 시스템에 의해 답변 응답이 생성되었음을 나타내기 위해 "Y"를 괄호 안에 포함한다. 예를 들어, "응, 미켈란젤로가 모나리자를 그렸어"라고 대답할 수 있다. 하지만, 답변을 제공하는 대신에, 원래 질의에 대한 응답의 정확성을 확인하기 위해 "후속" 변형들인 다수의 변형들이 생성된다. 특히, 변형들 VI, V2 및 V3이 생성된다. 괄호들 안에 "N"으로 표시되는 바와 같이, 각각의 후속 변형들에 응답하여 검색 시스템에 의해 "답변 없음" 응답들이 생성되었다. 다수의 후속 변형들에 대해 이용가능한 답변이 없다고 생각하면, 제어기 엔진은 (후속 변형들이 어떤 답변으로 이어지지 않기 때문에) 원래 질의에 대한 "답변 응답"이 부정확하다고 결정할 수 있다. 결과로서, 제어기 엔진은 "아니오"라는 응답(892B)을 제공할 수 있다. In FIG. 8B, the user provided a
그래픽 인터페이스의 예들이 도 8a 및 도 8b에 제시되어 있지만, 사용자의 음성 입력에 기초하여 질의들이 추가로 또는 대안적으로 수신될 수 있다는 것 및/또는 변형들 및/또는 응답들은 클라이언트 디바이스를 통해 청각적으로 사용자에게 제공하기 위해 부가적으로 또는 대안적으로 제공될 수 있다는 것이 이해된다. Although examples of the graphical interface are presented in FIGS. 8A and 8B, queries may be additionally or alternatively received based on a user's voice input and / or variations and / or responses are audited via the client device. In addition, it is to be understood that the present invention may be additionally or alternatively provided to the user.
여기에 서술된 시스템들이 사용자들에 대한 개인 정보를 수집하거나 개인 정보를 사용할 수 있는 상황들에서, 프로그램들 또는 피처들이 사용자 정보(예를 들어, 사용자의 사회적 네트워크, 사회적 활동들 또는 행동들, 직업, 사용자의 선호도, 또는 사용자의 현재 지리적 위치에 대한 정보)를 수집하는지를 제어하거나 또는 사용자에게 더 관련될 수 있는 콘텐츠 서버로부터 콘텐츠를 수신할지 여부 및/또는 수신하는 방법을 제어할 기회를 사용자들은 제공받을 수 있다. 또한, 특정 데이터는, 개인 식별 정보가 제거되도록 저장 또는 사용하기 전에 하나 이상의 방식으로 처리될 수 있다. 예를 들어, 어떤 개인 식별 정보도 사용자에 대해 결정될 수 없도록 사용자의 신원이 처리될 수 있거나, 또는 (도시, ZIP 코드 또는 주 레벨과 같은) 지리적 위치 정보가 획득되는 경우 사용자의 지리적 위치가 일반화될 수 있어, 사용자의 특정 지리적 위치는 결정될 수 없다. 따라서, 사용자는 사용자에 관한 정보가 어떻게 수집되고 그리고/또는 사용되는지 제어할 수 있다.In situations where the systems described herein may collect or use personal information about users, programs or features may be used to identify user information (eg, a user's social network, social activities or behaviors, occupations). , Users' preferences, or information about the user's current geographic location) or provide users with an opportunity to control whether and / or how to receive content from content servers that may be more relevant to the user. I can receive it. In addition, certain data may be processed in one or more ways prior to storage or use so that personally identifiable information is removed. For example, the user's identity may be processed such that no personally identifiable information can be determined for the user, or the user's geographic location may be generalized if geographic location information (such as city, ZIP code, or state level) is obtained. As such, a particular geographic location of the user cannot be determined. Thus, the user can control how information about the user is collected and / or used.
도 9는 여기에 서술된 기술들의 하나 이상의 양태들을 수행하기 위해 선택적으로 이용될 수 있는 예시적인 컴퓨팅 디바이스(910)의 블록도이다. 컴퓨팅 디바이스(910)는 버스 서브시스템(912)을 통해 다수의 주변 디바이스들과 통신하는 적어도 하나의 프로세서(914)(예를 들어, CPU, GPU 및/또는 TPU)를 포함한다. 이러한 주변 디바이스들은, 예를 들어, 메모리 서브시스템(925) 및 파일 저장 서브시스템(926)을 포함하는 저장 서브시스템(1024), 사용자 인터페이스 출력 디바이스들(920), 사용자 인터페이스 입력 디바이스들(922) 및 네트워크 인터페이스 서브시스템(915)을 포함할 수 있다. 입력 디바이스 및 출력 디바이스는 컴퓨팅 디바이스(910)와의 사용자 상호 작용을 가능하게 한다. 네트워크 인터페이스 서브시스템(915)은 외부 네트워크들에 인터페이스를 제공하고 그리고 다른 컴퓨팅 디바이스들 내의 대응하는 인터페이스 디바이스들에 연결된다.9 is a block diagram of an
사용자 인터페이스 입력 디바이스들(922)은, 키보드, 마우스, 트랙볼, 터치 패드 또는 그래픽 태블릿과 같은 포인팅 디바이스, 스캐너, 디스플레이에 통합된 터치 스크린, 음성 인식 시스템들과 같은 오디오 입력 디바이스들, 마이크로폰들, 및/또는 다른 유형의 입력 디바이스들을 포함할 수 있다. 일반적으로, 용어 "입력 디바이스(input device)"의 사용은 컴퓨팅 디바이스(910)에 또는 통신 네트워크상에 정보를 입력하는 모든 가능한 유형들을 디바이스들 및 방식들을 포함하도록 의도된다.User
사용자 인터페이스 출력 디바이스들(920)은 디스플레이 서브시스템, 프린터, 팩스 머신 또는 오디오 출력 디바이스들과 같은 비 시각적 디스플레이들을 포함할 수 있다. 디스플레이 서브 시스템은 음극선관(CRT), 액정 디스플레이(LCD)와 같은 평판 디바이스, 프로젝션 디바이스, 또는 가시적 이미지를 생성하기 위한 다른 메커니즘을 포함할 수 있다. 디스플레이 서브 시스템은 또한 오디오 출력 디바이스들을 통한 비 시각적 디스플레이를 제공할 수 있다. 일반적으로, 용어 "출력 디바이스(output device)"의 사용은 컴퓨팅 디바이스(910)로부터 사용자 또는 다른 머신 또는 컴퓨팅 디바이스로 정보를 출력하는 모든 가능한 유형들의 디바이스들 및 방식들을 포함하도록 의도된다. User
저장 서브시스템(924)은 여기에 서술된 일부 또는 모든 모듈들의 기능을 제공하는 프로그래밍 및 데이터 구조를 저장한다. 예를 들어, 저장 서브시스템(924)은 여기에 서술된 방법들의 선택된 측면들을 수행하기 위한 로직을 포함할 수 있다.
이들 소프트웨어 모듈들은 일반적으로 프로세서(914) 단독으로 또는 다른 프로세서들과 조합하여 실행된다. 저장 서브시스템(924)에서 사용되는 메모리(925)는, 프로그램 실행 중 명령어들 및 데이터의 저장을 위한 메인 랜덤 액세스 메모리(RAM)(930) 및 고정된 명령어들이 저장되는 판독 전용 메모리(ROM)(932)를 포함하는 다수의 메모리들을 포함할 수 있다. 파일 저장 서브시스템(926)은 프로그램 및 데이터 파일들을 위한 영구 저장 장치를 제공할 수 있으며, 그리고 하드 디스크 드라이브, 관련 착탈가능한 매체와 함께 플로피 디스크 드라이브, CD-ROM 드라이브, 광 드라이브 또는 착탈가능한 매체 카트리지들을 포함할 수 있다. 특정 구현들의 기능을 구현하는 모듈들은, 저장 서브시스템(924)의 파일 저장 서브시스템(926) 또는 프로세서(들)(914)에 의해 액세스 가능한 다른 머신들에 저장될 수 있다.These software modules are generally executed by the
버스 서브시스템(912)은 컴퓨팅 디바이스(910)의 다양한 컴포넌트들 및 서브 시스템들이 의도된 바와 같이 서로 통신하게 하는 메커니즘을 제공한다. 버스 서브시스템(912)은 단일 버스로서 개략적으로 도시되어 있지만, 버스 서브시스템의 다른 구현들은 다수의 버스들을 사용할 수 있다.
컴퓨팅 디바이스(910)는 워크스테이션, 서버, 컴퓨팅 클러스터, 블레이드 서버, 서버 팜 또는 임의의 다른 데이터 프로세싱 시스템 또는 컴퓨팅 디바이스를 포함하는 다양한 유형일 수 있다. 컴퓨터들 및 네트워크들의 끊임없이 변화하는 특성으로 인해, 도 9에 도시된 컴퓨팅 디바이스(910)의 서술은 단지 일부 구현들을 설명하기 위한 특정 예로서 의도된다. 도 9에 도시된 컴퓨팅 디바이스보다 많거나 적은 컴포넌트들을 갖는 컴퓨팅 디바이스(910)의 많은 다른 구성들이 가능하다.
Claims (36)
클라이언트 디바이스를 통해 사용자의 사용자 인터페이스 입력에 기초하여 생성된 원래 질의(query)를 수신하는 단계와;
상기 원래 질의의 토큰들을 입력으로서 훈련된 생성 모델에 적용하는 단계와;
상기 원래 질의의 토큰들을 상기 훈련된 생성 모델에 적용하는 것에 기초하여 상기 원래 질의의 적어도 하나의 변형을 생성하는 단계와;
상기 적어도 하나의 변형 및 상기 적어도 하나의 변형에 대한 적어도 하나의 검색 시스템 응답 중 적어도 하나에 기초하여 출력을 생성하는 단계와; 그리고
상기 원래 질의에 응답하여, 상기 클라이언트 디바이스를 통한 표현을 위해 출력을 제공하는 단계를 포함하는 것을 특징으로 하는
하나 이상의 프로세서에 의해 구현되는 방법.A method implemented by one or more processors,
Receiving via the client device an original query generated based on the user interface input of the user;
Applying the tokens of the original query as input to a trained generation model;
Generating at least one variant of the original query based on applying tokens of the original query to the trained generation model;
Generating an output based on at least one of the at least one variant and at least one search system response to the at least one variant; And
In response to the original query, providing an output for presentation through the client device.
A method implemented by one or more processors.
상기 입력의 일부로서, 상기 훈련된 생성 모델에 상기 사용자와 관련된 하나 이상의 속성을 적용하는 단계를 더 포함하는 것을 특징으로 하는
하나 이상의 프로세서에 의해 구현되는 방법.The method of claim 1,
As part of the input, further comprising applying one or more attributes associated with the user to the trained generation model.
A method implemented by one or more processors.
상기 훈련된 생성 모델에 대한 하나 이상의 속성에 기초하여 상기 원래 질의의 적어도 하나의 변형을 생성하는 단계를 더 포함하는 것을 특징으로 하는
하나 이상의 프로세서에 의해 구현되는 방법.The method of claim 2,
Generating at least one variant of the original query based on one or more attributes for the trained generation model.
A method implemented by one or more processors.
상기 하나 이상의 속성은, 사용자의 위치, 상기 사용자가 현재 참여한 태스크(task) 및 상기 사용자의 위치에서의 날씨 중 하나 이상을 포함하는 것을 특징으로 하는
하나 이상의 프로세서에 의해 구현되는 방법.The method according to claim 2 or 3,
The one or more attributes include one or more of a user's location, a task that the user currently participates in, and weather at the user's location.
A method implemented by one or more processors.
상기 입력의 일부로서, 상기 훈련된 생성 모델에, 현재 시간, 현재 요일 및 현재 날짜 중 적어도 하나를 포함하는 하나 이상의 시간 속성을 적용하는 단계를 더 포함하는 것을 특징으로 하는
하나 이상의 프로세서에 의해 구현되는 방법.The method according to any one of claims 1 to 4,
As part of the input, further comprising applying one or more time attributes to the trained generation model including at least one of a current time, a current day of the week, and a current date.
A method implemented by one or more processors.
상기 사용자에 대해 예측된 태스크를 결정하는 단계와; 그리고
입력으로서, 상기 훈련된 생성 모델에, 상기 사용자에 대해 예측되는 태스크의 하나 이상의 태스크 속성을 적용하는 단계를 더 포함하고,
상기 원래 질의의 적어도 하나의 변형을 생성하는 단계는, 상기 훈련된 생성 모델에 상기 하나 이상의 태스크 속성의 적용에 기초하는 것을 특징으로 하는
하나 이상의 프로세서에 의해 구현되는 방법.The method according to any one of claims 1 to 5,
Determining a predicted task for the user; And
As an input, applying one or more task attributes of a task predicted for the user to the trained generation model,
Generating at least one variant of the original query is based on the application of the one or more task attributes to the trained generation model.
A method implemented by one or more processors.
상기 사용자에 대해 예측된 태스크를 결정하는 단계는, 상기 클라이언트 디바이스 또는 추가 클라이언트 디바이스를 통한 상기 사용자와의 하나 이상의 상호작용에 기초하는 것을 특징으로 하는
하나 이상의 프로세서에 의해 구현되는 방법.The method of claim 6,
Determining a predicted task for the user is based on one or more interactions with the user via the client device or an additional client device.
A method implemented by one or more processors.
상기 예측된 태스크가 결정되는 것에 기초하여, 상기 하나 이상의 상호 작용은 상기 사용자에 의해 전송된 전자 통신 또는 상기 사용자에 의해 생성된 캘린더 엔트리를 포함하는 것을 특징으로 하는
하나 이상의 프로세서에 의해 구현되는 방법.The method of claim 7, wherein
Based on the predicted task being determined, the one or more interactions comprise an electronic communication sent by the user or a calendar entry generated by the user.
A method implemented by one or more processors.
상기 사용자에 대해 예측된 태스크를 결정하는 단계는, 상기 사용자에게 전송된 전자 통신 또는 상기 사용자의 저장된 캘린더 엔트리에 기초하는 것을 특징으로 하는
하나 이상의 프로세서에 의해 구현되는 방법.The method of claim 6,
Determining a task predicted for the user is based on an electronic communication sent to the user or a stored calendar entry of the user.
A method implemented by one or more processors.
훈련 인스턴스 입력 및 훈련 인스턴스 출력을 포함하는 훈련 인스턴스를 생성하는 단계와; 그리고
상기 생성된 훈련 인스턴스에 기초하여 상기 생성 모델을 훈련하는 단계를 더 포함하며,
상기 훈련 인스턴스 입력은:
제1 질의의 제1 질의 토큰들, 및
태스크 속성을 포함하고,
상기 훈련 인스턴스 출력은:
제2 질의의 제2 질의 토큰들을 포함하며,
상기 훈련 인스턴스는, 상기 제1 질의의 과거 제출 및 후속하는 상기 제2 질의의 과거 제출이 상기 예측된 태스크와 관련된다는 결정에 기초하여 훈련 인스턴스 입력으로서 상기 태스크 속성으로 생성되는 것을 특징으로 하는
하나 이상의 프로세서에 의해 구현되는 방법.The method of claim 6,
Creating a training instance comprising a training instance input and a training instance output; And
Training the generation model based on the generated training instance;
The training instance input is:
First query tokens of the first query, and
Contains task attributes,
The training instance output is:
Includes second query tokens of the second query,
The training instance is generated with the task attribute as a training instance input based on a determination that past submission of the first query and subsequent past submission of the second query are related to the predicted task.
A method implemented by one or more processors.
상기 예측된 태스크와 관련된 과거 질의 제출들에 기초하여 훈련되는 상기 훈련된 생성 모델을 기반으로, 복수의 훈련된 생성 모델들로부터 훈련된 생성 모델을 선택하는 단계를 포함하는 것을 특징으로 하는
하나 이상의 프로세서에 의해 구현되는 방법.The method according to any one of claims 6 to 10,
Selecting a trained generation model from a plurality of trained generation models based on the trained generation model trained based on past query submissions associated with the predicted task.
A method implemented by one or more processors.
상기 예측된 태스크와 관련된 과거 질의 제출들에 기초하여 생성되는 훈련 인스턴스들을 선택하는 단계와; 그리고
상기 선택된 훈련 인스턴스들에 기초하여 상기 생성 모델을 훈련하는 단계를 더 포함하는 것을 특징으로 하는
하나 이상의 프로세서에 의해 구현되는 방법.The method of claim 11,
Selecting training instances generated based on past query submissions associated with the predicted task; And
Training the generation model based on the selected training instances.
A method implemented by one or more processors.
2개 이상의 이전에 제출된 질의들의 그룹은 상기 예측된 태스크와 관련된다고 결정하는 단계와;
상기 이전에 제출된 질의들의 그룹에 기초하여 상기 훈련 인스턴스들 중 하나를 생성하는 단계와; 그리고
상기 예측된 태스크와 관련된 훈련 인스턴스들 중 하나를 라벨링하는 단계를 더 포함하고,
상기 예측된 태스크와 관련된 과거 질의 제출들에 기초하여 생성되는 훈련 인스턴스들을 선택하는 단계는, 상기 라벨링에 기초하여 상기 훈련 인스턴스들 중 하나를 선택하는 단계를 포함하는 것을 특징으로 하는
하나 이상의 프로세서에 의해 구현되는 방법.The method of claim 12,
Determining that a group of two or more previously submitted queries is associated with the predicted task;
Creating one of the training instances based on the group of previously submitted queries; And
Labeling one of the training instances associated with the predicted task,
Selecting training instances generated based on past query submissions associated with the predicted task comprises selecting one of the training instances based on the labeling.
A method implemented by one or more processors.
2개 이상의 이전에 제출된 질의들의 그룹은 상기 예측된 태스크와 관련된다고 결정하는 단계는, 상기 이전에 제출된 질의들의 제출 이후에 수행되는 컴퓨터 기반 동작에 기초하는 것을 특징으로 하는
하나 이상의 프로세서에 의해 구현되는 방법.The method of claim 13,
Determining that a group of two or more previously submitted queries is related to the predicted task, based on a computer-based operation performed after submission of the previously submitted queries.
A method implemented by one or more processors.
상기 사용자와 공통으로 하나 이상의 속성을 갖는 사용자들의 그룹의 과거 질의 제출들에 기초하여 훈련되는 상기 훈련된 생성 모델을 기반하여, 복수의 훈련된 생성 모델들로부터 훈련된 생성 모델을 선택하는 단계와; 그리고
입력으로서, 상기 선택된 훈련된 생성 모델에 원래 질의의 토큰들을 적용하는 단계를 더 포함하는 것을 특징으로 하는
하나 이상의 프로세서에 의해 구현되는 방법.The method according to any one of claims 1 to 5,
Selecting a trained generation model from a plurality of trained generation models based on the trained generation model trained based on past query submissions of a group of users having one or more attributes in common with the user; And
As an input, applying tokens of an original query to the selected trained generation model
A method implemented by one or more processors.
상기 훈련된 생성 모델은 하나 이상의 메모리 계층을 갖는 심층 신경망 모델인 것을 특징으로 하는
하나 이상의 프로세서에 의해 구현되는 방법.The method according to any one of claims 1 to 15,
The trained generation model is a deep neural network model having one or more memory layers.
A method implemented by one or more processors.
상기 원래 질의의 적어도 하나의 변형을 생성하는 단계는, 상기 훈련된 생성 모델의 학습된 파라미터들에 기초하여 상기 변형을 생성하는 단계를 포함하고,
상기 방법은:
상기 훈련된 생성 모델에, 상기 원래 질의의 토큰들 및 상기 원래 질의의 변형의 변형 토큰들 중 적어도 하나를 포함하는 추가 입력을 적용하는 단계와;
상기 추가 입력에 기초하여 상기 훈련된 생성 모델에 대한 상기 원래의 질의 추가 변형을 생성하는 단계 - 상기 추가 변형은 상기 변형 및 상기 원래의 질의와 상이하고, 상기 원래의 질의 추가 변형을 생성하는 단계는 상기 훈련된 생성 모델의 학습된 파라미터들에 기초하여 상기 추가 변형을 생성하는 단계를 포함하며 - 와;
상기 검색 시스템에 상기 원래 질의의 추가 변형을 제출하는 것에 기초하여 상기 원래 질의의 추가 변형에 대한 추가 변형 응답을 결정하는 단계와;
상기 변형 응답 및 상기 추가 변형 응답 중 적어도 하나에 기초하여 출력을 생성하는 단계와; 그리고
상기 원래 질의에 응답하여, 상기 클라이언트 디바이스를 통한 표현을 위한 출력을 제공하는 단계를 더 포함하는 것을 특징으로 하는
하나 이상의 프로세서에 의해 구현되는 방법.The method according to any one of claims 1 to 16,
Generating at least one variant of the original query comprises generating the variant based on learned parameters of the trained generation model,
The method is:
Applying an additional input to the trained generation model, the additional input comprising at least one of tokens of the original query and variant tokens of the modification of the original query;
Generating the original query further variant for the trained generation model based on the further input, wherein the further variant is different from the variant and the original query, and generating the original query further variant Generating the further modification based on the learned parameters of the trained generation model;
Determining a further modification response to the further modification of the original query based on submitting the further modification of the original query to the search system;
Generating an output based on at least one of the modification response and the further modification response; And
In response to the original query, providing an output for presentation through the client device.
A method implemented by one or more processors.
상기 훈련된 생성 모델은 질의 변형들의 다수의 유형들을 생성하도록 훈련되고, 그리고 상기 변형은 상기 질의 변형들의 다수 유형들 중 제1 유형이고 그리고 상기 추가 변형은 상기 질의 변형들의 다수의 유형들 중 제2 유형인 것을 특징으로 하는
하나 이상의 프로세서에 의해 구현되는 방법.The method of claim 17,
The trained generation model is trained to produce multiple types of query variants, and the variant is a first type of the multiple types of query variants and the further variant is a second of the multiple types of query variants. Characterized in that the type
A method implemented by one or more processors.
상기 제1 유형은, 등가 질의, 후속 질의, 일반화 질의, 정규화 질의, 연루 질의, 사양 질의, 설명 질의 및 언어 번역 질의 중 하나이고, 그리고 상기 제2 유형은, 등가 질의, 후속 질의, 일반화 질의, 정규화 질의, 연루 질의, 사양 질의, 설명 질의 및 언어 번역 질의 중 다른 하나인 것을 특징으로 하는
하나 이상의 프로세서에 의해 구현되는 방법.The method of claim 18,
The first type is one of an equivalent query, a subsequent query, a generalized query, a normalized query, an implicit query, a specification query, a description query, and a language translation query, and the second type is an equivalent query, a subsequent query, a generalized query, Characterized in that the other one of the normalized query, implicit query, specification query, description query
A method implemented by one or more processors.
상기 변형은, 상기 훈련된 생성 모델에 대한 입력의 일부로서 적용되는 제1 유형 값에 기초하여, 상기 제1 유형으로서 상기 훈련된 생성 모델에 대해 생성되고, 그리고
상기 추가 변형은, 상기 훈련된 생성 모델에 대한 추가 입력의 일부로서 적용되는 제2 유형 값에 기초하여, 상기 제2 유형으로서 상기 훈련된 생성 모델에 대해 생성되는 것을 특징으로 하는
하나 이상의 프로세서에 의해 구현되는 방법.The method of claim 18,
The modification is generated for the trained generation model as the first type, based on a first type value applied as part of the input to the trained generation model, and
The further modification is generated for the trained generation model as the second type based on a second type value applied as part of the further input to the trained generation model.
A method implemented by one or more processors.
상기 훈련된 생성 모델에 적용되는 상기 추가 입력은 상기 원래 질의의 토큰들을 포함하는 것을 특징으로 하는
하나 이상의 프로세서에 의해 구현되는 방법.The method of claim 17,
The additional input applied to the trained generation model comprises tokens of the original query
A method implemented by one or more processors.
상기 추가 입력은 상기 원래 질의의 변형의 변형 토큰들을 더 포함하는 것을 특징으로 하는
하나 이상의 프로세서에 의해 구현되는 방법.The method of claim 21,
The further input further comprises variant tokens of the variant of the original query
A method implemented by one or more processors.
상기 추가 입력은, 상기 원래 질의의 변형에 대한 변형 응답에 기초한 변형 응답 피처들을 더 포함하는 것을 특징으로 하는
하나 이상의 프로세서에 의해 구현되는 방법.The method of claim 21,
The additional input further includes modification response features based on the transformation response to the transformation of the original query.
A method implemented by one or more processors.
상기 추가 변형을 생성하기 전에, 상기 변형 응답에 기초하여, 상기 변형 응답을 출력으로서 제공할지 또는 상기 추가 변형을 생성할지를 결정하는 단계를 더 포함하고,
상기 추가 변형을 생성하는 것은, 상기 변형 응답을 제공하는 대신에 상기 추가 변형을 생성하기로 결정하는 것에 달려있는 것을 특징으로 하는
하나 이상의 프로세서에 의해 구현되는 방법.The method of claim 17,
Before generating the further modification, further comprising determining, based on the deformation response, whether to provide the deformation response as an output or to generate the additional deformation,
Generating the further variation depends on determining to create the further variation instead of providing the variation response.
A method implemented by one or more processors.
상기 변형 응답을 출력으로서 제공할지 또는 상기 추가 변형을 생성할지를 결정하는 단계는, 상기 원래 질의의 변형에 더 기초하는 것을 특징으로 하는
하나 이상의 프로세서에 의해 구현되는 방법.The method of claim 24,
Determining whether to provide the variant response as an output or generate the further variant, further based on a variant of the original query
A method implemented by one or more processors.
상기 변형 응답에 기초하여, 상기 변형 응답을 출력으로서 제공할지 또는 상기 추가 변형을 생성할지를 결정하는 단계는:
상기 변형 응답의 피처를, 제어기 입력으로서 훈련된 제어 모델에 적용하는 단계와;
상기 제어기 입력에 기초하여 상기 훈련된 제어 모델에 대해 제어기 출력을 생성하는 단계와; 그리고
상기 제어기 출력에 기초하여 상기 추가 변형을 생성하기로 결정하는 단계를 포함하는 것을 특징으로 하는
하나 이상의 프로세서에 의해 구현되는 방법.The method of claim 24,
Based on the modification response, determining whether to provide the modification response as an output or generate the further modification:
Applying a feature of the deformation response to a trained control model as a controller input;
Generating a controller output for the trained control model based on the controller input; And
Determining to generate the further modification based on the controller output.
A method implemented by one or more processors.
상기 변형 응답에 기초하여, 상기 변형 응답을 출력으로서 제공할지 또는 상기 추가 변형을 생성할지를 결정하는 단계는:
상기 입력의 일부로 원래 질의의 변형을 상기 훈련된 제어 모델에 적용하는 단계를 더 포함하는 것을 특징으로 하는
하나 이상의 프로세서에 의해 구현되는 방법.The method of claim 26,
Based on the modification response, determining whether to provide the modification response as an output or generate the further modification:
Applying a modification of the original query to the trained control model as part of the input.
A method implemented by one or more processors.
상기 훈련된 제어 모델은, 상기 검색 시스템 또는 추가 검색 시스템과의 과거 상호 작용에 기초하여 결정된 보상들에 기반한 강화 학습을 기초로 훈련되는 것을 특징으로 하는
하나 이상의 프로세서에 의해 구현되는 방법.The method of claim 26,
The trained control model is trained based on reinforcement learning based on rewards determined based on past interactions with the search system or further search system.
A method implemented by one or more processors.
상기 훈련된 제어 모델은, 상기 훈련된 생성 모델과는 별개이지만 상기 훈련된 생성 모델과 조합하여 훈련되는 것을 특징으로 하는
하나 이상의 프로세서에 의해 구현되는 방법.The method of claim 26,
The trained control model is trained separately from the trained generation model but in combination with the trained generation model.
A method implemented by one or more processors.
상기 훈련된 제어 모델은, 피드 포워드(feed forward) 신경망 또는 반복 신경망인 것을 특징으로 하는
하나 이상의 프로세서에 의해 구현되는 방법.The method of claim 26,
The trained control model is characterized in that the feed forward (feed forward) neural network or iterative neural network
A method implemented by one or more processors.
상기 입력은 상기 사용자와 관련된 하나 이상의 속성을 더 포함하고, 그리고 상기 추가 입력은 상기 하나 이상의 속성을 더 포함하는 것을 특징으로 하는
하나 이상의 프로세서에 의해 구현되는 방법.The method according to any one of claims 17 to 26,
The input further comprises one or more attributes associated with the user, and wherein the additional input further comprises the one or more attributes.
A method implemented by one or more processors.
네트워크를 통해 원래의 요청을 상기 검색 시스템에 전송하는 단계 - 상기 원래의 요청은 상기 원래의 질의를 포함하며 - 와; 그리고
상기 원래의 요청에 응답하여 상기 검색 시스템으로부터 원래의 응답을 수신하는 단계를 더 포함하고,
상기 원래 질의의 토큰들을 입력으로서 훈련된 생성 모델에 적용하는 단계 및 상기 변형을 생성하는 단계는, 상기 검색 시스템으로부터의 상기 원래 응답에 기초하는 것을 특징으로 하는
하나 이상의 프로세서에 의해 구현되는 방법.The method of any one of claims 17 to 31,
Sending an original request to the search system over a network, the original request including the original query; And
Receiving an original response from the search system in response to the original request,
Applying the tokens of the original query to a trained generation model as input and generating the variant are based on the original response from the search system.
A method implemented by one or more processors.
상기 훈련된 생성 모델은 메모리 계층들을 갖는 심층 신경망 모델인 것을 특징으로 하는
하나 이상의 프로세서에 의해 구현되는 방법.The method according to any one of claims 1 to 32,
The trained generation model is a deep neural network model with memory layers
A method implemented by one or more processors.
상기 훈련된 생성 모델을 생성하기 위해 시퀀스 대 시퀀스 신경망 기계 번역을 훈련하는 단계를 더 포함하는 것을 특징으로 하는
하나 이상의 프로세서에 의해 구현되는 방법.The method according to any one of claims 1 to 33,
Training sequence-to-sequence neural network machine translation to produce the trained generation model.
A method implemented by one or more processors.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201762492154P | 2017-04-29 | 2017-04-29 | |
US62/492,154 | 2017-04-29 | ||
PCT/US2018/029834 WO2018200979A1 (en) | 2017-04-29 | 2018-04-27 | Generating query variants using a trained generative model |
Publications (2)
Publication Number | Publication Date |
---|---|
KR20200003132A true KR20200003132A (en) | 2020-01-08 |
KR102313472B1 KR102313472B1 (en) | 2021-10-15 |
Family
ID=62165685
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
KR1020197035500A KR102313472B1 (en) | 2017-04-29 | 2018-04-27 | Generate query variants using a trained generative model |
Country Status (6)
Country | Link |
---|---|
US (2) | US11663201B2 (en) |
EP (1) | EP3602349A1 (en) |
JP (1) | JP6918140B2 (en) |
KR (1) | KR102313472B1 (en) |
CN (2) | CN110574021B (en) |
WO (1) | WO2018200979A1 (en) |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
KR20220155785A (en) * | 2021-05-17 | 2022-11-24 | 삼성생명보험주식회사 | Method and apparatus for operating chatbot |
Families Citing this family (20)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
WO2018167830A1 (en) * | 2017-03-13 | 2018-09-20 | 日本電気株式会社 | Dialog device, dialog system, and computer-readable recording medium |
US11216437B2 (en) | 2017-08-14 | 2022-01-04 | Sisense Ltd. | System and method for representing query elements in an artificial neural network |
WO2019035862A1 (en) | 2017-08-14 | 2019-02-21 | Sisense Ltd. | System and method for increasing accuracy of approximating query results using neural networks |
US11256985B2 (en) | 2017-08-14 | 2022-02-22 | Sisense Ltd. | System and method for generating training sets for neural networks |
CN107992585B (en) * | 2017-12-08 | 2020-09-18 | 北京百度网讯科技有限公司 | Universal label mining method, device, server and medium |
US11061811B2 (en) * | 2017-12-15 | 2021-07-13 | International Business Machines Corporation | Optimizing software testing via group testing |
US20190272465A1 (en) * | 2018-03-01 | 2019-09-05 | International Business Machines Corporation | Reward estimation via state prediction using expert demonstrations |
US11086911B2 (en) * | 2018-07-31 | 2021-08-10 | Wipro Limited | Method and system for generating question variations to user input |
US11004449B2 (en) * | 2018-11-29 | 2021-05-11 | International Business Machines Corporation | Vocal utterance based item inventory actions |
US11922323B2 (en) * | 2019-01-17 | 2024-03-05 | Salesforce, Inc. | Meta-reinforcement learning gradient estimation with variance reduction |
JP2021089446A (en) * | 2019-03-13 | 2021-06-10 | ダイキン工業株式会社 | Selection method for model and deep reinforcement learning method |
US10878008B1 (en) * | 2019-09-13 | 2020-12-29 | Intuit Inc. | User support with integrated conversational user interfaces and social question answering |
US11782910B2 (en) | 2019-11-15 | 2023-10-10 | Samsung Electronics Co., Ltd. | System and method for dynamic inference collaboration |
US11521124B2 (en) | 2019-12-13 | 2022-12-06 | Robert Bosch Gmbh | Reciprocating generative models |
CN111241398B (en) * | 2020-01-10 | 2023-07-25 | 百度在线网络技术（北京）有限公司 | Data prefetching method, device, electronic equipment and computer readable storage medium |
US11455306B2 (en) | 2020-01-21 | 2022-09-27 | Oracle International Corporation | Query classification and processing using neural network based machine learning |
CN111222052B (en) * | 2020-04-24 | 2020-08-11 | 支付宝(杭州)信息技术有限公司 | Searching method and device and electronic equipment |
US20210397610A1 (en) * | 2020-06-23 | 2021-12-23 | Soundhound, Inc. | Machine learning system for digital assistants |
EP3961434A1 (en) * | 2020-08-27 | 2022-03-02 | Samsung Electronics Co., Ltd. | Method and apparatus for concept matching |
US11704307B2 (en) | 2020-12-23 | 2023-07-18 | Oracle International Corporation | Intelligent query editor using neural network based machine learning |
Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
KR20080072673A (en) * | 2005-11-30 | 2008-08-06 | 마이크로소프트 코포레이션 | Adaptive semantic reasoning engine |
US20120233140A1 (en) * | 2011-03-09 | 2012-09-13 | Microsoft Corporation | Context-aware query alteration |
KR20170043582A (en) * | 2015-05-21 | 2017-04-21 | 바이두 유에스에이 엘엘씨 | Multilingual image question answering |
Family Cites Families (32)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7617205B2 (en) * | 2005-03-30 | 2009-11-10 | Google Inc. | Estimating confidence for query revision models |
US20060074883A1 (en) * | 2004-10-05 | 2006-04-06 | Microsoft Corporation | Systems, methods, and interfaces for providing personalized search and information access |
JP2008537225A (en) * | 2005-04-11 | 2008-09-11 | テキストディガー，インコーポレイテッド | Search system and method for queries |
US7584177B2 (en) * | 2005-06-29 | 2009-09-01 | Google Inc. | Determination of a desired repository |
US7962479B2 (en) * | 2005-11-09 | 2011-06-14 | Yahoo! Inc. | System and method for generating substitutable queries |
US20080005069A1 (en) * | 2006-06-28 | 2008-01-03 | Microsoft Corporation | Entity-specific search model |
US9110975B1 (en) * | 2006-11-02 | 2015-08-18 | Google Inc. | Search result inputs using variant generalized queries |
US20100023495A1 (en) * | 2007-12-21 | 2010-01-28 | Yahoo! Inc. | System for suggesting keywords based on mobile specific attributes |
US7984004B2 (en) * | 2008-01-17 | 2011-07-19 | Microsoft Corporation | Query suggestion generation |
US10726083B2 (en) * | 2010-10-30 | 2020-07-28 | International Business Machines Corporation | Search query transformations |
US8583675B1 (en) * | 2009-08-28 | 2013-11-12 | Google Inc. | Providing result-based query suggestions |
US8762374B1 (en) * | 2010-03-08 | 2014-06-24 | Emc Corporation | Task driven context-aware search |
US8326861B1 (en) * | 2010-06-23 | 2012-12-04 | Google Inc. | Personalized term importance evaluation in queries |
RU2013124949A (en) * | 2010-10-30 | 2014-12-10 | БЛЕККО, Инк. | DYNAMIC DISPLAY OF SEARCH RESULTS |
US8521672B2 (en) * | 2010-11-22 | 2013-08-27 | Microsoft Corporation | Dependency-based query expansion alteration candidate scoring |
US8626681B1 (en) * | 2011-01-04 | 2014-01-07 | Google Inc. | Training a probabilistic spelling checker from structured data |
US20120191745A1 (en) * | 2011-01-24 | 2012-07-26 | Yahoo!, Inc. | Synthesized Suggestions for Web-Search Queries |
US20120269116A1 (en) * | 2011-04-25 | 2012-10-25 | Bo Xing | Context-aware mobile search based on user activities |
US10984337B2 (en) * | 2012-02-29 | 2021-04-20 | Microsoft Technology Licensing, Llc | Context-based search query formation |
US8984012B2 (en) * | 2012-06-20 | 2015-03-17 | Microsoft Technology Licensing, Llc | Self-tuning alterations framework |
US9141916B1 (en) * | 2012-06-29 | 2015-09-22 | Google Inc. | Using embedding functions with a deep network |
US9317585B2 (en) | 2013-03-15 | 2016-04-19 | Google Inc. | Search query suggestions based on personal information |
US9772994B2 (en) * | 2013-07-25 | 2017-09-26 | Intel Corporation | Self-learning statistical natural language processing for automatic production of virtual personal assistants |
US9535960B2 (en) * | 2014-04-14 | 2017-01-03 | Microsoft Corporation | Context-sensitive search using a deep learning model |
US9836554B2 (en) * | 2014-04-30 | 2017-12-05 | Excalibur Ip, Llc | Method and system for providing query suggestions including entities |
US10503733B2 (en) * | 2014-10-14 | 2019-12-10 | Google Llc | Assistive browsing using context |
US9910930B2 (en) * | 2014-12-31 | 2018-03-06 | TCL Research America Inc. | Scalable user intent mining using a multimodal restricted boltzmann machine |
US11899728B2 (en) * | 2015-10-05 | 2024-02-13 | Yahoo Assets Llc | Methods, systems and techniques for ranking personalized and generic search query suggestions |
US10055500B2 (en) * | 2015-10-27 | 2018-08-21 | International Business Machines Corporation | Optimizing searches |
US20170178048A1 (en) * | 2015-12-22 | 2017-06-22 | Microsoft Technology Licensing, Llc | Identification and presentation of tasks based on predicted periods of user availability |
US10769547B2 (en) * | 2015-12-30 | 2020-09-08 | Oath Inc. | Mobile searches utilizing a query-goal-mission structure |
WO2018097091A1 (en) | 2016-11-25 | 2018-05-31 | 日本電信電話株式会社 | Model creation device, text search device, model creation method, text search method, data structure, and program |
-
2018
- 2018-04-27 JP JP2019558737A patent/JP6918140B2/en active Active
- 2018-04-27 US US16/609,318 patent/US11663201B2/en active Active
- 2018-04-27 EP EP18724709.3A patent/EP3602349A1/en not_active Withdrawn
- 2018-04-27 CN CN201880028212.7A patent/CN110574021B/en active Active
- 2018-04-27 CN CN202311209572.6A patent/CN117312494A/en active Pending
- 2018-04-27 KR KR1020197035500A patent/KR102313472B1/en active IP Right Grant
- 2018-04-27 WO PCT/US2018/029834 patent/WO2018200979A1/en unknown
-
2023
- 2023-05-12 US US18/196,913 patent/US20230281193A1/en active Pending
Patent Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
KR20080072673A (en) * | 2005-11-30 | 2008-08-06 | 마이크로소프트 코포레이션 | Adaptive semantic reasoning engine |
US20120233140A1 (en) * | 2011-03-09 | 2012-09-13 | Microsoft Corporation | Context-aware query alteration |
KR20170043582A (en) * | 2015-05-21 | 2017-04-21 | 바이두 유에스에이 엘엘씨 | Multilingual image question answering |
Non-Patent Citations (1)
Title |
---|
大塚 淳史 외 4인, 답을 예측하는 문서검색수법의 제안, DEIM Forum 2017 B6-3, 2017.03.31. <URL: https://db-event.jpn.org/deim2017/papers/328.pdf> 1부.* * |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
KR20220155785A (en) * | 2021-05-17 | 2022-11-24 | 삼성생명보험주식회사 | Method and apparatus for operating chatbot |
Also Published As
Publication number | Publication date |
---|---|
KR102313472B1 (en) | 2021-10-15 |
WO2018200979A1 (en) | 2018-11-01 |
CN110574021B (en) | 2023-10-13 |
US11663201B2 (en) | 2023-05-30 |
US20230281193A1 (en) | 2023-09-07 |
JP6918140B2 (en) | 2021-08-11 |
EP3602349A1 (en) | 2020-02-05 |
US20200142888A1 (en) | 2020-05-07 |
CN117312494A (en) | 2023-12-29 |
JP2020518912A (en) | 2020-06-25 |
CN110574021A (en) | 2019-12-13 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
KR102313472B1 (en) | Generate query variants using a trained generative model | |
JP6854921B2 (en) | Multitasking neural network system with task-specific and shared policies | |
US20220004879A1 (en) | Regularized neural network architecture search | |
US11941527B2 (en) | Population based training of neural networks | |
US20170061341A1 (en) | Workflow management for crowd worker tasks with fixed throughput and budgets | |
CN107463701B (en) | Method and device for pushing information stream based on artificial intelligence | |
US10922611B2 (en) | Neural network optimizer search | |
CN109885842A (en) | Handle text neural network | |
WO2021027256A1 (en) | Method and apparatus for processing interactive sequence data | |
CN110476173B (en) | Hierarchical device placement with reinforcement learning | |
CN111737434A (en) | Generating automated assistant responses and/or actions directly from conversation histories and resources | |
CN111652378A (en) | Learning to select vocabulary of category features | |
US20230012316A1 (en) | Automation of leave request process | |
US10810493B1 (en) | Training and/or utilizing recurrent neural network model to determine subsequent source(s) for electronic resource interaction | |
CN111340605A (en) | Method and device for training user behavior prediction model and user behavior prediction | |
US20230359789A1 (en) | Varying embedding(s) and/or action model(s) utilized in automatic generation of action set responsive to natural language request | |
US11983634B2 (en) | Multi-task neural network systems with task-specific policies and a shared policy | |
Shan et al. | WebPut: A web-aided data imputation system for the general type of missing string attribute values | |
US20240061847A1 (en) | Set intersection approximation using attribute representations | |
WO2023059315A1 (en) | Stochastic optimization using machine learning | |
CN116802644A (en) | Machine learning ranking and predictive calibration | |
CN115033795A (en) | Individualized accurate education system based on condition generation type confrontation network | |
CN116467586A (en) | Model training method, device, equipment, medium and program product |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A201 | Request for examination | ||
E902 | Notification of reason for refusal | ||
E701 | Decision to grant or registration of patent right |