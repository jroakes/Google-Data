CN111344779A - Training and/or determining responsive actions for natural language input using coder models - Google Patents
Training and/or determining responsive actions for natural language input using coder models Download PDFInfo
- Publication number
- CN111344779A CN111344779A CN201880073730.0A CN201880073730A CN111344779A CN 111344779 A CN111344779 A CN 111344779A CN 201880073730 A CN201880073730 A CN 201880073730A CN 111344779 A CN111344779 A CN 111344779A
- Authority
- CN
- China
- Prior art keywords
- query
- encoding
- training
- encoder model
- response
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
- 238000012549 training Methods 0.000 title claims abstract description 280
- 230000009471 action Effects 0.000 title abstract description 55
- 230000004044 response Effects 0.000 claims abstract description 198
- 238000000034 method Methods 0.000 claims abstract description 78
- 230000000875 corresponding effect Effects 0.000 claims description 54
- 238000012545 processing Methods 0.000 claims description 43
- 230000008569 process Effects 0.000 claims description 11
- 238000004891 communication Methods 0.000 claims description 9
- 230000015654 memory Effects 0.000 claims description 7
- 230000001276 controlling effect Effects 0.000 claims description 3
- 238000006243 chemical reaction Methods 0.000 claims 1
- 238000004590 computer program Methods 0.000 claims 1
- 238000003062 neural network model Methods 0.000 abstract description 10
- 238000010801 machine learning Methods 0.000 abstract description 4
- 239000013598 vector Substances 0.000 description 19
- 238000010586 diagram Methods 0.000 description 10
- 230000006870 function Effects 0.000 description 8
- 238000013507 mapping Methods 0.000 description 7
- 239000003795 chemical substances by application Substances 0.000 description 5
- 230000000306 recurrent effect Effects 0.000 description 5
- 230000008094 contradictory effect Effects 0.000 description 4
- 230000000670 limiting effect Effects 0.000 description 4
- 239000000463 material Substances 0.000 description 4
- 230000007935 neutral effect Effects 0.000 description 4
- 230000002829 reductive effect Effects 0.000 description 4
- 238000013528 artificial neural network Methods 0.000 description 3
- 238000013527 convolutional neural network Methods 0.000 description 3
- 230000007246 mechanism Effects 0.000 description 3
- 230000006855 networking Effects 0.000 description 3
- 229920002803 thermoplastic polyurethane Polymers 0.000 description 3
- 230000009118 appropriate response Effects 0.000 description 2
- 230000002457 bidirectional effect Effects 0.000 description 2
- 238000004364 calculation method Methods 0.000 description 2
- 230000002452 interceptive effect Effects 0.000 description 2
- 238000003058 natural language processing Methods 0.000 description 2
- 230000002093 peripheral effect Effects 0.000 description 2
- 230000000644 propagated effect Effects 0.000 description 2
- 230000000007 visual effect Effects 0.000 description 2
- 230000004913 activation Effects 0.000 description 1
- 239000004973 liquid crystal related substance Substances 0.000 description 1
- 230000004048 modification Effects 0.000 description 1
- 238000012986 modification Methods 0.000 description 1
- 230000003287 optical effect Effects 0.000 description 1
- 230000036961 partial effect Effects 0.000 description 1
- 230000002085 persistent effect Effects 0.000 description 1
- 238000012552 review Methods 0.000 description 1
- 238000011524 similarity measure Methods 0.000 description 1
- 239000007787 solid Substances 0.000 description 1
- 238000013519 translation Methods 0.000 description 1
Images
Classifications
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/22—Procedures used during a speech recognition process, e.g. man-machine dialogue
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/33—Querying
- G06F16/332—Query formulation
- G06F16/3329—Natural language query formulation or dialogue systems
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/33—Querying
- G06F16/3331—Query processing
- G06F16/334—Query execution
- G06F16/3344—Query execution using natural language analysis
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/33—Querying
- G06F16/3331—Query processing
- G06F16/334—Query execution
- G06F16/3346—Query execution using probabilistic model
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/35—Clustering; Classification
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/30—Semantic analysis
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N5/00—Computing arrangements using knowledge-based models
- G06N5/04—Inference or reasoning models
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/08—Speech classification or search
- G10L15/18—Speech classification or search using natural language modelling
- G10L15/1822—Parsing for meaning understanding
Abstract
Systems, methods, and computer-readable media relate to: training an encoder model, the encoder model operable to determine (directly and/or indirectly) semantic similarity of the natural language text string to each of the one or more additional natural language text strings; and/or using the trained coder model to determine one or more responsive actions to perform in response to the natural language query. The encoder model is a machine learning model, such as a neural network model. In some implementations of training an encoder model, the encoder model is trained as part of a larger network architecture trained based on one or more tasks that are different from the "semantic text similarity" task that may use the encoder model.
Description
Background
A user interfaces with various applications using free-form natural language input. For example, a user may engage in a human-machine conversation using an interactive software application referred to herein as an "automated assistant" (also referred to as a "chat robot," "interactive personal assistant," "intelligent personal assistant," "personal voice assistant," "session agent," etc.). For example, a human being (which may be referred to as a "user" when they interact with an automated assistant) may provide commands, queries, and/or requests (collectively referred to herein as "queries") using free-form natural language input, which may be voiced utterances that are converted to text and then processed, and/or free-form natural language input by typing.
Many automated assistants and other applications are configured to perform one or more responsive actions in response to various queries. For example, in response to the natural language query "how are you," the automated assistant may be configured to output "great, thanks for asking" graphically and/or audibly in response to the query. As another example, in response to a query for "what's of the weather for tomorrow," an automated assistant may be configured (e.g., via an API) to interface with a weather agent (e.g., a third party agent) to determine a "local" tomorrow's weather forecast, and respond to the query with graphical and/or audio output conveying such weather forecast. As yet another example, in response to a user query for "play music video on my TV," an automated assistant may be configured to stream music videos on the user's web TV.
However, many automated assistants may not be able to perform actions that automated assistants may perform in response to various queries seeking to perform such actions. For example, an automated assistant may be configured to stream music videos on a user's web television in response to a query of "play music videos on my TV," but may not be able to perform such actions in response to various other queries such as "make a music videos of the music videos on the tube," although other queries seek to perform the same actions. Thus, the automated assistant will not perform the action expected by the query, but may provide a general error response (e.g., "I don't know how to do") or not respond at all.
Disclosure of Invention
Implementations of the present description are directed to systems, methods, and computer-readable media relating to: training an encoder model, the encoder model operable to determine (directly and/or indirectly) semantic similarity of the natural language text string to each of the one or more additional natural language text strings; and/or using the trained coder model to determine one or more responsive actions to perform in response to the natural language query. The encoder model is a machine learning model, such as a neural network model.
For example, some implementations use a trained coder model to process free-form natural language input for an automated assistant. Processing the free-form natural language input using the trained coder model generates an encoding of the free-form natural language input, e.g., an encoding of a vector of values. The codes are then compared to predetermined codes that each have one or more automated assistant actions mapped thereto (directly and/or indirectly mapped). The automated assistant action mapped to the predetermined code may include, for example, providing a particular response to the audible and/or graphical representation, providing a particular type of response to the audible and/or graphical representation, interfacing with a third party agent, interfacing with an internet of things (IoT) device, determining one or more values (e.g., "slot value") to include in a command to the agent and/or IoT device, and so forth. The predetermined encodings may each be an encoding of a corresponding text segment that has been assigned to a corresponding automated assistant action. Further, each predetermined encoding may be generated based on processing of the corresponding text segment using a trained encoder model. Further, the predetermined encoding is mapped to a corresponding automatic assistant action based on the corresponding automatic assistant action assigned to the text segment for which the predetermined encoding was generated. As one example, the predetermined encoding may be generated based on processing of "hello" using a trained encoder model, and the predetermined encoding may be mapped to an automatic assistant action that provides a response to a "nice thank you query" based on a response assigned to the text passage "hello" (e.g., previously manually assigned by a programmer of the automatic assistant).
A comparison (of the encoding of the free-form natural language input with the predetermined encoding) may be used to determine the predetermined encoding or encodings "closest" to the encoding. Actions that map to one or more "closest" predetermined codes may then be performed by the automated assistant, optionally depending on the "closest" predetermined codes being "close enough" (e.g., a distance threshold being met). As one example, each encoding may be a vector of values, and the comparison of the two encodings may be a dot product of the vectors, which results in a scalar value indicative of the distance between the two vectors (e.g., the scalar value may be from 0 to 1, where the size of the scalar value indicates the distance), and indicative of the semantic similarity of the two text segments based on which the encodings were generated.
As one particular example, the programmer may explicitly assign the automatic assistant action of "streaming music video on tv" to be assigned to the text segment "play music video on my tv", but may not explicitly assign the action (or any action) to the text segment "make some of the videos of a music track appear on the pipe". The text segment "play music video on my television" may be processed using a trained encoder model to generate an encoding of the text segment, and the encoding may be stored with a mapping of automatic assistant actions that "stream music video on television". Thereafter, the free-form natural language input "make some videos of the music track appear on the pipe" may be directed to the automated assistant based on user interface input from the user. The input "make some video of a music track appear on the pipe" may be processed using a trained encoder model to generate an encoding and compare the encoding to a predetermined encoding (including a predetermined encoding of "play music video on my television"). Based on this comparison, it may be determined that the predetermined encoding of "play music on my television" is closest to the encoding of "have some video of the music track appear on the pipe," and the proximity threshold is met. In response, the automated assistant can perform the action mapped to the predetermined code.
In these and other ways, the automated assistant robustly and accurately responds to various natural language inputs by performing appropriate automated assistant actions, even without explicitly mapping the automated assistant actions directly to the natural language inputs. This results in an improved automated assistant. In addition, from a computing resource perspective, it is effective to generate an encoding that "causes some of the music videos of a music track to appear on the pipe" as a comparison of the encoding to a predetermined encoding (because a simple dot product and/or other comparison may be used). Additionally, maximum internal product searching and/or other techniques may be used to further improve efficiency. This results in the automated assistant performing responsive actions faster (relative to other techniques) and/or determining responsive actions to perform (relative to other techniques) using less computing resources. Moreover, storing a mapping of codes to automated assistant actions may utilize storage space more efficiently than storing a mapping of complete text segments to automated assistant actions. In addition, fewer mappings of automatic assistant actions may be provided because a single predetermined encoding may semantically (in distance) represent multiple semantically similar text segments without mapping each of those text segments to an automatic assistant action. Further, where the automated assistant receives a query as a speech input, the resources required to process the speech input to determine the query (e.g., speech-to-text processing) may be reduced, as appropriate automated assistant actions may be performed without a failed query response requiring the user to enter another query in an attempt to obtain the desired results. Similarly, when a query is processed by a system that is remote from the automated assistant (e.g., when a component of the automated assistant is located on a device that is remote from the client device that provided the query), the resources required to send the query and receive an appropriate response may be reduced because appropriate automated assistant actions may be performed without having to send another query to attempt to obtain the same results. In this way, the use of network resources may be reduced.
Additionally and/or alternatively, implementations of the present specification relate to various techniques for training an encoder model. The encoder model is a machine learning model, such as a neural network model. Various encoder model architectures may be utilized, such as feedforward neural network models, recurrent neural network models (i.e., including one or more recurrent layers, such as long-short term memory (LSTM) layers and/or Gated Recurrent Unit (GRU) layers), recurrent and convolutional neural network models (i.e., including one or more convolutional layers and one or more recurrent layers), and/or transducer encoders.
In some implementations of training an encoder model, the encoder model is trained as part of a larger network architecture that is trained based on one or more tasks that are different from the "semantic text similarity" task (e.g., the semantic similarity task described above with respect to the automated assistant example) for which the encoder model may be used. In some of those implementations, the encoder model is trained as part of a larger network architecture that is trained to enable prediction of whether a text response is a true response to a text input. As a working example, training instances may be utilized, each training instance including training instance inputs comprising: input characteristics of the text input and response characteristics of the text response. The training instances each further include a training instance output that indicates whether the text response to the training instance input is an actual response to the text input to the training instance input. For the training example, a text response is used based on the text response being indicated as actually being a "response" to the text input in the dialog resource. For example, the text input may be an earlier-in-time email, text message, chat message, social networking message, internet comment (e.g., comment from an internet discussion platform), etc. of the first user, and the response may be a full or partial response email, text message, chat message, social networking message, internet comment, etc. of the additional user. For example, the text input may be an internet discussion and the response may be a reply to the internet discussion.
During training, and continuing the working example, the input features of the training instance input of the training instance are applied as input to the encoder model (without applying the response features of the training instance input), and the input encoding is generated based on processing the input using the encoder model. Further, response features of the training instance input are applied as input to the encoder model (without applying input features of the training instance input), and the response encoding is generated based on processing the input using the encoder model. The response code is further processed using an inference model to generate a final response code. The inference model may be a machine learning model, such as a feed forward neural network model. A response score is then determined based on a comparison of the input code and the final response code. For example, the response score may be based on a dot product of the input vector and the response vector. For example, the dot product may yield values from 0 to 1, where a "1" indicates the highest likelihood that the corresponding response is an appropriate response to the corresponding electronic communication and a "0" indicates the lowest likelihood. Then, both the inference model and the encoder model may be updated based on a comparison of: response scores (and optionally additional response scores in the batch processing techniques described herein); and a response score indicated by the training instance (e.g., "1" or other "positive" response score for positive training instance and "0" or other "negative" response score for negative training instance). For example, an error may be determined based on a difference between the response score and the indicated response score, and propagated back over the inference model and the encoder model.
With this training, the encoder model is trained to be used independently (i.e., without an inference model) to derive the corresponding encoding that provides a robust and accurate semantic representation of the corresponding input. Similarly, by training positive instances, each based on the text input and the actual response, and negative instances, each based on the text input and the non-actual response, of the text response, the semantic representation of the corresponding input is based at least in part on the text input and the actual text response; and learned differences between text input and text responses that are not actual responses. Further, training instances based on text input and text response can be efficiently generated in an unsupervised manner as described herein, and a large variety of training instances can be generated from one or more corpora (e.g., publicly available internet reviews as described herein). The use of such a large number of unsupervised and diverse training examples can result in a powerful encoder model that can be generalized to many different text segments.
After training, the encoder model (i.e., without the inference model) can be used independently to determine semantic similarity between two text strings (semantic text similarity task). For example, a first encoding of a first text string may be generated based on processing the first text string using a trained encoder model, and a second encoding of a second text string may be generated based on processing the second text string using the trained encoder model. Further, the two encodings may be compared to determine a score that indicates a degree of semantic similarity between the first text string and the second text string. For example, the score may be based on a dot product of the first encoding and the second encoding. For example, the dot product may yield values from 0 to 1, where "1" indicates the highest degree of similarity and "0" indicates the lowest degree of similarity (and highest degree of dissimilarity).
Such scores may be used for various purposes. Such scores may be used, for example, for various automated assistant purposes, such as those described above. As another example, a search engine may use such scores to determine one or more text queries that are semantically similar to the received text query. Further, since the score indicating the similarity between two text segments is based on a comparison of the corresponding encodings of the two text segments, the trained coder model can be used to predetermine the encodings of the various text segments (e.g., those explicitly assigned to corresponding response actions (e.g., corresponding automated assistant actions)), as well as those predetermined encodings that are stored (e.g., and mappings to their corresponding response actions). Thus, the similarity of an input natural language query to a given text segment may be determined by processing the natural language query using a trained coder model to generate a code, and then comparing the generated code to pre-stored codes for the given text segment. This eliminates the need to determine the pre-stored code at runtime, thereby saving various computing resources at runtime and/or reducing the latency of generating a response at runtime. Further, at runtime, an encoding of the natural language input query input vector is determined based on processing the query using the trained encoder model, and the same encoding of the natural language query may be compared to a plurality of predetermined encodings. This enables the encoding to be determined at runtime by a single call to the encoder model and used as compared to each of a plurality of predetermined encodings.
In some implementations of training an encoder model, the encoder model is trained as part of a larger network architecture that is trained based on a number of tasks that are different from the "semantic text similarity" task for which the encoder model may be used. In some of those implementations, the encoder model is trained based on a task that predicts whether the text response is a true response to the text input (e.g., as described above), and the encoder model is trained based on at least one additional task that is different from the semantic text similarity task. In those implementations, the encoder model is utilized and updated in the training for each task, but a different additional component of the larger network architecture is utilized and updated for each task. For example, the inference model described above may be used for a task of predicting whether a text response is a true response, and the determined error for that task is used to update the inference model and the encoder model during training. Also, for example, for an additional task, an additional model may be utilized, and the determined error for the additional task is used during training to update the additional model and the encoder model.
In various implementations of training an encoder model based on multiple tasks other than the "semantic text similarity" task, the encoder model is trained on multiple tasks simultaneously. In other words, the encoder model is not trained first for a first task, then for a second task after the training for the first task is completed, and so on. Instead, one or more updates of the weights of the encoder model (e.g., by one or more back-propagation of errors) may be based on a first task, then one or more updates of the weights of the encoder model may be based on a second task, then one or more updates of the weights of the encoder model may be based on the first task, then one or more updates of the weights of the encoder model may be based on the second task, and so on. In some of these various implementations, separate workers (computer work) may be utilized in the training, and each worker trains only the corresponding task using a batch of training instances for the corresponding task. A different number of workers may be involved in the tasks to adjust the impact of each task in training the encoder model. As one example, 95% of workers may be trained on whether the predictive text response is a true response task, while 5% of workers may be trained on additional tasks.
Various additional tasks may be utilized, and various additional network architecture components other than the encoder model may be utilized. One example of an additional task is a natural language inference task, which may be trained using supervised training instances (e.g., from a Stanford Natural Language Inference (SNLI) dataset). Such training instances each include a pair of text segments as training instance inputs, and a training instance output that is an artificial label for one of a plurality of categories (e.g., entailment, contradictory, and neutral categories) of the pair of text segments. The accessory network architecture components that may be used for natural language inference tasks may include feed forward neural network models, such as models with fully connected layers and softmax layers.
In training for natural language inference tasks, a first segment of text of a training instance input of a training instance is applied as input to an encoder model (without applying a second segment of text of the training instance input), and a first encoding is generated based on processing the input using the encoder model. Further, the second text segment of the training instance input is applied as an input to the encoder model (without applying the first text segment of the training instance input), and the second encoding is generated based on processing the input using the encoder model. The feature vector may be generated based on the first encoding and the second encoding, e.g., (u)1,u2,|u1-u2|,u1*u2) A feature vector of (1), wherein u1Represents the first code, u2Representing the second code. Feature vectors may be processed using a feed-forward neural network model for natural language inference tasks to generate predictions for each of a plurality of classes (e.g., entailment, contradictory, and neutral classes). The label classes of the prediction and training instance outputs of the training instance may be compared and a feed-forward neural network model of the natural language inference task updated based on the comparison (and optionally additional comparisons of the batch processing technique natural language inference task described herein). For example, the error may be determined based on the comparison and propagated back on the two models.
Various implementations disclosed herein may include one or more non-transitory computer-readable storage media storing instructions executable by a processor (e.g., a Central Processing Unit (CPU), a Graphics Processing Unit (GPU), and/or a Tensor Processing Unit (TPU)) to perform a method, such as one or more of the methods described herein. Other various implementations may include a system of one or more computers including one or more processors operable to execute stored instructions to perform a method, such as one or more of the methods described herein.
It should be understood that all combinations of the foregoing concepts and additional concepts described in greater detail herein are considered a part of the subject matter disclosed herein. For example, all combinations of claimed subject matter appearing at the end of this disclosure are considered part of the subject matter disclosed herein.
Drawings
Fig. 1 illustrates an example of training an encoder model according to some implementations disclosed herein.
Fig. 2A illustrates an example of an encoder model according to some implementations disclosed herein.
Fig. 2B illustrates another example of an encoder model according to some implementations disclosed herein.
Fig. 2C illustrates yet another example of an encoder model according to some implementations disclosed herein.
Fig. 3 illustrates another example of training an encoder model according to some implementations disclosed herein.
Fig. 4 is a flow diagram illustrating an example method of training an encoder model according to some implementations disclosed herein.
FIG. 5 is a flow diagram illustrating an example method of generating a code for a text segment assigned to a responsive action.
FIG. 6 is a flow diagram illustrating an example method for using a trained coder model to determine one or more responsive actions to perform in response to a natural language query.
FIG. 7 illustrates an example architecture of a computing device.
Detailed Description
Semantic Text Similarity (STS) is a task for measuring the similarity or equivalence of two text segments. Accurately measuring similarity is a fundamental language understanding problem in the sense that it applies to many Natural Language Processing (NLP) challenges, including machine translation, summarization, problem solving, and semantic searching.
Implementations disclosed herein relate to training an encoder model and/or embedding (also referred to herein as encoding) that utilizes the trained encoder model to generate text segments. Further, implementations relate to comparing a given embedding of a given text segment with an embedding of additional text segments to determine one or more embeddings that are closest to the given embedding. In some of those implementations, the given text segment is a query, the embedding that most closely maps to the given embedding is mapped to one or more responsive actions, and the responsive action is performed in response to the query based on the embedding that most closely maps to the responsive action.
In various implementations, the encoder model is trained as part of a larger network architecture that is trained based on one or more tasks other than the "semantic text similarity" task (e.g., the semantic similarity task described above with respect to the automated assistant example) for which the encoder model may be used. In some of those implementations, the encoder model is trained as part of a larger network architecture that is trained to enable prediction of whether a text response is a true response to a text input. Such training may utilize training instances that include training instance inputs including: input characteristics of the text input and response characteristics of the text response. Text input and responses may be determined from one or more conversational corpora in an unsupervised manner. As one non-limiting example, training instances may be determined based on structured conversation data from one or more internet discussion platform corpuses. Such a corpus may contain millions of posts and billions of comments, as well as metadata about the author of the comment and the previous comments the comment replied to. If comment A replies to comment B, "comment A" in the corpus is referred to as a child object of "comment B" in the corpus. Comments and their children may be extracted from the corpus to form textual inputs, textual response pairs for the training instance. One or more rules may be selectively applied to filter out certain comments from the training instance. For example, a comment may be excluded if it meets one or more of the following conditions: the number of characters ≧ a threshold (e.g., 350), the percentage of alphabetic characters ≦ a threshold (e.g., 70%), beginning with "https", "/r/" or "@", and/or the author's name contains "bot" and/or other terms. Even if these filters and/or other filters are applied, millions of inputs can be determined from such a corpus, response pairs, and used to generate positive training instances.
When training an encoder model as part of a larger network architecture that is trained to predict whether a text response is a true response to a text input, the task of determining whether a text response is a true response to a text input may be modeled as P (y | x) in order to rank all possible text responses (y) given a text input (x). More formally:
since the total number of text responses is too large, it is difficult to calculate the probability of a text response y for all other text responses. Thus, the probability can be approximated by computing the probability for randomly sampled K-1 responses-the above equation can be written as:
a larger network architecture (including the encoder model) can be trained to estimate the joint probability of all possible text inputs, text responses to P (x, y). Discriminant training may be utilized that uses the softmax function to maximize the probability of a true response y. Thus, it can be expressed as
in training the encoder model as beingWhen training to be able to predict whether a text response is part of a larger network architecture for a true response to a text input, the goal is to train the encoder model so that it can be used for general text embedding that generates text segments. Since the goal is to learn general text embedding, and each training instance includes a training instance input with a text input and a text response, both the text input and the text response of the training instance input are processed (but separately) using the same encoder model to generate an encoding vector u for the text input and an encoding vector v for the text response. Next, the encoding vector v for the text response is further fed into a feed-forward neural network (inference model) to obtain a final response vector v'. After the input and response are encoded, the dot product uTv' is used to obtain the final score. In the training process, for a training batch of K input-response pairs, the inputs are paired with all responses in the same batch and fed into the scoring model, and the above training objectives are used to maximize the probability of a true response.
Turning now to fig. 1, an example of training the encoder model 130 is provided, where the encoder model 130 is trained as part of a larger network architecture (also including an inference network model 140) that is trained to be able to predict whether a text response is a true response to a text input.
Fig. 1 includes an input response resource 101. The input response resources 101 may include one or more conversation resources, such as threads in an internet discussion platform, chat messages, social networking messages, and the like. The training instance engine 170 utilizes the input response resource 101 to automatically generate an input response training instance 190. Each input responsive training instance 190 includes training instance inputs including: input characteristics of a text input determined from resource 101, and response characteristics of a text response determined from resource 101. Each input response training instance 190 also includes a training instance output that indicates whether the text response of the corresponding training instance input is an actual response to the text input of the training instance input. For the training instance, the text response is utilized based on being indicated as actually a "response" to the text input in the dialog resource.
In some implementations, the training instance engine 170 only generates and stores positive training instances. In some of those implementations, a negative training instance is generated at training time based on the batch of positive training instances used for training. For example, six negative training instances may be generated based on a batch of three positive training instances. For example, two negative training instances may be generated based on pairing an input text segment (of the training instance input) of a given training instance with each of the response text segments (of the training instance input) of the other two training instances (assuming that the response text segments of the other two training instances are not "true" responses to the input text segment of the given text segment). In some versions of those implementations, the negative training instances are efficiently generated by considering the various encodings generated during training, as described in more detail herein.
In FIG. 1, training engine 180 retrieves training instance 191A from input-response training instance 190. The training engine 180 may be implemented by one or more processors. The training instance includes input 191A1, response 191A2, and an indication. As described herein, the input 191a1 may be based on a text input determined from a dialog resource. The input 191A1 may be the text input itself, or a representation thereof, such as a bag of words of various n-grams (e.g., unigram, bigram, trigram, and/or other n-grams) embedded in a text passage, all or part of a text passage embedded based on another model (e.g., a GloVE embedding model and/or a Word2Vec embedding model), and/or other representations. As described herein, the response 191a2 may be based on a textual response determined from a dialog resource. Response 191a2 may be the text response itself or a representation thereof. This indication indicates whether training instance 191A is a negative training instance or a positive training instance (i.e., whether response 191A2 is for a response that is a true response to the communication upon which input 191A2 is based). In some implementations, the indication may be omitted. For example, input response training instance 190 may store only "positive" inputs and responses, and may assume a "positive" label for training instances from input response training instance 190.
The training engine 180 processes the response code 191B2 using the inference network model 140 to generate a final response code 197A. Inference network model 140 effectively (through training) transforms response encodings into an "input" space.
The similarity metric module 122 determines a value based on a comparison of the input encoding 191B1 and the final response encoding 197A. For example, the similarity measure module 122 may determine a value that is a scalar result of a dot product between the final response encoding 197A and the transpose of the input encoding 191B 1.
The similarity metric module 122 provides the values to an error module 182, which error module 182 may be a module of the training engine 180. Error module 182 determines error 183A (if any) based on a comparison of the value with a positive or negative indication 191A3 provided by training engine 180 for training instance 191A. The positive or negative indication 191A3 may be based on the indication of training instance 191A (if any), or may be inferred as described above. For example, if training instance 191A is a positive training instance, then indication 191A3 may be a "1" (or other value), whereas if training instance 191A is a negative training instance, then indication 191A3 may be a "0" (or other value). The error module 182 then updates both the inference network model 140 and the encoder model 130 based on the error (optionally based on other errors determined for the batch when the training instance 191A of fig. 1 is part of the batch of training instances using batch learning and based on the error). For example, the error module 182 may perform back propagation on the inference network model 140 and the encoder model 130 based on the error and loss functions.
Although fig. 1 is shown for a single training instance, it should be understood that during training, a large number of training instances will be utilized in the training.
Turning now to fig. 2A-2C, various examples of an encoder model 130 are provided. 2A-2C specifically illustrate various implementations, encoder models having different architectures may be trained in accordance with the techniques described herein. For illustrative purposes, the encoder model of fig. 2A-2C is illustrated as input encoding 191B1 used to generate input 191a 1. It should be understood that these models may also be used to generate the response encoding 191B2 of the response 191a2, and that different encoder models may generate different encodings.
Fig. 2A shows a first encoder model 130A, which is one implementation of the encoder model 130. The first encoder model 130A is a Deep Neural Network (DNN), which is a feed-forward network with multiple Tanh layers 131a1-131 AN. In some implementations, the input 191A1 applied to the first encoder model 130A can be a bag of n-gram representations. The bag n-gram representation may be included in the training instance or may be generated from a text passage (either in the training instance or at the time of inference). In some implementations, to build a DNN encoder with a pocket of n-grams, n-gram features can be extracted from a large number (e.g., all) of session resources. For each n-gram feature, a fixed size of embedding can be learned during the training process. Finally, the embedded values can be summed over each dimension of all n-gram features in a comment, then divided by the square root of the comment length. The final vector may be used as input to the DNN encoder.
Fig. 2B shows a second encoder model 130B, which is another implementation of the encoder model 130. The second encoder model 130B includes a bi-directional LSTM layer 132B3 built on top of one or more Convolutional Neural Network (CNN) layers 132B 2. The second encoder model 130B also includes a word input layer 132B1, where the embedding of each n-gram of a text segment can be used as input. Sequences (w) of words (and/or other n-grams) in a given text segment1,w2,...,wt) Each word may be embedded in a vector. Convolutional layer 132B2 is then used to perform convolution on the embedded word vector using the tanh activation function. Note that the number of filters of convolutional layer 132B2 is the same as the dimension of word embedding. The output sequence is then processed using bidirectional LSTM
Wherein
Fig. 2C shows a third encoder model 130C, which is another implementation of the encoder model 130. The third encoder model 130C is a model with a converter architecture. The converter architecture uses a lot of attention mechanisms, largely eliminating repetition and convolution. Although some converter architectures include an encoder and a decoder, only the encoder components are included in fig. 2C. Since the converter encoder output is a variable length sequence, it can be reduced to a fixed length by calculating the average of all sequence positions. The third encoder model 130C includes multi-head attention 133C2, add and normalize 133C3, feed forward 133C4, and add and normalize 133C5 components. The input embedding 133C1 of the input 191a1 may be applied as an input to the third encoder model 130C.
In some implementations of training the encoder model, the encoder model is trained as part of a larger network architecture trained based on a number of tasks that are different from the "semantic text similarity" task that may use the encoder model 130. In some of those implementations, the encoder model 130 is trained based on a task that predicts whether the text response is a true response to the text input (e.g., as described above), and the encoder model 130 is trained based on at least one additional task that is also different from the semantic text similarity task.
One example of an additional task is a natural language inference task, which may be trained using supervised training instances (e.g., from a Stanford Natural Language Inference (SNLI) dataset). Such training instances each include a pair of text segments as training instance inputs, and a training instance output that is an artificial label for one of a plurality of categories (e.g., entailment, contradictory, and neutral categories) of the pair of text segments. Additional network architecture components that may be used for natural language inference tasks may include feed forward neural network models, such as models with fully connected layers and softmax layers.
Turning now to fig. 3, one example of training the encoder model 130 as part of training a larger network architecture based on multiple tasks is shown. In fig. 3, the input response training instance 190 is used to generate an error that is used to update the inference network model 140 and the encoder model 130 in the same manner as described with respect to fig. 1.
Fig. 3 also includes NLI training examples 192, which may include, for example, those from the SNLI data set described above. Training engine 180 retrieves training instance 192A from NLI training instance 192. Training instance 192A includes training instance inputs of first input 192A1 and second input 192A2, and training instance outputs 192A3 that indicate labels of the categories of the first and second inputs (e.g., that are implied, contradictory, or neutral with respect to one another).
The training engine 180 processes the first input encoding 192B1 and the second input encoding 192B2 using the additional model 150 to generate predictions of the classes of the inputs 192A1 and 192A2 of the training instance 192A. In particular, in FIG. 3, training engine 180 constructs feature vectors 151 (u)1,u2,|u1-u2|,u1*u2) Wherein u is1Represents the first input encoding 192B1, and u2Representing second input encoding 192B 2. The feature vectors are fed into a three-way classifier comprising a fully connected layer 152 and three (for three classes) softmax layers 153 to generate a prediction of the class.
The error module 182 determines the error 184A (if any) based on a comparison of the predicted class and the labeled class 192A3 provided by the training engine 180 for the training instance 192A. Error module 182 then updates both additional model 150 and encoder model 130 based on error 184A (and optionally other errors determined based on the batch when batch learning is used and training example 192A of fig. 3 is part of the batch of training examples from NLI training example 192). For example, the error module 182 may perform back propagation on the additional model 150 and the encoder model 130 based on the error and loss functions.
Although fig. 3 is shown with respect to a single training instance 192A, it should be understood that during training, a large number of training instances from NLI training instance 192 will be utilized in the training.
With training based on fig. 3, encoder model 130 is updated based on the errors determined based on input response training instance 190 and based on the errors determined based on NLI training instance 192. The encoder model 130 may be trained on these different tasks simultaneously. In other words, the encoder model 130 is not trained first based on the input response training instance 190, and then the NLI training instance 192 is trained after the training of the input response training instance 190 is completed. Instead, one or more updates to the weights of the encoder model 130 (e.g., via one or more back-propagation of errors) may be based on the input response training instance 190, then one or more updates to the weights of the encoder model 130 may be based on the NLI training instance 192, then one or more updates to the weights of the encoder model 130 may be based on the input response training instance 190, then one or more updates to the weights of the encoder model may be based on the NLI training instance 192, and so on. In some of the various implementations, independent workers (computer work) may be utilized in the training, and each worker trains only the corresponding task using a batch of training instances for the corresponding task. A different number of workers may be invested in the tasks to adjust the impact of each task in the encoder model training.
Turning now to fig. 4, a flow diagram is provided that illustrates a method 400 of training an encoder model in accordance with various implementations disclosed herein. For convenience, the operations of the flow diagrams are described with reference to a system that performs the operations. The system may include one or more components, such as one or more processors (e.g., CPUs, GPUs, and/or TPUs). While the operations of method 400 are shown in a particular order, this is not meant to be limiting. One or more operations may be reordered, omitted, or added.
At block 452, the system identifies a batch of training instances. For example, each training instance may be a training instance with an input, a response, and an indication of whether the training instance is a positive instance or a negative instance (e.g., whether the response is a "true" response to the input).
At block 454, the system selects a training instance for the batch.
At block 456, the system generates an input encoding based on processing the input of the selected training instance using the encoder model.
At block 458, the system generates a response encoding based on processing the response of the selected training instance using the encoder model.
At block 460, the system generates a final response encoding based on processing the response encoding in block 458 on the inference model.
In block 462, the system determines a correlation value based on the input encoding of block 456 and the final response encoding of block 460.
In block 464, the system determines an error for the training instance based on a comparison of the correlation value in block 462 with the correlation value indicated by the training instance. For example, where the training instance is a positive training instance, the response score indicated by the training instance may be a "1" or other "positive" value.
In block 464, the system determines whether there are any other unprocessed training instances in the batch. If so, the system proceeds to block 454 and selects an additional training instance. The system then performs blocks 456, 458, 460, 462, and 464 based on the additional training instances.
If at an iteration of block 466, the system determines that there are no other unprocessed training instances in the batch, the system proceeds to block 468.
At block 468, the system determines additional negative response scores based on the dot product of the input encoding and the final response encoding based on different training examples. For example, the system may determine an additional negative response score based on a dot product of the input encoding generated based on the first training instance at block 456 and the final response encoding generated based on the second, different training instance at block 460. By using an input encoding and a final response encoding generated based on two different training instances, it can be assumed that the corresponding inputs and responses are not based on "actual" input response pairs. Accordingly, it may be assumed that the additional response score generated at block 468 is an additional "negative" response score (i.e., generated with respect to a valid "negative" training instance). Execution of block 468 effectively provides additional negative training instances while enabling reuse of previously generated input encodings and final response encodings. In other words, additional negative training instances are effectively obtained without the need for computationally intensive further input encoding and generation of final response encoding.
As a specific example, assume that the batch of block 452 consists of 100 training instances. After training based on 100 positive training instances, 100 input encodings and 100 final response encodings have been generated. A first "negative" correlation value may be generated based on a dot product of a first input encoding of a first training instance and a second final response encoding of a second training instance. A second "negative" correlation value may be generated based on a dot product of the first input encoding and a third final response encoding of a third training instance. Other "negative" correlation values may be determined based on the dot product of the first input encoding and the final response encoding of the fourth through one hundred training instances. Furthermore, 99 "negative" correlation values may be similarly determined based on the input encoding of the second training instance and the final response encoding of the other training instances (not those of the second training instance); similarly, 99 "negative" correlation values are determined based on the input encoding of the third training instance and the final response encoding of the other training instances (those that are not the third training instance); and so on. Correspondingly, 9,900 "negative" correlation values can be generated by a dot product calculation that is effective based on the relative calculation of the codes that the positive training instances have generated. Further, the total error may be determined (at block 472 below) based on all "negative" correlation values and a function (e.g., softmax function) of the total error that counter-propagates (at block 474) across the input and response encoder models.
At block 470, the system determines additional errors based on the additional negative response scores determined at block 468. In particular, because the response score determined at block 468 is considered for additional negative examples, the system determines additional errors based on a comparison of the negative response score of block 468 to a "0" or other "negative" value.
At block 472, the system determines the error for the lot. The error for the batch may be based on the error determined in the iterations of block 464 and block 470.
At block 474, the system back-propagates batch-based errors on the encoder model and the inference model.
The system may then identify a new batch of training instances and restart method 400 for the new batch. Such training may continue until one or more criteria are met. Although fig. 4 illustrates a particular batch training method, it should be understood that non-batch training may additionally or alternatively be utilized in training. Also, in some implementations, blocks 468 and 470 may be omitted and/or other blocks may be omitted or added. Further, although FIG. 4 illustrates training based on a single task, multi-task training may also be utilized as described herein.
Turning now to fig. 5, a flow diagram is provided that illustrates a method 500 of generating encoding for a text segment assigned to a responsive action in accordance with various implementations disclosed herein. For convenience, the operations of the flow diagrams are described with reference to a system that performs the operations. The system may include one or more components, such as one or more processors (e.g., CPUs, GPUs, and/or TPUs). Although the operations of method 500 are shown in a particular order, this is not meant to be limiting. One or more operations may be reordered, omitted, or added.
At block 552, the system identifies a text segment assigned to the response action, for example, a text segment assigned to an automated assistant response action.
At block 554, the system generates an encoding based on the processing of the text segment using the trained encoder model.
At block 556, the system stores the association of the encoding and the response action.
In block 558, the system determines whether additional text segments exist. If so, the system proceeds to block 552 and identifies additional text segments. Additional text segments may be assigned to the same responsive action or to another responsive action. The system then performs blocks 554 and 556 based on the additional text segment.
If, at an iteration of block 558, the system determines that there are no additional text segments, the system ends method 500. Through multiple iterations of blocks 552, 554, and 556, multiple encodings of multiple text segments may be generated and multiple associations of encodings with corresponding responsive actions stored. For example, multiple encodings of multiple text segments may be stored in association with a first automatic assistant response action, multiple encodings of multiple text segments may be stored in association with a second automatic assistant response action, and so on.
Turning now to fig. 6, a flow diagram is provided that illustrates a method 600 of using a trained encoder model to determine one or more response actions to perform in response to a natural language query, in accordance with various implementations disclosed herein. For convenience, the operations of the flow diagrams are described with reference to a system that performs the operations. The system may include one or more components, such as one or more processors (e.g., CPUs, GPUs, and/or TPUs). Although the operations of method 600 are shown in a particular order, this is not meant to be limiting. One or more operations may be reordered, omitted, or added.
At block 652, the system receives the query. The query may be provided, for example, as a spoken utterance or as a typed query.
At block 654, the system generates a query encoding based on processing of the query using the trained encoder model. For example, where the query is a spoken utterance, speech-to-text processing that captures audio data of the spoken utterance may be performed, and the generated text may be processed using a trained encoder model to generate the query encoding. Also, for example, where the query is a typed query, the text of the typed query can be processed using a trained encoder model to generate a query encoding.
At block 656, the system identifies the responsive action based on a comparison of the code generated in block 654 with a pre-stored code associated with the corresponding responsive action. For example, the system may identify a response action with a pre-stored code that is closest in distance in the embedding space to the code generated in block 654. In some implementations, the system identifies the responsive action based on its pre-stored code being closest to the code generated in block 654 and based on the pre-stored code satisfying a proximity threshold with respect to the code generated in block 654.
At block 658, the system performs a response action in response to the received query.
Fig. 7 is a block diagram of an example computing device 710 that may optionally be used to perform one or more aspects of the techniques described herein. The computing device 710 includes at least one processor 714 (e.g., a CPU, GPU, and/or TPU) that communicates with a plurality of peripheral devices via a bus subsystem 712. These peripheral devices may include a storage subsystem 724 (including, for example, a memory subsystem 725 and a file storage subsystem 726), a user interface output device 720, a user interface input device 722, and a network interface subsystem 715. Input devices 722 and output devices 720 allow a user to interact with computing device 710. Network interface subsystem 715 provides an interface to external networks and couples to corresponding interface devices in other computing devices.
The user interface input devices 722 may include a keyboard, a pointing device such as a mouse, trackball, touchpad, or tablet, a scanner, a touch screen incorporated into a display, an audio input device such as a voice recognition system, microphone, and/or other types of input devices. In general, use of the term "input device" is intended to include all possible types of devices as well as the manner in which information is input into computing device 710 or a communication network.
User interface output devices 720 may include a display subsystem, a printer, a fax machine, or a non-visual display such as an audio output device. The display subsystem may include a Cathode Ray Tube (CRT), a flat panel device such as a Liquid Crystal Display (LCD), a projection device, or other mechanism for creating a conventional image. The display subsystem may also provide non-visual displays, for example, via an audio output device. In general, use of the term "output device" is intended to include all possible types of devices as well as ways to output information from computing device 710 to a user or to another machine or computing device.
These software modules are typically executed by processor 714 alone or in combination with other processors. Memory subsystem 725, used in storage subsystem 724, may include a number of memories, including a main Random Access Memory (RAM)730 for storing instructions and data during program execution and a Read Only Memory (ROM)732 in which fixed instructions are stored. File storage subsystem 726 may provide persistent storage for program and data files, and may include a hard disk drive, a solid state drive, a floppy disk drive along with associated removable media, a CD-ROM drive, an optical disk drive, or a removable media cartridge. Modules implementing the functionality of some implementations may be stored by file storage subsystem 726 in storage subsystem 724 or in other machines accessible by processor 714.
In some implementations, a method implemented by one or more processors is provided that includes identifying a plurality of training instances that each include an input and a response. For each of the positive training instances: the input is based on content of the corresponding electronic communication, and the reply is based on a corresponding responsive electronic communication that is responsive to the corresponding electronic communication. The method also includes training the encoder model based on the positive training instance. Training the encoder model based on a given instance of the training instance includes: generating an input encoding based on processing the input using an encoder model; generating a response encoding based on processing the response using the encoder model; generating a final response code based on processing the response code using the inference model; determining a value based on a comparison of the input code and the final response code; and updates both the inference model and the encoder model based on a comparison of the value with a given value indicated by the given instance.
These and other implementations of the techniques disclosed herein may include one or more of the following features.
In some implementations, the method further includes training the encoder model based on a plurality of different additional training instances, where the plurality of different additional training instances are for different tasks than the tasks of the plurality of training instances. Training the encoder model based on given different instances of different additional training instances may include: generating a first encoding based on processing a first input given different instances using an encoder model; generating a second encoding based on processing a second input given a different instance using the encoder model; generating a prediction based on processing the first encoding and the second encoding using additional models, wherein the additional models are not utilized in training the encoder model based on the positive training instance; and updating both the additional model and the encoder model based on a comparison of the prediction to the tagged output given the different instances. The markup output can indicate, for example, a particular category of a plurality of potential categories of the natural language inference task. Training the encoder model based on a plurality of different additional training instances may occur simultaneously with training the encoder model based on the training instance being trained. Training the encoder model based on a plurality of different additional training instances may be by one or more first worker threads, and training the encoder model based on a training instance is by one or more second worker threads.
In some implementations, the method further includes, after training the encoder model: a similarity value for the two text segments is determined using the trained encoder model, independent of the inference model, wherein the similarity value indicates semantic similarity of the two text segments. Determining a similarity value for two text segments using the trained encoder model may include: receiving a query for an automated assistant; generating a query encoding based on processing the query using the trained encoder model; comparing the query encoding to a plurality of predetermined query encodings, each predetermined query encoding stored in association with one or more corresponding actions; determining a given predetermined query code that is most similar to the query code based on the comparison; and in response to the query and based on a given predetermined query code that is most similar to the query code, cause the automated assistant to perform one or more corresponding actions stored in association with the given predetermined query code. The method may further comprise: a distance between the query encoding and a given predetermined query encoding is determined to satisfy a proximity threshold, and the automated assistant may be further caused to perform one or more corresponding actions in response to determining that the distance satisfies the proximity threshold. Comparing the query encoding to a plurality of predetermined query encodings may include: generating a plurality of scalar values, each scalar value being based on a corresponding dot product of a query encoding and a corresponding one of a given predetermined query encoding; based on the comparison, determining a given predetermined query encoding that is most similar to the query encoding may comprise: the given predetermined query encoding is selected based on the scalar value based on the dot product of the query encoding and the given predetermined query encoding being the smallest of the generated plurality of scalar values. The query may be a query that is not explicitly mapped to one or more corresponding actions by the automated assistant. The query may be based on user input received at the first computing device, and the one or more corresponding actions may include controlling one or more additional devices.
In some implementations, there is provided a method implemented by one or more processors, the method comprising: the encoder model is trained simultaneously based on a plurality of first training instances customized for a first task and based on a plurality of second training instances customized for a second task. The first task is different from the second task, and the first task and the second task are different from the semantic text similarity task. The method further comprises, after training the encoder model: semantic text similarity of two text segments is determined using a trained encoder model.
In some implementations, there is provided a method implemented by one or more processors, the method comprising: receiving a query for an automated assistant; and generating a query encoding based on processing the query using the trained encoder model; comparing the query encoding to a plurality of predetermined query encodings, each predetermined query encoding stored in association with one or more corresponding actions; determining a given predetermined query code that is most similar to the query code based on the comparison; and in response to the query and based on a given predetermined query code that is most similar to the query code, cause the automated assistant to perform one or more corresponding actions stored in association with the given predetermined query code.
Although several implementations have been described and illustrated herein, one or more of a variety of other means and/or structures for performing the function and/or obtaining the result and/or the advantages described herein may be utilized and each such variation and/or modification is considered to be within the scope of the implementations described herein. More generally, all parameters, dimensions, materials and/or configurations will depend on the particular application or applications for which the teachings are used. Those skilled in the art will recognize, or be able to ascertain using no more than routine experimentation, many equivalents to the specific implementations described herein. It is, therefore, to be understood that the foregoing implementations are presented by way of example only and that, within the scope of the appended claims and equivalents thereto, implementations may be practiced otherwise than as specifically described and claimed. Implementations of the present disclosure are directed to each individual feature, system, article, material, kit, and/or method described herein. In addition, any combination of two or more such features, systems, articles, materials, kits, and/or methods, if such features, systems, articles, materials, kits, and/or methods are not mutually inconsistent, is included within the scope of the present disclosure.
Claims (23)
1. A method implemented by one or more processors, comprising:
identifying a plurality of positive training instances that each include an input and a response, wherein for each of the positive training instances:
the input is based on the content of the corresponding electronic communication, an
The reply is based on a corresponding responsive electronic communication that is responsive to the corresponding electronic communication;
training an encoder model based on the positive training instances, wherein training the encoder model based on a given instance of the positive training instances comprises:
generating an input encoding based on processing the input using the encoder model;
generating a response encoding based on processing the response using the encoder model;
generating a final response code based on processing the response code using an inference model;
determining a value based on a comparison of the input encoding and the final response encoding; and
updating both the inference model and the encoder model based on a comparison of the value with a given value indicated by the given instance; and is
After training the encoder model:
determining a similarity value for two text segments using a trained encoder model, independent of the inference model, wherein the similarity value indicates semantic similarity of the two text segments.
2. The method of claim 1, further comprising:
training the encoder model based on a plurality of different additional training instances, wherein the plurality of different additional training instances are for different tasks than the tasks of the plurality of training instances.
3. The method of claim 2, wherein training the encoder model based on a given different instance of the different additional training instances comprises:
generating a first encoding based on processing a first input of the given different instance using the encoder model;
generating a second encoding based on processing a second input of the given different instance using the encoder model;
generating a prediction based on processing of the first encoding and the second encoding using an additional model, wherein the additional model is not used in training the encoder model based on the positive training instance; and
updating both the additional model and the encoder model based on a comparison of the prediction to a labeled output of the given different instance.
4. The method of claim 3, wherein the tagged output indicates a particular category of a plurality of potential categories of natural language inference tasks.
5. The method of claim 3 or claim 4, wherein training the encoder model based on the plurality of different additional training instances occurs simultaneously with training the encoder model based on the positive training instance.
6. The method of claim 5, wherein training the encoder model based on the plurality of different additional training instances is by one or more first worker threads, and wherein training the encoder model based on the training instance is by one or more second worker threads.
7. The method of any preceding claim, wherein determining a similarity value for the two text segments using a trained encoder model comprises:
receiving a query for an automated assistant;
generating a query encoding based on processing the query using a trained encoder model;
comparing the query encoding to a plurality of predetermined query encodings, each predetermined query encoding stored in association with one or more corresponding actions;
determining a given predetermined query code that is most similar to the query code based on the comparison; and
in response to the query and based on a given predetermined query encoding that is most similar to the query encoding, causing the automated assistant to perform one or more corresponding actions stored in association with the given predetermined query encoding.
8. The method of claim 7, further comprising:
determining that a distance between the query code and the given predetermined query code satisfies a proximity threshold;
wherein causing the automated assistant to perform one or more corresponding actions is further in response to determining that the distance satisfies the proximity threshold.
9. The method of claim 7 or claim 8, wherein comparing the query encoding to the plurality of predetermined query encodings comprises:
generating a plurality of scalar values, each scalar value based on a corresponding dot product of the query encoding and a corresponding given one of the given predetermined query encodings; and
wherein determining a given predetermined query encoding that is most similar to the query encoding based on the comparison comprises: the given predetermined query encoding is selected based on the scalar value based on the dot product of the query encoding and the given predetermined query encoding being the smallest of the generated plurality of scalar values.
10. The method of any of claims 7 to 9, wherein the query is not explicitly mapped to the one or more corresponding actions by the automated assistant.
11. The method of any of claims 7 to 10, wherein the query is based on user input received at the first computing device, and wherein the one or more corresponding actions include controlling one or more additional devices.
12. The method of any of claims 7 to 11, wherein the query is received as a speech input, wherein the method further comprises: performing a speech-to-text conversion process on the speech input to generate text, and wherein generating query encoding based on processing the query using a trained encoder model comprises: processing the text using the trained encoder model.
13. A method implemented by one or more processors, comprising:
simultaneously training an encoder model based on a plurality of first training instances customized for a first task and based on a plurality of second training instances customized for a second task,
wherein the first task is different from the second task, and wherein the first task and the second task are different from a semantic text similarity task; and
after training the encoder model:
semantic text similarity of two text segments is determined using a trained encoder model.
14. The method of claim 13, wherein determining semantic text similarity of two text segments using the trained encoder model comprises:
receiving a query for an automated assistant;
generating a query encoding based on processing the query using the trained encoder model;
comparing the query encoding to a plurality of predetermined query encodings, each predetermined query encoding stored in association with one or more corresponding actions;
determining a given predetermined query code that is most similar to the query code based on the comparison; and
in response to the query and based on a given predetermined query encoding that is most similar to the query encoding, causing the automated assistant to perform one or more corresponding actions stored in association with the given predetermined query encoding.
15. A method implemented by one or more processors, comprising:
receiving a query for an automated assistant;
generating a query encoding based on processing the query using a trained encoder model;
comparing the query encoding to a plurality of predetermined query encodings, each predetermined query encoding stored in association with one or more corresponding actions;
determining a given predetermined query code that is most similar to the query code based on the comparison; and
causing, in response to the query and based on the given predetermined query encoding that is most similar to the query encoding, the automated assistant to perform one or more corresponding actions stored in association with the given predetermined query encoding.
16. The method of claim 15, further comprising:
determining that a distance between the query code and the given predetermined query code satisfies a proximity threshold;
wherein causing the automated assistant to perform one or more corresponding actions is further in response to determining that the distance satisfies the proximity threshold.
17. The method of claim 15 or claim 16, wherein comparing the query encoding to the plurality of predetermined query encodings comprises:
generating a plurality of scalar values, each scalar value based on a corresponding dot product of the query encoding and a corresponding given one of the given predetermined query encodings; and
wherein determining a given predetermined query encoding that is most similar to the query encoding based on the comparison comprises: the given predetermined query encoding is selected based on the scalar value based on the dot product of the query encoding and the given predetermined query encoding being the smallest of the generated plurality of scalar values.
18. The method of any of claims 15 to 17, wherein the query is not explicitly mapped to the one or more corresponding actions by the automated assistant.
19. The method of any of claims 15 to 18, wherein the query is based on user input received at the first computing device, and wherein the one or more corresponding actions include controlling one or more additional devices.
20. The method of any of claims 15 to 19, wherein the trained encoder model has been trained using the method of any of claims 1 to 6.
21. The method of any of claims 15 to 19, wherein the method is performed by a computing device remote from the automated assistant.
22. An apparatus comprising one or more processors and a memory, the memory storing computer-readable instructions that, when executed by the processors, cause the apparatus to perform the method of any preceding claim.
23. A computer program product comprising computer readable instructions which, when executed by a computer, cause the computer to perform the method of any one of claims 1 to 21.
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
CN202410020901.0A CN117912459A (en) | 2017-12-15 | 2018-12-14 | Training and/or determining responsive actions to natural language input using encoder models |
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201762599550P | 2017-12-15 | 2017-12-15 | |
US62/599,550 | 2017-12-15 | ||
PCT/US2018/065727 WO2019118864A1 (en) | 2017-12-15 | 2018-12-14 | Training and/or using an encoder model to determine responsive action(s) for natural language input |
Related Child Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202410020901.0A Division CN117912459A (en) | 2017-12-15 | 2018-12-14 | Training and/or determining responsive actions to natural language input using encoder models |
Publications (2)
Publication Number | Publication Date |
---|---|
CN111344779A true CN111344779A (en) | 2020-06-26 |
CN111344779B CN111344779B (en) | 2024-01-23 |
Family
ID=65003525
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201880073730.0A Active CN111344779B (en) | 2017-12-15 | 2018-12-14 | Training and/or determining responsive actions to natural language input using encoder models |
CN202410020901.0A Pending CN117912459A (en) | 2017-12-15 | 2018-12-14 | Training and/or determining responsive actions to natural language input using encoder models |
Family Applications After (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202410020901.0A Pending CN117912459A (en) | 2017-12-15 | 2018-12-14 | Training and/or determining responsive actions to natural language input using encoder models |
Country Status (4)
Country | Link |
---|---|
US (3) | US10783456B2 (en) |
EP (2) | EP3568852B1 (en) |
CN (2) | CN111344779B (en) |
WO (1) | WO2019118864A1 (en) |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN113282977A (en) * | 2021-03-19 | 2021-08-20 | 广州天越电子科技有限公司 | CAD Chinese input shortcut command method based on NLP technology bert model |
Families Citing this family (22)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11113480B2 (en) * | 2016-09-26 | 2021-09-07 | Google Llc | Neural machine translation systems |
WO2019118864A1 (en) | 2017-12-15 | 2019-06-20 | Google Llc | Training and/or using an encoder model to determine responsive action(s) for natural language input |
US10887182B1 (en) * | 2018-05-10 | 2021-01-05 | Hrl Laboratories, Llc | System and method for pairwise network alignment |
US11544461B2 (en) * | 2019-05-14 | 2023-01-03 | Intel Corporation | Early exit for natural language processing models |
US11354504B2 (en) * | 2019-07-10 | 2022-06-07 | International Business Machines Corporation | Multi-lingual action identification |
CN112287722A (en) * | 2019-07-23 | 2021-01-29 | 北京中关村科金技术有限公司 | In-vivo detection method and device based on deep learning and storage medium |
CN110600059B (en) * | 2019-09-05 | 2022-03-15 | Oppo广东移动通信有限公司 | Acoustic event detection method and device, electronic equipment and storage medium |
US11379670B1 (en) * | 2019-09-30 | 2022-07-05 | Splunk, Inc. | Automatically populating responses using artificial intelligence |
CN110811558B (en) * | 2019-11-18 | 2022-07-05 | 郑州大学 | Sleep arousal analysis method based on deep learning |
TWI798513B (en) * | 2019-12-20 | 2023-04-11 | 國立清華大學 | Training method of natural language corpus for the decision making model of machine learning |
CN111582020A (en) * | 2020-03-25 | 2020-08-25 | 平安科技（深圳）有限公司 | Signal processing method, signal processing device, computer equipment and storage medium |
US11238113B2 (en) * | 2020-04-01 | 2022-02-01 | Grand Rounds Inc. | Systems and methods for machine learning models for search engine performance optimization |
CN111680159B (en) * | 2020-06-11 | 2023-08-29 | 华东交通大学 | Data processing method and device and electronic equipment |
US11508360B2 (en) * | 2020-09-15 | 2022-11-22 | Microsoft Technology Licensing, Llc | Synthetic data generation for training of natural language understanding models |
CN112216359B (en) * | 2020-09-29 | 2024-03-26 | 百度国际科技（深圳）有限公司 | Medical data verification method and device and electronic equipment |
US20220179833A1 (en) * | 2020-12-03 | 2022-06-09 | International Business Machines Corporation | Metadata based mapping assist |
CN112417869B (en) * | 2020-12-10 | 2023-08-15 | 长春理工大学 | Product model description comparison method and system |
US11675965B2 (en) * | 2021-04-07 | 2023-06-13 | At&T Intellectual Property I, L.P. | Converting text to a numerical vector by mapping to a hypercube |
CN113535918B (en) * | 2021-07-14 | 2022-09-09 | 梁晨 | Pre-training dual attention neural network semantic inference dialogue retrieval method and system, retrieval equipment and storage medium |
CN113870839B (en) * | 2021-09-29 | 2022-05-03 | 北京中科智加科技有限公司 | Language identification device of language identification model based on multitask |
US20230252549A1 (en) * | 2022-02-09 | 2023-08-10 | Maplebear Inc. (Dba Instacart) | Search Relevance Model Using Self-Adversarial Negative Sampling |
CN117711381A (en) * | 2024-02-06 | 2024-03-15 | 北京边锋信息技术有限公司 | Audio identification method, device, system and electronic equipment |
Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20040002860A1 (en) * | 2002-06-28 | 2004-01-01 | Intel Corporation | Low-power noise characterization over a distributed speech recognition channel |
US20160350655A1 (en) * | 2015-05-26 | 2016-12-01 | Evature Technologies (2009) Ltd. | Systems Methods Circuits and Associated Computer Executable Code for Deep Learning Based Natural Language Understanding |
EP3128439A1 (en) * | 2015-08-07 | 2017-02-08 | Google, Inc. | Text classification and transformation based on author |
CN106653030A (en) * | 2016-12-02 | 2017-05-10 | 北京云知声信息技术有限公司 | Punctuation mark adding method and device |
CN107293296A (en) * | 2017-06-28 | 2017-10-24 | 百度在线网络技术（北京）有限公司 | Voice identification result correcting method, device, equipment and storage medium |
US20170323636A1 (en) * | 2016-05-05 | 2017-11-09 | Conduent Business Services, Llc | Semantic parsing using deep neural networks for predicting canonical forms |
Family Cites Families (12)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7725307B2 (en) * | 1999-11-12 | 2010-05-25 | Phoenix Solutions, Inc. | Query engine for processing voice based queries including semantic decoding |
US6766316B2 (en) * | 2001-01-18 | 2004-07-20 | Science Applications International Corporation | Method and system of ranking and clustering for document indexing and retrieval |
US8935191B2 (en) * | 2012-05-02 | 2015-01-13 | Sap Ag | Reuse of on-demand enterprise system customization knowledge utilizing collective experience |
US9519859B2 (en) * | 2013-09-06 | 2016-12-13 | Microsoft Technology Licensing, Llc | Deep structured semantic model produced using click-through data |
US9535960B2 (en) | 2014-04-14 | 2017-01-03 | Microsoft Corporation | Context-sensitive search using a deep learning model |
US10388274B1 (en) * | 2016-03-31 | 2019-08-20 | Amazon Technologies, Inc. | Confidence checking for speech processing and query answering |
US10832665B2 (en) * | 2016-05-27 | 2020-11-10 | Centurylink Intellectual Property Llc | Internet of things (IoT) human interface apparatus, system, and method |
US10170107B1 (en) * | 2016-12-29 | 2019-01-01 | Amazon Technologies, Inc. | Extendable label recognition of linguistic input |
CN110945500A (en) | 2017-06-08 | 2020-03-31 | 脸谱公司 | Key value memory network |
US10585991B2 (en) * | 2017-06-29 | 2020-03-10 | Microsoft Technology Licensing, Llc | Virtual assistant for generating personalized responses within a communication session |
US20190108282A1 (en) * | 2017-10-09 | 2019-04-11 | Facebook, Inc. | Parsing and Classifying Search Queries on Online Social Networks |
WO2019118864A1 (en) | 2017-12-15 | 2019-06-20 | Google Llc | Training and/or using an encoder model to determine responsive action(s) for natural language input |
-
2018
- 2018-12-14 WO PCT/US2018/065727 patent/WO2019118864A1/en unknown
- 2018-12-14 US US16/611,725 patent/US10783456B2/en active Active
- 2018-12-14 CN CN201880073730.0A patent/CN111344779B/en active Active
- 2018-12-14 EP EP18830624.5A patent/EP3568852B1/en active Active
- 2018-12-14 EP EP20169141.7A patent/EP3696810A1/en active Pending
- 2018-12-14 CN CN202410020901.0A patent/CN117912459A/en active Pending
-
2020
- 2020-08-17 US US16/995,149 patent/US11842253B2/en active Active
-
2023
- 2023-11-01 US US18/386,015 patent/US20240062111A1/en active Pending
Patent Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20040002860A1 (en) * | 2002-06-28 | 2004-01-01 | Intel Corporation | Low-power noise characterization over a distributed speech recognition channel |
US20160350655A1 (en) * | 2015-05-26 | 2016-12-01 | Evature Technologies (2009) Ltd. | Systems Methods Circuits and Associated Computer Executable Code for Deep Learning Based Natural Language Understanding |
EP3128439A1 (en) * | 2015-08-07 | 2017-02-08 | Google, Inc. | Text classification and transformation based on author |
US20170323636A1 (en) * | 2016-05-05 | 2017-11-09 | Conduent Business Services, Llc | Semantic parsing using deep neural networks for predicting canonical forms |
CN106653030A (en) * | 2016-12-02 | 2017-05-10 | 北京云知声信息技术有限公司 | Punctuation mark adding method and device |
CN107293296A (en) * | 2017-06-28 | 2017-10-24 | 百度在线网络技术（北京）有限公司 | Voice identification result correcting method, device, equipment and storage medium |
Non-Patent Citations (1)
Title |
---|
XIAOQIANG ZHOU 等: ""An Auto-Encoder for Learning Conversation Representation Using LSTM"" * |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN113282977A (en) * | 2021-03-19 | 2021-08-20 | 广州天越电子科技有限公司 | CAD Chinese input shortcut command method based on NLP technology bert model |
Also Published As
Publication number | Publication date |
---|---|
EP3568852B1 (en) | 2020-06-03 |
WO2019118864A1 (en) | 2019-06-20 |
US20200380418A1 (en) | 2020-12-03 |
US20240062111A1 (en) | 2024-02-22 |
EP3568852A1 (en) | 2019-11-20 |
CN111344779B (en) | 2024-01-23 |
US11842253B2 (en) | 2023-12-12 |
EP3696810A1 (en) | 2020-08-19 |
CN117912459A (en) | 2024-04-19 |
US10783456B2 (en) | 2020-09-22 |
US20200104746A1 (en) | 2020-04-02 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN111344779B (en) | Training and/or determining responsive actions to natural language input using encoder models | |
JP6916264B2 (en) | Real-time speech recognition methods based on disconnection attention, devices, equipment and computer readable storage media | |
US11568855B2 (en) | System and method for defining dialog intents and building zero-shot intent recognition models | |
US11972365B2 (en) | Question responding apparatus, question responding method and program | |
CN108334496B (en) | Man-machine conversation understanding method and system for specific field and related equipment | |
CN110741364B (en) | Determining the status of an automated assistant dialog | |
WO2019235103A1 (en) | Question generation device, question generation method, and program | |
CN110678882A (en) | Selecting answer spans from electronic documents using machine learning | |
CN108536735A (en) | Multi-modal lexical representation method and system based on multichannel self-encoding encoder | |
JP7342971B2 (en) | Dialogue processing device, learning device, dialogue processing method, learning method and program | |
CN110297894B (en) | Intelligent dialogue generating method based on auxiliary network | |
CN114528387A (en) | Deep learning conversation strategy model construction method and system based on conversation flow bootstrap | |
CN112183062B (en) | Spoken language understanding method based on alternate decoding, electronic equipment and storage medium | |
JP7279099B2 (en) | Dialogue management | |
CN113326367A (en) | Task type dialogue method and system based on end-to-end text generation | |
CN112349294A (en) | Voice processing method and device, computer readable medium and electronic equipment | |
WO2023116572A1 (en) | Word or sentence generation method and related device | |
CN111832699A (en) | Computationally efficient expressive output layer for neural networks | |
Heymann et al. | Improving ctc using stimulated learning for sequence modeling | |
CN116186219A (en) | Man-machine dialogue interaction method, system and storage medium | |
JP7445089B2 (en) | Fast-emission low-latency streaming ASR using sequence-level emission regularization | |
Hwang et al. | End-to-end dialogue system with multi languages for hospital receptionist robot | |
CN115617972A (en) | Robot dialogue method, device, electronic equipment and storage medium | |
JP6605997B2 (en) | Learning device, learning method and program | |
CN114492758A (en) | Training neural networks using layer-by-layer losses |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
GR01 | Patent grant | ||
GR01 | Patent grant |