US10897608B2 - Capturing light-field images with uneven and/or incomplete angular sampling - Google Patents
Capturing light-field images with uneven and/or incomplete angular sampling Download PDFInfo
- Publication number
- US10897608B2 US10897608B2 US16/032,261 US201816032261A US10897608B2 US 10897608 B2 US10897608 B2 US 10897608B2 US 201816032261 A US201816032261 A US 201816032261A US 10897608 B2 US10897608 B2 US 10897608B2
- Authority
- US
- United States
- Prior art keywords
- light
- microlens array
- exit pupil
- image
- field
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N13/00—Stereoscopic video systems; Multi-view video systems; Details thereof
- H04N13/20—Image signal generators
- H04N13/204—Image signal generators using stereoscopic image cameras
- H04N13/207—Image signal generators using stereoscopic image cameras using a single 2D image sensor
- H04N13/229—Image signal generators using stereoscopic image cameras using a single 2D image sensor using lenticular lenses, e.g. arrangements of cylindrical lenses
-
- G—PHYSICS
- G02—OPTICS
- G02B—OPTICAL ELEMENTS, SYSTEMS OR APPARATUS
- G02B3/00—Simple or compound lenses
- G02B3/0006—Arrays
- G02B3/0037—Arrays characterized by the distribution or form of lenses
- G02B3/005—Arrays characterized by the distribution or form of lenses arranged along a single direction only, e.g. lenticular sheets
-
- G—PHYSICS
- G02—OPTICS
- G02B—OPTICAL ELEMENTS, SYSTEMS OR APPARATUS
- G02B3/00—Simple or compound lenses
- G02B3/0006—Arrays
- G02B3/0037—Arrays characterized by the distribution or form of lenses
- G02B3/0056—Arrays characterized by the distribution or form of lenses arranged along two different directions in a plane, e.g. honeycomb arrangement of lenses
-
- G—PHYSICS
- G02—OPTICS
- G02B—OPTICAL ELEMENTS, SYSTEMS OR APPARATUS
- G02B30/00—Optical systems or apparatus for producing three-dimensional [3D] effects, e.g. stereoscopic images
- G02B30/10—Optical systems or apparatus for producing three-dimensional [3D] effects, e.g. stereoscopic images using integral imaging methods
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N13/00—Stereoscopic video systems; Multi-view video systems; Details thereof
- H04N13/20—Image signal generators
- H04N13/204—Image signal generators using stereoscopic image cameras
- H04N13/207—Image signal generators using stereoscopic image cameras using a single 2D image sensor
- H04N13/218—Image signal generators using stereoscopic image cameras using a single 2D image sensor using spatial multiplexing
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N13/00—Stereoscopic video systems; Multi-view video systems; Details thereof
- H04N13/20—Image signal generators
- H04N13/204—Image signal generators using stereoscopic image cameras
- H04N13/207—Image signal generators using stereoscopic image cameras using a single 2D image sensor
- H04N13/232—Image signal generators using stereoscopic image cameras using a single 2D image sensor using fly-eye lenses, e.g. arrangements of circular lenses
Definitions
- the present document relates to the use of multiple light-field cameras to capture images with uneven and/or irregular angular sampling.
- Light-field cameras may be used to capture a four-dimensional (4D) light-field image, with two spatial dimensions, x and y, and two angular dimensions, u and v.
- 4D four-dimensional
- a plenoptic microlens array and a single photosensor, containing a two-dimensional (2D) array of pixels are used.
- These plenoptic light-field cameras capture image data that may be much more versatile than traditional two-dimensional image data.
- a light-field image may be processed to create a set of virtual views, in which focus distance, center of perspective, depth-of-field, and/or other virtual-camera parameters are varied within ranges enabled by the data in the four-dimensional light-field image. Further, the light-field data may be analyzed to calculate a depth map and/or analysis information.
- the desired output from the light-field camera may be a combination of high-resolution image data and depth data, often in the form of a depth map or a set of three-dimensional (3D) points (a point cloud).
- the desired output may be high-resolution depth data.
- Various embodiments of the described system capture light-field images with uneven and/or incomplete angular sampling. Such embodiments may increase spatial and/or output resolution, increase the quality of the depth data, extend the refocusable range of the system, and/or increase the optical baseline. Some of the embodiments utilize novel exit pupil shapes and/or configurations of the microlens array.
- FIG. 1 is a diagram of a plenoptic light-field camera, according to one embodiment.
- FIGS. 2A-2E are diagrams of various aspects of the plenoptic light-field camera of FIG. 1 .
- FIG. 3 shows a cross-sectional view of a double Gauss lens design, including an aperture stop, according to one embodiment.
- FIG. 4 shows a portion of an image captured with a microlens array paired with a circular aperture.
- FIG. 5 shows a portion of an image captured with a microlens array paired with a rectangular or even square aperture.
- FIG. 6 shows a portion of an image captured with a microlens array paired with a generally circular aperture.
- FIGS. 7A-7C show the relationships between the exit pupil, microlens array, and disk images, according to certain embodiments.
- FIGS. 8A and 8B show exemplary embodiments with exit pupils of high aspect ratios, with nonzero rotational offsets applied between the exit pupils and the microlens arrays and square packing of microlenses, according to certain embodiments.
- FIGS. 9A and 9B show exemplary embodiments with exit pupils of high aspect ratios, with nonzero rotational offsets applied between the exit pupils and the microlens arrays and hexagonal packing of microlenses, according to certain embodiments.
- FIGS. 10A, 10B and 10C show captured disk images using a hexagonally packed microlens array and three different exit pupil configurations, according to certain embodiments.
- FIGS. 11A and 11B show exemplary embodiments with the exit pupils of high aspect ratios, with nonzero rotational offsets applied between the exit pupils and the microlens arrays and hexagonal packing of microlenses, according to another embodiment.
- FIG. 12 shows an exemplary embodiment with an exit pupils of high aspect ratio, with nonzero rotational offsets applied between the exit pupils and the microlens arrays and hexagonal packing of microlenses, according to another embodiment.
- FIGS. 13A and 13B show a virtual view in the form of an image, and depth data in the form of a depth map corresponding to the image, respectively, according to one embodiment.
- FIGS. 14A and 14B conceptually show a discontinuous aperture with three sections, according to one embodiment.
- FIG. 15 shows the relationship between the exit pupil, microlens array, and disk images when the exit pupil has a high aspect ratio and the microlens array uses lenses of the same aspect ratio using rectangular packing.
- FIG. 16 shows the relationship between the exit pupil, microlens array, and disk images when the exit pupil has a high aspect ratio and the microlens array uses cylindrical lenses, according to one embodiment.
- FIGS. 17A-17D show exemplary microlens packing arrangements.
- FIG. 18A conceptually shows a discontinuous exit pupil of two parts, according to one embodiment.
- FIG. 18B shows how segments of a disk image created from a square packed microlens array and an exit pupil of this type may tessellate.
- FIGS. 19A and 19B show two exemplary embodiments on a square packed microlens array, using an exit pupil that is discontinuous in two dimensions, according to one embodiment.
- FIGS. 20A-20D conceptually show an embodiment that may use a variety of masks to create a light-field camera with different configurable properties, but without changing the microlens array, photosensor, and/or any additional aspect of the objective lens, according to one embodiment.
- FIG. 21 depicts a portion of a light-field image.
- FIG. 22 depicts an example of an architecture for implementing the methods of the present disclosure in a light-field capture device, according to one embodiment.
- FIG. 23 depicts an example of an architecture for implementing the methods of the present disclosure in a post-processing system communicatively coupled to a light-field capture device, according to one embodiment.
- FIG. 24 depicts an example of an architecture for a light-field camera for implementing the methods of the present disclosure according to one embodiment.
- the described embodiments may provide for capturing continuous or nearly continuous light-field data from many or all directions facing away from the capture system, which may enable the generation of virtual views that are more accurate and/or allow viewers greater viewing freedom.
- a data acquisition device can be any device or system for acquiring, recording, measuring, estimating, determining and/or computing data representative of a scene, including but not limited to two-dimensional image data, three-dimensional image data, and/or light-field data.
- a data acquisition device may include optics, sensors, and image processing electronics for acquiring data representative of a scene, using techniques that are well known in the art.
- One skilled in the art will recognize that many types of data acquisition devices can be used in connection with the present disclosure, and that the disclosure is not limited to cameras.
- any use of such term herein should be considered to refer to any suitable device for acquiring image data.
- the system and method described herein can be implemented in connection with light-field images captured by light-field capture devices including but not limited to those described in Ng et al., Light-field photography with a hand-held plenoptic capture device, Technical Report CSTR 2005-02, Stanford Computer Science.
- FIG. 22 there is shown a block diagram depicting an architecture for implementing the method of the present disclosure in a light-field capture device such as a camera 2200 .
- FIG. 23 there is shown a block diagram depicting an architecture for implementing the method of the present disclosure in a post-processing system 2300 communicatively coupled to a light-field capture device such as a camera 2200 , according to one embodiment.
- FIGS. 22 and 23 are merely exemplary, and that other architectures are possible for camera 2200 .
- One skilled in the art will further recognize that several of the components shown in the configurations of FIGS. 22 and 23 are optional, and may be omitted or reconfigured.
- camera 2200 may be a light-field camera that includes light-field image data acquisition device 2209 having optics 2201 , image sensor 2203 (including a plurality of individual sensors for capturing pixels), and microlens array 2202 .
- Optics 2201 may include, for example, aperture 2212 for allowing a selectable amount of light into camera 2200 , and main lens 2213 for focusing light toward microlens array 2202 .
- microlens array 2202 may be disposed and/or incorporated in the optical path of camera 2200 (between main lens 2213 and image sensor 2203 ) so as to facilitate acquisition, capture, sampling of, recording, and/or obtaining light-field image data via image sensor 2203 . Referring now also to FIG.
- FIG. 24 there is shown an example of an architecture for a light-field camera, or camera 2200 , for implementing the method of the present disclosure according to one embodiment.
- the figure is not shown to scale.
- FIG. 24 shows, in conceptual form, the relationship between aperture 2212 , main lens 2213 , microlens array 2202 , and image sensor 2203 , as such components interact to capture light-field data for one or more objects, represented by an object 2401 , which may be part of a scene 2402 .
- camera 2200 may also include a user interface 2205 for allowing a user to provide input for controlling the operation of camera 2200 for capturing, acquiring, storing, and/or processing image data.
- the user interface 2205 may receive user input from the user via an input device 2206 , which may include any one or more user input mechanisms known in the art.
- the input device 2206 may include one or more buttons, switches, touch screens, gesture interpretation devices, pointing devices, and/or the like.
- post-processing system 2300 may include a user interface 2305 that allows the user to control operation of the system.
- camera 2200 may also include control circuitry 2210 for facilitating acquisition, sampling, recording, and/or obtaining light-field image data.
- the control circuitry 2210 may, in particular, be used to switch image capture configurations in response to receipt of the corresponding user input.
- control circuitry 2210 may manage and/or control (automatically or in response to user input) the acquisition timing, rate of acquisition, sampling, capturing, recording, and/or obtaining of light-field image data.
- camera 2200 may include memory 2211 for storing image data, such as output by image sensor 2203 .
- memory 2211 can include external and/or internal memory.
- memory 2211 can be provided at a separate device and/or location from camera 2200 .
- camera 2200 when camera 2200 is in a light-field image capture configuration, camera 2200 may store raw light-field image data, as output by image sensor 2203 , and/or a representation thereof, such as a compressed image data file.
- camera 2200 when camera 2200 is in a conventional image capture configuration, camera 2200 may store conventional image data, which may also be stored as raw, processed, and/or compressed output by the image sensor 2203 .
- captured image data is provided to post-processing circuitry 2204 .
- the post-processing circuitry 2204 may be disposed in or integrated into light-field image data acquisition device 2209 , as shown in FIG. 22 , or it may be in a separate component external to light-field image data acquisition device 2209 , as shown in FIG. 23 . Such separate component may be local or remote with respect to light-field image data acquisition device 2209 .
- Any suitable wired or wireless protocol can be used for transmitting image data 2221 to circuitry 2204 ; for example, the camera 2200 can transmit image data 2221 and/or other data via the Internet, a cellular data network, a Wi-Fi network, a Bluetooth communication protocol, and/or any other suitable means.
- Such a separate component may include any of a wide variety of computing devices, including but not limited to computers, smartphones, tablets, cameras, and/or any other device that processes digital information.
- Such a separate component may include additional features such as a user input 2215 and/or a display screen 2216 . If desired, light-field image data may be displayed for the user on the display screen 2216 .
- Light-field images often include a plurality of projections (which may be circular or of other shapes) of aperture 2212 of camera 2200 , each projection taken from a different vantage point on the camera's focal plane.
- the light-field image may be captured on image sensor 2203 .
- the interposition of microlens array 2202 between main lens 2213 and image sensor 2203 causes images of aperture 2212 to be formed on image sensor 2203 , each microlens in microlens array 2202 projecting a small image of main-lens aperture 2212 onto image sensor 2203 .
- These aperture-shaped projections are referred to herein as disks, although they need not be circular in shape.
- the term “disk” is not intended to be limited to a circular region, but can refer to a region of any shape.
- Light-field images include four dimensions of information describing light rays impinging on the focal plane of camera 2200 (or other capture device).
- Two spatial dimensions (herein referred to as x and y) are represented by the disks themselves.
- Two angular dimensions (herein referred to as u and v) are represented as the pixels within an individual disk.
- the angular resolution of a light-field image with 100 pixels within each disk, arranged as a 10 ⁇ 10 Cartesian pattern is 10 ⁇ 10.
- This light-field image has a 4-D (x,y,u,v) resolution of (400,300,10,10).
- FIG. 21 there is shown an example of a 2-disk by 2-disk portion of such a light-field image, including depictions of disks 2102 and individual pixels 2101 ; for illustrative purposes, each disk 2102 is ten pixels 2101 across.
- the 4-D light-field representation may be reduced to a 2-D image through a process of projection and reconstruction.
- a virtual surface of projection may be introduced, and the intersections of representative rays with the virtual surface can be computed. The color of each representative ray may be taken to be equal to the color of its corresponding pixel.
- the spatial output resolution is the full 12 megapixels.
- the configuration may include 10 angular samples in each of u and v.
- the light-field sensor would sample at 400 ⁇ 300 ⁇ 10 ⁇ 10, using the full 12 megapixels.
- the alias-free spatial resolution of virtual views would be 400 ⁇ 300, a very low resolution.
- higher resolution is desired for many use cases, including artistic photography and industrial imaging, it is desirable to find ways to increase the output resolution of the system while preserving some or all of the other benefits of light-field images.
- a plenoptic light-field camera 100 may capture a light-field using an objective lens 110 , plenoptic microlens array 120 , and photosensor 130 .
- the objective lens 110 may be positioned to receive light through an aperture (not shown) having an exit pupil.
- Each microlens in the plenoptic microlens array 120 may create an image of the aperture on the surface of the photosensor 130 .
- the plenoptic light-field camera 100 may facilitate the generation of extended depth-of-field images and other processed images based on the light-field data captured by the plenoptic light-field camera 100 .
- FIG. 1 is a simplified representation for illustrative purposes; light-field camera 100 may include additional components and elements not depicted in FIG. 1 .
- FIGS. 2A through 2E are diagrams of various aspects of the plenoptic light-field camera 100 of FIG. 1 .
- FIG. 2A shows a cross-sectional view of the plenoptic light-field camera 100 , including an aperture stop 200 in the objective lens 110 .
- FIG. 2B shows a cross-sectional illustration of a plenoptic microlens 210 of the plenoptic microlens array 120 , central rays 220 passing through the plenoptic microlens 210 , and the disk image 230 generated on the surface of the photosensor 130 .
- FIG. 2C is a diagram of the aperture stop 200 from a top-down view.
- FIG. 2D is a top down view of a 2 ⁇ 2 set of plenoptic microlenses 210 with square packing.
- FIG. 2E is a top down view of the disk images 230 generated on the surface of the photosensor 130 .
- FIG. 3 shows a cross-sectional view of a double Gauss lens design 300 , including an aperture stop 310 .
- the double Gauss lens design 300 is one of many lens types that may be suitable for use in light-field imaging. As shown, the double Gauss lens design 300 may have a plurality of lens elements 320 .
- FIGS. 17A through 17D show exemplary lens packing arrangements, according to certain embodiments.
- FIG. 17A shows a square packing arrangement 1700 .
- FIG. 17B shows a rectangular packing arrangement 1720 .
- FIG. 17C shows a hexagonal packing arrangement 1740 .
- FIG. 17D shows an elliptical packing arrangement 1760 .
- FIGS. 4, 5 and 6 show exemplary image data captured by a light-field camera, using different aperture shapes and microlens array packing. Various combinations of aperture shapes and microlens array packing layouts may be used.
- FIG. 4 is a portion of an image 400 captured with a microlens array paired with a circular aperture.
- the microlenses 410 of the microlens array may be generally circular in shape to match the shape of the aperture, and may be packed such that each pair of adjacent rows of the microlenses 410 is offset from each other by 50% of the diameter of a microlens 410 .
- This packing may enable the protruding portions of each microlens 410 to protrude into the empty areas between the adjoining microlenses 410 of each adjacent row.
- the result may be that each microlens 410 has six immediate neighbors arranged around the microlens 410 in a generally hexagonal formation. This packing layout may be referred to as “hexagonal packing,” as in the hexagonal packing arrangement 1740 of FIG. 17C .
- FIG. 5 is a portion of an image 500 captured with a microlens array paired with a rectangular or even square aperture.
- the microlenses 510 of the microlens array may be generally square in shape to match the shape of the aperture, and may be packed in a generally rectangular grid, with each microlens 510 aligned with its horizontal and vertical neighbors. This packing layout may be referred to as “square packing,” as in the square packing arrangement 1700 of FIG. 17A .
- FIG. 6 is a portion of an image 600 captured with a microlens array paired with a generally circular aperture.
- the microlenses 610 of the microlens array may be generally circular in shape to match the shape of the aperture, and may be packed in a generally rectangular grid, with each microlens 610 aligned with its horizontal and vertical neighbors.
- square packing may be used for the microlenses 610 as in the image 500 , as in the square packing arrangement 1700 of FIG. 17A .
- the result may be that, in the image 600 , there is more interstitial “black” space than is present in the image 400 .
- the horizontal and vertical alignment of the microlenses 610 may provide some computational advantages as the image 600 is processed.
- Another method to increase the output resolution of a plenoptic camera is to reduce the number of pixels under each microlens.
- the device may sample at 800 ⁇ 600 ⁇ 5 ⁇ 5.
- the spatial resolution may be increased, but the angular resolution is decreased. Reducing the angular sampling may also cause the refocusable range and other benefits of the light-field image to be reduced.
- An alternative method to increase the output resolution is to increase the pixel count of the sensor.
- a 48-megapixel sensor may be used instead of a 12-megapixel sensor.
- the 4D sampling resolution may be 800 ⁇ 600 ⁇ 10 ⁇ 10, if all new resolution is allocated to the spatial dimensions.
- new resolution may be evenly allocated approximately evenly across all four dimensions with a sampling resolution of 572 ⁇ 428 ⁇ 14 ⁇ 14. While increasing the pixel count improves output resolution, such an approach significantly increases the requirements of the photosensor, readout, storage, processing and other aspects of the total image processing system. Further, for a given physical area, there are practical limits (including optical aspects such as diffraction) to the maximum number of pixels that may be effectively used.
- Various embodiments of the systems and methods described herein capture light-field images with uneven and/or incomplete angular sampling. Such embodiments may increase spatial and/or output resolution, increase the quality of the depth data, extend the refocusable range of the system, and/or increase the optical baseline. Some of the embodiments utilize novel exit pupil shapes and/or configurations of the microlens array. These various approaches can be implemented singly or in any suitable combination with one another.
- the exit pupil contains a long axis and a short axis.
- Embodiments of this type may have relatively higher angular sampling in one dimension than in the other, orthogonal dimension.
- Embodiments of this type may be advantageous when depth data and/or high-resolution virtual view data are desired as output. Generating depth data from light-field data is dependent on the algorithm(s) and processing selected, but in general a larger optical baseline and/or higher density angular sampling provides better results. Depth data may be used to apply effects, modify the image, generate three-dimensional models of objects in the scene, and/or the like.
- FIGS. 13A and 13B respectively show a virtual view in the form of an image 1300 and depth data in the form of a depth map 1350 .
- the image 1300 may be projected from light-field data.
- the depth map 1350 may be a grayscale image as shown, and may be generated by processing the light-field data. In the depth map 1350 , dark portions of the image represent surfaces that are closer to the camera, while light portions indicate surfaces further from the camera.
- a standard plenoptic camera system has an alias-free output resolution approximately equal to photo_sensor_pixel_count/N 2 .
- the alias-free output resolution may become photo_sensor_pixel_count/Nu, an inversely linear relationship with Nu, which may be far preferable to the standard plenoptic relationship that is inversely quadratic with N.
- configurations may be made that have higher angular sampling (along one axis) with the same alias-free output resolution, higher alias-free output resolution with the same angular sampling, or a combination of higher alias-free output resolution and higher angular sampling.
- the light-field camera may use cylindrical lenses in the microlens array.
- One example of such an embodiment is shown in FIG. 16 .
- an exemplary exit pupil 1600 is shown, along with a portion of a microlens array 1610 and a portion of a disk image 1620 .
- the exit pupil 1600 may have a high aspect ratio. Specifically, the exit pupil 1600 may be much wider along a long axis than it is tall along a short axis perpendicular to the long axis.
- the aspect ratio of the exit pupil may be N: 1 .
- the microlens array 1610 may be a one-dimensional array of cylindrical lenses 1630 .
- the focal length of the cylindrical lenses 1630 may be approximately equal to the separation between the microlens array and the photosensor (not shown).
- the focal length of the microlens array 1610 divided by the width of a cylindrical lens 1630 may also be substantially equivalent to the Wide F/# of the objective lens (not shown).
- the short axis of the cylindrical lenses 1630 may be parallel to the long axis of the exit pupil 1600 , and this case may be considered to have an MLA-to-exit pupil rotation of 0°.
- the disk image 1620 may have a plurality of segments 1640 , each of which has a width substantially equal to N pixels.
- the four-dimensional sampling rate on a photosensor of W ⁇ H pixels may be W/N ⁇ H ⁇ N ⁇ 1.
- This type of camera may be considered a three-dimensional light-field camera, as one of the angular dimensions contains only a single sample.
- the microlens array 1610 and the exit pupil 1600 may be aligned with each other to provide a 0° rotational offset between the microlens array 1610 and the exit pupil 1600 , the sensor (not shown) need not be constrained to a 0° relative to the microlens array 1610 and/or the exit pupil 1600 .
- an anamorphic lens and/or sensor with a high aspect ratio may be used.
- the aperture stop may be physically circular, square, or otherwise have substantially equal width and height.
- the anamorphic lens may be used to stretch the aperture and image on the sensor, for example by a factor of N.
- the exit pupil, or the view of the aperture stop as seen from the sensor may have a long axis and a short axis.
- the cylindrical microlens array may be designed so that each disk image is N pixels wide. Further, an ultrawide sensor may be used.
- the aspect ratio of the sensor may be WN:H.
- the reconstruction processing may reverse the stretching introduced by the anamorphic lens and output virtual views with an aspect ratio of W:H.
- the microlens array may use rectangular or elliptical packing of the microlens elements, and may have an MLA-to-exit pupil rotation of 0°. This is shown in FIG. 15 , which is a conceptual illustration using a rectangular packing of microlens elements.
- an exemplary exit pupil 1500 is shown, along with a portion of a microlens array 1510 and a portion of a disk image 1520 .
- the exit pupil 1500 may have a high aspect ratio, like the exit pupil 1600 of FIG. 16 .
- the exit pupil 1500 , the microlenses 1530 of the microlens array 1510 , and the segments 1540 of the disk image 1520 may all have an aspect ratio of c 2 :1.
- the aperture may be physically circular, square or otherwise have substantially equal width and height, while the microlens array and disk image segments may have an aspect ratio of c 2 :1.
- the anamorphic lens may be used to stretch the aperture and image on the sensor, for example by a factor of c 2 .
- the exit pupil, or the view of the aperture stop as seen from the sensor may have a long axis and a short axis.
- a wide sensor may be used such that the virtual views will have a desired aspect ratio that may be different than the aspect ratio of the two-dimensional image data captured on the photosensor.
- the system may also be implemented using vertical configurations or any other orientation.
- the exit pupil may have a long axis and a short axis
- the plenoptic microlens array may use square packing or hexagonal packing
- the MLA-to-exit pupil rotation may be set to a specific angle so that the disk images tessellate without overlapping.
- FIGS. 7A-7C show the relationships between the exit pupil, microlens array, and disk images in such embodiments.
- FIG. 7A shows one typical configuration for a light-field camera.
- the exit pupil 700 is circular, the microlenses 712 of the microlens array 710 are arranged in a square packing, and the f/# of the main lens is equal or nearly equal to the f/# of the microlens array.
- the segments 722 of the disk image 720 are tightly packed circles in a square lattice.
- FIG. 7B shows the effect of increasing the size of an exit pupil 730 while keeping other aspects unchanged.
- the f/# of the main lens (not shown) is lower than the f/# of the microlens array 740 .
- the segments 752 of the disk image 750 show significant overlap, and the image data may not be usable.
- FIG. 7C shows an embodiment of the invention.
- the exit pupil 760 is as wide as shown in FIG. 7B , but is only half as tall.
- the microlens array 770 is rotated 45°, but otherwise unchanged. In this configuration, the segments 782 of the disk image 780 do not overlap and have an aspect ratio of 2:1.
- FIGS. 10A, 10B and 10C show captured images 1000 , 1030 , and 1060 , respectively, using a hexagonally packed microlens array and three different exit pupil configurations.
- the f/# of the main lens is approximately equal to the f/# of the microlens array and the exit pupil shape is circular.
- the disk images 1010 are circular and almost touching.
- the f/# of the main lens is smaller than the f/# of the microlens array, and the exit pupil is circular.
- the disk images 1040 are circular and overlap. The overlapping regions are the brightest portions of the image.
- the Wide F/# is smaller than the f/# of the microlens array
- the Narrow F/# is larger than the f/# of the microlens array
- the long axis of the exit pupil is rotated relative to the hexagonal axes.
- the disk images 1070 appear rotated and elongated.
- the sampling along one angular dimension is greater than in the other angular dimension, but the reduction in spatial resolution may be equal across both spatial dimensions, relative to the sensor.
- Using rectangular or elliptical microlens packing, with matched exit pupil shape, may result in a similar tradeoff.
- the structure of the microlens array 770 remains square, and the spatial resolution may remain 400 ⁇ 300 for the exemplary sensor even though Nx is substantially larger than Ny.
- the microlens array uses square packing. At specific MLA-to-exit pupil rotations, specific aspect ratios may be used for the exit pupil and disk images.
- angle may be any rotation that results in a similar tessellation pattern in any orientation.
- angle, 90° ⁇ angle, 90°+angle, 180° ⁇ angle, 180°+angle, 270° ⁇ angle, and 270°+angle may all result in similar tessellation patterns.
- the microlens array 810 is rotated 26.6°.
- the segments 840 of the disk image 820 have a 5:1 aspect ratio and do not overlap.
- the microlens array 860 is rotated 18.4° relative to the exit pupil 850 .
- the segments 890 of the disk images 870 have a 10:1 aspect ratio and do not overlap.
- the microlens array uses hexagonal packing. At specific MLA-to-exit pupil rotations, specific aspect ratios may be used for the exit pupil and disk images.
- angle may be any rotation that results in a similar tessellation pattern in any orientation.
- angle, 90° ⁇ angle, 90°+angle, 180° ⁇ angle, 180°+angle, 270° ⁇ angle, and 270°+angle may all result in similar tessellation patterns.
- FIGS. 9A and 9B show an exit pupil 900 with an aspect ratio of approximately 3.5:1.
- the microlens array 910 uses hexagonal packing.
- the axes of the hexagonal lattice are rotated 30° relative to the long axis of the exit pupil 900 .
- A is the diameter of an exit pupil 920 that results in an optimal packing of circular disk images onto the sensor without overlap, given a hexagonal microlens array and a focal length.
- the long axis of the exit pupil is rotated 30° relative to the hexagonal axes of the microlens array, the dimensions of a rectangular exit pupil that results in optimally packed disk images has a width of SQRT(3)*A and a height of A/2.
- FIG. 9B conceptually shows the packing of the rectangular disk images 930 relative to the hexagonally packed microlens array 910 .
- FIGS. 11A and 11B show another way to implement the system in FIGS. 9A and 9B .
- the width may be fixed to A, while the f/# of the microlens may be increased by SQRT(3) while the diameter of each microlens 1130 in the microlens array 1100 is decreased by the same factor.
- the density of the microlens array 1100 (within a fixed area) is increased and thus the overall spatial resolution can be improved.
- FIG. 12 conceptually shows the packing of the rectangular disk images 1210 relative to the hexagonally packed microlens array 1200 , when the MLA-exit pupil rotation is approximately 19° and the aspect ratio of the exit pupil is approximately 8:1.
- the image sensor-to-exit pupil rotation may be 0°.
- the axes of the disk images may align with the axes of the photosensor.
- the f/# of the microlens array may be slightly smaller than the f/# that may result in ideal tessellation of disk images with no gaps or overlap.
- the slightly smaller f/# may introduce small dark regions between disk images, and may reduce crosstalk between neighboring disk images when the light is captured by the photosensor.
- microlens packing may be extended to include any type of microlens packing.
- the microlens packing may be triangular, diamond shaped, or in any other pattern.
- a disjointed or discontinuous exit pupil may be used. Embodiments of this type may be preferred, for example, when a larger optical baseline is desired, but decreasing the depth-of-field of the subviews is not.
- FIG. 18A conceptually shows a discontinuous exit pupil having two sections 1810 separated by a distance 1820 equal to the sum of the widths of each section.
- Each of the two sections 1810 may have a width 1830 equal to d, and the center gap may have a width equal to the distance 1820 , which may be 2*d.
- the two sections 1810 may have a total width that sums to 2d, where one section may have a width equal to d+x and the other a width equal to d ⁇ x.
- this embodiment may have the same number of angular samples, the same depth-of-field in each subview, and double the optical baseline.
- FIG. 18B shows how segments 1860 of a disk image created from a square packed microlens array 1850 and an exit pupil 1800 of this type may tessellate when the microlens array 1850 uses square packing and the MLA-to-exit pupil rotation is 26.6°.
- a discontinuous exit pupil that is divided into two parts like the exit pupil 1800 may be used in conjunction with various MLA-to-exit pupil rotations and packing patterns to increase or reduce the aspect ratio.
- FIGS. 14A and 14B show another embodiment.
- the exit pupil 1400 contains three discontinuous sections: a wide center section 1410 , and two narrow end sections 1420 .
- FIG. 14B shows how the segments 1440 of the disk image tessellate relative to a microlens array 1430 using hexagonal packing.
- the relative sizes of each section of a pupil with three discontinuous sections may be adjusted relative to each other to provide other tessellation patterns.
- FIGS. 19A and 19B show two exemplary embodiments on a square packed microlens array, using an exit pupil that is discontinuous in two dimensions.
- FIG. 19A illustrates segments 1900 of a disk image on a microlens array 1910 , in which each segment 1900 includes four isosceles triangles oriented outward from an empty square. The empty square of each segment 1900 may be filled with the isosceles triangles of neighboring segments 1900 .
- FIG. 19B illustrates segments 1950 of a disk image on a microlens array 1960 , in which each segment 1950 includes a square and four trapezoids oriented outward from the square, which surrounded by a larger empty space with a square boundary. The empty space of each segment 1950 may be filled with the trapezoids of neighboring segments 1900 .
- Discontinuous pupils may have any number of sections, which may be arranged in a wide variety of one-dimensional and/or two-dimensional patterns.
- accurate and specific MLA-to-exit pupil rotation may be required for the disk images to properly tessellate on the photosensor without overlapping.
- the image sensor-to-exit pupil rotation and the MLA-to-sensor rotation may be unspecified.
- the image sensor-to-exit pupil rotation is 0°, or substantially 0°. Alignment of the exit pupil axes with the axes of the photosensor may reduce crosstalk between disk images on the photosensor, and/or reduce the need for any “dead zone” allocated between disk images. In some embodiments, dead zones may be used to reduce crosstalk between disk images, typically, by slightly reducing the f/# of the microlens array relative to the objective lens.
- a controllable and/or adjustable aperture mask may be used in conjunction with the embodiments described above and a lens with a low f/# compared to the f/# of the microlens array.
- FIGS. 20A through 20D conceptually show an embodiment that may use a variety of masks to create a light-field camera with different configurable properties, but without changing the microlens array, photosensor, and/or any additional aspect of the objective lens.
- the microlens array may use square packing and have an f/# substantially equal to X.
- FIG. 20A conceptually shows a fully “open” aperture 2000 , which may have a lower f/# than the microlens array.
- the segments of the disk image in this exemplary embodiment may overlap, and the captured light-field data may not be usable.
- FIG. 20B shows the aperture 2000 with a square mask 2020 applied.
- the f/# of the objective lens may be substantially equal to X, and the segments of the disk image may tessellate on the photosensor with little dead space and/or overlap.
- a MLA-to-exit pupil rotation of 0° may be used.
- the light-field camera may perform like a standard plenoptic light-field camera, with substantially equivalent sampling in both angular dimensions.
- FIG. 20C shows the aperture 2000 with a mask 2040 having a 2:1 aspect ratio applied at or near the aperture plane.
- an MLA-to-exit pupil rotation of 45° may be applied.
- FIG. 20D shows the aperture 2000 with a mask 2060 having a 5:1 aspect ratio applied at or near the aperture plane.
- an MLA-to-exit pupil rotation of 26.6° may be applied.
- controllable aperture can support any of the embodiments described in this document, and many others.
- any of embodiments described in the Exit Pupils with High Aspect Ratio section are supported, for any value of k.
- the total area of such portions may advantageously be substantially identical.
- the number of the microlenses in the microlens array may be unchanging, and the size of the photosensor may be unchanging, the total area allocated to each disk image such that there is minimal dead space and/or overlap, may also be unchanging.
- aperture masks may be used to vary the aspect ratio of an exit pupil on a system with a square packed microlens array
- alternative packing for example, hexagonal, rectangular, elliptical, etc.
- alternative exit pupil designs for example, a discontinuous aperture
- an LCD panel may be placed at or near the aperture plane.
- the LCD panel may allow light to pass through certain areas of the aperture, while blocking light passage through other areas.
- LCD panels may be manufactured with very high resolutions, nearly arbitrary mask shapes may be generated.
- the LCD panel mask may be controlled in any manner, including but not limited to manual control, automatic control and/or control via a user interface on the camera system.
- mechanical masks may be inserted into and/or removed from the aperture plane.
- the mechanical masks may be made from any suitable material, for example thin sheets of black plastic or black anodized aluminum. The material may be cut to remove the portions through which light is to pass.
- the objective lens may have a slit in the side that allows users to manually apply and/or remove mechanical aperture masks.
- the objective lens may include one or more mechanical masks that may be automatically changed. The mechanical mask insertion and/removal may be controlled in any manner, including manual control, automatic control and/or controlled by a user interface on the camera system.
- various masks such as the square mask 2020 , the mask 2040 , and the mask 2060 , may be provided in a single camera through the use of a movable element on which all of the masks are located.
- a rotatable disk may have masks that can be selectively rotated into alignment with the aperture.
- a rectangular strip may have masks arranged in a linear fashion such that translation of the strip can selectively move the masks into alignment with the aperture.
- various movable elements can be combined to provide a mask with a changeable shape. For example, four rectangular plates may be movable toward or away from the center of the aperture to effectively provide the square mask 2020 , the mask 2040 , and/or the mask 2060 .
- the user of the light-field camera may select the appropriate mask for each shot.
- Processing of the light-field images from the embodiments listed above may be performed using the same algorithms and techniques generally used to process light-field images. In at least one embodiment, some changes are made to such algorithms and techniques so that they better suit the architectures described herein.
- each pixel on the photosensor (having raster position (s, t) in the light-field image) may be mapped to a light-field coordinate (x, y, u, v).
- ( x,y,u,v ) f ( s,t )
- a masking function may be used to help create this mapping.
- the mapping of raster coordinates to light-field coordinates may be performed with an algorithm such as the following:
- processing of the light-field image may be carried out in a manner similar to those set forth in prior art descriptions of light-field image processing.
- the resulting light-field image may have enhanced angular resolution along one dimension, which may facilitate and/or enhance the manner in which the light-field image may be used.
- Some embodiments may include a system or a method for performing the above-described techniques, either singly or in any combination.
- Other embodiments may include a computer program product comprising a non-transitory computer-readable storage medium and computer program code, encoded on the medium, for causing a processor in a computing device or other electronic device to perform the above-described techniques.
- Certain aspects include process steps and instructions described herein in the form of an algorithm. It should be noted that the process steps and instructions of described herein can be embodied in software, firmware and/or hardware, and when embodied in software, can be downloaded to reside on and be operated from different platforms used by a variety of operating systems.
- This apparatus may be specially constructed for the required purposes, or it may comprise a general-purpose computing device selectively activated or reconfigured by a computer program stored in the computing device.
- a computer program may be stored in a computer readable storage medium, such as, but is not limited to, any type of disk including floppy disks, optical disks, CD-ROMs, magnetic-optical disks, read-only memories (ROMs), random access memories (RAMs), EPROMs, EEPROMs, flash memory, solid state drives, magnetic or optical cards, application specific integrated circuits (ASICs), and/or any type of media suitable for storing electronic instructions, and each coupled to a computer system bus.
- the computing devices referred to herein may include a single processor or may be architectures employing multiple processor designs for increased computing capability.
- the techniques described herein can be implemented as software, hardware, and/or other elements for controlling a computer system, computing device, or other electronic device, or any combination or plurality thereof.
- Such an electronic device can include, for example, a processor, an input device (such as a keyboard, mouse, touchpad, trackpad, joystick, trackball, microphone, and/or any combination thereof), an output device (such as a screen, speaker, and/or the like), memory, long-term storage (such as magnetic storage, optical storage, and/or the like), and/or network connectivity, according to techniques that are well known in the art.
- Such an electronic device may be portable or nonportable.
- Examples of electronic devices that may be used for implementing the techniques described herein include: a mobile phone, personal digital assistant, smartphone, kiosk, server computer, enterprise computing device, desktop computer, laptop computer, tablet computer, consumer electronic device, television, set-top box, or the like.
- An electronic device for implementing the techniques described herein may use any operating system such as, for example: Linux; Microsoft Windows, available from Microsoft Corporation of Redmond, Wash.; Mac OS X, available from Apple Inc. of Cupertino, Calif.; iOS, available from Apple Inc. of Cupertino, Calif.; Android, available from Google, Inc. of Mountain View, Calif.; and/or any other operating system that is adapted for use on the device.
- the techniques described herein can be implemented in a distributed processing environment, networked computing environment, or web-based computing environment. Elements can be implemented on client computing devices, servers, routers, and/or other network or non-network components. In some embodiments, the techniques described herein are implemented using a client/server architecture, wherein some components are implemented on one or more client computing devices and other components are implemented on one or more servers. In one embodiment, in the course of implementing the techniques of the present disclosure, client(s) request content from server(s), and server(s) return content in response to the requests.
- a browser may be installed at the client computing device for enabling such requests and responses, and for providing a user interface by which the user can initiate and control such interactions and view the presented content.
- Any or all of the network components for implementing the described technology may, in some embodiments, be communicatively coupled with one another using any suitable electronic network, whether wired or wireless or any combination thereof, and using any suitable protocols for enabling such communication.
- a network is the Internet, although the techniques described herein can be implemented using other networks as well.
Abstract
Description
-
- Alias-free resolution: a resolution equal to the number of microlenses in the plenoptic microlens array; two-dimensional images created at this resolution from a light field image typically do not contain objectionable processing artifacts.
- Aperture stop: The element, be it the rim of a lens or a separate diaphragm, which determines the amount of light reaching the image. In this disclosure, “aperture stop” and “aperture” may be used interchangeably.
- Conventional image: an image in which the pixel values are not, collectively or individually, indicative of the angle of incidence at which light is received by a camera.
- Depth: a representation of distance between an object and/or corresponding image sample and a microlens array of a camera.
- Depth data: any depth or three-dimensional information that may be generated from light field data, which may include, but is not limited to, a depth map, a three-dimensional point cloud, and/or a three-dimensional mesh.
- Depth map: a two-dimensional array of depth values, which may be calculated from a light field image. See also “depth data.”
- Depth-of-field: the range of object distances for which a projected image (especially a virtual view) is sharp to some sufficient degree.
- Disk: a region in a light-field image that is illuminated by light passing through a single microlens; may be circular or any other suitable shape.
- Elliptical packing: a packing pattern that tessellates stretched hexagonal regions onto a stretched hexagonal lattice. In this disclosure, elliptical packing is used to describe the pattern of the microlens elements in the microlens array. An example of this packing is shown in
FIG. 17D . - Entrance pupil: in an optical system, the optical image of the physical aperture stop, as seen through the front of the lens system. The geometric size, location, and angular acceptance of the entrance pupil acts as the camera's window of view into the world.
- Exit pupil: the exit pupil is the image of the aperture stop as seen from an axial point on the image plane through the interposed lenses, if there are any. In a light-field camera, the image plane is best thought of as the active surface of the microlens array.
- F-Number (f/#): focal length divided by entrance pupil size. In this document, the entrance pupil size used in the calculation of f/# is considered to be the width or height for a square, the inner diameter for a hex, or the diameter of a circle. The f/# of the microlens array may be considered to be the lens pitch (equal to the distance between the centers of neighboring lens elements) divided by the distance between the microlens array and the sensor surface.
- Hexagonal packing: a packing pattern that tessellates hexagonal regions onto a hexagonal lattice. In this disclosure, hexagonal packing is a specific type of elliptical packing where the hexagon is regular. In this disclosure, hexagonal packing is used to describe the pattern of the microlens elements in the microlens array. An example of this packing is shown in
FIG. 17C . - Image: a two-dimensional array of pixel values, or pixels, each specifying a color.
- Input device: any device that receives input from a user.
- Light-field camera: any camera or device capable of capturing light-field images.
- Light-field coordinate, or “four-dimensional light-field coordinate”: for a single light-field camera, the four-dimensional coordinate (for example, x, y, u, v) used to index a light-field sample captured by a light-field camera, in which (x, y) may be the spatial coordinate representing the intersection point of a light ray with a microlens array, and (u, v) may be the angular coordinate representing an intersection point of the light ray with an aperture plane.
- Light-field data: data indicative of the angle of incidence at which light is received by a camera.
- Light-field image: an image that contains a representation of light-field data captured at the sensor, which may be a four-dimensional sample representing information carried by ray bundles received by a single light-field camera.
- Main lens, or objective lens: a lens or set of lenses that directs light from a scene toward an image sensor.
- Microlens: a small lens, typically one in an array of similar microlenses.
- Microlens array: an array of microlenses arranged in a predetermined pattern.
- MLA-to-exit pupil rotation: the rotation, in degrees, of the long axis of the exit pupil relative to a primary axis of the microlens array.
- MLA-to-sensor rotation: the rotation, in degrees, of a primary axis of the microlens array relative to a primary axis of the photosensor array.
- Narrow F/#: For an irregular exit pupil, the f/# based on the short axis of the exit pupil.
- Optical baseline: the size of the entrance pupil, as measured across some axis. In this disclosure, the optical baseline refers to the measurement across the long axis, unless otherwise specified. Larger optical baselines equate to greater disparity between the opposing sides of the entrance pupil. The greater disparity may increase the accuracy of certain types of calculations, particularly in the generation of depth data.
- Packing, or packing arrangement: the manner in which microlenses are arranged to form a microlens array
- Plenoptic light-field camera: a type of light-field camera that employs a microlens-based approach in which a plenoptic microlens array is positioned between the objective lens and the photosensor.
- Plenoptic microlens array: a microlens array in a plenoptic camera that is used to capture directional information for incoming light rays, with each microlens creating an image of the aperture stop of the objective lens on the surface of the image sensor.
- Processor: any processing device capable of processing digital data, which may be a microprocessor, ASIC, FPGA, or other type of processing device.
- Ray bundle, ray, or bundle: a set of light rays recorded in aggregate by a single pixel in a photosensor.
- Rectangular packing: a packing pattern that tessellates rectangular regions onto a rectangular grid. In this disclosure, rectangular packing is used to describe the pattern of the microlens elements in the microlens array. An example of this packing is shown in
FIG. 17B . - Segment, or image segment: a single image of the exit pupil, viewed through a plenoptic microlens, and captured by a region on the surface of an image sensor.
- Sensor, photosensor, or image sensor: a light detector in a camera capable of generating images based on light received by the sensor.
- Subview: the view or image from an individual view in a light-field camera (a subaperture image in a plenoptic light-field camera, or an image created by a single objective lens in an objective lens array in an array light-field camera).
- Super resolution: resolutions higher than the alias-free resolution. Certain image processing techniques can significantly increase the resolution of reconstructed two-dimensional images, but may introduce objectionable visual artifacts.
- Virtual view: a two-dimensional image created by processing a light field image based on various parameters. Virtual view types include, but are not limited to, refocused images and extended depth of field (EDOF) images.
- Wide F/#: For an irregular exit pupil, the f/# based on the long axis of the exit pupil.
angle=90−atan(k)
width=SQRT(k{circumflex over ( )}2+1)
height=1/W
aspect_ratio=width:height
-
- “k” is a the sequence number
- “angle” is the MLA-Exit Pupil rotation, in degrees
- “width” is the width of the disk image, relative to the width at k=0
- “height” is the height of the disk image, relative to the height at k=0
- “aspect_ratio” is the aspect ratio of disk images that results in fully tessellated packing, on the sensor, with no dead space or overlap
k | angle | width | | aspect ratio | |
0 | 90 | 1 | 1 | 1:1 |
1 | 45 | 1.41 | 0.707 | 2:1 |
2 | 26.6 | 2.24 | 0.447 | 5:1 |
3 | 18.4 | 3.16 | 0.316 | 10:1 |
4 | 14.0 | 4.12 | 0.243 | 17:1 |
angle=atan(0.5*sqrt(3)/(k+0.5))
width=SQRT((k+0.5){circumflex over ( )}2+(0.5*SQRT(3)){circumflex over ( )}2)
height=SQRT(3)/(W*2)
aspect_ratio=width:height
-
- k is a the sequence number
- angle is the MLA-Exit Pupil rotation, in degrees
- width is the width of the disk image, relative to the width at k=0
- height is the height of the disk image, relative to the height at k=0
- aspect_ratio is the aspect ratio of disk images that results in fully tessellated packing, on the sensor, with no dead space or overlap
MLA-Exit | |||||
k | Pupil rotation | width | | aspect ratio | |
0 | 60 | 1 | 1 | 1:1 |
1 | 30 | 1.73 | 0.5 | 3.5:1 |
2 | 19.1 | 2.65 | 0.33 | 8:1 |
3 | 13.9 | 3.61 | 0.24 | 15:1 |
4 | 10.9 | 4.58 | 0.19 | 24:1 |
(x,y,u,v)=f(s,t)
diskImageList = lightField.getDiskImageList( ) | ||
for each diskImage in diskImageList | ||
x = diskImage.center.s / lightField.raster.width | ||
y = diskImage.center.t / lightField.raster.height | ||
bb = diskImage.boundingBox | ||
for (t=bb.startT; t<bb.endT; t++) | ||
for (s=bb.startS; s<bb.endS; s++) |
if (diskImage.mask.contains(s, t) | ||
deltaS = diskImage.center.s − s | ||
deltaT = diskImage.center.t − t | ||
u = lightField.deltaPixelsToAngularCoord(deltaS) | ||
v = lightField.deltaPixelsToAngularCoord(deltaT) | ||
-
- lightField is a light-field image object. The object has a list of disk images, determined previously (for example, during a calibration process) or calculated as needed (for example, from a geometric and/or optical model of the camera system).
- x and y are the spatial light-field coordinates, in a normalized 0 to 1 range.
- diskImage is a disk image object. Each disk image knows the location of its center coordinate, contains a bounding box outside of which are no pixels in the disk image, and a masking test function that returns true if a raster coordinate contains image data associated with the disk image.
- u and v are the angular light-field coordinates, centered at 0.
- deltaPixelsToAngularCoord is a conversion function that converts from linear pixel offsets to an angular coordinate. The input is the offset of a raster coordinate from the center location of the disk image containing that coordinate along a single dimension.
Claims (14)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US16/032,261 US10897608B2 (en) | 2015-05-26 | 2018-07-11 | Capturing light-field images with uneven and/or incomplete angular sampling |
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201562166595P | 2015-05-26 | 2015-05-26 | |
US15/142,565 US10033986B2 (en) | 2015-05-26 | 2016-04-29 | Capturing light-field images with uneven and/or incomplete angular sampling |
US16/032,261 US10897608B2 (en) | 2015-05-26 | 2018-07-11 | Capturing light-field images with uneven and/or incomplete angular sampling |
Related Parent Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US15/142,565 Continuation US10033986B2 (en) | 2015-05-26 | 2016-04-29 | Capturing light-field images with uneven and/or incomplete angular sampling |
Publications (2)
Publication Number | Publication Date |
---|---|
US20190124318A1 US20190124318A1 (en) | 2019-04-25 |
US10897608B2 true US10897608B2 (en) | 2021-01-19 |
Family
ID=57394198
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US15/142,565 Active 2036-06-22 US10033986B2 (en) | 2015-05-26 | 2016-04-29 | Capturing light-field images with uneven and/or incomplete angular sampling |
US16/032,261 Active 2036-07-01 US10897608B2 (en) | 2015-05-26 | 2018-07-11 | Capturing light-field images with uneven and/or incomplete angular sampling |
Family Applications Before (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US15/142,565 Active 2036-06-22 US10033986B2 (en) | 2015-05-26 | 2016-04-29 | Capturing light-field images with uneven and/or incomplete angular sampling |
Country Status (2)
Country | Link |
---|---|
US (2) | US10033986B2 (en) |
WO (1) | WO2016191035A1 (en) |
Families Citing this family (9)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10317597B2 (en) * | 2014-08-26 | 2019-06-11 | The Board Of Trustees Of The Leland Stanford Junior University | Light-field microscopy with phase masking |
KR102507383B1 (en) * | 2016-11-08 | 2023-03-08 | 한국전자통신연구원 | Method and system for stereo matching by using rectangular window |
KR102646437B1 (en) * | 2016-11-25 | 2024-03-11 | 삼성전자주식회사 | Captureing apparatus and metohd based on multi lens |
WO2018205164A1 (en) * | 2017-05-10 | 2018-11-15 | Shanghaitech University | Method and system for three-dimensional model reconstruction |
EP3416381A1 (en) | 2017-06-12 | 2018-12-19 | Thomson Licensing | Method and apparatus for providing information to a user observing a multi view content |
EP3416371A1 (en) * | 2017-06-12 | 2018-12-19 | Thomson Licensing | Method for displaying, on a 2d display device, a content derived from light field data |
CN109141347A (en) * | 2017-06-28 | 2019-01-04 | 京东方科技集团股份有限公司 | Vehicle-mounted vidicon distance measuring method and device, storage medium and electronic equipment |
WO2020214719A1 (en) * | 2019-04-15 | 2020-10-22 | Owl Autonomous Imaging, Inc. | Thermal ranging devices and methods |
KR20220053067A (en) | 2020-10-21 | 2022-04-29 | 삼성전자주식회사 | Device for improving image resolution in camera system having lens causing distortion and operation method thereof |
Citations (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20100265385A1 (en) * | 2009-04-18 | 2010-10-21 | Knight Timothy J | Light Field Camera Image, File and Configuration Data, and Methods of Using, Storing and Communicating Same |
US20130229532A1 (en) * | 2012-03-01 | 2013-09-05 | Canon Kabushiki Kaisha | Image processing device, image processing method, and program |
Family Cites Families (21)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP3801616B2 (en) | 2003-05-29 | 2006-07-26 | 松下電器産業株式会社 | Imaging device |
EP2398224B1 (en) | 2004-10-01 | 2016-01-13 | The Board of Trustees of The Leland Stanford Junior University | Imaging arrangements and methods therefor |
WO2007092545A2 (en) | 2006-02-07 | 2007-08-16 | The Board Of Trustees Of The Leland Stanford Junior University | Variable imaging arrangements and methods therefor |
US7620309B2 (en) | 2006-04-04 | 2009-11-17 | Adobe Systems, Incorporated | Plenoptic camera |
US20080260291A1 (en) | 2007-04-17 | 2008-10-23 | Nokia Corporation | Image downscaling by binning |
US8290358B1 (en) * | 2007-06-25 | 2012-10-16 | Adobe Systems Incorporated | Methods and apparatus for light-field imaging |
US8559756B2 (en) | 2007-08-06 | 2013-10-15 | Adobe Systems Incorporated | Radiance processing by demultiplexing in the frequency domain |
US7962033B2 (en) | 2008-01-23 | 2011-06-14 | Adobe Systems Incorporated | Methods and apparatus for full-resolution light-field capture and rendering |
US8189065B2 (en) | 2008-01-23 | 2012-05-29 | Adobe Systems Incorporated | Methods and apparatus for full-resolution light-field capture and rendering |
JP4483951B2 (en) | 2008-01-28 | 2010-06-16 | ソニー株式会社 | Imaging device |
US8289440B2 (en) | 2008-12-08 | 2012-10-16 | Lytro, Inc. | Light field data acquisition devices, and methods of using and manufacturing same |
US7949252B1 (en) | 2008-12-11 | 2011-05-24 | Adobe Systems Incorporated | Plenoptic camera with large depth of field |
US8817015B2 (en) | 2010-03-03 | 2014-08-26 | Adobe Systems Incorporated | Methods, apparatus, and computer-readable storage media for depth-based rendering of focused plenoptic camera data |
JP5671842B2 (en) | 2010-06-03 | 2015-02-18 | 株式会社ニコン | Image processing apparatus and imaging apparatus |
US8768102B1 (en) | 2011-02-09 | 2014-07-01 | Lytro, Inc. | Downsampling light field images |
US8666191B2 (en) | 2011-03-02 | 2014-03-04 | Canon Kabushiki Kaisha | Systems and methods for image capturing |
US8995785B2 (en) | 2012-02-28 | 2015-03-31 | Lytro, Inc. | Light-field processing and analysis, camera control, and user interfaces and interaction on light-field capture devices |
CN104303493A (en) * | 2012-05-09 | 2015-01-21 | 莱特洛公司 | Optimization of optical systems for improved light field capture and manipulation |
EP2693396A1 (en) * | 2012-07-30 | 2014-02-05 | Nokia Corporation | Method, apparatus and computer program product for processing of multimedia content |
EP2923483A1 (en) * | 2012-11-21 | 2015-09-30 | Nokia Technologies Oy | A module for plenoptic camera system |
US9030580B2 (en) * | 2013-09-28 | 2015-05-12 | Ricoh Company, Ltd. | Color filter modules for plenoptic XYZ imaging systems |
-
2016
- 2016-04-29 WO PCT/US2016/030121 patent/WO2016191035A1/en active Application Filing
- 2016-04-29 US US15/142,565 patent/US10033986B2/en active Active
-
2018
- 2018-07-11 US US16/032,261 patent/US10897608B2/en active Active
Patent Citations (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20100265385A1 (en) * | 2009-04-18 | 2010-10-21 | Knight Timothy J | Light Field Camera Image, File and Configuration Data, and Methods of Using, Storing and Communicating Same |
US20130229532A1 (en) * | 2012-03-01 | 2013-09-05 | Canon Kabushiki Kaisha | Image processing device, image processing method, and program |
Also Published As
Publication number | Publication date |
---|---|
US10033986B2 (en) | 2018-07-24 |
WO2016191035A1 (en) | 2016-12-01 |
US20190124318A1 (en) | 2019-04-25 |
US20160353082A1 (en) | 2016-12-01 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US10897608B2 (en) | Capturing light-field images with uneven and/or incomplete angular sampling | |
US9900510B1 (en) | Motion blur for light-field images | |
US10085005B2 (en) | Capturing light-field volume image and video data using tiled light-field cameras | |
CN110036410B (en) | Apparatus and method for obtaining distance information from view | |
US20170059305A1 (en) | Active illumination for enhanced depth map generation | |
US20170256036A1 (en) | Automatic microlens array artifact correction for light-field images | |
US20170365068A1 (en) | Combining light-field data with active depth data for depth map generation | |
US8749694B2 (en) | Methods and apparatus for rendering focused plenoptic camera data using super-resolved demosaicing | |
US10200624B2 (en) | Three-dimensional, 360-degree virtual reality exposure control | |
WO2018024006A1 (en) | Rendering method and system for focused light-field camera | |
TWI536822B (en) | Imaging systems and methods using square image sensor for flexible image orientation | |
US9955057B2 (en) | Method and apparatus for computational scheimpflug camera | |
US10545215B2 (en) | 4D camera tracking and optical stabilization | |
WO2016168415A1 (en) | Light guided image plane tiled arrays with dense fiber optic bundles for light-field and high resolution image acquisition | |
US20170295324A1 (en) | Three-dimensional, 360-degree virtual reality camera system | |
KR102635003B1 (en) | Light field data representation | |
US20170332000A1 (en) | High dynamic range light-field imaging | |
JP6234401B2 (en) | Image processing apparatus, imaging apparatus, image processing method, and program | |
Ueno et al. | Compound-Eye Camera Module as Small as 8.5$\times $8.5$\times $6.0 mm for 26 k-Resolution Depth Map and 2-Mpix 2D Imaging | |
WO2019096057A1 (en) | Dynamic image generation method, and processing device | |
TWI717387B (en) | An apparatus and a method for computer implemented generating data, a light field imaging device, a device for rendering an image and a non-transitory computer program product for a programmable apparatus | |
US20210112234A1 (en) | Light field data representation | |
Bazeille et al. | Light-field image acquisition from a conventional camera: design of a four minilens ring device | |
Corke | Image Formation | |
Wu et al. | Automatic calibration and simplified decoding pipeline for plenoptic camera |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
FEPP | Fee payment procedure |
Free format text: ENTITY STATUS SET TO UNDISCOUNTED (ORIGINAL EVENT CODE: BIG.); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
AS | Assignment |
Owner name: LYTRO, INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:PITTS, COLVIN;LIANG, CHIA-KAI;AKELEY, KURT;SIGNING DATES FROM 20160420 TO 20160424;REEL/FRAME:048242/0485Owner name: GOOGLE LLC, CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:LYTRO, INC.;REEL/FRAME:048261/0618Effective date: 20180325 |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: DOCKETED NEW CASE - READY FOR EXAMINATION |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NON FINAL ACTION MAILED |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: RESPONSE TO NON-FINAL OFFICE ACTION ENTERED AND FORWARDED TO EXAMINER |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NON FINAL ACTION MAILED |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: RESPONSE TO NON-FINAL OFFICE ACTION ENTERED AND FORWARDED TO EXAMINER |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NOTICE OF ALLOWANCE MAILED -- APPLICATION RECEIVED IN OFFICE OF PUBLICATIONS |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: PUBLICATIONS -- ISSUE FEE PAYMENT VERIFIED |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |