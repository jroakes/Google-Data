CN107071440A - Use the motion-vector prediction of previous frame residual error - Google Patents
Use the motion-vector prediction of previous frame residual error Download PDFInfo
- Publication number
- CN107071440A CN107071440A CN201611234686.6A CN201611234686A CN107071440A CN 107071440 A CN107071440 A CN 107071440A CN 201611234686 A CN201611234686 A CN 201611234686A CN 107071440 A CN107071440 A CN 107071440A
- Authority
- CN
- China
- Prior art keywords
- value
- pixel
- frame
- mask
- residual error
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/103—Selection of coding mode or of prediction mode
- H04N19/105—Selection of the reference unit for prediction within a chosen coding or prediction mode, e.g. adaptive choice of position and number of pixels used for prediction
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/117—Filters, e.g. for pre-processing or post-processing
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/119—Adaptive subdivision aspects, e.g. subdivision of a picture into rectangular or non-rectangular coding blocks
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/124—Quantisation
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/132—Sampling, masking or truncation of coding units, e.g. adaptive resampling, frame skipping, frame interpolation or high-frequency transform coefficient masking
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/134—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or criterion affecting or controlling the adaptive coding
- H04N19/136—Incoming video signal characteristics or properties
- H04N19/137—Motion inside a coding unit, e.g. average field, frame or block difference
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/134—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or criterion affecting or controlling the adaptive coding
- H04N19/146—Data rate or code amount at the encoder output
- H04N19/147—Data rate or code amount at the encoder output according to rate distortion criteria
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/134—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or criterion affecting or controlling the adaptive coding
- H04N19/157—Assigned coding mode, i.e. the coding mode being predefined or preselected to be further used for selection of another element or parameter
- H04N19/159—Prediction type, e.g. intra-frame, inter-frame or bidirectional frame prediction
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/169—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding
- H04N19/17—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding the unit being an image region, e.g. an object
- H04N19/176—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding the unit being an image region, e.g. an object the region being a block, e.g. a macroblock
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/169—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding
- H04N19/182—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding the unit being a pixel
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/169—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding
- H04N19/186—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding the unit being a colour or a chrominance component
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/44—Decoders specially adapted therefor, e.g. video decoders which are asymmetric with respect to the encoder
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/50—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding
- H04N19/503—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding involving temporal prediction
- H04N19/51—Motion estimation or motion compensation
- H04N19/513—Processing of motion vectors
- H04N19/517—Processing of motion vectors by encoding
- H04N19/52—Processing of motion vectors by encoding by predictive encoding
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/50—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding
- H04N19/503—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding involving temporal prediction
- H04N19/51—Motion estimation or motion compensation
- H04N19/537—Motion estimation other than block-based
- H04N19/543—Motion estimation other than block-based using regions
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/50—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding
- H04N19/593—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using predictive coding involving spatial prediction techniques
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/60—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using transform coding
- H04N19/61—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using transform coding in combination with predictive coding
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/60—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using transform coding
- H04N19/625—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using transform coding using discrete cosine transform [DCT]
Abstract
The present invention relates to a kind of motion-vector prediction of use previous frame residual error.Poor Residual Generation mask between the pixel value as at least two frames in addition to the present frame in video sequence.Then, mask is used by inter prediction encoding or decoding current block.Mask forms the edge of object in the border of object, and can be used in the different piece of reference frame being combined into single piece.This can improve code efficiency.
Description
Background technology
Digital video frequency flow represents video usually using frame sequence or rest image.Each frame can include multiple pieces, should
Block can include the information of the value for color, brightness or other attributes for describing pixel in turn.Data volume in video flowing is very big,
And the transmission and storage of video can use substantial amounts of calculating or the communication resource.Due to being related to mass data in video data,
Therefore need high performance compression to transmit and store.This is usually directed to the inter prediction using motion vector.
The content of the invention
Present invention relates in general to code and decode vision data using the motion-vector prediction using previous frame residual error,
Such as video stream data.
Included according to the method for being used for coding or decoding video signal of an aspect of this disclosure：From as except present frame
Outside at least two frames pixel value between poor residual error in current block in generation present frame mask, and by making
With the inter prediction encoding or decoding current block of the mask.Vision signal include define video sequence frame, these frames have by
The block of pixel composition.
Device described herein be on one side for encode or decoding video signal device, the vision signal includes
Multiple frames of video sequence are defined, these frames have the block being made up of pixel.The device includes processor and non-transitory is stored
Device, non-transitory memory storage includes making the instruction of computing device method, and methods described includes：According to Residual Generation video
The mask of the current block in present frame in sequence, residual error is between the pixel value of at least two frames in addition to present frame
Difference, and pass through inter prediction encoding or decoding current block using mask.
The another aspect of equipment described herein be it is a kind of be used for generate for encode or decoding video signal work as
The device of preceding piece of mask, the vision signal includes defining multiple frames of video sequence, and these frames have block, and these blocks are by picture
Element composition.The device includes processor and non-transitory memory, and non-transitory memory storage includes making computing device side
The instruction of method, method includes：Residual error, the first frame are calculated by subtracting the pixel value of the first frame in from the pixel value of the second frame in
Before the present frame being respectively positioned on each frame in the second frame in video sequence, by threshold application in the respective pixel in residual error
The pixel value of position, includes the threshold value residual error of pixel to generate, and each pixel in the threshold value residual error has the first value or different
One in the second value of the first value, and first area or bag of the extension including the threshold value residual error with the first pixel being worth
At least one in the second area for the threshold value residual error for including the pixel with second value, has pixel to be formed with the first value
The mask of second continuous part of the first continuous part of position and the location of pixels with second value, the first continuous part and
Two continuous parts are not overlapping, and the border between the first continuous part and the second continuous part extends on the both sides of mask；And
And, wherein mask has and the current block identical pixel size.
These and other side of the disclosure is more fully described in book described further below, appended claims and accompanying drawing
Face.
Brief description of the drawings
This specification with reference to drawings discussed below, wherein identical reference refers to identical in several views
Part.
Fig. 1 is the schematic diagram that Video coding conciliates code system.
Fig. 2 is that by the block diagram of the example of the computing device of dispatching station or receiving station.
Fig. 3 is the figure for the video flowing that encode and then decode.
Fig. 4 is the block diagram of the video compression system according to the one side instructed herein.
Fig. 5 is the block diagram of the video decompression system according to the another aspect instructed herein.
Fig. 6 is encoded or solved according to the motion-vector prediction by using previous frame residual error of an embodiment of the disclosure
The flow chart of the process of code block.
Fig. 7 is the flow for being used for the process using previous frame Residual Generation mask of an embodiment according to the disclosure
Figure.
Fig. 8 A-8C are the figures for illustrating Fig. 7 process.
Embodiment
Video flowing can be compressed to reduce by various technologies needed for transmission or store video flowing bandwidth.Video flowing
It can be encoded into bit stream, bit stream can be related to compression, be then communicated to decoder, decoder can be decoded or solved
Compressed video data is so that it prepares to be used to watch or further processing.Encoded video stream can be related in video quality and bit stream
The parameter of balance between size, wherein, transmission or stored bits stream can be increased by increasing the perceived quality of the video flowing of decoding
Required bit number.
A kind of technology for realizing good compression performance utilizes the space of vision signal by space and/or motion compensated prediction
And temporal correlation.For example, inter prediction recognizes the previous coding similar to the current block to be encoded using motion vector
With the block of decoding.By the difference between encoding motion vector and two blocks, decoder can re-create current block.However,
Object seldom falls on conventional block boundary in the picture.The result is that code efficiency.
On the contrary, teaching herein describes the generation for not needing block (for example, square) inter predictor and used, so as to
Preferably match the object of frame in.This can create the steep cliff mask (cliff for block by using the residual error of previous frame
Mask) realize, it allows two different motion vectors being applied to the block.To can wherein use teaching herein
Further details are described after the initial discussion of environment.
Fig. 1 is the schematic diagram that Video coding conciliates code system 100.Dispatching station 102 can for example be retouched with such as Fig. 1
The computer of the inside configuration for the hardware stated.However, other suitable embodiments of dispatching station 102 are possible.For example, hair
102 processing of seeing off can be distributed between devices.
Network 104 can be with linkup transmit station 102 and receiving station 106, the coding and decoding for video flowing.Specifically, may be used
With the encoded video stream in dispatching station 102, and the video flowing encoded can be decoded in receiving station 106.Network 104 can be with
It is such as internet.Network 104 can also be LAN (LAN), wide area network (WAN), VPN (VPN), honeycomb electricity
Telephone network or any other means that video flowing is sent to such as receiving station 106 from dispatching station 102 in this example.
In one example, receiving station 106 can be the calculating of the inside configuration with all hardware as described in Figure 1
Machine.However, other suitable embodiments of receiving station 106 are possible.For example, the processing of receiving station 106 can be distributed in
Between multiple equipment.
The other embodiment that Video coding conciliates code system 100 is possible.For example, embodiment can omit network
104.In another embodiment, video flowing can be encoded, and be then stored for being transferred to receiving station 106 later or have
Any other equipment of memory.In one embodiment, receiving station 106 is received (for example, total via network 104, computer
Line and/or some communication paths) coding video flowing, and store video flowing to decode later.It is real in example embodiment
When host-host protocol (RTP) be used for by network 104 transmit coding video.In another embodiment, can use except RTP it
Outer host-host protocol, such as the video stream protocol based on HTTP (HTTP).
When in video conferencing system in use, for example, dispatching station 102 and/or receiving station 106 can include it is as described below
Coding and decoding video flowing ability.For example, receiving station 106 can be video conference participants, it is from video conference service
Device (for example, dispatching station 102) receives coded video bit stream to decode and watch, and further coding and by the video of its own
Bit stream, which is sent to videoconference server, to be used to be decoded and be watched by other participants.
Fig. 2 is the block diagram of the example for the computing device 200 that can implement dispatching station or receiving station.For example, computing device 200
One or two in Fig. 1 dispatching station 102 and receiving station 106 can be implemented.Computing device 200 can include multiple calculate
The form of the computing system of equipment, or can be the form of single computing device, such as mobile phone, tablet PC, knee
Laptop computer, notebook, desktop computer etc..
CPU 202 in computing device 200 can be CPU.Or, CPU 202 can be can manipulate or
The equipment or multiple equipment of any other type of the information that processing is developed now or in the future.Although disclosed embodiment can
To use single processor as depicted, such as CPU 202 is implemented, but more than one processor can be used to realize speed
Advantage in terms of degree and efficiency.
In embodiments, the memory 204 in computing device 200 can be read-only storage (ROM) equipment or random
Access memory (RAM) equipment.The storage device of any other suitable type may be used as memory 204.Memory 204 can be with
Including by the codes accessed using bus 212 of CPU 202 and data 206.Memory 204 can also include the He of operating system 208
Application program 210, application program 210 includes at least one program for allowing CPU 202 to perform method described here.Example
Such as, application program 210 can include applying 1 to N, and it also includes the Video coding application for performing method described here.Meter
Holder 214 can also be included by calculating equipment 200, and holder 214 for example can be the storage being used together with mobile computing device
Card.Because video communication sessions can include substantial amounts of information, they can be stored in holder 214 whole or in part
In, and needed according to processing to be loaded into memory 204.
Computing device 200 can also include one or more output equipments, such as display.In one example, show
Device 218 can be touch-sensitive display, and it combines display with the operable tactile sensor inputted with sensing touch.Display
218 can be coupled to CPU 202 via bus 212.In addition to display 218 or it is used as the replacement of display 218, Ke Yiti
Allow for user program perhaps or otherwise use other output equipments of computing device 200.When output equipment be display or
During including display, display can be implemented by number of ways, including liquid crystal display (LCD), cathode-ray tube (CRT) are aobvious
Show device or light emitting diode (LED) display, such as Organic Light Emitting Diode (OLED) display.
Computing device 200 can also include image sensing apparatus 220 or be communicated with image sensing apparatus 220, image sense
Measurement equipment 220 be, for example, camera, or now exist or in the future exploitation can sense such as image manipulation computing device 200
User image any other image sensing apparatus 220.Image sensing apparatus 220 may be oriented such that it points to behaviour
Make the user of computing device 200.In this example, the position of image sensing apparatus 220 and optical axis can be arranged such that visual field is wrapped
Include with the direct neighbor of display 218 and display 218 from its visible region.
Computing device 200 can also include sound sensing equipment 222, or be communicated with sound sensing equipment 222, sound sense
Measurement equipment 222 is, for example, microphone, or exist now or Future Development can sense the sound near computing device 200
Any other sound sensing equipment.Sound sensing equipment 222 may be oriented such that its point operation computing device 200
User, and can be configured as receiving the sound that is sent by user in user's operating computing device 200, for example voice or its
His sounding.
Although the CPU 202 and memory 204 of computing device 200 are described as being integrated into individual unit by Fig. 2, can
To utilize other configurations.CPU 202 operation can be distributed in can directly or across local or other networks couple it is multiple
On machine (each machine has one or more processors).Memory 204 can be distributed on multiple machines, such as based on net
The memory of network or the memory in multiple machines of operation of computing device 200 are performed.Although being depicted as list here
Individual bus, but the bus 212 of computing device 200 can be made up of multiple buses.In addition, holder 214 can be with direct-coupling
To the other assemblies of computing device 200, or can be via network access, and the single integrated of such as storage card can be included
Multiple units of unit or such as multiple storage cards.Therefore computing device 200 can be implemented with various configurations.
Fig. 3 is the exemplary plot for the video flowing 300 that encode and then decode.Video flowing 300 includes video sequence 302.
Next stage, video sequence 302 includes multiple consecutive frames 304.Although three frames are depicted as consecutive frame 304, video sequence
302 can include any amount of consecutive frame 304 and then consecutive frame 304 can be further subdivided into single frame, such as frame
306.In next stage, frame 306 can be divided into a series of planes or fragment 308.Fragment 308 can for example allow parallel place
The subset of the frame of reason.Fragment 308 can also be the subset for the frame that video data can be separated into seperate color.For example, colored
The frame 306 of video data can include luminance plane and two colorimetric planes.Fragment 308 can be carried out at varying resolutions
Sampling.
No matter whether frame 306 is divided into fragment 308, and frame 306 can be further subdivided into block 310, and block 310 can be included
Corresponding to the data of 16 × 16 pixels in such as frame 306.Block 310 can also be arranged to include one from pixel data
Or the data of multiple planes.Block 310 can also be any other suitable size, such as 4 × 4 pixels, 8 × 8 pixels, 16 × 8
Pixel, 8 × 16 pixels, 16 × 16 pixels or bigger.Unless otherwise stated, term ' block ' and ' macro block ' herein can be mutual
Change and use.Can be according to teaching herein come by the subregion of frame 306 as discussed in greater detail below.
Fig. 4 is the block diagram of the encoder 400 according to embodiment.As described above, encoder 400 can be in dispatching station 102
In be such as stored in the computer software programs in such as memory of memory 204 by providing and implement.Computer software
Program can include machine instruction, and when by processor, for example CPU 202 is performed, machine instruction makes dispatching station 102 with described in Fig. 4
Mode video data is encoded.Encoder 400 can also be implemented as being included in special hard in such as dispatching station 102
Part.Encoder 400 is used with following at different levels to perform various functions in forward path (being shown by real connection line) with producing
The bit stream 420 that video flowing 300 is encoded or compressed as input：Prediction stage 402, conversion stage 404, quantized level within the frame/frames
406 and entropy code level 408.Encoder 400 can also include reconstruct path (being shown by virtually connecting wiring) to be used to encode not to reconstruct
Carry out the frame of block.As shown in figure 4, encoder 400 has the following various functions at different levels to perform in reconstruct path：Quantification level
410, inverse transformation level 412, reconstruction stage 414 and loop filtering level 416.The other structures change of encoder 400 can be used for coding
Video flowing 300.
When video flowing 300 is rendered for coding, frame 306 can be handled in units of block.Predicting within the frame/frames
Level 402, can be used frame in-prediction (also referred to as infra-frame prediction) or inter prediction (also referred herein as inter prediction or interframe-pre-
Survey) carry out encoding block.It is in any case possible to form prediction block.In the case of infra-frame prediction, can from previously encoded and
Sample formation prediction block in the present frame of reconstruction., can be from one or more previous construction in the case of inter prediction
Reference frame in sample formation prediction block, what following article was discussed in more detail.
Next, again referring to Fig. 4, prediction block can be subtracted from current block in prediction stage 402 within the frame/frames, it is residual to produce
Poor block (also referred to as residual error).Conversion stage 404 uses block-based conversion to be conversion coefficient by real transform in such as frequency domain.This
Planting block-based conversion includes such as discrete cosine transform (DCT) and asymmetric discrete sine transform (ADST).Other are based on block
Conversion be possible.In addition, the combination of different conversion can apply to single residual error.In an example of the application of conversion
In, DCT transforms to residual block in frequency domain, and wherein transform coefficient values are based on spatial frequency.The low-limit frequency in the matrix upper left corner
(DC) coefficient and the highest frequency coefficient in the matrix lower right corner.It is worth noting that, the size of prediction block and therefore obtain it is residual
Poor block can be differently configured from the size of transform block.For example, prediction block can be divided into be applied to individually to convert smaller
Block.
Conversion coefficient is converted to discrete quantised value by quantized level 406 using quantizer values or quantification gradation, and it is referred to as quantifying
Conversion coefficient.For example, conversion coefficient can with divided by quantizer values and be truncated.Quantified conversion coefficient is then by entropy code
Level 408 carries out entropy code.Any amount of technology (including token and binary tree) can be used to perform entropy code.Then by entropy
The coefficient of coding can include for example used type of prediction, transformation classes together with the other information for being decoded to block
Type, motion vector and quantizer values, are output to compression bit stream 420 together.What compression bit stream 420 can be encoded also referred to as regards
Frequency flow or coding video bit stream, and these terms are by used interchangeably herein.
Reconstruct path (being shown by virtually connecting wiring) in Fig. 4 can be used to ensure that encoder 400 and decoder 500 (below
Description) bit stream 420 of compression is decoded using identical reference frame.Reconstruct path performs similarly to retouch in further detail below
The function of occurring in the decoding process stated, the conversion coefficient for being included in quantification 410 pairs of quantizations of level carries out quantification and inverse
Conversion stage 412 carries out inverse transformation to the conversion coefficient of quantification, to produce derivative residual block (also referred to as derivative residual error).In reconstruct
In the stage 414, the prediction block predicted at prediction stage 402 within the frame/frames can be added to derivative residual error to create reconstructed blocks.Ring
Road filtering stage 416 can apply to reconstructed blocks to reduce the distortion of such as block artifacts.
Other modifications of encoder 400 can be used for encoding compression bit stream 420.For example, based on non-shifting
Encoder 400 can directly quantify residual signal for some pieces or frame, without conversion stage 404.In another embodiment
In, quantized level 406 and quantification level 410 can be combined into single level by encoder 400.
Fig. 5 is the block diagram of the decoder 500 according to another embodiment.Decoder 500 can be for example by providing storage
Computer software programs in memory 204 are implemented in receiving station 106.Computer software programs can refer to including machine
Order, when computing device of the machine instruction by such as CPU202 so that receiving station 106 decodes in the way of described in Fig. 5
Video data.Decoder 500 can also be implemented in the hardware in including such as dispatching station 102 or receiving station 106.
Similar to the reconstruct path of encoder 400 as discussed above, decoder 500 includes following rank in one example
Section with perform various functions with from bit stream 420 produce outputting video streams 516：Entropy decoding level 502, quantification level 504, inverse transformation
Level 506, within the frame/frames prediction stage 508, reconstruction stage 510, loop filtering level 512 and block elimination filtering level 514.Decoder 500 its
Its constructional variant can be used for the bit stream 420 of decoding compression.
When the bit stream 420 of compression is rendered for decoding, the data element in the bit stream 420 of compression can be by entropy
Decoder stage 502 is decoded, to produce the conversion coefficient of one group of quantization.The conversion coefficient of quantification 504 pairs of quantizations of level carries out quantification
(for example, by the way that the conversion coefficient of quantization is multiplied by into quantizer values), and inverse transformation level 506 uses selected alternative types pair
The conversion coefficient of quantification carries out inverse transformation, to produce derivative residual error, using the header information decoded from compression bit stream 420,
Decoder 500 can use within the frame/frames prediction stage 508 come create with encoder 400, such as in prediction stage within the frame/frames
402, the prediction block identical prediction block of establishment.In reconstruction stage 510, prediction block can be added to derivative residual error to create reconstruct
Block.Loop filtering level 512 can apply to reconstructed blocks to reduce block artifacts.Reconstructed blocks can be filtered using other.Show herein
In example, block elimination filtering level 514 is applied to reconstructed blocks to reduce block distortion, and result is output as outputting video streams 516.Output
Video flowing 516 may be additionally referred to as the video flowing of decoding, and term is by used interchangeably herein.
Other modifications of decoder 500 can be used for the bit stream 420 of decoding compression.For example, decoder 500 can not have
Outputting video streams 516 are produced in the case of having block elimination filtering level 514.
As set forth above, it is possible to which code block is encoded or solved by motion-vector prediction using previous frame residual error.In general, from two
The Residual Generation calculated between the pixel of individual frame (for example, most latter two frame before present frame) is used for the mask of block, and then
By using the inter prediction encoding or solution code block of mask.In this way, it is allowed to which two different motion vectors are applied to block
The object that mask can be used in preferably matching image, so as to improve video compress.
Fig. 6 be according to an embodiment of the disclosure be used for encoded using previous frame residual error by motion-vector prediction
Or the flow chart of the process 600 of solution code block.Method or process 600 can be implemented with auxiliary in such as system of computing device 200
Help coding or the decoding of video flowing.Process 600 may be implemented as the calculating for example by such as dispatching station 102 or receiving station 106
The software program that equipment is performed.Software program can include the machine readable finger being stored in such as memory of memory 204
Order, when machine readable instructions are by such as CPU 202 computing device so that computing device implementation procedure 600.Process 600
Hardware can also be used to realize in whole or in part.As described above, some computing devices can have multiple memories and multiple
The step of processor, and in this case, process 600 or operation can use different processor and memory to divide
Match somebody with somebody.The use of the term " processor " and " memory " of singulative herein includes only having a processor or a storage
The computing device of device and the equipment with multiple processors or memory, each processor or memory can be used for performing
Step, but Overall Steps need not be performed.
Simple for explanation, process 600 is depicted and is described as series of steps or operation.However, according to the disclosure
The step of and operation can occur in various orders and/or simultaneously.In addition, according to the step of the disclosure or operation can with herein
Other steps or operation for not presenting and describing occur together.In addition, the step of simultaneously not all is shown or operation are required for being used for
Realize the method according to disclosed theme.Can be to each frame repetitive process 600 of input signal.
When process 600 is cataloged procedure, input signal can be such as video flowing 300.Input signal can by with appoint
The computer of the mode implementation procedure 600 of what quantity is received.For example, input signal can be captured by image sensing apparatus 220, or
Input of the person by being connected to bus 212 is received from another equipment.In another embodiment, it can be retrieved from holder 214
Input signal.Other reception modes of input signal and other sources are also possible.For example, when process 600 is decoding process,
Input signal can be the bit stream of the coding of the bit stream 420 such as compressed.
Using input signal, 602, it is from the poor residual error between the pixel value as two frames in addition to present frame
Current block generation mask in present frame in video sequence.Generally, mask can be by calculating two frames (for example, present frame
Two frames before) between residual error, carry out thresholding to residual error and remove the residual error of thresholding generating.Can be with optional
Ground, which obscures a minor valve, is added to mask.
More specifically, Fig. 7 be according to an embodiment of the disclosure be used for use previous frame Residual Generation mask
The flow chart of process 700.Fig. 8 A-8C are the figures of the process 700 for explanation figure 7.
Method or process 700 can realize the coding or solution with auxiliary video stream in such as system of computing device 200
Code.Process 700 may be implemented as the software program for example by such as computing device of dispatching station 102 or receiving station 106.
Software program can include being stored in machine readable instructions in such as memory of memory 204, when machine readable instructions by
During such as CPU202 computing device so that computing device implementation procedure 700.Process 700 hardware can also be used overall or
Partly realize.As described above, some computing devices can have multiple memories and multiple processors, and in such case
Under, the step of process 700 or operation can use different processor and memory to be distributed.
For the purpose of simplifying the description, process 700 is depicted and described as series of steps or operation.However, according to the disclosure
Steps and operations can occur in various orders and/or simultaneously.In addition, according to the step of the disclosure or operation can with herein not
Other steps or operation for presenting and describing occur together.In addition, the step of simultaneously not all is shown or operation are required for being used in fact
Now according to the method for disclosed theme.Can be to each block or each frame repetitive process 700 of input signal.
In process 700,702, generation mask includes calculating the residual error between two frames.More specifically, can pass through
Subtract the pixel value of the first frame in calculate residual error from the pixel value of the second frame in, vice versa.First frame and the second frame can be with
Before the present frame in the video sequence defined by input signal.First frame and the second frame can be consecutive frames, but more
Desirably, their one or more frames in video sequence and the time quantum of definition are separated.In this example, the time of definition
Measure as 200ms, but other values are also possible.Pixel value can be represented in such as the first frame and the location of pixels of the second frame in
Some or all of luminance component or chromatic component.
In one embodiment, the picture of the pixel of the second frame in is subtracted from the pixel value of the common position pixel of the first frame in
Element value, vice versa.Position pixel has identical pixel coordinate in different frame altogether.In one embodiment, the second frame in
Pixel and the first frame in common position pixel and current block pixel altogether position.Or, the pixel of the second frame in and the first frame in
Pixel shift motion vector of the common position pixel relative to current block.In some cases, the picture in one of the first frame or the second frame
Element can be with the common position of present frame, and the pixel in another frame is relative to current block shift movement vector.Desirably, pixel value is
All pixel values for obtaining reconstruct from the coding of encoder and subsequent decoding process as described in Figure 4.
When generating mask in an encoding process, various technologies can be used to select the two frames.At one especially
In simple embodiment, most latter two consecutive frame before present frame is used.In another embodiment, it can select current
Last frame before frame, and at most it is identified as the frame of the reference frame of last frame.In other embodiments, it may be selected
Other frames are to provide the residual error for mask generating process.
When generating mask in decoding process, the two can be distinguished from the header information in the bit stream of coding
Frame, is discussed in greater detail below.
Residual error can represent the entirety or an only part for frame of frame.That is, the whole size or pin of frame can be directed to
To the only a part of frame, such as block of frame, to calculate residual error.An example is shown in Fig. 8 A.Wherein, from the second frame 804
Position pixel value subtracts all pixels value of the first frame 802 altogether.Result is residual frame (or residual error) 806.As that can see in fig. 8 a
Go out, the second that the circular object 808 of ball, moon etc. is moved in the second frame 804 from the first position in the first frame 802
Put.Residual error 806 shows the crescent by 810 of the difference of the pixel value of the first frame 802 and the second frame 804.In this case, using frame
Whole region calculate residual error.However, it is possible to the calculating to a part (for example, block base) implementation procedure 700 of frame or
Subsequent step.
Generation mask also includes in process 700,704, to the residual error threshold application in 702 generations.More specifically, mistake
Journey 700 can include threshold application in the pixel value of the respective pixel location in residual error, to generate threshold value residual error.Threshold value residual error
Including with the pixel with the part identical size of the residual error or residual error of threshold application.In some embodiments, threshold value is residual
Each pixel in difference has the first value or different from one in the second value of the first value.Threshold value can be on the occasion of or negative value,
Or can be with the scope of definition value.
In one embodiment, threshold application includes carrying out the pixel value of the respective pixel location in residual error and threshold value
Compare.Then, when pixel value is less than threshold value, the first value is assigned to the same pixel position in threshold value residual error.Or, work as picture
When element value is more than threshold value, second value is assigned to the same pixel position in threshold value residual error.For example, the first value can be zero, and
Second value can be max pixel value 256.In one embodiment, when the first value is value 0, second value is value 1.Threshold value is not
Need for any particular value, as long as the change of the relative motion at the edge of its object of the capture between two frames, while minimum
Change background or represent the capture of the minimum change of the value of the pixel of object.One value can be such as 75, and other values be can
Can.Unless the non-island residual error across two borders of threshold value residual error is produced by thresholding, otherwise threshold value residual error is not so good as mask
It is useful.Can adjust the value, or can make residual error part will not generate to prediction as another mask it is useful
Mask decision.
With reference to Fig. 8 B, for example, being shown as the block 812 of a part for Fig. 8 residual error 806.In block 812, edge and the moon
Movement of the shadow zone domain representation circular object 808 (for example, its edge) between the first frame 802 and the second frame 804.By threshold application
Edge and shadow region is caused to be assigned value 1 in block 812, while other regions are assigned value 1.For example, corresponding to block in new block
The location of pixels (that is, threshold value residual error) in 812 with the pixel of the value in the range of ± 75 is assigned value 1, and corresponding to the model
The other location of pixels enclosed in the threshold value residual error of outer pixel are assigned value 0.See non-island residual error across two borders, therefore
Block 812 can generate useful mask.
Referring again to Fig. 7, the process 700 for generating mask can also include modification threshold value residual error.In 706, use example
Growth and/or contracting function such as to threshold value residual error are changed in the 704 threshold value residual errors by threshold application obtained by residual error.
That is, remove threshold value residual error.In one example, modification is included in threshold value residual error only to the right and downwards recursively using life
Long step.In such embodiment, if there is provided up or left side any adjacent pixel (that is, with value 1),
Current pixel (that is, being converted into value 1) is then set.Can by worked in the part of larger " chunk " or threshold value residual error come
Improve the speed that recurrence increases.For example, if any pixel were arranged on the bottom of 4 × 4 pixel groups, all picture in the group
Element is set.Or, the region with the other values in threshold value residual error can be grown using recurrence Growth Function.It is general next
Say, modification threshold value residual error includes the area limited based on the contiguous pixels with the minimum number of the first value in two values
The value of the neighbouring pixel in domain, using growth function to extend the region.
Up to the present this modification process of 706 described causes two substantially continuous regions with separation value.
However, it is possible to there is such region, the continuity pixel of one of value can be hindered by the single pixel of another value or pixel
Disconnect.It can include reducing these discontinuous additional steps in 706 modification threshold value residual errors.In one example, threshold value is changed
Residual error includes application contracting function to remove the region limited by the contiguous pixels of the maximum quantity with the first value, and this has
The pixel of second value of the contiguous pixels of the maximum quantity of first value in two values is surrounded, or is removed by with second
The region that the contiguous pixels of the maximum quantity of value are limited, should have the contiguous pixels of maximum quantity of second value by with first
The pixel of value is surrounded.By removing the region, it means that change value causes the first value and second value to form non-in block or frame in
Overlapping continuum.
An example of the mask obtained from modification threshold value residual error is can see from Fig. 8 C.Entered by the block 812 to Fig. 8 B
Row thresholding changes resulting threshold value residual error to generate mask 814 using growth and contracting function so that constitute online
Side on pixel all there is the first value, and the pixel on online opposite side all has the steep cliff mask of second value.Although
Steep cliff mask (for example, simply black and white) can be used, the optional last step of mask is produced according to Fig. 7 process 700
Suddenly, including it will obscure using the border in mask.Fuzzy value will be discussed in greater detail below.At this point, noting
Cause to be formed the value around the border seamlessly transitted between zones to fuzzy.Fuzzy can be formed according to various interpolation techniques
A minor valve obscure.Once generating mask, process 700 terminates.
Once generating mask, it can be used for encoding or decoding current block.Referring again to Fig. 6, encoded or solved using mask
One embodiment of code current block is included in 604 the first prediction block of inter prediction parts, in 606 the second prediction blocks of inter prediction
Part, prediction block is generated 608 using the part, and current block is decoded using prediction block at 610.
When process 600 is cataloged procedure, including the use of mask use is performed in 604 the first prediction block of inter prediction part
In the first motion search of the pixel value in the first continuous part of the location of pixels of the current block in reference frame.That is,
Finding causes to swear for the first motion of the best match with the pixel value in the first continuous part of the mask altogether current block of position
Amount.The best match defines the first prediction block part.Similarly, in 606 inter prediction the second prediction block parts including the use of covering
Mould performs the second motion search of the pixel value in the second continuous part for the location of pixels of the current block in reference frame.
That is, finding causes second for the best match with the pixel value in the second continuous part of the mask altogether current block of position
Motion vector.The best match defines the second prediction block part., can be to many although describing the use of a reference frame
Search is performed in a reference frame, and best match need not be in identical reference frame.
When process 600 is cataloged procedure, 608, prediction block is generated using part to be included by using mask
The result of the first motion search is combined with the result of the second motion search to generate prediction block.Can be by by the picture of best match
Plain value is combined in single prediction block to realize this combination.For example, prediction block can with corresponding to the first prediction block
There is pixel at the position in Part I that first continuous part of the mask of partial value is essentially coincided, and with
Have at the position in Part II essentially coincided corresponding to the second continuous part of the mask of the value of the second prediction block part
Pixel.Boundary between the Part I and Part II of prediction block, pixel value is the combination according to fuzzy pixel value.
For example, fuzzy can be in the value between 1 and 0 that boundary has 0.75,0.50 and 0.25.In this case, in two portions
/ borderline region at pixel include the first group pixel adjacent with Part I, Part I has Part I
Common position pixel pixel value 75% with 25% value combined of the pixel value of the common position pixel of Part II, in addition to
Second group of adjacent pixel of two parts, Part II has the 25% of the pixel value of the common position pixel of Part I and second
The value of 75% combination of the pixel value for the common position pixel divided, and the 3rd group of picture being included between the first and second borderline regions
Element, the first and second borderline regions have the common position picture by the 50% of the pixel value of the common position pixel of Part I and Part II
The value of 50% combination of the pixel value of element.This is a simple example, and for combining two groups of pictures using obscuring mask
Element is to generate the other technologies of prediction block in the technical scope based on present disclosure of those skilled in the art.
It is worth noting that, mask can be changed for 604 and 606 inter prediction.That is, for example, mask
It can be rotated.It is the pixel for searching for selection every time in this change current block.Therefore motion search is performed including the use of rotation
Mask performs the first and second motion search in reference frame, i.e. find for each independent continuous part with spinning mask
Juxtaposed present frame best match.Then, the best match in part is shared with life in 608 mask sets that rotation is similarly used
Into prediction block.
Can also be by the way that mask shift movement vector to be changed to mask for 604 and 606 inter prediction.That is, it is right
It can should be separated in the benefit of the part of size (no matter all or part of frame) the coding present frame of mask by adjusting mask
Continuous part between border and be benefited.Border can be adjusted for example, by adjusting pixel value, so as to get mask side
The size of continuous part increases, and size of the continuous part on the opposite side of mask in the border of mask reduces current
A motion vector in (for example, last) frame before frame.For example, for the moving boundary simultaneously therefore motion of shifting mask
Vector can be the motion vector of the block of the last frame of the common position of current block with being just predicted.
610, encode current block using prediction block and include residual error generation for current block, and must with decoding current block
The information coded residual needed is into the bit stream of coding.For example, cataloged procedure can be including the use of change as described with respect to fig. 4
Level 404, quantized level 406 and entropy code level 408 is changed to handle residual error.Information necessary to decoding current block can make including instruction
The mode indicators (sometimes referred to as indicating) of the current block encoded with mask, indicate which frame is used to generate mask in the encoder
Designator (such as frame ID), the motion vector found as the result of motion search, the identifier of reference frame and to covering
The designator of any modification of mould.For example, if mask is rotated to be used for cataloged procedure, bit stream will include such finger
Show.The information can be included in frame, piece, fragment or block header, and not all information are required for sending out in identical header
Send.In addition, not every information is required for being transmitted.If for example, generation mask after do not change mask (for example,
It is not rotated), then it need not send the designator of modification.If in addition, all the time using two in the past in the mask pattern
Frame is encoded, then need not recognize the two frames used in bit stream.Other modifications are also possible.
It is appreciated that the generation of single mask may not cause block most from the specification of description Fig. 4 cataloged procedure
Efficient coding.Therefore, Fig. 6 process is incorporated into performs inter prediction using different masks (or same mask of rotation)
In the circulation of one or more rate-distortions, it is used for find with minimum coding cost (for example, the number of the bit of coding
Amount) coding current block mask and motion vector.
When process 600 is decoding process, performed according to Fig. 6 602 from frame Residual Generation mask.According to an embodiment party
Formula, when using mask pattern, is obtained for calculating from the bit stream (for example, the header of information is included by entropy decoding) of coding
The frame of residual error.Or, frame can be understood by using mask pattern.If for example, always using previous the two of present frame
Individual consecutive frame, then need not individually signal the mark of frame to decoder.
It is used for inter prediction second in 604 the first motion vectors for being used for the first prediction block of inter prediction part and 606
Second motion vector of prediction block part can be obtained from the header in bit stream.Can in 604 the first prediction block of inter prediction parts
With including：The first reference block is generated using the first motion vector, and mask is applied to the first reference block, to generate the first mask
Reference block (that is, the first prediction block part).Similarly, it can include in 606 the second prediction block of inter prediction parts：Use second
Motion vector generates the second reference block, and applied to the second reference block, to generate the second mask reference block, (that is, second is pre- by mask
Survey block portion point).608 by with above for described by cataloged procedure in the way of similar mode using some generate predict
Block.
Decoding current block using prediction block 610 includes the residual error from bit stream decoding current block, and prediction block is added
To residual error.For example, decoding process can be including the use of the inverse transformation level described by entropy decoding level 502,504 and Fig. 5 of quantification level
506 processing residual errors.It is then possible to rebuild current block in phase of regeneration 510, as described with reference to Figure 5.
Pixel prediction is used to reduce the data encoded amount in bit stream.A kind of technology is from previous using motion vector
The frame copy block of pixels of coding.In fact, object does not fall on conventional block boundary generally.According to teaching herein, preferably with
Simultaneously therefore it can improve the fallout predictor (for example, prediction block) of video compress with the edge shape of object.
The aspect of coding and decoding as described above illustrates some examples of coding and decoding technology.However, should manage
Solution, can mean to compress, decompresses, convert or any other as the coding and decoding of those terms used in claim
Processing or data variation.
Word " example " is used herein to mean that as example, example or explanation.It is described herein as " example "
Any aspect or design be not necessarily to be construed as relative to other aspect or design be preferred or favourable.On the contrary, using
Word " example " is intended to that concept is presented in a concrete fashion.As used in this application, term "or" is intended to indicate that inclusive
"or" rather than exclusive "or".That is, clearly indicate unless otherwise indicated or from the context, otherwise " X bags
Include A or B " and be intended to indicate that any naturally inclusive arrangement.If that is, X includes A；X includes B；Or X includes A and B two
Person, then under any previous examples meet " X include A or B ".In addition, explicitly indicating that unless otherwise indicated or from the context
Singulative, the article " one " and " one " otherwise used in the application and appended claims should generally be interpreted to represent
" one or more ".In addition, unless so description, otherwise term " embodiment " used throughout or " embodiment "
It is not intended as expression identical embodiment or embodiment.
Dispatching station 102 and/or receiving station 106 (and be stored thereon and/or thus perform, including by the He of encoder 400
The algorithm of decoder 500, method, instruction etc.) embodiment can be realized in hardware, software or its any combinations.Hardware
Such as computer, intellectual property (IP) core, application specific integrated circuit (ASIC), programmable logic array, optical treatment can be included
Device, programmable logic controller (PLC), microcode, microcontroller, server, microprocessor, digital signal processor or any other
Suitable circuit.In the claims, term " processor " is appreciated that either individually or in combination including any foregoing hard
Part.Term " signal " and " data " are used interchangeably.In addition, the part of dispatching station 102 and receiving station 106 not necessarily must be with phase
Same mode is realized.
In addition, in one aspect, for example, dispatching station 102 or receiving station 106 can be used with the general of computer program
Computer or general processor realize that computer program performs any corresponding method, algorithm and/or referred to when executed
Order.Additionally or alternatively, it is, for example, possible to use can include is used to perform any method as described herein, algorithm or instruction
Other hardware special-purpose computer/processor.
Dispatching station 102 and receiving station 106 can realize on the computer for example in video conferencing system.Alternatively, send out
See off 102 can realize on the server, and receiving station 106 can realize in the equipment separated with server, such as hand
Hold communication equipment.In this case, dispatching station 102 can use encoder 400 by vision signal of the research content for coding,
And the vision signal of coding is sent to communication equipment.Then, then communication equipment can use the decoding coding of decoder 500
Vision signal.Alternatively, communication equipment can decode the content being locally stored on a communications device, for example, not by dispatching station 102
The content of transmission.Other embodiments suitably sent and received are available.For example, receiving station 106 can be generally solid
Fixed personal computer rather than portable communication device, and/or the equipment including encoder 400 can also include decoder
500。
In addition, all or part of of embodiments of the present invention can use such as computer usable medium or computer
The form of the computer program product of computer-readable recording medium access.Computer usable medium or computer-readable medium can be being capable of example
As visibly included, storing, transmitting or transmitting appointing for the program for being used by any processor or being used in combination with any processor
What equipment.Medium can be such as electronics, magnetic, optics, electromagnetism or semiconductor devices.Other suitable media can also be used.
Above-described embodiment, embodiment and aspect has been described in order to be readily appreciated that the present invention, and does not limit this
Invention.On the contrary, it is contemplated that covering the various modifications being included within the scope of the appended claims and equivalent arrangements, its model
Enclose and meet broadest explanation, so as to including all allowed by law such modifications and equivalent structure.
Claims (20)
1. a kind of method being used for using computing device coding or decoding video signal, the vision signal includes defining video sequence
The frame of row, the frame has the block formed by pixel, and methods described includes：
Poor residual error between the pixel value as at least two frames in the video sequence in addition to present frame, generation
Mask for the current block in the present frame in the video sequence；And
Using the mask is by inter prediction encoding or decodes the current block.
2. according to the method described in claim 1, wherein, generating the mask includes：
The residual error, first frame and institute are calculated by subtracting the pixel value of the first frame in from the pixel value of the second frame in
The second framing bit is stated before the present frame in the video sequence, and first frame and second frame by one or
Multiple frames and the time quantum of definition are spaced apart.
3. according to the method described in claim 1, wherein, the mask have location of pixels the first continuous part and pixel position
The second continuous part put, first continuous part and second continuous part be not overlapping, and the first continuous portion
It is divided to the border between second continuous part to extend between two edges of the mask, methods described is further wrapped
Include：
Using the mask for the pixel value in first continuous part of the location of pixels in the current block in reference
Frame in performs the first motion search；
Using the mask for the pixel value in second continuous part of the location of pixels in the current block described
The second motion search is performed in reference frame；And
Generated by using the result of mask combination first motion search with the result of second motion search
Prediction block.
4. according to the method described in claim 1, wherein, generating the mask includes：
It is described by threshold application in the pixel value of the respective pixel location in the residual error to generate the threshold value residual error including pixel
Each pixel in threshold value residual error has the first value or the second value different from the described first value；And
The threshold value residual error is changed to generate the mask.
5. method according to claim 4, wherein, include using the threshold value：
The pixel value of each location of pixels in the residual error and the threshold value are compared；
When the pixel value of each location of pixels is less than the threshold value, first value is assigned in the threshold value residual error
Same pixel position；And
When the pixel value of each location of pixels is more than the threshold value, the second value is assigned in the threshold value residual error
Same pixel position.
6. method according to claim 4, wherein, changing the threshold value residual error includes：
Based on the value of the adjacent pixel in the region with being limited by the contiguous pixels of the minimum number with first value, application
Growth function is to extend the region.
7. method according to claim 6, wherein, changing the threshold value residual error includes：
Using contracting function to remove the region limited by the contiguous pixels of the maximum quantity with first value, the tool
The contiguous pixels for having the maximum quantity of first value are surrounded by the pixel with the second value.
8. method according to claim 4, wherein, at least two frame includes the first frame and the second frame, methods described
Further comprise：
The pixel value for subtracting by the pixel value of the common position pixel from first frame in pixel of second frame in is calculated
The residual error, and wherein, before encoding or decoding the current block, the border of the mask is shifted by motion vector.
9. according to the method described in claim 1, further comprise：
Rotate the mask；
The first motion search is performed in reference frame using the mask of rotation；
The second motion search is performed in the reference frame using the mask of the rotation；And
Combine the block that is found by first motion search using the mask and found by second motion search
Block, to generate the prediction block for being used for encoding the current block.
10. according to the method described in claim 1, further comprise：
Receiving includes the first motion vector, the second motion vector and the designator for the mask pattern that encodes the current block
Coded bit stream；And
After the mask is generated：
The mask is applied to the first reference block for obtaining from first motion vector to generate the first mask reference block；
The mask is applied to the second reference block for obtaining from second motion vector to generate the second mask reference block；With
And
The first mask reference block and the second mask reference block are combined to generate prediction block, wherein：
The current block is decoded including the use of the prediction block by current block described in interframe prediction decoding using the mask.
11. a kind of be used for the device of coding or decoding video signal, the vision signal includes defining the frame of video sequence, described
Frame has block, and described piece is formed by pixel, and described device includes：
Processor；And
Non-transitory memory, the non-transitory memory storage makes the instruction of the computing device operation upon execution,
The operation includes：
Poor residual error between the pixel value as at least two frames in the video sequence in addition to present frame, generation
Mask for the current block in the present frame in the video sequence；And
Using the mask is by inter prediction encoding or decodes the current block.
12. device according to claim 11, wherein, the operation further comprises by being covered described in following step generation
Mould：
Calculate as described in poor between the pixel value of the first frame in the video sequence and the pixel value of the second frame in
Residual error；
The pixel value of each location of pixels in the residual error is compared with threshold value；
When the pixel value of each location of pixels is less than the threshold value, the first value is assigned to the identical picture in threshold value residual error
Plain position；
When the pixel value of each location of pixels is more than the threshold value, second value is distributed into the phase in the threshold value residual error
Same location of pixels；And
Extension includes the first area of the pixel with the described first value and the secondth area including the pixel with the second value
At least one in domain, to form the first continuous part of the location of pixels with the described first value and with the second value
The mask of second continuous part of location of pixels, first continuous part and second continuous part be not overlapping, and institute
The border between the first continuous part and second continuous part is stated between two edges of the mask to extend.
13. device according to claim 12, the operation further comprises：
By described in changing between first continuous part and second continuous part before using the mask
The value of pixel around border changes the mask；And
Prediction block is generated, the prediction block includes：It is being overlapped with the location of pixels of first continuous part, by with described first
First piece of the pixel that the first associated motion vector of the location of pixels of continuous part is obtained, with second continuous part
It is that location of pixels is overlapped, being obtained by second motion vector associated with the location of pixels of second continuous part second piece
Pixel, and overlapped with the pixel around the border between first continuous part and second continuous part
Described first piece and described second piece of pixel combined value.
14. device as claimed in claim 11, the operation also includes：
The first signal is read in the coded bit stream associated with the current block of the present frame, first signal refers to
Show and the current block is encoded using mask；Wherein generate the mask and include and use as the in the video sequence
Poor residual error between the pixel value of the pixel value of one frame and the second frame generates the mask；
The first prediction block is generated in reference frame using the first motion vector；
The second prediction block is generated in reference frame using the second motion vector；And
Combine first prediction block with second prediction block to produce the combination for the current block using the mask
Prediction block；And wherein decoding the current block includes：
The current block is decoded using the prediction block of the combination.
15. device according to claim 14, the operation further comprises：
Read in the bit stream of the coding associated with the current block and indicate first frame and second frame
At least secondary signal；
The 3rd signal for indicating first motion vector is read from the bit stream of the coding；And
The 4th signal for indicating second motion vector is read from the bit stream of the coding.
16. device according to claim 14, wherein, the pixel value of first frame and second frame is included by compiling
Code and the reconstructed pixel value for decoding first frame and second frame and generating.
17. a kind of device for the mask for generating the current block for coding or decoding video signal, the vision signal includes fixed
The frame of adopted video sequence, the frame has the block formed by pixel, and described device includes：
Processor；And
Non-transitory memory, the non-transitory memory storage makes the instruction of the computing device operation when implemented,
The operation includes：
Residual error, first frame and described second are calculated by subtracting the pixel value of the first frame in from the pixel value of the second frame in
Framing bit is before the present frame in the video sequence；
It is described by threshold application in the pixel value of the respective pixel location in the residual error to generate the threshold value residual error including pixel
Each pixel in threshold value residual error has the first value or different from the described first value or second value；And
Extension includes the first area of the threshold value residual error of the pixel with the described first value and including the picture with the second value
Element threshold value residual error second area at least one, with formed with described first value location of pixels the first continuous portion
Point and location of pixels with the second value the second continuous part the mask, first continuous part and described the
Two continuous parts are not overlapping, and the border between first continuous part and second continuous part is in the mask
Extend between two edges；And wherein described mask has and the current block identical Pixel Dimensions.
18. device according to claim 17, the operation further comprises：
By fuzzy application in the pixel around the border, the vague definition have the described first value and the second value it
Between value pixel region.
19. device according to claim 17, the operation further comprises：
After at least one in extending the first area and the second area, using contracting function with remove by with
The region that the contiguous pixels for the maximum quantity with first value that the pixel of the second value is surrounded are limited, it is described to be formed
Mask.
20. device according to claim 17, the operation further comprises by following application threshold values：
The pixel value of each location of pixels in the residual error and the threshold value are compared；
When the pixel value of each location of pixels is less than the threshold value, first value is assigned in the threshold value residual error
Same pixel position；And
When the pixel value of each location of pixels is more than the threshold value, the second value is assigned in the threshold value residual error
Same pixel position.
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US15/010,594 US10469841B2 (en) | 2016-01-29 | 2016-01-29 | Motion vector prediction using prior frame residual |
US15/010,594 | 2016-01-29 |
Publications (2)
Publication Number | Publication Date |
---|---|
CN107071440A true CN107071440A (en) | 2017-08-18 |
CN107071440B CN107071440B (en) | 2020-04-28 |
Family
ID=57796999
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201611234686.6A Active CN107071440B (en) | 2016-01-29 | 2016-12-28 | Motion vector prediction using previous frame residuals |
Country Status (9)
Country | Link |
---|---|
US (1) | US10469841B2 (en) |
JP (1) | JP6761033B2 (en) |
KR (1) | KR102097281B1 (en) |
CN (1) | CN107071440B (en) |
AU (1) | AU2016389089B2 (en) |
CA (1) | CA3001731C (en) |
DE (2) | DE202016008178U1 (en) |
GB (1) | GB2546886B (en) |
WO (1) | WO2017131900A1 (en) |
Cited By (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN110741640A (en) * | 2017-08-22 | 2020-01-31 | 谷歌有限责任公司 | Optical flow estimation for motion compensated prediction in video coding |
CN113711272A (en) * | 2019-04-23 | 2021-11-26 | Oppo广东移动通信有限公司 | Method and system for non-spurious motion detection |
Families Citing this family (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10306258B2 (en) | 2016-01-29 | 2019-05-28 | Google Llc | Last frame motion vector partitioning |
US10469841B2 (en) | 2016-01-29 | 2019-11-05 | Google Llc | Motion vector prediction using prior frame residual |
US10462482B2 (en) * | 2017-01-31 | 2019-10-29 | Google Llc | Multi-reference compound prediction of a block using a mask mode |
JP7319365B2 (en) * | 2018-11-22 | 2023-08-01 | 北京字節跳動網絡技術有限公司 | Adjustment method for inter-prediction based on sub-blocks |
JP7481430B2 (en) | 2019-08-13 | 2024-05-10 | 北京字節跳動網絡技術有限公司 | Motion Accuracy in Subblock-Based Inter Prediction |
CN114762330A (en) | 2019-09-22 | 2022-07-15 | 北京字节跳动网络技术有限公司 | Sub-picture encoding and decoding of video |
CN117480778A (en) * | 2021-06-15 | 2024-01-30 | Oppo广东移动通信有限公司 | Residual coding and video coding methods, devices, equipment and systems |
Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5103488A (en) * | 1989-06-21 | 1992-04-07 | Cselt Centro Studi E Laboratori Telecommunicazioni Spa | Method of and device for moving image contour recognition |
US5177608A (en) * | 1990-09-20 | 1993-01-05 | Nec Corporation | Method and apparatus for coding moving image signal |
US5969772A (en) * | 1997-10-30 | 1999-10-19 | Nec Corporation | Detection of moving objects in video data by block matching to derive a region motion vector |
EP2280550A1 (en) * | 2009-06-25 | 2011-02-02 | Thomson Licensing | Mask generation for motion compensation |
CN105165012A (en) * | 2013-04-23 | 2015-12-16 | 高通股份有限公司 | Repositioning of prediction residual blocks in video coding |
Family Cites Families (47)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JPS62104283A (en) | 1985-10-31 | 1987-05-14 | Kokusai Denshin Denwa Co Ltd <Kdd> | Noise reduction system for differential decoding signal in animation picture transmission |
JP3037383B2 (en) | 1990-09-03 | 2000-04-24 | キヤノン株式会社 | Image processing system and method |
GB2266023B (en) | 1992-03-31 | 1995-09-06 | Sony Broadcast & Communication | Motion dependent video signal processing |
FR2751772B1 (en) * | 1996-07-26 | 1998-10-16 | Bev Bureau Etude Vision Soc | METHOD AND DEVICE OPERATING IN REAL TIME FOR LOCALIZATION AND LOCATION OF A RELATIVE MOTION AREA IN A SCENE, AS WELL AS FOR DETERMINING THE SPEED AND DIRECTION OF MOVEMENT |
US6614847B1 (en) | 1996-10-25 | 2003-09-02 | Texas Instruments Incorporated | Content-based video compression |
US6404813B1 (en) | 1997-03-27 | 2002-06-11 | At&T Corp. | Bidirectionally predicted pictures or video object planes for efficient and flexible video coding |
US20020015513A1 (en) * | 1998-07-15 | 2002-02-07 | Sony Corporation | Motion vector detecting method, record medium on which motion vector calculating program has been recorded, motion detecting apparatus, motion detecting method, picture encoding apparatus, picture encoding method, motion vector calculating method, record medium on which motion vector calculating program has been recorded |
US7085424B2 (en) * | 2000-06-06 | 2006-08-01 | Kobushiki Kaisha Office Noa | Method and system for compressing motion image information |
US7277486B2 (en) * | 2002-05-03 | 2007-10-02 | Microsoft Corporation | Parameterization for fading compensation |
JP4506308B2 (en) * | 2004-07-02 | 2010-07-21 | 三菱電機株式会社 | Image processing apparatus and image monitoring system using the image processing apparatus |
US7756348B2 (en) * | 2006-10-30 | 2010-07-13 | Hewlett-Packard Development Company, L.P. | Method for decomposing a video sequence frame |
KR20080107965A (en) | 2007-06-08 | 2008-12-11 | 삼성전자주식회사 | Method and apparatus for encoding and decoding image using object boundary based partition |
BRPI0818344A2 (en) | 2007-10-12 | 2015-04-22 | Thomson Licensing | Methods and apparatus for encoding and decoding video of geometrically partitioned bi-predictive mode partitions |
EP2081386A1 (en) * | 2008-01-18 | 2009-07-22 | Panasonic Corporation | High precision edge prediction for intracoding |
KR100939917B1 (en) * | 2008-03-07 | 2010-02-03 | 에스케이 텔레콤주식회사 | Encoding system using motion estimation and encoding method using motion estimation |
US20090320081A1 (en) | 2008-06-24 | 2009-12-24 | Chui Charles K | Providing and Displaying Video at Multiple Resolution and Quality Levels |
US8675736B2 (en) | 2009-05-14 | 2014-03-18 | Qualcomm Incorporated | Motion vector processing |
US8358691B1 (en) | 2009-10-30 | 2013-01-22 | Adobe Systems Incorporated | Methods and apparatus for chatter reduction in video object segmentation using a variable bandwidth search region |
US9473792B2 (en) * | 2009-11-06 | 2016-10-18 | Texas Instruments Incorporated | Method and system to improve the performance of a video encoder |
KR20110061468A (en) * | 2009-12-01 | 2011-06-09 | (주)휴맥스 | Methods for encoding/decoding high definition image and apparatuses for performing the same |
KR101484280B1 (en) * | 2009-12-08 | 2015-01-20 | 삼성전자주식회사 | Method and apparatus for video encoding by motion prediction using arbitrary partition, and method and apparatus for video decoding by motion compensation using arbitrary partition |
WO2011096770A2 (en) * | 2010-02-02 | 2011-08-11 | (주)휴맥스 | Image encoding/decoding apparatus and method |
US8879632B2 (en) | 2010-02-18 | 2014-11-04 | Qualcomm Incorporated | Fixed point implementation for geometric motion partitioning |
JP5368631B2 (en) * | 2010-04-08 | 2013-12-18 | 株式会社東芝 | Image encoding method, apparatus, and program |
EP2559248A2 (en) | 2010-04-12 | 2013-02-20 | Qualcomm Incorporated | Fixed point implementation for geometric motion partitioning |
DK2559246T3 (en) | 2010-04-13 | 2016-09-19 | Ge Video Compression Llc | Fusion of sample areas |
US20130128979A1 (en) * | 2010-05-11 | 2013-05-23 | Telefonaktiebolaget Lm Ericsson (Publ) | Video signal compression coding |
WO2012042654A1 (en) | 2010-09-30 | 2012-04-05 | 富士通株式会社 | Image decoding method, image encoding method, image decoding device, image encoding device, image decoding program, and image encoding program |
EP2625855B8 (en) | 2010-10-08 | 2021-03-10 | GE Video Compression, LLC | Picture coding supporting block partitioning and block merging |
US20120147961A1 (en) | 2010-12-09 | 2012-06-14 | Qualcomm Incorporated | Use of motion vectors in evaluating geometric partitioning modes |
US10027982B2 (en) * | 2011-10-19 | 2018-07-17 | Microsoft Technology Licensing, Llc | Segmented-block coding |
EP2942961A1 (en) | 2011-11-23 | 2015-11-11 | HUMAX Holdings Co., Ltd. | Methods for encoding/decoding of video using common merging candidate set of asymmetric partitions |
EP2842325A4 (en) | 2012-04-24 | 2015-10-14 | Lyrical Labs Video Compression Technology Llc | Macroblock partitioning and motion estimation using object analysis for video compression |
US20130287109A1 (en) | 2012-04-29 | 2013-10-31 | Qualcomm Incorporated | Inter-layer prediction through texture segmentation for video coding |
US20130329800A1 (en) * | 2012-06-07 | 2013-12-12 | Samsung Electronics Co., Ltd. | Method of performing prediction for multiview video processing |
US9549182B2 (en) * | 2012-07-11 | 2017-01-17 | Qualcomm Incorporated | Repositioning of prediction residual blocks in video coding |
US9076062B2 (en) * | 2012-09-17 | 2015-07-07 | Gravity Jack, Inc. | Feature searching along a path of increasing similarity |
US9819965B2 (en) | 2012-11-13 | 2017-11-14 | Intel Corporation | Content adaptive transform coding for next generation video |
GB2520002B (en) * | 2013-11-04 | 2018-04-25 | British Broadcasting Corp | An improved compression algorithm for video compression codecs |
US9986236B1 (en) * | 2013-11-19 | 2018-05-29 | Google Llc | Method and apparatus for encoding a block using a partitioned block and weighted prediction values |
TWI536811B (en) | 2013-12-27 | 2016-06-01 | 財團法人工業技術研究院 | Method and system for image processing, decoding method, encoder and decoder |
US20180176559A1 (en) * | 2014-03-19 | 2018-06-21 | Samsung Electronics Co., Ltd. | Method for performing filtering at partition boundary of block related to 3d image |
US10554965B2 (en) * | 2014-08-18 | 2020-02-04 | Google Llc | Motion-compensated partitioning |
US9613288B2 (en) * | 2014-11-14 | 2017-04-04 | Adobe Systems Incorporated | Automatically identifying and healing spots in images |
JP6443869B2 (en) * | 2014-11-14 | 2018-12-26 | ホアウェイ・テクノロジーズ・カンパニー・リミテッド | System and method for processing digital images |
US9838710B2 (en) * | 2014-12-23 | 2017-12-05 | Intel Corporation | Motion estimation for arbitrary shapes |
US10469841B2 (en) | 2016-01-29 | 2019-11-05 | Google Llc | Motion vector prediction using prior frame residual |
-
2016
- 2016-01-29 US US15/010,594 patent/US10469841B2/en active Active
- 2016-12-19 GB GB1621550.1A patent/GB2546886B/en active Active
- 2016-12-20 CA CA3001731A patent/CA3001731C/en active Active
- 2016-12-20 DE DE202016008178.1U patent/DE202016008178U1/en active Active
- 2016-12-20 JP JP2018519395A patent/JP6761033B2/en active Active
- 2016-12-20 KR KR1020187010572A patent/KR102097281B1/en active IP Right Grant
- 2016-12-20 DE DE102016124926.2A patent/DE102016124926A1/en active Pending
- 2016-12-20 AU AU2016389089A patent/AU2016389089B2/en active Active
- 2016-12-20 WO PCT/US2016/067792 patent/WO2017131900A1/en active Application Filing
- 2016-12-28 CN CN201611234686.6A patent/CN107071440B/en active Active
Patent Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5103488A (en) * | 1989-06-21 | 1992-04-07 | Cselt Centro Studi E Laboratori Telecommunicazioni Spa | Method of and device for moving image contour recognition |
US5177608A (en) * | 1990-09-20 | 1993-01-05 | Nec Corporation | Method and apparatus for coding moving image signal |
US5969772A (en) * | 1997-10-30 | 1999-10-19 | Nec Corporation | Detection of moving objects in video data by block matching to derive a region motion vector |
EP2280550A1 (en) * | 2009-06-25 | 2011-02-02 | Thomson Licensing | Mask generation for motion compensation |
CN105165012A (en) * | 2013-04-23 | 2015-12-16 | 高通股份有限公司 | Repositioning of prediction residual blocks in video coding |
Cited By (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN110741640A (en) * | 2017-08-22 | 2020-01-31 | 谷歌有限责任公司 | Optical flow estimation for motion compensated prediction in video coding |
CN110741640B (en) * | 2017-08-22 | 2024-03-29 | 谷歌有限责任公司 | Optical flow estimation for motion compensated prediction in video coding |
CN113711272A (en) * | 2019-04-23 | 2021-11-26 | Oppo广东移动通信有限公司 | Method and system for non-spurious motion detection |
Also Published As
Publication number | Publication date |
---|---|
AU2016389089B2 (en) | 2020-01-02 |
US10469841B2 (en) | 2019-11-05 |
JP6761033B2 (en) | 2020-09-23 |
CA3001731A1 (en) | 2017-08-03 |
GB201621550D0 (en) | 2017-02-01 |
GB2546886B (en) | 2019-10-09 |
CA3001731C (en) | 2020-11-24 |
DE202016008178U1 (en) | 2017-05-24 |
GB2546886A (en) | 2017-08-02 |
JP2018536339A (en) | 2018-12-06 |
KR20180054715A (en) | 2018-05-24 |
US20170223357A1 (en) | 2017-08-03 |
AU2016389089A1 (en) | 2018-04-19 |
DE102016124926A1 (en) | 2017-08-03 |
CN107071440B (en) | 2020-04-28 |
KR102097281B1 (en) | 2020-04-06 |
WO2017131900A1 (en) | 2017-08-03 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN107071440A (en) | Use the motion-vector prediction of previous frame residual error | |
EP3861755B1 (en) | Techniques and apparatus for weighted-median prediction for point-cloud attribute coding | |
US20220353534A1 (en) | Transform Kernel Selection and Entropy Coding | |
CN107534669A (en) | Single stream transmission method for multi-user's video conference | |
CN110073663A (en) | Use the transformation coefficient code of rank figure | |
CN107027032A (en) | Last frame motion vector subregion | |
US10506240B2 (en) | Smart reordering in recursive block partitioning for advanced intra prediction in video coding | |
US11140395B2 (en) | Method and apparatus for adaptive point cloud attribute coding | |
CN107205149A (en) | The motion vectors reference selection tracked by reference to frame buffer | |
US20210112270A1 (en) | Dynamic motion vector referencing for video coding | |
CN109983770A (en) | Multistage composite prediction | |
CN104704826B (en) | Two steps quantify and coding method and device | |
CN110169068B (en) | DC coefficient sign coding scheme | |
US10798402B2 (en) | Same frame motion estimation and compensation | |
CN109891894A (en) | It is compiled and is restored using the video of domain transformation recursion filter | |
CN107205156A (en) | Pass through the motion-vector prediction of scaling | |
WO2018169571A1 (en) | Segmentation-based parameterized motion models | |
CN107318015A (en) | Hybrid predicting pattern for Video coding | |
CN107302700A (en) | Adaptive direction loop filter | |
CN109891885A (en) | The guidance offset correction restored in video compiling for loop | |
CN108605145A (en) | Mixed boolean-token ANS coefficient codes | |
CN107018416A (en) | For video and the adaptive chip data size coding of compression of images | |
US10225573B1 (en) | Video coding using parameterized motion models | |
CN110679151A (en) | Video coding using parametric motion models | |
CN110731082B (en) | Compression of groups of video frames using reverse ordering |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
CB02 | Change of applicant information | ||
CB02 | Change of applicant information |
Address after: American CaliforniaApplicant after: Google limited liability companyAddress before: American CaliforniaApplicant before: Google Inc. |
|
GR01 | Patent grant | ||
GR01 | Patent grant |