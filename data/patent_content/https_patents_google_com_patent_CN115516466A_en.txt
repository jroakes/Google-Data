CN115516466A - Hyper-parametric neural network integration - Google Patents
Hyper-parametric neural network integration Download PDFInfo
- Publication number
- CN115516466A CN115516466A CN202180033319.2A CN202180033319A CN115516466A CN 115516466 A CN115516466 A CN 115516466A CN 202180033319 A CN202180033319 A CN 202180033319A CN 115516466 A CN115516466 A CN 115516466A
- Authority
- CN
- China
- Prior art keywords
- parameters
- neural networks
- neural network
- training
- integration
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
- G06N20/20—Ensemble learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/045—Combinations of networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/0985—Hyperparameter optimisation; Meta-learning; Learning-to-learn
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N5/00—Computing arrangements using knowledge-based models
- G06N5/01—Dynamic search techniques; Heuristics; Dynamic trees; Branch-and-bound
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/048—Activation functions
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/084—Backpropagation, e.g. using gradient descent
Abstract
Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for generating neural network integrations. In particular, the neural networks in the ensemble are trained using different hyper-parameters from each other.
Description
Cross Reference to Related Applications
This application claims priority to U.S. provisional application No.63/035,614, filed on 5/6/2020, which is incorporated herein in its entirety.
Technical Field
This description relates to training neural networks.
Background
Neural networks are outputs that employ a machine learning model of one or more layers of nonlinear elements to predict received inputs. Some neural networks include one or more hidden layers in addition to an output layer. The output of each hidden layer is used as an input to the next layer in the network (i.e., the next hidden layer or output layer). Each layer of the network generates an output from the received input in accordance with the current values of the respective set of parameters.
Disclosure of Invention
This specification describes a system implemented as a computer program on one or more computers in one or more locations that generates an integration of multiple neural networks (ensembles) to perform a particular machine learning task.
Particular embodiments of the subject matter described in this specification can be implemented to realize one or more of the following advantages.
Conventional techniques for generating an integration of a neural network ensure the diversity of predictions generated by the neural network in the integration by initializing the training neural network with different parameters, i.e., by initializing parameter values of the parameters of the neural network in the integration to different initial values. However, the described techniques alter both the parameters used for training of the neural network and the initialization of the hyper-parameters. By generating integrations not only on weights but also on hyper-parameters using the described techniques, the generated integrations can outperform conventional integrations in terms of accuracy of predictions generated by the integrations and in providing metrics for quantifying uncertainty of predictions generated by the integrations.
Furthermore, by generating a computationally efficient batch integration in a manner that also ensures hyper-parametric diversity among the generated batch integrations, the described techniques can improve prediction quality and uncertainty quantification in a computationally efficient manner.
For example, in various example embodiments, the neural networks in the generated integration of K neural networks share at least some parameters. Since such shared parameters need to be stored only once, even if used by multiple neural networks, the resulting integration is suitable for memory efficient storage. In particular, since parameters are shared between neural networks in the integration of K neural networks, the amount of memory required to store the integration of K neural networks can be the same as or less than the memory available in the constrained memory space storing the integration of K neural networks. Furthermore, in some embodiments where the K neural networks share parameters, the output of each of the K neural networks can be generated in parallel for an entire batch of multiple inputs, thereby reducing the delay for generating predictions for integration relative to conventional techniques.
The details of one or more embodiments of the subject matter of this specification are set forth in the accompanying drawings and the description below. Other features, aspects, and advantages of the subject matter will become apparent from the description, the drawings, and the claims.
Drawings
FIG. 1 illustrates an example training system.
FIG. 2 is a flow diagram of an example process for generating ultra-deep integration.
FIG. 3 is a flow diagram of an example process for generating superslusterintegrated.
FIG. 4 shows a graph indicating the performance of ultra-deep integration and ultra-batch integration across various machine learning tasks.
Like reference numbers and designations in the various drawings indicate like elements.
Detailed Description
Fig. 1 illustrates an example training system 100. Training system 100 is an example of a system implemented as a computer program on one or more computers in one or more locations, in which the systems, components, and techniques described below can be implemented.
The training system 100 uses the training data set 102 and the validation data set 104 to generate an integration 130 of a plurality of trained neural networks 120A-K that have been trained to perform a particular machine learning task.
The training data set 102 includes a plurality of training examples and, for each training example, a respective target output. The target output for a given training example is the output that should be generated by performing a particular machine learning task on the corresponding training input.
The validation data set 104 also includes a plurality of examples, and for each example, a respective target output, but will typically include different examples than those in the training data set 102. The examples in the verification dataset 104 will also be referred to as "verification examples".
Each neural network 120A-K in the ensemble 130 is configured to process network inputs for a particular task and generate outputs for the particular task.
Due to the manner in which the system generates the integration 130 and trains the neural networks 120 in the integration 130, each trained neural network 120 in the integration 130 will typically have different parameter values than the other trained neural networks 120 in the integration 130. Thus, different ones of the neural networks 120A-K are capable of generating different network outputs for different network inputs for a particular machine learning task.
The neural networks 120A-K in the ensemble 130 can be trained to perform any kind of machine learning task, i.e., can be configured to receive any kind of digital data input and generate any kind of scoring, classification, or regression output based on the input.
In some cases, each neural network is a neural network configured to perform image processing tasks, i.e., receive an input image, and process the input image, i.e., process intensity values for pixels of the input image, to generate a network output for the input image. For example, the task may be image classification, and the output generated by the neural network for a given image may be a score for each of a set of object classes, where each score represents an estimated likelihood that the image contains an image of an object belonging to that class. As another example, the task can be image embedding generation and the output generated by the neural network can be digital embedding of the input image. As yet another example, the task can be object detection, and the output generated by the neural network can identify a location in the input image depicting a particular type of object. As yet another example, the task can be image segmentation, and the output generated by the neural network can assign each pixel of the input image to a class from a set of classes.
As another example, if the input to the neural network is an internet resource (e.g., a web page), a document or portion of a document or a feature extracted from an internet resource, document or portion of a document, the task can be to classify the resource or document, i.e., the output generated by the neural network for a given internet resource, document or portion of a document can be a score for each topic in the set of topics, wherein each score represents an estimated likelihood that the internet resource, document or portion of a document is relevant to the topic.
As another example, if the input to the neural network is a feature of the impression context of a particular advertisement, the output generated by the neural network may be a score representing an estimated likelihood that the particular advertisement will be clicked.
As another example, if the input to the neural network is a feature of a personalized recommendation for the user, e.g., a feature characterizing the context of the recommendation, e.g., a feature characterizing a previous action taken by the user, the output generated by the neural network may be a score for each of a set of content items, where each score represents an estimated likelihood that the user will respond favorably to the recommended content item.
As another example, if the input to the neural network is a sequence of text in one language, the output generated by the neural network may be a score for each of a set of text segments in another language, where each score represents an estimated likelihood that a text segment in the other language is an appropriate translation of the input text to the other language.
As another example, the task may be an audio processing task. For example, if the input to the neural network is a sequence representing a spoken utterance, the output generated by the neural network may be for each text segment in the set of text segments, each score representing an estimated likelihood that the text segment is a correct transcription of the utterance. As another example, if the input to the neural network is a sequence representing a spoken utterance, the output generated by the neural network can indicate whether a particular word or phrase ("hotword") was spoken in the utterance. As another example, if the input to the neural network is a sequence representing a spoken utterance, the output generated by the neural network is capable of recognizing the natural language in which the utterance was spoken.
As another example, a task can be a natural language processing or understanding task that operates on a text sequence of some natural language, such as an implication task, a paraphrase task, a text similarity task, an emotion task, a sentence completion task, a grammar task, and so forth.
As another example, the task can be a text-to-speech task, where the input is text in natural language or a feature of the text in natural language, and the network output is a spectrogram or other data defining audio of the text spoken in natural language.
As another example, the task can be a health prognosis task, where the input is electronic health record data for the patient and the output is a prognosis related to the patient's future health, e.g., a predicted treatment that should be prescribed for the patient, a likelihood that the patient will have an adverse health event, or a predicted diagnosis of the patient.
As another example, the task can be a smart agent control task, where the input is an observation characterizing a state of the environment and the output defines an action to be performed by the smart agent in response to the observation. An agent can be, for example, a real-world or simulated robot, a control system for an industrial installation, or a control system controlling a different kind of agent.
Specifically, the system 100 generates the integration 130 of the neural networks 120A-K in a manner that takes into account different hyper-parameters of the training techniques used to train the neural networks. Thus, the integration 130 can be referred to as "hyper-parameter integration" 130.
A hyper-parameter is a value or setting that modifies how the training technique operates when modified. In other words, given a training data set comprising a plurality of training examples and given current values of parameters of a neural network, different hyper-parameters will result in different updates being generated for the current values of the parameters as a result of performing a training technique on the training data set.
Examples of the hyperparameters include weights of terms in the loss function, loss rates of different layers of the neural network, hyperparameters of the regularization term (e.g., L2 penalty term), tag smoothing hyperparameters values that determine the amount of tag smoothing to be applied to the tags of the training examples during training, learning rate values or learning rate attenuation values or other hyperparameters used by the training techniques, batch sizes, and so forth.
The system 100 can generate the integration 130 in a manner that takes into account different hyper-parameters of the training techniques used in any of several ways.
In some embodiments, the system 100 generates a pool of candidate trained neural networks, each candidate trained neural network having been trained using a different combination of hyper-parameters and parameter initialization, and then selects an ensemble of neural networks 130 from the pool of candidate trained neural networks.
The integration 130 generated in this manner will be referred to as ultra-deep integration. Generating the ultra-deep integration is described in more detail below with reference to fig. 2 and 3.
In some other implementations, the system 100 generates the integration 130 such that each of the neural networks 120A-K shares some parameters among all of the neural networks 120A-K in the integration, and each neural network has some parameters that are not shared. "sharing" a parameter between two neural networks means that the parameter takes the same value in both neural networks.
More specifically, in these embodiments, each of the neural networks 120A-K has at least one "integration layer". The integration layer is a layer having: the parameters include (i) a shared parameter having a same value for all of the plurality of neural networks 120A-K, (ii) a particular parameter having a different value for different ones of the plurality of neural networks 120A-K, and (iii) an embedding parameter including a first embedding parameter that maps a current hyper-parameter used for training of the neural networks to a modification of a parameter of a layer.
As a particular example, for each neural network, the particular parameters of each integration layer in the neural network can include (i) a first particular parameter that modifies a shared parameter for the integration layer and (ii) a second particular parameter that defines a particular bias vector for the integration layer in the neural network.
In this example, to generate the final values of the parameters of the integration layers of a given one of the neural networks 120A-K at any given time during training, the system 100 applies the final modifications to the shared parameters that are determined using the particular parameters for the given neural network and by applying the embedded parameters to the current hyper-parameters used to train the given neural network. The system 100 then uses the modified shared parameters generated by applying the final modification as weights for the integration layer, e.g., as a weight matrix for the kernel of the linear or convolutional layer, and uses the particular bias vectors defined by the second particular parameters as bias vectors for the integration layer in the given neural network.
Additionally, in some cases, the embedding parameters further include a second embedding parameter of the modifier that maps the current hyperparameter to a particular bias vector.
Thus, in these examples, the system further applies the modifier generated from the second parameter and the current hyperparameter to the particular bias vector, and uses the modified bias vector as a bias vector for the integration layer in the given neural network.
As a specific example, when the integration layer is a linear layer, the weight matrix W of the integration layer of the neural network k in the integration of the current hyper-parameter λ k is given k (λ k ) Can satisfy the following conditions:
W k (λ k )＝W⊙(r k s k T )+[△⊙(u k v k T )]⊙e(λ k ) T ，
where W and Δ are shared kernels composed of shared weights, which indicates element-by-element multiplication, r k ，s k ，u k And v k Is a vector of specific parameters specific to the neural network k, and e (λ) k ) Is the embedding of the current hyperparameter generated using the embedding parameters. For example, the embedding can be generated by applying a matrix of embedding parameters to a vector of current hyperparameters.
In addition, when the linear layer has a bias term, the current hyperparameter λ is given k Bias vector b of the integration layer of the neural network k in the integration k (λ k ) Can satisfy the following conditions:
b k (λ k )＝b k +δ k ⊙e′(λ k ) T ，
wherein, b k And delta k Is a bias term specific to the neural network k, and e' (λ) k ) Is the embedding of the current hyperparameter generated using the second embedding parameters. For example, the embedding can be generated by applying a matrix of second embedding parameters to a vector of current hyperparameters.
Thus, to compute the output for the integration layer of the neural network k, the input to that layer is associated with a weight matrix W k (λ k ) Multiply and bias the vector b k (λ k ) Is added to the product.
As another particular example, when the integration layer is a convolutional layer, the current hyper-parameter λ is given k Kernel K of the integration layer of the neural network K in the integration k (λ k ) Can satisfy the following conditions:
K k (λ k )＝K⊙(r k s k T )+[△⊙(u k v k T )]⊙e(λ k ) T ，
where K and Δ are kernels composed of shared parameters.
In addition, when the convolutional layer has a bias term, the current hyper-parameter λ is given k Bias term b for the integration layer of the neural network k in the integration k (λ k ) Can satisfy the following conditions:
b k (λ k )＝b k +δ k ⊙e′(λ k ) T .
in the above two equations, the rank-1 factor, i.e., r k s k T And u k v k T And should be understood to be broadcast along the height and width dimensions.
Thus, to compute the output of the integration layer of the neural network k, at the kernel W k (λ k ) Convolution is performed with the input of the sum layer, and the bias term b is applied k (λ k ) Added to the output of the convolution.
Because the integration layer shares a large number of parameters, and because these shared parameters need only be stored once for all K neural networks, the K neural networks will typically be more computationally efficient than other equivalent ultra-deep integrations, e.g., with a much smaller memory footprint. Furthermore, when integration is used to process a batch of multiple neural network inputs, due to the structure of the integration layer, the network outputs of the batch of all K neural networks can be computed in parallel in one forward pass through a single "composite" neural network representing all K neural networks by tiling the neural network inputs in the batch before they are processed by the "composite" neural network.
In some cases, each layer within the K neural networks having parameters is an integration layer, i.e., each linear layer and/or each convolutional layer is configured as an integration layer as described above. In some other cases, only a proper subset of the layers of the K neural networks having parameters are integration layers, i.e., one or more linear layers, convolutional layers, or other types of neural network layers do not share any parameters between the K neural networks in the integration.
The integration 130 generated by the K neural networks with at least one integration layer will be referred to as super-batch integration. Generating superstored integrations is described in more detail below with reference to FIG. 3.
After the integration 130 is generated (and trained) by the system 100, the system 100 can process the new network inputs using the integration 130 to generate new network outputs for the machine learning task.
For example, the final output of the integration for a given new network input can be a measure of the central tendency of the new network outputs generated by the networks 120A-K in the integration 130 for the given network input, e.g., an average or an average after one or more of the largest outliers have been removed. Using the output of the integration 130 rather than the output of a single network can result in an output with improved accuracy over machine learning tasks.
In addition to generating the final output, the outputs of the networks 120A-K in the integration 130 can be used to generate a measure of uncertainty in the accuracy of the final output, e.g., as a measure of variability of the outputs of the various networks in the integration. The measure of variability can be, for example, an entropy-based measure of variability. As one example, the metric can be equal to the sum of the Kullback-Leibler (KL) divergence between the network output and the final output generated by each neural network. As another example, the metric can be equal to the difference between the entropy of the final output and the average of the entropy of the individual network outputs generated by the neural network in the integration. Alternatively, for classification tasks, a measure of variability can be calculated based on a direct comparison of scores assigned to a predetermined subset of the categories of the computing network output. For example, the measure of variability can be calculated as the difference between the maximum score calculated for any category in the subset by any integration and the minimum score calculated for any category in the subset by any integration.
In more detail, after generating the ensemble 130, i.e., after training each of the neural networks 120A-K, and for ultra-deep integration, selecting the neural networks 120A-K to be included in the ensemble, the system 100 can receive new network inputs and process the new network inputs using each of the K neural networks 120A-K in the ensemble 130 to generate K new network outputs for the new network inputs.
The system can then generate final new network outputs for the new network inputs from the K new network outputs, for example, as a measure of the central tendency of the K new network outputs.
The system is also able to generate a measure of uncertainty in the accuracy of the final new network output from the K new network outputs.
When the integration is superslustered, to process a new network input using each of the K neural networks in the integration, the system determines a respective hyperparameter for each of the K neural networks, and for each integration layer in the K neural networks, applies the embedded parameters for the neural networks to the determined hyperparameter to generate modifiers for the shared parameters, and then uses the modified shared parameters as described above. Determining the hyper-parameters after training will be described below with reference to fig. 3.
FIG. 2 is a flow diagram of an example process 200 for generating superscalar integration. For convenience, process 200 will be described as being performed by a system of one or more computers located at one or more locations. For example, a training system suitably programmed in accordance with the present description, such as training system 100 of FIG. 1, can perform process 200.
Specifically, the system performs the process 200 to generate an integration of K neural networks to perform the machine learning task, where K is a fixed integer greater than 1.
The system identifies a set of N different hyper-parameters for training a neural network with parameters to perform a machine learning task (step 202). Like K, N is an integer greater than 1 and can be equal to K or can be an integer greater than K.
In some implementations, to identify a set of N different hyperparameters, the system applies a hyperparameter search technique to identify M best performing hyperparameters for the machine learning task, where M is an integer greater than N.
The system can apply any suitable hyper-parameter search technique for searching the best hyper-parameter set. As a specific example, the system can use a random search and select the M best performing hyperparameters evaluated as part of the random search technique. Other examples of hyper-parametric search techniques that can be used include grid search and automatic hyper-parametric adjustment techniques, such as a hyper-parametric adjustment technique based on bayesian optimization.
The system then selects N hyper-parameters from the M best performing hyper-parameters using an integrated selection technique.
As a specific example, the system can generate a set of M second candidate neural networks, each having been trained using a different one of the M best performing hyperparameters. That is, the system can train the respective neural network using each of the M best performing hyper-parameters on the same training data set or on a respective portion of a larger training data set to generate a set of M second candidate neural networks.
The system then generates a first integration of N candidate neural networks from the M second candidate neural networks by repeatedly adding to the first integration of N candidate neural networks, i.e., by adding a new candidate neural network at each of a plurality of iterations. At each iteration, the system can select, from the M candidate neural networks, the candidate neural network that, if added to the first integration, would result in the greatest improvement in performance of the first integration over the machine learning task. The system can measure the performance integrated on the machine learning task as the performance integrated on the multiple verification examples from the verification data set of the machine learning task using an appropriate performance measure of the integrated final output, e.g., an average negative log-likelihood of the final output generated by the integration for the multiple verification examples.
Then, the system selects the hyperparameters used to train the N candidate neural networks in the first ensemble as the N hyperparameters.
The system generates a set of first candidate trained neural networks (step 204).
To generate the first set of candidate trained neural networks, the system can train a plurality of sets of neural networks for each of N different hyper-parameters.
In particular, for each of N different hyper-parameters, the system is able to select a plurality of different initializations for the values of the parameters of the neural network. For example, the system can select a fixed number of different initializations by applying an appropriate random parameter initialization scheme to each parameter of the neural network for each initialization. For example, the system can generate an independent sample from a given probability distribution (e.g., a gaussian distribution) for each initialization. As another example, the system can generate independent samples from a distribution that assigns a positive sign to a parameter with one probability and a negative sign to a parameter with another probability. That is, each different initialization is a different random initialization of values of parameters of the neural network.
For each of the N different hyper-parameters and for each of the different initializations, the system can train the corresponding neural network with (i) the different hyper-parameters and (ii) the parameter values initialized using the different initializations to generate a trained neural network.
By doing so for each of the N different hyper-parameters, the resulting set of first candidate trained neural networks includes a plurality of different neural networks trained using different combinations of parameter initialization and hyper-parameters.
The system generates an ensemble of K neural networks by selecting K neural networks from the first candidate trained neural networks (step 206).
In particular, the system may generate the integration using the same or different integration generation techniques used to select the N hyper-parameters.
As a particular example, the system can generate an ensemble of K neural networks from the set of first candidate trained neural networks by adding a new first candidate trained neural network to the ensemble at each of a plurality of iterations.
At each iteration, the system can add the first candidate trained neural network to the integration by selecting, from the first candidate trained neural networks in the set, the neural network that, if added to the integration, would result in the greatest improvement in the performance of the integration of any neural network in the integration.
In some cases, the system performs this iterative selection without replacement, i.e., once a given candidate is added to the set, it is removed from the available candidate pool in subsequent iterations.
In some other cases, the system performs this iterative selection without replacement, i.e., once a given candidate is added to the integration, it is not removed from the pool of available candidates in subsequent iterations and is available to be added to the integration again in later iterations. In these cases, the system can continue to perform iterations until K unique neural networks have been added to the integration, or until a total of K neural networks have been added to the integration (even if some of the K are different instances of the same neural network). Because the final output is computed as a measure of the concentration trend, the final output will weight the output generated by the neural network with more than one instance in the integration more strongly than the output generated by the neural network with only one instance in the integration.
FIG. 3 is a flow diagram of an example process 300 for generating ultra-deep integration. For convenience, process 300 will be described as being performed by a system of one or more computers located at one or more locations. For example, a training system (e.g., training system 100 of FIG. 1) suitably programmed in accordance with the present description can perform process 300.
Specifically, the system performs the process 300 to train an integration with K neural networks, each configured to perform a machine learning task.
Each of the K neural networks has a plurality of neural network layers having respective parameters, wherein at least one of those layers is an integration layer having, for each of the K neural networks: the method includes (i) a shared parameter shared among all K neural networks in the integration, (ii) a neural network-specific parameter, and (iii) an embedding parameter comprising a first embedding parameter of a modifier that maps the current hyper-parameter to the shared parameter.
In some cases, the embedding parameters are specific to the neural network, while in other cases, the embedding parameters are shared between the neural networks in the integration.
Additionally, in some cases, each integration layer also includes a second embedding parameter of the modifier that maps the current hyper-parameter to a bias of the integration layer.
The operation of the integration layer is described above with reference to fig. 1.
During training of the neural networks in the ensemble, each of the K neural networks is trained with hyper-parameters that are re-sampled from a different distribution than the other K neural networks. That is, during training, the system maintains a respective set of hyperparametric distribution parameters for each of the K neural networks that define a distribution over the hyperparameters used for training of the neural networks.
In particular, each hyperparameter distribution defines a distribution over the possible values of each hyperparameter trained that will vary between different neural networks in the integration. For example, each neural network can be trained with the same batch size, while the loss rate, regularization rate, or both can vary between different neural networks in the integration.
As a specific example, the system can represent a given set of hyper-parameters, which includes a respective value for each hyper-parameter that can vary as a multi-dimensional vector. For each neural network, the hyperparametric distribution can be represented as a plurality of independent distributions, e.g., one distribution for each dimension in a multidimensional vector. The hyper-parametric distribution parameters then define each individual distribution. For example, each distribution can be a log-uniform distribution, and the hyper-parametric distribution parameters can include two parameters for each dimension that define the bounds of the corresponding log-uniform distribution's range.
The system then trains the K neural networks by repeatedly performing the process 300 on different sets of training examples using the maintained data.
For each of the K neural networks, the system samples a hyperparameter from a distribution defined by a respective hyperparametric distribution parameter set of the neural network (step 302). For example, for a given neural network, the system can sample the respective values for each dimension of the multi-dimensional vector from the independent distribution for that dimension for the given neural network.
The system obtains a plurality of training examples of a machine learning task (step 304). For example, the system can sample a small batch of multiple training examples from a training dataset of a machine learning task. The training data can include a plurality of training examples, and for each training example, can include a respective target output, i.e., an output that should be generated by the neural network by performing a machine learning task on the corresponding training example.
For each of the K neural networks, the system trains the neural network over a plurality of training examples according to the hyper-parameters sampled for the neural network to determine updates to at least the shared parameters, the specific parameters, and the embedded parameters of the first neural network layer (step 306).
In some implementations, the system trains each of the neural networks to minimize a loss function that measures, for each neural network, a loss between a network output generated by the neural network for a given training example and a target output for the given training example. The loss between the output and the target output can be in any form suitable for machine learning tasks, e.g., a cross-entropy loss or a negative log-likelihood loss. That is, in these embodiments, the loss function includes a respective loss term for each of the K neural networks that measures the loss between the network output generated by the neural network for the given training example and the target output for the given training example. For example, the loss function can measure an average of the losses of a plurality of training examples.
In some other implementations, the system trains each of the neural networks to minimize a loss function that measures a loss between a final output generated from the network outputs generated by the K neural networks for the given training example and a target output for the given training example. As described above, the final output for a given training example can be a measure of the central tendency of the net outputs generated by the K neural networks.
In any of these embodiments, the loss function can include one or more additional terms, such as a regularization term or an auxiliary loss term or both, in addition to the term(s) of the loss between the measurement output and the target output.
To perform training of a given neural network, for each integration layer, the system applies first embedded parameters to the hyper-parameters sampled for the given neural network to generate modifiers for shared parameters, and processes inputs of the given neural network according to the shared parameters modified as described above. When included, the system also applies the second embedding parameters to the hyper-parameters sampled for the given neural network to generate modifiers for bias terms of the integration layer.
To determine the updates, for each integration layer, the system calculates, e.g., by back-propagation, respective gradients of the loss function with respect to the shared and embedded parameters of the integration layer, and for each neural network, calculates a respective gradient with respect to a particular parameter of the integration layer of that neural network. The system then maps the gradient to an update using an appropriate optimizer, e.g., adam, rmsProp, adaactor, SGD, etc.
Similarly, the system also computes updates to the remaining parameters of the neural network in the integration, i.e., updates to any layer that is not an integration layer within any neural network, by computing the gradient of the loss function with respect to those parameters.
The system then applies the updates determined for each of the K neural networks to the shared parameters (step 308). For each of the K neural networks, the system will also apply an update to a particular parameter of a first neural network layer of the neural network. Thus, a single shared update is applied to the shared parameters, while different neural network-specific updates are applied to specific parameters of each neural network.
In addition to updating the parameters, the system is also able to update the hyperparametric distribution of each neural network at each iteration of the process 300.
In particular, the system can obtain a plurality of verification examples and update the respective sets of hyper-parameter distribution parameters based on the performance of the K neural networks on the verification examples.
In particular, the system can calculate a gradient of the hyperparametric distribution parameter of each neural network relative to a validation loss function that (i) measures, for each neural network, a loss between a network output generated by the neural network for a given one of the validation examples and a target output for the given validation example, or (ii) measures a loss between a final output generated from network outputs generated by the K neural networks for the given validation example and the target output for the given validation example.
In some cases, the validation loss function also includes a term that measures the entropy of the hyperparametric distribution (i.e., the entropy of the overall distribution generated by combining the hyperparametric distributions of all neural networks in the integration) as defined by the current hyperparametric distribution parameter. Items that include this entropy can encourage diversity in the probability distribution of neural networks in the integration.
As described above, after training, the system needs to select a corresponding hyper-parameter for each neural network in the integration in order to generate an output for the new input. As a specific example, after the training has been completed, for each of the K neural networks, the system can fix the hyperparameters by selecting the hyperparameters using the probability distributions defined by the hyperparametric distribution parameters by the end of the training process. More specifically, for any given neural network, the system can select the value of each dimension of the multidimensional vector as the mean of the distribution of the dimensions defined by the final distribution parameters after training.
FIG. 4 shows graphs 400 and 450 indicating the performance of ultra-deep integration and ultra-batch integration across various machine learning tasks.
In particular, the graph 400 illustrates the performance of ultra-deep integration, referred to as "deep integration," configured to perform image classification and training on a CIFAR-100 dataset relative to a baseline technique, where all integrations in a batch are trained using the same hyper-parameters. As can be seen from this figure, ultra-deep integration is superior to deep integration over a range of different integration sizes, where the size of integration is the number of neural networks in the integration.
Graph 450 shows the performance of a single neural network, two baseline deep integration based techniques (fixed INIT integration and deep integration), ultra-deep integration, two baseline techniques known to be computationally efficient (batch integration, self-tuned network), and ultra-batch integration on two image classification tasks: one image classification task was trained on the CIFAR-100 dataset and another image classification task was trained on the fashion MNIST dataset. Graph 450 also shows results for two different neural network architectures: multilayer perceptron (MLP) and LeNet. That is, the graph 450 shows that each neural network is a result of MLP and each neural network is a result of LeNet. The MLP can include a plurality of linear hidden layers optionally separated from the nonlinear activation function layers, and further optionally include a random deactivation (dropout) layer before the last layer of the neural network. LeNet is a convolutional neural network, which consists of: the first two-dimensional convolutional layer with the largest pooling operation, followed by the two-dimensional convolutional layer with the largest pooling operation, and finally two dense layers. The activation function can be applied after each convolutional layer. In addition, a random deactivation layer can be included before the last dense layer.
As can be seen from graph 450, ultra-deep integration is generally superior to techniques based on baseline deep integration, while ultra-batch integration is generally superior to baseline computationally efficient techniques on various performance measures (negative log-likelihood ("nll"), classification accuracy ("acc"), and expected calibration error ("ece")).
The term "configured" is used herein in connection with system and computer program components. For a system of one or more computers to be configured to perform a particular operation or action, it refers to the system having installed thereon software, firmware, hardware, or a combination thereof that in operation causes the system to perform the operation or action. By one or more computer programs to be configured to perform particular operations or actions, it is meant that the one or more programs include instructions that, when executed by data processing apparatus, cause the apparatus to perform the operations or actions.
Embodiments of the subject matter and the functional operations described in this specification can be implemented in digital electronic circuitry, in tangibly embodied computer software or firmware, in computer hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them. Embodiments of the subject matter described in this specification can be implemented as one or more computer programs, i.e., one or more modules of computer program instructions encoded on a tangible, non-transitory storage medium for execution by, or to control the operation of, data processing apparatus. The computer storage medium can be a machine-readable storage device, a machine-readable storage substrate, a random or serial access memory device, or a combination of one or more of them. Alternatively or in addition, the program instructions can be encoded on an artificially generated propagated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal, that is generated to encode information for transmission to suitable receiver apparatus for execution by a data processing apparatus.
The term "data processing apparatus" refers to data processing hardware and encompasses all types of apparatus, devices, and machines for processing data, including by way of example a programmable processor, a computer, or multiple processors or computers. The apparatus can also be or further comprise special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit). The apparatus can optionally include, in addition to hardware, code that creates an execution environment for the computer program, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, or a combination of one or more of them.
A computer program, which may also be referred to or described as a program, software application, app, module, software module, script, or code, can be written in any form of programming language, including compiled or interpreted languages, or declarative or procedural languages; and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, or other unit suitable for use in a computing environment. A program may, but need not, correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data, e.g., one or more scripts stored in a markup language document, in a single file dedicated to the program in question, or in multiple coordinated files, e.g., files that store one or more modules, sub programs, or portions of code. A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a data communication network.
In this specification, the term "database" is used broadly to refer to any collection of data: the data need not be structured in any particular way, or at all, and it can be stored on a storage device in one or more locations. Thus, for example, the index database can include multiple data sets, each of which can be organized and accessed differently.
Similarly, in this specification, the term "engine" is used broadly to refer to a software-based system, subsystem, or process that is programmed to perform one or more particular functions. Typically, the engine will be implemented as one or more software modules or components installed on one or more computers in one or more locations. In some cases, one or more computers will be dedicated to a particular engine; in other cases, multiple engines can be installed and run on the same computer or computers.
The processes and logic flows described in this specification can be performed by one or more programmable computers executing one or more computer programs to perform functions by operating on input data and generating output. The processes and logic flows can also be performed by, and in particular by, special purpose logic circuitry, e.g., an FPGA or an ASIC, or by a combination of special purpose logic circuitry and one or more programmed computers.
A computer suitable for executing a computer program can be based on a general purpose or special purpose microprocessor or both, or any other type of central processing unit. Generally, a central processing unit will receive instructions and data from a read-only memory or a random access memory or both. The essential elements of a computer are a central processing unit for executing or performing instructions and one or more memory devices for storing instructions and data. The central processing unit and the memory can be supplemented by, or incorporated in, special purpose logic circuitry. Generally, a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks. However, a computer need not have such devices. Moreover, a computer can be embedded in another device, e.g., a mobile telephone, a Personal Digital Assistant (PDA), a mobile audio or video player, a game console, a Global Positioning System (GPS) receiver, or a portable storage device, e.g., a Universal Serial Bus (USB) flash drive, to name a few.
Computer readable media suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, e.g., internal hard disks or removable disks; magneto-optical disks; and CD ROM and DVD-ROM disks.
To provide for interaction with a user, embodiments of the subject matter described in this specification can be implemented on a computer having a display device, e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to the user and a keyboard and a pointing device, e.g., a mouse or a trackball, by which the user can provide input to the computer. Other kinds of devices can also be used to provide for interaction with the user; for example, feedback provided to the user can be any form of sensory feedback, e.g., visual feedback, auditory feedback, or tactile feedback; and input from the user can be received in any form, including acoustic, speech, or tactile input. In addition, the computer can interact with the user by sending documents to and receiving documents from the device used by the user, e.g., by sending web pages to a web browser on the user's device in response to receiving requests from the web browser. Further, a computer can interact with a user by sending a text message or other form of message to a personal device, such as a smartphone that is running a messaging application, and then receiving a response message from the user.
The data processing apparatus for implementing the machine learning model can also include, for example, a dedicated hardware accelerator unit for processing common and computationally intensive portions of machine learning training or production, i.e., inferences, workloads.
The machine learning model can be implemented and deployed using a machine learning framework, such as a TensorFlow framework, a Microsoft Cognitive Toolkit framework, an Apache Singa framework, or an Apache MXNet framework.
Embodiments of the subject matter described in this specification can be implemented in a computing system that includes a back-end component, e.g., as a data server; or include middleware components, such as application servers; or include a front-end component, e.g., a client computer having a graphical user interface, a web browser, or an app through which a user can interact with an embodiment of the subject matter described in this specification; or any combination of one or more such back-end, middleware, or front-end components. The components of the system can be interconnected by any form or medium of digital data communication (e.g., a communication network). Examples of communication networks include a local area network ("LAN") and a wide area network ("WAN"), e.g., the Internet.
The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other. In some embodiments, the server transmits data, e.g., HTML pages, to the user device, e.g., for the purpose of displaying data to and receiving user input from a user interacting with the device acting as a client. Data generated at the user device, e.g., a result of the user interaction, can be received at the server from the device.
While this specification contains many specific implementation details, these should not be construed as limitations on the scope of any invention or of what may be claimed, but rather as descriptions of features that may be specific to particular embodiments of particular inventions. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely, various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Moreover, although features may be described above as acting in certain combinations and even initially claimed as such, one or more features from a claimed combination can in some cases be excised from the combination, and the claimed combination may be directed to a subcombination or variation of a subcombination.
Similarly, while operations are depicted in the drawings and described in the claims below in a particular order, this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order, or that all illustrated operations be performed, to achieve desirable results. In some cases, multitasking and parallel processing may be advantageous. Moreover, the separation of various system modules and components in the embodiments described above should not be understood as requiring such separation in all embodiments, and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.
Specific embodiments of the subject matter have been described. Other embodiments are within the scope of the following claims. For example, the actions recited in the claims can be performed in a different order and still achieve desirable results. As one example, the processes depicted in the accompanying figures do not necessarily require the particular order shown, or sequential order, to achieve desirable results. In some cases, multitasking and parallel processing may be advantageous.
Claims (23)
1. A method of training an integration comprising K neural networks to perform a machine learning task, wherein K is an integer greater than 1,
wherein each of the K neural networks includes a plurality of neural network layers having respective parameters,
wherein the plurality of neural network layers includes a first neural network layer having, for each of the K neural networks:
(i) Shared parameters shared among all K neural networks in the ensemble,
(ii) A specific parameter specific to the neural network, an
(iii) An embedding parameter comprising a first embedding parameter that maps a current hyper-parameter to a modifier for the shared parameter,
wherein the method comprises the following steps:
maintaining, for each of the K neural networks, a respective set of hyperparametric distribution parameters that define a distribution over hyperparameters used for training of the neural network; and
training the K neural networks by repeatedly performing the following operations:
for each of the K neural networks, sampling a hyperparameter from the distribution defined by the respective hyperparameter distribution parameter set for the neural network;
obtaining a plurality of training examples;
for each of the K neural networks, training the neural network on the plurality of training examples in accordance with the hyper-parameters sampled for the neural network to determine updates to at least the shared parameters, the particular parameters, and the embedded parameters of the first neural network layer; and
applying the determined updates for each of the K neural networks to the shared parameters.
2. The method of claim 1, wherein the embedding parameters are shared between neural networks in the integration.
3. The method of any of claims 1 or 2, the operations further comprising:
for each of the K neural networks, applying the update to the particular parameter of the first neural network layer of the neural network.
4. The method of any of claims 1-3, wherein training each of the neural networks on the training examples includes training each of the neural networks to minimize a loss function that measures, for each neural network, a loss between a network output generated by the neural network for a given training example and a target output for the given training example.
5. The method of any of claims 1-3, wherein training each of the neural networks on the training examples includes training each of the neural networks to minimize a loss function that measures a loss between a final output generated from network outputs generated by the K neural networks for a given training example and a target output for the given training example.
6. The method of any of claims 1-5, wherein, for each of the K neural networks, training the neural network on the plurality of training examples in accordance with the sampled hyper-parameters comprises applying the embedding parameters to the sampled hyper-parameters to generate the modifier for the shared parameters.
7. The method of any of claims 1-6, the operations further comprising:
obtaining a plurality of verification examples; and
updating the respective sets of hyperparametric distribution parameters based on performance of the K neural networks on the verification example.
8. The method of any of claims 1-7, wherein the particular parameters include a first particular parameter that modifies the shared parameter and a second particular parameter that defines a particular bias vector for the first neural network layer.
9. The method of claim 8, wherein the embedding parameters further comprise a second embedding parameter that maps a current hyperparameter to a modifier for the particular bias vector.
10. A method of training an integration comprising K neural networks to perform a machine learning task, wherein K is an integer greater than 1, and wherein the method comprises:
identifying a set of N different hyper-parameters for training a neural network having parameters to perform the machine learning task, wherein N is an integer greater than 1; and
for each of the N different hyperparameters, generating a set of first candidate trained neural networks by:
selecting a plurality of different initializations for values of parameters of the neural network; and
for each of the different initializations, training the corresponding neural network with (i) the different hyper-parameters and (ii) the parameter values initialized using the different initializations to generate a trained neural network; and
generating an ensemble of the K neural networks by selecting K neural networks from the first candidate trained neural networks.
11. The method of claim 10, wherein identifying a set of N different hyper-parameters for training a neural network in the ensemble comprises:
applying a hyper-parameter search technique to identify M best performing hyper-parameters for the machine learning task, wherein M is an integer greater than N; and
n hyper-parameters are selected from the M best performing hyper-parameters using a first ensemble selection technique.
12. The method of claim 11, wherein N equals K.
13. The method of any of claims 11 or 12, wherein the hyper-parametric search technique is a random search.
14. The method according to any one of claims 11-13, wherein selecting the N hyper-parameters using the integrated selection technique comprises:
generating a set of M second candidate neural networks, each second candidate neural network having been trained using a different one of the M best performing hyper-parameters;
generating a first integration of N candidate neural networks from the M second candidate neural networks by repeatedly selecting a candidate neural network from the M candidate neural networks to add to the first integration, wherein the candidate neural network, if added to the first integration, results in a maximum increase in performance of the first integration; and
selecting the hyperparameters used to train the N candidate neural networks in the first ensemble as the N hyperparameters.
15. The method of any one of claims 10-14, wherein generating an integration of the K neural networks includes generating the integration using a second integration generation technique.
16. The method of claim 15, wherein generating an integration of K neural networks comprises:
generating an ensemble of the K neural networks from the first set of candidate trained neural networks by repeatedly selecting a first candidate trained neural network from the first set of candidate trained neural networks to add to the ensemble, wherein the first candidate trained neural network, if added to the ensemble, results in a maximum improvement in performance of the ensemble.
17. The method of any one of claims 10-16, wherein the different initializations of the parameters of the neural network are different random initializations of the values of the parameters of the neural network.
18. The method of any preceding claim, further comprising: after training the integration:
receiving a new network input;
processing the new network input using each of the K neural networks in the ensemble to generate K new network outputs for the new network input; and
generating a final new network output for the new network input from the K new network outputs.
19. The method of claim 18, further comprising:
generating a measure of uncertainty in accuracy of the final new network output from the K new network outputs.
20. The method of any one of claims 18 or 19, when also in accordance with one of claims 1-9, wherein processing the new network input using each of the K neural networks in the ensemble to generate K new network outputs for the new network input comprises:
for each of the K neural networks, after the training is complete, determining a hyperparameter based on the respective hyperparameter distribution parameter set for the neural network, and applying the embedding parameters for the neural network to the determined hyperparameter.
21. The method of any of the preceding claims, wherein the machine learning task comprises an image classification, image embedding generation, object detection, image segmentation, speech recognition, text-to-speech, or real-world agent control task.
22. A system comprising one or more computers and one or more storage devices storing instructions that, when executed by the one or more computers, cause the one or more computers to perform operations of the respective methods of any preceding claim.
23. One or more computer storage media storing instructions that, when executed by one or more computers, cause the one or more computers to perform operations of the respective methods of any of claims 1-21.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US202063035614P | 2020-06-05 | 2020-06-05 | |
US63/035,614 | 2020-06-05 | ||
PCT/US2021/036255 WO2021248140A1 (en) | 2020-06-05 | 2021-06-07 | Hyperparameter neural network ensembles |
Publications (1)
Publication Number | Publication Date |
---|---|
CN115516466A true CN115516466A (en) | 2022-12-23 |
Family
ID=76797092
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202180033319.2A Pending CN115516466A (en) | 2020-06-05 | 2021-06-07 | Hyper-parametric neural network integration |
Country Status (4)
Country | Link |
---|---|
US (1) | US20230206030A1 (en) |
EP (1) | EP4118584A1 (en) |
CN (1) | CN115516466A (en) |
WO (1) | WO2021248140A1 (en) |
Family Cites Families (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20190122141A1 (en) * | 2017-10-23 | 2019-04-25 | Microsoft Technology Licensing, Llc | Fast hyperparameter search for machine-learning program |
-
2021
- 2021-06-07 US US18/008,404 patent/US20230206030A1/en active Pending
- 2021-06-07 CN CN202180033319.2A patent/CN115516466A/en active Pending
- 2021-06-07 WO PCT/US2021/036255 patent/WO2021248140A1/en unknown
- 2021-06-07 EP EP21737855.3A patent/EP4118584A1/en active Pending
Also Published As
Publication number | Publication date |
---|---|
EP4118584A1 (en) | 2023-01-18 |
US20230206030A1 (en) | 2023-06-29 |
WO2021248140A1 (en) | 2021-12-09 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11934956B2 (en) | Regularizing machine learning models | |
US11568207B2 (en) | Learning observation representations by predicting the future in latent space | |
US10936949B2 (en) | Training machine learning models using task selection policies to increase learning progress | |
US11669744B2 (en) | Regularized neural network architecture search | |
US11080589B2 (en) | Sequence processing using online attention | |
US20210049298A1 (en) | Privacy preserving machine learning model training | |
US11922281B2 (en) | Training machine learning models using teacher annealing | |
US20220092416A1 (en) | Neural architecture search through a graph search space | |
US11803731B2 (en) | Neural architecture search with weight sharing | |
US20220188636A1 (en) | Meta pseudo-labels | |
US20220391706A1 (en) | Training neural networks using learned optimizers | |
US20220253713A1 (en) | Training neural networks using layer-wise losses | |
US20220019856A1 (en) | Predicting neural network performance using neural network gaussian process | |
US20230063686A1 (en) | Fine-grained stochastic neural architecture search | |
US20230121404A1 (en) | Searching for normalization-activation layer architectures | |
US20230206030A1 (en) | Hyperparameter neural network ensembles | |
WO2022072890A1 (en) | Neural architecture and hardware accelerator search | |
CN114730380A (en) | Deep parallel training of neural networks | |
US20220129760A1 (en) | Training neural networks with label differential privacy | |
US20240005131A1 (en) | Attention neural networks with tree attention mechanisms | |
US20230107247A1 (en) | Neural networks with transformed activation function layers | |
US20230316729A1 (en) | Training neural networks | |
WO2023154491A1 (en) | Training neural networks using layerwise fisher approximations |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |