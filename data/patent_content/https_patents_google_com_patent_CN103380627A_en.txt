CN103380627A - Providing dynamic content with an electronic video - Google Patents
Providing dynamic content with an electronic video Download PDFInfo
- Publication number
- CN103380627A CN103380627A CN2011800452662A CN201180045266A CN103380627A CN 103380627 A CN103380627 A CN 103380627A CN 2011800452662 A CN2011800452662 A CN 2011800452662A CN 201180045266 A CN201180045266 A CN 201180045266A CN 103380627 A CN103380627 A CN 103380627A
- Authority
- CN
- China
- Prior art keywords
- video
- content
- dynamic content
- computing device
- client computing
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/60—Network structure or processes for video distribution between server and client or between remote clients; Control signalling between clients, server and network components; Transmission of management data between server and client, e.g. sending from server to client commands for recording incoming content stream; Communication details between server and client
- H04N21/65—Transmission of management data between client and server
- H04N21/658—Transmission by the client directed to the server
- H04N21/6581—Reference data, e.g. a movie identifier for ordering a movie or a product identifier in a home shopping application
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/20—Servers specifically adapted for the distribution of content, e.g. VOD servers; Operations thereof
- H04N21/23—Processing of content or additional data; Elementary server operations; Server middleware
- H04N21/234—Processing of video elementary streams, e.g. splicing of video streams, manipulating MPEG-4 scene graphs
- H04N21/23412—Processing of video elementary streams, e.g. splicing of video streams, manipulating MPEG-4 scene graphs for generating or manipulating the scene composition of objects, e.g. MPEG-4 objects
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/20—Servers specifically adapted for the distribution of content, e.g. VOD servers; Operations thereof
- H04N21/27—Server based end-user applications
- H04N21/274—Storing end-user multimedia data in response to end-user request, e.g. network recorder
- H04N21/2743—Video hosting of uploaded data from client
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/47—End-user applications
- H04N21/478—Supplemental services, e.g. displaying phone caller identification, shopping application
- H04N21/4788—Supplemental services, e.g. displaying phone caller identification, shopping application communicating with other users, e.g. chatting
Abstract
In one implementation, a computer-implemented method includes receiving a request from a client computing device for an electronic video, and dynamically identifying content to display while the video is played based on one or more content parameters associated with the video that indicate, at least, a type of dynamic content to be identified after the request is received. The method can further include providing the identified dynamic content to the client computing device in a form so that the dynamic content will be displayed on the client computing device in accordance with one or more display parameters that indicate, at least, a time during playback of the video or a location in relation to the video at which the dynamic content is displayed.
Description
The cross reference of related application
The application requires in U. S. application sequence number No.12/885 that submit to, that be entitled as PROVIDING DYNAMIC CONTENT WITH AN ELECTRONIC VIDEO on September 20th, 2010, and 950 priority is integrated with this paper with its disclosure by reference.
Technical field
This document has been described technology, method, system and the computer program that is used for providing with electric video dynamic content generally.
Background technology
Many websites (for example, FACEBOOK, YOUTUBE etc.) with electric video (for example allow the user, the video of FLASH video, MPEG-2 coding, QUICKTIME video etc.) upload to its computer server system (for example to pass through network, the internet) to other users distribution (for example, the video playback that send of stream, video file download etc.).Part in these websites has allowed the user to add static note (for example, text, hyperlink) to its video.Video annotation is the extra video content that the content of video is replenished.Note has been presented as the part that covers video in time and the position of user's appointment during video playback text box.
For example, suppose that the Alice is the user who has uploaded the one minute video that is illustrated in Hawaiian sight spot (such as the seaside resort that begins at video with at the surfing course of 30 seconds marks).The Alice can add video annotation to describe these sight spots in whole video.For example, the Alice can add with the title of seaside resort with to the first video annotation of the link of the webpage of this seaside resort, with the second video annotation of the expense of surfing course, and with the 3rd video annotation to the link of the travelling website that is provided to Hawaiian air ticket price.The Alice can specify in video and begin ad-hoc location (for example, will can not cover the position of the important content in the video) on video and locate to show that the first video annotation and its continue until 30 marks in second (the surfing course of video partly begins) of video.The Alice can specify the second video annotation to be marked at another position display on the video and to continue until video finishes in 30 seconds of video.The Alice can further specify the 3rd video annotation from 45 second mark until video finish in the position display different from the position of the second note.When another user Bob (for example checks, stream send from the video website) during Alice's video, can time of Alice's appointment, position and with the content of Alice's appointment (for example, the title of holiday resort, to the holiday resort link, surfing course expense, to the link of travelling website) together to Bob's display video note.
Summary of the invention
This document has been described technology, method, system and the computer program that is used for providing with electric video dynamic content (for example, text, hyperlink, image, animation, video, sound etc.).When being request service (or in its threshold time amount) to video, can dynamically retrieving and treat the extra video content (for example, video annotation) that shows with video.For example, launch based on top example, the Alice can show that the dynamic video annotation of Hawaiian current weather situation adds its Hawaii video to being configured to when the user asks and/or checks this video.When the Bob to video website request Alice about Hawaiian video the time, can retrieve Hawaiian current weather situation and it is shown to the Bob as time and the position of the note in this video in Alice's appointment.
According to the template of user's appointment and/or the entity that is associated with video, the author's (for example, the uploader of video, the founder of video, copyright holder etc.) such as video can be video Dynamic Selection and retrieval of content.Can based on many factors, such as the information (for example, video request person's geographical position, video request person's social networks existence etc.) about video request person, come chosen content.Any one that can be from multiple electronic third-party content provider, such as social networks (for example, FACEBOOK), the travel server system (for example, KAYAK.COM) and/or electronic reference resources (for example, WIKIPEDIA), dynamic retrieval of content.
Further launch based on top example, the Alice can the content creating template, so that the 3rd video annotation comprises from video request person's current geographic position to Hawaiian current air ticket price transaction, rather than the static linkage that is provided to the travelling website is as the 3rd video annotation.For example, suppose that the Bob is positioned at New York, New York, and Bob (passing through computing equipment) to the server system request Alice of trustship Alice's video about Hawaiian video.Based on the specified template of Alice, the current geographic position that this server system can be determined the Bob (for example, use its Internet protocol (IP) address to search Bob's geographical position, obtain/receive Bob's geographical position etc. by cell tower triangulation or global positioning system (GPS)), and retrieval is about from New York to the information of Hawaiian current air ticket price quote (for example, mutual with third party's website of travelling).Then, these air ticket price quote can be provided to the Bob at special time (for example, 45 second mark) and at ad-hoc location during this Hawaii video of playback as content (for example, video annotation).
In one embodiment, computer implemented method is included in the computer server system place from the request of client computing device reception to electric video; And based on the one or more content parameters that are associated with video and the type of the dynamic content that is identified is treated in indication after receiving request at least, come Dynamic Recognition to treat the content that shows when displaying video, dynamic content is can be in the content of playing the type that automatically changes along with passage of time between electric video.The method may further include with certain forms the dynamic content of being identified is offered client computing device, so that on client computing device, show this dynamic content, this dynamic content of indicated number, during playback video at least time of described one or more display parameters or the position relevant with video according to one or more display parameters.As the part of this computer implemented method, content parameters and display parameters were specified by the first user that is associated with this video before receiving request.
In another embodiment, computer implemented method is included in the computer server system place from the request of client computing device reception to electric video.The method can also comprise that generating code is to offer client computing device, the content that described code shows when impelling the client computing device Dynamic Recognition to treat at displaying video when being explained by client computing device, wherein this code is generated as and comprises that the one or more content parameters that are associated with video and indicate at least the type of dynamic content to be identified, dynamic content are can be in the content of playing the type that automatically changes along with passage of time between electric video.The method may further include to client computing device code and the one or more display parameters that generate is provided, and wherein one or more display parameters at least indicated number are treated time dynamic content, during playback video or the position relevant with video by client computing device identification.As the part of the method, content parameters and display parameters were specified by the first user that is associated with this video before receiving request.
In another embodiment, be used for providing the system of dynamic content to comprise one or more computer servers and being configured to from the interface of client computing device reception to the request of electric video for these one or more servers with electric video.This system may further include the dynamic content recognizer component of these one or more servers, it is configured to based on the one or more content parameters that are associated with video and the type of the dynamic content that is identified is treated in indication after receiving request at least, come Dynamic Recognition to treat the content that shows when displaying video, dynamic content is can be in the content of playing the type that automatically changes along with passage of time between electric video.This system can comprise the dynamic content subsystem of these one or more servers in addition, it is configured to certain forms the dynamic content of being identified be offered client computing device, so that on client computing device, show this dynamic content, this dynamic content of indicated number, during playback video at least time of described one or more display parameters or the position relevant with video according to one or more display parameters.As the part of this system, content parameters and display parameters were specified by the first user that is associated with this video before receiving request.
One or more embodiments of the detail have been set forth at accompanying drawing with in the following describes.Technology described here, method, system and computer program can provide various advantages.For example, provide together dynamic content can make video more relevant with given user with video.For example, can be based on the information about the user, such as user's current geographic position, come the content that Dynamic Selection connects user and video (for example, the air ticket price quote from user's current location to the destination of video, describing).
In another example, provide dynamic content can make video more relevant with the current time.For example, can Dynamic Recognition about the news of the theme of video, and it is provided with video as content.Such news can be filled up and may just ask the information breach that exists between the time of video the time that creates video and user.
In further example, the author who provides dynamic content can reduce video will spend time quantum that video is updated in addition.In the situation of static video annotation, the author monitors current information, then in case renewal is identified, just manually edits note to comprise the information of renewal.By contrast, the user can a drawing template establishment, and subsequently, can quote this template in the lifetime of video and identify and retrieve dynamic content, and without user's further action.
In addition, dynamic content can be localized concerning the user.Localization can comprise that Preferred Language (for example, Spanish, Arabic, English etc.), currency (for example, Euro, dollar etc.) and/or time format with the user (for example, 12 hours form, 24-hour format) represent dynamic content to the user.User's computing equipment, can indicate localization information concerning the user such as user's web-browsing device or other client application.For example, can represent dynamic content for video annotation to the Arabic viewer with arabic text, and can this represents dynamic content for the same video note to Spanish viewer with Spain's Chinese language.
It will be apparent that other features of the present invention, purpose and advantage require from description and accompanying drawing and accessory rights.
Description of drawings
Fig. 1 is for the concept map that the example system of dynamic content is provided with electric video.
Fig. 2 has described to be used for providing with electric video the example system of dynamic content.
Fig. 3 A-D has described to be used for providing with electric video the example technique of dynamic content.
Fig. 4 A-F is the screenshotss of the example electric video that shows of the content with Dynamic Recognition.
Fig. 5 be can be used for being implemented in the system and method described in this document, as client or as the block diagram of the computing equipment of server or a plurality of servers.
In each accompanying drawing, the identical identical element of reference symbol indication.
Embodiment
This document described generally be used for electric video (for example, the electric video that stream send, the electric video of download etc.) technology, method, system and the computer program of dynamic content (for example, text, hyperlink, image, animation, video, sound etc.) be provided together.The request to video in response to from client computing device (for example, laptop computer, desktop computer, smart mobile phone, mobile phone, dull and stereotyped computing equipment etc.) can be video Dynamic Recognition and retrieval of content.Can work in coordination with provides the content of Dynamic Recognition to the playback of video to client computing device, and shows the content (for example, dynamic content can be shown as covering the video annotation of the part of video) of Dynamic Recognition in client computing device.Dynamic content can replenish or augment electric video.
For example, you have created the electric video that race is shown subscriber card, have wherein recorded ten the 100 meter dash times the fastest, and he uploads to video server system (for example, FACEBOOK, YOUTUBE etc.) to distribute to other users with this video.What know is, the most front ten the 100 meter dash times may change along with passage of time, and Ka Er specifies and is used for the future time Dynamic Recognition of being checked by another user at his video and shows many kinds of parameters about the information of current the most front ten 100 meters times.For example, Ka Er can specify to identify dynamic content (about the information of current the most front ten 100 meters times) and show content parameters and the display parameters of dynamic content with his video.Content parameters can be specified the type (for example, the fact/sport information) of dynamic content to be retrieved and is used for the parameter of identification expectation content (for example, current the most front ten the 100 meter dash times).Display parameters can be specified time, duration and/or the position (for example, showing current the most front ten the 100 meters times in last 30 seconds of playback in the row below the right side at video) for the treatment of to show explicitly with video dynamic content.
Further launch based on this example, video server system can be identified dynamic content and provide this dynamic content to following viewer explicitly with the video of Ka Er with the specified parameter of Ka Er.For example, upload at Ka Er/final updating several years after his video, another user Dai Fu (passing through computing equipment) is to the video of video server system request Ka Er.In response to the request of wearing the husband, video server system can use the specified content parameters of Ka Er from current the most front ten the 100 meter dash times of content source (for example, as the third party content supplier of WIKIPEDIA or be provided with the search engine of the keyword that Ka Er identifies) identification at least.In addition, video server system can be configured the video of Ka Er and/or the dynamic content that retrieves (current the most front ten the 100 meter dash times), so that come video with Ka Er to show dynamic content (for example, showing current the most front ten the 100 meters times in last 30 seconds of playback in the row below the right side at video) according to the display parameters of appointment.Video server system can offer Dai Fucong with the video of asking with dynamic content, and it has asked the computing equipment of the video of Ka Er.During this video of playback on the computing equipment, can represent about the current information of the most front ten the 100 meter dash times to wearing the husband, and must find out such information or upgrade the information of this video/be associated with this video without him or Ka Er.
As below in greater detail, can identify and provide dynamic content with many kinds of parameters.For example, can be based on identifying dynamic content with the computing equipment of request video and/or the information that the user is associated.For example, can be with identify the dynamic content treating to represent with video (for example, the identification film is positioned near the projection time of the cinema the user geographically) with the computing equipment of request video and/or geographical position that the user is associated.In another example, can identify dynamic content based on the information that is associated with other users.For example, at social networks (for example can use the user of the request of sending, FACEBOOK, LINKEDIN, MYSPACE, TWITTER etc.) in the acquaintance (for example, friend, business contact, household etc.) comment and/or the recommendation delivered, identify the dynamic content that provides to the user of the request of sending with video is provided.
Fig. 1 is for the concept map that the example system 100 of dynamic content is provided with electric video 102.Example system 100 is depicted as and comprises the author's computing equipment 104 that video 102 is uploaded to video server system 106.System 100 has also been described with backward video server system 106 request videos 102, and as response, is provided with video 102 and is the client computing device 108 of the content of video 102 Dynamic Recognition.
Author's computing equipment 104 can be any one in the multiple computing equipment, such as laptop computer, desktop computer, smart mobile phone, mobile phone, dull and stereotyped computing equipment and net book.Author's computing equipment 104 is depicted as receiver, video 102.For example, video 102 can (for example receive from another computing equipment, download from another computing equipment), from computer-readable recording medium (for example, flash memory device, CD/DVD etc.), read and/or use the video editing that is installed on author's computing equipment 104 should be used for establishment by author's computing equipment 104.
Describe such as steps A (112), author's computing equipment 104 is video 102(and movie trailer 110) drawing template establishment 114.Template 114 can comprise that video server system 106 makes to identify the parameter (for example, content parameters, display parameters etc.) that the dynamic content that provides with video 102 is provided.In this example system 100, template 114 comprises that the dynamic content that specify to be used for video 102 should comprise that (in movie trailer 110 previews) film is being positioned at the parameter of the projection time of the one or more cinemas viewer's the current geographic position near.For example, parameter based on general introduction in template 114, provide the information relevant with the cinema of just showing the film of describing in movie trailer 110 that is positioned at New York (for example the first user that on geography, is arranged in New York, New York, projection time, street address, price etc.), and provide the different information relevant from the cinema of just showing this film that is positioned at Zurich with the second user who on geography, is positioned at Zurich, SUI.
Although being depicted as, template 114 comprises content parameters, yet, in template 114, can comprise other parameters.For example, template 114 can comprise display parameters, it (for example provides during specifying in playback video 102, demonstration, broadcast etc.) dynamic content time, the duration of dynamic content is provided, the effect that when dynamic content is provided, is applied to dynamic content (for example, fade in, fade out, transparency, font, color etc.) and/or with respect to the position of the dynamic content to be supplied of video (for example, cover video, near the video demonstration etc.).
Author's computing equipment 104 can independent or collaborative video server system 106 drawing template establishments 114.For example, author's computing equipment 104 can move the independent utility that is configured to generate template 114, uses such as being installed in video editing on author's computing equipment 104/note.In another example, author's computing equipment 104 can be by with video server system 106 mutual, such as the application based on browser that provides to author's computing equipment 104 by network (for example, the internet) by video server system 106, drawing template establishment 114.
Such as step B(116) in the institute describe, author's computing equipment 104 offers video server system 106 with video 102 and template 114.For example, author's computing equipment 104 can upload to video server 106 to distribute to other users with video 102 and template 114.Can go up back(ing) board 114 explicitly with video 102, so that video server system 106 is being quoted template 114 with video 102 dynamic content supplieds for to the request service of video 102 time.
Such as step C(122) institute describe, client computing device 108(is similar to author's computing equipment 104) provide electronic request to video 102 by network (for example, internet, Local Area Network, wide area network (WAN) etc.) to video server system 106.For example, 108 requests comprise that the webpage of video 102 responds to client computing device, can provide this request to video server system 106.
Such as step D(124) indicated, in response to receiving request from client computing device 108, video server system 106 usefulness templates 114 come Dynamic Recognition that the content that provides with video 102 is provided.For example, video server system 106 can be associated with the video 102 that client computing device 108 is asked by recognition template 114, and can assess to determine how to obtain dynamic content to the parameter that is included in the template 114.For example, the type that video server system 106 can be determined just requested multidate information (for example, film information, travel information, the fact/reference information, social network information etc.), and based on the type of information, identify the one or more content providers that wait to contact to obtain dynamic content.Example system 100 comprises content provider 126a-n, wherein content provider 126a be social networking system (for example, FACEBOOK, LINKEDIN, TWITTER etc.), content provider 126b be the film information system (for example, MOVIEFONE, company of cinema etc.), content provider 126c be information system (for example, news polymerizer, really simple syndication (RSS) news are fed etc.), and content provider 126n is travelling quotation system (for example, TRAVELOCITY, KAYAK etc.).The multiple other guide supplier who does not describe also can be the part of system 100.
In the example of describing, video server system 106 can determine that the type of the information of asking is film information in template 114.Therefore, video server system 106 can be identified as the 126b of this film information system and wait to contact the content provider who obtains the dynamic content of expectation for video 102.Video server system 106 can content-based type and content provider predetermined related make such determining.In addition, in some instances, video server system 106 self can be identified as the content provider of the content (such as the video related content) to particular type.Should more than the information of a type (for example provide with video 102 such as specifying when template 114, the projection time of film 110 is provided and from the nearest comment to film 110 of news agency) time, video server system 106 can be identified more than a content provider.
Indicated such as step F (130), video server system 106 will offer the content provider that the 126b(of film information system identifies for the type of dynamic content specified in template 114 with the geographical location information 132 of client computing device 108 to the request of dynamic content).As response, the 126b of film information system identification is positioned near the cinema in geographical position of client computing device 108, and such as step G(134) indicated, will respond with dynamic content 136 and offer video server system 106.In this example, dynamic content 136 is included in the film described in the movie trailer 110 information in the projection time of Mega-Theater and Small Theater.This dynamic content 136 can provide time of the request of video 102 with the geographical position (for example, client computing device 108 may be moved to different geographical position) of client computing device 108 with to video server system 106 and change.
Such as step H(138) indicated, video server system 106 provides video 102 and dynamic content 136 to client computing device 102.Video server system 106 can be configured to quote and show dynamic content 138 video 102 and/or the information that provides with video (webpage that for example, represents video 102 just within it) during video playback.Can reconfigure dynamic content 138 in addition and/or reformatting to represent (for example, content server 126b can provide dynamic content 138 with the form different from the form that is used for representing with video 102) with video 102.Video server system 106 can offer client computing device 108 together or separately with video 102 and dynamic content 138.
For example, video server system 106 can be distributed to client computing device 108 with video 102, wherein video 102(and/or the information that is associated) being initialised becomes video 102 request notes.For example, can be set to the comment field that video 102 is associated very, and can be set to video server system 106 in the note source.Videoconference client on client computing device 108 (for example, FLASH player, QUICKTIME player etc.) when beginning to load video 102 for playback, videoconference client can be to video server system 106 request notes, video server system 106 then can execution in step D-H to provide dynamic content 136 to client computing device 102.In another example, can provide simultaneously video 102 and dynamic content 136 to client computing device 108, wherein video 102 is initialized to and locates locally and/or quote dynamic content 136 on client computing device 108.
Client computing device 108 can be play the video 102 that receives from video server system 106, describes such as example video image 140.In addition, represent dynamic content 136 at the frame 142(at the top that covers video image 140 for example, note).Frame 142 can be positioned at the top of video image 140, and can be demonstrated at special time during playback video 102 according to template 114.In the example of describing, the frame 142 that comprises dynamic content 136 is translucent, so that it not exclusively covers any part of video 102.Can dynamic content 136 be integrated in the playback of video 102 with other effects.
Fig. 2 has described to be used for providing with electric video the example system 200 of dynamic content.System 200 is similar to the system 100 of describing with reference to figure 1 in the above.System 200 comprises the client computing device 202 that is configured to provide to video server system 204 the dynamic content template.Video server system 204 is configured to video is distributed to client computing device 206 with the content from content provider system 208 Dynamic Recognition.
Client computing device 202 is similar to author's computing equipment 104 of describing with reference to figure 1 in the above.Client computing device 202 can be any one in the multiple computing equipment, such as laptop computer, desktop computer, smart mobile phone and dull and stereotyped computing equipment.Client computing device comprises the dynamic content formwork module 210 that is configured to provide interface (for example, graphical user interface (GUI)), and by this interface, the user can be video creation dynamic content template.Dynamic content formwork module 210 can input to generate the dynamic content template based on the user that the interface that provides by dynamic content formwork module 210 receives.The dynamic content template can comprise be used to the various parameters for the treatment of as the dynamic content of electric video identification, is similar to the template 114 of describing with reference to figure 1 in the above.
Client computing device 202 can use I/O (I/O) interface 212 that the template that creates is offered video server system 204, and I/O interface 212 is configured to communicate by letter with video server system 204 by network 214.I/O interface 212 can be the interface that is configured to by any type of network 214 transmissions and the information of reception, such as Ethernet card, wireless network transmitter and cellular signal transmitter.Network 214 can be any one in the multiple communication network, such as internet, LAN, WAN, 3G/4G wireless network, fiber optic network or its any combination.
Client computing device 202 can provide the dynamic content template that generates electric video associated therewith by network 214 to video server system 204 in addition.Dynamic content formwork module 210 and/or video server system 204 can check to be that video submits to the user of dynamic content template whether to be authorized to do like this with in the multiple proving program any one.Various associations between user and the video can provide abundant mandate, have uploaded with it relevant video, founder that the user is video and/or the user copyright holder that is video of dynamic content template such as the user.
Subsystem of video 218 comprises and is configured to store and the video storage/retrieval module 224 of retrieve video.Video storage/retrieval module 224 can be stored and retrieve video alternately with video library 226.Video library 226 is similar to the video library 118 of describing with reference to figure 1 in the above.The video storage that video storage/retrieval module 224 can provide client computing device 202 in video library 226, and in response to the request to video from client computing device 208, can be from the video of video library 226 retrieve stored.
Dynamic content subsystem 220 comprises the template stores/retrieval module 228 that is configured to store and retrieve the dynamic content template.Template be stored and be retrieved to template stores/retrieval module 228 can alternately with ATL.ATL 230 is similar to the ATL 120 of describing with reference to figure 1 in the above.The template stores that template stores/retrieval module 228 can provide client computing device 202 is in ATL 230, and in response to the request to video from client computing device 208, can come video identification dynamic content for asking from the template of ATL 230 retrieve stored.
The client computing device 108 that client computing device 208 is similar to client computing device 202 and describes with reference to figure 1 in the above.Client computing device 208 be depicted as comprise be configured to play electric video video player 230(for example, FLASH player, QUICKTIME player etc.) and to the video request module 232(of video server system 204 request electric videos for example be configured to web-browsing device application etc.).Video request module 232 can be by being transferred to the electronic request of video server system 204 to the I/O interface 212 I/O interface 234 similar with 216 via network 214.
Subsystem of video 218 can also comprise video player configuration module 238, and the information that provides with the video of asking is provided in its generation, and it starts video player 230 provides dynamic content with video.For example, video player configuration module 238 can arrange the sign that is associated with the video of asking, and it should show extra video content with video to video player 230 indications.Video player configuration module 230 can also arrange resource identifier and indicate and can retrieve the position that dynamic content provides with video.
In some embodiments, video request processing module 236 can also indicate dynamic content subsystem 220 to identify to treat the dynamic content that provides with video, and dynamic content and video (with other information) can be gathered together and offer client computing device 208.In such execution mode, video player configuration module 238 can arrange resource identifier and indicate dynamic content is offered client computing device 208 with video.
In other embodiments, video request processing module 236 is not mutual with dynamic content subsystem 220, and is not having in the situation of dynamic content the video of asking to be offered client computing device 208 at first.In such execution mode, video player configuration module 238 can be arranged to resource identifier with video server system 204(and more specifically for dynamic extra video content, dynamic content subsystem 220) resource location that is associated.The video player 230 that arranging like this can be impelled client computing device 208 after the video of asking at least part of is provided to client computing device 208 to video server system 204 requests dynamic content.
Receive the dynamically additionally request of video content in response to (from subsystem of video 218 and/or client computing device 208), dynamic content subsystem 220 can be retrieved the one or more templates that are associated with associated video with template stores/retrieval module 228 and ATL 230.Dynamic content subsystem 220 also comprises client-side information extraction module 240, and it need can determine whether any client ends relative to identify dynamic content.Client ends relative can be with following relevant: the client computing device 202(of video and/or dynamic content template and/or the user who is associated with client computing device 202 are provided), just ask the client computing device 208(of video and/or the user who is associated with client computing device 208) and/or other user/client computing device.For example, client-side information extraction module 240 can be determined the geographical position that is associated with client computing device 208.
Dynamic content subsystem 220 comprises dynamic content recognizer component 242 in addition, and it is configured to identify the dynamic content that video of asking to be synergistic offers client computing device 208.Dynamic content recognizer component 242 can based on dynamic content template that the video of asking is associated in the parameter illustrated identify dynamic content.Based on template, dynamic content recognizer component 242 can based on the dynamic content that obtains alternately expectation that can from a plurality of content providers, be identified as suitable content provider's content provider system 206.
The client/user information that the parameter that dynamic content recognizer component 242 can comprise in the dynamic content template by network 214 usefulness and client-side information extraction module 240 are identified is come to content provider system 206 requests dynamic content.Content provider system 206 comprises and I/O interface 212,216 I/O interfaces 244 similar with 234.Content provider system 206 comprises the content retrieval module 246 that is configured to the request service of content.Content retrieval module 246 can be obtained the information of asking from the content library 248 that is configured to store the various contents of being safeguarded by content provider system 206.Content provider system 206 provides the attitude content subsystem 220 that reverses with the content of asking, itself so that this content can be offered subsystem of video 218 and/or client computing device 208.
Fig. 3 A-D has described to be used for providing with electric video the example technique 300 and 360 of dynamic content.Technology 300 and 360 is similar to the technology that is used for providing with electric video dynamic content of describing with reference to Fig. 1 and 2 in the above.Technology 300 and 360 part are depicted as by author's computing equipment 302, video server system 304, client computing device 306 and content provider system 308 and carry out.Author's computing equipment 302 is similar to author's computing equipment 104 and/or the client computing device 202 of describing with reference to Fig. 1 and 2 respectively in the above.Video server system 304 is similar to video server system 106 and/or the video server system 204 of describing with reference to Fig. 1 and 2 respectively in the above.Client computing device 306 is similar to client computing device 108 and/or the client computing device 208 of describing with reference to Fig. 1 and 2 respectively in the above.Content provider system 308 is similar to the 126a-n of content provider system and/or the content provider system 206 of describing with reference to Fig. 1 and 2 respectively in the above.
With reference to figure 3A, technology 300 creates the dynamic content template in step 310 and begins take author's computing equipment 302 as electric video.In step 312, author's computing equipment 302 offers video server system 304 with the template that creates.The template that creates can comprise for the content parameters of dynamic content and/or display parameters.Content parameters can be indicated for the many kinds of parameters of selecting dynamic content, such as the type of indicating dynamic content to be identified.Display parameters can be indicated with showing the much information that dynamic content is associated with video, should show the time of dynamic content and/or the information of position such as indication during playback video.
Video server system 304 receive the template that creates and with the template stores that creates for to be associated with video, so that when distributing video, can easily identify this template (step 314).Although do not describe, yet, author's computing equipment 302 can also provide the template that creates electric video associated therewith to video server system 304, and they can be by video server system 304 storages, for preparing to other users and/or computing equipment distribution.
In step 316, client computing device 306 provides request to electric video to video server system 304.Video server system 304 receives these requests (step 318) and advances to the information (step 320) of obtaining about client computing device 306 and/or the user that is associated with client computing device 306 from client computing device 306.This information can be provided and/or be retrieved/determined by video server system 304 to video server system 304 by client computing device 306.For example, client computing device 306 can provide information about its current geographic position to video server system 304.In another example, video server system 304 can based on other information that are associated with client computing device 306, such as the IP address of client computing device 306, determine such information for client computing device 306.
Use for the parameter of the template of video (for example is included in, content parameters) and/or the information about client computing device 306 and/or its user of obtaining, video server system 304 can Dynamic Recognition be provided by the content (step 322) that provides with video.
For example, video server system 304 can obtain the information of identifying the geographical position that is associated with the user of client computing device 306 and/or client computing device 306 in step 320.Can identify multiple dynamic content with such geographical location information that obtains.For example, (in step 322) can identify dynamic content with this geographical location information that obtains, it comprises (for the theme of video that dynamic content is provided just therewith) film, concert or performance are at the threshold distance that is positioned at this geographical position (for example, in several Urban Streets, one mile, one kilometer etc.) the showing the time of place (for example, cinema, stadium, club, bar etc.).
In another example, (in the step 322) can identify dynamic content with the geographical location information that obtains, its be included in or the threshold distance in comfortable this geographical position in (for example, in several Urban Streets, one mile, one kilometer etc.) the harbour (for example, airport, railway station, harbour etc.) travelling carry the timetable of instrument route (course line that for example, is ranked, the rail link that is ranked, automobile line of being ranked etc.).Harbour in the threshold distance of the current geographic position of client computing device (and/or its user who is associated) can be that at least one in the geographical position that the instrument route serves carried in travelling.Travelling carry geographical position that the instrument route serves another can be included as another geographical position of at least part of theme of video.
In further example, video server system 304 can obtain the information that is associated with the user's of client computing device 306 social networks profile in step 320.Can identify multiple dynamic content with such social network information that obtains.For example, (in the step 322) can identify the comment that comprises the one or more acquaintances of user on one or more social networks and/or the dynamic content of state information with such social network information.It is relevant with at least one theme that represents in video that the social network information of identifying can be identified as.For example, have with the information that is identified in the theme that represents in the video (for example, the analyses of the label/text that is associated with video, the content of video etc.) similar label (for example, Hash label) and/or the social network information of keyword can be identified as relevant with video.
Video server system 304 can be by providing the request to dynamic content, from the such dynamic content (step 324) of content provider system 308 retrievals to content provider system 308.Can be in response to the request to video that receives in step 318, provide request to dynamic content to content provider system 308.Also (or as an alternative) can before receiving this request, provide the request of dynamic content as the pre-part of caching, dynamic content is buffered and (for example upgrades termly whereby, per minute, hour, day, the renewals such as week, the moon), waiting in expectation receives these requests from client computing device 306.By dynamic content is carried out pre-buffer memory, video server system 304 can be in response to from the request of client computing device 306 and distribute sooner dynamic content.
Content provider system 308 receives request (step 326) to dynamic content, content that retrieval is asked and provides the content of asking (step 328) to video server system 304.Video server system 304 receives content (step 330) from the content provider system.Video server system 304 can generate, and the code (step 332) that provides with dynamic content is provided.For example, video server system 304 can provide the video player on the client computing device 306 is initialized to the code of asking and/or show dynamic content with video.In another example, video server system 304 can generate and will impel client computing device 308 passing after the threshold time amount to video server system 304 and/or to the code of the dynamic content of content provider system 308 request renewals since receiving dynamic content and/or displaying video.For example, such code can impel client computing device 306 dynamic content that request of per a few minutes (for example, 2 minutes, 5 minutes, 10 minutes, 30 minutes etc.) is upgraded during playback video.
With reference to figure 3B, video server system 304 can provide dynamic content and the code (step 334) that generates to client computing device 306.Dynamic content can be provided or can be provided in response to the request from 306 pairs of dynamic contents of client computing device with the video that is associated (for example, can provide video and indication can be used for from video server system 304 retrievals the code of the dynamic content of video to client computing device 306).Client computing device 306 receives dynamic content (step 336) and provide this dynamic content (step 338) in the parameter of dynamic content template specified time and position during playback video.
During playback video, client computing device 306 can be to the renewal (step 340) of video server system 304 request to the dynamic content that receives.Can impel client computing device 306 that such request is provided based on the code that video server system in the step 332 304 generates.Video server system 304 receives to the request (step 342) of the dynamic content that upgrades and as responding and identifies the dynamic content (step 344) that upgrades.Step 344 can be similar to above-mentioned steps 322, just in that the time is performed to retrieve more current/up-to-date content after a while.Be similar to step 324-330, the dynamic content (step 346) that video server system 304 upgrades to 308 requests of content provider system, content provider system 308 receives this request (step 348) and retrieves and provide the content (step 350) of renewal, and it receives (step 352) by video server system 304.Then the dynamic content that upgrades can offer client computing device 306(step 354 by video server system 304) and at client computing device 306 collaborative videos shown (step 356).
Although do not describe among Fig. 3 A-B, yet client computing device 306 can receive dynamic content from content provider system 308 rather than from video server system 304.For example, video server system 304 can provide the information of the suitable content provider of identification system 308 and indication to be supplied to the information of content provider system 308 with the various content parameters of the multidate information that obtains expectation to client computing device 306.
Content provider system 308 can be any one in the plurality of kinds of contents source.For example, content provider system 308 can provide one or more electronics to unite to feed (for example, RSS feeds, blog services, press service etc.).For example, such electronics is fed and can be united microblogging (blog that for example, has character limit for each blog entries) for the user of social networks (for example, TWITTER, FACEBOOK etc.).Can based on the much information of the type that the content that provides is provided, such as label (for example, Hash label) and keyword, unite the identification dynamic content of feeding from electronics in electronics is fed.
In another example, content provider system 308 can provide one or more electronic reference resources, such as electronic encyclopedia (for example, WIKIPEDIA etc.), electronic dictionary (for example, DICTIONARY.COM etc.), the electronics treasure-house (for example, THESAURUS.COM etc.), electronic search engine (for example, BING, YAHOO! SEARCH etc.) or its any combination.Based on the much information of instruction content theme, such as label and keyword, can be from these reference source identification dynamic contents.
In another example, content provider system 308 can provide the TV broadcasting schedule, shows time and duration such as TV.Based on the much information about client computing device (and/or user of client computing device), such as current geographic position, time zone and/or Preferred Language, can such TV broadcasting schedule be identified as dynamic content for client computing device.Such information can (for example be provided by client computing device, client provides geographical location information, Preferred Language etc.) and/or (for example can be pushed off/determine, search the IP address of client computing device and the information that deduction is associated, as language preference).
Fig. 3 C-D has described example technique 360.This technology is as above-mentioned technology 300, but in technology 360, client computing device 306 is retrieved dynamic contents from content provider system 308, rather than receives dynamic contents from video server system 304.In technology 360, video server system 304 generates and impels client computing device 306 from the code of 308 identifications of content provider system and retrieval dynamic content when being explained by client computing device 306.
With reference to figure 3C, technology 360 is take following beginning: author's computing equipment 302 creates dynamic content template (step 362) and the template that is created is offered video server system 304(step 364 as electric video), be similar to reference technique 300 described steps 310 and 312 in the above.Video server system 304 receives the template that creates, and with this template stores that creates for to be associated with this video, so that when distributing this video, can easily identify this template (step 314), be similar to reference technique 300 described steps 314 in the above.
Be similar to step 316-320, client computing device 306 provides request (step 368) to electric video to video server system 304, video server system 304 receives these requests (step 370) from client computing device 306, and video server system 304 obtains the information (step 372) about client computing device 306 and/or the user that is associated with client computing device 306.
In step 374, video server system 304 generates the code to client computing device 306 to be supplied.This code is generated, so that when this code is explained by client computing device 306, it will impel client computing device 306 Dynamic Recognition and retrieval that the content that provides with video is provided.This code is based on the user about client computing device 306(and/or client computing device 306 who obtains) information and/or generate such as the specified dynamic content templates that are used for video of author's computing equipment 302.This code can comprise the much information that helps client computing device 306 identifications and retrieval dynamic content, such as the information of instruction set to be performed and/or identification content provider system 308.
In step 376, video server system 304 offers client computing device 306 with the code that generates.Client computing device 306 receives and explains the code (step 380) that generates.Based on the explanation to the code that generates, client computing device 306 Dynamic Recognition are provided by the content (step 382) that provides with video, are similar to the Dynamic Recognition that refer step 322 is in the above discussed.
With reference to figure 3D, client computing device 306 is to content provider system 308 requests dynamic content (step 384).Be similar to step 326-328, content provider system 308 receives request (step 386) to content from client computing device, and the retrieval content of asking and the content of asking offered client computing device 306(step 390).Client computing device receives this content (step 388) from the content provider system, and is similar to step 338, and this dynamic content (step 390) is provided during playback video.In some embodiments, client computing device 306 can be local and needn't with content provider system 308 mutual situation under, obtain the dynamic content that provides with video be provided.For example, can obtain this dynamic content from file and/or the data that are stored on the client computing device 306.
The dynamic content that the code that generates that video server system 304 offers client computing device 306 can impel client computing device 306 to upgrade in the threshold time amount that passed (for example, since received dynamic content passed threshold time amount, the threshold time amount that passed etc. during playback video) request afterwards in addition.In step 392, client computing device 306 can be asked the renewal to dynamic content during playback video.Be similar to step 348-350, the request (step 394) that content provider system 308 receives the content of upgrading, and retrieve the content of renewal and the content of upgrading is offered client computing device 306(step 396).Be similar to step 356, client computing device 306 receives the dynamic content that upgrades, and the content (step 398) of this renewal is provided during playback video.
Fig. 4 A-F is the screenshotss of the example electric video that just shows with the content of Dynamic Recognition.Described screenshotss have been described can be identified and offer client computing device for the various examples of the dynamic content that shows during the playback electric video.Described screenshotss are from client computing device, such as above-mentioned client computing device 108,208 and 306, angle.
Fig. 4 A shows the screenshotss 400 about the video 402 of the trailer of film Alice in Wonderland (Alice in Wonderland) of playing on the client computing device that is positioned at Zurich, SUI.Dynamic content 404 covers the top of video 402 when video 402 is just played.In these screenshotss, dynamic content 404 comprises that Alice in Wonderland is positioned near the projection time on the horizon of two cinemas the user/client computing device of just checking video 402 in Zurich.
In this example, the author 406 of video 402 may specify the dynamic content for video 402 should comprise that the film Alice in Wonderland is positioned near the projection time of the cinema of viewer's (checking user and/or the client computing device of video 402) geographically.Author 406 may also specify dynamic content 404 to treat the 0:22 mark (indicated such as time counter 408) from video 402 until video finishes to cover the top of video 402.
Fig. 4 B shows the screenshotss 420 about the video 422 in the source of the phrase of just playing in client computing device " young and inexperienced (wet behind the ears) ".Shown the dynamic content 424 that covers the top of video 422.In this example, dynamic content 424 comprises the information about phrase " young and inexperienced " that the user 426 of social networks (indicated for social networks such as icon 428) generates.Based on the relevant information of instruction content and video 422, such as the Hash label 430(#wetbehindtheears that is included in the content) and/or keyword " wet behind the ears " 432, dynamic content 424 can be identified to represent with video 422.Dynamic content 424 may be uploaded generated by user 426 at video 422 and/or the dynamic content that is associated template after other user's distributions.
Can be the user acquaintances's (for example, friend, business association etc.) on social networks that ask/check video 422 based on user 426, identification dynamic content 424 be for representing.Whether the author 434 of video 422 can specify the information that retrieves from social networks 428 should be from viewer's acquaintance.
Fig. 4 C shows the screenshotss 440 about the video 442 of the news report that grounds owing to volcanic ash plume Heathrow Airport flight.Dynamic content 444 covers the top of video 442.Dynamic content 444 comprises the feed related news about the volcano of (indicated such as RSS icon 446) from RSS.
Fig. 4 D shows the screenshotss 450 to the video 452 of the interview of movie director James Ka Meilong.Shown the dynamic content 454 that covers the bottom of video 452.Dynamic content 454 comprises the background information about James Ka Meilong from electronic encyclopedia (indicated such as icon 456).
Fig. 4 E shows the screenshotss 460 about the video 462 on Mauritanian island.Shown the dynamic content 464 that covers the bottom of video 462.Dynamic content 464 comprise from travelling quotation system (indicated such as icon 466) about to the viewer in the current location of the Zurich, SUI information to the quotation of the air ticket price between the Mauritius.
Fig. 4 F shows the screenshotss 470 from other exemplary dynamic contents 472 that can show with video 462 of travelling quotation system.Dynamic content 472 has represented multiple travel dates and price for the air ticket between Zurich and Mauritius.
Represent although dynamic content is depicted in top or the bottom of video in Fig. 4 A-F, yet other positions are possible.For example, can be on video or the Anywhere presenting information row of contiguous video.
Fig. 5 be can be used for being implemented in the system and method described in this document, as client or as the computing equipment 500 of server or a plurality of servers, 550 block diagram.Computing equipment 500 is intended to represent various forms of digital computers, such as Laptop Computer, desktop computer, work station, personal digital assistant, server, blade server, large-scale computer and other suitable computers.Computing equipment 550 is intended to represent various forms of mobile devices, such as personal digital assistant, cell phone, smart mobile phone and other similar computing equipments.In addition, computing equipment 500 or 550 can comprise USB (USB) flash drive.The USB flash memory driver can storage operating system and other application.The USB flash memory driver can comprise the I/O assembly, maybe can be inserted into the USB connector of the USB port of another computing equipment such as transmitting set.The assembly shown in this, its connection and relation with and function to be intended to be exemplary, and and be not intended to and be limited in the execution mode of describing and/or advocating in this document.
Computing equipment 500 comprises processor 502, memory 504, memory device 506, is connected to the high-speed interface 508 of memory 504 and high speed Extended Capabilities Port 510 and is connected to low speed bus 514 and the low-speed interface 512 of memory device 506.In the assembly 502,504,506,508,510 and 512 each is used various bus interconnections, and can be installed in according to circumstances on the public mainboard or otherwise installation.Processor 502 can be processed for the instruction in computing equipment 500 interior execution, comprises being stored in the memory 504 or being used on the memory device 506 in the instruction that shows the graphical information of GUI such as the outside input-output apparatus of the display 516 that is couple to high-speed interface 508.In other embodiments, can use according to circumstances a plurality of processors and/or a plurality of bus and a plurality of memory and type of memory.And, can connect a plurality of computing equipments 500, wherein each equipment provides the essential operation of part (for example, as cluster of server, blade server group or multicomputer system).
Memory 504 is stored in the information in the computing equipment 500.In one embodiment, memory 504 is one or more volatile memory-elements.In another embodiment, memory 504 is one or more Nonvolatile memery units.Memory 504 can also be the computer-readable medium of another kind of form, such as magnetic or CD.
Memory device 506 can provide mass memory for computing equipment 500.In one embodiment, memory device 506 can be or comprise computer-readable medium, such as floppy device, hard disc apparatus, compact disk equipment or carrying device, flash memory or other similar solid-state memory device or equipment array, be included in the equipment in storage area network network or other configurations.Computer program visibly can be included in the information carrier.Computer program can also be included in the instruction of carrying out when being performed such as one or more methods of above-mentioned those methods.Information carrier is computer or machine readable media, such as memory 504, memory device 506 or the memory on processor 502.
High-speed controller 508 is the intensive operations of computing equipment 500 managing bandwidths, and the intensive operation of low speed controller 512 management lower bandwidths.Such distribution of function is exemplary.In one embodiment, high-speed controller 508(is for example by graphic process unit or accelerator) be coupled to memory 504, display 516, and be coupled to the high speed Extended Capabilities Port 510 that can accept various expansion card (not shown).In this embodiment, low speed controller 512 is coupled to memory device 506 and low speed Extended Capabilities Port 514.(for example can comprise various communication port, USB, bluetooth, Ethernet, wireless ethernet) the low speed Extended Capabilities Port can be coupled to one or more input-output apparatus such as keyboard, indicating equipment, scanner, or for example be coupled to networked devices such as switch or repeater by network adapter.
As shown in the drawing, can be with multiple multi-form realization computing equipment 500.For example, computing equipment 500 may be implemented as standard server 520 or is implemented repeatedly in one group of such server.Computing equipment 500 can also be implemented as the part of frame server system 524.In addition, computing equipment 500 can be realized in the personal computer such as laptop computer 522.As an alternative, from the assembly of computing equipment 500 can with combine such as other assemblies in the mobile device (not shown) of equipment 550.In such equipment each can comprise one or more in the computing equipment 500,550, and whole system can be comprised of a plurality of computing equipments 500,550 of mutually intercommunication.
Except other assemblies, computing equipment 550 comprises processor 552, memory 564, the input-output apparatus such as display 554, communication interface 566 and transceiver 568.Equipment 550 can also be provided with memory device, such as mini drive or other equipment, so that extra storage to be provided.In the assembly 550,552,564,554,566 and 568 each is used various bus interconnections, and some assemblies can be installed on the public mainboard according to circumstances or otherwise installation.
As described below, memory can comprise for example flash memory and/or NVRAM memory.In one embodiment, computer program visibly is included in the information carrier.Computer program is included in the instruction of carrying out when being performed such as one or more methods of above-mentioned those methods.Information carrier is computer or machine readable media, such as memory 564, extended menory 574 or the memory on processor 552, wherein can for example receive by transceiver 568 or external interface 562.
As shown in the drawing, can be with multiple multi-form realization computing equipment 550.For example, computing equipment 550 may be implemented as cell phone 580.Computing equipment 550 can also be implemented as the part of smart mobile phone 582, personal digital assistant or other similar mobile devices.
Can be with Fundamental Digital Circuit, integrated circuit, custom-designed ASIC(application-specific integrated circuit (ASIC)), computer hardware, firmware, software and/or its combination realize the various execution modes of system described here and technology.These various execution modes can be included in can carry out on the programmable system and/or explainable one or more computer program in realization, described programmable system comprises at least one programmable processor, it can be special-purpose or general, coupled with from storage system, at least one input equipment and at least one output equipment receive data and instruction, and the transmission of data and instruction are to storage system, at least one input equipment and at least one output equipment.
These computer programs (being also referred to as program, software, software application or code) comprise the machine instruction for programmable processor, and can realize with advanced procedures and/or OO programming language and/or compilation/machine language.As used in this, term " machine readable media ", " computer-readable medium " for any computer program, device and/or equipment that machine instruction and/or data are provided to programmable processor (for example refer to, disk, CD, memory, programmable logic device (PLD)), comprise the machine readable media that receives as the machine instruction of machine-readable signal.Term " machine-readable signal " refers to for any signal that machine instruction and/or data are provided to programmable processor.
For mutual with the user is provided, system described here and technology can realize having following computer: the display device that is used for showing information to the user (for example, the CRT(cathode ray tube) or the LCD(liquid crystal display) monitor), and the user can provide to computer keyboard and the indicating equipment (for example, mouse or tracking ball) of input by it.Mutual with the user also can be provided with the equipment of other types; For example, the feedback that offers the user can be any type of perceptible feedback (for example, visual feedback, audio feedback or tactile feedback); And can comprise the input of acoustics, speech or sense of touch in any form, receive the input from the user.
System described here and technology can realize in comprising following computing system: aft-end assembly (for example, as data server); Or middleware component (for example, application server); Or front end assemblies (for example, have the user by its can with the mutual graphic user interface of the realization of system described here and technology or the client computer of Web browser); Or any combination of such rear end, middleware or front end assemblies.The assembly of system can be by digital data communications (for example, the communication network) interconnection of any form or medium.The example of communication network comprises local area network (LAN) (" LAN "), wide area network (" WAN "), peer-to-peer network (having from group or static member), grid computing infrastructure and internet.
Computing system can comprise client and server.It is mutual that client and server passes through communication network usually away from each other and typically.The relation of client and server relies on the computer program generation that moves on each computer and have each other the client-server relation.
Although describe some execution modes in the above in detail, yet other modifications are possible.In addition, can use for other mechanism that dynamic content is provided with electric video.In addition, particular order or the consecutive order shown in the logic flow of describing does not in the accompanying drawings need, the result who obtains to expect.Can other steps be provided, maybe can remove step from described flow process to described flow process, and other assemblies can be added to described system or remove assembly from described system.Therefore, other execution modes within the scope of the appended claims.
Claims (25)
1. computer implemented method comprises:
Receive request to electric video at the computer server system place from client computing device;
Based on the one or more content parameters that are associated with described video and the type of the dynamic content that is identified is treated in indication after receiving described request at least, come Dynamic Recognition to treat the content that shows when playing described video, described dynamic content is in the content of playing the type that can automatically change along with passage of time between described electric video; And
With certain forms the dynamic content of being identified is offered described client computing device, so that on described client computing device, show described dynamic content according to one or more display parameters, described one or more display parameters at least the described dynamic content of indicated number, the time during the described video of playback or the position relevant with described video;
Wherein said content parameters and described display parameters were specified by the first user that is associated with described video before receiving described request.
2. computer implemented method according to claim 1 further comprises: obtain the information about described client computing device or the second user of being associated with described client computing device;
Wherein said dynamic content is identified based on the information of obtaining in addition.
3. computer implemented method according to claim 2, the geographical position that the information of wherein obtaining identification is associated with described client computing device or described the second user; And
Wherein, based on the information of obtaining, described dynamic content is associated with described geographical position.
4. computer implemented method according to claim 3, wherein said dynamic content comprise indication film, concert or the performance information in the time of showing in the place of the threshold distance that is positioned at described geographical position.
5. computer implemented method according to claim 4, at least part of and described film of wherein said video, described concert or described performance are relevant.
6. computer implemented method according to claim 3, wherein said dynamic content comprise be indicated to or the threshold distance in comfortable described geographical position in the travelling at harbour carry the information of the timetable of instrument route.
7. it is relevant that computer implemented method according to claim 6, at least part of and described travelling of wherein said video carry another geographical position that the instrument route serves.
8. computer implemented method according to claim 2, the information of wherein obtaining is associated with the social networks profile of described the second user on social networks.
9. computer implemented method according to claim 8, wherein said dynamic content comprises the one or more acquaintances of described the second user on described social networks comment or state information.
10. computer implemented method according to claim 9, wherein said comment is relevant with at least one theme that represents in described video with described state information.
11. computer implemented method according to claim 1 further comprises: retrieve described dynamic content by described computer server system from one or more third party's computer server systems.
12. computer implemented method according to claim 11, wherein said dynamic content are retrieved after receiving described request and in response to receiving described request.
13. computer implemented method according to claim 11, wherein said dynamic content was retrieved as the part of pre-caching before receiving described request, and was upgraded termly by described computer server system.
14. computer implemented method according to claim 1 further comprises:
During the described video of playback on the described client computing device, from second request of described client computing device reception to the renewal of described dynamic content;
In response to the second request that receives, come Dynamic Recognition to treat the content of the renewal that when playing described video, shows based on described content parameters; And
With certain forms the dynamic content that is upgraded is offered described client computing device, so that on described client computing device, show the dynamic content that upgrades according to described display parameters.
15. computer implemented method according to claim 14 further comprises:
Generation treats to offer with described dynamic content the code of described client computing device, described code impels described client computing device to provide to described computer server system the threshold time amount that passed after described second of the dynamic content that upgrades is asked when being carried out by described client computing device.
16. being definition, computer implemented method according to claim 1, wherein said content parameters and described display parameters treat the part of the template of the dynamic annotation that when playing described video, is demonstrated.
17. computer implemented method according to claim 1, wherein said dynamic content are configured to cover at least part of of described video at during playback; And
Wherein said display parameters define position and the time that shows described dynamic content with described video at least.
Unite to feed from one or more electronics and be identified 18. computer implemented method according to claim 1, wherein said dynamic content are based on described content parameters specified one or more content tabs.
19. uniting to feed, computer implemented method according to claim 18, wherein said electronics comprise the microblogging that is associated with a plurality of different users.
20. computer implemented method according to claim 1, wherein said dynamic content are based on, and the specified one or more content topics of described content parameters are identified from one or more electronic reference resources.
21. computer implemented method according to claim 20, wherein said electronic reference resources comprise electronic encyclopedia, electronic dictionary, electronics treasure-house, electronic search engine or its combination.
22. a computer implemented method comprises:
Receive request to electric video at the computer server system place from client computing device;
Generating code is to offer described client computing device, described code impels described client computing device Dynamic Recognition to treat the content that shows when being explained by described client computing device when playing described video, wherein said code is generated as and comprises that the one or more content parameters that are associated with described video and indicate at least the type of dynamic content to be identified, described dynamic content are in the content of playing the type that can automatically change along with passage of time between described electric video;
Provide code and the one or more display parameters that generate to described client computing device, wherein said one or more display parameters at least indicated number are treated by the time described dynamic content, during the described video of playback of described client computing device identification or the position relevant with described video;
Wherein said content parameters and described display parameters were specified by the first user that is associated with described video before receiving described request.
23. computer implemented method according to claim 22, the code that wherein generates comprise that the one or more third party's computer server systems of identification contact to obtain the information of described dynamic content for described client computing device.
24. computer implemented method according to claim 22, the code that wherein generates further impel described client computing device to obtain the dynamic content of renewal after the threshold time amount that passed.
25. a system that is used for providing with electric video dynamic content, described system comprises:
One or more computer servers;
The interface that is used for described one or more servers, it is configured to from the request of client computing device reception to electric video;
The dynamic content recognizer component of described one or more servers, it is configured to based on the one or more content parameters that are associated with described video and the type of the dynamic content that is identified is treated in indication after receiving described request at least, come Dynamic Recognition to treat the content that shows when playing described video, described dynamic content is in the content of playing the type that can automatically change along with passage of time between described electric video; And
The dynamic content subsystem of described one or more servers, it is configured to certain forms the dynamic content of being identified be offered described client computing device, so that on described client computing device, show described dynamic content according to one or more display parameters, described one or more display parameters at least the described dynamic content of indicated number, the time during the described video of playback or the position relevant with described video;
Wherein said content parameters and described display parameters were specified by the first user that is associated with described video before receiving described request.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US12/885,950 | 2010-09-20 | ||
US12/885,950 US20120072957A1 (en) | 2010-09-20 | 2010-09-20 | Providing Dynamic Content with an Electronic Video |
PCT/US2011/051001 WO2012039959A2 (en) | 2010-09-20 | 2011-09-09 | Providing dynamic content with an electronic video |
Publications (1)
Publication Number | Publication Date |
---|---|
CN103380627A true CN103380627A (en) | 2013-10-30 |
Family
ID=45818936
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN2011800452662A Pending CN103380627A (en) | 2010-09-20 | 2011-09-09 | Providing dynamic content with an electronic video |
Country Status (5)
Country | Link |
---|---|
US (1) | US20120072957A1 (en) |
EP (1) | EP2619992A4 (en) |
JP (1) | JP2013542641A (en) |
CN (1) | CN103380627A (en) |
WO (1) | WO2012039959A2 (en) |
Cited By (8)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN103647761A (en) * | 2013-11-28 | 2014-03-19 | 小米科技有限责任公司 | Method and device for marking audio record, and terminal, server and system |
CN105306501A (en) * | 2014-06-26 | 2016-02-03 | 国际商业机器公司 | Method and system for performing interactive update on multimedia data |
CN105930059A (en) * | 2016-04-20 | 2016-09-07 | 网易（杭州）网络有限公司 | Display method and apparatus for mobile terminal |
CN106095229A (en) * | 2016-06-02 | 2016-11-09 | 网易（杭州）网络有限公司 | The display packing of a kind of mobile terminal and device |
WO2017020625A1 (en) * | 2015-08-03 | 2017-02-09 | 腾讯科技（深圳）有限公司 | Media content-based interaction method, device and medium |
CN108496368A (en) * | 2015-12-16 | 2018-09-04 | 格雷斯诺特公司 | Dynamic video covers |
CN110574385A (en) * | 2017-06-21 | 2019-12-13 | 谷歌有限责任公司 | Dynamic customized gap transition video for video streaming services |
CN110692251A (en) * | 2017-12-08 | 2020-01-14 | 谷歌有限责任公司 | Modifying digital video content |
Families Citing this family (40)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9448619B1 (en) * | 2011-11-30 | 2016-09-20 | Google Inc. | Video advertisement overlay system and method |
US10218756B2 (en) * | 2012-01-06 | 2019-02-26 | Comcast Cable Communications, Llc | Streamlined delivery of video content |
GB2500653A (en) * | 2012-03-28 | 2013-10-02 | Sony Corp | Broadcast audio video content distribution system with associated metadata defining links to other content |
WO2013152129A1 (en) * | 2012-04-03 | 2013-10-10 | Fourth Wall Studios, Inc. | Transmedia story management systems and methods |
US20170090735A1 (en) * | 2012-07-09 | 2017-03-30 | Jenny Q. Ta | Social network system and method |
US9767087B1 (en) * | 2012-07-31 | 2017-09-19 | Google Inc. | Video annotation system |
US9229632B2 (en) | 2012-10-29 | 2016-01-05 | Facebook, Inc. | Animation sequence associated with image |
US9507757B2 (en) | 2012-11-14 | 2016-11-29 | Facebook, Inc. | Generating multiple versions of a content item for multiple platforms |
US9507483B2 (en) | 2012-11-14 | 2016-11-29 | Facebook, Inc. | Photographs with location or time information |
US9607289B2 (en) | 2012-11-14 | 2017-03-28 | Facebook, Inc. | Content type filter |
US9696898B2 (en) | 2012-11-14 | 2017-07-04 | Facebook, Inc. | Scrolling through a series of content items |
US9684935B2 (en) * | 2012-11-14 | 2017-06-20 | Facebook, Inc. | Content composer for third-party applications |
US9606717B2 (en) | 2012-11-14 | 2017-03-28 | Facebook, Inc. | Content composer |
US9606695B2 (en) | 2012-11-14 | 2017-03-28 | Facebook, Inc. | Event notification |
US9081410B2 (en) | 2012-11-14 | 2015-07-14 | Facebook, Inc. | Loading content on electronic device |
US9218188B2 (en) | 2012-11-14 | 2015-12-22 | Facebook, Inc. | Animation sequence associated with feedback user-interface element |
US9547416B2 (en) | 2012-11-14 | 2017-01-17 | Facebook, Inc. | Image presentation |
US9235321B2 (en) | 2012-11-14 | 2016-01-12 | Facebook, Inc. | Animation sequence associated with content item |
US9245312B2 (en) | 2012-11-14 | 2016-01-26 | Facebook, Inc. | Image panning and zooming effect |
US9547627B2 (en) | 2012-11-14 | 2017-01-17 | Facebook, Inc. | Comment presentation |
US10489501B2 (en) * | 2013-04-11 | 2019-11-26 | Google Llc | Systems and methods for displaying annotated video content by mobile computing devices |
ES2788326T3 (en) * | 2013-08-29 | 2020-10-21 | Saronikos Trading & Services Unipessoal Lda | Receiver of television signals, received by air, cable or internet, equipped with memory means in which said television signals are memorized, in which it is possible to arrange and view the content of said memory means |
CN105556518A (en) | 2013-09-11 | 2016-05-04 | 辛赛股份有限公司 | Dynamic binding of live video content |
CN105579997A (en) | 2013-09-27 | 2016-05-11 | 辛赛股份有限公司 | Substrate for heat sink-equipped power module, and production method for same |
EP3050017A4 (en) | 2013-09-27 | 2017-06-21 | Cinsay, Inc. | Apparatus and method for supporting relationships associated with content provisioning |
US9747263B1 (en) | 2014-06-27 | 2017-08-29 | Google Inc. | Dynamic page classifier for ranking content |
US8954521B1 (en) * | 2014-07-22 | 2015-02-10 | Google Inc. | Management and presentation of notification content |
US10719808B2 (en) * | 2014-10-01 | 2020-07-21 | Maury Hanigan | Video assisted hiring system and method |
US20170094373A1 (en) * | 2015-09-29 | 2017-03-30 | Verance Corporation | Audio/video state detector |
US10638182B2 (en) | 2017-11-09 | 2020-04-28 | Rovi Guides, Inc. | Systems and methods for simulating a sports event on a second device based on a viewer's behavior |
US20190141383A1 (en) * | 2017-11-09 | 2019-05-09 | Rovi Guides, Inc. | Systems and methods for simulating a sports event based on availability of sports statistics |
US10728443B1 (en) | 2019-03-27 | 2020-07-28 | On Time Staffing Inc. | Automatic camera angle switching to create combined audiovisual file |
US10963841B2 (en) | 2019-03-27 | 2021-03-30 | On Time Staffing Inc. | Employment candidate empathy scoring system |
US10957085B2 (en) | 2019-08-15 | 2021-03-23 | International Business Machines Corporation | Methods and systems for adding content to images based on negative space recognition |
US11127232B2 (en) | 2019-11-26 | 2021-09-21 | On Time Staffing Inc. | Multi-camera, multi-sensor panel data extraction system and method |
US11023735B1 (en) | 2020-04-02 | 2021-06-01 | On Time Staffing, Inc. | Automatic versioning of video presentations |
US11144882B1 (en) | 2020-09-18 | 2021-10-12 | On Time Staffing Inc. | Systems and methods for evaluating actions over a computer network and establishing live network connections |
US11727040B2 (en) | 2021-08-06 | 2023-08-15 | On Time Staffing, Inc. | Monitoring third-party forum contributions to improve searching through time-to-live data assignments |
US11423071B1 (en) | 2021-08-31 | 2022-08-23 | On Time Staffing, Inc. | Candidate data ranking method using previously selected candidate data |
US11907652B2 (en) | 2022-06-02 | 2024-02-20 | On Time Staffing, Inc. | User interface and systems for document creation |
Citations (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
WO2001077776A2 (en) * | 2000-04-07 | 2001-10-18 | Visible World, Inc. | System and method for personalized message creation and delivery |
US20020108109A1 (en) * | 2001-02-07 | 2002-08-08 | Harris Doug S. | Method and apparatus for providing interactive media presentation |
CN1722173A (en) * | 2004-07-16 | 2006-01-18 | 索尼株式会社 | Information processing system, information processing apparatus and method, recording medium, and program |
JP2006148830A (en) * | 2004-11-25 | 2006-06-08 | Nec Corp | Information distribution method and apparatus and storage medium |
US20080022300A1 (en) * | 2006-07-10 | 2008-01-24 | Verizon Services Corp. | System and methods for real-time access to movie information |
US20090248672A1 (en) * | 2008-03-26 | 2009-10-01 | Mcintire John P | Method and apparatus for selecting related content for display in conjunction with a media |
JP2010141579A (en) * | 2008-12-11 | 2010-06-24 | Sharp Corp | Display device and display method |
Family Cites Families (13)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
WO2000058897A2 (en) * | 1999-03-30 | 2000-10-05 | Sourcegate Systems, Inc. | Internet point of access content insertion method and informationdistribution system |
US6792615B1 (en) * | 1999-05-19 | 2004-09-14 | New Horizons Telecasting, Inc. | Encapsulated, streaming media automation and distribution system |
US7917924B2 (en) * | 2000-04-07 | 2011-03-29 | Visible World, Inc. | Systems and methods for semantic editorial control and video/audio editing |
AU2001286629A1 (en) * | 2000-08-23 | 2002-03-04 | Imagicast, Inc. | Distributed publishing network |
US20030115598A1 (en) * | 2001-03-23 | 2003-06-19 | Pantoja William E. | System and method for interactively producing a web-based multimedia presentation |
JP2004102475A (en) * | 2002-09-06 | 2004-04-02 | D-Rights Inc | Advertisement information superimposing device |
US20040068758A1 (en) * | 2002-10-02 | 2004-04-08 | Mike Daily | Dynamic video annotation |
US20080126476A1 (en) * | 2004-08-04 | 2008-05-29 | Nicholas Frank C | Method and System for the Creating, Managing, and Delivery of Enhanced Feed Formatted Content |
US8799071B2 (en) * | 2005-11-10 | 2014-08-05 | Qdc Ip Technologies Pty Ltd | Personalized video generation |
US9847845B2 (en) * | 2007-10-09 | 2017-12-19 | Disney Enterprises, Inc. | System and method for providing additional content to a program stream |
US20090193457A1 (en) * | 2008-01-30 | 2009-07-30 | Eric Conn | Systems and methods for providing run-time enhancement of internet video files |
US20110197224A1 (en) * | 2010-02-09 | 2011-08-11 | Echostar Global B.V. | Methods and Apparatus For Selecting Advertisements For Output By A Television Receiver Based on Social Network Profile Data |
US10074094B2 (en) * | 2010-03-09 | 2018-09-11 | Excalibur Ip, Llc | Generating a user profile based on self disclosed public status information |
-
2010
- 2010-09-20 US US12/885,950 patent/US20120072957A1/en not_active Abandoned
-
2011
- 2011-09-09 CN CN2011800452662A patent/CN103380627A/en active Pending
- 2011-09-09 JP JP2013529205A patent/JP2013542641A/en active Pending
- 2011-09-09 EP EP11827213.7A patent/EP2619992A4/en not_active Withdrawn
- 2011-09-09 WO PCT/US2011/051001 patent/WO2012039959A2/en active Application Filing
Patent Citations (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
WO2001077776A2 (en) * | 2000-04-07 | 2001-10-18 | Visible World, Inc. | System and method for personalized message creation and delivery |
US20020108109A1 (en) * | 2001-02-07 | 2002-08-08 | Harris Doug S. | Method and apparatus for providing interactive media presentation |
CN1722173A (en) * | 2004-07-16 | 2006-01-18 | 索尼株式会社 | Information processing system, information processing apparatus and method, recording medium, and program |
JP2006148830A (en) * | 2004-11-25 | 2006-06-08 | Nec Corp | Information distribution method and apparatus and storage medium |
US20080022300A1 (en) * | 2006-07-10 | 2008-01-24 | Verizon Services Corp. | System and methods for real-time access to movie information |
US20090248672A1 (en) * | 2008-03-26 | 2009-10-01 | Mcintire John P | Method and apparatus for selecting related content for display in conjunction with a media |
JP2010141579A (en) * | 2008-12-11 | 2010-06-24 | Sharp Corp | Display device and display method |
Cited By (11)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN103647761A (en) * | 2013-11-28 | 2014-03-19 | 小米科技有限责任公司 | Method and device for marking audio record, and terminal, server and system |
CN105306501A (en) * | 2014-06-26 | 2016-02-03 | 国际商业机器公司 | Method and system for performing interactive update on multimedia data |
US10938918B2 (en) | 2014-06-26 | 2021-03-02 | International Business Machines Corporation | Interactively updating multimedia data |
WO2017020625A1 (en) * | 2015-08-03 | 2017-02-09 | 腾讯科技（深圳）有限公司 | Media content-based interaction method, device and medium |
CN108496368A (en) * | 2015-12-16 | 2018-09-04 | 格雷斯诺特公司 | Dynamic video covers |
CN105930059A (en) * | 2016-04-20 | 2016-09-07 | 网易（杭州）网络有限公司 | Display method and apparatus for mobile terminal |
CN106095229A (en) * | 2016-06-02 | 2016-11-09 | 网易（杭州）网络有限公司 | The display packing of a kind of mobile terminal and device |
CN106095229B (en) * | 2016-06-02 | 2020-06-09 | 网易（杭州）网络有限公司 | Display method and device of mobile terminal |
CN110574385A (en) * | 2017-06-21 | 2019-12-13 | 谷歌有限责任公司 | Dynamic customized gap transition video for video streaming services |
CN110574385B (en) * | 2017-06-21 | 2022-06-03 | 谷歌有限责任公司 | Method, system, and storage medium for improving video transitions |
CN110692251A (en) * | 2017-12-08 | 2020-01-14 | 谷歌有限责任公司 | Modifying digital video content |
Also Published As
Publication number | Publication date |
---|---|
WO2012039959A2 (en) | 2012-03-29 |
EP2619992A2 (en) | 2013-07-31 |
EP2619992A4 (en) | 2014-02-19 |
JP2013542641A (en) | 2013-11-21 |
WO2012039959A3 (en) | 2012-06-14 |
US20120072957A1 (en) | 2012-03-22 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN103380627A (en) | Providing dynamic content with an electronic video | |
US8856170B2 (en) | Bandscanner, multi-media management, streaming, and electronic commerce techniques implemented over a computer network | |
US9560400B2 (en) | Consuming paid media of a content platform | |
US7904505B2 (en) | Service to push author-spoken audio content with targeted audio advertising to users | |
US8862616B2 (en) | Multi-media management and streaming techniques implemented over a computer network | |
US7937380B2 (en) | System and method for recommended events | |
US9032396B2 (en) | Server apparatus, terminal apparatus, and application control system | |
US10079872B1 (en) | Subscription levels in an internet-based content platform | |
US9015759B2 (en) | Interactive map and related content for an entertainment program | |
US20070088817A1 (en) | Shared video service | |
US20150317057A1 (en) | Navigation apparatus for providing social network service (sns) service based on augmented reality, metadata processor, and metadata processing method in augmented reality navigation system | |
US20090254633A1 (en) | Methods, systems, and computer program products for distributing profile-based advertisement content and user identification-tagged media content | |
TW200845639A (en) | Tagging media assets, locations, and advertisements | |
US20150188960A1 (en) | System and method for online media content sharing | |
CN102549557A (en) | Singular, collective and automated creation of a media guide for online content | |
US20140337139A1 (en) | Channel-level advertising attributes in an internet-based content platform | |
US9509798B1 (en) | Subscriptions to paid channels of an internet-based content platform | |
US20160085515A1 (en) | Entity-Based External Functionality for Software Developers | |
KR20190093811A (en) | Method And System For Providing Traveler-Generated Contents As Recommended Travel Information | |
KR20110047768A (en) | Apparatus and method for displaying multimedia contents | |
US8863295B1 (en) | Linking video sharing accounts with content delivery accounts | |
KR20120139233A (en) | Data management system and method for displaying data thereof | |
KR101027155B1 (en) | Method for providing additional information in moving picture information by section | |
US9628415B2 (en) | Destination-configured topic information updates | |
US9288280B1 (en) | Viral flow of the media content across client devices |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
C06 | Publication | ||
PB01 | Publication | ||
C10 | Entry into substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
RJ01 | Rejection of invention patent application after publication |
Application publication date: 20131030 |
|
RJ01 | Rejection of invention patent application after publication |