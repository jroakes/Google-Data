US20230336879A1 - Lookup table processing and programming for camera image signal processing - Google Patents
Lookup table processing and programming for camera image signal processing Download PDFInfo
- Publication number
- US20230336879A1 US20230336879A1 US18/022,718 US202018022718A US2023336879A1 US 20230336879 A1 US20230336879 A1 US 20230336879A1 US 202018022718 A US202018022718 A US 202018022718A US 2023336879 A1 US2023336879 A1 US 2023336879A1
- Authority
- US
- United States
- Prior art keywords
- lut
- interpolation
- interpolated
- camera
- isp
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N5/00—Details of television systems
- H04N5/222—Studio circuitry; Studio devices; Studio equipment
- H04N5/262—Studio circuits, e.g. for mixing, switching-over, change of character of image, other special effects ; Cameras specially adapted for the electronic generation of special effects
- H04N5/2621—Cameras specially adapted for the electronic generation of special effects during image pickup, e.g. digital cameras, camcorders, video cameras having integrated special effects capability
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N23/00—Cameras or camera modules comprising electronic image sensors; Control thereof
- H04N23/80—Camera processing pipelines; Components thereof
- H04N23/84—Camera processing pipelines; Components thereof for processing colour signals
- H04N23/85—Camera processing pipelines; Components thereof for processing colour signals for matrixing
-
- G—PHYSICS
- G09—EDUCATION; CRYPTOGRAPHY; DISPLAY; ADVERTISING; SEALS
- G09G—ARRANGEMENTS OR CIRCUITS FOR CONTROL OF INDICATING DEVICES USING STATIC MEANS TO PRESENT VARIABLE INFORMATION
- G09G5/00—Control arrangements or circuits for visual indicators common to cathode-ray tube indicators and other visual indicators
- G09G5/02—Control arrangements or circuits for visual indicators common to cathode-ray tube indicators and other visual indicators characterised by the way in which colour is displayed
- G09G5/04—Control arrangements or circuits for visual indicators common to cathode-ray tube indicators and other visual indicators characterised by the way in which colour is displayed using circuits for interfacing with colour displays
-
- G—PHYSICS
- G09—EDUCATION; CRYPTOGRAPHY; DISPLAY; ADVERTISING; SEALS
- G09G—ARRANGEMENTS OR CIRCUITS FOR CONTROL OF INDICATING DEVICES USING STATIC MEANS TO PRESENT VARIABLE INFORMATION
- G09G5/00—Control arrangements or circuits for visual indicators common to cathode-ray tube indicators and other visual indicators
- G09G5/02—Control arrangements or circuits for visual indicators common to cathode-ray tube indicators and other visual indicators characterised by the way in which colour is displayed
- G09G5/06—Control arrangements or circuits for visual indicators common to cathode-ray tube indicators and other visual indicators characterised by the way in which colour is displayed using colour palettes, e.g. look-up tables
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N23/00—Cameras or camera modules comprising electronic image sensors; Control thereof
- H04N23/60—Control of cameras or camera modules
- H04N23/617—Upgrading or updating of programs or applications for camera control
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N23/00—Cameras or camera modules comprising electronic image sensors; Control thereof
- H04N23/60—Control of cameras or camera modules
- H04N23/65—Control of camera operation in relation to power supply
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N23/00—Cameras or camera modules comprising electronic image sensors; Control thereof
- H04N23/80—Camera processing pipelines; Components thereof
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N23/00—Cameras or camera modules comprising electronic image sensors; Control thereof
- H04N23/80—Camera processing pipelines; Components thereof
- H04N23/84—Camera processing pipelines; Components thereof for processing colour signals
- H04N23/843—Demosaicing, e.g. interpolating colour pixel values
-
- G—PHYSICS
- G09—EDUCATION; CRYPTOGRAPHY; DISPLAY; ADVERTISING; SEALS
- G09G—ARRANGEMENTS OR CIRCUITS FOR CONTROL OF INDICATING DEVICES USING STATIC MEANS TO PRESENT VARIABLE INFORMATION
- G09G2320/00—Control of display operating conditions
- G09G2320/06—Adjustment of display parameters
- G09G2320/0673—Adjustment of display parameters for control of gamma adjustment, e.g. selecting another gamma curve
-
- G—PHYSICS
- G09—EDUCATION; CRYPTOGRAPHY; DISPLAY; ADVERTISING; SEALS
- G09G—ARRANGEMENTS OR CIRCUITS FOR CONTROL OF INDICATING DEVICES USING STATIC MEANS TO PRESENT VARIABLE INFORMATION
- G09G2320/00—Control of display operating conditions
- G09G2320/06—Adjustment of display parameters
- G09G2320/0693—Calibration of display systems
-
- G—PHYSICS
- G09—EDUCATION; CRYPTOGRAPHY; DISPLAY; ADVERTISING; SEALS
- G09G—ARRANGEMENTS OR CIRCUITS FOR CONTROL OF INDICATING DEVICES USING STATIC MEANS TO PRESENT VARIABLE INFORMATION
- G09G2340/00—Aspects of display data processing
- G09G2340/14—Solving problems related to the presentation of information to be displayed
Definitions
- This document relates, generally, to processing of images captured by a camera. More specifically, this document relates to approaches for interpolating and processing lookup tables, and programming configuration information for image processing in an image signal processor (ISP) of a camera, such as a camera included in a mobile electronic device.
- ISP image signal processor
- Camera technology continues to advance.
- Cameras e.g., digital cameras
- mobile electronic devices smart phones, tablet computers, etc.
- recreation devices such as action cameras, as well as many other applications, such as automotive systems, security systems, and so forth.
- an image signal processor ISP
- LUTs look up tables
- process e.g., adjust, tune, etc.
- images image frames, etc.
- an image sensor of the camera such as by a CMOS sensor or a charge-coupled sensor, for example.
- Such LUTs can be stored in configuration registers (configuration memory) of the ISP and can each include a finite number of configuration values used by an ISP for processing captured image frames.
- configuration information can be related to, or correspond with, different aspects of captured image frames. These attributes can include lighting, exposure time, cumulative color temperature, chrominance, luminance, contrast, gamma, etc. of captured image frames.
- Such LUTs are typically large data structures, and the attributes they correspond with can be expressed as quantitative values, which may be referred to as image factors.
- image factors are continuous values, generating respective predetermined LUTs for possible values of each of a plurality of image factors is not practical due, at least, to an amount of memory that would be required to store those predetermined LUTs. Therefore, interpolation (e.g., bilinear interpolation, trilinear interpolation, etc.) and other processing can be performed using predetermined lookup tables that are tuned for achieving high quality captured image frames at key (index, etc.) values of various image factors to produce interpolated lookup tables (including interpolated LUT values).
- interpolation e.g., bilinear interpolation, trilinear interpolation, etc.
- LUT interpolation and processing is done on a per-frame basis. Therefore, for cameras that capture image frames (e.g., video) at 60 frames per second (FPS), an associated SW driver must perform interpolation and other processing of the LUTs used by an associated ISP run 60 times per second.
- Using current approaches limits (or negatively impacts) image processing performance of a camera, and can also adversely impact power consumption of a corresponding general purpose processor (main processor, central processor, etc.) of an electronic devices including a digital camera.
- a camera can include a dynamic memory, and a software driver configured to store, in the dynamic memory, a plurality of predetermined lookup tables (LUTs), a first LUT of the predetermined LUTs including first image signal processor (ISP) configuration information corresponding with a first value of a quantitative image factor, and a second LUT of the predetermined LUTs including second ISP configuration information corresponding with a second value of the quantitative image factor.
- the second value can be greater than the first value.
- the software driver can be further configured to issue an interpolation command indicating (including, specifying, etc.) a third value of the quantitative image factor corresponding with an image frame received by the ISP.
- the third value can be greater than the first value and less than the second value.
- the camera can also include a LUT processing circuit configured to receive the interpolation command, and in response to receiving the interpolation command: read the first LUT and the second LUT; and perform at least one interpolation operation to generate an interpolated LUT, the interpolated LUT can be generated based, at least, on the third value, the first LUT and the second LUT.
- the camera can further include an image signal processor (ISP) including a configuration register.
- ISP image signal processor
- the LUT processing circuit can be further configured to write the interpolated LUT to the configuration register.
- the proposed solution thus, in particular, relates to a camera which can include an image sensor configured to capture image frames; a dynamic memory; an image signal processor, ISP, including a configuration register and a software driver.
- the software driver may be configured to store, in the dynamic memory, a plurality of predetermined lookup tables, LUTs, for processing image frames depending on aspects of a captured image frame and/or on a use case.
- a first LUT of the predetermined LUTs may include first ISP configuration information corresponding with a first value of a quantitative image factor
- a second LUT of the predetermined LUTs may include second ISP configuration information corresponding with a second value of the quantitative image factor, the second value being greater than the first value.
- the software drive may be further configured to issue an interpolation command including a third value of the quantitative image factor corresponding with an image frame received by the ISP, the third value being greater than the first value and less than the second value.
- a LUT processing circuit of the camera may be configured to receive the interpolation command, and in response to receiving the interpolation command may read the first LUT and the second LUT; and perform at least one interpolation operation to generate an interpolated LUT, the interpolated LUT being generated based, at least, on the third value, the first LUT and the second LUT.
- the LUT processing circuit may then be further configured to write the interpolated LUT to the configuration register of the ISP.
- the predetermined LUTs can be associated with specific values (key configuration values) of the qualitative image factors relating to captured and/or computed image data for an image frame, such as sensor gain, exposure time, cumulative color temperature (CCT), white balance, luminance, etc.
- specific factors used can depend, at least, on the particular camera implementation.
- the predetermined LUTs can include configuration information for an image processing stack (e.g., of the ISP) based on, or corresponding with conditions of a scene depicted in a captured image frame and/or based on predetermined use cases, where different conditions and different use cases correspond to different ISP configuration information, such as different key configuration values of the LUTs, each LUT being associated with specific ISP configuration information so that an LUT is selectable (e.g., for use in an interpolation operation) depending on a condition of a scene and/or a use case.
- an image processing stack e.g., of the ISP
- a method can include storing, in memory of a computing device, a plurality of predetermined lookup tables (LUTs), a first LUT of the predetermined LUTs including first image signal processor (ISP) configuration information corresponding with a first value of a quantitative image factor, and a second LUT of the predetermined LUTs including second ISP configuration information corresponding with a second value of the quantitative image factor.
- the second value can be greater than the first value.
- the method can further include receiving, at a LUT processing circuit, an interpolation command indicating (including, specifying, etc.) a third value of the quantitative image factor corresponding with an image frame received by the ISP.
- the third value can be greater than the first value and less than the second value.
- the method can still further include, in response to receiving the interpolation command: reading, by the LUT processing circuit, the first LUT and the second LUT; performing an interpolation operation using the third value, the first LUT and the second LUT to generate an interpolated LUT; and writing the interpolated LUT to at least one of the memory or a configuration register of the ISP.
- FIG. 1 is a block diagram illustrating a camera that can be included, for example, in a mobile computing device, such as a smartphone.
- FIG. 2 is a block/state diagram illustrating operation of camera, including hardware lookup table (LUT) processing.
- LUT hardware lookup table
- FIGS. 3 A and 3 B are diagrams illustrating an example process of LUT interpolation that can be implemented by an LUT processing circuit.
- FIG. 4 is a block diagram illustrating an implementation of a camera including an LUT processing circuit.
- FIG. 5 is a block diagram illustrating another implementation of a camera including an LUT processing circuit.
- FIG. 6 is a diagram of a compute kernel that can be executed by, for example, the camera of FIG. 5 .
- FIG. 7 is a flowchart illustrating a method for image processing that can be implemented, for example, by the cameras of FIGS. 1 , 4 and 5 .
- FIG. 8 shows an example of a computer device and a mobile computer device that can be used to implement the techniques described here.
- LUT lookup table
- LUT engines LUT hardware engines
- interpolation operations e.g., bilinear interpolation operations, trilinear interpolation operations, etc.
- operations to perform packing transformation, translation, etc.
- ISP image signal processor
- Such approaches can achieve a significant reduction in an amount of general purpose processor cycles (e.g., of a mobile electronic device including a camera implementation such as those described herein) used in image processing (by a camera software (SW) driver). Further, these approaches can reduce power consumption by the associated general purpose processor (and overall power consumption of an electronic device implementing such approaches) by performing computationally intensive operations (e.g., interpolation operations) using a special purpose LUT processing circuit or LUT engine, such as the example implementations described herein.
- general purpose processor cycles e.g., of a mobile electronic device including a camera implementation such as those described herein
- SW camera software
- executing arithmetic operations on a general-purpose CPU can consume more power than the same operations performed on fixed-function hardware (e.g., an LUT processing circuit) specifically designed to perform (execute, etc.) such operations.
- fixed-function hardware e.g., an LUT processing circuit
- general-purpose CPUs can consume more power because they utilize a complex, generic execution pipeline for instruction fetch-decode-execute sequences. Therefore, an LUT interpolation process (operation, etc.), when performed using a general purpose CPU, will be performed as a series of general CPU instructions that are processed this execution pipeline.
- specialized hardware may not include a complex pipeline and, instead, can be configured to perform a set of fixed-functions in hardware that does not require complex programming and, therefore, can be implemented using less complicated circuitry than a general purpose CPU.
- Such less complicated circuit can include significantly less hardware gates than are used in general purpose CPU, which, as a result, uses less power (e.g., less power per operation.)
- the implementations described herein can also significantly improve image signal processing performance, allowing for improvements in image quality (e.g., as a result of possible additional image processing), increases in frame rates for captured image frames, and so forth.
- FIG. 1 is a block diagram illustrating a camera 100 (e.g., a digital camera) that can be included, for example, in a mobile computing device, such as the smartphone 882 shown in FIG. 8 below.
- the camera 100 can, of course, be implemented in other electronic devices, such as tablet computers, notebook computers, laptop computers, action cameras, body cameras, etc.
- the elements of the camera 100 are given by way of example and for purposes of illustration. It will be appreciated that, a camera implementing the approaches described herein can, include other elements, can have elements replaced with different elements, can have multiple elements combined into a single integrated element, can have elements omitted, and so forth.
- the camera 100 includes a general purpose processor 110 (e.g., a general purpose CPU), a memory 120 , such as dynamic random access memory (DRAM), a LUT processing circuit 130 , an ISP 140 , and an image sensor 150 (e.g., a CMOS sensor, a charge-coupled device (CCD) sensor, etc.).
- a general purpose processor 110 e.g., a general purpose CPU
- a memory 120 such as dynamic random access memory (DRAM)
- DRAM dynamic random access memory
- LUT processing circuit 130 e.g., a LUT processing circuit 130
- ISP 140 e.g., a CMOS sensor, a charge-coupled device (CCD) sensor, etc.
- image sensor 150 e.g., a CMOS sensor, a charge-coupled device (CCD) sensor, etc.
- communication paths are shown between various elements of the camera 100 . These communication paths are illustrative and, in some implementations, other communication paths or operational relationships can
- the camera 100 of FIG. 1 includes a camera SW driver 112 running on the general purpose processor 110 .
- the camera SW driver 112 can be configured, e.g., as part of an initialization process, to store, in the memory 120 , a plurality of predetermined lookup tables (LUTs) as part of the LUTs 122 .
- the camera SW driver 112 can be configured to store lookup tables that have been previously generated (e.g., by image quality engineers) and that include ISP configuration information for various aspects of image capturing and processing by the ISP 140 and/or the image sensor 150 .
- these predetermined LUTs can be associated with specific values (key configuration values) of qualitative image factors relating to captured and/or computed image data for an image frame, such as sensor gain, exposure time, cumulative color temperature (CCT), white balance, luminance, etc.
- the specific factors used will depend, at least, on the particular camera implementation.
- the LUTs 122 can also include intermediate interpolated LUTs, which are written by the LUT processing circuit 130 and used in interpolations where more than one factor (and multiple interpolation operations) is (are) used to generate an interpolated LUT (e.g., ISP configuration data) that is written to the configuration registers 142 for use by the ISP 140 .
- such LUTs predetermined LUTs and/or interpolated LUTs
- Such predetermined LUTs can include configuration information for the image processing stack (e.g., of the ISP 140 ) that can correspond with specific conditions of a scene depicted in a captured image frame and/or with specific use cases, where different conditions and different use cases correspond to different key configuration values of the LUTs, each LUT being associated with a specific key configuration value so that an LUT is selectable (e.g., for use in an interpolation operation) depending on a condition of a scene and/or a use case.
- the predetermined LUTs can include configuration information for the image processing stack (e.g., of the ISP 140 ) based on various (e.g., potential) scene conditions and/or use cases (e.g.
- such interpolation operations can be performed by the LUT processing circuit 130 (the LUT processing circuit 430 , or the LUT engine 530 ), e.g., using one or more special purpose LUT arithmetic and logic units (ALUs), such as are further described below.
- ALUs special purpose LUT arithmetic and logic units
- the memory 120 can also include a command buffer 124 , which can receive LUT processing commands (e.g., interpolation commands, bitwise operation commands, shift commands, etc.) from the camera SW driver 112 .
- LUT processing commands e.g., interpolation commands, bitwise operation commands, shift commands, etc.
- the LUT processing circuit 130 can then read commands for execution from the command buffer 124 and perform associated LUT operations (e.g., using special purpose LUT ALUs included in the LUT processing circuit 130 ).
- the ISP 140 of the camera 100 includes configuration registers 142 , which can be used to store LUTs (e.g., interpolated LUTs) that include configuration information (e.g., corresponding with qualitative images factors that were determined based on a previously captured image frame) to capture and process a next image frame.
- LUTs e.g., interpolated LUTs
- configuration information e.g., corresponding with qualitative images factors that were determined based on a previously captured image frame
- the LUTs stored in the configuration registers 142 can be updated after each image frame is captured. That is, LUT processing, such as described herein, can be performed for every frame in a sequence of captured image frames and configuration information in the configuration registers 142 for the ISP 140 can be updated after each image frame capture.
- interpolation for all configuration LUTs can be performed 60 times per second (after each image frame is captured) and the configuration registers 142 can be updated with the newly interpolated LUTs.
- LUTs used in image processing can each include hundreds of values, or more, and multiple LUTs can be used for processing each image (e.g., at a frame capture rate).
- interpolation of that one LUT would involve 60,000 interpolation calculations per second (e.g., 60 ⁇ 1000, for an image frame capture rate of 60 fps).
- the number of calculations can be further multiplied in implementations where LUT interpolation is cascaded. For instance, if tri-linear interpolation is performed, seven interpolation operations can be performed to produce a final interpolated LUT (e.g., with each interpolation operation including sixty-thousand calculations using the above example).
- FIG. 2 is a block/state flow diagram 200 illustrating operation of a camera that includes hardware lookup table (LUT) processing, such as described herein.
- the state flow diagram 200 can be implemented by the cameras disclosed herein (e.g., the cameras 100 , 400 and 500 ). However, for purposes of discussion of FIG. 2 , the state flow diagram 200 will be described generally, without specific reference to any particular camera implementation.
- the state flow diagram 200 which implements a feedback loop, can include an ISP state 210 that operates based on configuration information (e.g., LUTs) stored in configuration registers 212 .
- configuration information e.g., LUTs
- an image frame e.g., pixel data for the image frame
- statistics on the captured image frame can be determined, which can then be communicated as image and statistics 220 for processing and analysis at state 230 .
- auto-tuning algorithms e.g., auto-focus, auto-exposure and auto-white-balance
- 3 A algorithms 232 can be performed on the image and statistics 220 (e.g., by a camera SW driver).
- the 3 A algorithms 232 can be configured to calculate qualitative image factors (for each captured image frame), such as the image factors described herein.
- the calculated image factors can then be used, as part of LUT hardware processing 234 , to generate (and in some implementations, pack or transform) LUTs that adjust the configuration information included in the configuration registers 212 based a current scene (as represented by the image and statistics 220 ).
- This updated (adjusted) configuration information can be included in register updates 236 .
- the register updates 236 can then be communicated to the configuration registers 212 via a feedback path 240 , and the process of the state flow diagram 200 can be repeated for a new (next) captured image frame.
- the LUT hardware processing 234 can include performing LUT interpolation operations on various LUTs (e.g., predetermined LUTs and/or intermediate interpolated LUTs).
- LUTs e.g., predetermined LUTs and/or intermediate interpolated LUTs.
- each LUT that is used at the ISP state 210 e.g., that is stored in the configuration registers 212
- the LUT hardware processing 234 can include performing packing operations on one or more LUTs (e.g., interpolated LUTs).
- LUTs e.g., interpolated LUTs
- camera ISP hardware can require LUTs including configuration information to be in a specific format and/or arrangement.
- specific ISP hardware can expect different bit widths LUT entries, or that more than one LUT be packed (merged) into a single (combined) LUT.
- each LUT entry of such a packed or merged LUT could include different values from the LUTs that are packed (merged) together.
- Packing operations on LUTs can be performed using arithmetic operations, bitwise (logical) operations, and/or shift operation. Accordingly, special purpose LUT ALUs that are used for performing interpolation operations can also be configured to perform LUT packing operations.
- FIGS. 3 A and 3 B are diagrams, 300 and 350 respectively, that illustrate an example process of LUT interpolation that can be implemented by an LUT processing circuit.
- the LUT interpolation process shown in FIGS. 3 A and 3 B illustrates LUT interpolation for a single value of one qualitative image factor X (e.g., an interpolation factor X 301 ), which can be a value of a qualitative image factor, such as those factors described herein.
- X e.g., an interpolation factor X 301
- FIGS. 3 A and 3 B can be implemented to perform a second interpolation operation based on a second qualitative image factor to produce a final interpolated LUT that is used as configuration information for an ISP.
- Such multifactor LUT interpolations can be performed in a number of manners, such as using a hierarchical flow to generate intermediate LUTs from predetermined LUTs, and then using intermediate LUTs and/or other predetermined LUTs to generate a final interpolated LUT that is written to configuration registers of an associated ISP.
- values of qualitative image factors e.g., key values and interpolation factors
- FIGS. 3 A and 3 B illustrate an LUT interpolation process using a value of an image factor X (e.g., the interpolation factor X 301 ).
- the interpolation factor X 301 can be used, depending on the computed value of the interpolation factor X 301 , as a ratio for interpolating (e.g., bilinear interpolation) between configuration information included in predetermined LUTs 320 , 322 , 324 and 326 .
- the predetermined LUTs 320 , 322 , 324 and 326 are respectively associated with key values of A, B, C and D of the factor X, as is shown in FIG. 3 A .
- FIG. 3 A As is also shown in FIG.
- the key values A, B, C and D define interpolation factor ranges 310 illustrated by the horizontal, doubled-ended arrows in FIG. 3 A .
- a first interpolation factor range is between A and B
- a second interpolation factor range is between B and C
- a third interpolation factor range is between C and D.
- a ⁇ B ⁇ C ⁇ D and X is between B and C. That is B ⁇ X ⁇ C.
- interpolation between the predetermined LUT 322 associated with the key value B and the predetermined LUT 324 associated with the key value C is performed using the interpolation factor X 301 .
- the interpolation factor X 301 can being used as a ratio for performing (bilinear) hardware interpolation 360 on the predetermined LUTs 322 and 324 to produce an interpolated LUT 370 (which can be an intermediate interpolated LUT or a final interpolated LUT that is used to update ISP configuration registers.
- such bilinear interpolation can be performed by special purpose LUT ALUs that can be configured to perform bilinear interpolation computations, such as discussed below with respect to, at least, FIG. 4 .
- FIG. 4 is a block diagram illustrating an implementation of a camera 400 including an LUT processing circuit 430 (LUT processing hardware).
- the camera 400 includes a camera SW driver 412 (e.g., running on a general purpose processor), memory 420 (DRAM) and camera/ISP hardware 440 .
- the camera SW driver 412 can be configured to write a plurality of predetermined LUTs, such as the LUTs 322 and 324 of the example of FIGS. 3 A and 3 B , e.g., as part of an initialization process of the camera 400 .
- the camera SW driver 412 can also be configured to issue an interpolation command (Interp_command) or other LUT processing commands, which can be directly communicated to the LUT processing circuit 430 or, as discussed herein, could be placed in a command buffer in the memory 420 , and then read from the command buffer by the LUT processing circuit 430 prior to execution.
- Interpolation command issued by the camera SW driver 412 for performing such an interpolation operation could take the form of:
- the LUT processing circuit 430 can be configured to read the LUT 322 and the LUT 324 from the memory 420 , e.g., using a programming direct memory access (DMA) controller (programming DMA 434 ).
- DMA programming direct memory access
- the LUT processing circuit 430 can be implemented in a programming DMA (the programming DMA 434 ), or a limited programming DMA can be implemented as part of the LUT processing circuit 430 .
- a programming DMA can be excluded, and the LUT processing circuit 430 can include a read DMA and a write DMA for, respectively accessing (reading) LUTs and writing LUTs.
- the programming DMA 434 can be a specialized DMA that can read and execute register programming commands that are stored in memory.
- a register command can be a register write, poll, etc. command (e.g. write_register(register_address, value)), which can direct the DMA to perform an operation on the register space of the ISP hardware (e.g., writing/polling of ISP hardware registers without direct intervention of a main CPU).
- one supported command of the programming DMA 434 can be to accept an address of an LUT the memory 420 (e.g., an address of the LUT 370 ) that is to be written to a hardware LUT (e.g., an ISP configuration LUT 442 ) and coordinate writing of the LUT, taking into account any dependencies (e.g., waiting from the LUT to be generate before initiating writing the LUT).
- an LUT the memory 420 e.g., an address of the LUT 370
- a hardware LUT e.g., an ISP configuration LUT 442
- one or more special purpose LUT ALUs 432 can be implemented in the LUT processing circuit 430 .
- the LUT ALUs 432 can perform interpolation operations (computations, operations, etc.) consistent with the interpolation command issued by the camera SW driver 412 to generate an interpolated LUT. These operations, depending the number of LUT ALUs 432 , can be performed sequentially and/or in parallel.
- each entry of the interpolated LUT can be computed from corresponding entries in the LUTs 322 and 324 , and the interpolation factor X 301 using the following equation:
- LUT_out_val represents values of the interpolated LUT being generated
- LUT1_val represents corresponding values in the LUT 322
- x represents the interpolation factor X 301
- LUT2_val represents corresponding values in the LUT 324 .
- the values of the qualitative image factor key values corresponding with the LUTs, and the interpolation factor X
- specific values e.g., ISP configuration values
- additional interpolation commands, or other LUT processing commands can be received by the LUT processing circuit 430 (e.g., directly from the camera SW driver 412 or read from a command buffer in the memory 420 ).
- the final interpolated LUT can be written as a configuration LUT to the LUT storage are 442 of the camera/ISP hardware 440 .
- multiple interpolation commands for generating an interpolated LUT using multiple interpolation operations and interpolation factors can be expressed as a chained command.
- a command for generating an interpolated LUT based on multiple image factor (interpolation) values e.g., one interpolation operation based on sensor gain (e.g., taking sensor gain into account) and another interpolation operation based on luminance (e.g., taking luminance into account) can be issued by the camera SW driver 412 as a chained command in the form of:
- lut1 and lut2 are interpolated using the interpolation factor x to generate an intermediate interpolated LUT lut3_out.
- the LUT processing circuit 430 can, in accordance with the above chained command, interpolate between lut3_out and lut4 using the interpolation factor y to generate the final interpolated LUT lut_out, and then lut_out can be written to lut_register_addr (e.g., in the LUT registers 442 of the camera 400 ).
- Using such command chaining can allow for the camera SW driver 412 to express all requested interpolation operations for a captured image frame as a sequence of interpolation commands that can be interwoven with other register programming commands expressed by the camera SW driver 412 .
- dependencies between the LUT commands (e.g., interpolation and packing commands) and ISP configuration register write commands can be enforced by the LUT processing circuit 430 , e.g., such as by using a wait for interrupt request feature (e.g., wait for irq) of the programming DMA 434 .
- FIG. 5 is a block diagram illustrating another implementation of a camera 500 including an LUT processing circuit (LUT engine 530 ).
- the camera 500 includes a camera SW driver 512 (e.g., running on a general purpose processor), memory 520 (DRAM) and camera/ISP hardware 540 (including configuration LUTs 542 ).
- the camera SW driver 512 can be configured to write a plurality of predetermined LUTs, such as the LUTs 322 and 324 of the example of FIGS. 3 A and 3 B , e.g., as part of an initialization process of the camera 500 .
- the camera SW driver 512 can also be configured to issue an interpolation command (Intern_command) or other LUT processing commands, which can be directly communicated to the LUT engine 530 or, as discussed herein, could be placed in a command buffer in the memory 520 , and then read from the command buffer by the LUT engine 530 prior to execution.
- Intern_command interpolation command
- other LUT processing commands which can be directly communicated to the LUT engine 530 or, as discussed herein, could be placed in a command buffer in the memory 520 , and then read from the command buffer by the LUT engine 530 prior to execution.
- the camera SW driver 512 , the memory 520 and the camera/ISP hardware 540 can operate similar to the corresponding elements of the camera 400 . Accordingly, for purposes of brevity and clarity, those elements of the camera 500 will not be described in further detail again with respect to FIG. 5 .
- the camera 500 can differ from the camera 400 in at least the following ways.
- the LUT engine 530 is implemented as a standalone LUT processing circuit from a programming DMA 560 of the camera 500 .
- the LUT engine 530 includes, in addition to the LUT ALUs 532 , DMAs 534 and an operation control circuit 536 .
- the DMAs 534 can include at least one basic read DMA for accessing LUTs in the memory 520 , and a basic write DMA for writing LUTs to the/ 520 , or to the LUT configuration register 542 of the camera/ISP hardware 540 .
- the LUT engine 530 of the camera 500 can be configured to work in conjunction with the programming DMA 560 , e.g., to coordinate writing of LUTs to the configuration LUTs 542 .
- the LUT engine 530 can be configured to send an interrupt request IRQ to the programming DMA 560 when an interpolated (and packed) LUT is ready to be written to the configuration LUTs 542 of the camera/ISP hardware 540 .
- the operational control circuit 536 can be configured to decode more complicated command structures than the LUT processing circuit 430 .
- the operation control circuit 536 can be configured to decode and schedule execution of operations of the compute kernel 600 illustrated in FIG. 6 .
- supported LUT processing operations of the LUT engine 530 can be more complicated, flexible and computationally sophisticated than supported LUT processing operations of the LUT processing circuit 430 .
- the operation control circuit 536 can also be configured to initiate operations of the programming DMA 560 (e.g., via interrupt requests), as well as schedule compute kernel execution (computations) on available ALUs of the LUT ALUs 532 .
- the LUT ALUs 532 can include a plurality of parallel implemented special purpose LUT ALUs that are configured to execute (perform) LUT processing operation (e.g., interpolation operations, bitwise operations, shift operations, etc.) for processing LUTs for use in image processing (e.g., to generate configuration LUTs for use by the camera/ISP hardware 540 of the camera 500 ).
- LUT processing operation e.g., interpolation operations, bitwise operations, shift operations, etc.
- FIG. 6 is a diagram of a compute kernel 600 that can be implemented in, for example, the camera of FIG. 5 .
- a compute kernel that is executed by an LUT processing circuit can have other forms.
- the compute kernel 600 incudes only a single instruction (e.g., an interpolation instruction using a single interpolation factor).
- the compute kernel 600 could include multiple (e.g., chained) interpolation instructions based on multiple interpolation factors, bitwise (logical) instructions, shift instructions, etc.
- the specific instructions and fields included in such a compute kernel will depend on the specific implementation and/or the instructions an LUT processing circuit (e.g., the LUT engine 530 ) is being instructed to execute.
- the camera SW driver 512 can generate the compute kernel 600 (as well as other compute kernels and instructions that are sent to the programming DMA 560 , such as ISP configuration register write instructions). The camera SW driver 512 can then communicate the compute kernel 600 , as well as other compute kernels, to the LUT engine 530 .
- the operation control circuit 536 can schedule (control, direct, etc.) execution of any compute kernels received from the camera SW driver 512 (e.g., using the special purpose LUT ALUs 532 and the DMAs 534 , which can include one or more read DMAs and one or more write DMAs).
- such compute kernels can have a simple format. However, as noted above, such compute kernels (e.g., the compute kernel 600 ) can be extended to include additional operations, which can be used in conjunction with adding and/or changing functionality and/or capabilities of an LUT engine (e.g., the LUT ALUs 532 of the LUT engine 530 ).
- LUT engine e.g., the LUT ALUs 532 of the LUT engine 530
- LUT compute kernels can be executed using element-wise computations. That is, a compute kernel, such as the compute kernel 600 , can be executed by performing computations (e.g., interpolation computes) one at a time (e.g., using single corresponding entries from multiple LUTs, such as predetermined LUTs, and/or intermediate interpolated LUTs). Accordingly, using the approaches described herein, parallelization of LUT processing operations can be implemented by scheduling, e.g., by the operation control circuit 536 , such element-wise computations across multiple, parallel implemented LUT ALUs 532 for concurrent processing of interpolation (or other) computations.
- a compute kernel such as the compute kernel 600
- parallelization of LUT processing operations can be implemented by scheduling, e.g., by the operation control circuit 536 , such element-wise computations across multiple, parallel implemented LUT ALUs 532 for concurrent processing of interpolation (or other) computations.
- the LUT engine 530 could be used to interpolate between predetermined LUTs 522 and 524 using a computed interpolation factor (ratio) X.
- each of the predetermined LUTs can include one-thousand entries. If the LUT engine 530 of the camera 500 includes one-thousand special purpose LUT ALUs 532 , interpolation (e.g., bilinear interpolation) between the LUTs 522 and 524 could then be completed in a single operation cycle, with each of the one-thousand LUT ALUs 532 concurrently completing a single element-wise interpolation computation. Accordingly, parallelization using multiple ALUs can be used to further improve image processing capabilities (power, bandwidth, speed, etc.).
- the elements of the example compute kernel 600 are briefly described below.
- the compute kernel 600 is illustrated using a binary layout of a linear interpolation compute kernel that the LUT engine 530 can execute (e.g., as administered by the operation control circuit 536 ).
- the compute kernel 600 is given by of example, and for purposes of illustrating a compute kernel for a single command.
- additional fields related to additional commands e.g., for additional interpolation operations, LUT packing operations, etc. can be included in such a compute kernel.
- the compute kernel 600 includes an Op field 610 , a size field 620 , a statisticsgs field 630 , a len field 640 , a first (lut1) address field 650 , a second (lut2) address field 660 , a third (lut3) address field 670 , a ratio (factor) 680 and an operation (Ierp) field 690 , that lists the fields 650 , 660 , 670 and 680 as arguments.
- the op field 610 can identify the type of command(s) included in the compute kernel 600 .
- the size field 620 can specify the total size (e.g., in bytes, etc.) of the compute kernel 600 .
- the consgs field 630 can specify a number of argument entries for the compute kernel 600 .
- the len field 640 can specify a number of the kernel computation entries for the compute kernel 600 .
- the first address field 650 can be a memory address of a first input LUT (e.g., LUT 522 ).
- the second address field 660 can be a memory address of a second input LUT (e.g., LUT 524 ).
- the third address field 650 can be an address of an output LUT (e.g., an intermediate interpolated LUT 570 ) and/or an address of an ISP configuration (final interpolated) LUT 542 , e.g., in configuration registers of the ISP 540 .
- the ratio field 680 can be an interpolation factor (e.g., X), such as those discussed herein.
- the operation field 690 can be, in this example, a bilinear interpolation opcode (Ierp) that is executable (e.g., directly executable) by the special purpose LUT ALUs 532 .
- Ierp bilinear interpolation opcode
- FIG. 7 is a flowchart illustrating a method 700 for image processing that can be implemented, for example, by the cameras of FIGS. 1 , 4 and 5 . It will be appreciated, however, that the method 700 can be implemented by cameras having other configurations. For purposes of discussion and illustration, the method 700 will be described with further reference to, at least, FIG. 1 and FIG. 2 .
- the method 700 includes, at block 702 , performing an initial camera setup.
- the camera SW driver 112 can write a plurality of predetermined LUTs (e.g., LUTs 122 ) to the memory 120 , such as the predetermined LUTs as described herein (e.g., predetermined LUTs for adjusting chrominance, luminance, gamma, brightness, etc.).
- the camera SW driver 112 can instruct the LUT processing circuit 130 (or other circuit, such as a programming DMA) to write (copy, store, etc.) initial LUTs in the configuration registers 142 of the ISP 140 , as an initial image frame capture configuration.
- the initial setup at block 702 can be performed in other ways.
- the method 700 includes capturing an image frame including the image and statistics 220 (e.g., pixel data and quantitative values corresponding with the captured image frame, such as brightness, video, preview, etc.).
- the ISP 140 can provide the statistics 220 to the camera SW driver 112 , which can execute the 3 A algorithms 232 on the image and statistics 220 and determine one or more value of qualitative image factors that can by used to adjust the configuration of the ISP 140 based on the captured scene of the image of the image and statistics 220 .
- the camera SW driver 112 can, based on the calculated factors, send one or more interpolation commands and/or other LUT processing commands (e.g., packing operations) to the LUT processing circuit 130 , such as in the form of a single interpolation operation, a chained interpolation operation, a compute kernel (such as the compute kernel 600 ), and so forth.
- the factors computed can depend on the specific camera implementation and/or on the image and statistics 220 of the captured frame.
- the factors can include values (e.g., to be used to adjust the ISP 140 configuration) corresponding with sensor gain, exposure time, cumulative color temperature, white balance, etc.
- the LUT processing circuit 130 can then execute the interpolation commands (e.g., by executing interpolation operations) and/or the other LUT processing commands (e.g., packing operations), such as using the approaches described herein, or using other approaches as appropriate for a specific implementation.
- LUTs that will be used in the interpolation operations can be read from the memory 120 using an identity operation and one or more LUT ALUs can perform LUT processing in correspondence with the commands (and factors) received from the camera SW driver 112 .
- multiple LUT interpolation operations can performed in generating a single interpolated LUT that is ultimately written to the ISP 140 's configuration registers 142 .
- the method 700 includes, at block 710 , writing interpolated and processed LUTs (e.g., intermediate or final LUTs) to the memory 120 and/or the configuration registers 142 to update the configuration information for the ISP 140 .
- LUTs e.g., intermediate or final LUTs
- the method 700 can return to block 704 , and another image frame capture and LUT processing sequence (blocks 704 to 710 ) can be performed (e.g., where this sequence is repeated at a frame rate of the associated camera, such as 30 FPS, 60 FPS, etc.).
- FIG. 8 shows an example of a generic computer device 800 and a generic mobile computer device 850 , which may be used with the techniques described here.
- Computing device 800 is intended to represent various forms of digital computers, such as laptops, desktops, tablets, workstations, personal digital assistants, televisions, servers, blade servers, mainframes, and other appropriate computing devices.
- Computing device 850 is intended to represent various forms of mobile devices, such as personal digital assistants, cellular telephones, smart phones, and other similar computing devices.
- the components shown here, their connections and relationships, and their functions, are meant to be exemplary only, and are not meant to limit implementations of the inventions described and/or claimed in this document.
- Computing device 800 includes a processor 802 , memory 804 , a storage device 806 , a high-speed interface 808 connecting to memory 804 and high-speed expansion ports 810 , and a low speed interface 812 connecting to low speed bus 814 and storage device 806 .
- the processor 802 can be a semiconductor-based processor.
- the memory 804 can be a semiconductor-based memory.
- Each of the components 802 , 804 , 806 , 808 , 810 , and 812 are interconnected using various busses, and may be mounted on a common motherboard or in other manners as appropriate.
- the processor 802 can process instructions for execution within the computing device 800 , including instructions stored in the memory 804 or on the storage device 806 to display graphical information for a GUI on an external input/output device, such as display 816 coupled to high speed interface 808 .
- multiple processors and/or multiple buses may be used, as appropriate, along with multiple memories and types of memory.
- multiple computing devices 800 may be connected, with each device providing portions of the necessary operations (e.g., as a server bank, a group of blade servers, or a multi-processor system).
- the memory 804 stores information within the computing device 800 .
- the memory 804 is a volatile memory unit or units.
- the memory 804 is a non-volatile memory unit or units.
- the memory 804 may also be another form of computer-readable medium, such as a magnetic or optical disk.
- the storage device 806 is capable of providing mass storage for the computing device 800 .
- the storage device 806 may be or contain a computer-readable medium, such as a floppy disk device, a hard disk device, an optical disk device, or a tape device, a flash memory or other similar solid state memory device, or an array of devices, including devices in a storage area network or other configurations.
- a computer program product can be tangibly embodied in an information carrier.
- the computer program product may also contain instructions that, when executed, perform one or more methods, such as those described above.
- the information carrier is a computer- or machine-readable medium, such as the memory 804 , the storage device 806 , or memory on processor 802 .
- the high speed controller 808 manages bandwidth-intensive operations for the computing device 800 , while the low speed controller 812 manages lower bandwidth-intensive operations.
- the high-speed controller 808 is coupled to memory 804 , display 816 (e.g., through a graphics processor or accelerator), and to high-speed expansion ports 810 , which may accept various expansion cards (not shown).
- low-speed controller 812 is coupled to storage device 806 and low-speed expansion port 814 .
- the low-speed expansion port which may include various communication ports (e.g., USB, Bluetooth, Ethernet, wireless Ethernet) may be coupled to one or more input/output devices, such as a keyboard, a pointing device, a scanner, or a networking device such as a switch or router, e.g., through a network adapter.
- input/output devices such as a keyboard, a pointing device, a scanner, or a networking device such as a switch or router, e.g., through a network adapter.
- the computing device 800 may be implemented in a number of different forms, as shown in the figure. For example, it may be implemented as a standard server 820 , or multiple times in a group of such servers. It may also be implemented as part of a rack server system 824 . In addition, it may be implemented in a personal computer such as a laptop computer 822 . Alternatively, components from computing device 800 may be combined with other components in a mobile device (not shown), such as device 850 . Each of such devices may contain one or more of computing device 800 , 850 , and an entire system may be made up of multiple computing devices 800 , 850 communicating with each other.
- Computing device 850 includes a processor 852 , memory 864 , an input/output device such as a display 854 , a communication interface 866 , and a transceiver 868 , among other components.
- the device 850 may also be provided with a storage device, such as a microdrive or other device, to provide additional storage.
- a storage device such as a microdrive or other device, to provide additional storage.
- Each of the components 850 , 852 , 864 , 854 , 866 , and 868 are interconnected using various buses, and several of the components may be mounted on a common motherboard or in other manners as appropriate.
- the processor 852 can execute instructions within the computing device 850 , including instructions stored in the memory 864 .
- the processor may be implemented as a chipset of chips that include separate and multiple analog and digital processors.
- the processor may provide, for example, for coordination of the other components of the device 850 , such as control of user interfaces, applications run by device 850 , and wireless communication by device 850 .
- Processor 852 may communicate with a user through control interface 858 and display interface 856 coupled to a display 854 .
- the display 854 may be, for example, a TFT LCD (Thin-Film-Transistor Liquid Crystal Display) or an OLED (Organic Light Emitting Diode) display, or other appropriate display technology.
- the display interface 856 may comprise appropriate circuitry for driving the display 854 to present graphical and other information to a user.
- the control interface 858 may receive commands from a user and convert them for submission to the processor 852 .
- an external interface 862 may be provided in communication with processor 852 , so as to enable near area communication of device 850 with other devices. External interface 862 may provide, for example, for wired communication in some implementations, or for wireless communication in other implementations, and multiple interfaces may also be used.
- the memory 864 stores information within the computing device 850 .
- the memory 864 can be implemented as one or more of a computer-readable medium or media, a volatile memory unit or units, or a non-volatile memory unit or units.
- Expansion memory 874 may also be provided and connected to device 850 through expansion interface 872 , which may include, for example, a SIMM (Single In Line Memory Module) card interface.
- SIMM Single In Line Memory Module
- expansion memory 874 may provide extra storage space for device 850 , or may also store applications or other information for device 850 .
- expansion memory 874 may include instructions to carry out or supplement the processes described above, and may include secure information also.
- expansion memory 874 may be provided as a security module for device 850 , and may be programmed with instructions that permit secure use of device 850 .
- secure applications may be provided via the SIMM cards, along with additional information, such as placing identifying information on the SIMM card in a non-hackable manner.
- the memory may include, for example, flash memory and/or NVRAM memory, as discussed below.
- a computer program product is tangibly embodied in an information carrier.
- the computer program product contains instructions that, when executed, perform one or more methods, such as those described above.
- the information carrier is a computer- or machine-readable medium, such as the memory 864 , expansion memory 874 , or memory on processor 852 , that may be received, for example, over transceiver 868 or external interface 862 .
- Device 850 may communicate wirelessly through communication interface 866 , which may include digital signal processing circuitry where necessary. Communication interface 866 may provide for communications under various modes or protocols, such as GSM voice calls, SMS, EMS, or MMS messaging, CDMA, TDMA, PDC, WCDMA, CDMA2000, or GPRS, among others. Such communication may occur, for example, through radio-frequency transceiver 868 . In addition, short-range communication may occur, such as using a Bluetooth, WiFi, or other such transceiver (not shown). In addition, GPS (Global Positioning System) receiver module 870 may provide additional navigation- and location-related wireless data to device 850 , which may be used as appropriate by applications running on device 850 .
- GPS Global Positioning System
- Device 850 may also communicate audibly using audio codec 860 , which may receive spoken information from a user and convert it to usable digital information. Audio codec 860 may likewise generate audible sound for a user, such as through a speaker, e.g., in a handset of device 850 . Such sound may include sound from voice telephone calls, may include recorded sound (e.g., voice messages, music files, etc.) and may also include sound generated by applications operating on device 850 .
- Audio codec 860 may receive spoken information from a user and convert it to usable digital information. Audio codec 860 may likewise generate audible sound for a user, such as through a speaker, e.g., in a handset of device 850 . Such sound may include sound from voice telephone calls, may include recorded sound (e.g., voice messages, music files, etc.) and may also include sound generated by applications operating on device 850 .
- the computing device 850 may be implemented in a number of different forms, as shown in the figure. For example, it may be implemented as a cellular telephone 880 . It may also be implemented as part of a smartphone 882 , personal digital assistant, or other similar mobile device.
- implementations of the systems and techniques described here can be realized in digital electronic circuitry, integrated circuitry, specially designed ASICs (application specific integrated circuits), computer hardware, firmware, software, and/or combinations thereof.
- ASICs application specific integrated circuits
- These various implementations can include implementation in one or more computer programs that are executable and/or interpretable on a programmable system including at least one programmable processor, which may be special or general purpose, coupled to receive data and instructions from, and to transmit data and instructions to, a storage system, at least one input device, and at least one output device.
- the systems and techniques described here can be implemented on a computer having a display device (e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor) for displaying information to the user and a keyboard and a pointing device (e.g., a mouse or a trackball) by which the user can provide input to the computer.
- a display device e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor
- a keyboard and a pointing device e.g., a mouse or a trackball
- Other kinds of devices can be used to provide for interaction with a user as well; for example, feedback provided to the user can be any form of sensory feedback (e.g., visual feedback, auditory feedback, or tactile feedback); and input from the user can be received in any form, including acoustic, speech, or tactile input.
- the systems and techniques described here can be implemented in a computing system that includes a back end component (e.g., as a data server), or that includes a middleware component (e.g., an application server), or that includes a front end component (e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the systems and techniques described here), or any combination of such back end, middleware, or front end components.
- the components of the system can be interconnected by any form or medium of digital data communication (e.g., a communication network). Examples of communication networks include a local area network (“LAN”), a wide area network (“WAN”), and the Internet.
- LAN local area network
- WAN wide area network
- the Internet the global information network
- the computing system can include clients and servers.
- a client and server are generally remote from each other and typically interact through a communication network.
- the relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other.
Abstract
In a general aspect, a camera can include a dynamic memory, and a software driver configured to store, in the dynamic memory, a plurality of predetermined lookup tables (LUTs), and to issue an interpolation command indicating a value of a quantitative image factor corresponding with an image frame received by the ISP. The camera can also include a LUT processing circuit configured to receive the interpolation command, and in response to receiving the interpolation command: read a first predetermined LUT and a second predetermined LUT from the dynamic memory; and perform at least one interpolation operation to generate an interpolated LUT. The camera can further include an image signal processor (ISP) including a configuration register, and the LUT processing circuit can be configured to write the interpolated LUT to the configuration register.
Description
- This document relates, generally, to processing of images captured by a camera. More specifically, this document relates to approaches for interpolating and processing lookup tables, and programming configuration information for image processing in an image signal processor (ISP) of a camera, such as a camera included in a mobile electronic device.
- Camera technology continues to advance. Cameras (e.g., digital cameras) are integrated in mobile electronic devices (smartphones, tablet computers, etc.) and can be implemented in recreation devices, such as action cameras, as well as many other applications, such as automotive systems, security systems, and so forth. In such digital cameras, an image signal processor (ISP) can be implemented, which can operate using one or more look up tables (LUTs) to process (e.g., adjust, tune, etc.) images (image frames, etc.) captured by an image sensor of the camera, such as by a CMOS sensor or a charge-coupled sensor, for example. Such LUTs can be stored in configuration registers (configuration memory) of the ISP and can each include a finite number of configuration values used by an ISP for processing captured image frames. Such configuration information can be related to, or correspond with, different aspects of captured image frames. These attributes can include lighting, exposure time, cumulative color temperature, chrominance, luminance, contrast, gamma, etc. of captured image frames.
- Such LUTs are typically large data structures, and the attributes they correspond with can be expressed as quantitative values, which may be referred to as image factors. However, because such image factors are continuous values, generating respective predetermined LUTs for possible values of each of a plurality of image factors is not practical due, at least, to an amount of memory that would be required to store those predetermined LUTs. Therefore, interpolation (e.g., bilinear interpolation, trilinear interpolation, etc.) and other processing can be performed using predetermined lookup tables that are tuned for achieving high quality captured image frames at key (index, etc.) values of various image factors to produce interpolated lookup tables (including interpolated LUT values).
- In current approaches, software drivers running on a general purpose processor are used to perform such lookup table processing, which can include interpolation operations to calculate interpolated values included in an interpolated LUT, and operations for formatting LUTs for use in specific ISP hardware. Also, because more than one image factor often is involved in interpolating each LUT used by an ISP, generating LUTs that are used by an ISP can include performing more than one interpolation operation per LUT.
- Further, LUT interpolation and processing is done on a per-frame basis. Therefore, for cameras that capture image frames (e.g., video) at 60 frames per second (FPS), an associated SW driver must perform interpolation and other processing of the LUTs used by an associated ISP run 60 times per second. Using current approaches limits (or negatively impacts) image processing performance of a camera, and can also adversely impact power consumption of a corresponding general purpose processor (main processor, central processor, etc.) of an electronic devices including a digital camera.
- In a general aspect, a camera can include a dynamic memory, and a software driver configured to store, in the dynamic memory, a plurality of predetermined lookup tables (LUTs), a first LUT of the predetermined LUTs including first image signal processor (ISP) configuration information corresponding with a first value of a quantitative image factor, and a second LUT of the predetermined LUTs including second ISP configuration information corresponding with a second value of the quantitative image factor. The second value can be greater than the first value. The software driver can be further configured to issue an interpolation command indicating (including, specifying, etc.) a third value of the quantitative image factor corresponding with an image frame received by the ISP. The third value can be greater than the first value and less than the second value. The camera can also include a LUT processing circuit configured to receive the interpolation command, and in response to receiving the interpolation command: read the first LUT and the second LUT; and perform at least one interpolation operation to generate an interpolated LUT, the interpolated LUT can be generated based, at least, on the third value, the first LUT and the second LUT. The camera can further include an image signal processor (ISP) including a configuration register. The LUT processing circuit can be further configured to write the interpolated LUT to the configuration register.
- The proposed solution thus, in particular, relates to a camera which can include an image sensor configured to capture image frames; a dynamic memory; an image signal processor, ISP, including a configuration register and a software driver. The software driver may be configured to store, in the dynamic memory, a plurality of predetermined lookup tables, LUTs, for processing image frames depending on aspects of a captured image frame and/or on a use case. A first LUT of the predetermined LUTs may include first ISP configuration information corresponding with a first value of a quantitative image factor, and a second LUT of the predetermined LUTs may include second ISP configuration information corresponding with a second value of the quantitative image factor, the second value being greater than the first value. The software drive may be further configured to issue an interpolation command including a third value of the quantitative image factor corresponding with an image frame received by the ISP, the third value being greater than the first value and less than the second value. A LUT processing circuit of the camera may be configured to receive the interpolation command, and in response to receiving the interpolation command may read the first LUT and the second LUT; and perform at least one interpolation operation to generate an interpolated LUT, the interpolated LUT being generated based, at least, on the third value, the first LUT and the second LUT. The LUT processing circuit may then be further configured to write the interpolated LUT to the configuration register of the ISP. The predetermined LUTs can be associated with specific values (key configuration values) of the qualitative image factors relating to captured and/or computed image data for an image frame, such as sensor gain, exposure time, cumulative color temperature (CCT), white balance, luminance, etc. The specific factors used can depend, at least, on the particular camera implementation. The predetermined LUTs can include configuration information for an image processing stack (e.g., of the ISP) based on, or corresponding with conditions of a scene depicted in a captured image frame and/or based on predetermined use cases, where different conditions and different use cases correspond to different ISP configuration information, such as different key configuration values of the LUTs, each LUT being associated with specific ISP configuration information so that an LUT is selectable (e.g., for use in an interpolation operation) depending on a condition of a scene and/or a use case.
- In another general aspect, a method can include storing, in memory of a computing device, a plurality of predetermined lookup tables (LUTs), a first LUT of the predetermined LUTs including first image signal processor (ISP) configuration information corresponding with a first value of a quantitative image factor, and a second LUT of the predetermined LUTs including second ISP configuration information corresponding with a second value of the quantitative image factor. The second value can be greater than the first value. The method can further include receiving, at a LUT processing circuit, an interpolation command indicating (including, specifying, etc.) a third value of the quantitative image factor corresponding with an image frame received by the ISP. The third value can be greater than the first value and less than the second value. The method can still further include, in response to receiving the interpolation command: reading, by the LUT processing circuit, the first LUT and the second LUT; performing an interpolation operation using the third value, the first LUT and the second LUT to generate an interpolated LUT; and writing the interpolated LUT to at least one of the memory or a configuration register of the ISP.
- The details of one or more implementations are set forth in the accompanying drawings and the description below. Other features will be apparent from the description and drawings, and from the claims.
-
FIG. 1 is a block diagram illustrating a camera that can be included, for example, in a mobile computing device, such as a smartphone. -
FIG. 2 is a block/state diagram illustrating operation of camera, including hardware lookup table (LUT) processing. -
FIGS. 3A and 3B are diagrams illustrating an example process of LUT interpolation that can be implemented by an LUT processing circuit. -
FIG. 4 is a block diagram illustrating an implementation of a camera including an LUT processing circuit. -
FIG. 5 is a block diagram illustrating another implementation of a camera including an LUT processing circuit. -
FIG. 6 is a diagram of a compute kernel that can be executed by, for example, the camera ofFIG. 5 . -
FIG. 7 is a flowchart illustrating a method for image processing that can be implemented, for example, by the cameras ofFIGS. 1, 4 and 5 . -
FIG. 8 shows an example of a computer device and a mobile computer device that can be used to implement the techniques described here. - Like reference symbols in the various drawings indicate like elements.
- To address the drawbacks discussed above, such as limited image processing performance and power consumption, the approaches described herein use hardware apparatuses, such as lookup table (LUT) processing circuits and/or LUT hardware engines (LUT engines) to perform LUT processing operations, such as interpolation operations (e.g., bilinear interpolation operations, trilinear interpolation operations, etc.), operations to perform packing (transformation, translation, etc.) of LUTs (e.g., to configure them for specific image signal processor (ISP) hardware configuration registers), etc.
- Such approaches can achieve a significant reduction in an amount of general purpose processor cycles (e.g., of a mobile electronic device including a camera implementation such as those described herein) used in image processing (by a camera software (SW) driver). Further, these approaches can reduce power consumption by the associated general purpose processor (and overall power consumption of an electronic device implementing such approaches) by performing computationally intensive operations (e.g., interpolation operations) using a special purpose LUT processing circuit or LUT engine, such as the example implementations described herein. For instance, executing arithmetic operations on a general-purpose CPU (such as for LUT interpolation, etc.) can consume more power than the same operations performed on fixed-function hardware (e.g., an LUT processing circuit) specifically designed to perform (execute, etc.) such operations. For instance, general-purpose CPUs can consume more power because they utilize a complex, generic execution pipeline for instruction fetch-decode-execute sequences. Therefore, an LUT interpolation process (operation, etc.), when performed using a general purpose CPU, will be performed as a series of general CPU instructions that are processed this execution pipeline.
- In contrast, specialized hardware (e.g., the LUT processing circuits and/or LUT engines described herein), may not include a complex pipeline and, instead, can be configured to perform a set of fixed-functions in hardware that does not require complex programming and, therefore, can be implemented using less complicated circuitry than a general purpose CPU. Such less complicated circuit can include significantly less hardware gates than are used in general purpose CPU, which, as a result, uses less power (e.g., less power per operation.) Further, the implementations described herein can also significantly improve image signal processing performance, allowing for improvements in image quality (e.g., as a result of possible additional image processing), increases in frame rates for captured image frames, and so forth.
-
FIG. 1 is a block diagram illustrating a camera 100 (e.g., a digital camera) that can be included, for example, in a mobile computing device, such as thesmartphone 882 shown inFIG. 8 below. Thecamera 100 can, of course, be implemented in other electronic devices, such as tablet computers, notebook computers, laptop computers, action cameras, body cameras, etc. The elements of the camera 100 (as well as the elements of other camera implementations described herein) are given by way of example and for purposes of illustration. It will be appreciated that, a camera implementing the approaches described herein can, include other elements, can have elements replaced with different elements, can have multiple elements combined into a single integrated element, can have elements omitted, and so forth. - As shown in
FIG. 1 , thecamera 100 includes a general purpose processor 110 (e.g., a general purpose CPU), amemory 120, such as dynamic random access memory (DRAM), aLUT processing circuit 130, anISP 140, and an image sensor 150 (e.g., a CMOS sensor, a charge-coupled device (CCD) sensor, etc.). InFIG. 1 , communication paths (operational couplings) are shown between various elements of thecamera 100. These communication paths are illustrative and, in some implementations, other communication paths or operational relationships can be included or defined in thecamera 100. - The
camera 100 ofFIG. 1 includes acamera SW driver 112 running on thegeneral purpose processor 110. In this example, thecamera SW driver 112 can be configured, e.g., as part of an initialization process, to store, in thememory 120, a plurality of predetermined lookup tables (LUTs) as part of theLUTs 122. For instance, thecamera SW driver 112 can be configured to store lookup tables that have been previously generated (e.g., by image quality engineers) and that include ISP configuration information for various aspects of image capturing and processing by theISP 140 and/or theimage sensor 150. For instance, these predetermined LUTs can be associated with specific values (key configuration values) of qualitative image factors relating to captured and/or computed image data for an image frame, such as sensor gain, exposure time, cumulative color temperature (CCT), white balance, luminance, etc. The specific factors used will depend, at least, on the particular camera implementation. In some implementations, theLUTs 122 can also include intermediate interpolated LUTs, which are written by theLUT processing circuit 130 and used in interpolations where more than one factor (and multiple interpolation operations) is (are) used to generate an interpolated LUT (e.g., ISP configuration data) that is written to the configuration registers 142 for use by theISP 140. Depending on the particular implementation, such LUTs (predetermined LUTs and/or interpolated LUTs) can be one-dimensional, two-dimensional, and/or three-dimensional, and can include integer values, floating point values, etc. - Such predetermined LUTs can include configuration information for the image processing stack (e.g., of the ISP 140) that can correspond with specific conditions of a scene depicted in a captured image frame and/or with specific use cases, where different conditions and different use cases correspond to different key configuration values of the LUTs, each LUT being associated with a specific key configuration value so that an LUT is selectable (e.g., for use in an interpolation operation) depending on a condition of a scene and/or a use case. In particular, the predetermined LUTs can include configuration information for the image processing stack (e.g., of the ISP 140) based on various (e.g., potential) scene conditions and/or use cases (e.g. cloudy, sunny, video, preview, etc.) corresponding, for each predetermined LUT, with a respective key configuration (factor) value of the set of key configuration values for each different factor that is used by a given implementation. However, in some implementations, because such scene factors are continuous variables, interpolation between the predetermined tables may need to be performed when a computed factor for a captured image frame is between key values (e.g., greater than one key factor value and less than a second key factor value) for corresponding predetermined lookup tables. In the camera 100 (and similarly in the
camera 400 ofFIG. 4 and thecamera 500 ofFIG. 5 ), such interpolation operations can be performed by the LUT processing circuit 130 (theLUT processing circuit 430, or the LUT engine 530), e.g., using one or more special purpose LUT arithmetic and logic units (ALUs), such as are further described below. - As shown in
FIG. 1 , thememory 120 can also include acommand buffer 124, which can receive LUT processing commands (e.g., interpolation commands, bitwise operation commands, shift commands, etc.) from thecamera SW driver 112. TheLUT processing circuit 130 can then read commands for execution from thecommand buffer 124 and perform associated LUT operations (e.g., using special purpose LUT ALUs included in the LUT processing circuit 130). - The
ISP 140 of thecamera 100, as shown inFIG. 1 , includes configuration registers 142, which can be used to store LUTs (e.g., interpolated LUTs) that include configuration information (e.g., corresponding with qualitative images factors that were determined based on a previously captured image frame) to capture and process a next image frame. In some implementations, the LUTs stored in the configuration registers 142 can be updated after each image frame is captured. That is, LUT processing, such as described herein, can be performed for every frame in a sequence of captured image frames and configuration information in the configuration registers 142 for theISP 140 can be updated after each image frame capture. For instance, if thecamera 100 captures image frames at 60 frames per second (fps), interpolation for all configuration LUTs (using one or more factors) can be performed 60 times per second (after each image frame is captured) and the configuration registers 142 can be updated with the newly interpolated LUTs. For instance, LUTs used in image processing can each include hundreds of values, or more, and multiple LUTs can be used for processing each image (e.g., at a frame capture rate). As an example, for an LUT that includes 1000 entries, interpolation of that one LUT would involve 60,000 interpolation calculations per second (e.g., 60×1000, for an image frame capture rate of 60 fps). The number of calculations can be further multiplied in implementations where LUT interpolation is cascaded. For instance, if tri-linear interpolation is performed, seven interpolation operations can be performed to produce a final interpolated LUT (e.g., with each interpolation operation including sixty-thousand calculations using the above example). -
FIG. 2 is a block/state flow diagram 200 illustrating operation of a camera that includes hardware lookup table (LUT) processing, such as described herein. In some implementations, the state flow diagram 200 can be implemented by the cameras disclosed herein (e.g., thecameras FIG. 2 , the state flow diagram 200 will be described generally, without specific reference to any particular camera implementation. - As shown in
FIG. 2 , the state flow diagram 200, which implements a feedback loop, can include anISP state 210 that operates based on configuration information (e.g., LUTs) stored in configuration registers 212. In the state flow diagram 200, at theISP state 210, an image frame (e.g., pixel data for the image frame) can be captured and statistics on the captured image frame can be determined, which can then be communicated as image andstatistics 220 for processing and analysis atstate 230. - At
state 230, auto-tuning algorithms (e.g., auto-focus, auto-exposure and auto-white-balance), which can be referred to as3 A algorithms 232, can be performed on the image and statistics 220 (e.g., by a camera SW driver). The3 A algorithms 232 can be configured to calculate qualitative image factors (for each captured image frame), such as the image factors described herein. The calculated image factors can then be used, as part of LUT hardware processing 234, to generate (and in some implementations, pack or transform) LUTs that adjust the configuration information included in the configuration registers 212 based a current scene (as represented by the image and statistics 220). This updated (adjusted) configuration information can be included in register updates 236. The register updates 236 can then be communicated to the configuration registers 212 via afeedback path 240, and the process of the state flow diagram 200 can be repeated for a new (next) captured image frame. - As described herein, the LUT hardware processing 234 can include performing LUT interpolation operations on various LUTs (e.g., predetermined LUTs and/or intermediate interpolated LUTs). Depending on the particular implementation, each LUT that is used at the ISP state 210 (e.g., that is stored in the configuration registers 212) can be interpolated using one or more qualitative image factors, such as using the approaches described herein.
- In addition to LUT interpolation operations, the LUT hardware processing 234 can include performing packing operations on one or more LUTs (e.g., interpolated LUTs). For instance, in some implementations, camera ISP hardware can require LUTs including configuration information to be in a specific format and/or arrangement. For example, in some implementation, specific ISP hardware can expect different bit widths LUT entries, or that more than one LUT be packed (merged) into a single (combined) LUT. In some implementations, each LUT entry of such a packed or merged LUT could include different values from the LUTs that are packed (merged) together. Packing operations on LUTs can be performed using arithmetic operations, bitwise (logical) operations, and/or shift operation. Accordingly, special purpose LUT ALUs that are used for performing interpolation operations can also be configured to perform LUT packing operations.
-
FIGS. 3A and 3B are diagrams, 300 and 350 respectively, that illustrate an example process of LUT interpolation that can be implemented by an LUT processing circuit. The LUT interpolation process shown inFIGS. 3A and 3B illustrates LUT interpolation for a single value of one qualitative image factor X (e.g., an interpolation factor X 301), which can be a value of a qualitative image factor, such as those factors described herein. It will be appreciated, however, that the process ofFIGS. 3A and 3B (or a similar process) can be implemented to perform a second interpolation operation based on a second qualitative image factor to produce a final interpolated LUT that is used as configuration information for an ISP. Such multifactor LUT interpolations can be performed in a number of manners, such as using a hierarchical flow to generate intermediate LUTs from predetermined LUTs, and then using intermediate LUTs and/or other predetermined LUTs to generate a final interpolated LUT that is written to configuration registers of an associated ISP. In some implementations, values of qualitative image factors (e.g., key values and interpolation factors) can be normalized to have values between zero and one, though other approaches can be used. - As indicated above,
FIGS. 3A and 3B illustrate an LUT interpolation process using a value of an image factor X (e.g., the interpolation factor X 301). In this example, theinterpolation factor X 301 can be used, depending on the computed value of theinterpolation factor X 301, as a ratio for interpolating (e.g., bilinear interpolation) between configuration information included inpredetermined LUTs predetermined LUTs FIG. 3A . As is also shown inFIG. 3A , the key values A, B, C and D, for this example, define interpolation factor ranges 310 illustrated by the horizontal, doubled-ended arrows inFIG. 3A . For instance, a first interpolation factor range is between A and B, a second interpolation factor range is between B and C, and a third interpolation factor range is between C and D. In this example A<B<C<D and X is between B and C. That is B<X<C. - Accordingly, as shown by the diagram 350 of
FIG. 3B , for this example, because the image factor X falls within the interpolation factor range between key values B and C, interpolation between thepredetermined LUT 322 associated with the key value B and thepredetermined LUT 324 associated with the key value C is performed using theinterpolation factor X 301. That is, in this example, theinterpolation factor X 301 can being used as a ratio for performing (bilinear)hardware interpolation 360 on thepredetermined LUTs FIG. 4 . -
FIG. 4 is a block diagram illustrating an implementation of acamera 400 including an LUT processing circuit 430 (LUT processing hardware). As with thecamera 100, thecamera 400 includes a camera SW driver 412 (e.g., running on a general purpose processor), memory 420 (DRAM) and camera/ISP hardware 440. Also, as discussed with respect to thecamera SW driver 112 of thecamera 100, thecamera SW driver 412 can be configured to write a plurality of predetermined LUTs, such as theLUTs FIGS. 3A and 3B , e.g., as part of an initialization process of thecamera 400. In some implementations, thecamera SW driver 412 can also be configured to issue an interpolation command (Interp_command) or other LUT processing commands, which can be directly communicated to theLUT processing circuit 430 or, as discussed herein, could be placed in a command buffer in thememory 420, and then read from the command buffer by theLUT processing circuit 430 prior to execution. Further referring to the LUT interpolation example ofFIGS. 3A and 3B , the interpolation command issued by thecamera SW driver 412 for performing such an interpolation operation could take the form of: -
- op(Interp, x, LUT1_addr, LUT2_addr, dst_LUT),
where x is theinterpolation factor X 301, LUT1_addr is the address of thepredetermined LUT 322, LUT2_addr is the address of thepredetermined LUT 324, and dst_LUT is the address of theintermediate LUT 370 and/or the address in the configuration LUTs 442 (configuration registers) of the camera/ISP hardware 440 of thecamera 400 for writing the interpolated LUT.
- op(Interp, x, LUT1_addr, LUT2_addr, dst_LUT),
- In response to receiving the interpolation command (e.g., from the
camera SW driver 412 or a command buffer in the memory 420), theLUT processing circuit 430 can be configured to read theLUT 322 and theLUT 324 from thememory 420, e.g., using a programming direct memory access (DMA) controller (programming DMA 434). In some implementations, theLUT processing circuit 430 can be implemented in a programming DMA (the programming DMA 434), or a limited programming DMA can be implemented as part of theLUT processing circuit 430. In some implementations, a programming DMA can be excluded, and theLUT processing circuit 430 can include a read DMA and a write DMA for, respectively accessing (reading) LUTs and writing LUTs. - In the example implementation of
FIG. 4 , theprogramming DMA 434 can be a specialized DMA that can read and execute register programming commands that are stored in memory. For instance a register command can be a register write, poll, etc. command (e.g. write_register(register_address, value)), which can direct the DMA to perform an operation on the register space of the ISP hardware (e.g., writing/polling of ISP hardware registers without direct intervention of a main CPU). For instance, in some implementations, one supported command of theprogramming DMA 434 can be to accept an address of an LUT the memory 420 (e.g., an address of the LUT 370) that is to be written to a hardware LUT (e.g., an ISP configuration LUT 442) and coordinate writing of the LUT, taking into account any dependencies (e.g., waiting from the LUT to be generate before initiating writing the LUT). - As shown in
FIG. 4 , one or more specialpurpose LUT ALUs 432 can be implemented in theLUT processing circuit 430. In this example, after reading theLUTs LUT ALUs 432 can perform interpolation operations (computations, operations, etc.) consistent with the interpolation command issued by thecamera SW driver 412 to generate an interpolated LUT. These operations, depending the number ofLUT ALUs 432, can be performed sequentially and/or in parallel. In this example, each entry of the interpolated LUT can be computed from corresponding entries in theLUTs interpolation factor X 301 using the following equation: -
LUT_out_val=LUT1_val*x+LUT2_val*(1−x)—Where 0<=x<=1, - In the above equation, LUT_out_val represents values of the interpolated LUT being generated, LUT1_val represents corresponding values in the
LUT 322, x represents theinterpolation factor X 301, and LUT2_val represents corresponding values in theLUT 324. As discussed above, in this example, the values of the qualitative image factor (key values corresponding with the LUTs, and the interpolation factor X) can be normalized to be between 0 and 1, though specific values (e.g., ISP configuration values) included in the LUTs may not be normalized. In some implementations, additional interpolation commands, or other LUT processing commands (e.g., packing commands) can be received by the LUT processing circuit 430 (e.g., directly from thecamera SW driver 412 or read from a command buffer in the memory 420). Once the commands for generating a final interpolated LUT are completed, the final interpolated LUT can be written as a configuration LUT to the LUT storage are 442 of the camera/ISP hardware 440. - For instance, in some implementation, multiple interpolation commands for generating an interpolated LUT using multiple interpolation operations and interpolation factors (computed values of qualitative images factors based on a captured image frame) can be expressed as a chained command. For instance, a command for generating an interpolated LUT based on multiple image factor (interpolation) values, e.g., one interpolation operation based on sensor gain (e.g., taking sensor gain into account) and another interpolation operation based on luminance (e.g., taking luminance into account) can be issued by the
camera SW driver 412 as a chained command in the form of: -
op(Interp,x,lut1,lut2,lut3_out)→op(Interp,y,lut3_out,lut4,lut_out)→op(write_lut,lut_register,addr,lut_out), - Where, in this example, lut1 and lut2 are interpolated using the interpolation factor x to generate an intermediate interpolated LUT lut3_out. After lut3_out is generated, the
LUT processing circuit 430 can, in accordance with the above chained command, interpolate between lut3_out and lut4 using the interpolation factor y to generate the final interpolated LUT lut_out, and then lut_out can be written to lut_register_addr (e.g., in the LUT registers 442 of the camera 400). - Using such command chaining can allow for the
camera SW driver 412 to express all requested interpolation operations for a captured image frame as a sequence of interpolation commands that can be interwoven with other register programming commands expressed by thecamera SW driver 412. In some implementations, such as in thecamera 400, dependencies between the LUT commands (e.g., interpolation and packing commands) and ISP configuration register write commands can be enforced by theLUT processing circuit 430, e.g., such as by using a wait for interrupt request feature (e.g., wait for irq) of theprogramming DMA 434. -
FIG. 5 is a block diagram illustrating another implementation of acamera 500 including an LUT processing circuit (LUT engine 530). As with thecameras camera 500 includes a camera SW driver 512 (e.g., running on a general purpose processor), memory 520 (DRAM) and camera/ISP hardware 540 (including configuration LUTs 542). Also, as discussed with respect to thecamera SW driver 112 of thecamera 100 and thecamera SW driver 412 of thecamera 400, thecamera SW driver 512 can be configured to write a plurality of predetermined LUTs, such as theLUTs FIGS. 3A and 3B , e.g., as part of an initialization process of thecamera 500. In some implementations, thecamera SW driver 512 can also be configured to issue an interpolation command (Intern_command) or other LUT processing commands, which can be directly communicated to theLUT engine 530 or, as discussed herein, could be placed in a command buffer in thememory 520, and then read from the command buffer by theLUT engine 530 prior to execution. - In some implementations, the
camera SW driver 512, thememory 520 and the camera/ISP hardware 540 can operate similar to the corresponding elements of thecamera 400. Accordingly, for purposes of brevity and clarity, those elements of thecamera 500 will not be described in further detail again with respect toFIG. 5 . - As can be seen from a comparison of
FIG. 5 withFIG. 4 , thecamera 500 can differ from thecamera 400 in at least the following ways. For instance, theLUT engine 530 is implemented as a standalone LUT processing circuit from a programming DMA 560 of thecamera 500. Further, theLUT engine 530, as compared to theLUT processing circuit 430, includes, in addition to theLUT ALUs 532,DMAs 534 and anoperation control circuit 536. In some implementations, theDMAs 534 can include at least one basic read DMA for accessing LUTs in thememory 520, and a basic write DMA for writing LUTs to the/520, or to theLUT configuration register 542 of the camera/ISP hardware 540. - The
LUT engine 530 of thecamera 500 can be configured to work in conjunction with the programming DMA 560, e.g., to coordinate writing of LUTs to theconfiguration LUTs 542. For instance, theLUT engine 530 can be configured to send an interrupt request IRQ to the programming DMA 560 when an interpolated (and packed) LUT is ready to be written to theconfiguration LUTs 542 of the camera/ISP hardware 540. - In some implementations, the
operational control circuit 536 can be configured to decode more complicated command structures than theLUT processing circuit 430. For instance, theoperation control circuit 536 can be configured to decode and schedule execution of operations of thecompute kernel 600 illustrated inFIG. 6 . As a result, supported LUT processing operations of theLUT engine 530 can be more complicated, flexible and computationally sophisticated than supported LUT processing operations of theLUT processing circuit 430. Further, theoperation control circuit 536 can also be configured to initiate operations of the programming DMA 560 (e.g., via interrupt requests), as well as schedule compute kernel execution (computations) on available ALUs of theLUT ALUs 532. As discussed herein, theLUT ALUs 532 can include a plurality of parallel implemented special purpose LUT ALUs that are configured to execute (perform) LUT processing operation (e.g., interpolation operations, bitwise operations, shift operations, etc.) for processing LUTs for use in image processing (e.g., to generate configuration LUTs for use by the camera/ISP hardware 540 of the camera 500). -
FIG. 6 is a diagram of acompute kernel 600 that can be implemented in, for example, the camera ofFIG. 5 . In other implementations, a compute kernel that is executed by an LUT processing circuit, such as theLUT engine 530 ofFIG. 5 , can have other forms. For instance, for purposes of example and illustration, thecompute kernel 600 incudes only a single instruction (e.g., an interpolation instruction using a single interpolation factor). In other instances, thecompute kernel 600 could include multiple (e.g., chained) interpolation instructions based on multiple interpolation factors, bitwise (logical) instructions, shift instructions, etc. The specific instructions and fields included in such a compute kernel will depend on the specific implementation and/or the instructions an LUT processing circuit (e.g., the LUT engine 530) is being instructed to execute. - For the
compute kernel 600, with further reference to thecamera 500 ofFIG. 5 , in this example, thecamera SW driver 512 can generate the compute kernel 600 (as well as other compute kernels and instructions that are sent to the programming DMA 560, such as ISP configuration register write instructions). Thecamera SW driver 512 can then communicate thecompute kernel 600, as well as other compute kernels, to theLUT engine 530. Theoperation control circuit 536 can schedule (control, direct, etc.) execution of any compute kernels received from the camera SW driver 512 (e.g., using the specialpurpose LUT ALUs 532 and theDMAs 534, which can include one or more read DMAs and one or more write DMAs). - As illustrated by the
compute kernel 600 ofFIG. 6 , such compute kernels can have a simple format. However, as noted above, such compute kernels (e.g., the compute kernel 600) can be extended to include additional operations, which can be used in conjunction with adding and/or changing functionality and/or capabilities of an LUT engine (e.g., theLUT ALUs 532 of the LUT engine 530). - In some implementations, LUT compute kernels can be executed using element-wise computations. That is, a compute kernel, such as the
compute kernel 600, can be executed by performing computations (e.g., interpolation computes) one at a time (e.g., using single corresponding entries from multiple LUTs, such as predetermined LUTs, and/or intermediate interpolated LUTs). Accordingly, using the approaches described herein, parallelization of LUT processing operations can be implemented by scheduling, e.g., by theoperation control circuit 536, such element-wise computations across multiple, parallel implementedLUT ALUs 532 for concurrent processing of interpolation (or other) computations. In an example implementation, theLUT engine 530 could be used to interpolate between predetermined LUTs 522 and 524 using a computed interpolation factor (ratio) X. In this example, each of the predetermined LUTs can include one-thousand entries. If theLUT engine 530 of thecamera 500 includes one-thousand specialpurpose LUT ALUs 532, interpolation (e.g., bilinear interpolation) between the LUTs 522 and 524 could then be completed in a single operation cycle, with each of the one-thousandLUT ALUs 532 concurrently completing a single element-wise interpolation computation. Accordingly, parallelization using multiple ALUs can be used to further improve image processing capabilities (power, bandwidth, speed, etc.). - Referring again to
FIG. 6 , the elements of theexample compute kernel 600 are briefly described below. As shown inFIG. 6 , thecompute kernel 600 is illustrated using a binary layout of a linear interpolation compute kernel that theLUT engine 530 can execute (e.g., as administered by the operation control circuit 536). As noted above, thecompute kernel 600 is given by of example, and for purposes of illustrating a compute kernel for a single command. In some implementations, additional fields related to additional commands (e.g., for additional interpolation operations, LUT packing operations, etc.) can be included in such a compute kernel. - In the example of
FIG. 6 , thecompute kernel 600 includes anOp field 610, asize field 620, anumargs field 630, alen field 640, a first (lut1)address field 650, a second (lut2)address field 660, a third (lut3)address field 670, a ratio (factor) 680 and an operation (Ierp)field 690, that lists thefields op field 610 can identify the type of command(s) included in thecompute kernel 600. Thesize field 620 can specify the total size (e.g., in bytes, etc.) of thecompute kernel 600. Thenumargs field 630 can specify a number of argument entries for thecompute kernel 600. Thelen field 640 can specify a number of the kernel computation entries for thecompute kernel 600. - For this example, which can be for a bilinear interpolation operation, the
first address field 650 can be a memory address of a first input LUT (e.g., LUT 522). Thesecond address field 660 can be a memory address of a second input LUT (e.g., LUT 524). Thethird address field 650 can be an address of an output LUT (e.g., an intermediate interpolated LUT 570) and/or an address of an ISP configuration (final interpolated)LUT 542, e.g., in configuration registers of theISP 540. Theratio field 680 can be an interpolation factor (e.g., X), such as those discussed herein. And theoperation field 690 can be, in this example, a bilinear interpolation opcode (Ierp) that is executable (e.g., directly executable) by the specialpurpose LUT ALUs 532. -
FIG. 7 is a flowchart illustrating amethod 700 for image processing that can be implemented, for example, by the cameras ofFIGS. 1, 4 and 5 . It will be appreciated, however, that themethod 700 can be implemented by cameras having other configurations. For purposes of discussion and illustration, themethod 700 will be described with further reference to, at least,FIG. 1 andFIG. 2 . - The
method 700 includes, atblock 702, performing an initial camera setup. For instance, in thecamera 100, atblock 702, thecamera SW driver 112 can write a plurality of predetermined LUTs (e.g., LUTs 122) to thememory 120, such as the predetermined LUTs as described herein (e.g., predetermined LUTs for adjusting chrominance, luminance, gamma, brightness, etc.). Further, thecamera SW driver 112 can instruct the LUT processing circuit 130 (or other circuit, such as a programming DMA) to write (copy, store, etc.) initial LUTs in the configuration registers 142 of theISP 140, as an initial image frame capture configuration. In other implementations, the initial setup atblock 702 can be performed in other ways. - At
block 704, themethod 700 includes capturing an image frame including the image and statistics 220 (e.g., pixel data and quantitative values corresponding with the captured image frame, such as brightness, video, preview, etc.). TheISP 140 can provide thestatistics 220 to thecamera SW driver 112, which can execute the3 A algorithms 232 on the image andstatistics 220 and determine one or more value of qualitative image factors that can by used to adjust the configuration of theISP 140 based on the captured scene of the image of the image andstatistics 220. - At block 706, the
camera SW driver 112 can, based on the calculated factors, send one or more interpolation commands and/or other LUT processing commands (e.g., packing operations) to theLUT processing circuit 130, such as in the form of a single interpolation operation, a chained interpolation operation, a compute kernel (such as the compute kernel 600), and so forth. As noted above, the factors computed can depend on the specific camera implementation and/or on the image andstatistics 220 of the captured frame. For instance, the factors can include values (e.g., to be used to adjust theISP 140 configuration) corresponding with sensor gain, exposure time, cumulative color temperature, white balance, etc. - At
block 708, theLUT processing circuit 130 can then execute the interpolation commands (e.g., by executing interpolation operations) and/or the other LUT processing commands (e.g., packing operations), such as using the approaches described herein, or using other approaches as appropriate for a specific implementation. For instance, LUTs that will be used in the interpolation operations can be read from thememory 120 using an identity operation and one or more LUT ALUs can perform LUT processing in correspondence with the commands (and factors) received from thecamera SW driver 112. As noted herein, multiple LUT interpolation operations can performed in generating a single interpolated LUT that is ultimately written to theISP 140's configuration registers 142. - After completion of LUT processing by the
LUT processing circuit 130 atblock 708, themethod 700 includes, atblock 710, writing interpolated and processed LUTs (e.g., intermediate or final LUTs) to thememory 120 and/or the configuration registers 142 to update the configuration information for theISP 140. As shown, inFIG. 7 , after completion of the operations ofblock 710, themethod 700 can return to block 704, and another image frame capture and LUT processing sequence (blocks 704 to 710) can be performed (e.g., where this sequence is repeated at a frame rate of the associated camera, such as 30 FPS, 60 FPS, etc.). -
FIG. 8 shows an example of ageneric computer device 800 and a genericmobile computer device 850, which may be used with the techniques described here.Computing device 800 is intended to represent various forms of digital computers, such as laptops, desktops, tablets, workstations, personal digital assistants, televisions, servers, blade servers, mainframes, and other appropriate computing devices.Computing device 850 is intended to represent various forms of mobile devices, such as personal digital assistants, cellular telephones, smart phones, and other similar computing devices. The components shown here, their connections and relationships, and their functions, are meant to be exemplary only, and are not meant to limit implementations of the inventions described and/or claimed in this document. -
Computing device 800 includes aprocessor 802,memory 804, astorage device 806, a high-speed interface 808 connecting tomemory 804 and high-speed expansion ports 810, and alow speed interface 812 connecting tolow speed bus 814 andstorage device 806. Theprocessor 802 can be a semiconductor-based processor. Thememory 804 can be a semiconductor-based memory. Each of thecomponents processor 802 can process instructions for execution within thecomputing device 800, including instructions stored in thememory 804 or on thestorage device 806 to display graphical information for a GUI on an external input/output device, such asdisplay 816 coupled tohigh speed interface 808. In other implementations, multiple processors and/or multiple buses may be used, as appropriate, along with multiple memories and types of memory. Also,multiple computing devices 800 may be connected, with each device providing portions of the necessary operations (e.g., as a server bank, a group of blade servers, or a multi-processor system). - The
memory 804 stores information within thecomputing device 800. In one implementation, thememory 804 is a volatile memory unit or units. In another implementation, thememory 804 is a non-volatile memory unit or units. Thememory 804 may also be another form of computer-readable medium, such as a magnetic or optical disk. - The
storage device 806 is capable of providing mass storage for thecomputing device 800. In one implementation, thestorage device 806 may be or contain a computer-readable medium, such as a floppy disk device, a hard disk device, an optical disk device, or a tape device, a flash memory or other similar solid state memory device, or an array of devices, including devices in a storage area network or other configurations. A computer program product can be tangibly embodied in an information carrier. The computer program product may also contain instructions that, when executed, perform one or more methods, such as those described above. The information carrier is a computer- or machine-readable medium, such as thememory 804, thestorage device 806, or memory onprocessor 802. - The
high speed controller 808 manages bandwidth-intensive operations for thecomputing device 800, while thelow speed controller 812 manages lower bandwidth-intensive operations. Such allocation of functions is exemplary only. In one implementation, the high-speed controller 808 is coupled tomemory 804, display 816 (e.g., through a graphics processor or accelerator), and to high-speed expansion ports 810, which may accept various expansion cards (not shown). In the implementation, low-speed controller 812 is coupled tostorage device 806 and low-speed expansion port 814. The low-speed expansion port, which may include various communication ports (e.g., USB, Bluetooth, Ethernet, wireless Ethernet) may be coupled to one or more input/output devices, such as a keyboard, a pointing device, a scanner, or a networking device such as a switch or router, e.g., through a network adapter. - The
computing device 800 may be implemented in a number of different forms, as shown in the figure. For example, it may be implemented as astandard server 820, or multiple times in a group of such servers. It may also be implemented as part of arack server system 824. In addition, it may be implemented in a personal computer such as alaptop computer 822. Alternatively, components fromcomputing device 800 may be combined with other components in a mobile device (not shown), such asdevice 850. Each of such devices may contain one or more ofcomputing device multiple computing devices -
Computing device 850 includes aprocessor 852,memory 864, an input/output device such as adisplay 854, acommunication interface 866, and atransceiver 868, among other components. Thedevice 850 may also be provided with a storage device, such as a microdrive or other device, to provide additional storage. Each of thecomponents - The
processor 852 can execute instructions within thecomputing device 850, including instructions stored in thememory 864. The processor may be implemented as a chipset of chips that include separate and multiple analog and digital processors. The processor may provide, for example, for coordination of the other components of thedevice 850, such as control of user interfaces, applications run bydevice 850, and wireless communication bydevice 850. -
Processor 852 may communicate with a user throughcontrol interface 858 anddisplay interface 856 coupled to adisplay 854. Thedisplay 854 may be, for example, a TFT LCD (Thin-Film-Transistor Liquid Crystal Display) or an OLED (Organic Light Emitting Diode) display, or other appropriate display technology. Thedisplay interface 856 may comprise appropriate circuitry for driving thedisplay 854 to present graphical and other information to a user. Thecontrol interface 858 may receive commands from a user and convert them for submission to theprocessor 852. In addition, anexternal interface 862 may be provided in communication withprocessor 852, so as to enable near area communication ofdevice 850 with other devices.External interface 862 may provide, for example, for wired communication in some implementations, or for wireless communication in other implementations, and multiple interfaces may also be used. - The
memory 864 stores information within thecomputing device 850. Thememory 864 can be implemented as one or more of a computer-readable medium or media, a volatile memory unit or units, or a non-volatile memory unit or units.Expansion memory 874 may also be provided and connected todevice 850 throughexpansion interface 872, which may include, for example, a SIMM (Single In Line Memory Module) card interface.Such expansion memory 874 may provide extra storage space fordevice 850, or may also store applications or other information fordevice 850. Specifically,expansion memory 874 may include instructions to carry out or supplement the processes described above, and may include secure information also. Thus, for example,expansion memory 874 may be provided as a security module fordevice 850, and may be programmed with instructions that permit secure use ofdevice 850. In addition, secure applications may be provided via the SIMM cards, along with additional information, such as placing identifying information on the SIMM card in a non-hackable manner. - The memory may include, for example, flash memory and/or NVRAM memory, as discussed below. In one implementation, a computer program product is tangibly embodied in an information carrier. The computer program product contains instructions that, when executed, perform one or more methods, such as those described above. The information carrier is a computer- or machine-readable medium, such as the
memory 864,expansion memory 874, or memory onprocessor 852, that may be received, for example, overtransceiver 868 orexternal interface 862. -
Device 850 may communicate wirelessly throughcommunication interface 866, which may include digital signal processing circuitry where necessary.Communication interface 866 may provide for communications under various modes or protocols, such as GSM voice calls, SMS, EMS, or MMS messaging, CDMA, TDMA, PDC, WCDMA, CDMA2000, or GPRS, among others. Such communication may occur, for example, through radio-frequency transceiver 868. In addition, short-range communication may occur, such as using a Bluetooth, WiFi, or other such transceiver (not shown). In addition, GPS (Global Positioning System)receiver module 870 may provide additional navigation- and location-related wireless data todevice 850, which may be used as appropriate by applications running ondevice 850. -
Device 850 may also communicate audibly usingaudio codec 860, which may receive spoken information from a user and convert it to usable digital information.Audio codec 860 may likewise generate audible sound for a user, such as through a speaker, e.g., in a handset ofdevice 850. Such sound may include sound from voice telephone calls, may include recorded sound (e.g., voice messages, music files, etc.) and may also include sound generated by applications operating ondevice 850. - The
computing device 850 may be implemented in a number of different forms, as shown in the figure. For example, it may be implemented as acellular telephone 880. It may also be implemented as part of asmartphone 882, personal digital assistant, or other similar mobile device. - Various implementations of the systems and techniques described here can be realized in digital electronic circuitry, integrated circuitry, specially designed ASICs (application specific integrated circuits), computer hardware, firmware, software, and/or combinations thereof. These various implementations can include implementation in one or more computer programs that are executable and/or interpretable on a programmable system including at least one programmable processor, which may be special or general purpose, coupled to receive data and instructions from, and to transmit data and instructions to, a storage system, at least one input device, and at least one output device.
- These computer programs (also known as programs, software, software applications or code) include machine instructions for a programmable processor, and can be implemented in a high-level procedural and/or object-oriented programming language, and/or in assembly/machine language. As used herein, the terms “machine-readable medium” “computer-readable medium” refers to any computer program product, apparatus and/or device (e.g., magnetic discs, optical disks, memory, Programmable Logic Devices (PLDs)) used to provide machine instructions and/or data to a programmable processor, including a machine-readable medium that receives machine instructions as a machine-readable signal. The term “machine-readable signal” refers to any signal used to provide machine instructions and/or data to a programmable processor.
- To provide for interaction with a user, the systems and techniques described here can be implemented on a computer having a display device (e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor) for displaying information to the user and a keyboard and a pointing device (e.g., a mouse or a trackball) by which the user can provide input to the computer. Other kinds of devices can be used to provide for interaction with a user as well; for example, feedback provided to the user can be any form of sensory feedback (e.g., visual feedback, auditory feedback, or tactile feedback); and input from the user can be received in any form, including acoustic, speech, or tactile input.
- The systems and techniques described here can be implemented in a computing system that includes a back end component (e.g., as a data server), or that includes a middleware component (e.g., an application server), or that includes a front end component (e.g., a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the systems and techniques described here), or any combination of such back end, middleware, or front end components. The components of the system can be interconnected by any form or medium of digital data communication (e.g., a communication network). Examples of communication networks include a local area network (“LAN”), a wide area network (“WAN”), and the Internet.
- The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other.
- A number of embodiments have been described. Nevertheless, it will be understood that various modifications may be made without departing from the spirit and scope of the invention.
- In addition, the logic flows depicted in the figures do not require the particular order shown, or sequential order, to achieve desirable results. In addition, other steps may be provided, or steps may be eliminated, from the described flows, and other components may be added to, or removed from, the described systems. Accordingly, other embodiments are within the scope of the following claims.
Claims (16)
1. A camera comprising:
a dynamic memory;
an image signal processor, ISP, including a configuration register;
a software driver configured to:
store, in the dynamic memory, a plurality of predetermined lookup tables, LUTs, a first LUT of the predetermined LUTs including first ISP configuration information corresponding with a first value of a quantitative image factor, and a second LUT of the predetermined LUTs including second ISP configuration information corresponding with a second value of the quantitative image factor, the second value being greater than the first value; and
issue an interpolation command indicating a third value of the quantitative image factor corresponding with an image frame received by the ISP, the third value being greater than the first value and less than the second value;
a LUT processing circuit configured to receive the interpolation command, and in response to receiving the interpolation command:
read the first LUT and the second LUT; and
perform at least one interpolation operation to generate an interpolated LUT, the interpolated LUT being generated based, at least, on the third value, the first LUT and the second LUT,
wherein the LUT processing circuit is further configured to write the interpolated LUT to the configuration register of the ISP.
2. The camera of claim 1 , wherein the LUT processing circuit is further configured to, during performance of the interpolation operation, write an intermediate interpolated LUT to the dynamic memory, the interpolated LUT being further generated based on the intermediate interpolated LUT and a third LUT of the plurality of predetermined LUTs.
3. The camera of claim 2 , wherein the interpolation command is a chained interpolation command.
4. The camera of claim 2 , wherein the LUT processing circuit incudes:
a read direct memory access controller configured to read the first LUT and the second LUT from the dynamic memory; and
a write direct memory access controller configured to write the intermediate interpolated LUT to the dynamic memory.
5. The camera of claim 4 , further comprising a programming direct memory access (DMA) controller configured to:
receive, from the software driver, a command to write the interpolated LUT to the configuration register; and
in response to the command to write the interpolated LUT to the configuration register and an interrupt signal from the LUT processing circuit, write the interpolated LUT to the configuration register, the interrupt signal indicating completion of generation of the interpolated LUT.
6. The camera of claim 1 , wherein:
the interpolation command is included in a compute kernel that is executed by the LUT processing circuit; and
the LUT processing circuit includes an operation control circuit and at least one LUT arithmetic and logic unit (ALU)
the operation control circuit being configured:
to decode the compute kernel; and
schedule LUT processing operations included in the compute kernel for execution by the at least one LUT ALU; and
the at least one LUT ALU is configured to execute the scheduled LUT processing operations, including the interpolation operation.
7. The camera of claim 6 , wherein the at least one LUT ALU includes a plurality of operationally parallel LUT ALUs, the operation control circuit being further configured to schedule parallel execution of LUT processing operations by the plurality of operationally parallel LUT ALUs.
8. The camera of claim 1 , wherein the LUT processing circuit further includes a programming direct memory access (DMA) controller configured to:
read the interpolation command from a command buffer included in the dynamic memory; and
write the interpolated LUT to the configuration register.
9. A mobile electronic device including the camera of claim 1 .
10. A method comprising:
storing, in memory of a computing device, a plurality of predetermined lookup tables (LUTs), a first LUT of the predetermined LUTs including first image signal processor (ISP) configuration information corresponding with a first value of a quantitative image factor, and a second LUT of the predetermined LUTs including second ISP configuration information corresponding with a second value of the quantitative image factor, the second value being greater than the first value;
receiving, at a LUT processing circuit, an interpolation command indicating a third value of the quantitative image factor corresponding with an image frame received by the ISP, the third value being greater than the first value and less than the second value;
in response to receiving the interpolation command:
reading, by the LUT processing circuit, the first LUT and the second LUT;
performing an interpolation operation using the third value, the first LUT and the second LUT to generate an interpolated LUT; and
writing the interpolated LUT to at least one of the memory or a configuration register of the ISP.
11. The method of claim 10 , wherein the interpolation command further includes:
an address of the first LUT in the memory of the computing device;
an address of the second LUT in the memory of the computing device; and
an address of the configuration register of the ISP.
12. The method of claim 10 , wherein the quantitative image factor is a first quantitative image factor, the interpolation operation is a first interpolation operation, the interpolated LUT is a first interpolated LUT, and the writing the interpolated LUT includes writing the first interpolated LUT to the memory, the method further comprising, in response to the interpolation command:
reading, by the LUT processing circuit, a third LUT of the plurality of predetermined LUTs;
performing an interpolation operation using a value of a second quantitative image factor, the first interpolated LUT and the third LUT to generate a second interpolated LUT; and
writing the second interpolated LUT to at least one of the memory or the configuration register of the ISP.
13. The method of claim 12 , wherein the interpolation command is a chained interpolation command.
14. The method of claim 10 , wherein the interpolation command is included in a compute kernel that is executed by the LUT processing circuit.
15. The method of claim 10 , further comprising, prior to writing the interpolated LUT to the configuration register of the ISP, performing by the LUT processing circuit on the interpreted LUT, at least one of a shift operation or a bitwise operation to format the interpreted LUT for writing to the configuration register of the ISP.
16. The method of claim 10 , wherein the interpolation operation is a bilinear interpolation operation.
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/US2020/070451 WO2022046147A1 (en) | 2020-08-24 | 2020-08-24 | Lookup table processing and programming for camera image signal processing |
Publications (1)
Publication Number | Publication Date |
---|---|
US20230336879A1 true US20230336879A1 (en) | 2023-10-19 |
Family
ID=72356546
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US18/022,718 Pending US20230336879A1 (en) | 2020-08-24 | 2020-08-24 | Lookup table processing and programming for camera image signal processing |
Country Status (3)
Country | Link |
---|---|
US (1) | US20230336879A1 (en) |
EP (1) | EP4201054A1 (en) |
WO (1) | WO2022046147A1 (en) |
Families Citing this family (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN117176933B (en) * | 2023-11-02 | 2024-01-23 | 摩尔线程智能科技(北京)有限责任公司 | Image signal processing method and device, electronic equipment and storage medium |
Family Cites Families (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7656415B2 (en) * | 2006-04-28 | 2010-02-02 | Microsoft Corporation | Aggregation of curve effects |
US8780225B2 (en) * | 2011-10-12 | 2014-07-15 | Apple Inc. | Use of noise-optimized selection criteria to calculate scene white points |
US9077943B2 (en) * | 2012-05-31 | 2015-07-07 | Apple Inc. | Local image statistics collection |
JP6004757B2 (en) * | 2012-06-07 | 2016-10-12 | キヤノン株式会社 | Image processing apparatus and image processing method |
US9241142B2 (en) * | 2013-01-24 | 2016-01-19 | Analog Devices Global | Descriptor-based stream processor for image processing and method associated therewith |
US10332481B2 (en) * | 2015-11-02 | 2019-06-25 | Dolby Laboratories Licensing Corporation | Adaptive display management using 3D look-up table interpolation |
US9602739B1 (en) * | 2016-10-23 | 2017-03-21 | Visual Supply Company | Lookup table interpolation in a film emulation camera system |
-
2020
- 2020-08-24 WO PCT/US2020/070451 patent/WO2022046147A1/en unknown
- 2020-08-24 US US18/022,718 patent/US20230336879A1/en active Pending
- 2020-08-24 EP EP20767699.0A patent/EP4201054A1/en active Pending
Also Published As
Publication number | Publication date |
---|---|
WO2022046147A1 (en) | 2022-03-03 |
EP4201054A1 (en) | 2023-06-28 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11074082B2 (en) | Fully extensible camera processing pipeline interface | |
JP6486996B2 (en) | Image tone adjustment using local tone curve calculation | |
JP4344383B2 (en) | Memory command handler for use in an image signal processor having a data driven architecture | |
JP2020516981A (en) | Configurable and programmable image processor unit | |
US20200043135A1 (en) | Blended neural network for super-resolution image processing | |
US10951822B2 (en) | Mobile device including multiple cameras | |
US20130004071A1 (en) | Image signal processor architecture optimized for low-power, processing flexibility, and user experience | |
US11182887B2 (en) | Method of processing images using high dynamic range while preserving frame rate and image processing device performing the same | |
US20170061677A1 (en) | Disparate scaling based image processing device, method of image processing, and electronic system including the same | |
US8798386B2 (en) | Method and system for processing image data on a per tile basis in an image sensor pipeline | |
US11758284B2 (en) | Image processors and image processing methods | |
US9927862B2 (en) | Variable precision in hardware pipelines for power conservation | |
CN101753820A (en) | Information processing apparatus, buffer control method, and computer program | |
US20230336879A1 (en) | Lookup table processing and programming for camera image signal processing | |
US20080293449A1 (en) | Method and system for partitioning a device into domains to optimize power consumption | |
US20200388016A1 (en) | Image signal processor, operating method thereof, and image processing system including the image signal processor | |
KR20170049191A (en) | Image processing apparatus and Image processing method | |
US11501418B2 (en) | Multi-level lookup tables for control point processing and histogram collection | |
KR20220010297A (en) | Edge-based sharpness strength control circuit, image sensing device and operation method thereof | |
Blasinski et al. | Real-time, color image barrel distortion removal | |
Luo et al. | Improved LUT-based image warping for video cameras | |
US20220292344A1 (en) | Processing data in pixel-to-pixel neural networks | |
JP2018191154A (en) | Image processing apparatus, image processing method, and program | |
KR20220004315A (en) | Image processing apparatus for reducing the amount of calculation in MCU | |
Thevenin et al. | Embedded processor extensions for image processing |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
STPP | Information on status: patent application and granting procedure in general |
Free format text: DOCKETED NEW CASE - READY FOR EXAMINATION |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:SADAT KOOCH MOHTASHA, SEYED HOSSEIN;ROMANENKO, YURIY ALEKSANDROVICH;OIZUMI, MUNENORI;SIGNING DATES FROM 20230913 TO 20230919;REEL/FRAME:064995/0225 |