US11551159B2 - Schema-guided response generation - Google Patents
Schema-guided response generation Download PDFInfo
- Publication number
- US11551159B2 US11551159B2 US16/724,604 US201916724604A US11551159B2 US 11551159 B2 US11551159 B2 US 11551159B2 US 201916724604 A US201916724604 A US 201916724604A US 11551159 B2 US11551159 B2 US 11551159B2
- Authority
- US
- United States
- Prior art keywords
- schema
- natural language
- service
- computing system
- api
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
- 230000004044 response Effects 0.000 title claims abstract description 80
- 238000000034 method Methods 0.000 claims abstract description 65
- 238000012545 processing Methods 0.000 claims description 20
- 230000006870 function Effects 0.000 claims description 18
- 230000009471 action Effects 0.000 claims description 14
- 238000009826 distribution Methods 0.000 claims description 14
- 230000005236 sound signal Effects 0.000 claims description 5
- 239000008186 active pharmaceutical agent Substances 0.000 claims 1
- 238000001514 detection method Methods 0.000 claims 1
- 230000008569 process Effects 0.000 abstract description 17
- 238000003058 natural language processing Methods 0.000 abstract description 9
- 238000013473 artificial intelligence Methods 0.000 abstract description 8
- 230000008901 benefit Effects 0.000 abstract description 8
- 238000004891 communication Methods 0.000 description 18
- 238000013459 approach Methods 0.000 description 11
- 238000013528 artificial neural network Methods 0.000 description 8
- 238000010586 diagram Methods 0.000 description 6
- 230000010006 flight Effects 0.000 description 6
- 238000012549 training Methods 0.000 description 4
- 230000004913 activation Effects 0.000 description 3
- 230000008859 change Effects 0.000 description 3
- 238000007792 addition Methods 0.000 description 2
- 230000004075 alteration Effects 0.000 description 2
- 241001522316 Pyrrhula pyrrhula Species 0.000 description 1
- 230000003213 activating effect Effects 0.000 description 1
- 230000005540 biological transmission Effects 0.000 description 1
- 230000001143 conditioned effect Effects 0.000 description 1
- 238000013500 data storage Methods 0.000 description 1
- 238000013135 deep learning Methods 0.000 description 1
- 238000005516 engineering process Methods 0.000 description 1
- 238000001914 filtration Methods 0.000 description 1
- 230000010354 integration Effects 0.000 description 1
- 230000003993 interaction Effects 0.000 description 1
- 238000012423 maintenance Methods 0.000 description 1
- 238000013507 mapping Methods 0.000 description 1
- 230000007246 mechanism Effects 0.000 description 1
- 238000012986 modification Methods 0.000 description 1
- 230000004048 modification Effects 0.000 description 1
- 230000008520 organization Effects 0.000 description 1
- 238000012358 sourcing Methods 0.000 description 1
- 230000001131 transforming effect Effects 0.000 description 1
- 230000001755 vocal effect Effects 0.000 description 1
Images
Classifications
-
- G06Q50/40—
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/21—Design, administration or maintenance of databases
- G06F16/211—Schema design and management
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/20—Information retrieval; Database structures therefor; File system structures therefor of structured data, e.g. relational data
- G06F16/24—Querying
- G06F16/242—Query formulation
- G06F16/243—Natural language query formulation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/20—Natural language analysis
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/30—Semantic analysis
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F9/00—Arrangements for program control, e.g. control units
- G06F9/06—Arrangements for program control, e.g. control units using stored programs, i.e. using an internal store of processing equipment to receive or retain programs
- G06F9/46—Multiprogramming arrangements
- G06F9/54—Interprogram communication
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q10/00—Administration; Management
- G06Q10/02—Reservations, e.g. for tickets, services or events
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q50/00—Systems or methods specially adapted for specific business sectors, e.g. utilities or tourism
- G06Q50/30—Transportation; Communications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/045—Combinations of networks
Definitions
- the present disclosure relates generally to natural language processing. More particularly, the present disclosure relates to computer-implemented systems and methods which can process natural language descriptions of application services and natural language descriptions of user inputs to determine a system response. Aspects of the present disclosure can further include processing the natural language descriptions to generate embeddings and using the embeddings to determine the system response which can include a dialogue state.
- Today's virtual assistants e.g., an artificial intelligence-based software agent help users to accomplish a wide variety of tasks, including finding flights, searching for nearby events and movies, making reservations, sourcing information from the web and more. They provide this functionality by offering a unified natural language interface to a wide variety of services across the web.
- the present disclosure is directed to systems and methods for performing task-oriented response generation that can provide advantages for artificial intelligence systems or other computing systems that include natural language processing for interpreting user input.
- Example implementations can process natural language descriptions of various services that can be accessed by the system.
- systems can identify relevant values for executing one of the services, based in part on providing representations of the natural language input and the natural language description to a machine learned model.
- One example aspect of the present disclosure is directed to systems including models such as natural language encoders that can receive a natural language input and output an embedding based on the natural language input.
- a system task e.g., a predicted dialogue state, an API query to an API associated with the service, a predicted dialogue policy, and/or a natural language response
- the natural language encoder can be configured to generate one embedding from a user input (e.g., a request to use a service) and a second embedding generated from the natural language description of a service (e.g., a description of a function of the service).
- a machine learned model e.g., a neural network
- FIG. 1 A depicts an example computing system according to example implementations of the present disclosure.
- FIG. 1 B depicts an example computing device including one or more applications in communication with a dialogue state model according to example implementations of the present disclosure.
- FIG. 1 C depicts an example aspect of example implementations according to the present disclosure showing an example schema
- FIG. 2 depicts an example dialogue state model including a dialogue state predictor.
- the dialogue state model is shown receiving embedded representations to determine output data according to example implementations of the present disclosure.
- FIG. 3 depicts another example dialogue state model including a natural language encoder and a dialogue state predictor according to example implementations of the present disclosure.
- FIG. 3 depicts an alternate input displaying a schema and user input provided to the dialogue state model to determine output data.
- FIG. 4 depicts an example process flow diagram illustrating an example process for determining output such as a predicted dialogue state, application response data, or a NL response from AI to human according to example implementations of the present disclosure.
- FIG. 5 depicts a flow chart displaying an example method according to example implementations of the present disclosure.
- FIG. 6 depicts an example user-system dialogue generated according to example implementations of the present disclosure.
- FIG. 7 depicts an example structure of an example encoder model, BERT, for use in certain implementations according to the present disclosure.
- the present disclosure provides systems and methods for performing task-oriented response generation that can provide advantages for artificial intelligence systems or other computing systems that include natural language processing for interpreting user input.
- aspects of the present disclosure are directed to a schema-guided approach for building virtual assistants.
- Example implementations of the proposed approach enable utilization of a single model across multiple disparate services and domains, with no domain-specific parameters.
- a pre-trained language model can be used to generate schema embedding(s) for natural language description(s) of a schema for one or more inputs to an application programming interface (API) associated with performance of a service.
- the language model can be used to generate content embedding(s) for natural language content associated with user input(s) (e.g., text entered into the dialogue by a user).
- a computing system can perform various dialogue tasks based at least in part on the one or more schema embeddings and/or the one or more content embeddings.
- the tasks can include determining: a predicted dialogue state, an API query to the API associated with the service, a predicted dialogue policy, and/or a natural language response to the user input(s) based on the embedding(s).
- each service or API provides a natural language description of the functions listed in its schema along with their associated attributes. These descriptions can then be used to learn a distributed semantic representation of the schema (e.g., a schema embedding), which can be given as an additional input to the dialogue system.
- the dialogue system can then be implemented as a single unified model, containing no domain or service specific parameters. This unified model facilitates representation of common knowledge between similar concepts in different services, while the use of distributed representations of the schema makes it possible to operate over new services that are not present in the training data.
- an example computing system can include or have access to one or more remote or local applications or services which have application programming interfaces (APIs) that provide protocols for performing or requesting performance of a function or service.
- the example computing system can include a virtual assistant which can interact with a user via a dialogue (e.g., a textual or verbal dialogue).
- the virtual assist and/or an associated computing system
- Response generation can include identifying and/or performing the function or service offered by one of the remote or local applications or services.
- the virtual assistant may interact with the remote or local application or service via a pre-defined API associated with the application or service.
- the virtual assistant may not need to be explicitly programmed to handle communications according to such APIs.
- a schema-guided approach can be employed in which a virtual assistant (or other dialogue system) operates on distributed semantic representations (e.g., embeddings) of the schema of the API generated by a natural language encoder model from natural language descriptions of the schema of the API.
- a computing system can obtain information related to the APIs of the function or service, such as a schema for the inputs to the API.
- the information can include a natural language (NL) description of the function/service as well as natural language description(s) of any input(s) for performing the function/service and/or the schema itself.
- the system can also include components and/or instructions for obtaining a user input (e.g., a request to book a flight), in the form of a natural language (NL) description.
- the example system can process some or all of the schema NL descriptions as well as the user NL description from the user input using a natural language encoder to obtain one or more schema embeddings and one or more content embeddings, respectively. Based at least on one or both sets of embeddings (schema and content), the system can determine a next action.
- example systems may utilize a machine learned model to execute one or more tasks such as determining a predicted dialogue state, generating an API query to the API associated with the service, determining a predicted dialogue policy, or generating a natural language response to the one or more user inputs.
- a machine learned model to execute one or more tasks such as determining a predicted dialogue state, generating an API query to the API associated with the service, determining a predicted dialogue policy, or generating a natural language response to the one or more user inputs.
- Example implementations of the present disclosure can realize these advantages using a single model configured to determine a response based on paring embedded representations of system natural language descriptions with embedded representations of natural language inputs, rather than using an individually trained model for each service. Additionally, by not using models that are trained individually for each service, implementations are robust to updates in services and need not be retrained when a service is modified (e.g., to change the inputs) as well as the addition of new services. Thus, example implementations of the present disclosure enable “zero-shot” dialogue tasks to be performed on previously un-seen application or service APIs.
- a user trying to book a flight using an example device may prompt the device “find direct round trip flights from Baltimore to Seattle.”
- the device can process the user prompt to generate a content embedding and obtain a schema associated with performing a travel booking service.
- the schema may include one or more inputs that are each associated with a natural language description of the respective input.
- the device can also process the schema to generate a schema embedding and provide both the schema embedding and the content embedding to a trained model in accordance with the present disclosure.
- the device can determine the dialogue state which can include assigning values to the one or more inputs.
- the device may also provide the one or more inputs assigned by the model to the API to cause the API to attempt to execute the service and/or provide application response data that can be used to determine a device policy or device response.
- the device response can include accessing natural language descriptions of available actions that may be processed by a natural language generator, alone or in combination with the device policy, to output a natural language response.
- the natural language response can be provided as audio using a speaker in communication with the device. Every user prompt may not fulfill all of the inputs or other requirements for executing the service. In such cases, the device may continue to update the dialogue state by requesting a second user prompt.
- Example systems can process the second user prompt and/or additional user prompts to create subsequent embeddings that can be stored or aggregated.
- example devices can be used to perform task-oriented response generation by predicting a current state for performing the task using system level descriptions in combination with user input(s).
- implementations according to the present disclosure can utilize a model configured to predict some or all elements of the schema based on natural language descriptions associated with the elements and in combination with natural language input received by the system (such as user input).
- a schema can include at least the following elements: a set of intents, a set of inputs, and a set of values that can be taken by the inputs and/or the intents.
- the model can determine probability distributions for assigning values from the set of values to certain inputs and/or certain intents.
- probability distributions can be referred to as an active intents parameter which can define the current action preformed by the system (e.g., determining a departure date for a flight booking services), a requested inputs parameter which can define available inputs from the set of one or more inputs, and a user goals parameter which can define values assigned to available inputs.
- an active intents parameter which can define the current action preformed by the system (e.g., determining a departure date for a flight booking services)
- a requested inputs parameter which can define available inputs from the set of one or more inputs
- a user goals parameter which can define values assigned to available inputs.
- only one active intent may be available for any one service and so the active intent parameter may be omitted or may be determined at an application/API level.
- the model may only be configured to determine the requested inputs parameter and the user goal parameter.
- a service may include multiple intents for which the active intent parameter can be predicted.
- aspects of the requested inputs parameter can include the subset of inputs with values provided in the current user prompt (e.g., flying out May 16 and returning May 20). While the user prompt generally includes values, these values may be related to inputs included in the schema using the machine-learned model and so embedded representations of both the user prompt and the schema can be used to determine probability distributions for possible inputs requested by the current user input as well as possible values for said inputs.
- aspects of the user goal parameter can include the set of all constraints/inputs specified till the current user prompt (e.g., booking a flight; departing Baltimore May 16; arriving Seattle; returning Baltimore May 20).
- the user goal parameter can be determined based on predicting the difference in the user goal at the previous dialogue state and the current dialogue state.
- Example implementations can accumulate user goal updates to determine the predicted user goal parameter.
- Convergence of user goal updates and/or a system response indicating that the service can be executed by the API may be used to provide a signal indicating that the model can select a terminating natural language description.
- This information can be provided to a natural language decoder to generate a natural language response from the device to a user (e.g., “ok, found several flights with prices between 300 to 500 dollars”).
- the system may determine a policy response that includes requesting a value for a schema input (e.g., a schema input that has not been assigned or that the assigned value should change).
- the system may access a policy selector to determine a policy response indicating the unassigned and/or incorrect input.
- the policy response can be provided to a natural language generator for generating a natural language response that would be understood by a person.
- the system may then relay the natural language response as audio for the user (e.g., “what day would you like to depart?”).
- the model may be configured to predict additional distributions used to assist in assigning values to certain inputs and/or intents in the case of multiple intents.
- determining the user goal parameter can include assigning a status to each of the inputs included in the schema and, determining a value for the input based on the input status.
- Example trained models for assigning an input status can be configured to predict whether an input should remain unchanged based on the current user prompt, whether an input is unnecessary based on the active intent, or whether a value should be predicted and assigned to the input.
- the model can be configured to determine logits based on the current content embedding (e.g., the embedding produced from processing the current user prompt) and the schema embedding.
- the schema embedding may be limited to the embedding for the natural language description associated with the input for which a value is currently being predicted.
- example devices can access various applications for a wide variety of services including weather forecast, travel booking, playing music, and other domain areas.
- the device can convert the audio signal into data that can be processed by the system to generate an output such as performing a task. While the user providing the prompt may only understand voice responses from the device, it should be understood that implementations more generally operate to perform task-oriented response generation, which can include predicting a dialogue state, an API query to the API associated with the service, a predicted dialogue policy, and/or a natural language response.
- Example implementations according to the present disclosure can include operations that may be executed on computing devices.
- the computing devices may include features such as artificial intelligence assistants that can or can access a plurality of applications through associated APIs.
- Each of the APIs can be configured to perform functions/services based on the receipt of one or more inputs. Since each API can perform one or more services, each service may be associated with a schema defining one or more inputs for performing the service associated with the schema.
- Example devices can also include natural language processing engines that can process a natural language input such as a user prompt or a text description to produce one or more embeddings according to example methods disclosed herein. Based on the embeddings, example devices may further utilize trained models to track dialogue state and/or predict device policy.
- One example implementation according to the present disclosure includes a computer implemented method for performing task-oriented response generation. Aspects of the method can include: obtaining a natural language description of a schema.
- the schema can define one or more inputs to an application programming interface (API) associated with performing a service. Each of the one or more inputs can have a respective natural language description.
- API application programming interface
- the schema as a whole may have a general natural language description that may include one or more keywords that may be used to identify the service based on an initial user request.
- obtaining the natural language description of the schema can be performed for one or more schemas.
- methods can also include obtaining a natural language description of a second schema.
- the natural language description of the second schema can be different or the same as the natural language description of the schema.
- the natural language description of the second schema can define one or more second inputs to the same API or to a second application programming interface (API), the second schema associated with performing a second service.
- API application programming interface
- the method can also include processing the natural language description of the schema and/or the second schema to obtain one or more schema embeddings and/or second schema embeddings. Since the schema are each associated a service that can be performed by an example system (e.g., by providing one or more inputs to an API), the schema embeddings may be obtained each time the method is executed by the system. Alternatively, schema embeddings may be generated for each application and stored for later access.
- aspects of obtaining the natural language description of the schema can include determining or selecting a schema from a group of schemas. For instance, the method may determine the schema to obtain or the schema embedding to obtain based at least in part on receiving natural language data descriptive of textual content from one or more user inputs. Thus, the example method can further include obtaining natural language data such as a voice recording (e.g., a user prompt).
- a voice recording e.g., a user prompt
- the method can process natural language data using the machine-learned natural language encoder to obtain one or more content embeddings. Based at least in part one the one or more content embeddings and the one or more schema embeddings, the method can also include determining one or more tasks such as: a predicted dialogue state, an API query to the API associated with the service, a predicted dialogue policy, and a natural language response to the one or more user inputs.
- determining the predicted dialogue state can include at least determining a user intent defining one or more goals, where each of the goals is associated with at least one input of the one or more inputs defining the schema. Since implementations according to the present disclosure can include a plurality of services each associated with a respective schema, the user intent may be determined solely from inputs associated with a first schema or in combination with second inputs associated with a second schema. In this manner, determining the predicted dialogue state can include determining a schema from a group of one or more schemas. For instance, the machine-learned model can output logits for assigning a value to one of the one or more inputs, one of the one or more second inputs, or both.
- the model may assign values only to inputs associated with the first schema or second inputs associated with the second schema. Further, implementations may track the predicted dialogue state or updates to the predicted dialogue state by saving or otherwise recording the value(s) assigned to the one or more inputs or the one or more second inputs.
- the method can include generating the API query to the API associated with the service or the second service based at least on the predicted dialogue state.
- the predicted dialogue state can include values assigned to some threshold selection of the one or more inputs and/or the one or more second inputs.
- Example thresholds can include an assigned value to one input, assigned values to all required inputs (e.g., certain inputs), or assigned values to all inputs.
- Generating the API query can also include logic and/or syntax derived from the API for performing the service by providing the assigned values associated with the inputs to the API. In this manner, the predicted dialogue state can be used generate an API query.
- the method may further include submitting the API query to the API associated with the service or the second service.
- Aspects of submitting the API query can include receiving a dataset that includes a response from the API associated with the service or the second service.
- the dataset including the response can include information for determining the predicted dialogue policy, the natural language response, or both based on the dataset.
- the service can include a travel booking service
- the API query can request a booking action by an application associated with the booking service.
- implementations can determine system tasks over a series of user actions. For example, methods can further include generating a system response based at least in part on the content embedding.
- the system response can include a natural language response which may be provided (e.g., using a speaker) to a user.
- Further aspects can include receiving a user response (e.g., a second user input) including natural language data that may be processed using a machine-learned natural language encoder to generate one or more response embeddings.
- methods can update at least one of the one or more tasks such as the predicted dialogue state.
- aspects of updating the predicted dialogue state can include comparing the one or more goals determined based on the one or more response embeddings with the one or more goals determined based on the one or more content embeddings.
- neural networks such as BERT.
- the neural networks can be configured to take two sequences (e.g., p and q) as input and, based on the input, the neural network can output an embedded sequence pair representation and/or token level representation.
- the neural networks can include a variety of configurations including one or more hidden layers. Further the embedding can be generated from one of the hidden layers or from a combination of hidden layers produced by the neural network.
- the systems may include or otherwise have access to a database including one or more schema sets each including at least one schema.
- Each schema set can be associated with one API of a plurality of APIs and each schema included in one of the schema sets can be associated with performing a respective service.
- example implementations may define a hierarchy of actions such as first identifying a schema set associated with an API. Then identifying a schema within the schema set.
- example methods may include filtering operations that can be included as part of obtaining the schema or one or more schema embeddings.
- certain methods can further include identifying the service from a plurality of services based at least in part on the one or more user inputs.
- aspects of computing systems, devices, and methods according to the disclosure include natural language processing models. These models may be configured to access or receive input such as audio signals that can be received by a microphone included in the device or in communication with the device. While natural language descriptions are exemplified throughout using audio examples, embodiments according to the present disclosure are not limited solely to audio processing. Content embeddings or other embeddings may also be produced from user input in the form of text (e.g., by typing a request on an interface in communication with an example system). Further, example systems and methods can include operations for providing a response to a user. For example, output from a policy model or natural language generator may be provided to a speaker in communication with the system to output the natural language response as audio to a user.
- FIG. 1 A depicts a block diagram of an example computing system 100 for performing task-oriented response generation according to example embodiments of the present disclosure.
- the system 100 can include a user computing device 102 and/or a server computing system 130 that for some implementations can be communicatively coupled over a network 180 .
- the user computing device 102 can be any type of computing device, such as, for example, a personal computing device (e.g., laptop or desktop), a mobile computing device (e.g., smartphone or tablet), a gaming console or controller, a wearable computing device, an embedded computing device, or any other type of computing device.
- a personal computing device e.g., laptop or desktop
- a mobile computing device e.g., smartphone or tablet
- a gaming console or controller e.g., a gaming console or controller
- a wearable computing device e.g., an embedded computing device, or any other type of computing device.
- the user computing device 102 can include one or more processors 112 and memory 114 .
- the one or more processors 112 can be, for example, any suitable processing device (e.g., a processor core, a microprocessor, an ASIC, a FPGA, a controller, a microcontroller, etc.) and can be one processor or a plurality of processors that are operatively connected.
- the memory 114 can include one or more non-transitory computer-readable storage mediums, such as RAM, ROM, EEPROM, EPROM, flash memory devices, magnetic disks, etc., and combinations thereof.
- the memory 114 can store data 116 and instructions 118 which are executed by the one or more processors 112 to cause the user computing device 102 to perform operations.
- the user computing device 102 can store or access one or more dialogue state models 120 .
- the dialogue state models 120 can be or can otherwise include various natural language processing features such as voice to text, natural language encoders, or other similar methods for converting natural language to an embedded representation.
- the dialogue state models 120 can also include dialogue state predictors configured to determine probability distributions for assigning values to one or more inputs of a schema. Aspects of the schema can include natural language descriptions associated with each of the one or more inputs as well as possible values that some or all of the one or more inputs may be assigned.
- the one or more dialogue state models 120 can be received from the server computing system 130 over network 180 , stored in the user computing device memory 114 , and then used or otherwise implemented by the one or more processors 112 .
- the user computing device 102 can implement multiple parallel instances of a single dialogue state model 120 (e.g., to perform natural language processing and/or dialogue state prediction in parallel.) These use cases may provide advantages for processing large numbers of schema, for example, when a user computing device has access to a large number of applications each associated with different APIs.
- the dialogue state model 120 can function to perform operations such as processing natural language descriptions, determining a predicted dialogue state that can include assigning one or more values to possible schema inputs, determining an API query to an API associated with the schema, determining a predicted dialogue policy based on communication with a policy selector, and/or determining a natural language response based on communication with a natural language decoder.
- the dialogue state model 120 can include or be in communication with other models for performing instructions 118 included as part of the memory 114 . Instructions 118 for other models may be executed to obtain application response data generated by providing the predicted dialogue state to an application using an associated API. Additionally or alternatively, the predicted dialogue state may be provided to a policy selector configured to determine possible operations in accordance with device and/or application actions. Additionally or alternatively, the predicted dialogue state may be provided to a natural language generator configured to decode a system response such as assigned input values to generate a natural language response that would be interpretable by a human. Further, while the predicted dialogue state may be provided to the natural language generator as system predictions using the dialogue state predictor, intermediate values such as embeddings produced by the natural language encoder may be provided in addition or in lieu of the predicted dialogue state.
- the server computing system 130 can include one or more processors 132 and a memory 134 .
- the one or more processors 132 can be any suitable processing device (e.g., a processor core, a microprocessor, an ASIC, a FPGA, a controller, a microcontroller, etc.) and can be one processor or a plurality of processors that are operatively connected.
- the memory 134 can include one or more non-transitory computer-readable storage mediums, such as RAM, ROM, EEPROM, EPROM, flash memory devices, magnetic disks, etc., and combinations thereof.
- the memory 134 can store data 136 and instructions 138 which are executed by the processor 132 to cause the server computing system 130 to perform operations.
- the server computing system 130 may include or is otherwise implemented by one or more server computing devices. In instances in which the server computing system 130 includes plural server computing devices, such server computing devices can operate according to sequential computing architectures, parallel computing architectures, or some combination thereof.
- the server computing system 130 can store or otherwise include one or more dialogue state models 140 .
- the dialogue state models 140 can be or can otherwise include various natural language processing capability and machine-learned models.
- the network 180 can be any type of communications network, such as a local area network (e.g., intranet), wide area network (e.g., Internet), or some combination thereof and can include any number of wired or wireless links.
- communication over the network 180 can be carried via any type of wired and/or wireless connection, using a wide variety of communication protocols (e.g., TCP/IP, HTTP, SMTP, FTP), encodings or formats (e.g., HTML, XML), and/or protection schemes (e.g., VPN, secure HTTP, SSL).
- FIG. 1 A illustrates one example computing system 100 that can be used to implement the present disclosure.
- Other computing systems 100 can be used as well.
- the user computing device 102 can include additional components such as a speaker and/or a display for providing a natural language response.
- the user computing device 102 may also include a microphone for receiving natural language input in the form of audio.
- the display or a keyboard in communication with the user computing device 102 may be used to transmit natural language input in the form of text.
- the user computing device 102 and/or the server computing system 130 can include or have access to one or more computing devices 50 which can together include a number of applications (e.g., applications 1 through N).
- FIG. 1 B depicts one example computing device 50 .
- each application can contain include an application programming interface (API) for accessing one or more services performed by the application (e.g., flights, alarms, restaurants, media, hotels, ride sharing, rental services, movies, weather, music, homes, events banks, etc.)
- API application programming interface
- each application can communicate with one or more other components of the computing device, such as, for example, one or more sensors, a context manager, a device state component, and/or additional components such as machine learned models or natural language encoders.
- each application can communicate with each device component using a system API (e.g., a public API).
- the API used by each application is specific to that application.
- example implementations according to the present disclosure can each include an API for providing one or more services each associated with a schema.
- Each schema can include natural language descriptions of the service as well as natural language descriptions for one or more inputs used by the API to perform the service.
- the schema can also include values that may be associated with the one or more inputs. For instance, values for a flight service including can include airport codes, dates, number of stops, etc.
- each of these applications are in communication with a single dialogue state model, which can allow for improved communication between services.
- the dialogue state model can interface with a central device layer to communicate model outputs to adjust the device state or provide context parameters such as device policies for data transmission or output. For instance, at certain points a device component such as a microphone may need to be activated to receive user input. Based on an output of the dialogue state model, the device may activate one or more additional components or sensor(s) to receive new user input such as natural language data. As another example, at certain points a device component such as a speaker may need to be activated to transmit audio data.
- aspects of implementations according to the present disclosure can include communication protocols for transmitting data by activating or deactivating certain features of an example computing device 50 based at least in part on output of the dialogue state model.
- FIG. 2 depicts a block diagram of an example dialogue state model 200 according to the present disclosure.
- the dialogue state model 200 can include a dialogue state predictor 202 configured to provide output data 206 based on the receipt of one or more embedded representations 204 .
- Example embedded representations can include embeddings derived from natural language descriptions such as descriptions of schema elements and user inputs.
- the output data 206 can be in the form of computing system responses that can be provided to application APIs, device context managers and/or policy selectors, natural language generators, or other components to provide additional processing.
- dialogue state tracking is used to perform task-oriented response generation which may ultimately be provided in the form of a natural language response from a device including the dialogue state model 200 to a user.
- aspects of example methods and systems include the ability to track dialogue state, thus output data 206 may represent updates to a previous dialogue state.
- FIG. 3 depicts a block diagram of another example dialogue state model 300 according to the present disclosure.
- the dialogue state model 300 more explicitly demonstrates how natural language descriptions of schema and user input 304 may be obtained by a component of the dialogue state model 300 such as a natural language encoder 302 configured to generate an embedding based on receiving a natural language description.
- the output from the natural language encoder 302 including the embeddings are provided 306 to a dialogue state predictor 202 configured to perform similar operations as described in FIG. 2 .
- example dialogue state models 200 300 may include various configurations of components such as the natural language encoder 302 and the dialogue state predictor 202 . Further these components may be stored separately on different devices that are in communication with one another or may be included on the same device as part of a single model configured to perform sequential processing of example inputs.
- FIG. 4 displays an example process flow diagram of an example method for determining response generation according to example implementations of the present disclosure.
- FIG. 4 displays inputs including a natural language (NL) description of a schema 402 and natural language (NL) description of a user input 404 provided to a natural language encoder 406 to produce a schema embedding 408 and content embedding 410 , respectively.
- NL natural language
- NL natural language
- a dialogue state predictor 412 can generate a predicted dialogue state 414 .
- the predicted dialogue state 414 can include information related to preforming a service such as assigning values to inputs for performing a service associated with an application API 416 .
- the application API 416 can process information, such as included as part of the predicted dialogue state 414 .
- the application API 416 may generate, based at least in part on the predicted dialogue state 414 , a response including application response data 418 .
- Application response data 418 may be provided to a policy selector 420 in combination with one or more of natural language (NL) descriptions of available system actions 422 , the predicted dialogue state 414 and/or the schema embedding 408 and content embedding 410 to determine a device policy 424 indicative of allowable actions as well as descriptions of allowable actions that the device may perform.
- NL natural language
- a natural language encoder/generator 426 may be used to process the device policy 424 from the policy selector 420 and/or based on the predicted dialogue state 414 to generate a natural language (NL) response from the device (AI) to a human 428 .
- NL natural language
- implementations according to the present disclosure may be used to generate responses to human prompts that can be communicated by an artificial intelligence (AI) system.
- AI artificial intelligence
- FIG. 5 depicts a flow chart diagram of an example method for generating training data according to example embodiments of the present disclosure.
- FIG. 5 depicts steps performed in a particular order for purposes of illustration and discussion, methods of the present disclosure are not limited to the particularly illustrated order or arrangement.
- the various steps of the method 500 can be omitted, rearranged, combined, and/or adapted in various ways without deviating from the scope of the present disclosure.
- a computing system can obtain a natural language description of a schema comprising one or more inputs to an application programming interface (API) associated with performing a service.
- API application programming interface
- obtaining the natural language description can include accessing local or remote data storage such as local memory, traditional databases, cloud databases, or other similar components which include information descriptive of the schema.
- the computing system can process the natural language description of the schema using a machine-learned natural language encoder to obtain one or more schema embeddings.
- Example natural language encoders can include pre-trained neural networks such as BERT.
- the computing system can obtain natural language data descriptive of textual content that comprises one or more user inputs.
- implementations can include or be in communication components such as microphones, keyboards, touch screens, or other similar components for receiving a user input.
- the user input can be in the form of natural language (e.g., speech) that can be recorded by the system and stored for later processing or processed without storing.
- the computing system can process the natural language data using the machine-learned natural language encoder to obtain one or more content embeddings.
- example natural language encoders can include pre-trained neural networks such as BERT. Further, the same natural language encoder may be used to generate the one or more content embeddings as the natural language encoder used to generate the schema embeddings.
- the computing system can determine, based at least in part on the one or more schema embeddings and based at least in part on the one or more content embeddings, one or more tasks from the group: a predicted dialogue state, an API query to the API associated with the service, a predicted dialogue policy, and a natural language response to the one or more user inputs.
- the at least one task can include generating the predicted dialogue state.
- aspects of the predicted dialogue state can include a user intent defining one or more goals, each of the one or more goals is associated with at least one input of the schema used to generate the schema embedding.
- the user intent can also include data descriptive of a probability distribution including values for performing at least the service or a null service.
- the user intent may also include data descriptive of a second service associated with the same schema or a second schema.
- a machine-learned model can be trained to determine the probability distribution (e.g., using supervised or unsupervised, or a combination of training methods).
- the machine-learned model can be configured to take as input one schema embedding and one content embedding pair.
- the machine-learned model may be configured to determine predictions for at least one additional schema that an example system may have access to (e.g., for comparison to the schema).
- the machine learned model may be configured to receive as input one schema embedding and one content embedding pair or one second schema embedding and one content embedding pair, or both pairs of embeddings.
- FIG. 6 depicts an example dialogue between a user and an example computing system including a dialogue state model according to example implementations of the present disclosure.
- a user may prompt the example system “Find direct round trip flights from Baltimore to Seattle.”
- the dialogue model may identify an application including a service/function for searching flights.
- the function may include a schema having inputs such as origin, destination, number of stops (num_stops), departure date, return date, etc.
- the system can determine a dialogue state including assigning values to some or all of the inputs (e.g., in the first round of dialogue the computing system can predict the origin, destination, and number of stops).
- the API associated with the schema may indicate that further information is needed to generate a successful query.
- This information can be used to generate a natural language response from the system to the user such as “sure, what dates are you looking for?”
- the user may provide additional data in the form of a second user prompt such as “flying out May 16 and return May 20.”
- This information can be used to update the dialogue state including the predicting additional values for inputs while other inputs are left unchanged. Based on this information the system may provide a response such as “found one flight for 302 dollars.”
- one implementation in accordance with the present disclosure can include a single model shared among all services and domains.
- predictions can be conditioned on pertinent API's schemas using descriptions of intents and inputs.
- the model can be robust to unseen inputs from new APIs or when a change is made to an existing API.
- Using sufficiently trained natural language encoders such as ELMo (Peters et al. 2019) and BERT (Devlin et al. 2019) can provide one mechanism for providing such flexibility.
- these encoders still need to be coupled with a dialogue state predictor that is configured to understand a broad variety of domains using natural language descriptions tied to schema elements associated with the API inputs.
- the dialogue state tracking model can be configured to predict the active intent parameter, the requested inputs parameter, and the user goal parameter.
- the model also includes a natural language encoder for obtaining the embedded representations of the schema and the user prompt.
- an example schema can include a two-sequence format as displayed in Table 1.
- Table 1 includes several elements, an application for performing one or more services, inputs for performing one or more services for the application, and values for certain inputs.
- Each of these elements can be related through two sequences as shown. The sequences can be used to define relationships such as services related to the application or which an application can perform by an API call, inputs related to services or which are required to perform the API call by the service, and values that can be taken for certain inputs.
- each of these elements are provided in the form of natural language descriptions that can be provided to a trained natural language encoder.
- FIG. 1 C displays another representation of an example schema.
- the example schema depicts a service or application that can include a name and description.
- the schema also depicts one or more intents which each include a natural language description and a set of required slots (e.g., inputs) that can be used to execute the intent.
- the schema further depicts one or more slots which include natural language descriptions, a name, and may also include values that can be taken by the slot. While illustrated as possible values, it should be understood that the descriptions shown are provided to demonstrate an example configuration and that variations may be used depending on the service. Further one example advantage of implementations according to the present disclosure includes the ability for example systems and methods to handle various schema that can have varying numbers of slots/inputs and intents based on the inclusion of a natural language description.
- a BERT natural language encoder can take two sequences p and q as input and output an embedded sequence pair representation u CLS and token level representations ⁇ t 1 t n+m ⁇ .
- the BERT encoder can be used to obtain schema element embeddings and encode user prompts for dialogue state tracking.
- the BERT model can obtain embedded representations of services, inputs, and categorical input values in each schema. For instance, the sequences shown in Table 1 can be fed to a pretrained BERT encoder and the output u CLS used as the schema embedding.
- the utterance and schema embeddings are used together to obtain model predictions using a set of projections that can be defined as below.
- h 1 ; h 2 ⁇ d , W i T and b i T for 1 ⁇ i ⁇ 3 are trainable parameters of suitable dimensions and A is the activation function.
- An activation function such as gelu (Hendrycks and Gimpel 2016) activation as in BERT may be used as part of the projection task.
- h 1 A ( W 1 T +b 1 T ) (1)
- the active intent denotes the intent currently being processed by the system. It takes the value “NONE” if no intent for the service is currently being processed.
- i0 be a trainable parameter in Rd for the “NONE” intent.
- the intent network we define the intent network as below.
- l j F intent ( u;i j ;1),1 ⁇ j ⁇ I (4)
- the logits l j are normalized using softmax to yield a distribution over all I service plus the “NONE” service. During inference, we predict the highest probability intent as active.
- the model may predict the difference between the user goal for the current turn and preceding user turn.
- the predicted user goal updates are accumulated to yield the predicted user goal.
- Logits for a given categorical input are normalized using softmax to get a distribution over all possible values. The value with the maximum mass is assigned to the input.
- logits obtained using equations 8 and 9 are normalized using softmax to yield two distributions over all tokens. These two distributions respectively correspond to the start and end index of the span corresponding to the input.
- the indices i ⁇ j maximizing start[i]+end[j] are predicted to be the span boundary and the corresponding value is assigned to the input.
- the technology discussed herein makes reference to servers, databases, software applications, and other computer-based systems, as well as actions taken and information sent to and from such systems.
- the inherent flexibility of computer-based systems allows for a great variety of possible configurations, combinations, and divisions of tasks and functionality between and among components.
- processes discussed herein can be implemented using a single device or component or multiple devices or components working in combination.
- Databases and applications can be implemented on a single system or distributed across multiple systems. Distributed components can operate sequentially or in parallel.
Abstract
Description
TABLE 1 |
Example schema including example input |
sequences for a natural language encoder. |
|
|
|
Application | Service descriptions | Application description |
Input | Service descriptions | Input descriptions |
Value | Input descriptions | values |
h 1 =A(W 1 T +b 1 T) (1)
h 2 =A(W 2 T ⊕h 11)+b 2 T) (2)
1=W 1 T h 2 +b 3 T (3)
l j =F intent(u;i j;1),1≤j≤I (4)
The logits lj are normalized using softmax to yield a distribution over all I service plus the “NONE” service. During inference, we predict the highest probability intent as active.
l j =F req(u;s j;1);1≤j≤I (5)
1status j=
1value j,k=
1vstart j,k=
1end j,k=
In the second stage, equation 7 is used to obtain a logit for each value taken by each categorical input. Logits for a given categorical input are normalized using softmax to get a distribution over all possible values. The value with the maximum mass is assigned to the input. For each non-categorical input, logits obtained using equations 8 and 9 are normalized using softmax to yield two distributions over all tokens. These two distributions respectively correspond to the start and end index of the span corresponding to the input. The indices i≤j maximizing start[i]+end[j] are predicted to be the span boundary and the corresponding value is assigned to the input.
Claims (16)
Priority Applications (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US16/724,604 US11551159B2 (en) | 2019-12-23 | 2019-12-23 | Schema-guided response generation |
US18/152,553 US20230162098A1 (en) | 2019-12-23 | 2023-01-10 | Schema-Guided Response Generation |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US16/724,604 US11551159B2 (en) | 2019-12-23 | 2019-12-23 | Schema-guided response generation |
Related Child Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US18/152,553 Continuation US20230162098A1 (en) | 2019-12-23 | 2023-01-10 | Schema-Guided Response Generation |
Publications (2)
Publication Number | Publication Date |
---|---|
US20210192397A1 US20210192397A1 (en) | 2021-06-24 |
US11551159B2 true US11551159B2 (en) | 2023-01-10 |
Family
ID=76438928
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US16/724,604 Active 2041-03-12 US11551159B2 (en) | 2019-12-23 | 2019-12-23 | Schema-guided response generation |
US18/152,553 Pending US20230162098A1 (en) | 2019-12-23 | 2023-01-10 | Schema-Guided Response Generation |
Family Applications After (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US18/152,553 Pending US20230162098A1 (en) | 2019-12-23 | 2023-01-10 | Schema-Guided Response Generation |
Country Status (1)
Country | Link |
---|---|
US (2) | US11551159B2 (en) |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20210074279A1 (en) * | 2017-10-12 | 2021-03-11 | Google Llc | Determining state of automated assistant dialog |
Families Citing this family (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11599357B2 (en) * | 2020-01-31 | 2023-03-07 | International Business Machines Corporation | Schema-based machine-learning model task deduction |
US11720559B2 (en) * | 2020-06-02 | 2023-08-08 | Salesforce.Com, Inc. | Bridging textual and tabular data for cross domain text-to-query language semantic parsing with a pre-trained transformer language encoder and anchor text |
US11501754B2 (en) * | 2020-07-07 | 2022-11-15 | Beijing Didi Infinity Technology And Development Co., Ltd. | Specifying trip destinations from spoken dialogs |
US11481210B2 (en) * | 2020-12-29 | 2022-10-25 | X Development Llc | Conditioning autoregressive language model to improve code migration |
US20220277031A1 (en) * | 2021-03-01 | 2022-09-01 | International Business Machines Corporation | Guided exploration for conversational business intelligence |
US11501086B2 (en) * | 2021-04-05 | 2022-11-15 | ZeroShotBot, Inc. | Systems and methods for zero-shot, fast-generation and implementation of an intelligent virtual dialogue agent using one or more pre-trained machine learning-based language models and a response corpus |
Citations (10)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20160202957A1 (en) * | 2015-01-13 | 2016-07-14 | Microsoft Technology Licensing, Llc | Reactive agent development environment |
US9548050B2 (en) | 2010-01-18 | 2017-01-17 | Apple Inc. | Intelligent automated assistant |
WO2019074509A1 (en) | 2017-10-12 | 2019-04-18 | Google Llc | Determining state of automated assistant dialog |
US20190132264A1 (en) * | 2017-10-30 | 2019-05-02 | International Business Machines Corporation | Generation of a chatbot interface for an application programming interface |
US20200042642A1 (en) * | 2018-08-02 | 2020-02-06 | International Business Machines Corporation | Implicit dialog approach for creating conversational access to web content |
US20200192727A1 (en) * | 2017-04-25 | 2020-06-18 | Intento, Inc. | Intent-Based Organisation Of APIs |
US20200334730A1 (en) * | 2019-04-04 | 2020-10-22 | NuFronteer Media Inc. | Internet of Things (IoT) Configurator |
US20210182497A1 (en) * | 2019-12-17 | 2021-06-17 | Microsoft Technology Licensing, Llc | Conversational manifests for enabling complex bot communications |
US20210182126A1 (en) * | 2018-07-06 | 2021-06-17 | Capital One Services, Llc | Systems and methods to identify breaking application program interface changes |
US20210249001A1 (en) * | 2018-05-07 | 2021-08-12 | Bayerische Motoren Werke Aktiengesellschaft | Dialog System Capable of Semantic-Understanding Mapping Between User Intents and Machine Services |
-
2019
- 2019-12-23 US US16/724,604 patent/US11551159B2/en active Active
-
2023
- 2023-01-10 US US18/152,553 patent/US20230162098A1/en active Pending
Patent Citations (10)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9548050B2 (en) | 2010-01-18 | 2017-01-17 | Apple Inc. | Intelligent automated assistant |
US20160202957A1 (en) * | 2015-01-13 | 2016-07-14 | Microsoft Technology Licensing, Llc | Reactive agent development environment |
US20200192727A1 (en) * | 2017-04-25 | 2020-06-18 | Intento, Inc. | Intent-Based Organisation Of APIs |
WO2019074509A1 (en) | 2017-10-12 | 2019-04-18 | Google Llc | Determining state of automated assistant dialog |
US20190132264A1 (en) * | 2017-10-30 | 2019-05-02 | International Business Machines Corporation | Generation of a chatbot interface for an application programming interface |
US20210249001A1 (en) * | 2018-05-07 | 2021-08-12 | Bayerische Motoren Werke Aktiengesellschaft | Dialog System Capable of Semantic-Understanding Mapping Between User Intents and Machine Services |
US20210182126A1 (en) * | 2018-07-06 | 2021-06-17 | Capital One Services, Llc | Systems and methods to identify breaking application program interface changes |
US20200042642A1 (en) * | 2018-08-02 | 2020-02-06 | International Business Machines Corporation | Implicit dialog approach for creating conversational access to web content |
US20200334730A1 (en) * | 2019-04-04 | 2020-10-22 | NuFronteer Media Inc. | Internet of Things (IoT) Configurator |
US20210182497A1 (en) * | 2019-12-17 | 2021-06-17 | Microsoft Technology Licensing, Llc | Conversational manifests for enabling complex bot communications |
Non-Patent Citations (27)
Title |
---|
Bapna et al, "Towards Zero-Shot Frame Semantic Parsing for Domain Scaling", arXiv:1707v1, Jul. 7, 2017, 5 pages. |
Budzianowski et al, "Multiwoza Large-Scale Multi-Domain Wizard-of-Oz Dataset for Taskoriented Dialogue Modelling", arXiv:1810v3, Apr. 20, 2020, 14 pages. |
Chao et al. "BERT-DST: Scalable End-to-End Dialogue State Tracking with Bidirectional Encoder Representations from Transformer", arXiv:1907v1, Jul. 5, 2019, 5 pages. |
Devlin et al, "Bert: Pre-Training of Deep Bidirectional Transformers for Language Understanding", arXiv:1810v2, May 24, 2019, 16 pages. |
El Asri, ". Frames: A Corpus for Adding Memory to Goal-Oriented Dialogue Systems", arXiv:1704v2, Apr. 13, 2017, 17 pages. |
Eric, "Multiwoz 2.1: Multi-Domain Dialogue State Corrections and State Tracking Baselines", arXiv:1907v4, Dec. 3, 2019, 7 pages. |
Goel, ". HyST: A Hybrid Approach for Flexible and Accurate Dialogue State Tracking", arXiv:1907v1, Jul. 1, 2019, 5 pages. |
Hemphill et al., ". The ATIS Spoken Language Systems Pilot Corpus", Proceedings of a Workshop Held at Hidden Valley, Pennsylvania. Jun, 24-27, 1990, pp. 96-101. |
Henderson et al, "The Second Dialog State Tracking Challenge", In Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), 263-272. |
Henderson et al, "The Third Dialog State Tracking Challenge", Spoken Language Technology Workshop, 2014, pp. 324-329. |
Henderson et al, "Wordbased Dialog State Tracking with Recurrent Neural Networks", In Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pp. 292-299. |
Hendrycks et al., Gaussian error linear units (GELUS), arXiv:1606v3. Nov. 11, 2018, 9 pages. |
Kelley, "An Iterative Design Methodology for User-Friendly Natural Language Office Information Applications", Transactions on Information Systems, 2(1), pp. 26-41. |
Kim et al, "Efficient Large-Scale Neural Domain Classification with Personalized Attention", Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, pp. 2214-2224. |
Kim et al, "The Fourth Dialog State Tracking Challenge", Dialogues with Social Robots, pp. 435-449. |
Mrks{hacek over ( )}ic' et al, "Neural Belief Tracker: Data-Driven Dialogue State Tracking", arXiv:1606v2, Apr. 21, 2017, 12 pages. |
Peters et al., "Deep Contextualized Word Representations", arXiv:1802v2, Mar. 22, 2018, 15 pages. |
Rastogi et al, "Multitask Learning for Joint Language Understanding and Dialogue State Tracking", arXiv:1811v1, Nov. 13, 2018, 9 pages. |
Rastogi et al, "Scalable Multi-Domain Dialogue State Tracking", arXiv:1712v2, Jan. 2, 2018, 8 pages. |
Shah et al, "Building a Conversational Agent Overnight with Dialogue Self-Play", arXiv:1801v1, Jan. 15, 2018, 11 pages. |
Shah et al., "Robust Zero-Shot Cross-Domain Slot Filling with Example Values", arXiv:1906v1, Jun. 17, 2019, 7 pages. |
Wen et al, "A Network-Based End-to-End Trainable Task-Oriented Dialogue System", 15th Conference of the European Chapter of the Association for Computational Linguistics, vol. 1, p. 438-449. |
Williams et al, "The Dialog State Tracking Challenge", Proceedings of the SIGDIAL 2013 Conference, pp. 404-413. |
Wu et al, "Transferable Multi-Domain State Generator for Task-Oriented Dialogue Systems", arXiv:1905v2, May 26, 2019, 12 pages. |
Xia et al, "Zero-Shot User Intent Detection via Capsule Neural Networks", arXiv:1809v1, Sep. 2, 2018, 10 pages. |
Yang et al, ". Transfer Learning for Sequence Tagging with Hierarchical Recurrent Networks", arXiv:1703v1, Mar. 18, 2017, 10 pages. |
Zhang et al, "Global-Locally Self-Attentive Encoder for Dialogue State Tracking", Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, vol. 1, pp. 1458-1467. |
Cited By (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20210074279A1 (en) * | 2017-10-12 | 2021-03-11 | Google Llc | Determining state of automated assistant dialog |
US11790899B2 (en) * | 2017-10-12 | 2023-10-17 | Google Llc | Determining state of automated assistant dialog |
Also Published As
Publication number | Publication date |
---|---|
US20230162098A1 (en) | 2023-05-25 |
US20210192397A1 (en) | 2021-06-24 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11551159B2 (en) | Schema-guided response generation | |
US20230419074A1 (en) | Methods and systems for neural and cognitive processing | |
US11823289B2 (en) | User controlled task execution with task persistence for assistant systems | |
US11816439B2 (en) | Multi-turn dialogue response generation with template generation | |
US20230028944A1 (en) | Dialogue generation method and network training method and apparatus, storage medium, and device | |
EP3711000B1 (en) | Regularized neural network architecture search | |
US10713574B2 (en) | Cognitive distributed network | |
EP3411835B1 (en) | Augmenting neural networks with hierarchical external memory | |
US11295251B2 (en) | Intelligent opportunity recommendation | |
CN109101217A (en) | Method and system for purposefully calculating | |
EP3884426B1 (en) | Action classification in video clips using attention-based neural networks | |
US11715042B1 (en) | Interpretability of deep reinforcement learning models in assistant systems | |
US11481646B2 (en) | Selecting answer spans from electronic documents using neural networks | |
CN116802629A (en) | Multi-factor modeling for natural language processing | |
CN114945914A (en) | Reference expression generation | |
CN117296058A (en) | Variant Inconsistent Attacks (VIA) as a simple and effective method of combating attacks | |
CN116490879A (en) | Method and system for over-prediction in neural networks | |
CN116583837A (en) | Distance-based LOGIT values for natural language processing | |
CN116547676A (en) | Enhanced logic for natural language processing | |
CN111667069A (en) | Pre-training model compression method and device and electronic equipment | |
Yin et al. | Context-uncertainty-aware chatbot action selection via parameterized auxiliary reinforcement learning | |
Chakrabarti | Artificial conversations for chatter bots using knowledge representation, learning, and pragmatics | |
Trivedi et al. | Deep learning applications on edge computing | |
KR20220069403A (en) | Method and apparatus for sentiment analysis service including highlighting function | |
Perez | Dialog state tracking, a machine reading approach using a memory-enhanced neural network |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
FEPP | Fee payment procedure |
Free format text: ENTITY STATUS SET TO UNDISCOUNTED (ORIGINAL EVENT CODE: BIG.); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: APPLICATION DISPATCHED FROM PREEXAM, NOT YET DOCKETED |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:RASTOGI, ABHINAV KUMAR;GUPTA, RAGHAV;ZANG, XIAOXUE;AND OTHERS;SIGNING DATES FROM 20200206 TO 20200224;REEL/FRAME:051902/0590 |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: DOCKETED NEW CASE - READY FOR EXAMINATION |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NON FINAL ACTION MAILED |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: RESPONSE TO NON-FINAL OFFICE ACTION ENTERED AND FORWARDED TO EXAMINER |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NOTICE OF ALLOWANCE MAILED -- APPLICATION RECEIVED IN OFFICE OF PUBLICATIONS |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: AWAITING TC RESP., ISSUE FEE NOT PAID |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NOTICE OF ALLOWANCE MAILED -- APPLICATION RECEIVED IN OFFICE OF PUBLICATIONS |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: PUBLICATIONS -- ISSUE FEE PAYMENT VERIFIED |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |