US8218913B1 - Identifying a front page in media material - Google Patents
Identifying a front page in media material Download PDFInfo
- Publication number
- US8218913B1 US8218913B1 US12/190,176 US19017608A US8218913B1 US 8218913 B1 US8218913 B1 US 8218913B1 US 19017608 A US19017608 A US 19017608A US 8218913 B1 US8218913 B1 US 8218913B1
- Authority
- US
- United States
- Prior art keywords
- page
- front page
- media
- matching
- confidence score
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Expired - Fee Related, expires
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V30/00—Character recognition; Recognising digital ink; Document-oriented image-based pattern recognition
- G06V30/40—Document-oriented image-based pattern recognition
- G06V30/41—Analysis of document content
- G06V30/418—Document matching, e.g. of document images
Definitions
- Embodiments of the present invention relate to computer-aided analysis of media material.
- Computers can be used to perform or aid analysis of documents and printed material. For instance, techniques and systems have been developed to identify blocks of media material, such as columns in a newspaper, from text and images in a document. The identification of other portions of media material can be important in many document imaging applications. For example, the identification of lines, gutters and other intervening items may aid in the analysis of media material.
- FIG. 2 illustrates a system for assisting the identification of a front page, according to an embodiment of the present invention.
- FIG. 5 shows a flowchart illustrating a method for identifying a front page, according to an embodiment of the present invention.
- FIG. 6 shows a flowchart illustrating another method for identifying a front page, according to an embodiment of the present invention.
- Embodiments described herein refer to systems and methods for identifying a front page from a media image.
- Front page identification provides a solution to the inadequate dating and organizing of media material.
- Media material may include, but is not limited to, newspapers, magazines, catalogues, brochures, pamphlets, and other types of print media.
- Media material may be scanned from an archived format. Such formats may include sequences of media images on microfilm, microfiche, electronic documents, or from any other archiving means.
- a media image may include one or more media pages. Once front pages are identified in a media image or sequence of media images, the sequence may be segmented into editions. Everything between a front page and the next front page may be considered an edition.
- beginning and ending dates in a roll may be used to fill in the intermediary dates. If beginning and ending dates in a roll are entered, manually or automatically, a system can then assign dates to the media pages in a roll.
- Embodiments of the present invention include methods and systems for identifying a front page from a media image.
- the term “front page” is used broadly herein to refer to a first page, cover page, or other page in a media material having one or more feature points indicative of a leading page.
- a front page can include but is not limited to a page having a masthead.
- Aspects of the present invention include using matching criteria to identify a front page of a newspaper in the presence of page defects and background clutter.
- FIG. 1 illustrates an exemplary system 100 for identifying at least one front page within an image representing media, according to an embodiment.
- System 100 includes matcher 110 , aggregator 120 , reviewer 130 and tagger 150 .
- System 100 (including its components) can be implemented to run on any type of processing device including, but not limited to, a computer, workstation, distributed computing system, embedded system, stand-alone electronic device, networked device, mobile device, set-top box, television, or other type of processor or computer system.
- Matcher 110 , aggregator 120 , reviewer 130 and tagger 150 may be coupled together directly or over a network.
- Matcher 110 may be configured to receive the image representing media having at least one page. Matcher 110 may also be configured to compare each page to at least one matching criterion to produce a matching confidence score for each page.
- a matching confidence score may be any representation relating to how well a page compares to matching criteria.
- Matching criteria may include one or more feature points. Matching criteria may also include descriptors of feature points. Feature points may be identified from a template page, according to an embodiment.
- a template page may include a sample page.
- a template may include a portion of a page.
- a template page may include a front page.
- a front page may be identified from a media image.
- a template page may be identified manually, semi-automatically, or automatically.
- matching criteria may include a template page. Matching criteria may include any set of reference points or descriptors to be used for comparison. According to an embodiment, matching criteria may also include a set of rules.
- Feature points may include any mark, location, portion of an image, group of pixels, or identifying feature for purposes of image analysis. Feature points may also be local, or pertain to certain locations of media material. According to another embodiment, feature points may include affine invariant feature points. Affine invariant feature points do not require that the image have a specific global orientation. Affine invariant feature points are analyzed independently and are thus more immune to defects in scanning such as image rotation, scaling, sizing, or translation.
- FIG. 3 shows media material having a masthead 300 .
- Local feature point 310 includes a corner of the first letter “T” in “The Times”.
- Second local feature point 320 includes a portion of the right top corner of a decorative image between “The” and “Times”.
- Local feature points 310 and 320 are distinguishable when considered independently. By contrast, other local points, such as those located in whitespace, may not be. Having a sufficient number of effective local feature points will assist with occlusion and disocclusion, where portions of an image may be missing, smudged, torn, smeared, marked, or suffering from any other scanning, printing, or handling defect. A match may still be found if enough local feature points are used.
- newspaper titles on different newspaper front pages may be related by affine transforms. That is, all affine invariant feature points from one image should be transformable into their respective matching feature point in the other images via a single affine transformation (within a margin of error).
- a RANSAC Random Sample Consensus
- a mismatch should be returned by the system.
- feature points may be affine invariant.
- Descriptor vectors for such affine invariant features may also be computed. For instance, a local feature point of a front page may be identified. In another image of the front page, which could be scaled, rotated, or translated with respect to the first front page, a local feature point at the same corresponding position may be located. The feature descriptor vectors would be the same, within a margin of error.
- fewer irrelevant feature points may be identified by whitening certain portions of a media page.
- feature points and descriptors may be computed for each candidate front page. Other embodiments may use different feature point identification or description schemes.
- Feature points may be identified by manual input, automatic algorithms, and/or self-learning.
- a local feature detector may be used to identify local features and/or to compute descriptors for those local features. Examples of local feature detectors, among others, include Hessian Affine, Difference of Gaussian Detector (DoG), or Harris Affine local feature detectors. Descriptors may include, among others, scale-invariant feature transform (SIFT) or gradient location and orientation histogram (GLOH) descriptors.
- SIFT scale-invariant feature transform
- GLOH gradient location and orientation histogram
- matcher 110 may be configured to identify a set of matching feature points. These matching feature points may form a feature point pair.
- a pair may include a feature point from a template front page and a feature point from a candidate front page.
- FIG. 4 shows a template front page masthead 410 and a slightly rotated candidate front page masthead 420 .
- Feature point pairs 430 - 460 are shown in FIG. 4 . All pairs of feature points may be examined to find a maximal set of “best match” pairs. If this maximal set is too small, a match may be rejected.
- finding a set of best match pairs may involve considering differences between identified feature points of a pair.
- finding best match pairs may involve finding feature points that are close to or closest to feature points of a template front page from a list of points.
- the quality or score of a match between a pair of feature points may be measured or aided by certain metrics between feature points.
- Metrics may include Euclidean distances.
- the distance between feature points 432 and 452 may be measured compared to the distance between feature points 434 and 454 . In this case, since the measured distances are similar, a higher matching score would be produced. However, the distance between feature points 432 and 442 is much different than the distance between feature points 434 and 444 and a lower matching score would be produced. Such differences may also affect how some feature points are used to determine a matching score.
- an affine transformation between two sets of feature points may be estimated via RANSAC.
- Matcher 110 may also produce a matching confidence score based upon the quality of a match, a score, a distance, an estimate, constraints, a scale factor, or any other determination relating to how feature points are matched and measured.
- matching may be performed using additional geometric constraints.
- a list of correspondences may be used. For example, a matching feature point for one corresponding feature, like the notch in a letter of a title, may be found. Analysis may then be performed for a certain distance to the right and then a certain distance downward. If another corresponding feature, such as a corner of another letter in a newspaper title, is found where it is expected, then the feature point is verified or the confidence score is increased. This analysis may be adjusted to accommodate scaling or rotation of a media page in a media image.
- images may also be scaled up or down to assist in analysis.
- median least squares may be used.
- a local feature detector such as a Laplacian of Gaussian (LoG) detector or a Difference of Gaussian (DoG) detector may be used to identify a number of feature points in a media page.
- Feature points may include local features, such as those identified as feature points 452 and 454 in FIG. 4 . These feature points may be descriptors identified with an algorithm such as scale-invariant feature transform (SIFT).
- SIFT scale-invariant feature transform
- feature points once feature points are identified in a media page, they may be matched with feature points in a template page. However, sometimes there are defects on the media page. Certain steps may be taken to help mitigate these defects. For example, if there are occlusions near feature points 452 and 454 , the area around feature points 452 and 454 may be whitened to eliminate any occlusional clutter.
- Analysis may then be performed for the feature points, according to this embodiment.
- Different types of analyses may be performed, including for the area directly around the feature points.
- analysis may be performed on the area below feature point 452 of the template page, wherein a portion of straight line 456 is found.
- Line 456 is one of the parallel lines that separates the printed date and price of the paper from the masthead and articles.
- the portion of line 456 below feature point 452 is a corresponding feature that may help verify feature points 452 and 454 .
- This analysis may also be performed for feature point 454 of the media page and for the area directly below.
- There is a straight line 458 below feature point 454 is oriented at an angle due to a rotational defect of the media page.
- an affine transformation may be performed on this pair of feature points.
- This may include a rotational transform of feature point 454 to rotate or reorient the portion of line 458 below feature point 454 to better match the feature point of 452 and its surrounding area.
- this feature point pair may receive a higher matching score.
- this affine transformation may be estimated using RANSAC. The transformation may be used because it is an inlier (as opposed to an outlier) in the model developed using RANSAC.
- This feature point pair may be included in a set of matching pairs, according to an embodiment.
- This set of matching pairs may be analyzed in order to assign a score to the media page as a whole. If the media page has a sufficient matching score, the media page may advance as a candidate front page. This candidate front page will then be aggregated with other front page candidates.
- System 100 includes aggregator 120 .
- Aggregator 120 may be configured to aggregate, as front page candidates, each page having a matching confidence score that exceeds a matching confidence score threshold. This threshold may be determined manually or automatically. This threshold may also be re-calibrated. Front page candidates may be aggregated from electronic images, scanned images, or data extracted by optical character recognition (OCR). According to another embodiment, front page candidates may be recorded with their matching confidence scores.
- OCR optical character recognition
- System 100 includes reviewer 130 .
- Reviewer 130 may be configured to receive decision information.
- Decision information may include a final decision 140 on whether a front page candidate is a front page.
- decision information may be generated manually by human decision.
- Reviewer 130 may be configured to enable a user to view and/or vote on front page candidates. A user may then input his or her votes on whether a front page candidate is an actual front page. For example, majority voting may be used to make a human decision. In this case, a front page candidate would be identified as an actual front page when it receives votes from a majority of users (reviewers), or a predetermined number of users. Such a human decision may be made with or without the further assistance of computer-aided analysis.
- decision information may be generated all or in part by computer analysis. Decision information may also be generated automatically or in combination with human analysis. Review 130 may be configured to identify front pages from front page candidates based upon decision information. According to a further embodiment, this identification of an actual front page may also be based upon a combination of decision information and matching confidence scores. According to another embodiment, identification may involve other data, modules or methods.
- Tagger 150 may be configured to tag, physically mark, or electronically mark front page candidates that have been identified as front pages. Tagging may be done in many different ways, as appreciated by those skilled in the art(s) of document analysis or imaging.
- System 100 may be assisted by identification support system 200 , as shown in FIG. 2 , according to an embodiment.
- System 200 may include patch clipper 210 , pre-binding module 220 , quality assurance module 230 , analysis continuity module 240 , and page dater 250 .
- Components of system 200 may be coupled together directly or over a network.
- any component of exemplary system 200 may exist separately from system 200 .
- any combination of the components shown in FIG. 2 may or may not be used.
- Patch clipper 210 may be configured to select patches of a page, rather than a whole template, for a comparison with matching criterion. Patches may be of various shapes and sizes. Patches may also be selected for being flawless or the proper size. Patches may include distinguishable places. For example, corners of a letter may be broken down into patches. Other examples of patches may include areas related to a list of correspondences, or locations that correspond to other locations. Patches for matching may be selected for various other strategic reasons. According to an embodiment, patch clipper 210 may work in cooperation with matcher 110 .
- Pre-binding module 220 may be configured to enable a user to identify an image, among images representing media, having at least one front page candidate. This image may be used as a template. It need not be the first such image in a series of images. Pre-binding module 220 may also be configured to allow a media image to be marked as to whether certain data, like a masthead, is visible or not.
- Quality assurance module 230 may be configured to enable a user to receive at least one request for input. For example, one or more questions or decisions to be made may be sent to a user or system module for further analysis or more information. The human or system module may provide an answer or additional information to quality assurance module 230 . An answer may also be provided regarding a date. Date recognition using OCR may reduce the number of questions. Quality assurance module 230 may be configured to provide an output for each front page candidate. Quality assurance module 230 may also be configured to store this additional information. Quality assurance module 230 may comprise a GUI or may be web-based. According to an embodiment, quality assurance module 230 may work in cooperation with reviewer 130 .
- Analysis continuity module 240 may be configured to recalibrate a matching confidence score threshold. It may recalibrate the threshold based upon information relating to the matching of feature points of related pages. It may also use information about pages that are not quite front page candidates or front page candidates that are not quite front pages. Analysis continuity module 240 may also consider information from the pages in between front pages. For example, it may identify discontinuities, missed front pages or missing pages in between the front pages. According to an embodiment, analysis continuity module 240 may work in cooperation with matcher 110 , aggregator 120 , quality assurance module 230 and/or reviewer 130 .
- Page dater 250 may be configured to obtain a date from each identified front page. Page dater 250 may also be configured to assign the date to the pages associated with an identified front page. According to an embodiment, page dater 250 may be performed with the assistance of an OCR system. According to another embodiment, page dater 250 may be performed with the assistance of human input. According to a further embodiment, page dater 250 may work in cooperation with aggregator 120 or tagger 150 .
- FIG. 5 illustrates an exemplary method 500 for identifying at least one front page within an image representing media having at least one page (steps 502 - 508 ), according to an embodiment.
- method 500 will be described with reference to system 100 but is not necessarily limited to this system.
- step 502 each page of an image representing media is compared to matching criteria that include feature points in order to produce a matching confidence score. This may be performed by matcher 110 . Pages with matching confidence scores that exceed a matching confidence score threshold are aggregated as front page candidates in step 504 . This may be performed by aggregator 120 .
- Decision information 140 is received in step 506 and is used to identify front pages from the front page candidates. This step may be performed with the assistance of reviewer 130 .
- step 508 each identified front page is tagged. This may be performed by tagger 150 .
- FIG. 6 illustrates another exemplary method 600 for identifying at least one front page (steps 602 - 614 ) with additional steps that may be performed, according to an embodiment.
- method 600 will be described with reference to systems 100 and 200 but is not necessarily so limited.
- patches of each page of an image representing media may be selected for comparison. This may be performed by patch clipper 210 . Patches of each page may be compared to matching criteria in step 604 .
- the matching criteria may include feature points or descriptors of feature points. These feature points may be identified from a template page. These feature points may be extracted from a template page. These feature points may be identified in a manner described above.
- steps 606 differences or similarities between matching criteria and features of selected patches are calculated. If necessary, an affine transformation may be performed to verify feature point matches. Other steps may be performed to help clarify the feature points to be analyzed.
- global consistency metrics may be used. For example, a distance between selected feature points is measured in step 608 . This measurement may be used as it may be effective in analyzing affine feature points. If the page is rotated, this measurement may still be consistent. Other global consistency metrics may be used to handle other defects, including translation and scaling defects. In this embodiment, a matching confidence score is produced in step 610 based upon the calculated differences and the measured distances.
- step 612 pages that exceed a matching confidence score threshold are forwarded, as front page candidates, to aggregator 120 .
- Steps 604 - 612 may be performed by matcher 110 .
- a matching confidence score threshold may be recalibrated as necessary, as shown in step 614 .
- the matching score threshold may need to be increased or decreased based upon a frequency of certain matching scores. Recalibration step 614 will help front page candidate selection to become more consistent among a number of media pages or sets of media pages.
- This step may be performed by analysis continuity module 240 . According to another embodiment, this step may also be performed by aggregator 120 .
- front page identification system 100 can be used and scaled to analyze a large amount of media material. In this way, content from the images representing media can be made available locally and remotely over networks to a wide range of users.
- System 100 can allow users to review text data in media material accessed locally or remotely at libraries, universities, government agencies, businesses, and other sites.
- System 100 or the results of system 100 can be used in connection with a search engine, web portal, or other web site to allow remote users to review and search media material having layout.
- a computer system may include, but is not limited to, a computer, workstation, server, mobile device (such as a laptop, mobile phone, smart phone, or personal data assistant), kiosk, game console, set-top box, or television.
- mobile device such as a laptop, mobile phone, smart phone, or personal data assistant
Abstract
Description
Claims (25)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US12/190,176 US8218913B1 (en) | 2008-08-12 | 2008-08-12 | Identifying a front page in media material |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US12/190,176 US8218913B1 (en) | 2008-08-12 | 2008-08-12 | Identifying a front page in media material |
Publications (1)
Publication Number | Publication Date |
---|---|
US8218913B1 true US8218913B1 (en) | 2012-07-10 |
Family
ID=46395973
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US12/190,176 Expired - Fee Related US8218913B1 (en) | 2008-08-12 | 2008-08-12 | Identifying a front page in media material |
Country Status (1)
Country | Link |
---|---|
US (1) | US8218913B1 (en) |
Cited By (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20110243450A1 (en) * | 2010-04-01 | 2011-10-06 | Microsoft Corporation | Material recognition from an image |
US8483447B1 (en) * | 2010-10-05 | 2013-07-09 | Google Inc. | Labeling features of maps using road signs |
Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20070071290A1 (en) * | 2005-09-28 | 2007-03-29 | Alex Shah | Image Classification And Information Retrieval Over Wireless Digital Networks And The Internet |
US20070136259A1 (en) * | 2004-03-24 | 2007-06-14 | Dorfman Barnaby M | System and method for displaying information in response to a request |
US20080107338A1 (en) * | 2006-11-03 | 2008-05-08 | Google Inc. | Media material analysis of continuing article portions |
US7424129B2 (en) * | 2001-11-19 | 2008-09-09 | Ricoh Company, Ltd | Printing system with embedded audio/video content recognition and processing |
US20090092322A1 (en) * | 2003-09-25 | 2009-04-09 | Berna Erol | Semantic Classification and Enhancement Processing of Images for Printing Applications |
US20090167760A1 (en) * | 2007-12-27 | 2009-07-02 | Nokia Corporation | Triangle Mesh Based Image Descriptor |
-
2008
- 2008-08-12 US US12/190,176 patent/US8218913B1/en not_active Expired - Fee Related
Patent Citations (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7424129B2 (en) * | 2001-11-19 | 2008-09-09 | Ricoh Company, Ltd | Printing system with embedded audio/video content recognition and processing |
US20090092322A1 (en) * | 2003-09-25 | 2009-04-09 | Berna Erol | Semantic Classification and Enhancement Processing of Images for Printing Applications |
US20070136259A1 (en) * | 2004-03-24 | 2007-06-14 | Dorfman Barnaby M | System and method for displaying information in response to a request |
US20070071290A1 (en) * | 2005-09-28 | 2007-03-29 | Alex Shah | Image Classification And Information Retrieval Over Wireless Digital Networks And The Internet |
US7428321B1 (en) * | 2005-09-28 | 2008-09-23 | Facedouble, Inc. | Image classification and information retrieval over wireless digital networks and the internet |
US20080107338A1 (en) * | 2006-11-03 | 2008-05-08 | Google Inc. | Media material analysis of continuing article portions |
US20090167760A1 (en) * | 2007-12-27 | 2009-07-02 | Nokia Corporation | Triangle Mesh Based Image Descriptor |
Non-Patent Citations (1)
Title |
---|
Liu et al., "Newspaper Headlines Extraction from Microfilm Images," IEEE, 2002, pp. 208-211. |
Cited By (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20110243450A1 (en) * | 2010-04-01 | 2011-10-06 | Microsoft Corporation | Material recognition from an image |
US8565536B2 (en) * | 2010-04-01 | 2013-10-22 | Microsoft Corporation | Material recognition from an image |
US9025866B2 (en) | 2010-04-01 | 2015-05-05 | Microsoft Technology Licensing, Llc | Material recognition from an image |
US8483447B1 (en) * | 2010-10-05 | 2013-07-09 | Google Inc. | Labeling features of maps using road signs |
US8755572B1 (en) * | 2010-10-05 | 2014-06-17 | Google Inc. | Labeling features of maps using road signs |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US9639751B2 (en) | Property record document data verification systems and methods | |
CN111476227B (en) | Target field identification method and device based on OCR and storage medium | |
US8792715B2 (en) | System and method for forms classification by line-art alignment | |
US10417489B2 (en) | Aligning grid lines of a table in an image of a filled-out paper form with grid lines of a reference table in an image of a template of the filled-out paper form | |
US7120318B2 (en) | Automatic document reading system for technical drawings | |
US8064703B2 (en) | Property record document data validation systems and methods | |
Erol et al. | HOTPAPER: multimedia interaction with paper using mobile phones | |
US8036497B2 (en) | Method, program and apparatus for storing document and/or image using invariant values calculated from feature points and method, program and apparatus for retrieving document based on stored document and/or image | |
RU2668717C1 (en) | Generation of marking of document images for training sample | |
Gebhardt et al. | Document authentication using printing technique features and unsupervised anomaly detection | |
TWI725465B (en) | Image processing system, image processing method and program product | |
Pintus et al. | ATHENA: Automatic text height extraction for the analysis of text lines in old handwritten manuscripts | |
US20120082372A1 (en) | Automatic document image extraction and comparison | |
US9300831B2 (en) | Information processing apparatus, method, and recording medium | |
JPH11232306A (en) | Method and system for document check | |
Fatema et al. | Developing a system for automatic detection of books | |
US20130050765A1 (en) | Method and apparatus for document authentication using image comparison on a block-by-block basis | |
US8218913B1 (en) | Identifying a front page in media material | |
US20070217691A1 (en) | Property record document title determination systems and methods | |
JP2003109007A (en) | Device, method and program for classifying slip form and image collating device | |
CN116486423A (en) | Financial ticketing data processing method based on image recognition | |
Shweka et al. | Automatic extraction of catalog data from digital images of historical manuscripts | |
KR100957508B1 (en) | System and method for recognizing optical characters | |
Ketwong et al. | The simple image processing scheme for document retrieval using date of issue as query | |
JP2001126010A (en) | Document processor, document definition generation method and area extraction method and storage medium |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:THIRTHALA, SRIRAM;CHAUDHURY, KRISHNENDU;REEL/FRAME:021377/0716Effective date: 20080811 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
FPAY | Fee payment |
Year of fee payment: 4 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044101/0405Effective date: 20170929 |
|
FEPP | Fee payment procedure |
Free format text: MAINTENANCE FEE REMINDER MAILED (ORIGINAL EVENT CODE: REM.); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
LAPS | Lapse for failure to pay maintenance fees |
Free format text: PATENT EXPIRED FOR FAILURE TO PAY MAINTENANCE FEES (ORIGINAL EVENT CODE: EXP.); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
STCH | Information on status: patent discontinuation |
Free format text: PATENT EXPIRED DUE TO NONPAYMENT OF MAINTENANCE FEES UNDER 37 CFR 1.362 |
|
FP | Lapsed due to failure to pay maintenance fee |
Effective date: 20200710 |