US11790264B2 - Systems and methods for performing knowledge distillation - Google Patents
Systems and methods for performing knowledge distillation Download PDFInfo
- Publication number
- US11790264B2 US11790264B2 US16/445,651 US201916445651A US11790264B2 US 11790264 B2 US11790264 B2 US 11790264B2 US 201916445651 A US201916445651 A US 201916445651A US 11790264 B2 US11790264 B2 US 11790264B2
- Authority
- US
- United States
- Prior art keywords
- trained
- outputs
- learned
- training
- model
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/084—Backpropagation, e.g. using gradient descent
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/045—Combinations of networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/096—Transfer learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N5/00—Computing arrangements using knowledge-based models
- G06N5/02—Knowledge representation; Symbolic representation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/044—Recurrent networks, e.g. Hopfield networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/0464—Convolutional networks [CNN, ConvNet]
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/082—Learning methods modifying the architecture, e.g. adding, deleting or silencing nodes or connections
Definitions
- the present disclosure relates generally to knowledge distillation. More particularly, the present disclosure relates to knowledge distillation methods and systems that can leverage a corpus of pre-trained models and/or the predictions from these models to learn a distilled model from unlabeled and/or weakly labeled datasets.
- Knowledge distillation has been proposed as a mechanism to transfer knowledge from an individual model or group of models (also known as “teacher(s)”) to a single model (also known as a “student”) by utilizing the predictions (e.g., outputs) of the individual model or group of models.
- Efforts in knowledge distillation have mainly focused on averaging the predictions of the teacher(s) while using the same datasets to train the student that were used to train the teacher(s). While this approach has shown some benefits, it also has drawbacks due to the need for continued and possibly immutable storage of the training datasets. Needed in the art are improved distillation techniques that can be applied with little or no knowledge of the teacher(s) architecture or training data.
- One example aspect of the present disclosure is directed to methods for performing knowledge distillation.
- Each of these methods may include executing the following actions using one or more computing devices: obtaining an initial training dataset, the initial training dataset including multiple training examples; obtaining a plurality of sets of outputs respectively produced for the multiple training examples by a plurality of pre-trained machine-learned models, each of the pre-trained machine-learned models having been previously trained to perform a respective task based on a respective pre-trained model training dataset; evaluating a respective performance of each pretrained machine-learned model based at least in part on the set of outputs generated by the pre-trained machine-learned model; determining for the set of outputs generated by each pre-trained machine-learned model, whether to include one or more outputs of the set of outputs in a distillation training dataset based at least in part on the respective performance of such pre-trained machine-learned model; and training a distilled machine-learned model using at least a portion of the distillation training dataset.
- Another example aspect of the present disclosure is directed to computing systems for performing knowledge distillation.
- these computing systems can include one or more processors and one or more non-transitory computer-readable media that collectively store instructions that, when executed by the one or more processors cause the computing system to perform operations.
- These operations can include methods for performing knowledge distillation as disclosed herein or variations of these methods as would be understood by a person of ordinary skill in the art from this disclosure.
- FIG. 1 A depicts a block diagram of an example computing system that performs knowledge distillation according to example embodiments of the present disclosure.
- FIG. 1 B depicts a block diagram of an example computing device that performs knowledge distillation according to example embodiments of the present disclosure.
- FIG. 1 C depicts a block diagram of an example computing device that performs knowledge distillation according to example embodiments of the present disclosure.
- FIG. 2 depicts a block diagram of an example method for performing knowledge distillation according to example embodiments of the present disclosure.
- FIG. 3 depicts a block diagram of an example method for performing knowledge distillation from training data including unlabeled or weakly labeled data according to example embodiments of the present disclosure.
- FIG. 4 depicts a block diagram of an example method for performing knowledge distillation from a training data including unlabeled or weakly labeled data according to example embodiments of the present disclosure.
- FIG. 5 depicts a flow chart diagram of an example method to perform knowledge distillation according to example embodiments of the present disclosure.
- the present disclosure provides computing systems and methods directed to distillation of information from multiple machine-learned models based on evaluation of the performance of such models.
- aspects of the present disclosure are directed to systems and methods that intelligently select certain model outputs produced by machine-learned models for inclusion in a distillation training dataset that can be used to train a distilled machine-learned model.
- the model outputs can be selected for inclusion in the distillation training dataset based on an evaluation of the performance of the corresponding machine-learned model's ability to correctly infer outputs of that type or label.
- outputs can be selected on a per label basis (e.g., based on the performance of the model relative to such label) and/or through application of one or more machine-learned trust models (e.g., that have been trained to predict the correctness of the corresponding model's outputs).
- a distillation training dataset can be generated (e.g., from weakly labeled or unlabeled data) which includes only model outputs that are high quality or otherwise associated with respective machine-learned models that have demonstrated expertise or competence in performing the specific task that led to such model output.
- the present disclosure provides an intelligent model evaluation and output selection process that leverages a corpus of existing machine-learned models and/or access to their predictions to generate a high-quality distillation training dataset (e.g., from majority weakly labeled and/or unlabeled data) which can be used to train a highly accurate distillation machine-learned model.
- a high-quality distillation training dataset e.g., from majority weakly labeled and/or unlabeled data
- a computing system can have access to a corpus of existing machine-learned models which have been previously trained on different respective sets of training data.
- the pre-trained machine-learned models may have been trained to perform different respective tasks. The tasks may be related or unrelated.
- the pre-trained machine-learned models may be models that have been generated by the same or other entities (e.g., individuals, teams, corporations, corporate divisions, etc.). than the entity that is operating the computing system.
- the pre-trained models can be internally accessible (e.g., via a corporation or other entity's internal computing networks) or can be publicly accessible (e.g., via the Internet and/or a repository).
- the computing system may not have access to or knowledge of the respective training data used to train each pre-trained model, or even, in some cases, knowledge of the model's architecture.
- the computing system can generally be able to provide input data to each model and to receive an output (e.g., an inference or prediction) from each model based on the input data.
- the computing system can run the models or can interact with a host of the models (e.g., via an API) to receive the outputs.
- the computing system can perform inference with each pre-trained model to obtain outputs from the pre-trained model.
- the computing system may not have access to pre-trained models or knowledge of the models' architectures, but instead may simply have access to sets of outputs known to have been previously generated for certain training examples by the pre-trained models.
- a database may store sets of pre-trained model outputs for certain known inputs (e.g., training examples) which can be accessed by the computing system.
- the group of pre-trained machine-learned models can each be configured to perform any task (e.g., classification, regression, detection, and encoding).
- each pre-trained machine-learned model can be configured as a classifier, such as a binary image classifier, trained to infer a classification label for each training example as an output.
- the group of pre-trained machine-learned models can include a multi-label image classifier trained to infer one or more classification labels for each training example as an output.
- knowledge from a group of machine-learned models can be distilled to take advantage of task specific and/or domain specific knowledge without requiring the complete datasets used to train each machine-learned model or, in some cases, even access to the model itself.
- each machine-learned model can be trained as a binary classifier to identify if an image depicts a certain breed of dog or not.
- an initial prediction can be generated for an inferred breed for each training example in the dataset.
- previously generated predictions for the dataset can be accessed.
- one or more expert machine-learned models can be identified that infer high-quality predictions.
- a distillation model can be trained to perform a different, but potentially related task such as performing multi-class classification relative to all breeds of dogs.
- an aspect of certain methods and systems described can include the ability to combine models from different domains without domain-specific expertise.
- knowledge can be distilled from a group of machine-learned models where each has been trained to perform a task (e.g., image classification, natural language recognition, voice-to-text, etc.).
- a task e.g., image classification, natural language recognition, voice-to-text, etc.
- an initial prediction can be generated for each machine-learned model on each training example.
- one or more expert models can be identified as a subset of the group of machine-learned models.
- an output of the expert model e.g., a label, an embedding, a probability, etc.
- an initial dataset containing a number of training examples may first be obtained or generated.
- the training examples included in the initial dataset do not need to be the same as the examples that were used to train each individual machine-learned model.
- methods and systems disclosed herein may utilize initial datasets that include training examples for performing a task that is related or unrelated to the particular task(s) that each pre-trained model was trained to perform.
- the distillation dataset can be used to train a distillation model that can perform the respective task of each individual machine-learned model to condense the knowledge of separate machine-learned models into a single model.
- the distillation dataset may be used to perform model discovery such that the distillation dataset can be used to train a distillation model that can perform a discovered task that was not performed by one of the machine-learned models or that was performed by the pre-trained model with lower accuracy compared to the distillation model.
- methods for performing knowledge distillation in accordance with this disclosure can be used with datasets that include labeled data (e.g., data including some ground truth or label), weakly labeled, unlabeled, or a combination of thereof.
- labeled data e.g., data including some ground truth or label
- the initial dataset can include between about 20% to about 80% of unlabeled or weakly labeled training examples, such as between about 30% to about 75%, about 40% to about 70%, or about 50% to about 60%.
- the training examples in the initial dataset can include mostly weakly labeled or unlabeled training examples.
- the outputs selected for inclusion in the distillation training dataset may be considered trusted without the need for a validation dataset (e.g., on a per-label or per-task basis).
- the initial training dataset can include or be associated with a validation dataset that includes labeled data (e.g., training examples that have a ground truth answer or label).
- the validation dataset may be used to assist in the determination of an expert machine-learned model for performing a certain task.
- the designation of an expert machine-learned model can be used to assign high quality labels to the weakly labeled or unlabeled data that may improve the performance of the distillation model by increasing the size and/or quality of the distillation training dataset.
- one goal of methods and systems described herein is to evaluate a body of training data using the knowledge of a group of pre-trained models.
- aspects of the present disclosure include evaluating the outputs from the group of pre-trained models to determine which pre-trained models perform better at certain task(s).
- a validation dataset can be used in some implementations to determine which model provides outputs that demonstrate higher quality, accuracy, and/or precision for a given task or label.
- high-quality labels can be inferred for the unlabeled training examples without the need for manual labeling or additional data mining to expand the distillation training dataset.
- the distillation dataset can be used to train a distillation model.
- Evaluating the performance of each pre-trained model can be accomplished in several ways such as analyzing each model on a per-label basis (e.g., find best performer for each label), training an additional model which can be referred to as a trust model, or a combination of both.
- Aspects of the current disclosure can include evaluating each pre-trained model's performance using a validation dataset that includes labeled examples (e.g., examples including or associated with a ground truth).
- the evaluation of each pre-trained model's performance can be based on the outputs generated by each pre-trained model using a dataset that includes only unlabeled or weakly labeled training examples.
- analyzing each model on a per-label basis can include comparing the outputs from each pre-trained model to determine the best performer or a group of relatively higher performing pre-trained models for a given label. For example, an initial dataset including a validation dataset can be provided to two pre-trained models. Each pre-trained model can generate a set of outputs for both the unlabeled data (ul-output) and the validation data (l-output). The respective outputs generated for the validation data (l-output) can then be compared, for each of the two models, to the ground truth labels of the validation data to determine the best performer or expert model.
- each pre-trained model can be configured as a binary classifier trained to determine if an image included a certain dog breed or not. If one pre-trained model were to infer a breed for an image that depicted such breed of dog, while the other did not, this model can be considered the expert for that label.
- This performance comparison can be extended to outputs generated by each pre-trained model until some threshold is met (e.g., comparison to all models, to a majority of the models, or until enough training examples are associated with high-quality outputs for a label).
- each pre-trained model can generate a set of outputs for both the unlabeled data and the validation data.
- a population or consensus label can then be determined using the output of each pre-trained model for a training example.
- the population or consensus label can be an average, distribution, or other statistic determined using the collective outputs. For instance, using the same dog breed example, the average output for a training example including an image of a collie should ideally be low (i.e., most of the pre-trained models were not trained to identify that specific breed).
- Selecting the expert pre-trained model can include comparing each model output for a training example to the consensus and selecting one or more models that differ from the consensus by a threshold (e.g., standard deviation, percentile, etc.).
- a threshold e.g., standard deviation, percentile, etc.
- high quality labels may be inferred as the consensus of all expert models.
- high quality labels may include any output by each expert model related to the label assigned or associated with that model.
- analysis on a per-label basis can be focused on assessing the ability of each pre-trained model for performing a task (e.g., assigning a label) to determine an expert model for the task.
- the expert model for a task will be considered as producing high-quality inference, but only for the identified task.
- this does not omit the possibility that one pre-trained model may be configured to perform multiple tasks and so the same methodology may be used to assign one pre-trained model as the expert for one or more tasks.
- this analysis may reveal that none of the pre-trained models are experts for a given task or that multiple pre-trained models are experts for a general task, but that other attributes of the input training examples can be used to assign multiple experts having complementary specializations.
- one or more expert models can be assigned for detecting the same breed but differentiated based on the background in an image such as if the breed is on a couch, in a field, or at the beach.
- a distillation model according to the disclosure can be trained based on the outputs of the one or more expert models.
- one or more trust models can be trained (e.g., using the validation dataset) for each pre-trained model.
- the trust model(s) for each pre-trained model can learn to predict, based on the input, when the pre-trained model is providing a correct output (e.g., which can be structured, for each pre-trained model, as a binary classification problem).
- a single trust model can be trained to select, based on the input and from all available pre-trained machine-learned models, one or more of the pre-trained machine-learned models to serve as an expert specifically for that input (e.g., which can be structured as a multi-class and/or multi-label classification problem).
- the trust model(s) can be trained using a validation dataset in which the outputs of each pre-trained model can be evaluated against ground truth data (e.g., thereby providing the ability to learn when to “trust” each pre-trained model).
- aspects of training one or more additional machine-learning models as trust models can include learning underlying trends in each pre-trained model's outputs for the initial dataset. For example, confidence for performing a task (e.g., assigning a label) given a training example may be inferred from the outputs of each pre-trained model.
- Example output can include labels such as words, phrases and numbers, embeddings such as hidden layers included in a neural network, or numbers.
- Each trust model can be configured to use some or all of this information in combination with the validation dataset to determine which model or models generate high-quality output for performing a task.
- training the distillation model may be performed in parallel with training the one or more trust models. In these cases, feedback from the performance of the distillation model for performing a task may also be used to train the trust models.
- analysis using trust models can be focused on providing the trust models with training data to improve their ability to evaluate the confidence, accuracy, or other measure of “correctness” in each pre-trained model's outputs for a given task. As the trust models learn, they improve the ability to differentiate high quality labels from noise.
- the computing system can determine whether to include certain pre-trained model outputs in the distillation training dataset based on the evaluation techniques described above. As examples, determining whether to include one or more outputs of the plurality set of outputs in the distillation training dataset can include determining, for each pre-trained machine-learned model and for each label, whether to include in the distillation training dataset all outputs or a subset of the outputs with the label.
- determining whether to include one or more outputs of the plurality set of outputs in the distillation training dataset can include, for each classification label: selecting a highest-performing pre-trained machine-learned model for such label; and including in the distillation training dataset all outputs of the set of outputs generated by such pre-trained machine-learned model that have such label.
- determining whether to include one or more outputs of the plurality of sets of outputs in the distillation training dataset can also be based in part on the selection of one or more expert models. For example, a weighting can be applied to some or all outputs from the set of outputs inferred by a pre-trained machine-learned model based in part on the selection of an expert model. This weighting can be used to filter outputs for which the expert model performs better (e.g., best) than the group of pre-trained machine-learned models.
- determining whether to include one or more outputs of the plurality of sets of outputs in the distillation training dataset can also be based in part on the learning rate, accuracy, or other metric used to characterize the distilled machine-learned model.
- the computing system can train a distilled machine-learned model on the distillation training dataset.
- An aspect of training the distilled machine-learned model using at least a portion of the distillation training dataset can include selecting a model architecture.
- the distilled machine-learned model can be configured as a neural network including one or more hidden layers.
- the neural network can be configured as a multi-label classifier.
- the number of labels identified by the distilled machine-learned model can include all or only a portion of the labels or tasks for which one or more respective expert model were identified.
- the portion of the distillation training dataset can include training examples associated with inferred outputs (e.g., outputs inferred by one of the pre-trained models), training examples associated with ground truths, or both.
- the portion of the distillation training dataset can include a percentage of training examples associated with inferred outputs relative to the total number of trained examples included in the distillation training dataset.
- the percentage of training examples associated with inferred outputs included in the distillation training dataset can be greater than about 50% (e.g., greater than 60%, 65%, 70%, 75%, 80%, 85%, 90%, or 95%) such that most of the distillation dataset includes inferred labels determined based on the expertise of the pre-trained machine learned models.
- the portion of the distillation training dataset may only include training examples associated with inferred outputs (i.e., the percentage is 100%).
- training the distillation model can include passing an embedding to the models as a light-weight representation of more complex data.
- the embedding would implicitly include information about the expert model which can allow the distillation model to take advantage of the expert model's strengths.
- an expert model can include a trained neural network having one or more hidden layers. Rather than training the distillation model using the output of the full neural network, an output from one or more hidden layers of the pre-trained model (e.g., which may be referred to as an embedding) may be used as the target for the distilled model to match.
- the task performed by the expert model does not need to be known beforehand, but it can still be learned by the distillation model using the embedding. That is, the distilled model can be trained to generate as its output an “embedding” produced at an intermediate layer of an expert model.
- an aspect of certain methods for performing knowledge distillation can include an initial segmentation of the pre-trained machine-learned models based in part on the data-type(s) received by each model. Additionally or alternatively, an aspect of certain methods can include an output filtering or clustering (e.g., grouping) based on the data-type(s) output by each model. One or both of these operations can be performed in parallel or in combination with methods for performing knowledge distillation as disclosed herein.
- aspects of the disclosure can provide improvements to computing technologies and to distillation learning methods by reducing the need to compartmentalize and store training data. Instead, knowledge distillation techniques may rely on the expertise of the pre-trained machine-learning models to infer high-quality outputs by the inclusion of one or more evaluation techniques. Using this methodology may result in decreased costs for data storage. Additionally, certain implementations may be used with initial datasets continuing mostly weak data, which reduces the need for expensive labeling.
- the systems and methods of the present disclosure provide a number of technical effects and benefits.
- the methods and systems for performing knowledge distillation described herein can be implemented using weakly labeled or unlabeled initial datasets that do not necessarily need 100% overlapping label-sets or overlapping domains.
- This generality can improve the ability of certain implementations to combine disparate models without knowledge of the underlying model architecture or training data.
- the distilled model may outperform any of the underlying pre-trained models, thereby advancing the state-of-the-art on the specific problem to be addressed.
- the systems and methods of the present disclosure can leverage the knowledge of the pre-trained models to learn a highly accurate distilled machine-learned model from an initial training dataset that is primarily weakly labeled or unlabeled.
- the need for costly and time-consuming manual labeling can be reduced.
- the systems and methods of the present disclosure may be implemented without storage or maintenance of the underlying pre-trained models. While storing the actual models is possible, it is not necessary for all implementations.
- the predictions of the pre-trained models for a shared input dataset can be stored as a lower representation of the underlying model. Advantages in compute and maintainability may be achieved by keeping the predictions over a shared dataset rather than keeping the models (though at the expense of storage). For example, if a trust-model needs to be updated (or ratings need to be sent) by keeping the predictions this can be done by simply processing existing data.
- FIG. 1 A depicts a block diagram of an example computing system 100 for performing knowledge distillation according to example embodiments of the present disclosure.
- the system 100 includes a user computing device 102 , a server computing system 130 , a training computing system 150 , and a set of machine-learned models 190 that are communicatively coupled over a network 180 .
- the user computing device 102 can be any type of computing device, such as, for example, a personal computing device (e.g., laptop or desktop), a mobile computing device (e.g., smartphone or tablet), a gaming console or controller, a wearable computing device, an embedded computing device, or any other type of computing device.
- a personal computing device e.g., laptop or desktop
- a mobile computing device e.g., smartphone or tablet
- a gaming console or controller e.g., a gaming console or controller
- a wearable computing device e.g., an embedded computing device, or any other type of computing device.
- the user computing device 102 includes one or more processors 112 and a memory 114 .
- the one or more processors 112 can be any suitable processing device (e.g., a processor core, a microprocessor, an ASIC, a FPGA, a controller, a microcontroller, etc.). and can be one processor or a plurality of processors that are operatively connected.
- the memory 114 can include one or more non-transitory computer-readable storage mediums, such as RAM, ROM, EEPROM, EPROM, flash memory devices, magnetic disks, etc., and combinations thereof.
- the memory 114 can store data 116 and instructions 118 which are executed by the processor 112 to cause the user computing device 102 to perform operations.
- the user computing device 102 can store or include one or more distillation machine-learned models 120 .
- the distillation machine-learned models 120 can be or can otherwise include various machine-learned models such as neural networks (e.g., deep neural networks) or other types of machine-learned models, including non-linear models and/or linear models.
- Neural networks can include feed-forward neural networks, recurrent neural networks (e.g., long short-term memory recurrent neural networks), convolutional neural networks or other forms of neural networks.
- Example distillation machine-learned models 120 are discussed with reference to FIGS. 2 - 5 .
- the one or more distillation machine-learned models 120 can be received from the server computing system 130 over network 180 , stored in the user computing device memory 114 , and then used or otherwise implemented by the one or more processors 112 .
- the user computing device 102 can implement multiple parallel instances of a single distillation machine-learned model 120 (e.g., to perform parallel training across multiple instances of the distillation training dataset).
- knowledge distillation utilizes the ability of multiple machine-learned models 190 to infer high-quality outputs for a given task. Using this information, the inferred outputs can be used to curate a distillation training dataset for training the distillation model in one or multiple instances. Aspects of the disclosure include multiple examples for evaluating the set of outputs determined from the machine-learned models 190 that may be used to determine if the outputs should be included in the distillation training dataset. The distillation training dataset can then be used to train one or more distillation machine-learned models 120 140 on a user computing device 102 or a server computing system 130 .
- one or more distillation machine-learned models 140 can be included in or otherwise stored and implemented by the server computing system 130 that communicates with the user computing device 102 according to a client-server relationship.
- the distillation machine-learned models 140 can be implemented by the server computing system 140 as a portion of a web service.
- one or more models 120 can be stored and implemented at the user computing device 102 and/or one or more models 140 can be stored and implemented at the server computing system 130 .
- the user computing device 102 can also include one or more user input component 122 that receives user input.
- the user input component 122 can be a touch-sensitive component (e.g., a touch-sensitive display screen or a touch pad) that is sensitive to the touch of a user input object (e.g., a finger or a stylus).
- the touch-sensitive component can serve to implement a virtual keyboard.
- Other example user input components include a microphone, a traditional keyboard, or other means by which a user can provide user input.
- the server computing system 130 includes one or more processors 132 and a memory 134 .
- the one or more processors 132 can be any suitable processing device (e.g., a processor core, a microprocessor, an ASIC, a FPGA, a controller, a microcontroller, etc.). and can be one processor or a plurality of processors that are operatively connected.
- the memory 134 can include one or more non-transitory computer-readable storage mediums, such as RAM, ROM, EEPROM, EPROM, flash memory devices, magnetic disks, etc., and combinations thereof.
- the memory 134 can store data 136 and instructions 138 which are executed by the processor 132 to cause the server computing system 130 to perform operations.
- the server computing system 130 includes or is otherwise implemented by one or more server computing devices. In instances in which the server computing system 130 includes plural server computing devices, such server computing devices can operate according to sequential computing architectures, parallel computing architectures, or some combination thereof.
- the server computing system 130 can store or otherwise include one or more distillation machine-learned models 140 .
- the models 140 can be or can otherwise include various machine-learned models.
- Example machine-learned models include neural networks or other multi-layer non-linear models.
- Example neural networks include feed forward neural networks, deep neural networks, recurrent neural networks, and convolutional neural networks.
- Example models 140 are discussed with reference to FIGS. 2 - 5 .
- the user computing device 102 and/or the server computing system 130 can train the models 120 and/or 140 via interaction with the training computing system 150 that is communicatively coupled over the network 180 .
- the training computing system 150 can be separate from the server computing system 130 or can be a portion of the server computing system 130 .
- the training computing system 150 includes one or more processors 152 and a memory 154 .
- the one or more processors 152 can be any suitable processing device (e.g., a processor core, a microprocessor, an ASIC, a FPGA, a controller, a microcontroller, etc.). and can be one processor or a plurality of processors that are operatively connected.
- the memory 154 can include one or more non-transitory computer-readable storage mediums, such as RAM, ROM, EEPROM, EPROM, flash memory devices, magnetic disks, etc., and combinations thereof.
- the memory 154 can store data 156 and instructions 158 which are executed by the processor 152 to cause the training computing system 150 to perform operations.
- the training computing system 150 includes or is otherwise implemented by one or more server computing devices.
- the training computing system 150 can include a model trainer 160 that trains the machine-learned models 120 and/or 140 stored at the user computing device 102 and/or the server computing system 130 using various training or learning techniques, such as, for example, backwards propagation of errors.
- performing backwards propagation of errors can include performing truncated backpropagation through time.
- the model trainer 160 can perform a number of generalization techniques (e.g., weight decays, dropouts, etc.). to improve the generalization capability of the models being trained.
- the model trainer 160 can train the distillation machine-learned models 120 and/or 140 based on a set of training data 162 .
- the training data 162 can include, for example, images, text, audio, and other various mediums of data. Additionally, the training data 162 may include examples from various fields such as social networks, chemistry, biology, computer science, and business. In some implementations, the training data 162 may include labeled, and unlabeled data. In certain implementations, the training data 162 may include solely unlabeled data.
- the training examples can be provided by the user computing device 102 .
- the model 120 provided to the user computing device 102 can be trained by the training computing system 150 on user-specific data received from the user computing device 102 . In some instances, this process can be referred to as personalizing the model.
- the model trainer 160 includes computer logic utilized to provide desired functionality.
- the model trainer 160 can be implemented in hardware, firmware, and/or software controlling a general purpose processor.
- the model trainer 160 includes program files stored on a storage device, loaded into a memory and executed by one or more processors.
- the model trainer 160 includes one or more sets of computer-executable instructions that are stored in a tangible computer-readable storage medium such as RAM hard disk or optical or magnetic media.
- the network 180 can be any type of communications network, such as a local area network (e.g., intranet), wide area network (e.g., Internet), or some combination thereof and can include any number of wired or wireless links.
- communication over the network 180 can be carried via any type of wired and/or wireless connection, using a wide variety of communication protocols (e.g., TCP/IP, HTTP, SMTP, FTP), encodings or formats (e.g., HTML, XML), and/or protection schemes (e.g., VPN, secure HTTP, SSL).
- FIG. 1 A illustrates one example computing system that can be used to implement the present disclosure.
- the user computing device 102 can include the model trainer 160 and the training dataset 162 .
- the models 120 can be both trained and used locally at the user computing device 102 .
- the user computing device 102 can implement the model trainer 160 to personalize the models 120 based on user-specific data.
- FIG. 1 B depicts a block diagram of an example computing device 10 that performs according to example embodiments of the present disclosure.
- the computing device 10 can be a user computing device or a server computing device.
- the computing device 10 includes a number of applications (e.g., applications 1 through N). Each application contains its own machine learning library and machine-learned model(s). For example, each application can include a machine-learned model.
- Example applications include a text messaging application, an email application, a dictation application, a virtual keyboard application, a browser application, etc.
- each application can communicate with a number of other components of the computing device, such as, for example, one or more sensors, a context manager, a device state component, and/or additional components.
- each application can communicate with each device component using an API (e.g., a public API).
- the API used by each application is specific to that application.
- FIG. 1 C depicts a block diagram of an example computing device 50 that performs according to example embodiments of the present disclosure.
- the computing device 50 can be a user computing device or a server computing device.
- the computing device 50 includes a number of applications (e.g., applications 1 through N). Each application is in communication with a central intelligence layer.
- Example applications include a text messaging application, an email application, a dictation application, a virtual keyboard application, a browser application, etc.
- each application can communicate with the central intelligence layer (and model(s) stored therein) using an API (e.g., a common API across all applications).
- the central intelligence layer includes a number of machine-learned models. For example, as illustrated in FIG. 1 C , a respective machine-learned model (e.g., a model) can be provided for each application and managed by the central intelligence layer. In other implementations, two or more applications can share a single machine-learned model. For example, in some implementations, the central intelligence layer can provide a single model (e.g., a single model) for all of the applications. In some implementations, the central intelligence layer is included within or otherwise implemented by an operating system of the computing device 50 .
- a respective machine-learned model e.g., a model
- two or more applications can share a single machine-learned model.
- the central intelligence layer can provide a single model (e.g., a single model) for all of the applications.
- the central intelligence layer is included within or otherwise implemented by an operating system of the computing device 50 .
- the central intelligence layer can communicate with a central device data layer.
- the central device data layer can be a centralized repository of data for the computing device 50 . As illustrated in FIG. 1 C , the central device data layer can communicate with a number of other components of the computing device, such as, for example, one or more sensors, a context manager, a device state component, and/or additional components. In some implementations, the central device data layer can communicate with each device component using an API (e.g., a private API).
- an API e.g., a private API
- FIG. 2 depicts a block diagram of an example process to generate a distillation machine-learned model 214 .
- Aspects of the disclosure include processes for determining a distillation training dataset 208 for training the distillation model 214 .
- FIG. 2 illustrates an initial training dataset 202 being provided to a group of pre-trained ML models 204 (e.g., pre-trained candidate 1 through pre-trained candidate N).
- the training data 202 can be processed by each pre-trained ML model to produce a respective set of outputs 206 for each of the pre-trained ML models 204 .
- a different (but potentially overlapping) subset of the initial training data 202 is processed by each respective model 204 .
- each model 204 may produce respective outputs 206 on the same or different subsets of training data 202 .
- An evaluation 210 can be performed based in part on the outputs 206 to characterize the group of pre-trained ML models 204 and this evaluation 210 may be used to help select certain outputs 212 from the plurality of sets of outputs 206 for inclusion in the distillation training dataset 208 for training a distillation model 214 .
- the evaluation 210 of the performance of each pre-trained model 204 can be accomplished in several ways. As an example, as illustrated in FIG. 3 , the evaluation 210 can include analyzing each model 204 on a per-label basis (e.g., find best performer for each label). As another example, as illustrated in FIG. 4 , the evaluation 210 can include training an additional model which can be referred to as a trust model. In some implementations, the evaluation 210 of each pre-trained model's performance can be accomplished using a validation dataset that includes labeled examples (e.g., examples including or associated with a ground truth). Alternatively, the evaluation of each pre-trained model's performance can be based on the outputs generated by each pre-trained model using a dataset that includes only unlabeled or weakly labeled training examples.
- an initial dataset 202 containing a number of training examples may first be obtained or generated.
- the training examples included in the initial dataset 202 do not need to be the same as the examples that were used to train each individual pre-trained machine-learned model 204 .
- methods and systems disclosed herein may utilize initial datasets 202 that include training examples for performing a task that is related or unrelated to the particular task(s) that each pre-trained model 204 was trained to perform.
- initial training datasets 202 that include labeled data (e.g., data including some ground truth or label), weakly labeled data, unlabeled data, or a combination of thereof.
- labeled data e.g., data including some ground truth or label
- the initial dataset 202 can include between about 20% to about 80% of unlabeled or weakly labeled training examples, such as between about 30% to about 75%, about 40% to about 70%, or about 50% to about 60%.
- aspects of the present disclosure include evaluating the outputs 206 from the group of pre-trained models 204 to determine which pre-trained models 204 perform better at certain task(s). For example, a validation dataset can be used in some implementations to determine which model 204 provides outputs that demonstrate higher quality, accuracy, and/or precision for a given task or label. Using this information, high-quality labels can be inferred for the unlabeled training examples without the need for manual labeling or additional data mining to expand the distillation training dataset 208 . After generation of a distillation dataset 208 containing high-quality labels, the distillation dataset 208 can be used to train a distillation model 214 .
- evaluating 210 each model 204 on a per-label basis can include comparing the outputs 206 from each pre-trained model 204 to determine the best performer or a group of relatively higher performing pre-trained models 204 for a given label.
- the initial dataset 202 including a validation dataset can be provided to two pre-trained models 204 .
- Each pre-trained model 204 can generate a set of outputs 206 for both the unlabeled data (ul-output) and the validation data (l-output).
- each pre-trained model 204 can be configured as a binary classifier trained to determine if an image included a certain dog breed or not. If one pre-trained model 204 were to infer a breed for an image that depicted such breed of dog, while the other did not, this model can be considered the expert for that label.
- This performance comparison can be extended to outputs generated by each pre-trained model until some threshold is met (e.g., comparison to all models, to a majority of the models, or until enough training examples are associated with high-quality outputs for a label).
- each pre-trained model 204 can generate a set of outputs for both the unlabeled data and the validation data.
- a population or consensus label can then be determined using the output 206 of each pre-trained model 204 for a training example.
- the population or consensus label can be an average, distribution, or other statistic determined using the collective outputs 206 . For instance, using the same dog breed example, the average output for a training example including an image of a collie should ideally be low (i.e., most of the pre-trained models were not trained to identify that specific breed).
- Selecting the expert pre-trained model can include comparing each model output for a training example to the consensus and selecting one or more models that differ from the consensus by a threshold (e.g., standard deviation, percentile, etc.). as the expert model(s) for a given label.
- a threshold e.g., standard deviation, percentile, etc.
- high quality labels may be inferred as the consensus of all expert models.
- high quality labels may include any output by each expert model related to the label assigned or associated with that model.
- analysis on a per-label basis can be focused on evaluating 210 the ability of each pre-trained model 204 for performing a task (e.g., assigning a label) to determine an expert model for the task.
- the expert model for a task will be considered as producing high-quality inference, but only for the identified task.
- this does not omit the possibility that one pre-trained model may be configured to perform multiple tasks and so the same methodology may be used to assign one pre-trained model as the expert for one or more tasks.
- this analysis may reveal that none of the pre-trained models are experts for a given task or that multiple pre-trained models are experts for a general task, but that other attributes of the input training examples can be used to assign multiple experts having complementary specializations.
- one or more expert models can be assigned for detecting the same breed but differentiated based on the background in an image such as if the breed is on a couch, in a field, or at the beach.
- a distillation model 2214 according to the disclosure can be trained based on the outputs of the one or more expert models.
- the computing system can determine whether to include certain pre-trained model outputs 206 in the distillation training dataset 208 based on the evaluation techniques described above.
- selecting one or more outputs 206 of the plurality of sets of outputs for inclusion in the distillation training dataset 208 can include determining, for each pre-trained machine-learned model 204 and for each label, whether to include in the distillation training dataset 208 all outputs or a subset of the outputs with the label.
- determining whether to include one or more outputs 206 of the plurality set of outputs in the distillation training dataset 208 can include, for each classification label: selecting a highest-performing pre-trained machine-learned model 204 for such label; and including in the distillation training dataset all outputs of the set of outputs 206 generated by such pre-trained machine-learned model 204 that have such label.
- selecting one or more outputs 206 of the plurality of sets of outputs for inclusion in the distillation training dataset 208 can also be based in part on the selection of one or more expert models. For example, a weighting can be applied to some or all outputs 206 from the set of outputs inferred by a pre-trained machine-learned model based in part on the selection of an expert model. This weighting can be used to filter outputs for which the expert model performs better (e.g., best) than the group of pre-trained machine-learned models.
- one or more trust models can be trained (e.g., using the validation dataset) for each pre-trained model 204 .
- the trust model(s) for each pre-trained model 204 can learn to predict, based on the input, when the pre-trained model 204 is providing a correct output 206 (e.g., which can be structured, for each pre-trained model, as a binary classification problem).
- a single trust model can be trained to select, based on the input and from all available pre-trained machine-learned models, one or more of the pre-trained machine-learned models 204 to serve as an expert specifically for that input (e.g., which can be structured as a multi-class and/or multi-label classification problem).
- the trust model(s) can be trained using a validation dataset in which the outputs 206 of each pre-trained model 204 can be evaluated against ground truth data (e.g., thereby providing the ability to learn when to “trust” each pre-trained model 204 ).
- aspects of training one or more additional machine-learning models as trust models can include learning underlying trends in each pre-trained model's outputs 206 for the initial dataset 202 . For example, confidence for performing a task (e.g., assigning a label) given a training example may be inferred from the outputs 206 of each pre-trained model 204 .
- Example output 206 can include labels such as words, phrases and numbers, embeddings such as hidden layers included in a neural network, or numbers.
- Each trust model can be configured to use some or all of this information in combination with the validation dataset to determine which model or models 204 generate high-quality output for performing a task.
- training the distillation model 214 may be performed in parallel with training the one or more trust models. In these cases, feedback from the performance of the distillation model 214 for performing a task may also be used to train the trust models.
- analysis using trust models can be focused on providing the trust models with training data to improve their ability to evaluate the confidence, accuracy, or other measure of “correctness” in each pre-trained model's outputs 206 for a given task. As the trust models learn, they improve the ability to differentiate high quality labels from noise.
- the computing system can determine whether to include certain pre-trained model outputs 206 in the distillation training dataset 208 based on the evaluation techniques described above.
- the predictions of the trust models can be used to select which outputs 206 are included in the distillation training dataset 208 (e.g., if the trust model predicts that a certain output 206 from a certain model 204 is correct based on the input, such output 206 can be included in the distillation training dataset 208 ).
- the training examples included in the training data 202 can be provided to the distillation model along with a certain outputs 212 (e.g., high-confidence outputs) that have been determined based in part on the respective performance of each of the pre-trained ML models 204 .
- a certain outputs 212 e.g., high-confidence outputs
- unlabeled or weakly labeled examples included in the training data 202 can be included in a distillation training dataset 208 used to train the distillation model 214 by associating these examples with a predicted output 206 from one of the pre-trained models 204 .
- FIG. 2 demonstrates providing an initial dataset 202 to a group of pre-trained ML models 204 to generate sets of outputs 206 (e.g., set 1 outputs, set 2 outputs, etc.). for the group of pre-trained model 204 .
- Each set of outputs included in the sets of outputs 206 can then be evaluated to to determine whether none, some or all of the outputs 206 from each set of outputs should be included in a distillation training dataset 208 (e.g., based on the confidence of the pre-trained model for performing the task associated with the output). For instance, FIG. 2 depicts that only one output (o1) from the set of outputs generated by pre-trained model 1 was selected for inclusion in the distillation training dataset 208 . Since the outputs selected for inclusion in the distillation training dataset 208 were determined from training examples included in the training data, some or all of the training data 202 may be included in the distillation training dataset 208 .
- the evaluation 210 can be performed to determine or designate an expert ML model for accomplishing a task (e.g., task A, task B, or task C).
- Example tasks can include image classification such as identification of a dog breed, natural language processing such as audio to text, etc.
- the identification of an expert ML model can help improve the quality of the distillation training dataset which may further improve the distillation model to distinguish between similar tasks.
- the evaluation 210 can be performed based in part on the output from one or more trust models (e.g., trust model 1, 2, . . . N).
- the trust model(s) can each be trained to determine expertise for a ML model to perform certain tasks, or one trust model may be trained to determine expertise for all the ML models at performing a specific task.
- the trust model(s) may be trained on a per-task basis, on a per-ML model basis, or a combination of both.
- feedback based on the performance of the distillation model for performing a certain task may be used in certain implementations to train the one or more trust models.
- FIG. 5 depicts a flow chart diagram of an example method to perform according to example embodiments of the present disclosure.
- FIG. 5 depicts steps performed in a particular order for purposes of illustration and discussion, the methods of the present disclosure are not limited to the particularly illustrated order or arrangement.
- the various steps of the method 500 can be omitted, rearranged, combined, and/or adapted in various ways without deviating from the scope of the present disclosure.
- a computing system may obtain an initial training dataset that comprises a set of training examples.
- the initial training dataset can include a first portion that is labeled and a second portion that is not labeled, and wherein the first portion of the initial training dataset is used as the validation dataset.
- Obtaining the initial training dataset can include accessing data libraries, generating training data, and/or updating or otherwise modifying data. For example, data showing an image of a dog may be accessed through the Internet, obtained by taking a photograph, or an image of multiple dogs may be modified to only focus or include a single dog.
- the computing system may determine a plurality of sets of outputs by respectively performing inference on the set of training examples with a plurality of pre-trained machine-learned models, each of the plurality of pre-trained machine-learned models having been previously trained to perform a respective task based on a respective pre-trained model training dataset.
- performing inference can include providing one or all of the training examples in the initial dataset to each of the pre-trained machine-learned models.
- the sets of outputs can be the true output of the machine-learned model or an intermediate representation such as an embedding (e.g., a hidden layer when using a neural network.)
- the computing system may evaluate a respective performance of each pre-trained machine-learned model based at least in part on the set of outputs generated by the pre-trained machine-learned model. For example, evaluating the performance can be performed on a per-label basis or can be performed through the use of one or more trust models.
- the computing system may determine for the set of outputs generated by each pre-trained machine-learned model whether to include one or more outputs of the set of outputs in a distillation training dataset based at least in part on the respective performance of such pre-trained machine-learned model. For example, outputs can be selected on a per-label basis, according to the trust model(s), and/or according to other techniques.
- the computing system train a distilled machine-learned model using at least a portion of the distillation training dataset.
- the technology discussed herein makes reference to servers, databases, software applications, and other computer-based systems, as well as actions taken and information sent to and from such systems.
- the inherent flexibility of computer-based systems allows for a great variety of possible configurations, combinations, and divisions of tasks and functionality between and among components.
- processes discussed herein can be implemented using a single device or component or multiple devices or components working in combination.
- Databases and applications can be implemented on a single system or distributed across multiple systems. Distributed components can operate sequentially or in parallel.
Abstract
Description
Claims (20)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US16/445,651 US11790264B2 (en) | 2019-06-19 | 2019-06-19 | Systems and methods for performing knowledge distillation |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US16/445,651 US11790264B2 (en) | 2019-06-19 | 2019-06-19 | Systems and methods for performing knowledge distillation |
Publications (2)
Publication Number | Publication Date |
---|---|
US20200401929A1 US20200401929A1 (en) | 2020-12-24 |
US11790264B2 true US11790264B2 (en) | 2023-10-17 |
Family
ID=74037814
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US16/445,651 Active 2040-07-30 US11790264B2 (en) | 2019-06-19 | 2019-06-19 | Systems and methods for performing knowledge distillation |
Country Status (1)
Country | Link |
---|---|
US (1) | US11790264B2 (en) |
Families Citing this family (13)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11868855B2 (en) * | 2019-11-04 | 2024-01-09 | Hewlett Packard Enterprise Development Lp | Resiliency for machine learning workloads |
US11604984B2 (en) * | 2019-11-18 | 2023-03-14 | Shanghai United Imaging Intelligence Co., Ltd. | Systems and methods for machine learning based modeling |
GB2609768A (en) * | 2020-11-02 | 2023-02-15 | Zhejiang Lab | Multi-task language model-oriented meta-knowledge fine tuning method and platform |
CN112651379B (en) * | 2021-01-12 | 2022-07-08 | 杭州像素元科技有限公司 | Single-lane congestion detection method based on deep learning |
CN112819090B (en) * | 2021-02-22 | 2022-05-10 | 武汉工程大学 | Knowledge distillation data enhancement method and system based on generation of countermeasure network |
CN112802023A (en) * | 2021-04-14 | 2021-05-14 | 北京小白世纪网络科技有限公司 | Knowledge distillation method and device for pleural lesion segmentation based on lifelong learning |
CN113222175B (en) * | 2021-04-29 | 2023-04-18 | 深圳前海微众银行股份有限公司 | Information processing method and system |
US11693987B2 (en) | 2021-04-30 | 2023-07-04 | International Business Machines Corporation | Database security |
CN113312548B (en) * | 2021-05-17 | 2022-05-03 | 浙江大学 | Knowledge distillation-based information retrieval method |
CN113762463A (en) * | 2021-07-26 | 2021-12-07 | 华南师范大学 | Model pruning method and system for raspberry pi processor |
CN113807540A (en) * | 2021-09-17 | 2021-12-17 | 北京搜狗科技发展有限公司 | Data processing method and device |
WO2023205095A1 (en) * | 2022-04-18 | 2023-10-26 | Sri International | Simulation of an electronic block |
GB202206105D0 (en) * | 2022-04-27 | 2022-06-08 | Samsung Electronics Co Ltd | Method for knowledge distillation and model generation |
Citations (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20160078339A1 (en) * | 2014-09-12 | 2016-03-17 | Microsoft Technology Licensing, Llc | Learning Student DNN Via Output Distribution |
-
2019
- 2019-06-19 US US16/445,651 patent/US11790264B2/en active Active
Patent Citations (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20160078339A1 (en) * | 2014-09-12 | 2016-03-17 | Microsoft Technology Licensing, Llc | Learning Student DNN Via Output Distribution |
Non-Patent Citations (10)
Title |
---|
Avnimelech, R. et al, Boosted Mixture of Experts: An Ensemble Learning Scheme, 1999, [retrieved on Jul. 16, 2021], Retrieved from Internet:<http://www.cs.tau.ac.il/˜nin/papers/bme_nc.pdf> (Year: 1999). * |
Ba, L., et al, Do Deep Nets Really Need to be Deep?, [retrieved Nov. 21, 2022], Retrieved from Internet:<https://proceedings.neurips.cc/paper/2014/hash/ea8fcd92d59581717e06eb187f10666d-Abstract.html> (Year: 2014). * |
Caruana, R. et al, Ensemble Selection from Libraries of Models, 2004, [retrieved on Jul. 16, 2021], Retrieved from Internet:<https://dl.acm.org/doi/pdf/10.1145/1015330.1015432> (Year: 2004). * |
Fukuda, T., et al, Efficient Knowledge Distillation from an Ensemble of Teachers, 2017, [retrieved Jan. 25, 2022], Retrieved from Internet:<https://www.isca-speech.org/archive_v0/Interspeech_2017/pdfs/0614.PDF> (Year: 2017). * |
Guyon, I. et al, Feature Extraction: foundations and applications, 2008, [retrieved on Jul. 16, 2021], Retrieved from Internet:<https://books.google.com/books?hl=en&lr=&id=FOTzBwAAQBAJ&oi=fnd&pg=PA1&dq=feature+extraction&ots=5Ui9P58uq2&sig=UoAqGwvLOCaVG9IpYFBkkUJLE3Q#v=onepage&q&f=false> (Year: 2008). * |
Guyon, I. et al, Feature Extraction: foundations and applications, 2008, [retrieved on Jul. 16, 2021], Retrieved from Internet:<https://books.google.com/books?hl=en&lr=&id=FOTzBwAAQBAJ&oi=fnd&pg=PA1&dq=feature+extraction&ots=5Ui9P58uq2&sig=UoAqGwvLOCaVG9lpYFBkkUJLE3Q#v=onepage&q&f=false> (Year: 2008). * |
Hinton, G. et al, Distilling the Knowledge in a Neural Network, 2015, [retrieved on Jul. 16, 2021], Retrieved from Internet:< https://arxiv.org/pdf/1503.02531.pdf.> (Year: 2015). * |
Jacobs, R. et al, Task Decomposition Through Competition in a Modular Connectionist Architecture: The What and Where Vision Tasks, [retrieved Jun. 21, 2022], Retrieved from Internet:<https://www.sciencedirect.com/science/article/abs/pii/036402139180006Q> (Year: 1991). * |
Jacobs, R., et al, Adaptive Mixtures of Local Experts, 1991, [retrieved Jun. 13, 2022], Retrieved from Internet: <https://ieeexplore.ieee.org/abstract/document/6797059> (Year: 1991). * |
You, S. et al, Learning from Multiple Teacher Networks, 2017, [retrieved on Jul. 16, 2021], Retrieved from Internet:<https://dl.acm.org/doi/pdf/10.1145/3097983.3098135> (Year: 2017). * |
Also Published As
Publication number | Publication date |
---|---|
US20200401929A1 (en) | 2020-12-24 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11790264B2 (en) | Systems and methods for performing knowledge distillation | |
Xiao et al. | Readmission prediction via deep contextual embedding of clinical concepts | |
US11138471B2 (en) | Augmentation of audiographic images for improved machine learning | |
Molnar et al. | General pitfalls of model-agnostic interpretation methods for machine learning models | |
WO2018196760A1 (en) | Ensemble transfer learning | |
US11914969B2 (en) | Contrastive pre-training for language tasks | |
Han et al. | Semi-supervised active learning for sound classification in hybrid learning environments | |
US20210374605A1 (en) | System and Method for Federated Learning with Local Differential Privacy | |
Lee et al. | Diagnosis prediction via medical context attention networks using deep generative modeling | |
Feng et al. | A hierarchical multi-label classification method based on neural networks for gene function prediction | |
US11501787B2 (en) | Self-supervised audio representation learning for mobile devices | |
US20230368070A1 (en) | Systems and methods for adaptative training of machine learning models | |
Song et al. | Ada-boundary: accelerating DNN training via adaptive boundary batch selection | |
EP3980941A1 (en) | Likelihood ratios for out-of-distribution detection | |
Zhao et al. | Comparing two machine learning approaches in predicting lupus hospitalization using longitudinal data | |
Ishkhanov et al. | Time-based sequence model for personalization and recommendation systems | |
Ma'sum et al. | Assessor-guided learning for continual environments | |
US20170236056A1 (en) | Automated predictive modeling and framework | |
Zaghir et al. | Real-world patient trajectory prediction from clinical notes using artificial neural networks and UMLS-based extraction of concepts | |
Oh et al. | Generalizing predictions to unseen sequencing profiles via deep generative models | |
Gao | Modeling stock market using new hybrid intelligent method based on MFNN and IBHA | |
Theodorou et al. | Synthesize extremely high-dimensional longitudinal electronic health records via hierarchical autoregressive language model | |
CN115516473A (en) | Hybrid human-machine learning system | |
Wassan et al. | Deep convolutional neural network and IoT technology for healthcare | |
US20240152540A1 (en) | Rapid adaptation to contemporary text datasets |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
FEPP | Fee payment procedure |
Free format text: ENTITY STATUS SET TO UNDISCOUNTED (ORIGINAL EVENT CODE: BIG.); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:DUERIG, THOMAS J.;WANG, HONGSHENG;RUDKIN, SCOTT ALEXANDER;SIGNING DATES FROM 20190624 TO 20190625;REEL/FRAME:049591/0334 |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NON FINAL ACTION MAILED |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: RESPONSE TO NON-FINAL OFFICE ACTION ENTERED AND FORWARDED TO EXAMINER |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: FINAL REJECTION MAILED |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: RESPONSE AFTER FINAL ACTION FORWARDED TO EXAMINER |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: ADVISORY ACTION MAILED |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: DOCKETED NEW CASE - READY FOR EXAMINATION |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NON FINAL ACTION MAILED |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: RESPONSE TO NON-FINAL OFFICE ACTION ENTERED AND FORWARDED TO EXAMINER |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: FINAL REJECTION MAILED |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NOTICE OF ALLOWANCE MAILED -- APPLICATION RECEIVED IN OFFICE OF PUBLICATIONS |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: PUBLICATIONS -- ISSUE FEE PAYMENT RECEIVED |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: PUBLICATIONS -- ISSUE FEE PAYMENT VERIFIED |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |