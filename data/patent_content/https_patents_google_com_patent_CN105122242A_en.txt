CN105122242A - Methods, systems, and media for presenting mobile content corresponding to media content - Google Patents
Methods, systems, and media for presenting mobile content corresponding to media content Download PDFInfo
- Publication number
- CN105122242A CN105122242A CN201480021167.4A CN201480021167A CN105122242A CN 105122242 A CN105122242 A CN 105122242A CN 201480021167 A CN201480021167 A CN 201480021167A CN 105122242 A CN105122242 A CN 105122242A
- Authority
- CN
- China
- Prior art keywords
- image
- channel
- programme
- audio
- user
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
- 238000000034 method Methods 0.000 title claims abstract description 52
- 230000004044 response Effects 0.000 claims abstract description 44
- 238000005516 engineering process Methods 0.000 claims description 30
- 239000000284 extract Substances 0.000 claims description 7
- 230000007246 mechanism Effects 0.000 description 28
- 230000000875 corresponding effect Effects 0.000 description 23
- 238000004891 communication Methods 0.000 description 17
- 230000008569 process Effects 0.000 description 10
- 230000008878 coupling Effects 0.000 description 7
- 238000010168 coupling process Methods 0.000 description 7
- 238000005859 coupling reaction Methods 0.000 description 7
- 238000001514 detection method Methods 0.000 description 6
- 238000004458 analytical method Methods 0.000 description 5
- 238000000605 extraction Methods 0.000 description 5
- 230000005540 biological transmission Effects 0.000 description 4
- 238000004590 computer program Methods 0.000 description 4
- 230000002596 correlated effect Effects 0.000 description 4
- 238000012545 processing Methods 0.000 description 4
- 230000006870 function Effects 0.000 description 3
- 230000000712 assembly Effects 0.000 description 2
- 238000000429 assembly Methods 0.000 description 2
- 238000010586 diagram Methods 0.000 description 2
- 238000001914 filtration Methods 0.000 description 2
- 230000002452 interceptive effect Effects 0.000 description 2
- 230000002045 lasting effect Effects 0.000 description 2
- 238000012015 optical character recognition Methods 0.000 description 2
- 230000003287 optical effect Effects 0.000 description 2
- 230000000153 supplemental effect Effects 0.000 description 2
- 230000001052 transient effect Effects 0.000 description 2
- 230000009471 action Effects 0.000 description 1
- 230000003213 activating effect Effects 0.000 description 1
- 230000004913 activation Effects 0.000 description 1
- 230000003321 amplification Effects 0.000 description 1
- 230000008901 benefit Effects 0.000 description 1
- 239000004020 conductor Substances 0.000 description 1
- 238000013480 data collection Methods 0.000 description 1
- 238000013461 design Methods 0.000 description 1
- 235000013399 edible fruits Nutrition 0.000 description 1
- 230000001965 increasing effect Effects 0.000 description 1
- 238000009434 installation Methods 0.000 description 1
- 239000000203 mixture Substances 0.000 description 1
- 238000003199 nucleic acid amplification method Methods 0.000 description 1
- 239000013307 optical fiber Substances 0.000 description 1
- 238000012856 packing Methods 0.000 description 1
- 230000002093 peripheral effect Effects 0.000 description 1
- 230000001737 promoting effect Effects 0.000 description 1
- 239000004065 semiconductor Substances 0.000 description 1
- 238000012546 transfer Methods 0.000 description 1
- 238000013519 translation Methods 0.000 description 1
- 235000013311 vegetables Nutrition 0.000 description 1
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/47—End-user applications
- H04N21/482—End-user interface for program selection
- H04N21/4828—End-user interface for program selection for searching program descriptors
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/41—Structure of client; Structure of client peripherals
- H04N21/414—Specialised client platforms, e.g. receiver in car or embedded in a mobile appliance
- H04N21/41407—Specialised client platforms, e.g. receiver in car or embedded in a mobile appliance embedded in a portable device, e.g. video client on a mobile phone, PDA, laptop
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/43—Processing of content or additional data, e.g. demultiplexing additional data from a digital video stream; Elementary client operations, e.g. monitoring of home network or synchronising decoder's clock; Client middleware
- H04N21/439—Processing of audio elementary streams
- H04N21/4394—Processing of audio elementary streams involving operations for analysing the audio stream, e.g. detecting features or characteristics in audio streams
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/43—Processing of content or additional data, e.g. demultiplexing additional data from a digital video stream; Elementary client operations, e.g. monitoring of home network or synchronising decoder's clock; Client middleware
- H04N21/44—Processing of video elementary streams, e.g. splicing a video clip retrieved from local storage with an incoming video stream, rendering scenes according to MPEG-4 scene graphs
- H04N21/44008—Processing of video elementary streams, e.g. splicing a video clip retrieved from local storage with an incoming video stream, rendering scenes according to MPEG-4 scene graphs involving operations for analysing video streams, e.g. detecting features or characteristics in the video stream
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/47—End-user applications
- H04N21/472—End-user interface for requesting content, additional data or services; End-user interface for interacting with content, e.g. for content reservation or setting reminders, for requesting event notification, for manipulating displayed content
- H04N21/47217—End-user interface for requesting content, additional data or services; End-user interface for interacting with content, e.g. for content reservation or setting reminders, for requesting event notification, for manipulating displayed content for controlling playback functions for recorded or on-demand content, e.g. using progress bars, mode or play-point indicators or bookmarks
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/47—End-user applications
- H04N21/472—End-user interface for requesting content, additional data or services; End-user interface for interacting with content, e.g. for content reservation or setting reminders, for requesting event notification, for manipulating displayed content
- H04N21/4722—End-user interface for requesting content, additional data or services; End-user interface for interacting with content, e.g. for content reservation or setting reminders, for requesting event notification, for manipulating displayed content for requesting additional data associated with the content
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/47—End-user applications
- H04N21/472—End-user interface for requesting content, additional data or services; End-user interface for interacting with content, e.g. for content reservation or setting reminders, for requesting event notification, for manipulating displayed content
- H04N21/4722—End-user interface for requesting content, additional data or services; End-user interface for interacting with content, e.g. for content reservation or setting reminders, for requesting event notification, for manipulating displayed content for requesting additional data associated with the content
- H04N21/4725—End-user interface for requesting content, additional data or services; End-user interface for interacting with content, e.g. for content reservation or setting reminders, for requesting event notification, for manipulating displayed content for requesting additional data associated with the content using interactive regions of the image, e.g. hot spots
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/60—Network structure or processes for video distribution between server and client or between remote clients; Control signalling between clients, server and network components; Transmission of management data between server and client, e.g. sending from server to client commands for recording incoming content stream; Communication details between server and client
- H04N21/65—Transmission of management data between client and server
- H04N21/658—Transmission by the client directed to the server
- H04N21/6582—Data stored in the client, e.g. viewing habits, hardware capabilities, credit card number
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/80—Generation or processing of content or additional data by content creator independently of the distribution process; Content per se
- H04N21/81—Monomedia components thereof
- H04N21/8126—Monomedia components thereof involving additional data, e.g. news, sports, stocks, weather forecasts
- H04N21/8133—Monomedia components thereof involving additional data, e.g. news, sports, stocks, weather forecasts specifically related to the content, e.g. biography of the actors in a movie, detailed information about an article seen in a video program
Abstract
Methods, systems, and media for presenting mobile content corresponding to media content are provided. In some implementations, a method for providing information relating to media content is provided, the method comprising: determining a channel that is providing the television program; causing images relating to the television program to be presented, wherein the images are selected based on the channel and a time parameter; receiving a user selection of an image; identifying an entity within the selected image using one or more image recognition techniques; generating a search query based at least in part on the identified entity; obtaining search results responsive to the generated search query; and causing at least one of the search results to be presented to the mobile device in response to receiving the user selection of the image.
Description
The cross reference of related application
This application claims the right of priority of the U.S. Patent Application No. 13/827,413 submitted on March 14th, 2013, it is integrally merged into herein by reference.
Technical field
Disclosed theme relates to for presenting the method corresponding with media content, system and medium.
Background technology
While viewing TV programme, the information of beholder usually to relevant to TV programme is interested.Such as, beholder may want search about the actor seen in film or the additional information about the position shown in documentary film.
Search engine allows beholder's searching resource on the internet, and described resource comprises web page, image, video content and audio content.Typical search engine is provided for the web page of inputted search item, and wherein, this search word is inputted by beholder.The Search Results carried out for specific search term is provided to beholder.In addition, along with the appearance of mobile device, the use of mobile search engine increases.Such as, use mobile device, beholder can perform search and browsing internet content while viewing TV programme.
But text based search engine may be limited a little for this user.User wants the name of the certain actor learned in film and obtains in the example about the additional information of this certain actor wherein, user can attempt by finding the title of film (such as, from program guide, to instruct website, from the guide etc. printed from online television) and searching for film mobile search engine by its title being input to and obtaining this information.User then put into Search Results with find comprise the information relevant with film web page (such as, comprise the online website of the information relevant with film and TV programme), access this web page, and search for whole web page to find the information relevant to certain actor.If user can find this actor on this web page, then another relevant to certain actor in user's access websites page, and scan this page whole to find the expectation information about certain actor.This is time-consuming process for user.In addition, this may make user miss quite a few TV programme or suspend TV programme with through program thus to obtain this type of information.
Therefore, the mechanism presenting the mobile content corresponding with media content is expected to be useful in.
Summary of the invention
Provide for presenting the method corresponding with media content, system and medium.
Embodiment there is provided a kind of for providing the method for the information relevant to media content according to some of disclosed theme, described method comprises: use hardware processor to determine the channel providing TV programme; Use described hardware processor to make the multiple images relevant to described TV programme to be presented, wherein said multiple image is selected based on described channel and time parameter; Use described hardware processor to receive to select the user from the image in described multiple image; Use described hardware processor, use one or more image recognition technology to identify the entity in selected image; Described hardware processor is used to generate search inquiry based on identified entity at least in part; Use described hardware processor, obtain multiple Search Results in response to generated search inquiry; And use described hardware processor, in response to receive the user of described image is selected and make in described multiple Search Results at least one be presented to described mobile device.
According to some implementation systems of disclosed theme, provide a kind of for providing the system of the information relevant to media content, described system comprises: hardware processor, and described hardware processor is configured to: determine the channel providing TV programme; The multiple images relevant to described TV programme are presented, and wherein said multiple image is selected based on described channel and time parameter; Receive and the user from the image in described multiple image is selected; Use one or more image recognition technology to identify the entity in selected image; Search inquiry is generated at least in part based on identified entity; Multiple Search Results is obtained in response to generated search inquiry; And in response to receive the user of described image is selected and make in described multiple Search Results at least one be presented to described mobile device.
According to some embodiments of disclosed theme, provide a kind of non-transitory computer-readable medium comprising computer executable instructions, described computer executable instructions makes described processor perform when being executed by processor a kind of for providing the method for the information relevant to media content.Described method comprises: determine the channel providing TV programme; The multiple images relevant to TV programme are presented, and wherein, described multiple image is selected based on described channel and time parameter; Receive and the user from the image in described multiple image is selected; Use one or more image recognition technology to identify the entity in selected image; At least in part based on described identification entity and generate search inquiry; Multiple Search Results is obtained in response to generated search inquiry; And in response to receive the user of described image is selected and make in described multiple Search Results at least one be presented to described mobile device.
Embodiment there is provided a kind of for providing the system of the information relevant to media content according to some of disclosed theme.Described system comprises: for determining the device of the channel providing TV programme; For the device that the multiple images impelling relevant to described TV programme are presented, wherein, described multiple image is selected based on described channel and time parameter; For receiving the device selected the user from the image in described multiple image; For using one or more image recognition technology to identify the device of the entity in selected image; For generating the device of search inquiry at least in part based on identified entity; For obtaining the device of multiple Search Results in response to generated search inquiry; And in response to receive the user of described image is selected and make in described multiple Search Results at least one be presented to the device of described mobile device.
In some embodiments, described system also comprises the device for receiving the voice data corresponding with TV programme from mobile device, and wherein said channel is determined based on received voice data.
In some embodiments, described system also comprises the device of the audio-frequency fingerprint for obtaining described voice data.
In some embodiments, described system also comprises the device for generating described audio-frequency fingerprint from received voice data.
In some embodiments, described system also comprises: for extracting the device of audio stream from each in multiple television channel; For the device generating at least one audio-frequency fingerprint at least partially for the audio stream that extract corresponding with in described multiple television channel of each in described multiple television channel; And the device at least one audio-frequency fingerprint described is stored in the database of indexing by channel.
In some embodiments, described system also comprises: for the device compared with at least one audio-frequency fingerprint stored by audio-frequency fingerprint; And for relatively identifying described TV Festival destination device based on described.
In some embodiments, described system also comprises: for extracting the device of multiple program video from each in multiple television channel; And for described multiple program video being stored in by the device in the database of channel and time index.
In some embodiments, described system also comprises for using determined channel and described time parameter to obtain the device of described multiple image, and wherein, described multiple image is the subset of extracted multiple program video.
In some embodiments, described system also comprises: for receiving the device selected the second user of the area-of-interest in selected image; And for using described one or more image recognition technology to identify the device of the entity in described area-of-interest.
In some embodiments, described system also comprises: for using face recognition technology to detect the device of the multiple faces in selected image; For the device of pointing out described mobile device to select face from detected multiple faces; And for identifying the device of the entity be associated with selected face.
In some embodiments, described system also comprises: for accessing guide data to determine described TV Festival destination device based on determined channel and described time parameter; For receiving the device of the programme information relevant to described TV programme; And for using the programme information received to identify the device of the entity in selected image.
Accompanying drawing explanation
When considering in conjunction with the following drawings, the following embodiment with reference to disclosed theme more fully can understand the various objects of disclosed theme, feature and advantage, the element that Reference numeral identification identical is in the drawing identical.
Fig. 1 shows the illustrated examples of the process for presenting Search Results based on media content of some embodiments according to disclosed theme.
Fig. 2 show according to some embodiments of disclosed theme for determining that based on voice data channel and other programme information also transmit the illustrated examples of the process of the Snipping Tool be associated with voice data.
Fig. 3 shows the illustrated examples of the process for generating search inquiry of some embodiments according to disclosed theme, and this search inquiry comprises the entity gone out from the user-selected image recognition by client application.
Fig. 4 shows the equipment providing the media content of such as TV programme of some embodiments according to disclosed theme, and the illustrated examples of mobile device, this mobile device provides multiple images relevant to TV programme, for selecting the interface of image and the Search Results relevant with the entity recognized in the picture when client application is initiated.
Fig. 5 show according to some embodiments of disclosed theme be suitable for as herein described for providing the schematic diagram of the demonstrative system of the realization of the mechanism of the content (such as Search Results) corresponding with media content.
Fig. 6 shows according to the detailed example of in the operable server of some embodiments of disclosed theme and the computing equipment of Fig. 5.
Embodiment
A kind of mechanism for presenting the mobile content corresponding with media content is embodiment there is provided according to some of disclosed theme.
In some embodiments, these mechanism can audio reception data or any other suitable media data relevant to one or more program.Such as, in response to starting client application on the mobile apparatus, these mechanism can enter channel detection pattern, and it comprises activation audio input device (such as, microphone) and catches the voice data corresponding with the current TV programme presented on the display device.In particularly example, audio-frequency fingerprint or other suitable numeral any can be generated from received voice data, audio-frequency fingerprint wherein can be used to identify the same or similar part of voice data.
In response to receiving voice data, this mechanism can identify the channel providing TV programme.Such as, when receiving voice data and/or audio-frequency fingerprint, the expression (such as, other audio-frequency fingerprint, other voice data etc.) that this mechanism can store voice data and other compares to identify this channel.
In some embodiments, it should be noted and may not capture voice data.Such as, channel detection pattern can comprise by using client application to carry out channel-identification to detect media playback (these media heavily equipment of visiting are connected to mobile device) the current channel be transferred to.In another example, when mobile device comprises the transmitter of the code for transmitting such as infrared code or code sequence to media playback, last channel of user's selection that channel detection pattern can comprise by determining mobile device carrys out channel-identification.In this example, when mobile device and user input device (such as, telepilot) when being connected via communication network, the inquiry that channel detection pattern can comprise by transmitting last channel selected for user to user input device carrys out channel-identification.In another example, client application can present channel list for selection to the user of mobile device.In this example, client application can allow user's indicating user of mobile device just at the specific channel of the upper viewing of media playback (this media playback or can not be connected to mobile device).
Use the channel information or other suitable programme information any that are associated with voice data, this mechanism can obtain the multiple images relevant to program.Such as, these mechanism can enter Snipping Tool browse mode, it comprises the database of access images (such as, the Snipping Tool of programme content) and obtains multiple images that are corresponding with identified channel and time parameter (such as, last N minute).Then image can be transmitted back to the client application that performs on the mobile apparatus look back for the user of client application and select.In this example, client application can present to user the multiple images comprising the scene presented by channel in special time period.
In response to receiving the selection of user in image, this mechanism can generate search inquiry.Such as, in response to receiving selected image, these mechanism can enter result display mode, and this result display mode comprises the entity (such as, people, position, boundary mark, object etc.) in the selected image of identification and generates search inquiry based on identified entity at least in part.In particularly example, this mechanism can comprise and uses one or more image recognition technology (such as, image recognition, optical character identification, recognition of face etc.) to identify one or more entities in selected image.In another particularly example, this mechanism can receive the area-of-interest in selected image, and can identify one or more entity in this region-of-interest.This area-of-interest can comprise the user's defined range such as comprising Given Face, particular landmark etc.
When generating search inquiry, this mechanism can perform search to obtain Search Results in response to the search inquiry comprising identified entity.Search Results can comprise in response to the project in search inquiry the URL(uniform resource locator) (URL) be such as associated with web page.In some embodiments, this mechanism can select at least one in Search Results to be sent to client application for presenting to user.In some embodiments, all Search Results can be sent to client application for presenting to user by described mechanism.As an alternative, described mechanism can automatically open the webpage be associated with selected Search Results (such as, the Search Results of foremost) in the suitable web-browsing application performed on the mobile apparatus.It should be noted and any suitable content can be supplied to mobile device, such as comprise entity information, the entity information of summary, the answer that link set, with the entity that identify corresponding news information etc. corresponding with institute identifying information.
Although it should be noted that embodiment relate generally to as herein described provides the mobile content corresponding with TV programme, this is only illustrative.Although TV programme can be media content that is live, broadcast, this mechanism can be embodied as and the mobile content corresponding with recorded content, OTT (over-the-top) content etc. is provided.
These mechanism can use in various applications.Such as, these mechanism can be utilized for mobile device user provides and carries out mutual chance with the media content presented on the display device.In another example, these mechanism can be used to when not inputting text based search inquiry in search engine as mobile device user provides the additional information be associated with presented media content.In another example, then automatically can present Snipping Tool and entity relevant information then to user in response to startup realizes the client application of mechanism described herein.
Forward Fig. 1 to, show the illustrated examples 100 of the process for presenting Search Results based on media content according to some embodiments of disclosed theme.At 105 places, computing equipment can load the client application presenting Search Results based on media content.Computing equipment can be mobile device (such as, cell phone, smart phone, tablet computing device, wearable computing equipment etc.).
It should be noted that media content can comprise the one or more programs from each provenance, such as air broadcast program, the program of being broadcasted by cable television provider, the program of being broadcasted by phonevision provider, the program of being broadcasted by satellite television provider, request program, OTT program, internet content, flow-medium performance, institute's recorded program etc.
At 110 places, once client application is loaded, this client application can enter channel detection pattern, and it can be started by the audio sample obtaining the current TV programme presented.Such as, client application can activate the audio input device of the such as microphone being coupled to computing equipment, and wherein this audio input device catches and record audio sample or other suitable voice data any of being associated with presented TV programme.In another example, client application can receive the user's instruction in order to store the voice data for being transferred to Audio Matching service.
In some embodiments, client application can activate audio input device, and this audio input device catches audio frequency from its surrounding environment and uses suitable wave filter and/or other audio frequency to strengthen the voice data extracted with presented TV programme associated audio fingerprint or filtering.Such as, the unvoiced section of audio sample can be removed to reduce the document size of audio sample.In another example, can remove there is distortion audio sample part to reduce the document size of audio sample.In another example, do not comprise the voice data with given quality at least partially in response to what determine audio sample, client application can point out another audio sample of user record of client application.
In some embodiments, the client application run on the computing device can use any suitable audio-frequency fingerprint recognition technology to generate the audio-frequency fingerprint of audio sample at 215 places.This audio-frequency fingerprint can be the numeral generated from received audio sample, and wherein this audio-frequency fingerprint can be used to the identical or similar portions identifying voice data.As an alternative, the audio sample be associated with TV programme can be sent to the search system generating audio-frequency fingerprint by client application.
At 120 places, client application can transmit obtained audio sample and/or audio-frequency fingerprint for analysis.Such as, in startup client application when activating audio input device, audio sample and/or audio-frequency fingerprint streaming automatically can be transferred to the search system of access coupling service (such as, the service of audio-frequency fingerprint coupling) by client application.As mentioned above, audio sample streaming can be transferred to search system by client application, and wherein this search system generates the audio-frequency fingerprint corresponding with audio sample, and this audio-frequency fingerprint is sent to the service of audio-frequency fingerprint coupling for analysis.
In some embodiments, additional information can be transmitted together with audio sample, additional information such as client device information, subscriber profile information, positional information, user preference, timing information and can be used for generating the out of Memory of search inquiry be associated with the audio sample of TV programme.
It should be noted that client application wherein (or other mechanism as herein described) is collected in the embodiment described herein about the information of specific user, client application can be controlled whether collect the chance how information and/or collected user profile about specific user to be used by client application for user provides.Example about the information of user can comprise the interest of user and the identifying information (such as, user profiles, user certificate, device identification etc.) of user.In addition, about some information of user can be locally stored (such as, not sharing), encryption and/or before it is stored with one or more mode process to remove individual identifiable design information.Such as, client application anonymous identifier (e-mail address etc. of the user identifier such as, be not associated with the name of user, the user name of user and/or password, user) stores user preference for specific user and/or user interest.Use these technology, user can control to collect and about what information of user and/or this information how be used by client application.
Forward Fig. 2 to, when receiving audio sample and/or other additional information at 205 places from client application, the audio-frequency fingerprint of the audio sample received by can generating at 210 places.Again, can audio-frequency fingerprint be generated by client application or other suitable application any and sent it to search system for analysis.
At 215 places, generated audio-frequency fingerprint and multiple audio-frequency fingerprint can compare by search system.Such as, the subset of the audio-frequency fingerprint be associated with audio sample generated from client application with the audio-frequency fingerprint stored can be compared.In particularly example, search system can accessing database or comprise other suitable memory device of multiple audio-frequency fingerprint and described multiple audio-frequency fingerprint is filtered into the subset of audio-frequency fingerprint by position-based information, user preference and the out of Memory that receives from client application.In this example, the audio-frequency fingerprint be associated with the positional information received can be only used to compare with the audio-frequency fingerprint generated.In another example, the special audio fingerprint from database or memory device can be used to compare before other, the audio-frequency fingerprint be such as associated with welcome channel, the audio-frequency fingerprint of renewal, the audio-frequency fingerprint etc. usually mated.
In some embodiments, such as, search system can comprise the capture module receiving also processing signals from multiple source (such as, multiple channel).These capture modules can catch video screen snapshot and/or generate audio-frequency fingerprint from voice data with specified time interval for each channel with the specific time interval (such as, every two seconds or three seconds).Generally speaking, these capture modules can monitor the media content from multiple content source, and generating video Snipping Tool, audio-frequency fingerprint and/or other suitable content designator any.More particularly, generated video screen snapshot, audio-frequency fingerprint and other content designator can be stored in memory device by these capture modules.Such as, capture module can monitor and provide the channel of broadcast television content and in the database be stored in by generated audio-frequency fingerprint by channel and time index.
It should be noted, generated video screen snapshot, audio-frequency fingerprint and other content designator by channel and time index can be abandoned in some embodiments after the schedule time.Such as, in response to determining that video screen snapshot joins with the time correlation outside special time window, search system or other suitable assembly any can remove video screen snapshot from database.
At 220 places, can determine whether to find coupling.If do not find the audio-frequency fingerprint mated, then search system can turn back to 205 and wait for from client application and receive supplemental audio sample.Addedly or as an alternative, search system can transmit message request user to client application and restart client application, transmit another audio sample and/or input or verify customizing messages (such as, programme information, such as channel, service provider information, programm name etc.).
In response to recognizing audio-frequency fingerprint coupling at 220 places, search system can identify the channel or other suitable content designator any that are associated with the audio-frequency fingerprint mated.Such as, coupling audio-frequency fingerprint can be associated with channel (such as, channel X), and search system uses this association to determine that the user of client application is watching the TV programme provided on this channel.In another example, search system can transmit to client application the notice that channel has been identified.Such as, this notice can comprise the instruction that search system has successfully identified channel from received audio sample and/or the channel that identifies.
It should be noted in some embodiments, client application can initiate channel detection pattern (such as, the step 110-120 of Fig. 1 and the step 205-220 of Fig. 2) when not catching audio-frequency information or use audio-frequency fingerprint.
In some embodiments, search system can comprise by detect media playback (it is connected to mobile device) the current channel be transferred to carry out channel-identification.Such as, search system can transmit inquiry to determine which equipment is connected to mobile device to mobile device.In response to determining that the media playback of such as television equipment or Set Top Box is connected to mobile device, search system can the application of instructing client end be carried out communicating to determine the current channel be transferred to of media playback with media playback.As an alternative, in response to determining that the user input device of such as telepilot is connected to mobile device, search system the application of instructing client end can carry out last channel of communicating to determine to be transferred to or previous channel with user input device.
In example particularly, the client application performed on the mobile apparatus can comprise the second screen application, or can communicate with second screen application of installing on the mobile apparatus.Second screen application can such as allow the user to mobile device or other the second screen equipment to present the content of the media playback being sent to such as television equipment or Set Top Box.Client application can use the second screen application to determine the channel that media playback is just presenting on the second screen equipment.
In another example particularly, the client application performed on the mobile apparatus can comprise remote control application, or can communicate with the remote control application of installing on the mobile apparatus.Remote control application can such as allow mobile device to issue order (such as, channel increasings, channel down etc.) in order to control media playback and responsively and the infrared transmitter that instruction is connected to mobile device transmits the infrared code of correspondence to media playback.Client application can use remote control application to determine last channel or previous channel of being transferred to.
In some embodiments, client application can present channel list for selection to the user of mobile device.In this example, search system can receive user just at specific channel or other suitable content designator any of the upper viewing of media playback (it or can not be connected to mobile device).
In some embodiments, client application can enter Snipping Tool browse mode, and it can start the request of the image corresponding with identified channel by transmitting at 230 places.Such as, client application can automatically transmit to image (such as video screen snapshot), to identified channel and the request to specified time interval (Snipping Tool of last N minute that the channel such as, coming freely to identify provides) to search system.As mentioned above, search system can comprise one or more database or other suitable memory device, other image that described memory device comprises stored video screen snapshot and catches from the media content provided by multiple source.
Responsively, search system can receive multiple Snipping Tool or other image based on identified channel and given interval from accessed database at 235 places.Such as, search system can receive the multiple Snipping Tools corresponding with the program of five minutes that provide on a particular channel.
At 240 places, multiple Snipping Tool and other image can be sent to client application for presenting to user.
Referring back to Fig. 1, at 125 places, the multiple images be associated with TV programme can be presented to user.Such as, the image (such as, Snipping Tool) that client application can allow user from first to last to roll different, wherein user can vertically or flatly roll on the computing device.In another example, client application can provide whole multiple images for user, and wherein user can carry out translation and amplification to specific image.
In response to receiving and presenting multiple image to user, client application can select image 130 place prompting users from multiple image.Such as, client application can detect that the region highlighted is placed on the time of image also being pressed on the computing device suitable button by user.In another example, when computing equipment is the mobile device with touch-screen, client application can respond the contact with touch-screen, and the one or many on such as touch-screen knocks, in the movement etc. keeping the contact point while contact continuously.
In some embodiments, select the user of image in response to receiving at 130 places, client application can select area-of-interest 135 place prompting users in selected image.Such as, when computing equipment is the mobile device with touch-screen, client application can ask the particular region of interest of user in selected image provides one or many to knock.In example particularly, client application can be analyzed selected image and selected image is divided into one or more subsegment (such as, based on identified object).
In embodiment particularly, client application can use face recognition technology to detect the one or more faces in selected image.Responsively, the chance of during client application can provide detected by selection for user face.Such as, user can select the face of the interested actor in selected image.Selected face can be used to further graphical analysis and query generation.Addedly or as an alternative, client application can use Identifying Technique of Object the one or more objects in selected image to be detected.This can comprise the project identified in selected image, boundary mark and/or position.Similarly, the chance of in the object that client application can provide detected by selection for user, described detected object can be used to further graphical analysis and query generation.
At 140 places, client application can enter result display mode, and the user that this result display mode can comprise other suitable part any of selected image, selected area-of-interest, selected face, selected objects and/or image selects to be sent to search server.
Forward Fig. 3 to, in response to other the suitable part any receiving selected image and/or image at 305 places, search system can use one or more image recognition technology to identify the entity in selected image.Such as, entity can comprise people, place, event, object, animal, mark, characteristic, feature or any other suitable entity relevant with TV programme.These entities can be associated with TV programme in every way.Such as, the image of people or boundary mark can be included in the vision signal be associated with program.
In a particular example, can based on face recognition technology identify the entity that is associated with TV programme with identify be included in be associated with program selected by people in image, such as actor and actress.In another example, can based on image recognition technology identify the entity that is associated with TV programme with identify be included in be associated with program selected by boundary mark in image.In another example, can based on optical character recognition identify the entity that is associated with TV programme with identify be included in be associated with program selected by key word in image.
In some embodiments, search system can obtain for providing additional information to identify the guide data of the entity in selected image.Such as, the search system of the guide data of such as electronic program guide data is used can to obtain the list of the actor of the TV programme provided on identified channel, actress and/or cast member.This type of guide data can be provided together with selected image, wherein search system can use one or more image recognition technology to identify the entity in selected image.Guide data such as can be used for filter false certainly, thus improves Entity recognition accuracy.Identified entity can be transmitted back to search system from picture recognition module.
In some embodiments, when recognizing entity, search system can generate search inquiry at 315 places.This type of search inquiry can comprise identified entity and/or the information relevant to identified entity.Such as, this search system can generate the search of the title comprising identified entity for the transmission to search engine.In some embodiments, search inquiry can also comprise by search system and/or client application at the content information previously obtained.
At 320 places, search system can perform search.In some embodiments, search system can perform search by generated search inquiry is sent to search engine, and then this search engine can perform search.In some embodiments, search system can use search application programming interface (API) to search for Search Results in various content source in response to generated search inquiry.The Search Results in response to generated search inquiry can be obtained at 325 places.
In some embodiments, search system can use any suitable method one or more to what select in Search Results.Such as, search system can be selected most popular Search Results (such as, coming the Search Results of foremost), select maximally related Search Results etc.
As an alternative, as selecting substituting of one or more Search Results, all Search Results can be sent to client application for presenting to user by search system.This can allow scanning input to pass through Search Results and select the suitable Search Results for obtaining the additional information about the expectation entity from image.
In some embodiments, search system can use one or more criterion to carry out rank to Search Results.Such as, search system can assign weight to each Search Results, and the Search Results that news is correlated with is by the Search Results weighting higher of being correlated with than business.In another example, search system can determine that the user of client application sets user preference, and described user preference indicates the preference of Search Results or the page of being correlated with from specific website reception news.In this example, search system can based on this type of user preference automatically filter search results.
At 330 places, one or more Search Results can be sent to client application for presenting to user.Referring back to Fig. 1, then client application can receive and present the one or more Search Results be associated with selected image and/or area-of-interest to user.Such as, client application can in response to selection image and provide Search Results to user, and then, user can select for about in selected image identify the Search Results of the additional information of entity.In another example, client application can load the page be associated with Search Results in web-browsing application.That is, in response to loading client application and selection image of interest, client application can for user's providing package be containing the page of the information relevant to the entity identified in selected image.
It should be noted, in some embodiments, client application can transmit the audio sample relevant to the TV programme presented or other suitable voice data any to search system continuously and/or periodically.Responsively, the image upgraded can be provided for you to choose to client application, and provide Search Results when have selected in image one.More specifically, with the audio sample upgraded with recently select the corresponding Search Results of image can be turned back to client application continuously and/or periodically and show on the graphic user interface be associated with client application (web-browsing such as, loading the URL be associated with Search Results is applied).
Should also be noted that the channel that the user that client application can continue identify customer end application is in some embodiments transferred to.Such as, become another in response to from a channel, client application can receive and upgraded audio sample and upgraded audio sample carry out channel-identification based on this.In another example, client application can continue access second screen application or remote control application (such as, in predetermined time) and identify last channel be transferred to.
Fig. 4 to show according to the display of television programmes of some embodiments of disclosed theme or the television equipment 400 of other suitable media content and display for selecting image, select area-of-interest and/or present the computing equipment 410 at multiple interfaces of the content relevant to identified entity.As shown, television equipment 400 can display of television programmes 405 (or other suitable media content) over the display.
In response to transmitting the audio sample (such as, the audio-frequency fingerprint that generate) corresponding with the TV programme 405 provided on television equipment 400, computing equipment 410 can processing audio sample to determine the channel corresponding with audio sample.As mentioned above, this can comprise and to be generated and the audio-frequency fingerprint be stored in audio fingerprint database compares with by catching voice data from multiple channel by generated audio-frequency fingerprint.This coupling audio-frequency fingerprint can be used for identifying the channel be associated with audio sample, and then, this channel can be used as the identifier in image data base (such as, video screen snapshot) to retrieve the multiple images relevant to one or more TV programme.Similarly, as described above, other proper method can be used to carry out channel-identification, such as by carrying out communicating last channel determining to be transferred to the second screen application or remote control application.Can also by with channel identifier list can be selected to point out the user of mobile device and receive user select channel carry out channel-identification.
As mentioned above, the computing equipment 410 of such as the second screen equipment can be coupled to television equipment 400 (such as, communicate with television equipment 400) or make program 405 be present in equipment on television equipment 400, such as Set Top Box or digital media receiver.In some embodiments, computing equipment 410 can be not coupled to television equipment 400 autonomous device or make program 405 be present in equipment (such as, the second screen equipment of such as mobile phone or flat computer communicates with search server) on television equipment 400.Similarly, as described above, computing equipment 410 can be suitable for user present entity be correlated with in any computing equipment of perhaps other content association, such as smart phone, flat computer, wearable computer, head-up display, laptop computer, personal computer (PC), intelligent television etc.
As shown, multiple image 415 and 420 is presented to user on the graphic user interface be associated with client application.It should be noted and can present image in any suitable manner---such as, wherein present the rolled image list of image one at a time, once can present multiple images etc. based on the size of the display of computing equipment 410.Such as, when computing equipment be such as tablet computing device there is the second screen equipment of large display time, multiple image can be presented in graphical user interfaces.In another example, when computing equipment is smart phone, once can present an image, and the option navigating to another image (such as, use one or more gesture on the touchscreen, press suitable button etc. on smart phone) can be provided for user.
In some embodiments, client application can indicate and be easily selected by a user from the image in multiple image.Such as, as shown in Figure 4, region 415 can be highlighted in selected image peripheral placement to select with indicating user.In another example, client application can wait for the second action with instruction to the selection highlighting image, such as waving and sweep gesture or user presses the button on the touchscreen.
In some embodiments, in response to have selected image, client application can ask user to provide further information about selected image.Such as, as shown in Figure 4, in response to have selected image 415 (such as, the Snipping Tool in the TV programme of special time), client application can ask user to select area-of-interest 430.Such as, area-of-interest 430 can be the region of the free form of being painted by user.In another example, multiple region (such as, use the face of face recognition technology, use the object etc. of Identifying Technique of Object) can be presented when performing image recognition technology by client application.In these examples, client application can ask user to select area-of-interest to be transmitted back to search system for together with selected image.This such as can promote that search system generates the search inquiry for expecting entity (such as, actor, actress, boundary mark, object etc.).
In some embodiments, client application can also provide the supplementary option relevant to selected image or selected area-of-interest for user.Such as, as shown in Figure 4, client application can provide option 435 for user.Option 435 can ask user to select enquirement project to be transmitted back to search system for together with selected image and/or selected area-of-interest.As shown, whom enquirement project comprises (such as, is whom in selected image), what (such as, what object shown in selected image or boundary mark is) and where (where this scene such as, in selected image occurs).This also can promote that search system generates the search inquiry for expecting entity (the actor vs boundary mark such as, in selected image).
Equally as shown in Figure 4, suitable information is transmitted (such as in response to search system, selected image, selected area-of-interest, enquirement item etc.), search can be generated with the entity identified in selected image, and one or more Search Results 440 can be presented to user.In this particular example, display of search results 440 on the graphic user interface be associated with client application (network browsing such as, loading the URL be associated with Search Results is applied).More specifically, in response to recognizing entity (such as, actor) in the area-of-interest 430 in image 415, automatically actor's film works catalog page can be shown to the user of client application.
Forward Fig. 5 to, show in the above for presenting the illustrated examples 500 of the vague generalization schematic diagram of the system of the mechanism of mobile content based on media content according to some embodiments of disclosed theme.As illustrated, system 500 can comprise one or more computing equipment 510.Computing equipment 510 can be connected to the communication network 506 that can link to server 502 via communication link 504 by one or more communication link 508.In some embodiments, computing equipment 510 and server 502 can be linked to one or more content source 514 via communication link 512.
System 500 can comprise one or more server 502.Server 502 can be any suitable server of access for providing search application, such as processor, computing machine, data processing equipment or this kind equipment any appropriately combined.Such as, can by search application distribution to multiple aft-end assembly and multiple front end assemblies and/or interface.In example particularly, the rear end group of such as Data Collection and Data dissemination can be performed on one or more server 502.
In some embodiments, the front end assemblies of the search application (or part of search application) of such as user interface and/or channel recognition feature can be performed on one or more computing equipment 510.
In some embodiments, each in computing equipment 510 and server 502 can be any one in the common apparatus of such as computing machine or the specialized equipment of such as client, server etc.Any one in these universal or special equipment can comprise any suitable assembly, such as hardware processor (it can be microprocessor, digital signal processor, controller etc.), storer, communication interface, display controller, input equipment etc.Such as, computing equipment 510 can be embodied as smart phone, flat computer, wearable computer, intelligent television, Set Top Box, digital media receiver, game console, personal computer, laptop computer, personal digital assistant (PDA), home entertainment system, other suitable computing equipment any or it is any appropriately combined.
Such as, in some embodiments, the first computing equipment 510 can be used to present program, first computing equipment 510 such as intelligent television, Set Top Box, digital media receiver etc., and the second computing equipment 510 can be used to present supplemental content, the second computing equipment 510 such as flat computer, smart phone, wearable computer, PDA etc.
In some embodiments, content source 514 can be any suitable content source, such as wired (or phone) television content source, satellite television content source, request program content source, OTT program content source, internet content source, stream transmission program content source, other suitable content source any or it is any appropriately combined.
In some embodiments, communication network 506 can be the combination of any suitable computer network or such network, and shown such network comprises the Internet, in-house network, wide area network (WAN), LAN (Local Area Network) (LAN), wireless network, Digital Subscriber Line (DSL) network, frame-relay network, asynchronous transfer mode (ATM) network, VPN (virtual private network) (VPN) etc.Communication link 504,508 and 512 can be any communication link being suitable for transmitting data between computing equipment 510, server 502 and/or content source 514, such as network link, dial-up link, wireless link, hardwire link, other suitable communication link any or this type of link any appropriately combined.Computing equipment 510 can make it possible to use the techniques described herein, and shown calculating can allow the feature using described mechanism.Computing equipment 510, server 502 and content source 514 can be positioned at any suitable position.
In some embodiments, server 502 can comprise one or more module 520-532 and/or can, by the database 540-542 interconnected, be used for generating based on media content information and presenting the mechanism of Search Results for the various function and/or promotion that perform search application.
In some embodiments, front-end server module 520 can perform the process for generating interactive content as combined such as described in Fig. 1-3 above.Such as, front-end server can serve as the client application that performs on computing equipment 510 and such as capture module 522, Audio Matching module 542, Snipping Tool and browses agency between other server module of module 526 and search module 532.
In some embodiments, as combined such as described in Fig. 1 above, capture module 522 can receive the media data relevant to program or channel, such as video data, voice data, electronic program guide data, metadata etc.Addedly or as an alternative, capture module 522 can from extracting various media data from the content that content source provides, as combined such as described in Fig. 1.This type of extracts media data can comprise such as audio-frequency fingerprint, captions, video screen snapshot etc.This information can be stored in such as database (not shown) to be applied in when channel-identification, acquisition Snipping Tool and/or various other operate for the search performed on front-end server 520 and use.
In some embodiments, Audio Matching module 524 can receive from capture module 524 audio fingerprint data being used for program, and the audio fingerprint data received and the audio fingerprint data be stored in fingerprint database 542 is compared.This fingerprint database can such as be used for channel-identification as described above, determine to present to the program etc. of user.
In some embodiments, Snipping Tool is browsed module 526 and can be extracted one or more image based on identified channel.Such as, based on identified channel, Snipping Tool browses module 526 can retrieve the image corresponding with the special time window that this channel is associated.Select in response to the user received image, Snipping Tool is browsed module 526 and keyword-extraction module 528 or other suitable module any can be used to come from image zooming-out and identify one or more entity.In addition, Snipping Tool browses module 526 can comprise identification module 530, and it is configured to perform one or more recognition technology, such as face recognition technology, image recognition technology, optical character recognition etc.
In some embodiments, keyword-extraction module 528 can extract entity, the entity such as above described in composition graphs 1.Such as, keyword-extraction module 528 can extract the identity of people, place, event, object, animal, mark or other suitable entity any.Addedly or as an alternative, keyword-extraction module 528 can use identification module 530 to identify entity, the database of the information of the image of the face from video Snipping Tool and known face information (such as, the face information of known individuality) such as can be compared the identity of the people determined in image by this identification module 530.Similarly, identification module 530 such as can will compare the identity of the object determined in image from such as buildings, decree, the packing of product, electronic installation, fruit and the object of vegetables or the information of image of other suitable object any and the database of known object information.As mentioned above, any suitable recognition technology can be identified module 530 and is used for promoting to browse by keyword-extraction module 528 and/or Snipping Tool the Entity recognition that module 526 carries out from program related data.
In some embodiments, front-end server module can access search module 532.Search module 532 such as can generate search inquiry based on the entity identified in selected image and perform search in response to search inquiry to obtain Search Results.In example particularly, identified entity can be sent to search module 532, search module 530 constructs the one or more search inquiries relevant to the content that the channel identified and the entity information identified are associated.Once generate relevant search inquiry, this search inquiry can be supplied to suitable search engine, shown search engine response in search inquiry in one or more thesaurus and index Search Results.In some embodiments, search engine can be that searched module 532 uses the general search engine such as searched for application programming interface (API) and access.As an alternative, search engine can be the search engine exclusively by the front-end server 520 of system 500 or other assembly any use.
As mentioned above, in some embodiments, can filter and/or personalization Search Results based on the user of client application.Such as, can remove based on user search history, previous user interactive selection, user's setting, user profiles, client device type, customer location and/or other user profile and/or retain Search Results.Search Results can be supplied to front-end server 520, Search Results is generated as the form being suitable for result to send back to the client application performed on computing equipment 510 by front-end server 520.Such as, Search Results can be formatted as HTML (Hypertext Markup Language) (HTML) content, it can allow the web-browsing application display of search results on computing equipment 510 (such as, by loading the webpage be associated).In another example, Search Results can be formatd, make in its client application that can be shown in execution on computing equipment 510.That is, in response to loading client application and selection image of interest, client application can show the Search Results corresponding with media content.
In some embodiments, the guide data 540 of such as electronic program guides (EPG) database can be accessed.Such as, front-end server module 520 can access guide data 540 with obtain to identified channel or the relevant programme information of identification program, and use this programme information to come Filtering entity, Search Results etc.It should be noted, in some embodiments, guide data 540 can be provided from such as content source 514.
It should be noted, although module 520-532 and database 540-542 is illustrated as being included in server 502, these modules and/or database can be provided with various being combined in different servers.Such as, search module 532 can be provided in first server, and module 520-530 can be provided on second server.As another example, each module can be provided on different server.It should be noted, these are only examples, and can organize described module in any suitable manner.
Should also be noted that, being module 520-532 to be comprised the part for search application, can eachly be independent application, or can be any part that other is suitably applied.
Fig. 6 illustrates the example 600 according to the hardware of one in the server 502 that can be used for realizing describing in Fig. 5 of some embodiment of disclosed theme and computing equipment 510.With reference to figure 6, computing equipment 510 can comprise can by hardware processor 612, display 614, input equipment 616 and the storer 618 interconnected.In some embodiments, storer 618 can comprise the memory device (such as non-transitory computer-readable medium) for storing the computer program for control hardware processor 612.
Hardware processor 612 can use computer program rendering content and/or interface on display 614, and it allows user and client application interact and are transmitted and receive data by communication link 508.It should also be noted that can receive from any suitable source by communication link 508 or other communications link reception any to data.In some embodiments, hardware processor 612 can use such as transmitter, receiver, emittor/receiver, transceiver or other suitable communication facilities any to transmit and receive data by communication link 608 or other communication link any.Input equipment 616 can be computer keyboard, mouse, trace ball, keypad, telepilot, other suitable input equipment any or its any combination suitably.Addedly or as an alternative, input equipment 616 can comprise the touch-screen display 614 that can receive input (such as using finger, contact pilotage etc.).
Server 502 can comprise can by hardware processor 622, display 624, input equipment 626 and the storer 628 interconnected.In some embodiments, storer 628 can comprise for storing by communication link 504 or the memory device by other data received, and storer 622 can receive the order and value that are transmitted by one or more users of such as computing equipment 510.Memory device may further include the server program for control hardware processor 622.
Software, firmware, hardware can be embodied as in computing equipment 510 and/or server 502 or it is any appropriately combined for providing the mechanism described herein of Search Results and other content based on media content.
In some embodiments, server 602 can be embodied as a server or the server of any proper number can be distributed as.Such as, multiple server 502 can be realized can carry out with computing equipment 510 speed that communicates to increase reliability, the function of application and/or server on various position.
In some embodiments, client application can comprise application interface (not shown), and/or can reside in the storer 618 of computing equipment 510 and/or the storer 628 of server 502.Addedly or as an alternative, graphic user interface (" GUI ") can be distributed to computing equipment 510, it can allow user to interact with the client application residing in such as server 502 place.
In some embodiments, application can comprise client side software, SERVER SIDE SOFTWARE, hardware, firmware or it is any appropriately combined.Such as, application can contain the computer program making one or more processor perform content generation application.As another example, application can be contained with performing the computing equipment 510 of application and/or the computer program write of the discernible programming language of server 502 (such as, by the program that programming language is write, this programming language such as Java, C, Objective-C, C++, C#, Javascript, VisualBasic, HTML, XML, ColdFusion, other proper method any or it is any appropriately combined).
In some embodiments, application can contain one or more webpage or web page portions (such as, via any coding suitably, such as HTML (Hypertext Markup Language) (" HTML "), Dynamic Hyper Text Makeup Language (" DHTML "), extend markup language (" XML "), JavaServerPages (" JSP "), Active Server Pages (" ASP "), ColdFusion or other proper method any).
Therefore, method, system and the medium for presenting the mobile content corresponding with media content is provided.
In some embodiments, any suitable computer-readable medium can be used for storing the instruction being used for performing function as herein described and/or process.Such as, in some embodiments, computer-readable medium can be temporary or non-transitory.Such as, non-transitory computer-readable medium can comprise such as magnetic medium (such as hard disk, floppy disk etc.), optical medium (such as compact disk, digital video disc, Blu-ray dish etc.), semiconductor medium (such as flash memory, electrically programable ROM (EPROM), EEPROM (Electrically Erasable Programmable Read Only Memo) (EEPROM) etc.), not transient or lack any suitable medium of any lasting outward appearance and/or any suitable tangible medium during the transmission.As another example, temporary computer-readable medium can be included on network, in wire, conductor, optical fiber, circuit, the transient during the transmission and signal lacked in any suitable medium of any lasting outward appearance and/or any suitable invisible medium.
Being understood that can according to be not limited to shown in figure and the above-mentioned steps of the process of Fig. 1-3 is carried out or performed to any order of described order and sequence or sequence.Further, some above-mentioned steps of the process of Fig. 1-3 can substantially side by side or be concurrently carried out or perform in due course to reduce stand-by period and processing time.
Should also be noted that as used herein term mechanism can contain hardware, software, firmware or it is any appropriately combined.
Although describe in foregoing illustrative embodiment and illustrate the present invention, but be understood that the disclosure only completes in an illustrative manner, and the many changes in the details that embodiments of the present invention can be carried out when not departing from the spirit and scope of the present invention only limited by claim subsequently.Can in every way by the Feature Combination of disclosed embodiment and rearranging.
Claims (30)
1., for providing a method for the information relevant to media content, described method comprises:
Hardware processor is used to determine the channel providing TV programme;
Use described hardware processor to make the multiple images relevant to described TV programme to be presented, wherein said multiple image is selected based on described channel and time parameter;
Use described hardware processor to receive to select the user from the image in described multiple image;
Use described hardware processor, use one or more image recognition technology to identify the entity in selected image;
Described hardware processor is used to generate search inquiry based on identified entity at least in part;
Use described hardware processor, obtain multiple Search Results in response to generated search inquiry; And
Use described hardware processor, in response to receive the user of described image is selected and make in described multiple Search Results at least one be presented to described mobile device.
2. method according to claim 1, comprise further and receive the voice data corresponding with TV programme from mobile device, wherein said channel determines based on received voice data.
3. method according to claim 2, wherein, receives described voice data and comprises the audio-frequency fingerprint obtaining described voice data further.
4. method according to claim 3, comprises further:
Audio stream is extracted from each multiple television channel;
For at least one audio-frequency fingerprint of generation at least partially from the audio stream that extract corresponding with described multiple television channel of each in described multiple television channel; And
At least one audio-frequency fingerprint described is stored in the database by channel index.
5. method according to claim 4, comprises further:
Described audio-frequency fingerprint and at least one audio-frequency fingerprint stored are compared; And
Relatively described TV programme is identified based on described.
6. method according to claim 1, comprises further:
Multiple program video is extracted from each multiple television channel; And
Described multiple program video is stored in the database by channel and time index.
7. method according to claim 6, wherein, the described multiple image relevant to described TV programme is presented by using determined channel and described time parameter to obtain described multiple image, and wherein said multiple image is the subset of extracted multiple program video.
8. method according to claim 1, comprises further:
Receive and the second user of the area-of-interest in selected image is selected; And
Use described one or more image recognition technology to identify the entity in described area-of-interest.
9. method according to claim 1, comprises further:
Use face recognition technology detects the multiple faces in selected image;
Described mobile device is pointed out to select face from detected multiple faces; And
Identify the entity be associated with selected face.
10. method according to claim 1, comprises further:
Access guide data is to determine described TV programme based on determined channel and described time parameter;
Receive the programme information relevant to described TV programme; And
Use the programme information received to identify the entity in selected image.
11. 1 kinds for providing the system of the information relevant to media content, described system comprises:
Hardware processor, described hardware processor is configured to:
Determine the channel that TV programme is provided;
The multiple images relevant to described TV programme are presented, and wherein said multiple image is selected based on described channel and time parameter;
Receive and the user from the image in described multiple image is selected;
Use one or more image recognition technology to identify the entity in selected image;
Search inquiry is generated at least in part based on identified entity;
Multiple Search Results is obtained in response to generated search inquiry; And
In response to receive the user of described image is selected and make in described multiple Search Results at least one be presented to described mobile device.
12. systems according to claim 11, wherein, described hardware processor is configured to receive the voice data corresponding with TV programme from mobile device further, wherein determines described channel based on received voice data.
13. systems according to claim 12, wherein, described hardware processor is configured to the audio-frequency fingerprint obtaining described voice data further.
14. systems according to claim 13, wherein, described hardware processor is configured to further:
Audio stream is extracted from each multiple television channel;
For at least one audio-frequency fingerprint of generation at least partially from the audio stream that extract corresponding with described multiple television channel of each in described multiple television channel; And
At least one audio-frequency fingerprint described is stored in the database by channel index.
15. systems according to claim 14, wherein, described hardware processor is configured to further:
Described audio-frequency fingerprint and at least one audio-frequency fingerprint stored are compared; And
Relatively described TV programme is identified based on described.
16. systems according to claim 11, wherein, described hardware processor is configured to further:
Multiple program video is extracted from each multiple television channel; And
Described multiple program video is stored in the database by channel and time index.
17. systems according to claim 16, wherein, described hardware processor is configured to use determined channel and described time parameter to obtain described multiple image further, and wherein said multiple image is the subset of extracted multiple program video.
18. systems according to claim 11, wherein, described hardware processor is configured to further:
Receive and the second user of the area-of-interest in selected image is selected; And
Use described one or more image recognition technology to identify the entity in described area-of-interest.
19. systems according to claim 11, wherein, described hardware processor is configured to further:
Use face recognition technology detects the multiple faces in selected image;
Described mobile device is pointed out to select face from detected multiple faces; And
Identify the entity be associated with selected face.
20. systems according to claim 11, wherein, described hardware processor is configured to further:
Access guide data is to determine described TV programme based on determined channel and described time parameter;
Receive the programme information relevant to described TV programme; And
Use the programme information received to identify the entity in selected image.
21. 1 kinds of non-transitory computer-readable medium comprising computer executable instructions, described computer executable instructions makes described processor perform when being executed by processor a kind of for providing the method for the information relevant to media content, and described method comprises:
Determine the channel that TV programme is provided;
The multiple images relevant to described TV programme are presented, and wherein said multiple image is selected based on described channel and time parameter;
Receive and the user from the image in described multiple image is selected;
Use one or more image recognition technology to identify the entity in selected image;
Search inquiry is generated at least in part based on identified entity;
Multiple Search Results is obtained in response to generated search inquiry; And
In response to receive the user of described image is selected and make in described multiple Search Results at least one be presented to described mobile device.
22. non-transitory computer-readable medium according to claim 21, wherein, described method comprises further from the mobile device reception voice data corresponding with TV programme, wherein determines described channel based on received voice data.
23. non-transitory computer-readable medium according to claim 22, wherein, described method comprises the audio-frequency fingerprint obtaining described voice data further.
24. non-transitory computer-readable medium according to claim 23, wherein, described method comprises further:
Audio stream is extracted from each multiple television channel;
For at least one audio-frequency fingerprint of generation at least partially from the audio stream that extract corresponding with described multiple television channel of each in described multiple television channel; And
At least one audio-frequency fingerprint described is stored in the database by channel index.
25. non-transitory computer-readable medium according to claim 24, wherein, described method comprises further:
Described audio-frequency fingerprint and at least one audio-frequency fingerprint stored are compared; And
Relatively described TV programme is identified based on described.
26. non-transitory computer-readable medium according to claim 21, wherein, described method comprises further:
Multiple program video is extracted from each multiple television channel; And
Described multiple program video is stored in the database by channel and time index.
27. non-transitory computer-readable medium according to claim 6, wherein, described method comprises further and uses determined channel and described time parameter to obtain described multiple image, and wherein said multiple image is the subset of extracted multiple program video.
28. non-transitory computer-readable medium according to claim 1, wherein, described method comprises further:
Receive and the second user of the area-of-interest in selected image is selected; And
Use described one or more image recognition technology to identify the entity in described area-of-interest.
29. non-transitory computer-readable medium according to claim 1, wherein, described method comprises further:
Use face recognition technology detects the multiple faces in selected image;
Described mobile device is pointed out to select face from detected multiple faces; And
Identify the entity be associated with selected face.
30. non-transitory computer-readable medium according to claim 1, wherein, described method comprises further:
Access guide data is to determine described TV programme based on determined channel and described time parameter;
Receive the programme information relevant to described TV programme; And
Use the programme information received to identify the entity in selected image.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US13/827,413 US9247309B2 (en) | 2013-03-14 | 2013-03-14 | Methods, systems, and media for presenting mobile content corresponding to media content |
US13/827,413 | 2013-03-14 | ||
PCT/US2014/024255 WO2014159578A1 (en) | 2013-03-14 | 2014-03-12 | Methods, systems, and media for presenting mobile content corresponding to media content |
Publications (1)
Publication Number | Publication Date |
---|---|
CN105122242A true CN105122242A (en) | 2015-12-02 |
Family
ID=50771560
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201480021167.4A Pending CN105122242A (en) | 2013-03-14 | 2014-03-12 | Methods, systems, and media for presenting mobile content corresponding to media content |
Country Status (7)
Country | Link |
---|---|
US (3) | US9247309B2 (en) |
EP (1) | EP2973037A1 (en) |
JP (1) | JP6408551B2 (en) |
KR (1) | KR102128115B1 (en) |
CN (1) | CN105122242A (en) |
CA (1) | CA2908549C (en) |
WO (1) | WO2014159578A1 (en) |
Cited By (11)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN108702572A (en) * | 2016-05-25 | 2018-10-23 | 谷歌有限责任公司 | Control method, system and the medium of audio output |
CN109923539A (en) * | 2016-11-10 | 2019-06-21 | 谷歌有限责任公司 | Identify the audio-visual media item with particular audio content |
CN110178116A (en) * | 2017-01-17 | 2019-08-27 | 谷歌有限责任公司 | Assist screenshotss |
CN110278483A (en) * | 2018-03-13 | 2019-09-24 | 联发科技股份有限公司 | Image processing method and relevant image processing apparatus |
CN110651267A (en) * | 2017-09-13 | 2020-01-03 | 谷歌有限责任公司 | Effectively enhancing images with related content |
CN110678861A (en) * | 2017-12-22 | 2020-01-10 | 谷歌有限责任公司 | Image selection suggestions |
CN110709835A (en) * | 2017-12-12 | 2020-01-17 | 谷歌有限责任公司 | Providing video previews of search results |
CN110830843A (en) * | 2015-06-12 | 2020-02-21 | 尼尔森（美国）有限公司 | Detecting channel changes by automatic content recognition fingerprint matching |
CN110891186A (en) * | 2016-02-29 | 2020-03-17 | 格雷斯诺特公司 | Media presentation device |
CN112565892A (en) * | 2019-09-26 | 2021-03-26 | 聚好看科技股份有限公司 | Method for identifying roles of video programs and related equipment |
CN113841415A (en) * | 2019-06-07 | 2021-12-24 | 六科股份有限公司 | Content modification system with selection features based on technical characteristics |
Families Citing this family (109)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9318108B2 (en) | 2010-01-18 | 2016-04-19 | Apple Inc. | Intelligent automated assistant |
US8977255B2 (en) | 2007-04-03 | 2015-03-10 | Apple Inc. | Method and system for operating a multi-function portable electronic device using voice-activation |
US8676904B2 (en) | 2008-10-02 | 2014-03-18 | Apple Inc. | Electronic devices with voice command and contextual data processing capabilities |
US10706373B2 (en) | 2011-06-03 | 2020-07-07 | Apple Inc. | Performing actions associated with task items that represent tasks to perform |
US10417037B2 (en) | 2012-05-15 | 2019-09-17 | Apple Inc. | Systems and methods for integrating third party services with a digital assistant |
US9948998B1 (en) | 2012-11-01 | 2018-04-17 | Google Llc | Providing content related to a selected channel for presentation to a user via a client device |
CN104969289B (en) | 2013-02-07 | 2021-05-28 | 苹果公司 | Voice trigger of digital assistant |
US10652394B2 (en) | 2013-03-14 | 2020-05-12 | Apple Inc. | System and method for processing voicemail |
US10748529B1 (en) | 2013-03-15 | 2020-08-18 | Apple Inc. | Voice activated device for use with a voice-based digital assistant |
KR20140133351A (en) * | 2013-05-10 | 2014-11-19 | 삼성전자주식회사 | Remote control device, Display apparatus and Method for controlling the remote control device and the display apparatus thereof |
US10191964B2 (en) * | 2013-05-30 | 2019-01-29 | Microsoft Technology Licensing, Llc | Automatic isolation and selection of screenshots from an electronic content repository |
US10176167B2 (en) | 2013-06-09 | 2019-01-08 | Apple Inc. | System and method for inferring user intent from speech inputs |
US9940510B2 (en) * | 2013-09-27 | 2018-04-10 | Hewlett-Packard Development Company, L.P. | Device for identifying digital content |
KR20150072209A (en) * | 2013-12-19 | 2015-06-29 | 한국전자통신연구원 | Method and system for contents based on multi-screen |
US20170134806A1 (en) * | 2014-04-24 | 2017-05-11 | Axwave Inc. | Selecting content based on media detected in environment |
US9583121B2 (en) | 2014-05-16 | 2017-02-28 | Alphonso Inc. | Apparatus and method for determining co-location of services |
US10170123B2 (en) | 2014-05-30 | 2019-01-01 | Apple Inc. | Intelligent assistant for home automation |
US9715875B2 (en) | 2014-05-30 | 2017-07-25 | Apple Inc. | Reducing the need for manual start/end-pointing and trigger phrases |
US9966065B2 (en) | 2014-05-30 | 2018-05-08 | Apple Inc. | Multi-command single utterance input method |
CN104023251B (en) * | 2014-06-13 | 2015-08-19 | 腾讯科技（深圳）有限公司 | Based on interactive approach and the system of video |
US9338493B2 (en) | 2014-06-30 | 2016-05-10 | Apple Inc. | Intelligent automated assistant for TV user interactions |
US9916328B1 (en) | 2014-07-11 | 2018-03-13 | Google Llc | Providing user assistance from interaction understanding |
US9965559B2 (en) | 2014-08-21 | 2018-05-08 | Google Llc | Providing automatic actions for mobile onscreen content |
AU2015308717B2 (en) | 2014-08-28 | 2021-02-18 | Retailmenot, Inc. | Reducing the search space for recognition of objects in an image based on wireless signals |
US9606716B2 (en) | 2014-10-24 | 2017-03-28 | Google Inc. | Drag-and-drop on a mobile device |
US9992307B2 (en) | 2015-02-03 | 2018-06-05 | Google Llc | Interoperability of discovery and connection protocols between client devices and first screen devices |
US9886953B2 (en) | 2015-03-08 | 2018-02-06 | Apple Inc. | Virtual assistant activation |
US10204104B2 (en) * | 2015-04-14 | 2019-02-12 | Google Llc | Methods, systems, and media for processing queries relating to presented media content |
US9703541B2 (en) | 2015-04-28 | 2017-07-11 | Google Inc. | Entity action suggestion on a mobile device |
US10200824B2 (en) | 2015-05-27 | 2019-02-05 | Apple Inc. | Systems and methods for proactively identifying and surfacing relevant content on a touch-sensitive device |
US9704020B2 (en) | 2015-06-16 | 2017-07-11 | Microsoft Technology Licensing, Llc | Automatic recognition of entities in media-captured events |
US10628009B2 (en) | 2015-06-26 | 2020-04-21 | Rovi Guides, Inc. | Systems and methods for automatic formatting of images for media assets based on user profile |
AU2016277553B2 (en) * | 2015-06-26 | 2022-02-17 | Rovi Guides, Inc. | Systems and methods for automatic formatting of images for media assets based on user profile |
US20160378747A1 (en) | 2015-06-29 | 2016-12-29 | Apple Inc. | Virtual assistant for media playback |
US9913056B2 (en) | 2015-08-06 | 2018-03-06 | Dolby Laboratories Licensing Corporation | System and method to enhance speakers connected to devices with microphones |
US10331312B2 (en) | 2015-09-08 | 2019-06-25 | Apple Inc. | Intelligent automated assistant in a media environment |
US10740384B2 (en) | 2015-09-08 | 2020-08-11 | Apple Inc. | Intelligent automated assistant for media search and playback |
US10671428B2 (en) | 2015-09-08 | 2020-06-02 | Apple Inc. | Distributed personal assistant |
US10747498B2 (en) | 2015-09-08 | 2020-08-18 | Apple Inc. | Zero latency digital assistant |
US10970646B2 (en) | 2015-10-01 | 2021-04-06 | Google Llc | Action suggestions for user-selected content |
US10178527B2 (en) | 2015-10-22 | 2019-01-08 | Google Llc | Personalized entity repository |
US10691473B2 (en) | 2015-11-06 | 2020-06-23 | Apple Inc. | Intelligent automated assistant in a messaging environment |
US10956666B2 (en) | 2015-11-09 | 2021-03-23 | Apple Inc. | Unconventional virtual assistant interactions |
US10055390B2 (en) | 2015-11-18 | 2018-08-21 | Google Llc | Simulated hyperlinks on a mobile device based on user intent and a centered selection of text |
CN106973322A (en) | 2015-12-09 | 2017-07-21 | 财团法人工业技术研究院 | Multi-media content cross-screen synchronization device and method, playing device and server |
US10223066B2 (en) | 2015-12-23 | 2019-03-05 | Apple Inc. | Proactive assistance based on dialog communication between devices |
KR102102453B1 (en) * | 2016-01-08 | 2020-04-20 | 주식회사 아이플래테아 | Viewer rating calculation server, viewer rating calculation method, and viewer rating calculation remote device |
US10409970B2 (en) * | 2016-02-22 | 2019-09-10 | Nice Ltd. | System and method for resolving user identification |
US10063918B2 (en) | 2016-02-29 | 2018-08-28 | Gracenote, Inc. | Media channel identification with multi-match detection and disambiguation based on single-match |
US9930406B2 (en) | 2016-02-29 | 2018-03-27 | Gracenote, Inc. | Media channel identification with video multi-match detection and disambiguation based on audio fingerprint |
US10586535B2 (en) | 2016-06-10 | 2020-03-10 | Apple Inc. | Intelligent digital assistant in a multi-tasking environment |
DK179415B1 (en) | 2016-06-11 | 2018-06-14 | Apple Inc | Intelligent device arbitration and control |
DK201670540A1 (en) | 2016-06-11 | 2018-01-08 | Apple Inc | Application integration with a digital assistant |
DK179343B1 (en) * | 2016-06-11 | 2018-05-14 | Apple Inc | Intelligent task discovery |
US10575055B2 (en) * | 2016-07-11 | 2020-02-25 | Sony Corporation | Using automatic content recognition (ACR) to weight search results for audio video display device (AVDD) |
US20180310066A1 (en) * | 2016-08-09 | 2018-10-25 | Paronym Inc. | Moving image reproduction device, moving image reproduction method, moving image distribution system, storage medium with moving image reproduction program stored therein |
JP6232632B1 (en) * | 2016-08-09 | 2017-11-22 | パロニム株式会社 | Video playback program, video playback device, video playback method, video distribution system, and metadata creation method |
CN106254892B (en) * | 2016-08-09 | 2019-04-26 | 北海爱飞数码科技有限公司 | Interactive system based on television set and internet |
US20180101540A1 (en) * | 2016-10-10 | 2018-04-12 | Facebook, Inc. | Diversifying Media Search Results on Online Social Networks |
US10535005B1 (en) | 2016-10-26 | 2020-01-14 | Google Llc | Providing contextual actions for mobile onscreen content |
CN108124167A (en) * | 2016-11-30 | 2018-06-05 | 阿里巴巴集团控股有限公司 | A kind of play handling method, device and equipment |
US10528251B2 (en) | 2016-12-13 | 2020-01-07 | International Business Machines Corporation | Alternate video summarization |
US11237696B2 (en) | 2016-12-19 | 2022-02-01 | Google Llc | Smart assist for repeated actions |
KR20180079762A (en) | 2017-01-02 | 2018-07-11 | 삼성전자주식회사 | Method and device for providing information about a content |
KR20180081390A (en) * | 2017-01-06 | 2018-07-16 | 삼성전자주식회사 | Image display device and operating method for the same |
US10166465B2 (en) | 2017-01-20 | 2019-01-01 | Essential Products, Inc. | Contextual user interface based on video game playback |
US10359993B2 (en) | 2017-01-20 | 2019-07-23 | Essential Products, Inc. | Contextual user interface based on environment |
US20180213290A1 (en) * | 2017-01-20 | 2018-07-26 | Essential Products, Inc. | Contextual user interface based on media playback |
DK180048B1 (en) | 2017-05-11 | 2020-02-04 | Apple Inc. | MAINTAINING THE DATA PROTECTION OF PERSONAL INFORMATION |
US10726832B2 (en) | 2017-05-11 | 2020-07-28 | Apple Inc. | Maintaining privacy of personal information |
DK179745B1 (en) | 2017-05-12 | 2019-05-01 | Apple Inc. | SYNCHRONIZATION AND TASK DELEGATION OF A DIGITAL ASSISTANT |
DK201770427A1 (en) | 2017-05-12 | 2018-12-20 | Apple Inc. | Low-latency intelligent automated assistant |
DK179496B1 (en) | 2017-05-12 | 2019-01-15 | Apple Inc. | USER-SPECIFIC Acoustic Models |
US10303715B2 (en) | 2017-05-16 | 2019-05-28 | Apple Inc. | Intelligent automated assistant for media exploration |
US20180336892A1 (en) | 2017-05-16 | 2018-11-22 | Apple Inc. | Detecting a trigger of a digital assistant |
CN107396176A (en) * | 2017-07-18 | 2017-11-24 | 青岛海信电器股份有限公司 | The player method and device of audio-video document |
US11144584B2 (en) * | 2017-10-03 | 2021-10-12 | Google Llc | Coordination of parallel processing of audio queries across multiple devices |
JP6463826B1 (en) * | 2017-11-27 | 2019-02-06 | 株式会社ドワンゴ | Video distribution server, video distribution method, and video distribution program |
US20190253751A1 (en) * | 2018-02-13 | 2019-08-15 | Perfect Corp. | Systems and Methods for Providing Product Information During a Live Broadcast |
US10818288B2 (en) | 2018-03-26 | 2020-10-27 | Apple Inc. | Natural assistant interaction |
US10928918B2 (en) | 2018-05-07 | 2021-02-23 | Apple Inc. | Raise to speak |
US11145294B2 (en) | 2018-05-07 | 2021-10-12 | Apple Inc. | Intelligent automated assistant for delivering content from user experiences |
DK179822B1 (en) | 2018-06-01 | 2019-07-12 | Apple Inc. | Voice interaction at a primary device to access call functionality of a companion device |
US10892996B2 (en) | 2018-06-01 | 2021-01-12 | Apple Inc. | Variable latency device coordination |
DK180639B1 (en) | 2018-06-01 | 2021-11-04 | Apple Inc | DISABILITY OF ATTENTION-ATTENTIVE VIRTUAL ASSISTANT |
US11055346B2 (en) * | 2018-08-03 | 2021-07-06 | Gracenote, Inc. | Tagging an image with audio-related metadata |
US11462215B2 (en) | 2018-09-28 | 2022-10-04 | Apple Inc. | Multi-modal inputs for voice commands |
CN109525877B (en) * | 2018-10-18 | 2021-04-20 | 百度在线网络技术（北京）有限公司 | Video-based information acquisition method and device |
US11348573B2 (en) | 2019-03-18 | 2022-05-31 | Apple Inc. | Multimodality in digital assistant systems |
US11307752B2 (en) | 2019-05-06 | 2022-04-19 | Apple Inc. | User configurable task triggers |
DK201970509A1 (en) | 2019-05-06 | 2021-01-15 | Apple Inc | Spoken notifications |
US11140099B2 (en) | 2019-05-21 | 2021-10-05 | Apple Inc. | Providing message response suggestions |
DK180129B1 (en) | 2019-05-31 | 2020-06-02 | Apple Inc. | User activity shortcut suggestions |
DK201970510A1 (en) | 2019-05-31 | 2021-02-11 | Apple Inc | Voice identification in digital assistant systems |
US11227599B2 (en) | 2019-06-01 | 2022-01-18 | Apple Inc. | Methods and user interfaces for voice-based control of electronic devices |
US10477287B1 (en) | 2019-06-18 | 2019-11-12 | Neal C. Fairbanks | Method for providing additional information associated with an object visually present in media content |
US11202109B2 (en) | 2019-07-19 | 2021-12-14 | Roku, Inc. | Method and system for use of network affiliation as basis to determine channel rendered by content presentation device |
US11722729B2 (en) * | 2019-07-19 | 2023-08-08 | Roku, Inc. | Method and system for use of earlier and/or later single-match as basis to disambiguate channel multi-match with non-matching programs |
US11556596B2 (en) | 2019-12-31 | 2023-01-17 | Spotify Ab | Systems and methods for determining descriptors for media content items |
US11281710B2 (en) * | 2020-03-20 | 2022-03-22 | Spotify Ab | Systems and methods for selecting images for a media item |
US11043220B1 (en) | 2020-05-11 | 2021-06-22 | Apple Inc. | Digital assistant hardware abstraction |
US11061543B1 (en) | 2020-05-11 | 2021-07-13 | Apple Inc. | Providing relevant data items based on context |
US11755276B2 (en) | 2020-05-12 | 2023-09-12 | Apple Inc. | Reducing description length based on confidence |
US11490204B2 (en) | 2020-07-20 | 2022-11-01 | Apple Inc. | Multi-device audio adjustment coordination |
US11438683B2 (en) | 2020-07-21 | 2022-09-06 | Apple Inc. | User identification using headphones |
US11882334B2 (en) * | 2020-07-24 | 2024-01-23 | Dish Network Technologies India Private Limited | Automated user-responsive video content |
US11956518B2 (en) | 2020-11-23 | 2024-04-09 | Clicktivated Video, Inc. | System and method for creating interactive elements for objects contemporaneously displayed in live video |
CN113343005A (en) * | 2021-05-17 | 2021-09-03 | 北京百度网讯科技有限公司 | Searching method, searching device, electronic equipment and readable storage medium |
TR2021016527A2 (en) * | 2021-10-22 | 2021-11-22 | Siskon Enduestriyel Otomasyon Sistemleri Sanayi Ve Ticaret Anonim Sirketi | A FACE RECOGNITION SYSTEM TO IDENTIFY PEOPLE ON THE SCREEN |
Citations (8)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN1735162A (en) * | 2004-08-12 | 2006-02-15 | 上海乐金广电电子有限公司 | OSD maker of television programme guide information and its forming method |
CN101883230A (en) * | 2010-05-31 | 2010-11-10 | 中山大学 | Digital television actor retrieval method and system |
CN101981574A (en) * | 2008-03-31 | 2011-02-23 | 杜比实验室特许公司 | Distributed media fingerprint repositories |
US20110282906A1 (en) * | 2010-05-14 | 2011-11-17 | Rovi Technologies Corporation | Systems and methods for performing a search based on a media content snapshot image |
EP2388721A1 (en) * | 2010-05-19 | 2011-11-23 | Google Inc. | Presenting mobile content based on programming context |
CN102833617A (en) * | 2012-09-20 | 2012-12-19 | 北京十分科技有限公司 | Method for synchronously displaying affiliated information of multimedia program, system and terminal |
CN102868934A (en) * | 2012-08-01 | 2013-01-09 | 青岛海信传媒网络技术有限公司 | Method and device for retrieving video object information based on smart television |
US20130047178A1 (en) * | 2011-08-21 | 2013-02-21 | Kyoungsoo Moon | Video display device, terminal device, and method thereof |
Family Cites Families (60)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2001216309A (en) * | 2000-01-31 | 2001-08-10 | Keio Gijuku | Object specifying device and camera |
US8205223B2 (en) * | 2000-04-12 | 2012-06-19 | Lg Electronics Inc. | Method and video device for accessing information |
US6636237B1 (en) | 2000-07-31 | 2003-10-21 | James H. Murray | Method for creating and synchronizing links to objects in a video |
US20020147984A1 (en) | 2000-11-07 | 2002-10-10 | Tomsen Mai-Lan | System and method for pre-caching supplemental content related to a television broadcast using unprompted, context-sensitive querying |
US20060129908A1 (en) | 2003-01-28 | 2006-06-15 | Markel Steven O | On-content streaming media enhancement |
EP1810505B1 (en) * | 2004-11-04 | 2014-03-12 | Koninklijke Philips N.V. | Incorporation of lead actor information for tv recommenders |
US8185543B1 (en) * | 2004-11-10 | 2012-05-22 | Google Inc. | Video image-based querying for video content |
KR20060077988A (en) * | 2004-12-30 | 2006-07-05 | 삼성전자주식회사 | System and method for information providing service through retrieving of context in multimedia communication system |
KR20070100975A (en) | 2005-01-14 | 2007-10-15 | 코닌클리케 필립스 일렉트로닉스 엔.브이. | A method and a system for constructing virtual video channel |
JP2006270869A (en) * | 2005-03-25 | 2006-10-05 | Dainippon Printing Co Ltd | Associated information acquisition system and method, management apparatus, and associated information transmission program |
US8064516B2 (en) | 2005-06-02 | 2011-11-22 | Broadcom Corporation | Text recognition during video compression |
KR100686827B1 (en) * | 2005-07-11 | 2007-02-26 | 삼성에스디아이 주식회사 | Lithium Secondary Battery |
JP2007058532A (en) * | 2005-08-24 | 2007-03-08 | Sony Corp | Information processing system, information processor and method, program, and recording medium |
JP2009524273A (en) * | 2005-11-29 | 2009-06-25 | グーグル・インコーポレーテッド | Repetitive content detection in broadcast media |
US20070136773A1 (en) | 2005-12-14 | 2007-06-14 | O'neil Douglas | Systems and methods for providing television services using implicit content to indicate the availability of additional content |
US8296808B2 (en) * | 2006-10-23 | 2012-10-23 | Sony Corporation | Metadata from image recognition |
US8861898B2 (en) * | 2007-03-16 | 2014-10-14 | Sony Corporation | Content image search |
CN104866553A (en) | 2007-12-31 | 2015-08-26 | 应用识别公司 | Method, system, and computer program for identification and sharing of digital images with face signatures |
US8301618B2 (en) * | 2008-02-26 | 2012-10-30 | Microsoft Corporation | Techniques to consume content and metadata |
WO2009137368A2 (en) | 2008-05-03 | 2009-11-12 | Mobile Media Now, Inc. | Method and system for generation and playback of supplemented videos |
KR101380777B1 (en) | 2008-08-22 | 2014-04-02 | 정태우 | Method for indexing object in video |
US8239359B2 (en) | 2008-09-23 | 2012-08-07 | Disney Enterprises, Inc. | System and method for visual search in a video media player |
US20100121973A1 (en) | 2008-11-12 | 2010-05-13 | Yuliya Lobacheva | Augmentation of streaming media |
US20120311623A1 (en) * | 2008-11-14 | 2012-12-06 | Digimarc Corp. | Methods and systems for obtaining still images corresponding to video |
JP5386161B2 (en) * | 2008-12-05 | 2014-01-15 | ソフトバンクモバイル株式会社 | Information provision system |
JP5189481B2 (en) * | 2008-12-26 | 2013-04-24 | Ｋｄｄｉ株式会社 | Video-related information presentation device, video-related information presentation system, and control program for video-related information presentation device |
JP2010200170A (en) * | 2009-02-26 | 2010-09-09 | Nec Corp | Image information providing system, image information providing method, and image information providing program |
US9135277B2 (en) * | 2009-08-07 | 2015-09-15 | Google Inc. | Architecture for responding to a visual query |
US9191726B2 (en) | 2009-09-30 | 2015-11-17 | Disney Enterprises, Inc. | System and method for providing media content enhancement |
US8463100B2 (en) | 2009-11-05 | 2013-06-11 | Cosmo Research Company Limited | System and method for identifying, providing, and presenting content on a mobile device |
US8301596B2 (en) | 2010-01-15 | 2012-10-30 | Hulu Llc | Method and apparatus for providing supplemental video content for third party websites |
KR101562588B1 (en) * | 2010-01-26 | 2015-10-23 | 엘지전자 주식회사 | Information providing apparatus and method thereof |
US20110243449A1 (en) | 2010-03-31 | 2011-10-06 | Nokia Corporation | Method and apparatus for object identification within a media file using device identification |
US9264785B2 (en) | 2010-04-01 | 2016-02-16 | Sony Computer Entertainment Inc. | Media fingerprinting for content determination and retrieval |
US8560583B2 (en) | 2010-04-01 | 2013-10-15 | Sony Computer Entertainment Inc. | Media fingerprinting for social networking |
KR101123370B1 (en) * | 2010-05-14 | 2012-03-23 | 주식회사 코리아퍼스텍 | service method and apparatus for object-based contents for portable device |
CN103004228A (en) | 2010-07-26 | 2013-03-27 | 皇家飞利浦电子股份有限公司 | Obtaining keywords for searching |
CN103229120A (en) | 2010-09-28 | 2013-07-31 | 国际商业机器公司 | Providing answers to questions using hypothesis pruning |
US20120096499A1 (en) * | 2010-10-19 | 2012-04-19 | Charles Dasher | Apparatus and method for facilitating video-on-demand catalog search and content distribution |
US9241195B2 (en) * | 2010-11-05 | 2016-01-19 | Verizon Patent And Licensing Inc. | Searching recorded or viewed content |
US10070201B2 (en) | 2010-12-23 | 2018-09-04 | DISH Technologies L.L.C. | Recognition of images within a video based on a stored representation |
US9424471B2 (en) * | 2011-03-01 | 2016-08-23 | Sony Corporation | Enhanced information for viewer-selected video object |
US20120240144A1 (en) | 2011-03-17 | 2012-09-20 | Anthony Rose | Content provision |
WO2012139240A1 (en) * | 2011-04-11 | 2012-10-18 | Intel Corporation | Next generation television with content shifting and interactive selectability |
US9075875B1 (en) | 2011-05-13 | 2015-07-07 | Google Inc. | System and method for recommending television programs based on user search queries |
JP2013016030A (en) * | 2011-07-04 | 2013-01-24 | Mitsubishi Electric Corp | Program reproduction apparatus and program reproduction method |
JP6029264B2 (en) * | 2011-07-07 | 2016-11-24 | 富士ゼロックス株式会社 | Transfer device and image forming apparatus |
US20130036442A1 (en) * | 2011-08-05 | 2013-02-07 | Qualcomm Incorporated | System and method for visual selection of elements in video content |
US20110289532A1 (en) * | 2011-08-08 | 2011-11-24 | Lei Yu | System and method for interactive second screen |
US9317571B2 (en) | 2011-08-26 | 2016-04-19 | Google Inc. | Third party content provider integrations |
US9049496B2 (en) | 2011-09-01 | 2015-06-02 | Gracenote, Inc. | Media source identification |
WO2013040533A1 (en) | 2011-09-16 | 2013-03-21 | Umami Co. | Second screen interactive platform |
US9098533B2 (en) | 2011-10-03 | 2015-08-04 | Microsoft Technology Licensing, Llc | Voice directed context sensitive visual search |
KR101952170B1 (en) * | 2011-10-24 | 2019-02-26 | 엘지전자 주식회사 | Mobile device using the searching method |
US9866915B2 (en) | 2011-11-28 | 2018-01-09 | Excalibur Ip, Llc | Context relevant interactive television |
US9596515B2 (en) | 2012-01-04 | 2017-03-14 | Google Inc. | Systems and methods of image searching |
KR20130081595A (en) * | 2012-01-09 | 2013-07-17 | 삼성전자주식회사 | Display apparatus, remote control apparatus and searching method therof |
US8484017B1 (en) | 2012-09-10 | 2013-07-09 | Google Inc. | Identifying media content |
US20140255003A1 (en) | 2013-03-05 | 2014-09-11 | Google Inc. | Surfacing information about items mentioned or presented in a film in association with viewing the film |
US9384217B2 (en) | 2013-03-11 | 2016-07-05 | Arris Enterprises, Inc. | Telestration system for command processing |
-
2013
- 2013-03-14 US US13/827,413 patent/US9247309B2/en active Active
-
2014
- 2014-03-12 JP JP2016501451A patent/JP6408551B2/en active Active
- 2014-03-12 KR KR1020157028591A patent/KR102128115B1/en active IP Right Grant
- 2014-03-12 CA CA2908549A patent/CA2908549C/en active Active
- 2014-03-12 WO PCT/US2014/024255 patent/WO2014159578A1/en active Application Filing
- 2014-03-12 CN CN201480021167.4A patent/CN105122242A/en active Pending
- 2014-03-12 EP EP14725797.6A patent/EP2973037A1/en not_active Ceased
-
2016
- 2016-01-25 US US15/005,470 patent/US9609391B2/en active Active
-
2017
- 2017-02-13 US US15/431,431 patent/US20170155964A1/en not_active Abandoned
Patent Citations (8)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN1735162A (en) * | 2004-08-12 | 2006-02-15 | 上海乐金广电电子有限公司 | OSD maker of television programme guide information and its forming method |
CN101981574A (en) * | 2008-03-31 | 2011-02-23 | 杜比实验室特许公司 | Distributed media fingerprint repositories |
US20110282906A1 (en) * | 2010-05-14 | 2011-11-17 | Rovi Technologies Corporation | Systems and methods for performing a search based on a media content snapshot image |
EP2388721A1 (en) * | 2010-05-19 | 2011-11-23 | Google Inc. | Presenting mobile content based on programming context |
CN101883230A (en) * | 2010-05-31 | 2010-11-10 | 中山大学 | Digital television actor retrieval method and system |
US20130047178A1 (en) * | 2011-08-21 | 2013-02-21 | Kyoungsoo Moon | Video display device, terminal device, and method thereof |
CN102868934A (en) * | 2012-08-01 | 2013-01-09 | 青岛海信传媒网络技术有限公司 | Method and device for retrieving video object information based on smart television |
CN102833617A (en) * | 2012-09-20 | 2012-12-19 | 北京十分科技有限公司 | Method for synchronously displaying affiliated information of multimedia program, system and terminal |
Cited By (28)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN110830843A (en) * | 2015-06-12 | 2020-02-21 | 尼尔森（美国）有限公司 | Detecting channel changes by automatic content recognition fingerprint matching |
CN110830843B (en) * | 2015-06-12 | 2022-01-04 | 六科股份有限公司 | System and method for identifying media |
CN112702648A (en) * | 2016-02-29 | 2021-04-23 | 格雷斯诺特公司 | Method and system for detecting and responding to media channel changes |
US11617009B2 (en) | 2016-02-29 | 2023-03-28 | Roku, Inc. | Media channel identification and action with multi-match detection and disambiguation based on matching with differential reference-fingerprint feature |
CN111954026A (en) * | 2016-02-29 | 2020-11-17 | 格雷斯诺特公司 | Media channel identification and action with multiple match detection based on reference stream comparison |
CN111954026B (en) * | 2016-02-29 | 2024-03-01 | 六科股份有限公司 | Media channel identification and action with multiple match detection based on reference stream comparison |
CN110891186A (en) * | 2016-02-29 | 2020-03-17 | 格雷斯诺特公司 | Media presentation device |
CN108702572B (en) * | 2016-05-25 | 2021-04-06 | 谷歌有限责任公司 | Method, system, and medium for controlling audio output |
US10776074B2 (en) | 2016-05-25 | 2020-09-15 | Google Llc | Methods, systems, and media for controlling audio output |
CN108702572A (en) * | 2016-05-25 | 2018-10-23 | 谷歌有限责任公司 | Control method, system and the medium of audio output |
US11294620B2 (en) | 2016-05-25 | 2022-04-05 | Google Llc | Methods, systems, and media for controlling audio output |
CN109923539B (en) * | 2016-11-10 | 2024-03-08 | 谷歌有限责任公司 | Identifying audiovisual media items having particular audio content |
CN109923539A (en) * | 2016-11-10 | 2019-06-21 | 谷歌有限责任公司 | Identify the audio-visual media item with particular audio content |
CN110178116A (en) * | 2017-01-17 | 2019-08-27 | 谷歌有限责任公司 | Assist screenshotss |
CN110178116B (en) * | 2017-01-17 | 2022-08-16 | 谷歌有限责任公司 | Auxiliary screen shot |
CN110651267B (en) * | 2017-09-13 | 2023-09-19 | 谷歌有限责任公司 | Effectively enhancing images with related content |
CN110651267A (en) * | 2017-09-13 | 2020-01-03 | 谷歌有限责任公司 | Effectively enhancing images with related content |
US11747960B2 (en) | 2017-09-13 | 2023-09-05 | Google Llc | Efficiently augmenting images with related content |
US11762902B2 (en) | 2017-12-12 | 2023-09-19 | Google Llc | Providing a video preview of search results |
CN110709835A (en) * | 2017-12-12 | 2020-01-17 | 谷歌有限责任公司 | Providing video previews of search results |
CN110709835B (en) * | 2017-12-12 | 2023-10-10 | 谷歌有限责任公司 | Video preview providing search results |
US11775139B2 (en) | 2017-12-22 | 2023-10-03 | Google Llc | Image selection suggestions |
CN110678861B (en) * | 2017-12-22 | 2023-12-08 | 谷歌有限责任公司 | Image selection suggestion |
CN110678861A (en) * | 2017-12-22 | 2020-01-10 | 谷歌有限责任公司 | Image selection suggestions |
CN110278483A (en) * | 2018-03-13 | 2019-09-24 | 联发科技股份有限公司 | Image processing method and relevant image processing apparatus |
CN113841415A (en) * | 2019-06-07 | 2021-12-24 | 六科股份有限公司 | Content modification system with selection features based on technical characteristics |
CN112565892B (en) * | 2019-09-26 | 2022-12-27 | 聚好看科技股份有限公司 | Method for identifying roles of video programs and related equipment |
CN112565892A (en) * | 2019-09-26 | 2021-03-26 | 聚好看科技股份有限公司 | Method for identifying roles of video programs and related equipment |
Also Published As
Publication number | Publication date |
---|---|
CA2908549C (en) | 2021-05-25 |
US20140282660A1 (en) | 2014-09-18 |
WO2014159578A1 (en) | 2014-10-02 |
US20160156986A1 (en) | 2016-06-02 |
KR20150127238A (en) | 2015-11-16 |
US9247309B2 (en) | 2016-01-26 |
JP2016521390A (en) | 2016-07-21 |
US20170155964A1 (en) | 2017-06-01 |
CA2908549A1 (en) | 2014-10-02 |
KR102128115B1 (en) | 2020-06-29 |
JP6408551B2 (en) | 2018-10-17 |
EP2973037A1 (en) | 2016-01-20 |
US9609391B2 (en) | 2017-03-28 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN105122242A (en) | Methods, systems, and media for presenting mobile content corresponding to media content | |
US11743557B2 (en) | Methods, systems, and media for presenting supplemental content relating to media content based on state information that indicates a subsequent visit to the content interface | |
US20210250652A1 (en) | Methods, systems, and media for presenting supplemental information corresponding to on-demand media content | |
US10333767B2 (en) | Methods, systems, and media for media transmission and management | |
US11941041B2 (en) | Methods, systems, and media for presenting news items corresponding to media content | |
KR102212355B1 (en) | Identification and presentation of internet-accessible content associated with currently playing television programs | |
CN111274449A (en) | Video playing method and device, electronic equipment and storage medium | |
KR20200023094A (en) | Method of simple image searching and service device thereof |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
C06 | Publication | ||
PB01 | Publication | ||
C10 | Entry into substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
CB02 | Change of applicant information |
Address after: California, USAApplicant after: Google Inc.Address before: California, USAApplicant before: Google Inc. |
|
CB02 | Change of applicant information | ||
RJ01 | Rejection of invention patent application after publication |
Application publication date: 20151202 |
|
RJ01 | Rejection of invention patent application after publication |