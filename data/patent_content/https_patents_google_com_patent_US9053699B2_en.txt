US9053699B2 - Apparatus and method for audio frame loss recovery - Google Patents
Apparatus and method for audio frame loss recovery Download PDFInfo
- Publication number
- US9053699B2 US9053699B2 US13/545,277 US201213545277A US9053699B2 US 9053699 B2 US9053699 B2 US 9053699B2 US 201213545277 A US201213545277 A US 201213545277A US 9053699 B2 US9053699 B2 US 9053699B2
- Authority
- US
- United States
- Prior art keywords
- frame
- audio
- sequence
- coded
- frames
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Expired - Fee Related, expires
Links
Images
Classifications
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L19/00—Speech or audio signals analysis-synthesis techniques for redundancy reduction, e.g. in vocoders; Coding or decoding of speech or audio signals, using source filter models or psychoacoustic analysis
- G10L19/005—Correction of errors induced by the transmission channel, if related to the coding algorithm
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L19/00—Speech or audio signals analysis-synthesis techniques for redundancy reduction, e.g. in vocoders; Coding or decoding of speech or audio signals, using source filter models or psychoacoustic analysis
- G10L19/04—Speech or audio signals analysis-synthesis techniques for redundancy reduction, e.g. in vocoders; Coding or decoding of speech or audio signals, using source filter models or psychoacoustic analysis using predictive techniques
- G10L19/16—Vocoder architecture
- G10L19/18—Vocoders using multiple modes
- G10L19/20—Vocoders using multiple modes using sound class specific coding, hybrid encoders or object based coding
Definitions
- the present invention relates generally to audio encoding/decoding and more specifically to audio frame loss recovery.
- Digital Signal Processors In the last twenty years microprocessor speed has increased by several orders of magnitude and Digital Signal Processors (DSPs) have become ubiquitous. As a result, it has become feasible and attractive to transition from analog communication to digital communication. Digital communication offers the advantage of being able to utilize bandwidth more efficiently and allows for error correcting techniques to be used. Thus, by using digital communication, one can send more information through an allocated spectrum space and send the information more reliably. Digital communication can use wireless links (e.g., radio frequency) or physical network media (e.g., fiber optics, copper networks).
- wireless links e.g., radio frequency
- physical network media e.g., fiber optics, copper networks.
- Digital communication can be used for transmitting and receiving different types of data, such as audio data (e.g., speech), video data (e.g., still images or moving images) or telemetry.
- audio data e.g., speech
- video data e.g., still images or moving images
- telemetry e.g., telemetry
- audio communications various standards have been developed, and many of those standards rely upon frame based coding in which, for example, high quality audio is encoded and decoded using frames (e.g., 20 millisecond frames).
- audio coding standards have evolved that use sequentially mixed time domain coding and frequency domain coding. Time domain coding is typically used when the source audio is voice and typically involves the use of CELP (code excited linear prediction) based analysis-by-synthesis coding.
- CELP code excited linear prediction
- Frequency domain coding is typically used for such non-voice sources such as music and is typically based on quantization of MDCT (modified discrete cosine transform) coefficients. Frequency domain coding is also referred to “transform domain coding.”
- a mixed time domain and transform domain signal may experience a frame loss.
- the device When a device receiving the signal decodes the signal, the device will encounter the portion of the signal having the frame loss, and may request that the transmitter resend the signal. Alternatively, the receiving device may attempt to recover the lost frame.
- Frame loss recovery techniques typically use information from frames in the signal that occur before and after the lost frame to construct a replacement frame.
- FIG. 1 is a block diagram 100 of a communication system, in accordance with certain embodiments.
- FIG. 2 is a timing diagram 200 of a frame coded audio signal used in the communication system, in accordance with certain embodiments.
- FIGS. 3 and 4 show a flow chart 300 of some steps of a method for audio frame loss recover used by a device operating in the communication system of FIG. 1 , in accordance with certain embodiments.
- FIG. 5 shows a timing diagram 500 of a decoded frame coded audio signal being processed by a device in the communication system of FIG. 1 , in accordance with certain embodiments.
- FIGS. 6-8 are flow charts 605 , 705 , 805 , each showing a step of the method 300 described with reference to FIGS. 3 and 4 , in accordance with certain embodiments.
- FIG. 9 is a block diagram 900 of a device used in the communication system 100 described with reference to FIG. 1 , in accordance with certain embodiments.
- Embodiments described herein relate to decoding coded audio signals, which results in a digitized (sampled) version of the source analog audio signal.
- the signals can be speech or other audio such as music that are converted to digital information and communicated by wire or wirelessly.
- the portion of the communication system 100 includes an audio source 105 , a network 110 , and a user device (also referred to as user equipment, or UE) 120 .
- the audio source 105 may be one of many types of audio sources, such as another UE, or a music server, or a media player, or a personal recorder, or a wired telephone.
- the network 110 may be a point to point network or a broadcast network, or a plurality of such networks coupled together. There may be a plurality of audio sources and UE's in the communication system 100 .
- the UE 120 may be a wired or wireless device.
- the UE 120 is a wireless communication device (e.g., a cell phone) and the network 110 includes a radio network station to communicate to the UE 120 .
- the network 110 includes an IP network that is coupled to the UE 120 , and the UE 120 comprises a gateway coupled to a wired telephone.
- the communication system 100 is capable of communicating audio signals between the audio source 105 and the UE 120 . While embodiments of the UE 120 described herein are described as being wireless devices, they may alternatively be wired devices using the types of coding protocols described herein. Audio from the audio source 105 is communicated to the UE 120 using an audio signal that may have different forms during its conveyance from the audio source 120 to the UE 120 .
- the audio signal may be an analog signal at the audio source that is converted to a digitally sampled audio signal by the network 110 .
- the audio signal is received in a form that uses audio compression encoding techniques that are optimized for conveying a sequential mixture of voice and non voice audio in a channel or link that may induce errors.
- the voice audio can be effectively compressed by using certain time domain coding techniques, while music and other non-voice audio can be effectively compressed by certain transform domain encoding (frequency encoding) techniques.
- CELP code excited linear prediction
- analysis-by-synthesis coding is the time domain coding technique that is used.
- the transform domain coding is typically based on quantization of MDCT (modified discrete cosine transform) coefficients.
- the audio signal received at the UE 120 is a mixed audio signal that uses time domain coding and transform domain coding in a sequential manner.
- the UE 120 is described as a user device for the embodiments described herein, in other embodiments it may be a device not commonly thought of as a user device. For example, it may be an audio device used for presenting audio for a movie in a cinema.
- the network 110 and UE 120 may communicate in both directions using a frame based communication protocol, wherein a sequence of frames is used, each frame having a duration and being encoded with compression encoding that is appropriate for the desired audio bandwidth.
- analog source audio may be digitally sampled 16000 times per second and sequences of the digital samples may be used to generate compression coded frames every 20 milliseconds.
- the compression encoding e.g., CELP and/or MDCT
- the frames may include other information such as error mitigation information, a sequence number and other metadata, and the frames may be included within groupings of frames that may include error mitigation, sequence number, and metadata for more than one frame.
- Such frame groups may be, for example, packets or audio messages. It will be appreciated that in some embodiments, most particularly those systems that include packet transmission techniques, frames may not be received sequentially in the order in which they are transmitted, and in some instances a frame or frames may be lost.
- Some embodiments are designed to handle a mixed audio signal that changes between voice and non-voice by providing for changing from time domain coding to transform domain coding and also from transform domain coding to time domain coding.
- the first frame that is transform coded is called the transition frame.
- decoding means generating, from the compressed audio encoded within each frame, a set of audio sample values that may be used as an input to a digital to analog converter.
- a gap (the transition gap) would occur between the last audio sample value generated by the time domain decoding technique and the first audio sample generated by the transform decoding technique.
- There is an initialization delay in the decoding of a transition frame which is present because the synthesis memory for the transform domain frame from the previous time domain frame is not available in the current transform domain frame. This results in cessation of output at the start of the transition frame which results in a gap.
- the gap may be filled by generating what may be termed transition gap filler estimated audio samples and inserting them into the gap of a coded transition frame.
- One way to generate the transition gap fillers is a forward/backward search method that uses a search process to find two sequential sets (vectors) of audio sample values of equal length; one vector that precedes the transition gap and one vector that succeeds the transition gap; such that when they are combined using a unique gain value for each vector, minimize a distortion value of the combined vector.
- a length of the two vectors is chosen. It may be equal to or greater than the transition gap. (a value greater than the transition gap provides for overlap smoothing of samples values that are in an overlap region resulting from length of the resulting vector being longer than the transition gap).
- the values that are varied during the search are the positions of the vectors that are combined (one within the time domain frame preceding the transition frame and one from the transition frame), and the gain used for each vector.
- This technique results in a coded transition frame that allows a decoder to produce quality audio at the transition frame using a normal transition decoding technique when the transition frame is correctly received.
- the normal transition decoding technique obtains information from received meta data associated with the transition frame that allows the gains and positions of the vectors used to generate the transition vector to be identified, from which the transition vector can be generated, thereby providing estimated audio sample values for the transition gap.
- a timing diagram 200 shows a portion of a coded audio signal 200 comprising a sequence of audio frames that is being received by a device such as UE 120 .
- Five of the frames in the sequence are identified in the timing diagram 200 .
- Two frames of time domain coded audio, frames 205 , 210 are followed by three frames of transform domain coded audio, frames 215 , 220 , 225 .
- the transition frame is frame 215 .
- the type of encoding used for each frame may be identified to the receiving device by metadata that is sent within or outside of the frame structure of the received frames, but in the examples described herein, the identification is within each of the received frames.
- a lost frame When operating in an environment in which individual frames are occasionally not recoverable by the receiving device (which can occur in both wired and wireless systems due to a variety of channel disturbances), it is desirable to be able to construct an approximation of a lost frame (alternatively described as performing a lost frame recovery) that provides acceptable audio performance rather than request retransmission, because of the typically long time delay needed to request and receive a retransmission of the lost frame.
- a sequence of two or more frames may be lost.
- the term “sequence” as used to describe lost frames includes the case of only one lost frame.
- Embodiments described herein below provide for audio recovery in the case when the transition frame is lost or unusable due to corruption (uncorrectable errors).
- the term “lost frame” will be used for both the case when a frame is either not received or incorrectly received.
- FIG. 5 shows a timing diagram of the decoded audio frames that result from the method.
- Decoded audio frames 505 , 510 ( FIG. 5 ) are generated using the time domain decoding method used for the time domain coded portion of the mixed audio signal preceding the transition frame 215 of FIG. 2 , with coded frames 205 and 210 ( FIG. 2 ) used as inputs, respectively, to generate decoded frames 505 , 510 .
- a sequence of one or more lost frames of coded audio (e.g., frame 505 in FIG. 5 or e.g., frames 505 and 510 in FIG. 5 ) is identified as being lost or corrupted. This may be accomplished by determined that the sequence numbers in received frames do not include the sequence numbers of the lost frames.
- the frame of coded audio 210 ( FIG. 2 ) that immediately precedes the sequence of lost frames (in an example of one lost frame, frame 215 in FIG. 2 ) is identified as having been encoded using a time domain coding method.
- the lost frames in the sequence are replaced using known techniques for replacing audio samples of lost time domain coded frames.
- the lost frames are frames 210 , 215 ( FIG. 2 ), and the audio samples for the lost frames are replaced by using known techniques for replacing lost time domain frames, resulting in frames 510 , 515 ( FIG. 5 ).
- the frame of coded audio 220 ( FIG. 2 ) that immediately follows the sequence of lost frames is identified as having been encoded using a transform domain coding method (i.e., not using time domain nor transition frame encoding).
- the last frame 220 ( FIG. 2 ) in the sequence of lost frames may be any one of the last time domain frame preceding a transition frame or the transition frame or a transform domain coded frame.
- a determination may be made at step 316 ( FIG.
- step 317 FIG. 3
- step 345 FIG. 4
- a pitch delay is obtained from a selected frame or frames that precede or follow the sequence of replacement frames.
- the pitch delay is the period expressed as a quantity of audio samples that represents the fundamental frequency of voice audio within a frame or frames.
- typical pitch delays are in the range of 16-160 samples.
- the name pitch delay arises from a mathematical model of voice that includes a filter having delay characteristics determined by the pitch delay.
- a frame is selected that immediately precedes or immediately follows the sequence of lost frames (in the example of one lost frame, these are, respectively, coded frames 210 , 220 of FIG. 2 .
- the pitch delay is typically received as a parameter with each of the time domain frames, and in some embodiments, with certain of the transform domain frames.
- the time domain frame immediately preceding the sequence of lost frames is selected from which to obtain the pitch delay.
- this is encoded frame 210 ( FIG. 2 ), which becomes decoded frame 510 ( FIG. 5 ).
- a second decoded audio portion 525 ( FIG. 5 ) of the decoded audio output frame 530 ( FIG. 5 ) is generated as a set of sample values based on the frame 220 ( FIG. 2 ), using normal transform domain decoding techniques for decoding the frame 220 ( FIG. 2 ).
- using the normal transform domain decoding techniques for decoding a first transform frame in a sequence of time domain coded frames following by transform domain coded frames results in audio sample values only for a portion of the first transform domain decoded frame, which is this case is the second portion of decoded audio output frame 530 ( FIG. 5 ), leaving a transition audio gap at the beginning of the decoded frame.
- step 335 FIG.
- a first decoded audio portion 520 ( FIG. 5 ) of an output audio frame 530 ( FIG. 5 ) is generated based on the pitch delay.
- the first decoded audio portion 520 ( FIG. 5 ) comprises a set of estimated audio samples, ⁇ g , and may also be described as a transition gap filler 520 ( FIG. 5 ).
- the pitch delay may be used to select from where audio sample values are obtained within certain decoded audio frames to form the first decoded audio portion 520 ( FIG. 5 ) of decoded audio output frame 530 ( FIG. 5 ).
- the decoded audio output frame 530 FIG.
- step 5 (also referred herein to as a new transition frame) is generated by combining the first audio portion 520 ( FIG. 5 ) sequentially with the second decoded audio portion 525 ( FIG. 5 ).
- the sequential combination of the first audio portion 520 ( FIG. 5 ) and the second audio portion 525 ( FIG. 5 ) is performed by inserting the first audio portion 520 ( FIG. 5 ) at the beginning of the decoded output audio frame 530 ( FIG. 5 ), followed by the second audio portion 525 ( FIG. 5 ).
- the method ends at step 345 ( FIG. 4 ) by continuing the decoding of transform domain frames using the normal transform domain decoding technique
- the first and second portions 520 , 525 ( FIG. 5 ) of the decoded output audio frame 530 may comprise audio sample values that overlap in time and for which overlap smoothing techniques are applied during the sequential combination.
- ⁇ s (0) is the last sample value of a selected decoded time domain frame from which the transition gap filler audio sample values; ⁇ g (i), 0 ⁇ i ⁇ l, are partially derived.
- ⁇ a (0) is the first sample value of a selected decoded transform frame from which the transition gap filler audio sample values; ⁇ g (i), 0 ⁇ i ⁇ l, are partially derived.
- the selected decoded time domain frame is the last replacement frame of the sequence of lost frames (e.g., frame 515 of FIG. 5 ), or in some cases, from the frame preceding the last replacement frame. Audio samples may be used from the frame preceding the last replacement frame, for example, when the pitch delay exceeds the frame length.
- the selected decoded transform domain frame is the decoded transform frame (e.g., frame 530 of FIG. 5 ) that is following immediately after the sequence of lost frames.
- the first decoded audio portion determined at step 335 ( FIG. 4 ) is determined from the second decoded audio portion 530 ( FIG. 5 ) determined at step 330 ( FIG. 4 ), which is shown as step 705 of FIG. 7 .
- the value l is the length of the transition gap filler.
- the value i is a decoded audio sample index. Equation (1) relies upon the sample rates of both the time domain frames and transform domain frames being equivalent. Index changes may be made to the above formula in embodiments when the sample rates are different.
- T 1 is a quantity of samples whose total duration approximates the pitch delay T.
- the pitch delay T is determined from a correctly received frame (see step 325 of FIG. 4 ) and is used as a backward offset ( ⁇ T 1 ) into the selected decoded time domain frame.
- the pitch delay may be determined from the decoded time domain frame immediately preceding the last lost frame (in this example, frame 510 of FIG. 5 ) or a transform domain frame (e.g., 530 of FIG. 5 ).
- the pitch delay may be obtained from the decoded output frame 530 ( FIG. 5 ) in step 325 of FIG. 4 when there are a predetermined minimum number of lost frames, such as two.
- the value T 2 is used as a forward offset into the selected decoded transform domain frame.
- T 2 is a quantity of sample durations that approximates a minimum integral multiple of the pitch delay that prevents attempted usage of decoded sample values that would be in the transition gap (and therefore cannot be determined from the decoded transform domain coded frame 220 ( FIG. 2 ) immediately following the lost frame).
- the decoded time domain frame that is selected to be used for deriving the first portion of the transition gap filler bits is a replacement time domain frame other than the one immediately preceding the last lost frame. For example, when the pitch delay exceeds one frame length, audio samples may taken from the frame preceding the last replacement frame. A set of samples of length l is used from the selected decoded time domain frame, wherein the position of the selected set of samples is determined in manner to properly align the offsets of the first and second portions.
- the gains ⁇ and ⁇ are either each preset equal to 0.5, or in some embodiments one of the gains is preset at a value ⁇ that is other than 0.5 and ⁇ is preset to 1 ⁇ .
- the choice of gains may be based on the particular types of time domain and transform domain coding used and other parameters related to the time domain and transform portions of the audio, such as the type of the audio in each portion. For example, if the time domain frame is unvoiced or silent frame then ⁇ and ⁇ are preset to 0.0 and 1.0, respectively.
- the transition gap filler is generated to be longer than the transition gap (i.e., l is longer than the transition gap caused by decoding a first transform domain coded frame) in order provide smooth merging with wither the last frame of the sequence of replacement frames (at the leading edge of the longer gap filler vector) or the portion of the decoded transform domain frame that follows the transition gap (at the trailing edge of the longer gap filler vector), or both.
- the values of the overlapping samples at an edge are each modified by a different set of multiplying factors, each set having a factor for each sample, wherein in one set the factors increase with an index value and in the other set the factors decrease with the index value, and for which the sum of the two factors for every index value is one, and for which the index spans the overlap at the edge.
- Embodiments described herein provide a method of generating a new decoded time-domain-to-transform-domain transition audio frame when a coded transition frame is lost, without knowing the parameters of the lost transition frame.
- the decoder does not know that the lost frame was a transition frame and hence the lost frame is reconstructed using a time domain frame error reconstruction method.
- the next good frame which is a transform domain frame, becomes a new transition frame for the decoder.
- the method is resource efficient and the new transition frame provides good audio quality.
- FIG. 9 is a block diagram of a device 900 that includes a receiver/transmitter, in accordance with certain embodiments, and represents a user device such as UE 120 or other device that processes audio frames such as those described with reference to FIG. 2 after they are sent over a channel or link, in accordance with techniques described with reference to FIGS. 1-7 .
- the device 900 includes one or more processors 905 , each of which may include such sub-functions as central processing units, cache memory, instruction decoders, just to name a few.
- the processors execute program instructions which could be located within the processors in the form of programmable read only memory, or may located in a memory 910 to which the processors 905 are bi-directionally coupled.
- the program instructions that are executed include instructions for performing the methods described with reference to flow charts 300 , 600 and 700 .
- the processors 905 may include input/output interface circuitry and may be coupled to human interface circuitry 915 .
- the processors 905 are further coupled to at least a receive function, although in many embodiments, the processors 905 are coupled to a receive-transmit function 920 that in wireless embodiments is coupled to a radio antenna 925 .
- the receive-transmit function 920 is a wired receive-transmit function and the antenna is replaced by one or more wired couplings.
- the receive/transmit function 920 itself comprises one or more processors and memory, and may also comprise circuits that are unique to input-output functionality.
- the device 900 may be a personal communication device such as a cell phone, a tablet, or a personal computer, or may be any other type of receiving device operating in a digital audio network.
- the device 900 is an LTE (Long Term Evolution) UE (user equipment that operates in a 3GPP ( 3rd Generation Partnership Project) network.
- LTE Long Term Evolution
- 3GPP 3rd Generation Partnership Project
- a computer readable medium may be any tangible medium capable of storing instructions to be performed by a microprocessor.
- the medium may be one of or include one or more of a CD disc, DVD disc, magnetic or optical disc, tape, and silicon based removable or non-removable memory.
- the programming instructions may also be carried in the form of packetized or non-packetized wireline or wireless transmission signals.
- some embodiments may comprise one or more generic or specialized processors (or “processing devices”) such as microprocessors, digital signal processors, customized processors and field programmable gate arrays (FPGAs) and unique stored program instructions (including both software and firmware) that control the one or more processors to implement, in conjunction with certain non-processor circuits, some, most, or all of the functions of the methods and/or apparatuses described herein.
- processors or “processing devices”
- microprocessors digital signal processors
- FPGAs field programmable gate arrays
- unique stored program instructions including both software and firmware
Abstract
Description
ŝ g(i)=α·ŝ s(i−T 1)+β·ŝ a(i+T 2); 0≦i<l (1)
ŝ g1(i)=α1 ·ŝ s(i−T 1)+β1 ·ŝ a(i+T 2); 0≦i<l/2 (2a)
ŝ g2(i)=α2 ·ŝ s(i−T 1)+β2 ·ŝ a(i+T 2); l/2≦i<l (2b)
Claims (9)
ŝ g(i)=α·ŝ s(i−T 1)+β·ŝ g(i+T 2); 0<+i+l,
ŝ g(i)=α·ŝ s(i−T 1)+β·ŝ α(i+T 2); 0<+i+l,
ŝ g(i)=α·ŝs(i−T 1)+β·ŝ α(i+T 2); 0<+i+l,
Priority Applications (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US13/545,277 US9053699B2 (en) | 2012-07-10 | 2012-07-10 | Apparatus and method for audio frame loss recovery |
EP13735485.8A EP2873070A1 (en) | 2012-07-10 | 2013-06-14 | Apparatus and method for audio frame loss recovery |
PCT/US2013/045763 WO2014011353A1 (en) | 2012-07-10 | 2013-06-14 | Apparatus and method for audio frame loss recovery |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US13/545,277 US9053699B2 (en) | 2012-07-10 | 2012-07-10 | Apparatus and method for audio frame loss recovery |
Publications (2)
Publication Number | Publication Date |
---|---|
US20140019142A1 US20140019142A1 (en) | 2014-01-16 |
US9053699B2 true US9053699B2 (en) | 2015-06-09 |
Family
ID=48782598
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US13/545,277 Expired - Fee Related US9053699B2 (en) | 2012-07-10 | 2012-07-10 | Apparatus and method for audio frame loss recovery |
Country Status (3)
Country | Link |
---|---|
US (1) | US9053699B2 (en) |
EP (1) | EP2873070A1 (en) |
WO (1) | WO2014011353A1 (en) |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20150255079A1 (en) * | 2012-09-28 | 2015-09-10 | Dolby Laboratories Licensing Corporation | Position-Dependent Hybrid Domain Packet Loss Concealment |
Families Citing this family (8)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9129600B2 (en) * | 2012-09-26 | 2015-09-08 | Google Technology Holdings LLC | Method and apparatus for encoding an audio signal |
EP2980795A1 (en) * | 2014-07-28 | 2016-02-03 | Fraunhofer-Gesellschaft zur Förderung der angewandten Forschung e.V. | Audio encoding and decoding using a frequency domain processor, a time domain processor and a cross processor for initialization of the time domain processor |
FR3024582A1 (en) | 2014-07-29 | 2016-02-05 | Orange | MANAGING FRAME LOSS IN A FD / LPD TRANSITION CONTEXT |
CN107004417B (en) | 2014-12-09 | 2021-05-07 | 杜比国际公司 | MDCT domain error concealment |
CN109426794A (en) * | 2017-09-04 | 2019-03-05 | 上海百蝠信息技术有限公司 | Show the monitoring method and device, computer readable storage medium, terminal of information |
CN112187705B (en) * | 2019-07-04 | 2022-04-15 | 成都鼎桥通信技术有限公司 | Audio playing method and equipment |
CN111883173B (en) * | 2020-03-20 | 2023-09-12 | 珠海市杰理科技股份有限公司 | Audio packet loss repairing method, equipment and system based on neural network |
CN113096685B (en) * | 2021-04-02 | 2024-05-07 | 北京猿力未来科技有限公司 | Audio processing method and device |
Citations (8)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
EP0932141A2 (en) | 1998-01-22 | 1999-07-28 | Deutsche Telekom AG | Method for signal controlled switching between different audio coding schemes |
WO1999050828A1 (en) | 1998-03-30 | 1999-10-07 | Voxware, Inc. | Low-complexity, low-delay, scalable and embedded speech and audio coding with adaptive frame loss concealment |
US20060173675A1 (en) | 2003-03-11 | 2006-08-03 | Juha Ojanpera | Switching between coding schemes |
US20080046235A1 (en) | 2006-08-15 | 2008-02-21 | Broadcom Corporation | Packet Loss Concealment Based On Forced Waveform Alignment After Packet Loss |
WO2008066265A1 (en) | 2006-11-30 | 2008-06-05 | Samsung Electronics Co., Ltd. | Frame error concealment method and apparatus and error concealment scheme construction method and apparatus |
EP2270776A1 (en) | 2008-05-22 | 2011-01-05 | Huawei Technologies Co., Ltd. | Method and device for frame loss concealment |
US20110007827A1 (en) * | 2008-03-28 | 2011-01-13 | France Telecom | Concealment of transmission error in a digital audio signal in a hierarchical decoding structure |
US8015000B2 (en) | 2006-08-03 | 2011-09-06 | Broadcom Corporation | Classification-based frame loss concealment for audio signals |
-
2012
- 2012-07-10 US US13/545,277 patent/US9053699B2/en not_active Expired - Fee Related
-
2013
- 2013-06-14 WO PCT/US2013/045763 patent/WO2014011353A1/en active Application Filing
- 2013-06-14 EP EP13735485.8A patent/EP2873070A1/en not_active Withdrawn
Patent Citations (9)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
EP0932141A2 (en) | 1998-01-22 | 1999-07-28 | Deutsche Telekom AG | Method for signal controlled switching between different audio coding schemes |
US20030009325A1 (en) | 1998-01-22 | 2003-01-09 | Raif Kirchherr | Method for signal controlled switching between different audio coding schemes |
WO1999050828A1 (en) | 1998-03-30 | 1999-10-07 | Voxware, Inc. | Low-complexity, low-delay, scalable and embedded speech and audio coding with adaptive frame loss concealment |
US20060173675A1 (en) | 2003-03-11 | 2006-08-03 | Juha Ojanpera | Switching between coding schemes |
US8015000B2 (en) | 2006-08-03 | 2011-09-06 | Broadcom Corporation | Classification-based frame loss concealment for audio signals |
US20080046235A1 (en) | 2006-08-15 | 2008-02-21 | Broadcom Corporation | Packet Loss Concealment Based On Forced Waveform Alignment After Packet Loss |
WO2008066265A1 (en) | 2006-11-30 | 2008-06-05 | Samsung Electronics Co., Ltd. | Frame error concealment method and apparatus and error concealment scheme construction method and apparatus |
US20110007827A1 (en) * | 2008-03-28 | 2011-01-13 | France Telecom | Concealment of transmission error in a digital audio signal in a hierarchical decoding structure |
EP2270776A1 (en) | 2008-05-22 | 2011-01-05 | Huawei Technologies Co., Ltd. | Method and device for frame loss concealment |
Non-Patent Citations (4)
Title |
---|
Combescure, Pierre et al.: "A 16, 24, 32 Kbit/S Wideband Speech Codec Based on ATCELP", Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), vol. I, Phoenix, Arizona, USA, Mar. 1999, all pages. |
International Telecommunication Union, ITU-T, G.711, Telecommunication Standardization Sector of ITU, Sep. 1999, "Series G.: Transmission Systems and Media, Digital Systems and Networks, Terminal equipments Coding of analogue signals by pulse code modulation", Pulse code modulation (PCM) of voice frequencies, Appendix I: A high qulaity low-complexity algorithm for packet loss concealment with G.711, ITU-T Recommendation G.711-Appendix I (Previously CCITT Recommendation), all pages. |
International Telecommunication Union, ITU-T, G.718, Telecommunication Standardization Sector of ITU, Jun. 2008, "Series G.: Transmission Systems and Media, Digital Systems and Networks, Digital terminal equipments-Coding of voice and audio signals", Frame error robust narrow-band and wideband embedded variable bit-rate coding of speech and audio from 8-32 kbit/s, Recommendation ITU-T G.718, all pages. |
Patent Cooperation Treaty, International Search Report and Written Opinion of the International Searching Authority for International Application No. PCT/US2013/045763, Dec. 2, 2013, 11 pages. |
Cited By (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20150255079A1 (en) * | 2012-09-28 | 2015-09-10 | Dolby Laboratories Licensing Corporation | Position-Dependent Hybrid Domain Packet Loss Concealment |
US9514755B2 (en) * | 2012-09-28 | 2016-12-06 | Dolby Laboratories Licensing Corporation | Position-dependent hybrid domain packet loss concealment |
US9881621B2 (en) | 2012-09-28 | 2018-01-30 | Dolby Laboratories Licensing Corporation | Position-dependent hybrid domain packet loss concealment |
Also Published As
Publication number | Publication date |
---|---|
US20140019142A1 (en) | 2014-01-16 |
WO2014011353A1 (en) | 2014-01-16 |
EP2873070A1 (en) | 2015-05-20 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US9053699B2 (en) | Apparatus and method for audio frame loss recovery | |
US9123328B2 (en) | Apparatus and method for audio frame loss recovery | |
US11670314B2 (en) | Audio decoder, apparatus for generating encoded audio output data and methods permitting initializing a decoder | |
JP5587405B2 (en) | System and method for preventing loss of information in speech frames | |
US20190198027A1 (en) | Audio frame loss recovery method and apparatus | |
EP3175564B1 (en) | System and method of redundancy based packet transmission error recovery | |
US9916837B2 (en) | Methods and apparatuses for transmitting and receiving audio signals | |
US20170187635A1 (en) | System and method of jitter buffer management | |
KR102019617B1 (en) | Channel Adjustment for Interframe Time Shift Variations | |
US11955130B2 (en) | Layered coding and data structure for compressed higher-order Ambisonics sound or sound field representations | |
US20210312932A1 (en) | Multichannel Audio Signal Processing Method, Apparatus, and System | |
JP2008261904A (en) | Encoding device, decoding device, encoding method and decoding method | |
EP3117432B1 (en) | Audio coding method and apparatus | |
EP3682445B1 (en) | Selecting channel adjustment method for inter-frame temporal shift variations | |
CN110770822B (en) | Audio signal encoding and decoding | |
US9437203B2 (en) | Error concealment for speech decoder | |
CN112992161A (en) | Audio encoding method, audio decoding method, audio encoding apparatus, audio decoding medium, and electronic device | |
BR112017000791B1 (en) | PACKET TRANSMISSION ERROR RECOVERY SYSTEM AND METHOD BASED ON REDUNDANCY | |
BR112017001088B1 (en) | PACKET TRANSMISSION ERROR RECOVERY DEVICE AND METHOD BASED ON REDUNDANCY | |
US20070005347A1 (en) | Method and apparatus for data frame construction |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: MOTOROLA MOBILITY LLC, ILLINOISFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:MITTAL, UDAR;ASHLEY, JAMES P.;REEL/FRAME:028521/0249Effective date: 20120710 |
|
AS | Assignment |
Owner name: GOOGLE TECHNOLOGY HOLDINGS LLC, CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:MOTOROLA MOBILITY LLC;REEL/FRAME:034286/0001Effective date: 20141028 |
|
AS | Assignment |
Owner name: GOOGLE TECHNOLOGY HOLDINGS LLC, CALIFORNIAFree format text: CORRECTIVE ASSIGNMENT TO CORRECT THE REMOVE INCORRECT PATENT NO. 8577046 AND REPLACE WITH CORRECT PATENT NO. 8577045 PREVIOUSLY RECORDED ON REEL 034286 FRAME 0001. ASSIGNOR(S) HEREBY CONFIRMS THE ASSIGNMENT;ASSIGNOR:MOTOROLA MOBILITY LLC;REEL/FRAME:034538/0001Effective date: 20141028 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 4TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1551); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 4 |
|
FEPP | Fee payment procedure |
Free format text: MAINTENANCE FEE REMINDER MAILED (ORIGINAL EVENT CODE: REM.); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
LAPS | Lapse for failure to pay maintenance fees |
Free format text: PATENT EXPIRED FOR FAILURE TO PAY MAINTENANCE FEES (ORIGINAL EVENT CODE: EXP.); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
STCH | Information on status: patent discontinuation |
Free format text: PATENT EXPIRED DUE TO NONPAYMENT OF MAINTENANCE FEES UNDER 37 CFR 1.362 |
|
FP | Lapsed due to failure to pay maintenance fee |
Effective date: 20230609 |