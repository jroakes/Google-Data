KR20230141950A - Voice query qos based on client-computed content metadata - Google Patents
Voice query qos based on client-computed content metadata Download PDFInfo
- Publication number
- KR20230141950A KR20230141950A KR1020237033169A KR20237033169A KR20230141950A KR 20230141950 A KR20230141950 A KR 20230141950A KR 1020237033169 A KR1020237033169 A KR 1020237033169A KR 20237033169 A KR20237033169 A KR 20237033169A KR 20230141950 A KR20230141950 A KR 20230141950A
- Authority
- KR
- South Korea
- Prior art keywords
- speech input
- speech
- asr
- processing
- user device
- Prior art date
Links
- 238000000034 method Methods 0.000 claims abstract description 67
- 238000012545 processing Methods 0.000 claims description 278
- 230000015654 memory Effects 0.000 claims description 46
- 230000004044 response Effects 0.000 claims description 31
- 238000013518 transcription Methods 0.000 claims description 19
- 230000035897 transcription Effects 0.000 claims description 19
- 230000009471 action Effects 0.000 claims description 12
- 230000007958 sleep Effects 0.000 claims description 4
- 238000007781 pre-processing Methods 0.000 abstract description 44
- 230000008569 process Effects 0.000 description 35
- 230000000694 effects Effects 0.000 description 12
- 230000007613 environmental effect Effects 0.000 description 10
- 230000006399 behavior Effects 0.000 description 8
- 238000004590 computer program Methods 0.000 description 8
- 230000003993 interaction Effects 0.000 description 7
- 238000010586 diagram Methods 0.000 description 6
- 230000006870 function Effects 0.000 description 4
- 230000003287 optical effect Effects 0.000 description 4
- 230000005236 sound signal Effects 0.000 description 3
- 230000005540 biological transmission Effects 0.000 description 2
- 230000008859 change Effects 0.000 description 2
- 238000004891 communication Methods 0.000 description 2
- 238000001514 detection method Methods 0.000 description 2
- 230000000977 initiatory effect Effects 0.000 description 2
- 230000006855 networking Effects 0.000 description 2
- 239000004065 semiconductor Substances 0.000 description 2
- 230000003068 static effect Effects 0.000 description 2
- 230000001960 triggered effect Effects 0.000 description 2
- 241000282412 Homo Species 0.000 description 1
- 230000001413 cellular effect Effects 0.000 description 1
- 230000006266 hibernation Effects 0.000 description 1
- 238000012804 iterative process Methods 0.000 description 1
- 239000004973 liquid crystal related substance Substances 0.000 description 1
- 238000012423 maintenance Methods 0.000 description 1
- 238000012986 modification Methods 0.000 description 1
- 230000004048 modification Effects 0.000 description 1
- 238000013442 quality metrics Methods 0.000 description 1
- 239000007787 solid Substances 0.000 description 1
- 230000000007 visual effect Effects 0.000 description 1
Classifications
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/22—Procedures used during a speech recognition process, e.g. man-machine dialogue
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/60—Information retrieval; Database structures therefor; File system structures therefor of audio data
- G06F16/63—Querying
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/16—Sound input; Sound output
- G06F3/167—Audio in a user interface, e.g. using voice commands for navigating, audio feedback
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/08—Speech classification or search
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/26—Speech to text systems
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/28—Constructional details of speech recognition systems
- G10L15/30—Distributed recognition, e.g. in client-server systems, for mobile phones or network applications
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L25/00—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00
- G10L25/48—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00 specially adapted for particular use
- G10L25/51—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00 specially adapted for particular use for comparison or discrimination
- G10L25/60—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00 specially adapted for particular use for comparison or discrimination for measuring the quality of voice signals
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L65/00—Network arrangements, protocols or services for supporting real-time applications in data packet communication
- H04L65/80—Responding to QoS
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L67/00—Network arrangements or protocols for supporting network services or applications
- H04L67/50—Network services
- H04L67/56—Provisioning of proxy services
- H04L67/568—Storing data temporarily at an intermediate stage, e.g. caching
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L67/00—Network arrangements or protocols for supporting network services or applications
- H04L67/50—Network services
- H04L67/60—Scheduling or organising the servicing of application requests, e.g. requests for application data transmissions using the analysis and optimisation of the required network resources
- H04L67/61—Scheduling or organising the servicing of application requests, e.g. requests for application data transmissions using the analysis and optimisation of the required network resources taking into account QoS or priority requirements
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/08—Speech classification or search
- G10L2015/088—Word spotting
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/22—Procedures used during a speech recognition process, e.g. man-machine dialogue
- G10L2015/226—Procedures used during a speech recognition process, e.g. man-machine dialogue using non-speech characteristics
Abstract
방법은, 사용자 디바이스로부터 ASR(automated speech recognition) 요청을 수신하는 단계를 포함하며, ASR 요청은 사용자 디바이스에 의해 캡처된 스피치 입력, 및 스피치 입력과 연관된 콘텐츠 메타데이터를 포함한다. 콘텐츠 메타데이터는 사용자 디바이스에 의해 생성된다. 방법은 또한, 스피치 입력과 연관된 콘텐츠 메타데이터에 기반하여 ASR 요청에 대한 우선순위 스코어를 결정하는 단계, 및 대응하는 우선순위 스코어를 각각 갖는 계류중인 ASR 요청들의 프리-프로세싱 백로그에 ASR 요청을 캐싱하는 단계를 포함한다. 프리-프로세싱 백로그 내의 계류중인 ASR 요청들은 우선순위 스코어들의 순위로 랭킹된다. 방법은 또한, 프리-프로세싱 백로그로부터, 계류중인 ASR 요청들 중 하나 이상의 계류중인 ASR 요청들을 백엔드-측 ASR 모듈에 제공하는 단계를 포함하며, 더 높은 우선순위 스코어들과 연관된 계류중인 ASR 요청들은 더 낮은 우선순위 스코어들과 연관된 계류중인 ASR 요청들 전에 프로세싱된다. The method includes receiving an automated speech recognition (ASR) request from a user device, wherein the ASR request includes speech input captured by the user device, and content metadata associated with the speech input. Content metadata is created by the user device. The method also includes determining a priority score for an ASR request based on content metadata associated with the speech input, and caching the ASR request in a pre-processing backlog of pending ASR requests each having a corresponding priority score. It includes steps to: Pending ASR requests in the pre-processing backlog are ranked by priority scores. The method also includes providing, from a pre-processing backlog, one or more of the pending ASR requests to a backend-side ASR module, wherein the pending ASR requests associated with higher priority scores have more pending ASR requests. Processed before pending ASR requests associated with low priority scores.
Description
[0001] 본 개시내용은 클라이언트-컴퓨팅된 콘텐츠 메타데이터에 기반한 음성 질의(voice query) QoS(quality of service)에 관한 것이다.[0001] This disclosure relates to voice query quality of service (QoS) based on client-computed content metadata.
[0002] 스피치-가능(speech-enabled) 환경(예컨대, 가정, 작업장, 학교, 자동차 등)은 사용자가 컴퓨터-기반 시스템에 대해 질의(query) 또는 커맨드(command)를 큰 소리로 말할 수 있게 하고, 컴퓨터-기반 시스템은 질의를 처리(field)하고 이에 응답하며 그리고/또는 커맨드에 기반하여 기능을 수행한다. 스피치-가능 환경은, 그 환경의 다양한 룸들 또는 영역들을 통해 분배되어 있는 연결된 마이크로폰 디바이스들의 네트워크를 사용하여 구현될 수 있다. 이러한 디바이스들은, 핫워드(hotword)들을 사용하여, 환경에 존재하는 다른 개인에게 향하는 발언(utterance)과 대조적으로, 주어진 발언이 시스템에 향하는 때를 식별하는 것을 도울 수 있다. 따라서, 디바이스들은 슬립(sleep) 상태 또는 동면(hibernation) 상태로 동작하고, 검출된 발언이 핫워드를 포함하는 경우에만 웨이크업(wake-up)할 수 있다. 백엔드 서버에서 발생하는 질의 프로세싱(query processing)은 비용이 많이 들며, 그리고 주어진 시간에 처리할 수 있는 것보다 더 많은 질의들로 서버가 오버로드(overload)될 수 있다. 예컨대, 대규모 이벤트들 동안 텔레비전 프로그래밍/광고들에 존재하는 핫워드들은 서버가 오버로드되게 하여, 사용 불능(outage)을 초래할 수 있다. [0002] Speech-enabled environments (e.g., homes, workplaces, schools, cars, etc.) allow users to say queries or commands out loud to computer-based systems, and computer- The underlying system fields and responds to queries and/or performs functions based on commands. A speech-enabled environment may be implemented using a network of connected microphone devices distributed throughout various rooms or areas of the environment. These devices can use hotwords to help identify when a given utterance is directed at the system as opposed to utterance directed at another individual present in the environment. Accordingly, devices operate in a sleep state or hibernation state and can wake-up only when the detected utterance includes a hotword. Query processing on backend servers is expensive, and servers can be overloaded with more queries than they can process at any given time. For example, hotwords present in television programming/advertisements during large events can cause servers to become overloaded, resulting in outage.
[0003] 음성 가능 디바이스(voice enabled device)(예컨대, 음성 어시스턴트를 실행하는 사용자 디바이스)는 사용자가 질의 또는 커맨드를 큰 소리로 말할 수 있게 하고, 질의를 처리하고 이에 응답하며 그리고/또는 커맨드에 기반하여 기능을 수행한다. 음성 가능 디바이스에 대한 주의를 환기시키기 위해 말하는 미리 결정된 용어/어구(term/phrase)를 합의(agreement)에 의해 지정하는 "핫워드"(또한 "키워드", "주의 단어", "웨이크업 어구/단어", "트리거 어구" 또는 "음성 액션 개시 커맨드"로서 지칭됨)의 사용을 통해, 음성 가능 디바이스는 시스템에게 향하는 발언들과 환경 내의 개인에게 향하는 발언들을 식별(즉, 발언에서 핫워드 다음에 오는 하나 이상의 용어들을 프로세싱하기 위한 웨이크업 프로세스를 개시하기 위해서임)할 수 있다. 전형적으로, 음성 가능 디바이스는 배터리 전력을 절약하기 위해 슬립 상태 또는 저 전력 상태로 동작하고, 발화된(spoken) 핫워드를 검출하기 위해 입력 오디오 데이터를 프로세싱한다. 예컨대, 저 전력 상태에 있는 동안, 음성 가능 디바이스는 마이크로폰을 통해 입력 오디오를 캡처하고, 입력 오디오 내의 핫워드의 존재를 검출하도록 훈련된 핫워드 검출기를 사용한다. 핫워드가 입력 오디오에서 검출될 때, 음성 가능 디바이스는 핫워드 및/또는 입력 오디오에서 핫워드 다음에 오는 임의의 다른 용어들을 프로세싱하기 위한 웨이크업 프로세스를 개시한다. [0003] A voice enabled device (e.g., a user device running a voice assistant) allows a user to speak a query or command out loud, process and respond to the query, and/or perform functions based on the command. Perform. A “hotword” (also “keyword”, “attention word”, “wakeup phrase/ Through the use of utterances (referred to as “words,” “trigger phrases,” or “voice action initiation commands”), a voice-enabled device identifies utterances that are directed to the system and those that are directed to individuals in the environment (i.e., following a hotword in an utterance). to initiate a wake-up process for processing one or more terms that are coming). Typically, voice-enabled devices operate in a sleep or low-power state to save battery power and process input audio data to detect spoken hotwords. For example, while in a low power state, a voice-enabled device captures input audio through a microphone and uses a hotword detector trained to detect the presence of hotwords in the input audio. When a hotword is detected in the input audio, the speech-enabled device initiates a wakeup process to process the hotword and/or any other terms that follow the hotword in the input audio.
[0004] 전형적으로, 음성 가능 디바이스가 스피치의 발언(예컨대, 입력 오디오)에서 핫워드의 존재를 검출함으로써 웨이크업한 후, 음성 가능 디바이스는 핫워드 및 핫워드 다음에 오는 하나 이상의 다른 용어들을 네트워크를 통해 서버-기반 프로세싱 스택(server-based processing stack)(질의 프로세싱 백엔드(query processing backend)로 또한 지칭됨)으로 전송하며, 이러한 서버-기반 프로세싱 스택은 적어도, 핫워드 및/또는 핫워드 다음에 오는 임의의 다른 용어들을 프로세싱하도록 구성된 ASR(automated speech recognizer)을 포함한다. 여기서, ASR은 수신된 오디오를 ASR 요청으로서 취급하고, 핫워드 및/또는 핫워드 다음에 오는 다른 용어들을 대응하는 텍스트로 전사(transcribe)할 수 있다. 텍스트는, 입력 오디오에 의해 특정된 음성 질의를 결정하고 그리고 질의에 관련된 액션을 수행하도록 적절한 컴포넌트에 질의를 제공하는 해석 계층(interpretation layer)에 제공될 수 있다. 따라서, 음성 가능 디바이스의 사용자가 다음의 스피치: "Hey Google, what restaurants are still open right now?"를 발언하는 경우, 음성 가능 디바이스는 핫워드("Hey Google")를 검출하는 것에 대한 응답으로 웨이크업하며, 음성 질의에 대응하는, 핫워드 다음에 오는 용어들("what nearby restaurants are still open right now?")을 프로세싱을 위해 서버-기반 프로세싱 스택에 제공할 수 있다. 이 예에서, 서버-기반 프로세싱 스택의 ASR은 음성 질의를 대응하는 텍스트로 전사할 것이고, 해석 계층은 근처 레스토랑들의 영업 시간에 대한 검색이 필요하다고 결정할 것이며, 검색 엔진은 현재 영업 중인 근처 레스토랑들을 포함하는 검색 결과들의 리스트를 획득할 것이다. 검색 결과들은 디스플레이 또는 가청 출력을 위해 음성 가능 디바이스에 다시 제공될 수 있다. 일부 시나리오들에서, 서버-기반 프로세싱 스택은 또한, 검색 결과들의 리스트를 합성된 스피치(synthesized speech)로 변환하도록 구성된 TTS(text-to-speech) 변환기를 포함하며, 합성된 스피치는 그에 대한 가청 출력을 위해 음성 가능 디바이스로 다시 제공된다. [0004] Typically, after a speech-capable device wakes up by detecting the presence of a hotword in an utterance of speech (e.g., input audio), the speech-capable device transmits the hotword and one or more other terms following the hotword to a server over the network. - to a server-based processing stack (also referred to as a query processing backend), which server-based processing stack is configured to transmit at least the hotword and/or any following the hotword. Contains an automated speech recognizer (ASR) configured to process different terms. Here, ASR may treat the received audio as an ASR request and transcribe the hotword and/or other terms following the hotword into corresponding text. The text may be provided to an interpretation layer, which determines the speech query specified by the input audio and provides the query to the appropriate components to perform actions related to the query. Therefore, if the user of a voice-enabled device utters the following speech: “Hey Google, what restaurants are still open right now?”, the voice-enabled device wakes in response to detecting the hotword (“Hey Google”). Up, the terms following the hotword (“what nearby restaurants are still open right now?”), corresponding to the voice query, can be provided to the server-based processing stack for processing. In this example, the ASR in the server-based processing stack will transcribe the voice query into corresponding text, the interpretation layer will determine that a search is needed for the opening hours of nearby restaurants, and the search engine will determine which nearby restaurants are currently open. You will get a list of search results. Search results may be provided back to the voice-enabled device for display or audible output. In some scenarios, the server-based processing stack also includes a text-to-speech converter configured to convert the list of search results into synthesized speech, wherein the synthesized speech produces an audible output therefor. It is again provided as a voice-enabled device for .
[0005] 서버-기반 프로세싱 스택은 전체 사용자 집단(user population)과 연관된 복수의 음성 가능 디바이스들로부터 수신되는 음성 질의들을 프로세싱하도록 구성된다. 이는, 서버-기반 프로세싱 스택에 의한 프로세싱을 위해 음성 질의들을 전송하는 수백만 개의 음성 가능 디바이스들을 포함할 수 있다. 음성 질의들을 프로세싱하는 것은 비용이 많이 드는 작업이며, 일부 상황들에서, 서버-기반 프로세싱 스택은 자신이 주어진 시간에 프로세싱할 수 있는 것보다 너무 많은 음성 질의들로 오버로드될 수 있다. 예컨대, 핫워드들, 또는 핫워드들과 유사하게 들리는 다른 용어들이 대규모 텔레비전 프로그래밍 이벤트들(예컨대, 슈퍼볼(Superbowl) 동안의 광고)에 존재하는 경우, (예컨대, 가정의 텔레비전에 근접한) 근처의 음성 가능 디바이스들은 핫워드를 검출하고 서버-기반 프로세싱 스택에 의도하지 않은 음성 질의를 발행함으로써, 서버-기반 프로세싱 스택에서의 트래픽에 매우 큰 스파이크를 초래할 수 있다. 서버-기반 프로세싱 스택이, 실제 사용자에 의해 개시되지 않고 그리고/또는 시간이 중요하지 않은 음성 질의들을 단순히 드롭(drop)시키는 것을 고려할 수 있지만, 비용이 많이 드는 프로세싱을 시작하지 않으면서 그러한 질의들을 식별하는 것은 어렵다. [0005] The server-based processing stack is configured to process voice queries received from a plurality of voice enabled devices associated with an entire user population. This may include millions of voice-enabled devices transmitting voice queries for processing by a server-based processing stack. Processing voice queries is an expensive task, and in some situations, a server-based processing stack can become overloaded with more voice queries than it can process at any given time. For example, when hotwords, or other terms that sound similar to hotwords, are present in large-scale television programming events (e.g., commercials during the Superbowl), nearby (e.g., close to home televisions) Voice enabled devices can detect hotwords and issue unintended voice queries to the server-based processing stack, resulting in very large spikes in traffic in the server-based processing stack. A server-based processing stack could consider simply dropping voice queries that are not initiated by an actual user and/or are not time critical, but rather identify such queries without initiating costly processing. It's hard to do.
[0006] 본원에서의 구현들은, 음성 가능 디바이스들(예컨대, 사용자 디바이스들)로부터 ASR 요청들을 수신하는 질의 프로세싱 백엔드(예컨대, 서버-기반 프로세싱 스택)에 관한 것이다. 각각의 ASR 요청이, 프로세싱을 위한 음성 질의를 포함하는, 사용자 디바이스에 의해 캡처되는 대응하는 스피치 입력을 포함하는 것에 부가하여, 각각의 ASR 요청은 음성 가능 디바이스에 의해 생성되는 스피치 입력과 연관된 콘텐츠 메타데이터를 또한 포함한다. 스피치 입력과 연관된 콘텐츠 메타데이터에 기반하여, 질의 프로세싱 백엔드는 각각의 ASR 요청에 대한 우선순위 스코어(priority score)를 결정하고, 그리고 각각 해당 우선순위 스코어를 가지며 우선순위 스코어들의 순위(order)로 랭크(rank)된 계류중(pending)인 ASR 요청들의 프리-프로세싱 백로그(pre-processing backlog)에 ASR 요청을 캐싱(cache)할 수 있다. 그 후, 질의 프로세싱 백엔드는, 백엔드-측 ASR 모듈의 프로세싱 가용성에 기반하여, 프리-프로세싱 백로그로부터 백엔드-측 ASR 모듈(또는 질의 프로세싱 백엔드의 다른 컴포넌트)로 하나 이상의 계류중인 ASR 요청들을 제공할 수 있다. 여기에서는, 백엔드-측 ASR 모듈이 선착순(first-come first-serve)에 기반하여 각각의 계류중인 ASR 요청들을 프로세싱하고자 시도함으로써 트래픽 스파이크들 동안 오버로드되는 것이 아니라, 백엔드-측 ASR 모듈이 더 낮은 우선순위 스코어들과 연관된 계류중인 ASR 요청들을 프로세싱하기 전에 더 높은 우선순위 스코어들과 연관된 계류중인 ASR 요청들을 프로세싱하도록 ASR 요청들의 우선순위가 부여된다. 새로운 ASR 요청들이 들어오면, 프리-프로세싱 백로그 내의 계류중인 ASR 요청들은 우선순위 스코어들에 기반하여 재정렬(re-order)된다. 이상적으로, 실제 사용자들에 의해 개시되었을 가능성이 없고 그리고/또는 시간이 중요하지 않은 의도하지 않은 음성 질의들과 연관된 그러한 ASR 요청들에는 더 낮은 우선순위 스코어들이 할당된다. 따라서, 백엔드-ASR 모듈이 더 높은 우선순위 스코어들과 연관된 ASR 요청들을 먼저 프로세싱하도록, 더 낮은 우선순위 스코어들과 연관된 ASR 요청들은 트래픽 스파이크들 동안 프리-프로세싱 백로그에 남아 있다. [0006] Implementations herein relate to a query processing backend (eg, server-based processing stack) that receives ASR requests from voice capable devices (eg, user devices). In addition to each ASR request including a corresponding speech input captured by the user device that includes a speech query for processing, each ASR request also includes content metadata associated with the speech input generated by the speech capable device. Also includes data. Based on the content metadata associated with the speech input, the query processing backend determines a priority score for each ASR request, and each ASR request has a corresponding priority score and is ranked in order of the priority scores. ASR requests can be cached in a pre-processing backlog of ranked and pending ASR requests. The query processing backend may then serve one or more pending ASR requests from the pre-processing backlog to the backend-side ASR module (or another component of the query processing backend), based on the processing availability of the backend-side ASR module. there is. Here, rather than the backend-side ASR module being overloaded during traffic spikes by attempting to process each pending ASR request on a first-come first-serve basis, the backend-side ASR module has a lower ASR requests are prioritized to process pending ASR requests associated with higher priority scores before processing pending ASR requests associated with priority scores. When new ASR requests come in, pending ASR requests in the pre-processing backlog are re-ordered based on priority scores. Ideally, lower priority scores are assigned to those ASR requests that are unlikely to have been initiated by actual users and/or are associated with unintentional voice queries that are not time critical. Accordingly, ASR requests associated with lower priority scores remain in the pre-processing backlog during traffic spikes, such that the backend-ASR module processes ASR requests associated with higher priority scores first.
[0007] 일부 예들에서, 어떠한 임계치 미만의 우선순위 스코어들은 단순히 해당 ASR 요청이 드롭되는 결과를 초래할 수 있다. 콘텐츠 메타데이터로부터 결정되는 낮은 우선순위 스코어는 또한, 해당 ASR 요청의 프로세싱이 실패할 것이라는 강력한 표시자일 수 있다. 예컨대, 콘텐츠 메타데이터는 스피치 입력과 연관된 오디오의 품질이 매우 불량하다는 것을 표시할 수 있으며, 따라서, 불량한 오디오 품질은, 백엔드-ASR 모듈이 오디오 데이터를 대응하는 텍스트로 성공적으로 전사하는 것이 어려울 것이라는 표시를 제공할 수 있다. 동시에, 음성 가능 디바이스에 의해 캡처되는 스피치와 연관된 불량한 오디오 품질은 또한, 핫워드(또는 유사하게 들리는 단어)를 말한 사용자가 음성 가능 디바이스에 가까이 있지 않으며, 그에 따라, 음성 가능 디바이스에 스피치 입력을 제공하고자 의도했을 가능성이 없었음을 표시할 수 있다. 콘텐츠 메타데이터는 또한, 음성 가능 디바이스와 연관된 사용자가 스피치 입력을 말했을 가능성이 있는지 여부를 표시할 수 있다. 예컨대, 음성 가능 디바이스 상의 핫워드 검출기는 스피치 입력을 그 사용자에 대한 오디오 프로파일과 비교하고, 그 사용자가 스피치 입력을 말했을 가능성이 높은지 여부를 결정할 수 있다. 사용자가 스피치 입력을 말했을 가능성이 있음을 콘텐츠 메타데이터가 표시할 때, 대응하는 ASR 요청에는 다른 사용자가 스피치 입력을 말했을 경우보다 더 높은 우선순위 스코어가 할당될 수 있다. 반면, 다른 사용자 또는 오디오 브로드캐스트 디바이스(예컨대, TV, 음악 스피커 또는 음향 사운드들을 출력할 수 있는 기타 비-인간 소스)로부터의 브로드캐스트 오디오가 스피치 입력을 개시했다고 콘텐츠 메타데이터가 표시할 때, 대응하는 ASR 요청에는 낮은 우선순위 스코어가 할당될 수 있다. 콘텐츠 메타데이터는, 음성 가능 디바이스에 의해 컴퓨팅/생성되어 질의 프로세싱 백엔드에 제공되는 ASR 요청에 포함되는 임의의 타입의 데이터를 포함할 수 있으며, 그에 따라, 질의 프로세싱 백엔드는 ASR 요청에 대한 어떠한 프로세싱도 발생시키지 않으면서(또는 최소한의 매우 제한된 양의 프로세싱으로) ASR 요청의 중요도에 우선순위를 부여할 수 있다. 전술한 내용을 고려하여, 스피치 입력과 연관된 콘텐츠 메타데이터는 대응하는 ASR 요청이 백엔드-측 ASR 모듈에 의해 성공적으로 프로세싱될 가능성 및/또는 대응하는 ASR 요청의 프로세싱이 음성 가능 디바이스와 연관된 사용자에게 영향을 미치게 될 가능성을 나타낸다. [0007] In some examples, priority scores below a certain threshold may simply result in the corresponding ASR request being dropped. A low priority score determined from content metadata can also be a strong indicator that processing of that ASR request will fail. For example, content metadata may indicate that the quality of the audio associated with the speech input is very poor, such that poor audio quality indicates that it will be difficult for the backend-ASR module to successfully transcribe the audio data into corresponding text. can be provided. At the same time, the poor audio quality associated with speech captured by a voice-enabled device may also indicate that the user who said the hotword (or similar-sounding word) is not close to the voice-enabled device and, therefore, is not providing speech input to the voice-enabled device. It can indicate that there was no possibility that it was intended to be done. Content metadata may also indicate whether the user associated with the speech-enabled device likely uttered the speech input. For example, a hotword detector on a speech-enabled device may compare the speech input to an audio profile for the user and determine whether the user most likely uttered the speech input. When content metadata indicates that a user likely uttered the speech input, the corresponding ASR request may be assigned a higher priority score than if the speech input was uttered by another user. On the other hand, when the content metadata indicates that the speech input was initiated by broadcast audio from another user or an audio broadcast device (e.g., a TV, music speaker, or other non-human source capable of outputting acoustic sounds), the response ASR requests that do so may be assigned a low priority score. Content metadata may include any type of data that is included in an ASR request that is computed/generated by a voice-enabled device and provided to a query processing backend, such that the query processing backend does not perform any processing on the ASR request. You can prioritize the importance of ASR requests without generating them (or at least with a very limited amount of processing). Considering the foregoing, content metadata associated with a speech input determines the likelihood that the corresponding ASR request will be successfully processed by the backend-side ASR module and/or that processing of the corresponding ASR request will have an impact on the user associated with the voice-enabled device. Indicates the possibility of reaching .
[0008] 홈 디바이스들에서의 스피치 프로세싱은 종종, 서버에서 피크 시간에 발생하여, 스피치 프로세싱에 대한 요청들의 큰 백로그를 생성할 수 있다. 이러한 요청들 중 일부는 진짜(genuine) 요청들일 수 있는 반면, 일부는 브로드캐스트 오디오(예컨대, 텔레비전들, 라디오들과 같은 비-인간 소스들로부터의 오디오 출력, 또는 합성된 스피치)의 결과일 수 있다. 본 발명의 목적은 대량(large volume)의 스피치 인식 요청들의 프로세싱을 개선하는 방법을 제공하는 것이다. 요청들에 우선순위들을 부여함으로써, 스피치 인식 모듈이, 다른 요청들에는 더 낮은 우선순위를 할당하여, 더 중요하거나 긴급한 요청들을 프로세싱하게 허용한다. 이는 오버로드되는 시간에 스피치 인식 모듈의 사용을 최적화한다. [0008] Speech processing in home devices often occurs at peak times on servers, which can create a large backlog of requests for speech processing. Some of these requests may be genuine requests, while others may be the result of broadcast audio (e.g., audio output from non-human sources such as televisions, radios, or synthesized speech). there is. It is an object of the present invention to provide a method for improving the processing of large volume speech recognition requests. Assigning priorities to requests allows the speech recognition module to process more important or urgent requests while assigning lower priorities to other requests. This optimizes the use of the speech recognition module at times of overload.
[0009] 본 개시내용의 일 양상은 음성 질의들에 대한 서비스 품질(quality of service)을 제공하기 위한 방법을 제공한다. 방법은, 질의 프로세싱 백엔드의 데이터 프로세싱 하드웨어에서, 사용자 디바이스로부터 ASR(automated speech recognition) 요청을 수신하는 단계를 포함한다. ASR 요청은 사용자 디바이스에 의해 캡처된 스피치 입력 및 스피치 입력과 연관된 콘텐츠 메타데이터를 포함한다. 스피치 입력은 음성 질의를 포함하고, 콘텐츠 메타데이터는 사용자 디바이스에 의해 생성된다. 방법은 또한, 데이터 프로세싱 하드웨어에 의해, 스피치 입력과 연관된 콘텐츠 메타데이터에 기반하여 ASR 요청에 대한 우선순위 스코어를 결정하는 단계를 포함한다. 방법은 또한, 데이터 프로세싱 하드웨어에 의해, 대응하는 우선순위 스코어를 각각 갖는 계류중인 ASR 요청들의 프리-프로세싱 백로그에 ASR 요청을 캐싱(caching)하는 단계를 포함한다. 프리-프로세싱 백로그 내의 계류중인 ASR 요청들은 우선순위 스코어들의 순위로 랭킹된다. 방법은, 데이터 프로세싱 하드웨어에 의해, 백엔드-측 ASR 모듈의 프로세싱 가용성에 기반하여, 프리-프로세싱 백로그로부터, 계류중인 ASR 요청들 중 하나 이상의 계류중인 ASR 요청들을 백엔드-측 ASR 모듈에 제공하는 단계를 더 포함한다. 더 높은 우선순위 스코어들과 연관된 계류중인 ASR 요청들은 더 낮은 우선순위 스코어들과 연관된 계류중인 ASR 요청들 전에 백엔드-측 ASR 모듈에 의해 프로세싱된다. [0009] One aspect of the disclosure provides a method for providing quality of service for voice queries. The method includes receiving, at data processing hardware of a query processing backend, an automated speech recognition (ASR) request from a user device. The ASR request includes speech input captured by the user device and content metadata associated with the speech input. Speech input includes voice queries, and content metadata is generated by the user device. The method also includes determining, by the data processing hardware, a priority score for the ASR request based on content metadata associated with the speech input. The method also includes caching, by the data processing hardware, the ASR request in a pre-processing backlog of pending ASR requests each having a corresponding priority score. Pending ASR requests in the pre-processing backlog are ranked by priority scores. The method includes providing, by data processing hardware, one or more of the pending ASR requests from a pre-processing backlog to a backend-side ASR module, based on the processing availability of the backend-side ASR module. Includes more. Pending ASR requests associated with higher priority scores are processed by the backend-side ASR module before pending ASR requests associated with lower priority scores.
[0010] 본 개시내용의 구현들은 다음의 선택적 특징들 중 하나 이상을 포함할 수 있다. 일부 구현들에서, 백엔드-측 ASR 모듈은, 계류중인 ASR 요청들의 프리-프로세싱 백로그로부터 각각의 계류중인 ASR 요청을 수신하는 것에 대한 응답으로, 계류중인 ASR 요청을 프로세싱하여, 계류중인 ASR 요청과 연관된 대응하는 스피치 입력에 대한 ASR 결과를 생성하도록 구성된다. 일부 예들에서, 방법은, 계류중인 ASR 요청들의 프리-프로세싱 백로그에 하나 이상의 새로운 ASR 요청들을 캐싱하는 것에 대한 응답으로, 데이터 프로세싱 하드웨어에 의해, 우선순위 스코어들의 순위로 프리-프로세싱 백로그 내의 계류중인 ASR 요청들을 재랭킹(re-ranking)하는 단계를 더 포함한다. 부가적으로 또는 대안적으로, 방법은, 데이터 프로세싱 하드웨어에 의해, 타임아웃 임계치를 충족하는 시간 기간 동안 프리-프로세싱 백로그에 상주하는 계류중인 임의의 ASR 요청들이 백엔드-측 ASR 모듈에 의해 프로세싱되는 것을 거절하는 단계를 포함할 수 있다. 일부 구현들에서, 방법은, 우선순위 스코어 임계치 미만의 각각의 우선순위 스코어를 갖는 새로운 ASR 요청을 수신하는 것에 대한 응답으로, 데이터 프로세싱 하드웨어에 의해, 새로운 ASR 요청이 백엔드-측 ASR 모듈에 의해 프로세싱되는 것을 거절하는 단계를 더 포함한다. [0010] Implementations of the present disclosure may include one or more of the following optional features. In some implementations, the backend-side ASR module, in response to receiving each pending ASR request from a pre-processing backlog of pending ASR requests, processes the pending ASR request to determine the and configured to generate an ASR result for a corresponding speech input. In some examples, the method, in response to caching one or more new ASR requests in a pre-processing backlog of pending ASR requests, caches, by data processing hardware, the pending ASR requests in the pre-processing backlog in order of priority scores. It further includes a step of re-ranking ASR requests in progress. Additionally or alternatively, the method may include, by the data processing hardware, any pending ASR requests residing in the pre-processing backlog for a period of time that satisfies a timeout threshold are processed by the backend-side ASR module. It may include the step of rejecting something. In some implementations, the method includes, in response to receiving a new ASR request with a respective priority score less than a priority score threshold, causing the new ASR request to be processed by the backend-side ASR module, by the data processing hardware. It further includes the step of refusing to become.
[0011] 스피치 입력과 연관된 콘텐츠 메타데이터는, 대응하는 ASR이 백엔드-측 ASR 모듈에 의해 성공적으로 프로세싱될 가능성을 나타낼 수 있다. 일부 구현들에서, 스피치 입력과 연관된 콘텐츠 메타데이터는, 대응하는 ASR 요청의 프로세싱이 사용자 디바이스와 연관된 사용자에게 영향을 미치게 될 가능성을 나타낸다. 스피치 입력과 연관되고 사용자 디바이스에 의해 생성되는 콘텐츠 메타데이터는: 사용자 디바이스와 연관된 사용자가 사용자 디바이스에 로그인했는지 여부를 표시하는 로그인 표시자(login indicator); 스피치 입력이 사용자 디바이스와 연관된 스피커 프로파일(speaker profile)과 일치할 가능성을 표시하는, 스피치 입력에 대한 스피커-식별 스코어(speaker-identification score); 스피치 입력이 비-인간 소스로부터의 브로드캐스트된 또는 합성된 스피치 출력에 대응할 가능성을 표시하는, 스피치 입력에 대한 브로드캐스트된-스피치 스코어(broadcasted-speech score); 스피치 입력에서 음성 질의에 선행하는 하나 이상의 용어들이 미리 정의된 핫워드에 대응할 가능성을 표시하는 핫워드 신뢰도 스코어(hotword confidence score); 사용자 디바이스와 질의 프로세싱 백엔드 사이에서 다중-턴-상호작용(multi-turn-interaction)이 진행 중인지 여부를 표시하는 활동 표시자(activity indicator); 스피치 입력의 오디오 신호 스코어; 사용자 디바이스에 대한 사용자의 거리 및 포지션을 표시하는 공간적-국부화 스코어(spatial-localization score); 사용자 디바이스에 상주하는 온-디바이스(on-device) ASR 모듈에 의해 생성되는, 스피치 입력의 전사(transcription); 사용자 디바이스의 현재 거동을 표시하는 사용자 디바이스 거동 신호(user device behavior signal); 또는 사용자 디바이스에 대한 현재 환경 조건들을 표시하는 환경 조건 신호 중 적어도 하나를 포함할 수 있다. [0011] Content metadata associated with a speech input may indicate the likelihood that the corresponding ASR will be successfully processed by a backend-side ASR module. In some implementations, content metadata associated with a speech input indicates the likelihood that processing of a corresponding ASR request will affect a user associated with the user device. Content metadata associated with speech input and generated by the user device may include: a login indicator indicating whether the user associated with the user device is logged in to the user device; a speaker-identification score for the speech input, indicating the likelihood that the speech input matches a speaker profile associated with the user device; a broadcasted-speech score for a speech input, which indicates the likelihood that the speech input corresponds to broadcasted or synthesized speech output from a non-human source; a hotword confidence score, which indicates the likelihood that one or more terms preceding the voice query in the speech input correspond to a predefined hotword; an activity indicator indicating whether a multi-turn-interaction is in progress between the user device and the query processing backend; Audio signal score of speech input; a spatial-localization score that indicates the user's distance and position relative to the user device; Transcription of speech input, generated by an on-device ASR module residing on the user device; a user device behavior signal indicating the current behavior of the user device; or at least one of an environmental condition signal indicating current environmental conditions for the user device.
[0012] 일부 구현들에서, 사용자 디바이스는, 발화된 발언(spoken utterance)에서 음성 질의에 선행하는 핫워드를 검출하는 것에 대한 응답으로, 음성 질의를 포함하는 스피치 입력을 캡처하고; 스피치 입력과 연관된 콘텐츠 메타데이터를 생성하고; 그리고 대응하는 ASR 요청을 데이터 프로세싱 하드웨어로 송신하도록 구성된다. 스피치 입력은 핫워드를 더 포함할 수 있다. 일부 예들에서, 방법은, 데이터 프로세싱 하드웨어로부터, 온-디바이스 프로세싱 명령(on-device processing instruction)들을 사용자 디바이스로 송신하는 단계를 더 포함한다. 온-디바이스 프로세싱 명령들은, 질의 프로세싱 백엔드가 오버로드되었다고 사용자 디바이스가 결정할 때, 온-디바이스로, 사용자 디바이스에 의해 캡처된 임의의 새로운 스피치 입력들의 적어도 일부를 국부적으로 프로세싱하기 위한 하나 이상의 기준들을 제공한다. 이러한 예에서, 사용자 디바이스는: 사용자 디바이스에 의해 데이터 프로세싱 하드웨어로 통신된 이전 ASR 요청들과 연관된 이력 데이터를 획득하거나; 데이터 프로세싱 하드웨어로부터, 질의 프로세싱 백엔드에서의 과거 및/또는 예측된 오버로드 조건들의 스케줄을 수신하거나; 또는 프로세싱 백엔드에서의 현재 오버로드 조건을 표시하는 오버로드 조건 상태 통지를 데이터 프로세싱 하드웨어로부터 즉시(on the fly) 수신하는 것 중 적어도 하나에 의해, 질의 프로세싱 백엔드가 오버로드되었다고 결정하도록 구성될 수 있다. 더욱이, 임의의 새로운 스피치 입력들의 적어도 일부를 국부적으로 프로세싱하기 위한 하나 이상의 기준들은, 사용자 디바이스에게: 디바이스 상에 상주하는 로컬 ASR 모듈을 사용하여 새로운 스피치 입력을 전사하는 것; 새로운 스피치 입력에 대응하는 음성 질의를 결정하기 위해 새로운 스피치 입력의 전사를 해석하는 것; 사용자 디바이스가 새로운 스피치 입력에 대응하는 음성 질의와 연관된 액션을 실행할 수 있는지 여부를 결정하는 것; 또는 사용자 디바이스가 음성 질의와 연관된 액션을 실행할 수 없을 때, 스피치 입력의 전사를 질의 프로세싱 시스템에 송신하는 것 중 적어도 하나를 하도록 지시하는 것을 포함할 수 있다. 일부 구현들에서, 하나 이상의 기준들을 제공하는 온-디바이스 프로세싱 명령들은, 사용자 디바이스가 ASR 요청을 질의 프로세싱 백엔드로 송신하기 위해 콘텐츠 메타데이터의 대응하는 부분들이 충족시켜야 하는 하나 이상의 임계치들을 포함한다. 일부 예들에서, 온-디바이스 프로세싱 명령들은 추가로, 임계치들 중 적어도 하나가 충족되지 않을 때 ASR 요청을 드롭시키도록 사용자 디바이스에게 지시한다. [0012] In some implementations, the user device captures speech input including a spoken query in response to detecting a hotword that precedes the spoken query in a spoken utterance; generate content metadata associated with the speech input; and configured to transmit a corresponding ASR request to the data processing hardware. Speech input may further include hotwords. In some examples, the method further includes transmitting on-device processing instructions from the data processing hardware to the user device. The on-device processing instructions provide one or more criteria for locally processing, on-device, at least a portion of any new speech inputs captured by the user device when the user device determines that the query processing backend is overloaded. do. In this example, the user device: obtains historical data associated with previous ASR requests communicated by the user device to data processing hardware; Receive, from data processing hardware, a schedule of historical and/or predicted overload conditions in the query processing backend; or receiving on the fly an overload condition status notification from the data processing hardware indicating a current overload condition in the processing backend. . Moreover, one or more criteria for locally processing at least a portion of any new speech inputs may include: directing the user device to: transcribe the new speech input using a local ASR module residing on the device; interpreting a transcription of new speech input to determine a speech query corresponding to the new speech input; determining whether the user device is capable of executing an action associated with a voice query corresponding to the new speech input; or when the user device is unable to perform an action associated with the voice query, transmitting a transcription of the speech input to the query processing system. In some implementations, the on-device processing instructions providing one or more criteria include one or more thresholds that corresponding portions of content metadata must meet for the user device to transmit an ASR request to the query processing backend. In some examples, the on-device processing instructions further direct the user device to drop the ASR request when at least one of the thresholds is not met.
[0013] 본 개시내용의 다른 양상은 음성 질의들에 대한 서비스 품질을 제공하기 위한 시스템을 제공한다. 시스템은 질의 프로세싱 백엔드의 데이터 프로세싱 하드웨어 및 데이터 프로세싱 하드웨어와 통신하는 메모리 하드웨어를 포함한다. 메모리 하드웨어는, 데이터 프로세싱 하드웨어 상에서 실행될 때 데이터 프로세싱 하드웨어로 하여금 동작들을 수행하게 하는 명령들을 저장한다. 동작들은 사용자 디바이스로부터 ASR(automated speech recognition) 요청을 수신하는 동작을 포함한다. ASR 요청은 사용자 디바이스에 의해 캡처된 스피치 입력 및 스피치 입력과 연관된 콘텐츠 메타데이터를 포함한다. 스피치 입력은 음성 질의를 포함하고, 콘텐츠 메타데이터는 사용자 디바이스에 의해 생성된다. 동작들은 또한, 스피치 입력과 연관된 콘텐츠 메타데이터에 기반하여 ASR 요청에 대한 우선순위 스코어를 결정하는 동작, 및 대응하는 우선순위 스코어를 각각 갖는 계류중인 ASR 요청들의 프리-프로세싱 백로그에 ASR 요청을 캐싱하는 동작을 포함한다. 프리-프로세싱 백로그 내의 계류중인 ASR 요청들은 우선순위 스코어들의 순위로 랭킹된다. 동작들은, 백엔드-측 ASR 모듈의 프로세싱 가용성에 기반하여, 프리-프로세싱 백로그로부터, 계류중인 ASR 요청들 중 하나 이상의 계류중인 ASR 요청들을 백엔드-측 ASR 모듈에 제공하는 동작을 더 포함한다. 더 높은 우선순위 스코어들과 연관된 계류중인 ASR 요청들은 더 낮은 우선순위 스코어들과 연관된 계류중인 ASR 요청들 전에 백엔드-측 ASR 모듈에 의해 프로세싱된다. [0013] Another aspect of the disclosure provides a system for providing quality of service for voice queries. The system includes data processing hardware of a query processing backend and memory hardware that communicates with the data processing hardware. Memory hardware stores instructions that, when executed on the data processing hardware, cause the data processing hardware to perform operations. The operations include receiving an automated speech recognition (ASR) request from a user device. The ASR request includes speech input captured by the user device and content metadata associated with the speech input. Speech input includes voice queries, and content metadata is generated by the user device. The operations also include determining a priority score for the ASR request based on content metadata associated with the speech input, and caching the ASR request in a pre-processing backlog of pending ASR requests each having a corresponding priority score. Includes actions. Pending ASR requests in the pre-processing backlog are ranked by priority scores. The operations further include providing one or more of the pending ASR requests from the pre-processing backlog to the backend-side ASR module, based on processing availability of the backend-side ASR module. Pending ASR requests associated with higher priority scores are processed by the backend-side ASR module before pending ASR requests associated with lower priority scores.
[0014] 이 양상은 다음의 선택적 특징들 중 하나 이상을 포함할 수 있다. 일부 구현들에서, 백엔드-측 ASR 모듈은, 계류중인 ASR 요청들의 프리-프로세싱 백로그로부터 각각의 계류중인 ASR 요청을 수신하는 것에 대한 응답으로, 계류중인 ASR 요청을 프로세싱하여, 계류중인 ASR 요청과 연관된 대응하는 스피치 입력에 대한 ASR 결과를 생성하도록 구성된다. 일부 예들에서, 동작들은, 계류중인 ASR 요청들의 프리-프로세싱 백로그에 하나 이상의 새로운 ASR 요청들을 캐싱하는 것에 대한 응답으로, 우선순위 스코어들의 순위로 프리-프로세싱 백로그 내의 계류중인 ASR 요청들을 재랭킹하는 동작을 더 포함한다. 부가적으로 또는 대안적으로, 동작들은, 타임아웃 임계치를 충족하는 시간 기간 동안 프리-프로세싱 백로그에 상주하는 계류중인 임의의 ASR 요청들이 백엔드-측 ASR 모듈에 의해 프로세싱되는 것을 거절하는 동작을 더 포함할 수 있다. 일부 구현들에서, 동작들은, 우선순위 스코어 임계치 미만의 각각의 우선순위 스코어를 갖는 새로운 ASR 요청을 수신하는 것에 대한 응답으로, 새로운 ASR 요청이 백엔드-측 ASR 모듈에 의해 프로세싱되는 것을 거절하는 동작을 더 포함한다. [0014] This aspect may include one or more of the following optional features. In some implementations, the backend-side ASR module, in response to receiving each pending ASR request from a pre-processing backlog of pending ASR requests, processes the pending ASR request to determine the and configured to generate an ASR result for a corresponding speech input. In some examples, the operations include re-ranking pending ASR requests in the pre-processing backlog by ranking priority scores in response to caching one or more new ASR requests in the pre-processing backlog of pending ASR requests. Includes more actions. Additionally or alternatively, the operations further comprise denying any pending ASR requests residing in the pre-processing backlog from being processed by the backend-side ASR module for a period of time that satisfies a timeout threshold. It can be included. In some implementations, the operations include, in response to receiving a new ASR request with a respective priority score less than a priority score threshold, denying the new ASR request from being processed by the backend-side ASR module. Includes more.
[0015] 스피치 입력과 연관된 콘텐츠 메타데이터는, 대응하는 ASR 요청이 백엔드-측 ASR 모듈에 의해 성공적으로 프로세싱될 가능성을 나타낼 수 있다. 일부 예들에서, 스피치 입력과 연관된 콘텐츠 메타데이터는, 대응하는 ASR 요청의 프로세싱이 사용자 디바이스와 연관된 사용자에게 영향을 미치게 될 가능성을 나타낸다. 스피치 입력과 연관되고 사용자 디바이스에 의해 생성되는 콘텐츠 메타데이터는: 사용자 디바이스와 연관된 사용자가 사용자 디바이스에 로그인했는지 여부를 표시하는 로그인 표시자; 스피치 입력이 사용자 디바이스와 연관된 스피커 프로파일과 일치할 가능성을 표시하는, 스피치 입력에 대한 스피커-식별 스코어; 스피치 입력이 비-인간 소스로부터의 브로드캐스트된 또는 합성된 스피치 출력에 대응할 가능성을 표시하는, 스피치 입력에 대한 브로드캐스트된-스피치 스코어; 스피치 입력에서 음성 질의에 선행하는 하나 이상의 용어들이 미리 정의된 핫워드에 대응할 가능성을 표시하는 핫워드 신뢰도 스코어; 사용자 디바이스와 질의 프로세싱 백엔드 사이에서 다중-턴-상호작용이 진행 중인지 여부를 표시하는 활동 표시자; 스피치 입력의 오디오 신호 스코어; 사용자 디바이스에 대한 사용자의 거리 및 포지션을 표시하는 공간적-국부화 스코어; 사용자 디바이스에 상주하는 온-디바이스 ASR 모듈에 의해 생성되는 스피치 입력의 전사; 사용자 디바이스의 현재 거동을 표시하는 사용자 디바이스 거동 신호; 또는 사용자 디바이스에 대한 현재 환경 조건들을 표시하는 환경 조건 신호 중 적어도 하나를 포함할 수 있다. [0015] Content metadata associated with the speech input may indicate the likelihood that the corresponding ASR request will be successfully processed by the backend-side ASR module. In some examples, content metadata associated with a speech input indicates the likelihood that processing of a corresponding ASR request will affect a user associated with the user device. Content metadata associated with speech input and generated by the user device may include: a login indicator indicating whether the user associated with the user device is logged in to the user device; a speaker-identification score for the speech input, indicating the likelihood that the speech input matches a speaker profile associated with the user device; a broadcasted-speech score for a speech input, indicating the likelihood that the speech input corresponds to broadcasted or synthesized speech output from a non-human source; a hotword confidence score indicating the likelihood that one or more terms preceding the voice query in the speech input correspond to a predefined hotword; an activity indicator indicating whether a multi-turn-interaction is in progress between the user device and the query processing backend; Audio signal score of speech input; a spatial-localization score indicating the user's distance and position relative to the user device; Transcription of speech input generated by an on-device ASR module residing on the user device; a user device behavior signal indicating current behavior of the user device; or at least one of an environmental condition signal indicating current environmental conditions for the user device.
[0016] 일부 구현들에서, 사용자 디바이스는, 발화된 발언에서 음성 질의에 선행하는 핫워드를 검출하는 것에 대한 응답으로, 음성 질의를 포함하는 스피치 입력을 캡처하고; 스피치 입력과 연관된 콘텐츠 메타데이터를 생성하고; 그리고 대응하는 ASR 요청을 데이터 프로세싱 하드웨어로 송신하도록 구성된다. 스피치 입력은 핫워드를 더 포함할 수 있다. 일부 예들에서, 동작들은 온-디바이스 프로세싱 명령들을 사용자 디바이스로 송신하는 동작을 더 포함한다. 온-디바이스 프로세싱 명령들은, 질의 프로세싱 백엔드가 오버로드되었다고 사용자 디바이스가 결정할 때, 온-디바이스로, 사용자 디바이스에 의해 캡처된 임의의 새로운 스피치 입력들의 적어도 일부를 국부적으로 프로세싱하기 위한 하나 이상의 기준들을 제공한다. 이러한 예들에서, 사용자 디바이스는: 사용자 디바이스에 의해 데이터 프로세싱 하드웨어로 통신된 이전 ASR 요청들과 연관된 이력 데이터를 획득하거나; 데이터 프로세싱 하드웨어로부터, 질의 프로세싱 백엔드에서의 과거 및/또는 예측된 오버로드 조건들의 스케줄을 수신하거나; 또는 프로세싱 백엔드에서의 현재 오버로드 조건을 표시하는 오버로드 조건 상태 통지를 데이터 프로세싱 하드웨어로부터 즉시 수신하는 것 중 적어도 하나에 의해, 질의 프로세싱 백엔드가 오버로드되었다고 결정하도록 구성될 수 있다. 추가의 예들에서, 임의의 새로운 스피치 입력들의 적어도 일부를 국부적으로 프로세싱하기 위한 하나 이상의 기준들은, 사용자 디바이스에게: 디바이스 상에 상주하는 로컬 ASR 모듈을 사용하여 새로운 스피치 입력을 전사하는 것; 새로운 스피치 입력에 대응하는 음성 질의를 결정하기 위해 새로운 스피치 입력의 전사를 해석하는 것; 사용자 디바이스가 새로운 스피치 입력에 대응하는 음성 질의와 연관된 액션을 실행할 수 있는지 여부를 결정하는 것; 또는 사용자 디바이스가 음성 질의와 연관된 액션을 실행할 수 없을 때, 스피치 입력의 전사를 질의 프로세싱 시스템에 송신하는 것 중 적어도 하나를 하도록 지시하는 것을 포함한다. 일부 구현들에서, 하나 이상의 기준들을 제공하는 온-디바이스 프로세싱 명령들은, 사용자 디바이스가 ASR 요청을 질의 프로세싱 백엔드로 송신하기 위해 콘텐츠 메타데이터의 대응하는 부분들이 충족시켜야 하는 하나 이상의 임계치들을 포함한다. 일부 예들에서, 온-디바이스 프로세싱 명령들은 추가로, 임계치들 중 적어도 하나가 충족되지 않을 때 ASR 요청을 드롭시키도록 사용자 디바이스에게 지시한다. [0016] In some implementations, the user device captures speech input including a voice query in response to detecting a hotword that precedes the voice query in the spoken utterance; generate content metadata associated with the speech input; and configured to transmit a corresponding ASR request to the data processing hardware. Speech input may further include hotwords. In some examples, the operations further include transmitting on-device processing commands to the user device. The on-device processing instructions provide one or more criteria for locally processing, on-device, at least a portion of any new speech inputs captured by the user device when the user device determines that the query processing backend is overloaded. do. In these examples, the user device may: obtain historical data associated with previous ASR requests communicated by the user device to data processing hardware; Receive, from data processing hardware, a schedule of historical and/or predicted overload conditions in the query processing backend; or immediately receiving an overload condition status notification from the data processing hardware indicating a current overload condition in the processing backend. In further examples, one or more criteria for locally processing at least a portion of any new speech inputs may include, to the user device: transcribing the new speech input using a local ASR module residing on the device; interpreting a transcription of new speech input to determine a speech query corresponding to the new speech input; determining whether the user device is capable of executing an action associated with a voice query corresponding to the new speech input; or when the user device is unable to perform an action associated with the voice query, transmitting a transcription of the speech input to the query processing system. In some implementations, the on-device processing instructions providing one or more criteria include one or more thresholds that corresponding portions of content metadata must meet for the user device to transmit an ASR request to the query processing backend. In some examples, the on-device processing instructions further direct the user device to drop the ASR request when at least one of the thresholds is not met.
[0017] 본 개시내용의 하나 이상의 구현들의 세부사항들은 첨부된 도면들 및 이하의 설명에서 기술된다. 다른 양상들, 특징들 및 이점들은 설명 및 도면들로부터 및 청구항들로부터 자명할 것이다.[0017] The details of one or more implementations of the present disclosure are set forth in the accompanying drawings and the description below. Other aspects, features and advantages will be apparent from the description and drawings and from the claims.
[0018]
도 1은 사용자 디바이스들로부터 수신되는 계류중인 ASR(automated speech recognition) 요청들에 우선순위를 부여하기 위한 예시적인 시스템을 개략적으로 예시한다.
[0019]
도 2는 사용자 디바이스에 의해 캡처되는 스피치 입력과 연관된 콘텐츠 메타데이터를 생성하는 예시적인 사용자 디바이스를 개략적으로 예시한다.
[0020]
도 3a 내지 도 3c는 계류중인 ASR 요청들을 계속해서 재랭킹(re-rank)하도록 구성된 예시적인 음성 질의 QoS(quality of service) 관리자를 개략적으로 예시한다.
[0021]
도 4는 온-디바이스 프로세싱 명령들을 사용자 디바이스에 제공하는 도 1의 QoS 관리자를 개략적으로 예시한다.
[0022]
도 5는, 질의 프로세싱 스택에서의 프로세싱 가용성에 기반하여, 질의 프로세싱 스택에서 계류중인 ASR 요청들을 프로세싱하는 방법에 대한 동작들의 예시적인 어레인지먼트의 흐름도이다.
[0023]
도 6은 서버-기반 질의 프로세싱 스택이 오버로드될 때 온-디바이스 프로세싱 명령들을 실행하는 방법에 대한 동작들의 예시적인 어레인지먼트의 흐름도이다.
[0024]
도 7은 본원에 설명되는 시스템들 및 방법들을 구현하기 위해 사용될 수 있는 예시적인 컴퓨팅 디바이스의 개략도이다.
[0025]
다양한 도면들에서 유사한 참조 부호들은 유사한 요소들을 표시한다.[0018] Figure 1 schematically illustrates an example system for prioritizing pending automated speech recognition (ASR) requests received from user devices.
[0019] Figure 2 schematically illustrates an example user device that generates content metadata associated with speech input captured by the user device.
[0020] Figures 3A-3C schematically illustrate an example voice query quality of service (QoS) manager configured to continuously re-rank pending ASR requests.
[0021] Figure 4 schematically illustrates the QoS manager of Figure 1 providing on-device processing instructions to a user device.
[0022] Figure 5 is a flow diagram of an example arrangement of operations for a method of processing pending ASR requests in a query processing stack, based on processing availability in the query processing stack.
[0023] Figure 6 is a flow diagram of an example arrangement of operations for a method of executing on-device processing instructions when a server-based query processing stack is overloaded.
[0024] Figure 7 is a schematic diagram of an example computing device that can be used to implement the systems and methods described herein.
[0025] Similar reference numbers in the various drawings indicate similar elements.
[0026] 도 1을 참조하면, 일부 구현들에서, 시스템(100)은, 네트워크(130)를 통해 원격 시스템(140)과 통신할 수 있는 사용자(10, 10a-n)와 각각 연관된 사용자 디바이스들(200, 200a-n)을 포함한다. 일부 사용자들(10)은 하나 초과의 사용자 디바이스(200)와 연관될 수 있고 그리고/또는 일부 사용자 디바이스들(200)은 하나 초과의 사용자(10)(예컨대, 가정의 가족 구성원들)와 연관될 수 있다. 원격 시스템(140)은 확장가능/탄력적 자원들(scalable/elastic resources)(142)을 갖는 분산형 시스템(예컨대, 클라우드 컴퓨팅 환경)일 수 있다. 자원들(142)은 컴퓨팅 자원들(144)(예컨대, 데이터 프로세싱 하드웨어) 및/또는 저장 자원들(146)(예컨대, 메모리 하드웨어)을 포함한다. 일부 구현들에서, 원격 시스템(140)은 음성 질의 QoS(quality of service) 관리자(300) 및 질의 프로세싱 스택(700, 700a)을 포함한다. 질의 프로세싱 스택(700a)은 질의 프로세싱 백엔드, 서버-기반 또는 백엔드-측 질의 프로세싱 스택(700a)으로 지칭될 수 있다. QoS 관리자(300)는 사용자 디바이스(200)로부터, 스피치 입력(104)과 연관된 콘텐츠 메타데이터(110) 및 오디오 데이터(103)를 포함하는 ASR(automatic speech recognition) 요청(102)을 수신하도록 구성된다. 그런 다음, QoS 관리자(300)는 적어도 콘텐츠 메타데이터(110)에 기반하여 우선순위 스코어(311)를 ASR 요청(102)에 할당할 수 있다. 수신된 각각의 ASR 요청(102)에 할당되는 우선순위 스코어(311)를 사용하여 그리고 질의 프로세싱 스택(700)의 프로세싱 가용성에 기반하여, QoS 관리자(300)는 각각의 ASR 요청(102)에 대응하는 랭킹(312)을 할당하고, 가장 높은 순위로부터 가장 낮은 순위까지의 랭킹(312)의 순위로 질의 프로세싱 스택(700)에 ASR 요청들(102)을 제공하는 바, 즉 더 높은 우선순위 스코어들(311)과 연관된 랭킹들(312)을 갖는 ASR 요청들은 더 낮은 우선순위 스코어들(311)과 연관된 랭킹들(312)을 갖는 ASR 요청들(102) 전에 질의 프로세싱 스택(700)에 의해 프로세싱된다.[0026] 1 , in some implementations, system 100 includes user devices 200, each associated with a user 10, 10a-n, that can communicate with a remote system 140 over a network 130. 200a-n). Some users 10 may be associated with more than one user device 200 and/or some user devices 200 may be associated with more than one user 10 (e.g., household family members). You can. Remote system 140 may be a distributed system (e.g., a cloud computing environment) with scalable/elastic resources 142. Resources 142 include computing resources 144 (eg, data processing hardware) and/or storage resources 146 (eg, memory hardware). In some implementations, remote system 140 includes a voice query quality of service (QoS) manager 300 and query processing stacks 700 and 700a. Query processing stack 700a may be referred to as a query processing backend, server-based, or backend-side query processing stack 700a. The QoS manager 300 is configured to receive, from the user device 200, an automatic speech recognition (ASR) request 102 including content metadata 110 and audio data 103 associated with the speech input 104. . QoS manager 300 may then assign a priority score 311 to ASR request 102 based at least on content metadata 110 . Using the priority score 311 assigned to each received ASR request 102 and based on the processing availability of the query processing stack 700, the QoS manager 300 responds to each ASR request 102. assigns a ranking 312 and provides ASR requests 102 to the query processing stack 700 with a ranking 312 from highest to lowest, i.e., higher priority scores. ASR requests with rankings 312 associated with 311 are processed by query processing stack 700 before ASR requests 102 with rankings 312 associated with lower priority scores 311 .
[0027] 사용자 디바이스(200)는 데이터 프로세싱 하드웨어(204) 및 메모리 하드웨어(206)를 포함한다. 사용자 디바이스(200)는, 사용자(10)로부터 스피치 입력(104)을 캡처하여 오디오 데이터(103)(예컨대, 전기 신호들)로 변환하기 위한 오디오 캡처 디바이스(예컨대, 마이크로폰)를 포함할 수 있다. 일부 구현들에서, 데이터 프로세싱 하드웨어(204)는, 원격 시스템(140) 상에서 실행되는 질의 프로세싱 스택(700a) 대신에 또는 그를 대신하여 질의 프로세싱 스택(700, 700b)을 실행하도록 구성된다. 예컨대, 질의 프로세싱 스택(700b)은, 원격 시스템(140) 상에서 실행되는 질의 프로세싱 스택(700a)과 동일한 또는 상이한 컴포넌트들 중 일부, 이를테면, 비제한적으로, 온-디바이스 ASR 모듈(220n)(도 2), 해석기 모듈(interpreter module)(720), 또는 TTS(text-to-speech) 모듈(730) 중 적어도 하나를 포함할 수 있다. 일부 예들에서, 사용자 디바이스(200)는 네트워크 연결을 요구하지 않고 신속하게 저-충실도(low-fidelity) 전사들을 생성하기 위해 온-디바이스 ASR 모듈(220n)(도 2)을 실행하는 반면, 원격 시스템(140)은 온-디바이스 저-충실도 전사들에 비해 더 높은 레이턴시를 희생시키면서 고-충실도(high-fidelity) 전사들을 생성할 수 있는 서버-기반 ASR 모듈(710)을 실행한다. 사용자 디바이스(200)는 네트워크(130)를 통해 원격 시스템(140)과 통신할 수 있는 임의의 컴퓨팅 디바이스일 수 있다. 사용자 디바이스(200)는 데스크탑 컴퓨팅 디바이스들 및 모바일 컴퓨팅 디바이스들, 이를테면, 랩톱들, 스마트 스피커들, 스마트 디스플레이들, 태블릿들, 스마트폰들, 및 웨어러블 컴퓨팅 디바이스들(예컨대, 헤드셋들 및/또는 워치들)을 포함하지만, 이들로 제한되지 않는다. [0027] User device 200 includes data processing hardware 204 and memory hardware 206. User device 200 may include an audio capture device (e.g., a microphone) to capture speech input 104 from user 10 and convert it into audio data 103 (e.g., electrical signals). In some implementations, data processing hardware 204 is configured to execute query processing stacks 700 and 700b instead of or instead of query processing stack 700a executing on remote system 140. For example, query processing stack 700b may include some of the same or different components as query processing stack 700a executing on remote system 140, including, but not limited to, on-device ASR module 220n (FIG. 2 ), an interpreter module 720, or a text-to-speech (TTS) module 730. In some examples, user device 200 executes on-device ASR module 220n (FIG. 2) to quickly generate low-fidelity transcriptions without requiring a network connection, while remote system 140 implements a server-based ASR module 710 that can generate high-fidelity transcriptions at the expense of higher latency compared to on-device low-fidelity transcriptions. User device 200 may be any computing device capable of communicating with remote system 140 over network 130. User device 200 includes desktop computing devices and mobile computing devices, such as laptops, smart speakers, smart displays, tablets, smartphones, and wearable computing devices (e.g., headsets and/or watches). s), but is not limited to these.
[0028] 도시된 예에서, 사용자(10)는 말을 함(speaking)으로써 사용자 디바이스(200)에 스피치 입력(104)을 제공할 수 있고, 사용자 디바이스(200)는 스피치 입력(104)을 캡처하여 오디오 데이터(103)로 변환할 수 있다. 그런 다음, 사용자 디바이스(200)는 스피치 입력(104)과 연관된 콘텐츠 메타데이터(110) 및 오디오 데이터(103)를 포함하는 ASR 요청(102)을, 원격 시스템(140) 상에서 실행되는 QoS 관리자(300a)에 송신할 수 있다. 여기서, QoS 관리자(300)는 적어도 콘텐츠 메타데이터(110)에 기반하여 ASR 요청(102)에 랭킹(312)을 할당하고, 가장 높은 랭킹(312)으로부터 가장 낮은 랭킹(312)의 순위로 ASR 요청(102)을 질의 프로세싱 스택(700)에 전송한다. 사용자 디바이스(200)는 선택적으로, ASR 요청(102), 또는 ASR 요청(102)의 일부 부분을 프로세싱하기 위해, 온-디바이스(on-device)로 질의 프로세싱 스택(700b)을 실행할 수 있다. 예컨대, 네트워크 통신들이 다운(down)되거나 또는 이용 가능하지 않을 때, 사용자 디바이스(200)는 ASR 요청(102)을 프로세싱하기 위해 로컬로 질의 프로세싱 스택(700b)을 실행할 수 있다. 일부 예들에서, ASR 요청(102)이 시간에 민감한 것으로 결정되는 경우, 예컨대, 1분 동안 타이머를 설정하기 위한 ASR 요청(102)의 경우, 사용자 디바이스(200)는 ASR 요청(102)을 프로세싱하기 위해 로컬로 질의 프로세싱 스택(700b)을 실행할 수 있다. 본원에서의 구현들은, 원격 시스템(140) 상에서 실행되는 QoS 관리자(300a)가, 서버-기반 질의 프로세싱 스택(700)이 오버로드되었고 그리고/또는 프로세싱하기 위한 ASR 요청들(102)에 있어서 현재 큰 스파이크를 겪고 있다고 결정/검출하는 시나리오들에서, 사용자 디바이스(200)가 로컬로 질의 프로세싱 스택(700b)을 실행하는 것을 더 포함한다. [0028] In the example shown, user 10 may provide speech input 104 to user device 200 by speaking, and user device 200 may capture speech input 104 to produce audio data. It can be converted to (103). User device 200 then sends an ASR request 102 containing content metadata 110 and audio data 103 associated with speech input 104 to QoS manager 300a executing on remote system 140. ) can be sent to. Here, the QoS manager 300 assigns a ranking 312 to the ASR request 102 based at least on the content metadata 110 and orders the ASR requests in order from the highest ranking 312 to the lowest ranking 312. (102) is transmitted to the query processing stack (700). User device 200 may optionally execute query processing stack 700b on-device to process ASR request 102, or some portion of ASR request 102. For example, when network communications are down or unavailable, user device 200 may execute query processing stack 700b locally to process ASR request 102. In some examples, if the ASR request 102 is determined to be time sensitive, such as an ASR request 102 to set a timer for one minute, the user device 200 may process the ASR request 102. For this purpose, the query processing stack 700b can be executed locally. Implementations herein may determine that a QoS manager 300a running on a remote system 140 determines that the server-based query processing stack 700 is overloaded and/or is currently experiencing a large number of ASR requests 102 for processing. In scenarios where it determines/detects that it is experiencing a spike, it further includes the user device 200 locally executing the query processing stack 700b.
[0029] QoS 관리자(300)에 의해 획득되는 콘텐츠 메타데이터(110)는 스피치 입력(104)과 연관된 스피치 인식 카테고리, 사용자(10)와 연관된 사용자 디바이스(200) 상에서 실행되는 애플리케이션, 스피치 입력(104)이 수신된 시점에서 사용자(10)의 로케이션, 사용자(10)를 식별하는 사용자 식별자, 사용자(10)와 연관된 인구 통계학적 정보, 사용자(10)가 사용자 디바이스(200)에 로그인(sign in)했는지 여부, 사용자(10)가 현재, 시스템(100)과의 다중-턴 상호작용의 일부인지 여부, 사용자 디바이스(200)에 대한 사용자(10)의 거리 및 포지션을 결정하는 공간적-국부화 정보(spatial-localization information), 또는 복수의 소스들(220, 220a-n)(도 2)로부터의 데이터/정보를 활용(leverage)하는 애드 분류기(add classifier)를 사용자 디바이스(200) 상에서 실행시킴으로써 획득되는 광고-가능성(ad-likeliness) 정보 중 적어도 하나를 포함할 수 있다. 구체적으로, 그리고 도 2를 참조하여 아래에서 더 상세히 설명되는 바와 같이, 사용자 디바이스(200)는 각각의 스피치 입력(104)과 연관된 콘텐츠 메타데이터(110)를 생성하고, 그리고 콘텐츠 메타데이터(110) 및 스피치 입력(104)(예컨대, 오디오 데이터(103))을 포함하는 연관된 ASR 요청(102)을, 원격 시스템(140) 상에서 실행되는 QoS 관리자(300a)에 제공하도록 구성된다. [0029] Content metadata 110 obtained by QoS manager 300 includes the speech recognition category associated with speech input 104, the application running on user device 200 associated with user 10, and the speech input 104 received. The location of the user 10 at the time, a user identifier identifying the user 10, demographic information associated with the user 10, whether the user 10 has logged in to the user device 200, Spatial-localization information that determines whether user 10 is currently part of a multi-turn interaction with system 100, distance and position of user 10 relative to user device 200. information), or ad-potential obtained by running an add classifier leveraging data/information from a plurality of sources 220, 220a-n (FIG. 2) on the user device 200. It may contain at least one of (ad-likeliness) information. Specifically, and as described in more detail below with reference to FIG. 2, user device 200 generates content metadata 110 associated with each speech input 104, and and an associated ASR request 102 including speech input 104 (e.g., audio data 103) to QoS manager 300a executing on remote system 140.
[0030] QoS 관리자(300)는 랭커(ranker)(310) 및 프리-프로세싱 백로그(pre-processing backlog)(320)를 포함한다. 랭커(310)는, ASR 요청(102)이 진짜일 가능성을 결정하기 위해, ASR 요청(102)에 포함된 콘텐츠 메타데이터(110)를 분석하고, 그리고 ASR 요청(102)이 진짜일 가능성에 기반하여 ASR 요청(102)에 대응하는 랭킹(312)을 할당하도록 구성된다. 본원에서 사용되는 바와 같이, "진짜(genuine)" ASR 요청(102)은, 실제 사용자(10)에 의해 발화되고 질의 프로세싱 스택(700)에 의한 프로세싱을 위한 음성 질의로서 사용자 디바이스(200)로 향하는 스피치 입력(104)을 포함하는 ASR 요청(102)을 지칭한다. 일부 예들에서, QoS 관리자(300)는, ASR 요청(102)에 포함된 콘텐츠 메타데이터(110)에 기반하여, 각각의 수신된 ASR 요청(102)에 대한 대응하는 우선순위 스코어(311)를 결정한다. 여기서, QoS 관리자(300)는 대응하는 우선순위 스코어(311)에 기반하여 각각의 ASR 요청(102)에 랭킹(312)을 할당할 수 있다. 따라서, 각각의 수신된 ASR 요청(102)에 대한 콘텐츠 메타데이터(110)에 기반하는 우선순위 스코어(311)는 ASR 요청이 진짜일 가능성을 표시할 수 있다. 예컨대, 콘텐츠 메타데이터(110)는, ASR 요청(102)이 사용자들(10, 10a-n) 중 하나 이외의 소스, 이를테면 텔레비전/라디오 광고, 알림(announcement) 또는 다른 프로그래밍 동안 비-인간 소스(예컨대, 텔레비전 또는 라디오)(12)로부터 왔음을 표시할 수 있다. 따라서, ASR 요청(102)이 진짜가 아닐 가능성이 있음을 콘텐츠 메타데이터(110)가 표시하기 때문에, 랭커(310)는 ASR 요청(102)에 대해 낮은 우선순위 스코어(311)를 결정하고, 이에 의해, 랭커(310)로 하여금, ASR 요청(102)이 진짜일 가능성이 낮음에 기반하여 ASR 요청(102)에 낮은 랭킹(312)을 할당하게 한다. 다른 예들에서, 콘텐츠 메타데이터(110)는 ASR 요청(102)이 사용자들(10, 10a-n) 중 하나로부터 왔음을 표시하며, 따라서, 랭커(310)는, ASR 요청(102)이 진짜일 가능성이 높음에 기반하여, ASR 요청(102)에 대해 높은 우선순위 스코어(311)를 결정하고 그리고 ASR 요청(102)에 높은 랭킹(312)을 할당한다. 부가적으로 또는 대안적으로, 랭커(310)는 ASR 요청(102)이 진짜일 가능성을 결정하기 위해, 콘텐츠 메타데이터(110)에 부가하여 또는 그 대신에, 오디오 데이터(103) 및/또는 임의의 다른 적절한 정보를 분석할 수 있다. [0030] The QoS manager 300 includes a ranker 310 and a pre-processing backlog 320. Ranker 310 analyzes content metadata 110 included in ASR request 102 to determine the likelihood that ASR request 102 is genuine, and determines the likelihood that ASR request 102 is genuine. It is configured to assign a ranking (312) corresponding to the ASR request (102). As used herein, a “genuine” ASR request 102 is a voice query uttered by a real user 10 and directed to user device 200 for processing by query processing stack 700. Refers to an ASR request (102) containing a speech input (104). In some examples, QoS manager 300 determines a corresponding priority score 311 for each received ASR request 102 based on content metadata 110 included in the ASR request 102. do. Here, the QoS manager 300 may assign a ranking 312 to each ASR request 102 based on the corresponding priority score 311. Accordingly, a priority score 311 based on content metadata 110 for each received ASR request 102 may indicate the likelihood that the ASR request is genuine. For example, content metadata 110 may indicate that ASR request 102 is from a source other than one of users 10, 10a-n, such as a non-human source (during a television/radio advertisement, announcement, or other programming). For example, it can indicate that it came from a television or radio) (12). Accordingly, because the content metadata 110 indicates that the ASR request 102 is likely not genuine, the ranker 310 determines a low priority score 311 for the ASR request 102, and thus causes the ranker 310 to assign a low rank 312 to the ASR request 102 based on the low likelihood that the ASR request 102 is genuine. In other examples, content metadata 110 indicates that ASR request 102 came from one of users 10, 10a-n, and thus ranker 310 determines whether ASR request 102 is genuine. Based on the likelihood, a high priority score 311 is determined for the ASR request 102 and a high rank 312 is assigned to the ASR request 102. Additionally or alternatively, ranker 310 may use audio data 103 and/or random data, in addition to or instead of content metadata 110, to determine the likelihood that ASR request 102 is genuine. Other pertinent information can be analyzed.
[0031] 각각의 ASR 요청(102)에 대해 우선순위 스코어(311)를 결정하고 랭킹(312)을 할당한 후, 랭커(310)는 대응하는 우선순위 스코어(311)(랭커(310)에 의해 이전에 결정됨)를 각각 갖는 계류중인 ASR 요청들(102)의 프리-프로세싱 백로그(320)에 ASR 요청(102)을 캐싱한다. 여기서, 프리-프로세싱 백로그(320) 내의 계류중인 ASR 요청들(102)은, 질의 프로세싱 스택(700)이 더 낮은 랭킹들(312)과 연관된 계류중인 ASR 요청들(102)을 프로세싱하기 전에 더 높은 랭킹들(312)과 연관된 계류중인 ASR 요청들(102)을 프로세싱하도록, 우선순위 스코어들(311)의 순위로 랭킹된다. [0031] After determining a priority score 311 and assigning a ranking 312 to each ASR request 102, the ranker 310 determines the corresponding priority score 311 (previously determined by the ranker 310). ) and cache the ASR request 102 in the pre-processing backlog 320 of pending ASR requests 102 each having . Here, pending ASR requests 102 in the pre-processing backlog 320 are processed further before the query processing stack 700 processes pending ASR requests 102 associated with lower rankings 312. Ranked in order of priority scores 311, to process pending ASR requests 102 associated with high rankings 312.
[0032] 새로운 ASR 요청(102)이 QoS 관리자(300)에 의해 네트워크(130)를 통해 수신됨에 따라, 랭커(310)는 연속적으로 또는 반-연속적으로, 프리-프로세싱 백로그(320) 내의 계류중인 ASR 요청들(102)의 리스트(322)를 수신하고, 계류중인 ASR 요청들(102)을 재랭킹한다. 예컨대, 랭커(310)는, 새로운 ASR 요청(102)이 질의 프로세싱 스택(700)에 의해 프로세싱되기를 대기하면서 프리-프로세싱 백로그(320) 내에 현재 캐싱되어 있는 계류중인 ASR 요청들(102)의 리스트(322) 내의 임의의 우선순위 스코어(311)보다 높은 대응하는 우선순위 스코어(311)를 갖는다고 결정할 수 있다. 백로그(320)는 계류중인 ASR 요청들(102)의 리스트(322)를 랭커(310)에 피드백으로서 제공할 수 있고, 랭커(310)는 계류중인 ASR 요청들(102)의 리스트(322) 내의 랭킹들(312)보다 더 높은 랭킹(312)을 새로운 ASR 요청(102)에 할당할 수 있으며, 그에 따라, 새로운 ASR 요청(102)은 질의 프로세싱 스택(700)에 의한 프로세싱을 위한 백로그(320) 내의 다른 계류중인 ASR 요청들(102)보다 우선한다. 일부 구현들에서, 랭커(310)는 리스트(322) 내의 계류중인 ASR 요청들(102) 중 적어도 하나를 드롭시킨다. 예컨대, 랭커(310)는 백로그(320) 내의 계류중인 ASR 요청들(102)의 양이 미리 결정된 임계 값을 초과한다고 결정할 수 있다. 더 높은 랭킹들(312)을 갖는 새로운 ASR 요청들(102)에 대한 백로그(320) 내의 공간을 클리어하고 그리고/또는 대역폭을 증가시키기 위해, 랭커(310)는 더 낮은 랭킹(312)과 연관된 계류중인 ASR 요청들(102) 중 적어도 하나를 드롭시킬 수 있다. 부가적으로 또는 대안적으로, 랭커(310)는 타임아웃된, 즉 미리 결정된 임계 값을 초과하는 시간 지속기간 동안 백로그(320)에서 계류되었던, 계류중인 ASR 요청들(102)의 리스트(322) 내의 계류중인 ASR 요청들(102) 중 적어도 하나를 드롭시킬 수 있다. [0032] As new ASR requests 102 are received by QoS manager 300 over network 130, ranker 310 continuously or semi-continuously processes pending ASR requests in pre-processing backlog 320. Receive a list 322 of files 102 and re-rank the pending ASR requests 102. For example, ranker 310 may maintain a list of pending ASR requests 102 that are currently cached in pre-processing backlog 320, waiting for new ASR requests 102 to be processed by query processing stack 700. It may be determined that the corresponding priority score 311 is higher than any priority score 311 in 322. Backlog 320 may provide a list 322 of pending ASR requests 102 as feedback to ranker 310, and ranker 310 may provide a list 322 of pending ASR requests 102. A higher rank 312 may be assigned to the new ASR request 102 than the ranks 312 in It takes precedence over other pending ASR requests (102) in 320). In some implementations, ranker 310 drops at least one of the pending ASR requests 102 in list 322. For example, ranker 310 may determine that the amount of pending ASR requests 102 in backlog 320 exceeds a predetermined threshold. To clear space in the backlog 320 and/or increase bandwidth for new ASR requests 102 with higher rankings 312, ranker 310 may At least one of the pending ASR requests 102 may be dropped. Additionally or alternatively, ranker 310 may generate a list 322 of pending ASR requests 102 that have timed out, i.e., have been pending in backlog 320 for a time duration exceeding a predetermined threshold. ) can drop at least one of the pending ASR requests 102 in ).
[0033] 프리-프로세싱 백로그(320) 내의 각각의 계류중인 ASR 요청(102)은, 계류중인 ASR 요청들(102)에 할당된 랭킹들(312)에 기반하여, 질의 프로세싱 스택(700)에 의해 프로세싱되기를 대기하고 있다. 예컨대, 가장 높게 랭킹된 ASR 요청(102)(예컨대, 가장 높은 우선순위 스코어(311)와 연관된 ASR 요청(102))은 두 번째로 가장 높게 랭킹된 ASR 요청(102)(예컨대, 다음으로 가장 높은 우선순위 스코어(311)와 연관된 ASR 요청(102)) 전에 프로세싱되고, 두 번째로 가장 높게 랭킹된 ASR 요청(102)은 세 번째로 가장 높게 랭킹된 ASR 요청(102) 전에 프로세싱되는 식이다. 백로그(320)는, 계류중인 ASR 요청들(102)의 재랭킹을 가능하게 하기 위해, 리스트(322)를 랭커(310)에 연속적으로 또는 반-연속적으로 통신한다. [0033] Each pending ASR request 102 in the pre-processing backlog 320 may be processed by the query processing stack 700 based on the ranks 312 assigned to the pending ASR requests 102. Waiting. For example, the highest ranked ASR request 102 (e.g., the ASR request 102 associated with the highest priority score 311) is the second highest ranked ASR request 102 (e.g., the next highest The ASR request 102 associated with the priority score 311 is processed before the second highest ranked ASR request 102 is processed before the third highest ranked ASR request 102, and so on. Backlog 320 continuously or semi-continuously communicates list 322 to ranker 310 to enable re-ranking of pending ASR requests 102.
[0034] 원격 시스템(140) 상의 질의 프로세싱 스택(700, 700a)은, 스피치 입력(104)과 연관된 콘텐츠 메타데이터(110) 및 오디오 데이터(103)를 포함하는, 드롭되거나 타임아웃되지 않은 각각의 ASR 요청(102)을 QoS 관리자(300)로부터 랭킹(312)의 내림차순으로 수신한다. 질의 프로세싱 스택(700)은 적어도 ASR 모듈(710), 해석기 모듈(720), 또는 TTS 모듈(730)을 포함한다. ASR 모듈(710)은 ASR 요청(102)에 대해 다양한 동작들, 예컨대, 프로세싱, 노이즈 모델링, 음향 모델링, 언어 모델, 주석 등을 수행하여, 스피치 입력(104)에 대한 스피치 인식 결과(예컨대, 전사)를 생성할 수 있다. ASR 모듈(710)은, ASR 요청(102)의 의도를 결정하고 응답을 생성하기 위해, 이러한 스피치 인식 결과를 해석기(720)에 전송한다. 예컨대, 현재 시간을 요청하는 ASR 요청(102)은, 질의 프로세싱 스택(700)이 사용자(10)의 시간대에서 현재 시간을 결정하고 응답을 생성함으로써 충족될 것이다. TTS 모듈(730)은 이러한 응답을 텍스트에서 스피치로 변환하고 사용자 디바이스(200)에 오디오 형태의 응답을 출력할 수 있으며, 그런 다음 이는, 예컨대 사용자 디바이스(200)의 스피커들을 통해, 합성된 스피치로서 사용자(10)에게 출력된다. 부가적으로 또는 대안적으로, 응답은 텍스트 형태로 사용자 디바이스(200)에 출력될 수 있으며, 그런 다음 이는, 예컨대 사용자 디바이스(200)의 스크린을 통해 사용자(10)에게 송신된다. 다른 구현들에서, 사용자 디바이스(200)는 질의 프로세싱 스택(700a)으로부터 텍스트 또는 다른 데이터의 형태로 응답을 수신하고, 온-디바이스 TTS 모듈을 사용하여 응답을 스피치로 변환할 수 있다. [0034] The query processing stack 700, 700a on the remote system 140 processes each ASR request that is not dropped or times out, including content metadata 110 and audio data 103 associated with the speech input 104. 102) is received from the QoS manager 300 in descending order of ranking 312. Query processing stack 700 includes at least an ASR module 710, interpreter module 720, or TTS module 730. The ASR module 710 performs various operations, such as processing, noise modeling, acoustic modeling, language model, annotation, etc., on the ASR request 102 to produce speech recognition results (e.g., transcription) for the speech input 104. ) can be created. ASR module 710 sends these speech recognition results to interpreter 720 to determine the intent of ASR request 102 and generate a response. For example, an ASR request 102 requesting the current time would be satisfied by query processing stack 700 determining the current time in the user's 10 time zone and generating a response. TTS module 730 may convert this response from text to speech and output the response in audio form to user device 200, which may then be used as synthesized speech, such as through speakers of user device 200. It is output to the user (10). Additionally or alternatively, the response may be output to user device 200 in text form, which is then transmitted to user 10, such as via a screen of user device 200. In other implementations, user device 200 may receive a response in the form of text or other data from query processing stack 700a and convert the response into speech using an on-device TTS module.
[0035] 도 2는, 스피치 입력(104)을 캡처하고, 복수의 소스들(220, 220a-n) 중 하나 이상으로부터 정보/데이터를 수집하고, QoS 관리자(300)에 전송되는 ASR 요청(102)에 포함시키기 위해 스피치 입력(104)과 연관된 콘텐츠 메타데이터(110)를 생성하는 예시적인 사용자 디바이스(200)를 도시한다. 사용자 디바이스(200)는 스크린(212)을 포함하고, 스크린(212) 상에 디스플레이하기 위해 그래픽 사용자 인터페이스(214)를 실행시킨다. 도 2에 도시된 바와 같이, 스피치 입력(104)은, 사용자 디바이스(200), 예컨대, 사용자 디바이스(200) 상에서 실행되는 캘린더 애플리케이션(200e)에 특정 날짜(12월 8일)에 대한 이벤트(Skip Fikany's birthday)를 부가하기 위해, 캘린더 애플리케이션(220e)으로 향하는 핫워드("Hey Google") 및 후속 음성 질의에 대응한다. 일부 구현들에서, 사용자 디바이스(200)는 그래픽 사용자 인터페이스(214)에 디스플레이되는 음성 검색/커맨드 윈도우(216)에 스피치 입력(104)의 전사를 제시한다. [0035] 2 captures speech input 104 and collects information/data from one or more of a plurality of sources 220, 220a-n and includes it in an ASR request 102 that is sent to QoS manager 300. An example user device 200 is shown that generates content metadata 110 associated with speech input 104 to do so. User device 200 includes a screen 212 and executes a graphical user interface 214 for display on screen 212 . As shown in Figure 2, the speech input 104 is an event (Skip) for a specific date (December 8) in the user device 200, for example, a calendar application 200e running on the user device 200. To add Fikany's birthday, a hotword (“Hey Google”) directed to calendar application 220e and a subsequent voice query are responded to. In some implementations, user device 200 presents a transcription of speech input 104 in a voice search/command window 216 that is displayed in graphical user interface 214.
[0036] 사용자 디바이스(200)가 스피치 입력(104)을 수신한 후, 사용자 디바이스(200)는 복수의 소스들(220)로부터의, 스피치 입력(104)과 연관된 정보/데이터를 활용하며, 그리고 원격 시스템(140) 상에서 실행되는 질의 프로세싱 스택(700) 또는 QoS 관리자(300)가 ASR 요청(102)의 프로세싱을 시작할 것을 요구하지 않으면서, QoS 관리자(300)에 의해 사용하기 위한 스피치 입력(104)에 대한 콘텍스트 또는 힌트들을 제공하는 데 사용될 수 있는 콘텐츠 메타데이터(110)를 생성하기 위해 (데이터 프로세싱 하드웨어(204) 상의) 신호 생성기(218)를 실행시킨다. 스피치 입력(104)과 연관되고 신호 생성기(218)에 의해 생성되는 콘텐츠 메타데이터(110)는, 사용자 디바이스(200)와 연관된 사용자(10)가 사용자 디바이스(200)에 로그인했는지 여부를 표시하는 로그인 표시자; 스피치 입력이 사용자 디바이스(200)와 연관된 스피커 프로파일과 일치할 가능성을 표시하는, 스피치 입력(104)에 대한 스피커-식별 스코어; 스피치 입력(104)이 비-인간 소스(예컨대, 텔레비전)로부터의 브로드캐스트된 또는 합성된 스피치 출력에 대응할 가능성을 표시하는, 스피치 입력(104)에 대한 브로드캐스트된-스피치 스코어; 스피치 입력(104)에서 검출되는, 음성 질의에 선행하는 하나 이상의 용어들이 핫워드에 대응할 가능성을 표시하는 핫워드 신뢰도 스코어; 사용자 디바이스(200)와 질의 프로세싱 스택(700)(즉, 질의 프로세싱 백엔드) 사이에서 다중-턴-상호작용이 진행 중인지 여부를 표시하는 활동 표시자; 스피치 입력(104)의 오디오 신호 품질 메트릭(audio signal quality metric); 사용자 디바이스(200)에 대한 사용자(10)의 거리 및 포지션을 표시하는 공간적-국부화 스코어; 온-디바이스 ASR 모듈(220n)에 의해 생성되는, 스피치 입력(104)의 전사(transcript)(예컨대, 저-충실도 전사); 사용자 디바이스(200)의 현재 거동을 표시하는 사용자 디바이스 거동 신호; 또는 사용자 디바이스(200)에 대한 현재 환경 조건들을 표시하는 환경 조건 신호 중 적어도 하나를 포함한다. 복수의 소스들(200)은, 스피커 분류기(speaker classifier)(220, 220a), 브로드캐스트 오디오 분류기(220, 200b), 핫워드 검출기(220, 220c), 세션 활동 로그(session activity log)(220, 220d), 사용자 디바이스(200) 상에서 실행되는 하나 이상의 애플리케이션들(220, 220e), 오디오 품질 스코어러(audio quality scorer)(220, 220f), 사용자 디바이스(200)의 하나 이상의 센서들(220, 220g), 및 온-디바이스 ASR(220, 220n) 중 적어도 하나를 포함하지만, 이들로 제한되지 않는다. 명백해질 바와 같이, 신호 생성기(218)는 스피치 입력(104)과 연관된 콘텐츠 메타데이터(110)를 생성하기 위해, 소스들(220) 중 임의의 소스뿐만 아니라 임의의 다른 적절한 소스들로부터의 데이터/정보를 활용하도록 구성된다. 더욱이, 2개 이상의 소스들(220)로부터 획득된 데이터/정보는 더 중첩되어, 신호 생성기(218)가 보다 강력한 콘텐츠 메타데이터(110)를 생성할 수 있게 한다. [0036] After user device 200 receives speech input 104, user device 200 utilizes information/data associated with speech input 104 from a plurality of sources 220 and remote system ( 140) to the speech input 104 for use by the QoS manager 300, without requiring the query processing stack 700 or the QoS manager 300 to begin processing the ASR request 102. Runs a signal generator 218 (on data processing hardware 204) to generate content metadata 110 that can be used to provide context or hints. Content metadata 110 associated with speech input 104 and generated by signal generator 218 may indicate whether the user 10 associated with user device 200 is logged in to user device 200. indicator; a speaker-identification score for speech input 104, indicating the likelihood that the speech input matches a speaker profile associated with user device 200; a broadcasted-speech score for speech input 104, indicating the likelihood that speech input 104 corresponds to broadcasted or synthesized speech output from a non-human source (e.g., television); a hotword confidence score indicating the likelihood that one or more terms preceding the spoken query, detected in speech input 104, correspond to the hotword; an activity indicator indicating whether a multi-turn-interaction is in progress between user device 200 and query processing stack 700 (i.e., query processing backend); audio signal quality metric of speech input 104; a spatial-localization score indicating the distance and position of user 10 relative to user device 200; a transcript (e.g., low-fidelity transcription) of speech input 104, generated by on-device ASR module 220n; a user device behavior signal indicating the current behavior of the user device 200; or an environmental condition signal indicating current environmental conditions for the user device 200. A plurality of sources 200 include a speaker classifier (220, 220a), a broadcast audio classifier (220, 200b), a hotword detector (220, 220c), and a session activity log (220). , 220d), one or more applications 220, 220e running on the user device 200, an audio quality scorer 220, 220f, one or more sensors 220, 220g of the user device 200. ), and at least one of the on-device ASRs 220 and 220n. As will become clear, signal generator 218 may use data from any of sources 220 as well as any other suitable sources to generate content metadata 110 associated with speech input 104. It is designed to utilize information. Moreover, data/information obtained from two or more sources 220 may overlap more, allowing signal generator 218 to generate more robust content metadata 110.
[0037] 스피커 분류기(220a)는 스피치 입력(104)의 오디오 데이터(103)(예컨대, 발음, 타이밍 등과 관련된 음향 피처들)를 사용자 디바이스(200)의 하나 이상의 사용자들(10)과 연관된 스피커 프로파일에 대한 음향 피처들과 비교할 수 있다. 예컨대, 스피커 프로파일은, 스마트 스피커와 같은 사용자 디바이스(200)를 사용하도록 권한이 부여된, 가정의 하나 이상의 사용자들(10)에 의해 스피커 등록 프로세스(speaker enrollment process) 동안 학습 및/또는 생성될 수 있다. 스피치 입력(104)의 오디오 데이터(103)가 사용자 디바이스(200)와 연관된 하나 이상의 사용자들(10)에 대한 스피커 프로파일의 음향 피처들과 일치하는 경우, 스피커 분류기(220a)는 스피치 입력(104)이 사용자 디바이스(200)와 연관된 사용자(10)에 의해 발화되었을 가능성이 있음을 표시하는 높은 스피커-식별 스코어를 출력할 수 있다. 이 경우, 신호 생성기(218)는 대응하는 ASR 요청(102)이 진짜일 가능성이 높음을 표시하는 콘텐츠 메타데이터(110)를 제공하기 위해, 높은 스피커-식별 스코어를 사용할 수 있다. 다른 한편으로, 스피커 분류기(220a)는, 스피치 입력(104)의 오디오 데이터(103)가 사용자 디바이스(200)와 연관된 사용자(10)에 대한 스피커 프로파일의 음향 피처들과 일치하지 않을 경우, 낮은 스피커-식별 스코어를 제공할 수 있다. 따라서, 스피커-식별 스코어는, 오디오 데이터(103)가 알려진 스피커 프로파일과 일치하는 확률 또는 신뢰도 값에 대응할 수 있다. [0037] Speaker classifier 220a may classify audio data 103 (e.g., acoustic features related to pronunciation, timing, etc.) of speech input 104 into acoustic profiles associated with one or more users 10 of user device 200. You can compare features. For example, a speaker profile may be learned and/or created during a speaker enrollment process by one or more users 10 in the home who are authorized to use a user device 200, such as a smart speaker. there is. If the audio data 103 of speech input 104 matches the acoustic features of a speaker profile for one or more users 10 associated with user device 200, speaker classifier 220a determines the speech input 104. This may output a high speaker-identification score indicating that the utterance was likely made by the user 10 associated with the user device 200. In this case, signal generator 218 may use a high speaker-identification score to provide content metadata 110 that indicates that the corresponding ASR request 102 is likely genuine. On the other hand, speaker classifier 220a determines if the audio data 103 of speech input 104 does not match the acoustic features of the speaker profile for user 10 associated with user device 200, then speaker classifier 220a -An identification score can be provided. Accordingly, the speaker-identification score may correspond to a probability or confidence value that the audio data 103 matches a known speaker profile.
[0038] 브로드캐스트 오디오 분류기(220b)는, 스피치 입력(104)이 비-인간 소스(12), 예컨대, 텔레비전, 라디오, 컴퓨터, 또는 브로드캐스트된 그리고/또는 합성된 스피치를 출력할 수 있는 임의의 다른 오디오 출력 디바이스로부터의 브로드캐스트된 또는 합성된 스피치 출력에 대응할 가능성을 표시하는, 스피치 입력에 대한 브로드캐스트된-스피치 스코어를 제공하기 위해, 스피치 입력(104)의 오디오 데이터(103)를 분석할 수 있다. 본원에서 사용되는 바와 같이, 브로드캐스트된 스피치는, 인간(예컨대, 뉴스캐스터, 배우, 라디오 인물(radio personality) 등)에 의해 발화되지만, 광고, 라디오 프로그램, 텔레비전 쇼 및/또는 영화와 같은 미디어 이벤트 동안 비-인간 소스(12)로부터 나오는/방송되는 오디오 콘텐츠에 대응하는 스피치를 지칭한다. 다른 한편으로, 합성된 스피치는, 예컨대 TTS(text-to-speech) 시스템에 의해 생성되는 비-인간 스피치를 지칭한다. 브로드캐스트 오디오 분류기(220b)는, 비-인간 소스(12)로부터 나오는/브로드캐스트되는 오디오 콘텐츠에 첨부될 수 있으며 그리고/또는 합성된 스피치이거나 또는 미디어 이벤트 동안 브로드캐스트되는 비-인간 소스(12)로부터의 스피치 출력과 사용자 디바이스(200)에 근접한 실제 인간들의 스피치 출력을 구별하기 위해 자체 학습될 수 있는 워터마크(watermark)들 또는 다른 피처들을 검출할 수 있을 수 있다. [0038] Broadcast audio classifier 220b allows speech input 104 to be transmitted from a non-human source 12, such as television, radio, computer, or any other audio capable of outputting broadcasted and/or synthesized speech. Audio data 103 of speech input 104 may be analyzed to provide a broadcasted-speech score for the speech input, indicating the likelihood that it corresponds to broadcasted or synthesized speech output from an output device. . As used herein, broadcasted speech is uttered by a human being (e.g., a newscaster, actor, radio personality, etc.), but also in media events such as commercials, radio programs, television shows, and/or movies. refers to speech corresponding to audio content coming from/broadcasting from a non-human source 12. On the other hand, synthesized speech refers to non-human speech produced, for example, by text-to-speech (TTS) systems. The broadcast audio classifier 220b may be attached to audio content emanating from/broadcast from a non-human source 12 and/or is synthesized speech or is broadcast during a media event. It may be possible to detect watermarks or other features that can be self-learned to distinguish speech output from the user device 200 from the speech output of actual humans proximate to the user device 200.
[0039] 일부 예들에서, 브로드캐스트 오디오 분류기(220b)는 또한, 브로드캐스트된-스피치 스코어를 결정하기 위한 기초로서, 스피커 분류기(220a)에 의해 제공되는 스피커-식별 스코어를 분석한다. 예컨대, 스피커 분류기로부터 출력되는 높은 스피커-식별 스코어는 스피치 입력(104)이 비-인간 소스(12)로부터 출력되지 않았다는 강한 표시인 반면, 스피커 분류기(220a)로부터 출력되는 낮은 스피커-식별 스코어는 스피치 입력(104)이 비-인간 소스(12)로부터 나왔을 수 있는 가능성을 열어 둔다. [0039] In some examples, broadcast audio classifier 220b also analyzes the speaker-identification score provided by speaker classifier 220a as a basis for determining the broadcasted-speech score. For example, a high speaker-identification score output from the speaker classifier is a strong indication that the speech input 104 is not from a non-human source 12, whereas a low speaker-identification score output from the speaker classifier 220a is a strong indication that the speech input 104 is not from a non-human source 12. This leaves open the possibility that input 104 may have come from a non-human source 12.
[0040] 핫워드 검출기(220c)는 스피치 입력(104)에 대한 핫워드 신뢰도 스코어를 계산하고, 핫워드 신뢰도 스코어를 핫워드 신뢰도 스코어 임계치와 비교한다. 핫워드 신뢰도 스코어 임계치는, 핫워드 검출기(220c)에 의해 검출될 때, 슬립-상태로부터 웨이크업하여, 음성 질의에 대응하는, 스피치 입력(104)의 나머지 부분을 캡처하고, 질의 프로세싱 스택(700)에 전송될 ASR 요청(102)을 생성하도록 사용자 디바이스(200)를 트리거하는 핫워드 신뢰도 스코어를 나타낸다. 사용자(10)가 지정된 핫워드 "Ok Google"을 명확하게 말하고 사용자 디바이스(200) 근처에 있는 경우들에서, 핫워드 신뢰도 스코어는 높을 수 있다(예컨대, > 0.9). 일부 경우들에서, 사용자 디바이스(200) 근처의 사용자(10)는, 지정된 핫워드 "Ok Google"과 유사하게 들리는 "Ok poodle"과 같은 어구를 말할 수 있으며, 이에 의해, 더 낮은 신뢰도 스코어(예컨대, 0.7)를 야기하지만, 핫워드 신뢰도 스코어 임계치(예컨대, 0.68)를 여전히 충족시킬 수 있다. 더욱이, 스피커가 사용자 디바이스(200)로부터 더 멀리 떨어져 있거나 덜 명확하게 말하는 경우, 핫워드 신뢰도 스코어들은 감소될 수 있다. 따라서, 스피치 입력(104)의 핫워드 신뢰도 스코어(즉, 스피치 입력(104)의 초기 부분)을 포함하는 콘텐츠 메타데이터(110)를 제공하는 것은, 핫워드 신뢰도 스코어 임계치가 사용자 디바이스(200)를 웨이크업하게 트리거하도록 충족되었지만, 핫워드 신뢰도 스코어는 스피커가 멀리 떨어져 있고/있거나 핫워드와 유사하게 들리는 어떠한 다른 어구를 말했으며 그에 따라 사용자 디바이스(200)를 호출할 의도가 없었음을 표시하기에 충분히 낮을 수 있다는 것을 표시할 수 있다. 따라서, 핫워드 신뢰도 스코어는, 콘텐츠 메타데이터(110)가 ASR 요청이 진짜일 가능성이 있는지 여부를 표시하는 데 기여할 수 있다. [0040] Hotword detector 220c calculates a hotword confidence score for speech input 104 and compares the hotword confidence score to a hotword confidence score threshold. The hotword confidence score threshold, when detected by the hotword detector 220c, wakes up from the sleep-state, captures the remaining portion of the speech input 104, corresponding to the voice query, and processes the query processing stack 700. ) represents a hotword reliability score that triggers the user device 200 to generate an ASR request 102 to be transmitted. In cases where user 10 clearly utters the designated hotword “Ok Google” and is nearby user device 200, the hotword confidence score may be high (eg, >0.9). In some cases, a user 10 near user device 200 may say a phrase such as “Ok poodle” that sounds similar to the designated hotword “Ok Google”, thereby resulting in a lower trust score (e.g. , 0.7), but may still meet the hotword confidence score threshold (e.g., 0.68). Moreover, if the speaker is further away from user device 200 or speaks less clearly, hotword confidence scores may decrease. Accordingly, providing content metadata 110 that includes the hotword confidence score of the speech input 104 (i.e., the initial portion of the speech input 104) determines that the hotword confidence score threshold will determine the user device 200. Although sufficient to trigger a wakeup, the hotword confidence score is sufficient to indicate that the speaker is far away and/or has uttered any other phrase that sounds similar to the hotword and thus has no intention of calling the user device 200. This can indicate that it can be low enough. Accordingly, the hotword confidence score may contribute to the content metadata 110 indicating whether the ASR request is likely to be genuine.
[0041] 세션 활동 로그(220d)는 사용자 디바이스(200)와 질의 프로세싱 스택(700) 사이의 상호작용들의 로그를 제공할 수 있다. 예컨대, 로그(220d)는 질의 프로세싱 스택(700)에 전송된 최근의 ASR 요청들(102)의 타임 스탬프들 및 질의 프로세싱 스택으로부터 리턴된 대응하는 TTS 응답들을 포함할 수 있다. 신호 생성기(218)는 세션 활동 로그(220d)에 액세스하여, 사용자 디바이스(200)와 질의 프로세싱 스택(700) 사이에서 다중-턴 상호작용이 진행 중인지 여부를 표시하는 콘텐츠 메타데이터(110)를 결정할 수 있다. 예컨대, 음성 질의에 대한 ASR 요청(102)이 "Should I bring an umbrella"라고 묻는 것이라면, 세션 활동 로그(220d)는, 사용자 디바이스(200)가 "What is the temperature going to be tomorrow morning in Detroit"라고 묻는 이전 음성 질의를 방금 제공했고, "The temperature in Detroit tomorrow will be 62-degrees at 7am and will reach 73-degrees by 11am"이라고 알리는 TTS 응답을 질의 프로세싱 스택(700)으로부터 수신했음을 나타낼 수 있다. 따라서, 신호 생성기(218)는, 사용자(10)가 현재 사용자 디바이스(200)와의 계속적인 논의에 관여하고 있기 때문에, ASR 요청(102)이 진짜일 가능성이 있음을 표시하는 콘텐츠 메타데이터(110)를 ASR 요청(102)에 포함시키기 위해 생성할 수 있다. 다른 예에서, 사용자(10)는 최근에, 사용자 디바이스(200)에게 로컬 레스토랑들을 검색하도록 요청하는 ASR 요청(102)을 제출했을 수 있다. 로컬 레스토랑들 중 하나에 예약을 하도록 사용자 디바이스(200)에 요청하는 후속 ASR 요청(102)이 제출되는 경우, 세션 활동 로그(220d)는 사용자 디바이스(200)와 질의 프로세싱 스택(700) 사이에 다중-턴 상호작용이 진행중임을 표시할 수 있다. 더욱이, 신호 생성기(218)는, 특정 애플리케이션(220e), 이를테면 디지털 음성 어시스턴트가, 사용자 디바이스(200)와 질의 프로세싱 스택 간에 진행중인 다중-턴-상호작용에 대한 활동 표시자를 제공하기 위해 사용자 디바이스(200) 상에서 현재 실행되고 있음을 추가로 결정할 수 있다. 일부 예들에서, 디지털 음성 어시스턴트 애플리케이션(220e)은 신호 생성기(218)에 의한 사용을 위해 세션 활동 로그(220d)에 세션 활동을 로깅(log)한다.[0041] Session activity log 220d may provide a log of interactions between user device 200 and query processing stack 700. For example, log 220d may include timestamps of recent ASR requests 102 sent to query processing stack 700 and corresponding TTS responses returned from the query processing stack. Signal generator 218 accesses session activity log 220d to determine content metadata 110 that indicates whether a multi-turn interaction is in progress between user device 200 and query processing stack 700. You can. For example, if the ASR request 102 for the voice query asks “Should I bring an umbrella,” the session activity log 220d may indicate that the user device 200 asks “What is the temperature going to be tomorrow morning in Detroit” It may indicate that a previous voice query asking "The temperature in Detroit tomorrow will be 62-degrees at 7am and will reach 73-degrees by 11am" was just provided, and a TTS response was received from the query processing stack 700. Accordingly, signal generator 218 generates content metadata 110 indicating that ASR request 102 is likely genuine because user 10 is currently engaged in an ongoing discussion with user device 200. Can be created for inclusion in the ASR request 102. In another example, user 10 may have recently submitted an ASR request 102 requesting user device 200 to search for local restaurants. When a subsequent ASR request 102 is submitted requesting the user device 200 to make a reservation at one of the local restaurants, the session activity log 220d records multiple connections between the user device 200 and the query processing stack 700. -Can indicate that turn interaction is in progress. Moreover, signal generator 218 may be used to enable a particular application 220e, such as a digital voice assistant, to provide an activity indicator for an ongoing multi-turn interaction between user device 200 and the query processing stack. ), it can be further determined that it is currently running. In some examples, digital voice assistant application 220e logs session activity in session activity log 220d for use by signal generator 218.
[0042] 오디오 품질 스코어러(220f)는 스피치 입력의 오디오 품질 스코어를 결정하도록 구성될 수 있다. 일부 예들에서, 오디오 품질 스코어러(220f)는 스피치 입력(104)과 연관된 오디오 데이터(103)의 음량(loudness)(예컨대, 데시벨)을 측정한다. 측정된 음량은, 핫워드 검출기(220c)에 의해 검출되는 핫워드에 대응하는 오디오 데이터(103)의 부분, 핫워드 다음에 오는 음성 질의에 대응하는 오디오 데이터(103)의 부분, 또는 사용자 디바이스(200)에 의해 캡처되는 전체 오디오 데이터(103)에 대응할 수 있다. 스피치 입력(104)의 오디오 품질 스코어는 추가로, 오디오 데이터(103)에 존재하는 백그라운드 노이즈의 레벨을 표시할 수 있다. 따라서, 오디오 품질 스코어는 단순히, 스피치 입력(104)의 오디오 품질의 신뢰도 스코어, 즉, 스피치 입력(104)이 사용자 디바이스(200)의 마이크로폰에 의해 얼마나 잘 캡처되었는지를 나타낼 수 있다. [0042] Audio quality scorer 220f may be configured to determine an audio quality score of a speech input. In some examples, audio quality scorer 220f measures the loudness (e.g., decibels) of audio data 103 associated with speech input 104. The measured sound volume is the portion of the audio data 103 corresponding to the hotword detected by the hotword detector 220c, the portion of the audio data 103 corresponding to the voice query following the hotword, or the user device ( It may correspond to the entire audio data 103 captured by 200). The audio quality score of speech input 104 may further indicate the level of background noise present in audio data 103. Accordingly, the audio quality score may simply represent a confidence score of the audio quality of speech input 104, i.e., how well speech input 104 was captured by the microphone of user device 200.
[0043] 신호 생성기(218)는, 예컨대, 사용자 디바이스(200)에 대한 사용자(10)의 거리 및 포지션을 표시하기 위해, 다수의 소스들(220)로부터의 데이터/정보를 활용함으로써, 스피치 입력(104)에 대한 공간적-국부화 스코어를 포함하는 콘텐츠 메타데이터(110)를 결정할 수 있다. 일부 예들에서, 핫워드 검출기(220c)로부터의 핫워드 신뢰도 스코어 및/또는 오디오 품질 스코어러(220f)로부터의 오디오 품질 스코어가 공간적-국부화 스코어에 기여할 수 있다. 예컨대, 스피치 입력(104)을 말한 소스(예컨대, 사용자(10))가 사용자 디바이스(200) 근처에 있지 않음을 표시하기 위해, 낮은 핫워드 신뢰도 스코어 및/또는 낮은 오디오 품질 스코어가 사용될 수 있다. 부가적으로 또는 대안적으로, 공간적-국부화 스코어는 사용자 디바이스(200)의 하나 이상의 센서들(220, 200g)에 의해 수집된 데이터/정보에 기반할 수 있다. 센서들(220g)은 광-검출 센서, 가속도계, 마이크로폰, 자이로스코프, 자력계, 근접 센서, 터치스크린 센서, 기압계, 또는 GPS(global positioning system) 센서 중 적어도 하나를 포함할 수 있지만, 이들로 제한되지 않는다. 예컨대, 사용자 디바이스(200)가 한 쌍의 스마트 헤드폰들을 포함하는 경우, 센서들(220g) 중 하나 이상은, 사용자(10)가 현재 헤드폰들을 착용하고 있는지 여부 또는 헤드폰들이 착용되고 있지 않고 그에 따라 사용되지 않는지 여부를 결정하는 데 사용될 수 있다. 사용자(10)가 스마트 헤드폰들을 착용하고 있는지 여부는 센서들(220g) 중 하나, 예컨대 근접 센서, 가속도계 등에 의해 결정될 수 있다. 이 예에서, 신호 생성기(218)는, 사용자(10)가 스마트 헤드폰들을 착용하고 있을 때에는 높은 공간적-국부화 스코어(예컨대, 1의 이진 값)를 생성할 수 있고, 사용자(10)가 스마트 헤드폰들을 착용하고 있지 않을 때에는 낮은 공간적-국부화 스코어(예컨대, 0의 이진 값)를 생성할 수 있다. 다른 예로서, 센서들(220g) 중 하나는, 방이 어두운지 여부를 표시하기 위해, 집의 방에 로케이팅된 사용자 디바이스(200)의 환경에서 광 에너지를 검출할 수 있을 수 있다. 예컨대, 특정된 임계치 미만의 광 에너지의 레벨은 사용자 디바이스(200)가 암실에 로케이팅되어 있음을 표시할 수 있다. 따라서, 신호 생성기(218)는, 사용자 디바이스(200)와 동일한 방에 사용자들(10)이 존재할 가능성이 없음을 표시하기 위해, (예컨대, 현재 시간에 추가로 액세스함으로써) 사용자 디바이스(200)가 저녁 동안 암실에 로케이팅될 때 낮은 공간적-국부화 스코어를 결정할 수 있다. 반대로, 신호 생성기(218)는, 공간적-국부화 스코어를 결정할 때, 사용자 디바이스(200)에게 방의 조명을 끌 것을 요청하는 최근의 ASR 요청(102)이 있었음을 표시하는, 세션 활동 로그(220d)로부터의 정보를 활용할 수 있으며, 이에 따라, 공간적-국부화 스코어는 대신에, 사용자들(10)이 암실에 있음을 반영할 수 있다. 또 다른 예로서, 차량의 인포테인먼트(infotainment) 시스템의 일부인 사용자 디바이스(200)는, 센서들(220g)을 사용하여, 사용자(10)가 차량의 객실(cabin)에 있는지 여부, 차량이 달리고 있는지 여부 등을 결정할 수 있다. 이 예에서, 사용자 디바이스(200)가 스피치 입력(104)을 캡처함에도 불구하고, 차량의 객실에 아무도 없고 차량이 작동하지 않는다는 사실은, 스피치 입력(104)이 어떠한 다른 사용자 디바이스(200)로 향했거나 또는 인포테인먼트 시스템에 의해 우연히 캡처된 백그라운드 노이즈였음을 표시할 수 있다. [0043] Signal generator 218 may input speech input 104 by utilizing data/information from multiple sources 220, e.g., to indicate the distance and position of user 10 relative to user device 200. Content metadata 110 including a spatial-localization score for may be determined. In some examples, a hotword confidence score from hotword detector 220c and/or an audio quality score from audio quality scorer 220f may contribute to the spatial-localization score. For example, a low hotword confidence score and/or a low audio quality score may be used to indicate that the source (e.g., user 10) speaking speech input 104 is not near user device 200. Additionally or alternatively, the spatial-localization score may be based on data/information collected by one or more sensors 220, 200g of user device 200. Sensors 220g may include, but are not limited to, at least one of a light-detection sensor, an accelerometer, a microphone, a gyroscope, a magnetometer, a proximity sensor, a touch screen sensor, a barometer, or a global positioning system (GPS) sensor. No. For example, if user device 200 includes a pair of smart headphones, one or more of sensors 220g may determine whether user 10 is currently wearing headphones or whether headphones are not being worn and are used accordingly. It can be used to determine whether or not it is working. Whether the user 10 is wearing smart headphones may be determined by one of the sensors 220g, such as a proximity sensor, an accelerometer, etc. In this example, signal generator 218 may generate a high spatial-localization score (e.g., a binary value of 1) when user 10 is wearing smart headphones, and when user 10 is wearing smart headphones When not being worn, they may produce a low spatial-localization score (e.g., a binary value of 0). As another example, one of sensors 220g may detect light energy in the environment of user device 200 located in a room of a home to indicate whether the room is dark. For example, a level of light energy below a specified threshold may indicate that user device 200 is located in a dark room. Accordingly, signal generator 218 may cause user device 200 to indicate that users 10 are unlikely to be present in the same room as user device 200 (e.g., by further accessing the current time). Low spatial-localization scores can be determined when located in a dark room during the evening. Conversely, signal generator 218, when determining the spatial-localization score, records session activity log 220d, which indicates that there has been a recent ASR request 102 requesting user device 200 to turn off the lights in the room. Information from may be utilized, such that the spatial-localization score may instead reflect that users 10 are in a dark room. As another example, user device 200, which is part of a vehicle's infotainment system, uses sensors 220g to determine whether user 10 is in the cabin of the vehicle and whether the vehicle is running. etc. can be decided. In this example, although user device 200 captures speech input 104, the fact that no one is in the cabin of the vehicle and the vehicle is not running means that speech input 104 is not directed to any other user device 200. This may indicate that the noise was detected or was background noise accidentally captured by the infotainment system.
[0044] 로그인 표시자를 포함하는 콘텐츠 메타데이터(110)는, 사용자(10)가 사용자 디바이스(200)에 로그인되어 있는지 여부, 예컨대, 사용자(10)가 사용자 디바이스(200)에 액세스/잠금해제(unlock)하기 위한 적절한 크리덴셜(credential)들을 입력했는지 여부를 결정할 수 있다. 사용자 디바이스(200)에 로그인된 사용자(10)의 존재는 ASR 요청(102)이 진짜일 가능성을 증가시킬 수 있다. 또한, 로그인 표시자는 사용자(10)가 사용자 디바이스(200) 상에서 실행되는 특정 애플리케이션(220e)에 로그인되어 있는지 여부를 표시할 수 있다. 예컨대, 신호 생성기(218)는, 로그인된 사용자(10)의 사용자 디바이스(200) 상에서 실행되는 캘린더 애플리케이션(220e)에 액세스함으로써 로그인 표시자를 생성하고, 로그인된 사용자(10)가 5분 내에 회의가 있다고 결정할 수 있다. 이 예에서, 로그인 표시자는, 로그인된 사용자(10)가 회의를 위한 정보(예컨대, 지시들, 노트(note)들 등)를 필요로 하기 때문에, 스피치 입력(104)에 대한 ASR 요청(102)을 신속하게 프로세싱하는 것이 중요하다는 것을 표시하는 콘텐츠 메타데이터(110)를 제공할 수 있다. 다른 예로서, 로그인된 사용자(10)는 집주인일 수 있으며, 그리고 신호 생성기(218)는, 캘린더 애플리케이션(220e)에 액세스하여, 로그인된 사용자(10)가 로그인된 사용자(10)의 집 이외의 로케이션에서 약속이 있음을 결정함으로써, 로그인 표시자를 생성할 수 있다. 예컨대, 사용자 디바이스(200)가 로그인된 사용자(10)의 집에 로케이팅된 스마트 스피커이고, 그리고 사용자 디바이스(200)가 캘린더 애플리케이션(220e)에서의 약속과 동일한 시간에 발화된 핫워드를 검출할 때 트리거되는 경우, 로그인 표시자는, 로그인된 사용자(10)가 스피치 입력(104)을 제공하지 않았을 가능성이 높다는 것을 표시하는 콘텐츠 메타데이터(110)를 제공할 수 있고, 그에 의해, 대응하는 ASR 요청(102)은 진짜가 아닐 가능성이 있게 된다. 사용자(10)는, 로그인 정보, 애플리케이션 사용, 및 로케이션 정보를 제공하는 데 명시적으로 동의하도록 요구될 수 있다. [0044] Content metadata 110, including a login indicator, determines whether user 10 is logged in to user device 200, e.g., when user 10 accesses/unlocks user device 200. You can determine whether you have entered the appropriate credentials. The presence of user 10 logged in to user device 200 may increase the likelihood that ASR request 102 is genuine. Additionally, the login indicator may indicate whether the user 10 is logged in to a specific application 220e running on the user device 200. For example, signal generator 218 generates a login indicator by accessing calendar application 220e running on user device 200 of logged in user 10 and determines that logged in user 10 has a meeting within 5 minutes. You can decide that there is. In this example, the login indicator is an ASR request 102 for speech input 104 because the logged in user 10 needs information for a meeting (e.g. instructions, notes, etc.) Content metadata 110 may be provided indicating that it is important to process quickly. As another example, logged-in user 10 may be a homeowner, and signal generator 218 may access calendar application 220e to determine whether logged-in user 10 is in a home other than logged-in user 10's home. By determining that there is an appointment at the location, a login indicator can be created. For example, if user device 200 is a smart speaker located in the home of logged in user 10, and user device 200 detects a hotword uttered at the same time as an appointment in calendar application 220e, When triggered, the login indicator may provide content metadata 110 indicating that the logged in user 10 most likely did not provide the speech input 104, thereby resulting in a corresponding ASR request. There is a possibility that (102) is not real. User 10 may be required to explicitly agree to provide login information, application usage, and location information.
[0045] 신호 생성기(218)는, 예컨대, 스피치 입력(104)이 캡처되는 시점에 사용자(10)가 사용자 디바이스(200)와 상호작용할 가능성을 표시하기 위해, 다수의 소스들(220)로부터의 데이터/정보를 활용함으로써, 사용자 디바이스 거동 신호를 포함하는 콘텐츠 메타데이터(110)를 결정할 수 있다. 예컨대, 하나 이상의 센서들(220g)로부터의 정보는, 사용자 디바이스가 거꾸로 있는지, 아래로 향하고 있는지 여부(예컨대, 사용자 디바이스가 스마트폰 또는 태블릿인 경우), 사용자 디바이스(200)가 서랍/지갑에 있는지 여부 등을 표시할 수 있다. 이들 시나리오들에서는, 사용자 디바이스(200)가 우발적으로 트리거되었을 가능성이 크며, 그에 의해, 대응하는 ASR 요청(102)이 진짜가 아닐 가능성이 있게 된다. 센서들(220g)로부터의 정보는, (예컨대, GPS 센서(220g)로부터 획득되는) 사용자 디바이스의 로케이션 및/또는 사용자 디바이스(200)의 네트워크 연결의 신호 강도를 더 포함할 수 있다. 예컨대, 사용자 디바이스(200)가 현재 불량한 신호 강도를 가지고 있으며 그리고 (예컨대, 이력 지식에 기반하여) 고르지 않은(spotty) 셀 커버리지를 갖는 것으로 악명 높은 로케이션에 있음을 표시하는 사용자 디바이스 거동 신호는, 대응하는 ASR 요청(102)에 우선순위를 부여할 때 QoS 관리자(300)에 유용할 수 있는데, 왜냐하면 ASR 요청(102)이 진짜일지라도, 사용자 디바이스(200)가 질의 프로세싱 스택에 의해 프로세싱되는 대응하는 응답(예컨대, ASR 출력 및/또는 TTS 응답)을 수신하지 못할 수 있는 가능성이 크기 때문이다. 이러한 상황에서, 질의 프로세싱 스택(700)이 높은 트래픽 스파이크들을 겪고 있을 때, 다른 계류중인 ASR 요청들(102)을 먼저 프로세싱하는 것이 유익할 수 있는데, 이는 그 각각의 사용자 디바이스들(200)로 성공적으로 다시 리턴될 가능성이 더 높은 대응하는 응답들을 생성할 것이다. [0045] Signal generator 218 may collect data/information from multiple sources 220, e.g., to indicate the likelihood that user 10 will interact with user device 200 at the time speech input 104 is captured. By utilizing , content metadata 110 including user device behavior signals can be determined. For example, information from one or more sensors 220g may include whether the user device 200 is upside down or facing down (e.g., if the user device is a smartphone or tablet), and whether the user device 200 is in a drawer/wallet. It can be displayed whether or not. In these scenarios, it is likely that the user device 200 has been triggered accidentally, thereby creating a possibility that the corresponding ASR request 102 is not genuine. Information from sensors 220g may further include the location of the user device (e.g., obtained from GPS sensor 220g) and/or the signal strength of the network connection of user device 200. For example, a user device behavior signal indicating that the user device 200 currently has poor signal strength and is in a location notorious for having spotty cell coverage (e.g., based on historical knowledge) may correspond to This may be useful for the QoS manager 300 in prioritizing ASR requests 102 because, even if an ASR request 102 is genuine, the user device 200 does not process the corresponding response by the query processing stack. This is because there is a high possibility that (e.g., ASR output and/or TTS response) may not be received. In this situation, when the query processing stack 700 is experiencing high traffic spikes, it may be advantageous to process other pending ASR requests 102 first, which may be successful with their respective user devices 200. will generate corresponding responses that are more likely to be returned back to .
[0046] 신호 생성기(218)는, 예컨대, 사용자 디바이스(200)를 둘러싸는 조건들을 평가 및 분석하기 위해, 다수의 소스들(220)로부터의 데이터/정보를 활용함으로써 환경 조건 신호(environmental condition signal)를 포함하는 콘텐츠 메타데이터(110)를 결정할 수 있다. 구체적으로, 환경 조건 신호는 사용자 디바이스(200)를 둘러싸는 환경 조건들을 결정하기 위해 센서들(220g) 중 하나 이상을 활용할 수 있다. 예컨대, 환경 조건 신호는, 사용자 디바이스(200)에 근접한 몇몇 사용자 디바이스들(200)이 있다는 것, 사용자 디바이스(200)가 연결되는 네트워크의 조건들(예컨대, 네트워크가 오버로드됨), 사용자 디바이스(200)의 GPS 좌표들, 사용자 디바이스(200)가 외부에 있는지, 현재 이동하고 있는지, 불량한 셀룰러 영역 또는 데이터 수신 영역에 접근하고 있는지 여부 등을 표시할 수 있다. [0046] Signal generator 218 includes an environmental condition signal, e.g., by utilizing data/information from multiple sources 220 to evaluate and analyze conditions surrounding user device 200. Content metadata 110 may be determined. Specifically, the environmental condition signal may utilize one or more of sensors 220g to determine environmental conditions surrounding user device 200. For example, the environmental condition signal may indicate that there are several user devices 200 in close proximity to the user device 200, conditions of the network to which the user device 200 is connected (e.g., the network is overloaded), and the user device ( GPS coordinates of 200), whether the user device 200 is outside, currently moving, approaching a poor cellular area or a data reception area, etc. may be displayed.
[0047] 위의 설명에서 제시된 바와 같이, 사용자 디바이스(200)는, 네트워크 연결을 요구하지 않으면서 신속하게 저-충실도 전사들을 생성하기 위해 온-디바이스 ASR 모듈(220n)(예컨대, 로컬 질의 프로세싱 스택(700b))을 실행시키는 능력을 가질 수 있다. 유리하게, 신호 생성기(218)에 의해 생성되는 콘텐츠 메타데이터(110)는, ASR 요청(102)에 대한 잠재적으로 관련된 정보 또는 세부 사항들을 QoS 관리자(300)에 제공하기 위해, 온-디바이스 ASR 모듈(220n)에 의해 생성되는 스피치 입력(104)의 저-충실도 전사를 포함할 수 있다. 여기서, 저-충실도 전사는 ASR 요청(102)이 시간에 민감한 음성 질의(예컨대, 1분 동안 타이머를 설정하기 위한 커맨드)를 포함한다는 것을 나타낼 수 있으며, 이에 의해, ASR 요청(102)이 즉시 프로세싱되게 ASR 요청(102)에 높은 우선순위 스코어(311)를 할당하도록 QoS 관리자(300)에 통지한다. 이러한 동일한 시나리오에서, ASR 요청(102)이 백로그(320)에 캐싱될 때 질의 프로세싱 스택(700a)이 오버로드되고 최대(full) 프로세싱 용량에 있는 경우, 질의 프로세싱 스택(700a)은 ASR 요청(102)(예컨대, 1분 동안 타이머를 설정하기 위한 명령들을 전송)을 즉시 프로세싱할 수 없을 수 있고, 단순히 ASR 요청(102)을 드롭시킬 수 있고, 선택적으로는, 요청이 현재 완료될 수 없다는 것을 사용자(10)에게 통지할 수 있다. 이는, 짧은 지속기간 동안 타이머를 설정하는 것은, ASR 요청(102)을 제공한 이후 시간이 경과한 후에는 거의 사용되지 않기 때문에, 사용자(10)에게 바람직할 것이다. 그러나, 커맨드가 더 긴 지속기간, 이를테면 10분 동안 타이머를 설정하는 것인 경우, 질의 프로세싱 스택(700a)이 ASR 요청(102)을 프로세싱할 수 있을 때까지, ASR 요청(102)이 프리-프로세싱 백로그(320)에 계류되고 캐싱될 수 있도록 허용가능할 수 있으며, 이에 의해, 타이머를 설정하기 위한 명령들은 ASR 요청(102)이 프리-프로세싱 백로그(320)에서 계류되는 동안 트래픽의 증가로 인해 야기되는 레이턴시를 보상할 수 있다. [0047] As presented in the description above, user device 200 may use an on-device ASR module 220n (e.g., local query processing stack 700b) to quickly generate low-fidelity transcriptions without requiring a network connection. ) can have the ability to execute. Advantageously, the content metadata 110 generated by the signal generator 218 is stored in the on-device ASR module to provide potentially relevant information or details about the ASR request 102 to the QoS manager 300. It may include a low-fidelity transcription of the speech input 104 produced by 220n. Here, the low-fidelity transcription may indicate that the ASR request 102 includes a time-sensitive voice query (e.g., a command to set a timer for one minute), thereby causing the ASR request 102 to be processed immediately. This notifies the QoS manager 300 to assign a high priority score 311 to the ASR request 102. In this same scenario, when query processing stack 700a is overloaded and at full processing capacity when ASR requests 102 are cached in backlog 320, query processing stack 700a is unable to process ASR requests ( 102) (e.g., sending commands to set a timer for one minute) may not be processed immediately and may simply drop the ASR request 102, optionally indicating that the request cannot currently be completed. The user 10 may be notified. This may be desirable for the user 10 because setting a timer for a short duration may be of little use after some time has passed since providing the ASR request 102. However, if the command is to set a timer for a longer duration, such as 10 minutes, the ASR request 102 may be pre-processed until the query processing stack 700a is able to process the ASR request 102. may be allowed to be pending in the backlog 320 and cached, whereby instructions to set a timer may be allowed to be cached while an ASR request 102 is pending in the pre-processing backlog 320 due to an increase in traffic. The resulting latency can be compensated for.
[0048] 도시된 예에서, 신호 생성기(218)가 스피치 입력(104)과 연관된 콘텐츠 메타데이터(110)를 컴파일링(compile)하고 생성한 후, 사용자 디바이스(200)는 대응하는 스피치 입력(104) 및 오디오 데이터(103)와 함께 ASR 요청(102)에 포함시키기 위한 콘텐츠 메타데이터(110)를 임베딩한다. 그런 다음, 사용자 디바이스(200)는 ASR 요청(102)을 QoS 관리자(300)에 전송한다. [0048] In the example shown, after signal generator 218 compiles and generates content metadata 110 associated with speech input 104, user device 200 generates the corresponding speech input 104 and audio. Embeds content metadata 110 for inclusion in the ASR request 102 along with the data 103. User device 200 then sends an ASR request 102 to QoS manager 300.
[0049] 도 3a 내지 도 3c는, 사용자 디바이스들(200)로부터 수신되는 ASR 요청들(102)에 랭킹들(312)을 할당하고, 질의 프로세싱 스택(700)의 프로세싱 가용성에 기반하여 가장 높은 순위로부터 가장 낮은 순위까지의 랭킹(312)의 순위로 ASR 요청들(102)을 질의 프로세싱 스택(700)에 제공하는 음성 질의 QoS 관리자(300)의 개략도들을 제공한다. 질의 프로세싱 스택(700)은 ASR 모듈(710)(도 1), 해석기 모듈(720)(도 1), 또는 TTS 모듈(730)(도 1) 중 적어도 하나를 포함할 수 있지만, 이에 제한되지 않는다. 도시된 예에서, 질의 프로세싱 스택(700)은 현재, 질의 프로세싱 스택(700)이 오버로드되게 하는 ASR 요청들(102)의 큰 트래픽 스파이크를 겪고 있을 수 있다. 예컨대, 대형 미디어 이벤트(예컨대, Superbowl) 동안 방영되는 텔레비전 광고는 발화되는 핫워드를 포함할 수 있으며, 이러한 핫워드는 사용자 가정의 텔레비전들(예컨대, 비-인간 소스(12))로부터 출력될 때, 해당 가정의 스피치-가능 사용자 디바이스들(200)로 하여금 트리거되어, 텔레비전들로부터 출력되는 핫워드의 검출 후에 캡처되는 오디오 데이터(103)를 포함하는 거짓(false) ASR 요청들(102)을 생성하게 한다. [0049] 3A-3C assign rankings 312 to ASR requests 102 received from user devices 200, from highest to lowest based on the processing availability of the query processing stack 700. Provides schematic diagrams of a voice query QoS manager 300 that provides ASR requests 102 to the query processing stack 700 in a ranking order of 312. Query processing stack 700 may include, but is not limited to, at least one of ASR module 710 (FIG. 1), interpreter module 720 (FIG. 1), or TTS module 730 (FIG. 1). . In the example shown, query processing stack 700 may currently be experiencing a large traffic spike in ASR requests 102 causing query processing stack 700 to become overloaded. For example, a television commercial airing during a large media event (e.g., the Superbowl) may include hotwords uttered when these hotwords are output from televisions in a user's home (e.g., non-human source 12). , triggering the household's speech-capable user devices 200 to generate false ASR requests 102 containing audio data 103 that are captured after detection of a hotword output from the televisions. Let it be done.
[0050] 도 3a를 참조하면, 프리-프로세싱 백로그(320)는, 음성 질의 QoS 관리자(300)의 랭커(310)가 사용자 디바이스(200)로부터 새로운 ASR 요청 D(102d)를 수신할 때, 질의 프로세싱 스택(700)에 의해 프로세싱되기를 대기하는 계류중인 ASR 요청들(A(102a), B(102b), C(102c))을 포함한다. 랭커(310)는, 새로운 ASR 요청 D(102d)와 연관된 콘텐츠 메타데이터(110)에 기반하여, 새로운 ASR 요청 D(102d)에 대한 대응하는 우선순위 스코어(311)를 결정할 수 있다. 새로운 ASR 요청 D(102d)가 수신될 때, 프리-프로세싱 백로그(320) 내의 계류중인 ASR 요청들(102a, 102b, 102c)은 이들의 우선순위 스코어들(311)의 순위로 랭킹되며, 그에 따라, ASR 요청 A(102a)는 가장 높은 랭킹(312)과 연관되고, ASR 요청 C(102b)는 다음으로 가장 높은 랭킹(312)과 연관되며, ASR 요청 B(102b)는 가장 낮은 랭킹(312)과 연관된다. 따라서, ASR 요청 C(102c)는, QoS 관리자(300)가 ASR 요청 B(102b)를 수신한 후에, 대응하는 사용자 디바이스(200)로부터 QoS 관리자(300)에서 수신되었을 수 있지만, 랭커(310)는 ASR 요청 B(102b)에 할당된 랭크(312)보다 더 높은 랭크(312)를 ASR 요청 C(102c)에 할당한다. 프리-프로세싱 백로그(320)는, 질의 프로세싱 스택(700)에 의해 프로세싱되기를 대기하는, 우선순위 스코어들(311)의 순위로 랭킹된 수천 내지 수백만 개의 계류중인 ASR 요청들(102)을 포함할 수 있다. 도 3a를 계속 참조하면, 프리-프로세싱 백로그(320)는 계류중인 ASR 요청들(A(102a), C(102c), B(102b))의 리스트(322)를 랭커(310)에 제공하며, 랭커(310)는 우선순위 스코어들에 기반하여 새로운 ASR 요청 D(102d)와 함께, 계류중인 ASR 요청들(A(102a), C(102c), B(102b))을 재랭킹한다. [0050] Referring to Figure 3A, the pre-processing backlog 320 is the query processing stack when the ranker 310 of the voice query QoS manager 300 receives a new ASR request D 102d from the user device 200. Includes pending ASR requests (A (102a), B (102b), C (102c)) waiting to be processed by 700. Ranker 310 may determine a corresponding priority score 311 for new ASR request D 102d based on content metadata 110 associated with new ASR request D 102d. When a new ASR request D (102d) is received, the pending ASR requests (102a, 102b, 102c) in the pre-processing backlog (320) are ranked by the rank of their priority scores (311), and Accordingly, ASR request A (102a) is associated with the highest ranking (312), ASR request C (102b) is associated with the next highest ranking (312), and ASR request B (102b) is associated with the lowest ranking (312). ) is related to. Accordingly, ASR request C 102c may have been received at QoS manager 300 from a corresponding user device 200 after QoS manager 300 has received ASR request B 102b, but ranker 310 assigns a higher rank 312 to ASR request C 102c than the rank 312 assigned to ASR request B 102b. The pre-processing backlog 320 may contain thousands to millions of pending ASR requests 102, ranked by priority scores 311, waiting to be processed by the query processing stack 700. You can. Still referring to Figure 3A, pre-processing backlog 320 provides ranker 310 with a list 322 of pending ASR requests (A (102a), C (102c), B (102b)). , ranker 310 reranks the pending ASR requests (A (102a), C (102c), B (102b)) along with the new ASR request D (102d) based on the priority scores.
[0051] 일부 구현들에서, 랭커(310)는, 타임아웃 임계치를 충족하는 시간 기간 동안 프리-프로세싱 백로그(320)에 상주하는 임의의 계류중인 ASR 요청들(102)이 질의 프로세싱 스택(700)(예컨대, 백엔드-측 ASR 모듈(710))에 의해 프로세싱되는 것을 거절한다. 도 3b는, 계류중인 ASR 요청 B(102b)가 타임아웃 임계치를 충족하기 때문에, 랭커(310)가 계류중인 ASR 요청 B(102b)가 질의 프로세싱 스택(700)에 의해 프로세싱되는 것을 거절하는 것을 도시한다. 예컨대, 계류중인 ASR 요청 B(102b)는 그러한 낮은 우선순위 스코어(311)를 포함했을 수 있어서, ASR 요청 B(102b)가 리스트(322)의 맨 아래에 머물도록 야기하며, 그에 따라, ASR 요청 B(102b)는 이후의 시간에 새로운 ASR 요청(102)이 수신될 때 조차도 결코 프로세싱되지 않는다. 따라서, ASR 요청 B(102b)는 프리-프로세싱 백로그(320)로부터 드롭된다. 도 3b는, 새로운 ASR 요청 D(102d)가 계류중인 ASR 요청 C(102c)의 우선순위 스코어(311)보다는 더 높고 계류중인 ASR 요청 A(102a)의 우선순위 스코어보다는 더 낮은 우선순위 스코어(311)를 포함한다고 랭커(310)가 결정하는 것을 추가로 도시한다. 따라서, 랭커(310)는, ASR 요청 A(102a)가 여전히 가장 높은 랭킹(312)과 연관되고, ASR 요청 D(102d)가 이제 다음으로 가장 높은 랭킹(312)과 연관되며, ASR 요청 C(102c)가 이제 가장 낮은 스코어(312)와 연관되도록 하는, 계류중인 ASR 요청들(A(102a), D(102d), C(102c))의 재랭킹된 리스트(322)를 프리-프로세싱 백로그(320)에 제공한다. 따라서, 계류중인 ASR 요청(102)의 리스트(322)에서 ASR 요청 C(102c)보다 높게 랭킹된 새로운 ASR 요청 D(102d)는, 질의 프로세싱 스택(700)에 의한 프로세싱을 위해 백로그(320)에서 새로운 ASR 요청 D(102d)가 ASR 요청 C(102c)보다 우선하도록 야기한다. 그러나, ASR 요청 A(102a)는 질의 프로세싱 스택(700)에 의한 프로세싱을 위해 새로운 ASR 요청 D(102d)보다 우선한다. [0051] In some implementations, ranker 310 may cause any pending ASR requests 102 residing in pre-processing backlog 320 for a period of time that satisfies a timeout threshold to be processed by query processing stack 700 (e.g. , refuses to be processed by the backend-side ASR module 710). FIG. 3B shows ranker 310 rejecting pending ASR Request B 102b from being processed by query processing stack 700 because pending ASR Request B 102b meets a timeout threshold. do. For example, pending ASR Request B 102b may have included such a low priority score 311, causing ASR Request B 102b to stay at the bottom of the list 322, and thus ASR Request B 102b. B 102b is never processed even when a new ASR request 102 is received at a later time. Accordingly, ASR request B 102b is dropped from pre-processing backlog 320. 3B shows that the new ASR request D 102d has a priority score 311 that is higher than the priority score 311 of the pending ASR request C 102c and lower than the priority score 311 of the pending ASR request A 102a. ) is further shown to be determined by the ranker 310 to include. Accordingly, the ranker 310 determines that ASR request A 102a is still associated with the highest ranking 312, ASR request D 102d is now associated with the next highest ranking 312, and ASR request C( Pre-processing backlog a re-ranked list 322 of pending ASR requests (A(102a), D(102d), C(102c)) such that 102c) is now associated with the lowest score 312 Provided at (320). Accordingly, a new ASR request D 102d ranked higher than ASR request C 102c in the list 322 of pending ASR requests 102 is placed in the backlog 320 for processing by the query processing stack 700. causes the new ASR request D (102d) to take precedence over ASR request C (102c). However, ASR request A 102a takes precedence over new ASR request D 102d for processing by query processing stack 700.
[0052] 도 3c를 참조하면, 질의 프로세싱 스택(700)은, 프리-프로세싱 백 로그(320)에 캐싱된 계류중인 다음 ASR 요청(102)을 프로세싱하기 위해 이용 가능하다. ASR 요청 A(102a)가 프리-프로세싱 백로그(320)에서 프로세싱되기를 대기하는 계류중인 ASR 요청들(102)의 리스트(322)에서 가장 높은 랭킹(312)과 연관되기 때문에, 프리-프로세싱 백로그(320)는 ASR 요청 A(102a)를 프로세싱을 위해 질의 프로세싱 스택(700)에 제공한다. 따라서, ASR 요청 A(102a)는 백로그(320) 및 계류중인 ASR 요청들(102)의 리스트(322)로부터 제거된다. [0052] Referring to Figure 3C, query processing stack 700 is available for processing the next pending ASR request 102 cached in pre-processing backlog 320. Because ASR request A 102a is associated with the highest rank 312 in the list 322 of pending ASR requests 102 waiting to be processed in the pre-processing backlog 320, the pre-processing backlog 320 320 provides ASR request A 102a to query processing stack 700 for processing. Accordingly, ASR request A 102a is removed from the backlog 320 and the list 322 of pending ASR requests 102.
[0053] ASR 요청 A(102a)가 프로세싱을 위해 질의 프로세싱 스택(700)에 제공되는 것과 동시에, 음성 질의 QoS 관리자(300)의 랭커(310)는 대응하는 사용자 디바이스(200)로부터 새로운 ASR 요청 E(102e)를 수신하며, 그리고 프리-프로세싱 백로그(320)로부터 계류중인 ASR 요청들(D(102d), C(102c))의 리스트(322)를 피드백으로서 수신한다. 여기서, 랭커(310)는 새로운 ASR 요청 E(102e)와 연관된 콘텐츠 메타데이터(110)에 기반하여 새로운 ASR 요청 E(102e)에 대한 대응하는 우선순위 스코어(311)를 결정한 다음, 우선순위 스코어들에 기반하여, 새로운 ASR 요청 E(102e)와 함께 계류중인 ASR 요청들(D(102d), C(102c))을 재랭킹할 수 있다. 새로운 ASR 요청들(102)이 수신될 때 프리-프로세싱 백로그(320) 내의 계류중인 ASR 요청들(102)을 연속적으로 재랭킹하는 것은 반복적인 프로세스이며, 질의 프로세싱 스택(700)의 프로세싱 가용성에 의존한다. [0053] At the same time that the ASR request A 102a is presented to the query processing stack 700 for processing, the ranker 310 of the voice query QoS manager 300 receives a new ASR request E 102e from the corresponding user device 200. and receives as feedback a list 322 of pending ASR requests (D 102d, C 102c) from the pre-processing backlog 320. Here, the ranker 310 determines the corresponding priority score 311 for new ASR request E 102e based on the content metadata 110 associated with new ASR request E 102e and then calculates the priority scores. Based on, the pending ASR requests (D (102d), C (102c)) can be re-ranked along with the new ASR request E (102e). Successively re-ranking pending ASR requests 102 in the pre-processing backlog 320 as new ASR requests 102 are received is an iterative process, and may affect the processing availability of the query processing stack 700. It depends.
[0054] 도 4는 사용자 디바이스(200)에 온-디바이스 프로세싱 명령들(420)을 통신하는 QoS 관리자(300)의 개략도(400)를 도시하며, 이러한 온-디바이스 프로세싱 명령들은, 질의 프로세싱 스택에 고 부하 조건(high load condition)이 존재할 때, 사용자 디바이스(200)가 ASR 요청들(102)을 프로세싱을 위해 질의 프로세싱 스택(700)(예컨대, 질의 프로세싱 백엔드)에 전송할지 여부를 결정할 수 있게 한다. 고 부하 조건은, 질의 프로세싱 스택(700a)이 프로세싱을 위해 질의 프로세싱 스택(700)에 전송된 ASR 요청들(102)의 수에 있어서의 큰 트래픽 스파이크로 인해 오버로드되었음을 표시할 수 있다. QoS 관리자(300)는, 질의 프로세싱 스택(700a)이 프로세싱을 담당하는 음성 가능 사용자 디바이스들(200)의 집단의 전부 또는 그러한 집단의 선택된 서브-세트들에 온-디바이스 프로세싱 명령들(420)을 제공할 수 있다. 하나의 디바이스 타입(예컨대, 스마트 스피커)과 연관된 사용자 디바이스들(200)은 다른 디바이스 타입(예컨대, 스마트 폰)과 연관된 사용자 디바이스들(200)과 상이한 ASR 요청 명령들(420)을 수신할 수 있다. 온-디바이스 프로세싱 명령들(420)은, 질의 프로세싱 스택(700a)이 오버로드되었다고 사용자 디바이스(200)가 결정할 때, 온-디바이스로, 사용자 디바이스(200)에 의해 캡처되는 임의의 새로운 스피치 입력들(104)의 적어도 일부를 (예컨대, 온-디바이스 질의 프로세싱 스택(700b)에서) 국부적으로 프로세싱하기 위한 하나 이상의 기준들을 제공할 수 있다. [0054] 4 shows a schematic diagram 400 of a QoS manager 300 communicating on-device processing commands 420 to a user device 200, which may be used to address high load conditions on the query processing stack. When a high load condition exists, the user device 200 can determine whether to transmit the ASR requests 102 to the query processing stack 700 (e.g., query processing backend) for processing. A high load condition may indicate that query processing stack 700a is overloaded due to a large traffic spike in the number of ASR requests 102 sent to query processing stack 700 for processing. QoS manager 300 may issue on-device processing commands 420 to all or selected subsets of the population of voice capable user devices 200 for which query processing stack 700a is responsible for processing. can be provided. User devices 200 associated with one device type (e.g., smart speaker) may receive different ASR request commands 420 than user devices 200 associated with another device type (e.g., smart phone). . On-device processing instructions 420 are configured to, on-device, any new speech inputs captured by user device 200 when user device 200 determines that query processing stack 700a is overloaded. One or more criteria may be provided for processing at least a portion of 104 locally (e.g., in on-device query processing stack 700b).
[0055] 온-디바이스 프로세싱 명령들(420)은, ASR 요청들(102)과 연관된 콘텐츠 메타데이터(110)에 기반하여, 질의 프로세싱 스택(700a)이 오버로드될 때 ASR 요청들(102)을 질의 프로세싱 스택(700a)에 전송하기 위한 기준들을 제공할 수 있다. 일부 구현들에서, 온-디바이스 프로세싱 명령들(420)은, 사용자 디바이스(200)가 고 부하 조건 동안 ASR 요청(102)을 질의 프로세싱 스택(700a)에 송신하기 위해 콘텐츠 메타데이터(110)의 대응하는 부분들이 충족시켜야 하는 하나 이상의 임계치들을 제공한다. 예컨대, 온-디바이스 프로세싱 명령들(420)은, 핫워드 신뢰도 스코어가 충족시켜야 하는 핫워드 신뢰도 스코어 임계치 및/또는 스피치 입력(104)의 오디오 품질 스코어가 충족시켜야 하는 오디오 품질 스코어 임계치를 제공할 수 있다. 사용자 디바이스(200)는 일반적으로 디폴트 임계치들을 적용하지만, 온-디바이스 프로세싱 명령들(420)에 제공되는 임계치들은, 진짜라는 높은 신뢰도를 갖는 (또는 사용자에게 큰 영향을 미치는) ASR 요청들(102) 만이 프로세싱을 위해 질의 프로세싱 스택(700a)에 전송되도록 더 보수적일 수 있다. 예에서, 사용자 디바이스(200)는 일반적으로, 0.68보다 큰 핫워드 신뢰도 스코어들과 연관된 ASR 요청들(102)을 프로세싱을 위해 질의 프로세싱 스택(700a)에 전송할 수 있다. 그러나, 질의 프로세싱 스택(700a)이 오버로드될 때, 온-디바이스 프로세싱 명령들(420)은, ASR 요청들(102)이 프로세싱을 위해 질의 프로세싱 스택(700a)에 전송되기 위해서는 적어도 0.8의 핫워드 신뢰도 스코어들과 연관되어야 함을 표시할 수 있다. 온-디바이스 프로세싱 명령들(420)은 추가로, 임계치들 중 적어도 하나가 충족되지 않을 때 ASR 요청(102)을 드롭시키도록 사용자 디바이스(200)에게 지시할 수 있다. QoS 관리자(300)는 고 부하 조건이 존재할 때마다 즉시 온-디바이스 프로세싱 명령들(420)을 전송할 수 있거나, 또는 QoS 관리자(300)는, 나중에 고 부하 조건들이 발생할 때 사용자 디바이스들(200)이 온-디바이스 프로세싱 명령들(420)을 적용/실행할 수 있도록, 온-디바이스 프로세싱 명령들(420)을 사용자 디바이스들(200)에 언제라도 전송할 수 있다. 질의 프로세싱 스택(700a)이 오버로드되는 경우, 명령들(420)에 의해 정의되는 임계치들을 충족시키지 않는 오디오 품질을 갖는 ASR 요청들(102)을 필터링할 때 사용자 디바이스들(200)이 사용하기 위한 오디오 품질 임계치들이 유사하게 제공될 수 있다.[0055] On-device processing instructions 420 may, based on content metadata 110 associated with ASR requests 102, process ASR requests 102 into the query processing stack when query processing stack 700a is overloaded. Standards for transmission to 700a may be provided. In some implementations, on-device processing instructions 420 allow user device 200 to configure the corresponding content metadata 110 to send an ASR request 102 to query processing stack 700a during high load conditions. Provides one or more thresholds that must be met. For example, on-device processing instructions 420 may provide a hotword reliability score threshold that the hotword reliability score must meet and/or an audio quality score threshold that the audio quality score of speech input 104 must meet. there is. The user device 200 generally applies default thresholds, but the thresholds provided in the on-device processing instructions 420 may be used to determine whether ASR requests 102 have a high confidence that they are genuine (or have a significant impact on the user). One may be more conservative such that only the queries are sent to the query processing stack 700a for processing. In an example, user device 200 may generally transmit ASR requests 102 associated with hotword reliability scores greater than 0.68 to query processing stack 700a for processing. However, when query processing stack 700a is overloaded, on-device processing instructions 420 require a hotword of at least 0.8 for ASR requests 102 to be sent to query processing stack 700a for processing. It can be indicated that it should be associated with reliability scores. On-device processing instructions 420 may further instruct the user device 200 to drop the ASR request 102 when at least one of the thresholds is not met. The QoS manager 300 may send on-device processing commands 420 immediately whenever high load conditions exist, or the QoS manager 300 may send user devices 200 later when high load conditions occur. The on-device processing commands 420 may be transmitted to the user devices 200 at any time so that the on-device processing commands 420 can be applied/executed. If query processing stack 700a is overloaded, user devices 200 may use Audio quality thresholds may similarly be provided.
[0056] 도시된 예에서, 사용자 디바이스(200)는 스피치 입력(104)을 캡처하고, 스피치 입력(104)과 연관된 콘텐츠 메타데이터(110)를 생성한다. 예컨대, 사용자 디바이스(200)는, 소스들(220) 중 하나 이상으로부터 획득된 정보/데이터에 기반하여 콘텐츠 메타데이터(110)를 생성하도록 구성된 신호 생성기(218)를 실행시킨다. 사용자 디바이스들(200)에 의해 생성되는 콘텐츠 메타데이터(110)는 도 2를 참조하여 위에서 설명되었다. 스피치 입력(104) 및 연관된 콘텐츠 메타데이터(110)를 포함하는 대응하는 ASR 요청(102)을 전송(또는 국부적으로 프로세싱)하기 전에, 사용자 디바이스(200)는 질의 프로세싱 스택(700a)에 고 부하 조건이 존재하는지 여부를 결정할 수 있다. 일부 예들에서, 사용자 디바이스(200)는, 질의 프로세싱 스택(700a)에서의 오버로드 조건의 존재를 표시하는 통지(410)(예컨대, 오버로드 조건 상태 통지)를 QoS 관리자(300)로부터 즉시 수신한다. 부가적으로 또는 대안적으로, 사용자 디바이스(200)는, 질의 프로세싱 스택(700a)에서의 과거 및/또는 예측된 오버로드 조건들의 스케줄을 포함하는 통지들(410)을 수신할 수 있다. 사용자 디바이스(200)는 이러한 스케줄을 메모리 하드웨어(206) 상에 저장할 수 있다. [0056] In the example shown, user device 200 captures speech input 104 and generates content metadata 110 associated with speech input 104. For example, user device 200 executes signal generator 218 configured to generate content metadata 110 based on information/data obtained from one or more of sources 220 . Content metadata 110 generated by user devices 200 was described above with reference to FIG. 2 . Before transmitting (or locally processing) a corresponding ASR request 102 containing speech input 104 and associated content metadata 110, user device 200 may place a high load condition on query processing stack 700a. You can determine whether it exists or not. In some examples, user device 200 immediately receives notification 410 (e.g., an overload condition status notification) from QoS manager 300 indicating the presence of an overload condition in query processing stack 700a. . Additionally or alternatively, user device 200 may receive notifications 410 that include a schedule of past and/or predicted overload conditions in query processing stack 700a. User device 200 may store this schedule on memory hardware 206.
[0057] 다른 예들에서, 사용자 디바이스(200)는, 사용자 디바이스(200)에 의해 질의 프로세싱 스택(700a)에 통신된 이전 ASR 요청들(102)과 연관된 이력 데이터(250)(예컨대, ASR 요청 이력)를 획득함으로써, 질의 프로세싱 스택(700a)에 오버로드 조건이 존재한다고 결정한다. 이력 데이터(250)는 사용자 디바이스(200)의 메모리 하드웨어(206) 상에 저장(또는 원격으로 저장)될 수 있다. 이력 데이터(250)는, 사용자 디바이스(200) 및/또는 다른 사용자 디바이스들(200)이 질의 프로세싱 스택(700a)이 오버로드되었을 때의 시나리오들을 경험한 특정 날짜들, 요일들, 시간들 등을 표시할 수 있다. 예컨대, 사용자 디바이스(200)는, 지난 2주 동안 평일 밤 대략 7:36 pm마다, 질의 프로세싱 스택에서 오버로드 조건을 경험했다. 이 예에서, Jeopardy 쇼(show) 동안의 텔레비전 광고는, 지정된 핫워드("Hey Google")와 실질적으로 유사하게 들리는 억양으로 배우가 말한 어구("Hey poodle")를 포함할 수 있으며, 그 결과 다수의 가정들에서 음성 가능 디바이스들의 잘못된 트리거링을 초래할 수 있다. [0057] In other examples, user device 200 obtains historical data 250 (e.g., ASR request history) associated with previous ASR requests 102 communicated by user device 200 to query processing stack 700a. By doing so, it is determined that an overload condition exists in the query processing stack 700a. Historical data 250 may be stored on memory hardware 206 of user device 200 (or stored remotely). Historical data 250 may include specific dates, days of the week, times, etc., when user device 200 and/or other user devices 200 experienced scenarios when query processing stack 700a was overloaded. It can be displayed. For example, user device 200 has experienced an overload condition in the query processing stack approximately every weekday night at 7:36 pm for the past two weeks. In this example, a television commercial during the Jeopardy show may include a phrase (“Hey poodle”) spoken by an actor with an intonation that sounds substantially similar to a designated hotword (“Hey Google”), resulting in This can lead to incorrect triggering of voice enabled devices in many homes.
[0058] 부가적으로, 온-디바이스 프로세싱 명령들(420)은, 질의 프로세싱 스택(700a)이 오버로드되었다고 사용자 디바이스(200)가 결정할 때, 온-디바이스로, 사용자 디바이스(200)에 의해 캡처된 임의의 새로운 스피치 입력들(104)의 적어도 일부를 국부적으로 프로세싱하기 위한 하나 이상의 기준들을 제공할 수 있다. 예컨대, 임의의 새로운 스피치 입력들(104)의 적어도 일부를 국부적으로 프로세싱하기 위한 하나 이상의 기준들은, 사용자 디바이스(200)에게: 사용자 디바이스(200) 상에 상주하는 로컬 ASR 모듈(200n)(예컨대, 이용 가능한 경우)을 사용하여 새로운 스피치 입력(104)을 전사하는 것; 새로운 스피치 입력(104)에 대응하는 음성 질의를 결정하기 위해 새로운 스피치 입력(104)의 전사를 해석하는 것; 사용자 디바이스(200)가 새로운 스피치 입력(104)에 대응하는 음성 질의와 연관된 액션을 실행할 수 있는지 여부를 결정하는 것; 또는 사용자 디바이스(200)가 음성 질의와 연관된 액션을 실행할 수 없을 때, 스피치 입력(104)의 전사를 질의 프로세싱 스택(700a)에 송신하는 것 중 적어도 하나를 하도록 지시하는 것을 포함할 수 있다. 일부 구현들에서, 온-디바이스 프로세싱 명령들(420)에 의해 제공되는 하나 이상의 기준들은, 질의 프로세싱 스택(700a)이 ASR 요청(102)의 다른 부분들을 프로세싱하는 동안, 사용자 디바이스(200)에 의한 로컬 프로세싱을 위해 ASR 요청(102)의 일부 부분들을 위임한다. 예컨대, 사용자 디바이스(200)는, 질의 프로세싱 스택(700a)이 텍스트로 사용자 디바이스(200)에 ASR 응답을 제공할 수 있도록 클라이언트-측 TTS 모듈을 포함할 수 있으며, 그리고 사용자 디바이스(200)는 대응하는 합성된 스피치를 생성하기 위해 클라이언트-측 TTS 모듈을 사용할 수 있다. 이러한 시나리오들은, 서버-측 질의 프로세싱 스택(700a)이 오버로드 조건 동안 TTS 응답을 생성해야만 하는 것을 경감(alleviate)시킬 것이다. [0058] Additionally, on-device processing instructions 420 may be used to process any captured by user device 200, on-device, when user device 200 determines that query processing stack 700a is overloaded. One or more criteria may be provided for locally processing at least some of the new speech inputs 104. For example, one or more criteria for locally processing at least a portion of any new speech inputs 104 may provide to user device 200: a local ASR module 200n residing on user device 200 (e.g., transcribing new speech input 104 using (if available); interpreting the transcription of the new speech input 104 to determine a speech query corresponding to the new speech input 104; determining whether user device 200 can execute an action associated with a voice query corresponding to new speech input 104; or transmitting a transcription of the speech input 104 to the query processing stack 700a when the user device 200 is unable to perform an action associated with the voice query. In some implementations, one or more criteria provided by on-device processing instructions 420 may be used by user device 200 while query processing stack 700a processes other portions of ASR request 102. Delegate some portions of the ASR request 102 for local processing. For example, user device 200 may include a client-side TTS module such that query processing stack 700a can provide an ASR response in text to user device 200, and user device 200 responds. You can use a client-side TTS module to generate synthesized speech. These scenarios will alleviate the server-side query processing stack 700a from having to generate a TTS response during an overload condition.
[0059] 도 5는, 질의 프로세싱 스택(700a)에서의 프로세싱 가용성에 기반하여 질의 프로세싱 스택(700a)(예컨대, 질의 프로세싱 스택(700a)의 백엔드-측 ASR 모듈(710a))에서 계류중인 ASR 요청들(102)을 프로세싱하는 방법(500)에 대한 동작들의 예시적인 어레인지먼트의 흐름도이다. 동작(502)에서, 방법(500)은, 질의 프로세싱 스택(700a)의 데이터 프로세싱 하드웨어(144)(예컨대, 질의 프로세싱 백엔드)에서, 사용자 디바이스(200)로부터 ASR 요청(102)을 수신하는 단계를 포함한다. ASR 요청(102)은, 음성 질의를 포함하는, 사용자 디바이스(200)에 의해 캡처되는 스피치 입력(104), 및 스피치 입력(104)과 연관된 콘텐츠 메타데이터(110)를 포함한다. 도 2를 참조하여 위에서 설명된 바와 같이, 콘텐츠 메타데이터(110)는 사용자 디바이스(200)에 의해 생성된다. 동작(504)에서, 방법(500)은, 데이터 프로세싱 하드웨어(144)에 의해, 스피치 입력과 연관된 콘텐츠 메타데이터(110)에 기반하여, ASR 요청(102)에 대한 우선순위 스코어(311)를 결정하는 단계를 포함한다. [0059] 5 illustrates pending ASR requests 102 in query processing stack 700a (e.g., backend-side ASR module 710a of query processing stack 700a) based on processing availability in query processing stack 700a. ) is a flowchart of an example arrangement of operations for a method 500 of processing. At operation 502, method 500 includes receiving, at data processing hardware 144 (e.g., a query processing backend) of query processing stack 700a, an ASR request 102 from user device 200. Includes. ASR request 102 includes speech input 104 captured by user device 200, including a voice query, and content metadata 110 associated with speech input 104. As described above with reference to FIG. 2 , content metadata 110 is created by user device 200 . At operation 504, method 500 determines, by data processing hardware 144, a priority score 311 for ASR request 102 based on content metadata 110 associated with the speech input. It includes steps to:
[0060] 동작(506)에서, 방법(500)은, 데이터 프로세싱 하드웨어(144)에 의해, 대응하는 우선순위 스코어(311)를 각각 갖는 계류중인 ASR 요청들(102)의 프리-프로세싱 백로그(320)에 ASR 요청(102)을 캐싱하는 단계를 포함한다. 도 3a 내지 도 3c를 참조하여 위에서 설명된 바와 같이, 프리-프로세싱 백로그(320) 내의 계류중인 ASR 요청들(102)은 우선순위 스코어들(311)의 순위로 랭킹된다. 프리-프로세싱 백로그(320)는 원격 시스템(140)의 저장 자원들(예컨대, 메모리 하드웨어)(146) 상에 상주할 수 있다. 동작(508)에서, 방법(500)은, 데이터 프로세싱 하드웨어(144)에 의해, 백엔드-측 ASR 모듈(710)의 프로세싱 가용성에 기반하여, 프리-프로세싱 백로그(320)로부터, 계류중인 ASR 요청들(102) 중 하나 이상의 계류중인 ASR 요청들(102)을 백엔드-측 ASR 모듈(710)(또는 질의 프로세싱 스택(700a)의 다른 모듈)에 제공하는 단계를 포함한다. 도 3a 내지 도 3c를 참조하여 위에서 설명된 바와 같이, 더 높은 우선순위 스코어들(311)과 연관된 백로그(320) 내의 계류중인 ASR 요청들(102)은 더 낮은 우선순위 스코어들(311)과 연관된 계류중인 ASR 요청들(102) 전에 백엔드-측 ASR 모듈(710)에 의해 프로세싱된다. [0060] At operation 506, the method 500 causes the data processing hardware 144 to add to the pre-processing backlog 320 of pending ASR requests 102 each having a corresponding priority score 311. and caching the ASR request (102). As described above with reference to FIGS. 3A-3C, pending ASR requests 102 in pre-processing backlog 320 are ranked by priority scores 311. Pre-processing backlog 320 may reside on storage resources (e.g., memory hardware) 146 of remote system 140. At operation 508, the method 500 determines, by the data processing hardware 144, a pending ASR request from the pre-processing backlog 320 based on the processing availability of the backend-side ASR module 710. and providing one or more of the pending ASR requests 102 to the backend-side ASR module 710 (or another module of the query processing stack 700a). As described above with reference to FIGS. 3A-3C , pending ASR requests 102 in backlog 320 associated with higher priority scores 311 are associated with lower priority scores 311 . Processed by the backend-side ASR module 710 before associated pending ASR requests 102.
[0061] 도 6은, 서버-기반 질의 프로세싱 스택(700a)이 오버로드될 때(예컨대, 스택(700a)에서 오버로드 조건이 존재할 때) 온-디바이스 프로세싱 명령들을 실행하는 방법(600)에 대한 동작들의 예시적인 어레인지먼트의 흐름도이다. 방법(600)은 사용자 디바이스(200)의 데이터 프로세싱 하드웨어(204) 상에서 실행될 수 있다. 동작(602)에서, 방법(600)은 사용자 디바이스(200)에서 ASR 요청(102)을 생성하는 단계를 포함한다. 여기서, ASR 요청(102)은, 음성 질의를 포함하는, 사용자 디바이스(200)에 의해 캡처되는 스피치 입력(104)뿐만 아니라, 사용자 디바이스(200)에 의해 생성되고 스피치 입력(104)과 연관된 콘텐츠 메타데이터(110)를 포함한다. 스피치 입력들(104)과 연관된 콘텐츠 메타데이터(110)를 생성하는 것은 도 2를 참조하여 위에서 설명되었다. 동작(604)에서, 방법은, 사용자 디바이스(200)에서, 서버-측 질의 프로세싱 스택(700a)으로부터 온-디바이스 프로세싱 명령들(420)을 수신하는 단계를 포함한다. 예컨대, 도 4는 사용자 디바이스(200)가 온-디바이스 프로세싱 명령들(420)을 수신하는 것을 도시한다. 온-디바이스 프로세싱 명령들(420)은, ASR 요청들(102)과 연관된 콘텐츠 메타데이터(110)에 기반하여, 질의 프로세싱 스택(700a)이 오버로드될 때 ASR 요청들(102)을 질의 프로세싱 스택(700a)에 전송하기 위한 기준들을 제공할 수 있다. 일부 구현들에서, 온-디바이스 프로세싱 명령들(420)은, 사용자 디바이스(200)가 오버로드 조건 동안 ASR 요청(102)을 질의 프로세싱 스택(700a)에 송신하기 위해 콘텐츠 메타데이터(110)의 대응하는 부분들이 충족시켜야 하는 하나 이상의 임계치들을 제공한다.[0061] 6 illustrates operations for a method 600 of executing on-device processing instructions when server-based query processing stack 700a is overloaded (e.g., when an overload condition exists in stack 700a). This is a flow chart of the arrangement. Method 600 may be executed on data processing hardware 204 of user device 200. At operation 602 , method 600 includes generating an ASR request 102 at user device 200 . Here, the ASR request 102 includes a speech input 104 captured by the user device 200, including a voice query, as well as content metadata generated by the user device 200 and associated with the speech input 104. Includes data 110. Generating content metadata 110 associated with speech inputs 104 was described above with reference to FIG. 2 . At operation 604, the method includes receiving, at the user device 200, on-device processing instructions 420 from a server-side query processing stack 700a. For example, Figure 4 shows user device 200 receiving on-device processing commands 420. On-device processing instructions 420 may, based on content metadata 110 associated with ASR requests 102, process ASR requests 102 into the query processing stack when query processing stack 700a is overloaded. Standards for transmission to 700a may be provided. In some implementations, on-device processing instructions 420 cause user device 200 to send an ASR request 102 to query processing stack 700a during an overload condition. Provides one or more thresholds that must be met.
[0062] 동작(606)에서, 방법(600)은 또한, 사용자 디바이스(200)에 의해, 서버-측 질의 프로세싱 스택(700a)이 오버로드되었는지 여부를 결정하는 단계를 포함한다. 도 4를 참조하여 위에서 더 상세히 설명된 바와 같이, 사용자 디바이스(200)는, 질의 프로세싱 스택(700a)으로부터 통지(410)를 수신할 시, 또는 사용자 디바이스(200)(및/또는 다른 사용자 디바이스들)에 의해 질의 프로세싱 스택(700a)에 통신된 이전 ASR 요청들과 연관된 이력 데이터(250)(예컨대, 예측-기반) 중 적어도 하나에 기반하여 오버로드 조건을 결정할 수 있다. 통지(410a)는, 현재의 오버로드 조건을 표시하기 위해 질의 프로세싱 스택(700a)에 의해 즉시 전송되는 오버로드 조건 상태 통지, 및/또는 질의 프로세싱 스택(700a)에서의 과거 및/또는 예측된 오버로드 조건들의 스케줄을 포함할 수 있다. 동작(608)에서, 질의 프로세싱 스택(700a)이 오버로드되었다고 사용자 디바이스(200)가 결정할 때, 방법(600)은, 사용자 디바이스(200)에 의해, 온-디바이스 프로세싱 명령들(420)을 실행하는 단계를 포함한다. 사용자 디바이스(200)에 의해 온-디바이스 프로세싱 명령들(420)을 실행하는 것은 도 4를 참조하여 위에서 설명되었다. [0062] At operation 606 , method 600 also includes determining whether server-side query processing stack 700a has been overloaded by user device 200 . As described in more detail above with reference to FIG. 4 , upon receiving notification 410 from query processing stack 700a, user device 200 (and/or other user devices) ) may determine the overload condition based on at least one of the historical data 250 (e.g., prediction-based) associated with previous ASR requests communicated to the query processing stack 700a. Notification 410a is an overload condition status notification sent immediately by query processing stack 700a to indicate a current overload condition, and/or past and/or predicted overload conditions in query processing stack 700a. May include a schedule of load conditions. At operation 608, when the user device 200 determines that the query processing stack 700a is overloaded, the method 600 includes executing, by the user device 200, on-device processing instructions 420. It includes steps to: Executing on-device processing instructions 420 by user device 200 was described above with reference to FIG. 4 .
[0063] 소프트웨어 애플리케이션(즉, 소프트웨어 자원)은 컴퓨팅 디바이스로 하여금 작업을 수행하게 하는 컴퓨터 소프트웨어를 지칭할 수 있다. 일부 예들에서, 소프트웨어 애플리케이션은 "애플리케이션", "앱" 또는 "프로그램"으로 지칭될 수 있다. 예시적인 애플리케이션들은 시스템 진단 애플리케이션들, 시스템 관리 애플리케이션들, 시스템 유지 보수 애플리케이션들, 워드 프로세싱 애플리케이션들, 스프레드 시트 애플리케이션들, 메시징 애플리케이션들, 미디어 스트리밍 애플리케이션들, 소셜 네트워킹 애플리케이션들, 및 게이밍 애플리케이션들을 포함한다(그러나 이에 제한되지 않음).[0063] A software application (i.e., software resource) may refer to computer software that causes a computing device to perform a task. In some examples, a software application may be referred to as an “application,” “app,” or “program.” Exemplary applications include system diagnostic applications, system management applications, system maintenance applications, word processing applications, spreadsheet applications, messaging applications, media streaming applications, social networking applications, and gaming applications. (but not limited to this).
[0064] 비-일시적인 메모리는 컴퓨팅 디바이스에 의한 사용을 위해 일시적 또는 영구적으로 프로그램들(예컨대, 명령들의 시퀀스들) 또는 데이터(예컨대, 프로그램 상태 정보)를 저장하기 위해 사용되는 물리적 디바이스들일 수 있다. 비-일시적인 메모리는 휘발성 및/또는 비-휘발성 어드레싱 가능한 반도체 메모리일 수 있다. 비휘발성 메모리의 예들은 플래시 메모리 및 ROM(read-only memory)/PROM(programmable read-only memory)/EPROM(erasable programmable read-only memory)/EEPROM(electronically erasable programmable read-only memory)(예컨대, 통상적으로 부트 프로그램들과 같은 펌웨어에 사용됨)을 포함한다(그러나, 이에 제한되지 않음). 휘발성 메모리의 예들은 RAM(Random Access Memory), DRAM(Dynamic Random Access Memory), SRAM(Static Random Access Memory), PCM(Phase Change Memory)뿐만 아니라 디스크들 또는 테이프들을 포함한다(그러나, 이에 제한되지 않음).[0064] Non-transitory memory may be physical devices used to temporarily or permanently store programs (eg, sequences of instructions) or data (eg, program state information) for use by a computing device. Non-transitory memory may be volatile and/or non-volatile addressable semiconductor memory. Examples of non-volatile memory include flash memory and read-only memory (ROM)/programmable read-only memory (PROM)/erasable programmable read-only memory (EPROM)/electronically erasable programmable read-only memory (EEPROM) (e.g. (used in firmware such as boot programs), including (but not limited to). Examples of volatile memory include (but are not limited to) random access memory (RAM), dynamic random access memory (DRAM), static random access memory (SRAM), phase change memory (PCM), as well as disks or tapes. ).
[0065] 도 7은 본 문서에서 설명되는 시스템들 및 방법들을 구현하기 위해 사용될 수 있는 예시적인 컴퓨팅 디바이스(700)의 개략도이다. 컴퓨팅 디바이스(700)는 랩톱들, 데스크톱들, 워크스테이션들, 개인 휴대 정보 단말들, 서버들, 블레이드 서버들, 메인프레임들 및 다른 적절한 컴퓨터들과 같은 다양한 형태들의 디지털 컴퓨터들을 표현하도록 의도된다. 여기에 도시된 컴포넌트들, 이들의 연결들 및 관계들, 및 기능들은 오직 예시일 뿐이며, 본 문헌에서 설명 및/또는 청구된 발명들의 구현들을 제한하려는 의도가 아니다.[0065] FIG. 7 is a schematic diagram of an example computing device 700 that can be used to implement the systems and methods described herein. Computing device 700 is intended to represent various types of digital computers, such as laptops, desktops, workstations, personal digital assistants, servers, blade servers, mainframes, and other suitable computers. The components, their connections and relationships, and functions shown herein are illustrative only and are not intended to limit implementations of the inventions described and/or claimed in this document.
[0066] 컴퓨팅 디바이스(700)는 프로세서(711)(예컨대, 데이터 프로세싱 하드웨어(144)), 메모리(721)(예컨대, 메모리 하드웨어(146)), 저장 디바이스(731), 메모리(721) 및 고속 확장 포트들(750)에 연결되는 고속 인터페이스/제어기(740), 및 저속 버스(770) 및 저장 디바이스(731)에 연결되는 저속 인터페이스/제어기(760)를 포함한다. 컴포넌트들(711, 721, 731, 740, 750, 760) 각각은 다양한 버스들을 사용하여 상호연결되며, 공통 마더보드 상에 또는 적절한 다른 방식들로 장착될 수 있다. 프로세서(711)는, 고속 인터페이스(740)에 커플링된 디스플레이(780)와 같은 외부 입력/출력 디바이스 상의 GUI(graphical user interface)에 대한 그래픽 정보를 디스플레이하기 위해 메모리(721)에 또는 저장 디바이스(731) 상에 저장된 명령들을 포함하는, 컴퓨팅 디바이스(700) 내에서의 실행을 위한 명령들을 프로세싱할 수 있다. 다른 구현들에서, 다수의 프로세서들 및/또는 다수의 버스들이 다수의 메모리들 및 메모리의 타입들과 함께 적절하게 사용될 수 있다. 또한, 다수의 컴퓨팅 디바이스들(700)은 (예컨대, 서버 뱅크, 블레이드 서버들의 그룹, 또는 다중 프로세서 시스템으로서) 필요한 동작들의 부분들을 제공하는 각각의 디바이스와 연결될 수 있다.[0066] Computing device 700 includes a processor 711 (e.g., data processing hardware 144), memory 721 (e.g., memory hardware 146), storage device 731, memory 721, and high-speed expansion ports. a high-speed interface/controller 740 coupled to 750, and a low-speed interface/controller 760 coupled to low-speed bus 770 and storage device 731. Components 711, 721, 731, 740, 750, 760 are each interconnected using various buses and may be mounted on a common motherboard or in other suitable manners. Processor 711 may store graphical information in memory 721 or a storage device ( Instructions for execution within computing device 700 may be processed, including instructions stored on 731). In other implementations, multiple processors and/or multiple buses may be suitably used with multiple memories and types of memory. Additionally, multiple computing devices 700 may be connected (eg, as a server bank, a group of blade servers, or a multiprocessor system) with each device providing portions of the required operations.
[0067] 메모리(721)는 컴퓨팅 디바이스(700) 내에 비-일시적으로 정보를 저장한다. 메모리(721)는 컴퓨터 판독 가능 매체, 휘발성 메모리 유닛(들) 또는 비휘발성 메모리 유닛(들)일 수 있다. 비-일시적인 메모리(721)는 컴퓨팅 디바이스(700)에 의한 사용을 위해 일시적 또는 영구적으로 프로그램들(예컨대, 명령들의 시퀀스들) 또는 데이터(예컨대, 프로그램 상태 정보)를 저장하기 위해 사용되는 물리적 디바이스들일 수 있다. 비휘발성 메모리의 예들은 플래시 메모리 및 ROM(read-only memory)/PROM(programmable read-only memory)/EPROM(erasable programmable read-only memory)/EEPROM(electronically erasable programmable read-only memory)(예컨대, 통상적으로 부트 프로그램들과 같은 펌웨어에 사용됨)을 포함한다(그러나, 이에 제한되지 않음). 휘발성 메모리의 예들은 RAM(Random Access Memory), DRAM(Dynamic Random Access Memory), SRAM(Static Random Access Memory), PCM(Phase Change Memory)뿐만 아니라 디스크들 또는 테이프들을 포함한다(그러나, 이에 제한되지 않음).[0067] Memory 721 stores information non-transitory within computing device 700. Memory 721 may be a computer-readable medium, volatile memory unit(s), or non-volatile memory unit(s). Non-transitory memory 721 may be physical devices used to temporarily or permanently store programs (e.g., sequences of instructions) or data (e.g., program state information) for use by computing device 700. You can. Examples of non-volatile memory include flash memory and read-only memory (ROM)/programmable read-only memory (PROM)/erasable programmable read-only memory (EPROM)/electronically erasable programmable read-only memory (EEPROM) (e.g., conventional memory). (used in firmware such as boot programs), including (but not limited to). Examples of volatile memory include (but are not limited to) random access memory (RAM), dynamic random access memory (DRAM), static random access memory (SRAM), phase change memory (PCM), as well as disks or tapes. ).
[0068] 저장 디바이스(731)는 컴퓨팅 디바이스(700)에 대한 대용량 저장을 제공할 수 있다. 일부 구현들에서, 저장 디바이스(731)는 컴퓨터 판독 가능 매체이다. 다양한 다른 구현들에서, 저장 디바이스(731)는 플로피 디스크 디바이스, 하드 디스크 디바이스, 광 디스크 디바이스 또는 테이프 디바이스, 플래시 메모리 또는 다른 유사한 솔리드 스테이트 메모리 디바이스, 또는 저장 영역 네트워크 또는 다른 구성들의 디바이스들을 포함하는 디바이스들의 어레이일 수 있다. 추가적인 구현들에서, 컴퓨터 프로그램 제품은 정보 캐리어에서 유형적으로 구현된다. 컴퓨터 프로그램 제품은 전술된 것들과 같이, 실행될 때, 하나 이상의 방법들을 수행하는 명령들을 포함한다. 정보 캐리어는 메모리(721), 저장 디바이스(731) 또는 프로세서(711) 상의 메모리와 같은 컴퓨터 또는 머신 판독 가능 매체이다.[0068] Storage device 731 may provide mass storage for computing device 700. In some implementations, storage device 731 is a computer-readable medium. In various other implementations, storage device 731 may be a device including a floppy disk device, a hard disk device, an optical disk device or tape device, flash memory or other similar solid state memory device, or a storage area network or other configurations of devices. It may be an array of . In further implementations, the computer program product is tangibly embodied in an information carrier. A computer program product includes instructions that, when executed, perform one or more methods, such as those described above. The information carrier is a computer or machine-readable medium, such as memory 721, storage device 731, or memory on processor 711.
[0069] 고속 제어기(740)는 컴퓨팅 디바이스(700)에 대한 대역폭 집약적인 동작들을 관리하는 반면, 저속 제어기(760)는 더 낮은 대역폭 집약적 동작들을 관리한다. 이러한 업무 할당은 단지 예시적이다. 일부 구현들에서, 고속 제어기(740)는 (예컨대, 그래픽 프로세서 또는 가속기를 통해) 메모리(721), 디스플레이(780)에 그리고 다양한 확장 카드들(미도시)을 수용할 수 있는 고속 확장 포트들(750)에 커플링된다. 일부 구현들에서, 저속 제어기(760)는 저장 디바이스(731) 및 저속 확장 포트(790)에 커플링된다. 다양한 통신 포트들(예컨대, USB, 블루투스, 이더넷, 무선 이더넷)을 포함할 수 있는 저속 확장 포트(790)는 키보드, 포인팅 디바이스, 스캐너와 같은 하나 이상의 입력/출력 디바이스들, 또는 예컨대, 네트워크 어댑터를 통해 스위치 또는 라우터와 같은 네트워킹 디바이스에 커플링될 수 있다.[0069] High-speed controller 740 manages bandwidth-intensive operations for computing device 700, while low-speed controller 760 manages lower bandwidth-intensive operations. These task assignments are exemplary only. In some implementations, high-speed controller 740 is connected to memory 721 (e.g., via a graphics processor or accelerator), display 780, and high-speed expansion ports (e.g., via a graphics processor or accelerator) that can accommodate various expansion cards (not shown). 750). In some implementations, low-speed controller 760 is coupled to storage device 731 and low-speed expansion port 790. Low-speed expansion port 790, which may include various communication ports (e.g., USB, Bluetooth, Ethernet, wireless Ethernet), can connect one or more input/output devices such as a keyboard, pointing device, scanner, or, e.g., a network adapter. It can be coupled to a networking device such as a switch or router.
[0070] 컴퓨팅 디바이스(700)는 도면에 도시된 바와 같이 다수의 상이한 형태들로 구현될 수 있다. 예컨대, 이는, 표준 서버(700a)로서 또는 그러한 서버들(701)의 그룹에서 여러번, 랩톱 컴퓨터(703)로서 또는 랙 서버 시스템(705)의 일부로서 구현될 수 있다.[0070] Computing device 700 may be implemented in a number of different forms as shown in the figure. For example, it could be implemented as a standard server 700a or multiple times in a group of such servers 701, as a laptop computer 703, or as part of a rack server system 705.
[0071] 본원에 설명된 시스템들 및 기술들의 다양한 구현들은 디지털 전자 및/또는 광학 회로부, 집적 회로부, 특별히 설계된 ASIC들(application specific integrated circuits), 컴퓨터 하드웨어, 펌웨어, 소프트웨어 및/또는 이들의 조합들로 실현될 수 있다. 이러한 다양한 구현들은, 저장 시스템, 적어도 하나의 입력 디바이스 및 적어도 하나의 출력 디바이스로부터 데이터 및 명령들을 수신하고 그에 데이터 및 명령들을 송신하도록 커플링된, 특수 목적 또는 범용일 수 있는 적어도 하나의 프로그래밍가능 프로세서를 포함하는 프로그래밍가능 시스템 상에서 실행 가능한 및/또는 해석가능한 하나 이상의 컴퓨터 프로그램들로 구현을 포함할 수 있다.[0071] Various implementations of the systems and techniques described herein may be realized with digital electronic and/or optical circuitry, integrated circuitry, specially designed application specific integrated circuits (ASICs), computer hardware, firmware, software, and/or combinations thereof. You can. These various implementations include at least one programmable processor, which may be special purpose or general purpose, coupled to receive and transmit data and instructions to a storage system, at least one input device, and at least one output device. It may include implementation as one or more computer programs executable and/or interpretable on a programmable system including.
[0072] 이러한 컴퓨터 프로그램들(또한 프로그램들, 소프트웨어, 소프트웨어 애플리케이션들 또는 코드로 공지됨)은 프로그래밍가능한 프로세서에 대한 머신 명령들을 포함하고, 하이 레벨 절차 및/또는 객체 지향 프로그래밍 언어 및/또는 어셈블리/기계 언어로 구현될 수 있다. 본원에 사용되는 바와 같이, "머신 판독 가능 매체" 및 "컴퓨터 판독 가능 매체"라는 용어들은 머신 판독 가능 신호로서 머신 명령들을 수신하는 머신 판독 가능 매체를 포함하는, 머신 명령들 및/또는 데이터를 프로그래밍가능 프로세서에 제공하기 위해 사용되는 임의의 컴퓨터 프로그램 제품, 비-일시적인 컴퓨터 판독 가능 매체, 장치 및/또는 디바이스(예컨대, 자기 디스크들, 광 디스크들, 메모리, PLD(Programmable Logic Device)들)를 지칭한다. "머신 판독 가능 신호"라는 용어는 머신 명령들 및/또는 데이터를 프로그래밍가능 프로세서에 제공하기 위해 사용되는 임의의 신호를 지칭한다.[0072] These computer programs (also known as programs, software, software applications or code) contain machine instructions for a programmable processor and are written in a high-level procedural and/or object-oriented programming language and/or assembly/machine language. It can be implemented. As used herein, the terms “machine-readable medium” and “computer-readable medium” refer to a machine-readable medium that receives machine instructions as machine-readable signals for programming machine instructions and/or data. Refers to any computer program product, non-transitory computer-readable medium, apparatus and/or device (e.g., magnetic disks, optical disks, memory, Programmable Logic Devices (PLDs)) used to provide to a capable processor. do. The term “machine readable signal” refers to any signal used to provide machine instructions and/or data to a programmable processor.
[0073] 본 명세서에서 설명된 프로세스들 및 로직 흐름들은 입력 데이터에 대해 동작하고 출력을 생성함으로써 기능들을 수행하기 위해 하나 이상의 컴퓨터 프로그램들을 실행하는, 데이터 프로세싱 하드웨어로 또한 지칭되는 하나 이상의 프로그래밍가능 프로세서들에 의해 수행될 수 있다. 예컨대, FPGA(field programmable gate array) 또는 ASIC(application specific integrated circuit)와 같은 특수 목적 로직 회로부에 의해 프로세스들 및 로직 흐름들이 또한 수행될 수 있다. 컴퓨터 프로그램의 실행에 적합한 프로세서들은 예시의 방식으로, 범용 및 특수 목적 마이크로프로세서들 둘 모두, 및 임의의 종류의 디지털 컴퓨터의 임의의 하나 이상의 프로세서들을 포함한다. 일반적으로, 프로세서는 판독 전용 메모리 또는 랜덤 액세스 메모리 또는 둘 모두로부터 명령어들 및 데이터를 수신할 것이다. 컴퓨터의 필수 엘리먼트들은 명령들을 수행하기 위한 프로세서 및 명령들 및 데이터를 저장하기 위한 하나 이상의 메모리 디바이스들이다. 일반적으로, 컴퓨터는 또한 데이터를 저장하기 위한 하나 이상의 대용량 저장 디바이스들, 예컨대, 자기, 자기 광학 디스크들 또는 광학 디스크들을 포함하거나, 또는 이들로부터 데이터를 수신하거나 이들에 데이터를 전송하거나 또는 둘 모두를 위해 동작가능하게 커플링될 것이다. 그러나, 컴퓨터는 이러한 디바이스들을 가질 필요가 없다. 컴퓨터 프로그램 명령들 및 데이터를 저장하기에 적합한 컴퓨터 판독 가능 매체들은, 예컨대, 반도체 메모리 디바이스들, 예컨대, EPROM, EEPROM 및 플래시 메모리 디바이스들; 자기 디스크들, 예컨대, 내부 하드 디스크들 또는 착탈식 디스크들; 자기-광학 디스크들; 및 CD-ROM 및 DVD-ROM 디스크들을 포함하는 모든 형태들의 비휘발성 메모리, 매체들 및 메모리 디바이스들을 포함한다. 프로세서 및 메모리는 특수 목적 로직 회로에 의해 보완되거나 그에 통합될 수 있다.[0073] The processes and logic flows described herein are performed by one or more programmable processors, also referred to as data processing hardware, that execute one or more computer programs to perform functions by operating on input data and producing output. It can be. Processes and logic flows may also be performed by special purpose logic circuitry, for example, a field programmable gate array (FPGA) or an application specific integrated circuit (ASIC). Processors suitable for executing a computer program include, by way of example, both general-purpose and special-purpose microprocessors, and any one or more processors of any type of digital computer. Typically, a processor will receive instructions and data from read-only memory or random access memory, or both. The essential elements of a computer are a processor to carry out instructions and one or more memory devices to store instructions and data. Typically, a computer also includes one or more mass storage devices, such as magnetic, magneto-optical or optical disks, for storing data, receiving data from or transmitting data to them, or both. will be operably coupled for However, the computer does not need to have these devices. Computer-readable media suitable for storing computer program instructions and data include, for example, semiconductor memory devices such as EPROM, EEPROM, and flash memory devices; magnetic disks, such as internal hard disks or removable disks; magneto-optical disks; and all forms of non-volatile memory, media and memory devices, including CD-ROM and DVD-ROM disks. The processor and memory may be supplemented by or integrated with special purpose logic circuitry.
[0074] 사용자와의 상호작용을 제공하기 위해, 본 개시내용의 하나 이상의 양상들은 디스플레이 디바이스, 예컨대, 사용자에게 정보를 디스플레이하기 위한 CRT(cathode ray tube), LCD(liquid crystal display) 모니터 또는 터치 스크린, 및 선택적으로 키보드 및 포인팅 디바이스, 예컨대, 사용자가 컴퓨터에 입력을 제공할 수 있도록 하는 마우스 또는 트랙볼을 갖는 컴퓨터 상에서 구현될 수 있다. 다른 종류들의 디바이스들이 또한 사용자와의 상호작용을 제공하기 위해 사용될 수 있는데: 예컨대, 사용자에게 제공된 피드백은 임의의 형태의 센서 피드백, 예컨대, 시각적 피드백, 청각적 피드백 또는 촉각적 피드백일 수 있고; 사용자로부터의 입력은 음향, 스피치 또는 촉각적 입력을 포함하는 임의의 형태로 수신될 수 있다. 또한, 컴퓨터는 예컨대, 웹 브라우저로부터 수신된 요청들에 응답하여 사용자의 클라이언트 디바이스 상의 웹 브라우저에 웹 페이지들을 전송함으로써, 사용자에 의해 사용되는 디바이스에 문서들을 전송하고 그로부터 문서들을 수신함으로써 사용자와 상호작용할 수 있다. [0074] To provide interaction with a user, one or more aspects of the present disclosure may include a display device, such as a cathode ray tube (CRT), liquid crystal display (LCD) monitor, or touch screen for displaying information to a user, and optionally a touch screen. It may be implemented on a computer with a keyboard and a pointing device, such as a mouse or trackball that allows a user to provide input to the computer. Other types of devices may also be used to provide interaction with the user: for example, the feedback provided to the user may be any form of sensor feedback, such as visual feedback, auditory feedback or tactile feedback; Input from the user may be received in any form, including acoustic, speech, or tactile input. The computer may also interact with the user by sending documents to and receiving documents from the device used by the user, for example, by sending web pages to a web browser on the user's client device in response to requests received from the web browser. You can.
[0075] 다수의 구현들이 설명되었다. 그럼에도 불구하고, 본 개시내용의 사상 및 범위를 벗어나지 않고 다양한 수정들이 행해질 수 있음이 이해될 것이다. 따라서, 다른 구현들은 다음의 청구항들의 범위 내에 존재한다. [0075] A number of implementations have been described. Nonetheless, it will be understood that various modifications may be made without departing from the spirit and scope of the disclosure. Accordingly, other implementations are within the scope of the following claims.
Claims (20)
상기 음성 가능 디바이스에 의해 캡처되는 스피치 입력의 초기 부분을 수신하는 동작;
핫워드 검출기에 의해, 상기 스피치 입력의 초기 부분 내의 키워드의 존재를 검출하는 동작;
상기 스피치 입력의 초기 부분 내의 키워드의 존재를 검출하는 것에 대한 응답으로:
슬립 상태로부터 웨이크업하고 상기 스피치 입력의 나머지 부분을 캡처하기 위해 상기 음성 가능 디바이스를 트리거하는 동작;
상기 스피치 입력이 상기 음성 가능 디바이스를 향할 가능성을 나타내는 콘텐츠 메타데이터를 결정하기 위해 상기 음성 가능 디바이스에 의해 캡처되는 상기 스피치 입력에 대응하는 오디오 데이터를 프로세싱하는 동작; 및
상기 콘텐츠 메타데이터에 기초하여, 상기 음성 가능 디바이스로 하여금 상기 스피치 입력이 질의 프로세싱 스택에 의해 프로세싱되는 것을 드롭(drop)하도록 지시하는 동작
을 포함하는,
컴퓨터에서 구현되는 방법.1. A computer-implemented method executing on data processing hardware on a voice enabled device, the method causing the data processing hardware to perform operations, the operations comprising:
receiving an initial portion of speech input captured by the speech enabled device;
detecting, by a hotword detector, the presence of a keyword within an initial portion of the speech input;
In response to detecting the presence of a keyword within the initial portion of the speech input:
triggering the speech capable device to wake up from a sleep state and capture the remaining portion of the speech input;
processing audio data corresponding to the speech input captured by the speech capable device to determine content metadata indicating a likelihood that the speech input is directed to the speech capable device; and
Based on the content metadata, instruct the speech enabled device to drop the speech input from being processed by a query processing stack.
Including,
How it is implemented on a computer.
상기 오디오 데이터를 프로세싱하는 것에 의해 결정되는 상기 콘텐츠 메타데이터는 상기 스피치 입력과 연관되는 오디오 품질의 신뢰도 스코어를 포함하는,
컴퓨터에서 구현되는 방법.According to claim 1,
wherein the content metadata determined by processing the audio data includes a confidence score of audio quality associated with the speech input.
How it is implemented on a computer.
상기 동작들은:
상기 스피치 입력과 연관되는 상기 오디오 품질의 신뢰도 스코어가 임계치를 충족시키지 않는다고 결정하는 동작을 더 포함하고, 상기 음성 가능 디바이스로 하여금 상기 스피치 입력이 상기 질의 프로세싱 스택에 의해 프로세싱되는 것을 드롭하도록 지시하는 동작은 상기 스피치 입력과 연관되는 상기 신뢰도 스코어가 상기 임계치를 충족시키지 않는다고 결정하는 동작에 기초하는,
컴퓨터에서 구현되는 방법.According to clause 2,
The above operations are:
further comprising determining that a confidence score of the audio quality associated with the speech input does not meet a threshold, and directing the speech capable device to drop the speech input from processing by the query processing stack. is based on determining that the confidence score associated with the speech input does not meet the threshold,
How it is implemented on a computer.
상기 오디오 데이터를 프로세싱하는 것에 의해 결정되는 상기 콘텐츠 메타데이터는 상기 스피치 입력과 연관되는 오디오 품질 스코어를 포함하는,
컴퓨터에서 구현되는 방법.According to claim 1,
wherein the content metadata determined by processing the audio data includes an audio quality score associated with the speech input.
How it is implemented on a computer.
상기 오디오 품질 스코어는 상기 오디오 데이터 내에 존재하는 백그라운드 노이즈의 레벨을 표시하는,
컴퓨터에서 구현되는 방법.According to claim 1,
The audio quality score indicates the level of background noise present in the audio data,
How it is implemented on a computer.
상기 동작들은, 상기 스피치 입력의 초기 부분 내의 키워드의 존재를 검출하는 것에 대한 응답으로, 상기 스피치 입력이 사용자 디바이스와 연관된 스피커 프로파일과 일치할 가능성을 표시하는 상기 스피치 입력에 대한 스피커-식별 스코어를 결정하기 위해 상기 오디오 데이터를 프로세싱하는 동작을 더 포함하는,
컴퓨터에서 구현되는 방법.According to claim 1,
The operations may, in response to detecting the presence of a keyword within an initial portion of the speech input, determine a speaker-identification score for the speech input that indicates the likelihood that the speech input matches a speaker profile associated with a user device. Further comprising the operation of processing the audio data to
How it is implemented on a computer.
상기 동작들은, 상기 스피치 입력의 초기 부분 내의 키워드의 존재를 검출하는 것에 대한 응답으로:
상기 음성 가능 디바이스 상에 존재하는 로컬 ASR 모듈을 사용하여 상기 스피치 입력을 전사(transcribe)하는 동작
을 더 포함하고, 상기 음성 가능 디바이스로 하여금 상기 스피치 입력이 상기 질의 프로세싱 스택에 의해 프로세싱되는 것을 드롭하도록 지시하는 동작은 상기 음성 가능 디바이스로 하여금 상기 스피치 입력의 전사가 상기 질의 프로세싱 스택에 의해 프로세싱되는 것을 드롭하도록 지시하는 동작을 포함하는,
컴퓨터에서 구현되는 방법.According to claim 1,
The operations are in response to detecting the presence of a keyword within the initial portion of the speech input:
Transcribing the speech input using a local ASR module residing on the speech capable device.
further comprising: directing the speech-enabled device to drop the speech input from being processed by the query processing stack, wherein the operation of directing the speech-enabled device to drop the transcription of the speech input from being processed by the query processing stack Including an action instructing to drop something,
How it is implemented on a computer.
상기 음성 가능 디바이스는 스마트폰을 포함하는,
컴퓨터에서 구현되는 방법.According to claim 1,
The voice-enabled device includes a smartphone,
How it is implemented on a computer.
상기 음성 가능 디바이스는 스마트 스피커를 포함하는,
컴퓨터에서 구현되는 방법.According to claim 1,
The voice-enabled device includes a smart speaker,
How it is implemented on a computer.
상기 음성 가능 디바이스는 태블릿을 포함하는,
컴퓨터에서 구현되는 방법.According to claim 1,
The voice-enabled device includes a tablet,
How it is implemented on a computer.
사용자 디바이스의 데이터 프로세싱 하드웨어; 및
상기 데이터 프로세싱 하드웨어와 통신하며 명령들을 저장하는 메모리 하드웨어를 포함하며, 상기 명령들은, 상기 데이터 프로세싱 하드웨어 상에서 실행될 때, 상기 데이터 프로세싱 하드웨어로 하여금 동작들을 수행하게 하며, 상기 동작들은:
음성 가능 디바이스에 의해 캡처되는 스피치 입력의 초기 부분을 수신하는 동작;
핫워드 검출기에 의해, 상기 스피치 입력의 초기 부분 내의 키워드의 존재를 검출하는 동작;
상기 스피치 입력의 초기 부분 내의 키워드의 존재를 검출하는 것에 대한 응답으로:
슬립 상태로부터 웨이크업하고 상기 스피치 입력의 나머지 부분을 캡처하기 위해 상기 음성 가능 디바이스를 트리거하는 동작;
상기 스피치 입력이 상기 음성 가능 디바이스를 향할 가능성을 나타내는 콘텐츠 메타데이터를 결정하기 위해 상기 음성 가능 디바이스에 의해 캡처되는 상기 스피치 입력에 대응하는 오디오 데이터를 프로세싱하는 동작; 및
상기 콘텐츠 메타데이터에 기초하여, 상기 음성 가능 디바이스로 하여금 상기 스피치 입력이 질의 프로세싱 스택에 의해 프로세싱되는 것을 드롭하도록 지시하는 동작
을 포함하는,
시스템.As a system,
data processing hardware of the user device; and
and memory hardware that communicates with the data processing hardware and stores instructions, wherein the instructions, when executed on the data processing hardware, cause the data processing hardware to perform operations, the operations being:
Receiving an initial portion of speech input captured by a speech-enabled device;
detecting, by a hotword detector, the presence of a keyword within an initial portion of the speech input;
In response to detecting the presence of a keyword within the initial portion of the speech input:
triggering the speech capable device to wake up from a sleep state and capture the remaining portion of the speech input;
processing audio data corresponding to the speech input captured by the speech capable device to determine content metadata indicating a likelihood that the speech input is directed to the speech capable device; and
Based on the content metadata, instruct the speech enabled device to drop the speech input from being processed by a query processing stack.
Including,
system.
상기 오디오 데이터를 프로세싱하는 것에 의해 결정되는 상기 콘텐츠 메타데이터는 상기 스피치 입력과 연관되는 오디오 품질의 신뢰도 스코어를 포함하는,
시스템.According to claim 11,
wherein the content metadata determined by processing the audio data includes a confidence score of audio quality associated with the speech input.
system.
상기 동작들은:
상기 스피치 입력과 연관되는 상기 오디오 품질의 신뢰도 스코어가 임계치를 충족시키지 않는다고 결정하는 동작을 더 포함하고, 상기 음성 가능 디바이스로 하여금 상기 스피치 입력이 상기 질의 프로세싱 스택에 의해 프로세싱되는 것을 드롭하도록 지시하는 동작은 상기 스피치 입력과 연관되는 상기 신뢰도 스코어가 상기 임계치를 충족시키지 않는다고 결정하는 동작에 기초하는,
시스템.According to claim 12,
The above operations are:
further comprising determining that a confidence score of the audio quality associated with the speech input does not meet a threshold, and directing the speech capable device to drop the speech input from processing by the query processing stack. is based on determining that the confidence score associated with the speech input does not meet the threshold,
system.
상기 오디오 데이터를 프로세싱하는 것에 의해 결정되는 상기 콘텐츠 메타데이터는 상기 스피치 입력과 연관되는 오디오 품질 스코어를 포함하는,
시스템.According to claim 11,
wherein the content metadata determined by processing the audio data includes an audio quality score associated with the speech input.
system.
상기 오디오 품질 스코어는 상기 오디오 데이터 내에 존재하는 백그라운드 노이즈의 레벨을 표시하는,
시스템.According to claim 11,
The audio quality score indicates the level of background noise present in the audio data,
system.
상기 동작들은, 상기 스피치 입력의 초기 부분 내의 키워드의 존재를 검출하는 것에 대한 응답으로, 상기 스피치 입력이 상기 사용자 디바이스와 연관된 스피커 프로파일과 일치할 가능성을 표시하는 상기 스피치 입력에 대한 스피커-식별 스코어를 결정하기 위해 상기 오디오 데이터를 프로세싱하는 동작을 더 포함하는,
시스템.According to claim 11,
The operations may, in response to detecting the presence of a keyword within an initial portion of the speech input, generate a speaker-identification score for the speech input that indicates the likelihood that the speech input matches a speaker profile associated with the user device. further comprising processing the audio data to determine,
system.
상기 동작들은, 상기 스피치 입력의 초기 부분 내의 키워드의 존재를 검출하는 것에 대한 응답으로:
상기 음성 가능 디바이스 상에 존재하는 로컬 ASR 모듈을 사용하여 상기 스피치 입력을 전사하는 동작
을 더 포함하고, 상기 음성 가능 디바이스로 하여금 상기 스피치 입력이 상기 질의 프로세싱 스택에 의해 프로세싱되는 것을 드롭하도록 지시하는 동작은 상기 음성 가능 디바이스로 하여금 상기 스피치 입력의 전사가 상기 질의 프로세싱 스택에 의해 프로세싱되는 것을 드롭하도록 지시하는 동작을 포함하는,
시스템.According to claim 11,
The operations are in response to detecting the presence of a keyword within the initial portion of the speech input:
Transcribing the speech input using a local ASR module residing on the speech capable device.
further comprising: directing the speech-enabled device to drop the speech input from being processed by the query processing stack, wherein the operation of directing the speech-enabled device to drop the transcription of the speech input from being processed by the query processing stack Including an action instructing to drop something,
system.
상기 음성 가능 디바이스는 스마트폰을 포함하는,
시스템.According to claim 11,
The voice-enabled device includes a smartphone,
system.
상기 음성 가능 디바이스는 스마트 스피커를 포함하는,
시스템.According to claim 11,
The voice-enabled device includes a smart speaker,
system.
상기 음성 가능 디바이스는 태블릿을 포함하는,
시스템.According to claim 11,
The voice-enabled device includes a tablet,
system.
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
KR1020227014492A KR102585673B1 (en) | 2019-02-06 | 2019-02-06 | Voice query qos based on client-computed content metadata |
PCT/US2019/016882 WO2020162930A1 (en) | 2019-02-06 | 2019-02-06 | Voice query qos based on client-computed content metadata |
Related Parent Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
KR1020227014492A Division KR102585673B1 (en) | 2019-02-06 | 2019-02-06 | Voice query qos based on client-computed content metadata |
Publications (2)
Publication Number | Publication Date |
---|---|
KR20230141950A true KR20230141950A (en) | 2023-10-10 |
KR102638177B1 KR102638177B1 (en) | 2024-02-16 |
Family
ID=65529789
Family Applications (3)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
KR1020227014492A KR102585673B1 (en) | 2019-02-06 | 2019-02-06 | Voice query qos based on client-computed content metadata |
KR1020237033169A KR102638177B1 (en) | 2019-02-06 | 2019-02-06 | Voice query qos based on client-computed content metadata |
KR1020217028043A KR102393876B1 (en) | 2019-02-06 | 2019-02-06 | Voice query QoS based on client-computed content metadata |
Family Applications Before (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
KR1020227014492A KR102585673B1 (en) | 2019-02-06 | 2019-02-06 | Voice query qos based on client-computed content metadata |
Family Applications After (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
KR1020217028043A KR102393876B1 (en) | 2019-02-06 | 2019-02-06 | Voice query QoS based on client-computed content metadata |
Country Status (6)
Country | Link |
---|---|
US (3) | US20220093104A1 (en) |
EP (2) | EP3906549B1 (en) |
JP (2) | JP7241190B2 (en) |
KR (3) | KR102585673B1 (en) |
CN (1) | CN113412516B (en) |
WO (1) | WO2020162930A1 (en) |
Families Citing this family (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20200394994A1 (en) * | 2019-06-12 | 2020-12-17 | Nvidia Corporation | Invertible neural network to synthesize audio signals |
US20210050003A1 (en) * | 2019-08-15 | 2021-02-18 | Sameer Syed Zaheer | Custom Wake Phrase Training |
KR102629796B1 (en) * | 2019-10-15 | 2024-01-26 | 삼성전자 주식회사 | An electronic device supporting improved speech recognition |
US11557300B2 (en) * | 2020-10-16 | 2023-01-17 | Google Llc | Detecting and handling failures in other assistants |
US20230055511A1 (en) * | 2021-08-20 | 2023-02-23 | International Business Machines Corporation | Optimizing clustered filesystem lock ordering in multi-gateway supported hybrid cloud environment |
KR20230043397A (en) * | 2021-09-24 | 2023-03-31 | 삼성전자주식회사 | Server, electronic device for processing user's utterance and operating method thereof |
Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
KR20170070094A (en) * | 2014-10-01 | 2017-06-21 | 엑스브레인, 인크. | Voice and connection platform |
KR20180042376A (en) * | 2015-09-21 | 2018-04-25 | 아마존 테크놀로지스, 인크. | Select device to provide response |
KR20180092380A (en) * | 2017-02-09 | 2018-08-20 | 주식회사 엘지유플러스 | Method and apparatus for providing music file |
Family Cites Families (21)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
GB2323693B (en) * | 1997-03-27 | 2001-09-26 | Forum Technology Ltd | Speech to text conversion |
US8239197B2 (en) * | 2002-03-28 | 2012-08-07 | Intellisist, Inc. | Efficient conversion of voice messages into text |
US8073681B2 (en) * | 2006-10-16 | 2011-12-06 | Voicebox Technologies, Inc. | System and method for a cooperative conversational voice user interface |
WO2008073850A2 (en) * | 2006-12-08 | 2008-06-19 | Sri International | Method and apparatus for reading education |
JP5042799B2 (en) * | 2007-04-16 | 2012-10-03 | ソニー株式会社 | Voice chat system, information processing apparatus and program |
US20100010823A1 (en) * | 2008-07-14 | 2010-01-14 | Ebay Inc. | Systems and methods for network based customer service |
WO2011148594A1 (en) | 2010-05-26 | 2011-12-01 | 日本電気株式会社 | Voice recognition system, voice acquisition terminal, voice recognition distribution method and voice recognition program |
US9620122B2 (en) * | 2011-12-08 | 2017-04-11 | Lenovo (Singapore) Pte. Ltd | Hybrid speech recognition |
US10354650B2 (en) * | 2012-06-26 | 2019-07-16 | Google Llc | Recognizing speech with mixed speech recognition models to generate transcriptions |
DE102013001219B4 (en) * | 2013-01-25 | 2019-08-29 | Inodyn Newmedia Gmbh | Method and system for voice activation of a software agent from a standby mode |
JP2014153663A (en) * | 2013-02-13 | 2014-08-25 | Sony Corp | Voice recognition device, voice recognition method and program |
WO2014125736A1 (en) * | 2013-02-14 | 2014-08-21 | ソニー株式会社 | Speech recognition device, speech recognition method and program |
KR102346302B1 (en) * | 2015-02-16 | 2022-01-03 | 삼성전자 주식회사 | Electronic apparatus and Method of operating voice recognition in the electronic apparatus |
CN117577099A (en) * | 2017-04-20 | 2024-02-20 | 谷歌有限责任公司 | Method, system and medium for multi-user authentication on a device |
US10170112B2 (en) * | 2017-05-11 | 2019-01-01 | Google Llc | Detecting and suppressing voice queries |
US11106729B2 (en) * | 2018-01-08 | 2021-08-31 | Comcast Cable Communications, Llc | Media search filtering mechanism for search engine |
KR20190084789A (en) * | 2018-01-09 | 2019-07-17 | 엘지전자 주식회사 | Electric terminal and method for controlling the same |
US10742799B2 (en) * | 2018-02-27 | 2020-08-11 | Leo Technologies, Llc | Automated speech-to-text processing and analysis of call data apparatuses, methods and systems |
US11017778B1 (en) * | 2018-12-04 | 2021-05-25 | Sorenson Ip Holdings, Llc | Switching between speech recognition systems |
KR20200074680A (en) * | 2018-12-17 | 2020-06-25 | 삼성전자주식회사 | Terminal device and method for controlling thereof |
CN109300472A (en) * | 2018-12-21 | 2019-02-01 | 深圳创维－Rgb电子有限公司 | A kind of audio recognition method, device, equipment and medium |
-
2019
- 2019-02-06 JP JP2021545818A patent/JP7241190B2/en active Active
- 2019-02-06 CN CN201980091504.XA patent/CN113412516B/en active Active
- 2019-02-06 US US17/310,175 patent/US20220093104A1/en active Pending
- 2019-02-06 WO PCT/US2019/016882 patent/WO2020162930A1/en unknown
- 2019-02-06 KR KR1020227014492A patent/KR102585673B1/en active IP Right Grant
- 2019-02-06 EP EP19707535.1A patent/EP3906549B1/en active Active
- 2019-02-06 KR KR1020237033169A patent/KR102638177B1/en active IP Right Grant
- 2019-02-06 EP EP22215558.2A patent/EP4187534A1/en active Pending
- 2019-02-06 KR KR1020217028043A patent/KR102393876B1/en active IP Right Grant
-
2022
- 2022-05-02 US US17/661,625 patent/US20220262367A1/en active Pending
-
2023
- 2023-03-06 JP JP2023033369A patent/JP7470839B2/en active Active
- 2023-10-04 US US18/480,798 patent/US20240029740A1/en active Pending
Patent Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
KR20170070094A (en) * | 2014-10-01 | 2017-06-21 | 엑스브레인, 인크. | Voice and connection platform |
KR20180042376A (en) * | 2015-09-21 | 2018-04-25 | 아마존 테크놀로지스, 인크. | Select device to provide response |
KR20180092380A (en) * | 2017-02-09 | 2018-08-20 | 주식회사 엘지유플러스 | Method and apparatus for providing music file |
Also Published As
Publication number | Publication date |
---|---|
CN113412516B (en) | 2024-04-05 |
KR102393876B1 (en) | 2022-05-02 |
EP4187534A1 (en) | 2023-05-31 |
US20220093104A1 (en) | 2022-03-24 |
US20240029740A1 (en) | 2024-01-25 |
JP2023075215A (en) | 2023-05-30 |
CN113412516A (en) | 2021-09-17 |
KR102638177B1 (en) | 2024-02-16 |
US20220262367A1 (en) | 2022-08-18 |
KR20220058976A (en) | 2022-05-10 |
KR102585673B1 (en) | 2023-10-05 |
JP7241190B2 (en) | 2023-03-16 |
JP7470839B2 (en) | 2024-04-18 |
KR20210112403A (en) | 2021-09-14 |
EP3906549A1 (en) | 2021-11-10 |
EP3906549B1 (en) | 2022-12-28 |
WO2020162930A1 (en) | 2020-08-13 |
JP2022519648A (en) | 2022-03-24 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
KR102638177B1 (en) | Voice query qos based on client-computed content metadata | |
KR102314096B1 (en) | Intercom-style communication using multiple computing devices | |
EP3485489B1 (en) | Contextual hotwords | |
KR101726945B1 (en) | Reducing the need for manual start/end-pointing and trigger phrases | |
US10580407B1 (en) | State detection and responses for electronic devices | |
US11721338B2 (en) | Context-based dynamic tolerance of virtual assistant | |
US20220157318A1 (en) | Dynamically adapting on-device models, of grouped assistant devices, for cooperative processing of assistant requests | |
US20230143177A1 (en) | Contextual suppression of assistant command(s) | |
US20230186909A1 (en) | Selecting between multiple automated assistants based on invocation properties | |
US20240046925A1 (en) | Dynamically determining whether to perform candidate automated assistant action determined from spoken utterance | |
WO2023113877A1 (en) | Selecting between multiple automated assistants based on invocation properties | |
KR20230153450A (en) | Device arbitration for local implementation of automatic speech recognition | |
KR20240011841A (en) | Provide relevant queries to secondary automated assistants based on past interactions | |
KR20240033006A (en) | Automatic speech recognition with soft hotwords |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A107 | Divisional application of patent | ||
E701 | Decision to grant or registration of patent right | ||
GRNT | Written decision to grant |