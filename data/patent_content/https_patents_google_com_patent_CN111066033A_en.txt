CN111066033A - Machine learning method for generating labels of fuzzy results - Google Patents
Machine learning method for generating labels of fuzzy results Download PDFInfo
- Publication number
- CN111066033A CN111066033A CN201780094512.0A CN201780094512A CN111066033A CN 111066033 A CN111066033 A CN 111066033A CN 201780094512 A CN201780094512 A CN 201780094512A CN 111066033 A CN111066033 A CN 111066033A
- Authority
- CN
- China
- Prior art keywords
- features
- training data
- labels
- partition
- list
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
- G06N20/20—Ensemble learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F18/00—Pattern recognition
- G06F18/20—Analysing
- G06F18/21—Design or setup of recognition systems or techniques; Extraction of features in feature space; Blind source separation
- G06F18/214—Generating training patterns; Bootstrap methods, e.g. bagging or boosting
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F18/00—Pattern recognition
- G06F18/20—Analysing
- G06F18/21—Design or setup of recognition systems or techniques; Extraction of features in feature space; Blind source separation
- G06F18/217—Validation; Performance evaluation; Active pattern learning techniques
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F18/00—Pattern recognition
- G06F18/40—Software arrangements specially adapted for pattern recognition, e.g. user interfaces or toolboxes therefor
- G06F18/41—Interactive pattern learning with a human teacher
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/08—Learning methods
- G06N3/088—Non-supervised learning, e.g. competitive learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N7/00—Computing arrangements based on specific mathematical models
- G06N7/02—Computing arrangements based on specific mathematical models using fuzzy logic
-
- G—PHYSICS
- G16—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR SPECIFIC APPLICATION FIELDS
- G16H—HEALTHCARE INFORMATICS, i.e. INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR THE HANDLING OR PROCESSING OF MEDICAL OR HEALTHCARE DATA
- G16H10/00—ICT specially adapted for the handling or processing of patient-related medical or healthcare data
- G16H10/60—ICT specially adapted for the handling or processing of patient-related medical or healthcare data for patient-specific data, e.g. for electronic patient records
-
- G—PHYSICS
- G16—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR SPECIFIC APPLICATION FIELDS
- G16H—HEALTHCARE INFORMATICS, i.e. INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR THE HANDLING OR PROCESSING OF MEDICAL OR HEALTHCARE DATA
- G16H50/00—ICT specially adapted for medical diagnosis, medical simulation or medical data mining; ICT specially adapted for detecting, monitoring or modelling epidemics or pandemics
- G16H50/20—ICT specially adapted for medical diagnosis, medical simulation or medical data mining; ICT specially adapted for detecting, monitoring or modelling epidemics or pandemics for computer-aided diagnosis, e.g. based on medical expert systems
Abstract
A machine learning method for generating labels for members of a training set is described, where the labels are not directly available in the training set data. In the first stage of the method, an iterative process is used to build up a list of features (herein "partition features") that are conceptually related to class labels using human-machine circuits (experts). In the second part of the process, we generate labels for the members of the training set, use the labels to build an enhancement model to propose additional partition features, score the labels of the members of the training set according to the enhancement model, and then evaluate the labels assigned to a small subset of members according to their scores using a human-machine loop. The tags assigned to some or all of those members in the subset may be flipped according to the evaluation. The end result of this process is an interpretable model that explains how the labels are generated, as well as a tagged training data set.
Description
Cross Reference to Related Applications
This application claims U.S. provisional application serial No.62/552,011, filed on 30/8/2017.
Background
The present disclosure relates to the field of machine learning, and more particularly, to a method of generating a label for each of the members of a set of training data, where the label is not available in the training data itself. The labels are conceptually associated with certain specific features or attributes of the sample in the training data (a term referred to herein as "results").
Machine learning models, such as neural network models used in the prediction of health sciences or to build predictive tests, are typically generated from a collection of electronic health records. Some labels are present in the training set used to generate the model and are considered "heavy", e.g., hospitalized mortality (patient dies or not dies in the hospital), transfer to Intensive Care Unit (ICU), i.e., patients are transferred to or not transferred to ICU during their hospitalization.
On the other hand, in non-uniform data such as electronic health records, some concepts that are semantically well-defined are difficult to extract or may not be labeled (label) in the training data. In this document, the term "non-uniform" means that generic terms are named in a manner specific to a particular organization, rather than being uniformly named between different organizations. For example, "acetaminophen 500 mg" may be referred to as "drug 001" in one particular hospital, and thus the same thing is called differently in two different tissues, and thus the terms are not uniform. As another example, whether a patient has received dialysis is conceptually clear at a high level, but there are many different types of dialysis in the data (intermittent hemodialysis, pure ultrafiltration, continuous venous-venous hemodiafiltration), so the underlying data may require extensive rules to fully capture this "blurred" subject of interest. Further, some labels are not explicitly available in the training set, but a label needs to be assigned to a member in the training set, e.g., to indicate that the member has certain specific characteristics.
Manual addition of labels is time consuming. It is also subject to human error. In addition, since there may be some subjectivity in assigning labels, the results may be inconsistent, particularly if different health records are labeled by different individuals.
Therefore, there is a need in the art for a predictive model that takes into account such "fuzzy label" scenarios. This document represents a scalable solution to this problem and describes a method for generating labels for all members of training data. Furthermore, we describe the generation of interpretable, coherent, and understandable models for generating labels in training data. Furthermore, the present disclosure allows additional predictive models, such as clinical decision support models, to be built from the tagged training data.
Disclosure of Invention
In one aspect, a computer-implemented method of generating class labels for members of a training data set is disclosed. The method is performed by certain processing instructions implemented by a processor of a computer. The training data for each member of the set includes a plurality of features. In the context of an electronic health record, a member may be, for example, an electronic health record of an individual patient, training data may be time-series data in the electronic health record of the patient, and features may be things in the electronic health record such as vital signs, medications, diagnoses, hospitalizations, text in clinical notes, and the like. The class labels generated by this method are "fuzzy" (that is, not explicitly available in the training data) labels.
The method comprises a first stage of refining features associated with class labels using input from a human-machine circuit or operator, and comprises steps a) to d). In step a), an initial list of partition characteristics conceptually related to category labels is received from an operator or human-machine loop (i.e., a subject matter expert). These initial partition characteristics may be considered hints for the boot process. They typically have high accuracy (i.e., strongly correlated with the desired label), but have a lower recall (the lower proportion of examples in the training set have a partition characteristic). The method comprises a step b): the training data is tagged with the partition features and additional partition features that are not in the initial partition feature list are generated that are associated with the category tags. Basically, a machine (computer) uses the partition features to generate labels for training data, for example, using decision lists or logic defined by an operator. In one embodiment, the machine builds an augmented model to generate or propose additional partition features. The method comprises step c): the selected one of the additional section features is added to the initial section feature list according to an operator input. Essentially, the method uses a human-machine loop to examine the proposed additional partition features and add "good" partition features (based on expert evaluation) to the partition feature list. The selection may be based on, for example, whether the additional partition features are causally related to the category label.
The method comprises a step d): repeating steps b) and c) one or more times to obtain a final partition characteristic list. Basically, in processing the instruction, we iterate steps b) and c) several times to generate the final partition feature list.
The computer-implemented process continues to a second stage of tag refinement using input from a manual evaluation of the tags. The second stage comprises step e): tagging the training data with the final partition feature list from step d); step f): building a further enhancement model using the labels generated in step e); step g): scoring the training examples using the further enhanced model of step f); and step h): generating labels for the subset of members of the training examples based on the scoring of step g) using input from an operator. For example, we can use a known scoring metric such as F1 and select a threshold based on that metric, and for members of the training set near the threshold, we use a human operator to assign labels to those members, or equivalently examine the labels generated in step e) and confirm them or flip them based on a human evaluation.
The result of this process is an interpretable model explaining how we generate fuzzy labels, i.e. a further enhancement model from step f), and a labeled training set from steps e) and h). The tagged training set may then be used as input to generate other models, such as predictive models for predicting future clinical events of the newly input electronic health record.
In one embodiment, at least some of the features of the training data are words contained in the health record, and at least some of the partitioned features are a determination of whether one or more words are present in the health record. In another embodiment, at least some of the features in the training data are measurements in a health record (e.g., vital signs, blood urea nitrogen, blood pressure, etc.), and at least some of the partition features are determinations of whether one or more measurements are present in the health record, e.g., BUN > -52 mg/dL or measurements over a given time period.
Furthermore, after the manual tagging input of step h), we can continue to model the tagged data set and perform an additional "active learning" step at the end of the process to further refine the tags. Thus, in one embodiment, we repeat steps f), g) and h) one or more times to further refine the labels, wherein for each iteration the input of step f) is a training set of labels from the previous iteration.
In another aspect, a computer-implemented method of generating a feature list for assigning class labels to members of a training data set is disclosed. The training data for each member of the set is in the form of a plurality of features. The method is performed in a computer processor by software instructions and comprises the steps of: a) receiving an initial list of partition features conceptually related to category labels from an operator; b) tagging training data using the initial list of partition features and identifying additional partition features associated with the category tag that are not in the initial list of partition features; c) adding the selected one of the additional partition features to the initial partition feature list according to an operator input to obtain an updated partition feature list; and d) repeating steps b) and c) one or more times using the updated partition feature list as input in step b) to obtain a final partition feature list.
In yet another aspect, a computer-implemented method for generating class labels for members of a training data set is provided. The training data for each member of the set is in the form of a plurality of features. The method is implemented in software instructions in a computer processor and comprises the steps of: (a) gradually building a list of partitioned features using a first augmented model with input from a human machine loop (operator); (b) tagging members of the training data set with a list of partition features; (c) building a further enhancement model from the tagged members of the training data set and generating additional partition features; (d) scoring the labels of the members of the training data set and determining a threshold; (e) identifying a subset of members of a training data set near a threshold; and (f) assigning the tags to the subset of members using input from a human machine loop (operator).
As mentioned above, it is possible to do further active learning to refine the tags using a human machine loop; thus, more models can be built from the tagged training set, and we can repeat or iterate the assignment of tags by the operator. For example, we can repeat steps (c), (d), (e) and (f) at least once and thereby further refine the label. We can repeat this process several times, each time using the tagged training data from the last iteration as input for step c).
The term "enhanced model" is used herein to denote a supervised machine learning model that learns from tagged training data, where a plurality of iteratively learned weak classifiers are combined to produce a strong classifier. Many methods of generating an augmented model are known.
It will be noted that in the broadest sense, the method of the present disclosure can be used to train "features" in data, where the term "features" is used in its traditional sense in machine learning as a single atomic element in training data used to build classifiers, e.g., a single word in a medical record, laboratory test results. In the following description, we describe features in the form of logical operations that provide a more complex way of determining whether a particular element is present in training data, while taking into account temporal information associated with the element. More generally, the method may utilize a test (or query) in the form of a function applicable to any member of the training data to detect the presence of one or more of the features in that member of the training data.
Thus, in one further aspect of the disclosure, a computer-implemented method of generating a respective class label for each of a plurality of members of a training data set is described. The training data for each member of the set includes a plurality of features. The method comprises the steps of executing the following instructions in a processor of a computer:
a) receiving an initial list of tests from an operator, the tests conceptually associated with class labels, each test being a function applicable to any member of the training data to detect one or more features in that member of the training data;
b) tagging the training data with tests and identifying additional tests associated with the category tags that are not in the initial test list;
c) adding selected ones of the additional tests to the initial test list based on the input data from the operator;
d) repeating steps b) and c) one or more times to obtain a final test list;
e) tagging the training data with the final test list from step d);
f) building an augmented model using the tags generated in step e);
g) scoring the training examples using the augmented model established in step f), and
h) generating, using input from an operator, respective labels for the subset of members of the training examples based on the scores of step g).
In one embodiment, in step b), additional tests are generated using the augmented model.
In one embodiment, step f) comprises the steps of: the further enhancement model is initialized with the final test list and additional tests for building a new enhancement model are iteratively generated in each iteration. In one embodiment, generating iterations of additional tests includes receiving operator input to deselect some of the generated additional tests.
In one embodiment, the scoring step g) comprises determining a threshold value associated with the score and identifying members of the training data having a score that differs from the threshold value by an amount within a predetermined range, and wherein step h) comprises the step of generating a label for the identified members of the training data set.
In one embodiment, once the labels have been assigned according to steps e) and h), the method comprises the further step of building a predictive model from the set of samples having labels assigned according to steps e) and h).
In one embodiment, the members of the training data set include respective sets of electronic health records. In addition to electronic health records, the method may also use other types of training data, as the method is generally applicable to assigning fuzzy labels in other situations. In one embodiment, at least some of the features of the training data are words contained in the health record, and at least some of the tests are a determination of whether one or more corresponding predetermined words are present in the health record, or a determination of whether one or more measurements are present.
In one embodiment, at least some features of the training data are associated with real-valued and temporal components and are in { X, X }i,tiTuple format of type, where X is the name of the feature, XiIs the real value of the feature, and tiIs a real value xiA time component of (a); and the test includes predicates defined as binary functions operating on the sequence of tuples or logical operations on the sequence of tuples.
Drawings
Fig. 1 is a flow chart illustrating one embodiment of a method of the present disclosure.
Fig. 2 is a detailed flowchart showing the steps of building the final enhancement model (22) of fig. 1.
FIG. 3 is an illustration of the use of the process of FIG. 1 for a training set in the form of an electronic health record.
Fig. 4 is a probability histogram as a result of the scoring step of fig. 1.
Detailed Description
This document discloses a method for generating a prediction model that takes into account such "fuzzy label" situations, where training labels are not explicitly available. This document represents an extensible solution to this problem and describes a method of generating labels for a subset of members, or even all members, of the training data. Furthermore, we describe generating interpretable, coherent, and understandable models for generating labels in training data. Furthermore, the present disclosure allows additional predictive models, such as clinical decision support models, to be built from the tagged training data. Thus, these methods have several technical advantages. In addition, to generate useful predictive models from electronic health records with broad applicability, labels need to be built for training data, and such predictive models would be difficult, expensive, or time consuming to produce or use without the benefits of the methods of the present disclosure.
Referring now to FIG. 1, this document describes a computer-implemented method 100 of generating class labels for members of a training data set 10. The method includes a process 102 executing on a computer that generates an interpretable model that generates class labels for training data. The output 28 of the process 102 is the interpretable model and the training data set that is now labeled according to the model.
The training data for each member of the set 10 includes a plurality of features. In the context of an electronic health record, a member of the training data may be, for example, an electronic health record for an individual patient. The training data may be time series data in an electronic health record, and the features may be words found in the electronic health record, such as vital signs, medications, diagnoses, hospitalizations, clinical notes, and the like. We describe features later in this document in the form of "predicates", which are the ratio of { features: real value; time value } of the training data in tuple format. The class labels generated by the method 100 are "fuzzy" (i.e., not explicitly available in the training data) labels, and thus the training data 10 is initially unlabeled in this regard.
Still referring to FIG. 1, the method indicated by the flowchart 102 is performed by software instructions running in a computer. Method 102 includes a first stage of refining features associated with category labels using input from a human-machine loop or operator, and includes steps 12, 14, 16 and loop 18. In step 12, an initial list of partition features conceptually associated with category labels is received from an operator (expert) 104. The operator 104 uses the workstation 106 to specify a small list of features associated with the tag, that is, one, two or five features or so. The operator is a domain expert (such as a doctor) and this initial list of features is based on his or her own domain knowledge. These initial partition characteristics may be considered hints for the boot process. They typically have high accuracy, but have low recall rates. For example, to label a patient as "acute kidney injury," one initial characteristic may be "whether dialysis occurred in the patient's medical history.
The method includes a step 14 of tagging training data with partition features and generating additional partition features related to class tags that are not in the initial list of partition features. Basically, a machine (computer) uses the partition features to generate labels for the training data 10. Category labels may be assigned based on the partition features using the OR operator, that is, if any initial partition feature is present in the patient record, it is labeled as a positive example, otherwise it is a negative example. The tagging logic may be more complex than simply using an OR operator, e.g., feature 1OR feature 2, where feature 2 is (feature 2aAND (and) feature 2 b). In the context of features that take the form of "predicates" described below, the tagging logic may be two predicates, one of which is a combination of two other predicates that are "anded" together. Since the feature takes the form of a "predicate", it may be very capable of expressing, for example, whether there was "dialysis" in the last week, or whether the laboratory test value exceeded a certain threshold. The logic for generating the tags is typically assigned or generated by a human operator.
In one embodiment, the machine builds an enhanced model to generate or propose additional partition features, which may be done by constraining the model to not use the initial feature list. For example, the initial feature "whether dialysis occurred in the patient's medical history" may lead to the following new recommendation: 1) "whether hemodialysis occurred in the patient's medical history", 2) "whether the patient's laboratory test value of BUN (blood urea nitrogen) was > 52mg/dL over the past week. These additional features are highly correlated with the "acute kidney injury" fuzzy label. With respect to the labels generated by the partition features, additional partition features may be proposed based on weighted information gains of randomly selected features.
At step 16, human operator 104 may select or edit the suggested features and add them to the initial partition feature list. Essentially, the method uses a "man-machine loop" 104 to check for additional partition features proposed and "good" partition features (based on expert evaluation) are added to the partition feature list, possibly requiring some editing, e.g., laboratory test result thresholds. The selection may be based on, for example, whether the additional partition features are causally related to the category label. This aspect injects expert knowledge into the augmented model and helps to generate interpretable models that explain how fuzzy labels are assigned to training data in a human understandable way.
The method comprises a looping step 18 of repeating steps b) and c) one or more times to obtain a final partition feature list. Basically, we iterate the software instructions steps 14 and 16 several times to generate the final partitioned feature list, using the total feature list obtained at the completion of step 16 as input for each iteration. This iterative process of steps 14, 16 and loop 18 gradually builds the enhanced model and results in a final partition feature list that is satisfactory to human operators.
The process continues to a second stage of label refinement using input from a manual evaluation of the subset of training labels. The second stage includes a step 20 of tagging the training data with the final partition feature list from step d). Basically, we use the model produced by repeating steps 14, 16 and 18 a number of times to generate labels for the training data.
By using the "OR" operator, category labels may be assigned based on the final list of partitioned features, that is, a particular sample (patient data) is labeled as positive if any of the partitioned features are present in its training data, and negative otherwise. The tagging logic may be more complex than simply using an OR operator, e.g., feature 1OR feature 2, where feature 2 is (feature 2a AND feature 2 b). In the context of features that take the form of "predicates" described below, the tagging logic may be two predicates, one of which is a combination of two other predicates that are anded together, as in the previous example. Since the feature takes the form of a "predicate" in the illustrated embodiment, it may be highly capable of expressing, for example, whether there was "dialysis" in the last week, or whether the laboratory test value exceeded a certain threshold.
The process then proceeds to step 22 where we use the tags generated in step 20 to build a further augmented model. Step 22 is shown in more detail in fig. 2 and will be described below. Basically, in step 22 we initialize the model with the final feature list developed from steps 14, 16 and 18, and then we allow the model to use these features and ask it to use additional features if necessary. We optionally use the "human machine loop" 104 to deselect some of the additional features that are not desired, e.g., those features that are causally unrelated to the category label.
At step 24, we score all training examples using the enhanced model of step 22. At step 26, we sample a subset of examples where their scores indicate that the model is uncertain for their label in step 24, i.e. the model is uncertain for those examples, and give those examples to a human expert for further evaluation. For example, we can use a known scoring metric such as F1, and select a threshold based on that metric, and for members of the training set near the threshold, we use a human operator to assign labels to those members, or equivalently, examine the class labels assigned by the machine, and either confirm them or flip them (flip). This example subset should be much smaller than the entire training data set, so we save a lot of expensive and time consuming manual labeling work by using process 102.
The output 28 of the process 102 is an interpretable model explaining how we generate fuzzy labels, i.e. the enhanced model from step 22, and the labeled training set from steps 20 and 26. The tagged training set may then be used as input to train other machine learning models, such as predictive models for predicting future clinical events of other patients based on their electronic health records.
Furthermore, as mentioned above, it is possible to further "active learning" to refine the tags using a human-machine loop; thus, more models can be built from the tagged training set, and we can repeat or iterate the assignment of tags by the operator in the second phase of the process.
Examples will now be provided for steps 14, 16 and 18 and to explain how the augmented model is initially constrained to use the initial partition features. More specifically, the partition features are used to select which examples are positive and which are negative for the enhancement model. Then, in subsequent iterations of loops 14 and 16, they are excluded from the enhancement model (otherwise the enhancement model would only use the partition features themselves and would not obtain new features). Assume, in this example, that the ambiguous label is "acute kidney injury".
1. In the first iteration, the expert searches for all patients with "dialysis" in the record (this is a small list of one of the partition features provided in step 12) at step 14. This is done using an initial partition feature (predicate) that encodes the query "whether dialysis is present in the record".
2. All records with "dialysis" were considered positive, otherwise not. These tags were used to run enhancements, but importantly, did not include the presence or absence of dialysis in the partition predicate "record"
3. The enhancement then proposes a new predicate, such as "whether hemodialysis occurred" or "whether BUN (blood urea nitrogen) was measured". As described above, these partition predicates may be generated by the weighted information gain of randomly selected predicates, which is the process described in step 204 of fig. 2.
4. At step 16, the expert selects "hemodialysis" and "BUN". Now, in the second iteration of the cycle 18, all patients with dialysis OR hemodialysis OR BUN are considered positive and run enhancement using these labels (excluding the partition predicate "dialysis" and "hemodialysis" and "BUN"). In a second iteration of the loop 18, a new partition predicate is proposed (again using the weighted information gain) at step 14, and the expert reviews and selects some additional partition predicates at step 16.
5. The process (loop 18) is repeated several times or until the expert is satisfied with partitioning the predicate.
Fig. 2 shows an embodiment of how the further enhancement model in step 22 is generated. The process of step 22 shown in fig. 2 may also be used for the iterations of steps 14, 16 and 18 of the first stage of the process.
At step 200, we initialize a further enhancement model with the final feature list resulting from step 20 of FIG. 1. At step 202, a number (e.g., 5000) of additional features are randomly selected. At step 204, the new randomly selected features are scored to obtain weighted information gains relative to class labels (e.g., fuzzy labels discussed herein) associated with the predictions of the enhancement model, and we select some small number Y of these features, where Y is, for example, 10 or 20. The weight of each sample is derived from the probability p of the computed sample, given the current enhancement model. Then the importance q is q ═ label-prediction |. This means that the erroneous samples of the enhancement model are more important in the current enhancement round. Then, using the importance q and the label of the sample, the weighted information gain of the candidate feature with respect to the label and the current enhancement model can be calculated. Alternatively, we can choose the features randomly and then perform the gradient step with L1 regularization. Another approach is to sample the feature set and evaluate the Information gain according to the method described in https:// en. wikipedia.org/wiki/Information _ gain _ in _ decision _ trees, or to use the technique described in the Trivedi et al article "An Interactive Tool for Natural Language Processing on Clinical Text, arXiv:1707.01890[ cs.HC ] (7 months in 2017)".
In step 206, we compute the weight of the selected feature with the highest weighted information gain. In this step, we then perform a gradient fit to calculate the weights of all selected features. We use gradient descent with log-loss and L1 regularization to compute new weights for all previous and newly added features. We performed the fitting using the fob algorithm, see the paper by Duchi and Singer, effective Online and Batch Learning using forward backing scattering, j.mach.lean.res. (2009).
At step 208, we then use a human machine loop (such as the operator 104 of fig. 1) to select or equivalently remove or deselect a feature in response to the operator input. In particular, an expert such as the physician 104 operating the computer 106 looks at the randomly selected features with the highest information gain and then removes those features that are deemed not to be trustworthy or causally relevant to the predictive task of the model. For example, if one of the features is "number of breakfast" and the predicted task is in-patient mortality, the operator may choose to deselect the feature because it has no causal relationship to whether the patient is at risk for in-patient mortality.
In step 210 it is checked whether the selection process of the additional feature is complete. Typically, the "no" branch 212 is entered for ten or twenty iterations during which an augmented model is built up that includes the final partitioned feature list generated from steps 14, 16 and 18 plus the additional features generated from steps 202, 204, 206 and 208. When a sufficient number of iterations have been completed, the process proceeds to steps 24 and 26 of FIG. 1, described above, i.e., the final augmented model is used to score the training set and the human-machine loop assigns labels to the boundary members of the training set.
FIG. 3 is a diagrammatic view of a process for generating fuzzy labels for training data in the form of electronic health records. In particular, the process includes a preprocessing step 50, a process 102 of fig. 1 and 2 that generates labels for the training data and constructs interpretable models explaining how the training data is labeled, and a step 300 of building additional models using the labeled training data.
In a preprocessing step 50, we start with an input data set 52 of the original electronic health record. In one possible example, this data set may be a MIMIC-III data set containing patient anonymous health record data between 2002 and 2012 about an intensive care patient at a bose israeli medical center, boston, massachusetts. This data set is described in a.e. johnson et al, MIMIC-III, a free accessible crystalline carecatabase, j.sci.data, 2016. Of course, other patient-unidentified electronic health record data sets may also be used. The data set 52 may include electronic Health records obtained from a plurality of institutions that use different underlying data formats for storing electronic Health records, in which case there is an optional step 54 of converting them to a standardized format, such as Fast Health Interoperability Resource (FHIR) format, see SMART on FHIR: a standards-based, interactive adaptive platform for electronic Health records, J Am Med info asset.2016; 899-908, in which case the electronic health record is converted to an FHIR "resources" package and sorted by patient into a time series or chronological order. Further details regarding step 54 are described in U.S. provisional patent application serial No. 62/538,112, filed on 28.7.2017, the contents of which are incorporated herein by reference. For aggregated patient-unidentified electronic health records used to create models, our system includes a sandbox infrastructure that separates each EHR data set from each other according to regulations, data permissions, and/or data usage agreements. The data in each sandbox is encrypted; all data access is controlled, logged and audited at the individual level.
The data in the data set 52 contains a number of features, which may be hundreds of thousands or more. In the example of an electronic health record, a feature may be a particular word or phrase in an unstructured clinical note (text) created by a doctor or nurse. The characteristic may be a particular laboratory value, vital sign, diagnosis, medical visit, prescribed medication, symptom, etc. Each feature is associated with a real-valued and time component. At step 56, we take the type { X, X }i,tiThe tuple format of (1) formats the data, where X is the name of the feature, XiIs the real value of a feature (e.g., word or phrase, drug, symptom, etc.) and tiIs a real value xiThe time component of (a). The time component may be an index (e.g., an index indicating the location of the real value in a time-varying sequence of events), or the time elapsed since the real value occurred and the time at which the model generated or made the prediction. The generation of the tuple at step 56 is performed for each electronic health record for each patient in the data set. An example of a tuple is { "Note: sepsis ", 1, 1000 seconds } and {" heart rate per minute ", 120, 1 day }.
In step 58, to process the time series nature of the data, we binarize all features to predicate, and so truly valuable features can be represented by predicate (such as heart rate >120 beats per minute in the last hour). The term "predicate" in this document is defined as a binary function that operates on a sequence of one or more of the tuples of step 56 or a logical operation on a sequence of tuples. All predicates are functions that return a 1 if true or a 0 otherwise. As an example, the predicate "present" (Exist) "heart rate times per minute" in [ { "heart rate times per minute", 120, 1 week } ] returns 1 because on the sequence of the last week there is a tuple with { "heart rate times per minute", 120, 1 day } in the entire sequence of heart rate times per minute tuples.
predicate may also be a logical combination of binary functions over a sequence of tuples, such as the presence of predicate 1ORpredicate 2; OR there is predicate 1OR predicate 2, where predicate 2 ═ is (predicate 2AAND predicate 2B). As another example, a predicate may be a combination of two "present" predicates of the drug vancomycin AND tazobactam over a certain period of time.
At step 58, there is an optional step of grouping predicates into two groups based on human understandability (i.e., understandable to the expert in the field). Examples of predicates in group 1 (which are the most understandable predicates to humans) are:
presence of: x-marker (token)/feature X is present at any point of the patient timeline. Here, X may be a letter in a note, or a name or program code of a laboratory, or the like.
Count: # X > C. Whether the number of flags/features X present at all times exceeds C. More generally, a "count" predictor returns a result of 0 or 1 based on the feature count in the electronic health record data for a given patient relative to the number of numerical parameters C.
Other types of human understandable predicates may be selected as belonging to group 1, depending on the type of prediction/label assigned by the model. Furthermore, an operator or expert may generate or define a human-understandable predicate during model training.
The predicate in group 2 (which is less understood by humans) may be, for example:
at t: (i)<T, any of x: (i)>V。x(i) Whether or not the value of (b) exceeds V (or alternatively X) at a time less than T in the past<＝V)。
·Max/Min/Avg_i x(i)>And V. The maximum or minimum or mean value of X is greater than V (or alternatively X) at all times<＝V)。
The Hawkes process. When x: (i)>Does the sum of the exponential time decay pulses at V exceed a certain activation a within a certain time window T? Activation of sumiI(x(i)>V)*exp(-t(i)/T)
A decision list predicate, where any two union (connections) of the above predicates are used.
In step 102 of fig. 3, in order to build an interpretable model for generating fuzzy labels, it may be desirable to use only human-understandable prerecate as a feature to be used in the process of fig. 1 and 2. Once the training data has been tagged according to process 102 of fig. 1, additional predictive models may be built on top of the tagged training data. Examples of such predictive models are known in the technical and patent literature. For further details regarding the integration of several different types of predictive models and models for making health predictions, see U.S. provisional patent application serial No. 62/538,112, filed 2017, month 7, day 28, the contents of which are incorporated herein by reference.
Examples of the invention
This example will describe an example of generating a label for "dialysis" on an input training set of electronic health records. In this example, the training set is a small sample of 434 patients in the MIMIC-III data set described above.
A. Establishing a partition predicate ( steps 12, 14, 16, 18 of FIG. 1)
The first iteration through loop 18:
1. start (Seed) (step 12): the prefix selected by the operator is "E: composition.section.text.div.tokenized dialysis" (coverage: 32 examples, which is the number of examples triggered by this prefix.)
2. Step 14 and step 16: the machine provides a list and manually selects:
o E composition section text div tokenized dialysis (coverage: 32)
o E composition section text div tokenized end stage renal disease (coverage: 17)
o #, composition.section.text.div.tokenized dialysis > -2 (coverage: 25)
o E composition section text div tokenized renal failure (coverage: 79)
A second iteration through loop 18:
1. at the beginning: 4 prefixes from the first iteration.
2. The machine provides a predicate list and selects these additional predicates manually:
a.E DensePercentileTokens loci _ 2160-0.9 _ mg _ dl (coverage: 35)
b.E DensePercentileTokens loci _ 2160-0.85 _ mg _ dl (coverage: 45)
c.E DensePercentileTokens loinc _ 3094-0.8 _ mg _ dl (coverage: 71)
(the predicate of the signature type "densepercenteleTokens" refers to a laboratory test (identified by the loinc "code) and the test results are very high compared to the general population, which indicates disease. for example," E: densepercenteleTokens loinc _ 2160-0.9 _ mg _ dl "indicates that the patient has a 90 th percentile of creatinine (loinc code 2160-0) measurements (measured in mg/dl)).
A third iteration through loop 18:
1. at the beginning: 7 predicates from the second iteration.
2. The machine provides a list and selects these additional predicates manually:
a.E DensePercentileTokens loinc _ 3094-0.85 _ mg _ dl (coverage: 61)
b.E DensePercentileTokens loinc _2777-1_0.9_ mg _ dl (coverage: 75)
B. Second stage ( Steps 20, 22, 24 and 26 of FIG. 1)
1. We tag the training data using the final predicate list: 9 predicates from the first stage. (step 20)
2. A model initialized with 9 predicates is established. Allowing the model to pick more predicates. (step 22)
3. The examples in the training set are scored (step 24). The best threshold cutoff (probability 0.367) is chosen to obtain the best F1 (0.869). The area of performance metric under the curve (AUC/ROC) of the receiver operating characteristic graph is 0.971 (independent of the threshold). The histogram is shown in fig. 4.
4. Labeling boundary examples (step 26). There are 59 examples within 1% of the probability threshold, i.e., 36.7% +/-1%. This represents 14% of the training data set. From the human evaluation resources we own, we can decide how many examples we can evaluate. This step is similar to the "active learning" technique in machine learning. A simple tool on the user interface of the computer can be used to present the patient within 1% of the probability threshold for manual evaluation and assignment of labels to these samples.
Note that this process will pick more examples on the negative side due to the shape of the distribution. In this particular case, it is desirable that we want to check more instances on the negative side, since the risk of false negatives is greater.
The verification of the above process may be performed as a "sanity check". For example, we can compare the relevant label "ccs: 50 "(i.e.," diabetes and complications "), the final model was evaluated on a separate validation dataset (1135 examples). In this exercise, we obtained a reasonably good AUC/ROC of 0.79. This validates our approach. As a comparison, the data was based on "ccs: the model built with the 50 "tag yields an AUC/ROC of 0.88 on the same evaluation dataset. The first few predicates are related to "ccs: 50 "related drugs, but are not specific to dialysis.
More formal evaluations in the form of manual evaluations of small, uniformly sampled subsets of the data set are also possible. We can compute the accuracy of the fuzzy label against those manually assigned labels.
Further consideration of examples
It is preferable to select a "objective" fuzzy label feature or predicate, such as a laboratory result, procedure, or drug. On the other hand, physician notes are typically only available afterwards and are therefore not very useful in a real-time clinical decision environment. It may be desirable to use a note item only when the note item is very specific to the tagging task.
In step 16 (and optionally in step 22 of fig. 2), the coverage of each predicate is displayed to the human expert. It is not surprising that the machine-suggested predicates all have reasonable coverage, as demonstrated in this example.
Some visualization of the suggested predicates in step 16 and optionally in step 22 may be useful, such as plotting their semantic relationships in a 2D chart, where the dot size is proportional to their weight.
Different human experts (104, fig. 1) may get different final prefix lists. One may wish to compare survey and assessment models to each other based on different final predicate lists. One metric may be based on "tag flipping" in the manual evaluation of the tags in step 26. Fewer flips means that the human expert is more accurate.
In the second stage of model generation (fig. 1), comprising steps 20, 22, 24 and 26, there are several options as to how to perform the method, including:
1) based on the labels from the current feature list that created the partition, the further enhancement model of step 22 is trained, as explained in detail above.
2) The domain experts (man-machine loop 104) are allowed to combine predicate into their selected rules (e.g., at least two of the following flags must be present in the note: "dialysis", "end stage renal disease", "renal failure", and must have one of the following laboratory values: "E: densepercentolekens loci _3094-0_0.8_ mg _ dl", "E: densepercentolekens loci _ 2160-0.85 _ mg _ dl", "E: densepercentolekens loci _ 2160-0.9 _ mg _ dl (coverage: 35)".
3) Active learning is used to strategically select untagged examples for human experts to evaluate, according to a particular strategy.
As described above, we can perform the second phase of the method of FIG. 1 several times to further refine the manually assigned labels using active learning (step 26).
Claims (29)
1. A computer-implemented method of generating class labels for members of a set of training data, wherein the training data for each member of the set comprises a plurality of features, the method comprising the steps of executing in a processor of a computer:
a) receiving an initial list of partition features conceptually related to the category label from an operator;
b) tagging the training data with the partition features and identifying additional partition features associated with the category tag that are not in the initial list of partition features with an augmented model;
c) adding selected ones of the additional section features to the initial section feature list according to the operator input;
d) repeating steps b) and c) one or more times to obtain a final partition feature list;
e) tagging the training data with the final list of partition features from step d);
f) building a further enhancement model using the labels generated in step e);
g) scoring the training examples using the further enhanced model of step f), and
h) generating labels from the subset of members of the training examples based on the scoring of step g) using input from the operator.
2. The method of claim 1, wherein step f) comprises the steps of: initializing the further enhancement model with the final list of partition features and iteratively generating additional features for building a new further enhancement model in each iteration.
3. The method of claim 1or claim 2, wherein generating iterations of additional features comprises receiving operator input to deselect some of the generated additional features.
4. A method according to any one of claims 1-3, wherein the scoring step g) comprises determining a threshold value associated with the score and identifying members of the training data within the threshold value, and wherein step h) comprises the step of generating labels for the identified members of the set of training data.
5. The method according to any of claims 1-4, further comprising the step of building a predictive model from a set of samples having labels assigned according to steps e) and h).
6. The method of any of claims 1-5, wherein the members of the training data set comprise respective sets of electronic health records.
7. The method of claim 6, wherein at least some of the features of the training data are associated with real-valued and time components, and such features are in { X, X }i,tiTuple format of type, where X is the name of the feature, XiIs the real value of the feature, and tiIs said real value xiA time component of (a); and wherein the features comprise a predicate defined as a binary function operating on a sequence of tuples or a logical operation on the sequence of tuples.
8. The method of claim 6, wherein at least some of the features of the training data are words contained in the health record and at least some of the partitioned features are a determination of whether one or more words are present in the health record.
9. The method of claim 6, wherein at least some of the features in the training data are measurements in the health record and at least some of the partition features are a determination of whether one or more measurements are present in the health record.
10. A computer-implemented method of generating a partitioned feature list for assigning class labels to members of a set of training data, wherein the training data for each member of the set comprises a plurality of features, the method comprising the steps of executing in a processor of a computer:
a) receiving an initial list of partition features conceptually related to the category label from an operator;
b) tagging the training data using the initial list of partition features and utilizing an enhanced model to identify additional partition features that are not in the initial list of partition features that are associated with the category tag;
c) adding selected ones of the additional partition features to the initial partition feature list according to the operator input to obtain an updated partition feature list;
d) repeating steps b) and c) one or more times using the updated partition feature list as input in step b) to obtain a final partition feature list.
11. The method of claim 10, wherein step b) comprises iteratively building an enhancement model initialized with the initial set of partition features, and wherein in each iteration of building the enhancement model, additional partition features are identified.
12. The method of claim 10 or claim 11, wherein the method further comprises the step of using the final list of partitioned features to generate the class labels for members in the training data set.
13. The method of any of claims 10-12, wherein the set of training data comprises a set of electronic health records.
14. The method of claim 13, wherein the training data is associated with real-valued and time components and is in { X, X }i,tiTuple format of type, where X is the name of the feature, XiIs the real value of the feature, and tiIs said real value xiA time component of (a); and the features include a predicate defined as a binary function that operates on a sequence of tuples or a logical operation on the sequence of tuples.
15. A computer-implemented method for generating class labels for members of a set of training data, wherein the training data for each member of the set comprises a plurality of features, the method comprising the steps of executing in a processor of a computer:
(a) progressively building a list of partitioned features using a first augmented model with user input;
(b) tagging members of the training data set with the list of partitioned features;
(c) building a further enhancement model from the labeled members of the set of training data and generating additional partition features;
(d) scoring labels of members of the training data set and determining a threshold;
(e) identifying a subset of members of the training data set that are within the threshold; and
(f) assigning a label to the subset of members using user input.
16. The method of claim 15, wherein the set of training data comprises a set of electronic health records.
17. The method of claim 16, wherein the training data is associated with real-valued and time components and is in { X, X }i,tiTuple format of type, where X is the name of the feature, XiIs the real value of the feature, and tiIs said real value xiA time component of (a); and the features include a predicate defined as a binary function that operates on a sequence of tuples or a logical operation on the sequence of tuples.
18. The method of claim 15, further comprising the step of repeating steps (c), (d), (e), and (f) at least once.
19. The method according to any of claims 15-18, further comprising the step of building a predictive model from the training data set with labels assigned according to steps b) and f).
20. A computer-implemented method of generating a respective class label for each of a plurality of members of a set of training data, wherein the training data for each member of the set comprises a plurality of features, the method comprising the steps of executing in a processor of a computer:
a) receiving an initial list of tests from an operator, the tests conceptually associated with the category labels, each test being a function applicable to any member of the training data to detect one or more features in that member of the training data;
b) tagging the training data using the test and identifying additional tests associated with the category tag that are not in the initial test list;
c) adding selected ones of the additional tests to the initial test list based on data input from an operator;
d) repeating steps b) and c) one or more times to obtain a final test list;
e) tagging the training data with the final test list from step d);
f) building an augmented model using the tags generated in step e);
g) scoring the training examples using the augmented model established in step f), and
h) generating, using input from an operator, respective labels for a subset of the members of the training examples based on the scores of step g).
21. The method of claim 20, wherein in step b) the additional tests are generated using an augmented model.
22. The method according to claims 20-21, wherein step f) comprises the steps of: a further enhancement model is initialized with the final test list and additional tests for building a new enhancement model are iteratively generated in each iteration.
23. The method of claim 22, wherein generating iterations of additional tests includes receiving operator input to deselect some of the generated additional tests.
24. A method according to any one of claims 20-23, wherein the scoring step g) comprises determining a threshold value associated with the score and identifying members of the training data whose score differs from the threshold value by an amount within a predetermined range, and wherein step h) comprises the step of generating labels for the identified members of the set of training data.
25. The method according to any of claims 20-24, further comprising the step of building a predictive model from a set of samples having labels assigned according to steps e) and h).
26. The method of any of claims 20-24, wherein the members of the training data set comprise respective sets of electronic health records.
27. The method of claim 26, wherein at least some features of the training data are associated with real-valued and temporal components and are in the form { X, Xi,tiTuple format of type, where X is the name of the feature, XiIs the real value of the feature, and tiIs said real value xiA time component of (a); and the test includes a predicate defined as a binary function that operates on a sequence of tuples or a logical operation on the sequence of tuples.
28. The method of claim 26, wherein at least some features of the training data are words contained in the health records, and at least some of the tests are determinations of whether one or more corresponding predetermined words are present in the health records.
29. The method of claim 26, wherein at least some of the features in the training data are measurements in the health record and at least some of the features are a determination of whether one or more measurements are present in the health record.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201762552011P | 2017-08-30 | 2017-08-30 | |
US62/552,011 | 2017-08-30 | ||
PCT/US2017/054215 WO2019045759A1 (en) | 2017-08-30 | 2017-09-29 | Machine learning method for generating labels for fuzzy outcomes |
Publications (1)
Publication Number | Publication Date |
---|---|
CN111066033A true CN111066033A (en) | 2020-04-24 |
Family
ID=65525998
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201780094512.0A Pending CN111066033A (en) | 2017-08-30 | 2017-09-29 | Machine learning method for generating labels of fuzzy results |
Country Status (4)
Country | Link |
---|---|
US (1) | US20200388358A1 (en) |
EP (1) | EP3676756A4 (en) |
CN (1) | CN111066033A (en) |
WO (1) | WO2019045759A1 (en) |
Cited By (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
WO2022012347A1 (en) * | 2020-07-14 | 2022-01-20 | International Business Machines Corporation | Predictive models having decomposable hierarchical layers configured to generate interpretable results |
Families Citing this family (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11875230B1 (en) * | 2018-06-14 | 2024-01-16 | Amazon Technologies, Inc. | Artificial intelligence system with intuitive interactive interfaces for guided labeling of training data for machine learning models |
US11120364B1 (en) | 2018-06-14 | 2021-09-14 | Amazon Technologies, Inc. | Artificial intelligence system with customizable training progress visualization and automated recommendations for rapid interactive development of machine learning models |
US11868436B1 (en) | 2018-06-14 | 2024-01-09 | Amazon Technologies, Inc. | Artificial intelligence system for efficient interactive training of machine learning models |
US11915113B2 (en) * | 2019-03-07 | 2024-02-27 | Verint Americas Inc. | Distributed system for scalable active learning |
US11669753B1 (en) | 2020-01-14 | 2023-06-06 | Amazon Technologies, Inc. | Artificial intelligence system providing interactive model interpretation and enhancement tools |
US20210304039A1 (en) * | 2020-03-24 | 2021-09-30 | Hitachi, Ltd. | Method for calculating the importance of features in iterative multi-label models to improve explainability |
CN112699467A (en) * | 2020-12-29 | 2021-04-23 | 香港理工大学深圳研究院 | Method for supervising and checking ships and allocating inspectors in port country |
Citations (9)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20030208374A1 (en) * | 2002-05-02 | 2003-11-06 | Komal Mangtani | System and method for electronic business transaction reliability |
US20090319456A1 (en) * | 2008-06-19 | 2009-12-24 | Microsoft Corporation | Machine-based learning for automatically categorizing data on per-user basis |
US20110119210A1 (en) * | 2009-11-16 | 2011-05-19 | c/o Microsoft Corporation | Multiple Category Learning for Training Classifiers |
US20120290319A1 (en) * | 2010-11-11 | 2012-11-15 | The Board Of Trustees Of The Leland Stanford Junior University | Automatic coding of patient outcomes |
CN103294764A (en) * | 2012-02-29 | 2013-09-11 | 国际商业机器公司 | Method and system for extracting information from electronic documents |
CN103299324A (en) * | 2010-11-11 | 2013-09-11 | 谷歌公司 | Learning tags for video annotation using latent subtags |
CN105894088A (en) * | 2016-03-25 | 2016-08-24 | 苏州赫博特医疗信息科技有限公司 | Medical information extraction system and method based on depth learning and distributed semantic features |
CN106682696A (en) * | 2016-12-29 | 2017-05-17 | 华中科技大学 | Multi-example detection network based on refining of online example classifier and training method thereof |
US20170140114A1 (en) * | 2015-11-13 | 2017-05-18 | Cerner Innovation, Inc. | Machine learning clinical decision support system for risk categorization |
Family Cites Families (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7756800B2 (en) * | 2006-12-14 | 2010-07-13 | Xerox Corporation | Method for transforming data elements within a classification system based in part on input from a human annotator/expert |
WO2016175990A1 (en) * | 2015-04-30 | 2016-11-03 | Biodesix, Inc. | Bagged filtering method for selection and deselection of features for classification |
US11544570B2 (en) * | 2015-06-30 | 2023-01-03 | Arizona Board Of Regents On Behalf Of Arizona State University | Method and apparatus for large scale machine learning |
US9805305B2 (en) * | 2015-08-07 | 2017-10-31 | Yahoo Holdings, Inc. | Boosted deep convolutional neural networks (CNNs) |
US10332028B2 (en) * | 2015-08-25 | 2019-06-25 | Qualcomm Incorporated | Method for improving performance of a trained machine learning model |
-
2017
- 2017-09-29 CN CN201780094512.0A patent/CN111066033A/en active Pending
- 2017-09-29 US US16/636,989 patent/US20200388358A1/en active Pending
- 2017-09-29 WO PCT/US2017/054215 patent/WO2019045759A1/en unknown
- 2017-09-29 EP EP17923667.4A patent/EP3676756A4/en active Pending
Patent Citations (9)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20030208374A1 (en) * | 2002-05-02 | 2003-11-06 | Komal Mangtani | System and method for electronic business transaction reliability |
US20090319456A1 (en) * | 2008-06-19 | 2009-12-24 | Microsoft Corporation | Machine-based learning for automatically categorizing data on per-user basis |
US20110119210A1 (en) * | 2009-11-16 | 2011-05-19 | c/o Microsoft Corporation | Multiple Category Learning for Training Classifiers |
US20120290319A1 (en) * | 2010-11-11 | 2012-11-15 | The Board Of Trustees Of The Leland Stanford Junior University | Automatic coding of patient outcomes |
CN103299324A (en) * | 2010-11-11 | 2013-09-11 | 谷歌公司 | Learning tags for video annotation using latent subtags |
CN103294764A (en) * | 2012-02-29 | 2013-09-11 | 国际商业机器公司 | Method and system for extracting information from electronic documents |
US20170140114A1 (en) * | 2015-11-13 | 2017-05-18 | Cerner Innovation, Inc. | Machine learning clinical decision support system for risk categorization |
CN105894088A (en) * | 2016-03-25 | 2016-08-24 | 苏州赫博特医疗信息科技有限公司 | Medical information extraction system and method based on depth learning and distributed semantic features |
CN106682696A (en) * | 2016-12-29 | 2017-05-17 | 华中科技大学 | Multi-example detection network based on refining of online example classifier and training method thereof |
Cited By (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
WO2022012347A1 (en) * | 2020-07-14 | 2022-01-20 | International Business Machines Corporation | Predictive models having decomposable hierarchical layers configured to generate interpretable results |
US11593680B2 (en) | 2020-07-14 | 2023-02-28 | International Business Machines Corporation | Predictive models having decomposable hierarchical layers configured to generate interpretable results |
GB2611983A (en) * | 2020-07-14 | 2023-04-19 | Ibm | Predictive models having decomposable hierarchical layers configured to generate interretable results |
Also Published As
Publication number | Publication date |
---|---|
WO2019045759A1 (en) | 2019-03-07 |
EP3676756A1 (en) | 2020-07-08 |
US20200388358A1 (en) | 2020-12-10 |
EP3676756A4 (en) | 2021-12-15 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN111066033A (en) | Machine learning method for generating labels of fuzzy results | |
Dash et al. | Deep learning techniques for biomedical and health informatics | |
Suresh et al. | Hybridized neural network and decision tree based classifier for prognostic decision making in breast cancers | |
Blum | Discovery and Representation of Causal Relationships from a Large Time-Oriented Clinical Database: The RX Project: The RX Project | |
Peissig et al. | Relational machine learning for electronic health record-driven phenotyping | |
JP6916310B2 (en) | Human-participatory interactive model training | |
Huang et al. | Probabilistic modeling personalized treatment pathways using electronic health records | |
US11847411B2 (en) | Obtaining supported decision trees from text for medical health applications | |
Mathur | Machine learning applications using python: Cases studies from healthcare, retail, and finance | |
US20180210925A1 (en) | Reliability measurement in data analysis of altered data sets | |
Rabie et al. | A decision support system for diagnosing diabetes using deep neural network | |
Rios et al. | Supervised extraction of diagnosis codes from EMRs: role of feature selection, data selection, and probabilistic thresholding | |
Enad et al. | A Review on artificial intelligence and quantum machine learning for heart disease diagnosis: current techniques, challenges, and issues, recent developments, and future directions | |
Ahmad et al. | Lightweight ResGRU: a deep learning-based prediction of SARS-CoV-2 (COVID-19) and its severity classification using multimodal chest radiography images | |
Xue et al. | Differential diagnosis of heart disease in emergency departments using decision tree and medical knowledge | |
Schneider | Machine learning and artificial intelligence | |
Shawi et al. | Interpretable local concept-based explanation with human feedback to predict all-cause mortality | |
Baron | Artificial Intelligence in the Clinical Laboratory: An Overview with Frequently Asked Questions | |
Alharbi | Unsupervised abstraction for reducing the complexity of healthcare process models | |
Bhattacharya et al. | Machine Learning for Biomedical and Health Informatics | |
Gancheva et al. | X-Ray Images Analytics Algorithm based on Machine Learning | |
Shellshear et al. | Machine learning, deep learning and neural networks | |
Nasarian et al. | Designing Interpretable ML System to Enhance Trustworthy AI in Healthcare: A Systematic Review of the Last Decade to A Proposed Robust Framework | |
Damen et al. | Pastel: a semantic platform for assisted clinical trial patient recruitment | |
US11636933B2 (en) | Summarization of clinical documents with end points thereof |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |