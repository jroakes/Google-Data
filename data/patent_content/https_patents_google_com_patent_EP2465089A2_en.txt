EP2465089A2 - Separating reputation of users in different roles - Google Patents
Separating reputation of users in different rolesInfo
- Publication number
- EP2465089A2 EP2465089A2 EP10808522A EP10808522A EP2465089A2 EP 2465089 A2 EP2465089 A2 EP 2465089A2 EP 10808522 A EP10808522 A EP 10808522A EP 10808522 A EP10808522 A EP 10808522A EP 2465089 A2 EP2465089 A2 EP 2465089A2
- Authority
- EP
- European Patent Office
- Prior art keywords
- user
- nodes
- comment
- ranking
- rater
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Ceased
Links
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q30/00—Commerce
- G06Q30/02—Marketing; Price estimation or determination; Fundraising
Definitions
- Amazon.com allows users to review products offered on that web site and to rate the reviews provided by reviewers.
- a particular user may act as both an author, by submitting a review, and a rater, by rating a review submitted by another user.
- a method may be performed by one or more server devices.
- the method may include receiving, from a user and at a processor of the one or more server devices, a first comment associated with a web page, the user acting in an author capacity with respect to the first comment; receiving, from the user and at a processor of the one or more server devices, a rating of a second comment, the second comment being different from the first comment, the user acting in a rater capacity with respect to the second comment; calculating, using a processor of the one or more server devices, a first ranking score for the user acting in the author capacity based on one or more first signals; calculating, using a processor of the one or more server devices, a second ranking score for the user acting in the rater capacity based on one or more second signals, where the one or more second signals are different from the one or more first signals; and providing one of a first ranked list that includes a plurality of authors, the user being placed in the first list according to the first ranking score, or a second ranked list that includes
- one or more server devices may include a processor and a memory.
- the processor may receive, from a user, a first comment for a web page, the user acting in an author capacity with respect to the first comment; receive, from the user, a rating of a second comment, the second comment being different from the first comment, the user acting in a rater capacity with respect to the second comment; determine a first ranking score for the user acting in the author capacity, the first ranking score being based on one or more first signals; and determine a second ranking score for the user acting in the rater capacity, the second ranking score being based on one or more second signals, the one or more second signals being different from the one or more first signals.
- the memory may store the first ranking score, and store the second ranking score.
- a system may include one or more devices.
- the one or more devices may include means for determining a first reputation for a user in an author capacity; means for determining a second reputation for the user in a rater capacity, the second reputation being determined differently than the first reputation; means for determining an overall reputation for the user based on the first reputation and the second reputation; and means for providing a ranked list of users, the user being placed in the list at a location based on the overall reputation.
- a computer-readable medium may contain instructions executable by one or more devices.
- the computer-readable medium may include one or more instructions to represent a plurality of users, acting in author capacities, as first nodes; one or more instructions to represent the plurality of users, acting in rater capacities, as second nodes; one or more instructions to represent a plurality of comments as third nodes; one or more instructions to form first edges from the first nodes to the third nodes based on relationships between the first nodes and the third nodes; one or more instructions to form second edges from the third nodes to the first nodes based on the relationships between the first nodes and the third nodes; one or more instructions to form third edges from the second nodes to the third nodes based on relationships between the second nodes and the third nodes; one or more instructions to form fourth edges from the first nodes to the second nodes based on relationships between the first nodes and the second nodes; and one or more instructions to form fifth edges from the second nodes to the first nodes based on the relationships between the first nodes.
- the computer-readable medium may further include one or more instructions to assign initial values to the first nodes, the second nodes, and the third nodes; one or more instructions to run iterations of a graph algorithm to obtain ranking values, the iterations being run until values of the first nodes, second nodes, and third nodes converge or a number of iterations has been reached, where the ranking value of each first node reflects a reputation of the corresponding user acting in the author capacity, where the ranking value of each second node reflects a reputation of the corresponding user acting in the rater capacity, and where the ranking value of each third node reflects an indication of quality of the corresponding comment; and one or more instructions to provide at least one of a list of authors that is ordered based on the ranking values of the first nodes, a list of raters that is ordered based on the ranking values of the second nodes, or a ranked list of comments, the comments in the ranked list being selected based using the ranking values of the comments in the ranked list.
- a method may include maintaining, in a memory associated with one or more server devices, a database that associates, for each user of a plurality of users, an identifier for the user with information identifying a first ranking score of the user acting in an author capacity with respect to one or more first comments and a second ranking score of the user acting in a rater capacity with respect to one or more second comments; receiving, at a processor associated with the one or more server devices, a request for a ranking of raters; retrieving, in response to receiving the request and using a processor associated with the one or more server devices, the user identifiers and the second ranking scores, associated with the users, from the database; and providing, using a processor associated with one or more server devices, a list of the user identifiers, where the user identifiers in the list are ranked according to the second ranking scores associated with the users.
- a method may be performed by one or more server devices.
- the method may include determining, using a processor of the one or more server devices, a first reputation for a user acting in a first role; determining, using a processor of the one or more server devices, a second reputation for the user acting in a second role, the second role being different than the first role; associating, in a memory associated with the one or more server devices, an identifier of the user with a first value representing the first reputation and a second value representing the second reputation; and providing, using a processor of the one or more server devices, a ranked list of users, the user being placed in the ranked list at a location based on the first reputation or the second reputation.
- Fig. 1 is a diagram illustrating an overview of an exemplary implementation described herein;
- Fig. 2 is a diagram of an exemplary environment in which systems and methods described herein may be implemented
- Fig. 3 is a diagram of exemplary components of a client or a server of Fig. 2;
- Fig. 4 is a diagram of functional components of a server of Fig. 2;
- Fig. 5 is a diagram of functional components of the comments component of Fig. 4;
- Figs. 6 and 7 are diagrams of exemplary databases that may be associated with the comments component of Fig. 4;
- Fig. 8 is a flowchart of an exemplary process for determining initial author scores
- Fig. 9 is a flowchart of an exemplary process for determining initial rater scores
- Fig. 10 is a flowchart of an exemplary process for determining initial comment scores
- Fig. 1 1 is a flowchart of an exemplary process for determining ranking scores for authors, raters, and comments;
- Fig. 12 is a flowchart of an exemplary process for providing user information
- Fig. 13 is a diagram of an exemplary graphical user interface that may provide user information
- Fig. 14 is a flowchart of an exemplary process for providing rater rankings
- Figs. 15-17 are diagrams of exemplary graphical user interfaces that may provide rater ranking information.
- Fig. 18 is a diagram of an exemplary graphical user interface that may provide user ranking information.
- a "comment,” as used herein, may include text, audio data, video data, and/or image data that provides an opinion of, or otherwise remarks upon, the contents of a document or a portion of a document.
- One example of a comment may include a document whose sole purpose is to contain the opinion/remark.
- Another example of a comment may include a blog post.
- Yet another example of a comment may include a web page or a news article that remarks upon an item (e.g., a product, a service, a company, a web site, a person, a geographic location, or something else that can be remarked upon).
- a "document,” as the term is used herein, is to be broadly interpreted to include any machine-readable and machine-storable work product.
- a document may include, for example, an e-mail, a web site, a file, a combination of files, one or more files with embedded links to other files, a news group posting, a news article, a blog, a business listing, an electronic version of printed text, a web advertisement, etc.
- a common document is a web page.
- Documents often include textual information and may include embedded information (such as meta information, images, hyperlinks, etc.) and/or embedded instructions (such as Javascript, etc.).
- Fig. 1 is a diagram illustrating an overview of an exemplary implementation described herein.
- a web page provides information about a particular topic (shown simply as "web page” in Fig. 1).
- a user (shown as “user_A” in Fig. 1) may decide to provide a comment regarding a web page. In this case, the user might activate a commenting feature to provide the comment. The user may then provide an opinion or remark as the content of the comment.
- user_A has provided two comments regarding the web page (shown as “comment 1" and “comment 2" in Fig. 1).
- another user shown as “user_B” in Fig. 1) has also provided two comments (shown as "comment 3" and "comment 4" in Fig. 1) regarding the web page.
- the comments may be stored in a database in association with the web page.
- users may rate comments authored by other users.
- user_A has rated comment 3, authored by user B.
- the rating may include a positive indication (e.g., that user A found the comment helpful, agreed with the comment, liked the comment, etc.) or a negative indication (e.g., that user A found the comment unhelpful, disagreed with the comment, disliked the comment, etc.).
- user_B has rated comment 2, authored by user_A. In this way, user_A and user_B may act as authors for comments provided for the portion of the web page and raters for ratings given to comments provided by others.
- a user's reputation may be separated into different roles (e.g., an author role and a rater role) and the user's reputation with respect to these different roles may individually contribute to the ranking of comments with which the user is associated in an author capacity or a rater capacity.
- the different roles may affect the ranking of each other. That is, a user's author rank may affect the user's rater rank, and the user's rater rank may affect the user's author rank.
- Fig. 1 The number of users, comments, and web pages, illustrated in Fig. 1, is provided for explanatory purposes only. It will be appreciated that, in practice, there may be more users and/or web pages and more or fewer comments.
- FIG. 2 is a diagram of an exemplary environment 200 in which systems and methods described herein may be implemented.
- Environment 200 may include multiple clients 210 connected to multiple servers 220-240 via a network 250. Two clients 210 and three servers
- 220-240 have been illustrated as connected to network 250 for simplicity. In practice, there may be more or fewer clients and servers. Also, in some instances, a client may perform a function of a server and a server may perform a function of a client.
- Clients 210 may include client entities.
- An entity may be defined as a device, such as a personal computer, a wireless telephone, a personal digital assistant (PDA), a lap top, or another type of computation or communication device, a thread or process running on one of these devices, and/or an object executed by one of these devices.
- PDA personal digital assistant
- a client 210 may include a browser application that permits documents to be searched and/or accessed.
- Client 210 may also include software, such as a plug- in, an applet, a dynamic link library (DLL), or another executable object or process, that may operate in conjunction with (or be integrated into) the browser to obtain and display comments.
- Client 210 may obtain the software from server 220 or from a third party, such as a third party server, disk, tape, network, CD-ROM, etc.
- the software may be pre-installed on client 210.
- the software will be described as integrated into the browser.
- the browser may provide a commenting function.
- the commenting function may permit a user to generate a comment regarding a document, permit the user to view a comment that was previously generated by the user or by other users, and/or permit the user to rate a previously-generated comment.
- Servers 220-240 may include server entities that gather, process, search, and/or maintain documents in a manner described herein.
- server 220 may gather, process, and/or maintain comments that are associated with particular documents.
- Servers 230 and 240 may store or maintain comments and/or documents.
- servers 220-240 are shown as separate entities, it may be possible for one or more of servers 220-240 to perform one or more of the functions of another one or more of servers 220-240. For example, it may be possible that two or more of servers 220-240 are implemented as a single server. It may also be possible for a single one of servers 220-240 to be implemented as two or more separate (and possibly distributed) devices.
- Network 250 may include any type of network, such as a local area network (LAN), a wide area network (WAN), a telephone network (e.g., the Public Switched Telephone Network (PSTN) or a cellular network), an intranet, the Internet, or a combination of networks.
- LAN local area network
- WAN wide area network
- PSTN Public Switched Telephone Network
- Fig. 3 is a diagram of exemplary components of a client or server entity (hereinafter called “client/server entity”), which may correspond to one or more of clients 210 and/or servers 220-240.
- client/server entity may include a bus 310, a processor 320, a main memory 330, a read only memory (ROM) 340, a storage device 350, an input device 360, an output device 370, and a communication interface 380.
- client/server entity may include additional, fewer, different, or differently arranged components than are illustrated in Fig. 3.
- Bus 310 may include a path that permits communication among the components of the client/server entity.
- Processor 320 may include a processor, a microprocessor, or processing logic (e.g., an application specific integrated circuit (ASIC) or a field programmable gate array (FPGA)) that may interpret and execute instructions.
- Main memory 330 may include a random access memory (RAM) or another type of dynamic storage device that may store information and instructions for execution by processor 320.
- ROM 340 may include a ROM device or another type of static storage device that may store static information and instructions for use by processor 320.
- Storage device 350 may include a magnetic and/or optical recording medium and its corresponding drive, or a removable form of memory, such as a flash memory.
- Input device 360 may include a mechanism that permits an operator to input information to the client/server entity, such as a keyboard, a mouse, a button, a pen, a touch screen, voice recognition and/or biometric mechanisms, etc.
- Output device 370 may include a mechanism that outputs information to the operator, including a display, a light emitting diode (LED), a speaker, etc.
- Communication interface 380 may include any transceiver-like mechanism that enables the client/server entity to communicate with other devices and/or systems. For example, communication interface 380 may include mechanisms for communicating with another device or system via a network, such as network 250.
- the client/server entity may perform certain operations relating to determining the reputations of users with respect to their roles as authors and raters.
- the client/server entity may perform these operations in response to processor 320 executing software instructions contained in a computer-readable medium, such as memory 330.
- a computer-readable medium may be defined as a logical or physical memory device.
- a logical memory device may include a space within a single physical memory device or spread across multiple physical memory devices.
- the software instructions may be read into memory 330 from another computer-readable medium, such as storage device 350, or from another device via communication interface 380.
- the software instructions contained in memory 330 may cause processor 320 to perform processes that will be described later.
- hardwired circuitry may be used in place of or in combination with software instructions to implement processes described herein.
- implementations described herein are not limited to any specific combination of hardware circuitry and software.
- Fig. 4 is a diagram of exemplary functional components of server 220.
- server 220 may include a comments component 410 and a comments database 420.
- server 220 may include more or fewer functional components.
- one or more of the functional components shown in Fig. 4 may be located in a device separate from server 220.
- Comments component 410 may interact with clients 210 to obtain and/or serve comments.
- a user of a client 210 may access a particular document and generate a comment regarding the document.
- the document may include some amount of text (e.g., some number of words), an image, a video, or some other form of media.
- Client 210 may send the comment and information regarding the document to comments component 410.
- Comments component 410 may receive the comment provided by a client 210 in connection with the particular document. Comments component 410 may gather certain information regarding the comment, such as information regarding the author of the comment, a timestamp that indicates a date and/or time at which comment was created, the content of the comment, and/or an address (e.g., a URL) associated with the document. Comments component 410 may receive at least some of this information from client 210. Comments component 410 may store the information regarding the comment in comments database 420.
- Comments component 410 may also serve a comment in connection with a document accessed by a client 210.
- comments component 410 may obtain a comment from comments database 420 and provide that comment to client 210 when client 210 accesses a document with which that comment is associated in comments database 420.
- Comments component 410 may also receive ratings for comments served by comments component 410.
- a comment When a comment is presented to a user in connection with presentation of a particular document, the user may be given the opportunity to provide explicit feedback on that comment. For example, the user may indicate whether the comment is meaningful (e.g., a positive vote) or not meaningful (e.g., a negative vote) to the user (with respect to the particular document) by selecting an appropriate voting button.
- This user feedback positive or negative
- the rating may be a simple positive or negative indication, as described above, or may represent a degree of like/dislike for a comment (e.g., the rating may be represented as a scale from, for example, 1 to 5).
- Client 210 may send the rating and other information, such as information identifying the particular comment on which the rating is provided, information identifying the user, etc. to comments component 410.
- Comments component 410 may store the ratings in comments database 420 in association with information identifying the users that submitted the ratings and the comments for which the ratings were submitted.
- Comments database 420 may store information regarding comments.
- comments database 420 may include various fields that are separately searchable.
- Comments component 410 may search comments database 420 to identify comments associated with a particular author, a particular rater, or a particular document.
- Fig. 5 is a diagram of functional components of comments component 410 of Fig. 4. As shown in Fig. 5, comments component 410 may include an author component 510, a rater component 520, a comment component 530, and a rank calculation component 540. In another implementation, comments component 410 may include more or fewer functional components. For example, one or more of the functional components shown in Fig. 5 may be located in a device separate from server 220 or may be associated with a different functional component of server 220.
- Author component 510 may receive signals associated with an author of a comment and calculate an initial author score for the author based on the signals. In one implementation, author component 510 may calculate an initial author score for a user based on, for example, the length of time that the user has been a user of the system (e.g., the commenting system) or registered with the system (e.g., with the assumption that the longer that a user has been a user of the system (or registered with the system), the more trustworthy the user is). Author component 510 may further calculate the initial author score based on additional or other signals relating to the author.
- the system e.g., the commenting system
- Author component 510 may further calculate the initial author score based on additional or other signals relating to the author.
- the age of the author if known, may be used in the initial author score calculation (e.g., with the assumption, for example, that the users between a certain age range may provide better comments).
- the education background of the author if known, may be used in the initial author score calculation (e.g., with the assumption, for example, that the users with higher degrees may provide better comments).
- author component 510 may weigh some of the signals more heavily than other signals.
- Rater component 520 may receive signals associated with a rater of a comment and calculate an initial score for the rater based on the signals.
- rater component 520 may calculate an initial rater score for a user based on the ratings provided by the user on a group of comments and the ratings provided by other users for the same group of comments. For example, rater component 520 may identify the comment ratings submitted by the user and compare how the user rated the different comments to how the majority of users rated the different comments. If rater component 520 determines that the user has agreed with the consensus on a majority of the user's ratings, rater component 520 may calculate a higher (i.e., better) initial rater score for that user.
- rater component 520 may calculate a lower (i.e., worse) initial rater score for that user. Rater component 520 may consider other signals in calculating the initial rater score. When multiple signals are used in calculating the initial rater score, rater component 520 may weigh some of the signals more heavily than other signals.
- Comment component 530 may receive signals associated with a comment and calculate an initial score for the comment based on the signals. In one implementation, comment component 530 may calculate an initial comment score for a comment based on the length of the comment. In this situation, longer comments (e.g., comments containing more than a threshold number of words) may be considered to be better comments than comments containing a fewer number of words. Comment component 530 may alternatively or additionally consider a language model of the comment. For example, the closer the language of a comment is to Standard English (or some other language), the better the comment may be considered to be. Other signals may alternatively or additionally be used. When multiple signals are used in calculating the initial comment score, comment component 530 may weigh some of the signals more heavily than other signals.
- Rank calculation component 540 may combine the initial author scores, initial rater scores, and initial comment scores to calculate author ranking scores, rater ranking scores, and comment ranking scores.
- the author ranking scores may reflect reputations of the
- a higher ranking score may reflect that a user has a better reputation as an author over another user with a lower ranking score.
- the rater ranking scores may reflect reputations of the corresponding users as raters.
- the comment ranking scores may represent the quality of the corresponding comments.
- rank calculation component 540 may calculate the author ranking scores, rater ranking scores, and comment ranking scores based on a graph.
- rank calculation component 540 may represent every author, every rater, and every comment as nodes.
- Rank calculation component 540 may further represent relationships between these nodes as edges (or links). For example, an edge may be present between a first node that represents an author and a second node that represents the comment that the author submitted.
- edges or links
- an edge may be present between a first node that represents an author and a second node that represents the comment that the author submitted.
- author nodes may be linked to the comment nodes that the authors submitted and the comment nodes may be linked to the author nodes, allowing reputations of author nodes to be passed to comment nodes and qualities of comment nodes to be passed to author nodes.
- an edge may be present between a first node that represents a rater and a second node that represents the comment for which the rater has submitted a rating.
- rater nodes may be linked to comment nodes and comment nodes may be linked to rater nodes, allowing reputations of rater nodes to be passed to comment nodes and qualities of comment nodes to be passed to rater nodes.
- an edge may be present between a first node that represents a user in his/her author capacity and a second node that represents the user in his/her rater capacity.
- the node representing author_A may be linked to the node representing rater A and the node representing rater A may be linked to the node representing author_A.
- some of the edges may be weighed more heavily than other edges. For example, an edge from an author node to a rater node may be assigned a higher weight than the weight assigned to an edge from the rater node to the author node.
- the different weights may, for example, be based on the observation that an author with a good reputation may likely also be a good rater, but a good rater may not necessarily be a good author.
- ranking calculation component 540 may calculate ranking scores for the nodes.
- rank calculation component 540 may use an algorithm similar to the PageRankTM algorithm to calculate the ranking scores for the nodes.
- rank calculation component 540 may assign the initial scores calculated by author component 510, rater component 520, and comment component 530 to the nodes.
- Rank calculation component 540 may run iterations of the graph algorithm (where all or a portion of the initial scores of the nodes are conveyed to nodes to which the node links) until the ranking scores converge.
- rank calculation component 540 may terminate running iterations of the graph algorithm after a fixed number of iterations (without checking for convergence).
- rank calculation component 540 may terminate running iterations of the graph algorithm when either the values converge or a predefined maximum number of iterations have been reached.
- rank calculation component 540 may use one or more other algorithms to calculate author ranking scores, rater ranking scores, and comment ranking scores or simply take the initial scores calculated by author component 510, rater component 520, and comment component 530 as the ranking scores. Once calculated, rank calculation component 540 may store the ranking scores in a database, such as databases 600 and 700.
- Fig. 6 is a diagram of a first exemplary database 600 that may be associated with comments component 410 of Fig. 4. While one database is described below, it will be appreciated that database 600 may include multiple databases stored locally at server 220 (e.g., in comments database 420), or stored at one or more different and/or possibly remote locations.
- database 600 may include a group of entries with the following exemplary fields: a user identifier (ID) field 610, an author ranking field 620, a rater ranking field 630, and a user ranking field 640.
- Database 600 may contain additional fields (not shown) that aid comment component 410 in providing information relating to users.
- User identifier field 610 may store information that identifies a user.
- user identifier field 610 may store a sequence of characters that uniquely identifies a user. In one implementation, the sequence of characters may correspond to a user name, an e-mail address, or some other type of identification information.
- Author ranking field 620 may store a value representing the author ranking score (e.g., as calculated by rank calculation component 540) for the particular user, identified in user identifier field 610, when acting in an author capacity.
- Rater ranking field 630 may store a value representing the rater ranking score (e.g., as calculated by rank calculation component 540) for the particular user, identified in user identifier field 610, when acting in a rater capacity.
- User ranking field 640 may store a value representing an overall user ranking score for the particular user identified in user identifier field 610. The user ranking score may be calculated by combining the author ranking score with the rater ranking score.
- rank calculation component 540 may weigh the author ranking score for a particular user more heavily than the rater ranking score for the user, or vice versa. Rank calculation component 540 may then add the weighted scores to produce the user ranking score. Other ways of combining the author ranking score with the rater ranking score may alternatively be used.
- the user ranking scores may represent overall reputations for the users.
- Fig. 7 is a diagram of a second exemplary database 700 that may be associated with comments component 410 of Fig. 4. While one database is described below, it will be appreciated that database 700 may include multiple databases stored locally at server 220 (e.g., in comments database 420), or stored at one or more different and/or possibly remote locations.
- database 700 may include a group of entries with the following exemplary fields: a comment identifier field 710 and a comment ranking field 720.
- Database 700 may contain additional fields (not shown) that aid comment component 410 in providing information relating to comments.
- Comment identifier field 710 may store information that identifies a comment. For example, comment identifier field 710 may store a sequence of characters that uniquely identifies a comment. Comment ranking field 720 may store a value representing the comment ranking score (e.g., as calculated by rank calculation component 540) for the particular comment identified in comment identifier field 710.
- Fig. 8 is a flowchart of an exemplary process for determining initial author scores.
- the process of Fig. 8 may be performed by one or more components within server 220, client 210, or a combination of client 210 and server 220.
- the process may be performed by one or more components within another device or a group of devices separate from or including client 210 and/or server 220.
- Fig. 8 shows blocks in a particular order, the actual order may differ. For example, some blocks may be performed in parallel or in a different order than shown in Fig. 8.
- the process of Fig. 8 may include receiving signals for authors (block 810).
- the signals may include any information that may be used to determine initial scores for the authors that reflect an initial level of reputation of the authors.
- the signals for a particular author may include the length of time that the author has been a user of the system (e.g., the commenting system) or registered with the system.
- the author when an author has been a user of the system for more than some period of time (or has been registered with the system for more than some period of time), the author may be given a higher (i.e., better) score than another author who has been a user of the system for less than the period of time.
- the signals may include an age of the author.
- an author whose age is between a certain range may be given a higher (i.e., better) score than another author whose age is outside the range.
- the signals may include an educational background of the author. With respect to these signals, an author with a higher educational background may be given a higher (i.e., better) score than another author having a lower educational background.
- Other types of signals may additionally or alternatively be used.
- the signals may further indicate the quantity of comments submitted by the author. With respect to these signals, an author who submits a quantity of comments that is above a threshold may be given a higher score than another author who submits a quantity of comments that is below the threshold.
- the process may further include computing initial author scores based on the received signals (block 820).
- author component 510 may calculate scores for each of the different author signals received and may combine the scores to obtain the initial author scores.
- author component 510 assigns a score to an author based the length of time that the author is a user of the system. For example, if the author has been a user of the system for a very short amount of time (below a first threshold), the author may be assigned a lowest (or worst) score. If the author has been a user of the system for more than the very short amount of time (above the first threshold), but less than a second, longer amount to time (below a second threshold), the author may be assigned a medium score.
- author component 510 may combine the scores to obtain the initial scores for the authors.
- author component 510 may, for each individual author, add the individual scores for the individual author to obtain an initial author score for the author.
- Author component 510 may, in some implementations, weigh the score associated with one of the signals more heavily than the score associated with another one of the signals. Other manners of combining the scores to obtain the initial author scores may alternatively be used.
- the process may further include storing the initial author scores (block 830).
- author component 510 may store the initial author scores in a database, such as database 600.
- author component 510 may store the initial author scores in field 620 in the appropriate rows of database 600.
- Fig. 9 is a flowchart of an exemplary process for determining initial rater scores.
- the process of Fig. 9 may be performed by one or more components within server 220, client 210, or a combination of client 210 and server 220.
- the process of Fig. 9 may be performed by one or more components within server 220, client 210, or a combination of client 210 and server 220.
- the process of Fig. 9 may be performed by one or more components within server 220, client 210, or a combination of client 210 and server 220.
- the process may be performed by one or more components within another device or a group of devices separate from or including client 210 and/or server 220.
- Fig. 9 shows blocks in a particular order, the actual order may differ. For example, some blocks may be performed in parallel or in a different order than shown in Fig. 9.
- the process of Fig. 9 may include identifying, for a rater, ratings of comments submitted by the rater (block 910).
- comments component 410 may receive ratings for comments served by comments component 410.
- the user may be given the opportunity to provide explicit feedback on that comment. For example, the user may indicate whether the comment is meaningful (e.g., a positive vote) or not meaningful (e.g., a negative vote) to the user (with respect to the particular document) by selecting an appropriate voting button. This user feedback (positive or negative) may be considered a rating for the comment by the user.
- Client 210 may send the rating and other information, such as information identifying the particular comment on which the rating is provided, information identifying the user, etc. to comments component 410.
- Comments component 410 may store the ratings in comments database 420 in association with information identifying the users that submitted the ratings and the comments for which the ratings were submitted.
- rater component 520 may identify, in comments database 420 and for a particular rater, the ratings submitted by the rater and the comments for which the ratings were submitted.
- the process may further include determining, for each comment rated by the rater, how other raters rated the comment (block 920). For example, rater component 520 may access, using information identifying a comment, all the ratings submitted for the comment from comments database 420 and may identify, for each comment, how the other raters rated the comment.
- the process may further include computing an initial score for the rater based on how the rater rated the comments and how other raters rated the same comments (block 930). For example, rater component 420 may compare, for each comment that the rater rated, the rater's rating to the ratings submitted by all other raters of the comment. Rater component 420 may calculate a score for each comment based on whether the rater agreed with the majority of raters of the comment. For example, if the rater's rating agreed with the ratings of the majority of raters of the comment, the rater may be assigned a first (or better) score for that particular comment.
- Rater component 420 may add the scores for the comments for which the rater submitted ratings to obtain the initial rater score for the rater.
- rater component 420 may weigh scores for some of the rater's ratings more heavily than others of the rater's ratings. Other manners of combining the scores to obtain the initial rater score may alternatively be used. In addition, other manners of determining the initial rater score may alternatively be used.
- the process may further include storing the initial rater score (block 940).
- rater component 520 may store the initial rater score in a database, such as database 600.
- rater component 520 may store the initial rater score in field 630 in the appropriate row of database 600 for the user identifier with which the rater is associated.
- Fig. 10 is a flowchart of an exemplary process for determining initial comment scores.
- the process of Fig. 10 may be performed by one or more components within server 220, client 210, or a combination of client 210 and server 220.
- the process may be performed by one or more components within another device or a group of devices separate from or including client 210 and/or server 220.
- Fig. 10 shows blocks in a particular order, the actual order may differ. For example, some blocks may be performed in parallel or in a different order than shown in Fig. 10.
- the process of Fig. 10 may include receiving signals for comments (block 1010).
- the signals may include any information that may be used to determine initial scores for the comments that reflect a level of quality of the comments.
- the signals for a particular comment may include the length of the comment. In this situation, a first comment that contains more than a threshold number of terms may be assigned a higher (or better) score than another comment containing less than the threshold number of terms.
- the signals may include information identifying how closely the language used in a particular comment matches a particular language model.
- a comment whose language more closely matches Standard English may be assigned a higher (or better) score than another comment whose language does not closely match Standard English (e.g., comments using slang or abbreviations).
- Other types of signals may alternatively be used.
- the process may further include computing initial comment scores based on the received signals (block 1020).
- comment component 530 may calculate scores for each of the different signals received and may combine the scores to obtain the initial comment scores. Once scores for the different signals are calculated, comment component 530 may combine the scores to obtain the initial scores for the comments. In one implementation, comment component 530 may add the individual scores for the individual comments to obtain an initial comment score for each individual comment. Comment component 530 may, in some implementations, weigh the score from one of the signals more heavily than the score from another one of the signals. Other manners of combining the scores to obtain the initial comment scores may alternatively be used.
- the process may further include storing the initial comment scores (block 1030).
- comment component 530 may store the initial comment scores in a database, such as database 700.
- comment component 530 may store the initial comment scores in field 720 in the appropriate rows of database 700.
- Fig. 1 1 is a flowchart of an exemplary process for determining ranking scores for authors, raters, and comments.
- the process of Fig. 11 may be performed by one or more components within server 220, client 210, or a combination of client 210 and server 220.
- the process may be performed by one or more components within another device or a group of devices separate from or including client 210 and/or server 220.
- Fig. 1 1 shows blocks in a particular order, the actual order may differ. For example, some blocks may be performed in parallel or in a different order than shown in Fig. 1 1.
- the process of Fig. 1 1 may include representing the authors, raters, and comments as nodes (block 11 10).
- rank calculation component 540 may retrieve information identifying each author, rater, and comment from databases 600 and 700 and may represent each author, rater, and comment as a different node in a graph. The process may further include representing relationships between authors, raters, and comments as edges (block 11 10). For example, rank calculation component 540 may provide an edge from a first node that represents an author to a second node that represents the comment that the author submitted. Thus, author nodes may be linked to the comment nodes that the authors submitted. Similarly, rank calculation component 540 may provide an edge from a first node that represents a comment to a second node that represents the author who submitted the comment. Thus, comment nodes may be linked to the author nodes, representing the authors who submitted the comments.
- rank calculation component 540 may provide an edge from a first node that represents a rater and a second node that represents the comment for which the rater has submitted a rating.
- rater nodes may be linked to the comment nodes for which rater nodes have submitted ratings and comment nodes may be linked to rater nodes.
- rank calculation component 540 may provide an edge from a first node that represents a user in his/her author capacity and a second node that represents the user in his/her rater capacity and an edge from the second node to the first node.
- a user's author node may be linked to the user's rater node and a user's rater node may be linked to the user's author node.
- a user's reputation as a rater can influence (positively or negatively) the user's reputation as an author, and vice versa.
- some of the above edges may be weighted more heavily than others of the above edges.
- a first author may identify one or more second authors as "favorite" authors or may subscribe to receive indications when the one or more second authors submit comments.
- rank calculation component 540 may provide an edge from a first node, representing a first user acting in his/her author capacity, and a second node, representing a second user acting in his/her author capacity, where the first user has indicated the second user as a "favorite" or has subscribed to the second user. In this way, a user's author reputation can be influenced by another user's author reputation.
- the process may further include assigning initial values to the nodes in the graph (block
- rank calculation component 540 may assign the initial author scores (e.g., as calculated above with respect to Fig. 8) to the appropriate author nodes.
- rank calculation component 540 may assign the initial rater scores (e.g., as calculated above with respect to Fig. 9) to the appropriate rater nodes.
- rank calculation component 540 may assign the initial comment scores (e.g., as calculated above with respect to Fig. 10) to the appropriate comment nodes.
- the process may further include calculating ranking scores for all the nodes in the graph (block 1130).
- rank calculation component 540 may use an algorithm similar to the PageRankTM algorithm to calculate the ranking scores for the nodes.
- rank calculation component 540 may run iterations of the graph algorithm (where all or a portion of the initial scores of the nodes are conveyed to nodes to which the node links).
- Other techniques for calculating the ranking scores can alternatively be used.
- the process may include determining whether the calculated ranking scores have sufficiently converged and/or a number of iterations have been reached (block 1 140). As described above, rank calculation component 540 may run iterations of the graph algorithm until the values of the nodes converge, until a number of iterations (e.g., a threshold number) has been reached, or either when the values of the nodes have converged or the number of iterations has been reached. If the calculated ranking scores have not sufficiently converged and/or the number of iterations has not been reached (block 1140 - NO), then rank calculation component 540 may continue running iterations of the graph (block 1 130).
- a number of iterations e.g., a threshold number
- the ranking scores may be stored (block 1 150).
- rank calculation component 540 may store the ranking scores in one or more databases, such as databases 600 and 700.
- the storage of the author ranking scores may act to replace the initial author scores in field 620 of database 600
- the storage of the rater ranking scores may act to replace the initial rater scores in field 630 of database 600
- the storage of the comment ranking scores may act to replace the initial comment scores in field 720 of database 700.
- the process may further include using the calculated ranking scores (block 1 160).
- the author ranking scores may be used for providing a ranked list of authors.
- the rater ranking scores may be used for providing a ranked list of raters.
- the comment ranking scores may be used for selecting a highest ranking group of comments for display with a particular document.
- the initial comment ranking scores may be calculated.
- the initial author ranking scores may be then calculated using the appropriate initial comment scores (in addition to the author signals). Thereafter, when no edges between authors and comments would be necessary when graphically representing the authors, raters, and comments since an initial author score would already reflect the qualities of the comments that the particular author submitted.
- Fig. 12 is a flowchart of an exemplary process for providing user information.
- the process of Fig. 12 may be performed by one or more components within server 220, client 210, or a combination of client 210 and server 220.
- the process of Fig. 12 may be performed by one or more components within server 220, client 210, or a combination of client 210 and server 220.
- the process may be performed by one or more components within another device or a group of devices separate from or including client 210 and/or server 220.
- Fig. 12 shows blocks in a particular order, the actual order may differ. For example, some blocks may be performed in parallel or in a different order than shown in Fig. 12.
- the process of Fig. 12 may include receiving a request for information relating to a user (block 1210).
- server 220 may receive the request from a client 210.
- the request may include information identifying the user.
- the request may be submitted to server 220 in response to a command from a user of client 210 (e.g., in response to the user selecting a link or button on a provided graphical user interface, in response to the user selecting a menu item, in response to the user submitting a request for a particular web page, etc.).
- the process may further include retrieving the requested information from a database, such as database 600 or another database (block 1220).
- the retrieved information may include, for example, the user's author ranking score, the user's rater ranking score, and a list of comments that the user has authored and/or rated.
- the retrieved information may include additional, fewer, or different information relating to the user.
- the process may further include providing the retrieved information (block 1230).
- server 220 may provide a graphical user interface to client 210 that depicts the retrieved information.
- Fig. 13 is a diagram of an exemplary graphical user interface 1300 that may be provided to a client 210. As illustrated in Fig. 13, graphical user interface 1300 may provide information about the requested user ("Paul Bunyan" in this example). The information may include a picture of the user, the user's author ranking 1310 (depicted as "28" in this example), the user's rater ranking 1320 (depicted as "1" in this example), and a sortable list 1330 of the user's comments.
- Paul Bunyan is the 28 l highest ranking author of the system and the highest ranked rater of the system.
- graphical user interface 1300 may also include a list of comments that the user has rated and the rating given to those comments by the user.
- the user's reputation may be divided between the different roles in which the user acts. That is, the user's reputation as an author and the user's reputation as a rater may be provided.
- users may be encouraged to author comments and to rate comments, wanting to be the highest ranking in one or both categories.
- Fig. 14 is a flowchart of an exemplary process for providing rater rankings. In one implementation, the process of Fig. 14 may be performed by one or more components within server 220, client 210, or a combination of client 210 and server 220. In another
- the process may be performed by one or more components within another device or a group of devices separate from or including client 210 and/or server 220.
- Fig. 14 shows blocks in a particular order, the actual order may differ. For example, some blocks may be performed in parallel or in a different order than shown in Fig. 14.
- the process of Fig. 14 may include receiving a request for rater rankings (block 1410).
- server 220 may receive, from a client 210, a request for the rankings of the raters of the system.
- the request may be submitted to server 220 in response to a command from a user of client 210 (e.g., in response to the user selecting a link or button on a provided graphical user interface, in response to the user selecting a menu item, in response to the user submitting a request for a particular web page, etc.).
- the process may further include retrieving rater ranking information from a database, such as database 600 or another database (block 1420).
- server 220 may access database 600 and retrieve information identifying the users (e.g., from field 610) and the corresponding ranking values from rater ranking field 630.
- the process may include providing the rater ranking information (block 1430).
- server 220 may provide the rater ranking information, sorted based on rank (i.e., with the highest ranking rater listed first).
- Fig. 15 is a diagram of an exemplary graphical user interface 1500 that may provide rater ranking information. As illustrated in Fig. 15, graphical user interface 1500 may provide a ranked list of raters. As illustrated, user "Paul Bunyan" is the highest ranking rater. Each user may be associated information, such as the number of items rated, topical categories in which the user is considered to be an expert rater, etc.
- comments component 410 may, for example, calculate a ranking score for the user for different topical categories (such as electronics, automobiles, etc.). Comments component 410 may select one or more of the topical categories in which the user ranks the highest as the categories of expertise for the user. In a similar manner, comments component 410 may determine that a particular user is a better rater for comments in a first language (e.g., English) than comments in a second language (e.g., Spanish). As yet another example, comments component 410 may determine, for example, based on the geographic location of a particular user, that the user is a better rater of comments that relate to the user's geographic location than for comments that relate to a different geographic location.
- a first language e.g., English
- comments component 410 may determine, for example, based on the geographic location of a particular user, that the user is a better rater of comments that relate to the user's geographic location than for comments that relate to a different geographic location.
- comments component 410 may determine that the user is better at rating comments about California than another user who lives in New York.
- Graphical user interface 1500 may further provide these other types of information. By providing rater rankings, users of the system will be encouraged to rate comments, attempting to become the highest ranking rater.
- the topical categories depicted in Fig. 15 may be provided as selectable links.
- a graphical user interface may be provided that lists the highest ranking raters for that particular topical category.
- Fig. 16 is a diagram of an exemplary graphical user interface 1600 that may be provided in response to selection of a topical category in graphical user interface 1500.
- graphical user interface 1600 may provide a ranked list of raters for the topical category "software.”
- user "Angela Arden” is the highest ranking user in the software category.
- Each user may be associated information, such as the number of comments rated in that topical category, etc.
- Fig. 17 is a diagram of an exemplary graphical user interface 1700 that may be provided to a user.
- graphical user interface 1700 may provide information regarding changes of rater rankings over a time period.
- the time period is a week. Other time periods may alternatively be used.
- user "Paul Bunyan" is the highest ranking rater and this user has moved up four spots in the past week.
- comments component 410 may calculate a user ranking score by combining, in some fashion, the user's author ranking score with the user's rater ranking score.
- Fig. 18 is a diagram of an exemplary graphical user interface 1800 that may provide user ranking information. As illustrated in Fig. 18, graphical user interface 1800 may provide a ranked list of users. In Fig. 18, user “Andy Bendict" is the highest ranking user. Each user may be associated with information, such as the user's author rank, the user's rater rank, etc. By providing user rankings, which reflect the different roles in which the users may act, users of the system will be encouraged to author comments and rate comments, attempting to become the highest ranking user.
- Implementations, described herein, may separate a user's reputation into different roles: as an author and as a rater. Ranking values may be determined for each of the user's different roles and these ranking values may be used to rank the comments that the user authored and rated.
- comments component 410 may calculate an initial author rank score for a particular user and use this score as the user's initial rater rank score.
- the user's rater ranking score may be ignored during the calculation of the author ranking scores and comment ranking scores, as described in connection with Fig. 11.
- logic that performs one or more functions.
- logic may include hardware, such as a processor, an ASIC, or a FPGA, or a combination of hardware and software (e.g., software running on a general purpose processor that transforms the general purpose processor to a special-purpose processor that functions according to the exemplary processes described above).
- scores are generated for authors, raters, and/or comments.
- the scoring scheme has been described where higher scores are better than lower scores. This need not be the case. In another implementation, the scoring scheme may be switched to one in which lower scores are better than higher scores.
Abstract
Description
Claims
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US12/540,045 US20110041075A1 (en) | 2009-08-12 | 2009-08-12 | Separating reputation of users in different roles |
PCT/US2010/043994 WO2011019526A2 (en) | 2009-08-12 | 2010-07-30 | Separating reputation of users in different roles |
Publications (2)
Publication Number | Publication Date |
---|---|
EP2465089A2 true EP2465089A2 (en) | 2012-06-20 |
EP2465089A4 EP2465089A4 (en) | 2012-07-11 |
Family
ID=43586742
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
EP10808522A Ceased EP2465089A4 (en) | 2009-08-12 | 2010-07-30 | Separating reputation of users in different roles |
Country Status (4)
Country | Link |
---|---|
US (1) | US20110041075A1 (en) |
EP (1) | EP2465089A4 (en) |
CA (1) | CA2771214A1 (en) |
WO (1) | WO2011019526A2 (en) |
Families Citing this family (17)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US8280882B2 (en) * | 2005-04-21 | 2012-10-02 | Case Western Reserve University | Automatic expert identification, ranking and literature search based on authorship in large document collections |
US8386564B2 (en) * | 2006-11-30 | 2013-02-26 | Red Hat, Inc. | Methods for determining a reputation score for a user of a social network |
US20120072268A1 (en) * | 2010-09-21 | 2012-03-22 | Servio, Inc. | Reputation system to evaluate work |
US9311678B2 (en) | 2010-12-15 | 2016-04-12 | Facebook, Inc. | Comment plug-in for third party system |
US9183307B2 (en) * | 2010-12-15 | 2015-11-10 | Facebook, Inc. | Comment ordering system |
US8793154B2 (en) * | 2011-08-18 | 2014-07-29 | Alterian, Inc. | Customer relevance scores and methods of use |
US9123055B2 (en) | 2011-08-18 | 2015-09-01 | Sdl Enterprise Technologies Inc. | Generating and displaying customer commitment framework data |
US9158851B2 (en) * | 2011-12-20 | 2015-10-13 | Yahoo! Inc. | Location aware commenting widget for creation and consumption of relevant comments |
US10346444B1 (en) * | 2012-01-12 | 2019-07-09 | OpsDog, Inc. | Management of standardized organizational data |
US9411856B1 (en) * | 2012-10-01 | 2016-08-09 | Google Inc. | Overlay generation for sharing a website |
US9277024B2 (en) * | 2012-12-19 | 2016-03-01 | International Business Machines Corporation | Suppressing content of a social network |
CN103914491B (en) * | 2013-01-09 | 2017-11-17 | 腾讯科技（北京）有限公司 | To the data digging method and system of high-quality user-generated content |
US11086905B1 (en) * | 2013-07-15 | 2021-08-10 | Twitter, Inc. | Method and system for presenting stories |
US9912973B2 (en) * | 2014-08-07 | 2018-03-06 | Echostar Technologies L.L.C. | Systems and methods for facilitating content discovery based on viewer ratings |
US10068666B2 (en) * | 2016-06-01 | 2018-09-04 | Grand Rounds, Inc. | Data driven analysis, modeling, and semi-supervised machine learning for qualitative and quantitative determinations |
US20200151752A1 (en) * | 2018-11-12 | 2020-05-14 | Aliaksei Kazlou | System and method for acquiring consumer feedback via rebate reward and linking contributors to acquired feedback |
CN112269924A (en) * | 2020-10-16 | 2021-01-26 | 北京师范大学珠海校区 | Ranking-based commenting method and device, electronic equipment and medium |
Family Cites Families (13)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6285999B1 (en) * | 1997-01-10 | 2001-09-04 | The Board Of Trustees Of The Leland Stanford Junior University | Method for node ranking in a linked database |
US20010049597A1 (en) * | 2000-03-16 | 2001-12-06 | Matthew Klipstein | Method and system for responding to a user based on a textual input |
WO2003034637A2 (en) * | 2001-10-18 | 2003-04-24 | Transpose, Llc | System and method for measuring rating reliability through rater prescience |
US7421660B2 (en) * | 2003-02-04 | 2008-09-02 | Cataphora, Inc. | Method and apparatus to visually present discussions for data mining purposes |
US7536315B2 (en) * | 2003-02-13 | 2009-05-19 | Sap Aktiengesellschaft | Self-balancing of idea ratings |
US7363214B2 (en) * | 2003-08-08 | 2008-04-22 | Cnet Networks, Inc. | System and method for determining quality of written product reviews in an automated manner |
US7809548B2 (en) * | 2004-06-14 | 2010-10-05 | University Of North Texas | Graph-based ranking algorithms for text processing |
US7558769B2 (en) * | 2005-09-30 | 2009-07-07 | Google Inc. | Identifying clusters of similar reviews and displaying representative reviews from multiple clusters |
US20080109491A1 (en) * | 2006-11-03 | 2008-05-08 | Sezwho Inc. | Method and system for managing reputation profile on online communities |
US8949876B2 (en) * | 2007-03-21 | 2015-02-03 | Productwiki, Inc. | Methods and systems for creating and providing collaborative user reviews of products and services |
KR100925376B1 (en) * | 2007-09-12 | 2009-11-09 | 엔에이치엔(주) | Method for controlling display of replies, and system and computer-readable recording medium for implementing same method |
US9251279B2 (en) * | 2007-10-10 | 2016-02-02 | Skyword Inc. | Methods and systems for using community defined facets or facet values in computer networks |
US20090199104A1 (en) * | 2008-02-01 | 2009-08-06 | Spigit, Inc. | Idea collaboration method |
-
2009
- 2009-08-12 US US12/540,045 patent/US20110041075A1/en not_active Abandoned
-
2010
- 2010-07-30 WO PCT/US2010/043994 patent/WO2011019526A2/en active Application Filing
- 2010-07-30 EP EP10808522A patent/EP2465089A4/en not_active Ceased
- 2010-07-30 CA CA2771214A patent/CA2771214A1/en not_active Abandoned
Non-Patent Citations (2)
Title |
---|
See also references of WO2011019526A2 * |
The technical aspects identified in the present application (Art. 56 EPC) are considered part of common general knowledge. Due tot heir notoriety no documentary evidence is found to be required. For further details see the accompanying Opinion and the reference below. XP002456414 * |
Also Published As
Publication number | Publication date |
---|---|
US20110041075A1 (en) | 2011-02-17 |
WO2011019526A3 (en) | 2011-05-05 |
EP2465089A4 (en) | 2012-07-11 |
WO2011019526A2 (en) | 2011-02-17 |
CA2771214A1 (en) | 2011-02-17 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US9875313B1 (en) | Ranking authors and their content in the same framework | |
US20110041075A1 (en) | Separating reputation of users in different roles | |
US9390144B2 (en) | Objective and subjective ranking of comments | |
US8027988B1 (en) | Category suggestions relating to a search | |
US8489586B2 (en) | Methods and systems for endorsing local search results | |
US8661031B2 (en) | Method and apparatus for determining the significance and relevance of a web page, or a portion thereof | |
US9135350B2 (en) | Computer-generated sentiment-based knowledge base | |
US7996391B2 (en) | Systems and methods for providing search results | |
US20140297615A1 (en) | Endorsing Search Results | |
US9292863B2 (en) | Representative keyword selection | |
US9116945B1 (en) | Prediction of human ratings or rankings of information retrieval quality | |
US20190108275A1 (en) | Systems and methods for providing recommendations for academic and research entities | |
US8977630B1 (en) | Personalizing search results | |
WO2016018471A1 (en) | Personalized search based on similarity | |
US8666914B1 (en) | Ranking non-product documents | |
CN107003829B (en) | Request-related result regions within and outside of view for each result category | |
WO2016076790A1 (en) | Method and system for profiling job candidates | |
US20140095465A1 (en) | Method and apparatus for determining rank of web pages based upon past content portion selections | |
US20140149378A1 (en) | Method and apparatus for determining rank of web pages based upon past content portion selections | |
KR101172487B1 (en) | Method and system to provide search list and search keyword ranking based on information database attached to search result | |
US8595225B1 (en) | Systems and methods for correlating document topicality and popularity |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PUAI | Public reference made under article 153(3) epc to a published international application that has entered the european phase |
Free format text: ORIGINAL CODE: 0009012 |
|
17P | Request for examination filed |
Effective date: 20120308 |
|
AK | Designated contracting states |
Kind code of ref document: A2Designated state(s): AL AT BE BG CH CY CZ DE DK EE ES FI FR GB GR HR HU IE IS IT LI LT LU LV MC MK MT NL NO PL PT RO SE SI SK SM TR |
|
A4 | Supplementary search report drawn up and despatched |
Effective date: 20120612 |
|
RIC1 | Information provided on ipc code assigned before grant |
Ipc: G06Q 30/00 20120101AFI20120605BHEPIpc: G06Q 50/00 20120101ALI20120605BHEP |
|
DAX | Request for extension of the european patent (deleted) | ||
17Q | First examination report despatched |
Effective date: 20150224 |
|
REG | Reference to a national code |
Ref country code: DERef legal event code: R003 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: THE APPLICATION HAS BEEN REFUSED |
|
18R | Application refused |
Effective date: 20160211 |
|
P01 | Opt-out of the competence of the unified patent court (upc) registered |
Effective date: 20230524 |