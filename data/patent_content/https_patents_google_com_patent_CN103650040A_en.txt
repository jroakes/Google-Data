CN103650040A - Noise supression method and apparatus using multiple feature modeling for speech/noise likelihood - Google Patents
Noise supression method and apparatus using multiple feature modeling for speech/noise likelihood Download PDFInfo
- Publication number
- CN103650040A CN103650040A CN201180072331.0A CN201180072331A CN103650040A CN 103650040 A CN103650040 A CN 103650040A CN 201180072331 A CN201180072331 A CN 201180072331A CN 103650040 A CN103650040 A CN 103650040A
- Authority
- CN
- China
- Prior art keywords
- frame
- noise
- feature
- speech probability
- division
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Images
Classifications
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L21/00—Processing of the speech or voice signal to produce another audible or non-audible signal, e.g. visual or tactile, in order to modify its quality or its intelligibility
- G10L21/02—Speech enhancement, e.g. noise reduction or echo cancellation
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L25/00—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00
- G10L25/78—Detection of presence or absence of voice signals
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L21/00—Processing of the speech or voice signal to produce another audible or non-audible signal, e.g. visual or tactile, in order to modify its quality or its intelligibility
- G10L21/02—Speech enhancement, e.g. noise reduction or echo cancellation
- G10L21/0208—Noise filtering
Abstract
Systems and methods of noise suppression based on an estimation of the noise spectrum, and a Wiener type filter to suppress the estimated noise. The noise spectrum may be estimated based on a model that classifies each time/frame and frequency component of a received signal as speech or noise by using a speech/noise likelihood (e.g., probability) function. The speech/noise likelihood function is updated and adapted, for each input frame and frequency, by incorporating multiple speech/noise classification features into a model for a feature-based probability function.
Description
Field that the present invention belongs to
The present invention is relevant with method with sound signal (as voice communication) transmission system substantially.Particularly, various aspects of the present invention relate to use speech probability modeling estimation and filtered noise.
Background
In voice communication, periphery and/or ground unrest are too much understood interfere with communications folk prescription or the understanding of both sides to Content of Communication, sometimes even cause talking with nonsensical.Ambient noise comprises the sound in various extraneous sources, and wherein comparatively common noise source comprises computing machine, fan, microphone and office equipment.
Summary of the invention
The present invention's general introduction has been introduced some concepts with simplified form, allows reader have individual basic understanding to related fields of the present invention.The present invention's general introduction is not that popularity of the present invention is summarized, and not introduces key of the present invention or important component part, also non-description scope of the present invention yet.Concepts more of the present invention are only set forth in the present invention general introduction, as " detaileds description " place mat partly below.
One embodiment of the present of invention relate to by the method for the estimation of squelch assembly and filtered noise.The method comprises: each frame of the continuous multiple frames input signal receiving for squelch assembly, is estimated as basis with the initial noise to this frame, definition speech probability function; Measure the multicomponent signal characteristic of division of each frame in multiframe; Every frame signal characteristic of division that use is measured, the speech probability based on feature of each frame in calculating multiframe; The speech probability based on feature of each frame in the multiframe calculating is applied to one or more dynamic weighting factors; Speech probability according to the every frame calculating based on feature, the speech probability function of each frame in modification multiframe; And use amended every frame speech probability function, upgrade the initial noise of each frame in multiframe and estimate.
In another embodiment of the present invention, the method for estimation and filtered noise further comprises: the initial noise after using every frame to upgrade is estimated, to each the filtering frames noise in multiframe.
In another embodiment of the present invention, one or more dynamic weighting factors comprise the weighted sum threshold parameter of every frame signal characteristic of division.
In another embodiment of the present invention, initial noise estimates it is that fractile noise with each frame in continuous multiple frames is estimated as basis.
In another embodiment of the present invention, the method for estimation and filtered noise further comprises: every frame signal characteristic of division of measuring is applied to one or more dynamic weighting factors; And for the frame of applying one or more dynamic weighting factors, upgrade its speech probability based on feature.
In another embodiment of the present invention, the method for estimation and filtered noise further comprises: one or more dynamic weighting factors are combined with the signal characteristic of division of measuring, form the speech probability function based on feature.
In another embodiment of the present invention, the method for estimation and filtered noise further comprises: the speech probability function based on feature that upgrades each frame in multiframe; And according to the speech probability function based on feature after upgrading, upgrade the speech probability function of each frame in multiframe.
In another embodiment of the present invention, multicomponent signal characteristic of division is for being divided into a kind of voice or noise classification state by input signal.
In another embodiment of the present invention, use recurrence average to upgrade the speech probability function based on feature.
In another embodiment of the present invention, the speech probability function based on feature is to draw by using mapping function that the signal characteristic of division of every frame is mapped to a probable value.
In another embodiment of the present invention, mapping function is to define according to the value of signal characteristic of division, and comprises one or more threshold values and width parameter.
In another embodiment of the present invention, speech probability function further be take the likelihood ratio factor of frame and is basis.
In another embodiment of the present invention, multicomponent signal characteristic of division at least comprises: time dependent average likelihood, frequency spectrum flatness are measured and spectrum mask difference is measured.
In another embodiment of the present invention, one or more dynamic weighting factors to one of major general's following characteristics is elected multicomponent signal characteristic of division as: time dependent likelihood ratio, frequency spectrum flatness are measured and spectrum mask difference is measured.
In another embodiment of the present invention, spectrum mask difference measures that to take the contrast of input signal spectrum and Pattern Noise frequency spectrum be basic.
In another embodiment of the present invention, the noise that the estimation of Pattern Noise frequency spectrum be take after upgrading estimates that (using speech probability function and one group of form parameter estimating after upgrading to upgrade) is basis.
In another embodiment of the present invention, the form parameter estimating is one or more displacements, amplitude and normalizing parameter.
In another embodiment of the present invention, the method for estimation and filtered noise further comprises: for response is to each the filtering frames noise in multiframe, according to amended frame speech probability function, the energy of each frame of convergent-divergent.
In another embodiment of the present invention, the method for estimation and filtered noise further comprises: for being applied to the weighted sum threshold parameter of every frame signal characteristic of division, initial value is set; And after first interval appears in input signal, upgrade the initial value of weighted sum threshold parameter.
In another embodiment of the present invention, estimate and the method for filtered noise further comprises: when there is first interval, calculate the histogram of every frame signal characteristic of division; According to being derived from histogrammic one or more quantity, determine the new value of weighted sum threshold parameter; And when the interval for the second time of input signal, use the new value of weighted sum threshold parameter.
In another embodiment of the present invention, first and for the second time interval is to occur according to the sequence of the frame of input signal.
And in another embodiment of the present invention, the method of estimation and filtered noise further comprises: will be derived from histogrammic one or more quantity and one or more inner parameter and compare, to determine the corresponding weighted sum threshold parameter of the speech probability of input signal based on feature.
The detailed scope of application of the present invention will clearly be set forth in below " detailed description " part.But, what need to recognize is a bit, " detailed description " and for the concrete example enumerated of explanation the preferred embodiments of the present invention only for elaboration explanation, one of ordinary skill in the art, by reading this " detailed description ", should be able to understand many changes and revised context in spirit of the present invention and the scope of application apparently.
Accompanying drawing summary
By reading below " detailed description ", and in conjunction with claim and the diagram of enclosing, one of ordinary skill in the art just can more clearly understand target of the present invention, feature and characteristic, and all authority requires and accompanying drawing is all the part of this instructions.In these accompanying drawings:
Fig. 1 describe, in general terms an exemplary embodiment, this example may be carried out herein one or more aspects of introducing.
Fig. 2 is a calcspar, according to the one or more embodiment that introduce, has explained the typical components of noise suppressing system herein.
Fig. 3 is a schematic diagram, and the one or more embodiment according to introducing herein, have explained buffering and windowing flow process.
Fig. 4 is a process flow diagram, according to the one or more embodiment that introduce, has explained the more new technological process of characteristic threshold value and weighting parameters herein.
Fig. 5 is a calcspar, and the one or more embodiment according to introducing herein, have explained the example calculations equipment for multipath route and processing audio input signal.
Title herein is only established for convenience of reading, and can not affect scope of invention or the meaning applied for a patent.
In these accompanying drawings, for ease of understanding and easy-to-read, there is ingredient or the operation of same or similar structure or function, with identical reference number or acronym, marked.Below " detailed description " part will describe in detail to accompanying drawing.
describe in detail
Many examples of the present invention will be shown in this part.Following description will provide detail, so that reader can fully understand these examples.But various equivalent modifications will be understood that the present invention may not can when practical application implements described full details content.Equally, various equivalent modifications also should be understood that the present invention also may comprise other many obvious characteristics of not introducing in detail herein.In addition, in below describing in detail, may not show or introduce some well-known structure or functions, to avoid that associated description is caused to unnecessary interference and fuzzy.
Squelch is intended to eliminate or reduces periphery ground unrest, improves the sharpness of target audio, thereby provides the more comfortable force environment of listening for hearer.In certain embodiments of the present invention, squelch is carried out in frequency domain, and can implement noise for frequency domain and estimate and noise filtering.In the very jiggly situation of noise level, if only rely on local signal to noise ratio (S/N ratio) (SNR) to implement squelch, in the time of conventionally can causing determining the possibility of voice and noise, there is wrong deviation.For each incoming frame and frequency, upgrade and regulate the process of voice/noise probability measure to comprise the probability of the multiple voice/noise classification feature of use (as " the signal characteristic of division " that relate to or " noise estimation feature ") estimation based on feature herein, thereby the voice/noise existing in frame is made to more accurate and stable estimation, will this be carried out to more detailed description herein.Below describe in content, " voice/noise classification feature ", " signal characteristic of division " and " noise estimation feature " are interchangeable, all refer to can be used in each frame and frequency the feature that (as measured) is categorized into input signal voice or noise states.
The present invention and the estimation of squelch related aspect based on to noise spectrum design, and adopt Wei Na (Wiener) wave filter to suppress the noise that estimation draws.Noise spectrum can rely on a kind of method to estimate, even with voice/noise likelihood (as probability) function, by received signal each/frame and frequency component be categorized as voice or noise.Below will introduce in detail voice/noise probability function, and the use in noise spectrum is estimated.
In at least some are arranged, can be configured squelch assembly, to carry out multiple voice probabilistic Modeling described herein.For instance, for each incoming frame of the voice that receive, squelch assembly may be carried out following processing: signal analysis, comprises buffering, windowing and Fourier transform; Noise is estimated and filtration, comprises definite initial noise estimation, computing voice/noise likelihood function, according to voice/noise likelihood function, upgrades initial noise estimation, and use S filter to suppress the noise that estimation draws; And signal is synthetic, comprise that inverse Fourier transform, convergent-divergent and window are synthetic.In addition, also can do further configuration to squelch assembly, make it generate the speech frame that estimation draws, as the output of above-mentioned flow process.
The discussion of Fig. 1 and below has been carried out description brief, that summarize to an exemplary embodiment of the present invention, and this embodiment has realized many aspects of the present invention.As shown in Figure 1, squelch assembly 40 may be arranged in the near-end environment of signal transmission path, and capture device 5 is also arranged in near-end environment simultaneously, sends equipment 30 and is arranged in distal environment.In some are arranged, squelch assembly 40 may be an assembly in large-scale audio frequency (as sound) communication system.Squelch assembly 40 may be a stand-alone assembly in this large scale system, may be also a subassembly in this system stand-alone assembly (not shown).In the example embodiment showing at Fig. 1, squelch assembly 40 is arranged to receive and process the input content from capture device 5, and exports one or more other audio frequency processing components (not shown)s to.These other audio frequency processing components can be that acoustic echo is controlled (AEC), automatic gain controls (AGC) and/or other sound qualities are improved assembly.In certain embodiments, these other processing components may receive the input content from capture device 5 before squelch assembly 40.
Capture device 5 can be any one in numerous audio input device, such as for catching sound and generating one or more microphones of input signal.Sending equipment 30 can be any one in numerous audio output apparatus, comprises for exporting one or one group of loudspeaker of one or more channel sound.For instance, capture device 5 and send the internal hardware devices that equipment 30 can be computer system, can be also with wired and/or wireless connections mode, to access the peripherals of computer system.In some are arranged, capture device 5 and send the assembly that equipment 30 can be the individual equipments such as loudspeaker, telephone receiver.In addition, capture device 5 and send in equipment 30 any one or two may possess analog digital conversion and/or digital-to-analogue conversion function.
At least in the embodiment shown in fig. 1, squelch assembly 40 comprises that one for coordinating the controller 50 of a plurality of flow processs and timing considerations.Squelch assembly 40 also can comprise a signal analysis unit 10, noise estimation unit 15, a S filter 20, and a signal synthesis unit 25.Any one in these parts can communicate with controller 50, and controller 50 just can be accelerated flow processs more as herein described like this.The each side details of signal analysis unit 10, noise estimation unit 15, S filter 20 and signal synthesis unit 25 will be described in further detail later.
In certain embodiments of the present invention, one or more other assemblies, module, unit etc. all can be used as the part in squelch assembly 40, can supplement or alternate figures 1 shown in parts.1. in squelch assembly 40, sign title (as signal analysis unit, the noise estimation unit etc.) essence of assembly unit is only example title, is not in order to limit the scope of the invention.
Fig. 2 is a process flow diagram, and the complete noise of having explained the present invention suppresses an example embodiment of system and method.Noise suppressing system shown in Fig. 2 comprises three main flow processs: signal analysis 270, noise are estimated and filtered 275, and signal synthetic 280.Signal analysis flow process 270 can comprise a plurality of preprocessing process, and these processes must be carried out for incoming frame 200, just can in frequency domain, implement squelch.For instance, signal analysis 270 may comprise the pre-treatment step of buffering 205, windowing 210 and discrete Fourier transform (DFT) (DFT) 215.Noise shown in Fig. 2 is estimated and filtering process 275 comprises step or sub-process: decision-directed (DD) renewal 225, the voice/noise possibility of initial noise estimation 220, posteriority and priori SNR measure 230, possibility is measured and is carried out based on likelihood ratio (LR) factor, and likelihood ratio is to use posteriority and priori SNR, and speech probability density function (PDF) model 235(is as Gauss, Laplace operator, gamma, super-Gaussian etc.), also with good grounds feature modeling 240, noise estimate to upgrade 245 and application dimension receive the definite probability of agc filter 250 and definite.In addition, in signal synthesis flow 280, incoming frame 200 need to be converted back to time domain, therefore also comprise the step of inverse discrete Fourier transform 255, convergent-divergent 260 and window synthetic 265.The result of signal synthesis flow 280 is exactly output frame 290, the speech frame that estimation that Here it is draws.Each flow process of above-mentioned noise suppressing system shown in Fig. 2 and sub-process will below be described in more detail.
Introduce herein for reducing and eliminates noise suppressing method and the system of noise in speech signal, according to the model equation of below, carry out (according to forms of time and space demonstration):
y(t)＝x(t)+N(t)
Wherein, x (t) is pure voice signal, and y (t) is the noise cancellation signal that has observing, and N (t) is noise.At least, in the following description of a plurality of flow processs shown in Fig. 2 and step, this model hypothesis (the unknown) voice signal is subject to additive noise and disturbs, and has noise cancellation signal y (t) uncorrelated with voice signal x (t).In frequency domain, above model equation adopts following form:
Y
k(m)＝X
k(m)+N
k(m)
Wherein, k represents frequency, m representative frame index (frame number using in short-term window DFT215, refers to below).
Signal analysis
At least in some is arranged, noise suppressing system is as shown in Figure 2 that to take frame be the real-time system of basis operation, when receiving a frame (as incoming frame 200), can its data be cushioned and be analyzed.For example, the frame size of incoming frame 200 is 10 milliseconds (ms).The sampling rate of 8kHz is equivalent to 80 samples, and the sampling rate of 16kHz is just equivalent to 160 samples.In one or more other layouts, the noise suppressing system as shown in Figure 2 of introducing herein may substitute and/or additionally support other incoming frame size, comprises 15ms, 20ms and 30ms.For clarity sake, below describing is that to take the situation that incoming frame 200, frame size be 10ms be basis.
After through buffering 205, incoming frame 200 enters into windowing 210 and DFT215, to incoming frame 200 is mapped in frequency domain.Because DFT215 is 2 exponential through optimizing applicable data length, thus at least in some is arranged, this incoming frame can with analysis buffers length be 128 samples and 256 samples.Fig. 3 is a schematic diagram, has shown buffering 205 and the windowing 210 step examples introduced herein.Fig. 3 shown when sampling rate be 8kHz and while only analyzing a signal frame, be how data to be cushioned and windowing.As the example shows, the frame size of the new frame of data 305 is 80 samples, and this new frame is added in the buffer zone 320 that is of a size of 128 samples.In addition, windowed function 310 is in the buffer zone below showing through expansion.
Because analysis buffers (buffer zone 320 as shown in Figure 3) is than the size of frame large (frame 305 as shown in Figure 3), therefore as in the previous shown in data 330, between continuous buffer zone, have overlappingly, this lap comprises front 48 samples from frame 305 in the example shown.Although analysis buffers 320 has correlativity to each other, so overlapping noise reduction that conventionally can make is more smooth, also can give the synthetic restriction that brings.For instance, when the buffer zone lap having added as frame 305, must be to signal windowing to avoid sudden change.
As mentioned above, any overlapping (buffer zone 320 as shown in Figure 3) between analysis buffers all may need windowing process.At least, in a layout, in frequency domain, carry out can adding identical window before and after noise processed.Particularly, shown in Fig. 2, the window synthesis step 265 of the windowing step 210 of signal analysis flow process 270 and signal synthesis flow 280 can be used the same window.Therefore, in such layout, window function is necessary for protects power mapping, and the quadratic sum of the window of overlapping buffer zone part is necessary for 1, as follows:
w
2(N)+w
2(M+N)＝1
Wherein, N is buffer length, and M is the length of frame.Definition y (n, m) is the sound signal of making an uproar in internal buffer time index n and frame m, and the signal of process windowing is:
y
w(n,m)＝w(n)y(n,m)
In layouts more of the present invention, noise is estimated and is suppressed flow process and carry out in frequency domain.In the DFT of signal analysis flow process 270 step 215, use the DFT of windowing data that incoming frame 200 is transformed in frequency domain:
K represents frequency slots index (sub-band).Because the flow process use S filter of introducing herein carries out squelch (details see below), therefore in the magnitude of carrying out only considering when noise is estimated frequency response | Y (m) |.
Noise is estimated and is filtered
The noise of system shown in Figure 2 is estimated and filtering process 275, uses the speech probability model that comprises a plurality of signal characteristics that each incoming frame 200 of the signal receiving is categorized as to voice or noise.Voice/noise classification, for each time/frame and frequency definition, is realized by voice/noise probability function, below will be described in detail.By voice/noise classification, at signal suspension, when (occurring noise), just can more thoroughly upgrade the initial estimation of noise spectrum, the signal that contains like this residual noise sound just more smooth (as music noise still less), and to the measurement of the noise spectrum of astable noise source just more accurately and more sane.Example system as shown in Figure 2, noise is estimated and filtering process 275 comprises the following steps: decision-directed (DD) renewal 225, the voice/noise possibility of initial noise estimation 220, posteriority and priori SNR measure 230, possibility is measured and is carried out based on likelihood ratio (LR) factor, likelihood ratio is to use posteriority and priori SNR, and speech probability density function (PDF) model 235(is as Gauss), also with good grounds feature modeling 240, noise estimate to upgrade 245 and application dimension receive the definite probability of agc filter 250 and definite.Below by introducing in detail each, comprise that noise is estimated and the step of filtering process 275.
In one or more layouts, initial noise estimates that 220 is to be estimated as basis with fractile noise.Noise is estimated controlled by fractile parameter, and this parameter represents with q.According to the noise that initial noise estimating step 220 is definite, estimate, only can be as the starting condition that promotes the follow-up flow process that noise upgrades/estimates.
The wave filter of processing for squelch conventionally can be with priori SNR and the rear SNR(of determining posteriority SNR) explain.Therefore,, before carrying out any actual inhibition, need to estimate priori and posterior SNR quantity.Noise is estimated and voice/noise possibility determination step 230 of filtering process 275 also needs priori and posteriority SNR quantity, below will be described in detail this.
In one example, the input power spectrum relevant to noise power spectrum that posteriority SNR may refer to observe is basic transient state SNR, is defined as follows:
Wherein, Y
k(m) be the frequency spectrum of making an uproar of input, N
k(m) be noise spectrum, residing time/frame is m, and frequency is k.In this example, priori SNR may be the expectation value of pure (the unknown) power spectrum signal relevant to noise power spectrum, can be expressed as:
Wherein, X
k(m) be the spectral coefficient of unknown clean speech signal.Noise power spectrum in above-mentioned each posteriority and priori SNR may derive from initial estimation noise spectrum definite in initial noise estimating step 220, and this frequency spectrum is estimated as basis with fractile.In at least one embodiment, when expressing posteriority and priori SNR, possible use amount number of stages replaces square magnitude showing in above-mentioned calculating:
Because purified signal is unknown signaling, to the estimation of priori SNR, be therefore priori SNR and the transient state SNR σ of previous frame (incoming frame before the incoming frame 200 of processing by system shown in Figure 2) through estimating
k(m) mean value:
Wherein, H (k, m – 1) is agc filter for a upper processed frame (as noise is estimated and filtering process 275 dimension used is received agc filter 250), | Y
k(m – 1) | be the amplitude spectrum that the previous frame that observes has the voice of making an uproar.In above-mentioned expression formula, first is the priori SNR of a upper time frame, and second portion is that the transient state of priori SNR is estimated.At least in this example, decision-directed (DD) that above-mentioned expression formula can be regarded as to the priori SNR225 step of noise estimation and filtering process 275 upgrades, and time smoothing parameter is γ
dd.Priori SNR is the smooth version of posteriority SNR, and there are some hysteresis the time.γ
ddlarger, fluency is higher, but time delay also can increase.In one or more layouts, the value of smoothing parameter is～0.98.
According to some aspect of the present invention, the priori of above describing and defining and posteriority SNR are the components of voice/noise possibility determination step 230 of noise estimation and filtering process 275.At least in this example, voice/noise possibility is measured and to be comprised two factors: (1) LR(likelihood ratio) factor, according to priori and posteriority SNR, determine, and (2) take feature modeling as basic probability, and will below be described in more detail.
Defining and obtaining the model for voice/noise possibility, the state of voice is defined as H
k,m=H
1 k,m, noise states is defined as H
k,m=H
0 k,m.Define voice and the noise states of each frame m and frequency slots k.Voice/noise-like probability of state can be expressed as:
P(H
k,m|Y
k(m),{F})
Voice/noise probability depends on the noise inputs spectral coefficient Y observing
k(m), and some characteristics of handled signal (as signal characteristic of division), be defined as in this example { F}.The expression formula of above-mentioned voice/noise possibility is in this article also referred to as " speech probability function ".At least, in a layout, characteristic can be any function that has the input spectrum of making an uproar, passing frequency spectrum data, model data and offline data etc.For example, { F} can comprise frequency spectrum flatness measurement, resonance peak distance, LPC remnants, template matches etc. to characteristic.
Below in expression formula, voice/noise states is suppressed the dependence of (k, m), H
k,mbe written as H with contracted notation.Therefore,, according to bayes rule (Bayes rule), when computing voice/noise probability, may be expressed as:
P(H|Y
k(m),{F})αP(Y
k(m)|H,{F})q
k,m(H|{F})p({F})
Wherein, p ({ F}) is that to take the characteristic of signal be basic prior probability, this value below be set as a constant in one or more expression formulas.In this example, quantity q
k,m(H|{F}) be that { voice/noise probability under F}, detailed description please see below characteristic.When describing each aspect of the present invention content, above-mentioned quantity q
k,m(H|{F}) be also referred to as " speech probability based on feature ".Do not consider take that { F} is basic prior probability, and is contracted notation, mark q
k,m(H
1| F})=q and q
k,m(H
0| F}) and=1 – q, standardized speech probability can be write:
Likelihood ratio (LR) Δ wherein
kfor:
At above-mentioned Δ
kexpression formula in, at least in model as herein described is arranged, quantity P (Y
k(m) | H
1,0, F}) be to suppose to determine by Linear state model with for the Gaussian probability-density function (PDF) of voice and noise spectrum coefficient.More specifically, the linear model of noisy input signal can be expressed as: Y under voice status
k(m)=X
k(m)+N
k(m), H=H wherein
1; Y under noise state
k(m)=N
k(m), H=H wherein
0.Suppose that Gauss PDF is used complexity coefficient { X
k, N
k, quantity P (Y
k(m) | H, F}) be expressed as follows:
Owing to can determining probability according to linear model and Gauss PDF hypothesis completely, therefore feature can be relied on and deletes from above-mentioned expression formula.Like this, likelihood ratio Δ
kjust become:
Wherein, ρ
k(m) be that the SNR(of unknown signaling is priori SNR), σ
k(m) be that to determine signal SNR(be posteriority SNR or transient state SNR for frequency k and frame m rear).At one, realize in example, the priori SNR using in above-mentioned expression formula and posteriority SNR are defined and are estimated by magnitude, and formula is:
According to above-mentioned expression formula and description, at least, in a layout, voice/noise states probability can pass through likelihood ratio (Δ
k) and quantity q
k,m(H
1| F}) and=q acquisition, wherein, likelihood ratio is definite according to frequently becoming posteriority and priori SNR, and quantity is that detailed description vide infra based on feature or the probability based on model.Therefore, voice/noise states probability can be expressed as:
P(H
0Y
k(m),{F})＝1-P(H
1Y
k(m),{F})
Because there is time frame to become the likelihood ratio factor (Δ to the frequency between frame
k) have very great fluctuation process, so at least in the layout of a noise suppressing system described herein, can use the likelihood ratio factor of elapsed time smoothing processing:
In addition, the geometric mean of the likelihood ratio factor of elapsed time smoothing processing (comprising all frequencies) can be used as the reliable measurements result to the voice/noise classification based on frame:
As mentioned above, can use Gauss's hypothesis as voice PDF model 235 in voice/noise possibility determining step 230, thereby obtain likelihood ratio.In one or more other are arranged, other voice PDF model also can be used as measuring the basis of likelihood ratio, comprises Laplace operator, gamma and/or super-Gaussian.For instance, when Gauss hypothesis can reasonable representation noise, this hypothesis might not be applicable to voice, especially in shorter time frame (as～10ms).In this case, can use another kind of voice PDF model, but this increases complicacy possibly.
As shown in Figure 2, to in noise estimation and filtering process 275, determine voice/noise possibility (or probability) 230, this not only needs local SNR(is priori SNR and transient state SNR) guiding, also will be in conjunction with the speech model/Cognitive contents obtaining from feature modeling 240.Speech model/Cognitive contents is incorporated into during voice/noise probability determines, can allows squelch flow process as herein described process better and/or distinguish extremely unsettled noise level, if only rely on local SNR, may cause possibility deviation.At least, in a layout, system has been used a flow process, to each frame that comprises local SNR and phonetic feature/model data and frequency renewal and the probability q of adaptation based on feature
k,m(H|F).Below described this renewal and adapt in the various aspects of flow process symbol q
k,m(H|F)=q
k,m.Because flow process described herein only take frame as basis to quantity q
k,m(H|F) modeling and renewal, so variable k has just been subject to inhibition.
According to one or aspects of contents of the present invention, to the renewal of the probability based on feature, can adopt with drag:
q
m=γ
qq
m-1+(1-γ
q)M(z,w)
Wherein, γ
pbe a smoothing constant, M (z) is the mapping function (as between 0 and 1) of preset time and frequency.Variable z in this mapping function is z=F – T, and wherein F is tested feature, and T is threshold value.Parameter w represents the shape/width characteristics of mapping function.Mapping function, according to feature and threshold value and the width parameter measured, is divided into voice (M approaches 1) or noise (M approaches 0) by time-frequency groove.
In a layout, noise estimate and filtering process 275 at enforcement feature modeling 240 when determining voice/noise possibility 230, can consider the following characteristics of voice signal: (1) LRT average, can draw based on local SNR, (2) frequency spectrum flatness, can draw based on voice harmonic-model, and (3) spectrum mask difference is measured.Below will be described in more detail these three features.Need to recognize a bit, except three exemplary characteristics hereinafter described, also can use a lot of other phonic signal characters to act as a supplement or alternative features.
1.LRT characteristics of mean
As mentioned above, the geometric mean of the likelihood ratio of elapsed time smoothing processing (LR) factor is the reliability index of voice/noise states:
Wherein the LR factor processed of elapsed time draws according to described expression formula above.While using LRT characteristics of mean, an example of mapping function M (z) may be " S " type curvilinear function, for example:
M(z)=0.5*(tanh(w
1z
1)+0.5)
z=T
1–F
1
Wherein, F
1feature, w
1a transition/width parameter, for controlling the flatness of from 0 to 1 mapping.Threshold parameter T
1need to determine according to parameter setting, will be described in more detail this herein.
2. frequency spectrum flatness feature
For obtaining frequency spectrum flatness feature, suppose that voice have more harmonic wave behavior than noise.Yet voice spectrum tends to occur peak value in fundamental frequency (fundamental tone) and harmonic wave, noise spectrum relatively flat.Therefore, at least, in some is arranged, the summation that local frequency spectrum flatness is measured can be used as the good basis for estimation of indication/differentiation voice and noise.
When calculating frequency spectrum flatness, N represents the quantity of frequency slots, and B represents the quantity of frequency band.K is frequency slots index, and j is frequency band index.Each frequency band will comprise a large amount of frequency slots.For instance, the frequency spectrum of 128 grooves can be divided into 4 frequency bands (low strap, middle low strap, middle high-band and high-band), and each frequency band comprises 32 grooves.In another example, only use a frequency band that comprises all frequencies.Frequency spectrum flatness can draw by calculating the geometric mean of input range spectrum and the ratio of arithmetical mean:
Wherein N represents the frequency number in frequency band.For noise, the quantity F calculating
2bigger than normal and be constant, and for voice, the quantity calculating is less than normal and be variable.Equally, an example of the mapping function M (z) upgrading for the prior probability to based on feature can be expressed as " S " type curvilinear function:
M(z)=0.5*(tanh(w
2z
2)+0.5)
z=T
2–F
2
3. spectrum mask difference characteristic
Except the relevant hypothesis of the above-mentioned noise for frequency spectrum flatness feature, another hypothesis of relevant noise spectrum is that noise spectrum is more stable than voice spectrum.Therefore the global shape that, can suppose noise spectrum all tends to keep identical at any given sections.According to this hypothesis, can continue to incorporate the 3rd feature in this routine voice/noise probability is determined.These supplementary features can be measured the deviation of input spectrum and noise spectrum shape.
This 3rd feature can and be determined as the noise spectrum of learning template by contrast input spectrum.At least in some is arranged, template frequency spectrum is very likely that the section of noise or speech pause is determined by upgrading in frequency spectrum (being set as at first zero).This comparative result is the conservative estimation to noise, wherein only speech probability is determined lower than threshold value (as P (H
1| Y
k(m), F}) < λ) section place upgraded noise.In other are arranged, template frequency spectrum also may be directed in algorithm, or screens from the shape table of the different noises of correspondence.Consider input spectrum Y
k(m) and template frequency spectrum (can be expressed as α
k(m)), as wanted, obtain spectrum mask difference characteristic, can first the measurement of frequency spectrum difference be defined as:
Wherein, (α, u) is form parameter, comprises linear displacement and amplitude parameter, by J is minimized to acquisition.Parameter (α, u) obtains by linear equation, therefore can easily extract this parameter to each frame.In some examples, these parameters can show that any simple displacement/scale of input spectrum (in the situation that volume increases) changes.This feature will become and standardizedly estimate afterwards,
Wherein standardization be all frequencies and before time frame at the average input spectrum of some time window:
As mentioned above, spectrum mask difference characteristic can be measured the difference/deviation of masterplate or acquistion noise spectrum and input spectrum.At least, in some is arranged, this spectrum mask difference characteristic can be used for revising the voice/noise probability q based on feature
k,m(H|F).If F
3less, incoming frame frequency spectrum can be regarded as to " approaching " template frequency spectrum, and probably regard this incoming frame as noise.On the other hand, if spectrum mask difference characteristic value is larger, represent that incoming frame (as incoming frame 200) frequency spectrum and noise template frequency spectrum have very big-difference, just can judge that this frame is voice.In one or more situations of change, template frequency spectrum can be directed into voice/noise probabilistic algorithm, or is used for digitized measurement and use as online resource.
With LRT characteristics of mean and frequency spectrum flatness feature similarity, can use above-mentioned identical " S " type curvilinear function, spectrum mask difference characteristic value is mapped as to probability weight.Need Special attention will be given to, spectrum mask difference characteristic is measured more general than frequency spectrum flatness pattern measurement.If a masterplate possesses the smooth frequency spectrum of constant (approaching perfect), spectrum mask difference characteristic can be reduced to the measurement to frequency spectrum flatness.
At least, in a layout, can in measuring, spectrum mask difference add weighting time limit W
k, to give prominence to the characteristic frequency band in frequency spectrum:
In this example, the weighting time limit of all frequencies can remain W
k=1.
A plurality of features mentioned above (being LRT average, frequency spectrum flatness and spectrum mask difference) can occur in the more new template of voice/noise probability simultaneously, as follows:
Q
m(H|F
1, F
2, F
3)=q
m=γ
pq
m-1+ (1-γ
p) [τ
1m(F
1-T
1)+τ
2m(F
2-T
2)+τ
3m(F
3-T
3)] different features sources (is that different features is passed on different information from different signals, that for example First Characteristic is passed on is electric energy measurement or local SNR, what Second Characteristic was passed on is noise spectrum flatness, what the 3rd feature was passed on is noise stability and general shape), these features complement each other, with provide one more stable, have more adaptive voice/noise probability and upgrade.In the Renewal model of the voice/noise probability above, comprise various weighting time limit (τ
i), threshold parameter { T
i, and for the width parameter of mapping function.For instance, if the frequency spectrum flatness feature (F of given input
2) unreliable, for example noise spectrum is not very smooth, second weighting time limit τ
2may be set to zero, i.e. τ
2=0, thus avoid the measurement of Renewal model to occur unreliable result.For arranging of these weighting time limits and threshold parameter, will below be described in more detail.
Fig. 2 has shown the process of system definite voice/noise possibility 230 in noise estimation and filtering process 275, after possibility is determined, will carry out noise and estimate to upgrade 245(as the renewal of soft decision recurrence noise).For instance, noise estimates that renewal 245 can be expressed as follows:
Wherein
to be the estimation to noise spectrum magnitude while being k of m, frequency slots frame/time.Parameter γ
ncontrol the smoothness that noise upgrades, second time limit used input spectrum and noise estimation last time to upgrade noise, then according to voice/noise probability as above, is weighted, and this can be expressed as:
LR factor Δ wherein
k(m) be:
Quantity q
mbe based on model or the voice/noise probability based on feature, derive from the above-mentioned Renewal model with a plurality of features.Above-mentioned noise estimation model can upgrade each frame of noise possibility large (being that voice possibility is less) and the noise of frequency slots.For the little frame of noise possibility and frequency slots, will the estimation of a upper frame in signal be estimated as noise.
At least, in a layout, noise estimates that more new technological process is subject to voice/noise possibility and smoothness parameter γ
ncontrol, smoothness parameter can be set as the value as 0.85.In different examples, for speech probability, surpass the region of threshold parameter λ, smoothness parameter may be increased to γ
n≈ 0.99, to prevent that the noise level of voice beginning from increasing too high.In one or more layouts, threshold parameter is set to λ=0.2/0.25, hereinafter will be described in detail this.
After completing noise and estimate upgrading 245, noise is estimated and filtering process 275 can adopt to tie up and receives agc filter 250, to reduce or eliminate the estimating noise amount from incoming frame 200.Standard S filter is expressed as follows:
Wherein,
In one or more conventional methods, can be to the direct Applicative time method of average of wave filter, to reduce any interframe fluctuation.According to some aspect of the present invention, S filter represents with priori SNR, and decision-directed (DD) upgrades for priori SNR is carried out to time average calculating.S filter can be expressed as with priori SNR:
Wherein, ρ
k(m) represent priori SNR defined above, noise spectrum replaced with to the noise spectrum that estimation draws:
As mentioned above, according to DD, upgrade and estimate priori SNR.This agc filter, by getting the end and crossing and subtract each other parameter, can draw:
In this layout and other layouts, because upgrading, DD clearly priori SNR is carried out to time average calculating, so can not carry out again external time average computation to this agc filter.Parameter beta is active arrangement (as the pattern) definition according to the noise suppressor of implementing in noise suppressing system (being the squelch assembly 15 shown in Fig. 1).
S filter is applied in incoming quality level frequency spectrum, to obtain the signal (as the estimation to basic speech signal) through suppressing.In noise estimation and filtering process 275, adopt S filter 250 to draw:
Signal is synthetic
Signal synthetic 280 comprises various posteriority squelch processing, to generate the output frame 290 that comprises clean speech.After application S filter, use reverse DFT255 that frame is converted back to time domain.In one or more layouts, convert back time domain and can be expressed as:
Wherein,
After reverse DFT255, as a part for signal synthesis flow 280, the signal through squelch is implemented to energy convergent-divergent 260.Energy convergent-divergent can be used for helping reconstructed speech frame, and reconstruction mode can increase the energy of the voice after suppressing.For example, while implementing convergent-divergent, should guarantee to only have speech frame to be amplified to a certain degree, and noise frame remain unchanged.Because squelch may reduce speech signal level, therefore in convergent-divergent 260 processes, voice section is suitably amplified and benefited.In a layout, the energy loss according to speech frame in noise estimation and filtering process 275, implements convergent-divergent 260 to this frame.Gain situation can recently be determined by the energy before and after squelch is processed by this speech frame:
In current example, can be according to below model extraction scale:
Wherein,
the speech probability of frame m, by getting the speech probability function P (H of all frequencies
1| Y
k(m), F}) mean value and obtain:
In above-mentioned scale equation, if probability
approach 1(this frame may be voice), first will be larger; If this frame may be noise, second will be larger.
In above-mentioned scale equation, parameter A (K), the convergent-divergent of B (K) control inputs frame (as incoming frame 200).For instance, in a layout, A (K), B (K) may control convergent-divergent by following formula: if K>0.5, A (K)=1.0+1.3* (K – 0.5), maximal value obtains by 1/K.If K<0.5, A (K)=1.0.B parameter (K)=1.0, so this frame can not carry out convergent-divergent for noise region.The scale in these regions can be determined by the end item of getting in S filter.
Signal synthetic 280 also comprises window synthetic operation 265, and this operation provides the final output frame 290 of estimating the voice that draw.In one example, window synthetic 265 is:
Wherein, scale parameter is drawn by the above-mentioned scale equation formula of each frame.
Parameter estimation
The Renewal model (formula is as follows) of the voice/noise probability function based on feature comprises a plurality of characteristic weighing (τ that are applied to pattern measurement
i) and threshold value { T
iparameter:
q
m(H|F
1,F
2,F
3)＝q
m＝γ
pq
m-1+(1-γ
p)[τ
1M(F
1-T
1)+τ
2M(F
2-T
2)+τ
3M(F
3-T
3)]
These weightings (τ
i) and threshold value { T
iparameter is used for preventing that insecure pattern measurement from entering Renewal model.Mapping function also comprises width parameter { w
ito control the shape of mapping function:
M=M(F
i-T
i;w
i)
For example,, if the LRT characteristics of mean (F of given input
1) unreliable, if for example there is mistake in initial noise evaluation, first weighting parameters τ
1can be set to zero, i.e. τ
1=0, thus avoid the measurement of insecure LRT average to be brought in Renewal model.
At least in one embodiment, being initially set to of characteristic weighing and threshold parameter, is only used LRT characteristics of mean (F
1), so τ
1=τ
3=0, and the initial threshold of feature is T
1=0.5.Table 1 has been listed the example parameter setting that a plurality of embodiment draw according to the present invention.Table 1 has been indicated each parameter, and provides Short Description and example default value for each parameter.Need to recognize a bit, except these parameters of listing in table 1, can also use a plurality of other parameter settings and/or default value as a supplement or alternate parameter.In table 1, the width parameter of the mapping function that each feature is corresponding is set to identical value, i.e. w=4.
Table 1
In one or more embodiments, for example, for characteristic threshold value and the weighting parameters (T, listing in the Renewal model of voice/noise probability of pattern measurement
1, T
2, T
3and τ
1, τ
2, τ
3, these parameters are also contained in table 1 above) and will after being set, interval dynamically update.In one example, characteristic threshold value and weighting parameters may upgrade for each window W, wherein W=500 frame.In other examples, may use to substitute and upgrade interval, comprise a plurality of frame numbers or set of time interval.In these and other embodiment of the present invention, as shown in Figure 4, may carry out for pattern measurement the more new technological process of characteristic threshold value and weighting parameters.4.
Fig. 4 has set forth for pattern measurement (as LRT characteristics of mean (F
1), frequency spectrum flatness feature (F
2) and spectrum mask difference characteristic (F
3)) example flow of regeneration characteristics threshold value and weighting parameters.This flow process from step 400, for the characteristic threshold value of the first W frame of voice sequence (i.e. 500 frames) and weighting parameters (as T
1, T
2, T
3and τ
1, τ
2, τ
3) be set to initial value.For instance, the initial value of threshold value and weighting parameters may be { T
1=0.5} and { τ
1=1.0, τ
2=0, τ
3=0}.
In step 405, may calculate the W frame feature of relevant (as current or current) parameter estimation window, and draw histogram.For the home window of voice sequence, step 405 comprises the first W frame of this sequence, and the threshold value of this sections and weighting parameters are fixed to the initial value of setting in step 400.In the subsequent window (i.e. the window sequence of other except home window) of voice sequence, threshold value and weighting parameters are fixed as the value from W frame gained before.
Flow process proceeds to step 410, after handling W frame, the histogrammic quantity calculating, extracts new threshold value and weighting parameters for feature from step 405.In one example, the threshold value of feature and weighting parameters be from some histogram quantity, comprises histogram peak position, histogram height, each feature mean value in histogrammic certain limit separately, and the fluctuation of histogrammic certain limit separately of each feature.Except above-mentioned quantity, in the histogram that also can calculate, extract many other quantity from step 405, as a supplement or alternative numerical value, for extract new characteristic threshold value and weighting parameters in step 410.
At least, in a layout, the quantity extracting from the histogram of step 410 and some inner parameters are made comparisons, to determine corresponding prior model threshold value and weighting parameters.The example of these inner parameters may comprise following set: (1) scale parameter, and the domination peak value in the histogram that is applied to measure or the summation of two peak values, to obtain characteristic threshold value; (2) parameter for two too approaching histograms are merged; (3) in the situation that peak averaging height is too small, for refusing the parameter of feature; (4) in the situation that average peak position is too small, for refusing the parameter of feature; (5) in the situation that the LRT characteristic fluctuation within the scope of histogram is too low, for refusing the parameter of some features; And the minimum and maximum limit of the threshold value of (6) each feature.Except above-mentioned example parameter, also can use many other parameters as inner parameter, make comparisons with the quantity extracting in step 410.
In step 415, the threshold value of extracting and weighting parameters are fixed or are set to characteristic threshold value and the weighting parameters of the next W frame of voice sequence from step 410.If arrive the end of voice sequence in step 420, this flow process finishes.But if do not arrive the end of voice sequence in step 420, this flow process will be returned to step 405, use the next W frame repeating step 405 of sequence to step 420, and at step 415 fixed threshold and weighting parameters.
In some embodiments of the invention, as shown in Figure 4, the initial characteristics threshold value and the weighting parameters that in step 400, arrange, will be used in whole voice sequence, and without the value of upgrading these parameters.In other embodiments, after handling the first W frame window of sequence, may upgrade a subthreshold and weighting parameters (, after the initial value of threshold value and weighting parameters, once upgrading).
In other embodiment of the present invention, the characteristic threshold value shown in Fig. 4 and weighting parameters be new technological process more, may use the overlaid windows of sequence, wherein W
1comprise frame 1-500, W
2comprise frame 250-750, W
3comprise frame 500-1000 etc.Another alternative method is to use non-overlapped window, wherein W
1comprise frame 1-500, W
2comprise frame 500-1000, W
3comprise frame 1000-1500, by that analogy.In addition, although some are arranged, use fixing window, each W comprises 500 frames; Other are arranged may use window variable or that change.For instance, W
1may comprise 500 frames, W
2comprise 250 frames, and W
3comprise 750 frames.In addition,, in one or more layouts, these windows variable or that change may be overlapping or non-overlapped, as W
1comprise frame 1-500(500 frame), W
2comprise frame 500-750(250 frame, non-overlapped), and W
3comprise frame 500-1250(750 frame, overlapping).Need to recognize a bit, threshold value and weighting parameters can upgrade according to other multiple window configurations, these configurations comprise multiple other features of given sequence.
According to the more new technological process shown in Fig. 4, in some cases, the characteristic threshold value and the weighting parameters that from step 410, extract can stop one or more features (as LRT characteristics of mean (F
1), frequency spectrum flatness feature (F
2) and/or spectrum mask difference characteristic (F
3)) for the Renewal model of computing voice/noise probability.In this case, the weighting parameters that is not included in each feature in Renewal model will be set to 0.
In the situation that used three kinds of features during the Renewal model of computing voice/noise probability, parameter more characteristic threshold value and the weighting parameters extraction step (step 410 as shown in Figure 4) of new technological process may produce following result: (1) is used all three feature { τ
1=1/3, τ
2=1/3, τ
3=1/3}; (2) use two features, as feature 1 and 3{ τ
1=1/2, τ
2=0, τ
3=1/2}; Or (3) only used a feature, as feature 1{ τ
1=1.0, τ
2=0, τ
3=0}.
Fig. 5 is a calcspar, has explained the example calculations equipment 500 for multipath route, and one or more embodiment according to the present invention draw and form.In the most basic configuration 501, computing equipment 500 generally includes one or more processors 510 and Installed System Memory 520.Rambus 530 can be used for realizing the communication between processor 510 and Installed System Memory 520.
According to required configuration, processor 510 can be any type, includes but not limited to: microprocessor (μ P), microcontroller (μ C), digital signal processor (DSP) or their combination in any.Processor 510 can comprise one or more buffer memory ranks, as level cache 511 and L2 cache 512, processor cores 513 and register 514.Processor cores 513 comprises an ALU (ALU), a floating point unit (FPU), a digital signal processing core (DSP core), or their combination in any.Memory Controller Hub 515 also can together be used with processor 510, and in certain embodiments, Memory Controller Hub 515 is inside ingredients of processor 510.
According to required configuration, Installed System Memory 520 can be any type, includes but not limited to: volatile memory (as RAM), nonvolatile memory (as ROM and flash memory etc.) or their combination in any.Installed System Memory 520 generally includes an operating system 521, one or more application program 522 and routine data 524.At least in certain embodiments, application program 522 comprises a multipath Processing Algorithm 523, and this algorithm configuration is for to pass to noisy input signal in squelch assembly.Multipath Processing Algorithm is further used for other assemblies from squelch component passes to signal processing approach by the output of processing through squelch.Routine data 524 also comprises multipath route data 525, can be used for that noisy input signal is passed to squelch assembly etc. along a plurality of signal pathways and locate, can guarantee like this that this assembly is controlled or changed this in other audio frequency processing procedures to receive this signal before having noise cancellation signal.
Installed System Memory 520, movable memory equipment 551 and non-moving memory device 552 all belong to computer-readable storage medium.Computer-readable storage medium includes but not limited to RAM, ROM, EEPROM, flash memory or other memory technologies, CD-ROM, digital versatile disc (DVD) or other optical memories, magnetic tape cassette, tape, magnetic disk memory or other magnetic stories, or can be used in storage information needed and can carry out by computing equipment 500 any other medium of access.Any this type of computer-readable storage medium may be all a part for computing equipment 500.
Computing equipment 500 also comprises interface bus 542, and this interface bus is for promoting communicating by letter from various interface equipment (such as output interface, peripheral interface and communication interface etc.) to basic setup 501, and this type of communication realizes by bus/interface controller 540.Example output device 560 comprises a Graphics Processing Unit 561 and an audio treatment unit 562, configuration is arbitrary unit or simultaneously configure two unit wherein, can communicate with the various external units such as display or loudspeaker, this type of communication realizes by one or more A/V ports 563.Exemplary peripheral interface 570 comprises a serial interface controller 571 or a parallel interface controller 572, these two kinds of interface controllers all can be through configuration, realization and input equipment are (for example, keyboard, mouse, pen, voice-input device or touch input device etc.) etc. the communication of external unit or other peripherals (such as printer or scanner etc.), this type of communication realizes by one or more I/O ports 573.Example communication device 580 comprises a network controller 581, and this controller is arranged, can promote and one or more other computing equipments 590 between network service (not shown), this type of communication realizes by one or more communication port 582.Such communication connection is an example of communication media.Common communication media comprises other data of computer-readable instruction, data structure, program module or modulated data signal form, such as carrier wave or other transmission mechanisms, also comprises any information transmitting medium." modulated data signal " can be the signal that has one or more feature sets, or can in signal, to information, encode, and it is changed.For instance, communication media includes but not limited to: the wire mediums such as cable network or directly wire connection, and the wireless medium such as audio frequency, radio frequency (RF), infrared ray (IR) and other wireless mediums." computer-readable medium " used herein word comprises storage medium and communication media.
The hardware and software of system aspects is realized does not almost have any difference; Use hardware or software conventionally (but not such was the case with, in some cases, selects hardware or the software may be extremely important) be a kind of design alternative, represented the balance of cost and efficiency.Flow process described herein and/or system and/or other technologies can for example, play a role by various kinds of media thing (hardware, software and/or firmware), and the environment of flow process and/or system and/or other technologies deployment is different, first-selected medium is also by different.For example, if the personnel of realizing determine speed and accuracy, be most important, he may be inclined to and select hardware and/or firmware medium; If determine that dirigibility is most important, may be inclined to and select software to realize.In one or more other situations, the personnel of realization may also can select being combined with of hardware, software and/or firmware.
More than describe in detail by using calcspar, process flow diagram and/or example, listed the various embodiments of equipment and/or flow process.Owing to comprising one or more functions and/or operation in these calcspars, process flow diagram and/or example, the personnel of association area will obtain such understanding: each function in these calcspars, process flow diagram or example and/or operation can come separately and/or realize simultaneously by hardware, software, firmware or three's combination in any widely.
In one or more embodiments, several parts of invention described herein can be achieved by special IC (ASIC), field programmable gate array (FPGA), digital signal processor (DSP) or other integrated forms.Yet, one of ordinary skill in the art can find, some aspect of embodiment described herein (all or part of) can be in integrated circuit equivalence realize, for example, as the one or more computer programs that move on one or more computing machines (one or more programs of moving in one or more computer systems), for example, as one or more programs (one or more programs of moving on one or more microprocessors) of moving on one or more processors, as firmware or as the combination in any of above-mentioned form.One of ordinary skill in the art also will further recognize, according to the present invention, one of ordinary skill in the art can be like a cork for software and/or firmware design circuit and/or write code.
In addition, one of ordinary skill in the art will be understood that, the operating mechanism of invention described herein can be distributed as various forms of program products, and why type the signal transmission medium of no matter carrying out this distribution for reality, the illustrative embodiment of invention described herein is all applicable.The example of signal transmission medium includes but not limited to following content: medium that can record type, such as floppy disk, hard disk drive, CD (CD), digital video disk (DVD), numerical tape and computer memory etc.; And the medium of transport-type, such as numeral and/or analogue communication medium (such as fiber optic cables, waveguide, wire communication link and wireless communication link etc.).
One of ordinary skill in the art also will recognize, in this field, in mode described herein, describe equipment and/or flow process, then use engineering practice by the equipment of so describing and/or Process integration in data handling system, this way is very common.That is to say, in equipment described herein and/or flow process, to have at least a part to be integrated in data handling system by the experiment of fair amount.One of ordinary skill in the art will recognize, typical data handling system generally includes one or more system unit shells; A video display apparatus; Volatibility or nonvolatile memory; The processor such as microprocessor and digital signal processor; The computational entities such as operating system, driver, graphic user interface and application program; One or more interactive devices, such as touch pad or touch-screen; And/or control system, comprise backfeed loop and control motor (for example,, for the feedback of sensing location and/or speed; For control motor mobile and/or adjustment assembly and/or quantity).Typical data handling system may utilize commercially available applicable assembly on the market to realize, such as normally used those assemblies in calculate/communication of data and/or network calculations/communication system.
About a large amount of plural number and/or singular noun of using herein, one of ordinary skill in the art can be based on context and/or usable condition, adopts odd number or plural form.For clarity sake, clearly listed the change situation of various singular/plural herein.
In view of having disclosed a plurality of different aspects and embodiment herein, one of ordinary skill in the art should be able to understand the rest by analogy, and expect other aspects and embodiment.The various aspects and the embodiment that disclose are herein the use in order to explain, and are not intended to propose restriction, and following claim has indicated true scope and the intrinsic meaning of patent.
Claims (according to the modification of the 19th of treaty)
1. by a method for the estimation of squelch assembly and filtered noise, the method comprises the following steps:
Each frame of the continuous multiple frames input signal that squelch assembly receives for it, is estimated as basis with the initial noise to this frame, definition speech probability function;
Measure the multicomponent signal characteristic of division of each frame in multiframe;
Every frame signal characteristic of division that use is measured, the speech probability based on feature of each frame in calculating multiframe;
Speech probability to the every frame calculating based on feature is applied one or more dynamic weighting factors, and every frame signal characteristic of division of measuring is applied to one or more dynamic weighting factors;
Speech probability according to the every frame calculating after the one or more dynamic weighting factors of application based on feature, the speech probability function of each frame in modification multiframe;
Use amended every frame speech probability function, upgrade the initial noise of each frame in multiframe and estimate; And
Initial noise after using every frame to upgrade is estimated, to each the filtering frames noise in multiframe.
2. method according to claim 1, is characterized in that, one or more dynamic weighting factors comprise the weighted sum threshold parameter of every frame signal characteristic of division.
3. method according to claim 1, is characterized in that, initial noise estimates it is that fractile noise with each frame in continuous multiple frames is estimated as basis.
4. method according to claim 1, is characterized in that, the speech probability based on feature that one or more dynamic weighting factors are applied to calculate, and concrete steps comprise:
Every frame signal characteristic of division of measuring is applied to one or more dynamic weighting factors; And
Frame for the one or more dynamic weighting factors of application, upgrades its speech probability based on feature.
5. method according to claim 4, it is characterized in that, every frame signal characteristic of division of measuring is applied to the step of one or more dynamic weighting factors, comprised one or more dynamic weighting factors are combined with the signal characteristic of division of measuring, form the speech probability function based on feature.
6. method according to claim 5, the method further comprises:
Upgrade the speech probability function based on feature of each frame in multiframe; And
According to the speech probability function based on feature after upgrading, upgrade the speech probability function of each frame in multiframe.
7. method according to claim 1, is characterized in that, multicomponent signal characteristic of division is for being divided into a kind of voice or noise classification state by input signal.
8. method according to claim 6, is characterized in that, uses recurrence average to upgrade the speech probability function based on feature.
9. method according to claim 5, is characterized in that, the speech probability function based on feature is to draw by using mapping function that the signal characteristic of division of every frame is mapped to a probable value.
10. method according to claim 9, is characterized in that, mapping function is according to the value definition of signal characteristic of division, and comprises one or more threshold values and width parameter.
11. methods according to claim 1, is characterized in that, it is basis that speech probability function further be take the likelihood ratio factor of frame.
12. methods according to claim 1, is characterized in that, multicomponent signal characteristic of division at least comprises: time dependent average likelihood, frequency spectrum flatness are measured and spectrum mask difference is measured.
13. methods according to claim 1, is characterized in that, one or more dynamic weighting factors to one of major general's following characteristics is elected multicomponent signal characteristic of division as: time dependent likelihood ratio, frequency spectrum flatness are measured and spectrum mask difference is measured.
14. according to method described in claim 12, it is characterized in that, spectrum mask difference measures that to take the contrast of input signal spectrum and Pattern Noise frequency spectrum be basic.
15. according to method described in claim 14, it is characterized in that, the noise that the estimation of Pattern Noise frequency spectrum be take after upgrading estimates that (using speech probability function and one group of form parameter estimating after upgrading to upgrade) is basis.
16. according to method described in claim 15, it is characterized in that, the form parameter estimating is one or more displacements, amplitude and normalizing parameter.
17. methods according to claim 1, the method further comprises:
For response is to each the filtering frames noise in multiframe, according to amended frame speech probability function, the energy of each frame of convergent-divergent.
18. methods according to claim 2, the method further comprises:
For being applied to the weighted sum threshold parameter of every frame signal characteristic of division, initial value is set; And
After first interval appears in input signal, upgrade the initial value of weighted sum threshold parameter.
19. according to method described in claim 18, it is characterized in that, the step of upgrading the initial value of weighted sum threshold parameter comprises:
When there is first interval, calculate the histogram of every frame signal characteristic of division;
According to being derived from histogrammic one or more quantity, determine the new value of weighted sum threshold parameter; And
When the interval for the second time of input signal, use the new value of weighted sum threshold parameter.
20. according to method described in claim 19, it is characterized in that, first and for the second time interval is to occur according to the sequence of the frame of input signal.
21. according to method described in claim 19, and the method further comprises:
To be derived from histogrammic one or more quantity and one or more inner parameter and compare, to determine the corresponding weighted sum threshold parameter of the speech probability of input signal based on feature.
Claims (22)
1. by a method for the estimation of squelch assembly and filtered noise, the method comprises the following steps:
Each frame of the continuous multiple frames input signal that squelch assembly receives for it, is estimated as basis with the initial noise to this frame, definition speech probability function;
Measure the multicomponent signal characteristic of division of each frame in multiframe;
Every frame signal characteristic of division that use is measured, the speech probability based on feature of each frame in calculating multiframe;
The speech probability based on feature of each frame in the multiframe calculating is applied to one or more dynamic weighting factors;
Speech probability according to the every frame calculating based on feature, the speech probability function of each frame in modification multiframe; And
Use amended every frame speech probability function, upgrade the initial noise of each frame in multiframe and estimate.
2. method according to claim 1, the method further comprises:
Initial noise after using every frame to upgrade is estimated, to each the filtering frames noise in multiframe.
3. method according to claim 1, is characterized in that, one or more dynamic weighting factors comprise the weighted sum threshold parameter of every frame signal characteristic of division.
4. method according to claim 1, is characterized in that, initial noise estimates it is that fractile noise with each frame in continuous multiple frames is estimated as basis.
5. method according to claim 1, is characterized in that, the speech probability based on feature that one or more dynamic weighting factors are applied to calculate, and concrete steps comprise:
Every frame signal characteristic of division of measuring is applied to one or more dynamic weighting factors; And
Frame for the one or more dynamic weighting factors of application, upgrades its speech probability based on feature.
6. method according to claim 5, it is characterized in that, every frame signal characteristic of division of measuring is applied to the step of one or more dynamic weighting factors, comprised one or more dynamic weighting factors are combined with the signal characteristic of division of measuring, form the speech probability function based on feature.
7. method according to claim 6, the method further comprises:
Upgrade the speech probability function based on feature of each frame in multiframe; And
According to the speech probability function based on feature after upgrading, upgrade the speech probability function of each frame in multiframe.
8. method according to claim 1, is characterized in that, multicomponent signal characteristic of division is for being divided into a kind of voice or noise classification state by input signal.
9. method according to claim 7, is characterized in that, uses recurrence average to upgrade the speech probability function based on feature.
10. method according to claim 6, is characterized in that, the speech probability function based on feature is to draw by using mapping function that the signal characteristic of division of every frame is mapped to a probable value.
11. methods according to claim 10, is characterized in that, mapping function is according to the value definition of signal characteristic of division, and comprises one or more threshold values and width parameter.
12. methods according to claim 1, is characterized in that, it is basis that speech probability function further be take the likelihood ratio factor of frame.
13. methods according to claim 1, is characterized in that, multicomponent signal characteristic of division at least comprises: time dependent average likelihood, frequency spectrum flatness are measured and spectrum mask difference is measured.
14. methods according to claim 1, is characterized in that, one or more dynamic weighting factors to one of major general's following characteristics is elected multicomponent signal characteristic of division as: time dependent likelihood ratio, frequency spectrum flatness are measured and spectrum mask difference is measured.
15. according to method described in claim 13, it is characterized in that, spectrum mask difference measures that to take the contrast of input signal spectrum and Pattern Noise frequency spectrum be basic.
16. according to method described in claim 15, it is characterized in that, the noise that the estimation of Pattern Noise frequency spectrum be take after upgrading estimates that (using speech probability function and one group of form parameter estimating after upgrading to upgrade) is basis.
17. according to method described in claim 16, it is characterized in that, the form parameter estimating is one or more displacements, amplitude and normalizing parameter.
18. methods according to claim 2, the method further comprises:
For response is to each the filtering frames noise in multiframe, according to amended frame speech probability function, the energy of each frame of convergent-divergent.
19. methods according to claim 3, the method further comprises:
For being applied to the weighted sum threshold parameter of every frame signal characteristic of division, initial value is set; And
After first interval appears in input signal, upgrade the initial value of weighted sum threshold parameter.
20. according to method described in claim 19, it is characterized in that, the step of upgrading the initial value of weighted sum threshold parameter comprises:
When there is first interval, calculate the histogram of every frame signal characteristic of division;
According to being derived from histogrammic one or more quantity, determine the new value of weighted sum threshold parameter; And
When the interval for the second time of input signal, use the new value of weighted sum threshold parameter.
21. according to method described in claim 20, it is characterized in that, first and for the second time interval is to occur according to the sequence of the frame of input signal.
22. according to method described in claim 20, and the method further comprises:
To be derived from histogrammic one or more quantity and one or more inner parameter and compare, to determine the corresponding weighted sum threshold parameter of the speech probability of input signal based on feature.
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/US2011/036637 WO2012158156A1 (en) | 2011-05-16 | 2011-05-16 | Noise supression method and apparatus using multiple feature modeling for speech/noise likelihood |
Publications (2)
Publication Number | Publication Date |
---|---|
CN103650040A true CN103650040A (en) | 2014-03-19 |
CN103650040B CN103650040B (en) | 2017-08-25 |
Family
ID=44279729
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201180072331.0A Active CN103650040B (en) | 2011-05-16 | 2011-05-16 | Use the noise suppressing method and device of multiple features modeling analysis speech/noise possibility |
Country Status (2)
Country | Link |
---|---|
CN (1) | CN103650040B (en) |
WO (1) | WO2012158156A1 (en) |
Cited By (26)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN104886981A (en) * | 2015-04-29 | 2015-09-09 | 成都陌云科技有限公司 | Active noise reduction bed |
CN104900237A (en) * | 2015-04-24 | 2015-09-09 | 上海聚力传媒技术有限公司 | Method, device and system for denoising audio information |
CN105355199A (en) * | 2015-10-20 | 2016-02-24 | 河海大学 | Model combination type speech recognition method based on GMM (Gaussian mixture model) noise estimation |
WO2016119501A1 (en) * | 2015-01-28 | 2016-08-04 | 中兴通讯股份有限公司 | Method and apparatus for implementing missing feature reconstruction |
CN106024018A (en) * | 2015-03-27 | 2016-10-12 | 大陆汽车系统公司 | Real-time wind buffet noise detection |
CN106384597A (en) * | 2016-08-31 | 2017-02-08 | 广州市百果园网络科技有限公司 | Audio frequency data processing method and device |
CN106486135A (en) * | 2015-08-27 | 2017-03-08 | 想象技术有限公司 | Near-end Voice Detection device |
CN106571150A (en) * | 2015-10-12 | 2017-04-19 | 阿里巴巴集团控股有限公司 | Method and system for positioning human acoustic zone of music |
CN107123419A (en) * | 2017-05-18 | 2017-09-01 | 北京大生在线科技有限公司 | The optimization method of background noise reduction in the identification of Sphinx word speeds |
CN107564512A (en) * | 2016-06-30 | 2018-01-09 | 展讯通信（上海）有限公司 | Voice activity detection method and device |
CN108022591A (en) * | 2017-12-30 | 2018-05-11 | 北京百度网讯科技有限公司 | The processing method of speech recognition, device and electronic equipment in environment inside car |
CN109643552A (en) * | 2016-09-09 | 2019-04-16 | 大陆汽车系统公司 | Robust noise estimation for speech enhan-cement in variable noise situation |
CN109643554A (en) * | 2018-11-28 | 2019-04-16 | 深圳市汇顶科技股份有限公司 | Adaptive voice Enhancement Method and electronic equipment |
CN109979478A (en) * | 2019-04-08 | 2019-07-05 | 网易（杭州）网络有限公司 | Voice de-noising method and device, storage medium and electronic equipment |
CN110265064A (en) * | 2019-06-12 | 2019-09-20 | 腾讯音乐娱乐科技（深圳）有限公司 | Audio sonic boom detection method, device and storage medium |
CN110648680A (en) * | 2019-09-23 | 2020-01-03 | 腾讯科技（深圳）有限公司 | Voice data processing method and device, electronic equipment and readable storage medium |
CN110739005A (en) * | 2019-10-28 | 2020-01-31 | 南京工程学院 | real-time voice enhancement method for transient noise suppression |
WO2020125376A1 (en) * | 2018-12-18 | 2020-06-25 | 腾讯科技（深圳）有限公司 | Voice denoising method and apparatus, computing device and computer readable storage medium |
CN111429929A (en) * | 2020-03-03 | 2020-07-17 | 厦门快商通科技股份有限公司 | Voice denoising method, voice recognition method and computer readable storage medium |
CN111986691A (en) * | 2020-09-04 | 2020-11-24 | 腾讯科技（深圳）有限公司 | Audio processing method and device, computer equipment and storage medium |
CN112002339A (en) * | 2020-07-22 | 2020-11-27 | 海尔优家智能科技（北京）有限公司 | Voice noise reduction method and device, computer-readable storage medium and electronic device |
WO2021007841A1 (en) * | 2019-07-18 | 2021-01-21 | 深圳市汇顶科技股份有限公司 | Noise estimation method, noise estimation apparatus, speech processing chip and electronic device |
CN112581962A (en) * | 2015-05-27 | 2021-03-30 | 谷歌有限责任公司 | Context sensitive dynamic update of a speech to text model in a speech enabled electronic device |
CN113470674A (en) * | 2020-03-31 | 2021-10-01 | 珠海格力电器股份有限公司 | Voice noise reduction method and device, storage medium and computer equipment |
CN113539300A (en) * | 2020-04-10 | 2021-10-22 | 宇龙计算机通信科技(深圳)有限公司 | Voice detection method and device based on noise suppression, storage medium and terminal |
CN110648680B (en) * | 2019-09-23 | 2024-05-14 | 腾讯科技（深圳）有限公司 | Voice data processing method and device, electronic equipment and readable storage medium |
Families Citing this family (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
TWI557722B (en) * | 2012-11-15 | 2016-11-11 | 緯創資通股份有限公司 | Method to filter out speech interference, system using the same, and computer readable recording medium |
WO2016135741A1 (en) * | 2015-02-26 | 2016-09-01 | Indian Institute Of Technology Bombay | A method and system for suppressing noise in speech signals in hearing aids and speech communication devices |
CN111261183B (en) * | 2018-12-03 | 2022-11-22 | 珠海格力电器股份有限公司 | Method and device for denoising voice |
CN112017676A (en) * | 2019-05-31 | 2020-12-01 | 京东数字科技控股有限公司 | Audio processing method, apparatus and computer readable storage medium |
CN111477243B (en) * | 2020-04-16 | 2023-05-23 | 维沃移动通信有限公司 | Audio signal processing method and electronic equipment |
Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN1770264A (en) * | 2000-12-28 | 2006-05-10 | 日本电气株式会社 | Noise removing method and device |
EP1662481A2 (en) * | 2004-11-25 | 2006-05-31 | LG Electronics Inc. | Speech detection method |
EP2058797A1 (en) * | 2007-11-12 | 2009-05-13 | Harman Becker Automotive Systems GmbH | Discrimination between foreground speech and background noise |
-
2011
- 2011-05-16 WO PCT/US2011/036637 patent/WO2012158156A1/en active Application Filing
- 2011-05-16 CN CN201180072331.0A patent/CN103650040B/en active Active
Patent Citations (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN1770264A (en) * | 2000-12-28 | 2006-05-10 | 日本电气株式会社 | Noise removing method and device |
EP1662481A2 (en) * | 2004-11-25 | 2006-05-31 | LG Electronics Inc. | Speech detection method |
EP2058797A1 (en) * | 2007-11-12 | 2009-05-13 | Harman Becker Automotive Systems GmbH | Discrimination between foreground speech and background noise |
Cited By (39)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
WO2016119501A1 (en) * | 2015-01-28 | 2016-08-04 | 中兴通讯股份有限公司 | Method and apparatus for implementing missing feature reconstruction |
CN106024018A (en) * | 2015-03-27 | 2016-10-12 | 大陆汽车系统公司 | Real-time wind buffet noise detection |
CN104900237A (en) * | 2015-04-24 | 2015-09-09 | 上海聚力传媒技术有限公司 | Method, device and system for denoising audio information |
CN104886981A (en) * | 2015-04-29 | 2015-09-09 | 成都陌云科技有限公司 | Active noise reduction bed |
CN112581962A (en) * | 2015-05-27 | 2021-03-30 | 谷歌有限责任公司 | Context sensitive dynamic update of a speech to text model in a speech enabled electronic device |
CN112581962B (en) * | 2015-05-27 | 2024-04-05 | 谷歌有限责任公司 | Context-sensitive dynamic updating of speech-to-text models in speech-enabled electronic devices |
CN106486135A (en) * | 2015-08-27 | 2017-03-08 | 想象技术有限公司 | Near-end Voice Detection device |
CN106486135B (en) * | 2015-08-27 | 2021-11-30 | 想象技术有限公司 | Near-end speech detector, speech system and method for classifying speech |
CN106571150A (en) * | 2015-10-12 | 2017-04-19 | 阿里巴巴集团控股有限公司 | Method and system for positioning human acoustic zone of music |
CN106571150B (en) * | 2015-10-12 | 2021-04-16 | 阿里巴巴集团控股有限公司 | Method and system for recognizing human voice in music |
CN105355199A (en) * | 2015-10-20 | 2016-02-24 | 河海大学 | Model combination type speech recognition method based on GMM (Gaussian mixture model) noise estimation |
CN105355199B (en) * | 2015-10-20 | 2019-03-12 | 河海大学 | A kind of model combination audio recognition method based on the estimation of GMM noise |
CN107564512A (en) * | 2016-06-30 | 2018-01-09 | 展讯通信（上海）有限公司 | Voice activity detection method and device |
CN107564512B (en) * | 2016-06-30 | 2020-12-25 | 展讯通信（上海）有限公司 | Voice activity detection method and device |
CN106384597A (en) * | 2016-08-31 | 2017-02-08 | 广州市百果园网络科技有限公司 | Audio frequency data processing method and device |
CN109643552A (en) * | 2016-09-09 | 2019-04-16 | 大陆汽车系统公司 | Robust noise estimation for speech enhan-cement in variable noise situation |
CN107123419A (en) * | 2017-05-18 | 2017-09-01 | 北京大生在线科技有限公司 | The optimization method of background noise reduction in the identification of Sphinx word speeds |
US11017799B2 (en) | 2017-12-30 | 2021-05-25 | Beijing Baidu Netcom Science And Technology Co., Ltd. | Method for processing voice in interior environment of vehicle and electronic device using noise data based on input signal to noise ratio |
CN108022591A (en) * | 2017-12-30 | 2018-05-11 | 北京百度网讯科技有限公司 | The processing method of speech recognition, device and electronic equipment in environment inside car |
CN108022591B (en) * | 2017-12-30 | 2021-03-16 | 北京百度网讯科技有限公司 | Processing method and device for voice recognition in-vehicle environment and electronic equipment |
CN109643554A (en) * | 2018-11-28 | 2019-04-16 | 深圳市汇顶科技股份有限公司 | Adaptive voice Enhancement Method and electronic equipment |
WO2020125376A1 (en) * | 2018-12-18 | 2020-06-25 | 腾讯科技（深圳）有限公司 | Voice denoising method and apparatus, computing device and computer readable storage medium |
CN109979478A (en) * | 2019-04-08 | 2019-07-05 | 网易（杭州）网络有限公司 | Voice de-noising method and device, storage medium and electronic equipment |
CN110265064A (en) * | 2019-06-12 | 2019-09-20 | 腾讯音乐娱乐科技（深圳）有限公司 | Audio sonic boom detection method, device and storage medium |
CN112602150A (en) * | 2019-07-18 | 2021-04-02 | 深圳市汇顶科技股份有限公司 | Noise estimation method, noise estimation device, voice processing chip and electronic equipment |
WO2021007841A1 (en) * | 2019-07-18 | 2021-01-21 | 深圳市汇顶科技股份有限公司 | Noise estimation method, noise estimation apparatus, speech processing chip and electronic device |
CN110648680A (en) * | 2019-09-23 | 2020-01-03 | 腾讯科技（深圳）有限公司 | Voice data processing method and device, electronic equipment and readable storage medium |
CN110648680B (en) * | 2019-09-23 | 2024-05-14 | 腾讯科技（深圳）有限公司 | Voice data processing method and device, electronic equipment and readable storage medium |
CN110739005A (en) * | 2019-10-28 | 2020-01-31 | 南京工程学院 | real-time voice enhancement method for transient noise suppression |
CN110739005B (en) * | 2019-10-28 | 2022-02-01 | 南京工程学院 | Real-time voice enhancement method for transient noise suppression |
CN111429929B (en) * | 2020-03-03 | 2023-01-03 | 厦门快商通科技股份有限公司 | Voice denoising method, voice recognition method and computer readable storage medium |
CN111429929A (en) * | 2020-03-03 | 2020-07-17 | 厦门快商通科技股份有限公司 | Voice denoising method, voice recognition method and computer readable storage medium |
CN113470674A (en) * | 2020-03-31 | 2021-10-01 | 珠海格力电器股份有限公司 | Voice noise reduction method and device, storage medium and computer equipment |
CN113470674B (en) * | 2020-03-31 | 2023-06-16 | 珠海格力电器股份有限公司 | Voice noise reduction method and device, storage medium and computer equipment |
CN113539300A (en) * | 2020-04-10 | 2021-10-22 | 宇龙计算机通信科技(深圳)有限公司 | Voice detection method and device based on noise suppression, storage medium and terminal |
CN112002339A (en) * | 2020-07-22 | 2020-11-27 | 海尔优家智能科技（北京）有限公司 | Voice noise reduction method and device, computer-readable storage medium and electronic device |
CN112002339B (en) * | 2020-07-22 | 2024-01-26 | 海尔优家智能科技（北京）有限公司 | Speech noise reduction method and device, computer-readable storage medium and electronic device |
CN111986691A (en) * | 2020-09-04 | 2020-11-24 | 腾讯科技（深圳）有限公司 | Audio processing method and device, computer equipment and storage medium |
CN111986691B (en) * | 2020-09-04 | 2024-02-02 | 腾讯科技（深圳）有限公司 | Audio processing method, device, computer equipment and storage medium |
Also Published As
Publication number | Publication date |
---|---|
CN103650040B (en) | 2017-08-25 |
WO2012158156A1 (en) | 2012-11-22 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN103650040A (en) | Noise supression method and apparatus using multiple feature modeling for speech/noise likelihood | |
US11138992B2 (en) | Voice activity detection based on entropy-energy feature | |
CN106486131B (en) | A kind of method and device of speech de-noising | |
CN103354937B (en) | Comprise the aftertreatment of the medium filtering of noise suppression gain | |
US8239194B1 (en) | System and method for multi-channel multi-feature speech/noise classification for noise suppression | |
CN100382141C (en) | System for inhibitting wind noise | |
CN101390155B (en) | Voice recognition with speaker adaptation and registration with pitch | |
US4720802A (en) | Noise compensation arrangement | |
CN102197424B (en) | Systems, methods, apparatus for coherence detection | |
US20160284346A1 (en) | Deep neural net based filter prediction for audio event classification and extraction | |
US20050143997A1 (en) | Method and apparatus using spectral addition for speaker recognition | |
CN101790752A (en) | Multiple microphone voice activity detector | |
US11069366B2 (en) | Method and device for evaluating performance of speech enhancement algorithm, and computer-readable storage medium | |
CN103325379A (en) | Method and device used for acoustic echo control | |
CN103325384A (en) | Harmonicity estimation, audio classification, pitch definition and noise estimation | |
Chowdhury et al. | Bayesian on-line spectral change point detection: a soft computing approach for on-line ASR | |
EP3757993A1 (en) | Pre-processing for automatic speech recognition | |
KR101581885B1 (en) | Apparatus and Method for reducing noise in the complex spectrum | |
EP2845190B1 (en) | Processing apparatus, processing method, program, computer readable information recording medium and processing system | |
Malek et al. | Block‐online multi‐channel speech enhancement using deep neural network‐supported relative transfer function estimates | |
Schmidt et al. | Reduction of non-stationary noise using a non-negative latent variable decomposition | |
Bavkar et al. | PCA based single channel speech enhancement method for highly noisy environment | |
López-Espejo et al. | Feature enhancement for robust speech recognition on smartphones with dual-microphone | |
Lee et al. | Bone-conduction sensor assisted noise estimation for improved speech enhancement | |
Dat et al. | On-line Gaussian mixture modeling in the log-power domain for signal-to-noise ratio estimation and speech enhancement |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
C10 | Entry into substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
GR01 | Patent grant | ||
GR01 | Patent grant | ||
CP01 | Change in the name or title of a patent holder | ||
CP01 | Change in the name or title of a patent holder |
Address after: American CaliforniaPatentee after: Google limited liability companyAddress before: American CaliforniaPatentee before: Google Inc. |