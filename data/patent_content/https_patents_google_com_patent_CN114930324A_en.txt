CN114930324A - Shared embedded privacy control for searching and indexing media content - Google Patents
Shared embedded privacy control for searching and indexing media content Download PDFInfo
- Publication number
- CN114930324A CN114930324A CN202080092016.3A CN202080092016A CN114930324A CN 114930324 A CN114930324 A CN 114930324A CN 202080092016 A CN202080092016 A CN 202080092016A CN 114930324 A CN114930324 A CN 114930324A
- Authority
- CN
- China
- Prior art keywords
- user
- media content
- images
- media
- digital key
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/50—Information retrieval; Database structures therefor; File system structures therefor of still image data
- G06F16/53—Querying
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/60—Protecting data
- G06F21/62—Protecting access to data via a platform, e.g. using keys or access control rules
- G06F21/6218—Protecting access to data via a platform, e.g. using keys or access control rules to a system of files or objects, e.g. local or distributed file system or database
- G06F21/6245—Protecting personal data, e.g. for financial or medical purposes
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/40—Information retrieval; Database structures therefor; File system structures therefor of multimedia data, e.g. slideshows comprising image and additional audio data
- G06F16/41—Indexing; Data structures therefor; Storage structures
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/40—Information retrieval; Database structures therefor; File system structures therefor of multimedia data, e.g. slideshows comprising image and additional audio data
- G06F16/43—Querying
- G06F16/438—Presentation of query results
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/70—Information retrieval; Database structures therefor; File system structures therefor of video data
- G06F16/73—Querying
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/951—Indexing; Web crawling techniques
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/30—Authentication, i.e. establishing the identity or authorisation of security principals
- G06F21/31—User authentication
- G06F21/32—User authentication using biometric data, e.g. fingerprints, iris scans or voiceprints
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F21/00—Security arrangements for protecting computers, components thereof, programs or data against unauthorised activity
- G06F21/60—Protecting data
- G06F21/602—Providing cryptographic facilities or services
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N3/00—Computing arrangements based on biological models
- G06N3/02—Neural networks
- G06N3/04—Architecture, e.g. interconnection topology
- G06N3/045—Combinations of networks
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V40/00—Recognition of biometric, human-related or animal-related patterns in image or video data
- G06V40/10—Human or animal bodies, e.g. vehicle occupants or pedestrians; Body parts, e.g. hands
- G06V40/16—Human faces, e.g. facial parts, sketches or expressions
- G06V40/172—Classification, e.g. identification
Abstract
This document describes techniques and systems that implement shared embedded privacy control for searching and indexing media content. A set of images of a user's face is obtained and a machine learning model (122) is applied to the set of images to generate a user-specific dataset (124) for facial embedding of the user. Media content stored in a media store (116, 136) is indexed by applying a machine learning model (122) to the media content to provide indexed media information (118) identifying one or more faces shown in the media content. Access to the indexed media information (118) by other users to query media content for images or videos depicting the user is controlled based on a digital key (112) that the user shares with the other users, wherein the digital key (112) is associated with a user-specific data set (124), the user-specific data set (124) usable to identify the images or videos depicting the user.
Description
Background
The deep learning model may generate embeddings for different types of input, such as multiple input images of a given user's face. Embedding is an n-dimensional vector representing an image and can be used by machine learning techniques to represent the visual appearance of a person based on multiple images of the person. Embedding can be used in a variety of different applications to create models that can be used to identify people in media content, such as images, video, or audio content. Depending on the application, embedding may be used to capture, for example, the user's face, the user's body, the user's fingerprint, or even the user's voice. While these embeddings are a powerful tool, they can identify the user's sensitive data.
Disclosure of Invention
This document describes techniques and systems that implement shared embedded privacy control for searching and indexing media content. The techniques described herein allow users to give access to search and indexing features based on embedding user faces into a limited set of white-listed users, and then revoke access from one or more of these users.
Techniques and systems include a method of controlling privacy of a shared embedding for searching and indexing media content. The method includes obtaining a set of images of a first user's face and applying a machine learning model to the set of images to generate a user-specific dataset for facial embedding of the first user. Media content stored in the media storage is then indexed based on the user-specific dataset to provide indexed information identifying one or more faces shown in the media content. Access to indexed information of media content is controlled by a second user for querying an image or video depicting the first user based on a digital key shared by the first user and the second user, wherein the digital key is associated with a user-specific data set and the user-specific data set is usable to identify the image or video depicting the first user.
The digital key may be stored only "in the cloud," such as at the service provider system or other secure online storage associated with the service provider system, and not at the user's device. The service provider system may provide online storage of personalized media collections for the user. These personalized media collections may be account-based and securely encrypted. In such an embodiment, a user may provide user credentials to log into their account and then initiate a search query through the service provider system based on their account. In this way, the shared digital key is not shared with any actual user device, and thus forgery and copying can be more securely prevented. In addition, personalized media collections that may be searched for a particular user may be bound to the user's account, thereby protecting other media collections from unauthorized searches.
Personalized media collections of a user may be indexed, and a service provider system may store the indexed information for each media collection individually. Maintaining separately stored indexed information for different users may provide an additional level of security from unauthorized access (e.g., granting access to indexed information for a first user increases unauthorized access to indexed information for a second user).
This summary is provided to introduce simplified concepts related to shared embedded privacy controls for searching and indexing media content, which are further described in the detailed description and accompanying drawings that follow. This summary is not intended to identify essential features of the claimed subject matter, nor is it intended for use in determining the scope of the claimed subject matter.
Drawings
Details of one or more aspects of shared embedded privacy control for searching and indexing media content are described in this document with reference to the following figures. The same numbers are used throughout the drawings to reference like functions and components:
FIG. 1 illustrates an example environment in which techniques for shared embedded privacy control for searching and indexing media content may be implemented.
FIG. 2 illustrates an example embodiment of an electronic device that may implement shared embedded privacy controls for searching and indexing media content.
FIG. 3 illustrates an example embodiment of shared embedded privacy control for searching and indexing media content.
FIG. 4 depicts example search results for a user-specific search query in accordance with the techniques described herein.
Fig. 5 depicts an example method for controlling privacy of shared embedding for searching and indexing media content.
FIG. 6 depicts additional details of the method of FIG. 5, including a method for controlling access to media content of a user-specific search query.
FIG. 7 depicts additional details of the method of FIG. 5, including a method of updating a user-specific data set based on additional data.
FIG. 8 depicts additional details of the method of FIG. 5, including a method of updating a user-specific data set based on data removal.
Fig. 9 depicts an example method for controlling privacy of shared embedding for searching and indexing media content.
Fig. 10 illustrates an example computing system that may be implemented as any type of client, server, and/or electronic device as described with reference to fig. 1-9 to implement shared embedded privacy control for searching and indexing media content, or in which techniques for shared embedded privacy control for searching and indexing media content may be implemented.
Detailed Description
SUMMARY
This document describes techniques and systems that implement shared embedded privacy control for searching and indexing media content. Shared embedding of a user, such as face embedding, may allow another user to detect the user's face in arbitrary data, which may be undesirable. For example, the leaked embedding may allow anyone using it to detect a user's face in a public video stream. The technology described in this document provides a software-based solution to control search access to particular users described in media content. In particular, the techniques allow users to give access to search and indexing features based on embedding user faces into a limited set of white listed users, and then revoke access to one or more of the users.
In aspects, a method of privacy control for face-embedded sharing for searching and indexing media content is described. The method is performed by a service provider system obtaining a set of images of a first user's face and applying a machine learning model to the set of images to generate a user-specific dataset for facial embedding of the first user. The method also includes the service provider system indexing the media content stored in the media storage by applying a machine learning model to the media content to provide indexed information identifying one or more faces shown in the media content. Further, the method comprises: the service provider system controls, through the application programming interface, access of the second user to the indexed information in the media content for the image or video depicting the first user. Access is controlled based on a digital key shared by the first user and the second user. The digital key is associated with a user-specific data set. The user-specific data set may be used with the indexed information to identify an image or video in the media content depicting the first user.
These are just a few examples of how the described techniques and apparatus may be used to implement privacy controls for face-embedded sharing or searching and indexing media content. Other examples and embodiments are also described in this document. This document now turns to an example operating environment, followed by a description of example devices, methods, and systems.
Operating environment
Fig. 1 illustrates an example environment 100 in which techniques implementing privacy control for face-embedded sharing for searching and indexing media content may be implemented. The example environment 100 includes an electronic device 102 (e.g., a user device) configured to communicate with a service provider system 104 via a network 106. The electronic device 102 includes a privacy control module 108, an embedding module 110, one or more digital keys 112, and media content 114.
A user of the electronic device 102 may initiate a search query to the service provider system 104 to search the media store 116 for an image of the user. The electronic device 102 invokes an Application Programming Interface (API)128 at the search manager module 126 to access the indexed media information 118 and search for embedded information that substantially matches the user-specific data set 124 of the user. Based on the matching embedded information, the search manager module 126 may locate a corresponding image in the media store 116 depicting the user. The resulting image is then presented in a display application at the electronic device 102 via the display device 130.
A user of the electronic device 102 may share access to indexed media information 118 corresponding to the user to one or more other users (e.g., family, friends, etc.). This allows other users to query the media store 116 using user-specific queries. In an example, user B initiates a user-specific query at their user device 132 to find an image of user a (the user of the electronic device 102) in the media store 116 of the service provider system 104. However, neither the machine learning model 122 nor the user-specific dataset 124 are shared with user B. Instead, user B has a digital key previously provided by user A that corresponds to user A's user-specific data set 124. User B provides the digital key to search manager module 126. The API128 of the search manager module 126 uses the digital key to identify the user-specific data set 124 for user a. The API128 compares the embedding in the user-specific data set 124 of the user with the indexed media information 118 to identify matching embedding and the index information corresponding to the matching embedding. API128 uses the identified index information to locate a corresponding image or video from media store 116 that depicts user a. The API128 may then return the corresponding image to the user device 132 of user B for display.
In some aspects, user B may wish to query a different image or video corpus using user a's user-specific query. For example, user B may query media storage 136 for the media storage service 134 for user A's images. Alternatively, user B may query a local store (not shown) of user device 132. In either case, user B initiates a query to API128 that includes the digital key shared by user A and an identification of the location of the particular image or video corpus to be searched (e.g., media storage 136 or local storage of user device 132). If these corpuses have not been indexed by the storage service module 120, the API128 applies (or calls the storage service module 120 to apply) the machine learning model 122 to a particular image or video corpus to index the content. The storage service module 120 of the service provider system 104 retains the resulting indexed information in the indexed media information 118. Search manager module 126 can then compare the resulting indexed information to user-specific dataset 124 to identify which images in a particular image or video corpus (e.g., media store 136 or local storage of user device 132) include user a, and provide the results to user device 132 for user B.
In some aspects, the electronic device 102 may include the machine learning model 122, or an instance of the machine learning model 122. The embedding module 110 can apply the machine learning model 122 to a set of images captured and/or stored by the electronic device 102 in the media content 114 to generate a user-specific data set 124 (e.g., an embedded set). In some aspects, the image collection may be an image captured using a near-infrared camera, such as by a facial authentication system (e.g., a facial unlock application) that captures near-infrared image data of a user's face and generates an embedding (n-dimensional numerical value vector) that digitally represents unique facial features of the user without including personally identifiable information. The electronic device 102 may then transmit (e.g., upload) the embedding (e.g., the user-specific data set 124) to the service provider system 104 to store it "in the cloud". In one example, the electronic device 102 or the service provider system 104 may create a three-dimensional (3D) representation of the face to then be used as face-embedded input data.
The privacy control module 108 is configured to generate a digital key 112 for sharing with authorized users. Only authorized users having a shared key (e.g., digital key 112) can call API128 to access indexed media information 118 to identify a particular image or video from an image or video corpus that depicts the user.
Because the user-specific data set 124 is not directly exposed to other users (the only access granted to other users is the indexed content for the search query), the granted access may be revoked. User a of the electronic device 102 may choose to revoke shared access by deleting a digital key previously shared with a particular user (e.g., user B). The next time user B initiates a search for an image or video depicting user a, then no results are provided.
Throughout this disclosure, it is described that a computing system (e.g., electronic device 102, client device, server device, service provider system 104, computer, or other type of computing system) may analyze information (e.g., radar, inertial and facial recognition sensor data, images) associated with a user, such as the facial images just mentioned. However, the computing system may be configured to use the information only after the computing system receives explicit permission to use the data from a user of the computing system. Individual users may have constant control of what the program can or cannot do with the sensor data. For example, before the electronic device 102 shares sensor data with other devices (e.g., trains models executed at other devices), the electronic device 102 may pre-process the sensor data to ensure that any user identification information or device identification information embedded in the data is removed. Thus, the user may control whether information is collected about the user and the user device, and how the information is used by the computing device and/or the remote computing system if the information is collected.
Although the examples described herein are directed to image data depicting a user's face, the techniques described herein may also be implemented on other types of data to generate corresponding embeddings that may be used to search for media content of the data that corresponds to the user. Some exemplary other types of input may include voice data, large whole-body images, fingerprint data, iris scan data, video data, and so forth. The embedding generated from the speech data can be used to find video or audio files of the user who is speaking, or audio segments in these video or audio files. In one example, these techniques may be used to identify when a particular person is speaking during a recorded conference or who is speaking at different times during the conference. The embedding generated from the whole-body image of the user may be used to identify the user based on his gait or how the user moves. These techniques may also be used for face authentication. For example, if a company uses facial authentication and has a user-specific data set for the user, the user may be provided with a digital key to access the API with a facial scan to enter the secure building. In yet another example, using these techniques, the user may not be required to train the new electronic device for the facial unlock application. Instead, the new electronic device may be provided with a digital key, which allows the new electronic device to call an API to access the user-specific data set to authenticate the user for facial unlocking.
In more detail, consider fig. 2, which illustrates an example implementation 200 of an electronic device 102 that may implement privacy control for face-embedded sharing for searching and indexing media content. The electronic device 102 of fig. 2 is shown with various exemplary devices, including a smartphone 102-1, a tablet computer 102-2, a laptop computer 102-3, a desktop computer 102-4, a computing watch 102-5, computing glasses 102-6, a gaming system 102-7, a home automation control system 102-8, and a microwave oven 102-9. The electronic device 102 may also include other devices such as televisions, entertainment systems, audio systems, automobiles, drones, track pads, drawing pads, netbooks, e-readers, home security systems, and other household appliances. Note that the electronic device 102 may be wearable, non-wearable but mobile or relatively stationary (e.g., desktop and appliance).
The electronic device 102 also includes one or more computer processors 202 and one or more computer-readable media 204, including memory media and storage media. An application and/or operating system 206 embodied as computer-readable instructions on computer-readable media 204 may be executed by computer processor 202 to provide some or all of the functionality described herein. For example, the computer-readable media 204 may include the privacy control module 108, the embedding module 110, the media content 114, the machine learning model 122, and the secure storage unit 208. The embedded module 110 may invoke the machine learning model 122. The privacy control module 108 may control (e.g., authorize, revoke) access to the digital key 112 that authorizes user-specific searches in the media store.
The secure storage unit 208 is configured to store secure data (e.g., user credentials) for privacy control, such as control to unlock the electronic device 102 (including facial authentication data, password/password information, fingerprint data, etc.). While the security data may be used to authenticate the user using facial authentication, password/password authentication, fingerprint authentication, voice authentication, etc., to unlock the electronic device 102, the security data may not be able to obtain personal information about the user. In particular, the user cannot be identified by the security data. Rather, the security data is used to simply determine whether data received from a user attempting to unlock the handset matches stored profile data (e.g., the user-specific data set 124) representative of the user setting security on the electronic device 102. In an example, the embedding generated from the captured image of the user's face is a numerical vector representation of the user's facial features. These embeddings are only used to compare with new embeddings generated by images captured during face authentication attempts to locate a match. In other implementations, these embeddings are used to compare with new embeddings generated from an image depicting a user's face captured by a camera of the electronic device 102 or stored in the media content 114 (obtained from another device).
The electronic device 102 may also include a network interface 210. The electronic device 102 may use a network interface 210 for communicating data over a wired, wireless, or optical network. By way of example, and not limitation, network interface 210 may communicate data over a Local Area Network (LAN), a Wireless Local Area Network (WLAN), a Personal Area Network (PAN), a Wide Area Network (WAN), an intranet, the internet, a peer-to-peer network, or a mesh network.
Various embodiments of the authentication system 212 may include a system on a chip (SoC), one or more Integrated Circuits (ICs), a processor with embedded processor instructions or configured to access processor instructions stored in memory, hardware with embedded firmware, a printed circuit board with various hardware components, or any combination thereof. In an example, the authentication system 212 may compare authentication data received from the user with the security data stored in the secure storage unit 208 in the secure mode to authenticate the user to unlock the electronic device 102. In some aspects, the authentication system 212 generates authentication data using image data obtained from the camera system and provides the authentication data to the secure storage unit 208 to enable the secure storage unit 208 to compare the authentication data to stored security data and determine if there is a match.
The electronic device 102 also includes a camera system 214 implemented to capture image data. The image data may be used to generate a three-dimensional depth map of an object, such as a user's face. Any suitable camera system may be used, including color cameras (e.g., red, green, blue (RGB) cameras or Near Infrared (NIR) cameras). The camera system 214 may be integrated in the electronic device 102 or otherwise associated with the electronic device 102. In aspects, the camera system 214 may be wirelessly connected with the electronic device 102.
The electronic device 102 may also include one or more sensors 216. The one or more sensors 216 may include any of a variety of sensors such as an audio sensor (e.g., a microphone), a touch input sensor (e.g., a touch screen), an image capture device (e.g., a camera or a video camera), a proximity sensor (e.g., a capacitive sensor), or an ambient light sensor (e.g., a photodetector).
The electronic device 102 may also include a display device 130. The display device 130 may include any suitable display device, such as a touch screen, a Liquid Crystal Display (LCD), a Thin Film Transistor (TFT) LCD, an in-plane switching (IPS) LCD, a capacitive touch screen display, an Organic Light Emitting Diode (OLED) display, an Active Matrix Organic Light Emitting Diode (AMOLED) display, a super AMOLED display, or the like.
The electronic device 102 may also include a face detector 218. The face detector 218 may detect a face boundary for each of one or more faces in the image. By detecting face boundaries, the face detector 218 limits the amount of image data processed by the embedding module 110. In an embodiment, the face detector 218 may be implemented as computer readable instructions on the computer readable medium 204 and executed by the computer processor 202 to detect face boundaries of individual faces in an image.
These and other capabilities and configurations, as well as the manner in which the entities of fig. 1 and 2 act and interact, are set forth in greater detail below. These entities may be further divided, combined, and the like. The environment 100 of fig. 1, the embodiments 200, 300, and 400 of fig. 2-4, and the detailed methods of fig. 5-9 illustrate some of the many possible environments and devices in which the techniques can be employed.
Fig. 3 illustrates an example implementation 300 of shared embedded privacy control for searching and indexing media content. Fig. 3 illustrates a service provider system 104 and a plurality of electronic devices 102, such as device a 302, device B304, and device C306. In the example shown, each of the devices corresponds to a different user, e.g., device a 302 corresponds to user a 308, device B corresponds to user B310, and device C corresponds to user C312.
Each of the devices may be implemented with an instance of the privacy control module 108 to control access to an image or video search of a corresponding user. In this exemplary embodiment 300, user A308 of device A302 has selected to store a user-specific data set 124 (e.g., data set A314) at the service provider system 104. Data set a 314 is generated based on the machine learning model 122 applied to the image collection of user a 308, or provided by device a 302, or stored in the media store 116 of the service provider system 104, or both.
The service provider system 104 provides online storage of personalized collections of media for users. These personalized media collections may be account-based and securely encrypted in media storage 116. Each user may have one or more personalized collections of media, such as images and videos organized in different folders or subfolders. Because the personalized media collection is account-based, the user may log into his or her account using any suitable electronic device and upload images and/or videos to create the personalized media collection. To simplify the illustrated example, each user is shown with one electronic device and one collection of personalized media. For example, the media store 116 includes media collection A318 uploaded by user A308, media collection B320 uploaded by user B310, and media collection C322 uploaded by user C312.
In order to share access to a user-specific data set 124 used to search for media content describing the user, the corresponding privacy control module 108 may provide the corresponding digital key 112. A new key is created for each user with whom access is shared (e.g., 10 different keys are generated for 10 users, respectively). To revoke access by a particular user, the privacy control module 108 deletes its corresponding key. In the example shown, device a 302 and/or service provider system 104 store a set of digital keys 112 (e.g., owned keys 324, including keys a1, a2, …, An) for user a 308. Further, the set of digital keys 112 (e.g., the owned key 326, which includes keys B1, B2, …, Bn) is stored by device B304 and service provider system 104. In some implementations, only the service provider system 104 stores each user's digital key 112 and management of the digital key 112 is account-based, such that users can log into their accounts at the service provider system 104 to manage shared keys.
As further shown, user A308 has shared a first key A1 (shown by shared key 328) with device B304 and a second key A2 (shown by shared key 330) with device C306. Similarly, device B304 shares key B1 with device C306 but does not provide any keys to device a 302. In the example shown, device C306 does not possess any keys because user C312 has not selected to store the user-specific data set at the service provider system 104, and therefore, no digital key is generated for device C306. Alternatively, the digital key 112 may be stored only "in the cloud," e.g., on the service provider system 104 or other secure online storage associated with the service provider system 104, and not on the user's device. In such embodiments, the user may provide user credentials to log into their account and then initiate a search query through the service provider system 104 based on their account. In this way, the shared digital key 112 is not shared with any user device, and thus can be more securely protected from counterfeiting and copying. In addition, media collections that may be searched for a particular user may be bound to the user's account, thereby protecting other media collections from unauthorized searches.
Assume that user B310 wishes to search the images and/or videos of user a 308 for their personalized media collection B320. User B310 enters a search query into device B304. Device B304 then calls API128 at service provider system 104 and provides an indication of shared key a1 and media collection B320 to API 128. If media collection B320 has not been indexed, the API128 may apply the machine learning model 122 to media collection B320 to generate corresponding indexed information. Service provider system 104 may store the corresponding indexed information in indexed media information 118 separately from other indexed information corresponding to other media collections. Separately storing indexed information for different users may provide an additional level of security to prevent unauthorized access (e.g., a granted access to indexed information for a first user gains unauthorized access to indexed information for a second user).
The API128 accesses user A's 308 data set A314 using the shared key A1 and compares the embedding in data set A314 with the indexed media information 118 corresponding to media collection B320. If the API locates a matching embedding in the indexed media information 118 corresponding to media collection B320, the API128 identifies corresponding images and/or videos in media collection B320 and returns those images and/or videos to device B304 as a result of the search query. As a result, it is not possible to identify which face or person in the image and/or video is user a 308. Without such identifying information, user B310 cannot construct a copy of data set A314. The result is only indicative of an image and/or video depicting user a 308.
In some implementations, the service provider system 104 may use the results of the search query of user B310 to update the data set a 314 of user a 308 even though user a 308 may not have access to the media collection B320 of user B310. The larger the user-specific data set 124, the more accurate the results of the user-specific search query may be.
Because the shared keys 330A2 and B1 have been shared with device C306, user C312 may initiate a search query for images with one or both of user A308 and user B310. Assume that user C312 initiates a search query for an image of user a 308 or user B310. The privacy control module 108 provides both keys A2 and B1 to the API128, and the API128 identifies the corresponding data sets (e.g., data set A314 and data set B316). The API128 compares these data sets with the indexed media information 118 corresponding to media collection C322 of user C312. Based on the matching embedding, the service provider system 104 returns search results identifying images from the media collection C322 that show one or both of user a 308 and user B310.
Note that user B310 does not share a digital key (e.g., one of the owned keys 326) with user a 308. Thus, user A308 is not permitted to use data set B316 for a search query. More specifically, if user a 308 initiates a search query 310 for images of user B310 in media collection a 318, service provider system 104 does not return any results. Because device a 302 does not provide the API128 with the appropriate digital key, the API128 is unable to identify which user-specific data set 124 to use for comparison with the indexed media information 118.
Similarly, if user a 308 chooses to revoke access to data set a from user C312, user a 308 may enter a command to cause the privacy control module 108 to delete the previously shared key a2 at the service provider system 104 (and at device a 302). Then, when device C306 performs a subsequent query search for media collection C322 showing images or videos 308 of user a 308 using key a2, service provider system 104 does not return results regardless of whether similar search queries previously provided results. Thus, device C is substantially prevented from performing a user-specific search on the image or video depicting user A308.
Further, in the example shown, user C312 has not selected to store user-specific data set 124 at service provider system 104. Thus, neither device a 302 nor device B304 may obtain results for a search query for images and/or videos of user C312.
Continuing with the example shown in FIG. 3, FIG. 4 depicts example search results for a user-specific search query in accordance with the techniques described herein. In fig. 4, index 400 includes example indexed information (e.g., indexed media information 118) indicating that image a 402 contains user a 308 and user B310, image B contains user B310, and video C404 includes user a 308 in frames X-Y and user B310 in frames Q-Z.
User C312 of device C306 enters a search query in the search bar 406 "with user A's images and/or videos". Device C306 transmits the search query to API128 along with an appropriate shared key (e.g., key a2 shown in shared key 330 in fig. 3). The API128 uses the shared key a2 to identify the corresponding user-specific data set 124 (e.g., data set a 314) for comparison to the index 400. Based on this comparison, the API128 returns search results 408 that include image A402 and video C404.
In another example, user A308 of device A302 enters a search query of "video with user B" in search bar 410. Here, no results are provided in the search pane 412 because device a 302 cannot provide a shared key corresponding to user B's 310 data set B316, such as a copy of one of user B's 310 owned keys 326, with the search query.
Example method
Fig. 5-8 depict example methods 500, 600, 700, and 800 for controlling privacy of shared embedding for searching and indexing media content. These methods may be performed by service provider system 104 using search manager module 126 to control access to search an image or video corpus using a user-specific query. FIG. 5 depicts a method of indexing media content based on a user-specific data set. Fig. 6 depicts additional details of method 500 in fig. 5, including a method 600 for controlling access to media content for a user-specific search query. FIG. 7 depicts additional details of method 500 in FIG. 5, including a method 700 of updating a user-specific data set based on additional data. FIG. 8 depicts additional details of method 500 in FIG. 5, including a method 800 of updating a user-specific data set based on data removal.
At 502, the service provider system obtains a set of images of the first user's face. For example, the service provider system 104 may obtain a set of images from the electronic device 102.
At 504, the service provider system applies a machine learning model to the set of images to generate a face-embedded user-specific dataset for the first user. For example, the service provider system 104 may apply the machine learning model 122 to a collection of images to generate a user-specific data set 124 for a user of the electronic device 102.
At 506, the service provider system indexes the media content stored in the media store by applying a machine learning model to the media content to provide indexed information identifying one or more faces shown in the media content. For example, the service provider system 104 may index the media stores 116 stored in the service provider system 104 by applying the user-specific data sets 124 to the media content in the media stores 116 and identifying images or videos depicting the users of the electronic devices 102, which provides the indexed media information 118.
At 508, the service provider system controls access to the indexed information in the media content by the second user with respect to the image or video depicting the first user. For example, service provider system 104 may implement search manager module 126 for controlling access to indexed media information 118. The search manager module includes an API128 that acts as an intermediary between the user devices (e.g., electronic device 102, user device 132) and the secure data stored in the service provider system 104. If the second user provides the authorized digital key, the API128 accesses the indexed media information 118 and uses the user-specific data set 124 corresponding to the digital key to identify matching inlays in the indexed media information 118 that indicate the particular image or video depicting the first user in the media store 116. The method 500 may optionally proceed to any of the methods 600, 700, or 800 described with reference to fig. 6-8, respectively.
Fig. 6 depicts additional details of the method 500 depicted in fig. 5, including a method 600 of controlling access to media content for a user-specific search query. At 602, a service provider system receives a search query from media content depicting an image or video of a first user. For example, the service provider system 104 receives a search query from the requesting user device 132 for an image or video depicting a first user of the electronic device 102. The search query includes a digital key previously shared by the first user of the electronic device 102 and the second user of the requesting user device 132. The search query also includes an indication of a particular media store (e.g., a personalized collection of media in media store 116, media store 136 at media storage service 134, local storage at user device 132).
At 604, the service provider system determines whether the search query has an authorized digital key by using a search manager module having an Application Programming Interface (API). For example, the API128 determines whether the digital key provided by the search query matches one of the digital keys 112 associated with the first user.
If the API determines that the digital key is not authorized ("NO" of 604), then the service provider system does not return any results to the search query at 606. For example, digital key 112 may have been deleted based on input from a first user, which results in digital key 112 no longer being authorized for searching. In some cases, the search query may not include the digital key.
If the API determines that the digital key is authorized ("YES" of 604), then at 608, the API identifies a user-specific data set based on the digital key. For example, the API128 uses the digital key 112 to locate the first user's user-specific data set 124, which provides an indication of which face to search in the media store 116.
At 610, the API accesses the indexed information to identify which images or videos from the media content depict the first user based on the user-specific data set. For example, API128 compares to indexed media information 118 using facial embedding in user-specific data set 124. Indexed media information 118 includes an embedding associated with a face in media store 116. Accordingly, the embedding in the indexed media information 118 that matches the facial embedding in the user-specific data set 124 directs the API128 to an image or video in the media store that depicts the first user.
At 612, the service provider system provides search results including an identified image or video from the media content depicting the first user. For example, the service provider system 104 transmits the identified image or video depicting the first user as search results for the search query to the requesting user device 132.
FIG. 7 depicts additional details of method 500 in FIG. 5, including a method 700 of updating a user-specific data set based on additional data. At 702, the service provider system receives one or more additional images from an electronic device of a first user. For example, the electronic device 102 may upload one or more new images depicting the user's face, such as a close-up photograph or a full-body photograph.
At 704, the service provider system applies the machine learning model to the one or more additional images to generate one or more new facial inlays. At 706, the service provider system adds one or more new face embeddings to the user-specific dataset for face embedding by the first user to update the user-specific dataset. Additional embedding may improve the user-specific data set to achieve more accurate results (e.g., more accurate identification of the user in an image or video) than less embedding. Method 700 then returns to 508 in fig. 5 to control access to the indexed information.
FIG. 8 depicts additional details of method 500 in FIG. 5, including a method 800 of updating a user-specific data set based on data removal. At 802, the service provider system receives input from a first user to delete one or more images from a collection of images previously used to generate a user-specific dataset. For example, the first user may choose to remove or delete one or more images used to generate the user-specific data set 124. The user may not like a particular image or the image may be an old image that is no longer a good representation of the user's current facial features.
At 804, the service provider system deletes one or more images from the set of images based on input from the first user to provide a subset of images. For example, the storage service module 120 of the service provider system 104 deletes images selected by the user for removal.
At 806, the service provider system updates the user-specific dataset for facial embedding of the first user by applying the machine learning model to the subset of images to provide an updated user-specific dataset. To update the user-specific data set 124 when the image set is reduced, the storage service module 120 may recreate the user-specific data set 124. Alternatively, the storage service module 120 may delete the embedding corresponding to the deleted image from the user-specific data set 124. For multiple deleted images, multiple corresponding embeddings may be deleted from the user-specific data set 124. Method 700 then returns to 508 in FIG. 5 to control access to the indexed information. In at least some aspects, methods 700 and 800 can be combined such that the user-specific dataset can be updated based on the addition and removal of images used to generate the user-specific dataset.
Fig. 9 depicts an example method 900 for controlling privacy of shared embedding for searched and indexed media content. The method 900 may be performed by an electronic device 102, the electronic device 102 using a privacy control module 108 to control access by searching an image or video corpus using a user-specific query.
At 902, the electronic device captures a set of images of a first user of the electronic device. For example, a first user of the electronic device 102 may capture an image (e.g., "self-portrait") using the camera system 214. The image may be captured using a color camera of the camera system 214. Alternatively, the near-infrared camera of camera system 214 may be used to capture images, such as during facial authentication by authentication system 212.
According to one option at 904, the electronic device transmits the set of images to a service provider system for cloud storage and generation of a user-specific data set for facial embedding of the first user. For example, the electronic device 102 uploads the collection of images to the service provider system 104 for secure storage in the media storage 116.
As an alternative to transmitting the set of images to the service provider system at 904, the electronic device can optionally apply a machine learning model to the set of images to generate a user-specific dataset for facial embedding of the first user at 906. For example, the electronic device 102 can apply the machine learning model 122 stored at the electronic device 102 to the set of images. The machine learning model 122 may be part of a face authentication system (e.g., authentication system 212) for creating a face embedding from a captured user image to authenticate the user for the registered embedding to unlock the electronic device 102. The machine learning model 122 may generate a face-embedded user-specific dataset 124 based on the set of images.
At 908, the electronic device transmits the user-specific data set to the service provider system for cloud storage. For example, the electronic device 102 may transmit the user-specific data set 124 to the service provider system 104 instead of the image collection.
At 910, whether proceeding from 904 or 908, the electronic device shares a digital key associated with the user-specific data set with the second user to enable the second user to invoke a user-specific image search at the service provider system for images or videos depicting the first user. The user of the electronic device 102 can share the digital key 112 with a friend to cause the friend to search the media store 116 for images or videos describing the user. Each buddy of a user is provided with a different digital key.
At 912, the electronic device revokes access to the user-specific image search by requesting the service provider system to delete the digital key previously shared with the second user. For example, the user of the electronic device 102 may revoke access previously provided to a friend by deleting a digital key shared with the friend. Thus, the friend is no longer authorized to search using the user-specific dataset 124 of the user to find an image or video depicting the user.
In general, any of the components, modules, methods, and operations described herein may be implemented using software, firmware, hardware (e.g., fixed logic circuitry), manual processing, or any combination thereof. Some operations of the example methods may be described in the general context of executable instructions of local and/or remote computer processing systems that are stored on computer-readable memory, and embodiments may include software applications, programs, functions, and the like. Alternatively or additionally, any of the functions described herein may be performed, at least in part, by one or more hardware logic components such as, but not limited to, Field Programmable Gate Arrays (FPGAs), Application Specific Integrated Circuits (ASICs), Application Specific Standard Products (ASSPs), systems on a chip (socs), Complex Programmable Logic Devices (CPLDs), and the like.
Example computing System
Fig. 10 illustrates various components of an example computing system 1000, which may be implemented as any type of client, server, and/or electronic device, as previously described with reference to fig. 1-9, to implement shared embedded privacy controls for searching and indexing media content.
Computing system 1000 includes communication devices 1002 that enable wired and/or wireless communication of device data 1004 (e.g., radar data, authentication data, reference data, received data, data being received, data scheduled for broadcast, and data packets of the data). The device data 1004 or other device content may include configuration settings of the device, media content stored on the device, and/or information associated with a user of the device (e.g., identity of a person within a radar site or customized air gesture data). The media content stored on the computing system 1000 may include any type of radar, biometric, audio, video, and/or image data. Computing system 1000 includes one or more data inputs 1006 via which any type of data, media content, and/or inputs can be received, such as human utterances, interactions with radar fields, touch inputs, user-selectable inputs or interactions (explicit or implicit), messages, music, television media content, recorded video content, and any other type of audio, video, and/or image data received from any content and/or data source.
Computing system 1000 also includes communication interfaces 1008 that can be implemented as any one or more of a serial and/or parallel interface, a wireless interface, any type of network interface, a modem, and as any other type of communication interface. Communication interfaces 1008 provide a connection and/or communication links between computing system 1000 and a communication network by which other electronic, computing, and communication devices communicate data with computing system 1000.
Computing system 1000 includes one or more processors 1010 (e.g., any of microprocessors, controllers, or other controllers) which may process various computer-executable instructions to control the operation of computing system 1000 and to implement, or may implement techniques for, shared embedded privacy control for searching and indexing media content. Alternatively or in addition, computing system 1000 may be implemented with any one or combination of hardware, firmware, or fixed logic circuitry that is implemented in connection with processing and control circuits which are generally identified at 1012. Although not shown, the computing system 1000 may include a system bus or data transfer system that couples the various components within the device. The system bus can include any one or combination of different bus structures, such as a memory bus or memory controller, a peripheral bus, a universal serial bus, and/or a processor or local bus that utilizes any of a variety of bus architectures.
Computing system 1000 also includes computer-readable media 1014, such as one or more memory devices capable of persistent and/or non-transitory data storage (as opposed to mere signal transmission), examples of which include Random Access Memory (RAM), non-volatile memory (e.g., any one or more of a read-only memory (ROM), flash memory, EPROM, EEPROM, etc.), and a disk storage device. The disk storage device may be implemented as any type of magnetic or optical storage device, such as a hard disk drive, a recordable and/or rewriteable Compact Disc (CD), any type of a Digital Versatile Disc (DVD), and the like. The computing system 1000 may also include a mass storage media device (storage media) 1016.
Computer-readable media 1014 provides data storage mechanisms to store the device data 1004, as well as various device applications 1018 and any other types of information and/or data related to operational aspects of computing system 1000. For example, an operating system 1020 can be maintained as a computer application with the computer-readable media 1014 and executed on processors 1010. The device applications 1018 may include a device manager, such as any form of a control application, software application, signal processing and control module, device-specific native code, abstraction module, air gesture recognition module, and other modules. The device applications 1018 may also include system components, engines, modules, or managers to implement shared embedded privacy controls for searching and indexing media content, such as the storage service module 120 or the search manager module 126. Computing system 1000 may also include or have access to one or more machine learning systems.
Some examples are described below:
example 1. a method of controlling privacy of a shared embedding for searching and indexing media content, the method performed by a service provider system: obtaining a set of images of a first user's face; applying a machine learning model to the set of images to generate a user-specific dataset for facial embedding of the first user; indexing media content stored in a media store by applying the machine learning model to the media content to provide indexed information identifying one or more faces shown in the media content; and controlling, by an application programming interface, access to the indexed information by a second user to query the media content for images or videos depicting the first user, the access being controlled based on a digital key shared by the first user and the second user, the digital key being associated with the user-specific data set usable for comparison with the indexed information to identify images or videos in the media content depicting the first user.
Example 2. the method of example 1, wherein the user-specific data set is securely encrypted and inaccessible to the second user.
Example 3. the method of any preceding example, wherein the set of images comprises a plurality of color images.
Example 4. the method of any preceding example, further comprising: receiving a search query from the media content depicting an image or video of the first user, the search query including a digital key associated with the user-specific dataset; accessing, by the application programming interface, the indexed information using the digital key to identify which images or videos from the media content depict the first user; and providing search results including the identified image or video from the media content depicting the first user.
Example 5. the method of example 4, further comprising: identifying the user-specific data set based on the digital key; and searching the indexed information for one or more embeddings that match one or more facial embeddings in the user-specific dataset.
Example 6. the method of examples 4 or 5, wherein the identified video includes one or more frames of the identified video depicting the first user's face.
The method of any preceding example, wherein the media storage is owned by a third party entity.
The method of any preceding example, further comprising: receiving one or more additional images from the first user's electronic device; updating the user-specific data set for facial embedding of the first user by: applying the machine learning model to the one or more additional images to generate one or more new facial embeddings; and adding the one or more new embeddings to a user-specific dataset for facial embedding of the first user.
Example 9. the method of any preceding example, further comprising: deleting one or more images from the set of images previously used to generate the user-specific dataset based on user input from the first user, the deletion providing a subset of images; and updating the user-specific dataset for facial embedding by the first user by applying the machine learning model to the subset of images to generate an updated user-specific dataset.
Example 10. the method of any preceding example, further comprising: a face boundary is detected for each face in the set of images using a face detector.
Example 11. the method of any preceding example, further comprising: maintaining a set of digital keys that the first user shares with other users, each digital key in the set of digital keys being shared with a different user.
The method of any preceding example, wherein the media content comprises a media collection associated with the second user; the method further comprises the following steps: searching the media collection associated with the second user for an image or video depicting the first user.
The method of any preceding example, further comprising: receiving a user selection to delete a digital key shared by the first user with the second user; receiving a subsequent search query from the electronic device of the second user, the subsequent search query including a digital key shared by the first user; and based on determining that the digital key is not included in the set of digital keys associated with the user-specific dataset for the first user, not returning any results to the search query.
The method of any preceding example, further comprising: receiving a second search query from a third user that depicts an image or video of the first user from the media content, the second search query not including a digital key associated with the user-specific dataset; and not returning any results to the second search query.
Example 15. a service provider system, comprising: a media storage; a storage service module for managing data stored in the media store; a machine learning model to generate a user-specific dataset for facial embedding of a particular user; and; and a processor and memory for implementing the method of any preceding example.
Conclusion
Although embodiments and apparatus for implementing techniques for shared embedded privacy control for searching and indexing media content have been described in language specific to features and/or methods, it is to be understood that the subject of the appended claims is not necessarily limited to the specific features or methods described. Rather, the specific features and methods are disclosed as example implementations of shared embedded privacy controls for searching and indexing media content.
Claims (15)
1. A method of controlling privacy of a shared embedding for searching and indexing media content, the method performed by a service provider system:
obtaining a set of images of a first user's face;
applying a machine learning model to the set of images to generate a user-specific dataset for facial embedding of the first user;
indexing media content stored in a media storage by applying the machine learning model to the media content to provide indexed information identifying one or more faces shown in the media content; and
controlling, by an application programming interface, access to the indexed information of the media content by a second user to query an image or video depicting the first user for the media content, the access being controlled based on a digital key shared by the first user and the second user, the digital key being associated with the user-specific data set that is usable to compare with the indexed information to identify the image or video in the media content depicting the first user.
2. The method of claim 1, wherein the user-specific data set is securely encrypted and inaccessible to the second user.
3. The method of any preceding claim, wherein the set of images comprises a plurality of color images.
4. The method of any preceding claim, further comprising:
receiving a search query from the media content depicting an image or video of the first user, the search query including a digital key associated with the user-specific dataset;
accessing, by the application programming interface, the indexed information using the digital key to identify which images or videos from the media content depict the first user; and
providing search results including the identified image or video from the media content depicting the first user.
5. The method of claim 4, further comprising:
identifying the user-specific data set based on the digital key; and
searching the indexed information for one or more embeddings that match one or more facial embeddings in the user-specific dataset.
6. The method of claim 4 or 5, wherein the identified video comprises one or more frames of the identified video depicting the first user's face.
7. The method of any preceding claim, wherein the media store is owned by a third party entity.
8. The method of any preceding claim, further comprising:
receiving one or more additional images from the first user's electronic device; and
updating the user-specific data set for facial embedding of the first user by:
applying the machine learning model to the one or more additional images to generate one or more new facial embeddings; and
adding the one or more new embeddings to the user-specific dataset for facial embedding of the first user.
9. The method of any preceding claim, further comprising:
deleting one or more images from the set of images previously used to generate the user-specific dataset based on user input from the first user, the deletion providing a subset of images; and
updating the user-specific dataset for facial embedding of the first user by applying the machine learning model to the subset of images to generate an updated user-specific dataset.
10. The method of any preceding claim, further comprising: a face boundary is detected for each face in the set of images using a face detector.
11. The method of any preceding claim, further comprising: maintaining a set of digital keys shared by the first user with other users, each digital key in the set of digital keys being shared with a different user.
12. The method of claim 1, wherein:
the media content comprises a media collection associated with the second user; and
the method further comprises the following steps: searching the media collection associated with the second user for an image or video depicting the first user.
13. The method of any preceding claim, further comprising:
receiving a user selection to delete a digital key shared by the first user with the second user;
receiving a subsequent search query from the electronic device of the second user, the subsequent search query including a digital key shared by the first user; and
based on determining that the digital key is not included in the set of digital keys associated with the user-specific dataset for the first user, not returning any results to the search query.
14. The method of any preceding claim, further comprising:
receiving a second search query from a third user from the media content depicting an image or video of the first user, the second search query not including a digital key associated with the user-specific dataset; and
not returning any results to the second search query.
15. A service provider system comprising:
media storage;
a storage services module to manage data stored in the media store;
a machine learning model to generate a user-specific dataset for facial embedding of a specific user; and
a processor and memory for implementing the method of any preceding claim.
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/US2020/012352 WO2021141568A1 (en) | 2020-01-06 | 2020-01-06 | Privacy controls for sharing embeddings for searching and indexing media content |
Publications (1)
Publication Number | Publication Date |
---|---|
CN114930324A true CN114930324A (en) | 2022-08-19 |
Family
ID=69400664
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202080092016.3A Pending CN114930324A (en) | 2020-01-06 | 2020-01-06 | Shared embedded privacy control for searching and indexing media content |
Country Status (6)
Country | Link |
---|---|
US (1) | US20210209248A1 (en) |
EP (1) | EP4055504A1 (en) |
JP (1) | JP7448664B2 (en) |
KR (1) | KR20220108153A (en) |
CN (1) | CN114930324A (en) |
WO (1) | WO2021141568A1 (en) |
Families Citing this family (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20220311764A1 (en) * | 2021-03-24 | 2022-09-29 | Daniel Oke | Device for and method of automatically disabling access to a meeting via computer |
Family Cites Families (18)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20170286433A1 (en) * | 2005-10-26 | 2017-10-05 | Cortica, Ltd. | System and method for sharing images |
US8208764B2 (en) * | 2006-01-21 | 2012-06-26 | Elizabeth Guckenberger | Photo automatic linking system and method for accessing, linking, and visualizing “key-face” and/or multiple similar facial images along with associated electronic data via a facial image recognition search engine |
US20080127331A1 (en) * | 2006-09-26 | 2008-05-29 | Glenn Robert Seidman | Method, system, and apparatus for linked personas authenticator |
US20090037419A1 (en) * | 2007-08-03 | 2009-02-05 | Johannes Huber | Website exchange of personal information keyed to easily remembered non-alphanumeric symbols |
CN104866553A (en) * | 2007-12-31 | 2015-08-26 | 应用识别公司 | Method, system, and computer program for identification and sharing of digital images with face signatures |
JP2011516966A (en) | 2008-04-02 | 2011-05-26 | グーグル インコーポレイテッド | Method and apparatus for incorporating automatic face recognition in a digital image collection |
US9015139B2 (en) * | 2010-05-14 | 2015-04-21 | Rovi Guides, Inc. | Systems and methods for performing a search based on a media content snapshot image |
US8311337B2 (en) | 2010-06-15 | 2012-11-13 | Cyberlink Corp. | Systems and methods for organizing and accessing feature vectors in digital images |
US9244923B2 (en) | 2012-08-03 | 2016-01-26 | Fuji Xerox Co., Ltd. | Hypervideo browsing using links generated based on user-specified content features |
US10027727B1 (en) * | 2012-11-21 | 2018-07-17 | Ozog Media, LLC | Facial recognition device, apparatus, and method |
US9531833B2 (en) | 2012-11-28 | 2016-12-27 | Qualcomm Incorporated | System and method for use of network services in receiving content and data |
JP6570840B2 (en) | 2015-01-29 | 2019-09-04 | Ｄｙｎａｂｏｏｋ株式会社 | Electronic apparatus and method |
US11222227B2 (en) * | 2017-01-25 | 2022-01-11 | Chaim Mintz | Photo subscription system and method using biometric identification |
EP3568787B1 (en) * | 2017-05-17 | 2024-04-10 | Google LLC | Automatic image sharing with designated users over a communication network |
US10628662B2 (en) | 2018-04-05 | 2020-04-21 | International Business Machines Corporation | Automated and unsupervised curation of image datasets |
US10990246B1 (en) * | 2018-10-31 | 2021-04-27 | Amazon Technologies, Inc. | Techniques for generating digital content |
CN112041847A (en) * | 2018-12-07 | 2020-12-04 | 微软技术许可有限责任公司 | Providing images with privacy tags |
US11636438B1 (en) * | 2019-10-18 | 2023-04-25 | Meta Platforms Technologies, Llc | Generating smart reminders by assistant systems |
-
2020
- 2020-01-06 WO PCT/US2020/012352 patent/WO2021141568A1/en unknown
- 2020-01-06 JP JP2022541677A patent/JP7448664B2/en active Active
- 2020-01-06 KR KR1020227023062A patent/KR20220108153A/en not_active Application Discontinuation
- 2020-01-06 EP EP20702960.4A patent/EP4055504A1/en active Pending
- 2020-01-06 CN CN202080092016.3A patent/CN114930324A/en active Pending
-
2021
- 2021-01-06 US US17/142,974 patent/US20210209248A1/en active Pending
Also Published As
Publication number | Publication date |
---|---|
JP7448664B2 (en) | 2024-03-12 |
WO2021141568A1 (en) | 2021-07-15 |
KR20220108153A (en) | 2022-08-02 |
JP2022553453A (en) | 2022-12-22 |
EP4055504A1 (en) | 2022-09-14 |
US20210209248A1 (en) | 2021-07-08 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
KR101756844B1 (en) | Computing system and apparatus for privacy-aware sharing management and method of operation thereof | |
US11336968B2 (en) | Method and device for generating content | |
US20240121322A1 (en) | Methods and systems for providing a visual content gallery within a controlled environment | |
US10984410B2 (en) | Entity-sovereign data wallets using distributed ledger technology | |
WO2017143879A1 (en) | File permission management method and device | |
US20130205382A1 (en) | Resource Access Based on Multiple Credentials | |
US20090328205A1 (en) | User established group-based security for user created restful resources | |
CN105659250B (en) | World driven access control | |
US20220100831A1 (en) | Face Authentication Embedding Migration and Drift-Compensation | |
US20100214062A1 (en) | Verification apparatus and authentication apparatus | |
CN106055941A (en) | Terminal method and apparatus | |
JP7448664B2 (en) | Privacy controls for sharing embeds to search and index media content | |
US11363027B2 (en) | Media data based user profiles | |
JP7007032B2 (en) | Information processing equipment, information processing methods and information processing programs | |
US11582037B2 (en) | Apparatus and methods for secure distributed communications and data access | |
US10432418B1 (en) | Integrating cognitive technology with social networks to identify and authenticate users in smart device systems | |
WO2021048377A1 (en) | Resource access control | |
US20220114243A1 (en) | Data control using digital fingerprints | |
KR20200132999A (en) | Single device multiple authentication system | |
KR20200020575A (en) | Method for generating content and device therefor | |
GB2587191A (en) | Resource access control |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |