US20180302680A1 - On-Demand Video Surfing - Google Patents
On-Demand Video Surfing Download PDFInfo
- Publication number
- US20180302680A1 US20180302680A1 US15/381,997 US201615381997A US2018302680A1 US 20180302680 A1 US20180302680 A1 US 20180302680A1 US 201615381997 A US201615381997 A US 201615381997A US 2018302680 A1 US2018302680 A1 US 2018302680A1
- Authority
- US
- United States
- Prior art keywords
- video
- scene
- videos
- rendering device
- content stream
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Abandoned
Links
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/47—End-user applications
- H04N21/472—End-user interface for requesting content, additional data or services; End-user interface for interacting with content, e.g. for content reservation or setting reminders, for requesting event notification, for manipulating displayed content
- H04N21/47202—End-user interface for requesting content, additional data or services; End-user interface for interacting with content, e.g. for content reservation or setting reminders, for requesting event notification, for manipulating displayed content for requesting content on demand, e.g. video on demand
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/70—Information retrieval; Database structures therefor; File system structures therefor of video data
- G06F16/78—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
- G06F16/783—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using metadata automatically derived from the content
-
- G06F17/30784—
-
- H04L65/4084—
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L65/00—Network arrangements, protocols or services for supporting real-time applications in data packet communication
- H04L65/60—Network streaming of media packets
- H04L65/61—Network streaming of media packets for supporting one-way streaming services, e.g. Internet radio
- H04L65/612—Network streaming of media packets for supporting one-way streaming services, e.g. Internet radio for unicast
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/20—Servers specifically adapted for the distribution of content, e.g. VOD servers; Operations thereof
- H04N21/23—Processing of content or additional data; Elementary server operations; Server middleware
- H04N21/234—Processing of video elementary streams, e.g. splicing of video streams, manipulating MPEG-4 scene graphs
- H04N21/23418—Processing of video elementary streams, e.g. splicing of video streams, manipulating MPEG-4 scene graphs involving operations for analysing video streams, e.g. detecting features or characteristics
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/20—Servers specifically adapted for the distribution of content, e.g. VOD servers; Operations thereof
- H04N21/25—Management operations performed by the server for facilitating the content distribution or administrating data related to end-users or client devices, e.g. end-user or client device authentication, learning user preferences for recommending movies
- H04N21/266—Channel or content management, e.g. generation and management of keys and entitlement messages in a conditional access system, merging a VOD unicast channel into a multicast channel
- H04N21/26603—Channel or content management, e.g. generation and management of keys and entitlement messages in a conditional access system, merging a VOD unicast channel into a multicast channel for automatically generating descriptors from content, e.g. when it is not made available by its provider, using content analysis techniques
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/43—Processing of content or additional data, e.g. demultiplexing additional data from a digital video stream; Elementary client operations, e.g. monitoring of home network or synchronising decoder's clock; Client middleware
- H04N21/439—Processing of audio elementary streams
- H04N21/4394—Processing of audio elementary streams involving operations for analysing the audio stream, e.g. detecting features or characteristics in audio streams
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/43—Processing of content or additional data, e.g. demultiplexing additional data from a digital video stream; Elementary client operations, e.g. monitoring of home network or synchronising decoder's clock; Client middleware
- H04N21/44—Processing of video elementary streams, e.g. splicing a video clip retrieved from local storage with an incoming video stream, rendering scenes according to MPEG-4 scene graphs
- H04N21/44008—Processing of video elementary streams, e.g. splicing a video clip retrieved from local storage with an incoming video stream, rendering scenes according to MPEG-4 scene graphs involving operations for analysing video streams, e.g. detecting features or characteristics in the video stream
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/45—Management operations performed by the client for facilitating the reception of or the interaction with the content or administrating data related to the end-user or to the client device itself, e.g. learning user preferences for recommending movies, resolving scheduling conflicts
- H04N21/4508—Management of client data or end-user data
- H04N21/4532—Management of client data or end-user data involving end-user characteristics, e.g. viewer profile, preferences
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/47—End-user applications
- H04N21/472—End-user interface for requesting content, additional data or services; End-user interface for interacting with content, e.g. for content reservation or setting reminders, for requesting event notification, for manipulating displayed content
- H04N21/47217—End-user interface for requesting content, additional data or services; End-user interface for interacting with content, e.g. for content reservation or setting reminders, for requesting event notification, for manipulating displayed content for controlling playback functions for recorded or on-demand content, e.g. using progress bars, mode or play-point indicators or bookmarks
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/40—Client devices specifically adapted for the reception of or interaction with content, e.g. set-top-box [STB]; Operations thereof
- H04N21/47—End-user applications
- H04N21/482—End-user interface for program selection
- H04N21/4828—End-user interface for program selection for searching program descriptors
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/80—Generation or processing of content or additional data by content creator independently of the distribution process; Content per se
- H04N21/83—Generation or processing of protective or descriptive data associated with content; Content structuring
- H04N21/835—Generation of protective data, e.g. certificates
- H04N21/8352—Generation of protective data, e.g. certificates involving content or source identification data, e.g. Unique Material Identifier [UMID]
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/80—Generation or processing of content or additional data by content creator independently of the distribution process; Content per se
- H04N21/83—Generation or processing of protective or descriptive data associated with content; Content structuring
- H04N21/84—Generation or processing of descriptive data, e.g. content descriptors
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N21/00—Selective content distribution, e.g. interactive television or video on demand [VOD]
- H04N21/80—Generation or processing of content or additional data by content creator independently of the distribution process; Content per se
- H04N21/83—Generation or processing of protective or descriptive data associated with content; Content structuring
- H04N21/845—Structuring of content, e.g. decomposing content into time segments
- H04N21/8456—Structuring of content, e.g. decomposing content into time segments by decomposing the content in the time domain, e.g. in time segments
Definitions
- Channel surfing is the process of quickly scanning through different television channels to find content of interest.
- Channel surfing live television can result in a user stumbling across a “hook” (e.g., a scene of interest) in television content that grabs the user's attention and prompts the user to continue watching.
- a “hook” e.g., a scene of interest
- One problem with channel surfing is that the user may skip a channel currently showing a commercial during a program in which the user may have interest. The user may also skip a channel having content of interest if a show on that channel is currently at a scene that does not grab the user's attention, even though the user may enjoy the overall show.
- VOD video on-demand
- HBO® On-demand Service
- the users are generally required to rely on arbitrary factors, such as cover art, ratings, a description, and other metadata to decide whether to watch a particular movie or show. Because the number of available movies and shows is so great, users are subjected to the paradox of choice, which results in many users spending greater amounts of time browsing than actually watching a show because they are unsure as to what exactly they want to watch.
- FIG. 1 illustrates an example environment in which methodologies for on-demand video surfing can be embodied.
- FIG. 2 illustrates an example implementation of a computing device of FIG. 1 in greater detail in accordance with one or more embodiments.
- FIG. 3 illustrates an example implementation of time-shifting on-demand content in accordance with one or more embodiments.
- FIG. 4 illustrates an example scenario of navigating time-shifted on-demand content in accordance with one or more embodiments.
- FIG. 5 illustrates an example implementation of time-shifting on-demand content in accordance with one or more embodiments.
- FIG. 6 illustrates an example implementation of navigating time-shifted on-demand content in accordance with one or more embodiments.
- FIG. 7 illustrates example methods of navigating media content using methodologies for on-demand video surfing in accordance with one or more embodiments.
- FIG. 8 illustrates example methods for navigating media content using methodologies for on-demand video surfing in accordance with one or more embodiments.
- FIG. 9 illustrates various components of an electronic device that can implement methodologies for on-demand video surfing in accordance with one or more embodiments.
- VOD video on-demand
- the methodologies for on-demand video surfing described herein improve navigation for VOD content by using a search query specifying types of scenes (e.g., hooks), which increases a likelihood of catching the user's attention.
- a server can stream a time-shifted video to the client device beginning at a particular scene, or the server can transmit a mark to the client device indicating a location of the scene in the video to enable the client device to jump directly to the scene when the video is played.
- the user can surf through the videos in a manner similar to channel surfing television channels, but with the client device navigating directly to scenes of the specified type in each video based on the search query.
- This avoids browsing certain moments in the videos that have a low likelihood of catching the user's attention, and allows the user to surf through purposefully chosen moments in the videos.
- these techniques reduce time spent browsing for content of interest or time spent surfing through on-demand content in comparison to conventional techniques.
- These techniques further allow playback of any of the videos to automatically continue through to the end of the video or, based on a user input, restart at a beginning of the video.
- the term “hook” may refer to a scene designed to catch a user's attention.
- an action movie can include scenes with thrilling action, such as explosions or car chases, that grab a user's interest and prompt the user to continue watching. Movie trailers frequently use hooks or portions of hooks that show users a very dramatic or exciting moment in the movie in an attempt to encourage the users to watch a particular movie.
- the hook can be chosen by a service provider or studio, or can be selected based on one or more factors, such as spikes on social media while the video aired, extracted clips uploaded to a content sharing website (e.g., Youtube®), crowd volume in a live sporting event, and so on.
- a hook can include a wide variety of hooks designed to grab the user's attention, and can be selected based on audience interaction or feedback.
- time-shift refers to playing a video at a time other than time zero (e.g., a beginning of the video).
- Time-shifting can be performed in a variety of different ways. Some examples include: streaming a video to a client device beginning at a location that is not at time zero of the video, identifying a mark associated with the video that is usable to skip to a specified location in the video, or identifying a location in the video that is not at time zero and which indicates a beginning of a portion of the video that is transmittable to the client device for playback. Other examples are also contemplated, and are discussed in further detail below. Accordingly, the term “time-shift” can refer to a variety of different ways to cause a video to be initiated for playback at a time other than time zero.
- FIG. 1 illustrates an example environment 100 in which methodologies for on-demand video surfing can be embodied.
- the example environment 100 includes examples of a video-rendering device 102 and a service provider 104 communicatively coupled via a network 106 .
- Functionality represented by the service provider 104 may be performed by a single entity, may be divided across other entities that are communicatively coupled via the network 106 , or any combination thereof.
- the functionality represented by the service provider 104 can be performed by any of a variety of entities, including a cloud-based service, an enterprise hosted server, or any other suitable entity.
- Computing devices that are used to implement the service provider 104 or the video-rendering device 102 may be configured in a variety of ways.
- Computing devices may be configured as a desktop computer, a laptop computer, a mobile device (e.g., assuming a handheld configuration such as a tablet or mobile phone), and so forth.
- a computing device may be representative of a plurality of different devices, such as multiple servers of the service provider 104 utilized by a business to perform operations “over the cloud” as further described in relation to FIG. 8 .
- the service provider 104 is representative of functionality to distribute media content 108 obtained from one or more content providers 110 .
- the service provider 104 is configured to make various resources 112 available over the network 106 to clients, such as the video-rendering device 102 .
- the resources 112 can include program content or VOD content that has been processed by a content controller module 114 ( a ).
- the content controller module 114 ( a ) can authenticate a user to access a user account that is associated with permissions for accessing corresponding resources, such as particular television stations or channels, from a provider. The authentication can be performed using credentials (e.g., user name and password) before access is granted to the user account and corresponding resources 112 .
- resources 112 may be available without authentication or account-based access.
- the resources 112 can include any suitable combination of services and/or content typically made available over a network by one or more providers.
- Some examples of services include, but are not limited to: a content publisher service that distributes content, such as streaming videos and the like, to various computing devices, an advertising server service that provides advertisements to be used in connection with distributed content, and so forth.
- Content may include various combinations of assets, video comprising part of an asset, advertisements, audio, multi-media streams, animations, images, television program content such as television content streams, applications, device applications, and the like.
- the content controller module 114 ( a ) is further configured to manage content requested by the video-rendering device 102 .
- the video-rendering device 102 can receive a search query from a user, and transmit the search query to the service provider 104 to search for a particular genre of movie.
- the content controller module 114 ( a ) represents functionality to perform a search for media content matching search criteria of the search query. Then, results of the search can be communicated to the video-rendering device 102 to enable the user of the video-rendering device 102 to view media content matching the search criteria.
- the content controller module 114 ( a ) is configured to identify specific scenes in the resultant media content, and time-shift the results according to the specific scenes matching the search criteria to enable the computing device to navigate between the videos from specific scene to specific scene.
- the content provider 110 provides the media content 108 that can be processed by the service provider 104 and subsequently distributed to and consumed by end-users of computing devices, such as video-rendering device 102 .
- Media content 108 provided by the content provider 110 can include streaming media via one or more channels, such as one or more programs, on-demand videos, movies, and so on.
- the network 106 is illustrated as the Internet, the network may assume a wide variety of configurations.
- the network 106 may include a wide-area-network (WAN), a local-area-network (LAN), a wireless network, a public telephone network, an intranet, and so on.
- WAN wide-area-network
- LAN local-area-network
- wireless network a public telephone network
- intranet an intranet
- a single network 106 may be representative of multiple networks.
- a variety of different networks 106 can be utilized to implement the techniques described herein.
- the video-rendering device 102 is illustrated as including a communication module 116 , a display module 118 , and a content manager module 114 ( b ).
- the communication module 116 is configured to communicate with the service provider 104 to request particular resources 112 and/or media content 108 .
- the display module 118 is configured to utilize a renderer to display media content via a display device 120 .
- the communication module 116 receives the media content 108 from the service provider 104 , and processes the media content 108 for display.
- the content manager module 114 ( b ) represents an instance of the content manager module 114 ( a ).
- the content manager module 114 ( b ) is configured to manage local media content based on search queries received at the video-rendering device 102 .
- the content management module 114 ( a ) represents functionality to perform a search for local media content that matches search criteria of the search query. Then, results of the search can be presented to the user via the display device 120 of the video-rendering device 102 to enable the user of the video-rendering device 102 to view local media content matching the search criteria.
- the content controller module 114 ( b ) is configured to identify specific scenes in the local media content based on the search query, and time-shift the results according to the specific scenes to enable navigation between the results from specific scene to specific scene.
- FIG. 2 illustrates an example implementation 200 of a client device, such as the video-rendering device 102 of FIG. 1 , in greater detail in accordance with one or more embodiments.
- the video-rendering device 102 is illustrated with various non-limiting example devices: smartphone 102 - 1 , laptop 102 - 2 , television 102 - 3 , desktop 102 - 4 , tablet 102 - 5 , camera 102 - 6 , and smartwatch 102 - 7 .
- the video-rendering device 102 includes processor(s) 202 and computer-readable media 204 , which includes memory media 206 and storage media 208 .
- the computer-readable media 204 also includes the content manager module 114 , which can search for and provide on-demand content that is time-shifted according to specific scenes matching search criteria of a search query.
- the video-rendering device 102 also includes I/O ports 210 and network interfaces 212 .
- I/O ports 210 can include a variety of ports, such as by way of example and not limitation, high-definition multimedia interface (HDMI), digital video interface (DVI), display port, fiber-optic or light-based, audio ports (e.g., analog, optical, or digital), USB ports, serial advanced technology attachment (SATA) ports, peripheral component interconnect (PCI) express based ports or card slots, serial ports, parallel ports, or other legacy ports.
- the video-rendering device 102 may also include the network interface(s) 212 for communicating data over wired, wireless, or optical networks.
- the network interface 212 may communicate data over a local-area-network (LAN), a wireless local-area-network (WLAN), a personal-area-network (PAN), a wide-area-network (WAN), an intranet, the Internet, a peer-to-peer network, point-to-point network, a mesh network, and the like.
- LAN local-area-network
- WLAN wireless local-area-network
- PAN personal-area-network
- WAN wide-area-network
- intranet the Internet
- peer-to-peer network point-to-point network
- mesh network and the like.
- FIG. 3 illustrates an example implementation 300 of time-shifting streaming content in accordance with one or more embodiments.
- “on-demand surfing” is the process of scanning through different VOD content to find videos of interest.
- On-demand video surfing provides functionality, via the video-rendering device 102 , to browse through and preview different videos based on specific hooks in the videos.
- a user may enter a search query to initiate a search for particular hooks or type of hooks (also referred to herein as “scene type”).
- the search query can specify a type of action or event occurring in a scene.
- hooks include explosions, car chases, romantic scenes, first fights, scoring plays in a sporting event, interviews with a particular celebrity, and so on. Accordingly, by entering the search query, the user may determine the type of hook that is to be viewed.
- video image recognition techniques can be used to identify different portions of the videos that correspond to different types of hooks, such as a particular scene with an explosion, a scene including a particular actor, a scene in which a particular actor speaks or is injured, a scene in which a particular team scores a goal, and so forth. Accordingly, any suitable video image recognition technique can be utilized to analyze, identify, and tag different portions of a video as including a specific type of hook.
- a search has been performed to identify multiple on-demand videos each having a scene corresponding to search criteria of a search query.
- One or more identified videos are provided as a content stream.
- a first stream includes video 302
- a second stream includes video 304
- another stream includes video 306
- yet another stream includes video 308 .
- Any number of videos can be provided as content streams. Because the videos are provided as content streams, the user can navigate (vertically in the illustrated example) between the videos.
- Each of the identified videos includes a particular scene (e.g., hook) that matches the search criteria of the search query.
- video 302 includes scene 310 represented by hash marks that identify a beginning and an ending of the scene.
- video 304 includes scene 312
- video 306 includes scene 314 , and so forth.
- the identified scenes 310 , 312 , 314 include a similar type of content but differ in actual content. Further, the identified scenes 310 , 312 , 314 can include different durations of time and can be located at different times in the videos 302 , 304 , 306 , respectively, in comparison to one another.
- scene 314 has a longer relative time duration than scenes 310 , 312
- scene 312 has the shortest relative time duration among the scenes 310 , 312 , 314
- the scene 310 may begin at time 10 : 32 while the scene 312 begins at time 13 : 17 and the scene 314 begins at time 11 : 40 .
- Some scenes may be located near the beginning of a respective video while other scenes are located near the end of the respective video. Accordingly, each scene can be located at any of a variety of locations within the respective video.
- the videos are aligned based on a beginning of each video, such as at alignment point 316 , which is set at time zero for each video. Allowing the user to navigate between the streams at this point would result in navigating to the beginning (e.g., time zero) of each video.
- a beginning of each video such as at alignment point 316 , which is set at time zero for each video. Allowing the user to navigate between the streams at this point would result in navigating to the beginning (e.g., time zero) of each video.
- One problem with this is that the first several minutes of many movies generally includes information related to a production company, titles, logos, opening credits, and so on. None of this information, however, is likely to be a hook, particularly a hook corresponding to the search criteria.
- the content management module 114 is configured to realign the videos in the content streams based on the identified hooks.
- the on-demand content e.g., videos 302 , 304 , 306
- the videos are time-shifted and aligned based on the identified hooks (e.g., scenes 310 , 312 , 314 ).
- the videos include different content, the videos are aligned at alignment point 318 , which is at different times in each video.
- the alignment point 318 allows navigation to particular moments in each video. For example, video 302 is aligned to scene 310 , video 304 is aligned to scene 312 , video 306 is aligned to scene 314 , and so on.
- the identified videos can include video identities (IDs) that are provided to the client device. Then, a user input via the client device can select a video ID to request that a corresponding video begin streaming for display at the client device. Alternatively, the service provider 104 can provide a corresponding video file to the client device based on the selected video ID. In at least one example, a portion of the video file beginning at the scene is sent to the client device for playback. Alternatively, an entire video file can be sent to the client device along with a mark specifying a location (e.g., alignment point 318 ) of the scene in the video file. The client device can then use the mark to jump directly to the scene corresponding to the search criteria.
- IDs video identities
- video 302 is selected to initiate playback. Rather than playing the video 302 at the beginning (e.g., time zero), the video 302 automatically begins playing at scene 310 . If the user desires to browse to a next video, the video-rendering device 102 can navigate (e.g., navigation 320 ) to the next stream and begin playback of the video 304 directly at scene 312 . Accordingly, the techniques described herein for on-demand video surfing allow navigation 320 directly to a hook in each video. Although navigation 320 is illustrated in a single direction, the video-rendering device 102 can also navigate in the reverse direction, jump to a particular video, skip a video, return to a previous video, or any combination thereof. Accordingly, the navigation 320 is not limited to a unidirectional navigation.
- playback of each video is not limited to playback of the identified scene (e.g., hook).
- the playback of the first video automatically continues after the hook is completed.
- the playback of the video 306 automatically continues after reaching the end of the scene 314 to play back a remaining portion of the video subsequent to the scene, as is represented by arrow 322 .
- the video-rendering device 102 can navigate to time zero of the video 306 to view the video 306 from the beginning. Also, at any time during the playback of the video 306 , the user can navigate to the hook in a video of the next stream.
- FIG. 4 illustrates an example scenario of navigating time-shifted on-demand content in accordance with one or more embodiments.
- the search query is for “goals scored in soccer last night”.
- Various soccer videos matching the search query are obtained and time-shifted to allow navigation between the soccer videos at locations corresponding to goals scored in each of those soccer games.
- the computing device initiates playback of video 302 at scene 310 , which includes a goal being scored.
- the scene is presented via the display device 120 of the video-rendering device 102 .
- a user input initiates navigation to video 304 and scene 312 is automatically presented via the display device 120 .
- the scene 312 shows another goal being made in a different soccer game.
- Further navigation occurs and causes scene 314 to be presented, which shows yet another goal being made in yet another soccer game (e.g., video 306 ).
- the user can skip around to any of the different soccer games based on the scenes matching the search query.
- FIG. 5 illustrates an example implementation 500 of time-shifting on-demand content in accordance with one or more embodiments.
- a single video can include multiple scenes matching the search criteria, and the resultant content streams can include a subset of streams corresponding to a same video but relative to different scenes.
- video 502 includes scenes 504 , 506 , and 508 that each match the search criteria.
- the content management module 114 can generate multiple streams corresponding to the video 502 , where an instance of the video 502 in each stream is time-shifted according to a different hook.
- the video 502 is provided in three separate streams based on the three identified scenes 504 , 506 , 508 .
- a first stream is provided that includes an instance of the video 502 time-shifted based on the scene 504
- a second stream is provided that includes an instance of the video 502 time-shifted based on the scene 506
- a third stream is provided that includes an instance of the video 502 time-shifted based on scene 506 .
- This enables navigation between the scenes 504 , 506 , 508 from the same video 502 .
- This further enables playback to continue after any of the scenes 504 , 506 , 508 , rather than automatically navigating to or playing back a next hook.
- navigation to a next hook is responsive to a user navigation input.
- the video 502 can include multiple marks that indicate a respective location of each scene 504 , 506 , 508 . These marks can be provided to the client device to enable the client device to jump to locations associated with one or more of the scenes 504 , 506 , 508 . Thus, the client device can initiate playback of the video 502 at any of the scenes 504 , 506 , 508 , and navigate between the scenes 504 , 506 , 508 in the video 502 . From the user perspective, the client device simply skips to specific scenes in the video 502 that correspond to the search query.
- FIG. 6 illustrates an example implementation of navigating time-shifted on-demand content in greater detail in accordance with one or more embodiments.
- navigation between the videos can occur at any point in time prior to, at, or after the end of the hook.
- playback begins at alignment point 318 corresponding to scene 310 of video 302 .
- time 602 which is prior to completing playback of the scene 310
- the content manager module 114 causes playback of the video 302 to cease, and navigates (e.g., arrow 604 ) to the next stream to cause playback of video 304 to begin at scene 312 .
- the user may become interested in the video 304 based on scene 312 , and allows the playback (e.g., arrow 606 ) of the video 304 to continue past scene 312 .
- the user becomes disinterested in the video 304 and decides to navigate to another video.
- a user input is received at time 608 , and the video-rendering device 102 navigates (e.g., arrow 610 ) to scene 314 of video 306 .
- navigation between the streams can occur at any point in time, and there is no minimum or maximum time required for viewing before navigation is allowed.
- navigation can skip one or more streams, and is not limited to sequential or linear navigation in a list of streams.
- the user becomes interested in video 306 based on scene 314 and allows playback to continue after the scene 314 . Accordingly, playback 612 of the video 306 continues until the end of the video 306 , or until receiving a user input that initiates navigation to yet another stream or otherwise ceases playback 612 of the video 306 .
- users can easily and efficiently navigate directly to specific types of hooks in on-demand videos, based on a user-generated search query.
- At least some of the on-demand videos can be accessible via an on-demand service or local storage. Browsing the hooks of the videos enables the user to more easily decide which video to continue watching than by using conventional techniques, at least because the user can immediately view specific parts of the videos that are most likely to grab his attention.
- FIGS. 7 and 8 are shown as operations performed by one or more entities.
- the orders in which operations of these methods are shown and/or described are not intended to be construed as a limitation, and any number or combination of the described method operations can be combined in any order to implement a method, or an alternate method.
- FIG. 7 illustrates example methods 700 of navigating media content using methodologies for on-demand video surfing in accordance with one or more embodiments.
- a user-generated search query is received.
- the search query is received based on a user input, such as an audio (e.g., voice) input.
- a user input such as an audio (e.g., voice) input.
- the user may say “show me explosions”, “show me puppies”, or “show me interviews with [insert public figure]”, and so on.
- the video-rendering device 102 can recognize the user's voice commands and convert an associated audio signal into the search query.
- the user input can be based on selection of a menu item, icon, or object displayed via a user interface presented on the display device 120 of the video-rendering device 102 or on a display device of a remote controller.
- on-demand content is searched based on search criteria associated with the search query to identify videos having at least one scene corresponding to the search criteria.
- the service provider 104 searches the on-demand content based on the search query.
- Video image recognition techniques can be used to identify and label scenes in the on-demand content.
- metadata associated with the on-demand content can include information identifying different scenes according to different scene type based on events occurring in these scenes.
- the video-rendering device 102 or the service provider 104 can search the metadata and/or the on-demand content to locate videos matching the search criteria.
- video identities (IDs) corresponding to the identified videos, the identified videos, or portions of the identified videos are provided to the video-rendering device.
- the service provider 104 can provide IDs to enable the video-rendering device 102 to select one or more of the videos for playback, such as via a content stream.
- the service provider 104 can also provide an indication (e.g., mark) that specifies a location of the scene in a video that corresponds to the search criteria. A separate indication can be provided for each video identified based on the search. The indication is configured to enable the client device to jump directly to the location of the scene in the video when the video is selected for playback.
- the service provider 104 provides the video IDs to the video-rendering device 102 , which allows the service provider 104 to provide a particular video responsive to a user input selecting a corresponding video ID.
- the video-rendering device is caused to play the video at the scene.
- the service provider 104 can begin streaming the video to the video-rendering device 102 beginning at the scene.
- the service provider 104 can provide the video to the video-rendering device 102 to allow the video-rendering device 102 to skip directly to the scene by using the mark and play the video at the scene.
- a remaining portion of the video that is subsequent to the scene is automatically streamed in response to completion of playback of the scene.
- the service provider 104 can cause the video-rendering device 102 to play the remaining portion of the video without interruption.
- a user of the video-rendering device 102 is not limited to watching only the scene, but can continue watching the video past the end of the scene.
- an additional selection of an additional video ID associated with an additional video is received. For instance, during playback of a first video, a user of the video-rendering device 102 decides to navigate to another video, and thus selects a second video ID via a user interface at the video-rendering device 102 . This selection of the second video ID is received at the service provider 104 for processing.
- the video-rendering device is caused to play the additional video at the scene corresponding to the search criteria in response to the additional selection.
- the service provider 104 can provide a second video to the video-rendering device 102 via a separate content stream from the first video.
- the service provider 104 can provide the second video to the video-rendering device 102 along with a mark that identifies the location of the scene in the second video that matches the search criteria. Providing this information enables the video-rendering device 102 to skip to the scene in the second video when playing the second video.
- FIG. 8 illustrates example methods 800 of navigating media content using methodologies for on-demand video surfing in accordance with one or more embodiments.
- a user-generated search query specifying search criteria is received.
- a client device receives a user input, such as a voice input or selection of a user interface instrumentality presented via a display device of the client device.
- the search query is provided to a server to search on-demand content for videos having a scene corresponding to the search criteria.
- one or more of the videos are received at the client device.
- the videos can be received via a content stream.
- the videos can be time-shifted such that the videos are playable directly at the scene corresponding to the search criteria in each video. For example, if the search query was for explosions, then the videos are aligned to each scene having an explosion. Then, when the user navigates to a particular video, the scene with the explosion is presented, rather than the beginning of the video.
- at least a portion of the videos can be downloaded at the client device to enable the client device to play a portion of a video beginning at the scene.
- a mark associated with a respective video is received that indicates a location of the scene in the respective video. This mark is usable by the client device to jump directly to the specific location of the scene in the video.
- a selected video is played at the scene corresponding to the search criteria in response to a user input selecting the video. For instance, a user can select one of the videos via a user interface of the client device, such as via a list, an icon, an image, or object.
- the client device begins playing the video at the scene by using the mark to jump directly to the location of the scene in the video.
- the client device can receive the selected video as streaming content that begins at the location of the scene.
- a remaining portion of the selected video subsequent to the scene is automatically played in response to playback of the video reaching an end of the scene.
- playback of the video is not limited to the scene only, but the client device can continue playing the video past the end of the scene and through to the end of the video.
- an additional user input is received that selects an additional video. For instance, a user may select a different video ID via the user interface to initiate playback of a different video.
- the selected different video is played at the scene corresponding to the search criteria in response to receiving the additional user input.
- the user can surf through a variety of different on-demand videos at scenes corresponding to the user-generated search query, and can allow any of the videos to continue playing past the end of the scene and through to the end of the video or play a selected video from the beginning.
- These methodologies allow a user to surf through different on-demand videos in an easy and efficient manner Using these techniques, the user can preview purposefully chosen scenes in each video that are likely to grab the user's attention, rather than simply read a description of the video, or view a movie trailer of the video. Furthermore, those purposefully chosen scenes are based on a user-generated search query, which represents the user specifying the type of hook that he is interested in at that moment in time. Additionally, playback of the video is not limited to those particular scenes, but the playback can continue through the end of the video. Moreover, surfing through the on-demand content in this way allows the user to essential assess a production quality of the video based on the viewed scene. Accordingly, these methodologies and techniques provide a variety of functionalities that improve conventional techniques used to navigate on-demand content.
- FIG. 9 illustrates various components of an example electronic device 900 that can be utilized to implement on-demand video surfing as described with reference to any of the previous FIGS. 1-8 .
- the electronic device may be implemented as any one or combination of a fixed or mobile device, in any form of a consumer, computer, portable, user, communication, phone, navigation, gaming, audio, camera, messaging, media playback, and/or other type of electronic device, such as the video-rendering device 102 described with reference to FIGS. 1 and 2 .
- Electronic device 900 includes communication transceivers 902 that enable wired and/or wireless communication of device data 904 , such as received data, transmitted data, or sensor data as described above.
- Example communication transceivers include NFC transceivers, WPAN radios compliant with various IEEE 902.15 (BluetoothTM) standards, WLAN radios compliant with any of the various IEEE 902.11 (WiFiTM) standards, WWAN (3GPP-compliant) radios for cellular telephony, wireless metropolitan area network (WMAN) radios compliant with various IEEE 902.16 (WiMAXTM) standards, and wired local-area-network (LAN) Ethernet transceivers.
- Electronic device 900 may also include one or more data input ports 906 via which any type of data, media content, and/or inputs can be received, such as user-selectable inputs, messages, music, television content, recorded video content, and any other type of audio, video, and/or image data received from any content and/or data source (e.g., other video devices).
- Data input ports 906 may include USB ports, coaxial cable ports, and other serial or parallel connectors (including internal connectors) for flash memory, DVDs, CDs, and the like. These data input ports may be used to couple the electronic device to components (e.g., image sensor 102 ), peripherals, or accessories such as keyboards, microphones, or cameras.
- Electronic device 900 of this example includes processor system 908 (e.g., any of application processors, microprocessors, digital-signal-processors, controllers, and the like), or a processor and memory system (e.g., implemented in a SoC), which process (i.e., execute) computer-executable instructions to control operation of the device.
- Processor system 908 may be implemented as an application processor, embedded controller, microcontroller, and the like.
- a processing system may be implemented at least partially in hardware, which can include components of an integrated circuit or on-chip system, digital-signal processor (DSP), application-specific integrated circuit (ASIC), field-programmable gate array (FPGA), a complex programmable logic device (CPLD), and other implementations in silicon and/or other hardware.
- DSP digital-signal processor
- ASIC application-specific integrated circuit
- FPGA field-programmable gate array
- CPLD complex programmable logic device
- electronic device 900 can be implemented with any one or combination of software, hardware, firmware, or fixed logic circuitry that is implemented in connection with processing and control circuits, which are generally identified at 910 (processing and control 910 ).
- electronic device 900 can include a system bus, crossbar, or data transfer system that couples the various components within the device.
- a system bus can include any one or combination of different bus structures, such as a memory bus or memory controller, a peripheral bus, a universal serial bus, and/or a processor or local bus that utilizes any of a variety of bus architectures.
- Electronic device 900 also includes one or more memory devices 912 that enable data storage, examples of which include random access memory (RAM), non-volatile memory (e.g., read-only memory (ROM), flash memory, EPROM, EEPROM, etc.), and a disk storage device.
- Memory device(s) 912 provide data storage mechanisms to store the device data 904 , other types of information and/or data, and various device applications 920 (e.g., software applications).
- operating system 914 can be maintained as software instructions within memory device 912 and executed by processors (e.g., processor system 908 ).
- content management module 114 is embodied in memory devices 912 of electronic device 900 as executable instructions or code. Although represented as a software implementation, content management module 114 may be implemented as any form of a control application, software application, signal-processing and control module, or hardware or firmware installed on the electronic device 900 .
- Electronic device 900 also includes audio and/or video processing system 916 that processes audio data and/or passes through the audio and video data to audio system 918 and/or to display system 922 (e.g., a screen of a smart phone or camera).
- Audio system 918 and/or display system 922 may include any devices that process, display, and/or otherwise render audio, video, display, and/or image data.
- Display data and audio signals can be communicated to an audio component and/or to a display component via an RF (radio frequency) link, S-video link, HDMI (high-definition multimedia interface), composite video link, component video link, DVI (digital video interface), analog audio connection, or other similar communication link, such as media data port 924 .
- audio system 918 and/or display system 922 are external components to electronic device 900 .
- display system 922 can be an integrated component of the example electronic device, such as part of an integrated touch interface.
Abstract
Description
- Television viewers frequently engage in “channel surfing”, which is the process of quickly scanning through different television channels to find content of interest. Channel surfing live television can result in a user stumbling across a “hook” (e.g., a scene of interest) in television content that grabs the user's attention and prompts the user to continue watching. One problem with channel surfing is that the user may skip a channel currently showing a commercial during a program in which the user may have interest. The user may also skip a channel having content of interest if a show on that channel is currently at a scene that does not grab the user's attention, even though the user may enjoy the overall show.
- In contrast to live television, when users browse video on-demand (VOD) content using an On-demand Service (e.g., Netflix®, Play®, HBO®), the users are generally required to rely on arbitrary factors, such as cover art, ratings, a description, and other metadata to decide whether to watch a particular movie or show. Because the number of available movies and shows is so great, users are subjected to the paradox of choice, which results in many users spending greater amounts of time browsing than actually watching a show because they are unsure as to what exactly they want to watch.
- These problems are time consuming to users, and in many cases can lead to user frustration. To avoid choosing a video that the user may not enjoy, users frequently spend extended amounts of time browsing information about various shows rather than actually watching a show.
- This background description is provided for the purpose of generally presenting the context of the disclosure. Unless otherwise indicated herein, material described in this section is neither expressly nor impliedly admitted to be prior art to the present disclosure or the appended claims.
- Apparatuses of and techniques using methodologies for on-demand video surfing are described with reference to the following drawings. The same numbers are used throughout the drawings to reference like features and components:
-
FIG. 1 illustrates an example environment in which methodologies for on-demand video surfing can be embodied. -
FIG. 2 illustrates an example implementation of a computing device ofFIG. 1 in greater detail in accordance with one or more embodiments. -
FIG. 3 illustrates an example implementation of time-shifting on-demand content in accordance with one or more embodiments. -
FIG. 4 illustrates an example scenario of navigating time-shifted on-demand content in accordance with one or more embodiments. -
FIG. 5 illustrates an example implementation of time-shifting on-demand content in accordance with one or more embodiments. -
FIG. 6 illustrates an example implementation of navigating time-shifted on-demand content in accordance with one or more embodiments. -
FIG. 7 illustrates example methods of navigating media content using methodologies for on-demand video surfing in accordance with one or more embodiments. -
FIG. 8 illustrates example methods for navigating media content using methodologies for on-demand video surfing in accordance with one or more embodiments. -
FIG. 9 illustrates various components of an electronic device that can implement methodologies for on-demand video surfing in accordance with one or more embodiments. - Conventional techniques that allow users to channel surf through video on-demand (VOD) content are inefficient at least because users may only rely on descriptive text that fails to accurately portray content in a video. This form of content browsing to find content of interest is time consuming, and users frequently spend more time browsing the descriptive text than actually viewing content of interest.
- The methodologies for on-demand video surfing described herein improve navigation for VOD content by using a search query specifying types of scenes (e.g., hooks), which increases a likelihood of catching the user's attention. Further, when resultant videos are provided to a client device, the videos are time-shifted according to the hooks. For instance, a server can stream a time-shifted video to the client device beginning at a particular scene, or the server can transmit a mark to the client device indicating a location of the scene in the video to enable the client device to jump directly to the scene when the video is played.
- In this way, the user can surf through the videos in a manner similar to channel surfing television channels, but with the client device navigating directly to scenes of the specified type in each video based on the search query. This avoids browsing certain moments in the videos that have a low likelihood of catching the user's attention, and allows the user to surf through purposefully chosen moments in the videos. Further, these techniques reduce time spent browsing for content of interest or time spent surfing through on-demand content in comparison to conventional techniques. These techniques further allow playback of any of the videos to automatically continue through to the end of the video or, based on a user input, restart at a beginning of the video.
- As used herein, the term “hook” may refer to a scene designed to catch a user's attention. For example, an action movie can include scenes with thrilling action, such as explosions or car chases, that grab a user's interest and prompt the user to continue watching. Movie trailers frequently use hooks or portions of hooks that show users a very dramatic or exciting moment in the movie in an attempt to encourage the users to watch a particular movie. The hook can be chosen by a service provider or studio, or can be selected based on one or more factors, such as spikes on social media while the video aired, extracted clips uploaded to a content sharing website (e.g., Youtube®), crowd volume in a live sporting event, and so on. Accordingly, a hook can include a wide variety of hooks designed to grab the user's attention, and can be selected based on audience interaction or feedback.
- As used herein, the term “time-shift” refers to playing a video at a time other than time zero (e.g., a beginning of the video). Time-shifting can be performed in a variety of different ways. Some examples include: streaming a video to a client device beginning at a location that is not at time zero of the video, identifying a mark associated with the video that is usable to skip to a specified location in the video, or identifying a location in the video that is not at time zero and which indicates a beginning of a portion of the video that is transmittable to the client device for playback. Other examples are also contemplated, and are discussed in further detail below. Accordingly, the term “time-shift” can refer to a variety of different ways to cause a video to be initiated for playback at a time other than time zero.
- The following discussion first describes an operating environment, followed by techniques and procedures that may be employed in this environment. This discussion continues with an example electronic device in which methodologies for on-demand video surfing can be embodied.
-
FIG. 1 illustrates anexample environment 100 in which methodologies for on-demand video surfing can be embodied. Theexample environment 100 includes examples of a video-rendering device 102 and aservice provider 104 communicatively coupled via anetwork 106. Functionality represented by theservice provider 104 may be performed by a single entity, may be divided across other entities that are communicatively coupled via thenetwork 106, or any combination thereof. Thus, the functionality represented by theservice provider 104 can be performed by any of a variety of entities, including a cloud-based service, an enterprise hosted server, or any other suitable entity. - Computing devices that are used to implement the
service provider 104 or the video-rendering device 102 may be configured in a variety of ways. Computing devices, for example, may be configured as a desktop computer, a laptop computer, a mobile device (e.g., assuming a handheld configuration such as a tablet or mobile phone), and so forth. Additionally, a computing device may be representative of a plurality of different devices, such as multiple servers of theservice provider 104 utilized by a business to perform operations “over the cloud” as further described in relation toFIG. 8 . - The
service provider 104 is representative of functionality to distributemedia content 108 obtained from one ormore content providers 110. Generally speaking, theservice provider 104 is configured to makevarious resources 112 available over thenetwork 106 to clients, such as the video-rendering device 102. In the illustrated example, theresources 112 can include program content or VOD content that has been processed by a content controller module 114(a). In some implementations, the content controller module 114(a) can authenticate a user to access a user account that is associated with permissions for accessing corresponding resources, such as particular television stations or channels, from a provider. The authentication can be performed using credentials (e.g., user name and password) before access is granted to the user account and correspondingresources 112.Other resources 112 may be available without authentication or account-based access. Theresources 112 can include any suitable combination of services and/or content typically made available over a network by one or more providers. Some examples of services include, but are not limited to: a content publisher service that distributes content, such as streaming videos and the like, to various computing devices, an advertising server service that provides advertisements to be used in connection with distributed content, and so forth. Content may include various combinations of assets, video comprising part of an asset, advertisements, audio, multi-media streams, animations, images, television program content such as television content streams, applications, device applications, and the like. - The content controller module 114(a) is further configured to manage content requested by the video-
rendering device 102. For instance, the video-rendering device 102 can receive a search query from a user, and transmit the search query to theservice provider 104 to search for a particular genre of movie. The content controller module 114(a) represents functionality to perform a search for media content matching search criteria of the search query. Then, results of the search can be communicated to the video-rendering device 102 to enable the user of the video-rendering device 102 to view media content matching the search criteria. As is discussed in more detail below, the content controller module 114(a) is configured to identify specific scenes in the resultant media content, and time-shift the results according to the specific scenes matching the search criteria to enable the computing device to navigate between the videos from specific scene to specific scene. - The
content provider 110 provides themedia content 108 that can be processed by theservice provider 104 and subsequently distributed to and consumed by end-users of computing devices, such as video-rendering device 102.Media content 108 provided by thecontent provider 110 can include streaming media via one or more channels, such as one or more programs, on-demand videos, movies, and so on. - Although the
network 106 is illustrated as the Internet, the network may assume a wide variety of configurations. For example, thenetwork 106 may include a wide-area-network (WAN), a local-area-network (LAN), a wireless network, a public telephone network, an intranet, and so on. Further, although asingle network 106 is shown, thenetwork 106 may be representative of multiple networks. Thus, a variety ofdifferent networks 106 can be utilized to implement the techniques described herein. - The video-
rendering device 102 is illustrated as including acommunication module 116, adisplay module 118, and a content manager module 114(b). Thecommunication module 116 is configured to communicate with theservice provider 104 to requestparticular resources 112 and/ormedia content 108. Thedisplay module 118 is configured to utilize a renderer to display media content via adisplay device 120. Thecommunication module 116 receives themedia content 108 from theservice provider 104, and processes themedia content 108 for display. - The content manager module 114(b) represents an instance of the content manager module 114(a). The content manager module 114(b) is configured to manage local media content based on search queries received at the video-
rendering device 102. For example, the content management module 114(a) represents functionality to perform a search for local media content that matches search criteria of the search query. Then, results of the search can be presented to the user via thedisplay device 120 of the video-rendering device 102 to enable the user of the video-rendering device 102 to view local media content matching the search criteria. As is discussed in more detail below, the content controller module 114(b) is configured to identify specific scenes in the local media content based on the search query, and time-shift the results according to the specific scenes to enable navigation between the results from specific scene to specific scene. - Having generally described an environment in which methodologies for on-demand video surfing may be implemented, this discussion now turns to
FIG. 2 , which illustrates anexample implementation 200 of a client device, such as the video-rendering device 102 ofFIG. 1 , in greater detail in accordance with one or more embodiments. The video-rendering device 102 is illustrated with various non-limiting example devices: smartphone 102-1, laptop 102-2, television 102-3, desktop 102-4, tablet 102-5, camera 102-6, and smartwatch 102-7. The video-rendering device 102 includes processor(s) 202 and computer-readable media 204, which includesmemory media 206 andstorage media 208. Applications and/or an operating system (not shown) embodied as computer-readable instructions on the computer-readable media 204 can be executed by the processor(s) 202 to provide some or all of the functionalities described herein, as can partially or purely hardware or firmware implementations. The computer-readable media 204 also includes thecontent manager module 114, which can search for and provide on-demand content that is time-shifted according to specific scenes matching search criteria of a search query. - The video-
rendering device 102 also includes I/O ports 210 and network interfaces 212. I/O ports 210 can include a variety of ports, such as by way of example and not limitation, high-definition multimedia interface (HDMI), digital video interface (DVI), display port, fiber-optic or light-based, audio ports (e.g., analog, optical, or digital), USB ports, serial advanced technology attachment (SATA) ports, peripheral component interconnect (PCI) express based ports or card slots, serial ports, parallel ports, or other legacy ports. The video-rendering device 102 may also include the network interface(s) 212 for communicating data over wired, wireless, or optical networks. By way of example and not limitation, thenetwork interface 212 may communicate data over a local-area-network (LAN), a wireless local-area-network (WLAN), a personal-area-network (PAN), a wide-area-network (WAN), an intranet, the Internet, a peer-to-peer network, point-to-point network, a mesh network, and the like. - Having described the video-
rendering device 102 ofFIG. 1 in greater detail, this discussion now turns toFIG. 3 , which illustrates anexample implementation 300 of time-shifting streaming content in accordance with one or more embodiments. Similar to channel surfing, “on-demand surfing” is the process of scanning through different VOD content to find videos of interest. On-demand video surfing provides functionality, via the video-rendering device 102, to browse through and preview different videos based on specific hooks in the videos. In implementations, a user may enter a search query to initiate a search for particular hooks or type of hooks (also referred to herein as “scene type”). For example, the search query can specify a type of action or event occurring in a scene. Some examples of hooks include explosions, car chases, romantic scenes, first fights, scoring plays in a sporting event, interviews with a particular celebrity, and so on. Accordingly, by entering the search query, the user may determine the type of hook that is to be viewed. In implementations, video image recognition techniques can be used to identify different portions of the videos that correspond to different types of hooks, such as a particular scene with an explosion, a scene including a particular actor, a scene in which a particular actor speaks or is injured, a scene in which a particular team scores a goal, and so forth. Accordingly, any suitable video image recognition technique can be utilized to analyze, identify, and tag different portions of a video as including a specific type of hook. - In the
example implementation 300, a search has been performed to identify multiple on-demand videos each having a scene corresponding to search criteria of a search query. One or more identified videos are provided as a content stream. For example, a first stream includesvideo 302, a second stream includesvideo 304, another stream includesvideo 306, and yet another stream includesvideo 308. Any number of videos can be provided as content streams. Because the videos are provided as content streams, the user can navigate (vertically in the illustrated example) between the videos. - Each of the identified videos includes a particular scene (e.g., hook) that matches the search criteria of the search query. For example,
video 302 includesscene 310 represented by hash marks that identify a beginning and an ending of the scene. In addition,video 304 includesscene 312,video 306 includesscene 314, and so forth. The identifiedscenes scenes videos scene 314 has a longer relative time duration thanscenes scene 312 has the shortest relative time duration among thescenes scene 310 may begin at time 10:32 while thescene 312 begins at time 13:17 and thescene 314 begins at time 11:40. Some scenes may be located near the beginning of a respective video while other scenes are located near the end of the respective video. Accordingly, each scene can be located at any of a variety of locations within the respective video. - Initially, the videos are aligned based on a beginning of each video, such as at
alignment point 316, which is set at time zero for each video. Allowing the user to navigate between the streams at this point would result in navigating to the beginning (e.g., time zero) of each video. One problem with this is that the first several minutes of many movies generally includes information related to a production company, titles, logos, opening credits, and so on. None of this information, however, is likely to be a hook, particularly a hook corresponding to the search criteria. - In at least one implementation, the
content management module 114 is configured to realign the videos in the content streams based on the identified hooks. In the illustrated example, the on-demand content (e.g.,videos scenes alignment point 318, which is at different times in each video. Thealignment point 318 allows navigation to particular moments in each video. For example,video 302 is aligned toscene 310,video 304 is aligned toscene 312,video 306 is aligned toscene 314, and so on. - In another example implementation, the identified videos can include video identities (IDs) that are provided to the client device. Then, a user input via the client device can select a video ID to request that a corresponding video begin streaming for display at the client device. Alternatively, the
service provider 104 can provide a corresponding video file to the client device based on the selected video ID. In at least one example, a portion of the video file beginning at the scene is sent to the client device for playback. Alternatively, an entire video file can be sent to the client device along with a mark specifying a location (e.g., alignment point 318) of the scene in the video file. The client device can then use the mark to jump directly to the scene corresponding to the search criteria. - In implementations,
video 302 is selected to initiate playback. Rather than playing thevideo 302 at the beginning (e.g., time zero), thevideo 302 automatically begins playing atscene 310. If the user desires to browse to a next video, the video-rendering device 102 can navigate (e.g., navigation 320) to the next stream and begin playback of thevideo 304 directly atscene 312. Accordingly, the techniques described herein for on-demand video surfing allownavigation 320 directly to a hook in each video. Althoughnavigation 320 is illustrated in a single direction, the video-rendering device 102 can also navigate in the reverse direction, jump to a particular video, skip a video, return to a previous video, or any combination thereof. Accordingly, thenavigation 320 is not limited to a unidirectional navigation. - Further, playback of each video is not limited to playback of the identified scene (e.g., hook). For example, rather than playing the hook in a first video and then automatically jumping to a next video's hook, the playback of the first video automatically continues after the hook is completed. In the illustrated example, assume the user enjoys the
scene 314 of thevideo 306 such that the user desires to continue viewing thevideo 306. In this case, the playback of thevideo 306 automatically continues after reaching the end of thescene 314 to play back a remaining portion of the video subsequent to the scene, as is represented byarrow 322. In addition, subsequent to the playback being initiated and responsive to a user selection of a user interface instrumentality, the video-rendering device 102 can navigate to time zero of thevideo 306 to view thevideo 306 from the beginning. Also, at any time during the playback of thevideo 306, the user can navigate to the hook in a video of the next stream. -
FIG. 4 illustrates an example scenario of navigating time-shifted on-demand content in accordance with one or more embodiments. Assume the search query is for “goals scored in soccer last night”. Various soccer videos matching the search query are obtained and time-shifted to allow navigation between the soccer videos at locations corresponding to goals scored in each of those soccer games. For example, the computing device initiates playback ofvideo 302 atscene 310, which includes a goal being scored. The scene is presented via thedisplay device 120 of the video-rendering device 102. At any point prior to, at, or after the end ofscene 310, a user input initiates navigation tovideo 304 andscene 312 is automatically presented via thedisplay device 120. Thescene 312 shows another goal being made in a different soccer game. Further navigation occurs and causesscene 314 to be presented, which shows yet another goal being made in yet another soccer game (e.g., video 306). The user can skip around to any of the different soccer games based on the scenes matching the search query. -
FIG. 5 illustrates anexample implementation 500 of time-shifting on-demand content in accordance with one or more embodiments. In some instances, a single video can include multiple scenes matching the search criteria, and the resultant content streams can include a subset of streams corresponding to a same video but relative to different scenes. In the illustrated example,video 502 includesscenes - In implementations, the
content management module 114 can generate multiple streams corresponding to thevideo 502, where an instance of thevideo 502 in each stream is time-shifted according to a different hook. In the illustrated example, thevideo 502 is provided in three separate streams based on the three identifiedscenes video 502 time-shifted based on thescene 504, a second stream is provided that includes an instance of thevideo 502 time-shifted based on thescene 506, and a third stream is provided that includes an instance of thevideo 502 time-shifted based onscene 506. This enables navigation between thescenes same video 502. This further enables playback to continue after any of thescenes - In at least one implementation, the
video 502 can include multiple marks that indicate a respective location of eachscene scenes video 502 at any of thescenes scenes video 502. From the user perspective, the client device simply skips to specific scenes in thevideo 502 that correspond to the search query. -
FIG. 6 illustrates an example implementation of navigating time-shifted on-demand content in greater detail in accordance with one or more embodiments. As mentioned above, navigation between the videos can occur at any point in time prior to, at, or after the end of the hook. Continuing with the above example fromFIGS. 3 and 4 , assume playback begins atalignment point 318 corresponding toscene 310 ofvideo 302. Attime 602, which is prior to completing playback of thescene 310, a user input is received to navigate to a next stream. Consequently, thecontent manager module 114 causes playback of thevideo 302 to cease, and navigates (e.g., arrow 604) to the next stream to cause playback ofvideo 304 to begin atscene 312. The user may become interested in thevideo 304 based onscene 312, and allows the playback (e.g., arrow 606) of thevideo 304 to continuepast scene 312. - At some point after
scene 312, the user becomes disinterested in thevideo 304 and decides to navigate to another video. Thus, a user input is received attime 608, and the video-rendering device 102 navigates (e.g., arrow 610) toscene 314 ofvideo 306. Accordingly, navigation between the streams can occur at any point in time, and there is no minimum or maximum time required for viewing before navigation is allowed. Further, as illustrated byarrow 610, navigation can skip one or more streams, and is not limited to sequential or linear navigation in a list of streams. In the illustrated example, the user becomes interested invideo 306 based onscene 314 and allows playback to continue after thescene 314. Accordingly,playback 612 of thevideo 306 continues until the end of thevideo 306, or until receiving a user input that initiates navigation to yet another stream or otherwise ceasesplayback 612 of thevideo 306. - Using the techniques described herein, users can easily and efficiently navigate directly to specific types of hooks in on-demand videos, based on a user-generated search query. At least some of the on-demand videos can be accessible via an on-demand service or local storage. Browsing the hooks of the videos enables the user to more easily decide which video to continue watching than by using conventional techniques, at least because the user can immediately view specific parts of the videos that are most likely to grab his attention.
- The following discussion describes methods by which techniques are implemented to enable use of methodologies for on-demand video surfing. These methods can be implemented utilizing the previously described environment and example systems, devices, and implementations, such as shown in
FIGS. 1-6 . Aspects of these example methods are illustrated inFIGS. 7 and 8 , which are shown as operations performed by one or more entities. The orders in which operations of these methods are shown and/or described are not intended to be construed as a limitation, and any number or combination of the described method operations can be combined in any order to implement a method, or an alternate method. -
FIG. 7 illustratesexample methods 700 of navigating media content using methodologies for on-demand video surfing in accordance with one or more embodiments. At 702, a user-generated search query is received. In implementations, the search query is received based on a user input, such as an audio (e.g., voice) input. For example, the user may say “show me explosions”, “show me puppies”, or “show me interviews with [insert public figure]”, and so on. The video-rendering device 102 can recognize the user's voice commands and convert an associated audio signal into the search query. In at least one implementation, the user input can be based on selection of a menu item, icon, or object displayed via a user interface presented on thedisplay device 120 of the video-rendering device 102 or on a display device of a remote controller. - At 704, on-demand content is searched based on search criteria associated with the search query to identify videos having at least one scene corresponding to the search criteria. For example, the
service provider 104 searches the on-demand content based on the search query. Video image recognition techniques can be used to identify and label scenes in the on-demand content. In implementations, metadata associated with the on-demand content can include information identifying different scenes according to different scene type based on events occurring in these scenes. The video-rendering device 102 or theservice provider 104 can search the metadata and/or the on-demand content to locate videos matching the search criteria. - At 706, video identities (IDs) corresponding to the identified videos, the identified videos, or portions of the identified videos are provided to the video-rendering device. For example, the
service provider 104 can provide IDs to enable the video-rendering device 102 to select one or more of the videos for playback, such as via a content stream. In implementations, theservice provider 104 can also provide an indication (e.g., mark) that specifies a location of the scene in a video that corresponds to the search criteria. A separate indication can be provided for each video identified based on the search. The indication is configured to enable the client device to jump directly to the location of the scene in the video when the video is selected for playback. In at least one implementation, theservice provider 104 provides the video IDs to the video-rendering device 102, which allows theservice provider 104 to provide a particular video responsive to a user input selecting a corresponding video ID. - At 708, responsive to a user input selecting a video ID associated with one of the videos, the video-rendering device is caused to play the video at the scene. In implementations, the
service provider 104 can begin streaming the video to the video-rendering device 102 beginning at the scene. In other implementations, theservice provider 104 can provide the video to the video-rendering device 102 to allow the video-rendering device 102 to skip directly to the scene by using the mark and play the video at the scene. - Optionally at 710, a remaining portion of the video that is subsequent to the scene is automatically streamed in response to completion of playback of the scene. By continuing streaming the video, the
service provider 104 can cause the video-rendering device 102 to play the remaining portion of the video without interruption. In this way, a user of the video-rendering device 102 is not limited to watching only the scene, but can continue watching the video past the end of the scene. - Optionally at 712, an additional selection of an additional video ID associated with an additional video is received. For instance, during playback of a first video, a user of the video-
rendering device 102 decides to navigate to another video, and thus selects a second video ID via a user interface at the video-rendering device 102. This selection of the second video ID is received at theservice provider 104 for processing. - At 714, the video-rendering device is caused to play the additional video at the scene corresponding to the search criteria in response to the additional selection. For instance, the
service provider 104 can provide a second video to the video-rendering device 102 via a separate content stream from the first video. Alternatively, theservice provider 104 can provide the second video to the video-rendering device 102 along with a mark that identifies the location of the scene in the second video that matches the search criteria. Providing this information enables the video-rendering device 102 to skip to the scene in the second video when playing the second video. -
FIG. 8 illustratesexample methods 800 of navigating media content using methodologies for on-demand video surfing in accordance with one or more embodiments. At 802, a user-generated search query specifying search criteria is received. For instance, a client device receives a user input, such as a voice input or selection of a user interface instrumentality presented via a display device of the client device. At 804, the search query is provided to a server to search on-demand content for videos having a scene corresponding to the search criteria. - At 806, one or more of the videos are received at the client device. For instance, the videos can be received via a content stream. In implementations, the videos can be time-shifted such that the videos are playable directly at the scene corresponding to the search criteria in each video. For example, if the search query was for explosions, then the videos are aligned to each scene having an explosion. Then, when the user navigates to a particular video, the scene with the explosion is presented, rather than the beginning of the video. Alternatively, at least a portion of the videos can be downloaded at the client device to enable the client device to play a portion of a video beginning at the scene. In yet other embodiments, a mark associated with a respective video is received that indicates a location of the scene in the respective video. This mark is usable by the client device to jump directly to the specific location of the scene in the video.
- At 808, a selected video is played at the scene corresponding to the search criteria in response to a user input selecting the video. For instance, a user can select one of the videos via a user interface of the client device, such as via a list, an icon, an image, or object. The client device begins playing the video at the scene by using the mark to jump directly to the location of the scene in the video. Alternatively, the client device can receive the selected video as streaming content that begins at the location of the scene.
- Optionally at 810, a remaining portion of the selected video subsequent to the scene is automatically played in response to playback of the video reaching an end of the scene. For instance, playback of the video is not limited to the scene only, but the client device can continue playing the video past the end of the scene and through to the end of the video. Optionally at 812, an additional user input is received that selects an additional video. For instance, a user may select a different video ID via the user interface to initiate playback of a different video. At 814, the selected different video is played at the scene corresponding to the search criteria in response to receiving the additional user input. In this way, the user can surf through a variety of different on-demand videos at scenes corresponding to the user-generated search query, and can allow any of the videos to continue playing past the end of the scene and through to the end of the video or play a selected video from the beginning.
- These methodologies allow a user to surf through different on-demand videos in an easy and efficient manner Using these techniques, the user can preview purposefully chosen scenes in each video that are likely to grab the user's attention, rather than simply read a description of the video, or view a movie trailer of the video. Furthermore, those purposefully chosen scenes are based on a user-generated search query, which represents the user specifying the type of hook that he is interested in at that moment in time. Additionally, playback of the video is not limited to those particular scenes, but the playback can continue through the end of the video. Moreover, surfing through the on-demand content in this way allows the user to essential assess a production quality of the video based on the viewed scene. Accordingly, these methodologies and techniques provide a variety of functionalities that improve conventional techniques used to navigate on-demand content.
-
FIG. 9 illustrates various components of an exampleelectronic device 900 that can be utilized to implement on-demand video surfing as described with reference to any of the previousFIGS. 1-8 . The electronic device may be implemented as any one or combination of a fixed or mobile device, in any form of a consumer, computer, portable, user, communication, phone, navigation, gaming, audio, camera, messaging, media playback, and/or other type of electronic device, such as the video-rendering device 102 described with reference toFIGS. 1 and 2 . -
Electronic device 900 includescommunication transceivers 902 that enable wired and/or wireless communication of device data 904, such as received data, transmitted data, or sensor data as described above. Example communication transceivers include NFC transceivers, WPAN radios compliant with various IEEE 902.15 (Bluetooth™) standards, WLAN radios compliant with any of the various IEEE 902.11 (WiFi™) standards, WWAN (3GPP-compliant) radios for cellular telephony, wireless metropolitan area network (WMAN) radios compliant with various IEEE 902.16 (WiMAX™) standards, and wired local-area-network (LAN) Ethernet transceivers. -
Electronic device 900 may also include one or moredata input ports 906 via which any type of data, media content, and/or inputs can be received, such as user-selectable inputs, messages, music, television content, recorded video content, and any other type of audio, video, and/or image data received from any content and/or data source (e.g., other video devices).Data input ports 906 may include USB ports, coaxial cable ports, and other serial or parallel connectors (including internal connectors) for flash memory, DVDs, CDs, and the like. These data input ports may be used to couple the electronic device to components (e.g., image sensor 102), peripherals, or accessories such as keyboards, microphones, or cameras. -
Electronic device 900 of this example includes processor system 908 (e.g., any of application processors, microprocessors, digital-signal-processors, controllers, and the like), or a processor and memory system (e.g., implemented in a SoC), which process (i.e., execute) computer-executable instructions to control operation of the device.Processor system 908 may be implemented as an application processor, embedded controller, microcontroller, and the like. A processing system may be implemented at least partially in hardware, which can include components of an integrated circuit or on-chip system, digital-signal processor (DSP), application-specific integrated circuit (ASIC), field-programmable gate array (FPGA), a complex programmable logic device (CPLD), and other implementations in silicon and/or other hardware. - Alternatively or in addition,
electronic device 900 can be implemented with any one or combination of software, hardware, firmware, or fixed logic circuitry that is implemented in connection with processing and control circuits, which are generally identified at 910 (processing and control 910). - Although not shown,
electronic device 900 can include a system bus, crossbar, or data transfer system that couples the various components within the device. A system bus can include any one or combination of different bus structures, such as a memory bus or memory controller, a peripheral bus, a universal serial bus, and/or a processor or local bus that utilizes any of a variety of bus architectures. -
Electronic device 900 also includes one ormore memory devices 912 that enable data storage, examples of which include random access memory (RAM), non-volatile memory (e.g., read-only memory (ROM), flash memory, EPROM, EEPROM, etc.), and a disk storage device. Memory device(s) 912 provide data storage mechanisms to store the device data 904, other types of information and/or data, and various device applications 920 (e.g., software applications). For example,operating system 914 can be maintained as software instructions withinmemory device 912 and executed by processors (e.g., processor system 908). In some aspects,content management module 114 is embodied inmemory devices 912 ofelectronic device 900 as executable instructions or code. Although represented as a software implementation,content management module 114 may be implemented as any form of a control application, software application, signal-processing and control module, or hardware or firmware installed on theelectronic device 900. -
Electronic device 900 also includes audio and/orvideo processing system 916 that processes audio data and/or passes through the audio and video data toaudio system 918 and/or to display system 922 (e.g., a screen of a smart phone or camera).Audio system 918 and/ordisplay system 922 may include any devices that process, display, and/or otherwise render audio, video, display, and/or image data. Display data and audio signals can be communicated to an audio component and/or to a display component via an RF (radio frequency) link, S-video link, HDMI (high-definition multimedia interface), composite video link, component video link, DVI (digital video interface), analog audio connection, or other similar communication link, such asmedia data port 924. In some implementations,audio system 918 and/ordisplay system 922 are external components toelectronic device 900. Alternatively or additionally,display system 922 can be an integrated component of the example electronic device, such as part of an integrated touch interface. - Although embodiment of methodologies for on-demand video surfing have been described in language specific to features and/or methods, the subject of the appended claims is not necessarily limited to the specific features or methods described. Rather, the specific features and methods are disclosed as example implementations of on-demand video surfing.
Claims (24)
Priority Applications (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US15/381,997 US20180302680A1 (en) | 2016-12-16 | 2016-12-16 | On-Demand Video Surfing |
PCT/US2017/053124 WO2018111372A1 (en) | 2016-12-16 | 2017-09-23 | On-demand video surfing |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US15/381,997 US20180302680A1 (en) | 2016-12-16 | 2016-12-16 | On-Demand Video Surfing |
Publications (1)
Publication Number | Publication Date |
---|---|
US20180302680A1 true US20180302680A1 (en) | 2018-10-18 |
Family
ID=60020632
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US15/381,997 Abandoned US20180302680A1 (en) | 2016-12-16 | 2016-12-16 | On-Demand Video Surfing |
Country Status (2)
Country | Link |
---|---|
US (1) | US20180302680A1 (en) |
WO (1) | WO2018111372A1 (en) |
Cited By (31)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10728443B1 (en) | 2019-03-27 | 2020-07-28 | On Time Staffing Inc. | Automatic camera angle switching to create combined audiovisual file |
US10963841B2 (en) | 2019-03-27 | 2021-03-30 | On Time Staffing Inc. | Employment candidate empathy scoring system |
US11023735B1 (en) | 2020-04-02 | 2021-06-01 | On Time Staffing, Inc. | Automatic versioning of video presentations |
US11057682B2 (en) * | 2019-03-24 | 2021-07-06 | Apple Inc. | User interfaces including selectable representations of content items |
US11070889B2 (en) | 2012-12-10 | 2021-07-20 | Apple Inc. | Channel bar user interface |
US11127232B2 (en) | 2019-11-26 | 2021-09-21 | On Time Staffing Inc. | Multi-camera, multi-sensor panel data extraction system and method |
US11144882B1 (en) | 2020-09-18 | 2021-10-12 | On Time Staffing Inc. | Systems and methods for evaluating actions over a computer network and establishing live network connections |
US11194546B2 (en) | 2012-12-31 | 2021-12-07 | Apple Inc. | Multi-user TV user interface |
US11245967B2 (en) | 2012-12-13 | 2022-02-08 | Apple Inc. | TV side bar user interface |
US11290762B2 (en) | 2012-11-27 | 2022-03-29 | Apple Inc. | Agnostic media delivery system |
US11297392B2 (en) | 2012-12-18 | 2022-04-05 | Apple Inc. | Devices and method for providing remote control hints on a display |
CN114449361A (en) * | 2018-10-09 | 2022-05-06 | 腾讯科技（深圳）有限公司 | Media data playing method and device, readable storage medium and computer equipment |
US11423071B1 (en) | 2021-08-31 | 2022-08-23 | On Time Staffing, Inc. | Candidate data ranking method using previously selected candidate data |
US11461397B2 (en) | 2014-06-24 | 2022-10-04 | Apple Inc. | Column interface for navigating in a user interface |
US11467726B2 (en) | 2019-03-24 | 2022-10-11 | Apple Inc. | User interfaces for viewing and accessing content on an electronic device |
US11520858B2 (en) | 2016-06-12 | 2022-12-06 | Apple Inc. | Device-level authorization for viewing content |
US11520467B2 (en) | 2014-06-24 | 2022-12-06 | Apple Inc. | Input device and user interface interactions |
US11543938B2 (en) | 2016-06-12 | 2023-01-03 | Apple Inc. | Identifying applications on which content is available |
US11582517B2 (en) | 2018-06-03 | 2023-02-14 | Apple Inc. | Setup procedures for an electronic device |
US11609678B2 (en) | 2016-10-26 | 2023-03-21 | Apple Inc. | User interfaces for browsing content from multiple content applications on an electronic device |
CN116089653A (en) * | 2023-03-20 | 2023-05-09 | 山东大学 | Video retrieval model based on scene information |
US11683565B2 (en) | 2019-03-24 | 2023-06-20 | Apple Inc. | User interfaces for interacting with channels that provide content that plays in a media browsing application |
US11720229B2 (en) | 2020-12-07 | 2023-08-08 | Apple Inc. | User interfaces for browsing and presenting content |
US11727040B2 (en) | 2021-08-06 | 2023-08-15 | On Time Staffing, Inc. | Monitoring third-party forum contributions to improve searching through time-to-live data assignments |
US11797606B2 (en) | 2019-05-31 | 2023-10-24 | Apple Inc. | User interfaces for a podcast browsing and playback application |
US11843838B2 (en) | 2020-03-24 | 2023-12-12 | Apple Inc. | User interfaces for accessing episodes of a content series |
US11863837B2 (en) | 2019-05-31 | 2024-01-02 | Apple Inc. | Notification of augmented reality content on an electronic device |
US11899895B2 (en) | 2020-06-21 | 2024-02-13 | Apple Inc. | User interfaces for setting up an electronic device |
US11907652B2 (en) | 2022-06-02 | 2024-02-20 | On Time Staffing, Inc. | User interface and systems for document creation |
US11934640B2 (en) | 2021-01-29 | 2024-03-19 | Apple Inc. | User interfaces for record labels |
US11962836B2 (en) | 2019-03-24 | 2024-04-16 | Apple Inc. | User interfaces for a media browsing application |
Families Citing this family (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN110691281B (en) * | 2018-07-04 | 2022-04-01 | 北京字节跳动网络技术有限公司 | Video playing processing method, terminal device, server and storage medium |
Citations (12)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20060184963A1 (en) * | 2003-01-06 | 2006-08-17 | Koninklijke Philips Electronics N.V. | Method and apparatus for similar video content hopping |
US20110103768A1 (en) * | 2009-10-29 | 2011-05-05 | Sony Corporation | Information processing apparatus, scene search method, and program |
US20120239690A1 (en) * | 2011-03-16 | 2012-09-20 | Rovi Technologies Corporation | Utilizing time-localized metadata |
US20130291019A1 (en) * | 2012-04-27 | 2013-10-31 | Mixaroo, Inc. | Self-learning methods, entity relations, remote control, and other features for real-time processing, storage, indexing, and delivery of segmented video |
US20140122059A1 (en) * | 2012-10-31 | 2014-05-01 | Tivo Inc. | Method and system for voice based media search |
US20140281985A1 (en) * | 2013-03-15 | 2014-09-18 | General Instrument Corporation | Maximum Value Displayed Content Feature |
US8937620B1 (en) * | 2011-04-07 | 2015-01-20 | Google Inc. | System and methods for generation and control of story animation |
US9077956B1 (en) * | 2013-03-22 | 2015-07-07 | Amazon Technologies, Inc. | Scene identification |
US20160094875A1 (en) * | 2014-09-30 | 2016-03-31 | United Video Properties, Inc. | Systems and methods for presenting user selected scenes |
US20170094366A1 (en) * | 2015-09-29 | 2017-03-30 | Fujitsu Limited | Video image reproduction device, video image distribution server, method of reproducing video image and method of distributing video image |
US9854305B2 (en) * | 2015-09-08 | 2017-12-26 | Naver Corporation | Method, system, apparatus, and non-transitory computer readable recording medium for extracting and providing highlight image of video content |
US9858967B1 (en) * | 2015-09-09 | 2018-01-02 | A9.Com, Inc. | Section identification in video content |
Family Cites Families (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2007142750A (en) * | 2005-11-17 | 2007-06-07 | National Agency For The Advancement Of Sports & Health | Video image browsing system, computer terminal and program |
-
2016
- 2016-12-16 US US15/381,997 patent/US20180302680A1/en not_active Abandoned
-
2017
- 2017-09-23 WO PCT/US2017/053124 patent/WO2018111372A1/en active Application Filing
Patent Citations (12)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20060184963A1 (en) * | 2003-01-06 | 2006-08-17 | Koninklijke Philips Electronics N.V. | Method and apparatus for similar video content hopping |
US20110103768A1 (en) * | 2009-10-29 | 2011-05-05 | Sony Corporation | Information processing apparatus, scene search method, and program |
US20120239690A1 (en) * | 2011-03-16 | 2012-09-20 | Rovi Technologies Corporation | Utilizing time-localized metadata |
US8937620B1 (en) * | 2011-04-07 | 2015-01-20 | Google Inc. | System and methods for generation and control of story animation |
US20130291019A1 (en) * | 2012-04-27 | 2013-10-31 | Mixaroo, Inc. | Self-learning methods, entity relations, remote control, and other features for real-time processing, storage, indexing, and delivery of segmented video |
US20140122059A1 (en) * | 2012-10-31 | 2014-05-01 | Tivo Inc. | Method and system for voice based media search |
US20140281985A1 (en) * | 2013-03-15 | 2014-09-18 | General Instrument Corporation | Maximum Value Displayed Content Feature |
US9077956B1 (en) * | 2013-03-22 | 2015-07-07 | Amazon Technologies, Inc. | Scene identification |
US20160094875A1 (en) * | 2014-09-30 | 2016-03-31 | United Video Properties, Inc. | Systems and methods for presenting user selected scenes |
US9854305B2 (en) * | 2015-09-08 | 2017-12-26 | Naver Corporation | Method, system, apparatus, and non-transitory computer readable recording medium for extracting and providing highlight image of video content |
US9858967B1 (en) * | 2015-09-09 | 2018-01-02 | A9.Com, Inc. | Section identification in video content |
US20170094366A1 (en) * | 2015-09-29 | 2017-03-30 | Fujitsu Limited | Video image reproduction device, video image distribution server, method of reproducing video image and method of distributing video image |
Cited By (45)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11290762B2 (en) | 2012-11-27 | 2022-03-29 | Apple Inc. | Agnostic media delivery system |
US11070889B2 (en) | 2012-12-10 | 2021-07-20 | Apple Inc. | Channel bar user interface |
US11245967B2 (en) | 2012-12-13 | 2022-02-08 | Apple Inc. | TV side bar user interface |
US11317161B2 (en) | 2012-12-13 | 2022-04-26 | Apple Inc. | TV side bar user interface |
US11297392B2 (en) | 2012-12-18 | 2022-04-05 | Apple Inc. | Devices and method for providing remote control hints on a display |
US11822858B2 (en) | 2012-12-31 | 2023-11-21 | Apple Inc. | Multi-user TV user interface |
US11194546B2 (en) | 2012-12-31 | 2021-12-07 | Apple Inc. | Multi-user TV user interface |
US11520467B2 (en) | 2014-06-24 | 2022-12-06 | Apple Inc. | Input device and user interface interactions |
US11461397B2 (en) | 2014-06-24 | 2022-10-04 | Apple Inc. | Column interface for navigating in a user interface |
US11520858B2 (en) | 2016-06-12 | 2022-12-06 | Apple Inc. | Device-level authorization for viewing content |
US11543938B2 (en) | 2016-06-12 | 2023-01-03 | Apple Inc. | Identifying applications on which content is available |
US11966560B2 (en) | 2016-10-26 | 2024-04-23 | Apple Inc. | User interfaces for browsing content from multiple content applications on an electronic device |
US11609678B2 (en) | 2016-10-26 | 2023-03-21 | Apple Inc. | User interfaces for browsing content from multiple content applications on an electronic device |
US11582517B2 (en) | 2018-06-03 | 2023-02-14 | Apple Inc. | Setup procedures for an electronic device |
CN114449361A (en) * | 2018-10-09 | 2022-05-06 | 腾讯科技（深圳）有限公司 | Media data playing method and device, readable storage medium and computer equipment |
US11683565B2 (en) | 2019-03-24 | 2023-06-20 | Apple Inc. | User interfaces for interacting with channels that provide content that plays in a media browsing application |
US11445263B2 (en) | 2019-03-24 | 2022-09-13 | Apple Inc. | User interfaces including selectable representations of content items |
US11750888B2 (en) | 2019-03-24 | 2023-09-05 | Apple Inc. | User interfaces including selectable representations of content items |
US11467726B2 (en) | 2019-03-24 | 2022-10-11 | Apple Inc. | User interfaces for viewing and accessing content on an electronic device |
US11057682B2 (en) * | 2019-03-24 | 2021-07-06 | Apple Inc. | User interfaces including selectable representations of content items |
US11962836B2 (en) | 2019-03-24 | 2024-04-16 | Apple Inc. | User interfaces for a media browsing application |
US10728443B1 (en) | 2019-03-27 | 2020-07-28 | On Time Staffing Inc. | Automatic camera angle switching to create combined audiovisual file |
US11961044B2 (en) | 2019-03-27 | 2024-04-16 | On Time Staffing, Inc. | Behavioral data analysis and scoring system |
US11457140B2 (en) | 2019-03-27 | 2022-09-27 | On Time Staffing Inc. | Automatic camera angle switching in response to low noise audio to create combined audiovisual file |
US10963841B2 (en) | 2019-03-27 | 2021-03-30 | On Time Staffing Inc. | Employment candidate empathy scoring system |
US11863858B2 (en) | 2019-03-27 | 2024-01-02 | On Time Staffing Inc. | Automatic camera angle switching in response to low noise audio to create combined audiovisual file |
US11863837B2 (en) | 2019-05-31 | 2024-01-02 | Apple Inc. | Notification of augmented reality content on an electronic device |
US11797606B2 (en) | 2019-05-31 | 2023-10-24 | Apple Inc. | User interfaces for a podcast browsing and playback application |
US11783645B2 (en) | 2019-11-26 | 2023-10-10 | On Time Staffing Inc. | Multi-camera, multi-sensor panel data extraction system and method |
US11127232B2 (en) | 2019-11-26 | 2021-09-21 | On Time Staffing Inc. | Multi-camera, multi-sensor panel data extraction system and method |
US11843838B2 (en) | 2020-03-24 | 2023-12-12 | Apple Inc. | User interfaces for accessing episodes of a content series |
US11861904B2 (en) | 2020-04-02 | 2024-01-02 | On Time Staffing, Inc. | Automatic versioning of video presentations |
US11023735B1 (en) | 2020-04-02 | 2021-06-01 | On Time Staffing, Inc. | Automatic versioning of video presentations |
US11184578B2 (en) | 2020-04-02 | 2021-11-23 | On Time Staffing, Inc. | Audio and video recording and streaming in a three-computer booth |
US11636678B2 (en) | 2020-04-02 | 2023-04-25 | On Time Staffing Inc. | Audio and video recording and streaming in a three-computer booth |
US11899895B2 (en) | 2020-06-21 | 2024-02-13 | Apple Inc. | User interfaces for setting up an electronic device |
US11720859B2 (en) | 2020-09-18 | 2023-08-08 | On Time Staffing Inc. | Systems and methods for evaluating actions over a computer network and establishing live network connections |
US11144882B1 (en) | 2020-09-18 | 2021-10-12 | On Time Staffing Inc. | Systems and methods for evaluating actions over a computer network and establishing live network connections |
US11720229B2 (en) | 2020-12-07 | 2023-08-08 | Apple Inc. | User interfaces for browsing and presenting content |
US11934640B2 (en) | 2021-01-29 | 2024-03-19 | Apple Inc. | User interfaces for record labels |
US11727040B2 (en) | 2021-08-06 | 2023-08-15 | On Time Staffing, Inc. | Monitoring third-party forum contributions to improve searching through time-to-live data assignments |
US11966429B2 (en) | 2021-08-06 | 2024-04-23 | On Time Staffing Inc. | Monitoring third-party forum contributions to improve searching through time-to-live data assignments |
US11423071B1 (en) | 2021-08-31 | 2022-08-23 | On Time Staffing, Inc. | Candidate data ranking method using previously selected candidate data |
US11907652B2 (en) | 2022-06-02 | 2024-02-20 | On Time Staffing, Inc. | User interface and systems for document creation |
CN116089653A (en) * | 2023-03-20 | 2023-05-09 | 山东大学 | Video retrieval model based on scene information |
Also Published As
Publication number | Publication date |
---|---|
WO2018111372A1 (en) | 2018-06-21 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US20180302680A1 (en) | On-Demand Video Surfing | |
US10367913B2 (en) | Systems and methods for tracking user behavior using closed caption text | |
US10080043B2 (en) | Modifying media asset metadata to include identification of key moment | |
US8887200B2 (en) | Smart catch-up for media content viewing | |
US20200183479A1 (en) | Method and system for implementing auto-switching or auto-playing video content | |
US9077947B2 (en) | Presenting linear and nonlinear content via DVR | |
US10397634B2 (en) | System and method for synchronized presentation of video timeline metadata | |
US20210392387A1 (en) | Systems and methods for storing a media asset rescheduled for transmission from a different source | |
US11711587B2 (en) | Using manifest files to determine events in content items | |
EP3375192B1 (en) | Caching mechanism for repeated content | |
US20130173796A1 (en) | Systems and methods for managing a media content queue | |
US20130347029A1 (en) | Systems and methods for navigating to content without an advertisement | |
US20130081083A1 (en) | Method of managing contents and image display device using the same | |
US20130073673A1 (en) | Content Storage and Identification | |
US10909218B2 (en) | System and method for providing a content consumption journal to users in a multi-device environment | |
US10210906B2 (en) | Content playback and recording based on scene change detection and metadata | |
US20140114919A1 (en) | Systems and methods for providing synchronized media content | |
US20160308923A1 (en) | Method and system for playing live broadcast streaming media | |
US10063621B2 (en) | Systems and methods for enabling users to receive access to content in closed network | |
US9578374B1 (en) | DVR playlist provisioning system | |
US20140372424A1 (en) | Method and system for searching video scenes | |
US10917702B2 (en) | Creating customized short-form content from long-form content | |
US10382812B1 (en) | Methods and systems for selecting a destination for storage of a media asset based on trick-play likelihood | |
AU2019240676A1 (en) | Systems and methods for enabling users to receive access to content in closed network | |
US20190222906A1 (en) | Content Aggregation |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:CORMICAN, NEIL P.;REEL/FRAME:040641/0865Effective date: 20161214 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044567/0001Effective date: 20170929 |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: DOCKETED NEW CASE - READY FOR EXAMINATION |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NON FINAL ACTION MAILED |
|
STCB | Information on status: application discontinuation |
Free format text: ABANDONED -- FAILURE TO RESPOND TO AN OFFICE ACTION |