JP6839234B2 - Feedback controller for data transmission - Google Patents
Feedback controller for data transmission Download PDFInfo
- Publication number
- JP6839234B2 JP6839234B2 JP2019127639A JP2019127639A JP6839234B2 JP 6839234 B2 JP6839234 B2 JP 6839234B2 JP 2019127639 A JP2019127639 A JP 2019127639A JP 2019127639 A JP2019127639 A JP 2019127639A JP 6839234 B2 JP6839234 B2 JP 6839234B2
- Authority
- JP
- Japan
- Prior art keywords
- content
- processors
- audio signal
- processing system
- data processing
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
- 230000005540 biological transmission Effects 0.000 title description 18
- 230000005236 sound signal Effects 0.000 claims description 106
- 238000004891 communication Methods 0.000 claims description 96
- 238000000034 method Methods 0.000 claims description 95
- 230000004044 response Effects 0.000 claims description 82
- 230000008569 process Effects 0.000 claims description 47
- 230000001747 exhibiting effect Effects 0.000 claims 1
- 238000012545 processing Methods 0.000 description 197
- 230000009471 action Effects 0.000 description 91
- 238000004590 computer program Methods 0.000 description 11
- 238000005108 dry cleaning Methods 0.000 description 10
- 230000000694 effects Effects 0.000 description 10
- 230000003993 interaction Effects 0.000 description 9
- 230000006399 behavior Effects 0.000 description 7
- 238000005516 engineering process Methods 0.000 description 7
- 238000006243 chemical reaction Methods 0.000 description 5
- 230000006870 function Effects 0.000 description 5
- 238000013515 script Methods 0.000 description 5
- 238000005406 washing Methods 0.000 description 5
- 238000004458 analytical method Methods 0.000 description 4
- 238000003058 natural language processing Methods 0.000 description 4
- 230000003287 optical effect Effects 0.000 description 4
- 235000013305 food Nutrition 0.000 description 3
- 230000000670 limiting effect Effects 0.000 description 3
- 238000010801 machine learning Methods 0.000 description 3
- 238000007726 management method Methods 0.000 description 3
- 238000003491 array Methods 0.000 description 2
- 230000000903 blocking effect Effects 0.000 description 2
- 238000010586 diagram Methods 0.000 description 2
- 238000011156 evaluation Methods 0.000 description 2
- 230000033001 locomotion Effects 0.000 description 2
- 238000000926 separation method Methods 0.000 description 2
- 230000003068 static effect Effects 0.000 description 2
- 230000001360 synchronised effect Effects 0.000 description 2
- 230000029305 taxis Effects 0.000 description 2
- 238000012546 transfer Methods 0.000 description 2
- IRLPACMLTUPBCL-KQYNXXCUSA-N 5'-adenylyl sulfate Chemical compound C1=NC=2C(N)=NC=NC=2N1[C@@H]1O[C@H](COP(O)(=O)OS(O)(=O)=O)[C@@H](O)[C@H]1O IRLPACMLTUPBCL-KQYNXXCUSA-N 0.000 description 1
- 230000002730 additional effect Effects 0.000 description 1
- 230000002776 aggregation Effects 0.000 description 1
- 238000004220 aggregation Methods 0.000 description 1
- 230000008901 benefit Effects 0.000 description 1
- 230000008859 change Effects 0.000 description 1
- 230000000295 complement effect Effects 0.000 description 1
- 230000008878 coupling Effects 0.000 description 1
- 238000010168 coupling process Methods 0.000 description 1
- 238000005859 coupling reaction Methods 0.000 description 1
- 238000013500 data storage Methods 0.000 description 1
- 238000003066 decision tree Methods 0.000 description 1
- 230000003247 decreasing effect Effects 0.000 description 1
- 238000001514 detection method Methods 0.000 description 1
- 238000002592 echocardiography Methods 0.000 description 1
- 230000008451 emotion Effects 0.000 description 1
- 238000001914 filtration Methods 0.000 description 1
- 239000000446 fuel Substances 0.000 description 1
- 238000011835 investigation Methods 0.000 description 1
- 239000004973 liquid crystal related substance Substances 0.000 description 1
- 238000013507 mapping Methods 0.000 description 1
- 239000011159 matrix material Substances 0.000 description 1
- 238000000691 measurement method Methods 0.000 description 1
- 238000010295 mobile communication Methods 0.000 description 1
- 238000012544 monitoring process Methods 0.000 description 1
- 230000000877 morphologic effect Effects 0.000 description 1
- 230000008520 organization Effects 0.000 description 1
- 230000037081 physical activity Effects 0.000 description 1
- 230000001902 propagating effect Effects 0.000 description 1
- 238000013442 quality metrics Methods 0.000 description 1
- 230000008439 repair process Effects 0.000 description 1
- 230000004043 responsiveness Effects 0.000 description 1
- 230000011218 segmentation Effects 0.000 description 1
- 239000004065 semiconductor Substances 0.000 description 1
- 239000007787 solid Substances 0.000 description 1
- 238000007619 statistical method Methods 0.000 description 1
- 238000013179 statistical model Methods 0.000 description 1
- 238000012360 testing method Methods 0.000 description 1
- 238000012549 training Methods 0.000 description 1
- 230000009466 transformation Effects 0.000 description 1
- 238000000844 transformation Methods 0.000 description 1
Classifications
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/22—Procedures used during a speech recognition process, e.g. man-machine dialogue
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/08—Speech classification or search
- G10L15/18—Speech classification or search using natural language modelling
- G10L15/1822—Parsing for meaning understanding
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/33—Querying
- G06F16/332—Query formulation
- G06F16/3329—Natural language query formulation or dialogue systems
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/33—Querying
- G06F16/3331—Query processing
- G06F16/334—Query execution
- G06F16/3343—Query execution using phonetics
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/33—Querying
- G06F16/3331—Query processing
- G06F16/334—Query execution
- G06F16/3344—Query execution using natural language analysis
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/40—Information retrieval; Database structures therefor; File system structures therefor of multimedia data, e.g. slideshows comprising image and additional audio data
- G06F16/43—Querying
- G06F16/432—Query formulation
- G06F16/433—Query formulation using audio data
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/903—Querying
- G06F16/9032—Query formulation
- G06F16/90332—Natural language query formulation or dialogue systems
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/951—Indexing; Web crawling techniques
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/16—Sound input; Sound output
- G06F3/167—Audio in a user interface, e.g. using voice commands for navigating, audio feedback
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/20—Natural language analysis
- G06F40/205—Parsing
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/20—Natural language analysis
- G06F40/268—Morphological analysis
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/20—Natural language analysis
- G06F40/279—Recognition of textual entities
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/30—Semantic analysis
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/08—Speech classification or search
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L25/00—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00
- G10L25/48—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00 specially adapted for particular use
- G10L25/51—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00 specially adapted for particular use for comparison or discrimination
- G10L25/60—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00 specially adapted for particular use for comparison or discrimination for measuring the quality of voice signals
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L25/00—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00
- G10L25/48—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00 specially adapted for particular use
- G10L25/69—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00 specially adapted for particular use for evaluating synthetic or decoded voice signals
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L25/00—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00
- G10L25/78—Detection of presence or absence of voice signals
- G10L25/87—Detection of discrete points within a voice signal
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L25/00—Speech or voice analysis techniques not restricted to a single one of groups G10L15/00 - G10L21/00
- G10L25/90—Pitch determination of speech signals
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04B—TRANSMISSION
- H04B17/00—Monitoring; Testing
- H04B17/30—Monitoring; Testing of propagation channels
- H04B17/309—Measuring or estimating channel quality parameters
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L51/00—User-to-user messaging in packet-switching networks, transmitted according to store-and-forward or real-time protocols, e.g. e-mail
- H04L51/04—Real-time or near real-time messaging, e.g. instant messaging [IM]
- H04L51/046—Interoperability with other network applications or services
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L65/00—Network arrangements, protocols or services for supporting real-time applications in data packet communication
- H04L65/1066—Session management
- H04L65/1069—Session establishment or de-establishment
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L65/00—Network arrangements, protocols or services for supporting real-time applications in data packet communication
- H04L65/60—Network streaming of media packets
- H04L65/61—Network streaming of media packets for supporting one-way streaming services, e.g. Internet radio
- H04L65/612—Network streaming of media packets for supporting one-way streaming services, e.g. Internet radio for unicast
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L65/00—Network arrangements, protocols or services for supporting real-time applications in data packet communication
- H04L65/60—Network streaming of media packets
- H04L65/75—Media network packet handling
- H04L65/762—Media network packet handling at the source
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L65/00—Network arrangements, protocols or services for supporting real-time applications in data packet communication
- H04L65/80—Responding to QoS
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L67/00—Network arrangements or protocols for supporting network services or applications
- H04L67/01—Protocols
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L67/00—Network arrangements or protocols for supporting network services or applications
- H04L67/50—Network services
- H04L67/53—Network services using third party service providers
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L67/00—Network arrangements or protocols for supporting network services or applications
- H04L67/50—Network services
- H04L67/535—Tracking the activity of the user
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04M—TELEPHONIC COMMUNICATION
- H04M3/00—Automatic or semi-automatic exchanges
- H04M3/22—Arrangements for supervision, monitoring or testing
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04M—TELEPHONIC COMMUNICATION
- H04M3/00—Automatic or semi-automatic exchanges
- H04M3/22—Arrangements for supervision, monitoring or testing
- H04M3/2236—Quality of speech transmission monitoring
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04M—TELEPHONIC COMMUNICATION
- H04M3/00—Automatic or semi-automatic exchanges
- H04M3/42—Systems providing special services or facilities to subscribers
- H04M3/487—Arrangements for providing information services, e.g. recorded voice services or time announcements
- H04M3/493—Interactive information services, e.g. directory enquiries ; Arrangements therefor, e.g. interactive voice response [IVR] systems or voice portals
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04M—TELEPHONIC COMMUNICATION
- H04M3/00—Automatic or semi-automatic exchanges
- H04M3/42—Systems providing special services or facilities to subscribers
- H04M3/487—Arrangements for providing information services, e.g. recorded voice services or time announcements
- H04M3/493—Interactive information services, e.g. directory enquiries ; Arrangements therefor, e.g. interactive voice response [IVR] systems or voice portals
- H04M3/4931—Directory assistance systems
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/08—Speech classification or search
- G10L2015/088—Word spotting
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/22—Procedures used during a speech recognition process, e.g. man-machine dialogue
- G10L2015/223—Execution procedure of a spoken command
Description
本願は、発明の名称を「データ送信のためのフィードバックコントローラ」とした２０１６年１２月３０日に出願された米国特許出願番号第１５／３９５、６９４号の利益を主張し、本明細書に引用によりすべての目的で全体として取り込まれる。 The present application claims the benefit of U.S. Patent Application Nos. 15/395, 694 filed on December 30, 2016 with the title of the invention "Feedback Controller for Data Transmission" and is cited herein. Is taken in as a whole for all purposes.
コンピューティングデバイスの間のパケット・ベースのまたは、ネットワークトラフィックデータの過度なネットワーク送信は、コンピューティングデバイスが当該ネットワークトラフィックデータを正しく処理し、当該ネットワークトラフィックデータに関連する動作を完了し、または当該ネットワークトラフィックデータにタイムリーに応答することを不可能としうる。ネットワークトラフィックデータの当該過度なネットワーク送信はまた、応答するコンピューティングデバイスがその処理能力を上回る場合に、データのルーティングを複雑化しまたは当該応答の品質を劣化させうる、これは非効率的な帯域幅利用をもたらしうる。コンテンツ・アイテム・オブジェクトに対応するネットワーク送信の制御は、コンピューティングデバイスの間のネットワークトラフィックデータのネットワーク送信を開始しうる多数のコンテンツ・アイテム・オブジェクトにより複雑化されうる。 Excessive network transmission of packet-based or network traffic data between computing devices causes the computing device to properly process the network traffic data and complete the operations associated with the network traffic data, or the network. It may be impossible to respond to traffic data in a timely manner. The excessive network transmission of network traffic data can also complicate the routing of the data or degrade the quality of the response if the responding computing device exceeds its processing power, which is an inefficient bandwidth. Can bring usage. Controlling network transmissions for content item objects can be complicated by a large number of content item objects that can initiate network transmissions of network traffic data between computing devices.
本開示は一般に、１つまたは複数のインタフェースまたは１つまたは複数のタイプのコンピュータネットワーク上のデータ送信に対するフィードバックコントローラに関する。例えば、コンピューティングシステムは制限された数のインタフェース、制限されたタイプのインタフェースにアクセスでき、または制限された数の利用可能なインタフェースが所与の時点にあるかもしれない。特定のタイプのインタフェースがより多いコンピューティングリソースまたはバッテリを消費しうるので、システムが現在利用可能なインタフェースに応答して情報を効率的に送信するのは困難であるかもしれない。異種のコンピューティングリソースが音声ベースのコンピューティング環境においてオーディオベースの命令を効率的に処理し、一貫しておよび正確に解析するのは困難であるので、効率的に、信頼性高く、および正確に異種のコンピューティングリソース上で情報を通信するのは困難であるかもしれない。例えば、当該異種のコンピューティングリソースは、同一の音声モデルへのアクセスを有さないかもしれず、または当該オーディオベースの命令を正確かつ一環して解析するのを困難にしうる古いまたは非同期の音声モデルにアクセスするかもしれない。 The present disclosure generally relates to a feedback controller for data transmission on one or more interfaces or one or more types of computer networks. For example, a computing system may have access to a limited number of interfaces, a limited number of interfaces, or a limited number of available interfaces at a given point in time. It may be difficult for a system to efficiently send information in response to currently available interfaces, as certain types of interfaces can consume more computing resources or batteries. Efficient, reliable, and accurate because it is difficult for heterogeneous computing resources to efficiently process audio-based instructions and analyze them consistently and accurately in a voice-based computing environment. Communicating information on disparate computing resources can be difficult. For example, the heterogeneous computing resources may not have access to the same voice model, or in older or asynchronous voice models that may make it difficult to analyze the audio-based instructions accurately and collectively. May access.
本開示のシステムおよび方法は一般にデータ送信のためのフィードバックコントローラに関する。データ処理システムは、当該音声ベースの命令を解析し、コンテンツセレクタコンポーネントにより実施されるリアルタイムコンテンツ選択プロセスを介してコンテンツ・アイテムを選択するように集約音声に基づいてトレーニングされる音声モデルを用いて、当該音声ベースの入力を処理することができる。データ処理システムは、当該選択されたコンテンツ・アイテムを当該クライアントコンピューティングデバイスに送信して、当該クライアントコンピューティングデバイスおよび当該選択されたコンテンツ・アイテムに関連付けられたサードパーティプロバイダデバイスの間の通信セッションを開始することができる。データ処理システムは当該通信セッションに関する情報を監視または受信して、当該通信セッションの特性を測定し品質信号を生成することができる。データ処理システムは次いで、当該リアルタイムコンテンツ選択プロセスに影響を及ぼすために、当該品質信号に基づいて当該コンテンツセレクタコンポーネントを調節または制御することができる。例えば、当該コンテンツセレクタコンポーネントが低品質通信セッションに関連付けられたコンテンツ・アイテム・オブジェクトを選択するのをブロックまたは防止することは、当該コンテンツ・アイテムを選択し通信セッションを確立するのを許可するのと比べて、無駄なリソース消費を減らすことができる。さらに、バッテリ電力を利用するクライアントデバイスに対して、当該フィードバックモニタコンポーネントはバッテリ利用を節約することができる。 The systems and methods of the present disclosure generally relate to feedback controllers for data transmission. The data processing system analyzes the voice-based instructions and uses a voice model that is trained based on aggregated voice to select content items through a real-time content selection process performed by the content selector component. The voice-based input can be processed. The data processing system sends the selected content item to the client computing device to have a communication session between the client computing device and the third-party provider device associated with the selected content item. You can start. The data processing system can monitor or receive information about the communication session, measure the characteristics of the communication session, and generate quality signals. The data processing system can then adjust or control the content selector component based on the quality signal to influence the real-time content selection process. For example, blocking or preventing the content selector component from selecting a content item object associated with a poor quality communication session allows the content item to be selected and a communication session established. In comparison, wasteful resource consumption can be reduced. In addition, for client devices that utilize battery power, the feedback monitor component can save battery usage.
少なくとも１つの態様はコンピュータネットワーク上のデータ送信に対するフィードバック制御システムに関する。当該システムは自然言語プロセッサおよびコンテンツセレクタコンポーネントを実行するデータ処理システムを含むことができる。当該システムはフィードバックモニタコンポーネントを含むことができる。自然言語プロセッサコンポーネントは、データ処理システムのインタフェースを介して、クライアントデバイスのセンサにより検出された入力オーディオ信号を含むデータパケットを受信することができる。自然言語プロセッサコンポーネントは当該入力オーディオ信号を解析して、要求および当該要求に対応するトリガキーワードを識別することができる。データ処理システムは、自然言語プロセッサにより識別された当該トリガキーワードを受信し、当該トリガキーワードに基づいて、リアルタイムコンテンツ選択プロセスを介してコンテンツ・アイテムを選択するコンテンツセレクタコンポーネントを含むことができる。当該システムはフィードバックモニタコンポーネントを含むことができる。当該フィードバックモニタコンポーネントは、クライアントデバイスと、当該コンテンツ・アイテムとの対話に応答してクライアントデバイスとの通信セッションを確立した会話アプリケーションプログラミングインタフェースとの間で送信された可聴信号を運搬するデータパケットを受信することができる。当該フィードバックモニタは、当該可聴信号に基づいて当該通信セッションの特性を測定することができる。当該フィードバックモニタコンポーネントは当該測定された特性に基づいて品質信号を生成することができる。当該コンテンツセレクタコンポーネントは当該品質信号に基づいて当該リアルタイム選択プロセスを調節することができる。 At least one aspect relates to a feedback control system for data transmission over a computer network. The system can include a data processing system that runs a natural language processor and content selector components. The system can include a feedback monitor component. The natural language processor component can receive a data packet containing an input audio signal detected by a sensor on the client device via the interface of the data processing system. The natural language processor component can analyze the input audio signal to identify the request and the trigger keyword corresponding to the request. The data processing system can include a content selector component that receives the trigger keyword identified by the natural language processor and selects a content item through a real-time content selection process based on the trigger keyword. The system can include a feedback monitor component. The feedback monitor component receives a data packet carrying an audible signal transmitted between the client device and the conversational application programming interface that has established a communication session with the client device in response to the interaction with the content item. can do. The feedback monitor can measure the characteristics of the communication session based on the audible signal. The feedback monitor component can generate a quality signal based on the measured characteristics. The content selector component can adjust the real-time selection process based on the quality signal.
少なくとも１つの態様はフィードバック制御システムを用いてコンピュータネットワーク上でデータを送信する方法に関する。当該方法を、少なくとも部分的に、自然言語プロセッサコンポーネントおよびコンテンツセレクタコンポーネントを実行するデータ処理システムにより実施することができる。当該方法を、少なくとも部分的にフィードバックモニタコンポーネントにより実施することができる。当該方法は、自然言語プロセッサコンポーネントが、データ処理システムのインタフェースを介して、クライアントデバイスのセンサにより検出された入力オーディオ信号を含むデータパケットを受信するステップを含むことができる。当該方法は、データ処理システムが当該入力オーディオ信号を解析して、要求および当該要求に対応するトリガキーワードを識別するステップを含むことができる。当該方法は、当該コンテンツセレクタコンポーネントが自然言語プロセッサにより識別された当該トリガキーワードを受信するステップを含むことができる。当該方法は、当該コンテンツセレクタコンポーネントが、当該トリガキーワードに基づいて、リアルタイムコンテンツ選択プロセスを介してコンテンツ・アイテムを選択するステップを含むことができる。当該方法は、当該フィードバックモニタコンポーネントが、クライアントデバイスと、当該コンテンツ・アイテムとの対話に応答してクライアントデバイスとの通信セッションを確立した会話アプリケーションプログラミングインタフェースとの間で送信された可聴信号を運搬するデータパケットを受信するステップを含むことができる。当該方法は、当該フィードバックモニタコンポーネントが当該可聴信号に基づいて当該通信セッションの品質を測定するステップを含むことができる。当該方法は、当該フィードバックモニタコンポーネントが当該測定された特性に基づいて品質信号を生成するステップを含むことができる。当該方法は、当該フィードバックモニタコンポーネントが当該品質信号に基づいて当該リアルタイム選択プロセスを調節するステップを含むことができる。 At least one aspect relates to a method of transmitting data over a computer network using a feedback control system. The method can be performed, at least in part, by a data processing system running a natural language processor component and a content selector component. The method can be implemented, at least in part, by the feedback monitor component. The method can include the step of the natural language processor component receiving a data packet containing an input audio signal detected by a sensor on the client device via the interface of the data processing system. The method can include a step in which the data processing system analyzes the input audio signal to identify the request and the trigger keyword corresponding to the request. The method can include the step of receiving the trigger keyword identified by the natural language processor for the content selector component. The method can include a step in which the content selector component selects a content item through a real-time content selection process based on the trigger keyword. The method carries an audible signal transmitted by the feedback monitor component between a client device and a conversational application programming interface that has established a communication session with the client device in response to interaction with the content item. It can include a step of receiving a data packet. The method can include the step of the feedback monitor component measuring the quality of the communication session based on the audible signal. The method can include the step of the feedback monitor component generating a quality signal based on the measured characteristics. The method can include a step in which the feedback monitor component adjusts the real-time selection process based on the quality signal.
これらのおよび他の態様および実装を以下で説明する。以上の情報および以下の詳細な説明は様々な態様および実装の例示的な例を含み、クレームした態様および実装の性質と特徴を理解するための概要またはフレームワークを提供する。当該図面は当該様々な態様および実装の例示とさらなる理解を提供し、本明細書に組み込まれ本明細書の一部を構成する。 These and other aspects and implementations are described below. The above information and the detailed description below include exemplary examples of various aspects and implementations and provide an overview or framework for understanding the nature and characteristics of the claimed aspects and implementations. The drawings provide examples and further understanding of the various aspects and implementations, which are incorporated herein and constitute a portion of the specification.
添付図面は正しい縮尺で描かれていない。当該様々な図面における同じ参照番号および指定は同じ要素を示す。明確さの目的のため、全てのコンポーネントが全ての図面においてラベル付けされていないかもしれない。 The attached drawings are not drawn to the correct scale. The same reference numbers and designations in the various drawings indicate the same elements. For clarity purposes, not all components may be labeled in all drawings.
以下は、およびコンピュータネットワーク上のデータ送信のためのフィードバック制御システムの方法、装置、およびシステムの実装に関連する様々な概念のより詳細な説明である。上で導入し以下でさらに詳細に説明する様々な概念を任意の多数の方法で実装してもよい。 The following is a more detailed description of the methods, devices, and various concepts related to the implementation of feedback control systems for data transmission over computer networks. Various concepts introduced above and described in more detail below may be implemented in any number of ways.
本開示は一般に、１つまたは複数のインタフェースまたは１つまたは複数のタイプのコンピュータネットワーク上のデータ送信に対するフィードバックコントローラに関する。例えば、コンピューティングシステムは制限された数のインタフェース、制限されたタイプのインタフェースにアクセスでき、または制限された数の利用可能なインタフェースが所与の時点にあるかもしれない。特定のタイプのインタフェースがより多いコンピューティングリソースまたはバッテリを消費しうるので、システムが現在利用可能なインタフェースに応答して情報を効率的に送信するのは困難であるかもしれない。異種のコンピューティングリソースが音声ベースのコンピューティング環境においてオーディオベースの命令を効率的に処理し、一貫しておよび正確に解析するのは困難であるので、効率的に、信頼性高く、および正確に異種のコンピューティングリソース上で情報を通信するのは困難であるかもしれない。例えば、当該異種のコンピューティングリソースは、同一の音声モデルへのアクセスを有さないかもしれず、または当該オーディオベースの命令を解析するのを困難にしうる古いまたは非同期の音声モデルにアクセスするかもしれない。 The present disclosure generally relates to a feedback controller for data transmission on one or more interfaces or one or more types of computer networks. For example, a computing system may have access to a limited number of interfaces, a limited number of interfaces, or a limited number of available interfaces at a given point in time. It may be difficult for a system to efficiently send information in response to currently available interfaces, as certain types of interfaces can consume more computing resources or batteries. Efficient, reliable, and accurate because it is difficult for heterogeneous computing resources to efficiently process audio-based instructions and analyze them consistently and accurately in a voice-based computing environment. Communicating information on disparate computing resources can be difficult. For example, the heterogeneous computing resource may not have access to the same voice model, or may access an older or asynchronous voice model that can make it difficult to parse the audio-based instructions. ..
本開示のシステムおよび方法は一般にデータ送信のためのフィードバックコントローラに関する。データ処理システムは、当該音声ベースの命令を解析し、コンテンツセレクタコンポーネントにより実施されるリアルタイムコンテンツ選択プロセスを介してコンテンツ・アイテムを選択するように集約音声に基づいてトレーニングされる音声モデルを用いて、当該音声ベースの入力を処理することができる。データ処理システムは、当該選択されたコンテンツ・アイテムを当該クライアントコンピューティングデバイスに送信して、当該クライアントコンピューティングデバイスおよび当該選択されたコンテンツ・アイテムに関連付けられたサードパーティプロバイダデバイスの間の通信セッションを開始することができる。データ処理システムは、当該通信セッションに関する情報を監視または受信して、当該通信セッションの特性を測定し品質信号を生成することができる。データ処理システムは次いで、当該リアルタイムコンテンツ選択プロセスに影響を及ぼすために、当該品質信号に基づいて当該コンテンツセレクタコンポーネントを調節または制御することができる。 The systems and methods of the present disclosure generally relate to feedback controllers for data transmission. The data processing system analyzes the voice-based instructions and uses a voice model that is trained based on aggregated voice to select content items through a real-time content selection process performed by the content selector component. The voice-based input can be processed. The data processing system sends the selected content item to the client computing device to have a communication session between the client computing device and the third-party provider device associated with the selected content item. You can start. The data processing system can monitor or receive information about the communication session, measure the characteristics of the communication session, and generate quality signals. The data processing system can then adjust or control the content selector component based on the quality signal to influence the real-time content selection process.
図１は、コンピュータネットワーク上のデータ送信のための例示的なフィードバック制御システム１００を示す。システム１００はコンテンツ選択インフラを含むことができる。システム１００はデータ処理システム１０２を含むことができる。データ処理システム１０２はネットワーク１０５を介してコンテンツプロバイダコンピューティングデバイス１０６、サービスプロバイダコンピューティングデバイス１０８、またはクライアントコンピューティングデバイス１０４の１つまたは複数と通信することができる。ネットワーク１０５は、インターネット、ローカル・エリア・ネットワーク、広域ネットワーク、メトロポリタン・ネットワーク、または他の領域ネットワーク、イントラネット、衛星ネットワーク、および音声またはデータモバイル電話ネットワークのような他の通信ネットワークのようなコンピュータネットワークを含むことができる。ネットワーク１０５を、ラップトップ、デスクトップ、タブレット、携帯情報端末、スマートフォン、ポータブルコンピュータ、またはスピーカのような少なくとも１つのコンピューティングデバイス１０４に提供、出力、描画、または表示できる、ウェブページ、ウェブサイト、ドメイン名、またはユニフォーム・リソース・ロケータのような情報リソースにアクセスするために使用することができる。例えば、ネットワーク１０５を介してコンピューティングデバイス１０４のユーザは、サービスプロバイダ１０８またはコンテンツプロバイダ１０６により提供された情報またはデータにアクセスすることができる。 FIG. 1 shows an exemplary feedback control system 100 for data transmission over a computer network. The system 100 can include a content selection infrastructure. The system 100 can include a data processing system 102. The data processing system 102 can communicate with one or more of the content provider computing device 106, the service provider computing device 108, or the client computing device 104 via the network 105. Network 105 includes computer networks such as the Internet, local area networks, wide area networks, metropolitan networks, or other area networks, intranets, satellite networks, and other communication networks such as voice or data mobile telephone networks. Can include. Web pages, websites, domains that can provide, output, draw, or display network 105 to at least one computing device 104 such as laptops, desktops, tablets, personal digital assistants, smartphones, portable computers, or speakers. It can be used to access information resources such as names, or uniform resource locators. For example, the user of the computing device 104 can access the information or data provided by the service provider 108 or the content provider 106 via the network 105.
ネットワーク１０５は、コンテンツ配置または検索エンジン結果システムに関連付けられるか、または、サードパーティコンテンツ・アイテムをコンテンツ・アイテム配置キャンペーンの一部として含む権利があるディスプレイネットワーク、例えば、インターネット上で利用可能な情報リソースのサブセットを含むかまたは構成することができる。ネットワーク１０５を、クライアントコンピューティングデバイス１０４により提供、出力、描画、または表示できるウェブページ、ウェブサイト、ドメイン名、またはユニフォーム・リソース・ロケータのような情報リソースにアクセスするためにデータ処理システム１０２により使用することができる。例えば、ネットワーク１０５を介してクライアントコンピューティングデバイス１０４のユーザは、コンテンツプロバイダコンピューティングデバイス１０６またはサービスプロバイダコンピューティングデバイス１０８により提供された情報またはデータにアクセスすることができる。 Network 105 is a display network that is associated with a content placement or search engine results system or is entitled to include third-party content items as part of a content item placement campaign, eg, information resources available on the Internet. Can contain or configure a subset of. The network 105 is used by the data processing system 102 to access information resources such as web pages, websites, domain names, or uniform resource locators that can be provided, output, drawn, or displayed by the client computing device 104. can do. For example, the user of the client computing device 104 can access the information or data provided by the content provider computing device 106 or the service provider computing device 108 via the network 105.
ネットワーク１０５は、任意のタイプまたは形態のネットワークであってもよく、ポイント・ツー・ポイントネットワーク、ブロードキャストネットワーク、広帯域ネットワーク、ローカル・エリア・ネットワーク、電気通信ネットワーク、データ通信ネットワーク、コンピュータネットワーク、ＡＴＭ（Asynchronous Transfer Mode）ネットワーク、ＳＯＮＥＴ（Synchronous Optical Network）ネットワーク、ＳＤＨ（Synchronous Digital Hierarchy）ネットワーク、ワイヤレスネットワークおよび有線ネットワークのうち何れかを含んでもよい。ネットワーク１０５は赤外線チャネルまたは衛星帯域のような無線リンクを含んでもよい。ネットワーク１０５のトポロジはバス、星形、またはリング・ネットワークトポロジを含んでもよい。当該ネットワークは、高度携帯電話プロトコル（「ＡＭＰＳ」）、時分割多重アクセス（「ＴＤＭＡ」）、符号分割多重アクセス（「ＣＤＭＡ」）、グローバル・システム・フォー・モバイル・コミュニケーション（「ＧＳＭ(登録商標)」）、汎用パケット無線サービス（「ＧＰＲＳ」）またはユニバーサル・モバイル電気通信システム（「ＵＭＴＳ」）を含む、モバイルデバイスの間で通信するために使用される任意の１つまたは複数のプロトコルを用いた携帯電話ネットワークを含んでもよい。様々なタイプのデータが異なるプロトコルを介して送信されてもよい、または同一のタイプのデータが異なるプロトコルを介して送信されてもよい。 The network 105 may be any type or form of network, including point-to-point networks, broadcast networks, broadband networks, local area networks, telecommunications networks, data communications networks, computer networks, and ATMs (Asynchronous). Any one of Transfer Mode (Transfer Mode) network, SONET (Synchronous Optical Network) network, SDH (Synchronous Digital Hierarchy) network, wireless network and wired network may be included. The network 105 may include wireless links such as infrared channels or satellite bands. The network 105 topology may include a bus, star, or ring network topology. The network includes Advanced Mobile Phone Protocol (“AMPS”), Time Division Multiple Access (“TDMA”), Code Division Multiple Access (“CDMA”), and Global System for Mobile Communication (“GSM®”). ”), Using any one or more protocols used to communicate between mobile devices, including general packet radio service (“GPRS”) or universal mobile telecommunications (“UMTS”). It may include a mobile phone network. Different types of data may be transmitted via different protocols, or the same type of data may be transmitted via different protocols.
システム１００は少なくとも１つのデータ処理システム１０２を含むことができる。データ処理システム１０２は、ネットワーク１０５を介して、例えばコンピューティングデバイス１０４、コンテンツプロバイダデバイス１０６（コンテンツプロバイダ１０６）、またはサービスプロバイダデバイス１０８（またはサービスプロバイダ１０８）と通信するためのプロセッサを有するコンピューティングデバイスのような少なくとも１つの論理デバイスを含むことができる。データ処理システム１０２は、少なくとも１つの計算リソース、サーバ、プロセッサまたはメモリを含むことができる。例えば、データ処理システム１０２は少なくとも１つのデータセンタに配置された複数の計算リソースまたはサーバを含むことができる。データ処理システム１０２は、複数の、論理的にグループ化されたサーバを含むことができ、分散コンピューティング技術を促進する。サーバの当該論理グループをデータセンタ、サーバ・ファームまたはマシン・ファームと称してもよい。当該サーバはまた、地理的に分散されることができる。データセンタまたはマシン・ファームを単一のエンティティとして管理してもよく、または当該マシン・ファームは複数のマシン・ファームを含むことができる。各マシン・ファーム内の当該サーバは不均一であることができる。即ち、当該サーバまたはマシンのうち１つまたは複数が１つまたは複数のタイプのオペレーティング・システムプラットフォームに従って動作することができる。 The system 100 can include at least one data processing system 102. The data processing system 102 is a computing device having a processor for communicating with, for example, a computing device 104, a content provider device 106 (content provider 106), or a service provider device 108 (or service provider 108) via a network 105. Can include at least one logical device such as. The data processing system 102 can include at least one computational resource, server, processor or memory. For example, the data processing system 102 can include a plurality of computational resources or servers located in at least one data center. The data processing system 102 can include a plurality of logically grouped servers, facilitating distributed computing technology. The logical group of servers may be referred to as a data center, server farm or machine farm. The servers can also be geographically dispersed. A data center or machine farm may be managed as a single entity, or the machine farm can contain multiple machine farms. The server in each machine farm can be non-uniform. That is, one or more of the servers or machines can operate according to one or more types of operating system platforms.
当該マシン・ファーム内のサーバを、関連付けられた記憶システムとともに高密度ラック・システムに格納でき、エンタープライズデータセンタに配置することができる。例えば、当該サーバをこのように統合することで当該システムのシステム管理可能性、データセキュリティ、物理セキュリティを高めることができ、高性能ネットワーク上にサーバおよび高性能記憶システムを配置することでシステム性能を高めることができる。サーバおよび記憶システムを含むデータ処理システム１０２コンポーネントの全部または一部の集約化は、それらを高度なシステム管理ツールと組み合わせることで、サーバリソースのより効率的な利用を可能とし、これは電力および処理要件を節約し帯域幅利用を減らす。 The servers in the machine farm can be stored in a high-density rack system with an associated storage system and can be located in an enterprise data center. For example, by integrating the servers in this way, the system manageability, data security, and physical security of the system can be enhanced, and by arranging the servers and high-performance storage systems on a high-performance network, the system performance can be improved. Can be enhanced. Aggregation of all or part of the data processing system 102 components, including servers and storage systems, allows them to be combined with advanced system management tools to enable more efficient use of server resources, which is power and processing. Save requirements and reduce bandwidth usage.
システム１００は、少なくとも１つのサービスプロバイダデバイス１０８を含み、それにアクセスし、または対話することができる。サービスプロバイダデバイス１０８は、ネットワーク１０５を介して例えばコンピューティングデバイス１０４、データ処理システム１０２、またはコンテンツプロバイダ１０６と通信するためのプロセッサを有するコンピューティングデバイスのような少なくとも１つの論理デバイスを含むことができる。サービスプロバイダデバイス１０８は、少なくとも１つの計算リソース、サーバ、プロセッサまたはメモリを含むことができる。例えば、サービスプロバイダデバイス１０８は少なくとも１つのデータセンタに配置された複数の計算リソースまたはサーバを含むことができる。サービスプロバイダデバイス１０８はデータ処理システム１０２の１つまたは複数のコンポーネントまたは機能を含むことができる。 System 100 includes at least one service provider device 108, which can be accessed or interacted with. The service provider device 108 can include at least one logical device, such as a computing device 104, a data processing system 102, or a computing device having a processor for communicating with the content provider 106 over the network 105. .. The service provider device 108 can include at least one compute resource, server, processor or memory. For example, the service provider device 108 can include a plurality of compute resources or servers located in at least one data center. The service provider device 108 may include one or more components or functions of the data processing system 102.
コンテンツプロバイダコンピューティングデバイス１０６は、クライアントコンピューティングデバイス１０４により表示するためのオーディオベースのコンテンツ・アイテムを、オーディオ出力コンテンツ・アイテムとして提供することができる。当該コンテンツ・アイテムは「Would you like me to order you a taxi?」と述べる音声ベースのメッセージのような商品またはサービスの申し出を含むことができる。例えば、コンテンツプロバイダコンピューティングデバイス１５５は、音声ベースのクエリに応答して提供できる一連のオーディオコンテンツ・アイテムを格納するためのメモリを含むことができる。コンテンツプロバイダコンピューティングデバイス１０６はまた、オーディオベースのコンテンツ・アイテム（または他のコンテンツ・アイテム）をデータ処理システム１０２に提供することができる。それらをデータリポジトリ１２４に格納することができる。データ処理システム１０２は当該オーディオコンテンツ・アイテムを選択し、当該オーディオコンテンツ・アイテムをクライアントコンピューティングデバイス１０４に提供する（または提供するようにコンテンツプロバイダコンピューティングデバイス１０４に指示する）ことができる。当該オーディオベースのコンテンツ・アイテムは、排他的にオーディオであることができ、または、テキスト、画像、またはビデオデータと組み合わせることができる。 The content provider computing device 106 can provide an audio-based content item for display by the client computing device 104 as an audio output content item. The content item may include an offer for goods or services, such as a voice-based message stating "Would you like me to order you a taxi?". For example, the content provider computing device 155 may include memory for storing a set of audio content items that can be provided in response to voice-based queries. The content provider computing device 106 can also provide audio-based content items (or other content items) to the data processing system 102. They can be stored in the data repository 124. The data processing system 102 can select the audio content item and provide (or instruct the content provider computing device 104 to provide) the audio content item to the client computing device 104. The audio-based content item can be exclusively audio or can be combined with text, images, or video data.
サービスプロバイダデバイス１０８はインタフェースを含むことができ、または少なくとも１つのサービスプロバイダ自然言語プロセッサコンポーネント１４２およびサービスプロバイダインタフェース１４４と通信することができる。サービスプロバイダコンピューティングデバイス１０８は、少なくとも１つのサービスプロバイダ自然言語プロセッサ（ＮＬＰ）コンポーネント１４２および少なくとも１つのサービスプロバイダインタフェース１４４を含むことができる。サービスプロバイダＮＬＰコンポーネント１４２（またはサービスプロバイダコンピューティングデバイス１０８のダイレクト・アクションＡＰＩのような他のコンポーネント）は、クライアントコンピューティングデバイス１０４と（データ処理システム１０２を介してまたはデータ処理システム１０２をバイパスして）協働して、クライアントコンピューティングデバイス１０４およびサービスプロバイダコンピューティングデバイス１０８の間の行き来するリアルタイム音声またはオーディオベースの会話（例えば、セッション）を生成することができる。サービスプロバイダＮＬＰ１４２はデータ処理システム１０２のＮＬＰコンポーネント１１２としての１つまたは複数の機能または特徴を含むことができる。例えば、サービスプロバイダインタフェース１４４はデータメッセージを受信またはデータ処理システム１０２のダイレクト・アクションＡＰＩ１１６に提供することができる。サービスプロバイダコンピューティングデバイス１０８およびコンテンツプロバイダコンピューティングデバイス１０６を同一のエンティティに関連付けることができる。例えば、コンテンツプロバイダコンピューティングデバイス１０６はカーシェア・サービスに対して利用可能なコンテンツ・アイテムを生成、格納、または作成でき、サービスプロバイダコンピューティングデバイス１０８はクライアントコンピューティングデバイス１０６とのセッションを確立してクライアントコンピューティングデバイス１０４のエンド・ユーザをピックアップするためのタクシーまたはカーシェア・サービスの車の配送をアレンジすることができる。データ処理システム１０２、ダイレクト・アクションＡＰＩ１１６を介して、ＮＬＰコンポーネント１１２または他のコンポーネントはまた、当該クライアントコンピューティングデバイスとのセッションを確立し、サービスプロバイダコンピューティングデバイス１０４を含むかまたはバイパスして、例えばタクシーまたは当該カーシェア・サービスの車の配送をアレンジすることができる。 The service provider device 108 can include an interface or can communicate with at least one service provider natural language processor component 142 and a service provider interface 144. The service provider computing device 108 can include at least one service provider natural language processor (NLP) component 142 and at least one service provider interface 144. The service provider NLP component 142 (or other component, such as the direct action API of the service provider computing device 108), and the client computing device 104 (via or bypassing the data processing system 102). ) Can work together to generate back and forth real-time voice or audio-based conversations (eg, sessions) between the client computing device 104 and the service provider computing device 108. The service provider NLP 142 may include one or more functions or features as the NLP component 112 of the data processing system 102. For example, the service provider interface 144 can receive a data message or provide it to the direct action API 116 of the data processing system 102. The service provider computing device 108 and the content provider computing device 106 can be associated with the same entity. For example, the content provider computing device 106 can generate, store, or create content items available for the car sharing service, and the service provider computing device 108 establishes a session with the client computing device 106. A taxi or car sharing service car delivery can be arranged to pick up the end user of the client computing device 104. Through the data processing system 102, the direct action API 116, the NLP component 112 or other component also establishes a session with the client computing device and includes or bypasses the service provider computing device 104, eg. Delivery of taxis or cars of the car-sharing service can be arranged.
コンピューティングデバイス１０４は、インタフェースを含むことができ、または少なくとも１つのセンサ１３４、トランスデューサ１３６、オーディオドライバ１３８、またはプリプロセッサ１４０と通信することができる。センサ１３４は、例えば、周辺光センサ、近接性センサ、温度センサ、加速度計、ジャイロスコープ、動き検出器、ＧＰＳセンサ、位置センサ、マイクロフォン、またはタッチセンサを含むことができる。トランスデューサ１３６はスピーカまたはマイクロフォンを含むことができる。オーディオドライバ１３８はソフトウェアインタフェースをハードウェアトランスデューサ１３６に提供することができる。当該オーディオドライバはデータ処理システム１０２により提供されたオーディオファイルまたは他の命令を実行して、対応する音波または音波を生成するようにトランスデューサ１３６を制御することができる。プリプロセッサ１４０を、キーワードを検出し当該キーワードに基づいてアクションを実施するように構成することができる。プリプロセッサ１４０は、１つまたは複数の用語をフィルタするか、または、当該用語を、さらなる処理のために当該用語をデータ処理システム１０２に送信する前に修正することができる。プリプロセッサ１４０は当該マイクロフォンにより検出されたアナログオーディオ信号をデジタルオーディオ信号に変換し、ネットワーク１０５を介して、当該デジタルオーディオ信号を運搬する１つまたは複数のデータパケットをデータ処理システム１０２に送信することができる。幾つかのケースでは、プリプロセッサ１４０は、かかる送信を実施するための命令を検出したことに応答して、当該入力オーディオ信号の一部または全部を運搬するデータパケットを送信することができる。当該命令は、例えば、当該入力オーディオ信号を含むデータパケットをデータ処理システム１０２に送信するためのトリガキーワードまたは他のキーワードまたは承認を含むことができる。 The computing device 104 can include an interface or can communicate with at least one sensor 134, a transducer 136, an audio driver 138, or a preprocessor 140. The sensor 134 can include, for example, an ambient light sensor, a proximity sensor, a temperature sensor, an accelerometer, a gyroscope, a motion detector, a GPS sensor, a position sensor, a microphone, or a touch sensor. Transducer 136 can include a speaker or a microphone. The audio driver 138 can provide a software interface to the hardware transducer 136. The audio driver can execute the audio file or other instruction provided by the data processing system 102 to control the transducer 136 to produce the corresponding sound wave or sound wave. The preprocessor 140 can be configured to detect a keyword and perform an action based on that keyword. The preprocessor 140 can filter one or more terms, or modify the terms before sending them to the data processing system 102 for further processing. The preprocessor 140 may convert the analog audio signal detected by the microphone into a digital audio signal and transmit one or more data packets carrying the digital audio signal to the data processing system 102 via the network 105. it can. In some cases, the preprocessor 140 may transmit a data packet carrying some or all of the input audio signal in response to detecting an instruction to perform such transmission. The instruction may include, for example, a trigger keyword or other keyword or approval for transmitting a data packet containing the input audio signal to the data processing system 102.
クライアントコンピューティングデバイス１０４をエンド・ユーザに関連付けることができる。当該エンド・ユーザは、（センサ１３４を介して）音声クエリをオーディオ入力としてクライアントコンピューティングデバイス１０４に入力し、データ処理システム１０２（またはコンテンツプロバイダコンピューティングデバイス１０６またはサービスプロバイダコンピューティングデバイス１０８）からクライアントコンピューティングデバイス１０４に、トランスデューサ１３６（例えば、スピーカ）からの出力を提供できる、コンピュータ生成された音声の形でオーディオ出力を受信する。当該コンピュータ生成された音声は実際の人またはコンピュータ生成された言語からの記録を含むことができる。 The client computing device 104 can be associated with the end user. The end user inputs a voice query (via the sensor 134) as audio input to the client computing device 104 from the data processing system 102 (or content provider computing device 106 or service provider computing device 108) to the client. The computing device 104 receives the audio output in the form of computer-generated audio that can provide the output from the transducer 136 (eg, speaker). The computer-generated audio may include recordings from a real person or computer-generated language.
データリポジトリ１２４は１つまたは複数のローカルまたは分散データベースを含むことができ、データベース管理システムを含むことができる。データリポジトリ１２４はコンピュータデータ記憶またはメモリを含むことができ、他のデータのうち１つまたは複数のパラメータ１２６、１つまたは複数のポリシ１２８、コンテンツデータ１３０、またはテンプレート１３２を格納することができる。パラメータ１２６、ポリシ１２８、およびテンプレート１３２は、音声ベースのセッションに関するルールクライアントコンピューティングデバイス１０４およびデータ処理システム１０２（またはサービスプロバイダコンピューティングデバイス１０８）の間のような情報を含むことができる。コンテンツデータ１３０は、オーディオ出力に対するコンテンツ・アイテムまたは関連付けられたメタデータ、ならびにクライアントコンピューティングデバイス１０４との１つまたは複数の通信セッションの一部でありうる入力オーディオメッセージを含むことができる。 The data repository 124 can include one or more local or distributed databases and can include a database management system. The data repository 124 can include computer data storage or memory and can store one or more parameters 126, one or more policies 128, content data 130, or template 132 of other data. Parameters 126, policies 128, and template 132 can include information such as between the rules client computing device 104 and the data processing system 102 (or service provider computing device 108) for voice-based sessions. Content data 130 can include content items or associated metadata for audio output, as well as input audio messages that can be part of one or more communication sessions with the client computing device 104.
データ処理システム１０２は少なくとも１つの計算リソースまたはサーバを有するコンテンツ配置システムを含むことができる。データ処理システム１０２は、インタフェースを含むことができ、または少なくとも１つのインタフェース１１０と通信することができる。データ処理システム１０２は、インタフェースを含むことができ、または少なくとも１つの自然言語プロセッサコンポーネント１１２と通信することができる。データ処理システム１０２は、インタフェースを含むことができ、または少なくとも１つのダイレクト・アクションアプリケーションプログラミングインタフェース（「ＡＰＩ」）１１６と通信することができる。データ処理システム１０２は、インタフェースを含むことができ、または少なくとも１つのセッションハンドラ１１４と通信することができる。データ処理システム１０２は、インタフェースを含むことができ、または少なくとも１つのコンテンツセレクタコンポーネント１１８と通信することができる。データ処理システム１０２は、インタフェースを含むことができ、または少なくとも１つのフィードバックモニタコンポーネント１２０と通信することができる。データ処理システム１０２は、インタフェースを含むことができ、または少なくとも１つのオーディオ信号ジェネレータ１２２と通信することができる。データ処理システム１０２は、インタフェースを含むことができ、または少なくとも１つのデータリポジトリ１２４と通信することができる。少なくとも１つのデータリポジトリ１２４は、１つまたは複数のデータ構造またはデータベースに、パラメータ１２６、ポリシ１２８、コンテンツデータ１３０、またはテンプレート１３２を含むかまたは格納することができる。パラメータ１２６は、例えば、閾値、距離、時間間隔、期間、スコア、または重みを含むことができる。コンテンツデータ１３０は、例えば、コンテンツキャンペーン情報、コンテンツグループ、コンテンツ選択基準、コンテンツ・アイテム・オブジェクトまたはコンテンツプロバイダ１０６により提供されたまたはコンテンツ選択を促進するためにデータ処理システムにより取得または決定された他の情報を含むことができる。コンテンツデータ１３０は、例えば、コンテンツキャンペーンの履歴性能を含むことができる。 The data processing system 102 can include a content placement system having at least one computational resource or server. The data processing system 102 can include interfaces or can communicate with at least one interface 110. The data processing system 102 can include an interface or can communicate with at least one natural language processor component 112. The data processing system 102 can include an interface or can communicate with at least one direct action application programming interface (“API”) 116. The data processing system 102 can include an interface or can communicate with at least one session handler 114. The data processing system 102 can include an interface or can communicate with at least one content selector component 118. The data processing system 102 can include an interface or can communicate with at least one feedback monitor component 120. The data processing system 102 can include an interface or can communicate with at least one audio signal generator 122. The data processing system 102 can include an interface or can communicate with at least one data repository 124. At least one data repository 124 may include or store parameters 126, policies 128, content data 130, or templates 132 in one or more data structures or databases. Parameter 126 can include, for example, threshold, distance, time interval, duration, score, or weight. Content data 130 may be, for example, content campaign information, content groups, content selection criteria, content item objects or other content provided or determined by a data processing system to facilitate content selection. Information can be included. The content data 130 can include, for example, the history performance of the content campaign.
インタフェース１１０、自然言語プロセッサコンポーネント１１２、セッションハンドラ１１４、ダイレクト・アクションＡＰＩ１１６、コンテンツセレクタコンポーネント１１８、フィードバックモニタコンポーネント１２０、またはオーディオ信号ジェネレータコンポーネント１２２はそれぞれ、プログラム可能論理アレイエンジンのような少なくとも１つの処理ユニットまたは他の論理デバイス、またはデータベースリポジトリまたはデータベース１２４と通信するように構成されたモジュールを含むことができる。インタフェース１１０、自然言語プロセッサコンポーネント１１２、セッションハンドラ１１４、ダイレクト・アクションＡＰＩ１１６、コンテンツセレクタコンポーネント１１８、フィードバックモニタコンポーネント１２０、オーディオ信号ジェネレータコンポーネント１２２およびデータリポジトリ１２４は別々のコンポーネント、単一のコンポーネント、またはデータ処理システム１０２の一部であることができる。データ処理システム１０２のようなシステム１００およびそのコンポーネント、は１つまたは複数のプロセッサ、論理デバイス、または回路のようなハードウェア要素を含むことができる。 The interface 110, natural language processor component 112, session handler 114, direct action API 116, content selector component 118, feedback monitor component 120, or audio signal generator component 122 each is at least one processing unit, such as a programmable logical array engine. Alternatively, it can include other logical devices, or modules configured to communicate with the database repository or database 124. The interface 110, natural language processor component 112, session handler 114, direct action API 116, content selector component 118, feedback monitor component 120, audio signal generator component 122 and data repository 124 are separate components, a single component, or data processing. It can be part of system 102. The system 100 and its components, such as the data processing system 102, can include hardware elements such as one or more processors, logical devices, or circuits.
データ処理システム１０２は複数のコンピューティングデバイス１０４に関連付けられた匿名コンピュータネットワーク活動情報を取得することができる。コンピューティングデバイス１０４のユーザは、データ処理システム１０２を肯定的に認証してユーザのコンピューティングデバイス１０４に対応するネットワーク活動情報を取得することができる。例えば、データ処理システム１０２は１つまたは複数のタイプのネットワーク活動情報を取得することに対する同意に関してコンピューティングデバイス１０４のユーザを促すことができる。コンピューティングデバイス１０４のユーザのアイデンティティは匿名のままであってもよくコンピューティングデバイス１０４を、一意な識別子（例えば、データ処理システムまたは当該コンピューティングデバイスのユーザにより提供された当該コンピューティングデバイスの一意な識別子）に関連付けることができる。データ処理システムは各観測を対応する一意な識別子に関連付けることができる。 The data processing system 102 can acquire anonymous computer network activity information associated with the plurality of computing devices 104. The user of the computing device 104 can positively authenticate the data processing system 102 to obtain network activity information corresponding to the user's computing device 104. For example, the data processing system 102 can prompt the user of the computing device 104 for consent to acquire one or more types of network activity information. The identity of the user of the computing device 104 may remain anonymous, giving the computing device 104 a unique identifier (eg, a unique identifier for the computing device provided by the data processing system or the user of the computing device). It can be associated with an identifier). The data processing system can associate each observation with a corresponding unique identifier.
コンテンツプロバイダ１０６は電子コンテンツキャンペーンを確立することができる。当該電子コンテンツキャンペーンをコンテンツデータ１３０としてデータリポジトリ１２４に格納することができる。電子コンテンツキャンペーンは、共通のテーマに対応する１つまたは複数のコンテンツグループを指すことができる。コンテンツキャンペーンは、コンテンツグループ、コンテンツ・アイテムデータオブジェクト、およびコンテンツ選択基準を含む階層的データ構造を含むことができる。コンテンツキャンペーンを生成するために、コンテンツプロバイダ１０６は、当該コンテンツキャンペーンのキャンペーンレベルパラメータの値を指定することができる。当該キャンペーンレベルパラメータは、例えば、キャンペーン名、コンテンツ・アイテム・オブジェクトを配置するための好適なコンテンツネットワーク、当該コンテンツキャンペーンに使用されるリソースの値、当該コンテンツキャンペーンの開始日と終了日、当該コンテンツキャンペーンの期間、コンテンツ・アイテム・オブジェクト配置のスケジュール、言語、地理的位置、コンテンツ・アイテム・オブジェクトを提供するコンピューティングデバイスのタイプを含むことができる。幾つかのケースでは、インプレッションは、コンテンツ・アイテム・オブジェクトがそのソース（例えば、データ処理システム１０２またはコンテンツプロバイダ１０６）からフェッチされたときを指すことができ、計測可能である。幾つかのケースでは、クリック詐欺の可能性のため、ロボット活動をインプレッションとしてフィルタし除外することができる。したがって、幾つかのケースでは、インプレッションはWebサーバからブラウザからのページ要求への応答の測定値を指すことができる、当該ページ要求はロボット活動およびエラーコードからフィルタされ、コンピューティングデバイス１０４に表示するためのコンテンツ・アイテム・オブジェクトを描画する機会にできるだけ近いポイントで記録される。幾つかのケースでは、インプレッションは視聴可能または可聴なインプレッションを指すことができる。例えば、当該コンテンツ・アイテム・オブジェクトは、少なくとも部分的に（例えば、２０％、３０％、３０％、４０％、５０％、６０％、７０％、またはそれ以上）クライアントコンピューティングデバイス１０４のディスプレイデバイスで視聴可能、またはコンピューティングデバイス１０４のスピーカ１３６を介して可聴である。クリックまたは選択は、可聴インプレッションへの音声応答、マウス・クリック、タッチ対話、ジェスチャ、振動、オーディオ対話、またはキーボードクリックのような当該コンテンツ・アイテム・オブジェクトとのユーザ対話を指すことができる。変換は、ユーザが、当該コンテンツ・アイテム・オブジェクトに関して所望のアクションをとったこと、例えば、製品またはサービスの購入、調査の完了、当該コンテンツ・アイテムに対応する物理的な店の訪問、または電子トランザクションの完了を指すことができる。 Content provider 106 can establish an electronic content campaign. The electronic content campaign can be stored in the data repository 124 as content data 130. An electronic content campaign can refer to one or more content groups that correspond to a common theme. Content campaigns can include a hierarchical data structure that includes content groups, content item data objects, and content selection criteria. To generate the content campaign, the content provider 106 can specify the value of the campaign level parameter of the content campaign. The campaign level parameters include, for example, the campaign name, a suitable content network for placing content item objects, the value of resources used for the content campaign, the start and end dates of the content campaign, and the content campaign. Period, schedule of content item object placement, language, geographic location, and type of computing device that provides the content item object. In some cases, the impression can refer to when the content item object is fetched from its source (eg, data processing system 102 or content provider 106) and is measurable. In some cases, robot activity can be filtered out as impressions due to the potential for click fraud. Therefore, in some cases, the impression can point to a measure of the response from the web server to the page request from the browser, which page request is filtered from the robot activity and error code and displayed on the computing device 104. Recorded at a point as close as possible to the opportunity to draw the content item object for. In some cases, impressions can refer to audible or audible impressions. For example, the content item object is at least partially (eg, 20%, 30%, 30%, 40%, 50%, 60%, 70%, or more) the display device of the client computing device 104. It can be viewed on or audible through the speaker 136 of the computing device 104. Clicks or selections can refer to user interactions with the content item object, such as voice responses to audible impressions, mouse clicks, touch interactions, gestures, vibrations, audio interactions, or keyboard clicks. The conversion is that the user has taken the desired action with respect to the content item object, eg, purchasing a product or service, completing an investigation, visiting a physical store corresponding to the content item, or an electronic transaction. Can point to the completion of.
コンテンツプロバイダ１０６はさらに、コンテンツキャンペーンに対する１つまたは複数のコンテンツグループを確立することができる。コンテンツグループは、１つまたは複数のコンテンツ・アイテム・オブジェクトおよびキーワード、単語、用語、フレーズ、地理的位置、コンピューティングデバイスのタイプ、日時、関心、トピック、または垂直線のような対応するコンテンツ選択基準を含む。同一のコンテンツキャンペーンのもとでのコンテンツグループは同一のキャンペーンレベルパラメータを共有できるが、キーワード、（例えば、メイン・コンテンツに対するネガティブなキーワードの存在下で当該コンテンツ・アイテムの配置をブロックする）ネガティブなキーワード、キーワードに対する入札、または当該入札またはコンテンツキャンペーンに関連付けられたパラメータのような特定のコンテンツグループレベルパラメータに対して仕様をカスタマイズしているかもしれない。 Content provider 106 can also establish one or more content groups for content campaigns. Content groups are one or more content item objects and corresponding content selection criteria such as keywords, words, terms, phrases, geographic locations, computing device types, dates, interests, topics, or vertical lines. including. Content groups under the same content campaign can share the same campaign level parameters, but are negative for keywords (eg, blocking the placement of content items in the presence of negative keywords for the main content). You may have customized specifications for specific content group-level parameters, such as keywords, bids for keywords, or parameters associated with such bids or content campaigns.
新たなコンテンツグループを生成するために、コンテンツプロバイダは、コンテンツグループのコンテンツグループレベルパラメータの値を提供することができる。当該コンテンツグループレベルパラメータは、例えば、コンテンツグループの名前またはコンテンツグループのテーマ、および異なるコンテンツ配置の機会（例えば、自動配置または管理された配置）に対する入札または結果（例えば、クリック、インプレッション、または変換）を含む。コンテンツグループの名前またはコンテンツグループのテーマはコンテンツプロバイダ１０６が当該コンテンツグループのどのコンテンツ・アイテム・オブジェクトが表示のために選択されるべきかに対するトピックまたは主題をキャプチャするために使用できる、１つまたは複数の用語であることができる。例えば、カー・ディーラーは、それが有する車のブランドごとに異なるコンテンツグループを生成でき、さらに、それが有する車のモデルごとに異なるコンテンツグループを生成してもよい。当該カー・ディーラーが使用できるコンテンツグループテーマの例には、例えば、「Make A sports car」「Make B sports car」、「Make C sedan」、「Make C truck」、「Make C hybrid」、または「Make D hybrid」が含まれる。例示的なコンテンツキャンペーンテーマは「ハイブリッド」であることができ、例えば「Make C hybrid」および「Make D hybrid」の両方に対するコンテンツグループを含む。 To generate a new content group, the content provider can provide values for the content group level parameters of the content group. The content group level parameters are, for example, the name of the content group or the theme of the content group, and bids or results (eg, clicks, impressions, or transformations) for different content placement opportunities (eg, automatic placement or managed placement). including. The name of the content group or the theme of the content group can be used by the content provider 106 to capture a topic or subject for which content item object of the content group should be selected for display. Can be the term. For example, a car dealer may generate different content groups for each brand of car it has, and may also generate different content groups for each model of car it has. Examples of content group themes available to the car dealer include, for example, "Make A sports car," "Make B sports car," "Make C sedan," "Make C truck," "Make C hybrid," or "Make C hybrid." "Make D hybrid" is included. An exemplary content campaign theme can be "hybrid" and includes content groups for both "Make C hybrid" and "Make D hybrid", for example.
コンテンツプロバイダ１０６は、１つまたは複数のキーワードおよびコンテンツ・アイテム・オブジェクトを各コンテンツグループに提供することができる。キーワードは、当該コンテンツ・アイテム・オブジェクトに関連付けられるかまたは識別された製品またはサービスに関連する用語を含むことができる。キーワードは１つまたは複数の用語またはフレーズを含むことができる。例えば、カー・ディーラーはコンテンツグループまたはコンテンツキャンペーンのためのキーワードとして、「スポーツカー」、「Ｖ６エンジン」、「四輪駆動」、「燃料効率」、を含むことができる。幾つかのケースでは、ネガティブなキーワードを、特定の用語またはキーワードに対するコンテンツ配置を回避、防止、ブロック、または無効にするためにコンテンツプロバイダにより指定することができる。コンテンツプロバイダは、コンテンツ・アイテム・オブジェクトを選択するために使用される厳密なマッチ、フレーズマッチ、または広義のマッチのようなマッチングのタイプを指定することができる。 Content provider 106 may provide one or more keywords and content item objects to each content group. Keywords can include terms related to the product or service associated with or identified with the content item object. Keywords can include one or more terms or phrases. For example, a car dealer can include "sports car," "V6 engine," "four-wheel drive," and "fuel efficiency" as keywords for a content group or content campaign. In some cases, negative keywords can be specified by the content provider to avoid, prevent, block, or disable content placement for a particular term or keyword. Content providers can specify the type of match, such as exact match, phrase match, or broad match used to select a content item object.
コンテンツプロバイダ１０６は、コンテンツプロバイダ１０６により提供されたコンテンツ・アイテム・オブジェクトを選択するためにデータ処理システム１０２により使用される１つまたは複数のキーワードを提供することができる。コンテンツプロバイダ１０６は、入札する１つまたは複数のキーワードを識別でき、さらに様々なキーワードに対する入札量を提供することができる。コンテンツプロバイダ１０６は、コンテンツ・アイテム・オブジェクトを選択するためにデータ処理システム１０２により使用される追加のコンテンツ選択基準を提供することができる。複数のコンテンツプロバイダ１０６は同一のまたは異なるキーワードに入札でき、データ処理システム１０２は、電子メッセージのキーワードの指示を受信したことに応答して、コンテンツ選択プロセスまたは広告オークションを実行することができる。 The content provider 106 may provide one or more keywords used by the data processing system 102 to select the content item object provided by the content provider 106. Content provider 106 can identify one or more keywords to bid on and can provide bid volumes for various keywords. Content provider 106 can provide additional content selection criteria used by the data processing system 102 to select content item objects. The plurality of content providers 106 can bid on the same or different keywords, and the data processing system 102 can execute the content selection process or the advertisement auction in response to receiving the instruction of the keyword of the electronic message.
コンテンツプロバイダ１０６は、データ処理システム１０２により選択するための１つまたは複数のコンテンツ・アイテム・オブジェクトを提供することができる。データ処理システム１０２（例えば、コンテンツセレクタコンポーネント１１８を介して）はリソース位置、コンテンツスケジュール、最大入札、キーワード、およびコンテンツグループに対して指定された他の選択基準にマッチするコンテンツ配置機会が利用可能になったとき、当該コンテンツ・アイテム・オブジェクトを選択することができる。様々なタイプのコンテンツ・アイテム・オブジェクトは、音声コンテンツ・アイテム、オーディオコンテンツ・アイテム、テキストコンテンツ・アイテム、画像コンテンツ・アイテム、ビデオコンテンツ・アイテム、マルチメディアコンテンツ・アイテム、またはコンテンツ・アイテムリンクのようなコンテンツグループに含まれることができる。コンテンツ・アイテムを選択すると、データ処理システム１０２は、コンピューティングデバイス１０４またはコンピューティングデバイス１０４のディスプレイデバイスに描画するために当該コンテンツ・アイテム・オブジェクトを送信することができる。描画は、当該コンテンツ・アイテムをディスプレイデバイスに表示すること、またはコンピューティングデバイス１０４のスピーカを介して当該コンテンツ・アイテムを再生することを含むことができる。データ処理システム１０２は、コンピューティングデバイス１０４への命令を、当該コンテンツ・アイテムを描画するオブジェクトに提供することができる。データ処理システム１０２は、オーディオ信号または音波を生成するように、コンピューティングデバイス１０４、またはコンピューティングデバイス１０４のオーディオドライバ１３８に指示することができる。 Content provider 106 may provide one or more content item objects for selection by the data processing system 102. Data processing system 102 (eg, via content selector component 118) makes available content placement opportunities that match resource locations, content schedules, maximum bids, keywords, and other selection criteria specified for content groups. When it becomes, the content item object can be selected. Various types of content item objects can be audio content items, audio content items, text content items, image content items, video content items, multimedia content items, or content item links. Can be included in content groups. When a content item is selected, the data processing system 102 can transmit the content item object for drawing to the computing device 104 or the display device of the computing device 104. Drawing can include displaying the content item on a display device or playing the content item through the speakers of the computing device 104. The data processing system 102 can provide an instruction to the computing device 104 to an object that draws the content item. The data processing system 102 can instruct the computing device 104, or the audio driver 138 of the computing device 104, to generate an audio signal or sound wave.
データ処理システム１０２は例えば、データパケットを用いて情報を送受信するように設計され、構成され、構築され、または動作するインタフェースコンポーネント１１０を含むことができる。インタフェース１１０は、ネットワークプロトコルのような１つまたは複数のプロトコルを用いて情報を送受信することができる。インタフェース１１０は、ハードウェアインタフェース、ソフトウェアインタフェース、有線インタフェース、またはワイヤレスインタフェースを含むことができる。インタフェース１１０は、或るフォーマットから別のフォーマットへのデータ変換またはデータ・フォーマットを促進することができる。例えば、インタフェース１１０は、ソフトウェアコンポーネントのような様々なコンポーネントの間で通信するための定義を含むアプリケーションプログラミングインタフェースを含むことができる。 The data processing system 102 can include, for example, an interface component 110 designed, configured, constructed, or operating to send and receive information using data packets. Interface 110 can send and receive information using one or more protocols, such as network protocols. The interface 110 can include a hardware interface, a software interface, a wired interface, or a wireless interface. Interface 110 can facilitate data conversion or data format from one format to another. For example, interface 110 can include an application programming interface that includes definitions for communicating between various components, such as software components.
データ処理システム１０２は、入力オーディオ信号をデータ処理システム１０２のインタフェース１１０に送信し当該クライアントコンピューティングデバイスのコンポーネントを駆動して、出力オーディオ信号を描画するためのアプリのようなクライアントコンピューティングデバイス１０４にインストールされたアプリケーション、スクリプトまたはプログラムを含むことができる。データ処理システム１０２はオーディオ入力信号を含むかまたは識別するデータパケットまたは他の信号を受信することができる。例えば、データ処理システム１０２は、ＮＬＰコンポーネント１１２を実行して、当該オーディオ信号を受信または取得し、当該オーディオ信号を解析することができる。例えば、ＮＬＰコンポーネント１１２は人間とコンピュータの間の対話を提供することができる。ＮＬＰコンポーネント１１２を、自然言語を理解しデータ処理システム１０２が人間または自然言語入力から意味を導出するための技術で構成することができる。ＮＬＰコンポーネント１１２は、統計的機械学習のような機械学習に基づく技術を含むことができるかまたはそれで構成することができる。ＮＬＰコンポーネント１１２は、決定木、統計的モデル、または確率論的モデルを利用して当該入力オーディオ信号を解析することができる。ＮＬＰコンポーネント１１２は、例えば、名前付きエンティティ認識（例えば、テキストのストリームが与えられると、当該テキスト内のどのアイテムを人または場所のような正確な名前にマップするか、および人、位置、または組織のような、各かかる名前がどんなタイプかを判定する）、自然言語生成（例えば、コンピュータデータベースまたはセマンティックな意図からの情報を理解可能な人間言語に変換する）、自然言語理解（例えば、コンピュータモジュールが操作できる１次論理構造のようなより形式的な表現にテキストを変換する）、マシン変換（例えば、自動的に或る人間の言語から別の人間の言語にテキストを翻訳する）、形態学的セグメンテーション（例えば、単語を独立な形態素に分離し当該形態素のクラスを識別する。これは、考慮されている言語の単語の形態学または構造の複雑性に基づいて困難なものでありうる）、質問回答（例えば、人間の言語の質問への回答を決定する。これは、特定的または制約なしであることができる）、セマンティック処理（例えば、識別された単語を、同様な意味を有する他の単語に関連付けるために単語を識別しその意味を符号化した後に発生しうる処理）のような機能を実施することができる。 The data processing system 102 transmits an input audio signal to the interface 110 of the data processing system 102 to drive a component of the client computing device to a client computing device 104 such as an application for drawing an output audio signal. It can contain installed applications, scripts or programs. The data processing system 102 can receive data packets or other signals that include or identify audio input signals. For example, the data processing system 102 can execute the NLP component 112 to receive or acquire the audio signal and analyze the audio signal. For example, the NLP component 112 can provide a human-computer interaction. The NLP component 112 can be constructed with techniques for understanding natural language and allowing the data processing system 102 to derive meaning from human or natural language input. The NLP component 112 can include or can be configured with machine learning based techniques such as statistical machine learning. The NLP component 112 can analyze the input audio signal using a decision tree, a statistical model, or a stochastic model. NLP component 112, for example, named entity recognition (eg, given a stream of text, which item in the text maps to an exact name such as person or place, and person, location, or organization. Determining what type each such name is, such as), natural language generation (eg, converting information from a computer database or semantic intent into an understandable human language), natural language understanding (eg, computer module). Converts text into more formal representations such as linear logical structures that can be manipulated), machine conversion (eg, automatically translates text from one human language to another), morphology Target segmentation (eg, separating a word into independent morphologies and identifying the class of that morphology, which can be difficult based on the morphological or structural complexity of the words in the language being considered), Question Answers (eg, determining the answer to a human language question, which can be specific or unconstrained), semantic processing (eg, identified words, other words with similar meanings) Functions such as (processing that can occur after identifying a word and encoding its meaning) to associate it with the word can be performed.
ＮＬＰコンポーネント１１２は、入力信号を（例えば、データリポジトリ１２４に）格納された、代表的な組のオーディオ波形に対して比較し最も近いマッチを選択することで、当該オーディオ入力信号を認識されたテキストに変換する。当該１組のオーディオ波形を、データ処理システム１０２にアクセス可能なデータリポジトリ１２４または他のデータベースに格納することができる。当該代表的な波形は大規模な１組のユーザにわたって生成され、次いでユーザからの会話サンプルで補強してもよい。当該オーディオ信号が認識されたテキストに変換された後、ＮＬＰコンポーネント１１２は、当該テキストを、関連付けられた、例えばユーザにわたるトレーニングを介してまたはマニュアル手動を通じて、データ処理システム１０２がサービス提供できるアクションに関連付けられた単語にマッチする。 The NLP component 112 recognizes the audio input signal by comparing the input signal with respect to a representative set of audio waveforms stored (eg, in the data repository 124) and selecting the closest match. Convert to. The set of audio waveforms can be stored in a data repository 124 or other database accessible to the data processing system 102. The representative waveform may be generated over a large set of users and then reinforced with conversation samples from the users. After the audio signal is converted to recognized text, the NLP component 112 associates the text with an associated action that the data processing system 102 can service, eg, through training across users or manually. Matches the word.
オーディオ入力信号はクライアントコンピューティングデバイス１０４のセンサ１３４またはトランスデューサ１３６（例えば、マイクロフォン）により検出されることができる。トランスデューサ１３６、オーディオドライバ１３８、または他のコンポーネントを介して、クライアントコンピューティングデバイス１０４は当該オーディオ入力信号をデータ処理システム１０２に（例えば、ネットワーク１０５を介して）提供することができる。それを、（例えば、インタフェース１１０により）受信でき、ＮＬＰコンポーネント１１２に提供するかまたはデータリポジトリ１２４に格納することができる。 The audio input signal can be detected by a sensor 134 or a transducer 136 (eg, a microphone) of the client computing device 104. Through the transducer 136, the audio driver 138, or other component, the client computing device 104 can provide the audio input signal to the data processing system 102 (eg, via the network 105). It can be received (eg, by interface 110) and provided to NLP component 112 or stored in the data repository 124.
ＮＬＰコンポーネント１１２は入力オーディオ信号を取得することができる。当該入力オーディオ信号から、ＮＬＰコンポーネント１１２は、少なくとも１つの要求または当該要求に対応する少なくとも１つのトリガキーワードを識別することができる。当該要求は当該入力オーディオ信号の意図または主題を示すことができる。当該トリガキーワードは行われる可能性があるアクションのタイプを示すことができる。例えば、ＮＬＰコンポーネント１１２は当該入力オーディオ信号を解析して、夕方に家を出てディナーおよび映画に参加する少なくとも１つの要求を識別することができる。当該トリガキーワードは、取るべきアクションを示す少なくとも１つの単語、フレーズ、語源または部分語、または派生物を含むことができる。例えば、当該入力オーディオ信号からのトリガキーワード「go」または「to go to」は輸送に対する必要性を示すことができる。本例では、当該入力オーディオ信号（または識別された要求）は輸送の意図を直接表現しないが、当該トリガキーワードは、輸送が当該要求により示される少なくとも１つの他のアクションに対する補完的アクションであることを示す。 The NLP component 112 can acquire the input audio signal. From the input audio signal, the NLP component 112 can identify at least one request or at least one trigger keyword corresponding to that request. The request can indicate the intent or subject of the input audio signal. The trigger keyword can indicate the type of action that may be taken. For example, NLP component 112 can analyze the input audio signal to identify at least one request to leave home in the evening to attend a dinner and a movie. The trigger keyword can include at least one word, phrase, etymology or subword, or derivative that indicates the action to be taken. For example, the trigger keyword "go" or "to go to" from the input audio signal can indicate the need for transport. In this example, the input audio signal (or identified request) does not directly represent the intent of transport, but the trigger keyword is that transport is a complementary action to at least one other action indicated by the request. Is shown.
ＮＬＰコンポーネント１１２は当該入力オーディオ信号を解析し、識別し、決定し、取り出し、または当該要求および当該トリガキーワードを取得することができる。例えば、ＮＬＰコンポーネント１１２は、セマンティック処理技術を当該入力オーディオ信号に適用して、当該トリガキーワードまたは当該要求を識別することができる。ＮＬＰコンポーネント１１２は、当該セマンティック処理技術を当該入力オーディオ信号に適用して、第１のトリガキーワードおよび第２のトリガキーワードのような１つまたは複数のトリガキーワードを含むトリガ・フレーズを識別することができる。例えば、当該入力オーディオ信号は「I need someone to do my laundry and my dry cleaning」という文章を含むことができる。ＮＬＰコンポーネント１１２は、セマンティック処理技術、または他の自然言語処理技術を、当該文章を含む当該データパケットに適用して、トリガ・フレーズ「do my laundry」および「do my dry cleaning」を識別することができる。ＮＬＰコンポーネント１１２はさらに、洗濯、およびドライ・クリーニングのような複数のトリガキーワードを識別することができる。例えば、ＮＬＰコンポーネント１１２は、当該トリガ・フレーズが当該トリガキーワードおよび第２のトリガキーワードを含むと判定することができる。 The NLP component 112 can analyze, identify, determine, retrieve, or obtain the request and the trigger keyword of the input audio signal. For example, NLP component 112 can apply semantic processing techniques to the input audio signal to identify the trigger keyword or the request. The NLP component 112 may apply the semantic processing technique to the input audio signal to identify a trigger phrase containing one or more trigger keywords, such as a first trigger keyword and a second trigger keyword. it can. For example, the input audio signal can include the sentence "I need someone to do my laundry and my dry cleaning". NLP component 112 may apply semantic processing technology, or other natural language processing technology, to the data packet containing the text to identify the trigger phrases "do my laundry" and "do my dry cleaning". it can. The NLP component 112 can further identify multiple trigger keywords such as washing and dry cleaning. For example, the NLP component 112 can determine that the trigger phrase includes the trigger keyword and a second trigger keyword.
ＮＬＰコンポーネント１１２は、入力オーディオ信号をフィルタしてトリガキーワードを識別することができる。例えば、当該入力オーディオ信号を運搬する当該データパケットは「It would be great if I could get someone that could help me go to the airport」を含むことができる。この場合ＮＬＰコンポーネント１１２は、「it」、「would」、「be」、「great」、「if」、「I」、「could」、「get」、「someone」、「that」、「could」、または「help」といった１つまたは複数の用語をフィルタして除去することができる。これらの用語をフィルタして除去することで、ＮＬＰコンポーネント１１２は、「go to the airport」のようなトリガキーワードをより正確におよび信頼性高く識別し、これがタクシーまたは乗車共有サービスの要求であると判定することができる。 The NLP component 112 can filter the input audio signal to identify the trigger keyword. For example, the data packet carrying the input audio signal can include "It would be great if I could get someone that could help me go to the airport". In this case, the NLP component 112 is "it", "would", "be", "great", "if", "I", "could", "get", "someone", "that", "could". , Or one or more terms such as "help" can be filtered out. By filtering out these terms, the NLP component 112 more accurately and reliably identifies trigger keywords such as "go to the airport," which is a request for a taxi or boarding sharing service. Can be determined.
幾つかのケースでは、ＮＬＰコンポーネントは、入力オーディオ信号を運搬するデータパケットが１つまたは複数の要求を含むと判定することができる。例えば、当該入力オーディオ信号は「I need someone to do my laundry and my dry cleaning」という文章を含むことができる。ＮＬＰコンポーネント１１２はこれが洗濯サービスおよびドライ・クリーニングサービスの要求であると判定することができる。ＮＬＰコンポーネント１１２は、これが、洗濯サービスおよびドライ・クリーニングサービスの両方を提供できるサービスプロバイダに対する単一の要求であると判定することができる。ＮＬＰコンポーネント１１２は、これが２つの要求、即ち、洗濯サービスを実施するサービスプロバイダに対する第１の要求、およびドライ・クリーニングサービスを提供するサービスプロバイダに対する第２の要求であると判定することができる。幾つかのケースでは、ＮＬＰコンポーネント１１２は、当該複数の決定された要求を単一の要求に結合し、当該単一の要求をサービスプロバイダデバイス１０８に送信することができる。幾つかのケースでは、ＮＬＰコンポーネント１１２は当該独立な要求を各サービスプロバイダデバイス１０８に送信するか、または別々に両方の要求を同一のサービスプロバイダデバイス１０８に送信することができる。 In some cases, the NLP component can determine that the data packet carrying the input audio signal contains one or more requests. For example, the input audio signal can include the sentence "I need someone to do my laundry and my dry cleaning". The NLP component 112 can determine that this is a requirement for laundry and dry cleaning services. The NLP component 112 can determine that this is a single request to a service provider capable of providing both laundry and dry cleaning services. The NLP component 112 can determine that this is two requirements, a first requirement for the service provider performing the laundry service and a second requirement for the service provider providing the dry cleaning service. In some cases, the NLP component 112 may combine the plurality of determined requests into a single request and send the single request to the service provider device 108. In some cases, the NLP component 112 may send the independent request to each service provider device 108, or both requests separately to the same service provider device 108.
データ処理システム１０２は、トリガキーワードに基づいて、当該要求に応答してアクションデータ構造を生成するように設計され構成されたダイレクト・アクションＡＰＩ１１６を含むことができる。データ処理システム１０２のプロセッサは、ダイレクト・アクションＡＰＩ１１６を起動して、カーシェア・サービスからの車のようなサービスまたは製品を要求または注文するためのサービスプロバイダデバイス１０８に対するデータ構造を生成するスクリプトを実行することができる。ダイレクト・アクションＡＰＩ１１６は、データをデータリポジトリ１２４から取得することができ、ならびにエンド・ユーザの同意によりクライアントコンピューティングデバイス１０４から受信されたデータを、サービスプロバイダデバイス１０８がカーシェア・サービスからの車の予約のような動作を実施できるようにするための位置、時間、ユーザアカウント、物流または他の情報を決定するために取得することができる。ダイレクト・アクションＡＰＩ１１６を用いて、データ処理システム１０２はまた、サービスプロバイダデバイス１０８と通信して、この例ではカーシェアのピックアップ予約を行うことによって変換を完了することができる。 The data processing system 102 can include a direct action API 116 designed and configured to generate an action data structure in response to the request based on the trigger keyword. The processor of the data processing system 102 activates the direct action API 116 to execute a script that generates a data structure for the service provider device 108 for requesting or ordering a car-like service or product from the car sharing service. can do. The direct action API 116 can retrieve the data from the data repository 124, as well as the data received from the client computing device 104 with the consent of the end user, from the service provider device 108 to the car sharing service. It can be obtained to determine the location, time, user account, repository or other information that enables an operation such as a reservation to be performed. Using the direct action API 116, the data processing system 102 can also communicate with the service provider device 108 to complete the conversion by making a pick-up reservation for car sharing in this example.
ダイレクト・アクションＡＰＩ１１６はデータ処理システム１０２により決定されるように、指定されたアクションを実行してエンド・ユーザの意図を満たすことができる。その入力で指定された当該アクションに依存して、ダイレクト・アクションＡＰＩ１１６は、ユーザ要求を満たすのに必要なパラメータを識別するコードまたはダイアログスクリプトを実行することができる。かかるコードは、例えば、ホーム・オートメーションサービスの名前のようなデータリポジトリ１２４内の追加の情報を検索でき、またはエンド・ユーザに要求されたタクシーの意図した宛先のような質問をするために、クライアントコンピューティングデバイス１０４で描画するためのオーディオ出力を提供することができる。ダイレクト・アクションＡＰＩ１１６は必要なパラメータを決定し、当該情報をアクションデータ構造にパッケージ化することができ、当該データ構造を次いで、満たすべきコンテンツセレクタコンポーネント１１８またはサービスプロバイダコンピューティングデバイス１０８のような別のコンポーネントに送信することができる。 The direct action API 116 can perform the specified action to meet the end user's intent, as determined by the data processing system 102. Depending on the action specified in the input, the direct action API116 can execute code or a dialog script that identifies the parameters needed to satisfy the user request. Such code can retrieve additional information in the data repository 124, such as the name of the home automation service, or ask the end user a question such as the intended destination of the taxi requested. It is possible to provide an audio output for drawing on the computing device 104. The direct action API 116 can determine the required parameters and package the information into an action data structure, which in turn can be satisfied by another content selector component 118 or service provider computing device 108 such as the service provider computing device 108. Can be sent to the component.
ダイレクト・アクションＡＰＩ１１６は当該アクションデータ構造を生成または構築するための命令またはコマンドを、ＮＬＰコンポーネント１１２、またはデータ処理システム１０２の他のコンポーネントから受信することができる。ダイレクト・アクションＡＰＩ１１６はデータリポジトリ１２４に格納されたテンプレートリポジトリ１３２からテンプレートを選択するためのアクションのタイプを決定することができる。アクションのタイプは、例えば、サービス、製品、予約、またはチケットを含むことができる。アクションのタイプはさらに、サービスまたは製品のタイプを含むことができる。例えば、サービスのタイプは、カーシェア・サービス、フード・デリバリーサービス、洗濯サービス、メイドサービス、修理サービス、または家庭サービスを含むことができる。製品のタイプは、例えば、衣服、靴、おもちゃ、電子、コンピュータ、ブック、または宝石を含むことができる。予約のタイプは、例えば、ディナー予約またはヘアサロンの予約を含むことができる。チケットのタイプは、例えば、映画チケット、競技場チケット、または飛行機チケットを含むことができる。幾つかのケースでは、サービス、製品、予約またはチケットのタイプを、価格、位置、発送、可用性、または他の属性のタイプに基づいて分類することができる。 The direct action API 116 can receive instructions or commands for generating or constructing the action data structure from the NLP component 112, or any other component of the data processing system 102. The direct action API 116 can determine the type of action for selecting a template from the template repository 132 stored in the data repository 124. The type of action can include, for example, a service, product, reservation, or ticket. The type of action can further include the type of service or product. For example, the type of service can include car sharing service, food delivery service, laundry service, maid service, repair service, or home service. The type of product can include, for example, clothing, shoes, toys, electronic, computers, books, or jewelry. The type of booking can include, for example, a dinner booking or a hair salon booking. Ticket types can include, for example, movie tickets, stadium tickets, or airplane tickets. In some cases, the type of service, product, booking or ticket can be categorized based on price, location, shipping, availability, or other attribute type.
ダイレクト・アクションＡＰＩ１１６は、要求のタイプを識別すると、対応するテンプレートにテンプレートリポジトリ１３２からアクセスすることができる。テンプレートは、ダイレクト・アクションＡＰＩ１１６により（エンド・ユーザをピックアップ位置でピックアップしてエンド・ユーザを目的地に輸送するためにタクシーを回す動作のような）サービスプロバイダデバイス１０８に要求されたさらなる動作に対して埋めることができる構造化データ・セット内のフィールドを含むことができる。ダイレクト・アクションＡＰＩ１１６は、テンプレートリポジトリ１３２内で検索を実施して、当該トリガキーワードおよび要求の１つまたは複数の特性にマッチするテンプレートを選択することができる。例えば、当該要求が宛先への車または乗車の要求に対応する場合、データ処理システム１０２はカーシェア・サービス・テンプレートを選択することができる。当該カーシェア・サービス・テンプレートは、以下のフィールド、即ち、デバイス識別子、ピックアップ位置、目的地、乗客の数、またはサービスのタイプのうち１つまたは複数を含むことができる。ダイレクト・アクションＡＰＩ１１６は当該フィールドを値で埋めることができる。当該フィールドを値で埋めるために、ダイレクト・アクションＡＰＩ１１６は、コンピューティングデバイス１０４の１つまたは複数のセンサ１３４またはデバイス１０４のユーザインタフェースをピングし、そこから情報をポーリングまたは取得することができる。例えば、ダイレクト・アクションＡＰＩ１１６は、ＧＰＳセンサのような位置センサを用いて当該ソース位置を検出することができる。ダイレクト・アクションＡＰＩ１１６は、コンピューティングデバイス１０４のエンド・ユーザに調査、プロンプト、またはクエリを送信することで、さらなる情報を取得することができる。当該ダイレクト・アクションＡＰＩは、データ処理システム１０２のインタフェース１１０およびコンピューティングデバイス１０４のユーザインタフェース（例えば、オーディオインタフェース、音声ベースのユーザインタフェース、ディスプレイ、またはタッチ・スクリーン）を介して、調査、プロンプト、またはクエリを送信することができる。したがって、ダイレクト・アクションＡＰＩ１１６は、当該トリガキーワードまたは当該要求に基づいて当該アクションデータ構造に対するテンプレートを選択し、１つまたは複数のセンサ１３４により検出されたまたはユーザインタフェースを介して取得された情報で当該テンプレート内の１つまたは複数のフィールドを埋め、サービスプロバイダデバイス１０８による動作の実施を促進するための当該アクションデータ構造を生成、作成、または構築することができる。 Once the direct action API116 identifies the type of request, the corresponding template can be accessed from the template repository 132. The template is for additional actions requested by the service provider device 108 (such as the action of picking up the end user at the pick-up position and turning a taxi to transport the end user to their destination) by the direct action API116. Can include fields in structured data sets that can be filled in. The direct action API 116 can perform a search in the template repository 132 to select a template that matches one or more characteristics of the trigger keyword and request. For example, if the request corresponds to a car or boarding request to a destination, the data processing system 102 may select a car sharing service template. The car-sharing service template may include one or more of the following fields: device identifier, pickup location, destination, number of passengers, or type of service. The direct action API 116 can fill the field with a value. To fill the field with a value, the direct action API 116 can ping the user interface of one or more sensors 134 or device 104 of the computing device 104 and poll or obtain information from it. For example, the direct action API 116 can detect the source position using a position sensor such as a GPS sensor. The direct action API 116 can retrieve further information by sending a survey, prompt, or query to the end user of the computing device 104. The direct action API is explored, prompted, or conducted through the interface 110 of the data processing system 102 and the user interface of the computing device 104 (eg, an audio interface, a voice-based user interface, a display, or a touch screen). You can send a query. Therefore, the direct action API 116 selects a template for the action data structure based on the trigger keyword or the request and is said to be information detected by one or more sensors 134 or obtained through the user interface. One or more fields in the template can be filled to generate, create, or build such action data structures to facilitate the performance of actions by the service provider device 108.
データ処理システム１０２は、例えば、当該トリガキーワード、要求、サードパーティプロバイダデバイス１０８、サードパーティプロバイダデバイス１０８のタイプ、サードパーティプロバイダデバイス１０８が入るカテゴリ（例えば、タクシーサービス、洗濯サービス、フラワー・サービス、またはフード・デリバリー）、位置、または他のセンサ情報を含む様々な因子のうち１つまたは複数に基づいて当該テンプレートをテンプレートデータ構造１３２から選択することができる。 The data processing system 102 may include, for example, the trigger keyword, request, third party provider device 108, type of third party provider device 108, category containing the third party provider device 108 (eg, taxi service, washing service, flower service, or The template can be selected from the template data structure 132 based on one or more of various factors including food delivery), location, or other sensor information.
当該トリガキーワードに基づいて当該テンプレートを選択するために、データ処理システム１０２は、（例えば、ダイレクト・アクションＡＰＩ１１６を介して）当該トリガキーワードを用いて検索または他のクエリ動作をテンプレートデータベース１３２に実施して、当該トリガキーワードにマップまたは対応するテンプレートデータ構造を識別することができる。例えば、テンプレートデータベース１３２内の各テンプレートを、当該テンプレートが、通信セッションを確立するためにサードパーティプロバイダデバイス１０８が処理できる当該トリガキーワードに応答してアクションデータ構造を生成するように構成されることを示すための１つまたは複数のトリガキーワードに関連付けることができる。 To select the template based on the trigger keyword, the data processing system 102 performs a search or other query action on the template database 132 using the trigger keyword (eg, via the direct action API 116). The map or corresponding template data structure can be identified for the trigger keyword. For example, each template in the template database 132 may be configured to generate an action data structure in response to the trigger keyword that the template can process by the third party provider device 108 to establish a communication session. It can be associated with one or more trigger keywords to indicate.
幾つかのケースでは、データ処理システム１０２は、当該トリガキーワードに基づいてサードパーティプロバイダデバイス１０８を識別することができる。サードパーティプロバイダ１０８を当該トリガキーワードに基づいて識別するために、データ処理システム１０２は、データリポジトリ１２４内で検索を実施して、当該トリガキーワードにマップするサードパーティプロバイダデバイス１０８を識別することができる。例えば、当該トリガキーワードが「ride」または「to go to」を含む場合、データ処理システム１０２は、（例えば、ダイレクト・アクションＡＰＩ１１６を介して）サードパーティプロバイダデバイス１０８をタクシーサービス会社Ａに対応するとして識別することができる。データ処理システム１０２は、識別されたサードパーティプロバイダデバイス１０８を用いて当該テンプレートをテンプレートデータベース１３２から選択することができる。例えば、テンプレートデータベース１３２は、通信セッションを確立するためにサードパーティプロバイダデバイス１０８が処理できる当該トリガキーワードに応答してアクションデータ構造を生成するように構成されたサードパーティプロバイダデバイス１０８またはエンティティの間のテンプレートに対するマッピングまたは相関関係を含むことができる。幾つかのケースでは、当該テンプレートを、サードパーティプロバイダデバイス１０８に対して、またはサードパーティプロバイダデバイス１０８のカテゴリに関してカスタマイズすることができる。データ処理システム１０２は、サードパーティプロバイダ１０８に対する当該テンプレートに基づいて当該アクションデータ構造を生成することができる。 In some cases, the data processing system 102 can identify the third party provider device 108 based on the trigger keyword. To identify the third party provider 108 based on the trigger keyword, the data processing system 102 can perform a search in the data repository 124 to identify the third party provider device 108 that maps to the trigger keyword. .. For example, if the trigger keyword includes "ride" or "to go to", the data processing system 102 will assume that the third party provider device 108 (eg, via the direct action API 116) corresponds to the taxi service company A. Can be identified. The data processing system 102 can select the template from the template database 132 using the identified third party provider device 108. For example, the template database 132 is between a third party provider device 108 or an entity configured to generate an action data structure in response to the trigger keyword that the third party provider device 108 can process to establish a communication session. Can include mappings or correlations to templates. In some cases, the template can be customized for the third party provider device 108 or for the category of the third party provider device 108. The data processing system 102 can generate the action data structure based on the template for the third party provider 108.
当該アクションデータ構造を構築または生成するために、データ処理システム１０２は、値で埋めるべき当該選択されたテンプレート内の１つまたは複数のフィールドを識別することができる。当該フィールドを、数値、文字列、ユニコード値、ブール論理、二進値、１６進値、識別子、位置座標、地理的領域、タイムスタンプ、または他の値で埋めることができる。当該フィールドまたは当該データ構造自体を、データセキュリティを維持するために、暗号化またはマスクすることができる。 To build or generate the action data structure, the data processing system 102 can identify one or more fields in the selected template to be filled with values. The field can be filled with numbers, strings, Unicode values, Boolean logic, binary values, hexadecimal values, identifiers, position coordinates, geographic areas, timestamps, or other values. The field or the data structure itself can be encrypted or masked to maintain data security.
当該テンプレート内の当該フィールドを決定すると、データ処理システム１０２は、当該テンプレートのフィールドを埋めるための当該フィールドに対する値を識別して、当該アクションデータ構造を生成することができる。データ処理システム１０２は、検索または他のクエリ動作をデータリポジトリ１２４に実施することで、当該フィールドに対する値を取得し、取り出し、決定し、または識別することができる。 Once the field in the template is determined, the data processing system 102 can generate the action data structure by identifying the value for the field to fill the field in the template. The data processing system 102 can obtain, retrieve, determine, or identify a value for the field by performing a search or other query operation on the data repository 124.
幾つかのケースでは、データ処理システム１０２は、当該フィールドに対する情報または値がデータリポジトリ１２４にないと判定することができる。データ処理システム１０２は、データリポジトリ１２４に格納された情報または値が古い、陳腐であるか、またはトリガキーワードおよび要求に応答してＮＬＰコンポーネント１１２により識別されたアクションデータ構造を構築する目的に適していないと判定することができる（例えば、クライアントコンピューティングデバイス１０４の位置が古い位置であり現在の位置でないかもしれないこと、アカウントが切れているかもしれないこと、当該宛先レストランが新たな位置に移動しているかもしれないこと、物理活動情報、または輸送のモード）。 In some cases, the data processing system 102 can determine that the information or value for the field is not in the data repository 124. The data processing system 102 is suitable for the purpose of constructing an action data structure where the information or values stored in the data repository 124 are outdated, obsolete, or identified by the NLP component 112 in response to trigger keywords and requests. (For example, the location of the client computing device 104 may be the old location and not the current location, the account may have expired, and the destination restaurant has moved to the new location. What you may be doing, physical activity information, or mode of transport).
データ処理システム１０２が、データ処理システム１０２のメモリ内で、当該テンプレートの当該フィールドに対する値または情報に対するアクセスを現在有さないと判定した場合、データ処理システム１０２は当該値または情報を取得することができる。データ処理システム１０２は、クライアントコンピューティングデバイス１０４の１つまたは複数の利用可能なセンサを問い合わせまたはポーリングし、クライアントコンピューティングデバイス１０４のエンド・ユーザに当該情報を促し、またはＨＴＴＰプロトコルを用いてオンラインのWebベースのリソースにアクセスすることによって、当該情報を取得することができる。例えば、データ処理システム１０２は、それがクライアントコンピューティングデバイス１０４の現在の位置を有さないと判定でき、現在の位置は当該テンプレートの必要とされるフィールドであってもよい。データ処理システム１０２は、クライアントコンピューティングデバイス１０４に当該位置情報を問い合わせることができる。データ処理システム１０２は、全地球測位システムセンサ、WIFI三角測量、携帯電波塔三角測量、Bluetooth（登録商標）ビーコン、ＩＰアドレス、または他の位置検知技術のような１つまたは複数の位置センサ１３４を用いて当該位置情報を提供するように、クライアントコンピューティングデバイス１０４に要求することができる。 If the data processing system 102 determines in the memory of the data processing system 102 that it does not currently have access to the value or information for the field in the template, the data processing system 102 may acquire the value or information. it can. The data processing system 102 queries or polls one or more available sensors of the client computing device 104 to prompt the end user of the client computing device 104 for that information, or online using the HTTP protocol. The information can be obtained by accessing a web-based resource. For example, the data processing system 102 may determine that it does not have the current position of the client computing device 104, which may be the required field of the template. The data processing system 102 can inquire the client computing device 104 for the location information. The data processing system 102 includes one or more position sensors 134 such as global positioning system sensors, WIFI triangulation, mobile tower triangulation, Bluetooth® beacons, IP addresses, or other location detection technologies. It can be requested that the client computing device 104 be used to provide the location information.
ダイレクト・アクションＡＰＩ１１６は、当該アクションデータ構造をサードパーティプロバイダデバイス（例えば、サービスプロバイダデバイス１０８）に送信して、サードパーティプロバイダデバイス１０８に、会話アプリケーションプログラミングインタフェース（例えば、サービスプロバイダＮＬＰコンポーネント１４２）を起動してサードパーティプロバイダデバイス１０８およびクライアントコンピューティングデバイス１０４の間の通信セッションを確立させることができる。サービスプロバイダデバイス１０８およびクライアントコンピューティングデバイス１００４の間の通信セッションを確立したことに応答して、サービスプロバイダデバイス１０８は、データパケットをクライアントコンピューティングデバイス１０４にネットワーク１０５を介して直接に送信することができる。幾つかのケースでは、サービスプロバイダデバイス１０８は、データ処理システム１０２およびネットワーク１０５を介して、データパケットをクライアントコンピューティングデバイス１０４に送信することができる。 The direct action API 116 sends the action data structure to a third-party provider device (eg, service provider device 108) to launch a conversational application programming interface (eg, service provider NLP component 142) on the third-party provider device 108. It is possible to establish a communication session between the third party provider device 108 and the client computing device 104. In response to establishing a communication session between the service provider device 108 and the client computing device 1004, the service provider device 108 may send data packets directly to the client computing device 104 over the network 105. it can. In some cases, the service provider device 108 can send data packets to the client computing device 104 via the data processing system 102 and the network 105.
幾つかのケースでは、サードパーティプロバイダデバイス１０８は会話ＡＰＩ１４２の少なくとも一部を実行することができる。例えば、サードパーティプロバイダデバイス１０８は、当該通信セッションの特定の態様またはクエリのタイプを扱うことができる。サードパーティプロバイダデバイス１０８は、データ処理システム１０２により実行されるＮＬＰコンポーネント１１２を利用して、当該通信セッションに関連付けられたオーディオ信号の処理およびクエリに対する応答の生成を促進してもよい。幾つかのケースでは、データ処理システム１０２はサードパーティプロバイダ１０８に構成された会話ＡＰＩ１４２を含むことができる。幾つかのケースでは、データ処理システムは、当該クライアントコンピューティングデバイスおよび当該サードパーティプロバイダデバイスの間でデータパケットをルーティングして、当該通信セッションを確立する。データ処理システム１０２は、サードパーティプロバイダデバイス１０８から、当該サードパーティプロバイダデバイスがクライアントデバイス１０４との当該通信セッションを確立したとの指示を受信することができる。当該指示は、クライアントコンピューティングデバイス１０４の識別子、当該通信セッションが確立されたときに対応するタイムスタンプ、または当該通信セッションに関連付けられた当該アクションデータ構造のような当該通信セッションに関連付けられた他の情報を含むことができる。幾つかのケースでは、データ処理システム１０２は、当該通信セッションおよびフィードバックモニタコンポーネント１２０を管理して当該通信セッションの特性を測定するセッションハンドラコンポーネント１１４を含むことができる。 In some cases, the third-party provider device 108 may perform at least a portion of the conversation API 142. For example, the third party provider device 108 can handle a particular aspect or query type of the communication session. The third-party provider device 108 may utilize the NLP component 112 executed by the data processing system 102 to facilitate the processing of the audio signal associated with the communication session and the generation of a response to the query. In some cases, the data processing system 102 may include a conversation API 142 configured at a third party provider 108. In some cases, the data processing system routes data packets between the client computing device and the third-party provider device to establish the communication session. The data processing system 102 can receive an instruction from the third-party provider device 108 that the third-party provider device has established the communication session with the client device 104. The instruction may be an identifier for the client computing device 104, a time stamp corresponding to when the communication session was established, or other information associated with the communication session, such as the action data structure associated with the communication session. Information can be included. In some cases, the data processing system 102 may include a session handler component 114 that manages the communication session and feedback monitor component 120 and measures the characteristics of the communication session.
データ処理システム１０２は、クライアントデバイス１０４およびデータ処理システム１０２の間の通信セッションを確立するために、セッションハンドラコンポーネント１１４を包含し、実行し、アクセスし、または通信することができる。当該通信セッションは、クライアントデバイス１０４のセンサ１３４により検出された入力オーディオ信号、およびデータ処理システム１０２によりクライアントデバイス１０４に送信された出力信号を含むクライアントデバイス１０４およびデータ処理システム１０２の間の１つまたは複数のデータ送信を指すことができる。データ処理システム１０２は、当該入力オーディオ信号を受信したことに応答して、（例えば、セッションハンドラコンポーネント１１４を介して）当該通信セッションを確立することができる。データ処理システム１０２は当該通信セッションに対する期間を設定することができる。データ処理システム１０２は当該通信セッションに対して設定された当該期間に対してタイマまたはカウンタを設定することができる。当該タイマの期限切れに応答して、データ処理システム１０２は当該通信セッションを終了することができる。 The data processing system 102 can include, execute, access, or communicate with the session handler component 114 to establish a communication session between the client device 104 and the data processing system 102. The communication session is one or more between the client device 104 and the data processing system 102, including the input audio signal detected by the sensor 134 of the client device 104 and the output signal transmitted by the data processing system 102 to the client device 104. It can refer to multiple data transmissions. The data processing system 102 can establish the communication session (eg, via the session handler component 114) in response to receiving the input audio signal. The data processing system 102 can set a period for the communication session. The data processing system 102 can set a timer or counter for the period set for the communication session. In response to the expiration of the timer, the data processing system 102 can terminate the communication session.
当該通信セッションは、クライアントデバイス１０４が当該セッションを確立するための認証情報または証明書を提供するネットワークベースの通信セッションを指すことができる。幾つかのケースでは、当該通信セッションは、当該セッション中にデータパケットにより運搬されるオーディオ信号のトピックまたはコンテキストを指す。例えば、第１の通信セッションはタクシーサービスに関連する（例えば、キーワード、アクションデータ構造、またはコンテンツ・アイテム・オブジェクトを含む）クライアントデバイス１０４およびデータ処理システム１０２の間で送信されたオーディオ信号を指すことができ、第２の通信セッションは洗濯およびドライ・クリーニングサービスに関連するクライアントデバイス１０４およびデータ処理システム１０２の間で送信されたオーディオ信号を指すことができる。本例では、データ処理システム１０２は当該オーディオ信号のコンテキストが異なると（例えば、ＮＬＰコンポーネント１１２を介して）判定し、当該２つの組のオーディオ信号を異なる通信セッションに分離することができる。セッションハンドラ１１４は、ドライ・クリーニングおよび洗濯サービスに関連する１つまたは複数のオーディオ信号を識別したことに応答して乗車サービスに関連する第１のセッションを終了することができる。したがって、データ処理システム１０２は、当該オーディオ信号のコンテキストを検出したことに応答して当該ドライ・クリーニングおよび洗濯サービスに関連する当該オーディオ信号に対する第２のセッションを開始または確立することができる。 The communication session can refer to a network-based communication session in which the client device 104 provides credentials or certificates to establish the session. In some cases, the communication session refers to the topic or context of the audio signal carried by the data packet during the session. For example, the first communication session refers to an audio signal transmitted between a client device 104 and a data processing system 102 related to a taxi service (including, for example, keywords, action data structures, or content item objects). The second communication session can point to the audio signal transmitted between the client device 104 and the data processing system 102 associated with the washing and dry cleaning service. In this example, the data processing system 102 can determine that the audio signals have different contexts (eg, via the NLP component 112) and can separate the two sets of audio signals into different communication sessions. The session handler 114 may terminate the first session related to the boarding service in response to identifying one or more audio signals related to the dry cleaning and washing services. Thus, the data processing system 102 can initiate or establish a second session for the audio signal associated with the dry cleaning and washing service in response to detecting the context of the audio signal.
データ処理システム１０２は自然言語プロセッサにより識別されたトリガキーワードを受信し、当該トリガキーワードに基づいて、リアルタイムコンテンツ選択プロセスを介してコンテンツ・アイテムを選択するためにコンテンツセレクタコンポーネント１１８を包含、実行、または通信することができる。幾つかのケースでは、ダイレクト・アクションＡＰＩ１１６は当該アクションデータ構造をコンテンツセレクタコンポーネント１１８に送信して、リアルタイムコンテンツ選択プロセスを実施し、コンテンツプロバイダデバイス１０６（またはサードパーティプロバイダデバイス１０８）およびクライアントコンピューティングデバイス１０４の間の通信セッションを確立することができる。 The data processing system 102 receives a trigger keyword identified by a natural language processor and includes, executes, or includes a content selector component 118 to select a content item through a real-time content selection process based on the trigger keyword. Can communicate. In some cases, the direct action API 116 sends the action data structure to the content selector component 118 to perform a real-time content selection process, content provider device 106 (or third party provider device 108) and client computing device. A communication session between 104 can be established.
当該コンテンツ選択プロセスは、サードパーティコンテンツプロバイダ１０６により提供されたスポンサーされたコンテンツ・アイテム・オブジェクトを選択するステップを指すかまたは含むことができる。当該コンテンツ選択プロセスは、複数のコンテンツプロバイダにより提供されたコンテンツ・アイテムを解析し、処理し、重み付けし、またはマッチして、コンピューティングデバイス１０４に提供するための１つまたは複数のコンテンツ・アイテムを選択するサービスを含むことができる。当該コンテンツ選択プロセスをリアルタイムまたはオフラインで実施することができる。当該コンテンツ選択プロセスをリアルタイムに実施することは、当該コンテンツ要求がクライアントコンピューティングデバイス１０４を介して受信されたことに応答して当該コンテンツ選択プロセスを実施するステップを指すことができる。当該リアルタイムコンテンツ選択プロセスを、当該要求を受信する時間間隔（例えば、５秒、１０秒、２０秒、３０秒、１分、２分、３分、５分、１０分、または２０分）内に実施（例えば、開始または完了）することができる。当該リアルタイムコンテンツ選択プロセスを、クライアントコンピューティングデバイス１０４との通信セッション中に、または、当該通信セッションが終了した後のある時間間隔内に、実施することができる。 The content selection process may refer to or include the step of selecting a sponsored content item object provided by the third party content provider 106. The content selection process analyzes, processes, weights, or matches content items provided by multiple content providers to deliver one or more content items to the computing device 104. Can include services of choice. The content selection process can be performed in real time or offline. Performing the content selection process in real time can refer to the step of performing the content selection process in response to the content request being received via the client computing device 104. The real-time content selection process is performed within the time interval for receiving the request (eg, 5 seconds, 10 seconds, 20 seconds, 30 seconds, 1 minute, 2 minutes, 3 minutes, 5 minutes, 10 minutes, or 20 minutes). It can be carried out (eg, started or completed). The real-time content selection process can be performed during a communication session with the client computing device 104 or within some time interval after the communication session ends.
例えば、データ処理システム１０２は、コンテンツ・アイテム・オブジェクトを選択するように設計、構築、構成、または動作可能なコンテンツセレクタコンポーネント１１８を含むことができる。音声ベースの環境内で表示するためのコンテンツ・アイテムを選択するために、データ処理システム１０２は（例えば、ＮＬＰコンポーネント１１２を介して）当該入力オーディオ信号を解析して、キーワード（例えば、トリガキーワード）を識別し、当該キーワードを使用して広いマッチ、厳密なマッチ、またはフレーズマッチに基づいてマッチングコンテンツ・アイテムを選択することができる。例えば、コンテンツセレクタコンポーネント１１８は候補コンテンツ・アイテムの主題を分析、解析、または処理して、当該候補コンテンツ・アイテムの主題が、クライアントコンピューティングデバイス１０４のマイクロフォンにより検出された入力オーディオ信号のキーワードまたはフレーズの主題に対応するかどうかを判定することができる。コンテンツセレクタコンポーネント１１８は、画像処理技術、文字認識技術、自然言語処理技術、またはデータベース検索を用いて、音声、オーディオ、当該候補コンテンツ・アイテムの用語、文字、テキスト、記号、または画像を識別、分析、または認識してもよい。当該候補コンテンツ・アイテムは当該候補コンテンツ・アイテムの主題を示すメタデータを含んでもよく、この場合コンテンツセレクタコンポーネント１１８は当該メタデータを処理して、当該候補コンテンツ・アイテムの主題が当該入力オーディオ信号に対応するかどうかを判定してもよい。 For example, the data processing system 102 can include a content selector component 118 that can be designed, built, configured, or operated to select content item objects. To select content items to display in a voice-based environment, the data processing system 102 analyzes the input audio signal (eg, via the NLP component 112) and keywords (eg, trigger keywords). You can use the keyword to select matching content items based on a wide match, an exact match, or a phrase match. For example, the content selector component 118 analyzes, analyzes, or processes the subject of the candidate content item, and the subject of the candidate content item is a keyword or phrase of the input audio signal detected by the microphone of the client computing device 104. It is possible to determine whether or not it corresponds to the subject of. The content selector component 118 uses image processing technology, character recognition technology, natural language processing technology, or database search to identify and analyze audio, audio, terminology, characters, text, symbols, or images of the candidate content item. , Or may be recognized. The candidate content item may include metadata indicating the subject of the candidate content item, in which case the content selector component 118 processes the metadata and the subject of the candidate content item becomes the input audio signal. It may be determined whether or not it corresponds.
コンテンツプロバイダ１０６は、コンテンツ・アイテムを含むコンテンツキャンペーンをセットアップするときに、追加のインジケータを提供してもよい。コンテンツプロバイダ１０６は、コンテンツセレクタコンポーネント１１８が当該候補コンテンツ・アイテムに関する情報を用いて検索を実施することで識別しうる情報を当該コンテンツキャンペーンまたはコンテンツグループレベルで提供してもよい。例えば、当該候補コンテンツ・アイテムは一意な識別子を含んでもよく、当該一意な識別子を、コンテンツグループ、コンテンツキャンペーン、またはコンテンツプロバイダにマップしてもよい。コンテンツセレクタコンポーネント１１８は、データリポジトリ１２４内のコンテンツキャンペーンデータ構造に格納された情報に基づいて、コンテンツプロバイダ１０６に関する情報を決定してもよい。 Content provider 106 may provide additional indicators when setting up a content campaign that includes content items. The content provider 106 may provide information at the content campaign or content group level that can be identified by the content selector component 118 performing a search with information about the candidate content item. For example, the candidate content item may include a unique identifier, which may be mapped to a content group, content campaign, or content provider. The content selector component 118 may determine information about the content provider 106 based on the information stored in the content campaign data structure in the data repository 124.
データ処理システム１０２は、コンピュータネットワークを介して、コンピューティングデバイス１０４で提示するためのコンテンツに対する要求を受信することができる。データ処理システム１０２は、クライアントコンピューティングデバイス１０４のマイクロフォンにより検出された入力オーディオ信号を処理することによって当該要求を識別することができる。当該要求は、当該要求に関連付けられた当該デバイスのタイプ、位置、およびキーワードのような当該要求の選択基準を含むことができる。当該要求は当該アクションデータ構造を含むことができる。 The data processing system 102 can receive a request for content to be presented by the computing device 104 via a computer network. The data processing system 102 can identify the request by processing the input audio signal detected by the microphone of the client computing device 104. The request can include selection criteria for the request, such as the type, location, and keywords of the device associated with the request. The request can include the action data structure.
当該要求に応答して、データ処理システム１０２は、コンテンツ・アイテム・オブジェクトをデータリポジトリ１２４またはコンテンツプロバイダ１０６に関連付けられたデータベースから選択し、ネットワーク１０５を介してコンピューティングデバイス１０４を介して提供するための当該コンテンツ・アイテムを提供することができる。当該コンテンツ・アイテム・オブジェクトを、サービスプロバイダデバイス１０８と異なるコンテンツプロバイダデバイス１０８により提供することができる。当該コンテンツ・アイテムは、当該アクションデータ構造のサービスのタイプと異なるサービスのタイプ（例えば、タクシーサービス対フード・デリバリーサービス）に対応することができる。コンピューティングデバイス１０４は当該コンテンツ・アイテム・オブジェクトと対話することができる。コンピューティングデバイス１０４は当該コンテンツ・アイテムへのオーディオ応答を受信することができる。コンピューティングデバイス１０４は、当該コンテンツ・アイテム・オブジェクトに関連付けられたハイパーリンクまたは他のボタンを選択するための指示を受信することができる。当該指示は、コンピューティングデバイス１０４に、サービスプロバイダ１０８を識別し、サービスプロバイダ１０８にサービスを要求し、サービスを実施し、情報をサービスプロバイダ１０８に送信し、またはサービスプロバイダデバイス１０８を問い合わせるようにサービスプロバイダ１０８に指示させるかまたはそれらを可能とする。 In response to the request, the data processing system 102 selects a content item object from the database associated with the data repository 124 or the content provider 106 and provides it over the network 105 and over the computing device 104. The content item can be provided. The content item object can be provided by a content provider device 108 that is different from the service provider device 108. The content item can correspond to a type of service different from the type of service of the action data structure (eg, taxi service vs. food delivery service). The computing device 104 can interact with the content item object. The computing device 104 can receive an audio response to the content item. The computing device 104 can receive instructions for selecting a hyperlink or other button associated with the content item object. The instruction services the computing device 104 to identify the service provider 108, request the service from the service provider 108, perform the service, send information to the service provider 108, or query the service provider device 108. Have provider 108 direct or enable them.
データ処理システム１０２は、出力信号を生成するためのオーディオ信号ジェネレータコンポーネント１２２を包含し、実行し、または通信する。当該出力信号は１つまたは複数の部分を含むことができる。例えば、当該出力信号は第１の部分および第２の部分を含むことができる。当該出力信号の第１の部分は当該アクションデータ構造に対応することができる。当該出力信号の第２の部分は、当該リアルタイムコンテンツ選択プロセス中にコンテンツセレクタコンポーネント１１８により選択されたコンテンツ・アイテムに対応することができる。 The data processing system 102 includes, executes, or communicates with an audio signal generator component 122 for generating an output signal. The output signal may include one or more parts. For example, the output signal can include a first portion and a second portion. The first part of the output signal can correspond to the action data structure. The second part of the output signal can correspond to the content item selected by the content selector component 118 during the real-time content selection process.
オーディオ信号ジェネレータコンポーネント１２２は、第１のデータ構造に対応する音を有する第１の部分で出力信号を生成することができる。例えば、オーディオ信号ジェネレータコンポーネント１２２は、ダイレクト・アクションＡＰＩ１１６によりアクションデータ構造のフィールドに埋められた１つまたは複数の値に基づいて当該出力信号の第１の部分を生成することができる。タクシーサービスの例では、当該フィールドに対する値は、例えば、ピックアップ位置に対する123 Main Street、目的地に対する1234 Main Street、乗客の数に関して２、およびサービスのレベルに関してエコノミーを含むことができる。オーディオ信号ジェネレータコンポーネント１２２は、コンピューティングデバイス１０４のエンド・ユーザがサービスプロバイダ１０８へ当該要求を送信することについて先に進みたいことを確認するために、当該出力信号の第１の部分を生成することができる。第１の部分は、以下の出力「Would you like to order an economy car from taxi service provider A to pick two people up at 123 Main Street and drop off at 1234 Main Street?」を含むことができる。 The audio signal generator component 122 can generate an output signal in a first portion having a sound corresponding to the first data structure. For example, the audio signal generator component 122 can generate a first portion of the output signal based on one or more values filled in the fields of the action data structure by the direct action API 116. In the taxi service example, the values for the field can include, for example, 123 Main Street for the pickup position, 1234 Main Street for the destination, 2 for the number of passengers, and economy for the level of service. The audio signal generator component 122 generates a first portion of the output signal to ensure that the end user of the computing device 104 wants to proceed with sending the request to the service provider 108. Can be done. The first part can include the following output "Would you like to order an economy car from taxi service provider A to pick two people up at 123 Main Street and drop off at 1234 Main Street?".
幾つかのケースでは、第１の部分は、サービスプロバイダデバイス１０８から受信された情報を含むことができる。サービスプロバイダデバイス１０８から受信された当該情報を、当該アクションデータ構造に対してカスタマイズすることができる。例えば、データ処理システム１０２は（例えば、ダイレクト・アクションＡＰＩ１１６を介して）動作を実施するようにサービスプロバイダ１０８に指示する前に、当該アクションデータ構造をサービスプロバイダ１０８に送信することができる。その代わり、データ処理システム１０２はサービスプロバイダデバイス１０８に、初期または予備的処理を当該アクションデータ構造に実施して当該動作に関する予備的情報を生成するように指示することができる。当該タクシーサービスの例において、当該アクションデータ構造に対する当該予備的処理は、当該ピックアップ位置の周囲に配置されたサービス要件のレベルを満たす利用可能なタクシーを識別するステップ、最も近い利用可能なタクシーが当該ピックアップ位置に到達するための時間を推定するステップ、当該目的地への到着時刻を推定するステップ、および当該タクシーサービスに対する価格を推定するステップを含むことができる。当該推定された予備値は、固定された値、様々な条件、または値の範囲に基づいて変化を受ける推定値を含んでもよい。サービスプロバイダデバイス１０８は、当該予備情報をデータ処理システム１０２に返すか、または直接ネットワーク１０４を介してクライアントコンピューティングデバイス１０４に返すことができる。データ処理システム１０２は、サービスプロバイダデバイス１０８からの当該予備的結果を当該出力信号に取り込み、当該出力信号をコンピューティングデバイス１０４に送信することができる。当該出力信号は、例えば、「Taxi Service Company A can pick you up at 123 Main Street in 10 minutes, and drop you off at 1234 Main Street by 9 AM for $10. Do you want to order this ride?」を含むことができ、これは当該出力信号の第１の部分を形成することができる。 In some cases, the first part may include information received from the service provider device 108. The information received from the service provider device 108 can be customized for the action data structure. For example, the data processing system 102 may send the action data structure to the service provider 108 before instructing the service provider 108 to perform the operation (eg, via the direct action API 116). Instead, the data processing system 102 can instruct the service provider device 108 to perform initial or preliminary processing on the action data structure to generate preliminary information about the operation. In the taxi service example, the preliminary processing for the action data structure is the step of identifying available taxis that meet the level of service requirements placed around the pick-up location, the closest available taxi A step of estimating the time to reach the pick-up position, a step of estimating the arrival time at the destination, and a step of estimating the price for the taxi service can be included. The estimated preliminary value may include a fixed value, various conditions, or an estimated value that is subject to change based on a range of values. The service provider device 108 can return the preliminary information to the data processing system 102 or directly to the client computing device 104 via the network 104. The data processing system 102 can incorporate the preliminary result from the service provider device 108 into the output signal and transmit the output signal to the computing device 104. The output signal should include, for example, "Taxi Service Company A can pick you up at 123 Main Street in 10 minutes, and drop you off at 1234 Main Street by 9 AM for $ 10. Do you want to order this ride?" This can form the first part of the output signal.
幾つかのケースでは、データ処理システム１０２は当該出力信号の第２の部分を形成することができる。当該出力信号の第２の部分は、リアルタイムコンテンツ選択プロセス中にコンテンツセレクタコンポーネント１１８により選択されたコンテンツ・アイテムを含むことができる。第１の部分は第２の部分と異なることができる。例えば、第１の部分は、クライアントコンピューティングデバイス１０４のセンサ１３４により検出された入力オーディオ信号を運搬するデータパケットに直接応答するアクションデータ構造に対応する情報を含むことができ、第２の部分は、当該アクションデータ構造に垂直方向に関連しうるか、またはコンテンツプロバイダデバイス１０６により提供されたスポンサーされたコンテンツを含むコンテンツセレクタコンポーネント１０４により選択されたコンテンツ・アイテムを含むことができる。例えば、コンピューティングデバイス１０４のエンド・ユーザはタクシーをタクシーサービス会社Ａに要求することができる。データ処理システム１０２は、タクシーサービス会社Ａからのタクシーに関する情報を含むための当該出力信号の第１の部分を生成することができる。しかし、データ処理システム１０２は、キーワード「taxi service」およびエンド・ユーザが関心があるかもしれないアクションデータ構造に含まれる情報に基づいて選択されたコンテンツ・アイテムを含むための当該出力信号の第２の部分を生成することができる。例えば、第２の部分は、タクシーサービス会社Ｂのような異なるタクシーサービス会社により提供されたコンテンツ・アイテムまたは情報を含むことができる。ユーザはタクシーサービス会社Ｂに特段要求していないかもしれないが、データ処理システム１０２は、ユーザがタクシーサービス会社Ｂと動作を実施することを選択しうるので、それにもかかわらずタクシーサービス会社Ｂからのコンテンツ・アイテムを提供してもよい。 In some cases, the data processing system 102 can form a second portion of the output signal. The second portion of the output signal can include content items selected by the content selector component 118 during the real-time content selection process. The first part can be different from the second part. For example, the first part can contain information corresponding to the action data structure that directly responds to the data packet carrying the input audio signal detected by the sensor 134 of the client computing device 104, and the second part. Can include content items that may be vertically related to the action data structure or selected by the content selector component 104 that includes sponsored content provided by the content provider device 106. For example, the end user of computing device 104 may request a taxi from taxi service company A. The data processing system 102 can generate a first portion of the output signal to include information about the taxi from the taxi service company A. However, the data processing system 102 is the second output signal to include the content item selected based on the keyword "taxi service" and the information contained in the action data structure that the end user may be interested in. Part of can be generated. For example, the second part can include content items or information provided by different taxi service companies such as taxi service company B. Although the user may not specifically request the taxi service company B, the data processing system 102 may nevertheless from the taxi service company B because the user may choose to operate with the taxi service company B. Content items may be provided.
データ処理システム１０２は、ピックアップ時刻、宛先の到着時刻、および乗車の価格を決定するための情報を、当該アクションデータ構造からタクシーサービス会社Ｂに送信することができる。データ処理システム１０２は、この情報を受信して、「Taxi Service Company B can pick you up at 123 Main Street in 2 minutes, and drop you off at 1234 Main Street by 8:52 AM for $15. Do you want this ride instead?」のように当該出力信号の第２の部分を生成することができる。コンピューティングデバイス１０４のエンド・ユーザは次いで、タクシーサービス会社Ａにより提供された乗車またはタクシーサービス会社Ｂにより提供された乗車を選択することができる。 The data processing system 102 can transmit information for determining the pick-up time, the arrival time of the destination, and the price of the boarding from the action data structure to the taxi service company B. Upon receiving this information, the data processing system 102 receives "Taxi Service Company B can pick you up at 123 Main Street in 2 minutes, and drop you off at 1234 Main Street by 8:52 AM for $ 15. Do you want this. A second part of the output signal can be generated, such as "ride instead?". The end user of the computing device 104 can then select a ride provided by taxi service company A or a ride provided by taxi service company B.
当該出力信号の第２の部分で、タクシーサービス会社Ｂにより提供されたサービスに対応するスポンサーされたコンテンツ・アイテムを提供する前に、データ処理システム１０２は、第２の部分が（例えば、コンテンツセレクタコンポーネント１１８により）リアルタイムコンテンツ選択プロセス中に選択されたコンテンツ・アイテム・オブジェクトに対応するとエンド・ユーザコンピューティングデバイスに通知することができる。しかし、データ処理システム１０２は、当該通知をコンピューティングデバイス１０４のエンド・ユーザに提供するための異なるタイプのインタフェースに対して制限されたアクセスを有することができる。例えば、コンピューティングデバイス１０４はディスプレイデバイスを含まなくてもよく、または、当該ディスプレイデバイスを無効またはターンオフしてもよい。コンピューティングデバイス１０４の当該ディスプレイデバイスはコンピューティングデバイス１０４のスピーカより多くのリソースを消費するかもしれず、コンピューティングデバイス１０４の当該スピーカを用いて当該通知を運搬することと比べて、コンピューティングデバイス１０４の当該ディスプレイデバイスをターンオンするのはあまり効率的でないかもしれない。したがって、幾つかのケースでは、データ処理システム１０２は、１つまたは複数のインタフェースまたは１つまたは複数のタイプのコンピュータネットワーク上の情報送信の効率および有効性を高めることができる。例えば、データ処理システム１０２は、（例えば、オーディオ信号ジェネレータコンポーネント１２２を介して）、当該コンテンツ・アイテムを含む出力オーディオ信号の部分をモジュール化して、当該出力信号のその部分が当該スポンサーされたコンテンツ・アイテムを含むという指示または通知をエンド・ユーザに提供することができる。 In the second part of the output signal, before providing the sponsored content item corresponding to the service provided by the taxi service company B, the data processing system 102 has a second part (eg, a content selector). The end user computing device can be notified that it corresponds to the content item object selected during the real-time content selection process (by component 118). However, the data processing system 102 may have restricted access to different types of interfaces for providing the notification to the end user of the computing device 104. For example, the computing device 104 may not include a display device, or the display device may be disabled or turned off. The display device of the computing device 104 may consume more resources than the speaker of the computing device 104, and the computing device 104 may use the speaker of the computing device 104 to carry the notification. Turning on the display device may not be very efficient. Therefore, in some cases, the data processing system 102 can increase the efficiency and effectiveness of transmitting information on one or more interfaces or one or more types of computer networks. For example, the data processing system 102 (eg, via the audio signal generator component 122) modularizes a portion of the output audio signal that includes the content item, and that portion of the output signal is the sponsored content. Instructions or notifications to include the item can be provided to the end user.
データ処理システム１０２（は例えば、インタフェース１１０およびネットワーク１０５を介して）、オーディオ信号ジェネレータコンポーネント１２２により生成された出力信号を含むデータパケットを送信することができる。当該出力信号は、クライアントデバイス１０４のオーディオドライバコンポーネント１３８またはクライアントデバイス１０４により実行されるオーディオドライバコンポーネント１３８に、クライアントデバイス１０４のスピーカ（例えば、トランスデューサ１３６）を駆動して当該出力信号に対応する音波を生成させることができる。 A data processing system 102 (eg, via interface 110 and network 105) can transmit a data packet containing an output signal generated by the audio signal generator component 122. The output signal is generated by driving a speaker (for example, a transducer 136) of the client device 104 to the audio driver component 138 of the client device 104 or the audio driver component 138 executed by the client device 104, and transmitting a sound wave corresponding to the output signal. Can be generated.
データ処理システム１０２はフィードバックモニタコンポーネント１２０を含むことができる。フィードバックモニタコンポーネント１２０は通信セッションの特性を測定するためのハードウェアまたはソフトウェアを含むことができる。フィードバックモニタコンポーネント１２０は、当該コンテンツ・アイテムとの対話に応答してクライアントデバイスとの通信セッションを確立した、クライアントデバイス（例えば、コンピューティングデバイス１０４）および会話アプリケーションプログラミングインタフェース（例えば、データ処理システムにより実行されるＮＬＰコンポーネント１１２またはサービスプロバイダデバイス１０８、サードパーティプロバイダデバイス、またはコンテンツプロバイダデバイス１０６により実行されるサービスプロバイダＮＬＰコンポーネント１４２）の間で送信された可聴信号を運搬するデータパケットを受信することができる。幾つかのケースでは、コンテンツプロバイダデバイス１０６は、サービスプロバイダＮＬＰコンポーネント１４２またはＮＬＰコンポーネント１１２の１つまたは複数の機能またはコンポーネントを含むＮＬＰコンポーネントを実行することができる。サービスプロバイダデバイス１０８またはコンテンツプロバイダデバイス１０６により実行されるＮＬＰコンポーネントを、サービスプロバイダデバイス１０８またはコンテンツプロバイダデバイス１０６に対してカスタマイズすることができる。ＮＬＰコンポーネントをカスタマイズすることで、ＮＬＰコンポーネントは、ＮＬＰコンポーネントを、ＮＬＰコンポーネントおよびクライアントコンピューティングデバイス１０４の間の削減された往来をもたらすより正確なクエリおよび応答で構成できるので、汎用または標準ＮＬＰコンポーネントと比較して帯域幅利用および要求応答を減らすことができる。 The data processing system 102 may include a feedback monitor component 120. The feedback monitor component 120 may include hardware or software for measuring the characteristics of the communication session. The feedback monitor component 120 is performed by a client device (eg, computing device 104) and a conversational application programming interface (eg, a data processing system) that establishes a communication session with the client device in response to interaction with the content item. Data packets carrying an audible signal transmitted between the NLP component 112 or the service provider device 108, the third party provider device, or the service provider NLP component 142) performed by the content provider device 106 can be received. .. In some cases, the content provider device 106 may perform an NLP component that includes one or more functions or components of the service provider NLP component 142 or NLP component 112. The NLP component executed by the service provider device 108 or the content provider device 106 can be customized for the service provider device 108 or the content provider device 106. By customizing the NLP component, the NLP component can be configured with more accurate queries and responses that result in reduced traffic between the NLP component and the client computing device 104, thus being a generic or standard NLP component. Compared to this, bandwidth utilization and request response can be reduced.
フィードバックモニタコンポーネント１２０は、可聴信号に基づいて通信セッションの特性を測定することができる。フィードバックモニタコンポーネント１２０は当該測定された特性に基づいて品質信号を生成することができる。当該品質信号は、品質レベル、品質メトリック、品質スコアまたは品質レベルを含むかまたは指すことができる。当該品質信号は、例えば、数値スコア（例えば、０を最低品質および１０を最高品質、またはその逆として０乃至１０）、文字グレード（例えば、Ａを最高品質としてＡ乃至Ｆ）、二進値（例えば、はい／いいえ、良／悪、１／０、高／低）、順位、またはパーセンタイルを含むことができる。当該品質信号は、同一のＮＬＰコンポーネントまたはプロバイダデバイス１０６または１０８と通信する複数のクライアントデバイスの間の通信から決定された平均品質信号を含むことができる。 The feedback monitor component 120 can measure the characteristics of the communication session based on the audible signal. The feedback monitor component 120 can generate a quality signal based on the measured characteristics. The quality signal may include or point to a quality level, quality metric, quality score or quality level. The quality signal is, for example, a numerical score (eg, 0 for the lowest quality and 10 for the highest quality, or vice versa, 0 to 10), a character grade (eg, A for the highest quality, A to F), and a binary value (eg, A for the highest quality) For example, it can include yes / no, good / bad, 1/0, high / low), rank, or percentile. The quality signal can include an average quality signal determined from communication between multiple client devices communicating with the same NLP component or provider device 106 or 108.
フィードバックモニタコンポーネント１２０は、様々な測定技術、ヒューリスティック技術、ポリシ、条件、または試験を用いて当該通信セッションの特性を測定することができる。フィードバックモニタコンポーネント１２０は、クライアントデバイス１０４およびコンテンツプロバイダデバイス、サードパーティデバイス、サービスプロバイダまたはデータ処理システムの間で送信されたデータパケットを解析して、当該通信セッションの特性を決定することができる。当該品質は、通信されているデータまたは当該データの品質を送信するために使用される通信チャネルの品質を指すことができる。例えば、当該通信チャネルの品質は、信号雑音比、周辺雑音レベル、遅延、ラグ、レイテンシ、ばらつき、エコー、または通話途切れを指すことができる。通信されている当該データの品質は、コンピューティングデバイスのマイクロフォンにより検出されたオーディオ信号に応答しているＮＬＰコンポーネントにより生成された応答の品質を指すことができる。当該データの品質は、ＮＬＰコンポーネントがクライアントデバイス１０４から当該オーディオ信号またはクエリを受信することと応答を送信することの間のＮＬＰコンポーネントの応答性、ＮＬＰコンポーネントの精度、またはレイテンシに基づくことができる。 The feedback monitor component 120 can measure the characteristics of the communication session using various measurement techniques, heuristic techniques, policies, conditions, or tests. The feedback monitor component 120 can analyze data packets transmitted between the client device 104 and the content provider device, third party device, service provider or data processing system to characterize the communication session. The quality can refer to the quality of the data being communicated or the communication channel used to transmit the quality of the data. For example, the quality of the communication channel can refer to signal-to-noise ratio, ambient noise level, delay, lag, latency, variation, echo, or call interruption. The quality of the data being communicated can refer to the quality of the response produced by the NLP component responding to the audio signal detected by the microphone of the computing device. The quality of the data can be based on the NLP component's responsiveness, NLP component accuracy, or latency between receiving the audio signal or query from the client device 104 and sending the response.
フィードバックモニタコンポーネント１２０は、背景雑音および当該信号レベルの量を測定して信号雑音（「ＳＮＲ」）比を決定することにより、当該通信チャネルの品質を決定することができる。フィードバックモニタコンポーネント１２０は、測定されたまたは決定されたＳＮＲを閾値と比較して、当該品質のレベルを決定することができる。例えば、１０ｄＢＳＮＲを良好と考えてもよい。当該閾値を、機械学習モデルを介して（例えば、複数のデバイスからのフィードバックに基づいて）予め決定または決定することができる。 The feedback monitor component 120 can determine the quality of the communication channel by measuring the amount of background noise and the signal level to determine the signal-to-noise ratio (“SNR”) ratio. The feedback monitor component 120 can compare the measured or determined SNR with a threshold to determine the level of quality. For example, 10 dB SNR may be considered good. The threshold can be pre-determined or determined via a machine learning model (eg, based on feedback from multiple devices).
フィードバックモニタコンポーネント１２０はさらに、クライアントデバイス１０４およびプロバイダデバイスまたはデータ処理システムの間のピング時間に基づいて通信チャネルの品質を決定することができる。データ処理システムは、当該ピング時間を閾値と比較して、当該品質のレベルを決定することができる。例えば、当該ピング閾値は、２０ｍｓ、３０ｍｓ、５０ｍｓ、１００ｍｓ、２００ｍｓまたはそれ以上であることができる。フィードバックモニタコンポーネント１２０は、オーディオのばらつき（例えば、当該オーディオ内のポーズまたはブレーク、当該オーディオの切り抜き）に基づいて当該通信チャネルの品質を決定することができる。フィードバックモニタコンポーネント１２０は、低品質レベルを決定するために当該通信チャネル内のエコーを識別することができる。フィードバックモニタコンポーネント１２０は、或る時間間隔中のＮＬＰコンポーネントに対する通話途切れの数または通話途切れの全通話数との比率を決定し、それを閾値と比較して、当該品質レベルを決定することができる。例えば、当該閾値は、毎時２つの通話途切れ、または１００通話ごとの１つの通話途切れであることができる。 The feedback monitor component 120 can further determine the quality of the communication channel based on the ping time between the client device 104 and the provider device or data processing system. The data processing system can compare the ping time with a threshold to determine the level of quality. For example, the ping threshold can be 20 ms, 30 ms, 50 ms, 100 ms, 200 ms or more. The feedback monitor component 120 can determine the quality of the communication channel based on audio variability (eg, pauses or breaks in the audio, clippings of the audio). The feedback monitor component 120 can identify echoes within the communication channel to determine the low quality level. The feedback monitor component 120 can determine the number of interrupted calls or the ratio of the total number of interrupted calls to the NLP component during a certain time interval and compare it with a threshold to determine the quality level. .. For example, the threshold can be two call breaks per hour or one call break every 100 calls.
フィードバックモニタコンポーネント１２０は、クライアントコンピューティングデバイス１０４と通信するＮＬＰコンポーネント（または会話ＡＰＩ）により生成された応答の品質に基づいて当該通信セッションの品質を決定することができる。当該応答の品質は、ＮＬＰコンポーネントにより提供された当該応答に応答して、例えば、ＮＬＰコンポーネントが応答を生成するのにかかった時間、当該応答のテキスト、当該応答の精度、当該応答の関連性、当該応答のセマンティック分析、またはクライアントデバイスのネットワーク活動を含むかまたはそれに基づくことができる。フィードバックモニタコンポーネント１２０は、ＮＬＰコンポーネントが、ＮＬＰコンポーネントが当該オーディオ信号をクライアントデバイス１０４から受信したときに対応するタイムスタンプ、およびＮＬＰが当該応答を送信するときに対応するタイムスタンプを区別することで当該応答を生成するのにかかった時間を決定することができる。フィードバックモニタコンポーネント１２０は、クライアントデバイスが当該オーディオ信号を送信するときに対応するタイムスタンプおよびクライアントデバイスが当該応答をＮＬＰコンポーネントから受信するときに対応するタイムスタンプを区別することで当該時間を決定することができる。 The feedback monitor component 120 can determine the quality of the communication session based on the quality of the response generated by the NLP component (or conversation API) communicating with the client computing device 104. The quality of the response is, for example, the time it took for the NLP component to generate the response, the text of the response, the accuracy of the response, the relevance of the response, in response to the response provided by the NLP component. It can include or be based on a semantic analysis of the response, or network activity of the client device. The feedback monitor component 120 is such that the NLP component distinguishes between the corresponding time stamp when the NLP component receives the audio signal from the client device 104 and the corresponding time stamp when the NLP sends the response. You can determine how long it took to generate a response. The feedback monitor component 120 determines the time by distinguishing between the corresponding time stamp when the client device transmits the audio signal and the corresponding time stamp when the client device receives the response from the NLP component. Can be done.
フィードバックモニタコンポーネント１２０は当該応答を含むデータパケットを解析することで当該応答の品質を決定することができる。例えば、フィードバックモニタコンポーネント１２０は、クライアントデバイスから、当該応答のテキスト、当該応答の精度、または当該クエリに対する当該応答の関連性を解析し分析することができる。フィードバックモニタコンポーネント１２０は、当該クエリを別のＮＬＰコンポーネントに提供することでこの評価を実施でき、当該２つのＮＬＰコンポーネントからの応答を比較することができる。フィードバックモニタコンポーネント１２０は、当該クエリおよびサードパーティ評価者への応答を提供することでこの評価を実施することができる。フィードバックモニタコンポーネント１２０は、複数の応答を複数のクライアントデバイスにより提供された複数の同様なクエリと比較することで、当該応答の一貫性を決定することができる。フィードバックモニタコンポーネント１２０は、クライアントデバイスが同一のクエリを含むオーディオ信号を送信する回数（例えば、当該応答がクライアントデバイスにより送信されたクエリに十分に応答していないことを示す）に基づいて当該応答の品質を決定することができる。 The feedback monitor component 120 can determine the quality of the response by analyzing the data packet containing the response. For example, the feedback monitor component 120 can analyze and analyze the text of the response, the accuracy of the response, or the relevance of the response to the query from the client device. The feedback monitor component 120 can perform this evaluation by providing the query to another NLP component and can compare the responses from the two NLP components. The feedback monitor component 120 can perform this evaluation by providing the query and the response to the third party evaluator. The feedback monitor component 120 can determine the consistency of the response by comparing the plurality of responses with a plurality of similar queries provided by the plurality of client devices. The feedback monitor component 120 of the response is based on the number of times the client device sends an audio signal containing the same query (eg, indicating that the response is not sufficiently responding to the query sent by the client device). Quality can be determined.
フィードバックモニタコンポーネント１２０は、クライアントデバイスのネットワーク活動に基づいてＮＬＰにより生成された応答の品質を決定することができる。例えば、ＮＬＰコンポーネントは、音声クエリをクライアントデバイスから受信し、当該音声クエリに対する応答を生成し、クライアントデバイスへの応答を運搬するデータパケットを送信することができる。クライアントデバイスは、ＮＬＰコンポーネントから応答を受信すると、ネットワーク活動を実施するかまたはネットワーク活動を変更することができる。例えば、クライアントデバイスは通信セッションを終了することができる。これは、ＮＬＰコンポーネントが完全にクライアントデバイスに応答したこと、またはＮＬＰがクライアントデバイスに完全に応答するのに失敗し、クライアントデバイスがＮＬＰコンポーネントに関して諦めたことを示すことができる。当該フィードバックモニタコンポーネントは、クライアントデバイスが、ＮＬＰコンポーネントにより生成された応答に関連付けられた確信度スコアに基づく良いまたは悪い理由のために通話を終了したと判定することができる。当該確信度スコアを、当該応答を生成するために使用される確率論的または統計的セマンティック分析に関連付けることができる。 The feedback monitor component 120 can determine the quality of the response generated by NLP based on the network activity of the client device. For example, the NLP component can receive a voice query from a client device, generate a response to the voice query, and send a data packet carrying the response to the client device. Upon receiving the response from the NLP component, the client device can perform or modify network activity. For example, a client device can end a communication session. This can indicate that the NLP component has fully responded to the client device, or that the NLP has failed to fully respond to the client device and the client device has given up on the NLP component. The feedback monitor component can determine that the client device has terminated the call for good or bad reasons based on the confidence score associated with the response generated by the NLP component. The confidence score can be associated with the probabilistic or statistical semantic analysis used to generate the response.
フィードバックモニタコンポーネント１２０は、クライアントデバイスが、クライアントデバイスにより送信されたオーディオ信号の欠如に基づいて通信セッションを終了したと判定することができる。フィードバックモニタコンポーネント１２０は、クライアントデバイスが、クライアントデバイスにより送信された終了コマンドに基づいて当該通信セッションを終了したと判定することができる。フィードバックモニタコンポーネント１２０は、クライアントデバイスからの沈黙の量（例えば、オーディオ信号の欠如）に基づいて品質レベルを決定することができる。クライアントデバイスからのＳＮＲが閾値（例えば、６ｄＢ、３ｄＢ、または０ｄＢ）より小さいことに基づいて、オーディオ信号の欠如を識別することができる。当該フィードバックモニタコンポーネントは、当該通信セッションの期間に基づいて当該特性を測定することができる。例えば、閾値より大きい期間は、クライアントデバイスのエンド・ユーザが当該通信セッションに満足していること示すことができる。しかし当該クライアントのユーザが当該通信セッションに関与する不要なまたは望まない拡張された時間量を費やしたかもしれないので、オーディオ信号の増大された振幅、反復されたクエリ、および減少したテンポのような他の特性と結合された長期間は低品質を示してもよい。 The feedback monitor component 120 can determine that the client device has terminated the communication session based on the lack of audio signals transmitted by the client device. The feedback monitor component 120 can determine that the client device has terminated the communication session based on the termination command sent by the client device. The feedback monitor component 120 can determine the quality level based on the amount of silence from the client device (eg, lack of audio signal). The lack of an audio signal can be identified based on the SNR from the client device being less than a threshold (eg, 6 dB, 3 dB, or 0 dB). The feedback monitor component can measure the characteristics based on the duration of the communication session. For example, a period greater than the threshold can indicate that the end user of the client device is satisfied with the communication session. However, such as increased amplitude of the audio signal, repeated queries, and decreased tempo because the user of the client may have spent an unnecessary or unwanted extended amount of time involved in the communication session. Poor quality may be exhibited for long periods of time combined with other properties.
ＮＬＰコンポーネントは、クライアントデバイスにより送信されたクエリに対するセマンティック分析を実施して、クライアントデバイスが、ＮＬＰコンポーネントが生成され応答を提供しているけれども、同一のまたは同様なクエリを反復的に送信すると判定することができる。フィードバックモニタコンポーネント１２０は、閾値（例えば、２、３、４、５、６、７またはそれ以上）を超える時間間隔（または逐次的に反復されたクエリ）内の反復クエリの数に基づいて、品質レベルが低いと判定することができる。 The NLP component performs a semantic analysis on the query sent by the client device and determines that the client device iteratively sends the same or similar query even though the NLP component is generated and provides a response. be able to. The Feedback Monitor component 120 provides quality based on the number of repeated queries within a time interval (or sequentially repeated queries) that exceeds a threshold (eg, 2, 3, 4, 5, 6, 7 or higher). It can be determined that the level is low.
幾つかのケースでは、フィードバックモニタコンポーネント１２０は、当該通信セッションの異なる部分（例えば、開始、中央、または終了、または時間間隔）で当該通信セッションの品質を決定することができる。例えば、フィードバックモニタコンポーネント１２０は、当該通信セッションの第１の部分または第１の時間間隔の品質、および第１の部分または第１の時間間隔に続く当該通信セッション内の第２の部分または第２の時間間隔の品質を決定することができる。フィードバックモニタコンポーネント１２０は、当該品質を当該２つの部分で比較して、全体の通信セッションの品質を決定することができる。例えば、閾値より大きい当該２つの部分の間の品質の差異は、低品質、一貫しない品質、または信頼できない品質を示すことができる。 In some cases, the feedback monitor component 120 can determine the quality of the communication session at different parts of the communication session (eg, start, center, or end, or time interval). For example, the feedback monitor component 120 provides the quality of the first part or first time interval of the communication session, and the second part or second part of the communication session following the first part or first time interval. The quality of the time interval can be determined. The feedback monitor component 120 can compare the quality between the two parts to determine the quality of the overall communication session. For example, a quality difference between the two parts that is greater than the threshold can indicate poor quality, inconsistent quality, or unreliable quality.
幾つかのケースでは、フィードバックモニタコンポーネント１２０は、当該通信セッションの特性またはその少なくとも一部に基づいて当該品質を決定することができる。当該特性は、例えば、振幅、周波数、テンポ、トーン、およびピッチのうち少なくとも１つを含むことができる。例えば、フィードバックモニタコンポーネント１２０は、当該クライアントのユーザデバイスの反応または当該クライアントのユーザの感情を決定するために当該特性を使用することができる。例えば、クライアントデバイスにより送信された当該オーディオ信号の振幅がＮＬＰからの各応答の後に増大した場合、当該フィードバックモニタは、エンド・ユーザがＮＬＰコンポーネント生成された応答に対して苛ついていると判定することができる。フィードバックモニタコンポーネント１２０は、クライアントデバイスにより検出された当該オーディオ信号の振幅を、同一の通信セッションまたは異なる通信セッション中にクライアントデバイスにより受信された閾値または他のオーディオ信号と比較することができる。 In some cases, the feedback monitor component 120 can determine the quality based on the characteristics of the communication session or at least a portion thereof. The property can include, for example, at least one of amplitude, frequency, tempo, tone, and pitch. For example, the feedback monitor component 120 can use the property to determine the reaction of the client's user device or the emotion of the client's user. For example, if the amplitude of the audio signal transmitted by the client device increases after each response from NLP, the feedback monitor determines that the end user is frustrated with the response generated by the NLP component. Can be done. The feedback monitor component 120 can compare the amplitude of the audio signal detected by the client device with the threshold value or other audio signal received by the client device during the same or different communication sessions.
フィードバックモニタコンポーネント１２０は、クライアントデバイスにより検出されたおよびＮＬＰコンポーネントに送信されたオーディオ信号のテンポまたはピッチのような特性に基づいて品質を決定することができる。フィードバックモニタコンポーネント１２０は、例えば、各ＮＬＰ応答の後の当該テンポのスローダウン（例えば、時間間隔当たりに話された単語の割合）が、エンド・ユーザが、ＮＬＰコンポーネントにより生成された応答に満足しておらず、ＮＬＰコンポーネントが当該オーディオ信号をより良く解析し当該応答を改善できるようにより遅く繰り返していると示しうると判定することができる。幾つかのケースでは、増大したまたは一定のテンポが、クライアントデバイスの利用が、ＮＬＰにより生成された応答で満足され当該応答における確信度を有することを示すことができる。幾つかのケースでは、クライアントデバイスにより検出されたオーディオ信号のピッチの増大は、ＮＬＰからの応答の貧弱な品質または当該応答における確信度の欠如を示すことができる。 The feedback monitor component 120 can determine the quality based on characteristics such as tempo or pitch of the audio signal detected by the client device and transmitted to the NLP component. The feedback monitor component 120, for example, slows down the tempo after each NLP response (eg, the percentage of words spoken per time interval) so that the end user is satisfied with the response generated by the NLP component. It can be determined that the NLP component can better analyze the audio signal and indicate that it is repeating slower so that the response can be improved. In some cases, an increased or constant tempo can indicate that client device utilization is satisfied with the response generated by NLP and has confidence in that response. In some cases, an increase in the pitch of the audio signal detected by the client device can indicate poor quality of the response from NLP or lack of confidence in the response.
幾つかのケースでは、フィードバックモニタコンポーネント１２０は、品質を測定または決定するためのクエリをクライアントデバイスに送信することができる。例えば、フィードバックモニタコンポーネント１２０は、通信セッションの品質、ＮＬＰコンポーネント、またはプロバイダデバイスに関してエンド・ユーザに調査質問を送信することができる。幾つかのケースでは、フィードバックモニタコンポーネント１２０は、第１の品質信号が閾値より小さいとフィードバックモニタコンポーネント１２０が判定したことに応答して当該クエリを生成することができる。例えば、フィードバックモニタコンポーネント１２０は、クライアントデバイスにより検出された当該オーディオ信号のテンポの減少と組み合わせたクライアントデバイスにより検出された当該オーディオ信号の振幅の増大のような特性を用いて当該品質を測定することに基づいて第１の品質信号を決定することができる。フィードバックモニタコンポーネント１２０は、振幅およびテンポの結合された特性に基づいて低いレベルの品質を示す品質信号を生成することができる。当該結合特性に基づいて決定された低品質信号に応答して、フィードバックモニタコンポーネント１２０は、当該通信セッションの品質を暗黙的にまたは明示的に問い合わせる（例えば、ＮＬＰコンポーネントにより生成された応答にどれだけ満足していますか？、当該通信セッションにはどれだけ満足していますか？）クエリを生成しクライアントデバイスに送信することができる。別の例では、データ処理システムは、サービスプロバイダ１０８が当該要求されたサービスを提供できるかどうかに基づいて品質を決定することができる。例えば、エンド・ユーザは製品またはサービスを要求しうるが、サービスプロバイダ１０８は、彼らがその製品を持っておらずまたはそのサービスを実施できないと述べることで応答する。これは、エンド・ユーザにサービスプロバイダ１０８に対するフラストレーションを示させることができる。データ処理システム１０２は、このフラストレーションを識別し、それに応じて品質を割り当てることができる。 In some cases, the feedback monitor component 120 can send a query to the client device to measure or determine quality. For example, the feedback monitor component 120 can send survey questions to the end user regarding the quality of the communication session, the NLP component, or the provider device. In some cases, the feedback monitor component 120 can generate the query in response to the feedback monitor component 120 determining that the first quality signal is less than the threshold. For example, the feedback monitor component 120 measures the quality using characteristics such as an increase in the amplitude of the audio signal detected by the client device in combination with a decrease in the tempo of the audio signal detected by the client device. The first quality signal can be determined based on. The feedback monitor component 120 can generate a quality signal indicating a low level of quality based on the combined characteristics of amplitude and tempo. In response to a low quality signal determined based on the coupling characteristics, the feedback monitor component 120 implicitly or explicitly queries the quality of the communication session (eg, how much to the response generated by the NLP component). Are you satisfied? How satisfied are you with the communication session?) You can generate a query and send it to the client device. In another example, the data processing system can determine the quality based on whether the service provider 108 can provide the requested service. For example, end users may request a product or service, but service provider 108 responds by stating that they do not have the product or cannot perform the service. This can cause the end user to show frustration with the service provider 108. The data processing system 102 can identify this frustration and assign quality accordingly.
幾つかのケースでは、フィードバックモニタコンポーネント１２０は、複数の電子サーフェスでのネットワーク活動に基づいて特性を測定し、当該複数の電子サーフェスから測定された品質を集約して合計された品質信号を生成することができる。当該合計された品質信号は、平均、重み付き平均、絶対和、または他の結合された品質信号値であることができる。フィードバックモニタコンポーネント１２０はさらに、当該結合された品質信号値に対する統計値を生成し、または、標準偏差、分散、３シグマ品質、または６シグマ品質の決定のような統計的分析を実施することができる。 In some cases, the feedback monitor component 120 measures characteristics based on network activity on a plurality of electronic surfaces and aggregates the quality measured from the plurality of electronic surfaces to produce a summed quality signal. be able to. The summed quality signal can be average, weighted average, absolute sum, or other combined quality signal value. The feedback monitor component 120 can also generate statistics for the combined quality signal value or perform statistical analysis such as standard deviation, variance, 3 sigma quality, or 6 sigma quality determination. ..
フィードバックモニタコンポーネント１２０は、コンテンツセレクタコンポーネント１１８により実施されたリアルタイムコンテンツ選択プロセスを調節することができる。当該リアルタイムコンテンツ選択プロセスを調節することは、クライアントデバイス１０４との通信セッションを確立するために使用されるＮＬＰコンポーネントを実行したコンテンツプロバイダデバイス１０６またはサービスプロバイダデバイス１０８またはサードパーティプロバイダデバイス１０８により提供されたコンテンツ・アイテムを選択するために使用される重みを調節することを指すことができる。例えば、当該コンテンツ・アイテムが低品質通信セッションをもたらしたとき、フィードバックモニタコンポーネント１２０は、コンテンツ・アイテムが同様なアクションデータ構造または同様なクライアントデバイス１０４（またはそのアカウントまたはプロフィール）に対して選択されている可能性を減らすために、当該コンテンツ・アイテムを含むコンテンツデータ１３０の属性またはパラメータを調節することができる。 The feedback monitor component 120 can adjust the real-time content selection process performed by the content selector component 118. Coordinating the real-time content selection process was provided by the content provider device 106 or service provider device 108 or third party provider device 108 that ran the NLP component used to establish a communication session with the client device 104. It can refer to adjusting the weights used to select content items. For example, when the content item results in a poor quality communication session, the feedback monitor component 120 is selected for the content item to have a similar action data structure or a similar client device 104 (or its account or profile). The attributes or parameters of the content data 130 containing the content item can be adjusted to reduce the possibility of being present.
幾つかのケースでは、フィードバックモニタコンポーネント１２０は、当該リアルタイム選択プロセスにおいて品質信号が閾値より小さいことに応答して、当該コンテンツ・アイテムをコンテンツセレクタコンポーネント１１８が選択することを防止またはブロックすることができる。幾つかのケースでは、フィードバックモニタコンポーネント１２０は、コンテンツセレクタコンポーネント１１８が、当該リアルタイム選択プロセスにおいて、当該品質信号が閾値以上であることに応答して当該コンテンツ・アイテムを選択することを可能または許可することができる。 In some cases, the feedback monitor component 120 can prevent or block the content selector component 118 from selecting the content item in response to the quality signal being less than the threshold in the real-time selection process. .. In some cases, the feedback monitor component 120 allows or allows the content selector component 118 to select the content item in response to the quality signal being above a threshold in the real-time selection process. be able to.
図２は、コンピュータネットワーク上のデータ送信に対するフィードバック制御システムの動作の例示である。当該システムは、図１に示すシステム１００の１つまたは複数のコンポーネントを含むことができる。システム１００は、１つまたは複数のクライアントコンピューティングデバイス１０４ａ−ｎにより実行または提供される１つまたは複数の電子サーフェス２０２ａ−ｎを含むことができる。電子サーフェス２０２ａ−ｎの例はオーディオインタフェース、音声ベースのインタフェース、ディスプレイスクリーン、ＨＴＭＬコンテンツ・アイテム、マルチメディア、画像、ビデオ、テキストベースのコンテンツ・アイテム、ＳＭＳ、メッセージングアプリケーション、チャットアプリケーション、または自然言語プロセッサを含むことができる。 FIG. 2 is an example of the operation of the feedback control system for data transmission on a computer network. The system may include one or more components of the system 100 shown in FIG. System 100 may include one or more electronic surfaces 202an performed or provided by one or more client computing devices 104an. Examples of electronic surfaces 202an are audio interfaces, voice-based interfaces, display screens, HTML content items, multimedia, images, videos, text-based content items, SMS, messaging applications, chat applications, or natural language processors. Can be included.
動作２０４で、クライアントコンピューティングデバイス１０４は、電子サーフェス２０２からまたはそれを介してフィードバックを示す信号または他の情報データパケットを受信することができる。動作２０６で、１つまたは複数のクライアントコンピューティングデバイス１０４ａ−ｎ、１つまたは複数のサービスプロバイダデバイス１０８ａ−ｎ、または１つまたは複数のコンテンツプロバイダデバイス１０６ａ−ｎはデータパケットをフィードバックモニタコンポーネント１２４に送信することができる。当該データパケットを、クライアントデバイス１０４およびサービスプロバイダデバイス１０８またはコンテンツプロバイダデバイス１０６のうち１つまたは複数の間で確立された当該通信セッションに関連付けることができる。当該データパケットを各デバイスからフィードバックモニタコンポーネント１２４に送信することができる。 In operation 204, the client computing device 104 can receive a signal or other information data packet indicating feedback from or through the electronic surface 202. In operation 206, one or more client computing devices 104an, one or more service provider devices 108an, or one or more content provider devices 106an send data packets to the feedback monitor component 124. Can be sent. The data packet can be associated with the communication session established between one or more of the client device 104 and the service provider device 108 or the content provider device 106. The data packet can be transmitted from each device to the feedback monitor component 124.
幾つかのケースでは、フィードバックモニタコンポーネント１２４は、デバイス１０４、１０６または１０８から各デバイスに送信されたデータパケットをインターセプトしてもよい。フィードバックモニタコンポーネント１２４は、当該インターセプトされたデータパケットを分析し、当該データパケットをその意図した宛先にルーティングまたは転送することができる。したがって、フィードバックモニタコンポーネント１２４は、クライアントデバイス１０４およびサービス／サードパーティプロバイダデバイス１０８またはコンテンツプロバイダデバイス１０６に対する中間物であることができる。 In some cases, the feedback monitor component 124 may intercept data packets transmitted from the device 104, 106 or 108 to each device. The feedback monitor component 124 can analyze the intercepted data packet and route or forward the data packet to its intended destination. Thus, the feedback monitor component 124 can be an intermediate to the client device 104 and the service / third party provider device 108 or the content provider device 106.
動作２０８で、フィードバックモニタコンポーネント１２４は、当該通信セッションからインターセプトされたまたは受信されたデータパケットをＮＬＰコンポーネント１１２に送信することができる。動作２１０で、ＮＬＰコンポーネント１１２は、当該データパケットのセマンティック分析を実施し、それらをフィードバックコンポーネント１２４に提供し戻すことができる。幾つかのケースでは、ＮＬＰコンポーネント１１２は、通信セッション２０６からのオーディオ信号に自然言語処理を実施して、プロバイダデバイス１０６または１０８により生成されたＮＬＰコンポーネントの応答を比較することができる。フィードバックモニタコンポーネント１２４は、制御ＮＬＰコンポーネント１１２により生成された応答を比較して、当該サードパーティＮＬＰコンポーネントが比較可能なまたは満足できるレベルで機能しているかどうかを判定することができる。 In operation 208, the feedback monitor component 124 can send data packets intercepted or received from the communication session to the NLP component 112. In operation 210, the NLP component 112 can perform a semantic analysis of the data packets and provide them back to the feedback component 124. In some cases, the NLP component 112 can perform natural language processing on the audio signal from the communication session 206 to compare the response of the NLP component generated by the provider device 106 or 108. The feedback monitor component 124 can compare the responses generated by the control NLP component 112 to determine if the third party NLP component is functioning at a comparable or satisfactory level.
動作２１２で、フィードバックモニタコンポーネント１２４は、通信セッション２０６に対する品質信号を決定し、コンテンツセレクタコンポーネント１１８により実施された当該リアルタイムコンテンツ選択プロセスを調節して、次回にコンテンツセレクタコンポーネント１１８がコンテンツに対する要求を受信したとき、コンテンツセレクタコンポーネント１１８が通信セッション２０６に関連付けられたコンテンツ・アイテム（またはコンテンツプロバイダ）を適切に重み付けして、当該コンテンツ・アイテムが選択されている可能性を増大または減少できるようにすることができる。例えば、プロバイダ１０８が複数の低品質通信セッションに関連付けられる場合、フィードバックモニタコンポーネント１２４は、プロバイダ１０８との通信セッションの確立をもたらしうるコンテンツ・アイテムの選択を防止するようにコンテンツセレクタコンポーネント１１８に指示することができる。 In operation 212, the feedback monitor component 124 determines the quality signal for the communication session 206 and adjusts the real-time content selection process performed by the content selector component 118 so that the content selector component 118 receives the request for the content next time. When this happens, the content selector component 118 appropriately weights the content item (or content provider) associated with the communication session 206 so that it can increase or decrease the likelihood that the content item is selected. Can be done. For example, if the provider 108 is associated with multiple low quality communication sessions, the feedback monitor component 124 instructs the content selector component 118 to prevent selection of content items that could result in the establishment of a communication session with the provider 108. be able to.
図３は、パケット化されたオーディオ信号の動的変調を実施するための例示的な方法の例示である。方法３００を、システム１００またはシステム４００の１つまたは複数のコンポーネント、システムまたは要素により実施することができる。方法３００は、データ処理システムが入力オーディオ信号を受信することを含むことができる（動作３０５）。データ処理システムは当該入力オーディオ信号をクライアントコンピューティングデバイスから受信することができる。例えば、データ処理システムにより実行される自然言語プロセッサコンポーネントは当該入力オーディオ信号を、データ処理システムのインタフェースを介してクライアントコンピューティングデバイスから受信することができる。データ処理システムは、当該クライアントコンピューティングデバイス（またはクライアントデバイス）のセンサにより検出された入力オーディオ信号を運搬または含むデータパケットを受信することができる。 FIG. 3 illustrates an exemplary method for performing dynamic modulation of a packetized audio signal. Method 300 can be implemented by one or more components, systems or elements of system 100 or system 400. Method 300 can include the data processing system receiving an input audio signal (operation 305). The data processing system can receive the input audio signal from the client computing device. For example, a natural language processor component executed by a data processing system can receive the input audio signal from a client computing device via the interface of the data processing system. The data processing system can receive data packets that carry or include input audio signals detected by the sensors of the client computing device (or client device).
動作３１０で、方法３００はデータ処理システムが入力オーディオ信号を解析することを含むことができる。自然言語プロセッサコンポーネントは当該入力オーディオ信号を解析して、要求および当該要求に対応するトリガキーワードを識別することができる。例えば、クライアントデバイスにより検出された当該オーディオ信号は、「Okay device, I need a ride from Taxi Service Company A to go to 1234 Main Street」を含むことができる。このオーディオ信号において、当該初期トリガキーワードは「Okay device」を含むことができ、これは、クライアントデバイスが入力オーディオ信号をデータ処理システムに送信することを示すことができる。クライアントデバイスのプリプロセッサは、残りのオーディオ信号をデータ処理システムに送信する前に用語「Okay device」をフィルタして除外することができる。幾つかのケースでは、クライアントデバイスは、追加の用語をフィルタして除外するか、または、さらなる処理のためにキーワードをデータ処理システムに送信することができる。 In operation 310, method 300 can include the data processing system parsing the input audio signal. The natural language processor component can analyze the input audio signal to identify the request and the trigger keyword corresponding to the request. For example, the audio signal detected by the client device can include "Okay device, I need a ride from Taxi Service Company A to go to 1234 Main Street". In this audio signal, the initial trigger keyword can include "Okay device", which can indicate that the client device sends the input audio signal to the data processing system. The preprocessor of the client device can filter out the term "Okay device" before sending the remaining audio signal to the data processing system. In some cases, the client device can filter out additional terms or send keywords to the data processing system for further processing.
データ処理システムは当該入力オーディオ信号内のトリガキーワードを識別することができる。当該トリガキーワードは、例えば、「to go to」または「ride」またはこれらの用語の変形を含むことができる。当該トリガキーワードはサービスまたは製品のタイプを示すことができる。データ処理システムは当該入力オーディオ信号内の要求を識別することができる。当該要求を用語「I need」に基づいて決定することができる。当該トリガキーワードおよび要求を、セマンティック処理技術または他の自然言語処理技術を用いて決定することができる。 The data processing system can identify the trigger keyword in the input audio signal. The trigger keyword may include, for example, "to go to" or "ride" or a variant of these terms. The trigger keyword can indicate the type of service or product. The data processing system can identify the request in the input audio signal. The requirement can be determined based on the term "I need". The trigger keywords and requirements can be determined using semantic processing techniques or other natural language processing techniques.
幾つかのケースでは、データ処理システムはアクションデータ構造を生成することができる。データ処理システムは当該トリガキーワード、要求、サードパーティプロバイダデバイス、または他の情報に基づいて、当該アクションデータ構造を生成することができる。当該アクションデータ構造は当該要求に応答することができる。例えば、当該クライアントコンピューティングデバイスのエンド・ユーザがタクシーをタクシーサービス会社Ａに要求した場合、当該アクションデータ構造はタクシーサービス会社Ａへタクシーサービスを要求する情報を含むことができる。データ処理システムは、タクシーサービス会社Ａに対するテンプレートを選択し、当該テンプレート内のフィールドを値で埋め、タクシーサービス会社Ａがタクシー当該クライアントのユーザコンピューティングデバイスに送り、ユーザをピックアップしユーザを当該要求された宛先に輸送できるようにすることができる。 In some cases, the data processing system can generate action data structures. The data processing system can generate the action data structure based on the trigger keyword, request, third party provider device, or other information. The action data structure can respond to the request. For example, if the end user of the client computing device requests a taxi from a taxi service company A, the action data structure may include information requesting a taxi service from the taxi service company A. The data processing system selects a template for taxi service company A, fills the fields in the template with values, and taxi service company A sends the taxi to the user computing device of the client, picks up the user, and requests the user. It can be made to be transported to the destination.
動作３１５で、データ処理システムはコンテンツ・アイテムを選択することができる。例えば、コンテンツセレクタコンポーネントは、トリガキーワード、要求またはアクションデータ構造を受信し、リアルタイムコンテンツ選択プロセスを介してコンテンツ・アイテムを選択することができる。当該選択されたコンテンツ・アイテムはコンテンツプロバイダ、サービスプロバイダ、または他のサードパーティプロバイダに対応することができる。クライアントデバイスは、当該コンテンツ・アイテムと対話して、当該コンテンツ・アイテムのプロバイダまたは当該コンテンツ・アイテムに関連付けられた他のデバイスとの通信セッションを確立することができる。当該コンテンツ・アイテムに関連付けられたデバイスは、ＮＬＰのような会話ＡＰＩを用いてクライアントデバイスと対話することができる。 At operation 315, the data processing system can select content items. For example, a content selector component can receive a trigger keyword, request or action data structure and select a content item through a real-time content selection process. The selected content item can correspond to a content provider, service provider, or other third-party provider. The client device can interact with the content item to establish a communication session with the content item provider or other device associated with the content item. The device associated with the content item can interact with the client device using a conversational API such as NLP.
動作３２０で、フィードバックモニタコンポーネントは、当該コンテンツ・アイテムとの対話に応答してクライアントデバイスとの通信セッションを確立したクライアントデバイスおよび会話アプリケーションプログラミングインタフェースの間で送信された可聴信号を運搬するデータパケットを受信することができる。動作３２５で、当該フィードバックモニタコンポーネントは、当該可聴信号に基づいて当該通信セッションの品質または特性を測定し、当該測定された特性に基づいて品質信号を生成することができる。動作３３０で、当該フィードバックモニタコンポーネントまたはデータ処理システムは当該品質信号に基づいて当該リアルタイム選択プロセスを調節することができる。 At operation 320, the feedback monitor component carries a data packet carrying an audible signal transmitted between the client device and the conversational application programming interface that has established a communication session with the client device in response to the interaction with the content item. Can be received. In operation 325, the feedback monitor component can measure the quality or characteristics of the communication session based on the audible signal and generate a quality signal based on the measured characteristics. At operation 330, the feedback monitor component or data processing system can adjust the real-time selection process based on the quality signal.
図４は例示的なコンピュータシステム４００のブロック図である。当該コンピュータシステムまたはコンピューティングデバイス４００は、システム１００、またはデータ処理システム１０２のようなそのコンポーネントを含むことができるかまたはそれを実装するために使用される。データ処理システム１０２はインテリジェント・パーソナル・アシスタントまたは音声ベースのデジタルアシスタントを含むことができる。コンピューティングシステム４００は、情報を通信するためのバス４０５または他の通信コンポーネントおよび情報を処理するためにバス４０５に接続されるプロセッサ４１０または処理回路を含む。コンピューティングシステム４００はまた１つまたは複数のプロセッサ４１０または情報を処理するための当該バスに接続される処理回路を含むことができる。コンピューティングシステム４００はまた、情報、およびプロセッサ４１０により実行される命令を格納するためのバス４０５に接続されたランダム・アクセスメモリ（ＲＡＭ）または他の動的記憶デバイスのようなメイン・メモリ４１５を含む。メイン・メモリ４１５はデータリポジトリ１４５であることができるかまたはそれを含むことができる。メイン・メモリ４１５をまた、プロセッサ４１０による命令の実行中に位置情報、一時的変数、または他の中間情報を格納するために使用することができる。コンピューティングシステム４００はさらに、プロセッサ４１０のための静的情報および命令を格納するためにバス４０５に接続される読取専用メモリ（ＲＯＭ）４２０または他の静的記憶デバイスを含んでもよい。固体状態デバイス、磁気ディスクまたは光ディスクのような記憶デバイス４２５を、永続的に情報および命令を格納するためにバス４０５に接続することができる。記憶デバイス４２５はデータリポジトリ１４５を含むことができるかまたはその一部であることができる。 FIG. 4 is a block diagram of an exemplary computer system 400. The computer system or computing device 400 can include or is used to include or implement a system 100, or its components such as a data processing system 102. The data processing system 102 can include an intelligent personal assistant or a voice-based digital assistant. The computing system 400 includes a bus 405 or other communication component for communicating information and a processor 410 or processing circuit connected to the bus 405 for processing information. The computing system 400 can also include one or more processors 410 or a processing circuit connected to the bus for processing information. The computing system 400 also provides main memory 415, such as random access memory (RAM) or other dynamic storage device, connected to bus 405 for storing information and instructions executed by processor 410. Including. The main memory 415 can be or can be a data repository 145. Main memory 415 can also be used to store location information, temporary variables, or other intermediate information during instruction execution by processor 410. The computing system 400 may further include read-only memory (ROM) 420 or other static storage device connected to bus 405 to store static information and instructions for processor 410. A storage device 425, such as a solid state device, magnetic disk or optical disk, can be connected to bus 405 to permanently store information and instructions. The storage device 425 can include or be part of a data repository 145.
コンピューティングシステム４００を、情報をユーザに表示するために、バス４０５を介して、液晶ディスプレイ、またはアクティブ行列ディスプレイのようなディスプレイ４３５に接続してもよい。英数字および他のキーを含むキーボードのような入力デバイス４３０を、情報およびコマンド選択をプロセッサ４１０に通信するためにバス４０５に接続してもよい。入力デバイス４３０はタッチ・スクリーンディスプレイ４３５を含むことができる。入力デバイス４３０はまた、マウス、トラックボール、またはカーソル方向キーのようなカーソル・コントロールを、プロセッサ４１０に通信しディスプレイ４３５上のカーソル移動を制御するための方向情報およびコマンド選択を含むことができる。ディスプレイ４３５は、例えば、図１のデータ処理システム１０２の一部、クライアントコンピューティングデバイス１５０または他のコンポーネントであることができる。 The computing system 400 may be connected via a bus 405 to a liquid crystal display or a display 435 such as an active matrix display to display information to the user. An input device 430, such as a keyboard containing alphanumeric characters and other keys, may be connected to bus 405 to communicate information and command selections to processor 410. The input device 430 can include a touch screen display 435. The input device 430 can also include directional information and command selection for communicating a cursor control such as a mouse, trackball, or cursor direction key to the processor 410 to control cursor movement on the display 435. The display 435 can be, for example, a portion of the data processing system 102 of FIG. 1, a client computing device 150 or other component.
本明細書で説明したプロセス、システムおよび方法を、プロセッサ４１０がメイン・メモリ４１５に含まれる命令の配置を実行したことに応答して、コンピューティングシステム４００により実装することができる。かかる命令を、記憶デバイス４２５のような別のコンピュータ可読媒体からメイン・メモリ４１５に読み込むことができる。メイン・メモリ４１５に含まれる命令の配置の実行は、コンピューティングシステム４００に本明細書で説明した例示的なプロセスを実施させる。マルチプロセッシング配置における１つまたは複数のプロセッサをまた、メイン・メモリ４１５に含まれる命令を実行するために使用することができる。ハードワイヤード回路を、本明細書で説明するシステムおよび方法とともにソフトウェア命令の代わりにまたはそれを組み合わせて使用することができる。本明細書で説明したシステムおよび方法はハードウェア回路およびソフトウェアの任意の特定の組合せに限定されない。 The processes, systems and methods described herein can be implemented by the computing system 400 in response to processor 410 performing the placement of instructions contained in main memory 415. Such instructions can be read into main memory 415 from another computer-readable medium, such as storage device 425. Execution of the placement of instructions contained in main memory 415 causes the computing system 400 to perform the exemplary process described herein. One or more processors in a multiprocessing arrangement can also be used to execute instructions contained in main memory 415. Hardwired circuits can be used in place of or in combination with software instructions with the systems and methods described herein. The systems and methods described herein are not limited to any particular combination of hardware circuits and software.
例示的なコンピューティングシステムを図４で説明したが、本明細書で説明した動作を含む当該主題を、本明細書で開示した構造およびそれらの構造的均等物を含む他のタイプのデジタル電子回路で、またはコンピュータソフトウェア、ファームウェア、またはハードウェアで、またはそれらの１つまたは複数の組合せで実装することができる。 Although an exemplary computing system has been described in FIG. 4, other types of digital electronic circuits, including the structures disclosed herein and their structural equivalents, cover the subject matter including the operations described herein. It can be implemented in, or in computer software, firmware, or hardware, or in one or more combinations thereof.
本明細書で説明するシステムがユーザに関する個人情報を収集するか、または個人情報を利用しうる状況に対して、ユーザにプログラムまたは機能が個人情報（例えば、ユーザのソーシャルネットワーク、ソーシャルアクションまたはアクティビティ、ユーザの嗜好、またはユーザの位置に関する情報）を収集しうるかどうか、またはユーザにより関連しうるコンテンツサーバまたは他のデータ処理システムからコンテンツを受信するかどうかまたはその方法を制御するための機会を与えてもよい。さらに、特定のデータはそれが格納または使用される前に１つまたは複数の方法で匿名化してもよく、その結果個人的に識別可能な情報がパラメータを生成するときに除去される。例えば、ユーザのアイデンティティを匿名化してもよく、その結果個人的に識別可能な情報をユーザに対して決定できず、またはユーザの特定の位置を決定できないように、ユーザの地理的位置を位置情報が取得される場所で（例えば都市、郵便番号、または状態レベルに）一般化してもよい。したがって、ユーザは、どのように情報がユーザに関して収集され当該コンテンツサーバにより使用されるかを制御することができる。 For situations where the system described herein collects or may use personal information about you, the program or function gives you personal information (eg, your social network, social actions or activities, etc.). Given the opportunity to control whether or not information about a user's preferences or location of a user can be collected, or whether or how content is received from a content server or other data processing system that may be more relevant to the user. May be good. In addition, certain data may be anonymized in one or more ways before it is stored or used, so that personally identifiable information is removed when generating parameters. For example, the user's geographic location may be anonymized so that personally identifiable information cannot be determined for the user or the user's specific location cannot be determined as a result. May be generalized where it is obtained (eg to city, zip code, or state level). Therefore, the user can control how information is collected about the user and used by the content server.
当該主題および本明細書で説明した動作を、本明細書で開示した構造およびそれらの構造的均等物を含むデジタル電子回路で、またはコンピュータソフトウェア、ファームウェア、またはドウェアで、またはそれらの１つまたは複数の組合せで実装することができる。本明細書で説明した当該主題を、データ処理装置による実行のためにまたは当該装置の動作を制御するために１つまたは複数のコンピュータ記憶媒体で符号化された、１つまたは複数のコンピュータプログラム、例えば、コンピュータプログラム命令の１つまたは複数の回路として実装することができる。代替的にまたは追加として、当該プログラム命令を、人工的に生成された伝播信号、例えば、データ処理装置による実行のために適切な受信器装置に送信するための情報を符号化するために生成されたマシン生成された電気、光、または電磁気信号で符号化することができる。コンピュータ記憶媒体は、コンピュータ可読記憶デバイス、コンピュータ可読記憶基板、ランダムなまたはシリアル・アクセスメモリ・アレイまたはデバイス、またはそれらの１つまたは複数の組合せであることができ、または、それらに含まれることができる。コンピュータ記憶媒体は伝播信号ではないが、コンピュータ記憶媒体は、人工的に生成された伝播信号で符号化されたコンピュータプログラム命令のソースまたは宛先であることができる。当該コンピュータ記憶媒体はまた、１つまたは複数の別々のコンポーネントまたは媒体（例えば、複数のＣＤ、ディスク、または他の記憶デバイス）であることができ、または、それに含まれることができる。本明細書で説明した動作を、１つまたは複数のコンピュータ可読記憶デバイスに格納されまたは他のソースから受信されたデータに対してデータ処理装置により実施される動作として実装することができる。 The subject matter and the operations described herein can be performed in digital electronic circuits, including the structures disclosed herein and their structural equivalents, or in computer software, firmware, or software, or one or more of them. It can be implemented by the combination of. One or more computer programs, the subject matter described herein, encoded in one or more computer storage media for execution by a data processing device or to control the operation of the device. For example, it can be implemented as one or more circuits of computer program instructions. Alternatively or additionally, the program instruction is generated to encode an artificially generated propagating signal, eg, information to be sent to an appropriate receiver device for execution by a data processing device. It can be encoded with a machine-generated electrical, optical, or electromagnetic signal. The computer storage medium can be, or can be contained in, a computer-readable storage device, a computer-readable storage board, a random or serial access memory array or device, or a combination thereof. it can. Although the computer storage medium is not a propagation signal, the computer storage medium can be the source or destination of a computer program instruction encoded by an artificially generated propagation signal. The computer storage medium can also be or can be one or more separate components or media (eg, multiple CDs, discs, or other storage devices). The operations described herein can be implemented as operations performed by a data processor on data stored in one or more computer-readable storage devices or received from other sources.
「データ処理システム」「コンピューティングデバイス」「コンポーネント」または「データ処理装置」という用語は、例としてプログラム可能プロセッサ、コンピュータ、システム・オン・チップ、または以上のうち複数または組合せを含む、データを処理するための様々な装置、デバイス、およびマシンを包含する。当該装置は、特殊目的論理回路、例えば、ＦＰＧＡ（フィールドプログラム可能ゲート・アレイ）またはＡＳＩＣ（特殊用途向け集積回路）を含むことができる。当該装置はまた、ハードウェアに加えて、着目するコンピュータプログラムに対する実行環境を生成するコード、例えば、プロセッサファームウェア、プロトコル・スタック、データベース管理システム、オペレーティング・システム、クロス・プラットフォームランタイム環境、仮想マシン、またはそれらの１つまたは複数の組合せを構成するコードを含むことができる。当該装置および実行環境は、ウェブサービス、分散コンピューティングおよびグリッド・コンピューティングインフラのような様々な異なるコンピューティングモデルインフラを実現することができる。例えば、ダイレクト・アクションＡＰＩ１１６、コンテンツセレクタコンポーネント１１８、またはＮＬＰコンポーネント１１２および他のデータ処理システム１０２コンポーネントは、１つまたは複数のデータ処理装置、システム、コンピューティングデバイス、またはプロセッサを含むかまたは共有ことができる。 The terms "data processing system," "computing device," "component," or "data processing device" process data, including, for example, programmable processors, computers, system-on-chips, or multiple or combinations of the above. Includes various devices, devices, and machines for. The device can include special purpose logic circuits, such as FPGAs (Field Programmable Gate Arrays) or ASICs (Application Specific Integrated Circuits). In addition to the hardware, the device also generates code that generates an execution environment for the computer program of interest, such as processor firmware, protocol stacks, database management systems, operating systems, cross-platform runtime environments, virtual machines, or It can include codes that make up one or more combinations of them. The device and execution environment can implement a variety of different computing model infrastructures such as web services, distributed computing and grid computing infrastructures. For example, a direct action API 116, a content selector component 118, or an NLP component 112 and another data processing system 102 component may include or share one or more data processing devices, systems, computing devices, or processors. it can.
Ａコンピュータプログラム（プログラム、ソフトウェア、ソフトウェアアプリケーション、アプリ、スクリプト、またはコードとしても知られる）を、コンパイル型言語またはインタプリタ型言語、宣言型または手続型言語を含む任意の形態のプログラミング言語で書くことができ、スタンドアロンプログラムまたはモジュール、コンポーネント、サブルーチン、オブジェクト、またはコンピューティング環境で使用するのに適した他のユニットを含む任意の形態で展開することができる。コンピュータプログラムはイルシステム内のファイルに対応することができる。コンピュータプログラムを、他のプログラムまたはデータを保持するファイル部分（例えば、マークアップ言語ドキュメントに格納された１つまたは複数のスクリプト）に、着目するプログラム専用の単一のファイルに、または複数の協調ファイルに（例えば、１つまたは複数のモジュール、サブプログラム、またはコード部分を格納するファイル）格納することができる。コンピュータプログラムを、１つのコンピュータ上でまたは１つのサイトに配置されるかまたは複数のサイトにわたって分散され通信ネットワークにより相互接続された複数のコンピュータ上で実行されるように展開することができる。 A. Writing a computer program (also known as a program, software, software application, app, script, or code) in any form of programming language, including compiled or interpreted languages, declarative or procedural languages. It can be deployed in any form, including stand-alone programs or modules, components, subroutines, objects, or other units suitable for use in a computing environment. Computer programs can handle files in the Ilsystem. Computer programs in other programs or file parts that hold data (eg, one or more scripts stored in a markup language document), in a single file dedicated to the program of interest, or in multiple collaborative files. (For example, a file that stores one or more modules, subprograms, or code parts). Computer programs can be deployed to run on one computer, at one site, or on multiple computers distributed across multiple sites and interconnected by communication networks.
本明細書で説明した当該プロセスおよび論理フローを、入力データで動作し出力を生成することによって、１つまたは複数のコンピュータプログラムを実行する１つまたは複数のプログラム可能プロセッサ（例えば、データ処理システム１０２のコンポーネント）により実施して、アクションを実施することができる。当該プロセスおよび論理フローはまた、特殊目的論理回路、例えば、ＦＰＧＡ（フィールドプログラム可能ゲート・アレイ）またはＡＳＩＣ（特殊用途向け集積回路）により実施でき、装置をまた特殊目的論理回路、例えば、ＦＰＧＡ（フィールドプログラム可能ゲート・アレイ）またはＡＳＩＣ（特殊用途向け集積回路）として実装することができる。コンピュータプログラム命令およびデータを格納するのに適したデバイス、例として半導体メモリデバイス、例えば、ＥＰＲＯＭ、ＥＥＰＲＯＭ、およびフラッシュ・メモリデバイスを含むあらゆる形態の非揮発性メモリ、媒体およびメモリデバイス、磁気ディスク、例えば、内部ハードディスクまたは取外し可能ディスク、磁気光ディスク、およびＣＤＲＯＭおよびＤＶＤ−ＲＯＭディスクを含む。当該プロセッサおよび当該メモリを特殊目的論理回路で補完するかまたはそれに組み込むことができる。 One or more programmable processors (eg, data processing system 102) that execute one or more computer programs by operating the processes and logical flows described herein on input data and producing outputs. Actions can be performed by performing with (components of). The process and logic flow can also be implemented by special purpose logic circuits such as FPGAs (Field Programmable Gate Arrays) or ASICs (Application Specific Integrated Circuits) and devices can also be implemented by special purpose logic circuits such as FPGAs (Fields). It can be implemented as a programmable gate array) or an ASIC (application specific integrated circuit). All forms of non-volatile memory, media and memory devices, magnetic disks, eg, including semiconductor memory devices such as EPROM, EEPROM, and flash memory devices, suitable for storing computer program instructions and data. Includes internal hard disks or removable disks, magnetic optical disks, and CDROM and DVD-ROM disks. The processor and the memory can be complemented or incorporated into a special purpose logic circuit.
本明細書で説明する主題を、バックエンドコンポーネントを、例えば、データサーバとして含むか、またはミドルウェアコンポーネント、例えば、アプリケーションサーバを含むか、またはフロントエンドコンポーネント、例えば、ユーザがそれを通じて本明細書で説明した当該主題の実装と対話できるグラフィカルユーザインタフェースまたはウェブブラウザを有するクライアントコンピュータ、または１つまたは複数のかかるバックエンド、ミドルウェア、またはフロントエンドコンポーネントの組合せを含むコンピューティングシステムで実装することができる。当該システムの当該コンポーネントはデジタルデータ通信、例えば、通信ネットワークの任意の形態または媒体により相互接続することができる。通信ネットワークの例は、ローカル・エリア・ネットワーク（「ＬＡＮ」）および広帯域ネットワーク（「ＷＡＮ」）、インターネットワーク（例えば、インターネット）、およびピア・ツー・ピアネットワーク（例えば、アドホックピア・ツー・ピアネットワーク）を含む。 The subject matter described herein includes a back-end component, eg, as a data server, or a middleware component, eg, an application server, or a front-end component, eg, a user, through which the subject matter is described herein. It can be implemented on a client computer with a graphical user interface or web browser capable of interacting with the implementation of the subject, or on a computing system that includes one or more such combinations of backend, middleware, or frontend components. The components of the system can be interconnected by digital data communication, eg, any form or medium of communication network. Examples of communication networks are local area networks (“LAN”) and broadband networks (“WAN”), internetworks (eg, the Internet), and peer-to-peer networks (eg, ad hoc peer-to-peer networks). )including.
システム１００またはシステム４００のようなコンピューティングシステムはクライアントおよびサーバを含むことができる。クライアントおよびサーバは一般に互いから離れており、一般に通信ネットワークを通じて対話する（例えば、ネットワーク１６５）。クライアントおよびサーバの関係は、当該各コンピュータで実行され互いにクライアントサーバ関係を有するコンピュータプログラムにより生ずる。幾つかの実装では、サーバは、（例えば、データを表示し、ユーザ入力をクライアントデバイスと対話するユーザから受信する目的で）データ（例えば、コンテンツ・アイテムを表すデータパケット）をクライアントデバイスに送信する。クライアントデバイスで生成されたデータ（例えば、ユーザ対話の結果）はクライアントデバイスから当該サーバでから受信されることができる（例えば、コンピューティングデバイス１５０またはコンテンツプロバイダコンピューティングデバイス１５５またはサービスプロバイダコンピューティングデバイス１６０からデータ処理システム１０２により受信される）。 A computing system such as system 100 or system 400 can include clients and servers. Clients and servers are generally separated from each other and generally interact through communication networks (eg, network 165). The client-server relationship arises from a computer program that runs on each computer and has a client-server relationship with each other. In some implementations, the server sends data (eg, a data packet representing a content item) to the client device (eg, for the purpose of displaying data and receiving user input from the user interacting with the client device). .. Data generated on a client device (eg, the result of a user interaction) can be received from the client device on the server (eg, compute device 150 or content provider compute device 155 or service provider compute device 160). (Received by the data processing system 102).
動作を当該図面において特定の順序で説明したが、かかる動作を示した特定の順序でまたは逐次的な順序で実施する必要はなく、全ての図示した動作を実施する必要はない。本明細書で説明した動作を異なる順序で実施することができる。 Although the operations have been described in the drawings in a particular order, it is not necessary to perform such operations in the particular order or sequential order in which they are shown, and not all of the illustrated operations need to be performed. The operations described herein can be performed in different orders.
様々なシステムコンポーネントの分離は全ての実装における分離を要求しないが、当該説明したプログラムコンポーネントを単一のハードウェアまたはソフトウェア製品に含めることができる。例えば、ＮＬＰコンポーネント１１０またはコンテンツセレクタコンポーネント１２５は、単一のコンポーネント、アプリ、またはプログラム、または１つまたは複数の処理回路を有する論理デバイス、またはデータ処理システム１０２の１つまたは複数のサーバの一部であることができる。 Separation of various system components does not require separation in all implementations, but the program components described above can be included in a single hardware or software product. For example, NLP component 110 or content selector component 125 may be a single component, app, or program, or a logical device with one or more processing circuits, or part of one or more servers in the data processing system 102. Can be.
幾つかの例示的な実装を説明したので、以上は、例示的であり限定的ではなく、例として提示されていることは明らかである。特に、本明細書で提示した例の多くは方法の動作またはシステム要素の特定の組合せを含むが、これらの動作およびこれらの要素を他の方法で組み合わせて同一の目的を実現してもよい。１実装と関連して説明した動作、要素および特徴は他の実装または実装における類似の役割から排除されるものではない。 Having described some exemplary implementations, it is clear that the above are exemplary, not limiting, and are presented as examples. In particular, many of the examples presented herein include specific combinations of method behaviors or system elements, but these behaviors and these elements may be combined in other ways to achieve the same purpose. The behaviors, elements and features described in connection with one implementation are not excluded from other implementations or similar roles in the implementation.
本明細書で使用したフレーズおよび用語は説明の目的のためであり限定として解釈されるべきではない。「〜を含む」、「〜を備える」、「〜を有する」、「〜を包含する」、「〜が関与する」、「〜により特徴付けられる」、「〜の点で特徴付けられる」、およびその本明細書における変形の使用、は、その後に列挙された項目、その均等物、および追加の項目、ならびに排他的にその後に列挙された項目からなる代替的な実装を含むことを意味する。１実装では、本明細書で説明するシステムおよび方法は当該説明した要素、動作、またはコンポーネントの１つ、複数の各組合せ、または全てから成る。 The phrases and terms used herein are for explanatory purposes only and should not be construed as limiting. "Contains", "Contains", "Has", "Contains", "Involves", "Characterizes by", "Characters in terms of", And the use of variations thereof herein is meant to include alternative implementations consisting of the items listed thereafter, their equivalents, and additional items, as well as the items listed exclusively thereafter. .. In one implementation, the systems and methods described herein consist of one, multiple combinations, or all of the described elements, behaviors, or components.
本明細書で単一形で参照されるシステムおよび方法の実装または要素または動作に対する任意の言及は複数のこれらの要素を含む実装を含んでもよく、本明細書の任意の実装または要素または動作への複数形の任意の参照は単一の要素のみを含む実装を含んでもよい。単一形または複数形における参照は本明細書で開示したシステムまたは方法、それらのコンポーネント、動作、または要素を単一のまたは複数の構成に限定しようとするものではない。任意の情報、動作または要素に基づく任意の動作または要素への参照は当該動作または要素は任意の情報、動作、または要素に少なくとも部分的に基づく実装を含んでもよい。 Any reference to an implementation or element or behavior of a system and method referred to herein in a single form may include an implementation that includes more than one of these elements, to any implementation or element or behavior herein. Any reference to the plural form of may include an implementation containing only a single element. References in the single or plural form are not intended to limit the systems or methods disclosed herein, their components, behaviors, or elements to a single or multiple configuration. References to any action or element based on any information, action or element may include an implementation in which the action or element is at least partially based on any information, action or element.
本明細書で開示した任意の実装を任意の他の実装または実施形態と組み合わせてもよく「実装」、「幾つかの実装」、「１実装」等への言及は必ずしも相互に排他的ではなく、当該実装と関連して説明した特定の特徴、構造、または特性が少なくとも１つの実装または実施形態に含まれてもよいを示すことを意図している。本明細書で使用した用語は必ずしも全て同一の実装を参照しない。任意の実装を、任意の他の実装と、包含的にまたは排他的に、本明細書で開示した態様および実装と一貫する任意の方式で結合してもよい。 Any implementation disclosed herein may be combined with any other implementation or embodiment. References to "implementation," "some implementations," "one implementation," etc. are not necessarily mutually exclusive. , It is intended to indicate that the particular features, structures, or properties described in connection with such implementation may be included in at least one implementation or embodiment. All terms used herein do not necessarily refer to the same implementation. Any implementation may be combined with any other implementation, inclusively or exclusively, in any manner consistent with the embodiments and implementations disclosed herein.
「または」に対する言及は、「または」を用いて説明された任意の用語が当該説明した用語のうち１つ、複数、および全ての何れかを示しうるように、包含的として解釈してもよい。例えば、「‘Ａ’および‘Ｂ’のうち少なくとも１つ」への言及は‘Ａ’のみ、‘Ｂ’のみ、ならびに‘Ａ’および‘Ｂ’の両方を含むことができる。「〜を備える」または他のオープンな用語と関連して使用されるかかる言及は追加の項目を含むことができる。 References to "or" may be construed as inclusive so that any term described using "or" can indicate one, more, or all of the described terms. .. For example, a reference to "at least one of'A'and'B'" can include only'A', only'B', and both'A'and'B'. Such references used in connection with "with" or other open terms may include additional items.
当該図面、詳細な説明または任意の請求項における技術的特徴に参照記号が続く場合、当該参照記号は当該図面、詳細な説明、および特許請求の範囲の明瞭性を高めるために含まれている。したがって、当該参照記号もそれがないことも任意のクレーム要素の範囲に対する限定効果を有さない。 Where a reference symbol follows the drawing, detailed description or technical feature in any claim, the reference symbol is included to enhance clarity of the drawing, detailed description, and claims. Therefore, neither the reference symbol nor its absence has a limiting effect on the scope of any claim element.
本明細書で説明するシステムおよび方法をその特徴から逸脱せずに他の特定の形態で具体化してもよい。例えば、データ処理システム１０２は、第２のアクション２１０が完了するかまたはまさに始まろうとすることを示す第２のアクション２１０からのデータのような、当該スレッド２００のアクションの当該シーケンスにおける過去のアクションからのデータに少なくとも部分的に基づいて、後続のアクションに対して（例えば、第３のアクション２１５に対して）コンテンツ・アイテムを選択することができる。以上の実装は説明したシステムおよび方法の限定ではなく例示的なものである。本明細書で説明するシステムおよび方法の範囲はしたがって以上の説明ではなく添付の特許請求の範囲により示され、添付の特許請求の範囲の均等物の意味と範囲に入る変更がそこに包含される。 The systems and methods described herein may be embodied in other particular forms without departing from their characteristics. For example, the data processing system 102 may from a past action in the sequence of actions of the thread 200, such as data from a second action 210 indicating that the second action 210 has completed or is about to begin. Content items can be selected for subsequent actions (eg, for a third action 215), at least in part based on the data in. The above implementations are exemplary rather than limited to the systems and methods described. The scope of the systems and methods described herein is therefore indicated by the appended claims rather than by the above description, which includes the meaning and scope of the equivalents of the appended claims. ..
１０２ データ処理システム
１０４ コンピューティングデバイス
１０５ ネットワーク
１０６ コンテンツプロバイダデバイス
１０８ サービス・プロバイダ・デバイス
１１０ インタフェース
１１２ 自然言語プロセッサコンポーネント
１１４ セッション・ハンドラ・コンポーネント
１１６ ダイレクト・アクションＡＰＩ
１１８ コンテンツセレクタコンポーネント
１２０ フィードバック監視コンポーネント
１２２ オーディオ信号生成器コンポーネント
１２４ データリポジトリ
１２６ パラメータ
１２８ ポリシ
１３０ コンテンツ・データ
１３２ テンプレート
１３４ センサ
１３６ トランスデューサ
１３８ オーディオドライバ
１４０ プリプロセッサ
１４２ サービス・プロバイダの自然言語プロセッサコンポーネント
１４４ サービス・プロバイダ・インタフェース
102 Data Processing System 104 Computing Device 105 Network 106 Content Provider Device 108 Service Provider Device 110 Interface 112 Natural Language Processor Component 114 Session Handler Component 116 Direct Action API
118 Content Selector Component 120 Feedback Monitoring Component 122 Audio Signal Generator Component 124 Data Repository 126 Parameters 128 Policy 130 Content Data 132 Template 134 Sensor 136 Transducer 138 Audio Driver 140 Preprocessor 142 Service Provider Natural Language Processor Component 144 Service Provider interface
Claims (20)
クライアントデバイスのセンサにより検出された入力オーディオ信号を含むデータパケットをインタフェースを介して受信し、
前記入力オーディオ信号を解析して、要求および前記要求に対応するトリガキーワードを識別し、
前記入力オーディオ信号に基づいて、通信セッションの特性を測定し、
前記測定された特性に基づいて品質信号を生成し、
前記品質信号に基づいてリアルタイムコンテンツ選択プロセスを調整し、
前記要求およびトリガキーワードに応答して、前記品質信号に基づき調整された前記リアルタイムコンテンツ選択プロセスを介してコンテンツ・アイテムを選択する
ための1つまたは複数のプロセッサを備える、システム。 A system for transmitting data via a computer network
Data packets containing the input audio signal detected by the sensor of the client device are received through the interface and
The input audio signal is analyzed to identify the request and the trigger keyword corresponding to the request.
Based on the input audio signal, to measure the characteristics of the communication session,
Generate a quality signal based on the measured characteristics
Adjust the real-time content selection process based on the quality signal
A system comprising one or more processors for selecting content items through the real-time content selection process tuned based on the quality signal in response to the request and trigger keywords.
前記入力オーディオ信号の欠如に基づいて低いレベルの品質を示す前記品質信号を生成する
ための前記1つまたは複数のプロセッサを備える、請求項1に記載のシステム。 The data packet is analyzed to determine the lack of the input audio signal.
The system of claim 1, comprising the one or more processors for producing the quality signal exhibiting a low level of quality based on the lack of the input audio signal.
前記第1の特性および前記第2の特性の比較に基づいて前記特性を測定する
ための前記1つまたは複数のプロセッサを備える、請求項1に記載のシステム。 The first characteristic of the input audio signal is determined at the first time interval, the second characteristic of the input audio signal is determined at the second time interval following the first time interval.
The system of claim 1, comprising the one or more processors for measuring the characteristics based on a comparison of the first characteristic and the second characteristic.
前記複数の音声ベースのクエリへの応答に基づいて前記特性を測定する
ための前記1つまたは複数のプロセッサを備える、請求項1に記載のシステム。 Send multiple voice-based queries to the client device and
The system of claim 1, comprising the one or more processors for measuring the characteristics based on the response to the plurality of voice-based queries.
1つまたは複数のプロセッサによって、クライアントデバイスのセンサにより検出された入力オーディオ信号を含むデータパケットをインタフェースを介して受信するステップと、
前記1つまたは複数のプロセッサによって、前記入力オーディオ信号を解析して、要求および前記要求に対応するトリガキーワードを識別するステップと、
前記1つまたは複数のプロセッサによって、前記入力オーディオ信号に基づいて、通信セッションの特性を測定するステップと、
前記1つまたは複数のプロセッサによって、前記測定された特性に基づいて品質信号を生成するステップと、
前記1つまたは複数のプロセッサによって、前記品質信号に基づいてリアルタイムコンテンツ選択プロセスを調整するステップと、
前記1つまたは複数のプロセッサによって、前記要求およびトリガキーワードに応答して、前記品質信号に基づき調整された前記リアルタイムコンテンツ選択プロセスを介してコンテンツ・アイテムを選択するステップと
を含む、方法。 A method for transmitting data over a computer network
A step of receiving a data packet through an interface by one or more processors, including an input audio signal detected by a sensor on a client device.
A step of analyzing the input audio signal by the one or more processors to identify the request and the trigger keyword corresponding to the request.
By the one or more processors, based on the input audio signal, and measuring the characteristics of the communication session,
The step of generating a quality signal based on the measured characteristics by the one or more processors.
The step of coordinating the real-time content selection process based on the quality signal by the one or more processors.
A method comprising the step of selecting a content item by the one or more processors in response to the request and trigger keywords through the real-time content selection process tuned based on the quality signal.
前記1つまたは複数のプロセッサによって、前記入力オーディオ信号の欠如に基づいて低いレベルの品質を示す前記品質信号を生成するステップと
を含む、請求項11に記載の方法。 A step of analyzing the data packet by the one or more processors to determine the lack of the input audio signal.
11. The method of claim 11, comprising the step of producing the quality signal by the one or more processors that exhibits a low level of quality based on the lack of the input audio signal.
前記1つまたは複数のプロセッサによって、前記第1の特性および前記第2の特性の比較に基づいて前記特性を測定するステップと
を含む、請求項11に記載の方法。 The one or more processors determine the first characteristic of the input audio signal in the first time interval and the second characteristic of the input audio signal in the second time following the first time interval. Steps to determine by interval and
11. The method of claim 11, comprising measuring the characteristics by the one or more processors based on a comparison of the first characteristic and the second characteristic.
前記1つまたは複数のプロセッサによって、前記複数の音声ベースのクエリへの応答に基づいて前記特性を測定するステップと
を含む、請求項11に記載の方法。 The step of sending multiple voice-based queries to the client device by the one or more processors.
11. The method of claim 11, comprising measuring the characteristics by the one or more processors based on the response to the plurality of voice-based queries.
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US15/395,694 US10431209B2 (en) | 2016-12-30 | 2016-12-30 | Feedback controller for data transmissions |
US15/395,694 | 2016-12-30 |
Related Parent Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2017556911A Division JP6556865B2 (en) | 2016-12-30 | 2017-08-31 | Feedback controller for data transmission |
Related Child Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2021019789A Division JP7044916B2 (en) | 2016-12-30 | 2021-02-10 | Feedback controller for data transmission |
Publications (2)
Publication Number | Publication Date |
---|---|
JP2019174846A JP2019174846A (en) | 2019-10-10 |
JP6839234B2 true JP6839234B2 (en) | 2021-03-03 |
Family
ID=59923556
Family Applications (3)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2017556911A Active JP6556865B2 (en) | 2016-12-30 | 2017-08-31 | Feedback controller for data transmission |
JP2019127639A Active JP6839234B2 (en) | 2016-12-30 | 2019-07-09 | Feedback controller for data transmission |
JP2021019789A Active JP7044916B2 (en) | 2016-12-30 | 2021-02-10 | Feedback controller for data transmission |
Family Applications Before (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2017556911A Active JP6556865B2 (en) | 2016-12-30 | 2017-08-31 | Feedback controller for data transmission |
Family Applications After (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2021019789A Active JP7044916B2 (en) | 2016-12-30 | 2021-02-10 | Feedback controller for data transmission |
Country Status (9)
Country | Link |
---|---|
US (3) | US10431209B2 (en) |
EP (2) | EP4149097A1 (en) |
JP (3) | JP6556865B2 (en) |
KR (3) | KR102208990B1 (en) |
CN (2) | CN112967716A (en) |
AU (2) | AU2017386098B2 (en) |
DE (2) | DE112017000131T5 (en) |
GB (1) | GB2564921B (en) |
WO (1) | WO2018125303A1 (en) |
Families Citing this family (12)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10630751B2 (en) | 2016-12-30 | 2020-04-21 | Google Llc | Sequence dependent data message consolidation in a voice activated computer network environment |
US10956485B2 (en) | 2011-08-31 | 2021-03-23 | Google Llc | Retargeting in a search environment |
US9703757B2 (en) | 2013-09-30 | 2017-07-11 | Google Inc. | Automatically determining a size for a content item for a web page |
US10431209B2 (en) * | 2016-12-30 | 2019-10-01 | Google Llc | Feedback controller for data transmissions |
US10614153B2 (en) * | 2013-09-30 | 2020-04-07 | Google Llc | Resource size-based content item selection |
US10929081B1 (en) * | 2017-06-06 | 2021-02-23 | United Services Automobile Association (Usaa) | Context management for multiple devices |
US11553082B2 (en) * | 2017-12-29 | 2023-01-10 | Trysit Nitidharmatut | Simultaneous voice and data content driven commercial data platform |
US11145300B2 (en) | 2018-05-07 | 2021-10-12 | Google Llc | Activation of remote devices in a networked system |
US11715467B2 (en) * | 2019-04-17 | 2023-08-01 | Tempus Labs, Inc. | Collaborative artificial intelligence method and system |
CN111738007B (en) * | 2020-07-03 | 2021-04-13 | 北京邮电大学 | Chinese named entity identification data enhancement algorithm based on sequence generation countermeasure network |
CN114065976A (en) * | 2020-07-29 | 2022-02-18 | 宝马股份公司 | Vehicle service reservation method and system based on natural language input |
US20220334900A1 (en) * | 2021-04-14 | 2022-10-20 | Nvidia Corporation | Application programming interface to indicate increased resource usage |
Family Cites Families (165)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4603430A (en) | 1984-09-21 | 1986-07-29 | Hughes Aircraft Company | Target discrimination utilizing median filters |
JP3181592B2 (en) | 1992-12-01 | 2001-07-03 | マイクロソフト コーポレイション | Method and system for in-place interaction with embedded objects |
US5812935A (en) * | 1993-04-17 | 1998-09-22 | Hughes Electronics | Cellular system employing base station transmit diversity according to transmission quality level |
US5608727A (en) * | 1995-05-02 | 1997-03-04 | Motorola, Inc. | Method and system for management of frequency spectrum among multiple applications on a shared medium |
US6119101A (en) | 1996-01-17 | 2000-09-12 | Personal Agents, Inc. | Intelligent agents for electronic commerce |
DE19716445A1 (en) | 1997-04-21 | 1998-10-22 | Heidelberger Druckmasch Ag | Character broadening process |
US6529730B1 (en) * | 1998-05-15 | 2003-03-04 | Conexant Systems, Inc | System and method for adaptive multi-rate (AMR) vocoder rate adaption |
US6829646B1 (en) | 1999-10-13 | 2004-12-07 | L. V. Partners, L.P. | Presentation of web page content based upon computer video resolutions |
US20010016034A1 (en) | 1998-12-08 | 2001-08-23 | Sukhinder Singh | Method and apparatus for obtaining and aggregating off-line user data for re-packaging and presentation to users over a data-packet-network |
US7003729B1 (en) | 1999-04-20 | 2006-02-21 | I2 Technologies Us, Inc. | Method and apparatus for supporting multiple alternative graphical user interfaces in computer-moderated electronic commerce |
US6275806B1 (en) | 1999-08-31 | 2001-08-14 | Andersen Consulting, Llp | System method and article of manufacture for detecting emotion in voice signals by utilizing statistics for voice signal parameters |
US6684249B1 (en) | 2000-05-26 | 2004-01-27 | Sonicbox, Inc. | Method and system for adding advertisements over streaming audio based upon a user profile over a world wide area network of computers |
FI20001577A (en) * | 2000-06-30 | 2001-12-31 | Nokia Mobile Phones Ltd | Speech coding |
US6857007B1 (en) | 2000-08-30 | 2005-02-15 | Bloomfield Enterprises, Llc | Personal digital assistant facilitated communication system |
WO2002086864A1 (en) * | 2001-04-18 | 2002-10-31 | Rutgers, The State University Of New Jersey | System and method for adaptive language understanding by computers |
WO2002089105A2 (en) | 2001-05-02 | 2002-11-07 | Bitstream, Inc. | Methods, systems, and programming for producing and displaying subpixel-optimized images and digital content including such images |
US7219309B2 (en) | 2001-05-02 | 2007-05-15 | Bitstream Inc. | Innovations for the display of web pages |
GB0118294D0 (en) | 2001-07-27 | 2001-09-19 | Ibm | Method and system for deadlock detection and avoidance |
GB2392595A (en) | 2002-08-30 | 2004-03-03 | Hewlett Packard Co | Page composition |
US20040056894A1 (en) | 2002-09-19 | 2004-03-25 | Igor Zaika | System and method for describing and instantiating extensible user interfaces |
US7296230B2 (en) | 2002-11-29 | 2007-11-13 | Nippon Telegraph And Telephone Corporation | Linked contents browsing support device, linked contents continuous browsing support device, and method and program therefor, and recording medium therewith |
WO2004068320A2 (en) | 2003-01-27 | 2004-08-12 | Vincent Wen-Jeng Lue | Method and apparatus for adapting web contents to different display area dimensions |
WO2004072867A1 (en) | 2003-02-14 | 2004-08-26 | Access Co., Ltd. | Browser program for performing table-layout |
KR20040076649A (en) | 2003-02-26 | 2004-09-03 | 삼성전자주식회사 | Apparatus and method for displaying browser graphic by aspect ratio |
KR100447526B1 (en) | 2003-03-18 | 2004-09-08 | 엔에이치엔(주) | A method of determining an intention of internet user, and a method of advertising via internet by using the determining method and a system thereof |
GB2418509A (en) | 2003-06-03 | 2006-03-29 | Forbes Holton Norris Iii | Flexible, dynamic menu-based web-page architecture |
JP3920818B2 (en) | 2003-07-22 | 2007-05-30 | 株式会社東芝 | Scheduling method and information processing system |
GB0320278D0 (en) | 2003-08-29 | 2003-10-01 | Hewlett Packard Development Co | Constrained document layout |
US7809843B1 (en) | 2003-09-18 | 2010-10-05 | Intel Corporation | Globally unique identification in communications protocols and databases |
NO20034724D0 (en) | 2003-10-22 | 2003-10-22 | Opera Software Asa | Presentation of HTML content on a display terminal |
US7930206B2 (en) | 2003-11-03 | 2011-04-19 | Google Inc. | System and method for enabling an advertisement to follow the user to additional web pages |
KR100458461B1 (en) | 2004-03-04 | 2004-11-26 | 엔에이치엔(주) | Method and system for advertisement related to information service |
JP2005275601A (en) * | 2004-03-23 | 2005-10-06 | Fujitsu Ltd | Information retrieval system with voice |
US7853255B2 (en) | 2004-04-16 | 2010-12-14 | Broadcom Corporation | Digital personal assistance via a broadband access gateway |
US20060103667A1 (en) | 2004-10-28 | 2006-05-18 | Universal-Ad. Ltd. | Method, system and computer readable code for automatic reize of product oriented advertisements |
US20060111971A1 (en) | 2004-11-24 | 2006-05-25 | Microsoft Corporation | System and method for on-line and off-line advertising in content delivered to a display screen |
EP1861800A1 (en) | 2005-03-09 | 2007-12-05 | Medio Systems, Inc. | Method and system of bidding for advertisement placement on computing devices |
US7730418B2 (en) | 2005-05-04 | 2010-06-01 | Workman Nydegger | Size to content windows for computer graphics |
CN101199002B (en) * | 2005-06-09 | 2011-09-07 | 株式会社A.G.I. | Speech analyzer detecting pitch frequency, speech analyzing method, and speech analyzing program |
JP4665639B2 (en) * | 2005-07-19 | 2011-04-06 | 日本電気株式会社 | Communication quality monitoring system, communication quality monitoring device, communication quality degradation point identifying device, method and program in the device |
JP2007080357A (en) | 2005-09-13 | 2007-03-29 | Toshiba Corp | Information storage medium, information reproducing method, information reproducing apparatus |
US8195133B2 (en) | 2005-09-14 | 2012-06-05 | Jumptap, Inc. | Mobile dynamic advertisement creation and placement |
FI118779B (en) | 2005-10-07 | 2008-03-14 | Riku Rikkola | Cards, receiving device for cards and systems for transmitting electrical energy |
JP2007115293A (en) | 2005-10-17 | 2007-05-10 | Toshiba Corp | Information storage medium, program, information reproducing method, information reproducing apparatus, data transfer method, and data processing method |
US7904505B2 (en) | 2005-11-02 | 2011-03-08 | At&T Intellectual Property I, L.P. | Service to push author-spoken audio content with targeted audio advertising to users |
WO2007091096A1 (en) | 2006-02-10 | 2007-08-16 | Spinvox Limited | A mass-scale, user-independent, device-independent, voice message to text conversion system |
US7606875B2 (en) | 2006-03-28 | 2009-10-20 | Microsoft Corporation | Detecting serving area of a web resource |
CN101055577A (en) | 2006-04-12 | 2007-10-17 | 龙搜（北京）科技有限公司 | Collector capable of extending markup language |
US8582663B2 (en) | 2006-08-08 | 2013-11-12 | Core Wireless Licensing S.A.R.L. | Method, device, and system for multiplexing of video streams |
US9318108B2 (en) | 2010-01-18 | 2016-04-19 | Apple Inc. | Intelligent automated assistant |
KR101029786B1 (en) * | 2006-09-13 | 2011-04-19 | 니뽄 덴신 덴와 가부시키가이샤 | Emotion detecting method, emotion detecting apparatus, emotion detecting program that implements the same method, and storage medium that stores the same program |
CN101529307B (en) | 2006-11-01 | 2012-03-28 | 日本电气株式会社 | Image display device |
US7742922B2 (en) * | 2006-11-09 | 2010-06-22 | Goller Michael D | Speech interface for search engines |
US8031857B2 (en) * | 2006-12-19 | 2011-10-04 | Scenera Technologies, Llc | Methods and systems for changing a communication quality of a communication session based on a meaning of speech data |
US7877696B2 (en) | 2007-01-05 | 2011-01-25 | Eastman Kodak Company | Multi-frame display system with semantic image arrangement |
US8107960B2 (en) | 2007-01-23 | 2012-01-31 | Toshiba America Research, Inc. | Prioritized query |
GB2451415B (en) | 2007-02-13 | 2011-08-17 | Vodafone Plc | Content reproduction in telecommunications systems |
US8413070B1 (en) | 2007-05-07 | 2013-04-02 | Adobe Systems Incorporated | Declarative resizeable list in electronic form |
KR20100017440A (en) | 2007-05-29 | 2010-02-16 | 가부시키가이샤 아쿠세스 | Terminal, history management method, and computer usable recording medium for history management |
US20090085921A1 (en) | 2007-10-01 | 2009-04-02 | Lydia Mai Do | Populate Web-Based Content Based on Space Availability |
US8095865B2 (en) | 2007-11-21 | 2012-01-10 | Microsoft Corporation | Layout manager |
US8555193B2 (en) | 2008-01-17 | 2013-10-08 | Google Inc. | System for intelligent automated layout and management of interactive windows |
WO2009114634A1 (en) | 2008-03-11 | 2009-09-17 | Hongguag Bi | Ad matching system and method thereof |
US8453051B1 (en) | 2008-03-31 | 2013-05-28 | Amazon Technologies, Inc. | Dynamic display dependent markup language interface |
US20090279108A1 (en) | 2008-05-12 | 2009-11-12 | Nagayasu Hoshi | Image Processing Apparatus |
JP4547638B2 (en) | 2008-05-29 | 2010-09-22 | ソニー株式会社 | Web page display device and Web page display method |
CA2633177A1 (en) | 2008-06-03 | 2009-12-03 | Contec Innovations, Inc. | Method and system for producing a presentation message for a mobile device |
US20090300120A1 (en) | 2008-06-03 | 2009-12-03 | Contec Innovations Inc. | Method and system for producing a presentation message for a mobile device |
US9357075B1 (en) * | 2008-06-05 | 2016-05-31 | Avaya Inc. | Conference call quality via a connection-testing phase |
US8527339B2 (en) | 2008-06-26 | 2013-09-03 | Microsoft Corporation | Quality based pricing and ranking for online ads |
US8706547B2 (en) | 2008-08-29 | 2014-04-22 | Google Inc. | Dynamic pricing for content presentations |
US8438310B2 (en) | 2008-10-01 | 2013-05-07 | Adp Dealer Services, Inc. | Systems and methods for configuring a website having a plurality of operational modes |
US8938672B2 (en) | 2008-11-04 | 2015-01-20 | International Business Machines Corporation | Amending the display property of grid elements |
CN101437032B (en) * | 2008-12-19 | 2011-11-16 | 重庆邮电大学 | System for monitoring VOIP voice quality based on SIP protocol and detection method thereof |
US8145561B1 (en) | 2009-01-05 | 2012-03-27 | Sprint Communications Company L.P. | Phone usage pattern as credit card fraud detection trigger |
JP4978629B2 (en) | 2009-01-19 | 2012-07-18 | コニカミノルタビジネステクノロジーズ株式会社 | Item setting device, control method thereof, and control program |
JP5018794B2 (en) | 2009-01-20 | 2012-09-05 | コニカミノルタビジネステクノロジーズ株式会社 | PRINT JOB OUTPUT DEVICE, ITS CONTROL METHOD, AND CONTROL PROGRAM |
JP4760921B2 (en) | 2009-01-28 | 2011-08-31 | コニカミノルタビジネステクノロジーズ株式会社 | Item setting device, control method thereof, and control program |
US20100198694A1 (en) | 2009-01-30 | 2010-08-05 | Google Inc. | Advertisement Slot Configuration |
US8949582B2 (en) | 2009-04-27 | 2015-02-03 | Lsi Corporation | Changing a flow identifier of a packet in a multi-thread, multi-flow network processor |
US8448074B2 (en) | 2009-05-01 | 2013-05-21 | Qualcomm Incorporated | Method and apparatus for providing portioned web pages in a graphical user interface |
US9858925B2 (en) | 2009-06-05 | 2018-01-02 | Apple Inc. | Using context information to facilitate processing of commands in a virtual assistant |
JP5299125B2 (en) | 2009-06-30 | 2013-09-25 | 富士ゼロックス株式会社 | Document processing apparatus and program |
JP5340088B2 (en) | 2009-09-07 | 2013-11-13 | キヤノン株式会社 | Information processing method and apparatus |
JP5032543B2 (en) | 2009-09-16 | 2012-09-26 | 株式会社東芝 | Scheduling apparatus, method and program |
US8402379B2 (en) | 2009-09-30 | 2013-03-19 | SAP Portals Israel Limited | Dynamic content layout for a user interface display |
US9124642B2 (en) * | 2009-10-16 | 2015-09-01 | Qualcomm Incorporated | Adaptively streaming multimedia |
CN102043788A (en) * | 2009-10-21 | 2011-05-04 | 北京金石智博科技发展有限公司 | Video search system based on content comparison |
CN102082879B (en) * | 2009-11-27 | 2014-07-30 | 华为技术有限公司 | Method, device and system for call center speech detection |
JP5186047B2 (en) | 2009-11-30 | 2013-04-17 | 楽天株式会社 | Object display device, object display method, object display control program, and computer-readable recording medium recording the program |
US10276170B2 (en) | 2010-01-18 | 2019-04-30 | Apple Inc. | Intelligent automated assistant |
US8428759B2 (en) * | 2010-03-26 | 2013-04-23 | Google Inc. | Predictive pre-recording of audio for voice input |
US8793598B2 (en) | 2010-04-14 | 2014-07-29 | Microsoft Corporation | Cross-browser web dialog platform |
US10467655B1 (en) | 2010-04-15 | 2019-11-05 | Quantcast Corporation | Protected audience selection |
US20110271194A1 (en) | 2010-04-29 | 2011-11-03 | Google Inc. | Voice ad interactions as ad conversions |
US9560206B2 (en) * | 2010-04-30 | 2017-01-31 | American Teleconferencing Services, Ltd. | Real-time speech-to-text conversion in an audio conference session |
BR112012033098A2 (en) | 2010-06-29 | 2016-11-22 | Rakuten Inc | information processing device, method and program, and recording media |
KR101731843B1 (en) | 2010-09-02 | 2017-05-02 | 삼성전자 주식회사 | Method and Apparatus for displaying items |
KR101045589B1 (en) | 2010-09-15 | 2011-07-01 | 주식회사 유비온 | Playback equipment for contents received over network and method thereof |
JP2012073863A (en) | 2010-09-29 | 2012-04-12 | Rakuten Inc | Advertisement display program, advertisement display device, advertisement display method, recording medium, and advertisement display system |
CA2821970A1 (en) | 2010-12-14 | 2012-06-21 | Soorena Salari | Apparatus, system, and method for a micro commerce ad |
US20120159314A1 (en) | 2010-12-16 | 2012-06-21 | Microsoft Corporation | Adaptive content layout |
US20120158490A1 (en) | 2010-12-16 | 2012-06-21 | Yahoo! Inc. | Sponsored search auction mechanism for rich media advertising |
US8510237B2 (en) | 2011-03-15 | 2013-08-13 | Qualcomm Incorporated | Machine learning method to identify independent tasks for parallel layout in web browsers |
US20130007602A1 (en) | 2011-06-29 | 2013-01-03 | Apple Inc. | Fixed layout electronic publications |
US8872855B2 (en) | 2011-07-21 | 2014-10-28 | Flipboard, Inc. | Adjusting orientation of content regions in a page layout |
US9396167B2 (en) | 2011-07-21 | 2016-07-19 | Flipboard, Inc. | Template-based page layout for hosted social magazines |
US10630751B2 (en) | 2016-12-30 | 2020-04-21 | Google Llc | Sequence dependent data message consolidation in a voice activated computer network environment |
US9020981B2 (en) | 2011-09-30 | 2015-04-28 | Comprehend Systems, Inc. | Systems and methods for generating schemas that represent multiple data sources |
US9760236B2 (en) | 2011-10-14 | 2017-09-12 | Georgia Tech Research Corporation | View virtualization and transformations for mobile applications |
US9542956B1 (en) | 2012-01-09 | 2017-01-10 | Interactive Voice, Inc. | Systems and methods for responding to human spoken audio |
WO2013155619A1 (en) | 2012-04-20 | 2013-10-24 | Sam Pasupalak | Conversational agent |
WO2013162582A1 (en) * | 2012-04-26 | 2013-10-31 | Empire Technology Development Llc | Multimedia application rental and billing |
US9323443B2 (en) | 2012-05-02 | 2016-04-26 | International Business Machines Corporation | Drilling of displayed content in a touch screen device |
US20130305144A1 (en) | 2012-05-09 | 2013-11-14 | Ni Group Limited | Method of Publishing Digital Content |
US20130305145A1 (en) | 2012-05-09 | 2013-11-14 | Ni Group Limited | A Method of Publishing Digital Content |
US9280610B2 (en) | 2012-05-14 | 2016-03-08 | Apple Inc. | Crowd sourcing information to fulfill user requests |
US10607250B2 (en) | 2012-06-04 | 2020-03-31 | Facebook, Inc. | Advertisement selection and pricing using discounts based on placement |
US20140019462A1 (en) | 2012-07-15 | 2014-01-16 | Microsoft Corporation | Contextual query adjustments using natural action input |
US20140033228A1 (en) | 2012-07-25 | 2014-01-30 | Google Inc. | Configuring content display dimensions |
EP2898460A1 (en) | 2012-09-20 | 2015-07-29 | Google, Inc. | Determining a configuration of a content item display environment |
US20140108941A1 (en) | 2012-10-17 | 2014-04-17 | Christopher Stephen Joel | Method and Apparatus for Automatically Optimizing the Loading of Images in a Cloud-Based Proxy Service |
US9164966B1 (en) | 2012-10-24 | 2015-10-20 | Google Inc. | Determining sizes of content items |
CN103873706B (en) * | 2012-12-18 | 2016-12-28 | 北京裕丰大通科技有限公司 | Dynamic and intelligent speech recognition IVR service system |
JP6028556B2 (en) * | 2012-12-19 | 2016-11-16 | 富士通株式会社 | Dialog control method and computer program for dialog control |
US20140180796A1 (en) | 2012-12-21 | 2014-06-26 | Sándor Sás | Selecting and serving content items of different content item types for a content item slot |
KR20140089876A (en) * | 2013-01-07 | 2014-07-16 | 삼성전자주식회사 | interactive interface apparatus and method for comtrolling the server |
CN103093752A (en) * | 2013-01-16 | 2013-05-08 | 华南理工大学 | Sentiment analytical method based on mobile phone voices and sentiment analytical system based on mobile phone voices |
KR20140094336A (en) * | 2013-01-22 | 2014-07-30 | 삼성전자주식회사 | A electronic device for extracting a emotion of user and method for extracting a emotion of user in the electronic device |
CN104969289B (en) | 2013-02-07 | 2021-05-28 | 苹果公司 | Voice trigger of digital assistant |
KR102050897B1 (en) * | 2013-02-07 | 2019-12-02 | 삼성전자주식회사 | Mobile terminal comprising voice communication function and voice communication method thereof |
US20140258849A1 (en) | 2013-03-06 | 2014-09-11 | Google Inc. | Automatic Alignment of a Multi-Dimensional Layout |
US11233841B2 (en) | 2013-03-15 | 2022-01-25 | Yottaa, Inc. | Systems and methods for configuration-based optimization by an intermediary |
US20140337127A1 (en) | 2013-04-23 | 2014-11-13 | Brightcove, Inc. | Client bridge |
US20140324582A1 (en) * | 2013-04-30 | 2014-10-30 | Google Inc. | Social network enhanced content items responsive to search queries |
EP2814244A1 (en) * | 2013-06-11 | 2014-12-17 | Alcatel Lucent | A method and a system for improving communication quality of a video conference |
US9483444B2 (en) | 2013-07-09 | 2016-11-01 | Flipboard, Inc. | Dynamic layout engine for a digital magazine |
US20150088970A1 (en) | 2013-09-20 | 2015-03-26 | Yottaa Inc. | Systems and methods for managing loading priority or sequencing of fragments of a web object |
US10431209B2 (en) * | 2016-12-30 | 2019-10-01 | Google Llc | Feedback controller for data transmissions |
US10614153B2 (en) | 2013-09-30 | 2020-04-07 | Google Llc | Resource size-based content item selection |
US9703757B2 (en) | 2013-09-30 | 2017-07-11 | Google Inc. | Automatically determining a size for a content item for a web page |
WO2015062627A1 (en) | 2013-10-29 | 2015-05-07 | Telefonaktiebolaget L M Ericsson (Publ) | Control of a chain of services |
US20150278370A1 (en) * | 2014-04-01 | 2015-10-01 | Microsoft Corporation | Task completion for natural language input |
US10726831B2 (en) | 2014-05-20 | 2020-07-28 | Amazon Technologies, Inc. | Context interpretation in natural language processing using previous dialog acts |
US9350770B2 (en) * | 2014-05-30 | 2016-05-24 | Apple Inc. | Redundant transmission channels for real-time applications on mobile devices |
US9330433B2 (en) | 2014-06-30 | 2016-05-03 | Intel Corporation | Data distribution fabric in scalable GPUs |
US10108817B2 (en) | 2014-09-26 | 2018-10-23 | Microsoft Technology Licensing, Llc | Privacy-preserving cookies for personalization without user tracking |
US10235996B2 (en) | 2014-10-01 | 2019-03-19 | XBrain, Inc. | Voice and connection platform |
US9959129B2 (en) | 2015-01-09 | 2018-05-01 | Microsoft Technology Licensing, Llc | Headless task completion within digital personal assistants |
US20160274864A1 (en) | 2015-03-20 | 2016-09-22 | Google Inc. | Systems and methods for enabling user voice interaction with a host computing device |
US20160358367A1 (en) | 2015-06-07 | 2016-12-08 | Apple Inc. | Animation based on Content Presentation Structures |
US10331312B2 (en) | 2015-09-08 | 2019-06-25 | Apple Inc. | Intelligent automated assistant in a media environment |
US20170092278A1 (en) | 2015-09-30 | 2017-03-30 | Apple Inc. | Speaker recognition |
US9747926B2 (en) | 2015-10-16 | 2017-08-29 | Google Inc. | Hotword recognition |
US9928840B2 (en) | 2015-10-16 | 2018-03-27 | Google Llc | Hotword recognition |
US10691473B2 (en) | 2015-11-06 | 2020-06-23 | Apple Inc. | Intelligent automated assistant in a messaging environment |
US9940929B2 (en) | 2015-12-09 | 2018-04-10 | Lenovo (Singapore) Pte. Ltd. | Extending the period of voice recognition |
CN105654950B (en) * | 2016-01-28 | 2019-07-16 | 百度在线网络技术（北京）有限公司 | Adaptive voice feedback method and device |
US11477139B2 (en) | 2016-02-25 | 2022-10-18 | Meta Platforms, Inc. | Techniques for messaging bot rich communication |
US9864732B2 (en) | 2016-05-02 | 2018-01-09 | Google Inc. | User interfaces that facilitate management of formatting of digital content |
CN106033476B (en) | 2016-05-19 | 2019-07-23 | 西安交通大学 | A kind of increment type figure calculation method under distributed computation mode in cloud computing environment |
CN106055662A (en) * | 2016-06-02 | 2016-10-26 | 竹间智能科技（上海）有限公司 | Emotion-based intelligent conversation method and system |
US10192552B2 (en) | 2016-06-10 | 2019-01-29 | Apple Inc. | Digital assistant providing whispered speech |
US20180012595A1 (en) | 2016-07-07 | 2018-01-11 | Intelligently Interactive, Inc. | Simple affirmative response operating system |
US20180191798A1 (en) | 2016-12-30 | 2018-07-05 | Google Inc. | Methods and systems for server-side rendering of native content for presentation |
-
2016
- 2016-12-30 US US15/395,694 patent/US10431209B2/en active Active
-
2017
- 2017-08-31 EP EP22187299.7A patent/EP4149097A1/en active Pending
- 2017-08-31 CN CN202110129598.4A patent/CN112967716A/en active Pending
- 2017-08-31 GB GB1802156.8A patent/GB2564921B/en active Active
- 2017-08-31 JP JP2017556911A patent/JP6556865B2/en active Active
- 2017-08-31 WO PCT/US2017/049766 patent/WO2018125303A1/en active Application Filing
- 2017-08-31 EP EP17771624.8A patent/EP3360313B1/en active Active
- 2017-08-31 KR KR1020197032040A patent/KR102208990B1/en active IP Right Grant
- 2017-08-31 KR KR1020217002298A patent/KR102415921B1/en active IP Right Grant
- 2017-08-31 DE DE112017000131.5T patent/DE112017000131T5/en active Pending
- 2017-08-31 DE DE212017000030.9U patent/DE212017000030U1/en active Active
- 2017-08-31 AU AU2017386098A patent/AU2017386098B2/en active Active
- 2017-08-31 CN CN201780001629.XA patent/CN108605076B/en active Active
- 2017-08-31 KR KR1020177031379A patent/KR102040783B1/en active IP Right Grant
-
2019
- 2019-07-09 JP JP2019127639A patent/JP6839234B2/en active Active
- 2019-08-19 US US16/544,367 patent/US10643608B2/en active Active
-
2020
- 2020-04-20 US US16/853,251 patent/US11475886B2/en active Active
- 2020-10-12 AU AU2020256315A patent/AU2020256315B2/en active Active
-
2021
- 2021-02-10 JP JP2021019789A patent/JP7044916B2/en active Active
Also Published As
Similar Documents
Publication | Publication Date | Title |
---|---|---|
JP6839234B2 (en) | Feedback controller for data transmission | |
US11627065B2 (en) | Selective sensor polling | |
JP7163253B2 (en) | Audio-based data structure generation |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A621 | Written request for application examination |
Free format text: JAPANESE INTERMEDIATE CODE: A621Effective date: 20190712 |
|
A131 | Notification of reasons for refusal |
Free format text: JAPANESE INTERMEDIATE CODE: A131Effective date: 20200907 |
|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20201125 |
|
TRDD | Decision of grant or rejection written | ||
A01 | Written decision to grant a patent or to grant a registration (utility model) |
Free format text: JAPANESE INTERMEDIATE CODE: A01Effective date: 20210112 |
|
A61 | First payment of annual fees (during grant procedure) |
Free format text: JAPANESE INTERMEDIATE CODE: A61Effective date: 20210212 |
|
R150 | Certificate of patent or registration of utility model |
Ref document number: 6839234Country of ref document: JPFree format text: JAPANESE INTERMEDIATE CODE: R150 |
|
R250 | Receipt of annual fees |
Free format text: JAPANESE INTERMEDIATE CODE: R250 |