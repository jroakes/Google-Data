US9069776B1 - Serving encrypted and plain data from a low latency non-volatile memory - Google Patents
Serving encrypted and plain data from a low latency non-volatile memory Download PDFInfo
- Publication number
- US9069776B1 US9069776B1 US13/843,871 US201313843871A US9069776B1 US 9069776 B1 US9069776 B1 US 9069776B1 US 201313843871 A US201313843871 A US 201313843871A US 9069776 B1 US9069776 B1 US 9069776B1
- Authority
- US
- United States
- Prior art keywords
- low latency
- files
- data
- index
- random access
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active, expires
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/10—File systems; File servers
- G06F16/11—File system administration, e.g. details of archiving or snapshots
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/31—Indexing; Data structures therefor; Storage structures
- G06F16/316—Indexing structures
- G06F16/319—Inverted lists
-
- G06F17/3007—
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/951—Indexing; Web crawling techniques
Definitions
- This specification relates to storing data on a server for use in response to a query.
- Information retrieval systems match queries against an index of documents generated from a document corpus (e.g., the World Wide Web).
- a document corpus e.g., the World Wide Web.
- a typical inverted index maps the words in the documents to locations of the words within the documents.
- a document processing system e.g., a web crawler and indexer, prepares the inverted index by processing the contents of the documents, pages, files, or sites retrieved from the document corpus using an automated process.
- the document processing system may also store the contents of the documents, or portions of the content, in a repository for use by a query processor when responding to a query.
- a process executes on a server having a low latency volatile random access memory and a low latency non-volatile memory.
- the process is associated with an index file stored in the low latency volatile random access memory and encrypted and non-encrypted data stored in the low latency non-volatile memory.
- the non-encrypted data will also be referred to as “plain” data.
- Data that results from a decryption of encrypted data will be referred to only as “decrypted” data and never as plain data.
- the process receives a query, finds data necessary to generate a response to the query using the index file, and retrieves the data from the low latency non-volatile memory whether the data is in an encrypted or a plain format.
- the process provides responses to queries where the responses are generated from a portion of either the encrypted data or the plain data stored in the low latency non-volatile memory.
- the low latency non-volatile memory includes one or more flash memory devices. In certain implementations, the low latency volatile random access memory includes one or more dynamic random access memory devices. In some implementations, the data stored in the low latency volatile random access memory is used for temporary computations.
- implementations include corresponding computer systems, methods, and computer programs recorded on one or more computer storage devices, each configured to perform the actions of the methods.
- a system of one or more computers to be configured to perform particular operations or actions means that the system has installed on it software, firmware, hardware, or a combination of them that in operation cause the system to perform the operations or actions.
- one or more computer programs to be configured to perform particular operations or actions means that the one or more programs include instructions that, when executed by data processing apparatus, cause the apparatus to perform the actions.
- the subject matter described in this specification can be implemented in particular embodiments so as to realize one or more of the following advantages.
- the techniques described in this specification can allow a process to use larger index files that are associated with encrypted data because the encrypted data can be stored on larger low latency non-volatile memory.
- the system can control access to the encrypted data instead of only storing unencrypted copies of the encrypted data in a volatile random access memory, preventing unauthorized access to the encrypted data.
- the use of low latency volatile random access memory and low latency non-volatile memory can increase the performance of the system by allowing the system to respond to queries for data more quickly.
- the data stored in the low latency volatile random access memory may become inaccessible to prevent access to decrypted data stored in the low latency volatile random access memory while the encrypted data stored on the low latency non-volatile memory remains encrypted.
- FIG. 1 is a block diagram of an environment for storing data in and serving data from a low latency non-volatile memory.
- FIG. 2 is a flowchart of an example method to provide a first response to a first query.
- FIG. 3 is a flowchart of an example method to provide a second response to a second query.
- FIG. 1 is a block diagram of an environment 100 for storing data in and serving data from a low latency non-volatile memory.
- the low latency non-volatile memory stores both encrypted and unencrypted data while the environment 100 prevents unauthorized access to the encrypted data.
- the environment 100 includes a librarian 102 which receives data, e.g., one or more files, creates an index file corresponding to the data, and provides the data to a repository manager 104 .
- the repository manager 104 stores the data in a data repository 106 and tracks where the data is stored.
- the data repository 106 includes one or more memory devices for storing data.
- the memory devices may include one or more hard disk drives and/or one or more flash drives, to name a few examples.
- the data repository 106 stores both encrypted and plain data.
- the repository manager 104 accesses the encrypted data stored in the data repository 106 , the encrypted data is not decrypted. This may reduce overhead, by eliminating unnecessary decryption of data, and may increase the security of the data, by not decrypting the encrypted data until the encrypted data is needed.
- the repository manager 104 and the data repository 106 are implemented on the same system of one or more computers.
- the computers are configured with and execute instructions to transfer the data between the repository manager 104 and the data repository 106 , in addition to other actions performed by the repository manager 104 and the data repository 106 .
- the repository manager 104 and the data repository 106 are included in separate systems, where each system includes one or more computers.
- the index file created by the librarian 102 stores a mapping between information that may be responsive to a query and where the information is located in the data.
- the index file can represent a table with one column of the table indicating types of information that can be responsive to a query where the different types of information can be indices or tokens in the index file.
- a second column in the table includes the locations where the information (e.g., the tokens) can be found, such as the addresses of one or more files that include the tokens.
- Some examples types of index files can include tries, inverted indexes, citation indexes, n-gram indexes, and document-term matrices.
- each of the indices is associated with a posting list.
- a posting list indicates for each of a number of tokens the specific location of the token in the files associated with the specific index.
- the posting list can identify specific index records included in a file that contain the token.
- the librarian 102 stores the index file in a memory associated with the librarian 102 .
- a system that includes one or more computers executes the librarian 102 process on one or more processors and includes one or more memories used to store a plurality of index files.
- the one or more memories can include a plurality of hard disk drives, a plurality of flash drives, and/or multiple random access memories, among other types of memories.
- the librarian 102 When the librarian 102 receives an indication that data stored in the data repository 106 has been requested, the librarian 102 sends a notification to the repository manager 104 specifying one or more files that the repository manager 104 should retrieve from the data repository 106 and provide to a server 108 . The librarian 102 also identifies the index file associated with the one or more files and provides the index file to the server 108 .
- the server 108 stores the one or more files on a low latency non-volatile memory 110 and the index file on a low latency volatile random access memory 112 .
- the low latency non-volatile memory 110 can include flash memory, ferroelectric random access memory, or both kinds of devices, among other examples.
- the low latency volatile random access memory 112 can include one or more low latency dynamic random access memory devices, one or more low latency static random access memory devices, or both, among other examples.
- the server 108 executes one or more software modules that process the data and/or the index file.
- a file loader 114 receives the data from the repository manager 104 and the index file from the librarian 102 and stores the plain data and the index file in either the low latency non-volatile memory 110 or the low latency volatile random access memory 112 , and the encrypted data in the low latency non-volatile memory 110 .
- a data decrypter 116 decrypts encrypted data to allow a process 118 , executing on the server 108 , to access the decrypted data and generate responses from the decrypted data.
- the decrypted data is stored first on the low latency volatile random access memory 112 .
- Decrypted data is not stored on the low latency non-volatile memory 110 .
- the process 118 , the data decrypter 116 , and the data loaded by the file loader 114 into the low latency non-volatile memory 110 and into the low latency volatile random access memory 112 remain in place for an extended period of time, (e.g., minutes, hours, days, weeks, etc.) to provide query response services to other servers in the environment.
- an extended period of time e.g., minutes, hours, days, weeks, etc.
- the data decrypter 116 is a software module included in the process 118 . In other implementations, the decrypter 116 is instantiated as a separate process, as illustrated in FIG. 1 .
- a random document key is generated for use during decryption of the new file and stored in encrypted form in the file header of the new file.
- the data decrypter 116 retrieves the random document key and provides the random document key to a key store.
- the key store verifies that a client that sent the query associated with the new file has access to the new file and provides the data decrypter 116 with a decrypted key, generated from the random document key, so that the data decrypter 116 can use the decrypted key during decryption of all or a portion of the new file.
- a different computer or system from the server 108 includes the file loader 114 .
- a computer in communication with the server 108 can execute the instructions for the file loader 114 and store data from the repository manager 104 on the low latency non-volatile memory 110 .
- a computer network e.g., a local area network (LAN), wide area network (WAN), the Internet, or a combination of them, provides data communication between the devices and systems in the environment 100 .
- the server 108 can communicate across the network with the computers that host the librarian 102 , and/or the computers that host the repository manager 104 .
- FIG. 2 is a flowchart of an example method 200 to provide a first response to a first query.
- the method 200 will be described as being performed by a system made up of one or more appropriately programmed computers operating in one or more locations.
- the system can include at least one of the computers from the environment 100 .
- the system executes ( 202 ) a process on a server.
- the server is a computer that includes a low latency non-volatile memory and a low latency volatile random access memory.
- the server receives ( 204 ) plain data.
- the plain data includes at least one plain file and comprises public information that does not need to be encrypted.
- the plain data may include one or more web pages, one or more public news articles, and/or one or more public advertisements, among other types of public information or public documents.
- the plain data is associated with the process.
- a file loader receives the plain data from a repository manager.
- the server executes the file loader and the file loader manages the receipt and storage of files received by the computer according to whether the files are encrypted or plain.
- each plain file includes one or more plain index records.
- each of the plain index records is a portion of the plain file that may be accessed by the server.
- the server stores ( 206 ) the plain data in one of the low latency memories of the server.
- the plain data can be stored in the low latency non-volatile memory or in the low latency volatile random access memory.
- the server receives ( 208 ) encrypted data in the form of one or more encrypted files.
- the encrypted data may include personal calendar appointments, contact information, one or more personal files, and/or one or more electronic mail messages, among other types of private information that is encrypted to prevent unauthorized access to the information.
- each encrypted file includes one or more encrypted index records.
- Each of the encrypted index records is a portion of the encrypted file that may be accessed by the server and provided by the server in response to a query.
- the server stores ( 210 ) the encrypted data in the low latency non-volatile memory without decryption of the encrypted data.
- the encrypted data is copied byte for byte from the repository manager to the flash memory.
- the server receives ( 212 ) an index file.
- the index file includes indices that each include an address of a file associated with the index and stored in the low latency non-volatile memory and a flag indicating whether the file associated with the index is encrypted.
- the index file includes one or more indices for both the plain files and the encrypted files. All of the files stored in the low latency non-volatile memory and associated with the process are associated with at least one index in the index file.
- each of the indices is associated with an index record, where the index records are included in either the plain files or the encrypted files.
- the server stores ( 214 ) the index file in a low latency volatile random access memory.
- a file loader stores the index file in the low latency volatile random access memory of the server.
- the index file is in plain format and accessible to the process.
- the server receives ( 216 ) a query.
- the server may receive the query from a higher level server.
- the server identifies ( 218 ) one or more files that need to be processed to generate a response to the query. For example, the process uses the index file to find one or more indices associated with data necessary to generate the response to the first query. Using the indices, the process identifies one or more files that contain data for the process to use when generating the response.
- the server determines ( 220 ) that at least one of the files is stored in the low latency non-volatile memory in an encrypted format. For example, based on one of the indices identified by the process, the process identifies the flag associated with one of the indices and determines, based on the flag, that the corresponding file is encrypted.
- the server retrieves ( 222 ) a portion of one of the files stored in an encrypted format from the low latency non-volatile memory.
- a data decrypter uses the index to determine the address of the portion of the one of the files, or the index record, that will be used to generate a response to the query.
- the process retrieves the portion of the one of the files and provides the portion of the one of the files to the data decrypter.
- the server decrypts ( 224 ) the portion of the one of the files.
- the data decrypter decrypts the portion of the one of the files, or the index record, that is stored in an encrypted format.
- the server stores ( 226 ) the decrypted portion of the one of the files in the low latency volatile random access memory.
- encrypted data exists in plain format only in the low latency volatile random access memory to reduce the possibility of unauthorized access to the encrypted or private data when the data is in a non-encrypted form, ensuring that only the process, executing on the server, has access to the decrypted data based on access control permissions associated with the low latency volatile random access memory.
- the low latency volatile random access memory functions as a cache, where the data (i.e., the plain or decrypted data) associated with the process and in the low latency volatile random access memory is only accessible to the process on the server.
- the data i.e., the plain or decrypted data
- the buffer in the low latency volatile random access memory used to store the decrypted data may be overwritten with different data, either decrypted or plain data, that is associated with the process.
- the server provides ( 228 ) a response to the query.
- the server generates the response from the decrypted portion of the one of the files that is stored in the low latency volatile random access memory.
- the server may also use data from one or more additional files, either encrypted files or plain files, while generating the response.
- the server may provide the response to the computer that submitted the query.
- the server will use the same universe of data to generate responses to many queries, sometimes using the same subsets and sometimes using different subsets of data (i.e., decrypted and/or plain data) for temporary computations when generating different responses. For this reason, the server may keep different subsets of data in the low latency volatile random access memory for different periods of time.
- FIG. 3 is a flowchart of an example method 300 to provide a second response to a second query.
- the method 300 will be described as being performed by a system made up of one or more appropriately programmed computers operating in one or more locations.
- the system can include at least one of the computers from the environment 100 .
- the method 300 can be performed after or in conjunction with the method 200 .
- a server receives ( 302 ) a second query.
- the server executes a process that receives the second query and includes a low latency non-volatile memory and a low latency volatile random access memory.
- the server identifies ( 304 ) one or more second files that need to be processed to generate a response to the second query. For example, the process identifies the one or more second files based on indices included in an index file stored in the low latency volatile random access memory, where the indices include the addresses of the second files in the low latency non-volatile memory.
- the server determines ( 306 ) that at least one of the second files is stored in the low latency non-volatile memory in a plain format. For example, the process determines that a flag included in one of the indices associated with one of the second files indicates that the one of the second files is stored in a plain format on the low latency non-volatile memory.
- the server retrieves ( 308 ) a portion of one of the second files stored in a plain format from the low latency non-volatile memory.
- the index identifying the one of the second files is associated with an index record included in the one of the second files.
- the portion of the one of the second files that the server retrieves from the low latency non-volatile memory is the index record.
- the server stores ( 310 ) the portion of the one of the second files in the low latency volatile random access memory.
- the server provides ( 312 ) a second response to the second query, where the second response is generated from the portion of the one of the second files stored in the low latency volatile random access memory.
- the process generates the second response from the portion of the one of the second files, and provides the second response to the computer that submitted the second query or a computer specified in the second query as the destination for the response.
- the process generates the second response from one or more portions where each of the portions is associated with one of the second files.
- the server causes ( 314 ) the data in the low latency volatile random access memory to become lost upon termination of the process. For example, the contents of the low latency volatile random access memory will be lost after the process exits, guaranteeing that no access to plain data can be made by an external, unauthorized process.
- the data in the low latency volatile random access memory becomes lost when the server resets the address space of the process. In certain implementations, the data in the low latency volatile random access memory becomes lost when the server erases the low latency volatile random access memory.
- the method 300 can perform the steps associated with providing the second response without causing the data in the low latency volatile random access memory becomes lost.
- the server when the method 300 is performed in conjunction with the method 200 , the server provides the second response without providing the first response.
- the server when the method 300 is performed in conjunction with the method 200 , the server provides the second response to the second query before providing the first response to the first query.
- the librarian when a librarian determines that data provided to the system has been updated, the librarian provides the updated data and an updated index file associated with the updated data to the system.
- the server receives encrypted and plain data from a repository manager and an index file, associated with the data, from a librarian.
- the server provides one or more responses to queries, where the responses are generated from the encrypted data and/or the plain data.
- the librarian when the librarian determines that some of the data provided to the system has been updated, the librarian provides the repository manager with instructions to send the all of the data, including the updated data, to the system.
- the file loader in the system receives the data, including the updated data, from the repository manager, and receives an updated index file from the librarian.
- the system ends the process that was associated with the non-updated data and executes a new process, where the new process is associated with the data most recently received from the repository manager and the librarian, including the updated data.
- the new process provides responses to additional queries, where the responses are generated from the data, potentially including the updated data.
- a system when a system includes a larger dataset, multiple processes can be executed on separate servers and associated with different portions of the data.
- the system can provide queries to the respective servers where the queries that are provided to a specific server are determined based on the data stored in the specific server.
- the computer that submitted the query to the system may receive responses from each of the multiple servers that received the query.
- Embodiments of the subject matter and the functional operations described in this specification can be implemented in digital electronic circuitry, in tangibly-embodied computer software or firmware, in computer hardware, including the structures disclosed in this specification and their structural equivalents, or in combinations of one or more of them.
- Embodiments of the subject matter described in this specification can be implemented as one or more computer programs, i.e., one or more modules of computer program instructions encoded on a tangible non-transitory program carrier for execution by, or to control the operation of, data processing apparatus.
- the program instructions can be encoded on an artificially-generated propagated signal, e.g., a machine-generated electrical, optical, or electromagnetic signal, that is generated to encode information for transmission to suitable receiver apparatus for execution by a data processing apparatus.
- the computer storage medium can be a machine-readable storage device, a machine-readable storage substrate, a random or serial access memory device, or a combination of one or more of them.
- data processing apparatus refers to data processing hardware and encompasses all kinds of apparatus, devices, and machines for processing data, including by way of example a programmable processor, a computer, or multiple processors or computers.
- the apparatus can also be or further include special purpose logic circuitry, e.g., an FPGA (field programmable gate array) or an ASIC (application-specific integrated circuit).
- the apparatus can optionally include, in addition to hardware, code that creates an execution environment for computer programs, e.g., code that constitutes processor firmware, a protocol stack, a database management system, an operating system, or a combination of one or more of them.
- a computer program which may also be referred to or described as a program, software, a software application, a module, a software module, a script, or code, can be written in any form of programming language, including compiled or interpreted languages, or declarative or procedural languages, and it can be deployed in any form, including as a stand-alone program or as a module, component, subroutine, or other unit suitable for use in a computing environment.
- a computer program may, but need not, correspond to a file in a file system.
- a program can be stored in a portion of a file that holds other programs or data, e.g., one or more scripts stored in a markup language document, in a single file dedicated to the program in question, or in multiple coordinated files, e.g., files that store one or more modules, sub-programs, or portions of code.
- Computers suitable for the execution of a computer program include, by way of example, general or special purpose microprocessors or both, or any other kind of central processing unit.
- a central processing unit will receive instructions and data from a read-only memory or a random access memory or both.
- the essential elements of a computer are a central processing unit for performing or executing instructions and one or more memory devices for storing instructions and data.
- a computer will also include, or be operatively coupled to receive data from or transfer data to, or both, one or more mass storage devices for storing data, e.g., magnetic, magneto-optical disks, or optical disks.
- Computer-readable media suitable for storing computer program instructions and data include all forms of non-volatile memory, media and memory devices, including by way of example semiconductor memory devices, e.g., EPROM, EEPROM, and flash memory devices; magnetic disks, e.g., internal hard disks or removable disks; magneto-optical disks; and CD-ROM and DVD-ROM disks.
- semiconductor memory devices e.g., EPROM, EEPROM, and flash memory devices
- magnetic disks e.g., internal hard disks or removable disks
- magneto-optical disks e.g., CD-ROM and DVD-ROM disks.
- the processor and the memory can be supplemented by, or incorporated in, special purpose logic circuitry.
- Embodiments of the subject matter described in this specification can be implemented in a computing system that includes a back-end component, e.g., as a data server, or that includes a middleware component, e.g., an application server.
- the components of the system can be interconnected by any form or medium of digital data communication, e.g., a communication network. Examples of communication networks include a local area network (LAN) and a wide area network (WAN), e.g., the Internet.
- LAN local area network
- WAN wide area network
- the computing system can include clients and servers.
- a client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other.
- a server transmits data, e.g., an HTML page, to a user device, e.g., for purposes of displaying data to and receiving user input from a user interacting with the user device, which acts as a client.
- Data generated at the user device e.g., a result of the user interaction, can be received from the user device at the server.
Abstract
Description
Claims (24)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US13/843,871 US9069776B1 (en) | 2013-03-15 | 2013-03-15 | Serving encrypted and plain data from a low latency non-volatile memory |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US13/843,871 US9069776B1 (en) | 2013-03-15 | 2013-03-15 | Serving encrypted and plain data from a low latency non-volatile memory |
Publications (1)
Publication Number | Publication Date |
---|---|
US9069776B1 true US9069776B1 (en) | 2015-06-30 |
Family
ID=53441767
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US13/843,871 Active 2034-01-02 US9069776B1 (en) | 2013-03-15 | 2013-03-15 | Serving encrypted and plain data from a low latency non-volatile memory |
Country Status (1)
Country | Link |
---|---|
US (1) | US9069776B1 (en) |
Cited By (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN110174997A (en) * | 2019-04-17 | 2019-08-27 | 贵州力创科技发展有限公司 | A kind of date storage method and block chain server based on persistent layer |
CN113467841A (en) * | 2021-05-17 | 2021-10-01 | 翱捷智能科技(上海)有限公司 | Dual-operating-system equipment and quick sleeping and awakening method thereof |
US11423158B2 (en) * | 2019-09-12 | 2022-08-23 | International Business Machines Corporation | Dynamic compression with dynamic multi-stage encryption for a data storage system |
-
2013
- 2013-03-15 US US13/843,871 patent/US9069776B1/en active Active
Cited By (3)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN110174997A (en) * | 2019-04-17 | 2019-08-27 | 贵州力创科技发展有限公司 | A kind of date storage method and block chain server based on persistent layer |
US11423158B2 (en) * | 2019-09-12 | 2022-08-23 | International Business Machines Corporation | Dynamic compression with dynamic multi-stage encryption for a data storage system |
CN113467841A (en) * | 2021-05-17 | 2021-10-01 | 翱捷智能科技(上海)有限公司 | Dual-operating-system equipment and quick sleeping and awakening method thereof |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11010386B2 (en) | Transparent analytical query accelerator over encrypted data | |
US11032263B2 (en) | Provide access to data storage services in a network environment | |
US10230701B2 (en) | Selective encryption of profile fields for multiple consumers | |
US10509768B2 (en) | Method and system for secure data storage and retrieval from cloud based service environment | |
US8997248B1 (en) | Securing data | |
US20210124730A1 (en) | Blockchain based distributed file systems | |
US20210157797A1 (en) | Method and system for data storage and retrieval | |
US20150026462A1 (en) | Method and system for access-controlled decryption in big data stores | |
US10516732B2 (en) | Disconnected ingest in a distributed storage system | |
US10009399B2 (en) | Asset streaming and delivery | |
US20230144263A1 (en) | Remote virtualized asset delivery and local provisioning | |
US8364979B1 (en) | Apparatus, system, and method to efficiently search and modify information stored on remote servers, while hiding access patterns | |
US11868339B2 (en) | Blockchain based distributed file systems | |
US11809377B2 (en) | Global data deduplication across multiple distributed file systems | |
US9069776B1 (en) | Serving encrypted and plain data from a low latency non-volatile memory | |
US9218296B2 (en) | Low-latency, low-overhead hybrid encryption scheme | |
US10635645B1 (en) | Systems and methods for maintaining aggregate tables in databases | |
US10803020B1 (en) | Data deduplication on a distributed file system | |
US9183403B2 (en) | Key retrieval | |
US8495368B1 (en) | Method to create a content management recommendation based on presence of confidential information in content | |
WO2017074460A1 (en) | Selective encryption of profile fields for multiple consumers | |
US11726986B2 (en) | Data deduplication on a distributed file system using conditional writes | |
US20230188324A1 (en) | Initialization vector handling under group-level encryption | |
US20220382898A1 (en) | Processing data pages under group-level encryption | |
US10409780B1 (en) | Making a copy of a profile store while processing live updates |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:TAROPA, EMANUEL;REEL/FRAME:030392/0559Effective date: 20130503 |
|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:TAROPA, EMANUEL;REEL/FRAME:030566/0685Effective date: 20130503 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
FEPP | Fee payment procedure |
Free format text: PAYOR NUMBER ASSIGNED (ORIGINAL EVENT CODE: ASPN); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044334/0466Effective date: 20170929 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 4TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1551); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 4 |
|
MAFP | Maintenance fee payment |
Free format text: PAYMENT OF MAINTENANCE FEE, 8TH YEAR, LARGE ENTITY (ORIGINAL EVENT CODE: M1552); ENTITY STATUS OF PATENT OWNER: LARGE ENTITYYear of fee payment: 8 |