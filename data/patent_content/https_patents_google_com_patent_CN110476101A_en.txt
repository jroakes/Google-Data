CN110476101A - For pathological augmented reality microscope - Google Patents
For pathological augmented reality microscope Download PDFInfo
- Publication number
- CN110476101A CN110476101A CN201780089316.4A CN201780089316A CN110476101A CN 110476101 A CN110476101 A CN 110476101A CN 201780089316 A CN201780089316 A CN 201780089316A CN 110476101 A CN110476101 A CN 110476101A
- Authority
- CN
- China
- Prior art keywords
- sample
- microscope
- image
- camera
- computing unit
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V20/00—Scenes; Scene-specific elements
- G06V20/20—Scenes; Scene-specific elements in augmented reality scenes
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N7/00—Television systems
- H04N7/18—Closed-circuit television [CCTV] systems, i.e. systems in which the video signal is not broadcast
- H04N7/183—Closed-circuit television [CCTV] systems, i.e. systems in which the video signal is not broadcast for receiving images from a single remote source
-
- G—PHYSICS
- G02—OPTICS
- G02B—OPTICAL ELEMENTS, SYSTEMS OR APPARATUS
- G02B21/00—Microscopes
- G02B21/36—Microscopes arranged for photographic purposes or projection purposes or digital imaging or video purposes including associated control and data processing arrangements
- G02B21/361—Optical details, e.g. image relay to the camera or image sensor
-
- G—PHYSICS
- G02—OPTICS
- G02B—OPTICAL ELEMENTS, SYSTEMS OR APPARATUS
- G02B21/00—Microscopes
- G02B21/36—Microscopes arranged for photographic purposes or projection purposes or digital imaging or video purposes including associated control and data processing arrangements
- G02B21/365—Control or image processing arrangements for digital or video microscopes
-
- G—PHYSICS
- G02—OPTICS
- G02B—OPTICAL ELEMENTS, SYSTEMS OR APPARATUS
- G02B21/00—Microscopes
- G02B21/36—Microscopes arranged for photographic purposes or projection purposes or digital imaging or video purposes including associated control and data processing arrangements
- G02B21/365—Control or image processing arrangements for digital or video microscopes
- G02B21/367—Control or image processing arrangements for digital or video microscopes providing an output produced by processing a plurality of individual source images, e.g. image tiling, montage, composite images, depth sectioning, image comparison
-
- G—PHYSICS
- G02—OPTICS
- G02B—OPTICAL ELEMENTS, SYSTEMS OR APPARATUS
- G02B21/00—Microscopes
- G02B21/36—Microscopes arranged for photographic purposes or projection purposes or digital imaging or video purposes including associated control and data processing arrangements
- G02B21/368—Microscopes arranged for photographic purposes or projection purposes or digital imaging or video purposes including associated control and data processing arrangements details of associated display arrangements, e.g. mounting of LCD monitor
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T11/00—2D [Two Dimensional] image generation
- G06T11/60—Editing figures and text; Combining figures or text
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T7/00—Image analysis
- G06T7/0002—Inspection of images, e.g. flaw detection
- G06T7/0012—Biomedical image inspection
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T2207/00—Indexing scheme for image analysis or image enhancement
- G06T2207/30—Subject of image; Context of image processing
- G06T2207/30004—Biomedical image processing
- G06T2207/30024—Cell structures in vitro; Tissue sections in vitro
-
- Y—GENERAL TAGGING OF NEW TECHNOLOGICAL DEVELOPMENTS; GENERAL TAGGING OF CROSS-SECTIONAL TECHNOLOGIES SPANNING OVER SEVERAL SECTIONS OF THE IPC; TECHNICAL SUBJECTS COVERED BY FORMER USPC CROSS-REFERENCE ART COLLECTIONS [XRACs] AND DIGESTS
- Y02—TECHNOLOGIES OR APPLICATIONS FOR MITIGATION OR ADAPTATION AGAINST CLIMATE CHANGE
- Y02A—TECHNOLOGIES FOR ADAPTATION TO CLIMATE CHANGE
- Y02A90/00—Technologies having an indirect contribution to adaptation to climate change
- Y02A90/10—Information and communication technologies [ICT] supporting adaptation to climate change, e.g. for weather forecasting or climate simulation
Abstract
It is used to check the microscope of the slice type comprising biological sample (such as tissue or blood) by virologist, in the change in terms of slice is moved to new position or magnifying power or focusing occurs, which is provided with the projection of the increase object (such as thermal map, boundary or annotation) to the visual field substantially in real time.Increasing object helps virologist to characterize or classify (being such as positive to the presence of cancer cell or pathogen) sample.
Description
Technical field
This disclosure relates to field of pathology, and relate more specifically to one kind and be used to help virologist to biological sample
The improved microscopic system and method that (such as blood or tissue) classifies, these biological samples for example comprising cancer cell or
Include pathology reagent (such as protozoan plasmodium or tuberculosis bacteria).
Background technique
In order to biological sample (such as organize) is characterized or classified, sample is placed on microscopic section, and
Virologist amplifies observation to the sample using microscope.Sample can use such as h and E
The reagent dyeing of (hematoxylin and eosin, H&E), so that potential interested feature is more readily spotted in sample.
It is alternatively possible to sample is dyed and is scanned using high-resolution digital scanner, and virologist in work station or
The enlarged drawing of sample is observed on the screen of computer.
For example, the assessment of lymphatic metastasis is the core by stages of the solid tumor (including breast cancer) of many types.The mistake
Journey needs the virologist of high degree of skill, and very time-consuming and easy error is negative or with small cancer especially for cancer
The knot of disease lesion.Current nursing standard includes the digital slices for checking the knot biopsy for having utilized h and E to dye.
However, read has several intrinsic limitations manually, including the reliability in reader's fatigue and classification person between classification person,
These can all negatively affect the sensibility of process.Accurately checking and assess for lymph node biopsy slice is extremely important, because of lymph
The presence of tumour cell may need to carry out cancer new or more positive treatment in nodal tissue, and improve the existence machine of patient
Meeting.
The prior art includes that the background of digital organization chart picture is adapted to depth learning technology and housebroken neural network
To improve cancer diagnosis, characterization and/or description by stages.Related background art includes following article: G.Litjens's et al.
" deep learning is as the tool for improving histopathological diagnosis accuracy and efficiency " (Deep learning as a
Tool for increasing accuracy and efficiency of histopathological diagnosis),
Www.nature.com/scientificreports 6:26286 (in May, 2016)；D.Wang's et al. " shifts for identifying
The deep learning of property breast cancer " (Deep Learning for Identifying Metastatic Breast Cancer),
ARXiv:1606.05718v1 (in June, 2016)；" image analysis and machine in digital pathology of A.Madabhushi et al.
Study: challenge and opportunity " (Image analysis and machine learning in digital pathology:
Challenges and opportunities), medical image analysis 33, p.170-175 (2016)；A.Schuamberg et al.
" H&E dye full slice deep learning prediction prostate cancer in SPOP mutation status " (H&E-stained Whole Slide
Deep Learning Predicts SPOP Mutation State in Prostate Cancer), bioRxiv Preprint
http:/.bioRxiv.or/content/early/2016/07/17/064279.Other interested prior arts include
" the depth convolutional neural networks based on the diagnosis of microscopical point-of care " (Deep Convolutional of Quinn et al.
Neural Networks for Microscopy-based Point of Care Diagnostics), international doctor in 2016
Treat health care Conference on Machine Learning record.
This field, which has been described, increases the microscopical visual field with several examples of assisted surgery.See United States Patent (USP) Shen
2016/0183779 and disclosed PCT application WO 2016/130424A1 please be disclose.Additionally referring to " enhancing aobvious for Watson et al.
Micro- art: the real-time covering of bright field and near-infrared fluorescent image " (Augmented microscopy:real-time overlay
Of bright-field and near-infrared fluorescence images), biomedical optical magazine,
Vol.20 in October, (10) 2015.
Summary of the invention
On the one hand, it describes a kind of for being checked using microscope help comprising biological sample (blood, tissue, phlegm, excrement
Deng) microscopic section method.The visual field for the sample that this method is seen including the use of camera capture by microscopical eyepiece
Amplifier digital image the step of.Machine learning mode discriminator receives image, and according to the Data Identification sample in digital picture
Interested region in product.These interested regions can be may be containing the region of cancer cell, or in other application
In be protozoan plasmodium in blood sample mark, which causes malaria or tuberculosis in sputum sample product
Bacterium.This method further includes that will increase object (enhancement) to be stacked on the visual field by microscope ocular as covering
Step.According to the specific application, increase object a possibility that can taking several forms, such as including cancer cell high " thermal map " or
Coloud coding region, region of interest border, annotation (such as Prostate tissue specimens Gleason score), measured value or
Other labels.When user is relative to microscope optics mobile example or changes magnifying power or focuses, new images are by camera
Capture and be supplied into machine learning mode discriminator, and new region of interest border, annotation and/or other kinds of
Increase object to be coated on the visual field by eyepiece.It is poly- relative to the mobile slice of microscope optics, change in virologist
Burnt or when changing magnifying power and continuing through eyepiece observation sample, the display for newly increasing object being covered on the visual field is substantially real-time
(that is, at several seconds or in even part second) occurs.The type pair for increasing object and helping virologist according to sample of covering
(such as comprising cancer cell or tissue, or including pathogen) biological sample is classified or is characterized.
The disclosure can also be characterized as the system in microscopical form, and it includes biological sample which, which has for accommodating,
Slice objective table and the amplifier digital image of sample seen by microscopical eyepiece of eyepiece, capture digital camera,
It and include the computing unit that the machine learning mode discriminator of image is received from camera.Mode discriminator is trained to execute
" reasoning " it is (such as cancer cell or tissue, all to identify interested region in the biological sample being currently placed on objective table
Such as viral pathogen, protozoan or bacterium, parasitic ovum).Mode discriminator is identified by camera captured image
Area-of-interest.Computing unit generated in the form of region of interest border, annotation, thermal map and/or other information be covered on it is logical
Cross the increase object on the view of eyepiece.When user is relative to microscope mobile example or changes magnifying power or focuses, can generate
Additional increase object.
On the one hand, it provides and a kind of is used to help user and utilizes check with the microscope of eyepiece comprising biological sample
The method of slice, comprising the following steps: (a) captures the number of the view for the sample seen by microscopical eyepiece using camera
Image (b) uses area-of-interest of the machine learning mode discriminator from by camera captured image in identical samples, and
(c) object will be increased as covering to be stacked on the view for the sample seen by microscopical eyepiece, wherein increasing object is based on sample
The area-of-interest identified in product, (d) wherein, when sample is moved relative to microscope optics, or when micro-
When the magnifying power of mirror or focusing change, the new digital picture of the new view of sample is captured by a camera and is supplied to machine learning mould
Formula identifier, and new increase object is stacked to essentially in real time on the new view for the sample seen by eyepiece, thus should
Increasing object helps user to classify or characterize biological sample.
Step (b) can further include the steps that the basic real-time generation for promoting to increase object using reasoning accelerator.It should
Method can further include providing interface in being coupled to microscopical computing unit to be used for different types of biological sample to receive
New machine learning mode discriminator and be locally stored in the step in computing unit.Biological sample can be from by group
It knits, the type of the sample group selection of lymph node, blood, phlegm, urine, excrement, water, soil and food composition.Area-of-interest can
To include cancer cell or tissue, eucaryotic cell structure, cell type or pathogen, wherein pathogen is optionally from by plasmodium, knot
The pathogen selected in the group that core bacillus, malaria protozoan, virus, parasitic ovum form.Increasing object can be from by thermal map, sense
The increase object that interest zone boundary, annotation, Gleason scoring, the prediction of classification possibility, cell count and physical measurements values form
It is selected in group, wherein physical measurements values are optionally diameter of tumor.This method can further include in work associated with microscope
Make the step of display is from one or more image-regions of other one or more samples on the monitor stood, it is one or more
Other samples are similar to the sample in microscopical active view.This method can further include display and shown one or more
The step of a other samples associated metadata.
This method can further include will be by the image data and increase object of the view for the sample that microscopical eyepiece is seen
The step of being output to external display.Microscope can further include being used to support and relative to the mobile motor-driven loading being sliced of eyepiece
Platform, and wherein this method further includes being come using microscope motorized stage and digital camera and machine learning mode discriminator
The step of Preliminary detection is executed to the potential area-of-interest in biological sample.This method can further include control motorized stage
To move the objective table to place potential area-of-interest to be watched by user and in latent in the region of interest each
A place generates the step of increasing object.This method can further include will have the view of the microscope example of stacked increase object with from
The isolated digital picture for the sample that the full slice scanning of slice comprising biological sample obtains is integrated to generate the integrated of sample
The step of view.This method can further include the steps that highlighting sample view on the integrated view of sample.Microscope can
To further include being used to support and moving relative to eyepiece the motorized stage of slice, and wherein this method further includes isolated
Region is specified in digital picture and mobile motorized stage makes specified region be located at the step in the microscopical visual field.
This method can further include being used as information projection associated with specified region to sample in isolated digital picture
View increase object, wherein the information projected optionally includes label and/or annotation.
This method can further include downloading the additional aggregates of machine mode of learning identifier from remote data source by network
The step of.This method can also include: to receive the data of instruction magnifying power of microscope；And it is selected based on received data more
Machine learning mode discriminator in a machine learning mode discriminator.Selected machine learning mode discriminator can be used for
Area-of-interest from by camera captured image in identical samples.
On the one hand, a kind of system for being used to help user and checking the slice comprising biological sample is provided, comprising: micro-
Mirror, the microscope have objective table, at least one object lens and the eyepiece for accommodating the slice comprising biological sample；Digital phase
Machine, the digital camera are configured as capturing the digital picture of the view for the sample seen by the microscopical eyepiece；It calculates single
Member, the computing unit include machine learning mode discriminator, which is configured as from the digital camera
Digital picture is received, wherein the mode discriminator is trained to identify and currently be placed in the biological sample of the type on objective table
Area-of-interest, and the area-of-interest in the digital picture that wherein mode discriminator identification is captured by the camera, and
And wherein the computing unit generates the data for indicating the object of the increase to the sample view seen by microscopical eyepiece, wherein should
Increase object based on the area-of-interest in sample；It is coupled to one or more optical modules of eyepiece, for folding the increase object
It sets on the visual field；Wherein the camera, computing unit and one or more optical modules are configured so that when sample is relative to aobvious
When micro mirror optical device is moved, or when microscopical magnifying power or focusing change, the new digitized map of the new view of sample
As being captured by a camera and being supplied to machine learning mode discriminator, and new increase object be stacked to substantially in real time it is logical
It crosses on the New view for the sample that eyepiece is seen.
Camera substantially continuous can be operated to capture digital picture by frame rate.The system can further include to digitized map
As the reasoning accelerator operated, to promote to increase the basic real-time generation of object.The system can further include computer unit
In the interface to portable computer storage medium, the portable computer storage medium include be used for different type biology sample
The new machine learning mode discriminator of product.Biological sample can be from by tissue, lymph node, blood, phlegm, urine, excrement,
The type selected in the sample sets of water, soil and food composition.Area-of-interest may include cancer cell or tissue, cell knot
Structure, cell type or pathogen, wherein pathogen optionally from by plasmodium, tubercle bacillus, malaria protozoan, virus, post
It is selected in the group of infested ovum composition.Increase object can from by thermal map, region of interest border, annotation, Gleason scoring, classification can
It can be selected in the increase object group of property prediction, cell count and physical measurements values composition, wherein physical measurements values are optionally tumours
Diameter.The system can further include external workstation associated with microscope, which has display, the display
Device shows that one or more image-regions from other one or more samples, one or more of the other sample are worked as with microscope
Sample in front view is similar.Display can show metadata associated with other shown one or more samples.
The system can further include display, and wherein computing unit exports the view for the sample seen by microscope over the display
The image data and increase object of figure.
Microscope carrier may include the motorized stage for being used to support and moving relative to eyepiece slice, and wherein
The microscope, motorized stage, digital camera and machine learning mode discriminator are to the potential region of interest in biological sample
Domain executes the mode operation of Preliminary detection.Motor can be configured as moving stage to place latent in the region of interest every
One to be watched by user, and wherein computing unit and one or more optical modules in latent in the region of interest every
It is generated at one and increases object.The system can further include external workstation, which, which has, is coupled to computing unit
Display, and wherein on microscope have the sample view of stacked increase object with from the complete of the slice comprising biological sample
The isolated digital picture for the sample that slice scanning obtains is integrated and is shown over the display, to generate the integrated view of sample.
Computing unit can have in the form of general purpose computer to the interface of digital camera and to one or more optical modules
Interface.Computing unit can further include the interface to computer network.
Further, with microscope ocular, for accommodating the objective table, the Yi Jiyong that wrap slice with sample
In the microscopic system of the digital camera of the image in the visual field of capture microscope ocular, improvement is provided, which includes: coupling
Microscopical computing unit is closed, which includes the collection for being coupled to microscopical deep neural network mode discriminator
It closes, with different magnifying powers, the training on one group of sample sections, the set are received by camera the deep neural network mode discriminator
The image of generation.
Computing unit can further include the interface to portable computer storage medium, the portable computer storage medium
Include the new engine mode of learning identifier for different type biological sample or microscope applications.
Further, a kind of device is provided, which includes: portable computer storage in combination
The collection of medium, each portable computer storage medium include the different type for use micro- sem observation by virologist
Biological sample different machine learning mode discriminators, each of different machine learning mode discriminator is with machine
The form of the set of mode of learning identifier is trained with different amplification stages.
Further, a kind of method of training machine mode of learning identifier is provided, comprising:
A) the full slice image of multiple slices of the biological sample comprising given type is obtained；B) the full slice image is held
Row parameter deformation, to simulate the optical quality of the digital picture by the camera capture for being coupled to microscopical eyepiece；And c)
Carry out training machine mode of learning identifier using the full slice image deformed in step b).
Further, a kind of method of training machine mode of learning identifier is provided, comprising:
A) using the microscope with camera and more than one object lens of the type used by virologist, with microscope
The different magnifying powers that provide of more than one object lens multiple digital pictures of biological sample are obtained in the microscopical visual field；With
B) using the set of the image training machine mode of learning identifier obtained in the step a), each member in set with object
An associated specific magnifying power in mirror is trained.
This method can further include step a) being repeated to different types of biological sample and b) to generate machine learning mould
The step of multiple and different set of formula identifier.This method can further include by multiple and different collection of machine learning mode discriminator
Each of conjunction is stored to the step on portable computer storage medium.
Disclosed method and system realize several significant advantages, including the region of interest in the microscopical visual field
The basic real-time display of domain increase object.Optical path itself is not interrupted, i.e., virologist is still in the visual field of microscope ocular
Middle observation actual slice, rather than digital representation.The increase object being covered on the visual field can take many forms, these forms can
To be modified according to the type of sample.In addition, in some embodiments, the modular method of design on hardware and software allows
Any kind of detection or classification mode identification model are run in computing unit.Example includes:
A) cancer is deposited in the presence (such as prostate cancer, breast cancer) of general tumour or cancer cell or lymph node tissue
In；
B) plasmodium or tubercle bacillus in test sample；
C) tissue signature, such as macrophage are detected；
D) the depth characterization of tissue sample, for example, the prostata tissue of detection display Gleason 3 and 4 characteristic of Gleason, with
And user selects the level or degree of characterization；
D) in addition to pathology, the quality control of any detection of optical microscopy or classification task, such as electronic building brick is used
System checks.
Compared with virologist identifies area-of-interest from the digital picture scanned, disclosed method and system are mentioned
Several advantages have been supplied, and has been as general as pathology and provides attractive new alternative method.Firstly, virologist practises
It is used to observe physics glass slice on microscope, rather than observes digital picture on the screen.Microscope has bigger view
Open country, and can be focused on z-plane, and full slice scan image is not always in this way, full slice scans in many formats
Image only captures image in the best but single depth of focus.Physics microscope usually has than the digital picture of scanning more preferable
Optical quality, this is useful for the diagnosis of edge case or characterization.Additionally, virologist does not have to concern that full slice is swept
Retouch instrument whether miss cell fragment or in low coverage it is out of focus.In addition, quick diagnosis, nothing may be implemented using physics slice
It needs delayed sweep and uploads slice.Additionally, full slice scanner and associated equipment and work station are very expensive, certain
In the case of cost be up to hundreds of thousands of dollars, than the feature with the disclosure microscope more than several orders of magnitude.
In addition, the desk-top microscopical small form factor of loading and low power require so that using this public affairs in remote districts
The microscope (such as carrying out malaria detection or screening for cancer in Africa or remote Pacific Islands) opened is feasible.It is additional
Ground, by providing local or operation reasoning offline ability, without uploading data, this eliminates data sharing limitation, interconnection
Net connection and uploading bandwidth requirement.
In another aspect of the present disclosure, a kind of system includes being stored on one group of slice with the depth of different magnifying powers training
The computing unit of the set of neural network filter device, the computing unit are coupled to aobvious with digital camera and optical device
Micro mirror, it is stacked or cover active view by microscope ocular for object will to be increased.In one embodiment, exist
Several such set of the storage on discrete portable computer storage medium (such as SD card etc.), a set are used for mode
Each of identification application type.It is contemplated that a kind of modular system, wherein computing unit has interface (such as SD card is inserted
Slot), for receiving any one of multiple independent SD cards, each SD card is mounted with for specific application (such as breast cancer inspection
Survey, prostate cancer detection, malaria detection etc.) mode discriminator set, to enable microscope with virologist's
Demand develops and is different pathology application assembly and upgrading software and model.
Optionally, the interface in computing unit may be coupled to local area network or wide area network (such as internet), and machine
The additional aggregates of mode of learning identifier can be under remote location (such as remote data storage, cloud or remote server)
It is downloaded to computing unit.
As used herein, term " biological sample " is intended to be broadly defined as to include blood or blood constituent, from plant
Or the tissue or tissue fragment, phlegm, excrement, urine or other body substances of animal, and may the water containing pathogen, soil
Or foodstuff samples.
Detailed description of the invention
Fig. 1 is the schematic diagram for pathological augmented reality microscopic system, virologist's work with optional connection
Make station to be shown in conjunction with.
Fig. 2A is the diagram that the field of microscope of breast cancer sample is shown at given amplification stage (such as 10x).Fig. 2 B
It is the diagram for the enhancing view seen by virologist using the microscope of Fig. 1, is superimposed wherein increasing object in the form of " thermal map "
In the sample on the visual field of possible canceration, registration Weir cell.The stacked help virologist of thermal map characterizes sample in Fig. 2 B
Product, because their attention is guided into the area-of-interest of especially possible canceration by it.If virologist will change microscope
Object lens (for example, being changed to 40X lens) then will see the new of sample by microscope ocular so as to the thermal map region of enlarged drawing 2B
The visual field captures new images, and new thermal map is covered on visual field (not shown) substantially in real time (for example, with one second or two seconds)
On, further virologist to be helped to study sample.
Fig. 3 A is the diagram that the field of microscope of prostate cancer specimens is shown at given amplification stage (such as 10x).Figure
3B is the diagram of the view for the enhancing seen by virologist using the microscope of Fig. 1, wherein the increase object in outline form is folded
It sets in surrounding sample on the visual field of the cell of possible canceration.Increasing object further includes providing the text box of annotation, in this example
For Gleason Scoring System and tumor size data.The stacked help virologist of profile and annotation in Fig. 3 B characterizes sample,
Because their attention is guided into the area-of-interest of especially possible canceration by it, and provides the scoring of suggestion for sample.If
Virologist will change focal plane position or depth (that is, adjusting microscopical focusing), to detect profile at different depth
Interior area-of-interest, then the New view of sample will be seen by microscope ocular and be captured by camera, and substantially real-time
New increase object (not shown) (such as profile and annotation text box) is covered on the visual field by ground (for example, in one second or two seconds)
On, further virologist to be helped to study sample.
Fig. 4 A is the diagram in the visual field by microscopical blood sample at lower magnification.Fig. 4 B shows the view of Fig. 4 A
Open country, but there are the increase objects of plasmodium (Plasmodium) to be coated over the visual field in the identical samples wherein in the form of rectangle
On, to help virologist to characterize sample.
Fig. 5 is the more detailed block diagram of the computing unit of Fig. 1.
Fig. 6 is the flow chart for showing the workflow of system of Fig. 1.
Fig. 7 is the chart for showing color code or rank for explaining the increase object in the form of thermal map.
Fig. 8 is the diagram of machine learning mode discriminator, and form is trained in advance on one group of microscopic section image
Independent depth convolutional neural networks set.Each member of set is trained under specific amplification stage.
Fig. 9 is the diagram of one group of portable computer storage medium, and each of storage medium is loaded with code, parameter
And associated data, these data are indicated for specific application (in the detection of breast cancer in such as breast tissue, prostata tissue
The detection of cancer cell and characterization etc.), on one group of microscopic section image training independent depth convolutional neural networks collection
It closes.The user for wanting the system of Fig. 1 of enhancing microscopic system ability can obtain one or more media of Fig. 9, and by phase
The set of associated depth convolutional neural networks is loaded into the local computing unit of Fig. 1 and Fig. 5.It is alternatively possible to pass through meter
Calculate additional aggregates of the network interface in unit from remote data storage downloading depth convolutional neural networks.
Specific embodiment
Fig. 1 is the schematic diagram for pathological augmented reality microscopic system 100, the virologist with optional connection
Work station 140 is shown in conjunction with.System 100 includes conventional virologist's microscope 102 comprising eyepiece 104 is (in stereomicroscopy
In the case where mirror, it is optionally the second eyepiece).The support of objective table 110 includes the slice 114 of biological sample.Light source 112 projects
Light passes through sample.Micro objective 108 guides the image of sample into optical module 120 as illustrated by arrows 106.In microscope
The middle additional lens 108A and 108B of setting, for providing different amplification stages.Focus control knob 160 allows user to change
The depth of focus of lens 108.
Microscope includes optical module 120, which combines such as pellicle mirror 122 or beam combiner/separation
The component of device covers the visual field by eyepiece for that will increase object.Optical module 120 allows virologist as routinely aobvious
The microscopical visual field is equally seen in micro mirror, and will increase object (thermal map, boundary or profile, annotation as needed or automatically
Deng) it is considered as the covering on the visual field, which shows 128 He of generation unit by augmented reality (augmented reality, AR)
Lens 130 project in the visual field.The image generated by display unit 128 is combined by pellicle mirror 122 with field of microscope.Make
For the alternative solution of pellicle mirror, liquid crystal display (liquid crystal display, LCD) can be placed in the optical path, it should
Liquid crystal display is projected in optical path using transmission yin as that will increase object.
Optical module 120 can take a variety of different forms, and describe this using various terms in the art
Kind module.For example, it is referred to as " projecting unit ", " image injection module " or " optical perspective display technology ".This list is described
The document of member includes U.S. Patent Application Publication 2016/0183779 (see the description of Fig. 1,11,12,13) and disclosed PCT application
WO 2016/130424A1 (see the description of Fig. 2,3,4A to 4C)；Watson et al. " enhancing microscopy: bright field and near-infrared are glimmering
The real-time covering of light image " (Augmented microscopy:real-time overlay of bright-field and
Near-infrared fluorescence images), " biomedical optical magazine ", vol.20 (10) October 2015；
" using the augmented reality of surgical operation microscope " (Augmentation of Reality Using an of Edwards et al.
Operating Microscope), image guided surgery is performed the operation magazine (J.Image Guided Surgery), Vol.1no.3
(1995)；" the three-dimensional augmented reality in surgery microscope " (Stereo augmented reality in of Edwards et al.
The surgical microscope), medicine and virtual reality (editor) IOS such as (19997) J.D.Westward that meet are published
Society, page 102.
The microscopical visual field is oriented to eyepiece 104 and is also oriented to digital camera 124 by pellicle mirror 122.The lens of camera are not
It shows, but is conventional lenses.Camera can be used with the high-resolution of for example per second 10 or 30 frames operation (such as 16,000,000 pictures
Element) camera form.The enlarged drawing for the sample that digital camera capture is seen by microscopical eyepiece.The number captured by camera
Word image is supplied to computing unit 126.Computing unit 126 will be more fully described in Fig. 5.Optionally, camera can be adopted
With the form of ultrahigh resolution digital camera, such as developed by Cannon and the APS-H- size announced in September, 2015 (about
29.2x 20.2mm) 2.5 hundred million pixel cmos sensors.
In brief, computing unit 126 includes the machine learning mode discriminator that image is received from camera.Machine learning mould
Formula identifier can use the form of depth convolutional neural networks, and the depth convolutional neural networks are in the class with tested biological sample
It is trained on the identical one group of microscopic section image of type.Additionally, mode discriminator preferably takes mode discriminator
The form of set, each mode discriminator on one group of slice with different amplification stages (for example, 5X, 10X, 20X, 40X) into
Row training.Mode discriminator is trained to identify area-of-interest in the image for the biological sample being currently placed on objective table
(such as cancer cell or tissue, virus or pathogen, the parasitic ovum of bacterium etc.).Mode discriminator is identified by camera 124
Area-of-interest in captured image.Computing unit 126, which generates, indicates the object of the increase to the view of sample seen in user
Data, which is generated and is projected by AR display unit 128, and is combined by pellicle mirror 122 with the eyepiece visual field.
By camera 124 to the substantially continuous capture of image, by mode discriminator to the quick execution of the reasoning of image, with
And generation and projection as the increase object being covered on the visual field, so that the system 100 of Fig. 1 can continue to provide the increasing to the visual field
Add object, and works as operator and change magnifying power by switch to different object lens 108A or 108B, or focused by operation
When knob 160 carrys out the navigation (for example, by using motor 116 of driving objective table) around slice to change the depth of focus, side
Virologist is helped to characterize essentially in real time or classification samples.This is the major progress of this field, and is microscopical to using
The improvement of routine pathology.
So-called " substantially in real time ", we mean that being cut changing magnifying power, changing the depth of focus or navigation and be then parked in
In 10 seconds of the new position of on piece, object will be increased or covering projects on the visual field.In fact, as explained below that
Sample, in the case where optionally using reasoning accelerator, it is anticipated that in most cases, new covering can become focusing
Change, generate and projected on the visual field in one second or two seconds even part second of magnification change or slice position variation.
In short, then disclose it is a kind of using have eyepiece 104 microscope 102 help user (such as virologist) look into
The method for seeing the slice 114 comprising biological sample.Method includes the following steps: being passed through using the capture user of camera 124 micro-
The digital picture for the sample that the eyepiece of mirror is seen is caught using machine learning mode discriminator (200, Fig. 5, Fig. 8) from by camera 124
Area-of-interest in the image obtained in identical samples, and increase object is stacked to user as covering and passes through microscopical mesh
On the sample view that mirror is seen.Relative to microscope optics mobile example or the microscopical magnifying power of change or gather in user
Jiao Shi, new image is captured by a camera and is supplied to machine learning mode discriminator, and new increase object is by substantially in real time
Ground covers on the new view for the sample seen by eyepiece.The increase object covered helps user to divide biological sample
Class.
Fig. 2A is the figure that the field of microscope 150 of breast cancer sample 152 is shown at given amplification stage (such as 10X)
Show.Fig. 2A shows the visual field for not increasing object, as the microscope of the prior art.Fig. 2 B is to use Fig. 1 by virologist
The diagram of enhancing view seen of microscope, wherein increasing object 154 in the sample may canceration with the form of " thermal map " superposition
Registration Weir cell the visual field on." thermal map " is one group of pixel for indicating the tissue of possible canceration, these pixels are according to Fig. 7
Code coloring with highlight include cancer cell high probability (such as red) region.The stacked side of thermal map 154 in Fig. 2 B
Virologist is helped to characterize sample, because their attention is guided into the area-of-interest of especially possible canceration by it.If pathology
Scholar to change micro objective (for example, selection Fig. 1 in lens 108A) so as to enlarged drawing 2B thermal map region 154 (for example,
Change into 40X lens), then the New view of sample will be seen by microscope ocular and be directed toward camera.Camera 124 captures new figure
Picture, and generate new 154 (not shown) of thermal map substantially in real time (for example, with one second or two seconds) and be covered on the visual field
On, further to help virologist to study with higher magnifying power sample.
In a kind of possible configuration, microscope 102 include identify which micro objective be currently to sample into
The ability of the position of row imaging is (for example, using switch or pass through the microscope of the operation for turning objective table to control comprising lens
The user instruction of electronic equipment), and this mark is transmitted to computing unit 126 using simple electronic equipment, so that mould
Correct machine learning pattern recognition module (Fig. 8 seen below) in formula identifier set, which is endowed, holds new field-of-view image
The task of row reasoning.
Fig. 3 A is the diagram that the field of microscope 150 of prostate cancer specimens is shown at given amplification stage (such as 10X),
As the not conventional microscopy of the ability of the disclosure.Fig. 3 B is the enhancing seen by virologist using the microscope of Fig. 1
The diagram in the visual field 150, wherein increasing object is stacked in the visual field for surrounding the cell of possible canceration in sample in the form of profile 156
On.Increasing object further includes providing the text box of annotation, is measured in this example for Gleason (Gleason) Scoring System and size
Value.In this particular example, annotation be in profile 87% cell be 3 grades of Gleason scoring, 13% cell is Gleason 4
Grade scoring, and the diameter for the tumour being made of the cell of 4 grades of Gleason scorings is 0.12 μm.
Another possible increase object is the confidence score of sample cell canceration.For example, increase object can take probability or
The form of confidence score, the cell in such as profile be 3 grades of Gleason 85% confidence level and profile in cell be
4 grades of Gleason of 15% confidence level.In addition, measured value (0.12 μm) can be the diameter of entire contour area.
The stacked help virologist of profile and annotation in Fig. 3 B characterizes sample, because it guides their attention into
The area-of-interest of especially possible canceration, and the scoring of suggestion is provided for sample.If virologist will change microscopical poly-
Depth of focus degree is to detect the area-of-interest in profile 156, then the New view of sample will be seen by microscope ocular and by phase
Machine 124 captures, and substantially in real time (for example, in one second or two seconds) by new increase object (such as profile and annotation text
This frame) it is covered on the (not shown) of the visual field, further virologist to be helped to study sample.The system of Fig. 1 is optionally
The ability for increasing object projection is opened or closed including virologist, such as by providing on the attachment station 140 of Fig. 1 to being
The control of system provides simple user interface on computing unit 126, or by opening and closing AR display unit 128
Floor push.
Fig. 4 A is at lower magnification by the hypothetical diagram in the microscopical visual field 150 of blood sample, such as in routine
As seeing in microscope.The view includes the ingredient of various blood fragments (red blood cell and leucocyte) and such as blood platelet.
Fig. 4 B shows the same visual field of Fig. 4 A, but wherein in plasmodium (plasmodium present in the identical samples of 156 form of rectangle
Belong to) increase object be coated on the visual field, with help virologist characterize sample, be in this case malaria-positive.
Following table 1 lists the optical characteristics for pathological typical microscope and can be in camera used in Fig. 1
124 digital resolution.
Table 1
* it is based on 16MP camera
Fig. 5 is a kind of block diagram of possible form of the computing unit 126 of Fig. 1.Substantially, in a kind of possible configuration,
Computing unit is dedicated computer system, is designed to execute the required task of the system of Fig. 1, including hold captured image
Row reasoning generates the numerical data of the covering for the visual field, and optional reasoning accelerates to execute reasoning operation fast enough, thus
The basic real-time display of realization increase object, and the additional machine learning model (mode discriminator) of load are additional to support
The ability of pathology task.
In Fig. 5, computing unit includes depth convolutional neural networks mode discriminator 200, depth convolutional neural networks mould
The form of formula identifier 200 is by storage for the process instruction of neural network and the memory 202 of parameter and for capturing
Image execute reasoning central processing unit 204.The module can also include graphics card 206, for based on from mode knowledge
The reasoning results of other device 200 generate the numerical data (for example, thermal map, annotation, profile etc.) of covering.Memory 212 includes place
Reason instruction for selecting machine learning model appropriate based on current amplification stage, and is assisted with remote work station 140 (Fig. 1)
Adjust shared field-of-view image and other tasks explained herein.Computing unit can also include reasoning accelerator 214, to add
Execution reasoning of the speed to institute's captured image.Computing unit further includes the various interfaces to the other assemblies of system, including is used for
The interface (not shown) (such as USB port) of digital picture is received from camera, is shown for sending AR for digital displaying data
The interface (for example, network cable port or the port HDMI) 208 of unit 128, to work station 140 interface (for example, network cable
Port) 216 and computing unit is enable to receive and download the portable medium comprising additional modes identifier (see Fig. 9)
Interface 210 (for example, SC card reader), with the ability of expansion system, thus to different pathologic applications execution pattern identifications and
Covering generates.Module in high-speed bus 220 or network connection computing unit 126.In fact, additional hard disk drive, place
Reason device or other assemblies can reside in computing unit, and details is not particularly critical.
In another possible configuration, computing unit 126 can take be enhanced to have (multiple) mode discriminator and
The general purpose computer (such as PC) of accelerator and the form of pattern process module as shown in Figure 5.As shown in Figure 1, personal meter
Calculation machine has the interface (for example, USB port that digital image data is received from camera) to camera, to the interface of AR projecting unit
(for example, the port HDMI) and the network interface for making it possible to download additional mode discriminator and/or being communicated with remote work station.
In use, it is assumed that multiple and different mode discriminators are loaded into computing unit, then automated sample type is examined
Device or manual selector is surveyed to cut between sample associative mode identification model (for example, prostate cancer vs breast cancer vs malaria detects)
It changes, and suitable machine learning mode discriminator or model is selected based on this.As previously explained, slice is moved to
New position (for example, by using motor 116 of driving objective table) is switched to another micro objective 108 (amplifying) triggering
Increase the update of object.Optionally, if only changing magnifying power, the set of the different models operated under different amplification stages (see
Reasoning Fig. 8) is executed to sample, and the reasoning results can combine the same position in slice.It was submitted on 2 23rd, 2017
It is entitled " to be used to help method and system (the Method and that virologist identifies tumour cell in amplification organization chart picture
System for Assisting Pathologist Identification of Tumor Cells in Magnified
Tissue Images) " Serial No. PCT/US17/019051 pending PCT application in describe how to execute the operation
Further details, content are incorporated herein by reference.Another option is that computing unit can be by single from microscope to calculating
The simple electronic communication of member knows current magnifying power from microscope.Microscope monitors user and which lens is put into optical path,
And send selection information to computing unit.
Existed used in the computing unit of Fig. 5 with the depth convolutional neural networks mode discriminator of the type shown in 200
It is well-known in pattern-recognition and field of machine vision, and retouching in detail to it is therefore omitted for simplicity
It states.The Google Inception-v3 depth convolutional neural networks frame that present mode identifier is based on is described in scientific literature
Structure.Referring to below with reference to document, content is incorporated herein by reference: " going deep into convolution " (Going of C.Szegedy et al.
Deeper with Convolutions), arXiv:1409.4842 [cs.CV] (in September, 2014)；C.Szegedy's et al.
" initial fabric for thinking deeply computer vision again " (Rethinking the Inception Architecture for
Computer Vision), arXiv:1512.00567 [cs.CV] (in December, 2015)；See also C.Szegedy et al. in
The U.S. Patent application for the Serial No. 14/839,452 that August in 2015 is submitted on the 28th " handles image using deep neural network
(Processing Images Using Deep Neural Networks)".The forth generation quilt of referred to as Inception-v4
It is considered the alternative architecture of mode discriminator 306.Referring to " Inception-v4, the Inception- of C.Szegedy et al.
The influence of ResNet and remaining connection to study " (Inception-v4, Inception-ResNet and the Impact of
Residual Connections on Learning), arXiv:1602.0761 [cs.CV] (2 months 2016).See also in
U.S. Patent application " image classification neural network (the Image for the Serial No. 15/395,530 that on December 30th, 2016 submits
Classification Neural Networks)".The description of convolutional neural networks is passed through in these papers and patent application
It is incorporated herein by reference.
Other documents for describing deep-neural-network mode discriminator include following item: " the depth of G.Litjens et al.
Exercises are the tool for improving histopathological diagnosis accuracy and efficiency " (Deep learning as a tool for
Increasing accuracy and efficiency of histopathological diagnosis),
Www.nature.com/scientificreports 6:26286 (in May, 2016)；King .Wang's et al. " turns for identifying
The deep learning of shifting property breast cancer " (Deep Learning for Identifying Metastatic Breast
Cancer), ARXiv:1606.05718v1 (in June, 2016)；" the image point in digital pathology of A.Madabhushi et al.
Analysis and machine learning: challenge and opportunity " (Image analysis and machine learning in digital
Pathology:Challenges and opportunities), medical image analysis (Medical Image Analysis)
33,p.170-175(2016)；" in H&E dyeing full slice deep learning prediction prostate cancer of A.Schuamberg et al.
SPOP mutation status " (H&E-stained Whole Slide Deep Learning Predicts SPOP Mutation
State in Prostate Cancer), bioRxiv Preprint http :/.bioRxiv.or/content/early/2016/
07/17/064279。
For training the training slice source of deep neural network mode discriminator 200 can be by interested sample class
One group of slice of type carries out full slice and scans generation of starting from scratch.For example, the sectioning image for training can be from Jia Lifuni
Santiago naval medicine center (Naval Medical Center in San Diego, NMCSD) in sub- state and the public can obtain
The source (such as CAMELYON16 challenge match and cancer gene group map (The Cancer Genome Atlas, TCGA)) obtained
It obtains.Optionally, they can be generated from one group of image of the different slices captured by the camera of Fig. 1.
Digital full slice scanner and system for stained slice are well known in the art.This equipment and correlation
System can be obtained from Aperio scientific & technical corporation, Bang Song photoelectricity company, Philip, Ventana Medical Systems and other companies.
Digital full slice image can be obtained with the first amplification stage (such as 40X), this is convention.Image can be up-sampled
Or down-sampling, to obtain the training image of other magnifying powers.It is alternatively possible to different magnifying powers (for example, with conventional hand
Each amplification stage that dynamic microscope provides) Multiple-Scan training slice.
Inference speed
In some embodiments, the digital picture as microscopical whole visual field can be made inferences.At other
In the case of, it may be desirable to only to a part of image (several 299 × 299 rectangular pixels pieces such as around central region)
Reasoning is executed, or reasoning is executed to some major part in the visual field.
Use the model and 16MP camera based on Inception-v3 with 299x299 pixel input size, optics FoV
Spheric region intensive covering (diameter of 2700 pixels) need~120 piece reasonings.If reasoning is just for centre three
/ mono- operation (increases reasoning granularity, and is used as context for other 2/3rds), then~1200 reasonings is needed to call.Such as
Fruit addition rotates and turn over or integrates (ensembling), then additional reasoning may be needed to call.
Table 2 is listed using the graphics processing unit of state of the art and the reasoning call number of reasoning accelerator and is pushed away
Manage the time.
Table 2
* assume 150 reasonings per second, Inception-v3
* hypothesis is 56000 reasonings per second using reasoning accelerator system
Assuming that camera 124 is run with 30 frame (fps) per second, and it is seamless substantially close to real-time experience to obtain, there is rotation
Turn, overturning and the intensive covering of integrated reasonable combination are possible.
Reasoning accelerator (214, Fig. 5)
Reasoning accelerator (also referred to as artificial intelligence (AI) accelerator) is a kind of emerging microprocessor or coprocessor, should
Class microprocessor or coprocessor are designed to accelerate to execute the process of the reasoning of the input data set for pattern-recognition.These
System is at present using customization dedicated IC chip (application-specific integrated circuit
Chip, ASIC), field programmable gate array (field programmable gate array, FPGA), graphics processing unit
The combining form of (graphics processing unit, GPU) and universal computing unit.In some applications of the system of Fig. 1
In, it would be desirable to it include reasoning accelerator in computing unit 126, as shown in Figure 5.Reasoning is described in the art to add
Fast device, referring to entitled " neural network processor (the Neural Network Processor) " of Jonathon Ross et al.
U.S. Patent Application Publication 2016/0342891, and these reasoning accelerators can get currently on the market, such as NVidia TM
With Tesla TM P40 and P4 GPU accelerator and Intel TM deep learning reasoning accelerator.
In a simple embodiment, the system of Fig. 1 can be used only and be inserted into standard PC (computing unit 126)
The output of USB camera, the identification of standard PC execution pattern, and (increase cover graphics via graphics card output interface (for example, HDMI)
Add object) it is output to AR display equipment.The reasoning can be completed by the graphics processing unit (GPU) in standard PC.In this configuration
In, the reasoning accelerator in equipment is optional, and not required.In the case where needing faster reasoning, computer
Can use ready-made reasoning accelerator later is enhanced as card module.
Increase the generation of object
The generation for projecting the increase object on the visual field can execute as follows:
1) the moving model reasoning on the visual field of machine learning mode discriminator 200 in computing unit 126, it is each to create
The tumour probability (used here as cancer detection as example) in region.
2a) thermal map: the tumour probability of each image sheet in the visual field is converted into color value (for example, RGB), and will
These color values are stitched together to create thermal map.This task can be executed by graphics card 206.
2b) polygonal profile: tumour probability with some score (such as probability > 50%) thresholding, and remaining area (or
Multiple regions, if there is several not connected areas) boundary formed polygonal profile.Equally, this task can be by
Graphics card 206 executes.
3) image on display is converted by AR display unit 128 from step 2a or 2b digital image data, then
It is projected in optical path by lens 130 and pellicle mirror 120.
Additionally, graphics card 206 can be generated individually or together with the output from machine learning mode discriminator and be used for
Including increasing Gleason Scoring System, annotation in object data etc. in number, and this additional increasing is provided to AR display module 128
Add object.
The communication of microscope and computer about the position on slice.
In fact, in some cases, other than virologist uses the microscopic system of Fig. 1, being held to sample slice
The scanning of row full slice may be useful.In this case, full slice, which scans, may reside on work station 140 (or by
Work station 140 and computing unit 126 are shared).A variety of possible purposes can be made of the increase object in the visual field, comprising:
1. highlighting microscope present viewing field (field of view, FoV) on full slice image (for example, for teaching
Learn purpose).The positioning of FoV can pass through the image registration (image registration) of MIcrosope image to full slice image
It completes, or is completed by using the motor 116 of driving microscope carrier 110, wherein motor coordinate is mapped to entirely
On sectioning image coordinate.
2. the specified region in microscope FoV self-navigation to slice.For example, microscope can be under " prescan " mode
Operation, in this mode, motor 116 drive microscopic section to a series of X-Y location, and utilize phase at each position
Machine obtains low magnification image.Image is passed to the machine learning mode discriminator in computing unit 126, and pattern-recognition
Device identifies those images from the corresponding position comprising area-of-interest (for example, it may be possible to cell of canceration).Then, in virologist
During use, motor 116 can be operable to driving slice to those positions, and operator is prompted to study the view at each position
Open country, and utilize increase object (the thermal map, profile etc.) visual field Lai Zengqiang appropriate.In this embodiment, computing unit can combine
Microscopical user interface operates, to help the workflow of virologist.This user interface can be bonded to micro-
In mirror itself, or it is present in the display 142 of work station 140.For example, work station 140 includes that display is aobvious in Fig. 1
The display 142 of the present viewing field 150 of micro mirror.By using mouse 146 or keyboard 144, virologist can be on a workstation
Input order, so that microscope carrier motor 116 is stepped through a series of positions on slice comprising area-of-interest.It can be with
The mark of the potential area-of-interest under low magnifying power is executed on full slice image, and uses motor coordinate to slice coordinates
Mapping the position of potential area-of-interest is converted into slice coordinates.
3. label and annotation are transferred to MIcrosope image from full slice image
The full slice image of the sample slice obtained by full slice scanner may be provided in image
The label or annotation of various object of interest.Because can obtain between the slice on full slice image and motorized stage 110
Registration (for example, according to mapping of 116 position of motor to full slice image coordinate), it is possible to label and annotation transfer are arrived
On the MIcrosope image seen by eyepiece.This is possible in the following manner: label and annotation are supplied to computing unit
In graphics card 206, and then when motor driven sliding block is to the coordinate that wherein there is this label and annotation, by this mark
The numerical data of label and annotation is supplied to AR display unit 128.
The method for obtaining the registration between the slice on full slice image and microscope may be implemented as algorithm solution party
Case, or position by using computer vision methods (such as image registration) full slice image corresponding to camera image
Region is implemented.
4. the visual field is output to locally-stored device together with prediction, for for example using in pathologists report
In fact, virologist may expect to record their work in terms of characterization or graded samples.This record can
In the form of using the digital picture of the visual field (be with or without increase object), these digital pictures can be generated and store (for example,
In the memory 212 of computing unit), and attached pathology work station 140 is then transmitted them to via interface 216.
Workstation software generally includes working flow software, and virologist is executing classification to sample or characterizing task and while generating report abides by
Follow the working flow software.This software includes tool (such as icon or prompt), this allows virologist that will be stored in storage
The storage digital picture and associated annotation or increase object in the visual field in device 212 are inserted into report.
It may include other optional feature in system.
A. for showing the output port in the visual field on a monitor
Computing unit includes interface or port 216, is worked for computing unit to be connected to attached peripheral virologist
Stand 140.The interface allows the visual field captured by camera and is transferred to work station 140 by any increase object that graphics card generates
Monitor 142.
B. the monitor connected as needed shows image-region similar with the image-region in present viewing field, with note
It releases.
In a kind of possible configuration, the display of monitor 142 of work station 140 is from other slices (for example, coming from other
Patient) to the image-region of the image-region " similar " in present viewing field, and for (multiple) other slice there may be
Any increase object or annotation.Specifically, work station 140 may include be loaded with one group from other patients other be sliced
The memory of digital image data, and potentially have hundreds of or thousands of such slices.Work station may include that mode is known
Other device, the mode discriminator execute the pattern-recognition in the slice visual field on microscope to other all this digital slices images,
And select closest to the visual field image.The visual field (that is, part of selected digital slices stored in memory) can work
It stands and is presented together with the present viewing field by microscope 100 on 140 display 142.The memory of storage on a workstation
In each of slice all with metadata (result or survival data, year after such as patient's diagnosis, date, treatment, treatment
Age, smoker's situation etc.) it is associated.The display in the visual field of selected digital slices can use the display of metadata to increase
By force.
Increase the example of object
1. thermal map
Fig. 2 B shows the example of " thermal map " of the form of the covering of colour element, which identifies area of special interest
Domain, such as may include the region of cancer cell.Thermal map helps virologist by the way that covering is presented to virologist on the visual field
Check slice, in the covering, the zone of dispersion (i.e. the group of pixel) of the slice of the high probability comprising tumour cell is with specific
Color (such as kermesinus) instruction.On the contrary, the relatively low region of probability in the visual field comprising tumour cell can individually be stayed
Under, or with contrastive colours (such as blue or purple) reproduction.Thermal map image can be accompanied by a series of different zones, in these areas
There is the cell group of the high probability comprising tumour cell in domain.
In one embodiment, small pixel (" piece ") group in the digital slices image captured by camera 124 is commented
Divide range from 0.0 to 1.0.The region of thermal map 20 with highest scoring is shown as kermesinus, and with lowest score
Region is perhaps individually left (non-reinforced) or is shown as another contrastive colours, such as purple.The code 22 of Fig. 7 is basic
It is upper to distribute color to tumour probability score using visible spectrum (i.e. the color of rainbow).However, it is possible to which visible spectrum is used only
A part, such as only generate tumour probability possibility greater than 0.5 pixel increase object.Moreover, another it is possible can
In alternative embodiment, only gray level can be used for code, for example, wherein white corresponds to scoring 0, black corresponds to scoring
1, and gray level constitutes the value between 0 and 1.It is, for example, possible to use single color (such as greens), and opacity is (grey
Degree) it can be used for codes for tumor probability.
" disease is used to help in the PCT application co-pending of the 23 days 2 months Serial No. PCT/US17/019051 submitted in 2017
Neo-confucian identifies method and system (the Method and System for of tumour cell in amplification organization chart picture
Assisting Pathologist Identification of Tumor Cells in Magnified Tissue
Images the further details of generation and the calculating about thermal map and tumour probability score are described in) ", this application passes through reference
It is hereby incorporated by.
2. the profile and annotation of area-of-interest
Fig. 3 B shows the example of the profile of area-of-interest, and profile can generate as described above and be projected the visual field
On.Profile can be accompanied by text material (annotation), such as Gleason scoring, the measured value (such as diameter of tumor) of size, cancer
The prediction of disease possibility, cell count or other associated pathology information.Dimensional measurement Value Data (for example, " diameter of tumor 2mm ")
Display be possible because computing unit knows current object lens focal power, and therefore the pixel of image data can be turned
Change physical unit into.This measured value can trigger additional label or annotation, such as " micrometastasis " vs " macro transfer ".Annotation is also
It may include statistical data, the percentage of the image positive of such as cancer cell and the percentage of cancer cell image feminine gender, and set
Reliability or probability score.
3. identifying the rectangle of object
Fig. 4 B shows the use example of the rectangle or bounding box placed around object of interest.This method can be used for
Such as mark food, blood, water or bacterium (such as tuberculosis) in other types biological sample, (such as malaria is former for protozoan
Worm), parasitic ovum or other pathogens.Rectangle can be accompanied by additional information, such as annotation (such as size), confidence level or probability
Scoring, sample identification etc., this depends on application.
Workflow
Fig. 6 is the flow chart for showing the workflow of the system using Fig. 1.In step 302, user will newly be sliced 114 and insert
Enter onto microscope carrier 110.In step 304, sample classification device or manually select (for example, by using attached work
Stand 140 or by the user interface controls on microscope or computing unit) according to the type selection mode of the sample on slice know
Other model (for example, breast cancer, prostate cancer, malaria), and the correlation machine mode of learning identifier in computing unit is marked
Note is for operation.
It is captured by digital camera 124 in the image of step 306, the visual field and is sent to computing unit 126.If operator moves
Dynamic slice (for example, by operating stage motor 116 under panning mode), then by the new images in the camera capture visual field.It is similar
Ground captures new images if operator changes object lens 108 (for example, zooming in or out).New images are sent to computing unit
126.(in fact, camera 124 can be with the continuous frame rate operation of for example per second 10 or 30 frames, and the view in computing unit
Wild update can be substantially continuous, rather than just when stage position or object lens change).
In step 312, the image in the visual field is provided as input to the study of the correlation machine in computing unit 126 (Fig. 5)
Mode discriminator 200, to execute reasoning.In fact, step 312 can synchronously be repeated with the frame rate of camera 124.
Graphics card or GPU 206 in step 314, computing unit 126, which generate, corresponds to increasing relevant to sample type
Add the digital image data of object or reinforcer, and this digital image data is provided to AR display unit 128, to project
Onto the visual field, observed in eyepiece 104 for virologist.
Computing unit may include control (for example, by attached work station), and by these controls, user be can specify
What they wished to is projected onto the type of the annotation or increase object on the visual field, to wish microscope about them to user
The control how to be operated under augmented reality mode.For example, user, which can only be specified in the form of thermal map, increases object.As another
Example, if sample is blood sample, user can specify in the form of rectangle, plasmodium present in identical samples
Increase object.In prostate samples, user can specify the boundary profile that Gleason scoring is 3 or higher cell peripheral, with
And the annotation such as shown in prior figures 3B with description.As another example, switch can be provided a user (such as foot-operated to open
Close) to open and close projection, and therefore shown in field of microscope and increase object.
The set of machine learning mode discriminator
It should be noted that the system of Fig. 1 is designed to make in conjunction with the microscope for providing several different object lens and amplification stage
With.In general, specific mode discriminator or machine learning model are with the training on one group of training slice of specific amplification stage.Cause
This, in order to adapt to a possibility that user changes object lens during checking given sample, the preferred embodiment of computing unit includes mould
The set of formula identifier, each mode discriminator are trained on the image data with different amplification stages.For example, in fig. 8 it is shown that
The set of four different mode identifiers (406A, 406B, 406C and 406D).Each of mode discriminator uses depth
The form of convolutional neural networks, the training on set of number sectioning image with specific magnifying power of depth convolutional neural networks.For example,
Mode discriminator 406A training on 40X amplification sectioning image.Mode discriminator 406B training on 20X amplification sectioning image.
Mode discriminator 406C training on 10X amplification sectioning image.Mode discriminator 406D training on 5X amplification sectioning image.Reason
In the case of thinking, each of amplification stage of mode discriminator training is corresponding to available amplification stage on the microscope of Fig. 1.
This is not required, and mismatches, is then caught by camera 124 because if existing between magnifying power of microscope and training slice magnifying power
The MIcrosope image obtained can be sampled or down-sampling is with the amplification stage corresponding to mode discriminator.
In operation, according to the current object lens used on microscope, by piece (i.e. a part of microscope FoV, such as 299
× 299 rectangular pixels pieces) 402A, 402B, 402C or 402D as input 404A, 404B, 404C or 404D be supplied to related figure
Case identifier 406A, 406B, 406C, 406D.In thermal map application, the scoring of the pixel piece between 0 and 1 is returned with multinomial logic
The form returned is generated as the last layer of neural network filter device 406A, 406B, 406C, 406D, generate in 0 and 1 it
Between probability form, the input data (piece) belong to the prediction of which kind of vs of health (is here have tumour).It is multinomial
Formula logistic regression is well-known in supervised learning and optimization field, sometimes referred to as " Softmax recurrence ".It can be in net
The religion found on (http://ufldl.stanford.edu/tutorial/supervised/SoftmaxRegression/)
Journey provides further details, incorporated herein by reference.Therefore, output 408A, 408B, 408C, 408D is pixel piece
Scoring.
In one configuration, all that form the microscopical visual field are executed with the process for generating the scoring of pixel piece.It is defeated
408A, 408B, 408C, 408D are provided to the graphics card (GPU) 206 in computing unit out, indicate that enhancing (is originally being shown to generate
Example in be thermal map) data.Under in the case of objective table is remain stationary but user changes magnifying power, it can be used in Fig. 8 and show
Two in set member out generate thermal map, and one be used for the second magnifying power for the first magnifying power and one.It is theoretical
On, it can be with the output of composite set member.Therefore, in a kind of modification, using multiple members of set, such as
It is deposited in focussing plane in varying situations, multiple output 408A, 408B, 408C or 408D are supplied to combiner function
250, the combiner function 250 combination exports and transmits data to graphics card.Further details it is previously cited in
It is described in the PCT Patent Application submitted within 23 days 2 months 2017.
It is also understood that computing unit is preferably incorporated in pathologic applications that microscope is used for (for example, breast cancer group
Knit, lymph node tissue, prostata tissue, malaria etc.) each of different amplification stages under on microscopic section image
The set of trained mode discriminator, as shown in Figure 8.
Portable medium with machine learning mode discriminator
In one embodiment, the computing unit 126 of Fig. 1 and Fig. 5 includes hardware configuration, for receiving and being locally stored needle
To newly trained mode discriminator/machine learning model of different types of biological sample or microscope applications.This configuration example
Such as it is illustrated as SD card interface 210 in Fig. 5, the single SD card comprising machine learning model is allowed to be inserted into computing unit
In, and content is downloaded and stored in memory 202.Fig. 9 shows the example of one group of 900SD card, including card 902,
904,906 and 908.Model parameter of each card comprising the machine learning mode discriminator for particular pathologies application, filtering
Device coefficient, executable code and other details, the mark (card 902) of cancer cell in such as breast tissue, cancer in prostata tissue
The mark (card 906) of mycobacterium tuberculosis in the mark (card 904) of cell, blood sample, for the blood sample of malaria detection
The middle protozoic mark of plasmodium (card 908).In this type of design, computing unit may be provided as example with for general
The standard facility of the machine learning model of logical pathologic applications (such as cancer cell detection in Pap smear), and user can be with
Additional card or card group 900 are obtained from provider or source, to improve ability of the microscope for other pathologic applications.With this
Kind mode, the laboratory of operation microscope can according to need or according to market demands, for specific pathologic applications, finishing
Their demands to augmented reality in microscope.Laboratory does not need creation model, but service provider can be with one group of instruction
Practice sectioning image and discretely create these models, verify model to ensure robustness and versatility, and then creation includes this
The portable storage media (such as SD card) of class model, and it is supplied to client as needed.
Although SD card is shown in FIG. 9, can certainly use can store machine learning pattern recognition model
Other physical formats of memory devices, including those of those of currently available format and generation in future format.Computing unit
Also it may be coupled to computer network, and additional machine learning mould downloaded by the computer interface of such as interface 216 (Fig. 5)
Type (or model set).
Specific application
Although it have been described that microscope is used for several specific applications that pathology are checked, including breast cancer detection, forefront
Gland cancer detection, pathogen (such as plasmodium, tuberculosis, malarial parasite, parasitic ovum) mark etc., it is to be understood that, pathology
What the other application in field was certainly possible to.Additionally, the principle of the system of Fig. 1 can extend to microscopical other and answer
With quality control checking, food safety or the inspection of, small part, water quality monitoring etc..
Autonomous system
Microscopic system with local computing unit and Fig. 1 of (multiple) pattern recognition model is ideally suited as this
Ground autonomous system.As long as it can provide suitable power supply for electronic equipment shown in Fig. 1 and Fig. 5, it can be considered as
It is portable, and can be used in remote location.In its most basic form, it does not need any internet or other networks
Connection, and attached peripheral work station 140 is nor indispensable.Computing unit can have the attached use of own
Family interface (not shown) or control change to open or close enhancing, preference pattern, be directed to selected specific magnifying power to suitable
When machine learning model and any other nonproductive task.The design of user interface can take any suitable form, all
User is guided to provide suitable selection such as simple touch screen and icon.
Networked deployment
In another configuration, the system of Fig. 1 can be implemented in networked environment, and wherein computing unit is connected to remote service
Device, for example, to obtain new machine learning model or execution reasoning or reasoning acceleration on isolated platform.For example, previously tying
Close remote work station 140 display description processing task in it is some can locally execute on a workstation or far from meter
It calculates and is executed on the Net-connected computer of both unit and work station.
Motor driven objective table 110/116
The combination of motor driven objective table 110 (it is very common in pathology microscope) allow to be formed additional function with
Further help virologist.For example, slice driving can be arrived a series of positions by motor 116, to utilize the phase being entirely sliced
Machine captures low magnification image.Then the machine of training under low amplification stage low magnification image being supplied in computing unit
Device mode of learning identifier, to provide suspicious region (for example, it may be possible to contain cancer cell or may be containing the area of mycobacterium tuberculosis
Domain) Preliminary detection.Then, microscope carrier can be automatically driven in a series of steps comprising potentially relevant region
Those of domain.The increment positioning of slice can be executed according to the order of user, for example, by being used for microscopical control or leading to
The user interface of affiliated work station is crossed to execute.
Using current technology, search in detail is carried out to full slice to obtain area-of-interest with 40X in a short time
It is currently infeasible.However, using the system of Fig. 1, using can detect suspicious region with low magnifying power and then only exist
The low magnifying power model amplified when needing is currently feasible.
Model training
In some embodiments, the image obtained from camera 124 can be different from terms of optical quality or resolution ratio
The image for the full slice scanner that machine learning mode discriminator is trained on it.Digital camera 124 and associated optics group
The quality of part has a much relations with this, and it is desirable that the quality of digital camera and associated optical module with for capturing
Training sectioning image optical module and camera it is identical in quality or almost the same.Although image resolution ratio should be it is comparable,
But the image from microscope camera 124 may have some artifacts (such as geometric distortion), these artifacts are swept in full slice
It retouches and is not present in instrument training image or less presence.Theoretically, the specific training image of microscope is collected for training new model
It is possible.However, this is not an especially expansible solution.More practical solution is to ensure that based on full slice
The pattern recognition model of image is generalized to the MIcrosope image captured by camera 124.It is if promote using default models
It is unacceptable, then should can according to full slice image scanning generate expert along training data, these scanning " seeming " as
Their corresponding microscope camera images.This expert along training data can be by introducing full slice image for parameter deformation
Scan image is simultaneously generated using the image through deforming for training.The example of this parameter deformation include distortion, addition noise,
Reduce resolution ratio, fuzzy and setting contrast.
Alternative is to generate a large amount of training image according to multiple slices using microscopical camera, then uses this
A little images carry out training pattern, rather than use obtains image from full slice scanner.
Another alternative be trained production confrontation network (generative adversarial network,
GAN) image for training machine mode of learning identifier is generated.
It is further to consider
The picture quality of the camera 124 of Fig. 1 is important consideration.Since camera real-time streams are usually image source, answer
In research real-time streams the picture quality of image with obtained from full slice scanner and be used for trained static image it is (usually high-quality
Amount) comparable situation and this influence to model performance.
One special challenge is that the optical resolution of human eye is significantly larger than the resolution ratio of current digital camera.For example,
In order to detect small transfer, to identical transfer, machine learning model may need compared with the mankind may need into one
Step amplification (being switched to higher focal power object lens).Solving the problems, such as a kind of this method is, when user check it is potential interested
Region when, prompt user to be switched to high (or higher) amplification stage, and then generate new increase with higher focal power
Object.Another method is using ultrahigh resolution camera, such as cmos sensor of 2.5 hundred million pixel of Cannon.
As described above, the optical module 120 including pellicle mirror 122 should be placed in the optical path, so that it is reproduced most preferably
Visual experience.In a kind of possible configuration, microscope can there are two the forms of the stereoscope of eyepiece using tool, and
It can will increase object to project in the visual field of one or two eyepiece.
Another consideration is to ensure that in the case where be registrated identical with camera, and eyes are seen increase object on the visual field or covered
Lid.This can be used the reference mark being present in the visual field and is executed by camera captured image.
It should also be noted that can reside in the label being examined on the full slice image of slice can be transferred to camera
Image is simultaneously projected onto the visual field, for example, using image registration techniques, as previously mentioned,
The change (such as focus, refractive calibration) carried out by user to optical device will affect camera image and shown
Image on picture quality.Camera image needs to keep clear and high quality, allows to execute reasoning.A kind of possible
In configuration, computing unit includes picture quality detector module, and it is when good enough which assesses image
To execute reasoning.If image does not have quality good enough, user can be prompted to carry out correction appropriate, such as adjustment focal length
Or other pH effects are carried out to microscope.
Previously it is also noted that the augmented reality microscope of the disclosure is suitable for other purposes, such as checks or quality controls,
Such as in the manufacture of electronic building brick or other products, carried out wherein checking by microscope.Therefore, as the additional of the disclosure
Aspect has been disclosed and a kind of be used to help user the microscope with eyepiece is utilized to check object the object of manufacture (for example)
Method, comprising the following steps: the digital picture of object that (a) is seen by user by microscope ocular using camera capture,
(b) identify the area-of-interest in object (for example, lacking from by camera captured image using machine learning mode discriminator
It is sunken), and will (c) increase the view that object is stacked to the object seen by user by microscopical eyepiece as covering.With
Family is relative to microscope optics mobile example, and when then stopping or change microscopical magnifying power or focusing, new
Digital picture is captured by a camera and is supplied to machine learning mode discriminator, and new increase object is stacked essentially in real time
Onto the new view for the object seen by eyepiece, thus increases object and user is helped to classify or characterize object.Appended power
The feature that benefit requires is deemed applicable to this variation, wherein object is (for example, the object of manufacture instead of the biological sample on slice
Body, computer chip, small part etc.) it is checked by microscope, and camera captures the object seen in field of microscope
Image.
On the one hand a kind of system that help user checks the slice comprising biological sample can also be provided, the system is to combine
Mode include: microscope, the microscope have for accommodates include biological sample slice objective table, at least one object lens
And eyepiece；Digital camera, the amplifier digital image for the sample that digital camera capture is seen by microscopical eyepiece；It calculates single
Member, the computing unit include the machine learning mode discriminator that digital picture is received from digital camera, wherein the mode discriminator
It is trained to the area-of-interest that mark is currently placed in the biological sample of the type on objective table, and wherein the mode is known
Other device identifies the area-of-interest in the digital picture captured by the camera, and wherein the computing unit generates expression to user
The data of the increase object in the visual field for the sample seen by eyepiece；It is coupled to one or more optical modules of eyepiece, being used for will
Increase object to be stacked on the visual field；The wherein camera, computing unit and one or more optical module operations, so that opposite in user
In microscope optics mobile example, and then stop or change microscopical magnifying power or focus when, captured by camera
New digital picture is simultaneously supplied into machine learning mode discriminator, and new increase object be stacked to essentially in real time it is logical
It crosses on the New view for the sample that eyepiece is seen.
Although specifically describing currently preferred embodiments, the problem of all about scope of the invention, will all pass through
It is answered with reference to the appended claims explained according to foregoing teachings.
Claims (39)
1. a kind of method for being used to help user and the microscope with eyepiece being utilized to check the slice comprising biological sample, including with
Lower step:
(a) digital picture of the view for the sample seen by the microscopical eyepiece is captured using camera,
(b) region of interest in the sample is identified from by the camera captured image using machine learning mode discriminator
Domain, and
(c) object will be increased as covering to be stacked on the view for the sample seen by the microscopical eyepiece, wherein described
Increase object based on the area-of-interest identified in the sample,
(d) wherein, when the sample is moved relative to microscope optics, or when the microscopical magnifying power or
When focusing change, the new digital picture of the new view of the sample is captured by the camera and is supplied to the machine learning mould
Formula identifier, and new increase object is stacked in essentially in real time on the new view for the sample seen by eyepiece, thus institute
Stating increase object helps user to classify or characterize the biological sample.
2. according to the method described in claim 1, wherein, step (b) further includes promoting the increase using reasoning accelerator
The step of basic real-time generation of object.
3. according to the method described in claim 1, further include in being coupled to the microscopical computing unit provide interface with
It receives the new machine learning mode discriminator for different types of biological sample and is locally stored in the calculating list
Step in member.
4. according to the method in any one of claims 1 to 3, wherein the biological sample be from by tissue, lymph node,
The type selected in the sample sets that blood, phlegm, urine, excrement, water, soil and food form.
5. according to the method in any one of claims 1 to 3, wherein the area-of-interest include cancer cell or tissue,
Eucaryotic cell structure, cell type or pathogen, wherein the pathogen is optionally from primary by plasmodium, tubercle bacillus, malaria
The pathogen selected in the group that animal, virus, parasitic ovum form.
6. according to the method in any one of claims 1 to 3, wherein the increase object is from by thermal map, area-of-interest side
It is selected in the increase object group that boundary, annotation, Gleason scoring, the prediction of classification possibility, cell count and physical measurements values form,
In, the physical measurements values are optionally diameter of tumor.
7. method according to any one of claim 1 to 6 further includes in work station associated with the microscope
The step of being shown on monitor from one or more image-regions of other one or more samples, it is one or more of its
His sample is similar to the sample in the microscopical active view.
8. according to the method described in claim 7, further including that display is associated with other shown one or more samples
The step of metadata.
9. method according to any one of claim 1 to 8 further includes the sample that will be seen by the microscopical eyepiece
The step of image data and increase object of the view of product are output to external display.
10. method according to any one of claim 1 to 9, wherein the microscope further includes being used to support and relatively
In the motorized stage of the mobile slice of the eyepiece, and wherein, the method also includes use microscope motorized stage and
Digital camera and machine learning mode discriminator execute the Preliminary detection of the potential area-of-interest in the biological sample
The step of.
11. according to the method described in claim 10, further including controlling the motorized stage to move the objective table to put
The potential area-of-interest is set to be watched by user and in the life of each of potential area-of-interest region
At the step of increasing object.
12. method according to any one of claim 1 to 11 further includes the microscope that will have be stacked increase object
The isolated digital image collection of the view of sample and the sample obtained from the scanning of the full slice of the slice comprising the biological sample
The step of at integrated view to generate the sample.
13. further including according to the method for claim 12, highlighting the sample on the integrated view of the sample
The step of view.
14. according to the method for claim 12, wherein the microscope further includes being used to support and relative to the eyepiece
The motorized stage of mobile slice, and wherein, the method also includes specifying region simultaneously in the isolated digital picture
And the mobile motorized stage makes specified region be located at the step in the microscopical visual field.
15. further including according to the method for claim 14, by information projection associated with specified region described
As the increase object of the view to the sample in isolated digital picture, wherein the information of the projection optionally includes mark
Label and/or annotation.
16. further including downloading machine from remote data source by network according to claim 1 to method described in any one of 15
The step of additional aggregates of mode of learning identifier.
17. according to claim 1 to method described in any one of 15, further includes:
Receive the data for indicating the microscopical magnifying power；And
The machine learning mode discriminator in multiple machine learning mode discriminators is selected based on received data；
Wherein, selected machine learning mode discriminator be used to identify the sample from by the camera captured image
In area-of-interest.
18. a kind of system for helping user to check the slice comprising biological sample, comprising:
Microscope, the microscope have objective table, at least one object lens and the mesh for accommodating the slice comprising biological sample
Mirror,
Digital camera, the digital camera are configured as capturing the number of the view for the sample seen by the microscopical eyepiece
Word image,
Computing unit, the computing unit include machine learning mode discriminator, and the machine learning mode discriminator is configured
To receive digital picture from the digital camera, wherein the mode discriminator is trained to mark and is currently placed on the load
Area-of-interest in the biological sample of type on object platform, and wherein, the mode discriminator identification is caught by the camera
The area-of-interest in digital picture obtained, and wherein, the computing unit, which generates, to be indicated to by the microscopical mesh
The data of the increase object for the sample view that mirror is seen, wherein the increase object is based on the area-of-interest in the sample；And
It is coupled to one or more optical modules of the eyepiece, one or more of optical modules are used for the increase object
It is stacked on the visual field；
Wherein, the camera, computing unit and one or more optical modules are configured so that when the sample is relative to aobvious
When micro mirror optical device is moved, or when microscopical magnifying power or focusing change, the new number of the new view of the sample
Word image captures and is supplied to the machine learning mode discriminator by the camera, and new increase object is by substantially real
When be stacked on the New view for the sample seen by the eyepiece.
19. system according to claim 18, wherein the substantially continuous operation of camera is by frame rate capture number
Image.
20. system according to claim 18 further includes the reasoning accelerator operated to the digital picture, to promote
Into the basic real-time generation for increasing object.
21. system described in any one of 8 to 20 according to claim 1 further includes arriving portable computing in computing unit
The interface of machine storage medium, the portable computer storage medium include the new machine for different types of biological sample
Mode of learning identifier.
22. system described in any one of 8 to 21 according to claim 1, wherein the biological sample is from by tissue, lymph
The type selected in the sample sets that knot, blood, phlegm, urine, excrement, water, soil and food form.
23. system described in any one of 8 to 22 according to claim 1, wherein the area-of-interest includes cancer cell or group
It knits, eucaryotic cell structure, cell type or pathogen, wherein the pathogen is optionally from former by plasmodium, tubercle bacillus, malaria
It is selected in the group that lively object, virus, parasitic ovum form.
24. system described in any one of 8 to 23 according to claim 1, wherein the increase object is from by thermal map, region of interest
It is selected in the increase object group that domain boundary, annotation, Gleason scoring, the prediction of classification possibility, cell count and physical measurements values form
It selects, wherein the physical measurements values are optionally diameter of tumor.
25. system described in any one of 8 to 24 according to claim 1 further includes external workstation associated with microscope,
The external workstation has display, and the display shows one or more images from other one or more samples
Region, one or more of other samples are similar to the sample in the microscopical active view.
26. system according to claim 25, wherein the display is shown and other shown one or more samples
The associated metadata of condition.
27. system described in any one of 8 to 24 according to claim 1, wherein the system also includes displays, and its
In, the computing unit export on the display the view for the sample seen by the microscope image data and
The increase object.
28. system described in any one of 8 to 27 according to claim 1, wherein the microscope carrier includes being used to support
With the motorized stage relative to the mobile slice of the eyepiece, and wherein, the microscope, motorized stage, digital camera
It is operated with machine learning mode discriminator with the mode for executing Preliminary detection to the potential area-of-interest in the biological sample.
29. system according to claim 28, wherein it is described to place that the motor is configured as moving the objective table
Each of potential area-of-interest region by user to be watched, and wherein, the computing unit and one or more
Optical module generates at each of potential area-of-interest region increases object.
30. system described in any one of 8 to 24 according to claim 1 further includes external workstation, the external workstation tool
There is the display for being coupled to the computing unit, and wherein, the sample for the increase object that having on the microscope is stacked
The isolated digital picture of view and the sample obtained from the scanning of the full slice of the slice comprising biological sample is integrated and is shown in
On the display, to generate the integrated view of sample.
31. system described in any one of 8 to 30 according to claim 1, wherein the computing unit is in the shape of general purpose computer
Formula has the interface to the interface of the digital camera and to one or more of optical modules.
32. system described in any one of 8 to 31 according to claim 1, wherein the computing unit further includes to computer network
The interface of network.
33. a kind of wrapping the objective table of slice with sample and for capturing described show with microscope ocular, for accommodating
Improvement in the microscopic system of the digital camera of the image in the visual field of micro mirror eyepiece, the improvement include:
It is coupled to the microscopical computing unit, the computing unit includes being coupled to the microscopical deep neural network
The set of mode discriminator, deep neural network mode discriminator training on one group of sample sections with different magnifying powers,
The set receives the image generated by the camera.
34. improvement according to claim 33, wherein the computing unit further includes to portable computer storage medium
Interface, the portable computer storage medium includes the new machine for different type biological sample or microscope applications
Mode of learning identifier.
35. a kind of device, described device include: in combination
The set of portable computer storage medium, each portable computer storage medium include for be made by virologist
With the different machine learning mode discriminators for the different types of biological sample that microscope is checked, the different machine learning
Each of mode discriminator is in the form of machine learning mode discriminator set with different amplification stage training.
36. a kind of method of training machine mode of learning identifier, comprising:
A) the full slice image of multiple slices of the biological sample comprising given type is obtained；
B) parameter deformation is executed to the full slice image, to simulate the camera capture by being coupled to the microscopical eyepiece
Digital picture optical quality；And
C) the machine learning mode discriminator is trained using the full slice image deformed in step b).
37. a kind of method of training machine mode of learning identifier, comprising:
A) using the microscope with camera and more than one object lens of the type used by virologist, with the microscope
The different magnifying powers that provide of more than one object lens multiple digitized maps of biological sample are obtained in the microscopical visual field
Picture；With
B) using the set of the image training machine mode of learning identifier obtained in the step a), each of described set at
Member is trained with associated with an object lens in the object lens specific magnifying power.
38. according to the method for claim 37, further include to different types of biological sample repeat step a) and b) to
The step of generating multiple and different set of machine learning mode discriminator.
39. further including according to the method for claim 38, in multiple and different set by machine learning mode discriminator
Each is stored to the step on portable computer storage medium.
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/US2017/037212 WO2018231204A1 (en) | 2017-06-13 | 2017-06-13 | Augmented reality microscope for pathology |
Publications (2)
Publication Number | Publication Date |
---|---|
CN110476101A true CN110476101A (en) | 2019-11-19 |
CN110476101B CN110476101B (en) | 2022-02-18 |
Family
ID=64660880
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201780089316.4A Active CN110476101B (en) | 2017-06-13 | 2017-06-13 | Augmented reality microscope for pathology |
Country Status (5)
Country | Link |
---|---|
US (2) | US11010610B2 (en) |
EP (1) | EP3586181B1 (en) |
JP (1) | JP6947841B2 (en) |
CN (1) | CN110476101B (en) |
WO (1) | WO2018231204A1 (en) |
Cited By (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN110727097A (en) * | 2019-12-19 | 2020-01-24 | 上海兰脉信息科技有限公司 | Pathological microscopic image real-time acquisition and analysis system, method, device and medium |
CN111160238A (en) * | 2019-12-27 | 2020-05-15 | 上海杏脉信息科技有限公司 | Microscopic image quality analysis method, training method, system, device and medium |
CN111522136A (en) * | 2020-05-12 | 2020-08-11 | 宁波蓝明信息科技有限公司 | Light filtering type augmented reality microscopic imaging system |
CN114066875A (en) * | 2021-11-25 | 2022-02-18 | 数坤(北京)网络科技股份有限公司 | Slice image processing method and device, storage medium and terminal device |
Families Citing this family (34)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10890751B2 (en) * | 2016-02-05 | 2021-01-12 | Yu-Hsuan Huang | Systems and applications for generating augmented reality images |
CN107527069A (en) * | 2017-08-22 | 2017-12-29 | 京东方科技集团股份有限公司 | Image processing method, device, electronic equipment and computer-readable medium |
EP3608701A1 (en) * | 2018-08-09 | 2020-02-12 | Olympus Soft Imaging Solutions GmbH | Method for providing at least one evaluation method for samples |
EP3844781A4 (en) * | 2018-08-30 | 2022-05-11 | Applied Materials, Inc. | System for automatic tumor detection and classification |
US10818386B2 (en) * | 2018-11-21 | 2020-10-27 | Enlitic, Inc. | Multi-label heat map generating system |
US11282198B2 (en) | 2018-11-21 | 2022-03-22 | Enlitic, Inc. | Heat map generating system and methods for use therewith |
WO2020146037A1 (en) | 2019-01-09 | 2020-07-16 | Google Llc | Augmented reality laser capture microdissection machine |
CN113439227B (en) * | 2019-01-22 | 2023-06-09 | 应用材料公司 | Capturing and storing enlarged images |
US11255785B2 (en) | 2019-03-14 | 2022-02-22 | Applied Materials, Inc. | Identifying fiducial markers in fluorescence microscope images |
EP3938763A4 (en) | 2019-03-14 | 2022-12-07 | Applied Materials, Inc. | Identifying fiducial markers in microscope images |
CN109815945B (en) * | 2019-04-01 | 2024-04-30 | 上海徒数科技有限公司 | Respiratory tract examination result interpretation system and method based on image recognition |
CN110490130A (en) * | 2019-08-16 | 2019-11-22 | 腾讯科技（深圳）有限公司 | Intelligent optical data processing method, device and computer readable storage medium |
US11328485B2 (en) * | 2019-08-23 | 2022-05-10 | Tencent America LLC | Method and apparatus for displaying an augmented-reality image corresponding to a microscope view |
AU2020344517A1 (en) * | 2019-09-09 | 2022-03-24 | PAIGE.AI, Inc. | Systems and methods for processing images of slides for digital pathology |
WO2021061613A1 (en) | 2019-09-24 | 2021-04-01 | Applied Materials, Inc. | Interactive training of a machine learning model for tissue segmentation |
AU2020365118A1 (en) * | 2019-10-18 | 2022-04-28 | Nanostring Technologies, Inc. | Systems and methods for spatial mapping of expression profiling |
US11551344B2 (en) * | 2019-12-09 | 2023-01-10 | University Of Central Florida Research Foundation, Inc. | Methods of artificial intelligence-assisted infrastructure assessment using mixed reality systems |
EP4078151A4 (en) | 2019-12-17 | 2024-01-03 | Applied Materials Inc | System and method for acquisition and processing of multiplexed fluorescence in-situ hybridization images |
EP4097636A1 (en) * | 2020-01-28 | 2022-12-07 | PAIGE.AI, Inc. | Systems and methods for processing electronic images for computational detection methods |
WO2021158952A1 (en) * | 2020-02-05 | 2021-08-12 | Origin Labs, Inc. | Systems configured for area-based histopathological learning and prediction and methods thereof |
WO2021161447A1 (en) * | 2020-02-13 | 2021-08-19 | オリンパス株式会社 | Optical microscope system |
CN111292310B (en) * | 2020-02-14 | 2024-01-26 | 生物岛实验室 | Method, device, electronic equipment and storage medium for acquiring biological tissue image |
WO2021166219A1 (en) * | 2020-02-21 | 2021-08-26 | オリンパス株式会社 | Optical microscope system |
US11131842B2 (en) * | 2020-03-02 | 2021-09-28 | Tencent America LLC | Method and apparatus for displaying information ring and augmented reality display for microscope |
US11211160B2 (en) * | 2020-03-13 | 2021-12-28 | PAIGE.AI, Inc. | Systems and methods of automatically processing electronic images across regions |
EP4130842A4 (en) * | 2020-03-31 | 2024-05-15 | Evident Corp | Microscope system, projection unit, and egg testing assistance method |
CN111598133B (en) * | 2020-04-22 | 2022-10-14 | 腾讯医疗健康(深圳)有限公司 | Image display method, device, system, equipment and medium based on artificial intelligence |
CN112288684B (en) * | 2020-07-15 | 2021-06-25 | 华北理工大学 | Pathogenic judgment system and method applying density analysis |
WO2022019138A1 (en) * | 2020-07-20 | 2022-01-27 | キヤノン株式会社 | Image processing device, image processing method, and program |
US20230281968A1 (en) * | 2020-07-30 | 2023-09-07 | Anaut Inc. | Recording Medium, Method for Generating Learning Model, Surgical Support Device and Information Processing Method |
US11550991B2 (en) * | 2021-03-29 | 2023-01-10 | Capital One Services, Llc | Methods and systems for generating alternative content using adversarial networks implemented in an application programming interface layer |
WO2023114470A1 (en) * | 2021-12-16 | 2023-06-22 | University Of Miami | Augmented and mixed reality incorporating pathology results in surgical settings |
CN115032780B (en) * | 2022-05-25 | 2024-01-26 | 北京理工大学 | Quick processing system for tissue pathology pictures and working method thereof |
DE102022206025A1 (en) | 2022-06-14 | 2023-12-14 | Carl Zeiss Microscopy Gmbh | Population classification using point cloud features |
Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20150213599A1 (en) * | 2014-01-25 | 2015-07-30 | Pangea Diagnostics Ltd. | Automated histological diagnosis of bacterial infection using image analysis |
CN105652429A (en) * | 2016-03-22 | 2016-06-08 | 哈尔滨理工大学 | Automatic focusing method for microscope cell glass slide scanning based on machine learning |
WO2016130424A1 (en) * | 2015-02-09 | 2016-08-18 | The Arizona Board Of Regents Of Regents On Behalf Of The University Of Arizona | Augmented stereoscopic microscopy |
US20160314583A1 (en) * | 2013-12-19 | 2016-10-27 | Axon Dx, Llc | Cell detection, capture and isolation methods and apparatus |
US20170045356A1 (en) * | 2015-08-14 | 2017-02-16 | Kla-Tencor Corporation | System, method and computer program product for calibration of metrology tools |
Family Cites Families (29)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6711283B1 (en) | 2000-05-03 | 2004-03-23 | Aperio Technologies, Inc. | Fully automatic rapid microscope slide scanner |
DE102004055683B4 (en) | 2004-10-26 | 2006-09-07 | Carl Zeiss Surgical Gmbh | Eye Surgery Microscopy System and Method Therefor |
CA2631564A1 (en) * | 2004-11-29 | 2006-06-01 | Hypermed, Inc. | Medical hyperspectral imaging for evaluation of tissue and tumor |
JP2011181015A (en) | 2010-03-03 | 2011-09-15 | Olympus Corp | Diagnostic information distribution device and pathology diagnosis system |
US10139613B2 (en) * | 2010-08-20 | 2018-11-27 | Sakura Finetek U.S.A., Inc. | Digital microscope and method of sensing an image of a tissue sample |
WO2012062681A1 (en) | 2010-11-08 | 2012-05-18 | Seereal Technologies S.A. | Display device, in particular a head-mounted display, based on temporal and spatial multiplexing of hologram tiles |
US20140233826A1 (en) | 2011-09-27 | 2014-08-21 | Board Of Regents Of The University Of Texas System | Systems and methods for automated screening and prognosis of cancer from whole-slide biopsy images |
JP2013104964A (en) | 2011-11-11 | 2013-05-30 | Toshiba Corp | Holographic display device |
DE102012218382B4 (en) * | 2012-10-09 | 2015-04-23 | Leica Microsystems Cms Gmbh | Method for determining a laser microdissection range and associated laser microdissection system |
US20160123813A1 (en) | 2013-05-29 | 2016-05-05 | Canon Kabushiki Kaisha | Spectral microscopy device |
DE102013214318A1 (en) | 2013-07-22 | 2015-01-22 | Olympus Soft Imaging Solutions Gmbh | Method for creating a microscope image |
EP3036558B1 (en) | 2013-08-19 | 2020-12-16 | Basf Se | Detector for determining a position of at least one object |
US20150103401A1 (en) * | 2013-10-11 | 2015-04-16 | Datacolor Holding Ag | Reference color slide for use in color correction of transmission-microscope slides |
AU2015220783B2 (en) | 2014-02-24 | 2021-02-04 | Ventana Medical Systems, Inc. | Methods, kits, and systems for scoring the immune response to cancer by simultaneous detection of CD3, CD8, CD20, and FoxP3 |
EP3116432B1 (en) | 2014-03-14 | 2020-07-22 | Brainlab AG | Improved overlay of anatomical information in a microscope image |
DE102014007909A1 (en) | 2014-05-27 | 2015-12-03 | Carl Zeiss Meditec Ag | Surgical microscope |
US9754371B2 (en) * | 2014-07-31 | 2017-09-05 | California Institute Of Technology | Multi modality brain mapping system (MBMS) using artificial intelligence and pattern recognition |
CN110110843B (en) | 2014-08-29 | 2020-09-25 | 谷歌有限责任公司 | Method and system for processing images |
DE102014118382B4 (en) | 2014-12-11 | 2020-07-02 | Carl Zeiss Meditec Ag | Optical observation device and method for operating an optical observation device. |
US9645379B2 (en) | 2014-12-29 | 2017-05-09 | Novartis Ag | Magnification in ophthalmic procedures and associated devices, systems, and methods |
US9747546B2 (en) | 2015-05-21 | 2017-08-29 | Google Inc. | Neural network processor |
US10828125B2 (en) | 2015-11-03 | 2020-11-10 | Synaptive Medical (Barbados) Inc. | Dual zoom and dual field-of-view microscope |
CN105266897B (en) | 2015-11-25 | 2018-03-23 | 上海交通大学医学院附属第九人民医院 | A kind of microsurgery navigation system and air navigation aid based on augmented reality |
WO2017142629A1 (en) | 2016-02-18 | 2017-08-24 | Google Inc. | Image classification neural networks |
US10025902B2 (en) | 2016-08-12 | 2018-07-17 | Verily Life Sciences Llc | Enhanced pathology diagnosis |
JP2019532352A (en) | 2016-08-28 | 2019-11-07 | オーグメンティクス メディカル リミテッド | System for histological examination of tissue specimens |
EP3570753A4 (en) | 2017-02-23 | 2020-10-21 | Google LLC | Method and system for assisting pathologist identification of tumor cells in magnified tissue images |
JP6915349B2 (en) * | 2017-04-04 | 2021-08-04 | コニカミノルタ株式会社 | Image processing equipment, image processing method, and image processing program |
US10552663B2 (en) * | 2017-05-02 | 2020-02-04 | Techcyte, Inc. | Machine learning classification and training for digital microscopy cytology images |
-
2017
- 2017-06-13 WO PCT/US2017/037212 patent/WO2018231204A1/en unknown
- 2017-06-13 JP JP2019553446A patent/JP6947841B2/en active Active
- 2017-06-13 US US16/495,302 patent/US11010610B2/en active Active
- 2017-06-13 CN CN201780089316.4A patent/CN110476101B/en active Active
- 2017-06-13 EP EP17913789.8A patent/EP3586181B1/en active Active
-
2021
- 2021-04-07 US US17/224,688 patent/US11594024B2/en active Active
Patent Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20160314583A1 (en) * | 2013-12-19 | 2016-10-27 | Axon Dx, Llc | Cell detection, capture and isolation methods and apparatus |
US20150213599A1 (en) * | 2014-01-25 | 2015-07-30 | Pangea Diagnostics Ltd. | Automated histological diagnosis of bacterial infection using image analysis |
WO2016130424A1 (en) * | 2015-02-09 | 2016-08-18 | The Arizona Board Of Regents Of Regents On Behalf Of The University Of Arizona | Augmented stereoscopic microscopy |
US20170045356A1 (en) * | 2015-08-14 | 2017-02-16 | Kla-Tencor Corporation | System, method and computer program product for calibration of metrology tools |
CN105652429A (en) * | 2016-03-22 | 2016-06-08 | 哈尔滨理工大学 | Automatic focusing method for microscope cell glass slide scanning based on machine learning |
Cited By (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN110727097A (en) * | 2019-12-19 | 2020-01-24 | 上海兰脉信息科技有限公司 | Pathological microscopic image real-time acquisition and analysis system, method, device and medium |
CN111474701A (en) * | 2019-12-19 | 2020-07-31 | 上海兰脉信息科技有限公司 | Pathological microscopic image real-time acquisition and analysis system, method, device and medium |
CN111474701B (en) * | 2019-12-19 | 2021-11-30 | 上海杏脉信息科技有限公司 | Pathological microscopic image real-time acquisition and analysis system, method, device and medium |
CN111160238A (en) * | 2019-12-27 | 2020-05-15 | 上海杏脉信息科技有限公司 | Microscopic image quality analysis method, training method, system, device and medium |
CN111522136A (en) * | 2020-05-12 | 2020-08-11 | 宁波蓝明信息科技有限公司 | Light filtering type augmented reality microscopic imaging system |
CN114066875A (en) * | 2021-11-25 | 2022-02-18 | 数坤(北京)网络科技股份有限公司 | Slice image processing method and device, storage medium and terminal device |
Also Published As
Publication number | Publication date |
---|---|
EP3586181B1 (en) | 2021-09-22 |
JP6947841B2 (en) | 2021-10-13 |
EP3586181A1 (en) | 2020-01-01 |
CN110476101B (en) | 2022-02-18 |
US20200097727A1 (en) | 2020-03-26 |
EP3586181A4 (en) | 2020-07-29 |
US20210224541A1 (en) | 2021-07-22 |
US11594024B2 (en) | 2023-02-28 |
WO2018231204A1 (en) | 2018-12-20 |
JP2020521946A (en) | 2020-07-27 |
US11010610B2 (en) | 2021-05-18 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN110476101A (en) | For pathological augmented reality microscope | |
EP3776458B1 (en) | Augmented reality microscope for pathology with overlay of quantitative biomarker data | |
US11927738B2 (en) | Computational microscopy based-system and method for automated imaging and analysis of pathology specimens | |
Hanna et al. | Whole slide imaging: technology and applications | |
KR20220119669A (en) | Method and system for digital staining of microscopic images using deep learning | |
CN107111874A (en) | System and method for the coexpression analysis during fraction is calculated to be immunized | |
Salido et al. | A low-cost automated digital microscopy platform for automatic identification of diatoms | |
WO2017150194A1 (en) | Image processing device, image processing method, and program | |
Rajesh | Cybernetic microbial detection system using transfer learning | |
CN108352073A (en) | Computer-implemented complex tissue image with real-time, tunable interface | |
US20040014165A1 (en) | System and automated and remote histological analysis and new drug assessment | |
Gallas et al. | Evaluation environment for digital and analog pathology: a platform for validation studies | |
Yagi et al. | Comment on “Quality evaluation of microscopy and scanned histological images for diagnostic purposes”: Are scanners better than microscopes? | |
US20200074628A1 (en) | Image processing apparatus, imaging system, image processing method and computer readable recoding medium | |
US20240153088A1 (en) | Medical image analysis apparatus, medical image analysis method, and medical image analysis system | |
Waithe et al. | Object detection networks and augmented reality for cellular detection in fluorescence microscopy acquisition and analysis | |
US20240090846A1 (en) | Autonomous healthcare visual system for real-time prevention, diagnostics, treatments and rehabilitation | |
Gil et al. | Comparison of various neural network-based models for retinal lesion analysis | |
Tran et al. | Mobile Fluorescence Imaging and Protein Crystal Recognition | |
WO2021157397A1 (en) | Information processing apparatus and information processing system | |
Hassini et al. | Investigating the Joint Amplitude and Phase Imaging of Stained Samples in Automatic Diagnosis | |
CN116997932A (en) | Information processing apparatus, information processing method, information processing system, and conversion model | |
Yagi et al. | Digital imaging in pathology: for standardization | |
Wood | A microscopy scanning system for clinical chromosome diagnostics |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
GR01 | Patent grant | ||
GR01 | Patent grant |