CN106095766A - Use selectivity again to talk and correct speech recognition - Google Patents
Use selectivity again to talk and correct speech recognition Download PDFInfo
- Publication number
- CN106095766A CN106095766A CN201610273179.7A CN201610273179A CN106095766A CN 106095766 A CN106095766 A CN 106095766A CN 201610273179 A CN201610273179 A CN 201610273179A CN 106095766 A CN106095766 A CN 106095766A
- Authority
- CN
- China
- Prior art keywords
- text
- voice
- speech recognition
- recognition engine
- search
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Granted
Links
Classifications
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/22—Procedures used during a speech recognition process, e.g. man-machine dialogue
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/30—Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data
- G06F16/33—Querying
- G06F16/332—Query formulation
- G06F16/3329—Natural language query formulation or dialogue systems
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/60—Information retrieval; Database structures therefor; File system structures therefor of audio data
- G06F16/63—Querying
- G06F16/632—Query formulation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/60—Information retrieval; Database structures therefor; File system structures therefor of audio data
- G06F16/63—Querying
- G06F16/638—Presentation of query results
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/60—Information retrieval; Database structures therefor; File system structures therefor of audio data
- G06F16/68—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually
- G06F16/683—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using metadata automatically derived from the content
- G06F16/685—Retrieval characterised by using metadata, e.g. metadata not derived from the content or metadata generated manually using metadata automatically derived from the content using automatically derived transcript of audio data, e.g. lyrics
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/951—Indexing; Web crawling techniques
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/20—Natural language analysis
- G06F40/232—Orthographic correction, e.g. spell checking or vowelisation
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/26—Speech to text systems
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/28—Constructional details of speech recognition systems
- G10L15/32—Multiple recognisers used in sequence or in parallel; Score combination systems therefor, e.g. voting systems
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L15/00—Speech recognition
- G10L15/22—Procedures used during a speech recognition process, e.g. man-machine dialogue
- G10L2015/223—Execution procedure of a spoken command
Abstract
Disclose use selectivity again to talk and correct speech recognition.Embodiment of the present disclosure includes following action: provide the first text for the display on the calculating equipment of user, first text provides from the first speech recognition engine based on the first voice from described calculating equipment, and show as search inquiry, voice correction instruction is received from described calculating equipment, the part that described voice correction instruction instruction the first text is to be corrected, the second voice is received from described calculating equipment, the second text is received from the second speech recognition engine based on described second voice, described second speech recognition engine is different from described first speech recognition engine, use the described part of the first text described in described second text instead to provide combine text, and provide combine text to show on said computing device for as correction search inquiry.
Description
Background technology
The Internet provides many to such as image file, audio file, video file and webpage
Plant the access of resource.Search system can be in response to the inquiry submitted to by user to identify that resource is also
And to provide the information about this resource in the way of useful for user.User can be by such as
Click on navigating search results to obtain information interested.
Summary of the invention
This specification relates to the speech recognition in search system, and such as speech is to text.
Embodiment of the present disclosure is generally directed to use and optionally again tells and correct voice
Identify.More specifically, embodiment of the present disclosure sensing is again told text based on (by user) and is searched
The part of rope inquiry, corrects this part of text search inquiry.In some instances, literary composition
This part of this search inquiry is corrected to provide the text search query of correction.
Usually, the creation aspect of the subject content described in this manual can include with
Realizing in the method for lower action, described action includes: provide the first text for user's
On calculating equipment show, described first text based on the first voice from described calculating equipment from
First speech recognition engine provides, and shows as search inquiry, from described calculating equipment
Receiving voice correction instruction, the correction instruction of described voice will school for indicate described first text
Positive part, receives the second voice from described calculating equipment, based on described second voice from second
Speech recognition engine receives the second text, and described second speech recognition engine is different from described first
Speech recognition engine, uses the described part of the first text described in described second text instead to carry
For combine text, and provide described combine text for as revising search inquiry described
Show on calculating equipment.Other embodiment of present aspect includes being configured to perform calculating
The correspondence system of action, device and the computer program of the method for coding in machine storage device.
The embodiment of these and other each can include in following feature with embodiment
One or more: described part includes the entirety of described first text；Described part includes little
Entirety in described first text；Described second speech recognition engine includes that described first voice is known
Other engine and the function that at least one is additional；At least one additional function described include based on
The potential text of one or more entity selection that described first text is associated is as described second
Text；Described action also includes: receive the first Search Results based on described first text, with
And provide described first Search Results for showing on said computing device；Described action is also
Including: receive the second Search Results based on described second text, and provide described second to search
Hitch fruit is for replacing described first Search Results to show on said computing device；And institute
The correction instruction of predicate sound includes at least one word in the multiple words to described first text
User selects.
The particular implementation of this theme described in this manual can be carried out thus realize
One or more advantages in advantages below.In some instances, to the part of initial query
Correction is faster and resource efficiency is higher.Such as, from User Perspective, again tell this
Part rather than again tell the entirety of initial query be faster/easier.From resource viewpoint,
Relative with initial query overall is performed speech recognition, this part is performed speech recognition needs
Less bandwidth and less computer process ability and/or memorizer.In some instances,
Being simplified alternately with the user of the equipment of calculating, such as, user spells out word rather than whole
Individual inquiry.In some instances, can be in the case of the resource not consuming increase, will be more multiple
Miscellaneous speech recognition may be used for being converted to the second voice more accurately text, such as, because
Second voice is shorter than the entirety of initial query.
The details of one or more embodiments of this theme described in this manual is below
Accompanying drawing and describe in propose.Other features, aspect and the advantage of this theme will from describe,
Accompanying drawing and claim become obvious.
Accompanying drawing explanation
Fig. 1 depicts example and searches for the example context of system offer Search Results wherein.
Fig. 2 A-2D depicts the example use case according to embodiment of the present disclosure.
Fig. 3 depicts the sample voice identification system according to embodiment of the present disclosure.
Fig. 4 depicts the instantiation procedure that can perform according to embodiment of the present disclosure.
Similar reference in various figures with refer to indicate similar element.
Detailed description of the invention
Embodiment of the present disclosure is generally directed to use selective words correction voice of putting off until some time later to know
Not.More specifically, embodiment of the present disclosure is pointed to again tells search inquiry based on user
Part corrects this part.In some embodiments, it is provided that the first text is for user
Display, this first text based on from calculate equipment user the first voice and from first voice know
Other engine provides.In some instances, this first text is the search being committed to search system
Inquiry.In some embodiments, user may indicate that the part to be corrected of the first text,
And the second voice can be provided, use the second speech recognition engine to process to provide to it
Second text.In some embodiments, this part of this first text is by this second text generation
For to provide combine text.In some instances, combine text is to be committed to repairing of search system
Positive search inquiry.
Fig. 1 depicts search system wherein and inquires about the example ring of offer Search Results based on user
Border 100.In some instances, example context 100 allows users to and one or more calculating
The service interaction that machine realizes.The computer implemented service of example can include search service, electricity
Sub-mail service, chatting service, document sharing service, calendar sharing services, photo are shared
Service, video sharing service, blog services, microblogging service, social networking service, location (
Point cognition) service, enrolled for service and grading and check service.In the example of fig. 1, retouch
Having painted search system 120, it provides search service, as used herein described in more detail.
With continued reference to Fig. 1, example context 100 include connect website 104, subscriber equipment 106,
With search system 120 network 102, network 102 such as LAN (LAN), wide area network (WAN),
The Internet or a combination thereof.In some instances, can be through wiredly and/or wirelessly communication link
Access network 102.Such as, the mobile computing device of such as smart phone can utilize cellular network
Access network 102.Environment 100 can include website 104 up to a million and subscriber equipment 106.
In some instances, it is provided that website 104 is as being associated with domain name and by one or many
One or more resources 105 of individual trust server.The website of example is with suitable machine readable
The set of the webpage that language (such as HTML (HTML)) formats, it can comprise
The programming element of text, image, content of multimedia and such as script.Each website 104 quilt
Publisher safeguards, such as, manage and/or have the entity of this website.
In some instances, resource 105 be provided by network 102 and and resource address
The data that (such as URL (URL)) is associated.In some instances, can be by net
104 resources 105 provided of standing include webpage, word-processing document and portable document format (PDF)
Document, image, video and feeding source, and other suitable digital content.Resource 105
The content of such as word, phrase, image and sound can be included, and can include embedding
Information, such as, metamessage and hyperlink and/or the instruction (such as, script) embedded.
In some instances, subscriber equipment 106 is can be asked by network 102 and be received money
The electronic equipment in source 105.The subscriber equipment 106 of example includes to be sent by network 102
With receive the personal computer of data, laptop computer and mobile computing device, such as,
Smart phone and/or tablet computing device.As used in whole document, term mobile computing
Equipment (" mobile device ") refers to the subscriber equipment being configured to be communicated by mobile communications network.
Smart phone (such as realizing the phone by internet communication) is an example of mobile device.With
Family equipment 106 can perform user's application (such as web browser) to contribute to by network 102
Send and receive data.
In some instances, in order to contribute to the search of resource 105, search system 120 is passed through
Creep and index the resource 105 provided on website 104 to identify resource 105.About resource
The data of 105 can index based on the resource corresponding to these data.Resource 105 indexed also
And the copy cached alternatively is stored in search index 122.
Search inquiry 109 is committed to search system 120 by subscriber equipment 106.In some examples
In, subscriber equipment 106 can include one or more input pattern.The pattern of example can be wrapped
Include keyboard, touch screen and/or mike.Such as, user can use keyboard and/or touch screen
Typewrite in the search query.As another example, user can say search inquiry, user
Voice is captured by mike, and processes to provide search inquiry by speech recognition.
In response to receiving search inquiry 109, search system 120 access search index 122 with
Identify relevant to search inquiry 109 (such as there is at least one for search inquiry 109 minimum
Specific relevance scoring) resource 105.Search system 120 identifies resource 105, and generation includes
Identify that the Search Results of the Search Results 112 of resource 105 shows 111, and Search Results is shown
Show that 111 are back to subscriber equipment 106.In an example context, Search Results shows and can wrap
Include one or more webpage, such as, one or more result of page searching.In some instances,
Can be based on providing webpage with the web document that any suitable machine-readable language is write.
It is contemplated, however, that, embodiment of the present disclosure can include other suitable display types.Such as,
Can be in the display generated by the application performed on the computing device and/or by operating system
The display that (such as Mobile operating system) generates provides Search Results.In some instances, permissible
Search Results is provided based on any suitable form (such as, Javascript-html, plain text).
Search Results 112 is the data generated by search system 120, and it identifies specific search
The resource 105 that inquiry responds, and include the link pointing to this resource 105.Searching of example
Hitch fruit 112 can include web page title, from webpage extract text fragments or image section,
URL with webpage.In some instances, can retrieve from resource data store storehouse and searching
The data provided in hitch fruit 112.Such as, search system 120 can provide Search Results to show
Showing 111, it shows Search Results 112.In some instances, can be with from resource data store
The information that storehouse provides is inserted Search Results and is shown 111, such as web page title, the literary composition extracted from webpage
This fragment or image section.
In some instances, the data of the search inquiry 109 for submitting to during user conversation
It is stored in data repository, such as history data store storehouse 124.Such as, search system 120
Can by search inquiry be stored in history data store storehouse 124.
In some instances, it is intended that provide in response to each search inquiry 109 is responded
Search Results 112 and the selection data of action taked also are deposited (such as, by search system 120)
Storage is in history data store storehouse 124.These actions can include Search Results 112 whether by
Select, such as, click on pointer or hovering.For each selection of Search Results 112, choosing
Select data and can also include identifying the number of the search inquiry 109 for its offer Search Results 112
According to.
In some embodiments, user can submit search inquiry 109 to based on voice.Such as,
User can face toward the microphone talk of subscriber equipment 106, and the voice of user can conduct
Speech data (the also referred to as first voice) is captured in the data file.In some instances, it is provided that
Speech data is as the search inquiry 109 being committed to search system 120 by network 102.One
In a little embodiments, speech data can be provided to speech recognition system 130 by search system 120.
In some instances, speech recognition system 130 can process speech data to provide text.Example
As, speech recognition system 130 can use speech to text engine (the also referred to as first speech recognition
Engine) process speech data to provide text.In some instances, speech recognition system 130
Being thered is provided by text to search system 120, the text is processed by search system 120 as search inquiry
To provide Search Results 112.In some instances, it is provided that search inquiry is for user
Display, such as, together with Search Results.By this way, user can be seen how to identify
Voice, and the search inquiry that Search Results is based on.
Although search system 120 and speech recognition system 130 are depicted as point in the example of fig. 1
Vertical system, it should be appreciated that search system 120 and speech recognition system 130 can be included
In same system, such as, search system 120 can include speech recognition system therein
130。
According to embodiment of the present disclosure, user can correct a part for search inquiry, such as
One or more words.In some instances, user may determine that a part for search inquiry is
Incorrect, such as, the speech recognition of this part is inaccurately identified to the voice of user,
And may indicate that this part is intended to correction.Such as, user can select to be used user to set
This part of standby 106 these search inquiries displayed to the user that.In some embodiments, user
Again facing to the microphone talk of subscriber equipment 106, and the voice of user can be as part
Speech data (the also referred to as second voice) is captured in the data file.In some instances, it is provided that
These part of speech data are as the speech again of this part of search inquiry, and pass through network 102
It is committed to search system 120.In some embodiments, search system 120 can be by this part
Speech data provides to speech recognition system 130, and can include and again the saying of phonetic entry
Talk about the instruction of these corresponding part of speech data.In some instances, speech recognition system 130
These part of speech data can be processed to provide review text.Such as, speech recognition system 130
Speech can be used to process this part of speech to text engine (the also referred to as second speech recognition engine)
Data.
In some embodiments, different for processing the first speech recognition engine of speech data
In the second speech recognition engine for processing part of speech data.In some instances, relatively
In the second speech recognition engine, the first speech recognition engine can be used for utilizing the strictest
Accuracy threshold the processing the most rapidly of speech data is provided.Such as, the first speech recognition
Engine can use less resource, such as, processor, memorizer, and can ratio second
Speech recognition engine more quickly provides result.In some instances, know relative to the first voice
Other engine, it is more accurate that the second speech recognition engine can be used to provide for part of speech data
Process, such as, tightened up accuracy threshold.Such as, the second speech recognition engine is permissible
Use more resource, such as, processor, memorizer, and can provide than the first voice
Identify the more accurate result of engine.In some instances, although the second speech recognition engine is than
One speech recognition engine is more complicated, and may consume more resource, but is to provide result
Speed can be similar.Such as, and as used herein described in more detail, the first language
Sound identification engine can process the voice more than the second speech recognition engine, such as, second
Speech recognition engine the most only processes the part of Original submission voice.
In some embodiments, review text is provided to searching for system by speech recognition system 130
System 120, search system 120 provides, based on search inquiry and this review text, the search inquiry revised.
Such as, search system 120 uses this part of the text instead search inquiry revised to provide correction
Search inquiry.Search system 120 processes the search that the search inquiry revised has been revised with offer
As a result 112.In some instances, it is provided that the search inquiry of correction for displaying to the user that,
Such as, together with Search Results.By this way, user it can be seen that how voice is corrected,
And the search inquiry that Search Results is based on.
Fig. 2 A-2D depicts the example use case according to embodiment of the present disclosure.Specifically
With reference to Fig. 2 A, user 200 uses calculating equipment 202 to scan for.More specifically, user 200
Use calculating equipment 202 that search inquiry is committed to search system, such as, the search system of Fig. 1
System 120, search system provides Search Results to display to the user that on calculating equipment 202.
In the example described, it is provided that calculating equipment 202 is as mobile computing device, such as, intelligence
Can phone, flat board.It will be appreciated, however, that the calculating equipment of any suitable type can be used
Realize embodiment of the present disclosure, such as, desktop computer, laptop computer, all
Wearable computing equipment such as intelligent watch.
In the example described, calculating equipment 202 shows that user 200 can use it to submit to
Search inquiry and the search interface 204 of reception Search Results.The search interface 204 of example includes searching
Rope frame 206, search button 208, search-results region 210 and microphone button 212.One
In a little examples, the search inquiry being submitted to search system shows in search box 206, and
Obtained Search Results shows in search-results region 210.In some instances, user
200 can select search button 208 to submit to search inquiry to search system to start.Show at some
In example, search inquiry is automatically submitted to search system, and do not require user select search for by
Button 208.
According to embodiment of the present disclosure, user 200 provides the first voice 220 as to search
The input at interface 204.In the example described, the first voice 220 includes that inquiry [shows me
The picture of Maradona].In some instances, calculating equipment 202 uses mike record first
Voice 220, and generate the one or more numbers stored by the first voice 220 as voice data
According to file (such as .wav file .mp3 file).In some embodiments, equipment 202 is calculated
First voice 220 is provided to search system.In some instances, by the first voice 220 certainly
There is provided to search system, such as, it is not required that user selects search button 208 dynamicly.Show at some
In example, after user has said the entirety of the first voice 220, the first voice 220 is passed
Deliver to search system.Such as, search system 120 receives the first voice 220 in a request
Entirety.In some instances, the part of the first voice 220 is sent to when they are uttered
Search system.Such as, when each part of the first voice 220 is uttered, search system this
A little parts (such as word).
In some embodiments, and as used herein described in more detail, the first voice
220 are processed to provide the first literary composition by speech recognition system (speech recognition system 130 of such as Fig. 1)
This (such as text search query).Such as, voice data can be provided to voice knowledge by search system
Other system is for process.In some instances, speech recognition system uses the first speech recognition
Engine processes the first voice 220 to provide the first text.
In some embodiments, it is provided that the first text is for calculating display on equipment 202.
In some instances, search system receives the first text and by the first literary composition from speech recognition system
Originally calculating equipment 202 it is sent to.In some instances, the first text shows as search inquiry 222
Show in search box 206.In some instances, the first text is looked into by search system as search
Inquiry process to provide Search Results, at least some therein be sent to calculating equipment 202 and
It is displayed in search-results region 210 as Search Results 224.In some instances, exist
Search inquiry 222 before it, is shown to use by calculating equipment 202 Search Results 224 and display
Family.Such as, the first text can and show in search box 206 as search inquiry 222,
And can subsequently and show Search Results 224, such as, in the display of search inquiry 222 with search
Time lag is there is between the display of hitch fruit 224.
In the example described, search inquiry 222 is provided as [showing me the figure of Madonna
Sheet].Accordingly, word [Maradona] is identified as [Madonna] improperly by speech recognition system.
Therefore, Search Results 224 includes singer-composer, actress and producer Madonna
Image.That is, the search inquiry 222 that Search Results 224 is based on is incorrect, because its
[showing me the picture of Maradona] should be provided as.
According to embodiment of the present disclosure, user 200 can correct the part of search inquiry 222
To provide the search inquiry revised, the search inquiry of described correction can be committed to search system.
In some embodiments, user 200 can provide voice correction instruction, and its instruction search is looked into
Ask the part that 222 (the such as first texts) are to be corrected.Such as, user can select search inquiry 222
One or more words to be corrected.In some instances, user 200 can be in this part
Upper percussion, it may for example comprise the calculating equipment 202 of touch panel device.
Fig. 2 B depicts the part 230 to be corrected of search inquiry 222.In the example described
In, user 200 selects word [Madonna] to be corrected.
Fig. 2 C depicts user 200 and again tells part 230.In the example described, use
Family 200 provides the second voice 232 as the input to search interface 204.In showing of being described
In example, the second voice 232 includes [Maradona].In some instances, user 200 can spell
Write out part 230 to be corrected.In the example of Fig. 2 A-2C, user 200 can spell out
Second text 232, such as, " M-A-R-A-D-O-N-A ".In some instances, equipment is calculated
202 use mike record the second voice 232, and generate the second voice 232 as audio frequency
One or more data files of data storage, such as .wav file .mp3 file.At some
In embodiment, the second voice 232 is provided to search system by calculating equipment 202.At some
In example, the second voice 232 is automatically provided to search system, such as, it is not required that user
Select search button 208.
In some embodiments, and as used herein described in more detail, by the second language
The instruction (also referred to as correcting instruction) that sound 232 is corresponding with part to be corrected with the second voice 232
There is provided to speech recognition system.In some instances, the second voice 232 is by speech recognition system
Process to provide the second text.In some instances, and also respond to correction instruction, voice
Identification system uses the second speech recognition engine to process the second voice 232 to provide the second text.
In some instances, and as used herein described in more detail, the second speech recognition engine
It is different from the first speech recognition engine.
According to embodiment of the present disclosure, provide combine text based on the first text and the second text.
In some embodiments, this part of the first text, such as in the example described, will
[Madonna] from the first text suppression and by second text instead of such as [Maradona] to carry
For combine text.In some embodiments, search system receives second from speech recognition system
Text and provide combine text based on the first text and the second text.
Referring now to Fig. 2 D, and in some embodiments, it is provided that combine text for
Display on calculating equipment 202.In some instances, combine text is sent to by search system
Calculating equipment 202.In some instances, combine text searching as correction in search box 206
Rope inquiry 222' shows.In some instances, search system using combine text as search inquiry
Processing to provide Search Results, its at least some is sent to calculating equipment 202 and as searching
Hitch fruit 240 shows in search-results region 210.In some instances, at the equipment of calculating
202 and before showing Search Results 240, the search inquiry 222' of correction is shown to user.Example
As, can show in search box 206 by the search inquiry 222' using combine text and as correction,
And can subsequently and show Search Results 240, such as, aobvious at the search inquiry 222' revised
Show and can there is time lag between the display of Search Results 240.
In some embodiments, and such as describe in the example of Fig. 2 A-2D, Yong Huxuan
Select the part to be corrected of text, and say this correction, such as, select [Madonna] and say
Go out [Maradona] such as the second voice.In some instances, to correct in response to text
Part user select, automatically activate calculating equipment mike.In some instances,
User selects the part to be corrected of text, and user activates mike, such as, selects wheat
Gram wind button 212.
In some embodiments, replace again tell this part to be corrected, user tell to
This part to be corrected provides the phrase of context.Such as, and continue the example of Fig. 2 A-2D,
Replacing saying [Maradona] or [M-A-R-A-D-O-N-A], described above, user is permissible
Say [my meaning is that football player], such as, as the second voice, it is to correct
Part provide context.In some instances, this context can be used in this part
Make between potential correction and distinguishing, as used herein described in more detail.
In some embodiments, part to be corrected is not selected clearly by user.At figure
In the example of 2A-2D, user selects word [Madonna], such as by touching at the equipment of calculating
Touch the upper percussion [Madonna] of screen.In some instances, and replacing selection part, user is permissible
There is provided the second voice to provide the context of this correction, process this second voice and to correct to determine
Part, and provide for correcting the second text of this part.Such as, and continue Fig. 2 A-2D
Example, the second voice can include [no, my meaning is that football player], [I
The meaning is Maradona], [changing Madonna into Maradona] or [delete Madonna].
Accordingly, the second voice provides context to select part to be corrected, and may be used for right
Make between the potential correction of this part and distinguishing, as used herein described in more detail.One
In a little examples, user activated mike before providing the second voice, such as, select mike to press
Button 212.
In some embodiments, a part of to be corrected in the case of automatically activate Mike
Wind.Such as, and as discussed above, in response to the user's selection to part to be corrected,
Can automatically activate mike.In some instances, search inquiry be displayed to user it
After can automatically activate mike.By this way, user can provide the second voice, and
Do not require that first user activates mike.
Fig. 3 depicts the sample voice identification system 300 according to embodiment of the present disclosure.Show
Example speech recognition system 300 includes the first speech recognition engine 302 and the second speech recognition engine
304.In some instances, speech recognition system 300 receives input data 306, uses first
Speech recognition engine 302 or the second speech recognition engine 304 process input data 306, and carry
For output data 308.In some instances, input data 306 are provided to language from search system
Sound identification system 300, and speech recognition system 300 by output data provide to the system of searching for.
In some embodiments, input data 306 include being provided to search system by user
The voice data (speech data) of the first voice.With reference to the example of Fig. 2 A-2D, input data 306
The audio file of the first voice [showing me the picture of Maradona] can be included.In some examples
In, the first speech recognition engine 302 processes input data 306 to provide output data 308.?
In some embodiments, output data 308 are the first texts based on voice data.With reference to figure
The example of 2A-2D, output data 308 can include comprising such as and [show me the figure of Madonna
Sheet] the text of the first text.
In some instances, the first text can be by the first speech recognition engine based on potential text
The incompatible selection of collection.In some instances, based on the respective confidence being associated with potential text
Mark and from the set of potential text, select the first text.Such as, and use Fig. 2 A-2D
Example, the first voice can be processed to provide [showing me the picture of Madonna] and [show me
The picture of Maradona].In this example, [picture of Madonna is shown me] and the first confidence
Degree scoring (such as 95%) is associated, and [showing me the picture of Maradona] and the second confidence
Degree scoring (such as 92%) is associated.It was determined that the first confidence score is more than the second confidence level
Scoring.Therefore, select [showing me the picture of Madonna] as the first text.In other words,
The potential text conduct in the set of potential text with the highest confidence score can be selected
First text.
In some embodiments, input data 306 include being provided to search system by user
The voice data (part of speech data) of the second voice, and correction instruction.With reference to Fig. 2 A-2D
Example, input data 306 can include the audio file of the second voice [Maradona], and
Correction instruction.In some instances, the second speech recognition engine 304 processes input data 306
To provide output data 308.Such as, correction instruction is included in response to input data 306, by the
Two speech recognition engines 304 are used for processing this voice data.In some embodiments, output
Data 308 are the second texts based on this voice data.With reference to the example of Fig. 2 A-2D, output
Data 308 can include the text comprising such as second text of [Maradona].
In some embodiments, the first speech recognition engine 302 is different from the second speech recognition
Engine 304.In some instances, relative to the second speech recognition engine 304, the first voice is known
The strictest accuracy threshold that other engine 302 can be used for is to provide voice number
According to relatively process more rapidly.Such as, relative to the second speech recognition engine 304, the first language
Sound identification engine 302 can realize speech recognition algorithm less complex, more coarse.With this
The mode of kind, compared to the second speech recognition engine 304, the first speech recognition engine 302 can phase
To more quickly providing result and the resource of less such as processor, memorizer can be used.
In some instances, relative to the first speech recognition engine 302, the second speech recognition engine 304
Can be used to provide for processing more accurately part of speech data, the most tightened up is accurate
Degree threshold value.Such as, relative to the first speech recognition engine 302, the second speech recognition engine 304
More complicated, more accurate speech recognition algorithm can be realized.By this way, if processed
If identical voice data, compared to the first speech recognition engine 304, the second speech recognition is drawn
Hold up 304 result will be the most more slowly provided and more such as processor, storage can be used
The resource of device,.
In some embodiments, although the second speech recognition engine 302 is to know than the first voice
Other engine 304 is more complicated, but is to provide the speed of result and for providing the resource of result
Amount can be similar.Such as, and as used herein described in more detail, the first voice
Identify that engine 302 can process ratio the second more voice data of speech recognition engine 304,
Such as, the second speech recognition engine 304 the most only processes the part of Original submission voice.Ginseng
According to the example of Fig. 2 A-2D, the first speech recognition engine 302 processes text and [shows me Maradona
Picture], and the second speech recognition engine 304 only processes text [Maradona].
Described above, the first speech recognition engine is different from the second speech recognition engine.?
In some examples, the second speech recognition is different, because the second speech recognition includes the first language
Sound identification engine, and for processing the additional function of the second voice and/or different parameters.
It is to say, and in some instances, the second speech recognition engine be the first speech recognition with
And for processing the additional function of the second voice and/or different parameters.
In some embodiments, process the set with the potential text of offer of second voice, permissible
The second text is determined according to it.In some instances, from latent to provided based on the second voice
The selection of the set of text is got rid of and is included in the text in the first text.Such as, to latent
The part to be corrected of text is got rid of in the selection of the set of text.Continue showing of Fig. 2 A-2D
Example, the second voice can include [Maradona], can process it and include to provide
The set of the potential text of [Madonna] and [Maradona], such as.Because [Madonna] is
It is included in the such as first text and is selected to for correcting, so from for the second text
Selection in get rid of [Madonna].Therefore, select potential text [Maradona] as potential literary composition
This.
In some embodiments, and in response to the second voice, can process and be used for determining
The potential text of one text is so that corresponding entity is associated with each other.In some instances, can locate
Manage the second voice and one or more entity can be associated with it.In some embodiments,
The entity being associated with the second voice can with and the set of potential text in latent in the text
Each entity being associated compares.In some instances, select that there is at least one real
The potential text of body, described entity with and the entity that is associated of the second voice match.
In an illustrative manner, and use the example of Fig. 2 A-2D, can process the first voice with
There is provided [showing me the picture of Madonna] and [showing me the picture of Maradona] as potential literary composition
Potential text in this set.In some instances, [picture of Madonna is shown me]
Can be associated with entity [singer], [actress], [producer] and [musician] etc., and [give
I sees the picture of Maradona] can be with entity [athlete], [football player] and [play soccer
] etc. be associated.In some instances, the second voice is provided as that [my meaning is that football
Athlete], and can be associated with entity [physical culture], [football] and [football player].Can
To determine, potential text and the second voice jointly have entity [football player].Therefore, may be used
To select potential text [showing me the picture of Maradona] as the text of correction, such as, combine
Text.
In some embodiments, multiple entities and information associated there can be as structures
Data are stored in knowledge graph.In some instances, knowledge graph includes multiple node and at node
Between limit.In some instances, node on behalf entity, and limit represents the pass between entity
System.In some instances, can be based on the structured data based on territory, type and character
Scheme and knowledge graph is provided.In some instances, territory include sharing one of NameSpace or
Multiple types.In some instances, it is provided that NameSpace as the catalogue of the object of unique name,
Wherein each object in NameSpace has unique name, such as, and identifier.Show at some
In example, type represents the "Yes" relation about topic, and for preserving the set of character.
In some instances, topic represents such as people, place or the entity of things.In some instances,
Each topic can have one or more type associated there.In some instances, property
" having " relation that matter is associated with topic and defines between this topic and value of this character.
In some instances, the value of this character can include another topic.
Fig. 4 depicts the instantiation procedure 400 that can perform according to embodiment of the present disclosure.
Instantiation procedure 400 can such as be realized by the example context 100 of Fig. 1, such as, searches for system
120 and/or speech recognition system 130.In some instances, instantiation procedure 400 can be by using
One or more computer executable programs performed by one or more calculating equipment provide.
Receive the first speech data (402).Such as, search system (the search system of such as Fig. 1
120) the first speech data is received from subscriber equipment.Receive the first text based on the first speech data
(404).Such as, search system is from speech recognition system (speech recognition system 130 of such as Fig. 1)
Receive the first text.In some instances, the first speech data is provided to voice by search system
Identification system.There is provided the first text for display (406).Such as, search system will be used for showing
The first text shown is sent to subscriber equipment, such as, is being searched as search inquiry by the first text
The search box at rope interface shows.Determine whether the correction (408) indicated the first text.
Such as, search system can receive correction instruction from subscriber equipment.In some instances, permissible
User in response to subscriber equipment selects the part of the first text to provide correction instruction.At some
In example, follow-up phonetic entry can be provided to provide correction instruction in response to user.If
Do not receive correction instruction, then provide Search Results for display (410).Such as, search system
System may determine that the Search Results responding the first text as search inquiry, and can
To provide this Search Results for display.
If receiving correction instruction, then second speech data (412).Such as, search system from
Subscriber equipment receives second speech data.The second text (414) based on second speech data.Example
As, search system is from speech recognition system the second text.In some instances, search system will
Second speech data provides to speech recognition system.There is provided combine text for display (416).
Such as, the combine text being used for display is sent to subscriber equipment by search system, such as will combination
Text shows in the search box of search interface as the search inquiry revised.In some instances,
Search system provides combine text based on the first text and the second text.Such as, this first text
Part to be corrected can be by the second text instead.In some instances, this first text
This part is the entirety of the first text.In some instances, this part of this first text is less than
The entirety of the first text.There is provided Search Results for display (410).Such as, search system can
To determine the Search Results that the combine text as the search inquiry revised is responded, and
This Search Results can be provided for display.
The instantiation procedure 400 of Fig. 4 is included in and has been provided for the first text (such as, as search
Inquiry) for display after, or having been provided for combine text (such as, as having revised
Search inquiry) for display after, it is provided that Search Results is for display.It is contemplated, however, that search
Fruit relatively simultaneously can show hitch with the display of the first text or combine text.Such as, exist
In some embodiments, the first text and Search Results based on the first text can be determining
No it is corrected showing before to the first text.
The embodiment of the subject content described in this manual and operation can be included in this
In the Fundamental Digital Circuit of the structure disclosed in description and their equivalent structures or in calculating
In machine software, firmware or hardware, or realize in the combination of one or more of which.?
The embodiment of the theme described in this specification can use one or more computer program,
I.e. one or more modules of computer program instructions realize, the one or more computer
Program encodes for being performed by data processing equipment or for controlling on computer-readable storage medium
The operation of data processing equipment.Alternatively or in addition, programmed instruction can be coded in manually
On the transmitting signal generated, electricity, light or the electromagnetic signal that such as machine generates, described signal
It is generated with to for performing for by data processing equipment to the transmission of suitable acceptor device
Information encode.Computer-readable storage medium can be or be included in computer-readable storage
Equipment, computer-readable memory substrate, random or serial access memory array or equipment or
In the combination of one or more of which.Additionally, when computer-readable storage medium is not to propagate letter
Number time, computer-readable storage medium can be in manually generated transmitting signal coding computer
The source of programmed instruction or destination.Computer-readable storage medium can also be or be included in one or
Multiple discrete physical assemblies or medium (such as, multiple CD, dish or other storage device)
In.
The operation described in this manual may be implemented as by data processing equipment being stored in
Data on one or more computer-readable storage part equipment or held from the data in other sources
The operation of row.
Term " data processing equipment " is contained all types of devices for processing data, is set
Standby and machine, including programmable processor by way of example, computer, system on chip,
Or aforesaid multiple or combination.This device can include dedicated logic circuit, and such as, FPGA is (existing
Field programmable gate array) or ASIC (special IC).In addition to hardware, this device also may be used
To include the code performing environment creating the computer program for being discussed, such as, constitute
Ring when processor firmware, protocol stack, data base management system, operating system, cross-platform operation
The code of the combination of border, virtual machine or one or more of which.This device and execution ring
Border can realize various different computation model architecture, such as web services, distributed meter
Calculate and grid computing infrastructures.
Computer program (also referred to as program, software, software application, script or code) is permissible
Write by programming language in any form, including compilation or interpretative code, illustrative or process
Language, and it can be disposed in any form, including as stand-alone program or as module,
Assembly, subroutine, object or be suitable for other unit used in a computing environment.Calculate
Machine program can but need not, corresponding with the file in file system.Program can be stored
Part (such as, storage in marking language document at the file keeping other programs or data
One or more scripts) in, in the single file being exclusively used in discussed program, or many
Individual coordinated files (such as, stores the file of one or more module, subprogram or code section)
In.Computer program can be deployed, with on a computer or be positioned at a website
Place or by across multiple websites distribution and by multiple computers of interconnection of telecommunication network on perform.
The process described in this manual and logic flow can be by performing one or more computers
One or more programmable processors of program perform, with by operating for input data
And generate output to perform action.Described process and logic flow can also be (existing by such as FPGA
Field programmable gate array) or the dedicated logic circuit of ASIC (special IC) perform, and
It is (special integrated that device can also be implemented as such as FPGA (field programmable gate array) or ASIC
Circuit) dedicated logic circuit.
By way of example, the processor being adapted for carrying out computer program includes, general micro-process
Both device and special microprocessor, and any kind of digital computer any one or many
Individual processor.Generally, processor will from read only memory or random access memory or the two connect
Receive instruction and data.The element of computer can include the place for performing the action according to instruction
Reason device, and for storing one or more memory devices of instruction and data.Generally, calculate
Machine sets also including or being operatively coupled for the one or more a large amount of storage parts storing data
Standby, with receive from it data or to its shift data, or the two, such as, disk, magneto-optic disk,
Or CD.But, computer need not have such equipment.Additionally, computer can be by
It is embedded in another equipment, such as, mobile phone, personal digital assistant (PDA), mobile sound
Frequency or video player, game console, global positioning system (GPS) receptor or portable
Storage device (such as, USB (universal serial bus) (USB) flash driver), names a few.It is suitable for
Equipment in storage computer program instructions and data includes the non-volatile memories of all of form
(such as, device, medium and memory devices, include semiconductor memory devices in an illustrative manner
EPROM, EEPROM and flash memory device)；Disk (such as, internal hard drive or can
Mobile dish)；Magneto-optic disk；With CD ROM and DVD-ROM dish.Processor and memorizer can
With by supplemented or be incorporated in dedicated logic circuit.
Mutual in order to provide with user, the embodiment of the theme described in this manual can
To be implemented in the display device (such as CRT (cathode ray having for displaying to the user that information
Pipe) or LCD (liquid crystal display) monitor), and user can be by it to computer offer input
Keyboard and instruction equipment (such as mouse or trace ball) computer on.Other classes can also be provided
It is mutual that the equipment of type provides with user；Such as, it is provided that can be any to the feedback of user
The sensory feedback of form, such as, visual feedback, auditory feedback or sense of touch feedback；And come
Can be received in any form from the input of user, including acoustics, voice or sense of touch
Input.Additionally, computer can be sent document by the equipment used to user and be connect from it
Message in-coming shelves come mutual with user；Such as, by response to the request from web browser by net
Page sends to this web browser on the client device of user.
The embodiment of this theme described in this manual can be implemented in and include rear end group
Part (such as data server) or include middleware component (such as application server) or bag
Including front end assemblies (such as can be with the embodiment party of the theme described in this manual by its user
What formula was mutual has the client computer of graphic user interface or Web browser) or one or
In any combination of calculating system of multiple such rear ends, middleware or front end assemblies.System
Assembly can be interconnected by any form of such as communication network digital data communications or medium, example
Such as communication network.The example of communication network include LAN (" LAN ") and wide area network (" WAN "),
Internet (such as, the Internet) and peer-to-peer network (such as, self-organizing peer-to-peer network).
Calculating system can include client and server.Client and server is typically each other
Away from and generally by communication network mutual.The relation of client and server by means of
Run on corresponding computer and have each other client-server relation computer program and
Produce.In some embodiments, data (such as html page) are sent to visitor by server
Family end equipment is (such as, for the user video data mutual with client device and connecing from it
Receive the purpose of user's input).Data (the knot that such as, user is mutual generated at client device
Really) can receive from client device at server.
Although this specification comprises many specific embodiment details, but these should be by
It is considered as the restriction of the scope that any embodiment of this disclosure maybe can be claimed, but
It is considered as the description to the feature specific to example embodiment.In this manual with discrete enforcement
Feature described by the context of mode, it is also possible to realize in the combination of single embodiment.
On the contrary, the various features described in the context of single embodiment can also be real discretely
In present multiple embodiment, or in any suitable sub-portfolio.Although additionally, above may be used
Can describe feature as working with some combination, and also be even initially so to require to protect
Protect, but can be in some cases from one or more features of claimed combination
Remove from this combination, and this claimed combination can point to the change of sub-portfolio or sub-portfolio
Change.
Similarly, although operation is described the most in a particular order, but this should be by
It is understood as require that such operation with shown specific order or should be held in a subsequent order
OK, or all illustrated operations should be performed to realize desired result.In certain situation
Under, multitask and parallel processing can be favourable.Additionally, in embodiments described above
In the separation of various system components be understood not to require in all of embodiment
Such separation, and it is to be understood that described program assembly and system can be generally at lists
The software product of one is integrated or is packaged in multiple software product.
Therefore, it has been described that the particular implementation of this theme.Other embodiments are following
In the range of claim.In some cases, the action recorded in the claims can be with
Different orders performs and still realizes desired result.Additionally, describe in the accompanying drawings
Process not necessarily requires the most consecutive or sequential shown order to realize desired knot
Really.In some embodiments, multitask and parallel processing can be favourable.
Claims (32)
1. a computer implemented method, described method includes:
The first text is provided to show on the calculating equipment of user, based on from described calculating
The first voice that equipment receives, described first text is provided from the first speech recognition engine, and
And be shown as search inquiry；
Receiving voice correction instruction from described calculating equipment, the correction instruction of described voice is used for indicating
Part to be corrected in described first text；
The second voice is received from described calculating equipment；
The second text is received from the second speech recognition engine based on described second voice, described
Two speech recognition engines are different from described first speech recognition engine；
Use the described part of the first text described in described second text instead, to provide combination literary composition
This；And
There is provided described combine text, for as revising search inquiry on said computing device
Display.
Method the most according to claim 1, wherein, described part includes described first literary composition
This entirety.
Method the most according to claim 1, wherein, described part includes less than described
The entirety of one text.
4. according to the method according to any one of claim 1-3, wherein, described second voice
Identify that engine includes described first speech recognition engine and the function that at least one is additional.
Method the most according to claim 4, wherein, at least one additional function described
Including: based on the one or more entities being associated with described first text, select potential literary composition
This is as described second text.
6., according to the method according to any one of claim 1-3, also include:
Receive the first Search Results based on described first text；And
There is provided described first Search Results, for showing on said computing device.
Method the most according to claim 6, also includes:
Receive the second Search Results based on described second text；And
There is provided described second Search Results, for replacing described first on said computing device
Search Results shows.
8. according to the method according to any one of claim 1-3, wherein, described voice correction
Instruction includes that the user of at least one word in described multiple words to the first text selects.
9. a computer implemented method, described method includes:
The first text is provided to show on the calculating equipment of user, based on from described calculating
The first voice that equipment receives, described first text is provided from the first speech recognition engine, and
And be shown as search inquiry；
Receiving voice correction instruction from described calculating equipment, the correction instruction of described voice is used for indicating
Part to be corrected in described first text；
The second voice is received from described calculating equipment；
The second text is received from the second speech recognition engine based on described second voice, described
Two speech recognition engines are different from described first speech recognition engine；
Use the described part of the first text described in described second text instead, to provide combination literary composition
This；And
There is provided described combine text, for as revising search inquiry on said computing device
Display.
Method the most according to claim 9, wherein, described part includes described first
The entirety of text.
11. methods according to claim 9, wherein, described part includes less than described
The entirety of the first text.
12. according to the method according to any one of claim 9 to 11, wherein, and described second
Speech recognition engine includes described first speech recognition engine and the function that at least one is additional.
13. methods according to claim 12, wherein, at least one additional merit described
Can include: based on the one or more entities being associated with described first text, select potential
Text is as described second text.
14., according to the method according to any one of claim 9 to 11, also include:
Receive the first Search Results based on described first text；And
There is provided described first Search Results, for showing on said computing device.
15. methods according to claim 14, wherein said operation also includes:
Receive the second Search Results based on described second text；And
There is provided described second Search Results, for replacing described first on said computing device
Search Results shows.
16. according to the method according to any one of claim 9 to 11, wherein, and described voice
Correction instruction includes user's choosing of at least one word in the multiple words to described first text
Select.
17. 1 kinds of computer implemented systems, including
For providing first text device for showing on the calculating equipment of user, based on
The first voice received from described calculating equipment, described first text is from the first speech recognition engine
It is provided, and is shown as search inquiry；
For receiving the device of voice correction instruction from described calculating equipment, the correction of described voice refers to
Show for indicating part to be corrected in described first text；
For receiving the device of the second voice from described calculating equipment；
For receiving the dress of the second text from the second speech recognition engine based on described second voice
Putting, described second speech recognition engine is different from described first speech recognition engine；
For using the described part of the first text described in described second text instead to provide combination
The device of text；And
For providing described combine text for as revising search inquiry at described calculating equipment
The device of upper display.
18. systems according to claim 17, wherein, described part includes described first
The entirety of text.
19. computer implemented systems according to claim 17, wherein, described part
Including the entirety less than described first text.
20. according to the computer implemented system according to any one of claim 17 to 19,
Wherein, described second speech recognition engine include described first speech recognition engine and at least one
Additional function.
21. computer implemented systems according to claim 20, wherein, described at least
One additional function includes: based on the one or more entities being associated with described first text,
Select potential text as described second text.
22. according to the system according to any one of claim 17 to 19, including:
For receiving the device of the first Search Results based on described first text；And
For providing described first Search Results for the dress shown on said computing device
Put.
23. computer implemented systems according to claim 22, wherein, described operation
Also include:
For receiving the device of the second Search Results based on described second text；And
For providing described second Search Results for replacing described on said computing device
The device that one Search Results shows.
24. according to the computer implemented system according to any one of claim 17 to 19,
Wherein, described voice correction instruction includes at least one in the multiple words to described first text
The user of word selects.
25. 1 kinds of computer implemented systems, including
For providing first text device for showing on the calculating equipment of user, based on
The first voice received from described calculating equipment, described first text is from the first speech recognition engine
It is provided, and is shown as search inquiry；
For receiving the device of voice correction instruction from described calculating equipment, the correction of described voice refers to
Show for indicating part to be corrected in described first text；
For receiving the device of the second voice from described calculating equipment；
For receiving the dress of the second text from the second speech recognition engine based on described second voice
Putting, described second speech recognition engine is different from described first speech recognition engine；
For using the described part of the first text described in described second text instead to provide combination
The device of text；And
For providing described combine text for as revising search inquiry at described calculating equipment
The device of upper display.
26. systems according to claim 25, wherein, described part includes described first
The entirety of text.
27. computer implemented systems according to claim 25, wherein, described part
Including the entirety less than described first text.
28. according to the computer implemented system according to any one of claim 25 to 27,
Wherein, described second speech recognition engine include described first speech recognition engine and at least one
Additional function.
29. computer implemented systems according to claim 28, wherein, described at least
One additional function includes: based on the one or more entities being associated with described first text,
Select potential text as described second text.
30., according to the system according to any one of claim 25 to 27, also include:
For receiving the device of the first Search Results based on described first text；And
For providing described first Search Results for the dress shown on said computing device
Put.
31. computer implemented systems according to claim 30, wherein, described operation
Also include:
For receiving the device of the second Search Results based on described second text；And
For providing described second Search Results for replacing described on said computing device
The device that one Search Results shows.
32. according to the computer implemented system according to any one of claim 25 to 27,
Wherein, described voice correction instruction includes at least one in the multiple words to described first text
The user of word selects.
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201562153839P | 2015-04-28 | 2015-04-28 | |
US62/153,839 | 2015-04-28 |
Publications (2)
Publication Number | Publication Date |
---|---|
CN106095766A true CN106095766A (en) | 2016-11-09 |
CN106095766B CN106095766B (en) | 2021-12-21 |
Family
ID=55755434
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201610273179.7A Active CN106095766B (en) | 2015-04-28 | 2016-04-28 | Correcting speech recognition using selective re-speaking |
Country Status (3)
Country | Link |
---|---|
US (1) | US10354647B2 (en) |
EP (1) | EP3089159B1 (en) |
CN (1) | CN106095766B (en) |
Cited By (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN108647190A (en) * | 2018-04-25 | 2018-10-12 | 北京华夏电通科技有限公司 | A kind of speech recognition text is inserted into the method, apparatus and system of notes document |
CN110663079A (en) * | 2017-05-24 | 2020-01-07 | 乐威指南公司 | Method and system for correcting input generated using automatic speech recognition based on speech |
CN110956958A (en) * | 2019-12-04 | 2020-04-03 | 深圳追一科技有限公司 | Searching method, searching device, terminal equipment and storage medium |
CN112750438A (en) * | 2019-10-30 | 2021-05-04 | Lg 电子株式会社 | Artificial intelligence device |
Families Citing this family (8)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10331402B1 (en) * | 2017-05-30 | 2019-06-25 | Amazon Technologies, Inc. | Search and knowledge base question answering for a voice user interface |
US10978073B1 (en) | 2017-07-09 | 2021-04-13 | Otter.ai, Inc. | Systems and methods for processing and presenting conversations |
US11024316B1 (en) * | 2017-07-09 | 2021-06-01 | Otter.ai, Inc. | Systems and methods for capturing, processing, and rendering one or more context-aware moment-associating elements |
CN111128183B (en) * | 2019-12-19 | 2023-03-17 | 北京搜狗科技发展有限公司 | Speech recognition method, apparatus and medium |
CN111883122B (en) * | 2020-07-22 | 2023-10-27 | 海尔优家智能科技（北京）有限公司 | Speech recognition method and device, storage medium and electronic equipment |
US11676623B1 (en) | 2021-02-26 | 2023-06-13 | Otter.ai, Inc. | Systems and methods for automatic joining as a virtual meeting participant for transcription |
KR20220124547A (en) * | 2021-03-03 | 2022-09-14 | 삼성전자주식회사 | Electronic device for correcting user's voice input and operating method for the same |
US20220284887A1 (en) * | 2021-03-03 | 2022-09-08 | Samsung Electronics Co., Ltd. | Electronic device for correcting speech input of user and operating method thereof |
Citations (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20040172245A1 (en) * | 2003-02-28 | 2004-09-02 | Lee Rosen | System and method for structuring speech recognized text into a pre-selected document format |
US20050033574A1 (en) * | 2003-08-06 | 2005-02-10 | Samsung Electronics Co., Ltd. | Method and apparatus handling speech recognition errors in spoken dialogue systems |
US20080162137A1 (en) * | 2006-12-28 | 2008-07-03 | Nissan Motor Co., Ltd. | Speech recognition apparatus and method |
CN101593076A (en) * | 2008-05-28 | 2009-12-02 | Lg电子株式会社 | Portable terminal and the method that is used to revise its text |
CN101655837A (en) * | 2009-09-08 | 2010-02-24 | 北京邮电大学 | Method for detecting and correcting error on text after voice recognition |
US20110054900A1 (en) * | 2007-03-07 | 2011-03-03 | Phillips Michael S | Hybrid command and control between resident and remote speech recognition facilities in a mobile voice-to-speech application |
CN103207769A (en) * | 2012-01-16 | 2013-07-17 | 联想(北京)有限公司 | Method and user equipment for voice amending |
Family Cites Families (159)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JPS5598797A (en) | 1979-01-20 | 1980-07-28 | Sharp Kk | Electronic translator |
US4866778A (en) | 1986-08-11 | 1989-09-12 | Dragon Systems, Inc. | Interactive speech recognition apparatus |
US5027406A (en) | 1988-12-06 | 1991-06-25 | Dragon Systems, Inc. | Method for interactive speech recognition and training |
US5909666A (en) | 1992-11-13 | 1999-06-01 | Dragon Systems, Inc. | Speech recognition system which creates acoustic models by concatenating acoustic models of individual words |
DE69423838T2 (en) | 1993-09-23 | 2000-08-03 | Xerox Corp | Semantic match event filtering for speech recognition and signal translation applications |
US5510981A (en) | 1993-10-28 | 1996-04-23 | International Business Machines Corporation | Language translation apparatus and method using context-based translation models |
TW323364B (en) | 1993-11-24 | 1997-12-21 | At & T Corp | |
US6070140A (en) | 1995-06-05 | 2000-05-30 | Tran; Bao Q. | Speech recognizer |
US5855000A (en) | 1995-09-08 | 1998-12-29 | Carnegie Mellon University | Method and apparatus for correcting and repairing machine-transcribed input using independent or cross-modal secondary input |
US5712957A (en) | 1995-09-08 | 1998-01-27 | Carnegie Mellon University | Locating and correcting erroneously recognized portions of utterances by rescoring based on two n-best lists |
US6067521A (en) * | 1995-10-16 | 2000-05-23 | Sony Corporation | Interrupt correction of speech recognition for a navigation device |
US5799279A (en) | 1995-11-13 | 1998-08-25 | Dragon Systems, Inc. | Continuous speech recognition of text and commands |
US5794189A (en) | 1995-11-13 | 1998-08-11 | Dragon Systems, Inc. | Continuous speech recognition |
US6064959A (en) | 1997-03-28 | 2000-05-16 | Dragon Systems, Inc. | Error correction in speech recognition |
US6397180B1 (en) | 1996-05-22 | 2002-05-28 | Qwest Communications International Inc. | Method and system for performing speech recognition based on best-word scoring of repeated speech attempts |
US5857099A (en) | 1996-09-27 | 1999-01-05 | Allvoice Computing Plc | Speech-to-text dictation system with audio message capability |
GB2302199B (en) | 1996-09-24 | 1997-05-14 | Allvoice Computing Plc | Data processing method and apparatus |
US5829000A (en) * | 1996-10-31 | 1998-10-27 | Microsoft Corporation | Method and system for correcting misrecognized spoken words or phrases |
US5864805A (en) * | 1996-12-20 | 1999-01-26 | International Business Machines Corporation | Method and apparatus for error correction in a continuous dictation system |
US5953541A (en) | 1997-01-24 | 1999-09-14 | Tegic Communications, Inc. | Disambiguating system for disambiguating ambiguous input sequences by displaying objects associated with the generated input sequences in the order of decreasing frequency of use |
US5909667A (en) | 1997-03-05 | 1999-06-01 | International Business Machines Corporation | Method and apparatus for fast voice selection of error words in dictated text |
US6490561B1 (en) | 1997-06-25 | 2002-12-03 | Dennis L. Wilson | Continuous speech voice transcription |
US6182028B1 (en) | 1997-11-07 | 2001-01-30 | Motorola, Inc. | Method, device and system for part-of-speech disambiguation |
US6397179B2 (en) | 1997-12-24 | 2002-05-28 | Nortel Networks Limited | Search optimization system and method for continuous speech recognition |
JP2991178B2 (en) | 1997-12-26 | 1999-12-20 | 日本電気株式会社 | Voice word processor |
US6195637B1 (en) | 1998-03-25 | 2001-02-27 | International Business Machines Corp. | Marking and deferring correction of misrecognition errors |
US5970451A (en) | 1998-04-14 | 1999-10-19 | International Business Machines Corporation | Method for correcting frequently misrecognized words or command in speech application |
US6424983B1 (en) | 1998-05-26 | 2002-07-23 | Global Information Research And Technologies, Llc | Spelling and grammar checking system |
US6374220B1 (en) | 1998-08-05 | 2002-04-16 | Texas Instruments Incorporated | N-best search for continuous speech recognition using viterbi pruning for non-output differentiation states |
US6195635B1 (en) | 1998-08-13 | 2001-02-27 | Dragon Systems, Inc. | User-cued speech recognition |
US6405170B1 (en) | 1998-09-22 | 2002-06-11 | Speechworks International, Inc. | Method and system of reviewing the behavior of an interactive speech recognition application |
US6606598B1 (en) | 1998-09-22 | 2003-08-12 | Speechworks International, Inc. | Statistical computing and reporting for interactive speech applications |
US6138099A (en) * | 1998-10-19 | 2000-10-24 | International Business Machines Corp. | Automatically updating language models |
US6192343B1 (en) | 1998-12-17 | 2001-02-20 | International Business Machines Corporation | Speech command input recognition system for interactive computer display with term weighting means used in interpreting potential commands from relevant speech terms |
US6922669B2 (en) | 1998-12-29 | 2005-07-26 | Koninklijke Philips Electronics N.V. | Knowledge-based strategies applied to N-best lists in automatic speech recognition systems |
CA2366057C (en) | 1999-03-05 | 2009-03-24 | Canon Kabushiki Kaisha | Database annotation and retrieval |
US6314397B1 (en) | 1999-04-13 | 2001-11-06 | International Business Machines Corp. | Method and apparatus for propagating corrections in speech recognition software |
US6611802B2 (en) | 1999-06-11 | 2003-08-26 | International Business Machines Corporation | Method and system for proofreading and correcting dictated text |
US6327566B1 (en) * | 1999-06-16 | 2001-12-04 | International Business Machines Corporation | Method and apparatus for correcting misinterpreted voice commands in a speech recognition system |
US6374221B1 (en) | 1999-06-22 | 2002-04-16 | Lucent Technologies Inc. | Automatic retraining of a speech recognizer while using reliable transcripts |
US6374214B1 (en) | 1999-06-24 | 2002-04-16 | International Business Machines Corp. | Method and apparatus for excluding text phrases during re-dictation in a speech recognition system |
CN1207664C (en) | 1999-07-27 | 2005-06-22 | 国际商业机器公司 | Error correcting method for voice identification result and voice identification system |
US6219640B1 (en) | 1999-08-06 | 2001-04-17 | International Business Machines Corporation | Methods and apparatus for audio-visual speaker recognition and utterance verification |
US6789231B1 (en) | 1999-10-05 | 2004-09-07 | Microsoft Corporation | Method and system for providing alternatives for text derived from stochastic input sources |
US6581033B1 (en) | 1999-10-19 | 2003-06-17 | Microsoft Corporation | System and method for correction of speech recognition mode errors |
CN1329861C (en) | 1999-10-28 | 2007-08-01 | 佳能株式会社 | Pattern matching method and apparatus |
US7310600B1 (en) | 1999-10-28 | 2007-12-18 | Canon Kabushiki Kaisha | Language recognition using a similarity measure |
US20020111990A1 (en) | 1999-11-01 | 2002-08-15 | Wood Christopher Noah | Internet based message management system |
US7392185B2 (en) | 1999-11-12 | 2008-06-24 | Phoenix Solutions, Inc. | Speech based learning/training system using semantic decoding |
US7725307B2 (en) | 1999-11-12 | 2010-05-25 | Phoenix Solutions, Inc. | Query engine for processing voice based queries including semantic decoding |
US20030182113A1 (en) | 1999-11-22 | 2003-09-25 | Xuedong Huang | Distributed speech recognition for mobile communication devices |
US7280964B2 (en) | 2000-04-21 | 2007-10-09 | Lessac Technologies, Inc. | Method of recognizing spoken language with recognition of language color |
WO2001084535A2 (en) | 2000-05-02 | 2001-11-08 | Dragon Systems, Inc. | Error correction in speech recognition |
US6587824B1 (en) * | 2000-05-04 | 2003-07-01 | Visteon Global Technologies, Inc. | Selective speaker adaptation for an in-vehicle speech recognition system |
US7149970B1 (en) | 2000-06-23 | 2006-12-12 | Microsoft Corporation | Method and system for filtering and selecting from a candidate list generated by a stochastic input method |
US7200555B1 (en) | 2000-07-05 | 2007-04-03 | International Business Machines Corporation | Speech recognition correction for devices having limited or no display |
US6856956B2 (en) | 2000-07-20 | 2005-02-15 | Microsoft Corporation | Method and apparatus for generating and displaying N-best alternatives in a speech recognition system |
US7216077B1 (en) | 2000-09-26 | 2007-05-08 | International Business Machines Corporation | Lattice-based unsupervised maximum likelihood linear regression for speaker adaptation |
US7085716B1 (en) | 2000-10-26 | 2006-08-01 | Nuance Communications, Inc. | Speech recognition using word-in-phrase command |
EP1209659B1 (en) | 2000-11-22 | 2005-10-05 | Matsushita Electric Industrial Co., Ltd. | Method and apparatus for text input utilizing speech recognition |
US7027987B1 (en) | 2001-02-07 | 2006-04-11 | Google Inc. | Voice interface for a search engine |
EP1417824A4 (en) | 2001-07-18 | 2006-09-13 | Min-Kyum Kim | Apparatus and method for inputting alphabet characters |
US7027988B1 (en) | 2001-07-20 | 2006-04-11 | At&T Corp. | System and method of ε removal of weighted automata and transducers |
US7809574B2 (en) | 2001-09-05 | 2010-10-05 | Voice Signal Technologies Inc. | Word recognition using choice lists |
US7444286B2 (en) | 2001-09-05 | 2008-10-28 | Roth Daniel L | Speech recognition using re-utterance recognition |
JP4241376B2 (en) | 2001-09-17 | 2009-03-18 | コーニンクレッカ フィリップス エレクトロニクス エヌ ヴィ | Correction of text recognized by speech recognition through comparison of speech sequences in recognized text with speech transcription of manually entered correction words |
US7149550B2 (en) | 2001-11-27 | 2006-12-12 | Nokia Corporation | Communication terminal having a text editor application with a word completion feature |
DE10211777A1 (en) | 2002-03-14 | 2003-10-02 | Philips Intellectual Property | Creation of message texts |
US6928407B2 (en) | 2002-03-29 | 2005-08-09 | International Business Machines Corporation | System and method for the automatic discovery of salient segments in speech transcripts |
JP3762327B2 (en) * | 2002-04-24 | 2006-04-05 | 株式会社東芝 | Speech recognition method, speech recognition apparatus, and speech recognition program |
US20040024582A1 (en) | 2002-07-03 | 2004-02-05 | Scott Shepard | Systems and methods for aiding human translation |
EP1525739A1 (en) | 2002-07-29 | 2005-04-27 | British Telecommunications Public Limited Company | Improvements in or relating to information provision for call centres |
US7386454B2 (en) | 2002-07-31 | 2008-06-10 | International Business Machines Corporation | Natural error handling in speech recognition |
KR100668297B1 (en) | 2002-12-31 | 2007-01-12 | 삼성전자주식회사 | Method and apparatus for speech recognition |
US20040249637A1 (en) | 2003-06-04 | 2004-12-09 | Aurilab, Llc | Detecting repeated phrases and inference of dialogue models |
US7475015B2 (en) | 2003-09-05 | 2009-01-06 | International Business Machines Corporation | Semantic language modeling and confidence measurement |
US20050102140A1 (en) | 2003-11-12 | 2005-05-12 | Joel Davne | Method and system for real-time transcription and correction using an electronic communication environment |
US7440895B1 (en) | 2003-12-01 | 2008-10-21 | Lumenvox, Llc. | System and method for tuning and testing in a speech recognition system |
US20060036438A1 (en) | 2004-07-13 | 2006-02-16 | Microsoft Corporation | Efficient multimodal method to provide input to a computing device |
US8335688B2 (en) | 2004-08-20 | 2012-12-18 | Multimodal Technologies, Llc | Document transcription system training |
US7533018B2 (en) | 2004-10-19 | 2009-05-12 | Motorola, Inc. | Tailored speaker-independent voice recognition system |
JP4679254B2 (en) | 2004-10-28 | 2011-04-27 | 富士通株式会社 | Dialog system, dialog method, and computer program |
JP4604178B2 (en) * | 2004-11-22 | 2010-12-22 | 独立行政法人産業技術総合研究所 | Speech recognition apparatus and method, and program |
US20060149551A1 (en) | 2004-12-22 | 2006-07-06 | Ganong William F Iii | Mobile dictation correction user interface |
US7949533B2 (en) | 2005-02-04 | 2011-05-24 | Vococollect, Inc. | Methods and systems for assessing and improving the performance of a speech recognition system |
US20060215821A1 (en) | 2005-03-23 | 2006-09-28 | Rokusek Daniel S | Voice nametag audio feedback for dialing a telephone call |
US7565282B2 (en) | 2005-04-14 | 2009-07-21 | Dictaphone Corporation | System and method for adaptive automatic error correction |
US8438142B2 (en) | 2005-05-04 | 2013-05-07 | Google Inc. | Suggesting and refining user input based on original user input |
JP4680691B2 (en) * | 2005-06-15 | 2011-05-11 | 富士通株式会社 | Dialog system |
EP1734509A1 (en) | 2005-06-17 | 2006-12-20 | Harman Becker Automotive Systems GmbH | Method and system for speech recognition |
US20060293889A1 (en) | 2005-06-27 | 2006-12-28 | Nokia Corporation | Error correction for speech recognition systems |
US20060293890A1 (en) | 2005-06-28 | 2006-12-28 | Avaya Technology Corp. | Speech recognition assisted autocompletion of composite characters |
DE102005030963B4 (en) | 2005-06-30 | 2007-07-19 | Daimlerchrysler Ag | Method and device for confirming and / or correcting a speech input supplied to a speech recognition system |
KR20070002567A (en) | 2005-06-30 | 2007-01-05 | 삼성전자주식회사 | Cooker with bar code scanner and control method thereof |
US8473295B2 (en) | 2005-08-05 | 2013-06-25 | Microsoft Corporation | Redictation of misrecognized words using a list of alternatives |
US7620549B2 (en) * | 2005-08-10 | 2009-11-17 | Voicebox Technologies, Inc. | System and method of supporting adaptive misrecognition in conversational speech |
JP4542974B2 (en) * | 2005-09-27 | 2010-09-15 | 株式会社東芝 | Speech recognition apparatus, speech recognition method, and speech recognition program |
US7930168B2 (en) | 2005-10-04 | 2011-04-19 | Robert Bosch Gmbh | Natural language processing of disfluent sentences |
US20070094022A1 (en) | 2005-10-20 | 2007-04-26 | Hahn Koo | Method and device for recognizing human intent |
US7941316B2 (en) | 2005-10-28 | 2011-05-10 | Microsoft Corporation | Combined speech and alternate input modality to a mobile device |
US7840406B2 (en) | 2006-02-07 | 2010-11-23 | Samsung Electronics Co., Ltd. | Method for providing an electronic dictionary in wireless terminal and wireless terminal implementing the same |
JP4734155B2 (en) | 2006-03-24 | 2011-07-27 | 株式会社東芝 | Speech recognition apparatus, speech recognition method, and speech recognition program |
US7689420B2 (en) | 2006-04-06 | 2010-03-30 | Microsoft Corporation | Personalizing a context-free grammar using a dictation language model |
US8209175B2 (en) | 2006-06-08 | 2012-06-26 | Microsoft Corporation | Uncertainty interval content sensing within communications |
US7756710B2 (en) | 2006-07-13 | 2010-07-13 | Sri International | Method and apparatus for error correction in speech recognition applications |
GB0616070D0 (en) | 2006-08-12 | 2006-09-20 | Ibm | Speech Recognition Feedback |
US7949536B2 (en) | 2006-08-31 | 2011-05-24 | Microsoft Corporation | Intelligent speech recognition of incomplete phrases |
JP2008090625A (en) | 2006-10-02 | 2008-04-17 | Sharp Corp | Character input device, character input method, control program, and recording medium |
US7840407B2 (en) | 2006-10-13 | 2010-11-23 | Google Inc. | Business listing search |
US7890326B2 (en) | 2006-10-13 | 2011-02-15 | Google Inc. | Business listing search |
US8055502B2 (en) | 2006-11-28 | 2011-11-08 | General Motors Llc | Voice dialing using a rejection reference |
US7953627B2 (en) | 2006-12-12 | 2011-05-31 | American Express Travel Related Services Company, Inc. | Identifying industry segments with highest potential for new customers or new spending for current customers |
EP1933302A1 (en) * | 2006-12-12 | 2008-06-18 | Harman Becker Automotive Systems GmbH | Speech recognition method |
JP2008233678A (en) | 2007-03-22 | 2008-10-02 | Honda Motor Co Ltd | Voice interaction apparatus, voice interaction method, and program for voice interaction |
US8306816B2 (en) | 2007-05-25 | 2012-11-06 | Tigerfish | Rapid transcription by dispersing segments of source material to a plurality of transcribing stations |
WO2008151212A1 (en) | 2007-06-04 | 2008-12-11 | Nexidia Inc. | Speech skills assessment |
US8831946B2 (en) | 2007-07-23 | 2014-09-09 | Nuance Communications, Inc. | Method and system of indexing speech data |
US8036464B2 (en) | 2007-09-07 | 2011-10-11 | Satyam Computer Services Limited | System and method for automatic segmentation of ASR transcripts |
JP4839291B2 (en) | 2007-09-28 | 2011-12-21 | Ｋｄｄｉ株式会社 | Speech recognition apparatus and computer program |
US8155959B2 (en) | 2007-11-07 | 2012-04-10 | Robert Bosch Gmbh | Dialog system for human agent to correct abnormal output |
KR101170612B1 (en) | 2008-03-11 | 2012-08-03 | 에스케이 텔레콤주식회사 | Method and system for providing speech recognition by using user images |
US8082148B2 (en) | 2008-04-24 | 2011-12-20 | Nuance Communications, Inc. | Testing a grammar used in speech recognition for reliability in a plurality of operating environments having different background noise |
US20090326938A1 (en) | 2008-05-28 | 2009-12-31 | Nokia Corporation | Multiword text correction |
US8296144B2 (en) | 2008-06-04 | 2012-10-23 | Robert Bosch Gmbh | System and method for automated testing of complicated dialog systems |
KR100988397B1 (en) | 2008-06-09 | 2010-10-19 | 엘지전자 주식회사 | Mobile terminal and text correcting method in the same |
US8140330B2 (en) * | 2008-06-13 | 2012-03-20 | Robert Bosch Gmbh | System and method for detecting repeated patterns in dialog systems |
JP5226401B2 (en) | 2008-06-25 | 2013-07-03 | インターナショナル・ビジネス・マシーンズ・コーポレーション | Apparatus and method for supporting retrieval of document data |
US8364481B2 (en) | 2008-07-02 | 2013-01-29 | Google Inc. | Speech recognition with parallel recognition tasks |
WO2010000322A1 (en) | 2008-07-03 | 2010-01-07 | Mobiter Dicta Oy | Method and device for converting speech |
US8019608B2 (en) | 2008-08-29 | 2011-09-13 | Multimodal Technologies, Inc. | Distributed speech recognition using one way communication |
US8965765B2 (en) | 2008-09-19 | 2015-02-24 | Microsoft Corporation | Structured models of repetition for speech recognition |
EP2196989B1 (en) | 2008-12-10 | 2012-06-27 | Nuance Communications, Inc. | Grammar and template-based speech recognition of spoken utterances |
US8768852B2 (en) | 2009-01-13 | 2014-07-01 | Amazon Technologies, Inc. | Determining phrases related to other phrases |
KR101556594B1 (en) * | 2009-01-14 | 2015-10-01 | 삼성전자 주식회사 | Signal processing apparatus and method of recognizing voice thereof |
US8739055B2 (en) | 2009-05-07 | 2014-05-27 | Microsoft Corporation | Correction of typographical errors on touch displays |
US8407617B2 (en) | 2009-09-11 | 2013-03-26 | Visual Study Bible, Llc | Providing a visual representation of various resources related to passages of classic literature |
US9502025B2 (en) * | 2009-11-10 | 2016-11-22 | Voicebox Technologies Corporation | System and method for providing a natural language content dedication service |
US9275640B2 (en) | 2009-11-24 | 2016-03-01 | Nexidia Inc. | Augmented characterization for speech recognition |
US8589163B2 (en) | 2009-12-04 | 2013-11-19 | At&T Intellectual Property I, L.P. | Adapting language models with a bit mask for a subset of related words |
US8903793B2 (en) * | 2009-12-15 | 2014-12-02 | At&T Intellectual Property I, L.P. | System and method for speech-based incremental search |
US8914401B2 (en) | 2009-12-30 | 2014-12-16 | At&T Intellectual Property I, L.P. | System and method for an N-best list interface |
US8494852B2 (en) | 2010-01-05 | 2013-07-23 | Google Inc. | Word-level correction of speech input |
US20120016671A1 (en) | 2010-07-15 | 2012-01-19 | Pawan Jaggi | Tool and method for enhanced human machine collaboration for rapid and accurate transcriptions |
US8880403B2 (en) | 2010-09-03 | 2014-11-04 | Canyon Ip Holdings Llc | Methods and systems for obtaining language models for transcribing communications |
US9123339B1 (en) | 2010-11-23 | 2015-09-01 | Google Inc. | Speech recognition using repeated utterances |
US9418152B2 (en) | 2011-02-09 | 2016-08-16 | Nice-Systems Ltd. | System and method for flexible speech to text search mechanism |
US9674328B2 (en) | 2011-02-22 | 2017-06-06 | Speak With Me, Inc. | Hybridized client-server speech recognition |
CN102682763B (en) * | 2011-03-10 | 2014-07-16 | 北京三星通信技术研究有限公司 | Method, device and terminal for correcting named entity vocabularies in voice input text |
US8972240B2 (en) | 2011-05-19 | 2015-03-03 | Microsoft Corporation | User-modifiable word lattice display for editing documents and search queries |
JP2013025299A (en) | 2011-07-26 | 2013-02-04 | Toshiba Corp | Transcription support system and transcription support method |
EP2645364B1 (en) * | 2012-03-29 | 2019-05-08 | Honda Research Institute Europe GmbH | Spoken dialog system using prominence |
US8775175B1 (en) | 2012-06-01 | 2014-07-08 | Google Inc. | Performing dictation correction |
US9384736B2 (en) * | 2012-08-21 | 2016-07-05 | Nuance Communications, Inc. | Method to provide incremental UI response based on multiple asynchronous evidence about user input |
US10031968B2 (en) * | 2012-10-11 | 2018-07-24 | Veveo, Inc. | Method for adaptive conversation state management with filtering operators applied dynamically as part of a conversational interface |
US9190055B1 (en) * | 2013-03-14 | 2015-11-17 | Amazon Technologies, Inc. | Named entity recognition with personalized models |
EP2862164B1 (en) * | 2013-08-23 | 2017-05-31 | Nuance Communications, Inc. | Multiple pass automatic speech recognition |
US10446141B2 (en) * | 2014-08-28 | 2019-10-15 | Apple Inc. | Automatic speech recognition based on user feedback |
US9514743B2 (en) * | 2014-08-29 | 2016-12-06 | Google Inc. | Query rewrite corrections |
US9830321B2 (en) * | 2014-09-30 | 2017-11-28 | Rovi Guides, Inc. | Systems and methods for searching for a media asset |
-
2016
- 2016-04-14 EP EP16165438.9A patent/EP3089159B1/en active Active
- 2016-04-28 US US15/140,891 patent/US10354647B2/en active Active
- 2016-04-28 CN CN201610273179.7A patent/CN106095766B/en active Active
Patent Citations (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20040172245A1 (en) * | 2003-02-28 | 2004-09-02 | Lee Rosen | System and method for structuring speech recognized text into a pre-selected document format |
US20050033574A1 (en) * | 2003-08-06 | 2005-02-10 | Samsung Electronics Co., Ltd. | Method and apparatus handling speech recognition errors in spoken dialogue systems |
US20080162137A1 (en) * | 2006-12-28 | 2008-07-03 | Nissan Motor Co., Ltd. | Speech recognition apparatus and method |
US20110054900A1 (en) * | 2007-03-07 | 2011-03-03 | Phillips Michael S | Hybrid command and control between resident and remote speech recognition facilities in a mobile voice-to-speech application |
CN101593076A (en) * | 2008-05-28 | 2009-12-02 | Lg电子株式会社 | Portable terminal and the method that is used to revise its text |
CN101655837A (en) * | 2009-09-08 | 2010-02-24 | 北京邮电大学 | Method for detecting and correcting error on text after voice recognition |
CN103207769A (en) * | 2012-01-16 | 2013-07-17 | 联想(北京)有限公司 | Method and user equipment for voice amending |
Cited By (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN110663079A (en) * | 2017-05-24 | 2020-01-07 | 乐威指南公司 | Method and system for correcting input generated using automatic speech recognition based on speech |
CN108647190A (en) * | 2018-04-25 | 2018-10-12 | 北京华夏电通科技有限公司 | A kind of speech recognition text is inserted into the method, apparatus and system of notes document |
CN112750438A (en) * | 2019-10-30 | 2021-05-04 | Lg 电子株式会社 | Artificial intelligence device |
CN110956958A (en) * | 2019-12-04 | 2020-04-03 | 深圳追一科技有限公司 | Searching method, searching device, terminal equipment and storage medium |
Also Published As
Publication number | Publication date |
---|---|
US20160322049A1 (en) | 2016-11-03 |
EP3089159B1 (en) | 2019-08-28 |
EP3089159A1 (en) | 2016-11-02 |
US10354647B2 (en) | 2019-07-16 |
CN106095766B (en) | 2021-12-21 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN106095766A (en) | Use selectivity again to talk and correct speech recognition | |
US11269873B2 (en) | Retrieving context from previous sessions | |
AU2014201827B2 (en) | Scoring concept terms using a deep network | |
US10783156B1 (en) | Scoring candidate answer passages | |
US9817646B1 (en) | Multiplatform and multichannel distribution of web applications across devices | |
CN105051732B (en) | The ranking of locally applied content | |
US10102482B2 (en) | Factorized models | |
US10394841B2 (en) | Generating contextual search presentations | |
US9679027B1 (en) | Generating related questions for search queries | |
CN105900087B (en) | For inquiring the abundant content of answer | |
US10503803B2 (en) | Animated snippets for search results | |
US20120166276A1 (en) | Framework that facilitates third party integration of applications into a search engine | |
US20230186348A1 (en) | Image Recognition Based Content Item Selection | |
US10180964B1 (en) | Candidate answer passages | |
RU2685991C1 (en) | Instant context-based search recommendations | |
US9135307B1 (en) | Selectively generating alternative queries | |
US9146972B2 (en) | Ranking of presentation modes for particular content | |
CN106471497B (en) | Context-using assisted browsing | |
CN107408125B (en) | Image for query answers | |
US11789946B2 (en) | Answer facts from structured content | |
US20180285444A1 (en) | Rewriting contextual queries | |
US11151129B1 (en) | Modifying query in discourse context | |
CN106471492B (en) | Acts of indexing resources | |
US20180137587A1 (en) | Contextual personalized list of recommended courses | |
US20180137588A1 (en) | Contextual personalized list of recommended courses |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
C06 | Publication | ||
PB01 | Publication | ||
CB02 | Change of applicant information | ||
CB02 | Change of applicant information |
Address after: American CaliforniaApplicant after: Google limited liability companyAddress before: American CaliforniaApplicant before: Google Inc. |
|
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
GR01 | Patent grant | ||
GR01 | Patent grant |