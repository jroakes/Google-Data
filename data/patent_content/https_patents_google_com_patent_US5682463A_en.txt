US5682463A - Perceptual audio compression based on loudness uncertainty - Google Patents
Perceptual audio compression based on loudness uncertainty Download PDFInfo
- Publication number
- US5682463A US5682463A US08/384,049 US38404995A US5682463A US 5682463 A US5682463 A US 5682463A US 38404995 A US38404995 A US 38404995A US 5682463 A US5682463 A US 5682463A
- Authority
- US
- United States
- Prior art keywords
- loudness
- audio signal
- frequency domain
- measure
- noise
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Expired - Lifetime
Links
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04B—TRANSMISSION
- H04B1/00—Details of transmission systems, not covered by a single one of groups H04B3/00 - H04B13/00; Details of transmission systems not characterised by the medium used for transmission
- H04B1/66—Details of transmission systems, not covered by a single one of groups H04B3/00 - H04B13/00; Details of transmission systems not characterised by the medium used for transmission for reducing bandwidth of signals; for improving efficiency of transmission
- H04B1/665—Details of transmission systems, not covered by a single one of groups H04B3/00 - H04B13/00; Details of transmission systems not characterised by the medium used for transmission for reducing bandwidth of signals; for improving efficiency of transmission using psychoacoustic properties of the ear, e.g. masking effect
Definitions
- the present invention relates generally to audio signal compression systems and more specifically to such systems which employ models of human perception in achieving high levels of signal compression.
- Perceptual coding of audio signals involves the concept of "perceptual masking.”
- Perceptual masking refers to a psycho-acoustic effect where a listener cannot hear an otherwise audible sound because that sound is presented to the listener in the presence of another sound (referred to as the "masking signal").
- This psycho-acoustic effect has been employed to advantage in several audio compression systems which treat the audio signal--the signal to be compressed--as the masking signal and coding (or quantizer) noise as the signal to be masked.
- These systems seek to quantize the audio signal with a quantizer stepsize which is as large as possible without introducing audible quantization noise in the audio signal.
- the level of quantization noise which may be introduced without audible effect will be a function of how well a particular audio signal--the masker--serves to supply a masking effect.
- the greater the masking ability of the audio signal the coarser the quantization may be without introducing audible noise.
- the coarser the quantization the lower the bit-rate of the compressed signal.
- Tonality of an audio signal at a given point in time was computed based on how well the audio signal matched a predicted audio signal value at that time, the prediction being a function of past audio signal values.
- the predicted audio signal value is determined based on an assumption that the audio signal is a pure tone. If the predicted signal value matched the actual value of the signal, the assumption that the actual signal could be well represented by a tone model would be validated and a large value of tonality (e.g., one, on a normalized scale) would result.
- the predicted signal value did not match the actual signal value very well--a result which undercuts the original assumption that the signal could be well represented by a pure tone--a comparatively small value of tonality would result.
- the signal would be assigned a tonality metric value of less than one, with the exact value being dependent on the degree to which the actual signal value differed from the predicted value. (Chaos, on a normalized scale, is a measure which equals one minus the value of tonality).
- tonality and chaos
- the concept is based on an observed effects on masking ability of different types of signals, not an understanding of how such effects are caused in the human auditory system as a result of exposure to such signal.
- the present invention provides method and apparatus for encoding an audio signal in accordance with a model of noise masking which is based on a measure of loudness uncertainty. Loudness uncertainty is central to a newly developed understanding of how noise masking effects are caused in the human auditory system.
- measures of loudness uncertainty are compared with a loudness differential between original and synthesized audio signals in a subband, analysis-by-synthesis framework.
- a plurality of different (provisional) encodings quantization stepsizes
- Such an encoding is the one deemed appropriate for the band. This stepsize may then be used to quantize the signal in that band.
- FIG. 1 is a table enumerating sources of decision variable uncertainties in detecting the presence of a tone in noise.
- FIG. 2 is a table summarizing results of three experiments conducted in a study.
- FIG. 3A illustrates amplitude spectra of masking stimuli (or maskers) used in the experiments.
- FIG. 3B illustrates amplitude spectra of probes used in the experiments.
- FIG. 3C illustrates phase relationships between the probes and the components of the maskers.
- FIG. 4 illustrates masked audiograms using a variable frequency pure tone probe for a first subject in a first experiment.
- FIG. 5 illustrates second masked audiograms for the first subject in the first experiment.
- FIG. 6 are plots of probe levels at masked thresholds versus the bandwidth of a masker corresponding to four subjects in a second experiment.
- FIG. 7 are plots of the relative intensity increments at masked thresholds versus the bandwidth of the masker corresponding to the four subjects in the second experiment.
- FIG. 8 are plots of the relative intensity increments as a function of probe tone intensity corresponding to two different bandwidths of the masker.
- FIG. 9 are plots of probe levels at masked thresholds as a function of the masker bandwidth corresponding to the four subjects in the second experiment and a third experiment.
- FIG. 10 illustrates a model of auditory detection.
- FIG. 11 are plots of the measured masked thresholds from FIG. 6 versus thresholds predicted using the model of FIG. 10 corresponding to the four subjects.
- FIG. 12 is a plot of measured just noticeable differences (JNDs) in intensity thresholds versus thresholds predicted using two models of non-linearity.
- FIG. 13 shows a breakdown of sources of uncertainties for tones masked by noise in the second experiment.
- FIG. 14 is a phaser diagram for computing a probability distribution.
- FIG. 15 presents an illustrative embodiment of the present invention.
- FIG. 16 presents a loudness computation for use in the illustrative embodiment of FIG. 15.
- FIG. 17 presents a variable resolution analysis filterbank for use in the illustrative embodiment of FIG. 15.
- FIGS. 18A and 18B respectively illustrate two groupings of modified discrete cosine transform (MDCT) subbands used in the filterbank of FIG. 17.
- MDCT modified discrete cosine transform
- FIG. 19 presents a quantization processor for use in the illustrative embodiment of FIG. 15.
- the neural code When sound is transduced by the cochlea of the human auditory system, it is turned into a neural code.
- the neural code is close to a non-homogeneous Poisson process.
- the variance of the process's random variable here the number of spikes, is approximately equal to the mean.
- N k the number of spikes that result from a 50 ms tone burst of 1 kHz.
- N k the number of spikes N k are generated, where k indexes the trial. For example, for the trial, we get N 1 spikes, and for the 10 th , we find N 10 spikes.
- Loudness of auditory signals is related to the total number of spikes summed over all of the nerve fibers.
- the following sections 1 through 8 discuss a study on the relationship between masking, the just noticeable difference (JND) in intensity and loudness, which suggests that noise masking in the human auditory system is a function of the uncertainty in loudness as perceived by a human (note that numerals in brackets throughout the discussion refer to the corresponding references in section 8):
- the problem of determining the masked threshold for an arbitrary masker is a basic problem in psychophysics which has many important engineering applications.
- the masked threshold is needed in speech and music coders to determine the bit allocations 35, 22, 39!.
- the masked threshold is important in calculating the loudness of a signal 13, 37, 45!.
- masking is important in defining the critical bandwidth.
- the masking is required when calculating the articulation index when determining speech intelligibility 11!.
- the difference in the masking ability of tones versus equal intensity narrow band noises is particularly confounding for a variety of published methods that compute masked threshold based on the energy spectrum of the masking stimulus. For example, most techniques for calculating the loudness of an arbitrary sound rely on the assumption that loudness is directly related to the pattern of excitation in the auditory nerve 12, 13, 37, 45!. All of these methods infer the profile of neural activity produced by a sound from the psychophysical masked audiogram when that sound is used as the masker. The area under the masked audiogram is transformed into a representation of the neural activity 13! or "specific loudness" 45! which, when integrated across the spectrum, yields an estimate of the total loudness of the sound.
- Speech and music coders which exploit the masking properties of the input sound to hide quantization noise are also hampered by the difference in masking efficacy of tones versus noises when computing the masked threshold 35, 22!. Developers of these coders struggle with the problem of defining the two classes of signals, tonelike versus noise-like, as well as identifying the two classes in sub-bands of the input signal. If a unifying model that relates the masking properties of noise signals to tone signals existed, the issues currently faced by these coders when categorizing signals might be eliminated.
- the intensity increment will be greatest for positively correlated masker and probe signals and least for negatively correlated signals. If the masker or probe are random signals, as is the case for tones masked by random noise, the correlation between masker and probe will vary amongst trials. Therefore, the intensity increment is random when a tone is added to random noise as opposed to a constant intensity increment when a tone is added to another tone or frozen noise. Frequently, and incorrectly, it has been assumed that the masker and probe signal are uncorrelated when calculating the intensity increment. Before describing the experiments we will review the issues relevant to making the connection between masking and intensity increments.
- the probe signal is a scaled copy of the masker signal, namely
- ⁇ is a scale factor.
- the observer's task becomes one of detecting a just noticeable difference in intensity (JND I ) when the probe is added to the masker.
- JND I just noticeable difference in intensity
- the detectability of intensity increments has been examined using detection theory 14, 6!.
- the basic idea behind signal detection theory is that the observer bases their judgments on a decision variable which is a random function of the stimulus.
- the decision variable must be a function of the stimulus intensity in a JND I task.
- the uncertainty associated with the subjective ranking of a stimulus is reflected in the distribution of the decision variable.
- Detection theory shows that the variance of the decision variable limits the subject's ability to distinguish between stimuli that differ only in their intensity 14, 15, 6, 26, 32, 23, 19!.
- Masking and JND I are typically measured in a two-interval forced choice (2-IFC) paradigm, where one interval contains the masker m T and the other interval contains the masker plus probe m T +p T .
- the order of presentation of the two intervals within a trial is randomized and the subject is asked to identify which interval contains the probe.
- the probe level is varied until the level corresponding to a given detection criterion (e.g. 76% correct) is located.
- a given detection criterion e.g. 76% correct
- the variance of the decision variable in JND tasks may be decomposed into an internal and external source of uncertainty 6, 26, 32, 4!.
- the internal uncertainty is an inherent characteristic of the auditory system (e.g. uncertainty contributed by the stochastic neural representation) and represents a fundamental limit on the best performance possible (e.g. in a tone JND I task).
- External uncertainty is contributed by the signal.
- the intensity of a finite duration sample of Gaussian noise varies randomly about some mean value thus providing an external source of signal level uncertainty. Buus demonstrated that the JND I for a sub-critical bandwidth (SCBW) Gaussian noise is reduced if the noise is frozen rather than random from interval to interval at sound levels greater than 60 dB SPL 4!.
- SCBW sub-critical bandwidth
- Buus interprets the ⁇ I/I for the frozen noise as a measure of the internal uncertainty (subjective uncertainty) and the ⁇ I/I for the random noise as a measure of the combined internal and external certainty (stimulus uncertainty).
- the ⁇ I/I of a tone was found to be the same as that of an equal intensity frozen SCBW noise, which is consistent with this interpretation 4!.
- Green derived an approximate solution for the intensity distribution of a band limited, time truncated Gaussian noise 14!.
- the value of the decision variable is linearly related to the intensity of the stimulus (the "energy model") and the implicit assumption that the internal uncertainty is dominated by the external signal intensity uncertainty, Green shows that such a detection model is qualitatively consistent with psychophysically measured performance. However, the quantitative predictions are consistently lower than observed human performance. The difference between the predicted and observed values is on the order of 5 dB 14!.
- De Boer attributed this failure to a lack of an internal source of uncertainty and reformulated Green's model by including an internal source whose variance was proportional to the stimulus intensity 6!. Although de Boer's results indicated an improvement in the qualitative fit of the revised model to psychophysical data, the range of values of the detectability parameter and of the constant of proportionality relating internal variance to stimulus intensity (which, in some cases, assumed negative values) indicated an overall failure of de Boer's model to quantitatively account for the data 6!.
- a relationship between masking and JND I can be established if it can be shown that the decision variable is a function of the same stimulus attribute(s) in these two tasks. It is clear that the decision variable in a JND I task must be a random function of only the stimulus intensity because this is the only attribute of the signal that is changed within a trial. However, the decision variable in a masking task could be a function of the shape of the stimulus waveform as well as the stimulus intensity since both of these attributes change when the probe is added to the masker. The question is, how much of an improvement in detection performance can we expect if the information contained in the details of the signal waveform is utilized in addition to the information in the signal intensity?
- Experiment III was designed to unambiguously identify intensity and not waveform as the stimulus attribute responsible for determining the absolute lowest masked threshold.
- a second and equally important source of the increased threshold is that adding a tone to random noise results in a random intensity increment as opposed to the constant intensity increment in JND I tasks.
- the threshold for any SCBW probe masked by any SCBW masker of equal or greater bandwidth can be it random or deterministic, can be predicted if the distribution of internal uncertainty (i.e. the tone JND I ) is known.
- Our goal is to develop a model that can accurately predict the masked threshold for a narrow band probe in the presence of an arbitrary SCBW masker.
- Such a model would, amongst other things, explain the approximately 20 dB difference in masking efficacy of tones versus noises.
- the endeavor is based on the hypothesis that the decision variable, when one is detecting the presence of a tone in noise, is solely a function of the stimulus intensity as in the JND I task. Therefore, the central issue we investigate is the relationship between the intensity increment at threshold for a tone masked by a SCBW masker and the JND I of the masker.
- the detectability of intensity increments is governed by the statistical distribution of the decision variable.
- Table 1 in FIG. 1 decomposes these sources of decision variable uncertainty.
- Previous "energy models” fail to quantitatively predict the increase in decision variable variance when the masker is a random noise versus a frozen stimulus. Although these energy models included external sources of uncertainty contributed by the chi-squared intensity distribution of band-limited, time-truncated Gaussian noise, we believe that the failures are due to the omission of an additional source of external uncertainty, the waveform uncertainty.
- our random noise stimuli are generated by summing sine waves of constant intensities but random phases.
- Such a noise stimulus has constant intensity (constant spectral level) but a random waveform from interval to interval.
- any uncertainty in the decision variable due to our constant spectrum level random noise can not be ascribed to intensity variability.
- using such a noise stimulus permits control over the correlation between the probe and masker signals thus enabling us to study the contribution of masker-probe correlation uncertainty to the variance of the decision variable.
- n(t) is a 70 dB SPL constant spectral level random noise signal centered at 1 kHz
- s(t) is a 70 dB 1 kHz sine
- S(t, f) is a sine of frequency f Hz.
- Subscripts (i ⁇ j ⁇ k) on the noise signals emphasize that a different realization of the random noise is presented during each interval (and trial), whereas subscripts on the sine signals emphasize that a different phase for the sine may be presented during each interval.
- Starred superscripts on the noise indicate that although the noise was random between intervals, the correlation between the noise masker and tone probe was controlled so that adding a sine to the noise resulted in a constant intensity increment regardless of the noise realization.
- Experiment I we verify that our constant spectrum level random noise reproduces the tone versus noise masking results previously observed using Gaussian random noise 7, 8!.
- Experiment I involves measuring the masked audiogram for (1) a fixed phase tone masker, (2) a 120 Hz wide flat spectrum random noise masker, and (3) a random phase tone masker. All maskers have a center frequency of 1 kHz and are presented at 70 dB SPL. Audiograms are measured using a 2-IFC paradigm.
- Experiment III is identical to Experiment II except that a 3-IFC rather than 2-IFC paradigm is employed to measure the thresholds.
- All stimuli were digitally generated at a 40 kHz sampling rate.
- the stimulus duration was 100 milliseconds.
- a five millisecond cosine ramp was used to smoothly gate the stimuli on and off.
- FIG. 3A depicts the amplitude spectra of the three different stimuli used as maskers.
- Masking stimuli had bandwidths (BW) of zero (i.e. pure tone), 40 Hz, and 120 Hz. All maskers are centered at 1 kHz and presented at 70 dB SPL for a duration of 100 milliseconds. Phases of the noise masker components are random (uniformly distributed).
- FIG. 3B depicts the amplitude spectra of the probes (gray vectors). The probe was either (1) a scaled copy of the masker (JND I task), or (2) a 1 kHz tone (masking task). Probe is gated simultaneously with the masker.
- FIG. 1 scaled copy of the masker
- 3C shows the phase relationships between the 1 kHz tone probe (P) and the 1 kHz component of the masker (M) in the masking tasks (case #2 in the middle row).
- the relative phase (re ⁇ ) between the probe and masker was either zero (in phase), ⁇ radians (out of phase), or random (uniformly distributed).
- the magnitude (vector length) of M and S is the same in all three examples; the magnitude of P differs, depending on the phase relationship.
- the narrow band noise (NBN) stimuli were constructed by summing sine waves having equal amplitude (see FIGS. 3A, 3B and 3C) and randomly chosen phase assignments drawn from a uniform distribution. New phase assignments were drawn for each interval and trial.
- the masking stimuli were always presented at 70 dB-SPL, thus the amplitude of the sine wave components of the NBN are inversely related to the bandwidth of the stimulus (see FIGS. 3A, 3B and 3C).
- the frequency increment between adjacent sine waves composing the masker is determined by the fundamental frequency of the stimulus. Since the stimulus duration was 100 msec, the fundamental frequency was 10 Hz.
- a 40 Hz bandwidth signal centered at 1 kHz contained five components at frequencies 980, 990, 1000, 1010, and 1020 Hz as shown in FIG. 3A.
- FIG. 3B depicts the amplitude spectra of the probes used in these two detection tasks (probes are represented by gray vectors whereas maskers are represented by black vectors).
- the probe is simply a scaled copy of the masker. Adding the probe to the masker produces an intensity increment in the signal (Eq. 8-9).
- the probe was always a 1 kHz pure tone (i.e. the probe has the same frequency as the center component of the NBN masker).
- the probe was a variable frequency tone.
- FIG. 3C is a vector diagram of the three different relative phase (re ⁇ ) conditions between P and M for which we collected data.
- the length of the vector symbolizes the magnitude of the signal while the relative angle between the M and P vector symbolizes the relative phase relationship.
- Stimuli were digitally generated in real time on a 486 PC.
- An Ariel DSP-16 converted the signals to analog and was followed by a 15 kHz low pass filter (Wavetek Brickwall Filter).
- the transducer was constructed by cannibalizing a Hyundai YH-2 headset and placing one of the drivers in an enclosure similar to a Sokolich driver.
- a piece of airline headset tubing 80 centimeters in length was used to deliver the acoustic stimulus from the driver to the ear. This tubing was terminated with an Etymotic ER-14 foam ear tip. The foam plug was inserted into the auditory meatus of the subject to complete the closed field sound delivery system.
- Thresholds were measured using either a two interval forced choice (2-IFC) paradigm and/or a 3-IFC paradigm.
- the 100 msec presentation intervals were separated by 500 msec; there was a 500 msec waiting period before the start of the next presentation after the subject entered their response to the previous trial.
- the "down" step size was 2 dB until the tenth reversal occurred, then 1 dB until the twentieth reversal occurred and, finally, 0.5 dB until the end of the block of trials.
- a block of trials ran until 30 reversals occurred.
- Each of the experiments generally consisted of 1 block yielding an average of ⁇ 125 measures per experiment. In some cases, the experiment was repeated and the results of the next block of trials were combined with the previous block of trials. Thus, each threshold estimate was based on the subject's response to approximately 125 to 375 trials. No data was discarded or selected.
- Subject #1 was a male in his 30s; subject #2 was a male in his 50s; subject #3 was a female in her 20s; subject #4 was a male in his 50s. All subjects had normal audiograms except subject #4 who displayed about a 20 dB presbyacusis hearing loss. The first two subjects were the first and second authors, respectively.
- FIG. 4 displays the results. Specifically, FIG. 4 shows masked audiograms using a variable frequency pure tone probe for subject #1.
- Maskers (1) 120 Hz wide constant spectrum level random noise centered on 1 kHz at 70 dB SPL (solid with *), (2) 1 kHz tone at 70 dB SPL (dashed with ⁇ ), and (3) in quiet (dotted with x) are used.
- the tone masker and tone probe are frozen in this experiment (i.e. same phase from interval to interval). Therefore, the correlation between the tone masker and tone probe is constant whereas the correlation between the noise masker and tone probe is random.
- the masked threshold at 1 kHz is 66 dB SPL for the noise masker and 46 dB SPL for the tone masker. This difference of 20 dB is the focus of this discussion.
- FIG. 4 shows the same qualitative result as that demonstrated previously by Egan and Hake who used bandpassed Gaussian noise rather than a constant spectrum level noise masker. That is, the masked threshold at the center frequency of the masker is 20 dB greater for a constant spectrum level random noise masker than for a tone masker. The lower curve shows threshold in quiet.
- FIG. 5 displays the resulting masked audiograms. With the exception of the audiogram for the tone masker, all conditions and results in this figure are the same as those in FIG. 5.
- the 1 kHz 70 dB SPL tone masker's phase was random from interval to interval in this experiment.
- the masked threshold at 1 kHz for the random phase tone masker is 73 dB SPL, 27 dB greater than that for the frozen tone masker used in FIG. 5.
- the masked audiogram for the 120 Hz wide noise in FIG. 5 is identical to that shown in the previous figure.
- the masked threshold for a 1 kHz probe is approximately 10 dB greater if the masking tone has random phase as opposed to 20 dB less when the masking tone has a fixed phase. All of these observations are consistent with the hypothesis that part of the difference in masked thresholds between tone and noise maskers may be due to the different correlations between the probe and masker, and different correlations with the distortion products.
- FIG. 6 shows plots of probe level at masked threshold (2-IFC 76% correct) versus the bandwidth of the masker.
- a dashed line corresponds to the JND I experiment in which the probe was a scaled copy of the masker.
- Solid lines correspond to the masking experiments in which the probe was a 1 kHz tone.
- the three different symbols on the masking plots (“*", "+”, and "x") correspond to the three different relative phase relationships between the tone probe and the 1 kHz component of the masker ("in phase”, “ ⁇ radians out of phase", and "random phase", respectively). Symbols that are not on a line (i.e.
- the solid lines in FIG. 6 represent plots of detection thresholds for tones in the presence of 70 dB-SPL maskers; the maskers are identical to the stimuli used in the JND I experiments.
- the three relative phase cases correspond to conditions under which the correlation between the masker and probe is maximally positive (in phase addition), maximally negative (out of phase addition), and random correlation (random relative phase addition).
- the results of FIG. 6 show that the masked threshold is very sensitive to the nature of the correlation between probe and masker. Indeed, the masked threshold can vary by as much as 10 dB for masker bandwidths approaching a critical band, and by as much as 30 dB for masker bandwidths approaching zero, depending on the correlation.
- FIG. 7 shows plots of the relative intensity increment ( ⁇ I/I) at masked threshold (2-IFC 76% correct) versus the bandwidth of the masker.
- Two sets of data, corresponding to the JND I and the tone masked threshold for "in phase addition" are shown; the data and related symbols are the same as those shown in the two lower-most curves of FIG. 6 except that they are plotted in terms of ⁇ I/I. Symbols that are not on a line (i.e.
- FIG. 7 shows that the ⁇ Is in the JND I and masking tasks (in phase addition) are identical.
- the threshold for detecting the tone probe in the presence of the masker is achieved when the intensity increment caused by adding the tone in phase to the masker is equal to the JND I of the masking stimulus.
- a probe tone of larger amplitude is required to achieve the same intensity increment if the tone is not in phase with the corresponding frequency component in the masker.
- This intuitive result which can be deduced from Eq. 5, is illustrated in the phaser diagram of FIG. 3C where the length of the probe vector had to be increased as the relative phase between the probe and masker increased to achieve the same signal amplitude.
- FIG. 8 shows plots of the relative intensity increment ⁇ I/I as a function of probe tone intensity.
- the masker is a tone in the upper graph and a 40 Hz wide constant spectral level noise in the lower graph.
- ⁇ I/I is plotted for the case where (1) the probe tone is added "in phase” to the masker (i.e. maximally positive correlation between m T and p T ), and (2) the probe tone is added " ⁇ radians out of phase” to the masker (i.e. maximally negative correlation between m T and p T ).
- Horizontal dash-dot lines show the thresholds for a just noticeable change in stimulus intensity.
- Vertical dash-dot lines are drawn where the ⁇ I/I just exceeds the bound for a just noticeable intensity increment in the two relative phase cases.
- FIG. 8 plots the relative intensity increment ⁇ I/I as a function of the probe intensity for two extreme cases of correlation between the masker and probe.
- the solid line represents the case where the probe is added in phase to the masker (the condition illustrated by the left drawing in FIG. 3C) whereas the dashed line represents a probe added ⁇ radians out of phase to the masker (the middle drawing in FIG. 3C).
- Vertical dash-dot lines have been drawn where the in phase and out of phase curves pass through the +0.57 dB and +1.2 dB lines,respectively.
- the probe intensities corresponding to these intersections are the same as those measured for the in phase and out of phase cases for the 0 and 40 Hz wide maskers in FIG. 6 for subject #1.
- FIG. 8 also illustrates how psychophysically measured masked threshold is biased by the measurement procedure.
- the subject is instructed to choose the interval containing the probe in a 2-IFC task.
- a reasonable criterion would be to pick the interval that sounds more tonal.
- the similarity between ⁇ I/I s in the masking and JND I tasks shown in FIG. 7 suggests that the subject relies on an intensity cue. In this case the subject will guess that the more intense interval is most likely to contain the probe.
- FIG. 8 shows that the intensity of the stimulus may actually decrease when the probe is added to the noise. Thus the subject may pick the incorrect interval even though they correctly identified the more intense interval.
- the subject will select the interval that sounds most different from the other two intervals. Hence the subject will tend to correctly identify the interval containing the probe whether the addition of the probe decreases or increases the intensity by a just noticeable amount.
- a 3-IFC experiment would demonstrate whether the waveform change associated with adding a tone to a noise masker (e.g. tonality cue) may provide a lower threshold cue for detecting the presence of the probe.
- Symbols that are not on a line i.e. above and below the lines connecting symbols) represent the 95% confidence limits ( ⁇ 2 ⁇ ) of the estimated thresholds.
- FIGS. 6-9 support the hypothesis that JND in intensity and masked threshold, classically discussed as separate and unrelated psycho-acoustic phenomena, are related to the same physical limitations of the auditory system. This concept is further developed into a model of auditory detection which we will test by attempting to predict all the results shown in FIG. 6 from the JND I data.
- FIG. 11 shows the results of these predictions.
- results from FIG. 6 are plotted against the predicted masked thresholds.
- the in phase and out of phase predictions are computed as described above and illustrated in FIG. 7. Intuitively, one would expect the random relative phase predictions to fall somewhere between the in phase and out of phase predictions. How to compute the random phase predictions is the subject of the next section.
- FIG. 10 depicts a model that is consistent with our masking and JND I data.
- the observer bases all their judgments on the output of a hypothetical channel whose value will be referred to as the decision variable.
- the decision variable is a random function of the input signal.
- the decision variable function is decomposed into our components which are represented by the four successive processing blocks in FIG. 10. This processing includes a band-pass filter, a non-linear monotonic transformation of the signal, an integrator, followed by the addition of signal dependent internal uncertainty. Since all of the signals used herein have sub-critical bandwidths, we can essentially ignore the effects of the filter whose pass-band is wider than the signal's bandwidth.
- ⁇ describes the non-linear transformation of the input signal
- T is the duration of the stimulus
- e is a mean zero stochastic process.
- Random function e represents the internal uncertainty. The uncertainty e is normally distributed with variance that is a function of
- the upper-most row depicts the input acoustic signals. These plots represent snap-shots of a portion of a single presentation of the signal. The remaining rows of graphs are based on multiple presentations of the signal to the system.
- the first column represents the case for multiple presentations of a pure tone to the channel; since the pure tone is deterministic, the channel sees the exact same signal during each presentation.
- the second column represents the case where different realizations of a random SCBW constant spectral level noise have been presented; in this case, the channel sees a different waveform during each presentation.
- the last column represents the case in which a pure tone has been added to the random SCBW noise used in the middle column; the relative phase between the pure tone and the corresponding component in the SCBW noise is random from trial to trial.
- G External uncertainty associated with the stimuli is represented by the distribution of G.
- the value of G is given by the integral of the signal after passing through the non-linearity.
- the ensemble average value of G over the sample space of noise waveforms, ⁇ noise in Eq. 15, is approximately equal to that of a pure tone of equal intensity
- E G! is the expected value of G.
- the variance of G, ⁇ 2 noise in Eq 15 depends on the parameters of the noise (e.g. bandwidth of the noise).
- the distribution of G given by Eq. 15 is for the case of a constant spectral level (constant intensity) noise input. If the input has a random intensity distribution, as is the case for a tone masked by random noise, the distribution of G will not necessarily be Gaussian. Stimulus based uncertainty is depicted in the second (middle) row of graphs in FIG. 10. These graphs illustrate the probability density functions (PDFs) for G that result from many presentations of the stimuli illustrated in the first row.
- PDFs probability density functions
- the abscissa corresponds to the value of G while the ordinate represents the frequency of occurrence (probability) of that value of G.
- this distribution is a delta function since identical copies of the signal pass through the non-linearities during each interval.
- this distribution will take the form of a Gaussian (Eq. 15).
- the intensity of the acoustic signal before it enters the channel will vary from trial to trial. This intensity distribution is derived in the Supplement section below.
- the PDF of G depicted in the last column of the second row reflects both the variability of intensity in the composite signal due to the interaction of the tone and noise, as well as the variability introduced by the non-linearities.
- the PDF of the decision variable N which includes additional uncertainty contributed by the stochastic nature of the neural representation, the internal uncertainty e, is shown in the lower row of graphs.
- the PDF of G for a tone is a delta function
- the JND I for a tone is determined by the variance of e.
- the variance of e can be inferred from the ⁇ I/I for a just noticeable difference in intensity of a tone. Since the ⁇ I/I of a tone depends on intensity 33!, the "near-miss to Weber's law", the variance of e must depend on G (see Eq. 13) 26, 32, 23, 19!.
- the lower-left graph illustrates the PDF of N for a tone.
- This normal distribution has mean G and variance ⁇ 2 G .
- the distribution of G is not a delta function. If the variance of G is not large, the distribution of e will be approximately the same as that for a tone whose G is equal to the expected value of the noise G (Eq. 16). Since the expected value of G is approximately the same in all three cases, the variance of the internal uncertainty e is approximately the same in all three cases.
- the PDFs for N in the last two columns can be computed by convolving the distribution of e from the tone case with the PDFs for G in the last two columns.
- the last row of graphs in FIG. 10 illustrate the results of these convolutions.
- the observer will detect the presence of "beats" (or a change in the beat rate) before detecting a significant change in the overall intensity when the probe is added to the masker--this represents a case where the waveform of the signal contains information in the form of a predictable temporal intensity cue whose perceptual threshold is lower than the change in the overall intensity of the signal.
- the latter case can not be accounted for using this model.
- the first is the variance of the normally distributed internal uncertainty. This parameter can be inferred from the JND I for a tone.
- the second is the exact form of the non-linearity, the function ⁇ .
- the function ⁇ is related to the loudness growth function. The exact form of ⁇ is only necessary to predict the JND I for random SCBW noises. Rather than predict the JND I for the noise maskers, we will just use their measured values from Experiment II in this section.
- ⁇ N is a direct measure of the variance of the internal uncertainty, e.
- G is normally distributed in a random noise JND I task, ⁇ N is a measure of the combined internal and external uncertainty.
- the resulting intensity increment randomly varies from trial to trial.
- the randomness of the intensity increment represents another source of external uncertainty and must be reflected in the distribution of G and, subsequently, N. This case is illustrated in the right-most column of FIG. 10.
- the PDF for N corresponding to the random intensity increment case can be computed as follows: First determine the PDF for ⁇ I of the tone plus random SCBW noise; an analytic expression describing this PDF has been derived in the appendix. Then convert this ⁇ I PDF to a distribution in N-domain using Eq. 18 and convolve it with the PDF for N which was inferred from the measured JND I of the random SCBW noise masker.
- FIG. 11 replots the measured masked thresholds (solid lines) from FIG. 6 and compares them to the masked thresholds predicted from the JND I thresholds (dashed lines) using our model.
- Predictions for the probe added to the masker with a fixed phase relationship are computed by finding the probe tone intensity that corresponds to the same ⁇ I as found in the JND I experiment using that masker (this procedure was illustrated graphically in FIG. 8).
- Predictions for the probe added to the masker with a random phase relationship are computed by finding the probe level that corresponded to a probability of 76% correct identification in a 2-IFC task.
- the random phase case was predicted by choosing a probe intensity, computing the intensity distributions within the model as described in the previous section, culminating with the evaluation of Eq. 22. This computation was repeated in an iterative fashion until the probe level corresponding to 76% correct was found. The latter search was terminated when the estimated probe level changed by less than ⁇ 0.01 dB from iteration to iteration.
- a logical choice for the non-linearity is the loudness growth function.
- the decision variable in our model is solely a function of signal intensity, and because the decision variable represents the subjective ranking of stimulus intensity, the loudness growth function relating signal intensity (or pressure) to loudness is consistent with this model.
- FIG. 12 displays the constant spectral level noise JND I predictions along with their measured values for subject #1.
- measured JND I thresholds are plotted against values predicted using two models of the non-linearity.
- Measured threshold data are represented by open circles and are connected by solid lines. Upper and lower open circles represent the estimated 95% confidence limits ( ⁇ 2 ⁇ ) of the measured thresholds.
- Data predicted using the loudness and energy models are connected by dashed and dash-dot lines, respectively.
- the predictions using the loudness growth function as the non-linearity are all within the 95% confidence limits of the measured results.
- the predicted JND I as a function of bandwidth follow the same pattern as the measured JND I .
- the energy model on the other hand, completely fails to predict the noise JND I .
- the JND I predicted using the energy model for the noise are slightly greater than that for the tone due to the small amount of energy variability introduced by the 5 msec on/off ramps used to gate the random noise.
- tone masked threshold on the bandwidth of the masking stimulus (i.e. tone versus sub-critical bandwidth random noise maskers) and to develop a quantitative model that predicts tone masked thresholds.
- tone masked threshold on the bandwidth of the masking stimulus (i.e. tone versus sub-critical bandwidth random noise maskers)
- FIG. 7 we demonstrated that the relative intensity increment ⁇ I/I at masked threshold caused by the addition of a tone to a random narrow band masker is equal to the JND I of the masker.
- the masking experiment in FIG. 7 was designed such that the addition of a constant amplitude probe tone caused a constant (deterministic) increment in the intensity of the stimulus from trial to trial even though the waveform of the masking noise was changing from interval to interval.
- the equality between the threshold intensity increment in the masking and JND I task of FIG. 7 is a quantitative demonstration of Miller's 27! hypothesis that masking and JND I tasks are fundamentally related.
- Incrementing the intensity of the SCBW noise masker by adding an in phase tone (tone masked by noise) and incrementing the intensity by adding a scaled copy of the masker represents two extreme methods for changing the intensity of the masker without changing its bandwidth. In one case, we changed the amplitude of only one component in the masker's spectrum and in the other case we changed the amplitude of all components in the masker's spectrum. However, the ⁇ I/I at detection threshold was the same in these two cases. This observation implies that any SCBW probe whose bandwidth is less than or equal to the masker and causes a constant intensity change when added to the masker (i.e. having a fixed correlation with the masker) will have the same threshold ⁇ I/I.
- FIG. 13 replots the results for subject #1 from Experiment II (these are the same data as previously shown in FIG. 6).
- the points in FIG. 13 corresponding to the masked threshold for a tone masked by another tone and for a tone masked by noise are circled.
- the 21 dB difference in masked threshold between these two maskers is decomposed into three contributions delineated by the horizontal dotted lines. These contributions are (1) the waveform uncertainty associated with the random noise masker, (2) the algebraic consequence of incrementing the intensity of the masker using a tone probe, and (3) the ⁇ I uncertainty due to adding a tone to random noise.
- a horizontal dotted line has been drawn at the probe level corresponding to masked threshold in the presence of these two maskers. There is the 21 dB difference between these masked thresholds.
- Increment #2 shows that there is a 7 dB increase due to the algebraic consequence of converting the JND I ⁇ I for a noise probe to an equivalent ⁇ I for a tone probe added in phase to the masker.
- increment #3 shows that there is a 10 dB increase due to the ⁇ I uncertainty associated with adding a tone to random noise with no correlation control.
- the integral of the signal after the non-linearity will not necessarily be constant. Only a system which has a squaring non-linearity followed by an integrator, such as Green's 14! or de Boer's 6! "energy detector" models, would predict a constant value for the decision variable if presented with our constant energy SCBW random noise.
- the energy detector model fails to predict the increase in JND I as the bandwidth of the signal is increased from zero.
- using a loudness growth function as the non-linearity does predict the increase in JND I for noise.
- the psychoacoustic performance of the auditory system in 2-IFC tasks has been compared to two types of optimal detectors: (1) A detector that compares the energy (or, equivalently, the intensity) in the two intervals 14, 6!, and (2) a detector that compares the signal waveforms in the two intervals 21!. If the task is to identify which of two intervals contains a tone, where one interval contains random narrow band Gaussian noise plus the tone and the other interval contains the random noise alone, these two detectors yield identical performance.
- Peterson et al. 29! analyzed the performance of an optimal detector designed to discriminate between a masker alone and masker plus probe based on the resulting waveform change for the case of a band-limited, time-truncated Gaussian noise masker. If the probe is a random narrow band Gaussian noise of the same bandwidth and duration as the noise masker (i.e. a noise JND I task), Peterson et al.'s results are identical to those obtained by Green using a detector whose criterion is the intensity change 14!.
- Peterson et al. 29! also derived the discriminability of a waveform change resulting from adding a finite duration sinusoid to the random narrow band Gaussian noise masker.
- the derivation assumed that the sinusoid's frequency was within the pass band of the random noise and that its phase was unknown to the observer.
- Gaussian noise As a signal whose waveform and spectrum are being "roved” thereby eliminating or minimizing the details of the waveform information.
- a bandlimited, time-truncated Gaussian noise has a spectrum whose component amplitudes are Rayleigh distributed. Adding a low level tone to this noise will change the amplitude of one of the components in the noise spectrum, however, this amplitude change may not be distinguishable from the inherent random variability of the component's amplitude. The situation is analogous to that for the intensity of the noise which is also random.
- the filter represents the transduction of motion at a fixed point on the basilar membrane to a neural representation of the signal amplitude.
- This element represents a filter since each point on the basilar membrane is particularly sensitive to a narrow range of frequencies (the critical band).
- the non-linearity represents not only the mechanical non-linearities present in the basilar membrane motion but, also, non-linearities contributed by the transduction of membrane motion to auditory nerve impulses by the inner hair cells, and the subsequent non-linearities contributed by neural processing and transmission across synapses to higher order neurons.
- the stimulus level estimated at the site of cognition will be a function of these system non-linearities 46!.
- Recent neurophysiological evidence suggests that the representation of acoustic stimulus envelope in the CNS is enhanced in the output of the principal cells of the ventral cochlear nucleus (VCN) relative to the auditory nerve 40, 41!. This suggests that the auditory system may be particularly concerned with preserving, or enhancing, information about the stimulus envelope. Further, it is evident that the neural representation of stimulus envelope in the output of VCN principal cells is a non-linear function of the acoustic stimulus 40, 41!. Neurophysiological evidence also suggests that information about the stimulus envelope is represented in the output of auditory cortical cells, however, this representation appears to be low pass filtered with respect to that in the output of the VCN (see 24! for review). These properties of the central representation of acoustic stimuli are consistent with the notion that information about the stimulus envelope is available to higher (cognitive) centers in the brain, thus providing a foundation for performing comparisons of stimulus envelope over time and comparisons of integrated level.
- the additive internal Gaussian distributed uncertainty is simply an approximate way of accounting for the inherent stochastic nature of the neural encoding. Many psychophysical models have explicitly accounted for this by including an internal source that behaves as an independent additive uncertainty. Most published models assume that the internal uncertainty is Gaussian distributed but they differ in how they model the dependence of the variance on the stimulus. For example, it has been proposed that this variance is proportional to: stimulus intensity 30, 32!, the expected value of the decision variable 26, 23, 19!, and the square of the stimulus intensity 6! or combinations of the these 47, 32!.
- the statistics of auditory nerve fibers with best frequencies greater than 3 k-5 k Hz can be viewed as a Poisson process that is modified by a refractory dead-time to a first approximation 38, 42, 25!.
- the discrimination process was based on counts of events in the auditory nerve as Fletcher and Munson originally proposed 12!, it would be reasonable to assume that the internal variance was related to the expected value of the decision variable as some have suggested 26, 23, 19!.
- the statistics of neural discharge patterns of principal cells in the auditory CNS can be quite regular as well 3, 43, 1!.
- the low-pass filter represented by the integrator in our model is distinct from and dominates the lowpass filtering contributed by brainstem neural processing which has a time constant on the order of milliseconds. This low-pass filtering which is inherent to all neurons probably limits the detectability of amplitude modulations in the signal.
- Masked thresholds for arbitrary probes can be accurately predicted given the JND I of the masking stimulus and the correlation between the probe and masker.
- Non-linearities in the auditory system contribute to the difference between tone and random noise JND I .
- the difference in masking efficacy of tone versus random noise maskers is due to (1) The increase in the JND I due to the random waveform of the masker, and (2) the uncertainty in the intensity increment resulting from adding the probe to the random masker.
- uncertainty provides a theory for calculating the masked threshold of signals. This theory first requires the calculation of the partial loudness, which is the loudness along the basilar membrane, and then the computation of the standard deviation of those partial loudnesses based on the Poisson model.
- the basic philosophy of the present invention is that distortions of the audio signal are only perceptible if they result in a detectable change in relative loudness in a particular frequency region.
- Relative loudness is the difference between the loudness of the original signal and a signal synthesized based on coded version of that signal (coded signal). This determination is advantageously made in each of the relevant cochlear (or critical) frequency bands associated with the human auditory system, to wit:
- the loudness of the signal is computed as a moving exponentially weighted average of the output of the non-linearity.
- the loudness calculation is performed on both the original audio signal and the coded (distorted) audio signal; a normalized difference between the original and coded partial loudness yields a measure of the perceptual distance between the loudness of the two signals over a frequency region.
- d ⁇ 1 For each frequency region (filter), the difference between the original and coded partial loudness is divided by the square root of the original's loudness (i.e., the uncertainty of the original) to yield a detectability measure, d' k (i).
- the "uncertainty" in the loudness of a signal is related to the square root of its loudness (hence the square root in the denominator).
- d ⁇ 1 represents a distortion that is perceptually detectable whereas d ⁇ 1 represents a distortion that is not perceptible.
- the above method then outlines the basis for the creating a perceptual audio coder whose output is perceptually indistinguishable from the original audio signal.
- a coder that distorts the audio signal in a manner that maintains all d' k (i) ⁇ 1 will produce an audio signal that is perceptually indistinguishable from the original.
- a coder that minimizes the function max d' k (i)! for all k and i will produce the most perceptually transparent signal.
- processors For clarity of explanation, the illustrative embodiment of the present invention is presented as comprising individual functional blocks (including functional blocks labeled as "processors"). The functions these blocks represent may be provided through the use of either shared or dedicated hardware, including, but not limited to, hardware capable of executing software. For example, the functions of processors presented in FIG. 15 may be provided by a single shared processor. (Use of the term "processor” should not be construed to refer exclusively to hardware capable of executing software.)
- Illustrative embodiments may comprise digital signal processor (DSP) hardware, such as the AT&T DSP16 or DSP32C, read-only memory (ROM) for storing software performing the operations discussed below, and random access memory (RAM) for storing DSP results.
- DSP digital signal processor
- ROM read-only memory
- RAM random access memory
- VLSI Very large scale integration
- An illustrative embodiment of the present invention operates in accordance with an analysis-by-synthesis subband framework to code an input audio signal, x(i).
- Signal x(i) is broken into frequency components (or "subbands") both for the purpose of perceptual modeling and to obtain a suitable representation for coding.
- a different subband framework is used for each of these purposes.
- signal x(i) is applied to a cochlear filterbank, while for the purpose of coding efficiency, signal x(i) is applied to a coding filterbank.
- a segment of M samples of x(i) is broken into M subbands.
- a provisional coding i.e., quantization
- the initial quantization step size is determined based on the loudness of the signal, L k .
- the provisional coding introduces quantization noise, n k .
- This synthesized audio signal, x k having loudness L k , is then used to determine a coding metric, referred to as the "detectability" metric.
- the detectability metric represents a comparison of the change in computed loudness,
- , as between original and synthesized audio signals, with the uncertainty in loudness for that subband, ⁇ L .sbsb.k ⁇ L k .
- This metric is then compared with a threshold to determine whether coding noise introduced by quantization is perceptually detectable. This comparison can yield one of three possibilities: (i) the coding noise is undetectable without any severe overcoding of the signal; (ii) the coding noise is undetectable with significant overcoding; or (iii) the coding noise is detectable.
- the signal is requantized using coarser quantizer step size, and the detectability metric is recomputed with the same possibilities reexamined.
- the first of these steps concerns an attempt at reducing the detectability of the noise without modifying the step size. This is done by modifying the phase relationship between the audio signal, x k , and quantization noise, n k .
- the audio signal is requantized using the same quantizer step size, and the detectability metric is recomputed. If the detectability metric is now below the threshold, coding is complete for the segment. Otherwise, the quantizer step size is reduced and the audio signal is requantized. The detectability metric is recomputed and the above possibilities reexamined.
- FIG. 15 presents an illustrative embodiment of the present invention which employs analysis and synthesis features.
- the analysis feature of this embodiment has two components: (i) an analysis of the audio signal for the purpose of a loudness computation, and (ii) an analysis of the audio signal for purposes of quantization.
- the audio signal to be coded x(i) is provided to a loudness computation processor 10 for a determination of signal loudness in each of a plurality of signal subbands.
- the details of the loudness computation are performed in FIG. 16.
- the loudness computation is presented on a subband basis and can be understood for all K subbands of a cochlear filterbank 11 by focusing on subband k.
- the number of subbands, K of the cochlear filterbank depends on how accurately the basilar membrane of the cochlea is to be modeled for a particular audio signal bandwidth. For example, for 20 kHz CD-quality audio, the number of subbands in the filterbank may be about 80.
- Cochlear filterbanks suitable for use in realizing an embodiment of the invention are well known in the art. See, e.g., Allen, 68 J. Acoust. Soc. Am., 1660-70 (1980); and Allen, et al., 95 J. Acoust Soc. Am, 3006 (1994).
- Signal x(i) is provided to each filter of the cochlear filterbank 11.
- Filter 11-k generates the kth cochlear subband of signal, x k , for subsequent processing.
- This subband signal is passed through a non-linearity comprising of a squaring function 12-k and a cube-root function 14-k.
- the resulting signal, x 2/3 .sbsp.k, is then integrated over a 5 ms interval by integrator 16-k.
- the non-linearity is an approximation for the shape of a loudness growth function and is a good approximation based on current research. However, better approximations of this non-linearity may become available in the future.
- the 5 ms. integration interval may be varied.
- the integrated signal is then scaled by a factor ⁇ .
- the scale factor is used to ensure that the detectability metric can be compared to a threshold of approximately 1.
- the result is a measure of loudness for the subband signal, L k .
- the loudness computation 10 outputs a plurality of loudness measures, one for each subband.
- the audio signal, x(i) is provided to a variable resolution analysis filterbank (VRAF) 70.
- This filterbank 70 performs a modified discrete cosine transform (MDCT) of the signal for subsequent use in quantization.
- MDCT discrete cosine transform
- the MDCT is a subband decomposition filterbank that provides maximally decimated, uniform frequency resolution subbands. It also allows a perfect reconstruction of the filtered signal and therefore is particularly suited for coding techniques.
- the variability of the MDCT resolution pertains to the number of subbands it generates (i.e., the frequency resolution of the MDCT).
- VRAF 70 varies the number of subbands according to variability of loudness with time. The details of VRAF 70 are presented in FIG. 17.
- the VRAF 70 comprises a buffer memory 72 and a conventional variable resolution MDCT processor 74.
- the resolution of the MDCT processor 74 i.e., the number of subbands
- L k the resolution of the MDCT processor 74
- the audio signal, x(i) is buffered in memory 72 in order to allow the loudness computation 10 referenced above to precede the performance of the MDCT on the same segment of the audio signal, x(i).
- Buffer memory 72 stores two consecutive segments of 1024 input samples of the audio signal, and provides sufficient memory and control for a conventional 50% overlap "lapped" transform (or filtering) operation.
- MDCT processor 74 performs a conventional lapped transform of the buffered segments (2048 samples) with a resolution, M, as determined by a signal from resolution control processor 60.
- MDCT processor 74 generates a vector of output M subband samples (MDCT coefficients), s m , 1 ⁇ m ⁇ M for each input segment of input samples from buffer 72.
- MDCT coefficients M subband samples
- s m 1 ⁇ m ⁇ M
- output vectors are provided to quantization processor 80, discussed below.
- Resolution control 60 determines which of two frequency resolutions for the VRAF is appropriate for a given segment of the audio signal. Those of skill in the art will recognize that a greater number of frequency resolutions could be chosen for use with the embodiment for enhanced coding efficiency. Also, non-uniform frequency subbands could be employed. Resolution control 60 buffers the loudness measures (provided by computation 10) for each cochlear subband, L k , 1 ⁇ k ⁇ K, corresponding to a given segment. For each of the subbands, control 60 forms the absolute difference between the minimum and maximum values for L k (in that band) for the segment and compares it against a threshold. Illustratively, this threshold is 100. Control 60 counts the number of subbands where this difference exceeds the threshold.
- the MDCT subbands are grouped into a smaller set of coder bands, indexed by j.
- the grouping of MDCT subbands into coder bands approximates the critical band divisions of the human auditory system, as is conventional in the art. J. D. Johnston and K. Brandenberg, "Wideband Coding-Perceptual Considerations for Speech and Music," Advances in Speech Signal Processing, edited by S. Furui and M. M. Sondhi (1992).
- Grouping refers to the fact that each MDCT subband of a group will be quantized at the same stepsize and will have the same phase control treatment.
- Quantization processor 80 receives output vectors from VRAF 70 and quantizes these vectors according to a set of initial loudness signals output from loudness computation 10 and output from the differential loudness detectability processor 20. Quantization is performed for each vector received from VRAF 70.
- Processor 80 in FIG. 19 comprises quantizer step size control 85 which is coupled to phase control 83 and quantizer 86.
- Phase control 83 is further coupled to a memory 87, referred to as the waveform dictionary, which provides signals for modifying coder band data to effect phase variations between corresponding quantizer noise signals and original audio signals.
- Quantizer step size control 85 receives an initial quantizer threshold from processor 82 for each vector based upon subband loudness signals received from loudness computation 10.
- Quantizer step size control 85 also receives information from DLDP 20 pertaining to those coder subbands which may require either phase control or modified quantizer step size.
- Coder subband information is provided by mapping function 84 which selects appropriate coder subbands associated with a particular cochlear subband with use of a stored relationship (mapping) 81 between cochlear subbands and coder subbands.
- the coder band to cochlear band mapping memory 81 is a two-way associativity map between the K cochlear subbands and N coder bands, i.e., it is a K ⁇ N matrix whose (i,j) th element is 1 if the i th cochlear band and j th coder band associate with each other. This is determined by looking at the magnitude response of cochlear filter, i. If the magnitude response of i th filter is more than -25 dB (illustratively) of its peak response within the passband of j th coder band, the associativity is true.
- mapping 81 is used by both mapping function 84, which generates a list of coder bands associated with a particular cochlear band, and by the initial stepsize processor 82, which needs a list of cochlear subbands associated with a particular coder band.
- an initial quantizer step size, ⁇ j for each coder band needs to be calculated. This calculation is performed by initial stepsize processor 82.
- Processor 82 begins by computing the average energy in a coder band, I j , for each j. This average energy is equal to the sum of the squared values of the MDCT subband signals belonging to the coder band, j, divided by the number of MDCT subbands in the coder band.
- a minimum loudness measure is determined. This is done by first determining the minimum loudness value over time for each group of M coefficients (corresponding to the incoming vector from VRAF 70) of each cochlear subband, where M is the above-referenced frequency resolution. Next, based on the mapping from memory 81, the minimum of the previously determined minimum loudness values associated with the coder band is determined for each coder band, L j min .
- the noise power for each coder band, N j is illustratively computed as follows: ##EQU12##
- the initial quantizer stepsize, ⁇ j for each coder band is determined as follows: ##EQU13##
- processor 80 For each coder band, processor 80 quantizes all MDCT coefficients corresponding to the coder band with conventional uniform quantizer 86 employing stepsize ⁇ j . Phase control 83 performs no function at this time.
- Quantized values are further compressed using a conventional lossless encoding technique, such as Huffman encoding 100, to generate a coded bitstream. This bitstream is then made available to the synthesis portion of the coder.
- a conventional lossless encoding technique such as Huffman encoding 100
- Decoder 110 performs the reverse of the procedure applied by the noiseless coder 100 (i.e., decoder 110 performs conventional Huffman decoding).
- the output signal of decoder 110 corresponds to the output signal of quantization processor 80.
- This signal is then dequantized by dequantizer 120.
- Dequantizer 120 performs the reverse of the quantizer process performed by processor 80 given side information of quantizer step size and phase control.
- the output of dequantizer 120 is a set of subband signals which corresponds to the output of VRAF 70.
- VRAF -1 inverse MDCT processor 130 which performs the inverse of the process performed by VRAF 70 given side information concerning the frequency resolution, M.
- VRAF -1 inverse MDCT processor
- Signal x(i) is applied to loudness computation processor 30 which is identical to the loudness computation 10 discussed above.
- the result is a set of time-varying subband loudness signals, L k , which represents the loudness associated with x(i) (i.e., the loudness associated with the sum of quantization noise added to the original audio signal.)
- L k represents the loudness associated with x(i) (i.e., the loudness associated with the sum of quantization noise added to the original audio signal.)
- the result of this loudness computation depends on the phase relationship between the original audio signal and the noise signal.
- the degree to which these signals constructively interfere as a result of relative phase will affect overall loudness, L k .
- it is not merely relative signal and noise power (or energy) which is important.
- the illustrative embodiment actually exploits relative phase relationships in the coding process, as discussed below.
- Loudness signals L k provided by loudness computation 30 and loudness signals L k provided by loudness computation 10 are both supplied to differential loudness detectability processor (DLDP) 20 for the computation of a time-varying, subband metric, d' k (i).
- This metric is given by the following expression: ##EQU14## where ⁇ L k (i) is an estimate of the uncertainty associated with auditory neural encoding of the loudness (see discussion above). Such uncertainty may be represented by the standard deviation of a Poisson process, L, having a mean L k . Thus the standard deviation is given by ⁇ L k .
- the ratio facilitates a comparison of differential loudness to the measure of uncertainty associated with loudness (such a comparison could be made in a number of alternative ways). When differential loudness is larger than ⁇ L, then the coding noise will have a high probability of being audible (detectable); otherwise, coding noise will have a low probability of being audible.
- Values of d' k (i) for all i of a given segment of audio signal are compared to a detectability threshold, illustratively equal to one, and the differences stored. This comparison is made for all subbands independently. If all of the values of d' k (i) are below one but not below a second threshold, illustratively 0.9, the segment will likely not include audible coding noise in a frequency range close to the passband of cochlear subband k and will not be severely overcoded. Coding for the segment is complete if this test is satisfied for all k.
- the value of the second threshold affects how efficiently available bits will be utilized in coding, as well as coder complexity.
- signals are passed to quantization processor 80: (i) k, indicating the cochlear subband needing further processing; and (ii) the condition of overcoding or undercoding.
- Quantizer steps ize Control in the Quantization Processor
- Quantization processor 80 provides additional processing of MDCT coefficient data grouped according to coder bands according to the conditions discussed above. There are two modes of additional processing corresponding to the two conditions of noise detectability and overcoding. The first mode, corresponding to unmasked noise, involves phase control processing by processor 83 in combination with waveform dictionary 87 and, if needed, subsequent requantization with reduced stepsize. The second mode, corresponding to overcoding, involves requantization at increased stepsize. Prior to any remedial processing for these conditions, each cochlear subband index, k, provided by DLDP 20, is mapped into a list of one or more coder band indices j by mapping function 84 employing conventional table look-up in map 81 (described above).
- phase control process 83 For all coder bands j provided by mapping function 84 which require remedial action for unmasked noise, the phase control process 83 referenced above is sequentially applied for each band. This process adjusts the phase of the audio signal relative to a quantization noise signal by subtracting a scaled vector of random values (provided by a waveform dictionary 87, discussed below) from the vector of MDCT coefficients corresponding to the coder band j.
- the waveform dictionary 87 is scaled (multiplied) by the value of the quantizer stepsize for this band.
- the result of the subtraction is a vector which is then requantized by quantizer 86.
- Quantizer 86 uses the same stepsize as previously used for this coder band.
- the output of the quantizer 86 is applied to compression 100, and further to the synthesis process (110, 120, 130, and 30) to regenerate synthesized loudness, L k .
- DLDP 20 updates detectability measures d' k , which are then compared to previously computed d' k to determine whether any of the d' k which were previously above one have now been reduced without making any of the previously masked cochlear bands unmasked. If any of the previously masked cochlear bands have become unmasked, the phase control vector subtraction is disregarded. Otherwise, the number of cochlear subbands which have had reduced d' k is stored and the next dictionary entry is tried.
- the entry which has the largest number of reduced d' k values is identified and associated with the coder band j.
- the modified MDCT coefficients (modified due to vector subtraction) associated with the best entry are stored. If all entries result in unmasking one or more previously masked cochlear bands, then the MDCT coefficients corresponding to this coder band are left unchanged.
- An additional synthesis process is performed using quantized MDCT coefficients corresponding to the best entry to update the d' k values for that entry (which may have been lost during the above-referenced search).
- the list of coder bands that require processing to remedy unmasked noise is updated based on the best set of d' k values in the fashion described above (see discussion of mapping function 84). For the coder bands that are thus identified to require further processing for unmasked noise, any phase adjustment activated at a previous step is deactivated now.
- Quantizer stepsize is reduced for all of the coder bands in the updated list. The stepsize is reduced by multiplication with a constant less than one, illustratively 0.9. Requantization of all coder in the list is then performed. The synthesis process is also performed, culminating in the recalculation of the d' k values.
- the list of coder bands which require remedial action for unmasked noise is updated as previously discussed.
- Waveform dictionary 87 contains subdictionaries, each associated with a coder band size. Each subdirectory contains normalized vectors of a fixed length whose entries are generated by a Gaussian random number generator. As is clear from FIGS. 18A and 18B, the coder bands are of size 2 k , k-2,3,4,5,6. There is a subdirectory of dimension 2 k-2 for each k.
- quantizer stepsize is increased to relieve the condition. Processing of such coder bands will occur one band at a time. For each such coder band, quantizer stepsize will be increased by a factor greater than one, illustratively, 1.1.
- the coder band MDCT coefficients are then requantized and the synthesis process is performed. Updated values of d' k are computed and checked to determine whether any such values is greater than one. If not, the stepsize is again increased and the synthesis repeated. If any value of d' k exceeds one (as a result of any application of increased stepsize), the stepsize immediately preceding this condition is chose as the final stepsize for this coder band. All other overcoded coder bands are processed in this fashion in sequence.
- the output of the quantization processor 80 for each vector of MDCT coefficients will include quantized MDCT coefficients and side information for each coder band.
- Side information will include (per coder band) quantizer stepsize, an index to a dictionary entry selected by the phase control processing (an index of zero indicates no phase control processing for this coder band), and (per vector) information for resolution control of the inverse MDCT processor 130.
- processor 80 outputs a flag indicating that current processor 80 output is for use in transmission over a channel.
- This flag, T x is provided to transmitter 140 which provides coder output as a coded bit stream over the communication channel.
- the channel may comprise an actual transmission channel (such as a wired or wireless transmission channel, a telecommunications network, the Internet or other computer networks, LANs, WANs, MANs, etc.) and/or a storage medium (such as a compact disk (CD), CD-ROM, semiconductor memory, magnetic tape or disk, optical storage, etc).
- the synthesizer portion of the encoder contains a decoder suitable for use with the encoder.
- This decoder comprises the combination of the noiseless decoder 110, dequantizer 120, and inverse MDCT processor 130, as discussed above with reference to the synthesizer portion of the encoder presented in FIG. 15.
- an embodiment of the present invention may estimate a measure of loudness uncertainty as a measure of the variation of signal amplitude over time.
- This measure may be of the signal itself or a related quantity, such as signal energy.
- Such measures may be employed in traditional tonality approach to noise masking. See, e.g., U.S. patent application Ser. No. 08/384,097, entitled “Tonality for Perceptual audio Compression Based on Loudness Uncertainty,” assigned to the assigned hereof and filed on even date herewith, and incorporated herein by reference.
- the illustrative embodiment may be extended to provide for the coding of stereo audio using well-known sum/difference encoding techniques. See, J. D. Johnston and A. J. Ferreira, "Sum-Difference Stereo Transform Coding," Proceedings of IEEE, ICASSP, San Francisco, II-569-572 (1992). ##SPC1##
Abstract
Description
Masking stimulus≡m.sub.T =m(t) tε 0, T!. (1)
Probe stimulus≡p.sub.T =p(t) tε 0, T!. (2)
p(t)=αm(t),tm (8)
ΔI=(2α+α.sup.2)I m.sub.T !≈2αI m.sub.T ! (for small α). (9)
N=G+e(G), (11)
e=Normal (μ=0, σ.sup.2.sub.G), (13)
λ(s)αs.sup.c, (14)
G(noise)=Normal(μ.sub.noise, σ.sup.2.sub.noise). (15)
μ.sub.noise =E G(noise of intensity I)!≈G(tone of intensity I),(16)
E N.sub.I+ΔI !=E N.sub.I !+ΔI (17)
=E N.sub.I !+β((I+ΔI).sup.1/3 -I.sup.1/3), (18)
E G.sub.I+ΔI !=E G.sub.I !+β((I+ΔI).sup.1/3 -I.sup.1/3),(19)
σ.sub.N =E N.sub.I+ΔI !-E N.sub.I ! (20)
=β((I+ΔI).sup.1/3 -I.sup.1/). (21)
P.sub.C =∫p(N.sub.masker+probe =n)·P(N.sub.masker <n)dn,(22)
Z.sub.dB =10 log (N.sub.comp -1)A.sup.2.sub.comp -Y.sup.2 !,(35)
Claims (51)
Priority Applications (6)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US08/384,049 US5682463A (en) | 1995-02-06 | 1995-02-06 | Perceptual audio compression based on loudness uncertainty |
CA002167967A CA2167967A1 (en) | 1995-02-06 | 1996-01-24 | Perceptual audio compression based on loudness uncertainty |
EP96300698A EP0725494B1 (en) | 1995-02-06 | 1996-01-31 | Perceptual audio compression based on loudness uncertainty |
ES96300698T ES2142543T3 (en) | 1995-02-06 | 1996-01-31 | PERCEPTIVE AUDIO COMPRESSION BASED ON THE UNCERTAINTY OF SOUND VOLUME. |
DE69602773T DE69602773T2 (en) | 1995-02-06 | 1996-01-31 | Perceptual audio compression based on loudness uncertainty |
JP8053589A JPH08272399A (en) | 1995-02-06 | 1996-02-06 | Perception speech compression based on loudness uncertainty |
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US08/384,049 US5682463A (en) | 1995-02-06 | 1995-02-06 | Perceptual audio compression based on loudness uncertainty |
Publications (1)
Publication Number | Publication Date |
---|---|
US5682463A true US5682463A (en) | 1997-10-28 |
Family
ID=23515820
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US08/384,049 Expired - Lifetime US5682463A (en) | 1995-02-06 | 1995-02-06 | Perceptual audio compression based on loudness uncertainty |
Country Status (6)
Country | Link |
---|---|
US (1) | US5682463A (en) |
EP (1) | EP0725494B1 (en) |
JP (1) | JPH08272399A (en) |
CA (1) | CA2167967A1 (en) |
DE (1) | DE69602773T2 (en) |
ES (1) | ES2142543T3 (en) |
Cited By (73)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6000833A (en) * | 1997-01-17 | 1999-12-14 | Massachusetts Institute Of Technology | Efficient synthesis of complex, driven systems |
WO2000017855A1 (en) * | 1998-09-23 | 2000-03-30 | Samsung Electronics Co., Ltd. | Noise suppression for low bitrate speech coder |
US6055502A (en) * | 1997-09-27 | 2000-04-25 | Ati Technologies, Inc. | Adaptive audio signal compression computer system and method |
US6091773A (en) * | 1997-11-12 | 2000-07-18 | Sydorenko; Mark R. | Data compression method and apparatus |
US6092040A (en) * | 1997-11-21 | 2000-07-18 | Voran; Stephen | Audio signal time offset estimation algorithm and measuring normalizing block algorithms for the perceptually-consistent comparison of speech signals |
US6144937A (en) * | 1997-07-23 | 2000-11-07 | Texas Instruments Incorporated | Noise suppression of speech by signal processing including applying a transform to time domain input sequences of digital signals representing audio information |
US6246978B1 (en) * | 1999-05-18 | 2001-06-12 | Mci Worldcom, Inc. | Method and system for measurement of speech distortion from samples of telephonic voice signals |
US20010032086A1 (en) * | 2000-02-18 | 2001-10-18 | Shahab Layeghi | Fast convergence method for bit allocation stage of mpeg audio layer 3 encoders |
US6405338B1 (en) * | 1998-02-11 | 2002-06-11 | Lucent Technologies Inc. | Unequal error protection for perceptual audio coders |
US6456963B1 (en) * | 1999-03-23 | 2002-09-24 | Ricoh Company, Ltd. | Block length decision based on tonality index |
US6466912B1 (en) | 1997-09-25 | 2002-10-15 | At&T Corp. | Perceptual coding of audio signals employing envelope uncertainty |
US20040162723A1 (en) * | 2001-09-27 | 2004-08-19 | Lopez-Estrada Alex A. | Method, apparatus, and system for efficient rate control in audio encoding |
US6813600B1 (en) * | 2000-09-07 | 2004-11-02 | Lucent Technologies Inc. | Preclassification of audio material in digital audio compression applications |
US20050165587A1 (en) * | 2004-01-27 | 2005-07-28 | Cheng Corey I. | Coding techniques using estimated spectral magnitude and phase derived from mdct coefficients |
US20050240412A1 (en) * | 2004-04-07 | 2005-10-27 | Masahiro Fujita | Robot behavior control system and method, and robot apparatus |
WO2005008582A3 (en) * | 2003-06-13 | 2005-12-15 | Nielsen Media Res Inc | Methods and apparatus for embedding watermarks |
US20060262938A1 (en) * | 2005-05-18 | 2006-11-23 | Gauger Daniel M Jr | Adapted audio response |
US20060293884A1 (en) * | 2004-03-01 | 2006-12-28 | Bernhard Grill | Apparatus and method for determining a quantizer step size |
US20070092089A1 (en) * | 2003-05-28 | 2007-04-26 | Dolby Laboratories Licensing Corporation | Method, apparatus and computer program for calculating and adjusting the perceived loudness of an audio signal |
US20070162277A1 (en) * | 2006-01-12 | 2007-07-12 | Stmicroelectronics Asia Pacific Pte., Ltd. | System and method for low power stereo perceptual audio coding using adaptive masking threshold |
WO2007120452A1 (en) * | 2006-04-04 | 2007-10-25 | Dolby Laboratories Licensing Corporation | Audio signal loudness measurement and modification in the mdct domain |
US20070276656A1 (en) * | 2006-05-25 | 2007-11-29 | Audience, Inc. | System and method for processing an audio signal |
US20070291959A1 (en) * | 2004-10-26 | 2007-12-20 | Dolby Laboratories Licensing Corporation | Calculating and Adjusting the Perceived Loudness and/or the Perceived Spectral Balance of an Audio Signal |
US20070300066A1 (en) * | 2003-06-13 | 2007-12-27 | Venugopal Srinivasan | Method and apparatus for embedding watermarks |
US20080004873A1 (en) * | 2006-06-28 | 2008-01-03 | Chi-Min Liu | Perceptual coding of audio signals by spectrum uncertainty |
WO2007135198A3 (en) * | 2007-07-31 | 2008-01-17 | Phonak Ag | Method for adjusting a hearing device with frequency transposition and corresponding arrangement |
US20080318785A1 (en) * | 2004-04-18 | 2008-12-25 | Sebastian Koltzenburg | Preparation Comprising at Least One Conazole Fungicide |
US20090012783A1 (en) * | 2007-07-06 | 2009-01-08 | Audience, Inc. | System and method for adaptive intelligent noise suppression |
US20090323982A1 (en) * | 2006-01-30 | 2009-12-31 | Ludger Solbach | System and method for providing noise suppression utilizing null processing noise subtraction |
US7742737B2 (en) | 2002-01-08 | 2010-06-22 | The Nielsen Company (Us), Llc. | Methods and apparatus for identifying a digital audio signal |
US20100158263A1 (en) * | 2008-12-23 | 2010-06-24 | Roman Katzer | Masking Based Gain Control |
WO2010077361A1 (en) * | 2008-12-31 | 2010-07-08 | Audience, Inc. | Systems and methods for reconstructing decomposed audio signals |
US20100198378A1 (en) * | 2007-07-13 | 2010-08-05 | Dolby Laboratories Licensing Corporation | Audio Processing Using Auditory Scene Analysis and Spectral Skewness |
US20100202632A1 (en) * | 2006-04-04 | 2010-08-12 | Dolby Laboratories Licensing Corporation | Loudness modification of multichannel audio signals |
US20100202631A1 (en) * | 2009-02-06 | 2010-08-12 | Short William R | Adjusting Dynamic Range for Audio Reproduction |
US20100250258A1 (en) * | 2004-07-01 | 2010-09-30 | Dolby Laboratories Licensing Corporation | Method for Correcting Metadata Affecting the Playback Loudness of Audio Information |
US20100272285A1 (en) * | 2009-04-22 | 2010-10-28 | General Electric Company | Masking of pure tones within sound from a noise generating source |
US7853124B2 (en) | 2004-04-07 | 2010-12-14 | The Nielsen Company (Us), Llc | Data insertion apparatus and methods for use with compressed audio/video data |
US20110009987A1 (en) * | 2006-11-01 | 2011-01-13 | Dolby Laboratories Licensing Corporation | Hierarchical Control Path With Constraints for Audio Dynamics Processing |
US20110150229A1 (en) * | 2009-06-24 | 2011-06-23 | Arizona Board Of Regents For And On Behalf Of Arizona State University | Method and system for determining an auditory pattern of an audio segment |
US20110235813A1 (en) * | 2005-05-18 | 2011-09-29 | Gauger Jr Daniel M | Adapted Audio Masking |
US8078301B2 (en) | 2006-10-11 | 2011-12-13 | The Nielsen Company (Us), Llc | Methods and apparatus for embedding codes in compressed audio data streams |
US8143620B1 (en) | 2007-12-21 | 2012-03-27 | Audience, Inc. | System and method for adaptive classification of audio sources |
US8144881B2 (en) | 2006-04-27 | 2012-03-27 | Dolby Laboratories Licensing Corporation | Audio gain control using specific-loudness-based auditory event detection |
US8180064B1 (en) | 2007-12-21 | 2012-05-15 | Audience, Inc. | System and method for providing voice equalization |
US8189766B1 (en) | 2007-07-26 | 2012-05-29 | Audience, Inc. | System and method for blind subband acoustic echo cancellation postfiltering |
US8194882B2 (en) | 2008-02-29 | 2012-06-05 | Audience, Inc. | System and method for providing single microphone noise suppression fallback |
US8194880B2 (en) | 2006-01-30 | 2012-06-05 | Audience, Inc. | System and method for utilizing omni-directional microphones for speech enhancement |
US8199933B2 (en) | 2004-10-26 | 2012-06-12 | Dolby Laboratories Licensing Corporation | Calculating and adjusting the perceived loudness and/or the perceived spectral balance of an audio signal |
US8204252B1 (en) | 2006-10-10 | 2012-06-19 | Audience, Inc. | System and method for providing close microphone adaptive array processing |
US8204253B1 (en) | 2008-06-30 | 2012-06-19 | Audience, Inc. | Self calibration of audio device |
US8259926B1 (en) | 2007-02-23 | 2012-09-04 | Audience, Inc. | System and method for 2-channel and 3-channel acoustic echo cancellation |
US8345890B2 (en) | 2006-01-05 | 2013-01-01 | Audience, Inc. | System and method for utilizing inter-microphone level differences for speech enhancement |
US8355511B2 (en) | 2008-03-18 | 2013-01-15 | Audience, Inc. | System and method for envelope-based acoustic echo cancellation |
US20130073281A1 (en) * | 2007-12-18 | 2013-03-21 | Fujitsu Limited | Non-speech section detecting method and non-speech section detecting device |
US8412363B2 (en) | 2004-07-02 | 2013-04-02 | The Nielson Company (Us), Llc | Methods and apparatus for mixing compressed digital bit streams |
US8521530B1 (en) | 2008-06-30 | 2013-08-27 | Audience, Inc. | System and method for enhancing a monaural audio signal |
US8774423B1 (en) | 2008-06-30 | 2014-07-08 | Audience, Inc. | System and method for controlling adaptivity of signal modification using a phantom coefficient |
US8849231B1 (en) | 2007-08-08 | 2014-09-30 | Audience, Inc. | System and method for adaptive power control |
US8849433B2 (en) | 2006-10-20 | 2014-09-30 | Dolby Laboratories Licensing Corporation | Audio dynamics processing using a reset |
US8892426B2 (en) | 2008-12-24 | 2014-11-18 | Dolby Laboratories Licensing Corporation | Audio signal loudness determination and modification in the frequency domain |
US8949120B1 (en) | 2006-05-25 | 2015-02-03 | Audience, Inc. | Adaptive noise cancelation |
US9008329B1 (en) | 2010-01-26 | 2015-04-14 | Audience, Inc. | Noise reduction using multi-feature cluster tracker |
US9237400B2 (en) | 2010-08-24 | 2016-01-12 | Dolby International Ab | Concealment of intermittent mono reception of FM stereo radio receivers |
US9378754B1 (en) | 2010-04-28 | 2016-06-28 | Knowles Electronics, Llc | Adaptive spatial classifier for multi-microphone systems |
US9437180B2 (en) | 2010-01-26 | 2016-09-06 | Knowles Electronics, Llc | Adaptive noise reduction using level cues |
US9536540B2 (en) | 2013-07-19 | 2017-01-03 | Knowles Electronics, Llc | Speech signal separation and synthesis based on auditory scene analysis and speech modeling |
US9685921B2 (en) | 2012-07-12 | 2017-06-20 | Dts, Inc. | Loudness control with noise detection and loudness drop detection |
US9820042B1 (en) | 2016-05-02 | 2017-11-14 | Knowles Electronics, Llc | Stereo separation and directional suppression with omni-directional microphones |
US9838784B2 (en) | 2009-12-02 | 2017-12-05 | Knowles Electronics, Llc | Directional audio capture |
US9978388B2 (en) | 2014-09-12 | 2018-05-22 | Knowles Electronics, Llc | Systems and methods for restoration of speech components |
US10374564B2 (en) | 2017-04-20 | 2019-08-06 | Dts, Inc. | Loudness control with noise detection and loudness drop detection |
CN115171709A (en) * | 2022-09-05 | 2022-10-11 | 腾讯科技（深圳）有限公司 | Voice coding method, voice decoding method, voice coding device, voice decoding device, computer equipment and storage medium |
Families Citing this family (1)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6978236B1 (en) * | 1999-10-01 | 2005-12-20 | Coding Technologies Ab | Efficient spectral envelope coding using variable time/frequency resolution and time/frequency switching |
Citations (8)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5040217A (en) * | 1989-10-18 | 1991-08-13 | At&T Bell Laboratories | Perceptual coding of audio signals |
US5157760A (en) * | 1990-04-20 | 1992-10-20 | Sony Corporation | Digital signal encoding with quantizing based on masking from multiple frequency bands |
US5227788A (en) * | 1992-03-02 | 1993-07-13 | At&T Bell Laboratories | Method and apparatus for two-component signal compression |
US5285498A (en) * | 1992-03-02 | 1994-02-08 | At&T Bell Laboratories | Method and apparatus for coding audio signals based on perceptual model |
US5311561A (en) * | 1991-03-29 | 1994-05-10 | Sony Corporation | Method and apparatus for compressing a digital input signal with block floating applied to blocks corresponding to fractions of a critical band or to multiple critical bands |
US5341457A (en) * | 1988-12-30 | 1994-08-23 | At&T Bell Laboratories | Perceptual coding of audio signals |
US5375189A (en) * | 1991-09-30 | 1994-12-20 | Sony Corporation | Apparatus and method for audio data compression and expansion with reduced block floating overhead |
US5490170A (en) * | 1991-03-29 | 1996-02-06 | Sony Corporation | Coding apparatus for digital signal |
-
1995
- 1995-02-06 US US08/384,049 patent/US5682463A/en not_active Expired - Lifetime
-
1996
- 1996-01-24 CA CA002167967A patent/CA2167967A1/en not_active Abandoned
- 1996-01-31 ES ES96300698T patent/ES2142543T3/en not_active Expired - Lifetime
- 1996-01-31 EP EP96300698A patent/EP0725494B1/en not_active Expired - Lifetime
- 1996-01-31 DE DE69602773T patent/DE69602773T2/en not_active Expired - Fee Related
- 1996-02-06 JP JP8053589A patent/JPH08272399A/en active Pending
Patent Citations (8)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US5341457A (en) * | 1988-12-30 | 1994-08-23 | At&T Bell Laboratories | Perceptual coding of audio signals |
US5040217A (en) * | 1989-10-18 | 1991-08-13 | At&T Bell Laboratories | Perceptual coding of audio signals |
US5157760A (en) * | 1990-04-20 | 1992-10-20 | Sony Corporation | Digital signal encoding with quantizing based on masking from multiple frequency bands |
US5311561A (en) * | 1991-03-29 | 1994-05-10 | Sony Corporation | Method and apparatus for compressing a digital input signal with block floating applied to blocks corresponding to fractions of a critical band or to multiple critical bands |
US5490170A (en) * | 1991-03-29 | 1996-02-06 | Sony Corporation | Coding apparatus for digital signal |
US5375189A (en) * | 1991-09-30 | 1994-12-20 | Sony Corporation | Apparatus and method for audio data compression and expansion with reduced block floating overhead |
US5227788A (en) * | 1992-03-02 | 1993-07-13 | At&T Bell Laboratories | Method and apparatus for two-component signal compression |
US5285498A (en) * | 1992-03-02 | 1994-02-08 | At&T Bell Laboratories | Method and apparatus for coding audio signals based on perceptual model |
Non-Patent Citations (22)
Title |
---|
Allen et al., J. Acoust. Soc. Am., vol. 95, pp. 3006 (1994). * |
Allen, J.B., "Cochlear Micromechanics -A Physical Model of Transduction," J. Acoust. Soc. Am., vol.68, pp. 1660-1670 (1980). |
Allen, J.B., Cochlear Micromechanics A Physical Model of Transduction, J. Acoust. Soc. Am., vol.68, pp. 1660 1670 (1980). * |
Buus, S., "Level Discrimination of Frozen and Random Noise," J. Acost. Soc. Am., vol. 87, No. 6, pp. 2643-2654, Jun. 1990. |
Buus, S., Level Discrimination of Frozen and Random Noise, J. Acost. Soc. Am., vol. 87, No. 6, pp. 2643 2654, Jun. 1990. * |
Edler, "Coding of Audio Signals with Overlapping Block Transform and Adaptive Window Functions," Frequenz, vol. 43, pp. 252-256(1989). |
Edler, Coding of Audio Signals with Overlapping Block Transform and Adaptive Window Functions, Frequenz, vol. 43, pp. 252 256(1989). * |
Hellman, W. S. et al., "Intensity Discrimination as the Driving Force for Loudness," J. Acoust. Soc. Am., vol. 87, No. 3, pp. 1255-1265, Mar. 1990. |
Hellman, W. S. et al., Intensity Discrimination as the Driving Force for Loudness, J. Acoust. Soc. Am., vol. 87, No. 3, pp. 1255 1265, Mar. 1990. * |
Johnston et al., "Sum-Difference Stereo Transform Coding," Proc. of IEEE, ICASSP, San Francisco, II-569-572 (1992). |
Johnston et al., "Wideband Coding-Perceptual Considerations for Speech and Music," Advances in Speech Signal Processing, Furui et al., ed. (1992). |
Johnston et al., Sum Difference Stereo Transform Coding, Proc. of IEEE, ICASSP, San Francisco, II 569 572 (1992). * |
Johnston et al., Wideband Coding Perceptual Considerations for Speech and Music, Advances in Speech Signal Processing, Furui et al., ed. (1992). * |
Schroeder, M. R. et al., "Optimizing Digital Speech Coders by Exploiting Masking Properties of the Human Ear," J. Acoustic Soc. Am., vol. 66, No. 6, pp. 1647-1652, Dec. 1979. |
Schroeder, M. R. et al., Optimizing Digital Speech Coders by Exploiting Masking Properties of the Human Ear, J. Acoustic Soc. Am., vol. 66, No. 6, pp. 1647 1652, Dec. 1979. * |
Teich, M. C. et al., "Pulse-number Distribution for the Neural Spike Train in the Cat's Auditory Nerve," J. Acoust. Soc. Am., vol. 77, pp. 1110-1128, 1985. |
Teich, M. C. et al., Pulse number Distribution for the Neural Spike Train in the Cat s Auditory Nerve, J. Acoust. Soc. Am., vol. 77, pp. 1110 1128, 1985. * |
U.S. application No. 07/844811, (Johnston 16), filed Mar. 2, 1992. * |
U.S. application No. 07/844819, (Ferreira 1 15), filed Mar. 2, 1992. * |
U.S. application No. 07/844819, (Ferreira 1-15), filed Mar. 2, 1992. |
U.S. application No. 08/384097, (Allen 13 5 37 2), filed Feb. 6, 1995. * |
U.S. application No. 08/384097, (Allen 13-5-37-2), filed Feb. 6, 1995. |
Cited By (169)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6000833A (en) * | 1997-01-17 | 1999-12-14 | Massachusetts Institute Of Technology | Efficient synthesis of complex, driven systems |
US6144937A (en) * | 1997-07-23 | 2000-11-07 | Texas Instruments Incorporated | Noise suppression of speech by signal processing including applying a transform to time domain input sequences of digital signals representing audio information |
US6466912B1 (en) | 1997-09-25 | 2002-10-15 | At&T Corp. | Perceptual coding of audio signals employing envelope uncertainty |
US6055502A (en) * | 1997-09-27 | 2000-04-25 | Ati Technologies, Inc. | Adaptive audio signal compression computer system and method |
US6091773A (en) * | 1997-11-12 | 2000-07-18 | Sydorenko; Mark R. | Data compression method and apparatus |
US6092040A (en) * | 1997-11-21 | 2000-07-18 | Voran; Stephen | Audio signal time offset estimation algorithm and measuring normalizing block algorithms for the perceptually-consistent comparison of speech signals |
US6405338B1 (en) * | 1998-02-11 | 2002-06-11 | Lucent Technologies Inc. | Unequal error protection for perceptual audio coders |
WO2000017855A1 (en) * | 1998-09-23 | 2000-03-30 | Samsung Electronics Co., Ltd. | Noise suppression for low bitrate speech coder |
US6456963B1 (en) * | 1999-03-23 | 2002-09-24 | Ricoh Company, Ltd. | Block length decision based on tonality index |
US6564181B2 (en) * | 1999-05-18 | 2003-05-13 | Worldcom, Inc. | Method and system for measurement of speech distortion from samples of telephonic voice signals |
US6246978B1 (en) * | 1999-05-18 | 2001-06-12 | Mci Worldcom, Inc. | Method and system for measurement of speech distortion from samples of telephonic voice signals |
US20010032086A1 (en) * | 2000-02-18 | 2001-10-18 | Shahab Layeghi | Fast convergence method for bit allocation stage of mpeg audio layer 3 encoders |
US6999919B2 (en) * | 2000-02-18 | 2006-02-14 | Intervideo, Inc. | Fast convergence method for bit allocation stage of MPEG audio layer 3 encoders |
US6813600B1 (en) * | 2000-09-07 | 2004-11-02 | Lucent Technologies Inc. | Preclassification of audio material in digital audio compression applications |
US20040162723A1 (en) * | 2001-09-27 | 2004-08-19 | Lopez-Estrada Alex A. | Method, apparatus, and system for efficient rate control in audio encoding |
US7269554B2 (en) * | 2001-09-27 | 2007-09-11 | Intel Corporation | Method, apparatus, and system for efficient rate control in audio encoding |
US7742737B2 (en) | 2002-01-08 | 2010-06-22 | The Nielsen Company (Us), Llc. | Methods and apparatus for identifying a digital audio signal |
US8548373B2 (en) | 2002-01-08 | 2013-10-01 | The Nielsen Company (Us), Llc | Methods and apparatus for identifying a digital audio signal |
US20070092089A1 (en) * | 2003-05-28 | 2007-04-26 | Dolby Laboratories Licensing Corporation | Method, apparatus and computer program for calculating and adjusting the perceived loudness of an audio signal |
US8437482B2 (en) | 2003-05-28 | 2013-05-07 | Dolby Laboratories Licensing Corporation | Method, apparatus and computer program for calculating and adjusting the perceived loudness of an audio signal |
US8787615B2 (en) | 2003-06-13 | 2014-07-22 | The Nielsen Company (Us), Llc | Methods and apparatus for embedding watermarks |
US8351645B2 (en) | 2003-06-13 | 2013-01-08 | The Nielsen Company (Us), Llc | Methods and apparatus for embedding watermarks |
US9202256B2 (en) | 2003-06-13 | 2015-12-01 | The Nielsen Company (Us), Llc | Methods and apparatus for embedding watermarks |
US7643652B2 (en) | 2003-06-13 | 2010-01-05 | The Nielsen Company (Us), Llc | Method and apparatus for embedding watermarks |
AU2004258470B2 (en) * | 2003-06-13 | 2009-12-10 | The Nielsen Company (Us), Llc | Methods and apparatus for embedding watermarks |
US8085975B2 (en) | 2003-06-13 | 2011-12-27 | The Nielsen Company (Us), Llc | Methods and apparatus for embedding watermarks |
WO2005008582A3 (en) * | 2003-06-13 | 2005-12-15 | Nielsen Media Res Inc | Methods and apparatus for embedding watermarks |
US20070300066A1 (en) * | 2003-06-13 | 2007-12-27 | Venugopal Srinivasan | Method and apparatus for embedding watermarks |
US7460684B2 (en) | 2003-06-13 | 2008-12-02 | Nielsen Media Research, Inc. | Method and apparatus for embedding watermarks |
USRE48210E1 (en) * | 2004-01-27 | 2020-09-15 | Dolby Laboratories Licensing Corporation | Coding techniques using estimated spectral magnitude and phase derived from MDCT coefficients |
USRE48271E1 (en) * | 2004-01-27 | 2020-10-20 | Dolby Laboratories Licensing Corporation | Coding techniques using estimated spectral magnitude and phase derived from MDCT coefficients |
USRE46684E1 (en) * | 2004-01-27 | 2018-01-23 | Dolby Laboratories Licensing Corporation | Coding techniques using estimated spectral magnitude and phase derived from MDCT coefficients |
USRE44126E1 (en) * | 2004-01-27 | 2013-04-02 | Dolby Laboratories Licensing Corporation | Coding techniques using estimated spectral magnitude and phase derived from MDCT coefficients |
US20050165587A1 (en) * | 2004-01-27 | 2005-07-28 | Cheng Corey I. | Coding techniques using estimated spectral magnitude and phase derived from mdct coefficients |
US6980933B2 (en) * | 2004-01-27 | 2005-12-27 | Dolby Laboratories Licensing Corporation | Coding techniques using estimated spectral magnitude and phase derived from MDCT coefficients |
USRE42935E1 (en) * | 2004-01-27 | 2011-11-15 | Dolby Laboratories Licensing Corporation | Coding techniques using estimated spectral magnitude and phase derived from MDCT coefficients |
US7574355B2 (en) * | 2004-03-01 | 2009-08-11 | Fraunhofer-Gesellschaft Zur Foerderung Der Angewandten Forschung E.V. | Apparatus and method for determining a quantizer step size |
US20090274210A1 (en) * | 2004-03-01 | 2009-11-05 | Bernhard Grill | Apparatus and method for determining a quantizer step size |
US8756056B2 (en) | 2004-03-01 | 2014-06-17 | Fraunhofer-Gesellschaft Zur Foerderung Der Angewandten Forschung E.V. | Apparatus and method for determining a quantizer step size |
US20060293884A1 (en) * | 2004-03-01 | 2006-12-28 | Bernhard Grill | Apparatus and method for determining a quantizer step size |
US9332307B2 (en) | 2004-04-07 | 2016-05-03 | The Nielsen Company (Us), Llc | Data insertion apparatus and methods for use with compressed audio/video data |
US20050240412A1 (en) * | 2004-04-07 | 2005-10-27 | Masahiro Fujita | Robot behavior control system and method, and robot apparatus |
US8145492B2 (en) * | 2004-04-07 | 2012-03-27 | Sony Corporation | Robot behavior control system and method, and robot apparatus |
US7853124B2 (en) | 2004-04-07 | 2010-12-14 | The Nielsen Company (Us), Llc | Data insertion apparatus and methods for use with compressed audio/video data |
US8600216B2 (en) | 2004-04-07 | 2013-12-03 | The Nielsen Company (Us), Llc | Data insertion apparatus and methods for use with compressed audio/video data |
US20110055860A1 (en) * | 2004-04-07 | 2011-03-03 | Arun Ramaswamy | Data insertion apparatus and methods for use with compressed audio/video data |
US20080318785A1 (en) * | 2004-04-18 | 2008-12-25 | Sebastian Koltzenburg | Preparation Comprising at Least One Conazole Fungicide |
US20100250258A1 (en) * | 2004-07-01 | 2010-09-30 | Dolby Laboratories Licensing Corporation | Method for Correcting Metadata Affecting the Playback Loudness of Audio Information |
US8032385B2 (en) * | 2004-07-01 | 2011-10-04 | Dolby Laboratories Licensing Corporation | Method for correcting metadata affecting the playback loudness of audio information |
US9191581B2 (en) | 2004-07-02 | 2015-11-17 | The Nielsen Company (Us), Llc | Methods and apparatus for mixing compressed digital bit streams |
US8412363B2 (en) | 2004-07-02 | 2013-04-02 | The Nielson Company (Us), Llc | Methods and apparatus for mixing compressed digital bit streams |
US9705461B1 (en) | 2004-10-26 | 2017-07-11 | Dolby Laboratories Licensing Corporation | Calculating and adjusting the perceived loudness and/or the perceived spectral balance of an audio signal |
US10411668B2 (en) | 2004-10-26 | 2019-09-10 | Dolby Laboratories Licensing Corporation | Methods and apparatus for adjusting a level of an audio signal |
US11296668B2 (en) | 2004-10-26 | 2022-04-05 | Dolby Laboratories Licensing Corporation | Methods and apparatus for adjusting a level of an audio signal |
US10389319B2 (en) | 2004-10-26 | 2019-08-20 | Dolby Laboratories Licensing Corporation | Methods and apparatus for adjusting a level of an audio signal |
US10389321B2 (en) | 2004-10-26 | 2019-08-20 | Dolby Laboratories Licensing Corporation | Methods and apparatus for adjusting a level of an audio signal |
US10374565B2 (en) | 2004-10-26 | 2019-08-06 | Dolby Laboratories Licensing Corporation | Methods and apparatus for adjusting a level of an audio signal |
US10389320B2 (en) | 2004-10-26 | 2019-08-20 | Dolby Laboratories Licensing Corporation | Methods and apparatus for adjusting a level of an audio signal |
US8090120B2 (en) | 2004-10-26 | 2012-01-03 | Dolby Laboratories Licensing Corporation | Calculating and adjusting the perceived loudness and/or the perceived spectral balance of an audio signal |
US10361671B2 (en) | 2004-10-26 | 2019-07-23 | Dolby Laboratories Licensing Corporation | Methods and apparatus for adjusting a level of an audio signal |
US9979366B2 (en) | 2004-10-26 | 2018-05-22 | Dolby Laboratories Licensing Corporation | Calculating and adjusting the perceived loudness and/or the perceived spectral balance of an audio signal |
US10396739B2 (en) | 2004-10-26 | 2019-08-27 | Dolby Laboratories Licensing Corporation | Methods and apparatus for adjusting a level of an audio signal |
US9966916B2 (en) | 2004-10-26 | 2018-05-08 | Dolby Laboratories Licensing Corporation | Calculating and adjusting the perceived loudness and/or the perceived spectral balance of an audio signal |
US9960743B2 (en) | 2004-10-26 | 2018-05-01 | Dolby Laboratories Licensing Corporation | Calculating and adjusting the perceived loudness and/or the perceived spectral balance of an audio signal |
US9954506B2 (en) | 2004-10-26 | 2018-04-24 | Dolby Laboratories Licensing Corporation | Calculating and adjusting the perceived loudness and/or the perceived spectral balance of an audio signal |
US10396738B2 (en) | 2004-10-26 | 2019-08-27 | Dolby Laboratories Licensing Corporation | Methods and apparatus for adjusting a level of an audio signal |
US8488809B2 (en) | 2004-10-26 | 2013-07-16 | Dolby Laboratories Licensing Corporation | Calculating and adjusting the perceived loudness and/or the perceived spectral balance of an audio signal |
US8199933B2 (en) | 2004-10-26 | 2012-06-12 | Dolby Laboratories Licensing Corporation | Calculating and adjusting the perceived loudness and/or the perceived spectral balance of an audio signal |
US20070291959A1 (en) * | 2004-10-26 | 2007-12-20 | Dolby Laboratories Licensing Corporation | Calculating and Adjusting the Perceived Loudness and/or the Perceived Spectral Balance of an Audio Signal |
US10720898B2 (en) | 2004-10-26 | 2020-07-21 | Dolby Laboratories Licensing Corporation | Methods and apparatus for adjusting a level of an audio signal |
US10476459B2 (en) | 2004-10-26 | 2019-11-12 | Dolby Laboratories Licensing Corporation | Methods and apparatus for adjusting a level of an audio signal |
US9350311B2 (en) | 2004-10-26 | 2016-05-24 | Dolby Laboratories Licensing Corporation | Calculating and adjusting the perceived loudness and/or the perceived spectral balance of an audio signal |
US10454439B2 (en) | 2004-10-26 | 2019-10-22 | Dolby Laboratories Licensing Corporation | Methods and apparatus for adjusting a level of an audio signal |
US20060262938A1 (en) * | 2005-05-18 | 2006-11-23 | Gauger Daniel M Jr | Adapted audio response |
US8964997B2 (en) | 2005-05-18 | 2015-02-24 | Bose Corporation | Adapted audio masking |
US20110235813A1 (en) * | 2005-05-18 | 2011-09-29 | Gauger Jr Daniel M | Adapted Audio Masking |
US8867759B2 (en) | 2006-01-05 | 2014-10-21 | Audience, Inc. | System and method for utilizing inter-microphone level differences for speech enhancement |
US8345890B2 (en) | 2006-01-05 | 2013-01-01 | Audience, Inc. | System and method for utilizing inter-microphone level differences for speech enhancement |
US8332216B2 (en) * | 2006-01-12 | 2012-12-11 | Stmicroelectronics Asia Pacific Pte., Ltd. | System and method for low power stereo perceptual audio coding using adaptive masking threshold |
US20070162277A1 (en) * | 2006-01-12 | 2007-07-12 | Stmicroelectronics Asia Pacific Pte., Ltd. | System and method for low power stereo perceptual audio coding using adaptive masking threshold |
US20090323982A1 (en) * | 2006-01-30 | 2009-12-31 | Ludger Solbach | System and method for providing noise suppression utilizing null processing noise subtraction |
US9185487B2 (en) | 2006-01-30 | 2015-11-10 | Audience, Inc. | System and method for providing noise suppression utilizing null processing noise subtraction |
US8194880B2 (en) | 2006-01-30 | 2012-06-05 | Audience, Inc. | System and method for utilizing omni-directional microphones for speech enhancement |
US9584083B2 (en) | 2006-04-04 | 2017-02-28 | Dolby Laboratories Licensing Corporation | Loudness modification of multichannel audio signals |
US8731215B2 (en) | 2006-04-04 | 2014-05-20 | Dolby Laboratories Licensing Corporation | Loudness modification of multichannel audio signals |
US20100202632A1 (en) * | 2006-04-04 | 2010-08-12 | Dolby Laboratories Licensing Corporation | Loudness modification of multichannel audio signals |
US8504181B2 (en) | 2006-04-04 | 2013-08-06 | Dolby Laboratories Licensing Corporation | Audio signal loudness measurement and modification in the MDCT domain |
US20090304190A1 (en) * | 2006-04-04 | 2009-12-10 | Dolby Laboratories Licensing Corporation | Audio Signal Loudness Measurement and Modification in the MDCT Domain |
WO2007120452A1 (en) * | 2006-04-04 | 2007-10-25 | Dolby Laboratories Licensing Corporation | Audio signal loudness measurement and modification in the mdct domain |
CN101410892B (en) * | 2006-04-04 | 2012-08-08 | 杜比实验室特许公司 | Audio signal loudness measurement and modification in the mdct domain |
US8019095B2 (en) | 2006-04-04 | 2011-09-13 | Dolby Laboratories Licensing Corporation | Loudness modification of multichannel audio signals |
US8600074B2 (en) | 2006-04-04 | 2013-12-03 | Dolby Laboratories Licensing Corporation | Loudness modification of multichannel audio signals |
US9698744B1 (en) | 2006-04-27 | 2017-07-04 | Dolby Laboratories Licensing Corporation | Audio control using auditory event detection |
US9787268B2 (en) | 2006-04-27 | 2017-10-10 | Dolby Laboratories Licensing Corporation | Audio control using auditory event detection |
US9742372B2 (en) | 2006-04-27 | 2017-08-22 | Dolby Laboratories Licensing Corporation | Audio control using auditory event detection |
US11962279B2 (en) | 2006-04-27 | 2024-04-16 | Dolby Laboratories Licensing Corporation | Audio control using auditory event detection |
US11711060B2 (en) | 2006-04-27 | 2023-07-25 | Dolby Laboratories Licensing Corporation | Audio control using auditory event detection |
US9768749B2 (en) | 2006-04-27 | 2017-09-19 | Dolby Laboratories Licensing Corporation | Audio control using auditory event detection |
US11362631B2 (en) | 2006-04-27 | 2022-06-14 | Dolby Laboratories Licensing Corporation | Audio control using auditory event detection |
US9685924B2 (en) | 2006-04-27 | 2017-06-20 | Dolby Laboratories Licensing Corporation | Audio control using auditory event detection |
US9768750B2 (en) | 2006-04-27 | 2017-09-19 | Dolby Laboratories Licensing Corporation | Audio control using auditory event detection |
US8428270B2 (en) | 2006-04-27 | 2013-04-23 | Dolby Laboratories Licensing Corporation | Audio gain control using specific-loudness-based auditory event detection |
US9774309B2 (en) | 2006-04-27 | 2017-09-26 | Dolby Laboratories Licensing Corporation | Audio control using auditory event detection |
US10833644B2 (en) | 2006-04-27 | 2020-11-10 | Dolby Laboratories Licensing Corporation | Audio control using auditory event detection |
US9780751B2 (en) | 2006-04-27 | 2017-10-03 | Dolby Laboratories Licensing Corporation | Audio control using auditory event detection |
US9450551B2 (en) | 2006-04-27 | 2016-09-20 | Dolby Laboratories Licensing Corporation | Audio control using auditory event detection |
US9787269B2 (en) | 2006-04-27 | 2017-10-10 | Dolby Laboratories Licensing Corporation | Audio control using auditory event detection |
US9762196B2 (en) | 2006-04-27 | 2017-09-12 | Dolby Laboratories Licensing Corporation | Audio control using auditory event detection |
US9866191B2 (en) | 2006-04-27 | 2018-01-09 | Dolby Laboratories Licensing Corporation | Audio control using auditory event detection |
US10523169B2 (en) | 2006-04-27 | 2019-12-31 | Dolby Laboratories Licensing Corporation | Audio control using auditory event detection |
US8144881B2 (en) | 2006-04-27 | 2012-03-27 | Dolby Laboratories Licensing Corporation | Audio gain control using specific-loudness-based auditory event detection |
US9136810B2 (en) | 2006-04-27 | 2015-09-15 | Dolby Laboratories Licensing Corporation | Audio gain control using specific-loudness-based auditory event detection |
US10103700B2 (en) | 2006-04-27 | 2018-10-16 | Dolby Laboratories Licensing Corporation | Audio control using auditory event detection |
US10284159B2 (en) | 2006-04-27 | 2019-05-07 | Dolby Laboratories Licensing Corporation | Audio control using auditory event detection |
US8949120B1 (en) | 2006-05-25 | 2015-02-03 | Audience, Inc. | Adaptive noise cancelation |
US20070276656A1 (en) * | 2006-05-25 | 2007-11-29 | Audience, Inc. | System and method for processing an audio signal |
US8150065B2 (en) | 2006-05-25 | 2012-04-03 | Audience, Inc. | System and method for processing an audio signal |
US8934641B2 (en) | 2006-05-25 | 2015-01-13 | Audience, Inc. | Systems and methods for reconstructing decomposed audio signals |
US20080004873A1 (en) * | 2006-06-28 | 2008-01-03 | Chi-Min Liu | Perceptual coding of audio signals by spectrum uncertainty |
US8204252B1 (en) | 2006-10-10 | 2012-06-19 | Audience, Inc. | System and method for providing close microphone adaptive array processing |
US9286903B2 (en) | 2006-10-11 | 2016-03-15 | The Nielsen Company (Us), Llc | Methods and apparatus for embedding codes in compressed audio data streams |
US8078301B2 (en) | 2006-10-11 | 2011-12-13 | The Nielsen Company (Us), Llc | Methods and apparatus for embedding codes in compressed audio data streams |
US8972033B2 (en) | 2006-10-11 | 2015-03-03 | The Nielsen Company (Us), Llc | Methods and apparatus for embedding codes in compressed audio data streams |
US8849433B2 (en) | 2006-10-20 | 2014-09-30 | Dolby Laboratories Licensing Corporation | Audio dynamics processing using a reset |
US20110009987A1 (en) * | 2006-11-01 | 2011-01-13 | Dolby Laboratories Licensing Corporation | Hierarchical Control Path With Constraints for Audio Dynamics Processing |
US8521314B2 (en) | 2006-11-01 | 2013-08-27 | Dolby Laboratories Licensing Corporation | Hierarchical control path with constraints for audio dynamics processing |
US8259926B1 (en) | 2007-02-23 | 2012-09-04 | Audience, Inc. | System and method for 2-channel and 3-channel acoustic echo cancellation |
US8886525B2 (en) | 2007-07-06 | 2014-11-11 | Audience, Inc. | System and method for adaptive intelligent noise suppression |
US20090012783A1 (en) * | 2007-07-06 | 2009-01-08 | Audience, Inc. | System and method for adaptive intelligent noise suppression |
US8744844B2 (en) | 2007-07-06 | 2014-06-03 | Audience, Inc. | System and method for adaptive intelligent noise suppression |
US8396574B2 (en) | 2007-07-13 | 2013-03-12 | Dolby Laboratories Licensing Corporation | Audio processing using auditory scene analysis and spectral skewness |
US20100198378A1 (en) * | 2007-07-13 | 2010-08-05 | Dolby Laboratories Licensing Corporation | Audio Processing Using Auditory Scene Analysis and Spectral Skewness |
US8189766B1 (en) | 2007-07-26 | 2012-05-29 | Audience, Inc. | System and method for blind subband acoustic echo cancellation postfiltering |
US20100202625A1 (en) * | 2007-07-31 | 2010-08-12 | Phonak Ag | Method for adjusting a hearing device with frequency transposition and corresponding arrangement |
WO2007135198A3 (en) * | 2007-07-31 | 2008-01-17 | Phonak Ag | Method for adjusting a hearing device with frequency transposition and corresponding arrangement |
US8737631B2 (en) | 2007-07-31 | 2014-05-27 | Phonak Ag | Method for adjusting a hearing device with frequency transposition and corresponding arrangement |
US8849231B1 (en) | 2007-08-08 | 2014-09-30 | Audience, Inc. | System and method for adaptive power control |
US20130073281A1 (en) * | 2007-12-18 | 2013-03-21 | Fujitsu Limited | Non-speech section detecting method and non-speech section detecting device |
US8798991B2 (en) * | 2007-12-18 | 2014-08-05 | Fujitsu Limited | Non-speech section detecting method and non-speech section detecting device |
US8180064B1 (en) | 2007-12-21 | 2012-05-15 | Audience, Inc. | System and method for providing voice equalization |
US8143620B1 (en) | 2007-12-21 | 2012-03-27 | Audience, Inc. | System and method for adaptive classification of audio sources |
US9076456B1 (en) | 2007-12-21 | 2015-07-07 | Audience, Inc. | System and method for providing voice equalization |
US8194882B2 (en) | 2008-02-29 | 2012-06-05 | Audience, Inc. | System and method for providing single microphone noise suppression fallback |
US8355511B2 (en) | 2008-03-18 | 2013-01-15 | Audience, Inc. | System and method for envelope-based acoustic echo cancellation |
US8521530B1 (en) | 2008-06-30 | 2013-08-27 | Audience, Inc. | System and method for enhancing a monaural audio signal |
US8774423B1 (en) | 2008-06-30 | 2014-07-08 | Audience, Inc. | System and method for controlling adaptivity of signal modification using a phantom coefficient |
US8204253B1 (en) | 2008-06-30 | 2012-06-19 | Audience, Inc. | Self calibration of audio device |
US20100158263A1 (en) * | 2008-12-23 | 2010-06-24 | Roman Katzer | Masking Based Gain Control |
US8218783B2 (en) | 2008-12-23 | 2012-07-10 | Bose Corporation | Masking based gain control |
US9306524B2 (en) | 2008-12-24 | 2016-04-05 | Dolby Laboratories Licensing Corporation | Audio signal loudness determination and modification in the frequency domain |
US8892426B2 (en) | 2008-12-24 | 2014-11-18 | Dolby Laboratories Licensing Corporation | Audio signal loudness determination and modification in the frequency domain |
WO2010077361A1 (en) * | 2008-12-31 | 2010-07-08 | Audience, Inc. | Systems and methods for reconstructing decomposed audio signals |
US8229125B2 (en) | 2009-02-06 | 2012-07-24 | Bose Corporation | Adjusting dynamic range of an audio system |
US20100202631A1 (en) * | 2009-02-06 | 2010-08-12 | Short William R | Adjusting Dynamic Range for Audio Reproduction |
US20100272285A1 (en) * | 2009-04-22 | 2010-10-28 | General Electric Company | Masking of pure tones within sound from a noise generating source |
US8223985B2 (en) | 2009-04-22 | 2012-07-17 | General Electric Company | Masking of pure tones within sound from a noise generating source |
US9055374B2 (en) * | 2009-06-24 | 2015-06-09 | Arizona Board Of Regents For And On Behalf Of Arizona State University | Method and system for determining an auditory pattern of an audio segment |
US20110150229A1 (en) * | 2009-06-24 | 2011-06-23 | Arizona Board Of Regents For And On Behalf Of Arizona State University | Method and system for determining an auditory pattern of an audio segment |
US9838784B2 (en) | 2009-12-02 | 2017-12-05 | Knowles Electronics, Llc | Directional audio capture |
US9437180B2 (en) | 2010-01-26 | 2016-09-06 | Knowles Electronics, Llc | Adaptive noise reduction using level cues |
US9008329B1 (en) | 2010-01-26 | 2015-04-14 | Audience, Inc. | Noise reduction using multi-feature cluster tracker |
US9378754B1 (en) | 2010-04-28 | 2016-06-28 | Knowles Electronics, Llc | Adaptive spatial classifier for multi-microphone systems |
US9237400B2 (en) | 2010-08-24 | 2016-01-12 | Dolby International Ab | Concealment of intermittent mono reception of FM stereo radio receivers |
US9685921B2 (en) | 2012-07-12 | 2017-06-20 | Dts, Inc. | Loudness control with noise detection and loudness drop detection |
US9536540B2 (en) | 2013-07-19 | 2017-01-03 | Knowles Electronics, Llc | Speech signal separation and synthesis based on auditory scene analysis and speech modeling |
US9978388B2 (en) | 2014-09-12 | 2018-05-22 | Knowles Electronics, Llc | Systems and methods for restoration of speech components |
US9820042B1 (en) | 2016-05-02 | 2017-11-14 | Knowles Electronics, Llc | Stereo separation and directional suppression with omni-directional microphones |
US10374564B2 (en) | 2017-04-20 | 2019-08-06 | Dts, Inc. | Loudness control with noise detection and loudness drop detection |
CN115171709A (en) * | 2022-09-05 | 2022-10-11 | 腾讯科技（深圳）有限公司 | Voice coding method, voice decoding method, voice coding device, voice decoding device, computer equipment and storage medium |
Also Published As
Publication number | Publication date |
---|---|
DE69602773T2 (en) | 1999-11-11 |
CA2167967A1 (en) | 1996-08-07 |
EP0725494A1 (en) | 1996-08-07 |
JPH08272399A (en) | 1996-10-18 |
DE69602773D1 (en) | 1999-07-15 |
EP0725494B1 (en) | 1999-06-09 |
ES2142543T3 (en) | 2000-04-16 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US5682463A (en) | Perceptual audio compression based on loudness uncertainty | |
US5699479A (en) | Tonality for perceptual audio compression based on loudness uncertainty | |
US5632003A (en) | Computationally efficient adaptive bit allocation for coding method and apparatus | |
CA2166551C (en) | Computationally efficient adaptive bit allocation for coding method and apparatus | |
Sinha et al. | Low bit rate transparent audio compression using adapted wavelets | |
Brandenburg | OCF--A new coding algorithm for high quality sound signals | |
KR100269213B1 (en) | Method for coding audio signal | |
Pan | Digital audio compression | |
US5537510A (en) | Adaptive digital audio encoding apparatus and a bit allocation method thereof | |
CA2206129C (en) | Method and apparatus for applying waveform prediction to subbands of a perceptual coding system | |
EP0720148B1 (en) | Method for noise weighting filtering | |
JP3186292B2 (en) | High efficiency coding method and apparatus | |
HU215685B (en) | Method and device for encoding and decoding wideband digital data signals | |
US7164771B1 (en) | Process and system for objective audio quality measurement | |
WO1998015945A1 (en) | Variable length audio coding using a plurality of subband bit allocation patterns | |
US6091773A (en) | Data compression method and apparatus | |
EP0525774B1 (en) | Digital audio signal coding system and method therefor | |
US6466912B1 (en) | Perceptual coding of audio signals employing envelope uncertainty | |
Mahieux et al. | High-quality audio transform coding at 64 kbps | |
EP0612160A2 (en) | A bit allocation method for transform coder | |
JPH0846518A (en) | Information coding and decoding method, information coder and decoder and information recording medium | |
Parker et al. | The stimulus range effect: Evidence for top-down control of sensory intensity in audition | |
Hant et al. | A psychoacoustic-masking model to predict the perception of speech-like stimuli in noise | |
EP0612158B1 (en) | A block size determination method of a transform coder | |
AU677688B2 (en) | Computationally efficient adaptive bit allocation for encoding method and apparatus with allowance for decoder spectral distortions |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
AS | Assignment |
Owner name: AT&T IPM CORP.Free format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:ALLEN, JONATHAN BRANDON;SINHA, DEEPEN;SYDORENKO, MARK R.;REEL/FRAME:007400/0532;SIGNING DATES FROM 19950323 TO 19950329 |
|
AS | Assignment |
Owner name: LUCENT TECHNOLOGIES INC., NEW JERSEYFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:AT&T CORP.;REEL/FRAME:008488/0374Effective date: 19960329 |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
FEPP | Fee payment procedure |
Free format text: PAYOR NUMBER ASSIGNED (ORIGINAL EVENT CODE: ASPN); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
FPAY | Fee payment |
Year of fee payment: 4 |
|
AS | Assignment |
Owner name: THE CHASE MANHATTAN BANK, AS COLLATERAL AGENT, TEXFree format text: CONDITIONAL ASSIGNMENT OF AND SECURITY INTEREST IN PATENT RIGHTS;ASSIGNOR:LUCENT TECHNOLOGIES INC. (DE CORPORATION);REEL/FRAME:011722/0048Effective date: 20010222 |
|
FPAY | Fee payment |
Year of fee payment: 8 |
|
AS | Assignment |
Owner name: LUCENT TECHNOLOGIES INC., NEW JERSEYFree format text: TERMINATION AND RELEASE OF SECURITY INTEREST IN PATENT RIGHTS;ASSIGNOR:JPMORGAN CHASE BANK, N.A. (FORMERLY KNOWN AS THE CHASE MANHATTAN BANK), AS ADMINISTRATIVE AGENT;REEL/FRAME:018584/0446Effective date: 20061130 |
|
FPAY | Fee payment |
Year of fee payment: 12 |
|
AS | Assignment |
Owner name: AT&T CORP., NEW YORKFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:AT&T IPM CORP.;REEL/FRAME:027342/0572Effective date: 19950825 |
|
AS | Assignment |
Owner name: ALCATEL-LUCENT USA INC., NEW JERSEYFree format text: MERGER;ASSIGNOR:LUCENT TECHNOLOGIES INC.;REEL/FRAME:027386/0471Effective date: 20081101 |
|
AS | Assignment |
Owner name: LOCUTION PITCH LLC, DELAWAREFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:ALCATEL-LUCENT USA INC.;REEL/FRAME:027437/0922Effective date: 20111221 |
|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:LOCUTION PITCH LLC;REEL/FRAME:037326/0396Effective date: 20151210 |
|
AS | Assignment |
Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:044144/0001Effective date: 20170929 |