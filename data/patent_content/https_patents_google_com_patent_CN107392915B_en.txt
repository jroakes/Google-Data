CN107392915B - The pixel of screenshotss image based on capture content will calculate the content segmentation shown in equipment into region - Google Patents
The pixel of screenshotss image based on capture content will calculate the content segmentation shown in equipment into region Download PDFInfo
- Publication number
- CN107392915B CN107392915B CN201611223828.9A CN201611223828A CN107392915B CN 107392915 B CN107392915 B CN 107392915B CN 201611223828 A CN201611223828 A CN 201611223828A CN 107392915 B CN107392915 B CN 107392915B
- Authority
- CN
- China
- Prior art keywords
- area
- pixel
- region
- content
- engine
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/40—Information retrieval; Database structures therefor; File system structures therefor of multimedia data, e.g. slideshows comprising image and additional audio data
- G06F16/43—Querying
- G06F16/432—Query formulation
- G06F16/434—Query formulation using image data, e.g. images, photos, pictures taken by a user
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/953—Querying, e.g. by the use of web search engines
- G06F16/9535—Search customisation based on user profiles and personalisation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0481—Interaction techniques based on graphical user interfaces [GUI] based on specific properties of the displayed interaction object or a metaphor-based environment, e.g. interaction with desktop elements like windows or icons, or assisted by a cursor's changing behaviour or appearance
- G06F3/04817—Interaction techniques based on graphical user interfaces [GUI] based on specific properties of the displayed interaction object or a metaphor-based environment, e.g. interaction with desktop elements like windows or icons, or assisted by a cursor's changing behaviour or appearance using icons
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0484—Interaction techniques based on graphical user interfaces [GUI] for the control of specific functions or operations, e.g. selecting or manipulating an object, an image or a displayed text element, setting a parameter value or selecting a range
- G06F3/04842—Selection of displayed objects or displayed text elements
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F3/00—Input arrangements for transferring data to be processed into a form capable of being handled by the computer; Output arrangements for transferring data from processing unit to output unit, e.g. interface arrangements
- G06F3/01—Input arrangements or combined input and output arrangements for interaction between user and computer
- G06F3/048—Interaction techniques based on graphical user interfaces [GUI]
- G06F3/0487—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser
- G06F3/0488—Interaction techniques based on graphical user interfaces [GUI] using specific features provided by the input device, e.g. functions controlled by the rotation of a mouse with dual sensing arrangements, or of the nature of the input device, e.g. tap gestures based on pressure sensed by a digitiser using a touch-screen or digitiser, e.g. input of commands through traced gestures
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T7/00—Image analysis
- G06T7/10—Segmentation; Edge detection
- G06T7/11—Region-based segmentation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T7/00—Image analysis
- G06T7/30—Determination of transform parameters for the alignment of images, i.e. image registration
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T7/00—Image analysis
- G06T7/90—Determination of colour characteristics
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06V—IMAGE OR VIDEO RECOGNITION OR UNDERSTANDING
- G06V10/00—Arrangements for image or video recognition or understanding
- G06V10/40—Extraction of image or video features
- G06V10/46—Descriptors for shape, contour or point-related descriptors, e.g. scale invariant feature transform [SIFT] or bags of words [BoW]; Salient regional features
- G06V10/462—Salient features, e.g. scale invariant feature transforms [SIFT]
Abstract
The content segmentation that shows will be calculated in equipment into region the present invention relates to the pixel of the screenshotss image based on capture content, especially in will calculate the content segmentation that shows in equipment into the method and apparatus in region.The content segmentation shown in equipment will be calculated into region via the pixel of " the screenshotss image " of at least part (for example, all) of the content of analysis capture display to realize.Each pixel of screenshotss image be can analyze to determine one or more regions of screenshotss image, and optionally distribute corresponding semantic type to each region.It is some realize also directed in based on one or more Area generation interactive contents with provide for via calculate equipment be presented to the user.
Description
Background technique
Automatically extracting image and/or other contents from the certain documents checked on the computing device by user can be relatively
Direct process.E.g., including the html web page of image can explicitly limit the position of the image, and the position can be by
Equipment is calculated to be used to extract the image.For example, can be by one or more calculating equipment (for example, by viewing html web page
The calculating equipment of user) image on html web page is extracted using the layered structure limited by html web page.The image of extraction
Calculating equipment, communication to one or more additional computing devices (for example, via e-mail) etc. can be saved in.
Summary of the invention
The embodiment of this specification is as follows for solving the problems, such as:, according to the prior art, is being calculated and set by user's extraction
The image of standby upper viewing and/or other contents in most cases can not.For example, many applications are (for example, for mobile electricity
" apply (apps) " of words, tablet computer etc.) image and/or other graphical contents for showing to user can be generated.From
It is impossible that many applications, which automatically extract content so far, unless the special support of application exports the content, (this is relatively not
Ordinary).This be encoded as display image in text content of text extraction in contrast, Text Feature Extraction now be move
The general feature of dynamic operating system.
By the way that from the graphic elements shown in equipment extraction content is calculated, the useful interaction with the content is possibly realized.This
Can allow for user execute with will be impossible (or it is impossible that the equipment, which is at least used alone) content in other ways
Related movement.
The realization of this specification is directed to the content segmentation that will be shown on the computing device into region.One in those realizations
A bit also directed in based on one or more Area generation interactive contents with provide for via calculate equipment be presented to the user.
It can be configured as via the interactive content that equipment is presented to the user is calculated: in response to defeated via the user interface for calculating equipment
Enter selection of the equipment to interactive content, executes so that calculating equipment for for generating the one or more of interactive content
One or more movements of region customization.
It is realized via the pixel of " the screenshotss image " of at least part (for example, all) of the content of analysis capture display
The content segmentation shown in equipment will be calculated into region.Each pixel of screenshotss image be can analyze to determine the one of screenshotss image
A or more region, and corresponding semantic type is distributed to each region.Region limits the continuum of screenshotss image,
And the semantic type in region is included in the classification of the content in the region.Semantic type may include such as " image ", " text
One's respective area ", " list-item " and/or more granularity types, such as " photographs ", " image as drawing ".It is cut to coming from
The analysis of the pixel of screen image can be enabled to from the display generated by any one of multiple applications (such as by not including
For extract image and/or other contents function mobile phone " application " generate display) extract image and/or it is other in
Hold.In some implementations, based on only being realized in the display captured in screenshotss image to the analysis of multiple pixels of screenshotss image
The segmentation of appearance.In some implementations, in any markup language (for example, HTML) for not analyzing the display that can be used for generating content
In the case of, realize the segmentation of the display content captured in screenshotss image.
In some implementations, it provides a method, this method is executed by one or more processors, and this method
It include: capture screenshotss image, which is supplied at least part of the display of user by the calculating equipment of user；
Screenshotss image is divided at least first area and second area by multiple pixels based on screenshotss image；Based on the more of first area
First semantic type is distributed to first area by a pixel；It is generated and is handed over based on the first semantic type of first area and first area
Mutual formula content；And interactive content is provided to be presented to the user via the calculating equipment of user.User via user calculating
The user interface input device selection interactive content of equipment customizes the calculating equipment execution of user for first area
One or more movements.
These and other realization of presently disclosed technology can optionally include one or more in following characteristics.
In some implementations, interactive content includes graphic elements, when via user interface input device selection pattern primitive
When part, which to calculate equipment: access webpage relevant to the content visible of first area, sending and first area
The relevant search of content visible, or the state of relevant to the content visible of the first area application of access.
In some implementations, method further include: identification via user interface input device or calculates the another of equipment by user
The particular user interface input that one user interface input device provides；And it is provided in response to the input of identification particular user interface
Interactive content is to be presented to the user.In some in those are realized, particular user interface input be directed to display with the
The corresponding part of the subset in one region, and interactive content is provided to be presented to the user based on being directed to display and the firstth area
The particular user interface of the corresponding part of the subset in domain inputs.In some versions that those are realized, interactive content includes figure
Shape element, when selecting graphic elements via user interface input device, so that calculating equipment in one or more nonvolatiles
Property computer-readable medium on save first area multiple pixels, without save second area any pixel.In those realities
In existing some other versions, interactive content includes additionally and/or alternatively graphic elements, is inputted when via user interface
When equipment selects the graphic elements, graphic elements to calculate equipment generation electronic communication, which includes first area
Multiple pixels, and electronic communication does not include any pixel of second area.The firstth area can be based on by generating interactive content
First semantic type in domain and first area, and can be independently of second area.Those realize in it is some in, friendship is provided
Mutual formula content for the calculating equipment via user to be presented to the user including not providing based on any of second area determination
Interactive content is provided in the case where interactive content.
In some implementations, one or more the processor for realizing this method includes calculating one of equipment or more
It is multiple to calculate device handler and far from one or more teleprocessing units for calculating equipment.It is some in those are realized
In, one or more processor of capture screenshotss image is made of one or more calculating device handlers, and
One or more the processor for generating interactive content includes one or more teleprocessing units.In those are realized
It is some in, be divided into one or more processor of at least first area and second area by one screenshotss image
Or more calculate device handler constitute.In some versions that those are realized, this method further includes by one or more
It is a to calculate multiple pixels of the device handler to first group of teleprocessing unit transmission first area, without by any of second area
Pixel is transmitted to first group of teleprocessing unit.First semantic type is distributed to one or more processing of first area
Device can be made of one or more calculating device handlers in some in those versions.In addition, in those versions
It is some in, this method can also include: to be transmitted from one or more calculating device handlers to first group of teleprocessing unit
First semantic type of first area；And/or the first semantic type based on first area, by one or more calculating equipment
Processor selects first group of teleprocessing unit.
In some implementations, this method further includes the bells and whistles of the first area in determining screenshotss image, and goes back base
Interactive content is generated in bells and whistles.In some in those are realized, it is full depending on bells and whistles to generate interactive content
Sufficient threshold value.Bells and whistles can indicate one of the following: in the absolute size of the first area in screenshotss image, screenshotss image
The relative size of first area, the pixel of the position of first area in screenshotss image and the first area in screenshotss image
Density.
In some implementations, screenshotss image is divided at least first area and second area includes dividing screenshotss image
At multiple units, each unit includes unique group pixel of screenshotss image, and for each of multiple units unit:
Correspondence one in multiple classification, and base are determined for the unit based on the pixel subset for the unique group pixel for including by unit
First area is determined in the classification of identified unit.Those realize in it is some in, determine that first area includes: to be based on
One or more minimum bounding boxes determine first area, each minimum bounding box includes with the first classification in classification
Multiple units.Those realize in it is some in, determine the given unit in the multiple unit classification include: based on standard
The pixel subset that random selection process determination includes by unit；And the counting based on the pixel subset as particular color is come really
Fixed classification.
In some implementations, a kind of method is provided, this method is executed by one or more processors, and this method packet
Include: capture screenshotss image, the screenshotss image capture are supplied at least part of the display of user by calculating equipment；Based on screenshotss
Screenshotss image is divided at least first area and second area by multiple pixels of image；Based on one in the following terms or more
Multiple at least one first characteristic to determine first area: multiple pixels, the size of first area and first of first area
The position in region；At least one second characteristic of second area: second area is determined based on one of the following or more
Multiple pixels, the size of second area and second area position；And multiple pixels execution based on first area is specific
Movement.Specific first movement is executed in the pixel of first area based on the first area with the first characteristic, and is not based on
Second area with the second characteristic executes specific action on the second region.
These and other realization of presently disclosed technology can optionally include one or more in following characteristics.
In some implementations, the first characteristic is the first semantic label, and the second characteristic is the second semantic label.
In some implementations, the first movement is that the pixel of first area is supplied to content recognition engine.In those realizations
In it is some in: based on one or more pixels of second area are supplied to individually with the second area of the second characteristic
Content recognition engine；Being not based on, there is the second area of the second characteristic the pixel of second area is supplied to any content recognition draws
It holds up；Or it is not based on the second area with the second characteristic and provides the pixel of second area for any further movement.
In some implementations, it provides a method, this method is executed by one or more processors, and this method
It include: capture screenshotss image, which is supplied at least part of the display of user by the calculating equipment of user；
Screenshotss image is divided at least first area and second area by multiple pixels based on screenshotss image；Based on the more of first area
First semantic type is distributed to first area by a pixel；Based in the determination of the first semantic type of first area and first area
Hold；And content is provided to be presented to the user via the calculating equipment of user.
These and other realization of presently disclosed technology can optionally include one or more in following characteristics.
In some implementations, content is information graphic element, which includes being present in first area
Entity attributes, entity image and/or focus on other contents of entity.
In some implementations, content is interactive content.
In some implementations, content is static content.Those realize in it is some in, content is information graphic element,
The information graphic element include the entity attributes being present in first area, the image of entity and/or focus on entity its
Its content.
In addition, some realize includes one or more one or more processors for calculating equipment, wherein described one
A or more processor can be operated to execute the instruction being stored in associated memory, and wherein instruction is configured as
So that executing any of above method.Some realizations further include that storage can be executed by one or more processors to execute on any
State the non-transitory computer-readable storage media of the computer instruction of method.
It should be appreciated that all combinations of aforementioned concepts and additional design are envisioned for institute's public affairs herein in greater detail herein
The a part for the theme opened.For example, all combination quilts of the theme claimed ending place of present disclosure
It is considered a part of presently disclosed subject matter.
Detailed description of the invention
Fig. 1 is the block diagram that the example context of techniques disclosed herein wherein may be implemented.
Fig. 2 shows want by the content segmentation shown on the computing device at region and based on a generation in region
It provides via the example for calculating the interactive content that equipment is presented to the user.
Fig. 3 is shown the content segmentation that will be shown on the computing device and is wanted at region and based on a generation in region
It provides via another example for calculating the interactive content that equipment is presented to the user.
Fig. 4 A shows example mobile computing device and just in the content of the display screen display of mobile computing device.
Fig. 4 B shows the screenshotss image of the content shown in Fig. 4 A, and showing can be true based on screenshotss image
Fixed example area.
Fig. 4 C show Fig. 4 A example mobile computing device and can be by interactive mode that mobile computing device is shown
The example held.
Fig. 4 D show Fig. 4 A example mobile computing device and can be by interactive mode that mobile computing device is shown
Another example held.
Fig. 4 E show Fig. 4 A example mobile computing device and can be by interactive mode that mobile computing device is shown
The another example held.
Fig. 5 is to show the flow chart for the exemplary method that screenshotss image is divided into one or more regions.
The example of the classification of grid cell and grid cell that the method that Fig. 6 A can be based on Fig. 5 determines.
Fig. 6 B shows the classification of the grid cell and grid cell of Fig. 6 A, and also showing can be based on the side of Fig. 5
The bounding box that method determines.
Fig. 7 is to show the content segmentation being displayed on calculate in equipment at region and based on the one or more of region
Characteristic executes the flow chart of the exemplary method of one or more movements to region.
Fig. 8 shows the exemplary architecture for calculating equipment.
Specific embodiment
The realization of this specification for by the content segmentation shown on the computing device at region.Some realizations are also used to base
In one or more Area generation interactive contents to provide for being presented to the user via calculating equipment.Via calculating equipment
The interactive content being presented to the user can be configured as: in response to the choosing via the user interface input device for calculating equipment
It selects, so that calculating equipment executes one or more movements, one or more movement is used for for one or more
The region for generating interactive content is customized.
In some implementations, it can use the optional semantic type in identified region and the region to generate and the area
The relevant interactive content of the content visible in domain.For example, can divide the screenshotss image of the display provided by calculating equipment with
Determine the specific region with the display of " photo " semantic type.Calculating equipment can choose multiple pixels in the region, and
And " photo " semantic type is had based on the region, those pixels can be sent to the identification engine for being configured to processing photo
(it is on the computing device or far from calculating equipment).Identify engine can based on pixel come the content of identification region, such as in the presence of
One or more entities in region, are present in region entity relevant to entity those of is present in region
The entity class etc. of those entities.Interactive content can be generated, and the content identified is customized and is provided use
It is presented to the user in via calculating equipment.For example, the content identified may include one or more entities, and interactive
Content can select in response to the user to interactive content and the calculating equipment of user is made to access the entity for being identified
The webpage of customization issues search relevant to the entity of identification, or accesses the state-applied the wherein state and the reality identified
Body is related.
In some implementations, it can use with certain semantic type (for example, semantic type of instruction " image ") really
Region is determined to provide the interaction of multiple pixels in the region for enabling calculating equipment (Local or Remote) preservation of user determining
Formula content, shared (for example, passing through Email, text, chat) those pixels and/or it is specified to be sent to it is one or more
Those of engine (long-range and/or local) pixel, for identification and/or the interactive content other based on the Area generation.Example
Such as, in response to determining region and determining that the region has semantic type " image ", (example can be selected in response to the user in the region
Such as, long-pressing) interactive content for the image is provided.This is able to carry out the calculating equipment of user to focus on user's
One or more movements on the specific region of display.And based on the analysis of the pixel to the screenshotss for including the region
The interactive content of generation to act to user's presentation, and does not need to show that the specific application in the region mentions for the extraction of image
For clearly supporting.
In some implementations, interactive content is generated based on identified region can be in response to true especially for this
The user interface in fixed region inputs, " long-pressing " in such as region.In in these implementations some, in addition to or replace being based on
It is likely to be present in any content of other non-selective regions on the display screen for calculating equipment, based on identified Area generation
Interactive content more highlightedly provided.In other implementations, interactive content is generated based on identified region can be with
It is in response to input in the user interface not especially for identified region, " long-pressing ", the language life of such as General Purpose Interface element
Enable (for example, " telling me more about the content on screen ") etc..
In some implementations, by the screenshotss image of display be divided into one or more regions and/or determine one or
The semantic type in more regions can be entirely or partly by one or more processors of the calculating equipment of generation display
It executes.Those realize in it is some in, generate interactive content and/or the interactive content is provided can be entirely or partly
By being executed far from one or more processors for calculating equipment.In some variants that these are realized, the described of equipment is calculated
One or more processors can based on identified region semantic type come branch fit over generate interactive content in which
Teleprocessing unit will handle the pixel from the region.For example, can provide to the first identification engine has image, semantic label
Region, can have the region of text semantic label to the second identification engine etc. offers.
In addition, in some implementations, display can be divided by one or more the processor for calculating equipment
One or more regions and/or the semantic type for determining one or more regions --- and can use region and/or
Semantic type is to limit for one or more processor by calculating equipment and/or by one or more long-range
Manage the quantity of the pixel for one or more additional calculations movement that device executes.For example, calculating the one or more of equipment
Display can be divided into the multiple regions of the semantic type with " image ", " text " and "None" by a processor.Processor
Pixel can be provided to image recognition engine from image-region (by one or more processors of calculating equipment or by long-range
Processor is realized), and text filed pixel can be supplied to text identification engine (by the one or more of calculating equipment
A processor is realized by teleprocessing unit), but any pixel from "None" region can not be provided.This can be by subtracting
Lack the number by the pixel of engine analysis to save the computing resource of engine, and/or can reduce in one or more engines
Far from the Internet use in the realization for calculating equipment (that is, because the pixel from "None" region is not sent to and remotely draws
It holds up).
As another example, when one or more bells and whistles when region meet threshold value, described the one of equipment is calculated
A or more processor only can provide region to one or more identification engines, and wherein those bells and whistles are in addition to area
Except the semantic type in domain.Bells and whistles may include the characteristic for indicating one of the following or more: in screenshotss image
The absolute size in region, the relative size in region in screenshotss image, the position in region in screenshotss image and snapshot
The density of the pixel in the region as in.For example, it may be possible to not send very small image, may not send for being known by identification engine
Other image (that is, the image for not having sufficiently high pixel density) without sufficiently high resolution ratio, may not send only
Only intake may not send the smaller portions of screenshotss image and/or be the image in the less prominent part of screenshotss image
Deng.
Turning now to Fig. 1, it is shown in which that the example context of techniques disclosed herein may be implemented.Example context includes
It calculates equipment 120, content router engine 128, content recognition engine 129A-C, interactive content and generates system 130 and reality
Body and action database 136.In some implementations, calculate equipment 120 be Portable movable calculate equipment, such as cellular phone,
Tablet computer, wrist-watch, headset equipment (such as glasses), virtual or augmented reality equipment, other is worn at laptop computer
Wear equipment, audio-frequency/video frequency system, navigation system, automobile and other Vehicular systems etc..
Although content router engine 128, content recognition engine 129A-C and interactive content is shown in FIG. 1 to generate
System 130 is separated with equipment 120 is calculated, but in some implementations, one or more components in those components it is all
Or aspect can be realized by calculating equipment 120.Moreover, although screenshotss segmenting system 121 is shown as in Fig. 1 to calculate equipment
120 a part, but in some implementations, the whole or aspect of system 121 can by far from calculate one of equipment 120 or
More calculate equipment to realize.Fig. 1 one or more components by far from calculate equipment 120 one or more meters
It calculates in the realization that equipment is realized, calculates equipment 120 and remote computing device can be via such as local area network (LAN) and/or wide area
Net (WAN) (for example, internet)) one or more networks communicated.
Calculating equipment 120 is client computing device, and is generated in all cases to the use for calculating equipment 120
The content that family is shown.For example, calculating equipment 120 can be carrying out using one in 127, and generate for via calculating
The content that the screen of equipment 120 is shown to user can be dominated at least partly by the application.It may include that can pacify using 127
One or more in the various applications calculated in equipment 120, such as web browser application, personal assistant is answered
With, business comment application, social networking application, chat application, SMS application, music application, Video Applications and/or offer be used for
Explore the application at the interface of the information about film, TV programme and other media.
Screenshotss segmenting system 121 at least selectively captures screenshotss image, and the screenshotss image capture is in capture screenshotss image
When at least part of display for being provided by calculating equipment 120, and the content segmentation Cheng Ji that will be shown on calculating equipment 120
In one or more semantic regions of the pixel of screenshotss image.In some implementations, screenshotss segmenting system 121 also with content road
It generates system 130 by device engine 128 and/or interactive content to dock, to obtain the friendship based on one or more cut zone
Mutual formula content.In some implementations, screen partition system 121 can be independent application.In some implementations, screenshotss segmentation system
System 121 can be integrated wholly or partly to calculate a part of the operating system of equipment 120 or firmware.
Screenshotss segmenting system 121 in shown realization includes screenshotss capture engine 122, segmentation engine 123, interface engine
124 and rendering engine 125.Screenshotss capture engine 122 captures screenshotss image, each screenshotss image capture is currently by calculating
Equipment 120 is supplied at least part of the display of user.
In some implementations, screenshotss capture engine 122 in response to user and is calculated in response to user interface input module 126
The interaction of one or more user interface input devices of equipment 120 and the certain user interface that provides inputs to capture screenshotss
Image.For example, in some implementations, screenshotss capture engine 122 can capture screenshotss image in response to following operation: pass through touch
Shield " pressing " (for example, short-press, long-pressing, with the power of an at least threshold level press) of visual user interface element；Calculate equipment 120
The actuating of mechanical interface element；It is supplied to the verbal order for calculating the microphone of equipment 120；One or more areas of touch screen
It presses in domain；Etc..In some implementations, screenshotss capture engine 122 can in response to other standards (such as via calculate equipment
120 open new opplication, are switched to different virtual screens etc. via equipment 120 is calculated) it is cut additionally and/or alternatively to capture
Screen image.In some implementations, screenshotss capture engine 122 can additionally and/or alternatively continuously, periodically and/or
Screenshotss image is captured with another rule or irregular spacing.
The screenshotss image that screenshotss capture engine 122 captures is divided into one or more semantic regions by segmentation engine 123.
In some implementations, segmentation engine 123 analyzes multiple pixels of screenshotss image, to determine one or more areas of screenshotss image
Domain and corresponding semantic type is distributed to each region.Region limits the continuum of screenshotss image, and the semanteme in region
Type is classified to including content in this region.Semantic type may include such as " image ", " text filed ", " column
Table entry " etc. --- and/or more granularity types (" photographs ", " image painted " etc.).
Segmentation engine 123 can use various technologies to determine the region of screenshotss image and/or the semantic type in region.?
In some realizations, segmentation engine 123 include training machine learning model (for example, convolutional neural networks (CNN) model) or with
Trained machine learning model communication, and the machine learning model of training can be utilized by segmentation engine 123, to determine region
And/or the semantic type in region.For example, trained machine learning model can be trained based on multiple training examples, with can
Input of the multiple pixels of application image as model, and the region and those regions for identifying input picture are generated on model
Semantic label output.In some in those are realized, it can be selected as that " side is defeated to receive user with training pattern
Enter ", and generate region of the identification comprising user's selection and optionally identify the output of the semantic label in the region.
In some implementations, segmentation engine 123 realize heuristic particle extractor with determine screenshotss image region and/or
The semantic type in region.In some in those implementations, heuristic particle extractor covers screenshotss using unit grid
Image, such as the coarseness grid of square shaped cells.For each unit of grid, heuristic particle extractor analysis is by list
(for example, less than 10%, such as 2.6%), and analysis pixel-based is to the unit point for the score of the pixel for the image that member includes
Class.Each unit belongs to which of multiple candidate classifications according to it to classify.For example, unit can be by binary class
" photo " or " non-photograph ".The classification of unit leads to cell matrix, cell matrix each be assigned corresponding classification.For example,
For binary class (for example, photo/non-photograph), each unit can be assigned positive (for example, photo) or negative (non-photograph
Piece) classification.Unit with given classification can be covered by minimum bounding box and merge the bounding box of intersection.For example, two
In system classification, positive unit can use bounding box and cover and merge intersection frame.The bounding box for not being able to satisfy size threshold value can
To be optionally dropped.If screenshotss image is contracted by before being analyzed by heuristic particle extractor, bounding box can be with
It is amplified to original screenshot resolution ratio.Bounding box identifies the position in the region in original screenshot, and for generating bounding box
The semantic label in those regions of Classification and Identification.
In some implementations, it is less than entire grid cell to be handled by heuristic particle extractor.For example, if the choosing of user
The position (for example, pressing on display) selected is provided as " side input ", then the analysis of grid cell can be selected with user
Start at the corresponding grid cell in the position selected.As long as bounding box continues to increase (as long as that is, adjacent list at least one direction
Member classification having the same), analysis proceeds to adjacent cells.It, will not when bounding box stopping is grown in any direction
Analyze the grid cell for the limit that the possibility exceeded it in this direction is grown.When bounding box stops growing in all directions
When, the analysis of grid cell can be completely stopped.The reality of heuristic particle extractor is provided in Fig. 5, Fig. 6 A and Fig. 6 B
Existing additional description.
Interface engine 124, which is provided, generates system 130 and/or other components with content router engine 128, interactive content
Interface.Interface engine 124 generates the offer of system 130 and snapshot to content router engine 128 and/or to interactive content
The corresponding content in one or more regions of picture.For example, interface engine 124 can provide the multiple of the region of screenshotss image
The instruction of the semantic label in pixel and the optionally region.In some implementations, the optionally analyzed area of interface engine 124
One or more characteristics, and and if only if when those standards meet one or more threshold values just by the region be supplied to one or
More components.The characteristic in region may include region semantic label and/or instruction it is below those of one or more
Characteristic: the absolute size in the region in screenshotss image, the relative size in region in screenshotss image, region in screenshotss image
The density of the pixel of position and the region in screenshotss image.For example, when region is unsatisfactory for size threshold value (for example, being very small
Region) when, when the region do not have sufficiently high resolution ratio (that is, the pixel in the region is not sufficiently high density) to be used for
When being identified by one or more content recognition engine 129A-C and/or when the region only occupy the sub-fraction of screenshotss image
And/or when in the non-protruding part of screenshotss image, interface engine 124 can not provide content for the region.
Rendering engine 125 manages the presentation of the interactive content generated based on identified region.For example, rendering engine
125 can be generated for rendering to the visual display and/or audible output of the interactive content generated of user.For example, wash with watercolours
Dye engine 125 can make interactive content be shown on the display screen for calculating equipment 120.For example, interactive content can be with
Be shown in one or more information " card " and/or " drop-down menu ", it is therein any one can optionally be covered on by analyzing
At least part of content for being captured of screenshotss image on, to generate interactive content.
There is provided herein the additional descriptions to engine 122-125.In some implementations, one or more engine 122-
125 whole or aspect can be combined and/or be realized in another engine.For example, in some implementations, the one of engine 124
A or more aspect can be incorporated into engine 123.Moreover, although engine 122-125 is illustrated in the example context of Fig. 1
It is calculated in equipment 120 to be arranged on, but this does not imply that limitation.In other implementations, one in engine 122-125 or
The whole or aspect of more can be realized on far from one or more calculating equipment for calculating equipment 120.
Content router engine 128 determines which of multiple content recognition engines (such as engine 129A-C) will processing
By the pixel for the given area that interface engine 124 provides.Content recognition engine 129A-C each is configured as: receiving area
Multiple pixels are as input, and the instruction for providing at least some contents in the region is used as output.For example, content recognition engine
129A can be configured as: receiving the pixel with the region of semantic label of photo, and provides to be present in and be formed by pixel
Image in one or more entities instruction, such as one or more special entities are (for example, instruction flower
(flowers) entity of narcissus and daisy (daisy)) and/or entity class (for example, entity of instruction flower).In addition, for example, interior
Holding identification engine 129B can be configured as: receiving the pixel with the region of semantic label of text, and provides by picture
The instruction of one or more characters and/or word present in the image that element is formed.In some implementations, in engine 129A-C
It is one or more may include image search system and/or deep neural network such as CNN.
In some implementations, content router engine 128 is based at least partially on the semantic label of given area to select
The engine of the processing of pixel for given area.It is deposited for example, content recognition engine 129A can be specifically configured as determination
The content being in the region of the semantic label with instruction photographs, engine 129B can be particularly configured as identification and deposit
The content being in the region with the semantic label for indicating non-photographic image, and engine 129C can be particularly configured as
Identification is present in the content in the region of the semantic label with instruction text.In such an example, content router engine
128 provide the pixel in the region from the semantic label with instruction photographs to content recognition engine 129B, with processing
Those pixels.
In some implementations, content router engine 128 can when selecting content recognition engine using additional and/or
The standard of substitution.For example, the size in region, the resolution ratio in region and/or other characteristics in region can influence which content is known
Other engine is equipped with the pixel from the region.In addition, for example, it may be considered that the availability of content recognition engine.Although will in Fig. 1
Content router engine 128 and content recognition engine 129A-C are illustrated as separating with calculating equipment 120, but in some realization sides
In formula, in those components it is one or more can calculate equipment 120 on realize.
Interactive content generates interactive content of the generation of system 140 for being presented to the user via equipment 120 is calculated,
Middle interactive content is customized to the content shown from calculating equipment 120 to user.Interactive content generates system 140 can
Based on one or more regions determined by segmentation engine 123 and to be optionally based on their semantic type come in generating
Hold.It includes that entity determines engine 132 and acts determining engine 134 that interactive content, which generates system 140,.
In some implementations, entity determines that engine 132 is received from one in content recognition engine 129A-C via calculating
Equipment 120 is shown to the instruction of content present in the region of the screenshotss image of the content of user.Entity determines that engine 132 is based on
Provided instruction is to determine one or more entities quoted in the content.Entity can for example with people, interested position
Set, address, one in telephone number etc. it is associated.In the implementation, instruction explicitly indicates entity, and entity determines engine
132 can choose the entity and/or one or more related entities as will be one of interactive content generated or
The entity of focus in terms of more.
In some implementations, reality is not explicitly indicated by the instruction of an offer in content recognition engine 129A-C
Body.For example, one in content recognition engine 129A-C can provide text, the text is present in text filed, but this article
This indefinite instruction any entity associated with the text.In in these implementations some, entity determines that engine 132 can be with
One or more entities are determined based on such information.For example, entity determine engine 142 can determine with it is one or more
The strong associated one or more entities of text or other information in a entity data bak (such as knowledge graph).For example,
Text can be most associated with by force with the alias of special entity.
In some implementations, it acts and determines that engine 134 is determined to determine that the entity that engine 132 determines executes to by entity
One or more computer baseds movement.Those realize in it is some in, act determine engine 134 be based on be mapped
Computer based to the entity in such as entity and one or more databases of action database 136 acts determining base
In the movement of computer.Entity and action database 136 include that each of multiple entities arrive associated with the entity one
The mapping of a or more computer based movement.Movement can directly with entity map, and/or can via with entity
The mapping indirect mappers of class are to entity.For example, making a phone call the movement of number can be mapped in multiple particular telephone numbers
Each, and/or can be associated with the class of general telephone number.In addition, for example, playing the movement of film can be reflected
It is mapped to multiple films, common film and/or only can be used in equipment 120 using one in 127 by being mounted on to calculate
Each of the film of program request viewing.
In the realization of movements multiple for Entity recognition, acts and determine that engine 134 can be optionally based on one or more
Multiple factors carry out ranking and/or filtering to the movement that is identified, such as: the associated intensity of movement and entity and/or
The class of entity；The history popularity generally acted；The history popularity of the movement for the application that content is originated from；Whether the movement can be through
It is executed by one or more applications 127 being mounted in calculating equipment 120；Via one be mounted in calculating equipment 120
Or more application 127 execution movement history popularity；Etc..
Interactive content, which generates system 130, will be presented to calculating equipment 120 based on the movement generation determined by engine 134
Interactive content.Interactive content can be vision, the sense of hearing and/or can via calculate equipment 120 one or more use
Family interface output equipment is supplied to the other forms of user.As an example, interactive content may include graphic elements (text
Originally, icon and/or image), when user selects the graphic elements via the user interface input device for calculating equipment 120, make
It calculates equipment 120 and executes one or more movements.For example, graphic elements can with cause it is one or more movement
The link of execution is associated.Movement may include the specific shape for for example accessing particular webpage, issuing specific search, access application
State, presentation additional media etc..Can optionally generate multiple projects of interactive content, and can optionally with non-interactive type
Content, which combines, provides interactive content, the content of alias or other attributes such as including one or more entities.
In some implementations, movement determines that engine 134 can be determined optionally and determines engine 132 independently of from entity
And/or one or more movements of the input of any of content recognition engine 129A-C.For example, in some implementations,
Interactive content can enable calculate equipment user save multiple pixels in determined region, share those pixels and/
Or it is specified to be sent to those of one or more add-on assembles pixel, the content in region and/or be used for base for identification
In the other interactive content of the Area generation.In some in those are realized, act and determine that engine 134 can be based on having
Certain semantic label and/or region with one or more bells and whistles generate interactive content.For example, in response to true
Determine region with one or more certain semantic types (for example, instruction " image " semantic type or be not " sky/nothing " appoint
What semantic type) semantic type, can provide interactive content allow users to execute one that focuses on the region or
More movements.For example, in response to determining region and determining the interaction that the region has semantic type " image ", for the image
Formula content can be generated and be configured to select the region (such as long-pressing) in response to user and be shown.Interactive content can
So that the calculating equipment of user is able to carry out one or more movements focused on the area.
Fig. 2 shows will calculate the content segmentation shown in equipment 120 at region and based on the generation friendship in region
Mutual formula content 207 is to provide the example being presented to the user via equipment 120 is calculated.In Fig. 2, screenshotss capture engine 122 is captured
Screenshotss image 201, the capture of screenshotss image 201 are supplied at least one of the display of user by the display screen of calculating equipment 120
Point.Screenshotss image 201 is supplied to segmentation engine 123 by screenshotss capture engine 122.
Segmentation engine 123 analyzes multiple pixels of screenshotss image 201 to determine one or more regions of screenshotss image
And corresponding semantic type is distributed to each region.Segmentation engine 123 can use various technologies to determine screenshotss image
Region and/or region semantic type.In some implementations, segmentation engine 123 includes the machine learning model (example of training
Such as, convolutional neural networks (CNN) model) or communicate with trained machine learning model, and the machine learning model of training can
To be utilized by segmentation engine 123, to determine the semantic type in region and/or region.In some implementations, segmentation engine 123 is real
Existing heuristic particle extractor is to determine the region of screenshotss image and/or the semantic type in region.
Segmentation engine 123 provides the semantic type of one in region with region 202 to interface engine 124.Interface engine
124 extract multiple pixels (for example, all or subset) of corresponding with region screenshotss image, and to content router engine
128 provide the instruction of the semantic type in pixel and region 203.In some implementations, interface engine 124 is defeated in response to user interface
Enter and (be such as specifically directed to the input of general user interface or user interface input in the region) to provide the pixel and semanteme in region 203
The instruction of type.In some implementations, interface engine 124 meets one or more based on one or more characteristics for determining region
Multiple threshold values provide the pixel in region 203 and the instruction of semantic type.
Content router engine 128 selects content recognition engine 129A from multiple content recognition engines, and will come from
The pixel in region 204 is supplied to engine 129A.In some implementations, content router engine 128 is based on area as described herein
The semantic type in domain selects content recognition engine 129A.In some implementations, content router engine 128 be based on it is additional and/
Or alternate standard (characteristic in such as region) selects engine 129A.In some implementations, router 128 can be based on engine 129A
Attribute pre-process the pixel for being supplied to engine 129A.For example, router 128 can change and be formed by provided pixel
The size and/or resolution ratio of image can be handled by engine 129A with realizing or more suitably be formatted for engine
The image of 129A processing.
Content recognition engine 129A determines at least some contents for indicating those pixels based on the pixel from region 204
One or more content instructions 205.Engine 129A determines that engine 142 provides content instruction 205 to entity.Entity determines engine
142 determine at least one entity 206 quoted in the content based on provided content instruction 205.
Entity determines that engine 142 provides entity 206 to determining engine 144 is acted.Act determine engine 144 be determined to by
One or more computer based movements relevant to entity 206 executed, and interactive content 207 is generated, the interaction
Formula content 207 makes it possible to execute those movements.
Engine 144 provides interactive content 207 to rendering engine 125 so that interactive content is presented in rendering engine 125
207.In some implementations, the display content captured by substitution by screenshotss image 201, or by providing by screenshotss image
201 capture display contents interactive content " on " part, rendering engine 125 display interactive content 207.
Turning now to some realizations and other realities described herein of the exemplary particular example of Fig. 4 A- Fig. 4 D, Fig. 2
Now described by additional detail.In Figure 4 A, calculating equipment 420 is on the display screen 440 for calculating equipment 420 shown in display
Content.The content being shown on display screen 440 can be applied (such as by the information receiving and transmitting executed on calculating equipment 420
Do not include the information receiving and transmitting application for the function from information receiving and transmitting application fetches image, text and/or other contents) display.
The content being shown on display screen 440 includes being sent to the first of the user for calculating equipment 420 by " Susan (Susan) " to disappear
The first content of text 444 for including in breath.The content further includes include in the second message for being sent to user by Susan
Two content of text 445 and the first image 446.Content further includes replying interface element 447, and user can choose reply interface element
447 reply message to generate, and content further include can be interacted by user so that calculate equipment 420 execute it is one or more
The system interface element 441,442,443 of movement.
Fig. 4 B shows the screenshotss image 460 of the content shown by the calculating equipment 420 in Fig. 4 A.Screenshotss image 460 can
To be captured by screenshotss capture engine 122.System interface element 441-443 is omitted (for example, screenshotss in the screenshotss image 460 of Fig. 4 B
The region of those elements " top " can only be captured), although they can be included in screenshotss image in other implementations.Figure
The instruction in the region determined by segmentation engine 123 based on screenshotss image is also shown in 4B.Region 461A includes in the first text
Hold 444, and can have first semantic type of such as " text ".Region 462A includes the second content of text 445, and
It can have the first semantic type.Region 463 includes the first image 446, and can have second semanteme of such as " image "
Type.Region 465 includes to reply interface element 447, and can have the third semantic type of such as " UI element ".It can also be with
Another region of all areas of the screenshotss image 460 including not including by region 461A, 461B, 463 or 465 is generated, and
It can have the 4th semantic type of such as "None".Although having graphically illustrated region in figure 4b, but it is to be understood that segmentation
Engine 123 can limited area in various ways.For example, region can be limited to the middle imago in the region by segmentation engine 123
All pixels in the pixel wide and pixels tall of element and the center pixel.
The friendship that Fig. 4 C shows the example mobile computing device 420 of Fig. 4 A and can be shown by mobile computing device 420
One example of mutual formula content.In some realizations of Fig. 4 C, the user for calculating equipment may be had been provided especially for packet
The user interface in the region 463 (Fig. 4 B) containing colored image inputs, " long-pressing " or " long click " in such as region or for this
The language in-put (for example, language in-put of " telling me more about the image on screen ") in region.Based on for region 463
User interface input, interface engine 124 can optionally together with the semantic type in the region instruction (for example, " image ") together
The pixel in region 463 is provided to content router engine 128.In some implementations, interface engine 124 provides the picture in region 463
Element, without providing the pixel from any other region.Those realize it is some in, do not provide from any other region
Pixel may cause one or more downstream components to the less consumption of computing resource (for example, since they need not also be analyzed
Those pixels) and/or reduction network flow (for example, when downstream components far from calculate equipment 420 when).
Content router engine 128 can be optionally based on the engine and be configured as processing picture associated with semantic type
A usually offer pixel into content recognition engine 129A-C.The engine can analyze pixel and determine the content of pixel
One or more instructions, such as image is the instruction of Daisy (daisy flower).
Interactive content, which generates system 130, can use the instruction of content to generate interactive content, such as graphic elements
474A, 474B and 474C.For example, interactive content, which generates system 130, can be generated graphic elements 474A, so that graphic elements
The selection of 474A executes one or more movements so that calculating equipment 420, one or more movement cause to issue with
The relevant search of Daisy (for example, search " daisy (daisy) " or " daisy flower (Daisy) ").In addition, for example, handing over
Graphic elements 474B can be generated in mutual formula content generation system 130, so that the selection of graphic elements 474B causes to calculate equipment 420
One or more movements are executed, one or more movement leads to the spy applied using 127 " garden (garden) "
It is accessed to determine state.For example, the selection of graphic elements 474B can to calculate the opening of equipment 420 garden (garden) application simultaneously
Navigate to the state for focusing on Daisy or the application in general decoration flower.In addition, for example, interactive content generates system
130 can be generated graphic elements 474C, so that the selection of graphic elements 474C causes to calculate the retrieval of equipment 420 and/or display is young
One or more additional images of chrysanthemum.
Interactive content generates system 130 and also generates non-interactive content 472, which provides image
The instruction of the class of the instruction of entity shown in (" Daisy ") and the entity (" Flower (flower) ").It is shown in figure " card " 470
Show and the content that system 130 generates is generated by interactive content, other contents on the figure " card " 470 covering display screen 440.
Further it is provided that meeting the instruction 473 in region 463, to provide feedback to the user for calculating equipment so that user knows: graphics card
470 content is directed to region 463, and/or is provided based on user to the selection in the region 463.Instruction 473 and/or figure
The generation and/or formatting of shape card 470 can generate system 130 by interactive content and/or rendering engine 125 executes.
Fig. 4 D shows the example mobile computing device 420 of Fig. 4 A and the interactive mode that can be shown by mobile computing device 420
Another example of content.In some realizations of Fig. 4 D, the user for calculating equipment, which can provide, is not directed to any specific region
User interface inputs, and " long-pressing " or " length is hit " or general language in-put on such as system element 482 are (for example, language in-put
" telling me more about the content on screen ").It is inputted based on more generally user interface, interface engine 124 can be to content
Router engine 128 provides the pixel of multiple regions, optionally together with the instruction of the semantic type in those regions.For example, interface
Engine 124 can provide the pixel from each of region 461A, 461B and 463.In some implementations, interface engine
124 provide the pixel of region 461A, 461B and 463, without providing pixel (such as the "None" region from any other region
And/or " UI element " region 465).Those realize it is some in, not providing the pixel from any other region may cause
One or more downstream components to the less consumption (for example, since they need not also analyze those pixels) of computing resource and/
Or the network flow (for example, when downstream components are far from equipment 420 is calculated) of reduction.
The semantic type that content router engine 128 can be optionally based on region draws to one or more content recognitions
It holds up 129A-C and the pixel in each region is provided.For example, router 128 can provide region 463 to content recognition engine 129A
Pixel, to content recognition engine 129B provide region 461A pixel, and to content recognition engine 129B provide region
The pixel of 461B.Those engines can analyze those pixels and determine one or more instructions of the content of pixel.For example, engine
129A can provide the instruction that region 463 includes Daisy, and it includes bulleted list that engine 129B, which can provide region 461A,
Instruction, and the text of those projects can be provided.
Interactive content generate system 130 can use the instruction of content generate such as graphic elements 474A, 474B,
The interactive content of 474C and 477.Graphic elements 474A-C is identical as shown in Fig. 4 C.Interactive content generates system 130
Graphic elements 477 can also be generated, so that the selection of graphic elements 477 is so that calculate equipment 420 for the project listed (from region
The instruction of content in 461A exports) it is added to Shopping List (shopping list), such as by one of calculating equipment 420
Or more application 127 maintenance Shopping Lists.
Interactive content generates system 130 and also generates non-interactive content 472, which provides image
The instruction of the class of the instruction of entity shown in (" daisy ") and the entity (" flower ").In the first figure " card " 470 provide by
Interactive content generates the content relevant to the content in region 363 that system 130 generates, and first figure " card " 470 covering is aobvious
Other contents on display screen curtain 440.It is provided in the second graph " card " 475 being visually distinct from and system is generated by interactive content
130 contents relevant to the content of region 361A generated, the second graph " card " 475 also cover its on display screen 440
Its content.The generation and/or formatting of card 470 and 475 can generate system 130 and/or rendering engine 125 by interactive content
It executes.
Referring now to Figure 3, show another example, by the content segmentation shown on the computing device at region and
Based on a generation interactive content in region to provide for being presented to the user via calculating equipment.In Fig. 3, screenshotss are caught
It obtains engine 122 and captures screenshotss image 301, the display that the capture of screenshotss image 301 is supplied to user by calculating the display screen of equipment
At least part.Screenshotss image 301 is supplied to segmentation engine 123 by screenshotss capture engine 122.
Segmentation engine 123 analyzes multiple pixels of screenshotss image 301, to determine one or more regions of screenshotss image
And corresponding semantic type is distributed to each region.Segmentation engine 123 can use various technologies to determine screenshotss image
Region and/or region semantic type.
Segmentation engine 123 provides the semantic type of one in region with region 302 to interface engine 124.Interface engine
124 determine the instruction of the semantic type in the offer region of engine 144 and region 302 to acting.In some implementations, interface engine
124 in response to provided by user interface input module 126 user interface input (user interface input be particularly directed to the area
Domain, such as be directed to the long-pressing or other selections in the region) come provide region and region 302 semantic type instruction.
It is one or more that movement determines that engine 144 is determined to be performed based on the semantic type in provided region
Computer based movement.For example, acting for the region with semantic type " image " and determining that engine 144 can provide friendship
Mutual formula content, the interactive content enable the calculating equipment (Local or Remote) of user to save the multiple of identified region
It pixel, shared (such as passing through Email, text, chat) those pixels and/or specified to send for remote server
Those pixels, for identification and/or the interactive content other based on the Area generation.This enables the calculating equipment of user
Execute one or more movements on the specific region for the display for focusing on user.
It acts and determines that engine 144 provides interactive content 304 to the rendering engine 125 that interactive content 304 is presented.
Turning now to Fig. 4 E, the additional detail quilt of the exemplary specific implementation of Fig. 3 and other realizations described herein
Description.Fig. 4 E, which is shown, to be calculated equipment 420 and can be provided for via display screen 440 into the interactive mode that user shows
Hold.Interactive mode can be provided in response to being particularly directed to the user interface input in the region 463 (Fig. 4 B) comprising colored image
Content.For example, user can provide user interface input while watching the display of Fig. 4 A.User interface input can be example
" long-pressing " in such as region or " length is hit " or the language in-put in the region is directed to (for example, the language of " selecting image on the screen "
Speech input).
It is inputted based on the user interface for being directed to region 463, interface engine 124 can determine that engine 144 provides to acting
The instruction of the semantic type in region 463 and region.It acts and determines that engine 144 can be determined in the region with semantic type
Upper execution computer action, and/or determine the instruction for extracting pixel corresponding with region 463.It acts and determines engine 144 also
Interactive content can be generated, such as graphic elements shown in pop-up window 476 " save image (saving image) ",
" share image (shared image) " and " search this image (searching for the image) ".
It acts and determines that graphic elements " save image " can be generated in engine 134, so that graphic elements " save image "
Selection automatically extract one or more (such as all) pixels in region 463 local or remote so that calculating equipment 420
Journey storage medium --- and automatically save image or one or more other interfaces are presented to user and thought with designated user
Where image is saved.It acts and determines that graphic elements " share image " can be generated in engine 134, so that graphic elements
The selection of " share image " so that calculate equipment 420 automatically extract one or more (for example, all) in region 463 as
Element, to be filled in Email, chat or other communications --- and automatically filling communication in image or to
One or more further interfaces, which are presented, in family should fill which type of communication with specified.It acts and determines that engine 134 can
To generate graphic elements " search image ", so that the selection of graphic elements " search image " to be based on so that calculating equipment 420
One or more (for example, all) pixels in region 463 issue search.Further it is provided that instruction 473, which meets area
Domain 463 is to provide feedback to the user for calculating equipment, so that user knows that interactive content is directed to region 463 and based on use
Family is provided the selection in the region 463.
Fig. 5 is to show the example side that screenshotss image is divided into one or more regions using heuristic particle extractor
The flow chart of method 500.For convenience's sake, the operation of flow chart is described with reference to the system for executing operation.The system can wrap
Include the various assemblies of various computer systems, such as segmentation engine 123.In addition, although showing method 500 with particular order
Operation, but this does not imply that limitation.One or more operations can be reordered, omit or add.
At frame 552, system receives screenshotss image.Screenshotss image capture is supplied to the aobvious of user by the calculating equipment of user
At least part shown.As Working Examples, it is assumed that system receives the screenshotss image 460 of Fig. 4 B.
At frame 554, system covers screenshotss image using unit grid.In some implementations, the grid of unit can be
Coarseness and/or rectangular cells.For example, the grid of unit can be square shaped cells, each square shaped cells is less than 0.2 "
Multiply 0.2 ", is, for example, less than 0.1 " to multiply for 0.1 " (for example, 0.9 " multiplies 0.9 ").Continue the Working Examples, Fig. 6 A shows cutting for Fig. 4 B
A part (that is, including colored part) of screen image 460, and show the element mesh that can be covered on screenshotss image 460
Lattice.Pay attention to being easy for diagram, the grid cell of Fig. 6 A is shown as that possible size is bigger in various implementations than them.
At frame 556, system classifies to each unit based on the pixel for including by unit.In some realizations
In, for each of multiple units of grid, the subset of the pixel for the image that network analysis includes by unit is (for example, small
In 10%, such as 2.6%), and classified based on the analysis to pixel subset to unit.In some implementations, the pixel of subset
It can be the quasi- random pixel of low difference of sparse dispersion, it is such as random based on the standard using Ha Erdun sequence and/or Sobol sequence
The pixel of sub-sampling selection.
System classifies to it according to which of multiple candidate classifications belonging to each unit.For example, single
Member can be " photo " or " non-photograph " by binary class.Continue the Working Examples, Fig. 6 A, which is shown, to be classified as with shade
Those of " non-photograph " unit, and show and be classified as " photo " without those of shade unit.For example, 61 quilt of unit
It is classified as " photo ", and unit 62 is classified as " non-photograph ".
System can use one or more of technologies to classify to given unit.For example, in some implementations, base
In the counting of the number of the unique color for the pixel analyzed and/or each of one or more of unique colors are deposited
Pixel quantity, unit can be classified as to " photo " or " non-photograph ".For example, if there is at least threshold value in the cells
The pixel of the unique color of number and/or the pixel that there is at least threshold number for one or more of unique colors, then it is single
Member can be classified as " photo ".As another example, the pixel of unit can be provided as the training classifier of training
Input, the training classifier are predicted to classify based on pixel group.Regardless of the technology for classification, the classification of unit leads to list
Variable matrix, each unit are assigned corresponding classification.
At frame 558, system generates bounding box based on the classification of unit.For example, system can be covered in binary class
Lid " just " unit and the bounding box for merging any intersection.System can optionally abandon any boundary for not being able to satisfy size threshold value
Frame.Continue the Working Examples, Fig. 6 B shows the grid cell of Fig. 6 A, wherein also showing bounding box 63.Bounding box 63 can be with
It is generated at frame 558, and bounding box 63 limits the one of a plurality of areas of screenshotss image 460.
At frame 560, system limits the semantic region of screenshotss image based on bounding box.If by one or more
Screenshotss image is contracted by before a block is analyzed, then bounding box can be expanded to original screenshot point in limited area by system
Resolution.The position in the region in (optionally, amplification) bounding box identification original screenshot.System can use for generating boundary
Frame is classified to identify the semantic label in those regions.Continue the Working Examples, based on raw based on the unit for being classified as " photo "
At bounding box 63 region, system can limit based on Fig. 6 B with instruction " photo " or the semantic label of other images
Bounding box 63.In some implementations, system can also be come by searching for the precise edge in the neighborhood at the rough edge detected
Finely tune the Roughen Edges in region.Whether the edge of given area, which can depend on system by system fine tuning, is expected with region
On the way.For example, fine tuning edge may be unnecessary to the analysis in region for identification engine, but when the region is to be extracted simultaneously
It may be desired whens saving, be sent to another user etc..
In some implementations, system processing in one or more pieces (for example, blocks 556 and 558) is less than entire grid
Unit.For example, if the position (for example, pressing over the display) of user selected is provided to system as " side input ",
Then the analysis of grid cell can start at grid cell corresponding with the position of the selection of user.As long as bounding box continues to increase
Long (as long as that is, adjacent cells classification having the same) at least one direction, analysis proceeds to adjacent cells.Work as boundary
When frame stops growing in any direction, the limit for extending beyond the possibility growth of bounding box in this direction will not be analyzed
Grid cell.When bounding box stops growing in all directions, the analysis of grid cell can be completely stopped.In these realities
In some in existing, the specific region that corresponding screenshotss image is inputted with user interface can be determined, without in the spy
The pixel determined in many units in the outside in region is analyzed.
Fig. 7 is to show that the content segmentation shown in equipment will be calculated into region and one or more spies based on region
Property executes the flow chart of the exemplary method 700 of one or more movements to region.The system may include various departments of computer science
The various assemblies of system, such as screenshotss segmenting system 121, content router engine 128, content recognition engine 129A-C and/or friendship
One or more components of mutual formula content generation system 130.In addition, although the operation of method 700 is shown with particular order,
This is not intended to limit.One or more operations can be reordered, omit or add.
At frame 752, at least part of screenshotss image for the display that system acquisition is provided by calculating equipment.
At frame 754, system divides the image into multiple regions based on the pixel of screenshotss image.System can use various
Technology determines the region of screenshotss image.For example, in some implementations, system include trained machine learning model or with instruction
Experienced machine learning model communication, and system can use trained machine learning model to determine region.In some realizations
In, system realizes heuristic particle extractor to determine the region of screenshotss image.
At frame 756, system determines at least one first characteristic of first area, and determines at least one of second area
Second characteristic.In some implementations, the first characteristic is the first semantic type, and the second characteristic is the second semantic type.One
In a little realizations, the characteristic of first area and/or second area includes the absolute size of corresponding region in screenshotss image, screenshotss image
In the relative size of middle corresponding region, screenshotss image in the position of corresponding region and screenshotss image the pixel of corresponding region it is close
Degree.
At frame 758, system executes specific action based on the first area with the first characteristic on the first region.Example
Such as, system can be with: based on the first area with the first characteristic, the firstth area for being used for content recognition is provided by content recognition engine
The pixel in domain；Based on the first area with the first characteristic, the specific content identification engine by being suitable for the first characteristic provides first
The pixel in region is used for content recognition；It can enable to select first area via user interface input, to cause to save
The pixel of first area, the pixel that first area is sent in one or more communications send the pixel of first area to
One or more content recognition engines；And/or other movements.
In some implementations, system is not based on the second characteristic and/or fails the second area pair with the first characteristic
Second area executes specific action.For example, if the second characteristic be " without/it is empty " semantic label, the pixel of second area can be with
It is not sent to any content recognition engine.In addition, for example, if the second characteristic be with the semantic label as the first characteristic not
With semantic label, then can send content recognition engine for the pixel of second area --- without by any of second area
Pixel is sent to the different content identification engine that the first movement can be directed to.
Fig. 8 is can be optionally for the example calculation for one or more aspects for executing technology described herein
The block diagram of device 810.In some implementations, calculate equipment 120, interactive content generates system 130 and/or other components can be with
One or more components including Example Computing Device 810.
Equipment 810 is calculated to generally include via at least one of bus subsystem 812 and multiple peripheral communications processing
Device 814.These peripheral equipments may include storage subsystem 824 (including for example memory sub-system 825 and file storage subsystem
System 826), user interface output equipment 820, user interface input device 822 and network interface subsystem 816.It outputs and inputs
Equipment allows to interact with the user for calculating equipment 810.Network interface subsystem 816 provides the interface for arriving external network, and coupling
Close the corresponding interface equipment in other calculating equipment.
User interface input device 822 may include keyboard, pointing device (such as mouse, trace ball, touch tablet or figure
Input board), scanner, the touch screen being integrated in display, the audio input device of such as speech recognition system, microphone
And/or other types of input equipment.In general, the use of term " input equipment ", which is intended to include, enters information into calculating
The equipment and mode of all possible types in equipment 810 or on communication network.
User interface output equipment 820 may include display subsystem, printer, facsimile machine or such as audio output apparatus
Non-vision display.Display subsystem may include cathode-ray tube (CRT), such as liquid crystal display (LCD) plate set
Standby, projection device or some other mechanisms for generating visual picture.Display subsystem can also be for example via audio output
Equipment provides non-vision display.In general, the use of term " output equipment " be intended to include from calculate equipment 810 to user or
To another machine or the equipment and mode of all possible types for calculating equipment output information.
Storage subsystem 824 stores programming and the data configuration for the function of providing some or all modules as described herein.
For example, storage subsystem 824 may include the logic for executing the selected aspect of the method for Fig. 5 and/or Fig. 7.
These software modules usually individually or with other processors are executed by processor 814 in combination.Storage subsystem
Memory 825 used in 824 can include multiple memories, and the multiple memory includes for depositing during program executes
It stores up the main random access memory (RAM) (RAM) 830 of instruction and data and wherein stores the read-only memory (ROM) 832 of fixed instruction.
File storage subsystem 826 can provide persistent storage for program and data files, and may include hard disk drive, floppy disk
Driver and associated removable media, CD-ROM drive, CD-ROM driver or removable media box.Realize certain realizations
The module of function can be stored in storage subsystem 824 by file storage subsystem 826 or be may have access to by processor 814
Other machines in.
Bus subsystem 812 is provided for making the various assemblies for calculating equipment 810 and subsystem it is anticipated that communicating with one another
Mechanism.Although bus subsystem 812 is shown schematically as single bus, the substitution realization of bus subsystem can make
With multiple buses.
Calculating equipment 810 can be various types of, including work station, server, computing cluster, blade server, clothes
Device field or any other data processing system of being engaged in calculate equipment.Due to the continually changing property of computer and networks, in Fig. 8
The description of the calculating equipment 810 of description is merely for illustrating the purpose of some realizations as specific example.Calculate many of equipment 810
Other configurations may have more than calculating equipment shown in fig. 8 or few component.
It, can in the case where system described herein collects the personal information about user or can use personal information
With provide a user control program or feature whether collect user information (for example, about the social networks of user, social movement or
The current geographic position of activity, the professional, preference of user or user) or control whether and/or how to be connect from content server
Receive the chance of content that may be more relevant with user.Furthermore, it is possible to one or more before storing or using certain data
Kind of mode handles these data, to remove personal recognizable information.For example, can handle the identity of user, make
Cannot determine personal recognizable information for user, or can be in place (such as the city, postal service for obtaining geographical location information
Coding or state rank) geographical location of user is summarized, so that not can determine that the specific geographic position of user.Therefore, it uses
Family can have the control to how to collect information and/or use information about user.
Although having been described and showing several realizations, it is available with for executing function and/or being tied
The various other means and/or structure of fruit and/or one or more advantages as described herein, and such variant and/or
Modification is considered in the range of realization described herein.More generally, all parameters as described herein, size, material and
Configuration is intended to be exemplary, and actual parameter, size, material and/or configuration will be depended on using the concrete application instructed.
Those skilled in the art will appreciate that being able to use at most routine experiment to determine many of specific implementation as described herein
Equivalent.It will thus be appreciated that aforementioned realization only provides in an illustrative manner, and in the following claims and their equivalents
In the range of, can by from specifically describe and it is claimed in a manner of different mode realize.The realization of the disclosure is related to herein
Each individual feature, system, article, material, external member and/or the method.In addition, if these features, system, system
Product, material, external member and/or method be not mutually internally inconsistent, then two or more this category feature, system, product, material, external members
And/or any combination of method includes within the scope of this disclosure.
Claims (15)
1. the method that the content shown on a kind of pair of display is split, comprising:
Screenshotss image is captured by one or more processors in multiple processors, the screenshotss image capture is by calculating equipment
It is supplied at least part of the display of user；
The screenshotss image is divided at least first area and second area, based on multiple pixels of the screenshotss image, by
One or more processors in the multiple processor carry out the segmentation；
First semantic type is distributed into the first area, simultaneously by one or more processors in the multiple processor
And multiple pixels based on the first area carry out the distribution；
The first semantic type based on the first area and the first area, by one in the multiple processor or more
Multiple processors generate interactive content；
Identification is set by the user via the user interface input device or another user interface input for calculating equipment
The standby particular user interface input provided, wherein particular user interface input is being directed to the display with firstth area
The corresponding part of the subset in domain；
In response to identifying the particular user interface input and based on the institute with the first area that is being directed to the display
The particular user interface input for stating the corresponding part of subset, provides the interactive content for via the use
The calculating equipment at family is presented to the user, wherein the user interface input via the calculating equipment of the user is set
The standby user to the interactive content selects the calculating equipment so that the user:
The one or more pixels for transmitting the first area, any pixel without transmitting the second area；
Saved in one or more non-transitory computer-readable mediums the multiple pixel of the first area without
Any pixel of the second area is saved, or
Electronic communication is generated, the electronic communication includes the multiple pixel of the first area, and the electronic communication
It does not include any pixel of the second area.
2. according to the method described in claim 1, wherein the interactive content includes graphic elements, when via user circle
When face input equipment selects the graphic elements, the graphic elements make the calculating equipment: one or more
The multiple pixel of the first area is saved in non-transitory computer-readable medium without saving the second area
Any pixel.
3. according to the method described in claim 1, wherein the interactive content includes graphic elements, when via user circle
When face input equipment selects the graphic elements, the graphic elements make the calculating equipment generate the electronic communication, institute
The multiple pixel that electronic communication includes the first area is stated, and the electronic communication does not include the second area
Any pixel.
4. according to the method described in claim 1, wherein generating the interactive content is based on the first area and described the
First semantic type in one region, and independently of the second area；And
The interactive content is wherein provided it is included in not provide for via the calculating equipment being presented to the user and is based on
The interactive content is provided in the case where any interactive content that the second area determines.
5. according to the method described in claim 1, wherein the multiple processor includes the one or more of the calculating equipment
It is a to calculate device handler and far from one or more teleprocessing units for calculating equipment；
Wherein one or more processor of the capture screenshotss image in the multiple processor is by one
Or more calculate device handler constitute；And
Wherein one or more processor of the generation interactive content in the multiple processor includes described
One or more teleprocessing units.
6. according to the method described in claim 5, wherein the screenshotss image being divided at least in the multiple processor
One or more processor of the first area and the second area is by one or more calculating equipment
Processor is constituted.
7. according to the method described in claim 6, further include:
From one or more calculating first group transmission of the device handler to one or more teleprocessing unit
The multiple pixel of the first area, it is one or more without any pixel of the second area to be transmitted to
Described first group of teleprocessing unit.
8. according to the method described in claim 7, wherein first semantic type being distributed in the multiple processor
One or more processor of the first area is made of one or more calculating device handler.
9. according to the method described in claim 8, further including at least one of the following:
From one or more described first group to one or more teleprocessing unit of device handler of calculating
Transmit first semantic type of the first area；And
Institute is selected based on first semantic type of the first area by one or more calculating device handler
Described first group for stating one or more teleprocessing units.
10. according to the method described in claim 1, further include:
The first area in the screenshotss image is determined by one or more processors in the multiple processor
Bells and whistles；
It wherein generates the interactive content and is based further on the bells and whistles.
11. meeting according to the method described in claim 10, wherein generating the interactive content depending on the bells and whistles
Threshold value.
12. according to the method for claim 11, wherein the bells and whistles indicate one of the following: the screenshotss image
In the absolute size of the first area, the relative size of the first area in the screenshotss image, the snapshot
The density of the pixel of the position and first area in the screenshotss image of the first area as in.
13. according to the method described in claim 1, the screenshotss image is wherein divided into at least described first area and described
Second area includes:
The screenshotss image is divided into multiple units, each unit includes unique group of the pixel of the screenshotss image
Pixel；
For each of the multiple unit unit, determine
The corresponding classification from multiple classification of pixel subset based on the unique group pixel for including by the unit；And
The first area is determined based on the corresponding classification of identified the multiple unit.
14. according to the method for claim 13, wherein determining that the first area includes:
The first area is determined based on one or more minimum bounding boxes, each minimum bounding box includes with described
Multiple units of the first classification in multiple classification.
15. according to the method for claim 13, wherein determining the classification packet of the given unit in the multiple unit
It includes:
The pixel subset for including by the given unit based on the determination of quasi- random selection process；With
The classification is determined based on the counting of the pixel subset as particular color.
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
CN201910221965.6A CN110009643B (en) | 2016-05-14 | 2016-12-27 | Segmenting display content into regions based on pixels of a screenshot image of captured content |
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US15/154,957 | 2016-05-14 | ||
US15/154,957 US9870623B2 (en) | 2016-05-14 | 2016-05-14 | Segmenting content displayed on a computing device into regions based on pixels of a screenshot image that captures the content |
Related Child Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201910221965.6A Division CN110009643B (en) | 2016-05-14 | 2016-12-27 | Segmenting display content into regions based on pixels of a screenshot image of captured content |
Publications (2)
Publication Number | Publication Date |
---|---|
CN107392915A CN107392915A (en) | 2017-11-24 |
CN107392915B true CN107392915B (en) | 2019-04-09 |
Family
ID=57794353
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201611223828.9A Active CN107392915B (en) | 2016-05-14 | 2016-12-27 | The pixel of screenshotss image based on capture content will calculate the content segmentation shown in equipment into region |
CN201910221965.6A Active CN110009643B (en) | 2016-05-14 | 2016-12-27 | Segmenting display content into regions based on pixels of a screenshot image of captured content |
Family Applications After (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201910221965.6A Active CN110009643B (en) | 2016-05-14 | 2016-12-27 | Segmenting display content into regions based on pixels of a screenshot image of captured content |
Country Status (8)
Country | Link |
---|---|
US (2) | US9870623B2 (en) |
EP (2) | EP3362915B1 (en) |
JP (1) | JP6549806B1 (en) |
KR (1) | KR101958377B1 (en) |
CN (2) | CN107392915B (en) |
DE (2) | DE202016008193U1 (en) |
GB (1) | GB2550236A (en) |
WO (1) | WO2017200574A1 (en) |
Families Citing this family (28)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN108877334B (en) * | 2018-06-12 | 2021-03-12 | 广东小天才科技有限公司 | Voice question searching method and electronic equipment |
US10572566B2 (en) * | 2018-07-23 | 2020-02-25 | Vmware, Inc. | Image quality independent searching of screenshots of web content |
CN109168069A (en) * | 2018-09-03 | 2019-01-08 | 聚好看科技股份有限公司 | A kind of recognition result subregion display methods, device and smart television |
US11039196B2 (en) | 2018-09-27 | 2021-06-15 | Hisense Visual Technology Co., Ltd. | Method and device for displaying a screen shot |
CN109271983B (en) * | 2018-09-27 | 2022-04-12 | 海信视像科技股份有限公司 | Display method and display terminal for identifying object in screenshot |
CN109634494A (en) * | 2018-11-12 | 2019-04-16 | 维沃移动通信有限公司 | A kind of image processing method and terminal device |
CN113168283A (en) * | 2018-12-18 | 2021-07-23 | 西门子股份公司 | Knowledge acquisition method, device and system for modeling |
CN109726179A (en) * | 2018-12-29 | 2019-05-07 | 努比亚技术有限公司 | Screenshot picture processing method, storage medium and mobile terminal |
KR20200106703A (en) * | 2019-03-05 | 2020-09-15 | 삼성전자주식회사 | Apparatus and method for providing information based on user selection |
US11073975B1 (en) * | 2019-03-29 | 2021-07-27 | Shutterstock, Inc. | Synthetic image generation in response to user creation of image |
CN110059596B (en) * | 2019-04-03 | 2020-07-07 | 北京字节跳动网络技术有限公司 | Image identification method, device, medium and electronic equipment |
CN110502293B (en) * | 2019-07-10 | 2022-02-01 | 维沃移动通信有限公司 | Screen capturing method and terminal equipment |
US10936351B2 (en) * | 2019-07-19 | 2021-03-02 | UiPath, Inc. | Multi-anchor based extraction, recognition, and machine learning of user interface (UI) |
US20210037071A1 (en) * | 2019-07-29 | 2021-02-04 | Steven Thomas Schoenwald | Efficient distribution and display of media |
CN110658971B (en) * | 2019-08-26 | 2021-04-23 | 维沃移动通信有限公司 | Screen capturing method and terminal equipment |
CN110619773A (en) * | 2019-09-19 | 2019-12-27 | 广东小天才科技有限公司 | Method and system for generating outline box, storage medium and electronic equipment |
EP3948506A4 (en) * | 2019-09-20 | 2022-06-01 | Samsung Electronics Co., Ltd. | Electronic device and screen capturing method thereof |
KR20210045891A (en) * | 2019-10-17 | 2021-04-27 | 삼성전자주식회사 | Electronic device and method for controlling and operating of screen capture |
CN110727495B (en) * | 2019-10-18 | 2022-12-23 | 深圳市比量科技传媒有限公司 | Automatic segmentation screenshot method and system for interface elements |
KR102541981B1 (en) * | 2019-12-03 | 2023-06-12 | 구글 엘엘씨 | Conversion of static content items to interactive content items |
CN114667557A (en) * | 2019-12-05 | 2022-06-24 | 谷歌有限责任公司 | Dual color management for multi-pixel density displays |
KR20210123009A (en) | 2020-04-02 | 2021-10-13 | 삼성전자주식회사 | Electronic device and method for controlling and operating of screen capture |
CN111638844A (en) * | 2020-05-22 | 2020-09-08 | 维沃移动通信有限公司 | Screen capturing method and device and electronic equipment |
DE102020123504A1 (en) * | 2020-09-09 | 2022-03-10 | Carl Zeiss Microscopy Gmbh | MICROSCOPY SYSTEM AND METHOD OF GENERATING AN HDR IMAGE |
US20220382802A1 (en) * | 2021-06-01 | 2022-12-01 | Google Llc | Smart suggestions for image zoom regions |
US11263749B1 (en) * | 2021-06-04 | 2022-03-01 | In-Med Prognostics Inc. | Predictive prognosis based on multimodal analysis |
DE112021007814T5 (en) * | 2021-07-23 | 2024-04-11 | Lg Electronics Inc. | Display device |
WO2024065234A1 (en) * | 2022-09-28 | 2024-04-04 | Citrix Systems, Inc. | Automation of repeated user operations |
Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
EP2312462A1 (en) * | 2009-10-14 | 2011-04-20 | CyberLink Corp. | Systems and methods for summarizing photos based on photo information and user preference |
CN102460515A (en) * | 2009-05-06 | 2012-05-16 | 奥多比公司 | Generating a modified image with additional content provided for a region thereof |
CN102521849A (en) * | 2010-10-14 | 2012-06-27 | 微软公司 | Region-based image manipulation |
CN102880381A (en) * | 2011-07-12 | 2013-01-16 | 索尼公司 | Context aware user interface system |
Family Cites Families (7)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7502521B2 (en) * | 2005-06-21 | 2009-03-10 | Microsoft Corporation | Image completion with structure propagation |
US9087059B2 (en) | 2009-08-07 | 2015-07-21 | Google Inc. | User interface for presenting search results for multiple regions of a visual query |
US8977639B2 (en) * | 2009-12-02 | 2015-03-10 | Google Inc. | Actionable search results for visual queries |
US8548990B2 (en) * | 2011-12-30 | 2013-10-01 | Microsoft Corporation | Presenting interactive images with search results |
KR102069014B1 (en) | 2012-09-25 | 2020-02-12 | 삼성전자 주식회사 | Apparatus and method for controlling split view in portable terminal equipment |
US9483518B2 (en) | 2012-12-18 | 2016-11-01 | Microsoft Technology Licensing, Llc | Queryless search based on context |
US9965559B2 (en) | 2014-08-21 | 2018-05-08 | Google Llc | Providing automatic actions for mobile onscreen content |
-
2016
- 2016-05-14 US US15/154,957 patent/US9870623B2/en active Active
- 2016-12-15 WO PCT/US2016/066941 patent/WO2017200574A1/en active Search and Examination
- 2016-12-15 KR KR1020187034592A patent/KR101958377B1/en active IP Right Grant
- 2016-12-15 EP EP16825948.9A patent/EP3362915B1/en active Active
- 2016-12-15 EP EP19174145.3A patent/EP3543869B1/en active Active
- 2016-12-15 JP JP2018560014A patent/JP6549806B1/en active Active
- 2016-12-21 GB GB1621800.0A patent/GB2550236A/en not_active Withdrawn
- 2016-12-27 CN CN201611223828.9A patent/CN107392915B/en active Active
- 2016-12-27 CN CN201910221965.6A patent/CN110009643B/en active Active
- 2016-12-29 DE DE202016008193.5U patent/DE202016008193U1/en active Active
- 2016-12-29 DE DE102016125883.0A patent/DE102016125883A1/en not_active Withdrawn
-
2017
- 2017-12-12 US US15/839,797 patent/US10147197B2/en active Active
Patent Citations (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN102460515A (en) * | 2009-05-06 | 2012-05-16 | 奥多比公司 | Generating a modified image with additional content provided for a region thereof |
EP2312462A1 (en) * | 2009-10-14 | 2011-04-20 | CyberLink Corp. | Systems and methods for summarizing photos based on photo information and user preference |
CN102521849A (en) * | 2010-10-14 | 2012-06-27 | 微软公司 | Region-based image manipulation |
CN102880381A (en) * | 2011-07-12 | 2013-01-16 | 索尼公司 | Context aware user interface system |
Also Published As
Publication number | Publication date |
---|---|
WO2017200574A1 (en) | 2017-11-23 |
CN107392915A (en) | 2017-11-24 |
CN110009643B (en) | 2020-05-05 |
CN110009643A (en) | 2019-07-12 |
EP3543869A1 (en) | 2019-09-25 |
EP3543869B1 (en) | 2021-02-03 |
GB2550236A (en) | 2017-11-15 |
US9870623B2 (en) | 2018-01-16 |
DE202016008193U1 (en) | 2017-04-26 |
US10147197B2 (en) | 2018-12-04 |
EP3362915A1 (en) | 2018-08-22 |
DE102016125883A1 (en) | 2017-11-16 |
GB201621800D0 (en) | 2017-02-01 |
US20180114326A1 (en) | 2018-04-26 |
KR101958377B1 (en) | 2019-07-02 |
US20170330336A1 (en) | 2017-11-16 |
EP3362915B1 (en) | 2019-05-29 |
JP2019522838A (en) | 2019-08-15 |
JP6549806B1 (en) | 2019-07-24 |
KR20180135074A (en) | 2018-12-19 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN107392915B (en) | The pixel of screenshotss image based on capture content will calculate the content segmentation shown in equipment into region | |
US20180225032A1 (en) | Generating interactive content items based on content displayed on a computing device | |
CN103714450A (en) | Natural language metric condition alerts generation | |
CN103714114A (en) | Natural language metric condition alerts orchestration | |
CN105264528A (en) | Client intent in integrated search environment | |
US20200159764A1 (en) | Method for Processing and Displaying Real-Time Social Data on Map | |
WO2018000744A1 (en) | Contact person detail prompting method | |
CN115698983A (en) | Client application content classification and discovery | |
JP6747683B1 (en) | Information processing device, method, and program | |
US20160277490A1 (en) | Using hierarchical reservoir sampling to compute percentiles at scale | |
JP6372165B2 (en) | Design management apparatus and program | |
US20190095073A1 (en) | System and method for visual exploration of subnetwork patterns in two-mode networks | |
KR20150101846A (en) | Image classification service system based on a sketch user equipment, service equipment, service method based on sketch and computer readable medium having computer program recorded therefor | |
CN109688041A (en) | Information processing method, device and server, intelligent terminal, storage medium | |
US11048713B2 (en) | System and method for visual exploration of search results in two-mode networks | |
CN114820011A (en) | User group clustering method and device, computer equipment and storage medium | |
JP2013196141A (en) | Terminal device, information display system and information display method | |
US20150170108A1 (en) | Server, user terminal, task management system, and method for managing task thereof | |
Triandafil et al. | Destination Management organizations: a systematization of recent literature with a focus on new research trends | |
JP2018077843A (en) | Thinking/discussion support system and method for the same | |
KR20220001614A (en) | Method for menu introduction system of MFP based on user pattern using machine learning | |
JP2023052442A (en) | Method of and system for generating animation image for presentation by dynamic keyboard interface | |
JP2021034034A (en) | Information processing apparatus, method and program | |
CN117991942A (en) | Interaction method, device, electronic equipment and storage medium | |
CN116402514A (en) | Entity object grading method, device, medium and equipment |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
CB02 | Change of applicant information | ||
CB02 | Change of applicant information |
Address after: American CaliforniaApplicant after: Google limited liability companyAddress before: American CaliforniaApplicant before: Google Inc. |
|
GR01 | Patent grant | ||
GR01 | Patent grant |