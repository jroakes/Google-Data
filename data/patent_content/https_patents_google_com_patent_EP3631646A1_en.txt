EP3631646A1 - Accelerated large-scale similarity calculation - Google Patents
Accelerated large-scale similarity calculationInfo
- Publication number
- EP3631646A1 EP3631646A1 EP18728476.5A EP18728476A EP3631646A1 EP 3631646 A1 EP3631646 A1 EP 3631646A1 EP 18728476 A EP18728476 A EP 18728476A EP 3631646 A1 EP3631646 A1 EP 3631646A1
- Authority
- EP
- European Patent Office
- Prior art keywords
- data
- processing unit
- entities
- query
- correlation
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/906—Clustering; Classification
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F17/00—Digital computing or data processing equipment or methods, specially adapted for specific functions
- G06F17/10—Complex mathematical operations
- G06F17/15—Correlation function computation including computation of convolution operations
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F17/00—Digital computing or data processing equipment or methods, specially adapted for specific functions
- G06F17/10—Complex mathematical operations
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F12/00—Accessing, addressing or allocating within memory systems or architectures
- G06F12/02—Addressing or allocation; Relocation
- G06F12/08—Addressing or allocation; Relocation in hierarchically structured memory systems, e.g. virtual memory systems
- G06F12/0802—Addressing of a memory level in which the access to the desired data or data block requires associative addressing means, e.g. caches
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F17/00—Digital computing or data processing equipment or methods, specially adapted for specific functions
- G06F17/10—Complex mathematical operations
- G06F17/18—Complex mathematical operations for evaluating statistical data, e.g. average values, frequency distributions, probability functions, regression analysis
Definitions
- This specification relates to computing processes for large-scale similarity calculations.
- an input sample matches multiple stored records.
- the database is likely to contain many DNA records (for example hundreds of thousands or even millions of records).
- the input sample can be the n records in the database that are determined to be the n closest matches to the input sample.
- the number n of retrieved records is smaller, typically much smaller, than the overall number of records in the database.
- the n retrieved records may be arranged in the order of most probable first.
- such a retrieval process can involve calculating a measure of similarity between the input sample and every record stored in the database, and then identifying the n records with the highest values of calculated similarity measure.
- the n retrieved records may be re-ordered so as to be arranged with reference to the value of calculated similarity measure.
- this process becomes increasingly computationally intensive and time consuming.
- Methods, systems, and apparatus including computer programs encoded on a computer storage medium, for obtaining data stored at a storage device using a first processor of an entity correlation system.
- the data includes information about multiple entities.
- the first processor generates data arrays using the obtained data.
- Each data array includes parameter values for multiple entities and is configured for processing at a respective computing cell of a second processor.
- the system provides the data arrays to the second processor.
- the second processor is configured to execute a correlation algorithm to concurrently process the data arrays at the respective computing cells.
- the second processor computes a correlation score based on calculations performed at the cells using the algorithm and the parameter values.
- the system determines relationships among entities of the data arrays based on the correlation score. The relationships indicate overlapping attributes that exist among subsets of entities.
- the method includes, obtaining, by a first processing unit of an entity correlation system, data stored at a storage device, the data comprising information about multiple entities; and generating, at the first processing unit, multiple data arrays using the data obtained from the data storage device.
- Each data array of the multiple data arrays : i) includes parameter values for multiple entities; and ii) is configured for processing at a respective computing cell of a second processing unit.
- the method includes providing, at the entity correlation system, at least two data arrays to the second processing unit, the second processing unit being configured to execute a correlation algorithm to concurrently process the at least two data arrays at respective computing cells of the second processing unit; computing, at the second processing unit, a correlation score based on calculations performed at the respective computing cells using the correlation algorithm and the parameter values for the multiple entities; and determining, at the entity correlation system, relationships among entities of the at least two data arrays based on the computed correlation score, wherein the relationships indicate overlapping attributes that exist among at least a subset of the entities.
- computing the correlation score comprises: selecting the particular correlation algorithm as a similarity algorithm or a conditional probability algorithm; calculating, using the particular correlation algorithm, an intersection between entities of the at least two data arrays and a union between entities of the at least two data arrays; and computing the correlation score based on the intersection and the union.
- the first processing unit is a central processing unit (CPU) that pre-sorts data obtained from the data storage device to generate the multiple data arrays;
- the second processing unit is a graphics processing unit (GPU) that performs parallel calculations using the parameter values for entities of the at least two data arrays;
- the particular correlation algorithm is a jaccard similarity algorithm, a cosine similarity algorithm, or a conditional probability algorithm.
- generating comprises: sorting, based on a sketching algorithm, the data comprising information about the multiple entities; and in response to sorting, generating a sketch representation of the data, each sketch representation corresponding to each of the multiple data arrays.
- each data array is a sketch representation of the data stored at the storage device; and at least a subset of the multiple data arrays comprises respective data arrays that each have a predetermined number of entities.
- each sketch representation is sized according to a quantity of computing cells that are included at the second processing unit.
- providing includes: storing each data array at a memory cache of the second processing unit, wherein the memory cache represents a compact memory of the second processing unit and each data array is sized according to the data capacity of the compact memory.
- At least one of the data arrays is configured for access by each of multiple computing cells that are included at the second processing unit.
- determining relationships among entities includes: determining whether the computed correlation scores exceed a threshold score; and in response to determining that the computed correlation scores exceed the threshold score, generating a listing of entities that are ranked using the correlation scores that exceed the threshold score.
- the method includes receiving first data items at a first processing unit (e.g., a CPU); generating, by the first processing unit and from at least the received first data items, data structures, each data structure representing a respective dataset; storing the data structures in a memory of a second processing unit (e.g., a GPU); receiving, at the first processing unit, a query from a user; processing in parallel, by the second processing unit, the query against two or more of the data structures stored at the second processing unit; and returning the results of the processing from the second processing unit to the first processing unit.
- a first processing unit e.g., a CPU
- storing the data structures in a memory of a second processing unit e.g., a GPU
- receiving, at the first processing unit, a query from a user processing in parallel, by the second processing unit, the query against two or more of the data structures stored at the second processing unit
- the second processing unit includes multiple processing cores, and processing, by the second processing unit, the query against the data structures comprises: processing the query in parallel in each processing core against a respective one of the data structures.
- processing, by the second processing unit, the query against the data structures stored at the second processing unit includes, for a data structure stored at the second processing unit, determining a respective measure of similarity between the data structure and the query.
- returning the results of the processing from the second processing unit to the first processing unit comprises returning information identifying the data structures that are n best matches to the query.
- the method includes the first processing unit generating a query data structure from the received query and sending the query data structure to the GPU; and wherein processing the query by the second processing unit comprises processing the query data structure against the data structures stored at the second processing unit.
- the data structures and the query data structure are KMV sketches.
- processing, by the second processing unit, the query against a data structure stored at the second processing unit comprises determining the union of the query data structure and the stored data structure.
- processing, by the second processing unit, the query against a data structure stored at the second processing unit comprises determining the intersection of the query data structure and the stored data structure.
- processing, by the second processing unit, the query against a data structure stored at the second processing unit includes determining the Jaccard similarity between the query data structure and the data structure.
- receiving the data items at the first processing unit comprises receiving the data items from a data hosting service; wherein receiving the data items at the first processing unit comprises receiving the data items from a data hosting service; and wherein the method further comprises returning the results of the processing from the first processing unit to the data hosting service.
- the method further includes: receiving, at the first processing unit, a second query; and processing, by the second processing unit, the second query against the data structures stored at the second processing unit.
- the method further includes: receiving second data items at the first processing unit; generating, by the first processing unit and from at least the received second data items, updated data structures, each updated data structure representing a respective dataset; and storing the updated data structures in the memory of the second processing unit.
- the method further includes: receiving, at the first processing unit, a third query; and processing, by the second processing unit, the third query against the updated data structures stored at the second processing unit.
- a processing system including a first processing unit in communication with a second processing unit is configured to carry out a method as defined in any one of the preceding paragraphs of this summary.
- a computer-readable medium contains stored instructions that, when executed by a processing system including a first processing unit in communication with a second processing unit causes the processing system to carry out a method as defined in any one of the preceding paragraphs of this summary.
- An aspect of the present disclosure provides a method comprising: receiving first data items at a first processing unit; generating, by the first processing unit and from at least the received first data items, data structures, each data structure representing a respective dataset; storing the data structures in a memory of a second processing unit; receiving, at the first processing unit, a query from a user; processing in parallel, by the second processing unit, the query against two or more of the data structures stored at the second processing unit; and returning the results of the processing from the second processing unit to the first processing unit.
- the first processing unit may be a CPU (central processing unit) and the second processing unit may be a GPU (graphics processing unit).
- a graphics processing unit can determine correlation scores, computation results, and/or similarity relationships among entities of pre-sorted data arrays with increased speed relative to other data correlation systems.
- the graphics processor can perform the necessary calculations associated with executing data correlation algorithms (jaccard similarity algorithms) without sorting/pre-sorting data before executing the correlation algorithm. Additionally, the graphics processor can perform the necessary calculations by engaging little to no inter thread data communications relative to other correlation systems. This is because each computing cell of the graphics processor performs computations on specific sets of data arrays for each query submitted by a user of the system.
- the described techniques can be implemented to achieve more than 20 million similarity calculations within one second using only a single computing cell of a graphics processor.
- the one second durations for achieving the at least 20 million similarity calculations is more than 10 times faster than the time required for a standard processor (e.g., a CPU) to perform the same amount of calculations.
- a standard processor e.g., a CPU
- the described techniques allow a given processor to process larger data arrays in a given time (or to process a data array of given size in a shorter time) and so effectively provide increased computing power for achieving data correlation calculations relative to other data processing apparatus.
- the described techniques provide a repeatable automated process that involves minimal human intervention and does not require manual execution of pre-sorting data, generating data arrays, or configuring a size of the data arrays.
- the techniques enable computing systems to quickly perform operations (e.g., a substantial number of similarity calculations) that the systems were previously unable to automatically perform in a fast manner due to challenges with using a k-min-hash or k-minimum value algorithm for sorting data in a graphics processor/GPU computing environment.
- FIG. 1 is a block diagram of an example computing system for determining correlations among entities using processors of the computing system.
- FIG. 2 is a flowchart of an example process for determining correlations among entities.
- FIG. 3 is an example architecture associated with at least one processor in the computing system of FIG. 1.
- FIG. 4 is another example architecture associated with the at least one processor in the computing system of FIG. 1.
- FIG. 5 is a block diagram of a computing system that can be used in connection with methods described in this specification.
- This document describes techniques for implementing a k-min-hash or k- minimum value (“KMV”) data processing algorithm to sort data that is pre-loaded at a graphics processing unit (GPU) to compute relationships between entities.
- the described techniques can be used to accelerate data correlation calculations, e.g., for determining similarities among entities, by storing pre-sorted data on a GPU so that computing cells of the GPU can quickly determine the relationships between the entities.
- the GPU determines the relationships by executing a particular type of correlation algorithm.
- the relationships can be computed or determined at the GPU with increased speed relative to current systems because the GPU is no longer required to pre-sort the data prior to executing the correlation algorithm.
- an entity correlation system stores large amounts of data that includes information describing different entities.
- the system can include a central processing unit (CPU) that is configured to obtain data from a data storage device, pre-sort the data, and generate multiple pre-sorted data arrays that each include a predetermined quantity of entities. Pre-sorting the data and generating the data arrays occurs in response to the CPU executing a KMV sketch algorithm to process the obtained data.
- the data arrays correspond to respective sets of data (or datasets).
- entities of one dataset can be items, persons, or various electronic and real world objects.
- entities of one dataset can be persons or users of a particular demographic (e.g., males in their 20’s) that reside in a certain geographic region (e.g., the United Kingdom (U.K.)).
- entities of another dataset can be users of another demographic (e.g., the general population) that also reside in the same geographic region.
- the system includes a tensor data flow interface that is configured to pre-load at least two data arrays (e.g., tensors) for storage at a memory device of the GPU.
- the GPU In response to the system receiving a user query for information, the GPU efficiently computes correlations (e.g., similarities) among entities in the respective datasets. For example, the query might seek information indicating which domain names 20-year-old males in the U.K. find more interesting relative to the general population in the U.K.
- the system computes the correlations by executing a specific type of correlation algorithm (e.g., ajaccard similarity algorithm) to calculate correlation scores that characterize relationships between entities of the different datasets.
- the system uses the correlation scores calculated at the GPU to generate a result set that provides information that is responsive to the received query.
- FIG. 1 is a block diagram of a computing system 100 for determining correlations among entities using processors of the computing system.
- System 100 generally includes a computing server 102, an entity correlation system 104, a data storage device 106, and a data ingest component 108.
- system 100 includes special-purpose hardware circuitry configured to execute specific computational rules for implementing k-min-hash or k-minimum value (“KMV”) algorithms. Execution of these specific rules enable sorting (e.g., pre-sorting) of large entity datasets and pre-loading of the entity datasets at a particular type of processing unit.
- KMV k-min-hash
- KMV k-minimum value
- the processing unit can be a processor device (e.g., a graphics processing unit (GPU)) configured to compute relationships between entities of the datasets.
- a processor device e.g., a graphics processing unit (GPU)
- GPU graphics processing unit
- techniques implemented using system 100 are used to accelerate different data correlation calculations, e.g., for determining overlapping attributes and/or similarities among entities.
- computing server 102 is configured to use entity correlation system 104 to determine correlations among entities of at least different datasets.
- entity correlation system 104 is included within server 102 as a sub-system of hardware circuits (e.g., special-purpose circuitry) that includes two or more processor microchips.
- server 102 can include processors (e.g., CPU and GPU), memory, and data storage devices 106 that collectively form computer systems of server 102. Processors of these computer systems process instructions for execution by server 102, including instructions stored in the memory or on the data storage device 106 to display graphical information for output at an example display monitor of system 100.
- execution of the stored instructions cause one or more of the actions described herein to be performed by server 102 or system 104.
- multiple processors may be used, as appropriate, along with multiple memories and types of memory.
- server 102 may be connected with multiple other computing devices, with each device (e.g., a server bank, groups of servers, modules, or a multi -processor system) performing portions of the actions, operations, or logical flows described in this specification.
- System 104 includes a data hosting service 110, a dataflow module 112, and a processor module 114.
- Hosting service 110 is configured to interface with processor module 114, using data flow module 112, to provide data for processing at module 114 in response to user interaction at data ingest component 108.
- hosting service 1 10 is configured for real-time access to a variety of different data sources for obtaining or receiving different types of data.
- the obtained data can be provisioned for processing at module 114 using the data flow management features (described below) of data flow module 112.
- system 104 and hosting service 110 can interact with ingest component 108 to receive query data 120 generated from user interaction at ingest component 108.
- system 104 and hosting service 110 can access storage device 106 to obtain various sets of data (e.g., datasets) for processing at module 114.
- Hosting service 110 includes a database of information that corresponds to “sketches.” In some implementations, these sketches are generated for storage in the database of hosting service 110 based on analysis and information sorting performed on datasets obtained from storage device 106.
- the database of hosting service 110 can include a variety of sketches that are grouped, or otherwise characterized, by information type. For example, the database can include sketches of pre-sorted entity data that correspond to different types of user queries, persons or individuals, demographics for different geographic regions, domain names, commercial products, or various digital and real-world items or objects.
- each sketch stored in the database is identified by a unique type indicator for characterizing information about entities (or queries) that form a sketch. For example, a unique type indicator can identify a sketch as including information for a specific type of entity (e.g., persons, locations, digital assets, or combinations of each) or specific types of queries obtained using query data 120 and that reference entities of a sketch.
- a“sketch” is a data array that describes a set of people or a set of things.
- a sketch can be a set of people living in the U.S. or another set of people living in the U.K.
- a sketch can be a set of persons, digital assets, or identifiers (for example IP addresses that accessed a particular URL (e.g., www.example.com) on a particular day and/or from a particular geographic location).
- each sketch in a database of multiple sketches can be sets of people (or respective identifiers assigned to people or items) that are grouped via a unique type indicator.
- a first sketch can include 18-year-olds, where each 18- year-old is a discrete entity, living in a particular city in the U.K. (e.g., London), while a second different sketch can include certain types of online content (e.g., a sponsored content item) that was clicked or interacted with by a user during a certain time-frame.
- a second different sketch can include certain types of online content (e.g., a sponsored content item) that was clicked or interacted with by a user during a certain time-frame.
- system 104 is configured to generate multiple data arrays using queries identified from query data 120 and datasets obtained from storage device 106.
- the data arrays are processed at module 114 to generate result sets that are responsive to a query submitted by a user interacting with ingest component 108.
- the query is a current query that is received in real-time by system 100 via ingest component 108.
- system 104 determines an entity type associated with the received query, uses the associated entity type to identify at least two data arrays (or sketches) that have been accessed from the database of hosting service 110, and processes the query using the at least two data arrays accessed from the database. In response to processing the query, system 104 generates a result set that is responsive to the query.
- Dataflow module 112 can be a computing module configured to provide data flow management functions of system 100.
- dataflow module 112 is configured to provide an application program interface (API) and a machine-learning (ML) framework.
- API application program interface
- ML machine-learning
- the API and ML framework enable system 100 to use a KMV data processing algorithm to process and sort datasets received at module 114 via hosting service 110.
- a first processor 116 e.g., CPU 116) of module 114 can receive datasets for generating pre-sorted data arrays using API features of dataflow module 112.
- first processor 116 is an example CPU and can be referred to herein as“CPU 116.”
- dataflow module 112 communicates with hosting service 110 to receive or obtain datasets for processing at module 114.
- CPU 116 processes the datasets by a executing a KMV algorithm to generate multiple respective sketches or data arrays that each have a predefined size attribute.
- a second processor 118 e.g., GPU 118
- module 114 can receive at least a subset of the multiple data arrays for loading in a memory cache of the second processor 118.
- second processor 118 is an example GPU and may be referred to herein as“GPU 118.”
- system 100 causes GPU 118 to execute an algorithm (e.g., a correlation algorithm) to perform correlation analysis using the data arrays that are loaded at the memory cache of GPU 118.
- GPU 118 can be any one of several types of GPUs that are used to execute different types of ML algorithms.
- dataflow module 112 is configured such that a specific kernel is provided for interfacing with each of the different types of GPUs that may be included as a processor device of module 114.
- dataflow module 112 is configured such that designers can generate software instructions and other coded algorithms for execution at the different types of GPUs that may be included at module 114.
- the algorithms can be executed to perform computations for determining similarities, inferences, probabilities, and correlations relating to entities, or for using statistical analysis to discern relationships among entities of large datasets.
- Processor module 114 includes CPU 116 and GPU 118.
- CPU 116 receives datasets obtained via hosting service 110, executes the KMV data processing algorithm to pre-sort the data, and generates multiple data arrays based on execution of the KMV algorithm (e.g., a sketch algorithm) and the pre-sorted data.
- Module 114 can be configured to sort entity data in the datasets and generate the data arrays using a batch process that runs or executes at CPU 116 based on predetermined processing schedules (e.g., batch processing once a day). In some implementations, module 114 is configured to generate the pre-sorted data arrays based on analysis of streams of entity data in the datasets obtained via hosting service 110.
- Each of the multiple pre-sorted data arrays correspond to respective sketches that each have a predefined size attribute.
- the predefined size can be set such that each data array includes no more than 64,000 (“64k”) entities.
- the size attribute can be more than 64k entities but less than a particular quantity of entities that would exceed a certain memory capacity of GPU 118.
- the predefined size attribute of the data array is set based on a cache memory capacity of the GPU 118.
- GPU 118 receives multiple data arrays or multiple groups of data arrays that are loaded at a memory /storage medium of GPU 118. For example, in a single instance, GPU 118 receives information for multiple entities based on a single data load that occurs at the GPU after CPU 118 generates the data arrays. The data arrays are loaded and stored in an area of GPU memory that can be considered“compact” relative to other memory sections of the GPU. For example, the multiple data arrays may be loaded at the compact cache memory of the GPU based on a predefined size attribute of 64k entities per data array.
- a data array is each configured for storage at the compact cache memory when an information density (e.g., parameter values) for each entity of the 64k entities does not exceed a threshold capacity of the compact cache memory.
- a data array can be represent a tensor and, thus, may be referred to herein as data structures or a query tensor or an entity tensor.
- a tensor is a geometric object and example geometric objects include matrices and data arrays.
- An example tensor can be a single dimension geometric object or a multi-dimensional geometric object.
- a single data loading operation can be performed such that GPU 118 receives data for generating a response to the query.
- GPU 118 can receive at least one data array with information about different entities and that has an entity type indicator which matches a type indicator of the received query.
- GPU 118 can also receive a query tensor that relates to the received query or that has a threshold amount of relevance to the received query.
- GPU 118 generates the response to the query using the information obtained during the data loading operation.
- a batch process runs in which system 104 computes a multitude of sketches for a database of hosting service 110.
- GPU 118 then loads information or parameter values for each of the multiple sketches or data arrays through the API associated with dataflow module 112.
- GPU 118 loads this data into its own internal memory from an example impasse database that is accessible via hosting service 110.
- the impasse database can be associated with an impasse service that communicates with CPU 116 and GPU 118 through a dataflow API to load the data arrays and to issue queries received at ingest component 108. For example, during run time, issued queries are processed against data arrays loaded at GPU 118 using a query path from hosting service 110, through the API of dataflow module 112, to GPU 118.
- FIG. 2 is a flowchart of an example process 200 for determining correlations among entities of respective data arrays.
- process 200 can be a process flow for calculating similarities among entities using a similarity algorithm executed at GPU 116.
- Process 200 can be implemented or executed using system 100 described above and descriptions of process 200 may reference the above-mentioned computing resources of system 100.
- described actions of process 200 are enabled by programmed software instructions that are executable by at least one processor and memory of computing systems described in this document.
- a first processing unit (e.g., a CPU) 116 of system 100 obtains data stored at storage device 106.
- the obtained data includes information about multiple entities (202).
- entities of one data array can be represented by a dataset that includes different types of items, persons, or various electronic and real world items or objects.
- entities of one dataset can be persons or users of a particular population group (e.g., males in their 20’s) that reside in a certain geographic region (e.g., the United Kingdom (U.K.)).
- entities of another dataset can be various types of items or users of another demographic (e.g., users of a general population) that also reside in the same geographic region.
- Processing unit/CPU 116 generates multiple data arrays 306 using the data obtained from a storage device (204).
- Each generated data array 308, 310, 312 of the multiple data arrays 306 generally includes one or more parameter values for each entity of the multiple entities assigned to the data array. That is,“Entity _l,l” in the DataArray l 308 in FIG. 3 can denote one or more parameter values for a first entity of the multiple entities in DataArray l,“Entity _l ,2” in the DataArray l 308 in FIG. 3 denotes one or more parameter values for a second entity, and so on.
- the parameter values can define particular types of entities as well as define attributes or characteristics of individual entities in a data array.
- parameter values can define an entity type as corresponding to a person, where attributes of the person (e.g., the entity) include information that the person has provided, such as the person’s gender, the person’s age, or the person’s geographic location.
- an entity type can correspond to a web- based or digital resource (e.g., the entity) and attributes of the web-based resource/entity can be a domain name, a uniform resource locator (URL), or an internet protocol (IP) address associated with the web-based entity.
- URL uniform resource locator
- IP internet protocol
- the users may be provided with an opportunity to enable/disable or control programs or features that may collect and/or use personal information (e.g., information about a user’s social network, social actions or activities, a user’s preferences or a user’s current location).
- personal information e.g., information about a user’s social network, social actions or activities, a user’s preferences or a user’s current location.
- certain data may be treated in one or more ways before it is stored or used, so that personally identifiable information associated with the user is removed.
- a user’s identity may be anonymized so that the no personally identifiable information can be determined for the user, or a user’s geographic location may be generalized where location information is obtained (such as to a city, ZIP code, or state level), so that a particular location of a user cannot be determined.
- System 100 is configured to analyze and process different sources of data accessible via storage device 106.
- CPU 116 can analyze and process data sources that include impression logs that are interacted with by certain users or data sources such as search data from a search engine accessed by different users.
- entities formed by groups of users, or by groups of user identifiers (IDs) for respective users can be divided into different groups based on age, gender, interests, location, or other characteristics of each user in the group.
- the KMV algorithm can represent an example hash algorithm that is processed using information about each user or each user ID in a group of entities.
- multiple sets of user IDs are represented as large parameter values that function as an emitter for pre-sorting data to generate the data arrays.
- pre sorting the data is done using a hash algorithm that hashes arbitrary strings of integers to a uniformly distributed emitter to generate the data arrays.
- CPU 116 executes the KMV algorithm to sort on user IDs in order to generate a sketch that is representative of some predefined whole user set. For example, from a whole user set of ten million user IDs males between the age of 18 and 35 that interact with sports related impressions, CPU 116 can perform a sort to generate a sketch or data array of only the minimum 64,000 user IDs as a sketch representation of the whole user set.
- system 100 can be configured to sort information in a dataset with reference to any attribute or parameter value that is included in the information.
- Each of the generated data arrays is configured for processing at a respective computing cell of a second processing unit (e.g., a GPU) 118.
- System 100 provides at least two data arrays to GPU 118 to compute scoring data and to determine relationships among entities of the data arrays based on the computed scoring data (206).
- sketches are loaded into memory of GPU 118 in a single instance for at least one query session.
- the query session represents a time at which the entity correlation system 104 is queried by a user seeking to obtain result sets that indicate relationships between entities of the sketches.
- responses to a query submitted by a user can be determined with enhanced speed and efficiency relative to other correlation systems because the system has already pre-sorted and pre-loaded data that is used to process the query.
- a user can access and randomly query system 104 by passing a new sketch as a query to system 104 via the query path.
- GPU 118 is configured to execute a correlation algorithm to concurrently process the data arrays at the respective cells of the GPU 118.
- processing unit 118 computes one or more correlation scores based on calculations performed at the respective computing cells (208).
- GPU 118 executes the correlation algorithm (e.g., a jaccard similarity algorithm) and computes correlation scores using parameter values for entities in the data arrays.
- the parameter values are provided as inputs for mathematical calculations involving the correlation algorithm.
- System 100 determines relationships among entities of the at least two data arrays based on the computed correlation scores (210). In some implementations, the relationships indicate overlapping attributes among at least a subset of the entities or similarities among entities of respective data arrays. For example, system 100 determines similarities among entities by computing intersections and unions at a single computing cell of GPU 118 and corresponding correlation scores that characterize the intersections and unions.
- hosting service 110 interfaces with GPU 118 to pass a new sketch as a query tensor for processing to determine a result that is responsive to the query.
- users can access system 100 where hosting service 110 is part of a real-time service platform that provides a response (e.g., in real-time) to a user query.
- a user submits a query for processing by GPU 118 in real-time, using an interface to GPU 118 provided via hosting service 110.
- GPU 118 processes the query using the techniques described this document to return a result, or sets of results, as a response to the query submitted by the user.
- GPU 118 executes the correlation algorithm to compute the intersection and union of the user query with every data array for a given set (or dataset) within the database.
- portions of a large-scale computation to determine intersections and unions and corresponding correlation scores are handled at individual computing cells of GPU 118.
- the query is processed against data structures that represent sketches or data arrays loaded at each computing cell (e.g., a thread or core) of GPU 118.
- System 104 processes the query by performing large-scale parallel computations which can involve every computing cell in the GPU being used to process the query against a respective one of the data structures.
- the respective one of the data structures can represent a different data array of entities that is loaded for processing at a single GPU computing cell. For example, a first sketch having 64k user IDs for females (first entities) of a certain age group living in the U.S.
- a second sketch having 64k user IDs for males (second entities) of a certain age group living in the U.K. can be loaded at a second different computing cell so the query can be processed against the second entities of this second sketch.
- hosting service 110 represents an information library that receives and processes queries to return results that indicate relationships such as similarities between entities or conditional probabilities involving different sets of entities. For example, a query (or command) can be“what are all the conditional probabilities associated with some earlier query?” Another query may be related to the conditional probabilities of all the ages of people that visit a particular website or URL. Similarly, another query can be“what are the overlapping URL’s visited by 30-year-old females living in the U.S. relative to 40-year-old males living in the U.K.?” For a given query, system 100 may compute intersections and unions to determine relationships among entities of the first data array vs. entities of the second data array and against a query sketch generated based on the user submitted query.
- system 100 can compute the intersections and unions to determine relationships by using respective computing cells of GPU 118 to execute a jaccard similarity algorithm.
- the executed algorithm is used to determine a similarity score that indicates a respective measure of similarity between entities of data structures processed at respective computing cells of GPU 118 relative to constraints indicated by a query.
- System 104 uses GPU 118 to computes a jaccard similarity (or correlation) score based on a comparison of entities included in at least two sets or data arrays.
- the jaccard similarity score can provide a numerical indication of which entities are shared between the two sets and which entities are distinct between the two sets.
- the jaccard similarity score provides a measure of similarity for two sets of data, with a range from 0% to 100%. For example, the higher the percentage, the more similar the two sets of entities.
- a correlation score can be a similarity score, a conditional probability, a metric indicating a statistical relationship, or a particular output parameter that defines rankings of interest for providing results to a user query.
- GPU 118 can be configured to execute the following commands i) through iv). These commands can represent a specific set of computer-implemented rules for determining relationships among entities of data arrays:
- a query tensor can be a vector (e.g., a high dimension vector) that represents a query entity in a vectorized manner.
- GPU table uri can specify a table type and table name (e.g., sstable al_inmarket_profile), where this table is pre-loaded in GPU 118 using the load command tfsketch gpu load table.
- Simlarity method enum can specify a selected similarity calculation method.
- the selected similarity calculation method can be a method such as jaccard similarity method or cosine similarity method.
- system 100 can calculate a size of an intersection of any two sets (entities of two different arrays/sketches) and the ratio of the intersection and union with reference to general set operations. These calculations provide a fundamental baseline upon which a variety of other computing processes can be built.
- system 100 can determine multiple types of statistical relationships between sets of entities using data obtained from various sources of information. For example, jaccard similarity is one statistical relationship that can be determined, while probabilities (e.g., conditional probabilities) indicate another statistical relationship. In general, any related statistic can be computed over cardinalities of sets based on the described teachings.
- System 104 can be configured to select a particular correlation algorithm from among a subset of algorithms.
- the algorithm can be selected as one of a similarity algorithm or a conditional probability algorithm.
- GPU 118 executes the particular correlation algorithm and calculates an intersection between entities of at least two data arrays and a union between entities of the at least two data arrays.
- System 104 computes the correlation score based on the intersection and the union.
- the selected correlation algorithm is a jaccard similarity algorithm, a cosine similarity algorithm, a unique statistical algorithm, or a specific computational process for determining conditional probabilities among sets of data.
- FIG. 3 is an example architecture 300 associated with at least one processor in the computing system of FIG. 1.
- Architecture 300 includes GPU/CPU transfer block 302 and respective data arrays 308, 310, and 312.
- data array 312 is a query tensor that is generated based on a user query received via ingest component 108. As described in more detail below, query tensor 312 is processed to determine a result that is responsive to the received query.
- each of the generated data arrays 308, 310, 312 is received generated using CPU 116 and loaded at GPU 118 using transfer block 302.
- each of the data arrays 308, 310, 312 is configured for processing at a respective computing cell of GPU 118.
- System 100 uses transfer block 302 and compact memory (e.g., GPU cache) to load and store data describing the various pre-sorted entities of a data array.
- compact memory e.g., GPU cache
- the entities of at least data arrays 308 and 310 can be users of a particular demographic (e.g., males in their 20’s) that reside in a certain geographic region (e.g., the United Kingdom (UK)).
- the correlation calculation is performed using at least the sets of pre-sorted entities in respective data arrays 308 and 310 that are stored at a compact memory of GPU 118.
- the data arrays are configured for storage in a compact memory or data cache of GPU 118 based on a predefined size and data structure of the data arrays.
- the predefined size can be set such that each data array includes no more than 64,000 (“64k”) entities.
- this predefined size attribute of the respective data arrays can be derived based on a processor core structure of GPU 118.
- Execution of the correlation algorithm to perform the computations causes large scale concurrent processing (e.g., massively parallel computations) to occur within GPU 118.
- concurrent processing can involve subsets of computing cells (thread blocks 304) in one or more transfer blocks 302.
- Computations can be considered“large scale concurrent processing” or“massively parallel” when the computations use more than athreshold percentage of all computing cells in GPU 118.
- massively parallel computations can use more than 70% of the available computing cells in GPU 118 (or some other appropriate threshold amount).
- Groups of threads (thread blocks) can be configured for both serial and parallel execution.
- GPU 118 includes thousands of computing cells or threads of thread blocks 304.
- a computing cell of GPU 118 is defined by a thread block that represents a group of threads. As indicated at FIG. 3 (described below), each thread block can be mapped to a corresponding transfer block 302. In some implementations, system 100 includes multiple transfer blocks and each transfer block defines a transfer path where CPU generated sketches are transferred for loading at computing cells of a thread block 304.
- FIG. 4 is an example processing architecture 400 associated with computing processes involving CPU 116 and GPU 118.
- Each data array loaded and stored at a respective thread block 304 (that includes multiple computing cells) of GPU 118 is sized in accordance with a quantity of computing cells that are included at the graphics processor.
- system 104 executes a process 402 that causes GPU 118 to fetch storage locations for loading and storing each data array at a memory cache of the GPU.
- the memory cache of GPU 118 can represent a compact memory and each data array is sized in accordance with a data capacity of the storage locations in the compact memory.
- At least one data array loaded at GPU 118 is a query tensor (e.g., data array 312) that is configured for access at each of the computing cells of GPU 118.
- the query tensor is replicated and is accessed in parallel at GPU 118 to compute relationships (e.g., similarities) among entities of respective data arrays.
- Each computing cell accesses and uses query information of the query tensor to calculate a respective correlation score at each cell.
- System 104 determines similarities and other relationships among entities of distinct data arrays when at least two data arrays are concurrently processed against the query tensor in a parallel manner at GPU 118.
- architecture 400 can be used to implement techniques for accelerating data calculations to determine similarities and other relationships among entities.
- the techniques can involve configuring the pre-sorted data arrays to have a size attribute (e.g., 64k) that does not exceed a memory threshold of GPU 118.
- the techniques can also involve storing the data arrays at GPU 118 and assigning each data array to a particular computing cell of GPU 118.
- System 104 can determine an assignment of each data array to a computing cell so that the cell can quickly access relevant data to determine relationships among entities.
- system 104 executes a process 404 that causes CPU 116 to fetch computation results produced by GPU 118.
- CPU 116 obtains correlation scores that represent the computation results and processes the results to generate query responses that are provided for output to the user that submitted the query.
- determining relationships among entities includes determining whether computed correlation scores exceed a threshold score. In response to determining that the computed correlation scores exceed the threshold score, system 104 generates a listing of entities that are ranked using the correlation scores that exceed the threshold score.
- system 104 returns results of the computations performed at GPU 118 to CPU 116 by returning information that identifies one or more data arrays that are n best matches to the query. For example, system 104 determines the n best matches to the query using correlation scores that are calculated when the data arrays are processed against the query tensor at the respective computing cells.
- data structures that are n best matches to the query are included in the generated listing of entities that are ranked using the correlation scores that exceed the threshold correlation score. Hence, data arrays that are n best matches to the query can be identified based on analysis of the generated listing of ranked entities.
- GPU 118 determines scores, computation results, and/or relationships among entities with increased speed relative to other correlation systems. This is because the described techniques enable GPU 118 to perform the necessary calculations without sorting/pre-sorting data before executing a particular correlation algorithm. Additionally, GPU 118 can perform the necessary calculations with minimal, or no, inter-thread data communication relative to other correlation systems. This is because the described techniques enable each computing cell of GPU 118 to perform computations on specific sets of data arrays without the need to communicate intermediate results to neighboring thread blocks for additional processing.
- FIG. 5 is a block diagram of computing devices 500, 550 that may be used to implement the systems and methods described in this document, as either a client or as a server or plurality of servers.
- Computing device 500 is intended to represent various forms of digital computers, such as laptops, desktops, workstations, personal digital assistants, servers, blade servers, mainframes, and other appropriate computers.
- Computing device 550 is intended to represent various forms of mobile devices, such as personal digital assistants, cellular telephones, smartphones, smartwatches, head-wom devices, and other similar computing devices.
- the components shown here, their connections and relationships, and their functions, are meant to be exemplary only, and are not meant to limit implementations described and/or claimed in this document.
- Computing device 500 includes a processor 502, memory 504, a storage device 506, a high-speed interface 508 connecting to memory 504 and high-speed expansion ports 510, and a low speed interface 512 connecting to low speed bus 514 and storage device 506.
- Each of the components 502, 504, 506, 508, 510, and 512 are interconnected using various busses, and may be mounted on a common motherboard or in other manners as appropriate.
- the processor 502 can process instructions for execution within the computing device 500, including instructions stored in the memory 504 or on the storage device 506 to display graphical information for a GUI on an external input/output device, such as display 516 coupled to high speed interface 508.
- multiple processors and/or multiple buses may be used, as appropriate, along with multiple memories and types of memory.
- multiple computing devices 500 may be connected, with each device providing portions of the necessary operations, e.g., as a server bank, a group of blade servers, or a multi-processor system.
- the memory 504 stores information within the computing device 500.
- the memory 504 is a computer-readable medium.
- the memory 504 is a volatile memory unit or units.
- the memory 504 is a non-volatile memory unit or units.
- the storage device 506 is capable of providing mass storage for the computing device 500.
- the storage device 506 is a computer-readable medium.
- the storage device 506 may be a floppy disk device, a hard disk device, an optical disk device, or a tape device, a flash memory or other similar solid state memory device, or an array of devices, including devices in a storage area network or other configurations.
- a computer program product is tangibly embodied in an information carrier.
- the computer program product contains instructions that, when executed, perform one or more methods, such as those described above.
- the information carrier is a computer- or machine-readable medium, such as the memory 504, the storage device 506, or memory on processor 502.
- the high-speed controller 508 manages bandwidth-intensive operations for the computing device 500, while the low speed controller 512 manages lower bandwidth intensive operations. Such allocation of duties is exemplary only.
- the high-speed controller 508 is coupled to memory 504, display 516, e.g., through a graphics processor or accelerator, and to high-speed expansion ports 510, which may accept various expansion cards (not shown).
- low-speed controller 512 is coupled to storage device 506 and low-speed expansion port 514.
- the low-speed expansion port which may include various communication ports, e.g., USB, Bluetooth, Ethernet, wireless Ethernet, may be coupled to one or more input/output devices, such as a keyboard, a pointing device, a scanner, or a networking device such as a switch or router, e.g., through a network adapter.
- input/output devices such as a keyboard, a pointing device, a scanner, or a networking device such as a switch or router, e.g., through a network adapter.
- the computing device 500 may be implemented in a number of different forms, as shown in the figure. For example, it may be implemented as a standard server 520, or multiple times in a group of such servers. It may also be implemented as part of a rack server system 524. In addition, it may be implemented in a personal computer such as a laptop computer 522. Alternatively, components from computing device 500 may be combined with other components in a mobile device (not shown), such as device 550. Each of such devices may contain one or more of computing device 500, 550, and an entire system may be made up of multiple computing devices 500, 550 communicating with each other.
- Computing device 550 includes a processor 552, memory 564, an input/output device such as a display 554, a communication interface 566, and a transceiver 568, among other components.
- the device 550 may also be provided with a storage device, such as a microdrive or other device, to provide additional storage.
- a storage device such as a microdrive or other device, to provide additional storage.
- Each of the components 550, 552, 564, 554, 566, and 568, are interconnected using various buses, and several of the components may be mounted on a common motherboard or in other manners as appropriate.
- the processor 552 can process instructions for execution within the computing device 550, including instructions stored in the memory 564.
- the processor may also include separate analog and digital processors.
- the processor may provide, for example, for coordination of the other components of the device 550, such as control of user interfaces, applications run by device 550, and wireless communication by device 550.
- Processor 552 may communicate with a user through control interface 558 and display interface 556 coupled to a display 554.
- the display 554 may be, for example, a TFT LCD display or an OLED display, or other appropriate display technology.
- the display interface 556 may include appropriate circuitry for driving the display 554 to present graphical and other information to a user.
- the control interface 558 may receive commands from a user and convert them for submission to the processor 552.
- an external interface 562 may be provided in communication with processor 552, so as to enable near area communication of device 550 with other devices.
- External interface 562 may provide, for example, for wired communication, e.g., via a docking procedure, or for wireless communication, e.g., via Bluetooth or other such technologies.
- the memory 564 stores information within the computing device 550.
- the memory 564 is a computer-readable medium.
- the memory 564 is a volatile memory unit or units.
- the memory 564 is a non-volatile memory unit or units.
- Expansion memory 574 may also be provided and connected to device 550 through expansion interface 572, which may include, for example, a SIMM card interface. Such expansion memory 574 may provide extra storage space for device 550, or may also store applications or other information for device 550. Specifically, expansion memory 574 may include instructions to carry out or supplement the processes described above, and may include secure information also.
- expansion memory 574 may be provided as a security module for device 550, and may be programmed with instructions that permit secure use of device 550.
- secure applications may be provided via the SIMM cards, along with additional information, such as placing identifying information on the SIMM card in a non-hackable manner.
- the memory may include for example, flash memory and/or MRAM memory, as discussed below.
- a computer program product is tangibly embodied in an information carrier.
- the computer program product contains instructions that, when executed, perform one or more methods, such as those described above.
- the information carrier is a computer- or machine-readable medium, such as the memory 564, expansion memory 574, or memory on processor 552.
- Device 550 may communicate wirelessly through communication interface 566, which may include digital signal processing circuitry where necessary. Communication interface 566 may provide for communications under various modes or protocols, such as GSM voice calls, SMS, EMS, or MMS messaging, CDMA, TDMA, PDC, WCDMA, CDMA2000, or GPRS, among others. Such communication may occur, for example, through radio-frequency transceiver 568. In addition, short-range communication may occur, such as using a Bluetooth, WiFi, or other such transceiver (not shown). In addition, GPS receiver module 570 may provide additional wireless data to device 550, which may be used as appropriate by applications running on device 550.
- GPS receiver module 570 may provide additional wireless data to device 550, which may be used as appropriate by applications running on device 550.
- Device 550 may also communicate audibly using audio codec 560, which may receive spoken information from a user and convert it to usable digital information. Audio codec 560 may likewise generate audible sound for a user, such as through a speaker, e.g., in a handset of device 550. Such sound may include sound from voice telephone calls, may include recorded sound, e.g., voice messages, music files, etc., and may also include sound generated by applications operating on device 550.
- Audio codec 560 may receive spoken information from a user and convert it to usable digital information. Audio codec 560 may likewise generate audible sound for a user, such as through a speaker, e.g., in a handset of device 550. Such sound may include sound from voice telephone calls, may include recorded sound, e.g., voice messages, music files, etc., and may also include sound generated by applications operating on device 550.
- the computing device 550 may be implemented in a number of different forms, as shown in the figure. For example, it may be implemented as a cellular telephone 580. It may also be implemented as part of a smartphone 582, personal digital assistant, or other similar mobile device.
- Various implementations of the systems and techniques described here can be realized in digital electronic circuitry, integrated circuitry, specially designed ASICs, computer hardware, firmware, software, and/or combinations thereof. These various implementations can include implementation in one or more computer programs that are executable and/or interpretable on a programmable system including at least one programmable processor, which may be special or general purpose, coupled to receive data and instructions from, and to transmit data and instructions to, a storage system, at least one input device, and at least one output device.
- the systems and techniques described here can be implemented on a computer having a display device, e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor, for displaying information to the user and a keyboard and a pointing device, e.g., a mouse or a trackball, by which the user can provide input to the computer.
- a display device e.g., a CRT (cathode ray tube) or LCD (liquid crystal display) monitor
- a keyboard and a pointing device e.g., a mouse or a trackball
- Other kinds of devices can be used to provide for interaction with a user as well; for example, feedback provided to the user can be any form of sensory feedback, e.g., visual feedback, auditory feedback, or tactile feedback; and input from the user can be received in any form, including acoustic, speech, or tactile input.
- the systems and techniques described here can be implemented in a computing system that includes a back end component, e.g., as a data server, or that includes a middleware component such as an application server, or that includes a front end component such as a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the systems and techniques described here, or any combination of such back end, middleware, or front end components.
- the components of the system can be interconnected by any form or medium of digital data communication such as, a communication network. Examples of communication networks include a local area network (“LAN”), a wide area network (“WAN”), and the Internet.
- the computing system can include clients and servers.
- a client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client-server relationship to each other.
- module is intended to include, but is not limited to, one or more computers configured to execute one or more software programs that include program code that causes a processing unit(s)/device(s) of the computer to execute one or more functions.
- computer is intended to include any data processing or computing devices/systems, such as a desktop computer, a laptop computer, a mainframe computer, a personal digital assistant, a server, a handheld device, a smartphone, a tablet computer, an electronic reader, or any other electronic device able to process data.
Abstract
Description
Claims
Applications Claiming Priority (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
PCT/US2018/030486 WO2019212537A1 (en) | 2018-05-01 | 2018-05-01 | Accelerated large-scale similarity calculation |
Publications (1)
Publication Number | Publication Date |
---|---|
EP3631646A1 true EP3631646A1 (en) | 2020-04-08 |
Family
ID=62486629
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
EP18728476.5A Pending EP3631646A1 (en) | 2018-05-01 | 2018-05-01 | Accelerated large-scale similarity calculation |
Country Status (6)
Country | Link |
---|---|
US (2) | US11379535B2 (en) |
EP (1) | EP3631646A1 (en) |
JP (1) | JP7213890B2 (en) |
KR (1) | KR102495793B1 (en) |
CN (1) | CN110959157B (en) |
WO (1) | WO2019212537A1 (en) |
Families Citing this family (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
CN110959157B (en) | 2018-05-01 | 2024-03-12 | 谷歌有限责任公司 | Accelerating large-scale similarity computation |
CN111984916B (en) * | 2020-10-09 | 2021-01-12 | 北京应用物理与计算数学研究所 | Mathematical equation solving component and parallel software research and development method and system |
Family Cites Families (64)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JPS5415591Y2 (en) | 1972-10-19 | 1979-06-22 | ||
US4905162A (en) * | 1987-03-30 | 1990-02-27 | Digital Equipment Corporation | Evaluation system for determining analogy and symmetric comparison among objects in model-based computation systems |
US5339257A (en) * | 1991-05-15 | 1994-08-16 | Automated Technology Associates Inc. | Real-time statistical process monitoring system |
US5560006A (en) * | 1991-05-15 | 1996-09-24 | Automated Technology Associates, Inc. | Entity-relation database |
JP3611601B2 (en) * | 1994-09-01 | 2005-01-19 | 富士通株式会社 | List processing system and method |
US5943663A (en) * | 1994-11-28 | 1999-08-24 | Mouradian; Gary C. | Data processing method and system utilizing parallel processing |
JPH08272824A (en) * | 1995-03-31 | 1996-10-18 | Hitachi Software Eng Co Ltd | Method for automatically retrieving gane arrangement data |
US6128608A (en) | 1998-05-01 | 2000-10-03 | Barnhill Technologies, Llc | Enhancing knowledge discovery using multiple support vector machines |
US6774917B1 (en) | 1999-03-11 | 2004-08-10 | Fuji Xerox Co., Ltd. | Methods and apparatuses for interactive similarity searching, retrieval, and browsing of video |
US6694325B2 (en) * | 2000-10-16 | 2004-02-17 | Frank Jas | Database method implementing attribute refinement model |
IES20010724A2 (en) * | 2001-07-30 | 2003-02-05 | Univ Dublin | Data processing system and method |
KR100483321B1 (en) | 2001-10-17 | 2005-04-15 | 한국과학기술원 | The Device and Method for Similarity Search Using Hyper-rectangle Based Multidimensional Data Segmentation |
JP3903783B2 (en) | 2001-12-14 | 2007-04-11 | 日本電気株式会社 | Face metadata generation method and apparatus, and face similarity calculation method and apparatus |
US20040002818A1 (en) * | 2001-12-21 | 2004-01-01 | Affymetrix, Inc. | Method, system and computer software for providing microarray probe data |
US7069268B1 (en) * | 2003-01-13 | 2006-06-27 | Cisco Technology, Inc. | System and method for identifying data using parallel hashing |
US6947933B2 (en) | 2003-01-23 | 2005-09-20 | Verdasys, Inc. | Identifying similarities within large collections of unstructured data |
US20090270717A1 (en) * | 2008-04-25 | 2009-10-29 | Welch Allyn, Inc. | Apparatus and method for diagnosis of optically identifiable ophthalmic conditions |
US7483034B2 (en) | 2004-02-25 | 2009-01-27 | Siemens Medical Solutions Usa, Inc. | System and method for GPU-based 3D nonrigid registration |
US7706633B2 (en) | 2004-04-21 | 2010-04-27 | Siemens Corporation | GPU-based image manipulation method for registration applications |
US20050246333A1 (en) * | 2004-04-30 | 2005-11-03 | Jiang-Liang Hou | Method and apparatus for classifying documents |
US7899796B1 (en) * | 2004-11-23 | 2011-03-01 | Andrew Borthwick | Batch automated blocking and record matching |
WO2007082308A2 (en) * | 2006-01-13 | 2007-07-19 | Bluespace Software Corp. | Determining relevance of electronic content |
JP5257071B2 (en) | 2006-08-03 | 2013-08-07 | 日本電気株式会社 | Similarity calculation device and information retrieval device |
US10621203B2 (en) * | 2007-01-26 | 2020-04-14 | Information Resources, Inc. | Cross-category view of a dataset using an analytic platform |
US8099401B1 (en) * | 2007-07-18 | 2012-01-17 | Emc Corporation | Efficiently indexing and searching similar data |
US7987177B2 (en) | 2008-01-30 | 2011-07-26 | International Business Machines Corporation | Method for estimating the number of distinct values in a partitioned dataset |
US8166047B1 (en) * | 2008-08-06 | 2012-04-24 | At&T Intellectual Property I, L.P. | Systems, devices, and/or methods for managing data |
US9171077B2 (en) | 2009-02-27 | 2015-10-27 | International Business Machines Corporation | Scaling dynamic authority-based search using materialized subgraphs |
US9413527B2 (en) | 2009-04-30 | 2016-08-09 | HGST Netherlands B.V. | Optimizing signature computation and sampling for fast adaptive similarity detection based on algorithm-specific performance |
WO2011014471A1 (en) * | 2009-07-27 | 2011-02-03 | Sensis Corporation | System and method for correlating past activities, determining hidden relationships and predicting future activities |
CA2790009C (en) * | 2010-02-18 | 2017-01-17 | Katsumi Inoue | Memory having information refinement detection function, information detection method using memory, device including memory, information detection method, method for using memory, and memory address comparison circuit |
US8620930B2 (en) * | 2010-03-11 | 2013-12-31 | Yahoo! Inc. | Method and system for determining similarity score |
FI20105252A0 (en) * | 2010-03-12 | 2010-03-12 | Medisapiens Oy | METHOD, ORGANIZATION AND COMPUTER SOFTWARE PRODUCT FOR ANALYZING A BIOLOGICAL OR MEDICAL SAMPLE |
US20180181705A1 (en) * | 2010-03-12 | 2018-06-28 | Medisapiens Oy | Method, an arrangement and a computer program product for analysing a biological or medical sample |
US10474647B2 (en) * | 2010-06-22 | 2019-11-12 | Primal Fusion Inc. | Methods and devices for customizing knowledge representation systems |
US8407215B2 (en) * | 2010-12-10 | 2013-03-26 | Sap Ag | Text analysis to identify relevant entities |
US9152882B2 (en) * | 2011-06-17 | 2015-10-06 | Microsoft Technology Licensing, Llc. | Location-aided recognition |
CN102855259B (en) * | 2011-06-30 | 2015-05-13 | Sap欧洲公司 | Parallelization of massive data clustering analysis |
JP4976578B1 (en) * | 2011-09-16 | 2012-07-18 | 楽天株式会社 | Image search apparatus and program |
US8873813B2 (en) * | 2012-09-17 | 2014-10-28 | Z Advanced Computing, Inc. | Application of Z-webs and Z-factors to analytics, search engine, learning, recognition, natural language, and other utilities |
US9916538B2 (en) * | 2012-09-15 | 2018-03-13 | Z Advanced Computing, Inc. | Method and system for feature detection |
US9317875B2 (en) * | 2012-10-08 | 2016-04-19 | Linkedin Corporation | Methods and systems for identifying similar schools |
US8862662B2 (en) * | 2012-10-29 | 2014-10-14 | The Boeing Company | Determination of latent interactions in social networks |
US9141823B2 (en) * | 2013-03-15 | 2015-09-22 | Veridicom, Sa De Cv | Abstraction layer for default encryption with orthogonal encryption logic session object; and automated authentication, with a method for online litigation |
US20150363553A1 (en) * | 2013-06-18 | 2015-12-17 | Naryan L. Rustgi | Medical registry |
US9396253B2 (en) * | 2013-09-27 | 2016-07-19 | International Business Machines Corporation | Activity based analytics |
US10042894B2 (en) * | 2013-10-31 | 2018-08-07 | Microsoft Technology Licensing, Llc | Temporal-based professional similarity |
US20160239499A1 (en) * | 2015-02-12 | 2016-08-18 | Red Hat, Inc. | Object Creation Based on Copying Objects Corresponding to Similar Entities |
US11001900B2 (en) * | 2015-06-30 | 2021-05-11 | Psomagen, Inc. | Method and system for characterization for female reproductive system-related conditions associated with microorganisms |
US20170161591A1 (en) * | 2015-12-04 | 2017-06-08 | Pilot Ai Labs, Inc. | System and method for deep-learning based object tracking |
US10402750B2 (en) * | 2015-12-30 | 2019-09-03 | Facebook, Inc. | Identifying entities using a deep-learning model |
US10268749B1 (en) * | 2016-01-07 | 2019-04-23 | Amazon Technologies, Inc. | Clustering sparse high dimensional data using sketches |
US20170270245A1 (en) * | 2016-01-11 | 2017-09-21 | Edico Genome, Corp. | Bioinformatics systems, apparatuses, and methods for performing secondary and/or tertiary processing |
US10585893B2 (en) * | 2016-03-30 | 2020-03-10 | International Business Machines Corporation | Data processing |
US10353911B2 (en) * | 2016-06-19 | 2019-07-16 | Data.World, Inc. | Computerized tools to discover, form, and analyze dataset interrelations among a system of networked collaborative datasets |
US10922761B2 (en) * | 2016-08-02 | 2021-02-16 | Mastercard International Incorporated | Payment card network data validation system |
US10635739B1 (en) * | 2016-08-25 | 2020-04-28 | Cyber Atomics, Inc. | Multidimensional connectivity graph-based tensor processing |
CN107818069B (en) * | 2016-09-12 | 2021-10-01 | 阿里巴巴集团控股有限公司 | Data processing method and system |
JP6414192B2 (en) * | 2016-12-21 | 2018-10-31 | 株式会社Ｊｖｃケンウッド | Information processing apparatus, information processing method, and information processing program |
US10565498B1 (en) * | 2017-02-28 | 2020-02-18 | Amazon Technologies, Inc. | Deep neural network-based relationship analysis with multi-feature token model |
US11238109B2 (en) * | 2017-03-09 | 2022-02-01 | Data.World, Inc. | Computerized tools configured to determine subsets of graph data arrangements for linking relevant data to enrich datasets associated with a data-driven collaborative dataset platform |
US11068453B2 (en) * | 2017-03-09 | 2021-07-20 | data.world, Inc | Determining a degree of similarity of a subset of tabular data arrangements to subsets of graph data arrangements at ingestion into a data-driven collaborative dataset platform |
US11138516B2 (en) * | 2017-06-30 | 2021-10-05 | Visa International Service Association | GPU enhanced graph model build and scoring engine |
CN110959157B (en) | 2018-05-01 | 2024-03-12 | 谷歌有限责任公司 | Accelerating large-scale similarity computation |
-
2018
- 2018-05-01 CN CN201880048473.5A patent/CN110959157B/en active Active
- 2018-05-01 JP JP2020560917A patent/JP7213890B2/en active Active
- 2018-05-01 WO PCT/US2018/030486 patent/WO2019212537A1/en unknown
- 2018-05-01 US US16/344,450 patent/US11379535B2/en active Active
- 2018-05-01 KR KR1020207033966A patent/KR102495793B1/en active IP Right Grant
- 2018-05-01 EP EP18728476.5A patent/EP3631646A1/en active Pending
-
2022
- 2022-06-13 US US17/839,116 patent/US11782991B2/en active Active
Also Published As
Publication number | Publication date |
---|---|
CN110959157B (en) | 2024-03-12 |
KR20210002647A (en) | 2021-01-08 |
WO2019212537A1 (en) | 2019-11-07 |
KR102495793B1 (en) | 2023-02-06 |
CN110959157A (en) | 2020-04-03 |
JP2021522605A (en) | 2021-08-30 |
US20210026889A1 (en) | 2021-01-28 |
US20220309101A1 (en) | 2022-09-29 |
US11782991B2 (en) | 2023-10-10 |
US11379535B2 (en) | 2022-07-05 |
JP7213890B2 (en) | 2023-01-27 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US9454580B2 (en) | Recommendation system with metric transformation | |
US9934512B2 (en) | Identifying influential users of a social networking service | |
US11782991B2 (en) | Accelerated large-scale similarity calculation | |
US9818142B2 (en) | Ranking product search results | |
CN107784010B (en) | Method and equipment for determining popularity information of news theme | |
US20190311009A1 (en) | Method and system for providing context based query suggestions | |
US20190294703A1 (en) | Search results through image attractiveness | |
US20230139783A1 (en) | Schema-adaptable data enrichment and retrieval | |
US11061948B2 (en) | Method and system for next word prediction | |
US10467307B1 (en) | Grouping of item data using seed expansion | |
US10496645B1 (en) | System and method for analysis of a database proxy | |
CN115795000A (en) | Joint similarity algorithm comparison-based enclosure identification method and device | |
Fageeri et al. | An efficient log file analysis algorithm using binary-based data structure | |
CN104615723B (en) | The determination method and apparatus of query word weighted value | |
US8971644B1 (en) | System and method for determining an annotation for an image | |
CN111241821A (en) | Method and device for determining behavior characteristics of user | |
Trinks | A classification of real time analytics methods. an outlook for the use within the smart factory | |
US10394913B1 (en) | Distributed grouping of large-scale data sets | |
CN111144098B (en) | Recall method and device for extended question | |
CN111539208B (en) | Sentence processing method and device, electronic device and readable storage medium | |
Kakkar et al. | Interactive analysis of big geospatial data with high‐performance computing: A case study of partisan segregation in the United States | |
CN117407418A (en) | Information acquisition method, information acquisition device, computer apparatus, storage medium, and program product | |
CN115269785A (en) | Search method, search device, computer equipment and storage medium | |
CN115017291A (en) | Hotspot problem analysis method and device, computer equipment and storage medium | |
CN117112724A (en) | Search pushing method, apparatus, device, storage medium and computer program product |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: UNKNOWN |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: THE INTERNATIONAL PUBLICATION HAS BEEN MADE |
|
PUAI | Public reference made under article 153(3) epc to a published international application that has entered the european phase |
Free format text: ORIGINAL CODE: 0009012 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: REQUEST FOR EXAMINATION WAS MADE |
|
17P | Request for examination filed |
Effective date: 20200103 |
|
AK | Designated contracting states |
Kind code of ref document: A1Designated state(s): AL AT BE BG CH CY CZ DE DK EE ES FI FR GB GR HR HU IE IS IT LI LT LU LV MC MK MT NL NO PL PT RO RS SE SI SK SM TR |
|
AX | Request for extension of the european patent |
Extension state: BA ME |
|
RAP1 | Party data changed (applicant data changed or rights of an application transferred) |
Owner name: GOOGLE LLC |
|
DAV | Request for validation of the european patent (deleted) | ||
DAX | Request for extension of the european patent (deleted) | ||
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: EXAMINATION IS IN PROGRESS |
|
17Q | First examination report despatched |
Effective date: 20211203 |