JP6963631B2 - Complex adaptive single-pass transcoding vs. two-pass transcoding - Google Patents
Complex adaptive single-pass transcoding vs. two-pass transcoding Download PDFInfo
- Publication number
- JP6963631B2 JP6963631B2 JP2019558785A JP2019558785A JP6963631B2 JP 6963631 B2 JP6963631 B2 JP 6963631B2 JP 2019558785 A JP2019558785 A JP 2019558785A JP 2019558785 A JP2019558785 A JP 2019558785A JP 6963631 B2 JP6963631 B2 JP 6963631B2
- Authority
- JP
- Japan
- Prior art keywords
- chunk
- media
- complexity
- media item
- encoder
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
- 230000003044 adaptive effect Effects 0.000 title 1
- 238000000034 method Methods 0.000 claims description 55
- 238000005259 measurement Methods 0.000 claims description 34
- 238000012545 processing Methods 0.000 claims description 25
- 230000003139 buffering effect Effects 0.000 claims description 8
- 230000002123 temporal effect Effects 0.000 claims description 8
- 230000004044 response Effects 0.000 claims description 5
- 230000011218 segmentation Effects 0.000 description 8
- 230000009471 action Effects 0.000 description 7
- 230000006870 function Effects 0.000 description 7
- 230000033001 locomotion Effects 0.000 description 7
- 238000010586 diagram Methods 0.000 description 6
- 238000004590 computer program Methods 0.000 description 5
- 230000008569 process Effects 0.000 description 5
- 238000013500 data storage Methods 0.000 description 3
- 238000010801 machine learning Methods 0.000 description 3
- 230000005540 biological transmission Effects 0.000 description 2
- 238000004422 calculation algorithm Methods 0.000 description 2
- 230000001413 cellular effect Effects 0.000 description 2
- 230000008859 change Effects 0.000 description 2
- 238000007906 compression Methods 0.000 description 2
- 230000006835 compression Effects 0.000 description 2
- 230000000694 effects Effects 0.000 description 2
- 230000007274 generation of a signal involved in cell-cell signaling Effects 0.000 description 2
- 238000012417 linear regression Methods 0.000 description 2
- 239000000047 product Substances 0.000 description 2
- 241000282994 Cervidae Species 0.000 description 1
- 241000023320 Luma <angiosperm> Species 0.000 description 1
- 238000004364 calculation method Methods 0.000 description 1
- 238000012937 correction Methods 0.000 description 1
- 238000013144 data compression Methods 0.000 description 1
- 230000007812 deficiency Effects 0.000 description 1
- 238000001514 detection method Methods 0.000 description 1
- 235000019800 disodium phosphate Nutrition 0.000 description 1
- 238000011143 downstream manufacturing Methods 0.000 description 1
- 230000006872 improvement Effects 0.000 description 1
- 230000000977 initiatory effect Effects 0.000 description 1
- 230000007774 longterm Effects 0.000 description 1
- 239000000463 material Substances 0.000 description 1
- OSWPMRLSEDHDFF-UHFFFAOYSA-N methyl salicylate Chemical compound COC(=O)C1=CC=CC=C1O OSWPMRLSEDHDFF-UHFFFAOYSA-N 0.000 description 1
- 230000003287 optical effect Effects 0.000 description 1
- 238000010587 phase diagram Methods 0.000 description 1
- 238000007781 pre-processing Methods 0.000 description 1
- 238000005070 sampling Methods 0.000 description 1
- 239000007787 solid Substances 0.000 description 1
- 239000013589 supplement Substances 0.000 description 1
- 230000001360 synchronised effect Effects 0.000 description 1
- 238000012546 transfer Methods 0.000 description 1
- 230000009466 transformation Effects 0.000 description 1
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/134—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or criterion affecting or controlling the adaptive coding
- H04N19/136—Incoming video signal characteristics or properties
- H04N19/14—Coding unit complexity, e.g. amount of activity or edge presence estimation
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/40—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using video transcoding, i.e. partial or full decoding of a coded input stream followed by re-encoding of the decoded output stream
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L41/00—Arrangements for maintenance, administration or management of data switching networks, e.g. of packet switching networks
- H04L41/08—Configuration management of networks or network elements
- H04L41/0803—Configuration setting
- H04L41/0813—Configuration setting characterised by the conditions triggering a change of settings
- H04L41/0816—Configuration setting characterised by the conditions triggering a change of settings the condition being an adaptation, e.g. in response to network events
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L65/00—Network arrangements, protocols or services for supporting real-time applications in data packet communication
- H04L65/60—Network streaming of media packets
- H04L65/75—Media network packet handling
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/103—Selection of coding mode or of prediction mode
- H04N19/109—Selection of coding mode or of prediction mode among a plurality of temporal predictive coding modes
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/103—Selection of coding mode or of prediction mode
- H04N19/11—Selection of coding mode or of prediction mode among a plurality of spatial predictive coding modes
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/103—Selection of coding mode or of prediction mode
- H04N19/112—Selection of coding mode or of prediction mode according to a given display mode, e.g. for interlaced or progressive display mode
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/102—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or selection affected or controlled by the adaptive coding
- H04N19/12—Selection from among a plurality of transforms or standards, e.g. selection between discrete cosine transform [DCT] and sub-band transform or selection between H.263 and H.264
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/134—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or criterion affecting or controlling the adaptive coding
- H04N19/136—Incoming video signal characteristics or properties
- H04N19/137—Motion inside a coding unit, e.g. average field, frame or block difference
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/134—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the element, parameter or criterion affecting or controlling the adaptive coding
- H04N19/146—Data rate or code amount at the encoder output
- H04N19/152—Data rate or code amount at the encoder output by measuring the fullness of the transmission buffer
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/169—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the coding unit, i.e. the structural portion or semantic portion of the video signal being the object or the subject of the adaptive coding
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N19/00—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals
- H04N19/10—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding
- H04N19/189—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the adaptation method, adaptation tool or adaptation type used for the adaptive coding
- H04N19/192—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the adaptation method, adaptation tool or adaptation type used for the adaptive coding the adaptation method, adaptation tool or adaptation type being iterative or recursive
- H04N19/194—Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using adaptive coding characterised by the adaptation method, adaptation tool or adaptation type used for the adaptive coding the adaptation method, adaptation tool or adaptation type being iterative or recursive involving only two passes
Description
本開示は、メディアトランスコーディングの分野に関し、詳細には、メディアアイテムの複数のチャンクの複雑度を決定し、複数の異なるトランスコーダから選択する際に複雑度を使用することに関する。 The present disclosure relates to the field of media transcoding, in particular relating to determining the complexity of multiple chunks of a media item and using the complexity in selecting from a number of different transcoders.
コンテンツ共有プラットフォームにより、ユーザは、ビデオ、オーディオ、および他のユーザが生成したコンテンツを共有することが可能になる。コンテンツ共有プラットフォームは、多くの場合、ユーザが生成したコンテンツ(たとえば、元のソースビデオ)を、ユーザデバイスに固有のエンコード形式からコンテンツ共有プラットフォームによって使用される1つまたは複数の形式にトランスコードする。トランスコーディングは、ソースビデオを元の形式からエンコードされていない表現にデコードし、次いで、エンコードされていない表現を新しい形式のためのエンコーダでエンコードすることを含み得る。トランスコーディングは、クライアントにビデオを提供するためのストレージリソースと帯域幅リソースを削減することができる。 Content sharing platforms allow users to share video, audio, and content generated by other users. Content sharing platforms often transcode user-generated content (eg, the original source video) from a user device-specific encoding format to one or more formats used by the content sharing platform. Transcoding can include decoding the source video from the original format into an unencoded representation, and then encoding the unencoded representation with an encoder for the new format. Transcoding can reduce storage and bandwidth resources to serve video to clients.
以下は、本開示のいくつかの態様の基本的な理解を提供するための本開示の簡略化された概要である。この概要は、本開示の広範な概要ではない。本開示の重要な要素または決定的な要素を識別することも、本開示の特定の実装形態のいかなる範囲または特許請求のいかなる範囲を線引きすることも意図していない。この概要の唯一の目的は、後に提示されるより詳細な説明の前置きとして、本開示のいくつかの概念を簡略化した形で提示することである。 The following is a simplified overview of the disclosure to provide a basic understanding of some aspects of the disclosure. This overview is not an extensive overview of this disclosure. It is not intended to identify the material or decisive elements of the present disclosure or to delineate any scope of the particular implementation or claims of the present disclosure. The sole purpose of this overview is to present some of the concepts of the present disclosure in a simplified form as a prelude to the more detailed description presented later.
本開示の一態様では、方法は、第1のチャンクおよび第2のチャンクを備えるメディアアイテムにアクセスするステップと、処理デバイスによって、第1のチャンクの第1のメディア複雑度指標と第2のチャンクの第2のメディア複雑度指標とを決定するステップと、処理デバイスによって、複数のエンコーダから第1のエンコーダおよび第2エンコーダを選択するステップであって、第1のエンコーダが、第1のチャンクの第1のメディア複雑度指標に基づいて選択され、第2のエンコーダが、第2のチャンクの第2のメディア複雑度指標に基づいて選択される、ステップと、第1のエンコーダを使用して第1のチャンクをエンコードし、第2のエンコーダを使用して第2のチャンクをエンコードするステップとを含む。 In one aspect of the disclosure, the method comprises accessing a media item with a first chunk and a second chunk, and depending on the processing device, a first media complexity indicator of the first chunk and a second chunk. The step of determining the second media complexity index and the step of selecting the first encoder and the second encoder from a plurality of encoders depending on the processing device, in which the first encoder is the first chunk. The first is selected based on the first media complexity index, the second encoder is selected based on the second media complexity index of the second chunk, the step and the first using the first encoder. Includes steps to encode one chunk and then use a second encoder to encode the second chunk.
一実装形態では、本方法はまた、メディアアイテムをキャプチャおよび記録したユーザデバイスからメディアアイテムを受信するステップと、メディアアイテムを第1のチャンクおよび第2のチャンクを備える複数のチャンクにセグメント化するステップとを含み得る。本方法はまた、エンコードされたメディアアイテムを形成するために、シングルパスエンコーダを使用してエンコードされたメディアアイテムの第1のチャンクと、2パスエンコーダを使用してエンコードされたメディアアイテムの第2のチャンクを組み合わせるステップとを含み得る。第1のエンコーダを選択するステップは、第1のチャンクの第1のメディア複雑度指標を所定のしきい値と比較するステップと、第1のメディア複雑度指標が所定のしきい値未満であることに応答してシングルパスエンコーダを選択するステップとを含み得る。 In one implementation, the method also receives the media item from the user device that captured and recorded the media item, and segmented the media item into multiple chunks with a first chunk and a second chunk. And can be included. The method also has a first chunk of media item encoded using a single-pass encoder and a second chunk of media item encoded using a 2-pass encoder to form an encoded media item. Can include steps to combine chunks of. The steps of selecting the first encoder are the step of comparing the first media complexity index of the first chunk with a predetermined threshold value and the step of comparing the first media complexity index with a predetermined threshold value. It may include the step of selecting a single path encoder in response.
別の実装形態では、第1のメディア複雑度指標および第2のメディア複雑度指標は、それぞれのチャンクの空間的および時間的分布を示し得る。メディアアイテムがビデオである場合、本方法は、メディアアイテムの第1のチャンクのビデオコーディング複雑度測定値および第2のチャンクのビデオコーディング複雑度測定値を決定するステップを含み得る。第1のチャンクのビデオコーディング複雑度(VCC)測定値を決定するステップは、第1のチャンクのピクセル単位のビットレート(R)、フレームレート(Fps)、クロマ係数(CF)、フレーム幅(W)、およびフレーム高さ(H)を決定するステップを含み得、次の数式に基づいてビデオコーディングの複雑度の値を計算するステップをさらに含む:VCC=R/(W*H*Fps*CF)。 In another implementation, the first media complexity index and the second media complexity index may indicate the spatial and temporal distribution of their respective chunks. If the media item is video, the method may include determining a video coding complexity measurement of the first chunk and a video coding complexity measurement of the second chunk of the media item. The steps to determine the video coding complexity (VCC) measurements for the first chunk are the bit rate (R), frame rate (Fps), chroma factor (CF), and frame width (W) per pixel of the first chunk. ), And the step of determining the frame height (H), and further including the step of calculating the value of video coding complexity based on the following formula: VCC = R / (W * H * Fps * CF) ).
別の実装形態では、複数のエンコーダは可変ビットレートエンコーダを備え得、第1のエンコーダはシングルパスエンコーダを備え、第2のエンコーダはマルチパスエンコーダを備える。メディアアイテムの第1のチャンクはシングルパスエンコーダを使用してエンコードされ得、メディアアイテムの第2のチャンクはマルチパスエンコーダを使用してエンコードされ得る。シングルパスエンコーダは、リーキーバケットモデルを使用して実装されるビデオバッファリング検証器を備えるシングルパストランスコーダであり得、マルチパスエンコーダは、制約された品質と制限されたビットレートとを備える2パストランスコーダであり得る。 In another implementation, the plurality of encoders may include a variable bit rate encoder, the first encoder comprises a single pass encoder and the second encoder comprises a multipath encoder. The first chunk of a media item can be encoded using a single-pass encoder and the second chunk of a media item can be encoded using a multi-pass encoder. A single-pass encoder can be a single-pass transcoder with a video buffering verifier implemented using a leaky bucket model, and a multi-pass encoder is a two-pass encoder with constrained quality and constrained bitrate. It can be a transcoder.
本開示は、添付の図面の図において、限定としてではなく、例として示されている。 The present disclosure is shown in the accompanying drawings as an example, not as a limitation.
コンテンツ共有プラットフォームは、多くの場合、メディアアイテムを共有できるように処理およびトランスコードされる数百万の着信メディアアイテムを受信する。従来のメディアコーディングシステムを使用してメディアアイテムをトランスコーディングすると、レイテンシが長くなる。多くの場合、トランスコーディングレイテンシは、ビデオの解像度、ビットレート、フレームレート、継続時間、または画像品質に応じて増加する。たとえば、単一のビデオトランスコーダによって3分のビデオを高解像度(HD)形式のビデオにトランスコードすると、ビデオコンテンツの長さの10倍の時間がかかる場合がある。長いトランスコーディングレイテンシは、ダウンストリーム処理(たとえば、ビデオ分析またはストリーミング)をさらに遅延させ、ユーザエクスペリエンスを低下させる可能性がある。従来のビデオトランスコーダは、多くの場合、ビデオコンテンツとコーディングの複雑度のトランスコーディングへの影響を無視することによってレイテンシを削減しようとする。ビデオコンテンツと複雑度のトランスコーディングへの影響を考慮せずにビデオをトランスコーディングすると、ビデオの品質とユーザエクスペリエンスが低下する可能性がある。 Content sharing platforms often receive millions of incoming media items that are processed and transcoded so that they can be shared. Transcoding media items using traditional media coding systems results in higher latency. Transcoding latency often increases with video resolution, bit rate, frame rate, duration, or image quality. For example, transcoding a 3-minute video to high-definition (HD) format video with a single video transcoder can take up to 10 times the length of the video content. Long transcoding latencies can further delay downstream processing (eg video analysis or streaming) and reduce the user experience. Traditional video transcoders often seek to reduce latency by ignoring the impact of video content and coding complexity on transcoding. Transcoding video without considering the impact of video content and complexity on transcoding can result in poor video quality and user experience.
本開示の態様および実装形態は、個々のチャンクの複雑度に基づいてメディアアイテムの異なるチャンクに対して異なるエンコーダを選択することによって、上記および他の欠陥に対処する。一例では、本技術は、メディアアイテムを複数のチャンクにセグメント化することを伴い得る。チャンクのうちのいくつかは第1のエンコーダによってエンコードされ得、他のチャンクは第2のエンコーダによってエンコードされ得る。どちらのエンコーダがどのチャンクに使用されるかの選択は、それぞれのチャンクの複雑度(たとえば、動きの量、色の変化、オーディオの変動)に基づき得る。チャンクの複雑度は、以前にエンコードされたチャンクの複雑度を示す数値または非数値であり得るメディア複雑度測定値を使用して表され得る。メディアアイテムが映画(たとえば、ビデオ)である場合、メディア複雑度測定値は、ビデオコーディング複雑度測定値と呼ばれ得る。一例では、特定のチャンクの時空間分布(たとえば、コンテンツの動き)を分析することによって、ビデオコーディング複雑度測定値が決定され得る。別の例では、メディア複雑度指標は、フレームのピクセル数にフレームレートを掛けた組合せで割ったチャンクのビットレートと、以下で説明する数学方程式を使用した他の情報に基づいて概算され得る。ビットレートは、あらかじめ定義された品質レベルまたは許容可能な品質レベルを達成するために必要なビットレートであり得る。いずれの例においても、エンコーダを選択する際に、メディア複雑度測定値(たとえば、ビデオコーディング複雑度)が分析され、1つまたは複数のしきい値と比較され得る。 The embodiments and implementations of the present disclosure address the above and other deficiencies by selecting different encoders for different chunks of media items based on the complexity of the individual chunks. In one example, the technique may involve segmenting a media item into multiple chunks. Some of the chunks can be encoded by the first encoder and the other chunks can be encoded by the second encoder. The choice of which encoder is used for which chunk can be based on the complexity of each chunk (eg, amount of movement, color change, audio variation). Chunk complexity can be expressed using media complexity measurements that can be numeric or non-numeric, indicating the complexity of previously encoded chunks. If the media item is a movie (eg, video), the media complexity measure can be referred to as the video coding complexity measure. In one example, a video coding complexity measure can be determined by analyzing the spatiotemporal distribution of a particular chunk (eg, content movement). In another example, the media complexity index can be estimated based on the chunk bit rate, which is the number of pixels in a frame divided by the frame rate, and other information using the mathematical equations described below. The bit rate can be a predefined quality level or the bit rate required to achieve an acceptable quality level. In either example, media complexity measurements (eg, video coding complexity) can be analyzed and compared to one or more thresholds when selecting an encoder.
本明細書で説明するシステムおよび方法は、より複雑なチャンク用の第1のエンコーダと、それほど複雑ではないチャンク用の第2のエンコーダを選択し得る。一例では、第1のエンコーダはマルチパスエンコーダであり得、第2のエンコーダはシングルパスエンコーダであり得る。マルチパスエンコーダはチャンクを分析する第1のパスを実行し得、後続のパスは分析中に集められた情報を使用してチャンクをエンコードし得る。シングルパスエンコーダは、チャンクの処理中に分析およびエンコードし得る。シングルパスエンコーダはマルチパスエンコーダよりも少ないコンピューティングリソースを使用し得るが、エンコード結果は第1のエンコーダの結果よりも効率が低い(たとえば、圧縮率または品質がより低い)場合がある。チャンクがより複雑な場合、エンコード効率の向上はユーザによって簡単に認識され得るが、チャンクがあまり複雑ではない場合、結果を認識しにくくなり得る。本明細書で説明する技術は、メディアアイテムの集約エンコードがほぼ同じ圧縮および品質でよりリソース効率のより良い方法で実行され得るように、メディアアイテムのより複雑なチャンクに対して第1のエンコーダを選択し、あまり複雑ではないチャンクに対して第2のエンコーダを選択し得る。 The systems and methods described herein may choose between a first encoder for more complex chunks and a second encoder for less complex chunks. In one example, the first encoder can be a multipath encoder and the second encoder can be a single pass encoder. The multipath encoder may perform a first pass to analyze the chunks, and subsequent passes may encode the chunks using the information gathered during the analysis. Single-pass encoders can analyze and encode during chunk processing. Single-pass encoders can use less computing resources than multi-pass encoders, but the encoded results may be less efficient (eg, less compressible or lesser in quality) than the results of the first encoder. If the chunks are more complex, the improvement in encoding efficiency can be easily recognized by the user, but if the chunks are less complex, the results can be less recognizable. The techniques described herein provide a first encoder for more complex chunks of media items so that aggregate encoding of media items can be performed in a more resource-efficient manner with approximately the same compression and quality. You can choose and choose a second encoder for less complex chunks.
本明細書で開示される技術は、コンピューティングデバイスが、シングルパスエンコーダまたはマルチパスエンコーダのいずれかを単独で使用する場合と比較して、より速いレートまたはより高い品質でメディアアイテムをエンコードすることを可能にするため有利である。一例では、これにより、コンテンツ共有プラットフォームが、より少ないコンピューティングリソースを使用して着信メディアアイテムを処理することが可能になり得る。別の例では、これにより、コンテンツ共有プラットフォームが、同じ量のコンピューティングリソースを使用して、着信メディアアイテムをより高い品質で処理することが可能になり得る。 The techniques disclosed herein are for computing devices to encode media items at faster rates or higher quality compared to using either single-pass encoders or multi-pass encoders alone. It is advantageous to enable. In one example, this could allow a content sharing platform to process incoming media items with less computing resources. In another example, this could allow the content sharing platform to process incoming media items with higher quality using the same amount of computing resources.
上記で参照された方法およびシステムの様々な態様は、限定ではなく例として本明細書で以下に詳細に説明される。以下に提供される例では、単純さと簡潔さのためにビデオを参照することがよくある。しかしながら、本開示の教示は一般にメディアアイテムに適用され、たとえば、オーディオ、テキスト、画像、プログラム命令などを含む様々なタイプのコンテンツまたはメディアアイテムに適用することができる。 Various aspects of the methods and systems referred to above are described in detail herein by way of example, but not by limitation. In the examples provided below, we often refer to the video for simplicity and brevity. However, the teachings of the present disclosure generally apply to media items and can be applied to various types of content or media items, including, for example, audio, text, images, program instructions, and the like.
図1は、本開示の一実装形態による、例示的なシステムアーキテクチャ100を示す。コンピュータシステム100の他のアーキテクチャが可能であり、本開示の実施形態を利用するコンピュータシステムの実装形態は、描かれた特定のアーキテクチャに必ずしも限定されない点に留意されたい。システムアーキテクチャ100は、コンテンツ共有プラットフォーム110、サーバ120、ユーザデバイス130A〜Z、ネットワーク140、およびデータストア150を含む。
FIG. 1 shows an exemplary system architecture 100 according to an implementation of the present disclosure. It should be noted that other architectures of the computer system 100 are possible and the implementation of the computer system utilizing the embodiments of the present disclosure is not necessarily limited to the particular architecture depicted. The system architecture 100 includes a
コンテンツ共有プラットフォーム110は、ユーザがメディアアイテム112A〜Zを消費、アップロード、共有、検索、承認(「好き」)、嫌悪、および/またはコメントすることを可能にし得る。コンテンツ共有プラットフォーム110は、メディアアイテム112A〜Zへのアクセスをユーザに提供するために使用され得るウェブサイト(たとえば、ウェブページ)またはアプリケーションバックエンドソフトウェアを含み得る。メディアアイテム112A〜Zは、ユーザによって選択されたデジタルコンテンツ、ユーザによって利用可能にされたデジタルコンテンツ、ユーザによってアップロードされたデジタルコンテンツ、コンテンツプロバイダによって選択されたデジタルコンテンツ、放送局によって選択されたデジタルコンテンツなどであり得る。メディアアイテム112A〜Zの例は、デジタルビデオ、デジタル映画、デジタル写真、デジタル音楽、ウェブサイトコンテンツ、ソーシャルメディアアップデート、電子書籍(ebooks)、電子雑誌、デジタル新聞、デジタルオーディオブック、電子ジャーナル、ウェブブログ、リアルシンプルシンジケーション(RSS)フィード、電子コミックブック、ソフトウェアアプリケーションなどを含み得るが、これらに限定されない。メディアアイテム112A〜Zは、インターネットおよび/またはモバイルデバイスアプリケーションを介して消費され得る。簡潔かつ簡単にするために、本明細書全体を通じてメディアアイテムの例としてオンラインビデオ(以下、ビデオとも呼ばれる)が使用される。
The
本明細書で使用されるように、「メディア」、「メディアアイテム」、「オンラインメディアアイテム」、「デジタルメディア」、「デジタルメディアアイテム」、「コンテンツ」、および「コンテンツアイテム」は、デジタルメディアアイテムをエンティティに提示するように構成されたソフトウェア、ファームウェア、またはハードウェアを使用して実行またはロードすることができる電子ファイルを含むことができる。一実装形態では、コンテンツ共有プラットフォームは、データストア150を使用してメディアアイテム112A〜Zを記憶し得る。一例では、メディアアイテムは、ユーザデバイス130Aのユーザによって識別されるユーザが生成したビデオであってもよく、または、ユーザデバイス130A〜Zのうちの1つまたは複数に別のメディアアイテムを提示する前、最中、または後に提示される、コンテンツ共有プラットフォーム110によって選択された広告であってもよい。
As used herein, "media," "media item," "online media item," "digital media," "digital media item," "content," and "content item" are digital media items. Can include electronic files that can be run or loaded using software, media, or hardware that is configured to present to the entity. In one implementation, the content sharing platform may use the data store 150 to store media items 112A-Z. In one example, the media item may be a user-generated video identified by a user on user device 130A, or before presenting another media item to one or more of user devices 130A-Z. It may be an advertisement selected by the
メディアチャンク152A〜Cは、特定のメディアアイテム(たとえば、メディアアイテム112A)の異なる部分であり得る。図1に示される例では、メディアチャンク152A〜Cは、メディアアイテム112Aのセグメント化されたコンテンツを含むメディアチャンクのシーケンスであり得る。セグメント化されたコンテンツは、メディアアイテムと同じ形式でもよく、異なる形式でもよい。シーケンスは、重複しないメディアチャンクの連続シーケンスであり得る。たとえば、期間がXのメディアアイテムは、それぞれがX/4の固定期間またはX/4の平均期間(すなわち、可変的にセグメント化されている場合)を有する4つのチャンクに分割され得る。別の例では、チャンクのうちの1つまたは複数が他のチャンクのうちの1つまたは複数と重複し得る。たとえば、期間がXのメディアアイテムは5つのチャンクに分割され得、チャンクのうちの4つは前述のように画像コンテンツ(たとえば、ビデオコンテンツ)のシーケンスを含み得、1つのチャンクはすべてのオーディオコンテンツを含み得る。画像コンテンツを含むチャンクは互いに重複しない場合があるが、オーディオコンテンツは4つの画像コンテンツチャンクの各々と重複し得る。一例では、ビデオコンテンツを伴うチャンク(たとえば、ビデオチャンク)は、中間ストリームのビデオデータを含み得る。ビデオチャンクは、チャンク識別データ(たとえば、v_id_123)によって識別され得、ビデオチャンクのシーケンス内の後続のビデオチャンクの識別データは、一定量(たとえば、v_id_124)だけ増分され得る。 Media chunks 152A-C can be different parts of a particular media item (eg, media item 112A). In the example shown in FIG. 1, media chunks 152A-C can be a sequence of media chunks containing segmented content of media item 112A. The segmented content may be in the same format as the media item or in a different format. The sequence can be a continuous sequence of non-overlapping media chunks. For example, a media item with a period of X can be divided into four chunks, each with a fixed period of X / 4 or an average period of X / 4 (ie, if it is variably segmented). In another example, one or more of the chunks may overlap with one or more of the other chunks. For example, a media item with period X can be divided into 5 chunks, 4 of which can contain a sequence of image content (eg video content) as described above, and one chunk can contain all audio content. May include. Chunks containing image content may not overlap with each other, but audio content can overlap with each of the four image content chunks. In one example, a chunk with video content (eg, a video chunk) may contain intermediate stream video data. Video chunks can be identified by chunk identification data (eg v_id_123), and the identification data of subsequent video chunks in a sequence of video chunks can be incremented by a certain amount (eg v_id_124).
サーバ120は、コンテンツ共有プラットフォーム110の一部であってもよく、メディアアイテム112A〜Zを処理するための別個のデバイスであってもよい。サーバ120は、1つまたは複数のコンピューティングデバイス(ラックマウントサーバ、ルータコンピュータ、サーバコンピュータ、パーソナルコンピュータ、メインフレームコンピュータ、ラップトップコンピュータ、タブレットコンピュータ、デスクトップコンピュータなど)、データストア(たとえば、ハードディスク、メモリ、データベース)、ネットワーク、ソフトウェアコンポーネント、および/またはハードウェアコンポーネントを含み得る。図1に示される例では、サーバ120は、メディアセグメンテーションコンポーネント122、複雑度決定コンポーネント124、およびトランスコーディングコンポーネント126を含み得る。
The
メディアセグメンテーションコンポーネント122は、メディアアイテム112A〜Zを分析し得、メディアアイテムの各々を1つまたは複数の部分にセグメント化し得る。メディアセグメンテーションコンポーネント122は、メディアアイテム112A〜Zの各々にアクセスし、メディアアイテムを中間ストリームなどの中間データ構造に変換し得る。次いで、メディアセグメンテーションコンポーネント122は、メディアストリームを1つまたは複数のチャンク(たとえば、メディアチャンク152A〜C)にセグメント化し得る。 The media segmentation component 122 may analyze media items 112A-Z and segment each of the media items into one or more parts. The media segmentation component 122 can access each of the media items 112A-Z and convert the media item into an intermediate data structure such as an intermediate stream. The media segmentation component 122 can then segment the media stream into one or more chunks (eg, media chunks 152A-C).
複雑度決定コンポーネント124は、以下でより詳細に説明するように、メディアアイテム全体を分析することによって、あるいはメディアアイテムのメタデータ、またはメディアアイテムの1つもしくは複数のチャンクなどのメディアアイテムの一部を分析することによって、メディアチャンク152A〜Cの複雑度を決定し得る。分析は、メディアチャンクごとのコーディング複雑度データを識別し得、コーディング複雑度データは、メディアアイテムのチャンクの画像または聴覚複雑度を表し得る1つまたは複数の測定値を決定するために使用され得る。 The complexity determination component 124 can analyze the entire media item, or part of a media item, such as the media item's metadata, or one or more chunks of the media item, as described in more detail below. The complexity of media chunks 152A-C can be determined by analyzing. The analysis can identify coding complexity data for each media chunk, and the coding complexity data can be used to determine one or more measurements that can represent an image or auditory complexity of a chunk of media items. ..
トランスコーディングコンポーネント126は、チャンクを修正するために、コーディング複雑度データにアクセスし、1つまたは複数のエンコーダ(たとえば、トランスコーダ)を選択し得る。トランスコーディングコンポーネント126は、同じメディアアイテムの複数の異なるチャンクをエンコードするために、複数の異なるエンコーダを選択し得る。たとえば、チャンクのうちのいくつかは、第1のトランスコーダを使用してエンコードされ得、同じメディアアイテムの他のチャンクは異なるトランスコーダを使用してエンコードされ得る。メディアアイテムがトランスコードされると、サーバ120またはコンテンツ共有プラットフォーム110の他のコンピューティングデバイスによって1つまたは複数のユーザデバイス130A〜Zに提供され得る。
ユーザデバイス130A〜Zは、パーソナルコンピュータ(PC)、ラップトップ、モバイル電話、スマートフォン、タブレットコンピュータ、ネットブックコンピュータ、ネットワーク接続テレビなどのコンピューティングデバイスを含み得る。いくつかの例では、ユーザデバイス130A〜Zはまた、「クライアントデバイス」と呼ばれ得る。ユーザデバイス130A〜Zの各々は、メディアキャプチャコンポーネント132A〜Zおよびメディアプレゼンテーションコンポーネント134A〜Zを含み得る。
User devices 130A-Z may include computing devices such as personal computers (PCs), laptops, mobile phones, smartphones, tablet computers, netbook computers, networked televisions and the like. In some examples, user devices 130A-Z may also be referred to as "client devices". Each of the user devices 130A-Z may include media capture components 132A-Z and
メディアキャプチャコンポーネント132A〜Zは、ユーザデバイスが、メディアアイテムを作成するためにユーザデバイスによって感知されたオーディオデータおよび画像データをキャプチャすることを可能にし得る。メディアプレゼンテーションコンポーネント134A〜Zは、ユーザデバイスが、コンテンツ共有プラットフォーム110から受信した記録済みメディアアイテムあるいは1つまたは複数のメディアアイテムを提示(たとえば、再生)することを可能にし得る。メディアプレゼンテーションコンポーネント134A〜Zは、画像、ビデオ、オーディオ、ウェブページ、ドキュメントなどを提示するメディアビューアを含み得る。
Media capture components 132A-Z may allow the user device to capture audio and image data sensed by the user device to create media items.
一例では、メディアビューアは、Webサーバによって提供されるコンテンツ(たとえば、ハイパーテキストマークアップ言語(HTML)ページなどのウェブページ、デジタルメディアアイテムなど)にアクセス、検索、提示、および/またはナビゲートすることができるウェブブラウザであり得る。メディアビューアは、コンテンツ(たとえば、ウェブページ、メディアビューア)をユーザにレンダリング、表示、および/または提示し得る。メディアビューアはまた、ウェブページ(たとえば、オンラインショップによって販売されている製品に関する情報を提供し得るウェブページ)に埋め込まれた、埋込みメディアプレーヤ(たとえば、Flash(登録商標)プレーヤまたはHTML5プレーヤ)を表示し得る。別の例では、メディアビューアは、ユーザがデジタルメディアアイテム(たとえば、デジタルビデオ、デジタル画像、電子書籍など)を見ることを可能にするスタンドアロンアプリケーション(たとえば、モバイルアプリケーション)であり得る。図1に示される例では、ユーザデバイス130A〜Zの各々は、メディア共有デバイス、メディア受信者デバイス、または両方の組合せとして機能し得る。 In one example, the media viewer accesses, searches, presents, and / or navigates content provided by a web server, such as web pages such as hypertext markup language (HTML) pages, digital media items, and so on. Can be a web browser that can. The media viewer may render, display, and / or present content (eg, a web page, media viewer) to the user. The media viewer also displays an embedded media player (eg, a Flash® player or HTML5 player) embedded in a web page (eg, a web page that can provide information about products sold by online shops). Can be done. In another example, the media viewer can be a stand-alone application (eg, a mobile application) that allows the user to view digital media items (eg, digital videos, digital images, ebooks, etc.). In the example shown in FIG. 1, each of the user devices 130A-Z can function as a media sharing device, a media receiver device, or a combination of both.
ネットワーク140は、サーバ120および他の公的に利用可能なコンピューティングデバイスへのアクセスを1つまたは複数のユーザデバイス130A〜Zに提供するパブリックネットワークであり得る。ネットワーク140は、1つまたは複数のワイドエリアネットワーク(WAN)、ローカルエリアネットワーク(LAN)、ワイヤードネットワーク(たとえば、イーサネット(登録商標)ネットワーク)、ワイヤレスネットワーク(たとえば、802.11ネットワークまたはWi-Fiネットワーク)、セルラーネットワーク(たとえば、ロングタームエボリューション(LTE)ネットワーク)、ルータ、ハブ、スイッチ、サーバコンピュータ、および/またはそれらの組合せを含み得る。
The
データストア150は、メモリ(たとえば、ランダムアクセスメモリ)、ドライブ(たとえば、ハードドライブ、フラッシュドライブ)、データベースシステム、あるいはデータを記憶することができる別のタイプのコンポーネントまたはデバイスであり得る。データストア150は、複数のコンピューティングデバイス(たとえば、複数のサーバコンピュータ)に広がることができる複数のストレージコンポーネント(たとえば、複数のドライブまたは複数のデータベース)を含み得る。データストア150は、コンテンツ共有プラットフォーム110から受信されるメディアアイテムのコピーを記憶するメディアキャッシュを含み得る。一例では、メディアアイテム112A〜Zの各々は、コンテンツ共有プラットフォーム110からダウンロードされるファイルであり得、メディアキャッシュにローカルに記憶され得る。別の例では、各メディアアイテム112は、コンテンツ共有プラットフォーム110からストリーミングされてもよく、トランスコードされるまで、サーバ120のメモリに一時的なコピーとして存在してもよい。
The data store 150 can be a memory (eg, random access memory), a drive (eg, a hard drive, a flash drive), a database system, or another type of component or device that can store data. The data store 150 may include multiple storage components (eg, multiple drives or multiple databases) that can be spread across multiple computing devices (eg, multiple server computers). The data store 150 may include a media cache that stores copies of media items received from the
本開示の実装形態は、サーバおよびコンテンツ共有プラットフォームに関して説明されているが、実装形態は一般に、デジタルコンテンツおよびユーザ間の接続を提供するあらゆるタイプのソーシャルネットワークにも適用され得る。本明細書で説明するシステムがユーザに関する個人情報を収集する状況、または個人情報を利用し得る状況では、コンテンツ共有プラットフォームがユーザ情報(たとえば、ユーザのソーシャルネットワークに関する情報、社会的なアクションまたは活動、職業、ユーザの嗜好、あるいはユーザの現在の場所)を収集するかどうかを制御するための、あるいはユーザに関連性の高い可能性があるコンテンツサーバからコンテンツを受信するかどうかを制御するための機会、および/またはその方法がユーザに提供され得る。さらに、特定のデータは、記憶または使用される前に1つまたは複数の方法で扱われ得るため、個人を特定できる情報は削除される。たとえば、ユーザの個人情報は、ユーザの個人を特定できる情報が決定されないように扱われ得、位置情報が取得されるユーザの地理的位置(たとえば、都市、郵便番号、または州レベル)が一般化され得るため、ユーザの特定の位置を決定することはできない。したがって、ユーザは、ユーザに関する情報が収集され、コンテンツ共有プラットフォームによって使用される方法の制御を有し得る。 Although the implementations of this disclosure are described for servers and content sharing platforms, the implementations can generally be applied to any type of social network that provides digital content and connections between users. In situations where the systems described herein collect or have access to personal information about a user, the Content Sharing Platform may use the user information (eg, information about the user's social network, social actions or activities, etc. Opportunity to control whether content is collected (occupation, user preference, or user's current location), or whether content is received from content servers that may be relevant to the user. , And / or methods thereof may be provided to the user. In addition, certain data may be treated in one or more ways before being stored or used, thus removing personally identifiable information. For example, a user's personal information can be treated so that no personally identifiable information about the user is determined, generalizing the user's geographic location (eg, city, zip code, or state level) from which the location information is obtained. It is not possible to determine a particular position for the user, as it may be. Therefore, the user may have control over how information about the user is collected and used by the content sharing platform.
本開示の実装形態では、「ユーザ」は単一の個人として表され得る。しかし、本開示の他の実装形態は、ユーザのセットおよび/または自動化されたソースによって制御されるエンティティである「ユーザ」を包含する。たとえば、ソーシャルネットワークにおけるコミュニティとしてフェデレーションされた個々のユーザのセットは、「ユーザ」と見なされ得る。 In the embodiments of the present disclosure, the "user" can be represented as a single individual. However, other implementations of the disclosure include "users", which are entities controlled by a set of users and / or automated sources. For example, a set of individual users federated as a community in a social network can be considered a "user".
図2は、例示的なコンピューティングシステム200を示すブロック図である。コンピューティングシステム200は図1のサーバ120と同一であってもよく、類似であってもよい。図2に示される例では、コンピューティングシステム200は、メディアセグメンテーションコンポーネント122、複雑度決定コンポーネント124、トランスコーディングコンポーネント126、およびデータストア150を含む。
FIG. 2 is a block diagram showing an exemplary computing system 200. The computing system 200 may be the same as or similar to the
メディアセグメンテーションコンポーネント122は、ディアアイテムを1つまたは複数のメディアチャンク152にセグメント化するために、メディアアイテム112を分析し得、またメディアアイテム112に対して1つまたは複数の前処理ステップを実行し得る。一例では、メディアセグメンテーションコンポーネント122は、中間ストリームモジュール210およびチャンク識別モジュール212を含み得る。
The media segmentation component 122 can analyze the media item 112 and perform one or more preprocessing steps on the media item 112 to segment the deer item into one or more media chunks 152. obtain. In one example, the media segmentation component 122 may include an
中間ストリームモジュール210は、1つまたは複数のデータストア150からメディアアイテム112にアクセスし得る。メディアアイテム112は、メディアアイテム112をキャプチャ、記録、変換、または記憶したコンピューティングデバイスまたはハードウェアデバイスに固有の形式であり得る。形式は、データを識別してインターリーブするための特定のマルチメディアコンテナ形式であり得、ビデオストリーム、オーディオストリーム、またはそれらの組合せなどの異なるタイプのデータを含み得る。形式は、Moving Picture Experts Group Standard(MPEG)(たとえば、MPEG4)、QuickTime File Format、Flash Video(.FLV、F4V)、Audio Video Interleaved(AVI)、Windows Media Video(WMV)、他の形式、またはそれらの組合せと同一であってもよく、類似であってもよい。一例では、メディアアイテム112は、メディアアイテムをキャプチャおよび記録したユーザデバイス(たとえば、モバイル電話、デジタル映画カメラ)に固有のネイティブ形式であり得る。別の例では、メディアアイテム112は、コンテンツ共有プラットフォームに特有の1つまたは複数の形式に変換され得る。いずれの例においても、メディアアイテム112の形式は、ソース形式または元の形式と見なされ得る。中間ストリームモジュール210は、メディアアイテム112を元の形式から1つまたは複数の中間形式に変換し得る。これは、メディアアイテムを元の形式から中間形式にデコードすることを含み得る。中間形式は、ストリームの形式(たとえば、中間ストリーム)であってもよく、ネイティブ形式とは異なっていてもよく、ネイティブ形式と類似であってもよく、同一であってもよい。
The
チャンク識別モジュール212は、中間ストリームにアクセスし、中間ストリームを1つまたは複数の固定サイズまたは可変サイズのメディアチャンク152にセグメント化し得る。一例としてビデオトランスコーディングを取り上げると、チャンク識別モジュール212は、中間ストリームを固定サイズのビデオチャンクに分割し得る。たとえば、中間ビデオストリームの15秒ごとのビデオデータは、個別のビデオチャンクとして識別され得る。別の例では、チャンク識別モジュール212は、フレーム内境界などの既存の境界に基づいて、中間ストリームを可変サイズのビデオチャンクに分割し得る。いずれの例においても、チャンク識別モジュール212は、ビデオコンテンツをビデオチャンクにセグメント化し得、チャンクの各々は、中間ストリームのビデオデータの少なくとも1つまたは複数の画像を含む。
The
オーディオコンテンツを伴う中間ストリームの場合、チャンク識別モジュール212は、中間ストリームを複数のオーディオチャンクにセグメント化し得る。ビデオストリームのオーディオデータは、より高い周波数(たとえば、48kHz)でサンプリングされ得、フレーム間圧縮は必要ない(たとえば、MP3オーディオデータ)。さらに、複雑なビデオ処理(たとえば、動きの推定および補正)による計算コストの高いビデオデータトランスコーディングと比較すると、オーディオトランスコーディングははるかに安価である。一例では、中間ストリームのオーディオチャンクは、中間ストリームのビデオチャンクより大きい場合がある。別の実施形態では、中間ストリームのオーディオコンテンツは、セグメント化されることなしにビデオまたは画像コンテンツから分離されてもよく、オーディオコンテンツ全体が単一のオーディオチャンクとして扱われてもよい。
For intermediate streams with audio content,
複雑度決定コンポーネント124は、メディアアイテム全体を分析することによって、またはメディアアイテムのメタデータあるいはメディアアイテムの1つまたは複数のチャンクなどのメディアアイテムの一部を分析することによって、メディアチャンク152の複雑度を決定し得る。分析はチャンクのコーディング複雑度データを識別し得、メディアアイテムのチャンクの聴覚、画像、またはビデオコーディング複雑度を表し得る1つまたは複数のメディア複雑度測定値を決定するためにコーディング複雑度データが使用され得る。複雑度決定コンポーネント124は、チャンク分析モジュール220および複雑度測定モジュール222を使用して、チャンクのメディア複雑度測定値252を決定し得る。
The complexity determination component 124 complicates the media chunk 152 by analyzing the entire media item or by analyzing part of the media item, such as the media item's metadata or one or more chunks of the media item. The degree can be determined. The analysis can identify the chunk coding complexity data, and the coding complexity data can be used to determine one or more media complexity measurements that can represent the chunk auditory, image, or video coding complexity of the media item. Can be used. The complexity determination component 124 may use the chunk analysis module 220 and the
メディア複雑度測定値252は、1つまたは複数のメディアチャンク152のコーディング複雑度を表す数値または非数値であってもよく、メディアアイテム112の特定のチャンクをエンコードする難しさを示してもよい。メディア複雑度測定値は、メディアアイテム112のチャンクに含まれる空間的および/または時間的情報(たとえば、モーションデータ)の量に直接または間接的に関連する(たとえば、比例する)可能性がある。たとえば、より高いメディア複雑度測定値は、ビデオフレームの大きい空間アクティビティに対応することが多いため、ビデオフレーム内の動き補償された大きい輝度残差値またはピクセル値の輝度分散に対応し得る。動きベクトルの長さ/エントロピー、およびフレーム残余のエネルギーなどの、ビデオフレームの抽出された時間的特徴も、ビデオフレームに存在する動きの量を反映する場合がある。 The media complexity measurement 252 may be a numeric or non-numeric value representing the coding complexity of one or more media chunks 152, and may indicate the difficulty of encoding a particular chunk of media item 112. Media complexity measurements can be directly or indirectly related (eg, proportional) to the amount of spatial and / or temporal information (eg, motion data) contained in chunks of media item 112. For example, higher media complexity measurements often correspond to large spatial activity in the video frame, which may correspond to a large motion-compensated luminance residual value or luminance variance of the pixel values within the video frame. The extracted temporal features of the video frame, such as the length / entropy of the motion vector and the energy of the frame residue, may also reflect the amount of motion present in the video frame.
チャンク分析モジュール220は、チャンクに関連付けられるコンテンツ情報を集めることによってチャンクを分析し得る。コンテンツ情報は、チャンクのフレームごとの分析を実行することなしに集められてよく、たとえば、チャンクまたはメディアアイテムに関連付けられるメタデータを分析することが含まれてよい。チャンク分析モジュール220は、複数のソースから情報を集めることができ、情報は、特定のチャンク、対応するメディアアイテム、他のチャンクまたはメディアアイテム、コンピューティングデバイス、ユーザ、他の情報あるいはそれらの組合せに関連し得る。コンテンツ情報は、メディアアイテムまたはチャンクの1つまたは複数の画像フレームの寸法に関連し得る。フレームの寸法は、フレームの幅(W)、フレームの高さ(H)、アスペクト比、他の寸法、またはそれらの組合せを含んでもよく、それらに関連してもよい。フレームの寸法は、ピクセル量(たとえば、1920×1080)、解像度値(たとえば、1080p、720p、1080i、720i)、解像度モード(たとえば、標準解像度(SD)、高解像度(HD)、超高解像度(UHD))、他の値、またはそれらの組合せで表現され得る。 The chunk analysis module 220 can analyze chunks by collecting content information associated with the chunks. Content information may be collected without performing a frame-by-frame analysis of chunks and may include, for example, analyzing metadata associated with chunks or media items. The chunk analysis module 220 can collect information from multiple sources and the information can be in a particular chunk, corresponding media item, other chunk or media item, computing device, user, other information or a combination thereof. Can be related. Content information can be related to the dimensions of one or more image frames of a media item or chunk. Frame dimensions may include, or may be related to, frame width (W), frame height (H), aspect ratio, other dimensions, or a combination thereof. Frame dimensions include pixel count (eg 1920 x 1080), resolution value (eg 1080p, 720p, 1080i, 720i), resolution mode (eg standard resolution (SD), high resolution (HD), ultra-high resolution (eg 1080p, 720p, 1080i, 720i)) It can be represented by UHD)), other values, or a combination thereof.
コンテンツ情報は、チャンクのフレームレートまたはビットレートに関する情報を含み得る。フレームレート(たとえば、フレーム周波数)は、時間単位で表示されるフレームの数を指し得、1秒あたりのフレーム数(Fps)で表現され得る。ビットレート(R)またはエンコードビットレートは、ソースコーディング(たとえば、データ圧縮)後のオーディオまたはビデオを表すために再生時間の単位ごとに使用されるビットの数を指し得る。ビットレートは、可変ビットレートマルチメディアソースコーディングスキームのコンテキストにおいて使用される場合、平均ビットレートであり得る。チャンクのエンコードビットレートは、バイト単位のチャンクのサイズを、記録の再生時間(秒)に8を掛けた値で割った値であり得る。一般的に、ビットレートが高いほど、チャンクはより複雑なコンテンツを含む。これは、ビデオの空間的および時間的特徴と、それに対応するエンコードビットレートの間に相関関係があることが多いためであり得る。 Content information may include information about chunk frame rates or bit rates. The frame rate (eg, frame frequency) can refer to the number of frames displayed in hours and can be expressed in frames per second (Fps). Bit rate (R) or encode bit rate can refer to the number of bits used per unit of playback time to represent audio or video after source coding (eg, data compression). The bit rate can be the average bit rate when used in the context of variable bit rate multimedia source coding schemes. The chunk encoding bit rate can be the size of the chunk in bytes divided by the playback time (seconds) of the recording multiplied by 8. In general, the higher the bit rate, the more complex the chunk contains. This may be because there is often a correlation between the spatial and temporal characteristics of the video and the corresponding encode bit rate.
コンテンツ情報は、チャンクのクロミナンスに関連してもよく、チャンクの色関連情報を伝達してもよい。色情報は、デジタルまたはアナログのビデオ撮影においてカラー画像パイプラインの一部として使用される色空間のファミリ(たとえば、YCbCr、YUV)に基づいている場合がある。色空間の例は、YCbCr(YCC)色空間であり得、これは、関連付けられる赤緑青(RGB)色空間からの数学的な座標変換によって定義され得る。Y(または、Y')は輝度成分であり得、CbおよびCrはそれぞれ青差と赤差の色差成分であり得る。 The content information may be related to chunk chrominance or may convey chunk color related information. Color information may be based on a family of color spaces (eg, YCbCr, YUV) used as part of the color image pipeline in digital or analog video capture. An example of a color space can be the YCbCr (YCC) color space, which can be defined by a mathematical coordinate transformation from the associated red-green-blue (RGB) color space. Y (or Y') can be a luminance component, and Cb and Cr can be color difference components of blue and red, respectively.
多くの場合、メディアアイテムは、クロマサブサンプリングを実行することによって、エンコードされたメディアアイテムにおいて利用可能な色情報を減らすことによって圧縮される。クロマサブサンプリングは、ルマ情報(たとえば、輝度)の解像度よりも低いクロマ情報(たとえば、色情報)の解像度で画像をエンコードし得る。サブサンプリングスキームは、一般的に、幅Jピクセルで高さ2ピクセルであり得る概念領域内の輝度およびクロミナンスサンプルの数を表す3部の比率J:a:b(たとえば、4:2:2)として表現される。「J」は水平サンプリング基準を表し、多くの場合値4である。「a」はJピクセルの1行目におけるクロミナンスサンプル(Cr、Cb)の数を表し、「b」はJピクセルの1行目と2行目の間のクロミナンスサンプル(Cr、Cb)の変化の数を表す。 Media items are often compressed by performing chroma subsampling to reduce the color information available in the encoded media item. Chroma subsampling can encode an image at a resolution of chroma information (eg, color information) that is lower than that of luma information (eg, brightness). Subsampling schemes generally have a three-part ratio J: a: b (eg 4: 2: 2) that represents the number of luminance and chromanance samples in a conceptual area that can be J pixels wide and 2 pixels high. Expressed as. "J" represents a horizontal sampling criterion, often a value of 4. "A" represents the number of chrominance samples (Cr, Cb) in the first row of J pixel, and "b" is the change of chrominance sample (Cr, Cb) between the first and second rows of J pixel. Represents a number.
クロマサブサンプリングの量は、クロマ係数(CF)で表され得る。一例では、クロマ係数は、4:4:4ベースラインなどのベースラインに対して計算され得る。次いで、係数の各々を合計し、結果を12(すなわち、4+4+4)で除算することによって、クロマ係数が決定され得る。たとえば、4:2:2Y'CbCrクロマサブサンプリングスキームを使用する圧縮画像は、4+2+2が8であり、8/12が2/3であるため、2/3のクロマ係数を有し得る。 The amount of chroma subsampling can be expressed in terms of chroma coefficient (CF). In one example, the chroma coefficient can be calculated for a baseline such as a 4: 4: 4 baseline. The chroma coefficient can then be determined by summing each of the coefficients and dividing the result by 12 (ie, 4 + 4 + 4). For example, a compressed image using the 4: 2: 2 Y'CbCr chroma subsampling scheme has a chroma coefficient of 2/3 because 4 + 2 + 2 is 8 and 8/12 is 2/3. obtain.
複雑度測定モジュール222は、チャンク分析モジュール220によって決定されたコンテンツ情報にアクセスし得、メディアチャンク152のメディア複雑度測定値252を計算し得る。メディアチャンクがビデオコンテンツを含む場合、メディア複雑度測定値は、ピクセルあたりのビット(bpp)値に基づいて概算されるビデオコーディング複雑度(VCC)測定値であり得る。ピクセルあたりのビット値は、チャンクの1つまたは複数のフレームにわたって、所与の品質レベルでピクセルをエンコードするために使用されるビットの数を表し得る。一例では、複雑度測定モジュール222は、チャンクのピクセル単位のビットレート(R)、フレームレート(Fps)、クロマ係数(CF)、フレーム幅(W)、およびフレーム高さ(H)を含むコンテンツ情報にアクセスすることによって、チャンクのビデオコーディング複雑度(VCC)測定値を決定し得る。次いで、複雑度測定モジュール222は、VCC=R/(W*H*Fps*CF)を備える数式に基づいてビデオコーディングの複雑度の値を計算し得る。
The
複雑度測定モジュール222は、ソースメディアチャンク152の1つまたは複数の追加の空間的および/または時間的特徴にVCC値を補足または基づかせることによって、メディア複雑度測定値252(たとえば、ビデオコーディング複雑度測定値)の精度を向上させることができる。たとえば、メディアチャンク152のVCC値は、フレームレベルの空間分散、残留エネルギー、スキップされたマクロブロック(MB)の数、およびチャンクの予測マクロブロックの動きベクトルをエンコードするためのビットの数に基づいて、追加的または代替的に計算され得る。ソースメディアチャンク152をエンコードするユニバーサルワークロードなどの他のコーディングパラメータをVCC値の計算において使用することができる。
複雑度決定コンポーネント124は、メディア複雑度測定値の決定を向上させるために、機械学習技法を組み込むことができる。一例では、複雑度決定コンポーネント124は、メディアアイテムの空間的および時間的特徴とその対応するエンコードビットレートとの間の相関関係を学習するために、メディアデータストアから選択されたメディアアイテムを使用してオフラインでトレーニングされ得る。たとえば、複雑度決定コンポーネント124は、大きいメディアセット(たとえば、ビデオデータベースからの20,000のビデオ)で線形回帰アルゴリズムを使用してトレーニングされ得る。選択したビデオ機能と正規化されたビットレートとの間の関係をモデル化するために、線形回帰アルゴリズムが使用され得る。 The complexity determination component 124 can incorporate machine learning techniques to improve the determination of media complexity measurements. In one example, the complexity determination component 124 uses a media item selected from a media data store to learn the correlation between the spatial and temporal characteristics of the media item and its corresponding encoded bit rate. Can be trained offline. For example, complexity determination component 124 can be trained using a linear regression algorithm on a large media set (eg, 20,000 videos from a video database). A linear regression algorithm can be used to model the relationship between the selected video function and the normalized bit rate.
トランスコーディングコンポーネント126は、チャンクを修正するために、コーディング複雑度データにアクセスし、1つまたは複数のエンコーダ(たとえば、トランスコーダ)を選択し得る。トランスコーディングコンポーネント126は、同じメディアアイテムの複数の異なるチャンクをトランスコードするために、複数の異なるエンコーダを選択し得る。たとえば、チャンクのうちのいくつかは第1のトランスコーダを使用してエンコードされ、同じメディアアイテムの他のチャンクは異なるトランスコーダを使用してエンコードされ得る。メディアアイテムがトランスコードされると、サーバ120、またはコンテンツ共有プラットフォーム110の他のコンピューティングデバイスによって、1つまたは複数のユーザデバイス130に提供され得る。一例では、トランスコーディングコンポーネント126は、選択モジュール230、開始モジュール232、および組合せモジュール234を含み得る。
選択モジュール230は、メディアチャンク152の各々についてメディア複雑度測定値252にアクセスし得、それぞれのメディア複雑度測定値に基づいてメディアチャンクのトランスコーダを選択し得る。選択モジュール230は、異なるエンコーダの間で選択する際に1つまたは複数のしきい値を使用し得る。しきい値は、コンピューティングシステム200に記憶された、またはコンピューティングシステム200にアクセス可能な所定の値に基づいてもよく、またメディアチャンク複雑度しきい値の特定の値(たとえば、ピクセルあたりのビット(bpp)値)に対応してもよい。所定のしきい値は、設計者、開発者、管理者、他のユーザ、またはそれらの組合せの入力に基づいてもよい。所定のしきい値は、機械学習に基づいて生成または調整され得、エンコーディングがチャンクで完了する前、最中、または後にフィードバックに基づいて時間とともに更新され得る。 The selection module 230 may have access to media complexity measurements 252 for each of the media chunks 152 and may select media chunk transcoders based on each media complexity measurement. The selection module 230 may use one or more thresholds when selecting between different encoders. The threshold may be based on a predetermined value stored in or accessible to the compute system 200, and may be based on a specific value of the media chunk complexity threshold (eg, per pixel). It may correspond to a bit (bpp) value). The predetermined threshold value may be based on the input of a designer, a developer, an administrator, another user, or a combination thereof. Predetermined thresholds can be generated or adjusted based on machine learning and can be updated over time based on feedback before, during, or after encoding is completed in chunks.
選択モジュール230は、メディアチャンクを符号化するために特定のエンコーダを選択する際に、チャンクのメディア複雑度指標を所定のしきい値と比較し得る。所定のしきい値(たとえば、VCCしきい値またはbppしきい値)は、コーディング複雑度のカテゴリ間の分割点を反映し得る。一例では、2つのカテゴリがあり得、所定のしきい値複雑度値は、2つのグループ間の分割を意味し得る。しきい値を下回るメディア複雑度測定値を有するチャンクは、チャンクの第1のセット(たとえば、より低い複雑度のチャンク)に関連付けられ得、しきい値以上のメディア複雑度測定値を有するチャンクは、チャンクの第2のセット(たとえば、より高い複雑度のチャンク)に関連付けられ得る。選択モジュール230は、より低い複雑度に関連付けられるチャンクをエンコードするためにシングルパスエンコーダ/トランスコーダを選択し得、より高い複雑度に関連付けられるチャンクをエンコードするために、マルチパスエンコーダ/トランスコーダを選択し得る。他の例では、3つ以上のカテゴリの複雑度がある。 The selection module 230 may compare a chunk's media complexity index with a predetermined threshold when selecting a particular encoder to encode the media chunk. A given threshold (eg, VCC threshold or bpp threshold) can reflect the dividing point between categories of coding complexity. In one example, there can be two categories, and a given threshold complexity value can mean a division between two groups. Chunks with media complexity measurements below the threshold can be associated with a first set of chunks (eg, chunks with lower complexity), and chunks with media complexity measurements above the threshold can be associated with. , Can be associated with a second set of chunks (eg, higher complexity chunks). Selection module 230 may select a single-pass encoder / transcoder to encode chunks associated with lower complexity, and a multi-pass encoder / transcoder to encode chunks associated with higher complexity. You can choose. In another example, there are three or more categories of complexity.
開始モジュール232は、メディアチャンクおよび選択されたエンコーダに基づいてエンコーディング要求を生成し得る。エンコーディング要求は、チャンク識別子、メディアコンテンツタイプ(たとえば、ビデオチャンク、オーディオチャンク)、エンコーダ識別子(たとえば、シングルパス、マルチパス)、チャンクサイズ、チャンクオフセット(たとえば、メディアアイテムに関するオフセット)、タイムスタンプ、ソース形式、ターゲット形式、他の情報、またはそれらの組合せの1つまたは複数を含み得る。開始モジュール232は、個々のメディアチャンク152に対する要求を提出してもよく、または複数のメディアチャンク152に対する要求を提出してもよい。たとえば、より高い複雑度のチャンクのうちの1つまたは複数(たとえば、第1のセットのすべて)を識別する要求、およびより低い複雑度のチャンクのうちの1つまたは複数(たとえば、第2のセットのすべて)を識別する別の要求が識別可能な要求があり得る。開始モジュール232は、エンコーディングを実行するために要求をコンピューティングシステム200上のコンポーネントに送信してもよく、エンコーディングを実行するために要求を1つまたは複数の他のコンピュータシステム(たとえば、クラスタのメンバー)に送信してもよい。いずれの例においても、メディアチャンクのエンコーディングは、並列に、直列に、またはそれらの組合せにおいて発生し得る。
組合せモジュール234はエンコードされたメディアチャンクにアクセスし得、メディアアイテムのエンコードされたバージョンを生成するためにエンコードされたメディアチャンクを組み合わせし得る。組合せモジュール234は、エンコードされたメディアチャンクにアクセスし得、エンコードされたチャンクをマージされたメディアアイテムにマージし得る。マージプロセスは、メディアアイテムの先頭に対応するチャンクを検出することを含み得る。エンコードされたチャンクが第1のチャンクであることに応答して、組合せモジュール234はヘッダ情報を保持し得、残りのチャンク(たとえば、第1ではないチャンク)については、組合せモジュール234はヘッダ情報を削除し得る。組合せモジュール234は、エンコードされたチャンクを順番に組み合わせてもよく、また組み合わせられたメディアアイテム内のエンコードされたチャンクの位置は、チャンク識別に基づいてもよい。たとえば、H.264ビデオ形式のチャンクはネットワーク抽象層(NAL)ヘッダを含み得、組合せモジュール234は第1のビデオチャンクに含まれるNALヘッダを保持し、後続のビデオチャンク内のNALヘッダを取り除くことができる。
図3は、本開示の1つまたは複数の態様による、同じメディアアイテムの異なるチャンクをトランスコードするために、複数の異なるトランスコーダを使用するための方法300の例示的な一例の流れ図を示す。方法300およびその個々の機能、ルーチン、サブルーチン、または動作の各々は、本方法を実行するコンピュータデバイスの1つまたは複数のプロセッサによって実行され得る。特定の実装形態では、方法300は、単一のコンピューティングデバイスによって実行され得る。あるいは、方法300は、2つ以上のコンピューティングデバイスによって実行され得、各コンピューティングデバイスは、方法の1つまたは複数の個々の機能、ルーチン、サブルーチン、または動作を実行し得る。例示的な例では、方法300を実装するコンピューティングデバイスは同期され得る。あるいは、方法300を実装するプロセスは、互いに関して非同期的に実行され得る。 FIG. 3 shows a flow diagram of an exemplary example of Method 300 for using multiple different transcoders to transcode different chunks of the same media item according to one or more aspects of the present disclosure. Each of Method 300 and its individual functions, routines, subroutines, or actions may be performed by one or more processors of the computer device performing the method. In certain implementations, Method 300 can be performed by a single computing device. Alternatively, method 300 may be performed by two or more computing devices, each computing device may perform one or more individual functions, routines, subroutines, or actions of the method. In an exemplary example, computing devices that implement Method 300 can be synchronized. Alternatively, the process of implementing method 300 can be performed asynchronously with respect to each other.
説明を簡単にするために、本開示の方法は一連の行為として図示および説明されている。しかしながら、本開示による行為は、様々な順序で、および/または同時に、ならびに本明細書では提示および説明されていない他の行為とともに発生する可能性がある。さらに、開示された主題に従って方法を実装するために、図示されたすべての行為が必要とされるわけではない。さらに、当業者は、本方法が状態図またはイベントを介して一連の相互に関係する状態として代替的に表され得ることを理解および認識するだろう。さらに、本明細書で開示される方法は、そのような方法をコンピューティングデバイスに輸送および転送することを容易にするために製造品に記憶するできることが理解されるべきである。本明細書で使用される「製造品」という用語は、任意のコンピュータ可読デバイスまたはストレージ媒体からアクセス可能なコンピュータプログラムを包含することが意図されている。一実装形態では、方法300は、図1のサーバ120または図2のコンピューティングシステム200によって実行され得る。
For simplicity of explanation, the methods of the present disclosure are illustrated and described as a series of actions. However, the acts of this disclosure may occur in various orders and / or simultaneously, and with other acts not presented and described herein. Moreover, not all of the actions illustrated are required to implement the method in accordance with the disclosed subject matter. In addition, one of ordinary skill in the art will understand and recognize that the method can be presented alternative as a series of interrelated states via a phase diagram or event. Further, it should be understood that the methods disclosed herein can be stored in the product to facilitate transport and transfer of such methods to computing devices. As used herein, the term "manufactured" is intended to include computer programs accessible from any computer-readable device or storage medium. In one implementation, method 300 may be performed by
方法300は、サーバデバイスまたはクライアントデバイスの処理デバイスによって実行され得、ブロック302において開始し得る。ブロック302において、処理デバイスは、第1のチャンクと第2のチャンクを備えるメディアアイテムにアクセスし得る。処理デバイスは、メディアアイテムをキャプチャおよび記録したユーザデバイスからメディアアイテムを受信し得、メディアアイテムを第1のチャンクおよび第2のチャンクを含む複数のチャンクにセグメント化し得る。一例では、メディアアイテムの第1のチャンクおよびメディアアイテムの第2のチャンクは、メディアアイテムの重複しない持続時間のシーケンスから導出され得る。たとえば、メディアアイテムは5分間の長さであってよく、メディアアイテムを生成するためにチャンクの各々を連結することができるようにチャンクにセグメント化され得る。別の例では、第1のチャンクと第2のチャンクは部分的または完全に重複し得る。たとえば、第1のチャンクはビデオのオーディオコンテンツを含み得、第2のチャンクはビデオの画像コンテンツであり得、オーディオコンテンツは、オーディオコンテンツとビデオコンテンツの一部またはすべてが同時に提示されるようにビデオコンテンツと重複し得る。いずれの例においても、処理デバイスは、より少ないコンピューティングリソースを使用してメディア複雑度測定値を決定することができるように、元のチャンクの代わりにより低い解像度にダウンスケールされたチャンク(たとえば、第1のチャンクおよび第2のチャンク)にアクセスし得る。
Method 300 can be performed by the processing device of the server device or client device and can start at
ブロック304において、処理デバイスは、第1のチャンクの第1のメディア複雑度指標と第2のチャンクの第2のメディア複雑度指標とを決定し得る。第1のメディア複雑度指標および第2のメディア複雑度指標の各々は、それぞれのチャンクの空間的および時間的分布を示し得る。メディアアイテムがビデオである場合、メディア複雑度指標は、メディアアイテムの第1のチャンクのビデオコーディング複雑度測定値および第2のチャンクのビデオコーディング複雑度測定値を含み得る。一例では、第1のチャンクのビデオコーディング複雑度(VCC)測定値を決定するステップは、第1のチャンクのピクセル単位のビットレート(R)、フレームレート(Fps)、クロマ係数(CF)、フレーム幅(W)、およびフレーム高さ(H)を決定するステップを含み得る。このコンテンツ情報は、以下の数式:VCC=R/(W*H*Fps*CF)に基づいてビデオコーディングの複雑度の値を計算するために使用され得る。
At
ブロック306において、処理デバイスは、複数のエンコーダから第1のエンコーダおよび第2のエンコーダを選択し得る。第1のエンコーダは第1のチャンクの第1のメディア複雑度指標に基づいて選択され得、第2のエンコーダは第2のチャンクの第2のメディア複雑度指標に基づいて選択される。一例では、第1のエンコーダを選択するステップは、第1のチャンクの第1のメディア複雑度指標を所定のしきい値と比較することと、第1のメディア複雑度指標が所定のしきい値未満であることに応答してシングルパスエンコーダを選択することとを行う処理デバイスを含み得る。所定のしきい値は、設計者、開発者、管理者、他のユーザ、またはそれらの組合せによって提供される所定の値に基づいてもよい。所定のしきい値は、機械学習に基づいて調整され得、エンコーディングがチャンクで完了した後にフィードバックに基づいて時間とともに修正され得る。
At
複数のエンコーダは、複数の可変ビットレートエンコーダを含み得、第1のエンコーダはシングルパスエンコーダであり得、第2のエンコーダはマルチパスエンコーダであり得る。シングルパスエンコーダは、ビデオバッファリング検証器(VBV)を含むシングルパストランスコーダであり得、マルチパスエンコーダは、制約された品質と制限されたビットレートとを備える2パストランスコーダであり得る。ビデオバッファリング検証器は、MPEG規格(たとえば、MPEG2)で使用されるビデオバッファモデルであり得、エンコードされたビデオストリームを別のデバイス(たとえば、デコーディングデバイス、ユーザデバイス)で正しくバッファリングして再生できることを確実にし得る。ビデオバッファリング検証器は、受信デバイス(たとえば、デコーダデバイス)においてバッファオーバーフローまたはバッファアンダーフローがあるかどうかを決定(たとえば、推定または予測)するために使用され得る。ビデオバッファリング検証器は、メディアストリームが受信されるビットレート(たとえば、最大ビットレート)およびメディアストリームが記憶されるバッファサイズを考慮に入れてもよい。一例では、ビデオバッファリング検証器は、1つまたは複数のリーキーバケットモデルを使用して実装され得る。離散イベントのいくつかのシーケンスが、それらの平均およびピークレートまたは頻度の定義された制限に適合するかどうかを決定するために、リーキーバケットモデルが使用され得る。リーキーバケットモデルは、データ送信(たとえば、パケット)が帯域幅とバースト性の定義された制限に適合していることを確認するために、パケット交換コンピュータネットワークに適用し得る。バースト性は、ネットワークトラフィックのフロー内の変動の指標である。 The plurality of encoders may include a plurality of variable bit rate encoders, the first encoder may be a single-pass encoder and the second encoder may be a multi-pass encoder. A single-pass encoder can be a single-pass transcoder that includes a video buffering verifier (VBV), and a multi-pass encoder can be a two-pass transcoder with constrained quality and a constrained bit rate. A video buffering verifier can be the video buffer model used in the MPEG standard (eg MPEG2), correctly buffering the encoded video stream on another device (eg decoding device, user device). You can be sure that you can play it. A video buffering verifier can be used to determine (eg, estimate or predict) whether a receiving device (eg, a decoder device) has a buffer overflow or buffer underflow. The video buffering verifier may take into account the bit rate at which the media stream is received (eg, the maximum bit rate) and the buffer size at which the media stream is stored. In one example, the video buffering verifier may be implemented using one or more leaky bucket models. A leaky bucket model can be used to determine whether several sequences of discrete events meet defined limits for their mean and peak rate or frequency. The leaky bucket model can be applied to packet-switched computer networks to ensure that data transmissions (eg, packets) meet the defined limits of bandwidth and burstability. Burstability is an indicator of fluctuations in the flow of network traffic.
ブロック308において、処理デバイスは、第1のエンコーダを使用して第1のチャンクをエンコードし得、第2のエンコーダを使用して第2のチャンクをエンコードする。一例では、メディアアイテムの第1のチャンクはシングルパスエンコーダを使用してエンコードされ得、メディアアイテムの第2のチャンクはマルチパスエンコーダを使用してエンコードされ得る。処理デバイスはまた、エンコードされたメディアアイテムを形成するために、メディアアイテムの第1のチャンク(シングルパスエンコーダを使用してエンコードされた)をメディアアイテムの第2のチャンク(2パスエンコーダを使用してエンコードされた)と組み合わせてもよい。ブロック308を参照して本明細書で上述した動作を完了することに応答して、本方法は終了し得る。
At
図4は、本開示の1つまたは複数の態様に従って動作するコンピュータシステムのブロック図を示している。特定の実装形態では、コンピュータシステム400は、(たとえば、ローカルエリアネットワーク(LAN)、イントラネット、エクストラネット、またはインターネットなどのネットワークを介して)他のコンピュータシステムに接続され得る。コンピュータシステム400は、クライアント-サーバ環境のサーバまたはクライアントコンピュータの容量で、あるいはピアツーピアまたは分散ネットワーク環境のピアコンピュータとして動作し得る。コンピュータシステム400は、パーソナルコンピュータ(PC)、タブレットPC、セットトップボックス(STB)、携帯情報端末(PDA)、セルラー電話、ウェブ機器、サーバ、ネットワークルータ、スイッチまたはブリッジ、あるいはそのデバイスによって実行されるべきアクションを指定する命令のセット(シーケンシャルまたはその他)を実行することができる任意のデバイスによって提供され得る。さらに、「コンピュータ」という用語は、本明細書で説明する方法のうちの任意の1つまたは複数を実行するために命令のセット(または、複数のセット)を個別または共同で実行するコンピュータの任意の集合を含むものとする。
FIG. 4 shows a block diagram of a computer system operating according to one or more aspects of the present disclosure. In certain embodiments, the
さらなる態様では、コンピュータシステム400は、処理デバイス402、揮発性メモリ404(たとえば、ランダムアクセスメモリ(RAM))、不揮発性メモリ406(たとえば、読取り専用メモリ(ROM)、または電気的消去可能プログラマブルROM(EEPROM))、およびバス408を介して互いに通信し得るデータストレージデバイス416を含み得る。
In a further aspect, the
処理デバイス402は、汎用プロセッサ(たとえば、複雑な命令セット計算(CISC)マイクロプロセッサ、縮小命令セット計算(RISC)マイクロプロセッサ、非常に長い命令語(VLIW)マイクロプロセッサ、他のタイプの命令セットを実装するマイクロプロセッサ、または命令セットのタイプの組合せを実装するマイクロプロセッサなど)、または専用プロセッサ(たとえば、特定用途向け集積回路(ASIC)、フィールドプログラマブルゲートアレイ(FPGA)、デジタル信号プロセッサ(DSP)、またはネットワークプロセッサなど)などの1つまたは複数のプロセッサによって提供され得る。
コンピュータシステム400は、ネットワークインターフェースデバイス422をさらに含み得る。コンピュータシステム400はまた、ビデオディスプレイユニット410(たとえば、LCD)、英数字入力デバイス412(たとえば、キーボード)、カーソル制御デバイス414(たとえば、マウス)、および信号生成デバイス420を含み得る。
データストレージデバイス416は、図1および図2のトランスコーディングコンポーネント126をエンコードする命令、ならびに図3の方法300を実装するための命令を含む、本明細書で説明する方法または機能のうちのいずれか1つまたは複数をエンコードする命令426を記憶し得る非一時的コンピュータ可読記憶媒体424を含み得る。
The data storage device 416 is one of the methods or functions described herein, including instructions for encoding the
命令426はまた、コンピュータシステム400による実行中に、揮発性メモリ404内および/または処理デバイス402内に完全にまたは部分的に存在することもあり、したがって、揮発性メモリ404および処理デバイス402もマシン可読記憶媒体を構成し得る。
コンピュータ可読記憶媒体424は、例示的な例では単一の媒体として示されているが、「コンピュータ可読記憶媒体」という用語は、実行可能な命令の1つまたは複数のセットを記憶する単一の媒体または複数の媒体(たとえば、集中または分散データベース、および/または関連付けられるキャッシュおよびサーバ)を含むものとする。「コンピュータ可読記憶媒体」という用語はまた、コンピュータに本明細書に記載の方法のうちのいずれか1つまたは複数を実行させるコンピュータによる実行のための命令のセットを記憶またはエンコードすることができる任意の有形媒体も含むものとする。「コンピュータ可読記憶媒体」という用語は、これらに限定されないが、ソリッドステートメモリ、光学媒体、および磁気媒体を含むものとする。
The computer-
本明細書で説明する方法、コンポーネント、および機能は、個別のハードウェアコンポーネントによって実装されてもよく、ASIC、FPGA、DSP、または類似のデバイスなどの他のハードウェアコンポーネントの機能に統合されてもよい。さらに、方法、コンポーネント、および機能は、ファームウェアモジュールまたはハードウェアデバイス内の機能回路によって実装され得る。さらに、方法、コンポーネント、および機能は、ハードウェアデバイスとコンピュータプログラムコンポーネントの任意の組合せにおいて、またはコンピュータプログラムにおいて実装され得る。 The methods, components, and features described herein may be implemented by individual hardware components or integrated into the functionality of other hardware components such as ASICs, FPGAs, DSPs, or similar devices. good. In addition, methods, components, and functions may be implemented by functional circuits within firmware modules or hardware devices. In addition, methods, components, and features may be implemented in any combination of hardware device and computer program components, or in a computer program.
特に明記しない限り、「検出」、「決定」、「解放」、「破壊」、「開始」、「作成」、「放棄」などの用語は、コンピュータシステムのレジスタおよびメモリ内の物理(電子)量として表されるデータを、コンピュータシステムのメモリまたはレジスタ、あるいは他のそのような情報ストレージ、送信、またはディスプレイデバイス内の物理量として同様に表される他のデータに操作および変換するコンピュータシステムによって実行または実装されるアクションとプロセスを指す。また、本明細書で使用される「第1」、「第2」、「第3」、「第4」などの用語は、異なる要素を区別するためのラベルとして意味され、それらの数値指定による順序の意味を有しない場合がある。 Unless otherwise stated, terms such as "detection," "decision," "release," "destroy," "start," "create," and "abandoned" are the physical (electronic) quantities in computer system registers and memory. Performed or transformed by a computer system that manipulates and transforms the data represented as into the memory or registers of the computer system, or other data also represented as physical quantities in such information storage, transmission, or display devices. Refers to the actions and processes that are implemented. In addition, terms such as "first", "second", "third", and "fourth" used in the present specification are meant as labels for distinguishing different elements, and are specified by their numerical values. May have no meaning in order.
本明細書で説明される例は、本明細書で説明される方法を実行するための装置にも関する。この装置は、本明細書に記載の方法を実行するために特別に構築されてもよく、またはコンピュータシステムに記憶されたコンピュータプログラムによって選択的にプログラムされた汎用コンピュータシステムを備えてもよい。そのようなコンピュータプログラムは、コンピュータ可読の有形のストレージ媒体に記憶され得る。 The examples described herein also relate to devices for performing the methods described herein. The device may be specially constructed to perform the methods described herein, or may include a general purpose computer system selectively programmed by a computer program stored in the computer system. Such computer programs may be stored on computer-readable tangible storage media.
本明細書で説明される方法および例示的な例は、任意の特定のコンピュータまたは他の装置に本質的に関連するものではない。本明細書に記載の教示に従って様々な汎用システムが使用され得、または方法300および/またはその個々の機能、ルーチン、サブルーチン、または動作の各々を実行するためにより特殊な装置を構築することが便利であることが分かる。これらの様々なシステムの構造の例は、上記の説明において記載されている。上記の説明は例示的なものであり、限定的なものではない。本開示は、特定の例示的な例および実装形態を参照して説明されたが、本開示は、説明された例および実装形態に限定されないことが認識されるであろう。本開示の範囲は、特許請求の範囲が権利を有する均等物の全範囲とともに、以下の特許請求の範囲を参照して決定されるべきである。 The methods and exemplary examples described herein are not inherently relevant to any particular computer or other device. Various general purpose systems may be used in accordance with the teachings described herein, or it is convenient to construct more specialized devices to perform each of the methods 300 and / or their individual functions, routines, subroutines, or operations. It turns out that. Examples of the structure of these various systems are given in the above description. The above description is exemplary and not limiting. Although the present disclosure has been described with reference to specific exemplary examples and implementations, it will be appreciated that the present disclosure is not limited to the examples and implementations described. The scope of the present disclosure should be determined with reference to the following claims, as well as the full range of equivalents for which the claims are entitled.
100 システムアーキテクチャ
110 コンテンツ共有プラットフォーム
112A〜Z メディアアイテム
120 サーバ
122 メディアセグメンテーションコンポーネント
124 複雑度決定コンポーネント
126 トランスコーディングコンポーネント
130A〜Z ユーザデバイス
132A〜Z メディアキャプチャコンポーネント
134A〜Z メディアプレゼンテーションコンポーネント
140 ネットワーク
150 データストア
152A〜C メディアチャンク
152 ソースメディアチャンク
200 コンピューティングシステム
210 中間ストリームモジュール
212 チャンク識別モジュール
220 チャンク分析モジュール
222 複雑度測定モジュール
230 選択モジュール
232 開始モジュール
234 組合せモジュール
252 メディア複雑度測定値
300 方法
400 コンピュータシステム
402 処理デバイス
404 揮発性メモリ
406 不揮発性メモリ
408 バス
410 ビデオディスプレイユニット
412 英数字入力デバイス
414 カーソル制御デバイス
416 データストレージデバイス
420 信号生成デバイス
422 ネットワークインターフェースデバイス
424 非一時的コンピュータ可読記憶媒体
426 命令
100 system architecture
110 Content Sharing Platform
112A ~ Z media items
120 servers
122 Media Segmentation Component
124 Complexity determination component
126 Transcoding components
130A-Z user device
132A-Z Media Capture Component
134A-Z Media Presentation Components
140 network
150 data store
152A-C Media Chunk
152 Source Media Chunk
200 computing system
210 Intermediate stream module
212 Chunk Identification Module
220 chunk analysis module
222 Complexity measurement module
230 selection module
232 Start module
234 Combination module
252 Media complexity measurements
300 ways
400 computer system
402 Processing device
404 Volatile memory
406 Non-volatile memory
408 bus
410 video display unit
412 Alphanumeric input device
414 Cursor control device
416 Data storage device
420 Signal generation device
422 network interface device
424 Non-temporary computer-readable storage medium
426 instructions
Claims (11)
前記メディアアイテムが、ビデオであり、
前記第1のチャンクおよび前記第2のチャンクの各々が、前記ビデオの複数のフレームに対応する複数の画像を含む、ステップと、
処理デバイスによって、前記第1のチャンクの平均ビットレートを決定するステップと、
複雑度測定モジュールを実行する前記処理デバイスによって、前記第1のチャンクの第1のメディア複雑度指標と前記第2のチャンクの第2のメディア複雑度指標とを決定するステップであって、
前記第1のメディア複雑度指標および前記第2のメディア複雑度指標の各々が、それぞれのチャンクに含まれる複数の画像の時間的分布に対応し、
前記第1のメディア複雑度指標が、前記第1のチャンクの前記平均ビットレートに基づく数式を使用して決定され、かつ前記第1のチャンクの前記複数のフレームの画像ピクセル値の分析を実行することなく決定される、ステップと、
前記処理デバイスによって、複数のエンコーダからシングルパスエンコーダおよびマルチパスエンコーダを選択するステップであって、
前記シングルパスエンコーダが、前記第1のチャンクの前記第1のメディア複雑度指標に基づいて選択され、前記第1のチャンクがより低い複雑度に関連付けられ、
前記マルチパスエンコーダが、前記第2のチャンクの前記第2のメディア複雑度指標に基づいて選択され、前記第2のチャンクがより高い複雑度に関連付けられる、ステップと、
前記シングルパスエンコーダを使用して前記メディアアイテムの前記第1のチャンクをエンコードし、前記マルチパスエンコーダを使用して前記メディアアイテムの前記第2のチャンクをエンコードするステップと
を備える、
方法。 A step to access a media item with a first chunk and a second chunk ,
The media item is a video
A step, wherein each of the first chunk and the second chunk contains a plurality of images corresponding to a plurality of frames of the video .
The step of determining the average bit rate of the first chunk depending on the processing device, and
A step of determining a first media complexity index of the first chunk and a second media complexity index of the second chunk by the processing device running the complexity measurement module.
Each of the first media complexity index and the second media complexity index corresponds to the temporal distribution of a plurality of images contained in each chunk.
It said first media complexity measure is determined using a formula based on the average bit rate of the first chunk, and performs an analysis of the image pixel values of said plurality of frames of the first chunk Steps and decisions that are decided without
It is a step of selecting a single-pass encoder and a multi-pass encoder from a plurality of encoders by the processing device.
The single-pass encoder is selected based on the first media complexity index of the first chunk so that the first chunk is associated with lower complexity.
A step in which the multipath encoder is selected based on the second media complexity index of the second chunk and the second chunk is associated with higher complexity .
The single-pass encoder is used to encode the first chunk of the media item, and the multi-pass encoder is used to encode the second chunk of the media item.
Method.
請求項1に記載の方法。 Each of the plurality of encoders comprises a variable bit rate encoder.
The method according to claim 1.
請求項1に記載の方法。 Each of said first medium complexity measure and the second medium complexity index, corresponding further respective spatial distribution of the plurality of images included in each chunk,
The method according to claim 1.
前記決定するステップが、
前記メディアアイテムの前記第1のチャンクのビデオコーディング複雑度測定値および前記第2のチャンクのビデオコーディング複雑度測定値を決定するステップを備える、
請求項1に記載の方法。 Before SL first media complexity measure and the second medium complexity measure is a video coding complexity (VCC) measurements,
The step to determine is
A step of determining a video coding complexity measurement of the first chunk and a video coding complexity measurement of the second chunk of the media item.
The method according to claim 1.
前記第2のチャンクのメタデータに基づいて、前記第2のチャンクのピクセル単位のビットレート(R)、フレームレート(Fps)、クロマ係数(CF)、フレーム幅(W)、またはフレーム高さ(H)のうちの1つまたは複数を決定することを含み、
前記複雑度測定モジュールによって、VCC=R/(W*H*Fps*CF)を備える数式に基づいて、前記第2のメディア複雑度指標のための値(VCC)を計算するステップをさらに備える、
請求項1に記載の方法。 Determining the second media complexity index of the second chunk can
Based on the metadata of the second chunk, the bit rate (R), frame rate (Fps), chroma coefficient (CF), frame width (W), or frame height (W) per pixel of the second chunk ( Including determining one or more of H)
The complexity measurement module further comprises a step of calculating a value (VCC) for the second media complexity index based on a mathematical expression with VCC = R / (W * H * Fps * CF).
The method according to claim 1.
前記マルチパスエンコーダが、制約された品質と制限されたビットレートを備える2パストランスコーダを備える、
請求項1に記載の方法。 The single-pass encoder is a single-pass transcoder equipped with a video buffering verifier.
The multipath encoder comprises a two-pass transcoder with constrained quality and a constrained bit rate.
The method according to claim 1.
請求項1に記載の方法。 The single pass encoder is implemented using a leaky bucket model.
The method according to claim 1.
前記第1のチャンクの前記第1のメディア複雑度指標を所定のしきい値と比較するステップと、
前記第1のメディア複雑度指標が所定のしきい値未満であることに応答して前記シングルパスエンコーダを選択するステップと
を備える、
請求項1に記載の方法。 The step of selecting the single pass encoder is
A step of comparing the first media complexity index of the first chunk with a predetermined threshold,
The first media complexity index comprises a step of selecting the single-pass encoder in response to being less than a predetermined threshold.
The method according to claim 1.
前記メディアアイテムを前記第1のチャンクおよび前記第2のチャンクを備える複数のチャンクにセグメント化するステップと、
エンコードされたメディアアイテムを形成するために、前記シングルパスエンコーダを使用してエンコードされた前記メディアアイテムの前記第1のチャンクと、前記マルチパスエンコーダを使用してエンコードされた前記メディアアイテムの前記第2のチャンクを組み合わせるステップと
をさらに備える、
請求項1に記載の方法。 The step of receiving the media item from the user device that captured and recorded the media item.
A step of segmenting the media item into a plurality of chunks having the first chunk and the second chunk,
The first chunk of the media item encoded using the single-pass encoder and the first chunk of the media item encoded using the multi-pass encoder to form an encoded media item. Further equipped with steps to combine 2 chunks,
The method according to claim 1.
前記メモリに動作可能に結合された前記処理デバイスと
を備えたシステムであって、前記処理デバイスが、請求項1から9のいずれか一項に記載の方法を実行するように構成される、
システム。 Memory and
A system comprising said processing device operably coupled to said memory, wherein the processing device is configured to perform the method of any one of claims 1-9.
system.
マシン可読記憶媒体。 The processing device stores an instruction for executing the method according to any one of claims 1 to 9.
Machine readable storage medium.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US15/600,272 | 2017-05-19 | ||
US15/600,272 US10771789B2 (en) | 2017-05-19 | 2017-05-19 | Complexity adaptive rate control |
PCT/US2018/018849 WO2018212816A1 (en) | 2017-05-19 | 2018-02-20 | Complexity adaptive single- vs. two-pass transcoding |
Publications (2)
Publication Number | Publication Date |
---|---|
JP2020521351A JP2020521351A (en) | 2020-07-16 |
JP6963631B2 true JP6963631B2 (en) | 2021-11-10 |
Family
ID=61563501
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
JP2019558785A Active JP6963631B2 (en) | 2017-05-19 | 2018-02-20 | Complex adaptive single-pass transcoding vs. two-pass transcoding |
Country Status (6)
Country | Link |
---|---|
US (1) | US10771789B2 (en) |
EP (1) | EP3596924A1 (en) |
JP (1) | JP6963631B2 (en) |
KR (1) | KR102316968B1 (en) |
CN (1) | CN110546953B (en) |
WO (1) | WO2018212816A1 (en) |
Families Citing this family (11)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10306250B2 (en) * | 2017-06-16 | 2019-05-28 | Oath Inc. | Video encoding with content adaptive resource allocation |
US11146608B2 (en) | 2017-07-20 | 2021-10-12 | Disney Enterprises, Inc. | Frame-accurate video seeking via web browsers |
US10652589B2 (en) * | 2017-12-08 | 2020-05-12 | Sling Media Pvt Ltd | Systems and methods for selecting an initial streaming bitrate |
US10728180B2 (en) * | 2018-08-21 | 2020-07-28 | At&T Intellectual Property I, L.P. | Apparatus, storage medium and method for adaptive bitrate streaming adaptation of variable bitrate encodings |
US10965945B2 (en) * | 2019-03-29 | 2021-03-30 | Bitmovin, Inc. | Optimized multipass encoding |
US11611784B2 (en) * | 2019-08-02 | 2023-03-21 | Dao Lab Limited | System and method for transferring large video files with reduced turnaround time |
CN110536168B (en) * | 2019-09-11 | 2021-09-17 | 北京达佳互联信息技术有限公司 | Video uploading method and device, electronic equipment and storage medium |
CN112969090A (en) * | 2019-12-03 | 2021-06-15 | 华为技术有限公司 | HTTP request transmission method and equipment |
CN111698262B (en) * | 2020-06-24 | 2021-07-16 | 北京达佳互联信息技术有限公司 | Bandwidth determination method, device, terminal and storage medium |
CN111757118B (en) | 2020-06-29 | 2023-04-21 | 北京百度网讯科技有限公司 | Video transcoding processing method, device, equipment and medium |
KR102554917B1 (en) * | 2022-04-05 | 2023-07-11 | 한국교통대학교산학협력단 | Appratus for data comprresion based on multi-modal, and control method thereof |
Family Cites Families (30)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6654417B1 (en) | 1998-01-26 | 2003-11-25 | Stmicroelectronics Asia Pacific Pte. Ltd. | One-pass variable bit rate moving pictures encoding |
US20030023982A1 (en) * | 2001-05-18 | 2003-01-30 | Tsu-Chang Lee | Scalable video encoding/storage/distribution/decoding for symmetrical multiple video processors |
US6700935B2 (en) | 2002-02-08 | 2004-03-02 | Sony Electronics, Inc. | Stream based bitrate transcoder for MPEG coded video |
US8054880B2 (en) * | 2004-12-10 | 2011-11-08 | Tut Systems, Inc. | Parallel rate control for digital video encoder with multi-processor architecture and picture-based look-ahead window |
US20040120398A1 (en) * | 2002-12-19 | 2004-06-24 | Ximin Zhang | System and method for adaptive field and frame video encoding using rate-distortion characteristics |
US7330509B2 (en) | 2003-09-12 | 2008-02-12 | International Business Machines Corporation | Method for video transcoding with adaptive frame rate control |
US7746927B1 (en) * | 2004-03-26 | 2010-06-29 | Apple Inc. | Robust single-pass variable bit rate encoding |
US20050232497A1 (en) | 2004-04-15 | 2005-10-20 | Microsoft Corporation | High-fidelity transcoding |
US7474701B2 (en) * | 2004-09-23 | 2009-01-06 | International Business Machines Corporation | Single pass variable bit rate control strategy and encoder for processing a video frame of a sequence of video frames |
US20060114995A1 (en) * | 2004-12-01 | 2006-06-01 | Joshua Robey | Method and system for high speed video encoding using parallel encoders |
CN101253777A (en) * | 2005-07-01 | 2008-08-27 | 极速决件公司 | Method, apparatus and system for use in multimedia signal encoding |
US8238424B2 (en) | 2007-02-09 | 2012-08-07 | Microsoft Corporation | Complexity-based adaptive preprocessing for multiple-pass video compression |
WO2009045683A1 (en) * | 2007-09-28 | 2009-04-09 | Athanasios Leontaris | Video compression and tranmission techniques |
US8588296B2 (en) | 2009-07-02 | 2013-11-19 | Dialogic Corporation | Bitrate control algorithm for video transcoding systems |
EP2285111A1 (en) | 2009-08-07 | 2011-02-16 | Canon Kabushiki Kaisha | Method for sending compressed data representing a digital image and corresponding device |
US8705623B2 (en) | 2009-10-02 | 2014-04-22 | Texas Instruments Incorporated | Line-based compression for digital image data |
US8767825B1 (en) | 2009-11-30 | 2014-07-01 | Google Inc. | Content-based adaptive video transcoding framework |
GB2471056B (en) * | 2010-03-09 | 2011-02-16 | Quantum Corp | Controlling configurable variable data reduction |
CN101854531B (en) * | 2010-05-24 | 2013-07-31 | 镇江唐桥微电子有限公司 | Multi-channel video unicode rate control method |
US20110299588A1 (en) * | 2010-06-04 | 2011-12-08 | Apple Inc. | Rate control in video communication via virtual transmission buffer |
US9338467B1 (en) | 2010-07-19 | 2016-05-10 | Google Inc. | Parallel video transcoding |
US8837601B2 (en) * | 2010-12-10 | 2014-09-16 | Netflix, Inc. | Parallel video encoding based on complexity analysis |
US10085023B2 (en) * | 2011-10-05 | 2018-09-25 | Texas Instruments Incorporated | Systems and methods for quantization of video content |
US8934538B2 (en) | 2011-10-17 | 2015-01-13 | Google Inc. | Rate-distortion-complexity optimization of video encoding |
US20130287361A1 (en) * | 2012-02-02 | 2013-10-31 | MOG Technologies S.A. | Methods for storage and access of video data while recording |
WO2014011848A2 (en) * | 2012-07-12 | 2014-01-16 | Huawei Technologies Co., Ltd. | Signaling and processing content with variable bitrates for adaptive streaming |
WO2014190308A1 (en) * | 2013-05-24 | 2014-11-27 | Sonic Ip, Inc. | Systems and methods of encoding multiple video streams with adaptive quantization for adaptive bitrate streaming |
US9749642B2 (en) * | 2014-01-08 | 2017-08-29 | Microsoft Technology Licensing, Llc | Selection of motion vector precision |
US9564136B2 (en) * | 2014-03-06 | 2017-02-07 | Dts, Inc. | Post-encoding bitrate reduction of multiple object audio |
US10063866B2 (en) * | 2015-01-07 | 2018-08-28 | Texas Instruments Incorporated | Multi-pass video encoding |
-
2017
- 2017-05-19 US US15/600,272 patent/US10771789B2/en active Active
-
2018
- 2018-02-20 EP EP18708822.4A patent/EP3596924A1/en active Pending
- 2018-02-20 JP JP2019558785A patent/JP6963631B2/en active Active
- 2018-02-20 CN CN201880026562.XA patent/CN110546953B/en active Active
- 2018-02-20 WO PCT/US2018/018849 patent/WO2018212816A1/en unknown
- 2018-02-20 KR KR1020197031997A patent/KR102316968B1/en active IP Right Grant
Also Published As
Publication number | Publication date |
---|---|
US20180338146A1 (en) | 2018-11-22 |
CN110546953B (en) | 2023-09-22 |
EP3596924A1 (en) | 2020-01-22 |
KR102316968B1 (en) | 2021-10-25 |
JP2020521351A (en) | 2020-07-16 |
WO2018212816A1 (en) | 2018-11-22 |
CN110546953A (en) | 2019-12-06 |
KR20190133745A (en) | 2019-12-03 |
US10771789B2 (en) | 2020-09-08 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
JP6963631B2 (en) | Complex adaptive single-pass transcoding vs. two-pass transcoding | |
US9800883B2 (en) | Parallel video transcoding | |
US9510028B2 (en) | Adaptive video transcoding based on parallel chunked log analysis | |
US20220030244A1 (en) | Content adaptation for streaming | |
US10454987B2 (en) | Bitrate optimization for multi-representation encoding using playback statistics | |
CN106537923B (en) | The technology of adaptive video stream | |
US20130104177A1 (en) | Distributed real-time video processing | |
WO2021147448A1 (en) | Video data processing method and apparatus, and storage medium | |
US20160134915A1 (en) | Adaptive bit rate system architectures using named domain networking | |
US10003626B2 (en) | Adaptive real-time transcoding method and streaming server therefor | |
US20150189222A1 (en) | Content-adaptive chunking for distributed transcoding | |
CN103733632A (en) | Dynamic bit rate adaptation over bandwidth varying connection | |
US11695978B2 (en) | Methods for generating video-and audience-specific encoding ladders with audio and video just-in-time transcoding | |
US20210266572A1 (en) | Optimized Multipass Encoding | |
KR101087194B1 (en) | Encoding System and Method of Moving Picture | |
Zabrovskiy et al. | ComplexCTTP: complexity class based transcoding time prediction for video sequences using artificial neural network | |
CA2889418A1 (en) | Video management based on changing scenes | |
WO2023207513A1 (en) | Video processing method and apparatus, and electronic device | |
US20220232275A1 (en) | Adaptive bitrate video testing from screen recording | |
JP5981803B2 (en) | Image quality evaluation apparatus, image quality evaluation method, and image quality evaluation program | |
Begen | Quality-aware HTTP adaptive streaming | |
US11818345B2 (en) | Bitrate-adaptive segmentation for video transcoding | |
Sangeetha et al. | A Survey on Performance Comparison of Video Coding Algorithms | |
Prakash et al. | Efficient Data usage and Savingwhile Streaming Video | |
Kim | Advanced Media Measuring Method Using MPEG-2 Transport Stream for High Quality Broadcasting Management System |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
A621 | Written request for application examination |
Free format text: JAPANESE INTERMEDIATE CODE: A621Effective date: 20191224 |
|
A977 | Report on retrieval |
Free format text: JAPANESE INTERMEDIATE CODE: A971007Effective date: 20210122 |
|
A131 | Notification of reasons for refusal |
Free format text: JAPANESE INTERMEDIATE CODE: A131Effective date: 20210201 |
|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20210428 |
|
A131 | Notification of reasons for refusal |
Free format text: JAPANESE INTERMEDIATE CODE: A131Effective date: 20210531 |
|
A521 | Request for written amendment filed |
Free format text: JAPANESE INTERMEDIATE CODE: A523Effective date: 20210825 |
|
TRDD | Decision of grant or rejection written | ||
A01 | Written decision to grant a patent or to grant a registration (utility model) |
Free format text: JAPANESE INTERMEDIATE CODE: A01Effective date: 20210921 |
|
A61 | First payment of annual fees (during grant procedure) |
Free format text: JAPANESE INTERMEDIATE CODE: A61Effective date: 20211015 |
|
R150 | Certificate of patent or registration of utility model |
Ref document number: 6963631Country of ref document: JPFree format text: JAPANESE INTERMEDIATE CODE: R150 |