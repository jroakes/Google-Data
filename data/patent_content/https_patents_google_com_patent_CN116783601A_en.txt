CN116783601A - Determining and/or mitigating an effective degree of reconstruction of predictions based on model updates transmitted in federal learning - Google Patents
Determining and/or mitigating an effective degree of reconstruction of predictions based on model updates transmitted in federal learning Download PDFInfo
- Publication number
- CN116783601A CN116783601A CN202180088371.8A CN202180088371A CN116783601A CN 116783601 A CN116783601 A CN 116783601A CN 202180088371 A CN202180088371 A CN 202180088371A CN 116783601 A CN116783601 A CN 116783601A
- Authority
- CN
- China
- Prior art keywords
- reconstruction
- model
- machine learning
- prediction
- generating
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
- 230000000116 mitigating effect Effects 0.000 title description 2
- 238000000034 method Methods 0.000 claims abstract description 166
- 238000010801 machine learning Methods 0.000 claims abstract description 124
- 239000011159 matrix material Substances 0.000 claims description 70
- 238000012549 training Methods 0.000 claims description 23
- 238000000926 separation method Methods 0.000 claims description 21
- 230000004044 response Effects 0.000 claims description 18
- 238000012545 processing Methods 0.000 claims description 13
- 230000004048 modification Effects 0.000 claims description 11
- 238000012986 modification Methods 0.000 claims description 11
- 238000013507 mapping Methods 0.000 claims description 7
- 230000003044 adaptive effect Effects 0.000 claims description 3
- 238000005457 optimization Methods 0.000 claims description 3
- 238000004590 computer program Methods 0.000 claims 1
- 238000005259 measurement Methods 0.000 description 13
- 238000009826 distribution Methods 0.000 description 7
- 230000008569 process Effects 0.000 description 7
- 230000015654 memory Effects 0.000 description 6
- 239000013598 vector Substances 0.000 description 6
- 230000005540 biological transmission Effects 0.000 description 5
- 238000000354 decomposition reaction Methods 0.000 description 4
- 230000000007 visual effect Effects 0.000 description 4
- 238000004891 communication Methods 0.000 description 3
- 230000002441 reversible effect Effects 0.000 description 3
- 238000013145 classification model Methods 0.000 description 2
- 238000013136 deep learning model Methods 0.000 description 2
- 238000005516 engineering process Methods 0.000 description 2
- 239000012634 fragment Substances 0.000 description 2
- 230000006870 function Effects 0.000 description 2
- 230000007246 mechanism Effects 0.000 description 2
- 230000003287 optical effect Effects 0.000 description 2
- 230000003071 parasitic effect Effects 0.000 description 2
- 230000002093 peripheral effect Effects 0.000 description 2
- 238000009877 rendering Methods 0.000 description 2
- 238000012216 screening Methods 0.000 description 2
- 230000003190 augmentative effect Effects 0.000 description 1
- 238000010586 diagram Methods 0.000 description 1
- 230000004069 differentiation Effects 0.000 description 1
- 230000000694 effects Effects 0.000 description 1
- 239000011521 glass Substances 0.000 description 1
- 239000004973 liquid crystal related substance Substances 0.000 description 1
- 230000002085 persistent effect Effects 0.000 description 1
Abstract
Embodiments relate to determining how efficiently predictions generated using a machine learning model can be reconstructed from model updates generated based on those predictions and based on applying specific loss techniques (e.g., specific cross entropy loss techniques). Some disclosed embodiments generate metrics that each indicate a degree of coincidence between a corresponding reconstruction generated using a corresponding model update and a corresponding prediction. In some of those embodiments, the metrics are used to determine whether to utilize the particular loss technique (for generating model updates) in federal learning of the machine learning model and/or additional machine learning models.
Description
Background
Federal learning of Machine Learning (ML) models is an increasingly popular ML technique for training ML models. In federal learning, the ML model on the device is stored locally on the user's client device, and the global ML model, i.e., the cloud-based counterpart of the ML model on the device, is stored remotely at a remote system (e.g., a server cluster). A client device using the on-device ML model may process input detected at the client device to generate a prediction, and may compare the prediction to a true value output to generate a client gradient. Further, the client device may transmit client model updates based on the client gradient to the remote system. For example, the client model update may be a client gradient, or may be based on the client gradient and additionally generated client gradients. For example, the client model updates may be generated from a very small batch of client gradients (e.g., 1 step, N samples), from client gradients over several steps (e.g., N steps, 1 sample each), or more generally, based on gradients from K steps with N samples at each step. The remote system may utilize the client model updates and optionally additional client model updates generated in a similar manner on additional client devices to update the weights of the global ML model. The remote system may transmit the global ML model or updated weights of the global ML model to the client device and/or other client devices. Each client device may then replace the on-device ML model with the global ML model or replace the weights of the on-device ML model with the updated weights of the global ML model, thereby updating the on-device ML model.
Thus, federal learning enables client devices to transmit locally generated model updates without transmitting underlying data (i.e., without transmitting corresponding inputs, predictions, or true value outputs) used to generate the model updates. In addition, the remote system can utilize model updates to efficiently update the global ML model without accessing or utilizing the underlying data. In these and other ways, federal learning may provide a degree of data security by eliminating the need to transmit underlying (and potentially sensitive) data, but instead transmitting only model updates generated based on such data. However, to ensure data security and/or increase the degree of data security, it is important that at least some (e.g., all, more than half, etc.) of the generated model updates cannot be reverse engineered to reveal information about the underlying data used to generate the model updates (e.g., reveal inputs, predictions, and/or true value outputs).
Disclosure of Invention
Embodiments disclosed herein relate to various techniques for determining how much predictions generated using machine learning models can be effectively reconstructed from model updates generated based on those predictions and based on applying specific loss techniques (e.g., specific cross entropy loss techniques). For simplicity, some examples described herein will be described with respect to model updating of a single gradient. However, as described herein, embodiments disclosed herein may be utilized in conjunction with model updates based on multiple gradients.
As an example, the predictions may each be a probability distribution or a sequence of probability distributions, and the gradients may each be generated based on applying a cross entropy based loss technique, from the predictions, and from the corresponding true-valued independent heat vectors (when the predictions are probability distributions) or the corresponding sequence of true-valued independent heat vectors (when the predictions are probability distribution sequences). Continuing with the example, a corresponding reconstruction for each of the predictions may be generated using matrix factorization of the gradients and using known lexical of the projection output layers of the machine learning model. More generally, a matrix factorization of model updates may be used and a corresponding reconstruction of each model update generated using a known vocabulary of projection output layers.
In some implementations, each reconstruction of the model update can include, for example: vocabulary rebuild packages (e.g., word rebuild packages when the vocabulary elements include words or word fragments) rebuild the vocabulary elements used to generate predictions of model updates, but not necessarily their order. Such reconstructions may each be generated using model updates and known lexicons without any reference to the corresponding current weights of the machine learning model and/or without reference to any other features in generating the corresponding predictions. In some embodiments, each reconstruction may additionally or alternatively include an ordered sequence reconstruction. In some of those embodiments, the ordered sequence reconstruction may be generated using a language model (or other model that specifies probabilities of various sequences of lexical elements) and optionally without reference to corresponding current weights of the machine learning model. For example, a language model may be utilized to determine which of a plurality of candidate ordered sequences of the lexical reconstruction package is most likely and use that candidate ordered sequence as the ordered sequence reconstruction. As another example, the ordered sequence reconstruction may be generated based on the vocabulary reconstruction package and further based on the corresponding current weights of the model learning when the corresponding prediction opportunity is generated. Optionally, in such examples, gradient matching reconstruction techniques and/or other reconstruction techniques that rely on the corresponding current weights may be used to generate the ordered sequence reconstruction. It should be noted, however, that such reconstruction techniques may be used with search spaces that are constrained according to (e.g., constrained to) lexical reconstruction packages. This may enable such reconstruction techniques to be performed more efficiently (i.e., with less processor resources) and/or more accurately (i.e., by constraining the search space to the lexically reconstructed parsing packages).
Some embodiments disclosed herein generate metrics that each indicate a degree of coincidence between a corresponding reconstruction generated using a corresponding model update and a corresponding prediction. Metrics collectively reflect how efficiently predictions can be generated from model updates generated using a particular loss technique. Thus, the metrics and/or overall metrics generated based on the metrics may be indicative of the degree of data security provided by gradients generated using particular loss techniques.
In some of those embodiments, the metrics are used to determine whether to utilize the particular loss technique (for generating gradients) in federal learning of the machine learning model and/or the additional machine learning model. For example, the metric and/or the overall metric generated based on the metric may be compared to a threshold and a particular loss technique utilized in federal learning only when the metric and/or the overall metric meets the threshold. As an additional example, metrics and/or overall metrics generated based on model updates generated with a particular loss technique may additionally or alternatively be compared to surrogate metrics and/or surrogate overall metrics each generated based on model updates generated with a corresponding surrogate particular loss technique. In such additional examples, a particular loss technique may be utilized only when the comparison indicates that the particular loss technique provides a greater degree of data security than an alternative particular loss technique. For example, a particular loss technique may be cross entropy loss with sign gradient descent, a replacement loss technique may be cross entropy loss with adaptive federal optimization, a parasitic replacement loss may be cross entropy loss with gradient sparseness, and a further parasitic replacement loss technique may be cross entropy loss without any gradient modification technique. A particular loss technique may be utilized only when its metric is more indicative of data security than the metrics of the replacement loss technique, the metrics of the additional replacement loss technique, and the metrics of the further additional loss technique. In these ways and others, a degree of data security provided by gradients generated using a particular loss technique may be ensured before utilizing the particular loss technique in federal learning. This may mitigate the occurrence of potentially evil actors that can effectively reconstruct the intercepted model updates and/or may prevent those actors from being able to distinguish between valid and invalid reconstructions of the intercepted model updates.
In some additional or alternative implementations, a request transmitted by a computing device may be received over one or more networks, and the request may include a model update, prediction pair. Model updates to pairs may each be generated based on predictions of pairs and based on application specific penalty techniques. In those embodiments, the reconstruction of each pair may be generated based on a model update of the pair, and a metric indicative of the degree of coincidence between the reconstruction of the pair and the prediction is then generated. The metrics may reflect how effectively the reconstruction meets the prediction (e.g., whether and/or to what extent). For example, if the reconstruction is a lexical reconstruction packet, the metrics may include: a metric indicating whether the lexical reconstruction packet includes all elements of the prediction but not any additional elements not in the prediction; and/or a metric indicating a number of elements that differ between the lexical reconstruction packet and the prediction (e.g., a number of elements that are in reconstruction but not in prediction and a number of elements that are in prediction but not in reconstruction). As another example, if the reconstruction is an ordered sequence reconstruction, the metrics may include: a metric indicating whether the reconstruction includes all elements of the prediction and in the order of the prediction and does not include any additional elements not in the prediction; and/or a metric indicating the degree of difference between the reconstruction and the prediction, if any (e.g., an edit distance-based metric or other metric reflecting the difference in elements and/or order between the reconstruction and the prediction). The generated metrics and/or overall metrics generated based on the metrics may be transmitted to the computing device in response to the request. In response to the transmission, the computing device may utilize the metrics and/or overall metrics in automatically determining whether to utilize a particular loss technique in federal learning and/or other machine learning model training. The transmission may additionally or alternatively cause the metrics and/or overall metrics to be rendered (e.g., visually rendered) at the computing device. This may enable a user of the computing device to determine (e.g., by looking at the visual rendering) a degree of data security provided by the gradient and determine whether to utilize a particular loss technique in federal learning and/or other machine learning model training based on the degree. In these ways and others, a degree of data security provided by gradients generated using a particular loss technique may be ensured prior to utilizing the particular loss technique in machine learning model training.
In various embodiments, the machine learning model is a model that includes a projection input layer, a weight matrix layer, and a projection output layer. The projection input layer may accept as input the lower dimensional generated embeddings and the weight matrix layer may be used to process the generated embeddings using the current weights of the weight matrix layer to generate the corresponding projection outputs of the projection output layer. The projection output layer has a vocabulary size that conforms to the machine learning model. In other words, the number of output nodes of the projected output layer may correspond to the vocabulary size, and each node will correspond to a particular discrete element of the vocabulary. The output generated at the projection output layer may be, for example, a lexical probability distribution. When an input sequence is applied to the projection input layer, an output sequence may be generated at the projection output layer and will have a size that matches the vocabulary and the length of the input sequence.
As one example, when the machine learning model is an automatic speech recognition model (e.g., an listen-see-spell LAS model), the projection input layer and sequence may be provided with an audio data embedding sequence of S x d dimensions (where S is the number of audio data embeddings and d is each embedded dimension), and the projection output may be an output sequence collectively having a length S x V, where V is the vocabulary size. In such examples, the elements of the vocabulary may be words or word fragments.
As another example, when the machine learning model is an image classification model, the embedding provided as input to the projection input layer may be image embedding of an image of dimension d (where d is the dimension of the embedding), and the projection output may have a length V, where V is the vocabulary size. In such an example, the elements of the vocabulary may be classifications. Additional and/or alternative machine learning models may be utilized that may include different vocabularies and/or may accept different types of embeddings as inputs.
Thus, various embodiments set forth techniques for ensuring that a particular loss technique utilized in federal learning imparts at least some degree of security, and may be used to ensure that a particular degree of security is imparted prior to utilizing a particular loss technique in federal learning of a particular machine learning model. In these and other ways, security of data may be enhanced for various client devices participating in federal learning. This may enable the benefits of federal learning to be achieved while ensuring a certain degree of safety.
The foregoing description is provided merely as an overview of some of the embodiments disclosed herein. These and other embodiments of the technology will be disclosed in more detail below.
It should be appreciated that all combinations of the foregoing concepts and additional concepts described in more detail herein are considered a part of the subject matter disclosed herein. For example, all combinations of claimed subject matter appearing at the end of this disclosure are considered part of the subject matter disclosed herein.
Drawings
FIG. 1 illustrates an example environment in which embodiments described herein may be implemented.
FIG. 2 is a flow chart illustrating an example method, the method comprising: generating, with the corresponding model update, a corresponding reconstruction of the corresponding prediction utilized in generating the corresponding model update; determining a metric based on comparing the corresponding reconstruction with the corresponding model update; and optionally performing one or more further actions based on the determined metrics.
FIG. 3 is a flow chart illustrating an example method of generating a predictive reconstruction using matrix factorization of corresponding gradients and using known vocabulary of projection outputs of a machine learning model utilized in generating predictions.
Fig. 4 shows an example of a projection layer of a machine learning model.
Fig. 5 shows an example of a reversible matrix, an orthogonal matrix generated based on decomposing the gradient, and a result matrix according to performing cross-product of the reversible matrix and the orthogonal matrix.
FIG. 6 schematically depicts an example architecture of a computer system.
Detailed Description
Before turning to the figures, a non-limiting overview of some embodiments of generating a reconstruction using the generated model updates is presented. Many deep learning models, such as classification models, include a fully connected layer to map d-dimensional representations extracted from input h to a C-dimensional vector z. The vector z represents the non-normalized logarithmic probability of its class, while C is the number of classes. The fully attached layers are herein
Is referred to as the projection layer. All classesThe probability distribution is by the pair +.>Derived using the softmax function. Training such models typically involves minimizing cross entropy loss, as exemplified by +.>As indicated.
Let W and b denote the weight and bias of the projection layer, respectively. Because z=wh+b, this results inFurther assume thatWith these assumptions, the model update of the projection layer can be represented by equation (1):
equation (1) applies to the losses calculated from a single sample with a single tag. Because introducing a new tag means adding a new term to the penalty, equation (1) can be generalized to various settings. For example, model updates for a very small batch of N samples or a sequence of length N are averaged from model updates calculated from each sample in the batch or each tag in the sequence. In such a scenario, equation (1) may be summarized by equation (2):
In the equation (2) for the case of the optical disc,and g= [ G ] 1 ，...，g N ]。
As another example, the model update after K steps is the sum of the model updates at each of the K steps. In such a scenario, equation (1) may be summarized by equation (3):
in equation (3), ΔW (i) And alpha i The softmax gradient and learning rate at time step i, h= [ α ], respectively 1 H (1) ，...，α K H (K) ]And g= [ G (1) ，...，G (K) ]。
In all these scenarios Δw may be represented as two low rank matricesAnd->Where S is the number of terms used to calculate the model update aw. For example, if the model update is calculated from a batch, then S is the batch size. As another example, if the model updates are aggregated according to several step updates, S is the total number of samples for these steps.
In many embodiments, both d and C are on the order of thousands in a large-scale deep learning model. Thus, in those embodiments, S < min { d, C } may be assumed. Since H and G are typically full rank matrices and their rows and columns do not have a linear dependency, this number S can be deduced from the rank of the weight matrix update, i.e. s=rank (Δw). Thus, the entity seeking to reconstruct the predictions based on model updates may already know the number of tags (including duplicates) from the knowledge of Δw. This is particularly helpful, for example, when Δw is calculated from the sequence of the tag. In this case, the length of the sequence will be revealed immediately to the entity that has access to aw.
At projection layer z and true value labelThe softmax cross entropy penalty is defined on the output of (a). Relative to z pair->Differentiation is carried out to obtain:
because the softmax function always returns the value in (0, 1), each row in G has a unique negative coordinate corresponding to the true value tag. Formally, we set the index of the negative coordinates in Neg (u) bounding vector u. Each row G in G i Meets Neg (g) i )＝{y i }. This observation is intuitive because to minimize the loss, the probability of a true value tag should be pushed to 1, while the probability of other tags should be pushed to 0. This observation implies that the tag can be revealed based on information about G.
Using Singular Value Decomposition (SVD), aw can be decomposed into P Σq, whereAnd->Is an orthogonal matrix, and->Is a diagonal matrix with non-negative elements on the diagonal.
Assume that there is a sample with label c. Presence vectorSo that rq c < 0 and rq j≠c > 0, or Neg (rq) = { c }. In other words, subspace rx=0 will be the point q in the S-dimensional space c With other points q j≠c And (5) separating.
If tag c appears in the batch, then for part i, y i =c, or Neg (g i ) = { c }. If r=g i Q T rQ=g i Or Neg (rQ) = { c }. This means that if tag c occurs in the batch, there is a linear classifier with no bias that will q c And q j≠c And (5) separating. The problem of finding a perfect classifier can be solved via linear programming. If present will q c And q j≠c Separate classifiers, the following problem has a solution.
s.t.rq c ≤0
In practice, solving LP (c) for each c may take time because the number of words in the vocabulary may be large. In view of the observation that many columns in Q are obviously inseparable, a screening loop may be applied to filter the inseparable columns. Considering each column in Q as a data point in S-dimensional space, the screening round returns all points that can be separated from the sampled subset of remaining points (e.g., using a perceptron algorithm). This may be significantly faster and/or more computationally efficient than solving the LP problem.
The following algorithm provides an overview of some embodiments of obtaining a set of tags (i.e., a vocabulary package) from a model update.
Input：Model update of the projection layer(input: projection layer)Model update of (c)
N←rank(ΔW)
Findthe right singular matrix of DeltaW (find->Right singular matrix of (c)
for i=1 to cdo (for i=1 to C, proceed)
if LP (i) has a solution then (if LP (i) has a solution)
Add label i into S (adding tag i to S)
end if (end if)
end for (end for)
Return: number of labels used to compute the update S set of labels S (return: updated number of labels S for calculating set of labels S)
Turning now to the drawings, FIG. 1 illustrates an example environment in which embodiments described herein may be implemented. The example environment includes client devices 106A-106N, a federal learning system 110, a reconstruction system 120, and one or more networks 108. Client devices 106A-106N, federal learning system 110, and/or rebuild system 120 may communicate with each other via network 108. The network 108 may include a Wide Area Network (WAN) (e.g., the internet) and/or a Local Area Network (LAN).
Client devices 106A-106N may include client devices via which a user may interact with reconstruction system 120, which may be located remotely from the client devices (in other implementations, reconstruction system 120 may be implemented in whole or in part on the client devices). For example, a user may interact with client device 108A (via a user interface input device of client device 108A) to cause the client device to transmit model update, prediction pairs to reconstruction system 120. In response to such transmissions, the reconstruction system 120 can generate metrics based on the transmitted pairs and then transmit the metrics to the client device 108A. In response to receiving the metrics, the client device 108A may utilize the metrics and/or overall metrics to automatically determine whether to utilize a particular loss technique in federal learning and/or other machine learning model training. In response to receiving the metrics, the client device 108A may additionally or alternatively cause the metrics and/or overall metrics to be rendered (e.g., visually rendered) at the client device 108A. This may enable a user of the client device 108A to determine a degree of data security provided by the gradient (e.g., by viewing a visual rendering via a screen of the client device 108A) and determine whether to utilize a particular loss technique in federal learning and/or other machine learning model training based on the degree.
As another example, a user may interact with client device 108A (via a user interface input device of client device 108A) to cause the client device to transmit model updates to reconstruction system 120. In response to such a transmission, the reconstruction system 120 may generate reconstructions that each correspond to one of the transmitted model updates, and then transmit an indication to the client device 108A of the reconstructions and which reconstructions correspond to which model updates. In response to receiving the rebuilds and an indication of which rebuilds correspond to which model updates, client device 108A may generate metrics and/or overall metrics based on comparing the rebuilds to actual predictions stored locally at client device 108A or otherwise accessible at client device 108A. Client device 108A may match the received reconstruction with the corresponding prediction based on an indication of which of the received reconstructions correspond to which model updates (e.g., using a locally stored mapping of model updates to predictions). Thus, in such an example, client device 108A transmits only model updates to reconstruction system 120, and does not transmit predictions. Further, the reconstruction system 120 returns a reconstruction generated based on the model update, thereby enabling the client device 108A to generate metrics based on the returned reconstruction.
The client devices 106A-106N may additionally or alternatively include client devices that interact with the federal learning system 110 in federal learning that participates in a global Machine Learning (ML) model 118. For example, each of the client devices 106A-106N is shown to include a corresponding one of the local ML models 108A-108N stored locally at the client device. The local ML models 108A-108N are each local correspondences of the global ML model 118 managed by the federal learning system 110.
In participating in federal learning, each of the client devices 106A-106N, using a corresponding one of its on-device ML models 108A-108N, may process corresponding inputs (e.g., based on user interface inputs detected at the client device and/or based on corresponding locally stored data inputs at the client device) to generate predictions, and may compare the predictions to the true value outputs to generate client gradients. For example, a cross entropy based loss technique may be used to generate client gradients. The true value output may be based on other data generated locally at the client device, and possibly optionally based on user input (e.g., explicitly or implicitly confirming the prediction, or explicitly or implicitly indicating a substitute true value that is different from the prediction). Further, the client devices 106A-106N may transmit model updates based on their locally generated client gradients to the federal learning system 110. It should be noted that model updates may be transmitted to federal learning system 110 without transmitting predicted or actual value outputs utilized in generating the model updates.
Federal learning system 110 can utilize the received client model updates, and optionally additional client model updates generated in a similar manner at additional client devices, to update the weights of global ML model 118. Federal learning system 110 can transmit updated global ML models 118, or updated weights of global ML models 118, to client devices 108A-108N and/or other client devices. Each client device may then replace the ML model on the device with the updated global ML model or replace the weights of the ML model on the device with the updated weights of the global ML model 118, thereby updating the ML model on the device. Further federal learning may optionally occur based on updated on-device ML models, resulting in a further updated global ML model 118, all of which may likewise be provided (or weighted) by client devices 106A-106N. The process may continue for a number of iterations, optionally until the ML model is deemed final based on the one or more conditions being met. The federal learning system 110 can be implemented, for example, by one or more servers, such as a cluster of optional distributed high performance servers.
Client devices 106A-106N may include one or more of the following: a desktop computing device, a laptop computing device, a standalone hardware device dedicated at least in part to an automated assistant, a tablet computing device, a mobile phone computing device, a computing device of a vehicle (e.g., an in-vehicle communication system and an in-vehicle entertainment system, an in-vehicle navigation system), or a wearable apparatus that includes a user of the computing device (e.g., a watch of a user with the computing device, glasses of a user with the computing device, a virtual or augmented reality computing device). Additional and/or alternative client devices may be provided. The client devices 106A-106N may each include one or more memories for storing data and software applications, one or more processors for accessing data and executing applications, and other components that facilitate communication over a network.
The reconstruction system 120 may be implemented, for example, by a client device and/or by one or more servers, such as an optional distributed high performance server cluster. The reconstruction system 120 is shown in fig. 1 as including a reconstruction engine 122, a measurement engine 124, and a selection engine 126.
The reconstruction engine 122 processes the model updates 134 and generates a corresponding reconstruction for each of the model updates 134. Model updates 134 processed at a given time may be provided by one of client device 106A, federal learning system 110, or even generated locally by reconstruction system 120. Further, as described herein, the model updates 134 may optionally each be paired with a corresponding one of the predictions 136 (e.g., via a map defining an association between the corresponding model update and the prediction).
In generating the reconstruction based on one of the model updates 134, the reconstruction engine 122 may use matrix factorization (factorization) of the model updates and use the known vocabulary 132 of the projection output layer of the corresponding ML model. For example, in the case of generating model updates based on one of the local ML models 108A-108N, the known vocabulary 132 of the projection output layers of the local ML models 108A-108N may be used to generate the reconstruction. In some implementations, the known vocabulary 132 is provided by a developer or other user with vocabulary knowledge of a machine learning model (e.g., in or with a request that includes a corresponding gradient). In some other implementations, the known vocabulary 132 is determined from an examination of the machine learning model and/or from providing a plurality of known inputs to the machine learning model and examining corresponding predictions and/or model updates. Providing a plurality of known inputs to the machine learning model and detecting corresponding predictions and/or model updates enables resolution of which output dimensions correspond to which elements of the vocabulary. For example, because the predictions that should be generated from known inputs are also known, it may be determined from predictions and/or model updates which output dimensions correspond to elements of the predicted vocabulary. By utilizing a plurality of known inputs and corresponding known predictions, some or all of the vocabulary may be efficiently derived by analyzing the actually generated predictions and/or model updates.
In some implementations, the reconstruction engine 122 generates a reconstruction that includes or is limited to lexical reconstruction packets that reconstruct the predicted lexical elements, but not necessarily their order. In other words, the reconstruction seeks to reconstruct the predicted lexical elements regardless of their order. While the rebuild may happen to include lexical elements in the correct order, the rebuild does not seek to determine the correct order. Such reconstructions may each be generated by the reconstruction engine 122 using model updates and known word exchanges and without any reference to the corresponding current weights of the machine learning model and/or without reference to any other features in generating the corresponding predictions. In some implementations, the reconstruction engine 122 may additionally or alternatively generate the reconstruction as an ordered sequence reconstruction. The reconstruction engine 122 may generate an ordered sequence reconstruction based on the lexical reconstruction package and further based on a language model (or more generally, a lexical model) and/or based on corresponding current weights of the machine learning model when the corresponding predictions are generated. In various embodiments, in generating the reconstruction, the reconstruction engine 122 performs some or all aspects of step 256A of fig. 3 (described below).
The measurement engine 124 compares the reconstruction generated by the reconstruction engine with its corresponding prediction 136 and generates a metric based on the comparison. For example, the measurement engine may compare the generated reconstruction generated based on a given one of the model updates 134 with a given one of the predictions 136 indicated as paired with the given one of the model updates 134. A given one of the predictions 136 may be a prediction that is actually generated using the corresponding ML model and utilized in generating a given one of the model updates 134 (e.g., based on comparing the prediction to a true value output). The metrics generated by the measurement engine 124 for reconstruction may reflect how effectively the reconstruction meets the predictions (e.g., whether and/or to what extent). For example, if the reconstruction is a lexical reconstruction packet, the measurement engine 124 may generate a metric of "1.0" if the lexical reconstruction packet includes all elements of the prediction but not any additional elements not in the prediction, otherwise "0.0". As another example, if the reconstruction is a lexical reconstruction packet, the measurement engine 124 may additionally or alternatively generate a metric that is non-binary and reflects the number of elements that differ between the lexical reconstruction packet and the prediction. For example, if no elements are different, the metric may be "1.0", if one of the four elements is different, "0.75", if three of the six elements are different, "0.5", if all elements are different, "0.0", and so on. In addition, the measurement engine 124 may also optionally generate an overall metric that varies with the individual metrics of the reconstruction. For example, the overall metric may include an average value of the individual metrics, a median value of the individual metrics, a standard deviation of the individual metrics, and/or other overall metrics that vary with the individual metrics. In various embodiments, measurement engine 124 performs some or all aspects of step 258 of fig. 2 (described below) in generating the individual metrics.
The selection engine 126 analyzes metrics (e.g., individual and/or overall metrics) generated by the measurement engine 124 for model updates generated in accordance with particular loss techniques for determining whether to utilize the particular loss techniques (e.g., in federal learning of the corresponding machine learning model and/or additional machine learning models). Thus, in various embodiments, the selection engine 126 may determine whether to select a particular loss technique to use or to instead select an alternative loss technique to use.
In some implementations, the selection engine 126 compares individual metrics and/or overall metrics generated by the measurement engine 124 for model updates generated according to a particular loss technique to a threshold. In those embodiments, the selection engine 126 may determine whether to utilize the particular penalty technique based at least in part on (e.g., only locally and/or based on other considerations) whether the metric and/or the overall metric meets a threshold.
In some implementations, the selection engine 126 compares (a) individual metrics and/or overall metrics generated by the measurement engine 124 for model updates generated according to a particular loss technique with (b) alternative individual metrics and/or alternative overall metrics generated by the measurement engine 124 for alternative gradients generated according to alternative particular loss techniques. In those embodiments, the selection engine 126 may determine whether to select a particular loss technique or to instead select an alternative particular loss technique based on the comparison (e.g., based on the comparison alone or also based on the threshold being met as described in the previous paragraph). For example, measurement engine 124 may determine to select a particular loss technique to utilize only when the comparison indicates that the particular loss technique provides a greater degree of data security than the alternative particular loss technique. Although the former example is provided with respect to comparing the corresponding metrics of two different specific loss techniques, more than two specific loss techniques may be considered, and the comparison (and resulting selection) may consider all of the corresponding metrics. In various embodiments, selection engine 126 performs some or all aspects of step 262 of fig. 2 (described below).
Fig. 2 is a flow chart illustrating an example method 200, the method 200 comprising: generating a corresponding reconstruction of the corresponding prediction utilized in generating the corresponding gradient using the corresponding model update; determining a metric based on comparing the corresponding reconstruction with the corresponding prediction; and optionally performing one or more further actions based on the determined metrics. For convenience, the operations of the flowcharts are described with reference to systems performing the operations. The system may include various components of various computer systems, such as one or more components of the reconstruction system 120 of fig. 1. Furthermore, although the operations of process 200 are shown in a particular order, this is not meant to be limiting. One or more operations may be reordered, omitted, and/or added.
At block 252, the system receives model update, prediction pairs. Model update, prediction pairs each include: predictions generated based on processing corresponding inputs using a machine learning model; and model updates generated based on applying the particular loss technique and based on the corresponding real value inputs (e.g., generated based on gradients, each gradient generated based on comparing the corresponding real value input to the prediction). For example, the model update may be a single gradient generated based on comparing a single prediction to a pair of true values, or may be a model update generated based on comparing a batch of gradients generated from multiple predictions and their corresponding true values. The model update, prediction pair received at block 252 may be generated by and received from a component of the system, or may be in transmission and received from another system or client device via a network.
At block 254, the system identifies model updates, prediction pairs from those received at block 252.
At block 256, the system generates a predicted reconstruction using the model update of the identified pair and independent of the prediction of the identified pair. In some implementations, block 256 includes a sub-block 256A in which the system uses matrix factorization of model updates and uses known vocabulary of projection outputs of machine learning models to generate the reconstruction. One non-limiting specific example of block 256A is described below with respect to FIG. 3.
At block 258, the system generates a metric based on comparing the reconstruction of the pair by block 256 to the prediction of the pair. The system may store the metrics (e.g., in ROM or RAM).
At block 260, the system determines whether there are any unprocessed model update, prediction pairs. If so, the system returns to block 254 and identifies unprocessed pairs. If not, the system optionally proceeds to optional block 262 and/or optional block 264. It should be noted that while shown serially in fig. 2 for convenience, in various embodiments, the system may perform multiple iterations of blocks 254, 256, and 258 in parallel (i.e., each iteration performed in parallel would involve processing a different pair).
At optional block 262, the system determines whether to utilize the particular penalty technique in federal training based on metrics generated via multiple iterations of block 258 (e.g., retrieved from RAM or ROM). In some implementations, the system determines whether to utilize a particular penalty technique in federal training based on the metrics themselves and/or based on overall metrics generated via individual metrics generated by multiple iterations of block 258. In some implementations, the system determines to utilize the particular loss technique in federal training only when some (e.g., X% thereof) or all of the individual metrics meet the individual thresholds and/or only when some (e.g., X% thereof) or all of the overall metrics meet the corresponding overall thresholds. In some additional or alternative embodiments, the system determines whether to utilize a particular loss technique in federal training based on comparing individual metrics and/or overall metrics of the particular loss technique to one or more individual metrics and/or overall metrics of alternative particular loss techniques. Based on performing blocks 252, 254, 256, and 258, individual metrics and/or overall metrics may be generated that replace a particular loss technique based on pairs that include model updates generated using the replacement particular loss technique.
At optional block 264, the system transmits individual metrics generated via multiple iterations of block 258, and/or an overall metric generated based on the generated individual metrics, in response to receiving the pairs at block 252. For example, the pair at block 252 may be received in a request from a server or client device, and the system may transmit the individual metrics and/or the overall metrics to the server or client device. For example, the individual metrics and/or the overall metrics may be included in a graphical user interface generated by the system and transmitted to the client device. Transmitting the graphical user interface to the client device may cause the client device to visually render the individual metrics and/or the overall metrics (e.g., after corresponding user input at the client device).
FIG. 3 is a flow chart illustrating one non-limiting example of block 256A of FIG. 2.
At block 256A1, the system identifies a gradient. The gradient may be a model update from one of the pairs of fig. 2. Alternatively, the gradient may be generated based on applying a cross entropy based loss technique and based on the true value output and prediction. The predictions are predictions generated based on processing the input using a machine learning model.
At block 256A2, the system decomposes the gradient into at least one sχv orthogonal matrix (Q), where S corresponds to the number of sequences in the prediction and V corresponds to the vocabulary size of the machine learning model. Each column in the matrix Q may represent an S-dimensional point corresponding to an element in the vocabulary. In some implementations, the system can decompose the gradient into a quadrature matrix Q using singular value decomposition. For example, the system may use singular value decomposition to decompose the gradient into two orthogonal matrices Q and P (which may also be sχv matrices) and a diagonal matrix Σ.
At block 256A3, the system determines which columns in Q include a split classifier. Block 256A3 may include a sub-block 256A3A in which the system performs a dot product of Q and Z, where Z is an sx S invertible matrix, and based on the result, identifies a result column of Q that includes a separation value (e.g., a negative value). For example, at subframe 156A3A, the system may be in a matrix generated by the dot product of Q and ZA row including a separation value (e.g., a negative value) is identified, and a column of Q having the same index value as the row is identified. A row with a separation value in the result matrix will indicate that the corresponding column of Q also has a separation value.
As an example, and referring to fig. 5, an example Z invertible matrix 123A (of size s×s) is shown intersecting an example Q orthogonal matrix 123B (of size s×v), resulting in an example Matrix 123C (size s×v). />The second row (shown shaded) of matrix 123C is the result of the cross product of the second row (shown shaded) of Z-invertible matrix 123A and the second column (shown shaded) of Q-orthogonal matrix 123B. Furthermore, the->The second row of matrix 123C includes a separation value, indicated by the vertical shading of cells in the second row and second column (as opposed to the diagonal shading of other cells in the second row). Based on one of the cells being distinguishable with respect to all other cells of the row, it is possible to determine +.>The second row of matrix 123C has a separation value. For example, one of the cells of the second row may be negative, while all other cells of the row may be positive. This may indicate that the second column of Q-ary matrix 123B (having the same "second" index value) also has a separation value. Note that->Additional rows of matrix 123C may have separation values, and thus, additional columns of Q may be determined to have additional separation values. However, for simplicity, only one such example is shown in fig. 5. Further, it should be noted that for simplicity, matrices 123A, 123B and 123C only show themSome of the cells, as indicated by ellipses. A matrix of various dimensions may be provided and the dimensions will depend on the corresponding vocabulary size and sequence length, as described herein.
Turning again to fig. 3, at block 256A4, the system generates a predicted reconstruction using the Q columns determined to include separate classifiers and a mapping of the Q columns to the vocabulary of the machine learning model. In some implementations, the box 256A4 includes a sub-box 256A4A and optionally a sub-box 256A4B. At sub-block 256A4A, the system generates a vocabulary rebuild package that may include an unordered list of those elements of the vocabulary that correspond to the Q columns determined to include separate classifiers.
At sub-block 256A4B, the system optionally generates an ordered sequence reconstruction using the current state of the model and the lexical reconstruction package of sub-block 256A 4A. It should be noted that the current state of the model is not utilized when generating the lexical reconstruction package at subframe 256A 4A. In some implementations, at sub-block 256A4B, the system does not utilize the current state of the model, but rather relies on a lexical reconstruction package and lexical model specifying probabilities for various sequences of lexical elements. For example, where the vocabulary includes words or word sequences, the vocabulary model may be a language model. For example, the system may utilize a language model to determine which of a plurality of candidate ordered sequences of the lexical reconstruction package is most likely, and the candidate ordered sequence is used as the ordered sequence reconstruction. In some implementations, at sub-block 256A4B, the system generates an ordered sequence reconstruction based on the vocabulary reconstruction package and further based on the corresponding current weights of the machine learning model at the time the corresponding predictions were generated. Optionally, in those embodiments, the system uses gradient matching reconstruction techniques and/or other reconstruction techniques that rely on corresponding current weights for generating an ordered sequence reconstruction. However, the system uses such reconstruction techniques where the search space is constrained based on (e.g., constrained to) lexically reconstructed packets.
At block 256A5, the system stores the reconstruction generated at block 256A4, as well as an association of the reconstruction with the gradients utilized in generating the reconstruction.
Can be based onThis knowledge motivates the example implementation of block 256A shown in fig. 3. In the former equation, +.>Representing a gradient with respect to a weight matrix (W) of the corresponding projection layer. In addition, A T Representing the transpose of the projection input (i.e., the dimension of the embedding and the length of the embedded sequence). Finally, let(s)>Representing the gradient relative to the projection output, which gradient is unknown but can be solved as described herein. By putting->Decomposition into P ΣQ, which can be written as P Σ (Z) -1 Z) Q, where Z is any sxs invertible matrix, and is further rewritten as (pΣz) -1 ) (ZQ). As previously described, (P ΣZ) -1 ) Equivalent to A T Meaning +.>Equal to (ZQ), and therefore, can be solved by the cross product of Z and Q>Furthermore, the->A row that includes a separation value (e.g., a negative value) will indicate that the Q column that has the same index value as that row also has a separation value. This indicates that the element corresponding to column Q in the vocabulary is included for generating the gradient +.>In the prediction of (3). By identifying Q columns with separate values and mapping those columns to elements of the known vocabulary for Q, a vocabulary reconstruction package can be generated. It should be noted that such a general purpose The technique is still applicable to multi-sample/batch gradients and/or multi-step gradients. In both cases ΔW is a number of updates ΔW i And matrix factorization remains effective (e.g., the sum of products remains a product).
Fig. 4 shows an example of a projection layer of a machine learning model, such as global model 118 (fig. 1) and local models 108A-108N (fig. 1). The projection layers include a projection input layer 118A, a weight matrix layer 118B, and a projection output layer 118C. The projection input layer 118A may accept as input the lower dimension generated embeddings (dimension d) and the weight matrix layer 118B may be used to process the generated embeddings using the current weights of the weight matrix layer 118B to generate the corresponding projection output (dimension V) of the projection output layer 118C. The projection output layer 118C has a vocabulary size (V) that conforms to the machine learning model. In other words, the number of output nodes of the projected output layer 118C may conform to the vocabulary size, and each node will correspond to a particular discrete element of the vocabulary. The output generated at the projection output layer 118C may be, for example, a lexical probability distribution. When an input sequence of length S (indicated by "S" in "Sxd" in FIG. 4) is applied to the projection input layer 118A, an output sequence of length S (indicated by "S" in "SxV" in FIG. 4) may be generated on the projection output layer 118C, and the output sequence will have a size that conforms to the vocabulary and the length of the input sequence.
FIG. 6 is a block diagram of an example computing device 610, which computing device 610 may optionally be used to perform one or more aspects of the techniques described herein. For example, a client device may include one or more aspects of an example computing device 610, and/or a server may include one or more aspects of an example computing device 610. The computing device 610 typically includes at least one processor 614, the at least one processor 614 communicating with a plurality of peripheral devices via a bus subsystem 612. These peripheral devices may include storage subsystems 624 including, for example, a memory subsystem 625 and a file storage subsystem 626, user interface output devices 620, user interface input devices 622, and network interface subsystem 616. Input and output devices allow users to interact with computing device 610. Network interface subsystem 616 provides an interface to external networks, and is coupled to corresponding interface devices among other computing devices.
The user interface input device 622 may include: a keyboard, a pointing device such as a mouse, trackball, touch pad, or tablet, a scanner, a touch screen incorporated into the display, an audio input device such as a voice recognition system, a microphone, and/or other types of input devices. In general, use of the term "input device" is intended to include all possible types of devices and ways of inputting information into computing device 610 or onto a communication network.
The user interface output device 620 may include a display subsystem, a printer, a facsimile machine, or a non-visual display, such as an audio output device. The display subsystem may include a Cathode Ray Tube (CRT), a flat panel device such as a Liquid Crystal Display (LCD), a projection device, or some other mechanism for creating a viewable image. The display subsystem may also provide for non-visual display, such as via an audio output device. In general, use of the term "output device" is intended to include all possible types of devices and ways of outputting information from computing device 610 to a user or to another machine or computing device.
Storage subsystem 624 stores programming and data structures that provide the functionality of some or all of the modules described herein. For example, storage subsystem 624 may include logic to perform selected aspects of the methods of fig. 2, 3, and/or other methods described herein.
These software modules are typically executed by processor 614 alone or in combination with other processors. The memory 625 used in the storage subsystem 624 may include a number of memories, including a main Random Access Memory (RAM) 630 for storing instructions and data during program execution and a Read Only Memory (ROM) 632 in which fixed instructions are stored. File storage subsystem 626 may provide persistent storage for program and data files, and may include a hard disk drive, a floppy disk drive, and associated removable media, CD-ROM drive, optical drive, or removable media cartridge. Modules implementing the functionality of certain embodiments may be stored by file storage subsystem 626 in storage subsystem 624, or in other machines accessible to processor 614.
Bus subsystem 612 provides a mechanism for letting the various components and subsystems of computing device 610 communicate with each other as intended. Although bus subsystem 612 is shown schematically as a single bus, alternative implementations of the bus subsystem may use multiple buses.
Computing device 610 may be of a variety of types including a workstation, a server, a computing cluster, a blade server, a server farm, or any other data processing system or computing device. Due to the ever-changing nature of computers and networks, the description of computing device 610 depicted in FIG. 6 is intended only as a specific example for purposes of illustrating some embodiments. Many other configurations of computing device 610 are possible with more or fewer components than the computing device depicted in fig. 6.
In the case where the system described herein collects personal information or available personal information about a user (or often referred to herein as a "participant"), the user may be provided with an opportunity to control whether programs or features collect user information (e.g., information about the user's social network, social actions or activities, profession, user preferences, or the user's current geographic location), or whether and/or how to receive content from a content server that may be more relevant to the user. Moreover, prior to storing or using certain data, the data may be processed in one or more ways such that personally identifiable information is removed. For example, the identity of the user may be processed such that personally identifiable information of the user cannot be determined, or the geographic location of the user may be summarized (such as to a city, zip code, or state level) where the geographic location information is obtained such that a particular geographic location of the user cannot be determined. Thus, the user may have control over how information about the user is collected and/or used.
In some implementations, a method implemented by one or more processors is provided and includes receiving a plurality of model update, prediction pairs. Each of the model update, prediction pair includes: (a) At least one corresponding prediction generated based on processing the corresponding input using a machine learning model having a corresponding current weight; and (b) a corresponding model update generated based on at least one gradient, wherein the at least one gradient is generated based on applying the particular loss technique and is generated based at least in part on the corresponding prediction and the corresponding true value output. The method further includes, for each of the model update, prediction pair: generating a reconstruction of the corresponding prediction using the corresponding model updates and the known vocabulary of the projected output of the machine learning model; and generating a correspondence metric reflecting a degree of correspondence between the reconstruction and the corresponding prediction based on comparing the reconstruction to the corresponding prediction. Generating the reconstruction is performed independently of the corresponding prediction. The method further includes determining whether to utilize a particular penalty technique in federal training of the machine learning model or the additional machine learning model based on the model update, the corresponding metrics of the prediction pairs.
These and other embodiments of the technology may include one or more of the following features.
In some implementations, the method further includes, in response to determining that a particular loss technique is utilized in federal training of the machine learning model or the additional machine learning model: the machine learning model or the additional machine learning model is caused to be stored locally on the plurality of client devices along with the corresponding instructions. The corresponding instructions cause the client device to locally generate a model update of the machine learning model or the additional machine learning model using the particular loss technique and transmit the model update to one or more remote servers.
In some implementations, determining whether to utilize a particular loss technique in federal training of the machine learning model or the additional machine learning model based on the correspondence metrics includes: generating an overall metric based on the corresponding metrics; comparing the overall metric to a threshold; and determining to utilize the particular penalty technique in federal training in response to the overall metric meeting a threshold.
In some implementations, determining whether to utilize a particular loss technique in federal training of the machine learning model or the additional machine learning model based on the corresponding metrics includes: generating an overall metric based on the corresponding metrics; comparing the population metric to a surrogate population metric, the surrogate population metric generated based on surrogate model updates, a predicted pair having surrogate corresponding model updates generated based on surrogate specific loss techniques different from the specific loss techniques; and determining to utilize the particular loss technique in federal training in response to the comparison. In some versions of those embodiments, the specific loss technique is cross entropy loss without any gradient modification technique, and the alternative specific loss technique is cross entropy loss with at least one gradient modification technique. In some of those versions, the at least one gradient modification technique includes a sign gradient descent and/or adaptive federal optimization. In some other versions of those implementations, the specific loss technique is cross entropy loss with a first gradient modification technique (or a first combination of gradient modification techniques), while the alternative specific loss technique is cross entropy loss with a second gradient modification technique (or a second combination of gradient modification techniques).
In some implementations, generating a reconstruction of the corresponding prediction using the corresponding model updates and known labels of projection outputs of the machine learning model includes: the reconstruction is generated using matrix factorization of the model updates and using known vocabulary of the projected output of the machine learning model. The reconstruction may include, for example, limited to, a lexical reconstruction package. The reconstruction may additionally or alternatively comprise an ordered sequence reconstruction, and generating the reconstruction may further comprise generating the ordered sequence reconstruction using corresponding current weights of the model.
In some versions of those embodiments, generating the reconstruction using matrix factorization of the model updates and using a known vocabulary of projection outputs of the machine learning model includes: decomposing the model update into an sχv orthogonal matrix, where S corresponds to the number of sequences in the prediction, and where V corresponds to the size of the known vocabulary; determining which columns in the sχv orthogonal matrix include the separation classifier; and generating a reconstruction using the columns determined to include the separator classifier and the mapping of the columns to the known vocabulary. In some of those versions, determining which columns in the sχv orthogonal matrix include a separation classifier includes: performing a dot product of the sxv orthogonal matrix and the sxs invertible matrix; and determining which rows comprise negative values based on an analysis of rows of the matrix derived from the dot product; and determining that a column includes a split classifier based on the column corresponding to a row that includes a negative value (e.g., having the same index value).
In some implementations, a method implemented by one or more processors is provided that includes receiving a request from a computing device via a network. The request includes a plurality of model update, prediction pairs. Each of the model update, prediction pair includes: (a) At least one corresponding prediction generated based on processing the corresponding input using a machine learning model having a corresponding current weight; and (b) a corresponding model update generated based on at least one gradient, wherein the at least one gradient is generated based on applying the particular loss technique and is generated based at least in part on the corresponding prediction and the corresponding true value output. The method further includes, for each of the model update, prediction pair: generating a reconstruction of the corresponding prediction using the corresponding model updates and the known vocabulary of the projected output of the machine learning model; and generating a correspondence metric reflecting the degree of coincidence of the reconstruction with the corresponding prediction based on comparing the reconstruction with the corresponding prediction. Generating the reconstruction is performed independently of the corresponding prediction. The method further includes transmitting, in response to the request, the model update, a corresponding metric of the predicted pair, and/or an overall metric based on the corresponding metric to the computing device via the network.
In some implementations, a method implemented by one or more processors is provided and includes receiving a request from a computing device via a network. The request includes a plurality of model updates. Each of the model updates is generated based on applying the particular penalty technique and based at least in part on the corresponding predictions and the corresponding true value outputs. The corresponding predictions are generated based on processing the corresponding inputs using a machine learning model with corresponding current weights. The method further includes generating a reconstruction of the corresponding prediction using, for each of the model updates, the corresponding model update and a known vocabulary of projection outputs of the machine learning model. Generating the reconstruction is performed independently of the corresponding prediction. The method further includes transmitting, in response to the request, a reconstruction of the corresponding prediction to the computing device via the network.
Additionally, some implementations include one or more processors (e.g., a Central Processing Unit (CPU), a Graphics Processing Unit (GPU), and/or a Tensor Processing Unit (TPU)) of one or more computing devices, wherein the one or more processors are operable to execute instructions stored in an associated memory, and wherein the instructions are configured to cause performance of any of the methods described herein. Some embodiments also include one or more transitory or non-transitory computer-readable storage media storing computer instructions executable by the one or more processors to perform any of the methods described herein.
Claims (25)
1. A method implemented by one or more processors, the method comprising:
receiving a plurality of model update, prediction pairs, each of the model update, prediction pairs comprising:
at least one corresponding prediction generated based on processing a corresponding input using a machine learning model having a corresponding current weight;
a corresponding model update generated based on at least one gradient generated based on application specific loss techniques and generated based at least in part on the corresponding predictions and corresponding true value outputs;
for each of the model update, prediction pair:
generating a reconstruction of the corresponding prediction using the corresponding model update and a known vocabulary of projection outputs of the machine learning model, wherein generating the reconstruction is performed independently of the corresponding prediction; and
generating a correspondence metric reflecting a degree of correspondence between the reconstruction and the corresponding prediction based on comparing the reconstruction to the corresponding prediction; and
determining whether to utilize the particular penalty technique in federal training of the machine learning model or an additional machine learning model based on the corresponding metrics of the model update, prediction pair.
2. The method of claim 1, further comprising:
in response to determining to utilize the particular loss technique in federal training of the machine learning model or the additional machine learning model:
causing the machine learning model or the additional machine learning model to correspond to instruction one
And stored locally on a plurality of client devices, the corresponding instructions causing the client devices to:
locally generating the machine learning model or using the specific penalty technique
Model update of the additional machine learning model, and
the model updates are transmitted to one or more remote servers.
3. The method of claim 1 or claim 2, wherein determining whether to utilize the particular loss technique in federal training of the machine learning model or an additional machine learning model based on the correspondence metric comprises:
generating an overall metric based on the corresponding metrics;
comparing the overall metric to a threshold; and
the particular loss technique is determined to be utilized in federal training in response to the overall metric satisfying the threshold.
4. The method of claim 1 or claim 2, wherein determining whether to utilize the particular loss technique in federal training of the machine learning model or an additional machine learning model based on the correspondence metric comprises:
Generating an overall metric based on the corresponding metrics;
comparing the overall metric to an alternative overall metric, the alternative overall metric being generated based on an alternative model update, a prediction pair having an alternative corresponding model update being generated based on an alternative specific loss technique different from the specific loss technique; and
the particular loss technique is determined to be utilized in federal training in response to the comparison meeting one or more conditions.
5. The method of claim 4, wherein the particular loss technique is cross entropy loss without any gradient modification technique, and wherein the alternative particular loss technique is cross entropy loss with at least one gradient modification technique.
6. The method of claim 5, wherein the at least one gradient modification technique comprises symbol gradient descent, gradient sparsification, and/or adaptive federal optimization.
7. The method of any preceding claim, wherein generating the reconstruction of the corresponding prediction using known labels of projection outputs of the corresponding model updates and the machine learning model comprises:
the reconstruction is generated using matrix factorization of the model updates and using the known vocabulary of projection outputs of the machine learning model.
8. The method of claim 7, wherein the reconstructing comprises lexically reconstructing a packet.
9. The method of claim 7 or claim 8, wherein generating the reconstruction using matrix factorization of the model updates and using a known vocabulary of projection outputs of the machine learning model comprises:
decomposing the model update into an sχv orthogonal matrix, wherein S corresponds to the number of sequences in the prediction, and wherein V corresponds to the size of the known vocabulary;
determining which columns in the sχv orthogonal matrix include a separation classifier; and
the reconstruction is generated using columns determined to include the separation classifier and a mapping of the columns to the known vocabulary.
10. The method of claim 9, wherein determining which columns in the sχv orthogonal matrix include the separation classifier comprises:
performing a dot product of the sxv orthogonal matrix and an sxs invertible matrix; and
determining which rows include negative values based on an analysis of rows of a result matrix from the dot product; and
determining that the column includes the separator classifier based on a column corresponding to a row that includes the negative value.
11. The method of any of claims 7 to 10, wherein the reconstruction comprises an ordered sequence reconstruction, and wherein generating the reconstruction further comprises generating the ordered sequence reconstruction using the corresponding current weights of the model.
12. A method implemented by one or more processors, the method comprising:
a request is received from a computing device via a network, wherein the request includes a plurality of model update, prediction pairs, each of the model update, prediction pairs comprising:
at least one corresponding prediction generated based on processing a corresponding input using a machine learning model having a corresponding current weight; and
a corresponding model update generated based on at least one gradient generated based on application specific loss techniques and generated based at least in part on the corresponding predictions and corresponding true value outputs;
for each of the model update, prediction pair:
generating a reconstruction of the corresponding prediction using the corresponding model update and a known vocabulary of projection outputs of the machine learning model, wherein generating the reconstruction is performed independently of the corresponding prediction; and
Generating a correspondence metric reflecting compliance of the reconstruction with the corresponding prediction based on comparing the reconstruction with the corresponding prediction;
transmitting, via the network, to the computing device in response to the request:
said model updates, predicts said corresponding metrics of pairs, and/or
An overall metric based on the corresponding metrics.
13. The method of claim 12, wherein generating the reconstruction of the corresponding prediction using the corresponding model update and known labels of projection outputs of the machine learning model comprises:
the reconstruction is generated using matrix factorization of the model updates and using the known vocabulary of projection outputs of the machine learning model.
14. The method of claim 13, wherein the reconstructing comprises lexically reconstructing a packet.
15. The method of claim 13 or claim 14, wherein the reconstruction comprises an ordered sequence reconstruction, and wherein generating the reconstruction further comprises generating the ordered sequence reconstruction using the corresponding current weights of the model and the lexical reconstruction package.
16. The method of any of claims 13 to 15, wherein generating the reconstruction using matrix factorization of the gradients and using known vocabulary of projection outputs of the machine learning model comprises:
Decomposing the model update into an sχv orthogonal matrix, wherein S corresponds to the number of sequences in the prediction, and wherein V corresponds to the size of the known vocabulary;
determining which columns in the sχv orthogonal matrix include a separation classifier; and
the reconstruction is generated using columns determined to include the separation classifier and a mapping of the columns to the known vocabulary.
17. The method of claim 16, wherein determining which columns in the sχv orthogonal matrix include the separation classifier comprises:
performing a dot product of the sxv orthogonal matrix and an sxs invertible matrix; and
determining which rows include negative values based on an analysis of rows of a result matrix from the dot product; and
determining that the column includes the separator classifier based on a column corresponding to a row that includes the negative value.
18. A method implemented by one or more processors, the method comprising:
receiving, via a network, a request from a computing device, wherein the request includes a plurality of model updates, wherein each of the model updates is generated based on application-specific penalty techniques and based at least in part on a corresponding prediction and a corresponding real value output, wherein the corresponding prediction is generated based on processing a corresponding input using a machine learning model having a corresponding current weight;
For each of the model updates:
generating a reconstruction of the corresponding prediction using the corresponding model update and a known vocabulary of projection outputs of the machine learning model, wherein generating the reconstruction is performed independently of the corresponding prediction; and
transmitting, via the network, to the computing device in response to the request:
the reconstruction of the corresponding prediction.
19. The method of claim 18, wherein generating the reconstruction of the corresponding prediction using the corresponding model update and known labels of projection outputs of the machine learning model comprises:
the reconstruction is generated using matrix factorization of the model updates and using the known vocabulary of projection outputs of the machine learning model.
20. The method of claim 18 or claim 19, wherein the reconstructing comprises lexically reconstructing packets.
21. The method of any of claims 18 to 20, wherein the reconstruction comprises an ordered sequence reconstruction, and wherein generating the reconstruction further comprises generating the ordered sequence reconstruction using the corresponding current weights of the model.
22. The method of claim 19, wherein generating the reconstruction using matrix factorization of the model updates and using a known vocabulary of projection outputs of the machine learning model comprises:
decomposing the model update into an sχv orthogonal matrix, wherein S corresponds to the number of sequences in the prediction, and wherein V corresponds to the size of the known vocabulary;
determining which columns in the sχv orthogonal matrix include a separation classifier; and
the reconstruction is generated using columns determined to include the separation classifier and a mapping of the columns to the known vocabulary.
23. A computer program comprising instructions which, when executed by one or more processors of a computing system, cause the computing system to perform the method of any preceding claim.
24. A computing system configured to perform the method of any one of claims 1 to 22.
25. A computer-readable storage medium storing instructions executable by one or more processors of a computing system to perform the method of any one of claims 1-22.
Applications Claiming Priority (4)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US63/194,663 | 2021-05-28 | ||
US17/535,405 US20220383204A1 (en) | 2021-05-28 | 2021-11-24 | Ascertaining and/or mitigating extent of effective reconstruction, of predictions, from model updates transmitted in federated learning |
US17/535,405 | 2021-11-24 | ||
PCT/US2021/063122 WO2022250732A1 (en) | 2021-05-28 | 2021-12-13 | Ascertaining and/or mitigating extent of effective reconstruction, of predictions, from model updates transmitted in federated learning |
Publications (1)
Publication Number | Publication Date |
---|---|
CN116783601A true CN116783601A (en) | 2023-09-19 |
Family
ID=88012044
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN202180088371.8A Pending CN116783601A (en) | 2021-05-28 | 2021-12-13 | Determining and/or mitigating an effective degree of reconstruction of predictions based on model updates transmitted in federal learning |
Country Status (1)
Country | Link |
---|---|
CN (1) | CN116783601A (en) |
-
2021
- 2021-12-13 CN CN202180088371.8A patent/CN116783601A/en active Pending
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11829880B2 (en) | Generating trained neural networks with increased robustness against adversarial attacks | |
US11915104B2 (en) | Normalizing text attributes for machine learning models | |
US20230177821A1 (en) | Document image understanding | |
EP3905126A2 (en) | Image clustering method and apparatus | |
CN109783490B (en) | Data fusion method and device, computer equipment and storage medium | |
US20210150412A1 (en) | Systems and methods for automated machine learning | |
US8775338B2 (en) | Computer-implemented systems and methods for constructing a reduced input space utilizing the rejected variable space | |
US11373117B1 (en) | Artificial intelligence service for scalable classification using features of unlabeled data and class descriptors | |
WO2018093935A1 (en) | Training neural networks using a clustering loss | |
Luo et al. | Graph entropy guided node embedding dimension selection for graph neural networks | |
JP2023535140A (en) | Identifying source datasets that fit the transfer learning process against the target domain | |
US20230005572A1 (en) | Molecular structure acquisition method and apparatus, electronic device and storage medium | |
Han et al. | SlimML: Removing non-critical input data in large-scale iterative machine learning | |
US20220405549A1 (en) | Multi-stream recurrent neural network transducer(s) | |
US11410065B2 (en) | Storage medium, model output method, and model output device | |
CN114816719B (en) | Training method and device of multi-task model | |
CN116783601A (en) | Determining and/or mitigating an effective degree of reconstruction of predictions based on model updates transmitted in federal learning | |
US20220383204A1 (en) | Ascertaining and/or mitigating extent of effective reconstruction, of predictions, from model updates transmitted in federated learning | |
WO2022250732A1 (en) | Ascertaining and/or mitigating extent of effective reconstruction, of predictions, from model updates transmitted in federated learning | |
JP7099254B2 (en) | Learning methods, learning programs and learning devices | |
CN111723247A (en) | Graph-based hypothetical computation | |
JP2020030702A (en) | Learning device, learning method, and learning program | |
US20240028828A1 (en) | Machine learning model architecture and user interface to indicate impact of text ngrams | |
US11868846B1 (en) | Quantum computing simulation using comparative rejection sampling | |
CN113505838B (en) | Image clustering method and device, electronic equipment and storage medium |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |