US11552814B2 - Proactive provision of new content to group chat participants - Google Patents
Proactive provision of new content to group chat participants Download PDFInfo
- Publication number
- US11552814B2 US11552814B2 US16/927,373 US202016927373A US11552814B2 US 11552814 B2 US11552814 B2 US 11552814B2 US 202016927373 A US202016927373 A US 202016927373A US 11552814 B2 US11552814 B2 US 11552814B2
- Authority
- US
- United States
- Prior art keywords
- message exchange
- participants
- participant
- exchange thread
- proactively
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Active
Links
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L12/00—Data switching networks
- H04L12/02—Details
- H04L12/16—Arrangements for providing special services to substations
- H04L12/18—Arrangements for providing special services to substations for broadcast or conference, e.g. multicast
- H04L12/1813—Arrangements for providing special services to substations for broadcast or conference, e.g. multicast for computer conferences, e.g. chat rooms
- H04L12/1827—Network arrangements for conference optimisation or adaptation
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L51/00—User-to-user messaging in packet-switching networks, transmitted according to store-and-forward or real-time protocols, e.g. e-mail
- H04L51/02—User-to-user messaging in packet-switching networks, transmitted according to store-and-forward or real-time protocols, e.g. e-mail using automatic reactions or user delegation, e.g. automatic replies or chatbot-generated messages
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F16/00—Information retrieval; Database structures therefor; File system structures therefor
- G06F16/90—Details of database functions independent of the retrieved data types
- G06F16/95—Retrieval from the web
- G06F16/953—Querying, e.g. by the use of web search engines
- G06F16/9535—Search customisation based on user profiles and personalisation
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F40/00—Handling natural language data
- G06F40/40—Processing or translation of natural language
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q10/00—Administration; Management
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L12/00—Data switching networks
- H04L12/02—Details
- H04L12/16—Arrangements for providing special services to substations
- H04L12/18—Arrangements for providing special services to substations for broadcast or conference, e.g. multicast
- H04L12/1813—Arrangements for providing special services to substations for broadcast or conference, e.g. multicast for computer conferences, e.g. chat rooms
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L65/00—Network arrangements, protocols or services for supporting real-time applications in data packet communication
- H04L65/40—Support for services or applications
- H04L65/403—Arrangements for multi-party communication, e.g. for conferences
- H04L65/4038—Arrangements for multi-party communication, e.g. for conferences with floor control
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L67/00—Network arrangements or protocols for supporting network services or applications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q10/00—Administration; Management
- G06Q10/06—Resources, workflows, human or project management; Enterprise or organisation planning; Enterprise or organisation modelling
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L51/00—User-to-user messaging in packet-switching networks, transmitted according to store-and-forward or real-time protocols, e.g. e-mail
- H04L51/21—Monitoring or handling of messages
- H04L51/216—Handling conversation history, e.g. grouping of messages in sessions or threads
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04L—TRANSMISSION OF DIGITAL INFORMATION, e.g. TELEGRAPHIC COMMUNICATION
- H04L67/00—Network arrangements or protocols for supporting network services or applications
- H04L67/50—Network services
- H04L67/75—Indicating network or usage conditions on the user display
Definitions
- Humans may engage in human-to-computer dialogs with interactive software applications referred to herein as “automated assistants” (also referred to as “chatbots,” “interactive personal assistants,” “intelligent personal assistants,” “personal voice assistants,” “conversational agents,” etc.).
- automated assistants also referred to as “chatbots,” “interactive personal assistants,” “intelligent personal assistants,” “personal voice assistants,” “conversational agents,” etc.
- humans which when they interact with automated assistants may be referred to as “users” may provide commands, queries, and/or requests (collectively referred to herein as “queries”) using spoken natural language input (i.e. utterances) which may in some cases be converted into text and then processed, and/or by providing textual (e.g., typed) natural language input.
- spoken natural language input i.e. utterances
- message exchange threads may be formed from textual group chats where all or most of the participants provide textual input into, for example, a message exchange client.
- message exchange threads may be formed from oral conversations between multiple participants, e.g., as part of voice conferences and/or video conferences.
- the bots may reactively and/or proactively incorporate various content into the thread, based on the content of the message exchange thread itself (i.e., the messages exchanged between the users) or based on publicly available information.
- the bots typically have, at most, access to the content of the message exchange thread (i.e., the messages exchanged between the users) and other publicly available information that may or may not be limited to their respective domains. This limits the type of content they are able to proactively incorporate into the group chat, particularly early on in the lifetime of the group chat when there may be limited conversational content from which to identify topics.
- Some “general purpose” (“GP”) automated assistants may include GP automated assistant “clients” that are installed locally on client devices and that are interacted with directly by users, as well as cloud-based counterpart(s) that leverage the virtually limitless resources of the cloud to cooperate with automated assistant clients respond to users' requests.
- the GP automated assistant client may provide, to the cloud-based counterpart(s), an audio recording of the user's voice input (or a text conversion thereof) and data indicative of the user's identity (e.g., credentials).
- the cloud-based counterpart may perform various processing on the input to return various results to the GP automated assistant client, which may then provide corresponding output to the user (or take some other action).
- the term “GP automated assistant,” when described herein as “serving” a particular user, may refer to the GP automated assistant client installed on the particular user's client device and any cloud-based counterpart that interacts with the GP automated assistant client to respond to the user's queries.
- automated assistant may refer more generally to any software process that receives natural language input and provides natural language output in response, such as one of the aforementioned domain-specific bots and/or a GP automated assistant.
- a GP automated assistant may have access to publicly-available data such as documents and other information available on the Internet, as well as “user-controlled resources” under the control of a particular user served by the automated assistant.
- User-controlled resources may be associated with a “user account” of the user, and may be locally accessible from client device(s) operated by the user and/or remotely (e.g., in the so-called “cloud”).
- User-controlled resources may take various forms, such as a user's calendar, emails, text messages, reminders, shopping lists, search history, browsing history, photos, documents, sensor data (e.g., position coordinates), content of past human-to-computer dialogs, personal preferences, and so forth.
- each participant may be associated with the aforementioned individual participant profile, which may be associated with (e.g., include) information related to the participant and/or controlled by the participant.
- participant's individual participant profile may include user-controlled resources related to the participant, such as the participant's search history, browsing history, location history (e.g., determined from multiple position coordinates obtained over time), personal documents, emails, calendar entries, reminder lists, prior contributions to other message exchange threads, prior exchanges with an automated assistant, prior consumption of proactively provided content (e.g., did the user ignore, swipe away, or otherwise reject proactively provided content?), etc.
- user-controlled resources related to the participant such as the participant's search history, browsing history, location history (e.g., determined from multiple position coordinates obtained over time), personal documents, emails, calendar entries, reminder lists, prior contributions to other message exchange threads, prior exchanges with an automated assistant, prior consumption of proactively provided content (e.g., did the user ignore, swipe away, or otherwise reject proactively provided content?), etc.
- an automated assistant may identify, based on individual participant profiles associated with one or more participants in the group chat, one or more shared interests of the participants.
- the automated assistant may also analyze content of the group chat to identify one or more topics of discussion.
- the automated assistant may use the shared interests, alone or in combination with the topics, to select new content to be proactively provided to the participants, e.g., by being incorporated into the group chat.
- the automated assistant need not be explicitly invoked or invited to join the group chat; hence, the “proactive” nature of the incorporation.
- the automated assistant may detect that a broad topic of “sports” and narrower topics of “baseball” and the teams involved in the baseball game are being discussed. Additionally, the automated assistant may detect, e.g., based on search history associated with one participant and location history of another participant, that both participants are interested (or potentially are interested) in a particular basketball team. Even though basketball in general and the commonly-liked basketball team in particular have not yet been mentioned, because the topic of “sports” has been raised in the group chat, the automated assistant may proactively incorporate content related to the potentially shared-interest basketball team into the group chat.
- the proactively-incorporated content may include, for instance, content obtained from publicly available sources.
- the automated assistant may select and proactively incorporate into the group chat a message such as “ ⁇ your shared-interest team> has a game tonight at 7:30 PM on ⁇ network>.”
- Some group chats may be persistent in that participants can join, leave, and then later rejoin the group chat. Indeed, some group chats may operate like a forum or message board that persists and can be revisited later. Accordingly, it is not required that automated assistants only proactively incorporate content when all participants are actively contributing to and/or participating in the group chat.
- automated assistants may incorporate messages into the group chat just as though they were themselves participants, even if no other participants are currently active in the group chat. This may occur, for instance, when new information becomes available, e.g., from one or more news sources.
- Other human participants may be notified of content proactively-incorporated by automated assistants in manners similar to how they might be notified that any other human participants contributed to the group chat. For example, a graphical icon associated with the group chat may be presented, e.g., on a home screen of a participant's smart phone, that includes a number of new (e.g., unread by that particular participant) messages.
- newly-initiated group chats may lack sufficient content alone to enable automated assistants to proactively incorporate content in an effective manner.
- One or more terms may be raised by participants that are susceptible to multiple interpretations. For example, suppose multiple non-American users begin a group chat discussing the topic “football.” This topic could be interpreted as American Football (e.g., the NFL) or traditional football (which is called “soccer” in the United States). Without more information, an automated assistant may proactively incorporate irrelevant information into the group chat. That is why, as noted above, with relatively newly established group chats, automated assistants may also utilize individual participant profiles to determine shared interests, which then may be used to select content to proactively incorporate into a group chat.
- an amount of influence shared participant interests have on selecting new content to proactively provide to the group chat participant may diminish based on a length of the message exchange thread. For example, the longer a temporal lifetime of the message exchange thread, the more heavily topics of discussion influence selection of content for proactive incorporation, relative to shared interests. Additionally or alternatively, the greater number of messages exchanged by multiple participants of the group chat, the more heavily topics of discussion influence selection of content for proactive incorporation, relative to shared interests. As more topics are raised and discussed, automated assistants may be better able to proactively provide content that is more likely to be well-received by the human participants.
- participant profiles may be updated based on participant reactions to proactively provided content. For example, suppose a particular interest attributed to a participant is used to select proactively provided content, and the participant provides negative feedback in response to the proactively provided content. In some implementations, the participant's profile may be updated to weaken or even eliminate the association between the participant and the interest.
- a method performed by one or more processors includes: analyzing, by one or more automated assistants, one or both of content of a message exchange thread involving multiple human participants and one or more documents associated with the message exchange thread, wherein the automated assistant is not explicitly invoked by any of the participants; identifying, by one or more of the automated assistants, based on the analyzing, one or more topics pertinent to the message exchange thread; identifying, by one or more of the automated assistants, based on individual participant profiles associated with the participants, one or more shared interests of the participants, wherein each participant of the multiple participants is associated with an individual participant profile that includes information related to the participant; selecting, by one or more of the automated assistants, new content that is based both on the one or more pertinent topics and one or more of the shared interests of the participants; and proactively providing, by one or more of the automated assistants, the new content to one or more of the participants.
- the proactively providing may include proactively incorporating the new content into the message exchange thread.
- the proactive providing may cause one or more client devices of the participants to output the new content via one or more output devices.
- the new content may be output at one or more client devices of the participants outside of the message exchange thread.
- the new content may include first new content
- the method may further include: selecting, by one or more of the automated assistants, after the proactively providing, second new content that is based on the one or more pertinent topics or one or more subsequent topics determined to be pertinent to the message exchange thread, wherein the second content is selected by one or more of the automated assistants without consideration of the shared interests of the participants; and proactively providing, by one or more of the automated assistants, the second new content to one or more of the participants.
- the one or more shared interests of the participants may be identified based on search history associated with one or more of the individual participant profiles. In various implementations, the one or more shared interests of the participants may be identified based on location history associated with one or more of the individual participant profiles. In various implementations, an amount of influence the one or more shared interests of the individuals has on selecting the new content may be based on a length of the message exchange thread. In various implementations, the length of the message exchange thread may include a temporal lifetime of the message exchange thread and/or may be based on a count of messages exchanged by the multiple participants.
- selecting the new content that is based both on the one or more pertinent topics and the one or more of the shared interests of the participants may include: identifying a group of content candidates based on the one or more pertinent topics; and selecting the new content, from the group of content candidates, based on one or more of the shared interests of the participants.
- the one or more documents associated with the message exchange thread may include a meeting agenda or a calendar entry.
- selecting the new content may be further based on prior feedback received from one or more of the participants in response to content that was proactively provided previously.
- implementations include one or more processors of one or more computing devices, where the one or more processors are operable to execute instructions stored in associated memory, and where the instructions are configured to cause performance of any of the aforementioned methods. Some implementations also include one or more non-transitory computer readable storage media storing computer instructions executable by one or more processors to perform any of the aforementioned methods.
- FIG. 1 is a block diagram of an example environment in which implementations disclosed herein may be implemented.
- FIGS. 2 , 3 , and 4 depict example group chats involving multiple participants in which disclosed techniques may be employed, in accordance with various implementations.
- FIG. 5 depicts a flowchart illustrating an example method according to implementations disclosed herein.
- FIG. 6 illustrates an example architecture of a computing device.
- the example environment includes a plurality of client computing devices 106 1-N .
- Each client device 106 may execute a respective instance of a general purpose (“GP”) automated assistant client 118 .
- GP general purpose
- One or more cloud-based GP automated assistant components 119 such as a natural language processor 122 , may be implemented on one or more computing systems (collectively referred to as a “cloud” computing system) that are communicatively coupled to client devices 106 1-N via one or more local and/or wide area networks (e.g., the Internet) indicated generally at 110 1 .
- an instance of an automated assistant client 118 by way of its interactions with one or more cloud-based automated assistant components 119 , may form what appears to be, from the user's perspective, a logical instance of a GP automated assistant 120 with which the user may engage in a human-to-computer dialog. Two instances of such a GP automated assistant 120 are depicted in FIG. 1 .
- a first GP automated assistant 120 A encompassed by a dashed line serves a first user 140 A operating first client device 106 1 and includes GP automated assistant client 118 1 and one or more cloud-based automated assistant components 119 .
- a second GP automated assistant 120 B encompassed by a dash-dash-dot line serves a second user 140 B operating another client device 106 N and includes GP automated assistant client 118 N and one or more cloud-based automated assistant components 119 . It thus should be understood that each user that engages with a GP automated assistant client 118 executing on a client device 106 may, in effect, engage with his or her own logical instance of a GP automated assistant 120 .
- automated assistant as used herein as “serving” a particular user will refer to the combination of a GP automated assistant client 118 executing on a client device 106 operated by the user and one or more cloud-based automated assistant components 119 (which may be shared amongst multiple GP automated assistant clients 118 ).
- the client devices 106 1-N may include, for example, one or more of: a desktop computing device, a laptop computing device, a tablet computing device, a mobile phone computing device, a computing device of a vehicle of the user (e.g., an in-vehicle communications system, an in-vehicle entertainment system, an in-vehicle navigation system), a standalone interactive speaker, and/or a wearable apparatus of the user that includes a computing device (e.g., a watch of the user having a computing device, glasses of the user having a computing device, a virtual or augmented reality computing device). Additional and/or alternative client computing devices may be provided.
- a desktop computing device e.g., a laptop computing device, a tablet computing device, a mobile phone computing device, a computing device of a vehicle of the user (e.g., an in-vehicle communications system, an in-vehicle entertainment system, an in-vehicle navigation system), a standalone interactive speaker, and/or a wear
- a given user may communicate with GP automated assistant 120 utilizing a plurality of client computing devices 106 that collectively from a coordinated “ecosystem” of computing devices.
- GP automated assistant 120 may be considered to “serve” that given user, e.g., endowing GP automated assistant 120 with enhanced access to user-controlled content (e.g., resources, documents, etc.) for which access is controlled by the “served” user.
- user-controlled content e.g., resources, documents, etc.
- a user-controlled resources engine 130 may be implemented on one or computing devices (which again may be collectively referred to as a “cloud”) to control access to resources controlled by each user.
- user-controlled resources engine 130 may be operably coupled with one or more computing systems that implement GP automated assistant 120 via one or more local and/or wide area networks (e.g., the Internet) indicated generally at 110 2 .
- user-controlled resources engine 130 may be implemented in whole or in part on the same computing systems that implement GP automated assistant 120 .
- user-controlled resources engine 130 may include one or more access control lists 126 that govern access to user-controlled resources 128 .
- access control list 126 may indicate access rights regarding multiple types of user-controlled resources for each user.
- Access control lists 126 may take various forms, such as database entries or a list of access control entries, that include indications, for each user, of what content controlled by that user is accessible to others (including the others' automated assistants), how it is accessible (e.g., read, write, etc.), and so forth.
- User-controlled resources 128 may include various data associated with each user. This data may include documents associated with the user (and in many cases, with one or more accounts of the user), such as documents the user stores on a so-called “cloud” drive.” It may also include emails and other electronic correspondence (e.g., text messages, social media posts, etc.). In some implementations, user-controlled resources 128 may include behavior related to the user's behavior, such as search query history (e.g., search logs), past conversations with a GP automated assistant 120 , browsing history, and so forth.
- search query history e.g., search logs
- browsing history e.g., browsing history, and so forth.
- User-controlled resources 128 may also include other resources associated with a user, such as a calendar, a reminder list, a shopping list, sensor data (e.g., position coordinate data produced by, for instance, a Global Positioning System, or “GPS,” sensor), and so forth.
- sensor data e.g., position coordinate data produced by, for instance, a Global Positioning System, or “GPS,” sensor
- the terms “individual participant profile” and “participant profile” may refer generally to user-controlled resources 128 associated with a particular participant in a message exchange thread.
- a participant's individual participant profile may include one or more position coordinates of the participant, data pertaining to browsing history of the participant, data pertaining to search history of the participant, documents (e.g., calendar entries, emails, etc.) controlled by the participant, etc.
- user-controlled resources 128 (or a “participant profile”) associated with a particular user may be associated with a “user account” of the user.
- a user may sign into his or her user account on one or more client devices (e.g., using various credentials such as a username/password, biometrics, etc.), thereby endowing a GP automated assistant 120 (including the locally-executing client 118 and any online components 119 ) that serves the user with access to these resources.
- GP automated assistant 120 may gain access to user-controlled resources 128 by way of the associated user account.
- the user may grant GP automated assistant 120 permission to access some or all of the user-controlled resources 128 controlled by the user.
- the user effectively grants GP automated assistant 120 access to user-controlled resources 128 .
- this may include modifying access control list 126 (or other similar security mechanism).
- user-controlled resources 128 is depicted in FIG. 1 as a single database, this is not to suggest that all user-controlled resources is stored in a single location.
- user-controlled resources may be stored (or otherwise available) in part on client devices 106 (e.g., sensor signals such as GPS, local documents, photos, media files, etc.), and/or may be distributed across a variety of cloud-based systems, each which may serve a different purpose (e.g., one set of one or more servers may provide email functionality, another set of one or more servers may provide calendar functionality, etc.).
- Each of the client computing devices 106 1-N may operate a variety of different applications, such as a corresponding one of a plurality of message exchange clients 107 1-N . and a corresponding one of a plurality of GP automated assistant clients 118 1-N .
- Message exchange clients 107 1-N may come in various forms and the forms may vary across the client computing devices 106 1-N and/or multiple forms may be operated on a single one of the client computing devices 106 1-N .
- one or more of the message exchange clients 107 1-N may come in the form of a short messaging service (“SMS”) and/or multimedia messaging service (“MMS”) client, an online chat client (e.g., instant messenger, Internet relay chat, or “IRC,” etc.), a messaging application associated with a social network, a personal assistant messaging service dedicated to conversations with GP automated assistant 120 , and so forth.
- SMS short messaging service
- MMS multimedia messaging service
- IRC Internet relay chat
- one or more of the message exchange clients 107 1-N may be implemented via a webpage or other resources rendered by a web browser (not depicted) or other application of client computing device 106 .
- GP automated assistant 120 engages in human-to-computer dialog sessions with one or more users via user interface input and output devices of one or more client devices 106 1-N .
- GP automated assistant 120 may engage in a human-to-computer dialog session with a user in response to user interface input provided by the user via one or more user interface input devices of one of the client devices 106 1-N .
- the user interface input is explicitly directed to GP automated assistant 120 .
- one of the message exchange clients 107 1-N may be a personal assistant messaging service dedicated to conversations with GP automated assistant 120 and user interface input provided via that personal assistant messaging service may be automatically provided to GP automated assistant 120 .
- the user interface input may be explicitly directed to GP automated assistant 120 in one or more of the message exchange clients 107 1-N based on particular user interface input that indicates GP automated assistant 120 is to be invoked.
- the particular user interface input may be one or more typed characters (e.g., @AutomatedAssistant), user interaction with a hardware button and/or virtual button (e.g., a tap, a long tap), an oral command (e.g., “Hey Automated Assistant”), and/or other particular user interface input.
- GP automated assistant 120 may engage in a dialog session in response to user interface input, even when that user interface input is not explicitly directed to GP automated assistant 120 .
- GP automated assistant 120 may examine the contents of user interface input and engage in a dialog session in response to certain terms being present in the user interface input and/or based on other cues.
- GP automated assistant 120 may engage interactive voice response (“IVR”), such that the user can utter commands, searches, etc., and the automated assistant may utilize natural language processing and/or one or more grammars to convert the utterances into text, and respond to the text accordingly.
- IVR interactive voice response
- Each computing device depicted in FIG. 1 may include one or more memories for storage of data and software applications, one or more processors for accessing data and executing applications, and other components that facilitate communication over a network.
- the operations performed by one or more of the client computing devices 106 1-N and/or by GP automated assistant 120 may be distributed across multiple computer systems.
- GP automated assistant 120 may be implemented as, for example, computer programs running on one or more computers in one or more locations that are coupled to each other through a network.
- each of the client computing devices 106 1-N may operate a GP automated assistant client 118 .
- each GP automated assistant client 118 may include a corresponding speech capture/text-to-speech (“TTS”)/speech-to-text (“STT”) module 114 .
- TTS speech capture/text-to-speech
- STT speech-to-text
- one or more aspects of speech capture/TTS/STT module 114 may be implemented separately from GP automated assistant client 118 .
- Each speech capture/TTS/STT module 114 may be configured to perform one or more functions: capture a user's speech, e.g., via a microphone (not depicted); convert that captured audio to text; and/or convert text to speech.
- a client device 106 may be relatively constrained in terms of computing resources (e.g., processor cycles, memory, battery, etc.)
- the speech capture/TTS/STT module 114 that is local to each client device 106 may be configured to convert a finite number of different spoken phrases—particularly phrases that invoke GP automated assistant 120 —to text.
- Other speech input may be sent to cloud-based automated assistant components 119 , which may include a cloud-based TTS module 116 and/or a cloud-based STT module 117 .
- STT module 117 may be configured to leverage the virtually limitless resources of the cloud to convert audio data captured by speech capture/TTS/STT module 114 into text (which may then be provided to natural language processor 122 ).
- TTS module 116 may be configured to leverage the virtually limitless resources of the cloud to convert textual data (e.g., natural language responses formulated by GP automated assistant 120 ) into computer-generated speech output.
- TTS module 116 may provide the computer-generated speech output to client device 106 to be output directly, e.g., using one or more speakers.
- textual data e.g., natural language responses
- GP automated assistant 120 may be provided to speech capture/TTS/STT module 114 , which may then convert the textual data into computer-generated speech that is output locally.
- GP automated assistant 120 may include a natural language processor 122 , the aforementioned TTS module 116 , the aforementioned STT module 117 , and other components that are not depicted in FIG. 1 .
- one or more of the engines and/or modules of GP automated assistant 120 may be omitted, combined, and/or implemented in a component that is separate from GP automated assistant 120 .
- GP automated assistant 120 generates responsive content in response to various inputs generated by a user of one of the client devices 106 1-N during a human-to-computer dialog session with GP automated assistant 120 .
- GP automated assistant 120 may provide the responsive content (e.g., over one or more networks when separate from a client device of a user) for presentation to the user as part of the dialog session.
- GP automated assistant 120 may generate responsive content in in response to free-form natural language input provided via one of the client devices 106 1-N .
- free-form input is input that is formulated by a user and that is not constrained to a group of options presented for selection by the user.
- Natural language processor 122 of GP automated assistant 120 processes natural language input generated by users via client devices 106 1-N and may generate annotated output for use by one or more other components of GP automated assistant 120 .
- the natural language processor 122 may process natural language free-form input that is generated by a user via one or more user interface input devices of client device 106 1 .
- the generated annotated output includes one or more annotations of the natural language input and optionally one or more (e.g., all) of the terms of the natural language input.
- the natural language processor 122 is configured to identify and annotate various types of grammatical information in natural language input.
- the natural language processor 122 may include a part of speech tagger configured to annotate terms with their grammatical roles.
- the part of speech tagger may tag each term with its part of speech such as “noun,” “verb,” “adjective,” “pronoun,” etc.
- the natural language processor 122 may additionally and/or alternatively include a dependency parser (not depicted) configured to determine syntactic relationships between terms in natural language input.
- the dependency parser may determine which terms modify other terms, subjects and verbs of sentences, and so forth (e.g., a parse tree)—and may make annotations of such dependencies.
- the natural language processor 122 may additionally and/or alternatively include an entity tagger (not depicted) configured to annotate entity references in one or more segments such as references to people (including, for instance, literary characters, celebrities, public figures, etc.), organizations, locations (real and imaginary), and so forth.
- entity tagger (not depicted) configured to annotate entity references in one or more segments such as references to people (including, for instance, literary characters, celebrities, public figures, etc.), organizations, locations (real and imaginary), and so forth.
- data about entities may be stored in one or more databases, such as in a knowledge graph (not depicted).
- the knowledge graph may include nodes that represent known entities (and in some cases, entity attributes), as well as edges that connect the nodes and represent relationships between the entities.
- a “banana” node may be connected (e.g., as a child) to a “fruit” node,” which in turn may be connected (e.g., as a child) to “produce” and/or “food” nodes.
- a restaurant called “Hypothetical Café” may be represented by a node that also includes attributes such as its address, type of food served, hours, contact information, etc.
- the “Hypothetical Café” node may in some implementations be connected by an edge (e.g., representing a child-to-parent relationship) to one or more other nodes, such as a “restaurant” node, a “business” node, a node representing a city and/or state in which the restaurant is located, and so forth.
- edge e.g., representing a child-to-parent relationship
- other nodes such as a “restaurant” node, a “business” node, a node representing a city and/or state in which the restaurant is located, and so forth.
- the entity tagger of the natural language processor 122 may annotate references to an entity at a high level of granularity (e.g., to enable identification of all references to an entity class such as people) and/or a lower level of granularity (e.g., to enable identification of all references to a particular entity such as a particular person).
- the entity tagger may rely on content of the natural language input to resolve a particular entity and/or may optionally communicate with a knowledge graph or other entity database to resolve a particular entity.
- the natural language processor 122 may additionally and/or alternatively include a coreference resolver (not depicted) configured to group, or “cluster,” references to the same entity based on one or more contextual cues.
- the coreference resolver may be utilized to resolve the term “there” to “Hypothetical Café” in the natural language input “I liked Hypothetical Café last time we ate there.”
- one or more components of the natural language processor 122 may rely on annotations from one or more other components of the natural language processor 122 .
- the named entity tagger may rely on annotations from the coreference resolver and/or dependency parser in annotating all mentions to a particular entity.
- the coreference resolver may rely on annotations from the dependency parser in clustering references to the same entity.
- one or more components of the natural language processor 122 may use related prior input and/or other related data outside of the particular natural language input to determine one or more annotations.
- techniques are described herein for analyzing, by one or more automated assistants (e.g., GP automated assistant 120 and/or domain-specific bots, etc.), one or both of content of a message exchange thread involving multiple human participants and one or more documents associated with the message exchange thread; identifying, by one or more of the automated assistants, based on the analyzing, one or more topics pertinent to the message exchange thread; identifying, by one or more of the automated assistants, based on individual participant profiles associated with the participants, one or more shared interests of the participants, wherein each participant of the multiple participants is associated with an individual participant profile that includes information related to the participant; selecting, by one or more of the automated assistants, new content that is based both on the one or more pertinent topics and one or more of the shared interests of the participants; and proactively providing, by one or more of the automated assistants, the new content to the participants.
- all of these operations may be performed even though the automated assistant is not explicitly invoked by any of the participants.
- GP automated assistant 120 may include a group chat analysis service 138 (e.g., any combination of hardware and software) that is configured to perform one or more of the above-described operations.
- group chat analysis service 138 may analyze various signals associated with a particular group chat, such as content of the group chat and/or documents associated with the group chat. Additionally, group chat analysis service 138 may consult with user-controlled resources engine 130 to identify shared interests of multiple participants of the group chat. Based on these data, group chat analysis service 138 (and more generally, GP automated assistant 120 ) may select new content to proactively provide to the group chat participants, even without GP automated assistant 120 having been invoked or invited to joining the group chat as a participant.
- group chat analysis service 138 may be implemented entirely separately from GP automated assistant 120 .
- a single group chat analysis service 138 may be deployed in a one-to-many relationship with a plurality of GP automated assistants 120 .
- FIG. 2 depicts an example group chat with three participants: a user (“YOU” in FIG. 2 ) that operates a client device 206 (which in this example is a smart phone or tablet but that is not meant to be limiting) and two other users, Jim and Alex.
- Client device 206 includes a touchscreen 240 , a transcript 242 of a message exchange thread (i.e. group chat) between the participants, and an input field 244 that may receive text, speech-to-text, or other types of input (e.g., images) from the user that operates client device 206 .
- GP automated assistant 120 may determine whether to proactively incorporate content into the group chat, and if so, what content to incorporate. For example, in some implementations, GP automated assistant 120 may analyze content of the group chat and identify, based on the analyzing, one or more topics discussed by the participants. In this example, the group chat is relatively new, so relatively few topics such as “sports” and “football” have been raised.
- sports is a relatively high level topic that encompasses myriad sub-topics such as specific sports, leagues, teams, players, games, etc.
- a person may be a fan of one sport (e.g., baseball) without having any interest whatsoever in another sport (e.g., auto racing).
- sport e.g., baseball
- sports e.g., auto racing
- football is ambiguous in that it could refer to American Football (e.g., the National Football League, college or high school football, “pigskin,” etc.) or football as much of the rest of the world thinks of it, which in the United States is usually referred to as “soccer.”
- GP automated assistant 120 may not be in a position to proactively incorporate content that likely will be well-received by the group chat participants. Accordingly, in various implementations, GP automated assistant 120 may identify, based on individual participant profiles associated with the participants of the group chat, one or more shared interests of the participants. As noted above, in some implementations, these individual participant profiles may be provided by user-controlled resources engine 130 in accordance with permissions stored in access control list 126 . In this example, suppose the respective participant profiles indicate that each group chat participant, or in some cases at least a majority of the group chat participants, are located inside of the United States. In various implementations, GP automated assistant 120 may use this information to disambiguate “football” to “American Football.”
- GP automated assistant 120 may ascertain from the respective participant profiles that each participant, or in some cases a majority of the participants, is interested in a particular American Football team, “team A” (enclosed in braces in FIG. 2 because it is a hypothetical team). Accordingly, GP automated assistant 120 may have enough information to intelligently select content to proactively incorporate into the group chat.
- GP automated assistant 120 (“AA” in FIG. 2 ) incorporates the statement “ ⁇ team A's> first game against ⁇ team B> is scheduled for Aug.
- GP automated assistant 120 may also incorporate other types of content, such as hyperlinks that when selected cause a web browser to open a document associated with a network address, or so-called “deeplinks” that when selected cause another application installed on client device 206 to open, e.g., in a predetermined state.
- a first graphical element 246 A comprises a hyperlink or deeplink to a web page or pre-loaded application that a user may operate to procure tickets to the game.
- a second graphical element 246 B comprises a hyperlink or deeplink that is selectable by the user to add the game to his or her calendar.
- a third graphical 246 C element comprises a hyperlink or deeplink that is operably by the used to cause the game to be recorded, e.g., by a digital video recorder (“DVR”).
- DVR digital video recorder
- GP automated assistant 120 is not limited to proactively incorporating new content into a group chat.
- GP automated assistant 120 may provide new content to participants using other interfaces and/or output modalities.
- new developments related to those shared interests/topics e.g., news stories
- one or more GP automated assistants 120 serving one or more of the participants may determine that new content is available that pertains to the shared interest. This content may be provided to the participants as, for example, text messages, notifications (e.g., on a lock screen), via graphical “cards,” audible output, haptic output, etc.
- each participant receives the proactively provided new content in the same manner, nor is it necessary that each participant necessarily receive the new content at all (e.g., a participant may elect not to receive such notifications).
- whether a particular group chat participant receives new content may depend on a variety of factors, such as how the participant has consumed such notifications in the past (e.g., clicked on them, rejected them by swiping them away, etc.) and/or based on feedback from the participant.
- GP automated assistant 120 proactively incorporates new content into a group chat that is not currently active (e.g., no participants currently have the group chat application open)
- the participants may nonetheless receive notification, e.g., as a number in parenthesis or other symbol within or adjacent a graphical element that represents the group chat or the application in which the participant accesses the group chat.
- new content that is proactively provided to a participant may also be used as signals for other activities engaged in by the participant using a computing device.
- alternative query suggestions that are selected for provision to a participant when the participant begins inputting text into a search field may be influenced (e.g., ranked) by new content that is provided to the participant using techniques described herein.
- proactively provided new content may be used to rank search results presented to the user and/or suggestions for media content. For example, the next song played back by a participant's streaming music service may be selected based at least in part on new content provided to the participant using techniques described herein.
- a participant profile may be adjusted based on feedback from the participant in response to proactively provided content. For example, suppose multiple participants in a group chat are determined to share a particular interest. This may be determined, for example, from search histories and browsing histories of the respective users. Now, suppose that a client device 106 operated by a given participant of the group chat participants is also often operated, for instance, by other members of the given participant's family with different interests. These different interests may nonetheless be attributed to the given participant, even if the given participant in fact does not have those interests. Consequently, those interests may be detected and, if shared with other participants in the group chat, used to select content to proactively provide to all the group chat participants.
- the given participant may reject this content, e.g., by swiping it away, or by providing more explicit negative feedback (e.g., clicking on a “not helpful” button). That negative feedback may then be used to modify the given participant's profile to exclude that interest.
- newly-initiated group chats may lack sufficient content alone to enable automated assistants (GP automated assistant 120 and/or one or more domain-specific bots) to proactively incorporate content in an effective manner.
- automated assistants GP automated assistant 120 and/or one or more domain-specific bots
- One or more terms may be raised by participants that are susceptible to multiple interpretations. Without more information, irrelevant information may be proactively incorporated into the group chat. That is why, as noted above, with relatively newly established group chats, individual participant profiles may also be utilized to determine shared interests, which then may be used to select content to proactively provide to group chat participants.
- an amount of influence shared participant interests have on selecting new content to proactively incorporate into the group chat may diminish based on a length of the message exchange thread. For example, the longer a temporal lifetime of the group chat, or the greater number of messages in the group chat, the more heavily topics of discussion may influence selection of content for proactive incorporation, relative to shared interests. As more topics are raised and discussed, GP automated assistants 120 and/or domain-specific bots may be better able to proactively incorporate content that is more likely to be well-received by the human participants.
- FIG. 3 demonstrates one example of the type of new content that may be proactivity incorporated into a group chat (or otherwise pushed to group chat participants) as the group chat matures.
- Client device 206 may be the same user's client device as was depicted in FIG. 2 .
- a number of weeks or months have passed since the group conversation depicted in FIG. 2 occurred, such that the NFL season has reached the playoffs.
- ⁇ team A> the team identified from the shared interests of the participants in FIG. 2 , has already been eliminated from contention. Consequently, topics pertaining to ⁇ team A> may not be as pertinent at this point in the season.
- GP automated assistant 120 (“AA” in FIG. 3 ) may proactively incorporate new content into the group chat.
- GP automated assistant 120 may search for and retrieve new content candidates based on the new topics, and then may rank the retrieved new content candidates on a variety of signals, such as older topics of conversations and/or shared user interests.
- GP automated assistant 120 may disambiguate between the multiple upcoming playoff games based on one or more shared interests of the participants.
- ⁇ team A> is in the NFC.
- GP automated assistant 120 may disambiguate between an upcoming AFC playoff game and an upcoming NFC playoff game based on this fact.
- GP automated assistant 120 may be able to disambiguate the phrase “starting QB” to two potential quarterbacks: the starting quarterbacks of the teams playing in the NFC playoff game.
- the term “available” may turn up in news stories and/or other data sources in relation to one of the NFC playoff teams, e.g., because that team's quarterback (John Jones) may have been injured recently, and there may be some question of him starting. This may enable GP automated assistant 120 to further disambiguate between the two NFC playoff teams. Accordingly, GP automated assistant 120 may proactively incorporate the following statement into the group chat: “John Jones' injury was upgraded last night. He is expected to start.”
- FIG. 4 depicts another example of techniques described herein being implemented, this time in the context of an audio conversation between multiple users (e.g., an “audio group chat” or “online teleconference”).
- a participant 401 is engaged in the audible conference with two other participants, Sarah and Samir, via a client device 406 that takes the form of a standalone interactive speaker.
- the multi-participant audio exchange may be implemented in various ways, such as using voice over IP, standard telephone infrastructure, or using other techniques often used to facilitate online conferences.
- client device 406 may be operating an instance of GP automated assistant client 118 , thereby allowing user 401 to engage in dialog with a GP automated assistant 120 .
- automated assistants such as the previously-described “bots” that often are tailored to specific domains, may be implemented in whole or in part on client device 406 , and/may be implemented on one or more remote computing systems (e.g., the cloud) such that content provided by the bot is audibly output at client device 406 .
- remote computing systems e.g., the cloud
- one or more automated assistants or other components may receive each user's audio inputs and convert those inputs into text, such that a transcript of the participants' conversation is available for analysis using techniques described herein.
- the participants may join the audio group chat of FIG. 4 using a particular application configured for such audio group chats.
- the application may (audible or visually) notify the participants that their conversation will be transcribed and used for analysis.
- the participants may have the option of opting out such transcription, e.g., as a group and/or on an individual participant basis. If all participants opt out, then no transcription may be made of the conversation. If only one participant opts out and one or more other participants opt in (or do not opt out), then any messages provided by the opted-out participant may not be transcribed/analyzed, and any analysis may be limited to messages provided by the other participant(s).
- one or more participants may be opted out automatically, without their having to provide explicit instructions. For example, if a particular participant consistently/frequently provides negative feedback in response to new content proactively provided using techniques described herein, then that participant may be opted out of transcription/analysis automatically. In some implementations, participants may be automatically opted out on a domain specific basis. For example, suppose a particular participant in a group chat has no interest in tennis, but that multiple other participants are keenly interest in tennis. In some implementations, only messages provided by participants with an interest in tennis may be transcribed/analyzed; messages provided by the disinterest participant may not.
- new tennis-related content that is proactively provided to other participants of the group chat may not be provided to the disinterested user (even in the message exchange thread itself; the disinterested user's message exchange client 107 may simply not receive the new content for display, and/or may elect not to present it).
- participant 401 may engage in the group chat using audio input (captured by a microphone) and audio output (one or more speakers).
- other participants such as Sarah and/or Samir in FIG. 4
- participant 401 begins by asking, “Do you guys want to hang out Friday night?” Sarah replies, “Sure. What should we do?” Samir replies, “I dunno, what do you guys think?”
- group chat analysis service 138 does not have many conversational topics to work with, other than the vague fact that the participants are making plans for Friday night.
- GP automated assistant 120 may consult with user-controlled resources engine 130 to analyze participant profiles with each of the participants to identify shared interests in, for instance, “movies” and “Laotian cuisine.” Based on these shared interest (and in some cases on geographic proximity of the participants determined from participant profiles), GP automated assistant 120 may identify new content for incorporation into the audio group chat.
- GP automated assistant 120 may search publicly-available data sources for information pertaining to local movie show times and available reservations at nearby Laotian restaurants. Consequently, GP automated assistant 120 proactively provides the following new content: “ ⁇ movie> is playing at ⁇ cinemas> at 7:30 that night. You could also grab some Laotian food at ⁇ Laotian restaurant> beforehand. I see a table for two is available at 6 . Shall I make a reservation?” Because client device 406 is an interactive standalone speaker (which may or may not include any display capabilities), this new content may be provided audibly by client device 406 , e.g., via one or more speakers. However, if one or more of the other participants is engaged in the group chat textually, e.g., by way of a message exchange client 107 , those one or more participants may receive the same new content in textual form.
- new content may be selected, even in a relatively new group chat, based on signals in addition to or instead of shared interests determined from participant profiles.
- multiple individuals may set up a group chat using enterprise chat software deployed, e.g., within a company or other organization.
- This enterprise chat software may enable individuals to associate group chats with particular documents and/or events.
- one individual (group chat coordinator) may create a calendar entry for a meeting with one or more other individuals.
- the group chat coordinator may configure the calendar event to be associated with a group chat (newly-established for the meeting or preexisting).
- the group chat coordinator may also add various information to the calendar entry, such as proposed topics of conversation (e.g., an agenda), one or more attached documents, etc.
- This added information may be analyzed, e.g., by GP automated assistant 120 , and used to select new content to proactively provide to the participants.
- the added information may include one or more topics extracted from a document associated with the group chat. Consequently, even early in a brand new group chat when few if any topics have been raised by participants, there may be sufficient preexisting topics for GP automated assistant 120 to intelligently select new content to proactively provide to participants.
- FIG. 5 is a flowchart illustrating an example method 500 according to implementations disclosed herein.
- This system may include various components of various computer systems, such as one or more components of GP automated assistant 120 (including group chat analysis service 138 ).
- operations of method 500 are shown in a particular order, this is not meant to be limiting. One or more operations may be reordered, omitted or added.
- the system may analyze, e.g., by way of one or more automated assistants 120 or other components such as group chat analysis service 138 , content of a message exchange thread (e.g., a textual, audio, and/or audio-visual group chat) involving multiple human participants.
- a message exchange thread e.g., a textual, audio, and/or audio-visual group chat
- the system may analyze, e.g., by way of one or more automated assistants 120 or other components such as group chat analysis service 138 , one or more documents associated with the message exchange thread. It should be understood that in some implementations, particularly when no documents are associated with the group chat, only the operations associated with block 502 may be performed.
- the system may identify, based on the analysis of block 502 and/or block 504 , one or more topics pertinent to the message exchange thread.
- topics Various conventional techniques may be employed to determine topics of discussion in a message exchange thread and/or an associated document (e.g., agenda, calendar entry, etc.).
- one or more topic classifiers may be employed, e.g., on an ongoing basis using a sliding window of message exchange thread content, to identify one or more current topics of discussion.
- Topic classifiers may take the form of machine learning models (supervised or unsupervised) or rules-based models.
- a topic classifier may be trained to provide output indicative of whether a particular topic is being discussed (e.g., binary output, or a probability). In other implementations, a topic classifier may be trained to provide output indicative of whether a plurality of different topics are being discussed. For example, a topic classifier may be configured to provide output indicating likelihoods or confidences that a plurality of different topics are being discussed. In some implementations, only those topics that have likelihoods/confidences that satisfy one or more thresholds may be identified as topics of discussion. In other implementations, only the n highest likelihood/confidence topics may be identified as topics of discussion.
- topic classification including but not limited to expectation maximization, term frequency-inverse document frequency (“td-idf”), na ⁇ ve Bayes classifiers, neural networks (e.g., instantaneously trained neural networks), support vector machines, various natural language processing approaches (e.g., topic segmentation), sentiment analysis, etc.
- td-idf term frequency-inverse document frequency
- na ⁇ ve Bayes classifiers e.g., instantaneously trained neural networks
- support vector machines e.g., topic segmentation
- natural language processing approaches e.g., topic segmentation
- sentiment analysis e.g., sentiment analysis, etc.
- the system may identify, e.g., based on individual participant profiles associated with the participants (e.g., information stored in user-controlled resources 128 , locally on client devices 106 , etc.), one or more shared interests of the participants. These shared interests may be identified based on a variety of different signals, including but not limited one or more position coordinates (e.g., current, historical, recent, etc.), browsing histories, searching histories, explicitly-set preferences, calendar entries (e.g., all or most participants scheduled to attend the same event(s)), reminder lists, shopping lists, etc.
- position coordinates e.g., current, historical, recent, etc.
- browsing histories e.g., searching histories, explicitly-set preferences
- calendar entries e.g., all or most participants scheduled to attend the same event(s)
- reminder lists e.g., shopping lists, etc.
- each participant it is not necessary that the same signal be used for each participant to identify an interest shared among most or all participants. For example, suppose a first participant in a group chat is associated with a position coordinate that is located in a particular city. Suppose a second participant has opted out of making position coordinates available, or that access control list 126 indicates that the other participants in the group chat (or group chat analysis service 138 ) lack sufficient permissions to access the second participant's position coordinate. In such a scenario, if the second participant's browsing history or search history (assuming these are available to group chat analysis service 138 ) indicate an interest in a particular sports team or other entities associated with the particular city, the second user may be assumed to share an interest in the particular city.
- every single participant share an interest for that interest to be used to select new content to proactively provide to the participants in a group chat. For example, suppose the majority of participants in a group chat exhibit an interest in a particular city. Even if participant profiles associated with the remaining minority of other participants do not include, respectively, data that explicitly suggests that they share interest in the particular city, so long as there is not information that tends to contradict their interests in the particular city, that particular city may be deemed a shared interest of the group chat participants.
- multiple shared interests may be identified, and the identified shared interests may be ranked, e.g., based on the number of participants that share those interests. In some such implementations, only the n (positive integer) highest ranking shared interests may be considered.
- the system may select new content to be proactively provided to participants in the group chat.
- the new content may be selected based on any pertinent topics that have been discussed (even if somewhat vague) in combination with the shared interests identified at block 508 .
- the topics that are used may be selected from the group chat itself or from document(s) associated with the group chat, such as attachments (e.g., agendas), documents that are linked to (e.g., by a participant) within the group chat, calendar entries associated with the group chat, etc.
- new content may take a variety of forms, such as recent news items corresponding to one or more topics/shared interests.
- the system may nonetheless select new content, e.g., as it becomes available. For example, suppose multiple participants of a group chat discuss an upcoming game. After the game is complete, information related to the outcome of the game may be selected at proactively provided (in block 512 discussed below) to the participants.
- the new content selected at block 510 may be proactively provided to one or more of the participants.
- the new content may be incorporated into the group chat, e.g., as a message provided by GP automated assistant 120 or in some cases by a domain-specific bot. It should be understood that this does not necessarily require that the new content be pushed to each client device, particularly in scenarios in which the group chat takes the form of an online forum, e.g., on a website.
- the new content may be pushed to each client device, e.g., as a notification separate from the group chat or within a local transcript of the group chat.
- the notification may be presented as a visual “card” that the user can select to obtain more information and/or take further action related to the new content.
- all participants need not necessarily be provided the new content, e.g., if they opted out or are disinterested in the topic/shared interest to which the new content relates.
- FIG. 6 is a block diagram of an example computing device 610 that may optionally be utilized to perform one or more aspects of techniques described herein.
- one or more of a client computing device, user-controlled resources engine 130 , and/or other component(s) may comprise one or more components of the example computing device 610 .
- Computing device 610 typically includes at least one processor 614 which communicates with a number of peripheral devices via bus subsystem 612 .
- peripheral devices may include a storage subsystem 624 , including, for example, a memory subsystem 625 and a file storage subsystem 626 , user interface output devices 620 , user interface input devices 622 , and a network interface subsystem 616 .
- the input and output devices allow user interaction with computing device 610 .
- Network interface subsystem 616 provides an interface to outside networks and is coupled to corresponding interface devices in other computing devices.
- User interface input devices 622 may include a keyboard, pointing devices such as a mouse, trackball, touchpad, or graphics tablet, a scanner, a touchscreen incorporated into the display, audio input devices such as voice recognition systems, microphones, and/or other types of input devices.
- pointing devices such as a mouse, trackball, touchpad, or graphics tablet
- audio input devices such as voice recognition systems, microphones, and/or other types of input devices.
- use of the term “input device” is intended to include all possible types of devices and ways to input information into computing device 610 or onto a communication network.
- User interface output devices 620 may include a display subsystem, a printer, a fax machine, or non-visual displays such as audio output devices.
- the display subsystem may include a cathode ray tube (CRT), a flat-panel device such as a liquid crystal display (LCD), a projection device, or some other mechanism for creating a visible image.
- the display subsystem may also provide non-visual display such as via audio output devices.
- output device is intended to include all possible types of devices and ways to output information from computing device 610 to the user or to another machine or computing device.
- Storage subsystem 624 stores programming and data constructs that provide the functionality of some or all of the modules described herein.
- the storage subsystem 624 may include the logic to perform selected aspects of the method of FIG. 5 , as well as to implement various components depicted in FIG. 1 .
- Memory 625 used in the storage subsystem 624 can include a number of memories including a main random access memory (RAM) 630 for storage of instructions and data during program execution and a read only memory (ROM) 632 in which fixed instructions are stored.
- a file storage subsystem 626 can provide persistent storage for program and data files, and may include a hard disk drive, a floppy disk drive along with associated removable media, a CD-ROM drive, an optical drive, or removable media cartridges.
- the modules implementing the functionality of certain implementations may be stored by file storage subsystem 626 in the storage subsystem 624 , or in other machines accessible by the processor(s) 614 .
- Bus subsystem 612 provides a mechanism for letting the various components and subsystems of computing device 610 communicate with each other as intended. Although bus subsystem 612 is shown schematically as a single bus, alternative implementations of the bus subsystem may use multiple busses.
- Computing device 610 can be of varying types including a workstation, server, computing cluster, blade server, server farm, or any other data processing system or computing device. Due to the ever-changing nature of computers and networks, the description of computing device 610 depicted in FIG. 6 is intended only as a specific example for purposes of illustrating some implementations. Many other configurations of computing device 610 are possible having more or fewer components than the computing device depicted in FIG. 6 .
- users are provided with one or more opportunities to control whether information is collected, whether the personal information is stored, whether the personal information is used, and how the information is collected about the user, stored and used. That is, the systems and methods discussed herein collect, store and/or use user personal information only upon receiving explicit authorization from the relevant users to do so.
- a user is provided with control over whether programs or features collect user information about that particular user or other users relevant to the program or feature.
- Each user for which personal information is to be collected is presented with one or more options to allow control over the information collection relevant to that user, to provide permission or authorization as to whether the information is collected and as to which portions of the information are to be collected.
- users can be provided with one or more such control options over a communication network.
- certain data may be treated in one or more ways before it is stored or used so that personally identifiable information is removed.
- a user's identity may be treated so that no personally identifiable information can be determined.
- a user's geographic location may be generalized to a larger region so that the user's particular location cannot be determined.
Abstract
Description
Claims (16)
Priority Applications (1)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US16/927,373 US11552814B2 (en) | 2017-06-29 | 2020-07-13 | Proactive provision of new content to group chat participants |
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US15/637,640 US10742435B2 (en) | 2017-06-29 | 2017-06-29 | Proactive provision of new content to group chat participants |
US16/927,373 US11552814B2 (en) | 2017-06-29 | 2020-07-13 | Proactive provision of new content to group chat participants |
Related Parent Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US15/637,640 Continuation US10742435B2 (en) | 2017-06-29 | 2017-06-29 | Proactive provision of new content to group chat participants |
Publications (2)
Publication Number | Publication Date |
---|---|
US20200344082A1 US20200344082A1 (en) | 2020-10-29 |
US11552814B2 true US11552814B2 (en) | 2023-01-10 |
Family
ID=63104002
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US15/637,640 Active 2037-12-22 US10742435B2 (en) | 2017-06-29 | 2017-06-29 | Proactive provision of new content to group chat participants |
US16/927,373 Active US11552814B2 (en) | 2017-06-29 | 2020-07-13 | Proactive provision of new content to group chat participants |
Family Applications Before (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
US15/637,640 Active 2037-12-22 US10742435B2 (en) | 2017-06-29 | 2017-06-29 | Proactive provision of new content to group chat participants |
Country Status (4)
Country | Link |
---|---|
US (2) | US10742435B2 (en) |
EP (2) | EP3513534B1 (en) |
CN (2) | CN114650263A (en) |
WO (1) | WO2019006146A1 (en) |
Families Citing this family (32)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US10742435B2 (en) | 2017-06-29 | 2020-08-11 | Google Llc | Proactive provision of new content to group chat participants |
US20190122526A1 (en) * | 2017-10-23 | 2019-04-25 | Qualcomm Incorporated | Automatic reminders generated through real time data |
US10771407B2 (en) * | 2017-12-29 | 2020-09-08 | Paypal, Inc. | Multi-level bot architecture for data access |
US10587553B1 (en) * | 2017-12-29 | 2020-03-10 | Entefy Inc. | Methods and systems to support adaptive multi-participant thread monitoring |
US11115360B2 (en) | 2018-07-30 | 2021-09-07 | Slack Technologies, Inc. | Method, apparatus, and computer program product for categorizing multiple group-based communication messages |
US11694278B2 (en) * | 2018-10-12 | 2023-07-04 | Yahoo Assets Llc | Automatic analysis of digital messaging content method and apparatus |
CN109547323B (en) * | 2018-10-17 | 2019-11-12 | 北京达佳互联信息技术有限公司 | Information processing method, device, server, terminal and storage medium |
US10616151B1 (en) | 2018-10-17 | 2020-04-07 | Asana, Inc. | Systems and methods for generating and presenting graphical user interfaces |
CN109873751B (en) * | 2019-01-11 | 2020-10-09 | 珠海格力电器股份有限公司 | Group chat voice information processing method and device, storage medium and server |
CN109873752B (en) * | 2019-01-25 | 2023-04-21 | 平安科技（深圳）有限公司 | Robot interaction method, device, storage medium and equipment in communication group |
US10977268B2 (en) * | 2019-05-31 | 2021-04-13 | Snowflake Inc. | Data exchange |
CN112015852A (en) * | 2019-05-31 | 2020-12-01 | 微软技术许可有限责任公司 | Providing responses in a session about an event |
US11270241B2 (en) * | 2019-06-13 | 2022-03-08 | Nice Ltd. | Systems and methods for discovery of automation opportunities |
US11204968B2 (en) | 2019-06-21 | 2021-12-21 | Microsoft Technology Licensing, Llc | Embedding layer in neural network for ranking candidates |
US11397742B2 (en) * | 2019-06-21 | 2022-07-26 | Microsoft Technology Licensing, Llc | Rescaling layer in neural network |
US11057320B2 (en) * | 2019-06-27 | 2021-07-06 | Walmart Apollo, Llc | Operation for multiple chat bots operation in organization |
JP7272893B2 (en) * | 2019-07-26 | 2023-05-12 | トヨタ自動車株式会社 | Control device |
US11258741B2 (en) * | 2019-08-15 | 2022-02-22 | Rovi Guides, Inc. | Systems and methods for automatically identifying spam in social media comments |
US11677703B2 (en) | 2019-08-15 | 2023-06-13 | Rovi Guides, Inc. | Systems and methods for automatically identifying spam in social media comments based on context |
US11461580B2 (en) | 2019-11-05 | 2022-10-04 | International Business Machines Corporation | Anchoring new concepts within a discussion community |
US11769497B2 (en) * | 2020-02-12 | 2023-09-26 | Apple Inc. | Digital assistant interaction in a video communication session environment |
US10819532B1 (en) | 2020-03-27 | 2020-10-27 | Ringcentral, Inc. | System and method for determining a source and topic of content for posting in a chat group |
US11410659B1 (en) * | 2020-03-30 | 2022-08-09 | Amazon Technologies, Inc. | Dynamic skill endpoint |
US11182748B1 (en) * | 2020-10-29 | 2021-11-23 | Microsoft Technology Licensing, Llc | Augmented data insight generation and provision |
WO2022125078A1 (en) * | 2020-12-08 | 2022-06-16 | Google Llc | Identifying and providing requested user information during voice calls and video calls |
US11763228B2 (en) | 2021-04-06 | 2023-09-19 | Nice Ltd. | Systems and methods for analyzing and connecting automation sequences |
US20220385605A1 (en) * | 2021-05-27 | 2022-12-01 | Microsoft Technology Licensing, Llc | Management of message threads generated from an intra-message split |
US11637798B2 (en) * | 2021-05-27 | 2023-04-25 | Microsoft Technology Licensing, Llc | Controlled display of related message threads |
US11652773B2 (en) | 2021-05-27 | 2023-05-16 | Microsoft Technology Licensing, Llc | Enhanced control of user interface formats for message threads based on device form factors or topic priorities |
US11716302B2 (en) | 2021-05-27 | 2023-08-01 | Microsoft Technology Licensing, Llc | Coordination of message thread groupings across devices of a communication system |
US20230403244A1 (en) * | 2021-06-15 | 2023-12-14 | Meta Platforms, Inc. | Methods, mediums, and systems for responding to a user service prompt |
WO2023102270A1 (en) * | 2021-12-03 | 2023-06-08 | Augusta Ai Llc | Systems and methods for inferring intent to opt-out of communications |
Citations (67)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
JP2001188784A (en) | 1999-12-28 | 2001-07-10 | Sony Corp | Device and method for processing conversation and recording medium |
JP2001290493A (en) | 2000-04-06 | 2001-10-19 | Asahi Kasei Corp | Automatic dialogue method |
JP2003108191A (en) | 2001-10-01 | 2003-04-11 | Toyota Central Res & Dev Lab Inc | Voice interacting device |
US6731307B1 (en) | 2000-10-30 | 2004-05-04 | Koninklije Philips Electronics N.V. | User interface/entertainment device that simulates personal interaction and responds to user's mental state and/or personality |
US20040162724A1 (en) | 2003-02-11 | 2004-08-19 | Jeffrey Hill | Management of conversations |
US20050054381A1 (en) | 2003-09-05 | 2005-03-10 | Samsung Electronics Co., Ltd. | Proactive user interface |
US20050131695A1 (en) | 1999-02-04 | 2005-06-16 | Mark Lucente | System and method for bilateral communication between a user and a system |
JP2005167628A (en) | 2003-12-02 | 2005-06-23 | Sony Corp | Information processor, informatino processing method, and computer program |
US20070201636A1 (en) | 2006-01-23 | 2007-08-30 | Icall, Inc. | System, method and computer program product for extracting user profiles and habits based on speech recognition and calling history for telephone system advertising |
US20080115068A1 (en) | 2006-11-13 | 2008-05-15 | International Business Machines Corporation | System and method to enhance instant messaging |
US20080189110A1 (en) | 2007-02-06 | 2008-08-07 | Tom Freeman | System and method for selecting and presenting advertisements based on natural language processing of voice-based input |
JP2009116552A (en) | 2007-11-05 | 2009-05-28 | Yahoo Japan Corp | Behavior attribute acquisition system and method for controlling the system |
US20090150156A1 (en) | 2007-12-11 | 2009-06-11 | Kennewick Michael R | System and method for providing a natural language voice user interface in an integrated voice navigation services environment |
CN101588323A (en) | 2009-06-11 | 2009-11-25 | 腾讯科技（深圳）有限公司 | Method and system for publishing message actively in IM group by using chat robots |
US20100088100A1 (en) | 2008-10-02 | 2010-04-08 | Lindahl Aram M | Electronic devices with voice command and contextual data processing capabilities |
US20100205541A1 (en) * | 2009-02-11 | 2010-08-12 | Jeffrey A. Rapaport | social network driven indexing system for instantly clustering people with concurrent focus on same topic into on-topic chat rooms and/or for generating on-topic search results tailored to user preferences regarding topic |
US20100217657A1 (en) | 1999-06-10 | 2010-08-26 | Gazdzinski Robert F | Adaptive information presentation apparatus and methods |
US20100241963A1 (en) | 2009-03-17 | 2010-09-23 | Kulis Zachary R | System, method, and apparatus for generating, customizing, distributing, and presenting an interactive audio publication |
US20100250672A1 (en) | 2009-03-27 | 2010-09-30 | Michael Steffen Vance | Providing event data to a group of contacts |
US20110066634A1 (en) | 2007-03-07 | 2011-03-17 | Phillips Michael S | Sending a communications header with voice recording to send metadata for use in speech recognition, formatting, and search in mobile search application |
WO2011088053A2 (en) | 2010-01-18 | 2011-07-21 | Apple Inc. | Intelligent automated assistant |
US20110271194A1 (en) | 2010-04-29 | 2011-11-03 | Google Inc. | Voice ad interactions as ad conversions |
US20120290950A1 (en) * | 2011-05-12 | 2012-11-15 | Jeffrey A. Rapaport | Social-topical adaptive networking (stan) system allowing for group based contextual transaction offers and acceptances and hot topic watchdogging |
CN102947823A (en) | 2010-04-01 | 2013-02-27 | 谷歌公司 | Conversational question and answer |
US20130159377A1 (en) | 2011-12-15 | 2013-06-20 | AsystMe, LLC | Proactive automated personal assistant |
US20130178388A1 (en) | 2008-05-14 | 2013-07-11 | Inserm (Institut National De La Sante Et De La Recherche Medicale) | Methods and Kits for the Diagnosis of Rheumatoid Arthritis |
US20130275164A1 (en) | 2010-01-18 | 2013-10-17 | Apple Inc. | Intelligent Automated Assistant |
US20130317823A1 (en) | 2012-05-23 | 2013-11-28 | Google Inc. | Customized voice action system |
US8612226B1 (en) | 2013-01-28 | 2013-12-17 | Google Inc. | Determining advertisements based on verbal inputs to applications on a computing device |
CN103577531A (en) | 2012-08-09 | 2014-02-12 | 国际商业机器公司 | Message subscription system and method based on message aggregate characteristics |
US20140129651A1 (en) | 2012-11-08 | 2014-05-08 | Ilya Gelfenbeyn | Human-assisted chat information system |
US20140229471A1 (en) * | 2013-02-12 | 2014-08-14 | International Business Machines Corporation | Ranking of meeting topics |
US20140278400A1 (en) | 2013-03-12 | 2014-09-18 | Microsoft Corporation | Search Results Using Intonation Nuances |
US20140310001A1 (en) | 2013-04-16 | 2014-10-16 | Sri International | Using Intents to Analyze and Personalize a User's Dialog Experience with a Virtual Personal Assistant |
US20150046147A1 (en) | 2008-04-15 | 2015-02-12 | Facebook, Inc. | Translation system information extraction |
CN104603830A (en) | 2012-07-03 | 2015-05-06 | 谷歌公司 | Creating social group events |
EP2884409A1 (en) | 2013-12-10 | 2015-06-17 | Harman International Industries, Incorporated | Context aware, proactive digital assistant |
US20150169284A1 (en) | 2013-12-16 | 2015-06-18 | Nuance Communications, Inc. | Systems and methods for providing a virtual assistant |
US20150169336A1 (en) | 2013-12-16 | 2015-06-18 | Nuance Communications, Inc. | Systems and methods for providing a virtual assistant |
US20150178388A1 (en) | 2013-12-19 | 2015-06-25 | Adobe Systems Incorporated | Interactive communication augmented with contextual information |
JP2015156231A (en) | 2010-06-17 | 2015-08-27 | マイクロソフト コーポレーション | Context based information aggregation system |
US20150254058A1 (en) | 2014-03-04 | 2015-09-10 | Microsoft Technology Licensing, Llc | Voice control shortcuts |
US20150269612A1 (en) | 2014-03-18 | 2015-09-24 | Microsoft Corporation | Entity platform and entity store |
WO2015187048A1 (en) | 2014-06-06 | 2015-12-10 | Obschestvo S Ogranichennoy Otvetstvennostiyu "Speactoit" | Proactive environment-based chat information system |
CN105359138A (en) | 2013-06-14 | 2016-02-24 | 微软技术许可有限责任公司 | Related content display associated with browsing |
US9368114B2 (en) | 2013-03-14 | 2016-06-14 | Apple Inc. | Context-sensitive handling of interruptions |
WO2016129276A1 (en) | 2015-02-12 | 2016-08-18 | パナソニックＩｐマネジメント株式会社 | Information dissemination method, server, information terminal device, system, and voice interaction system |
US20160294739A1 (en) | 2015-04-03 | 2016-10-06 | Xsell Technologies | Method and apparatus to increase personalization and enhance chat experiences on the internet |
CN106020488A (en) | 2016-06-03 | 2016-10-12 | 北京光年无限科技有限公司 | Man-machine interaction method and device for conversation system |
US20160321573A1 (en) | 2015-04-29 | 2016-11-03 | Microsoft Technology Licensing, Llc | Personalized contextual suggestion engine |
US20160373891A1 (en) * | 2005-09-14 | 2016-12-22 | Millennial Media Llc | Use of dynamic content generation parameters based on previous performance of those parameters |
US20170006356A1 (en) | 2015-07-01 | 2017-01-05 | Microsoft Corporation | Augmented experience of media presentation events |
US20170076327A1 (en) * | 2015-09-11 | 2017-03-16 | Yahoo! Inc. | Method and system for dynamically providing advertisements for comparison |
US20170083628A1 (en) | 2015-09-18 | 2017-03-23 | Facebook, Inc. | Detecting Key Topics on Online Social Networks |
CN106559321A (en) | 2016-12-01 | 2017-04-05 | 竹间智能科技（上海）有限公司 | The method and system of dynamic adjustment dialog strategy |
US20170180276A1 (en) | 2015-12-21 | 2017-06-22 | Google Inc. | Automatic suggestions and other content for messaging applications |
US9865260B1 (en) | 2017-05-03 | 2018-01-09 | Google Llc | Proactive incorporation of unsolicited content into human-to-computer dialogs |
US20180053114A1 (en) * | 2014-10-23 | 2018-02-22 | Brighterion, Inc. | Artificial intelligence for context classifier |
US20180061421A1 (en) | 2016-08-31 | 2018-03-01 | Microsoft Technology Licensing, Llc | Personalization of experiences with digital assistants in communal settings through voice and query processing |
US20180068656A1 (en) | 2016-09-02 | 2018-03-08 | Disney Enterprises, Inc. | Classifying Segments of Speech Based on Acoustic Features and Context |
US20180082682A1 (en) * | 2016-09-16 | 2018-03-22 | International Business Machines Corporation | Aerial drone companion device and a method of operating an aerial drone companion device |
US20180098030A1 (en) * | 2016-10-05 | 2018-04-05 | Avaya Inc. | Embedding content of interest in video conferencing |
US20180137856A1 (en) | 2016-11-15 | 2018-05-17 | At&T Intellectual Property I, L.P. | Asynchronous virtual assistant |
US20180183748A1 (en) * | 2016-12-27 | 2018-06-28 | Facebook, Inc. | Access Controls for Units of Content in a Messaging Service |
US20180373405A1 (en) * | 2017-06-27 | 2018-12-27 | Microsoft Technology Licensing, Llc | Targeted interest and content sharing platforms |
US10636418B2 (en) | 2017-03-22 | 2020-04-28 | Google Llc | Proactive incorporation of unsolicited content into human-to-computer dialogs |
US10742435B2 (en) | 2017-06-29 | 2020-08-11 | Google Llc | Proactive provision of new content to group chat participants |
Family Cites Families (10)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
WO2012135210A2 (en) * | 2011-03-31 | 2012-10-04 | Microsoft Corporation | Location-based conversational understanding |
GB2495222B (en) * | 2011-09-30 | 2016-10-26 | Apple Inc | Using context information to facilitate processing of commands in a virtual assistant |
US9465833B2 (en) * | 2012-07-31 | 2016-10-11 | Veveo, Inc. | Disambiguating user intent in conversational interaction system for large corpus information retrieval |
EP2912567A4 (en) * | 2012-12-11 | 2016-05-18 | Nuance Communications Inc | System and methods for virtual agent recommendation for multiple persons |
US9659298B2 (en) * | 2012-12-11 | 2017-05-23 | Nuance Communications, Inc. | Systems and methods for informing virtual agent recommendation |
AU2014274913B2 (en) * | 2013-06-07 | 2017-05-11 | Apple Inc. | Intelligent automated assistant |
CN105830048A (en) * | 2013-12-16 | 2016-08-03 | 纽昂斯通讯公司 | Systems and methods for providing a virtual assistant |
US9479931B2 (en) * | 2013-12-16 | 2016-10-25 | Nuance Communications, Inc. | Systems and methods for providing a virtual assistant |
CN104951428B (en) * | 2014-03-26 | 2019-04-16 | 阿里巴巴集团控股有限公司 | User's intension recognizing method and device |
CN105930367B (en) * | 2016-04-12 | 2020-06-09 | 华南师范大学 | Intelligent chat robot control method and control device |
-
2017
- 2017-06-29 US US15/637,640 patent/US10742435B2/en active Active
-
2018
- 2018-06-28 WO PCT/US2018/040057 patent/WO2019006146A1/en unknown
- 2018-06-28 EP EP18749908.2A patent/EP3513534B1/en active Active
- 2018-06-28 CN CN202210150947.5A patent/CN114650263A/en active Pending
- 2018-06-28 EP EP20213009.2A patent/EP3809643B1/en active Active
- 2018-06-28 CN CN201880035874.7A patent/CN110710170B/en active Active
-
2020
- 2020-07-13 US US16/927,373 patent/US11552814B2/en active Active
Patent Citations (74)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20050131695A1 (en) | 1999-02-04 | 2005-06-16 | Mark Lucente | System and method for bilateral communication between a user and a system |
US20100217657A1 (en) | 1999-06-10 | 2010-08-26 | Gazdzinski Robert F | Adaptive information presentation apparatus and methods |
JP2001188784A (en) | 1999-12-28 | 2001-07-10 | Sony Corp | Device and method for processing conversation and recording medium |
JP2001290493A (en) | 2000-04-06 | 2001-10-19 | Asahi Kasei Corp | Automatic dialogue method |
US6731307B1 (en) | 2000-10-30 | 2004-05-04 | Koninklije Philips Electronics N.V. | User interface/entertainment device that simulates personal interaction and responds to user's mental state and/or personality |
JP2003108191A (en) | 2001-10-01 | 2003-04-11 | Toyota Central Res & Dev Lab Inc | Voice interacting device |
US20040162724A1 (en) | 2003-02-11 | 2004-08-19 | Jeffrey Hill | Management of conversations |
US20050054381A1 (en) | 2003-09-05 | 2005-03-10 | Samsung Electronics Co., Ltd. | Proactive user interface |
JP2005167628A (en) | 2003-12-02 | 2005-06-23 | Sony Corp | Information processor, informatino processing method, and computer program |
US20160373891A1 (en) * | 2005-09-14 | 2016-12-22 | Millennial Media Llc | Use of dynamic content generation parameters based on previous performance of those parameters |
US20070201636A1 (en) | 2006-01-23 | 2007-08-30 | Icall, Inc. | System, method and computer program product for extracting user profiles and habits based on speech recognition and calling history for telephone system advertising |
US20130110505A1 (en) | 2006-09-08 | 2013-05-02 | Apple Inc. | Using Event Alert Text as Input to an Automated Assistant |
US9117447B2 (en) | 2006-09-08 | 2015-08-25 | Apple Inc. | Using event alert text as input to an automated assistant |
US20080115068A1 (en) | 2006-11-13 | 2008-05-15 | International Business Machines Corporation | System and method to enhance instant messaging |
US20080189110A1 (en) | 2007-02-06 | 2008-08-07 | Tom Freeman | System and method for selecting and presenting advertisements based on natural language processing of voice-based input |
US20110066634A1 (en) | 2007-03-07 | 2011-03-17 | Phillips Michael S | Sending a communications header with voice recording to send metadata for use in speech recognition, formatting, and search in mobile search application |
JP2009116552A (en) | 2007-11-05 | 2009-05-28 | Yahoo Japan Corp | Behavior attribute acquisition system and method for controlling the system |
US20090150156A1 (en) | 2007-12-11 | 2009-06-11 | Kennewick Michael R | System and method for providing a natural language voice user interface in an integrated voice navigation services environment |
US20150046147A1 (en) | 2008-04-15 | 2015-02-12 | Facebook, Inc. | Translation system information extraction |
US20130178388A1 (en) | 2008-05-14 | 2013-07-11 | Inserm (Institut National De La Sante Et De La Recherche Medicale) | Methods and Kits for the Diagnosis of Rheumatoid Arthritis |
US20100088100A1 (en) | 2008-10-02 | 2010-04-08 | Lindahl Aram M | Electronic devices with voice command and contextual data processing capabilities |
US20100205541A1 (en) * | 2009-02-11 | 2010-08-12 | Jeffrey A. Rapaport | social network driven indexing system for instantly clustering people with concurrent focus on same topic into on-topic chat rooms and/or for generating on-topic search results tailored to user preferences regarding topic |
US20140236953A1 (en) * | 2009-02-11 | 2014-08-21 | Jeffrey A. Rapaport | Methods using social topical adaptive networking system |
US20100241963A1 (en) | 2009-03-17 | 2010-09-23 | Kulis Zachary R | System, method, and apparatus for generating, customizing, distributing, and presenting an interactive audio publication |
US20100250672A1 (en) | 2009-03-27 | 2010-09-30 | Michael Steffen Vance | Providing event data to a group of contacts |
CN101588323A (en) | 2009-06-11 | 2009-11-25 | 腾讯科技（深圳）有限公司 | Method and system for publishing message actively in IM group by using chat robots |
WO2011088053A2 (en) | 2010-01-18 | 2011-07-21 | Apple Inc. | Intelligent automated assistant |
KR20130000423A (en) | 2010-01-18 | 2013-01-02 | 애플 인크. | Intent deduction based on previous user interactions with a voice assistant |
US20130275164A1 (en) | 2010-01-18 | 2013-10-17 | Apple Inc. | Intelligent Automated Assistant |
CN102792320A (en) | 2010-01-18 | 2012-11-21 | 苹果公司 | Intelligent automated assistant |
CN102947823A (en) | 2010-04-01 | 2013-02-27 | 谷歌公司 | Conversational question and answer |
US20110271194A1 (en) | 2010-04-29 | 2011-11-03 | Google Inc. | Voice ad interactions as ad conversions |
JP2015156231A (en) | 2010-06-17 | 2015-08-27 | マイクロソフト コーポレーション | Context based information aggregation system |
US20120290950A1 (en) * | 2011-05-12 | 2012-11-15 | Jeffrey A. Rapaport | Social-topical adaptive networking (stan) system allowing for group based contextual transaction offers and acceptances and hot topic watchdogging |
US20130159377A1 (en) | 2011-12-15 | 2013-06-20 | AsystMe, LLC | Proactive automated personal assistant |
US20130317823A1 (en) | 2012-05-23 | 2013-11-28 | Google Inc. | Customized voice action system |
CN104603830A (en) | 2012-07-03 | 2015-05-06 | 谷歌公司 | Creating social group events |
CN103577531A (en) | 2012-08-09 | 2014-02-12 | 国际商业机器公司 | Message subscription system and method based on message aggregate characteristics |
US20140129651A1 (en) | 2012-11-08 | 2014-05-08 | Ilya Gelfenbeyn | Human-assisted chat information system |
US8612226B1 (en) | 2013-01-28 | 2013-12-17 | Google Inc. | Determining advertisements based on verbal inputs to applications on a computing device |
US20140229471A1 (en) * | 2013-02-12 | 2014-08-14 | International Business Machines Corporation | Ranking of meeting topics |
US20140278400A1 (en) | 2013-03-12 | 2014-09-18 | Microsoft Corporation | Search Results Using Intonation Nuances |
US9368114B2 (en) | 2013-03-14 | 2016-06-14 | Apple Inc. | Context-sensitive handling of interruptions |
US20140310001A1 (en) | 2013-04-16 | 2014-10-16 | Sri International | Using Intents to Analyze and Personalize a User's Dialog Experience with a Virtual Personal Assistant |
CN105359138A (en) | 2013-06-14 | 2016-02-24 | 微软技术许可有限责任公司 | Related content display associated with browsing |
EP2884409A1 (en) | 2013-12-10 | 2015-06-17 | Harman International Industries, Incorporated | Context aware, proactive digital assistant |
US20150169284A1 (en) | 2013-12-16 | 2015-06-18 | Nuance Communications, Inc. | Systems and methods for providing a virtual assistant |
US20150169336A1 (en) | 2013-12-16 | 2015-06-18 | Nuance Communications, Inc. | Systems and methods for providing a virtual assistant |
US20150178388A1 (en) | 2013-12-19 | 2015-06-25 | Adobe Systems Incorporated | Interactive communication augmented with contextual information |
US20150254058A1 (en) | 2014-03-04 | 2015-09-10 | Microsoft Technology Licensing, Llc | Voice control shortcuts |
US20150269612A1 (en) | 2014-03-18 | 2015-09-24 | Microsoft Corporation | Entity platform and entity store |
WO2015187048A1 (en) | 2014-06-06 | 2015-12-10 | Obschestvo S Ogranichennoy Otvetstvennostiyu "Speactoit" | Proactive environment-based chat information system |
US20180053114A1 (en) * | 2014-10-23 | 2018-02-22 | Brighterion, Inc. | Artificial intelligence for context classifier |
WO2016129276A1 (en) | 2015-02-12 | 2016-08-18 | パナソニックＩｐマネジメント株式会社 | Information dissemination method, server, information terminal device, system, and voice interaction system |
US20160294739A1 (en) | 2015-04-03 | 2016-10-06 | Xsell Technologies | Method and apparatus to increase personalization and enhance chat experiences on the internet |
US20160321573A1 (en) | 2015-04-29 | 2016-11-03 | Microsoft Technology Licensing, Llc | Personalized contextual suggestion engine |
US20170006356A1 (en) | 2015-07-01 | 2017-01-05 | Microsoft Corporation | Augmented experience of media presentation events |
US20170076327A1 (en) * | 2015-09-11 | 2017-03-16 | Yahoo! Inc. | Method and system for dynamically providing advertisements for comparison |
US20170083628A1 (en) | 2015-09-18 | 2017-03-23 | Facebook, Inc. | Detecting Key Topics on Online Social Networks |
US20170180276A1 (en) | 2015-12-21 | 2017-06-22 | Google Inc. | Automatic suggestions and other content for messaging applications |
CN106020488A (en) | 2016-06-03 | 2016-10-12 | 北京光年无限科技有限公司 | Man-machine interaction method and device for conversation system |
US20180061421A1 (en) | 2016-08-31 | 2018-03-01 | Microsoft Technology Licensing, Llc | Personalization of experiences with digital assistants in communal settings through voice and query processing |
US20180068656A1 (en) | 2016-09-02 | 2018-03-08 | Disney Enterprises, Inc. | Classifying Segments of Speech Based on Acoustic Features and Context |
US20180082682A1 (en) * | 2016-09-16 | 2018-03-22 | International Business Machines Corporation | Aerial drone companion device and a method of operating an aerial drone companion device |
US20180098030A1 (en) * | 2016-10-05 | 2018-04-05 | Avaya Inc. | Embedding content of interest in video conferencing |
US20180137856A1 (en) | 2016-11-15 | 2018-05-17 | At&T Intellectual Property I, L.P. | Asynchronous virtual assistant |
CN106559321A (en) | 2016-12-01 | 2017-04-05 | 竹间智能科技（上海）有限公司 | The method and system of dynamic adjustment dialog strategy |
US20180183748A1 (en) * | 2016-12-27 | 2018-06-28 | Facebook, Inc. | Access Controls for Units of Content in a Messaging Service |
US10636418B2 (en) | 2017-03-22 | 2020-04-28 | Google Llc | Proactive incorporation of unsolicited content into human-to-computer dialogs |
US9865260B1 (en) | 2017-05-03 | 2018-01-09 | Google Llc | Proactive incorporation of unsolicited content into human-to-computer dialogs |
US10482882B2 (en) | 2017-05-03 | 2019-11-19 | Google Llc | Proactive incorporation of unsolicited content into human-to-computer dialogs |
US11114100B2 (en) | 2017-05-03 | 2021-09-07 | Google Llc | Proactive incorporation of unsolicited content into human-to-computer dialogs |
US20180373405A1 (en) * | 2017-06-27 | 2018-12-27 | Microsoft Technology Licensing, Llc | Targeted interest and content sharing platforms |
US10742435B2 (en) | 2017-06-29 | 2020-08-11 | Google Llc | Proactive provision of new content to group chat participants |
Non-Patent Citations (20)
Title |
---|
"Bots: An introduction for developers;" 13 sheets [online] [found on May 15, 2017], available in the Internet as URL: https://core.telegram.org/bots. |
Becker, Christian, et al. "Simulating the Emotion Dynamics of a Multimodal Conversational Agent." In Tutorial and Research Workshop on Affective Dialogue Systems, pp. 154-165. Springer Berlin Heidelberg, 2004. |
China National Intellectual Property Administration: Notice of Grant issued for Application No. 201880035874.7 dated Jan. 4, 2022. 4 pages. |
China National Intellectual Property Administration; Notification of First Office Action issued in Application No. 201880035874.7; 21 pages; dated Apr. 26, 2021. |
Constine, Josh "Facebook will launch group chatbots at F8;" Posted Mar. 29, 2017, TechCrunch, 9 sheets [online] [found on May 15, 2017], available in the Internet as URL: https://techcrunch.com/2017/03/29/facebook-group-bots/. |
European Patent Office; Communication issued in Application No. 20213009.2; 9 pages; dated Mar. 19, 2021. |
European Patent Office; Intention to Grant issued in Application No. 18749908.2; 48 pages; dated Oct. 13, 2020. |
European Patent Office; International Search Report and Written Opinion of PCT Ser. No. PCT/US2018/040057; 15 pages; dated Sep. 28, 2018. |
Japanese Patent Office: Office Action issued for Application No. 2019-560296 dated Nov. 2, 2020. |
Japanese Patent Office: Office Action issued in Application No. 2019-552127 dated Nov. 2, 2020. |
Japanese Patent Office; Notice of Reasons for Rejection issued in Application No. 2021-026066, 10 pages, dated Apr. 25, 2022. |
Koichiro Yoshino, Spoken Dialogue System based on Information Extraction from Web Text, Information Processing Society of Japan Research Report, H22, [CD ROM], Japan, Information Processing Society; dated 2010. |
Koshino et al., "Spoken Dialogue System based on Information Extraction from Web Text" The Special Interest Group Technical Reports of IPSJ Spoken Language Information Processing (SLP) No. 82, Aug. 15, 2010, pp. 1-6. |
Koshino et al., Spoken Dialogue System Based on Information Extraction and Presentation Using Similarity of Predicate Argument Structures (vol. 52, No. 12, pp. 3386-3397), Journal of Information Processing Society of Japan dated Dec. 15, 2011. |
Koshino et al., Spoken Dialogue System Using Information Extraction from the Web (No. 82, pp. 1-6), Information Processing Society of Japan, Spoken Language Processing (SLP) dated Oct. 15, 2010. |
L'Abbate, Marcello. "Modelling Proactive Behaviour of Conversational Interfaces." PhD diss., Technische Universität; 170 pages. 2006. |
McHugh, Molly "Slack is Overrun with Bots. Friendly, Wonderful Bots;" Aug. 21, 2015, Then One/Wired, 10 sheets [online] [found on May 15, 2017], available in the Internet as URL: https://www.wired.com/2015/08/slack-overrun-bots-friendly-wonderful-bots/. |
Metz, Rachel "Messaging App Adds and Assistant to the Conversation;" Apr. 4, 2014, MIT Technology Review, 9 sheets [online] [found on May 15, 2017], available in the Internet as URL: https://www.technologyreview.com/s/525991/messaging-app-adds-an-assistant-to-the-conversation/. |
Minker, W., et al. "Next-generation human-computer interfaces—towards intelligent, adaptive and proactive spoken language dialogue systems." In Intelligent Environments, 2006. IE 06. 2nd IET International Conference on (vol. 1, pp. 213-219). IET. |
The European Patent Office; Examination Report issued in Application No. 18749908.2 dated Sep. 27, 2019. |
Also Published As
Publication number | Publication date |
---|---|
EP3809643A1 (en) | 2021-04-21 |
EP3513534A1 (en) | 2019-07-24 |
WO2019006146A1 (en) | 2019-01-03 |
EP3513534B1 (en) | 2021-02-17 |
CN110710170B (en) | 2022-03-01 |
US20200344082A1 (en) | 2020-10-29 |
US20190007228A1 (en) | 2019-01-03 |
CN110710170A (en) | 2020-01-17 |
CN114650263A (en) | 2022-06-21 |
EP3809643B1 (en) | 2023-12-20 |
US10742435B2 (en) | 2020-08-11 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
US11552814B2 (en) | Proactive provision of new content to group chat participants | |
JP7443407B2 (en) | Automated assistant with conferencing capabilities | |
US10685187B2 (en) | Providing access to user-controlled resources by automated assistants | |
CN107391521B (en) | Automatically augmenting message exchange topics based on message classification | |
US11227017B2 (en) | Providing suggestions for interaction with an automated assistant in a multi-user message exchange thread | |
JP6942821B2 (en) | Obtaining response information from multiple corpora | |
CN112463104B (en) | Automatic assistant with conference function |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
FEPP | Fee payment procedure |
Free format text: ENTITY STATUS SET TO UNDISCOUNTED (ORIGINAL EVENT CODE: BIG.); ENTITY STATUS OF PATENT OWNER: LARGE ENTITY |
|
AS | Assignment |
Owner name: GOOGLE INC., CALIFORNIAFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:VUSKOVIC, VLADIMIR;ADAN, YARIV;SIGNING DATES FROM 20170629 TO 20170630;REEL/FRAME:053226/0022Owner name: GOOGLE LLC, CALIFORNIAFree format text: CHANGE OF NAME;ASSIGNOR:GOOGLE INC.;REEL/FRAME:053226/0047Effective date: 20170929 |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: DOCKETED NEW CASE - READY FOR EXAMINATION |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NON FINAL ACTION MAILED |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: RESPONSE TO NON-FINAL OFFICE ACTION ENTERED AND FORWARDED TO EXAMINER |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: FINAL REJECTION MAILED |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: DOCKETED NEW CASE - READY FOR EXAMINATION |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NOTICE OF ALLOWANCE MAILED -- APPLICATION RECEIVED IN OFFICE OF PUBLICATIONS |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: PUBLICATIONS -- ISSUE FEE PAYMENT VERIFIED |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: DOCKETED NEW CASE - READY FOR EXAMINATION |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: PUBLICATIONS -- ISSUE FEE PAYMENT VERIFIED |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: DOCKETED NEW CASE - READY FOR EXAMINATION |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: NOTICE OF ALLOWANCE MAILED -- APPLICATION RECEIVED IN OFFICE OF PUBLICATIONS |
|
STPP | Information on status: patent application and granting procedure in general |
Free format text: PUBLICATIONS -- ISSUE FEE PAYMENT VERIFIED |
|
STCF | Information on status: patent grant |
Free format text: PATENTED CASE |