EP3129984A1 - Mutual information based intelligibility enhancement - Google Patents
Mutual information based intelligibility enhancementInfo
- Publication number
- EP3129984A1 EP3129984A1 EP15715605.0A EP15715605A EP3129984A1 EP 3129984 A1 EP3129984 A1 EP 3129984A1 EP 15715605 A EP15715605 A EP 15715605A EP 3129984 A1 EP3129984 A1 EP 3129984A1
- Authority
- EP
- European Patent Office
- Prior art keywords
- signal
- audio signal
- noise
- intended
- user
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Ceased
Links
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04B—TRANSMISSION
- H04B15/00—Suppression or limitation of noise or interference
-
- G—PHYSICS
- G10—MUSICAL INSTRUMENTS; ACOUSTICS
- G10L—SPEECH ANALYSIS OR SYNTHESIS; SPEECH RECOGNITION; SPEECH OR VOICE PROCESSING; SPEECH OR AUDIO CODING OR DECODING
- G10L21/00—Processing of the speech or voice signal to produce another audible or non-audible signal, e.g. visual or tactile, in order to modify its quality or its intelligibility
- G10L21/02—Speech enhancement, e.g. noise reduction or echo cancellation
- G10L21/0316—Speech enhancement, e.g. noise reduction or echo cancellation by changing the amplitude
- G10L21/0364—Speech enhancement, e.g. noise reduction or echo cancellation by changing the amplitude for improving intelligibility
Definitions
- the present disclosure generally relates to methods and systems for signal processing. More specifically, aspects of the present disclosure relate to improving speech intelligibility in noisy environments.
- One embodiment of the present disclosure relates to a computer-implemented method for enhancing intelligibility of speech, the method comprising: receiving an approximation of an intended audio signal produced by a first user for play out to a second user; applying a modification algorithm to the audio signal prior to the audio signal being played out to the second user, the played out signal being mixed with channel noise to compose an observed signal, wherein the observed signal is approximated by the interpretation of the observed signal by the second user; and enhancing intelligibility of the audio signal played out to the second user by adjusting the modification algorithm to optimize mutual information between the intended signal and the interpreted signal.
- adjusting the modification algorithm to optimize the mutual information between the intended signal and the interpreted signal in the method for enhancing intelligibility of speech includes accounting for production and/or interpretation noise.
- applying the modification algorithm to the intended audio signal in the method for enhancing intelligibility of speech includes dividing the intended audio signal into a plurality of frequency bands and applying a gain to each of the frequency bands.
- Another embodiment of the present disclosure relates to a system for enhancing intelligibility of speech, the system comprising at least one processor and a computer- readable medium coupled to the at least one processor having instructions stored thereon which, when executed by the at least one processor, causes the at least one processor to: receive an approximation of an intended audio signal produced by a first user for play out to a second user; apply a modification algorithm to the audio signal prior to the audio signal being played out to the second user, the played out signal being mixed with channel noise to compose an observed signal, wherein the observed signal is approximated by the interpretation of the observed signal by the second user; and enhance intelligibility of the audio signal played out to the second user by adjusting the modification algorithm to optimize mutual information between the intended signal and the interpreted signal.
- the at least one processor in the system for enhancing intelligibility of speech is further caused to adjust the modification algorithm to optimize the mutual information between the intended signal and the interpreted signal by accounting for production and/or interpretation noise.
- the at least one processor in the system for enhancing intelligibility of speech is further caused to divide the intended audio signal into a plurality of frequency bands and apply a gain to each of the frequency bands.
- Yet another embodiment of the present disclosure relates to one or more non- transitory computer readable media storing computer-executable instructions that, when executed by one or more processors, causes the one or more processors to perform operations for enhancing intelligibility of speech comprising: receiving an approximation of an intended audio signal produced by a first user for play out to a second user; applying a modification algorithm to the audio signal prior to the audio signal being played out to the second user, the played out signal being mixed with channel noise to compose an observed signal, wherein the observed signal is approximated by the interpretation of the observed signal by the second user; and enhancing intelligibility of the audio signal played out to the second user by adjusting the modification algorithm to optimize mutual information between the intended signal and the interpreted signal.
- the one or more processors are caused to perform further operations comprising adjusting the modification algorithm to optimize the mutual information between the intended signal and the interpreted signal by accounting for production and/or interpretation noise.
- the methods and systems described herein may optionally include one or more of the following additional features: the approximation of the intended audio signal equals the intended audio signal; the interpreted signal equals the observed signal; the approximation of the intended audio signal equals the intended audio signal and the interpreted signal equals the observed signal, a difference between the intended audio signal and the approximation of the intended audio signal is attributable to additive production noise, a difference between the interpreted signal and the observed signal is attributable to additive interpretation noise; and/or the channel noise is environmental noise.
- Figure 1 is a schematic diagram illustrating an example application for speech intelligibility enhancement according to one or more embodiments described herein.
- Figure 2 is a block diagram illustrating an example system for speech intelligibility enhancement according to one or more embodiments described herein.
- Figure 3 is a block diagram illustrating an example system for speech intelligibility enhancement that accounts for production and/or interpretation noise according to one or more embodiments described herein.
- Figure 4 is a graphical representation illustrating example results for the maximization of mutual information between observed signals and uninterpreted signals in a noisy environment, for the linear frequency domain, according to one or more embodiments described herein.
- Figure 5 is a graphical representation illustrating example results for the maximization of mutual information between observed signals and uninterpreted signals in a noisy environment, for the equivalent rectangular bandwidth scale (ERB-scale) domain, according to one or more embodiments described herein.
- ERP-scale equivalent rectangular bandwidth scale
- Figure 6 is a graphical representation illustrating example results for the maximization of mutual information between unobserved signals and interpreted signals in a noisy environment, for the linear frequency domain with weighting, according to one or more embodiments described herein.
- Figure 7 is a graphical representation illustrating example results for the maximization of mutual information between unobserved signals and interpreted signals in a noisy environment, for the ERB-scale, according to one or more embodiments described herein.
- Figure 8 is a graphical representation illustrating example results of a speech intelligibility enhancement algorithm for a noise signal according to one or more embodiments described herein.
- Figure 9 is a graphical representation illustrating example results of a speech intelligibility enhancement algorithm for a noise signal and natural speech according to one or more embodiments described herein.
- Figure 10 is a graphical representation illustrating example results of a speech intelligibility enhancement algorithm for a noise signal and speech enhanced based on optimizing mutual information between the noisy observed signal and the uninterpreted signal according to one or more embodiments described herein.
- Figure 11 is a graphical representation illustrating example results of a speech intelligibility enhancement algorithm for a noise signal and speech enhanced based on optimizing mutual information between the noisy observed signal and the uninterpreted signal, and accounting for production and interpretation noise, according to one or more embodiments described herein.
- Figure 12 is a block diagram illustrating an example computing device arranged for improving intelligibility of speech in a noisy environment according to one or more embodiments described herein.
- Embodiments of the present disclosure provide methods and systems for improving the intelligibility of speech in a noisy environment.
- the speech intelligibility enhancement methods and systems described herein are based on a model of communication that maximizes mutual information between the observed signal and the received signal.
- the communication model accounts for noise inherent in the message production process as well as noise inherent in the message interpretation process.
- the production and interpretation noise processes have fixed signal-to-noise ratios.
- information theory can be used to define a simple yet effective model of human communication (it should be noted that the model also finds applicability to other biological communication systems, something that the model works well for, but is not optimal for infinite SNR).
- This communication model may then form the basis of an algorithm designed to optimize the intelligibility of speech in a noisy environment.
- the speech intelligibility optimization algorithm described herein utilizes informational theoretical concepts, rather than ad-hoc logic used by many existing approaches.
- the algorithm may include noise inherent in the message production process as well as the message interpretation process (so speech has a certain fidelity attached to it), and also considers the case where such inherent noise has a fixed signal-to-noise ratio.
- One advantage of the speech intelligibility optimization method described herein is that it only does something (e.g., manipulates the audio signal) when needed. As such, if there is no noise present, the algorithm does not alter or otherwise interfere with the audio signals, thereby preventing any speech distortion.
- Another advantage of the speech intelligibility optimization algorithm of the present disclosure is that the algorithm is very fast and efficient in comparison to most existing approaches. Accordingly, the algorithm lends itself to easy implementation in an appropriate device (e.g., cellular phone or smartphone).
- Production noise is typical of biological communication systems. For human communications, this can be seen at various levels of abstraction. The word choice to convey a message varies between occasions and between talkers. At a lower level of abstraction, speech can be seen as a sequence of discrete set of phonemes and the pronunciation of these phonemes varies significantly from one utterance to the next. This is reflected in the fact that some speech recognition techniques use statistical acoustic models. Similarly, the interpretation process for speech is noisy. For example, speech signals that are ambiguous in their pronunciation may be interpreted in various ways.
- FIG. 1 illustrates an example application in which the methods and systems for improving the intelligibility of speech in a noisy environment may be implemented, in accordance with one or more embodiments described herein.
- two users e.g., participants, individuals, parties, etc.
- 120a and 120b may be participating in an audio communication session at different physical locations (e.g., remote environments), where user 120a is at "Location 1" and user 120b is at "Location 2.”
- Also present at either or both of Location 1 and Location 2 may be one or more sources of noise 130 (e.g., music playing, automobiles, weather incidents, etc.).
- sources of noise 130 e.g., music playing, automobiles, weather incidents, etc.
- the users 120a and 120b may be in communication with each over, for example, a wired or wireless connection or network, and each of the users 120a and 120b may have a loudspeaker 105 and a microphone 110 for rendering and capturing, respectively, audio (e.g., speech) signals.
- audio e.g., speech
- a message S that is represented by a multidimensional stationary discrete-time signal.
- the signal is composed of scalar variables S k i , where k is the dimension index and i is the time index.
- the variables S k i may specify the complex amplitude or the gain in a particular time-frequency bin.
- the mutual information rate between the true multi-dimensional message sequence S and the received multi-dimensional message sequence Y describes the effectiveness of the communication process.
- the mutual information rate is equal to the mutual information /(S;; Y t ) between the multi-dimensional signals Sj and j at a particular time instant i.
- the following may be written:
- I(S i ; Y i ) ⁇ k I(S i ; Z i ) , (4) and the sequence S k i ⁇ X k i ⁇ Y k i ⁇ Z k i is now a Markov process.
- i time
- k represents the channel.
- the time subscript i may be omitted from the variance subscripts because the signals are stationary. It follows that the correlation coefficient between the message signal S i k and the actual signal X i k , denoted as p ⁇ k x k > is a fixed number on [0, 1].
- a fixed SNR for the interpretation noise is also reasonable.
- the auditory system contains a gain adaptation for each critical band, which naturally means that the precision of the interpretation scales with the signal over a significant dynamic range.
- the interpretation SNR can be considered fixed as well and the correlation coefficient P k z k can be considered as a fixed number on [0, 1].
- ERB equivalent rectangular bandwidth
- each ERB band is represented with one channel (e.g., one independent signal), with a signal power that equals all acoustic signal power observed across the ERB band in Hz (the linear frequency scale).
- One example objective of the methods and systems described herein is to optimize the effectiveness of the communication process by redistributing the variance between the channels, subject to a constraint on the overall variance.
- only the noisy message X (corresponding to the observable speech signal, as opposed to the true message S) may be available/accessible.
- the signal in channel k is multiplied by the scalar factor .
- the objective may now be formulated as
- B is the overall power constraint on the scaled observable signal Xi .
- equation (15) is a function only of the channel SNR, which is
- An example line search algorithm that may be used to determine the value of X that leads to the correct overall power is:
- a bi-section algorithm may be used to determine the value of X.
- FIG. 2 illustrates an example arrangement and data flows in a system 200 for enhancing intelligibility of speech in a noisy environment in accordance with one or more embodiments described herein.
- a far-end speech signal (210) may be modified at block 235 to optimize the intelligibility of the speech contained therein before the signal (210) is passed to block 240 for loudspeaker rendering, where the signal is played out to a user (e.g., human listener) 220 subject to environmental noise.
- a user e.g., human listener
- FIG. 3 illustrates another example arrangement and data flows in a system 300 for enhancing intelligibility of speech in a noisy environment in accordance with one or more embodiments described herein.
- blocks 330 thru 350 may correspond to solving for equation (16) described above.
- one or more of the example operations and/or data flows in systems 200 and 300, illustrated in FIGS. 2 and 3, respectively, may correspond to one or more of the operations, calculations, or determinations described above with respect to equations (1) - (25).
- the algorithm was performed on 16 kHz sampled speech and frequency dependent gains were implemented with Gabor analysis and synthesis filter banks with oversampling by a factor of two, a FFT size of 64 (resulting in 33 independent channels, of which 31 are complex and two are real), and a square-root Hann window.
- the Gabor filter bank was selected as it is a tight frame. It is important to note that while the selected gains may not be in the image of the forward transform (because of the oversampling), the inverse Gabor implicitly first projects onto that image.
- the power of each critical band was the sum of the signal powers in the Gabor filter bank channels within the band (it should be noted that the appropriate fraction of the power was used for instances where the critical bands are narrower than a Gabor filter).
- the appropriate gains were applied to the Gabor channels and the signal reconstructed with the Gabor synthesis filter bank.
- FIGS. 4-7 illustrate example behavior of the speech intelligibility enhancement algorithm in accordance with one or more of the embodiments described herein.
- the graphical representations shown in FIGS. 4-7 include results for all or part of an eight-second utterance spoken by an individual (e.g., a German- speaking male in this scenario).
- the noise was recorded in a train and the channel SNR for the selected examples is -5 dB, measured over the entire utterance.
- FIGS. 4 and 5 illustrate example results for the maximization of the mutual information between the observable signal Xi and the uninterpreted signal ?; in a noisy environment (e.g., a passenger train).
- FIGS. 4 and 5 consider the case where the production noise and the interpretation noise are zero.
- FIG. 4 is a graphical representation 400 showing the results for the linear frequency domain while
- FIG. 5 is a graphical representation 500 showing the results for the ERB domain.
- the graphical representation 400 illustrates the power ⁇
- assigned to the observed signal X k i /3 ⁇ 4 ' ⁇ fe (420), the power of the noise signal a ⁇ k (415), and the sum of these powers (410), for each frequency band k, for the case where the mutual information between the noisy observed signal Xi and the uninterpreted received signal Y t is optimized in the linear frequency domain.
- the graphical representation 500 illustrates (similar to graphical representation 400 shown in FIG. 4 and described above) the power assigned to the observed signal (520), the power of the noise signal (515), and the sum of these powers (510), for each frequency band k, for the case where the mutual information between the noisy observed signal X t and the uninterpreted received signal Y t is optimized in the ERB- scale domain.
- FIGS. 2 and 3 The graphical representations 200 and 300 shown in FIGS. 2 and 3, respectively, illustrate the waterfilling behavior expected when the production and interpretation noise are zero.
- the signal power and the noise power add to a constant, which is allowed by the overall constraint on power. It can be seen that for the higher frequency bands, the optimal gains b k for each band k of the observable signal X t are selected to make ⁇ + a jk a constant.
- FIGS. 6 and 7 illustrate what happens to the scenarios of the graphical representations 400 and 500 shown in FIGS. 4 and 5, respectively, if the production and interpretation SNR are considered (note that the graphical representations shown in FIGS. 4-7 are on the same scale).
- the graphical representation 700 illustrates (similar to graphical representation 600 shown in FIG. 6 and described above) the power assigned to the observed signal (720), the power of the noise signal (715), and the sum of these powers (710), for each frequency band k, for the case where the mutual information between the unobserved production signal Sj and the unobserved interpreted signal Z; is optimized in the ERB-scale domain.
- FIGS. 8-11 are spectrograms illustrating example behavior of the speech intelligibility enhancement algorithm of the present disclosure by means of the same utterance referred to in the above example (e.g., a speech fragment spoken by a German- speaking male). More particularly, spectrograms 840, 940, 1040, and 1140 illustrate example results for 1.3 seconds (s) of the utterance using the linear frequency scale. By the very nature of the algorithms described above (and illustrated in FIGS. 2 and 3), spectrograms 840, 940, 1040, and 1140 show small differences.
- Spectrogram 840 is for the noise signal, spectrogram 940 for the noise signal and natural speech, spectrogram 1040 for the noise signal and speech enhanced based on optimizing the mutual information between the noisy observed signal and the uninterpreted signal, and spectrogram 1140 for the noise signal and speech enhanced based on optimizing the mutual information between the noisy observed signal and the uninterpreted signal accounting for production and interpretation noise.
- Spectrogram 940 illustrates that natural speech is barely audible in the noisy environment at the selected channel SNR. In contrast, in the scenario where the mutual information between the noisy observed signal and the uninterpreted received signal is optimized, spectrogram 1040 illustrates that the signal is clearly audible at frequencies starting from around 2500 Hz.
- spectrogram 1140 illustrates that the resulting speech is both more intelligible and more pleasant sounding than in the case illustrated in spectrogram 1040.
- spectrogram 1140 shows that the speech signal is additionally enhanced in the region from 1500 to 3000 Hz.
- the reduced power at high frequencies does not affect intelligibility, while the enhancement in the mid-frequency range improves it significantly.
- the speech signal has a more natural spectral envelope when the production and interpretation noise are considered, the sound quality is significantly better.
- the transfer of power to low frequencies is further strengthened when the ERB-scale is used.
- the examples and embodiments of the present disclosure provide a straightforward model of speech communication for enhancing the intelligibility of speech in noisy environments.
- the model assumes that both the speech production and the speech interpretation processes are subject to noise that scales with the signal level, which is biologically plausible.
- the method for speech intelligibility enhancement works even when the production and interpretation noise are set to zero.
- model described herein indicates that the impact of noise during speech production and speech interpretation is similar, which implies that if production and interpretation fidelity come at a cost then efficient communication would result in similar signal-to-noise ratios for the production and interpretation processes (with the understanding that other functionalities of the speech production and interpretation systems may favor dissimilarities of these signal-to-noise ratios).
- the model also supports the proposal that the average spectral density of speech is a result of typical noise in the surrounding environment.
- the speech intelligibility optimization method of the present disclosure is based on the communication model described above, and assumes a Gaussian distribution of the speech. It should be understood that the behavior of the model may change when different distributions are assumed.
- FIG. 12 is a high-level block diagram of an exemplary computer (1200) arranged for enhancing the intelligibility of speech in a noisy environment, according to one or more embodiments described herein.
- the computing device (1200) typically includes one or more processors (1210) and system memory (1220).
- a memory bus (1230) can be used for communicating between the processor (1210) and the system memory (1220).
- the processor (1210) can be of any type including but not limited to a microprocessor ( ⁇ ), a microcontroller ( ⁇ ( ⁇ ), a digital signal processor (DSP), or any combination thereof.
- the processor (1210) can include one more levels of caching, such as a level one cache (1211) and a level two cache (1212), a processor core (1213), and registers (1214).
- the processor core (1213) can include an arithmetic logic unit (ALU), a floating point unit (FPU), a digital signal processing core (DSP Core), or any combination thereof.
- a memory controller (1216) can also be used with the processor (1210), or in some implementations the memory controller (1215) can be an internal part of the processor (1210).
- system memory (1220) can be of any type including but not limited to volatile memory (such as RAM), non-volatile memory (such as ROM, flash memory, etc.) or any combination thereof.
- System memory (1220) typically includes an operating system (1221), one or more applications (1222), and program data (1224).
- the application (1222) may include intelligibility enhancement algorithm (1223) for improving the intelligibility of speech in a noisy environment, in accordance with one or more embodiments described herein.
- Program Data (1224) may include storing instructions that, when executed by the one or more processing devices, implement a method for improving the intelligibility of speech in a noisy environment according to one or more embodiments described herein.
- program data (1224) may include audio signal data (1225), which may include data about production and/or interpretation noise (e.g., measurements of the production and/or interpretation noise levels).
- application (1222) can be arranged to operate with program data (1224) on an operating system (1221).
- the computing device (1200) can have additional features or functionality, and additional interfaces to facilitate communications between the basic configuration (1201) and any required devices and interfaces.
- System memory (1220) is an example of computer storage media.
- Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by computing device 1200. Any such computer storage media can be part of the device (1200).
- the computing device (1200) can be implemented as a portion of a small-form factor portable (or mobile) electronic device such as a cell phone, a smart phone, a personal data assistant (PDA), a personal media player device, a tablet computer (tablet), a wireless web-watch device, a personal headset device, an application-specific device, or a hybrid device that include any of the above functions.
- a small-form factor portable (or mobile) electronic device such as a cell phone, a smart phone, a personal data assistant (PDA), a personal media player device, a tablet computer (tablet), a wireless web-watch device, a personal headset device, an application-specific device, or a hybrid device that include any of the above functions.
- PDA personal data assistant
- tablet computer tablet computer
- non-transitory signal bearing medium examples include, but are not limited to, the following: a recordable type medium such as a floppy disk, a hard disk drive, a Compact Disc (CD), a Digital Video Disk (DVD), a digital tape, a computer memory, etc.; and a transmission type medium such as a digital and/or an analog communication medium (e.g., a fiber optic cable, a waveguide, a wired communications link, a wireless communication link, etc.).
Abstract
Description
Claims
Applications Claiming Priority (2)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/249,870 US10014961B2 (en) | 2014-04-10 | 2014-04-10 | Mutual information based intelligibility enhancement |
PCT/US2015/022724 WO2015157010A1 (en) | 2014-04-10 | 2015-03-26 | Mutual information based intelligibility enhancement |
Publications (1)
Publication Number | Publication Date |
---|---|
EP3129984A1 true EP3129984A1 (en) | 2017-02-15 |
Family
ID=52823862
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
EP15715605.0A Ceased EP3129984A1 (en) | 2014-04-10 | 2015-03-26 | Mutual information based intelligibility enhancement |
Country Status (3)
Country | Link |
---|---|
US (2) | US10014961B2 (en) |
EP (1) | EP3129984A1 (en) |
WO (1) | WO2015157010A1 (en) |
Families Citing this family (2)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11152015B2 (en) | 2017-03-22 | 2021-10-19 | Samsung Electronics Co., Ltd. | Method and apparatus for processing speech signal adaptive to noise environment |
US11335357B2 (en) * | 2018-08-14 | 2022-05-17 | Bose Corporation | Playback enhancement in audio systems |
Family Cites Families (4)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US7520851B2 (en) * | 1999-03-17 | 2009-04-21 | Neurominics Pty Limited | Tinnitus rehabilitation device and method |
US8615393B2 (en) | 2006-11-15 | 2013-12-24 | Microsoft Corporation | Noise suppressor for speech recognition |
US8632465B1 (en) * | 2009-11-03 | 2014-01-21 | Vivaquant Llc | Physiological signal denoising |
US9363614B2 (en) * | 2014-02-27 | 2016-06-07 | Widex A/S | Method of fitting a hearing aid system and a hearing aid fitting system |
-
2014
- 2014-04-10 US US14/249,870 patent/US10014961B2/en active Active
-
2015
- 2015-03-26 EP EP15715605.0A patent/EP3129984A1/en not_active Ceased
- 2015-03-26 WO PCT/US2015/022724 patent/WO2015157010A1/en active Application Filing
-
2018
- 2018-03-20 US US15/926,808 patent/US10396906B2/en active Active
Non-Patent Citations (2)
Title |
---|
None * |
See also references of WO2015157010A1 * |
Also Published As
Publication number | Publication date |
---|---|
US10014961B2 (en) | 2018-07-03 |
WO2015157010A1 (en) | 2015-10-15 |
US20150295662A1 (en) | 2015-10-15 |
US10396906B2 (en) | 2019-08-27 |
US20180212690A1 (en) | 2018-07-26 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
Kinoshita et al. | A summary of the REVERB challenge: state-of-the-art and remaining challenges in reverberant speech processing research | |
Das et al. | Fundamentals, present and future perspectives of speech enhancement | |
JP4805540B2 (en) | Stereo signal encoding | |
Ma et al. | Objective measures for predicting speech intelligibility in noisy conditions based on new band-importance functions | |
Wang | Time-frequency masking for speech separation and its potential for hearing aid design | |
JP4805541B2 (en) | Stereo signal encoding | |
Li et al. | An auditory-based feature extraction algorithm for robust speaker identification under mismatched conditions | |
US8880396B1 (en) | Spectrum reconstruction for automatic speech recognition | |
Kleijn et al. | Optimizing speech intelligibility in a noisy environment: A unified view | |
CN114203163A (en) | Audio signal processing method and device | |
Kumar | Real-time performance evaluation of modified cascaded median-based noise estimation for speech enhancement system | |
US20110066426A1 (en) | Real-time speaker-adaptive speech recognition apparatus and method | |
US9076446B2 (en) | Method and apparatus for robust speaker and speech recognition | |
Müller et al. | Contextual invariant-integration features for improved speaker-independent speech recognition | |
US10396906B2 (en) | Mutual information based intelligibility enhancement | |
Morita et al. | Robust voice activity detection based on concept of modulation transfer function in noisy reverberant environments | |
Yang et al. | Deep ad-hoc beamforming based on speaker extraction for target-dependent speech separation | |
Jokinen et al. | Signal-to-noise ratio adaptive post-filtering method for intelligibility enhancement of telephone speech | |
US9866955B2 (en) | Enhancement of intelligibility in noisy environment | |
US20220406325A1 (en) | Audio Processing Method, Method for Training Estimation Model, and Audio Processing System | |
CN113241090B (en) | Multichannel blind sound source separation method based on minimum volume constraint | |
Zhang et al. | A speech separation algorithm based on the comb-filter effect | |
Li et al. | A near-end listening enhancement system by RNN-based noise cancellation and speech modification | |
Shu et al. | A human auditory perception loss function using modified bark spectral distortion for speech enhancement | |
Hu et al. | Learnable spectral dimension compression mapping for full-band speech enhancement |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: THE INTERNATIONAL PUBLICATION HAS BEEN MADE |
|
PUAI | Public reference made under article 153(3) epc to a published international application that has entered the european phase |
Free format text: ORIGINAL CODE: 0009012 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: REQUEST FOR EXAMINATION WAS MADE |
|
17P | Request for examination filed |
Effective date: 20161019 |
|
AK | Designated contracting states |
Kind code of ref document: A1Designated state(s): AL AT BE BG CH CY CZ DE DK EE ES FI FR GB GR HR HU IE IS IT LI LT LU LV MC MK MT NL NO PL PT RO RS SE SI SK SM TR |
|
AX | Request for extension of the european patent |
Extension state: BA ME |
|
DAV | Request for validation of the european patent (deleted) | ||
DAX | Request for extension of the european patent (deleted) | ||
RAP1 | Party data changed (applicant data changed or rights of an application transferred) |
Owner name: GOOGLE LLC |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: EXAMINATION IS IN PROGRESS |
|
17Q | First examination report despatched |
Effective date: 20190204 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: EXAMINATION IS IN PROGRESS |
|
REG | Reference to a national code |
Ref country code: DERef legal event code: R003 |
|
STAA | Information on the status of an ep patent application or granted ep patent |
Free format text: STATUS: THE APPLICATION HAS BEEN REFUSED |
|
18R | Application refused |
Effective date: 20211019 |
|
P01 | Opt-out of the competence of the unified patent court (upc) registered |
Effective date: 20230519 |