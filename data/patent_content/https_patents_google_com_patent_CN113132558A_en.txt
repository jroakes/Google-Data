CN113132558A - Architecture for high performance power efficient programmable image processing - Google Patents
Architecture for high performance power efficient programmable image processing Download PDFInfo
- Publication number
- CN113132558A CN113132558A CN202110291114.6A CN202110291114A CN113132558A CN 113132558 A CN113132558 A CN 113132558A CN 202110291114 A CN202110291114 A CN 202110291114A CN 113132558 A CN113132558 A CN 113132558A
- Authority
- CN
- China
- Prior art keywords
- processor
- dimensional
- shift register
- array
- processing element
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
- 238000012545 processing Methods 0.000 title claims abstract description 86
- 239000000872 buffer Substances 0.000 claims abstract description 51
- 238000000034 method Methods 0.000 claims abstract description 48
- 239000012634 fragment Substances 0.000 claims 2
- 230000008569 process Effects 0.000 abstract description 35
- 230000006870 function Effects 0.000 description 15
- 238000013461 design Methods 0.000 description 9
- 238000003860 storage Methods 0.000 description 7
- 230000000694 effects Effects 0.000 description 6
- 238000011161 development Methods 0.000 description 5
- 230000009466 transformation Effects 0.000 description 5
- 238000013459 approach Methods 0.000 description 4
- 210000004027 cell Anatomy 0.000 description 4
- 238000005516 engineering process Methods 0.000 description 4
- 210000003126 m-cell Anatomy 0.000 description 3
- 238000007726 management method Methods 0.000 description 3
- 238000004891 communication Methods 0.000 description 2
- 230000003287 optical effect Effects 0.000 description 2
- 239000004065 semiconductor Substances 0.000 description 2
- 239000007787 solid Substances 0.000 description 2
- 230000000007 visual effect Effects 0.000 description 2
- 241000872198 Serjania polyphylla Species 0.000 description 1
- 229910000831 Steel Inorganic materials 0.000 description 1
- 230000003044 adaptive effect Effects 0.000 description 1
- 230000006399 behavior Effects 0.000 description 1
- 230000003542 behavioural effect Effects 0.000 description 1
- 238000004364 calculation method Methods 0.000 description 1
- 230000001413 cellular effect Effects 0.000 description 1
- 238000006243 chemical reaction Methods 0.000 description 1
- 238000004590 computer program Methods 0.000 description 1
- 239000000470 constituent Substances 0.000 description 1
- 238000010276 construction Methods 0.000 description 1
- 238000012937 correction Methods 0.000 description 1
- 230000001186 cumulative effect Effects 0.000 description 1
- 238000013500 data storage Methods 0.000 description 1
- 238000001514 detection method Methods 0.000 description 1
- 125000001475 halogen functional group Chemical group 0.000 description 1
- 238000003384 imaging method Methods 0.000 description 1
- 238000010801 machine learning Methods 0.000 description 1
- 238000004519 manufacturing process Methods 0.000 description 1
- 238000013507 mapping Methods 0.000 description 1
- 230000000873 masking effect Effects 0.000 description 1
- 238000007620 mathematical function Methods 0.000 description 1
- 239000011159 matrix material Substances 0.000 description 1
- 239000000203 mixture Substances 0.000 description 1
- 238000012986 modification Methods 0.000 description 1
- 230000004048 modification Effects 0.000 description 1
- 238000009877 rendering Methods 0.000 description 1
- 238000004088 simulation Methods 0.000 description 1
- 230000007480 spreading Effects 0.000 description 1
- 238000003892 spreading Methods 0.000 description 1
- 230000003068 static effect Effects 0.000 description 1
- 239000010959 steel Substances 0.000 description 1
- 238000012546 transfer Methods 0.000 description 1
- 238000012800 visualization Methods 0.000 description 1
Images
Classifications
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N5/00—Details of television systems
- H04N5/14—Picture signal circuitry for video frequency region
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T1/00—General purpose image data processing
- G06T1/20—Processor architectures; Processor configuration, e.g. pipelining
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06T—IMAGE DATA PROCESSING OR GENERATION, IN GENERAL
- G06T1/00—General purpose image data processing
- G06T1/60—Memory management
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N25/00—Circuitry of solid-state image sensors [SSIS]; Control thereof
- H04N25/70—SSIS architectures; Circuits associated therewith
- H04N25/71—Charge-coupled device [CCD] sensors; Charge-transfer registers specially adapted for CCD sensors
- H04N25/75—Circuitry for providing, modifying or processing image signals from the pixel array
-
- H—ELECTRICITY
- H04—ELECTRIC COMMUNICATION TECHNIQUE
- H04N—PICTORIAL COMMUNICATION, e.g. TELEVISION
- H04N5/00—Details of television systems
- H04N5/76—Television signal recording
- H04N5/91—Television signal processing therefor
-
- Y—GENERAL TAGGING OF NEW TECHNOLOGICAL DEVELOPMENTS; GENERAL TAGGING OF CROSS-SECTIONAL TECHNOLOGIES SPANNING OVER SEVERAL SECTIONS OF THE IPC; TECHNICAL SUBJECTS COVERED BY FORMER USPC CROSS-REFERENCE ART COLLECTIONS [XRACs] AND DIGESTS
- Y02—TECHNOLOGIES OR APPLICATIONS FOR MITIGATION OR ADAPTATION AGAINST CLIMATE CHANGE
- Y02D—CLIMATE CHANGE MITIGATION TECHNOLOGIES IN INFORMATION AND COMMUNICATION TECHNOLOGIES [ICT], I.E. INFORMATION AND COMMUNICATION TECHNOLOGIES AIMING AT THE REDUCTION OF THEIR OWN ENERGY USE
- Y02D10/00—Energy efficient computing, e.g. low power processors, power management or thermal management
Abstract
The present disclosure relates to an architecture for high performance power efficient programmable image processing. An apparatus includes an image processing unit including a network. The image processing unit includes a plurality of mask processor circuits, each mask processor circuit including an array of execution unit channels coupled to a two-dimensional shift register array structure to simultaneously process a plurality of overlapping masks by executing program code. The image processing unit includes a plurality of table generators correspondingly coupled between the plurality of stencil processors and the network, for parsing input line groups of the image data into input tables of the image data for processing by the stencil processors, and for forming output line groups of the image data from output tables of the image data received from the stencil processors. The image processing unit includes a plurality of line buffer units coupled to the network to pass line groups in a direction from producing stencil processors to consuming stencil processors to implement the overall program flow.
Description
Description of the cases
The application belongs to divisional application of Chinese patent application 201680019775.0 with the application date of 2016, 4 and 6.
Technical Field
The field of the invention relates generally to image processing and, more particularly, to an architecture for high performance power efficient programmable image processing
Background
Image processing typically involves the processing of pixel values organized into an array. Here, a two-dimensional array of spatial tissue captures the two-dimensional nature of the image (additional dimensions may include time (e.g., a sequence of two-dimensional images) and data type (e.g., color)). In the general case, the array pixel values are provided by a camera that has generated a still image or a sequence of frames to capture a moving image. Conventional image processors typically fall on either side of two extremes.
The first extreme considers image processing to be performed as a software program executing on a general purpose processor or a general purpose-like processor (e.g., a general purpose processor with vector instruction enhancements). While the first extreme typically provides a highly versatile application software development platform, its use of finer-grained data structures and associated overhead (e.g., instruction fetch and decode, processing of on-chip and off-chip data, speculative execution) ultimately results in a greater amount of energy being consumed per unit of data during execution of the program code.
The second opposite extreme applies fixed function hard-wired circuitry to larger blocks of data. The use of larger (relative to finer granularity) blocks of data directly applied to custom designed circuits greatly reduces power consumption per unit of data. However, the use of custom designed fixed function circuits often results in a limited set of tasks that the processor is capable of performing. Thus, a widely common programming environment (associated with the first extreme) is lacking under the second extreme.
A technology platform that provides a highly versatile opportunity for application software development combined with improved efficacy per unit of data remains a desirable but missing solution.
Disclosure of Invention
An apparatus is described. The apparatus includes an Image Processing Unit (IPU). The image processing unit includes a network. The image processing unit includes a plurality of mask processor circuits, each of the plurality of mask processor circuits including an array of execution unit lanes coupled to the two-dimensional shift register array structure to simultaneously process the plurality of overlapping masks by executing the program code. The image processing unit includes a plurality of tile generators correspondingly coupled between the plurality of stencil processors and the network. The patch generator is for parsing input line groups of image data into input patches of image data for processing by the stencil processor, and for forming output line groups of image data from output patches of image data received from the stencil processor. The image processing unit includes a plurality of line buffer units coupled to the network to pass line groups in a direction from producing stencil processors to consuming stencil processors to implement the overall program flow.
Drawings
The following description and the annexed drawings set forth in detail certain illustrative embodiments of the invention. In the drawings:
FIG. 1 illustrates an embodiment of an image processor hardware architecture;
2a, 2b, 2c, 2d, and 2e illustrate operations performed on a sheet with overlapping masks to parse image data into line groups, to parse line groups into sheets;
FIG. 3a illustrates an embodiment of an stencil processor;
FIG. 3b illustrates an embodiment of an instruction word for a stencil processor;
FIG. 4 illustrates an embodiment of a data computation unit within an stencil processor;
5a, 5b, 5c, 5d, 5e, 5f, 5g, 5h, 5i, 5j and 5k illustrate an example of using a two-dimensional shift array and execution channel array to determine a pair of adjacent output pixel values using overlapping masks;
FIG. 6 illustrates an embodiment of a unit cell for integrating an execution lane array and a two-dimensional shift array;
FIG. 7 illustrates a process for developing and implementing image processing program code;
FIG. 8 relates to a process for configuring an image processor;
FIGS. 9a and 9b relate to the operation of a line buffer unit;
FIG. 10a and FIG. 10b relate to a DAG program flow;
11a, 11b and 11c relate to a pipelined program flow;
FIG. 12 illustrates an exemplary computing system.
Detailed Description
a. Image processor hardware architecture and operation
Fig. 1 shows an embodiment of an architecture 100 for an image processor implemented in hardware. The image processor may, for example, be the target of a compiler that converts program code written for a virtual processor within a simulation environment into program code that is actually executed by a hardware processor. As shown in fig. 1, architecture 100 includes a plurality of line buffer units 101_1 through 101_ M interconnected with a plurality of mask (steel) processor units 102_1 through 102_ N and corresponding sheet (sheet) generator units 103_1 through 103-N by a network 104, e.g., a Network On Chip (NOC) comprising a network of switches on chip, a ring network on chip, or other type of network. In an embodiment, any line buffer unit may be connected to any tile generator and corresponding stencil processor through network 104.
In an embodiment, program code is compiled and loaded onto the respective stencil processors 102 to perform image processing operations defined by a software developer more previously (e.g., depending on design and implementation, the program code may also be loaded onto the stencil processor's associated sheet generator 103). In at least some examples, an image processing pipeline may be implemented by loading a first kernel program for a first pipeline stage into a first stencil processor 102_1, a second kernel program for a second pipeline stage into a second stencil processor 102_2, etc., where the first kernel performs the functions of the first stage of the pipeline, the second kernel performs the functions of the second stage of the pipeline, etc., and installing additional control flow methods to pass output image data from one stage of the pipeline to the next stage of the pipeline.
In other configurations, the image processor may be implemented as a parallel machine with two or more stencil processors 102_1, 102_2 operating the same kernel code. For example, a high density and high data rate image data stream may be processed by spreading frames across multiple stencil processors, each of which performs the same function.
In yet other configurations, essentially any DAG for a kernel may be loaded onto a hardware processor by: the corresponding stencil processor is configured with its own program code and appropriate control flow hooks (hooks) are configured into the hardware to direct the output image from one kernel to the input of the next kernel in the DAG design.
As a general flow, frames of image data are received by the macro I/O unit 105 and passed to one or more of the line buffer units 101 on a frame-by-frame basis. A particular line buffer unit parses its frame of image data into smaller regions of image data, called "line groups," and then passes the line groups through the network 104 to a particular tile generator. A complete or "full" single line group may, for example, consist of a number of consecutive complete rows or columns of data of a frame (for simplicity, this description will refer primarily to consecutive rows). The sheet generator further parses the line groups of image data into smaller regions of image data, called "sheets," and submits the sheets to their respective stencil processors.
In the case of an image processing pipeline or DAG stream with a single input, typically, the input frames are directed to the same line buffer unit 101_1, which parses the image data into line groups, and directs the line groups to a table generator 103_1, whose corresponding stencil processor 102_1 executes the code of the first core in the pipeline/DAG. When stencil processor 102_1 completes an operation on the line group it processes, tile generator 103_1 sends the output line group to "downstream" line buffer unit 101_2 (in some use cases, the output line group may be sent back to the same line buffer unit 101_1 that previously sent the input line group).
Then, one or more "consumer" kernels receive the image data generated by the first stencil processor 102_1 from the downstream line buffer unit 101_2, the one or more "consumer" kernels representing the next stage/operation in the pipeline/DAG executing on their own corresponding other tile generators and stencil processors (e.g., tile generator 103_2 and stencil processor 102_ 2). In this manner, a "producer" kernel operating on a first stencil processor forwards its output data to a "consumer" kernel operating on a second stencil processor, where the consumer kernel executes the next set of tasks after the producer kernel conforms to the design of the entire pipeline or DAG.
The mask processor 102 is designed to operate simultaneously on multiple overlapping masks of image data. The internal hardware processing capabilities of the multiple overlapping masks and mask processors effectively determine the size of the tableau. Here, within the mask processor 102, the execution channel array operates in unison to simultaneously process image data surface areas covered by multiple overlapping masks.
As will be described in greater detail below, in various embodiments, a table slice of image data is loaded into a two-dimensional register array structure within stencil processor 102. The use of a table slice and a two-dimensional register array structure is believed to effectively provide power consumption improvements by moving large amounts of data into a large amount of register space, e.g., a single load operation that causes a processing task to be performed directly on the immediately following data by an array of execution lanes. Furthermore, the use of an execution lane array and corresponding register array provides different mask sizes that are easily programmable/configurable.
Fig. 2a to 2e show at a high level embodiments of the parsing activity of the line buffer unit 101, both the finer granularity parsing activity of the table generator unit 103 and the mask processing activity of the mask processor 102 coupled to the table generator unit 103.
Fig. 2a illustrates an embodiment of an input frame of image data 201. Fig. 2a also illustrates a schematic representation of three overlapping masks 202 (each having a size of 3 pixels by 3 pixels), which mask processors are designed to operate on the three overlapping masks 202. Each mask is highlighted in solid black with the corresponding output pixel from which its output image data was generated. For simplicity, three overlapping masks 202 are illustrated as overlapping only in the vertical direction. It should be appreciated that in practice, the mask processor may be designed with overlapping masks in both the vertical and horizontal directions.
As shown in FIG. 2a, due to the vertically overlapping masks 202 within the mask processors, there is wide band (wide band) image data within the frame on which a single mask processor operates. As will be described in more detail below, in an embodiment, the mask processor processes the data within its overlapping masks across the image data in a left-to-right manner (and then repeats for the next set of lines in top-to-bottom order). Thus, as the stencil processor continues its operation, the number of solid black output pixel blocks will grow horizontally to the right. As described above, the line buffer unit 101 is responsible for parsing line groups of input image data from an incoming frame sufficient for the stencil processor to operate in an extended plurality of upcoming cycles. An exemplary illustration of the line group is shown as shaded region 203. In an embodiment, the line buffer unit 101 may understand the different dynamics of sending/receiving line groups to/from a tile generator. For example, a full width line of image data is passed between the line buffer unit and the tile generator according to a pattern known as "full-team". According to a second pattern, referred to as "virtual high (total) the line set is initially delivered in a subset of full width lines. The remaining rows are then sequentially passed in smaller (less than full width) segments.
In the case where the line group 203 of input image data has been defined by the line buffer unit and passed to the tile generator unit, the tile generator unit further parses the line group into a finer tile that more accurately fits to the hardware limitations of the stencil processor. More specifically, as will be described in further detail below, in an embodiment, each stencil processor is comprised of a two-dimensional shift register array. The two-dimensional shift register array essentially shifts the image data "below" the array of execution channels, with the shift pattern being such that each execution channel operates on the data within its own corresponding mask (i.e., each execution channel processes the information of its own mask to generate an output for that mask). In an embodiment, a tile is a surface area of input image data that is "filled" or otherwise loaded into a two-dimensional shift register array.
As will be described in more detail below, in various embodiments, there are actually multiple layers of two-dimensional register data that can be shifted over any period. For convenience, much of this specification will simply use the term "two-dimensional shift register" or the like to denote a structure having one or more such layers of two-dimensional register data that can be shifted.
Thus, as shown in FIG. 2b, the sheet generator parses the initial sheet 204 from the line set 203 and provides it to the stencil processor (where the sheet of data corresponds to the shaded area generally identified by reference numeral 204). As shown in fig. 2c and 2d, the mask processor operates on the table of input image data by effectively moving the overlapping mask 202 across the table in a left-to-right manner. As shown in fig. 2d, the number of pixels whose output values can be calculated from the data within the table is exhausted (no other pixel location can have an output value determined from the information within the table). For simplicity, the boundary regions of the image are omitted.
As shown in FIG. 2e, the tile generator then provides the next tile 205 to the stencil processor to continue operation. Note that when the mask starts to operate on the next sheet, the initial position of the mask is the next progression (progression) to the right from the depletion point on the first sheet (as previously illustrated in fig. 2 d). When the mask processor operates on the new sheet in the same manner as the first sheet is processed, the mask will simply continue to move to the right using the new sheet 205.
Note that there is some overlap between the data of the first sheet 204 and the data of the second sheet 205 due to the border area of the mask around the output pixel positions. This overlap can be handled simply by the slice generator retransmitting the overlapping data twice. In an alternative embodiment, to feed the next table to the stencil processor, the table generator may continue to send new data only to the stencil processor, and the stencil processor reuses overlapping data from the previous table.
b. Masking plate processor design and operation
Figure 3a illustrates an embodiment of an stencil processor architecture 300. As shown in FIG. 3a, the stencil processor includes a data computation unit 301, a scalar processor 302, and associated memory 303 and I/O unit 304. The data computation unit 301 includes an execution lane array 305, a two-dimensional shift array structure 306, and a separate random access memory 307 associated with a particular row or column of the array.
The I/O unit 304 is responsible for loading "input" tile data received from the tile generator into the data computation unit 301 and storing "output" tile data from the stencil processor into the tile generator. In an embodiment, loading the tile data into the data computation unit 301 entails parsing the received tile into rows/columns of image data and loading the rows/columns of image data into the two-dimensional shift register structure 306 or into the corresponding random access memory 307 of the rows/columns of the execution lane array (described in more detail below). If the slice is initially loaded into memory 307, then each execution lane within the execution lane array 305 may then load the slice data from the random access memory 307 into the two-dimensional shift register structure 306 as appropriate (e.g., when a load instruction immediately precedes a data operation on the slice). After the loading of the tablewalk data (whether directly from the tablewalk generator or from memory 307) into the register structure 306 is complete, the execution lanes of the execution lane array 305 operate on the data and eventually "write back" the completed data as a tablewalk directly into the tablewalk generator or random access memory 307. If the latter, I/O unit 304 fetches the data from random access memory 307 to form an output table slice, which is then forwarded to the table slice generator.
The term "execution lane" refers to a collection of one or more execution units capable of executing instructions (e.g., logic circuits that can execute instructions). However, in various embodiments, the execution path may include the functionality of more types of processors in addition to execution units. For example, an execution lane may include logic to decode received instructions, or in the case of a more MIMD-like design, to fetch and decode instructions, in addition to one or more execution units. For MIMD-like approaches, although a centralized program control approach has been largely described herein, a more distributed approach (e.g., including program code and program controllers within each execution lane of array 305) may be implemented in various alternative embodiments.
The combination of the execution lane array 305, the program controller 309, and the two-dimensional shift register structure 306 provide a wide adaptive/configurable hardware platform for a wide range of programmable functions. For example, application software developers can program kernels having a wide variety of functional capabilities and sizes (e.g., mask sizes), provided that the individual execution channels are capable of performing a wide variety of functions and can easily access input image data proximate to any output array location.
In addition to serving as a data store for image data operated on by the execution lane array 305, the random access memory 307 may also hold one or more look-up tables. In various embodiments, one or more scalar look-up tables may also be instantiated within scalar memory 303.
Scalar lookups involve passing the same data value from the same lookup table to each execution lane within the execution lane array 305 according to the same index. In various embodiments, the above VLIW instruction format is extended to further include a scalar opcode that directs a lookup operation performed by a scalar processor to a scalar lookup table. The index designated for use with the opcode may be an immediate operand or fetched from some other data storage location. Regardless, in an embodiment, a lookup from a scalar lookup table within scalar memory essentially involves broadcasting the same data value to all execution lanes within the execution lane array 305 during the same clock cycle. Additional details regarding the use and operation of the lookup table are provided further below.
Fig. 3b summarizes the VLIW instruction word embodiment described above. As shown in fig. 3b, the VLIW instruction word format comprises three fields for independent instructions: 1) scalar instructions 351 executed by a scalar processor; 2) ALU instructions 352 that are broadcast and executed in SIMD fashion by corresponding ALUs within the execution lane array; and 3) memory instructions 353 that are broadcast and executed in a partial SIMD manner (e.g., if execution lanes along the same row in the execution lane array share the same random access memory, one execution lane from each of the different rows actually executes the instruction (the format of the memory instructions 353 may include an operand that identifies which execution lane in each row executes the instruction).
In an embodiment, a scalar instruction executed by a scalar processor includes issuing a command to a tile generator to load/store a tile from/to a memory or 2D shift register of a data computation unit. Here, the operation of the slice generator may depend on the operation of the line buffer unit or other variable of the pre-run time understanding (composition) of the number of cycles it takes to prevent the slice generator from completing any command issued by the scalar processor. Thus, in an embodiment, scalar instruction 351 corresponds to or otherwise causes any VLIW word of a command issued to a table-slice generator to also include a no-operation (NOOP) instruction in the other two instruction fields 352, 353. The program code then enters a NOOP instruction loop for the instruction fields 352, 353 until the slice generator completes its load/store to/from the data computation unit. Here, upon issuing a command to the slice generator, the scalar processor may set the bit of the interlock register that the slice generator resets upon completion of the command. During the NOOP cycle, the scalar processor monitors the bits of the interlock bits. Normal execution begins again when the scalar processor detects that the tile generator has completed its command.
FIG. 4 illustrates an embodiment of a data computation component 401. As shown in FIG. 4, the data computation element 401 includes an array of execution lanes 405 logically located "above" a two-dimensional shift register array structure 406. As described above, in various embodiments, the image data tiles provided by the tile generator are loaded into the two-dimensional shift register 406. The execution channel then operates on the slice data from register structure 406.
Some significant architectural features of the data computation unit 401 include a shift register structure 406 having a wider dimension than the execution lane array 405. That is, outside of execution lane array 405, there is a register "outer loop (halo)" 409. Although the outer loop 409 is shown as being present on both sides of the execution lane array, the outer loop may be present on fewer (one) or more (three or four) sides of the execution lane array 405, depending on the implementation. The outer ring 405 is used to provide "overflow" space for data that overflows the boundaries of the execution lane array 405 as the data is moving "below" the execution lane 405. As a simple case, a 5x5 mask centered at the right edge of execution lane array 405 would require the four outer ring register locations to the more right when processing the leftmost pixels of the mask. For ease of drawing, while in a so-called embodiment the registers on either side (right, lower) will have horizontal and vertical connections, fig. 4 shows the registers on the right side of the outer ring as having only horizontal shift connections and the registers on the lower side of the outer ring as having only vertical shift connections.
Additional overflow space is provided by random access memory 407 coupled to each row and/or each column or a portion thereof in the array (e.g., random access memory may be assigned to a "region" of the execution lane array that spans 4 execution lanes per row and 2 execution lanes per column. Here, if the kernel operation of the execution lane requires it to process pixel values outside of the two-dimensional shift register array 406 (which some image processing routines may require), the plane of image data can be spilled further, for example, from the outer ring region 409 into random access memory 407. For example, consider a 6X6 mask in which the hardware includes an outer ring region of only four storage elements to the right of an execution lane on the right edge of the execution lane array. In this case, the data would need to be further offset to the right from the right edge of the outer ring 409 to fully process the mask. The data that is shifted out of the outer ring region 409 will then overflow into random access memory 407. Further applications of random access memory 407 and the stencil processor of fig. 3 are provided below.
Fig. 5a to 5k show working examples of the manner in which image data is shifted within the two-dimensional shift register array "below" the execution lane array as mentioned above. As shown in fig. 5a, the data content of a two-dimensional shift array is illustrated in a first array 507, and an execution lane array is illustrated by frame 505. Also, two adjacent execution lanes 510 within the execution lane array are simply illustrated. In this simple illustration 510, each execution lane includes a register R1 that may accept data from a shift register, accept data from the ALU output (e.g., appearing as an accumulator across cycles), or write output data to an output destination.
Each execution lane also has contents "below" it in a two-dimensional shift array that may be provided in local register R2. Thus, R1 is the physical register of the execution lane, while R2 is the physical register of the two-dimensional shift register array. The execution path includes an ALU that may operate on operands provided by R1 and/or R2. As described in more detail below, in an embodiment, the shift register is actually implemented by (a "depth" of) multiple storage/register elements per array location, but the shifting activity is limited to one plane of storage elements (e.g., one plane of storage elements is only shifted per cycle). Fig. 5a to 5k illustrate one of these deeper register locations for storing a result X from the corresponding execution lane. For ease of illustration, the deeper result register is illustrated alongside rather than below its corresponding register R2.
Fig. 5a to 5k focus on the calculation of two masks whose central positions are aligned with the pairs of execution lane positions 511 illustrated within the execution lane array. For ease of illustration, the execution lane pair 510 is illustrated as a horizontal neighbor when in fact the execution lane pair 510 is a vertical neighbor according to the example described below.
As initially shown in fig. 5a, the execution lane is centered at its center mask position. Figure 5b shows object code executed by two execution channels. As shown in FIG. 5b, the program code for both execution lanes causes the data in the shift register array to shift down one position and to shift right one position. This will align the two execution lanes with the upper left corner of their corresponding masks. The program code then causes the data in its corresponding location (in R2) to be loaded into R1.
The program code then causes the execution lane pair to shift the data within the shift register array one unit to the left, which causes the value to the right of the corresponding location of each execution lane to be shifted to the location of each execution lane, as shown in FIG. 5 c. The value in R1 (the previous value) is then added to the new value that has been shifted into the position of the execution lane (in R2). The result is written into R1. As shown in FIG. 5d, the same process as described above for FIG. 5C is repeated such that the result R1 now includes the value A + B + C in the upper execution lane and F + G + H in the lower execution lane. At this point, both execution lanes have processed the upper row of their corresponding masks. Note that if there is no outer ring area to the left of the execution channel array, then overflow will occur into the outer ring area to the left of the execution channel array (if there is one to the left) or random access memory.
As shown in FIG. 5e, the program code next shifts up the data within the shift register array by one unit, which aligns the two execution lanes with the right edge of the middle row of their corresponding masks. The register R1 for both execution paths currently includes the sum of the rightmost values of the top and middle rows of the mask. Fig. 5f and 5g illustrate the continued progression of the left shift across the middle row of masks for both execution lanes. The cumulative addition continues so that at the end of the process of FIG. 5g, both execution channels include the sum of the values of the top and middle rows of their corresponding masks.
FIG. 5h shows another shift that aligns each execution channel with the lowermost row of its corresponding mask. Fig. 5i and 5j show the processing on the process of continuing the shift to complete the masks for the two execution channels. FIG. 5k shows an additional shift to align each execution lane with its correct position in the data array and write its result.
In the example of fig. 5a-5k, note that the object code for the shift operation may include an instruction format that identifies the direction and magnitude of the shift expressed in (X, Y) coordinates. For example, the object code for moving up by one position may be expressed as SHIFT 0, +1 in the object code. As another example, shifting a position to the right may be expressed in object code as SHIFT +1, 0. In various embodiments, a larger magnitude SHIFT may also be specified in object code (e.g., SHIFT 0, + 2). Here, if the 2D shift register hardware only supports one position shift per cycle, the instruction may be interpreted by the machine as requiring multiple cycles of execution, or the 2D shift register hardware may be designed to support more than 1 position shift per cycle. Hereinafter, the latter embodiment will be described in further detail.
FIG. 6 shows another more detailed illustration of a unit cell for an array execution lane and shift register structure (registers in the outer ring region do not include a corresponding execution lane). In an embodiment, the execution lane and register space associated with each location in the execution lane array is implemented by instantiating the circuitry shown in FIG. 6 at each node of the execution lane array. As shown in FIG. 6, the unit cell includes an execution channel 601 coupled to a register file 602 made up of four registers R2 through R5. During any cycle, the execution channel 601 may read or write from any of the registers R1-R5. For instructions requiring two input operands, the execution lane may retrieve two operands from any of R1 through R5.
In an embodiment, a two-dimensional shift register structure is implemented by allowing the contents of any one of (only) one of the registers R2-R4 to be "shifted out" to one of its adjacent register files through the output multiplexer 603 and replacing the contents of any one of (only) one of the registers R2-R4 with contents "shifted in" from its corresponding one of its neighbors through the input multiplexer 604, such that the shifts between the neighbors are in the same direction (e.g., all execution lanes left shift, all execution lanes right shift, etc.) during a single cycle. Although it is common for the same register to have its contents shifted out and replaced with contents shifted in on the same cycle, the multiplexer arrangements 603, 604 allow different shift source and shift target registers to be in the same register file during the same cycle.
As shown in FIG. 6, note that during the shift sequence, an execution channel shifts content from its register file 602 to each of its left, right, top, and bottom neighbors. In conjunction with the same shift sequence, the execution channel also shifts content from a particular one of its left, right, top, and bottom neighbors into its register file. Again, the move-out target and the move-in source should coincide with the same shift direction for all execution lanes (e.g., if move-out is to the right neighbor, then move-in from the left neighbor).
Although in one embodiment, the contents of only one register per execution channel are allowed to shift per cycle, other embodiments may allow the contents of more than one register to be shifted in/out. For example, if the second instance of multiplexer circuits 603, 604 shown in fig. 6 is incorporated into the design of fig. 6, the contents of both registers may be shifted out/in during the same cycle. Of course, in embodiments that only allow shifting the contents of one register per cycle, shifting from multiple registers may occur between mathematical operations by consuming more clock cycles for shifting between mathematical operations (e.g., the contents of two registers may be shifted between mathematical operations by consuming two shift operations between mathematical operations).
If less than all of the contents of the execution channel's register file are shifted out during the move sequence, then note that the contents of the unshifted registers of each execution channel remain the same (not shifted). In this way, any un-shifted content that is not replaced by shifting in the content is still present locally to the execution lane during the shift cycle. The memory cells ("M") observed in each execution lane are used to load/store data from/to the random access memory space associated with the rows and/or columns of execution lanes within the execution lane array. Here, the M-cell functions as a standard M-cell because it is typically used to load/store data that cannot be loaded/stored from/to the execution channel's own register space. In various embodiments, the primary operation of the M-cell is to write data from the local register to memory, and read data from memory and write it to the local register.
For ISA opcodes supported by the ALU unit of the hardware execution path 601, in various embodiments, the mathematical opcodes supported by the hardware ALUs are globally identical (e.g., substantially the same) to the mathematical opcodes supported by the virtual execution path (e.g., ADD, SUB, MOV, MUL, MAD, ABS, DIV, SHL, SHR, MIN/MAX, SEL, AND, OR, XOR, NOT). As described above, memory access instructions may be executed by the execution lane 601 to fetch/store data from/to its associated random access memory. In addition, the hardware execution channel 601 supports shift operation instructions (right, left, up, down) to shift data within a two-dimensional shift register structure. As described above, the program control instructions are mainly executed by the scalar processor of the stencil processor.
c. Configuration of image processor and operation of line buffer unit
Fig. 7 shows a high-level view of an image processor technology platform, which comprises a virtual image processing environment 701, real image processing hardware 703 and a compiler 702 for converting high-level code written for the virtual processing environment 701 into object code that the real hardware 703 physically executes. As described in more detail below, the virtual processing environment 701 is widely generic in terms of applications that can be developed and customized for easy visualization of the constituent processes of the application. When the developer 704 completes the program code development work, the compiler 702 converts the code written within the virtual processing environment 701 into object code directed to the actual hardware 703.
In various embodiments, program code written for a hardware platform is written in unique virtual code that includes an instruction set with load and store instructions in an instruction format that identifies input and output array locations as, for example, X, Y coordinates. In various embodiments, the X, Y coordinate information may actually be programmed into the hardware platform and recognized/understood by its various components. This is different than, for example, converting X, Y coordinates (e.g., within a compiler) to different information. For example, in the case of a two-dimensional shift register structure within a stencil processor, the X, Y coordinate information is converted to register shift motion. In contrast, other parts of the hardware platform may specifically receive and understand X, Y coordinate information originally expressed at a high virtual code level.
As shown in FIG. 8, a program code developer expresses data locations as X, Y coordinates using a special instruction format at the virtual code level 801. During the compilation stage, the virtual code is converted into program code that is actually processed by the hardware (object code) and corresponding configuration information that is loaded into the configuration (e.g., register) space of the hardware. As shown in fig. 8, in an embodiment, object code for a particular kernel is loaded into the program space of scalar processor 805 of a stencil processor.
As part of the configuration process, configuration software executing on scalar processor 805 loads appropriate configuration information 811, 812 into both tile generator unit 803 and line buffer unit 801, tile generator unit 803 being coupled to stencil processor 802, line buffer unit 801 will generate new tiles for operation by stencil processor 802 or receive processed tiles generated by stencil processor 802. Here, the tiles can still generally be considered in terms of X, Y coordinates for the entire image. That is, once an image or frame is defined (e.g., in terms of number of pixels per row, number of rows, number of pixels per column, and number of columns), any portion or location of the image may still be indicated with X, Y coordinates.
Thus, in various embodiments, either or both of the tile generator unit 803 and the line buffer unit 801 are configured with information 811, 812 within their corresponding configuration spaces 806, 807 that establishes an information platform from which to identify specific locations and/or areas (e.g., line groups, tiles) of an image or frame in X, Y coordinates. In various implementations/uses, the X, Y coordinates may be the same X, Y coordinates expressed at the virtual code level.
Examples of such information include, for example, the number of active line groups in the line buffer unit, the image size of each line group (e.g., as a set of four X, Y coordinates (one for each corner) or a pair of X, Y coordinates (one for the lower closer corner and one for the higher farther corner) or absolute image width and image height, mask size (expressed as X, Y values that define the size of the overlapping mask area and/or individual masks of a mask processor), sheet and/or line group size (e.g., specified in the same sense as the image size but with smaller dimensions), etc And/or the number of dimensions as configuration information.
Fig. 9a illustrates, as just one example, the use of X, Y coordinates to define line groups within an image. Here, N line groups 902_1, 902_2, ·, 902_ N may be observed within the image 901. As shown from fig. 9a, each line group can be easily defined by referring to X, Y coordinates within the image defining, for example, one or more line group corner points. As such, in various embodiments, the wire group name or other data structure used to define a particular wire group may include an X, Y coordinate location associated with the wire group to facilitate specific identification thereof.
Referring briefly back to fig. 8, note that fig. 8 shows that during runtime, the tile generator 803 may request a "next" line group (or a portion of a line group) from the line buffer unit 801 by, for example, including X, Y coordinate information defining the desired data region. Fig. 9a shows a nominal "full width" line set consisting of only lines of image data for a complete row. In an alternative configuration, referred to as "virtual-high", the line buffer unit 801 initially passes only the first, higher portion of the line group as full width lines of image data. Then, the table generator specifically requests the next lower row of the line group of the composer in consecutive blocks, which is smaller than the full width row and is requested individually. In this way, the sheet generator makes multiple requests to obtain the full line group. Here, each such request may define the next portion by the X, Y coordinates attributed to the next portion.
As shown in fig. 9b, the line buffer unit includes a memory 901 (e.g., static or dynamic random access memory (SRAM or DRAM)) storing line groups 902_1 to 902_ N. Memory 901 may be implemented on-chip or off-chip with the same circuitry that implements the line buffer units (and, for example, the tile generator and stencil processor). Fig. 9b shows the activity between various cores that generate and consume line groups 902_1 to 902_ N for a particular image/frame within the memory 901.
As shown in fig. 9b, producer core K1 sends the new line group to line buffer unit 901 for storage in memory 901 in separate time instances P1, P2 through electrical PN. The producer kernel K1 executes on the stencil processor that generates the new data sheet. A tile generator coupled to the stencil processor accumulates tiles to form line groups and forwards the line groups to a line buffer unit, which stores them in memory.
Also as shown in FIG. 9b, there are two consumer cores K2, K3 operating on the line set 902_1 through 902_ N generated by the producer core K1. Here, the consumer cores K2 and K3 receive the first wire set 902_1 at times C21 and C31, respectively. Obviously, times C21 and C31 occur after time P1. Other limitations may not exist. For example, time C21 and/or C31 may occur before or after any of times P2 through PN. Here, the corresponding slice generators of cores K2 and K3 request the next line group at the time appropriate for their corresponding cores. If either of the cores K2, K3 requested the wire set 902_1 before time P1, the request is idle until after the wire set 902_1 is actually written to memory 901.
It is contemplated that requests from either or both of cores K2 and K3 for all of the wire sets 902_1 through 902_ N may arrive before time P1. Thus, the consumer core may request the line set at any time. As the consumer core requests the wire set, the wire set is forwarded to the consumer core, however, this is affected by the rate at which the producer core K1 can produce them. In various embodiments, the consumer core requests the line groups in turn and receives them in turn as well (core K2 receives the line groups 902_2 through 902_ N in turn at times C22 through C2N). For simplicity, only one producer core is illustrated for a particular line group. It is contemplated that various embodiments may be designed to allow different producers to write to the same line set (e.g., in the case where the consumer is not allowed to service until after all producers have written to the line set).
Without a producer core (because the consumer core is the first core in the DAG processing flow for the processor), a frame of image data may be transferred into memory 901 (e.g., via Direct Memory Access (DMA) or from a camera) and parsed into a line group. In the absence of a consumer core (since the producer core is the last core in the overall program flow of the processor), the resulting line sets may be combined to form an output frame.
d. Application and architecture of kernels
FIG. 10a illustrates an example of the structure and form that application software written within a virtual environment may take. As shown in fig. 10a, it may be desirable for program code to process one or more frames in the input image data 1001 to effect some overall transformation of the input image data 1001. The transformation is accomplished by operation of one or more kernels of program code 1002 operating on input image data in an organized sequence expressed by a developer.
For example, as shown in FIG. 10a, the global transformation is implemented by first processing each input image with a first kernel K1. The kernel K2 then manipulates the output image produced by the kernel K1. Then, the kernel K3_1 or K3_2 operates each of the output images generated by the kernel K2. Then, the kernel K4 operates the output image generated by the kernel K3_1/K3_ 2. The cores K3_1 and K3_2 may be the same core designed to speed up the overall process by applying parallel processing at the level of K3, or may be different cores (e.g., core K3_1 operates on a first particular type of input image, and core K3_2 operates on a second different type of input image).
In this way, a larger overall image processing sequence may take the form of an image processing pipeline or Directed Acyclic Graph (DAG), and as such, the development environment may be equipped to actually present a representation of the program code being developed to the developer. The kernel may be developed separately by a developer and/or may be provided by an entity that supplies any underlying technology, such as the actual signal processor hardware and/or its design, and/or by a third party (e.g., a vendor of kernel software written for a development environment). As such, it is expected that a nominal (nominal) development environment will include a kernel "library" that developers are free to "hook up" in various ways to achieve their overall flow of larger development work. Some of the basic kernels that are intended to be part of such a library may include kernels for providing any one or more of the following basic image processing tasks: convolution, denoising, color space conversion, edge and angle detection, sharpening, white balance, gamma correction, tone mapping, matrix multiplication, image registration, pyramid construction, wavelet transformation, block-wise discrete cosine and fourier transformation.
As described above, in various embodiments, each core runs on its own stencil processor. For example, referring to FIG. 10a, kernel K1 runs on a first stencil processor, kernel K2 runs on a second stencil processor, and so on. In addition, as described above, the core interface is generated and consumed by the line buffer unit.
FIG. 10b illustrates how an image processor may be configured to implement the DAG flow of FIG. 10 a. As shown in fig. 10b, the line buffer unit 1001_1(LBU _1) receives an input image stream and parses the received frames into line groups. The switching network is configured to route the wire set from LBU _1 to the first stencil processor 1002_1 on which kernel K1 executes. The output image from the kernel K1 is formatted into a line group and forwarded to the second line buffer unit 1001_2(LBU _ 2). These wire sets are then forwarded to the second stencil processor on which kernel K2 executes.
From fig. 10a, image information may be "split" (split) from the kernel K2 to any one of the kernels K3_1 or K3_ 2. Here, for example, the kernels K3_1 and K3_2 may process different channels associated with the entire image being processed. For example, the kernel K3_1 may process red (R) images, and the kernel K3_2 may process green (G) and blue (B) images. Alternatively, K3_1 may process visual images, while kernel K3_2 may process depth images (e.g., taken from a time-of-flight (time-of-flight) depth imaging camera along with the visual images). In any event, all channels of the image are processed by kernels K1 and K2, but different channels of the image have different kernels K3_1 and K3_2 to process. Furthermore, kernels K3_1 and K3_2 may be separate instances of the same (e.g., extremely dense in numbers) program code and use two stencil processors to speed up the processing of the K3 function by executing them in parallel.
In any case, the above-described "division" causes some line group image information from the core K2 to be buffered in the third line buffer unit 1001_3(LBU _3), and other line group image information from the core K2 to be buffered in the fourth line buffer unit 1001_4(LBU _ 4). The line group buffered in the LBU _3 line buffer unit is forwarded to the third stencil processor 1002_3 on which core K3_1 executes. The line group buffered in the LBU _4 line buffer unit is forwarded to the fourth stencil processor 1002_4 on which the core K3_2 executes. Output line groups from the cores K3_1 and K3_2 are buffered in the fifth and sixth line buffer units 1001_4(LBU _5), 1001_5(LBU _6), respectively. The line groups from the LBU _5 and LBU _6 line buffer units are then passed to the fifth stencil processor 1002_5 executing kernel K4. Note that the divided line groups are merged again at the fifth stencil processor 1002_ 5.
Fig. 11a and 11b relate to a more direct pipelined approach in which each stencil processor receives a line set from an immediately preceding stage and supplies to an immediately succeeding stage. Specifically, line buffer units 1101_1(LBU _1), 1101_2(LBU _2), 1101_3(LBU _3), and 1101_4(LBU _4) feed stencil processors 1102_1, 1102_2, 1102_3, and 1102_4, respectively, and stencil processors 1102_1, 1102_2, 1102_3, and 1102_4 perform cores K1, K2, K3, and K4, respectively. The stencil processors 1102_1, 1102_2, 1102_3, 1102_4 also feed line buffer units 1101_2(LBU _2), 1101_3(LBU _3), 1101_4(LBU _4), 1101_5(LBU _5), respectively.
Fig. 11c shows another pipeline method of executing two pipelines (K1-K3-.) and (K2-K4-). This configuration may be used to speed up the pipeline by executing in parallel (e.g., kernels K1 and K2 are the same, and kernels K3 and K4 are the same), or using two different pipelines (e.g., one pipeline processing one channel and the other processing the other channel) depending on the image data context.
In each of fig. 11b, 11b and 11c, note that the connection network 1004/1104 needs to be configured differently to connect stencil processors to source and sink (sink) line groups in an appropriate manner.
In various embodiments, the image processor includes an appropriate configuration space (e.g., implemented with configuration registers and/or random access memory, such as scalar memory of a scalar processor), where configuration information is maintained to implement any of a variety of configurations (e.g., DAG, image processing pipeline). Some exemplary configuration parameters include: 1) number of source images (number of source image frames streamed into the system from, for example, the main memory of a camera or larger computer system); 2) the number of line groups (the total number of line groups within the line buffer unit configured in the system);
3) the number of active stencil processors (the total number of active stencil processors in the system); 4) the number of Input line groups per stencil processor (one stencil processor can process more than 1 Input image frame, Num _ Input _ LGs _ persetc. essentially indicates how many different Input image frames the stencil processor will process); 5) the number of Output line groups per stencil processor (one stencil processor can process more than 1 Output image frame, Num _ Output _ LGs _ persetc. essentially indicates how many different Output image frames the stencil processor will process); 6) the number of consumers per line group (for each line group configured in each line buffer unit, Num _ Cons _ per _ LG indicates how many consumers the line group has). Other types of configuration information may be accepted by the system based on any of the features, structures, or operations of the system described above.
e. Example of implementation
It is important to note that the various image processor architectural features described above are not necessarily limited to image processing in the traditional sense, and thus may be applied to other applications that may (or may not) cause an image processor to be re-characterized. For example, if any of the various image processor architectural features described above are used to create and/or generate and/or render an animation, rather than the processing of an actual camera image, the image processor may be characterized as a graphics processing unit. Furthermore, the above-described image processor architecture features may be applied to other technical applications, such as video processing, vision processing, image recognition, and/or machine learning. Applied in this manner, the image processor may be integrated (e.g., as a coprocessor) with a more general-purpose processor (e.g., that is or is part of the CPU of a computing system), or may be a separate processor within the computing system.
The hardware design embodiments described above may be implemented within a semiconductor chip and/or as descriptions of circuit designs for eventual use in semiconductor fabrication processes. In the latter case, such circuit descriptions may take the form of higher/behavioral level circuit descriptions (e.g., VHDL descriptions) or low level circuit descriptions (e.g., Register Transfer Level (RTL) circuit descriptions, transistor level descriptions, or mask descriptions), or various combinations thereof. The circuit description is typically implemented on a computer-readable storage medium, such as a CD-ROM or other type of storage technology.
As can be appreciated from the preceding sections, the image processor as described above may be implemented in hardware on a computer system (e.g., as part of a system on a chip (SOC) of a handheld device that processes data from a camera of the handheld device). In the case where the image processor is implemented as a hardware circuit, it is noted that the image data processed by the image processor may be received directly from the camera. Here, the image processor may be part of a separate camera or part of a computing system with an integrated camera. In the latter case, the image data may be received directly from the camera or from a system memory of the computing system (e.g., the camera sends its image data to the system memory instead of the image processor). Note also that many of the features described in the previous section may be applicable to a graphics processor unit (rendering animation).
FIG. 12 provides an exemplary depiction of a computing system. Many of the components of the computing systems described below are suitable for use in computing systems (e.g., handheld devices such as smart phones or tablet computers) having integrated cameras and associated image processors. The skilled person will be able to easily distinguish between the two.
As shown in fig. 12, a basic computing system may include a central processing unit 1201 (which may include, for example, a plurality of general purpose processing cores 1215_1 through 1215_ N, and a main memory controller 1217 disposed on a multi-core processor or an application processor), a system memory 1202, a display 1203 (e.g., a touch screen, a tablet), a local wired point-to-point link (e.g., USB) interface 1204, various network I/O functions 1205 (such as an ethernet interface and/or a cellular modem subsystem), a wireless local area network (e.g., WiFi) interface 1206, a wireless point-to-point link (e.g., bluetooth) interface 1207 and a global positioning system interface 1208, various sensors 1209_1 through 1209_ N, one or more cameras 1210, a battery 1211, a power management control unit 1212, a speaker and microphone 1213, and an audio coder/decoder 1214.
The application processor or multi-core processor 1250 may include one or more general purpose processing cores 1215, one or more graphics processing units 1216, memory management functions 1217 (e.g., memory controllers), I/O control functions 1218, and image processing units 1219 within its CPU 1201. The general purpose processing core 1215 typically executes the operating system and application software of the computing system. The graphics processing unit 1216 typically performs graphics intensive functions, such as to generate graphical information that is presented on the display 1203. Memory control functions 1217 interface with system memory 1202 to write data to/read data from system memory 1202. The power management control unit 1212 generally controls the power consumption of the system 1200.
The image processing unit 1219 may be implemented according to any of the image processing unit embodiments described in detail in the previous section above. Alternatively or in combination, the IPU 1219 may be coupled to either or both of the GPU1216 and the CPU1201 as coprocessors thereof. Further, in various embodiments, GPU1216 may be implemented with any of the graphics processor features described in detail above.
Each of the touch screen display 1203, the communication interface 1204-. Depending on the implementation, various of these I/O components may be integrated on application processor/multi-core processor 1150, or may be located off-chip or off-package of application processor/multi-core processor 1250.
In an embodiment, the one or more cameras 1210 include a depth camera capable of measuring depth between the camera and objects in its field of view. Application software, operating system software, device driver software, and/or firmware executing on a general purpose CPU core (or other functional block having an instruction execution pipeline to execute program code) of an application processor or other processor may perform any of the functions described above.
Embodiments of the invention may include various processes as described above. The process may be implemented in machine-executable instructions. The instructions may be used to cause a general-purpose or special-purpose processor to perform certain processes. Alternatively, the processes may be performed by specific hardware components that contain hardwired and/or programmable logic for performing the processes, or by any combination of programmed computer components and custom hardware components.
Elements of the present invention may also be provided as a machine-readable medium for storing the machine-executable instructions. The machine-readable medium may include, but is not limited to, floppy diskettes, optical disks, CD-ROMs, and magneto-optical disks, FLASH memory, ROMs, RAMs, EPROMs, EEPROMs, magnetic or optical cards, propagation media or other type of media/machine-readable medium suitable for storing electronic instructions. For example, the invention may be downloaded as a computer program which may be transferred from a remote computer (e.g., a server) to a requesting computer (e.g., a client) by way of data signals embodied in a carrier wave or other propagation medium via a communication link (e.g., a modem or network connection).
In the foregoing specification, the invention has been described with reference to specific exemplary embodiments thereof. It will, however, be evident that various modifications and changes may be made thereto without departing from the broader spirit and scope of the invention as set forth in the appended claims. The specification and drawings are, accordingly, to be regarded in an illustrative rather than a restrictive sense.
Claims (21)
1. A processor, comprising:
a two-dimensional shift register array; and
a two-dimensional array of processing elements is provided,
wherein each shift register of the two-dimensional array of shift registers is dedicated to a respective processing element of the two-dimensional array of processing elements,
wherein each processing element is configured to execute instructions of a kernel program that causes the two-dimensional shift register array to shift a patch of input data stored in the two-dimensional shift register array in a two-dimensional pattern and causes each processing element to read a plurality of input values in a sequence through the two-dimensional pattern from a respective shift register dedicated to that processing element, the plurality of input values corresponding to a two-dimensional region of the patch of input data, and
wherein the instructions cause each processing element to calculate a respective result output value using the plurality of respective input values read from the respective shift register dedicated to that processing element when shifting the tile of input data in the two-dimensional pattern.
2. The processor of claim 1, further comprising a table tile generator configured to receive a table tile of output values computed by the two-dimensional array of processing elements and to provide the table tile of output values to a line buffer.
3. The processor of claim 2, wherein the line buffer is configured to receive the table slice of output values and provide the table slice of output values to one or more consumer processors.
4. The processor of claim 2, wherein the tile generator is configured to receive a line group from a producer line buffer and load a subsequent tile of input values into the two-dimensional shift register array of the processor.
5. The processor of claim 4, wherein the processor, the table fragment generator, and the line buffer are configured to implement a portion of an image processing pipeline.
6. The processor of claim 4, wherein the table slice generator is configured to write a table slice of output values to a plurality of line buffers.
7. The processor of claim 1, wherein each shift register of the two-dimensional array of shift registers is dedicated to a respective processing element of the two-dimensional array of processing elements.
8. The processor of claim 1, wherein each data shift from a first shift register to a second shift register in the two dimensional shift register array replaces a value previously stored in the second shift register.
9. The processor of claim 1, wherein the two-dimensional shift register array maintains a single copy of the input data while shifting the table slices of the data in the two-dimensional pattern.
10. The processor of claim 1, wherein, in shifting the table slice of input data in the two-dimensional pattern, each processing element reads the plurality of respective input values from a same respective shift register dedicated to that processing element.
11. The processor of claim 1, wherein the instructions cause each processing element to output a single respective result output value for the plurality of respective input values read when shifting the table of input data in the two-dimensional pattern.
12. A method performed by a processor, the processor comprising:
a two-dimensional shift register array; and
a two-dimensional array of processing elements is provided,
wherein each shift register of the two-dimensional array of shift registers is dedicated to a respective processing element of the two-dimensional array of processing elements, the method comprising:
executing, by each processing element of the two-dimensional array of processing elements, an instruction of a kernel program that causes the two-dimensional array of shift registers to shift a patch of input data stored in the two-dimensional array of shift registers in a two-dimensional pattern and that causes each processing element to read a plurality of input values in a sequence in the two-dimensional pattern from a respective shift register dedicated to that processing element, the plurality of input values corresponding to a two-dimensional area of the patch of input data; and
calculating, by each processing element of the two-dimensional array of processing elements, a respective resultant output value using the plurality of respective input values read from the respective shift register dedicated to that processing element when shifting the table slice of input data in the two-dimensional pattern.
13. The method of claim 12, further comprising:
receiving, by a tile generator, a tile of output values computed by the two-dimensional array of processing elements; and
the table slice of output values is provided to a line buffer.
14. The method of claim 13, further comprising:
receiving, by the line buffer, a table slice of the output value; and
providing the table of output values to one or more consumer processors.
15. The method of claim 13, further comprising:
receiving, by the tile generator, a set of lines from a producer line buffer; and
loading, by the tile generator, a subsequent tile of input values into the two-dimensional shift register array of the processor.
16. The method of claim 15, wherein the processor, the table fragment generator, and the line buffer implement a portion of an image processing pipeline.
17. The method of claim 15, further comprising writing, by the table slice generator, a table slice of output values to a plurality of line buffers.
18. The method of claim 12, wherein each shift register of the two-dimensional array of shift registers is dedicated to a respective processing element of the two-dimensional array of processing elements.
19. The method of claim 12, wherein shifting data from a first shift register to a second shift register in the two dimensional shift register array comprises replacing a value previously stored in the second shift register.
20. The method of claim 12, further comprising maintaining, by the two-dimensional shift register array, a single copy of the input data while shifting the table slices of data in the two-dimensional pattern.
21. The method of claim 12, further comprising:
reading, by each processing element, the plurality of respective input values from the same respective shift register dedicated to that processing element while shifting the table slice of input data in the two-dimensional pattern.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US14/694,828 US9965824B2 (en) | 2015-04-23 | 2015-04-23 | Architecture for high performance, power efficient, programmable image processing |
US14/694,828 | 2015-04-23 | ||
CN201680019775.0A CN107438860B (en) | 2015-04-23 | 2016-04-06 | Architecture for high performance power efficient programmable image processing |
Related Parent Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201680019775.0A Division CN107438860B (en) | 2015-04-23 | 2016-04-06 | Architecture for high performance power efficient programmable image processing |
Publications (1)
Publication Number | Publication Date |
---|---|
CN113132558A true CN113132558A (en) | 2021-07-16 |
Family
ID=55858889
Family Applications (2)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201680019775.0A Active CN107438860B (en) | 2015-04-23 | 2016-04-06 | Architecture for high performance power efficient programmable image processing |
CN202110291114.6A Pending CN113132558A (en) | 2015-04-23 | 2016-04-06 | Architecture for high performance power efficient programmable image processing |
Family Applications Before (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201680019775.0A Active CN107438860B (en) | 2015-04-23 | 2016-04-06 | Architecture for high performance power efficient programmable image processing |
Country Status (7)
Country | Link |
---|---|
US (3) | US9965824B2 (en) |
EP (2) | EP3286726B1 (en) |
JP (2) | JP6571790B2 (en) |
KR (2) | KR102278658B1 (en) |
CN (2) | CN107438860B (en) |
DE (1) | DE112016001837T5 (en) |
WO (1) | WO2016171909A1 (en) |
Families Citing this family (30)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US9515658B1 (en) * | 2014-10-09 | 2016-12-06 | Altera Corporation | Method and apparatus for implementing configurable streaming networks |
GB2539461B (en) * | 2015-06-16 | 2020-01-08 | Canon Kk | Image data encapsulation |
US10313641B2 (en) | 2015-12-04 | 2019-06-04 | Google Llc | Shift register with reduced wiring complexity |
US9830150B2 (en) | 2015-12-04 | 2017-11-28 | Google Llc | Multi-functional execution lane for image processor |
US10387988B2 (en) | 2016-02-26 | 2019-08-20 | Google Llc | Compiler techniques for mapping program code to a high performance, power efficient, programmable image processing hardware platform |
US10204396B2 (en) | 2016-02-26 | 2019-02-12 | Google Llc | Compiler managed memory for image processor |
US10380969B2 (en) | 2016-02-28 | 2019-08-13 | Google Llc | Macro I/O unit for image processor |
CN108885776B (en) * | 2016-03-24 | 2022-09-27 | 富士胶片株式会社 | Image processing apparatus, image processing method, and storage medium |
US10546211B2 (en) | 2016-07-01 | 2020-01-28 | Google Llc | Convolutional neural network on programmable two dimensional image processor |
US20180005059A1 (en) | 2016-07-01 | 2018-01-04 | Google Inc. | Statistics Operations On Two Dimensional Image Processor |
US20180007302A1 (en) | 2016-07-01 | 2018-01-04 | Google Inc. | Block Operations For An Image Processor Having A Two-Dimensional Execution Lane Array and A Two-Dimensional Shift Register |
US20180005346A1 (en) * | 2016-07-01 | 2018-01-04 | Google Inc. | Core Processes For Block Operations On An Image Processor Having A Two-Dimensional Execution Lane Array and A Two-Dimensional Shift Register |
US10795836B2 (en) * | 2017-04-17 | 2020-10-06 | Microsoft Technology Licensing, Llc | Data processing performance enhancement for neural networks using a virtualized data iterator |
US10467056B2 (en) * | 2017-05-12 | 2019-11-05 | Google Llc | Configuration of application software on multi-core image processor |
US10489199B2 (en) * | 2017-05-12 | 2019-11-26 | Google Llc | Program code transformations to improve image processor runtime efficiency |
US10872393B2 (en) * | 2017-05-15 | 2020-12-22 | Google Llc | Image processor with high throughput internal communication protocol |
US10489878B2 (en) * | 2017-05-15 | 2019-11-26 | Google Llc | Configurable and programmable image processor unit |
TWI769810B (en) | 2017-05-17 | 2022-07-01 | 美商谷歌有限責任公司 | Special purpose neural network training chip |
KR102008287B1 (en) * | 2017-05-23 | 2019-08-07 | 고려대학교 산학협력단 | Bidirectional fifo memoy and processing device for convoultion using the same |
WO2019143025A1 (en) * | 2018-01-16 | 2019-07-25 | 한국과학기술원 | Image processing method and device using line input and output |
US11468312B2 (en) | 2018-02-02 | 2022-10-11 | Samsung Electronics Co., Ltd. | Memory management for machine learning training on GPU |
US11468302B2 (en) | 2018-03-13 | 2022-10-11 | Recogni Inc. | Efficient convolutional engine |
CN108596822A (en) * | 2018-04-24 | 2018-09-28 | 上海顺久电子科技有限公司 | Date storage method, device and image processing system |
CN109316202B (en) * | 2018-08-23 | 2021-07-02 | 苏州佳世达电通有限公司 | Image correction method and detection device |
CN111209243B (en) * | 2018-11-21 | 2022-12-02 | 上海寒武纪信息科技有限公司 | Data processing device, method and related product |
CN111209231B (en) * | 2018-11-21 | 2021-05-11 | 上海寒武纪信息科技有限公司 | Data processing method and device and related products |
US20220035762A1 (en) | 2018-10-18 | 2022-02-03 | Shanghai Cambricon Information Technology Co., Ltd. | Network-on-chip data processing method and device |
US10552939B1 (en) | 2019-02-12 | 2020-02-04 | Google Llc | Image processor complex transfer functions |
TWI746126B (en) | 2020-08-25 | 2021-11-11 | 創鑫智慧股份有限公司 | Matrix multiplication device and operation method thereof |
CN112184536B (en) * | 2020-09-24 | 2022-09-30 | 成都海光集成电路设计有限公司 | Method, apparatus, device and medium for processing image data based on GEMM |
Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6067609A (en) * | 1998-04-09 | 2000-05-23 | Teranex, Inc. | Pattern generation and shift plane operations for a mesh connected computer |
US20080013862A1 (en) * | 2006-07-14 | 2008-01-17 | Fuji Xerox Co., Ltd. | Image processing apparatus, storage medium in which image processing program is stored, and image processing method |
US20080133881A1 (en) * | 2006-12-01 | 2008-06-05 | Thomson Licensing Llc | Array of processing elements with local registers |
US20080282061A1 (en) * | 2004-08-04 | 2008-11-13 | Hiroyuki Morishita | Array Type Operation Device |
US20110134131A1 (en) * | 2008-08-06 | 2011-06-09 | Nxp B.V. | Simd parallel processor architecture |
Family Cites Families (81)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US4445177A (en) | 1981-05-22 | 1984-04-24 | Data General Corporation | Digital data processing system utilizing a unique arithmetic logic unit for handling uniquely identifiable addresses for operands and instructions |
JPS6373380A (en) * | 1986-09-16 | 1988-04-02 | Matsushita Electric Ind Co Ltd | Image processor |
US4835712A (en) | 1986-04-14 | 1989-05-30 | Pixar | Methods and apparatus for imaging volume data with shading |
DE3851005T2 (en) | 1987-06-01 | 1995-04-20 | Applied Intelligent Syst Inc | Parallel neighboring processing system and method. |
US4935894A (en) | 1987-08-31 | 1990-06-19 | Motorola, Inc. | Multi-processor, multi-bus system with bus interface comprising FIFO register stocks for receiving and transmitting data and control information |
US5253308A (en) | 1989-06-21 | 1993-10-12 | Amber Engineering, Inc. | Massively parallel digital image data processor using pixel-mapped input/output and relative indexed addressing |
WO1994009595A1 (en) | 1991-09-20 | 1994-04-28 | Shaw Venson M | Method and apparatus including system architecture for multimedia communications |
JP3482660B2 (en) | 1993-09-08 | 2003-12-22 | ソニー株式会社 | Image data processing apparatus and image data processing method |
US5612693A (en) | 1994-12-14 | 1997-03-18 | International Business Machines Corporation | Sliding window data compression using a toroidal bit shift register |
US5706216A (en) * | 1995-07-28 | 1998-01-06 | Reisch; Michael L. | System for data compression of an image using a JPEG compression circuit modified for filtering in the frequency domain |
JP3573755B2 (en) | 1996-01-15 | 2004-10-06 | シーメンス アクチエンゲゼルシヤフト | Image processing processor |
US6031573A (en) | 1996-10-31 | 2000-02-29 | Sensormatic Electronics Corporation | Intelligent video information management system performing multiple functions in parallel |
US5892962A (en) | 1996-11-12 | 1999-04-06 | Lucent Technologies Inc. | FPGA-based processor |
US6366289B1 (en) | 1998-07-17 | 2002-04-02 | Microsoft Corporation | Method and system for managing a display image in compressed and uncompressed blocks |
US6587158B1 (en) | 1998-07-23 | 2003-07-01 | Dvdo, Inc. | Method and apparatus for reducing on-chip memory in vertical video processing |
US7010177B1 (en) | 1998-08-27 | 2006-03-07 | Intel Corporation | Portability of digital images |
EP1164544B1 (en) | 1999-03-16 | 2011-11-02 | Hamamatsu Photonics K.K. | High-speed vision sensor |
JP3922859B2 (en) | 1999-12-28 | 2007-05-30 | 株式会社リコー | Image processing apparatus, image processing method, and computer-readable recording medium storing program for causing computer to execute the method |
US6745319B1 (en) | 2000-02-18 | 2004-06-01 | Texas Instruments Incorporated | Microprocessor with instructions for shuffling and dealing data |
US6728862B1 (en) | 2000-05-22 | 2004-04-27 | Gazelle Technology Corporation | Processor array and parallel data processing methods |
US6728722B1 (en) | 2000-08-28 | 2004-04-27 | Sun Microsystems, Inc. | General data structure for describing logical data spaces |
US6986025B2 (en) | 2001-06-11 | 2006-01-10 | Broadcom Corporation | Conditional execution per lane |
US7286717B2 (en) | 2001-10-31 | 2007-10-23 | Ricoh Company, Ltd. | Image data processing device processing a plurality of series of data items simultaneously in parallel |
JP4146654B2 (en) | 2002-02-28 | 2008-09-10 | 株式会社リコー | Image processing circuit, composite image processing circuit, and image forming apparatus |
US9170812B2 (en) | 2002-03-21 | 2015-10-27 | Pact Xpp Technologies Ag | Data processing system having integrated pipelined array data processor |
WO2003088033A1 (en) | 2002-04-09 | 2003-10-23 | University Of Rochester | Multiplier-based processor-in-memory architectures for image and graphics processing |
AU2003286131A1 (en) | 2002-08-07 | 2004-03-19 | Pact Xpp Technologies Ag | Method and device for processing data |
US20060044576A1 (en) | 2004-07-30 | 2006-03-02 | Kabushiki Kaisha Toshiba | Apparatus for image processing |
US7593016B2 (en) * | 2004-04-08 | 2009-09-22 | Teranex Systems, Inc | Method and apparatus for high density storage and handling of bit-plane data |
US7667764B2 (en) | 2004-06-04 | 2010-02-23 | Konica Minolta Holdings, Inc. | Image sensing apparatus |
JP4219887B2 (en) | 2004-12-28 | 2009-02-04 | 富士通マイクロエレクトロニクス株式会社 | Image processing apparatus and image processing method |
ATE504043T1 (en) | 2005-04-28 | 2011-04-15 | Univ Edinburgh | RECONFIGURABLE INSTRUCTION CELL ARRAY |
US7882339B2 (en) | 2005-06-23 | 2011-02-01 | Intel Corporation | Primitives to enhance thread-level speculation |
JP2007067917A (en) | 2005-08-31 | 2007-03-15 | Matsushita Electric Ind Co Ltd | Image data processing apparatus |
US7602974B2 (en) | 2005-10-21 | 2009-10-13 | Mobilic Technology (Cayman) Corp. | Universal fixed-pixel-size ISP scheme |
FR2895103B1 (en) | 2005-12-19 | 2008-02-22 | Dxo Labs Sa | METHOD AND SYSTEM FOR PROCESSING DIGITAL DATA |
US7802073B1 (en) | 2006-03-29 | 2010-09-21 | Oracle America, Inc. | Virtual core management |
US20080111823A1 (en) | 2006-11-13 | 2008-05-15 | Faraday Technology Corp. | Graphics processing system |
US8321849B2 (en) | 2007-01-26 | 2012-11-27 | Nvidia Corporation | Virtual architecture and instruction set for parallel thread computing |
US20080244222A1 (en) | 2007-03-30 | 2008-10-02 | Intel Corporation | Many-core processing using virtual processors |
US8068114B2 (en) * | 2007-04-30 | 2011-11-29 | Advanced Micro Devices, Inc. | Mechanism for granting controlled access to a shared resource |
JP4389976B2 (en) | 2007-06-29 | 2009-12-24 | ブラザー工業株式会社 | Image processing apparatus and image processing program |
JP4844853B2 (en) | 2007-09-05 | 2011-12-28 | 国立大学法人東北大学 | Solid-state imaging device and driving method thereof |
CN102047241B (en) | 2008-05-30 | 2014-03-12 | 先进微装置公司 | Local and global data share |
JP4999791B2 (en) | 2008-06-30 | 2012-08-15 | キヤノン株式会社 | Information processing apparatus, control method thereof, and program |
US8456480B2 (en) | 2009-01-14 | 2013-06-04 | Calos Fund Limited Liability Company | Method for chaining image-processing functions on a SIMD processor |
US8332794B2 (en) * | 2009-01-22 | 2012-12-11 | Taiwan Semiconductor Manufacturing Company, Ltd. | Circuits and methods for programmable transistor array |
US20120030448A1 (en) * | 2009-03-30 | 2012-02-02 | Nec Corporation | Single instruction multiple date (simd) processor having a plurality of processing elements interconnected by a ring bus |
KR101572879B1 (en) | 2009-04-29 | 2015-12-01 | 삼성전자주식회사 | Dynamic parallel system and method for parallel application program |
US20110055495A1 (en) | 2009-08-28 | 2011-03-03 | Qualcomm Incorporated | Memory Controller Page Management Devices, Systems, and Methods |
US8976195B1 (en) | 2009-10-14 | 2015-03-10 | Nvidia Corporation | Generating clip state for a batch of vertices |
US8436857B2 (en) | 2009-10-20 | 2013-05-07 | Oracle America, Inc. | System and method for applying level of detail schemes |
US8595428B2 (en) | 2009-12-22 | 2013-11-26 | Intel Corporation | Memory controller functionalities to support data swizzling |
JP2011165132A (en) * | 2010-02-15 | 2011-08-25 | Seiko Epson Corp | Image processing apparatus, image processing circuit, and image processing method |
JP5835942B2 (en) * | 2010-06-25 | 2015-12-24 | キヤノン株式会社 | Image processing apparatus, control method thereof, and program |
US8749667B2 (en) | 2010-08-02 | 2014-06-10 | Texas Instruments Incorporated | System and method for maintaining maximum input rate while up-scaling an image vertically |
US8508612B2 (en) | 2010-09-30 | 2013-08-13 | Apple Inc. | Image signal processor line buffer configuration for processing ram image data |
US8797323B2 (en) | 2011-01-18 | 2014-08-05 | Intel Corporation | Shadowing dynamic volumetric media |
WO2012105174A1 (en) | 2011-01-31 | 2012-08-09 | パナソニック株式会社 | Program generation device, program generation method, processor device, and multiprocessor system |
US9092267B2 (en) | 2011-06-20 | 2015-07-28 | Qualcomm Incorporated | Memory sharing in graphics processing unit |
JP5739758B2 (en) * | 2011-07-21 | 2015-06-24 | ルネサスエレクトロニクス株式会社 | Memory controller and SIMD processor |
US20130027416A1 (en) | 2011-07-25 | 2013-01-31 | Karthikeyan Vaithianathan | Gather method and apparatus for media processing accelerators |
JP5742651B2 (en) | 2011-10-15 | 2015-07-01 | コニカミノルタ株式会社 | Image processing apparatus, linkage method, and linkage program |
JP5746100B2 (en) | 2011-12-27 | 2015-07-08 | 京セラドキュメントソリューションズ株式会社 | Image forming apparatus |
US8823736B2 (en) | 2012-01-20 | 2014-09-02 | Intel Corporation | Graphics tiling architecture with bounding volume hierarchies |
US10244246B2 (en) | 2012-02-02 | 2019-03-26 | Texas Instruments Incorporated | Sub-pictures for pixel rate balancing on multi-core platforms |
US9235769B2 (en) | 2012-03-15 | 2016-01-12 | Herta Security, S.L. | Parallel object detection method for heterogeneous multithreaded microarchitectures |
TWI520598B (en) | 2012-05-23 | 2016-02-01 | 晨星半導體股份有限公司 | Image processing apparatus and image processing method |
JP5939572B2 (en) * | 2012-07-11 | 2016-06-22 | 国立大学法人東京農工大学 | Data processing device |
US20140019486A1 (en) * | 2012-07-13 | 2014-01-16 | Amitava Majumdar | Logic Content Processing for Hardware Acceleration of Multi-Pattern Search |
US9232139B2 (en) | 2012-07-24 | 2016-01-05 | Apple Inc. | Image stabilization using striped output transformation unit |
CN202736078U (en) * | 2012-07-27 | 2013-02-13 | 华南理工大学 | Feature extraction module used for digital image processing |
US9378181B2 (en) | 2012-11-09 | 2016-06-28 | Intel Corporation | Scalable computing array |
US9449257B2 (en) * | 2012-12-04 | 2016-09-20 | Institute Of Semiconductors, Chinese Academy Of Sciences | Dynamically reconstructable multistage parallel single instruction multiple data array processing system |
CN103019656B (en) * | 2012-12-04 | 2016-04-27 | 中国科学院半导体研究所 | The multistage parallel single instruction multiple data array processing system of dynamic reconstruct |
US9851977B2 (en) * | 2012-12-06 | 2017-12-26 | Kalray | Apparatus and method for combining thread warps with compatible execution masks for simultaneous execution and increased lane utilization |
US8954992B2 (en) | 2013-03-15 | 2015-02-10 | Lenovo Enterprise Solutions (Singapore) Pte. Ltd. | Distributed and scaled-out network switch and packet processing |
US9477999B2 (en) * | 2013-09-20 | 2016-10-25 | The Board Of Trustees Of The Leland Stanford Junior University | Low power programmable image processor |
US9374542B2 (en) | 2014-03-28 | 2016-06-21 | Intel Corporation | Image signal processor with a block checking circuit |
US9818166B2 (en) * | 2015-01-16 | 2017-11-14 | Intel Corporation | Graph-based application programming interface architectures with producer/consumer nodes for enhanced image processing parallelism |
US9749548B2 (en) | 2015-01-22 | 2017-08-29 | Google Inc. | Virtual linebuffers for image signal processors |
-
2015
- 2015-04-23 US US14/694,828 patent/US9965824B2/en active Active
-
2016
- 2016-04-06 KR KR1020197011226A patent/KR102278658B1/en active IP Right Grant
- 2016-04-06 WO PCT/US2016/026221 patent/WO2016171909A1/en active Application Filing
- 2016-04-06 EP EP16719165.9A patent/EP3286726B1/en active Active
- 2016-04-06 JP JP2017550911A patent/JP6571790B2/en active Active
- 2016-04-06 CN CN201680019775.0A patent/CN107438860B/en active Active
- 2016-04-06 DE DE112016001837.1T patent/DE112016001837T5/en active Pending
- 2016-04-06 KR KR1020177028129A patent/KR101973733B1/en active IP Right Grant
- 2016-04-06 EP EP21159716.6A patent/EP3852050A1/en active Pending
- 2016-04-06 CN CN202110291114.6A patent/CN113132558A/en active Pending
-
2017
- 2017-05-18 US US15/599,348 patent/US10417732B2/en active Active
-
2019
- 2019-08-08 JP JP2019146502A patent/JP7202987B2/en active Active
- 2019-08-22 US US16/547,801 patent/US10719905B2/en active Active
Patent Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US6067609A (en) * | 1998-04-09 | 2000-05-23 | Teranex, Inc. | Pattern generation and shift plane operations for a mesh connected computer |
US20080282061A1 (en) * | 2004-08-04 | 2008-11-13 | Hiroyuki Morishita | Array Type Operation Device |
US20080013862A1 (en) * | 2006-07-14 | 2008-01-17 | Fuji Xerox Co., Ltd. | Image processing apparatus, storage medium in which image processing program is stored, and image processing method |
US20080133881A1 (en) * | 2006-12-01 | 2008-06-05 | Thomson Licensing Llc | Array of processing elements with local registers |
US20110134131A1 (en) * | 2008-08-06 | 2011-06-09 | Nxp B.V. | Simd parallel processor architecture |
Non-Patent Citations (1)
Title |
---|
WEI-MIN CHAO 等: "Pyramid Architecture for 3840X2160 Quad Full High Definition 30 Frames/s Video Acquisition", 《IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY》 * |
Also Published As
Publication number | Publication date |
---|---|
JP7202987B2 (en) | 2023-01-12 |
EP3852050A1 (en) | 2021-07-21 |
DE112016001837T5 (en) | 2018-03-08 |
US20160314555A1 (en) | 2016-10-27 |
US10417732B2 (en) | 2019-09-17 |
US20170256021A1 (en) | 2017-09-07 |
JP2018513475A (en) | 2018-05-24 |
JP6571790B2 (en) | 2019-09-04 |
JP2019220202A (en) | 2019-12-26 |
US10719905B2 (en) | 2020-07-21 |
KR101973733B1 (en) | 2019-04-29 |
US20190378239A1 (en) | 2019-12-12 |
CN107438860B (en) | 2021-03-23 |
KR102278658B1 (en) | 2021-07-16 |
US9965824B2 (en) | 2018-05-08 |
KR20170125396A (en) | 2017-11-14 |
CN107438860A (en) | 2017-12-05 |
EP3286726B1 (en) | 2021-03-03 |
KR20190043643A (en) | 2019-04-26 |
EP3286726A1 (en) | 2018-02-28 |
WO2016171909A1 (en) | 2016-10-27 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN107438860B (en) | Architecture for high performance power efficient programmable image processing | |
CN107563952B (en) | Convolutional neural network on programmable two-dimensional image processor | |
US10387989B2 (en) | Compiler techniques for mapping program code to a high performance, power efficient, programmable image processing hardware platform | |
US11140293B2 (en) | Sheet generator for image processor | |
KR101971657B1 (en) | Energy-efficient processor core architecture for image processors | |
CN107533750B (en) | Virtual image processor, and method and system for processing image data thereon | |
US20210165656A1 (en) | Two dimensional masked shift instruction | |
TW201737201A (en) | Compiler managed memory for image processor | |
CN110192220B (en) | Program code conversion for improving image processor runtime efficiency | |
CN110574067A (en) | Image processor I/O unit | |
KR20190107101A (en) | Image processor with support internal network and configurable number of active cores |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination | ||
RJ01 | Rejection of invention patent application after publication |
Application publication date: 20210716 |
|
RJ01 | Rejection of invention patent application after publication |