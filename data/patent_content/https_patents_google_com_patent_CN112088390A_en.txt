CN112088390A - Personalized match score for a place - Google Patents
Personalized match score for a place Download PDFInfo
- Publication number
- CN112088390A CN112088390A CN201980030762.7A CN201980030762A CN112088390A CN 112088390 A CN112088390 A CN 112088390A CN 201980030762 A CN201980030762 A CN 201980030762A CN 112088390 A CN112088390 A CN 112088390A
- Authority
- CN
- China
- Prior art keywords
- user
- score
- preferences
- places
- place
- Prior art date
- Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)
- Pending
Links
Images
Classifications
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q30/00—Commerce
- G06Q30/06—Buying, selling or leasing transactions
- G06Q30/0601—Electronic shopping [e-shopping]
- G06Q30/0631—Item recommendations
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F17/00—Digital computing or data processing equipment or methods, specially adapted for specific functions
- G06F17/10—Complex mathematical operations
- G06F17/18—Complex mathematical operations for evaluating statistical data, e.g. average values, frequency distributions, probability functions, regression analysis
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06F—ELECTRIC DIGITAL DATA PROCESSING
- G06F18/00—Pattern recognition
- G06F18/20—Analysing
- G06F18/24—Classification techniques
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06N—COMPUTING ARRANGEMENTS BASED ON SPECIFIC COMPUTATIONAL MODELS
- G06N20/00—Machine learning
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q30/00—Commerce
- G06Q30/02—Marketing; Price estimation or determination; Fundraising
- G06Q30/0201—Market modelling; Market analysis; Collecting market data
-
- G—PHYSICS
- G06—COMPUTING; CALCULATING OR COUNTING
- G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR
- G06Q30/00—Commerce
- G06Q30/02—Marketing; Price estimation or determination; Fundraising
- G06Q30/0282—Rating or review of business operators or products
Abstract
Personalized scores for places the user may want to visit are calculated and displayed to the user. Calculating a score based on at least one of inferred or explicit preferences using machine learning. The score may be displayed to the user related to the place, and in some examples, an explanation of the underlying factors that led to the score may also be displayed. Because each user is unique, the score for one person may be different from the score for another person. Thus, when a group of friends is at a place decided to visit (such as a place to eat), the personalized score for a given restaurant may be higher for a first user than for a second user.
Description
Cross Reference to Related Applications
This application claims benefit of the filing date of U.S. provisional patent application No. 62/667952, filed on 7/5/2018, the entire contents of which are incorporated herein by reference.
Background
When deciding which location to visit (visit), such as going out to have a meal, looking for things on weekends, shopping, etc., users use various information to help them make decisions. They can view ratings and reviews of the place, consult their friends or family, or rely on third party rankings to form a view of the place. This process can be lengthy and time consuming because everyone will use the information and each individual will not be the same opinion. The user may see the rating or comment and want to know if this reviewer has similar taste to them or cares about the same thing. It can be cumbersome to efficiently browse through large amounts of information about the potential locations of interest.
Disclosure of Invention
According to the present disclosure, personalized scores are provided for places that a user may want to visit. The score is calculated using machine learning, based on at least one of inferred or explicit parameters. The score may be displayed to the user in relation to the location, and in some examples, the user may also view the underlying factors that resulted in the score. Because each user is unique, the score for one person may be different from the score for another person. Thus, when a group of friends is deciding where to visit (such as a place to eat a meal), the personalized score for a first user may be higher for a given restaurant than the personalized score for a second user.
In addition to providing personalized scores, the systems and methods described herein provide a full view of all places that a user may want to know about. Thus, for example, a user can view an arbitrary place (e.g., a place that they hear from others, read in an article, see in an advertisement, etc.) and understand whether the place matches them well. This becomes even more important when trying to make a co-decision with multiple people. Each individual user may want to know whether a location is going for them, even if the location is not the best match for them. Each user may also want to know if the location is a bad match for them, or if one of their limits is violated.
One aspect of the present disclosure provides a method of providing a personal score for a place. The method includes identifying, using one or more processors, one or more places of potential interest to a user, identifying, using one or more processors, user preferences, determining, using one or more processors, an individual score for one or more of the places, the individual score generated based on the identified user preferences, and providing, using one or more processors, the individual score for one or more of the places displayed in association with information about the place. According to some examples, the method may further include receiving the request, matching one or more places of potential interest to the request, and ranking the places matching the request based on the personal score. User preferences may include implicit preferences inferred from information passively collected by the user, with the user's authorization, and/or explicit preferences entered by the user through a user interface. Determining the personal score may include applying a machine learning model. According to some examples, a set of interpretations may also be generated and provided for display, wherein the set of interpretations indicates a reason why the user may like one or more places.
Another aspect of the disclosure provides a system for providing a personal score for a place, comprising one or more memories storing preferences of a user, and one or more processors in communication with the one or more memories. The one or more processors may be configured to receive a request for a place, identify one or more places matching the request, identify user preferences, determine a personal score for one or more of the places matching the request, the personal score generated based on the identified user preferences, and provide the personal score for one or more of the places matching the request displayed in association with information about the places matching the request. The data processing load on the computing resources implementing the method may be reduced because it may no longer be necessary for the system to receive subsequent requests from the user, for example, if the search results are undesirable or not properly customized. Providing personal scores displayed in association with information about a location matching the request may resolve a conflict between providing appropriate information to the user in response to the request and making efficient use of available screen space.
Yet another aspect of the present disclosure provides a method for building a machine learning model to generate an individual score for a place, the individual score based on a preference of a given user. The method may include accessing data from a plurality of sources, using the accessed data to generate a user table including user visited data and online place interactions, using the accessed data to generate a place table including identifications of places matching a particular set of criteria and place-level attributes for identifying preferences, creating a lookup table that associates user identifiers to samples of places that the user indicates places of interest or disinterest, connecting the lookup table to the user table, and training a model using the connected table to predict a personal score for any given place. According to some examples, the method may further include calculating a personal score using the model, receiving a survey result related to an accuracy of the calculated personal score, and modifying the model based on the survey result.
Drawings
FIG. 1 illustrates an example interface according to aspects of the present disclosure.
Fig. 2 is a block diagram illustrating an example system in accordance with aspects of the present disclosure.
Fig. 3 illustrates another example interface according to aspects of the present disclosure.
Fig. 4 illustrates an example of information used to calculate a personalized score, according to aspects of the present disclosure.
Fig. 5 illustrates an example interpretation in accordance with aspects of the present disclosure.
Fig. 6 shows another example of an explanation according to an aspect of the present disclosure.
Fig. 7 is a flow diagram illustrating an example machine learning method in accordance with aspects of the present disclosure.
Fig. 8 is a flow chart illustrating another exemplary machine learning method in accordance with aspects of the present disclosure.
Fig. 9A-9C illustrate other example machine learning models, according to aspects of the present disclosure.
Fig. 10 is a flow diagram illustrating an example method of evaluating a machine learning model in accordance with aspects of the present disclosure.
FIG. 11 is an example interface indicating an example score according to aspects of the present disclosure.
Fig. 12 is another example interface according to aspects of the present disclosure.
13A-13C illustrate example interfaces for editing preferences according to aspects of the present disclosure.
FIG. 14 illustrates an example relationship between a location details page and a score details page in accordance with aspects of the present disclosure.
FIG. 15 illustrates an example relationship between a score details page and a preference edit section in accordance with aspects of the present disclosure.
FIG. 16 illustrates an example interface for obtaining information in accordance with aspects of the present disclosure.
FIG. 17 illustrates an example manipulation of the interface of FIG. 16.
FIG. 18 illustrates an example extension of an interface in accordance with aspects of the present disclosure.
FIG. 19 illustrates an example interface and manipulation of the interface to request feedback in accordance with aspects of the present disclosure.
Fig. 20 is another example illustrating manipulation of an example interface requesting feedback in accordance with aspects of the present disclosure.
Fig. 21 illustrates an example survey in accordance with aspects of the present disclosure.
Fig. 22 illustrates another example survey in accordance with aspects of the present disclosure.
FIG. 23 is a flow diagram illustrating an example method of providing a personal score for a place in accordance with aspects of the present disclosure.
Detailed Description
SUMMARY
The systems and methods described herein predict how well a place matches a user's tastes and preferences. The user's personal preferences are inferred using implicit signals. In some examples, explicit preferences are also collected directly from the user. These user preferences are then matched with the details of the place using a trained machine learning model to predict how well the place matches the user's taste in the form of a score. This score, and an explanation as to why the score was high or low, is provided to the user. The interpretation may include, for example, a location matching a preference that the user likes, or a preference that the user dislikes.
As just one example, the place searched by the user may be a restaurant. A profile may be generated for the user and various portions of the profile may be calculated. These various portions may include attributes such as dietary restrictions, cuisine preferences, environmental preferences, budget sensitivity, and the like. The profile may also include any interactions the user may have with the place, including but not limited to the user's location and web/search history, whether the user saved or bookmarked the place, whether they called or navigated to the place, and uploaded any comments, ratings, or photos for the place. This information can be used to infer locations that the user likes or visits frequently.
The client computing devices used to collect the implicit signals each have privacy settings that must be set to authorize such reporting. For example, a user of a client computing device has the option to turn such reports on or off, and has the option to select which types of information to report and which types of information not to report. For example only, a user may allow reporting for a particular visited location, but not all locations. In addition, privacy protection is provided for any data transmitted by the mobile device, including, for example, anonymization of personally identifiable information, aggregation of data, filtering of sensitive information, encryption, hashing or filtering of sensitive information to remove personal attributes, time limitations for information storage, or limitations on data usage or sharing. A cryptographic hash of the unique identifier may be used to uniquely identify the mobile device, rather than using any personal information.
For many of the inferred attributes, the user is provided with a mechanism for the user to provide, confirm, alter, or delete certain preferences. Depending on the attribute, the value may be "like", "dislike", "nondirectional", "must have", "cannot have", and so on. A profile may also be computed for each place to describe what type of place the place is. For example, each restaurant may have a profile that describes the restaurant by the type of cuisine provided, whether the restaurant caters to a particular diet, or a particular cuisine that the restaurant may have. The restaurant profile may also include information about the restaurant environment, the degree of similarity to another restaurant, price levels, and so forth. A list of paradigms may be generated for the user's favorite locations based on visits, the user's rating/comments of the locations, saving the locations to their favorite location list, and so forth. This can be further expanded to create a comprehensive user-place graph that indicates the user's preferences for each place that the user has interacted with in the past. These location preferences may be used to further determine the likelihood that the user will like to visit similar locations. The location similarity may be based on similarity between location profiles (e.g., similar menus, prices, ratings, environments, descriptions, reviews, etc.), or using collaborative filtering techniques to determine whether similar types of users visit both locations.
Although the above examples refer to restaurants, it should be understood that personalized scores may be generated for any number of different types of places. For example, a score may be generated for a store (e.g., clothing store, grocery store, electronic store, etc.), a hotel, an attraction (e.g., museum, amusement park, etc.), an activity (e.g., concert, sporting event, street mart, etc.), a gas station, or any other point of interest. Scores may also be generated for more general areas that include multiple points of interest, such as for a particular city, mall, etc.
A Machine Learning (ML) model is trained to predict the extent to which a user may like a place. Tags can be collected explicitly by survey questions, an in-app feedback mechanism, or other rating process that we ask the user directly how much they like a place. Tags can also be based on other agent signals such as location visits (location history) or location clicks (Web/search history). Each training example consists of a single label, which may be a survey response, a rating, a visit or click, and so on. The input features of the ML model include all of the implicit and explicit user preferences described above. As described above, the input features also include details about the location. The output of the model includes a score indicating the user's preference for a place, and the extent to which the place matches the user's personal preferences, and an interpretation of which particular attributes contribute most to the final score. For example, if the user is a vegetarian and a restaurant is popular among the vegetarian, the place may receive a high score. In contrast, for vegetarian users, the steak house would receive a low score.
The benefit of solving the problem in this way is to allow a wide range of users to benefit from the recommendation model. Users may passively provide information by authorizing reports of their location and/or search history. The user's preferences or their favorite locations can then be automatically inferred by observing where they visit, click on, or get to go. On the other hand, users who are not authorized to report on their history may still explicitly provide their preferences by setting their preference values and by providing direct feedback (e.g., ratings, comments, star ratings, etc.) as to whether they like places. In addition to inferring scores, a list of personalized reasons is provided for why a user may like or dislike places. These reasons may be directly related to the user profile (such as "because you like < cuisine X >" or "similar to < cuisine Y >" the user likes "), or the user profile may be combined with other information sources such as a list (e.g.," the top 10 places of < cuisine X > in SF "if the user likes < cuisine X >)) to make the reasons even more diverse. Such a listing may be from a third party publication or may be algorithmically generated. These reasons may help the user understand the reasons for recommending places. They also provide the user with the option of upgrading their profile if the inference is incorrect or the user's preferences have changed.
The personalized scoring system and method may be implemented in any of a number of applications, such as a search application, a mapping/navigation application, a scheduling application, a dining/shopping application, etc. For example, the score will be displayed when the user makes a category query (e.g., "restaurant near me") or if they search for a particular location. The score may be displayed in close proximity to other location details (e.g., user ratings, number of reviews, price information, etc.). The user can also click on the score to get a details page that explains how the score is computed (e.g., a list of reasons). In other examples, such as in a mapping application, the score may be displayed in the map itself, in close proximity to the location marker. In addition to merely displaying this score, places may be ranked by this score for recommendation purposes. For example, places with higher personalized scores may be ranked higher when the list is provided in response to a search for "restaurants near me".
In addition to the foregoing example implementations, the systems and methods may be used to send recommendations to a user for any of a number of now known or future developed applications or other products. The scores may be used in conjunction with other business logic for deciding when a recommendation should be made. These scores may also be used to decide which point of interest to display to the user on the map, such as by revealing the point of interest on the map view that the user is most likely to visit, which may allow for more efficient use of the available screen space. The scores may also be used for personalization of the electronic assistant device. For example, the assistant device may recommend restaurants to visit or for ordering, or may recommend things to do on weekends (such as visiting a park, attending a ceramic class, etc.). The assistant may also make recommendations to help the user explore new areas, such as "watch a local hiking trail" or "a favorite bar local to the restaurant". It should be understood that these are merely examples of many possible implementations and should not be considered limiting.
Example System
FIG. 1 illustrates an example display of a person's score for a given location. In this example, graphic 100 includes an image portion 110, a summary information portion 120, and a detailed information portion 130. The graphic 100 may be displayed (e.g., on a client device) in response to a request for information related to service a. For example, the request for information may include an address, a name of the service, a general geographic area, a type of service, and so forth. For example, the user may have submitted a search for restaurants and selected the search results corresponding to restaurant B. While restaurant B has been rated by 247 reviewers in the general public as having 4.5 stars, such information is not specifically tailored to the user. A personal score 125 is also provided, which in this example is 93%. As discussed in more detail below, the individual score 125 may be based on explicit and/or implicit preferences of the user. Such a score may give the user a better indication as to whether the user is likely to like restaurant B.
The image portion 110 includes images associated with the location. For example, for restaurant B, the image may be the interior or exterior of the restaurant, a particular dish provided in the restaurant, etc.
The summary information section 120 may include various information describing the location. For restaurant B, by way of example only, such information includes a rating 121, a price category 122, a distance 123 from a particular location (e.g., the user's location), a classification 124 of the type of food offered, and an individual score 125. Summary portion 120 can also include one or more links 126 to facilitate user actions related to the place. For example, the link 126 may enable the user to call a place, get directions to the place, visit a website of the place, book a table at the place, save the place to one or more personal lists, and so forth. The foregoing are merely examples, and it should be understood that summary information portion 120 may include any of a variety of other types of information. For example, the summary information section 120 can also include text, such as a list of business hours for restaurant B.
The detailed information section 130 may also include information related to the location. In some examples, such information may correspond to information in summary portion 120. For example, a comment to the location corresponding to the rating 121 may be provided. Other examples of detailed information may include descriptions, photographs, and references to places in other mediums, such as news or third party rankings.
Although a number of example portions are described above in connection with fig. 1, and the individual scores 125 are shown as being displayed as percentages, it should be understood that these are examples only. The personal score 125 may be provided for display in any of a variety of ways, such as text, drawings, charts, graphs, and the like. As described in further detail herein, the individual score 125 may also include a link to further information related to the individual score 125. For example, the further information may interpret the information used to determine the score and allow the user to update the information used. In some examples, the personal score may be provided to other applications, such as scheduling applications, communication applications, and the like.
FIG. 2 illustrates an example system for calculating a personal score for a place. The example system should be considered to limit the scope of the disclosure or the usability of the features described herein. In this example, system 200 may include a computing device 210 in communication with one or more client devices 260, 270 and a storage system 240 over a network 250. Each computing device 210 may contain one or more processors 220, memory 230, and other components typically found in general purpose computing devices. The memory 230 of each of the computing devices 210 may store information accessible by the one or more processors 220, including instructions 234 that may be executed by the one or more processors 220.
The memory 230 may also include data 232 that may be retrieved, operated upon, or stored by the processor. The memory may be of any non-transitory type capable of storing information accessible by the processor, such as a hard drive, memory card, ROM, RAM, DVD, CD-ROM, writable and read-only memory.
The instructions 234 may be any set of instructions (such as machine code) to be executed directly or indirectly by one or more processors (such as scripts). In this regard, the terms "instructions," "applications," "steps," and "programs" may be used interchangeably herein. The instructions may be stored in an object code format for direct processing by the processor, or in any other computing device language, including scripts or collections of independent source code modules, which are interpreted or compiled in advance as needed. The function, method and routine of the instructions are explained in more detail below.
The data 232 may be retrieved, stored, or modified by the one or more processors 220 in accordance with the instructions 234. For example, although the subject matter described herein is not limited by any particular data structure, the data may be stored in computer registers, in a relational database as a table or XML document having a plurality of different fields and records. The data may also be formatted in any computing device readable format, such as, but not limited to, binary values, ASCII, or Unicode. Further, the data may include any information sufficient to identify the relevant information, such as numbers, descriptive text, special codes, pointers, references to data stored in other memories (such as at other network locations), or information used by the function to compute the relevant data.
The one or more processors 220 may be any conventional processor, such as a commercially available CPU. Alternatively, the processor may be a dedicated component, such as an Application Specific Integrated Circuit (ASIC) or other hardware based processor. Although not required, one or more of the computing devices 210 may include dedicated hardware components to more quickly or efficiently perform particular computing processes, such as decoding video, matching video frames to images, distorting video, encoding distorted video, and so forth.
Although fig. 2 functionally shows the processor, memory, and other elements of computing device 210 in the same block diagram, the processor, computer, computing device, or memory may actually comprise multiple memories, computers, computing devices, or memories, which may or may not be stored in the same physical housing. For example, the memory may be a hard drive or other storage medium located in a different enclosure than that of computing device 210. Thus, references to a processor, computer, computing device, or memory will be understood to include references to a collection of processors, computers, computing devices, or memories, which may or may not operate in parallel. For example, computing device 210 may comprise a server computing device operating as a load balancing server farm, a distributed system, and the like. Further, while some of the functionality described below is indicated as occurring on a single computing device with a single processor, various aspects of the subject matter described herein may be implemented by multiple computing devices, e.g., communicating information over network 260.
Each of the computing devices 210, 260, 270 may be located at a different node of the network 250 and may be capable of communicating directly and indirectly with other nodes of the network 250. Although only a few computing devices are depicted in fig. 2, it should be understood that a typical system may include a large number of connected computing devices, each located at a different node of network 250. The network 250 and intervening nodes described herein may be interconnected using various protocols or systems, such that the network may be part of the internet, world wide web, a particular intranet, a wide area network, or a local network. The network may use standard communication protocols such as ethernet, WiFi and HTTP, one or more company specific protocols, and various combinations of the foregoing. Although certain advantages are obtained when information is sent or received as described above, other aspects of the subject matter described herein are not limited to any particular manner of information transmission.
By way of example, each of the computing devices 210 may include a web server capable of communicating with the storage system 240 and the computing devices 260, 270 via the network 250. For example, one or more of server computing devices 210 may transmit and present information to a user on a display (such as display 265 of computing device 260) using network 250. In this regard, the computing devices 260, 270 may be considered client computing devices and may perform all or some of the features described herein.
Each of the client computing devices 260, 270 may be configured similar to the server computing device 210, with one or more processors, memory, and instructions described above. Each client computing device 260, 270 may be a personal computing device intended for use by a user and having all the components typically used in connection with a personal computing device such as a Central Processing Unit (CPU), memory (e.g., RAM and internal hard drives) to store data and instructions, a display such as display 265 (e.g., a monitor having a screen, touch screen, projector, television, or other device operable to display information), and a user input device 266 (e.g., a mouse, keyboard, touch screen, or microphone). The client computing device may also include a camera 267 for recording video streams and/or capturing images, speakers, a network interface device, and all components for connecting these elements to one another. Client computing device 260 may also include a location determination system, such as GPS 268. Other examples of a location determination system may determine a location based on wireless access signal strength, images of geographic objects (such as landmarks), semantic indicators (such as light or noise levels), and so forth.
Although the client computing devices 260, 270 may each comprise a full-size personal computing device, they may alternatively comprise mobile computing devices capable of wirelessly exchanging data with a server over a network, such as the internet. By way of example only, client computing device 260 may be a mobile phone or device such as a wireless-enabled PDA, a tablet PC, a netbook, a smart watch, a head-mounted computing system, or any other device capable of obtaining information via the Internet. For example, a user may enter information using a keypad, microphone, with a camera using visual signals, or a touch screen.
Like the memory 230, the storage system 240 may be any type of computerized storage capable of storing information accessible by the server computing device 210, such as a hard drive, memory card, ROM, RAM, DVD, CD-ROM, writable and read-only memory. Further, storage system 240 may comprise a distributed storage system in which data is stored on a plurality of different storage devices physically located at the same or different geographic locations. The storage system may be connected to the computing devices via the network 250 as shown in fig. 2 and/or directly to any of the computing devices 210.
The storage system 240 may store data such as maps, information associated with different locations, user preferences, and the like. Using the stored data, the computing device 110 may determine an individual score for the location, the individual score being customized for each user.
FIG. 3 illustrates an example of providing a personal score for a plurality of search results. User 305 enters a search 308, in this example "dinner". Since user 305 has provided her location either explicitly or by authorizing location sharing on her client device, the user's location may be represented on map 315. The map 315 may also include depictions of geographic objects at particular geographic locations around the user 305. For example, the geographic objects may include roads, buildings, landmarks, statues, signposts, and the like. For example, the object may be depicted in a road map, an aerial image, a street level image, and the like.
A venue responsive to the user's search, such as a venue offering dinner within a predetermined geographic range of the user's location, is identified. Search results may also be represented on the map 315 (such as by marked points). Although not shown in fig. 3, the representation of the search results in the map 315 may also include individual scores. For example, the individual score may be represented by a percentage or other number on or next to the marked point. In other examples, the personal score may be represented by changing the size, shape, shading, or other aspects of the indicia or map. It should be understood that these are merely examples, and any of a variety of indicators may be used.
As shown, the search results may also be listed under the map and include personal scores in the list. In this particular example, the results are shown listed in order of highest personal score. Restaurant B most closely matches the explicit and or implicit preferences of user 305 and is therefore listed at the top with a high personal score of 93%. The next closest match to the user's preferences is restaurant X, with an individual score of 81%. Further matches, with progressively lower scores, may be listed under restaurant X and may be viewed by scrolling or the like.
FIG. 4 provides examples of different parameters that may be used to determine an individual score for a restaurant. As shown, such parameters include a variety of different types of preferences, such as budget, cuisine, fast food, supply, environment, and so forth. The parameters may also include limits. As just one possible example, the limitation may be that the user is allergic to nuts. Thus, a restaurant that places a bowl of peanuts on each table and encourages customers to throw the shells onto the floor would violate the user's restrictions. Such restaurants may receive a very low score or be excluded entirely from the search results. Other parameters may be compared to the user's history. For example, such parameters may include location similarity, favorite locations, visited locations, and the like. If a given restaurant is highly similar to one or more other restaurants that the user has visited or that have indicated as favorites, the given restaurant will receive a higher personal score for the user.
Although a number of example parameters are shown in FIG. 4, it should be understood that a number of other parameters are possible. Further, different types of parameters may be modified based on the type of location being searched. For example, a point of interest (museum, playground, etc.), service (e.g., car wash, salon, etc.), or other type of point of interest has different parameters relative to the characteristics of the location.
FIG. 5 provides examples of the different types of parameters shown in FIG. 4, and further provides examples of how such preferences may be presented to a user. Each example in the left column is listed in association with a type of preference in the right column. In this example, the preferences are ranked in order of importance. While a default order of importance may be used in some examples, in other examples the user may modify the order of importance based on the user's particular interests. In a further example, the order of importance may be determined based on implicit preferences of the user. For example, if the user only visits high-end places, but these places differ in the type of cuisine provided, the budget preference may be prioritized over the cuisine preference.
FIG. 6 provides an example of explicit preferences as compared to inferred preferences. For example, the user may explicitly indicate (such as through a user interface) that the user is a vegetarian and likes italian dish. The same information can be inferred if the user usually visits vegetarian locations as well as italian restaurants.
According to some examples, a combined personal score may be generated for two or more users. For example, two friends may be interested in meeting at a restaurant for dinner, but the two friends may have different personal preferences. Thus, a restaurant with a high personal score for one user may have a low personal score for another user. To accommodate two friends, the combined personal score may take into account factors (positive and negative) based on the preferences of the two users. For example, the first user may identify the second user by information associated with an account of the second user. For example, such information may include a unique identifier, an email address, a username, or any other unique information. Once the first user and the second user are identified, a combined personal score may be generated. The combined personal score may be provided along with other information, such as individual personal scores for the first user and/or the second user. The combined personal score may be provided by any of a number of applications, such as a communication application connecting the first user and the second user.
Machine learning
The personal score may be calculated using machine learning. According to some examples, the process is divided into different stages, including feature extraction, training example generation, model training, and evaluation.
Fig. 7 shows an example of how a personal scoring machine learning model is trained. Each training example consists of a (user, location) pair, optional context information, and a corresponding label. First, various user, location, and context data are concatenated together and a set of feature extractors are applied to the concatenated data to generate relevant machine-learned features. Similarly, a label extractor is applied to the corresponding training data source to generate the necessary labels for the examples.
As previously mentioned, the user, location, context, and training data may come from a variety of sources. User data may include inferred or explicit user preferences, places they visited, ratings and comments they have published, places they have bookmarked or saved, and so forth. The location data may include average star ratings, comments from the public, photographs of the location, web pages referring to the location, price ratings, menu items/cuisine provided, etc. The contextual data may include the time of day, day of week, season, weather, whether the user is traveling, or whether the user is planning with others. Finally, the training data may come from visiting histories, web and search activities, survey responses, user ratings, and the like.
The training data for the model may include both positive and negative factors. Positive factors may include, for example, explicitly answering in a survey that they like the place, the number of times the user has previously visited the place or a similar place, searching for the place, giving a high rating, or other factors indicating that the user may be interested in the place. Negative factors may include direct signals (such as answering in a survey that they dislike the place), giving a low rating, or inferring from the fact that the place has never been visited or interacted with by the user even though the place is close to other places that the user has visited. It should be understood that other training data may be used in addition to or in place of the training data described above.
A set of feature extractors uses the connected user/place/context data and outputs a set of machine-learned features, which may be scalars, category labels, or other suitable values for input into the machine-learned model. The features may depend only on the user data, only on the location data, or on a combination of all data. For example, the feature extracted only from the user data may be the frequency of outgoing meals. This indicates a premise of the possibility that the user would like to visit any restaurant. A feature based solely on location data may be an average star rating of a location or a number of visitors, the feature indicating a popularity of the location. The feature based on the combination of user and location data may be the user's preference for a particular cuisine or menu item provided at the location. Another example may be how similar the location is to one of the user's favorite restaurants. Additional context data may further refine the features to indicate whether the user has different preferences in different contexts, such as preferring convenient locations when raining, or preferring places of interest when traveling.
The label extractor uses the training data and outputs a single label for each instance, which may likewise be a scalar, class label, or other suitable value for the machine learning model. As an example, the tag may be the number of times the user has visited a place, or the tag may be a response that they have selected when asked in a survey to the extent that the user likes the place.
Depending on the selected set of features and labels, different machine learning models may be used. Such models may be trained in parallel. Some features may be common across all models, while each model may have its own particular features. A shared set of feature extractors may be developed. Each model may then select a desired subset of extractors. Similarly, different models may share the same tag extractor or use different tag extractors. As an example, the machine learning model may be a linear regression or deep neural network model that predicts how many times the user visits the site. As another example, the model may be a general regression model that predicts what the user will answer when they are asked in the survey to the extent that they like the place.
Fig. 8 shows an example of how the learned model may be applied. Given the (user, location) pairs and optional context information, the model may be used to predict a score indicating how much the user likes a location. In addition, the model will output a set of interpretations of why the user liked or disliked the place.
Based on the individual scores and interpretations shown to the user, the user may provide feedback or use other explicit controls to adjust their preferences. This may allow users to have finer grained control over their own data and improve the accuracy of the predicted individual scores.
The signals for the machine learning model may include both personalized signals and context signals so that the model can intelligently predict what the user prefers in a particular context. Examples of such signals include cuisine preferences expressed as scalar values, similar places, location, weather, time, dietary restrictions, similarity to other saved places, visited or high rated places, budget category, or any of a variety of other factors.
Fig. 9A illustrates an example linear machine learning model. In this model, user, location and context signals are mapped to a physical visited binary label. The positive tag is extracted directly from the user visit history. Negative tags are approximated from unexplored places near visited places. A user profile is a vector of unique identifications for users visiting more places than an average user within the same area. In some examples, the model may be enhanced by adding user search queries. The location profile includes a unique identifier and/or unique attributes of the location. By applying text embedding, text (such as comments, keywords, etc.) can be added as part of the place feature. Contextual characteristics include location, time, and weather. In the linear model, feature intersections can be applied between features (e.g., between budget preferences and cuisine, between time and other user/place profiles, etc.).
FIG. 9B illustrates an example user intent model. This model predicts the user's intent in terms of a unique identifier and unique attributes of a place. The intention model uses all personalization signals and context signals.
FIG. 9C illustrates an example binary intent model. This model uses intent as a feature and predicts binary labels for visits and clicks. This model requires a negative label. Click data may be used as a training label, in which case a negative label is an impression of intent without a click. The visit data may also be used as training labels, in which case a negative sampling method is applied to create a composite training label.
An individual score is generated using one or more of the models. For example only, the score may be calculated using linear regression.
During the training and evaluation phase, the machine learning model may be evaluated using survey and/or user generated data. For example, a survey may be provided to real users asking them for opinions about the places recommended by the model, as well as their opinions about the personal scores generated for them about the places. User generated data, such as ratings, reviews, lists of user-saved and favorite places, etc., may also be used by themselves, alone or in combination with surveys.
The evaluation of the machine learning model may focus on various metrics. For example, the evaluation metric may focus on the ranking of a particular place relative to other places. Additionally or alternatively, the evaluation metric may focus on individual scores generated for a particular location.
Fig. 10 shows an example of how survey data may be used to evaluate a machine learning model. To determine whether the results of one model can be distinguished from the results of another model, a paired t-test can be performed to see if the scores generated by the models differ significantly. Each t-test runs a set of sample data through one of the models. If the scores are not significantly different, another set of sample data may be tried. If the scores are significantly different, other metrics are calculated. For example, other metrics may include precision, recall, correctness, relevance between individual scores and user responses, and the like.
The results from the machine learning model may also be adjusted using, for example, explicit user preferences. For example, as mentioned above, the personal score for a particular location may be presented to the user along with an explanation of the factors that led to the generation of the personal score. The user may edit one or more factors, for example, by changing any of budget preferences, cuisine preferences, or factors. In such a case, an updated score may be generated.
User interface
Users may interact with their personal scores, such as viewing underlying factors or providing explicit preferences through a user interface. Examples of different aspects of the user interface are provided in fig. 11-22.
FIG. 11 provides an example of a possible score details page providing the user with information regarding the personal score for restaurant B in a particular location. In this example, the personal score is provided along with other summary information, such as the name of the restaurant, the type of cuisine provided, and the rating of the general public.
Further, as shown in FIG. 11, score details may also be provided. The score details section may list one or more explicit or inferred preferences that resulted in the score. Such preferences may include all or only selected ones of the preferences used. For example, in some examples, the score details section may list only a predetermined number of preferences that are given the greatest weight in the calculation of the individual score. In some examples, this list of preferences may also include links to update preferences. For example, the user may click "on your list of wanted" and be taken to another screen or web page or application showing the user's list of "wanted to go".
In some examples, a "how this is calculated" section may also be provided. This section may provide an explanation of the different types of reported information and be used to calculate the personal score. Additionally or alternatively, this portion may provide a link to edit the user's preferences. For example, a separate link may be provided that updates discrete information (such as turning a location history report on or off). A general link may also be provided that takes the user to a preferences edit section (e.g., "update your preferences"), such as those described below in connection with fig. 13A-13C.
FIG. 12 illustrates an example interface for a location details page where a personal score is not generated due to a lack of information. For example, if the user has not authorized reporting of location or web browsing history, and has not provided any explicit preferences, the machine learning model may not have enough information to calculate the score. In such a case, a prompt (such as a link with text requesting "tell us about your preferences", etc.) may be presented to the user. When interacting with the prompt, the user may be taken to the preferences edit section.
13A-13C provide various examples of a preference edit section. In the example of fig. 13A, preferences are indicated using tiles (tile). For example, various tiles may be displayed for each of a number of different categories. For restaurants, categories may include dietary preferences, budgets, tastes, cuisine, environmental, or other preferences. Each category may further include one or more options. The options may be represented by various types of graphics. For example, fig. 13A uses the patch representation option.
Each option may be marked by the user as a positive or negative preference, which may be reflected using a positive or negative indicator. The positive or negative indicators can include any of a variety of different representations, such as colors/shades, graphics (e.g., check marks, "x", circles with a line passing therethrough, etc.), or other representations. As shown in the example of fig. 13A, the categories of tastes include options for wine, cocktail, spirit, dessert, and pickles. The categories of environments include leisure, comfort, fashion, and others. It should be understood that the categories and options are merely examples, and any of a variety of different categories and options may be provided. In the taste category, the user has indicated his positive preference for favoring cocktails. In the environment category, the user has indicated a negative bias that he does not like a buzzy spot. In some examples, a user may indicate more than one positive or negative preference in a category.
Fig. 13B shows an example of representing options in a list format with a radio button next to each list item. The user may interact with the radio button to indicate a positive preference or a negative preference for an option in a list item.
Fig. 13C shows an example of representing options using a chip (chip). The patch shown is smaller than the patch of fig. 13A, so that more patches are visible in a given area. The user may interact with each tile to indicate a positive preference or a negative preference for the options represented by the tile.
13A-13C provide various examples of user interfaces for the preference edit section, it should be understood that various alternatives are possible. For example, the options may be represented by any of a number of different types of graphics. In some examples, the user may interact with the options to obtain more details about the options, such as a description.
FIG. 14 illustrates an example relationship between a location details page and a score details page. An example of a location details page is described above in connection with FIG. 1. The personal score provided on the location details page may be a link. As described in detail above in connection with FIG. 11, a score details page may be presented to the user as the user interacts with the link. In this example, the score details page also includes a section for user feedback. For example, this section may prompt the user to confirm whether the personal score is accurate based on the user's experience at restaurant B, or prompt the user to provide any other type of feedback. Further details of the feedback section are described below in connection with fig. 19-20.
FIG. 15 illustrates an example relationship between the score details page and the preference edit section. In this example, the score details page provides links to edit user preferences. Interacting with the link takes the user to the preference edit section where the user can alter their indication of whether any particular option has a positive or negative preference.
FIG. 16 illustrates an example information page that may be presented to a user when a personal score match is first achieved. For example, similar to fig. 12, further information about the user's preferences may be needed in order to generate a personal score. Thus, the information page is presented to the user. The information page may seek input from the user regarding what types of features are important to the user when selecting a restaurant or other point of interest. In some examples, various options may be presented as shortcuts, such as cocktail, pizza, romantic, and so forth. Links to the complete preference edit section are also presented.
FIG. 17 shows example interactions with the shortcut button of FIG. 16. For example, if the user clicks the "vegetarian" shortcut button, the user may be taken to a preferences page. On the preferences page, the vegetarian preferences are updated to positive preferences and are therefore represented using positive indicators. In addition to the dietary categories, further categories are presented. In this example, such further categories include budget, cuisine, and there are still more categories if the user scrolls further down. Each of these categories includes various options that can be selected by the user to indicate a positive preference or a negative preference. Once the user indicates preferences on the preferences page, the user may be taken to an updated information page. The updated information page includes a matching score, here 80%, based on the preferences indicated by the user on the preferences page.
FIG. 18 illustrates an example interface for a location details page, where one or more sections may be expanded to view further information. For example, if the portion explaining the basis for the matching score includes multiple factors, the list of factors may be compressed by hiding one or more factors (such as factors of low importance). If the user is interested in seeing such additional factors, the user may interact with a portion of the screen (such as an arrow button or the linked text "3 more" or any other type of link not shown). Under such interaction, the list may be expanded to make visible the previously hidden factors.
As mentioned above in connection with FIG. 14, the location details page may include a section that requests feedback from the user. Fig. 19 shows an example of the requested feedback. In this example, the user is asked whether the personal score appears to be correct. For example, the user may view information about restaurant B, such as summary information, other user reviews, restaurant B's website, menus, or any other available information from any of a number of sources. The user may also visit restaurant B and attempt to eat dinner there. The user can then determine whether the personal score is approximately the same as the user's own evaluation of restaurant B. If the user determines that the personal score is accurate, the user may click "Yes". Such feedback may be used to identify and reinforce machine learning models used to calculate scores. As shown in fig. 19, such feedback may also be used to suggest places similar to restaurant B that the user may also like.
Fig. 20 shows an example where the user indicates that the score seems inaccurate in the feedback section. To determine a more accurate score, the user may be required to provide additional feedback. As an example, the user may be required to update the user preferences. The user may additionally or alternatively be given the option of authorizing an automatic report. Other types of feedback (such as comments, etc.) are also possible. Additional feedback may be used to generate updated individual scores for the user.
Another type of feedback includes surveys. 21-22 illustrate examples of surveys that may be provided to a user. In FIG. 21, the survey is based on the actual visit of the user to the location. For example, if the user has authorized location reporting, a survey may be presented to the user upon determining that the user's device visited a location that matches the place. The survey may present one or more questions, such as asking the user if the user likes the location. The user may respond in any of a number of ways, not shown, including selecting a response button or using other features to interact with the survey.
In fig. 22, survey request confirmation of predictions is made based on the user's activities. For example, for activities in which the user visits a particular location, the model may infer that the user likes a particular option, such as a cocktail. The user may be required to confirm this inference or update the user's preferences if such inference is incorrect.
Example method
In addition to the example systems described above, example methods are now described. Such a method may be performed using any of the above-described systems, modifications thereof, or various systems having different configurations. It should be understood that the operations involved in the following methods need not be performed in the exact order described. Conversely, various operations may be processed in a different order or concurrently, and operations may be added or omitted.
Fig. 23 provides a flow chart illustrating a method 2300 of providing a personal score for a place. In block 2310, a request for a place is received. For example, the request may be a search entered through a search engine, a mapping application, or any other type of website, application, or the like. The location may be requested using various types of information, such as name, address, category, general location, etc. For example, the request may specify "near my gas station" or "what to do in Springfield" or any other such information. The requested location may be any number of different types of locations, such as restaurants, stores, banks, gas stations, fitness centers, museums, and the like.
In block 2320, a place matching the request is identified. As an example, all places within a predetermined geographic range may be identified as candidates for recommendation to the user. In some examples, the locations identified as matching the request may be indicated to the user on a map or in any other form.
In block 2330, user preferences are identified. The user preferences may be related to the type of location requested. For example, if the type of venue requested is a venue for a meal, the identified user preferences may be related to cuisine, budget, environment, and the like. If the type of location requested is a clothing store, the user preferences may relate to budget, style, etc. User preferences may be identified from a larger set of stored user preferences. For example, if a user authorizes location reporting or web history reporting, the user preferences may include inferences based on locations or websites previously visited by the user. The user preferences may also include explicit preferences entered by the user. Such explicit preferences may be entered at any time before or after the request is entered. In some examples, the user preferences may also include restrictions. For example, if a user cannot go to a particular type of restaurant because of a food allergy, such food allergy may be identified as a restriction. Various other types of constraints are also possible.
In block 2340, a personal score is generated for one or more of the places matching the request. The personal score is specific to the user and is generated based on the identified user preferences. The individual scores may be generated using a machine learning model, such as described above in connection with fig. 7-10.
In block 2350, places matching the request may optionally be sorted according to individual scores. For example, the results may be ranked from highest personal score to lowest personal score. In some examples, the ranking may be based on a number of factors, such as the individual score combined with the location. Further, matches that violate the constraints may be filtered from the results.
In block 2360, the personal score is provided for display, such as by transmission to a device of the user. For example, the personal score for a particular result may be provided along with other information about the particular result.
It should be understood that the above-described methods are merely examples and that other methods may be implemented. For example, recommendations may be proactively sent to the user without receiving a request from the user. For example, periodic (e.g., weekly) suggestions may be sent to the user based on locations in the area of interest to the user that have high personal scores.
Unless otherwise indicated, the foregoing alternatives are not mutually exclusive and may be implemented in various combinations to achieve unique advantages. As these and other variations and combinations of the features discussed above can be used without departing from the subject matter defined by the claims, the foregoing description of the embodiments should be taken by way of illustration rather than by way of limitation of the subject matter defined by the claims. Furthermore, the provision of examples described herein and phrases such as "and" including "and the like should not be construed to limit claimed subject matter to the particular examples; rather, the example is intended to illustrate only one of many possible embodiments. Moreover, the same reference numbers in different drawings may identify the same or similar elements.
Claims (20)
1. A method, comprising:
identifying, using one or more processors, one or more locations of potential interest to a user;
identifying, using one or more processors, a user preference;
determining, using one or more processors, an individual score for one or more of the places, the individual score generated based on the identified user preferences; and
providing, using one or more processors, a personal score for one or more of the places displayed in association with information about the places.
2. The method of claim 1, further comprising:
receiving a request;
matching the one or more places of potential interest with the request; and
ranking places matching the request based on the individual score.
3. The method of claim 1 or 2, wherein the user preferences comprise explicit preferences entered by a user through a user interface.
4. The method of claim 1 or 2 or 3, wherein the user preferences include implicit preferences inferred from information passively collected from the user with the user's authorization.
5. The method of any preceding claim, wherein determining the personal score comprises applying a machine learning model.
6. The method of any preceding claim, further comprising:
determining a set of interpretations for the determined individual score, an
Providing an explanation for display with the personal score.
7. The method of claim 6, wherein the set of interpretations indicates a reason why the user may like the one or more places.
8. The method of claim 6 or 7, wherein the set of interpretations are generated based on the identified user preferences and information about the one or more places.
9. A system, comprising:
one or more memories storing preferences of a user;
one or more processors in communication with the one or more memories, the one or more processors configured to:
receiving a request for a location;
identifying one or more places matching the request;
identifying a user preference;
determining an individual score for one or more of the places matching the request, the individual score generated based on the identified user preferences; and
providing the personal score for one or more of the places matching the request displayed in association with information about places matching the request.
10. The system of claim 9, wherein the one or more processors are further configured to rank places matching the request based on the personal score.
11. The system of claim 9 or 10, wherein the user preferences comprise explicit preferences entered by a user through a user interface.
12. The system of claim 9, 10 or 11, wherein the user preferences include implicit preferences inferred from information passively collected from the user with the user's authorization.
13. The system of any of claims 9 to 12, wherein determining the personal score comprises applying a machine learning model.
14. The system of any of claims 9-13, wherein the one or more processors are further configured to determine a set of interpretations for the determined score, and provide the set of interpretations for display.
15. A method for building a machine learning model to generate an individual score for a place, the individual score based on a given user's preferences, the method comprising:
accessing data from a plurality of sources;
generating a user table using the accessed data, the user table including user access data and online location interactions;
generating a place table using the accessed data, the place table including an identification of places that match a particular set of criteria and place-level attributes for identifying preferences;
creating a look-up table that associates user identifications to samples of places, the samples being places that the user has indicated interest or disinterest;
connecting the look-up table to the user table; and
the model is trained using the connected tables to predict the individual score for any given place.
16. The method of claim 15, further comprising:
calculating a personal score using the model;
receiving survey results related to the accuracy of the calculated personal score; and
modifying a model based on the survey results.
17. The method of claim 15 or 16, wherein the model is one of a linear classification model, a linear regression model, or a general regression model.
18. The method of claim 15, 16 or 17, wherein the training data for the model includes positive and negative factors.
19. The method of claim 18, wherein:
the positive factor relates to at least one of a user's previous visits to the place or a user's previous online interactions with the place; and
the negative factors relate to places that the user has not visited and interacted with previously, or places that the user has indicated a negative bias.
20. The method of any of claims 15 to 19, wherein the signal for the model may include both a personalization signal and a context signal.
Applications Claiming Priority (3)
Application Number | Priority Date | Filing Date | Title |
---|---|---|---|
US201862667952P | 2018-05-07 | 2018-05-07 | |
US62/667,952 | 2018-05-07 | ||
PCT/US2019/030873 WO2019217293A1 (en) | 2018-05-07 | 2019-05-06 | Personalized match score for places |
Publications (1)
Publication Number | Publication Date |
---|---|
CN112088390A true CN112088390A (en) | 2020-12-15 |
Family
ID=66625287
Family Applications (1)
Application Number | Title | Priority Date | Filing Date |
---|---|---|---|
CN201980030762.7A Pending CN112088390A (en) | 2018-05-07 | 2019-05-06 | Personalized match score for a place |
Country Status (4)
Country | Link |
---|---|
US (1) | US20190340537A1 (en) |
EP (1) | EP3776436A1 (en) |
CN (1) | CN112088390A (en) |
WO (1) | WO2019217293A1 (en) |
Families Citing this family (13)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US11348145B2 (en) * | 2018-09-14 | 2022-05-31 | International Business Machines Corporation | Preference-based re-evaluation and personalization of reviewed subjects |
US11361366B2 (en) * | 2019-10-01 | 2022-06-14 | EMC IP Holding Company LLC | Method, computer program product, and apparatus for workspace recommendations based on prior user ratings and similar selections |
US11699122B2 (en) | 2019-11-21 | 2023-07-11 | Rockspoon, Inc. | System and method for matching patrons, servers, and restaurants within the food service industry |
US11580460B2 (en) * | 2020-03-06 | 2023-02-14 | Airbnb, Inc. | Database systems for similar accommodation determination |
US11574257B2 (en) * | 2020-03-06 | 2023-02-07 | Airbnb, Inc. | Database systems for non-similar accommodation determination |
US11768945B2 (en) * | 2020-04-07 | 2023-09-26 | Allstate Insurance Company | Machine learning system for determining a security vulnerability in computer software |
US11854402B2 (en) * | 2020-07-10 | 2023-12-26 | Here Global B.V. | Method, apparatus, and system for detecting lane departure events based on probe data and sensor data |
US11494675B2 (en) * | 2020-08-03 | 2022-11-08 | Kpn Innovations, Llc. | Method and system for data classification to generate a second alimentary provider |
US20220138620A1 (en) * | 2020-11-03 | 2022-05-05 | Kpn Innovations, Llc. | Method and system for selecting an alimentary provider |
CN112328918B (en) * | 2021-01-06 | 2021-03-23 | 中智关爱通(南京)信息科技有限公司 | Commodity sorting method, computing device and computer-readable storage medium |
WO2023283116A1 (en) * | 2021-07-07 | 2023-01-12 | Capital One Services, Llc | Customized merchant price ratings |
US11663620B2 (en) | 2021-07-07 | 2023-05-30 | Capital One Services, Llc | Customized merchant price ratings |
US11789685B1 (en) * | 2022-08-29 | 2023-10-17 | International Business Machines Corporation | Training and using a machine learning module to determine locales and augmented reality representations of information on locales to render in an augmented reality display |
Citations (5)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20070118498A1 (en) * | 2005-11-22 | 2007-05-24 | Nec Laboratories America, Inc. | Methods and systems for utilizing content, dynamic patterns, and/or relational information for data analysis |
WO2013013091A1 (en) * | 2011-07-20 | 2013-01-24 | Ness Computing, Inc. | A recommendation engine that processes data including user data to provide recommendations and explanations for the recommendations to a user |
US8463295B1 (en) * | 2011-12-07 | 2013-06-11 | Ebay Inc. | Systems and methods for generating location-based group recommendations |
CN104520881A (en) * | 2012-06-22 | 2015-04-15 | 谷歌公司 | Ranking nearby destinations based on visit likelihoods and predicting future visits to places from location history |
US9122757B1 (en) * | 2011-06-19 | 2015-09-01 | Mr. Buzz, Inc. | Personal concierge plan and itinerary generator |
Family Cites Families (10)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20140031060A1 (en) * | 2012-07-25 | 2014-01-30 | Aro, Inc. | Creating Context Slices of a Storyline from Mobile Device Data |
US20140074395A1 (en) * | 2012-09-13 | 2014-03-13 | Michael Brown | Method of displaying points of interest and related portable electronic device |
US11494390B2 (en) * | 2014-08-21 | 2022-11-08 | Affectomatics Ltd. | Crowd-based scores for hotels from measurements of affective response |
US20160217412A1 (en) * | 2015-01-28 | 2016-07-28 | International Business Machines Corporation | People queue optimization and coordination |
US10510105B2 (en) * | 2016-06-10 | 2019-12-17 | Oath Inc. | Traveler recommendations |
US10769549B2 (en) * | 2016-11-21 | 2020-09-08 | Google Llc | Management and evaluation of machine-learned models based on locally logged data |
US20190102709A1 (en) * | 2017-10-03 | 2019-04-04 | Invight, Inc. | Systems and methods for coordinating venue systems and messaging control |
US10648826B2 (en) * | 2017-12-20 | 2020-05-12 | Mastercard International Incorporated | Providing stop recommendations based on a travel path and transaction data |
US20200118221A1 (en) * | 2018-10-16 | 2020-04-16 | Athan Slotkin | System and method for making group decisions |
WO2020219462A1 (en) * | 2019-04-23 | 2020-10-29 | The Mewah Corporation | Methods and systems for generating restaurant recommendations |
-
2019
- 2019-05-06 US US16/404,148 patent/US20190340537A1/en active Pending
- 2019-05-06 WO PCT/US2019/030873 patent/WO2019217293A1/en unknown
- 2019-05-06 EP EP19725478.2A patent/EP3776436A1/en active Pending
- 2019-05-06 CN CN201980030762.7A patent/CN112088390A/en active Pending
Patent Citations (6)
Publication number | Priority date | Publication date | Assignee | Title |
---|---|---|---|---|
US20070118498A1 (en) * | 2005-11-22 | 2007-05-24 | Nec Laboratories America, Inc. | Methods and systems for utilizing content, dynamic patterns, and/or relational information for data analysis |
US9122757B1 (en) * | 2011-06-19 | 2015-09-01 | Mr. Buzz, Inc. | Personal concierge plan and itinerary generator |
WO2013013091A1 (en) * | 2011-07-20 | 2013-01-24 | Ness Computing, Inc. | A recommendation engine that processes data including user data to provide recommendations and explanations for the recommendations to a user |
US8463295B1 (en) * | 2011-12-07 | 2013-06-11 | Ebay Inc. | Systems and methods for generating location-based group recommendations |
CN104520881A (en) * | 2012-06-22 | 2015-04-15 | 谷歌公司 | Ranking nearby destinations based on visit likelihoods and predicting future visits to places from location history |
CN107273437A (en) * | 2012-06-22 | 2017-10-20 | 谷歌公司 | The method and system of the offer information related to the place that user may access |
Also Published As
Publication number | Publication date |
---|---|
US20190340537A1 (en) | 2019-11-07 |
WO2019217293A1 (en) | 2019-11-14 |
EP3776436A1 (en) | 2021-02-17 |
WO2019217293A9 (en) | 2020-01-23 |
Similar Documents
Publication | Publication Date | Title |
---|---|---|
CN112088390A (en) | Personalized match score for a place | |
US11709851B2 (en) | Method and apparatus for quickly evaluating entities | |
US20230042931A1 (en) | Menu Personalization | |
JP5331795B2 (en) | Advertisement display method, advertisement display system, and advertisement display program | |
US8880516B2 (en) | Endorsing local search results | |
US9223866B2 (en) | Tagged favorites from social network site for use in search request on a separate site | |
JP5479673B2 (en) | How to filter virtual content | |
US8620764B2 (en) | Method for providing a recommendation such as a personalized recommendation, recommender system, and computer program product comprising a recommender computer program | |
US8595297B2 (en) | Searching data in a social network to provide an answer to an information request | |
US9110894B2 (en) | Systems and methods for determining related places | |
US20130024449A1 (en) | Method and apparatus for allowing users to augment searches | |
US9122757B1 (en) | Personal concierge plan and itinerary generator | |
US20140279196A1 (en) | System and methods for providing spatially segmented recommendations | |
US20130097162A1 (en) | Method and system for generating and presenting search results that are based on location-based information from social networks, media, the internet, and/or actual on-site location | |
AU2020286214B2 (en) | Persona for opaque travel item selection | |
TW201514735A (en) | System and method for providing targeted applications within a search results page | |
US9720570B2 (en) | Dynamic sorting and inference using gesture based machine learning | |
KR20100089030A (en) | System and method for communal search | |
WO2019005319A1 (en) | Storage of point of interest data on a user device for offline use | |
KR20150083673A (en) | Method and apparatus for providing tour plan service | |
Győrödi et al. | An extended recommendation system using data mining implemented for smart phones | |
Sarasa-Cabezuelo | Development of a Restaurant Recommendation System | |
Fernandes et al. | Interacting and making personalized recommendations of places of interest to tourists | |
AU2012283929B2 (en) | Method and apparatus for allowing users to augment searches | |
CN116940954A (en) | Personalized product and service search network platform designed by user |
Legal Events
Date | Code | Title | Description |
---|---|---|---|
PB01 | Publication | ||
PB01 | Publication | ||
SE01 | Entry into force of request for substantive examination | ||
SE01 | Entry into force of request for substantive examination |